{"text": " The following is a conversation with Jeff Hawkins. He's the founder of the Redwood Center for Theoretical Neuroscience in 2002 and New Menta in 2005. In his 2004 book titled On Intelligence and in the research before and after, he and his team have worked to reverse engineer the New York Cortex and propose artificial intelligence architectures approaches and ideas that are inspired by the human brain. These ideas include hierarchical temporal memory, HTM from 2004, and new work, the 1000s brain theory of intelligence from 2017, 18, and 19. Jeff's ideas have been an inspiration to many who have looked for progress beyond the current machine learning approaches, but they have also received criticism for lacking a body of empirical evidence supporting the models. This is always a challenge when seeking more than small incremental steps forward in AI. Jeff is a brilliant mind and many of the ideas he has developed and aggregated from neuroscience are worth understanding and thinking about. There are limits to deep learning as it is currently defined. Forward progress in AI is shrouded in mystery. My hope is that conversations like this can help provide an inspiring spark for new ideas. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, iTunes, or simply connect with me on Twitter at Lex Friedman spelled F-R-I-D. And now here's my conversation with Jeff Hawkins. I also firmly believe that we will not be able to create fully intelligent machines until we understand how the human brain works. So I don't see those as separate problems. I think there's limits to what can be done with machine intelligence if you don't understand the principles by which the brain works. And so I actually believe that studying the brain is actually the fastest way to get to machine intelligence. And within that, let me ask the impossible question. How do you not define but at least think about what it means to be intelligent? So I didn't try to answer that question first. We said let's just talk about how the brain works and let's figure out how certain parts of the brain, mostly the neocortex, but some other parts too, the parts of the brain most associated with intelligence, and let's discover the principles by how they work. Because intelligence isn't just like some mechanism and it's not just some capabilities. It's like, okay, we don't even know where to begin on this stuff. And so now that we've made a lot of progress on this, after we've made a lot of progress on how the neocortex works, and we can talk about that, I now have a very good idea what's going to be required to make intelligent machines. I can tell you today, some of the things are going to be necessary, I believe, to create intelligent machines. Well, so we'll get there. We'll get to the neocortex and some of the theories of how the whole thing works. And you're saying, as we understand more and more about the neocortex, about our own human mind, we'll be able to start to more specifically define what it means to be intelligent. It's not useful to really talk about that until... I don't know if it's not useful. Look, there's a long history of AI, as you know. And there's been different approaches taken to it. And who knows, maybe they're all useful. So the good old fashioned AI, the expert systems, the current convolutional neural networks, they all have their utility. They all have a value in the world. But I would think almost everyone agree that none of them are really intelligent in a sort of a deep way that humans are. And so it's just the question is how do you get from where those systems were or are today to where a lot of people think we're going to go? And there's a big, big gap there, a huge gap. And I think the quickest way of bridging that gap is to figure out how the brain does that. And then we can sit back and look and say, oh, what are these principles that the brain works on are necessary and which ones are not? Clearly, we don't have to build this in... and intelligent machines aren't going to be built out of organic living cells. But there's a lot of stuff that goes on the brain that's going to be necessary. So let me ask maybe, before we get into the fun details, let me ask maybe a depressing or a difficult question. Do you think it's possible that we will never be able to understand how our brain works? That maybe there's aspects to the human mind, like we ourselves cannot introspectively get to the core, that there's a wall you eventually hit? Yeah, I don't believe that's the case. I have never believed that's the case. There's not been a single thing we've ever, human have ever put their minds to. We've said, oh, we reached the wall. We can't go any further. People keep saying that. People used to believe that about life, you know, Alain Vaital, right? There's like, what's the difference between living matter and non-living matter? Something special you never understand. We no longer think that. So there's no historical evidence that suggests this is the case. And I just never even consider that's a possibility. I would also say I would also say today we understand so much about the near cortex. We've made tremendous progress in the last few years that I no longer think of as an open question. The answers are very clear to me. The pieces we know we don't know are clear to me, but the framework is all there. And it's like, oh, okay, we're going to be able to do this. This is not a problem anymore. It just takes time and effort. But there's no mystery, big mystery anymore. So then let's get into it for people like myself who are not very well versed in the human brain, except my own. Can you describe to me at the highest level, what are the different parts of the human brain and then zooming in on the near cortex, the parts of the near cortex and so on, a quick overview? Yeah, sure. The human brain, we can divide it roughly into two parts. There's the old parts, lots of pieces, and then there's the new part. The new part is the near cortex. It's new because it didn't exist before mammals. The only mammals have a near cortex and in humans, in primates, it's very large. In the human brain, the near cortex occupies about 70 to 75% of the volume of the brain. It's huge. And the old parts of the brain are, there's lots of pieces there. There's a spinal cord, and there's the brain stem, and the cerebellum, and the different parts of the basal ganglion and so on. In the old parts of the brain, you have the autonomic regulation like breathing and heart rate. You have basic behaviors. So like walking and running are controlled by the old parts of the brain. All the emotional centers of the brain are in the old part of the brain. So when you feel anger or hungry, lust or things like that, those are all in the old parts of the brain. And we associate with the near cortex all the things we think about as sort of high level perception and cognitive functions, anything from seeing and hearing and touching things to language to mathematics and engineering and science and so on. Those are all associated with the near cortex. And they're certainly correlated. Our abilities in those regards are correlated with the relative size of our near cortex compared to other mammals. So that's like the rough division. And you obviously can't understand the near cortex completely isolated, but you can understand a lot of it with just a few interfaces to the old parts of the brain. And so it gives you a system to study. The other remarkable thing about the near cortex compared to the old parts of the brain is the near cortex is extremely uniform. It's not visibly or anatomically or it's very it's like a I always like to say it's like the size of a dinner napkin about two and a half millimeters thick. And it looks remarkably the same everywhere. Everywhere you look in that two and a half millimeters is this detailed architecture. And it looks remarkably the same everywhere. And that's across species, a mouse versus a cat and a dog and a human. Where if you look at the old parts of the brain, there's lots of little pieces do specific things. So it's like the old parts of a brain involved like this is the part that controls heart rate. And this is the part that controls this and this is this kind of thing. And that's this kind of thing. And these evolve for eons of a long, long time. And they have those specific functions. And all of a sudden mammals come along and they got this thing called the near cortex. And it got large by just replicating the same thing over and over and over again. This is like, wow, this is incredible. So all the evidence we have. And this is an idea that was first articulated in a very cogent and beautiful argument by a guy named Vernon Malcastle in 1978, I think it was, that the neocortex all works on the same principle. So language, hearing, touch, vision, engineering, all these things are basically underlying or all built in the same computational substrate. They're really all the same problem. So the low level of the building blocks all look similar. Yeah. And they're not even that low level. We're not talking about like neurons. We're talking about this very complex circuit that exists throughout the neocortex is remarkably similar. It is, it's like, yes, you see variations of it here and there, more of the cell left and left and so on. But what Malcastle argued was it says, you know, if you take a section on neocortex, why is one a visual area and one is a auditory area? Or why is, and his answer was it's because one is connected to eyes and one is connected to ears. Literally, you mean just it's most closest in terms of number of connections to the sensor? Literally, if you took the optic nerve and attached it to a different part of the neocortex, that part would become a visual region. This actually, this experiment was actually done by McGonkiss Sir in developing, I think it was lemurs, I can't remember what it was, some animal. And, and there's a lot of evidence to this. You know, if you take a blind person, a person is born blind at birth. They, they're born with a visual neocortex. It doesn't may not get any input from the eyes, because of some congenital defect or something. And that region becomes, does something else. It picks up another task. So, and it's, it's, so it's this, it's this very complex thing. It's not like, oh, they're all built on neurons. No, they're all built in this very complex circuit. And, and somehow that circuit underlies everything. And so this is the, it's called the common cortical algorithm, if you will. Some scientists just find it hard to believe. And they just say, I can't believe that's true. But the evidence is overwhelming in this case. And so a large part of what it means to figure out how the brain creates intelligence and what is intelligence in the brain is to understand what that circuit does. If you can figure out what that circuit does, as amazing as it is, then you can, then you, then you understand what all these other cognitive functions are. So if you were to sort of put neural cortex outside of your book on intelligence, if you look, if you wrote a giant tome, a textbook on the neural cortex, and you look maybe a couple centuries from now, how much of what we know now would still be accurate two centuries from now. So how close are we in terms of understanding? So I'm going to, I have to speak from my own particular experience here. So I run a small research lab here. It's it's like any other research lab on the sort of the principal investigator, there's actually two of us and there's a bunch of other people. And this is what we do. We started the neural cortex, and we published our results and so on. So about three years ago, we had a real breakthrough in this, in this field. It's a tremendous breakthrough. We started, we've now published, I think, three papers on it. And so I have, I have a pretty good understanding of all the pieces and what we're missing. I would say that almost all the empirical data we've collected about the brain, which is enormous, if you don't know the neuroscience literature, it's just incredibly big. And it's, for the most part, all correct. It's facts and experimental results and measurements and all kinds of stuff. But none of that has been really assimilated into a theoretical framework. It's, it's data without, it's in the, in the language of Thomas Coon, the historian, it would be a sort of a pre-paradigm science, lots of data, but no way to fit it in together. I think almost all of that's correct. There's going to be some mistakes in there. And for the most part, there aren't really good cogent theories about how to put it together. It's not like we have two or three competing good theories, which ones are right and which ones are wrong. It's like, yeah, people just like scratching their heads, throwing things, you know, some people have given up on trying to like figure out what the whole thing does. In fact, there's very, very few labs that we do that focus really on theory and all this unassimilated data and trying to explain it. So it's not like we haven't, we've got it wrong. It's just that we haven't got it at all. So it's really, I would say, pretty early days in terms of understanding the fundamental theories, forces of the way our mind works. I don't think so. I would have said that's true five years ago. So as I said, we had some really big breakthroughs on this recently, and we started publishing papers on this. So we'll get to that. So I don't think it's, you know, I'm an optimist, and from where I sit today, most people would disagree with this, but from where I sit today, from what I know, it's not super early days anymore. The way these things go is it's not a linear path, right? You don't just start accumulating and get better and better and better. No, you got all the stuff you've collected. None of it makes sense. All these different things we just started around. And then you're going to have some breaking points all of a sudden, oh my God, now we got it right. That's how it goes in science. And I personally feel like we passed that little thing about a couple of years ago, all that big thing a couple of years ago. So we can talk about that. Time will tell if I'm right. But I feel very confident about it. That's the moment to say it on tape like this. At least very optimistic. So let's, before those few years ago, let's take a step back to HTM, the hierarchical temporal memory theory, which you first proposed on intelligence and went through a few different generations. Can you describe what it is, how it evolved through the three generations, since you first put it on paper? Yeah. So one of the things that neuroscientists just sort of missed for many, many years, and especially people who are thinking about theory, was the nature of time in the brain. Brains process information through time. The information coming into the brain is constantly changing. The patterns from my speech right now, if you're listening to it at normal speed, would be changing on your ears about every 10 milliseconds or so you'd have it change. This constant flow, when you look at the world, your eyes are moving constantly, three to five times a second, and the inputs completely. If I were to touch something like a coffee cup, as I move my fingers, the inputs change. So this idea that the brain works on time changing patterns is almost completely or was almost completely missing from a lot of the basic theories like fears of vision and so on. It's like, oh, no, we're going to put this image in front of you and flash it and say, what is it? convolutional neural networks work that way today, right? Classified this picture. But that's not what vision is like. Vision is this sort of crazy time-based pattern that's going all over the place and so is touch and so is hearing. So the first part of a hierarchical temporal memory was the temporal part. It's to say, you won't understand the brain, nor will you understand intelligent machines unless you're dealing with time-based patterns. The second thing was the memory component of it was, is to say that we aren't just processing input. We learn a model of the world. And the memory stands for that model. We have to, the point of the brain, the part of the neocortex, it learns a model of the world. We have to store things that are experiences in a form that leads to a model of the world. So we can move around the world. We can pick things up and do things and navigate and know how it's going on. So that's, that's what the memory referred to. And many people just, they were thinking about like certain processes without memory at all. They're just like processing things. And then finally, the hierarchical component was a reflection to that the neocortex, although it's just a uniform sheet of cells, different parts of it project to other parts, which project to other parts. And there is a sort of rough hierarchy in terms of that. So the hierarchical temporal memory is just saying, look, we should be thinking about the brain as time-based, you know, model memory-based and hierarchical processing. And, and that was a placeholder for a bunch of components that we would then plug into that. We still believe all those things I just said, but we now know so much more that I'm stopping to use the word hierarchical temporal memory yet because it's insufficient to capture the stuff we know. So again, it's not incorrect, but it's, I now know more and I would rather describe it more accurately. Yeah. So you're basically, we could think of HTM as emphasizing that there's three aspects of intelligence that are important to think about whatever the, whatever the eventual theory converges to. So in terms of time, how do you think of nature of time across different timescales? So you mentioned things changing, sensory inputs changing every 10, 20 minutes. What about every few minutes, every few months and years? Well, if you think about a neuroscience problem, the brain problem, neurons themselves can stay active for certain parts of time. They can, they're parts of the brain where they stay active for minutes, you know, so you could hold a certain perception or activity for a certain part of time, but not, most of them don't last that long. And so if you think about your thoughts or the activity neurons, if you're going to want to involve something that happened a long time ago, even just this morning, for example, the neurons haven't been active throughout that time. So you have to store that. So if I ask you, what did you have for breakfast today? That is memory. That is, you've built that into your model of the world now, you remember that. And that memory is in the synapses, it's basically in the formation of synapses. And so it's, you're sliding into what, you know, used to different timescales. There's timescales of which we are like understanding my language and moving about and seeing things rapidly and over time. That's the timescales of activities of neurons. But if you want to get in longer timescales, then it's more memory. And we have to invoke those memories to say, Oh, yes, well, now I can remember what I had for breakfast because I stored that someplace. I may forget it tomorrow, but I'd store it for now. So this memory also need to have the hierarchical aspect of reality is not just about concepts, it's also about time. Do you think of it that way? Uh, yeah, time is infused in everything. It's like, you really can't separate it out. If I ask you, what is the, what is your, you know, how's the brain learn a model of this coffee cup here? I have a coffee cup and then I met the coffee cup. I said, well, time is not an inherent property of this, of this, of the model I have with this cup, whether it's a visual model or tactile model. I can sense it through time, but the model itself doesn't really have much time. If I asked you, if I said, well, what is the model of my cell phone? My brain has learned a model of the cell phones. If you have a smartphone like this. And I said, well, this has time aspects to it. I have expectations when I turn it on, what's going to happen, what water, how long it's going to take to do certain things. If I bring up an app, what sequences. And so I have instant, it's like melodies in the world, you know, melody has a sense of time. So many things in the world move and act, and there's a sense of time related to them. Some don't, but most things do actually. So it's sort of infused throughout the models of the world. You build a model of the world, you're learning the structure of the objects in the world, and you're also learning how those things change through time. Okay, so it's, it really is just a fourth dimension that's infused deeply. And you have to make sure that your models of an intelligence incorporated. So like you mentioned, the state of neuroscience is deeply empirical, a lot of data collection. It's, you know, that's, that's where it is. You mentioned Thomas Kuhn, right? Yeah. And then you're proposing a theory of intelligence, and which is really the next step, the really important step to take. But why, why is HTM or what we'll talk about soon, the right theory? So is it more in this? Is it backed by intuition? Is it backed by evidence? Is it backed by a mixture of both? Is it kind of closer to where string theory is in physics, where there's mathematical components which show that, you know what, it seems that this, it fits together too well for it not to be true, which is what where string theory is. Is that where it's a mix of all those things, although definitely where we are right now, it's definitely much more on the empirical side than let's say string theory. The way this goes about, we're theorists, right? So we look at all this data and we're trying to come up with some sort of model that explains it, basically. And there's a, unlike string theory, there's this vast more amounts of empirical data here that I think that most physicists deal with. And so our challenge is to sort through that and figure out what kind of constructs would explain this. And when we have an idea, you come up with a theory of some sort, you have lots of ways of testing it. First of all, I am, you know, there are 100 years of assimilated, undesimulated empirical data from neuroscience. So we go back and read papers and we say, oh, did someone find this already? We can predict X, Y, and Z. And maybe no one's even talked about it since 1972 or something, but we go back and find that. And we say, oh, either it can support the theory or it can invalidate the theory. And we say, okay, we have to start over again. Oh, no, it's support. Let's keep going with that one. So the way I kind of view it, when we do our work, we come up, we look at all this empirical data, and it's what I call it as a set of constraints. We're not interested in something that's biologically inspired. We're trying to figure out how the actual brain works. So every piece of empirical data is a constraint on a theory. In theory, if you have the correct theory, it needs to explain every pin, right? So we have this huge number of constraints on the problem, which initially makes it very, very difficult. If you don't have many constraints, you can make up stuff all the day. You can say, oh, here's an answer. How you can do this, you can do that, you can do this. But if you consider all biology as a set of constraints, all neuroscience, a set of constraints, and even if you're working in one little part of the Neocortex, for example, there are hundreds and hundreds of constraints, these are empirical constraints, that it's very, very difficult initially to come up with a theoretical framework for that. But when you do, and it solves all those constraints at once, you have a high confidence that you got something close to correct. It's just mathematically almost impossible not to be. So that's the curse and the advantage of what we have. The curse is we have to meet all these constraints, which is really hard. But when you do meet them, then you have a great confidence that you've discovered something. In addition, then we work with scientific labs. So we'll say, oh, there's something we can't find, we can predict something, but we can't find it anywhere in the literature. So we will then, we have people we collaborated with, we'll say, sometimes they'll say, you know what, I have some collected data, which I didn't publish. But we can go back and look at it and see if we can find that, which is much easier than designing a new experiment, you know, new neuroscience experiments take a long time, years. So although some people are doing that now too. So, but between all of these things, I think it's a reasonable, actually a very, very good approach. We are blessed with the fact that we can test our theories out to Yang Yang here, because there's so much on a similar data. And we can also falsify our theories very easily, which we do often. So it's kind of reminiscent to whenever, whenever that was with Copernicus, you know, when you figure out that the sun's at the center of the solar system as opposed to Earth, the pieces just fall into place. Yeah, I think that's the general nature of the Ha moments is in Copernicus, it could be, you could say the same thing about Darwin. You could say the same thing about, you know, about the double helix, that people have been working on a problem for so long and have all this data and they can't make sense of it, they can't make sense of it. But when the answer comes to you and everything falls into place, it's like, oh, my gosh, that's it. That's got to be right. I asked both Jim Watson and Francis Crick about this. I asked them, you know, when you were working on trying to discover the structure of the double helix, and when you came up with the sort of the structure that ended up being correct, but it was sort of a guess, you know, it wasn't really verified yet. I said, did you know that it was right? And they both said, absolutely. So we absolutely knew it was right. And it doesn't matter if other people didn't believe it or not, we knew it was right, they'd get around to thinking it and agree with it eventually anyway. And that's the kind of thing you hear a lot with scientists who really are studying a difficult problem. And I feel that way too about our work. Have you talked to Crick or Watson about the problem you're trying to solve, the, of finding the DNA of the brain? Yeah. In fact, Francis Crick was very interested in this, in the latter part of his life. And in fact, I got interested in brains by reading an essay he wrote in 1979 called Thinking About the Brain. And that was when I decided I'm going to leave my profession of computers and engineering and become a neuroscientist, just reading that one essay from Francis Crick. I got to meet him later in life. I got to, I spoke at the Salk Institute and he was in the audience and then I had a tea with him afterwards. You know, he was interested in a different problem. He was focused on consciousness. Oh, the easy problem, right? Well, I think it's the red herring. And so we weren't really overlapping a lot there. Jim Watson, who's still alive, is also interested in this problem. And he was, when he was director of the Coltsman Harbor laboratories, he was really sort of behind moving in the direction of neuroscience there. And so he had a personal interest in this field. And I have met with him numerous times. And in fact, the last time was about a little bit over a year ago, I gave a talk at Coltsman Harbor Labs about the progress we were making in our work. And it was a lot of fun because he said, well, you wouldn't be coming here unless you had something important to say, so I'm going to go attend your talk. So he sat in the very front row. Next to him was the director of the lab, Bruce Stillman. So these guys are in the front row of this auditorium, right? So nobody else in the auditorium wants to sit in the front row because there's Jim Watson and there's the director. And I gave a talk and then I had dinner with Jim afterwards. But there's a great picture of my colleague, Subitai Amantik, where I'm up there sort of explaining the basics of this new framework we have. And Jim Watson is on the edge of his chair. He's literally on the edge of his chair, like intently staring up at the screen. And when he discovered the structure of DNA, the first public talk he gave was at Coltsman Harbor Labs. And there's a picture, there's a famous picture of Jim Watson standing at the whiteboard with a overrated thing pointing at something, holding at the double helix with his pointer. And it actually looks a lot like the picture of me. So there was a sort of funny, there's an area talking about the brain and there's Jim Watson staring up intently at it. And of course, there was, you know, whatever, 60 years earlier, he was standing, you know, pointing at the double helix. And it's one of the great discoveries in all of, you know, whatever, by all the science, all science DNA. So it's just the funny that there's echoes of that in your presentation. Do you think in terms of evolutionary timeline and history, the development of the neocortex was a big leap? Or is it just a small step? So like, if we ran the whole thing over again, from the from the birth of human of life on earth, how likely would we develop the mechanism of the neocortex? Okay, well, those are two separate questions. One is, was it a big leap? And one was how likely it is. Okay, they're not necessarily related. Maybe correlated. And we don't really have enough data to make a judgment about that. I would say definitely was a big leap. And I can tell you why I think I don't think it was just another incremental step. I'll get that moment. I don't really have any idea how likely it is. If we look at evolution, we have one data point, which is earth, right? Life formed on earth billions of years ago, whether it was introduced here, or it created here, or someone introduced it, we don't really know, but it was here early. It took a long, long time to get to multicellular life. And then from multicellular life, it took a long, long time to get the neocortex. And we've only had the neocortex for a few hundred thousand years. So that's like nothing. Okay, so is it likely? Well, certainly isn't something that happened right away on earth. And there were multiple steps to get there. So I would say it's probably not going to something that would happen instantaneously on other planets that might have life. It might take several billion years on average. Is it likely? I don't know, but you'd have to survive for several billion years to find out. Probably. Is it a big leap? Yeah, I think it is a qualitative difference in all other evolutionary steps. I can try to describe that if you'd like. Sure. In which way? Yeah, I can tell you how. Pretty much, let's start with a little preface. Many of the things that humans are able to do do not have obvious survival advantages precedent. We could create music. Is there a really survival advantage to that? Maybe, maybe not. What about mathematics? Is there a real survival advantage to mathematics? You can stretch it. You can try to figure these things out. But mostly evolutionary history, everything had immediate survival advantages to write. So I'll tell you a story, which I like. It may not be true. But the story goes as follows. Organisms have been evolving since the beginning of life here on Earth, adding this sort of complexity onto that and this sort of complexity onto that. And the brain itself is evolved this way. In fact, there's an old part, an older part, an older, older part to the brain that kind of just keeps calming on new things and we keep adding capabilities. And we got to the neocortex. Initially, it had a very clear survival advantage in that it produced better vision and better hearing and better touch and maybe, you know, say, so on. But what I think happens is that evolution took a mechanism, and this is in our recent theory, but it took a mechanism that evolved a long time ago for navigating in the world, for knowing where you are. These are the so-called grid cells and place cells of an old part of the brain. And it took that mechanism for building maps of the world and knowing where you are on those maps and how to navigate those maps and turns it into a sort of a slimmed down, idealized version of it. And that idealized version could now apply to building maps of other things, maps of coffee cups and maps of phones, maps of, you know, concepts, concepts, yes, and not just almost, exactly. And so you, and it just started replicating this stuff, right? You just think more and more and more. So we went from being sort of dedicated purpose neural hardware to solve certain problems that are important to survival to a general purpose neural hardware that could be applied to all problems. And now it's escaped the orbit of survival. It's, we are now able to apply it to things which we find enjoyment, you know, but aren't really clearly survival characteristics. And that it seems to only have happened in humans to the large extent. And so that's what's going on where we sort of have, we've sort of escaped the gravity of evolutionary pressure in some sense in the New York cortex. And it now does things which that are really interesting, discovering models of the universe, which may not really help us, doesn't matter. How does it help us surviving knowing that there might be multiverses or that there might be, you know, the age of the universe or how do, you know, various stellar things occur? It doesn't really help us survive at all. But we enjoy it. And that's what happened. Or at least not in the obvious way, perhaps it is required. If you look at the entire universe in an evolutionary way, it's required for us to do interplanetary travel and therefore survive past our own fun. But you know, let's not get too quick. Yeah, but you know, evolution works at one time frame and survival, if you think of survival of the phenotype, survival of the individual, what you're talking about there is spans well beyond that. So there's no genetic, I'm not transferring any genetic traits to my children that are going to help them survive better on Mars. Right. Totally different mechanism. So let's get into the new, as you've mentioned, this idea, I don't know if you have a nice name, 1000. I would call it the thousand brain theory of intelligence. I like it. So can you talk about the this idea of spatial view of concepts and so on? Yeah. So can I just describe sort of the there's an underlying core discovery, which then everything comes from that that's a very simple. This is really what happened. We were deep into problems about understanding how we build models of stuff in the world and how we make predictions about things. And I was holding a coffee cup just like this in my hand. And I had my finger was touching the side, my index finger. And then I moved it to the top. And I was going to feel the rim at the top of the cup. And I asked myself a very simple question. I said, well, first of all, let's say I know that my brain predicts what it's going to feel before it touches it. You can just think about it and imagine it. And so we know that the brain's making predictions all the time. So the question is, what does it take to predict that? Right. And there's a very interesting answer. First of all, it says the brain has to know it's touching a coffee cup. It has to have a model of a coffee cup and needs to know where the finger currently is on the cup relative to the cup. Because when I make a movement, it needs to know where it's going to be on the cup after the movement is completed relative to the cup. And then it can make a prediction about what it's going to sense. So this told me that the neocortex, which is making this prediction, needs to know that it's sensing it's touching a cup. And it needs to know the location of my finger relative to that cup in a reference frame of the cup. It doesn't matter where the cup is relative to my body. It doesn't matter its orientation. None of that matters. It's where my finger is relative to the cup, which tells me then that the neocortex has a reference frame that's anchored to the cup. Because otherwise, I wouldn't be able to say the location and I wouldn't be able to predict my new location. And then we quickly, very instantly, you can say, well, every part of my skin could touch this cup. And therefore, every part of my skin is making predictions and every part of my skin must have a reference frame that it's using to make predictions. So the big idea is that throughout the neocortex, everything is being stored and referenced in reference frames. You can think of them like XYZ reference frames, but they're not like that. We know a lot about the neural mechanisms for this. But the brain thinks in reference frames. And as an engineer, if you're an engineer, this is not surprising. You'd say, if I were to build a CAD model of the coffee cup, well, I would bring it up in some CAD software and I would assign some reference frame and say, this features at this location and so on. But the idea that this is occurring throughout the neocortex everywhere, it was a novel idea. And then a zillion things fell into place after that. A zillion. So now we think about the neocortex as processing information quite differently than we used to do it. We used to think about the neocortex as processing sensory data and extracting features from that sensory data and then extracting features from the features, very much like a deep learning network does today. But that's not how the brain works at all. The brain works by assigning everything, every input, everything to reference frames. And there are thousands, hundreds of thousands of them active at once in your neocortex. It's a surprising thing to think about. But once you sort of internalize this, you understand that it explains almost all the mysteries we've had about the structure. So one of the consequences of that is that every small part of the neocortex, say a millimeter square and there's 150,000 of those. So it's about 150,000 square millimeters. If you take every little square millimeter of the cortex, it's got some input coming into it and it's going to have reference frames where it's assigning that input to and each square millimeter can learn complete models of objects. So what do I mean by that? If I'm touching the coffee cup, well, if I just touch it in one place, I can't learn what this coffee cup is because I'm just feeling one part. But if I move it around the cup and touch it in different areas, I can build up a complete model of the cup because I'm now filling in that three dimensional map, which is the coffee cup, I can say, oh, what am I feeling at all these different locations? That's the basic idea. It's more complicated than that. But so through time, and we talked about time earlier, through time, even a single column, which is only looking at or a single part of the cortex, it's only looking at a small part of the world can build up a complete model of an object. And so if you think about the part of the brain, which is getting input from all my fingers, so there's spread across the top of your head here, this is the somatosensory cortex, there's columns associated with all the different areas of my skin. And what we believe is happening is that all of them are building models of this cup, every one of them, or things, not all building all, not every column or every part of the cortex builds models of everything. But they're all building models of something. And so you have, so when I touch this cup with my hand, there are multiple models of the cup being invoked. If I look at it with my eyes, there are again many models of the cup being invoked because each part of the visual system, the brain doesn't process an image, that's a misleading idea. It's just like your fingers touching the cup, so different parts of my retina are looking at different parts of the cup. And thousands and thousands of models of the cup are being invoked at once. And they're all voting with each other trying to figure out what's going on. So that's why we call it the Thousand Brains Theory of Intelligence because there isn't one model of a cup. There are thousands of models of this cup. There are thousands of models of your cell phone and about cameras and microphones and so on. It's a distributed modeling system, which is very different than what people have thought about it. So that's a really compelling and interesting idea. I have two first questions. So one, on the ensemble part of everything coming together, you have these Thousand Brains, how do you know which one has done the best job of forming the cup? Great question. Let me try to explain. There's a problem that's known in neuroscience called the sensor fusion problem. And so the idea is something like, oh, the image comes from the eye. There's a picture on the retina and it gets projected to the neocortex. Oh, by now it's all sped out all over the place and it's kind of squirrely and distorted and pieces are all over the, you know, it doesn't look like a picture anymore. When does it all come back together again? Right? Or you might say, well, yes, but I also, I also have sounds or touches associated with the cup. So I'm seeing the cup and touching the cup. How do they get combined together again? So this is called the sensor fusion problem as if all these disparate parts have to be brought together into one model someplace. That's the wrong idea. The right idea is that you get all these guys voting. There's auditory models of the cup, there's visual models of the cup, there's tactile models of the cup. In the vision system, there might be ones that are more focused on black and white, one's version on color. It doesn't really matter. There's just thousands and thousands of models of this cup and they vote. They don't actually come together in one spot. Just literally think of it this way. Imagine you have each column about the size of a little piece of spaghetti, okay? Like a two and a half millimeters tall and about a millimeter in white. They're not physical like, but you can think of them that way. And each one's trying to guess what this thing is we're touching. Now they can, they can do a pretty good job if they're allowed to move over time. So I can reach my hand into a black box and move my finger around an object and if I touch enough space, it's like, okay, I know what it is. But often we don't do that. Often I can just reach and grab something with my hand all at once and I get it. Or if I had to look through the world through a straw, so I'm only invoking one little column, I can only see part of something because I have to move the straw around. But if I open my eyes to see the whole thing at once. So what we think is going on is all these little pieces of spaghetti if you have all these little columns in the cortex or all trying to guess what it is that they're sensing. They'll do a better guess if they have time and can move over time. So if I move my eyes or move my fingers, but if they don't, they have a, they have a poor guess. It's a, it's a probabilistic guess of what they might be touching. Now imagine they can post their probability at the top of little piece of spaghetti, each one of them says, I think, and it's not really a probability distribution. It's more like a set of possibilities in the brain. It doesn't work as a probability distribution. It works as more like what we call a union. You could say, and one column says, I think it could be a coffee cup soda can or a water bottle. And another column says, I think it could be a coffee cup or, you know, telephone or camera or whatever. Right. And all these guys are saying what they think it might be. And there's these long range connections in certain layers in the cortex. So there's some layers in the, some cells types in each column send the projections across the brain. And that's the voting occurs. And so there's a simple associative memory mechanism. We've, we've described this in a recent paper and we've modeled this that says they can all quickly settle on the only or the one best answer for all of them. If there is a single best answer, they all vote and say, yep, it's got to be the coffee cup. And at that point, they all know it's a coffee cup. And at that point, everyone acts as if it's the coffee cup. They know it's a coffee, even though I've only seen one little piece of this world. I know it's a coffee cup I'm touching or I'm seeing or whatever. And so you can think of all these columns are looking at different parts and different places, different sensory input, different locations. They're all different. But this layer that's doing the voting, that's, it solidifies. It's just like it crystallizes and says, oh, we all know what we're doing. And so you don't bring these models together in one model, you just vote and there's a crystallization of the vote. Great. That's at least a compelling way to think about about the way you form a model of the world. Now, you talk about a coffee cup. Do you see this as far as I understand that you were proposing this as well, that this extends to much more than coffee cups? Yeah, it does. Or at least the physical world that expands to the world of concepts. Yeah, it does. And well, the first, the primary phase of evidence for that is that the regions of the neocortex that are associated with language or high-level thought or mathematics or things like that, they look like the regions of the neocortex that process vision and hearing and touch. They don't look any different or they look only marginally different. And so one would say, well, if Vernon Mountcastle, who proposed that all the parts of the neocortex do the same thing, if he's right, then the parts that are doing language or mathematics or physics are working on the same principle. They must be working on the principle of reference frames. So that's a little odd thought. But of course, we had no prior idea how these things happen, so let's go with that. And in our recent paper, we talked a little bit about that. I've been working on it more since. I have better ideas about it now. I'm sitting here very confident that that's what's happening. And I can give you some examples to help you think about that. It's not that we understand it completely, but I understand it better than I've described it in any paper so far. But we did put that idea out there. It's a good place to start. And the evidence would suggest it's how it's happening. And then we can start tackling that problem one piece at a time. What does it mean to do high-level thought? What does it mean to do language? How would that fit into a reference framework? I don't know if you could tell me if there's a connection, but there's an app called Anki that helps you remember different concepts. And they talk about a memory palace that helps you remember completely random concepts by trying to put them in a physical space in your mind and putting them next to each other. It's called the method of loci. For some reason, that seems to work really well. Now that's a very narrow kind of application of just remembering some facts. But that's a very, very telling one. Yes, exactly. So this seems like you're describing a mechanism why this seems to work. Yeah. So basically the way what we think is going on is all things you know, all concepts, all ideas, words, everything, you know, are stored in reference frames. And so if you want to remember something, you have to basically navigate through a reference frame the same way a rat navigates to a maven, the same way my finger rat navigates to this coffee cup. You are moving through some space. And so if you have a random list of things you would ask to remember, by assigning them to a reference frame, you've already know very well to see your house, right? And the idea of the method of loci is you can say, okay, in my lobby, I'm going to put this thing. And then the bedroom, I put this one. I go down the hall, I put this thing. And then you want to recall those facts or recall those things. You just walk mentally, you walk through your house. You're mentally moving through a reference frame that you already had. And that tells you there's two things that are really important about that. It tells us the brain prefers to store things in reference frames. And that the method of recalling things or thinking, if you will, is to move mentally through those reference frames. You could move physically through some reference frames, like I could physically move through the reference frame of this coffee cup. I can also mentally move through the reference frame of the coffee cup, imagining me touching it. But I can also mentally move my house. And so now we can ask yourself, are all concepts stored this way? There was some recent research using human subjects in fMRI. And I'm going to apologize for not knowing the name of the scientists who did this. But what they did is they put humans in this fMRI machine, which is one of these imaging machines. And they gave the humans tasks to think about birds. So they had different types of birds and birds that looked big and small and long necks and long legs, things like that. And what they could tell from the fMRI was a very clever experiment. Get to tell when humans were thinking about the birds, that the birds, the knowledge of birds was arranged in a reference frame, similar to the ones that are used when you navigate in a room. These are called grid cells. And there are grid cell-like patterns of activity in the neocortex when they do this. So it's a very clever experiment. And what it basically says is that even when you're thinking about something abstract, and you're not really thinking about it as a reference frame, it tells us the brain is actually using a reference frame. And it's using the same neural mechanisms. These grid cells are the basic same neural mechanisms that we propose that grid cells, which exist in the old part of the brain, the entirionic cortex, that that mechanism is now similar mechanism is used throughout the neocortex. It's the same nature of preserve this interesting way of creating reference frames. And so now they have empirical evidence that when you think about concepts like birds, that you're using reference frames that are built on grid cells. So that's similar to the method of loci, but in this case, the birds are related so that makes they create their own reference frame, which is consistent with bird space. And when you think about something, you go through that, you can make the same example. Let's take a math mathematics. Let's say you want to prove a conjecture. What is a conjecture? Conjecture is a statement you believe to be true, but you haven't proven it. And so it might be an equation. I want to show that this is equal to that. And you have some places you start with, you say, well, I know this is true, and I know this is true. And I think that maybe to get to the final proof, I need to go through some intermediate results. But I believe it's happening is literally these equations or these points are assigned to a reference frame, a mathematical reference frame. And when you do mathematical operations, a simple one might be multiply or divide, but you might be able to transform or something else, that is like a movement in the reference frame of the math. And so you're literally trying to discover a path from one location to another location in a space of mathematics. And if you can get to these intermediate results, then you know your map is pretty good. And you know you're using the right operations. Much of what we think about is solving hard problems, is designing the correct reference frame for that problem, figuring out how to organize the information, and what behaviors I want to use in that space to get me there. Yeah, so if you dig in an idea of this reference frame, whether it's the math, you start a set of axioms to try to get to proving the conjecture. Can you try to describe, maybe take a step back, how you think of the reference frame in that context? Is it the reference frame that the axioms are happy in? Is it the reference frame that might contain everything? Is it a changing thing? So you have many, many reference frames. I mean, in fact, the way the theory, the 1000 brain theory of intelligence says that every single thing in the world has its own reference frame. So every word has its own reference frames. And we can talk about this, the mathematics work out, this is no problem for neurons to do this. But how many reference frames does the coffee cup have? Well, it's on a table. Remember, let's say you ask how many reference frames could the column in my finger that's touching the coffee cup have? Because there are many, many copy, there are many, many models of coffee cups. So the coffee, there is no one model of coffee cup, there are many models of coffee cup. And you could say, well, how many different things can my finger learn? Is this is the question you want to ask? Imagine, I say every concept, every idea, everything you've ever know about that you can say, I know that thing, it has a reference frame associated with it. And what we do when we build composite objects, we can we assign reference frames to points, another reference frame. So my coffee cup has multiple components to it. It's got a limb, it's got a cylinder, it's got a handle. And those things that have their own reference frames, and they're assigned to a master reference frame, which is called this cup. And now I have this mental logo on it. Well, that's something that exists elsewhere in the world. It's its own thing. So it has its own reference frame. So we now have to say, how can I assign the mental logo reference frame onto the cylinder or onto the coffee cup? So it's all, we talked about this in the paper that came out in December of this last year. The idea of how you can assign reference frames to reference frames, how neurons could do this. So my question is, even though you mentioned reference frames a lot, I almost feel it's really useful to dig into how you think of what a reference frame is. I mean, it was already helpful for me to understand that you think of reference frames as something there is a lot of. Okay, so let's just say that we're going to have some neurons in the brain, not many actually, 10,000, 20,000 are going to create a whole bunch of reference frames. What does it mean? What is a reference frame? First of all, these reference frames are different than the ones you might have be used to. We know lots of reference things. For example, we know the Cartesian coordinates, x, y, z, that's a type of reference frame. We know longitude and latitude, that's a different type of reference frame. If I look at a printed map, you might have columns a through m and rows, you know, one through 20, that's a different type of reference frame. It's kind of a Cartesian reference frame. The interesting thing about the reference frames in the brain, we know this because these have been established through neuroscience, studying the entorhonic cortex. So I'm not speculating here. Okay, this is known neuroscience in an old part of the brain. The way these cells create reference frames, they have no origin. So what is more like you have a point, a point in some space, and you given a particular movement, you can then tell what the next point should be. And you can then tell what the next point would be and so on. You can use this to calculate how to get from one point to another. So how do I get from my house to my home, or how do I get my finger from the side of my cup to the top of the cup? How do I get from the axioms to the conjecture? So it's a different type of reference frame. And if you want, I can describe in more detail, I can paint a picture how you might want to think about that. It's really helpful to think it's something you can move through. Yeah. But is it helpful to think of it as spatial in some sense, or is there something? No, it's definitely spatial. It's spatial in a mathematical sense. How many dimensions? Can it be a crazy number of dimensions? Well, that's an interesting question. In the old part of the brain, the entorhonic cortex, they studied rats. And initially, it looks like, oh, this is just two dimensional. It's like the rat is in some box and a maze or whatever. And they know whether the rat is using these two dimensional reference frames and know where it is in the maze. We said, okay, what about bats? That's a mammal. And they fly in three dimensional space. How do they do that? They seem to know where they are. So this is a current area of active research. And it seems like somehow the neurons in the entorhonic cortex can learn three dimensional space. We just, two members of our team, along with Ilef Fett from MIT, just released a paper this literally last week, it's on bioarchive, where they show that you can, if you, the way these things work, and I won't get unless you want to, I won't get into the detail, but grid cells can represent any n dimensional space. It's not inherently limited. You can think of it this way. If you had two dimensional, the way it works is you had a bunch of two dimensional slices. That's the way these things work. There's a whole bunch of two dimensional models. And you can just, you can slice up any n dimensional space and with two dimensional projections. So, and you could have one dimensional models. It does. So there's, there's nothing inherent about the mathematics about the way the neurons do this, which, which constrained the dimensionality of the space, which I think was important. So obviously, I have a three dimensional map of this cup, maybe it's even more than that. I don't know. But it's clearly three dimensional map of the cup. I don't just have a projection of the cup. But when I think about birds or when I think about mathematics, perhaps it's more than three dimensions. Who knows? So in terms of each individual column building up more and more information over time, do you think that mechanism is well understood in your mind? You've proposed a lot of architectures there. Is that a key piece or is it, is the big piece, the thousand brain theory of intelligence, the ensemble of it all? Well, I think they're both big. I mean, clearly the concept as a theorist, the concept that's most exciting, right? A high level concept. A high level concept. This is a totally new way of thinking about how the near characteristics work. So that is appealing. It has all these ramifications. And with that, as a framework for how the brain works, you can make all kinds of predictions and solve all kinds of problems. Now we're trying to work through many of these details right now. Okay. How do the neurons actually do this? Well, it turns out, if you think about grid cells and place cells in the old parts of the brain, there's a lot that's known about them, but there's still some mysteries. There's a lot of debate about exactly the details, how these work and what are the signs. And we have that still, that same level of detail, that same level of concern. What we spend here, most of our time doing is trying to make a very good list of the things we don't understand yet. That's the key part here. What are the constraints? It's not like, oh, this seems to work. We're done. Now it's like, okay, it kind of works, but these are other things we know what has to do and it's not doing those yet. I would say we're well on the way here. We're not done yet. There's a lot of trickiness to this system, but the basic principles about how different layers in the neocortex are doing much of this, we understand, but there's some fundamental parts that we don't understand as well. So what would you say is one of the harder open problems or one of the ones that have been bothering you, keeping you up at night the most? Oh, well, right now, this is a detailed thing that wouldn't apply to most people, okay. But you want me to answer that question? Yeah, please. We've talked about, as if, oh, to predict what you're going to sense on this coffee cup, I need to know where my finger is going to be on the coffee cup. That is true, but it's insufficient. Think about my finger touches the edge of the coffee cup. My finger can touch it at different orientations. I can rotate my finger around here, and that doesn't change. I can make that prediction and somehow, so it's not just the location. There's an orientation component of this as well. This is known in the old part of the brain too. There's things called head direction cells, which way the rat is facing. It's the same kind of basic idea. So if my finger were a rat, you know, in three dimensions, I have a three-dimensional orientation, and I have a three-dimensional location. If I was a rat, I would have a, I think of it as a two-dimensional location, a two-dimensional orientation, a one-dimensional orientation, like just which way is it facing. So how the two components work together, how it is that I combine orientation, the orientation of my sensor, as well as the location, is a tricky problem, and I think I've made progress on it. So at a bigger version of that, the perspective is super interesting, but super specific. Yeah, I warned you. No, no, that's really good, but there's a more general version of that. Do you think context matters? The fact that we are in a building in North America, that we, in the day and age where we have mugs, I mean, there's all this extra information that you bring to the table about everything else in the room that's outside of just the coffee cup. Of course it is. How does it get connected, do you think? Yeah, and that is another really interesting question. I'm going to throw that under the rubric or the name of attentional problems. First of all, we have this model. I have many, many models. And also the question, does it matter because... Well, it matters for certain things. Of course it does. Maybe what we think of that as a coffee cup in another part of the world is viewed as something completely different, or maybe our logo, which is very benign in this part of the world, it means something very different in another part of the world. So those things do matter. I think the way to think about this the following, or one way to think about it, is we have all these models of the world. And we model everything. And as I said earlier, I kind of snuck it in there. Our models are actually, we build composite structure. So every object is composed of other objects, which are composed of other objects, and they become members of other objects. So this room has chairs and a table and a room and walls and so on. Now we can just arrange these things in a certain way. You go, oh, that's in the romantic conference room. And what we do is, when we go around the world and we experience the world, by walking into a room, for example, the first thing I do is say, oh, I'm in this room. Do I recognize the room? Then I can say, oh, look, there's a table here. And by attending to the table, I'm then assigning this table in the context of the room. Then I say, oh, on the table, there's a coffee cup. Oh, and on the table, there's a logo. And in the logo, there's the word Nemento. On the look in the logo, there's the letter E. On the look, it has an unusual surf. And it doesn't actually, but pretend that there's a surf. So the point is your attention is kind of drilling deep in and out of these nested structures. And I can pop back up and I can pop back down. I can pop back up and I can pop back down. So when I attend to the coffee cup, I haven't lost the context of everything else, but it's sort of, there's this sort of nested structure. So the attention filters the reference frame formation for that particular period of time? Yes. It basically, moment to moment, you attend the subcomponents, and then you can attend the subcomponents to subcomponents. You can move up and down that. You can move up and down that. We do that all the time. You're not even, now that I'm aware of it, I'm very conscious of it. But until, but most people don't even think about this, you know, you just walk in the room and you don't say, oh, I looked at the chair and I looked at the board and looked at that word on the board and I looked over here. What's going on? Right? So what percentage of your day are you deeply aware of this? And what part can you actually relax and just be Jeff? Me personally, like my personal day. Yeah. Unfortunately, I'm afflicted with too much of the former. Unfortunately, they are unfortunate. Yeah. So you don't think it's useful? Oh, it is useful. Totally useful. I think about this stuff almost all the time. And one of my primary ways of thinking is when I'm asleep at night, I always wake up in the middle of the night and then I stay awake for at least an hour with my eyes shut in sort of a half-sleep state thinking about these things. I come up with answers to problems very often in that sort of half-sleeping state. I think about on my bike ride, I think about on walks. I'm just constantly thinking about this. I have to almost schedule time to not think about this stuff because it's very, it's mentally taxing. When you're thinking about this stuff, are you thinking introspectively, like almost taking a step outside of yourself and trying to figure out what is your mind doing right now? I do that all the time, but that's not all I do. I'm constantly observing myself. So as soon as I started thinking about grid cells, for example, and getting into that, I started saying, oh, well, grid cells can have my place of sense in the world. That's where you know where you are. And it's interesting, we always have a sense of where we are unless we're lost. And so I started at night when I got up to go to the bathroom, I would start trying to do it completely with my eyes closed all the time and I would test my sense of grid cells. I would walk five feet and say, okay, I think I'm here. Am I really there? What's my error? And then I would calculate my error again and see how the errors can accumulate. So even something as simple as getting up in the middle of the night to go to the bathroom, I'm testing these theories out. It's kind of fun. I mean, the coffee cup is an example of that too. So I think I find that these sort of everyday introspections are actually quite helpful. It doesn't mean you can ignore the science. I mean, I spend hours every day reading ridiculously complex papers. That's not nearly as much fun, but you have to sort of build up those constraints and the knowledge about the field and who's doing what and what exactly they think is happening here. And then you can sit back and say, okay, let's try to have pieces all together. Let's come up with some, you know, I'm very, in this group here, people, they know they do this, I do this all the time. I come in with these introspective ideas and say, well, did we ever thought about this? Now watch, well, let's all do this together. And it's helpful. It's not, as long as you don't, if all you did was that, then you're just making up stuff, right? But if you're constraining it by the reality of the neuroscience, then it's really helpful. So let's talk a little bit about deep learning and the successes in the applied space of neural networks and ideas of training model on data and these simple computational units and you're on artificial neurons that would back propagation of statistical ways of being able to generalize from the training set onto data that's similar to that training set. So where do you think are the limitations of those approaches? What do you think are its strengths relative to your major efforts of constructing a theory of human intelligence? Yeah. Well, I'm not an expert in this field. I'm somewhat knowledgeable. So some of it is in just your intuition. What are your... Well, I have a little bit more than intuition, but I just want to say one of the things that you asked me, do I spend all my time thinking about neuroscience? I do. That's to the exclusion of thinking about things like convolutional neural networks. But I try to stay current. So look, I think it's great the progress they've made. It's fantastic. And as I mentioned earlier, it's very highly useful for many things. The models that we have today are actually derived from a lot of neuroscience principles. They are distributed processing systems and distributed memory systems. And that's how the brain works. They use things that we might call them neurons, but they're really not neurons at all. So we can just... They're not really neurons. So they're distributed processing systems. And nature of hierarchy that came also from neuroscience. And so there's a lot of things, the learning rules basically, not backprop, but other heavy and tight learning. I'd be curious to say they're not neurons at all. Can you describe in which way? I mean, some of it is obvious, but I'd be curious if you have specific ways in which you think are the biggest differences. Yeah, we had a paper in 2016 called Why Neurons of Thousands of Synapses. And if you read that paper, you'll know what I'm talking about here. A real neuron in the brain is a complex thing. Let's just start with the synapses on it, which is a connection between neurons. Real neurons can everywhere from five to 30,000 synapses on them. The ones near the cell body, the ones that are close to the soma or the cell body, those are like the ones that people model in artificial neurons. There's a few hundred of those, maybe they can affect the cell, they can make the cell become active. 95% of the synapses can't do that. They're too far away. So if you activate one of those synapses, it just doesn't affect the cell body enough to make any difference. Any one of them individually. Any one of them individually, or even if you do a mass of them. What real neurons do is the following. If you activate or you get 10 to 20 of them active at the same time, meaning they're all receiving an input at the same time, and those 10 to 20 synapses or 40 synapses within a very short distance on the dendro, like 40 microns, a very small area. So if you activate a bunch of these right next to each other at some distant place, what happens is it creates what's called the dendritic spike. And then dendritic spike travels through the dendroids and can reach the soma or the cell body. Now, when it gets there, it changes the voltage, which is sort of like going to make the cell fire, but never enough to make the cell fire. It's sort of what we call it, we depolarize the cell, you raise the voltage a little bit, but not enough to do anything. It's like, well, good as that. And then it goes back down again. So we proposed a theory, which I'm very confident basics are, is that what's happening there is those 95% of the synapses are recognizing dozens to hundreds of unique patterns. They can write, you know, about the 10 and 20 synapses at a time, and they're acting like predictions. So the neuron actually is a predictive engine on its own. It can fire when it gets enough what they call proximal input from those ones near the cell fire, but it can get ready to fire from dozens to hundreds of patterns that it recognizes from the other guys. And the advantage of this to the neuron is that when it actually does produce a spike in action potential, it does so slightly sooner than it would have otherwise. And so what could it slightly sooner? Well, the slightly sooner part is it, there's it all the neurons in the, the excitatory neurons in the brain are surrounded by these inhibitory neurons, and they're very fast, the inhibitory neurons, these basket cells. And if I get my spike out a little bit sooner than someone else, I inhibit all my neighbors around me. Right. And what you end up with is a different representation. You end up with a representation that matches your prediction. It's a, it's a sparser representation, meaning the few are non interactive, but it's much more specific. And so we showed how networks of these neurons can do very sophisticated temporal prediction, basically. So, so this summarizes real neurons in the brain are time based prediction engines. And, and they, and there's no concept of this at all, in artificial, what we call point neurons. I don't think you can mail the brain without them. I don't think you can build intelligence about it, because it's the, it's the, it's where large part of the time comes from. It's, it's, these are predictive models. And the time is, is there's a prior and a, you know, a prediction and an action. And it's inherent through every neuron in the neocortex. So, so I would say that point neurons sort of model a piece of that and not very well at that either. But, you know, like, like for example, synapses are very unreliable. And you cannot assign any precision to them. So even one digit of precision is not possible. So the way real neurons work is they don't add these, they don't change these weights accurately, like artificial neural networks do. They basically form new synapses. And so what you're trying to always do is, is detect the presence of some 10 to 20 active synapses at the same time, as opposed, and there's, they're almost binary. It's like, because you can't really represent anything much finer than that. So these are the kind of and I think that's actually another essential component, because the brain works on sparse patterns. And all that, all that mechanism is based on sparse patterns. And I don't actually think you could build our real brains or machine intelligence without incorporating some of those ideas. It's hard to even think about the complexity that emerges from the fact that the timing of the firing matters in the brain, the fact that you form new, new synapses. And I mean, everything you just mentioned in the past few minutes, trust me, if you spend time on it, you can get your mind around it. It's not like it's no longer a mystery to me. No, but, but sorry, as a function in a mathematical way, it's, can you get it start getting an intuition about what gets it excited, what not, and what kind of representation it's not as easy as there's many other types of neural networks that are more amenable to pure analysis. You know, especially very simple networks, you know, oh, I have four neurons and they're doing this. Can we, you know, describe them mathematically what they're doing type of thing. Even the complexity of convolutional neural networks today, it's sort of a mystery. They can't really describe the whole system. And so it's different. My colleague, Subitain Ahmad, he did a nice paper on this. You can get all the stuff on our website if you're interested in talking about some of the mathematical properties of sparse representations. And so we can't, what we can do is we can show mathematically, for example, why 10 to 20 synapses to recognize a pattern is the correct number is the right number you'd want to use. And by the way, that matches biology, we can show mathematically some of these concepts about the show why the brain is so robust to noise and error and fall out and so on. We can show that mathematically as well as empirically in simulations. But the system can't be analyzed completely. Any complex system can't. And so that's out of the realm. But there is there is mathematical benefits and intuitions that can be derived from mathematics. And we try to do that as well. Most most of our papers have a section about that. So I think it's refreshing and useful for me to be talking to you about deep neural networks, because your intuition basically says that we can't achieve anything like intelligence with artificial neural networks. Well, not in the current form. Not in the current form. I'm sure we can do it in the ultimate form, sure. So let me dig into it and see what your thoughts are there a little bit. So I'm not sure if you read this little blog post called Bitter Lesson by Rich Sutton. Recently, he's a reinforcement learning pioneer. I'm not sure if you're familiar with him. His basic idea is that all the stuff we've done in AI in the past 70 years, he's one of the old school guys. The biggest lesson learned is that all the tricky things we've done don't, you know, they benefit in the short term. But in the long term, what wins out is a simple general method that just relies on Moore's law on computation getting faster and faster. This is what he's saying. This is what has worked up to now. What has worked up to now, that if you're trying to build a system, if we're talking about, he's not concerned about intelligence. He's concerned about a system that works in terms of making predictions on applied, narrow AI problems. That's what the discussion is about. That you just try to go as general as possible and wait years or decades for the computation to make it actually. Is he saying that as a criticism or is he saying this is a prescription of what we ought to be doing? Well, it's very difficult. He's saying this is what has worked and yes, a prescription, but it's a difficult prescription because it says all the fun things you guys are trying to do, we are trying to do, he's part of the community, is saying it's only going to be short-term gains. This all leads up to a question, I guess, on artificial neural networks and maybe our own biological neural networks is, do you think if we just scale things up significantly, so take these dumb artificial neurons, the point neurons, I like that term, if we just have a lot more of them, do you think some of the elements that we see in the brain may start emerging? No, I don't think so. We can do bigger problems of the same type. It's been pointed out by many people that today's convolutional neural networks aren't really much different than the ones we had quite a while ago. They're bigger and train more and we have more labeled data and so on, but I don't think you can get to the kind of things I know the brain can do and that we think about as intelligence by just scaling it up. It's a good description of what's happened in the past, what's happened recently with the reemergence of artificial neural networks. It may be a good prescription for what's going to happen in the short term, but I don't think that's the path. I've said that earlier, there's an alternate path. I should mention to you, by the way, that we've made sufficient progress on the whole cortical theory in the last few years that last year, we decided to start actively pursuing how we get these ideas embedded into machine learning. That's again being led by my colleague, Subhathayamad, and because he's more of a machine learning guy, I'm more of an neuroscience guy. Now, I wouldn't say our focus, but it is now an equal focus here because we need to proselytize what we've learned, and we need to show how it's beneficial to the machine learning. We have a plan in place right now. In fact, we just did our first paper on this. I can tell you about that, but one of the reasons I want to talk to you is because I'm trying to get more people in the machine learning community to say, I need to learn about this stuff, and maybe we should just think about this a bit more about what we've learned about the brain, and what are those team members meant to have? What have they done? Is that useful for us? Yeah, so is there elements of all the cortical theory that things we've been talking about that may be useful in the short term? Yes, in the short term, yes. This is the, sorry to interrupt, but the open question is it certainly feels from my perspective that in the long term, some of the ideas we've been talking about will be extremely useful. The question is whether in the short term. Well, this is always what I would call the entrepreneur's dilemma. So you have this long term vision. Oh, we're going to all be driving electric cars or we're all going to have computers or we're all going to whatever. And, and you're at some point in time and you say, I can see that long term vision. I'm sure it's going to happen. How do I get there without killing myself, you know, without going out of business? That's the challenge. That's the dilemma. That's the really difficult thing to do. So we're facing that right now. So ideally what you'd want to do is find some steps along the way that you can get there incrementally. You don't have to like throw it all out and start over again. The first thing that we've done is we focus on the sparse representations. So just, just in case you don't know what that means or some of the listeners don't know what that means. In the brain, if I have like 10,000 neurons, what you would see is maybe 2% of them active at a time. You don't see 50%, you don't think 30%, you might see 2%. And it's always like that. For any set of sensory inputs. It doesn't matter if anything, it doesn't matter with any part of the brain. But which neurons differs? Which neurons are active? Yeah, so let me put this, let's say I take 10,000 neurons that are representing something. They're sitting there in a block together. It's a teeny little block in a neuron, 10,000 neurons. And they're representing a location, they're representing a cop, they're representing the input from my sensors. I don't know, it doesn't matter. It's representing something. The way the representations occur, it's always a sparse representation, meaning it's a population code. So which 200 cells are active tells me what's going on. It's not individual cells aren't that important at all. It's the population code that matters. And when you have sparse population codes, then all kinds of beautiful properties come out of them. So the brain uses sparse population codes that we've written and described these benefits in some of our papers. So they give this tremendous robustness to the systems. Your brains are incredibly robust. Neurons are dying all the time and spasming and synapses falling apart and, you know, all the time and it keeps working. So what Subitai and Louise, one of our other engineers here have done, I've shown that they're introducing sparseness into convolutional neural networks. Now other people are thinking along these lines, but we're going about it in a more principled way, I think. And we're showing that if you enforce sparseness throughout these convolutional neural networks, in both which neurons are active and the connections between them, that you get some very desirable properties. So one of the current hot topics in deep learning right now are these adversarial examples. So, you know, I can give me any deep learning network and I can give you a picture that looks perfect and you're going to call it, you know, you're going to say the monkey is, you know, an airplane. So that's a problem. And DARPA just announced some big thing. They're trying to, you know, have some contests for this. But if you enforce sparse representations here, many of these problems go away. They're much more robust and they're not easy to fool. So we've already shown some of those results, just literally in January or February, just like last month we did that. And you can, I think it's on bioarchive right now or on iCry, you can read about it. But so that's like a baby step. Okay. That's a take something from the brain. We know, we know about sparseness. We know why it's important. We know what it gives the brain. So let's try to enforce that onto this. What's your intuition why sparsity leads to robustness? Because it feels like it would be less robust. Why would you feel the rest robust to you? So it just feels like if the fewer neurons are involved, the more fragile the representation. Yeah, but I didn't say there was lots of funerals. I said, let's say 200. That's a lot. There's still a lot. So here's an intuition for it. This is a bit technical. So for, you know, for engineers, machine learning people, this would be easy, but all the listeners, maybe not. If you're trying to classify something, you're trying to divide some very high dimensional space into different pieces, A and B, and you're trying to create some point where you say all these points in this high dimensional space are A and all these points inside dimensional space are B. And if you have points that are close to that line, it's not very robust. It works for all the points you know about, but it's, it's not very robust because you just move a little bit and you've crossed over the line. When you have sparse representations, imagine I pick, I have, I'm going to pick 200 cells active out of, out of 10,000. Okay. So I have 200 cells active. Now let's say I pick randomly another, a different representation, 200. The overlap between those is going to be very small, just a few. I can pick millions of samples randomly of 200 neurons and not one of them will overlap more than just a few. So one way to think about is if I want to fool one of these representations to look like one of those other representations, I can't move just one cell or two cells or three cells or four cells. I have to move a hundred cells and that makes them robust. In terms of further, so you mentioned sparsity. Won't it be the next thing? Yeah. Okay. So we have, we picked one. We don't know if it's going to work well yet. So again, we're trying to come up incremental ways of moving from brain theory to add pieces to machine learning, current machine learning world and one step at a time. So the next thing we're going to try to do is sort of incorporate some of the ideas of the 1000 brains theory that you have many, many models and that are voting. Now that idea is not new. There's a mixture of models has been around for a long time, but the way the brain does it is a little different and the way it votes is different and the kind of way it represents uncertainty is different. So we're just starting this work, but we're going to try to see if we sort of incorporate some of the principles of voting or principles of 1000 brain theory, like lots of simple models that talk to each other in a very certain way. And can we build more machines and systems that learn faster and also, well, mostly are multimodal and robust to multimodal type of issues. So one of the challenges there is the machine learning computer vision community has certain sets of benchmarks. So it's a test based on which they compete. And I would argue, especially from your perspective, that those benchmarks aren't that useful for testing the aspects that the brain is good at or intelligent. They're not really testing intelligence. They're very fine. And it's been extremely useful for developing specific mathematical models, but it's not useful in the long term for creating intelligence. So you think you also have a role in proposing better tests? Yeah, this is a very, you've identified a very serious problem. First of all, the test that they have or the test that they want, not the test of the other things that we're trying to do, right? You know, what are the so on? The second thing is, sometimes these to be competitive in these tests, you have to have huge data sets and huge computing power. And so, you know, and we don't have that here. We don't have it as well as other big teams that big companies do. So there's numerous issues there. You know, we come out of, you know, we're our approach to this is all based on in some sense, you might argue elegance, we're coming at it from like a theoretical base that we think, Oh, my God, this is so, this is so clearly elegant. This is how brains work. This is what intelligence is. But the machine learning world has gotten in this phase where they think it doesn't matter. Doesn't matter what you think, as long as you do, you know, 0.1% better on this benchmark, that's what that's all that matters. And that's a problem. You know, we have to figure out how to get around that. That's that's a challenge for us. That's that's one of the challenges that we have to deal with. So I agree, you've identified a big issue. It's difficult for those reasons. But, you know, part of the reasons I'm talking to you here today is I hope I'm going to get some machine learning people to say, read those papers. Those might be some interesting ideas. I'm tired. I'm tired of doing this 0.1% improvement stuff, you know, well, that's what that's why I'm here as well, because I think machine learning now as a community is a place where the next step is needs to be orthogonal to what has received success in the past. You see other leaders saying this, machine learning leaders, you know, Jeff Hinton, with his capsules idea. Many people have gotten up saying, you know, we're going to hit road, maybe we should look at the brain, you know, things like that. So hopefully that thinking will occur organically. And then then we're in a nice position for people to come and look at our work and say, well, what can we learn from these guys? Yeah, MIT is just launching a billion dollar computing college that's centered around this idea. So on this idea of what? Well, the idea that, you know, the humanities, psychology and neuroscience have to work all together to get to build the S. Yeah. I mean, Stanford just did this human center today. I said, yeah, I'm a little disappointed in these initiatives because, you know, they're, they're focusing on sort of the human side of it. And it could very easily slip into how humans interact with intelligent machines, which is nothing wrong with that. But that's not, that is orthogonal to what we're trying to do. We're trying to say, like, what is the essence of intelligence? I don't care. In fact, I want to build intelligent machines that aren't emotional, that don't smile at you, that, you know, that aren't trying to tuck you in at night. Yeah, there is that pattern that you, when you talk about understanding humans is important for understanding intelligence, that you start slipping into topics of ethics or, yeah, like you said, the interactive elements as opposed to, no, no, no, we have to zoom in on the brain, study, study what the human brain, the baby, the, let's study what a brain does. Does. And then we can decide which parts of that we want to recreate in some system. But until you have that theory about what the brain does, what's the point? You know, it's just, you're going to be wasting time, I think. Right. Just to break it down on the artificial neural networks side, maybe you can speak to this on the, on the biologic neural networks side, the process of learning versus the process of inference. Maybe you can explain to me, what is there a difference between, you know, in artificial neural networks, there's a difference between the learning stage and the inference stage. Do you see the brain as something different? One of the, one of the big distinctions that people often say, I don't know how correct it is, is artificial neural networks need a lot of data, they're very inefficient learning. Do you see that as a correct distinction from the, the biology of the human brain, that the human brain is very efficient? Or is that just something we deceive ourselves with? No, it is efficient, obviously. We can learn new things almost instantly. And so what elements do you think? Yeah, I can talk about that. You brought up two issues there. So remember I talked early about the constraints we, we always feel, well, one of those constraints is the fact that brains are continually learning. That's not something we said, oh, we can add that later. That's something that was upfront, had to be there from the start, made our problems harder. But we showed, going back to the 2016 paper on sequence memory, we showed how that happens, how the brains infer and learn at the same time. And our models do that. They're not two separate phases or two separate sets of time. I think that's a big, big problem in AI, at least for many applications, not for all. So I can talk about that. There are some that gets detailed. There are some parts of the neocortex in the brain where actually what's going on, there's these, there's these, with these cycles, they're like cycles of activity in the brain. And there's very strong evidence that you're doing more of inference on one part of the phase and more of learning on the other part of the phase. So the brain can actually sort of separate different populations of cells are going back and forth like this. But in general, I would say that's an important problem. We have all of our networks that we've come up with do both. They're learning, continuous learning networks. And you mentioned benchmarks earlier. Well, there are no benchmarks about that. Exactly. So we have to like, we get in our little soapbox and say, hey, by the way, this is important and here's the mechanism for doing that. But until you can prove it to someone in some, you know, commercial system or something, it's a little harder. So yeah, one of the things I had to linger on that is in some ways to learn the concept of a coffee cup. You only need this one coffee cup and maybe some time alone in a room with it. Well, the first thing is I, when I imagine I reach my hand into a black box and I'm reaching, I'm trying to touch something. I don't know up front if it's something I already know, or if it's a new thing. And I have to, I'm doing both at the same time. I don't say, oh, let's see if it's a new thing. Oh, let's see if it's an old thing. I don't do that. As I go, my brain says, oh, it's new or it's not new. And if it's new, I start learning what it is. So and by the way, it starts learning from the get go, even if we're going to recognize it. So they're not separate problems. And so that's the thing. The other thing you mentioned was the fast learning. So I was just talking about continuous learning, but there's also fast learning. Literally, I can show you this coffee cup. And I say, here's a new coffee cup. It's got the logo on it. Take a look at it. Done. You're done. You can predict what it's going to look like, you know, in different positions. So I can talk about that too. In the brain, the way learning occurs. I mentioned this earlier, but I mentioned again, the way learning occurs, I imagine I have a section of a dendrite of a neuron. And I want to learn, I'm going to learn something new. I'm just doesn't matter what it is, I'm just going to learn something new. I need to recognize a new pattern. So what I'm going to do is I'm going to form new synapses. New synapses, we're going to rewire the brain onto that section of the dendrite. Once I've done that, everything else that neuron has learned is not affected by it. That's because it's isolated to that small section of the dendrite. They're not all being added together, like a point neuron. So if I learned something new on this segment here, it doesn't change any of the learning that occur anywhere else in that neuron. So I can add something without affecting previous learning. And I can do it quickly. Now let's talk, we can talk about the quickness, how it's done in real neurons. You might say, well, doesn't it take time to form synapses? Yes, it can take maybe an hour to form a new synapse. We can form memories quicker than that. And I can explain that happens too, if you want. But it's getting a bit neuroscience-y. That's great. But is there an understanding of these mechanisms at every level? So from the short-term memories and the forming many connections. So this idea of synaptogenesis, the growth of new synapses, that's well described, as well understood. And that's an essential part of learning. That is learning. That is learning. Going back many, many years, people was what's his name, the psychologist proposed, Heb, Donald Heb. He proposed that learning was the modification of the strength of a connection between two neurons. People interpreted that as the modification of the strength of a synapse. He didn't say that. He just said there's a modification between the effect of one neuron and another. So synaptogenesis is totally consistent with Donald Heb said. But anyway, there's these mechanisms, the growth of new synapse, you can go online, you can watch a video of a synapse growing in real time. It's literally, you can see this little thing going. It's pretty impressive. So those mechanisms are known. Now, there's another thing that we've speculated and we've written about, which is consistent with no neuroscience, but it's less proven. And this is the idea, how do I form a memory really, really quickly? Like instantaneous. If it takes an hour to grow a synapse, like that's not instantaneous. So there are types of synapses called silent synapses. They look like a synapse, but they don't do anything. They're just sitting there. It's like if an action potential comes in, it doesn't release any neurotransmitter. Some parts of the brain have more of these than others. For example, the hippocampus has a lot of them, which is where we associate most short-term memory with. So what we speculated, again, in that 2016 paper, we proposed that the way we form very quick memories, very short-term memories, or quick memories, is that we convert silent synapses into active synapses. It's like saying a synapse has a zero weight and a one weight. But the long-term memory has to be formed by synaptogenesis. So you can remember something really quickly by just flipping a bunch of these guys from silent to active. It's not from 0.1 to 0.15. It doesn't do anything until it releases transmitter. And if I do that over a bunch of these, I've got a very quick short-term memory. So I guess the lesson behind this is that most neural networks today are fully connected. Every neuron connects every other neuron from layer to layer. That's not correct in the brain. We don't want that. We actually don't want that. It's bad. You want a very sparse connectivity so that any neuron connects to some subset of the neurons in the other layer. And it does so on a dendrite by dendrite segment basis. So it's a very parcelated out type of thing. And that then learning is not adjusting all these weights, but learning is just saying, okay, connect to these 10 cells here right now. In that process, you know, with artificial neural networks, it's a very simple process of back propagation that adjusts the weights. The process of synaptogenesis. Synaptogenesis. Synaptogenesis. It's even easier. It's even easier. It's even easier. Back propagation requires something that really can't happen in brains. This back propagation of this error signal. They really can't happen. People are trying to make it happen in brains, but it doesn't happen in brain. This is pure Hebbian learning. Well, synaptogenesis is pure Hebbian learning. It's basically saying there's a population of cells over here that are active right now. And there's a population of cells over here active right now. How do I form connections between those active cells? And it's literally saying this guy became active. These 100 neurons here became active before this neuron became active. So form connections to those ones. That's it. There's no propagation of error. Nothing. All the networks we do, all the models we have work on almost completely on Hebbian learning, but in on dendritic segments and multiple synaptes at the same time. So now let's turn the question that you already answered and maybe you can answer it again. If you look at the history of artificial intelligence, where do you think we stand? How far are we from solving intelligence? You said you were very optimistic. Can you elaborate on that? Yeah. It's always the crazy question to ask because no one can predict the future. So I'll tell you a story. I used to run a different neuroscience institute called the Redburn Neuroscience Institute. And we would hold these symposiums and we'd get like 35 scientists from around the world to come together. And I used to ask them all the same question. I would say, well, how long do you think it'll be before we understand how the New York Cortex works? And everyone went around the room and they introduced the name and they have to answer that question. So I got, the typical answer was 50 to 100 years. Some people would say 500 years. Some people said never. I said, why are you, why are you a neuroscience? It's a good pay. It's interesting. So, you know, but it doesn't work like that. As I mentioned earlier, these are step functions. Things happen and then bingo, they happen. You can't predict that. I feel I've already passed a step function. So if I can do my job correctly over the next five years, then meaning I can proselytize these ideas, I can convince other people they're right, we can show that other people or other machine learning people should pay attention to these ideas, then we're definitely in an under 20 year time frame. If I can do those things, if I, if I'm not successful in that, and this is the last time anyone talks to me and no one reads our papers and, you know, I'm wrong or something like that, then, then I don't know. But it's, it's not 50 years. It's, it, you know, it'll, it'll, you know, the same thing about electric cars, how quickly are they going to populate the world? It probably takes about a 20 year span. It'll be something like that. But I think if I can do what I said, we're starting it. And of course, there could be other use of step functions. It could be everybody gives up on your ideas for 20 years, and then all of a sudden somebody picks it up again. Wait, that guy was onto something. Yeah. So that would be a, that would be a failure on my part, right? You know, think about Charles Babbage, you know, Charles Babbage, he's the guy who invented the computer back in the 18 something 1800s. And everyone forgot about it until, you know, 100 years later and say, Hey, this guy figured this stuff out a long time ago. Yeah. You know, but he was ahead of his time. Yeah. I don't think, you know, like, as I said, I recognize this is part of any entrepreneur's challenge. I use entrepreneur broadly in this case. I'm not meaning like I'm building a business trying to sell something. I mean, like I'm trying to sell ideas. And this is the challenge as to how you get people to pay attention to you. How do you get them to give you positive or negative feedback? How do you get to people act differently based on your ideas? So, you know, we'll see how well we do on that. So, you know, that there's a lot of hype behind artificial intelligence currently. Do you, as, as you look to spread the ideas that are of New York cortical theory of the things you're working on, do you think there's some possibility we'll hit an AI winter once again? Yeah, it's certainly a possibility. No question about it. Yeah. Well, I guess, do I worry about it? I haven't decided yet if that's good or bad for my mission. That's true. That's very true because it's almost like you need the winter to refresh the pallet. Yeah. So, it's like, I want, here's what you want to have it is you want like, to the extent that everyone is so thrilled about the current state of machine learning and AI and they don't imagine they need anything else. It makes my job harder. Right. If, if everything crashed completely and every student left the field and there was no money for anybody to do anything and it became an embarrassment to talk about machine intelligence and AI, that wouldn't be good for us either. You want, you want sort of the soft landing approach, right? You want enough people, the senior people in AI and machine learning and say, you know, we need other approaches. We really need other approaches. Damn, we need other approaches. Maybe we should look to the brain. Okay, let's look to the brain. Who's got some brain ideas? Okay, let's, let's start a little project on the side here, trying to do a brain idea related stuff. That's the ideal outcome we would want. So, I don't want a total winter and yet I don't want it to be sunny all the time either. So, what do you think it takes to build a system with human level intelligence where once demonstrated, you would be very impressed? So, does it have to have a body? Does it have to have the, the, the C word we used before consciousness as, as, as an entirety as a holistic sense? First of all, I don't think the goal is to create a machine that is human level intelligence. I think it's a false goal. Back to Turing, I think it was a false statement. We want to understand what intelligence is and then we can build intelligent machines of all different scales, all different capabilities. You know, a dog is intelligent. I don't need, you know, that'd be pretty good to have a dog, you know, but what about something that doesn't look like an animal at all in different spaces. So, my thinking about this is that we want to define what intelligence is, agree upon what makes an intelligent system. We can then say, okay, we're now going to build systems that work on those principles or some subset of them, and we can apply them to all different types of problems. And the, the kind, the idea, it's like computing. We don't ask, if I take a little, you know, little one chip computer, I don't say, well, that's not a computer because it's not as powerful as this, you know, big server over here. No, no, because we know that what the principles are computing on, and I can apply those principles to a small problem or into a big problem. And same intelligence needs to get there. We have to say, these are the principles. I can make a small one, a big one, I can make them distributed, I can put them on different sensors. They don't have to be human like at all. Now you did bring up a very interesting question about embodiment. Does it have to have a body? It has to have some concept of movement. It has to be able to move through these reference frames I talked about earlier. I, whether it's physically moving, like I need, if I'm going to have an AI that understands coffee cups, it's going to have to pick up the coffee cup and touch it and look at it with its, with its eyes and hands or something equivalent to that. If I have a mathematical AI, maybe it needs to move through mathematical spaces. I could have a virtual AI that lives in the internet and its movements are traversing links and digging into files, but it's got a location that it's traveling through some space. You can't have an AI that just takes some flash thing input, you know, we call it flash inference. Here's a pattern, done. No, it's movement time, movement pattern, movement pattern, movement pattern, attention, digging, building, building structure, just figuring out the model of the world. So some sort of embodiment, whether it's physical or not, has to be part of it. So self-awareness in the way to be able to answer where am I? You're bringing up self-awareness, it's a different topic, self-awareness. No, the very narrow definition, meaning knowing a sense of self enough to know where am I in this space? Yeah, basically the system, the system needs to know its location or each component of the system needs to know where it is in the world at that point in time. So self-awareness and consciousness, do you think, one, from the perspective of neuroscience and neocortex, these are interesting topics, solvable topics, do you have any ideas of why the heck it is that we have a subjective experience at all? Yeah, I have a lot of questions. And is it useful or is it just a side effect of us? It's interesting to think about. I don't think it's useful as a means to figure out how to build intelligent machines. It's something that systems do, and we can talk about what it is, that are like, well, if I build a system like this, then it would be self-aware. Or if I build it like this, it wouldn't be self-aware. So that's a choice I can have. It's not like, oh my god, it's self-aware. I heard an interview recently with this philosopher from Yale, I can't remember his name, I apologize for that. But he was talking about, well, if these computers were self-aware, then it would be a crime done, plug them. And I'm like, oh, come on. I unplug myself every night, I go to sleep. Is that a crime? I plug myself in again in the morning, and there I am. So people get kind of bent out of shape about this. I have very definite, very detailed understanding or opinions about what it means to be conscious and what it means to be self-aware. I don't think it's that interesting a problem. You talk to Kristoff Koch, he thinks that's the only problem. I didn't actually listen to your interview with him, but I know him, and I know that's the thing he cares about. He also thinks intelligence and consciousness have disjoint. So I mean, it's not, you don't have to have one or the other. I disagree with that. I just totally disagree with that. So where's your thoughts and consciousness? Where does it emerge from? Because it is... So then we have to break it down to the two parts, okay? Because consciousness isn't one thing, that's part of the problem with that term. It means different things to different people, and there's different components of it. There is a concept of self-awareness, okay? That can be very easily explained. You have a model of your own body, the neocortex models things in the world, and it also models your own body. And then it has a memory. It can remember what you've done, okay? So it can remember what you did this morning, can remember what you had for breakfast, and so on. And so I can say to you, okay, Lex, were you conscious this morning when you had your bagel? And you'd say, yes, I was conscious. Now what if I could take your brain and revert all the synapses back to the state they were this morning? And then I said to you, Lex, were you conscious when you ate the bagel? And he said, no, I wasn't conscious. I said, here's a video of eating the bagel. And he said, I wasn't there. I have no... That's not possible because I must have been unconscious at that time. So we can just make this one-to-one correlation between memory of your body's trajectory through the world over some period of time, a memory of it. And the ability to recall that memory is what you would call conscious. I was conscious of that. It's a self-awareness. And any system that can recall, memorize what it's done recently, and bring that back and invoke it again would say, yeah, I'm aware. I remember what I did. All right, I got it. That's an easy one, although some people think that's a hard one. The more challenging part of consciousness is this is one that's sometimes used by the word qualia, which is, why does an object seem red? Or what is pain? And why does pain feel like something? Why do I feel redness? Or why do I feel a little painless in a way? And then I could say, well, why does sight seems different than hearing? That's the same problem. It's really, these are all just neurons. And so how is it that why does looking at you feel different than hearing you? It feels different, but there's just neurons in my head. They're all doing the same thing. So that's an interesting question. The best treatise I've read about this is by a guy named O'Regan. O'Regan, he wrote a book called Why Red Doesn't Sound Like a Bell. It's a little, it's not a trade book, easy to read, but it, and it's an interesting question. Take something like color. Color really doesn't exist in the world. It's not a property of the world. Property of the world that exists is light frequency. And that gets turned into we have certain cells in the retina that respond to different frequencies, different than others. And so when they enter the brain, you just have a bunch of axons that are firing at different rates. And from that, we perceive color. But there is no color in the brain. I mean, there's, there's no color coming in on those synapses. It's just a correlation between some, some, some axons and some property of frequency. And that isn't even color itself. Frequency doesn't have a color. It's just a, it's just what it is. So then the question is, well, why does it even appear to have a color at all? Just as you're describing it, there seems to be a connection to these, those ideas of reference frames. I mean, it just feels like consciousness having the subject, assigning the feeling of red to the actual color or to the wavelength is useful for intelligence. Yeah, I think that's a good way of putting it. It's useful as a predictive mechanism or useful as a generalization idea. It's a way of grouping things together to say it's useful to have a model like this. Think about the, the, the well-known syndrome that people who've lost a limb experience called phantom limbs. And what they claim is they can have their arms removed, but they feel the arm that not only feel it, they know it's there. They, it's there. I can, I know it's there. They'll swear to you that it's there and then they can feel pain in their arm and they'll feel it in their finger and if they move their, they move their non-existent arm behind their back, then they feel the pain behind their back. So this whole idea that your arm exists is a model of your brain. It may or may not really exist. And just like, but it's useful to have a model of something that sort of correlates to things in the world so you can make predictions about what would happen when those things occur. It's a little bit of a fuzzy, but I think you're getting quite towards the answer there. It's, it's useful for the model of to, to express things certain ways that we can then map them into these reference frames and make predictions about them. I need to spend more time on this topic. It doesn't bother me. Do you really need to spend more time? It does feel special that we have subjective experience, but I'm yet to know why. I'm just, I'm just personally curious. It's not, it's not necessary for the work we're doing here. I don't think I need to solve that problem to build intelligent machines at all, not at all. But there is sort of the silly notion that you described briefly that doesn't seem so silly to us humans is, you know, if you're successful building intelligent machines, it feels wrong to then turn them off. Because if you're able to build a lot of them, it feels wrong to then be able to, you know, to turn off the, Well, why, but just let's, let's break that down a bit. As humans, why do we fear death? There's, there's two reasons we fear death. Well, first of all, I'll say when you're dead, it doesn't matter. Oh, okay. You're dead. So why do we fear death? We fear death for two reasons. One is because we are our program genetically to fear death. That's a, that's a survival and prop beginning of the genes thing. And we also are programmed to feel sad when people we know die. We don't feel sad for someone we don't know dies. There's people dying right now, they're only scared to say, I'm feel bad about them because I don't know them. But I knew them, I'd feel really bad. So again, this, these are old brain genetically embedded things that we fear death. There's outside of those, those uncomfortable feelings. There's nothing else to worry about. Wait, wait, hold on a second. Do you know the denial of death by Becker? You know, there's a thought that death is, you know, our whole conception of our world model kind of assumes immortality. And then death is this terror that underlies it all. So like, well, some people's world model, not mine. But okay, so what, what Becker would say is that you're just living in an illusion, you've constructed illusion for yourself, because it's such a terrible terror. The fact that what's the illusion, the illusion that death doesn't matter, you're still not coming to grips with the illusion of what that death is going to happen. Oh, like it's not going to happen. You're actually operating. You haven't, even though you said you've accepted it, you haven't really accepted the notion of death is what he was saying. So it sounds like, it sounds like you disagree with that notion. I mean, Yeah, yeah, totally. I, like, I, So death is not that such an important. Every night, every night I go to bed, it's like dying. With little deaths. It's full of death. And if I didn't wake up, it wouldn't matter to me. Only if I knew that was going to happen would it be bothersome. But I didn't know it was going to happen. How would I know? Then I would worry about my wife. So imagine, imagine I was a loner and I lived in Alaska and I lived them out there and there was no animals. Nobody knew I existed. I was just eating these roots all the time and nobody knew I was there. And one day I didn't wake up. What pain in the world would there exist? Well, so most people that think about this problem would say that you're just deeply enlightened or are completely delusional. But I would say, I would say that's a very enlightened way to see the world is that that's the rational one. Well, I think it's rational. That's right. But the fact is we don't, I mean, we really don't have an understanding of why the heck it is we're born and why we die and what happens after we die. Well, maybe there isn't a reason, maybe there is. So I'm interested in those big problems too, right? You know, you interviewed Max Tagmark, you know, and there's people like that, right? I'm interested in those big problems as well. And in fact, when I was young, I made a list of the biggest problems I could think of. First, why does anything exist? Second, why did we have the laws of physics that we have? Third, is life inevitable? And why is it here? Fourth, is intelligence inevitable? And why is it here? I stopped there because I figured if you can make a truly intelligent system, we'll be, that'll be the quickest way to answer the first three questions. I'm serious. And so I said, my mission, you know, you asked me earlier, my first mission is to understand the brain, but I felt that is the shortest way to get to true machine intelligence. And I want to get to true machine intelligence because even if it doesn't occur in my lifetime, other people will benefit from it because I think it'll occur in my lifetime, but you know, 20 years, you never know. And but that will be the quickest way for us to, you know, we can make super mathematicians, we can make super space explorers, we can make super physicists brains that do these things, and that can run experiments that we can't run, we don't have the abilities to manipulate things and so on. But we can build and tell the machines to do all those things. And with the ultimate goal of finding out the answers to the other questions. Let me ask you another depressing and difficult question, which is, once we achieve that goal, do you, of creating, no, of understanding intelligence, do you think we would be happier and more fulfilled as a species? Understanding intelligence or understanding the answers to the big questions? Understanding intelligence. Totally. Totally. It would be a far more fun place to live. You think so? Oh, yeah, why not? I mean, you know, just put aside this, you know, terminator nonsense and, and, and, and just think about, you can think about the, we can talk about the risk of AI if you want. I'd love to. So let's talk about. But I think the world is far better knowing things. We're always better than no things. Do you think it's better? Is it a better place to live in that I know that our planet is one of many in the solar system and the solar system is one of many of the galaxies? I think it's a more, I, I dread, I used to, I sometimes think like, God, what would it be like 300 years ago? I'd be looking up the sky. I can't understand anything. Oh my God, I'd be like going to bed every night going, what's going on here? Well, I mean, in some sense, I agree with you, but I'm not exactly sure. So I'm also a scientist. So I have, I share your views, but I'm not, we're, we're like rolling down the hill together. What's down the hill? I feel like we're climbing a hill. Whatever. We're getting, we're getting closer to enlightenment. Whatever. We're climbing, we're getting pulled up a hill by our curiosity. We are putting, our polarity is pulling, we're pulling ourselves up the hill by our curiosity. Yeah. Sisyphus are doing the same thing with the rock. Yeah. But okay, our happiness aside, do you have concerns about, you know, you talk about Sam Harris, Elon Musk, of existential threats of intelligence systems? No, I'm not worried about existential threats at all. There are, there are some things we really do need to worry about. Even today's AI, we have things we have to worry about. We have to worry about privacy and about how impacts false beliefs in the world. And, and we have real problems that, and things to worry about with today's AI. And that will continue as we create more intelligent systems. There's no question, you know, the whole issue about, you know, making intelligent armaments and weapons is something that really we have to think about carefully. I don't think of those as existential threats. I think those are the kind of threats we always face, and we'll have to face them here and, and, and we'll have to deal with them. The, we can, we could talk about what people think are the existential threats. But when I hear people talking about them, they all sound hollow to me. They're, they're based on ideas, they're based on people who really have no idea what intelligence is. And, and if they knew what intelligence was, they wouldn't say those things. So those are not experts in the field, you know. So yeah, so there's two, right? There's, so one is like super intelligent. So a system that becomes far, far superior in reasoning ability than us humans. How is that an existential threat? Then, so there's a lot of ways in which it could be. One way is us humans are actually irrational, inefficient, and get in the way of, of not happiness, but whatever the objective function is of maximizing that objective function. Yeah. Yeah. Super intelligent. There's a paperclip problem and things like that. But so the paperclip problem, but with a super intelligent. Yeah. Yeah. Yeah. So we already faced this threat in some sense. They're called bacteria. These are organisms in the world that would like to turn everything into bacteria. And they're constantly morphing. They're constantly changing to evade our protections. And in the past, they have killed huge swaths of populations of humans on this planet. So if you want to worry about something that's going to multiply endlessly, we have it. And I'm far more worried in that regard, I'm far more worried that some scientists in a laboratory will create a super virus or a super bacteria that we cannot control. That is a more existential threat. Putting an intelligence thing on top of it actually seems to make it less existential to me. It's like, it limits its power. It limits where it can go. It limits the number of things it can do in many ways. A bacteria is something you can't even see. So that's only one of those problems. Yes, exactly. So the other one, just in your intuition about intelligence, when you think about the intelligence of us humans, do you think of that as something, if you look at intelligence on a spectrum from zero to us humans, do you think you can scale that to something far superior? Yeah, all the mechanisms we've been talking about. Let me, I want to make another point here, Alex, before I get there. Sure. Intelligence is the neocortex. It is not the entire brain. If I, the goal is not to make a human. The goal is not to make an emotional system. The goal is not to make a system that wants to have sex and reproduce. Why would I build that? If I want to have a system that wants to reproduce and have sex, make bacteria, make computer viruses. Those are bad things. Don't do that. Those are really bad. Don't do those things. Regulate those. But if I just say I want an intelligent system, why doesn't have to have any of the human-like emotions? Why does it even care if it lives? Why does it even care if it has food? It doesn't care about those things. It's just, you know, it's just in a trance thinking about mathematics or it's out there just trying to build the space, you know, for it on Mars. It's a, we, that's a choice we make. Don't make human-like things. Don't make replicating things. Don't make things that have emotions. Just stick to the neocortex. So that's, that's a view actually that I share, but not everybody shares in the sense that you have faith and optimism about us as engineers of systems, humans as builders of systems to, to, to not put in stupid, not stupid. So this is why, this is why I mentioned the bacteria one. Because you might say, well, some person's going to do that. Well, some person today could create a bacteria that's resistant to all the non-antibacterial agents. So we already have that threat. We already know this is going on. It's not a new threat. So just accept that and then we have to deal with it, right? Yeah. So my point is nothing to do with intelligence. It, intelligence is a separate component that you might apply to a system that wants to reproduce and do stupid things. Let's not do that. Yeah. In fact, it is a mystery why people haven't done that yet. My, my dad as a physicist believes that the reason, for example, nuclear weapons haven't proliferated amongst evil people. So one, one belief that I share is that there's not that many evil people in the world that would, that, that would use back to whether it's bacteria, nuclear weapons, or maybe the future AI systems to do bad. So the fraction is small. And the second is that it's actually really hard, technically. So the, the intersection between evil and competent is small in terms. And by the way, to really annihilate humanity, you'd have to have, you know, sort of the, the nuclear winter phenomenon, which is not one person shooting, you know, or even 10 bombs, you'd have to have some automated system that, you know, detonates a million bombs or 10, whatever many thousands we have. So it's extreme evil combined with extreme competence and just building some stupid system that would automatically, you know, Dr. Strangelup type of thing, you know, I mean, look, we could have some nuclear bomb go off in some major city in the world. Like, I think that's actually quite likely even in my lifetime. I don't think that's unlike the thing. And it'll be a tragedy. But it won't be an existential threat. And it's the same as, you know, the virus of 1917, whenever it was, you know, the influenza, these bad things can happen and the plague and so on. We can't always prevent it. We always, to always try, but we can't. But they're not existential threats until we combine all those crazy things together. So on the, on the spectrum of intelligence from zero to human, do you have a sense of whether it's possible to create several orders of magnitude or at least double that of human intelligence, talking about New York context? I think it's the wrong thing to say double the intelligence. Break it down into different components. Can I make something that's a million times faster than a human brain? Yes, I can do that. Could I make something that is, has a lot more storage than human brain? Yes, I could do that. More common, more copies come. Can I make something that attaches to different sensors than human brain? Yes, I can do that. Could I make something that's distributed? So these people, yeah, we talked earlier about the important New York Cortex voting, they don't have to be co-located. Like, you know, they can be all around the places. I could do that, too. Those are the levers I have, but is it more intelligent? What depends what I train in on? What is it doing? Well, so here's the thing. So let's say larger in New York Cortex and or whatever size that allows for higher and higher hierarchies to form. We're talking about reference frames and concepts. So I could, could I have something that's a super physicist or a super mathematician? Yes. And the question is, once you have a super physicist, will they be able to understand something? Do you have a sense that it will be orders like us compared to ants? Could we ever understand it? Yeah. Most people cannot understand general relativity. It's a really hard thing to get. I mean, you can paint it in a fuzzy picture, stretchy space, you know? Yeah. But the field equations to do that in the deep intuitions are really, really hard. And I've tried, I'm unable to do it. Like, easy to get, you know, it's easy to get special relative, but general relative, man, that's too much. And so we already live with this to some extent. The vast majority of people can't understand actually what the vast majority of other people actually know. We're just either we don't have the effort to or we can't or we don't have time or just not smart enough, whatever. So, but we have ways of communicating. Einstein has spoken in a way that I can understand. He's given me analogies that are useful. I can use those analogies from my own work and think about, you know, concepts that are similar. It's not stupid. It's not like he's exist in some of the plane. There's no connection to my plane in the world here. So that will occur. It already has occurred. That's my point that this story is it already has occurred. We live it every day. One could argue that with we create machine intelligence that think a million times faster than us that it'll be so far, we can't make the connections. But, you know, at the moment, everything that seems really, really hard to figure out in the world when you actually figure it out is not that hard. You know, we can almost everyone can understand the multiverses. Almost everyone can understand quantum physics. Almost everyone can understand these basic things, even though hardly any people could figure those things out. Yeah, but really understand. So, only a few people really don't understand. You need to only understand the the projections, the sprinkles of the useful insights from that. That was my example of Einstein, right? His general theory of relativity is one thing that very, very, very few people can get. And what if we just said those other few people are also artificial intelligences? How bad is that? In some sense, they are, right? Yeah, they say already. I mean, Einstein wasn't a really normal person. He had a lot of weird quirks. And so the other people who work with him. So, you know, maybe they already were sort of this astral plane of intelligence that we live with it already. It's not a problem. It's still useful and, you know. So, do you think we are the only intelligent life out there in the universe? I would say that intelligent life has and will exist elsewhere in the universe. I'll say that. There is a question about contemporaneous intelligence life, which is hard to even answer when we think about relativity and the nature of space time. We can't say what exactly is this time someplace else in the world. But I think it's, you know, I do worry a lot about the filter idea, which is that perhaps intelligent species don't last very long. And so we haven't been around very long. And as a technological species, we've been around for almost nothing, right? You know, what 200 years or something like that. And we don't have any data, a good data point on whether it's likely that we'll survive or not. So, do I think that there have been intelligent life elsewhere in the universe? Almost certainly, of course. In the past and the future, yes. Does it survive for a long time? I don't know. This is another reason I'm excited about our work, is our work meaning the general world of AI. I think we can build intelligent machines that outlast us. And, you know, they don't have to be tied to earth. They don't have to, you know, I'm not saying they're recreating, you know, you know, aliens. I'm just saying if I asked myself, and this might be a good point to end on here. If I asked myself, you know, what's special about our species? We're not particularly interesting physically. We're not, we don't fly. We're not good swimmers. We're not very fast. We're not very strong, you know. It's our brain. That's the only thing. And we are the only species on this planet that's built the model of the world that extends beyond what we can actually sense. We're the only people who know about the far side of the moon and the other universes and other galaxies and other stars and what happens in the atom. That knowledge doesn't exist anywhere else. It's only in our heads. Cats don't do it. Dogs don't do it. Monkeys don't do it. That is what we've created that's unique. Not our genes. It's knowledge. And if I ask me, what is the legacy of humanity? What should our legacy be? It should be knowledge. We should preserve our knowledge in a way that it can exist beyond us. And I think the best way of doing that, in fact, you have to do it, is that it has to go along with intelligent machines to understand that knowledge. That's a very broad idea, but we should be thinking, I call it a state planning for humanity. We should be thinking about what we want to leave behind when as a species we're no longer here. And that'll happen sometime. Sooner or later, it's going to happen. And understanding intelligence and creating intelligence gives us a better chance to prolong. It does give us a better chance to prolong life, yes. It gives us a chance to live on other planets. But even beyond that, I mean, our solar system will disappear one day. It's given enough time. So I don't know. I doubt we will ever be able to travel to other things, but we could tell the stars, but we could send intelligent machines to do that. So you have an optimistic, a hopeful view of our knowledge of the echoes of human civilization living through the intelligent systems we create. Oh, totally. Well, I think the intelligent systems are greater in some sense, the vessel for bringing them beyond Earth or making them last beyond humans themselves. So... And how do you feel about that? That they won't be human, quote unquote. Okay, it's not. But human, what is human? Our species are changing all the time. Human today is not the same as human just 50 years ago. It's, what is human? Do we care about our genetics? Why is that important? As I point out, our genetics are no more interesting than a bacterium's genetics. It's no more interesting than a monkey's genetics. What we have, what's unique and what's valuable is our knowledge, what we've learned about the world. And that is the rare thing. That's the thing we want to preserve. We care about our genes. It's the knowledge. It's the knowledge. That's a really good place to end. Thank you so much for talking to me. Oh, it was fun.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 2.32, "text": " The following is a conversation with Jeff Hawkins.", "tokens": [50364, 440, 3480, 307, 257, 3761, 365, 7506, 9325, 10277, 13, 50480], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 1, "seek": 0, "start": 2.32, "end": 7.04, "text": " He's the founder of the Redwood Center for Theoretical Neuroscience in 2002 and New", "tokens": [50480, 634, 311, 264, 14917, 295, 264, 4477, 6092, 5169, 337, 440, 26262, 804, 1734, 8977, 6699, 294, 17822, 293, 1873, 50716], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 2, "seek": 0, "start": 7.04, "end": 13.280000000000001, "text": " Menta in 2005. In his 2004 book titled On Intelligence and in the research before and", "tokens": [50716, 376, 8938, 294, 14394, 13, 682, 702, 15817, 1446, 19841, 1282, 27274, 293, 294, 264, 2132, 949, 293, 51028], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 3, "seek": 0, "start": 13.280000000000001, "end": 18.64, "text": " after, he and his team have worked to reverse engineer the New York Cortex and propose artificial", "tokens": [51028, 934, 11, 415, 293, 702, 1469, 362, 2732, 281, 9943, 11403, 264, 1873, 3609, 28522, 3121, 293, 17421, 11677, 51296], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 4, "seek": 0, "start": 18.64, "end": 22.96, "text": " intelligence architectures approaches and ideas that are inspired by the human brain.", "tokens": [51296, 7599, 6331, 1303, 11587, 293, 3487, 300, 366, 7547, 538, 264, 1952, 3567, 13, 51512], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 5, "seek": 0, "start": 23.6, "end": 28.88, "text": " These ideas include hierarchical temporal memory, HTM from 2004, and new work,", "tokens": [51544, 1981, 3487, 4090, 35250, 804, 30881, 4675, 11, 11751, 44, 490, 15817, 11, 293, 777, 589, 11, 51808], "temperature": 0.0, "avg_logprob": -0.15734214442116873, "compression_ratio": 1.599337748344371, "no_speech_prob": 0.03057893179357052}, {"id": 6, "seek": 2888, "start": 28.88, "end": 36.08, "text": " the 1000s brain theory of intelligence from 2017, 18, and 19. Jeff's ideas have been an inspiration", "tokens": [50364, 264, 9714, 82, 3567, 5261, 295, 7599, 490, 6591, 11, 2443, 11, 293, 1294, 13, 7506, 311, 3487, 362, 668, 364, 10249, 50724], "temperature": 0.0, "avg_logprob": -0.09995943127256451, "compression_ratio": 1.5785953177257526, "no_speech_prob": 0.0020493699703365564}, {"id": 7, "seek": 2888, "start": 36.08, "end": 40.4, "text": " to many who have looked for progress beyond the current machine learning approaches,", "tokens": [50724, 281, 867, 567, 362, 2956, 337, 4205, 4399, 264, 2190, 3479, 2539, 11587, 11, 50940], "temperature": 0.0, "avg_logprob": -0.09995943127256451, "compression_ratio": 1.5785953177257526, "no_speech_prob": 0.0020493699703365564}, {"id": 8, "seek": 2888, "start": 40.4, "end": 46.16, "text": " but they have also received criticism for lacking a body of empirical evidence supporting the models.", "tokens": [50940, 457, 436, 362, 611, 4613, 15835, 337, 20889, 257, 1772, 295, 31886, 4467, 7231, 264, 5245, 13, 51228], "temperature": 0.0, "avg_logprob": -0.09995943127256451, "compression_ratio": 1.5785953177257526, "no_speech_prob": 0.0020493699703365564}, {"id": 9, "seek": 2888, "start": 46.16, "end": 50.72, "text": " This is always a challenge when seeking more than small incremental steps forward in AI.", "tokens": [51228, 639, 307, 1009, 257, 3430, 562, 11670, 544, 813, 1359, 35759, 4439, 2128, 294, 7318, 13, 51456], "temperature": 0.0, "avg_logprob": -0.09995943127256451, "compression_ratio": 1.5785953177257526, "no_speech_prob": 0.0020493699703365564}, {"id": 10, "seek": 2888, "start": 51.36, "end": 56.480000000000004, "text": " Jeff is a brilliant mind and many of the ideas he has developed and aggregated from neuroscience", "tokens": [51488, 7506, 307, 257, 10248, 1575, 293, 867, 295, 264, 3487, 415, 575, 4743, 293, 16743, 770, 490, 42762, 51744], "temperature": 0.0, "avg_logprob": -0.09995943127256451, "compression_ratio": 1.5785953177257526, "no_speech_prob": 0.0020493699703365564}, {"id": 11, "seek": 5648, "start": 56.48, "end": 61.36, "text": " are worth understanding and thinking about. There are limits to deep learning as it is", "tokens": [50364, 366, 3163, 3701, 293, 1953, 466, 13, 821, 366, 10406, 281, 2452, 2539, 382, 309, 307, 50608], "temperature": 0.0, "avg_logprob": -0.09842105028105945, "compression_ratio": 1.4820717131474104, "no_speech_prob": 0.004398302640765905}, {"id": 12, "seek": 5648, "start": 61.36, "end": 67.03999999999999, "text": " currently defined. Forward progress in AI is shrouded in mystery. My hope is that conversations", "tokens": [50608, 4362, 7642, 13, 35524, 4205, 294, 7318, 307, 50077, 292, 294, 11422, 13, 1222, 1454, 307, 300, 7315, 50892], "temperature": 0.0, "avg_logprob": -0.09842105028105945, "compression_ratio": 1.4820717131474104, "no_speech_prob": 0.004398302640765905}, {"id": 13, "seek": 5648, "start": 67.03999999999999, "end": 73.28, "text": " like this can help provide an inspiring spark for new ideas. This is the Artificial Intelligence", "tokens": [50892, 411, 341, 393, 854, 2893, 364, 15883, 9908, 337, 777, 3487, 13, 639, 307, 264, 5735, 10371, 27274, 51204], "temperature": 0.0, "avg_logprob": -0.09842105028105945, "compression_ratio": 1.4820717131474104, "no_speech_prob": 0.004398302640765905}, {"id": 14, "seek": 5648, "start": 73.28, "end": 78.56, "text": " Podcast. If you enjoy it, subscribe on YouTube, iTunes, or simply connect with me on Twitter", "tokens": [51204, 29972, 13, 759, 291, 2103, 309, 11, 3022, 322, 3088, 11, 33017, 11, 420, 2935, 1745, 365, 385, 322, 5794, 51468], "temperature": 0.0, "avg_logprob": -0.09842105028105945, "compression_ratio": 1.4820717131474104, "no_speech_prob": 0.004398302640765905}, {"id": 15, "seek": 7856, "start": 78.56, "end": 85.04, "text": " at Lex Friedman spelled F-R-I-D. And now here's my conversation with Jeff Hawkins.", "tokens": [50364, 412, 24086, 17605, 1601, 34388, 479, 12, 49, 12, 40, 12, 35, 13, 400, 586, 510, 311, 452, 3761, 365, 7506, 9325, 10277, 13, 50688], "temperature": 0.0, "avg_logprob": -0.2096069653828939, "compression_ratio": 0.9647058823529412, "no_speech_prob": 0.08876247704029083}, {"id": 16, "seek": 10856, "start": 109.52, "end": 115.36, "text": " I also firmly believe that we will not be able to create fully intelligent machines until we", "tokens": [50412, 286, 611, 20031, 1697, 300, 321, 486, 406, 312, 1075, 281, 1884, 4498, 13232, 8379, 1826, 321, 50704], "temperature": 0.0, "avg_logprob": -0.09953375582425099, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.6850743293762207}, {"id": 17, "seek": 10856, "start": 115.36, "end": 120.56, "text": " understand how the human brain works. So I don't see those as separate problems. I think there's", "tokens": [50704, 1223, 577, 264, 1952, 3567, 1985, 13, 407, 286, 500, 380, 536, 729, 382, 4994, 2740, 13, 286, 519, 456, 311, 50964], "temperature": 0.0, "avg_logprob": -0.09953375582425099, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.6850743293762207}, {"id": 18, "seek": 10856, "start": 120.56, "end": 124.24000000000001, "text": " limits to what can be done with machine intelligence if you don't understand the principles by which", "tokens": [50964, 10406, 281, 437, 393, 312, 1096, 365, 3479, 7599, 498, 291, 500, 380, 1223, 264, 9156, 538, 597, 51148], "temperature": 0.0, "avg_logprob": -0.09953375582425099, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.6850743293762207}, {"id": 19, "seek": 10856, "start": 124.24000000000001, "end": 130.0, "text": " the brain works. And so I actually believe that studying the brain is actually the fastest way", "tokens": [51148, 264, 3567, 1985, 13, 400, 370, 286, 767, 1697, 300, 7601, 264, 3567, 307, 767, 264, 14573, 636, 51436], "temperature": 0.0, "avg_logprob": -0.09953375582425099, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.6850743293762207}, {"id": 20, "seek": 10856, "start": 130.0, "end": 135.52, "text": " to get to machine intelligence. And within that, let me ask the impossible question. How do you", "tokens": [51436, 281, 483, 281, 3479, 7599, 13, 400, 1951, 300, 11, 718, 385, 1029, 264, 6243, 1168, 13, 1012, 360, 291, 51712], "temperature": 0.0, "avg_logprob": -0.09953375582425099, "compression_ratio": 1.8150943396226416, "no_speech_prob": 0.6850743293762207}, {"id": 21, "seek": 13552, "start": 135.52, "end": 138.72, "text": " not define but at least think about what it means to be intelligent?", "tokens": [50364, 406, 6964, 457, 412, 1935, 519, 466, 437, 309, 1355, 281, 312, 13232, 30, 50524], "temperature": 0.0, "avg_logprob": -0.11258774160224701, "compression_ratio": 1.804, "no_speech_prob": 0.00041071491432376206}, {"id": 22, "seek": 13552, "start": 139.36, "end": 144.4, "text": " So I didn't try to answer that question first. We said let's just talk about how the brain works", "tokens": [50556, 407, 286, 994, 380, 853, 281, 1867, 300, 1168, 700, 13, 492, 848, 718, 311, 445, 751, 466, 577, 264, 3567, 1985, 50808], "temperature": 0.0, "avg_logprob": -0.11258774160224701, "compression_ratio": 1.804, "no_speech_prob": 0.00041071491432376206}, {"id": 23, "seek": 13552, "start": 144.4, "end": 149.12, "text": " and let's figure out how certain parts of the brain, mostly the neocortex, but some other parts too,", "tokens": [50808, 293, 718, 311, 2573, 484, 577, 1629, 3166, 295, 264, 3567, 11, 5240, 264, 408, 905, 36143, 11, 457, 512, 661, 3166, 886, 11, 51044], "temperature": 0.0, "avg_logprob": -0.11258774160224701, "compression_ratio": 1.804, "no_speech_prob": 0.00041071491432376206}, {"id": 24, "seek": 13552, "start": 149.68, "end": 154.48000000000002, "text": " the parts of the brain most associated with intelligence, and let's discover the principles", "tokens": [51072, 264, 3166, 295, 264, 3567, 881, 6615, 365, 7599, 11, 293, 718, 311, 4411, 264, 9156, 51312], "temperature": 0.0, "avg_logprob": -0.11258774160224701, "compression_ratio": 1.804, "no_speech_prob": 0.00041071491432376206}, {"id": 25, "seek": 13552, "start": 154.48000000000002, "end": 159.92000000000002, "text": " by how they work. Because intelligence isn't just like some mechanism and it's not just some", "tokens": [51312, 538, 577, 436, 589, 13, 1436, 7599, 1943, 380, 445, 411, 512, 7513, 293, 309, 311, 406, 445, 512, 51584], "temperature": 0.0, "avg_logprob": -0.11258774160224701, "compression_ratio": 1.804, "no_speech_prob": 0.00041071491432376206}, {"id": 26, "seek": 15992, "start": 159.92, "end": 166.88, "text": " capabilities. It's like, okay, we don't even know where to begin on this stuff. And so now that we've", "tokens": [50364, 10862, 13, 467, 311, 411, 11, 1392, 11, 321, 500, 380, 754, 458, 689, 281, 1841, 322, 341, 1507, 13, 400, 370, 586, 300, 321, 600, 50712], "temperature": 0.0, "avg_logprob": -0.08360085120567909, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0517902746796608}, {"id": 27, "seek": 15992, "start": 166.88, "end": 171.51999999999998, "text": " made a lot of progress on this, after we've made a lot of progress on how the neocortex works,", "tokens": [50712, 1027, 257, 688, 295, 4205, 322, 341, 11, 934, 321, 600, 1027, 257, 688, 295, 4205, 322, 577, 264, 408, 905, 36143, 1985, 11, 50944], "temperature": 0.0, "avg_logprob": -0.08360085120567909, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0517902746796608}, {"id": 28, "seek": 15992, "start": 171.51999999999998, "end": 176.07999999999998, "text": " and we can talk about that, I now have a very good idea what's going to be required to make", "tokens": [50944, 293, 321, 393, 751, 466, 300, 11, 286, 586, 362, 257, 588, 665, 1558, 437, 311, 516, 281, 312, 4739, 281, 652, 51172], "temperature": 0.0, "avg_logprob": -0.08360085120567909, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0517902746796608}, {"id": 29, "seek": 15992, "start": 176.07999999999998, "end": 182.0, "text": " intelligent machines. I can tell you today, some of the things are going to be necessary, I believe,", "tokens": [51172, 13232, 8379, 13, 286, 393, 980, 291, 965, 11, 512, 295, 264, 721, 366, 516, 281, 312, 4818, 11, 286, 1697, 11, 51468], "temperature": 0.0, "avg_logprob": -0.08360085120567909, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0517902746796608}, {"id": 30, "seek": 15992, "start": 182.0, "end": 186.39999999999998, "text": " to create intelligent machines. Well, so we'll get there. We'll get to the neocortex and some of", "tokens": [51468, 281, 1884, 13232, 8379, 13, 1042, 11, 370, 321, 603, 483, 456, 13, 492, 603, 483, 281, 264, 408, 905, 36143, 293, 512, 295, 51688], "temperature": 0.0, "avg_logprob": -0.08360085120567909, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0517902746796608}, {"id": 31, "seek": 18640, "start": 186.4, "end": 191.36, "text": " the theories of how the whole thing works. And you're saying, as we understand more and more", "tokens": [50364, 264, 13667, 295, 577, 264, 1379, 551, 1985, 13, 400, 291, 434, 1566, 11, 382, 321, 1223, 544, 293, 544, 50612], "temperature": 0.0, "avg_logprob": -0.08072090148925781, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.005727565847337246}, {"id": 32, "seek": 18640, "start": 192.56, "end": 197.28, "text": " about the neocortex, about our own human mind, we'll be able to start to more specifically", "tokens": [50672, 466, 264, 408, 905, 36143, 11, 466, 527, 1065, 1952, 1575, 11, 321, 603, 312, 1075, 281, 722, 281, 544, 4682, 50908], "temperature": 0.0, "avg_logprob": -0.08072090148925781, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.005727565847337246}, {"id": 33, "seek": 18640, "start": 197.28, "end": 201.76, "text": " define what it means to be intelligent. It's not useful to really talk about that until...", "tokens": [50908, 6964, 437, 309, 1355, 281, 312, 13232, 13, 467, 311, 406, 4420, 281, 534, 751, 466, 300, 1826, 485, 51132], "temperature": 0.0, "avg_logprob": -0.08072090148925781, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.005727565847337246}, {"id": 34, "seek": 18640, "start": 201.76, "end": 206.88, "text": " I don't know if it's not useful. Look, there's a long history of AI, as you know. And there's", "tokens": [51132, 286, 500, 380, 458, 498, 309, 311, 406, 4420, 13, 2053, 11, 456, 311, 257, 938, 2503, 295, 7318, 11, 382, 291, 458, 13, 400, 456, 311, 51388], "temperature": 0.0, "avg_logprob": -0.08072090148925781, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.005727565847337246}, {"id": 35, "seek": 18640, "start": 206.88, "end": 214.48000000000002, "text": " been different approaches taken to it. And who knows, maybe they're all useful. So the good", "tokens": [51388, 668, 819, 11587, 2726, 281, 309, 13, 400, 567, 3255, 11, 1310, 436, 434, 439, 4420, 13, 407, 264, 665, 51768], "temperature": 0.0, "avg_logprob": -0.08072090148925781, "compression_ratio": 1.6911764705882353, "no_speech_prob": 0.005727565847337246}, {"id": 36, "seek": 21448, "start": 214.48, "end": 219.6, "text": " old fashioned AI, the expert systems, the current convolutional neural networks, they all have their", "tokens": [50364, 1331, 40646, 7318, 11, 264, 5844, 3652, 11, 264, 2190, 45216, 304, 18161, 9590, 11, 436, 439, 362, 641, 50620], "temperature": 0.0, "avg_logprob": -0.10545093455213181, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.0009107904625125229}, {"id": 37, "seek": 21448, "start": 219.6, "end": 225.51999999999998, "text": " utility. They all have a value in the world. But I would think almost everyone agree that none of", "tokens": [50620, 14877, 13, 814, 439, 362, 257, 2158, 294, 264, 1002, 13, 583, 286, 576, 519, 1920, 1518, 3986, 300, 6022, 295, 50916], "temperature": 0.0, "avg_logprob": -0.10545093455213181, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.0009107904625125229}, {"id": 38, "seek": 21448, "start": 225.51999999999998, "end": 232.95999999999998, "text": " them are really intelligent in a sort of a deep way that humans are. And so it's just the question", "tokens": [50916, 552, 366, 534, 13232, 294, 257, 1333, 295, 257, 2452, 636, 300, 6255, 366, 13, 400, 370, 309, 311, 445, 264, 1168, 51288], "temperature": 0.0, "avg_logprob": -0.10545093455213181, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.0009107904625125229}, {"id": 39, "seek": 21448, "start": 232.95999999999998, "end": 237.76, "text": " is how do you get from where those systems were or are today to where a lot of people think we're", "tokens": [51288, 307, 577, 360, 291, 483, 490, 689, 729, 3652, 645, 420, 366, 965, 281, 689, 257, 688, 295, 561, 519, 321, 434, 51528], "temperature": 0.0, "avg_logprob": -0.10545093455213181, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.0009107904625125229}, {"id": 40, "seek": 23776, "start": 237.76, "end": 244.88, "text": " going to go? And there's a big, big gap there, a huge gap. And I think the quickest way of bridging", "tokens": [50364, 516, 281, 352, 30, 400, 456, 311, 257, 955, 11, 955, 7417, 456, 11, 257, 2603, 7417, 13, 400, 286, 519, 264, 49403, 636, 295, 16362, 3249, 50720], "temperature": 0.0, "avg_logprob": -0.11478439966837566, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.22802184522151947}, {"id": 41, "seek": 23776, "start": 244.88, "end": 250.32, "text": " that gap is to figure out how the brain does that. And then we can sit back and look and say, oh,", "tokens": [50720, 300, 7417, 307, 281, 2573, 484, 577, 264, 3567, 775, 300, 13, 400, 550, 321, 393, 1394, 646, 293, 574, 293, 584, 11, 1954, 11, 50992], "temperature": 0.0, "avg_logprob": -0.11478439966837566, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.22802184522151947}, {"id": 42, "seek": 23776, "start": 250.32, "end": 255.35999999999999, "text": " what are these principles that the brain works on are necessary and which ones are not? Clearly,", "tokens": [50992, 437, 366, 613, 9156, 300, 264, 3567, 1985, 322, 366, 4818, 293, 597, 2306, 366, 406, 30, 24120, 11, 51244], "temperature": 0.0, "avg_logprob": -0.11478439966837566, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.22802184522151947}, {"id": 43, "seek": 23776, "start": 255.35999999999999, "end": 258.64, "text": " we don't have to build this in... and intelligent machines aren't going to be built out of", "tokens": [51244, 321, 500, 380, 362, 281, 1322, 341, 294, 485, 293, 13232, 8379, 3212, 380, 516, 281, 312, 3094, 484, 295, 51408], "temperature": 0.0, "avg_logprob": -0.11478439966837566, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.22802184522151947}, {"id": 44, "seek": 23776, "start": 260.48, "end": 265.76, "text": " organic living cells. But there's a lot of stuff that goes on the brain that's going to be necessary.", "tokens": [51500, 10220, 2647, 5438, 13, 583, 456, 311, 257, 688, 295, 1507, 300, 1709, 322, 264, 3567, 300, 311, 516, 281, 312, 4818, 13, 51764], "temperature": 0.0, "avg_logprob": -0.11478439966837566, "compression_ratio": 1.783882783882784, "no_speech_prob": 0.22802184522151947}, {"id": 45, "seek": 26576, "start": 265.76, "end": 271.84, "text": " So let me ask maybe, before we get into the fun details, let me ask maybe a depressing or", "tokens": [50364, 407, 718, 385, 1029, 1310, 11, 949, 321, 483, 666, 264, 1019, 4365, 11, 718, 385, 1029, 1310, 257, 36355, 420, 50668], "temperature": 0.0, "avg_logprob": -0.12242832779884338, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.0006261728121899068}, {"id": 46, "seek": 26576, "start": 271.84, "end": 277.36, "text": " a difficult question. Do you think it's possible that we will never be able to understand how our", "tokens": [50668, 257, 2252, 1168, 13, 1144, 291, 519, 309, 311, 1944, 300, 321, 486, 1128, 312, 1075, 281, 1223, 577, 527, 50944], "temperature": 0.0, "avg_logprob": -0.12242832779884338, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.0006261728121899068}, {"id": 47, "seek": 26576, "start": 277.36, "end": 284.96, "text": " brain works? That maybe there's aspects to the human mind, like we ourselves cannot introspectively", "tokens": [50944, 3567, 1985, 30, 663, 1310, 456, 311, 7270, 281, 264, 1952, 1575, 11, 411, 321, 4175, 2644, 560, 28713, 3413, 51324], "temperature": 0.0, "avg_logprob": -0.12242832779884338, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.0006261728121899068}, {"id": 48, "seek": 26576, "start": 284.96, "end": 289.84, "text": " get to the core, that there's a wall you eventually hit? Yeah, I don't believe that's the case.", "tokens": [51324, 483, 281, 264, 4965, 11, 300, 456, 311, 257, 2929, 291, 4728, 2045, 30, 865, 11, 286, 500, 380, 1697, 300, 311, 264, 1389, 13, 51568], "temperature": 0.0, "avg_logprob": -0.12242832779884338, "compression_ratio": 1.6228813559322033, "no_speech_prob": 0.0006261728121899068}, {"id": 49, "seek": 28984, "start": 290.71999999999997, "end": 294.4, "text": " I have never believed that's the case. There's not been a single thing we've ever,", "tokens": [50408, 286, 362, 1128, 7847, 300, 311, 264, 1389, 13, 821, 311, 406, 668, 257, 2167, 551, 321, 600, 1562, 11, 50592], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 50, "seek": 28984, "start": 294.4, "end": 298.64, "text": " human have ever put their minds to. We've said, oh, we reached the wall. We can't go any further.", "tokens": [50592, 1952, 362, 1562, 829, 641, 9634, 281, 13, 492, 600, 848, 11, 1954, 11, 321, 6488, 264, 2929, 13, 492, 393, 380, 352, 604, 3052, 13, 50804], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 51, "seek": 28984, "start": 298.64, "end": 303.44, "text": " People keep saying that. People used to believe that about life, you know, Alain Vaital, right?", "tokens": [50804, 3432, 1066, 1566, 300, 13, 3432, 1143, 281, 1697, 300, 466, 993, 11, 291, 458, 11, 967, 491, 691, 1001, 304, 11, 558, 30, 51044], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 52, "seek": 28984, "start": 303.44, "end": 306.4, "text": " There's like, what's the difference between living matter and non-living matter? Something", "tokens": [51044, 821, 311, 411, 11, 437, 311, 264, 2649, 1296, 2647, 1871, 293, 2107, 12, 75, 2123, 1871, 30, 6595, 51192], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 53, "seek": 28984, "start": 306.4, "end": 312.71999999999997, "text": " special you never understand. We no longer think that. So there's no historical evidence that", "tokens": [51192, 2121, 291, 1128, 1223, 13, 492, 572, 2854, 519, 300, 13, 407, 456, 311, 572, 8584, 4467, 300, 51508], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 54, "seek": 28984, "start": 312.71999999999997, "end": 317.44, "text": " suggests this is the case. And I just never even consider that's a possibility. I would also say", "tokens": [51508, 13409, 341, 307, 264, 1389, 13, 400, 286, 445, 1128, 754, 1949, 300, 311, 257, 7959, 13, 286, 576, 611, 584, 51744], "temperature": 0.0, "avg_logprob": -0.23907567413759903, "compression_ratio": 1.7383177570093458, "no_speech_prob": 0.005059317220002413}, {"id": 55, "seek": 31744, "start": 317.52, "end": 323.76, "text": " I would also say today we understand so much about the near cortex. We've made tremendous", "tokens": [50368, 286, 576, 611, 584, 965, 321, 1223, 370, 709, 466, 264, 2651, 33312, 13, 492, 600, 1027, 10048, 50680], "temperature": 0.0, "avg_logprob": -0.13155324580305713, "compression_ratio": 1.6245487364620939, "no_speech_prob": 0.0008034863858483732}, {"id": 56, "seek": 31744, "start": 323.76, "end": 330.88, "text": " progress in the last few years that I no longer think of as an open question. The answers are", "tokens": [50680, 4205, 294, 264, 1036, 1326, 924, 300, 286, 572, 2854, 519, 295, 382, 364, 1269, 1168, 13, 440, 6338, 366, 51036], "temperature": 0.0, "avg_logprob": -0.13155324580305713, "compression_ratio": 1.6245487364620939, "no_speech_prob": 0.0008034863858483732}, {"id": 57, "seek": 31744, "start": 330.88, "end": 336.0, "text": " very clear to me. The pieces we know we don't know are clear to me, but the framework is all there.", "tokens": [51036, 588, 1850, 281, 385, 13, 440, 3755, 321, 458, 321, 500, 380, 458, 366, 1850, 281, 385, 11, 457, 264, 8388, 307, 439, 456, 13, 51292], "temperature": 0.0, "avg_logprob": -0.13155324580305713, "compression_ratio": 1.6245487364620939, "no_speech_prob": 0.0008034863858483732}, {"id": 58, "seek": 31744, "start": 336.0, "end": 339.84, "text": " And it's like, oh, okay, we're going to be able to do this. This is not a problem anymore.", "tokens": [51292, 400, 309, 311, 411, 11, 1954, 11, 1392, 11, 321, 434, 516, 281, 312, 1075, 281, 360, 341, 13, 639, 307, 406, 257, 1154, 3602, 13, 51484], "temperature": 0.0, "avg_logprob": -0.13155324580305713, "compression_ratio": 1.6245487364620939, "no_speech_prob": 0.0008034863858483732}, {"id": 59, "seek": 31744, "start": 339.84, "end": 343.44, "text": " It just takes time and effort. But there's no mystery, big mystery anymore.", "tokens": [51484, 467, 445, 2516, 565, 293, 4630, 13, 583, 456, 311, 572, 11422, 11, 955, 11422, 3602, 13, 51664], "temperature": 0.0, "avg_logprob": -0.13155324580305713, "compression_ratio": 1.6245487364620939, "no_speech_prob": 0.0008034863858483732}, {"id": 60, "seek": 34344, "start": 344.0, "end": 352.24, "text": " So then let's get into it for people like myself who are not very well versed in the human brain,", "tokens": [50392, 407, 550, 718, 311, 483, 666, 309, 337, 561, 411, 2059, 567, 366, 406, 588, 731, 1774, 292, 294, 264, 1952, 3567, 11, 50804], "temperature": 0.0, "avg_logprob": -0.12106772263844807, "compression_ratio": 1.6801801801801801, "no_speech_prob": 0.00302666868083179}, {"id": 61, "seek": 34344, "start": 352.8, "end": 358.16, "text": " except my own. Can you describe to me at the highest level, what are the different parts", "tokens": [50832, 3993, 452, 1065, 13, 1664, 291, 6786, 281, 385, 412, 264, 6343, 1496, 11, 437, 366, 264, 819, 3166, 51100], "temperature": 0.0, "avg_logprob": -0.12106772263844807, "compression_ratio": 1.6801801801801801, "no_speech_prob": 0.00302666868083179}, {"id": 62, "seek": 34344, "start": 358.16, "end": 364.0, "text": " of the human brain and then zooming in on the near cortex, the parts of the near cortex and so on,", "tokens": [51100, 295, 264, 1952, 3567, 293, 550, 48226, 294, 322, 264, 2651, 33312, 11, 264, 3166, 295, 264, 2651, 33312, 293, 370, 322, 11, 51392], "temperature": 0.0, "avg_logprob": -0.12106772263844807, "compression_ratio": 1.6801801801801801, "no_speech_prob": 0.00302666868083179}, {"id": 63, "seek": 34344, "start": 364.0, "end": 369.68, "text": " a quick overview? Yeah, sure. The human brain, we can divide it roughly into two parts.", "tokens": [51392, 257, 1702, 12492, 30, 865, 11, 988, 13, 440, 1952, 3567, 11, 321, 393, 9845, 309, 9810, 666, 732, 3166, 13, 51676], "temperature": 0.0, "avg_logprob": -0.12106772263844807, "compression_ratio": 1.6801801801801801, "no_speech_prob": 0.00302666868083179}, {"id": 64, "seek": 36968, "start": 370.64, "end": 376.40000000000003, "text": " There's the old parts, lots of pieces, and then there's the new part. The new part is the near", "tokens": [50412, 821, 311, 264, 1331, 3166, 11, 3195, 295, 3755, 11, 293, 550, 456, 311, 264, 777, 644, 13, 440, 777, 644, 307, 264, 2651, 50700], "temperature": 0.0, "avg_logprob": -0.10930867348947833, "compression_ratio": 1.9106382978723404, "no_speech_prob": 0.0003150159027427435}, {"id": 65, "seek": 36968, "start": 376.40000000000003, "end": 382.08, "text": " cortex. It's new because it didn't exist before mammals. The only mammals have a near cortex", "tokens": [50700, 33312, 13, 467, 311, 777, 570, 309, 994, 380, 2514, 949, 35408, 13, 440, 787, 35408, 362, 257, 2651, 33312, 50984], "temperature": 0.0, "avg_logprob": -0.10930867348947833, "compression_ratio": 1.9106382978723404, "no_speech_prob": 0.0003150159027427435}, {"id": 66, "seek": 36968, "start": 382.08, "end": 387.2, "text": " and in humans, in primates, it's very large. In the human brain, the near cortex occupies about", "tokens": [50984, 293, 294, 6255, 11, 294, 2886, 1024, 11, 309, 311, 588, 2416, 13, 682, 264, 1952, 3567, 11, 264, 2651, 33312, 8073, 530, 466, 51240], "temperature": 0.0, "avg_logprob": -0.10930867348947833, "compression_ratio": 1.9106382978723404, "no_speech_prob": 0.0003150159027427435}, {"id": 67, "seek": 36968, "start": 387.2, "end": 393.52, "text": " 70 to 75% of the volume of the brain. It's huge. And the old parts of the brain are,", "tokens": [51240, 5285, 281, 9562, 4, 295, 264, 5523, 295, 264, 3567, 13, 467, 311, 2603, 13, 400, 264, 1331, 3166, 295, 264, 3567, 366, 11, 51556], "temperature": 0.0, "avg_logprob": -0.10930867348947833, "compression_ratio": 1.9106382978723404, "no_speech_prob": 0.0003150159027427435}, {"id": 68, "seek": 36968, "start": 394.72, "end": 398.64, "text": " there's lots of pieces there. There's a spinal cord, and there's the brain stem,", "tokens": [51616, 456, 311, 3195, 295, 3755, 456, 13, 821, 311, 257, 28022, 12250, 11, 293, 456, 311, 264, 3567, 12312, 11, 51812], "temperature": 0.0, "avg_logprob": -0.10930867348947833, "compression_ratio": 1.9106382978723404, "no_speech_prob": 0.0003150159027427435}, {"id": 69, "seek": 39864, "start": 398.64, "end": 401.36, "text": " and the cerebellum, and the different parts of the basal ganglion and so on.", "tokens": [50364, 293, 264, 11643, 7100, 449, 11, 293, 264, 819, 3166, 295, 264, 987, 304, 10145, 75, 313, 293, 370, 322, 13, 50500], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 70, "seek": 39864, "start": 401.91999999999996, "end": 406.24, "text": " In the old parts of the brain, you have the autonomic regulation like breathing and heart rate.", "tokens": [50528, 682, 264, 1331, 3166, 295, 264, 3567, 11, 291, 362, 264, 18203, 299, 15062, 411, 9570, 293, 1917, 3314, 13, 50744], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 71, "seek": 39864, "start": 406.24, "end": 410.56, "text": " You have basic behaviors. So like walking and running are controlled by the old parts of the", "tokens": [50744, 509, 362, 3875, 15501, 13, 407, 411, 4494, 293, 2614, 366, 10164, 538, 264, 1331, 3166, 295, 264, 50960], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 72, "seek": 39864, "start": 410.56, "end": 414.15999999999997, "text": " brain. All the emotional centers of the brain are in the old part of the brain. So when you", "tokens": [50960, 3567, 13, 1057, 264, 6863, 10898, 295, 264, 3567, 366, 294, 264, 1331, 644, 295, 264, 3567, 13, 407, 562, 291, 51140], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 73, "seek": 39864, "start": 414.15999999999997, "end": 417.2, "text": " feel anger or hungry, lust or things like that, those are all in the old parts of the brain.", "tokens": [51140, 841, 10240, 420, 8067, 11, 24672, 420, 721, 411, 300, 11, 729, 366, 439, 294, 264, 1331, 3166, 295, 264, 3567, 13, 51292], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 74, "seek": 39864, "start": 419.03999999999996, "end": 424.47999999999996, "text": " And we associate with the near cortex all the things we think about as sort of high level", "tokens": [51384, 400, 321, 14644, 365, 264, 2651, 33312, 439, 264, 721, 321, 519, 466, 382, 1333, 295, 1090, 1496, 51656], "temperature": 0.0, "avg_logprob": -0.11003973234945269, "compression_ratio": 2.007434944237918, "no_speech_prob": 0.00015841975982766598}, {"id": 75, "seek": 42448, "start": 424.48, "end": 432.88, "text": " perception and cognitive functions, anything from seeing and hearing and touching things to", "tokens": [50364, 12860, 293, 15605, 6828, 11, 1340, 490, 2577, 293, 4763, 293, 11175, 721, 281, 50784], "temperature": 0.0, "avg_logprob": -0.09181265454543264, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0001852174027590081}, {"id": 76, "seek": 42448, "start": 432.88, "end": 438.16, "text": " language to mathematics and engineering and science and so on. Those are all associated with the", "tokens": [50784, 2856, 281, 18666, 293, 7043, 293, 3497, 293, 370, 322, 13, 3950, 366, 439, 6615, 365, 264, 51048], "temperature": 0.0, "avg_logprob": -0.09181265454543264, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0001852174027590081}, {"id": 77, "seek": 42448, "start": 438.16, "end": 444.08000000000004, "text": " near cortex. And they're certainly correlated. Our abilities in those regards are correlated with", "tokens": [51048, 2651, 33312, 13, 400, 436, 434, 3297, 38574, 13, 2621, 11582, 294, 729, 14258, 366, 38574, 365, 51344], "temperature": 0.0, "avg_logprob": -0.09181265454543264, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0001852174027590081}, {"id": 78, "seek": 42448, "start": 444.08000000000004, "end": 449.12, "text": " the relative size of our near cortex compared to other mammals. So that's like the rough", "tokens": [51344, 264, 4972, 2744, 295, 527, 2651, 33312, 5347, 281, 661, 35408, 13, 407, 300, 311, 411, 264, 5903, 51596], "temperature": 0.0, "avg_logprob": -0.09181265454543264, "compression_ratio": 1.6741071428571428, "no_speech_prob": 0.0001852174027590081}, {"id": 79, "seek": 44912, "start": 449.2, "end": 455.44, "text": " division. And you obviously can't understand the near cortex completely isolated, but you", "tokens": [50368, 10044, 13, 400, 291, 2745, 393, 380, 1223, 264, 2651, 33312, 2584, 14621, 11, 457, 291, 50680], "temperature": 0.0, "avg_logprob": -0.10137076658361098, "compression_ratio": 1.748792270531401, "no_speech_prob": 0.001896692905575037}, {"id": 80, "seek": 44912, "start": 455.44, "end": 459.6, "text": " can understand a lot of it with just a few interfaces to the old parts of the brain.", "tokens": [50680, 393, 1223, 257, 688, 295, 309, 365, 445, 257, 1326, 28416, 281, 264, 1331, 3166, 295, 264, 3567, 13, 50888], "temperature": 0.0, "avg_logprob": -0.10137076658361098, "compression_ratio": 1.748792270531401, "no_speech_prob": 0.001896692905575037}, {"id": 81, "seek": 44912, "start": 460.32, "end": 467.12, "text": " And so it gives you a system to study. The other remarkable thing about the near cortex", "tokens": [50924, 400, 370, 309, 2709, 291, 257, 1185, 281, 2979, 13, 440, 661, 12802, 551, 466, 264, 2651, 33312, 51264], "temperature": 0.0, "avg_logprob": -0.10137076658361098, "compression_ratio": 1.748792270531401, "no_speech_prob": 0.001896692905575037}, {"id": 82, "seek": 44912, "start": 467.92, "end": 474.72, "text": " compared to the old parts of the brain is the near cortex is extremely uniform. It's not visibly or", "tokens": [51304, 5347, 281, 264, 1331, 3166, 295, 264, 3567, 307, 264, 2651, 33312, 307, 4664, 9452, 13, 467, 311, 406, 1452, 3545, 420, 51644], "temperature": 0.0, "avg_logprob": -0.10137076658361098, "compression_ratio": 1.748792270531401, "no_speech_prob": 0.001896692905575037}, {"id": 83, "seek": 47472, "start": 474.72, "end": 481.20000000000005, "text": " anatomically or it's very it's like a I always like to say it's like the size of a dinner napkin", "tokens": [50364, 21618, 298, 984, 420, 309, 311, 588, 309, 311, 411, 257, 286, 1009, 411, 281, 584, 309, 311, 411, 264, 2744, 295, 257, 6148, 9296, 5843, 50688], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 84, "seek": 47472, "start": 481.20000000000005, "end": 486.24, "text": " about two and a half millimeters thick. And it looks remarkably the same everywhere. Everywhere", "tokens": [50688, 466, 732, 293, 257, 1922, 24388, 5060, 13, 400, 309, 1542, 37381, 264, 912, 5315, 13, 37322, 50940], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 85, "seek": 47472, "start": 486.24, "end": 490.40000000000003, "text": " you look in that two and a half millimeters is this detailed architecture. And it looks", "tokens": [50940, 291, 574, 294, 300, 732, 293, 257, 1922, 24388, 307, 341, 9942, 9482, 13, 400, 309, 1542, 51148], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 86, "seek": 47472, "start": 490.40000000000003, "end": 494.64000000000004, "text": " remarkably the same everywhere. And that's across species, a mouse versus a cat and a dog and a", "tokens": [51148, 37381, 264, 912, 5315, 13, 400, 300, 311, 2108, 6172, 11, 257, 9719, 5717, 257, 3857, 293, 257, 3000, 293, 257, 51360], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 87, "seek": 47472, "start": 494.64000000000004, "end": 498.72, "text": " human. Where if you look at the old parts of the brain, there's lots of little pieces do specific", "tokens": [51360, 1952, 13, 2305, 498, 291, 574, 412, 264, 1331, 3166, 295, 264, 3567, 11, 456, 311, 3195, 295, 707, 3755, 360, 2685, 51564], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 88, "seek": 47472, "start": 498.72, "end": 503.20000000000005, "text": " things. So it's like the old parts of a brain involved like this is the part that controls", "tokens": [51564, 721, 13, 407, 309, 311, 411, 264, 1331, 3166, 295, 257, 3567, 3288, 411, 341, 307, 264, 644, 300, 9003, 51788], "temperature": 0.0, "avg_logprob": -0.12645724219997434, "compression_ratio": 2.00354609929078, "no_speech_prob": 0.0004441964556463063}, {"id": 89, "seek": 50320, "start": 503.2, "end": 506.0, "text": " heart rate. And this is the part that controls this and this is this kind of thing. And that's", "tokens": [50364, 1917, 3314, 13, 400, 341, 307, 264, 644, 300, 9003, 341, 293, 341, 307, 341, 733, 295, 551, 13, 400, 300, 311, 50504], "temperature": 0.0, "avg_logprob": -0.08934982684480042, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.00035695795668289065}, {"id": 90, "seek": 50320, "start": 506.0, "end": 510.96, "text": " this kind of thing. And these evolve for eons of a long, long time. And they have those specific", "tokens": [50504, 341, 733, 295, 551, 13, 400, 613, 16693, 337, 308, 892, 295, 257, 938, 11, 938, 565, 13, 400, 436, 362, 729, 2685, 50752], "temperature": 0.0, "avg_logprob": -0.08934982684480042, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.00035695795668289065}, {"id": 91, "seek": 50320, "start": 510.96, "end": 514.3199999999999, "text": " functions. And all of a sudden mammals come along and they got this thing called the near", "tokens": [50752, 6828, 13, 400, 439, 295, 257, 3990, 35408, 808, 2051, 293, 436, 658, 341, 551, 1219, 264, 2651, 50920], "temperature": 0.0, "avg_logprob": -0.08934982684480042, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.00035695795668289065}, {"id": 92, "seek": 50320, "start": 514.3199999999999, "end": 519.28, "text": " cortex. And it got large by just replicating the same thing over and over and over again.", "tokens": [50920, 33312, 13, 400, 309, 658, 2416, 538, 445, 3248, 30541, 264, 912, 551, 670, 293, 670, 293, 670, 797, 13, 51168], "temperature": 0.0, "avg_logprob": -0.08934982684480042, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.00035695795668289065}, {"id": 93, "seek": 50320, "start": 519.28, "end": 527.76, "text": " This is like, wow, this is incredible. So all the evidence we have. And this is an idea that was", "tokens": [51168, 639, 307, 411, 11, 6076, 11, 341, 307, 4651, 13, 407, 439, 264, 4467, 321, 362, 13, 400, 341, 307, 364, 1558, 300, 390, 51592], "temperature": 0.0, "avg_logprob": -0.08934982684480042, "compression_ratio": 1.910204081632653, "no_speech_prob": 0.00035695795668289065}, {"id": 94, "seek": 52776, "start": 527.76, "end": 534.88, "text": " first articulated in a very cogent and beautiful argument by a guy named Vernon Malcastle in 1978,", "tokens": [50364, 700, 43322, 294, 257, 588, 598, 6930, 293, 2238, 6770, 538, 257, 2146, 4926, 47516, 5746, 3734, 306, 294, 33191, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1327296738075999, "compression_ratio": 1.621160409556314, "no_speech_prob": 0.010165229439735413}, {"id": 95, "seek": 52776, "start": 534.88, "end": 543.76, "text": " I think it was, that the neocortex all works on the same principle. So language, hearing,", "tokens": [50720, 286, 519, 309, 390, 11, 300, 264, 408, 905, 36143, 439, 1985, 322, 264, 912, 8665, 13, 407, 2856, 11, 4763, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1327296738075999, "compression_ratio": 1.621160409556314, "no_speech_prob": 0.010165229439735413}, {"id": 96, "seek": 52776, "start": 543.76, "end": 548.3199999999999, "text": " touch, vision, engineering, all these things are basically underlying or all built in the same", "tokens": [51164, 2557, 11, 5201, 11, 7043, 11, 439, 613, 721, 366, 1936, 14217, 420, 439, 3094, 294, 264, 912, 51392], "temperature": 0.0, "avg_logprob": -0.1327296738075999, "compression_ratio": 1.621160409556314, "no_speech_prob": 0.010165229439735413}, {"id": 97, "seek": 52776, "start": 548.3199999999999, "end": 552.96, "text": " computational substrate. They're really all the same problem. So the low level of the building", "tokens": [51392, 28270, 27585, 13, 814, 434, 534, 439, 264, 912, 1154, 13, 407, 264, 2295, 1496, 295, 264, 2390, 51624], "temperature": 0.0, "avg_logprob": -0.1327296738075999, "compression_ratio": 1.621160409556314, "no_speech_prob": 0.010165229439735413}, {"id": 98, "seek": 52776, "start": 552.96, "end": 557.4399999999999, "text": " blocks all look similar. Yeah. And they're not even that low level. We're not talking about like", "tokens": [51624, 8474, 439, 574, 2531, 13, 865, 13, 400, 436, 434, 406, 754, 300, 2295, 1496, 13, 492, 434, 406, 1417, 466, 411, 51848], "temperature": 0.0, "avg_logprob": -0.1327296738075999, "compression_ratio": 1.621160409556314, "no_speech_prob": 0.010165229439735413}, {"id": 99, "seek": 55744, "start": 557.44, "end": 561.5200000000001, "text": " neurons. We're talking about this very complex circuit that exists throughout the neocortex is", "tokens": [50364, 22027, 13, 492, 434, 1417, 466, 341, 588, 3997, 9048, 300, 8198, 3710, 264, 408, 905, 36143, 307, 50568], "temperature": 0.0, "avg_logprob": -0.16248146432345031, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0008555481326766312}, {"id": 100, "seek": 55744, "start": 562.1600000000001, "end": 567.2, "text": " remarkably similar. It is, it's like, yes, you see variations of it here and there, more of the cell", "tokens": [50600, 37381, 2531, 13, 467, 307, 11, 309, 311, 411, 11, 2086, 11, 291, 536, 17840, 295, 309, 510, 293, 456, 11, 544, 295, 264, 2815, 50852], "temperature": 0.0, "avg_logprob": -0.16248146432345031, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0008555481326766312}, {"id": 101, "seek": 55744, "start": 567.2, "end": 574.08, "text": " left and left and so on. But what Malcastle argued was it says, you know, if you take a section on", "tokens": [50852, 1411, 293, 1411, 293, 370, 322, 13, 583, 437, 5746, 3734, 306, 20219, 390, 309, 1619, 11, 291, 458, 11, 498, 291, 747, 257, 3541, 322, 51196], "temperature": 0.0, "avg_logprob": -0.16248146432345031, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0008555481326766312}, {"id": 102, "seek": 55744, "start": 574.08, "end": 580.1600000000001, "text": " neocortex, why is one a visual area and one is a auditory area? Or why is, and his answer was", "tokens": [51196, 408, 905, 36143, 11, 983, 307, 472, 257, 5056, 1859, 293, 472, 307, 257, 17748, 827, 1859, 30, 1610, 983, 307, 11, 293, 702, 1867, 390, 51500], "temperature": 0.0, "avg_logprob": -0.16248146432345031, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0008555481326766312}, {"id": 103, "seek": 55744, "start": 581.0400000000001, "end": 584.32, "text": " it's because one is connected to eyes and one is connected to ears.", "tokens": [51544, 309, 311, 570, 472, 307, 4582, 281, 2575, 293, 472, 307, 4582, 281, 8798, 13, 51708], "temperature": 0.0, "avg_logprob": -0.16248146432345031, "compression_ratio": 1.7078651685393258, "no_speech_prob": 0.0008555481326766312}, {"id": 104, "seek": 58432, "start": 585.2800000000001, "end": 590.32, "text": " Literally, you mean just it's most closest in terms of number of connections to the sensor?", "tokens": [50412, 23768, 11, 291, 914, 445, 309, 311, 881, 13699, 294, 2115, 295, 1230, 295, 9271, 281, 264, 10200, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2015975793202718, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.000635980162769556}, {"id": 105, "seek": 58432, "start": 590.32, "end": 595.2, "text": " Literally, if you took the optic nerve and attached it to a different part of the neocortex,", "tokens": [50664, 23768, 11, 498, 291, 1890, 264, 48269, 16355, 293, 8570, 309, 281, 257, 819, 644, 295, 264, 408, 905, 36143, 11, 50908], "temperature": 0.0, "avg_logprob": -0.2015975793202718, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.000635980162769556}, {"id": 106, "seek": 58432, "start": 595.2, "end": 600.32, "text": " that part would become a visual region. This actually, this experiment was actually done by", "tokens": [50908, 300, 644, 576, 1813, 257, 5056, 4458, 13, 639, 767, 11, 341, 5120, 390, 767, 1096, 538, 51164], "temperature": 0.0, "avg_logprob": -0.2015975793202718, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.000635980162769556}, {"id": 107, "seek": 58432, "start": 600.32, "end": 606.6400000000001, "text": " McGonkiss Sir in developing, I think it was lemurs, I can't remember what it was, some animal.", "tokens": [51164, 21865, 266, 74, 891, 6144, 294, 6416, 11, 286, 519, 309, 390, 7495, 2156, 11, 286, 393, 380, 1604, 437, 309, 390, 11, 512, 5496, 13, 51480], "temperature": 0.0, "avg_logprob": -0.2015975793202718, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.000635980162769556}, {"id": 108, "seek": 58432, "start": 606.6400000000001, "end": 610.48, "text": " And, and there's a lot of evidence to this. You know, if you take a blind person, a person is", "tokens": [51480, 400, 11, 293, 456, 311, 257, 688, 295, 4467, 281, 341, 13, 509, 458, 11, 498, 291, 747, 257, 6865, 954, 11, 257, 954, 307, 51672], "temperature": 0.0, "avg_logprob": -0.2015975793202718, "compression_ratio": 1.6373239436619718, "no_speech_prob": 0.000635980162769556}, {"id": 109, "seek": 61048, "start": 610.48, "end": 616.0, "text": " born blind at birth. They, they're born with a visual neocortex. It doesn't", "tokens": [50364, 4232, 6865, 412, 3965, 13, 814, 11, 436, 434, 4232, 365, 257, 5056, 408, 905, 36143, 13, 467, 1177, 380, 50640], "temperature": 0.0, "avg_logprob": -0.12157509966594417, "compression_ratio": 1.75390625, "no_speech_prob": 0.0009109012316912413}, {"id": 110, "seek": 61048, "start": 616.0, "end": 621.44, "text": " may not get any input from the eyes, because of some congenital defect or something. And", "tokens": [50640, 815, 406, 483, 604, 4846, 490, 264, 2575, 11, 570, 295, 512, 416, 1766, 1686, 16445, 420, 746, 13, 400, 50912], "temperature": 0.0, "avg_logprob": -0.12157509966594417, "compression_ratio": 1.75390625, "no_speech_prob": 0.0009109012316912413}, {"id": 111, "seek": 61048, "start": 622.48, "end": 629.2, "text": " that region becomes, does something else. It picks up another task. So, and it's, it's,", "tokens": [50964, 300, 4458, 3643, 11, 775, 746, 1646, 13, 467, 16137, 493, 1071, 5633, 13, 407, 11, 293, 309, 311, 11, 309, 311, 11, 51300], "temperature": 0.0, "avg_logprob": -0.12157509966594417, "compression_ratio": 1.75390625, "no_speech_prob": 0.0009109012316912413}, {"id": 112, "seek": 61048, "start": 629.2, "end": 633.76, "text": " so it's this, it's this very complex thing. It's not like, oh, they're all built on neurons. No,", "tokens": [51300, 370, 309, 311, 341, 11, 309, 311, 341, 588, 3997, 551, 13, 467, 311, 406, 411, 11, 1954, 11, 436, 434, 439, 3094, 322, 22027, 13, 883, 11, 51528], "temperature": 0.0, "avg_logprob": -0.12157509966594417, "compression_ratio": 1.75390625, "no_speech_prob": 0.0009109012316912413}, {"id": 113, "seek": 61048, "start": 633.76, "end": 639.52, "text": " they're all built in this very complex circuit. And, and somehow that circuit underlies everything.", "tokens": [51528, 436, 434, 439, 3094, 294, 341, 588, 3997, 9048, 13, 400, 11, 293, 6063, 300, 9048, 833, 24119, 1203, 13, 51816], "temperature": 0.0, "avg_logprob": -0.12157509966594417, "compression_ratio": 1.75390625, "no_speech_prob": 0.0009109012316912413}, {"id": 114, "seek": 63952, "start": 640.16, "end": 647.04, "text": " And so this is the, it's called the common cortical algorithm, if you will. Some scientists just find", "tokens": [50396, 400, 370, 341, 307, 264, 11, 309, 311, 1219, 264, 2689, 11278, 804, 9284, 11, 498, 291, 486, 13, 2188, 7708, 445, 915, 50740], "temperature": 0.0, "avg_logprob": -0.10341774622599284, "compression_ratio": 1.8566037735849057, "no_speech_prob": 6.204584497027099e-05}, {"id": 115, "seek": 63952, "start": 647.04, "end": 651.4399999999999, "text": " it hard to believe. And they just say, I can't believe that's true. But the evidence is overwhelming", "tokens": [50740, 309, 1152, 281, 1697, 13, 400, 436, 445, 584, 11, 286, 393, 380, 1697, 300, 311, 2074, 13, 583, 264, 4467, 307, 13373, 50960], "temperature": 0.0, "avg_logprob": -0.10341774622599284, "compression_ratio": 1.8566037735849057, "no_speech_prob": 6.204584497027099e-05}, {"id": 116, "seek": 63952, "start": 651.4399999999999, "end": 656.3199999999999, "text": " in this case. And so a large part of what it means to figure out how the brain creates intelligence", "tokens": [50960, 294, 341, 1389, 13, 400, 370, 257, 2416, 644, 295, 437, 309, 1355, 281, 2573, 484, 577, 264, 3567, 7829, 7599, 51204], "temperature": 0.0, "avg_logprob": -0.10341774622599284, "compression_ratio": 1.8566037735849057, "no_speech_prob": 6.204584497027099e-05}, {"id": 117, "seek": 63952, "start": 656.3199999999999, "end": 662.24, "text": " and what is intelligence in the brain is to understand what that circuit does. If you can", "tokens": [51204, 293, 437, 307, 7599, 294, 264, 3567, 307, 281, 1223, 437, 300, 9048, 775, 13, 759, 291, 393, 51500], "temperature": 0.0, "avg_logprob": -0.10341774622599284, "compression_ratio": 1.8566037735849057, "no_speech_prob": 6.204584497027099e-05}, {"id": 118, "seek": 63952, "start": 662.24, "end": 668.0, "text": " figure out what that circuit does, as amazing as it is, then you can, then you, then you understand", "tokens": [51500, 2573, 484, 437, 300, 9048, 775, 11, 382, 2243, 382, 309, 307, 11, 550, 291, 393, 11, 550, 291, 11, 550, 291, 1223, 51788], "temperature": 0.0, "avg_logprob": -0.10341774622599284, "compression_ratio": 1.8566037735849057, "no_speech_prob": 6.204584497027099e-05}, {"id": 119, "seek": 66800, "start": 668.0, "end": 673.76, "text": " what all these other cognitive functions are. So if you were to sort of put neural cortex outside", "tokens": [50364, 437, 439, 613, 661, 15605, 6828, 366, 13, 407, 498, 291, 645, 281, 1333, 295, 829, 18161, 33312, 2380, 50652], "temperature": 0.0, "avg_logprob": -0.1188384453455607, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.004329668823629618}, {"id": 120, "seek": 66800, "start": 673.76, "end": 678.4, "text": " of your book on intelligence, if you look, if you wrote a giant tome, a textbook on the neural", "tokens": [50652, 295, 428, 1446, 322, 7599, 11, 498, 291, 574, 11, 498, 291, 4114, 257, 7410, 281, 1398, 11, 257, 25591, 322, 264, 18161, 50884], "temperature": 0.0, "avg_logprob": -0.1188384453455607, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.004329668823629618}, {"id": 121, "seek": 66800, "start": 678.4, "end": 685.76, "text": " cortex, and you look maybe a couple centuries from now, how much of what we know now would still", "tokens": [50884, 33312, 11, 293, 291, 574, 1310, 257, 1916, 13926, 490, 586, 11, 577, 709, 295, 437, 321, 458, 586, 576, 920, 51252], "temperature": 0.0, "avg_logprob": -0.1188384453455607, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.004329668823629618}, {"id": 122, "seek": 66800, "start": 685.76, "end": 690.72, "text": " be accurate two centuries from now. So how close are we in terms of understanding? So I'm going to,", "tokens": [51252, 312, 8559, 732, 13926, 490, 586, 13, 407, 577, 1998, 366, 321, 294, 2115, 295, 3701, 30, 407, 286, 478, 516, 281, 11, 51500], "temperature": 0.0, "avg_logprob": -0.1188384453455607, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.004329668823629618}, {"id": 123, "seek": 66800, "start": 690.72, "end": 695.84, "text": " I have to speak from my own particular experience here. So I run a small research lab here. It's", "tokens": [51500, 286, 362, 281, 1710, 490, 452, 1065, 1729, 1752, 510, 13, 407, 286, 1190, 257, 1359, 2132, 2715, 510, 13, 467, 311, 51756], "temperature": 0.0, "avg_logprob": -0.1188384453455607, "compression_ratio": 1.7173144876325088, "no_speech_prob": 0.004329668823629618}, {"id": 124, "seek": 69584, "start": 696.5600000000001, "end": 699.6800000000001, "text": " it's like any other research lab on the sort of the principal investigator, there's actually", "tokens": [50400, 309, 311, 411, 604, 661, 2132, 2715, 322, 264, 1333, 295, 264, 9716, 38330, 11, 456, 311, 767, 50556], "temperature": 0.0, "avg_logprob": -0.13667785611927, "compression_ratio": 1.7074074074074075, "no_speech_prob": 0.00014422379899770021}, {"id": 125, "seek": 69584, "start": 699.6800000000001, "end": 704.32, "text": " two of us and there's a bunch of other people. And this is what we do. We started the neural", "tokens": [50556, 732, 295, 505, 293, 456, 311, 257, 3840, 295, 661, 561, 13, 400, 341, 307, 437, 321, 360, 13, 492, 1409, 264, 18161, 50788], "temperature": 0.0, "avg_logprob": -0.13667785611927, "compression_ratio": 1.7074074074074075, "no_speech_prob": 0.00014422379899770021}, {"id": 126, "seek": 69584, "start": 704.32, "end": 710.1600000000001, "text": " cortex, and we published our results and so on. So about three years ago, we had a real", "tokens": [50788, 33312, 11, 293, 321, 6572, 527, 3542, 293, 370, 322, 13, 407, 466, 1045, 924, 2057, 11, 321, 632, 257, 957, 51080], "temperature": 0.0, "avg_logprob": -0.13667785611927, "compression_ratio": 1.7074074074074075, "no_speech_prob": 0.00014422379899770021}, {"id": 127, "seek": 69584, "start": 710.1600000000001, "end": 713.9200000000001, "text": " breakthrough in this, in this field. It's a tremendous breakthrough. We started, we've now", "tokens": [51080, 22397, 294, 341, 11, 294, 341, 2519, 13, 467, 311, 257, 10048, 22397, 13, 492, 1409, 11, 321, 600, 586, 51268], "temperature": 0.0, "avg_logprob": -0.13667785611927, "compression_ratio": 1.7074074074074075, "no_speech_prob": 0.00014422379899770021}, {"id": 128, "seek": 69584, "start": 713.9200000000001, "end": 720.32, "text": " published, I think, three papers on it. And so I have, I have a pretty good understanding of all", "tokens": [51268, 6572, 11, 286, 519, 11, 1045, 10577, 322, 309, 13, 400, 370, 286, 362, 11, 286, 362, 257, 1238, 665, 3701, 295, 439, 51588], "temperature": 0.0, "avg_logprob": -0.13667785611927, "compression_ratio": 1.7074074074074075, "no_speech_prob": 0.00014422379899770021}, {"id": 129, "seek": 72032, "start": 720.32, "end": 726.8000000000001, "text": " the pieces and what we're missing. I would say that almost all the empirical data we've collected", "tokens": [50364, 264, 3755, 293, 437, 321, 434, 5361, 13, 286, 576, 584, 300, 1920, 439, 264, 31886, 1412, 321, 600, 11087, 50688], "temperature": 0.0, "avg_logprob": -0.09262667645464887, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.004608886316418648}, {"id": 130, "seek": 72032, "start": 726.8000000000001, "end": 730.96, "text": " about the brain, which is enormous, if you don't know the neuroscience literature, it's just", "tokens": [50688, 466, 264, 3567, 11, 597, 307, 11322, 11, 498, 291, 500, 380, 458, 264, 42762, 10394, 11, 309, 311, 445, 50896], "temperature": 0.0, "avg_logprob": -0.09262667645464887, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.004608886316418648}, {"id": 131, "seek": 72032, "start": 730.96, "end": 740.96, "text": " incredibly big. And it's, for the most part, all correct. It's facts and experimental results and", "tokens": [50896, 6252, 955, 13, 400, 309, 311, 11, 337, 264, 881, 644, 11, 439, 3006, 13, 467, 311, 9130, 293, 17069, 3542, 293, 51396], "temperature": 0.0, "avg_logprob": -0.09262667645464887, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.004608886316418648}, {"id": 132, "seek": 72032, "start": 740.96, "end": 746.72, "text": " measurements and all kinds of stuff. But none of that has been really assimilated into a theoretical", "tokens": [51396, 15383, 293, 439, 3685, 295, 1507, 13, 583, 6022, 295, 300, 575, 668, 534, 8249, 45678, 666, 257, 20864, 51684], "temperature": 0.0, "avg_logprob": -0.09262667645464887, "compression_ratio": 1.5942622950819672, "no_speech_prob": 0.004608886316418648}, {"id": 133, "seek": 74672, "start": 746.72, "end": 753.44, "text": " framework. It's, it's data without, it's in the, in the language of Thomas Coon, the historian,", "tokens": [50364, 8388, 13, 467, 311, 11, 309, 311, 1412, 1553, 11, 309, 311, 294, 264, 11, 294, 264, 2856, 295, 8500, 3066, 266, 11, 264, 25139, 11, 50700], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 134, "seek": 74672, "start": 753.44, "end": 758.08, "text": " it would be a sort of a pre-paradigm science, lots of data, but no way to fit it in together.", "tokens": [50700, 309, 576, 312, 257, 1333, 295, 257, 659, 12, 2181, 345, 20181, 3497, 11, 3195, 295, 1412, 11, 457, 572, 636, 281, 3318, 309, 294, 1214, 13, 50932], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 135, "seek": 74672, "start": 758.08, "end": 760.8000000000001, "text": " I think almost all of that's correct. There's going to be some mistakes in there.", "tokens": [50932, 286, 519, 1920, 439, 295, 300, 311, 3006, 13, 821, 311, 516, 281, 312, 512, 8038, 294, 456, 13, 51068], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 136, "seek": 74672, "start": 762.08, "end": 767.2, "text": " And for the most part, there aren't really good cogent theories about how to put it together.", "tokens": [51132, 400, 337, 264, 881, 644, 11, 456, 3212, 380, 534, 665, 598, 6930, 13667, 466, 577, 281, 829, 309, 1214, 13, 51388], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 137, "seek": 74672, "start": 767.2, "end": 771.12, "text": " It's not like we have two or three competing good theories, which ones are right and which ones", "tokens": [51388, 467, 311, 406, 411, 321, 362, 732, 420, 1045, 15439, 665, 13667, 11, 597, 2306, 366, 558, 293, 597, 2306, 51584], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 138, "seek": 74672, "start": 771.12, "end": 774.64, "text": " are wrong. It's like, yeah, people just like scratching their heads, throwing things, you know,", "tokens": [51584, 366, 2085, 13, 467, 311, 411, 11, 1338, 11, 561, 445, 411, 29699, 641, 8050, 11, 10238, 721, 11, 291, 458, 11, 51760], "temperature": 0.0, "avg_logprob": -0.12914311965839975, "compression_ratio": 1.751572327044025, "no_speech_prob": 0.0008040464599616826}, {"id": 139, "seek": 77464, "start": 774.64, "end": 777.52, "text": " some people have given up on trying to like figure out what the whole thing does.", "tokens": [50364, 512, 561, 362, 2212, 493, 322, 1382, 281, 411, 2573, 484, 437, 264, 1379, 551, 775, 13, 50508], "temperature": 0.0, "avg_logprob": -0.08218697843880489, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00010228107566945255}, {"id": 140, "seek": 77464, "start": 777.52, "end": 784.16, "text": " In fact, there's very, very few labs that we do that focus really on theory and all this", "tokens": [50508, 682, 1186, 11, 456, 311, 588, 11, 588, 1326, 20339, 300, 321, 360, 300, 1879, 534, 322, 5261, 293, 439, 341, 50840], "temperature": 0.0, "avg_logprob": -0.08218697843880489, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00010228107566945255}, {"id": 141, "seek": 77464, "start": 784.16, "end": 788.88, "text": " unassimilated data and trying to explain it. So it's not like we haven't, we've got it wrong.", "tokens": [50840, 517, 640, 332, 45678, 1412, 293, 1382, 281, 2903, 309, 13, 407, 309, 311, 406, 411, 321, 2378, 380, 11, 321, 600, 658, 309, 2085, 13, 51076], "temperature": 0.0, "avg_logprob": -0.08218697843880489, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00010228107566945255}, {"id": 142, "seek": 77464, "start": 788.88, "end": 794.16, "text": " It's just that we haven't got it at all. So it's really, I would say, pretty early days", "tokens": [51076, 467, 311, 445, 300, 321, 2378, 380, 658, 309, 412, 439, 13, 407, 309, 311, 534, 11, 286, 576, 584, 11, 1238, 2440, 1708, 51340], "temperature": 0.0, "avg_logprob": -0.08218697843880489, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00010228107566945255}, {"id": 143, "seek": 77464, "start": 795.04, "end": 800.16, "text": " in terms of understanding the fundamental theories, forces of the way our mind works.", "tokens": [51384, 294, 2115, 295, 3701, 264, 8088, 13667, 11, 5874, 295, 264, 636, 527, 1575, 1985, 13, 51640], "temperature": 0.0, "avg_logprob": -0.08218697843880489, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.00010228107566945255}, {"id": 144, "seek": 80016, "start": 800.16, "end": 803.52, "text": " I don't think so. I would have said that's true five years ago.", "tokens": [50364, 286, 500, 380, 519, 370, 13, 286, 576, 362, 848, 300, 311, 2074, 1732, 924, 2057, 13, 50532], "temperature": 0.0, "avg_logprob": -0.11487648703835228, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.003482947824522853}, {"id": 145, "seek": 80016, "start": 805.28, "end": 810.48, "text": " So as I said, we had some really big breakthroughs on this recently, and we started publishing papers", "tokens": [50620, 407, 382, 286, 848, 11, 321, 632, 512, 534, 955, 22397, 82, 322, 341, 3938, 11, 293, 321, 1409, 17832, 10577, 50880], "temperature": 0.0, "avg_logprob": -0.11487648703835228, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.003482947824522853}, {"id": 146, "seek": 80016, "start": 810.48, "end": 816.7199999999999, "text": " on this. So we'll get to that. So I don't think it's, you know, I'm an optimist,", "tokens": [50880, 322, 341, 13, 407, 321, 603, 483, 281, 300, 13, 407, 286, 500, 380, 519, 309, 311, 11, 291, 458, 11, 286, 478, 364, 5028, 468, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11487648703835228, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.003482947824522853}, {"id": 147, "seek": 80016, "start": 816.7199999999999, "end": 820.3199999999999, "text": " and from where I sit today, most people would disagree with this, but from where I sit today,", "tokens": [51192, 293, 490, 689, 286, 1394, 965, 11, 881, 561, 576, 14091, 365, 341, 11, 457, 490, 689, 286, 1394, 965, 11, 51372], "temperature": 0.0, "avg_logprob": -0.11487648703835228, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.003482947824522853}, {"id": 148, "seek": 80016, "start": 820.3199999999999, "end": 827.1999999999999, "text": " from what I know, it's not super early days anymore. The way these things go is it's not a", "tokens": [51372, 490, 437, 286, 458, 11, 309, 311, 406, 1687, 2440, 1708, 3602, 13, 440, 636, 613, 721, 352, 307, 309, 311, 406, 257, 51716], "temperature": 0.0, "avg_logprob": -0.11487648703835228, "compression_ratio": 1.7171314741035857, "no_speech_prob": 0.003482947824522853}, {"id": 149, "seek": 82720, "start": 827.2, "end": 830.72, "text": " linear path, right? You don't just start accumulating and get better and better and better.", "tokens": [50364, 8213, 3100, 11, 558, 30, 509, 500, 380, 445, 722, 12989, 12162, 293, 483, 1101, 293, 1101, 293, 1101, 13, 50540], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 150, "seek": 82720, "start": 830.72, "end": 834.32, "text": " No, you got all the stuff you've collected. None of it makes sense. All these different", "tokens": [50540, 883, 11, 291, 658, 439, 264, 1507, 291, 600, 11087, 13, 14492, 295, 309, 1669, 2020, 13, 1057, 613, 819, 50720], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 151, "seek": 82720, "start": 834.32, "end": 837.5200000000001, "text": " things we just started around. And then you're going to have some breaking points all of a sudden,", "tokens": [50720, 721, 321, 445, 1409, 926, 13, 400, 550, 291, 434, 516, 281, 362, 512, 7697, 2793, 439, 295, 257, 3990, 11, 50880], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 152, "seek": 82720, "start": 837.5200000000001, "end": 843.5200000000001, "text": " oh my God, now we got it right. That's how it goes in science. And I personally feel like we", "tokens": [50880, 1954, 452, 1265, 11, 586, 321, 658, 309, 558, 13, 663, 311, 577, 309, 1709, 294, 3497, 13, 400, 286, 5665, 841, 411, 321, 51180], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 153, "seek": 82720, "start": 843.5200000000001, "end": 847.44, "text": " passed that little thing about a couple of years ago, all that big thing a couple of years ago.", "tokens": [51180, 4678, 300, 707, 551, 466, 257, 1916, 295, 924, 2057, 11, 439, 300, 955, 551, 257, 1916, 295, 924, 2057, 13, 51376], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 154, "seek": 82720, "start": 847.44, "end": 852.48, "text": " So we can talk about that. Time will tell if I'm right. But I feel very confident about it.", "tokens": [51376, 407, 321, 393, 751, 466, 300, 13, 6161, 486, 980, 498, 286, 478, 558, 13, 583, 286, 841, 588, 6679, 466, 309, 13, 51628], "temperature": 0.0, "avg_logprob": -0.13119661557924497, "compression_ratio": 1.72, "no_speech_prob": 0.04083218425512314}, {"id": 155, "seek": 85248, "start": 852.5600000000001, "end": 858.5600000000001, "text": " That's the moment to say it on tape like this. At least very optimistic. So let's,", "tokens": [50368, 663, 311, 264, 1623, 281, 584, 309, 322, 7314, 411, 341, 13, 1711, 1935, 588, 19397, 13, 407, 718, 311, 11, 50668], "temperature": 0.0, "avg_logprob": -0.14715805920687589, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.002888716058805585}, {"id": 156, "seek": 85248, "start": 858.5600000000001, "end": 865.84, "text": " before those few years ago, let's take a step back to HTM, the hierarchical temporal memory theory,", "tokens": [50668, 949, 729, 1326, 924, 2057, 11, 718, 311, 747, 257, 1823, 646, 281, 11751, 44, 11, 264, 35250, 804, 30881, 4675, 5261, 11, 51032], "temperature": 0.0, "avg_logprob": -0.14715805920687589, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.002888716058805585}, {"id": 157, "seek": 85248, "start": 865.84, "end": 869.36, "text": " which you first proposed on intelligence and went through a few different generations. Can", "tokens": [51032, 597, 291, 700, 10348, 322, 7599, 293, 1437, 807, 257, 1326, 819, 10593, 13, 1664, 51208], "temperature": 0.0, "avg_logprob": -0.14715805920687589, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.002888716058805585}, {"id": 158, "seek": 85248, "start": 869.36, "end": 874.48, "text": " you describe what it is, how it evolved through the three generations, since you first put it", "tokens": [51208, 291, 6786, 437, 309, 307, 11, 577, 309, 14178, 807, 264, 1045, 10593, 11, 1670, 291, 700, 829, 309, 51464], "temperature": 0.0, "avg_logprob": -0.14715805920687589, "compression_ratio": 1.5751072961373391, "no_speech_prob": 0.002888716058805585}, {"id": 159, "seek": 87448, "start": 874.48, "end": 882.24, "text": " on paper? Yeah. So one of the things that neuroscientists just sort of missed for many,", "tokens": [50364, 322, 3035, 30, 865, 13, 407, 472, 295, 264, 721, 300, 28813, 5412, 1751, 445, 1333, 295, 6721, 337, 867, 11, 50752], "temperature": 0.0, "avg_logprob": -0.1199270141458957, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.06185253709554672}, {"id": 160, "seek": 87448, "start": 882.24, "end": 887.6, "text": " many years, and especially people who are thinking about theory, was the nature of time in the brain.", "tokens": [50752, 867, 924, 11, 293, 2318, 561, 567, 366, 1953, 466, 5261, 11, 390, 264, 3687, 295, 565, 294, 264, 3567, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1199270141458957, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.06185253709554672}, {"id": 161, "seek": 87448, "start": 889.04, "end": 893.52, "text": " Brains process information through time. The information coming into the brain is constantly", "tokens": [51092, 4991, 1292, 1399, 1589, 807, 565, 13, 440, 1589, 1348, 666, 264, 3567, 307, 6460, 51316], "temperature": 0.0, "avg_logprob": -0.1199270141458957, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.06185253709554672}, {"id": 162, "seek": 87448, "start": 893.52, "end": 899.28, "text": " changing. The patterns from my speech right now, if you're listening to it at normal speed,", "tokens": [51316, 4473, 13, 440, 8294, 490, 452, 6218, 558, 586, 11, 498, 291, 434, 4764, 281, 309, 412, 2710, 3073, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1199270141458957, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.06185253709554672}, {"id": 163, "seek": 87448, "start": 900.0, "end": 904.0, "text": " would be changing on your ears about every 10 milliseconds or so you'd have it change.", "tokens": [51640, 576, 312, 4473, 322, 428, 8798, 466, 633, 1266, 34184, 420, 370, 291, 1116, 362, 309, 1319, 13, 51840], "temperature": 0.0, "avg_logprob": -0.1199270141458957, "compression_ratio": 1.658273381294964, "no_speech_prob": 0.06185253709554672}, {"id": 164, "seek": 90400, "start": 904.0, "end": 908.16, "text": " This constant flow, when you look at the world, your eyes are moving constantly,", "tokens": [50364, 639, 5754, 3095, 11, 562, 291, 574, 412, 264, 1002, 11, 428, 2575, 366, 2684, 6460, 11, 50572], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 165, "seek": 90400, "start": 908.16, "end": 912.48, "text": " three to five times a second, and the inputs completely. If I were to touch something like", "tokens": [50572, 1045, 281, 1732, 1413, 257, 1150, 11, 293, 264, 15743, 2584, 13, 759, 286, 645, 281, 2557, 746, 411, 50788], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 166, "seek": 90400, "start": 912.48, "end": 917.6, "text": " a coffee cup, as I move my fingers, the inputs change. So this idea that the brain works on", "tokens": [50788, 257, 4982, 4414, 11, 382, 286, 1286, 452, 7350, 11, 264, 15743, 1319, 13, 407, 341, 1558, 300, 264, 3567, 1985, 322, 51044], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 167, "seek": 90400, "start": 917.6, "end": 922.72, "text": " time changing patterns is almost completely or was almost completely missing from a lot of", "tokens": [51044, 565, 4473, 8294, 307, 1920, 2584, 420, 390, 1920, 2584, 5361, 490, 257, 688, 295, 51300], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 168, "seek": 90400, "start": 922.72, "end": 926.48, "text": " the basic theories like fears of vision and so on. It's like, oh, no, we're going to put this", "tokens": [51300, 264, 3875, 13667, 411, 15649, 295, 5201, 293, 370, 322, 13, 467, 311, 411, 11, 1954, 11, 572, 11, 321, 434, 516, 281, 829, 341, 51488], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 169, "seek": 90400, "start": 926.48, "end": 930.88, "text": " image in front of you and flash it and say, what is it? convolutional neural networks work that", "tokens": [51488, 3256, 294, 1868, 295, 291, 293, 7319, 309, 293, 584, 11, 437, 307, 309, 30, 45216, 304, 18161, 9590, 589, 300, 51708], "temperature": 0.0, "avg_logprob": -0.13133928112517623, "compression_ratio": 1.7953795379537953, "no_speech_prob": 0.00010888669203268364}, {"id": 170, "seek": 93088, "start": 930.88, "end": 936.56, "text": " way today, right? Classified this picture. But that's not what vision is like. Vision is this", "tokens": [50364, 636, 965, 11, 558, 30, 9471, 2587, 341, 3036, 13, 583, 300, 311, 406, 437, 5201, 307, 411, 13, 25170, 307, 341, 50648], "temperature": 0.0, "avg_logprob": -0.1264141233343827, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0002868292503990233}, {"id": 171, "seek": 93088, "start": 936.56, "end": 941.68, "text": " sort of crazy time-based pattern that's going all over the place and so is touch and so is hearing.", "tokens": [50648, 1333, 295, 3219, 565, 12, 6032, 5102, 300, 311, 516, 439, 670, 264, 1081, 293, 370, 307, 2557, 293, 370, 307, 4763, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1264141233343827, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0002868292503990233}, {"id": 172, "seek": 93088, "start": 941.68, "end": 946.0, "text": " So the first part of a hierarchical temporal memory was the temporal part. It's to say,", "tokens": [50904, 407, 264, 700, 644, 295, 257, 35250, 804, 30881, 4675, 390, 264, 30881, 644, 13, 467, 311, 281, 584, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1264141233343827, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0002868292503990233}, {"id": 173, "seek": 93088, "start": 946.8, "end": 950.32, "text": " you won't understand the brain, nor will you understand intelligent machines unless you're", "tokens": [51160, 291, 1582, 380, 1223, 264, 3567, 11, 6051, 486, 291, 1223, 13232, 8379, 5969, 291, 434, 51336], "temperature": 0.0, "avg_logprob": -0.1264141233343827, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0002868292503990233}, {"id": 174, "seek": 93088, "start": 950.32, "end": 955.92, "text": " dealing with time-based patterns. The second thing was the memory component of it was, is to say", "tokens": [51336, 6260, 365, 565, 12, 6032, 8294, 13, 440, 1150, 551, 390, 264, 4675, 6542, 295, 309, 390, 11, 307, 281, 584, 51616], "temperature": 0.0, "avg_logprob": -0.1264141233343827, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.0002868292503990233}, {"id": 175, "seek": 95592, "start": 956.64, "end": 964.16, "text": " that we aren't just processing input. We learn a model of the world. And the memory stands for", "tokens": [50400, 300, 321, 3212, 380, 445, 9007, 4846, 13, 492, 1466, 257, 2316, 295, 264, 1002, 13, 400, 264, 4675, 7382, 337, 50776], "temperature": 0.0, "avg_logprob": -0.13108685302734374, "compression_ratio": 1.8991935483870968, "no_speech_prob": 0.0007095997571013868}, {"id": 176, "seek": 95592, "start": 964.16, "end": 968.0799999999999, "text": " that model. We have to, the point of the brain, the part of the neocortex, it learns a model of", "tokens": [50776, 300, 2316, 13, 492, 362, 281, 11, 264, 935, 295, 264, 3567, 11, 264, 644, 295, 264, 408, 905, 36143, 11, 309, 27152, 257, 2316, 295, 50972], "temperature": 0.0, "avg_logprob": -0.13108685302734374, "compression_ratio": 1.8991935483870968, "no_speech_prob": 0.0007095997571013868}, {"id": 177, "seek": 95592, "start": 968.0799999999999, "end": 973.76, "text": " the world. We have to store things that are experiences in a form that leads to a model of", "tokens": [50972, 264, 1002, 13, 492, 362, 281, 3531, 721, 300, 366, 5235, 294, 257, 1254, 300, 6689, 281, 257, 2316, 295, 51256], "temperature": 0.0, "avg_logprob": -0.13108685302734374, "compression_ratio": 1.8991935483870968, "no_speech_prob": 0.0007095997571013868}, {"id": 178, "seek": 95592, "start": 973.76, "end": 977.28, "text": " the world. So we can move around the world. We can pick things up and do things and navigate and", "tokens": [51256, 264, 1002, 13, 407, 321, 393, 1286, 926, 264, 1002, 13, 492, 393, 1888, 721, 493, 293, 360, 721, 293, 12350, 293, 51432], "temperature": 0.0, "avg_logprob": -0.13108685302734374, "compression_ratio": 1.8991935483870968, "no_speech_prob": 0.0007095997571013868}, {"id": 179, "seek": 95592, "start": 977.28, "end": 980.9599999999999, "text": " know how it's going on. So that's, that's what the memory referred to. And many people just,", "tokens": [51432, 458, 577, 309, 311, 516, 322, 13, 407, 300, 311, 11, 300, 311, 437, 264, 4675, 10839, 281, 13, 400, 867, 561, 445, 11, 51616], "temperature": 0.0, "avg_logprob": -0.13108685302734374, "compression_ratio": 1.8991935483870968, "no_speech_prob": 0.0007095997571013868}, {"id": 180, "seek": 98096, "start": 980.96, "end": 986.1600000000001, "text": " they were thinking about like certain processes without memory at all. They're just like processing", "tokens": [50364, 436, 645, 1953, 466, 411, 1629, 7555, 1553, 4675, 412, 439, 13, 814, 434, 445, 411, 9007, 50624], "temperature": 0.0, "avg_logprob": -0.08477084141857219, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.0005883215926587582}, {"id": 181, "seek": 98096, "start": 986.1600000000001, "end": 992.1600000000001, "text": " things. And then finally, the hierarchical component was a reflection to that the neocortex,", "tokens": [50624, 721, 13, 400, 550, 2721, 11, 264, 35250, 804, 6542, 390, 257, 12914, 281, 300, 264, 408, 905, 36143, 11, 50924], "temperature": 0.0, "avg_logprob": -0.08477084141857219, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.0005883215926587582}, {"id": 182, "seek": 98096, "start": 992.1600000000001, "end": 997.52, "text": " although it's just a uniform sheet of cells, different parts of it project to other parts,", "tokens": [50924, 4878, 309, 311, 445, 257, 9452, 8193, 295, 5438, 11, 819, 3166, 295, 309, 1716, 281, 661, 3166, 11, 51192], "temperature": 0.0, "avg_logprob": -0.08477084141857219, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.0005883215926587582}, {"id": 183, "seek": 98096, "start": 997.52, "end": 1003.2, "text": " which project to other parts. And there is a sort of rough hierarchy in terms of that. So", "tokens": [51192, 597, 1716, 281, 661, 3166, 13, 400, 456, 307, 257, 1333, 295, 5903, 22333, 294, 2115, 295, 300, 13, 407, 51476], "temperature": 0.0, "avg_logprob": -0.08477084141857219, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.0005883215926587582}, {"id": 184, "seek": 98096, "start": 1003.84, "end": 1007.76, "text": " the hierarchical temporal memory is just saying, look, we should be thinking about the brain", "tokens": [51508, 264, 35250, 804, 30881, 4675, 307, 445, 1566, 11, 574, 11, 321, 820, 312, 1953, 466, 264, 3567, 51704], "temperature": 0.0, "avg_logprob": -0.08477084141857219, "compression_ratio": 1.806201550387597, "no_speech_prob": 0.0005883215926587582}, {"id": 185, "seek": 100776, "start": 1007.76, "end": 1016.16, "text": " as time-based, you know, model memory-based and hierarchical processing. And, and that was a", "tokens": [50364, 382, 565, 12, 6032, 11, 291, 458, 11, 2316, 4675, 12, 6032, 293, 35250, 804, 9007, 13, 400, 11, 293, 300, 390, 257, 50784], "temperature": 0.0, "avg_logprob": -0.08740358517087739, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.00010888463293667883}, {"id": 186, "seek": 100776, "start": 1016.16, "end": 1021.68, "text": " placeholder for a bunch of components that we would then plug into that. We still believe all", "tokens": [50784, 1081, 20480, 337, 257, 3840, 295, 6677, 300, 321, 576, 550, 5452, 666, 300, 13, 492, 920, 1697, 439, 51060], "temperature": 0.0, "avg_logprob": -0.08740358517087739, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.00010888463293667883}, {"id": 187, "seek": 100776, "start": 1021.68, "end": 1027.12, "text": " those things I just said, but we now know so much more that I'm stopping to use the word", "tokens": [51060, 729, 721, 286, 445, 848, 11, 457, 321, 586, 458, 370, 709, 544, 300, 286, 478, 12767, 281, 764, 264, 1349, 51332], "temperature": 0.0, "avg_logprob": -0.08740358517087739, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.00010888463293667883}, {"id": 188, "seek": 100776, "start": 1027.12, "end": 1031.44, "text": " hierarchical temporal memory yet because it's insufficient to capture the stuff we know. So", "tokens": [51332, 35250, 804, 30881, 4675, 1939, 570, 309, 311, 41709, 281, 7983, 264, 1507, 321, 458, 13, 407, 51548], "temperature": 0.0, "avg_logprob": -0.08740358517087739, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.00010888463293667883}, {"id": 189, "seek": 100776, "start": 1031.44, "end": 1036.8, "text": " again, it's not incorrect, but it's, I now know more and I would rather describe it more accurately.", "tokens": [51548, 797, 11, 309, 311, 406, 18424, 11, 457, 309, 311, 11, 286, 586, 458, 544, 293, 286, 576, 2831, 6786, 309, 544, 20095, 13, 51816], "temperature": 0.0, "avg_logprob": -0.08740358517087739, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.00010888463293667883}, {"id": 190, "seek": 103680, "start": 1036.8, "end": 1042.8799999999999, "text": " Yeah. So you're basically, we could think of HTM as emphasizing that there's three aspects", "tokens": [50364, 865, 13, 407, 291, 434, 1936, 11, 321, 727, 519, 295, 11751, 44, 382, 45550, 300, 456, 311, 1045, 7270, 50668], "temperature": 0.0, "avg_logprob": -0.17491947030121424, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0004953101160936058}, {"id": 191, "seek": 103680, "start": 1043.52, "end": 1047.68, "text": " of intelligence that are important to think about whatever the, whatever the eventual theory", "tokens": [50700, 295, 7599, 300, 366, 1021, 281, 519, 466, 2035, 264, 11, 2035, 264, 33160, 5261, 50908], "temperature": 0.0, "avg_logprob": -0.17491947030121424, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0004953101160936058}, {"id": 192, "seek": 103680, "start": 1047.68, "end": 1053.76, "text": " converges to. So in terms of time, how do you think of nature of time across different timescales?", "tokens": [50908, 9652, 2880, 281, 13, 407, 294, 2115, 295, 565, 11, 577, 360, 291, 519, 295, 3687, 295, 565, 2108, 819, 1413, 66, 4229, 30, 51212], "temperature": 0.0, "avg_logprob": -0.17491947030121424, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0004953101160936058}, {"id": 193, "seek": 103680, "start": 1053.76, "end": 1059.6, "text": " So you mentioned things changing, sensory inputs changing every 10, 20 minutes. What about", "tokens": [51212, 407, 291, 2835, 721, 4473, 11, 27233, 15743, 4473, 633, 1266, 11, 945, 2077, 13, 708, 466, 51504], "temperature": 0.0, "avg_logprob": -0.17491947030121424, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0004953101160936058}, {"id": 194, "seek": 103680, "start": 1059.6, "end": 1063.84, "text": " every few minutes, every few months and years? Well, if you think about a neuroscience", "tokens": [51504, 633, 1326, 2077, 11, 633, 1326, 2493, 293, 924, 30, 1042, 11, 498, 291, 519, 466, 257, 42762, 51716], "temperature": 0.0, "avg_logprob": -0.17491947030121424, "compression_ratio": 1.7100371747211895, "no_speech_prob": 0.0004953101160936058}, {"id": 195, "seek": 106384, "start": 1064.32, "end": 1071.4399999999998, "text": " problem, the brain problem, neurons themselves can stay active for certain parts of time.", "tokens": [50388, 1154, 11, 264, 3567, 1154, 11, 22027, 2969, 393, 1754, 4967, 337, 1629, 3166, 295, 565, 13, 50744], "temperature": 0.0, "avg_logprob": -0.14930381774902343, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.0005527126486413181}, {"id": 196, "seek": 106384, "start": 1071.4399999999998, "end": 1074.1599999999999, "text": " They can, they're parts of the brain where they stay active for minutes, you know,", "tokens": [50744, 814, 393, 11, 436, 434, 3166, 295, 264, 3567, 689, 436, 1754, 4967, 337, 2077, 11, 291, 458, 11, 50880], "temperature": 0.0, "avg_logprob": -0.14930381774902343, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.0005527126486413181}, {"id": 197, "seek": 106384, "start": 1074.1599999999999, "end": 1082.32, "text": " so you could hold a certain perception or activity for a certain part of time, but not,", "tokens": [50880, 370, 291, 727, 1797, 257, 1629, 12860, 420, 5191, 337, 257, 1629, 644, 295, 565, 11, 457, 406, 11, 51288], "temperature": 0.0, "avg_logprob": -0.14930381774902343, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.0005527126486413181}, {"id": 198, "seek": 106384, "start": 1082.32, "end": 1088.9599999999998, "text": " most of them don't last that long. And so if you think about your thoughts or the activity neurons,", "tokens": [51288, 881, 295, 552, 500, 380, 1036, 300, 938, 13, 400, 370, 498, 291, 519, 466, 428, 4598, 420, 264, 5191, 22027, 11, 51620], "temperature": 0.0, "avg_logprob": -0.14930381774902343, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.0005527126486413181}, {"id": 199, "seek": 106384, "start": 1088.9599999999998, "end": 1092.8799999999999, "text": " if you're going to want to involve something that happened a long time ago, even just this morning,", "tokens": [51620, 498, 291, 434, 516, 281, 528, 281, 9494, 746, 300, 2011, 257, 938, 565, 2057, 11, 754, 445, 341, 2446, 11, 51816], "temperature": 0.0, "avg_logprob": -0.14930381774902343, "compression_ratio": 1.8253968253968254, "no_speech_prob": 0.0005527126486413181}, {"id": 200, "seek": 109288, "start": 1092.88, "end": 1097.6000000000001, "text": " for example, the neurons haven't been active throughout that time. So you have to store that.", "tokens": [50364, 337, 1365, 11, 264, 22027, 2378, 380, 668, 4967, 3710, 300, 565, 13, 407, 291, 362, 281, 3531, 300, 13, 50600], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 201, "seek": 109288, "start": 1097.6000000000001, "end": 1102.3200000000002, "text": " So if I ask you, what did you have for breakfast today? That is memory. That is,", "tokens": [50600, 407, 498, 286, 1029, 291, 11, 437, 630, 291, 362, 337, 8201, 965, 30, 663, 307, 4675, 13, 663, 307, 11, 50836], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 202, "seek": 109288, "start": 1102.3200000000002, "end": 1105.8400000000001, "text": " you've built that into your model of the world now, you remember that. And that memory is in the", "tokens": [50836, 291, 600, 3094, 300, 666, 428, 2316, 295, 264, 1002, 586, 11, 291, 1604, 300, 13, 400, 300, 4675, 307, 294, 264, 51012], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 203, "seek": 109288, "start": 1107.1200000000001, "end": 1114.64, "text": " synapses, it's basically in the formation of synapses. And so it's, you're sliding into what,", "tokens": [51076, 5451, 2382, 279, 11, 309, 311, 1936, 294, 264, 11723, 295, 5451, 2382, 279, 13, 400, 370, 309, 311, 11, 291, 434, 21169, 666, 437, 11, 51452], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 204, "seek": 109288, "start": 1114.64, "end": 1118.5600000000002, "text": " you know, used to different timescales. There's timescales of which we are like", "tokens": [51452, 291, 458, 11, 1143, 281, 819, 1413, 66, 4229, 13, 821, 311, 1413, 66, 4229, 295, 597, 321, 366, 411, 51648], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 205, "seek": 109288, "start": 1118.5600000000002, "end": 1122.0800000000002, "text": " understanding my language and moving about and seeing things rapidly and over time. That's the", "tokens": [51648, 3701, 452, 2856, 293, 2684, 466, 293, 2577, 721, 12910, 293, 670, 565, 13, 663, 311, 264, 51824], "temperature": 0.0, "avg_logprob": -0.13176042011805944, "compression_ratio": 1.7880794701986755, "no_speech_prob": 0.00034591578878462315}, {"id": 206, "seek": 112208, "start": 1122.08, "end": 1126.6399999999999, "text": " timescales of activities of neurons. But if you want to get in longer timescales, then it's more", "tokens": [50364, 1413, 66, 4229, 295, 5354, 295, 22027, 13, 583, 498, 291, 528, 281, 483, 294, 2854, 1413, 66, 4229, 11, 550, 309, 311, 544, 50592], "temperature": 0.0, "avg_logprob": -0.1331661574694575, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.00021652971918229014}, {"id": 207, "seek": 112208, "start": 1126.6399999999999, "end": 1130.96, "text": " memory. And we have to invoke those memories to say, Oh, yes, well, now I can remember what", "tokens": [50592, 4675, 13, 400, 321, 362, 281, 41117, 729, 8495, 281, 584, 11, 876, 11, 2086, 11, 731, 11, 586, 286, 393, 1604, 437, 50808], "temperature": 0.0, "avg_logprob": -0.1331661574694575, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.00021652971918229014}, {"id": 208, "seek": 112208, "start": 1130.96, "end": 1137.4399999999998, "text": " I had for breakfast because I stored that someplace. I may forget it tomorrow, but I'd store it for", "tokens": [50808, 286, 632, 337, 8201, 570, 286, 12187, 300, 37126, 13, 286, 815, 2870, 309, 4153, 11, 457, 286, 1116, 3531, 309, 337, 51132], "temperature": 0.0, "avg_logprob": -0.1331661574694575, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.00021652971918229014}, {"id": 209, "seek": 112208, "start": 1137.4399999999998, "end": 1147.04, "text": " now. So this memory also need to have the hierarchical aspect of reality is not just about", "tokens": [51132, 586, 13, 407, 341, 4675, 611, 643, 281, 362, 264, 35250, 804, 4171, 295, 4103, 307, 406, 445, 466, 51612], "temperature": 0.0, "avg_logprob": -0.1331661574694575, "compression_ratio": 1.5726141078838174, "no_speech_prob": 0.00021652971918229014}, {"id": 210, "seek": 114704, "start": 1147.04, "end": 1149.6, "text": " concepts, it's also about time. Do you think of it that way?", "tokens": [50364, 10392, 11, 309, 311, 611, 466, 565, 13, 1144, 291, 519, 295, 309, 300, 636, 30, 50492], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 211, "seek": 114704, "start": 1149.6, "end": 1154.56, "text": " Uh, yeah, time is infused in everything. It's like, you really can't separate it out.", "tokens": [50492, 4019, 11, 1338, 11, 565, 307, 50083, 294, 1203, 13, 467, 311, 411, 11, 291, 534, 393, 380, 4994, 309, 484, 13, 50740], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 212, "seek": 114704, "start": 1155.44, "end": 1160.8, "text": " If I ask you, what is the, what is your, you know, how's the brain learn a model of this coffee cup", "tokens": [50784, 759, 286, 1029, 291, 11, 437, 307, 264, 11, 437, 307, 428, 11, 291, 458, 11, 577, 311, 264, 3567, 1466, 257, 2316, 295, 341, 4982, 4414, 51052], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 213, "seek": 114704, "start": 1160.8, "end": 1165.44, "text": " here? I have a coffee cup and then I met the coffee cup. I said, well, time is not an inherent", "tokens": [51052, 510, 30, 286, 362, 257, 4982, 4414, 293, 550, 286, 1131, 264, 4982, 4414, 13, 286, 848, 11, 731, 11, 565, 307, 406, 364, 26387, 51284], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 214, "seek": 114704, "start": 1165.44, "end": 1169.52, "text": " property of this, of this, of the model I have with this cup, whether it's a visual model or", "tokens": [51284, 4707, 295, 341, 11, 295, 341, 11, 295, 264, 2316, 286, 362, 365, 341, 4414, 11, 1968, 309, 311, 257, 5056, 2316, 420, 51488], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 215, "seek": 114704, "start": 1169.52, "end": 1174.8, "text": " tactile model. I can sense it through time, but the model itself doesn't really have much time.", "tokens": [51488, 47319, 2316, 13, 286, 393, 2020, 309, 807, 565, 11, 457, 264, 2316, 2564, 1177, 380, 534, 362, 709, 565, 13, 51752], "temperature": 0.0, "avg_logprob": -0.14705249425527211, "compression_ratio": 1.8213058419243986, "no_speech_prob": 0.05029868707060814}, {"id": 216, "seek": 117480, "start": 1174.8, "end": 1178.0, "text": " If I asked you, if I said, well, what is the model of my cell phone?", "tokens": [50364, 759, 286, 2351, 291, 11, 498, 286, 848, 11, 731, 11, 437, 307, 264, 2316, 295, 452, 2815, 2593, 30, 50524], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 217, "seek": 117480, "start": 1178.8799999999999, "end": 1183.36, "text": " My brain has learned a model of the cell phones. If you have a smartphone like this.", "tokens": [50568, 1222, 3567, 575, 3264, 257, 2316, 295, 264, 2815, 10216, 13, 759, 291, 362, 257, 13307, 411, 341, 13, 50792], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 218, "seek": 117480, "start": 1183.36, "end": 1187.9199999999998, "text": " And I said, well, this has time aspects to it. I have expectations when I turn it on,", "tokens": [50792, 400, 286, 848, 11, 731, 11, 341, 575, 565, 7270, 281, 309, 13, 286, 362, 9843, 562, 286, 1261, 309, 322, 11, 51020], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 219, "seek": 117480, "start": 1187.9199999999998, "end": 1191.2, "text": " what's going to happen, what water, how long it's going to take to do certain things.", "tokens": [51020, 437, 311, 516, 281, 1051, 11, 437, 1281, 11, 577, 938, 309, 311, 516, 281, 747, 281, 360, 1629, 721, 13, 51184], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 220, "seek": 117480, "start": 1191.76, "end": 1196.3999999999999, "text": " If I bring up an app, what sequences. And so I have instant, it's like melodies in the world,", "tokens": [51212, 759, 286, 1565, 493, 364, 724, 11, 437, 22978, 13, 400, 370, 286, 362, 9836, 11, 309, 311, 411, 47085, 294, 264, 1002, 11, 51444], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 221, "seek": 117480, "start": 1196.3999999999999, "end": 1201.44, "text": " you know, melody has a sense of time. So many things in the world move and act, and there's", "tokens": [51444, 291, 458, 11, 17997, 575, 257, 2020, 295, 565, 13, 407, 867, 721, 294, 264, 1002, 1286, 293, 605, 11, 293, 456, 311, 51696], "temperature": 0.0, "avg_logprob": -0.13492919014884042, "compression_ratio": 1.8185053380782918, "no_speech_prob": 0.00030531585798598826}, {"id": 222, "seek": 120144, "start": 1201.44, "end": 1210.16, "text": " a sense of time related to them. Some don't, but most things do actually. So it's sort of infused", "tokens": [50364, 257, 2020, 295, 565, 4077, 281, 552, 13, 2188, 500, 380, 11, 457, 881, 721, 360, 767, 13, 407, 309, 311, 1333, 295, 50083, 50800], "temperature": 0.0, "avg_logprob": -0.11951974097718583, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0010646048467606306}, {"id": 223, "seek": 120144, "start": 1210.16, "end": 1214.56, "text": " throughout the models of the world. You build a model of the world, you're learning the structure", "tokens": [50800, 3710, 264, 5245, 295, 264, 1002, 13, 509, 1322, 257, 2316, 295, 264, 1002, 11, 291, 434, 2539, 264, 3877, 51020], "temperature": 0.0, "avg_logprob": -0.11951974097718583, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0010646048467606306}, {"id": 224, "seek": 120144, "start": 1214.56, "end": 1219.44, "text": " of the objects in the world, and you're also learning how those things change through time.", "tokens": [51020, 295, 264, 6565, 294, 264, 1002, 11, 293, 291, 434, 611, 2539, 577, 729, 721, 1319, 807, 565, 13, 51264], "temperature": 0.0, "avg_logprob": -0.11951974097718583, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0010646048467606306}, {"id": 225, "seek": 120144, "start": 1220.64, "end": 1226.0800000000002, "text": " Okay, so it's, it really is just a fourth dimension that's infused deeply. And you have", "tokens": [51324, 1033, 11, 370, 309, 311, 11, 309, 534, 307, 445, 257, 6409, 10139, 300, 311, 50083, 8760, 13, 400, 291, 362, 51596], "temperature": 0.0, "avg_logprob": -0.11951974097718583, "compression_ratio": 1.6968325791855203, "no_speech_prob": 0.0010646048467606306}, {"id": 226, "seek": 122608, "start": 1226.08, "end": 1231.12, "text": " to make sure that your models of an intelligence incorporated. So", "tokens": [50364, 281, 652, 988, 300, 428, 5245, 295, 364, 7599, 21654, 13, 407, 50616], "temperature": 0.0, "avg_logprob": -0.12855073383876256, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.004902923014014959}, {"id": 227, "seek": 122608, "start": 1233.04, "end": 1236.96, "text": " like you mentioned, the state of neuroscience is deeply empirical, a lot of data collection.", "tokens": [50712, 411, 291, 2835, 11, 264, 1785, 295, 42762, 307, 8760, 31886, 11, 257, 688, 295, 1412, 5765, 13, 50908], "temperature": 0.0, "avg_logprob": -0.12855073383876256, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.004902923014014959}, {"id": 228, "seek": 122608, "start": 1237.6799999999998, "end": 1242.96, "text": " It's, you know, that's, that's where it is. You mentioned Thomas Kuhn, right?", "tokens": [50944, 467, 311, 11, 291, 458, 11, 300, 311, 11, 300, 311, 689, 309, 307, 13, 509, 2835, 8500, 591, 3232, 77, 11, 558, 30, 51208], "temperature": 0.0, "avg_logprob": -0.12855073383876256, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.004902923014014959}, {"id": 229, "seek": 122608, "start": 1242.96, "end": 1250.3999999999999, "text": " Yeah. And then you're proposing a theory of intelligence, and which is really the next step,", "tokens": [51208, 865, 13, 400, 550, 291, 434, 29939, 257, 5261, 295, 7599, 11, 293, 597, 307, 534, 264, 958, 1823, 11, 51580], "temperature": 0.0, "avg_logprob": -0.12855073383876256, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.004902923014014959}, {"id": 230, "seek": 125040, "start": 1250.4, "end": 1259.52, "text": " the really important step to take. But why, why is HTM or what we'll talk about soon,", "tokens": [50364, 264, 534, 1021, 1823, 281, 747, 13, 583, 983, 11, 983, 307, 11751, 44, 420, 437, 321, 603, 751, 466, 2321, 11, 50820], "temperature": 0.0, "avg_logprob": -0.1291677983601888, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.013015064410865307}, {"id": 231, "seek": 125040, "start": 1260.88, "end": 1268.48, "text": " the right theory? So is it more in this? Is it backed by intuition? Is it backed by", "tokens": [50888, 264, 558, 5261, 30, 407, 307, 309, 544, 294, 341, 30, 1119, 309, 20391, 538, 24002, 30, 1119, 309, 20391, 538, 51268], "temperature": 0.0, "avg_logprob": -0.1291677983601888, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.013015064410865307}, {"id": 232, "seek": 125040, "start": 1269.3600000000001, "end": 1274.96, "text": " evidence? Is it backed by a mixture of both? Is it kind of closer to where string theory is in physics,", "tokens": [51312, 4467, 30, 1119, 309, 20391, 538, 257, 9925, 295, 1293, 30, 1119, 309, 733, 295, 4966, 281, 689, 6798, 5261, 307, 294, 10649, 11, 51592], "temperature": 0.0, "avg_logprob": -0.1291677983601888, "compression_ratio": 1.5511363636363635, "no_speech_prob": 0.013015064410865307}, {"id": 233, "seek": 127496, "start": 1275.52, "end": 1282.24, "text": " where there's mathematical components which show that, you know what, it seems that this,", "tokens": [50392, 689, 456, 311, 18894, 6677, 597, 855, 300, 11, 291, 458, 437, 11, 309, 2544, 300, 341, 11, 50728], "temperature": 0.0, "avg_logprob": -0.14048807499772412, "compression_ratio": 1.7518518518518518, "no_speech_prob": 0.0009398602414876223}, {"id": 234, "seek": 127496, "start": 1282.88, "end": 1288.48, "text": " it fits together too well for it not to be true, which is what where string theory is. Is that", "tokens": [50760, 309, 9001, 1214, 886, 731, 337, 309, 406, 281, 312, 2074, 11, 597, 307, 437, 689, 6798, 5261, 307, 13, 1119, 300, 51040], "temperature": 0.0, "avg_logprob": -0.14048807499772412, "compression_ratio": 1.7518518518518518, "no_speech_prob": 0.0009398602414876223}, {"id": 235, "seek": 127496, "start": 1288.48, "end": 1293.04, "text": " where it's a mix of all those things, although definitely where we are right now, it's definitely", "tokens": [51040, 689, 309, 311, 257, 2890, 295, 439, 729, 721, 11, 4878, 2138, 689, 321, 366, 558, 586, 11, 309, 311, 2138, 51268], "temperature": 0.0, "avg_logprob": -0.14048807499772412, "compression_ratio": 1.7518518518518518, "no_speech_prob": 0.0009398602414876223}, {"id": 236, "seek": 127496, "start": 1293.04, "end": 1298.32, "text": " much more on the empirical side than let's say string theory. The way this goes about, we're", "tokens": [51268, 709, 544, 322, 264, 31886, 1252, 813, 718, 311, 584, 6798, 5261, 13, 440, 636, 341, 1709, 466, 11, 321, 434, 51532], "temperature": 0.0, "avg_logprob": -0.14048807499772412, "compression_ratio": 1.7518518518518518, "no_speech_prob": 0.0009398602414876223}, {"id": 237, "seek": 127496, "start": 1298.32, "end": 1302.32, "text": " theorists, right? So we look at all this data and we're trying to come up with some sort of model", "tokens": [51532, 27423, 1751, 11, 558, 30, 407, 321, 574, 412, 439, 341, 1412, 293, 321, 434, 1382, 281, 808, 493, 365, 512, 1333, 295, 2316, 51732], "temperature": 0.0, "avg_logprob": -0.14048807499772412, "compression_ratio": 1.7518518518518518, "no_speech_prob": 0.0009398602414876223}, {"id": 238, "seek": 130232, "start": 1302.3999999999999, "end": 1308.48, "text": " that explains it, basically. And there's a, unlike string theory, there's this vast more", "tokens": [50368, 300, 13948, 309, 11, 1936, 13, 400, 456, 311, 257, 11, 8343, 6798, 5261, 11, 456, 311, 341, 8369, 544, 50672], "temperature": 0.0, "avg_logprob": -0.14427376797324734, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0005357287591323256}, {"id": 239, "seek": 130232, "start": 1308.48, "end": 1316.56, "text": " amounts of empirical data here that I think that most physicists deal with. And so our challenge", "tokens": [50672, 11663, 295, 31886, 1412, 510, 300, 286, 519, 300, 881, 48716, 2028, 365, 13, 400, 370, 527, 3430, 51076], "temperature": 0.0, "avg_logprob": -0.14427376797324734, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0005357287591323256}, {"id": 240, "seek": 130232, "start": 1316.56, "end": 1323.36, "text": " is to sort through that and figure out what kind of constructs would explain this. And when we have", "tokens": [51076, 307, 281, 1333, 807, 300, 293, 2573, 484, 437, 733, 295, 7690, 82, 576, 2903, 341, 13, 400, 562, 321, 362, 51416], "temperature": 0.0, "avg_logprob": -0.14427376797324734, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0005357287591323256}, {"id": 241, "seek": 130232, "start": 1323.36, "end": 1329.2, "text": " an idea, you come up with a theory of some sort, you have lots of ways of testing it. First of all,", "tokens": [51416, 364, 1558, 11, 291, 808, 493, 365, 257, 5261, 295, 512, 1333, 11, 291, 362, 3195, 295, 2098, 295, 4997, 309, 13, 2386, 295, 439, 11, 51708], "temperature": 0.0, "avg_logprob": -0.14427376797324734, "compression_ratio": 1.6594827586206897, "no_speech_prob": 0.0005357287591323256}, {"id": 242, "seek": 132920, "start": 1329.92, "end": 1336.56, "text": " I am, you know, there are 100 years of assimilated, undesimulated empirical data from neuroscience.", "tokens": [50400, 286, 669, 11, 291, 458, 11, 456, 366, 2319, 924, 295, 8249, 45678, 11, 674, 279, 332, 6987, 31886, 1412, 490, 42762, 13, 50732], "temperature": 0.0, "avg_logprob": -0.13912138762297455, "compression_ratio": 1.6620689655172414, "no_speech_prob": 0.00021653869771398604}, {"id": 243, "seek": 132920, "start": 1336.56, "end": 1341.8400000000001, "text": " So we go back and read papers and we say, oh, did someone find this already? We can predict X,", "tokens": [50732, 407, 321, 352, 646, 293, 1401, 10577, 293, 321, 584, 11, 1954, 11, 630, 1580, 915, 341, 1217, 30, 492, 393, 6069, 1783, 11, 50996], "temperature": 0.0, "avg_logprob": -0.13912138762297455, "compression_ratio": 1.6620689655172414, "no_speech_prob": 0.00021653869771398604}, {"id": 244, "seek": 132920, "start": 1341.8400000000001, "end": 1347.68, "text": " Y, and Z. And maybe no one's even talked about it since 1972 or something, but we go back and", "tokens": [50996, 398, 11, 293, 1176, 13, 400, 1310, 572, 472, 311, 754, 2825, 466, 309, 1670, 32952, 420, 746, 11, 457, 321, 352, 646, 293, 51288], "temperature": 0.0, "avg_logprob": -0.13912138762297455, "compression_ratio": 1.6620689655172414, "no_speech_prob": 0.00021653869771398604}, {"id": 245, "seek": 132920, "start": 1347.68, "end": 1353.44, "text": " find that. And we say, oh, either it can support the theory or it can invalidate the theory. And", "tokens": [51288, 915, 300, 13, 400, 321, 584, 11, 1954, 11, 2139, 309, 393, 1406, 264, 5261, 420, 309, 393, 34702, 473, 264, 5261, 13, 400, 51576], "temperature": 0.0, "avg_logprob": -0.13912138762297455, "compression_ratio": 1.6620689655172414, "no_speech_prob": 0.00021653869771398604}, {"id": 246, "seek": 132920, "start": 1353.44, "end": 1356.88, "text": " we say, okay, we have to start over again. Oh, no, it's support. Let's keep going with that one.", "tokens": [51576, 321, 584, 11, 1392, 11, 321, 362, 281, 722, 670, 797, 13, 876, 11, 572, 11, 309, 311, 1406, 13, 961, 311, 1066, 516, 365, 300, 472, 13, 51748], "temperature": 0.0, "avg_logprob": -0.13912138762297455, "compression_ratio": 1.6620689655172414, "no_speech_prob": 0.00021653869771398604}, {"id": 247, "seek": 135688, "start": 1357.8400000000001, "end": 1365.2800000000002, "text": " So the way I kind of view it, when we do our work, we come up, we look at all this empirical data,", "tokens": [50412, 407, 264, 636, 286, 733, 295, 1910, 309, 11, 562, 321, 360, 527, 589, 11, 321, 808, 493, 11, 321, 574, 412, 439, 341, 31886, 1412, 11, 50784], "temperature": 0.0, "avg_logprob": -0.11691850026448568, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00021652926807291806}, {"id": 248, "seek": 135688, "start": 1365.2800000000002, "end": 1368.64, "text": " and it's what I call it as a set of constraints. We're not interested in something that's", "tokens": [50784, 293, 309, 311, 437, 286, 818, 309, 382, 257, 992, 295, 18491, 13, 492, 434, 406, 3102, 294, 746, 300, 311, 50952], "temperature": 0.0, "avg_logprob": -0.11691850026448568, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00021652926807291806}, {"id": 249, "seek": 135688, "start": 1368.64, "end": 1372.72, "text": " biologically inspired. We're trying to figure out how the actual brain works. So every piece", "tokens": [50952, 3228, 17157, 7547, 13, 492, 434, 1382, 281, 2573, 484, 577, 264, 3539, 3567, 1985, 13, 407, 633, 2522, 51156], "temperature": 0.0, "avg_logprob": -0.11691850026448568, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00021652926807291806}, {"id": 250, "seek": 135688, "start": 1372.72, "end": 1376.88, "text": " of empirical data is a constraint on a theory. In theory, if you have the correct theory,", "tokens": [51156, 295, 31886, 1412, 307, 257, 25534, 322, 257, 5261, 13, 682, 5261, 11, 498, 291, 362, 264, 3006, 5261, 11, 51364], "temperature": 0.0, "avg_logprob": -0.11691850026448568, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00021652926807291806}, {"id": 251, "seek": 135688, "start": 1376.88, "end": 1382.96, "text": " it needs to explain every pin, right? So we have this huge number of constraints on the problem,", "tokens": [51364, 309, 2203, 281, 2903, 633, 5447, 11, 558, 30, 407, 321, 362, 341, 2603, 1230, 295, 18491, 322, 264, 1154, 11, 51668], "temperature": 0.0, "avg_logprob": -0.11691850026448568, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.00021652926807291806}, {"id": 252, "seek": 138296, "start": 1383.04, "end": 1387.1200000000001, "text": " which initially makes it very, very difficult. If you don't have many constraints,", "tokens": [50368, 597, 9105, 1669, 309, 588, 11, 588, 2252, 13, 759, 291, 500, 380, 362, 867, 18491, 11, 50572], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 253, "seek": 138296, "start": 1387.1200000000001, "end": 1390.08, "text": " you can make up stuff all the day. You can say, oh, here's an answer. How you can do this,", "tokens": [50572, 291, 393, 652, 493, 1507, 439, 264, 786, 13, 509, 393, 584, 11, 1954, 11, 510, 311, 364, 1867, 13, 1012, 291, 393, 360, 341, 11, 50720], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 254, "seek": 138296, "start": 1390.08, "end": 1393.68, "text": " you can do that, you can do this. But if you consider all biology as a set of constraints,", "tokens": [50720, 291, 393, 360, 300, 11, 291, 393, 360, 341, 13, 583, 498, 291, 1949, 439, 14956, 382, 257, 992, 295, 18491, 11, 50900], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 255, "seek": 138296, "start": 1393.68, "end": 1397.2, "text": " all neuroscience, a set of constraints, and even if you're working in one little part of", "tokens": [50900, 439, 42762, 11, 257, 992, 295, 18491, 11, 293, 754, 498, 291, 434, 1364, 294, 472, 707, 644, 295, 51076], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 256, "seek": 138296, "start": 1397.2, "end": 1401.28, "text": " the Neocortex, for example, there are hundreds and hundreds of constraints, these are empirical", "tokens": [51076, 264, 1734, 905, 36143, 11, 337, 1365, 11, 456, 366, 6779, 293, 6779, 295, 18491, 11, 613, 366, 31886, 51280], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 257, "seek": 138296, "start": 1401.28, "end": 1406.88, "text": " constraints, that it's very, very difficult initially to come up with a theoretical framework", "tokens": [51280, 18491, 11, 300, 309, 311, 588, 11, 588, 2252, 9105, 281, 808, 493, 365, 257, 20864, 8388, 51560], "temperature": 0.0, "avg_logprob": -0.08973565742151061, "compression_ratio": 1.946236559139785, "no_speech_prob": 0.0011334838345646858}, {"id": 258, "seek": 140688, "start": 1406.88, "end": 1412.88, "text": " for that. But when you do, and it solves all those constraints at once, you have a high confidence", "tokens": [50364, 337, 300, 13, 583, 562, 291, 360, 11, 293, 309, 39890, 439, 729, 18491, 412, 1564, 11, 291, 362, 257, 1090, 6687, 50664], "temperature": 0.0, "avg_logprob": -0.07797264534494151, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.04083074629306793}, {"id": 259, "seek": 140688, "start": 1412.88, "end": 1418.5600000000002, "text": " that you got something close to correct. It's just mathematically almost impossible not to be.", "tokens": [50664, 300, 291, 658, 746, 1998, 281, 3006, 13, 467, 311, 445, 44003, 1920, 6243, 406, 281, 312, 13, 50948], "temperature": 0.0, "avg_logprob": -0.07797264534494151, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.04083074629306793}, {"id": 260, "seek": 140688, "start": 1419.1200000000001, "end": 1426.8000000000002, "text": " So that's the curse and the advantage of what we have. The curse is we have to meet all these", "tokens": [50976, 407, 300, 311, 264, 17139, 293, 264, 5002, 295, 437, 321, 362, 13, 440, 17139, 307, 321, 362, 281, 1677, 439, 613, 51360], "temperature": 0.0, "avg_logprob": -0.07797264534494151, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.04083074629306793}, {"id": 261, "seek": 140688, "start": 1426.8000000000002, "end": 1433.1200000000001, "text": " constraints, which is really hard. But when you do meet them, then you have a great confidence", "tokens": [51360, 18491, 11, 597, 307, 534, 1152, 13, 583, 562, 291, 360, 1677, 552, 11, 550, 291, 362, 257, 869, 6687, 51676], "temperature": 0.0, "avg_logprob": -0.07797264534494151, "compression_ratio": 1.7363636363636363, "no_speech_prob": 0.04083074629306793}, {"id": 262, "seek": 143312, "start": 1433.12, "end": 1438.6399999999999, "text": " that you've discovered something. In addition, then we work with scientific labs. So we'll say,", "tokens": [50364, 300, 291, 600, 6941, 746, 13, 682, 4500, 11, 550, 321, 589, 365, 8134, 20339, 13, 407, 321, 603, 584, 11, 50640], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 263, "seek": 143312, "start": 1438.6399999999999, "end": 1443.1999999999998, "text": " oh, there's something we can't find, we can predict something, but we can't find it anywhere in the", "tokens": [50640, 1954, 11, 456, 311, 746, 321, 393, 380, 915, 11, 321, 393, 6069, 746, 11, 457, 321, 393, 380, 915, 309, 4992, 294, 264, 50868], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 264, "seek": 143312, "start": 1443.1999999999998, "end": 1448.6399999999999, "text": " literature. So we will then, we have people we collaborated with, we'll say, sometimes they'll", "tokens": [50868, 10394, 13, 407, 321, 486, 550, 11, 321, 362, 561, 321, 42463, 365, 11, 321, 603, 584, 11, 2171, 436, 603, 51140], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 265, "seek": 143312, "start": 1448.6399999999999, "end": 1452.4799999999998, "text": " say, you know what, I have some collected data, which I didn't publish. But we can go back and", "tokens": [51140, 584, 11, 291, 458, 437, 11, 286, 362, 512, 11087, 1412, 11, 597, 286, 994, 380, 11374, 13, 583, 321, 393, 352, 646, 293, 51332], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 266, "seek": 143312, "start": 1452.4799999999998, "end": 1456.8799999999999, "text": " look at it and see if we can find that, which is much easier than designing a new experiment,", "tokens": [51332, 574, 412, 309, 293, 536, 498, 321, 393, 915, 300, 11, 597, 307, 709, 3571, 813, 14685, 257, 777, 5120, 11, 51552], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 267, "seek": 143312, "start": 1456.8799999999999, "end": 1461.9199999999998, "text": " you know, new neuroscience experiments take a long time, years. So although some people", "tokens": [51552, 291, 458, 11, 777, 42762, 12050, 747, 257, 938, 565, 11, 924, 13, 407, 4878, 512, 561, 51804], "temperature": 0.0, "avg_logprob": -0.08469143048138686, "compression_ratio": 1.8529411764705883, "no_speech_prob": 0.0013247645692899823}, {"id": 268, "seek": 146192, "start": 1461.92, "end": 1468.72, "text": " are doing that now too. So, but between all of these things, I think it's a reasonable,", "tokens": [50364, 366, 884, 300, 586, 886, 13, 407, 11, 457, 1296, 439, 295, 613, 721, 11, 286, 519, 309, 311, 257, 10585, 11, 50704], "temperature": 0.0, "avg_logprob": -0.1534341812133789, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.001169118215329945}, {"id": 269, "seek": 146192, "start": 1470.0800000000002, "end": 1474.4, "text": " actually a very, very good approach. We are blessed with the fact that we can test our theories", "tokens": [50772, 767, 257, 588, 11, 588, 665, 3109, 13, 492, 366, 12351, 365, 264, 1186, 300, 321, 393, 1500, 527, 13667, 50988], "temperature": 0.0, "avg_logprob": -0.1534341812133789, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.001169118215329945}, {"id": 270, "seek": 146192, "start": 1474.96, "end": 1479.28, "text": " out to Yang Yang here, because there's so much on a similar data. And we can also falsify our", "tokens": [51016, 484, 281, 11978, 11978, 510, 11, 570, 456, 311, 370, 709, 322, 257, 2531, 1412, 13, 400, 321, 393, 611, 16720, 2505, 527, 51232], "temperature": 0.0, "avg_logprob": -0.1534341812133789, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.001169118215329945}, {"id": 271, "seek": 146192, "start": 1479.28, "end": 1484.0800000000002, "text": " theories very easily, which we do often. So it's kind of reminiscent to whenever, whenever that", "tokens": [51232, 13667, 588, 3612, 11, 597, 321, 360, 2049, 13, 407, 309, 311, 733, 295, 44304, 281, 5699, 11, 5699, 300, 51472], "temperature": 0.0, "avg_logprob": -0.1534341812133789, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.001169118215329945}, {"id": 272, "seek": 146192, "start": 1484.0800000000002, "end": 1490.72, "text": " was with Copernicus, you know, when you figure out that the sun's at the center of the solar", "tokens": [51472, 390, 365, 11579, 1248, 36496, 11, 291, 458, 11, 562, 291, 2573, 484, 300, 264, 3295, 311, 412, 264, 3056, 295, 264, 7936, 51804], "temperature": 0.0, "avg_logprob": -0.1534341812133789, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.001169118215329945}, {"id": 273, "seek": 149072, "start": 1490.72, "end": 1496.24, "text": " system as opposed to Earth, the pieces just fall into place. Yeah, I think that's the general", "tokens": [50364, 1185, 382, 8851, 281, 4755, 11, 264, 3755, 445, 2100, 666, 1081, 13, 865, 11, 286, 519, 300, 311, 264, 2674, 50640], "temperature": 0.0, "avg_logprob": -0.15428970654805502, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0010159716475754976}, {"id": 274, "seek": 149072, "start": 1497.2, "end": 1503.84, "text": " nature of the Ha moments is in Copernicus, it could be, you could say the same thing about Darwin.", "tokens": [50688, 3687, 295, 264, 4064, 6065, 307, 294, 11579, 1248, 36496, 11, 309, 727, 312, 11, 291, 727, 584, 264, 912, 551, 466, 30233, 13, 51020], "temperature": 0.0, "avg_logprob": -0.15428970654805502, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0010159716475754976}, {"id": 275, "seek": 149072, "start": 1505.1200000000001, "end": 1511.3600000000001, "text": " You could say the same thing about, you know, about the double helix, that people have been", "tokens": [51084, 509, 727, 584, 264, 912, 551, 466, 11, 291, 458, 11, 466, 264, 3834, 801, 970, 11, 300, 561, 362, 668, 51396], "temperature": 0.0, "avg_logprob": -0.15428970654805502, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0010159716475754976}, {"id": 276, "seek": 149072, "start": 1511.3600000000001, "end": 1514.48, "text": " working on a problem for so long and have all this data and they can't make sense of it,", "tokens": [51396, 1364, 322, 257, 1154, 337, 370, 938, 293, 362, 439, 341, 1412, 293, 436, 393, 380, 652, 2020, 295, 309, 11, 51552], "temperature": 0.0, "avg_logprob": -0.15428970654805502, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0010159716475754976}, {"id": 277, "seek": 149072, "start": 1514.48, "end": 1519.28, "text": " they can't make sense of it. But when the answer comes to you and everything falls into place,", "tokens": [51552, 436, 393, 380, 652, 2020, 295, 309, 13, 583, 562, 264, 1867, 1487, 281, 291, 293, 1203, 8804, 666, 1081, 11, 51792], "temperature": 0.0, "avg_logprob": -0.15428970654805502, "compression_ratio": 1.793103448275862, "no_speech_prob": 0.0010159716475754976}, {"id": 278, "seek": 151928, "start": 1519.28, "end": 1526.3999999999999, "text": " it's like, oh, my gosh, that's it. That's got to be right. I asked both Jim Watson and Francis", "tokens": [50364, 309, 311, 411, 11, 1954, 11, 452, 6502, 11, 300, 311, 309, 13, 663, 311, 658, 281, 312, 558, 13, 286, 2351, 1293, 6637, 25640, 293, 19648, 50720], "temperature": 0.0, "avg_logprob": -0.09353065490722656, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0006069550872780383}, {"id": 279, "seek": 151928, "start": 1526.3999999999999, "end": 1533.44, "text": " Crick about this. I asked them, you know, when you were working on trying to discover the structure", "tokens": [50720, 4779, 618, 466, 341, 13, 286, 2351, 552, 11, 291, 458, 11, 562, 291, 645, 1364, 322, 1382, 281, 4411, 264, 3877, 51072], "temperature": 0.0, "avg_logprob": -0.09353065490722656, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0006069550872780383}, {"id": 280, "seek": 151928, "start": 1533.44, "end": 1540.72, "text": " of the double helix, and when you came up with the sort of the structure that ended up being correct,", "tokens": [51072, 295, 264, 3834, 801, 970, 11, 293, 562, 291, 1361, 493, 365, 264, 1333, 295, 264, 3877, 300, 4590, 493, 885, 3006, 11, 51436], "temperature": 0.0, "avg_logprob": -0.09353065490722656, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0006069550872780383}, {"id": 281, "seek": 151928, "start": 1542.3999999999999, "end": 1546.32, "text": " but it was sort of a guess, you know, it wasn't really verified yet. I said,", "tokens": [51520, 457, 309, 390, 1333, 295, 257, 2041, 11, 291, 458, 11, 309, 2067, 380, 534, 31197, 1939, 13, 286, 848, 11, 51716], "temperature": 0.0, "avg_logprob": -0.09353065490722656, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.0006069550872780383}, {"id": 282, "seek": 154632, "start": 1546.32, "end": 1551.36, "text": " did you know that it was right? And they both said, absolutely. So we absolutely knew it was", "tokens": [50364, 630, 291, 458, 300, 309, 390, 558, 30, 400, 436, 1293, 848, 11, 3122, 13, 407, 321, 3122, 2586, 309, 390, 50616], "temperature": 0.0, "avg_logprob": -0.11194736674680549, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0011155500542372465}, {"id": 283, "seek": 154632, "start": 1551.36, "end": 1555.52, "text": " right. And it doesn't matter if other people didn't believe it or not, we knew it was right,", "tokens": [50616, 558, 13, 400, 309, 1177, 380, 1871, 498, 661, 561, 994, 380, 1697, 309, 420, 406, 11, 321, 2586, 309, 390, 558, 11, 50824], "temperature": 0.0, "avg_logprob": -0.11194736674680549, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0011155500542372465}, {"id": 284, "seek": 154632, "start": 1555.52, "end": 1560.0, "text": " they'd get around to thinking it and agree with it eventually anyway. And that's the kind of thing", "tokens": [50824, 436, 1116, 483, 926, 281, 1953, 309, 293, 3986, 365, 309, 4728, 4033, 13, 400, 300, 311, 264, 733, 295, 551, 51048], "temperature": 0.0, "avg_logprob": -0.11194736674680549, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0011155500542372465}, {"id": 285, "seek": 154632, "start": 1560.0, "end": 1565.76, "text": " you hear a lot with scientists who really are studying a difficult problem. And I feel that way", "tokens": [51048, 291, 1568, 257, 688, 365, 7708, 567, 534, 366, 7601, 257, 2252, 1154, 13, 400, 286, 841, 300, 636, 51336], "temperature": 0.0, "avg_logprob": -0.11194736674680549, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0011155500542372465}, {"id": 286, "seek": 154632, "start": 1565.76, "end": 1571.52, "text": " too about our work. Have you talked to Crick or Watson about the problem you're trying to solve,", "tokens": [51336, 886, 466, 527, 589, 13, 3560, 291, 2825, 281, 4779, 618, 420, 25640, 466, 264, 1154, 291, 434, 1382, 281, 5039, 11, 51624], "temperature": 0.0, "avg_logprob": -0.11194736674680549, "compression_ratio": 1.7096774193548387, "no_speech_prob": 0.0011155500542372465}, {"id": 287, "seek": 157152, "start": 1572.0, "end": 1579.84, "text": " the, of finding the DNA of the brain? Yeah. In fact, Francis Crick was very interested in this,", "tokens": [50388, 264, 11, 295, 5006, 264, 8272, 295, 264, 3567, 30, 865, 13, 682, 1186, 11, 19648, 4779, 618, 390, 588, 3102, 294, 341, 11, 50780], "temperature": 0.0, "avg_logprob": -0.11823422281365646, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.0005700897891074419}, {"id": 288, "seek": 157152, "start": 1579.84, "end": 1585.28, "text": " in the latter part of his life. And in fact, I got interested in brains by reading an essay he wrote", "tokens": [50780, 294, 264, 18481, 644, 295, 702, 993, 13, 400, 294, 1186, 11, 286, 658, 3102, 294, 15442, 538, 3760, 364, 16238, 415, 4114, 51052], "temperature": 0.0, "avg_logprob": -0.11823422281365646, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.0005700897891074419}, {"id": 289, "seek": 157152, "start": 1585.28, "end": 1592.0, "text": " in 1979 called Thinking About the Brain. And that was when I decided I'm going to leave my", "tokens": [51052, 294, 30595, 1219, 24460, 7769, 264, 29783, 13, 400, 300, 390, 562, 286, 3047, 286, 478, 516, 281, 1856, 452, 51388], "temperature": 0.0, "avg_logprob": -0.11823422281365646, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.0005700897891074419}, {"id": 290, "seek": 157152, "start": 1592.0, "end": 1596.6399999999999, "text": " profession of computers and engineering and become a neuroscientist, just reading that one essay from", "tokens": [51388, 7032, 295, 10807, 293, 7043, 293, 1813, 257, 28813, 5412, 468, 11, 445, 3760, 300, 472, 16238, 490, 51620], "temperature": 0.0, "avg_logprob": -0.11823422281365646, "compression_ratio": 1.5622489959839359, "no_speech_prob": 0.0005700897891074419}, {"id": 291, "seek": 159664, "start": 1596.64, "end": 1603.6000000000001, "text": " Francis Crick. I got to meet him later in life. I got to, I spoke at the Salk Institute and he", "tokens": [50364, 19648, 4779, 618, 13, 286, 658, 281, 1677, 796, 1780, 294, 993, 13, 286, 658, 281, 11, 286, 7179, 412, 264, 318, 667, 9446, 293, 415, 50712], "temperature": 0.0, "avg_logprob": -0.1317998795282273, "compression_ratio": 1.5418326693227091, "no_speech_prob": 0.003944838419556618}, {"id": 292, "seek": 159664, "start": 1603.6000000000001, "end": 1609.6000000000001, "text": " was in the audience and then I had a tea with him afterwards. You know, he was interested in a", "tokens": [50712, 390, 294, 264, 4034, 293, 550, 286, 632, 257, 5817, 365, 796, 10543, 13, 509, 458, 11, 415, 390, 3102, 294, 257, 51012], "temperature": 0.0, "avg_logprob": -0.1317998795282273, "compression_ratio": 1.5418326693227091, "no_speech_prob": 0.003944838419556618}, {"id": 293, "seek": 159664, "start": 1609.6000000000001, "end": 1617.5200000000002, "text": " different problem. He was focused on consciousness. Oh, the easy problem, right? Well, I think it's", "tokens": [51012, 819, 1154, 13, 634, 390, 5178, 322, 10081, 13, 876, 11, 264, 1858, 1154, 11, 558, 30, 1042, 11, 286, 519, 309, 311, 51408], "temperature": 0.0, "avg_logprob": -0.1317998795282273, "compression_ratio": 1.5418326693227091, "no_speech_prob": 0.003944838419556618}, {"id": 294, "seek": 159664, "start": 1617.5200000000002, "end": 1624.24, "text": " the red herring. And so we weren't really overlapping a lot there. Jim Watson, who's still alive,", "tokens": [51408, 264, 2182, 720, 2937, 13, 400, 370, 321, 4999, 380, 534, 33535, 257, 688, 456, 13, 6637, 25640, 11, 567, 311, 920, 5465, 11, 51744], "temperature": 0.0, "avg_logprob": -0.1317998795282273, "compression_ratio": 1.5418326693227091, "no_speech_prob": 0.003944838419556618}, {"id": 295, "seek": 162424, "start": 1625.2, "end": 1630.08, "text": " is also interested in this problem. And he was, when he was director of the Coltsman Harbor", "tokens": [50412, 307, 611, 3102, 294, 341, 1154, 13, 400, 415, 390, 11, 562, 415, 390, 5391, 295, 264, 4004, 1373, 1601, 33740, 50656], "temperature": 0.0, "avg_logprob": -0.15620219189187753, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.000261079054325819}, {"id": 296, "seek": 162424, "start": 1630.08, "end": 1635.84, "text": " laboratories, he was really sort of behind moving in the direction of neuroscience there.", "tokens": [50656, 41013, 11, 415, 390, 534, 1333, 295, 2261, 2684, 294, 264, 3513, 295, 42762, 456, 13, 50944], "temperature": 0.0, "avg_logprob": -0.15620219189187753, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.000261079054325819}, {"id": 297, "seek": 162424, "start": 1636.48, "end": 1641.92, "text": " And so he had a personal interest in this field. And I have met with him numerous times.", "tokens": [50976, 400, 370, 415, 632, 257, 2973, 1179, 294, 341, 2519, 13, 400, 286, 362, 1131, 365, 796, 12546, 1413, 13, 51248], "temperature": 0.0, "avg_logprob": -0.15620219189187753, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.000261079054325819}, {"id": 298, "seek": 162424, "start": 1643.52, "end": 1649.2, "text": " And in fact, the last time was about a little bit over a year ago, I gave a talk at Coltsman", "tokens": [51328, 400, 294, 1186, 11, 264, 1036, 565, 390, 466, 257, 707, 857, 670, 257, 1064, 2057, 11, 286, 2729, 257, 751, 412, 4004, 1373, 1601, 51612], "temperature": 0.0, "avg_logprob": -0.15620219189187753, "compression_ratio": 1.665137614678899, "no_speech_prob": 0.000261079054325819}, {"id": 299, "seek": 164920, "start": 1649.28, "end": 1657.92, "text": " Harbor Labs about the progress we were making in our work. And it was a lot of fun because", "tokens": [50368, 33740, 40047, 466, 264, 4205, 321, 645, 1455, 294, 527, 589, 13, 400, 309, 390, 257, 688, 295, 1019, 570, 50800], "temperature": 0.0, "avg_logprob": -0.07999113571545309, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008828516001813114}, {"id": 300, "seek": 164920, "start": 1659.3600000000001, "end": 1662.24, "text": " he said, well, you wouldn't be coming here unless you had something important to say,", "tokens": [50872, 415, 848, 11, 731, 11, 291, 2759, 380, 312, 1348, 510, 5969, 291, 632, 746, 1021, 281, 584, 11, 51016], "temperature": 0.0, "avg_logprob": -0.07999113571545309, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008828516001813114}, {"id": 301, "seek": 164920, "start": 1662.24, "end": 1668.96, "text": " so I'm going to go attend your talk. So he sat in the very front row. Next to him was the director", "tokens": [51016, 370, 286, 478, 516, 281, 352, 6888, 428, 751, 13, 407, 415, 3227, 294, 264, 588, 1868, 5386, 13, 3087, 281, 796, 390, 264, 5391, 51352], "temperature": 0.0, "avg_logprob": -0.07999113571545309, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008828516001813114}, {"id": 302, "seek": 164920, "start": 1668.96, "end": 1672.48, "text": " of the lab, Bruce Stillman. So these guys are in the front row of this auditorium, right? So", "tokens": [51352, 295, 264, 2715, 11, 15429, 8291, 1601, 13, 407, 613, 1074, 366, 294, 264, 1868, 5386, 295, 341, 33970, 2197, 11, 558, 30, 407, 51528], "temperature": 0.0, "avg_logprob": -0.07999113571545309, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008828516001813114}, {"id": 303, "seek": 164920, "start": 1672.48, "end": 1675.6000000000001, "text": " nobody else in the auditorium wants to sit in the front row because there's Jim Watson and there's", "tokens": [51528, 5079, 1646, 294, 264, 33970, 2197, 2738, 281, 1394, 294, 264, 1868, 5386, 570, 456, 311, 6637, 25640, 293, 456, 311, 51684], "temperature": 0.0, "avg_logprob": -0.07999113571545309, "compression_ratio": 1.667857142857143, "no_speech_prob": 0.0008828516001813114}, {"id": 304, "seek": 167560, "start": 1675.6, "end": 1685.04, "text": " the director. And I gave a talk and then I had dinner with Jim afterwards. But there's a great", "tokens": [50364, 264, 5391, 13, 400, 286, 2729, 257, 751, 293, 550, 286, 632, 6148, 365, 6637, 10543, 13, 583, 456, 311, 257, 869, 50836], "temperature": 0.0, "avg_logprob": -0.17884890887202048, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0006262490642257035}, {"id": 305, "seek": 167560, "start": 1685.04, "end": 1689.84, "text": " picture of my colleague, Subitai Amantik, where I'm up there sort of explaining the basics of", "tokens": [50836, 3036, 295, 452, 13532, 11, 8511, 270, 1301, 2012, 394, 1035, 11, 689, 286, 478, 493, 456, 1333, 295, 13468, 264, 14688, 295, 51076], "temperature": 0.0, "avg_logprob": -0.17884890887202048, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0006262490642257035}, {"id": 306, "seek": 167560, "start": 1689.84, "end": 1694.56, "text": " this new framework we have. And Jim Watson is on the edge of his chair. He's literally on the edge", "tokens": [51076, 341, 777, 8388, 321, 362, 13, 400, 6637, 25640, 307, 322, 264, 4691, 295, 702, 6090, 13, 634, 311, 3736, 322, 264, 4691, 51312], "temperature": 0.0, "avg_logprob": -0.17884890887202048, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0006262490642257035}, {"id": 307, "seek": 167560, "start": 1694.56, "end": 1700.48, "text": " of his chair, like intently staring up at the screen. And when he discovered the structure of", "tokens": [51312, 295, 702, 6090, 11, 411, 560, 2276, 18043, 493, 412, 264, 2568, 13, 400, 562, 415, 6941, 264, 3877, 295, 51608], "temperature": 0.0, "avg_logprob": -0.17884890887202048, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.0006262490642257035}, {"id": 308, "seek": 170048, "start": 1700.48, "end": 1706.56, "text": " DNA, the first public talk he gave was at Coltsman Harbor Labs. And there's a picture,", "tokens": [50364, 8272, 11, 264, 700, 1908, 751, 415, 2729, 390, 412, 4004, 1373, 1601, 33740, 40047, 13, 400, 456, 311, 257, 3036, 11, 50668], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 309, "seek": 170048, "start": 1706.56, "end": 1710.72, "text": " there's a famous picture of Jim Watson standing at the whiteboard with a overrated thing pointing", "tokens": [50668, 456, 311, 257, 4618, 3036, 295, 6637, 25640, 4877, 412, 264, 2418, 3787, 365, 257, 670, 5468, 551, 12166, 50876], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 310, "seek": 170048, "start": 1710.72, "end": 1714.4, "text": " at something, holding at the double helix with his pointer. And it actually looks a lot like the", "tokens": [50876, 412, 746, 11, 5061, 412, 264, 3834, 801, 970, 365, 702, 23918, 13, 400, 309, 767, 1542, 257, 688, 411, 264, 51060], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 311, "seek": 170048, "start": 1714.4, "end": 1717.76, "text": " picture of me. So there was a sort of funny, there's an area talking about the brain and there's Jim", "tokens": [51060, 3036, 295, 385, 13, 407, 456, 390, 257, 1333, 295, 4074, 11, 456, 311, 364, 1859, 1417, 466, 264, 3567, 293, 456, 311, 6637, 51228], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 312, "seek": 170048, "start": 1717.76, "end": 1721.52, "text": " Watson staring up intently at it. And of course, there was, you know, whatever, 60 years earlier,", "tokens": [51228, 25640, 18043, 493, 560, 2276, 412, 309, 13, 400, 295, 1164, 11, 456, 390, 11, 291, 458, 11, 2035, 11, 4060, 924, 3071, 11, 51416], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 313, "seek": 170048, "start": 1721.52, "end": 1726.0, "text": " he was standing, you know, pointing at the double helix. And it's one of the great discoveries in", "tokens": [51416, 415, 390, 4877, 11, 291, 458, 11, 12166, 412, 264, 3834, 801, 970, 13, 400, 309, 311, 472, 295, 264, 869, 28400, 294, 51640], "temperature": 0.0, "avg_logprob": -0.1972102080883623, "compression_ratio": 1.9013157894736843, "no_speech_prob": 0.004263298120349646}, {"id": 314, "seek": 172600, "start": 1726.0, "end": 1732.32, "text": " all of, you know, whatever, by all the science, all science DNA. So it's just the funny that", "tokens": [50364, 439, 295, 11, 291, 458, 11, 2035, 11, 538, 439, 264, 3497, 11, 439, 3497, 8272, 13, 407, 309, 311, 445, 264, 4074, 300, 50680], "temperature": 0.0, "avg_logprob": -0.1515727091317225, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.03671889752149582}, {"id": 315, "seek": 172600, "start": 1732.32, "end": 1737.28, "text": " there's echoes of that in your presentation. Do you think in terms of evolutionary timeline and", "tokens": [50680, 456, 311, 47051, 295, 300, 294, 428, 5860, 13, 1144, 291, 519, 294, 2115, 295, 27567, 12933, 293, 50928], "temperature": 0.0, "avg_logprob": -0.1515727091317225, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.03671889752149582}, {"id": 316, "seek": 172600, "start": 1737.28, "end": 1747.36, "text": " history, the development of the neocortex was a big leap? Or is it just a small step? So like,", "tokens": [50928, 2503, 11, 264, 3250, 295, 264, 408, 905, 36143, 390, 257, 955, 19438, 30, 1610, 307, 309, 445, 257, 1359, 1823, 30, 407, 411, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1515727091317225, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.03671889752149582}, {"id": 317, "seek": 172600, "start": 1747.36, "end": 1752.72, "text": " if we ran the whole thing over again, from the from the birth of human of life on earth, how", "tokens": [51432, 498, 321, 5872, 264, 1379, 551, 670, 797, 11, 490, 264, 490, 264, 3965, 295, 1952, 295, 993, 322, 4120, 11, 577, 51700], "temperature": 0.0, "avg_logprob": -0.1515727091317225, "compression_ratio": 1.5932203389830508, "no_speech_prob": 0.03671889752149582}, {"id": 318, "seek": 175272, "start": 1752.72, "end": 1756.32, "text": " likely would we develop the mechanism of the neocortex? Okay, well, those are two separate", "tokens": [50364, 3700, 576, 321, 1499, 264, 7513, 295, 264, 408, 905, 36143, 30, 1033, 11, 731, 11, 729, 366, 732, 4994, 50544], "temperature": 0.0, "avg_logprob": -0.13538849063035918, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0007094452157616615}, {"id": 319, "seek": 175272, "start": 1756.32, "end": 1762.24, "text": " questions. One is, was it a big leap? And one was how likely it is. Okay, they're not necessarily", "tokens": [50544, 1651, 13, 1485, 307, 11, 390, 309, 257, 955, 19438, 30, 400, 472, 390, 577, 3700, 309, 307, 13, 1033, 11, 436, 434, 406, 4725, 50840], "temperature": 0.0, "avg_logprob": -0.13538849063035918, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0007094452157616615}, {"id": 320, "seek": 175272, "start": 1762.24, "end": 1767.2, "text": " related. Maybe correlated. And we don't really have enough data to make a judgment about that.", "tokens": [50840, 4077, 13, 2704, 38574, 13, 400, 321, 500, 380, 534, 362, 1547, 1412, 281, 652, 257, 12216, 466, 300, 13, 51088], "temperature": 0.0, "avg_logprob": -0.13538849063035918, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0007094452157616615}, {"id": 321, "seek": 175272, "start": 1768.0, "end": 1772.56, "text": " I would say definitely was a big leap. And I can tell you why I think I don't think it was just", "tokens": [51128, 286, 576, 584, 2138, 390, 257, 955, 19438, 13, 400, 286, 393, 980, 291, 983, 286, 519, 286, 500, 380, 519, 309, 390, 445, 51356], "temperature": 0.0, "avg_logprob": -0.13538849063035918, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0007094452157616615}, {"id": 322, "seek": 175272, "start": 1772.56, "end": 1778.32, "text": " another incremental step. I'll get that moment. I don't really have any idea how likely it is.", "tokens": [51356, 1071, 35759, 1823, 13, 286, 603, 483, 300, 1623, 13, 286, 500, 380, 534, 362, 604, 1558, 577, 3700, 309, 307, 13, 51644], "temperature": 0.0, "avg_logprob": -0.13538849063035918, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0007094452157616615}, {"id": 323, "seek": 177832, "start": 1778.32, "end": 1784.08, "text": " If we look at evolution, we have one data point, which is earth, right? Life formed on earth billions", "tokens": [50364, 759, 321, 574, 412, 9303, 11, 321, 362, 472, 1412, 935, 11, 597, 307, 4120, 11, 558, 30, 7720, 8693, 322, 4120, 17375, 50652], "temperature": 0.0, "avg_logprob": -0.11895423465304905, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0010004575597122312}, {"id": 324, "seek": 177832, "start": 1784.08, "end": 1788.8799999999999, "text": " of years ago, whether it was introduced here, or it created here, or someone introduced it,", "tokens": [50652, 295, 924, 2057, 11, 1968, 309, 390, 7268, 510, 11, 420, 309, 2942, 510, 11, 420, 1580, 7268, 309, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11895423465304905, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0010004575597122312}, {"id": 325, "seek": 177832, "start": 1788.8799999999999, "end": 1794.1599999999999, "text": " we don't really know, but it was here early. It took a long, long time to get to multicellular life.", "tokens": [50892, 321, 500, 380, 534, 458, 11, 457, 309, 390, 510, 2440, 13, 467, 1890, 257, 938, 11, 938, 565, 281, 483, 281, 2120, 573, 285, 1040, 993, 13, 51156], "temperature": 0.0, "avg_logprob": -0.11895423465304905, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0010004575597122312}, {"id": 326, "seek": 177832, "start": 1795.04, "end": 1802.6399999999999, "text": " And then from multicellular life, it took a long, long time to get the neocortex. And we've only", "tokens": [51200, 400, 550, 490, 2120, 573, 285, 1040, 993, 11, 309, 1890, 257, 938, 11, 938, 565, 281, 483, 264, 408, 905, 36143, 13, 400, 321, 600, 787, 51580], "temperature": 0.0, "avg_logprob": -0.11895423465304905, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0010004575597122312}, {"id": 327, "seek": 180264, "start": 1802.64, "end": 1809.0400000000002, "text": " had the neocortex for a few hundred thousand years. So that's like nothing. Okay, so is it", "tokens": [50364, 632, 264, 408, 905, 36143, 337, 257, 1326, 3262, 4714, 924, 13, 407, 300, 311, 411, 1825, 13, 1033, 11, 370, 307, 309, 50684], "temperature": 0.0, "avg_logprob": -0.09937353548796281, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.01205302681773901}, {"id": 328, "seek": 180264, "start": 1809.0400000000002, "end": 1813.76, "text": " likely? Well, certainly isn't something that happened right away on earth. And there were", "tokens": [50684, 3700, 30, 1042, 11, 3297, 1943, 380, 746, 300, 2011, 558, 1314, 322, 4120, 13, 400, 456, 645, 50920], "temperature": 0.0, "avg_logprob": -0.09937353548796281, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.01205302681773901}, {"id": 329, "seek": 180264, "start": 1813.76, "end": 1817.5200000000002, "text": " multiple steps to get there. So I would say it's probably not going to something that would happen", "tokens": [50920, 3866, 4439, 281, 483, 456, 13, 407, 286, 576, 584, 309, 311, 1391, 406, 516, 281, 746, 300, 576, 1051, 51108], "temperature": 0.0, "avg_logprob": -0.09937353548796281, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.01205302681773901}, {"id": 330, "seek": 180264, "start": 1817.5200000000002, "end": 1822.4, "text": " instantaneously on other planets that might have life. It might take several billion years on average.", "tokens": [51108, 9836, 13131, 322, 661, 15126, 300, 1062, 362, 993, 13, 467, 1062, 747, 2940, 5218, 924, 322, 4274, 13, 51352], "temperature": 0.0, "avg_logprob": -0.09937353548796281, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.01205302681773901}, {"id": 331, "seek": 180264, "start": 1823.0400000000002, "end": 1826.88, "text": " Is it likely? I don't know, but you'd have to survive for several billion years to find out.", "tokens": [51384, 1119, 309, 3700, 30, 286, 500, 380, 458, 11, 457, 291, 1116, 362, 281, 7867, 337, 2940, 5218, 924, 281, 915, 484, 13, 51576], "temperature": 0.0, "avg_logprob": -0.09937353548796281, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.01205302681773901}, {"id": 332, "seek": 182688, "start": 1827.8400000000001, "end": 1836.5600000000002, "text": " Probably. Is it a big leap? Yeah, I think it is a qualitative difference in all other evolutionary", "tokens": [50412, 9210, 13, 1119, 309, 257, 955, 19438, 30, 865, 11, 286, 519, 309, 307, 257, 31312, 2649, 294, 439, 661, 27567, 50848], "temperature": 0.0, "avg_logprob": -0.1272896864475348, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.004754649940878153}, {"id": 333, "seek": 182688, "start": 1836.5600000000002, "end": 1842.8000000000002, "text": " steps. I can try to describe that if you'd like. Sure. In which way? Yeah, I can tell you how.", "tokens": [50848, 4439, 13, 286, 393, 853, 281, 6786, 300, 498, 291, 1116, 411, 13, 4894, 13, 682, 597, 636, 30, 865, 11, 286, 393, 980, 291, 577, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1272896864475348, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.004754649940878153}, {"id": 334, "seek": 182688, "start": 1843.7600000000002, "end": 1849.6000000000001, "text": " Pretty much, let's start with a little preface. Many of the things that humans are able to do", "tokens": [51208, 10693, 709, 11, 718, 311, 722, 365, 257, 707, 659, 2868, 13, 5126, 295, 264, 721, 300, 6255, 366, 1075, 281, 360, 51500], "temperature": 0.0, "avg_logprob": -0.1272896864475348, "compression_ratio": 1.4207920792079207, "no_speech_prob": 0.004754649940878153}, {"id": 335, "seek": 184960, "start": 1850.32, "end": 1860.3999999999999, "text": " do not have obvious survival advantages precedent. We could create music. Is there", "tokens": [50400, 360, 406, 362, 6322, 12559, 14906, 37388, 13, 492, 727, 1884, 1318, 13, 1119, 456, 50904], "temperature": 0.0, "avg_logprob": -0.18901847244857192, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.03787924721837044}, {"id": 336, "seek": 184960, "start": 1860.3999999999999, "end": 1865.28, "text": " a really survival advantage to that? Maybe, maybe not. What about mathematics? Is there a real", "tokens": [50904, 257, 534, 12559, 5002, 281, 300, 30, 2704, 11, 1310, 406, 13, 708, 466, 18666, 30, 1119, 456, 257, 957, 51148], "temperature": 0.0, "avg_logprob": -0.18901847244857192, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.03787924721837044}, {"id": 337, "seek": 184960, "start": 1865.28, "end": 1870.48, "text": " survival advantage to mathematics? You can stretch it. You can try to figure these things out.", "tokens": [51148, 12559, 5002, 281, 18666, 30, 509, 393, 5985, 309, 13, 509, 393, 853, 281, 2573, 613, 721, 484, 13, 51408], "temperature": 0.0, "avg_logprob": -0.18901847244857192, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.03787924721837044}, {"id": 338, "seek": 184960, "start": 1872.08, "end": 1877.9199999999998, "text": " But mostly evolutionary history, everything had immediate survival advantages to write.", "tokens": [51488, 583, 5240, 27567, 2503, 11, 1203, 632, 11629, 12559, 14906, 281, 2464, 13, 51780], "temperature": 0.0, "avg_logprob": -0.18901847244857192, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.03787924721837044}, {"id": 339, "seek": 187792, "start": 1878.64, "end": 1886.24, "text": " So I'll tell you a story, which I like. It may not be true. But the story goes as follows.", "tokens": [50400, 407, 286, 603, 980, 291, 257, 1657, 11, 597, 286, 411, 13, 467, 815, 406, 312, 2074, 13, 583, 264, 1657, 1709, 382, 10002, 13, 50780], "temperature": 0.0, "avg_logprob": -0.15056632050370747, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0001795142306946218}, {"id": 340, "seek": 187792, "start": 1889.04, "end": 1892.3200000000002, "text": " Organisms have been evolving since the beginning of life here on Earth,", "tokens": [50920, 12538, 13539, 362, 668, 21085, 1670, 264, 2863, 295, 993, 510, 322, 4755, 11, 51084], "temperature": 0.0, "avg_logprob": -0.15056632050370747, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0001795142306946218}, {"id": 341, "seek": 187792, "start": 1893.68, "end": 1897.68, "text": " adding this sort of complexity onto that and this sort of complexity onto that. And the brain itself", "tokens": [51152, 5127, 341, 1333, 295, 14024, 3911, 300, 293, 341, 1333, 295, 14024, 3911, 300, 13, 400, 264, 3567, 2564, 51352], "temperature": 0.0, "avg_logprob": -0.15056632050370747, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0001795142306946218}, {"id": 342, "seek": 187792, "start": 1898.24, "end": 1903.3600000000001, "text": " is evolved this way. In fact, there's an old part, an older part, an older, older part to the", "tokens": [51380, 307, 14178, 341, 636, 13, 682, 1186, 11, 456, 311, 364, 1331, 644, 11, 364, 4906, 644, 11, 364, 4906, 11, 4906, 644, 281, 264, 51636], "temperature": 0.0, "avg_logprob": -0.15056632050370747, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0001795142306946218}, {"id": 343, "seek": 187792, "start": 1903.3600000000001, "end": 1907.3600000000001, "text": " brain that kind of just keeps calming on new things and we keep adding capabilities. And we", "tokens": [51636, 3567, 300, 733, 295, 445, 5965, 39723, 322, 777, 721, 293, 321, 1066, 5127, 10862, 13, 400, 321, 51836], "temperature": 0.0, "avg_logprob": -0.15056632050370747, "compression_ratio": 1.7677165354330708, "no_speech_prob": 0.0001795142306946218}, {"id": 344, "seek": 190736, "start": 1907.36, "end": 1913.84, "text": " got to the neocortex. Initially, it had a very clear survival advantage in that it produced better", "tokens": [50364, 658, 281, 264, 408, 905, 36143, 13, 29446, 11, 309, 632, 257, 588, 1850, 12559, 5002, 294, 300, 309, 7126, 1101, 50688], "temperature": 0.0, "avg_logprob": -0.19095055953316067, "compression_ratio": 1.68, "no_speech_prob": 7.36793881515041e-05}, {"id": 345, "seek": 190736, "start": 1913.84, "end": 1919.1999999999998, "text": " vision and better hearing and better touch and maybe, you know, say, so on. But what I think", "tokens": [50688, 5201, 293, 1101, 4763, 293, 1101, 2557, 293, 1310, 11, 291, 458, 11, 584, 11, 370, 322, 13, 583, 437, 286, 519, 50956], "temperature": 0.0, "avg_logprob": -0.19095055953316067, "compression_ratio": 1.68, "no_speech_prob": 7.36793881515041e-05}, {"id": 346, "seek": 190736, "start": 1919.1999999999998, "end": 1925.4399999999998, "text": " happens is that evolution took a mechanism, and this is in our recent theory, but it took a", "tokens": [50956, 2314, 307, 300, 9303, 1890, 257, 7513, 11, 293, 341, 307, 294, 527, 5162, 5261, 11, 457, 309, 1890, 257, 51268], "temperature": 0.0, "avg_logprob": -0.19095055953316067, "compression_ratio": 1.68, "no_speech_prob": 7.36793881515041e-05}, {"id": 347, "seek": 190736, "start": 1925.4399999999998, "end": 1930.32, "text": " mechanism that evolved a long time ago for navigating in the world, for knowing where you are.", "tokens": [51268, 7513, 300, 14178, 257, 938, 565, 2057, 337, 32054, 294, 264, 1002, 11, 337, 5276, 689, 291, 366, 13, 51512], "temperature": 0.0, "avg_logprob": -0.19095055953316067, "compression_ratio": 1.68, "no_speech_prob": 7.36793881515041e-05}, {"id": 348, "seek": 193032, "start": 1930.32, "end": 1934.32, "text": " These are the so-called grid cells and place cells of an old part of the brain.", "tokens": [50364, 1981, 366, 264, 370, 12, 11880, 10748, 5438, 293, 1081, 5438, 295, 364, 1331, 644, 295, 264, 3567, 13, 50564], "temperature": 0.0, "avg_logprob": -0.12508859219758406, "compression_ratio": 1.8582995951417005, "no_speech_prob": 0.030205819755792618}, {"id": 349, "seek": 193032, "start": 1935.12, "end": 1942.1599999999999, "text": " And it took that mechanism for building maps of the world and knowing where you are on those", "tokens": [50604, 400, 309, 1890, 300, 7513, 337, 2390, 11317, 295, 264, 1002, 293, 5276, 689, 291, 366, 322, 729, 50956], "temperature": 0.0, "avg_logprob": -0.12508859219758406, "compression_ratio": 1.8582995951417005, "no_speech_prob": 0.030205819755792618}, {"id": 350, "seek": 193032, "start": 1942.1599999999999, "end": 1947.9199999999998, "text": " maps and how to navigate those maps and turns it into a sort of a slimmed down, idealized version", "tokens": [50956, 11317, 293, 577, 281, 12350, 729, 11317, 293, 4523, 309, 666, 257, 1333, 295, 257, 25357, 1912, 760, 11, 7157, 1602, 3037, 51244], "temperature": 0.0, "avg_logprob": -0.12508859219758406, "compression_ratio": 1.8582995951417005, "no_speech_prob": 0.030205819755792618}, {"id": 351, "seek": 193032, "start": 1947.9199999999998, "end": 1953.12, "text": " of it. And that idealized version could now apply to building maps of other things, maps of", "tokens": [51244, 295, 309, 13, 400, 300, 7157, 1602, 3037, 727, 586, 3079, 281, 2390, 11317, 295, 661, 721, 11, 11317, 295, 51504], "temperature": 0.0, "avg_logprob": -0.12508859219758406, "compression_ratio": 1.8582995951417005, "no_speech_prob": 0.030205819755792618}, {"id": 352, "seek": 193032, "start": 1953.6799999999998, "end": 1959.2, "text": " coffee cups and maps of phones, maps of, you know, concepts, concepts, yes, and not just almost,", "tokens": [51532, 4982, 13381, 293, 11317, 295, 10216, 11, 11317, 295, 11, 291, 458, 11, 10392, 11, 10392, 11, 2086, 11, 293, 406, 445, 1920, 11, 51808], "temperature": 0.0, "avg_logprob": -0.12508859219758406, "compression_ratio": 1.8582995951417005, "no_speech_prob": 0.030205819755792618}, {"id": 353, "seek": 195920, "start": 1959.2, "end": 1964.4, "text": " exactly. And so you, and it just started replicating this stuff, right? You just think", "tokens": [50364, 2293, 13, 400, 370, 291, 11, 293, 309, 445, 1409, 3248, 30541, 341, 1507, 11, 558, 30, 509, 445, 519, 50624], "temperature": 0.0, "avg_logprob": -0.12540929967706854, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.00037986424285918474}, {"id": 354, "seek": 195920, "start": 1964.4, "end": 1970.48, "text": " more and more and more. So we went from being sort of dedicated purpose neural hardware to solve", "tokens": [50624, 544, 293, 544, 293, 544, 13, 407, 321, 1437, 490, 885, 1333, 295, 8374, 4334, 18161, 8837, 281, 5039, 50928], "temperature": 0.0, "avg_logprob": -0.12540929967706854, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.00037986424285918474}, {"id": 355, "seek": 195920, "start": 1970.48, "end": 1976.0, "text": " certain problems that are important to survival to a general purpose neural hardware that could", "tokens": [50928, 1629, 2740, 300, 366, 1021, 281, 12559, 281, 257, 2674, 4334, 18161, 8837, 300, 727, 51204], "temperature": 0.0, "avg_logprob": -0.12540929967706854, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.00037986424285918474}, {"id": 356, "seek": 195920, "start": 1976.0, "end": 1983.3600000000001, "text": " be applied to all problems. And now it's escaped the orbit of survival. It's, we are now able to", "tokens": [51204, 312, 6456, 281, 439, 2740, 13, 400, 586, 309, 311, 20397, 264, 13991, 295, 12559, 13, 467, 311, 11, 321, 366, 586, 1075, 281, 51572], "temperature": 0.0, "avg_logprob": -0.12540929967706854, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.00037986424285918474}, {"id": 357, "seek": 198336, "start": 1983.36, "end": 1992.24, "text": " apply it to things which we find enjoyment, you know, but aren't really clearly survival", "tokens": [50364, 3079, 309, 281, 721, 597, 321, 915, 32013, 11, 291, 458, 11, 457, 3212, 380, 534, 4448, 12559, 50808], "temperature": 0.0, "avg_logprob": -0.10293655168442499, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.0043305461294949055}, {"id": 358, "seek": 198336, "start": 1992.24, "end": 1998.0, "text": " characteristics. And that it seems to only have happened in humans to the large extent.", "tokens": [50808, 10891, 13, 400, 300, 309, 2544, 281, 787, 362, 2011, 294, 6255, 281, 264, 2416, 8396, 13, 51096], "temperature": 0.0, "avg_logprob": -0.10293655168442499, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.0043305461294949055}, {"id": 359, "seek": 198336, "start": 1999.12, "end": 2004.9599999999998, "text": " And so that's what's going on where we sort of have, we've sort of escaped the gravity of", "tokens": [51152, 400, 370, 300, 311, 437, 311, 516, 322, 689, 321, 1333, 295, 362, 11, 321, 600, 1333, 295, 20397, 264, 12110, 295, 51444], "temperature": 0.0, "avg_logprob": -0.10293655168442499, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.0043305461294949055}, {"id": 360, "seek": 198336, "start": 2004.9599999999998, "end": 2010.9599999999998, "text": " evolutionary pressure in some sense in the New York cortex. And it now does things which", "tokens": [51444, 27567, 3321, 294, 512, 2020, 294, 264, 1873, 3609, 33312, 13, 400, 309, 586, 775, 721, 597, 51744], "temperature": 0.0, "avg_logprob": -0.10293655168442499, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.0043305461294949055}, {"id": 361, "seek": 201096, "start": 2011.52, "end": 2016.0, "text": " that are really interesting, discovering models of the universe, which may not really help us,", "tokens": [50392, 300, 366, 534, 1880, 11, 24773, 5245, 295, 264, 6445, 11, 597, 815, 406, 534, 854, 505, 11, 50616], "temperature": 0.0, "avg_logprob": -0.14372394395911176, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.0011331866262480617}, {"id": 362, "seek": 201096, "start": 2016.0, "end": 2020.8, "text": " doesn't matter. How does it help us surviving knowing that there might be multiverses or", "tokens": [50616, 1177, 380, 1871, 13, 1012, 775, 309, 854, 505, 24948, 5276, 300, 456, 1062, 312, 2120, 1762, 279, 420, 50856], "temperature": 0.0, "avg_logprob": -0.14372394395911176, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.0011331866262480617}, {"id": 363, "seek": 201096, "start": 2020.8, "end": 2025.44, "text": " that there might be, you know, the age of the universe or how do, you know, various stellar", "tokens": [50856, 300, 456, 1062, 312, 11, 291, 458, 11, 264, 3205, 295, 264, 6445, 420, 577, 360, 11, 291, 458, 11, 3683, 42333, 51088], "temperature": 0.0, "avg_logprob": -0.14372394395911176, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.0011331866262480617}, {"id": 364, "seek": 201096, "start": 2025.44, "end": 2030.32, "text": " things occur? It doesn't really help us survive at all. But we enjoy it. And that's what happened.", "tokens": [51088, 721, 5160, 30, 467, 1177, 380, 534, 854, 505, 7867, 412, 439, 13, 583, 321, 2103, 309, 13, 400, 300, 311, 437, 2011, 13, 51332], "temperature": 0.0, "avg_logprob": -0.14372394395911176, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.0011331866262480617}, {"id": 365, "seek": 201096, "start": 2030.32, "end": 2037.2, "text": " Or at least not in the obvious way, perhaps it is required. If you look at the entire", "tokens": [51332, 1610, 412, 1935, 406, 294, 264, 6322, 636, 11, 4317, 309, 307, 4739, 13, 759, 291, 574, 412, 264, 2302, 51676], "temperature": 0.0, "avg_logprob": -0.14372394395911176, "compression_ratio": 1.7829457364341086, "no_speech_prob": 0.0011331866262480617}, {"id": 366, "seek": 203720, "start": 2037.2, "end": 2041.28, "text": " universe in an evolutionary way, it's required for us to do interplanetary travel and therefore", "tokens": [50364, 6445, 294, 364, 27567, 636, 11, 309, 311, 4739, 337, 505, 281, 360, 728, 16554, 302, 822, 3147, 293, 4412, 50568], "temperature": 0.0, "avg_logprob": -0.15153808237236238, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.007573558017611504}, {"id": 367, "seek": 203720, "start": 2041.28, "end": 2044.32, "text": " survive past our own fun. But you know, let's not get too quick.", "tokens": [50568, 7867, 1791, 527, 1065, 1019, 13, 583, 291, 458, 11, 718, 311, 406, 483, 886, 1702, 13, 50720], "temperature": 0.0, "avg_logprob": -0.15153808237236238, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.007573558017611504}, {"id": 368, "seek": 203720, "start": 2044.32, "end": 2050.0, "text": " Yeah, but you know, evolution works at one time frame and survival, if you think of survival", "tokens": [50720, 865, 11, 457, 291, 458, 11, 9303, 1985, 412, 472, 565, 3920, 293, 12559, 11, 498, 291, 519, 295, 12559, 51004], "temperature": 0.0, "avg_logprob": -0.15153808237236238, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.007573558017611504}, {"id": 369, "seek": 203720, "start": 2050.0, "end": 2055.6, "text": " of the phenotype, survival of the individual, what you're talking about there is spans well", "tokens": [51004, 295, 264, 7279, 13108, 11, 12559, 295, 264, 2609, 11, 437, 291, 434, 1417, 466, 456, 307, 44086, 731, 51284], "temperature": 0.0, "avg_logprob": -0.15153808237236238, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.007573558017611504}, {"id": 370, "seek": 203720, "start": 2055.6, "end": 2062.4, "text": " beyond that. So there's no genetic, I'm not transferring any genetic traits to my children", "tokens": [51284, 4399, 300, 13, 407, 456, 311, 572, 12462, 11, 286, 478, 406, 31437, 604, 12462, 19526, 281, 452, 2227, 51624], "temperature": 0.0, "avg_logprob": -0.15153808237236238, "compression_ratio": 1.689922480620155, "no_speech_prob": 0.007573558017611504}, {"id": 371, "seek": 206240, "start": 2063.28, "end": 2065.76, "text": " that are going to help them survive better on Mars.", "tokens": [50408, 300, 366, 516, 281, 854, 552, 7867, 1101, 322, 9692, 13, 50532], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 372, "seek": 206240, "start": 2065.76, "end": 2071.2000000000003, "text": " Right. Totally different mechanism. So let's get into the new, as you've mentioned,", "tokens": [50532, 1779, 13, 22837, 819, 7513, 13, 407, 718, 311, 483, 666, 264, 777, 11, 382, 291, 600, 2835, 11, 50804], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 373, "seek": 206240, "start": 2071.2000000000003, "end": 2075.28, "text": " this idea, I don't know if you have a nice name, 1000.", "tokens": [50804, 341, 1558, 11, 286, 500, 380, 458, 498, 291, 362, 257, 1481, 1315, 11, 9714, 13, 51008], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 374, "seek": 206240, "start": 2075.28, "end": 2077.2000000000003, "text": " I would call it the thousand brain theory of intelligence.", "tokens": [51008, 286, 576, 818, 309, 264, 4714, 3567, 5261, 295, 7599, 13, 51104], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 375, "seek": 206240, "start": 2077.2000000000003, "end": 2084.0, "text": " I like it. So can you talk about the this idea of spatial view of concepts and so on?", "tokens": [51104, 286, 411, 309, 13, 407, 393, 291, 751, 466, 264, 341, 1558, 295, 23598, 1910, 295, 10392, 293, 370, 322, 30, 51444], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 376, "seek": 206240, "start": 2084.0, "end": 2088.48, "text": " Yeah. So can I just describe sort of the there's an underlying core discovery,", "tokens": [51444, 865, 13, 407, 393, 286, 445, 6786, 1333, 295, 264, 456, 311, 364, 14217, 4965, 12114, 11, 51668], "temperature": 0.0, "avg_logprob": -0.19599753563557196, "compression_ratio": 1.5390334572490707, "no_speech_prob": 0.027156244963407516}, {"id": 377, "seek": 208848, "start": 2089.2, "end": 2092.32, "text": " which then everything comes from that that's a very simple.", "tokens": [50400, 597, 550, 1203, 1487, 490, 300, 300, 311, 257, 588, 2199, 13, 50556], "temperature": 0.0, "avg_logprob": -0.10477169210260565, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.005908858496695757}, {"id": 378, "seek": 208848, "start": 2093.12, "end": 2099.52, "text": " This is really what happened. We were deep into problems about understanding how we build models", "tokens": [50596, 639, 307, 534, 437, 2011, 13, 492, 645, 2452, 666, 2740, 466, 3701, 577, 321, 1322, 5245, 50916], "temperature": 0.0, "avg_logprob": -0.10477169210260565, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.005908858496695757}, {"id": 379, "seek": 208848, "start": 2099.52, "end": 2105.28, "text": " of stuff in the world and how we make predictions about things. And I was holding a coffee cup just", "tokens": [50916, 295, 1507, 294, 264, 1002, 293, 577, 321, 652, 21264, 466, 721, 13, 400, 286, 390, 5061, 257, 4982, 4414, 445, 51204], "temperature": 0.0, "avg_logprob": -0.10477169210260565, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.005908858496695757}, {"id": 380, "seek": 208848, "start": 2105.28, "end": 2110.96, "text": " like this in my hand. And I had my finger was touching the side, my index finger. And then I", "tokens": [51204, 411, 341, 294, 452, 1011, 13, 400, 286, 632, 452, 5984, 390, 11175, 264, 1252, 11, 452, 8186, 5984, 13, 400, 550, 286, 51488], "temperature": 0.0, "avg_logprob": -0.10477169210260565, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.005908858496695757}, {"id": 381, "seek": 208848, "start": 2110.96, "end": 2116.56, "text": " moved it to the top. And I was going to feel the rim at the top of the cup. And I asked myself", "tokens": [51488, 4259, 309, 281, 264, 1192, 13, 400, 286, 390, 516, 281, 841, 264, 15982, 412, 264, 1192, 295, 264, 4414, 13, 400, 286, 2351, 2059, 51768], "temperature": 0.0, "avg_logprob": -0.10477169210260565, "compression_ratio": 1.7076923076923076, "no_speech_prob": 0.005908858496695757}, {"id": 382, "seek": 211656, "start": 2116.56, "end": 2121.2799999999997, "text": " a very simple question. I said, well, first of all, let's say I know that my brain predicts", "tokens": [50364, 257, 588, 2199, 1168, 13, 286, 848, 11, 731, 11, 700, 295, 439, 11, 718, 311, 584, 286, 458, 300, 452, 3567, 6069, 82, 50600], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 383, "seek": 211656, "start": 2121.2799999999997, "end": 2125.04, "text": " what it's going to feel before it touches it. You can just think about it and imagine it.", "tokens": [50600, 437, 309, 311, 516, 281, 841, 949, 309, 17431, 309, 13, 509, 393, 445, 519, 466, 309, 293, 3811, 309, 13, 50788], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 384, "seek": 211656, "start": 2125.92, "end": 2129.2, "text": " And so we know that the brain's making predictions all the time. So the question is,", "tokens": [50832, 400, 370, 321, 458, 300, 264, 3567, 311, 1455, 21264, 439, 264, 565, 13, 407, 264, 1168, 307, 11, 50996], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 385, "seek": 211656, "start": 2129.2, "end": 2132.88, "text": " what does it take to predict that? Right. And there's a very interesting answer.", "tokens": [50996, 437, 775, 309, 747, 281, 6069, 300, 30, 1779, 13, 400, 456, 311, 257, 588, 1880, 1867, 13, 51180], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 386, "seek": 211656, "start": 2133.44, "end": 2136.72, "text": " First of all, it says the brain has to know it's touching a coffee cup. It has to have", "tokens": [51208, 2386, 295, 439, 11, 309, 1619, 264, 3567, 575, 281, 458, 309, 311, 11175, 257, 4982, 4414, 13, 467, 575, 281, 362, 51372], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 387, "seek": 211656, "start": 2136.72, "end": 2142.32, "text": " a model of a coffee cup and needs to know where the finger currently is on the cup relative to", "tokens": [51372, 257, 2316, 295, 257, 4982, 4414, 293, 2203, 281, 458, 689, 264, 5984, 4362, 307, 322, 264, 4414, 4972, 281, 51652], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 388, "seek": 211656, "start": 2142.32, "end": 2146.32, "text": " the cup. Because when I make a movement, it needs to know where it's going to be on the cup", "tokens": [51652, 264, 4414, 13, 1436, 562, 286, 652, 257, 3963, 11, 309, 2203, 281, 458, 689, 309, 311, 516, 281, 312, 322, 264, 4414, 51852], "temperature": 0.0, "avg_logprob": -0.10381030451300685, "compression_ratio": 1.9107692307692308, "no_speech_prob": 0.0001488230045652017}, {"id": 389, "seek": 214632, "start": 2146.32, "end": 2152.0, "text": " after the movement is completed relative to the cup. And then it can make a prediction about", "tokens": [50364, 934, 264, 3963, 307, 7365, 4972, 281, 264, 4414, 13, 400, 550, 309, 393, 652, 257, 17630, 466, 50648], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 390, "seek": 214632, "start": 2152.0, "end": 2156.32, "text": " what it's going to sense. So this told me that the neocortex, which is making this prediction,", "tokens": [50648, 437, 309, 311, 516, 281, 2020, 13, 407, 341, 1907, 385, 300, 264, 408, 905, 36143, 11, 597, 307, 1455, 341, 17630, 11, 50864], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 391, "seek": 214632, "start": 2156.32, "end": 2160.96, "text": " needs to know that it's sensing it's touching a cup. And it needs to know the location of", "tokens": [50864, 2203, 281, 458, 300, 309, 311, 30654, 309, 311, 11175, 257, 4414, 13, 400, 309, 2203, 281, 458, 264, 4914, 295, 51096], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 392, "seek": 214632, "start": 2160.96, "end": 2165.04, "text": " my finger relative to that cup in a reference frame of the cup. It doesn't matter where the", "tokens": [51096, 452, 5984, 4972, 281, 300, 4414, 294, 257, 6408, 3920, 295, 264, 4414, 13, 467, 1177, 380, 1871, 689, 264, 51300], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 393, "seek": 214632, "start": 2165.04, "end": 2169.2000000000003, "text": " cup is relative to my body. It doesn't matter its orientation. None of that matters. It's", "tokens": [51300, 4414, 307, 4972, 281, 452, 1772, 13, 467, 1177, 380, 1871, 1080, 14764, 13, 14492, 295, 300, 7001, 13, 467, 311, 51508], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 394, "seek": 214632, "start": 2169.2000000000003, "end": 2173.04, "text": " where my finger is relative to the cup, which tells me then that the neocortex", "tokens": [51508, 689, 452, 5984, 307, 4972, 281, 264, 4414, 11, 597, 5112, 385, 550, 300, 264, 408, 905, 36143, 51700], "temperature": 0.0, "avg_logprob": -0.05262316597832574, "compression_ratio": 2.0456273764258555, "no_speech_prob": 5.649689046549611e-05}, {"id": 395, "seek": 217304, "start": 2173.6, "end": 2178.4, "text": " has a reference frame that's anchored to the cup. Because otherwise, I wouldn't be able to", "tokens": [50392, 575, 257, 6408, 3920, 300, 311, 12723, 2769, 281, 264, 4414, 13, 1436, 5911, 11, 286, 2759, 380, 312, 1075, 281, 50632], "temperature": 0.0, "avg_logprob": -0.10437903487891481, "compression_ratio": 1.9243697478991597, "no_speech_prob": 0.00043052827822975814}, {"id": 396, "seek": 217304, "start": 2178.4, "end": 2182.48, "text": " say the location and I wouldn't be able to predict my new location. And then we quickly,", "tokens": [50632, 584, 264, 4914, 293, 286, 2759, 380, 312, 1075, 281, 6069, 452, 777, 4914, 13, 400, 550, 321, 2661, 11, 50836], "temperature": 0.0, "avg_logprob": -0.10437903487891481, "compression_ratio": 1.9243697478991597, "no_speech_prob": 0.00043052827822975814}, {"id": 397, "seek": 217304, "start": 2182.48, "end": 2186.56, "text": " very instantly, you can say, well, every part of my skin could touch this cup. And therefore,", "tokens": [50836, 588, 13518, 11, 291, 393, 584, 11, 731, 11, 633, 644, 295, 452, 3178, 727, 2557, 341, 4414, 13, 400, 4412, 11, 51040], "temperature": 0.0, "avg_logprob": -0.10437903487891481, "compression_ratio": 1.9243697478991597, "no_speech_prob": 0.00043052827822975814}, {"id": 398, "seek": 217304, "start": 2186.56, "end": 2189.7599999999998, "text": " every part of my skin is making predictions and every part of my skin must have a reference frame", "tokens": [51040, 633, 644, 295, 452, 3178, 307, 1455, 21264, 293, 633, 644, 295, 452, 3178, 1633, 362, 257, 6408, 3920, 51200], "temperature": 0.0, "avg_logprob": -0.10437903487891481, "compression_ratio": 1.9243697478991597, "no_speech_prob": 0.00043052827822975814}, {"id": 399, "seek": 217304, "start": 2190.8, "end": 2198.24, "text": " that it's using to make predictions. So the big idea is that throughout the neocortex,", "tokens": [51252, 300, 309, 311, 1228, 281, 652, 21264, 13, 407, 264, 955, 1558, 307, 300, 3710, 264, 408, 905, 36143, 11, 51624], "temperature": 0.0, "avg_logprob": -0.10437903487891481, "compression_ratio": 1.9243697478991597, "no_speech_prob": 0.00043052827822975814}, {"id": 400, "seek": 219824, "start": 2198.3199999999997, "end": 2207.52, "text": " everything is being stored and referenced in reference frames. You can think of them like", "tokens": [50368, 1203, 307, 885, 12187, 293, 32734, 294, 6408, 12083, 13, 509, 393, 519, 295, 552, 411, 50828], "temperature": 0.0, "avg_logprob": -0.1194696595183516, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0017005637055262923}, {"id": 401, "seek": 219824, "start": 2207.52, "end": 2211.7599999999998, "text": " XYZ reference frames, but they're not like that. We know a lot about the neural mechanisms for", "tokens": [50828, 48826, 57, 6408, 12083, 11, 457, 436, 434, 406, 411, 300, 13, 492, 458, 257, 688, 466, 264, 18161, 15902, 337, 51040], "temperature": 0.0, "avg_logprob": -0.1194696595183516, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0017005637055262923}, {"id": 402, "seek": 219824, "start": 2211.7599999999998, "end": 2216.64, "text": " this. But the brain thinks in reference frames. And as an engineer, if you're an engineer,", "tokens": [51040, 341, 13, 583, 264, 3567, 7309, 294, 6408, 12083, 13, 400, 382, 364, 11403, 11, 498, 291, 434, 364, 11403, 11, 51284], "temperature": 0.0, "avg_logprob": -0.1194696595183516, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0017005637055262923}, {"id": 403, "seek": 219824, "start": 2216.64, "end": 2221.2, "text": " this is not surprising. You'd say, if I were to build a CAD model of the coffee cup, well,", "tokens": [51284, 341, 307, 406, 8830, 13, 509, 1116, 584, 11, 498, 286, 645, 281, 1322, 257, 41143, 2316, 295, 264, 4982, 4414, 11, 731, 11, 51512], "temperature": 0.0, "avg_logprob": -0.1194696595183516, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0017005637055262923}, {"id": 404, "seek": 219824, "start": 2221.2, "end": 2224.7999999999997, "text": " I would bring it up in some CAD software and I would assign some reference frame and say,", "tokens": [51512, 286, 576, 1565, 309, 493, 294, 512, 41143, 4722, 293, 286, 576, 6269, 512, 6408, 3920, 293, 584, 11, 51692], "temperature": 0.0, "avg_logprob": -0.1194696595183516, "compression_ratio": 1.8095238095238095, "no_speech_prob": 0.0017005637055262923}, {"id": 405, "seek": 222480, "start": 2224.88, "end": 2229.92, "text": " this features at this location and so on. But the idea that this is occurring throughout", "tokens": [50368, 341, 4122, 412, 341, 4914, 293, 370, 322, 13, 583, 264, 1558, 300, 341, 307, 18386, 3710, 50620], "temperature": 0.0, "avg_logprob": -0.09804149738793234, "compression_ratio": 1.9823008849557522, "no_speech_prob": 0.0008829142316244543}, {"id": 406, "seek": 222480, "start": 2229.92, "end": 2238.6400000000003, "text": " the neocortex everywhere, it was a novel idea. And then a zillion things fell into place after", "tokens": [50620, 264, 408, 905, 36143, 5315, 11, 309, 390, 257, 7613, 1558, 13, 400, 550, 257, 710, 11836, 721, 5696, 666, 1081, 934, 51056], "temperature": 0.0, "avg_logprob": -0.09804149738793234, "compression_ratio": 1.9823008849557522, "no_speech_prob": 0.0008829142316244543}, {"id": 407, "seek": 222480, "start": 2238.6400000000003, "end": 2242.96, "text": " that. A zillion. So now we think about the neocortex as processing information quite", "tokens": [51056, 300, 13, 316, 710, 11836, 13, 407, 586, 321, 519, 466, 264, 408, 905, 36143, 382, 9007, 1589, 1596, 51272], "temperature": 0.0, "avg_logprob": -0.09804149738793234, "compression_ratio": 1.9823008849557522, "no_speech_prob": 0.0008829142316244543}, {"id": 408, "seek": 222480, "start": 2242.96, "end": 2246.48, "text": " differently than we used to do it. We used to think about the neocortex as processing", "tokens": [51272, 7614, 813, 321, 1143, 281, 360, 309, 13, 492, 1143, 281, 519, 466, 264, 408, 905, 36143, 382, 9007, 51448], "temperature": 0.0, "avg_logprob": -0.09804149738793234, "compression_ratio": 1.9823008849557522, "no_speech_prob": 0.0008829142316244543}, {"id": 409, "seek": 222480, "start": 2246.48, "end": 2250.88, "text": " sensory data and extracting features from that sensory data and then extracting features from", "tokens": [51448, 27233, 1412, 293, 49844, 4122, 490, 300, 27233, 1412, 293, 550, 49844, 4122, 490, 51668], "temperature": 0.0, "avg_logprob": -0.09804149738793234, "compression_ratio": 1.9823008849557522, "no_speech_prob": 0.0008829142316244543}, {"id": 410, "seek": 225088, "start": 2250.88, "end": 2255.6800000000003, "text": " the features, very much like a deep learning network does today. But that's not how the brain", "tokens": [50364, 264, 4122, 11, 588, 709, 411, 257, 2452, 2539, 3209, 775, 965, 13, 583, 300, 311, 406, 577, 264, 3567, 50604], "temperature": 0.0, "avg_logprob": -0.09850851111455795, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0013667414896190166}, {"id": 411, "seek": 225088, "start": 2255.6800000000003, "end": 2261.36, "text": " works at all. The brain works by assigning everything, every input, everything to reference", "tokens": [50604, 1985, 412, 439, 13, 440, 3567, 1985, 538, 49602, 1203, 11, 633, 4846, 11, 1203, 281, 6408, 50888], "temperature": 0.0, "avg_logprob": -0.09850851111455795, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0013667414896190166}, {"id": 412, "seek": 225088, "start": 2261.36, "end": 2266.1600000000003, "text": " frames. And there are thousands, hundreds of thousands of them active at once in your neocortex.", "tokens": [50888, 12083, 13, 400, 456, 366, 5383, 11, 6779, 295, 5383, 295, 552, 4967, 412, 1564, 294, 428, 408, 905, 36143, 13, 51128], "temperature": 0.0, "avg_logprob": -0.09850851111455795, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0013667414896190166}, {"id": 413, "seek": 225088, "start": 2267.52, "end": 2271.6, "text": " It's a surprising thing to think about. But once you sort of internalize this, you understand", "tokens": [51196, 467, 311, 257, 8830, 551, 281, 519, 466, 13, 583, 1564, 291, 1333, 295, 6920, 1125, 341, 11, 291, 1223, 51400], "temperature": 0.0, "avg_logprob": -0.09850851111455795, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0013667414896190166}, {"id": 414, "seek": 225088, "start": 2271.6, "end": 2279.6800000000003, "text": " that it explains almost all the mysteries we've had about the structure. So one of the consequences", "tokens": [51400, 300, 309, 13948, 1920, 439, 264, 30785, 321, 600, 632, 466, 264, 3877, 13, 407, 472, 295, 264, 10098, 51804], "temperature": 0.0, "avg_logprob": -0.09850851111455795, "compression_ratio": 1.6879432624113475, "no_speech_prob": 0.0013667414896190166}, {"id": 415, "seek": 227968, "start": 2280.24, "end": 2285.6, "text": " of that is that every small part of the neocortex, say a millimeter square and there's 150,000 of", "tokens": [50392, 295, 300, 307, 300, 633, 1359, 644, 295, 264, 408, 905, 36143, 11, 584, 257, 17942, 3732, 293, 456, 311, 8451, 11, 1360, 295, 50660], "temperature": 0.0, "avg_logprob": -0.09758832978039253, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0004878264444414526}, {"id": 416, "seek": 227968, "start": 2285.6, "end": 2290.24, "text": " those. So it's about 150,000 square millimeters. If you take every little square millimeter of the", "tokens": [50660, 729, 13, 407, 309, 311, 466, 8451, 11, 1360, 3732, 24388, 13, 759, 291, 747, 633, 707, 3732, 17942, 295, 264, 50892], "temperature": 0.0, "avg_logprob": -0.09758832978039253, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0004878264444414526}, {"id": 417, "seek": 227968, "start": 2290.24, "end": 2295.12, "text": " cortex, it's got some input coming into it and it's going to have reference frames where it's", "tokens": [50892, 33312, 11, 309, 311, 658, 512, 4846, 1348, 666, 309, 293, 309, 311, 516, 281, 362, 6408, 12083, 689, 309, 311, 51136], "temperature": 0.0, "avg_logprob": -0.09758832978039253, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0004878264444414526}, {"id": 418, "seek": 227968, "start": 2295.12, "end": 2301.44, "text": " assigning that input to and each square millimeter can learn complete models of objects. So what do", "tokens": [51136, 49602, 300, 4846, 281, 293, 1184, 3732, 17942, 393, 1466, 3566, 5245, 295, 6565, 13, 407, 437, 360, 51452], "temperature": 0.0, "avg_logprob": -0.09758832978039253, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0004878264444414526}, {"id": 419, "seek": 227968, "start": 2301.44, "end": 2305.8399999999997, "text": " I mean by that? If I'm touching the coffee cup, well, if I just touch it in one place, I can't", "tokens": [51452, 286, 914, 538, 300, 30, 759, 286, 478, 11175, 264, 4982, 4414, 11, 731, 11, 498, 286, 445, 2557, 309, 294, 472, 1081, 11, 286, 393, 380, 51672], "temperature": 0.0, "avg_logprob": -0.09758832978039253, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.0004878264444414526}, {"id": 420, "seek": 230584, "start": 2305.84, "end": 2310.32, "text": " learn what this coffee cup is because I'm just feeling one part. But if I move it around the cup", "tokens": [50364, 1466, 437, 341, 4982, 4414, 307, 570, 286, 478, 445, 2633, 472, 644, 13, 583, 498, 286, 1286, 309, 926, 264, 4414, 50588], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 421, "seek": 230584, "start": 2310.88, "end": 2314.8, "text": " and touch it in different areas, I can build up a complete model of the cup because I'm now", "tokens": [50616, 293, 2557, 309, 294, 819, 3179, 11, 286, 393, 1322, 493, 257, 3566, 2316, 295, 264, 4414, 570, 286, 478, 586, 50812], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 422, "seek": 230584, "start": 2314.8, "end": 2318.56, "text": " filling in that three dimensional map, which is the coffee cup, I can say, oh, what am I feeling", "tokens": [50812, 10623, 294, 300, 1045, 18795, 4471, 11, 597, 307, 264, 4982, 4414, 11, 286, 393, 584, 11, 1954, 11, 437, 669, 286, 2633, 51000], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 423, "seek": 230584, "start": 2318.56, "end": 2321.76, "text": " at all these different locations? That's the basic idea. It's more complicated than that.", "tokens": [51000, 412, 439, 613, 819, 9253, 30, 663, 311, 264, 3875, 1558, 13, 467, 311, 544, 6179, 813, 300, 13, 51160], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 424, "seek": 230584, "start": 2322.88, "end": 2328.0, "text": " But so through time, and we talked about time earlier, through time, even a single column,", "tokens": [51216, 583, 370, 807, 565, 11, 293, 321, 2825, 466, 565, 3071, 11, 807, 565, 11, 754, 257, 2167, 7738, 11, 51472], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 425, "seek": 230584, "start": 2328.0, "end": 2331.52, "text": " which is only looking at or a single part of the cortex, it's only looking at a small part of the", "tokens": [51472, 597, 307, 787, 1237, 412, 420, 257, 2167, 644, 295, 264, 33312, 11, 309, 311, 787, 1237, 412, 257, 1359, 644, 295, 264, 51648], "temperature": 0.0, "avg_logprob": -0.10439537612485214, "compression_ratio": 1.9054054054054055, "no_speech_prob": 0.0023228004574775696}, {"id": 426, "seek": 233152, "start": 2331.52, "end": 2336.96, "text": " world can build up a complete model of an object. And so if you think about the part of the brain,", "tokens": [50364, 1002, 393, 1322, 493, 257, 3566, 2316, 295, 364, 2657, 13, 400, 370, 498, 291, 519, 466, 264, 644, 295, 264, 3567, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1151788825662727, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0012446664040908217}, {"id": 427, "seek": 233152, "start": 2336.96, "end": 2341.44, "text": " which is getting input from all my fingers, so there's spread across the top of your head here,", "tokens": [50636, 597, 307, 1242, 4846, 490, 439, 452, 7350, 11, 370, 456, 311, 3974, 2108, 264, 1192, 295, 428, 1378, 510, 11, 50860], "temperature": 0.0, "avg_logprob": -0.1151788825662727, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0012446664040908217}, {"id": 428, "seek": 233152, "start": 2341.44, "end": 2346.16, "text": " this is the somatosensory cortex, there's columns associated with all the different areas of my", "tokens": [50860, 341, 307, 264, 3307, 26818, 694, 827, 33312, 11, 456, 311, 13766, 6615, 365, 439, 264, 819, 3179, 295, 452, 51096], "temperature": 0.0, "avg_logprob": -0.1151788825662727, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0012446664040908217}, {"id": 429, "seek": 233152, "start": 2346.16, "end": 2352.72, "text": " skin. And what we believe is happening is that all of them are building models of this cup,", "tokens": [51096, 3178, 13, 400, 437, 321, 1697, 307, 2737, 307, 300, 439, 295, 552, 366, 2390, 5245, 295, 341, 4414, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1151788825662727, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0012446664040908217}, {"id": 430, "seek": 233152, "start": 2352.72, "end": 2357.68, "text": " every one of them, or things, not all building all, not every column or every part of the", "tokens": [51424, 633, 472, 295, 552, 11, 420, 721, 11, 406, 439, 2390, 439, 11, 406, 633, 7738, 420, 633, 644, 295, 264, 51672], "temperature": 0.0, "avg_logprob": -0.1151788825662727, "compression_ratio": 1.7878787878787878, "no_speech_prob": 0.0012446664040908217}, {"id": 431, "seek": 235768, "start": 2357.68, "end": 2363.7599999999998, "text": " cortex builds models of everything. But they're all building models of something. And so you have,", "tokens": [50364, 33312, 15182, 5245, 295, 1203, 13, 583, 436, 434, 439, 2390, 5245, 295, 746, 13, 400, 370, 291, 362, 11, 50668], "temperature": 0.0, "avg_logprob": -0.09691413911450811, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.0010984593536704779}, {"id": 432, "seek": 235768, "start": 2363.7599999999998, "end": 2369.04, "text": " so when I touch this cup with my hand, there are multiple models of the cup being invoked.", "tokens": [50668, 370, 562, 286, 2557, 341, 4414, 365, 452, 1011, 11, 456, 366, 3866, 5245, 295, 264, 4414, 885, 1048, 9511, 13, 50932], "temperature": 0.0, "avg_logprob": -0.09691413911450811, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.0010984593536704779}, {"id": 433, "seek": 235768, "start": 2369.04, "end": 2373.2799999999997, "text": " If I look at it with my eyes, there are again many models of the cup being invoked because each part", "tokens": [50932, 759, 286, 574, 412, 309, 365, 452, 2575, 11, 456, 366, 797, 867, 5245, 295, 264, 4414, 885, 1048, 9511, 570, 1184, 644, 51144], "temperature": 0.0, "avg_logprob": -0.09691413911450811, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.0010984593536704779}, {"id": 434, "seek": 235768, "start": 2373.2799999999997, "end": 2379.3599999999997, "text": " of the visual system, the brain doesn't process an image, that's a misleading idea. It's just like", "tokens": [51144, 295, 264, 5056, 1185, 11, 264, 3567, 1177, 380, 1399, 364, 3256, 11, 300, 311, 257, 36429, 1558, 13, 467, 311, 445, 411, 51448], "temperature": 0.0, "avg_logprob": -0.09691413911450811, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.0010984593536704779}, {"id": 435, "seek": 235768, "start": 2379.3599999999997, "end": 2382.3199999999997, "text": " your fingers touching the cup, so different parts of my retina are looking at different parts of the", "tokens": [51448, 428, 7350, 11175, 264, 4414, 11, 370, 819, 3166, 295, 452, 1533, 1426, 366, 1237, 412, 819, 3166, 295, 264, 51596], "temperature": 0.0, "avg_logprob": -0.09691413911450811, "compression_ratio": 1.8631178707224334, "no_speech_prob": 0.0010984593536704779}, {"id": 436, "seek": 238232, "start": 2382.32, "end": 2388.1600000000003, "text": " cup. And thousands and thousands of models of the cup are being invoked at once. And they're all", "tokens": [50364, 4414, 13, 400, 5383, 293, 5383, 295, 5245, 295, 264, 4414, 366, 885, 1048, 9511, 412, 1564, 13, 400, 436, 434, 439, 50656], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 437, "seek": 238232, "start": 2388.1600000000003, "end": 2390.96, "text": " voting with each other trying to figure out what's going on. So that's why we call it the", "tokens": [50656, 10419, 365, 1184, 661, 1382, 281, 2573, 484, 437, 311, 516, 322, 13, 407, 300, 311, 983, 321, 818, 309, 264, 50796], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 438, "seek": 238232, "start": 2390.96, "end": 2395.52, "text": " Thousand Brains Theory of Intelligence because there isn't one model of a cup. There are thousands", "tokens": [50796, 29852, 474, 4991, 1292, 29009, 295, 27274, 570, 456, 1943, 380, 472, 2316, 295, 257, 4414, 13, 821, 366, 5383, 51024], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 439, "seek": 238232, "start": 2395.52, "end": 2399.2000000000003, "text": " of models of this cup. There are thousands of models of your cell phone and about cameras and", "tokens": [51024, 295, 5245, 295, 341, 4414, 13, 821, 366, 5383, 295, 5245, 295, 428, 2815, 2593, 293, 466, 8622, 293, 51208], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 440, "seek": 238232, "start": 2399.2000000000003, "end": 2403.6800000000003, "text": " microphones and so on. It's a distributed modeling system, which is very different than", "tokens": [51208, 30495, 293, 370, 322, 13, 467, 311, 257, 12631, 15983, 1185, 11, 597, 307, 588, 819, 813, 51432], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 441, "seek": 238232, "start": 2403.6800000000003, "end": 2408.1600000000003, "text": " what people have thought about it. So that's a really compelling and interesting idea. I have two", "tokens": [51432, 437, 561, 362, 1194, 466, 309, 13, 407, 300, 311, 257, 534, 20050, 293, 1880, 1558, 13, 286, 362, 732, 51656], "temperature": 0.0, "avg_logprob": -0.09159339101690996, "compression_ratio": 1.9087837837837838, "no_speech_prob": 0.0020499301608651876}, {"id": 442, "seek": 240816, "start": 2408.16, "end": 2412.56, "text": " first questions. So one, on the ensemble part of everything coming together, you have these", "tokens": [50364, 700, 1651, 13, 407, 472, 11, 322, 264, 19492, 644, 295, 1203, 1348, 1214, 11, 291, 362, 613, 50584], "temperature": 0.0, "avg_logprob": -0.13363754650778023, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.006584823597222567}, {"id": 443, "seek": 240816, "start": 2412.56, "end": 2418.7999999999997, "text": " Thousand Brains, how do you know which one has done the best job of forming the cup?", "tokens": [50584, 29852, 474, 4991, 1292, 11, 577, 360, 291, 458, 597, 472, 575, 1096, 264, 1151, 1691, 295, 15745, 264, 4414, 30, 50896], "temperature": 0.0, "avg_logprob": -0.13363754650778023, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.006584823597222567}, {"id": 444, "seek": 240816, "start": 2418.7999999999997, "end": 2423.8399999999997, "text": " Great question. Let me try to explain. There's a problem that's known in neuroscience called the", "tokens": [50896, 3769, 1168, 13, 961, 385, 853, 281, 2903, 13, 821, 311, 257, 1154, 300, 311, 2570, 294, 42762, 1219, 264, 51148], "temperature": 0.0, "avg_logprob": -0.13363754650778023, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.006584823597222567}, {"id": 445, "seek": 240816, "start": 2423.8399999999997, "end": 2429.2799999999997, "text": " sensor fusion problem. And so the idea is something like, oh, the image comes from the eye. There's", "tokens": [51148, 10200, 23100, 1154, 13, 400, 370, 264, 1558, 307, 746, 411, 11, 1954, 11, 264, 3256, 1487, 490, 264, 3313, 13, 821, 311, 51420], "temperature": 0.0, "avg_logprob": -0.13363754650778023, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.006584823597222567}, {"id": 446, "seek": 240816, "start": 2429.2799999999997, "end": 2434.48, "text": " a picture on the retina and it gets projected to the neocortex. Oh, by now it's all sped out all", "tokens": [51420, 257, 3036, 322, 264, 1533, 1426, 293, 309, 2170, 26231, 281, 264, 408, 905, 36143, 13, 876, 11, 538, 586, 309, 311, 439, 637, 292, 484, 439, 51680], "temperature": 0.0, "avg_logprob": -0.13363754650778023, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.006584823597222567}, {"id": 447, "seek": 243448, "start": 2434.48, "end": 2438.96, "text": " over the place and it's kind of squirrely and distorted and pieces are all over the, you know,", "tokens": [50364, 670, 264, 1081, 293, 309, 311, 733, 295, 2339, 347, 265, 356, 293, 33431, 293, 3755, 366, 439, 670, 264, 11, 291, 458, 11, 50588], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 448, "seek": 243448, "start": 2438.96, "end": 2443.6, "text": " it doesn't look like a picture anymore. When does it all come back together again? Right?", "tokens": [50588, 309, 1177, 380, 574, 411, 257, 3036, 3602, 13, 1133, 775, 309, 439, 808, 646, 1214, 797, 30, 1779, 30, 50820], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 449, "seek": 243448, "start": 2443.6, "end": 2448.56, "text": " Or you might say, well, yes, but I also, I also have sounds or touches associated with the cup.", "tokens": [50820, 1610, 291, 1062, 584, 11, 731, 11, 2086, 11, 457, 286, 611, 11, 286, 611, 362, 3263, 420, 17431, 6615, 365, 264, 4414, 13, 51068], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 450, "seek": 243448, "start": 2448.56, "end": 2452.56, "text": " So I'm seeing the cup and touching the cup. How do they get combined together again?", "tokens": [51068, 407, 286, 478, 2577, 264, 4414, 293, 11175, 264, 4414, 13, 1012, 360, 436, 483, 9354, 1214, 797, 30, 51268], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 451, "seek": 243448, "start": 2452.56, "end": 2456.48, "text": " So this is called the sensor fusion problem as if all these disparate parts have to be brought", "tokens": [51268, 407, 341, 307, 1219, 264, 10200, 23100, 1154, 382, 498, 439, 613, 14548, 473, 3166, 362, 281, 312, 3038, 51464], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 452, "seek": 243448, "start": 2456.48, "end": 2462.4, "text": " together into one model someplace. That's the wrong idea. The right idea is that you get all", "tokens": [51464, 1214, 666, 472, 2316, 37126, 13, 663, 311, 264, 2085, 1558, 13, 440, 558, 1558, 307, 300, 291, 483, 439, 51760], "temperature": 0.0, "avg_logprob": -0.10244575228009906, "compression_ratio": 1.7173913043478262, "no_speech_prob": 0.005219184327870607}, {"id": 453, "seek": 246240, "start": 2462.4, "end": 2466.56, "text": " these guys voting. There's auditory models of the cup, there's visual models of the cup,", "tokens": [50364, 613, 1074, 10419, 13, 821, 311, 17748, 827, 5245, 295, 264, 4414, 11, 456, 311, 5056, 5245, 295, 264, 4414, 11, 50572], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 454, "seek": 246240, "start": 2466.56, "end": 2471.84, "text": " there's tactile models of the cup. In the vision system, there might be ones that are more focused", "tokens": [50572, 456, 311, 47319, 5245, 295, 264, 4414, 13, 682, 264, 5201, 1185, 11, 456, 1062, 312, 2306, 300, 366, 544, 5178, 50836], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 455, "seek": 246240, "start": 2471.84, "end": 2475.36, "text": " on black and white, one's version on color. It doesn't really matter. There's just thousands and", "tokens": [50836, 322, 2211, 293, 2418, 11, 472, 311, 3037, 322, 2017, 13, 467, 1177, 380, 534, 1871, 13, 821, 311, 445, 5383, 293, 51012], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 456, "seek": 246240, "start": 2475.36, "end": 2480.56, "text": " thousands of models of this cup and they vote. They don't actually come together in one spot.", "tokens": [51012, 5383, 295, 5245, 295, 341, 4414, 293, 436, 4740, 13, 814, 500, 380, 767, 808, 1214, 294, 472, 4008, 13, 51272], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 457, "seek": 246240, "start": 2480.56, "end": 2485.36, "text": " Just literally think of it this way. Imagine you have each column about the size of a little", "tokens": [51272, 1449, 3736, 519, 295, 309, 341, 636, 13, 11739, 291, 362, 1184, 7738, 466, 264, 2744, 295, 257, 707, 51512], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 458, "seek": 246240, "start": 2485.36, "end": 2489.84, "text": " piece of spaghetti, okay? Like a two and a half millimeters tall and about a millimeter in white.", "tokens": [51512, 2522, 295, 28556, 11, 1392, 30, 1743, 257, 732, 293, 257, 1922, 24388, 6764, 293, 466, 257, 17942, 294, 2418, 13, 51736], "temperature": 0.0, "avg_logprob": -0.11924222586811453, "compression_ratio": 1.8594771241830066, "no_speech_prob": 0.0007321535958908498}, {"id": 459, "seek": 248984, "start": 2489.84, "end": 2494.48, "text": " They're not physical like, but you can think of them that way. And each one's trying to guess", "tokens": [50364, 814, 434, 406, 4001, 411, 11, 457, 291, 393, 519, 295, 552, 300, 636, 13, 400, 1184, 472, 311, 1382, 281, 2041, 50596], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 460, "seek": 248984, "start": 2494.48, "end": 2498.4, "text": " what this thing is we're touching. Now they can, they can do a pretty good job if they're allowed", "tokens": [50596, 437, 341, 551, 307, 321, 434, 11175, 13, 823, 436, 393, 11, 436, 393, 360, 257, 1238, 665, 1691, 498, 436, 434, 4350, 50792], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 461, "seek": 248984, "start": 2498.4, "end": 2503.36, "text": " to move over time. So I can reach my hand into a black box and move my finger around an object", "tokens": [50792, 281, 1286, 670, 565, 13, 407, 286, 393, 2524, 452, 1011, 666, 257, 2211, 2424, 293, 1286, 452, 5984, 926, 364, 2657, 51040], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 462, "seek": 248984, "start": 2503.36, "end": 2508.1600000000003, "text": " and if I touch enough space, it's like, okay, I know what it is. But often we don't do that.", "tokens": [51040, 293, 498, 286, 2557, 1547, 1901, 11, 309, 311, 411, 11, 1392, 11, 286, 458, 437, 309, 307, 13, 583, 2049, 321, 500, 380, 360, 300, 13, 51280], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 463, "seek": 248984, "start": 2508.1600000000003, "end": 2511.52, "text": " Often I can just reach and grab something with my hand all at once and I get it. Or", "tokens": [51280, 20043, 286, 393, 445, 2524, 293, 4444, 746, 365, 452, 1011, 439, 412, 1564, 293, 286, 483, 309, 13, 1610, 51448], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 464, "seek": 248984, "start": 2511.52, "end": 2515.76, "text": " if I had to look through the world through a straw, so I'm only invoking one little column,", "tokens": [51448, 498, 286, 632, 281, 574, 807, 264, 1002, 807, 257, 10099, 11, 370, 286, 478, 787, 1048, 5953, 472, 707, 7738, 11, 51660], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 465, "seek": 248984, "start": 2515.76, "end": 2518.88, "text": " I can only see part of something because I have to move the straw around. But if I open my eyes", "tokens": [51660, 286, 393, 787, 536, 644, 295, 746, 570, 286, 362, 281, 1286, 264, 10099, 926, 13, 583, 498, 286, 1269, 452, 2575, 51816], "temperature": 0.0, "avg_logprob": -0.10954511576685412, "compression_ratio": 1.7738419618528611, "no_speech_prob": 0.001064901938661933}, {"id": 466, "seek": 251888, "start": 2518.88, "end": 2523.12, "text": " to see the whole thing at once. So what we think is going on is all these little pieces of spaghetti", "tokens": [50364, 281, 536, 264, 1379, 551, 412, 1564, 13, 407, 437, 321, 519, 307, 516, 322, 307, 439, 613, 707, 3755, 295, 28556, 50576], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 467, "seek": 251888, "start": 2523.12, "end": 2527.2000000000003, "text": " if you have all these little columns in the cortex or all trying to guess what it is that they're", "tokens": [50576, 498, 291, 362, 439, 613, 707, 13766, 294, 264, 33312, 420, 439, 1382, 281, 2041, 437, 309, 307, 300, 436, 434, 50780], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 468, "seek": 251888, "start": 2527.2000000000003, "end": 2532.32, "text": " sensing. They'll do a better guess if they have time and can move over time. So if I move my eyes", "tokens": [50780, 30654, 13, 814, 603, 360, 257, 1101, 2041, 498, 436, 362, 565, 293, 393, 1286, 670, 565, 13, 407, 498, 286, 1286, 452, 2575, 51036], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 469, "seek": 251888, "start": 2532.32, "end": 2537.76, "text": " or move my fingers, but if they don't, they have a, they have a poor guess. It's a, it's a probabilistic", "tokens": [51036, 420, 1286, 452, 7350, 11, 457, 498, 436, 500, 380, 11, 436, 362, 257, 11, 436, 362, 257, 4716, 2041, 13, 467, 311, 257, 11, 309, 311, 257, 31959, 3142, 51308], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 470, "seek": 251888, "start": 2537.76, "end": 2542.0, "text": " guess of what they might be touching. Now imagine they can post their probability", "tokens": [51308, 2041, 295, 437, 436, 1062, 312, 11175, 13, 823, 3811, 436, 393, 2183, 641, 8482, 51520], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 471, "seek": 251888, "start": 2542.88, "end": 2546.4, "text": " at the top of little piece of spaghetti, each one of them says, I think, and it's not really a", "tokens": [51564, 412, 264, 1192, 295, 707, 2522, 295, 28556, 11, 1184, 472, 295, 552, 1619, 11, 286, 519, 11, 293, 309, 311, 406, 534, 257, 51740], "temperature": 0.0, "avg_logprob": -0.10255194346110026, "compression_ratio": 1.9331103678929766, "no_speech_prob": 0.0010986573761329055}, {"id": 472, "seek": 254640, "start": 2546.4, "end": 2550.8, "text": " probability distribution. It's more like a set of possibilities in the brain. It doesn't work", "tokens": [50364, 8482, 7316, 13, 467, 311, 544, 411, 257, 992, 295, 12178, 294, 264, 3567, 13, 467, 1177, 380, 589, 50584], "temperature": 0.0, "avg_logprob": -0.11574478472693492, "compression_ratio": 1.875, "no_speech_prob": 0.00034596776822581887}, {"id": 473, "seek": 254640, "start": 2550.8, "end": 2555.36, "text": " as a probability distribution. It works as more like what we call a union. You could say, and one", "tokens": [50584, 382, 257, 8482, 7316, 13, 467, 1985, 382, 544, 411, 437, 321, 818, 257, 11671, 13, 509, 727, 584, 11, 293, 472, 50812], "temperature": 0.0, "avg_logprob": -0.11574478472693492, "compression_ratio": 1.875, "no_speech_prob": 0.00034596776822581887}, {"id": 474, "seek": 254640, "start": 2555.36, "end": 2560.8, "text": " column says, I think it could be a coffee cup soda can or a water bottle. And another column says,", "tokens": [50812, 7738, 1619, 11, 286, 519, 309, 727, 312, 257, 4982, 4414, 17192, 393, 420, 257, 1281, 7817, 13, 400, 1071, 7738, 1619, 11, 51084], "temperature": 0.0, "avg_logprob": -0.11574478472693492, "compression_ratio": 1.875, "no_speech_prob": 0.00034596776822581887}, {"id": 475, "seek": 254640, "start": 2560.8, "end": 2567.84, "text": " I think it could be a coffee cup or, you know, telephone or camera or whatever. Right. And all", "tokens": [51084, 286, 519, 309, 727, 312, 257, 4982, 4414, 420, 11, 291, 458, 11, 19800, 420, 2799, 420, 2035, 13, 1779, 13, 400, 439, 51436], "temperature": 0.0, "avg_logprob": -0.11574478472693492, "compression_ratio": 1.875, "no_speech_prob": 0.00034596776822581887}, {"id": 476, "seek": 254640, "start": 2567.84, "end": 2571.6800000000003, "text": " these guys are saying what they think it might be. And there's these long range connections in", "tokens": [51436, 613, 1074, 366, 1566, 437, 436, 519, 309, 1062, 312, 13, 400, 456, 311, 613, 938, 3613, 9271, 294, 51628], "temperature": 0.0, "avg_logprob": -0.11574478472693492, "compression_ratio": 1.875, "no_speech_prob": 0.00034596776822581887}, {"id": 477, "seek": 257168, "start": 2571.7599999999998, "end": 2577.6, "text": " certain layers in the cortex. So there's some layers in the, some cells types in each column", "tokens": [50368, 1629, 7914, 294, 264, 33312, 13, 407, 456, 311, 512, 7914, 294, 264, 11, 512, 5438, 3467, 294, 1184, 7738, 50660], "temperature": 0.0, "avg_logprob": -0.10354279663603184, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0018099090084433556}, {"id": 478, "seek": 257168, "start": 2577.6, "end": 2582.72, "text": " send the projections across the brain. And that's the voting occurs. And so there's a simple", "tokens": [50660, 2845, 264, 32371, 2108, 264, 3567, 13, 400, 300, 311, 264, 10419, 11843, 13, 400, 370, 456, 311, 257, 2199, 50916], "temperature": 0.0, "avg_logprob": -0.10354279663603184, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0018099090084433556}, {"id": 479, "seek": 257168, "start": 2582.72, "end": 2587.04, "text": " associative memory mechanism. We've, we've described this in a recent paper and we've modeled this", "tokens": [50916, 4180, 1166, 4675, 7513, 13, 492, 600, 11, 321, 600, 7619, 341, 294, 257, 5162, 3035, 293, 321, 600, 37140, 341, 51132], "temperature": 0.0, "avg_logprob": -0.10354279663603184, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0018099090084433556}, {"id": 480, "seek": 257168, "start": 2588.56, "end": 2594.16, "text": " that says they can all quickly settle on the only or the one best answer for all of them.", "tokens": [51208, 300, 1619, 436, 393, 439, 2661, 11852, 322, 264, 787, 420, 264, 472, 1151, 1867, 337, 439, 295, 552, 13, 51488], "temperature": 0.0, "avg_logprob": -0.10354279663603184, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0018099090084433556}, {"id": 481, "seek": 257168, "start": 2594.7999999999997, "end": 2599.04, "text": " If there is a single best answer, they all vote and say, yep, it's got to be the coffee cup.", "tokens": [51520, 759, 456, 307, 257, 2167, 1151, 1867, 11, 436, 439, 4740, 293, 584, 11, 18633, 11, 309, 311, 658, 281, 312, 264, 4982, 4414, 13, 51732], "temperature": 0.0, "avg_logprob": -0.10354279663603184, "compression_ratio": 1.7622641509433963, "no_speech_prob": 0.0018099090084433556}, {"id": 482, "seek": 259904, "start": 2599.04, "end": 2602.8, "text": " And at that point, they all know it's a coffee cup. And at that point, everyone acts as if it's", "tokens": [50364, 400, 412, 300, 935, 11, 436, 439, 458, 309, 311, 257, 4982, 4414, 13, 400, 412, 300, 935, 11, 1518, 10672, 382, 498, 309, 311, 50552], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 483, "seek": 259904, "start": 2602.8, "end": 2605.92, "text": " the coffee cup. They know it's a coffee, even though I've only seen one little piece of this", "tokens": [50552, 264, 4982, 4414, 13, 814, 458, 309, 311, 257, 4982, 11, 754, 1673, 286, 600, 787, 1612, 472, 707, 2522, 295, 341, 50708], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 484, "seek": 259904, "start": 2605.92, "end": 2610.08, "text": " world. I know it's a coffee cup I'm touching or I'm seeing or whatever. And so you can think of", "tokens": [50708, 1002, 13, 286, 458, 309, 311, 257, 4982, 4414, 286, 478, 11175, 420, 286, 478, 2577, 420, 2035, 13, 400, 370, 291, 393, 519, 295, 50916], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 485, "seek": 259904, "start": 2610.08, "end": 2613.92, "text": " all these columns are looking at different parts and different places, different sensory input,", "tokens": [50916, 439, 613, 13766, 366, 1237, 412, 819, 3166, 293, 819, 3190, 11, 819, 27233, 4846, 11, 51108], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 486, "seek": 259904, "start": 2613.92, "end": 2617.84, "text": " different locations. They're all different. But this layer that's doing the voting,", "tokens": [51108, 819, 9253, 13, 814, 434, 439, 819, 13, 583, 341, 4583, 300, 311, 884, 264, 10419, 11, 51304], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 487, "seek": 259904, "start": 2619.04, "end": 2623.2799999999997, "text": " that's, it solidifies. It's just like it crystallizes and says, oh, we all know what we're", "tokens": [51364, 300, 311, 11, 309, 5100, 11221, 13, 467, 311, 445, 411, 309, 31924, 5660, 293, 1619, 11, 1954, 11, 321, 439, 458, 437, 321, 434, 51576], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 488, "seek": 259904, "start": 2623.2799999999997, "end": 2627.52, "text": " doing. And so you don't bring these models together in one model, you just vote and there's a", "tokens": [51576, 884, 13, 400, 370, 291, 500, 380, 1565, 613, 5245, 1214, 294, 472, 2316, 11, 291, 445, 4740, 293, 456, 311, 257, 51788], "temperature": 0.0, "avg_logprob": -0.09689834004356748, "compression_ratio": 1.99079754601227, "no_speech_prob": 0.0006070318049751222}, {"id": 489, "seek": 262752, "start": 2627.52, "end": 2632.48, "text": " crystallization of the vote. Great. That's at least a compelling way to think about", "tokens": [50364, 31924, 2144, 295, 264, 4740, 13, 3769, 13, 663, 311, 412, 1935, 257, 20050, 636, 281, 519, 466, 50612], "temperature": 0.0, "avg_logprob": -0.13028107298181413, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008163441671058536}, {"id": 490, "seek": 262752, "start": 2634.24, "end": 2642.0, "text": " about the way you form a model of the world. Now, you talk about a coffee cup. Do you see this", "tokens": [50700, 466, 264, 636, 291, 1254, 257, 2316, 295, 264, 1002, 13, 823, 11, 291, 751, 466, 257, 4982, 4414, 13, 1144, 291, 536, 341, 51088], "temperature": 0.0, "avg_logprob": -0.13028107298181413, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008163441671058536}, {"id": 491, "seek": 262752, "start": 2642.0, "end": 2646.16, "text": " as far as I understand that you were proposing this as well, that this extends to much more than", "tokens": [51088, 382, 1400, 382, 286, 1223, 300, 291, 645, 29939, 341, 382, 731, 11, 300, 341, 26448, 281, 709, 544, 813, 51296], "temperature": 0.0, "avg_logprob": -0.13028107298181413, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008163441671058536}, {"id": 492, "seek": 262752, "start": 2646.16, "end": 2654.08, "text": " coffee cups? Yeah, it does. Or at least the physical world that expands to the world of concepts.", "tokens": [51296, 4982, 13381, 30, 865, 11, 309, 775, 13, 1610, 412, 1935, 264, 4001, 1002, 300, 33706, 281, 264, 1002, 295, 10392, 13, 51692], "temperature": 0.0, "avg_logprob": -0.13028107298181413, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0008163441671058536}, {"id": 493, "seek": 265408, "start": 2654.08, "end": 2659.04, "text": " Yeah, it does. And well, the first, the primary phase of evidence for that is that", "tokens": [50364, 865, 11, 309, 775, 13, 400, 731, 11, 264, 700, 11, 264, 6194, 5574, 295, 4467, 337, 300, 307, 300, 50612], "temperature": 0.0, "avg_logprob": -0.14219486302342907, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.00019715935923159122}, {"id": 494, "seek": 265408, "start": 2659.04, "end": 2663.7599999999998, "text": " the regions of the neocortex that are associated with language or high-level thought or mathematics", "tokens": [50612, 264, 10682, 295, 264, 408, 905, 36143, 300, 366, 6615, 365, 2856, 420, 1090, 12, 12418, 1194, 420, 18666, 50848], "temperature": 0.0, "avg_logprob": -0.14219486302342907, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.00019715935923159122}, {"id": 495, "seek": 265408, "start": 2663.7599999999998, "end": 2667.52, "text": " or things like that, they look like the regions of the neocortex that process vision and hearing", "tokens": [50848, 420, 721, 411, 300, 11, 436, 574, 411, 264, 10682, 295, 264, 408, 905, 36143, 300, 1399, 5201, 293, 4763, 51036], "temperature": 0.0, "avg_logprob": -0.14219486302342907, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.00019715935923159122}, {"id": 496, "seek": 265408, "start": 2667.52, "end": 2674.08, "text": " and touch. They don't look any different or they look only marginally different. And so one would", "tokens": [51036, 293, 2557, 13, 814, 500, 380, 574, 604, 819, 420, 436, 574, 787, 10270, 379, 819, 13, 400, 370, 472, 576, 51364], "temperature": 0.0, "avg_logprob": -0.14219486302342907, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.00019715935923159122}, {"id": 497, "seek": 265408, "start": 2674.08, "end": 2679.2799999999997, "text": " say, well, if Vernon Mountcastle, who proposed that all the parts of the neocortex do the same", "tokens": [51364, 584, 11, 731, 11, 498, 47516, 8426, 3734, 306, 11, 567, 10348, 300, 439, 264, 3166, 295, 264, 408, 905, 36143, 360, 264, 912, 51624], "temperature": 0.0, "avg_logprob": -0.14219486302342907, "compression_ratio": 1.8223938223938223, "no_speech_prob": 0.00019715935923159122}, {"id": 498, "seek": 267928, "start": 2679.28, "end": 2683.84, "text": " thing, if he's right, then the parts that are doing language or mathematics or physics", "tokens": [50364, 551, 11, 498, 415, 311, 558, 11, 550, 264, 3166, 300, 366, 884, 2856, 420, 18666, 420, 10649, 50592], "temperature": 0.0, "avg_logprob": -0.08299627638699715, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.002396438969299197}, {"id": 499, "seek": 267928, "start": 2684.48, "end": 2687.6000000000004, "text": " are working on the same principle. They must be working on the principle of reference frames.", "tokens": [50624, 366, 1364, 322, 264, 912, 8665, 13, 814, 1633, 312, 1364, 322, 264, 8665, 295, 6408, 12083, 13, 50780], "temperature": 0.0, "avg_logprob": -0.08299627638699715, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.002396438969299197}, {"id": 500, "seek": 267928, "start": 2688.48, "end": 2695.0400000000004, "text": " So that's a little odd thought. But of course, we had no prior idea how these things happen,", "tokens": [50824, 407, 300, 311, 257, 707, 7401, 1194, 13, 583, 295, 1164, 11, 321, 632, 572, 4059, 1558, 577, 613, 721, 1051, 11, 51152], "temperature": 0.0, "avg_logprob": -0.08299627638699715, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.002396438969299197}, {"id": 501, "seek": 267928, "start": 2695.0400000000004, "end": 2701.84, "text": " so let's go with that. And in our recent paper, we talked a little bit about that. I've been", "tokens": [51152, 370, 718, 311, 352, 365, 300, 13, 400, 294, 527, 5162, 3035, 11, 321, 2825, 257, 707, 857, 466, 300, 13, 286, 600, 668, 51492], "temperature": 0.0, "avg_logprob": -0.08299627638699715, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.002396438969299197}, {"id": 502, "seek": 267928, "start": 2701.84, "end": 2706.96, "text": " working on it more since. I have better ideas about it now. I'm sitting here very confident", "tokens": [51492, 1364, 322, 309, 544, 1670, 13, 286, 362, 1101, 3487, 466, 309, 586, 13, 286, 478, 3798, 510, 588, 6679, 51748], "temperature": 0.0, "avg_logprob": -0.08299627638699715, "compression_ratio": 1.708955223880597, "no_speech_prob": 0.002396438969299197}, {"id": 503, "seek": 270696, "start": 2707.04, "end": 2710.2400000000002, "text": " that that's what's happening. And I can give you some examples to help you think about that.", "tokens": [50368, 300, 300, 311, 437, 311, 2737, 13, 400, 286, 393, 976, 291, 512, 5110, 281, 854, 291, 519, 466, 300, 13, 50528], "temperature": 0.0, "avg_logprob": -0.1014988402689784, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.006690122652798891}, {"id": 504, "seek": 270696, "start": 2711.12, "end": 2714.2400000000002, "text": " It's not that we understand it completely, but I understand it better than I've described it", "tokens": [50572, 467, 311, 406, 300, 321, 1223, 309, 2584, 11, 457, 286, 1223, 309, 1101, 813, 286, 600, 7619, 309, 50728], "temperature": 0.0, "avg_logprob": -0.1014988402689784, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.006690122652798891}, {"id": 505, "seek": 270696, "start": 2714.2400000000002, "end": 2722.8, "text": " in any paper so far. But we did put that idea out there. It's a good place to start. And the", "tokens": [50728, 294, 604, 3035, 370, 1400, 13, 583, 321, 630, 829, 300, 1558, 484, 456, 13, 467, 311, 257, 665, 1081, 281, 722, 13, 400, 264, 51156], "temperature": 0.0, "avg_logprob": -0.1014988402689784, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.006690122652798891}, {"id": 506, "seek": 270696, "start": 2722.8, "end": 2726.7200000000003, "text": " evidence would suggest it's how it's happening. And then we can start tackling that problem one", "tokens": [51156, 4467, 576, 3402, 309, 311, 577, 309, 311, 2737, 13, 400, 550, 321, 393, 722, 34415, 300, 1154, 472, 51352], "temperature": 0.0, "avg_logprob": -0.1014988402689784, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.006690122652798891}, {"id": 507, "seek": 270696, "start": 2726.7200000000003, "end": 2730.08, "text": " piece at a time. What does it mean to do high-level thought? What does it mean to do language? How", "tokens": [51352, 2522, 412, 257, 565, 13, 708, 775, 309, 914, 281, 360, 1090, 12, 12418, 1194, 30, 708, 775, 309, 914, 281, 360, 2856, 30, 1012, 51520], "temperature": 0.0, "avg_logprob": -0.1014988402689784, "compression_ratio": 1.7649253731343284, "no_speech_prob": 0.006690122652798891}, {"id": 508, "seek": 273008, "start": 2730.08, "end": 2737.04, "text": " would that fit into a reference framework? I don't know if you could tell me if there's a", "tokens": [50364, 576, 300, 3318, 666, 257, 6408, 8388, 30, 286, 500, 380, 458, 498, 291, 727, 980, 385, 498, 456, 311, 257, 50712], "temperature": 0.0, "avg_logprob": -0.11891100039848915, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.026341009885072708}, {"id": 509, "seek": 273008, "start": 2737.04, "end": 2742.3199999999997, "text": " connection, but there's an app called Anki that helps you remember different concepts.", "tokens": [50712, 4984, 11, 457, 456, 311, 364, 724, 1219, 1107, 2984, 300, 3665, 291, 1604, 819, 10392, 13, 50976], "temperature": 0.0, "avg_logprob": -0.11891100039848915, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.026341009885072708}, {"id": 510, "seek": 273008, "start": 2742.3199999999997, "end": 2747.92, "text": " And they talk about a memory palace that helps you remember completely random concepts by", "tokens": [50976, 400, 436, 751, 466, 257, 4675, 15207, 300, 3665, 291, 1604, 2584, 4974, 10392, 538, 51256], "temperature": 0.0, "avg_logprob": -0.11891100039848915, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.026341009885072708}, {"id": 511, "seek": 273008, "start": 2748.88, "end": 2752.3199999999997, "text": " trying to put them in a physical space in your mind and putting them next to each other.", "tokens": [51304, 1382, 281, 829, 552, 294, 257, 4001, 1901, 294, 428, 1575, 293, 3372, 552, 958, 281, 1184, 661, 13, 51476], "temperature": 0.0, "avg_logprob": -0.11891100039848915, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.026341009885072708}, {"id": 512, "seek": 273008, "start": 2752.3199999999997, "end": 2756.56, "text": " It's called the method of loci. For some reason, that seems to work really well.", "tokens": [51476, 467, 311, 1219, 264, 3170, 295, 450, 537, 13, 1171, 512, 1778, 11, 300, 2544, 281, 589, 534, 731, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11891100039848915, "compression_ratio": 1.7098039215686274, "no_speech_prob": 0.026341009885072708}, {"id": 513, "seek": 275656, "start": 2757.52, "end": 2760.48, "text": " Now that's a very narrow kind of application of just remembering some facts.", "tokens": [50412, 823, 300, 311, 257, 588, 9432, 733, 295, 3861, 295, 445, 20719, 512, 9130, 13, 50560], "temperature": 0.0, "avg_logprob": -0.17151323954264322, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.007118055131286383}, {"id": 514, "seek": 275656, "start": 2760.48, "end": 2763.04, "text": " But that's a very, very telling one.", "tokens": [50560, 583, 300, 311, 257, 588, 11, 588, 3585, 472, 13, 50688], "temperature": 0.0, "avg_logprob": -0.17151323954264322, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.007118055131286383}, {"id": 515, "seek": 275656, "start": 2763.04, "end": 2769.04, "text": " Yes, exactly. So this seems like you're describing a mechanism why this seems to work.", "tokens": [50688, 1079, 11, 2293, 13, 407, 341, 2544, 411, 291, 434, 16141, 257, 7513, 983, 341, 2544, 281, 589, 13, 50988], "temperature": 0.0, "avg_logprob": -0.17151323954264322, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.007118055131286383}, {"id": 516, "seek": 275656, "start": 2769.04, "end": 2773.68, "text": " Yeah. So basically the way what we think is going on is all things you know,", "tokens": [50988, 865, 13, 407, 1936, 264, 636, 437, 321, 519, 307, 516, 322, 307, 439, 721, 291, 458, 11, 51220], "temperature": 0.0, "avg_logprob": -0.17151323954264322, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.007118055131286383}, {"id": 517, "seek": 275656, "start": 2773.68, "end": 2779.6, "text": " all concepts, all ideas, words, everything, you know, are stored in reference frames.", "tokens": [51220, 439, 10392, 11, 439, 3487, 11, 2283, 11, 1203, 11, 291, 458, 11, 366, 12187, 294, 6408, 12083, 13, 51516], "temperature": 0.0, "avg_logprob": -0.17151323954264322, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.007118055131286383}, {"id": 518, "seek": 277960, "start": 2780.4, "end": 2786.48, "text": " And so if you want to remember something, you have to basically navigate through a reference", "tokens": [50404, 400, 370, 498, 291, 528, 281, 1604, 746, 11, 291, 362, 281, 1936, 12350, 807, 257, 6408, 50708], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 519, "seek": 277960, "start": 2786.48, "end": 2790.3199999999997, "text": " frame the same way a rat navigates to a maven, the same way my finger rat navigates to this", "tokens": [50708, 3920, 264, 912, 636, 257, 5937, 7407, 1024, 281, 257, 463, 553, 11, 264, 912, 636, 452, 5984, 5937, 7407, 1024, 281, 341, 50900], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 520, "seek": 277960, "start": 2790.3199999999997, "end": 2796.0, "text": " coffee cup. You are moving through some space. And so if you have a random list of things you", "tokens": [50900, 4982, 4414, 13, 509, 366, 2684, 807, 512, 1901, 13, 400, 370, 498, 291, 362, 257, 4974, 1329, 295, 721, 291, 51184], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 521, "seek": 277960, "start": 2796.0, "end": 2800.48, "text": " would ask to remember, by assigning them to a reference frame, you've already know very well", "tokens": [51184, 576, 1029, 281, 1604, 11, 538, 49602, 552, 281, 257, 6408, 3920, 11, 291, 600, 1217, 458, 588, 731, 51408], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 522, "seek": 277960, "start": 2800.48, "end": 2805.04, "text": " to see your house, right? And the idea of the method of loci is you can say, okay, in my lobby,", "tokens": [51408, 281, 536, 428, 1782, 11, 558, 30, 400, 264, 1558, 295, 264, 3170, 295, 450, 537, 307, 291, 393, 584, 11, 1392, 11, 294, 452, 21067, 11, 51636], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 523, "seek": 277960, "start": 2805.04, "end": 2808.16, "text": " I'm going to put this thing. And then the bedroom, I put this one. I go down the hall,", "tokens": [51636, 286, 478, 516, 281, 829, 341, 551, 13, 400, 550, 264, 11211, 11, 286, 829, 341, 472, 13, 286, 352, 760, 264, 6500, 11, 51792], "temperature": 0.0, "avg_logprob": -0.13215543812718886, "compression_ratio": 1.8590604026845639, "no_speech_prob": 0.012237603776156902}, {"id": 524, "seek": 280816, "start": 2808.16, "end": 2812.24, "text": " I put this thing. And then you want to recall those facts or recall those things. You just walk", "tokens": [50364, 286, 829, 341, 551, 13, 400, 550, 291, 528, 281, 9901, 729, 9130, 420, 9901, 729, 721, 13, 509, 445, 1792, 50568], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 525, "seek": 280816, "start": 2812.24, "end": 2816.56, "text": " mentally, you walk through your house. You're mentally moving through a reference frame", "tokens": [50568, 17072, 11, 291, 1792, 807, 428, 1782, 13, 509, 434, 17072, 2684, 807, 257, 6408, 3920, 50784], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 526, "seek": 280816, "start": 2816.56, "end": 2820.64, "text": " that you already had. And that tells you there's two things that are really important about that.", "tokens": [50784, 300, 291, 1217, 632, 13, 400, 300, 5112, 291, 456, 311, 732, 721, 300, 366, 534, 1021, 466, 300, 13, 50988], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 527, "seek": 280816, "start": 2820.64, "end": 2825.52, "text": " It tells us the brain prefers to store things in reference frames. And that the method of", "tokens": [50988, 467, 5112, 505, 264, 3567, 44334, 281, 3531, 721, 294, 6408, 12083, 13, 400, 300, 264, 3170, 295, 51232], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 528, "seek": 280816, "start": 2825.52, "end": 2831.52, "text": " recalling things or thinking, if you will, is to move mentally through those reference frames.", "tokens": [51232, 9901, 278, 721, 420, 1953, 11, 498, 291, 486, 11, 307, 281, 1286, 17072, 807, 729, 6408, 12083, 13, 51532], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 529, "seek": 280816, "start": 2831.52, "end": 2834.72, "text": " You could move physically through some reference frames, like I could physically move through", "tokens": [51532, 509, 727, 1286, 9762, 807, 512, 6408, 12083, 11, 411, 286, 727, 9762, 1286, 807, 51692], "temperature": 0.0, "avg_logprob": -0.10783883226596243, "compression_ratio": 2.08955223880597, "no_speech_prob": 0.0004582683613989502}, {"id": 530, "seek": 283472, "start": 2834.72, "end": 2837.8399999999997, "text": " the reference frame of this coffee cup. I can also mentally move through the reference frame", "tokens": [50364, 264, 6408, 3920, 295, 341, 4982, 4414, 13, 286, 393, 611, 17072, 1286, 807, 264, 6408, 3920, 50520], "temperature": 0.0, "avg_logprob": -0.09629715629245923, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0005192526150494814}, {"id": 531, "seek": 283472, "start": 2837.8399999999997, "end": 2843.9199999999996, "text": " of the coffee cup, imagining me touching it. But I can also mentally move my house. And so now we", "tokens": [50520, 295, 264, 4982, 4414, 11, 27798, 385, 11175, 309, 13, 583, 286, 393, 611, 17072, 1286, 452, 1782, 13, 400, 370, 586, 321, 50824], "temperature": 0.0, "avg_logprob": -0.09629715629245923, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0005192526150494814}, {"id": 532, "seek": 283472, "start": 2843.9199999999996, "end": 2850.0, "text": " can ask yourself, are all concepts stored this way? There was some recent research using human", "tokens": [50824, 393, 1029, 1803, 11, 366, 439, 10392, 12187, 341, 636, 30, 821, 390, 512, 5162, 2132, 1228, 1952, 51128], "temperature": 0.0, "avg_logprob": -0.09629715629245923, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0005192526150494814}, {"id": 533, "seek": 283472, "start": 2850.0, "end": 2854.9599999999996, "text": " subjects in fMRI. And I'm going to apologize for not knowing the name of the scientists who did", "tokens": [51128, 13066, 294, 283, 44, 5577, 13, 400, 286, 478, 516, 281, 12328, 337, 406, 5276, 264, 1315, 295, 264, 7708, 567, 630, 51376], "temperature": 0.0, "avg_logprob": -0.09629715629245923, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0005192526150494814}, {"id": 534, "seek": 283472, "start": 2854.9599999999996, "end": 2861.8399999999997, "text": " this. But what they did is they put humans in this fMRI machine, which is one of these imaging", "tokens": [51376, 341, 13, 583, 437, 436, 630, 307, 436, 829, 6255, 294, 341, 283, 44, 5577, 3479, 11, 597, 307, 472, 295, 613, 25036, 51720], "temperature": 0.0, "avg_logprob": -0.09629715629245923, "compression_ratio": 1.7761194029850746, "no_speech_prob": 0.0005192526150494814}, {"id": 535, "seek": 286184, "start": 2861.84, "end": 2867.6800000000003, "text": " machines. And they gave the humans tasks to think about birds. So they had different types of birds", "tokens": [50364, 8379, 13, 400, 436, 2729, 264, 6255, 9608, 281, 519, 466, 9009, 13, 407, 436, 632, 819, 3467, 295, 9009, 50656], "temperature": 0.0, "avg_logprob": -0.11183114178412784, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.00016344808682333678}, {"id": 536, "seek": 286184, "start": 2867.6800000000003, "end": 2872.56, "text": " and birds that looked big and small and long necks and long legs, things like that. And what they", "tokens": [50656, 293, 9009, 300, 2956, 955, 293, 1359, 293, 938, 408, 2761, 293, 938, 5668, 11, 721, 411, 300, 13, 400, 437, 436, 50900], "temperature": 0.0, "avg_logprob": -0.11183114178412784, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.00016344808682333678}, {"id": 537, "seek": 286184, "start": 2872.56, "end": 2879.04, "text": " could tell from the fMRI was a very clever experiment. Get to tell when humans were thinking", "tokens": [50900, 727, 980, 490, 264, 283, 44, 5577, 390, 257, 588, 13494, 5120, 13, 3240, 281, 980, 562, 6255, 645, 1953, 51224], "temperature": 0.0, "avg_logprob": -0.11183114178412784, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.00016344808682333678}, {"id": 538, "seek": 286184, "start": 2879.04, "end": 2885.52, "text": " about the birds, that the birds, the knowledge of birds was arranged in a reference frame,", "tokens": [51224, 466, 264, 9009, 11, 300, 264, 9009, 11, 264, 3601, 295, 9009, 390, 18721, 294, 257, 6408, 3920, 11, 51548], "temperature": 0.0, "avg_logprob": -0.11183114178412784, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.00016344808682333678}, {"id": 539, "seek": 286184, "start": 2885.52, "end": 2890.2400000000002, "text": " similar to the ones that are used when you navigate in a room. These are called grid cells.", "tokens": [51548, 2531, 281, 264, 2306, 300, 366, 1143, 562, 291, 12350, 294, 257, 1808, 13, 1981, 366, 1219, 10748, 5438, 13, 51784], "temperature": 0.0, "avg_logprob": -0.11183114178412784, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.00016344808682333678}, {"id": 540, "seek": 289024, "start": 2890.24, "end": 2894.3199999999997, "text": " And there are grid cell-like patterns of activity in the neocortex when they do this.", "tokens": [50364, 400, 456, 366, 10748, 2815, 12, 4092, 8294, 295, 5191, 294, 264, 408, 905, 36143, 562, 436, 360, 341, 13, 50568], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 541, "seek": 289024, "start": 2895.2799999999997, "end": 2900.8799999999997, "text": " So it's a very clever experiment. And what it basically says is that even when you're thinking", "tokens": [50616, 407, 309, 311, 257, 588, 13494, 5120, 13, 400, 437, 309, 1936, 1619, 307, 300, 754, 562, 291, 434, 1953, 50896], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 542, "seek": 289024, "start": 2900.8799999999997, "end": 2904.56, "text": " about something abstract, and you're not really thinking about it as a reference frame,", "tokens": [50896, 466, 746, 12649, 11, 293, 291, 434, 406, 534, 1953, 466, 309, 382, 257, 6408, 3920, 11, 51080], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 543, "seek": 289024, "start": 2904.56, "end": 2908.16, "text": " it tells us the brain is actually using a reference frame. And it's using the same neural", "tokens": [51080, 309, 5112, 505, 264, 3567, 307, 767, 1228, 257, 6408, 3920, 13, 400, 309, 311, 1228, 264, 912, 18161, 51260], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 544, "seek": 289024, "start": 2908.16, "end": 2912.7999999999997, "text": " mechanisms. These grid cells are the basic same neural mechanisms that we propose that grid cells,", "tokens": [51260, 15902, 13, 1981, 10748, 5438, 366, 264, 3875, 912, 18161, 15902, 300, 321, 17421, 300, 10748, 5438, 11, 51492], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 545, "seek": 289024, "start": 2912.7999999999997, "end": 2917.2799999999997, "text": " which exist in the old part of the brain, the entirionic cortex, that that mechanism", "tokens": [51492, 597, 2514, 294, 264, 1331, 644, 295, 264, 3567, 11, 264, 948, 347, 313, 299, 33312, 11, 300, 300, 7513, 51716], "temperature": 0.0, "avg_logprob": -0.12459839135408401, "compression_ratio": 1.8885017421602788, "no_speech_prob": 0.00036820198874920607}, {"id": 546, "seek": 291728, "start": 2917.28, "end": 2922.5600000000004, "text": " is now similar mechanism is used throughout the neocortex. It's the same nature of preserve this", "tokens": [50364, 307, 586, 2531, 7513, 307, 1143, 3710, 264, 408, 905, 36143, 13, 467, 311, 264, 912, 3687, 295, 15665, 341, 50628], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 547, "seek": 291728, "start": 2922.5600000000004, "end": 2927.6800000000003, "text": " interesting way of creating reference frames. And so now they have empirical evidence that", "tokens": [50628, 1880, 636, 295, 4084, 6408, 12083, 13, 400, 370, 586, 436, 362, 31886, 4467, 300, 50884], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 548, "seek": 291728, "start": 2927.6800000000003, "end": 2932.1600000000003, "text": " when you think about concepts like birds, that you're using reference frames that are built on", "tokens": [50884, 562, 291, 519, 466, 10392, 411, 9009, 11, 300, 291, 434, 1228, 6408, 12083, 300, 366, 3094, 322, 51108], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 549, "seek": 291728, "start": 2932.1600000000003, "end": 2936.88, "text": " grid cells. So that's similar to the method of loci, but in this case, the birds are related so", "tokens": [51108, 10748, 5438, 13, 407, 300, 311, 2531, 281, 264, 3170, 295, 450, 537, 11, 457, 294, 341, 1389, 11, 264, 9009, 366, 4077, 370, 51344], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 550, "seek": 291728, "start": 2936.88, "end": 2940.32, "text": " that makes they create their own reference frame, which is consistent with bird space.", "tokens": [51344, 300, 1669, 436, 1884, 641, 1065, 6408, 3920, 11, 597, 307, 8398, 365, 5255, 1901, 13, 51516], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 551, "seek": 291728, "start": 2941.0400000000004, "end": 2944.7200000000003, "text": " And when you think about something, you go through that, you can make the same example.", "tokens": [51552, 400, 562, 291, 519, 466, 746, 11, 291, 352, 807, 300, 11, 291, 393, 652, 264, 912, 1365, 13, 51736], "temperature": 0.0, "avg_logprob": -0.10643725925021702, "compression_ratio": 1.8682432432432432, "no_speech_prob": 0.00017951968766283244}, {"id": 552, "seek": 294472, "start": 2944.72, "end": 2949.9199999999996, "text": " Let's take a math mathematics. Let's say you want to prove a conjecture. What is a conjecture?", "tokens": [50364, 961, 311, 747, 257, 5221, 18666, 13, 961, 311, 584, 291, 528, 281, 7081, 257, 416, 1020, 540, 13, 708, 307, 257, 416, 1020, 540, 30, 50624], "temperature": 0.0, "avg_logprob": -0.09434177692119892, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.000829497876111418}, {"id": 553, "seek": 294472, "start": 2949.9199999999996, "end": 2956.08, "text": " Conjecture is a statement you believe to be true, but you haven't proven it. And so it might be an", "tokens": [50624, 2656, 1020, 540, 307, 257, 5629, 291, 1697, 281, 312, 2074, 11, 457, 291, 2378, 380, 12785, 309, 13, 400, 370, 309, 1062, 312, 364, 50932], "temperature": 0.0, "avg_logprob": -0.09434177692119892, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.000829497876111418}, {"id": 554, "seek": 294472, "start": 2956.08, "end": 2961.12, "text": " equation. I want to show that this is equal to that. And you have some places you start with,", "tokens": [50932, 5367, 13, 286, 528, 281, 855, 300, 341, 307, 2681, 281, 300, 13, 400, 291, 362, 512, 3190, 291, 722, 365, 11, 51184], "temperature": 0.0, "avg_logprob": -0.09434177692119892, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.000829497876111418}, {"id": 555, "seek": 294472, "start": 2961.12, "end": 2965.04, "text": " you say, well, I know this is true, and I know this is true. And I think that maybe to get to", "tokens": [51184, 291, 584, 11, 731, 11, 286, 458, 341, 307, 2074, 11, 293, 286, 458, 341, 307, 2074, 13, 400, 286, 519, 300, 1310, 281, 483, 281, 51380], "temperature": 0.0, "avg_logprob": -0.09434177692119892, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.000829497876111418}, {"id": 556, "seek": 294472, "start": 2965.04, "end": 2969.8399999999997, "text": " the final proof, I need to go through some intermediate results. But I believe it's happening", "tokens": [51380, 264, 2572, 8177, 11, 286, 643, 281, 352, 807, 512, 19376, 3542, 13, 583, 286, 1697, 309, 311, 2737, 51620], "temperature": 0.0, "avg_logprob": -0.09434177692119892, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.000829497876111418}, {"id": 557, "seek": 296984, "start": 2970.6400000000003, "end": 2976.96, "text": " is literally these equations or these points are assigned to a reference frame, a mathematical", "tokens": [50404, 307, 3736, 613, 11787, 420, 613, 2793, 366, 13279, 281, 257, 6408, 3920, 11, 257, 18894, 50720], "temperature": 0.0, "avg_logprob": -0.07461995060004077, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.0028001228347420692}, {"id": 558, "seek": 296984, "start": 2976.96, "end": 2981.2000000000003, "text": " reference frame. And when you do mathematical operations, a simple one might be multiply or", "tokens": [50720, 6408, 3920, 13, 400, 562, 291, 360, 18894, 7705, 11, 257, 2199, 472, 1062, 312, 12972, 420, 50932], "temperature": 0.0, "avg_logprob": -0.07461995060004077, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.0028001228347420692}, {"id": 559, "seek": 296984, "start": 2981.2000000000003, "end": 2985.28, "text": " divide, but you might be able to transform or something else, that is like a movement in the", "tokens": [50932, 9845, 11, 457, 291, 1062, 312, 1075, 281, 4088, 420, 746, 1646, 11, 300, 307, 411, 257, 3963, 294, 264, 51136], "temperature": 0.0, "avg_logprob": -0.07461995060004077, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.0028001228347420692}, {"id": 560, "seek": 296984, "start": 2985.28, "end": 2991.6800000000003, "text": " reference frame of the math. And so you're literally trying to discover a path from one location to", "tokens": [51136, 6408, 3920, 295, 264, 5221, 13, 400, 370, 291, 434, 3736, 1382, 281, 4411, 257, 3100, 490, 472, 4914, 281, 51456], "temperature": 0.0, "avg_logprob": -0.07461995060004077, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.0028001228347420692}, {"id": 561, "seek": 296984, "start": 2991.6800000000003, "end": 2998.1600000000003, "text": " another location in a space of mathematics. And if you can get to these intermediate results,", "tokens": [51456, 1071, 4914, 294, 257, 1901, 295, 18666, 13, 400, 498, 291, 393, 483, 281, 613, 19376, 3542, 11, 51780], "temperature": 0.0, "avg_logprob": -0.07461995060004077, "compression_ratio": 1.8622047244094488, "no_speech_prob": 0.0028001228347420692}, {"id": 562, "seek": 299816, "start": 2998.16, "end": 3002.0, "text": " then you know your map is pretty good. And you know you're using the right operations.", "tokens": [50364, 550, 291, 458, 428, 4471, 307, 1238, 665, 13, 400, 291, 458, 291, 434, 1228, 264, 558, 7705, 13, 50556], "temperature": 0.0, "avg_logprob": -0.09342430348981891, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.0006461011944338679}, {"id": 563, "seek": 299816, "start": 3002.96, "end": 3008.0, "text": " Much of what we think about is solving hard problems, is designing the correct reference", "tokens": [50604, 12313, 295, 437, 321, 519, 466, 307, 12606, 1152, 2740, 11, 307, 14685, 264, 3006, 6408, 50856], "temperature": 0.0, "avg_logprob": -0.09342430348981891, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.0006461011944338679}, {"id": 564, "seek": 299816, "start": 3008.0, "end": 3012.3999999999996, "text": " frame for that problem, figuring out how to organize the information, and what behaviors", "tokens": [50856, 3920, 337, 300, 1154, 11, 15213, 484, 577, 281, 13859, 264, 1589, 11, 293, 437, 15501, 51076], "temperature": 0.0, "avg_logprob": -0.09342430348981891, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.0006461011944338679}, {"id": 565, "seek": 299816, "start": 3012.3999999999996, "end": 3018.8799999999997, "text": " I want to use in that space to get me there. Yeah, so if you dig in an idea of this reference", "tokens": [51076, 286, 528, 281, 764, 294, 300, 1901, 281, 483, 385, 456, 13, 865, 11, 370, 498, 291, 2528, 294, 364, 1558, 295, 341, 6408, 51400], "temperature": 0.0, "avg_logprob": -0.09342430348981891, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.0006461011944338679}, {"id": 566, "seek": 299816, "start": 3018.8799999999997, "end": 3023.92, "text": " frame, whether it's the math, you start a set of axioms to try to get to proving the conjecture.", "tokens": [51400, 3920, 11, 1968, 309, 311, 264, 5221, 11, 291, 722, 257, 992, 295, 6360, 72, 4785, 281, 853, 281, 483, 281, 27221, 264, 416, 1020, 540, 13, 51652], "temperature": 0.0, "avg_logprob": -0.09342430348981891, "compression_ratio": 1.6977611940298507, "no_speech_prob": 0.0006461011944338679}, {"id": 567, "seek": 302392, "start": 3024.64, "end": 3029.84, "text": " Can you try to describe, maybe take a step back, how you think of the reference frame in that", "tokens": [50400, 1664, 291, 853, 281, 6786, 11, 1310, 747, 257, 1823, 646, 11, 577, 291, 519, 295, 264, 6408, 3920, 294, 300, 50660], "temperature": 0.0, "avg_logprob": -0.12718445914132254, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.0024720963556319475}, {"id": 568, "seek": 302392, "start": 3029.84, "end": 3037.12, "text": " context? Is it the reference frame that the axioms are happy in? Is it the reference frame", "tokens": [50660, 4319, 30, 1119, 309, 264, 6408, 3920, 300, 264, 6360, 72, 4785, 366, 2055, 294, 30, 1119, 309, 264, 6408, 3920, 51024], "temperature": 0.0, "avg_logprob": -0.12718445914132254, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.0024720963556319475}, {"id": 569, "seek": 302392, "start": 3037.12, "end": 3043.04, "text": " that might contain everything? Is it a changing thing? So you have many, many reference frames.", "tokens": [51024, 300, 1062, 5304, 1203, 30, 1119, 309, 257, 4473, 551, 30, 407, 291, 362, 867, 11, 867, 6408, 12083, 13, 51320], "temperature": 0.0, "avg_logprob": -0.12718445914132254, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.0024720963556319475}, {"id": 570, "seek": 302392, "start": 3043.04, "end": 3046.48, "text": " I mean, in fact, the way the theory, the 1000 brain theory of intelligence says that every", "tokens": [51320, 286, 914, 11, 294, 1186, 11, 264, 636, 264, 5261, 11, 264, 9714, 3567, 5261, 295, 7599, 1619, 300, 633, 51492], "temperature": 0.0, "avg_logprob": -0.12718445914132254, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.0024720963556319475}, {"id": 571, "seek": 302392, "start": 3046.48, "end": 3050.48, "text": " single thing in the world has its own reference frame. So every word has its own reference", "tokens": [51492, 2167, 551, 294, 264, 1002, 575, 1080, 1065, 6408, 3920, 13, 407, 633, 1349, 575, 1080, 1065, 6408, 51692], "temperature": 0.0, "avg_logprob": -0.12718445914132254, "compression_ratio": 1.9743589743589745, "no_speech_prob": 0.0024720963556319475}, {"id": 572, "seek": 305048, "start": 3050.48, "end": 3055.68, "text": " frames. And we can talk about this, the mathematics work out, this is no problem for neurons to do", "tokens": [50364, 12083, 13, 400, 321, 393, 751, 466, 341, 11, 264, 18666, 589, 484, 11, 341, 307, 572, 1154, 337, 22027, 281, 360, 50624], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 573, "seek": 305048, "start": 3055.68, "end": 3059.92, "text": " this. But how many reference frames does the coffee cup have? Well, it's on a table. Remember,", "tokens": [50624, 341, 13, 583, 577, 867, 6408, 12083, 775, 264, 4982, 4414, 362, 30, 1042, 11, 309, 311, 322, 257, 3199, 13, 5459, 11, 50836], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 574, "seek": 305048, "start": 3060.72, "end": 3066.88, "text": " let's say you ask how many reference frames could the column in my finger that's touching the coffee", "tokens": [50876, 718, 311, 584, 291, 1029, 577, 867, 6408, 12083, 727, 264, 7738, 294, 452, 5984, 300, 311, 11175, 264, 4982, 51184], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 575, "seek": 305048, "start": 3066.88, "end": 3070.8, "text": " cup have? Because there are many, many copy, there are many, many models of coffee cups. So", "tokens": [51184, 4414, 362, 30, 1436, 456, 366, 867, 11, 867, 5055, 11, 456, 366, 867, 11, 867, 5245, 295, 4982, 13381, 13, 407, 51380], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 576, "seek": 305048, "start": 3070.8, "end": 3074.32, "text": " the coffee, there is no one model of coffee cup, there are many models of coffee cup. And you", "tokens": [51380, 264, 4982, 11, 456, 307, 572, 472, 2316, 295, 4982, 4414, 11, 456, 366, 867, 5245, 295, 4982, 4414, 13, 400, 291, 51556], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 577, "seek": 305048, "start": 3074.32, "end": 3078.56, "text": " could say, well, how many different things can my finger learn? Is this is the question you want", "tokens": [51556, 727, 584, 11, 731, 11, 577, 867, 819, 721, 393, 452, 5984, 1466, 30, 1119, 341, 307, 264, 1168, 291, 528, 51768], "temperature": 0.0, "avg_logprob": -0.16668801837497288, "compression_ratio": 2.03886925795053, "no_speech_prob": 0.015420562587678432}, {"id": 578, "seek": 307856, "start": 3078.56, "end": 3083.52, "text": " to ask? Imagine, I say every concept, every idea, everything you've ever know about that you can", "tokens": [50364, 281, 1029, 30, 11739, 11, 286, 584, 633, 3410, 11, 633, 1558, 11, 1203, 291, 600, 1562, 458, 466, 300, 291, 393, 50612], "temperature": 0.0, "avg_logprob": -0.10358323169355634, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.001206386019475758}, {"id": 579, "seek": 307856, "start": 3083.52, "end": 3089.2, "text": " say, I know that thing, it has a reference frame associated with it. And what we do when we build", "tokens": [50612, 584, 11, 286, 458, 300, 551, 11, 309, 575, 257, 6408, 3920, 6615, 365, 309, 13, 400, 437, 321, 360, 562, 321, 1322, 50896], "temperature": 0.0, "avg_logprob": -0.10358323169355634, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.001206386019475758}, {"id": 580, "seek": 307856, "start": 3089.2, "end": 3094.32, "text": " composite objects, we can we assign reference frames to points, another reference frame. So", "tokens": [50896, 25557, 6565, 11, 321, 393, 321, 6269, 6408, 12083, 281, 2793, 11, 1071, 6408, 3920, 13, 407, 51152], "temperature": 0.0, "avg_logprob": -0.10358323169355634, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.001206386019475758}, {"id": 581, "seek": 307856, "start": 3094.32, "end": 3099.44, "text": " my coffee cup has multiple components to it. It's got a limb, it's got a cylinder, it's got a handle.", "tokens": [51152, 452, 4982, 4414, 575, 3866, 6677, 281, 309, 13, 467, 311, 658, 257, 30390, 11, 309, 311, 658, 257, 17884, 11, 309, 311, 658, 257, 4813, 13, 51408], "temperature": 0.0, "avg_logprob": -0.10358323169355634, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.001206386019475758}, {"id": 582, "seek": 307856, "start": 3100.64, "end": 3104.72, "text": " And those things that have their own reference frames, and they're assigned to a master reference", "tokens": [51468, 400, 729, 721, 300, 362, 641, 1065, 6408, 12083, 11, 293, 436, 434, 13279, 281, 257, 4505, 6408, 51672], "temperature": 0.0, "avg_logprob": -0.10358323169355634, "compression_ratio": 1.8620689655172413, "no_speech_prob": 0.001206386019475758}, {"id": 583, "seek": 310472, "start": 3104.72, "end": 3108.64, "text": " frame, which is called this cup. And now I have this mental logo on it. Well, that's something", "tokens": [50364, 3920, 11, 597, 307, 1219, 341, 4414, 13, 400, 586, 286, 362, 341, 4973, 9699, 322, 309, 13, 1042, 11, 300, 311, 746, 50560], "temperature": 0.0, "avg_logprob": -0.1310921106182161, "compression_ratio": 1.8517110266159695, "no_speech_prob": 0.010324576869606972}, {"id": 584, "seek": 310472, "start": 3108.64, "end": 3112.3999999999996, "text": " that exists elsewhere in the world. It's its own thing. So it has its own reference frame. So we", "tokens": [50560, 300, 8198, 14517, 294, 264, 1002, 13, 467, 311, 1080, 1065, 551, 13, 407, 309, 575, 1080, 1065, 6408, 3920, 13, 407, 321, 50748], "temperature": 0.0, "avg_logprob": -0.1310921106182161, "compression_ratio": 1.8517110266159695, "no_speech_prob": 0.010324576869606972}, {"id": 585, "seek": 310472, "start": 3112.3999999999996, "end": 3118.64, "text": " now have to say, how can I assign the mental logo reference frame onto the cylinder or onto the coffee", "tokens": [50748, 586, 362, 281, 584, 11, 577, 393, 286, 6269, 264, 4973, 9699, 6408, 3920, 3911, 264, 17884, 420, 3911, 264, 4982, 51060], "temperature": 0.0, "avg_logprob": -0.1310921106182161, "compression_ratio": 1.8517110266159695, "no_speech_prob": 0.010324576869606972}, {"id": 586, "seek": 310472, "start": 3118.64, "end": 3125.52, "text": " cup? So it's all, we talked about this in the paper that came out in December of this last year.", "tokens": [51060, 4414, 30, 407, 309, 311, 439, 11, 321, 2825, 466, 341, 294, 264, 3035, 300, 1361, 484, 294, 7687, 295, 341, 1036, 1064, 13, 51404], "temperature": 0.0, "avg_logprob": -0.1310921106182161, "compression_ratio": 1.8517110266159695, "no_speech_prob": 0.010324576869606972}, {"id": 587, "seek": 310472, "start": 3126.7999999999997, "end": 3130.48, "text": " The idea of how you can assign reference frames to reference frames, how neurons could do this.", "tokens": [51468, 440, 1558, 295, 577, 291, 393, 6269, 6408, 12083, 281, 6408, 12083, 11, 577, 22027, 727, 360, 341, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1310921106182161, "compression_ratio": 1.8517110266159695, "no_speech_prob": 0.010324576869606972}, {"id": 588, "seek": 313048, "start": 3130.48, "end": 3135.6, "text": " So my question is, even though you mentioned reference frames a lot, I almost feel it's really", "tokens": [50364, 407, 452, 1168, 307, 11, 754, 1673, 291, 2835, 6408, 12083, 257, 688, 11, 286, 1920, 841, 309, 311, 534, 50620], "temperature": 0.0, "avg_logprob": -0.10955988100873745, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.00027366503491066396}, {"id": 589, "seek": 313048, "start": 3135.6, "end": 3141.44, "text": " useful to dig into how you think of what a reference frame is. I mean, it was already helpful for me", "tokens": [50620, 4420, 281, 2528, 666, 577, 291, 519, 295, 437, 257, 6408, 3920, 307, 13, 286, 914, 11, 309, 390, 1217, 4961, 337, 385, 50912], "temperature": 0.0, "avg_logprob": -0.10955988100873745, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.00027366503491066396}, {"id": 590, "seek": 313048, "start": 3141.44, "end": 3147.76, "text": " to understand that you think of reference frames as something there is a lot of. Okay, so let's just", "tokens": [50912, 281, 1223, 300, 291, 519, 295, 6408, 12083, 382, 746, 456, 307, 257, 688, 295, 13, 1033, 11, 370, 718, 311, 445, 51228], "temperature": 0.0, "avg_logprob": -0.10955988100873745, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.00027366503491066396}, {"id": 591, "seek": 313048, "start": 3147.76, "end": 3152.32, "text": " say that we're going to have some neurons in the brain, not many actually, 10,000, 20,000 are going", "tokens": [51228, 584, 300, 321, 434, 516, 281, 362, 512, 22027, 294, 264, 3567, 11, 406, 867, 767, 11, 1266, 11, 1360, 11, 945, 11, 1360, 366, 516, 51456], "temperature": 0.0, "avg_logprob": -0.10955988100873745, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.00027366503491066396}, {"id": 592, "seek": 313048, "start": 3152.32, "end": 3156.16, "text": " to create a whole bunch of reference frames. What does it mean? What is a reference frame?", "tokens": [51456, 281, 1884, 257, 1379, 3840, 295, 6408, 12083, 13, 708, 775, 309, 914, 30, 708, 307, 257, 6408, 3920, 30, 51648], "temperature": 0.0, "avg_logprob": -0.10955988100873745, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.00027366503491066396}, {"id": 593, "seek": 315616, "start": 3157.12, "end": 3161.12, "text": " First of all, these reference frames are different than the ones you might have", "tokens": [50412, 2386, 295, 439, 11, 613, 6408, 12083, 366, 819, 813, 264, 2306, 291, 1062, 362, 50612], "temperature": 0.0, "avg_logprob": -0.13393285895596033, "compression_ratio": 1.9913419913419914, "no_speech_prob": 0.0002868384763132781}, {"id": 594, "seek": 315616, "start": 3161.12, "end": 3165.52, "text": " be used to. We know lots of reference things. For example, we know the Cartesian coordinates,", "tokens": [50612, 312, 1143, 281, 13, 492, 458, 3195, 295, 6408, 721, 13, 1171, 1365, 11, 321, 458, 264, 22478, 42434, 21056, 11, 50832], "temperature": 0.0, "avg_logprob": -0.13393285895596033, "compression_ratio": 1.9913419913419914, "no_speech_prob": 0.0002868384763132781}, {"id": 595, "seek": 315616, "start": 3165.52, "end": 3170.7999999999997, "text": " x, y, z, that's a type of reference frame. We know longitude and latitude, that's a different type", "tokens": [50832, 2031, 11, 288, 11, 710, 11, 300, 311, 257, 2010, 295, 6408, 3920, 13, 492, 458, 938, 4377, 293, 45436, 11, 300, 311, 257, 819, 2010, 51096], "temperature": 0.0, "avg_logprob": -0.13393285895596033, "compression_ratio": 1.9913419913419914, "no_speech_prob": 0.0002868384763132781}, {"id": 596, "seek": 315616, "start": 3170.7999999999997, "end": 3179.04, "text": " of reference frame. If I look at a printed map, you might have columns a through m and rows,", "tokens": [51096, 295, 6408, 3920, 13, 759, 286, 574, 412, 257, 13567, 4471, 11, 291, 1062, 362, 13766, 257, 807, 275, 293, 13241, 11, 51508], "temperature": 0.0, "avg_logprob": -0.13393285895596033, "compression_ratio": 1.9913419913419914, "no_speech_prob": 0.0002868384763132781}, {"id": 597, "seek": 315616, "start": 3179.04, "end": 3182.64, "text": " you know, one through 20, that's a different type of reference frame. It's kind of a Cartesian", "tokens": [51508, 291, 458, 11, 472, 807, 945, 11, 300, 311, 257, 819, 2010, 295, 6408, 3920, 13, 467, 311, 733, 295, 257, 22478, 42434, 51688], "temperature": 0.0, "avg_logprob": -0.13393285895596033, "compression_ratio": 1.9913419913419914, "no_speech_prob": 0.0002868384763132781}, {"id": 598, "seek": 318264, "start": 3182.72, "end": 3187.8399999999997, "text": " reference frame. The interesting thing about the reference frames in the brain, we know this", "tokens": [50368, 6408, 3920, 13, 440, 1880, 551, 466, 264, 6408, 12083, 294, 264, 3567, 11, 321, 458, 341, 50624], "temperature": 0.0, "avg_logprob": -0.15627259606713648, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.0010319814318791032}, {"id": 599, "seek": 318264, "start": 3187.8399999999997, "end": 3192.16, "text": " because these have been established through neuroscience, studying the entorhonic cortex.", "tokens": [50624, 570, 613, 362, 668, 7545, 807, 42762, 11, 7601, 264, 948, 284, 71, 11630, 33312, 13, 50840], "temperature": 0.0, "avg_logprob": -0.15627259606713648, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.0010319814318791032}, {"id": 600, "seek": 318264, "start": 3192.16, "end": 3196.7999999999997, "text": " So I'm not speculating here. Okay, this is known neuroscience in an old part of the brain. The", "tokens": [50840, 407, 286, 478, 406, 1608, 12162, 510, 13, 1033, 11, 341, 307, 2570, 42762, 294, 364, 1331, 644, 295, 264, 3567, 13, 440, 51072], "temperature": 0.0, "avg_logprob": -0.15627259606713648, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.0010319814318791032}, {"id": 601, "seek": 318264, "start": 3196.7999999999997, "end": 3203.7599999999998, "text": " way these cells create reference frames, they have no origin. So what is more like you have a point,", "tokens": [51072, 636, 613, 5438, 1884, 6408, 12083, 11, 436, 362, 572, 4957, 13, 407, 437, 307, 544, 411, 291, 362, 257, 935, 11, 51420], "temperature": 0.0, "avg_logprob": -0.15627259606713648, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.0010319814318791032}, {"id": 602, "seek": 318264, "start": 3204.3199999999997, "end": 3210.72, "text": " a point in some space, and you given a particular movement, you can then tell what the next point", "tokens": [51448, 257, 935, 294, 512, 1901, 11, 293, 291, 2212, 257, 1729, 3963, 11, 291, 393, 550, 980, 437, 264, 958, 935, 51768], "temperature": 0.0, "avg_logprob": -0.15627259606713648, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.0010319814318791032}, {"id": 603, "seek": 321072, "start": 3210.72, "end": 3216.7999999999997, "text": " should be. And you can then tell what the next point would be and so on. You can use this to", "tokens": [50364, 820, 312, 13, 400, 291, 393, 550, 980, 437, 264, 958, 935, 576, 312, 293, 370, 322, 13, 509, 393, 764, 341, 281, 50668], "temperature": 0.0, "avg_logprob": -0.10244792699813843, "compression_ratio": 1.7890625, "no_speech_prob": 0.0016483089420944452}, {"id": 604, "seek": 321072, "start": 3218.16, "end": 3223.3599999999997, "text": " calculate how to get from one point to another. So how do I get from my house to my home, or how", "tokens": [50736, 8873, 577, 281, 483, 490, 472, 935, 281, 1071, 13, 407, 577, 360, 286, 483, 490, 452, 1782, 281, 452, 1280, 11, 420, 577, 50996], "temperature": 0.0, "avg_logprob": -0.10244792699813843, "compression_ratio": 1.7890625, "no_speech_prob": 0.0016483089420944452}, {"id": 605, "seek": 321072, "start": 3223.3599999999997, "end": 3228.3999999999996, "text": " do I get my finger from the side of my cup to the top of the cup? How do I get from the axioms to", "tokens": [50996, 360, 286, 483, 452, 5984, 490, 264, 1252, 295, 452, 4414, 281, 264, 1192, 295, 264, 4414, 30, 1012, 360, 286, 483, 490, 264, 6360, 72, 4785, 281, 51248], "temperature": 0.0, "avg_logprob": -0.10244792699813843, "compression_ratio": 1.7890625, "no_speech_prob": 0.0016483089420944452}, {"id": 606, "seek": 321072, "start": 3229.6, "end": 3236.08, "text": " the conjecture? So it's a different type of reference frame. And if you want, I can describe", "tokens": [51308, 264, 416, 1020, 540, 30, 407, 309, 311, 257, 819, 2010, 295, 6408, 3920, 13, 400, 498, 291, 528, 11, 286, 393, 6786, 51632], "temperature": 0.0, "avg_logprob": -0.10244792699813843, "compression_ratio": 1.7890625, "no_speech_prob": 0.0016483089420944452}, {"id": 607, "seek": 321072, "start": 3236.08, "end": 3239.6, "text": " in more detail, I can paint a picture how you might want to think about that.", "tokens": [51632, 294, 544, 2607, 11, 286, 393, 4225, 257, 3036, 577, 291, 1062, 528, 281, 519, 466, 300, 13, 51808], "temperature": 0.0, "avg_logprob": -0.10244792699813843, "compression_ratio": 1.7890625, "no_speech_prob": 0.0016483089420944452}, {"id": 608, "seek": 323960, "start": 3239.6, "end": 3247.04, "text": " It's really helpful to think it's something you can move through. Yeah. But is it helpful to think", "tokens": [50364, 467, 311, 534, 4961, 281, 519, 309, 311, 746, 291, 393, 1286, 807, 13, 865, 13, 583, 307, 309, 4961, 281, 519, 50736], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 609, "seek": 323960, "start": 3247.04, "end": 3252.16, "text": " of it as spatial in some sense, or is there something? No, it's definitely spatial. It's spatial", "tokens": [50736, 295, 309, 382, 23598, 294, 512, 2020, 11, 420, 307, 456, 746, 30, 883, 11, 309, 311, 2138, 23598, 13, 467, 311, 23598, 50992], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 610, "seek": 323960, "start": 3252.16, "end": 3256.4, "text": " in a mathematical sense. How many dimensions? Can it be a crazy number of dimensions? Well,", "tokens": [50992, 294, 257, 18894, 2020, 13, 1012, 867, 12819, 30, 1664, 309, 312, 257, 3219, 1230, 295, 12819, 30, 1042, 11, 51204], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 611, "seek": 323960, "start": 3256.4, "end": 3259.52, "text": " that's an interesting question. In the old part of the brain, the entorhonic cortex,", "tokens": [51204, 300, 311, 364, 1880, 1168, 13, 682, 264, 1331, 644, 295, 264, 3567, 11, 264, 948, 284, 71, 11630, 33312, 11, 51360], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 612, "seek": 323960, "start": 3260.16, "end": 3264.64, "text": " they studied rats. And initially, it looks like, oh, this is just two dimensional. It's like the", "tokens": [51392, 436, 9454, 25691, 13, 400, 9105, 11, 309, 1542, 411, 11, 1954, 11, 341, 307, 445, 732, 18795, 13, 467, 311, 411, 264, 51616], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 613, "seek": 323960, "start": 3264.64, "end": 3269.12, "text": " rat is in some box and a maze or whatever. And they know whether the rat is using these two", "tokens": [51616, 5937, 307, 294, 512, 2424, 293, 257, 33032, 420, 2035, 13, 400, 436, 458, 1968, 264, 5937, 307, 1228, 613, 732, 51840], "temperature": 0.0, "avg_logprob": -0.12225120597415501, "compression_ratio": 1.792332268370607, "no_speech_prob": 0.0010644827270880342}, {"id": 614, "seek": 326912, "start": 3269.12, "end": 3274.7999999999997, "text": " dimensional reference frames and know where it is in the maze. We said, okay, what about bats?", "tokens": [50364, 18795, 6408, 12083, 293, 458, 689, 309, 307, 294, 264, 33032, 13, 492, 848, 11, 1392, 11, 437, 466, 26943, 30, 50648], "temperature": 0.0, "avg_logprob": -0.12366372158652858, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0001488346024416387}, {"id": 615, "seek": 326912, "start": 3275.3599999999997, "end": 3280.0, "text": " That's a mammal. And they fly in three dimensional space. How do they do that? They seem to know", "tokens": [50676, 663, 311, 257, 49312, 13, 400, 436, 3603, 294, 1045, 18795, 1901, 13, 1012, 360, 436, 360, 300, 30, 814, 1643, 281, 458, 50908], "temperature": 0.0, "avg_logprob": -0.12366372158652858, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0001488346024416387}, {"id": 616, "seek": 326912, "start": 3280.0, "end": 3285.8399999999997, "text": " where they are. So this is a current area of active research. And it seems like somehow the", "tokens": [50908, 689, 436, 366, 13, 407, 341, 307, 257, 2190, 1859, 295, 4967, 2132, 13, 400, 309, 2544, 411, 6063, 264, 51200], "temperature": 0.0, "avg_logprob": -0.12366372158652858, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0001488346024416387}, {"id": 617, "seek": 326912, "start": 3285.8399999999997, "end": 3292.24, "text": " neurons in the entorhonic cortex can learn three dimensional space. We just, two members of our", "tokens": [51200, 22027, 294, 264, 948, 284, 71, 11630, 33312, 393, 1466, 1045, 18795, 1901, 13, 492, 445, 11, 732, 2679, 295, 527, 51520], "temperature": 0.0, "avg_logprob": -0.12366372158652858, "compression_ratio": 1.676991150442478, "no_speech_prob": 0.0001488346024416387}, {"id": 618, "seek": 329224, "start": 3292.24, "end": 3298.8799999999997, "text": " team, along with Ilef Fett from MIT, just released a paper this literally last week,", "tokens": [50364, 1469, 11, 2051, 365, 286, 306, 69, 479, 3093, 490, 13100, 11, 445, 4736, 257, 3035, 341, 3736, 1036, 1243, 11, 50696], "temperature": 0.0, "avg_logprob": -0.16567480948663527, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.036209896206855774}, {"id": 619, "seek": 329224, "start": 3299.4399999999996, "end": 3305.8399999999997, "text": " it's on bioarchive, where they show that you can, if you, the way these things work, and I won't get", "tokens": [50724, 309, 311, 322, 12198, 1178, 488, 11, 689, 436, 855, 300, 291, 393, 11, 498, 291, 11, 264, 636, 613, 721, 589, 11, 293, 286, 1582, 380, 483, 51044], "temperature": 0.0, "avg_logprob": -0.16567480948663527, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.036209896206855774}, {"id": 620, "seek": 329224, "start": 3305.8399999999997, "end": 3311.9199999999996, "text": " unless you want to, I won't get into the detail, but grid cells can represent any n dimensional", "tokens": [51044, 5969, 291, 528, 281, 11, 286, 1582, 380, 483, 666, 264, 2607, 11, 457, 10748, 5438, 393, 2906, 604, 297, 18795, 51348], "temperature": 0.0, "avg_logprob": -0.16567480948663527, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.036209896206855774}, {"id": 621, "seek": 329224, "start": 3311.9199999999996, "end": 3318.0, "text": " space. It's not inherently limited. You can think of it this way. If you had two dimensional,", "tokens": [51348, 1901, 13, 467, 311, 406, 27993, 5567, 13, 509, 393, 519, 295, 309, 341, 636, 13, 759, 291, 632, 732, 18795, 11, 51652], "temperature": 0.0, "avg_logprob": -0.16567480948663527, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.036209896206855774}, {"id": 622, "seek": 329224, "start": 3318.0, "end": 3321.6, "text": " the way it works is you had a bunch of two dimensional slices. That's the way these things", "tokens": [51652, 264, 636, 309, 1985, 307, 291, 632, 257, 3840, 295, 732, 18795, 19793, 13, 663, 311, 264, 636, 613, 721, 51832], "temperature": 0.0, "avg_logprob": -0.16567480948663527, "compression_ratio": 1.7518796992481203, "no_speech_prob": 0.036209896206855774}, {"id": 623, "seek": 332160, "start": 3321.6, "end": 3326.16, "text": " work. There's a whole bunch of two dimensional models. And you can just, you can slice up any", "tokens": [50364, 589, 13, 821, 311, 257, 1379, 3840, 295, 732, 18795, 5245, 13, 400, 291, 393, 445, 11, 291, 393, 13153, 493, 604, 50592], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 624, "seek": 332160, "start": 3326.16, "end": 3330.88, "text": " n dimensional space and with two dimensional projections. So, and you could have one dimensional", "tokens": [50592, 297, 18795, 1901, 293, 365, 732, 18795, 32371, 13, 407, 11, 293, 291, 727, 362, 472, 18795, 50828], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 625, "seek": 332160, "start": 3330.88, "end": 3334.64, "text": " models. It does. So there's, there's nothing inherent about the mathematics about the way", "tokens": [50828, 5245, 13, 467, 775, 13, 407, 456, 311, 11, 456, 311, 1825, 26387, 466, 264, 18666, 466, 264, 636, 51016], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 626, "seek": 332160, "start": 3334.64, "end": 3340.0, "text": " the neurons do this, which, which constrained the dimensionality of the space, which I think was", "tokens": [51016, 264, 22027, 360, 341, 11, 597, 11, 597, 38901, 264, 10139, 1860, 295, 264, 1901, 11, 597, 286, 519, 390, 51284], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 627, "seek": 332160, "start": 3340.0, "end": 3344.88, "text": " important. So obviously, I have a three dimensional map of this cup, maybe it's even more than that.", "tokens": [51284, 1021, 13, 407, 2745, 11, 286, 362, 257, 1045, 18795, 4471, 295, 341, 4414, 11, 1310, 309, 311, 754, 544, 813, 300, 13, 51528], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 628, "seek": 332160, "start": 3344.88, "end": 3349.52, "text": " I don't know. But it's clearly three dimensional map of the cup. I don't just have a projection of", "tokens": [51528, 286, 500, 380, 458, 13, 583, 309, 311, 4448, 1045, 18795, 4471, 295, 264, 4414, 13, 286, 500, 380, 445, 362, 257, 22743, 295, 51760], "temperature": 0.0, "avg_logprob": -0.10522847209902976, "compression_ratio": 1.9896551724137932, "no_speech_prob": 0.0004172770131845027}, {"id": 629, "seek": 334952, "start": 3349.52, "end": 3353.92, "text": " the cup. But when I think about birds or when I think about mathematics, perhaps it's more than", "tokens": [50364, 264, 4414, 13, 583, 562, 286, 519, 466, 9009, 420, 562, 286, 519, 466, 18666, 11, 4317, 309, 311, 544, 813, 50584], "temperature": 0.0, "avg_logprob": -0.11286194571133318, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0008691160473972559}, {"id": 630, "seek": 334952, "start": 3353.92, "end": 3362.0, "text": " three dimensions. Who knows? So in terms of each individual column building up more and more", "tokens": [50584, 1045, 12819, 13, 2102, 3255, 30, 407, 294, 2115, 295, 1184, 2609, 7738, 2390, 493, 544, 293, 544, 50988], "temperature": 0.0, "avg_logprob": -0.11286194571133318, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0008691160473972559}, {"id": 631, "seek": 334952, "start": 3362.0, "end": 3368.32, "text": " information over time, do you think that mechanism is well understood in your mind? You've proposed", "tokens": [50988, 1589, 670, 565, 11, 360, 291, 519, 300, 7513, 307, 731, 7320, 294, 428, 1575, 30, 509, 600, 10348, 51304], "temperature": 0.0, "avg_logprob": -0.11286194571133318, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0008691160473972559}, {"id": 632, "seek": 334952, "start": 3368.32, "end": 3374.64, "text": " a lot of architectures there. Is that a key piece or is it, is the big piece, the thousand brain", "tokens": [51304, 257, 688, 295, 6331, 1303, 456, 13, 1119, 300, 257, 2141, 2522, 420, 307, 309, 11, 307, 264, 955, 2522, 11, 264, 4714, 3567, 51620], "temperature": 0.0, "avg_logprob": -0.11286194571133318, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0008691160473972559}, {"id": 633, "seek": 334952, "start": 3375.36, "end": 3378.88, "text": " theory of intelligence, the ensemble of it all? Well, I think they're both big. I mean,", "tokens": [51656, 5261, 295, 7599, 11, 264, 19492, 295, 309, 439, 30, 1042, 11, 286, 519, 436, 434, 1293, 955, 13, 286, 914, 11, 51832], "temperature": 0.0, "avg_logprob": -0.11286194571133318, "compression_ratio": 1.6423611111111112, "no_speech_prob": 0.0008691160473972559}, {"id": 634, "seek": 337888, "start": 3378.96, "end": 3382.96, "text": " clearly the concept as a theorist, the concept that's most exciting, right?", "tokens": [50368, 4448, 264, 3410, 382, 257, 27423, 468, 11, 264, 3410, 300, 311, 881, 4670, 11, 558, 30, 50568], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 635, "seek": 337888, "start": 3382.96, "end": 3386.2400000000002, "text": " A high level concept. A high level concept. This is a totally new way of thinking about", "tokens": [50568, 316, 1090, 1496, 3410, 13, 316, 1090, 1496, 3410, 13, 639, 307, 257, 3879, 777, 636, 295, 1953, 466, 50732], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 636, "seek": 337888, "start": 3386.2400000000002, "end": 3390.6400000000003, "text": " how the near characteristics work. So that is appealing. It has all these ramifications.", "tokens": [50732, 577, 264, 2651, 10891, 589, 13, 407, 300, 307, 23842, 13, 467, 575, 439, 613, 10211, 7833, 13, 50952], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 637, "seek": 337888, "start": 3390.6400000000003, "end": 3394.88, "text": " And with that, as a framework for how the brain works, you can make all kinds of predictions", "tokens": [50952, 400, 365, 300, 11, 382, 257, 8388, 337, 577, 264, 3567, 1985, 11, 291, 393, 652, 439, 3685, 295, 21264, 51164], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 638, "seek": 337888, "start": 3394.88, "end": 3398.4, "text": " and solve all kinds of problems. Now we're trying to work through many of these details right now.", "tokens": [51164, 293, 5039, 439, 3685, 295, 2740, 13, 823, 321, 434, 1382, 281, 589, 807, 867, 295, 613, 4365, 558, 586, 13, 51340], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 639, "seek": 337888, "start": 3398.4, "end": 3402.56, "text": " Okay. How do the neurons actually do this? Well, it turns out, if you think about grid cells and", "tokens": [51340, 1033, 13, 1012, 360, 264, 22027, 767, 360, 341, 30, 1042, 11, 309, 4523, 484, 11, 498, 291, 519, 466, 10748, 5438, 293, 51548], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 640, "seek": 337888, "start": 3402.56, "end": 3406.2400000000002, "text": " place cells in the old parts of the brain, there's a lot that's known about them, but there's still", "tokens": [51548, 1081, 5438, 294, 264, 1331, 3166, 295, 264, 3567, 11, 456, 311, 257, 688, 300, 311, 2570, 466, 552, 11, 457, 456, 311, 920, 51732], "temperature": 0.0, "avg_logprob": -0.14128790022451668, "compression_ratio": 1.836676217765043, "no_speech_prob": 0.0002611653180792928}, {"id": 641, "seek": 340624, "start": 3406.24, "end": 3410.0, "text": " some mysteries. There's a lot of debate about exactly the details, how these work and what are", "tokens": [50364, 512, 30785, 13, 821, 311, 257, 688, 295, 7958, 466, 2293, 264, 4365, 11, 577, 613, 589, 293, 437, 366, 50552], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 642, "seek": 340624, "start": 3410.0, "end": 3414.0, "text": " the signs. And we have that still, that same level of detail, that same level of concern.", "tokens": [50552, 264, 7880, 13, 400, 321, 362, 300, 920, 11, 300, 912, 1496, 295, 2607, 11, 300, 912, 1496, 295, 3136, 13, 50752], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 643, "seek": 340624, "start": 3414.0, "end": 3420.4799999999996, "text": " What we spend here, most of our time doing is trying to make a very good list of the things", "tokens": [50752, 708, 321, 3496, 510, 11, 881, 295, 527, 565, 884, 307, 1382, 281, 652, 257, 588, 665, 1329, 295, 264, 721, 51076], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 644, "seek": 340624, "start": 3420.4799999999996, "end": 3425.52, "text": " we don't understand yet. That's the key part here. What are the constraints? It's not like,", "tokens": [51076, 321, 500, 380, 1223, 1939, 13, 663, 311, 264, 2141, 644, 510, 13, 708, 366, 264, 18491, 30, 467, 311, 406, 411, 11, 51328], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 645, "seek": 340624, "start": 3425.52, "end": 3429.7599999999998, "text": " oh, this seems to work. We're done. Now it's like, okay, it kind of works, but these are other things", "tokens": [51328, 1954, 11, 341, 2544, 281, 589, 13, 492, 434, 1096, 13, 823, 309, 311, 411, 11, 1392, 11, 309, 733, 295, 1985, 11, 457, 613, 366, 661, 721, 51540], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 646, "seek": 340624, "start": 3429.7599999999998, "end": 3434.8799999999997, "text": " we know what has to do and it's not doing those yet. I would say we're well on the way here.", "tokens": [51540, 321, 458, 437, 575, 281, 360, 293, 309, 311, 406, 884, 729, 1939, 13, 286, 576, 584, 321, 434, 731, 322, 264, 636, 510, 13, 51796], "temperature": 0.0, "avg_logprob": -0.11357783016405608, "compression_ratio": 1.7816455696202531, "no_speech_prob": 0.001454925979487598}, {"id": 647, "seek": 343488, "start": 3434.96, "end": 3442.2400000000002, "text": " We're not done yet. There's a lot of trickiness to this system, but the basic principles about how", "tokens": [50368, 492, 434, 406, 1096, 1939, 13, 821, 311, 257, 688, 295, 4282, 1324, 281, 341, 1185, 11, 457, 264, 3875, 9156, 466, 577, 50732], "temperature": 0.0, "avg_logprob": -0.09530004724725946, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.00032498870859853923}, {"id": 648, "seek": 343488, "start": 3442.2400000000002, "end": 3446.08, "text": " different layers in the neocortex are doing much of this, we understand,", "tokens": [50732, 819, 7914, 294, 264, 408, 905, 36143, 366, 884, 709, 295, 341, 11, 321, 1223, 11, 50924], "temperature": 0.0, "avg_logprob": -0.09530004724725946, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.00032498870859853923}, {"id": 649, "seek": 343488, "start": 3447.12, "end": 3449.84, "text": " but there's some fundamental parts that we don't understand as well.", "tokens": [50976, 457, 456, 311, 512, 8088, 3166, 300, 321, 500, 380, 1223, 382, 731, 13, 51112], "temperature": 0.0, "avg_logprob": -0.09530004724725946, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.00032498870859853923}, {"id": 650, "seek": 343488, "start": 3449.84, "end": 3455.6800000000003, "text": " So what would you say is one of the harder open problems or one of the ones that have been bothering", "tokens": [51112, 407, 437, 576, 291, 584, 307, 472, 295, 264, 6081, 1269, 2740, 420, 472, 295, 264, 2306, 300, 362, 668, 31432, 51404], "temperature": 0.0, "avg_logprob": -0.09530004724725946, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.00032498870859853923}, {"id": 651, "seek": 343488, "start": 3455.6800000000003, "end": 3460.8, "text": " you, keeping you up at night the most? Oh, well, right now, this is a detailed thing that wouldn't", "tokens": [51404, 291, 11, 5145, 291, 493, 412, 1818, 264, 881, 30, 876, 11, 731, 11, 558, 586, 11, 341, 307, 257, 9942, 551, 300, 2759, 380, 51660], "temperature": 0.0, "avg_logprob": -0.09530004724725946, "compression_ratio": 1.685823754789272, "no_speech_prob": 0.00032498870859853923}, {"id": 652, "seek": 346080, "start": 3460.8, "end": 3464.96, "text": " apply to most people, okay. But you want me to answer that question? Yeah, please.", "tokens": [50364, 3079, 281, 881, 561, 11, 1392, 13, 583, 291, 528, 385, 281, 1867, 300, 1168, 30, 865, 11, 1767, 13, 50572], "temperature": 0.0, "avg_logprob": -0.10494130505017998, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.002980571473017335}, {"id": 653, "seek": 346080, "start": 3466.0800000000004, "end": 3470.88, "text": " We've talked about, as if, oh, to predict what you're going to sense on this coffee cup, I need", "tokens": [50628, 492, 600, 2825, 466, 11, 382, 498, 11, 1954, 11, 281, 6069, 437, 291, 434, 516, 281, 2020, 322, 341, 4982, 4414, 11, 286, 643, 50868], "temperature": 0.0, "avg_logprob": -0.10494130505017998, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.002980571473017335}, {"id": 654, "seek": 346080, "start": 3470.88, "end": 3474.96, "text": " to know where my finger is going to be on the coffee cup. That is true, but it's insufficient.", "tokens": [50868, 281, 458, 689, 452, 5984, 307, 516, 281, 312, 322, 264, 4982, 4414, 13, 663, 307, 2074, 11, 457, 309, 311, 41709, 13, 51072], "temperature": 0.0, "avg_logprob": -0.10494130505017998, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.002980571473017335}, {"id": 655, "seek": 346080, "start": 3476.2400000000002, "end": 3480.2400000000002, "text": " Think about my finger touches the edge of the coffee cup. My finger can touch it at different", "tokens": [51136, 6557, 466, 452, 5984, 17431, 264, 4691, 295, 264, 4982, 4414, 13, 1222, 5984, 393, 2557, 309, 412, 819, 51336], "temperature": 0.0, "avg_logprob": -0.10494130505017998, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.002980571473017335}, {"id": 656, "seek": 346080, "start": 3480.2400000000002, "end": 3487.52, "text": " orientations. I can rotate my finger around here, and that doesn't change. I can make that prediction", "tokens": [51336, 8579, 763, 13, 286, 393, 13121, 452, 5984, 926, 510, 11, 293, 300, 1177, 380, 1319, 13, 286, 393, 652, 300, 17630, 51700], "temperature": 0.0, "avg_logprob": -0.10494130505017998, "compression_ratio": 1.7434944237918215, "no_speech_prob": 0.002980571473017335}, {"id": 657, "seek": 348752, "start": 3488.16, "end": 3492.16, "text": " and somehow, so it's not just the location. There's an orientation component of this as well.", "tokens": [50396, 293, 6063, 11, 370, 309, 311, 406, 445, 264, 4914, 13, 821, 311, 364, 14764, 6542, 295, 341, 382, 731, 13, 50596], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 658, "seek": 348752, "start": 3493.2, "end": 3496.88, "text": " This is known in the old part of the brain too. There's things called head direction cells, which", "tokens": [50648, 639, 307, 2570, 294, 264, 1331, 644, 295, 264, 3567, 886, 13, 821, 311, 721, 1219, 1378, 3513, 5438, 11, 597, 50832], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 659, "seek": 348752, "start": 3496.88, "end": 3501.52, "text": " way the rat is facing. It's the same kind of basic idea. So if my finger were a rat,", "tokens": [50832, 636, 264, 5937, 307, 7170, 13, 467, 311, 264, 912, 733, 295, 3875, 1558, 13, 407, 498, 452, 5984, 645, 257, 5937, 11, 51064], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 660, "seek": 348752, "start": 3502.16, "end": 3505.04, "text": " you know, in three dimensions, I have a three-dimensional orientation,", "tokens": [51096, 291, 458, 11, 294, 1045, 12819, 11, 286, 362, 257, 1045, 12, 18759, 14764, 11, 51240], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 661, "seek": 348752, "start": 3505.6, "end": 3508.64, "text": " and I have a three-dimensional location. If I was a rat, I would have a,", "tokens": [51268, 293, 286, 362, 257, 1045, 12, 18759, 4914, 13, 759, 286, 390, 257, 5937, 11, 286, 576, 362, 257, 11, 51420], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 662, "seek": 348752, "start": 3508.64, "end": 3511.92, "text": " I think of it as a two-dimensional location, a two-dimensional orientation, a one-dimensional", "tokens": [51420, 286, 519, 295, 309, 382, 257, 732, 12, 18759, 4914, 11, 257, 732, 12, 18759, 14764, 11, 257, 472, 12, 18759, 51584], "temperature": 0.0, "avg_logprob": -0.13545413547092014, "compression_ratio": 2.0, "no_speech_prob": 0.002631214912980795}, {"id": 663, "seek": 351192, "start": 3512.0, "end": 3518.7200000000003, "text": " orientation, like just which way is it facing. So how the two components work together, how it is", "tokens": [50368, 14764, 11, 411, 445, 597, 636, 307, 309, 7170, 13, 407, 577, 264, 732, 6677, 589, 1214, 11, 577, 309, 307, 50704], "temperature": 0.0, "avg_logprob": -0.1777164406246609, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.009855982847511768}, {"id": 664, "seek": 351192, "start": 3518.7200000000003, "end": 3528.48, "text": " that I combine orientation, the orientation of my sensor, as well as the location, is a tricky", "tokens": [50704, 300, 286, 10432, 14764, 11, 264, 14764, 295, 452, 10200, 11, 382, 731, 382, 264, 4914, 11, 307, 257, 12414, 51192], "temperature": 0.0, "avg_logprob": -0.1777164406246609, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.009855982847511768}, {"id": 665, "seek": 351192, "start": 3528.48, "end": 3535.6800000000003, "text": " problem, and I think I've made progress on it. So at a bigger version of that, the perspective is", "tokens": [51192, 1154, 11, 293, 286, 519, 286, 600, 1027, 4205, 322, 309, 13, 407, 412, 257, 3801, 3037, 295, 300, 11, 264, 4585, 307, 51552], "temperature": 0.0, "avg_logprob": -0.1777164406246609, "compression_ratio": 1.5846994535519126, "no_speech_prob": 0.009855982847511768}, {"id": 666, "seek": 353568, "start": 3535.68, "end": 3541.3599999999997, "text": " super interesting, but super specific. Yeah, I warned you. No, no, that's really good, but", "tokens": [50364, 1687, 1880, 11, 457, 1687, 2685, 13, 865, 11, 286, 21284, 291, 13, 883, 11, 572, 11, 300, 311, 534, 665, 11, 457, 50648], "temperature": 0.0, "avg_logprob": -0.15911583427910334, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.20914846658706665}, {"id": 667, "seek": 353568, "start": 3542.08, "end": 3547.8399999999997, "text": " there's a more general version of that. Do you think context matters? The fact that we are", "tokens": [50684, 456, 311, 257, 544, 2674, 3037, 295, 300, 13, 1144, 291, 519, 4319, 7001, 30, 440, 1186, 300, 321, 366, 50972], "temperature": 0.0, "avg_logprob": -0.15911583427910334, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.20914846658706665}, {"id": 668, "seek": 353568, "start": 3548.3999999999996, "end": 3556.16, "text": " in a building in North America, that we, in the day and age where we have mugs, I mean,", "tokens": [51000, 294, 257, 2390, 294, 4067, 3374, 11, 300, 321, 11, 294, 264, 786, 293, 3205, 689, 321, 362, 275, 14950, 11, 286, 914, 11, 51388], "temperature": 0.0, "avg_logprob": -0.15911583427910334, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.20914846658706665}, {"id": 669, "seek": 353568, "start": 3557.12, "end": 3560.64, "text": " there's all this extra information that you bring to the table about", "tokens": [51436, 456, 311, 439, 341, 2857, 1589, 300, 291, 1565, 281, 264, 3199, 466, 51612], "temperature": 0.0, "avg_logprob": -0.15911583427910334, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.20914846658706665}, {"id": 670, "seek": 353568, "start": 3561.3599999999997, "end": 3564.56, "text": " everything else in the room that's outside of just the coffee cup. Of course it is.", "tokens": [51648, 1203, 1646, 294, 264, 1808, 300, 311, 2380, 295, 445, 264, 4982, 4414, 13, 2720, 1164, 309, 307, 13, 51808], "temperature": 0.0, "avg_logprob": -0.15911583427910334, "compression_ratio": 1.5924528301886793, "no_speech_prob": 0.20914846658706665}, {"id": 671, "seek": 356456, "start": 3564.56, "end": 3570.24, "text": " How does it get connected, do you think? Yeah, and that is another really interesting question.", "tokens": [50364, 1012, 775, 309, 483, 4582, 11, 360, 291, 519, 30, 865, 11, 293, 300, 307, 1071, 534, 1880, 1168, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 672, "seek": 356456, "start": 3570.24, "end": 3575.2799999999997, "text": " I'm going to throw that under the rubric or the name of attentional problems. First of all,", "tokens": [50648, 286, 478, 516, 281, 3507, 300, 833, 264, 5915, 1341, 420, 264, 1315, 295, 3202, 304, 2740, 13, 2386, 295, 439, 11, 50900], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 673, "seek": 356456, "start": 3575.2799999999997, "end": 3579.92, "text": " we have this model. I have many, many models. And also the question, does it matter because...", "tokens": [50900, 321, 362, 341, 2316, 13, 286, 362, 867, 11, 867, 5245, 13, 400, 611, 264, 1168, 11, 775, 309, 1871, 570, 485, 51132], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 674, "seek": 356456, "start": 3579.92, "end": 3584.64, "text": " Well, it matters for certain things. Of course it does. Maybe what we think of that as a coffee", "tokens": [51132, 1042, 11, 309, 7001, 337, 1629, 721, 13, 2720, 1164, 309, 775, 13, 2704, 437, 321, 519, 295, 300, 382, 257, 4982, 51368], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 675, "seek": 356456, "start": 3584.64, "end": 3588.32, "text": " cup in another part of the world is viewed as something completely different, or maybe our", "tokens": [51368, 4414, 294, 1071, 644, 295, 264, 1002, 307, 19174, 382, 746, 2584, 819, 11, 420, 1310, 527, 51552], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 676, "seek": 356456, "start": 3588.32, "end": 3592.48, "text": " logo, which is very benign in this part of the world, it means something very different in", "tokens": [51552, 9699, 11, 597, 307, 588, 3271, 788, 294, 341, 644, 295, 264, 1002, 11, 309, 1355, 746, 588, 819, 294, 51760], "temperature": 0.0, "avg_logprob": -0.13639962412145015, "compression_ratio": 1.78343949044586, "no_speech_prob": 0.0017536487430334091}, {"id": 677, "seek": 359248, "start": 3592.48, "end": 3599.2, "text": " another part of the world. So those things do matter. I think the way to think about this", "tokens": [50364, 1071, 644, 295, 264, 1002, 13, 407, 729, 721, 360, 1871, 13, 286, 519, 264, 636, 281, 519, 466, 341, 50700], "temperature": 0.0, "avg_logprob": -0.12812965288074737, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0004727649502456188}, {"id": 678, "seek": 359248, "start": 3599.2, "end": 3603.12, "text": " the following, or one way to think about it, is we have all these models of the world.", "tokens": [50700, 264, 3480, 11, 420, 472, 636, 281, 519, 466, 309, 11, 307, 321, 362, 439, 613, 5245, 295, 264, 1002, 13, 50896], "temperature": 0.0, "avg_logprob": -0.12812965288074737, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0004727649502456188}, {"id": 679, "seek": 359248, "start": 3604.64, "end": 3608.8, "text": " And we model everything. And as I said earlier, I kind of snuck it in there.", "tokens": [50972, 400, 321, 2316, 1203, 13, 400, 382, 286, 848, 3071, 11, 286, 733, 295, 2406, 1134, 309, 294, 456, 13, 51180], "temperature": 0.0, "avg_logprob": -0.12812965288074737, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0004727649502456188}, {"id": 680, "seek": 359248, "start": 3608.8, "end": 3614.88, "text": " Our models are actually, we build composite structure. So every object is composed of other", "tokens": [51180, 2621, 5245, 366, 767, 11, 321, 1322, 25557, 3877, 13, 407, 633, 2657, 307, 18204, 295, 661, 51484], "temperature": 0.0, "avg_logprob": -0.12812965288074737, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0004727649502456188}, {"id": 681, "seek": 359248, "start": 3614.88, "end": 3618.96, "text": " objects, which are composed of other objects, and they become members of other objects. So this", "tokens": [51484, 6565, 11, 597, 366, 18204, 295, 661, 6565, 11, 293, 436, 1813, 2679, 295, 661, 6565, 13, 407, 341, 51688], "temperature": 0.0, "avg_logprob": -0.12812965288074737, "compression_ratio": 1.9090909090909092, "no_speech_prob": 0.0004727649502456188}, {"id": 682, "seek": 361896, "start": 3618.96, "end": 3623.84, "text": " room has chairs and a table and a room and walls and so on. Now we can just arrange these things", "tokens": [50364, 1808, 575, 18299, 293, 257, 3199, 293, 257, 1808, 293, 7920, 293, 370, 322, 13, 823, 321, 393, 445, 9424, 613, 721, 50608], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 683, "seek": 361896, "start": 3623.84, "end": 3630.56, "text": " in a certain way. You go, oh, that's in the romantic conference room. And what we do is,", "tokens": [50608, 294, 257, 1629, 636, 13, 509, 352, 11, 1954, 11, 300, 311, 294, 264, 13590, 7586, 1808, 13, 400, 437, 321, 360, 307, 11, 50944], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 684, "seek": 361896, "start": 3630.56, "end": 3636.2400000000002, "text": " when we go around the world and we experience the world, by walking into a room, for example,", "tokens": [50944, 562, 321, 352, 926, 264, 1002, 293, 321, 1752, 264, 1002, 11, 538, 4494, 666, 257, 1808, 11, 337, 1365, 11, 51228], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 685, "seek": 361896, "start": 3636.2400000000002, "end": 3639.2, "text": " the first thing I do is say, oh, I'm in this room. Do I recognize the room?", "tokens": [51228, 264, 700, 551, 286, 360, 307, 584, 11, 1954, 11, 286, 478, 294, 341, 1808, 13, 1144, 286, 5521, 264, 1808, 30, 51376], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 686, "seek": 361896, "start": 3639.2, "end": 3644.0, "text": " Then I can say, oh, look, there's a table here. And by attending to the table,", "tokens": [51376, 1396, 286, 393, 584, 11, 1954, 11, 574, 11, 456, 311, 257, 3199, 510, 13, 400, 538, 15862, 281, 264, 3199, 11, 51616], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 687, "seek": 361896, "start": 3644.0, "end": 3647.12, "text": " I'm then assigning this table in the context of the room. Then I say, oh, on the table,", "tokens": [51616, 286, 478, 550, 49602, 341, 3199, 294, 264, 4319, 295, 264, 1808, 13, 1396, 286, 584, 11, 1954, 11, 322, 264, 3199, 11, 51772], "temperature": 0.0, "avg_logprob": -0.17190502785347603, "compression_ratio": 1.8380281690140845, "no_speech_prob": 0.002549550263211131}, {"id": 688, "seek": 364712, "start": 3647.12, "end": 3650.96, "text": " there's a coffee cup. Oh, and on the table, there's a logo. And in the logo,", "tokens": [50364, 456, 311, 257, 4982, 4414, 13, 876, 11, 293, 322, 264, 3199, 11, 456, 311, 257, 9699, 13, 400, 294, 264, 9699, 11, 50556], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 689, "seek": 364712, "start": 3650.96, "end": 3654.3199999999997, "text": " there's the word Nemento. On the look in the logo, there's the letter E. On the look,", "tokens": [50556, 456, 311, 264, 1349, 426, 1712, 78, 13, 1282, 264, 574, 294, 264, 9699, 11, 456, 311, 264, 5063, 462, 13, 1282, 264, 574, 11, 50724], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 690, "seek": 364712, "start": 3654.3199999999997, "end": 3659.6, "text": " it has an unusual surf. And it doesn't actually, but pretend that there's a surf.", "tokens": [50724, 309, 575, 364, 10901, 9684, 13, 400, 309, 1177, 380, 767, 11, 457, 11865, 300, 456, 311, 257, 9684, 13, 50988], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 691, "seek": 364712, "start": 3659.6, "end": 3666.24, "text": " So the point is your attention is kind of drilling deep in and out of these nested structures.", "tokens": [50988, 407, 264, 935, 307, 428, 3202, 307, 733, 295, 26290, 2452, 294, 293, 484, 295, 613, 15646, 292, 9227, 13, 51320], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 692, "seek": 364712, "start": 3667.3599999999997, "end": 3671.04, "text": " And I can pop back up and I can pop back down. I can pop back up and I can pop back down. So", "tokens": [51376, 400, 286, 393, 1665, 646, 493, 293, 286, 393, 1665, 646, 760, 13, 286, 393, 1665, 646, 493, 293, 286, 393, 1665, 646, 760, 13, 407, 51560], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 693, "seek": 364712, "start": 3671.6, "end": 3675.52, "text": " when I attend to the coffee cup, I haven't lost the context of everything else,", "tokens": [51588, 562, 286, 6888, 281, 264, 4982, 4414, 11, 286, 2378, 380, 2731, 264, 4319, 295, 1203, 1646, 11, 51784], "temperature": 0.0, "avg_logprob": -0.16479328887103356, "compression_ratio": 1.9692307692307693, "no_speech_prob": 0.002251208992674947}, {"id": 694, "seek": 367552, "start": 3676.08, "end": 3678.72, "text": " but it's sort of, there's this sort of nested structure.", "tokens": [50392, 457, 309, 311, 1333, 295, 11, 456, 311, 341, 1333, 295, 15646, 292, 3877, 13, 50524], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 695, "seek": 367552, "start": 3678.72, "end": 3681.84, "text": " So the attention filters the reference frame formation", "tokens": [50524, 407, 264, 3202, 15995, 264, 6408, 3920, 11723, 50680], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 696, "seek": 367552, "start": 3682.88, "end": 3684.24, "text": " for that particular period of time?", "tokens": [50732, 337, 300, 1729, 2896, 295, 565, 30, 50800], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 697, "seek": 367552, "start": 3684.24, "end": 3688.24, "text": " Yes. It basically, moment to moment, you attend the subcomponents,", "tokens": [50800, 1079, 13, 467, 1936, 11, 1623, 281, 1623, 11, 291, 6888, 264, 1422, 21541, 40496, 11, 51000], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 698, "seek": 367552, "start": 3688.24, "end": 3690.24, "text": " and then you can attend the subcomponents to subcomponents.", "tokens": [51000, 293, 550, 291, 393, 6888, 264, 1422, 21541, 40496, 281, 1422, 21541, 40496, 13, 51100], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 699, "seek": 367552, "start": 3690.24, "end": 3691.36, "text": " You can move up and down that.", "tokens": [51100, 509, 393, 1286, 493, 293, 760, 300, 13, 51156], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 700, "seek": 367552, "start": 3691.36, "end": 3693.36, "text": " You can move up and down that. We do that all the time. You're not even,", "tokens": [51156, 509, 393, 1286, 493, 293, 760, 300, 13, 492, 360, 300, 439, 264, 565, 13, 509, 434, 406, 754, 11, 51256], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 701, "seek": 367552, "start": 3694.08, "end": 3697.12, "text": " now that I'm aware of it, I'm very conscious of it. But until,", "tokens": [51292, 586, 300, 286, 478, 3650, 295, 309, 11, 286, 478, 588, 6648, 295, 309, 13, 583, 1826, 11, 51444], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 702, "seek": 367552, "start": 3698.16, "end": 3701.12, "text": " but most people don't even think about this, you know, you just walk in the room and you", "tokens": [51496, 457, 881, 561, 500, 380, 754, 519, 466, 341, 11, 291, 458, 11, 291, 445, 1792, 294, 264, 1808, 293, 291, 51644], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 703, "seek": 367552, "start": 3701.12, "end": 3704.48, "text": " don't say, oh, I looked at the chair and I looked at the board and looked at that word on the board", "tokens": [51644, 500, 380, 584, 11, 1954, 11, 286, 2956, 412, 264, 6090, 293, 286, 2956, 412, 264, 3150, 293, 2956, 412, 300, 1349, 322, 264, 3150, 51812], "temperature": 0.0, "avg_logprob": -0.14886837444086184, "compression_ratio": 1.9873817034700316, "no_speech_prob": 0.0007319922442547977}, {"id": 704, "seek": 370448, "start": 3704.48, "end": 3706.96, "text": " and I looked over here. What's going on? Right?", "tokens": [50364, 293, 286, 2956, 670, 510, 13, 708, 311, 516, 322, 30, 1779, 30, 50488], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 705, "seek": 370448, "start": 3706.96, "end": 3709.92, "text": " So what percentage of your day are you deeply aware of this?", "tokens": [50488, 407, 437, 9668, 295, 428, 786, 366, 291, 8760, 3650, 295, 341, 30, 50636], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 706, "seek": 370448, "start": 3709.92, "end": 3712.72, "text": " And what part can you actually relax and just be Jeff?", "tokens": [50636, 400, 437, 644, 393, 291, 767, 5789, 293, 445, 312, 7506, 30, 50776], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 707, "seek": 370448, "start": 3712.72, "end": 3714.32, "text": " Me personally, like my personal day.", "tokens": [50776, 1923, 5665, 11, 411, 452, 2973, 786, 13, 50856], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 708, "seek": 370448, "start": 3714.32, "end": 3714.48, "text": " Yeah.", "tokens": [50856, 865, 13, 50864], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 709, "seek": 370448, "start": 3715.36, "end": 3717.68, "text": " Unfortunately, I'm afflicted with too much of the former.", "tokens": [50908, 8590, 11, 286, 478, 48287, 292, 365, 886, 709, 295, 264, 5819, 13, 51024], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 710, "seek": 370448, "start": 3721.2, "end": 3722.64, "text": " Unfortunately, they are unfortunate.", "tokens": [51200, 8590, 11, 436, 366, 17843, 13, 51272], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 711, "seek": 370448, "start": 3722.64, "end": 3724.4, "text": " Yeah. So you don't think it's useful?", "tokens": [51272, 865, 13, 407, 291, 500, 380, 519, 309, 311, 4420, 30, 51360], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 712, "seek": 370448, "start": 3724.4, "end": 3725.76, "text": " Oh, it is useful. Totally useful.", "tokens": [51360, 876, 11, 309, 307, 4420, 13, 22837, 4420, 13, 51428], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 713, "seek": 370448, "start": 3726.64, "end": 3729.12, "text": " I think about this stuff almost all the time.", "tokens": [51472, 286, 519, 466, 341, 1507, 1920, 439, 264, 565, 13, 51596], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 714, "seek": 370448, "start": 3729.12, "end": 3733.76, "text": " And one of my primary ways of thinking is when I'm asleep at night,", "tokens": [51596, 400, 472, 295, 452, 6194, 2098, 295, 1953, 307, 562, 286, 478, 11039, 412, 1818, 11, 51828], "temperature": 0.0, "avg_logprob": -0.17109204034735687, "compression_ratio": 1.6909722222222223, "no_speech_prob": 0.0021154433488845825}, {"id": 715, "seek": 373376, "start": 3733.76, "end": 3738.0800000000004, "text": " I always wake up in the middle of the night and then I stay awake for at least an hour with my", "tokens": [50364, 286, 1009, 6634, 493, 294, 264, 2808, 295, 264, 1818, 293, 550, 286, 1754, 15994, 337, 412, 1935, 364, 1773, 365, 452, 50580], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 716, "seek": 373376, "start": 3738.0800000000004, "end": 3742.48, "text": " eyes shut in sort of a half-sleep state thinking about these things. I come up with answers to", "tokens": [50580, 2575, 5309, 294, 1333, 295, 257, 1922, 12, 82, 7927, 1785, 1953, 466, 613, 721, 13, 286, 808, 493, 365, 6338, 281, 50800], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 717, "seek": 373376, "start": 3742.48, "end": 3746.7200000000003, "text": " problems very often in that sort of half-sleeping state. I think about on my bike ride, I think", "tokens": [50800, 2740, 588, 2049, 294, 300, 1333, 295, 1922, 12, 82, 7927, 278, 1785, 13, 286, 519, 466, 322, 452, 5656, 5077, 11, 286, 519, 51012], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 718, "seek": 373376, "start": 3746.7200000000003, "end": 3751.5200000000004, "text": " about on walks. I'm just constantly thinking about this. I have to almost schedule time", "tokens": [51012, 466, 322, 12896, 13, 286, 478, 445, 6460, 1953, 466, 341, 13, 286, 362, 281, 1920, 7567, 565, 51252], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 719, "seek": 373376, "start": 3752.4, "end": 3757.1200000000003, "text": " to not think about this stuff because it's very, it's mentally taxing.", "tokens": [51296, 281, 406, 519, 466, 341, 1507, 570, 309, 311, 588, 11, 309, 311, 17072, 3366, 278, 13, 51532], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 720, "seek": 373376, "start": 3758.32, "end": 3762.0, "text": " When you're thinking about this stuff, are you thinking introspectively, like almost", "tokens": [51592, 1133, 291, 434, 1953, 466, 341, 1507, 11, 366, 291, 1953, 560, 28713, 3413, 11, 411, 1920, 51776], "temperature": 0.0, "avg_logprob": -0.10413012575747362, "compression_ratio": 1.8892857142857142, "no_speech_prob": 0.0012064323527738452}, {"id": 721, "seek": 376200, "start": 3762.08, "end": 3765.52, "text": " taking a step outside of yourself and trying to figure out what is your mind doing right now?", "tokens": [50368, 1940, 257, 1823, 2380, 295, 1803, 293, 1382, 281, 2573, 484, 437, 307, 428, 1575, 884, 558, 586, 30, 50540], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 722, "seek": 376200, "start": 3765.52, "end": 3770.64, "text": " I do that all the time, but that's not all I do. I'm constantly observing myself.", "tokens": [50540, 286, 360, 300, 439, 264, 565, 11, 457, 300, 311, 406, 439, 286, 360, 13, 286, 478, 6460, 22107, 2059, 13, 50796], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 723, "seek": 376200, "start": 3770.64, "end": 3775.12, "text": " So as soon as I started thinking about grid cells, for example, and getting into that,", "tokens": [50796, 407, 382, 2321, 382, 286, 1409, 1953, 466, 10748, 5438, 11, 337, 1365, 11, 293, 1242, 666, 300, 11, 51020], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 724, "seek": 376200, "start": 3775.12, "end": 3778.24, "text": " I started saying, oh, well, grid cells can have my place of sense in the world.", "tokens": [51020, 286, 1409, 1566, 11, 1954, 11, 731, 11, 10748, 5438, 393, 362, 452, 1081, 295, 2020, 294, 264, 1002, 13, 51176], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 725, "seek": 376200, "start": 3778.24, "end": 3781.44, "text": " That's where you know where you are. And it's interesting, we always have a sense of where", "tokens": [51176, 663, 311, 689, 291, 458, 689, 291, 366, 13, 400, 309, 311, 1880, 11, 321, 1009, 362, 257, 2020, 295, 689, 51336], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 726, "seek": 376200, "start": 3781.44, "end": 3785.84, "text": " we are unless we're lost. And so I started at night when I got up to go to the bathroom,", "tokens": [51336, 321, 366, 5969, 321, 434, 2731, 13, 400, 370, 286, 1409, 412, 1818, 562, 286, 658, 493, 281, 352, 281, 264, 8687, 11, 51556], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 727, "seek": 376200, "start": 3785.84, "end": 3789.2, "text": " I would start trying to do it completely with my eyes closed all the time and I would test my", "tokens": [51556, 286, 576, 722, 1382, 281, 360, 309, 2584, 365, 452, 2575, 5395, 439, 264, 565, 293, 286, 576, 1500, 452, 51724], "temperature": 0.0, "avg_logprob": -0.0798524280764022, "compression_ratio": 1.8388059701492536, "no_speech_prob": 0.0006877387640997767}, {"id": 728, "seek": 378920, "start": 3789.2, "end": 3794.3199999999997, "text": " sense of grid cells. I would walk five feet and say, okay, I think I'm here. Am I really there?", "tokens": [50364, 2020, 295, 10748, 5438, 13, 286, 576, 1792, 1732, 3521, 293, 584, 11, 1392, 11, 286, 519, 286, 478, 510, 13, 2012, 286, 534, 456, 30, 50620], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 729, "seek": 378920, "start": 3794.3199999999997, "end": 3797.8399999999997, "text": " What's my error? And then I would calculate my error again and see how the errors can accumulate.", "tokens": [50620, 708, 311, 452, 6713, 30, 400, 550, 286, 576, 8873, 452, 6713, 797, 293, 536, 577, 264, 13603, 393, 33384, 13, 50796], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 730, "seek": 378920, "start": 3797.8399999999997, "end": 3800.3199999999997, "text": " So even something as simple as getting up in the middle of the night to go to the bathroom,", "tokens": [50796, 407, 754, 746, 382, 2199, 382, 1242, 493, 294, 264, 2808, 295, 264, 1818, 281, 352, 281, 264, 8687, 11, 50920], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 731, "seek": 378920, "start": 3800.3199999999997, "end": 3805.04, "text": " I'm testing these theories out. It's kind of fun. I mean, the coffee cup is an example of that too.", "tokens": [50920, 286, 478, 4997, 613, 13667, 484, 13, 467, 311, 733, 295, 1019, 13, 286, 914, 11, 264, 4982, 4414, 307, 364, 1365, 295, 300, 886, 13, 51156], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 732, "seek": 378920, "start": 3805.6, "end": 3811.6, "text": " So I think I find that these sort of everyday introspections are actually quite helpful.", "tokens": [51184, 407, 286, 519, 286, 915, 300, 613, 1333, 295, 7429, 560, 28713, 626, 366, 767, 1596, 4961, 13, 51484], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 733, "seek": 378920, "start": 3812.7999999999997, "end": 3818.08, "text": " It doesn't mean you can ignore the science. I mean, I spend hours every day reading ridiculously", "tokens": [51544, 467, 1177, 380, 914, 291, 393, 11200, 264, 3497, 13, 286, 914, 11, 286, 3496, 2496, 633, 786, 3760, 41358, 51808], "temperature": 0.0, "avg_logprob": -0.09205547858928811, "compression_ratio": 1.7303030303030302, "no_speech_prob": 0.0021820946130901575}, {"id": 734, "seek": 381808, "start": 3818.08, "end": 3823.84, "text": " complex papers. That's not nearly as much fun, but you have to sort of build up those constraints", "tokens": [50364, 3997, 10577, 13, 663, 311, 406, 6217, 382, 709, 1019, 11, 457, 291, 362, 281, 1333, 295, 1322, 493, 729, 18491, 50652], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 735, "seek": 381808, "start": 3824.48, "end": 3828.88, "text": " and the knowledge about the field and who's doing what and what exactly they think is happening here.", "tokens": [50684, 293, 264, 3601, 466, 264, 2519, 293, 567, 311, 884, 437, 293, 437, 2293, 436, 519, 307, 2737, 510, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 736, "seek": 381808, "start": 3828.88, "end": 3832.16, "text": " And then you can sit back and say, okay, let's try to have pieces all together.", "tokens": [50904, 400, 550, 291, 393, 1394, 646, 293, 584, 11, 1392, 11, 718, 311, 853, 281, 362, 3755, 439, 1214, 13, 51068], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 737, "seek": 381808, "start": 3833.2799999999997, "end": 3838.3199999999997, "text": " Let's come up with some, you know, I'm very, in this group here, people, they know they do this,", "tokens": [51124, 961, 311, 808, 493, 365, 512, 11, 291, 458, 11, 286, 478, 588, 11, 294, 341, 1594, 510, 11, 561, 11, 436, 458, 436, 360, 341, 11, 51376], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 738, "seek": 381808, "start": 3838.3199999999997, "end": 3841.2799999999997, "text": " I do this all the time. I come in with these introspective ideas and say, well,", "tokens": [51376, 286, 360, 341, 439, 264, 565, 13, 286, 808, 294, 365, 613, 560, 28713, 488, 3487, 293, 584, 11, 731, 11, 51524], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 739, "seek": 381808, "start": 3841.2799999999997, "end": 3843.92, "text": " did we ever thought about this? Now watch, well, let's all do this together.", "tokens": [51524, 630, 321, 1562, 1194, 466, 341, 30, 823, 1159, 11, 731, 11, 718, 311, 439, 360, 341, 1214, 13, 51656], "temperature": 0.0, "avg_logprob": -0.1306882509043519, "compression_ratio": 1.7249190938511327, "no_speech_prob": 0.0012834817171096802}, {"id": 740, "seek": 384392, "start": 3844.88, "end": 3850.2400000000002, "text": " And it's helpful. It's not, as long as you don't, if all you did was that,", "tokens": [50412, 400, 309, 311, 4961, 13, 467, 311, 406, 11, 382, 938, 382, 291, 500, 380, 11, 498, 439, 291, 630, 390, 300, 11, 50680], "temperature": 0.0, "avg_logprob": -0.12268570793999566, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0006664741085842252}, {"id": 741, "seek": 384392, "start": 3850.2400000000002, "end": 3854.88, "text": " then you're just making up stuff, right? But if you're constraining it by the reality of", "tokens": [50680, 550, 291, 434, 445, 1455, 493, 1507, 11, 558, 30, 583, 498, 291, 434, 11525, 1760, 309, 538, 264, 4103, 295, 50912], "temperature": 0.0, "avg_logprob": -0.12268570793999566, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0006664741085842252}, {"id": 742, "seek": 384392, "start": 3854.88, "end": 3860.8, "text": " the neuroscience, then it's really helpful. So let's talk a little bit about deep learning and", "tokens": [50912, 264, 42762, 11, 550, 309, 311, 534, 4961, 13, 407, 718, 311, 751, 257, 707, 857, 466, 2452, 2539, 293, 51208], "temperature": 0.0, "avg_logprob": -0.12268570793999566, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0006664741085842252}, {"id": 743, "seek": 384392, "start": 3860.8, "end": 3868.88, "text": " the successes in the applied space of neural networks and ideas of training model on data", "tokens": [51208, 264, 26101, 294, 264, 6456, 1901, 295, 18161, 9590, 293, 3487, 295, 3097, 2316, 322, 1412, 51612], "temperature": 0.0, "avg_logprob": -0.12268570793999566, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0006664741085842252}, {"id": 744, "seek": 386888, "start": 3868.96, "end": 3873.12, "text": " and these simple computational units and you're on artificial neurons", "tokens": [50368, 293, 613, 2199, 28270, 6815, 293, 291, 434, 322, 11677, 22027, 50576], "temperature": 0.0, "avg_logprob": -0.16670019250167042, "compression_ratio": 1.649056603773585, "no_speech_prob": 0.014493647031486034}, {"id": 745, "seek": 386888, "start": 3873.92, "end": 3881.28, "text": " that would back propagation of statistical ways of being able to generalize from the training", "tokens": [50616, 300, 576, 646, 38377, 295, 22820, 2098, 295, 885, 1075, 281, 2674, 1125, 490, 264, 3097, 50984], "temperature": 0.0, "avg_logprob": -0.16670019250167042, "compression_ratio": 1.649056603773585, "no_speech_prob": 0.014493647031486034}, {"id": 746, "seek": 386888, "start": 3881.28, "end": 3887.44, "text": " set onto data that's similar to that training set. So where do you think are the limitations of", "tokens": [50984, 992, 3911, 1412, 300, 311, 2531, 281, 300, 3097, 992, 13, 407, 689, 360, 291, 519, 366, 264, 15705, 295, 51292], "temperature": 0.0, "avg_logprob": -0.16670019250167042, "compression_ratio": 1.649056603773585, "no_speech_prob": 0.014493647031486034}, {"id": 747, "seek": 386888, "start": 3887.44, "end": 3892.2400000000002, "text": " those approaches? What do you think are its strengths relative to your major efforts of", "tokens": [51292, 729, 11587, 30, 708, 360, 291, 519, 366, 1080, 16986, 4972, 281, 428, 2563, 6484, 295, 51532], "temperature": 0.0, "avg_logprob": -0.16670019250167042, "compression_ratio": 1.649056603773585, "no_speech_prob": 0.014493647031486034}, {"id": 748, "seek": 386888, "start": 3892.8, "end": 3897.6800000000003, "text": " constructing a theory of human intelligence? Yeah. Well, I'm not an expert in this field.", "tokens": [51560, 39969, 257, 5261, 295, 1952, 7599, 30, 865, 13, 1042, 11, 286, 478, 406, 364, 5844, 294, 341, 2519, 13, 51804], "temperature": 0.0, "avg_logprob": -0.16670019250167042, "compression_ratio": 1.649056603773585, "no_speech_prob": 0.014493647031486034}, {"id": 749, "seek": 389768, "start": 3897.7599999999998, "end": 3902.0, "text": " I'm somewhat knowledgeable. So some of it is in just your intuition. What are your...", "tokens": [50368, 286, 478, 8344, 33800, 13, 407, 512, 295, 309, 307, 294, 445, 428, 24002, 13, 708, 366, 428, 485, 50580], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 750, "seek": 389768, "start": 3902.0, "end": 3907.2, "text": " Well, I have a little bit more than intuition, but I just want to say one of the things that", "tokens": [50580, 1042, 11, 286, 362, 257, 707, 857, 544, 813, 24002, 11, 457, 286, 445, 528, 281, 584, 472, 295, 264, 721, 300, 50840], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 751, "seek": 389768, "start": 3907.2, "end": 3910.56, "text": " you asked me, do I spend all my time thinking about neuroscience? I do. That's to the exclusion", "tokens": [50840, 291, 2351, 385, 11, 360, 286, 3496, 439, 452, 565, 1953, 466, 42762, 30, 286, 360, 13, 663, 311, 281, 264, 33049, 51008], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 752, "seek": 389768, "start": 3910.56, "end": 3914.56, "text": " of thinking about things like convolutional neural networks. But I try to stay current.", "tokens": [51008, 295, 1953, 466, 721, 411, 45216, 304, 18161, 9590, 13, 583, 286, 853, 281, 1754, 2190, 13, 51208], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 753, "seek": 389768, "start": 3915.2, "end": 3919.7599999999998, "text": " So look, I think it's great the progress they've made. It's fantastic. And as I mentioned earlier,", "tokens": [51240, 407, 574, 11, 286, 519, 309, 311, 869, 264, 4205, 436, 600, 1027, 13, 467, 311, 5456, 13, 400, 382, 286, 2835, 3071, 11, 51468], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 754, "seek": 389768, "start": 3919.7599999999998, "end": 3926.16, "text": " it's very highly useful for many things. The models that we have today are actually derived", "tokens": [51468, 309, 311, 588, 5405, 4420, 337, 867, 721, 13, 440, 5245, 300, 321, 362, 965, 366, 767, 18949, 51788], "temperature": 0.0, "avg_logprob": -0.1264505807091208, "compression_ratio": 1.691131498470948, "no_speech_prob": 0.0009398280526511371}, {"id": 755, "seek": 392616, "start": 3926.16, "end": 3930.48, "text": " from a lot of neuroscience principles. They are distributed processing systems and distributed", "tokens": [50364, 490, 257, 688, 295, 42762, 9156, 13, 814, 366, 12631, 9007, 3652, 293, 12631, 50580], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 756, "seek": 392616, "start": 3930.48, "end": 3935.7599999999998, "text": " memory systems. And that's how the brain works. They use things that we might call them neurons,", "tokens": [50580, 4675, 3652, 13, 400, 300, 311, 577, 264, 3567, 1985, 13, 814, 764, 721, 300, 321, 1062, 818, 552, 22027, 11, 50844], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 757, "seek": 392616, "start": 3935.7599999999998, "end": 3939.68, "text": " but they're really not neurons at all. So we can just... They're not really neurons. So they're", "tokens": [50844, 457, 436, 434, 534, 406, 22027, 412, 439, 13, 407, 321, 393, 445, 485, 814, 434, 406, 534, 22027, 13, 407, 436, 434, 51040], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 758, "seek": 392616, "start": 3939.68, "end": 3947.04, "text": " distributed processing systems. And nature of hierarchy that came also from neuroscience.", "tokens": [51040, 12631, 9007, 3652, 13, 400, 3687, 295, 22333, 300, 1361, 611, 490, 42762, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 759, "seek": 392616, "start": 3947.04, "end": 3951.44, "text": " And so there's a lot of things, the learning rules basically, not backprop, but other heavy", "tokens": [51408, 400, 370, 456, 311, 257, 688, 295, 721, 11, 264, 2539, 4474, 1936, 11, 406, 646, 79, 1513, 11, 457, 661, 4676, 51628], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 760, "seek": 392616, "start": 3951.44, "end": 3955.92, "text": " and tight learning. I'd be curious to say they're not neurons at all. Can you describe in which", "tokens": [51628, 293, 4524, 2539, 13, 286, 1116, 312, 6369, 281, 584, 436, 434, 406, 22027, 412, 439, 13, 1664, 291, 6786, 294, 597, 51852], "temperature": 0.0, "avg_logprob": -0.1507286658653846, "compression_ratio": 1.9349315068493151, "no_speech_prob": 0.002888188697397709}, {"id": 761, "seek": 395592, "start": 3955.92, "end": 3960.88, "text": " way? I mean, some of it is obvious, but I'd be curious if you have specific ways in which", "tokens": [50364, 636, 30, 286, 914, 11, 512, 295, 309, 307, 6322, 11, 457, 286, 1116, 312, 6369, 498, 291, 362, 2685, 2098, 294, 597, 50612], "temperature": 0.0, "avg_logprob": -0.09229440307617187, "compression_ratio": 1.5870307167235496, "no_speech_prob": 0.0009390677441842854}, {"id": 762, "seek": 395592, "start": 3960.88, "end": 3965.44, "text": " you think are the biggest differences. Yeah, we had a paper in 2016 called Why Neurons of", "tokens": [50612, 291, 519, 366, 264, 3880, 7300, 13, 865, 11, 321, 632, 257, 3035, 294, 6549, 1219, 1545, 1734, 374, 892, 295, 50840], "temperature": 0.0, "avg_logprob": -0.09229440307617187, "compression_ratio": 1.5870307167235496, "no_speech_prob": 0.0009390677441842854}, {"id": 763, "seek": 395592, "start": 3965.44, "end": 3971.28, "text": " Thousands of Synapses. And if you read that paper, you'll know what I'm talking about here.", "tokens": [50840, 40535, 295, 26155, 2382, 279, 13, 400, 498, 291, 1401, 300, 3035, 11, 291, 603, 458, 437, 286, 478, 1417, 466, 510, 13, 51132], "temperature": 0.0, "avg_logprob": -0.09229440307617187, "compression_ratio": 1.5870307167235496, "no_speech_prob": 0.0009390677441842854}, {"id": 764, "seek": 395592, "start": 3971.28, "end": 3977.44, "text": " A real neuron in the brain is a complex thing. Let's just start with the synapses on it, which is", "tokens": [51132, 316, 957, 34090, 294, 264, 3567, 307, 257, 3997, 551, 13, 961, 311, 445, 722, 365, 264, 5451, 2382, 279, 322, 309, 11, 597, 307, 51440], "temperature": 0.0, "avg_logprob": -0.09229440307617187, "compression_ratio": 1.5870307167235496, "no_speech_prob": 0.0009390677441842854}, {"id": 765, "seek": 395592, "start": 3977.44, "end": 3983.28, "text": " a connection between neurons. Real neurons can everywhere from five to 30,000 synapses on them.", "tokens": [51440, 257, 4984, 1296, 22027, 13, 8467, 22027, 393, 5315, 490, 1732, 281, 2217, 11, 1360, 5451, 2382, 279, 322, 552, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09229440307617187, "compression_ratio": 1.5870307167235496, "no_speech_prob": 0.0009390677441842854}, {"id": 766, "seek": 398328, "start": 3984.2400000000002, "end": 3989.6800000000003, "text": " The ones near the cell body, the ones that are close to the soma or the cell body,", "tokens": [50412, 440, 2306, 2651, 264, 2815, 1772, 11, 264, 2306, 300, 366, 1998, 281, 264, 3307, 64, 420, 264, 2815, 1772, 11, 50684], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 767, "seek": 398328, "start": 3990.4, "end": 3994.5600000000004, "text": " those are like the ones that people model in artificial neurons. There's a few hundred of", "tokens": [50720, 729, 366, 411, 264, 2306, 300, 561, 2316, 294, 11677, 22027, 13, 821, 311, 257, 1326, 3262, 295, 50928], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 768, "seek": 398328, "start": 3994.5600000000004, "end": 4001.52, "text": " those, maybe they can affect the cell, they can make the cell become active. 95% of the synapses", "tokens": [50928, 729, 11, 1310, 436, 393, 3345, 264, 2815, 11, 436, 393, 652, 264, 2815, 1813, 4967, 13, 13420, 4, 295, 264, 5451, 2382, 279, 51276], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 769, "seek": 398328, "start": 4002.1600000000003, "end": 4005.92, "text": " can't do that. They're too far away. So if you activate one of those synapses,", "tokens": [51308, 393, 380, 360, 300, 13, 814, 434, 886, 1400, 1314, 13, 407, 498, 291, 13615, 472, 295, 729, 5451, 2382, 279, 11, 51496], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 770, "seek": 398328, "start": 4005.92, "end": 4008.8, "text": " it just doesn't affect the cell body enough to make any difference.", "tokens": [51496, 309, 445, 1177, 380, 3345, 264, 2815, 1772, 1547, 281, 652, 604, 2649, 13, 51640], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 771, "seek": 398328, "start": 4008.8, "end": 4010.0, "text": " Any one of them individually.", "tokens": [51640, 2639, 472, 295, 552, 16652, 13, 51700], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 772, "seek": 398328, "start": 4010.0, "end": 4012.32, "text": " Any one of them individually, or even if you do a mass of them.", "tokens": [51700, 2639, 472, 295, 552, 16652, 11, 420, 754, 498, 291, 360, 257, 2758, 295, 552, 13, 51816], "temperature": 0.0, "avg_logprob": -0.0951298194773057, "compression_ratio": 1.9465648854961832, "no_speech_prob": 9.314103954238817e-05}, {"id": 773, "seek": 401328, "start": 4014.0, "end": 4022.1600000000003, "text": " What real neurons do is the following. If you activate or you get 10 to 20 of them", "tokens": [50400, 708, 957, 22027, 360, 307, 264, 3480, 13, 759, 291, 13615, 420, 291, 483, 1266, 281, 945, 295, 552, 50808], "temperature": 0.0, "avg_logprob": -0.11335800433981008, "compression_ratio": 1.7182539682539681, "no_speech_prob": 7.03064797562547e-05}, {"id": 774, "seek": 401328, "start": 4023.44, "end": 4026.6400000000003, "text": " active at the same time, meaning they're all receiving an input at the same time,", "tokens": [50872, 4967, 412, 264, 912, 565, 11, 3620, 436, 434, 439, 10040, 364, 4846, 412, 264, 912, 565, 11, 51032], "temperature": 0.0, "avg_logprob": -0.11335800433981008, "compression_ratio": 1.7182539682539681, "no_speech_prob": 7.03064797562547e-05}, {"id": 775, "seek": 401328, "start": 4026.6400000000003, "end": 4031.2000000000003, "text": " and those 10 to 20 synapses or 40 synapses within a very short distance on the dendro,", "tokens": [51032, 293, 729, 1266, 281, 945, 5451, 2382, 279, 420, 3356, 5451, 2382, 279, 1951, 257, 588, 2099, 4560, 322, 264, 274, 521, 340, 11, 51260], "temperature": 0.0, "avg_logprob": -0.11335800433981008, "compression_ratio": 1.7182539682539681, "no_speech_prob": 7.03064797562547e-05}, {"id": 776, "seek": 401328, "start": 4031.2000000000003, "end": 4035.28, "text": " like 40 microns, a very small area. So if you activate a bunch of these right next to each", "tokens": [51260, 411, 3356, 3123, 13270, 11, 257, 588, 1359, 1859, 13, 407, 498, 291, 13615, 257, 3840, 295, 613, 558, 958, 281, 1184, 51464], "temperature": 0.0, "avg_logprob": -0.11335800433981008, "compression_ratio": 1.7182539682539681, "no_speech_prob": 7.03064797562547e-05}, {"id": 777, "seek": 401328, "start": 4035.28, "end": 4040.48, "text": " other at some distant place, what happens is it creates what's called the dendritic spike.", "tokens": [51464, 661, 412, 512, 17275, 1081, 11, 437, 2314, 307, 309, 7829, 437, 311, 1219, 264, 274, 521, 3210, 299, 21053, 13, 51724], "temperature": 0.0, "avg_logprob": -0.11335800433981008, "compression_ratio": 1.7182539682539681, "no_speech_prob": 7.03064797562547e-05}, {"id": 778, "seek": 404048, "start": 4041.12, "end": 4046.64, "text": " And then dendritic spike travels through the dendroids and can reach the soma or the cell body.", "tokens": [50396, 400, 550, 274, 521, 3210, 299, 21053, 19863, 807, 264, 274, 521, 340, 3742, 293, 393, 2524, 264, 3307, 64, 420, 264, 2815, 1772, 13, 50672], "temperature": 0.0, "avg_logprob": -0.11697864532470703, "compression_ratio": 1.790874524714829, "no_speech_prob": 0.00045830250019207597}, {"id": 779, "seek": 404048, "start": 4047.68, "end": 4053.44, "text": " Now, when it gets there, it changes the voltage, which is sort of like going to make the cell fire,", "tokens": [50724, 823, 11, 562, 309, 2170, 456, 11, 309, 2962, 264, 8352, 11, 597, 307, 1333, 295, 411, 516, 281, 652, 264, 2815, 2610, 11, 51012], "temperature": 0.0, "avg_logprob": -0.11697864532470703, "compression_ratio": 1.790874524714829, "no_speech_prob": 0.00045830250019207597}, {"id": 780, "seek": 404048, "start": 4053.44, "end": 4058.32, "text": " but never enough to make the cell fire. It's sort of what we call it, we depolarize the cell,", "tokens": [51012, 457, 1128, 1547, 281, 652, 264, 2815, 2610, 13, 467, 311, 1333, 295, 437, 321, 818, 309, 11, 321, 1367, 15276, 1125, 264, 2815, 11, 51256], "temperature": 0.0, "avg_logprob": -0.11697864532470703, "compression_ratio": 1.790874524714829, "no_speech_prob": 0.00045830250019207597}, {"id": 781, "seek": 404048, "start": 4058.32, "end": 4061.92, "text": " you raise the voltage a little bit, but not enough to do anything. It's like, well,", "tokens": [51256, 291, 5300, 264, 8352, 257, 707, 857, 11, 457, 406, 1547, 281, 360, 1340, 13, 467, 311, 411, 11, 731, 11, 51436], "temperature": 0.0, "avg_logprob": -0.11697864532470703, "compression_ratio": 1.790874524714829, "no_speech_prob": 0.00045830250019207597}, {"id": 782, "seek": 404048, "start": 4061.92, "end": 4068.8, "text": " good as that. And then it goes back down again. So we proposed a theory, which I'm very confident", "tokens": [51436, 665, 382, 300, 13, 400, 550, 309, 1709, 646, 760, 797, 13, 407, 321, 10348, 257, 5261, 11, 597, 286, 478, 588, 6679, 51780], "temperature": 0.0, "avg_logprob": -0.11697864532470703, "compression_ratio": 1.790874524714829, "no_speech_prob": 0.00045830250019207597}, {"id": 783, "seek": 406880, "start": 4069.28, "end": 4076.2400000000002, "text": " basics are, is that what's happening there is those 95% of the synapses are recognizing dozens", "tokens": [50388, 14688, 366, 11, 307, 300, 437, 311, 2737, 456, 307, 729, 13420, 4, 295, 264, 5451, 2382, 279, 366, 18538, 18431, 50736], "temperature": 0.0, "avg_logprob": -0.11081659897514011, "compression_ratio": 1.711191335740072, "no_speech_prob": 0.0005357300397008657}, {"id": 784, "seek": 406880, "start": 4076.2400000000002, "end": 4081.1200000000003, "text": " to hundreds of unique patterns. They can write, you know, about the 10 and 20 synapses at a time,", "tokens": [50736, 281, 6779, 295, 3845, 8294, 13, 814, 393, 2464, 11, 291, 458, 11, 466, 264, 1266, 293, 945, 5451, 2382, 279, 412, 257, 565, 11, 50980], "temperature": 0.0, "avg_logprob": -0.11081659897514011, "compression_ratio": 1.711191335740072, "no_speech_prob": 0.0005357300397008657}, {"id": 785, "seek": 406880, "start": 4082.0, "end": 4086.88, "text": " and they're acting like predictions. So the neuron actually is a predictive engine on its own.", "tokens": [51024, 293, 436, 434, 6577, 411, 21264, 13, 407, 264, 34090, 767, 307, 257, 35521, 2848, 322, 1080, 1065, 13, 51268], "temperature": 0.0, "avg_logprob": -0.11081659897514011, "compression_ratio": 1.711191335740072, "no_speech_prob": 0.0005357300397008657}, {"id": 786, "seek": 406880, "start": 4087.6000000000004, "end": 4091.6000000000004, "text": " It can fire when it gets enough what they call proximal input from those ones near the cell", "tokens": [51304, 467, 393, 2610, 562, 309, 2170, 1547, 437, 436, 818, 21932, 304, 4846, 490, 729, 2306, 2651, 264, 2815, 51504], "temperature": 0.0, "avg_logprob": -0.11081659897514011, "compression_ratio": 1.711191335740072, "no_speech_prob": 0.0005357300397008657}, {"id": 787, "seek": 406880, "start": 4091.6000000000004, "end": 4096.56, "text": " fire, but it can get ready to fire from dozens to hundreds of patterns that it recognizes from", "tokens": [51504, 2610, 11, 457, 309, 393, 483, 1919, 281, 2610, 490, 18431, 281, 6779, 295, 8294, 300, 309, 26564, 490, 51752], "temperature": 0.0, "avg_logprob": -0.11081659897514011, "compression_ratio": 1.711191335740072, "no_speech_prob": 0.0005357300397008657}, {"id": 788, "seek": 409656, "start": 4096.56, "end": 4103.360000000001, "text": " the other guys. And the advantage of this to the neuron is that when it actually does produce a spike", "tokens": [50364, 264, 661, 1074, 13, 400, 264, 5002, 295, 341, 281, 264, 34090, 307, 300, 562, 309, 767, 775, 5258, 257, 21053, 50704], "temperature": 0.0, "avg_logprob": -0.11953779169031091, "compression_ratio": 1.9053497942386832, "no_speech_prob": 0.00047282048035413027}, {"id": 789, "seek": 409656, "start": 4103.360000000001, "end": 4108.4800000000005, "text": " in action potential, it does so slightly sooner than it would have otherwise. And so what could", "tokens": [50704, 294, 3069, 3995, 11, 309, 775, 370, 4748, 15324, 813, 309, 576, 362, 5911, 13, 400, 370, 437, 727, 50960], "temperature": 0.0, "avg_logprob": -0.11953779169031091, "compression_ratio": 1.9053497942386832, "no_speech_prob": 0.00047282048035413027}, {"id": 790, "seek": 409656, "start": 4108.4800000000005, "end": 4113.120000000001, "text": " it slightly sooner? Well, the slightly sooner part is it, there's it all the neurons in the,", "tokens": [50960, 309, 4748, 15324, 30, 1042, 11, 264, 4748, 15324, 644, 307, 309, 11, 456, 311, 309, 439, 264, 22027, 294, 264, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11953779169031091, "compression_ratio": 1.9053497942386832, "no_speech_prob": 0.00047282048035413027}, {"id": 791, "seek": 409656, "start": 4113.120000000001, "end": 4116.56, "text": " the excitatory neurons in the brain are surrounded by these inhibitory neurons,", "tokens": [51192, 264, 13101, 4745, 22027, 294, 264, 3567, 366, 13221, 538, 613, 49858, 827, 22027, 11, 51364], "temperature": 0.0, "avg_logprob": -0.11953779169031091, "compression_ratio": 1.9053497942386832, "no_speech_prob": 0.00047282048035413027}, {"id": 792, "seek": 409656, "start": 4116.56, "end": 4122.4800000000005, "text": " and they're very fast, the inhibitory neurons, these basket cells. And if I get my spike out", "tokens": [51364, 293, 436, 434, 588, 2370, 11, 264, 49858, 827, 22027, 11, 613, 8390, 5438, 13, 400, 498, 286, 483, 452, 21053, 484, 51660], "temperature": 0.0, "avg_logprob": -0.11953779169031091, "compression_ratio": 1.9053497942386832, "no_speech_prob": 0.00047282048035413027}, {"id": 793, "seek": 412248, "start": 4122.48, "end": 4127.28, "text": " a little bit sooner than someone else, I inhibit all my neighbors around me. Right. And what you", "tokens": [50364, 257, 707, 857, 15324, 813, 1580, 1646, 11, 286, 49858, 439, 452, 12512, 926, 385, 13, 1779, 13, 400, 437, 291, 50604], "temperature": 0.0, "avg_logprob": -0.13412878534815334, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.000503265589941293}, {"id": 794, "seek": 412248, "start": 4127.28, "end": 4131.44, "text": " end up with is a different representation. You end up with a representation that matches your", "tokens": [50604, 917, 493, 365, 307, 257, 819, 10290, 13, 509, 917, 493, 365, 257, 10290, 300, 10676, 428, 50812], "temperature": 0.0, "avg_logprob": -0.13412878534815334, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.000503265589941293}, {"id": 795, "seek": 412248, "start": 4131.44, "end": 4135.919999999999, "text": " prediction. It's a, it's a sparser representation, meaning the few are non interactive, but it's", "tokens": [50812, 17630, 13, 467, 311, 257, 11, 309, 311, 257, 637, 685, 260, 10290, 11, 3620, 264, 1326, 366, 2107, 15141, 11, 457, 309, 311, 51036], "temperature": 0.0, "avg_logprob": -0.13412878534815334, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.000503265589941293}, {"id": 796, "seek": 412248, "start": 4135.919999999999, "end": 4142.5599999999995, "text": " much more specific. And so we showed how networks of these neurons can do very sophisticated temporal", "tokens": [51036, 709, 544, 2685, 13, 400, 370, 321, 4712, 577, 9590, 295, 613, 22027, 393, 360, 588, 16950, 30881, 51368], "temperature": 0.0, "avg_logprob": -0.13412878534815334, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.000503265589941293}, {"id": 797, "seek": 412248, "start": 4142.5599999999995, "end": 4149.839999999999, "text": " prediction, basically. So, so this summarizes real neurons in the brain are time based prediction", "tokens": [51368, 17630, 11, 1936, 13, 407, 11, 370, 341, 14611, 5660, 957, 22027, 294, 264, 3567, 366, 565, 2361, 17630, 51732], "temperature": 0.0, "avg_logprob": -0.13412878534815334, "compression_ratio": 1.7330960854092528, "no_speech_prob": 0.000503265589941293}, {"id": 798, "seek": 414984, "start": 4149.92, "end": 4157.28, "text": " engines. And, and they, and there's no concept of this at all, in artificial, what we call point", "tokens": [50368, 12982, 13, 400, 11, 293, 436, 11, 293, 456, 311, 572, 3410, 295, 341, 412, 439, 11, 294, 11677, 11, 437, 321, 818, 935, 50736], "temperature": 0.0, "avg_logprob": -0.1816028623438593, "compression_ratio": 1.8127340823970037, "no_speech_prob": 0.0010647672461345792}, {"id": 799, "seek": 414984, "start": 4157.28, "end": 4161.04, "text": " neurons. I don't think you can mail the brain without them. I don't think you can build intelligence", "tokens": [50736, 22027, 13, 286, 500, 380, 519, 291, 393, 10071, 264, 3567, 1553, 552, 13, 286, 500, 380, 519, 291, 393, 1322, 7599, 50924], "temperature": 0.0, "avg_logprob": -0.1816028623438593, "compression_ratio": 1.8127340823970037, "no_speech_prob": 0.0010647672461345792}, {"id": 800, "seek": 414984, "start": 4161.04, "end": 4165.92, "text": " about it, because it's the, it's the, it's where large part of the time comes from. It's, it's,", "tokens": [50924, 466, 309, 11, 570, 309, 311, 264, 11, 309, 311, 264, 11, 309, 311, 689, 2416, 644, 295, 264, 565, 1487, 490, 13, 467, 311, 11, 309, 311, 11, 51168], "temperature": 0.0, "avg_logprob": -0.1816028623438593, "compression_ratio": 1.8127340823970037, "no_speech_prob": 0.0010647672461345792}, {"id": 801, "seek": 414984, "start": 4165.92, "end": 4171.12, "text": " these are predictive models. And the time is, is there's a prior and a, you know, a prediction", "tokens": [51168, 613, 366, 35521, 5245, 13, 400, 264, 565, 307, 11, 307, 456, 311, 257, 4059, 293, 257, 11, 291, 458, 11, 257, 17630, 51428], "temperature": 0.0, "avg_logprob": -0.1816028623438593, "compression_ratio": 1.8127340823970037, "no_speech_prob": 0.0010647672461345792}, {"id": 802, "seek": 414984, "start": 4171.12, "end": 4176.56, "text": " and an action. And it's inherent through every neuron in the neocortex. So, so I would say that", "tokens": [51428, 293, 364, 3069, 13, 400, 309, 311, 26387, 807, 633, 34090, 294, 264, 408, 905, 36143, 13, 407, 11, 370, 286, 576, 584, 300, 51700], "temperature": 0.0, "avg_logprob": -0.1816028623438593, "compression_ratio": 1.8127340823970037, "no_speech_prob": 0.0010647672461345792}, {"id": 803, "seek": 417656, "start": 4176.56, "end": 4181.52, "text": " point neurons sort of model a piece of that and not very well at that either. But, you know, like,", "tokens": [50364, 935, 22027, 1333, 295, 2316, 257, 2522, 295, 300, 293, 406, 588, 731, 412, 300, 2139, 13, 583, 11, 291, 458, 11, 411, 11, 50612], "temperature": 0.0, "avg_logprob": -0.10005158826339343, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.003375545609742403}, {"id": 804, "seek": 417656, "start": 4181.52, "end": 4189.120000000001, "text": " like for example, synapses are very unreliable. And you cannot assign any precision to them.", "tokens": [50612, 411, 337, 1365, 11, 5451, 2382, 279, 366, 588, 20584, 2081, 712, 13, 400, 291, 2644, 6269, 604, 18356, 281, 552, 13, 50992], "temperature": 0.0, "avg_logprob": -0.10005158826339343, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.003375545609742403}, {"id": 805, "seek": 417656, "start": 4189.84, "end": 4195.200000000001, "text": " So even one digit of precision is not possible. So the way real neurons work is they don't add", "tokens": [51028, 407, 754, 472, 14293, 295, 18356, 307, 406, 1944, 13, 407, 264, 636, 957, 22027, 589, 307, 436, 500, 380, 909, 51296], "temperature": 0.0, "avg_logprob": -0.10005158826339343, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.003375545609742403}, {"id": 806, "seek": 417656, "start": 4195.200000000001, "end": 4199.92, "text": " these, they don't change these weights accurately, like artificial neural networks do. They basically", "tokens": [51296, 613, 11, 436, 500, 380, 1319, 613, 17443, 20095, 11, 411, 11677, 18161, 9590, 360, 13, 814, 1936, 51532], "temperature": 0.0, "avg_logprob": -0.10005158826339343, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.003375545609742403}, {"id": 807, "seek": 417656, "start": 4199.92, "end": 4205.76, "text": " form new synapses. And so what you're trying to always do is, is detect the presence of some 10", "tokens": [51532, 1254, 777, 5451, 2382, 279, 13, 400, 370, 437, 291, 434, 1382, 281, 1009, 360, 307, 11, 307, 5531, 264, 6814, 295, 512, 1266, 51824], "temperature": 0.0, "avg_logprob": -0.10005158826339343, "compression_ratio": 1.704225352112676, "no_speech_prob": 0.003375545609742403}, {"id": 808, "seek": 420576, "start": 4205.76, "end": 4211.68, "text": " to 20 active synapses at the same time, as opposed, and there's, they're almost binary. It's like,", "tokens": [50364, 281, 945, 4967, 5451, 2382, 279, 412, 264, 912, 565, 11, 382, 8851, 11, 293, 456, 311, 11, 436, 434, 1920, 17434, 13, 467, 311, 411, 11, 50660], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 809, "seek": 420576, "start": 4211.68, "end": 4215.52, "text": " because you can't really represent anything much finer than that. So these are the kind of", "tokens": [50660, 570, 291, 393, 380, 534, 2906, 1340, 709, 39130, 813, 300, 13, 407, 613, 366, 264, 733, 295, 50852], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 810, "seek": 420576, "start": 4216.16, "end": 4219.84, "text": " and I think that's actually another essential component, because the brain works on sparse", "tokens": [50884, 293, 286, 519, 300, 311, 767, 1071, 7115, 6542, 11, 570, 264, 3567, 1985, 322, 637, 11668, 51068], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 811, "seek": 420576, "start": 4219.84, "end": 4224.88, "text": " patterns. And all that, all that mechanism is based on sparse patterns. And I don't actually", "tokens": [51068, 8294, 13, 400, 439, 300, 11, 439, 300, 7513, 307, 2361, 322, 637, 11668, 8294, 13, 400, 286, 500, 380, 767, 51320], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 812, "seek": 420576, "start": 4224.88, "end": 4230.0, "text": " think you could build our real brains or machine intelligence without incorporating some of those", "tokens": [51320, 519, 291, 727, 1322, 527, 957, 15442, 420, 3479, 7599, 1553, 33613, 512, 295, 729, 51576], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 813, "seek": 420576, "start": 4230.0, "end": 4235.280000000001, "text": " ideas. It's hard to even think about the complexity that emerges from the fact that the timing of the", "tokens": [51576, 3487, 13, 467, 311, 1152, 281, 754, 519, 466, 264, 14024, 300, 38965, 490, 264, 1186, 300, 264, 10822, 295, 264, 51840], "temperature": 0.0, "avg_logprob": -0.10108152547277006, "compression_ratio": 1.7576687116564418, "no_speech_prob": 0.0011333416914567351}, {"id": 814, "seek": 423528, "start": 4235.28, "end": 4243.12, "text": " firing matters in the brain, the fact that you form new, new synapses. And I mean, everything", "tokens": [50364, 16045, 7001, 294, 264, 3567, 11, 264, 1186, 300, 291, 1254, 777, 11, 777, 5451, 2382, 279, 13, 400, 286, 914, 11, 1203, 50756], "temperature": 0.0, "avg_logprob": -0.15325261652469635, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.0004581710381899029}, {"id": 815, "seek": 423528, "start": 4243.12, "end": 4247.12, "text": " you just mentioned in the past few minutes, trust me, if you spend time on it, you can get your mind", "tokens": [50756, 291, 445, 2835, 294, 264, 1791, 1326, 2077, 11, 3361, 385, 11, 498, 291, 3496, 565, 322, 309, 11, 291, 393, 483, 428, 1575, 50956], "temperature": 0.0, "avg_logprob": -0.15325261652469635, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.0004581710381899029}, {"id": 816, "seek": 423528, "start": 4247.12, "end": 4252.32, "text": " around it. It's not like it's no longer a mystery to me. No, but, but sorry, as a function in a", "tokens": [50956, 926, 309, 13, 467, 311, 406, 411, 309, 311, 572, 2854, 257, 11422, 281, 385, 13, 883, 11, 457, 11, 457, 2597, 11, 382, 257, 2445, 294, 257, 51216], "temperature": 0.0, "avg_logprob": -0.15325261652469635, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.0004581710381899029}, {"id": 817, "seek": 423528, "start": 4252.32, "end": 4258.0, "text": " mathematical way, it's, can you get it start getting an intuition about what gets it excited,", "tokens": [51216, 18894, 636, 11, 309, 311, 11, 393, 291, 483, 309, 722, 1242, 364, 24002, 466, 437, 2170, 309, 2919, 11, 51500], "temperature": 0.0, "avg_logprob": -0.15325261652469635, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.0004581710381899029}, {"id": 818, "seek": 423528, "start": 4258.0, "end": 4263.759999999999, "text": " what not, and what kind of representation it's not as easy as there's many other types of neural", "tokens": [51500, 437, 406, 11, 293, 437, 733, 295, 10290, 309, 311, 406, 382, 1858, 382, 456, 311, 867, 661, 3467, 295, 18161, 51788], "temperature": 0.0, "avg_logprob": -0.15325261652469635, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.0004581710381899029}, {"id": 819, "seek": 426376, "start": 4263.76, "end": 4270.56, "text": " networks that are more amenable to pure analysis. You know, especially very simple networks, you", "tokens": [50364, 9590, 300, 366, 544, 18497, 712, 281, 6075, 5215, 13, 509, 458, 11, 2318, 588, 2199, 9590, 11, 291, 50704], "temperature": 0.0, "avg_logprob": -0.14742207136310514, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.001987307798117399}, {"id": 820, "seek": 426376, "start": 4270.56, "end": 4274.400000000001, "text": " know, oh, I have four neurons and they're doing this. Can we, you know, describe them mathematically", "tokens": [50704, 458, 11, 1954, 11, 286, 362, 1451, 22027, 293, 436, 434, 884, 341, 13, 1664, 321, 11, 291, 458, 11, 6786, 552, 44003, 50896], "temperature": 0.0, "avg_logprob": -0.14742207136310514, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.001987307798117399}, {"id": 821, "seek": 426376, "start": 4274.400000000001, "end": 4279.280000000001, "text": " what they're doing type of thing. Even the complexity of convolutional neural networks today,", "tokens": [50896, 437, 436, 434, 884, 2010, 295, 551, 13, 2754, 264, 14024, 295, 45216, 304, 18161, 9590, 965, 11, 51140], "temperature": 0.0, "avg_logprob": -0.14742207136310514, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.001987307798117399}, {"id": 822, "seek": 426376, "start": 4279.280000000001, "end": 4285.360000000001, "text": " it's sort of a mystery. They can't really describe the whole system. And so it's different. My colleague,", "tokens": [51140, 309, 311, 1333, 295, 257, 11422, 13, 814, 393, 380, 534, 6786, 264, 1379, 1185, 13, 400, 370, 309, 311, 819, 13, 1222, 13532, 11, 51444], "temperature": 0.0, "avg_logprob": -0.14742207136310514, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.001987307798117399}, {"id": 823, "seek": 426376, "start": 4285.360000000001, "end": 4292.88, "text": " Subitain Ahmad, he did a nice paper on this. You can get all the stuff on our website if you're", "tokens": [51444, 8511, 270, 491, 35911, 11, 415, 630, 257, 1481, 3035, 322, 341, 13, 509, 393, 483, 439, 264, 1507, 322, 527, 3144, 498, 291, 434, 51820], "temperature": 0.0, "avg_logprob": -0.14742207136310514, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.001987307798117399}, {"id": 824, "seek": 429288, "start": 4292.88, "end": 4297.92, "text": " interested in talking about some of the mathematical properties of sparse representations. And so we", "tokens": [50364, 3102, 294, 1417, 466, 512, 295, 264, 18894, 7221, 295, 637, 11668, 33358, 13, 400, 370, 321, 50616], "temperature": 0.0, "avg_logprob": -0.12613477098180892, "compression_ratio": 1.755458515283843, "no_speech_prob": 0.002321436535567045}, {"id": 825, "seek": 429288, "start": 4297.92, "end": 4304.56, "text": " can't, what we can do is we can show mathematically, for example, why 10 to 20 synapses to recognize a", "tokens": [50616, 393, 380, 11, 437, 321, 393, 360, 307, 321, 393, 855, 44003, 11, 337, 1365, 11, 983, 1266, 281, 945, 5451, 2382, 279, 281, 5521, 257, 50948], "temperature": 0.0, "avg_logprob": -0.12613477098180892, "compression_ratio": 1.755458515283843, "no_speech_prob": 0.002321436535567045}, {"id": 826, "seek": 429288, "start": 4304.56, "end": 4308.8, "text": " pattern is the correct number is the right number you'd want to use. And by the way, that matches", "tokens": [50948, 5102, 307, 264, 3006, 1230, 307, 264, 558, 1230, 291, 1116, 528, 281, 764, 13, 400, 538, 264, 636, 11, 300, 10676, 51160], "temperature": 0.0, "avg_logprob": -0.12613477098180892, "compression_ratio": 1.755458515283843, "no_speech_prob": 0.002321436535567045}, {"id": 827, "seek": 429288, "start": 4308.8, "end": 4317.52, "text": " biology, we can show mathematically some of these concepts about the show why the brain is so robust", "tokens": [51160, 14956, 11, 321, 393, 855, 44003, 512, 295, 613, 10392, 466, 264, 855, 983, 264, 3567, 307, 370, 13956, 51596], "temperature": 0.0, "avg_logprob": -0.12613477098180892, "compression_ratio": 1.755458515283843, "no_speech_prob": 0.002321436535567045}, {"id": 828, "seek": 431752, "start": 4318.4800000000005, "end": 4322.96, "text": " to noise and error and fall out and so on. We can show that mathematically as well as empirically", "tokens": [50412, 281, 5658, 293, 6713, 293, 2100, 484, 293, 370, 322, 13, 492, 393, 855, 300, 44003, 382, 731, 382, 25790, 984, 50636], "temperature": 0.0, "avg_logprob": -0.12437135240306026, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.010321144945919514}, {"id": 829, "seek": 431752, "start": 4322.96, "end": 4329.76, "text": " in simulations. But the system can't be analyzed completely. Any complex system can't. And so", "tokens": [50636, 294, 35138, 13, 583, 264, 1185, 393, 380, 312, 28181, 2584, 13, 2639, 3997, 1185, 393, 380, 13, 400, 370, 50976], "temperature": 0.0, "avg_logprob": -0.12437135240306026, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.010321144945919514}, {"id": 830, "seek": 431752, "start": 4329.76, "end": 4337.76, "text": " that's out of the realm. But there is there is mathematical benefits and intuitions that can", "tokens": [50976, 300, 311, 484, 295, 264, 15355, 13, 583, 456, 307, 456, 307, 18894, 5311, 293, 16224, 626, 300, 393, 51376], "temperature": 0.0, "avg_logprob": -0.12437135240306026, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.010321144945919514}, {"id": 831, "seek": 431752, "start": 4337.76, "end": 4342.080000000001, "text": " be derived from mathematics. And we try to do that as well. Most most of our papers have a section", "tokens": [51376, 312, 18949, 490, 18666, 13, 400, 321, 853, 281, 360, 300, 382, 731, 13, 4534, 881, 295, 527, 10577, 362, 257, 3541, 51592], "temperature": 0.0, "avg_logprob": -0.12437135240306026, "compression_ratio": 1.7731481481481481, "no_speech_prob": 0.010321144945919514}, {"id": 832, "seek": 434208, "start": 4342.08, "end": 4347.44, "text": " about that. So I think it's refreshing and useful for me to be talking to you about deep", "tokens": [50364, 466, 300, 13, 407, 286, 519, 309, 311, 19772, 293, 4420, 337, 385, 281, 312, 1417, 281, 291, 466, 2452, 50632], "temperature": 0.0, "avg_logprob": -0.09984494070721488, "compression_ratio": 1.725, "no_speech_prob": 0.05384025722742081}, {"id": 833, "seek": 434208, "start": 4347.44, "end": 4354.48, "text": " neural networks, because your intuition basically says that we can't achieve anything like intelligence", "tokens": [50632, 18161, 9590, 11, 570, 428, 24002, 1936, 1619, 300, 321, 393, 380, 4584, 1340, 411, 7599, 50984], "temperature": 0.0, "avg_logprob": -0.09984494070721488, "compression_ratio": 1.725, "no_speech_prob": 0.05384025722742081}, {"id": 834, "seek": 434208, "start": 4354.48, "end": 4357.76, "text": " with artificial neural networks. Well, not in the current form. Not in the current form. I'm sure", "tokens": [50984, 365, 11677, 18161, 9590, 13, 1042, 11, 406, 294, 264, 2190, 1254, 13, 1726, 294, 264, 2190, 1254, 13, 286, 478, 988, 51148], "temperature": 0.0, "avg_logprob": -0.09984494070721488, "compression_ratio": 1.725, "no_speech_prob": 0.05384025722742081}, {"id": 835, "seek": 434208, "start": 4357.76, "end": 4362.8, "text": " we can do it in the ultimate form, sure. So let me dig into it and see what your thoughts are there", "tokens": [51148, 321, 393, 360, 309, 294, 264, 9705, 1254, 11, 988, 13, 407, 718, 385, 2528, 666, 309, 293, 536, 437, 428, 4598, 366, 456, 51400], "temperature": 0.0, "avg_logprob": -0.09984494070721488, "compression_ratio": 1.725, "no_speech_prob": 0.05384025722742081}, {"id": 836, "seek": 434208, "start": 4362.8, "end": 4367.44, "text": " a little bit. So I'm not sure if you read this little blog post called Bitter Lesson by Rich", "tokens": [51400, 257, 707, 857, 13, 407, 286, 478, 406, 988, 498, 291, 1401, 341, 707, 6968, 2183, 1219, 363, 3904, 18649, 266, 538, 6781, 51632], "temperature": 0.0, "avg_logprob": -0.09984494070721488, "compression_ratio": 1.725, "no_speech_prob": 0.05384025722742081}, {"id": 837, "seek": 436744, "start": 4367.5199999999995, "end": 4373.28, "text": " Sutton. Recently, he's a reinforcement learning pioneer. I'm not sure if you're familiar with him.", "tokens": [50368, 40492, 1756, 13, 20072, 11, 415, 311, 257, 29280, 2539, 37668, 13, 286, 478, 406, 988, 498, 291, 434, 4963, 365, 796, 13, 50656], "temperature": 0.0, "avg_logprob": -0.10172688134826056, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.011858697980642319}, {"id": 838, "seek": 436744, "start": 4373.28, "end": 4379.44, "text": " His basic idea is that all the stuff we've done in AI in the past 70 years, he's one of the old", "tokens": [50656, 2812, 3875, 1558, 307, 300, 439, 264, 1507, 321, 600, 1096, 294, 7318, 294, 264, 1791, 5285, 924, 11, 415, 311, 472, 295, 264, 1331, 50964], "temperature": 0.0, "avg_logprob": -0.10172688134826056, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.011858697980642319}, {"id": 839, "seek": 436744, "start": 4379.44, "end": 4388.96, "text": " school guys. The biggest lesson learned is that all the tricky things we've done don't, you know,", "tokens": [50964, 1395, 1074, 13, 440, 3880, 6898, 3264, 307, 300, 439, 264, 12414, 721, 321, 600, 1096, 500, 380, 11, 291, 458, 11, 51440], "temperature": 0.0, "avg_logprob": -0.10172688134826056, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.011858697980642319}, {"id": 840, "seek": 436744, "start": 4388.96, "end": 4393.599999999999, "text": " they benefit in the short term. But in the long term, what wins out is a simple general method", "tokens": [51440, 436, 5121, 294, 264, 2099, 1433, 13, 583, 294, 264, 938, 1433, 11, 437, 10641, 484, 307, 257, 2199, 2674, 3170, 51672], "temperature": 0.0, "avg_logprob": -0.10172688134826056, "compression_ratio": 1.5925925925925926, "no_speech_prob": 0.011858697980642319}, {"id": 841, "seek": 439360, "start": 4394.400000000001, "end": 4399.76, "text": " that just relies on Moore's law on computation getting faster and faster.", "tokens": [50404, 300, 445, 30910, 322, 21644, 311, 2101, 322, 24903, 1242, 4663, 293, 4663, 13, 50672], "temperature": 0.0, "avg_logprob": -0.13069141387939454, "compression_ratio": 1.735042735042735, "no_speech_prob": 0.007341478485614061}, {"id": 842, "seek": 439360, "start": 4399.76, "end": 4402.72, "text": " This is what he's saying. This is what has worked up to now.", "tokens": [50672, 639, 307, 437, 415, 311, 1566, 13, 639, 307, 437, 575, 2732, 493, 281, 586, 13, 50820], "temperature": 0.0, "avg_logprob": -0.13069141387939454, "compression_ratio": 1.735042735042735, "no_speech_prob": 0.007341478485614061}, {"id": 843, "seek": 439360, "start": 4403.6, "end": 4409.92, "text": " What has worked up to now, that if you're trying to build a system, if we're talking about,", "tokens": [50864, 708, 575, 2732, 493, 281, 586, 11, 300, 498, 291, 434, 1382, 281, 1322, 257, 1185, 11, 498, 321, 434, 1417, 466, 11, 51180], "temperature": 0.0, "avg_logprob": -0.13069141387939454, "compression_ratio": 1.735042735042735, "no_speech_prob": 0.007341478485614061}, {"id": 844, "seek": 439360, "start": 4409.92, "end": 4413.360000000001, "text": " he's not concerned about intelligence. He's concerned about a system that works", "tokens": [51180, 415, 311, 406, 5922, 466, 7599, 13, 634, 311, 5922, 466, 257, 1185, 300, 1985, 51352], "temperature": 0.0, "avg_logprob": -0.13069141387939454, "compression_ratio": 1.735042735042735, "no_speech_prob": 0.007341478485614061}, {"id": 845, "seek": 439360, "start": 4414.400000000001, "end": 4420.160000000001, "text": " in terms of making predictions on applied, narrow AI problems. That's what the discussion is about.", "tokens": [51404, 294, 2115, 295, 1455, 21264, 322, 6456, 11, 9432, 7318, 2740, 13, 663, 311, 437, 264, 5017, 307, 466, 13, 51692], "temperature": 0.0, "avg_logprob": -0.13069141387939454, "compression_ratio": 1.735042735042735, "no_speech_prob": 0.007341478485614061}, {"id": 846, "seek": 442016, "start": 4421.12, "end": 4428.48, "text": " That you just try to go as general as possible and wait years or decades for the computation", "tokens": [50412, 663, 291, 445, 853, 281, 352, 382, 2674, 382, 1944, 293, 1699, 924, 420, 7878, 337, 264, 24903, 50780], "temperature": 0.0, "avg_logprob": -0.12714173112596786, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.006284875329583883}, {"id": 847, "seek": 442016, "start": 4428.48, "end": 4433.2, "text": " to make it actually. Is he saying that as a criticism or is he saying this is a prescription", "tokens": [50780, 281, 652, 309, 767, 13, 1119, 415, 1566, 300, 382, 257, 15835, 420, 307, 415, 1566, 341, 307, 257, 22456, 51016], "temperature": 0.0, "avg_logprob": -0.12714173112596786, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.006284875329583883}, {"id": 848, "seek": 442016, "start": 4433.2, "end": 4437.92, "text": " of what we ought to be doing? Well, it's very difficult. He's saying this is what has worked", "tokens": [51016, 295, 437, 321, 13416, 281, 312, 884, 30, 1042, 11, 309, 311, 588, 2252, 13, 634, 311, 1566, 341, 307, 437, 575, 2732, 51252], "temperature": 0.0, "avg_logprob": -0.12714173112596786, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.006284875329583883}, {"id": 849, "seek": 442016, "start": 4437.92, "end": 4440.88, "text": " and yes, a prescription, but it's a difficult prescription because it says", "tokens": [51252, 293, 2086, 11, 257, 22456, 11, 457, 309, 311, 257, 2252, 22456, 570, 309, 1619, 51400], "temperature": 0.0, "avg_logprob": -0.12714173112596786, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.006284875329583883}, {"id": 850, "seek": 442016, "start": 4441.5199999999995, "end": 4447.28, "text": " all the fun things you guys are trying to do, we are trying to do, he's part of the community,", "tokens": [51432, 439, 264, 1019, 721, 291, 1074, 366, 1382, 281, 360, 11, 321, 366, 1382, 281, 360, 11, 415, 311, 644, 295, 264, 1768, 11, 51720], "temperature": 0.0, "avg_logprob": -0.12714173112596786, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.006284875329583883}, {"id": 851, "seek": 444728, "start": 4447.28, "end": 4453.2, "text": " is saying it's only going to be short-term gains. This all leads up to a question, I guess,", "tokens": [50364, 307, 1566, 309, 311, 787, 516, 281, 312, 2099, 12, 7039, 16823, 13, 639, 439, 6689, 493, 281, 257, 1168, 11, 286, 2041, 11, 50660], "temperature": 0.0, "avg_logprob": -0.1325646582103911, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.00302602956071496}, {"id": 852, "seek": 444728, "start": 4453.84, "end": 4459.2, "text": " on artificial neural networks and maybe our own biological neural networks is,", "tokens": [50692, 322, 11677, 18161, 9590, 293, 1310, 527, 1065, 13910, 18161, 9590, 307, 11, 50960], "temperature": 0.0, "avg_logprob": -0.1325646582103911, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.00302602956071496}, {"id": 853, "seek": 444728, "start": 4460.32, "end": 4465.28, "text": " do you think if we just scale things up significantly, so take these dumb artificial", "tokens": [51016, 360, 291, 519, 498, 321, 445, 4373, 721, 493, 10591, 11, 370, 747, 613, 10316, 11677, 51264], "temperature": 0.0, "avg_logprob": -0.1325646582103911, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.00302602956071496}, {"id": 854, "seek": 444728, "start": 4465.84, "end": 4473.12, "text": " neurons, the point neurons, I like that term, if we just have a lot more of them,", "tokens": [51292, 22027, 11, 264, 935, 22027, 11, 286, 411, 300, 1433, 11, 498, 321, 445, 362, 257, 688, 544, 295, 552, 11, 51656], "temperature": 0.0, "avg_logprob": -0.1325646582103911, "compression_ratio": 1.6600985221674878, "no_speech_prob": 0.00302602956071496}, {"id": 855, "seek": 447312, "start": 4473.12, "end": 4478.08, "text": " do you think some of the elements that we see in the brain may start emerging?", "tokens": [50364, 360, 291, 519, 512, 295, 264, 4959, 300, 321, 536, 294, 264, 3567, 815, 722, 14989, 30, 50612], "temperature": 0.0, "avg_logprob": -0.08236386858183763, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0021147355437278748}, {"id": 856, "seek": 447312, "start": 4478.08, "end": 4484.96, "text": " No, I don't think so. We can do bigger problems of the same type. It's been pointed out by many", "tokens": [50612, 883, 11, 286, 500, 380, 519, 370, 13, 492, 393, 360, 3801, 2740, 295, 264, 912, 2010, 13, 467, 311, 668, 10932, 484, 538, 867, 50956], "temperature": 0.0, "avg_logprob": -0.08236386858183763, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0021147355437278748}, {"id": 857, "seek": 447312, "start": 4484.96, "end": 4488.72, "text": " people that today's convolutional neural networks aren't really much different than the ones we had", "tokens": [50956, 561, 300, 965, 311, 45216, 304, 18161, 9590, 3212, 380, 534, 709, 819, 813, 264, 2306, 321, 632, 51144], "temperature": 0.0, "avg_logprob": -0.08236386858183763, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0021147355437278748}, {"id": 858, "seek": 447312, "start": 4488.72, "end": 4493.68, "text": " quite a while ago. They're bigger and train more and we have more labeled data and so on,", "tokens": [51144, 1596, 257, 1339, 2057, 13, 814, 434, 3801, 293, 3847, 544, 293, 321, 362, 544, 21335, 1412, 293, 370, 322, 11, 51392], "temperature": 0.0, "avg_logprob": -0.08236386858183763, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0021147355437278748}, {"id": 859, "seek": 447312, "start": 4496.32, "end": 4501.12, "text": " but I don't think you can get to the kind of things I know the brain can do and that we think", "tokens": [51524, 457, 286, 500, 380, 519, 291, 393, 483, 281, 264, 733, 295, 721, 286, 458, 264, 3567, 393, 360, 293, 300, 321, 519, 51764], "temperature": 0.0, "avg_logprob": -0.08236386858183763, "compression_ratio": 1.7026022304832713, "no_speech_prob": 0.0021147355437278748}, {"id": 860, "seek": 450112, "start": 4501.12, "end": 4507.12, "text": " about as intelligence by just scaling it up. It's a good description of what's happened in", "tokens": [50364, 466, 382, 7599, 538, 445, 21589, 309, 493, 13, 467, 311, 257, 665, 3855, 295, 437, 311, 2011, 294, 50664], "temperature": 0.0, "avg_logprob": -0.07830941786459826, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0012444521998986602}, {"id": 861, "seek": 450112, "start": 4507.12, "end": 4511.68, "text": " the past, what's happened recently with the reemergence of artificial neural networks.", "tokens": [50664, 264, 1791, 11, 437, 311, 2011, 3938, 365, 264, 319, 29660, 15260, 295, 11677, 18161, 9590, 13, 50892], "temperature": 0.0, "avg_logprob": -0.07830941786459826, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0012444521998986602}, {"id": 862, "seek": 450112, "start": 4512.48, "end": 4516.16, "text": " It may be a good prescription for what's going to happen in the short term,", "tokens": [50932, 467, 815, 312, 257, 665, 22456, 337, 437, 311, 516, 281, 1051, 294, 264, 2099, 1433, 11, 51116], "temperature": 0.0, "avg_logprob": -0.07830941786459826, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0012444521998986602}, {"id": 863, "seek": 450112, "start": 4517.5199999999995, "end": 4521.92, "text": " but I don't think that's the path. I've said that earlier, there's an alternate path. I should", "tokens": [51184, 457, 286, 500, 380, 519, 300, 311, 264, 3100, 13, 286, 600, 848, 300, 3071, 11, 456, 311, 364, 18873, 3100, 13, 286, 820, 51404], "temperature": 0.0, "avg_logprob": -0.07830941786459826, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0012444521998986602}, {"id": 864, "seek": 450112, "start": 4521.92, "end": 4528.0, "text": " mention to you, by the way, that we've made sufficient progress on the whole cortical theory", "tokens": [51404, 2152, 281, 291, 11, 538, 264, 636, 11, 300, 321, 600, 1027, 11563, 4205, 322, 264, 1379, 11278, 804, 5261, 51708], "temperature": 0.0, "avg_logprob": -0.07830941786459826, "compression_ratio": 1.736220472440945, "no_speech_prob": 0.0012444521998986602}, {"id": 865, "seek": 452800, "start": 4528.0, "end": 4536.88, "text": " in the last few years that last year, we decided to start actively pursuing how we get these ideas", "tokens": [50364, 294, 264, 1036, 1326, 924, 300, 1036, 1064, 11, 321, 3047, 281, 722, 13022, 20222, 577, 321, 483, 613, 3487, 50808], "temperature": 0.0, "avg_logprob": -0.2558475536304516, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.002471879357472062}, {"id": 866, "seek": 452800, "start": 4536.88, "end": 4542.48, "text": " embedded into machine learning. That's again being led by my colleague, Subhathayamad,", "tokens": [50808, 16741, 666, 3479, 2539, 13, 663, 311, 797, 885, 4684, 538, 452, 13532, 11, 8511, 71, 998, 320, 335, 345, 11, 51088], "temperature": 0.0, "avg_logprob": -0.2558475536304516, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.002471879357472062}, {"id": 867, "seek": 452800, "start": 4543.04, "end": 4546.08, "text": " and because he's more of a machine learning guy, I'm more of an neuroscience guy.", "tokens": [51116, 293, 570, 415, 311, 544, 295, 257, 3479, 2539, 2146, 11, 286, 478, 544, 295, 364, 42762, 2146, 13, 51268], "temperature": 0.0, "avg_logprob": -0.2558475536304516, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.002471879357472062}, {"id": 868, "seek": 452800, "start": 4549.2, "end": 4556.32, "text": " Now, I wouldn't say our focus, but it is now an equal focus here because we need to", "tokens": [51424, 823, 11, 286, 2759, 380, 584, 527, 1879, 11, 457, 309, 307, 586, 364, 2681, 1879, 510, 570, 321, 643, 281, 51780], "temperature": 0.0, "avg_logprob": -0.2558475536304516, "compression_ratio": 1.5954545454545455, "no_speech_prob": 0.002471879357472062}, {"id": 869, "seek": 455632, "start": 4556.32, "end": 4563.28, "text": " proselytize what we've learned, and we need to show how it's beneficial to the machine", "tokens": [50364, 6267, 736, 83, 1125, 437, 321, 600, 3264, 11, 293, 321, 643, 281, 855, 577, 309, 311, 14072, 281, 264, 3479, 50712], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 870, "seek": 455632, "start": 4563.28, "end": 4567.599999999999, "text": " learning. We have a plan in place right now. In fact, we just did our first paper on this.", "tokens": [50712, 2539, 13, 492, 362, 257, 1393, 294, 1081, 558, 586, 13, 682, 1186, 11, 321, 445, 630, 527, 700, 3035, 322, 341, 13, 50928], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 871, "seek": 455632, "start": 4567.599999999999, "end": 4572.48, "text": " I can tell you about that, but one of the reasons I want to talk to you is because I'm trying to", "tokens": [50928, 286, 393, 980, 291, 466, 300, 11, 457, 472, 295, 264, 4112, 286, 528, 281, 751, 281, 291, 307, 570, 286, 478, 1382, 281, 51172], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 872, "seek": 455632, "start": 4573.2, "end": 4577.12, "text": " get more people in the machine learning community to say, I need to learn about this stuff,", "tokens": [51208, 483, 544, 561, 294, 264, 3479, 2539, 1768, 281, 584, 11, 286, 643, 281, 1466, 466, 341, 1507, 11, 51404], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 873, "seek": 455632, "start": 4577.12, "end": 4580.88, "text": " and maybe we should just think about this a bit more about what we've learned about the brain,", "tokens": [51404, 293, 1310, 321, 820, 445, 519, 466, 341, 257, 857, 544, 466, 437, 321, 600, 3264, 466, 264, 3567, 11, 51592], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 874, "seek": 455632, "start": 4580.88, "end": 4584.639999999999, "text": " and what are those team members meant to have? What have they done? Is that useful for us?", "tokens": [51592, 293, 437, 366, 729, 1469, 2679, 4140, 281, 362, 30, 708, 362, 436, 1096, 30, 1119, 300, 4420, 337, 505, 30, 51780], "temperature": 0.0, "avg_logprob": -0.14190186245340697, "compression_ratio": 1.798045602605863, "no_speech_prob": 0.0011510427575558424}, {"id": 875, "seek": 458464, "start": 4585.12, "end": 4589.76, "text": " Yeah, so is there elements of all the cortical theory that things we've been talking about", "tokens": [50388, 865, 11, 370, 307, 456, 4959, 295, 439, 264, 11278, 804, 5261, 300, 721, 321, 600, 668, 1417, 466, 50620], "temperature": 0.0, "avg_logprob": -0.12285393866423135, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.001863931305706501}, {"id": 876, "seek": 458464, "start": 4589.76, "end": 4593.360000000001, "text": " that may be useful in the short term? Yes, in the short term, yes.", "tokens": [50620, 300, 815, 312, 4420, 294, 264, 2099, 1433, 30, 1079, 11, 294, 264, 2099, 1433, 11, 2086, 13, 50800], "temperature": 0.0, "avg_logprob": -0.12285393866423135, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.001863931305706501}, {"id": 877, "seek": 458464, "start": 4593.360000000001, "end": 4599.200000000001, "text": " This is the, sorry to interrupt, but the open question is it certainly feels from my perspective", "tokens": [50800, 639, 307, 264, 11, 2597, 281, 12729, 11, 457, 264, 1269, 1168, 307, 309, 3297, 3417, 490, 452, 4585, 51092], "temperature": 0.0, "avg_logprob": -0.12285393866423135, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.001863931305706501}, {"id": 878, "seek": 458464, "start": 4599.200000000001, "end": 4604.160000000001, "text": " that in the long term, some of the ideas we've been talking about will be extremely useful.", "tokens": [51092, 300, 294, 264, 938, 1433, 11, 512, 295, 264, 3487, 321, 600, 668, 1417, 466, 486, 312, 4664, 4420, 13, 51340], "temperature": 0.0, "avg_logprob": -0.12285393866423135, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.001863931305706501}, {"id": 879, "seek": 458464, "start": 4604.160000000001, "end": 4608.4800000000005, "text": " The question is whether in the short term. Well, this is always what I would call the", "tokens": [51340, 440, 1168, 307, 1968, 294, 264, 2099, 1433, 13, 1042, 11, 341, 307, 1009, 437, 286, 576, 818, 264, 51556], "temperature": 0.0, "avg_logprob": -0.12285393866423135, "compression_ratio": 1.8075313807531381, "no_speech_prob": 0.001863931305706501}, {"id": 880, "seek": 460848, "start": 4608.48, "end": 4614.719999999999, "text": " entrepreneur's dilemma. So you have this long term vision. Oh, we're going to all be driving", "tokens": [50364, 14307, 311, 34312, 13, 407, 291, 362, 341, 938, 1433, 5201, 13, 876, 11, 321, 434, 516, 281, 439, 312, 4840, 50676], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 881, "seek": 460848, "start": 4614.719999999999, "end": 4618.16, "text": " electric cars or we're all going to have computers or we're all going to whatever.", "tokens": [50676, 5210, 5163, 420, 321, 434, 439, 516, 281, 362, 10807, 420, 321, 434, 439, 516, 281, 2035, 13, 50848], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 882, "seek": 460848, "start": 4618.959999999999, "end": 4623.12, "text": " And, and you're at some point in time and you say, I can see that long term vision. I'm sure", "tokens": [50888, 400, 11, 293, 291, 434, 412, 512, 935, 294, 565, 293, 291, 584, 11, 286, 393, 536, 300, 938, 1433, 5201, 13, 286, 478, 988, 51096], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 883, "seek": 460848, "start": 4623.12, "end": 4626.32, "text": " it's going to happen. How do I get there without killing myself, you know, without going out of", "tokens": [51096, 309, 311, 516, 281, 1051, 13, 1012, 360, 286, 483, 456, 1553, 8011, 2059, 11, 291, 458, 11, 1553, 516, 484, 295, 51256], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 884, "seek": 460848, "start": 4626.32, "end": 4631.759999999999, "text": " business? That's the challenge. That's the dilemma. That's the really difficult thing to do. So we're", "tokens": [51256, 1606, 30, 663, 311, 264, 3430, 13, 663, 311, 264, 34312, 13, 663, 311, 264, 534, 2252, 551, 281, 360, 13, 407, 321, 434, 51528], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 885, "seek": 460848, "start": 4631.759999999999, "end": 4636.24, "text": " facing that right now. So ideally what you'd want to do is find some steps along the way that you", "tokens": [51528, 7170, 300, 558, 586, 13, 407, 22915, 437, 291, 1116, 528, 281, 360, 307, 915, 512, 4439, 2051, 264, 636, 300, 291, 51752], "temperature": 0.0, "avg_logprob": -0.11366189669256341, "compression_ratio": 1.855263157894737, "no_speech_prob": 0.061857618391513824}, {"id": 886, "seek": 463624, "start": 4636.24, "end": 4639.84, "text": " can get there incrementally. You don't have to like throw it all out and start over again.", "tokens": [50364, 393, 483, 456, 26200, 379, 13, 509, 500, 380, 362, 281, 411, 3507, 309, 439, 484, 293, 722, 670, 797, 13, 50544], "temperature": 0.0, "avg_logprob": -0.10453977282085115, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0033760801889002323}, {"id": 887, "seek": 463624, "start": 4640.4, "end": 4647.5199999999995, "text": " The first thing that we've done is we focus on the sparse representations. So just, just in case", "tokens": [50572, 440, 700, 551, 300, 321, 600, 1096, 307, 321, 1879, 322, 264, 637, 11668, 33358, 13, 407, 445, 11, 445, 294, 1389, 50928], "temperature": 0.0, "avg_logprob": -0.10453977282085115, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0033760801889002323}, {"id": 888, "seek": 463624, "start": 4647.5199999999995, "end": 4651.5199999999995, "text": " you don't know what that means or some of the listeners don't know what that means. In the", "tokens": [50928, 291, 500, 380, 458, 437, 300, 1355, 420, 512, 295, 264, 23274, 500, 380, 458, 437, 300, 1355, 13, 682, 264, 51128], "temperature": 0.0, "avg_logprob": -0.10453977282085115, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0033760801889002323}, {"id": 889, "seek": 463624, "start": 4651.5199999999995, "end": 4656.88, "text": " brain, if I have like 10,000 neurons, what you would see is maybe 2% of them active at a time.", "tokens": [51128, 3567, 11, 498, 286, 362, 411, 1266, 11, 1360, 22027, 11, 437, 291, 576, 536, 307, 1310, 568, 4, 295, 552, 4967, 412, 257, 565, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10453977282085115, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0033760801889002323}, {"id": 890, "seek": 463624, "start": 4656.88, "end": 4662.5599999999995, "text": " You don't see 50%, you don't think 30%, you might see 2%. And it's always like that.", "tokens": [51396, 509, 500, 380, 536, 2625, 8923, 291, 500, 380, 519, 2217, 8923, 291, 1062, 536, 568, 6856, 400, 309, 311, 1009, 411, 300, 13, 51680], "temperature": 0.0, "avg_logprob": -0.10453977282085115, "compression_ratio": 1.6900369003690037, "no_speech_prob": 0.0033760801889002323}, {"id": 891, "seek": 466256, "start": 4662.56, "end": 4666.4800000000005, "text": " For any set of sensory inputs. It doesn't matter if anything, it doesn't matter with any part of the", "tokens": [50364, 1171, 604, 992, 295, 27233, 15743, 13, 467, 1177, 380, 1871, 498, 1340, 11, 309, 1177, 380, 1871, 365, 604, 644, 295, 264, 50560], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 892, "seek": 466256, "start": 4666.4800000000005, "end": 4674.080000000001, "text": " brain. But which neurons differs? Which neurons are active? Yeah, so let me put this, let's say I", "tokens": [50560, 3567, 13, 583, 597, 22027, 37761, 30, 3013, 22027, 366, 4967, 30, 865, 11, 370, 718, 385, 829, 341, 11, 718, 311, 584, 286, 50940], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 893, "seek": 466256, "start": 4674.080000000001, "end": 4678.0, "text": " take 10,000 neurons that are representing something. They're sitting there in a block together. It's a", "tokens": [50940, 747, 1266, 11, 1360, 22027, 300, 366, 13460, 746, 13, 814, 434, 3798, 456, 294, 257, 3461, 1214, 13, 467, 311, 257, 51136], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 894, "seek": 466256, "start": 4678.0, "end": 4681.6, "text": " teeny little block in a neuron, 10,000 neurons. And they're representing a location, they're", "tokens": [51136, 48232, 707, 3461, 294, 257, 34090, 11, 1266, 11, 1360, 22027, 13, 400, 436, 434, 13460, 257, 4914, 11, 436, 434, 51316], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 895, "seek": 466256, "start": 4681.6, "end": 4684.56, "text": " representing a cop, they're representing the input from my sensors. I don't know, it doesn't", "tokens": [51316, 13460, 257, 2971, 11, 436, 434, 13460, 264, 4846, 490, 452, 14840, 13, 286, 500, 380, 458, 11, 309, 1177, 380, 51464], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 896, "seek": 466256, "start": 4684.56, "end": 4690.0, "text": " matter. It's representing something. The way the representations occur, it's always a sparse", "tokens": [51464, 1871, 13, 467, 311, 13460, 746, 13, 440, 636, 264, 33358, 5160, 11, 309, 311, 1009, 257, 637, 11668, 51736], "temperature": 0.0, "avg_logprob": -0.1903107828564114, "compression_ratio": 2.013888888888889, "no_speech_prob": 0.004198387730866671}, {"id": 897, "seek": 469000, "start": 4690.0, "end": 4694.32, "text": " representation, meaning it's a population code. So which 200 cells are active tells me what's", "tokens": [50364, 10290, 11, 3620, 309, 311, 257, 4415, 3089, 13, 407, 597, 2331, 5438, 366, 4967, 5112, 385, 437, 311, 50580], "temperature": 0.0, "avg_logprob": -0.0894740006634008, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.009123571217060089}, {"id": 898, "seek": 469000, "start": 4694.32, "end": 4699.28, "text": " going on. It's not individual cells aren't that important at all. It's the population code that", "tokens": [50580, 516, 322, 13, 467, 311, 406, 2609, 5438, 3212, 380, 300, 1021, 412, 439, 13, 467, 311, 264, 4415, 3089, 300, 50828], "temperature": 0.0, "avg_logprob": -0.0894740006634008, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.009123571217060089}, {"id": 899, "seek": 469000, "start": 4699.28, "end": 4705.68, "text": " matters. And when you have sparse population codes, then all kinds of beautiful properties come out", "tokens": [50828, 7001, 13, 400, 562, 291, 362, 637, 11668, 4415, 14211, 11, 550, 439, 3685, 295, 2238, 7221, 808, 484, 51148], "temperature": 0.0, "avg_logprob": -0.0894740006634008, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.009123571217060089}, {"id": 900, "seek": 469000, "start": 4705.68, "end": 4710.16, "text": " of them. So the brain uses sparse population codes that we've written and described these", "tokens": [51148, 295, 552, 13, 407, 264, 3567, 4960, 637, 11668, 4415, 14211, 300, 321, 600, 3720, 293, 7619, 613, 51372], "temperature": 0.0, "avg_logprob": -0.0894740006634008, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.009123571217060089}, {"id": 901, "seek": 469000, "start": 4710.16, "end": 4717.36, "text": " benefits in some of our papers. So they give this tremendous robustness to the systems.", "tokens": [51372, 5311, 294, 512, 295, 527, 10577, 13, 407, 436, 976, 341, 10048, 13956, 1287, 281, 264, 3652, 13, 51732], "temperature": 0.0, "avg_logprob": -0.0894740006634008, "compression_ratio": 1.768939393939394, "no_speech_prob": 0.009123571217060089}, {"id": 902, "seek": 471736, "start": 4717.36, "end": 4721.92, "text": " Your brains are incredibly robust. Neurons are dying all the time and spasming and synapses", "tokens": [50364, 2260, 15442, 366, 6252, 13956, 13, 1734, 374, 892, 366, 8639, 439, 264, 565, 293, 637, 296, 2810, 293, 5451, 2382, 279, 50592], "temperature": 0.0, "avg_logprob": -0.15661690598827296, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.001048297039233148}, {"id": 903, "seek": 471736, "start": 4721.92, "end": 4729.12, "text": " falling apart and, you know, all the time and it keeps working. So what Subitai and Louise,", "tokens": [50592, 7440, 4936, 293, 11, 291, 458, 11, 439, 264, 565, 293, 309, 5965, 1364, 13, 407, 437, 8511, 270, 1301, 293, 35962, 11, 50952], "temperature": 0.0, "avg_logprob": -0.15661690598827296, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.001048297039233148}, {"id": 904, "seek": 471736, "start": 4729.12, "end": 4735.759999999999, "text": " one of our other engineers here have done, I've shown that they're introducing sparseness into", "tokens": [50952, 472, 295, 527, 661, 11955, 510, 362, 1096, 11, 286, 600, 4898, 300, 436, 434, 15424, 637, 685, 15264, 666, 51284], "temperature": 0.0, "avg_logprob": -0.15661690598827296, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.001048297039233148}, {"id": 905, "seek": 471736, "start": 4735.759999999999, "end": 4738.48, "text": " convolutional neural networks. Now other people are thinking along these lines, but we're going", "tokens": [51284, 45216, 304, 18161, 9590, 13, 823, 661, 561, 366, 1953, 2051, 613, 3876, 11, 457, 321, 434, 516, 51420], "temperature": 0.0, "avg_logprob": -0.15661690598827296, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.001048297039233148}, {"id": 906, "seek": 471736, "start": 4738.48, "end": 4744.0, "text": " about it in a more principled way, I think. And we're showing that if you enforce sparseness", "tokens": [51420, 466, 309, 294, 257, 544, 3681, 15551, 636, 11, 286, 519, 13, 400, 321, 434, 4099, 300, 498, 291, 24825, 637, 685, 15264, 51696], "temperature": 0.0, "avg_logprob": -0.15661690598827296, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.001048297039233148}, {"id": 907, "seek": 474400, "start": 4744.0, "end": 4751.92, "text": " throughout these convolutional neural networks, in both which neurons are active and the connections", "tokens": [50364, 3710, 613, 45216, 304, 18161, 9590, 11, 294, 1293, 597, 22027, 366, 4967, 293, 264, 9271, 50760], "temperature": 0.0, "avg_logprob": -0.1170142548424857, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.001168803428299725}, {"id": 908, "seek": 474400, "start": 4751.92, "end": 4757.12, "text": " between them, that you get some very desirable properties. So one of the current hot topics in", "tokens": [50760, 1296, 552, 11, 300, 291, 483, 512, 588, 30533, 7221, 13, 407, 472, 295, 264, 2190, 2368, 8378, 294, 51020], "temperature": 0.0, "avg_logprob": -0.1170142548424857, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.001168803428299725}, {"id": 909, "seek": 474400, "start": 4757.92, "end": 4762.64, "text": " deep learning right now are these adversarial examples. So, you know, I can give me any deep", "tokens": [51060, 2452, 2539, 558, 586, 366, 613, 17641, 44745, 5110, 13, 407, 11, 291, 458, 11, 286, 393, 976, 385, 604, 2452, 51296], "temperature": 0.0, "avg_logprob": -0.1170142548424857, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.001168803428299725}, {"id": 910, "seek": 474400, "start": 4762.64, "end": 4766.8, "text": " learning network and I can give you a picture that looks perfect and you're going to call it,", "tokens": [51296, 2539, 3209, 293, 286, 393, 976, 291, 257, 3036, 300, 1542, 2176, 293, 291, 434, 516, 281, 818, 309, 11, 51504], "temperature": 0.0, "avg_logprob": -0.1170142548424857, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.001168803428299725}, {"id": 911, "seek": 474400, "start": 4766.8, "end": 4772.4, "text": " you know, you're going to say the monkey is, you know, an airplane. So that's a problem.", "tokens": [51504, 291, 458, 11, 291, 434, 516, 281, 584, 264, 17847, 307, 11, 291, 458, 11, 364, 17130, 13, 407, 300, 311, 257, 1154, 13, 51784], "temperature": 0.0, "avg_logprob": -0.1170142548424857, "compression_ratio": 1.8045977011494252, "no_speech_prob": 0.001168803428299725}, {"id": 912, "seek": 477240, "start": 4772.4, "end": 4776.48, "text": " And DARPA just announced some big thing. They're trying to, you know, have some contests for this.", "tokens": [50364, 400, 49274, 10297, 445, 7548, 512, 955, 551, 13, 814, 434, 1382, 281, 11, 291, 458, 11, 362, 512, 660, 4409, 337, 341, 13, 50568], "temperature": 0.0, "avg_logprob": -0.1380047599474589, "compression_ratio": 1.5491803278688525, "no_speech_prob": 0.000709576706867665}, {"id": 913, "seek": 477240, "start": 4776.48, "end": 4782.0, "text": " But if you enforce sparse representations here, many of these problems go away. They're much more", "tokens": [50568, 583, 498, 291, 24825, 637, 11668, 33358, 510, 11, 867, 295, 613, 2740, 352, 1314, 13, 814, 434, 709, 544, 50844], "temperature": 0.0, "avg_logprob": -0.1380047599474589, "compression_ratio": 1.5491803278688525, "no_speech_prob": 0.000709576706867665}, {"id": 914, "seek": 477240, "start": 4782.0, "end": 4787.44, "text": " robust and they're not easy to fool. So we've already shown some of those results,", "tokens": [50844, 13956, 293, 436, 434, 406, 1858, 281, 7979, 13, 407, 321, 600, 1217, 4898, 512, 295, 729, 3542, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1380047599474589, "compression_ratio": 1.5491803278688525, "no_speech_prob": 0.000709576706867665}, {"id": 915, "seek": 477240, "start": 4788.24, "end": 4796.16, "text": " just literally in January or February, just like last month we did that. And you can, I think it's", "tokens": [51156, 445, 3736, 294, 7061, 420, 8711, 11, 445, 411, 1036, 1618, 321, 630, 300, 13, 400, 291, 393, 11, 286, 519, 309, 311, 51552], "temperature": 0.0, "avg_logprob": -0.1380047599474589, "compression_ratio": 1.5491803278688525, "no_speech_prob": 0.000709576706867665}, {"id": 916, "seek": 479616, "start": 4796.16, "end": 4802.32, "text": " on bioarchive right now or on iCry, you can read about it. But so that's like a baby step.", "tokens": [50364, 322, 12198, 1178, 488, 558, 586, 420, 322, 741, 38477, 11, 291, 393, 1401, 466, 309, 13, 583, 370, 300, 311, 411, 257, 3186, 1823, 13, 50672], "temperature": 0.0, "avg_logprob": -0.17772232540070065, "compression_ratio": 1.746212121212121, "no_speech_prob": 0.07693656533956528}, {"id": 917, "seek": 479616, "start": 4802.32, "end": 4805.92, "text": " Okay. That's a take something from the brain. We know, we know about sparseness. We know why", "tokens": [50672, 1033, 13, 663, 311, 257, 747, 746, 490, 264, 3567, 13, 492, 458, 11, 321, 458, 466, 637, 685, 15264, 13, 492, 458, 983, 50852], "temperature": 0.0, "avg_logprob": -0.17772232540070065, "compression_ratio": 1.746212121212121, "no_speech_prob": 0.07693656533956528}, {"id": 918, "seek": 479616, "start": 4805.92, "end": 4809.44, "text": " it's important. We know what it gives the brain. So let's try to enforce that onto this.", "tokens": [50852, 309, 311, 1021, 13, 492, 458, 437, 309, 2709, 264, 3567, 13, 407, 718, 311, 853, 281, 24825, 300, 3911, 341, 13, 51028], "temperature": 0.0, "avg_logprob": -0.17772232540070065, "compression_ratio": 1.746212121212121, "no_speech_prob": 0.07693656533956528}, {"id": 919, "seek": 479616, "start": 4809.44, "end": 4813.36, "text": " What's your intuition why sparsity leads to robustness? Because it feels like it would be", "tokens": [51028, 708, 311, 428, 24002, 983, 637, 685, 507, 6689, 281, 13956, 1287, 30, 1436, 309, 3417, 411, 309, 576, 312, 51224], "temperature": 0.0, "avg_logprob": -0.17772232540070065, "compression_ratio": 1.746212121212121, "no_speech_prob": 0.07693656533956528}, {"id": 920, "seek": 479616, "start": 4813.36, "end": 4822.88, "text": " less robust. Why would you feel the rest robust to you? So it just feels like if the fewer neurons", "tokens": [51224, 1570, 13956, 13, 1545, 576, 291, 841, 264, 1472, 13956, 281, 291, 30, 407, 309, 445, 3417, 411, 498, 264, 13366, 22027, 51700], "temperature": 0.0, "avg_logprob": -0.17772232540070065, "compression_ratio": 1.746212121212121, "no_speech_prob": 0.07693656533956528}, {"id": 921, "seek": 482288, "start": 4822.96, "end": 4827.84, "text": " are involved, the more fragile the representation. Yeah, but I didn't say there was lots of", "tokens": [50368, 366, 3288, 11, 264, 544, 23847, 264, 10290, 13, 865, 11, 457, 286, 994, 380, 584, 456, 390, 3195, 295, 50612], "temperature": 0.0, "avg_logprob": -0.18916676187107706, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.00382337742485106}, {"id": 922, "seek": 482288, "start": 4827.84, "end": 4834.400000000001, "text": " funerals. I said, let's say 200. That's a lot. There's still a lot. So here's an intuition for it.", "tokens": [50612, 1019, 260, 1124, 13, 286, 848, 11, 718, 311, 584, 2331, 13, 663, 311, 257, 688, 13, 821, 311, 920, 257, 688, 13, 407, 510, 311, 364, 24002, 337, 309, 13, 50940], "temperature": 0.0, "avg_logprob": -0.18916676187107706, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.00382337742485106}, {"id": 923, "seek": 482288, "start": 4835.12, "end": 4840.64, "text": " This is a bit technical. So for, you know, for engineers, machine learning people,", "tokens": [50976, 639, 307, 257, 857, 6191, 13, 407, 337, 11, 291, 458, 11, 337, 11955, 11, 3479, 2539, 561, 11, 51252], "temperature": 0.0, "avg_logprob": -0.18916676187107706, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.00382337742485106}, {"id": 924, "seek": 482288, "start": 4840.64, "end": 4845.6, "text": " this would be easy, but all the listeners, maybe not. If you're trying to classify something,", "tokens": [51252, 341, 576, 312, 1858, 11, 457, 439, 264, 23274, 11, 1310, 406, 13, 759, 291, 434, 1382, 281, 33872, 746, 11, 51500], "temperature": 0.0, "avg_logprob": -0.18916676187107706, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.00382337742485106}, {"id": 925, "seek": 482288, "start": 4845.6, "end": 4849.6, "text": " you're trying to divide some very high dimensional space into different pieces,", "tokens": [51500, 291, 434, 1382, 281, 9845, 512, 588, 1090, 18795, 1901, 666, 819, 3755, 11, 51700], "temperature": 0.0, "avg_logprob": -0.18916676187107706, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.00382337742485106}, {"id": 926, "seek": 484960, "start": 4849.6, "end": 4853.52, "text": " A and B, and you're trying to create some point where you say all these points in this", "tokens": [50364, 316, 293, 363, 11, 293, 291, 434, 1382, 281, 1884, 512, 935, 689, 291, 584, 439, 613, 2793, 294, 341, 50560], "temperature": 0.0, "avg_logprob": -0.11122616624410174, "compression_ratio": 1.8589211618257262, "no_speech_prob": 0.0009398789843544364}, {"id": 927, "seek": 484960, "start": 4853.52, "end": 4856.320000000001, "text": " high dimensional space are A and all these points inside dimensional space are B.", "tokens": [50560, 1090, 18795, 1901, 366, 316, 293, 439, 613, 2793, 1854, 18795, 1901, 366, 363, 13, 50700], "temperature": 0.0, "avg_logprob": -0.11122616624410174, "compression_ratio": 1.8589211618257262, "no_speech_prob": 0.0009398789843544364}, {"id": 928, "seek": 484960, "start": 4857.52, "end": 4863.280000000001, "text": " And if you have points that are close to that line, it's not very robust. It works for all", "tokens": [50760, 400, 498, 291, 362, 2793, 300, 366, 1998, 281, 300, 1622, 11, 309, 311, 406, 588, 13956, 13, 467, 1985, 337, 439, 51048], "temperature": 0.0, "avg_logprob": -0.11122616624410174, "compression_ratio": 1.8589211618257262, "no_speech_prob": 0.0009398789843544364}, {"id": 929, "seek": 484960, "start": 4863.280000000001, "end": 4868.240000000001, "text": " the points you know about, but it's, it's not very robust because you just move a little bit and", "tokens": [51048, 264, 2793, 291, 458, 466, 11, 457, 309, 311, 11, 309, 311, 406, 588, 13956, 570, 291, 445, 1286, 257, 707, 857, 293, 51296], "temperature": 0.0, "avg_logprob": -0.11122616624410174, "compression_ratio": 1.8589211618257262, "no_speech_prob": 0.0009398789843544364}, {"id": 930, "seek": 484960, "start": 4868.240000000001, "end": 4874.160000000001, "text": " you've crossed over the line. When you have sparse representations, imagine I pick, I have,", "tokens": [51296, 291, 600, 14622, 670, 264, 1622, 13, 1133, 291, 362, 637, 11668, 33358, 11, 3811, 286, 1888, 11, 286, 362, 11, 51592], "temperature": 0.0, "avg_logprob": -0.11122616624410174, "compression_ratio": 1.8589211618257262, "no_speech_prob": 0.0009398789843544364}, {"id": 931, "seek": 487416, "start": 4874.16, "end": 4880.24, "text": " I'm going to pick 200 cells active out of, out of 10,000. Okay. So I have 200 cells active.", "tokens": [50364, 286, 478, 516, 281, 1888, 2331, 5438, 4967, 484, 295, 11, 484, 295, 1266, 11, 1360, 13, 1033, 13, 407, 286, 362, 2331, 5438, 4967, 13, 50668], "temperature": 0.0, "avg_logprob": -0.0684384641976192, "compression_ratio": 1.7739463601532568, "no_speech_prob": 0.00394525658339262}, {"id": 932, "seek": 487416, "start": 4880.24, "end": 4884.88, "text": " Now let's say I pick randomly another, a different representation, 200. The overlap", "tokens": [50668, 823, 718, 311, 584, 286, 1888, 16979, 1071, 11, 257, 819, 10290, 11, 2331, 13, 440, 19959, 50900], "temperature": 0.0, "avg_logprob": -0.0684384641976192, "compression_ratio": 1.7739463601532568, "no_speech_prob": 0.00394525658339262}, {"id": 933, "seek": 487416, "start": 4884.88, "end": 4890.8, "text": " between those is going to be very small, just a few. I can pick millions of samples randomly", "tokens": [50900, 1296, 729, 307, 516, 281, 312, 588, 1359, 11, 445, 257, 1326, 13, 286, 393, 1888, 6803, 295, 10938, 16979, 51196], "temperature": 0.0, "avg_logprob": -0.0684384641976192, "compression_ratio": 1.7739463601532568, "no_speech_prob": 0.00394525658339262}, {"id": 934, "seek": 487416, "start": 4891.44, "end": 4898.88, "text": " of 200 neurons and not one of them will overlap more than just a few. So one way to think about", "tokens": [51228, 295, 2331, 22027, 293, 406, 472, 295, 552, 486, 19959, 544, 813, 445, 257, 1326, 13, 407, 472, 636, 281, 519, 466, 51600], "temperature": 0.0, "avg_logprob": -0.0684384641976192, "compression_ratio": 1.7739463601532568, "no_speech_prob": 0.00394525658339262}, {"id": 935, "seek": 487416, "start": 4898.88, "end": 4903.36, "text": " is if I want to fool one of these representations to look like one of those other representations,", "tokens": [51600, 307, 498, 286, 528, 281, 7979, 472, 295, 613, 33358, 281, 574, 411, 472, 295, 729, 661, 33358, 11, 51824], "temperature": 0.0, "avg_logprob": -0.0684384641976192, "compression_ratio": 1.7739463601532568, "no_speech_prob": 0.00394525658339262}, {"id": 936, "seek": 490336, "start": 4903.36, "end": 4908.16, "text": " I can't move just one cell or two cells or three cells or four cells. I have to move a hundred cells", "tokens": [50364, 286, 393, 380, 1286, 445, 472, 2815, 420, 732, 5438, 420, 1045, 5438, 420, 1451, 5438, 13, 286, 362, 281, 1286, 257, 3262, 5438, 50604], "temperature": 0.0, "avg_logprob": -0.11758268485635014, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0001488314737798646}, {"id": 937, "seek": 490336, "start": 4909.12, "end": 4916.08, "text": " and that makes them robust. In terms of further, so you mentioned sparsity.", "tokens": [50652, 293, 300, 1669, 552, 13956, 13, 682, 2115, 295, 3052, 11, 370, 291, 2835, 637, 685, 507, 13, 51000], "temperature": 0.0, "avg_logprob": -0.11758268485635014, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0001488314737798646}, {"id": 938, "seek": 490336, "start": 4916.08, "end": 4921.04, "text": " Won't it be the next thing? Yeah. Okay. So we have, we picked one. We don't know if it's going", "tokens": [51000, 14710, 380, 309, 312, 264, 958, 551, 30, 865, 13, 1033, 13, 407, 321, 362, 11, 321, 6183, 472, 13, 492, 500, 380, 458, 498, 309, 311, 516, 51248], "temperature": 0.0, "avg_logprob": -0.11758268485635014, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0001488314737798646}, {"id": 939, "seek": 490336, "start": 4921.04, "end": 4925.04, "text": " to work well yet. So again, we're trying to come up incremental ways of moving from", "tokens": [51248, 281, 589, 731, 1939, 13, 407, 797, 11, 321, 434, 1382, 281, 808, 493, 35759, 2098, 295, 2684, 490, 51448], "temperature": 0.0, "avg_logprob": -0.11758268485635014, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0001488314737798646}, {"id": 940, "seek": 490336, "start": 4925.759999999999, "end": 4931.36, "text": " brain theory to add pieces to machine learning, current machine learning world and one step at", "tokens": [51484, 3567, 5261, 281, 909, 3755, 281, 3479, 2539, 11, 2190, 3479, 2539, 1002, 293, 472, 1823, 412, 51764], "temperature": 0.0, "avg_logprob": -0.11758268485635014, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0001488314737798646}, {"id": 941, "seek": 493136, "start": 4931.36, "end": 4936.0, "text": " a time. So the next thing we're going to try to do is sort of incorporate some of the ideas of", "tokens": [50364, 257, 565, 13, 407, 264, 958, 551, 321, 434, 516, 281, 853, 281, 360, 307, 1333, 295, 16091, 512, 295, 264, 3487, 295, 50596], "temperature": 0.0, "avg_logprob": -0.12039299171511866, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.00043044870835728943}, {"id": 942, "seek": 493136, "start": 4937.5199999999995, "end": 4943.36, "text": " the 1000 brains theory that you have many, many models and that are voting. Now that idea is not", "tokens": [50672, 264, 9714, 15442, 5261, 300, 291, 362, 867, 11, 867, 5245, 293, 300, 366, 10419, 13, 823, 300, 1558, 307, 406, 50964], "temperature": 0.0, "avg_logprob": -0.12039299171511866, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.00043044870835728943}, {"id": 943, "seek": 493136, "start": 4943.36, "end": 4948.96, "text": " new. There's a mixture of models has been around for a long time, but the way the brain does it is", "tokens": [50964, 777, 13, 821, 311, 257, 9925, 295, 5245, 575, 668, 926, 337, 257, 938, 565, 11, 457, 264, 636, 264, 3567, 775, 309, 307, 51244], "temperature": 0.0, "avg_logprob": -0.12039299171511866, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.00043044870835728943}, {"id": 944, "seek": 493136, "start": 4948.96, "end": 4955.679999999999, "text": " a little different and the way it votes is different and the kind of way it represents", "tokens": [51244, 257, 707, 819, 293, 264, 636, 309, 12068, 307, 819, 293, 264, 733, 295, 636, 309, 8855, 51580], "temperature": 0.0, "avg_logprob": -0.12039299171511866, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.00043044870835728943}, {"id": 945, "seek": 493136, "start": 4955.679999999999, "end": 4960.96, "text": " uncertainty is different. So we're just starting this work, but we're going to try to see if we", "tokens": [51580, 15697, 307, 819, 13, 407, 321, 434, 445, 2891, 341, 589, 11, 457, 321, 434, 516, 281, 853, 281, 536, 498, 321, 51844], "temperature": 0.0, "avg_logprob": -0.12039299171511866, "compression_ratio": 1.8122605363984674, "no_speech_prob": 0.00043044870835728943}, {"id": 946, "seek": 496096, "start": 4961.36, "end": 4965.28, "text": " sort of incorporate some of the principles of voting or principles of 1000 brain theory,", "tokens": [50384, 1333, 295, 16091, 512, 295, 264, 9156, 295, 10419, 420, 9156, 295, 9714, 3567, 5261, 11, 50580], "temperature": 0.0, "avg_logprob": -0.16067020802558224, "compression_ratio": 1.6403940886699508, "no_speech_prob": 0.00014877956709824502}, {"id": 947, "seek": 496096, "start": 4966.0, "end": 4972.64, "text": " like lots of simple models that talk to each other in a very certain way.", "tokens": [50616, 411, 3195, 295, 2199, 5245, 300, 751, 281, 1184, 661, 294, 257, 588, 1629, 636, 13, 50948], "temperature": 0.0, "avg_logprob": -0.16067020802558224, "compression_ratio": 1.6403940886699508, "no_speech_prob": 0.00014877956709824502}, {"id": 948, "seek": 496096, "start": 4973.84, "end": 4980.4800000000005, "text": " And can we build more machines and systems that learn faster and also, well, mostly", "tokens": [51008, 400, 393, 321, 1322, 544, 8379, 293, 3652, 300, 1466, 4663, 293, 611, 11, 731, 11, 5240, 51340], "temperature": 0.0, "avg_logprob": -0.16067020802558224, "compression_ratio": 1.6403940886699508, "no_speech_prob": 0.00014877956709824502}, {"id": 949, "seek": 496096, "start": 4981.92, "end": 4989.6, "text": " are multimodal and robust to multimodal type of issues. So one of the challenges there", "tokens": [51412, 366, 32972, 378, 304, 293, 13956, 281, 32972, 378, 304, 2010, 295, 2663, 13, 407, 472, 295, 264, 4759, 456, 51796], "temperature": 0.0, "avg_logprob": -0.16067020802558224, "compression_ratio": 1.6403940886699508, "no_speech_prob": 0.00014877956709824502}, {"id": 950, "seek": 498960, "start": 4989.6, "end": 4995.52, "text": " is the machine learning computer vision community has certain sets of benchmarks.", "tokens": [50364, 307, 264, 3479, 2539, 3820, 5201, 1768, 575, 1629, 6352, 295, 43751, 13, 50660], "temperature": 0.0, "avg_logprob": -0.15158581733703613, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.0007786693749949336}, {"id": 951, "seek": 498960, "start": 4995.52, "end": 5000.96, "text": " So it's a test based on which they compete. And I would argue, especially from your perspective,", "tokens": [50660, 407, 309, 311, 257, 1500, 2361, 322, 597, 436, 11831, 13, 400, 286, 576, 9695, 11, 2318, 490, 428, 4585, 11, 50932], "temperature": 0.0, "avg_logprob": -0.15158581733703613, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.0007786693749949336}, {"id": 952, "seek": 498960, "start": 5001.92, "end": 5008.72, "text": " that those benchmarks aren't that useful for testing the aspects that the brain is good at", "tokens": [50980, 300, 729, 43751, 3212, 380, 300, 4420, 337, 4997, 264, 7270, 300, 264, 3567, 307, 665, 412, 51320], "temperature": 0.0, "avg_logprob": -0.15158581733703613, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.0007786693749949336}, {"id": 953, "seek": 498960, "start": 5008.72, "end": 5013.360000000001, "text": " or intelligent. They're not really testing intelligence. They're very fine. And it's been", "tokens": [51320, 420, 13232, 13, 814, 434, 406, 534, 4997, 7599, 13, 814, 434, 588, 2489, 13, 400, 309, 311, 668, 51552], "temperature": 0.0, "avg_logprob": -0.15158581733703613, "compression_ratio": 1.6244343891402715, "no_speech_prob": 0.0007786693749949336}, {"id": 954, "seek": 501336, "start": 5013.36, "end": 5019.759999999999, "text": " extremely useful for developing specific mathematical models, but it's not useful in the", "tokens": [50364, 4664, 4420, 337, 6416, 2685, 18894, 5245, 11, 457, 309, 311, 406, 4420, 294, 264, 50684], "temperature": 0.0, "avg_logprob": -0.11721038818359375, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.013422992080450058}, {"id": 955, "seek": 501336, "start": 5019.759999999999, "end": 5024.96, "text": " long term for creating intelligence. So you think you also have a role in proposing better", "tokens": [50684, 938, 1433, 337, 4084, 7599, 13, 407, 291, 519, 291, 611, 362, 257, 3090, 294, 29939, 1101, 50944], "temperature": 0.0, "avg_logprob": -0.11721038818359375, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.013422992080450058}, {"id": 956, "seek": 501336, "start": 5026.08, "end": 5030.08, "text": " tests? Yeah, this is a very, you've identified a very serious problem.", "tokens": [51000, 6921, 30, 865, 11, 341, 307, 257, 588, 11, 291, 600, 9234, 257, 588, 3156, 1154, 13, 51200], "temperature": 0.0, "avg_logprob": -0.11721038818359375, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.013422992080450058}, {"id": 957, "seek": 501336, "start": 5031.36, "end": 5035.5199999999995, "text": " First of all, the test that they have or the test that they want, not the test of the other", "tokens": [51264, 2386, 295, 439, 11, 264, 1500, 300, 436, 362, 420, 264, 1500, 300, 436, 528, 11, 406, 264, 1500, 295, 264, 661, 51472], "temperature": 0.0, "avg_logprob": -0.11721038818359375, "compression_ratio": 1.6208530805687205, "no_speech_prob": 0.013422992080450058}, {"id": 958, "seek": 503552, "start": 5035.52, "end": 5042.72, "text": " things that we're trying to do, right? You know, what are the so on? The second thing is,", "tokens": [50364, 721, 300, 321, 434, 1382, 281, 360, 11, 558, 30, 509, 458, 11, 437, 366, 264, 370, 322, 30, 440, 1150, 551, 307, 11, 50724], "temperature": 0.0, "avg_logprob": -0.13255423018075888, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.011684889905154705}, {"id": 959, "seek": 503552, "start": 5042.72, "end": 5049.280000000001, "text": " sometimes these to be competitive in these tests, you have to have huge data sets and huge computing", "tokens": [50724, 2171, 613, 281, 312, 10043, 294, 613, 6921, 11, 291, 362, 281, 362, 2603, 1412, 6352, 293, 2603, 15866, 51052], "temperature": 0.0, "avg_logprob": -0.13255423018075888, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.011684889905154705}, {"id": 960, "seek": 503552, "start": 5049.280000000001, "end": 5055.4400000000005, "text": " power. And so, you know, and we don't have that here. We don't have it as well as other big teams", "tokens": [51052, 1347, 13, 400, 370, 11, 291, 458, 11, 293, 321, 500, 380, 362, 300, 510, 13, 492, 500, 380, 362, 309, 382, 731, 382, 661, 955, 5491, 51360], "temperature": 0.0, "avg_logprob": -0.13255423018075888, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.011684889905154705}, {"id": 961, "seek": 503552, "start": 5055.4400000000005, "end": 5062.320000000001, "text": " that big companies do. So there's numerous issues there. You know, we come out of, you know,", "tokens": [51360, 300, 955, 3431, 360, 13, 407, 456, 311, 12546, 2663, 456, 13, 509, 458, 11, 321, 808, 484, 295, 11, 291, 458, 11, 51704], "temperature": 0.0, "avg_logprob": -0.13255423018075888, "compression_ratio": 1.7085201793721974, "no_speech_prob": 0.011684889905154705}, {"id": 962, "seek": 506232, "start": 5062.32, "end": 5066.0, "text": " we're our approach to this is all based on in some sense, you might argue elegance,", "tokens": [50364, 321, 434, 527, 3109, 281, 341, 307, 439, 2361, 322, 294, 512, 2020, 11, 291, 1062, 9695, 14459, 719, 11, 50548], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 963, "seek": 506232, "start": 5066.0, "end": 5068.799999999999, "text": " we're coming at it from like a theoretical base that we think, Oh, my God, this is so,", "tokens": [50548, 321, 434, 1348, 412, 309, 490, 411, 257, 20864, 3096, 300, 321, 519, 11, 876, 11, 452, 1265, 11, 341, 307, 370, 11, 50688], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 964, "seek": 506232, "start": 5068.799999999999, "end": 5071.679999999999, "text": " this is so clearly elegant. This is how brains work. This is what intelligence is.", "tokens": [50688, 341, 307, 370, 4448, 21117, 13, 639, 307, 577, 15442, 589, 13, 639, 307, 437, 7599, 307, 13, 50832], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 965, "seek": 506232, "start": 5071.679999999999, "end": 5074.88, "text": " But the machine learning world has gotten in this phase where they think it doesn't matter.", "tokens": [50832, 583, 264, 3479, 2539, 1002, 575, 5768, 294, 341, 5574, 689, 436, 519, 309, 1177, 380, 1871, 13, 50992], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 966, "seek": 506232, "start": 5075.44, "end": 5079.36, "text": " Doesn't matter what you think, as long as you do, you know, 0.1% better on this benchmark,", "tokens": [51020, 12955, 380, 1871, 437, 291, 519, 11, 382, 938, 382, 291, 360, 11, 291, 458, 11, 1958, 13, 16, 4, 1101, 322, 341, 18927, 11, 51216], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 967, "seek": 506232, "start": 5079.36, "end": 5085.28, "text": " that's what that's all that matters. And that's a problem. You know, we have to figure out how", "tokens": [51216, 300, 311, 437, 300, 311, 439, 300, 7001, 13, 400, 300, 311, 257, 1154, 13, 509, 458, 11, 321, 362, 281, 2573, 484, 577, 51512], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 968, "seek": 506232, "start": 5085.28, "end": 5088.639999999999, "text": " to get around that. That's that's a challenge for us. That's that's one of the challenges that", "tokens": [51512, 281, 483, 926, 300, 13, 663, 311, 300, 311, 257, 3430, 337, 505, 13, 663, 311, 300, 311, 472, 295, 264, 4759, 300, 51680], "temperature": 0.0, "avg_logprob": -0.14667562381949967, "compression_ratio": 1.87987987987988, "no_speech_prob": 0.0013669559266418219}, {"id": 969, "seek": 508864, "start": 5088.64, "end": 5095.12, "text": " we have to deal with. So I agree, you've identified a big issue. It's difficult for those reasons.", "tokens": [50364, 321, 362, 281, 2028, 365, 13, 407, 286, 3986, 11, 291, 600, 9234, 257, 955, 2734, 13, 467, 311, 2252, 337, 729, 4112, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13663900391129422, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.002672460861504078}, {"id": 970, "seek": 508864, "start": 5095.84, "end": 5100.72, "text": " But, you know, part of the reasons I'm talking to you here today is I hope I'm going to get some", "tokens": [50724, 583, 11, 291, 458, 11, 644, 295, 264, 4112, 286, 478, 1417, 281, 291, 510, 965, 307, 286, 1454, 286, 478, 516, 281, 483, 512, 50968], "temperature": 0.0, "avg_logprob": -0.13663900391129422, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.002672460861504078}, {"id": 971, "seek": 508864, "start": 5100.72, "end": 5105.04, "text": " machine learning people to say, read those papers. Those might be some interesting ideas. I'm tired.", "tokens": [50968, 3479, 2539, 561, 281, 584, 11, 1401, 729, 10577, 13, 3950, 1062, 312, 512, 1880, 3487, 13, 286, 478, 5868, 13, 51184], "temperature": 0.0, "avg_logprob": -0.13663900391129422, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.002672460861504078}, {"id": 972, "seek": 508864, "start": 5105.04, "end": 5107.6, "text": " I'm tired of doing this 0.1% improvement stuff, you know,", "tokens": [51184, 286, 478, 5868, 295, 884, 341, 1958, 13, 16, 4, 10444, 1507, 11, 291, 458, 11, 51312], "temperature": 0.0, "avg_logprob": -0.13663900391129422, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.002672460861504078}, {"id": 973, "seek": 508864, "start": 5108.400000000001, "end": 5112.96, "text": " well, that's what that's why I'm here as well, because I think machine learning now as a community", "tokens": [51352, 731, 11, 300, 311, 437, 300, 311, 983, 286, 478, 510, 382, 731, 11, 570, 286, 519, 3479, 2539, 586, 382, 257, 1768, 51580], "temperature": 0.0, "avg_logprob": -0.13663900391129422, "compression_ratio": 1.7159090909090908, "no_speech_prob": 0.002672460861504078}, {"id": 974, "seek": 511296, "start": 5112.96, "end": 5120.8, "text": " is a place where the next step is needs to be orthogonal to what has received success in the", "tokens": [50364, 307, 257, 1081, 689, 264, 958, 1823, 307, 2203, 281, 312, 41488, 281, 437, 575, 4613, 2245, 294, 264, 50756], "temperature": 0.0, "avg_logprob": -0.13026001971700918, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.016908081248402596}, {"id": 975, "seek": 511296, "start": 5120.8, "end": 5126.08, "text": " past. You see other leaders saying this, machine learning leaders, you know, Jeff Hinton, with", "tokens": [50756, 1791, 13, 509, 536, 661, 3523, 1566, 341, 11, 3479, 2539, 3523, 11, 291, 458, 11, 7506, 389, 12442, 11, 365, 51020], "temperature": 0.0, "avg_logprob": -0.13026001971700918, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.016908081248402596}, {"id": 976, "seek": 511296, "start": 5126.08, "end": 5129.76, "text": " his capsules idea. Many people have gotten up saying, you know, we're going to hit road,", "tokens": [51020, 702, 13855, 3473, 1558, 13, 5126, 561, 362, 5768, 493, 1566, 11, 291, 458, 11, 321, 434, 516, 281, 2045, 3060, 11, 51204], "temperature": 0.0, "avg_logprob": -0.13026001971700918, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.016908081248402596}, {"id": 977, "seek": 511296, "start": 5130.88, "end": 5136.08, "text": " maybe we should look at the brain, you know, things like that. So hopefully that thinking", "tokens": [51260, 1310, 321, 820, 574, 412, 264, 3567, 11, 291, 458, 11, 721, 411, 300, 13, 407, 4696, 300, 1953, 51520], "temperature": 0.0, "avg_logprob": -0.13026001971700918, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.016908081248402596}, {"id": 978, "seek": 511296, "start": 5136.08, "end": 5141.12, "text": " will occur organically. And then then we're in a nice position for people to come and look at our", "tokens": [51520, 486, 5160, 1798, 984, 13, 400, 550, 550, 321, 434, 294, 257, 1481, 2535, 337, 561, 281, 808, 293, 574, 412, 527, 51772], "temperature": 0.0, "avg_logprob": -0.13026001971700918, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.016908081248402596}, {"id": 979, "seek": 514112, "start": 5141.12, "end": 5144.96, "text": " work and say, well, what can we learn from these guys? Yeah, MIT is just launching a", "tokens": [50364, 589, 293, 584, 11, 731, 11, 437, 393, 321, 1466, 490, 613, 1074, 30, 865, 11, 13100, 307, 445, 18354, 257, 50556], "temperature": 0.0, "avg_logprob": -0.22808884737784402, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.005910074338316917}, {"id": 980, "seek": 514112, "start": 5144.96, "end": 5150.16, "text": " billion dollar computing college that's centered around this idea. So on this idea of what?", "tokens": [50556, 5218, 7241, 15866, 3859, 300, 311, 18988, 926, 341, 1558, 13, 407, 322, 341, 1558, 295, 437, 30, 50816], "temperature": 0.0, "avg_logprob": -0.22808884737784402, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.005910074338316917}, {"id": 981, "seek": 514112, "start": 5150.88, "end": 5155.599999999999, "text": " Well, the idea that, you know, the humanities, psychology and neuroscience have to work all", "tokens": [50852, 1042, 11, 264, 1558, 300, 11, 291, 458, 11, 264, 36140, 11, 15105, 293, 42762, 362, 281, 589, 439, 51088], "temperature": 0.0, "avg_logprob": -0.22808884737784402, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.005910074338316917}, {"id": 982, "seek": 514112, "start": 5155.599999999999, "end": 5161.36, "text": " together to get to build the S. Yeah. I mean, Stanford just did this human center today. I", "tokens": [51088, 1214, 281, 483, 281, 1322, 264, 318, 13, 865, 13, 286, 914, 11, 20374, 445, 630, 341, 1952, 3056, 965, 13, 286, 51376], "temperature": 0.0, "avg_logprob": -0.22808884737784402, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.005910074338316917}, {"id": 983, "seek": 514112, "start": 5161.36, "end": 5167.92, "text": " said, yeah, I'm a little disappointed in these initiatives because, you know, they're, they're", "tokens": [51376, 848, 11, 1338, 11, 286, 478, 257, 707, 13856, 294, 613, 16194, 570, 11, 291, 458, 11, 436, 434, 11, 436, 434, 51704], "temperature": 0.0, "avg_logprob": -0.22808884737784402, "compression_ratio": 1.6509090909090909, "no_speech_prob": 0.005910074338316917}, {"id": 984, "seek": 516792, "start": 5167.92, "end": 5173.4400000000005, "text": " focusing on sort of the human side of it. And it could very easily slip into how humans interact", "tokens": [50364, 8416, 322, 1333, 295, 264, 1952, 1252, 295, 309, 13, 400, 309, 727, 588, 3612, 11140, 666, 577, 6255, 4648, 50640], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 985, "seek": 516792, "start": 5173.4400000000005, "end": 5179.36, "text": " with intelligent machines, which is nothing wrong with that. But that's not, that is orthogonal", "tokens": [50640, 365, 13232, 8379, 11, 597, 307, 1825, 2085, 365, 300, 13, 583, 300, 311, 406, 11, 300, 307, 41488, 50936], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 986, "seek": 516792, "start": 5179.36, "end": 5183.12, "text": " to what we're trying to do. We're trying to say, like, what is the essence of intelligence? I don't", "tokens": [50936, 281, 437, 321, 434, 1382, 281, 360, 13, 492, 434, 1382, 281, 584, 11, 411, 11, 437, 307, 264, 12801, 295, 7599, 30, 286, 500, 380, 51124], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 987, "seek": 516792, "start": 5183.12, "end": 5187.04, "text": " care. In fact, I want to build intelligent machines that aren't emotional, that don't", "tokens": [51124, 1127, 13, 682, 1186, 11, 286, 528, 281, 1322, 13232, 8379, 300, 3212, 380, 6863, 11, 300, 500, 380, 51320], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 988, "seek": 516792, "start": 5187.04, "end": 5191.76, "text": " smile at you, that, you know, that aren't trying to tuck you in at night.", "tokens": [51320, 7563, 412, 291, 11, 300, 11, 291, 458, 11, 300, 3212, 380, 1382, 281, 18457, 291, 294, 412, 1818, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 989, "seek": 516792, "start": 5191.76, "end": 5196.88, "text": " Yeah, there is that pattern that you, when you talk about understanding humans is important", "tokens": [51556, 865, 11, 456, 307, 300, 5102, 300, 291, 11, 562, 291, 751, 466, 3701, 6255, 307, 1021, 51812], "temperature": 0.0, "avg_logprob": -0.12002588907877604, "compression_ratio": 1.825503355704698, "no_speech_prob": 0.001032067695632577}, {"id": 990, "seek": 519688, "start": 5196.88, "end": 5201.4400000000005, "text": " for understanding intelligence, that you start slipping into topics of ethics or,", "tokens": [50364, 337, 3701, 7599, 11, 300, 291, 722, 36779, 666, 8378, 295, 19769, 420, 11, 50592], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 991, "seek": 519688, "start": 5202.72, "end": 5206.88, "text": " yeah, like you said, the interactive elements as opposed to, no, no, no, we have to zoom in on", "tokens": [50656, 1338, 11, 411, 291, 848, 11, 264, 15141, 4959, 382, 8851, 281, 11, 572, 11, 572, 11, 572, 11, 321, 362, 281, 8863, 294, 322, 50864], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 992, "seek": 519688, "start": 5206.88, "end": 5212.72, "text": " the brain, study, study what the human brain, the baby, the, let's study what a brain does.", "tokens": [50864, 264, 3567, 11, 2979, 11, 2979, 437, 264, 1952, 3567, 11, 264, 3186, 11, 264, 11, 718, 311, 2979, 437, 257, 3567, 775, 13, 51156], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 993, "seek": 519688, "start": 5212.72, "end": 5217.92, "text": " Does. And then we can decide which parts of that we want to recreate in some system. But", "tokens": [51156, 4402, 13, 400, 550, 321, 393, 4536, 597, 3166, 295, 300, 321, 528, 281, 25833, 294, 512, 1185, 13, 583, 51416], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 994, "seek": 519688, "start": 5217.92, "end": 5221.12, "text": " until you have that theory about what the brain does, what's the point? You know, it's just,", "tokens": [51416, 1826, 291, 362, 300, 5261, 466, 437, 264, 3567, 775, 11, 437, 311, 264, 935, 30, 509, 458, 11, 309, 311, 445, 11, 51576], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 995, "seek": 519688, "start": 5221.12, "end": 5224.56, "text": " you're going to be wasting time, I think. Right. Just to break it down on the artificial", "tokens": [51576, 291, 434, 516, 281, 312, 20457, 565, 11, 286, 519, 13, 1779, 13, 1449, 281, 1821, 309, 760, 322, 264, 11677, 51748], "temperature": 0.0, "avg_logprob": -0.17042632136784547, "compression_ratio": 1.75, "no_speech_prob": 0.0005032798508182168}, {"id": 996, "seek": 522456, "start": 5224.56, "end": 5229.04, "text": " neural networks side, maybe you can speak to this on the, on the biologic neural networks side,", "tokens": [50364, 18161, 9590, 1252, 11, 1310, 291, 393, 1710, 281, 341, 322, 264, 11, 322, 264, 3228, 36661, 18161, 9590, 1252, 11, 50588], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 997, "seek": 522456, "start": 5229.04, "end": 5235.04, "text": " the process of learning versus the process of inference. Maybe you can explain to me,", "tokens": [50588, 264, 1399, 295, 2539, 5717, 264, 1399, 295, 38253, 13, 2704, 291, 393, 2903, 281, 385, 11, 50888], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 998, "seek": 522456, "start": 5236.400000000001, "end": 5240.0, "text": " what is there a difference between, you know, in artificial neural networks, there's a", "tokens": [50956, 437, 307, 456, 257, 2649, 1296, 11, 291, 458, 11, 294, 11677, 18161, 9590, 11, 456, 311, 257, 51136], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 999, "seek": 522456, "start": 5240.0, "end": 5244.240000000001, "text": " difference between the learning stage and the inference stage. Do you see the brain as something", "tokens": [51136, 2649, 1296, 264, 2539, 3233, 293, 264, 38253, 3233, 13, 1144, 291, 536, 264, 3567, 382, 746, 51348], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 1000, "seek": 522456, "start": 5244.240000000001, "end": 5249.84, "text": " different? One of the, one of the big distinctions that people often say, I don't know how correct", "tokens": [51348, 819, 30, 1485, 295, 264, 11, 472, 295, 264, 955, 1483, 49798, 300, 561, 2049, 584, 11, 286, 500, 380, 458, 577, 3006, 51628], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 1001, "seek": 522456, "start": 5249.84, "end": 5254.240000000001, "text": " it is, is artificial neural networks need a lot of data, they're very inefficient learning.", "tokens": [51628, 309, 307, 11, 307, 11677, 18161, 9590, 643, 257, 688, 295, 1412, 11, 436, 434, 588, 43495, 2539, 13, 51848], "temperature": 0.0, "avg_logprob": -0.12187735736370087, "compression_ratio": 2.0, "no_speech_prob": 0.014713631942868233}, {"id": 1002, "seek": 525456, "start": 5254.8, "end": 5260.160000000001, "text": " Do you see that as a correct distinction from the, the biology of the human brain,", "tokens": [50376, 1144, 291, 536, 300, 382, 257, 3006, 16844, 490, 264, 11, 264, 14956, 295, 264, 1952, 3567, 11, 50644], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1003, "seek": 525456, "start": 5260.160000000001, "end": 5264.160000000001, "text": " that the human brain is very efficient? Or is that just something we deceive ourselves with?", "tokens": [50644, 300, 264, 1952, 3567, 307, 588, 7148, 30, 1610, 307, 300, 445, 746, 321, 43440, 4175, 365, 30, 50844], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1004, "seek": 525456, "start": 5264.160000000001, "end": 5267.4400000000005, "text": " No, it is efficient, obviously. We can learn new things almost instantly.", "tokens": [50844, 883, 11, 309, 307, 7148, 11, 2745, 13, 492, 393, 1466, 777, 721, 1920, 13518, 13, 51008], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1005, "seek": 525456, "start": 5267.4400000000005, "end": 5272.240000000001, "text": " And so what elements do you think? Yeah, I can talk about that. You brought up two issues there.", "tokens": [51008, 400, 370, 437, 4959, 360, 291, 519, 30, 865, 11, 286, 393, 751, 466, 300, 13, 509, 3038, 493, 732, 2663, 456, 13, 51248], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1006, "seek": 525456, "start": 5272.240000000001, "end": 5277.200000000001, "text": " So remember I talked early about the constraints we, we always feel, well, one of those constraints", "tokens": [51248, 407, 1604, 286, 2825, 2440, 466, 264, 18491, 321, 11, 321, 1009, 841, 11, 731, 11, 472, 295, 729, 18491, 51496], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1007, "seek": 525456, "start": 5277.200000000001, "end": 5282.72, "text": " is the fact that brains are continually learning. That's not something we said, oh, we can add that", "tokens": [51496, 307, 264, 1186, 300, 15442, 366, 22277, 2539, 13, 663, 311, 406, 746, 321, 848, 11, 1954, 11, 321, 393, 909, 300, 51772], "temperature": 0.0, "avg_logprob": -0.12139958097734524, "compression_ratio": 1.7388535031847134, "no_speech_prob": 0.00038588402094319463}, {"id": 1008, "seek": 528272, "start": 5282.72, "end": 5289.52, "text": " later. That's something that was upfront, had to be there from the start, made our problems", "tokens": [50364, 1780, 13, 663, 311, 746, 300, 390, 30264, 11, 632, 281, 312, 456, 490, 264, 722, 11, 1027, 527, 2740, 50704], "temperature": 0.0, "avg_logprob": -0.10448421315943941, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0007792744436301291}, {"id": 1009, "seek": 528272, "start": 5290.08, "end": 5296.16, "text": " harder. But we showed, going back to the 2016 paper on sequence memory, we showed how that", "tokens": [50732, 6081, 13, 583, 321, 4712, 11, 516, 646, 281, 264, 6549, 3035, 322, 8310, 4675, 11, 321, 4712, 577, 300, 51036], "temperature": 0.0, "avg_logprob": -0.10448421315943941, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0007792744436301291}, {"id": 1010, "seek": 528272, "start": 5296.16, "end": 5302.56, "text": " happens, how the brains infer and learn at the same time. And our models do that. They're not", "tokens": [51036, 2314, 11, 577, 264, 15442, 13596, 293, 1466, 412, 264, 912, 565, 13, 400, 527, 5245, 360, 300, 13, 814, 434, 406, 51356], "temperature": 0.0, "avg_logprob": -0.10448421315943941, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0007792744436301291}, {"id": 1011, "seek": 528272, "start": 5302.56, "end": 5309.68, "text": " two separate phases or two separate sets of time. I think that's a big, big problem in AI,", "tokens": [51356, 732, 4994, 18764, 420, 732, 4994, 6352, 295, 565, 13, 286, 519, 300, 311, 257, 955, 11, 955, 1154, 294, 7318, 11, 51712], "temperature": 0.0, "avg_logprob": -0.10448421315943941, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0007792744436301291}, {"id": 1012, "seek": 530968, "start": 5309.76, "end": 5316.4800000000005, "text": " at least for many applications, not for all. So I can talk about that. There are some that gets", "tokens": [50368, 412, 1935, 337, 867, 5821, 11, 406, 337, 439, 13, 407, 286, 393, 751, 466, 300, 13, 821, 366, 512, 300, 2170, 50704], "temperature": 0.0, "avg_logprob": -0.10944659078223073, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.0008164856117218733}, {"id": 1013, "seek": 530968, "start": 5316.4800000000005, "end": 5321.6, "text": " detailed. There are some parts of the neocortex in the brain where actually what's going on,", "tokens": [50704, 9942, 13, 821, 366, 512, 3166, 295, 264, 408, 905, 36143, 294, 264, 3567, 689, 767, 437, 311, 516, 322, 11, 50960], "temperature": 0.0, "avg_logprob": -0.10944659078223073, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.0008164856117218733}, {"id": 1014, "seek": 530968, "start": 5321.6, "end": 5326.16, "text": " there's these, there's these, with these cycles, they're like cycles of activity in the brain.", "tokens": [50960, 456, 311, 613, 11, 456, 311, 613, 11, 365, 613, 17796, 11, 436, 434, 411, 17796, 295, 5191, 294, 264, 3567, 13, 51188], "temperature": 0.0, "avg_logprob": -0.10944659078223073, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.0008164856117218733}, {"id": 1015, "seek": 530968, "start": 5326.8, "end": 5332.320000000001, "text": " And there's very strong evidence that you're doing more of inference on one part of the phase and", "tokens": [51220, 400, 456, 311, 588, 2068, 4467, 300, 291, 434, 884, 544, 295, 38253, 322, 472, 644, 295, 264, 5574, 293, 51496], "temperature": 0.0, "avg_logprob": -0.10944659078223073, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.0008164856117218733}, {"id": 1016, "seek": 530968, "start": 5332.320000000001, "end": 5335.68, "text": " more of learning on the other part of the phase. So the brain can actually sort of separate different", "tokens": [51496, 544, 295, 2539, 322, 264, 661, 644, 295, 264, 5574, 13, 407, 264, 3567, 393, 767, 1333, 295, 4994, 819, 51664], "temperature": 0.0, "avg_logprob": -0.10944659078223073, "compression_ratio": 1.9243027888446216, "no_speech_prob": 0.0008164856117218733}, {"id": 1017, "seek": 533568, "start": 5335.68, "end": 5340.72, "text": " populations of cells are going back and forth like this. But in general, I would say that's an", "tokens": [50364, 12822, 295, 5438, 366, 516, 646, 293, 5220, 411, 341, 13, 583, 294, 2674, 11, 286, 576, 584, 300, 311, 364, 50616], "temperature": 0.0, "avg_logprob": -0.13553684040651484, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.001926172524690628}, {"id": 1018, "seek": 533568, "start": 5340.72, "end": 5346.88, "text": " important problem. We have all of our networks that we've come up with do both. They're learning,", "tokens": [50616, 1021, 1154, 13, 492, 362, 439, 295, 527, 9590, 300, 321, 600, 808, 493, 365, 360, 1293, 13, 814, 434, 2539, 11, 50924], "temperature": 0.0, "avg_logprob": -0.13553684040651484, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.001926172524690628}, {"id": 1019, "seek": 533568, "start": 5346.88, "end": 5351.84, "text": " continuous learning networks. And you mentioned benchmarks earlier. Well, there are no benchmarks", "tokens": [50924, 10957, 2539, 9590, 13, 400, 291, 2835, 43751, 3071, 13, 1042, 11, 456, 366, 572, 43751, 51172], "temperature": 0.0, "avg_logprob": -0.13553684040651484, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.001926172524690628}, {"id": 1020, "seek": 533568, "start": 5351.84, "end": 5357.92, "text": " about that. Exactly. So we have to like, we get in our little soapbox and say, hey, by the way,", "tokens": [51172, 466, 300, 13, 7587, 13, 407, 321, 362, 281, 411, 11, 321, 483, 294, 527, 707, 14587, 4995, 293, 584, 11, 4177, 11, 538, 264, 636, 11, 51476], "temperature": 0.0, "avg_logprob": -0.13553684040651484, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.001926172524690628}, {"id": 1021, "seek": 533568, "start": 5357.92, "end": 5363.84, "text": " this is important and here's the mechanism for doing that. But until you can prove it to someone", "tokens": [51476, 341, 307, 1021, 293, 510, 311, 264, 7513, 337, 884, 300, 13, 583, 1826, 291, 393, 7081, 309, 281, 1580, 51772], "temperature": 0.0, "avg_logprob": -0.13553684040651484, "compression_ratio": 1.6484641638225257, "no_speech_prob": 0.001926172524690628}, {"id": 1022, "seek": 536384, "start": 5363.84, "end": 5367.6, "text": " in some, you know, commercial system or something, it's a little harder. So yeah, one of the things", "tokens": [50364, 294, 512, 11, 291, 458, 11, 6841, 1185, 420, 746, 11, 309, 311, 257, 707, 6081, 13, 407, 1338, 11, 472, 295, 264, 721, 50552], "temperature": 0.0, "avg_logprob": -0.13814594797844434, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.0019262946443632245}, {"id": 1023, "seek": 536384, "start": 5367.6, "end": 5375.2, "text": " I had to linger on that is in some ways to learn the concept of a coffee cup. You only need this one", "tokens": [50552, 286, 632, 281, 45657, 322, 300, 307, 294, 512, 2098, 281, 1466, 264, 3410, 295, 257, 4982, 4414, 13, 509, 787, 643, 341, 472, 50932], "temperature": 0.0, "avg_logprob": -0.13814594797844434, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.0019262946443632245}, {"id": 1024, "seek": 536384, "start": 5375.2, "end": 5380.08, "text": " coffee cup and maybe some time alone in a room with it. Well, the first thing is I, when I imagine", "tokens": [50932, 4982, 4414, 293, 1310, 512, 565, 3312, 294, 257, 1808, 365, 309, 13, 1042, 11, 264, 700, 551, 307, 286, 11, 562, 286, 3811, 51176], "temperature": 0.0, "avg_logprob": -0.13814594797844434, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.0019262946443632245}, {"id": 1025, "seek": 536384, "start": 5380.08, "end": 5384.32, "text": " I reach my hand into a black box and I'm reaching, I'm trying to touch something. I don't know up", "tokens": [51176, 286, 2524, 452, 1011, 666, 257, 2211, 2424, 293, 286, 478, 9906, 11, 286, 478, 1382, 281, 2557, 746, 13, 286, 500, 380, 458, 493, 51388], "temperature": 0.0, "avg_logprob": -0.13814594797844434, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.0019262946443632245}, {"id": 1026, "seek": 536384, "start": 5384.32, "end": 5389.92, "text": " front if it's something I already know, or if it's a new thing. And I have to, I'm doing both at the", "tokens": [51388, 1868, 498, 309, 311, 746, 286, 1217, 458, 11, 420, 498, 309, 311, 257, 777, 551, 13, 400, 286, 362, 281, 11, 286, 478, 884, 1293, 412, 264, 51668], "temperature": 0.0, "avg_logprob": -0.13814594797844434, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.0019262946443632245}, {"id": 1027, "seek": 538992, "start": 5389.92, "end": 5394.72, "text": " same time. I don't say, oh, let's see if it's a new thing. Oh, let's see if it's an old thing. I", "tokens": [50364, 912, 565, 13, 286, 500, 380, 584, 11, 1954, 11, 718, 311, 536, 498, 309, 311, 257, 777, 551, 13, 876, 11, 718, 311, 536, 498, 309, 311, 364, 1331, 551, 13, 286, 50604], "temperature": 0.0, "avg_logprob": -0.1016522720977143, "compression_ratio": 1.8479087452471483, "no_speech_prob": 0.03513448312878609}, {"id": 1028, "seek": 538992, "start": 5394.72, "end": 5400.88, "text": " don't do that. As I go, my brain says, oh, it's new or it's not new. And if it's new, I start learning", "tokens": [50604, 500, 380, 360, 300, 13, 1018, 286, 352, 11, 452, 3567, 1619, 11, 1954, 11, 309, 311, 777, 420, 309, 311, 406, 777, 13, 400, 498, 309, 311, 777, 11, 286, 722, 2539, 50912], "temperature": 0.0, "avg_logprob": -0.1016522720977143, "compression_ratio": 1.8479087452471483, "no_speech_prob": 0.03513448312878609}, {"id": 1029, "seek": 538992, "start": 5401.6, "end": 5405.84, "text": " what it is. So and by the way, it starts learning from the get go, even if we're going to recognize", "tokens": [50948, 437, 309, 307, 13, 407, 293, 538, 264, 636, 11, 309, 3719, 2539, 490, 264, 483, 352, 11, 754, 498, 321, 434, 516, 281, 5521, 51160], "temperature": 0.0, "avg_logprob": -0.1016522720977143, "compression_ratio": 1.8479087452471483, "no_speech_prob": 0.03513448312878609}, {"id": 1030, "seek": 538992, "start": 5405.84, "end": 5410.96, "text": " it. So they're not separate problems. And so that's the thing. The other thing you mentioned", "tokens": [51160, 309, 13, 407, 436, 434, 406, 4994, 2740, 13, 400, 370, 300, 311, 264, 551, 13, 440, 661, 551, 291, 2835, 51416], "temperature": 0.0, "avg_logprob": -0.1016522720977143, "compression_ratio": 1.8479087452471483, "no_speech_prob": 0.03513448312878609}, {"id": 1031, "seek": 538992, "start": 5410.96, "end": 5416.32, "text": " was the fast learning. So I was just talking about continuous learning, but there's also fast", "tokens": [51416, 390, 264, 2370, 2539, 13, 407, 286, 390, 445, 1417, 466, 10957, 2539, 11, 457, 456, 311, 611, 2370, 51684], "temperature": 0.0, "avg_logprob": -0.1016522720977143, "compression_ratio": 1.8479087452471483, "no_speech_prob": 0.03513448312878609}, {"id": 1032, "seek": 541632, "start": 5416.32, "end": 5420.08, "text": " learning. Literally, I can show you this coffee cup. And I say, here's a new coffee cup. It's", "tokens": [50364, 2539, 13, 23768, 11, 286, 393, 855, 291, 341, 4982, 4414, 13, 400, 286, 584, 11, 510, 311, 257, 777, 4982, 4414, 13, 467, 311, 50552], "temperature": 0.0, "avg_logprob": -0.104767126195571, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.0038237206172198057}, {"id": 1033, "seek": 541632, "start": 5420.08, "end": 5425.04, "text": " got the logo on it. Take a look at it. Done. You're done. You can predict what it's going to look", "tokens": [50552, 658, 264, 9699, 322, 309, 13, 3664, 257, 574, 412, 309, 13, 18658, 13, 509, 434, 1096, 13, 509, 393, 6069, 437, 309, 311, 516, 281, 574, 50800], "temperature": 0.0, "avg_logprob": -0.104767126195571, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.0038237206172198057}, {"id": 1034, "seek": 541632, "start": 5425.04, "end": 5432.719999999999, "text": " like, you know, in different positions. So I can talk about that too. In the brain, the way learning", "tokens": [50800, 411, 11, 291, 458, 11, 294, 819, 8432, 13, 407, 286, 393, 751, 466, 300, 886, 13, 682, 264, 3567, 11, 264, 636, 2539, 51184], "temperature": 0.0, "avg_logprob": -0.104767126195571, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.0038237206172198057}, {"id": 1035, "seek": 541632, "start": 5432.719999999999, "end": 5437.44, "text": " occurs. I mentioned this earlier, but I mentioned again, the way learning occurs, I imagine I have", "tokens": [51184, 11843, 13, 286, 2835, 341, 3071, 11, 457, 286, 2835, 797, 11, 264, 636, 2539, 11843, 11, 286, 3811, 286, 362, 51420], "temperature": 0.0, "avg_logprob": -0.104767126195571, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.0038237206172198057}, {"id": 1036, "seek": 541632, "start": 5437.44, "end": 5443.5199999999995, "text": " a section of a dendrite of a neuron. And I want to learn, I'm going to learn something new. I'm", "tokens": [51420, 257, 3541, 295, 257, 274, 521, 35002, 295, 257, 34090, 13, 400, 286, 528, 281, 1466, 11, 286, 478, 516, 281, 1466, 746, 777, 13, 286, 478, 51724], "temperature": 0.0, "avg_logprob": -0.104767126195571, "compression_ratio": 1.7773722627737227, "no_speech_prob": 0.0038237206172198057}, {"id": 1037, "seek": 544352, "start": 5443.52, "end": 5447.6, "text": " just doesn't matter what it is, I'm just going to learn something new. I need to recognize a new", "tokens": [50364, 445, 1177, 380, 1871, 437, 309, 307, 11, 286, 478, 445, 516, 281, 1466, 746, 777, 13, 286, 643, 281, 5521, 257, 777, 50568], "temperature": 0.0, "avg_logprob": -0.07630275957512134, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.000732141372282058}, {"id": 1038, "seek": 544352, "start": 5447.6, "end": 5453.6, "text": " pattern. So what I'm going to do is I'm going to form new synapses. New synapses, we're going to", "tokens": [50568, 5102, 13, 407, 437, 286, 478, 516, 281, 360, 307, 286, 478, 516, 281, 1254, 777, 5451, 2382, 279, 13, 1873, 5451, 2382, 279, 11, 321, 434, 516, 281, 50868], "temperature": 0.0, "avg_logprob": -0.07630275957512134, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.000732141372282058}, {"id": 1039, "seek": 544352, "start": 5453.6, "end": 5460.4800000000005, "text": " rewire the brain onto that section of the dendrite. Once I've done that, everything else that neuron", "tokens": [50868, 319, 42689, 264, 3567, 3911, 300, 3541, 295, 264, 274, 521, 35002, 13, 3443, 286, 600, 1096, 300, 11, 1203, 1646, 300, 34090, 51212], "temperature": 0.0, "avg_logprob": -0.07630275957512134, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.000732141372282058}, {"id": 1040, "seek": 544352, "start": 5460.4800000000005, "end": 5466.320000000001, "text": " has learned is not affected by it. That's because it's isolated to that small section of the dendrite.", "tokens": [51212, 575, 3264, 307, 406, 8028, 538, 309, 13, 663, 311, 570, 309, 311, 14621, 281, 300, 1359, 3541, 295, 264, 274, 521, 35002, 13, 51504], "temperature": 0.0, "avg_logprob": -0.07630275957512134, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.000732141372282058}, {"id": 1041, "seek": 544352, "start": 5466.320000000001, "end": 5471.200000000001, "text": " They're not all being added together, like a point neuron. So if I learned something new on this", "tokens": [51504, 814, 434, 406, 439, 885, 3869, 1214, 11, 411, 257, 935, 34090, 13, 407, 498, 286, 3264, 746, 777, 322, 341, 51748], "temperature": 0.0, "avg_logprob": -0.07630275957512134, "compression_ratio": 1.8296296296296297, "no_speech_prob": 0.000732141372282058}, {"id": 1042, "seek": 547120, "start": 5471.2, "end": 5474.8, "text": " segment here, it doesn't change any of the learning that occur anywhere else in that neuron.", "tokens": [50364, 9469, 510, 11, 309, 1177, 380, 1319, 604, 295, 264, 2539, 300, 5160, 4992, 1646, 294, 300, 34090, 13, 50544], "temperature": 0.0, "avg_logprob": -0.09354235696010903, "compression_ratio": 1.6872727272727273, "no_speech_prob": 0.0006878167623654008}, {"id": 1043, "seek": 547120, "start": 5474.8, "end": 5479.44, "text": " So I can add something without affecting previous learning. And I can do it quickly.", "tokens": [50544, 407, 286, 393, 909, 746, 1553, 17476, 3894, 2539, 13, 400, 286, 393, 360, 309, 2661, 13, 50776], "temperature": 0.0, "avg_logprob": -0.09354235696010903, "compression_ratio": 1.6872727272727273, "no_speech_prob": 0.0006878167623654008}, {"id": 1044, "seek": 547120, "start": 5480.88, "end": 5484.4, "text": " Now let's talk, we can talk about the quickness, how it's done in real neurons. You might say,", "tokens": [50848, 823, 718, 311, 751, 11, 321, 393, 751, 466, 264, 1702, 1287, 11, 577, 309, 311, 1096, 294, 957, 22027, 13, 509, 1062, 584, 11, 51024], "temperature": 0.0, "avg_logprob": -0.09354235696010903, "compression_ratio": 1.6872727272727273, "no_speech_prob": 0.0006878167623654008}, {"id": 1045, "seek": 547120, "start": 5484.4, "end": 5489.84, "text": " well, doesn't it take time to form synapses? Yes, it can take maybe an hour to form a new synapse.", "tokens": [51024, 731, 11, 1177, 380, 309, 747, 565, 281, 1254, 5451, 2382, 279, 30, 1079, 11, 309, 393, 747, 1310, 364, 1773, 281, 1254, 257, 777, 5451, 11145, 13, 51296], "temperature": 0.0, "avg_logprob": -0.09354235696010903, "compression_ratio": 1.6872727272727273, "no_speech_prob": 0.0006878167623654008}, {"id": 1046, "seek": 547120, "start": 5490.8, "end": 5496.0, "text": " We can form memories quicker than that. And I can explain that happens too, if you want. But", "tokens": [51344, 492, 393, 1254, 8495, 16255, 813, 300, 13, 400, 286, 393, 2903, 300, 2314, 886, 11, 498, 291, 528, 13, 583, 51604], "temperature": 0.0, "avg_logprob": -0.09354235696010903, "compression_ratio": 1.6872727272727273, "no_speech_prob": 0.0006878167623654008}, {"id": 1047, "seek": 549600, "start": 5496.72, "end": 5501.28, "text": " it's getting a bit neuroscience-y. That's great. But is there an understanding", "tokens": [50400, 309, 311, 1242, 257, 857, 42762, 12, 88, 13, 663, 311, 869, 13, 583, 307, 456, 364, 3701, 50628], "temperature": 0.0, "avg_logprob": -0.1907926447251264, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0018097005086019635}, {"id": 1048, "seek": 549600, "start": 5501.28, "end": 5506.16, "text": " of these mechanisms at every level? So from the short-term memories and the forming", "tokens": [50628, 295, 613, 15902, 412, 633, 1496, 30, 407, 490, 264, 2099, 12, 7039, 8495, 293, 264, 15745, 50872], "temperature": 0.0, "avg_logprob": -0.1907926447251264, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0018097005086019635}, {"id": 1049, "seek": 549600, "start": 5507.52, "end": 5512.4, "text": " many connections. So this idea of synaptogenesis, the growth of new synapses, that's well", "tokens": [50940, 867, 9271, 13, 407, 341, 1558, 295, 5451, 2796, 8799, 9374, 11, 264, 4599, 295, 777, 5451, 2382, 279, 11, 300, 311, 731, 51184], "temperature": 0.0, "avg_logprob": -0.1907926447251264, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0018097005086019635}, {"id": 1050, "seek": 549600, "start": 5512.4, "end": 5516.72, "text": " described, as well understood. And that's an essential part of learning. That is learning.", "tokens": [51184, 7619, 11, 382, 731, 7320, 13, 400, 300, 311, 364, 7115, 644, 295, 2539, 13, 663, 307, 2539, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1907926447251264, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0018097005086019635}, {"id": 1051, "seek": 549600, "start": 5516.72, "end": 5524.56, "text": " That is learning. Going back many, many years, people was", "tokens": [51400, 663, 307, 2539, 13, 10963, 646, 867, 11, 867, 924, 11, 561, 390, 51792], "temperature": 0.0, "avg_logprob": -0.1907926447251264, "compression_ratio": 1.684873949579832, "no_speech_prob": 0.0018097005086019635}, {"id": 1052, "seek": 552456, "start": 5525.52, "end": 5531.120000000001, "text": " what's his name, the psychologist proposed, Heb, Donald Heb. He proposed that learning was the", "tokens": [50412, 437, 311, 702, 1315, 11, 264, 29514, 10348, 11, 15606, 11, 8632, 15606, 13, 634, 10348, 300, 2539, 390, 264, 50692], "temperature": 0.0, "avg_logprob": -0.1462038521454713, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001547961845062673}, {"id": 1053, "seek": 552456, "start": 5531.120000000001, "end": 5537.200000000001, "text": " modification of the strength of a connection between two neurons. People interpreted that as", "tokens": [50692, 26747, 295, 264, 3800, 295, 257, 4984, 1296, 732, 22027, 13, 3432, 26749, 300, 382, 50996], "temperature": 0.0, "avg_logprob": -0.1462038521454713, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001547961845062673}, {"id": 1054, "seek": 552456, "start": 5537.200000000001, "end": 5541.68, "text": " the modification of the strength of a synapse. He didn't say that. He just said there's a", "tokens": [50996, 264, 26747, 295, 264, 3800, 295, 257, 5451, 11145, 13, 634, 994, 380, 584, 300, 13, 634, 445, 848, 456, 311, 257, 51220], "temperature": 0.0, "avg_logprob": -0.1462038521454713, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001547961845062673}, {"id": 1055, "seek": 552456, "start": 5541.68, "end": 5546.400000000001, "text": " modification between the effect of one neuron and another. So synaptogenesis is totally consistent", "tokens": [51220, 26747, 1296, 264, 1802, 295, 472, 34090, 293, 1071, 13, 407, 5451, 2796, 8799, 9374, 307, 3879, 8398, 51456], "temperature": 0.0, "avg_logprob": -0.1462038521454713, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001547961845062673}, {"id": 1056, "seek": 552456, "start": 5546.400000000001, "end": 5550.8, "text": " with Donald Heb said. But anyway, there's these mechanisms, the growth of new synapse,", "tokens": [51456, 365, 8632, 15606, 848, 13, 583, 4033, 11, 456, 311, 613, 15902, 11, 264, 4599, 295, 777, 5451, 11145, 11, 51676], "temperature": 0.0, "avg_logprob": -0.1462038521454713, "compression_ratio": 1.859437751004016, "no_speech_prob": 0.001547961845062673}, {"id": 1057, "seek": 555080, "start": 5550.8, "end": 5553.84, "text": " you can go online, you can watch a video of a synapse growing in real time.", "tokens": [50364, 291, 393, 352, 2950, 11, 291, 393, 1159, 257, 960, 295, 257, 5451, 11145, 4194, 294, 957, 565, 13, 50516], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1058, "seek": 555080, "start": 5553.84, "end": 5558.96, "text": " It's literally, you can see this little thing going. It's pretty impressive. So those", "tokens": [50516, 467, 311, 3736, 11, 291, 393, 536, 341, 707, 551, 516, 13, 467, 311, 1238, 8992, 13, 407, 729, 50772], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1059, "seek": 555080, "start": 5558.96, "end": 5563.52, "text": " mechanisms are known. Now, there's another thing that we've speculated and we've written about,", "tokens": [50772, 15902, 366, 2570, 13, 823, 11, 456, 311, 1071, 551, 300, 321, 600, 1608, 6987, 293, 321, 600, 3720, 466, 11, 51000], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1060, "seek": 555080, "start": 5563.52, "end": 5569.12, "text": " which is consistent with no neuroscience, but it's less proven. And this is the idea,", "tokens": [51000, 597, 307, 8398, 365, 572, 42762, 11, 457, 309, 311, 1570, 12785, 13, 400, 341, 307, 264, 1558, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1061, "seek": 555080, "start": 5569.12, "end": 5573.92, "text": " how do I form a memory really, really quickly? Like instantaneous. If it takes an hour to", "tokens": [51280, 577, 360, 286, 1254, 257, 4675, 534, 11, 534, 2661, 30, 1743, 45596, 13, 759, 309, 2516, 364, 1773, 281, 51520], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1062, "seek": 555080, "start": 5573.92, "end": 5580.08, "text": " grow a synapse, like that's not instantaneous. So there are types of synapses called silent", "tokens": [51520, 1852, 257, 5451, 11145, 11, 411, 300, 311, 406, 45596, 13, 407, 456, 366, 3467, 295, 5451, 2382, 279, 1219, 12784, 51828], "temperature": 0.0, "avg_logprob": -0.1091467204846834, "compression_ratio": 1.6990291262135921, "no_speech_prob": 0.008057227358222008}, {"id": 1063, "seek": 558008, "start": 5580.08, "end": 5585.04, "text": " synapses. They look like a synapse, but they don't do anything. They're just sitting there. It's", "tokens": [50364, 5451, 2382, 279, 13, 814, 574, 411, 257, 5451, 11145, 11, 457, 436, 500, 380, 360, 1340, 13, 814, 434, 445, 3798, 456, 13, 467, 311, 50612], "temperature": 0.0, "avg_logprob": -0.08334447467137897, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0004582237161230296}, {"id": 1064, "seek": 558008, "start": 5585.04, "end": 5590.5599999999995, "text": " like if an action potential comes in, it doesn't release any neurotransmitter. Some parts of the", "tokens": [50612, 411, 498, 364, 3069, 3995, 1487, 294, 11, 309, 1177, 380, 4374, 604, 43286, 25392, 3508, 391, 13, 2188, 3166, 295, 264, 50888], "temperature": 0.0, "avg_logprob": -0.08334447467137897, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0004582237161230296}, {"id": 1065, "seek": 558008, "start": 5590.5599999999995, "end": 5595.2, "text": " brain have more of these than others. For example, the hippocampus has a lot of them, which is where", "tokens": [50888, 3567, 362, 544, 295, 613, 813, 2357, 13, 1171, 1365, 11, 264, 27745, 905, 1215, 301, 575, 257, 688, 295, 552, 11, 597, 307, 689, 51120], "temperature": 0.0, "avg_logprob": -0.08334447467137897, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0004582237161230296}, {"id": 1066, "seek": 558008, "start": 5595.2, "end": 5602.0, "text": " we associate most short-term memory with. So what we speculated, again, in that 2016 paper,", "tokens": [51120, 321, 14644, 881, 2099, 12, 7039, 4675, 365, 13, 407, 437, 321, 1608, 6987, 11, 797, 11, 294, 300, 6549, 3035, 11, 51460], "temperature": 0.0, "avg_logprob": -0.08334447467137897, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0004582237161230296}, {"id": 1067, "seek": 558008, "start": 5602.0, "end": 5608.16, "text": " we proposed that the way we form very quick memories, very short-term memories, or quick", "tokens": [51460, 321, 10348, 300, 264, 636, 321, 1254, 588, 1702, 8495, 11, 588, 2099, 12, 7039, 8495, 11, 420, 1702, 51768], "temperature": 0.0, "avg_logprob": -0.08334447467137897, "compression_ratio": 1.6784452296819787, "no_speech_prob": 0.0004582237161230296}, {"id": 1068, "seek": 560816, "start": 5608.16, "end": 5615.2, "text": " memories, is that we convert silent synapses into active synapses. It's like saying a synapse has", "tokens": [50364, 8495, 11, 307, 300, 321, 7620, 12784, 5451, 2382, 279, 666, 4967, 5451, 2382, 279, 13, 467, 311, 411, 1566, 257, 5451, 11145, 575, 50716], "temperature": 0.0, "avg_logprob": -0.09544522531570927, "compression_ratio": 1.7063197026022305, "no_speech_prob": 0.0005032650660723448}, {"id": 1069, "seek": 560816, "start": 5615.2, "end": 5621.5199999999995, "text": " a zero weight and a one weight. But the long-term memory has to be formed by synaptogenesis. So", "tokens": [50716, 257, 4018, 3364, 293, 257, 472, 3364, 13, 583, 264, 938, 12, 7039, 4675, 575, 281, 312, 8693, 538, 5451, 2796, 8799, 9374, 13, 407, 51032], "temperature": 0.0, "avg_logprob": -0.09544522531570927, "compression_ratio": 1.7063197026022305, "no_speech_prob": 0.0005032650660723448}, {"id": 1070, "seek": 560816, "start": 5621.5199999999995, "end": 5625.599999999999, "text": " you can remember something really quickly by just flipping a bunch of these guys from silent to active.", "tokens": [51032, 291, 393, 1604, 746, 534, 2661, 538, 445, 26886, 257, 3840, 295, 613, 1074, 490, 12784, 281, 4967, 13, 51236], "temperature": 0.0, "avg_logprob": -0.09544522531570927, "compression_ratio": 1.7063197026022305, "no_speech_prob": 0.0005032650660723448}, {"id": 1071, "seek": 560816, "start": 5626.08, "end": 5632.08, "text": " It's not from 0.1 to 0.15. It doesn't do anything until it releases transmitter.", "tokens": [51260, 467, 311, 406, 490, 1958, 13, 16, 281, 1958, 13, 5211, 13, 467, 1177, 380, 360, 1340, 1826, 309, 16952, 40121, 13, 51560], "temperature": 0.0, "avg_logprob": -0.09544522531570927, "compression_ratio": 1.7063197026022305, "no_speech_prob": 0.0005032650660723448}, {"id": 1072, "seek": 560816, "start": 5632.08, "end": 5635.5199999999995, "text": " And if I do that over a bunch of these, I've got a very quick short-term memory.", "tokens": [51560, 400, 498, 286, 360, 300, 670, 257, 3840, 295, 613, 11, 286, 600, 658, 257, 588, 1702, 2099, 12, 7039, 4675, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09544522531570927, "compression_ratio": 1.7063197026022305, "no_speech_prob": 0.0005032650660723448}, {"id": 1073, "seek": 563552, "start": 5636.240000000001, "end": 5640.88, "text": " So I guess the lesson behind this is that most neural networks today are fully connected.", "tokens": [50400, 407, 286, 2041, 264, 6898, 2261, 341, 307, 300, 881, 18161, 9590, 965, 366, 4498, 4582, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1120466985622374, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0005702774506062269}, {"id": 1074, "seek": 563552, "start": 5641.76, "end": 5645.92, "text": " Every neuron connects every other neuron from layer to layer. That's not correct in the brain.", "tokens": [50676, 2048, 34090, 16967, 633, 661, 34090, 490, 4583, 281, 4583, 13, 663, 311, 406, 3006, 294, 264, 3567, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1120466985622374, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0005702774506062269}, {"id": 1075, "seek": 563552, "start": 5645.92, "end": 5650.88, "text": " We don't want that. We actually don't want that. It's bad. You want a very sparse connectivity so", "tokens": [50884, 492, 500, 380, 528, 300, 13, 492, 767, 500, 380, 528, 300, 13, 467, 311, 1578, 13, 509, 528, 257, 588, 637, 11668, 21095, 370, 51132], "temperature": 0.0, "avg_logprob": -0.1120466985622374, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0005702774506062269}, {"id": 1076, "seek": 563552, "start": 5650.88, "end": 5656.64, "text": " that any neuron connects to some subset of the neurons in the other layer. And it does so on a", "tokens": [51132, 300, 604, 34090, 16967, 281, 512, 25993, 295, 264, 22027, 294, 264, 661, 4583, 13, 400, 309, 775, 370, 322, 257, 51420], "temperature": 0.0, "avg_logprob": -0.1120466985622374, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0005702774506062269}, {"id": 1077, "seek": 563552, "start": 5656.64, "end": 5663.360000000001, "text": " dendrite by dendrite segment basis. So it's a very parcelated out type of thing. And that then", "tokens": [51420, 274, 521, 35002, 538, 274, 521, 35002, 9469, 5143, 13, 407, 309, 311, 257, 588, 34082, 770, 484, 2010, 295, 551, 13, 400, 300, 550, 51756], "temperature": 0.0, "avg_logprob": -0.1120466985622374, "compression_ratio": 1.8365758754863812, "no_speech_prob": 0.0005702774506062269}, {"id": 1078, "seek": 566336, "start": 5663.36, "end": 5667.36, "text": " learning is not adjusting all these weights, but learning is just saying, okay, connect to these", "tokens": [50364, 2539, 307, 406, 23559, 439, 613, 17443, 11, 457, 2539, 307, 445, 1566, 11, 1392, 11, 1745, 281, 613, 50564], "temperature": 0.0, "avg_logprob": -0.15533769130706787, "compression_ratio": 1.9456066945606694, "no_speech_prob": 0.00048782891826704144}, {"id": 1079, "seek": 566336, "start": 5667.36, "end": 5673.36, "text": " 10 cells here right now. In that process, you know, with artificial neural networks, it's a very", "tokens": [50564, 1266, 5438, 510, 558, 586, 13, 682, 300, 1399, 11, 291, 458, 11, 365, 11677, 18161, 9590, 11, 309, 311, 257, 588, 50864], "temperature": 0.0, "avg_logprob": -0.15533769130706787, "compression_ratio": 1.9456066945606694, "no_speech_prob": 0.00048782891826704144}, {"id": 1080, "seek": 566336, "start": 5673.36, "end": 5679.839999999999, "text": " simple process of back propagation that adjusts the weights. The process of synaptogenesis.", "tokens": [50864, 2199, 1399, 295, 646, 38377, 300, 4369, 82, 264, 17443, 13, 440, 1399, 295, 5451, 2796, 8799, 9374, 13, 51188], "temperature": 0.0, "avg_logprob": -0.15533769130706787, "compression_ratio": 1.9456066945606694, "no_speech_prob": 0.00048782891826704144}, {"id": 1081, "seek": 566336, "start": 5679.839999999999, "end": 5684.16, "text": " Synaptogenesis. Synaptogenesis. It's even easier. It's even easier. It's even easier.", "tokens": [51188, 26155, 2796, 8799, 9374, 13, 26155, 2796, 8799, 9374, 13, 467, 311, 754, 3571, 13, 467, 311, 754, 3571, 13, 467, 311, 754, 3571, 13, 51404], "temperature": 0.0, "avg_logprob": -0.15533769130706787, "compression_ratio": 1.9456066945606694, "no_speech_prob": 0.00048782891826704144}, {"id": 1082, "seek": 566336, "start": 5684.16, "end": 5689.839999999999, "text": " Back propagation requires something that really can't happen in brains. This back propagation", "tokens": [51404, 5833, 38377, 7029, 746, 300, 534, 393, 380, 1051, 294, 15442, 13, 639, 646, 38377, 51688], "temperature": 0.0, "avg_logprob": -0.15533769130706787, "compression_ratio": 1.9456066945606694, "no_speech_prob": 0.00048782891826704144}, {"id": 1083, "seek": 568984, "start": 5689.84, "end": 5693.360000000001, "text": " of this error signal. They really can't happen. People are trying to make it happen in brains,", "tokens": [50364, 295, 341, 6713, 6358, 13, 814, 534, 393, 380, 1051, 13, 3432, 366, 1382, 281, 652, 309, 1051, 294, 15442, 11, 50540], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1084, "seek": 568984, "start": 5693.360000000001, "end": 5698.08, "text": " but it doesn't happen in brain. This is pure Hebbian learning. Well, synaptogenesis is pure", "tokens": [50540, 457, 309, 1177, 380, 1051, 294, 3567, 13, 639, 307, 6075, 634, 6692, 952, 2539, 13, 1042, 11, 5451, 2796, 8799, 9374, 307, 6075, 50776], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1085, "seek": 568984, "start": 5698.08, "end": 5702.08, "text": " Hebbian learning. It's basically saying there's a population of cells over here that are active", "tokens": [50776, 634, 6692, 952, 2539, 13, 467, 311, 1936, 1566, 456, 311, 257, 4415, 295, 5438, 670, 510, 300, 366, 4967, 50976], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1086, "seek": 568984, "start": 5702.08, "end": 5706.32, "text": " right now. And there's a population of cells over here active right now. How do I form connections", "tokens": [50976, 558, 586, 13, 400, 456, 311, 257, 4415, 295, 5438, 670, 510, 4967, 558, 586, 13, 1012, 360, 286, 1254, 9271, 51188], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1087, "seek": 568984, "start": 5706.32, "end": 5712.4800000000005, "text": " between those active cells? And it's literally saying this guy became active. These 100 neurons", "tokens": [51188, 1296, 729, 4967, 5438, 30, 400, 309, 311, 3736, 1566, 341, 2146, 3062, 4967, 13, 1981, 2319, 22027, 51496], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1088, "seek": 568984, "start": 5712.4800000000005, "end": 5717.4400000000005, "text": " here became active before this neuron became active. So form connections to those ones. That's it.", "tokens": [51496, 510, 3062, 4967, 949, 341, 34090, 3062, 4967, 13, 407, 1254, 9271, 281, 729, 2306, 13, 663, 311, 309, 13, 51744], "temperature": 0.0, "avg_logprob": -0.0991284121637759, "compression_ratio": 2.035335689045936, "no_speech_prob": 0.003483193926513195}, {"id": 1089, "seek": 571744, "start": 5717.44, "end": 5722.799999999999, "text": " There's no propagation of error. Nothing. All the networks we do, all the models we have work on", "tokens": [50364, 821, 311, 572, 38377, 295, 6713, 13, 6693, 13, 1057, 264, 9590, 321, 360, 11, 439, 264, 5245, 321, 362, 589, 322, 50632], "temperature": 0.0, "avg_logprob": -0.13458947633442125, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.0007320338627323508}, {"id": 1090, "seek": 571744, "start": 5723.5199999999995, "end": 5731.5199999999995, "text": " almost completely on Hebbian learning, but in on dendritic segments and multiple synaptes at the", "tokens": [50668, 1920, 2584, 322, 634, 6692, 952, 2539, 11, 457, 294, 322, 274, 521, 3210, 299, 19904, 293, 3866, 5451, 2796, 279, 412, 264, 51068], "temperature": 0.0, "avg_logprob": -0.13458947633442125, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.0007320338627323508}, {"id": 1091, "seek": 571744, "start": 5731.5199999999995, "end": 5737.36, "text": " same time. So now let's turn the question that you already answered and maybe you can answer it again.", "tokens": [51068, 912, 565, 13, 407, 586, 718, 311, 1261, 264, 1168, 300, 291, 1217, 10103, 293, 1310, 291, 393, 1867, 309, 797, 13, 51360], "temperature": 0.0, "avg_logprob": -0.13458947633442125, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.0007320338627323508}, {"id": 1092, "seek": 571744, "start": 5738.639999999999, "end": 5743.759999999999, "text": " If you look at the history of artificial intelligence, where do you think we stand? How", "tokens": [51424, 759, 291, 574, 412, 264, 2503, 295, 11677, 7599, 11, 689, 360, 291, 519, 321, 1463, 30, 1012, 51680], "temperature": 0.0, "avg_logprob": -0.13458947633442125, "compression_ratio": 1.5609756097560976, "no_speech_prob": 0.0007320338627323508}, {"id": 1093, "seek": 574376, "start": 5743.84, "end": 5748.8, "text": " far are we from solving intelligence? You said you were very optimistic. Can you elaborate on that?", "tokens": [50368, 1400, 366, 321, 490, 12606, 7599, 30, 509, 848, 291, 645, 588, 19397, 13, 1664, 291, 20945, 322, 300, 30, 50616], "temperature": 0.0, "avg_logprob": -0.12828404924510856, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.00843348540365696}, {"id": 1094, "seek": 574376, "start": 5748.8, "end": 5754.96, "text": " Yeah. It's always the crazy question to ask because no one can predict the future.", "tokens": [50616, 865, 13, 467, 311, 1009, 264, 3219, 1168, 281, 1029, 570, 572, 472, 393, 6069, 264, 2027, 13, 50924], "temperature": 0.0, "avg_logprob": -0.12828404924510856, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.00843348540365696}, {"id": 1095, "seek": 574376, "start": 5755.52, "end": 5761.4400000000005, "text": " So I'll tell you a story. I used to run a different neuroscience institute called the", "tokens": [50952, 407, 286, 603, 980, 291, 257, 1657, 13, 286, 1143, 281, 1190, 257, 819, 42762, 26860, 1219, 264, 51248], "temperature": 0.0, "avg_logprob": -0.12828404924510856, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.00843348540365696}, {"id": 1096, "seek": 574376, "start": 5761.4400000000005, "end": 5766.24, "text": " Redburn Neuroscience Institute. And we would hold these symposiums and we'd get like 35 scientists", "tokens": [51248, 4477, 21763, 1734, 8977, 6699, 9446, 13, 400, 321, 576, 1797, 613, 13240, 42161, 82, 293, 321, 1116, 483, 411, 6976, 7708, 51488], "temperature": 0.0, "avg_logprob": -0.12828404924510856, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.00843348540365696}, {"id": 1097, "seek": 574376, "start": 5766.24, "end": 5770.64, "text": " from around the world to come together. And I used to ask them all the same question. I would say,", "tokens": [51488, 490, 926, 264, 1002, 281, 808, 1214, 13, 400, 286, 1143, 281, 1029, 552, 439, 264, 912, 1168, 13, 286, 576, 584, 11, 51708], "temperature": 0.0, "avg_logprob": -0.12828404924510856, "compression_ratio": 1.6293706293706294, "no_speech_prob": 0.00843348540365696}, {"id": 1098, "seek": 577064, "start": 5770.64, "end": 5774.320000000001, "text": " well, how long do you think it'll be before we understand how the New York Cortex works?", "tokens": [50364, 731, 11, 577, 938, 360, 291, 519, 309, 603, 312, 949, 321, 1223, 577, 264, 1873, 3609, 28522, 3121, 1985, 30, 50548], "temperature": 0.0, "avg_logprob": -0.15899113019307454, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.0007320878794416785}, {"id": 1099, "seek": 577064, "start": 5774.320000000001, "end": 5777.04, "text": " And everyone went around the room and they introduced the name and they have to answer", "tokens": [50548, 400, 1518, 1437, 926, 264, 1808, 293, 436, 7268, 264, 1315, 293, 436, 362, 281, 1867, 50684], "temperature": 0.0, "avg_logprob": -0.15899113019307454, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.0007320878794416785}, {"id": 1100, "seek": 577064, "start": 5777.04, "end": 5784.64, "text": " that question. So I got, the typical answer was 50 to 100 years. Some people would say 500 years.", "tokens": [50684, 300, 1168, 13, 407, 286, 658, 11, 264, 7476, 1867, 390, 2625, 281, 2319, 924, 13, 2188, 561, 576, 584, 5923, 924, 13, 51064], "temperature": 0.0, "avg_logprob": -0.15899113019307454, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.0007320878794416785}, {"id": 1101, "seek": 577064, "start": 5784.64, "end": 5790.160000000001, "text": " Some people said never. I said, why are you, why are you a neuroscience? It's a good pay.", "tokens": [51064, 2188, 561, 848, 1128, 13, 286, 848, 11, 983, 366, 291, 11, 983, 366, 291, 257, 42762, 30, 467, 311, 257, 665, 1689, 13, 51340], "temperature": 0.0, "avg_logprob": -0.15899113019307454, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.0007320878794416785}, {"id": 1102, "seek": 577064, "start": 5792.56, "end": 5797.84, "text": " It's interesting. So, you know, but it doesn't work like that. As I mentioned earlier, these are", "tokens": [51460, 467, 311, 1880, 13, 407, 11, 291, 458, 11, 457, 309, 1177, 380, 589, 411, 300, 13, 1018, 286, 2835, 3071, 11, 613, 366, 51724], "temperature": 0.0, "avg_logprob": -0.15899113019307454, "compression_ratio": 1.6487455197132617, "no_speech_prob": 0.0007320878794416785}, {"id": 1103, "seek": 579784, "start": 5798.72, "end": 5802.56, "text": " step functions. Things happen and then bingo, they happen. You can't predict that.", "tokens": [50408, 1823, 6828, 13, 9514, 1051, 293, 550, 272, 18459, 11, 436, 1051, 13, 509, 393, 380, 6069, 300, 13, 50600], "temperature": 0.0, "avg_logprob": -0.11772928067616054, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0007792819524183869}, {"id": 1104, "seek": 579784, "start": 5803.52, "end": 5808.72, "text": " I feel I've already passed a step function. So if I can do my job correctly over the next five years,", "tokens": [50648, 286, 841, 286, 600, 1217, 4678, 257, 1823, 2445, 13, 407, 498, 286, 393, 360, 452, 1691, 8944, 670, 264, 958, 1732, 924, 11, 50908], "temperature": 0.0, "avg_logprob": -0.11772928067616054, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0007792819524183869}, {"id": 1105, "seek": 579784, "start": 5810.72, "end": 5814.96, "text": " then meaning I can proselytize these ideas, I can convince other people they're right,", "tokens": [51008, 550, 3620, 286, 393, 6267, 736, 83, 1125, 613, 3487, 11, 286, 393, 13447, 661, 561, 436, 434, 558, 11, 51220], "temperature": 0.0, "avg_logprob": -0.11772928067616054, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0007792819524183869}, {"id": 1106, "seek": 579784, "start": 5816.0, "end": 5820.400000000001, "text": " we can show that other people or other machine learning people should pay attention to these", "tokens": [51272, 321, 393, 855, 300, 661, 561, 420, 661, 3479, 2539, 561, 820, 1689, 3202, 281, 613, 51492], "temperature": 0.0, "avg_logprob": -0.11772928067616054, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0007792819524183869}, {"id": 1107, "seek": 579784, "start": 5820.400000000001, "end": 5825.84, "text": " ideas, then we're definitely in an under 20 year time frame. If I can do those things,", "tokens": [51492, 3487, 11, 550, 321, 434, 2138, 294, 364, 833, 945, 1064, 565, 3920, 13, 759, 286, 393, 360, 729, 721, 11, 51764], "temperature": 0.0, "avg_logprob": -0.11772928067616054, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0007792819524183869}, {"id": 1108, "seek": 582584, "start": 5825.92, "end": 5829.68, "text": " if I, if I'm not successful in that, and this is the last time anyone talks to me", "tokens": [50368, 498, 286, 11, 498, 286, 478, 406, 4406, 294, 300, 11, 293, 341, 307, 264, 1036, 565, 2878, 6686, 281, 385, 50556], "temperature": 0.0, "avg_logprob": -0.10994564403187145, "compression_ratio": 1.7403100775193798, "no_speech_prob": 0.0004441458731889725}, {"id": 1109, "seek": 582584, "start": 5829.68, "end": 5834.64, "text": " and no one reads our papers and, you know, I'm wrong or something like that, then,", "tokens": [50556, 293, 572, 472, 15700, 527, 10577, 293, 11, 291, 458, 11, 286, 478, 2085, 420, 746, 411, 300, 11, 550, 11, 50804], "temperature": 0.0, "avg_logprob": -0.10994564403187145, "compression_ratio": 1.7403100775193798, "no_speech_prob": 0.0004441458731889725}, {"id": 1110, "seek": 582584, "start": 5834.64, "end": 5841.52, "text": " then I don't know. But it's, it's not 50 years. It's, it, you know, it'll, it'll, you know,", "tokens": [50804, 550, 286, 500, 380, 458, 13, 583, 309, 311, 11, 309, 311, 406, 2625, 924, 13, 467, 311, 11, 309, 11, 291, 458, 11, 309, 603, 11, 309, 603, 11, 291, 458, 11, 51148], "temperature": 0.0, "avg_logprob": -0.10994564403187145, "compression_ratio": 1.7403100775193798, "no_speech_prob": 0.0004441458731889725}, {"id": 1111, "seek": 582584, "start": 5841.52, "end": 5845.28, "text": " the same thing about electric cars, how quickly are they going to populate the world? It probably", "tokens": [51148, 264, 912, 551, 466, 5210, 5163, 11, 577, 2661, 366, 436, 516, 281, 1665, 5256, 264, 1002, 30, 467, 1391, 51336], "temperature": 0.0, "avg_logprob": -0.10994564403187145, "compression_ratio": 1.7403100775193798, "no_speech_prob": 0.0004441458731889725}, {"id": 1112, "seek": 582584, "start": 5845.28, "end": 5850.24, "text": " takes about a 20 year span. It'll be something like that. But I think if I can do what I said,", "tokens": [51336, 2516, 466, 257, 945, 1064, 16174, 13, 467, 603, 312, 746, 411, 300, 13, 583, 286, 519, 498, 286, 393, 360, 437, 286, 848, 11, 51584], "temperature": 0.0, "avg_logprob": -0.10994564403187145, "compression_ratio": 1.7403100775193798, "no_speech_prob": 0.0004441458731889725}, {"id": 1113, "seek": 585024, "start": 5850.24, "end": 5855.76, "text": " we're starting it. And of course, there could be other use of step functions. It could be", "tokens": [50364, 321, 434, 2891, 309, 13, 400, 295, 1164, 11, 456, 727, 312, 661, 764, 295, 1823, 6828, 13, 467, 727, 312, 50640], "temperature": 0.0, "avg_logprob": -0.17529842501781026, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.19183839857578278}, {"id": 1114, "seek": 585024, "start": 5857.44, "end": 5861.76, "text": " everybody gives up on your ideas for 20 years, and then all of a sudden somebody picks it up", "tokens": [50724, 2201, 2709, 493, 322, 428, 3487, 337, 945, 924, 11, 293, 550, 439, 295, 257, 3990, 2618, 16137, 309, 493, 50940], "temperature": 0.0, "avg_logprob": -0.17529842501781026, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.19183839857578278}, {"id": 1115, "seek": 585024, "start": 5861.76, "end": 5865.5199999999995, "text": " again. Wait, that guy was onto something. Yeah. So that would be a, that would be a failure on", "tokens": [50940, 797, 13, 3802, 11, 300, 2146, 390, 3911, 746, 13, 865, 13, 407, 300, 576, 312, 257, 11, 300, 576, 312, 257, 7763, 322, 51128], "temperature": 0.0, "avg_logprob": -0.17529842501781026, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.19183839857578278}, {"id": 1116, "seek": 585024, "start": 5865.5199999999995, "end": 5870.5599999999995, "text": " my part, right? You know, think about Charles Babbage, you know, Charles Babbage, he's the guy", "tokens": [51128, 452, 644, 11, 558, 30, 509, 458, 11, 519, 466, 10523, 15820, 9742, 11, 291, 458, 11, 10523, 15820, 9742, 11, 415, 311, 264, 2146, 51380], "temperature": 0.0, "avg_logprob": -0.17529842501781026, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.19183839857578278}, {"id": 1117, "seek": 585024, "start": 5870.5599999999995, "end": 5878.32, "text": " who invented the computer back in the 18 something 1800s. And everyone forgot about it until, you", "tokens": [51380, 567, 14479, 264, 3820, 646, 294, 264, 2443, 746, 24327, 82, 13, 400, 1518, 5298, 466, 309, 1826, 11, 291, 51768], "temperature": 0.0, "avg_logprob": -0.17529842501781026, "compression_ratio": 1.6845878136200716, "no_speech_prob": 0.19183839857578278}, {"id": 1118, "seek": 587832, "start": 5878.32, "end": 5882.08, "text": " know, 100 years later and say, Hey, this guy figured this stuff out a long time ago. Yeah.", "tokens": [50364, 458, 11, 2319, 924, 1780, 293, 584, 11, 1911, 11, 341, 2146, 8932, 341, 1507, 484, 257, 938, 565, 2057, 13, 865, 13, 50552], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1119, "seek": 587832, "start": 5882.08, "end": 5885.679999999999, "text": " You know, but he was ahead of his time. Yeah. I don't think, you know, like, as I said,", "tokens": [50552, 509, 458, 11, 457, 415, 390, 2286, 295, 702, 565, 13, 865, 13, 286, 500, 380, 519, 11, 291, 458, 11, 411, 11, 382, 286, 848, 11, 50732], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1120, "seek": 587832, "start": 5886.32, "end": 5891.04, "text": " I recognize this is part of any entrepreneur's challenge. I use entrepreneur broadly in this", "tokens": [50764, 286, 5521, 341, 307, 644, 295, 604, 14307, 311, 3430, 13, 286, 764, 14307, 19511, 294, 341, 51000], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1121, "seek": 587832, "start": 5891.04, "end": 5893.92, "text": " case. I'm not meaning like I'm building a business trying to sell something. I mean,", "tokens": [51000, 1389, 13, 286, 478, 406, 3620, 411, 286, 478, 2390, 257, 1606, 1382, 281, 3607, 746, 13, 286, 914, 11, 51144], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1122, "seek": 587832, "start": 5893.92, "end": 5900.0, "text": " like I'm trying to sell ideas. And this is the challenge as to how you get people to pay attention", "tokens": [51144, 411, 286, 478, 1382, 281, 3607, 3487, 13, 400, 341, 307, 264, 3430, 382, 281, 577, 291, 483, 561, 281, 1689, 3202, 51448], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1123, "seek": 587832, "start": 5900.0, "end": 5905.36, "text": " to you. How do you get them to give you positive or negative feedback? How do you get to people", "tokens": [51448, 281, 291, 13, 1012, 360, 291, 483, 552, 281, 976, 291, 3353, 420, 3671, 5824, 30, 1012, 360, 291, 483, 281, 561, 51716], "temperature": 0.0, "avg_logprob": -0.12655567300730738, "compression_ratio": 1.8125, "no_speech_prob": 0.001548471045680344}, {"id": 1124, "seek": 590536, "start": 5905.36, "end": 5909.5199999999995, "text": " act differently based on your ideas? So, you know, we'll see how well we do on that.", "tokens": [50364, 605, 7614, 2361, 322, 428, 3487, 30, 407, 11, 291, 458, 11, 321, 603, 536, 577, 731, 321, 360, 322, 300, 13, 50572], "temperature": 0.0, "avg_logprob": -0.200586442594175, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.007812330033630133}, {"id": 1125, "seek": 590536, "start": 5910.08, "end": 5914.799999999999, "text": " So, you know, that there's a lot of hype behind artificial intelligence currently. Do you,", "tokens": [50600, 407, 11, 291, 458, 11, 300, 456, 311, 257, 688, 295, 24144, 2261, 11677, 7599, 4362, 13, 1144, 291, 11, 50836], "temperature": 0.0, "avg_logprob": -0.200586442594175, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.007812330033630133}, {"id": 1126, "seek": 590536, "start": 5916.24, "end": 5922.4, "text": " as, as you look to spread the ideas that are of New York cortical theory of the things you're", "tokens": [50908, 382, 11, 382, 291, 574, 281, 3974, 264, 3487, 300, 366, 295, 1873, 3609, 11278, 804, 5261, 295, 264, 721, 291, 434, 51216], "temperature": 0.0, "avg_logprob": -0.200586442594175, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.007812330033630133}, {"id": 1127, "seek": 590536, "start": 5922.4, "end": 5927.12, "text": " working on, do you think there's some possibility we'll hit an AI winter once again?", "tokens": [51216, 1364, 322, 11, 360, 291, 519, 456, 311, 512, 7959, 321, 603, 2045, 364, 7318, 6355, 1564, 797, 30, 51452], "temperature": 0.0, "avg_logprob": -0.200586442594175, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.007812330033630133}, {"id": 1128, "seek": 590536, "start": 5927.12, "end": 5929.44, "text": " Yeah, it's certainly a possibility. No question about it.", "tokens": [51452, 865, 11, 309, 311, 3297, 257, 7959, 13, 883, 1168, 466, 309, 13, 51568], "temperature": 0.0, "avg_logprob": -0.200586442594175, "compression_ratio": 1.6349206349206349, "no_speech_prob": 0.007812330033630133}, {"id": 1129, "seek": 592944, "start": 5930.16, "end": 5936.4, "text": " Yeah. Well, I guess, do I worry about it? I haven't decided yet if that's good or bad for", "tokens": [50400, 865, 13, 1042, 11, 286, 2041, 11, 360, 286, 3292, 466, 309, 30, 286, 2378, 380, 3047, 1939, 498, 300, 311, 665, 420, 1578, 337, 50712], "temperature": 0.0, "avg_logprob": -0.15146797143139887, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.07918643951416016}, {"id": 1130, "seek": 592944, "start": 5936.4, "end": 5943.679999999999, "text": " my mission. That's true. That's very true because it's almost like you need the winter to refresh", "tokens": [50712, 452, 4447, 13, 663, 311, 2074, 13, 663, 311, 588, 2074, 570, 309, 311, 1920, 411, 291, 643, 264, 6355, 281, 15134, 51076], "temperature": 0.0, "avg_logprob": -0.15146797143139887, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.07918643951416016}, {"id": 1131, "seek": 592944, "start": 5943.679999999999, "end": 5948.879999999999, "text": " the pallet. Yeah. So, it's like, I want, here's what you want to have it is you want like,", "tokens": [51076, 264, 24075, 302, 13, 865, 13, 407, 11, 309, 311, 411, 11, 286, 528, 11, 510, 311, 437, 291, 528, 281, 362, 309, 307, 291, 528, 411, 11, 51336], "temperature": 0.0, "avg_logprob": -0.15146797143139887, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.07918643951416016}, {"id": 1132, "seek": 592944, "start": 5949.5199999999995, "end": 5956.0, "text": " to the extent that everyone is so thrilled about the current state of machine learning and AI and", "tokens": [51368, 281, 264, 8396, 300, 1518, 307, 370, 18744, 466, 264, 2190, 1785, 295, 3479, 2539, 293, 7318, 293, 51692], "temperature": 0.0, "avg_logprob": -0.15146797143139887, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.07918643951416016}, {"id": 1133, "seek": 595600, "start": 5956.08, "end": 5961.04, "text": " they don't imagine they need anything else. It makes my job harder. Right. If, if everything", "tokens": [50368, 436, 500, 380, 3811, 436, 643, 1340, 1646, 13, 467, 1669, 452, 1691, 6081, 13, 1779, 13, 759, 11, 498, 1203, 50616], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1134, "seek": 595600, "start": 5961.04, "end": 5965.6, "text": " crashed completely and every student left the field and there was no money for anybody to do", "tokens": [50616, 24190, 2584, 293, 633, 3107, 1411, 264, 2519, 293, 456, 390, 572, 1460, 337, 4472, 281, 360, 50844], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1135, "seek": 595600, "start": 5965.6, "end": 5969.2, "text": " anything and it became an embarrassment to talk about machine intelligence and AI, that wouldn't", "tokens": [50844, 1340, 293, 309, 3062, 364, 43536, 281, 751, 466, 3479, 7599, 293, 7318, 11, 300, 2759, 380, 51024], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1136, "seek": 595600, "start": 5969.2, "end": 5973.84, "text": " be good for us either. You want, you want sort of the soft landing approach, right? You want enough", "tokens": [51024, 312, 665, 337, 505, 2139, 13, 509, 528, 11, 291, 528, 1333, 295, 264, 2787, 11202, 3109, 11, 558, 30, 509, 528, 1547, 51256], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1137, "seek": 595600, "start": 5973.84, "end": 5978.88, "text": " people, the senior people in AI and machine learning and say, you know, we need other approaches. We", "tokens": [51256, 561, 11, 264, 7965, 561, 294, 7318, 293, 3479, 2539, 293, 584, 11, 291, 458, 11, 321, 643, 661, 11587, 13, 492, 51508], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1138, "seek": 595600, "start": 5978.88, "end": 5982.96, "text": " really need other approaches. Damn, we need other approaches. Maybe we should look to the brain.", "tokens": [51508, 534, 643, 661, 11587, 13, 11907, 11, 321, 643, 661, 11587, 13, 2704, 321, 820, 574, 281, 264, 3567, 13, 51712], "temperature": 0.0, "avg_logprob": -0.10036067820307035, "compression_ratio": 1.8125, "no_speech_prob": 0.001133437966927886}, {"id": 1139, "seek": 598296, "start": 5982.96, "end": 5986.8, "text": " Okay, let's look to the brain. Who's got some brain ideas? Okay, let's, let's start a little", "tokens": [50364, 1033, 11, 718, 311, 574, 281, 264, 3567, 13, 2102, 311, 658, 512, 3567, 3487, 30, 1033, 11, 718, 311, 11, 718, 311, 722, 257, 707, 50556], "temperature": 0.0, "avg_logprob": -0.09083612629624664, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0021153329871594906}, {"id": 1140, "seek": 598296, "start": 5986.8, "end": 5991.2, "text": " project on the side here, trying to do a brain idea related stuff. That's the ideal outcome we", "tokens": [50556, 1716, 322, 264, 1252, 510, 11, 1382, 281, 360, 257, 3567, 1558, 4077, 1507, 13, 663, 311, 264, 7157, 9700, 321, 50776], "temperature": 0.0, "avg_logprob": -0.09083612629624664, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0021153329871594906}, {"id": 1141, "seek": 598296, "start": 5991.2, "end": 5996.32, "text": " would want. So, I don't want a total winter and yet I don't want it to be sunny all the time either.", "tokens": [50776, 576, 528, 13, 407, 11, 286, 500, 380, 528, 257, 3217, 6355, 293, 1939, 286, 500, 380, 528, 309, 281, 312, 20412, 439, 264, 565, 2139, 13, 51032], "temperature": 0.0, "avg_logprob": -0.09083612629624664, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0021153329871594906}, {"id": 1142, "seek": 598296, "start": 5997.52, "end": 6001.76, "text": " So, what do you think it takes to build a system with human level intelligence", "tokens": [51092, 407, 11, 437, 360, 291, 519, 309, 2516, 281, 1322, 257, 1185, 365, 1952, 1496, 7599, 51304], "temperature": 0.0, "avg_logprob": -0.09083612629624664, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0021153329871594906}, {"id": 1143, "seek": 598296, "start": 6002.96, "end": 6008.56, "text": " where once demonstrated, you would be very impressed? So, does it have to have a body?", "tokens": [51364, 689, 1564, 18772, 11, 291, 576, 312, 588, 11679, 30, 407, 11, 775, 309, 362, 281, 362, 257, 1772, 30, 51644], "temperature": 0.0, "avg_logprob": -0.09083612629624664, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0021153329871594906}, {"id": 1144, "seek": 600856, "start": 6008.56, "end": 6013.360000000001, "text": " Does it have to have the, the, the C word we used before consciousness", "tokens": [50364, 4402, 309, 362, 281, 362, 264, 11, 264, 11, 264, 383, 1349, 321, 1143, 949, 10081, 50604], "temperature": 0.0, "avg_logprob": -0.1352845504220608, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0005882111145183444}, {"id": 1145, "seek": 600856, "start": 6015.6, "end": 6021.280000000001, "text": " as, as, as an entirety as a holistic sense? First of all, I don't think the goal is to create a", "tokens": [50716, 382, 11, 382, 11, 382, 364, 31557, 382, 257, 30334, 2020, 30, 2386, 295, 439, 11, 286, 500, 380, 519, 264, 3387, 307, 281, 1884, 257, 51000], "temperature": 0.0, "avg_logprob": -0.1352845504220608, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0005882111145183444}, {"id": 1146, "seek": 600856, "start": 6021.280000000001, "end": 6025.84, "text": " machine that is human level intelligence. I think it's a false goal. Back to Turing, I think it was", "tokens": [51000, 3479, 300, 307, 1952, 1496, 7599, 13, 286, 519, 309, 311, 257, 7908, 3387, 13, 5833, 281, 314, 1345, 11, 286, 519, 309, 390, 51228], "temperature": 0.0, "avg_logprob": -0.1352845504220608, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0005882111145183444}, {"id": 1147, "seek": 600856, "start": 6025.84, "end": 6030.160000000001, "text": " a false statement. We want to understand what intelligence is and then we can build intelligent", "tokens": [51228, 257, 7908, 5629, 13, 492, 528, 281, 1223, 437, 7599, 307, 293, 550, 321, 393, 1322, 13232, 51444], "temperature": 0.0, "avg_logprob": -0.1352845504220608, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0005882111145183444}, {"id": 1148, "seek": 600856, "start": 6030.160000000001, "end": 6035.120000000001, "text": " machines of all different scales, all different capabilities. You know, a dog is intelligent.", "tokens": [51444, 8379, 295, 439, 819, 17408, 11, 439, 819, 10862, 13, 509, 458, 11, 257, 3000, 307, 13232, 13, 51692], "temperature": 0.0, "avg_logprob": -0.1352845504220608, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0005882111145183444}, {"id": 1149, "seek": 603512, "start": 6035.12, "end": 6039.04, "text": " I don't need, you know, that'd be pretty good to have a dog, you know, but what about something", "tokens": [50364, 286, 500, 380, 643, 11, 291, 458, 11, 300, 1116, 312, 1238, 665, 281, 362, 257, 3000, 11, 291, 458, 11, 457, 437, 466, 746, 50560], "temperature": 0.0, "avg_logprob": -0.10990501622684666, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.00041728277574293315}, {"id": 1150, "seek": 603512, "start": 6039.04, "end": 6044.32, "text": " that doesn't look like an animal at all in different spaces. So, my thinking about this is that we", "tokens": [50560, 300, 1177, 380, 574, 411, 364, 5496, 412, 439, 294, 819, 7673, 13, 407, 11, 452, 1953, 466, 341, 307, 300, 321, 50824], "temperature": 0.0, "avg_logprob": -0.10990501622684666, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.00041728277574293315}, {"id": 1151, "seek": 603512, "start": 6044.32, "end": 6049.599999999999, "text": " want to define what intelligence is, agree upon what makes an intelligent system. We can then say,", "tokens": [50824, 528, 281, 6964, 437, 7599, 307, 11, 3986, 3564, 437, 1669, 364, 13232, 1185, 13, 492, 393, 550, 584, 11, 51088], "temperature": 0.0, "avg_logprob": -0.10990501622684666, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.00041728277574293315}, {"id": 1152, "seek": 603512, "start": 6049.599999999999, "end": 6053.68, "text": " okay, we're now going to build systems that work on those principles or some subset of them,", "tokens": [51088, 1392, 11, 321, 434, 586, 516, 281, 1322, 3652, 300, 589, 322, 729, 9156, 420, 512, 25993, 295, 552, 11, 51292], "temperature": 0.0, "avg_logprob": -0.10990501622684666, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.00041728277574293315}, {"id": 1153, "seek": 603512, "start": 6054.24, "end": 6060.16, "text": " and we can apply them to all different types of problems. And the, the kind, the idea, it's", "tokens": [51320, 293, 321, 393, 3079, 552, 281, 439, 819, 3467, 295, 2740, 13, 400, 264, 11, 264, 733, 11, 264, 1558, 11, 309, 311, 51616], "temperature": 0.0, "avg_logprob": -0.10990501622684666, "compression_ratio": 1.7194244604316546, "no_speech_prob": 0.00041728277574293315}, {"id": 1154, "seek": 606016, "start": 6060.16, "end": 6065.68, "text": " like computing. We don't ask, if I take a little, you know, little one chip computer, I don't say,", "tokens": [50364, 411, 15866, 13, 492, 500, 380, 1029, 11, 498, 286, 747, 257, 707, 11, 291, 458, 11, 707, 472, 11409, 3820, 11, 286, 500, 380, 584, 11, 50640], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1155, "seek": 606016, "start": 6065.68, "end": 6069.599999999999, "text": " well, that's not a computer because it's not as powerful as this, you know, big server over here.", "tokens": [50640, 731, 11, 300, 311, 406, 257, 3820, 570, 309, 311, 406, 382, 4005, 382, 341, 11, 291, 458, 11, 955, 7154, 670, 510, 13, 50836], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1156, "seek": 606016, "start": 6069.599999999999, "end": 6072.8, "text": " No, no, because we know that what the principles are computing on, and I can apply those principles", "tokens": [50836, 883, 11, 572, 11, 570, 321, 458, 300, 437, 264, 9156, 366, 15866, 322, 11, 293, 286, 393, 3079, 729, 9156, 50996], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1157, "seek": 606016, "start": 6072.8, "end": 6076.8, "text": " to a small problem or into a big problem. And same intelligence needs to get there. We have to say,", "tokens": [50996, 281, 257, 1359, 1154, 420, 666, 257, 955, 1154, 13, 400, 912, 7599, 2203, 281, 483, 456, 13, 492, 362, 281, 584, 11, 51196], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1158, "seek": 606016, "start": 6076.8, "end": 6080.0, "text": " these are the principles. I can make a small one, a big one, I can make them distributed, I can", "tokens": [51196, 613, 366, 264, 9156, 13, 286, 393, 652, 257, 1359, 472, 11, 257, 955, 472, 11, 286, 393, 652, 552, 12631, 11, 286, 393, 51356], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1159, "seek": 606016, "start": 6080.0, "end": 6084.0, "text": " put them on different sensors. They don't have to be human like at all. Now you did bring up a very", "tokens": [51356, 829, 552, 322, 819, 14840, 13, 814, 500, 380, 362, 281, 312, 1952, 411, 412, 439, 13, 823, 291, 630, 1565, 493, 257, 588, 51556], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1160, "seek": 606016, "start": 6084.0, "end": 6089.12, "text": " interesting question about embodiment. Does it have to have a body? It has to have some concept", "tokens": [51556, 1880, 1168, 466, 28935, 2328, 13, 4402, 309, 362, 281, 362, 257, 1772, 30, 467, 575, 281, 362, 512, 3410, 51812], "temperature": 0.0, "avg_logprob": -0.10957495193907668, "compression_ratio": 1.8953168044077136, "no_speech_prob": 0.009706994518637657}, {"id": 1161, "seek": 608912, "start": 6089.2, "end": 6094.08, "text": " of movement. It has to be able to move through these reference frames I talked about earlier.", "tokens": [50368, 295, 3963, 13, 467, 575, 281, 312, 1075, 281, 1286, 807, 613, 6408, 12083, 286, 2825, 466, 3071, 13, 50612], "temperature": 0.0, "avg_logprob": -0.11733401673180717, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.00460684671998024}, {"id": 1162, "seek": 608912, "start": 6094.08, "end": 6097.68, "text": " I, whether it's physically moving, like I need, if I'm going to have an AI that", "tokens": [50612, 286, 11, 1968, 309, 311, 9762, 2684, 11, 411, 286, 643, 11, 498, 286, 478, 516, 281, 362, 364, 7318, 300, 50792], "temperature": 0.0, "avg_logprob": -0.11733401673180717, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.00460684671998024}, {"id": 1163, "seek": 608912, "start": 6097.68, "end": 6101.36, "text": " understands coffee cups, it's going to have to pick up the coffee cup and touch it and look at it", "tokens": [50792, 15146, 4982, 13381, 11, 309, 311, 516, 281, 362, 281, 1888, 493, 264, 4982, 4414, 293, 2557, 309, 293, 574, 412, 309, 50976], "temperature": 0.0, "avg_logprob": -0.11733401673180717, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.00460684671998024}, {"id": 1164, "seek": 608912, "start": 6101.36, "end": 6107.36, "text": " with its, with its eyes and hands or something equivalent to that. If I have a mathematical AI,", "tokens": [50976, 365, 1080, 11, 365, 1080, 2575, 293, 2377, 420, 746, 10344, 281, 300, 13, 759, 286, 362, 257, 18894, 7318, 11, 51276], "temperature": 0.0, "avg_logprob": -0.11733401673180717, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.00460684671998024}, {"id": 1165, "seek": 608912, "start": 6108.16, "end": 6113.44, "text": " maybe it needs to move through mathematical spaces. I could have a virtual AI that lives", "tokens": [51316, 1310, 309, 2203, 281, 1286, 807, 18894, 7673, 13, 286, 727, 362, 257, 6374, 7318, 300, 2909, 51580], "temperature": 0.0, "avg_logprob": -0.11733401673180717, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.00460684671998024}, {"id": 1166, "seek": 611344, "start": 6114.32, "end": 6120.879999999999, "text": " in the internet and its movements are traversing links and digging into files, but it's got a", "tokens": [50408, 294, 264, 4705, 293, 1080, 9981, 366, 23149, 278, 6123, 293, 17343, 666, 7098, 11, 457, 309, 311, 658, 257, 50736], "temperature": 0.0, "avg_logprob": -0.1601239245870839, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.01854024827480316}, {"id": 1167, "seek": 611344, "start": 6120.879999999999, "end": 6127.599999999999, "text": " location that it's traveling through some space. You can't have an AI that just takes some flash", "tokens": [50736, 4914, 300, 309, 311, 9712, 807, 512, 1901, 13, 509, 393, 380, 362, 364, 7318, 300, 445, 2516, 512, 7319, 51072], "temperature": 0.0, "avg_logprob": -0.1601239245870839, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.01854024827480316}, {"id": 1168, "seek": 611344, "start": 6127.599999999999, "end": 6134.719999999999, "text": " thing input, you know, we call it flash inference. Here's a pattern, done. No, it's movement time,", "tokens": [51072, 551, 4846, 11, 291, 458, 11, 321, 818, 309, 7319, 38253, 13, 1692, 311, 257, 5102, 11, 1096, 13, 883, 11, 309, 311, 3963, 565, 11, 51428], "temperature": 0.0, "avg_logprob": -0.1601239245870839, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.01854024827480316}, {"id": 1169, "seek": 611344, "start": 6134.719999999999, "end": 6138.08, "text": " movement pattern, movement pattern, movement pattern, attention, digging, building, building", "tokens": [51428, 3963, 5102, 11, 3963, 5102, 11, 3963, 5102, 11, 3202, 11, 17343, 11, 2390, 11, 2390, 51596], "temperature": 0.0, "avg_logprob": -0.1601239245870839, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.01854024827480316}, {"id": 1170, "seek": 611344, "start": 6138.08, "end": 6143.04, "text": " structure, just figuring out the model of the world. So some sort of embodiment, whether it's", "tokens": [51596, 3877, 11, 445, 15213, 484, 264, 2316, 295, 264, 1002, 13, 407, 512, 1333, 295, 28935, 2328, 11, 1968, 309, 311, 51844], "temperature": 0.0, "avg_logprob": -0.1601239245870839, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.01854024827480316}, {"id": 1171, "seek": 614304, "start": 6143.04, "end": 6147.92, "text": " physical or not, has to be part of it. So self-awareness in the way to be able to answer", "tokens": [50364, 4001, 420, 406, 11, 575, 281, 312, 644, 295, 309, 13, 407, 2698, 12, 17074, 1287, 294, 264, 636, 281, 312, 1075, 281, 1867, 50608], "temperature": 0.0, "avg_logprob": -0.18411454921815454, "compression_ratio": 1.848, "no_speech_prob": 0.00047997714136727154}, {"id": 1172, "seek": 614304, "start": 6147.92, "end": 6151.44, "text": " where am I? You're bringing up self-awareness, it's a different topic, self-awareness.", "tokens": [50608, 689, 669, 286, 30, 509, 434, 5062, 493, 2698, 12, 17074, 1287, 11, 309, 311, 257, 819, 4829, 11, 2698, 12, 17074, 1287, 13, 50784], "temperature": 0.0, "avg_logprob": -0.18411454921815454, "compression_ratio": 1.848, "no_speech_prob": 0.00047997714136727154}, {"id": 1173, "seek": 614304, "start": 6151.44, "end": 6159.04, "text": " No, the very narrow definition, meaning knowing a sense of self enough to know where am I in this", "tokens": [50784, 883, 11, 264, 588, 9432, 7123, 11, 3620, 5276, 257, 2020, 295, 2698, 1547, 281, 458, 689, 669, 286, 294, 341, 51164], "temperature": 0.0, "avg_logprob": -0.18411454921815454, "compression_ratio": 1.848, "no_speech_prob": 0.00047997714136727154}, {"id": 1174, "seek": 614304, "start": 6159.04, "end": 6164.64, "text": " space? Yeah, basically the system, the system needs to know its location or each component of the", "tokens": [51164, 1901, 30, 865, 11, 1936, 264, 1185, 11, 264, 1185, 2203, 281, 458, 1080, 4914, 420, 1184, 6542, 295, 264, 51444], "temperature": 0.0, "avg_logprob": -0.18411454921815454, "compression_ratio": 1.848, "no_speech_prob": 0.00047997714136727154}, {"id": 1175, "seek": 614304, "start": 6164.64, "end": 6170.72, "text": " system needs to know where it is in the world at that point in time. So self-awareness and", "tokens": [51444, 1185, 2203, 281, 458, 689, 309, 307, 294, 264, 1002, 412, 300, 935, 294, 565, 13, 407, 2698, 12, 17074, 1287, 293, 51748], "temperature": 0.0, "avg_logprob": -0.18411454921815454, "compression_ratio": 1.848, "no_speech_prob": 0.00047997714136727154}, {"id": 1176, "seek": 617072, "start": 6170.72, "end": 6176.320000000001, "text": " consciousness, do you think, one, from the perspective of neuroscience and neocortex,", "tokens": [50364, 10081, 11, 360, 291, 519, 11, 472, 11, 490, 264, 4585, 295, 42762, 293, 408, 905, 36143, 11, 50644], "temperature": 0.0, "avg_logprob": -0.125062318948599, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.010977289639413357}, {"id": 1177, "seek": 617072, "start": 6176.320000000001, "end": 6182.240000000001, "text": " these are interesting topics, solvable topics, do you have any ideas of why the heck it is that", "tokens": [50644, 613, 366, 1880, 8378, 11, 1404, 17915, 8378, 11, 360, 291, 362, 604, 3487, 295, 983, 264, 12872, 309, 307, 300, 50940], "temperature": 0.0, "avg_logprob": -0.125062318948599, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.010977289639413357}, {"id": 1178, "seek": 617072, "start": 6182.240000000001, "end": 6185.52, "text": " we have a subjective experience at all? Yeah, I have a lot of questions.", "tokens": [50940, 321, 362, 257, 25972, 1752, 412, 439, 30, 865, 11, 286, 362, 257, 688, 295, 1651, 13, 51104], "temperature": 0.0, "avg_logprob": -0.125062318948599, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.010977289639413357}, {"id": 1179, "seek": 617072, "start": 6185.52, "end": 6188.320000000001, "text": " And is it useful or is it just a side effect of us?", "tokens": [51104, 400, 307, 309, 4420, 420, 307, 309, 445, 257, 1252, 1802, 295, 505, 30, 51244], "temperature": 0.0, "avg_logprob": -0.125062318948599, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.010977289639413357}, {"id": 1180, "seek": 617072, "start": 6188.320000000001, "end": 6193.76, "text": " It's interesting to think about. I don't think it's useful as a means to figure out how to", "tokens": [51244, 467, 311, 1880, 281, 519, 466, 13, 286, 500, 380, 519, 309, 311, 4420, 382, 257, 1355, 281, 2573, 484, 577, 281, 51516], "temperature": 0.0, "avg_logprob": -0.125062318948599, "compression_ratio": 1.6965811965811965, "no_speech_prob": 0.010977289639413357}, {"id": 1181, "seek": 619376, "start": 6193.76, "end": 6201.280000000001, "text": " build intelligent machines. It's something that systems do, and we can talk about what it is,", "tokens": [50364, 1322, 13232, 8379, 13, 467, 311, 746, 300, 3652, 360, 11, 293, 321, 393, 751, 466, 437, 309, 307, 11, 50740], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1182, "seek": 619376, "start": 6201.84, "end": 6205.4400000000005, "text": " that are like, well, if I build a system like this, then it would be self-aware. Or", "tokens": [50768, 300, 366, 411, 11, 731, 11, 498, 286, 1322, 257, 1185, 411, 341, 11, 550, 309, 576, 312, 2698, 12, 17074, 13, 1610, 50948], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1183, "seek": 619376, "start": 6206.400000000001, "end": 6209.92, "text": " if I build it like this, it wouldn't be self-aware. So that's a choice I can have.", "tokens": [50996, 498, 286, 1322, 309, 411, 341, 11, 309, 2759, 380, 312, 2698, 12, 17074, 13, 407, 300, 311, 257, 3922, 286, 393, 362, 13, 51172], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1184, "seek": 619376, "start": 6209.92, "end": 6216.0, "text": " It's not like, oh my god, it's self-aware. I heard an interview recently with this", "tokens": [51172, 467, 311, 406, 411, 11, 1954, 452, 3044, 11, 309, 311, 2698, 12, 17074, 13, 286, 2198, 364, 4049, 3938, 365, 341, 51476], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1185, "seek": 619376, "start": 6216.0, "end": 6219.6, "text": " philosopher from Yale, I can't remember his name, I apologize for that. But he was talking about,", "tokens": [51476, 29805, 490, 26711, 11, 286, 393, 380, 1604, 702, 1315, 11, 286, 12328, 337, 300, 13, 583, 415, 390, 1417, 466, 11, 51656], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1186, "seek": 619376, "start": 6219.6, "end": 6223.12, "text": " well, if these computers were self-aware, then it would be a crime done, plug them. And I'm like,", "tokens": [51656, 731, 11, 498, 613, 10807, 645, 2698, 12, 17074, 11, 550, 309, 576, 312, 257, 7206, 1096, 11, 5452, 552, 13, 400, 286, 478, 411, 11, 51832], "temperature": 0.0, "avg_logprob": -0.12476091195415977, "compression_ratio": 1.8333333333333333, "no_speech_prob": 0.10372024774551392}, {"id": 1187, "seek": 622312, "start": 6223.12, "end": 6230.16, "text": " oh, come on. I unplug myself every night, I go to sleep. Is that a crime? I plug myself in again", "tokens": [50364, 1954, 11, 808, 322, 13, 286, 39456, 2059, 633, 1818, 11, 286, 352, 281, 2817, 13, 1119, 300, 257, 7206, 30, 286, 5452, 2059, 294, 797, 50716], "temperature": 0.0, "avg_logprob": -0.14819904989447474, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0003682713722810149}, {"id": 1188, "seek": 622312, "start": 6230.16, "end": 6235.92, "text": " in the morning, and there I am. So people get kind of bent out of shape about this.", "tokens": [50716, 294, 264, 2446, 11, 293, 456, 286, 669, 13, 407, 561, 483, 733, 295, 14075, 484, 295, 3909, 466, 341, 13, 51004], "temperature": 0.0, "avg_logprob": -0.14819904989447474, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0003682713722810149}, {"id": 1189, "seek": 622312, "start": 6235.92, "end": 6242.16, "text": " I have very definite, very detailed understanding or opinions about what it means to be conscious", "tokens": [51004, 286, 362, 588, 25131, 11, 588, 9942, 3701, 420, 11819, 466, 437, 309, 1355, 281, 312, 6648, 51316], "temperature": 0.0, "avg_logprob": -0.14819904989447474, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0003682713722810149}, {"id": 1190, "seek": 622312, "start": 6242.16, "end": 6247.12, "text": " and what it means to be self-aware. I don't think it's that interesting a problem. You talk to", "tokens": [51316, 293, 437, 309, 1355, 281, 312, 2698, 12, 17074, 13, 286, 500, 380, 519, 309, 311, 300, 1880, 257, 1154, 13, 509, 751, 281, 51564], "temperature": 0.0, "avg_logprob": -0.14819904989447474, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0003682713722810149}, {"id": 1191, "seek": 622312, "start": 6247.12, "end": 6252.16, "text": " Kristoff Koch, he thinks that's the only problem. I didn't actually listen to your interview with", "tokens": [51564, 19562, 4506, 40401, 11, 415, 7309, 300, 311, 264, 787, 1154, 13, 286, 994, 380, 767, 2140, 281, 428, 4049, 365, 51816], "temperature": 0.0, "avg_logprob": -0.14819904989447474, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.0003682713722810149}, {"id": 1192, "seek": 625216, "start": 6252.24, "end": 6255.68, "text": " him, but I know him, and I know that's the thing he cares about.", "tokens": [50368, 796, 11, 457, 286, 458, 796, 11, 293, 286, 458, 300, 311, 264, 551, 415, 12310, 466, 13, 50540], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1193, "seek": 625216, "start": 6255.68, "end": 6259.2, "text": " He also thinks intelligence and consciousness have disjoint. So I mean, it's not,", "tokens": [50540, 634, 611, 7309, 7599, 293, 10081, 362, 717, 48613, 13, 407, 286, 914, 11, 309, 311, 406, 11, 50716], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1194, "seek": 625216, "start": 6259.2, "end": 6263.599999999999, "text": " you don't have to have one or the other. I disagree with that. I just totally disagree with that.", "tokens": [50716, 291, 500, 380, 362, 281, 362, 472, 420, 264, 661, 13, 286, 14091, 365, 300, 13, 286, 445, 3879, 14091, 365, 300, 13, 50936], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1195, "seek": 625216, "start": 6264.4, "end": 6268.16, "text": " So where's your thoughts and consciousness? Where does it emerge from? Because it is...", "tokens": [50976, 407, 689, 311, 428, 4598, 293, 10081, 30, 2305, 775, 309, 21511, 490, 30, 1436, 309, 307, 485, 51164], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1196, "seek": 625216, "start": 6268.16, "end": 6272.0, "text": " So then we have to break it down to the two parts, okay? Because consciousness isn't one thing,", "tokens": [51164, 407, 550, 321, 362, 281, 1821, 309, 760, 281, 264, 732, 3166, 11, 1392, 30, 1436, 10081, 1943, 380, 472, 551, 11, 51356], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1197, "seek": 625216, "start": 6272.0, "end": 6275.44, "text": " that's part of the problem with that term. It means different things to different people,", "tokens": [51356, 300, 311, 644, 295, 264, 1154, 365, 300, 1433, 13, 467, 1355, 819, 721, 281, 819, 561, 11, 51528], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1198, "seek": 625216, "start": 6275.44, "end": 6280.0, "text": " and there's different components of it. There is a concept of self-awareness, okay?", "tokens": [51528, 293, 456, 311, 819, 6677, 295, 309, 13, 821, 307, 257, 3410, 295, 2698, 12, 17074, 1287, 11, 1392, 30, 51756], "temperature": 0.0, "avg_logprob": -0.17674144420748442, "compression_ratio": 1.88125, "no_speech_prob": 0.0031224575359374285}, {"id": 1199, "seek": 628000, "start": 6280.8, "end": 6287.36, "text": " That can be very easily explained. You have a model of your own body, the neocortex models", "tokens": [50404, 663, 393, 312, 588, 3612, 8825, 13, 509, 362, 257, 2316, 295, 428, 1065, 1772, 11, 264, 408, 905, 36143, 5245, 50732], "temperature": 0.0, "avg_logprob": -0.09772674636085435, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0002694695140235126}, {"id": 1200, "seek": 628000, "start": 6287.36, "end": 6294.0, "text": " things in the world, and it also models your own body. And then it has a memory. It can remember", "tokens": [50732, 721, 294, 264, 1002, 11, 293, 309, 611, 5245, 428, 1065, 1772, 13, 400, 550, 309, 575, 257, 4675, 13, 467, 393, 1604, 51064], "temperature": 0.0, "avg_logprob": -0.09772674636085435, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0002694695140235126}, {"id": 1201, "seek": 628000, "start": 6294.0, "end": 6298.0, "text": " what you've done, okay? So it can remember what you did this morning, can remember what you had", "tokens": [51064, 437, 291, 600, 1096, 11, 1392, 30, 407, 309, 393, 1604, 437, 291, 630, 341, 2446, 11, 393, 1604, 437, 291, 632, 51264], "temperature": 0.0, "avg_logprob": -0.09772674636085435, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0002694695140235126}, {"id": 1202, "seek": 628000, "start": 6298.0, "end": 6304.48, "text": " for breakfast, and so on. And so I can say to you, okay, Lex, were you conscious this morning when", "tokens": [51264, 337, 8201, 11, 293, 370, 322, 13, 400, 370, 286, 393, 584, 281, 291, 11, 1392, 11, 24086, 11, 645, 291, 6648, 341, 2446, 562, 51588], "temperature": 0.0, "avg_logprob": -0.09772674636085435, "compression_ratio": 1.7685185185185186, "no_speech_prob": 0.0002694695140235126}, {"id": 1203, "seek": 630448, "start": 6304.5599999999995, "end": 6310.16, "text": " you had your bagel? And you'd say, yes, I was conscious. Now what if I could take your brain", "tokens": [50368, 291, 632, 428, 3411, 338, 30, 400, 291, 1116, 584, 11, 2086, 11, 286, 390, 6648, 13, 823, 437, 498, 286, 727, 747, 428, 3567, 50648], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1204, "seek": 630448, "start": 6310.16, "end": 6314.959999999999, "text": " and revert all the synapses back to the state they were this morning? And then I said to you,", "tokens": [50648, 293, 319, 3281, 439, 264, 5451, 2382, 279, 646, 281, 264, 1785, 436, 645, 341, 2446, 30, 400, 550, 286, 848, 281, 291, 11, 50888], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1205, "seek": 630448, "start": 6314.959999999999, "end": 6318.639999999999, "text": " Lex, were you conscious when you ate the bagel? And he said, no, I wasn't conscious. I said,", "tokens": [50888, 24086, 11, 645, 291, 6648, 562, 291, 8468, 264, 3411, 338, 30, 400, 415, 848, 11, 572, 11, 286, 2067, 380, 6648, 13, 286, 848, 11, 51072], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1206, "seek": 630448, "start": 6318.639999999999, "end": 6323.2, "text": " here's a video of eating the bagel. And he said, I wasn't there. I have no... That's not possible", "tokens": [51072, 510, 311, 257, 960, 295, 3936, 264, 3411, 338, 13, 400, 415, 848, 11, 286, 2067, 380, 456, 13, 286, 362, 572, 485, 663, 311, 406, 1944, 51300], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1207, "seek": 630448, "start": 6323.2, "end": 6327.36, "text": " because I must have been unconscious at that time. So we can just make this one-to-one correlation", "tokens": [51300, 570, 286, 1633, 362, 668, 18900, 412, 300, 565, 13, 407, 321, 393, 445, 652, 341, 472, 12, 1353, 12, 546, 20009, 51508], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1208, "seek": 630448, "start": 6327.36, "end": 6331.919999999999, "text": " between memory of your body's trajectory through the world over some period of time,", "tokens": [51508, 1296, 4675, 295, 428, 1772, 311, 21512, 807, 264, 1002, 670, 512, 2896, 295, 565, 11, 51736], "temperature": 0.0, "avg_logprob": -0.09678269671155261, "compression_ratio": 1.786624203821656, "no_speech_prob": 0.0015976489521563053}, {"id": 1209, "seek": 633192, "start": 6331.92, "end": 6336.08, "text": " a memory of it. And the ability to recall that memory is what you would call conscious. I was", "tokens": [50364, 257, 4675, 295, 309, 13, 400, 264, 3485, 281, 9901, 300, 4675, 307, 437, 291, 576, 818, 6648, 13, 286, 390, 50572], "temperature": 0.0, "avg_logprob": -0.11381342371956246, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0003459732106421143}, {"id": 1210, "seek": 633192, "start": 6336.08, "end": 6342.16, "text": " conscious of that. It's a self-awareness. And any system that can recall, memorize what it's", "tokens": [50572, 6648, 295, 300, 13, 467, 311, 257, 2698, 12, 17074, 1287, 13, 400, 604, 1185, 300, 393, 9901, 11, 27478, 437, 309, 311, 50876], "temperature": 0.0, "avg_logprob": -0.11381342371956246, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0003459732106421143}, {"id": 1211, "seek": 633192, "start": 6342.16, "end": 6348.56, "text": " done recently, and bring that back and invoke it again would say, yeah, I'm aware. I remember what", "tokens": [50876, 1096, 3938, 11, 293, 1565, 300, 646, 293, 41117, 309, 797, 576, 584, 11, 1338, 11, 286, 478, 3650, 13, 286, 1604, 437, 51196], "temperature": 0.0, "avg_logprob": -0.11381342371956246, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0003459732106421143}, {"id": 1212, "seek": 633192, "start": 6348.56, "end": 6353.68, "text": " I did. All right, I got it. That's an easy one, although some people think that's a hard one.", "tokens": [51196, 286, 630, 13, 1057, 558, 11, 286, 658, 309, 13, 663, 311, 364, 1858, 472, 11, 4878, 512, 561, 519, 300, 311, 257, 1152, 472, 13, 51452], "temperature": 0.0, "avg_logprob": -0.11381342371956246, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0003459732106421143}, {"id": 1213, "seek": 633192, "start": 6354.64, "end": 6359.52, "text": " The more challenging part of consciousness is this is one that's sometimes used by the word", "tokens": [51500, 440, 544, 7595, 644, 295, 10081, 307, 341, 307, 472, 300, 311, 2171, 1143, 538, 264, 1349, 51744], "temperature": 0.0, "avg_logprob": -0.11381342371956246, "compression_ratio": 1.7316176470588236, "no_speech_prob": 0.0003459732106421143}, {"id": 1214, "seek": 635952, "start": 6359.52, "end": 6368.240000000001, "text": " qualia, which is, why does an object seem red? Or what is pain? And why does pain feel like", "tokens": [50364, 4101, 654, 11, 597, 307, 11, 983, 775, 364, 2657, 1643, 2182, 30, 1610, 437, 307, 1822, 30, 400, 983, 775, 1822, 841, 411, 50800], "temperature": 0.0, "avg_logprob": -0.12544524480426122, "compression_ratio": 1.84375, "no_speech_prob": 0.00047284431639127433}, {"id": 1215, "seek": 635952, "start": 6368.240000000001, "end": 6373.200000000001, "text": " something? Why do I feel redness? Or why do I feel a little painless in a way? And then I could say,", "tokens": [50800, 746, 30, 1545, 360, 286, 841, 2182, 1287, 30, 1610, 983, 360, 286, 841, 257, 707, 1822, 1832, 294, 257, 636, 30, 400, 550, 286, 727, 584, 11, 51048], "temperature": 0.0, "avg_logprob": -0.12544524480426122, "compression_ratio": 1.84375, "no_speech_prob": 0.00047284431639127433}, {"id": 1216, "seek": 635952, "start": 6373.200000000001, "end": 6376.8, "text": " well, why does sight seems different than hearing? That's the same problem. It's really,", "tokens": [51048, 731, 11, 983, 775, 7860, 2544, 819, 813, 4763, 30, 663, 311, 264, 912, 1154, 13, 467, 311, 534, 11, 51228], "temperature": 0.0, "avg_logprob": -0.12544524480426122, "compression_ratio": 1.84375, "no_speech_prob": 0.00047284431639127433}, {"id": 1217, "seek": 635952, "start": 6377.360000000001, "end": 6382.080000000001, "text": " these are all just neurons. And so how is it that why does looking at you feel different than", "tokens": [51256, 613, 366, 439, 445, 22027, 13, 400, 370, 577, 307, 309, 300, 983, 775, 1237, 412, 291, 841, 819, 813, 51492], "temperature": 0.0, "avg_logprob": -0.12544524480426122, "compression_ratio": 1.84375, "no_speech_prob": 0.00047284431639127433}, {"id": 1218, "seek": 635952, "start": 6382.96, "end": 6386.72, "text": " hearing you? It feels different, but there's just neurons in my head. They're all doing the same", "tokens": [51536, 4763, 291, 30, 467, 3417, 819, 11, 457, 456, 311, 445, 22027, 294, 452, 1378, 13, 814, 434, 439, 884, 264, 912, 51724], "temperature": 0.0, "avg_logprob": -0.12544524480426122, "compression_ratio": 1.84375, "no_speech_prob": 0.00047284431639127433}, {"id": 1219, "seek": 638672, "start": 6386.8, "end": 6392.16, "text": " thing. So that's an interesting question. The best treatise I've read about this is by a guy named", "tokens": [50368, 551, 13, 407, 300, 311, 364, 1880, 1168, 13, 440, 1151, 2387, 908, 286, 600, 1401, 466, 341, 307, 538, 257, 2146, 4926, 50636], "temperature": 0.0, "avg_logprob": -0.13862247642027128, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0016482314094901085}, {"id": 1220, "seek": 638672, "start": 6392.16, "end": 6398.8, "text": " O'Regan. O'Regan, he wrote a book called Why Red Doesn't Sound Like a Bell. It's a little,", "tokens": [50636, 422, 6, 8524, 1275, 13, 422, 6, 8524, 1275, 11, 415, 4114, 257, 1446, 1219, 1545, 4477, 12955, 380, 14673, 1743, 257, 11485, 13, 467, 311, 257, 707, 11, 50968], "temperature": 0.0, "avg_logprob": -0.13862247642027128, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0016482314094901085}, {"id": 1221, "seek": 638672, "start": 6400.400000000001, "end": 6406.64, "text": " it's not a trade book, easy to read, but it, and it's an interesting question. Take something like", "tokens": [51048, 309, 311, 406, 257, 4923, 1446, 11, 1858, 281, 1401, 11, 457, 309, 11, 293, 309, 311, 364, 1880, 1168, 13, 3664, 746, 411, 51360], "temperature": 0.0, "avg_logprob": -0.13862247642027128, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0016482314094901085}, {"id": 1222, "seek": 638672, "start": 6406.64, "end": 6411.52, "text": " color. Color really doesn't exist in the world. It's not a property of the world. Property of the", "tokens": [51360, 2017, 13, 10458, 534, 1177, 380, 2514, 294, 264, 1002, 13, 467, 311, 406, 257, 4707, 295, 264, 1002, 13, 48966, 295, 264, 51604], "temperature": 0.0, "avg_logprob": -0.13862247642027128, "compression_ratio": 1.6637931034482758, "no_speech_prob": 0.0016482314094901085}, {"id": 1223, "seek": 641152, "start": 6411.52, "end": 6417.92, "text": " world that exists is light frequency. And that gets turned into we have certain cells in the retina", "tokens": [50364, 1002, 300, 8198, 307, 1442, 7893, 13, 400, 300, 2170, 3574, 666, 321, 362, 1629, 5438, 294, 264, 1533, 1426, 50684], "temperature": 0.0, "avg_logprob": -0.08895878831879432, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.0014549053739756346}, {"id": 1224, "seek": 641152, "start": 6417.92, "end": 6421.280000000001, "text": " that respond to different frequencies, different than others. And so when they enter the brain,", "tokens": [50684, 300, 4196, 281, 819, 20250, 11, 819, 813, 2357, 13, 400, 370, 562, 436, 3242, 264, 3567, 11, 50852], "temperature": 0.0, "avg_logprob": -0.08895878831879432, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.0014549053739756346}, {"id": 1225, "seek": 641152, "start": 6421.280000000001, "end": 6426.72, "text": " you just have a bunch of axons that are firing at different rates. And from that, we perceive color.", "tokens": [50852, 291, 445, 362, 257, 3840, 295, 6360, 892, 300, 366, 16045, 412, 819, 6846, 13, 400, 490, 300, 11, 321, 20281, 2017, 13, 51124], "temperature": 0.0, "avg_logprob": -0.08895878831879432, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.0014549053739756346}, {"id": 1226, "seek": 641152, "start": 6426.72, "end": 6430.8, "text": " But there is no color in the brain. I mean, there's, there's no color coming in on those synapses.", "tokens": [51124, 583, 456, 307, 572, 2017, 294, 264, 3567, 13, 286, 914, 11, 456, 311, 11, 456, 311, 572, 2017, 1348, 294, 322, 729, 5451, 2382, 279, 13, 51328], "temperature": 0.0, "avg_logprob": -0.08895878831879432, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.0014549053739756346}, {"id": 1227, "seek": 641152, "start": 6430.8, "end": 6436.160000000001, "text": " It's just a correlation between some, some, some axons and some property of frequency.", "tokens": [51328, 467, 311, 445, 257, 20009, 1296, 512, 11, 512, 11, 512, 6360, 892, 293, 512, 4707, 295, 7893, 13, 51596], "temperature": 0.0, "avg_logprob": -0.08895878831879432, "compression_ratio": 1.8467432950191571, "no_speech_prob": 0.0014549053739756346}, {"id": 1228, "seek": 643616, "start": 6436.72, "end": 6440.5599999999995, "text": " And that isn't even color itself. Frequency doesn't have a color. It's just a,", "tokens": [50392, 400, 300, 1943, 380, 754, 2017, 2564, 13, 6142, 48154, 1177, 380, 362, 257, 2017, 13, 467, 311, 445, 257, 11, 50584], "temperature": 0.0, "avg_logprob": -0.12377447934494805, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.012817117385566235}, {"id": 1229, "seek": 643616, "start": 6441.28, "end": 6446.4, "text": " it's just what it is. So then the question is, well, why does it even appear to have a color at all?", "tokens": [50620, 309, 311, 445, 437, 309, 307, 13, 407, 550, 264, 1168, 307, 11, 731, 11, 983, 775, 309, 754, 4204, 281, 362, 257, 2017, 412, 439, 30, 50876], "temperature": 0.0, "avg_logprob": -0.12377447934494805, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.012817117385566235}, {"id": 1230, "seek": 643616, "start": 6447.84, "end": 6451.44, "text": " Just as you're describing it, there seems to be a connection to these, those ideas of reference", "tokens": [50948, 1449, 382, 291, 434, 16141, 309, 11, 456, 2544, 281, 312, 257, 4984, 281, 613, 11, 729, 3487, 295, 6408, 51128], "temperature": 0.0, "avg_logprob": -0.12377447934494805, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.012817117385566235}, {"id": 1231, "seek": 643616, "start": 6451.44, "end": 6460.08, "text": " frames. I mean, it just feels like consciousness having the subject, assigning the feeling of red", "tokens": [51128, 12083, 13, 286, 914, 11, 309, 445, 3417, 411, 10081, 1419, 264, 3983, 11, 49602, 264, 2633, 295, 2182, 51560], "temperature": 0.0, "avg_logprob": -0.12377447934494805, "compression_ratio": 1.6431718061674008, "no_speech_prob": 0.012817117385566235}, {"id": 1232, "seek": 646008, "start": 6460.88, "end": 6467.92, "text": " to the actual color or to the wavelength is useful for intelligence.", "tokens": [50404, 281, 264, 3539, 2017, 420, 281, 264, 22907, 307, 4420, 337, 7599, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11970828374226888, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.008312816731631756}, {"id": 1233, "seek": 646008, "start": 6467.92, "end": 6471.92, "text": " Yeah, I think that's a good way of putting it. It's useful as a predictive mechanism or useful", "tokens": [50756, 865, 11, 286, 519, 300, 311, 257, 665, 636, 295, 3372, 309, 13, 467, 311, 4420, 382, 257, 35521, 7513, 420, 4420, 50956], "temperature": 0.0, "avg_logprob": -0.11970828374226888, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.008312816731631756}, {"id": 1234, "seek": 646008, "start": 6471.92, "end": 6476.72, "text": " as a generalization idea. It's a way of grouping things together to say it's useful to have a model", "tokens": [50956, 382, 257, 2674, 2144, 1558, 13, 467, 311, 257, 636, 295, 40149, 721, 1214, 281, 584, 309, 311, 4420, 281, 362, 257, 2316, 51196], "temperature": 0.0, "avg_logprob": -0.11970828374226888, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.008312816731631756}, {"id": 1235, "seek": 646008, "start": 6476.72, "end": 6484.8, "text": " like this. Think about the, the, the well-known syndrome that people who've lost a limb experience", "tokens": [51196, 411, 341, 13, 6557, 466, 264, 11, 264, 11, 264, 731, 12, 6861, 19371, 300, 561, 567, 600, 2731, 257, 30390, 1752, 51600], "temperature": 0.0, "avg_logprob": -0.11970828374226888, "compression_ratio": 1.6088888888888888, "no_speech_prob": 0.008312816731631756}, {"id": 1236, "seek": 648480, "start": 6484.8, "end": 6492.72, "text": " called phantom limbs. And what they claim is they can have their arms removed, but they feel", "tokens": [50364, 1219, 903, 25796, 29315, 13, 400, 437, 436, 3932, 307, 436, 393, 362, 641, 5812, 7261, 11, 457, 436, 841, 50760], "temperature": 0.0, "avg_logprob": -0.12947166442871094, "compression_ratio": 2.0655021834061134, "no_speech_prob": 0.005384034477174282}, {"id": 1237, "seek": 648480, "start": 6492.72, "end": 6497.68, "text": " the arm that not only feel it, they know it's there. They, it's there. I can, I know it's there.", "tokens": [50760, 264, 3726, 300, 406, 787, 841, 309, 11, 436, 458, 309, 311, 456, 13, 814, 11, 309, 311, 456, 13, 286, 393, 11, 286, 458, 309, 311, 456, 13, 51008], "temperature": 0.0, "avg_logprob": -0.12947166442871094, "compression_ratio": 2.0655021834061134, "no_speech_prob": 0.005384034477174282}, {"id": 1238, "seek": 648480, "start": 6497.68, "end": 6501.04, "text": " They'll swear to you that it's there and then they can feel pain in their arm and they'll", "tokens": [51008, 814, 603, 11902, 281, 291, 300, 309, 311, 456, 293, 550, 436, 393, 841, 1822, 294, 641, 3726, 293, 436, 603, 51176], "temperature": 0.0, "avg_logprob": -0.12947166442871094, "compression_ratio": 2.0655021834061134, "no_speech_prob": 0.005384034477174282}, {"id": 1239, "seek": 648480, "start": 6501.04, "end": 6504.88, "text": " feel it in their finger and if they move their, they move their non-existent arm behind their", "tokens": [51176, 841, 309, 294, 641, 5984, 293, 498, 436, 1286, 641, 11, 436, 1286, 641, 2107, 12, 18217, 317, 3726, 2261, 641, 51368], "temperature": 0.0, "avg_logprob": -0.12947166442871094, "compression_ratio": 2.0655021834061134, "no_speech_prob": 0.005384034477174282}, {"id": 1240, "seek": 648480, "start": 6504.88, "end": 6510.72, "text": " back, then they feel the pain behind their back. So this whole idea that your arm exists is a model", "tokens": [51368, 646, 11, 550, 436, 841, 264, 1822, 2261, 641, 646, 13, 407, 341, 1379, 1558, 300, 428, 3726, 8198, 307, 257, 2316, 51660], "temperature": 0.0, "avg_logprob": -0.12947166442871094, "compression_ratio": 2.0655021834061134, "no_speech_prob": 0.005384034477174282}, {"id": 1241, "seek": 651072, "start": 6510.72, "end": 6517.52, "text": " of your brain. It may or may not really exist. And just like, but it's useful to have a model", "tokens": [50364, 295, 428, 3567, 13, 467, 815, 420, 815, 406, 534, 2514, 13, 400, 445, 411, 11, 457, 309, 311, 4420, 281, 362, 257, 2316, 50704], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1242, "seek": 651072, "start": 6517.52, "end": 6521.52, "text": " of something that sort of correlates to things in the world so you can make predictions about what", "tokens": [50704, 295, 746, 300, 1333, 295, 13983, 1024, 281, 721, 294, 264, 1002, 370, 291, 393, 652, 21264, 466, 437, 50904], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1243, "seek": 651072, "start": 6521.52, "end": 6525.2, "text": " would happen when those things occur. It's a little bit of a fuzzy, but I think you're getting", "tokens": [50904, 576, 1051, 562, 729, 721, 5160, 13, 467, 311, 257, 707, 857, 295, 257, 34710, 11, 457, 286, 519, 291, 434, 1242, 51088], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1244, "seek": 651072, "start": 6525.2, "end": 6530.96, "text": " quite towards the answer there. It's, it's useful for the model of to, to express things certain", "tokens": [51088, 1596, 3030, 264, 1867, 456, 13, 467, 311, 11, 309, 311, 4420, 337, 264, 2316, 295, 281, 11, 281, 5109, 721, 1629, 51376], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1245, "seek": 651072, "start": 6530.96, "end": 6534.88, "text": " ways that we can then map them into these reference frames and make predictions about them.", "tokens": [51376, 2098, 300, 321, 393, 550, 4471, 552, 666, 613, 6408, 12083, 293, 652, 21264, 466, 552, 13, 51572], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1246, "seek": 651072, "start": 6535.68, "end": 6538.56, "text": " I need to spend more time on this topic. It doesn't bother me.", "tokens": [51612, 286, 643, 281, 3496, 544, 565, 322, 341, 4829, 13, 467, 1177, 380, 8677, 385, 13, 51756], "temperature": 0.0, "avg_logprob": -0.08538633318089728, "compression_ratio": 1.755700325732899, "no_speech_prob": 0.03961511328816414}, {"id": 1247, "seek": 653856, "start": 6538.8, "end": 6544.64, "text": " Do you really need to spend more time? It does feel special that we have subjective experience,", "tokens": [50376, 1144, 291, 534, 643, 281, 3496, 544, 565, 30, 467, 775, 841, 2121, 300, 321, 362, 25972, 1752, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10835271046079438, "compression_ratio": 1.6556776556776556, "no_speech_prob": 0.0016739021521061659}, {"id": 1248, "seek": 653856, "start": 6544.64, "end": 6549.04, "text": " but I'm yet to know why. I'm just, I'm just personally curious. It's not,", "tokens": [50668, 457, 286, 478, 1939, 281, 458, 983, 13, 286, 478, 445, 11, 286, 478, 445, 5665, 6369, 13, 467, 311, 406, 11, 50888], "temperature": 0.0, "avg_logprob": -0.10835271046079438, "compression_ratio": 1.6556776556776556, "no_speech_prob": 0.0016739021521061659}, {"id": 1249, "seek": 653856, "start": 6549.04, "end": 6553.200000000001, "text": " it's not necessary for the work we're doing here. I don't think I need to solve that problem to", "tokens": [50888, 309, 311, 406, 4818, 337, 264, 589, 321, 434, 884, 510, 13, 286, 500, 380, 519, 286, 643, 281, 5039, 300, 1154, 281, 51096], "temperature": 0.0, "avg_logprob": -0.10835271046079438, "compression_ratio": 1.6556776556776556, "no_speech_prob": 0.0016739021521061659}, {"id": 1250, "seek": 653856, "start": 6553.200000000001, "end": 6558.0, "text": " build intelligent machines at all, not at all. But there is sort of the silly notion that you", "tokens": [51096, 1322, 13232, 8379, 412, 439, 11, 406, 412, 439, 13, 583, 456, 307, 1333, 295, 264, 11774, 10710, 300, 291, 51336], "temperature": 0.0, "avg_logprob": -0.10835271046079438, "compression_ratio": 1.6556776556776556, "no_speech_prob": 0.0016739021521061659}, {"id": 1251, "seek": 653856, "start": 6558.0, "end": 6564.0, "text": " described briefly that doesn't seem so silly to us humans is, you know, if you're successful", "tokens": [51336, 7619, 10515, 300, 1177, 380, 1643, 370, 11774, 281, 505, 6255, 307, 11, 291, 458, 11, 498, 291, 434, 4406, 51636], "temperature": 0.0, "avg_logprob": -0.10835271046079438, "compression_ratio": 1.6556776556776556, "no_speech_prob": 0.0016739021521061659}, {"id": 1252, "seek": 656400, "start": 6564.0, "end": 6571.12, "text": " building intelligent machines, it feels wrong to then turn them off. Because if you're able to", "tokens": [50364, 2390, 13232, 8379, 11, 309, 3417, 2085, 281, 550, 1261, 552, 766, 13, 1436, 498, 291, 434, 1075, 281, 50720], "temperature": 0.0, "avg_logprob": -0.1375446759737455, "compression_ratio": 1.7983870967741935, "no_speech_prob": 0.001867337734438479}, {"id": 1253, "seek": 656400, "start": 6571.12, "end": 6577.92, "text": " build a lot of them, it feels wrong to then be able to, you know, to turn off the,", "tokens": [50720, 1322, 257, 688, 295, 552, 11, 309, 3417, 2085, 281, 550, 312, 1075, 281, 11, 291, 458, 11, 281, 1261, 766, 264, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1375446759737455, "compression_ratio": 1.7983870967741935, "no_speech_prob": 0.001867337734438479}, {"id": 1254, "seek": 656400, "start": 6578.56, "end": 6582.96, "text": " Well, why, but just let's, let's break that down a bit. As humans, why do we fear death?", "tokens": [51092, 1042, 11, 983, 11, 457, 445, 718, 311, 11, 718, 311, 1821, 300, 760, 257, 857, 13, 1018, 6255, 11, 983, 360, 321, 4240, 2966, 30, 51312], "temperature": 0.0, "avg_logprob": -0.1375446759737455, "compression_ratio": 1.7983870967741935, "no_speech_prob": 0.001867337734438479}, {"id": 1255, "seek": 656400, "start": 6583.76, "end": 6587.92, "text": " There's, there's two reasons we fear death. Well, first of all, I'll say when you're", "tokens": [51352, 821, 311, 11, 456, 311, 732, 4112, 321, 4240, 2966, 13, 1042, 11, 700, 295, 439, 11, 286, 603, 584, 562, 291, 434, 51560], "temperature": 0.0, "avg_logprob": -0.1375446759737455, "compression_ratio": 1.7983870967741935, "no_speech_prob": 0.001867337734438479}, {"id": 1256, "seek": 656400, "start": 6587.92, "end": 6593.04, "text": " dead, it doesn't matter. Oh, okay. You're dead. So why do we fear death? We fear death for two", "tokens": [51560, 3116, 11, 309, 1177, 380, 1871, 13, 876, 11, 1392, 13, 509, 434, 3116, 13, 407, 983, 360, 321, 4240, 2966, 30, 492, 4240, 2966, 337, 732, 51816], "temperature": 0.0, "avg_logprob": -0.1375446759737455, "compression_ratio": 1.7983870967741935, "no_speech_prob": 0.001867337734438479}, {"id": 1257, "seek": 659304, "start": 6593.04, "end": 6598.96, "text": " reasons. One is because we are our program genetically to fear death. That's a, that's a", "tokens": [50364, 4112, 13, 1485, 307, 570, 321, 366, 527, 1461, 37582, 281, 4240, 2966, 13, 663, 311, 257, 11, 300, 311, 257, 50660], "temperature": 0.0, "avg_logprob": -0.19418691209525116, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.002590260235592723}, {"id": 1258, "seek": 659304, "start": 6598.96, "end": 6605.36, "text": " survival and prop beginning of the genes thing. And we also are programmed to feel sad when people", "tokens": [50660, 12559, 293, 2365, 2863, 295, 264, 14424, 551, 13, 400, 321, 611, 366, 31092, 281, 841, 4227, 562, 561, 50980], "temperature": 0.0, "avg_logprob": -0.19418691209525116, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.002590260235592723}, {"id": 1259, "seek": 659304, "start": 6605.36, "end": 6609.36, "text": " we know die. We don't feel sad for someone we don't know dies. There's people dying right now,", "tokens": [50980, 321, 458, 978, 13, 492, 500, 380, 841, 4227, 337, 1580, 321, 500, 380, 458, 2714, 13, 821, 311, 561, 8639, 558, 586, 11, 51180], "temperature": 0.0, "avg_logprob": -0.19418691209525116, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.002590260235592723}, {"id": 1260, "seek": 659304, "start": 6609.36, "end": 6612.08, "text": " they're only scared to say, I'm feel bad about them because I don't know them. But I knew them,", "tokens": [51180, 436, 434, 787, 5338, 281, 584, 11, 286, 478, 841, 1578, 466, 552, 570, 286, 500, 380, 458, 552, 13, 583, 286, 2586, 552, 11, 51316], "temperature": 0.0, "avg_logprob": -0.19418691209525116, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.002590260235592723}, {"id": 1261, "seek": 659304, "start": 6612.08, "end": 6618.96, "text": " I'd feel really bad. So again, this, these are old brain genetically embedded things that we", "tokens": [51316, 286, 1116, 841, 534, 1578, 13, 407, 797, 11, 341, 11, 613, 366, 1331, 3567, 37582, 16741, 721, 300, 321, 51660], "temperature": 0.0, "avg_logprob": -0.19418691209525116, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.002590260235592723}, {"id": 1262, "seek": 661896, "start": 6619.04, "end": 6625.2, "text": " fear death. There's outside of those, those uncomfortable feelings. There's nothing else", "tokens": [50368, 4240, 2966, 13, 821, 311, 2380, 295, 729, 11, 729, 10532, 6640, 13, 821, 311, 1825, 1646, 50676], "temperature": 0.0, "avg_logprob": -0.16305809486203077, "compression_ratio": 1.561576354679803, "no_speech_prob": 0.005384073127061129}, {"id": 1263, "seek": 661896, "start": 6625.2, "end": 6630.08, "text": " to worry about. Wait, wait, hold on a second. Do you know the denial of death by Becker?", "tokens": [50676, 281, 3292, 466, 13, 3802, 11, 1699, 11, 1797, 322, 257, 1150, 13, 1144, 291, 458, 264, 28754, 295, 2966, 538, 879, 9178, 30, 50920], "temperature": 0.0, "avg_logprob": -0.16305809486203077, "compression_ratio": 1.561576354679803, "no_speech_prob": 0.005384073127061129}, {"id": 1264, "seek": 661896, "start": 6631.04, "end": 6633.76, "text": " You know, there's a thought that death is,", "tokens": [50968, 509, 458, 11, 456, 311, 257, 1194, 300, 2966, 307, 11, 51104], "temperature": 0.0, "avg_logprob": -0.16305809486203077, "compression_ratio": 1.561576354679803, "no_speech_prob": 0.005384073127061129}, {"id": 1265, "seek": 661896, "start": 6636.32, "end": 6644.56, "text": " you know, our whole conception of our world model kind of assumes immortality. And then death is", "tokens": [51232, 291, 458, 11, 527, 1379, 30698, 295, 527, 1002, 2316, 733, 295, 37808, 44817, 1860, 13, 400, 550, 2966, 307, 51644], "temperature": 0.0, "avg_logprob": -0.16305809486203077, "compression_ratio": 1.561576354679803, "no_speech_prob": 0.005384073127061129}, {"id": 1266, "seek": 664456, "start": 6644.56, "end": 6649.6, "text": " this terror that underlies it all. So like, well, some people's world model, not mine.", "tokens": [50364, 341, 8127, 300, 833, 24119, 309, 439, 13, 407, 411, 11, 731, 11, 512, 561, 311, 1002, 2316, 11, 406, 3892, 13, 50616], "temperature": 0.0, "avg_logprob": -0.19401814004649287, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.011683065444231033}, {"id": 1267, "seek": 664456, "start": 6650.320000000001, "end": 6654.400000000001, "text": " But okay, so what, what Becker would say is that you're just living in an illusion,", "tokens": [50652, 583, 1392, 11, 370, 437, 11, 437, 879, 9178, 576, 584, 307, 300, 291, 434, 445, 2647, 294, 364, 18854, 11, 50856], "temperature": 0.0, "avg_logprob": -0.19401814004649287, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.011683065444231033}, {"id": 1268, "seek": 664456, "start": 6654.400000000001, "end": 6659.52, "text": " you've constructed illusion for yourself, because it's such a terrible terror. The fact that", "tokens": [50856, 291, 600, 17083, 18854, 337, 1803, 11, 570, 309, 311, 1270, 257, 6237, 8127, 13, 440, 1186, 300, 51112], "temperature": 0.0, "avg_logprob": -0.19401814004649287, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.011683065444231033}, {"id": 1269, "seek": 664456, "start": 6660.080000000001, "end": 6664.240000000001, "text": " what's the illusion, the illusion that death doesn't matter, you're still not coming to grips", "tokens": [51140, 437, 311, 264, 18854, 11, 264, 18854, 300, 2966, 1177, 380, 1871, 11, 291, 434, 920, 406, 1348, 281, 38037, 51348], "temperature": 0.0, "avg_logprob": -0.19401814004649287, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.011683065444231033}, {"id": 1270, "seek": 664456, "start": 6664.240000000001, "end": 6669.76, "text": " with the illusion of what that death is going to happen. Oh, like it's not going to happen.", "tokens": [51348, 365, 264, 18854, 295, 437, 300, 2966, 307, 516, 281, 1051, 13, 876, 11, 411, 309, 311, 406, 516, 281, 1051, 13, 51624], "temperature": 0.0, "avg_logprob": -0.19401814004649287, "compression_ratio": 1.7817460317460319, "no_speech_prob": 0.011683065444231033}, {"id": 1271, "seek": 666976, "start": 6670.64, "end": 6674.16, "text": " You're actually operating. You haven't, even though you said you've accepted it,", "tokens": [50408, 509, 434, 767, 7447, 13, 509, 2378, 380, 11, 754, 1673, 291, 848, 291, 600, 9035, 309, 11, 50584], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1272, "seek": 666976, "start": 6674.16, "end": 6677.68, "text": " you haven't really accepted the notion of death is what he was saying. So it sounds like,", "tokens": [50584, 291, 2378, 380, 534, 9035, 264, 10710, 295, 2966, 307, 437, 415, 390, 1566, 13, 407, 309, 3263, 411, 11, 50760], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1273, "seek": 666976, "start": 6679.52, "end": 6681.6, "text": " it sounds like you disagree with that notion. I mean,", "tokens": [50852, 309, 3263, 411, 291, 14091, 365, 300, 10710, 13, 286, 914, 11, 50956], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1274, "seek": 666976, "start": 6681.6, "end": 6684.24, "text": " Yeah, yeah, totally. I, like, I,", "tokens": [50956, 865, 11, 1338, 11, 3879, 13, 286, 11, 411, 11, 286, 11, 51088], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1275, "seek": 666976, "start": 6684.24, "end": 6687.12, "text": " So death is not that such an important. Every night, every night I go to bed,", "tokens": [51088, 407, 2966, 307, 406, 300, 1270, 364, 1021, 13, 2048, 1818, 11, 633, 1818, 286, 352, 281, 2901, 11, 51232], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1276, "seek": 666976, "start": 6687.12, "end": 6690.64, "text": " it's like dying. With little deaths. It's full of death. And if I didn't wake up,", "tokens": [51232, 309, 311, 411, 8639, 13, 2022, 707, 13027, 13, 467, 311, 1577, 295, 2966, 13, 400, 498, 286, 994, 380, 6634, 493, 11, 51408], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1277, "seek": 666976, "start": 6691.6, "end": 6695.280000000001, "text": " it wouldn't matter to me. Only if I knew that was going to happen would it be bothersome. But I", "tokens": [51456, 309, 2759, 380, 1871, 281, 385, 13, 5686, 498, 286, 2586, 300, 390, 516, 281, 1051, 576, 309, 312, 33980, 423, 13, 583, 286, 51640], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1278, "seek": 666976, "start": 6695.280000000001, "end": 6699.360000000001, "text": " didn't know it was going to happen. How would I know? Then I would worry about my wife.", "tokens": [51640, 994, 380, 458, 309, 390, 516, 281, 1051, 13, 1012, 576, 286, 458, 30, 1396, 286, 576, 3292, 466, 452, 3836, 13, 51844], "temperature": 0.0, "avg_logprob": -0.2341695058913458, "compression_ratio": 1.8102409638554218, "no_speech_prob": 0.019119128584861755}, {"id": 1279, "seek": 669936, "start": 6699.44, "end": 6704.0, "text": " So imagine, imagine I was a loner and I lived in Alaska and I lived them", "tokens": [50368, 407, 3811, 11, 3811, 286, 390, 257, 9155, 260, 293, 286, 5152, 294, 19553, 293, 286, 5152, 552, 50596], "temperature": 0.0, "avg_logprob": -0.12897410444034044, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0003300605749245733}, {"id": 1280, "seek": 669936, "start": 6704.0, "end": 6707.759999999999, "text": " out there and there was no animals. Nobody knew I existed. I was just eating these roots all the", "tokens": [50596, 484, 456, 293, 456, 390, 572, 4882, 13, 9297, 2586, 286, 13135, 13, 286, 390, 445, 3936, 613, 10669, 439, 264, 50784], "temperature": 0.0, "avg_logprob": -0.12897410444034044, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0003300605749245733}, {"id": 1281, "seek": 669936, "start": 6707.759999999999, "end": 6715.92, "text": " time and nobody knew I was there. And one day I didn't wake up. What pain in the world would there", "tokens": [50784, 565, 293, 5079, 2586, 286, 390, 456, 13, 400, 472, 786, 286, 994, 380, 6634, 493, 13, 708, 1822, 294, 264, 1002, 576, 456, 51192], "temperature": 0.0, "avg_logprob": -0.12897410444034044, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0003300605749245733}, {"id": 1282, "seek": 669936, "start": 6715.92, "end": 6721.92, "text": " exist? Well, so most people that think about this problem would say that you're just deeply enlightened", "tokens": [51192, 2514, 30, 1042, 11, 370, 881, 561, 300, 519, 466, 341, 1154, 576, 584, 300, 291, 434, 445, 8760, 36975, 51492], "temperature": 0.0, "avg_logprob": -0.12897410444034044, "compression_ratio": 1.6681614349775784, "no_speech_prob": 0.0003300605749245733}, {"id": 1283, "seek": 672192, "start": 6721.92, "end": 6729.84, "text": " or are completely delusional. But I would say, I would say that's a very enlightened", "tokens": [50364, 420, 366, 2584, 1103, 301, 1966, 13, 583, 286, 576, 584, 11, 286, 576, 584, 300, 311, 257, 588, 36975, 50760], "temperature": 0.0, "avg_logprob": -0.1796990880426371, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.08876118808984756}, {"id": 1284, "seek": 672192, "start": 6730.4, "end": 6735.76, "text": " way to see the world is that that's the rational one. Well, I think it's rational. That's right.", "tokens": [50788, 636, 281, 536, 264, 1002, 307, 300, 300, 311, 264, 15090, 472, 13, 1042, 11, 286, 519, 309, 311, 15090, 13, 663, 311, 558, 13, 51056], "temperature": 0.0, "avg_logprob": -0.1796990880426371, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.08876118808984756}, {"id": 1285, "seek": 672192, "start": 6735.76, "end": 6743.4400000000005, "text": " But the fact is we don't, I mean, we really don't have an understanding of why the heck it is we're", "tokens": [51056, 583, 264, 1186, 307, 321, 500, 380, 11, 286, 914, 11, 321, 534, 500, 380, 362, 364, 3701, 295, 983, 264, 12872, 309, 307, 321, 434, 51440], "temperature": 0.0, "avg_logprob": -0.1796990880426371, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.08876118808984756}, {"id": 1286, "seek": 672192, "start": 6743.4400000000005, "end": 6747.84, "text": " born and why we die and what happens after we die. Well, maybe there isn't a reason, maybe there is.", "tokens": [51440, 4232, 293, 983, 321, 978, 293, 437, 2314, 934, 321, 978, 13, 1042, 11, 1310, 456, 1943, 380, 257, 1778, 11, 1310, 456, 307, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1796990880426371, "compression_ratio": 1.76036866359447, "no_speech_prob": 0.08876118808984756}, {"id": 1287, "seek": 674784, "start": 6747.84, "end": 6752.24, "text": " So I'm interested in those big problems too, right? You know, you interviewed Max Tagmark,", "tokens": [50364, 407, 286, 478, 3102, 294, 729, 955, 2740, 886, 11, 558, 30, 509, 458, 11, 291, 19770, 7402, 11204, 5638, 11, 50584], "temperature": 0.0, "avg_logprob": -0.10047600699252769, "compression_ratio": 1.80859375, "no_speech_prob": 0.002799583598971367}, {"id": 1288, "seek": 674784, "start": 6752.24, "end": 6755.28, "text": " you know, and there's people like that, right? I'm interested in those big problems as well.", "tokens": [50584, 291, 458, 11, 293, 456, 311, 561, 411, 300, 11, 558, 30, 286, 478, 3102, 294, 729, 955, 2740, 382, 731, 13, 50736], "temperature": 0.0, "avg_logprob": -0.10047600699252769, "compression_ratio": 1.80859375, "no_speech_prob": 0.002799583598971367}, {"id": 1289, "seek": 674784, "start": 6755.28, "end": 6761.6, "text": " And in fact, when I was young, I made a list of the biggest problems I could think of. First,", "tokens": [50736, 400, 294, 1186, 11, 562, 286, 390, 2037, 11, 286, 1027, 257, 1329, 295, 264, 3880, 2740, 286, 727, 519, 295, 13, 2386, 11, 51052], "temperature": 0.0, "avg_logprob": -0.10047600699252769, "compression_ratio": 1.80859375, "no_speech_prob": 0.002799583598971367}, {"id": 1290, "seek": 674784, "start": 6761.6, "end": 6767.04, "text": " why does anything exist? Second, why did we have the laws of physics that we have? Third,", "tokens": [51052, 983, 775, 1340, 2514, 30, 5736, 11, 983, 630, 321, 362, 264, 6064, 295, 10649, 300, 321, 362, 30, 12548, 11, 51324], "temperature": 0.0, "avg_logprob": -0.10047600699252769, "compression_ratio": 1.80859375, "no_speech_prob": 0.002799583598971367}, {"id": 1291, "seek": 674784, "start": 6767.68, "end": 6773.04, "text": " is life inevitable? And why is it here? Fourth, is intelligence inevitable? And why is it here?", "tokens": [51356, 307, 993, 21451, 30, 400, 983, 307, 309, 510, 30, 23773, 11, 307, 7599, 21451, 30, 400, 983, 307, 309, 510, 30, 51624], "temperature": 0.0, "avg_logprob": -0.10047600699252769, "compression_ratio": 1.80859375, "no_speech_prob": 0.002799583598971367}, {"id": 1292, "seek": 677304, "start": 6773.04, "end": 6777.12, "text": " I stopped there because I figured if you can make a truly intelligent system,", "tokens": [50364, 286, 5936, 456, 570, 286, 8932, 498, 291, 393, 652, 257, 4908, 13232, 1185, 11, 50568], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1293, "seek": 677304, "start": 6777.84, "end": 6780.56, "text": " we'll be, that'll be the quickest way to answer the first three questions.", "tokens": [50604, 321, 603, 312, 11, 300, 603, 312, 264, 49403, 636, 281, 1867, 264, 700, 1045, 1651, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1294, "seek": 677304, "start": 6783.2, "end": 6788.64, "text": " I'm serious. And so I said, my mission, you know, you asked me earlier, my first mission is", "tokens": [50872, 286, 478, 3156, 13, 400, 370, 286, 848, 11, 452, 4447, 11, 291, 458, 11, 291, 2351, 385, 3071, 11, 452, 700, 4447, 307, 51144], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1295, "seek": 677304, "start": 6788.64, "end": 6792.16, "text": " to understand the brain, but I felt that is the shortest way to get to true machine intelligence.", "tokens": [51144, 281, 1223, 264, 3567, 11, 457, 286, 2762, 300, 307, 264, 31875, 636, 281, 483, 281, 2074, 3479, 7599, 13, 51320], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1296, "seek": 677304, "start": 6792.16, "end": 6795.92, "text": " And I want to get to true machine intelligence because even if it doesn't occur in my lifetime,", "tokens": [51320, 400, 286, 528, 281, 483, 281, 2074, 3479, 7599, 570, 754, 498, 309, 1177, 380, 5160, 294, 452, 11364, 11, 51508], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1297, "seek": 677304, "start": 6795.92, "end": 6799.6, "text": " other people will benefit from it because I think it'll occur in my lifetime, but you know,", "tokens": [51508, 661, 561, 486, 5121, 490, 309, 570, 286, 519, 309, 603, 5160, 294, 452, 11364, 11, 457, 291, 458, 11, 51692], "temperature": 0.0, "avg_logprob": -0.1262217008150541, "compression_ratio": 1.8928571428571428, "no_speech_prob": 0.0035922913812100887}, {"id": 1298, "seek": 679960, "start": 6799.6, "end": 6806.72, "text": " 20 years, you never know. And but that will be the quickest way for us to, you know, we can make", "tokens": [50364, 945, 924, 11, 291, 1128, 458, 13, 400, 457, 300, 486, 312, 264, 49403, 636, 337, 505, 281, 11, 291, 458, 11, 321, 393, 652, 50720], "temperature": 0.0, "avg_logprob": -0.12796824801284656, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.0035914855543524027}, {"id": 1299, "seek": 679960, "start": 6806.72, "end": 6812.88, "text": " super mathematicians, we can make super space explorers, we can make super physicists brains", "tokens": [50720, 1687, 32811, 2567, 11, 321, 393, 652, 1687, 1901, 24765, 433, 11, 321, 393, 652, 1687, 48716, 15442, 51028], "temperature": 0.0, "avg_logprob": -0.12796824801284656, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.0035914855543524027}, {"id": 1300, "seek": 679960, "start": 6812.88, "end": 6818.64, "text": " that do these things, and that can run experiments that we can't run, we don't have the abilities", "tokens": [51028, 300, 360, 613, 721, 11, 293, 300, 393, 1190, 12050, 300, 321, 393, 380, 1190, 11, 321, 500, 380, 362, 264, 11582, 51316], "temperature": 0.0, "avg_logprob": -0.12796824801284656, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.0035914855543524027}, {"id": 1301, "seek": 679960, "start": 6818.64, "end": 6822.56, "text": " to manipulate things and so on. But we can build and tell the machines to do all those things.", "tokens": [51316, 281, 20459, 721, 293, 370, 322, 13, 583, 321, 393, 1322, 293, 980, 264, 8379, 281, 360, 439, 729, 721, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12796824801284656, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.0035914855543524027}, {"id": 1302, "seek": 679960, "start": 6822.56, "end": 6827.360000000001, "text": " And with the ultimate goal of finding out the answers to the other questions.", "tokens": [51512, 400, 365, 264, 9705, 3387, 295, 5006, 484, 264, 6338, 281, 264, 661, 1651, 13, 51752], "temperature": 0.0, "avg_logprob": -0.12796824801284656, "compression_ratio": 1.811023622047244, "no_speech_prob": 0.0035914855543524027}, {"id": 1303, "seek": 682736, "start": 6827.599999999999, "end": 6834.799999999999, "text": " Let me ask you another depressing and difficult question, which is, once we achieve that goal,", "tokens": [50376, 961, 385, 1029, 291, 1071, 36355, 293, 2252, 1168, 11, 597, 307, 11, 1564, 321, 4584, 300, 3387, 11, 50736], "temperature": 0.0, "avg_logprob": -0.2382955551147461, "compression_ratio": 1.816831683168317, "no_speech_prob": 0.0010160567471757531}, {"id": 1304, "seek": 682736, "start": 6836.08, "end": 6842.96, "text": " do you, of creating, no, of understanding intelligence, do you think we would be happier", "tokens": [50800, 360, 291, 11, 295, 4084, 11, 572, 11, 295, 3701, 7599, 11, 360, 291, 519, 321, 576, 312, 20423, 51144], "temperature": 0.0, "avg_logprob": -0.2382955551147461, "compression_ratio": 1.816831683168317, "no_speech_prob": 0.0010160567471757531}, {"id": 1305, "seek": 682736, "start": 6842.96, "end": 6846.719999999999, "text": " and more fulfilled as a species? Understanding intelligence or understanding the answers to", "tokens": [51144, 293, 544, 21380, 382, 257, 6172, 30, 36858, 7599, 420, 3701, 264, 6338, 281, 51332], "temperature": 0.0, "avg_logprob": -0.2382955551147461, "compression_ratio": 1.816831683168317, "no_speech_prob": 0.0010160567471757531}, {"id": 1306, "seek": 682736, "start": 6846.719999999999, "end": 6852.88, "text": " the big questions? Understanding intelligence. Totally. Totally. It would be a far more fun", "tokens": [51332, 264, 955, 1651, 30, 36858, 7599, 13, 22837, 13, 22837, 13, 467, 576, 312, 257, 1400, 544, 1019, 51640], "temperature": 0.0, "avg_logprob": -0.2382955551147461, "compression_ratio": 1.816831683168317, "no_speech_prob": 0.0010160567471757531}, {"id": 1307, "seek": 685288, "start": 6852.88, "end": 6858.08, "text": " place to live. You think so? Oh, yeah, why not? I mean, you know, just put aside this, you know,", "tokens": [50364, 1081, 281, 1621, 13, 509, 519, 370, 30, 876, 11, 1338, 11, 983, 406, 30, 286, 914, 11, 291, 458, 11, 445, 829, 7359, 341, 11, 291, 458, 11, 50624], "temperature": 0.0, "avg_logprob": -0.16067040484884512, "compression_ratio": 1.88212927756654, "no_speech_prob": 0.14786297082901}, {"id": 1308, "seek": 685288, "start": 6858.08, "end": 6864.88, "text": " terminator nonsense and, and, and, and just think about, you can think about the, we can talk about", "tokens": [50624, 10761, 1639, 14925, 293, 11, 293, 11, 293, 11, 293, 445, 519, 466, 11, 291, 393, 519, 466, 264, 11, 321, 393, 751, 466, 50964], "temperature": 0.0, "avg_logprob": -0.16067040484884512, "compression_ratio": 1.88212927756654, "no_speech_prob": 0.14786297082901}, {"id": 1309, "seek": 685288, "start": 6864.88, "end": 6870.16, "text": " the risk of AI if you want. I'd love to. So let's talk about. But I think the world is far better", "tokens": [50964, 264, 3148, 295, 7318, 498, 291, 528, 13, 286, 1116, 959, 281, 13, 407, 718, 311, 751, 466, 13, 583, 286, 519, 264, 1002, 307, 1400, 1101, 51228], "temperature": 0.0, "avg_logprob": -0.16067040484884512, "compression_ratio": 1.88212927756654, "no_speech_prob": 0.14786297082901}, {"id": 1310, "seek": 685288, "start": 6870.16, "end": 6874.08, "text": " knowing things. We're always better than no things. Do you think it's better? Is it a better place to", "tokens": [51228, 5276, 721, 13, 492, 434, 1009, 1101, 813, 572, 721, 13, 1144, 291, 519, 309, 311, 1101, 30, 1119, 309, 257, 1101, 1081, 281, 51424], "temperature": 0.0, "avg_logprob": -0.16067040484884512, "compression_ratio": 1.88212927756654, "no_speech_prob": 0.14786297082901}, {"id": 1311, "seek": 685288, "start": 6874.08, "end": 6878.88, "text": " live in that I know that our planet is one of many in the solar system and the solar system is one", "tokens": [51424, 1621, 294, 300, 286, 458, 300, 527, 5054, 307, 472, 295, 867, 294, 264, 7936, 1185, 293, 264, 7936, 1185, 307, 472, 51664], "temperature": 0.0, "avg_logprob": -0.16067040484884512, "compression_ratio": 1.88212927756654, "no_speech_prob": 0.14786297082901}, {"id": 1312, "seek": 687888, "start": 6878.88, "end": 6883.28, "text": " of many of the galaxies? I think it's a more, I, I dread, I used to, I sometimes think like,", "tokens": [50364, 295, 867, 295, 264, 28755, 30, 286, 519, 309, 311, 257, 544, 11, 286, 11, 286, 22236, 11, 286, 1143, 281, 11, 286, 2171, 519, 411, 11, 50584], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1313, "seek": 687888, "start": 6883.28, "end": 6887.36, "text": " God, what would it be like 300 years ago? I'd be looking up the sky. I can't understand anything.", "tokens": [50584, 1265, 11, 437, 576, 309, 312, 411, 6641, 924, 2057, 30, 286, 1116, 312, 1237, 493, 264, 5443, 13, 286, 393, 380, 1223, 1340, 13, 50788], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1314, "seek": 687888, "start": 6887.36, "end": 6891.12, "text": " Oh my God, I'd be like going to bed every night going, what's going on here? Well, I mean, in", "tokens": [50788, 876, 452, 1265, 11, 286, 1116, 312, 411, 516, 281, 2901, 633, 1818, 516, 11, 437, 311, 516, 322, 510, 30, 1042, 11, 286, 914, 11, 294, 50976], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1315, "seek": 687888, "start": 6891.12, "end": 6896.72, "text": " some sense, I agree with you, but I'm not exactly sure. So I'm also a scientist. So I have, I share", "tokens": [50976, 512, 2020, 11, 286, 3986, 365, 291, 11, 457, 286, 478, 406, 2293, 988, 13, 407, 286, 478, 611, 257, 12662, 13, 407, 286, 362, 11, 286, 2073, 51256], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1316, "seek": 687888, "start": 6896.72, "end": 6903.36, "text": " your views, but I'm not, we're, we're like rolling down the hill together. What's down the hill?", "tokens": [51256, 428, 6809, 11, 457, 286, 478, 406, 11, 321, 434, 11, 321, 434, 411, 9439, 760, 264, 10997, 1214, 13, 708, 311, 760, 264, 10997, 30, 51588], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1317, "seek": 687888, "start": 6903.36, "end": 6907.52, "text": " I feel like we're climbing a hill. Whatever. We're getting, we're getting closer to enlightenment.", "tokens": [51588, 286, 841, 411, 321, 434, 14780, 257, 10997, 13, 8541, 13, 492, 434, 1242, 11, 321, 434, 1242, 4966, 281, 34661, 13, 51796], "temperature": 0.0, "avg_logprob": -0.15303494380070612, "compression_ratio": 1.762917933130699, "no_speech_prob": 0.03567129373550415}, {"id": 1318, "seek": 690752, "start": 6907.76, "end": 6913.200000000001, "text": " Whatever. We're climbing, we're getting pulled up a hill by our curiosity.", "tokens": [50376, 8541, 13, 492, 434, 14780, 11, 321, 434, 1242, 7373, 493, 257, 10997, 538, 527, 18769, 13, 50648], "temperature": 0.0, "avg_logprob": -0.22605297021698534, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.0007320130243897438}, {"id": 1319, "seek": 690752, "start": 6913.200000000001, "end": 6916.96, "text": " We are putting, our polarity is pulling, we're pulling ourselves up the hill by our curiosity.", "tokens": [50648, 492, 366, 3372, 11, 527, 12367, 507, 307, 8407, 11, 321, 434, 8407, 4175, 493, 264, 10997, 538, 527, 18769, 13, 50836], "temperature": 0.0, "avg_logprob": -0.22605297021698534, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.0007320130243897438}, {"id": 1320, "seek": 690752, "start": 6916.96, "end": 6923.120000000001, "text": " Yeah. Sisyphus are doing the same thing with the rock. Yeah. But okay, our happiness aside,", "tokens": [50836, 865, 13, 318, 14169, 950, 301, 366, 884, 264, 912, 551, 365, 264, 3727, 13, 865, 13, 583, 1392, 11, 527, 8324, 7359, 11, 51144], "temperature": 0.0, "avg_logprob": -0.22605297021698534, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.0007320130243897438}, {"id": 1321, "seek": 690752, "start": 6923.120000000001, "end": 6930.4800000000005, "text": " do you have concerns about, you know, you talk about Sam Harris, Elon Musk, of existential threats", "tokens": [51144, 360, 291, 362, 7389, 466, 11, 291, 458, 11, 291, 751, 466, 4832, 17426, 11, 28498, 26019, 11, 295, 37133, 14909, 51512], "temperature": 0.0, "avg_logprob": -0.22605297021698534, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.0007320130243897438}, {"id": 1322, "seek": 690752, "start": 6930.4800000000005, "end": 6934.240000000001, "text": " of intelligence systems? No, I'm not worried about existential threats at all. There are,", "tokens": [51512, 295, 7599, 3652, 30, 883, 11, 286, 478, 406, 5804, 466, 37133, 14909, 412, 439, 13, 821, 366, 11, 51700], "temperature": 0.0, "avg_logprob": -0.22605297021698534, "compression_ratio": 1.7045454545454546, "no_speech_prob": 0.0007320130243897438}, {"id": 1323, "seek": 693424, "start": 6934.24, "end": 6937.679999999999, "text": " there are some things we really do need to worry about. Even today's AI, we have things we have", "tokens": [50364, 456, 366, 512, 721, 321, 534, 360, 643, 281, 3292, 466, 13, 2754, 965, 311, 7318, 11, 321, 362, 721, 321, 362, 50536], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1324, "seek": 693424, "start": 6937.679999999999, "end": 6942.639999999999, "text": " to worry about. We have to worry about privacy and about how impacts false beliefs in the world.", "tokens": [50536, 281, 3292, 466, 13, 492, 362, 281, 3292, 466, 11427, 293, 466, 577, 11606, 7908, 13585, 294, 264, 1002, 13, 50784], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1325, "seek": 693424, "start": 6942.639999999999, "end": 6947.679999999999, "text": " And, and we have real problems that, and things to worry about with today's AI.", "tokens": [50784, 400, 11, 293, 321, 362, 957, 2740, 300, 11, 293, 721, 281, 3292, 466, 365, 965, 311, 7318, 13, 51036], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1326, "seek": 693424, "start": 6948.48, "end": 6952.0, "text": " And that will continue as we create more intelligent systems. There's no question, you", "tokens": [51076, 400, 300, 486, 2354, 382, 321, 1884, 544, 13232, 3652, 13, 821, 311, 572, 1168, 11, 291, 51252], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1327, "seek": 693424, "start": 6952.0, "end": 6957.44, "text": " know, the whole issue about, you know, making intelligent armaments and weapons is something", "tokens": [51252, 458, 11, 264, 1379, 2734, 466, 11, 291, 458, 11, 1455, 13232, 3726, 28401, 293, 7278, 307, 746, 51524], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1328, "seek": 693424, "start": 6957.44, "end": 6961.76, "text": " that really we have to think about carefully. I don't think of those as existential threats.", "tokens": [51524, 300, 534, 321, 362, 281, 519, 466, 7500, 13, 286, 500, 380, 519, 295, 729, 382, 37133, 14909, 13, 51740], "temperature": 0.0, "avg_logprob": -0.07610347659088844, "compression_ratio": 1.912280701754386, "no_speech_prob": 0.008572204038500786}, {"id": 1329, "seek": 696176, "start": 6961.76, "end": 6966.400000000001, "text": " I think those are the kind of threats we always face, and we'll have to face them here and, and,", "tokens": [50364, 286, 519, 729, 366, 264, 733, 295, 14909, 321, 1009, 1851, 11, 293, 321, 603, 362, 281, 1851, 552, 510, 293, 11, 293, 11, 50596], "temperature": 0.0, "avg_logprob": -0.11529893562441966, "compression_ratio": 1.908366533864542, "no_speech_prob": 0.006094292737543583}, {"id": 1330, "seek": 696176, "start": 6967.280000000001, "end": 6972.320000000001, "text": " and we'll have to deal with them. The, we can, we could talk about what people think are the", "tokens": [50640, 293, 321, 603, 362, 281, 2028, 365, 552, 13, 440, 11, 321, 393, 11, 321, 727, 751, 466, 437, 561, 519, 366, 264, 50892], "temperature": 0.0, "avg_logprob": -0.11529893562441966, "compression_ratio": 1.908366533864542, "no_speech_prob": 0.006094292737543583}, {"id": 1331, "seek": 696176, "start": 6972.320000000001, "end": 6977.360000000001, "text": " existential threats. But when I hear people talking about them, they all sound hollow to me.", "tokens": [50892, 37133, 14909, 13, 583, 562, 286, 1568, 561, 1417, 466, 552, 11, 436, 439, 1626, 23972, 281, 385, 13, 51144], "temperature": 0.0, "avg_logprob": -0.11529893562441966, "compression_ratio": 1.908366533864542, "no_speech_prob": 0.006094292737543583}, {"id": 1332, "seek": 696176, "start": 6977.360000000001, "end": 6981.360000000001, "text": " They're, they're based on ideas, they're based on people who really have no idea what intelligence", "tokens": [51144, 814, 434, 11, 436, 434, 2361, 322, 3487, 11, 436, 434, 2361, 322, 561, 567, 534, 362, 572, 1558, 437, 7599, 51344], "temperature": 0.0, "avg_logprob": -0.11529893562441966, "compression_ratio": 1.908366533864542, "no_speech_prob": 0.006094292737543583}, {"id": 1333, "seek": 696176, "start": 6981.360000000001, "end": 6987.4400000000005, "text": " is. And, and if they knew what intelligence was, they wouldn't say those things. So those are not", "tokens": [51344, 307, 13, 400, 11, 293, 498, 436, 2586, 437, 7599, 390, 11, 436, 2759, 380, 584, 729, 721, 13, 407, 729, 366, 406, 51648], "temperature": 0.0, "avg_logprob": -0.11529893562441966, "compression_ratio": 1.908366533864542, "no_speech_prob": 0.006094292737543583}, {"id": 1334, "seek": 698744, "start": 6987.44, "end": 6992.639999999999, "text": " experts in the field, you know. So yeah, so there's two, right? There's, so one is like", "tokens": [50364, 8572, 294, 264, 2519, 11, 291, 458, 13, 407, 1338, 11, 370, 456, 311, 732, 11, 558, 30, 821, 311, 11, 370, 472, 307, 411, 50624], "temperature": 0.0, "avg_logprob": -0.14645557898979683, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.0060940939001739025}, {"id": 1335, "seek": 698744, "start": 6992.639999999999, "end": 7003.04, "text": " super intelligent. So a system that becomes far, far superior in reasoning ability than us humans.", "tokens": [50624, 1687, 13232, 13, 407, 257, 1185, 300, 3643, 1400, 11, 1400, 13028, 294, 21577, 3485, 813, 505, 6255, 13, 51144], "temperature": 0.0, "avg_logprob": -0.14645557898979683, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.0060940939001739025}, {"id": 1336, "seek": 698744, "start": 7003.04, "end": 7009.839999999999, "text": " How is that an existential threat? Then, so there's a lot of ways in which it could be. One way is", "tokens": [51144, 1012, 307, 300, 364, 37133, 4734, 30, 1396, 11, 370, 456, 311, 257, 688, 295, 2098, 294, 597, 309, 727, 312, 13, 1485, 636, 307, 51484], "temperature": 0.0, "avg_logprob": -0.14645557898979683, "compression_ratio": 1.5159574468085106, "no_speech_prob": 0.0060940939001739025}, {"id": 1337, "seek": 700984, "start": 7010.64, "end": 7016.0, "text": " us humans are actually irrational, inefficient, and get in the way of,", "tokens": [50404, 505, 6255, 366, 767, 39914, 11, 43495, 11, 293, 483, 294, 264, 636, 295, 11, 50672], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1338, "seek": 700984, "start": 7017.52, "end": 7023.6, "text": " of not happiness, but whatever the objective function is of maximizing that objective function.", "tokens": [50748, 295, 406, 8324, 11, 457, 2035, 264, 10024, 2445, 307, 295, 5138, 3319, 300, 10024, 2445, 13, 51052], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1339, "seek": 700984, "start": 7023.6, "end": 7024.88, "text": " Yeah. Yeah. Super intelligent.", "tokens": [51052, 865, 13, 865, 13, 4548, 13232, 13, 51116], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1340, "seek": 700984, "start": 7024.88, "end": 7026.4800000000005, "text": " There's a paperclip problem and things like that.", "tokens": [51116, 821, 311, 257, 3035, 21614, 1154, 293, 721, 411, 300, 13, 51196], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1341, "seek": 700984, "start": 7026.4800000000005, "end": 7029.360000000001, "text": " But so the paperclip problem, but with a super intelligent.", "tokens": [51196, 583, 370, 264, 3035, 21614, 1154, 11, 457, 365, 257, 1687, 13232, 13, 51340], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1342, "seek": 700984, "start": 7029.360000000001, "end": 7033.84, "text": " Yeah. Yeah. Yeah. So we already faced this threat in some sense.", "tokens": [51340, 865, 13, 865, 13, 865, 13, 407, 321, 1217, 11446, 341, 4734, 294, 512, 2020, 13, 51564], "temperature": 0.0, "avg_logprob": -0.21786648740050613, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.01223787758499384}, {"id": 1343, "seek": 703384, "start": 7034.4800000000005, "end": 7040.400000000001, "text": " They're called bacteria. These are organisms in the world that would like to turn everything into", "tokens": [50396, 814, 434, 1219, 11763, 13, 1981, 366, 22110, 294, 264, 1002, 300, 576, 411, 281, 1261, 1203, 666, 50692], "temperature": 0.0, "avg_logprob": -0.11025375886396928, "compression_ratio": 1.7660377358490567, "no_speech_prob": 0.003172023454681039}, {"id": 1344, "seek": 703384, "start": 7040.400000000001, "end": 7045.68, "text": " bacteria. And they're constantly morphing. They're constantly changing to evade our protections.", "tokens": [50692, 11763, 13, 400, 436, 434, 6460, 1896, 79, 571, 13, 814, 434, 6460, 4473, 281, 1073, 762, 527, 29031, 13, 50956], "temperature": 0.0, "avg_logprob": -0.11025375886396928, "compression_ratio": 1.7660377358490567, "no_speech_prob": 0.003172023454681039}, {"id": 1345, "seek": 703384, "start": 7046.32, "end": 7053.2, "text": " And in the past, they have killed huge swaths of populations of humans on this planet.", "tokens": [50988, 400, 294, 264, 1791, 11, 436, 362, 4652, 2603, 1693, 998, 82, 295, 12822, 295, 6255, 322, 341, 5054, 13, 51332], "temperature": 0.0, "avg_logprob": -0.11025375886396928, "compression_ratio": 1.7660377358490567, "no_speech_prob": 0.003172023454681039}, {"id": 1346, "seek": 703384, "start": 7053.2, "end": 7057.4400000000005, "text": " So if you want to worry about something that's going to multiply endlessly, we have it.", "tokens": [51332, 407, 498, 291, 528, 281, 3292, 466, 746, 300, 311, 516, 281, 12972, 44920, 11, 321, 362, 309, 13, 51544], "temperature": 0.0, "avg_logprob": -0.11025375886396928, "compression_ratio": 1.7660377358490567, "no_speech_prob": 0.003172023454681039}, {"id": 1347, "seek": 703384, "start": 7058.32, "end": 7063.2, "text": " And I'm far more worried in that regard, I'm far more worried that some scientists in a laboratory", "tokens": [51588, 400, 286, 478, 1400, 544, 5804, 294, 300, 3843, 11, 286, 478, 1400, 544, 5804, 300, 512, 7708, 294, 257, 16523, 51832], "temperature": 0.0, "avg_logprob": -0.11025375886396928, "compression_ratio": 1.7660377358490567, "no_speech_prob": 0.003172023454681039}, {"id": 1348, "seek": 706320, "start": 7063.2, "end": 7068.4, "text": " will create a super virus or a super bacteria that we cannot control. That is a more existential", "tokens": [50364, 486, 1884, 257, 1687, 5752, 420, 257, 1687, 11763, 300, 321, 2644, 1969, 13, 663, 307, 257, 544, 37133, 50624], "temperature": 0.0, "avg_logprob": -0.10768804794702774, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0008556446409784257}, {"id": 1349, "seek": 706320, "start": 7068.4, "end": 7073.84, "text": " threat. Putting an intelligence thing on top of it actually seems to make it less existential", "tokens": [50624, 4734, 13, 31367, 364, 7599, 551, 322, 1192, 295, 309, 767, 2544, 281, 652, 309, 1570, 37133, 50896], "temperature": 0.0, "avg_logprob": -0.10768804794702774, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0008556446409784257}, {"id": 1350, "seek": 706320, "start": 7073.84, "end": 7078.48, "text": " to me. It's like, it limits its power. It limits where it can go. It limits the number of things", "tokens": [50896, 281, 385, 13, 467, 311, 411, 11, 309, 10406, 1080, 1347, 13, 467, 10406, 689, 309, 393, 352, 13, 467, 10406, 264, 1230, 295, 721, 51128], "temperature": 0.0, "avg_logprob": -0.10768804794702774, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0008556446409784257}, {"id": 1351, "seek": 706320, "start": 7078.48, "end": 7083.92, "text": " it can do in many ways. A bacteria is something you can't even see. So that's only one of those", "tokens": [51128, 309, 393, 360, 294, 867, 2098, 13, 316, 11763, 307, 746, 291, 393, 380, 754, 536, 13, 407, 300, 311, 787, 472, 295, 729, 51400], "temperature": 0.0, "avg_logprob": -0.10768804794702774, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0008556446409784257}, {"id": 1352, "seek": 706320, "start": 7083.92, "end": 7089.679999999999, "text": " problems. Yes, exactly. So the other one, just in your intuition about intelligence, when you", "tokens": [51400, 2740, 13, 1079, 11, 2293, 13, 407, 264, 661, 472, 11, 445, 294, 428, 24002, 466, 7599, 11, 562, 291, 51688], "temperature": 0.0, "avg_logprob": -0.10768804794702774, "compression_ratio": 1.7536764705882353, "no_speech_prob": 0.0008556446409784257}, {"id": 1353, "seek": 708968, "start": 7089.68, "end": 7095.6, "text": " think about the intelligence of us humans, do you think of that as something, if you look at", "tokens": [50364, 519, 466, 264, 7599, 295, 505, 6255, 11, 360, 291, 519, 295, 300, 382, 746, 11, 498, 291, 574, 412, 50660], "temperature": 0.0, "avg_logprob": -0.11349465236190923, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0005526401801034808}, {"id": 1354, "seek": 708968, "start": 7095.6, "end": 7102.0, "text": " intelligence on a spectrum from zero to us humans, do you think you can scale that to something far", "tokens": [50660, 7599, 322, 257, 11143, 490, 4018, 281, 505, 6255, 11, 360, 291, 519, 291, 393, 4373, 300, 281, 746, 1400, 50980], "temperature": 0.0, "avg_logprob": -0.11349465236190923, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0005526401801034808}, {"id": 1355, "seek": 708968, "start": 7102.0, "end": 7105.280000000001, "text": " superior? Yeah, all the mechanisms we've been talking about. Let me, I want to make another", "tokens": [50980, 13028, 30, 865, 11, 439, 264, 15902, 321, 600, 668, 1417, 466, 13, 961, 385, 11, 286, 528, 281, 652, 1071, 51144], "temperature": 0.0, "avg_logprob": -0.11349465236190923, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0005526401801034808}, {"id": 1356, "seek": 708968, "start": 7105.280000000001, "end": 7111.4400000000005, "text": " point here, Alex, before I get there. Sure. Intelligence is the neocortex. It is not the", "tokens": [51144, 935, 510, 11, 5202, 11, 949, 286, 483, 456, 13, 4894, 13, 27274, 307, 264, 408, 905, 36143, 13, 467, 307, 406, 264, 51452], "temperature": 0.0, "avg_logprob": -0.11349465236190923, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0005526401801034808}, {"id": 1357, "seek": 708968, "start": 7111.4400000000005, "end": 7118.240000000001, "text": " entire brain. If I, the goal is not to make a human. The goal is not to make an emotional system.", "tokens": [51452, 2302, 3567, 13, 759, 286, 11, 264, 3387, 307, 406, 281, 652, 257, 1952, 13, 440, 3387, 307, 406, 281, 652, 364, 6863, 1185, 13, 51792], "temperature": 0.0, "avg_logprob": -0.11349465236190923, "compression_ratio": 1.8185328185328185, "no_speech_prob": 0.0005526401801034808}, {"id": 1358, "seek": 711824, "start": 7118.24, "end": 7122.639999999999, "text": " The goal is not to make a system that wants to have sex and reproduce. Why would I build that?", "tokens": [50364, 440, 3387, 307, 406, 281, 652, 257, 1185, 300, 2738, 281, 362, 3260, 293, 29501, 13, 1545, 576, 286, 1322, 300, 30, 50584], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1359, "seek": 711824, "start": 7122.639999999999, "end": 7125.84, "text": " If I want to have a system that wants to reproduce and have sex, make bacteria,", "tokens": [50584, 759, 286, 528, 281, 362, 257, 1185, 300, 2738, 281, 29501, 293, 362, 3260, 11, 652, 11763, 11, 50744], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1360, "seek": 711824, "start": 7125.84, "end": 7130.96, "text": " make computer viruses. Those are bad things. Don't do that. Those are really bad. Don't do", "tokens": [50744, 652, 3820, 21785, 13, 3950, 366, 1578, 721, 13, 1468, 380, 360, 300, 13, 3950, 366, 534, 1578, 13, 1468, 380, 360, 51000], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1361, "seek": 711824, "start": 7130.96, "end": 7136.88, "text": " those things. Regulate those. But if I just say I want an intelligent system, why doesn't have to", "tokens": [51000, 729, 721, 13, 4791, 5256, 729, 13, 583, 498, 286, 445, 584, 286, 528, 364, 13232, 1185, 11, 983, 1177, 380, 362, 281, 51296], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1362, "seek": 711824, "start": 7136.88, "end": 7141.5199999999995, "text": " have any of the human-like emotions? Why does it even care if it lives? Why does it even care", "tokens": [51296, 362, 604, 295, 264, 1952, 12, 4092, 8462, 30, 1545, 775, 309, 754, 1127, 498, 309, 2909, 30, 1545, 775, 309, 754, 1127, 51528], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1363, "seek": 711824, "start": 7141.5199999999995, "end": 7146.24, "text": " if it has food? It doesn't care about those things. It's just, you know, it's just in a trance", "tokens": [51528, 498, 309, 575, 1755, 30, 467, 1177, 380, 1127, 466, 729, 721, 13, 467, 311, 445, 11, 291, 458, 11, 309, 311, 445, 294, 257, 504, 719, 51764], "temperature": 0.0, "avg_logprob": -0.08018142264961396, "compression_ratio": 1.943661971830986, "no_speech_prob": 0.0007792857359163463}, {"id": 1364, "seek": 714624, "start": 7146.24, "end": 7151.599999999999, "text": " thinking about mathematics or it's out there just trying to build the space, you know, for it on", "tokens": [50364, 1953, 466, 18666, 420, 309, 311, 484, 456, 445, 1382, 281, 1322, 264, 1901, 11, 291, 458, 11, 337, 309, 322, 50632], "temperature": 0.0, "avg_logprob": -0.13168513488769532, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.006386073771864176}, {"id": 1365, "seek": 714624, "start": 7151.599999999999, "end": 7158.08, "text": " Mars. It's a, we, that's a choice we make. Don't make human-like things. Don't make replicating", "tokens": [50632, 9692, 13, 467, 311, 257, 11, 321, 11, 300, 311, 257, 3922, 321, 652, 13, 1468, 380, 652, 1952, 12, 4092, 721, 13, 1468, 380, 652, 3248, 30541, 50956], "temperature": 0.0, "avg_logprob": -0.13168513488769532, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.006386073771864176}, {"id": 1366, "seek": 714624, "start": 7158.08, "end": 7161.599999999999, "text": " things. Don't make things that have emotions. Just stick to the neocortex. So that's, that's a", "tokens": [50956, 721, 13, 1468, 380, 652, 721, 300, 362, 8462, 13, 1449, 2897, 281, 264, 408, 905, 36143, 13, 407, 300, 311, 11, 300, 311, 257, 51132], "temperature": 0.0, "avg_logprob": -0.13168513488769532, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.006386073771864176}, {"id": 1367, "seek": 714624, "start": 7161.599999999999, "end": 7166.48, "text": " view actually that I share, but not everybody shares in the sense that you have faith and", "tokens": [51132, 1910, 767, 300, 286, 2073, 11, 457, 406, 2201, 12182, 294, 264, 2020, 300, 291, 362, 4522, 293, 51376], "temperature": 0.0, "avg_logprob": -0.13168513488769532, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.006386073771864176}, {"id": 1368, "seek": 714624, "start": 7166.48, "end": 7173.5199999999995, "text": " optimism about us as engineers of systems, humans as builders of systems to, to, to not put in", "tokens": [51376, 31074, 466, 505, 382, 11955, 295, 3652, 11, 6255, 382, 36281, 295, 3652, 281, 11, 281, 11, 281, 406, 829, 294, 51728], "temperature": 0.0, "avg_logprob": -0.13168513488769532, "compression_ratio": 1.7744360902255638, "no_speech_prob": 0.006386073771864176}, {"id": 1369, "seek": 717352, "start": 7174.080000000001, "end": 7178.96, "text": " stupid, not stupid. So this is why, this is why I mentioned the bacteria one. Because you might", "tokens": [50392, 6631, 11, 406, 6631, 13, 407, 341, 307, 983, 11, 341, 307, 983, 286, 2835, 264, 11763, 472, 13, 1436, 291, 1062, 50636], "temperature": 0.0, "avg_logprob": -0.13906778827790292, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.002631155075505376}, {"id": 1370, "seek": 717352, "start": 7178.96, "end": 7183.280000000001, "text": " say, well, some person's going to do that. Well, some person today could create a bacteria that's", "tokens": [50636, 584, 11, 731, 11, 512, 954, 311, 516, 281, 360, 300, 13, 1042, 11, 512, 954, 965, 727, 1884, 257, 11763, 300, 311, 50852], "temperature": 0.0, "avg_logprob": -0.13906778827790292, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.002631155075505376}, {"id": 1371, "seek": 717352, "start": 7183.280000000001, "end": 7189.84, "text": " resistant to all the non-antibacterial agents. So we already have that threat. We already know", "tokens": [50852, 20383, 281, 439, 264, 2107, 12, 394, 897, 14125, 831, 12554, 13, 407, 321, 1217, 362, 300, 4734, 13, 492, 1217, 458, 51180], "temperature": 0.0, "avg_logprob": -0.13906778827790292, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.002631155075505376}, {"id": 1372, "seek": 717352, "start": 7189.84, "end": 7195.92, "text": " this is going on. It's not a new threat. So just accept that and then we have to deal with it,", "tokens": [51180, 341, 307, 516, 322, 13, 467, 311, 406, 257, 777, 4734, 13, 407, 445, 3241, 300, 293, 550, 321, 362, 281, 2028, 365, 309, 11, 51484], "temperature": 0.0, "avg_logprob": -0.13906778827790292, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.002631155075505376}, {"id": 1373, "seek": 717352, "start": 7195.92, "end": 7201.120000000001, "text": " right? Yeah. So my point is nothing to do with intelligence. It, intelligence is a separate", "tokens": [51484, 558, 30, 865, 13, 407, 452, 935, 307, 1825, 281, 360, 365, 7599, 13, 467, 11, 7599, 307, 257, 4994, 51744], "temperature": 0.0, "avg_logprob": -0.13906778827790292, "compression_ratio": 1.8129770992366412, "no_speech_prob": 0.002631155075505376}, {"id": 1374, "seek": 720112, "start": 7201.2, "end": 7205.2, "text": " component that you might apply to a system that wants to reproduce and do stupid things.", "tokens": [50368, 6542, 300, 291, 1062, 3079, 281, 257, 1185, 300, 2738, 281, 29501, 293, 360, 6631, 721, 13, 50568], "temperature": 0.0, "avg_logprob": -0.12468445956052004, "compression_ratio": 1.59375, "no_speech_prob": 0.002471642568707466}, {"id": 1375, "seek": 720112, "start": 7205.84, "end": 7209.599999999999, "text": " Let's not do that. Yeah. In fact, it is a mystery why people haven't done that yet.", "tokens": [50600, 961, 311, 406, 360, 300, 13, 865, 13, 682, 1186, 11, 309, 307, 257, 11422, 983, 561, 2378, 380, 1096, 300, 1939, 13, 50788], "temperature": 0.0, "avg_logprob": -0.12468445956052004, "compression_ratio": 1.59375, "no_speech_prob": 0.002471642568707466}, {"id": 1376, "seek": 720112, "start": 7210.4, "end": 7216.48, "text": " My, my dad as a physicist believes that the reason, for example, nuclear weapons haven't", "tokens": [50828, 1222, 11, 452, 3546, 382, 257, 42466, 12307, 300, 264, 1778, 11, 337, 1365, 11, 8179, 7278, 2378, 380, 51132], "temperature": 0.0, "avg_logprob": -0.12468445956052004, "compression_ratio": 1.59375, "no_speech_prob": 0.002471642568707466}, {"id": 1377, "seek": 720112, "start": 7217.12, "end": 7223.28, "text": " proliferated amongst evil people. So one, one belief that I share is that there's not that many", "tokens": [51164, 24398, 9361, 770, 12918, 6724, 561, 13, 407, 472, 11, 472, 7107, 300, 286, 2073, 307, 300, 456, 311, 406, 300, 867, 51472], "temperature": 0.0, "avg_logprob": -0.12468445956052004, "compression_ratio": 1.59375, "no_speech_prob": 0.002471642568707466}, {"id": 1378, "seek": 722328, "start": 7223.28, "end": 7230.4, "text": " evil people in the world that would, that, that would use back to whether it's bacteria,", "tokens": [50364, 6724, 561, 294, 264, 1002, 300, 576, 11, 300, 11, 300, 576, 764, 646, 281, 1968, 309, 311, 11763, 11, 50720], "temperature": 0.0, "avg_logprob": -0.13975288156877486, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.07259153574705124}, {"id": 1379, "seek": 722328, "start": 7230.4, "end": 7236.719999999999, "text": " nuclear weapons, or maybe the future AI systems to do bad. So the fraction is small. And the second", "tokens": [50720, 8179, 7278, 11, 420, 1310, 264, 2027, 7318, 3652, 281, 360, 1578, 13, 407, 264, 14135, 307, 1359, 13, 400, 264, 1150, 51036], "temperature": 0.0, "avg_logprob": -0.13975288156877486, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.07259153574705124}, {"id": 1380, "seek": 722328, "start": 7236.719999999999, "end": 7242.5599999999995, "text": " is that it's actually really hard, technically. So the, the intersection between evil and", "tokens": [51036, 307, 300, 309, 311, 767, 534, 1152, 11, 12120, 13, 407, 264, 11, 264, 15236, 1296, 6724, 293, 51328], "temperature": 0.0, "avg_logprob": -0.13975288156877486, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.07259153574705124}, {"id": 1381, "seek": 722328, "start": 7242.5599999999995, "end": 7247.599999999999, "text": " competent is small in terms. And by the way, to really annihilate humanity, you'd have to have,", "tokens": [51328, 29998, 307, 1359, 294, 2115, 13, 400, 538, 264, 636, 11, 281, 534, 40430, 48104, 10243, 11, 291, 1116, 362, 281, 362, 11, 51580], "temperature": 0.0, "avg_logprob": -0.13975288156877486, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.07259153574705124}, {"id": 1382, "seek": 722328, "start": 7248.24, "end": 7252.16, "text": " you know, sort of the, the nuclear winter phenomenon, which is not one person shooting,", "tokens": [51612, 291, 458, 11, 1333, 295, 264, 11, 264, 8179, 6355, 14029, 11, 597, 307, 406, 472, 954, 5942, 11, 51808], "temperature": 0.0, "avg_logprob": -0.13975288156877486, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.07259153574705124}, {"id": 1383, "seek": 725216, "start": 7252.16, "end": 7257.599999999999, "text": " you know, or even 10 bombs, you'd have to have some automated system that, you know, detonates", "tokens": [50364, 291, 458, 11, 420, 754, 1266, 19043, 11, 291, 1116, 362, 281, 362, 512, 18473, 1185, 300, 11, 291, 458, 11, 39920, 1024, 50636], "temperature": 0.0, "avg_logprob": -0.16579753062764152, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.001064780750311911}, {"id": 1384, "seek": 725216, "start": 7257.599999999999, "end": 7262.4, "text": " a million bombs or 10, whatever many thousands we have. So it's extreme evil combined with extreme", "tokens": [50636, 257, 2459, 19043, 420, 1266, 11, 2035, 867, 5383, 321, 362, 13, 407, 309, 311, 8084, 6724, 9354, 365, 8084, 50876], "temperature": 0.0, "avg_logprob": -0.16579753062764152, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.001064780750311911}, {"id": 1385, "seek": 725216, "start": 7262.4, "end": 7267.2, "text": " competence and just building some stupid system that would automatically, you know, Dr. Strangelup", "tokens": [50876, 39965, 293, 445, 2390, 512, 6631, 1185, 300, 576, 6772, 11, 291, 458, 11, 2491, 13, 8251, 14282, 1010, 51116], "temperature": 0.0, "avg_logprob": -0.16579753062764152, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.001064780750311911}, {"id": 1386, "seek": 725216, "start": 7267.2, "end": 7273.76, "text": " type of thing, you know, I mean, look, we could have some nuclear bomb go off in some major city", "tokens": [51116, 2010, 295, 551, 11, 291, 458, 11, 286, 914, 11, 574, 11, 321, 727, 362, 512, 8179, 7851, 352, 766, 294, 512, 2563, 2307, 51444], "temperature": 0.0, "avg_logprob": -0.16579753062764152, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.001064780750311911}, {"id": 1387, "seek": 725216, "start": 7273.76, "end": 7277.5199999999995, "text": " in the world. Like, I think that's actually quite likely even in my lifetime. I don't think that's", "tokens": [51444, 294, 264, 1002, 13, 1743, 11, 286, 519, 300, 311, 767, 1596, 3700, 754, 294, 452, 11364, 13, 286, 500, 380, 519, 300, 311, 51632], "temperature": 0.0, "avg_logprob": -0.16579753062764152, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.001064780750311911}, {"id": 1388, "seek": 727752, "start": 7277.68, "end": 7283.84, "text": " unlike the thing. And it'll be a tragedy. But it won't be an existential threat. And it's the same", "tokens": [50372, 8343, 264, 551, 13, 400, 309, 603, 312, 257, 18563, 13, 583, 309, 1582, 380, 312, 364, 37133, 4734, 13, 400, 309, 311, 264, 912, 50680], "temperature": 0.0, "avg_logprob": -0.16425746824683213, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007805597968399525}, {"id": 1389, "seek": 727752, "start": 7283.84, "end": 7291.6, "text": " as, you know, the virus of 1917, whenever it was, you know, the influenza, these bad things can happen", "tokens": [50680, 382, 11, 291, 458, 11, 264, 5752, 295, 42757, 11, 5699, 309, 390, 11, 291, 458, 11, 264, 36408, 11, 613, 1578, 721, 393, 1051, 51068], "temperature": 0.0, "avg_logprob": -0.16425746824683213, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007805597968399525}, {"id": 1390, "seek": 727752, "start": 7291.6, "end": 7296.96, "text": " and the plague and so on. We can't always prevent it. We always, to always try, but we can't. But", "tokens": [51068, 293, 264, 28185, 293, 370, 322, 13, 492, 393, 380, 1009, 4871, 309, 13, 492, 1009, 11, 281, 1009, 853, 11, 457, 321, 393, 380, 13, 583, 51336], "temperature": 0.0, "avg_logprob": -0.16425746824683213, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007805597968399525}, {"id": 1391, "seek": 727752, "start": 7296.96, "end": 7300.320000000001, "text": " they're not existential threats until we combine all those crazy things together.", "tokens": [51336, 436, 434, 406, 37133, 14909, 1826, 321, 10432, 439, 729, 3219, 721, 1214, 13, 51504], "temperature": 0.0, "avg_logprob": -0.16425746824683213, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007805597968399525}, {"id": 1392, "seek": 727752, "start": 7301.040000000001, "end": 7306.240000000001, "text": " So on the, on the spectrum of intelligence from zero to human, do you have a sense of", "tokens": [51540, 407, 322, 264, 11, 322, 264, 11143, 295, 7599, 490, 4018, 281, 1952, 11, 360, 291, 362, 257, 2020, 295, 51800], "temperature": 0.0, "avg_logprob": -0.16425746824683213, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.007805597968399525}, {"id": 1393, "seek": 730624, "start": 7306.96, "end": 7312.88, "text": " whether it's possible to create several orders of magnitude or at least double that", "tokens": [50400, 1968, 309, 311, 1944, 281, 1884, 2940, 9470, 295, 15668, 420, 412, 1935, 3834, 300, 50696], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1394, "seek": 730624, "start": 7313.5199999999995, "end": 7315.84, "text": " of human intelligence, talking about New York context?", "tokens": [50728, 295, 1952, 7599, 11, 1417, 466, 1873, 3609, 4319, 30, 50844], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1395, "seek": 730624, "start": 7315.84, "end": 7320.08, "text": " I think it's the wrong thing to say double the intelligence. Break it down into different", "tokens": [50844, 286, 519, 309, 311, 264, 2085, 551, 281, 584, 3834, 264, 7599, 13, 16925, 309, 760, 666, 819, 51056], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1396, "seek": 730624, "start": 7320.08, "end": 7324.88, "text": " components. Can I make something that's a million times faster than a human brain? Yes,", "tokens": [51056, 6677, 13, 1664, 286, 652, 746, 300, 311, 257, 2459, 1413, 4663, 813, 257, 1952, 3567, 30, 1079, 11, 51296], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1397, "seek": 730624, "start": 7324.88, "end": 7331.2, "text": " I can do that. Could I make something that is, has a lot more storage than human brain? Yes,", "tokens": [51296, 286, 393, 360, 300, 13, 7497, 286, 652, 746, 300, 307, 11, 575, 257, 688, 544, 6725, 813, 1952, 3567, 30, 1079, 11, 51612], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1398, "seek": 730624, "start": 7331.2, "end": 7334.719999999999, "text": " I could do that. More common, more copies come. Can I make something that attaches to", "tokens": [51612, 286, 727, 360, 300, 13, 5048, 2689, 11, 544, 14341, 808, 13, 1664, 286, 652, 746, 300, 49404, 281, 51788], "temperature": 0.0, "avg_logprob": -0.15401389235157079, "compression_ratio": 1.8401486988847584, "no_speech_prob": 0.00031010297243483365}, {"id": 1399, "seek": 733472, "start": 7334.8, "end": 7339.280000000001, "text": " different sensors than human brain? Yes, I can do that. Could I make something that's distributed?", "tokens": [50368, 819, 14840, 813, 1952, 3567, 30, 1079, 11, 286, 393, 360, 300, 13, 7497, 286, 652, 746, 300, 311, 12631, 30, 50592], "temperature": 0.0, "avg_logprob": -0.17985218290298705, "compression_ratio": 1.5945017182130585, "no_speech_prob": 0.000882952066604048}, {"id": 1400, "seek": 733472, "start": 7339.280000000001, "end": 7342.96, "text": " So these people, yeah, we talked earlier about the important New York Cortex voting,", "tokens": [50592, 407, 613, 561, 11, 1338, 11, 321, 2825, 3071, 466, 264, 1021, 1873, 3609, 28522, 3121, 10419, 11, 50776], "temperature": 0.0, "avg_logprob": -0.17985218290298705, "compression_ratio": 1.5945017182130585, "no_speech_prob": 0.000882952066604048}, {"id": 1401, "seek": 733472, "start": 7342.96, "end": 7346.16, "text": " they don't have to be co-located. Like, you know, they can be all around the places. I could do that,", "tokens": [50776, 436, 500, 380, 362, 281, 312, 598, 12, 5842, 770, 13, 1743, 11, 291, 458, 11, 436, 393, 312, 439, 926, 264, 3190, 13, 286, 727, 360, 300, 11, 50936], "temperature": 0.0, "avg_logprob": -0.17985218290298705, "compression_ratio": 1.5945017182130585, "no_speech_prob": 0.000882952066604048}, {"id": 1402, "seek": 733472, "start": 7346.16, "end": 7353.360000000001, "text": " too. Those are the levers I have, but is it more intelligent? What depends what I train", "tokens": [50936, 886, 13, 3950, 366, 264, 45571, 286, 362, 11, 457, 307, 309, 544, 13232, 30, 708, 5946, 437, 286, 3847, 51296], "temperature": 0.0, "avg_logprob": -0.17985218290298705, "compression_ratio": 1.5945017182130585, "no_speech_prob": 0.000882952066604048}, {"id": 1403, "seek": 733472, "start": 7353.360000000001, "end": 7359.360000000001, "text": " in on? What is it doing? Well, so here's the thing. So let's say larger in New York Cortex", "tokens": [51296, 294, 322, 30, 708, 307, 309, 884, 30, 1042, 11, 370, 510, 311, 264, 551, 13, 407, 718, 311, 584, 4833, 294, 1873, 3609, 28522, 3121, 51596], "temperature": 0.0, "avg_logprob": -0.17985218290298705, "compression_ratio": 1.5945017182130585, "no_speech_prob": 0.000882952066604048}, {"id": 1404, "seek": 735936, "start": 7359.36, "end": 7368.48, "text": " and or whatever size that allows for higher and higher hierarchies to form. We're talking about", "tokens": [50364, 293, 420, 2035, 2744, 300, 4045, 337, 2946, 293, 2946, 35250, 530, 281, 1254, 13, 492, 434, 1417, 466, 50820], "temperature": 0.0, "avg_logprob": -0.16921227773030598, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0005440187524072826}, {"id": 1405, "seek": 735936, "start": 7368.48, "end": 7371.92, "text": " reference frames and concepts. So I could, could I have something that's a super physicist or", "tokens": [50820, 6408, 12083, 293, 10392, 13, 407, 286, 727, 11, 727, 286, 362, 746, 300, 311, 257, 1687, 42466, 420, 50992], "temperature": 0.0, "avg_logprob": -0.16921227773030598, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0005440187524072826}, {"id": 1406, "seek": 735936, "start": 7371.92, "end": 7377.12, "text": " a super mathematician? Yes. And the question is, once you have a super physicist, will they be", "tokens": [50992, 257, 1687, 48281, 30, 1079, 13, 400, 264, 1168, 307, 11, 1564, 291, 362, 257, 1687, 42466, 11, 486, 436, 312, 51252], "temperature": 0.0, "avg_logprob": -0.16921227773030598, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0005440187524072826}, {"id": 1407, "seek": 735936, "start": 7377.12, "end": 7383.04, "text": " able to understand something? Do you have a sense that it will be orders like us compared to ants?", "tokens": [51252, 1075, 281, 1223, 746, 30, 1144, 291, 362, 257, 2020, 300, 309, 486, 312, 9470, 411, 505, 5347, 281, 23355, 30, 51548], "temperature": 0.0, "avg_logprob": -0.16921227773030598, "compression_ratio": 1.6437768240343347, "no_speech_prob": 0.0005440187524072826}, {"id": 1408, "seek": 738304, "start": 7383.04, "end": 7391.2, "text": " Could we ever understand it? Yeah. Most people cannot understand general relativity.", "tokens": [50364, 7497, 321, 1562, 1223, 309, 30, 865, 13, 4534, 561, 2644, 1223, 2674, 45675, 13, 50772], "temperature": 0.0, "avg_logprob": -0.16150833458028813, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.012051576748490334}, {"id": 1409, "seek": 738304, "start": 7391.84, "end": 7395.76, "text": " It's a really hard thing to get. I mean, you can paint it in a fuzzy picture,", "tokens": [50804, 467, 311, 257, 534, 1152, 551, 281, 483, 13, 286, 914, 11, 291, 393, 4225, 309, 294, 257, 34710, 3036, 11, 51000], "temperature": 0.0, "avg_logprob": -0.16150833458028813, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.012051576748490334}, {"id": 1410, "seek": 738304, "start": 7395.76, "end": 7401.28, "text": " stretchy space, you know? Yeah. But the field equations to do that in the deep intuitions", "tokens": [51000, 48865, 1901, 11, 291, 458, 30, 865, 13, 583, 264, 2519, 11787, 281, 360, 300, 294, 264, 2452, 16224, 626, 51276], "temperature": 0.0, "avg_logprob": -0.16150833458028813, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.012051576748490334}, {"id": 1411, "seek": 738304, "start": 7401.28, "end": 7407.5199999999995, "text": " are really, really hard. And I've tried, I'm unable to do it. Like, easy to get, you know,", "tokens": [51276, 366, 534, 11, 534, 1152, 13, 400, 286, 600, 3031, 11, 286, 478, 11299, 281, 360, 309, 13, 1743, 11, 1858, 281, 483, 11, 291, 458, 11, 51588], "temperature": 0.0, "avg_logprob": -0.16150833458028813, "compression_ratio": 1.5662100456621004, "no_speech_prob": 0.012051576748490334}, {"id": 1412, "seek": 740752, "start": 7407.52, "end": 7410.240000000001, "text": " it's easy to get special relative, but general relative, man, that's too much.", "tokens": [50364, 309, 311, 1858, 281, 483, 2121, 4972, 11, 457, 2674, 4972, 11, 587, 11, 300, 311, 886, 709, 13, 50500], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1413, "seek": 740752, "start": 7412.320000000001, "end": 7416.8, "text": " And so we already live with this to some extent. The vast majority of people can't understand", "tokens": [50604, 400, 370, 321, 1217, 1621, 365, 341, 281, 512, 8396, 13, 440, 8369, 6286, 295, 561, 393, 380, 1223, 50828], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1414, "seek": 740752, "start": 7416.8, "end": 7421.200000000001, "text": " actually what the vast majority of other people actually know. We're just either we don't have", "tokens": [50828, 767, 437, 264, 8369, 6286, 295, 661, 561, 767, 458, 13, 492, 434, 445, 2139, 321, 500, 380, 362, 51048], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1415, "seek": 740752, "start": 7421.200000000001, "end": 7425.6, "text": " the effort to or we can't or we don't have time or just not smart enough, whatever. So,", "tokens": [51048, 264, 4630, 281, 420, 321, 393, 380, 420, 321, 500, 380, 362, 565, 420, 445, 406, 4069, 1547, 11, 2035, 13, 407, 11, 51268], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1416, "seek": 740752, "start": 7426.8, "end": 7430.8, "text": " but we have ways of communicating. Einstein has spoken in a way that I can understand.", "tokens": [51328, 457, 321, 362, 2098, 295, 17559, 13, 23486, 575, 10759, 294, 257, 636, 300, 286, 393, 1223, 13, 51528], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1417, "seek": 740752, "start": 7431.52, "end": 7437.120000000001, "text": " He's given me analogies that are useful. I can use those analogies from my own work and think", "tokens": [51564, 634, 311, 2212, 385, 16660, 530, 300, 366, 4420, 13, 286, 393, 764, 729, 16660, 530, 490, 452, 1065, 589, 293, 519, 51844], "temperature": 0.0, "avg_logprob": -0.12000416997653335, "compression_ratio": 1.7807308970099667, "no_speech_prob": 0.0013667794410139322}, {"id": 1418, "seek": 743712, "start": 7437.12, "end": 7443.44, "text": " about, you know, concepts that are similar. It's not stupid. It's not like he's exist in some", "tokens": [50364, 466, 11, 291, 458, 11, 10392, 300, 366, 2531, 13, 467, 311, 406, 6631, 13, 467, 311, 406, 411, 415, 311, 2514, 294, 512, 50680], "temperature": 0.0, "avg_logprob": -0.14307268000831289, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0007909231353551149}, {"id": 1419, "seek": 743712, "start": 7443.44, "end": 7448.32, "text": " of the plane. There's no connection to my plane in the world here. So that will occur. It already", "tokens": [50680, 295, 264, 5720, 13, 821, 311, 572, 4984, 281, 452, 5720, 294, 264, 1002, 510, 13, 407, 300, 486, 5160, 13, 467, 1217, 50924], "temperature": 0.0, "avg_logprob": -0.14307268000831289, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0007909231353551149}, {"id": 1420, "seek": 743712, "start": 7448.32, "end": 7452.8, "text": " has occurred. That's my point that this story is it already has occurred. We live it every day.", "tokens": [50924, 575, 11068, 13, 663, 311, 452, 935, 300, 341, 1657, 307, 309, 1217, 575, 11068, 13, 492, 1621, 309, 633, 786, 13, 51148], "temperature": 0.0, "avg_logprob": -0.14307268000831289, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0007909231353551149}, {"id": 1421, "seek": 743712, "start": 7454.4, "end": 7458.32, "text": " One could argue that with we create machine intelligence that think a million times faster", "tokens": [51228, 1485, 727, 9695, 300, 365, 321, 1884, 3479, 7599, 300, 519, 257, 2459, 1413, 4663, 51424], "temperature": 0.0, "avg_logprob": -0.14307268000831289, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0007909231353551149}, {"id": 1422, "seek": 743712, "start": 7458.32, "end": 7462.24, "text": " than us that it'll be so far, we can't make the connections. But, you know, at the moment,", "tokens": [51424, 813, 505, 300, 309, 603, 312, 370, 1400, 11, 321, 393, 380, 652, 264, 9271, 13, 583, 11, 291, 458, 11, 412, 264, 1623, 11, 51620], "temperature": 0.0, "avg_logprob": -0.14307268000831289, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.0007909231353551149}, {"id": 1423, "seek": 746224, "start": 7463.2, "end": 7467.28, "text": " everything that seems really, really hard to figure out in the world when you actually figure", "tokens": [50412, 1203, 300, 2544, 534, 11, 534, 1152, 281, 2573, 484, 294, 264, 1002, 562, 291, 767, 2573, 50616], "temperature": 0.0, "avg_logprob": -0.20519108242458767, "compression_ratio": 2.0044444444444443, "no_speech_prob": 0.0018099724547937512}, {"id": 1424, "seek": 746224, "start": 7467.28, "end": 7472.32, "text": " it out is not that hard. You know, we can almost everyone can understand the multiverses. Almost", "tokens": [50616, 309, 484, 307, 406, 300, 1152, 13, 509, 458, 11, 321, 393, 1920, 1518, 393, 1223, 264, 2120, 1762, 279, 13, 12627, 50868], "temperature": 0.0, "avg_logprob": -0.20519108242458767, "compression_ratio": 2.0044444444444443, "no_speech_prob": 0.0018099724547937512}, {"id": 1425, "seek": 746224, "start": 7472.32, "end": 7475.92, "text": " everyone can understand quantum physics. Almost everyone can understand these basic things,", "tokens": [50868, 1518, 393, 1223, 13018, 10649, 13, 12627, 1518, 393, 1223, 613, 3875, 721, 11, 51048], "temperature": 0.0, "avg_logprob": -0.20519108242458767, "compression_ratio": 2.0044444444444443, "no_speech_prob": 0.0018099724547937512}, {"id": 1426, "seek": 746224, "start": 7475.92, "end": 7480.96, "text": " even though hardly any people could figure those things out. Yeah, but really understand. So,", "tokens": [51048, 754, 1673, 13572, 604, 561, 727, 2573, 729, 721, 484, 13, 865, 11, 457, 534, 1223, 13, 407, 11, 51300], "temperature": 0.0, "avg_logprob": -0.20519108242458767, "compression_ratio": 2.0044444444444443, "no_speech_prob": 0.0018099724547937512}, {"id": 1427, "seek": 746224, "start": 7482.16, "end": 7485.36, "text": " only a few people really don't understand. You need to only understand the", "tokens": [51360, 787, 257, 1326, 561, 534, 500, 380, 1223, 13, 509, 643, 281, 787, 1223, 264, 51520], "temperature": 0.0, "avg_logprob": -0.20519108242458767, "compression_ratio": 2.0044444444444443, "no_speech_prob": 0.0018099724547937512}, {"id": 1428, "seek": 748536, "start": 7486.32, "end": 7490.799999999999, "text": " the projections, the sprinkles of the useful insights from that. That was my example of", "tokens": [50412, 264, 32371, 11, 264, 6103, 23870, 295, 264, 4420, 14310, 490, 300, 13, 663, 390, 452, 1365, 295, 50636], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1429, "seek": 748536, "start": 7490.799999999999, "end": 7495.2, "text": " Einstein, right? His general theory of relativity is one thing that very, very, very few people", "tokens": [50636, 23486, 11, 558, 30, 2812, 2674, 5261, 295, 45675, 307, 472, 551, 300, 588, 11, 588, 11, 588, 1326, 561, 50856], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1430, "seek": 748536, "start": 7495.2, "end": 7499.679999999999, "text": " can get. And what if we just said those other few people are also artificial intelligences?", "tokens": [50856, 393, 483, 13, 400, 437, 498, 321, 445, 848, 729, 661, 1326, 561, 366, 611, 11677, 5613, 2667, 30, 51080], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1431, "seek": 748536, "start": 7500.48, "end": 7505.12, "text": " How bad is that? In some sense, they are, right? Yeah, they say already. I mean, Einstein wasn't", "tokens": [51120, 1012, 1578, 307, 300, 30, 682, 512, 2020, 11, 436, 366, 11, 558, 30, 865, 11, 436, 584, 1217, 13, 286, 914, 11, 23486, 2067, 380, 51352], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1432, "seek": 748536, "start": 7505.12, "end": 7509.36, "text": " a really normal person. He had a lot of weird quirks. And so the other people who work with him.", "tokens": [51352, 257, 534, 2710, 954, 13, 634, 632, 257, 688, 295, 3657, 35645, 1694, 13, 400, 370, 264, 661, 561, 567, 589, 365, 796, 13, 51564], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1433, "seek": 748536, "start": 7509.36, "end": 7513.44, "text": " So, you know, maybe they already were sort of this astral plane of intelligence that", "tokens": [51564, 407, 11, 291, 458, 11, 1310, 436, 1217, 645, 1333, 295, 341, 5357, 2155, 5720, 295, 7599, 300, 51768], "temperature": 0.0, "avg_logprob": -0.16326411679494296, "compression_ratio": 1.7098765432098766, "no_speech_prob": 0.006096218712627888}, {"id": 1434, "seek": 751344, "start": 7514.16, "end": 7519.12, "text": " we live with it already. It's not a problem. It's still useful and, you know.", "tokens": [50400, 321, 1621, 365, 309, 1217, 13, 467, 311, 406, 257, 1154, 13, 467, 311, 920, 4420, 293, 11, 291, 458, 13, 50648], "temperature": 0.0, "avg_logprob": -0.08602394247954746, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.00010888691758736968}, {"id": 1435, "seek": 751344, "start": 7520.08, "end": 7524.0, "text": " So, do you think we are the only intelligent life out there in the universe?", "tokens": [50696, 407, 11, 360, 291, 519, 321, 366, 264, 787, 13232, 993, 484, 456, 294, 264, 6445, 30, 50892], "temperature": 0.0, "avg_logprob": -0.08602394247954746, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.00010888691758736968}, {"id": 1436, "seek": 751344, "start": 7524.799999999999, "end": 7530.24, "text": " I would say that intelligent life has and will exist elsewhere in the universe. I'll say that.", "tokens": [50932, 286, 576, 584, 300, 13232, 993, 575, 293, 486, 2514, 14517, 294, 264, 6445, 13, 286, 603, 584, 300, 13, 51204], "temperature": 0.0, "avg_logprob": -0.08602394247954746, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.00010888691758736968}, {"id": 1437, "seek": 751344, "start": 7531.36, "end": 7535.44, "text": " There is a question about contemporaneous intelligence life, which is hard to even answer", "tokens": [51260, 821, 307, 257, 1168, 466, 13046, 15447, 7599, 993, 11, 597, 307, 1152, 281, 754, 1867, 51464], "temperature": 0.0, "avg_logprob": -0.08602394247954746, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.00010888691758736968}, {"id": 1438, "seek": 751344, "start": 7535.44, "end": 7540.719999999999, "text": " when we think about relativity and the nature of space time. We can't say what exactly is this", "tokens": [51464, 562, 321, 519, 466, 45675, 293, 264, 3687, 295, 1901, 565, 13, 492, 393, 380, 584, 437, 2293, 307, 341, 51728], "temperature": 0.0, "avg_logprob": -0.08602394247954746, "compression_ratio": 1.715415019762846, "no_speech_prob": 0.00010888691758736968}, {"id": 1439, "seek": 754072, "start": 7540.72, "end": 7548.0, "text": " time someplace else in the world. But I think it's, you know, I do worry a lot about the filter", "tokens": [50364, 565, 37126, 1646, 294, 264, 1002, 13, 583, 286, 519, 309, 311, 11, 291, 458, 11, 286, 360, 3292, 257, 688, 466, 264, 6608, 50728], "temperature": 0.0, "avg_logprob": -0.09893626396102134, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0009695634362287819}, {"id": 1440, "seek": 754072, "start": 7548.0, "end": 7555.12, "text": " idea, which is that perhaps intelligent species don't last very long. And so we haven't been around", "tokens": [50728, 1558, 11, 597, 307, 300, 4317, 13232, 6172, 500, 380, 1036, 588, 938, 13, 400, 370, 321, 2378, 380, 668, 926, 51084], "temperature": 0.0, "avg_logprob": -0.09893626396102134, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0009695634362287819}, {"id": 1441, "seek": 754072, "start": 7555.12, "end": 7559.76, "text": " very long. And as a technological species, we've been around for almost nothing, right? You know,", "tokens": [51084, 588, 938, 13, 400, 382, 257, 18439, 6172, 11, 321, 600, 668, 926, 337, 1920, 1825, 11, 558, 30, 509, 458, 11, 51316], "temperature": 0.0, "avg_logprob": -0.09893626396102134, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0009695634362287819}, {"id": 1442, "seek": 754072, "start": 7559.76, "end": 7565.360000000001, "text": " what 200 years or something like that. And we don't have any data, a good data point on whether", "tokens": [51316, 437, 2331, 924, 420, 746, 411, 300, 13, 400, 321, 500, 380, 362, 604, 1412, 11, 257, 665, 1412, 935, 322, 1968, 51596], "temperature": 0.0, "avg_logprob": -0.09893626396102134, "compression_ratio": 1.6276150627615062, "no_speech_prob": 0.0009695634362287819}, {"id": 1443, "seek": 756536, "start": 7565.36, "end": 7570.639999999999, "text": " it's likely that we'll survive or not. So, do I think that there have been intelligent", "tokens": [50364, 309, 311, 3700, 300, 321, 603, 7867, 420, 406, 13, 407, 11, 360, 286, 519, 300, 456, 362, 668, 13232, 50628], "temperature": 0.0, "avg_logprob": -0.09493255615234375, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.004131969530135393}, {"id": 1444, "seek": 756536, "start": 7570.639999999999, "end": 7574.88, "text": " life elsewhere in the universe? Almost certainly, of course. In the past and the future, yes.", "tokens": [50628, 993, 14517, 294, 264, 6445, 30, 12627, 3297, 11, 295, 1164, 13, 682, 264, 1791, 293, 264, 2027, 11, 2086, 13, 50840], "temperature": 0.0, "avg_logprob": -0.09493255615234375, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.004131969530135393}, {"id": 1445, "seek": 756536, "start": 7576.32, "end": 7581.04, "text": " Does it survive for a long time? I don't know. This is another reason I'm excited about our work,", "tokens": [50912, 4402, 309, 7867, 337, 257, 938, 565, 30, 286, 500, 380, 458, 13, 639, 307, 1071, 1778, 286, 478, 2919, 466, 527, 589, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09493255615234375, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.004131969530135393}, {"id": 1446, "seek": 756536, "start": 7581.04, "end": 7587.12, "text": " is our work meaning the general world of AI. I think we can build intelligent machines", "tokens": [51148, 307, 527, 589, 3620, 264, 2674, 1002, 295, 7318, 13, 286, 519, 321, 393, 1322, 13232, 8379, 51452], "temperature": 0.0, "avg_logprob": -0.09493255615234375, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.004131969530135393}, {"id": 1447, "seek": 756536, "start": 7588.639999999999, "end": 7595.04, "text": " that outlast us. And, you know, they don't have to be tied to earth. They don't have to,", "tokens": [51528, 300, 484, 15459, 505, 13, 400, 11, 291, 458, 11, 436, 500, 380, 362, 281, 312, 9601, 281, 4120, 13, 814, 500, 380, 362, 281, 11, 51848], "temperature": 0.0, "avg_logprob": -0.09493255615234375, "compression_ratio": 1.6814814814814816, "no_speech_prob": 0.004131969530135393}, {"id": 1448, "seek": 759504, "start": 7595.04, "end": 7599.6, "text": " you know, I'm not saying they're recreating, you know, you know, aliens. I'm just saying", "tokens": [50364, 291, 458, 11, 286, 478, 406, 1566, 436, 434, 850, 44613, 11, 291, 458, 11, 291, 458, 11, 21594, 13, 286, 478, 445, 1566, 50592], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1449, "seek": 759504, "start": 7600.8, "end": 7604.96, "text": " if I asked myself, and this might be a good point to end on here. If I asked myself, you know,", "tokens": [50652, 498, 286, 2351, 2059, 11, 293, 341, 1062, 312, 257, 665, 935, 281, 917, 322, 510, 13, 759, 286, 2351, 2059, 11, 291, 458, 11, 50860], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1450, "seek": 759504, "start": 7604.96, "end": 7609.76, "text": " what's special about our species? We're not particularly interesting physically. We're not,", "tokens": [50860, 437, 311, 2121, 466, 527, 6172, 30, 492, 434, 406, 4098, 1880, 9762, 13, 492, 434, 406, 11, 51100], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1451, "seek": 759504, "start": 7609.76, "end": 7613.84, "text": " we don't fly. We're not good swimmers. We're not very fast. We're not very strong, you know.", "tokens": [51100, 321, 500, 380, 3603, 13, 492, 434, 406, 665, 1693, 43107, 13, 492, 434, 406, 588, 2370, 13, 492, 434, 406, 588, 2068, 11, 291, 458, 13, 51304], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1452, "seek": 759504, "start": 7613.84, "end": 7617.76, "text": " It's our brain. That's the only thing. And we are the only species on this planet that's built", "tokens": [51304, 467, 311, 527, 3567, 13, 663, 311, 264, 787, 551, 13, 400, 321, 366, 264, 787, 6172, 322, 341, 5054, 300, 311, 3094, 51500], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1453, "seek": 759504, "start": 7617.76, "end": 7622.32, "text": " the model of the world that extends beyond what we can actually sense. We're the only people who", "tokens": [51500, 264, 2316, 295, 264, 1002, 300, 26448, 4399, 437, 321, 393, 767, 2020, 13, 492, 434, 264, 787, 561, 567, 51728], "temperature": 0.0, "avg_logprob": -0.09447301144631493, "compression_ratio": 1.9112627986348123, "no_speech_prob": 0.00024524808395653963}, {"id": 1454, "seek": 762232, "start": 7622.32, "end": 7627.28, "text": " know about the far side of the moon and the other universes and other galaxies and other stars and", "tokens": [50364, 458, 466, 264, 1400, 1252, 295, 264, 7135, 293, 264, 661, 50168, 293, 661, 28755, 293, 661, 6105, 293, 50612], "temperature": 0.0, "avg_logprob": -0.12674245452880858, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.001115629798732698}, {"id": 1455, "seek": 762232, "start": 7628.4, "end": 7633.2, "text": " what happens in the atom. That knowledge doesn't exist anywhere else. It's only in our heads.", "tokens": [50668, 437, 2314, 294, 264, 12018, 13, 663, 3601, 1177, 380, 2514, 4992, 1646, 13, 467, 311, 787, 294, 527, 8050, 13, 50908], "temperature": 0.0, "avg_logprob": -0.12674245452880858, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.001115629798732698}, {"id": 1456, "seek": 762232, "start": 7633.759999999999, "end": 7638.24, "text": " Cats don't do it. Dogs don't do it. Monkeys don't do it. That is what we've created that's unique.", "tokens": [50936, 40902, 500, 380, 360, 309, 13, 35504, 500, 380, 360, 309, 13, 4713, 18847, 500, 380, 360, 309, 13, 663, 307, 437, 321, 600, 2942, 300, 311, 3845, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12674245452880858, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.001115629798732698}, {"id": 1457, "seek": 762232, "start": 7638.24, "end": 7644.4, "text": " Not our genes. It's knowledge. And if I ask me, what is the legacy of humanity? What should our", "tokens": [51160, 1726, 527, 14424, 13, 467, 311, 3601, 13, 400, 498, 286, 1029, 385, 11, 437, 307, 264, 11711, 295, 10243, 30, 708, 820, 527, 51468], "temperature": 0.0, "avg_logprob": -0.12674245452880858, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.001115629798732698}, {"id": 1458, "seek": 762232, "start": 7644.4, "end": 7648.88, "text": " legacy be? It should be knowledge. We should preserve our knowledge in a way that it can exist", "tokens": [51468, 11711, 312, 30, 467, 820, 312, 3601, 13, 492, 820, 15665, 527, 3601, 294, 257, 636, 300, 309, 393, 2514, 51692], "temperature": 0.0, "avg_logprob": -0.12674245452880858, "compression_ratio": 1.8052434456928839, "no_speech_prob": 0.001115629798732698}, {"id": 1459, "seek": 764888, "start": 7648.88, "end": 7653.68, "text": " beyond us. And I think the best way of doing that, in fact, you have to do it, is that it has to go", "tokens": [50364, 4399, 505, 13, 400, 286, 519, 264, 1151, 636, 295, 884, 300, 11, 294, 1186, 11, 291, 362, 281, 360, 309, 11, 307, 300, 309, 575, 281, 352, 50604], "temperature": 0.0, "avg_logprob": -0.10722777717991878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002510520862415433}, {"id": 1460, "seek": 764888, "start": 7653.68, "end": 7659.2, "text": " along with intelligent machines to understand that knowledge. That's a very broad idea,", "tokens": [50604, 2051, 365, 13232, 8379, 281, 1223, 300, 3601, 13, 663, 311, 257, 588, 4152, 1558, 11, 50880], "temperature": 0.0, "avg_logprob": -0.10722777717991878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002510520862415433}, {"id": 1461, "seek": 764888, "start": 7659.84, "end": 7664.32, "text": " but we should be thinking, I call it a state planning for humanity. We should be thinking", "tokens": [50912, 457, 321, 820, 312, 1953, 11, 286, 818, 309, 257, 1785, 5038, 337, 10243, 13, 492, 820, 312, 1953, 51136], "temperature": 0.0, "avg_logprob": -0.10722777717991878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002510520862415433}, {"id": 1462, "seek": 764888, "start": 7664.32, "end": 7669.76, "text": " about what we want to leave behind when as a species we're no longer here. And that'll happen", "tokens": [51136, 466, 437, 321, 528, 281, 1856, 2261, 562, 382, 257, 6172, 321, 434, 572, 2854, 510, 13, 400, 300, 603, 1051, 51408], "temperature": 0.0, "avg_logprob": -0.10722777717991878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002510520862415433}, {"id": 1463, "seek": 764888, "start": 7669.76, "end": 7674.400000000001, "text": " sometime. Sooner or later, it's going to happen. And understanding intelligence and creating", "tokens": [51408, 15053, 13, 17610, 260, 420, 1780, 11, 309, 311, 516, 281, 1051, 13, 400, 3701, 7599, 293, 4084, 51640], "temperature": 0.0, "avg_logprob": -0.10722777717991878, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.002510520862415433}, {"id": 1464, "seek": 767440, "start": 7674.4, "end": 7679.839999999999, "text": " intelligence gives us a better chance to prolong. It does give us a better chance to prolong life,", "tokens": [50364, 7599, 2709, 505, 257, 1101, 2931, 281, 27224, 13, 467, 775, 976, 505, 257, 1101, 2931, 281, 27224, 993, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1352442146366478, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0015975702553987503}, {"id": 1465, "seek": 767440, "start": 7680.4, "end": 7685.36, "text": " yes. It gives us a chance to live on other planets. But even beyond that, I mean, our", "tokens": [50664, 2086, 13, 467, 2709, 505, 257, 2931, 281, 1621, 322, 661, 15126, 13, 583, 754, 4399, 300, 11, 286, 914, 11, 527, 50912], "temperature": 0.0, "avg_logprob": -0.1352442146366478, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0015975702553987503}, {"id": 1466, "seek": 767440, "start": 7685.36, "end": 7690.5599999999995, "text": " solar system will disappear one day. It's given enough time. So I don't know. I doubt we will", "tokens": [50912, 7936, 1185, 486, 11596, 472, 786, 13, 467, 311, 2212, 1547, 565, 13, 407, 286, 500, 380, 458, 13, 286, 6385, 321, 486, 51172], "temperature": 0.0, "avg_logprob": -0.1352442146366478, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0015975702553987503}, {"id": 1467, "seek": 767440, "start": 7690.5599999999995, "end": 7696.32, "text": " ever be able to travel to other things, but we could tell the stars, but we could send intelligent", "tokens": [51172, 1562, 312, 1075, 281, 3147, 281, 661, 721, 11, 457, 321, 727, 980, 264, 6105, 11, 457, 321, 727, 2845, 13232, 51460], "temperature": 0.0, "avg_logprob": -0.1352442146366478, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0015975702553987503}, {"id": 1468, "seek": 767440, "start": 7696.32, "end": 7704.32, "text": " machines to do that. So you have an optimistic, a hopeful view of our knowledge of the", "tokens": [51460, 8379, 281, 360, 300, 13, 407, 291, 362, 364, 19397, 11, 257, 20531, 1910, 295, 527, 3601, 295, 264, 51860], "temperature": 0.0, "avg_logprob": -0.1352442146366478, "compression_ratio": 1.7709923664122138, "no_speech_prob": 0.0015975702553987503}, {"id": 1469, "seek": 770432, "start": 7704.32, "end": 7709.12, "text": " echoes of human civilization living through the intelligent systems we create.", "tokens": [50364, 47051, 295, 1952, 18036, 2647, 807, 264, 13232, 3652, 321, 1884, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1470, "seek": 770432, "start": 7709.12, "end": 7712.16, "text": " Oh, totally. Well, I think the intelligent systems are greater in some sense, the", "tokens": [50604, 876, 11, 3879, 13, 1042, 11, 286, 519, 264, 13232, 3652, 366, 5044, 294, 512, 2020, 11, 264, 50756], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1471, "seek": 770432, "start": 7712.719999999999, "end": 7718.48, "text": " vessel for bringing them beyond Earth or making them last beyond humans themselves.", "tokens": [50784, 18098, 337, 5062, 552, 4399, 4755, 420, 1455, 552, 1036, 4399, 6255, 2969, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1472, "seek": 770432, "start": 7719.04, "end": 7723.599999999999, "text": " So... And how do you feel about that? That they won't be human, quote unquote.", "tokens": [51100, 407, 485, 400, 577, 360, 291, 841, 466, 300, 30, 663, 436, 1582, 380, 312, 1952, 11, 6513, 37557, 13, 51328], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1473, "seek": 770432, "start": 7723.599999999999, "end": 7727.92, "text": " Okay, it's not. But human, what is human? Our species are changing all the time.", "tokens": [51328, 1033, 11, 309, 311, 406, 13, 583, 1952, 11, 437, 307, 1952, 30, 2621, 6172, 366, 4473, 439, 264, 565, 13, 51544], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1474, "seek": 770432, "start": 7728.5599999999995, "end": 7733.84, "text": " Human today is not the same as human just 50 years ago. It's, what is human? Do we care about", "tokens": [51576, 10294, 965, 307, 406, 264, 912, 382, 1952, 445, 2625, 924, 2057, 13, 467, 311, 11, 437, 307, 1952, 30, 1144, 321, 1127, 466, 51840], "temperature": 0.0, "avg_logprob": -0.1730963078940787, "compression_ratio": 1.717241379310345, "no_speech_prob": 0.00037381413858383894}, {"id": 1475, "seek": 773384, "start": 7733.84, "end": 7738.32, "text": " our genetics? Why is that important? As I point out, our genetics are no more interesting than", "tokens": [50364, 527, 26516, 30, 1545, 307, 300, 1021, 30, 1018, 286, 935, 484, 11, 527, 26516, 366, 572, 544, 1880, 813, 50588], "temperature": 0.0, "avg_logprob": -0.14178703177688468, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.0006768847233615816}, {"id": 1476, "seek": 773384, "start": 7738.32, "end": 7742.88, "text": " a bacterium's genetics. It's no more interesting than a monkey's genetics. What we have, what's", "tokens": [50588, 257, 9755, 2197, 311, 26516, 13, 467, 311, 572, 544, 1880, 813, 257, 17847, 311, 26516, 13, 708, 321, 362, 11, 437, 311, 50816], "temperature": 0.0, "avg_logprob": -0.14178703177688468, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.0006768847233615816}, {"id": 1477, "seek": 773384, "start": 7742.88, "end": 7748.64, "text": " unique and what's valuable is our knowledge, what we've learned about the world. And that", "tokens": [50816, 3845, 293, 437, 311, 8263, 307, 527, 3601, 11, 437, 321, 600, 3264, 466, 264, 1002, 13, 400, 300, 51104], "temperature": 0.0, "avg_logprob": -0.14178703177688468, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.0006768847233615816}, {"id": 1478, "seek": 773384, "start": 7748.64, "end": 7753.28, "text": " is the rare thing. That's the thing we want to preserve. We care about our genes.", "tokens": [51104, 307, 264, 5892, 551, 13, 663, 311, 264, 551, 321, 528, 281, 15665, 13, 492, 1127, 466, 527, 14424, 13, 51336], "temperature": 0.0, "avg_logprob": -0.14178703177688468, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.0006768847233615816}, {"id": 1479, "seek": 773384, "start": 7755.360000000001, "end": 7759.52, "text": " It's the knowledge. It's the knowledge. That's a really good place to end. Thank you so much", "tokens": [51440, 467, 311, 264, 3601, 13, 467, 311, 264, 3601, 13, 663, 311, 257, 534, 665, 1081, 281, 917, 13, 1044, 291, 370, 709, 51648], "temperature": 0.0, "avg_logprob": -0.14178703177688468, "compression_ratio": 1.8801652892561984, "no_speech_prob": 0.0006768847233615816}, {"id": 1480, "seek": 775952, "start": 7759.52, "end": 7761.52, "text": " for talking to me. Oh, it was fun.", "tokens": [50364, 337, 1417, 281, 385, 13, 876, 11, 309, 390, 1019, 13, 50464], "temperature": 0.0, "avg_logprob": -0.4301035063607352, "compression_ratio": 0.8095238095238095, "no_speech_prob": 0.4547635614871979}], "language": "en"}