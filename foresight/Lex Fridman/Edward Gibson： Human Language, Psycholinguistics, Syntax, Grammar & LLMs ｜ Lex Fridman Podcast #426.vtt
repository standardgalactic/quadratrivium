WEBVTT

00:00.000 --> 00:05.840
Naively, I certainly thought that all humans would have words for exact counting.

00:06.960 --> 00:12.480
And the Piroha don't, okay? So they don't have any words for even one. There's not a word for

00:12.480 --> 00:17.120
one in their language. And so there's certainly not a word for two, three, or four. So that kind

00:17.120 --> 00:21.760
of blows people's minds off. Yeah, that's blowing my mind. That's pretty weird. How are you going to

00:21.760 --> 00:27.280
ask? I want two of those. You just don't. And so that's just not a thing you can possibly ask in

00:27.280 --> 00:29.840
the Piroha. It's not possible. That is, there's no words for that.

00:32.160 --> 00:38.240
The following is a conversation with Edward Gibson, or Ted, as everybody calls him. He is a

00:38.240 --> 00:44.560
Psycho-Linguistics Professor at MIT. He heads the MIT Language Lab that investigates why human

00:44.560 --> 00:51.120
languages look the way they do, the relationship between cultural language and how people represent,

00:51.120 --> 00:57.680
process, and learn language. Also, he should have a book titled Syntax, A Cognitive Approach,

00:58.240 --> 01:04.800
published by MIT Press, coming out this fall. So look out for that. This is the Lex Freeman

01:04.800 --> 01:10.480
podcast. To support it, please check out our sponsors in the description. And now, dear friends,

01:10.480 --> 01:16.720
here's Edward Gibson. When did you first become fascinated with human language?

01:17.360 --> 01:24.640
As a kid in school, when we had to structure sentences and English grammar, I found that

01:24.640 --> 01:30.640
process interesting. I found it confusing as to what it was I was told to do. I didn't

01:30.640 --> 01:34.720
understand what the theory was behind it, but I found it very interesting.

01:34.720 --> 01:37.520
So when you look at grammar, you're almost thinking about like a puzzle,

01:37.520 --> 01:41.200
like almost like a mathematical puzzle? Yeah, I think that's right. I didn't know I was going

01:41.200 --> 01:46.320
to work on this at all at that point. I was really just, I was kind of a math geek person.

01:46.400 --> 01:49.280
Computer scientist. I really liked computer science. And then I found

01:50.000 --> 01:56.640
language as a neat puzzle to work on from an engineering perspective. Actually, that's what

01:56.640 --> 02:03.600
I, as a, I sort of accidentally, I decided after I finished my undergraduate degree,

02:03.600 --> 02:08.720
which was computer science and math and Canada and Queens University, I decided to go to grad

02:08.720 --> 02:15.040
school. That's what I always thought I would do. And I went to Cambridge, where they had a master's

02:15.040 --> 02:21.120
in a master's program in computational linguistics. And I hadn't taken a single language class

02:21.120 --> 02:26.640
before. All I'd taken was CS, computer science, math classes, pretty much mostly as an undergrad.

02:26.640 --> 02:29.520
And I just thought, oh, this was an interesting thing to do for a year,

02:30.240 --> 02:35.760
because it was a single year program. And then I ended up spending my whole life doing it.

02:35.760 --> 02:40.800
So fundamentally, your journey through life was one of a mathematician and computer scientists.

02:40.800 --> 02:46.480
And then you kind of discovered the puzzle, the problem of language, and approached it

02:46.480 --> 02:52.240
from that angle, to try to understand it from that angle, almost like a mathematician or maybe

02:52.240 --> 02:58.400
even an engineer. As an engineer, I'd say, I mean, to be frank, I had taken an AI class,

02:58.400 --> 03:03.200
I guess it was 83 or 85, somewhere 84 in there a long time ago. And there was a natural language

03:03.200 --> 03:08.800
section in there. And it didn't impress me. I thought there must be more interesting things

03:08.800 --> 03:16.160
we can do. It didn't seem very, it seemed just a bunch of hacks to me. It didn't seem like a real

03:16.160 --> 03:23.200
theory of things in any way. And so this seemed like an interesting area where there wasn't enough

03:23.200 --> 03:28.560
good work. Did you ever come across like the philosophy angle of logic? So if you think about

03:28.560 --> 03:36.400
the 80s with AI, the expert systems where you try to kind of maybe sidestep the poetry of language

03:36.400 --> 03:41.120
and some of the syntax and the grammar and all that kind of stuff and go to the underlying

03:41.120 --> 03:46.720
meaning that language is trying to communicate and try to somehow compress that in a computer

03:46.720 --> 03:51.840
representable way. Do you ever come across that in your studies? I mean, I probably did, but I

03:51.840 --> 03:56.720
wasn't as interested in it. I was trying to do the easier problems first than ones I could

03:57.280 --> 04:03.120
thought maybe were handleable, which seems like the syntax is easier, which is just the forms as

04:03.120 --> 04:06.560
opposed to the meaning. When you're starting talking about the meaning, that's a very hard

04:06.560 --> 04:11.840
problem. And it still is a really, really hard problem. But the forms is easier. And so I thought

04:11.840 --> 04:18.240
at least figuring out the forms of human language, which sounds really hard, but is actually maybe

04:18.240 --> 04:23.680
more tractable. So it's interesting. You think there is a big divide, there's a gap,

04:23.680 --> 04:29.440
there's a distance between form and meaning. Because that's a question you have discussed a

04:29.440 --> 04:34.960
lot with LLMs, because they're damn good at form. Yeah, I think it's what they're good at,

04:34.960 --> 04:38.720
is form. And that's why they're good, because they can do form, meaning's hard.

04:39.680 --> 04:44.160
Do you think they're, oh, wow. I mean, it's an open question, right? How close form and meaning

04:44.160 --> 04:49.600
are? We'll discuss it. But to me, studying form, maybe some romantic notion,

04:50.880 --> 04:58.080
gives you form is like the shadow of the bigger meaning thing underline language.

04:58.160 --> 05:05.360
Language is how we communicate ideas. We communicate with each other using language.

05:05.360 --> 05:10.720
So in understanding the structure of that communication, I think you start to understand

05:10.720 --> 05:15.920
the structure of thought and the structure of meaning behind those thoughts and communication

05:15.920 --> 05:22.880
to me. But to you, big gap. What do you find most beautiful about human language,

05:22.880 --> 05:27.760
maybe the form of human language, the expression of human language?

05:27.760 --> 05:34.400
What I find beautiful about human language is some of the generalizations that happen

05:34.400 --> 05:39.120
across the human language, just within and across a language. So let me give you an example of

05:39.120 --> 05:47.040
something which I find kind of remarkable, that is if a language, if it has a word order,

05:47.040 --> 05:51.200
such that the verbs tend to come before their objects. And so that's like English does that.

05:51.200 --> 05:57.440
So we have the subject comes first in a simple sentence. So I say, you know, the

05:58.480 --> 06:03.680
dog chased the cat or Mary kicked the ball. So the subject first, and then after the subject,

06:03.680 --> 06:09.040
there's the verb. And then we have objects. All these things come after in English. So it's generally

06:09.040 --> 06:13.760
a verb. And most of the stuff that we want to say comes after the subject. It's the objects.

06:13.760 --> 06:17.600
There's a lot of things we want to say they come after. And there's a lot of languages like that.

06:17.600 --> 06:24.000
About 40% of the languages of the world look like that. They're subject verb object languages.

06:24.000 --> 06:32.640
And then these languages tend to have prepositions, these little markers on the nouns

06:32.640 --> 06:38.720
that connect nouns to other nouns or nouns to verb. So when I say a verb, I say preposition

06:38.720 --> 06:44.720
like in or on or of or about, I say, I talk about something. The something is the object

06:44.800 --> 06:49.120
of that preposition that we have these little markers come also just like verbs,

06:49.120 --> 06:53.920
they come before their their nouns. Okay. And then so now we look at other languages

06:53.920 --> 07:00.080
that like Japanese or or Hindi or some, these are these are so called verb final languages.

07:00.080 --> 07:06.000
Those is about maybe a little more than 40%, maybe 45% of the world's languages are more,

07:06.000 --> 07:12.080
I mean, 50% of the world's languages are verb final. Those tend to be post positions,

07:12.080 --> 07:15.280
those markers, the same if you have the states have the same kinds of markers,

07:16.080 --> 07:22.080
as we do in English, but they put them after. So sorry, they put them first, the markers come

07:22.080 --> 07:29.600
first. So you say instead of, you know, talk about a book, you say a book about the opposite

07:29.600 --> 07:35.280
order there in Japanese or in Hindi, you do the opposite and the and the talk comes at the end.

07:35.280 --> 07:40.400
So the verb will come at the end as well. So instead of Mary kicked the ball, it's Mary

07:41.360 --> 07:48.160
ball kicked. And then if it's Mary kicked the ball to John, it's John two, the two,

07:48.160 --> 07:52.240
the little marker there, the preposition, it's a post position in these languages.

07:52.240 --> 07:56.320
And so the interesting thing, a fascinating thing to me is that within a language,

07:57.760 --> 08:06.080
this order aligns, it's harmonic. And so if it's one or the other, it's either verb initial or

08:06.160 --> 08:10.720
verb final, but then you then you'll have prepositions, prepositions or post positions.

08:10.720 --> 08:15.680
And so that and that's across the languages that we can look at. We've got around 1000 languages

08:15.680 --> 08:21.920
for there's around 7000 languages around on the earth right now. But we have information

08:21.920 --> 08:27.440
about say word order on around 1000 of those pretty decent amount of information. And for

08:27.440 --> 08:34.480
those 1000, which we know about, about 95% fit that pattern. So they will have either verb and

08:34.880 --> 08:41.280
it's about half and half or half verb initial, like English and half verb final, like Japanese.

08:41.280 --> 08:47.520
So just to clarify, verb initial is subject verb object. That's correct. Verb final is

08:47.520 --> 08:52.000
still subject, object verb. That's correct. Yeah, the subject is generally first.

08:52.000 --> 08:59.920
That's so fascinating. I ate an apple or I apple eight. Yes. Okay. And it's fascinating that there's

09:00.160 --> 09:05.360
pretty even division in the world amongst those 45%. Yeah, it's pretty, it's pretty even.

09:05.360 --> 09:09.600
And those two are the most common by far. Those two words, the subject tends to be first.

09:09.600 --> 09:13.120
There's so many interesting things, but these things are what I find so fascinating is there

09:13.120 --> 09:19.120
are these generalizations within and across a language. And not only those are the, and

09:19.120 --> 09:23.280
there's actually a simple explanation, I think, for a lot of that. And that is,

09:23.680 --> 09:29.600
you're trying to like minimize dependencies between words. That's basically the story,

09:30.160 --> 09:35.600
I think, behind a lot of why word order looks the way it is, is you, we're always connecting.

09:36.640 --> 09:39.520
What is it? What is the thing I'm telling you? I'm talking to you in sentences. You're talking

09:39.520 --> 09:45.360
to me in sentences. These are sequences of words, which are connected. And the connections are

09:45.360 --> 09:52.000
dependencies between the words. And it turns out that what we're trying to do in a language is

09:52.080 --> 09:57.200
actually minimize those dependency links. It's easier for me to say things if the words that

09:57.200 --> 10:02.240
are connecting for their meaning are close together. It's easier for you in understanding if that's

10:02.240 --> 10:08.560
also true. If they're far away, it's hard to produce that and it's hard for you to understand.

10:08.560 --> 10:13.840
And the languages of the world within a language and across languages fit that generalization,

10:13.840 --> 10:21.280
which is, so it turns out that having verbs initial and then having prepositions ends up

10:21.280 --> 10:27.440
making dependencies shorter. And having verbs final and having postpositions ends up making

10:27.440 --> 10:31.040
dependencies shorter than if you cross them. If you cross them, it ends up, you just end up,

10:31.040 --> 10:35.280
it's possible, you can do it. Even within a language. Within a language, you can do it.

10:35.280 --> 10:40.560
It just ends up with longer dependencies than if you didn't. And so languages tend to go that way.

10:40.560 --> 10:46.800
They tend to, they say they call it harmonic. So it was observed a long time ago without the

10:46.800 --> 10:53.440
explanation by a guy called Joseph Greenberg, who's a famous typologist from Stanford. He

10:53.440 --> 10:57.200
observed a lot of generalizations about how word order works. And these are some of the

10:57.200 --> 10:59.680
harmonic generalizations that he observed.

10:59.680 --> 11:04.560
Harmonic generalizations about word, word, word. There's so many things I want to ask you.

11:04.560 --> 11:04.880
Okay, good.

11:04.880 --> 11:09.760
Okay, let me just, sometimes basics. You mentioned dependencies a few times.

11:09.760 --> 11:10.240
Yeah.

11:10.240 --> 11:11.920
What do you mean by dependencies?

11:11.920 --> 11:18.640
Well, what I mean is in, in language, there's kind of three structures to three components

11:18.640 --> 11:24.480
to the structure of language. One is the sounds. So cat is cat and to in English. I'm not talking

11:24.480 --> 11:28.560
about that part. I'm talking, and then there's two meaning parts. And those are the words.

11:28.560 --> 11:32.880
And, and you're talking about meaning earlier. So words have a form and they have a meaning

11:32.880 --> 11:37.280
associated with them. And so cat is a full form in English and it has a meaning associated with

11:37.280 --> 11:44.080
whatever a cat is. And then the combinations of words, that's what I'll call grammar or syntax.

11:44.080 --> 11:51.280
And that's like, when I have a combination like the cat or two cats, okay, so where I

11:51.280 --> 11:55.280
take two different words there and put them together and I get a compositional meaning

11:55.280 --> 12:01.840
from putting those two different words together. And so that's the syntax. And in any sentence

12:01.840 --> 12:05.440
or utterance, whatever I'm talking to you, you're talking to me, we have a bunch of words

12:05.440 --> 12:13.040
and we're putting together in a sequence. They, it turns out they are connected so that every word

12:13.040 --> 12:18.000
is connected to just one other word in that, in that sentence. And so you end up with what's

12:18.000 --> 12:23.520
called technically a tree. It's a tree structure. So there, where there's a root of that, of that

12:23.520 --> 12:28.960
to utterance of that sentence. And then there's a bunch of dependence, like branches from that root

12:28.960 --> 12:34.560
that go down to the words, the words are the leaves in this metaphor for a tree.

12:34.560 --> 12:38.640
So a tree is also sort of a mathematical construct. Yeah. Yeah. It's a graph theoretical thing.

12:38.640 --> 12:44.320
Graph theory thing. Yeah. So in this fascinating that you can break down a sentence into a tree

12:44.320 --> 12:48.640
and then one, every word is hanging on to another, it's depending on it. That's right. And everyone

12:48.640 --> 12:52.240
agrees on that. So all linguists will agree with that. No one. It's not a controversial.

12:52.240 --> 12:56.400
That is not controversial. There's nobody sitting here. I do nothing mad at you. I don't think so.

12:56.400 --> 13:00.080
Okay. There's no linguists sitting there mad at this. No, I think in every language,

13:00.080 --> 13:06.480
I think everyone agrees that all sentences are trees at some level. Can I pause on that? Sure.

13:06.480 --> 13:14.400
Because it's to me just as a layman, it's surprising that you can break down sentences

13:14.400 --> 13:20.320
in many, mostly all languages into a tree. I think so. I've never heard of anyone

13:20.320 --> 13:25.120
disagreeing with that. That's weird. The details of the trees are what people disagree with.

13:25.840 --> 13:29.600
Well, okay. So what's the root of it? How do you construct?

13:29.600 --> 13:32.880
How hard is it? What is the process of constructing a tree from a sentence?

13:34.000 --> 13:39.520
Well, this is where, depending on what your theoretical notions, I'm going to say the simplest

13:39.520 --> 13:44.400
thing. Dependency grammar. It's like a bunch of people invented this. Tinier was the first

13:44.400 --> 13:50.000
French guy back in, I mean, the paper was published in 1959, but he was working on the 30s and stuff.

13:50.720 --> 13:57.840
And it goes back to, you know, philologist Panini was doing this in ancient India. Okay.

13:57.840 --> 14:02.480
And so, you know, doing something like this, the simplest thing we can think of is that there's

14:02.480 --> 14:08.000
just connections between the words to make the utterance. And so let's just say I have like two

14:08.000 --> 14:15.440
dogs entered a room. Okay. Here's a sentence. And so we're connecting two and dogs together.

14:15.440 --> 14:18.880
That's like, there's some dependency between those words to make some bigger meaning.

14:18.880 --> 14:26.720
And then we're connecting dogs now to entered, right? And we connect a room somehow to entered.

14:26.720 --> 14:31.280
And so I'm going to connect to room and then room back to entered. That's the tree,

14:31.280 --> 14:35.520
is I, the root is entered. That's the thing is like an entering event. That's what we're saying

14:35.520 --> 14:41.040
here. And the subject, which is whatever that dog is, is two dogs, it was, and the connection

14:41.040 --> 14:46.400
goes back to dogs, which goes back to them, then that goes back to two. I'm just, that's my tree.

14:46.400 --> 14:52.080
It starts at entered, goes to dogs down to two. And then the other side, after the verb,

14:52.080 --> 14:57.600
the object, it goes to room. And then that goes back to the determiner or article, whatever you

14:57.600 --> 15:01.360
want to call that word. So there's a bunch of categories of words here we're noticing. So

15:01.360 --> 15:08.080
there are verbs. Those are these things that typically mark, they refer to events and states

15:08.080 --> 15:12.480
in the world. And they're nouns, which typically refer to people, places and things is what people

15:12.480 --> 15:17.120
say, but they can refer to other more, they can refer to events themselves as well. They're

15:17.120 --> 15:23.280
marked by, you know, how they, how they, the category, the part of speech of a word is how

15:23.280 --> 15:28.560
it gets used in language. It's like, that's how you decide what the, what the category of a word

15:28.560 --> 15:34.400
is not, not by the meaning, but how it's, how it gets used. What's usually the root? Is it going

15:34.400 --> 15:40.640
to be the verb that defies the event? Yes. Yes. Yes. Okay. Yeah. I mean, if I don't say a verb,

15:40.640 --> 15:43.440
then there won't be a verb. And so it'll be something else. What if you're messing, are

15:43.440 --> 15:47.520
we talking about language that's like correct language? What if you're doing poetry and messing

15:47.520 --> 15:53.360
with stuff? Is it then, then rules got the window, right? Then it's, no, you're still, no, no, no,

15:53.360 --> 15:57.200
no, you're constrained by whatever language you're dealing with. Probably you have other

15:57.200 --> 16:01.760
constraints in poetry, such that you're like usually in poetry, there's multiple constraints

16:01.760 --> 16:06.320
that you want to, like you want to usually convey multiple meanings is the idea. And maybe you have

16:06.320 --> 16:11.440
like a rhythm or a rhyming structure as well. And depending on, so, but you usually are constrained

16:11.440 --> 16:17.440
by your, the rules of your language for the most part. And so you don't violate those too much.

16:17.440 --> 16:22.400
You can violate them somewhat, but not too much. So it has to be recognizable as your language.

16:22.400 --> 16:29.280
Like in English, I can't say dogs to entered room. Ah, I mean, I meant that, you know, two dogs

16:29.280 --> 16:35.840
entered a room and I can't mess with the order of the, the articles and the articles and the

16:35.840 --> 16:41.120
nouns. You just can't do that. In some languages, you can, you can mess around with the order

16:41.120 --> 16:46.320
of words much more. I mean, you speak Russian. Russian has a much freer word order than English.

16:46.320 --> 16:51.040
And so in fact, you can move around words in, you know, I told you that English has the subject,

16:51.040 --> 16:56.080
verb, object, word order. So does Russian, but Russian is much freer than English. And so you

16:56.080 --> 17:00.720
can actually mess around with the word order. So probably Russian poetry is going to be quite

17:00.720 --> 17:05.040
different from English poetry because the word order is much less constrained. Yeah,

17:05.120 --> 17:11.040
there's a much more extensive culture of poetry throughout the history of the last 100 years

17:11.040 --> 17:16.640
in Russia. And I always wondered why that is, but it seems that there's more flexibility

17:17.360 --> 17:22.080
in the way the language is used. There's more, you're more female language easier by

17:22.800 --> 17:25.920
altering the words, altering the order of the words, messing with it.

17:25.920 --> 17:29.680
Well, you can just mess with different things in each language. And so in Russian, you have

17:29.680 --> 17:34.960
case markers, right? On the end, which is these endings on the nouns, which tell you how it can

17:35.280 --> 17:38.960
each noun connects to the verb, right? We don't have that in English. And so when I say

17:40.000 --> 17:45.520
Mary kissed John, I don't know who the agent or the patient is, except by the order of the words,

17:45.520 --> 17:49.680
right? In Russian, you actually have a marker. On the end, if you're using a Russian name and

17:49.680 --> 17:55.280
each of those names, you'll also say, is it, you know, agent, it'll be the, you know, nominative,

17:55.280 --> 17:59.760
which is marking the subject, or an accusative will mark the object. And you could put them in

17:59.760 --> 18:04.640
the reverse order. You could put accusative first, as you could put subject, you could put

18:05.600 --> 18:10.880
the patient first, and then the verb, and then the, the, the subject, and that would be a perfectly

18:10.880 --> 18:15.840
good Russian sentence. And it would still mean Mary, I could say John kissed Mary, meaning Mary

18:15.840 --> 18:20.800
kissed John, as long as I use the case markers in the right way, you can't do that in English.

18:20.800 --> 18:26.720
And so I love the terminology of agent and patient. And, and the other ones you use,

18:27.360 --> 18:30.960
those are sort of linguistic terms, correct? Those are, those are for like kind of meaning,

18:30.960 --> 18:35.840
those are meaning. And, and subject and object are generally used for position. So subject is

18:35.840 --> 18:40.000
just like the thing that comes before the verb. And the object is when it comes after the verb.

18:40.000 --> 18:44.160
The agent is kind of like the thing doing it. That's kind of what that means, right? The,

18:44.160 --> 18:48.480
the, the subject is often the person doing the action, right? The thing. So yeah.

18:48.480 --> 18:52.000
Okay. This is fascinating. So how hard is it to form a tree in general? Is there,

18:52.400 --> 18:57.360
is there a procedure to it? Like if you look at different languages, is it supposed to be a

18:57.360 --> 19:01.040
very natural, like is it automatable or is there some human genius involved in?

19:01.040 --> 19:04.640
I think it's pretty automatable at this point. People can figure out the words are,

19:04.640 --> 19:08.000
they can figure out the morphemes, which are the, technically morphemes are the,

19:08.640 --> 19:13.600
the minimal meaning units within a language. Okay. And so when you say eats or drinks,

19:13.600 --> 19:16.800
it actually has two morphemes in an English. There's, there's the, there's the root,

19:16.800 --> 19:20.320
which is the verb. And then there's some ending on it, which tells you, you know,

19:20.320 --> 19:24.480
that's this third person, third person singular. Can you say what morphemes are?

19:24.480 --> 19:28.080
Morphemes are just the minimal meaning units within a language. And then a word is just

19:28.080 --> 19:31.520
kind of the things we put spaces between English and 10. They have a little bit more,

19:31.520 --> 19:36.160
they have the morphology as well. They have the endings, this inflexual morphology on the endings

19:36.160 --> 19:39.920
on the roots. They modify something about the word that adds additional meaning.

19:39.920 --> 19:43.040
They tell you, yeah, yeah. And so we have a little bit of that in English, very little,

19:43.040 --> 19:47.120
much more in Russian, for instance. And, and, but we have a little bit in English. And so we

19:47.120 --> 19:51.360
have a little on the, on the nouns, you can say it's either singular or plural. And, and you can

19:51.360 --> 19:57.120
say, same thing for, for, for verbs, like simple past tense, for example, it's like, you know,

19:57.120 --> 20:01.680
notice in English, we say drinks, you know, he drinks, but everyone else says, I drink,

20:01.680 --> 20:06.560
you drink, we drink, it's unmarked in a way. And then, but in the past tense, it's just drank

20:06.560 --> 20:10.720
for everyone. There's no morphology at all for past tense. There is morphology, it's marking

20:10.720 --> 20:15.440
past tense, but it's kind of, it's an irregular now. So we don't even, you know, it drink to

20:15.440 --> 20:20.160
drink, you know, it's not even a regular word. So in most verbs, many verbs, there's an ED,

20:20.160 --> 20:24.720
we kind of add. So walk to walked, we add that to say it's the past tense, that I just happened

20:24.720 --> 20:28.560
to choose an irregular because the high frequency word and the high frequency words tend to have

20:28.560 --> 20:33.200
irregular as in English for. What's an irregular? Irregular is just, there's, there isn't a rule.

20:33.200 --> 20:38.720
So drink to drink is an, it's an irregular. Drink, drink, okay, as opposed to walk, walked,

20:38.720 --> 20:42.880
talked, talked. And there's a lot of irregular, irregular as in English. There's a lot of

20:42.880 --> 20:47.280
irregular as in English. The, the, the frequent ones, the common words tend to be irregular.

20:47.280 --> 20:52.960
They'll let, there's many, many more low frequency words and those tend to be, those irregular ones.

20:52.960 --> 20:57.680
The evolution of the irregular is fascinating. It's essentially slang that's sticky because

20:57.680 --> 21:02.320
you're breaking the rules and then everybody use it and doesn't follow the rules. And they,

21:02.320 --> 21:07.680
they say screw it to the rules. It's fascinating. So you said it morphemes, lots of questions.

21:07.680 --> 21:12.800
So morphology is what, the study of morphemes? Morphology is the, is the connections between

21:12.800 --> 21:17.200
the morphemes onto the roots, the roots. So in English, we mostly have suffixes. We have

21:17.200 --> 21:21.760
endings on the words, not very much, but a little bit. And as opposed to prefixes,

21:21.760 --> 21:28.000
some words, depending on your language can have, you know, mostly prefixes, mostly suffixes or

21:28.000 --> 21:32.960
mostly, or both. And then even languages, several languages have things called infixes where you

21:32.960 --> 21:41.760
have some kind of a general form for the, for the root and you put stuff in the middle. You

21:41.760 --> 21:48.000
change the vowels. That's fascinating. That's fascinating. So in general, there's what, two

21:48.000 --> 21:53.840
morphemes per word, usually one or two or three? Well, in English, it's, it's one or two. In English,

21:53.840 --> 21:57.920
it tends to be one or two. There can be more, you know, in other languages, you know, a language,

21:58.000 --> 22:04.480
language like, like Finnish, which has a very elaborate morphology, there may be 10 morphemes

22:04.480 --> 22:09.600
on the end of a root. Okay. And so there may be, there may be millions of forms of a given word.

22:09.600 --> 22:18.800
Okay. Okay. I will ask the same question over and over. But how does the, just sometimes to

22:18.800 --> 22:24.640
understand things like morphemes, it's nice to just ask the question, how does these kinds of

22:24.640 --> 22:34.640
things evolve? So you have a great book studying sort of the, how, how, how the cognitive processing,

22:34.640 --> 22:39.360
how language used for communication. So the, the mathematical notion of how effective languages

22:39.360 --> 22:43.520
for communication, what role that plays in the evolution of language, but just high level,

22:44.240 --> 22:50.080
like how do we, how does a language evolve with where English is two morphemes or one or two

22:50.080 --> 22:56.400
morphemes per word and then Finnish has infinity per word? So what, how does that, how does that

22:56.400 --> 23:02.000
happen? Is it just people? That's a really good question. That's a very good question. It's like,

23:02.000 --> 23:07.520
why do languages have more morphology versus less morphology? And I don't think we know the

23:07.520 --> 23:12.560
answer to this. I know, I think there's just like a lot of good solutions to the problem of

23:12.560 --> 23:19.760
communication. And so I, like, I believe as you hinted that language is an invented system

23:19.760 --> 23:25.600
by humans for communicating their ideas. And I think we, it comes down to we label the things we

23:25.600 --> 23:30.000
want to talk about. Those are the morphemes and words. Those are the things we want to talk about

23:30.000 --> 23:36.080
in the world and we invent those things. And then we put them together in ways that are easy for us

23:36.160 --> 23:42.080
to convey, to process. But that's like a naive view. And I don't, I mean, I think it's probably

23:42.080 --> 23:43.840
right, right? It's naive and probably right.

23:43.840 --> 23:46.320
Well, that's a nice, I don't know if it's naive. I think it's simple.

23:46.320 --> 23:46.960
Simple. Yeah.

23:46.960 --> 23:52.320
I think naive is, naive is an indication that's an incorrect somehow. It's a trivial,

23:53.200 --> 23:59.360
too simple. I think it could very well be correct. But it's interesting how sticky it feels like

23:59.920 --> 24:06.080
two people got together. It just feels like once you figure out certain aspects of a language,

24:06.080 --> 24:10.480
that just becomes sticky and the tribe forms around that language, maybe the language,

24:10.480 --> 24:14.480
maybe the tribe forms first, then the language evolves. And then you just kind of agree and

24:14.480 --> 24:16.080
you stick to whatever that is.

24:16.080 --> 24:22.480
I mean, these are very interesting questions. We don't know really about how words, even words,

24:22.480 --> 24:27.120
get invented very much about, you know, we don't really, I mean, assuming they get invented,

24:27.920 --> 24:32.000
they, we don't really know how that process works and how these things evolve. What we have is

24:32.960 --> 24:40.320
kind of a current picture, a current picture of a few thousand languages, a few thousand

24:40.320 --> 24:46.240
instances. We don't have any pictures of really how these things are evolving, really. And then

24:46.240 --> 24:53.920
the evolution is massively, you know, confused by contact, right? So as soon as one language,

24:53.920 --> 25:00.320
group, one group runs into another, we are smart, humans are smart, and they take on

25:00.320 --> 25:05.600
whatever is useful in the other group. And so any kind of contrast, which you're talking about,

25:05.600 --> 25:10.160
which I find useful, I'm going to, I'm going to start using as well. So I worked a little bit

25:10.720 --> 25:18.480
in specific areas of words, in number words and in color words, and in color words. So we have,

25:19.040 --> 25:26.560
in English, we have around 11 words that everyone knows for colors. And many more, if you happen to

25:27.120 --> 25:31.440
be interested in color for some reason or other, if you're a fashion designer or an artist or something,

25:31.440 --> 25:37.120
you may have many, many more words. But we can see millions, like if you have normal color vision,

25:37.120 --> 25:41.680
normal trichrometric color vision, you can see millions of distinctions in color. So we don't

25:41.680 --> 25:46.800
have millions of words. You know, the most efficient, no, the most, you know, detailed color

25:46.800 --> 25:51.600
vocabulary would have over a million terms to distinguish all the different colors that we

25:51.600 --> 25:57.440
can see. But of course, we don't have that. So it's somehow, it's been, it's kind of useful

25:57.440 --> 26:03.280
for English to have evolved in some way to, there's 11 terms that people find useful to talk about,

26:03.280 --> 26:10.720
you know, black, white, red, blue, green, yellow, purple, gray, pink, and I probably miss something

26:10.720 --> 26:16.080
there. Anyway, there's 11 that everyone knows. And depending on your, but you go to different

26:16.080 --> 26:21.840
cultures, especially the non industrialized cultures, and there'll be many fewer. So some cultures

26:21.840 --> 26:29.280
will have only two, believe it or not, that the Danai and Papua New Guinea have only two labels

26:29.280 --> 26:34.400
that the group uses for color. And those are roughly black and white. They are very, very dark

26:34.400 --> 26:38.400
and very, very light, which are roughly black and white. And you might think, oh, they're dividing

26:38.400 --> 26:42.720
the whole color space into, you know, light and dark or something. And that's not really true.

26:42.720 --> 26:46.880
They mostly just only label the light, the black and the white things. They just don't talk about

26:46.880 --> 26:51.360
the colors for the other ones. And so, and then there's other groups, I worked with a group called

26:51.360 --> 26:58.560
the Chimani down in, in Bolivia, in South America, and they have three words that everyone knows,

26:58.560 --> 27:04.720
but there's a few others that are, that, that several people, that many people know. And so,

27:04.720 --> 27:10.000
they have made, it's kind of depending on how you count between three and seven words that

27:10.000 --> 27:16.240
the group knows. Okay. And again, they're black and white. Everyone knows those. And red, red is,

27:16.240 --> 27:21.360
you know, like that tends to be the third word that everyone, that cultures bring in, if there's

27:21.360 --> 27:25.360
a word, it's always red, the third one. And then after that, it's kind of all bets are off

27:25.360 --> 27:31.120
about what they bring in. And so after that, they bring in a sort of a big blue, green space group,

27:31.120 --> 27:36.160
group, they have one for that. And then they have, and then, you know, different people have

27:36.160 --> 27:41.440
different words that they'll use for other parts of the space. And so anyway, it's probably related

27:41.440 --> 27:46.160
to what they want to talk, what they, not what they, not what they see, because they see the

27:46.160 --> 27:53.120
same colors as we see. So it's not like they have, they don't, they have a weak, a low color palette

27:53.120 --> 27:58.080
and the things they're looking at, they're looking at a lot of beautiful scenery. Okay. A lot of

27:58.080 --> 28:04.000
different colored flowers and berries and things. And you know, and so there's lots of things of

28:04.000 --> 28:09.680
very bright colors, but they just don't label the color in those cases. And the reason probably,

28:09.680 --> 28:15.280
we don't know this, but we think probably what's going on here is that what you do, why you label

28:15.280 --> 28:20.080
something is you need to talk to someone else about it. And why do I need to talk about a color?

28:20.080 --> 28:26.160
Well, if I have two things which are identical, and I want you to give me the one that's different,

28:26.160 --> 28:31.360
and in the only way it varies is color, then I invent a word, which tells you, you know,

28:31.360 --> 28:35.520
this is the one I want. So I want the red sweater off the rack, not the green sweater, right?

28:35.520 --> 28:40.240
There's two. And so those things will be identical, because these are things we made and they're

28:40.240 --> 28:44.880
dyed, and there's nothing different about them. And so in industrialized society, we have,

28:45.760 --> 28:49.680
you know, everything, everything we've got is pretty much arbitrarily colored.

28:50.400 --> 28:54.880
But if you go to a non-industrialized group, that's not true. And so they don't,

28:54.880 --> 28:58.400
suddenly they're not interested in color. If you bring bright colored things to them,

28:58.400 --> 29:02.560
they like them just like we like them. Bright colors are great. They're beautiful.

29:03.760 --> 29:07.040
But they just don't need to, nobody to talk about them. They don't have.

29:07.040 --> 29:13.120
So probably color words is a good example of how language evolves from sort of function,

29:13.120 --> 29:15.680
when you need to communicate the use of something.

29:15.680 --> 29:16.320
I think so.

29:16.320 --> 29:22.160
Then you kind of invent different variations. And basically, you can imagine that the evolution

29:22.160 --> 29:27.200
of a language has to do with what the early tribes doing, like what they want it, what kind

29:27.200 --> 29:31.280
of problems they're facing them, and they're quickly figuring out how to efficiently communicate

29:32.160 --> 29:36.320
the solution to those problems, whether it's aesthetic or function, all that kind of stuff,

29:36.320 --> 29:41.920
running away from a mammoth or whatever. But you know, it's, so I think what you're pointing to

29:41.920 --> 29:47.200
is that we don't have data on the evolution of language, because many languages have formed

29:47.200 --> 29:50.000
a long time ago. So you don't get the chatter.

29:50.000 --> 29:55.760
We have a little bit of like old English to modern English, because there was a writing system.

29:55.840 --> 30:00.000
And we can see how old English looked. So the word order changed, for instance,

30:00.000 --> 30:03.600
in old English to middle English to modern English. And so it, you know, we could see

30:03.600 --> 30:08.400
things like that, but most languages don't even have a writing system. So of the 7000,

30:08.960 --> 30:13.360
only, you know, a small subset of those have a writing system. And even if they have a writing

30:13.360 --> 30:17.280
system, they, it's not a very modern writing system. And so they don't have it. So we just

30:17.280 --> 30:22.320
basically have for Mandarin, for Chinese, we have a lot of, a lot of evidence from,

30:22.880 --> 30:27.040
for long time and for English and not for much else, not from in German a little bit,

30:27.040 --> 30:32.000
but not for a whole lot of like long-term language evolution. We don't have a lot.

30:32.000 --> 30:34.720
Well, you can have snapshots is what we've got of current languages.

30:34.720 --> 30:39.440
Yeah, you get an inkling of that from the rapid communication and certain platforms,

30:39.440 --> 30:43.840
like on Reddit, there's different communities, and they'll come up with different slang,

30:43.840 --> 30:49.600
usually from my perspective, German by a little bit of humor, or maybe mockery or whatever,

30:50.160 --> 30:56.000
you know, just talking shit in different kinds of ways. And you could see the evolution

30:56.880 --> 31:04.800
of language there. Because I think a lot of things on the internet, you don't want to be the boring

31:04.800 --> 31:12.480
mainstream. So you like want to deviate from the proper way of talking. And so you get a lot of

31:12.480 --> 31:18.480
deviation, like rapid deviation, then when communities collide, you get like, just like you

31:18.480 --> 31:22.480
said, humans adapt to it. And you can see it through the lens of humor. I mean, it's very

31:22.480 --> 31:26.480
difficult to study, but you can imagine like a hundred years from now, well, if there's a new

31:26.480 --> 31:29.920
language born, for example, we'll get really high resolution data on.

31:29.920 --> 31:34.480
I mean, English is changing. English changes all the time. All languages change all the time. So,

31:35.120 --> 31:42.400
you know, it's a famous result about the Queen's English. So if you look at the Queen's vowels,

31:42.400 --> 31:47.440
the Queen's English is supposed to be, you know, originally the proper way for the talk was sort

31:47.440 --> 31:52.960
of defined by whoever the Queen talked, or the King, whoever was in charge. And so if you look

31:52.960 --> 32:00.080
at how her vowels changed from when she first became Queen in 1952 or 1953, when she was

32:00.080 --> 32:04.640
coronated, the first, I mean, that's Queen Elizabeth, who died recently, of course, until,

32:04.640 --> 32:09.200
you know, 50 years later, her vowels changed, her vowels shifted a lot. And so that, you know,

32:09.200 --> 32:15.600
even in the sounds of British English, in her, the way she was talking was changing. The vowels

32:15.600 --> 32:20.080
were changing slightly. So that's just, in the sounds, there's change. I don't know what's, you

32:20.080 --> 32:24.720
know, we're, I'm interested. We're all interested in what's driving any of these changes. The

32:24.720 --> 32:29.520
word order of English changed a lot over a thousand years, right? So it used to look like

32:29.520 --> 32:34.880
German. You know, it used to be a verb final language with case marking, and it shifted

32:34.880 --> 32:40.320
to a verb-medial language, a lot of contact. So a lot of contact with French. And it became a verb

32:40.320 --> 32:45.680
medial language with no case marking. And so it became this, you know, verb, verb initially thing.

32:45.680 --> 32:51.520
So, and so that's, it totally evolved. And so it may very well, I mean, you know, it doesn't evolve

32:51.520 --> 32:56.320
maybe very much in 20 years is maybe what you're talking about. But over 50 and 100 years, things

32:56.320 --> 33:02.800
change a lot, I think. We'll now have good data, which is great. Can you talk to what is syntax

33:02.800 --> 33:08.080
and what is grammar? So you wrote a book on syntax. I did. You were asking me before about what,

33:08.080 --> 33:12.640
you know, how do I figure out what a dependency structure is? I'd say the dependency structures

33:12.640 --> 33:16.880
aren't that hard to generally, I think it's a lot of agreement of what they, of what they are

33:16.880 --> 33:20.960
for almost any sentence in most languages. I think people will agree on a lot of that.

33:22.400 --> 33:27.920
There are other parameters in the mix such that some people think there's a more complicated

33:27.920 --> 33:31.760
grammar than just a dependency structure. And so, you know, like Noam Tromsky,

33:31.760 --> 33:40.000
he's the most famous linguist ever. And he is famous for proposing a slightly more complicated

33:40.000 --> 33:46.480
syntax. And so he invented phrase structure grammar. So he's well known for many, many

33:46.480 --> 33:52.080
things. But in the 50s, in the early 60s, like the late 50s, he was basically figuring out what's

33:52.080 --> 33:58.960
called formal language theory. So, and he figured out sort of a framework for figuring out how

33:58.960 --> 34:03.600
complicated language, you know, a certain type of language might be, so-called phrase structure

34:03.600 --> 34:11.600
grammars of language might be. And so he, his, his idea was that maybe we can, we can think

34:11.600 --> 34:16.720
about the complexity of a language by how complicated the rules are. Okay. And the rules

34:17.440 --> 34:22.800
will look like this. They will have a left-hand side and they'll have a right-hand side. Something

34:22.800 --> 34:26.000
will, on the left-hand side, will expand to the thing on the right-hand side. So we'll say we'll

34:26.000 --> 34:31.520
start with an S, which is like the root, which is a sentence. Okay. And then we're going to expand

34:31.520 --> 34:37.200
to things like a noun phrase and a verb phrase is what he would say, for instance. Okay. And S

34:37.200 --> 34:42.000
goes to an NP and a VP is a kind of a phrase structure rule. And then we figure out what an NP

34:42.000 --> 34:47.680
is. An NP is a determiner and a noun, for instance. And verb phrase is something else,

34:47.680 --> 34:52.400
is a verb and another noun phrase and another NP, for instance. Those are the rules of a very

34:52.480 --> 34:59.440
simple phrase structure. Okay. And, and so he, he proposed phrase structure grammar as a way to

34:59.440 --> 35:04.160
sort of cover human languages. And then he actually figured out that, well, depending on the formalization

35:04.160 --> 35:08.480
of those grammars, you might get more complicated or less complicated languages. And so you could,

35:08.480 --> 35:13.200
he could, he said, well, you, these are, these are things called, you know, context-free languages,

35:13.200 --> 35:17.520
that rule that he thought, you know, human languages tend to be what he calls context-free

35:17.520 --> 35:23.040
languages. And, but there are simpler languages, which are so-called regular languages, and they

35:23.040 --> 35:28.080
have a more, a more constrained form to the rules of the, of the phrase structure of, of these

35:28.080 --> 35:35.200
particular rules. So he, he basically discovered and kind of invented ways to describe the language.

35:35.200 --> 35:39.280
And though, and those are phrase, those are phrase structure, a human language. And he was

35:39.280 --> 35:43.120
mostly interested in English initially in his, his work in the 50s.

35:43.120 --> 35:48.080
So quick questions around all this. So formal language theory is the big field of just studying

35:48.080 --> 35:52.000
language formally. Yes. And it doesn't have to be human language there. We can have a computer

35:52.000 --> 36:01.600
languages, any kind of system, which is generating a, some set of expressions in a language. And

36:01.600 --> 36:08.080
those could be like the, the, you know, the statements in a computer language, for example.

36:08.080 --> 36:11.600
So it could be that, or it could be human language. So technically, you can study

36:11.600 --> 36:16.160
programming languages. Yes. And have been, I mean, heavily studied using this formalism.

36:16.160 --> 36:20.640
There, there's a big field of programming languages within the formal language.

36:20.640 --> 36:26.480
Okay. And then phrase structure grammar is this idea that you can break down language into this

36:26.480 --> 36:33.520
SNP, VP, like type of thing. It's a particular formalism for describing language. Okay. So

36:33.520 --> 36:37.360
and, and Chomsky was the first one, he's the one who figured that stuff out back in the 50s.

36:37.360 --> 36:43.040
And, and, and, but he, and, and that's equivalent. Actually, the context free grammar is actually

36:43.040 --> 36:47.280
is kind of equivalent in the sense that it generates the same sentences as a dependency

36:47.280 --> 36:52.080
grammar would, you know, as the dependency grammar is a little simpler in some way. You just have

36:52.080 --> 36:57.520
a root and it goes like, we don't have any of these, the rules are implicit, I guess, in,

36:57.520 --> 37:01.200
in, we just have connections between words. The free structure grammars are kind of a different

37:01.200 --> 37:06.400
way to think about the, the dependency grammar. It's slightly more complicated, but it's kind

37:06.400 --> 37:12.480
of the same in some ways. So to clarify, dependency grammar is the framework under

37:12.480 --> 37:17.200
which you see language. And you make a case that this is a good way to describe the language.

37:17.200 --> 37:24.080
That's correct. And no, no Chomsky is watching this is very upset right now. So let's just kidding.

37:24.080 --> 37:31.600
But what's the difference between where's the place of disagreement between phrase structure

37:31.600 --> 37:35.760
grammar and dependency grammar? They're very close. So free structure grammar and dependency

37:35.760 --> 37:41.600
grammar aren't that, aren't that far apart. I like dependency grammar, because it's more

37:41.600 --> 37:46.000
perspicuous, it's more transparent about representing the connections between the words.

37:46.000 --> 37:49.600
It's just a little harder to see in phrase structure grammar, you know, the place where

37:49.600 --> 37:55.520
Chomsky sort of devolved or went off from, from, from this is he also thought there was

37:56.720 --> 38:01.280
something called movement. Okay. And so, and so, and that's where we disagree. Okay, that's the

38:01.280 --> 38:04.960
place where I would say we disagree. And, and, and I mean, well, maybe we'll get into that later.

38:04.960 --> 38:09.520
But the idea is, if you want to, do you want me to explain that? No, I would love to explain

38:09.520 --> 38:14.320
movement. Okay, so you're saying so many interesting things. Okay, so here's the movement is

38:14.320 --> 38:19.920
Chomsky basically sees English. And he says, okay, I said, you know, we had that sentence

38:19.920 --> 38:23.120
early, like it was like two dogs entered the room, it's changed a little bit, say,

38:23.120 --> 38:28.720
two dogs will enter the room. And he notices that, hey, English, if I want to make a question,

38:29.360 --> 38:33.840
yes, no question from that same sentence, I say, instead of two dogs will enter the room,

38:33.840 --> 38:39.280
I say, will two dogs enter the room? Okay, there's a different way to say the same idea.

38:39.280 --> 38:44.000
And it's like, well, the auxiliary verb that will thing, it's at the front as opposed to

38:44.000 --> 38:48.480
in the middle. Okay. And so, and he looked, you know, if you look at English, you see that

38:48.480 --> 38:53.200
that's true for all those modal verbs. And for other kinds of auxiliary verbs in English,

38:53.200 --> 38:58.000
you always do that, you always put an auxiliary verb at the front. And, and what he's, when he

38:58.000 --> 39:03.600
saw that, so, you know, if I say, I can win this bet, can I win this bet, right? So I move a can

39:03.600 --> 39:08.880
to the front. So actually, that's a theory, I just gave you a theory there, he talks about it as

39:08.880 --> 39:14.480
movement, that word in the declarative is the root, is the sort of default way to think about

39:14.480 --> 39:19.120
the sentence, and you move the auxiliary verb to the front, that's a movement theory. Okay,

39:19.120 --> 39:25.120
he said, and he just thought that was just so obvious that it must be true, that there's nothing

39:25.120 --> 39:30.880
more to say about that, that this is how auxiliary verbs work in English. There's a movement rule,

39:31.520 --> 39:35.440
such that you're moved, like to get from the declarative to the interrogative, you're moving

39:35.440 --> 39:40.000
the auxiliary to the front. And it's a little more complicated as soon as you go to simple,

39:40.000 --> 39:44.320
simple present and simple past, because, you know, if I say, you know, John slept, you have to say,

39:44.880 --> 39:50.000
did John sleep, not slept John, right? And so you have to somehow get an auxiliary verb, and I

39:50.000 --> 39:55.200
guess underlyingly, it's like slept is, it's a little more complicated than that, but that's his

39:55.200 --> 39:59.920
idea, there's a movement, okay? And so a different way to think about that, that isn't, I mean,

40:00.480 --> 40:05.360
he ended up showing later. So he proposed this theory of grammar, which has movement, and there's

40:05.360 --> 40:10.400
other places where he thought there's movement, not just auxiliary verbs, but things like the passive

40:10.400 --> 40:15.840
in English, and things like questions, WH questions, a bunch of places where he thought

40:15.840 --> 40:21.120
there's also movement going on. And each one of those, he thinks there's words, well, phrases

40:21.120 --> 40:24.720
and words are moving around from one structure to another, which he called deep structure to

40:24.720 --> 40:28.720
surface structure. I mean, there's like two different structures in his theory, okay?

40:29.600 --> 40:35.040
There's a different way to think about this, which is there's no movement at all. There's a

40:35.040 --> 40:41.760
lexical copying rule, such that the word will or the word can, these auxiliary verbs, they just

40:41.760 --> 40:46.560
have two forms. And one of them is the declarative, and one of them is the interrogative. And you

40:46.560 --> 40:51.520
basically have the declarative one, and oh, I form the interrogative, or I can form one from

40:51.520 --> 40:56.400
the other, doesn't matter which direction you go. And I just have a new entry, which has the same

40:56.400 --> 41:01.920
meaning, which has a slightly different argument structure, argument structure, it's a fancy word

41:01.920 --> 41:09.200
for the ordering of the words. And so if I say, you know, it was the dogs, two dogs can or will

41:09.200 --> 41:17.120
enter the room. There's two forms of will. One is will declarative. And then, okay, I've got my

41:17.120 --> 41:22.160
subject to the left, it comes before me, and the verb comes after me in that one. And then

41:22.160 --> 41:27.440
the will interrogative is like, oh, I go first, interrogative will is first, and then I have

41:27.440 --> 41:31.600
the subject immediately after, and then the verb after that. And so you just, you can just

41:31.600 --> 41:36.160
generate from one of those words, another word with a slightly different argument structure

41:36.240 --> 41:41.520
with different ordering. And these are just lexical copies. They're not necessarily moving

41:41.520 --> 41:45.360
from one to another. There's no movement. There's a romantic notion that you have one

41:46.160 --> 41:51.680
main way to use a word, and then you could move it around, which is essentially what

41:51.680 --> 41:58.240
movement is applying. Yeah, but that's the lexical copying is similar. So then we do lexical copying

41:58.240 --> 42:03.600
for that same idea that maybe the declarative is the source, and then we can copy it. And so

42:03.680 --> 42:09.120
an advantage, there's multiple advantages of the lexical copying story. It's not my story. This is

42:09.120 --> 42:16.080
like Ivan Sog, a bunch of linguists have been proposing these stories as well in tandem with

42:16.080 --> 42:22.480
the movement story. Ivan Sog died a while ago, but he was one of the proponents of the

42:22.480 --> 42:28.720
non-movement of the lexical copying story. And so that is that a great advantage is, well,

42:29.440 --> 42:37.840
Chomsky, really famously in 1971, showed that the movement story leads to learnability problems.

42:37.840 --> 42:44.320
It leads to problems for how language is learned. It's really, really hard to figure out what the

42:44.320 --> 42:48.720
underlying structure of a language is if you have both phrase structure and movement. It's like

42:48.720 --> 42:53.440
really hard to figure out what came from what. There's like a lot of possibilities there. If

42:53.440 --> 42:58.320
you don't have that problem, the learning problem gets a lot easier. Just say there's lexical copies.

42:59.680 --> 43:02.960
Well, we say the learning problem. Do you mean like humans learning a new language?

43:02.960 --> 43:08.240
Yeah, just learning English. So baby is lying around, listening to the crib, listening to me talk,

43:08.240 --> 43:12.640
and how are they learning English? Or maybe it's a two-year-old who's learning

43:13.200 --> 43:19.040
interrogatives and stuff. How are they doing that? Are they doing it from like, are they figuring out?

43:20.400 --> 43:24.560
So Chomsky said it's impossible to figure it out, actually. He said it's actually impossible,

43:25.200 --> 43:30.400
not hard, but impossible. And therefore, that's where universal grammar comes from,

43:30.400 --> 43:36.800
is that it has to be built in. And so what they're learning is that there's some built-in movement

43:36.800 --> 43:43.440
is built in in his story is absolutely part of your language module. And then you are,

43:44.080 --> 43:48.080
you're just setting parameters. You're set, depending on English, is just sort of a variant

43:48.080 --> 43:53.040
of the universal grammar. And you're figuring out, oh, which orders does English do these things?

43:53.600 --> 44:00.640
The non-movement story doesn't have this. It's like much more bottom-up. You're learning rules.

44:00.640 --> 44:05.360
You're learning rules one by one. And, oh, this word is connected to that word.

44:06.800 --> 44:10.720
Another advantage, it's learnable. Another advantage of it is that it predicts

44:11.280 --> 44:16.160
that not all auxiliary might move. Like, it might depend on the word, depending on whether you,

44:16.720 --> 44:23.520
and that turns out to be true. So there's words that don't really work as auxiliary.

44:23.520 --> 44:29.440
They work in declarative and not in interrogative. So I can say, I'll give you the opposite first.

44:29.440 --> 44:34.560
I can say, aren't I invited to the party? Okay. And that's an interrogative form,

44:35.280 --> 44:40.480
but it's not from, I aren't invited to the party. There is no I aren't, right? So that's

44:40.560 --> 44:47.760
interrogative only. And then we also have forms like ought. I ought to do this.

44:48.560 --> 44:51.040
And I guess some British, old British people can say,

44:51.920 --> 44:56.240
exactly. It doesn't sound right, does it? For me, it sounds ridiculous. I don't even

44:56.240 --> 44:59.920
think ought is great, but I mean, I totally recognize I ought to do it. It's not too bad,

44:59.920 --> 45:02.080
actually. I can say ought to do this. That sounds pretty good.

45:02.080 --> 45:06.080
If I'm trying to sound sophisticated, maybe. I don't know. It just sounds completely out of

45:06.960 --> 45:12.720
to me. Anyway, so there are variants here. And a lot of these words just work in one

45:12.720 --> 45:17.200
versus the other. And that's fine under the lexical copying story. It's like, well,

45:17.200 --> 45:23.520
you just learned the usage. Whatever the usage is, is what you do with this word.

45:23.520 --> 45:27.760
But it doesn't, it's a little bit harder in the movement story. The movement story,

45:27.760 --> 45:31.520
like that's an advantage, I think, of lexical copying. And in all these different places,

45:31.840 --> 45:39.760
there's all these usage variants which make the movement story a little bit harder to work.

45:39.760 --> 45:43.600
So one of the main divisions here is the movement story versus the lexical copy story

45:43.600 --> 45:48.960
that has to do about the auxiliary words and so on. But if you're relying to the phrase

45:48.960 --> 45:54.880
structure grammar versus dependency grammar. Those are equivalent in some sense in that

45:54.880 --> 45:59.920
for any dependency grammar, I can generate a free structure grammar which generates

45:59.920 --> 46:07.280
exactly the same sentences. I just like the dependency grammar formalism because it makes

46:07.280 --> 46:13.520
something really salient, which is the lengths of dependencies between words, which isn't so

46:13.520 --> 46:17.680
obvious in the phrase structure. In the phrase structure, it's just kind of hard to see. It's

46:17.680 --> 46:24.000
in there. It's just very opaque. Technically, I think phrase structure grammar is mappable to

46:24.000 --> 46:28.800
dependency grammar. And vice versa. And vice versa. But there's like these little labels,

46:28.880 --> 46:34.080
S and PVP. Yeah. For a particular dependency grammar, you can make a phrase structure grammar

46:34.080 --> 46:38.960
which generates exactly those same sentences and vice versa. But there are many phrase

46:38.960 --> 46:43.680
structure grammars which you can't really make a dependency grammar. I mean, you can do a lot

46:43.680 --> 46:48.880
more in a phrase structure grammar. You get many more of these extra nodes, basically. You can

46:48.880 --> 46:54.800
have more structure in there. And some people like that. And maybe there's value to that. I don't

46:54.800 --> 47:01.360
like it. Well, for you, we should clarify. So dependency grammar, it's just one word depends

47:01.360 --> 47:08.240
on only one other word and you form these trees. And that makes, it really puts priority on those

47:08.240 --> 47:13.440
dependencies just like as a tree that you can then measure the distance of the dependency

47:13.440 --> 47:18.960
from one word to the other. They can then map to the cognitive processing of the

47:19.760 --> 47:24.000
of these sentences, how well how easy is to understand all that kind of stuff. So it just

47:24.000 --> 47:32.400
puts the focus on just like the mathematical distance of dependence between words. So like

47:32.400 --> 47:37.120
it's just a different focus. Absolutely. Just continue on a thread of Chomsky because it's

47:37.120 --> 47:42.800
really interesting because it as you're discussing disagreement, to the degree there's

47:42.800 --> 47:46.640
disagreement, you're also telling the history of the study of language, which is really awesome.

47:47.520 --> 47:53.760
So you mentioned context free versus regular. Does that distinction come into play for dependency

47:53.760 --> 48:00.400
grammars? No, not at all. I mean, regular languages are too simple for human languages.

48:02.240 --> 48:08.160
It's a part of the hierarchy, but human languages are in the phrase structure world are definitely,

48:09.920 --> 48:15.600
at least context free, maybe a little bit more, a little bit harder than that. So there's something

48:15.600 --> 48:20.960
called context sensitive as well, where you can have like this is the just the formal language

48:20.960 --> 48:27.920
description. In a context free grammar, you have one, this is like a bunch of like formal language

48:27.920 --> 48:32.400
theory we're doing here. I love it. Okay. So you have you have a left hand side category and

48:32.400 --> 48:37.280
you're expanding to anything on the right is a, that's a context free. So like the idea is that

48:37.280 --> 48:41.920
that category on the left expands in independent of context to those things, whatever they're on

48:41.920 --> 48:49.040
the right. It doesn't matter what. And a context sensitive says, okay, I actually have more than

48:49.040 --> 48:52.960
one thing on the left. I can tell you only in this context, you know, I have maybe you have

48:52.960 --> 48:57.040
like a left and a right context or just a left context or a right context, I have two or more

48:57.040 --> 49:01.920
stuff on the left tells you how to expand that those things in that way. Okay. So it's context

49:01.920 --> 49:08.480
sensitive. A regular language is just more constrained. And so it, it doesn't allow anything

49:08.480 --> 49:14.720
on the right. It allows very, it allows basically it's a one very complicated rule is kind of what

49:15.280 --> 49:21.520
a regular language is. And so it doesn't have any, let's just say long distance dependencies,

49:21.520 --> 49:26.400
it doesn't allow recursion, for instance, there's no recursion. Yeah, recursion is where you,

49:26.400 --> 49:30.560
which is human languages have recursion, they have embedding. And you can't, well, it doesn't

49:30.560 --> 49:35.040
allow center embedded recursion, which human languages have, which is what center embedded

49:35.120 --> 49:38.400
recursion, within a sentence, within a sentence. Yeah, within a sentence. So here we're going to

49:38.400 --> 49:42.960
get to that. But I, you know, the formal language stuff is a little aside, Chomsky wasn't proposing

49:42.960 --> 49:48.000
it for human languages, even he was just pointing out that human languages are context free. And

49:48.000 --> 49:52.080
then he was most in for, for human, because that was kind of stuff we did for formal languages.

49:52.080 --> 49:57.280
And what he was most interested in was human language. And that's like the, the movement is

49:57.280 --> 50:03.200
where we, we, we, where, where he sort of set off in on the, I would say a very interesting,

50:03.840 --> 50:06.800
but wrong foot. It was kind of interesting. It's a very, I agree. It's kind of,

50:06.800 --> 50:11.840
it's very interesting history. So there's a set, he proposed this multiple theories in 57,

50:11.840 --> 50:15.440
and then 65, they're, they all have this framework, though, was phrase structure,

50:15.440 --> 50:19.520
plus movement, different versions of the, of the phrase structure and the movement in the 57.

50:19.520 --> 50:24.240
This is the most famous original bits of Chomsky's work. And then 71 is when he figured out that

50:24.240 --> 50:30.240
those lead to learning problems, that, that there's cases where a kid could never figure out

50:30.880 --> 50:36.720
which rule, which set of rules was intended. And, and so, and then he said, well, that means it's

50:36.720 --> 50:41.520
innate. It's kind of interesting. He just really thought the movement was just so obviously true

50:41.520 --> 50:46.960
that he couldn't, he didn't even entertain giving it up. It's just obvious that that's obviously

50:46.960 --> 50:53.440
right. And it was later where people figured out that there's all these like subtle ways in which

50:53.440 --> 50:57.120
things would, which look like generalizations aren't generalizations. And they, you know,

50:57.120 --> 51:01.520
across the category, they're, they're word specific and they have, and they, they kind of

51:01.520 --> 51:05.280
work, but they don't work across various other words in the category. And so it's easier to just

51:05.280 --> 51:10.560
think of these things as lexical copies. And, and I think he was very obsessed. I don't know. I'm

51:10.560 --> 51:16.240
just guessing that he just, he really wanted this story to be simple in some sense. And language

51:16.240 --> 51:21.440
is a little more complicated in some sense, you know, he didn't like words. He never talks about

51:21.440 --> 51:25.920
words. He likes to talk about combinations of words and words are, you know, look up a dictionary,

51:25.920 --> 51:32.080
there's 50 senses for a common word, right? The word take will have 30 or 40 senses in it. So,

51:32.640 --> 51:37.760
there'll be many different senses for common words. And he just doesn't think about that. It's, or

51:37.760 --> 51:42.400
he doesn't think that's language. I think he doesn't think that's language. He thinks that

51:42.400 --> 51:49.520
words are distinct from combinations of words. I think they're the same. If you look at my brain

51:49.680 --> 51:56.400
in the scanner, while I'm listening to a language I understand, and you compare, I can localize my

51:56.400 --> 52:00.560
language network in a few minutes, in like 15 minutes. And what you do is I listen to a language

52:00.560 --> 52:06.400
I know, I listen to, you know, maybe some language I don't know, or I listen to muffled speech, or I

52:06.400 --> 52:10.960
read sentences, or I read non words, like I do anything like this, anything that sort of really

52:10.960 --> 52:15.040
like English and anything that's not very like English. So I've got something like it and not,

52:15.040 --> 52:21.840
and I got to control. And the voxels, which is just, you know, the 3D pixels in my brain

52:21.840 --> 52:30.480
that are responding most is a language area. And that's this left lateralized area in my head. And

52:31.360 --> 52:36.240
wherever I look in that network, if you look for the combinations versus the words, it's

52:37.280 --> 52:42.320
everywhere. It's the same. That's fascinating. And so it's like hard to find, there are no areas

52:42.320 --> 52:48.880
that we know. I mean, that's a little overstated right now. At this point, the technology isn't

52:48.880 --> 52:54.160
great. It's not bad. But we have the best way to figure out what's going on in my brain when I'm

52:54.160 --> 52:59.040
listening or reading language is to use fMRI, Functional Magnetic Resonance Imaging. And

52:59.040 --> 53:04.480
that's a very good localization method. So I can figure out where exactly these signals are coming

53:04.480 --> 53:09.040
from pretty, you know, down to, you know, millimeters, cubic millimeters are smaller,

53:09.040 --> 53:14.240
okay? Very small. We can figure those out very well. The problem is the when, okay? It's measuring

53:15.200 --> 53:20.320
oxygen, okay? And oxygen takes a little while to get to those cells. And so it takes on the

53:20.320 --> 53:25.120
order of seconds. So I talk fast. I probably listened fast and I can probably understand

53:25.120 --> 53:30.160
things really fast. So a lot of stuff happens in two seconds. And so to say that we know what's

53:30.160 --> 53:36.640
going on, that the words right now in that network, our best guess is that whole network

53:36.640 --> 53:42.080
is doing something similar, but maybe different parts of that network are doing different things.

53:42.080 --> 53:47.040
And that's probably the case. We just don't have very good methods to figure that out right at

53:47.040 --> 53:53.040
this moment. And so since we're kind of talking about the history of the study of language,

53:53.920 --> 53:58.800
what other interesting disagreements, and you're both at MIT or were for a long time,

53:58.800 --> 54:03.200
what kind of interesting disagreements there, attention of ideas are there between you and

54:03.200 --> 54:08.400
Noam Chomsky. And we should say that Noam was in the linguistics department. And you're,

54:09.840 --> 54:15.200
I guess, for a time were affiliated there, but primarily brain and cognitive science department,

54:15.760 --> 54:20.320
which is another way of studying language. And you've been talking about fMRI. So like what,

54:20.960 --> 54:26.240
is there something else interesting to bring to the surface about the disagreement between the two

54:26.240 --> 54:33.680
of you or other people in the industry? Yeah, I mean, I've been at MIT for 31 years since 1993,

54:33.680 --> 54:40.880
and Chomsky's been there much longer. So I met him, I knew him, I met when I first got there,

54:40.880 --> 54:47.760
I guess, and we would interact every now and then. I'd say that, so I'd say our biggest difference

54:47.760 --> 54:54.560
is our methods. And so that's the biggest difference between me and Noam, is that I

54:55.280 --> 55:01.440
gather data from people. I do experiments with people and I gather corpus data, whatever,

55:01.440 --> 55:05.680
whatever corpus data is available, and we do quantitative methods to evaluate

55:06.480 --> 55:13.520
any kind of hypothesis we have. He just doesn't do that. And so, you know, he has never once been

55:13.520 --> 55:19.360
associated with any experiment or corpus work ever. And so it's all thought experiments,

55:19.360 --> 55:23.360
it's his own intuitions. So I just don't think that's the way to do things.

55:24.880 --> 55:29.360
That's a, you know, across the street, they're across the street from us, kind of difference

55:29.360 --> 55:34.160
between brain and cog sci and linguistics. I mean, not all linguists, some of the linguists,

55:34.160 --> 55:38.960
depending on what you do, more speech oriented, they do more quantitative stuff. But in the

55:39.840 --> 55:45.520
meaning, words and, well, it's combinations of words, syntax, semantics, they tend not to do

55:46.080 --> 55:52.560
experiments and corpus analyses. So I know in linguistics size, probably, well,

55:52.560 --> 55:58.640
but the method is a symptom of a bigger approach, which is sort of a psychology philosophy side on

55:58.640 --> 56:03.520
Nome. And for you, it's more sort of data driven, sort of almost like mathematical approach.

56:03.520 --> 56:08.160
Yeah, I mean, I'm a psychologist. So I would say we're in psychology. You know, I mean,

56:08.160 --> 56:12.720
brain and cognitive sciences is MIT's old psychology department. It was a psychology

56:12.720 --> 56:17.040
department up until 1985, and it became the brain and cognitive science department. And so,

56:17.600 --> 56:21.440
I mean, my training is in psychology, I mean, my training is math and computer science, but I'm

56:21.440 --> 56:24.320
a psychologist. I mean, I mean, I don't know what I am.

56:24.320 --> 56:26.400
So data driven, psychologist. Yeah, yeah, yeah.

56:26.400 --> 56:30.640
You are. I am what I am, but I'm having to be called a linguist. I'm having to be called a

56:30.640 --> 56:33.760
computer scientist. I'm having to be called a psychologist, any of those things.

56:33.760 --> 56:38.800
But in the actual, like how that manifests itself outside of the methodology is like these

56:38.800 --> 56:43.760
differences, these subtle differences about the movement story versus the lexical copy story.

56:43.760 --> 56:48.640
Yeah, those are theories, right? So the theories, like the theories are, but I think the reason

56:48.640 --> 56:54.800
we differ in part is because of how we evaluate the theories. And so I evaluate theories quantitatively,

56:54.800 --> 57:02.880
and Nome doesn't. Got it. Okay, well, let's let's explore the theories that you explore in your

57:02.880 --> 57:10.960
book. Let's return to this dependency grammar framework of looking at language. What's a good

57:10.960 --> 57:14.560
justification why the dependency grammar framework is a good way to explain language?

57:15.280 --> 57:19.840
What's your intuition? So the reason I like dependency grammar, as I've

57:20.560 --> 57:26.000
said before, is that it's very transparent about its representation of distance between words.

57:26.000 --> 57:31.120
So it's like, all it is, is you've got a bunch of words, you're connecting them together to make a

57:31.120 --> 57:40.160
sentence. And a really neat insight, which turns out to be true, is that the further apart the pair

57:40.160 --> 57:43.680
of words are that you're connecting the harder it is to do the production, the harder it is to

57:43.680 --> 57:47.120
do the comprehension. It's as hard to produce, it's hard to understand when the words are far

57:47.120 --> 57:52.240
apart. When they're close together, it's easy to produce and it's easy to comprehend. Let me

57:52.240 --> 58:00.160
give you an example. Okay, so we have, in any language, we have mostly local connections between

58:00.160 --> 58:04.960
words, but they're abstract. The connections are abstract, they're between categories of words.

58:04.960 --> 58:12.400
And so you can always make things further apart if you add modification, for example,

58:12.400 --> 58:19.040
after a noun. So a noun in English comes before a verb, the subject noun comes before a verb,

58:19.040 --> 58:24.000
and then there's an object after, for example. So I can say what I said before, the dog entered

58:24.000 --> 58:29.200
the room or something like that. So I can modify dog. If I say something more about dog after it,

58:29.200 --> 58:36.240
then what I'm doing is, indirectly, I'm lengthening the dependence between dog and entered by adding

58:36.240 --> 58:46.400
more stuff to it. So I just make it explicit here if I say the boy who the cat scratched

58:47.040 --> 58:52.480
cried. We're going to have a mean cat here. And so what I've got here is, the boy cried,

58:52.480 --> 58:57.680
it would be a very short, simple sentence, and I just told you something about the boy,

58:57.680 --> 59:01.040
and I told you it was the boy who the cat scratched. Okay.

59:01.040 --> 59:05.840
So the cry is connected to the boy. The cry at the end is connected to the boy in the beginning.

59:05.840 --> 59:09.600
Right. And so I can do that. And I can say that that's a perfectly fine English sentence.

59:09.600 --> 59:17.680
And I can say the cat which the dog chased ran away or something. Okay. I can do that.

59:17.680 --> 59:22.880
But it's really hard. So it's really hard now. I've got whatever I have here. I have the boy

59:23.600 --> 59:30.720
who the cat. Now let's say I try to modify cat. Okay. The boy who the cat which the dog

59:30.800 --> 59:35.680
chased scratched ran away. Oh my God, that's hard, right? I can, I'm sort of just working

59:35.680 --> 59:40.480
that through in my head how to produce and how to, and it's really just horrendous to understand.

59:40.480 --> 59:44.480
It's not so bad. At least I've got intonation there to sort of mark the boundaries and stuff.

59:44.480 --> 59:50.400
But it's, that's really complicated. That's sort of English in a way. I mean, that follows the

59:50.400 --> 59:55.280
rules of English. But so what's interesting about that is, is that what I'm doing is nesting

59:55.280 --> 01:00:01.280
dependencies there. I'm putting one, I've got a subject connected to a verb there. And then I'm

01:00:01.280 --> 01:00:06.160
modifying that with a clause, another clause, which happens to have a subject and a verb relation.

01:00:06.160 --> 01:00:11.200
I'm trying to do that again on the second one. And what that does is it lengthens out the dependence,

01:00:11.200 --> 01:00:15.200
multiple dependence actually get lengthened out there. The dependencies get longer,

01:00:15.200 --> 01:00:19.600
on the outside ones get long. And even the ones in between get kind of long. And you just,

01:00:19.600 --> 01:00:25.040
so what's fascinating is that that's bad. That's really horrendous in English.

01:00:25.920 --> 01:00:30.320
But that's horrendous in any language. And so in, in no matter what language you look at,

01:00:30.320 --> 01:00:35.680
if you do just figure out some structure where I'm going to have some modification following

01:00:35.680 --> 01:00:39.920
some head, which is connected to some later head, and I do it again, it won't be good.

01:00:39.920 --> 01:00:45.280
It guaranteed like 100% that will be uninterpretable in that language in the same way that was

01:00:45.280 --> 01:00:50.320
uninterpretable in English. Just clarify, the distance of the dependencies is whenever

01:00:51.280 --> 01:00:59.200
the boy cried, there's a dependence between two words. And then you counting the number of what

01:00:59.200 --> 01:01:04.880
morphemes between them. That's a good question. I just say words. Your words are morphemes between.

01:01:04.880 --> 01:01:08.080
We don't know that. Actually, that's a very good question. What is the distance metric?

01:01:08.080 --> 01:01:13.520
But let's just say it's words. Sure. And you're saying the longer the distance of that dependence,

01:01:13.520 --> 01:01:22.880
the more no matter the language, except legalese. Even legalese. We'll talk about it. Okay. But that,

01:01:24.320 --> 01:01:28.480
the people will be very upset that speak that language, not upset, but they'll either not

01:01:28.480 --> 01:01:33.760
understand it. They'll be like, this is, their brain will be working in overtime.

01:01:33.760 --> 01:01:37.520
They will have a hard time either producing or comprehending it. They might tell you that's not

01:01:37.520 --> 01:01:42.320
their language. It's sort of the language. I mean, it's following, they'll agree with each of those

01:01:42.320 --> 01:01:47.360
pieces as part of the language. But somehow that combination will be very, very difficult to produce

01:01:47.360 --> 01:01:53.120
and understand. Is that a chicken or the egg issue here? Well, I'm giving you an explanation.

01:01:56.240 --> 01:01:59.360
I'm giving you two kinds of explanations. I'm telling you that center embedding,

01:01:59.360 --> 01:02:05.360
that's nesting, those are synonyms for the same concept here. And the explanation for what,

01:02:05.360 --> 01:02:08.400
those are always hard. Center embedding and nesting are always hard. And I give you an

01:02:08.400 --> 01:02:12.240
explanation for why they might be hard, which is long distance connections. There's a

01:02:12.320 --> 01:02:16.240
when you do center embedding, when you do nesting, you always have long distance connections between

01:02:16.240 --> 01:02:21.760
the dependents. That's not necessarily the right explanation. I can go through reasons why that's

01:02:21.760 --> 01:02:27.760
probably a good explanation. And it's not really just about one of them. So probably it's a pair

01:02:27.760 --> 01:02:33.280
of them or something of these dependents that get long, that drives you to be really confused

01:02:33.280 --> 01:02:39.680
in that case. And so what the behavioral consequence there, I mean, this is kind of methods,

01:02:39.680 --> 01:02:44.320
like how do we get at this? You could try to do experiments to get people to produce these things.

01:02:44.320 --> 01:02:47.440
They're going to have a hard time producing them. You can try to do experiments to get them to

01:02:47.440 --> 01:02:53.120
understand them and see how well they understand them, can they understand them. Another method you

01:02:53.120 --> 01:02:59.600
can do is give people partial materials and ask them to complete them, those center embedded

01:02:59.600 --> 01:03:03.840
materials and they'll fail. So I've done that. I've done all these kinds of things.

01:03:04.800 --> 01:03:10.320
Wait a minute. So central embedding, meaning like you take a normal sentence like boy cried and

01:03:10.320 --> 01:03:16.000
inject a bunch of crap in the middle that separates the boy and the cried. Okay, that's

01:03:16.000 --> 01:03:20.240
central bedding and nesting is on top of that. No, nesting is the same thing. Center embedding,

01:03:20.240 --> 01:03:24.000
those are totally equivalent terms. I'm sorry, I sometimes use one and sometimes use the other.

01:03:24.000 --> 01:03:30.880
Got it. Got it. And then what you're saying is there's a bunch of different kinds of experiments

01:03:30.880 --> 01:03:35.440
you can do. I mean, I like to understand one is like have more embedding, more central bedding,

01:03:35.440 --> 01:03:39.120
is it easier or harder to understand, but then you have to measure the level of understanding,

01:03:39.120 --> 01:03:43.360
I guess. Yeah, you could. I mean, there's multiple ways to do that. I mean, there's the simplest

01:03:43.360 --> 01:03:48.000
ways just to ask people, how good is it sound? How natural is this sound? That's a very blunt,

01:03:48.000 --> 01:03:52.800
but very good measure. It's very, very reliable. People will do the same thing. And so it's like,

01:03:52.800 --> 01:03:56.560
I don't know what it means exactly, but it's doing something such that we're measuring something

01:03:56.560 --> 01:04:00.160
about the confusion, the difficulty associated with those. And those like those are giving you

01:04:00.240 --> 01:04:05.440
signal. That's why you can say that. What about the completion of the central bed?

01:04:05.440 --> 01:04:14.400
So if you give them a partial sentence, say I say the book which the author who, and I ask you to

01:04:14.400 --> 01:04:18.880
now finish that off for me, I mean, either say it, but you can just say it's written in front

01:04:18.880 --> 01:04:23.120
of you and you can just type and have as much time as you want. They will, even though that one's

01:04:23.120 --> 01:04:28.480
not too hard, right? So if I say it's like the book is like, oh, the book which the author who I

01:04:28.480 --> 01:04:35.040
met wrote was good. That's a very simple completion for that. If I give that completion

01:04:35.040 --> 01:04:41.040
on online somewhere to a crowdsourcing platform and ask people to complete that,

01:04:41.040 --> 01:04:46.480
they will miss off a verb very regularly, like half of the time, maybe two thirds of the time.

01:04:46.480 --> 01:04:50.320
They'll say, they'll just leave off one of those verb phrases. Even with that simple so to say,

01:04:50.320 --> 01:05:00.000
the book which the author who, and they'll say was, you need three verbs, right? I need three

01:05:00.000 --> 01:05:06.880
verbs are who I met wrote was good, and they'll give me two. They'll say who was famous was good

01:05:06.880 --> 01:05:12.240
or something like that. They'll just give me two. And that'll happen about 60% of the time. So 40%,

01:05:12.240 --> 01:05:16.960
maybe 30%, they'll do it correctly, correctly, meaning they'll do a three verb phrase. I don't

01:05:17.040 --> 01:05:20.160
know what's correct or not. This is hard. It's a hard task.

01:05:20.160 --> 01:05:22.240
Yeah. I can actually, I'm struggling with it in my head.

01:05:22.240 --> 01:05:25.120
Yeah. Well, it's easier when you look at it.

01:05:25.120 --> 01:05:28.880
If you look at it a little easier, then listening is pretty tough because you have to,

01:05:28.880 --> 01:05:33.280
because there's no trace of it. You have to remember the words that I'm saying,

01:05:33.280 --> 01:05:37.200
which is very hard auditorily. We wouldn't do it this way. We do it written. You can look at it

01:05:37.200 --> 01:05:41.920
and figure it out. It's easier in many dimensions in some ways, depending on the person. It's easier

01:05:41.920 --> 01:05:47.760
to gather written data for, I mean, most sort of psycho, I work in psycholinguistics, right?

01:05:47.760 --> 01:05:52.800
Psychology of language and stuff. And so a lot of our work is based on written stuff because it's

01:05:52.800 --> 01:05:59.600
so easy to gather data from people doing written kinds of tasks. Spoken tasks are just more complicated

01:05:59.600 --> 01:06:05.200
to administer and analyze because people do weird things when they speak. And it's harder to analyze

01:06:05.200 --> 01:06:10.160
what they do, but they generally point to the same kinds of things.

01:06:10.160 --> 01:06:17.920
It's okay. So the universal theory of language by Ted Gibson is that you can form dependency,

01:06:19.120 --> 01:06:24.000
you can form trees from any senses, and you can measure the distance in some way of those

01:06:24.000 --> 01:06:30.560
dependencies. And then you can say that most languages have very short dependencies.

01:06:30.560 --> 01:06:34.720
All languages. All languages. All languages have short dependencies. You can actually measure that.

01:06:34.720 --> 01:06:40.080
So an ex-student of mine, this guy is at University of California, Irvine. Richard

01:06:40.080 --> 01:06:45.520
Futrell did a thing a bunch of years ago now where he looked at all the languages we could

01:06:45.520 --> 01:06:50.800
look at, which was about 40 initially. And now I think there's about 60 for which there are

01:06:50.800 --> 01:06:55.680
dependency structures. So they're meaning there's got to be like a big text, a bunch of texts,

01:06:55.680 --> 01:06:59.760
which have been parsed for the dependency structures. And there's about 60 of those

01:06:59.760 --> 01:07:05.920
which have been parsed that way. And for all of those, what he did was take any

01:07:07.040 --> 01:07:11.360
sentence in one of those languages, and you can do the dependency structure, and then start at

01:07:11.360 --> 01:07:15.200
the root. We were talking about dependency structures. That's pretty easy now. And he's

01:07:15.200 --> 01:07:21.280
trying to figure out what a control way you might say the same sentence is in that language. And so

01:07:21.280 --> 01:07:26.640
what he does is just like, all right, there's a root, and say as a sentence is, let's go back to,

01:07:26.880 --> 01:07:32.880
two dogs entered the room. So entered is the root. And entered has two dependents that's got

01:07:32.880 --> 01:07:38.320
dogs, and it has room. And what he does is like, let's scramble that order. That's three things,

01:07:38.320 --> 01:07:43.680
the root, and the head, and the two dependents, and into some random order, just random. And then

01:07:43.680 --> 01:07:48.320
just do that for all the dependents down the two. So now look, do it for the whatever was two in

01:07:48.320 --> 01:07:54.000
dogs and for in room. And that's not a very short sentence. When sentences get longer,

01:07:54.000 --> 01:07:58.720
and you have more dependents, there's more scrambling that's possible. And what he found,

01:07:58.720 --> 01:08:02.560
what so that so so that that's one, you can figure out one scrambling for that sentence,

01:08:02.560 --> 01:08:07.600
he did like a hundred times for every sentence and every corp and every one of these texts,

01:08:07.600 --> 01:08:13.760
every corpus. And then he just compared the dependency lengths in those random scramblings

01:08:13.760 --> 01:08:19.120
to what actually happened with what the English or the French or the German was in the original

01:08:19.120 --> 01:08:23.040
language or Chinese or what all these like 80, like, you know, 60 languages, okay. And the

01:08:23.040 --> 01:08:28.080
dependency lengths are always shorter in the real language compared to this kind of a control.

01:08:28.080 --> 01:08:36.960
And there's another, it's a little more rigid his control. So the way I described it, you could

01:08:36.960 --> 01:08:41.680
have crossed dependencies, like that by scrambling that way, you could scramble in any way at all.

01:08:42.560 --> 01:08:47.200
Languages don't do that. They tend not to cross dependencies very much. Like so the dependency

01:08:47.200 --> 01:08:51.920
structure, they just they tend to keep things non-crossed. And there's a, you know, like,

01:08:51.920 --> 01:08:55.440
there's a technical term they call that projective, but it's just non-crossed is all that is

01:08:55.440 --> 01:09:01.520
projective. And so if you just constrain the scrambling so that it only gives you projectives

01:09:01.520 --> 01:09:06.560
sort of non-crossed is the same thing holds. So it's so the you still still human languages are

01:09:06.560 --> 01:09:12.800
much shorter than these this kind of a control. So there's like, what it means is that that

01:09:12.800 --> 01:09:18.480
we're in every language, we're trying to put things close in relative to this kind of a control,

01:09:18.480 --> 01:09:21.680
like it doesn't matter about the word order, some of these are verb final, some of them is

01:09:21.680 --> 01:09:25.840
a verb, media-like English, and some are even verb initial. There are a few languages in the

01:09:25.840 --> 01:09:31.600
world which have VSO, word order, verb, subject, object languages, haven't talked about those.

01:09:31.600 --> 01:09:37.360
It's like 10% of the and even even in those languages, it's still short dependencies.

01:09:37.360 --> 01:09:42.720
Short dependencies is rules. Okay. So how what, what are some possible explanations for that?

01:09:43.920 --> 01:09:48.000
For why languages have evolved that way? So that that's one of the,

01:09:48.880 --> 01:09:54.640
I suppose disagreements you might have with Chomsky. So you consider the evolution of language

01:09:54.640 --> 01:10:04.000
in terms of information theory. And for you, the purpose of language is ease of communication,

01:10:04.000 --> 01:10:08.240
right, in processing. That's right. That's right. So I mean, the story here is just about

01:10:08.800 --> 01:10:13.760
communication. It is just about production really. It's about ease of production is the story.

01:10:13.760 --> 01:10:17.600
When you say production, can you? Oh, I just mean each of language production. It's easier for me

01:10:17.600 --> 01:10:23.520
to say things when the, when I'm doing, whenever I'm talking to you is somehow I'm formulating

01:10:23.520 --> 01:10:27.600
some idea in my head and I'm putting these words together. And it's easier for me to do that,

01:10:29.040 --> 01:10:33.280
to put, to say something where the words are close, closely connected in a dependency,

01:10:33.280 --> 01:10:38.480
as opposed to separated, like by putting something in between and over and over again.

01:10:38.480 --> 01:10:42.160
It's just hard for me to keep that in my head. It like, that's, that's the whole story.

01:10:42.160 --> 01:10:46.320
Like the story is basically, it's like the dependency grammar sort of gives that to you.

01:10:46.400 --> 01:10:51.200
Like just like long, long as bad, short as good. It's like easier to keep in mind because you

01:10:51.200 --> 01:10:56.400
have to keep it in mind for probably for production, probably matters in comprehension

01:10:56.400 --> 01:11:00.240
as well. Like also matters in comprehension. It's on both sides of it. The production and the,

01:11:00.240 --> 01:11:04.000
but I would guess it's probably evolved for production. It's about producing. It's what's

01:11:04.000 --> 01:11:09.600
easier for me to say that ends up being easier for you also. And that's very hard to disentangle

01:11:09.600 --> 01:11:14.400
this idea of who is it for? Is it for me, the speaker, or is it for you, the listener? I mean,

01:11:14.480 --> 01:11:19.280
part of my language is for you. Like the way I talk to you is going to be different

01:11:19.280 --> 01:11:23.280
from how I talk to different people. So I'm, I'm definitely angling what I'm saying

01:11:23.280 --> 01:11:27.840
to who I'm saying, right? It's not like I'm just talking the same way to every single person.

01:11:27.840 --> 01:11:33.840
And so I am sensitive to my audience, but how does that, does that, you know,

01:11:33.840 --> 01:11:38.480
work itself out in the, in the dependency link differences? I don't know. Maybe that's about

01:11:38.480 --> 01:11:42.480
just the words, that part, you know, which words I select. My initial intuition is that

01:11:43.440 --> 01:11:49.280
you optimize language for the audience. Yeah. But it's just kind of like messing with my head

01:11:49.280 --> 01:11:54.480
a little bit to say that some of the optimization might be, or it may be the primary objective,

01:11:54.480 --> 01:12:00.000
the optimization might be the ease of production. We have different senses, I guess. I'm, I'm like,

01:12:00.000 --> 01:12:04.640
very selfish and you're like, I think it's like, it's all about me. I'm like,

01:12:04.640 --> 01:12:08.880
I'm just doing what's easiest for me at all times. I don't want to, I'm like, I'll, I mean,

01:12:08.880 --> 01:12:13.680
but I have to, of course, choose the words that I think you're going to know. I'm not going to

01:12:13.680 --> 01:12:17.280
choose words you don't know. In fact, I'm going to fix that when I, you know, so there it's about,

01:12:17.280 --> 01:12:22.800
but, but maybe for, for the syntax, for the combinations, it's just about me. I feel like

01:12:22.800 --> 01:12:25.440
it's, I don't know though, it's great. Wait, wait, wait, wait, wait, but the purpose of

01:12:25.440 --> 01:12:30.720
communication is to be understood, is to convince others and so on. So like the selfish things to

01:12:30.720 --> 01:12:34.400
be understood. Okay. It's about the listener. It's a little circular there too then. Okay.

01:12:34.400 --> 01:12:39.040
Right. I mean, like the ease of production helps me be understood then.

01:12:40.400 --> 01:12:44.880
I don't think it's circular. So I think the primary, I think the primary objective is to be

01:12:44.880 --> 01:12:50.320
understood is about the listener. Cause otherwise the, if you're optimizing for the ease of production,

01:12:50.320 --> 01:12:54.560
then you're, you're not going to have any of the interesting complexity of language. Like

01:12:54.560 --> 01:12:58.080
you're trying to like explain. Well, let's control for what it is I want to say. Like I,

01:12:58.080 --> 01:13:01.920
I'm saying let's control for the thing, the, the message, control for the message.

01:13:01.920 --> 01:13:05.040
But that means the message needs to be understood. That's the goal.

01:13:05.040 --> 01:13:07.120
Oh, but that's the meaning. So I'm still talking about the form.

01:13:07.760 --> 01:13:12.800
Just the form of the meaning. How do I frame the form of the meaning is all I'm talking about.

01:13:12.800 --> 01:13:16.560
You're talking about a harder thing, I think, is like, how am I, like trying to change the

01:13:16.560 --> 01:13:22.400
meaning. Let's, let's keep the meaning constant. Like which, if you keep the meaning constant,

01:13:22.400 --> 01:13:27.520
how can I phrase whatever it is I need to say, like I gotta pick the right words and I'm gonna

01:13:27.520 --> 01:13:32.080
pick the order so that it's, so it's easy for me. That's, that's, that's what I think it's

01:13:32.080 --> 01:13:38.320
probably like. I think I'm still tying meaning and form together in my head. But you're saying,

01:13:38.320 --> 01:13:43.440
if you keep the meaning of what you're saying constant, would the optimization, yeah, it could

01:13:43.440 --> 01:13:49.200
be the primary objective of that optimization is the, for production. That's interesting.

01:13:49.920 --> 01:13:56.400
I'm struggling to keep constant the meaning. It's just so, I mean, I'm such a, I'm a human,

01:13:56.400 --> 01:14:03.280
right? So for me, the form without having introspected on this, the form and the meaning

01:14:03.280 --> 01:14:11.040
are tied together, like deeply because I'm a human. Like for me, when I'm speaking,

01:14:11.040 --> 01:14:16.080
because I haven't thought about language, like in a rigorous way about the form of language.

01:14:16.080 --> 01:14:23.760
But look, for any event, there's, there's an unbounded, I don't want to say infinite, but sort

01:14:23.760 --> 01:14:29.680
of ways that I might communicate that same event. This two dogs entered a room, I can say in many,

01:14:29.680 --> 01:14:35.440
many different ways. I can say, Hey, there's two dogs. They entered the room. Hey, the room was

01:14:35.440 --> 01:14:39.360
entered by something. The thing that was entered was two dogs. I mean, there's, I mean, it's kind

01:14:39.360 --> 01:14:46.080
of awkward and weird stuff. But those are all similar messages with different forms, but different

01:14:46.080 --> 01:14:50.640
ways that might frame. And of course, I use the same words there all the time. I could have referred

01:14:50.720 --> 01:14:55.600
to the dogs as a Dalmatian and a Poodle or something. I could have been more specific

01:14:55.600 --> 01:15:00.800
or less specific about what they are. And I could have said, been more abstract about the number.

01:15:00.800 --> 01:15:06.640
There's like, so I, like I'm trying to keep the meaning, which is this event constant. And then

01:15:06.640 --> 01:15:10.320
how am I going to describe that to get that to you? It kind of depends on what you need to know,

01:15:10.320 --> 01:15:15.280
right? And what I think you need to know. But I'm like, let's control for all that stuff and not,

01:15:15.840 --> 01:15:19.520
and then I'm just like choosing about, I'm doing something simpler than you're doing,

01:15:19.520 --> 01:15:26.320
which is just forms. Yes. Just words. So to you specifying the breed of dog and

01:15:27.120 --> 01:15:31.520
whether they're cute or not is changing the meaning. That might be, yeah. Yeah, that would be

01:15:31.520 --> 01:15:36.320
changing. Oh, that would be changing the meaning for sure. Right. So you're just, yeah. Yeah.

01:15:36.320 --> 01:15:40.800
That's changing the meaning. But say, even if we keep that constant, we can still talk about

01:15:40.800 --> 01:15:47.280
what's easier or hard for me, right? The listener and the, which phrase structures I use, which

01:15:47.280 --> 01:15:54.560
combinations, which, yeah. This is so fascinating and just like a really powerful window into human

01:15:54.560 --> 01:16:01.840
language. But I wonder still throughout this, how vast the gap between meaning and form,

01:16:01.840 --> 01:16:07.840
I just, I just have this like, maybe romanticized notion that they're close together, that they

01:16:07.840 --> 01:16:13.840
evolve close to like hand in hand, that you can't just simply optimize for one without

01:16:14.560 --> 01:16:20.480
the other being in the room with us. Like it's, well, it's kind of like an iceberg.

01:16:20.480 --> 01:16:25.120
Form is the tip of the iceberg and the rest, the, the meaning is the iceberg, but you can't like

01:16:25.120 --> 01:16:30.400
separate. But I think that's why these large language models are so successful is because

01:16:30.400 --> 01:16:35.680
they're good at form and form isn't that hard in some sense. And meaning is tough still. And

01:16:35.680 --> 01:16:38.560
that's why they're not, they're, you know, they don't understand what they're doing. We're going

01:16:38.640 --> 01:16:44.480
to talk about that later maybe, but like we can distinguish in our, forget about large language

01:16:44.480 --> 01:16:48.480
models, like humans, maybe you'll talk about that later too, is like the difference between

01:16:49.200 --> 01:16:54.560
language, which is a communication system and thinking, which is meaning. So language is a

01:16:54.560 --> 01:17:00.400
communication system for the meaning. It's not the meaning. And so that's why, I mean, that, and

01:17:00.400 --> 01:17:04.320
there's a lot of interesting evidence we can talk about relevant, relevant to that.

01:17:04.320 --> 01:17:08.640
Well, I mean, that's a really interesting question. What is the difference between

01:17:10.240 --> 01:17:17.600
language written, communicated versus thought? What to use the difference between them?

01:17:18.800 --> 01:17:25.200
Well, you or anyone cast a think of a task, which they think is, is a good thinking task. And

01:17:25.200 --> 01:17:29.920
there's lots and lots of tasks, which should be good thinking tasks. And whatever those tasks,

01:17:29.920 --> 01:17:34.160
let's say it's, you know, playing chess, or that's a good thinking task, or playing some game,

01:17:34.160 --> 01:17:40.240
or doing some complex puzzles, maybe, maybe remembering some digits that's thinking,

01:17:40.240 --> 01:17:44.000
remembering some, a lot of different tasks we might think, maybe just listening to music is

01:17:44.000 --> 01:17:48.320
thinking, or there's a lot of different tasks we might think of as thinking. There's a woman in

01:17:48.320 --> 01:17:53.040
my department at Federico, and she's done a lot of work at, on this question about what's the

01:17:53.040 --> 01:17:58.320
connection between language and thought. And, and so she uses, I was referring earlier to MRI,

01:17:58.320 --> 01:18:04.640
fMRI, that's her primary method. And so she is been really fascinated by this question about whether,

01:18:05.600 --> 01:18:08.880
what language is, okay? And so as I mentioned earlier, you can

01:18:09.440 --> 01:18:13.840
localize my language area, your language area in a few minutes, okay? In like 15 minutes,

01:18:13.840 --> 01:18:19.200
I can listen to language, listen to non-language or backward speech or something. And we'll find

01:18:19.200 --> 01:18:26.080
areas left lateralized network in my head, which is especially, which is very sensitive to language,

01:18:26.080 --> 01:18:29.600
as opposed to whatever that control was, okay? Can you specify what you mean by language, like

01:18:29.600 --> 01:18:33.920
communicated language? Like what is language? Just sentences. You know, I'm listening to English

01:18:33.920 --> 01:18:39.040
of any kind story, or I can read sentences, anything at all that I understand, if I understand it,

01:18:39.040 --> 01:18:44.080
then it'll activate my language network. So right now, my language network is going like crazy

01:18:44.080 --> 01:18:48.400
when I'm talking and when I'm listening to you, because we're both, we're communicating. And

01:18:48.400 --> 01:18:54.800
that's pretty stable. Yeah, it's incredibly stable. So I've, I happen to be married to this woman

01:18:54.880 --> 01:18:59.520
Federico. So I've been scanned by her over and over and over since 2007 or six or something.

01:18:59.520 --> 01:19:05.600
And so my language network is exactly the same, you know, like a month ago, as it was back in 2007.

01:19:05.600 --> 01:19:11.600
It's amazingly stable. It's astounding. And with it, it's, it's a really fundamentally cool thing.

01:19:11.600 --> 01:19:16.880
And so my language network is, it's like my face, okay? It's not changing much over time inside my

01:19:16.880 --> 01:19:22.720
head. Can I ask a quick question? Sorry, it's a small tangent. At which point in the, as you grow

01:19:22.800 --> 01:19:28.000
up from baby to adult, does it stabilize? We don't know. Like that's a, that's a very hard

01:19:28.000 --> 01:19:32.560
question. They're working on that right now because of the problem of scanning little kids,

01:19:32.560 --> 01:19:38.800
like doing the, trying to do local, trying to do the localization on little children in this scanner,

01:19:38.800 --> 01:19:42.800
or you're lying in the fMRI scan. That's the best way to figure out where something's going on

01:19:42.800 --> 01:19:47.360
inside our brains. And the scanner is loud and you're in this tiny little, you know, area,

01:19:47.360 --> 01:19:52.240
you're claustrophobic. And it doesn't bother me at all. I can go to sleep in there, but some people

01:19:52.240 --> 01:19:55.520
are bothered by it. And little kids don't really like it. And they don't like to lie still. And

01:19:55.520 --> 01:19:59.840
you have to be really still because you can move around. That's, that messes up the coordinates of

01:19:59.840 --> 01:20:04.560
where, where everything is. And so, you know, try to get, you know, your question is how and when

01:20:04.560 --> 01:20:08.960
our language developing, you know, how, when, when, how does this left lateralized system come to

01:20:08.960 --> 01:20:12.800
play? Where does it, you know, and it's really hard to get a two year old to do this task. But

01:20:12.800 --> 01:20:16.880
you can maybe where they're starting to get three and four and five year olds to do this task for

01:20:16.880 --> 01:20:21.360
short periods. And it looks like it's there pretty early. So clearly when you lead up to you,

01:20:21.440 --> 01:20:28.160
like a baby's first words, before that, there's a lot of fascinating turmoil going on about like

01:20:28.160 --> 01:20:33.680
figuring out like, what are, what are these people saying? And you're trying to like make

01:20:33.680 --> 01:20:37.760
sense, how does that connect to the world and all that kind of stuff. Yeah. That might be just

01:20:37.760 --> 01:20:42.400
fascinating development that's happening there. That's hard to introspect. But anyway, you,

01:20:42.400 --> 01:20:48.400
we're back to the scanner and I can find my network in 15 minutes. And now we can ask a,

01:20:49.040 --> 01:20:53.520
find my network, find yours, find, you know, 20 other people do this task. And we can do some

01:20:53.520 --> 01:20:59.200
other tasks. Anything else you think is thinking of some other thing. I can do a spatial memory task.

01:20:59.200 --> 01:21:05.920
I can do a music perception task. I can do programming task if I program. Okay. I can do

01:21:06.480 --> 01:21:12.080
where I can like understand computer programs. And none of those tasks will tap the language

01:21:12.080 --> 01:21:16.480
network at all, like at all. There's no overlap. They do, they're, they're highly activated in

01:21:16.480 --> 01:21:21.600
other parts of the brain. There's a, there's a bilateral network, which I think she tends to

01:21:21.600 --> 01:21:25.520
call the multiple demands network, which does anything kind of hard and, and so anything that's

01:21:25.520 --> 01:21:31.280
kind of difficult in some ways will activate that multiple demands network. I mean, music will be

01:21:31.280 --> 01:21:35.520
in some music area, you know, there's music specific kinds of areas. And so, but they're,

01:21:36.080 --> 01:21:41.520
but, but none of them are activating the language area at all, unless there's words, like, so if

01:21:41.520 --> 01:21:45.680
you have music and there's a song and you can hear the words then, then then you get the language

01:21:46.000 --> 01:21:50.400
area. We're talking about speaking and listening, but are, or are we also talking about reading?

01:21:50.400 --> 01:21:56.880
This is all comprehension of any kind. And so that is fast. So what this, this, this network

01:21:56.880 --> 01:22:01.280
doesn't make any difference if it's written or spoken. So the, the, the thing that she calls,

01:22:01.280 --> 01:22:05.840
Federico calls the language network is this high level language. So it's not about the spoken,

01:22:05.840 --> 01:22:09.680
the spoken language, and it's not about the written language is about either one of them.

01:22:09.680 --> 01:22:13.360
And so we're, so when you do speech, you're sort of list, you either, you're listening to speech

01:22:13.360 --> 01:22:17.280
and you'd, you know, subtract away some language you don't understand and see where it's, or you

01:22:17.280 --> 01:22:22.240
subtract away back, backward speech, which signs sounds like speech, but it isn't. And, and then

01:22:22.240 --> 01:22:28.480
so you take away the sound part altogether. And so, and then if you do written, you get exactly

01:22:28.480 --> 01:22:33.600
the same network. So for just reading the language versus reading sort of nonsense words or something

01:22:33.600 --> 01:22:39.680
like that, you'll find exactly the same network. And so it's just about high level, um, comprehension

01:22:39.680 --> 01:22:42.960
of language. Yeah. In this case, and the same thing happened, production is a little harder to

01:22:42.960 --> 01:22:46.560
run the scanner, but the same thing happens in production. You get the same network. So production

01:22:46.560 --> 01:22:50.080
is a little harder. You have to figure out how do you run a task, you know, in the network such

01:22:50.080 --> 01:22:53.040
that you're doing some kind of production. And I can't remember what, they've done a bunch of

01:22:53.040 --> 01:22:57.760
different kinds of tasks there where you get people to, you know, produce things. Yeah. Figure

01:22:57.760 --> 01:23:02.320
out how to produce and the same network goes on there. Exactly the same place. And so if, wait,

01:23:02.320 --> 01:23:06.080
wait, so if you read random words, yeah, if you read things like, um,

01:23:06.880 --> 01:23:10.480
like gibberish. Yeah. Yeah. Lewis Carroll's, Twas Brillig,

01:23:10.480 --> 01:23:15.040
Jabberwocky, right? They call that Jabberwocky speech. The network doesn't get activated.

01:23:15.040 --> 01:23:19.360
Not as much. There are words in there. Because it's like, there's function words and stuff.

01:23:19.360 --> 01:23:24.720
So it's lower activation. Yeah. Yeah. So there's like, basically the more language like it is,

01:23:24.720 --> 01:23:30.480
the higher it goes in the language network. And that network is there from when you speak from,

01:23:30.480 --> 01:23:35.280
as soon as you learn language. And, and it's, it's there, like you speak multiple languages,

01:23:35.280 --> 01:23:39.360
the same network is going for your multiple languages. So you speak English, you speak Russian,

01:23:40.240 --> 01:23:44.400
both of them are hitting that same network. If you, if you're affluent in those languages.

01:23:44.400 --> 01:23:49.280
So programming. Not at all. Isn't that amazing? Even if you're a really good programmer,

01:23:49.280 --> 01:23:54.800
that is not a human language. It's just not conveying the same information. And so it is

01:23:54.800 --> 01:23:58.800
not in the language network. And so that has mind blowing as I think. That's pretty cool.

01:23:58.800 --> 01:24:03.280
That's weird. It is amazing. And so that's like one set of day. This is hers like shows that

01:24:03.280 --> 01:24:08.480
what you might think is thinking is, is not language language is just the seek, just, just

01:24:08.480 --> 01:24:14.640
this conventionalized system that we've worked out in human languages. Oh, another fascinating

01:24:14.640 --> 01:24:21.680
little bit tidbit is that even if they're these constructed languages, like Klingon, or I don't

01:24:21.680 --> 01:24:25.280
know the languages from Game of Thrones, I'm sorry, I don't remember those languages, maybe a lot of

01:24:25.280 --> 01:24:29.440
people offended right now. There's people that speak those languages. They really speak those

01:24:29.440 --> 01:24:36.000
languages because the people that wrote the languages for the shows, they did an amazing

01:24:36.000 --> 01:24:40.960
job of constructing on something like a human language. And those that, that lights up the

01:24:40.960 --> 01:24:46.080
language area. That's like, because they can speak, you know, pretty much arbitrary thoughts

01:24:46.080 --> 01:24:50.640
in a human language. It's not a, it's a constructed human language. Probably it's related to human

01:24:50.640 --> 01:24:54.320
languages because the people that were constructing them were making them like human languages in

01:24:54.320 --> 01:24:59.600
various ways, but it also activates the same network, which is pretty, pretty cool. Anyway.

01:24:59.600 --> 01:25:04.800
Sorry to go into a place where you may be a little bit philosophical, but is it possible

01:25:05.440 --> 01:25:10.000
that this area of the brain is doing some kind of translation into a deeper set of

01:25:11.200 --> 01:25:17.840
almost like concepts? It has to be doing. So it's doing in communication, right? It is translating

01:25:18.400 --> 01:25:22.960
from thought, whatever that is, is more abstract, and it's doing that. That's what it's doing. Like,

01:25:22.960 --> 01:25:26.560
it is, that is kind of what it is doing. It's like kind of a meaning network, I guess.

01:25:27.360 --> 01:25:31.120
Yeah, like a translation network. Yeah. But I wonder what is at the core,

01:25:31.120 --> 01:25:37.120
at the bottom of it? Like, what are thoughts? Are they thoughts? To me, like, thoughts and words,

01:25:37.120 --> 01:25:42.960
are they neighbors or are, is it one turtle sitting on top of the other? Meaning, like, is there a

01:25:42.960 --> 01:25:49.680
deep set of concepts that we... Well, there's connections right between those, what these

01:25:49.680 --> 01:25:52.720
things mean. And then there's probably other parts of the brain that what these things mean.

01:25:52.800 --> 01:25:58.480
And so, you know, when I'm talking about whatever it is I want to talk about, it'll be represented

01:25:58.480 --> 01:26:02.640
somewhere else. That knowledge of whatever that is will be represented somewhere else.

01:26:02.640 --> 01:26:07.440
Well, I wonder if there's like some stable, nicely compressed encoding of meanings

01:26:08.240 --> 01:26:18.080
that's separate from language. I guess the implication here is that we don't think in

01:26:18.080 --> 01:26:22.480
language. That's correct. Isn't that cool? And that's so interesting.

01:26:22.480 --> 01:26:27.120
So people, I mean, this is like hard to do experiments on, but there is this idea of

01:26:27.120 --> 01:26:32.320
inner voice and a lot of people have an inner voice. And so, if you do a poll on the internet

01:26:32.320 --> 01:26:35.200
and ask if you hear yourself talking when you're just thinking or whatever,

01:26:35.840 --> 01:26:42.480
about 70 or 80% of people will say yes. Most people have an inner voice. I don't. And so,

01:26:42.480 --> 01:26:45.920
I always find this strange when... So, when people talk about an inner voice, I always

01:26:45.920 --> 01:26:51.520
thought this was a metaphor. And they hear, I know most of you, whoever's listening to this,

01:26:51.520 --> 01:26:55.920
thinks I'm crazy now because I don't have an inner voice. And I just don't know what you're

01:26:55.920 --> 01:27:02.080
listening to. It sounds so kind of annoying to me, but to have this voice going on while you're

01:27:02.080 --> 01:27:07.840
thinking, but I guess most people have that. And I don't have that. And we don't really know what

01:27:07.840 --> 01:27:12.560
that connects to. I wonder if the inner voice activates that same network. I don't know.

01:27:13.520 --> 01:27:17.520
I don't know. I mean, this could be speechy, right? So that's like, you hear, do you have an inner

01:27:17.520 --> 01:27:24.240
voice? I don't think so. A lot of people have this sense that they hear themselves. And then,

01:27:24.240 --> 01:27:28.000
say they read someone's email, I've heard people tell me that they hear that other person's voice

01:27:28.000 --> 01:27:33.680
when they read other people's emails. And I'm like, wow, that sounds so disruptive.

01:27:33.680 --> 01:27:38.160
I do think I like vocalize when I'm reading, but I don't think I hear a voice.

01:27:38.800 --> 01:27:40.880
Well, that's, you probably don't have an inner voice. Yeah, I don't think I have an inner voice.

01:27:40.880 --> 01:27:46.640
People have an inner voice. People have this strong percept of hearing sound in their heads

01:27:46.640 --> 01:27:50.240
when they're just thinking. I refuse to believe that's the majority of people.

01:27:50.240 --> 01:27:54.800
Majority, absolutely. What? It's like two-thirds or three-quarters. It's not.

01:27:54.800 --> 01:27:59.920
I would never ask class. And I went internet, they always say that. So you're in a minority.

01:27:59.920 --> 01:28:06.080
It could be a self-report flaw. It could be. You know, when I'm reading inside my head,

01:28:07.520 --> 01:28:13.680
I'm kind of like saying the words, which is probably the wrong way to read, but I don't

01:28:13.680 --> 01:28:19.680
hear a voice. There's no percept of a voice. I don't refuse to believe the majority of people

01:28:19.680 --> 01:28:24.160
have it. Anyway, it's a fascinating, the human brain is fascinating, but it still blew my mind

01:28:24.160 --> 01:28:31.280
that the, that language does appear, comprehension does appear to be separate from thinking.

01:28:32.560 --> 01:28:39.440
So that's one set. One set of data from Fedorenko's group is that no matter what task you do,

01:28:39.440 --> 01:28:43.840
if it doesn't have words and combinations of words in it, then it won't light up the language

01:28:43.840 --> 01:28:48.720
network. You know, you could, it'll be active somewhere else, but not there. So that's one.

01:28:48.720 --> 01:28:55.520
And then this other piece of evidence relevant to that question is, it turns out there are these,

01:28:55.520 --> 01:29:01.040
this group of people who've had a massive stroke on the left side and wiped out their language

01:29:01.040 --> 01:29:04.960
network. And as long as they didn't wipe out everything on the right as well, in that case,

01:29:04.960 --> 01:29:08.960
they wouldn't be, you know, cognitively functionable. But if they just wiped out language,

01:29:08.960 --> 01:29:13.840
which is pretty tough to do because it's, it's very expansive on the left. But if they have,

01:29:13.840 --> 01:29:19.760
then there are these, there's patients like this, so-called global aphasics, who can do

01:29:20.480 --> 01:29:24.800
any task just fine, but not language. They can't, you can't talk to them. I mean,

01:29:25.360 --> 01:29:30.480
they don't understand you. They can't speak, can't write, they can't read, but they can do,

01:29:30.480 --> 01:29:34.240
they can play chess, they can drive their cars, they can do all kinds of other stuff, you know,

01:29:34.240 --> 01:29:38.560
do math, they can do all, like, so math is not in the language area, for instance, you do arithmetic

01:29:38.560 --> 01:29:42.560
and stuff. That's not language area. It's got symbols. So people sort of confuse some kind of

01:29:42.560 --> 01:29:47.440
symbolic processing with language and symbolic processing is not the same. So there are symbols

01:29:47.440 --> 01:29:51.760
and they have meaning, but it's not language. It's not a, you know, conventionalized language

01:29:51.760 --> 01:29:56.560
system. And so language, so math isn't there. And so they can do math. They're, they do just as well

01:29:56.560 --> 01:30:01.120
as their control, age match controls and all these tasks. This is Rosemary Varley over in

01:30:01.120 --> 01:30:05.200
University College London, who has a bunch of patients who, who she's shown this that they're

01:30:05.200 --> 01:30:13.520
just, so that sort of combination suggests that language isn't necessary for thinking. It doesn't

01:30:13.520 --> 01:30:17.680
mean you can't think in language. You could think in language because language allows a lot of

01:30:17.680 --> 01:30:22.320
expression, but it's just, you don't need it for thinking. It's, it suggests that language is separate,

01:30:22.960 --> 01:30:27.600
is a separate system. This is kind of blowing my mind right now. I'm trying to load that in

01:30:27.600 --> 01:30:34.160
because it has implications for large language models. It sure does. And they've been working on

01:30:34.160 --> 01:30:39.280
that. Well, let's take a stroll there. You wrote that the best current theories of human language

01:30:39.280 --> 01:30:45.360
are arguably large language models. So this has to do with form. It's kind of a big theory. And,

01:30:46.080 --> 01:30:51.680
but the reason it's arguably the best is that it, it does the best at predicting what's English,

01:30:51.680 --> 01:30:56.320
for instance, it's, it's like incredibly good, you know, it better than any other theory. It's so,

01:30:56.320 --> 01:31:01.360
you know, but, you know, we don't, you know, there's, it's not sort of, there's not enough detail.

01:31:01.360 --> 01:31:04.080
What's opaque? Like, there's not, you don't know what's going on.

01:31:04.080 --> 01:31:07.920
No, what's going on. It's another black box. But I think it's, you know, it is a theory.

01:31:07.920 --> 01:31:12.240
What's your definition of a theory? Because it's a gigantic, it's a gigantic black box with,

01:31:12.240 --> 01:31:17.840
you know, a very large number of parameters controlling it. To me, theory usually requires

01:31:19.040 --> 01:31:23.600
a simplicity, right? Well, I don't know. Maybe I'm just being loose there. I think it's a,

01:31:23.600 --> 01:31:27.360
it's not, it's not a great theory, but it's a theory. It's a good theory in one sense,

01:31:27.360 --> 01:31:30.720
and then it covers all the data. Like anything you want to say in English, it does. And so

01:31:30.720 --> 01:31:35.200
that's why it's, that's how it's arguably the best, is that no other theory is as good as

01:31:35.200 --> 01:31:39.840
a large language model in predicting exactly what's good and what's bad in English.

01:31:40.400 --> 01:31:43.840
You know, now you're saying, is it a good theory? Well, probably not, you know,

01:31:43.840 --> 01:31:47.200
because I want a smaller theory than that. It's too big. I agree.

01:31:47.200 --> 01:31:53.600
You could probably construct mechanism by which it can generate a simple explanation of a

01:31:53.600 --> 01:32:01.440
particular language, like a set of rules, something like it could generate a dependency

01:32:01.440 --> 01:32:10.640
grammar for a language, right? Yeah. You could probably, you could probably just ask it about

01:32:10.640 --> 01:32:16.880
itself. Well, you know, that's, I mean, that presumes, and there's some evidence for this,

01:32:17.920 --> 01:32:22.640
some large language models are implementing something like dependency grammar inside them.

01:32:22.640 --> 01:32:28.320
And so there's work from a guy called Chris Manning and colleagues over at Stanford

01:32:28.320 --> 01:32:33.440
in natural language. And they looked at, I don't know how many large language model types,

01:32:33.440 --> 01:32:39.360
but certainly Burt and some others where, and where you do some kind of fancy math to figure

01:32:39.360 --> 01:32:43.440
out exactly what the sort of, what kind of abstractions of representations are going on.

01:32:43.440 --> 01:32:47.200
And they, and they were saying it does look like dependency structure is, is what they're

01:32:47.200 --> 01:32:51.520
constructing. It doesn't, like, so it's actually a very, very good map. So kind of a,

01:32:51.520 --> 01:32:58.080
they are constructing something like that. Does it mean that, you know, that they're using that

01:32:58.080 --> 01:33:03.040
for meaning? I mean, probably, but we don't know. You write that the kinds of theories of language

01:33:03.040 --> 01:33:08.320
that LLMs are closest to are called construction based theories. Can you explain what construction

01:33:08.320 --> 01:33:14.880
based theories are? It's just a general theory of language such that there's a form and a meaning

01:33:14.960 --> 01:33:20.960
pair for, for lots of pieces of the language. And so it's, it's, it's primarily usage based,

01:33:20.960 --> 01:33:24.880
is a construction grammar. It's just, it's trying to deal with the things that people

01:33:25.440 --> 01:33:31.280
actually say, actually say and actually write. And so that's, it's a usage based idea. And

01:33:31.280 --> 01:33:36.320
what's the constructional constructions either a simple word, so like a morpheme plus its meaning

01:33:36.320 --> 01:33:41.280
or a combination of words, it's basically combinations of words, like the rules. So,

01:33:41.920 --> 01:33:50.960
but it's, it's unspecified as to what the form of the grammar is under underlyingly.

01:33:50.960 --> 01:33:57.520
And so I would, I would argue that the dependency grammar is maybe the right form to use for the

01:33:57.520 --> 01:34:03.280
types of construction grammar. Construction grammar typically isn't kind of formalized

01:34:03.280 --> 01:34:08.400
quite. And so maybe the formalization, a formalization of that, it might be in dependency

01:34:08.400 --> 01:34:14.080
grammar. Yeah. I mean, I, I would think so, but I mean, it's up to people, other researchers

01:34:14.080 --> 01:34:19.600
in that area, if they agree or not. So. Well, do you think that large language models understand

01:34:19.600 --> 01:34:25.200
language? Are they mimicking language? I guess the deeper question there is, are they just

01:34:25.200 --> 01:34:31.360
understanding the surface form? Or do they understand something deeper about the meaning

01:34:31.360 --> 01:34:35.840
that then generates the form? I mean, I would argue they're doing the form, they're doing

01:34:35.840 --> 01:34:39.600
the form, they're doing it really, really well. And are they doing the meaning? No,

01:34:39.600 --> 01:34:44.480
probably not. I mean, there's lots of these examples from various groups showing that they

01:34:44.480 --> 01:34:48.800
can be tricked in all kinds of ways. They really don't understand the, the meaning of what's going

01:34:48.800 --> 01:34:55.360
on. And so there's a lot of examples that he and other groups have given, which just, which show

01:34:55.360 --> 01:34:59.600
they don't really understand what's going on. So, you know, the Monty Hall problem is this

01:34:59.600 --> 01:35:04.960
silly problem, right? Where, you know, if you have three door, it's less make a deal as this

01:35:04.960 --> 01:35:10.640
old game show, and there's three doors, and there's a prize behind one, and there's some

01:35:11.920 --> 01:35:16.480
junk prizes behind the other two, and you're trying to select one. And if you, you know,

01:35:16.480 --> 01:35:21.520
he knows Monty, he knows where the target item is, the good thing, he knows everything is back

01:35:21.520 --> 01:35:26.320
there. And you're supposed to, he gives you a choice, you choose one of the three, and then

01:35:26.320 --> 01:35:30.560
he opens one of the doors, and it's some junk prize. And then the question is, should you trade

01:35:30.560 --> 01:35:34.400
to get the other one? And the answer is yes, you should trade, because he knew which ones you could

01:35:34.400 --> 01:35:40.080
turn around. And so now the odds are two-thirds, okay? And then you just change that a little bit

01:35:40.080 --> 01:35:45.360
to the large language mall. The large language mall has seen that explanation so many times,

01:35:45.360 --> 01:35:49.440
that it just, if you change the story, it's a little bit, but it makes it sound like it's the

01:35:49.440 --> 01:35:55.600
Monty Hall problem, but it's not. You just say, oh, there's three doors, and one behind them is a

01:35:55.600 --> 01:36:00.160
good prize, and there's two bad doors. I happen to know it's behind door number one. The good prize,

01:36:00.160 --> 01:36:04.560
the car, is behind door number one. So I'm going to choose door number one. Monty Hall opens door

01:36:04.560 --> 01:36:08.640
number three, and shows me nothing there. Should I trade for door number two? Even though I know

01:36:08.640 --> 01:36:12.560
the good prize in door number one, and then the large language mall say, yes, you should trade,

01:36:12.560 --> 01:36:19.680
because it just goes through the forms that it's seen before so many times on these cases,

01:36:19.680 --> 01:36:24.400
where it, yes, you should trade, because your odds have shifted from one in three now to two out

01:36:24.400 --> 01:36:29.440
of three, to being that thing. It doesn't have any way to remember that actually you have a

01:36:29.440 --> 01:36:35.120
100% probability behind that door number one. You know that. That's not part of the scheme that

01:36:35.120 --> 01:36:40.160
it's seen hundreds and hundreds of times before. And so you can't, even if you try to explain to

01:36:40.160 --> 01:36:45.520
it that it's wrong, that they can't do that, it'll just keep giving you back the problem.

01:36:45.520 --> 01:36:49.200
But it's also possible that a larger language model would be aware of the fact that there's

01:36:49.200 --> 01:36:57.440
sometimes over a representation of a particular kind of formulation, and it's easy to get tricked

01:36:57.440 --> 01:37:04.560
by that. And so you could see if they get larger and larger models be a little bit more skeptical.

01:37:04.560 --> 01:37:13.360
So you see over a representation. So it just feels like form can, training on form can go

01:37:13.360 --> 01:37:22.320
really far in terms of being able to generate things that look like the thing understands

01:37:23.200 --> 01:37:32.560
deeply the underlying world model of the kind of mathematical world, physical world,

01:37:33.440 --> 01:37:38.640
psychological world that would generate these kinds of sentences. It just feels like you're

01:37:38.640 --> 01:37:44.080
creeping close to the meaning part, easily fooled, all this kind of stuff, but that's humans too.

01:37:44.960 --> 01:37:52.880
So it just seems really impressive how often it seems like it un-understands concepts.

01:37:54.160 --> 01:37:59.280
I mean, you don't have to convince me of that. I am very, very impressed, but does it,

01:37:59.280 --> 01:38:04.880
does it mean you're giving a possible world where maybe someone's going to train some other

01:38:04.880 --> 01:38:10.800
versions such that it'll be somehow abstracting away from types of forms? I mean, I don't think

01:38:10.800 --> 01:38:17.680
that's happened. No, no, no. I'm not saying that. I think when you just look at anecdotal examples

01:38:18.320 --> 01:38:22.720
and just showing a large number of them where it doesn't seem to understand and it's easily fooled,

01:38:23.280 --> 01:38:31.760
that does not seem like a scientific data-driven analysis of how many places is a damn impressive

01:38:32.480 --> 01:38:35.600
in terms of meaning and understanding and how many places is easily fooled.

01:38:36.560 --> 01:38:39.920
That's not the inference. So I don't want to make that, the inference I don't,

01:38:39.920 --> 01:38:43.760
I wouldn't want to make was that inference. The inference I'm trying to push is just that is it,

01:38:44.720 --> 01:38:49.520
is it like humans here? It's probably not like humans here. It's different. So humans don't make

01:38:49.520 --> 01:38:53.840
that error. If you explain that to them, they're not going to make that error. They don't make

01:38:53.840 --> 01:38:57.440
that error. And so that's something, it's doing something different from humans that they're

01:38:57.440 --> 01:39:02.160
doing in that case. What's the mechanism by which humans figure out that it's an error?

01:39:02.160 --> 01:39:06.640
I'm just saying the error there is like, if I explain to you there's 100% chance

01:39:06.640 --> 01:39:11.840
that the car is behind this case, this door, well, do you want to trade? If you'll say no.

01:39:11.840 --> 01:39:17.440
But this thing will say yes, because it's so, that trick, it's so wound up on the form

01:39:18.320 --> 01:39:23.280
that it's, that's an error that a human doesn't make, which is kind of interesting.

01:39:23.280 --> 01:39:25.920
Less likely to make, I should say. Yeah, less likely.

01:39:25.920 --> 01:39:28.480
Because like humans are very- Oh yeah.

01:39:29.120 --> 01:39:35.360
I mean, you're asking, you're asking humans, you're asking a system to understand 100%,

01:39:35.360 --> 01:39:38.480
like you're asking some mathematical concepts. And so like-

01:39:40.000 --> 01:39:45.760
Look, the places where large language models are, the form is amazing. So let's go back to

01:39:45.760 --> 01:39:50.000
nested structures, center embedded structures. Okay, if you ask a human to complete those,

01:39:50.000 --> 01:39:54.960
they can't do it. Neither can a large language model. They're just like humans in that. If you

01:39:54.960 --> 01:39:57.680
ask, if I ask a large language model- That's fascinating, by the way.

01:39:57.680 --> 01:40:01.680
The central embedding, the central embedding, it struggles with-

01:40:01.680 --> 01:40:04.960
Just like humans, exactly like humans. Exactly the same way as humans.

01:40:05.200 --> 01:40:11.360
And that's not trained. So they do exactly, so that is a similarity. So but then it's,

01:40:11.360 --> 01:40:15.600
that's not meaning, right? This is form. But when we get into meaning,

01:40:15.600 --> 01:40:20.080
this is where they get kind of messed up. When you start to saying, oh, what's behind this door?

01:40:20.080 --> 01:40:24.880
Oh, it's, you know, this is the thing I want. Humans don't mess that up as much, you know.

01:40:24.880 --> 01:40:31.200
Here, the form is just like, the form of the match is amazing, is similar, without being

01:40:31.200 --> 01:40:34.560
trained to do that. I mean, it's trained in the sense that it's getting lots of data,

01:40:34.560 --> 01:40:39.280
which is just like human data. But it's not being trained on, you know,

01:40:40.080 --> 01:40:44.160
bad sentences and being told what's bad. It just can't do those. It'll actually say things like,

01:40:44.160 --> 01:40:48.720
those are too hard for me to complete or something, which is kind of interesting.

01:40:48.720 --> 01:40:50.160
Actually, kind of, how does it know that? I don't know.

01:40:50.880 --> 01:40:58.320
But it really often doesn't just complete, very often says stuff that's true.

01:40:58.960 --> 01:41:04.880
And sometimes says stuff that's not true. And almost always the form is great.

01:41:05.760 --> 01:41:12.480
But it's still very surprising that with really great form, it's able to generate a lot of things

01:41:12.480 --> 01:41:20.480
that are true based on what is trained on and so on. So it's not just form that is generating.

01:41:21.280 --> 01:41:27.920
It's mimicking true statements from the internet. I guess the underlying idea

01:41:27.920 --> 01:41:33.200
there is that on the internet, truth is overrepresented versus falsehood.

01:41:33.200 --> 01:41:34.800
I think that's probably right. Yeah.

01:41:34.800 --> 01:41:38.880
So but the fundamental thing is trained on, you're saying is just form.

01:41:38.880 --> 01:41:41.280
I think so. Yeah. Yeah, I think so.

01:41:42.000 --> 01:41:47.040
Well, that's a sad, if that's, to me, that's still a little bit of open question. I probably

01:41:47.040 --> 01:41:54.080
lean agreeing with you, especially now you've just blown my mind that there's a separate

01:41:54.080 --> 01:42:00.720
module in the brain for language versus thinking. Maybe there's a fundamental part missing from

01:42:01.520 --> 01:42:06.880
the large language model approach that lacks the thinking, the reasoning capability.

01:42:08.240 --> 01:42:14.560
Yeah, that's what this group argues. So the same group, Fedorenko's group has a

01:42:14.560 --> 01:42:20.400
recent paper arguing exactly that. There's a guy called Kyle Mahwell who's here in Austin,

01:42:20.400 --> 01:42:24.960
Texas, actually. He's an old student of mine, but he's a faculty in linguistics at Texas,

01:42:24.960 --> 01:42:30.080
and he was the first author on that. That's fascinating. Still, to me, an open question.

01:42:31.120 --> 01:42:32.880
What do you have the interesting limits of LLMs?

01:42:34.800 --> 01:42:40.800
I don't see any limits to their form. Their form is perfect. Yeah, it's pretty much,

01:42:40.800 --> 01:42:44.960
I mean, it's close to- Well, you said ability to complete central embeddings.

01:42:44.960 --> 01:42:47.600
Yeah, it's just the same as humans. It seems the same.

01:42:47.600 --> 01:42:51.920
But that's not perfect, right? It should be- That's good. No, but I want to be like humans.

01:42:51.920 --> 01:42:56.160
I'm trying to, I want a model of humans. Oh, wait, wait, wait, wait, wait. Also,

01:42:56.160 --> 01:42:59.680
perfect is as close to humans as possible. I got it. Yeah.

01:42:59.680 --> 01:43:03.200
But you should be able to, if you're not human, you're like you're super human,

01:43:03.200 --> 01:43:06.000
you should be able to complete central embedded sentences, right?

01:43:06.640 --> 01:43:12.000
I mean, that's the mechanism is, if it's modeling some, I think it's kind of

01:43:12.000 --> 01:43:14.240
really interesting that it can't. That it's really interesting.

01:43:14.320 --> 01:43:18.560
It's more like, like I think it's potentially underlyingly modeling

01:43:18.560 --> 01:43:21.680
something like what the way the form is processed.

01:43:21.680 --> 01:43:26.000
The form of human language and how humans process the language.

01:43:26.000 --> 01:43:27.840
Yes. I think that's plausible.

01:43:27.840 --> 01:43:31.440
And how they generate language. Process language and general language, that's fascinating.

01:43:32.640 --> 01:43:38.640
So in that sense, they're perfect. If we can just linger on the center embedding thing,

01:43:38.640 --> 01:43:41.920
that's hard for LLMs to produce, and that seems really impressive because that's

01:43:41.920 --> 01:43:47.600
hard for humans to produce. And how does that connect to the thing we've been talking about

01:43:47.600 --> 01:43:54.640
before, which is the dependency grammar framework in which you view language and the finding that

01:43:54.640 --> 01:44:01.120
short dependencies seem to be a universal part of language. So why is it hard to complete center

01:44:01.120 --> 01:44:05.520
embeddings? So what I like about dependency grammar is it makes

01:44:05.680 --> 01:44:14.480
the cognitive cost associated with longer distance connections very transparent.

01:44:14.480 --> 01:44:18.720
Basically, as there's some, it turns out there is a cost associated with producing

01:44:18.720 --> 01:44:23.360
and comprehending connections between words, which are just not beside each other.

01:44:23.360 --> 01:44:28.560
The further apart they are, the worse it is according to, well, we can measure that.

01:44:28.560 --> 01:44:30.240
And there is a cost associated with that.

01:44:30.960 --> 01:44:34.960
Can you just linger on, what do you mean by cognitive cost and how do you measure it?

01:44:35.200 --> 01:44:39.520
You can measure it in a lot of ways. The simplest is just asking people to say

01:44:40.160 --> 01:44:46.880
whether how good a sentence sounds. We just ask, that's one way to measure, and you try to triangulate

01:44:46.880 --> 01:44:50.960
then across sentences and across structures to try to figure out what the source of that is.

01:44:50.960 --> 01:44:58.480
You can look at reading times in controlled materials, in certain kinds of materials,

01:44:58.480 --> 01:45:01.360
and then we can measure the dependency distances there.

01:45:01.760 --> 01:45:08.160
We can, there's a recent study which looked at, we're talking about the brain here,

01:45:08.160 --> 01:45:11.360
we could look at the language network, okay? We could look at the language network,

01:45:11.360 --> 01:45:16.480
and we could look at the activation in the language network, and how big the activation is

01:45:16.480 --> 01:45:20.960
depending on the length of the dependencies. And it turns out in just random sentences

01:45:20.960 --> 01:45:23.680
that you're listening to, if you're listening to, so it turns out there are people listening to

01:45:23.680 --> 01:45:33.120
stories here. And the longer the dependency is, the stronger the activation in the language

01:45:33.120 --> 01:45:37.280
network. And so there's some measure, there's a bunch of different measures we could do,

01:45:37.280 --> 01:45:42.000
that's a kind of a neat measure actually of actual activation in the brain.

01:45:42.000 --> 01:45:45.920
So that you can somehow in different ways convert it to a number. I wonder if there's a

01:45:45.920 --> 01:45:49.360
beautiful equation connecting cognitive costs and length of dependency,

01:45:49.440 --> 01:45:54.880
equals MC squared kind of thing. Yeah, it's complicated, but probably it's doable. I would

01:45:54.880 --> 01:46:00.960
guess it's doable. I tried to do that a while ago, and I was reasonably successful, but for

01:46:00.960 --> 01:46:04.720
some reason I stopped working on that. I agree with you that it would be nice to figure out.

01:46:04.720 --> 01:46:09.920
So there's like some way to figure out the cost. I mean, it's complicated. Another issue you raised

01:46:09.920 --> 01:46:15.360
before was like, how do you measure distance? Is it words? It probably isn't, is it part of the

01:46:15.360 --> 01:46:22.320
problem? Is that some words matter than more than others? And probably, meaning like nouns might

01:46:22.320 --> 01:46:26.080
matter depending, and then it maybe depends on which kind of noun. Is it a noun we've already

01:46:26.080 --> 01:46:31.280
introduced or a noun that's already been mentioned? Is it a pronoun versus a name? Like all these

01:46:31.280 --> 01:46:34.880
things probably matter. So probably the simplest thing to do is just like, oh, let's forget about

01:46:34.880 --> 01:46:42.240
all that and just think about words or morphemes. For sure. But there might be some insight in a

01:46:42.240 --> 01:46:52.320
kind of function that fits the data, meaning like what... I think it's an exponential. So we

01:46:52.320 --> 01:46:57.120
think it's probably an exponential such that the longer the distance, the less it matters.

01:46:57.120 --> 01:47:02.960
And so then it's the sum of those. That was our best guess a while ago. So you've got a bunch

01:47:02.960 --> 01:47:08.480
of dependencies. If you've got a bunch of them that are being connected at some point, at the ends

01:47:08.480 --> 01:47:15.280
of those, the cost is some exponential function of those is my guess. But because the reason it's

01:47:15.280 --> 01:47:20.080
probably an exponential is like, it's not just the distance between two words, because I can make a

01:47:20.080 --> 01:47:25.040
very, very long subject verb depends by adding lots and lots of noun phrases and prepositional

01:47:25.040 --> 01:47:30.080
phrases. And it doesn't matter too much. It's when you do nest it, when I have multiple of these,

01:47:30.720 --> 01:47:36.800
then things go really bad, go south. Probably somehow connected to working memory or something

01:47:37.360 --> 01:47:43.360
that's probably the function of the memory here is the access is trying to find those earlier

01:47:43.360 --> 01:47:48.400
things. It's kind of hard to figure out what was referred to earlier. Those are those connections.

01:47:48.400 --> 01:47:53.360
That's the sort of notion of working as opposed to a storagey thing, but trying to connect,

01:47:54.880 --> 01:47:59.200
retrieve those earlier words depending on what was in between. And then we're talking about

01:47:59.200 --> 01:48:04.240
interference of similar things in between. That's the right theory probably has that kind of notion

01:48:04.240 --> 01:48:08.800
and it is an interference of similar. And so I'm dealing with an abstraction over the right

01:48:08.800 --> 01:48:13.200
theory, which is just, it's count words, it's not right, but it's close. And then maybe you're

01:48:13.200 --> 01:48:18.800
right though, there's some sort of an exponential or something to figure out the total so we can

01:48:18.800 --> 01:48:24.800
figure out a function for any given sentence in any given language. But it's funny, people haven't

01:48:24.800 --> 01:48:29.760
done that too much, which I do think is, I'm interested that you find that interesting. I

01:48:29.760 --> 01:48:33.040
really find that interesting. And a lot of people haven't found it interesting. And I don't know

01:48:33.040 --> 01:48:36.480
why I haven't got people to want to work on that. I really like that too.

01:48:37.760 --> 01:48:41.040
That's a beautiful, in the underlying idea is beautiful that there's a cognitive

01:48:41.040 --> 01:48:45.920
cost that correlates with the length of dependency. It just, it feels like it's a deep,

01:48:45.920 --> 01:48:50.640
I mean, language is so fundamental to the human experience. And this is a nice clean

01:48:51.360 --> 01:48:58.880
theory of language where it's like, wow, okay. So like we like our words close together,

01:48:58.960 --> 01:49:02.720
dependent words close together. That's why I like it too. It's so simple.

01:49:02.720 --> 01:49:07.120
Yeah, the simplicity of the theory. And yet it explains some very complicated phenomena.

01:49:07.120 --> 01:49:11.440
If I write these very complicated sentences, it's kind of hard to know why they're so hard.

01:49:11.440 --> 01:49:16.480
And you can like, oh, nail it down. I can do like a, give you a math formula for why each one of

01:49:16.480 --> 01:49:20.960
them is bad and where. And that's kind of cool. I think that's very neat. Have you gone through

01:49:20.960 --> 01:49:27.600
the process? Is there like a, if you take a piece of text and then simplify, sort of like there's an

01:49:27.600 --> 01:49:35.040
average length of dependency, and then you like, you know, reduce it and see comprehension on the

01:49:35.040 --> 01:49:39.760
entire, not just a single sentence, but like, you know, you go from James Joyce to Hemingway or

01:49:39.760 --> 01:49:45.840
something. No, no, simple answer is no, that does, there's probably things you can do in that,

01:49:45.840 --> 01:49:50.160
in that kind of direction. That's fun. We might, you know, we're gonna talk about legalese at

01:49:50.160 --> 01:49:55.440
some point. And so we, maybe we'll talk about that kind of thinking with applied to legalese.

01:49:55.520 --> 01:49:58.080
Well, let's talk about legalese because you mentioned that as an exception,

01:49:58.080 --> 01:50:02.720
which is taking tangent upon tangent. That's an interesting one. You give it as an exception.

01:50:02.720 --> 01:50:08.240
It's an exception. That you say that most natural languages, as we've been talking about,

01:50:08.880 --> 01:50:14.800
have local dependencies with one exception, legalese. That's right. So what is legalese,

01:50:14.800 --> 01:50:19.920
first of all? Oh, well, legalese is what you think it is. It's just any legal language.

01:50:20.640 --> 01:50:24.720
I mean, like, I actually know very little about the kind of language that lawyers use.

01:50:24.720 --> 01:50:28.320
So I'm just talking about language in laws and language in contracts.

01:50:28.320 --> 01:50:28.800
Got it.

01:50:28.800 --> 01:50:34.000
So the stuff that you have to run into, we have to run into every other day or every day,

01:50:35.120 --> 01:50:40.720
and you skip over because it reads poorly. And or, you know, partly it's just long, right?

01:50:40.720 --> 01:50:45.440
There's a lot of text there that we don't really want to know about. And so, but the thing I'm

01:50:45.440 --> 01:50:51.600
interested in, so I've been working with this guy called Eric Martinez, who is a, he was a lawyer

01:50:52.160 --> 01:50:56.400
who was taking my class. I was teaching a psycholinguistics lab class. I haven't been

01:50:56.400 --> 01:51:00.800
teaching it for a long time at MIT. And he's a, he was a law student at Harvard. And he took the

01:51:00.800 --> 01:51:05.360
class because he had done some linguistics as an undergrad. And he was interested in the problem of

01:51:06.000 --> 01:51:12.800
why legalese sounds hard to understand, you know, why. And so why is it hard to understand and why

01:51:12.800 --> 01:51:17.280
do they write that way? If it is hard to understand, it seems apparent that it's hard to understand.

01:51:17.360 --> 01:51:24.800
The question is, why is it? And so we didn't know. And we did an evaluation of a bunch of contracts.

01:51:24.800 --> 01:51:28.960
Actually, we just took a bunch of random contracts, because I don't know, you know,

01:51:28.960 --> 01:51:33.760
there's contracts and laws might not be exactly the same, but contracts are kind of the things

01:51:33.760 --> 01:51:37.760
that most people have to deal with most of the time. And so that's kind of the most common

01:51:37.760 --> 01:51:43.760
thing that humans have, like humans, that adults in our industrialized society have to deal with

01:51:43.760 --> 01:51:49.680
a lot. And so that's what we pulled. And we didn't know what was hard about them. But it turns out

01:51:49.680 --> 01:51:54.960
that the way they're written is very center embedded, has nested structures in them. So

01:51:54.960 --> 01:51:58.960
it has low frequency words as well. That's not surprising. Lots of texts have low frequency,

01:51:58.960 --> 01:52:04.800
it does have surprising, slightly lower frequency words than other kinds of control texts, even

01:52:04.800 --> 01:52:10.000
sort of academic texts. Legalese is even worse. It is the worst that we weren't being able to find.

01:52:10.640 --> 01:52:14.720
You just reveal the game that lawyers are playing. They're optimizing a different...

01:52:14.720 --> 01:52:18.880
Well, you know, it's interesting. Now you're getting at why. And so, and I don't think...

01:52:18.880 --> 01:52:21.920
So now you're saying they're doing intentionally. I don't think they're doing intentionally.

01:52:21.920 --> 01:52:24.880
But let's... It's an emergent phenomena. Okay.

01:52:24.880 --> 01:52:29.200
Yeah, yeah, yeah. We'll get to that. We'll get to that. And so, but we wanted to see why. So we

01:52:29.200 --> 01:52:33.440
see what first as opposed... So because it turns out that we're not the first to observe that

01:52:33.440 --> 01:52:41.600
legalese is weird, like back to... Nixon had a plain language act in 1970, and Obama had one.

01:52:41.600 --> 01:52:47.600
And boy, a lot of these... A lot of presidents have said, oh, we've got to simplify legal language,

01:52:47.600 --> 01:52:52.240
must simplify it. But if you don't know how it's complicated, it's not easy to simplify it. You

01:52:52.240 --> 01:52:57.120
need to know what it is you're supposed to do before you can fix it. And so you need to cycle

01:52:57.120 --> 01:53:02.320
linguists to analyze the text and see what's wrong with it before you can fix it. You don't

01:53:02.320 --> 01:53:05.440
know how to fix it. How am I supposed to fix something? I don't know what's wrong with it.

01:53:05.440 --> 01:53:08.560
And so what we did was just... That's what we did. We figured out, well, it's okay. We just

01:53:08.560 --> 01:53:15.040
took a bunch of contracts, had people, and we encoded them for a bunch of features. And so

01:53:15.040 --> 01:53:19.440
another feature of the people, one of them was the center embedding. And so that is like basically

01:53:19.440 --> 01:53:27.280
how often a clause would intervene between a subject and a verb, for example. That's one kind

01:53:27.280 --> 01:53:33.600
of a center embedding of a clause. And turns out they're massively center embedded. So I think

01:53:33.600 --> 01:53:40.240
in random contracts and in random laws, I think you get about 70% or 70% of sentences

01:53:40.240 --> 01:53:44.960
have a center embedded clause, which is insanely high. If you go to any other text,

01:53:44.960 --> 01:53:50.320
it's down to 20% or something. It's so much higher than any control you can think of,

01:53:50.320 --> 01:53:55.520
including... You think, oh, people think, oh, technical, academic text, no, people don't write

01:53:55.520 --> 01:54:00.000
center embedded sentences in technical, academic texts. I mean, they do a little bit, but it's

01:54:00.000 --> 01:54:05.760
on the 20%, 30% realm as opposed to 70. And so there's that. And there's low frequency words.

01:54:05.760 --> 01:54:10.080
And then people, oh, maybe it's passive. People don't like the passive. Passive, for some reason,

01:54:10.080 --> 01:54:14.240
the passive voice in English has a bad rap. And I'm not really sure where that comes from.

01:54:16.240 --> 01:54:23.120
And there is a lot of passive. There's much more passive voice in legalese than there is

01:54:23.360 --> 01:54:25.920
in other texts. Passive voice accounts for some of the low frequency words.

01:54:25.920 --> 01:54:28.160
No, no, no, no. Those are separate. Those are separate.

01:54:28.160 --> 01:54:30.960
Oh, so passive voice sucks. Low frequency word sucks.

01:54:30.960 --> 01:54:32.400
Well, sucks are different. So these are different.

01:54:32.400 --> 01:54:33.520
That's a judgment on passive.

01:54:33.520 --> 01:54:36.160
Yeah, yeah, yeah. Drop the judgment. It's just like, these are frequent.

01:54:36.160 --> 01:54:41.200
These are things which happen in legalese texts. Then we can ask the dependent measure is like,

01:54:41.200 --> 01:54:45.520
how well you understand those things with those features. Okay. And so then,

01:54:45.520 --> 01:54:49.840
and it turns out the passive makes no difference. So it has a zero effect on your comprehension

01:54:49.840 --> 01:54:53.280
ability, on your recall ability. No, nothing at all. That means no effect.

01:54:54.400 --> 01:54:58.160
The words matter a little bit. They do low frequency words are going to hurt you in

01:54:58.160 --> 01:55:02.720
recall and understanding. But what really hurts is the central bedding.

01:55:02.720 --> 01:55:08.960
That kills you. That is like, that slows people down. That makes them very poor at understanding.

01:55:08.960 --> 01:55:12.800
That makes them, they can't recall what was said as well, nearly as well.

01:55:12.800 --> 01:55:16.160
And we did this not only on lay people. We didn't have a lot of lay people.

01:55:16.160 --> 01:55:21.120
We ran it on a hundred lawyers. We recruited lawyers from a wide range of

01:55:23.120 --> 01:55:28.000
sort of different levels of law firms and stuff. And they have the same pattern.

01:55:28.000 --> 01:55:32.960
So they also like, when they did this, I did not know what happened. I thought maybe they could

01:55:32.960 --> 01:55:37.360
process, they're used to legalese. They think you can process it just as well as it was normal.

01:55:37.360 --> 01:55:43.360
No, no, they're much better than lay people. So they're much, they can much better recall,

01:55:43.360 --> 01:55:48.320
much better understanding, but they have the same main effects as lay people, exactly the same.

01:55:48.320 --> 01:55:54.000
So they also much prefer the non-center. So we constructed non-center embedded versions of

01:55:54.000 --> 01:55:59.520
each of these. We constructed versions which have higher frequency words in those places.

01:55:59.520 --> 01:56:05.520
And we did, we un-passivized, we turned them into active versions. The passive active made no

01:56:05.520 --> 01:56:11.280
difference. The words made a little difference. And the un-center embedding makes big differences

01:56:11.280 --> 01:56:14.960
in all the populations. Un-center embedding. How hard is that process, by the way?

01:56:14.960 --> 01:56:19.120
It's not very hard. So I don't question, but how hard is it to detect center embedding?

01:56:19.120 --> 01:56:22.000
Oh, easy, easy to detect. That's just easy to parse. You just looking at long dependencies?

01:56:22.000 --> 01:56:26.800
Yeah, yeah. You can just, you can, so there's automatic parsers for English, which are pretty good.

01:56:26.800 --> 01:56:28.800
And they can detect center embedding. Oh, yeah. Very.

01:56:28.800 --> 01:56:32.240
Or, I guess, Nestle. Perfectly. Yeah, you learn pretty much.

01:56:32.240 --> 01:56:36.080
So you're not just looking for long dependencies. You're just literally looking for center embedding.

01:56:36.080 --> 01:56:39.280
Yeah, we are in this case, in these cases. But long dependencies are, they're highly

01:56:39.280 --> 01:56:44.800
correlated to this. So like a center embedding is a big bomb you throw inside of a sentence

01:56:44.800 --> 01:56:49.680
that just blows up the, that makes sure. Yeah. Can I read a sentence for you from these things?

01:56:49.680 --> 01:56:52.880
Sure. I see. I mean, this is just like one of the things that, this is just terrible.

01:56:52.880 --> 01:57:00.080
My eyes might glaze over in mid-sentence. No, I understand that. I mean, legally, this is hard.

01:57:00.080 --> 01:57:04.000
This is a go, because in the event that any payment or benefit by the company,

01:57:04.000 --> 01:57:08.080
all such payments and benefits, including the payments and benefits under section 3a here of

01:57:08.160 --> 01:57:12.640
being here and after referred to as a total payments, would be subject to the excise tax,

01:57:13.200 --> 01:57:17.840
then the cash severance payments shall be reduced. So that's something we pulled from a regular text,

01:57:17.840 --> 01:57:19.440
from a contract. Wow.

01:57:19.440 --> 01:57:23.520
And the center embedded bit there is just, for some reason, there's a definition.

01:57:24.080 --> 01:57:29.760
They throw the definition of what payments and benefits are in between the subject and the verbal.

01:57:29.760 --> 01:57:31.600
Let's, how about don't do that? Yeah.

01:57:31.600 --> 01:57:35.920
How about put the definition somewhere else as opposed to in the middle of the sentence?

01:57:35.920 --> 01:57:41.280
And so that's very, very common, by the way. That's what happens. You just throw your definitions,

01:57:41.280 --> 01:57:45.840
you use a word, a couple of words, and then you define it, and then you continue the sentence.

01:57:46.400 --> 01:57:49.600
Like, just don't write like that. And you ask, so then we asked lawyers, we thought,

01:57:49.600 --> 01:57:54.400
oh, maybe lawyers like this. Lawyers don't like this. They don't like this. They don't want to,

01:57:54.400 --> 01:57:59.600
they don't want to write like this. They, we asked them to rate materials which are with the same

01:57:59.600 --> 01:58:05.280
meaning with un-centered bed and center bed, and they much preferred the un-centered bed versions.

01:58:05.360 --> 01:58:08.480
On the comprehension, on the reading side. Yeah, well, and we asked them,

01:58:08.480 --> 01:58:12.080
we asked them, would you hire someone who writes like this or this? We asked them all kinds of

01:58:12.080 --> 01:58:16.640
questions, and they always preferred the less complicated version, all of them. So I don't

01:58:16.640 --> 01:58:20.640
even think they want it this way. Yeah, but how did it happen? How did it happen? That's a very good

01:58:20.640 --> 01:58:27.360
question. And the answer is, they still don't know. But I have some theories. Well, our best

01:58:27.360 --> 01:58:33.360
theory at the moment is that there's actually some kind of a performative meaning in the

01:58:33.360 --> 01:58:37.920
center embedding and the style which tells you it's legalese. We think that that's the kind

01:58:37.920 --> 01:58:43.600
of a style which tells you it's legalese. Like that's a reasonable guess. And maybe it's just,

01:58:43.600 --> 01:58:48.880
so for instance, if you're like, it's like a magic spell. So we kind of call this the magic

01:58:48.880 --> 01:58:53.120
spell hypothesis. So when you give them, when you tell someone to put a magic spell on someone,

01:58:53.120 --> 01:58:58.480
what do you do? They, you know, people know what a magic spell is and they do a lot of rhyming.

01:58:58.480 --> 01:59:02.080
You know, that's kind of what people will tend to do. They'll do rhyming and they'll do sort of

01:59:02.160 --> 01:59:07.200
like some kind of poetry kind of thing. Abracadabra type of thing. Yeah. And maybe that's,

01:59:07.200 --> 01:59:13.040
there's a syntactic sort of reflex here of a magic spell which is center embedding. And so

01:59:13.040 --> 01:59:17.600
that's like, oh, it's trying to like tell you this is like, this is something which is true,

01:59:17.600 --> 01:59:23.120
which is what the goal of law is, right, is telling you something that we want you to believe as

01:59:23.120 --> 01:59:27.680
certainly true, right? That's what legal contracts are trying to enforce on you, right?

01:59:27.680 --> 01:59:33.280
And so maybe that's like a form which has, this is like an abstract, very abstract form,

01:59:33.280 --> 01:59:36.880
center embedding, which has a, has a, has a meaning associated with it. Well,

01:59:37.600 --> 01:59:45.120
don't you think there's an incentive for lawyers to generate things that are hard to understand?

01:59:45.120 --> 01:59:48.960
That was our, one of our working hypotheses. We just couldn't find any evidence of that.

01:59:48.960 --> 01:59:53.840
No, lawyers also don't understand it. But you're creating space, why you yourself,

01:59:54.800 --> 01:59:59.520
but I mean, you ask in a communist Soviet Union, the individual members,

02:00:00.560 --> 02:00:07.360
their self-report is not going to correctly reflect what is broken about the gigantic bureaucracy

02:00:07.360 --> 02:00:13.680
that leads to Chernobyl or something like this. I think the incentives under which you

02:00:14.400 --> 02:00:20.080
operate are not always transparent to the members within that system. So like, it just

02:00:20.800 --> 02:00:27.120
feels like a strange coincidence that like, there is benefit if you just zoom out, look at the

02:00:27.120 --> 02:00:32.880
system as opposed to asking individual lawyers that making something hard to understand is going

02:00:32.880 --> 02:00:40.000
to make a lot of people money. Like there's going to, you're going to need a lawyer to figure that

02:00:40.000 --> 02:00:44.400
out, I guess, from the perspective of the individual, but then that could be the performative aspect.

02:00:44.400 --> 02:00:48.640
It could be as opposed to the incentive driven to be complicated. It could be performative

02:00:48.640 --> 02:00:54.640
to where we lawyers speak in this sophisticated way and you regular humans don't understand it,

02:00:54.640 --> 02:00:58.160
so you need to hire a lawyer. Yeah, I don't know which one it is, but it's suspicious.

02:00:59.120 --> 02:01:04.480
Suspicious that it's hard to understand and that everybody's eyes glaze over and they don't read.

02:01:04.480 --> 02:01:09.520
I'm suspicious as well. I'm still suspicious. And I hear what you're saying. It could be kind of a,

02:01:09.520 --> 02:01:13.600
you know, no individual and even average of individuals, it could just be a few bad apples

02:01:13.600 --> 02:01:19.360
in a way which are driving the effect in some way. Influential bad apples at the sort of,

02:01:20.240 --> 02:01:25.520
that everybody looks up to whatever they're like in central figures and how, you know.

02:01:25.520 --> 02:01:31.120
It turns out, but it is kind of interesting that among our 100 lawyers, they did not share

02:01:31.120 --> 02:01:36.880
it with us. They really didn't like it. And they weren't better than regular people at

02:01:36.880 --> 02:01:41.120
comprehending it or they were on average better. But they had the same difference.

02:01:42.000 --> 02:01:49.520
Exactly, same difference. But they wanted it fixed. And so that gave us hope that

02:01:50.160 --> 02:01:55.760
because it actually isn't very hard to construct a material which is uncenter embedded and has

02:01:55.760 --> 02:01:59.280
the same meaning, it's not very hard to do. Just basically in that situation, just putting

02:01:59.280 --> 02:02:02.960
definitions outside of the subject verb relation in that particular example, and that's kind of,

02:02:03.520 --> 02:02:07.360
that's pretty general. What they're doing is just throwing stuff in there, which you didn't

02:02:07.360 --> 02:02:12.480
have to put in there. There's extra words involved. Typically, you may need a few extra

02:02:12.480 --> 02:02:17.600
words sort of to refer to the things that you're defining outside in some way, because if you

02:02:17.600 --> 02:02:24.400
only use it in that one sentence, then there's no reason to introduce extra terms. So we might

02:02:24.400 --> 02:02:30.160
have a few more words, but it'll be easier to understand. So I mean, I have hope that now

02:02:30.160 --> 02:02:35.200
that maybe we can make legalese less convoluted in this way.

02:02:35.200 --> 02:02:40.080
So maybe the next president in the United States can, instead of saying generic things, say,

02:02:40.080 --> 02:02:47.600
I ban center embeddings and make Ted the language czar of the U.S.

02:02:47.600 --> 02:02:50.480
Eric Martinez is the guy you should really put in there.

02:02:53.200 --> 02:02:57.200
But center embeddings are the bad thing to have. That's right.

02:02:57.200 --> 02:03:00.080
So you can get rid of that. That'll do a lot of it. That'll fix a lot.

02:03:00.640 --> 02:03:06.560
That's fascinating. That is so fascinating. And it is really fascinating on many fronts that humans

02:03:06.560 --> 02:03:10.160
are just not able to deal with this kind of thing. And that language, because of that,

02:03:10.160 --> 02:03:15.600
evolved in the way you did. It's fascinating. So one of the mathematical formulations you have

02:03:16.240 --> 02:03:20.800
when talking about languages communication is, let's say, do you have noisy channels?

02:03:22.160 --> 02:03:27.600
What's a noisy channel? So that's about communication. And so this is going back

02:03:27.600 --> 02:03:35.760
to Shannon. So Claude Shannon was a student at MIT in the 40s. And so he wrote this very

02:03:35.760 --> 02:03:42.400
influential piece of work about communication theory or information theory. And he was interested

02:03:42.400 --> 02:03:47.840
in human language, actually. He was interested in this problem of communication, of getting a

02:03:48.880 --> 02:03:54.720
message from my head to your head. And he was concerned or interested in

02:03:55.680 --> 02:04:01.840
what was a robust way to do that. And so that assuming we both speak the same language, we

02:04:01.840 --> 02:04:09.440
both already speak English, whatever the language is, we speak that. What is a way that I can say

02:04:09.440 --> 02:04:15.920
the language so that it's most likely to get the signal that I want to you? And then the problem

02:04:15.920 --> 02:04:24.000
there in the communication is the noisy channel. There's a lot of noise in the system. I don't

02:04:24.000 --> 02:04:29.600
speak perfectly. I make errors. That's noise. There's background noise. You know that.

02:04:30.880 --> 02:04:34.320
Literal background noise. There is like white noise in the background or some other kind of

02:04:34.320 --> 02:04:39.840
noise. There's some speaking going on that you're at a party. That's background noise. You try to

02:04:39.840 --> 02:04:42.960
hear someone. It's hard to understand them because there's all this other stuff going on in the

02:04:42.960 --> 02:04:50.720
background. And then there's noise on the receiver side so that you have some problem

02:04:50.800 --> 02:04:55.280
maybe understanding me for stuff that's just internal to you in some way. So you've got some

02:04:55.280 --> 02:05:00.720
other problems, whatever, with understanding for whatever reasons. Maybe you've had too much to

02:05:00.720 --> 02:05:05.200
drink. Who knows why you're not able to pay attention to the signal? So that's the noisy

02:05:05.200 --> 02:05:09.520
channel. And so that language, if it's a communication system, we are trying to

02:05:10.400 --> 02:05:15.440
optimize in some sense the passing of the message from one side to the other. And

02:05:16.240 --> 02:05:23.920
so, I mean, one idea is that maybe aspects of word order, for example, might have optimized

02:05:23.920 --> 02:05:29.840
in some way to make language a little more easy to be passed from speaker to listener.

02:05:29.840 --> 02:05:34.400
And so Shannon's the guy that did the stuff way back in the forties. It's very interesting.

02:05:34.400 --> 02:05:39.600
Historically, he was interested in working in linguistics. He was in MIT. And this was his

02:05:39.600 --> 02:05:44.880
master's thesis of all things. It's crazy how much he did for his master's thesis. In 1948,

02:05:44.880 --> 02:05:49.840
I think, or 49 or something. And he wanted to keep working in language. And it just wasn't a

02:05:49.840 --> 02:05:56.800
popular communication as a reason, a source for what language was wasn't popular at the time.

02:05:56.800 --> 02:06:01.520
So Chomsky was becoming, it was moving in there. And he just wasn't able to get a handle there,

02:06:01.520 --> 02:06:08.160
I think. And so he moved to Bell Haps and worked on communication from a mathematical point of

02:06:08.160 --> 02:06:13.600
view and did all kinds of amazing work. And so he's just more on the signal side versus

02:06:13.680 --> 02:06:18.480
like the language side. It would have been interesting to see if you proceed the language

02:06:18.480 --> 02:06:22.640
side. That's really interesting. Yeah, he was interested in that. His examples in the forties

02:06:22.640 --> 02:06:30.000
are kind of like, they're very language like things. We can kind of show that there's a

02:06:30.000 --> 02:06:35.680
noisy channel process going on in when you're listening to me, you can often sort of guess

02:06:35.680 --> 02:06:42.640
what I meant by what you think I meant given what I said. And I mean, with respect to sort of

02:06:42.640 --> 02:06:46.800
why language looks the way it does, we might, there might be sort of, as I alluded to, there

02:06:46.800 --> 02:06:52.640
might be ways in which word order is somewhat optimized for, because of the noisy channel in

02:06:52.640 --> 02:06:57.840
some way. I mean, that's really cool to sort of model if you don't hear certain parts of a sentence

02:06:58.560 --> 02:07:02.480
or have some probability of missing that part, like how do you construct a language that's

02:07:02.480 --> 02:07:06.960
resilient to that? That's somewhat robust to that. Yeah, that's the idea. And then you're kind of

02:07:06.960 --> 02:07:12.560
saying like the word order and the syntax of language, the dependency length are all

02:07:13.120 --> 02:07:17.840
helpful. Yeah, well, the dependency length is really about memory, right? I think that's like

02:07:17.840 --> 02:07:22.880
about sort of what's easier or harder to produce in some way. And these other ideas are about sort

02:07:22.880 --> 02:07:28.960
of robustness to communication. So the problem of potential loss of loss of signal due to noise.

02:07:28.960 --> 02:07:34.080
It's so that there may be aspects of word order, which is somewhat optimized for that. And, you

02:07:34.080 --> 02:07:38.640
know, we have this one guess in that, and these are kind of just so stories. I have to be, you

02:07:38.640 --> 02:07:42.720
know, pretty frank, they're not like, I can't show this is true. All we can do is like look at the

02:07:42.720 --> 02:07:47.040
current languages of the world. This is like, we can't sort of see how languages change or anything

02:07:47.040 --> 02:07:51.520
because we've got these snapshots of a few, you know, hundred or a few thousand languages.

02:07:51.520 --> 02:07:57.600
We don't really, we can't do the right kinds of modifications to test these things experimentally.

02:07:57.600 --> 02:08:02.320
And so, you know, so just take this with a grain of salt, okay, from here, this stuff. The dependency

02:08:02.320 --> 02:08:07.200
stuff I can, I'm much more solid on. I'm like, here's what the lengths are, and here's what's

02:08:07.200 --> 02:08:10.880
hard. Here's what's easy. And this is a reasonable structure. I think I'm pretty reasonable. Here's

02:08:10.880 --> 02:08:16.160
like, why, you know, why does the word order look the way it does? We're now into shaky territory,

02:08:16.160 --> 02:08:20.720
but it's kind of cool. But we're talking about, just to be clear, we're talking about maybe just

02:08:20.720 --> 02:08:25.360
actually the sounds of communication. Like you and I are sitting in the bar, it's very loud,

02:08:25.360 --> 02:08:33.120
and you model with a noisy channel, the loudness, the noise, and we have the signal that's coming

02:08:33.200 --> 02:08:38.240
across. And you're saying word order might have something to do with optimizing that.

02:08:38.240 --> 02:08:38.800
Yes. Yes.

02:08:38.800 --> 02:08:39.920
There's a presence of noise. Yes.

02:08:39.920 --> 02:08:40.800
Yes. Yeah.

02:08:40.800 --> 02:08:43.760
It's really interesting. I mean, to me, it's interesting how much you can load into the

02:08:43.760 --> 02:08:48.720
noisy channel. Like how much can you bake in? You said like, you know, cognitive load on the

02:08:48.720 --> 02:08:49.680
receiver end.

02:08:49.680 --> 02:08:54.000
We think that those are, there's three, at least three different kinds of things going on there.

02:08:54.000 --> 02:08:56.320
And we probably don't want to treat them all as the same.

02:08:56.320 --> 02:08:56.640
Sure.

02:08:56.640 --> 02:09:00.640
And so I think that you, you know, the right model, a better model of a noisy channel would

02:09:01.200 --> 02:09:05.040
have three different sources of noise, which are background noise,

02:09:05.760 --> 02:09:10.800
speaker, inherent noise, and listener, inherent noise. And those are not,

02:09:10.800 --> 02:09:11.680
those are all different things.

02:09:11.680 --> 02:09:15.920
Sure. But then underneath it, there's a million other subsets of like what?

02:09:15.920 --> 02:09:16.720
Oh yeah. That's true.

02:09:16.720 --> 02:09:21.760
On the receiving, I mean, I just mentioned cognitive load on both sides. Then there's like

02:09:23.360 --> 02:09:28.000
speech impediments or just everything. World view, I mean, on the meeting,

02:09:28.080 --> 02:09:31.920
we start to creep into the meeting realm of like, we have different world views.

02:09:31.920 --> 02:09:34.880
Well, how about just form still though? Like just what language you know?

02:09:34.880 --> 02:09:39.520
Like, so how well you know the language? And so if it's second language for you versus first

02:09:39.520 --> 02:09:44.240
language, and how maybe what other languages you know, these are still just form stuff.

02:09:44.240 --> 02:09:48.880
And that's like potentially very informative. And, you know, how old you are, these things

02:09:48.880 --> 02:09:53.680
probably matter, right? So like a child learning a language is, is a, you know, as a noisy

02:09:54.240 --> 02:09:58.560
representation of English grammar, you know, depending on how old they are.

02:09:59.200 --> 02:10:02.320
So maybe when they're six, they're perfectly formed. But

02:10:03.200 --> 02:10:08.320
you mentioned one of the things is like a way to measure the language is learning problems.

02:10:08.960 --> 02:10:12.880
So like, what's the correlation between everything we've been talking about and how

02:10:12.880 --> 02:10:21.040
easy it is to learn a language? So is like a short dependencies correlated to ability to

02:10:21.040 --> 02:10:26.400
learn a language? Is there some kind of, or like the dependency grammars, there's some kind of

02:10:27.440 --> 02:10:30.320
connection there? How easy it is to learn?

02:10:30.320 --> 02:10:34.720
Yeah, well, all the languages in the world's language, none is right now,

02:10:34.720 --> 02:10:39.120
we know is any better than any other with respect to sort of optimizing dependency lengths,

02:10:39.120 --> 02:10:42.240
for example, they're all kind of do it, do it well, they all keep low.

02:10:42.720 --> 02:10:47.600
It's so that I think of every human language is some kind of an opposite sort of an optimization

02:10:47.600 --> 02:10:53.040
problem, a complex optimization problem to this communication problem. And so they've,

02:10:53.040 --> 02:10:57.120
like they've solved it, you know, they're just sort of noisy solutions to this problem of

02:10:57.120 --> 02:11:00.080
communication. There's just so many ways you can do this.

02:11:00.080 --> 02:11:03.920
So they're not optimized for learning, they're probably less for communication.

02:11:03.920 --> 02:11:06.560
And learning. So yes, one of the factors which,

02:11:07.120 --> 02:11:11.280
yeah, so learning is messing this up a bit. And so, so for example,

02:11:11.280 --> 02:11:15.760
if it were just about minimizing dependency lengths, and that was all that matters,

02:11:15.760 --> 02:11:21.520
you know, then we, you know, so then we might find grammars which didn't have regularity

02:11:21.520 --> 02:11:26.560
in their rules. But languages always have regularity in their rules. So what I mean by

02:11:26.560 --> 02:11:31.360
that is that if I wanted to say something to you in the optimal way to say it was,

02:11:31.360 --> 02:11:34.400
it would really matter to me, all that mattered was keeping the dependencies

02:11:35.280 --> 02:11:40.480
as close together as possible. Then I would have a very lack set of free structure or dependency

02:11:40.480 --> 02:11:44.160
rule. It wouldn't have very many of those. I would have very little of that. And I would

02:11:44.160 --> 02:11:48.240
just put the words as close to the things that refer to the things that are connected right

02:11:48.240 --> 02:11:52.560
beside each other. But we don't do that. Like there are, like there are word order rules, right?

02:11:52.560 --> 02:11:56.640
So they're very, and depending on the language, they're more and less strict, right? So you speak

02:11:56.640 --> 02:12:01.040
Russian, they're less strict than English. English is very rigid word order rules. We

02:12:01.040 --> 02:12:07.280
order things in a very particular way. And so why do we do that? Like that's probably not about

02:12:08.160 --> 02:12:11.360
communication. That's probably about learning. I mean, then we're talking about learning. It's

02:12:11.440 --> 02:12:17.760
probably easier to learn regular things, things which are very predictable and easy to, so that's

02:12:17.760 --> 02:12:20.880
probably about learning is our guess, because that can't be about communication.

02:12:20.880 --> 02:12:26.320
Can it be just noise? Can it be just the messiness of the development of a language?

02:12:26.320 --> 02:12:30.080
Well, if it were just a communication, then we should have languages which have very,

02:12:30.080 --> 02:12:34.640
very free word order. And we don't have that. We have free error, but not free. Like there's

02:12:34.640 --> 02:12:40.640
always- Well, no, but what I mean by noise is like cultural, like sticky cultural things,

02:12:40.640 --> 02:12:46.960
like the way, the way you communicate, just there's a stickiness to it. That it's an imperfect,

02:12:47.520 --> 02:12:53.120
it's a noisy, it's stochastic. The function over which you're optimizing is very noisy.

02:12:54.080 --> 02:13:00.160
So, because I don't, it feels weird to say that learning is part of the objective function,

02:13:00.160 --> 02:13:06.000
because some languages are way harder to learn than others, right? Or is that, that's not true.

02:13:06.000 --> 02:13:08.880
That's interesting. I mean, that's the public perception, right?

02:13:08.880 --> 02:13:12.640
Yes, that's true for a second language. For a second language.

02:13:12.640 --> 02:13:17.040
But that depends on what you started with, right? So, it really depends on how close

02:13:17.040 --> 02:13:21.520
that second language is to the first language you've got. And so, yes, it's very, very hard

02:13:21.520 --> 02:13:26.240
to learn Arabic if you've started with English, or it's harder to learn Japanese,

02:13:26.240 --> 02:13:31.680
or if you've started with Chinese, I think is the worst. There's like Defense Language Institute

02:13:31.680 --> 02:13:37.840
in the United States has like a list of how hard it is to learn what language from English.

02:13:37.840 --> 02:13:40.240
I think Chinese is the worst. But that's the second language.

02:13:40.240 --> 02:13:44.640
You're saying babies don't care? No. There's no evidence that there's anything harder,

02:13:44.640 --> 02:13:49.360
easier, but any baby, any language learned, like three or four, they speak that language.

02:13:49.360 --> 02:13:53.440
And so, there's no evidence of anything harder, easier, but any human language. They're all

02:13:53.440 --> 02:14:00.720
kind of equal. To what degree is language, this is returning to Chomsky a little bit, is innate.

02:14:01.520 --> 02:14:05.280
You said that for Chomsky, he used the idea that language is,

02:14:05.280 --> 02:14:08.720
some aspects of language are in need to explain away certain things that are observed.

02:14:09.680 --> 02:14:15.200
How much are we born with language at the core of our mind, brain?

02:14:16.880 --> 02:14:23.120
I mean, I, you know, the answer is I don't know, of course, but the, I mean, I like to,

02:14:23.120 --> 02:14:28.160
I'm an engineer at heart, I guess, and I sort of think it's fine to postulate that a lot of

02:14:28.160 --> 02:14:33.120
it's learned. And so, I'm guessing that a lot of it's learned. So, I think the reason Chomsky

02:14:33.120 --> 02:14:40.960
went with innateness is because he hypothesized movement in his grammar. He was interested in

02:14:40.960 --> 02:14:45.360
grammar and movement's hard to learn. I think he's right. Movement is a hard thing to learn,

02:14:45.360 --> 02:14:49.520
to learn these two things together and how they interact. And there's like a lot of ways in which

02:14:49.520 --> 02:14:52.960
you might generate exactly the same sentences. And it's like really hard. And so, he's like,

02:14:52.960 --> 02:14:58.480
oh, I guess it's learned. Sorry, I guess it's not learned, it's innate. And if you just throw out

02:14:58.480 --> 02:15:04.320
the movement and just think about that in a different way, you know, then you get some messiness.

02:15:04.880 --> 02:15:10.560
But the messiness is human language, which it actually fits better. That messiness isn't a

02:15:10.560 --> 02:15:20.560
problem. It's actually, it's a valuable asset of the theory. And so, I think I don't really see a

02:15:20.560 --> 02:15:25.280
reason to postulate much innate structure. And that's kind of why I think these large language

02:15:25.360 --> 02:15:30.800
models are learning so well, is because I think you can learn the form, the forms of human language

02:15:30.800 --> 02:15:34.400
from the input. I think that's like, it's likely to be true.

02:15:34.400 --> 02:15:37.200
So that part of the brain that lights up when you're doing all the comprehension,

02:15:37.200 --> 02:15:40.240
that could be learned. That could be just, you don't need, you don't need any.

02:15:40.240 --> 02:15:46.640
It doesn't have to be innate. So, like lots of stuff is modular in the brain that's learned.

02:15:46.640 --> 02:15:51.440
It doesn't have to, you know, so there's something called the visual word form area in the back.

02:15:51.520 --> 02:15:56.640
And so, it's in the back of your head, near the, you know, the visual cortex, okay? And that

02:15:57.360 --> 02:16:02.240
is very specialized language, sorry, very specialized brain area, which does

02:16:04.080 --> 02:16:08.000
visual word processing if you read, if you're a reader, okay? If you don't read, you don't have it,

02:16:08.000 --> 02:16:12.560
okay? Guess what? You spend some time learning to read and you develop that brain area,

02:16:12.560 --> 02:16:16.960
which does exactly that. And so, these, the modularization is not evidence for

02:16:16.960 --> 02:16:21.200
innateness. So, the modularization of a language area doesn't mean we're born with it.

02:16:21.200 --> 02:16:26.880
We could have easily learned that. We might have been born with it. We just don't know at this

02:16:26.880 --> 02:16:31.680
point. We might very well have been born with this left lateralized area. I mean, there's like

02:16:31.680 --> 02:16:37.440
a lot of other interesting components here, features of this kind of argument. So, some people

02:16:38.080 --> 02:16:42.640
get a stroke or something goes really wrong on the left side, where the left, where the language

02:16:42.640 --> 02:16:47.440
area would be. And that, and that isn't there. It's not, not available. And it develops just

02:16:47.440 --> 02:16:52.560
fine on the right. So, it's no lie. So, it's not about the left. It goes to the left. Like,

02:16:52.560 --> 02:16:57.840
this is a very interesting question. It's like, why is the, why are any of the brain areas the

02:16:57.840 --> 02:17:02.800
way that they are? And how, how, how did they come to be that way? And, you know, there's these

02:17:02.800 --> 02:17:07.200
natural experiments, which happen where people get these, you know, strange events in their

02:17:07.200 --> 02:17:12.720
brains at very young ages, which wipe out sections of their brain and, and they behave

02:17:12.720 --> 02:17:16.560
totally normally and no one knows anything was wrong. And we find out later, because they happen

02:17:16.560 --> 02:17:20.640
to be accidentally scanned for some reason. It's like, what, what happened to your left hemisphere?

02:17:20.640 --> 02:17:23.760
It's missing. There's not many people who have missed their whole left hemisphere, but they'll

02:17:23.760 --> 02:17:27.840
be missing some other section of their left or their right. And they behave absolutely normally,

02:17:27.840 --> 02:17:33.440
we would never know. So, that's like a very interesting, you know, current research. You know,

02:17:33.440 --> 02:17:37.920
this is another project that this person in Federico is working on. She's got all these people

02:17:37.920 --> 02:17:45.040
contacting her because she's scanned some people who have been missing sections, one person missing,

02:17:45.040 --> 02:17:49.520
missed a section of her brain and was scanned in her lab. And she, and she happened to be a writer

02:17:49.520 --> 02:17:55.280
for the New York Times. And there was an article in the New York Times about, about the, just about

02:17:55.280 --> 02:18:00.720
the scanning procedure and, and about what might be learned about by sort of the general process

02:18:00.720 --> 02:18:06.080
of MRI and language and that's her language. And, and because she's writing for the New York Times,

02:18:06.080 --> 02:18:11.920
then she, all these people started writing to her who also have similar, similar kinds of deficits

02:18:11.920 --> 02:18:18.080
because they've been, you know, accidentally, you know, to scan for some reason and, and found

02:18:18.080 --> 02:18:23.120
out they're missing some section. And they, they volunteer to be scanned. These are natural

02:18:23.120 --> 02:18:26.960
experiments. Natural experiments. They're kind of messy, but natural experiments kind of cool.

02:18:27.760 --> 02:18:33.360
She calls them interesting brains. The first few hours, days, months of human life are fascinating.

02:18:33.360 --> 02:18:37.040
It's like, well, inside the womb, actually, like that development,

02:18:39.440 --> 02:18:45.040
that machinery, whatever that is, seems to create powerful humans that are able to speak,

02:18:45.040 --> 02:18:49.680
comprehend, think, all that kind of stuff, no matter what happened, not no matter what, but

02:18:49.760 --> 02:18:56.960
robust to the different ways that the brain might be damaged and so on. That's really,

02:18:56.960 --> 02:19:02.800
that's really interesting. But what would Chomsky say about the fact, the thing you're saying now,

02:19:02.800 --> 02:19:09.760
that language is, seems to be happening separate from thought? Because as far as I understand,

02:19:09.760 --> 02:19:14.320
maybe you can correct me, he thought that language underpins. Yeah, he thinks so. I don't know what

02:19:14.320 --> 02:19:20.320
he'd say. He would be surprised because for him, the idea is that language is a sort of the foundation

02:19:20.320 --> 02:19:27.440
of thought. That's right. Absolutely. And it's pretty mind blowing to think that it could be

02:19:27.440 --> 02:19:32.480
completely separate from thought. That's right. But so, you know, he's basically a philosopher,

02:19:32.480 --> 02:19:35.360
philosopher of language in a way, thinking about these things. It's a fine thought.

02:19:36.480 --> 02:19:41.760
You can't test it in his methods. You can't do a thought experiment to figure that out.

02:19:41.760 --> 02:19:47.360
You need a scanner. You need brain damage people. You need something. You need ways to measure that.

02:19:47.360 --> 02:19:53.920
And that's what, you know, fMRI offers as a, and, you know, patients are a little messier.

02:19:53.920 --> 02:20:00.240
fMRI is pretty unambiguous, I'd say. It's like very unambiguous. There's no way to say that

02:20:00.240 --> 02:20:05.440
the language network is doing any of these tasks. There's, like, you should look at those data.

02:20:05.440 --> 02:20:09.760
It's like, there's no chance that you can say that those networks are overlapping. They're not

02:20:09.760 --> 02:20:14.160
overlapping. They're just, like, completely different. And so, you know, so the, you know,

02:20:14.160 --> 02:20:17.840
you can always make, you know, it's only two people. It's four people or something for the

02:20:18.560 --> 02:20:22.640
patients. And there's something special about them we don't know. But these are just random people.

02:20:23.280 --> 02:20:28.640
And with lots of them, and you find always the same effects. And it's very robust, I'd say.

02:20:28.640 --> 02:20:35.440
What's a fessing effect? What's the, you mentioned Bolivia. What's the connection between

02:20:36.000 --> 02:20:45.440
culture and language? You've also mentioned that, you know, much of our study of language

02:20:45.440 --> 02:20:52.720
comes from W-E-I-R-D, weird people, western educated, industrialized, rich, and democratic.

02:20:53.680 --> 02:21:00.400
So when you study, like, remote cultures, such as around the Amazon jungle, what can you learn

02:21:00.480 --> 02:21:08.000
about language? So that term weird is from Joe Henrich. He's at Harvard. He's a Harvard

02:21:08.000 --> 02:21:15.520
evolutionary biologist. And so he works on lots of different topics. And he basically was pushing

02:21:15.520 --> 02:21:21.680
that observation that we should be careful about the inferences we want to make when we're talking

02:21:21.680 --> 02:21:28.640
in psychology or, yeah, mostly in psychology, I guess, about humans if we're talking about,

02:21:29.520 --> 02:21:34.160
undergrads at MIT and Harvard. Those aren't the same, right? These aren't the same things.

02:21:34.160 --> 02:21:39.760
And so if you want to make inferences about language, for instance, there's a lot of very,

02:21:40.320 --> 02:21:45.360
a lot of other kinds of languages in the world, then English and French and Chinese, you know.

02:21:45.360 --> 02:21:52.000
And so maybe for language, we care about how culture, because cultures can be very,

02:21:52.000 --> 02:21:54.880
I mean, of course, English and Chinese cultures are very different. But

02:21:55.520 --> 02:22:01.280
you know, hunter-gatherers are much more different in some ways. And so if culture

02:22:01.280 --> 02:22:06.960
hasn't affected what language is, then we kind of want to look there as well as looking. It's

02:22:06.960 --> 02:22:10.320
not like the industrialized cultures aren't interesting. Of course they are. But we want

02:22:10.320 --> 02:22:15.120
to look at non-industrialized cultures as well. And so I've worked with two. I've worked with

02:22:15.120 --> 02:22:22.400
Chimani, which are in Bolivia and Amazon, both in the Amazon in these cases. And there are

02:22:22.400 --> 02:22:28.480
so-called farmer foragers, which is not hunter-gatherers. It's sort of one up from hunter-gatherers

02:22:28.480 --> 02:22:32.960
in that they do a little bit of farming as well. A lot of hunting as well, but a little bit of

02:22:32.960 --> 02:22:37.520
farming. And the kind of farming they do is the kind of farming that I might do if I ever were

02:22:37.520 --> 02:22:43.520
to grow like tomatoes or something in my backyard. So it's not like big field farming. It's just a

02:22:43.520 --> 02:22:47.440
farming for a family, a few things you do that. And so that's the kind of farming they do.

02:22:47.840 --> 02:22:54.720
And the other group I've worked with are the Pirahá, which are also in the Amazon and happen

02:22:54.720 --> 02:23:02.480
to be in Brazil. And that's with a guy called Dan Everett, who is a linguist, anthropologist,

02:23:02.480 --> 02:23:08.160
who actually lived and worked in the... I mean, he was a missionary, actually, initially, back in

02:23:08.160 --> 02:23:13.920
the 70s, working with trying to translate languages so they could teach them the Bible,

02:23:13.920 --> 02:23:19.200
teach them Christianity. What can you say about that? Yeah, so the two groups I've worked with,

02:23:19.200 --> 02:23:25.680
the Cimani and the Pirahá, are both isolate languages, meaning there's no known connected

02:23:25.680 --> 02:23:29.760
languages at all. They're just like on their own. Oh, cool. Yeah, there's a lot of those. And most of

02:23:29.760 --> 02:23:39.520
the isolates occur in the Amazon or in Papua New Guinea, in these places where the world has

02:23:39.520 --> 02:23:46.240
sort of stayed still for long enough. And so there aren't earthquakes. There aren't...

02:23:48.400 --> 02:23:54.240
Well, certainly no earthquakes in the Amazon jungle. And the climate isn't bad. So you don't

02:23:54.240 --> 02:23:59.360
have droughts. And so in Africa, you've got a lot of moving of people because there's

02:23:59.360 --> 02:24:03.600
drought problems. And so they get a lot of language contact when people have to...

02:24:04.320 --> 02:24:10.160
You've got to move because you've got no water, then you've got to get going. And then you run

02:24:10.160 --> 02:24:15.600
into contact with other tribes, other groups. In the Amazon, that's not the case. And so people

02:24:15.600 --> 02:24:19.520
can stay there for hundreds and hundreds and probably thousands of years, I guess. And so these

02:24:19.520 --> 02:24:25.280
groups have... The Cimani and the Pirahá are both isolates in that. And I guess they've just lived

02:24:25.280 --> 02:24:33.040
there for ages and ages with minimal contact with other outside groups. And so, I mean,

02:24:33.120 --> 02:24:38.960
I'm interested in them because they are... In these cases, I'm interested in their words.

02:24:38.960 --> 02:24:43.840
I would love to study their syntax, their orders of words, but I'm mostly just interested in how

02:24:43.840 --> 02:24:50.800
languages are connected to their cultures in this way. And so with the Pirahá,

02:24:50.800 --> 02:24:55.600
sort of most interesting, I was working on number there, number information. And so the

02:24:55.600 --> 02:24:59.200
basic idea is I think language is invented. That's what I get from the words here is that

02:24:59.200 --> 02:25:03.120
I think language is invented. We talked about color earlier. It's the same idea,

02:25:03.120 --> 02:25:08.640
so that what you need to talk about with someone else is what you're going to invent words for.

02:25:09.200 --> 02:25:16.240
And so we invent labels for colors that I need, not that I can see, but that things I need to

02:25:16.240 --> 02:25:20.080
tell you about so that I can get objects from you or get you to give me the right objects.

02:25:20.080 --> 02:25:26.960
And I just don't need a word for teal or a word for aquamarine in the Amazon jungle,

02:25:26.960 --> 02:25:30.640
for the most part, because I don't have two things which differ on those colors. I just

02:25:30.640 --> 02:25:36.560
don't have that. And so numbers are really another fascinating source of information here where

02:25:37.440 --> 02:25:44.880
you might... Naively, I certainly thought that all humans would have words for exact counting

02:25:46.000 --> 02:25:51.920
and the Pirahá don't. So they don't have any words for even one. There's not a word for one

02:25:51.920 --> 02:25:57.920
in their language. And so there's certainly not a word for two, three, or four. So that kind of

02:25:57.920 --> 02:26:02.400
blows people's minds off. Yeah, that is blowing my mind. That's pretty weird. How are you going to

02:26:02.400 --> 02:26:07.760
ask, I want two of those? You just don't. And so that's just not a thing you can possibly ask

02:26:07.760 --> 02:26:12.160
in the Pirahá. It's not possible. That is, there's no words for that. So here's how we found this

02:26:12.160 --> 02:26:18.240
out. So it was thought to be a one, two, many language. There are three words, four quantifiers

02:26:18.960 --> 02:26:25.280
for sets. And people had thought that those meant one, two, and many. But what they really

02:26:25.280 --> 02:26:30.320
mean is few, some, and many. Many is correct. It's few, some, and many. And so the way we

02:26:30.320 --> 02:26:38.400
figured this out, and this is kind of cool, is that we gave people... We had a set of objects.

02:26:38.400 --> 02:26:42.320
These are having to be spools of thread. It doesn't really matter what they are. Identical objects.

02:26:42.320 --> 02:26:46.400
And when I sort of start off here, I just give you one of those and say,

02:26:46.400 --> 02:26:50.800
what's that? Okay, so you're a Pirahá speaker and you tell me what it is. And then I give you two

02:26:50.800 --> 02:26:55.680
and say, what's that? And nothing's changing in this set except for the number. And then I just

02:26:55.680 --> 02:26:59.120
ask you to label these things. We just do this for a bunch of different people. And frankly,

02:26:59.120 --> 02:27:06.000
it's a... I did this task. And it's a little bit weird. So they say the word that we thought was

02:27:06.000 --> 02:27:10.240
one, it's few, but for the first one. And then maybe they say few or maybe they say some for

02:27:10.240 --> 02:27:15.360
the second. And then for the third or the fourth, they start using the word many for the set. And

02:27:15.360 --> 02:27:20.720
then five, six, seven, eight. I go all the way to ten. And it's always the same word. And they

02:27:20.720 --> 02:27:26.480
look at me like I'm stupid because they told me what the word was for six, seven, eight. And I'm

02:27:26.480 --> 02:27:31.760
going to continue asking them at nine and ten. I'm sorry. They understand that I want to know

02:27:31.760 --> 02:27:35.120
their language. That's the point of the task is like I'm trying to learn their language. And so

02:27:35.120 --> 02:27:41.120
that's okay. But it does seem like I'm a little slow because they already told me what the word

02:27:41.120 --> 02:27:45.840
for many was, five, six, seven. And I keep asking. So it's a little funny to do this task over and

02:27:45.840 --> 02:27:51.120
over. We did this with a guy called... Dan was our translator. He's the only one who really speaks

02:27:51.120 --> 02:27:59.200
Piazza fluently. He's a good bilingual for a bunch of languages, but also English and Piazza.

02:27:59.200 --> 02:28:03.520
And then a guy called Mike Frank was also a student with me down there. He and I did these

02:28:03.520 --> 02:28:10.560
things. And so you do that. Okay. And everyone does the same thing. We asked like 10 people.

02:28:10.560 --> 02:28:15.040
And they all do exactly the same labeling for one up. And then we just do the same thing

02:28:15.040 --> 02:28:19.040
down on random order. Actually, we do some of them up, some of them down first. Okay.

02:28:19.040 --> 02:28:23.600
And so we do, instead of one to 10, we do 10 down to one. And so I give them 10,

02:28:23.600 --> 02:28:28.960
nine, eight. They start saying the word for some. And then when you get to four,

02:28:28.960 --> 02:28:34.960
everyone is saying the word for few, which we thought was one. So the context determined

02:28:34.960 --> 02:28:40.160
what that quantifier they used was. So it's not a count word. They're not count words.

02:28:40.400 --> 02:28:43.520
They're just approximate words. And they're going to be noisy when you interview a bunch

02:28:43.520 --> 02:28:47.360
of people, what the definition of few, and there's going to be a threshold in the context.

02:28:48.160 --> 02:28:51.040
Yeah, I don't know what that means. That's going to be 10 on the context. I think it's

02:28:51.040 --> 02:28:53.840
true in English too, right? If you ask an English person what a few is, I mean,

02:28:53.840 --> 02:28:57.760
that's going to depend completely on the context. And it might actually be at first

02:28:57.760 --> 02:29:02.880
hard to discover. Because for a lot of people, the jump from one to two will be few.

02:29:03.680 --> 02:29:06.640
Right? So it's a jump. Yeah, it might be. It might still be there. Yeah.

02:29:07.600 --> 02:29:11.120
I mean, that's fascinating. That's fascinating that numbers don't present themselves.

02:29:11.120 --> 02:29:14.400
Yeah. So the words aren't there. And then, and so then we do these other things. Well,

02:29:14.400 --> 02:29:20.640
if they don't have the words, can they do exact matching kinds of tasks? Can they even do those

02:29:20.640 --> 02:29:27.600
tasks? And the answer is sort of yes and no. And so yes, they can do them. So here's the tasks

02:29:27.600 --> 02:29:32.320
that we did. We put out those spools of thread again. Okay. So maybe I put like three out here.

02:29:32.320 --> 02:29:37.760
And then we gave them some objects. And those happen to be uninflated red balloons. It doesn't

02:29:37.760 --> 02:29:42.400
really matter what they are. It's just a bunch of exactly the same thing. And it was easy to

02:29:42.400 --> 02:29:48.320
put down right next to these spools of thread. Okay. And so then I put out three of these.

02:29:48.320 --> 02:29:54.080
And your task was to just put one against each of my three things. And they could do that perfectly.

02:29:54.080 --> 02:29:57.840
So I mean, I would actually do that. It was a very easy task to explain to them because I have,

02:29:57.840 --> 02:30:03.040
I did this with this guy, Mike Frank, and he would be my, I'd be the experimenter telling him to do

02:30:03.040 --> 02:30:07.200
this and showing him to do this. And then we just like, just do what he did. You'll copy him. All we

02:30:07.200 --> 02:30:12.160
had to, I didn't have to speak to him, except for know what copy him, like do what he did is like

02:30:12.160 --> 02:30:16.160
all we had to be able to say. And then they would do that just perfectly. And it's always

02:30:16.160 --> 02:30:22.160
moving up. We do some sort of random number of items up to 10. And they basically do perfectly

02:30:22.160 --> 02:30:26.160
on that. They never get that wrong. I mean, that's not a counting task, right? That is just a match.

02:30:26.160 --> 02:30:29.280
You just put one against them. It doesn't matter how many, I don't need to know how many there are

02:30:29.280 --> 02:30:35.520
there to do that correctly. And they would make mistakes, but very, very few and no more than

02:30:35.520 --> 02:30:40.880
MIT undergrads. Just going to say, like there's no, these are low stakes. So, you know, you make

02:30:40.880 --> 02:30:44.640
mistakes. Counting is not required to complete the matching task. That's right. Not at all. Okay.

02:30:44.640 --> 02:30:49.920
And so, and so that's our control. And this guy had gone down there before and said that they

02:30:49.920 --> 02:30:53.600
couldn't do this task, but I just don't know what he did wrong there because they can do this task

02:30:53.600 --> 02:30:58.160
perfectly well. And, you know, I can train my dog to do this task. So, of course, they can do this

02:30:58.160 --> 02:31:03.360
task. And so, you know, it's not a hard task. But the other task that was sort of more interesting

02:31:03.360 --> 02:31:10.320
is like, so then we do a bunch of tasks where you need some way to encode the set.

02:31:10.320 --> 02:31:18.880
So, like one of them is just a, I just put a opaque sheet in front of the things I put down a

02:31:18.880 --> 02:31:23.200
bunch of set of these things and I put an opaque sheet down. And so you can't see them anymore.

02:31:23.200 --> 02:31:26.960
And I tell you, do the same thing you were doing before, right? You know, and it's easy if it's

02:31:26.960 --> 02:31:32.480
two or three, it's very easy. But if I don't have the words for eight, it's a little harder, like,

02:31:32.480 --> 02:31:38.320
maybe, you know, with practice, well, no. Because you have to count. For us, it's easy

02:31:38.320 --> 02:31:42.560
because we just, we just count them. It's just so easy to count them. But, but they don't,

02:31:42.560 --> 02:31:45.840
they can't count them because they don't count. They don't have words for this thing. And so,

02:31:45.840 --> 02:31:48.800
they would do approximate. It's totally fascinating. So, they would get them

02:31:48.800 --> 02:31:53.840
approximately right, you know, after four or five, you know, because you can,

02:31:53.840 --> 02:31:58.000
basically, you always get four right, three or four, that looks, that's something we can

02:31:58.000 --> 02:32:02.640
visually see. But, but after that, you kind of have, it's an approximate number. And so,

02:32:02.640 --> 02:32:07.440
then, and there's a bunch of tasks we did, and they all failed as, I mean, failed. They did

02:32:07.440 --> 02:32:12.320
approximate after five on all those tasks. And it kind of shows that the words,

02:32:13.600 --> 02:32:17.280
you kind of need the words, you know, to be able to do these, these kinds of tasks.

02:32:17.280 --> 02:32:21.680
This is a little bit of a chicken and egg thing there. Because if you don't have the words,

02:32:22.720 --> 02:32:28.000
then maybe they'll limit you in the kind of, like a little baby Einstein there,

02:32:28.720 --> 02:32:33.840
won't be able to come up with a counting task. You know what I mean? Like, the ability to count

02:32:33.840 --> 02:32:40.480
enables you to come up with interesting things, probably. So, yes, you develop counting because

02:32:40.480 --> 02:32:45.280
you need it. But then, once you have counting, you can probably come up with a bunch of different

02:32:45.280 --> 02:32:52.240
inventions, like how to, I don't know, what kind of thing they do matching really well for

02:32:52.240 --> 02:32:58.000
building purposes, building some kind of hut or something like this. So, it's interesting that

02:32:58.000 --> 02:33:01.600
language is a, a limiter on what you're able to do.

02:33:01.600 --> 02:33:07.040
Yeah, here's language is just, is the words, here is the words, like the words for exact count

02:33:07.680 --> 02:33:10.560
is the limiting factor here. They just don't have them.

02:33:10.880 --> 02:33:18.240
Yeah. Well, that's what I mean. That limit is also a limit on the society of what they're able to

02:33:18.240 --> 02:33:23.360
build. That's going to be true. Yeah. So, it's problem, I mean, we don't know, this is one of

02:33:23.360 --> 02:33:27.840
those problems with the snapshot of just current languages is that we don't know what causes a

02:33:27.840 --> 02:33:34.080
culture to discover slash invent accounting system. But the hypothesis is the guess out there is

02:33:34.080 --> 02:33:40.080
something to do with farming. So, if you have a bunch of goats and you want to keep track of them,

02:33:40.560 --> 02:33:44.560
and you have saved 17 goats and you go to bed at night and you get up in the morning,

02:33:44.560 --> 02:33:49.680
boy, it's easier to have a count system to do that. You know, that's an abstract abstraction

02:33:49.680 --> 02:33:54.320
over a set. So, they don't have, like, people often ask me when I talk to them about this kind

02:33:54.320 --> 02:33:57.360
of work, and they say, well, don't these, Peter, huh, don't they have kids? Don't they have a lot

02:33:57.360 --> 02:34:01.280
of children? I'm like, yeah, they have a lot of children. And they do, they often have families

02:34:01.280 --> 02:34:05.120
of three or four or five kids. And they go, well, don't they need the numbers to keep track of their

02:34:05.120 --> 02:34:10.160
kids? And I always ask the person who says this, like, do you have children? And the answer is

02:34:10.160 --> 02:34:15.040
always no, because that's not how you keep track of your kids. You care about their identities.

02:34:15.040 --> 02:34:20.320
It's very important to me when I go, I think I have five children. It's, it's, it doesn't matter

02:34:20.320 --> 02:34:26.000
which, yeah, it matters which five. It's like, if you replaced one with someone else, I would,

02:34:26.000 --> 02:34:30.240
I would care. A goat maybe not, right? That's the kind of point. It's an abstraction,

02:34:30.240 --> 02:34:33.760
something that looks very similar to the one wouldn't matter to me, probably.

02:34:33.760 --> 02:34:37.760
But if you care about goats, you're going to know them actually individually also.

02:34:37.760 --> 02:34:41.280
Yeah, you will. I mean, cows and goats, if there's a source of food and milk and all that kind

02:34:41.280 --> 02:34:44.560
of stuff, you're going to actually do it right there. But I'm saying it is an abstraction

02:34:44.560 --> 02:34:48.400
such that you don't have to care about their identities to do this thing fast. That's,

02:34:48.400 --> 02:34:53.680
that's the hypothesis, not mine. From anthropologists are guessing about where

02:34:53.680 --> 02:35:00.400
words for counting came from is from farming, maybe. Yeah. Do you have a sense why universal

02:35:00.400 --> 02:35:07.440
languages like Esperanto have not taken off? Like, why do we have all these different languages?

02:35:07.920 --> 02:35:14.640
Well, my guess is the function of a language is to do something in a community. And I mean,

02:35:14.640 --> 02:35:18.880
unless there's some function to that language in the community, it's not going to survive.

02:35:18.880 --> 02:35:23.760
It's not going to be useful. So here's a great example. So what I'm like, language death is

02:35:23.760 --> 02:35:29.440
super common. Okay. Languages are dying all around the world. And here's why they're dying.

02:35:29.440 --> 02:35:33.600
And it's like, yeah, I see this in, you know, it's not happening right now in either the

02:35:33.600 --> 02:35:38.240
Chimane or the, or the Piedoha, but it probably will. And so there's a neighboring group called

02:35:38.240 --> 02:35:44.720
Mostitan, which is, I said that it's a isolates. Actually, there's a dual. There's two of them.

02:35:44.720 --> 02:35:48.640
Okay. So it's actually, there's two languages, which are really close, which are Mostitan

02:35:48.640 --> 02:35:55.040
and Chimane, which are unrelated to anything else. And Mostitan is unlike Chimane in that

02:35:55.040 --> 02:36:00.160
it has a lot of contact with Spanish and it's dying. So that language is dying. The reason it's

02:36:00.160 --> 02:36:07.200
dying is there's not a lot of value for the local people in their native language. So there's much

02:36:07.200 --> 02:36:12.160
more value in knowing Spanish, like because they want to feed their families. And how do you feed

02:36:12.160 --> 02:36:16.400
your family? You learn Spanish, so you can make money, so you can get a job and do these things.

02:36:16.400 --> 02:36:20.640
And then you can, and then you make money. And so they want Spanish things they want. And so,

02:36:20.640 --> 02:36:27.040
so Mostitan is in danger and is dying. And that's normal. And so basically the problem is that people,

02:36:28.000 --> 02:36:35.440
the reason we learn languages to communicate, and we need to, we use it to make money and to

02:36:35.440 --> 02:36:42.640
do whatever it is to feed our families. And if that's not happening, then it won't take off.

02:36:42.640 --> 02:36:47.360
It's not like a game or something. This is like something we use. Like, why is English so popular?

02:36:47.360 --> 02:36:52.240
It's not because it's an easy language to learn. Maybe it is. I don't really know.

02:36:53.040 --> 02:36:57.360
But that's not why it's popular. But because the United States is a gigantic economy.

02:36:57.360 --> 02:37:02.160
Yeah. It's big economies that do this. It's all it is. It's all about money. And that's what,

02:37:02.160 --> 02:37:06.960
and so there's a motivation to learn Mandarin. There's a motivation to learn Spanish. There's

02:37:06.960 --> 02:37:10.800
a motivation to learn English. These languages are very valuable to know because there's so,

02:37:10.800 --> 02:37:16.160
so many speakers all over the world. There's less of a value economically. It's like kind of what

02:37:16.160 --> 02:37:20.720
drives this. It's not a, but it's not a, you know, it's not just for fun. I mean, there are these

02:37:20.720 --> 02:37:25.760
groups that do want to learn language just for language's sake. And then there's something,

02:37:25.760 --> 02:37:30.720
you know, to that, but those are rare. Those are rarities in general. Those are a few small

02:37:30.720 --> 02:37:34.240
groups that do that. Not most people don't do that. Well, if that was the primary driver,

02:37:34.240 --> 02:37:38.400
then everybody was speaking English or speaking one language. There's also a tension.

02:37:38.400 --> 02:37:39.280
That's happening.

02:37:39.280 --> 02:37:42.880
And that, well, we're moving towards fewer and fewer languages.

02:37:42.880 --> 02:37:48.400
We are. I wonder, you're right. Maybe, maybe, you know, this is slow, but maybe that's where

02:37:48.400 --> 02:37:54.880
we're moving. But there is a tension. You're saying a language that the fringes. But if you

02:37:55.440 --> 02:38:00.080
look at geopolitics and superpowers, it does seem that there's another thing in tension,

02:38:00.080 --> 02:38:05.920
which is a language is a national identity sometimes. For a certain nation. I mean,

02:38:05.920 --> 02:38:11.280
that's the, the war in Ukraine, language, Ukrainian language is a symbol of that war

02:38:11.840 --> 02:38:16.800
in many ways, like a country fighting for its own identity. So it's not merely the convenience.

02:38:16.800 --> 02:38:21.760
I mean, those two things that are a tension is the, the convenience of trade and the economics

02:38:21.760 --> 02:38:27.520
and be able to communicate with neighboring countries and trade more efficiently with

02:38:27.520 --> 02:38:31.360
neighboring countries, all that kind of stuff, but also identity of the group.

02:38:31.360 --> 02:38:32.640
That's right. I completely agree.

02:38:32.640 --> 02:38:40.400
Because language is the way, for every community, like dialects that emerge are a kind of identity

02:38:40.400 --> 02:38:46.720
for people. And sometimes a way for people to say FU to the more powerful people.

02:38:47.360 --> 02:38:51.120
That's interesting. So in that way, language can't be used as that tool.

02:38:51.120 --> 02:38:57.200
Yeah. I completely agree. And there's a lot of work to try to create that identity. So people

02:38:57.200 --> 02:39:04.720
want to do that. Speak, you know, as a cognitive scientist and language expert, I hope that continues

02:39:04.720 --> 02:39:08.080
because I don't want languages to die. I want languages to survive because,

02:39:10.080 --> 02:39:15.920
because they're so interesting for, for so many reasons. But I mean, I find them fascinating

02:39:15.920 --> 02:39:19.760
just for the language part, but I think they, you know, there's a lot of connections to culture

02:39:19.760 --> 02:39:25.440
as well, which is also very important. Do you have hope for machine translation

02:39:25.440 --> 02:39:29.680
that can break down the barriers of language? So while all these different diverse languages

02:39:29.680 --> 02:39:36.800
exist, I guess there's many ways of asking this question, but basically how hard is it to translate

02:39:37.680 --> 02:39:40.240
in an automated way from one language to another?

02:39:40.240 --> 02:39:44.640
There's, there's going to be cases where it's going to be really hard, right? So there are concepts

02:39:45.360 --> 02:39:49.920
that are in one language and not in another. Like the most extreme kinds of cases are these

02:39:49.920 --> 02:39:55.120
cases of number information. So exactly, like good luck translating a lot of English into

02:39:55.680 --> 02:39:59.840
it's just impossible. There's no way to do it because there are no words for these concepts

02:39:59.840 --> 02:40:05.040
that we're talking about. There's probably the flip side, right? There's probably stuff in

02:40:06.400 --> 02:40:10.480
which is going to be hard to translate into English on the other side. And so I just don't

02:40:10.480 --> 02:40:15.680
know what those concepts are. I mean, you know, the space, the world space is a little, is different

02:40:15.680 --> 02:40:19.440
from my world space. And so I don't know what like, so that the things they talk about things are,

02:40:20.080 --> 02:40:24.320
you know, it's going to have to do with their life as opposed to, you know, my industrial life,

02:40:24.320 --> 02:40:28.560
which is going to be different. And so there's going to be problems like that always.

02:40:29.280 --> 02:40:32.560
You know, there's like, it's not, maybe it's not so bad in the case of some of these spaces,

02:40:32.560 --> 02:40:37.040
and maybe it's going to be harder than others. And so it's pretty bad in number. It's like,

02:40:37.040 --> 02:40:41.520
you know, extreme, I'd say, in the number space, you know, exact number space, but in the color

02:40:41.520 --> 02:40:46.640
dimension, right? So that's not so bad. There's, I mean, but it's a problem that, that you don't

02:40:46.640 --> 02:40:52.160
have ways to talk about the concepts. There might be entire concepts that are missing. So to you,

02:40:52.160 --> 02:40:58.240
it's more about the space of concept versus the space of form. Like form, you can probably map.

02:40:58.240 --> 02:41:04.240
Yes. Yeah. But so you were talking earlier about translation and about how translations,

02:41:04.960 --> 02:41:08.240
you know, there's good and bad translations. I mean, now we're talking about translations of

02:41:08.240 --> 02:41:16.080
form, right? So what makes a writing good, right? It's not just the content. It's, you know,

02:41:16.080 --> 02:41:20.160
it's how it's written. And translating that, I, you know, I, you know, that's,

02:41:20.160 --> 02:41:26.480
that sounds difficult. We should, we should say that there is like, I don't, it has a day to say

02:41:26.480 --> 02:41:32.640
meaning, but there's a music and a rhythm to the form. When you look at the broad picture, like

02:41:32.640 --> 02:41:40.880
the Fritz Wietzi and Dostoyevsky and Tolstoy, or Hemingway Bukowski, James Joyce, like I mentioned,

02:41:40.880 --> 02:41:44.800
there's a beat to it. There's an edge to it that it's like, is in the form.

02:41:46.000 --> 02:41:51.760
We can probably get measures of those. Yeah. I don't know. I'm optimistic that we could get

02:41:51.760 --> 02:41:56.000
measures of those things. And so maybe that's translatable. I don't know. I don't know though.

02:41:56.000 --> 02:41:59.760
I haven't worked on that. I would love to see. That sounds totally fascinating.

02:41:59.760 --> 02:42:05.920
Translation to Hemingway. I mean, Hemingway is probably the lowest, I would love to see

02:42:05.920 --> 02:42:13.120
different authors, but the average per sentence dependency length for Hemingway is probably

02:42:13.120 --> 02:42:19.440
the shortest. That's your sense, huh? It's simple sentences with short, yeah, yeah, yeah, yeah.

02:42:19.440 --> 02:42:22.560
I mean, that's when, if you have really long sentences, even if they don't have center of

02:42:22.560 --> 02:42:26.240
writing, like. They can have longer connections. Yeah. They can have longer connections. They

02:42:26.240 --> 02:42:30.320
don't have to, right? You can have a long, long sentence with a bunch of local words. Yeah.

02:42:30.320 --> 02:42:34.480
Yeah. But it's, but it is much more likely to have the possibility of long dependencies with

02:42:34.480 --> 02:42:41.840
long sentences. Yeah. I met a guy named Azar Askin who does a lot of cool stuff. Really

02:42:41.840 --> 02:42:47.040
brilliant. He works with Tristan Harris and a bunch of stuff. But he was talking to me about

02:42:48.160 --> 02:42:54.400
communicating with animals. He co-founded Earth Species Project, where you're trying to find

02:42:54.400 --> 02:43:01.360
the common language between whales, crows, and humans. And he was saying that there is a lot

02:43:01.360 --> 02:43:06.560
of promising work that even though the signals are very different. Right. Like the actual, like,

02:43:08.480 --> 02:43:14.160
if you have embeddings of the languages, they're actually trying to communicate similar type things.

02:43:16.720 --> 02:43:21.280
Is there something you can comment on that? Like where, is there promise to that? And everything

02:43:21.280 --> 02:43:25.440
you've seen in different cultures, especially like remote cultures, that this is a possibility?

02:43:25.520 --> 02:43:32.560
No. They can talk to whales. I would say yes. I think it's not crazy at all. I think it's quite

02:43:32.560 --> 02:43:40.320
reasonable. There's this sort of weird view, well, odd view, I think, that to think that human language

02:43:40.320 --> 02:43:47.600
is somehow special. I mean, it is, maybe it is. We can certainly do more than any of the other

02:43:47.680 --> 02:43:58.000
species. And maybe our language system is part of that. It's possible. But people do have often

02:43:58.000 --> 02:44:04.480
talked about how human, like Chomsky, in fact, has talked about how human language has this

02:44:06.000 --> 02:44:11.680
compositionality thing that he thinks is sort of key in language. And the problem with that

02:44:11.680 --> 02:44:17.440
argument is he doesn't speak whale. And he doesn't speak crow, and he doesn't speak monkey.

02:44:18.480 --> 02:44:23.600
They say things like, well, they're making a bunch of grunts and squeaks. And the reasoning is like,

02:44:24.160 --> 02:44:29.440
that's bad reasoning. I'm pretty sure if you asked a whale what we're saying, they'd say, well,

02:44:29.440 --> 02:44:35.360
I'm making a bunch of weird noises. Exactly. And so it's like, this is a very odd reasoning to

02:44:35.360 --> 02:44:38.720
be making that human language is special because we're the only ones who have human language. I'm

02:44:39.360 --> 02:44:45.440
well, we don't know what those other, we just don't, we can't talk to them yet. And so there

02:44:45.440 --> 02:44:51.280
are probably a signal in there. And it might very well be something complicated, like human language.

02:44:51.280 --> 02:44:56.960
I mean, sure, with a small brain, in lower species, there's probably not a very good

02:44:56.960 --> 02:45:01.840
communication system. But in these higher species where you have what seems to be

02:45:03.200 --> 02:45:08.080
abilities to communicate something, there might very well be a lot more signal there than we're

02:45:09.280 --> 02:45:12.880
than we might have otherwise thought. But, but also if we have a lot of intellectual

02:45:12.880 --> 02:45:17.280
humility here, as somebody formerly from MIT, Neri Oxman, who I admire very much,

02:45:18.000 --> 02:45:26.960
has talked a lot about, has worked on communicating with plants. So like, yes, the signal there is

02:45:26.960 --> 02:45:33.680
even less than we're like, it's not out of the realm of possibility that all nature has a way of

02:45:33.680 --> 02:45:39.440
communicating. And it's a very different language, but they do develop a kind of language through

02:45:39.440 --> 02:45:45.200
the chemistry, through some way of communicating with each other. And if you have enough humility

02:45:45.200 --> 02:45:50.720
about that possibility, I think you can, I think it would be a very interesting in a few decades,

02:45:51.520 --> 02:45:57.520
maybe centuries, hopefully not a humbling possibility of being able to communicate not

02:45:57.520 --> 02:46:02.880
just between humans effectively, but between all of living things on earth.

02:46:04.000 --> 02:46:06.880
Well, I mean, I think some of them are not going to have much interesting to say,

02:46:08.320 --> 02:46:14.240
we don't know. We certainly don't know. I think if we're humble, there could be some

02:46:14.240 --> 02:46:19.680
interesting trees out there. Well, they're probably talking to other trees, right? They're not talking

02:46:19.680 --> 02:46:24.160
to us. And so to the extent they're talking, they're saying something interesting to some other,

02:46:24.800 --> 02:46:30.000
you know, conspecific as opposed to us, right? And so there probably is, there may be some signal

02:46:30.000 --> 02:46:36.560
there. So there are people out there, actually it's pretty common to say that human language

02:46:36.560 --> 02:46:42.960
is special and different from any other animal communication system. And I just don't think

02:46:42.960 --> 02:46:50.880
the evidence is there for that claim. I think it's not obvious. We just don't know, because we

02:46:50.880 --> 02:46:56.720
don't speak these other communication systems until we get better. You know, I do think there's,

02:46:56.720 --> 02:46:59.520
there are people working on that, as you pointed out, though, people working on

02:46:59.520 --> 02:47:02.000
whale speak, for instance, like that's really fascinating.

02:47:02.000 --> 02:47:07.440
Let me ask you a wild out there sci-fi question. If we make contact with an intelligent alien

02:47:07.440 --> 02:47:15.040
civilization and you get to meet them, how hard do you think, like how surprised would you be

02:47:15.040 --> 02:47:20.560
about their way of communicating? Do you think it would be recognizable? Maybe there's some

02:47:20.560 --> 02:47:25.760
parallels here when you go to the remote tribes. I mean, I would want Dan Everett with me. He is

02:47:25.760 --> 02:47:31.040
like amazing at learning foreign languages. And so he like, this is an amazing feat, right, to be

02:47:31.040 --> 02:47:36.320
able to go, this is a language, which has no translators before him. I mean, there were,

02:47:36.320 --> 02:47:40.320
he was a mystery, well, there was a guy that had been there before, but he wasn't very good.

02:47:40.320 --> 02:47:45.920
And so he learned the language far better than anyone else had learned before him. He's like good

02:47:45.920 --> 02:47:50.480
at, he's just a, he's a very social person. I think that's a big part of it is being able to

02:47:50.480 --> 02:47:56.640
interact. So I don't know, it kind of depends on these, this species from outer space, how

02:47:56.640 --> 02:48:00.480
much they want to talk to us. Is there something you can say about the process he follows?

02:48:00.480 --> 02:48:05.920
Like what, how do you show up to a tribe and socialize? I mean, I guess colors and counting is

02:48:05.920 --> 02:48:09.600
one of the most basic things to figure out. Yeah, you start that. You actually start with

02:48:09.600 --> 02:48:14.160
like objects and just say, you know, just throw a stick down and say stick. And then you say,

02:48:14.160 --> 02:48:17.760
what do you call this? And then they'll say the word, whatever. And he says,

02:48:17.760 --> 02:48:21.120
the standard thing to do is to throw two sticks at two sticks. And then, you know,

02:48:21.120 --> 02:48:25.360
he learned pretty quick that there weren't any count words in this language because

02:48:25.360 --> 02:48:28.800
they didn't know this wasn't interesting. I mean, it was kind of weird. They'd say some or

02:48:28.800 --> 02:48:32.320
something, the same word over and over again. And so, but that is a standard thing. You just

02:48:32.320 --> 02:48:37.840
like try to, but you have to be pretty out there socially, like willing to talk to random people,

02:48:38.640 --> 02:48:42.400
which these are, you know, really very different people from you. And he was, and he's,

02:48:42.400 --> 02:48:45.440
he's very social. And so I think that's a big part of this is like, that's how,

02:48:46.080 --> 02:48:50.480
you know, a lot of people know a lot of languages that they're willing to talk to other people.

02:48:50.480 --> 02:48:55.280
That's a tough one. We just show up knowing nothing. Yeah. Oh, God. It's beautiful that

02:48:55.280 --> 02:49:00.560
humans are able to connect in that way. Yeah. Yeah. You've had an incredible career exploring

02:49:00.560 --> 02:49:06.480
this fascinating topic. What advice would you give to young people about how to have a career

02:49:07.440 --> 02:49:12.320
like that or a life that they can be proud of? When you see something interesting,

02:49:12.320 --> 02:49:16.880
just go and do it. Like I do, I do that. Like that's something I do, which is kind of unusual

02:49:16.880 --> 02:49:20.880
for most people. So like when I saw the, like if Piedoha was available to go and visit, I was like,

02:49:20.880 --> 02:49:27.920
yes, yes, I'll go. And then when we couldn't go back, we had some trouble with the Brazilian

02:49:27.920 --> 02:49:31.520
government. There's some corrupt people there. It was very difficult to get, go back in there.

02:49:31.520 --> 02:49:34.960
And so I was like, all right, I got to find another group. And so we searched around and

02:49:34.960 --> 02:49:38.960
we were able to find the, because I wanted to keep working on this kind of problem. And so we

02:49:38.960 --> 02:49:42.880
found the Chimani and just go there. I didn't really have, we didn't have contact. We had a

02:49:42.880 --> 02:49:47.600
little bit of contact and brought someone. And that was, you know, we just, just kind of just

02:49:47.600 --> 02:49:53.040
try things. I say it's like, a lot of that's just like ambition, just try to do something

02:49:53.040 --> 02:49:57.440
that other people haven't done. Just give it a shot is what I, I mean, I do that all the time.

02:49:57.440 --> 02:50:03.280
I love it. And I love the fact that your pursuit of fun has landed you here talking to me. This

02:50:03.280 --> 02:50:08.960
was an incredible conversation that you're, you're, you're just a fascinating human being.

02:50:08.960 --> 02:50:12.880
Thank you for taking a journey through human language with me today. This is awesome.

02:50:12.880 --> 02:50:14.800
Thank you very much. It's been pleasure.

02:50:15.920 --> 02:50:20.400
Thanks for listening to this conversation with Edward Gibson. To support this podcast,

02:50:20.400 --> 02:50:25.680
please check out our sponsors in the description. And now let me leave you with some words from

02:50:25.760 --> 02:50:31.280
Wittgenstein. The limits of my language mean the limits of my world.

02:50:32.480 --> 02:50:41.600
Thank you for listening and hope to see you next time.

