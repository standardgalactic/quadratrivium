WEBVTT

00:00.000 --> 00:05.680
The following is a conversation with Bjarn Strelstrom. He's the creator of C++,

00:05.680 --> 00:11.600
programming language that after 40 years is still one of the most popular and powerful languages in

00:11.600 --> 00:18.080
the world. Its focus on fast, stable, robust code underlies many of the biggest systems in the world

00:18.080 --> 00:23.120
that we have come to rely on as a society. If you're watching this on YouTube, for example,

00:23.120 --> 00:29.280
many of the critical back-end components of YouTube are written in C++. Same goes for Google,

00:29.280 --> 00:35.200
Facebook, Amazon, Twitter, most Microsoft applications, Adobe applications, most database

00:35.200 --> 00:42.160
systems, and most physical systems that operate in the real world, like cars, robots, rockets that

00:42.160 --> 00:49.840
launch us into space, and one day will land us on Mars. C++ also happens to be the language

00:49.840 --> 00:55.680
that I use more than any other in my life. I've written several hundred thousand lines of C++

00:55.680 --> 01:01.520
source code. Of course, lines of source code don't mean much, but they do give hints of my

01:01.520 --> 01:06.800
personal journey through the world of software. I've enjoyed watching the development of C++

01:06.800 --> 01:13.040
as a programming language leading up to the big update in the standard in 2011 and those that

01:13.040 --> 01:20.320
followed in 14, 17, and toward the new C++20 standard hopefully coming out next year.

01:21.120 --> 01:26.560
This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it

01:26.560 --> 01:31.920
five stars on iTunes, support it on Patreon, or simply connect with me on Twitter at Lex

01:31.920 --> 01:38.880
Friedman, spelled F-R-I-D-M-A-N. And now, here's my conversation with Bjorn Strauss-Straub.

01:40.240 --> 01:44.000
What was the first program you've ever written? Do you remember?

01:44.080 --> 01:52.640
It was my second year in university, first year of computer science, and it was an Algor-60.

01:53.520 --> 02:02.400
I calculated the shape of a super ellipse and then connected points on the perimeter,

02:02.400 --> 02:10.480
creating star patterns. It was with a wedding on a paper printer.

02:11.440 --> 02:13.280
And that was in college, university?

02:13.280 --> 02:17.120
Yeah. I learned to program the second year in university.

02:18.400 --> 02:24.960
And what was the first programming language, if I may ask it this way, that you fell in love with?

02:26.480 --> 02:39.120
I think Algor-60. And after that, I remember Snowball. I remember Fortran didn't fall in love

02:39.120 --> 02:44.720
with that. I remember Pascal didn't fall in love with that. It all got in the way of me.

02:46.160 --> 02:49.360
And then I just covered Assembler, and that was much more fun.

02:50.320 --> 02:53.920
And from there, I went to microcode.

02:54.800 --> 03:01.120
So you were drawn to the, you found the low-level stuff beautiful?

03:01.120 --> 03:08.080
I went through a lot of languages, and then I spent significant time in Assembler and

03:08.080 --> 03:14.560
microcode. That was sort of the first really profitable things I paid for my masters, actually.

03:15.360 --> 03:18.480
And then I discovered Simula, which was absolutely great.

03:19.600 --> 03:20.080
Simula?

03:20.640 --> 03:29.040
Simula was the extension of Algor-60 done primarily for simulation, but basically they

03:29.040 --> 03:36.160
invented object-oriented programming at inheritance and runtime polymorphism while they were doing it.

03:36.400 --> 03:45.840
And that was a language that taught me that you could have the sort of the problems of a program

03:45.840 --> 03:51.520
grow with the size of the program rather than with the square of the size of the program.

03:52.480 --> 03:59.520
That is, you can actually modularize very nicely. And that was a surprise to me.

04:00.480 --> 04:09.920
It was also a surprise to me that a stricter type system than Pascal's was helpful, whereas Pascal's

04:09.920 --> 04:18.720
type system got in my way all the time. So you need a strong type system to organize your code well,

04:18.720 --> 04:20.800
but it has to be extensible and flexible.

04:21.520 --> 04:26.480
Let's get into the details a little bit. If you remember, what kind of type system did Pascal have?

04:27.120 --> 04:30.320
What type system, typing system did Algor-60 have?

04:31.040 --> 04:39.280
Basically, Pascal was sort of the simplest language that Niklaus Wiert could define that

04:39.280 --> 04:48.560
served the needs of Niklaus Wiert at the time. And it has a sort of a highly moral tone to it.

04:48.560 --> 04:53.680
That is, if you can say it in Pascal, it's good. And if you can't, it's not so good.

04:54.560 --> 05:02.000
Whereas, Simula, allowed you basically to build your own type system.

05:02.880 --> 05:08.720
So instead of trying to fit yourself into Niklaus Wiert's world,

05:09.920 --> 05:15.760
Christen Nürburgring's language and Oliohan Dahl's language allowed you to build your own.

05:15.760 --> 05:23.680
So it's sort of close to the original idea of you build a domain specific language.

05:24.480 --> 05:31.280
As a matter of fact, what you build is a set of types and relations among types

05:31.280 --> 05:35.520
that allows you to express something that's suitable for an application.

05:36.320 --> 05:42.160
When you say types, stuff you're saying has echoes of object during a programming.

05:42.160 --> 05:48.240
Yes, they invented it. Every language that uses the word class for type

05:49.040 --> 05:53.520
is a descendant of Simula, directly or indirectly.

05:55.040 --> 06:01.920
Christen Nürburgring and Oliohan Dahl were mathematicians and they didn't think in terms of

06:01.920 --> 06:10.400
types, but they understood sets and classes of elements. And so they called their types classes.

06:11.360 --> 06:16.960
And basically in C++, as in Simula classes, a user-defined type.

06:18.480 --> 06:25.120
So can you try the impossible task and give a brief history of programming languages from

06:25.120 --> 06:33.120
your perspective? So we started with ALGOL 60, Simula, Pascal, but that's just the 60s and 70s.

06:34.080 --> 06:42.560
I can try. The most sort of interesting and major improvement of programming languages was

06:43.600 --> 06:50.720
FORTRAN, the first FORTRAN. Because before that, ALGOL was written for a specific machine and each

06:50.720 --> 07:00.000
specific machine had a language, a simply language or a cross-impler or some extension of that idea.

07:00.000 --> 07:05.760
But you are writing for a specific machine in the term, in the language of that machine.

07:07.040 --> 07:17.200
And Barker and his team at IBM built a language that would allow you to write what you really

07:17.200 --> 07:24.160
wanted. That is, you could write it in a language that was natural for people. Now these people

07:24.160 --> 07:29.360
happened to be engineers and physicists, so the language that came out was somewhat unusual for

07:29.360 --> 07:34.320
the rest of the world. But basically they said formula translation because they wanted to have

07:34.320 --> 07:42.560
the mathematical formulas translated into the machine. And as a side effect, they got portability

07:43.280 --> 07:50.000
because now they are writing in the terms that the humans used and the way humans thought.

07:50.640 --> 07:57.440
And then they had a program that translated it into the machine's needs. And that was new and

07:57.440 --> 08:05.840
that was great. And it's something to remember. We want to raise the language to the human level,

08:05.840 --> 08:12.400
but we don't want to lose the efficiency. And that was the first step towards the human?

08:12.400 --> 08:18.480
That was the first step. And of course, there were very particular kinds of humans. Business

08:18.480 --> 08:24.880
people were different, so they got co-born instead and et cetera, et cetera. And Simula came

08:24.880 --> 08:35.440
out. No, let's not go to Simula yet. Let's go to Algon. Fortran didn't have at the time the notions of

08:36.640 --> 08:47.040
not a precise notion of type, not a precise notion of scope, not a set of translation faces that was

08:48.000 --> 08:55.440
what we have today, lexical, syntax, semantics. It was sort of a bit of a model in the early days,

08:55.440 --> 09:01.760
but hey, they've just done the big breakthrough in the history of programming, right? So you

09:01.760 --> 09:07.600
can't criticize them for not having gotten all the technical details right. So we got Algon.

09:07.600 --> 09:16.560
That was very pretty. And most people in commerce and science considered it useless because it was

09:16.560 --> 09:24.160
not flexible enough and it wasn't efficient enough and et cetera, et cetera. But that was the breakthrough

09:24.160 --> 09:31.440
from the technical point of view. And then Simula came along to make that idea more flexible.

09:32.240 --> 09:38.640
And you could define your own types. And that's where I got very interested.

09:39.600 --> 09:43.760
Christen Nygge, who's the main idea man behind Simula.

09:43.760 --> 09:45.040
That was late 60s.

09:45.040 --> 09:51.920
This was late 60s. Well, I was a visiting professor in Aarhus. And so I learned object

09:51.920 --> 10:02.000
oriented programming by sitting around and, well, in theory, discussing with Christen Nygge.

10:02.720 --> 10:09.200
But Christen, once you get started and in full flow, it's very hard to get a word in

10:09.200 --> 10:14.160
edge ways. It was great. I learned it from there.

10:14.160 --> 10:19.600
Not to romanticize the notion, but it seems like a big leap to think about or object-oriented

10:19.600 --> 10:31.440
programming. It's really a leap of abstraction. And was that as big and beautiful of a leap

10:31.440 --> 10:37.040
as it seems from now in retrospect? Or was it an obvious one at the time?

10:38.160 --> 10:45.600
It was not obvious. And many people have tried to do something like that. And most people didn't

10:45.600 --> 10:53.600
come up with something as wonderful as Simula. Lots of people got their PhDs and made their careers

10:53.600 --> 11:01.040
out of forgetting about Simula or never knowing it. For me, the key idea was basically I could get

11:01.040 --> 11:10.480
my own types. And that's the idea that goes further into C++, where I can get better types

11:10.480 --> 11:15.360
and more flexible types and more efficient types. But it's still the fundamental idea.

11:15.360 --> 11:21.520
When I want to write a program, I want to write it with my types. That is appropriate to my problem

11:22.480 --> 11:29.040
and under the constraints that I'm under with hardware, software, environment, etc.

11:29.840 --> 11:38.000
And that's the key idea. People picked up on the class hierarchies and the virtual functions

11:38.000 --> 11:47.040
and the inheritance. And that was only part of it. It was an interesting and major part and

11:47.040 --> 11:54.160
still a major part in a lot of graphic stuff. But it was not the most fundamental. It was

11:54.800 --> 11:59.680
when you wanted to relate one type to another, you don't want them all to be independent.

12:00.400 --> 12:10.480
The classical example is that you don't actually want to write city simulation with vehicles,

12:10.480 --> 12:16.160
where you say, well, if it's a bicycle, write the code for turning a bicycle to the left,

12:16.160 --> 12:22.160
if it's a normal car, turn right the normal carway, if it's a fire engine, turn right the fire engine

12:22.160 --> 12:30.400
way, you get these big case statements and bunches of if statements and such. Instead, you tell the

12:31.840 --> 12:38.240
base class that that's the vehicle and say, turn left the way you want to.

12:39.600 --> 12:50.320
And this is actually a real example. They used it to simulate and optimize the emergency services

12:50.320 --> 12:59.520
for somewhere in Norway back in the 60s. So this was one of the early examples for why you needed

12:59.520 --> 13:10.640
inheritance and you needed runtime polymorphism because you wanted to handle this set of vehicles

13:10.640 --> 13:18.640
in a manageable way. You can't just rewrite your code each time a new kind of vehicle comes along.

13:19.600 --> 13:24.720
Yeah, that's a beautiful, powerful idea. And of course, it stretches through your work,

13:24.720 --> 13:33.360
who C++ as we'll talk about. But I think you structured nicely what other breakthroughs came

13:33.360 --> 13:38.480
along in the history of programming languages. If we were to tell the history in that way.

13:39.440 --> 13:44.480
Obviously, I'm better telling the part of the history that that is the path I'm on,

13:44.560 --> 13:50.240
as opposed to all the paths. Yeah, you skipped the hippie John McCarthy and Lisp,

13:50.240 --> 13:57.680
one of my favorite languages. But Lisp is not one of my favorite languages. It's obviously

13:57.680 --> 14:03.600
important. It's obviously interesting. Lots of people write code in it. And then they rewrite it

14:03.600 --> 14:12.480
into CSE plus plus when they want to go to production. It's in the world I'm at, which are

14:12.480 --> 14:20.880
constrained by performance, reliability, issues, deployability, cost of hardware.

14:22.960 --> 14:30.480
I don't like things to be too dynamic. It is really hard to write a piece of code that's

14:30.480 --> 14:37.840
perfectly flexible, that you can also deploy on a small computer. And that you can also put in,

14:37.840 --> 14:44.240
say, a telephone switch in Bogota. What's the chance if you get an error and you find yourself

14:44.240 --> 14:50.800
in the debugger that the telephone switch in Bogota on late Sunday night has a programmer around?

14:51.840 --> 15:00.000
The chance is zero. And so a lot of things I think most about can't afford that flexibility.

15:00.960 --> 15:11.920
I'm quite aware that maybe 70, 80% of all code are not under the kind of constraints I'm interested

15:11.920 --> 15:19.840
in. But somebody has to do the job I'm doing, because you have to get from these high-level

15:19.840 --> 15:27.200
flexible languages to the hardware. The stuff that lasts for 10, 20, 30 years is robust,

15:27.280 --> 15:33.280
operates under very constrained conditions. Yes, absolutely. And it's fascinating and beautiful

15:33.280 --> 15:42.000
in its own way. C++ is one of my favorite languages. And so is Lisp. So I can embody too

15:42.000 --> 15:51.120
for different reasons as a programmer. I understand why Lisp is popular. And I can see

15:51.120 --> 16:05.200
the beauty of the ideas and similarly with Smalltalk. It's just not as relevant in my world.

16:05.200 --> 16:09.280
And by the way, I distinguish between those in the functional languages,

16:09.280 --> 16:17.040
where I go to things like ML and Haskell. Different kind of languages. They have a

16:17.040 --> 16:22.560
different kind of beauty and they're very interesting. And I actually try to learn from

16:23.600 --> 16:28.560
all the languages I encounter to see what is there that would make

16:30.000 --> 16:35.120
working on the kind of problems I'm interested in with the kind of constraints

16:36.720 --> 16:43.280
that I'm interested in. What can actually be done better? Because we can surely do better than we

16:43.280 --> 16:50.480
do today. You've said that it's good for any professional programmer to know at least five

16:50.480 --> 16:58.000
languages, speaking about a variety of languages that you've taken inspiration from. And you've

16:58.000 --> 17:06.720
listed yours as being, at least at the time, C++, obviously, Java, Python, Ruby and JavaScript.

17:07.280 --> 17:13.600
Can you, first of all, update that list, modify it? You don't have to be constrained

17:15.200 --> 17:20.400
to just five. But can you describe what you picked up also from each of these languages,

17:21.760 --> 17:25.920
how you see them as inspirations for even when you're working with C++?

17:25.920 --> 17:34.320
This is a very hard question to answer. So about languages, you should know languages.

17:34.880 --> 17:42.560
I reckon I knew about 25 or thereabouts when I did C++. It was easier in those days

17:42.560 --> 17:49.120
because the languages were smaller and you didn't have to learn a whole programming environment

17:49.120 --> 17:55.280
and such to do it. You could learn the language quite easily. And it's good to learn so many

17:55.280 --> 18:01.680
languages. And I imagine, just like with natural language for communication,

18:02.400 --> 18:08.240
there's different paradigms that emerge in all of them, that there's commonalities and so on.

18:08.880 --> 18:16.720
So I picked five out of a hat. The important thing that the number is not one.

18:21.040 --> 18:26.080
If you're a monoglot, you are likely to think that your own culture is the only one's

18:26.080 --> 18:31.200
period for everybody else's. A good learning of a foreign language and a foreign culture

18:31.200 --> 18:36.800
is important. It helps you think and be a better person. With programming languages,

18:36.800 --> 18:42.080
you become a better programmer, a better designer with the second language. Now,

18:42.080 --> 18:49.600
once you've got two, the way to five is not that long. It's the second one that's most important.

18:50.400 --> 18:59.200
And then when I had to pick five, I thought of thinking what kinds of languages are there.

18:59.200 --> 19:04.160
Well, there's a really low-level stuff. It's actually good to know machine code.

19:05.120 --> 19:07.040
Even still, sorry to interrupt. Even today.

19:09.920 --> 19:13.200
The C++ optimizer is right better machine code than I do.

19:14.160 --> 19:20.960
But I don't think I could appreciate them if I actually didn't understand machine code

19:20.960 --> 19:26.240
and machine architecture. At least in my position, I have to understand a bit of it,

19:26.240 --> 19:32.400
because you mess up the cache and you're off in performance by a factor of 100.

19:34.320 --> 19:39.600
It shouldn't be that if you're interested in either performance or the size of the computer

19:39.600 --> 19:48.720
you have to deploy. So I would go, that's a simpler. I used to mention C, but these days

19:48.720 --> 19:55.040
going low-level is not actually what gives you the performance. It is to express your ideas

19:55.600 --> 20:00.400
so cleanly that you can think about it and the optimizer can understand what you're up to.

20:01.200 --> 20:07.840
My favorite way of optimizing these days is to throw out the clever bits and see if it still

20:07.840 --> 20:16.240
runs fast and sometimes it runs faster. So I need the abstraction mechanisms or something like C++

20:16.240 --> 20:24.400
to write compact high-performance code. There was a beautiful keynote by Jason Turner at the CPP

20:24.400 --> 20:36.640
Con a couple of years ago where he decided he was going to program Pong on Motorola 6800, I think it

20:36.640 --> 20:43.600
was. And he says, well, this is relevant because it looks like a microcontroller. It has specialized

20:43.600 --> 20:50.960
hardware, it has not very much memory and it's relatively slow. And so he shows in real time

20:50.960 --> 20:57.760
how he writes Pong, starting with fairly straightforward low-level stuff, improving

20:57.760 --> 21:08.640
his subscriptions and what he's doing, he's writing C++ and it translates into 86 assembler,

21:08.640 --> 21:16.080
which you can do with Clang and you can see it in real time. It's the Compiler Explorer,

21:16.080 --> 21:21.760
which you can use on the web. And then he wrote a little program that translated 86 assembler into

21:22.640 --> 21:30.160
Motorola assembler. And so he types and you can see this thing in real time. You can see it in real

21:30.160 --> 21:36.480
time and even if you can't read the assembly code, you can just see it, his code gets better,

21:36.480 --> 21:45.120
the code, the assembler gets smaller, he increases the abstraction level, uses C++ 11 as it were

21:45.120 --> 21:51.520
better. This code gets cleaner, it gets easier maintained when the code shrinks and it keeps

21:51.520 --> 22:00.640
shrinking. And I could not, in any reasonable amount of time, write that assembler as good

22:01.200 --> 22:08.640
as the compiler generated from really quite nice modern C++. And I'll go as far as to say that

22:08.640 --> 22:18.960
the thing that looked like C was significantly uglier and smaller when it became, and larger

22:18.960 --> 22:26.720
when it became machine code. So the abstractions that can be optimized are important.

22:27.280 --> 22:32.160
I would love to see that kind of visualization in larger code bases. That might be beautiful.

22:32.160 --> 22:37.840
But you can't show a larger code base in a one-hour talk and have it fit on screen.

22:38.640 --> 22:46.800
So that's C and C++. So my two languages would be machine code and C++. And then I think you can

22:46.800 --> 22:53.920
learn a lot from the functional languages. So PIG has Gloloy ML. I don't care which. I think,

22:53.920 --> 23:03.280
actually, you learn the same lessons of expressing especially mathematical notions really clearly

23:03.280 --> 23:11.360
and having a type system that's really strict. And then you should probably have a language for

23:11.360 --> 23:18.640
sort of quickly churning out something. You could pick JavaScript, you could pick Python,

23:18.640 --> 23:23.840
you could pick Ruby. What do you make of JavaScript in general? So you kind of,

23:23.840 --> 23:28.560
you're talking in the platonic sense about languages, about what they're good at,

23:29.360 --> 23:34.400
what their philosophy of design is. But there's also a large user base behind

23:34.400 --> 23:39.440
each of these languages. And they use it in the way sometimes maybe it wasn't really designed for.

23:39.440 --> 23:40.080
That's right.

23:40.080 --> 23:43.680
JavaScript is used way beyond probably what it was designed for.

23:43.680 --> 23:48.800
Let me say it this way. When you build a tool, you do not know how it's going to be used.

23:49.440 --> 23:55.200
You try to improve the tool by looking at how it's being used and when people cut their fingers

23:55.280 --> 24:00.960
off and try and stop that from happening. But really, you have no control over how

24:00.960 --> 24:07.040
something is used. So I'm very happy and proud of some of the things C++ is being used at.

24:07.040 --> 24:13.840
And some of the things I wish people wouldn't do, Bitcoin mining being my favorite example,

24:13.840 --> 24:19.520
uses as much energy as Switzerland and mostly serves criminals.

24:20.320 --> 24:21.120
Yeah.

24:21.120 --> 24:27.360
But back to the languages, I actually think that having JavaScript run in the browser

24:30.480 --> 24:34.640
wasn't an enabling thing for a lot of things. Yes, you could have done it better,

24:34.640 --> 24:37.360
but people were trying to do it better and they were using

24:40.160 --> 24:45.440
sort of more principles, language designs, but they just couldn't do it right. And the

24:46.240 --> 24:52.560
non-professional programmers that write lots of that code just couldn't understand them. So

24:53.840 --> 25:01.520
it did an amazing job for what it was. It's not the previous language and I don't think it ever

25:01.520 --> 25:06.640
will be the previous language, but let's not be bigots here.

25:07.680 --> 25:10.480
So what was the origin story of C++?

25:11.360 --> 25:12.160
Yeah.

25:12.160 --> 25:20.400
So you basically gave a few perspectives of your inspiration of object-oriented programming

25:21.120 --> 25:26.240
that you had a connection with C++ and performance efficiency was an important

25:26.240 --> 25:27.360
a thing you were drawn to.

25:28.320 --> 25:30.000
Efficiency and reliability.

25:30.000 --> 25:30.720
Reliability.

25:30.720 --> 25:31.760
You have to get both.

25:32.880 --> 25:33.920
What's reliability?

25:34.800 --> 25:42.480
I really want my telephone calls to get through and I want the quality of what I am talking

25:42.480 --> 25:48.320
coming out at the other end. The other end might be in London or wherever.

25:49.920 --> 25:56.320
So and you don't want the system to be crashing. If you're doing a bank, you must

25:56.400 --> 26:03.680
crash. It might be your bank account that is in trouble. There's different constraints like

26:03.680 --> 26:08.720
games. It doesn't matter too much if there's a crash, nobody dies and nobody gets ruined.

26:08.720 --> 26:16.720
But I'm interested in the combination of performance partly because of sort of speed

26:16.720 --> 26:25.280
of things being done. Part of being able to do things that is necessary to have reliability

26:26.480 --> 26:34.720
of larger systems. If you spend all your time interpreting a symbol function call,

26:35.280 --> 26:39.440
you are not going to have enough time to do proper signal processing to get the

26:39.440 --> 26:46.080
telephone calls to sound right. Either that or you have to have 10 times as many computers

26:46.080 --> 26:51.840
and you can't afford your phone anymore. It's a ridiculous idea in the modern world because

26:51.840 --> 26:58.000
we've solved all of those problems. I mean they keep popping up in different ways

26:58.000 --> 27:03.120
because we tackle bigger and bigger problems so efficiency remains always an important aspect.

27:03.120 --> 27:10.960
But you have to think about efficiency not just as speed but as an enabler to important things

27:10.960 --> 27:19.840
and one of the things it enables is reliability, is dependability. When I press the pedal,

27:20.400 --> 27:28.000
the brake pedal of a car, it does not actually connect it directly to anything but a computer.

27:28.800 --> 27:33.840
That computer better work. Let's talk about reliability just a little bit.

27:34.480 --> 27:44.000
So modern cars have ECUs, have millions of lines of code today. So this is certainly

27:44.000 --> 27:48.400
especially true of autonomous vehicles where some of the aspect of the control or driver

27:48.480 --> 27:51.440
assistance systems that steer the car, they keep it in the lane and so on.

27:52.080 --> 27:58.240
So how do you think, I talked to regulators, people in government who are very nervous about

27:58.800 --> 28:05.440
testing the safety of these systems of software, ultimately software that makes decisions that

28:05.440 --> 28:11.920
could lead to fatalities. So how do we test software systems like these?

28:12.400 --> 28:23.120
First of all, safety, like performance and like security is a systems property. People tend to

28:23.120 --> 28:30.400
look at one part of a system at a time and saying something like, this is secure. That's all right.

28:30.400 --> 28:35.680
I don't need to do that. Yeah, that piece of code is secure. I'll buy you an operator.

28:35.680 --> 28:42.720
I'll buy you an operator. If you want to have reliability, if you want to have performance,

28:42.720 --> 28:46.000
if you want to have security, you have to look at the whole system.

28:46.960 --> 28:50.160
I did not expect you to say that, but that's very true. Yes.

28:50.160 --> 28:54.560
I'm dealing with one part of the system and I want my part to be really good,

28:55.120 --> 29:02.000
but I know it's not the whole system. Furthermore, making an individual part perfect

29:02.000 --> 29:09.680
may actually not be the best way of getting the highest degree of reliability and performance and

29:09.680 --> 29:17.680
such. There's people who say C++ type safe, not type safe. You can break it. Sure. I can break

29:17.680 --> 29:24.480
anything that runs on a computer. I may not go through your type system. If I wanted to break

29:24.480 --> 29:30.480
into your computer, I'll probably try SQL injection. It's very true. If you think about

29:30.480 --> 29:36.800
safety or even reliability at its system level, especially when a human being is involved,

29:38.160 --> 29:46.480
it starts becoming hopeless pretty quickly in terms of proving that something is

29:47.920 --> 29:52.160
safe to a certain level because there's so many variables. It's so complex.

29:52.160 --> 29:57.600
Well, let's get back to something we can talk about and actually make some progress on.

29:58.480 --> 30:05.680
We can look at C++ programs and we can try and make sure they crash less often.

30:06.960 --> 30:18.240
The way you do that is largely by simplification. The first step is to simplify the code, have less

30:18.240 --> 30:24.480
code, have code that are less likely to go wrong. It's not by runtime testing everything.

30:24.480 --> 30:32.400
It is not by big test frameworks that you're using. Yes, we do that also. But the first step

30:32.960 --> 30:39.600
is actually to make sure that when you want to express something, you can express it directly in

30:39.600 --> 30:46.640
code rather than going through endless loops and convolutions in your head before it gets down the

30:46.640 --> 30:56.560
code. If the way you're thinking about a problem is not in the code, there is a missing piece

30:56.560 --> 31:03.920
that's just in your head. The code, you can see what it does, but it cannot see what you thought

31:03.920 --> 31:09.520
about it unless you have expressed things directly. When you express things directly,

31:10.160 --> 31:16.080
you can maintain it. It's easier to find errors. It's easier to make modifications. It's actually

31:16.080 --> 31:24.560
easier to test it and, lo and behold, it runs faster. Therefore, you can use a smaller number

31:24.560 --> 31:32.240
of computers, which means there's less hardware that could possibly break. I think the key here

31:32.240 --> 31:39.440
is simplification, but it has to be to use the Einstein quote as simple as possible and no

31:39.440 --> 31:45.520
simpler. Not simpler. There are other areas with under constraints where you can be simpler than

31:45.520 --> 31:52.240
you can be in C++, but in the domain I'm dealing with, that's the simplification I'm after.

31:53.440 --> 32:02.640
So how do you inspire or ensure that the Einstein level of simplification is reached?

32:03.360 --> 32:11.920
So can you do code review? Can you look at code? If I gave you the code for the Ford F-150

32:12.880 --> 32:21.520
and said, here, is this a mess or is this okay? Is it possible to tell? Is it possible to regulate?

32:23.040 --> 32:31.600
An experienced developer can look at code and see if it smells. I mixed it for us deliberately.

32:32.560 --> 32:45.440
The point is that it is hard to generate something that is really obviously clean and

32:46.960 --> 32:52.240
can be appreciated, but you can usually recognize when you haven't reached that point.

32:53.200 --> 33:04.960
And so if I have never looked at the F-150 code, so I wouldn't know, but I know what I would be

33:04.960 --> 33:10.960
looking for. There I'll be looking for some tricks that correlate with bugs and elsewhere, and

33:11.200 --> 33:22.880
I have tried to formulate rules for what good code looks like, and the current version of that is

33:22.880 --> 33:32.480
called the C++ Core Guidelines. One thing people should remember is there's what you can do in a

33:32.480 --> 33:40.320
language and what you should do. In a language you have lots of things that is necessary in some

33:40.320 --> 33:46.480
context, but not in others. There's things that exist just because there's 30-year-old code out

33:46.480 --> 33:51.760
there and you can't get rid of it, but you can't have rules that says when you create it, try and

33:51.760 --> 34:01.600
follow these rules. This does not create good programs by themselves, but it limits the damage

34:02.640 --> 34:09.040
for mistakes. It limits the possibilities of mistakes, and basically we are trying to say

34:09.040 --> 34:16.400
what is it that a good programmer does at the fairly simple level of where you use the language

34:16.400 --> 34:25.360
and how you use it. Now I can put all the rules for chiseling in marble. It doesn't mean that somebody

34:25.360 --> 34:33.200
who follows all of those rules can do a masterpiece by Michelangelo. That is, there's something else

34:33.840 --> 34:41.360
to write a good program. Is there something else to create important work of art?

34:43.280 --> 34:52.480
There's some kind of inspiration, understanding, gift, but we can approach the

34:54.800 --> 35:03.040
technical, the craftsmanship level of it. The famous painters, the famous sculptures,

35:03.040 --> 35:13.440
was among other things superb craftsmen. They could express their ideas using their tools very well,

35:14.160 --> 35:20.400
and so these days I think what I'm doing, what a lot of people are doing, we're still trying to

35:20.400 --> 35:29.920
figure out how it is to use our tools very well. For a really good piece of code, you need a spark

35:29.920 --> 35:39.760
of inspiration, and you can't, I think, regulate that. You cannot say that I'll buy your picture

35:39.760 --> 35:49.040
only if you're at least Van Gogh. There are other things you can regulate, but not the inspiration.

35:50.400 --> 35:58.480
I think that's quite beautifully put. It is true that there is an experienced programmer when you

35:58.560 --> 36:09.840
see code that's inspired, that's like Michelangelo, you know it when you see it, and the opposite

36:09.840 --> 36:16.000
of that is code that is messy, code that smells, you know when you see it, and I'm not sure you

36:16.000 --> 36:23.520
can describe it in words except vaguely through guidelines and so on. Yes, it's easier to recognize

36:23.600 --> 36:31.040
ugly than to recognize beauty in code, and for the reason is that sometimes beauty comes from

36:31.040 --> 36:37.840
something that's innovative and unusual, and you have to sometimes think reasonably hard to appreciate

36:37.840 --> 36:48.240
that. On the other hand, the messes have things in common, and you can have static checkers and

36:48.240 --> 37:00.400
dynamic checkers that finds a large number of the most common mistakes. You can catch a lot of

37:00.400 --> 37:08.960
sloppiness mechanically. I'm a great fan of static analysis in particular, because you can check for

37:08.960 --> 37:15.440
not just the language rules, but for the usage of language rules, and I think we will see much

37:15.440 --> 37:21.360
more static analysis in the coming decade. Can you describe what static analysis is? You

37:22.400 --> 37:31.520
represent a piece of code so that you can write a program that goes over that representation

37:32.160 --> 37:43.360
and look for things that are right and not right. So for instance, you can analyze a program to see

37:43.440 --> 37:54.240
if resources are leaked. That's one of my favorite problems. It's not actually all that hard in

37:54.240 --> 38:00.320
modern C++, but you can do it. If you are writing in the C level, you have to have a malloc and a

38:00.320 --> 38:08.880
free, and they have to match. If you have them in a single function, you can usually do it very

38:08.880 --> 38:16.320
easily. If there's a malloc here, there should be a free there. On the other hand, in between can be

38:16.320 --> 38:23.280
drawing complete code, and then it becomes impossible. If you pass that pointer to the memory

38:23.280 --> 38:32.080
out of a function and then want to make sure that the free is done somewhere else, now it gets

38:32.080 --> 38:39.200
really difficult. And so for static analysis, you can run through a program and you can try and figure

38:39.200 --> 38:48.160
out if there's any leaks. And what you will probably find is that you will find some leaks,

38:48.160 --> 38:54.880
and you will find quite a few places where your analysis can't be complete. It might depend on

38:54.880 --> 39:03.840
runtime. It might depend on the cleverness of your analyzer, and it might take a long time. Some of

39:03.840 --> 39:13.840
these programs run for a long time. But if you combine such analysis with a set of rules such

39:13.840 --> 39:21.360
as how people could use it, you can actually see why the rules are violated, and that stops you from

39:21.440 --> 39:27.280
getting into the impossible complexities. You don't want to solve the holding problem.

39:28.640 --> 39:32.240
So static analysis is looking at the code without running the code?

39:32.240 --> 39:39.920
Yes. And thereby, it's almost not a production code, but it's almost like an education tool

39:40.560 --> 39:49.440
of how the language should be used. It guides you. At its best, it would guide you in how you

39:49.440 --> 39:51.840
write future code as well, and you learn together.

39:52.400 --> 39:58.320
Yes. So basically, you need a set of rules for how you use the language. Then you need a static

39:58.320 --> 40:06.960
analysis that catches your mistakes when you violate the rules or when your code ends up

40:07.760 --> 40:12.400
doing things that it shouldn't, despite the rules, because there is the language rules. We can go

40:12.400 --> 40:19.280
further. And again, it's back to my idea that I would much rather find errors before I start

40:19.280 --> 40:26.240
running the code. If nothing else, once the code runs, if it catches an error at run times, I have

40:26.240 --> 40:33.520
to have an error handler. And one of the hardest things to write in code is error handling code,

40:33.520 --> 40:38.640
because you know something went wrong. Do you know really exactly what went wrong?

40:39.360 --> 40:43.120
Usually not. How can you recover when you don't know what the problem was?

40:43.760 --> 40:51.840
You can't be 100 percent sure what the problem was in many, many cases. And this is part of it.

40:51.840 --> 40:58.880
So yes, we need good languages with good type systems. We need rules for how to use them.

40:58.880 --> 41:04.800
We need static analysis. And the ultimate for static analysis is, of course, program proof,

41:04.800 --> 41:12.480
but that still doesn't scale to the kind of systems we deploy. Then we start needing testing and

41:13.280 --> 41:22.000
the rest of the stuff. So C++ is an object-oriented programming language that creates, especially

41:22.000 --> 41:27.040
with its newer versions, as we'll talk about, higher and higher levels of abstraction. So

41:28.160 --> 41:34.000
how do you design? Let's even go back to the origin of C++. How do you design something with

41:34.000 --> 41:44.800
so much abstraction that's still efficient and is still something that you can manage,

41:44.800 --> 41:50.880
do static analysis on, you can have constraints on, they can be reliable, all those things we've

41:50.880 --> 42:00.640
talked about. So to me, there's a slight tension between high level abstraction and efficiency.

42:01.440 --> 42:06.720
That's a good question. I could probably have a year's course just trying to answer it.

42:08.400 --> 42:15.440
Yes, there's a tension between efficiency and abstraction, but you also get the interesting

42:15.440 --> 42:23.920
situation that you get the best efficiency out of the best abstraction. And my main tool for

42:23.920 --> 42:30.640
efficiency for performance actually is abstraction. So let's go back to how C++ got there.

42:32.000 --> 42:36.000
You said it was object-oriented programming language. I actually never said that.

42:37.120 --> 42:43.040
It's always quoted, but I never did. I said C++ supports object-oriented programming

42:43.040 --> 42:49.360
but it's not. And other techniques. And that's important because I think that the

42:49.360 --> 43:00.080
best solution to most complex interesting problems require ideas and techniques from things that

43:00.080 --> 43:12.320
has been called object-oriented data abstraction, function or traditional C-style code, all of the

43:12.320 --> 43:21.680
above. And so when I was designing C++, I soon realized I couldn't just add features.

43:23.520 --> 43:28.560
If you just add what looks pretty or what people ask for or what you think is good,

43:29.840 --> 43:36.560
one by one, you're not going to get a coherent whole. What you need is a set of guidelines that

43:37.520 --> 43:44.480
that guides your decisions. Should this feature be in or should this feature be out? How should a

43:44.480 --> 43:51.520
feature be modified before it can go in and such? And in the book I wrote about that,

43:51.520 --> 43:57.520
the design evolution of C++, there's a whole bunch of rules like that. Most of them are not

43:57.520 --> 44:06.000
language technical. They are things like don't violate static type system because I like static

44:06.000 --> 44:14.800
type system for the obvious reason that I like things to be reliable on reasonable amounts of

44:14.800 --> 44:23.760
hardware. But one of these rules is the zero overhead principle. The zero overhead principle.

44:24.640 --> 44:33.520
It basically says that if you have an abstraction, it should not cost anything compared to write

44:34.080 --> 44:44.560
the equivalent code at a lower level. So if I have, say, a matrix multiply,

44:46.000 --> 44:52.880
it should be written in such a way that you could not drop to the C level of abstraction and

44:52.880 --> 44:59.600
use arrays and pointers and such and run faster. And so people have written such

44:59.680 --> 45:06.800
matrix multiplications. And they've actually gotten code that ran faster than FORTRAN because

45:06.800 --> 45:12.800
once you had the right abstraction, you can eliminate, you can eliminate temporaries and you

45:12.800 --> 45:20.000
can do loop fusion and other good stuff like that. That's quite hard to do by hand and in a lower

45:20.000 --> 45:27.520
level language. And there's some really nice examples of that. And the key here is that that

45:28.240 --> 45:35.840
matrix multiplication, the matrix abstraction allows you to write code that's simple and easy.

45:35.840 --> 45:41.360
You can do that in any language. But with C++, it has the features so that you can also have

45:41.360 --> 45:48.880
this thing run faster than if you hand coded it. Now, people have given that lecture many times,

45:48.880 --> 45:54.800
I and others, and a very common question after the talk where you have demonstrated that you're

45:54.800 --> 46:00.160
going to outperform FORTRAN for dense matrix multiplication, people come up and says, yeah,

46:00.160 --> 46:08.080
but there was C++. If I rewrote your code and see how much faster would it run? The answer is much

46:08.080 --> 46:14.880
slower. This happened the first time actually back in the ages with a friend of mine called

46:14.880 --> 46:23.840
Doug McElroy who demonstrated exactly this effect. And so the principle is you should

46:23.840 --> 46:29.520
give programmers the tools so that the abstractions can follow the zero word principle.

46:30.320 --> 46:36.080
Furthermore, when you put in a language feature on C++ or a standard library feature,

46:36.080 --> 46:42.240
you try to meet this. It doesn't mean it's absolutely optimal, but it means if you hand

46:42.240 --> 46:50.480
code it with the usual facilities in the language in C++ in C, you should not be able to better it.

46:51.120 --> 46:59.440
Usually, you can do better if you use embedded assembler for machine code for some of the

46:59.440 --> 47:04.000
details to utilize part of a computer that the compiler doesn't know about,

47:04.640 --> 47:08.080
but you should get to that point before you beat the abstraction.

47:09.120 --> 47:14.640
So that's a beautiful ideal to reach for. And we meet it quite often.

47:15.600 --> 47:22.080
So where's the magic of that coming from? There's some of it is the compilation process. So the

47:22.080 --> 47:30.720
implementation is C++. Some of it is the design of the feature itself, the guidelines. So I've

47:30.720 --> 47:38.960
recently and often talked to Chris Ladner, so Clang. Just out of curiosity, is your

47:39.200 --> 47:45.920
relationship in general with the different implementations of C++, as you think about

47:46.640 --> 47:51.280
you and committee and other people in C++, think about the design of new features or design of

47:51.280 --> 48:02.720
previous features in trying to reach the ideal of zero overhead? Does the magic come from the design,

48:03.280 --> 48:13.840
the guidelines, or from the implementations? And not all. You go for programming technique,

48:13.840 --> 48:18.080
program language features, and implementation techniques. You need all three.

48:18.960 --> 48:22.880
And how can you think about all three at the same time?

48:23.680 --> 48:29.200
It takes some experience, takes some practice, and sometimes you get it wrong. But after a while,

48:29.200 --> 48:34.640
you sort of get it right. I don't write compilers anymore. But

48:36.720 --> 48:48.240
Brian Kernighan pointed out that one of the reasons C++ succeeded was some of the craftsmanship I put

48:48.240 --> 48:54.000
into the early compilers. And of course, I did the language design. Of course, I wrote a fair

48:54.000 --> 49:02.160
amount of code using this kind of stuff. And I think most of the successes involves progress in

49:02.160 --> 49:10.800
all three areas together. A small group of people can do that. Two, three people can work together

49:10.800 --> 49:15.280
to do something like that. It's ideal if it's one person that has all the skills necessary.

49:15.840 --> 49:22.560
But nobody has all the skills necessary in all the fields where C++ is used. So if you want to

49:22.560 --> 49:29.600
approach my ideal in, say, concurrent programming, you need to know about algorithms of concurrent

49:29.600 --> 49:35.680
programming. You need to know the the trigger of lock free programming. You need to know something

49:35.680 --> 49:41.920
about the compiler techniques. And then you have to know some of the program areas, sorry,

49:41.920 --> 49:48.880
the application areas where this is, like some forms of graphics or some forms of

49:48.880 --> 49:59.040
what we call a web serving kind of stuff. And that's very hard to get into a single head.

49:59.040 --> 50:05.200
But small groups can do it too. So is there differences in your view?

50:06.400 --> 50:10.400
Not saying which is better or so on, but difference in the different implementations

50:10.400 --> 50:16.160
of C++? Why are there several sort of maybe naive questions for me?

50:17.120 --> 50:25.760
This is a very reasonable question. When I designed C++,

50:28.560 --> 50:36.560
most languages have multiple implementations. Because if you run on an IBM, if you run on a

50:36.560 --> 50:42.000
Sun, if you run on a Motorola, there was just many, many companies and they each have their

50:42.000 --> 50:48.240
own compilation structure, the old compilers, it was just fairly common that there was many of them.

50:49.200 --> 50:56.000
And I wrote C front, assuming that other people would write compilers with C++,

50:56.000 --> 51:04.400
if successful. And furthermore, I wanted to utilize all the back end infrastructures that

51:04.400 --> 51:09.840
were available. I soon realized that my users were using 25 different linkers. I couldn't

51:09.840 --> 51:18.640
write my own linker. Yes, I could, but I couldn't write 25 linkers and also get any work done on

51:18.640 --> 51:26.560
the language. And so it came from a world where there was many linkers, many optimizers, many

51:27.200 --> 51:36.160
compiler front ends, not to start, but many operating systems. The whole world was not an

51:36.160 --> 51:43.120
86 and Linux box or something, whatever is the standard today. In the old days, they said a

51:43.680 --> 51:51.280
Vax. So basically, I assumed there would be lots of compilers. It was not a decision that there

51:51.280 --> 52:00.480
should be many compilers. It was just a fact. That's the way the world is. And yes, many compilers

52:01.200 --> 52:11.280
emerged. And today, there's at least four front ends, Clang, GCC, Microsoft, and

52:12.800 --> 52:21.520
EDG. It is the same group. They supply a lot of the independent organizations and the embedded

52:21.520 --> 52:28.320
systems industry. And there's lots and lots of back ends. We have to think about how many

52:28.320 --> 52:35.280
dozen back ends there are, because different machines have different things, especially in the

52:35.280 --> 52:43.600
embedded world, the machines are very different. The architectures are very different. And so

52:43.600 --> 52:52.240
having a single implementation was never an option. Now, I also happen to dislike monocultures.

52:53.200 --> 52:54.400
Monocultures.

52:54.400 --> 53:03.120
They are dangerous, because whoever owns the monoculture can go stale and there's no competition

53:03.120 --> 53:10.080
and there's no incentive to innovate. There's a lot of incentive to put barriers in the way of

53:10.080 --> 53:16.160
change, because, hey, we own the world and it's a very comfortable world for us. And who are you to

53:17.120 --> 53:26.800
mess with that? So I really am very happy that there's four front ends for C++. Clang's great,

53:27.680 --> 53:36.640
but GCC was great. But then it got somewhat stale. Clang came along and GCC is much better now.

53:37.280 --> 53:38.560
Competition is good.

53:38.560 --> 53:47.920
Microsoft is much better now. So at least a low number of front end puts a lot of pressure on

53:51.120 --> 53:57.840
standards compliance and also on performance and error messages and compile time speed,

53:57.840 --> 53:59.360
all this good stuff that we want.

54:00.000 --> 54:07.520
Do you think, crazy question, there might come along, do you hope there might come along

54:08.800 --> 54:15.280
implementation of C++ written given all of its history written from scratch,

54:16.480 --> 54:18.960
so written today from scratch?

54:18.960 --> 54:24.400
Well, Clang and the LLVM is more or less written from scratch.

54:24.880 --> 54:30.960
But there's been C++ 11, 14, 17, 20, there's been a lot of features.

54:30.960 --> 54:37.520
Sooner or later, somebody is going to try again. There has been attempts to write new C++

54:37.520 --> 54:43.280
compilers and some of them has been used and some of them has been absorbed into others and such.

54:43.280 --> 54:44.080
Yeah, it'll happen.

54:45.200 --> 54:52.960
So what are the key features of C++? And let's use that as a way to sort of talk about

54:53.920 --> 55:00.880
the evolution of C++, the new feature. So at the highest level, what are the features that were

55:00.880 --> 55:03.040
there in the beginning? What features got added?

55:04.400 --> 55:15.120
Let's first get a principle or an aim in place. C++ is for people who want to use hardware really

55:15.200 --> 55:19.920
well and then manage the complexity of doing that through abstraction.

55:21.600 --> 55:30.400
And so the first facility you have is a way of manipulating the machines at a fairly low level.

55:30.960 --> 55:39.920
That looks very much like C. It has loops, it has variables, it has pointers like machine

55:40.000 --> 55:49.360
addresses, it can access memory directly, it can allocate stuff in the absolute minimum of space

55:49.360 --> 55:56.400
needed on the machine. There's a machine facing part of C++, which is roughly equivalent to C.

55:57.200 --> 56:04.160
I said C++ could beat C and it can. It doesn't mean I dislike C. If I disliked C, I wouldn't have

56:05.120 --> 56:12.480
built on it. Furthermore, after Dennis Ritchie, I'm probably the major contributor to modern C.

56:13.760 --> 56:24.480
And well, I had lunch with Dennis most days for 16 years and we never had a harsh word between us.

56:24.480 --> 56:31.120
So these C versus C++ fights are for people who don't quite understand what's going on.

56:32.080 --> 56:39.040
And then the other part is the abstraction. And there the key is the class, which is a user-defined

56:39.040 --> 56:45.520
type. And my idea for the class is that you should be able to build a type that's just like the

56:45.520 --> 56:52.880
built-in types in the way you use them, in the way you declare them, in the way you get the

56:52.880 --> 57:01.920
memory, and you can do just as well. So in C++, there's an int. As in C, you should be able to

57:01.920 --> 57:09.920
build an abstraction, a class, which we can call capital int, that you can use exactly like an

57:09.920 --> 57:17.120
integer and run just as fast as an integer. There's the idea right there. And of course,

57:17.120 --> 57:23.840
you probably don't want to use the int itself, but it has happened. People have wanted integers

57:24.720 --> 57:29.360
that were range checked so that you couldn't overflow and such, especially for very safety

57:29.360 --> 57:36.320
critical applications like the fuel injection for a marine diesel engine for the largest ships.

57:37.040 --> 57:43.360
This is a real example, by the way. This has been done. They built themselves an integer

57:43.440 --> 57:48.800
that was just like integer, except that it couldn't overflow. If there was an overflow,

57:48.800 --> 57:56.320
you went into the error handling. And then you built more interesting types. You can build a

57:56.320 --> 58:04.160
matrix, which you need to do graphics, or you could build a gnome for a video game.

58:05.040 --> 58:09.840
And all of these are classes, and they appear just like the built-in types in terms of efficiency

58:09.840 --> 58:18.720
and so on. So what else is there? And flexibility. I don't know. For people who are not familiar with

58:18.720 --> 58:25.600
object-oriented programming, there's inheritance. There's a hierarchy of classes. Just like you

58:25.600 --> 58:34.880
said, create a generic vehicle that can turn left. What people found was that you don't actually

58:35.760 --> 58:47.520
know. How do I say this? A lot of types are related. That is, the vehicles, all vehicles are

58:47.520 --> 58:56.000
related. Bicycles, cars, fire engines, tanks. They have some things in common and some things

58:56.000 --> 59:01.520
that differ. And you would like to have the common things common and having the differences

59:02.480 --> 59:07.520
specific. And when you didn't want to know about the differences, like just turn left,

59:09.120 --> 59:14.560
you don't have to worry about it. That's how you get the traditional object-oriented

59:14.560 --> 59:21.120
programming coming out of Cmula adopted by Smalltalk and C++ and all the other languages.

59:21.680 --> 59:27.360
The other kind of obvious similarity between types comes when you have something like a vector.

59:27.920 --> 59:37.280
Fortran gave us a vector called array of doubles. But the minute you have a vector of

59:37.280 --> 59:44.560
doubles, you want a vector of double precision doubles and for short doubles, for graphics,

59:44.560 --> 59:51.760
and why should you not have a vector of integers while you're at it? Or a vector of

59:51.760 --> 01:00:01.440
vectors and a vector of vectors of chess pieces. Now we have a board, right? So this is, you express

01:00:02.400 --> 01:00:09.280
the commonality as the idea of a vector and the variations come through parameterization.

01:00:10.160 --> 01:00:17.440
And so here we get the two fundamental ways of abstracting, of having similarities of

01:00:18.400 --> 01:00:24.320
types in C++. There's the inheritance and there's a parameterization. There's the object-oriented

01:00:24.320 --> 01:00:30.080
programming and there's the generic programming. With the templates for the generic programming.

01:00:30.080 --> 01:00:38.240
Yep. So you've presented it very nicely, but now you have to make all that happen and make it

01:00:38.240 --> 01:00:44.800
efficient. So generic programming with templates, there's all kinds of magic going on, especially

01:00:45.760 --> 01:00:52.720
recently, that you can help catch up on. But it feels to me like you can do way more than what

01:00:52.720 --> 01:00:58.320
you just said with templates. You can start doing this kind of metaprogramming, this kind of...

01:00:58.320 --> 01:01:05.200
You can do metaprogramming also. I didn't go there in that explanation. We're trying to be very

01:01:05.200 --> 01:01:10.640
basics, but go back on to the implementation. If you couldn't implement this efficiently,

01:01:11.600 --> 01:01:18.080
if you couldn't use it so that it became efficient, it has no place in C++ because it

01:01:18.080 --> 01:01:26.080
will violate the zero overhead principle. So when I had to get object-oriented programming

01:01:26.080 --> 01:01:34.800
inheritance, I took the idea of virtual functions from Simula. Virtual functions is a Simula term,

01:01:34.800 --> 01:01:41.680
class is a Simula term. If you ever use those words, say thanks to Christian Nügel and Olio

01:01:41.680 --> 01:01:49.920
Handahl. And I get the simplest implementation I knew of, which was basically a jump table.

01:01:50.880 --> 01:01:57.040
So you get the virtual function table, the function goes in, do it, does an interaction

01:01:57.040 --> 01:02:01.600
through a table and get the right function. That's how you pick the right thing there.

01:02:01.600 --> 01:02:09.440
And I thought that was trivial. It's close to optimal. And it was obvious. It turned out the

01:02:09.440 --> 01:02:15.920
Simula had a more complicated way of doing it and therefore slower. And it turns out that most

01:02:15.920 --> 01:02:20.400
languages have something that's a little bit more complicated, sometimes more flexible,

01:02:20.400 --> 01:02:25.920
but you pay for it. And one of the strengths of C++ was that you could actually do this

01:02:25.920 --> 01:02:32.960
object-oriented stuff. And your overhead compared to ordinary functions, there's no

01:02:32.960 --> 01:02:41.120
indirection, it's sort of in 5, 10, 25 percent of just the core. It's down there. It's not two.

01:02:42.800 --> 01:02:48.160
And that means you can afford to use it. Furthermore, in C++, you have the distinction

01:02:48.160 --> 01:02:54.080
between a virtual function and a non-virtual function. If you don't want any overhead,

01:02:54.080 --> 01:02:59.520
if you don't need the interaction that gives you the flexibility in object-oriented programming,

01:02:59.520 --> 01:03:07.040
just don't ask for it. So the idea is that you only use virtual functions if you actually need

01:03:07.040 --> 01:03:13.040
the flexibility. So it's not zero overhead, but it's zero overhead compared to any other

01:03:13.040 --> 01:03:24.480
way of achieving the flexibility. Now, or to parameterization. Basically, the compiler looks at

01:03:26.720 --> 01:03:37.040
at the template, say the vector, and it looks at the parameter and then combines the two and

01:03:37.040 --> 01:03:43.440
generates a piece of code that is exactly as if you're ridden a vector of that specific type.

01:03:44.560 --> 01:03:50.640
So that's the minimal overhead. If you have many template parameters, you can actually

01:03:50.640 --> 01:03:57.280
combine code that the compiler couldn't usually see at the same time, and therefore get code

01:03:57.280 --> 01:04:05.040
that is faster than if you had handwritten the stuff, unless you were very, very clever.

01:04:05.040 --> 01:04:13.200
So the thing is parameterized code, the compiler fills stuff in during the compilation process,

01:04:13.200 --> 01:04:20.640
not during runtime. That's right. And furthermore, it gives all the information it's gotten,

01:04:21.360 --> 01:04:29.040
which is the template, the parameter, and the context of use. It combines the three and generates

01:04:29.040 --> 01:04:37.120
good code. But it can generate. Now, it's a little outside of what I'm even comfortable

01:04:37.120 --> 01:04:43.440
thinking about, but it can generate a lot of code. Yes. And how do you, I remember

01:04:44.560 --> 01:04:52.800
being both amazed at the power of that idea and how ugly the debugging looked.

01:04:53.520 --> 01:05:00.160
Yes. Debugging can be truly horrid. Come back to this because I have a solution. Anyway,

01:05:01.040 --> 01:05:10.400
the debugging was ugly. The code generated by C++ has always been ugly because there's these

01:05:10.400 --> 01:05:17.760
inherent optimizations. A modern C++ compiler has front-end, middle-end, and back-end optimizations.

01:05:17.760 --> 01:05:25.200
Even Cfront, back in 83, had front-end and back-end optimizations. I actually took the code,

01:05:26.800 --> 01:05:33.680
generated an internal representation, munched that representation to generate good code.

01:05:34.240 --> 01:05:39.600
So people say it's not a compiler, it generates C. The reason it generated C was I wanted to use

01:05:39.600 --> 01:05:45.280
a C's code generators that was really good at back-end optimizations. But I needed front-end

01:05:45.360 --> 01:05:56.240
optimizations. And therefore, the C I generated was optimized C. The way a really good handcrafted

01:05:56.240 --> 01:06:03.440
optimizer human could generate it, and it was not meant for humans. It was the output of a program,

01:06:03.440 --> 01:06:10.960
and it's much worse today. And with templates, it gets much worse still. So it's hard to combine

01:06:11.520 --> 01:06:20.560
simple debugging with the optimal code, because the idea is to drag in information from different

01:06:20.560 --> 01:06:32.960
parts of the code to generate machine code. And that's not readable. So what people often do

01:06:33.040 --> 01:06:42.240
for debugging is they turn the optimizer off. And so you get code that when something in your

01:06:42.240 --> 01:06:48.480
source code looks like a function core, it is a function core. When the optimizer is turned on,

01:06:49.120 --> 01:06:55.280
it may disappear, the function core. It may inline. And so one of the things you can do

01:06:56.000 --> 01:07:04.240
is you can actually get code that is smaller than the function core because you eliminate the

01:07:04.240 --> 01:07:12.080
function preamble and return. And that's just the operation there. One of the key things when I did

01:07:14.560 --> 01:07:21.200
templates was I wanted to make sure that if you have, say, a sort algorithm and you give it a

01:07:22.160 --> 01:07:30.480
sorting criteria, if that sorting criteria is simply comparing things with less than,

01:07:31.280 --> 01:07:38.880
the code generated should be the less than, not a indirect function core to a comparison

01:07:40.480 --> 01:07:47.120
object, which is what it is in the source code. But we really want down to the single instruction.

01:07:48.080 --> 01:07:55.280
And, but anyway, turn off the optimizer and you can debug. The first level of debugging

01:07:56.160 --> 01:08:01.360
can be done and I always do without the optimization on because then I can see what's going on.

01:08:02.000 --> 01:08:10.160
And then there's this idea of concepts that put some, now I've never even,

01:08:11.120 --> 01:08:17.680
I don't know if it was ever available in any form, but it puts some constraints on the stuff

01:08:17.680 --> 01:08:25.200
you can parameterize, essentially. Let me try and explain this. So yes, it wasn't there

01:08:26.400 --> 01:08:33.840
10 years ago. We have had versions of it that actually work for the last four or five years.

01:08:34.800 --> 01:08:43.760
It was a design by Gaby does raise at true sort and me, we were professors and postdocs in Texas

01:08:43.760 --> 01:08:53.200
at the time. And the implementation by interest sort and has been available for that time.

01:08:54.080 --> 01:09:03.280
And it is part of C plus plus 20. And this standard library that uses it. So this is

01:09:03.280 --> 01:09:13.920
becoming really very real. It's available in Klangen and GCC, GCC for a couple of years.

01:09:13.920 --> 01:09:20.000
And I believe Microsoft is soon going to do it expect all of C plus plus 20 to be available.

01:09:20.000 --> 01:09:30.160
So in all the major compilers in 20. But this kind of stuff is available now. I'm just saying

01:09:30.160 --> 01:09:35.760
that because otherwise people might think I was talking about science fiction. And so what I'm going

01:09:35.760 --> 01:09:43.120
to say is concrete, you can write it today. And there's production uses of it. So the basic idea

01:09:43.120 --> 01:09:55.040
is that when you have a generic component, like a sort function, the sort function will require

01:09:55.040 --> 01:10:03.120
at least two parameters, one, a data structure with a given type and a comparison criteria.

01:10:04.640 --> 01:10:09.920
And these things are related, but obviously you can't compare things if you don't know what the

01:10:09.920 --> 01:10:18.720
type of things you compare. And so you want to be able to say, I'm going to sort something and it

01:10:18.720 --> 01:10:24.720
is to be sortable. What does it mean to be sortable? You look it up in the standard, it has to have a

01:10:24.720 --> 01:10:31.200
it has to be a sequence with a beginning and an end. There has to be random access to that sequence.

01:10:31.200 --> 01:10:37.200
And there has to be the element types has to be comparable.

01:10:38.080 --> 01:10:41.280
Which means less than operator can operate on. Yes.

01:10:41.280 --> 01:10:47.280
Loss of logical operator can operate. Basically what concepts are their compile time predicates,

01:10:47.280 --> 01:10:53.120
their predicates you can ask, are you a sequence? Yes, I have a beginning and end.

01:10:53.920 --> 01:10:59.120
Are you a random access sequence? Yes, I have a subscripting and plus.

01:11:01.120 --> 01:11:06.640
Is your element type something that has a less than? Yes, I have a less than it's and

01:11:07.360 --> 01:11:13.200
so basically that's the system. And so instead of saying, I will take a parameter of any type,

01:11:13.200 --> 01:11:19.920
it'll say I'll take something that's sortable. And it's well defined. And so we say, okay,

01:11:20.720 --> 01:11:25.680
you can sort with less than I don't want less than I want greater than or something I invent.

01:11:25.680 --> 01:11:28.880
So you have two parameters, the sortable thing and the

01:11:29.920 --> 01:11:34.960
comparison criteria. And the comparison criteria will say, well, I can,

01:11:37.120 --> 01:11:40.960
you can write in saying it should operate on the element type.

01:11:42.320 --> 01:11:48.560
And it has the comparison operations. So that's just simply the fundamental thing.

01:11:48.560 --> 01:11:54.560
It's compile time predicates. Do you have the properties I need? So it specifies the requirements

01:11:55.280 --> 01:12:02.240
of the code on the parameters that it gets. It's very similar to types, actually.

01:12:03.200 --> 01:12:13.280
But operating in the space of concepts. The word concept was used by Alex Stefanov,

01:12:13.280 --> 01:12:18.160
who is sort of the father of generic programming in the context of C++.

01:12:19.520 --> 01:12:25.120
You know, there's other places that use that word, but the way we call generic programming is

01:12:25.120 --> 01:12:30.320
Alex's. And he called them concepts, because he said they're the sort of the fundamental

01:12:30.320 --> 01:12:36.480
concepts of an area. So they should be called concepts. And we've had concepts all the time.

01:12:36.480 --> 01:12:42.560
If you look at the K&R book about C, C has arithmetic types, and it has

01:12:43.440 --> 01:12:52.160
integral types. It says so in the book. And then it lists what they are, and they have

01:12:52.160 --> 01:12:58.720
certain properties. The difference today is that we can actually write a concept that will ask a

01:12:58.720 --> 01:13:05.200
type, are you an integral type? Do you have the properties necessary to be an integral type?

01:13:05.280 --> 01:13:13.360
Do you have plus, minus, divide, and such? So maybe the story of concepts,

01:13:14.000 --> 01:13:22.720
because I thought it might be part of C++11, C0x, whatever it was at the time.

01:13:27.280 --> 01:13:31.360
We'll talk a little bit about this fascinating process of standards, because I think it's

01:13:31.360 --> 01:13:38.080
really interesting for people. It's interesting for me. But why did it take so long? What shapes

01:13:38.080 --> 01:13:48.320
did the idea of concepts take? What were the challenges? Back in 1987 or thereabouts? 1987?

01:13:49.120 --> 01:13:54.960
Well, 1987 or thereabouts. When I was designing templates, obviously, I wanted to express the

01:13:54.960 --> 01:14:02.720
notion of what is required by a template of its arguments. And so I looked at this.

01:14:03.280 --> 01:14:10.400
And basically, for templates, I wanted three properties. I wanted to be very flexible.

01:14:11.040 --> 01:14:19.040
It had to be able to express things I couldn't imagine, because I know I can't imagine everything,

01:14:19.040 --> 01:14:25.680
and I've been suffering from languages that try to constrain you to only do what the designer

01:14:25.680 --> 01:14:34.640
thought good. I didn't want to do that. Secondly, it had to run as fast or faster than hand-written

01:14:34.640 --> 01:14:42.080
code. So basically, if I have a vector of t and I take a vector of char, it should run as fast as

01:14:42.080 --> 01:14:50.560
you build a vector of char yourself without parameterization. And thirdly, I wanted to be

01:14:50.560 --> 01:15:00.480
able to express the constraints of the arguments, have proper type checking of the interfaces,

01:15:01.680 --> 01:15:09.360
and neither I nor anybody else at the time knew how to get all three. And I thought for C++,

01:15:09.360 --> 01:15:17.600
I must have the two first. Otherwise, it's not C++. And it bothered me for another couple of decades

01:15:17.600 --> 01:15:24.320
that I couldn't solve the third one. I mean, I was the one that put function argument type checking

01:15:24.320 --> 01:15:30.640
into C. I know the value of good interfaces. I didn't invent that idea. It's very common,

01:15:30.640 --> 01:15:38.240
but I did it. And I wanted to do the same for templates, of course, and I couldn't. So it bothered

01:15:38.240 --> 01:15:48.400
me. Then we tried again, 2002, 2003. Gaby just raised and I started analyzing the problem,

01:15:49.200 --> 01:15:57.360
explained possible solutions. It was not a complete design. A group in University of Indiana,

01:15:58.480 --> 01:16:05.520
an old friend of mine, they started a project at Indiana and

01:16:08.880 --> 01:16:15.600
we thought we could get a good system of concepts in another two or three years.

01:16:17.360 --> 01:16:29.280
That would have made C++ 11 to C++ 06 or 07. Well, it turned out that I think we got a lot

01:16:29.360 --> 01:16:38.400
of the fundamental ideas wrong. They were too conventional. They didn't quite fit C++, in my

01:16:38.400 --> 01:16:46.560
opinion. Didn't serve implicit conversions very well. It didn't serve mixed type arithmetic,

01:16:46.560 --> 01:16:52.640
mixed type computations very well. A lot of stuff came out of the functional

01:16:53.200 --> 01:17:05.600
community. That community didn't deal with multiple types in the same way as C++ does,

01:17:06.240 --> 01:17:13.280
had more constraints on what you could express, and didn't have the draconian

01:17:14.000 --> 01:17:20.480
performance requirements. Basically, we tried. We tried very hard. We had some successes,

01:17:21.360 --> 01:17:29.440
but it just in the end wasn't. Didn't compile fast enough, was too hard to use,

01:17:30.320 --> 01:17:39.600
and didn't run fast enough unless you had optimizers that was beyond the state of the art.

01:17:39.600 --> 01:17:48.080
They still are. We had to do something else. Basically, it was the idea that a set of parameters

01:17:48.560 --> 01:17:54.480
has defined a set of operations, and you go through an interaction table just like for

01:17:54.480 --> 01:18:01.440
virtual functions, and then you try to optimize the interaction away to get performance.

01:18:02.720 --> 01:18:10.960
We just couldn't do all of that. Get back to the standardization. We are standardizing C++

01:18:10.960 --> 01:18:18.400
under ISO rules, which are very open process. People come in. There's no requirements for

01:18:18.400 --> 01:18:28.560
education or experience. You've started to develop C++. When was the first standard

01:18:28.560 --> 01:18:34.720
established? What is that like, the ISO standard? Is there a committee that you're referring to?

01:18:34.720 --> 01:18:39.840
Sure. There's a group of people. What's that like? How often do you meet? What's the discussion?

01:18:39.840 --> 01:18:52.800
I'll try and explain that. Sometime in early 1989, two people, one from IBM, one from HP,

01:18:52.800 --> 01:18:58.560
turned up in my office and told me I would like to standardize C++.

01:19:00.400 --> 01:19:08.240
This was a new idea to me. I pointed out that it wasn't finished yet, and it wasn't ready for

01:19:08.240 --> 01:19:14.000
formal standardization and such. They said, no, Brianna, you haven't gotten it. You really want to

01:19:14.000 --> 01:19:23.440
do this. Our organizations depend on C++. We cannot depend on something that's owned by

01:19:23.440 --> 01:19:30.400
another corporation that might be a competitor. Of course, we could rely on you, but you might

01:19:30.400 --> 01:19:37.120
get run over by a boss. We really need to get this out in the open. It has to be

01:19:38.080 --> 01:19:48.160
standardized under formal rules. We are going to standardize it under ISO rules,

01:19:48.800 --> 01:19:53.040
and you really want to be part of it because, basically, otherwise, we'll do it ourselves.

01:19:55.120 --> 01:20:03.600
We know you can do it better. Through a combination of arm twisting and flattery,

01:20:04.560 --> 01:20:06.560
it got started. In late

01:20:08.800 --> 01:20:17.360
in late 89, there was a meeting in DC at the, actually, no, it was not ISO,

01:20:17.360 --> 01:20:20.720
then it was ANSI, the American National Standard we're doing.

01:20:23.280 --> 01:20:28.800
We met there. We were lectured on the rules of how to do an ANSI standard.

01:20:28.800 --> 01:20:34.320
There was about 25 of us there, which apparently was a new record for that kind of meeting.

01:20:37.120 --> 01:20:42.400
Some of the old C guys that has been standardized in C was there, so we got some expertise in.

01:20:43.360 --> 01:20:49.200
The way this works is that it's an open process. Anybody can sign up if they pay the

01:20:49.200 --> 01:20:58.800
minimal fee, which is about $1,000. It's a little bit more now. I think it's $1,280.

01:20:59.920 --> 01:21:07.360
It's not going to kill you. We have three meetings a year. This is fairly standard.

01:21:08.320 --> 01:21:16.480
We tried two meetings a year for a couple of years that didn't work too well. Three one-week

01:21:16.480 --> 01:21:24.720
meetings a year. You meet and you have technical meetings, technical discussions,

01:21:24.720 --> 01:21:31.120
and then you bring proposals forward for votes. The votes are done one person per

01:21:32.560 --> 01:21:40.560
one vote per organization, so you can't have, say, IBM come in with 10 people and

01:21:40.560 --> 01:21:44.560
dominate things that's not allowed. These are organizations that extents to the

01:21:44.560 --> 01:21:56.000
UC++ or individuals. It's a bunch of people in the room deciding the design of a language

01:21:56.000 --> 01:22:03.840
based on which a lot of the world's systems run. Right. Well, I think most people would agree it's

01:22:03.840 --> 01:22:11.920
better than if I decided it, or better than if a single organization like AG&C decided it.

01:22:11.920 --> 01:22:17.520
I don't know if everyone agrees to that, by the way. Bureaucracies have their critics too.

01:22:17.520 --> 01:22:25.680
Yes. Look, standardization is not pleasant. It's horrifying.

01:22:25.680 --> 01:22:26.720
It's like democracy.

01:22:26.720 --> 01:22:32.560
But we, exactly. As Churchill says, democracy is the worst way except for the others.

01:22:33.520 --> 01:22:36.560
And it's about, say, the same performance standardization.

01:22:37.200 --> 01:22:44.880
But anyway, so we meet and we have these votes and that determines what the standard is.

01:22:45.760 --> 01:22:53.920
Couple of years later, we extended this so it became worldwide. We have standard organizations

01:22:53.920 --> 01:23:08.320
that are active in currently 15 to 20 countries and another 15 to 20 are sort of looking and voting

01:23:09.440 --> 01:23:16.160
based on the rest of the work on it. And we meet three times a year. Next week, I'll be in Cologne,

01:23:16.240 --> 01:23:24.000
Germany, spending a week doing standardization. And then we will vote out the committee draft

01:23:24.000 --> 01:23:33.600
or C++20, which goes to the national standards committees for comments and requests for changes

01:23:33.600 --> 01:23:39.680
and improvements. Then we do that. And there's a second set of votes where hopefully everybody

01:23:39.680 --> 01:23:47.040
votes in favor. This has happened several times. The first time we finished, we started in the

01:23:47.040 --> 01:23:55.760
first technical meeting was in 1990. The last was in 98. We voted it out. That was the standard

01:23:55.760 --> 01:24:02.880
that people used till 11 or a little bit past 11. And it was an international standard.

01:24:03.600 --> 01:24:12.320
All the countries voted in favor. It took longer with 11. I'll mention why, but all the

01:24:12.320 --> 01:24:21.920
nations voted in favor. And we work on the basis of consensus. That is, we do not want something

01:24:21.920 --> 01:24:29.440
that passes 60-40, because then we're getting dialects and opponents and people complain too

01:24:29.920 --> 01:24:36.400
much. They all complain too much. But basically, it has no real effect. The standards have been

01:24:36.400 --> 01:24:44.320
obeyed. They have been working to make it easier to use many compilers, many computers, and all

01:24:44.320 --> 01:24:52.000
of that kind of stuff. And so the first, it was traditional with ISO standards to take 10 years.

01:24:52.560 --> 01:24:58.640
We did the first one in eight, brilliant. And we thought we were going to do the next one in six,

01:24:58.640 --> 01:25:08.240
because now we're good at it. It took 13. Yeah, it was named OX. It was named OX.

01:25:08.240 --> 01:25:13.520
Hoping that you would at least get it within the single, within the odds, the single digits.

01:25:13.520 --> 01:25:17.600
I thought we would get, I thought we would get six, seven, or eight.

01:25:17.600 --> 01:25:23.120
The confidence of youth. That's right. Well, the point is that this was sort of like a second

01:25:24.080 --> 01:25:29.200
system effect. That is, we now knew how to do it. And so we're going to do it much better.

01:25:29.200 --> 01:25:35.680
And we've got more ambitious. And it took longer. Furthermore, there is this tendency,

01:25:35.680 --> 01:25:45.200
because it's a 10-year cycle, or age, doesn't matter. Just before you're about to ship,

01:25:45.280 --> 01:25:53.760
somebody has a bright idea. And so we really, really must get that in.

01:25:55.440 --> 01:26:04.000
We did that successfully with the STL. We got the standard library that gives us all the STL

01:26:04.000 --> 01:26:11.040
stuff. That basically, I think it saved C++. It was beautiful. And then people tried it with other

01:26:11.040 --> 01:26:17.520
things. And it didn't work so well. They got things in, but it wasn't as dramatic. And it took

01:26:17.520 --> 01:26:26.720
longer and longer and longer. So after C++ 11, which was a huge improvement, and what basically

01:26:26.720 --> 01:26:35.760
what most people are using today, we decided never again. And so how do you avoid those slips?

01:26:36.480 --> 01:26:45.200
And the answer is that you ship more often. So that if you have a slip on a 10-year cycle,

01:26:46.480 --> 01:26:52.400
by the time you know it's a slip, there's 11 years till you get it. Now with a three-year cycle,

01:26:53.200 --> 01:27:01.280
there is about four years till you get it. Like the delay between feature freeze and

01:27:02.080 --> 01:27:09.680
shipping. So you always get one or two years more. And so we shipped 14 on time. We shipped

01:27:10.240 --> 01:27:19.680
17 on time. And we will ship 20 on time. It'll happen. And furthermore, this

01:27:19.680 --> 01:27:25.680
allows, this gives a predictability that allows the implementers, the compiler implementers,

01:27:25.760 --> 01:27:33.680
the library implementers, they have a target and they deliver on it. 11 took two years before

01:27:34.400 --> 01:27:42.000
most compilers were good enough. 14, most compilers were actually getting pretty good in 14.

01:27:43.040 --> 01:27:51.360
17, everybody shipped in 17. We are going to have at least almost everybody ship,

01:27:51.360 --> 01:27:59.120
almost everything in 20. And I know this because they're shipping in 19. Predictability is good,

01:27:59.120 --> 01:28:03.920
delivery on time is good. And so, yeah. That's great. That's how it works.

01:28:05.920 --> 01:28:12.640
There's a lot of features that came in in C++ 11. There's a lot of features at the birth of C++

01:28:13.280 --> 01:28:20.320
that were amazing and ideas with concepts in 2020. What to you is the most,

01:28:21.840 --> 01:28:32.480
just to you personally, beautiful or just do you sit back and think, wow, that's just nice

01:28:33.280 --> 01:28:42.160
clean feature of C++? I have written two papers for the history of programming languages

01:28:42.160 --> 01:28:48.400
conference, which basically asked me such questions. And I'm writing a third one, which I will

01:28:48.400 --> 01:28:54.800
deliver at the history of programming languages conference in London next year. So I've been

01:28:54.800 --> 01:29:01.440
thinking about that. And there is one clear answer, constructors and destructors. The way a

01:29:01.440 --> 01:29:09.600
constructor can establish the environment for the use of a type for an object and the destructor

01:29:09.680 --> 01:29:16.800
cleans up any messes at the end of it. That is the key to C++. That's why we don't have to use

01:29:16.800 --> 01:29:22.800
garbage collection. That's how we can get predictable performance. That's how you can get

01:29:23.680 --> 01:29:32.160
the minimal overhead in many, many cases and have really clean types. It's the idea of

01:29:32.160 --> 01:29:41.280
constructor-destructor pairs. Sometimes it comes out under the name RII, resource acquisition is

01:29:41.280 --> 01:29:46.400
initialization, which is the idea that you grab resources and the constructor and release them

01:29:46.400 --> 01:29:54.160
in destructor. It's also the best example of why I shouldn't be in advertising. I get the best idea

01:29:54.160 --> 01:30:01.440
and I call it resource acquisition is initialization. Not the greatest naming I've ever heard.

01:30:03.120 --> 01:30:13.600
So it's types, abstraction of types. You said, I want to create my own types.

01:30:13.600 --> 01:30:20.960
So types is an essential part of C++ and making them efficient is the key part.

01:30:21.920 --> 01:30:29.040
And to you, this is almost getting philosophical, but the construction and the destruction,

01:30:29.040 --> 01:30:35.760
the creation of an instance of a type and the freeing of resources from that

01:30:36.400 --> 01:30:44.480
instance of a type is what defines the object. That's almost like birth and death is what

01:30:44.480 --> 01:30:50.880
defines human life. Yeah, that's right. By the way, philosophy is important. You can't do

01:30:51.680 --> 01:30:57.680
good language design without philosophy because what you are determining is what people can express

01:30:57.680 --> 01:31:06.720
and how. This is very important. By the way, constructors, destructors came into C++ in 79

01:31:07.520 --> 01:31:14.160
in about the second week of my work with what was then called C++. It is a fundamental idea.

01:31:15.200 --> 01:31:21.280
Next comes the fact that you need to control copying because once you control, as you said,

01:31:21.280 --> 01:31:28.480
birth and death, you have to control taking copies, which is another way of creating an object.

01:31:29.280 --> 01:31:35.200
And finally, you have to be able to move things around so you get the move operations.

01:31:35.200 --> 01:31:40.480
And that's the set of key operations you can define on a C++ type.

01:31:41.840 --> 01:31:51.040
And so to you, those things are just a beautiful part of C++ that is at the core of it all.

01:31:51.440 --> 01:31:56.800
Yes. You mentioned that you hope there will be one unified set of guidelines

01:31:56.800 --> 01:32:02.320
in the future for how to construct the programming language. So perhaps not one programming language,

01:32:02.320 --> 01:32:10.160
but a unification of how we build programming languages, if you remember such statements.

01:32:10.160 --> 01:32:15.040
I have some trouble remembering it, but I know the origin of that idea.

01:32:15.040 --> 01:32:20.000
So maybe you can talk about sort of C++ has been improving. There's been a lot of programming

01:32:20.000 --> 01:32:26.480
language. Where does the archer history taking us? Do you hope that there is a unification about

01:32:27.040 --> 01:32:30.480
the languages with which we communicate in the digital space?

01:32:32.560 --> 01:32:42.400
Well, I think that languages should be designed not by clobbering language features together and

01:32:43.440 --> 01:32:47.920
doing slightly different versions of somebody else's ideas, but through

01:32:48.880 --> 01:32:56.080
the creation of a set of principles, rules of thumbs, whatever you call them.

01:32:57.200 --> 01:33:05.280
I made them for C++ and we're trying to teach people in the Standards Committee about these

01:33:05.280 --> 01:33:09.680
rules because a lot of people come in and say, I've got a great idea. Let's put it in the language.

01:33:10.400 --> 01:33:15.600
And then you have to ask, why does it fit in the language? Why does it fit in this language?

01:33:15.680 --> 01:33:21.680
It may fit in another language and not here or it may fit here and not the other language.

01:33:21.680 --> 01:33:26.240
So you have to work from a set of principles and you have to develop that set of principles.

01:33:27.200 --> 01:33:38.880
And one example that I sometimes remember is I was sitting down with some of the designers of

01:33:38.880 --> 01:33:45.760
Common Lisp and we were talking about languages and language features and

01:33:46.880 --> 01:33:53.440
obviously we didn't agree about anything because, well, Lisp is not C++ and vice versa.

01:33:53.440 --> 01:33:55.040
It's too many parentheses.

01:33:55.040 --> 01:34:05.120
But suddenly we started making progress. I said, I had this problem and I developed it

01:34:05.120 --> 01:34:09.840
according to these ideas and they said, why? We had that problem, different problem,

01:34:09.840 --> 01:34:14.800
and we developed it with the same kind of principles. And so we worked through

01:34:16.560 --> 01:34:23.600
large chunks of C++ and large chunks of Common Lisp and figured out we actually had

01:34:24.320 --> 01:34:31.200
similar sets of principles of how to do it. But the constraints on our designs were very

01:34:31.200 --> 01:34:38.480
different and the aims for the usage was very different. But there was commonality

01:34:39.200 --> 01:34:45.840
in the way you reason about language features and the fundamental principles you were trying to do.

01:34:46.400 --> 01:34:53.200
So do you think that's possible to order? So just like there is perhaps a unified theory of

01:34:53.920 --> 01:34:58.720
physics, of the fundamental forces of physics, I'm sure there is

01:34:59.680 --> 01:35:05.840
commonalities among the languages, but there's also people involved that help

01:35:05.840 --> 01:35:12.560
drive the development of these languages. Do you have a hope or an optimism that

01:35:12.560 --> 01:35:19.440
there will be a unification if you think about physics in Einstein towards a simplified

01:35:20.080 --> 01:35:22.720
language? Do you think that's possible?

01:35:23.440 --> 01:35:31.680
So let's remember sort of modern physics, I think started with Galileo in the 1300s. So

01:35:31.680 --> 01:35:40.960
they've had 700 years to get going. Modern computing started in about 49. We've got,

01:35:41.680 --> 01:35:49.520
what is that, 70 years. They have 10 times. And furthermore, they're not as bothered with

01:35:49.600 --> 01:35:57.360
people using physics the way we are worried about programming. It's done by humans. So

01:35:58.240 --> 01:36:04.720
each have problems and constraints the others have, but we are very immature compared to physics.

01:36:07.360 --> 01:36:14.000
So I would look at sort of the philosophical level and look for fundamental principles.

01:36:14.800 --> 01:36:24.160
Like you don't leak resources, you shouldn't. You don't take errors at runtime that you don't

01:36:24.160 --> 01:36:32.080
need to. You don't violate some kind of type system. There's many kinds of type systems,

01:36:32.080 --> 01:36:39.120
but when you have one, you don't break it, et cetera, et cetera. There will be quite a few.

01:36:39.920 --> 01:36:46.960
And it will not be the same for all languages. But I think if we step back at some kind of

01:36:46.960 --> 01:36:55.280
philosophical level, we would be able to agree on sets of principles that applied to sets of

01:36:55.280 --> 01:37:06.880
problem areas. And within an area of use, like in C++'s case, what used to be called systems

01:37:06.880 --> 01:37:13.200
programming, the area between the hardware and the fluffier parts of the system,

01:37:14.640 --> 01:37:21.360
you might very well see a convergence. So these days, you see Rust having adopted RAII.

01:37:22.080 --> 01:37:27.360
And some time accuses me for having borrowed it 20 years before they discovered it. But

01:37:28.320 --> 01:37:37.920
it's, we're seeing some kind of convergence here instead of relying on garbage collection all

01:37:37.920 --> 01:37:45.920
the time. The garbage collection languages are doing things like the dispose patterns and such

01:37:45.920 --> 01:37:52.480
that imitate some of the construction, destruction stuff. And they're trying not to use the garbage

01:37:52.480 --> 01:37:57.840
collection all the time and things like that. So there's a conversion. But I think we have

01:37:57.840 --> 01:38:03.040
to step back to the philosophical level, agree on principles, and then we'll see some conversions,

01:38:04.320 --> 01:38:10.720
convergences, and it will be application domain specific.

01:38:12.160 --> 01:38:17.600
So a crazy question, but I work a lot with machine learning with deep learning. I'm not

01:38:17.600 --> 01:38:24.720
sure if you touched that world much. But you could think of programming as a thing that takes

01:38:24.720 --> 01:38:30.160
some input. Programming is the task of creating a program. And the program takes some input and

01:38:30.160 --> 01:38:38.720
produces some output. So machine learning systems train on data in order to be able to take an input

01:38:38.720 --> 01:38:48.240
and produce output. But they're messy, fuzzy things, much like we as children grow up,

01:38:48.880 --> 01:38:53.360
you know, we take some input, we make some output, but we're noisy, we mess up a lot,

01:38:53.360 --> 01:39:00.560
we're definitely not reliable biological system or a giant mess. So there's a sense in which

01:39:00.560 --> 01:39:07.520
machine learning is a kind of way of programming, but just fuzzy. It's very, very, very different

01:39:07.520 --> 01:39:14.880
than C plus plus. Because C plus plus is like it's just like you said, it's extremely reliable.

01:39:14.880 --> 01:39:20.240
It's efficient. It's, you know, you can you can measure you can test in a bunch of different ways

01:39:21.280 --> 01:39:25.040
with biological systems or machine learning systems, you can't say

01:39:26.240 --> 01:39:31.920
much, except sort of empirically saying that 99.8% of the time, it seems to work.

01:39:31.920 --> 01:39:39.920
What do you think about this fuzzy kind of programming? Do you even see it as programming?

01:39:39.920 --> 01:39:42.880
Is it solely and totally another kind of world?

01:39:43.600 --> 01:39:50.160
I think it's a different kind of world. And it is fuzzy. And in my domain, I don't like fuzziness.

01:39:51.520 --> 01:39:57.840
That is, people say things like they want everybody to be able to program.

01:39:57.840 --> 01:40:07.200
But I don't want everybody to program my, my, my, my, my airplane controls or the car controls.

01:40:08.160 --> 01:40:13.920
I want that to be done by engineers. I want that to be done with people that are specifically

01:40:13.920 --> 01:40:23.840
educated and trained for doing building things. And it is not for everybody. Similarly, a language

01:40:23.840 --> 01:40:33.760
like C++ is not for everybody. It is generated to be a sharp and effective tool for professionals,

01:40:33.760 --> 01:40:40.000
basically, and definitely for people who, who, who aim at some kind of precision.

01:40:40.800 --> 01:40:48.000
You don't have people doing calculations without understanding math, right? Counting on your fingers

01:40:48.000 --> 01:40:55.520
is not going to cut it if you want to fly to the moon. And so there are areas where

01:40:56.960 --> 01:41:08.560
an 84% accuracy rate, 16% false positive rate is perfectly acceptable and where people will

01:41:08.560 --> 01:41:17.280
probably get no more than 70. You said 98%. I, what I've seen is more like 84. And by,

01:41:17.760 --> 01:41:21.520
really, a lot of blood, sweat and tears, you can get up to the 92 and a half.

01:41:22.880 --> 01:41:33.760
So this is fine if it is say pre-screening stuff before the human look at it. It is not

01:41:33.760 --> 01:41:41.120
good enough for, for life-threatening situations. And so there's lots of areas where, where the

01:41:41.120 --> 01:41:46.800
fuzziness is perfectly acceptable and good and better than humans, cheaper than humans.

01:41:47.600 --> 01:41:54.400
But it's not the kind of engineering stuff I'm mostly interested in. I worry a bit about

01:41:55.200 --> 01:42:00.240
machine learning in the context of cars. You know, much more about this than I do.

01:42:00.240 --> 01:42:01.360
I worry too.

01:42:01.360 --> 01:42:07.840
But I'm, I'm, I'm sort of an amateur here. I've read some of the papers, but I've not ever done it.

01:42:08.640 --> 01:42:17.200
And the, the, the idea that scares me the most is the one I have heard and I don't know how

01:42:17.200 --> 01:42:28.560
common it is that you have this AI system, machine learning, all of these trained neural

01:42:28.560 --> 01:42:35.440
nets. And when there's something that's too complicated, they ask the human for help.

01:42:36.160 --> 01:42:44.720
But the human is reading a book or sleep and he has 30 seconds or three seconds to figure out

01:42:44.720 --> 01:42:50.800
what the problem was that the AI system couldn't handle and do the right thing. This is scary.

01:42:52.000 --> 01:42:55.920
I mean, how do you do the cut-over between the machine and the human?

01:42:56.400 --> 01:43:07.280
It's very, very difficult. And for the designer of one of the most reliable, efficient and powerful

01:43:07.280 --> 01:43:15.600
programming languages, C++, I can understand why that world is actually unappealing. It is for

01:43:15.600 --> 01:43:22.240
most engineers. To me, it's extremely appealing because we don't know how to get that interaction

01:43:22.240 --> 01:43:28.480
right, but I think it's possible, but it's very, very hard. It is. I mean, I was stating a problem,

01:43:28.480 --> 01:43:33.680
not a solution. That is possible. I mean, I would much rather never rely on a human. If you're

01:43:33.680 --> 01:43:40.080
driving a nuclear reactor, if you're or an autonomous vehicle, it's much better to design

01:43:40.080 --> 01:43:47.280
systems written in C++ that never ask human for help. Let, let, let's just get one fact in.

01:43:47.440 --> 01:43:51.360
Yeah. All of this AI stuff is on top of C++.

01:43:53.760 --> 01:44:00.080
So, so that's one reason I have to keep a weather eye out on what's going on in that field, but I

01:44:00.080 --> 01:44:04.960
will never become an expert in that area. But it's a good example of how you separate

01:44:05.760 --> 01:44:11.200
different areas of applications, and you have to have different tools, different principles.

01:44:11.840 --> 01:44:18.640
And then they interact. No major system today is written in one language, and there are good

01:44:18.640 --> 01:44:29.520
reasons for that. When you look back at your life work, what is a, what is a moment? What is a event

01:44:30.960 --> 01:44:35.760
creation that you're really proud of? They say, damn, I did pretty good there.

01:44:36.320 --> 01:44:39.440
Is it as obvious as the creation of C++?

01:44:39.440 --> 01:44:47.680
It's obvious. I've spent a lot of time with C++ and there's a combination of a few good ideas,

01:44:47.680 --> 01:44:54.480
a lot of hard work and a bit of luck. And I've tried to get away from it a few times,

01:44:54.480 --> 01:45:01.200
but I get dragged in again, partly because I'm most effective in this area and partly because

01:45:01.920 --> 01:45:08.400
partly because what I do has much more impact if I do it in the context of C++.

01:45:08.400 --> 01:45:14.400
So I have four and a half million people that pick it up tomorrow if I get something right.

01:45:14.400 --> 01:45:18.800
If I did it in another field, I would have to start learning, then I have to build it and then

01:45:18.800 --> 01:45:26.960
we'll see if anybody wants to use it. One of the things that has kept me going for all of these

01:45:26.960 --> 01:45:34.400
years is one, the good things that people do with it and the interesting things they do with it.

01:45:34.960 --> 01:45:41.040
And also, I get to see a lot of interesting stuff and talk to a lot of interesting people.

01:45:43.440 --> 01:45:50.880
I mean, if it has just been statements on paper or on a screen, I don't think I could have kept

01:45:50.880 --> 01:45:58.480
going. But I get to see the telescopes up on Mauna Kea and I actually went and see how Ford

01:45:58.480 --> 01:46:09.600
built cars and I got to JPL and see how they do the Mars rovers. There's so much cool stuff going on

01:46:09.600 --> 01:46:14.800
and most of the cool stuff is done by pretty nice people and sometimes in very nice places,

01:46:15.760 --> 01:46:27.440
Cambridge, Sofia and C++, Silicon Valley. There's more to it than just code, but code is central.

01:46:29.120 --> 01:46:33.520
On top of the code are the people in very nice places. Well, I think I speak for

01:46:34.400 --> 01:46:42.000
millions of people. We are in saying thank you for creating this language that so many

01:46:42.560 --> 01:46:48.880
systems are built on top of that make a better world. So thank you and thank you for talking

01:46:48.880 --> 01:46:52.320
today. Yeah, thanks and we'll make it even better. Good.

