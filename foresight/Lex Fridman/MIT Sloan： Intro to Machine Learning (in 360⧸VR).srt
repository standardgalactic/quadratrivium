1
00:00:00,000 --> 00:00:05,920
The video you're watching now is in 360. Resolution is not great but we wanted to

2
00:00:05,920 --> 00:00:10,280
try something different. So if you're on a desktop or laptop you can pan around

3
00:00:10,280 --> 00:00:13,800
with your mouse or if you're on a phone or tablet you should be able to just

4
00:00:13,800 --> 00:00:18,960
move your device to look around. Of course it's best viewed with a VR headset.

5
00:00:18,960 --> 00:00:23,320
The video that follows is a guest lecture on machine learning that I gave an

6
00:00:23,320 --> 00:00:28,560
MIT Sloan course on the business of artificial intelligence. The lecture is

7
00:00:28,560 --> 00:00:33,540
non-technical and intended to build intuition about these ideas amongst the

8
00:00:33,540 --> 00:00:38,400
business students in the audience. The room was a half circle so we thought why

9
00:00:38,400 --> 00:00:43,880
not film the lecture in 360. We recorded a screencast of the slides and pasted it

10
00:00:43,880 --> 00:00:48,480
into the video so that the slides are more crisp. Let me know what you think and

11
00:00:48,480 --> 00:00:56,120
remember it's an experiment. So this course is talking about the broad context

12
00:00:56,120 --> 00:00:59,880
the impact of artificial intelligence. The global. There's global which is the

13
00:00:59,880 --> 00:01:03,240
global impact of artificial intelligence. There's the business which is when you

14
00:01:03,240 --> 00:01:07,480
have to take these fun research ideas that I'll talk about today. A lot of them

15
00:01:07,480 --> 00:01:12,580
are cool on toy examples. When you bring them to reality you face real challenges

16
00:01:12,580 --> 00:01:18,040
which is what I would like to really highlight today. That's the business part.

17
00:01:18,040 --> 00:01:21,440
When you want to make real impact. When you're going to make these technologies

18
00:01:21,440 --> 00:01:26,920
a reality. So I'll talk about how amazing the technology is for a nerd like me but

19
00:01:26,920 --> 00:01:32,160
also talk about how when you take that into the real world what are the

20
00:01:32,160 --> 00:01:36,960
challenges you face. So machine learning which is the technology at the core of

21
00:01:36,960 --> 00:01:43,560
artificial intelligence. We'll talk about the promise. The excitement that I feel

22
00:01:43,560 --> 00:01:48,000
about it. The limitations. We'll bring it down a little bit. What are the real

23
00:01:48,040 --> 00:01:55,800
capabilities of technology. Where for the first time really as a civilization

24
00:01:55,800 --> 00:02:02,360
exploring the meaning of intelligence. It is if you pause for a second and just

25
00:02:02,360 --> 00:02:05,200
think you know maybe you have many of you want to make money out of this

26
00:02:05,200 --> 00:02:10,920
technology. Many of you want to save lives help people but also on the

27
00:02:10,920 --> 00:02:16,200
philosophical level we get to explore what makes us human. So while I'll talk

28
00:02:16,280 --> 00:02:21,320
about the low-level technologies also think about the incredible opportunity

29
00:02:21,320 --> 00:02:26,960
here. We get to almost psychoanalyze ourselves by trying to build versions of

30
00:02:26,960 --> 00:02:33,640
ourselves in the machine. All right so here's the open question. How powerful is

31
00:02:33,640 --> 00:02:38,480
artificial intelligence. How powerful is machine learning that lies at the core

32
00:02:38,480 --> 00:02:43,120
of artificial intelligence. Is it simply a helpful tool a special purpose tool to

33
00:02:43,120 --> 00:02:49,000
help you solve simple problems. Which is what it currently is. Currently

34
00:02:49,000 --> 00:02:54,760
machine learning artificial intelligence is a way if you can formally define the

35
00:02:54,760 --> 00:02:58,240
problem. You can formally define the tools you're working with. You can formally

36
00:02:58,240 --> 00:03:01,800
define the utility function where you want to achieve with those tools. As long

37
00:03:01,800 --> 00:03:05,720
as you can define those things we can come up with algorithms that can solve

38
00:03:05,720 --> 00:03:09,600
them. As long as you have the right kind of data which is what I'll talk about.

39
00:03:09,960 --> 00:03:20,200
Data is key. And the question is into the future can we break past this very

40
00:03:20,200 --> 00:03:22,920
narrow definition of what machine learning can give us which is solve

41
00:03:22,920 --> 00:03:29,440
specific problems. To something bigger. To where we approach the general

42
00:03:29,440 --> 00:03:33,000
intelligence that we exhibit as human beings. When we're born we know

43
00:03:33,080 --> 00:03:41,240
nothing and we learn quickly. From very little data. The right answer is we

44
00:03:41,240 --> 00:03:45,920
don't know. We don't know what are the limitations of the technology. What kind

45
00:03:45,920 --> 00:03:51,120
of machine learning are there. There are several flavors. The first two is what's

46
00:03:51,120 --> 00:03:55,720
really the first is what's achieved success today. Supervised learning. What

47
00:03:55,720 --> 00:04:01,760
I'm showing here on the left of the slide is the teachers. Is the data that is

48
00:04:01,840 --> 00:04:05,440
fed to the system. And on the right is the students which is the system itself

49
00:04:05,440 --> 00:04:09,280
from machine learning. So there's supervised learning. Whenever everybody

50
00:04:09,280 --> 00:04:13,960
talks about machine learning today. For the most part they're referring to

51
00:04:13,960 --> 00:04:17,600
supervised learning. Which means every single piece of data that is used to

52
00:04:17,600 --> 00:04:23,720
train the model is seen by human eyes. And those human eyes with an

53
00:04:23,720 --> 00:04:29,800
accompanying brain label that data in a way that makes it useful to the machine.

54
00:04:30,240 --> 00:04:35,080
This is critical. Because that's one. The blue box. The human. It's really

55
00:04:35,080 --> 00:04:40,760
costly. So whenever every single piece of data that's used to train the machine

56
00:04:40,760 --> 00:04:44,800
needs to be seen by a human. You need to pay for that human. And second you're

57
00:04:44,800 --> 00:04:51,120
limited to just the time. There's the amount of data necessary to label what

58
00:04:51,120 --> 00:04:57,760
it means to exist in this world is humongous. Augmented supervised learning

59
00:04:57,800 --> 00:05:01,240
is when you get machine to really to help you a little bit. There's a few

60
00:05:01,240 --> 00:05:04,520
tricks there. But still it's still only tricks. It's still the human is at the

61
00:05:04,520 --> 00:05:11,480
core of it. And the promise of future research that we're pursuing that I'm

62
00:05:11,480 --> 00:05:14,880
pursuing and perhaps in the applications if we get to discuss or some of the

63
00:05:14,880 --> 00:05:20,200
speakers here get to discuss. They're pursuing in semi-supervised and

64
00:05:20,200 --> 00:05:24,080
reinforcement learning. Where the human starts to play a smaller and smaller

65
00:05:24,080 --> 00:05:28,240
role in how much they get to annotate. They have to annotate the data. And the

66
00:05:28,240 --> 00:05:34,880
dream of the sort of wizards of the dark arts of deep learning are all excited

67
00:05:34,880 --> 00:05:40,640
about unsupervised learning. That has very few actual successes in application

68
00:05:40,640 --> 00:05:48,880
in the real world today. But it is the idea that you can build a machine that

69
00:05:48,880 --> 00:05:57,120
doesn't require a human teacher. A human being to teach you anything. It fills us

70
00:05:57,120 --> 00:06:05,320
artificial intelligence researchers with excitement. There's a theme here.

71
00:06:05,320 --> 00:06:12,600
Machine learning is really simple. The learning system in the middle. There's a

72
00:06:12,600 --> 00:06:17,920
training stage where you teach it something. All you need is some data.

73
00:06:17,960 --> 00:06:26,640
Input data. And you need to teach it the correct output for that input data. So

74
00:06:26,640 --> 00:06:32,080
you have to have a lot of pairs of input data and correct output. There'll be a

75
00:06:32,080 --> 00:06:35,280
theme of cats throughout this presentation. So if you want to teach a

76
00:06:35,280 --> 00:06:41,400
system difference between a cat and a dog, you need a lot of images of cats. And

77
00:06:41,400 --> 00:06:45,120
you need to tell it that this is a cat. This bounding box here in the image is a

78
00:06:45,160 --> 00:06:50,800
cat. You have to give it a lot of images of dogs and tell it, okay, in these

79
00:06:50,800 --> 00:06:56,520
pictures there are dogs. And then there's a spelling mistake on the second

80
00:06:56,520 --> 00:07:00,800
stage is the testing stage. When you actually give it new input data, it's

81
00:07:00,800 --> 00:07:06,160
never seen before. And you hope that it has given for cat versus dog enough data

82
00:07:06,160 --> 00:07:14,920
to guess is this new image that I've never seen before, a cat or a dog. Now

83
00:07:15,680 --> 00:07:24,160
one of the open questions you want to keep in mind is what in this world can we

84
00:07:24,160 --> 00:07:35,680
not model in this way? What activity? What task? What goal? I offer to you that

85
00:07:35,680 --> 00:07:48,360
there's nothing you can't model in this way. So let's think about what in terms

86
00:07:48,360 --> 00:07:54,360
of machine learning can be, so let's start small. What can be modeled in this

87
00:07:54,360 --> 00:07:59,280
way? First on the bottom of the slide left is one to one mapping where the

88
00:07:59,280 --> 00:08:04,320
input is an image of a cat and the output is a label that says cat or dog.

89
00:08:05,080 --> 00:08:10,760
You can also do one to many where the image, the input is an image of a cat and

90
00:08:10,760 --> 00:08:18,160
the output is a story about that cat, a captioning of the image. You can first of

91
00:08:18,160 --> 00:08:23,760
all, you can do the other way, many to one mapping where you give it a story

92
00:08:23,760 --> 00:08:28,320
about a cat and it generates an image. There's many to many. This is Google

93
00:08:28,320 --> 00:08:33,400
translate. We translate a sentence from one language to another and there's

94
00:08:33,640 --> 00:08:38,880
various flavors of that. Again, same theme here. Input data provided with

95
00:08:38,880 --> 00:08:47,440
correct output and then let it go into the wild where it runs on input data

96
00:08:47,440 --> 00:08:53,320
that hasn't seen before to provide guesses. And it's as simple as this.

97
00:08:53,320 --> 00:08:58,960
Whatever you can convert into one of the following four things. Numbers, vector of

98
00:08:59,000 --> 00:09:03,480
numbers, so a bunch of numbers, a sequence of numbers where the temporal

99
00:09:03,480 --> 00:09:09,640
dynamics matters, so like audio, video, where the sequence, the ordering matters,

100
00:09:09,640 --> 00:09:13,480
or a sequence of vector numbers, just a bunch of numbers. If you can convert it

101
00:09:13,480 --> 00:09:17,440
to numbers and I propose to you that there's nothing you can't convert it

102
00:09:17,440 --> 00:09:24,600
to numbers. If you can convert it to numbers, you can have a system learn to

103
00:09:24,600 --> 00:09:28,560
do it. And the same thing with the output. Generate numbers, vectors, and numbers

104
00:09:29,080 --> 00:09:31,840
sequence of numbers or sequence of vectors and numbers.

105
00:09:35,560 --> 00:09:37,400
First, is there any questions at this point?

106
00:09:39,960 --> 00:09:44,080
Well, we have a lot of fun slides to get through, but I'll pause every once in a

107
00:09:44,080 --> 00:09:48,520
while to make sure we're on the same page here. So what kind of input are we

108
00:09:48,520 --> 00:09:53,480
talking about? Just to fly through it. Images, so faces, or medical applications

109
00:09:53,480 --> 00:09:59,640
for looking at scans of different parts of the body to determine if, to

110
00:09:59,640 --> 00:10:05,200
diagnose any kind of medical conditions. Texts, so conversations, your texts,

111
00:10:05,200 --> 00:10:10,600
article, blog posts, for sentiment analysis, question and answering, so you

112
00:10:10,600 --> 00:10:14,760
ask it a question where the output you hope answers. Sounds of voice

113
00:10:14,760 --> 00:10:20,840
recognition, any kind of, anything you can tell from audio. Time series data, so

114
00:10:20,840 --> 00:10:26,240
financial data, stock market, you can use it to predict anything you want about

115
00:10:26,240 --> 00:10:30,040
the stock market, including whether to buy or sell. If you're curious, doesn't

116
00:10:30,040 --> 00:10:37,800
work quite well as a machine learning application. Physical world, so cars or

117
00:10:37,800 --> 00:10:42,800
any kind of object, any kind of robot that exists in this world. So location of

118
00:10:42,800 --> 00:10:47,520
where I am, location of where other things are, the actions of others, that

119
00:10:47,560 --> 00:10:51,600
could be all the input. All of it can be converted to numbers. And the correct

120
00:10:51,600 --> 00:10:56,120
output, same thing. Classification, a bunch of numbers. Classification is

121
00:10:56,120 --> 00:11:00,600
saying it's a cat or a dog. Regression is saying to what degree I turn the

122
00:11:00,600 --> 00:11:05,120
steering wheel. Sequence is generating audio, generating video, generating

123
00:11:05,120 --> 00:11:10,240
stories, captioning, text, images, generating anything you could think of as

124
00:11:10,240 --> 00:11:17,040
numbers. And at the core of it is a bunch of data agnostic machine learning

125
00:11:17,040 --> 00:11:20,840
algorithms. There's traditional ones, nearest neighbors, Naive Bay support

126
00:11:20,840 --> 00:11:30,480
machine, support vector machines. A lot of them are limited, and I'll describe

127
00:11:30,480 --> 00:11:36,200
how. And then there's neural networks. There's nothing special and new about

128
00:11:36,200 --> 00:11:43,200
neural networks. And I'll describe exactly the very subtle thing that is

129
00:11:43,880 --> 00:11:49,480
powerful. That's always been there all along. And certain things have now been

130
00:11:49,480 --> 00:11:53,640
able to unlock that power about neural networks. But it's still just the flavor

131
00:11:53,640 --> 00:11:57,960
of a machine learning algorithm. And the inspiration for neural networks, as

132
00:11:57,960 --> 00:12:03,600
Jonathan showed last time, is our human brain. It's perhaps why the media, perhaps

133
00:12:03,600 --> 00:12:09,560
why the hype is captivated by the idea of neural networks, is because you

134
00:12:09,600 --> 00:12:14,840
immediately jump to this feeling like, because there's this mysterious structure

135
00:12:14,840 --> 00:12:18,440
to them that scientists don't understand. Artificial neural networks, I'm

136
00:12:18,440 --> 00:12:23,200
referring to. And the biological ones. We don't understand them. And the

137
00:12:23,200 --> 00:12:29,640
similarity captivates our minds and we think, well, this approach is perhaps as

138
00:12:29,640 --> 00:12:36,640
limited, as limitless as our own human mind. But the comparison ends there. In

139
00:12:36,640 --> 00:12:43,400
fact, artificial neuron, their artificial neural networks are much simpler

140
00:12:43,400 --> 00:12:49,720
computational units. At the core of everything is this neuron. This is a

141
00:12:49,720 --> 00:12:58,760
computational unit that does two very simple operations. On the left side, it

142
00:12:58,760 --> 00:13:06,880
takes a set of numbers as inputs. It applies weights to those inputs, sums

143
00:13:06,880 --> 00:13:15,120
them together, applies a little bias, and provides an output somewhere between zero

144
00:13:15,120 --> 00:13:23,120
and one. So you can think of it as a computational entity that gets excited

145
00:13:23,280 --> 00:13:31,480
when it sees certain inputs and gets totally turned off when it gets other

146
00:13:31,480 --> 00:13:39,320
kinds of inputs. So maybe this neuron with a 0, with a 0.7, 0.6, 1.4 weights, it

147
00:13:39,320 --> 00:13:45,080
gets really excited when it sees pictures of cats and totally doesn't care about

148
00:13:45,080 --> 00:13:52,880
dogs. Some of us are like that. So that's the job of this neuron, is to detect

149
00:13:52,880 --> 00:14:01,000
cats. Now what, the way you build an artificial neural network, the way you

150
00:14:01,000 --> 00:14:06,040
release the power that I'll talk about in the following slides about the

151
00:14:06,040 --> 00:14:10,200
applications, what could be achieved, is just stacking a bunch of these together.

152
00:14:12,000 --> 00:14:18,160
Think about it. This is, this is a extremely simple computational unit.

153
00:14:19,120 --> 00:14:24,840
So you need to sort of pause whenever we talk about the following slides and

154
00:14:24,840 --> 00:14:31,920
think that there's a few slides that I'll show that say neural networks are

155
00:14:31,920 --> 00:14:37,920
amazing. I want you to think back to this slide that everything is built on top

156
00:14:37,920 --> 00:14:43,560
of these really simple addition operations with a simple nonlinear

157
00:14:43,560 --> 00:14:50,160
function applied at the end. Just a tiny math operation. We stack them together

158
00:14:50,160 --> 00:14:54,320
with it in a feedforward way so there's a bunch of layers and when people talk

159
00:14:54,320 --> 00:15:01,160
about deep neural networks it means there is a bunch of those layers and then

160
00:15:01,160 --> 00:15:05,320
there's recurrent neural networks that are also a special flavor that's able to

161
00:15:05,320 --> 00:15:12,000
have memory. So as opposed to just pushing input into output directly, it's

162
00:15:12,040 --> 00:15:16,280
also able to do stuff on the inside in a loop where it remembers things. This is

163
00:15:16,280 --> 00:15:19,680
useful for natural language processing, for audio processing, whenever the

164
00:15:19,680 --> 00:15:28,440
sequence is not, the length of the sequence is not defined. Okay, slide number

165
00:15:28,440 --> 00:15:35,200
one in terms of neural networks are amazing. This is, this is perhaps for the

166
00:15:35,240 --> 00:15:42,920
math nerds. But also I want you to use your imagination. There's a universality

167
00:15:42,920 --> 00:15:47,680
to neural networks. It means that the simple computational unit on the left is

168
00:15:47,680 --> 00:15:52,680
an input and the right is the output of this network with just a single hidden

169
00:15:52,680 --> 00:15:57,000
layer. It's called a hidden layer because it sits there in the middle of the

170
00:15:57,000 --> 00:16:03,640
input and the output layers. A single hidden layer with some number of nodes

171
00:16:04,560 --> 00:16:15,640
can represent any function. Any function. That means anything you want to build in

172
00:16:15,640 --> 00:16:22,880
this world. Everyone in this room can be represented with a neural network with a

173
00:16:22,880 --> 00:16:29,520
single hidden layer. So the power, and this is just one hidden layer, the power

174
00:16:29,560 --> 00:16:35,880
of these things is limitless. The problem, of course, is how do you find the

175
00:16:35,880 --> 00:16:43,560
network? So how do you build a network that is as clever as many of the people

176
00:16:43,560 --> 00:16:50,600
in this room? But the fact that you can build such a network is incredible. It's

177
00:16:50,600 --> 00:16:59,000
amazing. I want you to think about that. And the way you train a network, so it's

178
00:16:59,040 --> 00:17:05,160
born as a blank slate. Some random weights assigned to the edges. Again, a network

179
00:17:05,160 --> 00:17:08,080
is represented. The numbers at the core, the parameters at the core of this

180
00:17:08,080 --> 00:17:13,760
network are the numbers on each of those arrows, each of those edges. And you

181
00:17:13,760 --> 00:17:18,800
start knowing nothing. This is a baby network. And the way you teach it

182
00:17:18,800 --> 00:17:24,600
something, unfortunately, currently, as I said, in a supervised learning

183
00:17:24,960 --> 00:17:28,680
mechanism, you have to give it pairs of input and output. You have to give it

184
00:17:29,720 --> 00:17:37,560
pictures of cats and labels on those pictures saying that they're cats. And the

185
00:17:37,560 --> 00:17:47,760
basic fundamental operation of learning is when you compute the measure of an

186
00:17:47,760 --> 00:17:55,800
error and you back propagate it to the network. What I mean, everything's easier

187
00:17:55,800 --> 00:18:05,160
with cats. I apologize. I apologize. Too many cats. And so the input here is a cat.

188
00:18:05,160 --> 00:18:10,280
And the neural network we trained, it's just guessing. It doesn't know. So I don't

189
00:18:10,280 --> 00:18:16,920
know. It's guessing cat. Well, it happens to be right. So we have to, this is the

190
00:18:16,960 --> 00:18:21,520
measure of error. Yes. You got it right. And you have to back propagate that error.

191
00:18:22,640 --> 00:18:27,600
You have to reward the network for doing a good job. And all you do, what I mean

192
00:18:27,600 --> 00:18:33,400
by reward, there's weights on each of those edges. And so the node, the individual

193
00:18:33,400 --> 00:18:37,800
neurons that were responsible that back to that cat neuron, that cat neuron needs

194
00:18:37,800 --> 00:18:42,680
to be rewarded for seeing the cat. So you just increase the weights on the neurons

195
00:18:42,680 --> 00:18:46,800
that were associated with producing the correct answer. Now you give it a picture

196
00:18:46,840 --> 00:18:54,120
of a dog and the neural network says cat. Well, that's an incorrect answer. So no,

197
00:18:54,120 --> 00:18:57,840
there's a high error. It needs to be back propagated to the network. So the weights

198
00:18:57,840 --> 00:19:03,800
that were responsible with classifying this picture as a cat need to be punished.

199
00:19:03,800 --> 00:19:09,960
They need to be decreased. Simple. And you just repeat this process over and over.

200
00:19:09,960 --> 00:19:16,640
This is what we do as kids when we're first learning. For the most part,

201
00:19:16,680 --> 00:19:21,800
we're also supervised learning machines in the sense that we have our parents and

202
00:19:21,800 --> 00:19:28,440
we have the environment, the world, that teaches about what's correct and what's

203
00:19:28,440 --> 00:19:33,440
incorrect. And we back propagate this error and reward through our brain to learn.

204
00:19:34,440 --> 00:19:39,440
The problem is, as human beings, we don't need too many examples. And I'll talk

205
00:19:39,440 --> 00:19:43,200
about some of the drawbacks of these approaches. We don't need too many

206
00:19:43,240 --> 00:19:47,240
examples. You fall off your bike once or twice and you learn how to ride the bike.

207
00:19:47,240 --> 00:19:53,240
Unfortunately, neural networks need tens of thousands of times when they fall off

208
00:19:53,240 --> 00:19:58,240
the bike in order to learn how to not do it. That's one of the limitations.

209
00:19:58,240 --> 00:20:06,240
And one key thing I didn't mention here is when we refer to input data,

210
00:20:06,280 --> 00:20:14,280
we usually refer to sensory data, raw data. We have to represent that data in

211
00:20:14,280 --> 00:20:24,280
some clever way, in some deeply clever way, where we can reason about it,

212
00:20:24,280 --> 00:20:30,280
whether it's in our brains or in the neural network. And a very simple example

213
00:20:30,320 --> 00:20:37,320
here to illustrate why representation of data matters. So the way you represent

214
00:20:37,320 --> 00:20:43,320
the data can make the discrimination of one class from another, a cat versus dog,

215
00:20:43,320 --> 00:20:49,320
either incredibly difficult or incredibly simple. Here is a visualization of the

216
00:20:49,320 --> 00:20:54,320
same kind of data in Cartesian coordinates and polar coordinates. On the right,

217
00:20:54,360 --> 00:21:01,360
you can just draw a simple line to separate the two. What you want is a system that's

218
00:21:01,360 --> 00:21:07,360
able to learn the polar coordinate representation versus the Cartesian

219
00:21:07,360 --> 00:21:15,360
representation automatically. And this is where deep learning has stepped in and

220
00:21:15,360 --> 00:21:21,360
revealed the incredible power of this approach, which deep learning is the

221
00:21:21,400 --> 00:21:27,400
smallest circle there. It's a type of representational learning. Machine learning

222
00:21:27,400 --> 00:21:31,400
is the bigger second to the biggest. So this class is about the biggest circle,

223
00:21:31,400 --> 00:21:36,400
AI, includes robotics, includes all the fun things that are built on learning.

224
00:21:36,400 --> 00:21:40,400
And I'll discuss while machine learning I think will close this entire circle into

225
00:21:40,400 --> 00:21:46,400
one. But for now, AI is the biggest circle, then a subset of that is machine

226
00:21:46,400 --> 00:21:50,400
learning and a smaller subset of that is representation learning. So deep

227
00:21:50,440 --> 00:21:55,440
learning is not only able to say, given a few examples of cats and dogs that

228
00:21:55,440 --> 00:22:01,440
discriminate between a cat and a dog, it's able to represent what it means to be a

229
00:22:01,440 --> 00:22:09,440
cat. So it's able to automatically determine what are the fundamental

230
00:22:09,440 --> 00:22:15,440
units at the low level and the high level. We're talking about this very Plato.

231
00:22:15,480 --> 00:22:22,480
What it means to represent a cat from the whiskers to the high level shape of

232
00:22:22,480 --> 00:22:28,480
the head to the fuzziness and the deformable aspects of the cat. Not a cat

233
00:22:28,480 --> 00:22:32,480
expert, but I hear these are the features of a cat versus that are essential to

234
00:22:32,480 --> 00:22:37,480
discriminate between a cat and a dog. Learning those features as opposed to

235
00:22:37,480 --> 00:22:42,480
having to have experts, this is the drawback of systems that Jonathan talked

236
00:22:42,520 --> 00:22:46,520
about from the eighties and nineties where you have to bring in experts for any

237
00:22:46,520 --> 00:22:50,520
specific domain that you try to solve. You have to have them encode that

238
00:22:50,520 --> 00:22:58,520
information. Deep learning, this is simply the only big difference between deep

239
00:22:58,520 --> 00:23:02,520
learning and other methods is that it learns the representation for you. It

240
00:23:02,520 --> 00:23:06,520
learns what it means to be a cat. Nobody has to step in and help it figure out

241
00:23:06,560 --> 00:23:13,560
that cats have whiskers and dogs don't. What does this mean? The fact that it

242
00:23:13,560 --> 00:23:19,560
can learn these features, these whisker features, is as opposed to having five

243
00:23:19,560 --> 00:23:24,560
or ten or a hundred or five hundred features that are encoded by brilliant

244
00:23:24,560 --> 00:23:30,560
engineers with PhDs, it can find hundreds of thousands, millions of features

245
00:23:30,600 --> 00:23:38,600
automatically. Hundreds of millions of features. Stuff that can't be put into

246
00:23:38,600 --> 00:23:42,600
words or described, in fact it's one of the limitations in neural networks is they

247
00:23:42,600 --> 00:23:46,600
find so many fundamental things about what it means to be a cat that you can't

248
00:23:46,600 --> 00:23:52,600
visualize what it really knows. It just seems to know stuff. It finds that

249
00:23:52,600 --> 00:23:58,600
stuff automatically. What does this mean? The critical thing here is because it's

250
00:23:58,640 --> 00:24:03,640
able to automatically learn those hundreds of millions of features, it's able to

251
00:24:03,640 --> 00:24:12,640
utilize data. It doesn't start, the diminishing returns don't hit until well we

252
00:24:12,640 --> 00:24:15,640
don't know when they hit. The point is with the classical machine learning

253
00:24:15,640 --> 00:24:21,640
algorithms, you start hitting a wall when you have tens of thousands of images of

254
00:24:21,680 --> 00:24:30,680
cats. With deep learning, you get better and better with more data.

255
00:24:30,680 --> 00:24:36,680
Neural networks are amazing slide two. Here's a game, a simple arcade game where

256
00:24:36,680 --> 00:24:41,680
there's two paddles, they're bouncing a ball back and forth. Okay, great. You can

257
00:24:41,680 --> 00:24:45,680
figure out an artificial intelligence agent that can play this game. It can,

258
00:24:45,720 --> 00:24:51,720
not even that well, just kind of, it kind of learns to do alright and eventually

259
00:24:51,720 --> 00:25:01,720
win. Here's the fascinating thing. With deep learning as opposed to encoding the

260
00:25:01,720 --> 00:25:07,720
position of the paddles, the position of the ball, having an expert in this game,

261
00:25:07,720 --> 00:25:14,720
there's many, come in and encode the physics of this game. The input to the

262
00:25:14,760 --> 00:25:23,760
neural network is the raw pixels of the game. So, it's learning in the following

263
00:25:23,760 --> 00:25:29,760
way. You give it an evolution of the game. You give it a bunch of pixels.

264
00:25:29,760 --> 00:25:35,760
Pixels are, images are built up of pixels. They're just numbers from 0 to 256. So

265
00:25:35,760 --> 00:25:40,760
there's this array of numbers that represent each image and then you give it

266
00:25:40,800 --> 00:25:45,800
several tens of thousands of images that represent a game. So you have the stack

267
00:25:45,800 --> 00:25:51,800
of pixels and stack of images that represent a game. And the only thing you

268
00:25:51,800 --> 00:25:56,800
know, this giant stack of numbers, the only thing you know is at the end you

269
00:25:56,800 --> 00:26:04,800
won or lost. That's it. So based on that, you have to figure out how to play the

270
00:26:04,800 --> 00:26:09,760
game. You know nothing about games. You know nothing about colors or balls or

271
00:26:09,800 --> 00:26:17,800
paddles or winning or anything. That's it. So this is, why is this amazing? That

272
00:26:17,800 --> 00:26:22,800
it even works and it works, it wins. It's amazing because that's exactly what we do

273
00:26:22,800 --> 00:26:27,800
as human beings. This is general intelligence. So I need you to pause and

274
00:26:27,800 --> 00:26:31,800
think about this. We'll talk about special intelligence and the usefulness and

275
00:26:31,800 --> 00:26:37,800
okay, there's cool tricks here and there that we can do to get you an edge on your

276
00:26:37,840 --> 00:26:43,840
high frequency trading system. But this is general intelligence. General

277
00:26:43,840 --> 00:26:48,840
intelligence is the same intelligence we use as babies when we're born. What we

278
00:26:48,840 --> 00:26:53,840
get is an input, sensory input of image sensory input. Right now, all of us,

279
00:26:53,840 --> 00:27:00,840
most of us are seeing, hearing, feeling with touch and that's the only input we

280
00:27:00,880 --> 00:27:07,880
get. We know nothing and with that input, we have to learn something. Nobody is

281
00:27:07,880 --> 00:27:11,880
pre-teaching us stuff and this is an example of that. A trivial example, but

282
00:27:11,880 --> 00:27:16,880
one of the first examples where this is truly working. I'm sorry to linger on

283
00:27:16,880 --> 00:27:22,880
this, but it's a fundamental fact. The fact that we have systems that, and now

284
00:27:22,880 --> 00:27:28,880
outperform human beings in these simple arcade games is incredible. This is the

285
00:27:28,920 --> 00:27:36,920
research side of things. But let me step back, these again, the takeaways. That

286
00:27:36,920 --> 00:27:44,920
previous slide is why I think machine learning is limitless in the future.

287
00:27:44,920 --> 00:27:53,920
Currently, it's limited. Again, the representation of the data matters and if

288
00:27:53,960 --> 00:28:00,960
you want to have impact, we currently can only tackle the small problems. What are

289
00:28:00,960 --> 00:28:05,960
those problems? Image recognition. We can classify, given the entire image of a

290
00:28:05,960 --> 00:28:15,960
leopard, of a boat, of a mite, with pretty good accuracy of what's in that image.

291
00:28:15,960 --> 00:28:20,960
That's image classification. What else? We can find exactly where in that image

292
00:28:21,000 --> 00:28:27,000
each individual object is. That's called image segmentation. Again, the process

293
00:28:27,000 --> 00:28:36,000
is the same. The learning system in the middle, a neural network, as long as you

294
00:28:36,000 --> 00:28:42,000
give it a set of numbers as input and the correct set of labels as output, it

295
00:28:42,000 --> 00:28:47,000
learns to do that for data it hasn't seen in the past. Let me pause a second and

296
00:28:47,040 --> 00:28:52,040
maybe if you have any questions, does anyone have any questions about the

297
00:28:52,040 --> 00:28:55,040
techniques of neural networks? Yes.

298
00:28:55,080 --> 00:29:04,080
How do you represent data, as you mentioned, to us anyways, as well as

299
00:29:04,080 --> 00:29:12,080
coordinate the recent coordinates? How do you represent these two different

300
00:29:12,080 --> 00:29:15,080
kinds of data?

301
00:29:15,080 --> 00:29:23,080
That's a great question. In a couple of slides, I'll get to it exactly. The

302
00:29:23,120 --> 00:29:29,120
data representation, I'll elaborate in a little bit, but loosely, the data

303
00:29:29,120 --> 00:29:37,120
representation is for a neural network is in the weights of each of those arrows

304
00:29:37,120 --> 00:29:43,120
that connect the neurons. That's where the representation is. I'll show to

305
00:29:43,120 --> 00:29:51,120
really clarify that example of what that means. The Cartesian versus polar

306
00:29:51,160 --> 00:29:59,160
coordinates is just a very simple visualization of the concept. You want

307
00:29:59,160 --> 00:30:04,160
to be able to represent the data in an arbitrary way where there's no limits

308
00:30:04,160 --> 00:30:09,160
to the representation. It could be highly nonlinear, highly complex. Any other

309
00:30:09,160 --> 00:30:11,160
questions?

310
00:30:11,200 --> 00:30:16,200
We touched on it earlier. Generally speaking, in our current state, when we talk

311
00:30:16,200 --> 00:30:20,200
about machine learning or AI, it's simply statistical models that are able to

312
00:30:20,200 --> 00:30:25,200
recognize the trends or things of that nature where they're not necessarily

313
00:30:25,200 --> 00:30:32,200
thinking, but simply recognizing. I'm a little confused about how the current

314
00:30:32,200 --> 00:30:39,200
system differs from deep learning. Whether you think that there is a

315
00:30:39,240 --> 00:30:43,240
possibility of transition from recognizing to actually thinking.

316
00:30:43,240 --> 00:30:49,240
I have a couple of slides almost asking this question, because there's no

317
00:30:49,240 --> 00:30:54,240
good answers. One could argue, and I think somebody in the last class brought up

318
00:30:54,240 --> 00:31:03,240
that is machine learning just pattern recognition. It's possible that reasoning,

319
00:31:03,280 --> 00:31:14,280
thinking, is just pattern recognition. I'll describe sort of an intuition

320
00:31:14,280 --> 00:31:25,280
behind that. We tend to respect thinking a lot, because we've recently as human

321
00:31:25,280 --> 00:31:30,280
beings learned to do it. In our evolutionary time, we think that it's somehow

322
00:31:30,320 --> 00:31:35,320
special from, for example, perception. We've had visual perception for several

323
00:31:35,320 --> 00:31:41,320
orders of magnitude longer in our evolution as a living species. We've

324
00:31:41,320 --> 00:31:47,320
started to learn to reason, I think, about 100,000 years ago. We think it's

325
00:31:47,320 --> 00:31:52,320
somehow special from the same kind of mechanism we use for seeing things.

326
00:31:52,320 --> 00:31:57,320
Perhaps it's exactly the same thing. Perception is pattern recognition.

327
00:31:57,360 --> 00:32:03,360
Perhaps reasoning is just a few more layers of that. That's the hope.

328
00:32:03,360 --> 00:32:08,360
That's an open question.

329
00:32:08,400 --> 00:32:17,400
The concept of neural network itself is not very new. Is there any

330
00:32:17,400 --> 00:32:24,400
technical innovation breakthrough to expand the use of neural network?

331
00:32:24,400 --> 00:32:32,400
I think more it's just the increase of the result of computational

332
00:32:32,440 --> 00:32:38,440
innovation. Yes, that's a great question. There's been very few

333
00:32:38,440 --> 00:32:43,440
breakthroughs in neural networks, since through the AI winters that we've discussed,

334
00:32:43,440 --> 00:32:50,440
through a lot of excitement, in spurts, and even recently, there's been

335
00:32:50,440 --> 00:32:56,440
very few algorithmic innovations. The big gains came from compute,

336
00:32:56,480 --> 00:33:02,480
so improvements in GPU and better, faster computers. You can't underestimate

337
00:33:02,480 --> 00:33:08,480
the power of community, so the ability to share code and the internet,

338
00:33:08,480 --> 00:33:12,480
the ability to communicate together through the internet and work on code

339
00:33:12,480 --> 00:33:16,480
together, and then digitization of data, so the ability to have large data sets

340
00:33:16,480 --> 00:33:21,480
easily accessible and downloadable. All of those little things.

341
00:33:21,520 --> 00:33:25,520
I think in terms of the future of deep learning and machine learning,

342
00:33:25,520 --> 00:33:33,520
it all rides on compute, meaning continued, bigger, and faster computers.

343
00:33:33,520 --> 00:33:38,520
That doesn't necessarily mean Moore's law in making small and small chips.

344
00:33:38,520 --> 00:33:43,520
It means getting clever in different directions, massive parallelization,

345
00:33:43,520 --> 00:33:48,520
coming up with ways to do super-efficient, power-efficient

346
00:33:48,560 --> 00:33:53,560
implementations in neural networks, and so on.

347
00:33:53,560 --> 00:33:58,560
Let me just fly through a few examples of what we can do with machine learning

348
00:33:58,560 --> 00:34:02,560
just to give you a flavor, I think, in future lectures as possible.

349
00:34:02,560 --> 00:34:07,560
We'll discuss different speakers, different specific applications,

350
00:34:07,560 --> 00:34:12,560
really dig into those. As opposed to working with just images,

351
00:34:12,560 --> 00:34:17,560
you can work with videos and segment those, I mentioned, image segmentation.

352
00:34:17,600 --> 00:34:21,600
We can do video segmentation through video segment, the different parts

353
00:34:21,600 --> 00:34:25,600
of a scene that's useful to a particular application. Here in driving,

354
00:34:25,600 --> 00:34:29,600
you can segment the road from cars and vegetation

355
00:34:29,600 --> 00:34:33,600
and lane markings.

356
00:34:33,600 --> 00:34:37,600
You can also, this is a subtle but important point.

357
00:34:37,600 --> 00:34:42,600
Just go back to that one slide. How do they see the light?

358
00:34:42,640 --> 00:34:46,640
It's such a critical piece. The more I listen to you

359
00:34:46,640 --> 00:34:50,640
and read your stuff, it seems like this critical, these very small

360
00:34:50,640 --> 00:34:54,640
piece of information that we know are important, like there is a red light.

361
00:34:54,640 --> 00:34:58,640
I have to stop, I have to slow down. How does it filter that out

362
00:34:58,640 --> 00:35:02,640
and pick out that?

363
00:35:02,640 --> 00:35:06,640
It's got to be 100% reliable on that.

364
00:35:06,680 --> 00:35:10,680
Hello.

365
00:35:10,680 --> 00:35:14,680
Oof, hard question.

366
00:35:14,680 --> 00:35:18,680
The question was how do you detect the traffic light

367
00:35:18,680 --> 00:35:22,680
and lights.

368
00:35:22,680 --> 00:35:26,680
How do we do it as human beings? First of all, let's start there.

369
00:35:26,680 --> 00:35:30,680
The way we do it is by

370
00:35:30,680 --> 00:35:34,680
the knowledge we bring to the table. We know what it means

371
00:35:34,720 --> 00:35:38,720
to be on the road. There's a lot of the huge network of knowledge

372
00:35:38,720 --> 00:35:42,720
that you come with. And so that makes the perception problem much easier.

373
00:35:42,720 --> 00:35:46,720
This is pure perception. You take an image and you separate different parts

374
00:35:46,720 --> 00:35:50,720
based purely on tiny patterns of pixels.

375
00:35:50,720 --> 00:35:54,720
So first it finds all the edges and it learns that

376
00:35:54,720 --> 00:35:58,720
traffic lights have certain kinds of edges around them and then

377
00:35:58,720 --> 00:36:02,720
zoom out a little bit. They have

378
00:36:02,760 --> 00:36:06,760
certain collection of edges that make up this black

379
00:36:06,760 --> 00:36:10,760
rectangle type shape. So it's all about shapes. It kind of build up

380
00:36:10,760 --> 00:36:14,760
knowing this shape structure of things. But it's a purely

381
00:36:14,760 --> 00:36:18,760
perception problem and one of the things I argue is that if it's

382
00:36:18,760 --> 00:36:22,760
purely a perception approach and you bring no knowledge to the

383
00:36:22,760 --> 00:36:26,760
table about the physics of the world, the three-dimensional physics and the temporal dynamics,

384
00:36:26,760 --> 00:36:30,760
that you are not going to be able to successfully achieve

385
00:36:30,800 --> 00:36:34,800
near 100% accuracy on some of these systems.

386
00:36:34,800 --> 00:36:38,800
So that's exactly the right question is

387
00:36:38,800 --> 00:36:42,800
for all of these things, think about how you as a human being would solve

388
00:36:42,800 --> 00:36:46,800
these problems and what is lacking in the machine learning approach.

389
00:36:46,800 --> 00:36:50,800
What data is lacking in the machine learning approach in order to achieve

390
00:36:50,800 --> 00:36:54,800
the same kind of results, the same kind of reasoning required to

391
00:36:54,800 --> 00:36:58,800
that you would use as a human. So there is also image

392
00:36:58,840 --> 00:37:02,840
detection. Image detection, which means

393
00:37:02,840 --> 00:37:06,840
the subtle but important point. The stuff I mentioned before, image classification

394
00:37:06,840 --> 00:37:10,840
is given an image of a cat, you find the cat,

395
00:37:10,840 --> 00:37:14,840
sorry you don't find the cat, you say this image is of a cat or not, and then

396
00:37:14,840 --> 00:37:18,840
detection or localization is when you actually find where in the image that is.

397
00:37:18,840 --> 00:37:22,840
That problem is much harder but also doable

398
00:37:22,840 --> 00:37:26,840
with machine learning, with deep neural networks.

399
00:37:26,880 --> 00:37:30,880
Now as I said, inputs-outputs can be anything. The input can be

400
00:37:30,880 --> 00:37:34,880
video, the output can be video, and you can do anything you want with these videos,

401
00:37:34,880 --> 00:37:38,880
you can colorize the video. You can add, take an old black and white

402
00:37:38,880 --> 00:37:42,880
film and produce color images.

403
00:37:42,880 --> 00:37:46,880
Again, in terms of

404
00:37:46,880 --> 00:37:50,880
having an impact in the world using these applications,

405
00:37:50,880 --> 00:37:54,880
you have to think, this is a cool demonstration, but how well does it actually

406
00:37:54,920 --> 00:37:58,920
work in the real world? Translation,

407
00:37:58,920 --> 00:38:02,920
whether that's from text to text or image to image, you can translate

408
00:38:02,920 --> 00:38:06,920
here dark chocolate from one language to another.

409
00:38:06,920 --> 00:38:10,920
Class, global business of

410
00:38:10,920 --> 00:38:14,920
artificial intelligence, there's a reference below there, you can go and generate

411
00:38:14,920 --> 00:38:18,920
your own text. You can generate the writing of

412
00:38:18,920 --> 00:38:22,920
the act of generating handwriting. You can type in some text

413
00:38:22,960 --> 00:38:26,960
and given different styles that it learns from other handwriting

414
00:38:26,960 --> 00:38:30,960
samples, it can generate any kind of text using

415
00:38:30,960 --> 00:38:34,960
handwriting. Again, the input is language, the

416
00:38:34,960 --> 00:38:38,960
output is a sequence of writing

417
00:38:38,960 --> 00:38:42,960
of pen movements on the screen. You can complete sentences.

418
00:38:42,960 --> 00:38:46,960
This is kind of a fun one where if you start

419
00:38:46,960 --> 00:38:50,960
actually you can generate language, and you can generate

420
00:38:51,000 --> 00:38:55,000
language where you feed the system some input first. So in black

421
00:38:55,000 --> 00:38:59,000
there it says life is, and then have the neural network complete

422
00:38:59,000 --> 00:39:03,000
those sentences. Life is about kids.

423
00:39:03,000 --> 00:39:07,000
Life is about the weather, there's a lot of knowledge here

424
00:39:07,000 --> 00:39:11,000
I think being conveyed, and you can start the sentence with the meaning of life is.

425
00:39:11,000 --> 00:39:15,000
The meaning of life is literary recognition,

426
00:39:15,000 --> 00:39:19,000
true for us academics, or the meaning of life is the tradition of

427
00:39:19,040 --> 00:39:23,040
ancient human production. Also true.

428
00:39:23,040 --> 00:39:27,040
But these are all generated by a computer. You can also

429
00:39:27,040 --> 00:39:31,040
caption, this has become very popular recently, is

430
00:39:31,040 --> 00:39:35,040
caption generation. Given input as an image, the output is

431
00:39:35,040 --> 00:39:39,040
a set of text. The caption is the content of the image.

432
00:39:39,040 --> 00:39:43,040
You find the different objects in the image, that's a perception

433
00:39:43,040 --> 00:39:47,040
problem, and once you find the different objects, you stitch them together in a sentence

434
00:39:47,080 --> 00:39:51,080
that makes sense. You generate a bunch of sentences, and classify which sentences the most

435
00:39:51,080 --> 00:39:55,080
likely to fit this image.

436
00:39:55,080 --> 00:39:59,080
And you can, so certainly in the

437
00:39:59,080 --> 00:40:03,080
I try to avoid mentioning driving too much, because it is my field

438
00:40:03,080 --> 00:40:07,080
that is what I'm excited about, but then

439
00:40:07,080 --> 00:40:11,080
the moment I start talking about driving it'll all be about driving.

440
00:40:11,080 --> 00:40:15,080
But I should mention of course that deep learning is critical to driving

441
00:40:15,120 --> 00:40:19,120
applications, for both the perception and what is really exciting to us now is

442
00:40:19,120 --> 00:40:23,120
the end-to-end, the end-to-end approach.

443
00:40:23,120 --> 00:40:27,120
So whenever you say end-to-end in any application, what that means

444
00:40:27,120 --> 00:40:31,120
is you start from the very raw inputs that the

445
00:40:31,120 --> 00:40:35,120
system gets, and you produce the very final

446
00:40:35,120 --> 00:40:39,120
output that's expected of the system. So as opposed to in the cell driving car case

447
00:40:39,120 --> 00:40:43,120
as opposed to breaking a car down into each individual components of

448
00:40:43,160 --> 00:40:47,160
perception, localization, mapping, control, planning

449
00:40:47,160 --> 00:40:51,160
and just taking the whole stack and just ignoring

450
00:40:51,160 --> 00:40:55,160
all the super complex problems in the middle and just taking the external

451
00:40:55,160 --> 00:40:59,160
scene as input and as output produced steering and

452
00:40:59,160 --> 00:41:03,160
acceleration and braking commands. And so in this way, taking this input

453
00:41:03,160 --> 00:41:07,160
is the image of the external world, in this case in a Tesla

454
00:41:07,160 --> 00:41:11,160
we can generate steering commands for the car.

455
00:41:11,200 --> 00:41:15,200
And then input a bunch of numbers that's just images,

456
00:41:15,200 --> 00:41:19,200
output a single number that gives you the steering of

457
00:41:19,200 --> 00:41:23,200
the car.

458
00:41:23,200 --> 00:41:27,200
Okay, so let's step back

459
00:41:27,200 --> 00:41:31,200
for a second and think about what can't we do

460
00:41:31,200 --> 00:41:35,200
with machine learning. We talked about you can map numbers to numbers. Let's think about

461
00:41:35,200 --> 00:41:39,200
what we can't do. At the core of artificial intelligence in terms of

462
00:41:39,240 --> 00:41:43,240
how we can impact on this world is robotics. So what

463
00:41:43,240 --> 00:41:47,240
can't we solve in robotics and artificial intelligence with the machine learning approach?

464
00:41:47,240 --> 00:41:51,240
And let's break down what artificial intelligence means.

465
00:41:51,240 --> 00:41:55,240
Here's a stack starting at the very top is the environment, the world

466
00:41:55,240 --> 00:41:59,240
that you operate in. There's sensors that sense that world. There is feature

467
00:41:59,240 --> 00:42:03,240
extraction and learning from that data and there's some reasoning,

468
00:42:03,240 --> 00:42:07,240
planning and affectors are the ways you manipulate

469
00:42:07,280 --> 00:42:11,280
the world. What can't we learn in this way?

470
00:42:11,280 --> 00:42:15,280
So we've had a lot of success as Jonathan talked about

471
00:42:15,280 --> 00:42:19,280
in the history of AI with formal tasks, playing games,

472
00:42:19,280 --> 00:42:23,280
solving puzzles. Recently we're having a lot of breakthroughs with medical

473
00:42:23,280 --> 00:42:27,280
diagnosis. We're still

474
00:42:27,280 --> 00:42:31,280
struggling

475
00:42:31,280 --> 00:42:35,280
but are very excited about in the robotics space

476
00:42:35,320 --> 00:42:39,320
with more mundane tasks of walking, of

477
00:42:39,320 --> 00:42:43,320
basic perception, of natural language written and spoken.

478
00:42:43,320 --> 00:42:47,320
And then there is the human tasks which are

479
00:42:47,320 --> 00:42:51,320
perhaps completely out of reach of this pipeline

480
00:42:51,320 --> 00:42:55,320
at the moment is cognition,

481
00:42:55,320 --> 00:42:59,320
imagination, subjective

482
00:42:59,320 --> 00:43:03,320
experience. So high level reasoning, not just common sense,

483
00:43:03,360 --> 00:43:07,360
but high level human level reasoning.

484
00:43:07,360 --> 00:43:11,360
So let's fly through this pipeline. There's sensors,

485
00:43:11,360 --> 00:43:15,360
cameras, LiDAR, audio,

486
00:43:15,360 --> 00:43:19,360
there's communication that flies through the air

487
00:43:19,360 --> 00:43:23,360
or wired or wireless or wired. IMU measuring the movement

488
00:43:23,360 --> 00:43:27,360
of things. So that's the way you think about it.

489
00:43:27,360 --> 00:43:31,360
That's the way as human beings and as any kind of system that you design, you measure the world.

490
00:43:31,400 --> 00:43:35,400
You don't just get an API to the world.

491
00:43:35,400 --> 00:43:39,400
You need to somehow measure aspects of this world.

492
00:43:39,400 --> 00:43:43,400
So that's how you get the data. So that's how you convert the

493
00:43:43,400 --> 00:43:47,400
world into data you can play with. And once you have the data,

494
00:43:47,400 --> 00:43:51,400
this is the representation side. You have to convert that raw data, raw

495
00:43:51,400 --> 00:43:55,400
pixels, raw audio, raw LiDAR data. You have to convert that

496
00:43:55,400 --> 00:43:59,400
into data that's useful for the intelligence system,

497
00:43:59,440 --> 00:44:03,440
for the learning system to use to discriminate

498
00:44:03,440 --> 00:44:07,440
between one thing and another.

499
00:44:07,440 --> 00:44:11,440
For vision, that's finding edges, corners,

500
00:44:11,440 --> 00:44:15,440
object parts and entire objects. And there's the machine learning

501
00:44:15,440 --> 00:44:19,440
that I've talked about. There's different kinds of mapping

502
00:44:19,440 --> 00:44:23,440
of the representation that you've learned to an actual outputs.

503
00:44:23,440 --> 00:44:27,440
There is, once you have this, so you have this idea

504
00:44:27,480 --> 00:44:31,480
of, and this goes to maybe a little bit of Simon's question,

505
00:44:31,480 --> 00:44:35,480
is reasoning. This is something that's

506
00:44:35,480 --> 00:44:39,480
out of reach in machine learning at the moment. This is going to your question.

507
00:44:39,480 --> 00:44:43,480
Then we can build

508
00:44:43,480 --> 00:44:47,480
a world class machine learning system for taking an image

509
00:44:47,480 --> 00:44:51,480
and classifying that it's a duck. I wonder if this will work.

510
00:44:57,480 --> 00:45:01,480
Wake you up.

511
00:45:01,480 --> 00:45:05,480
So we could take, this is well studied,

512
00:45:05,480 --> 00:45:09,480
exceptionally well studied problem. We could take audio sample

513
00:45:09,480 --> 00:45:13,480
of a duck and tell that it's a duck. In fact, what species

514
00:45:13,480 --> 00:45:17,480
of bird? It's incredible how much research there is in bird species

515
00:45:17,480 --> 00:45:21,480
classification. And we can look at video and we can tell

516
00:45:21,480 --> 00:45:25,480
that we can do actual recognition that it's swimming. But we

517
00:45:25,520 --> 00:45:29,520
can't do with learning now, is reason. That if it

518
00:45:29,520 --> 00:45:33,520
looks like a duck, it swims like a duck and quacks like a duck,

519
00:45:33,520 --> 00:45:37,520
it's very likely to be a duck. This is the reasoning problem.

520
00:45:37,520 --> 00:45:41,520
This is the task that I personally am obsessed with

521
00:45:41,520 --> 00:45:45,520
and that I hope that machine learning can close.

522
00:45:45,520 --> 00:45:49,520
And then there is the planning action and the effectors.

523
00:45:55,520 --> 00:45:59,520
So this is another place

524
00:45:59,520 --> 00:46:03,520
where machine learning

525
00:46:03,520 --> 00:46:07,520
has not had many strides. There's mechanical issues here that are incredibly

526
00:46:07,520 --> 00:46:11,520
difficult. The degrees of freedom with all the actuators involved,

527
00:46:11,520 --> 00:46:15,520
with all the just the ability to

528
00:46:15,520 --> 00:46:19,520
localize every part of yourself in this dynamic

529
00:46:19,520 --> 00:46:23,520
space. Where things

530
00:46:23,560 --> 00:46:27,560
are constantly changing when there's degrees of uncertainty, when there's noise. Just that

531
00:46:27,560 --> 00:46:31,560
basic problem is exceptionally difficult.

532
00:46:35,560 --> 00:46:39,560
Let me just pose this question. We talked

533
00:46:39,560 --> 00:46:43,560
about what machine learning can do with the cats and the duck.

534
00:46:43,560 --> 00:46:47,560
We could do that. Given representation, it could predict what's in the image.

535
00:46:47,560 --> 00:46:51,560
But one of the open questions is, and deep

536
00:46:51,600 --> 00:46:55,600
learning has been able to do the feature extraction, the representation

537
00:46:55,600 --> 00:46:59,600
learning. This is the big breakthrough that everybody's excited about.

538
00:46:59,600 --> 00:47:03,600
But can it also reason? These are the open questions.

539
00:47:03,600 --> 00:47:07,600
Can it reason? Can it do the planning and action?

540
00:47:07,600 --> 00:47:11,600
And as human beings do, can it close the loop entirely

541
00:47:11,600 --> 00:47:15,600
from sensors to effectors? So learn not only

542
00:47:15,600 --> 00:47:19,600
the brain, but the way you sense the

543
00:47:19,640 --> 00:47:23,640
world, and the way you affect the world.

544
00:47:41,640 --> 00:47:45,640
So the question was about the pond game. Thank you.

545
00:47:45,680 --> 00:47:49,680
Let's get to talk to it for a little longer. It doesn't

546
00:47:49,680 --> 00:47:53,680
get punished when it doesn't detect the ball. This is the beautiful thing.

547
00:47:53,680 --> 00:47:57,680
It gets punished only at the very end of the game for losing the game, and gets

548
00:47:57,680 --> 00:48:01,680
rewarded for winning the game. So it knows nothing about that ball.

549
00:48:01,680 --> 00:48:05,680
And it learns about that ball. That's something you need to really sit and think

550
00:48:05,680 --> 00:48:09,680
about. Because like, as human

551
00:48:09,680 --> 00:48:13,680
beings, imagine if you're playing with a physical ball, how do you

552
00:48:13,720 --> 00:48:17,720
learn what a ball is? You get hurt by it,

553
00:48:17,720 --> 00:48:21,720
you like squeeze it, you throw it, you feel the dynamics of it,

554
00:48:21,720 --> 00:48:25,720
the physics of it, and

555
00:48:25,720 --> 00:48:29,720
nobody tells you about what a ball is. You're just using the raw

556
00:48:29,720 --> 00:48:33,720
sensory input. We take it for granted, and maybe this is what I can

557
00:48:33,720 --> 00:48:37,760
end on, is this is what something Jonathan

558
00:48:37,760 --> 00:48:41,760
brought up, is we take the simplicity of this task for granted.

559
00:48:41,840 --> 00:48:45,840
Because we've been, we've had eyes

560
00:48:45,840 --> 00:48:49,840
we broadly speaking as living

561
00:48:49,840 --> 00:48:53,840
species on planet Earth. These eyes have been evolved

562
00:48:53,840 --> 00:48:57,840
for 540 million years. So we have 540 million

563
00:48:57,840 --> 00:49:01,840
years of data. We've been walking for close to that

564
00:49:01,840 --> 00:49:05,840
by petal mammals. We have been

565
00:49:05,840 --> 00:49:09,840
thinking only very recently. So 100,000 years

566
00:49:09,840 --> 00:49:13,840
is 100 million years. And

567
00:49:13,840 --> 00:49:17,840
that's why we can't, some of these problems that we're trying to

568
00:49:17,840 --> 00:49:21,840
solve, you can't take for granted how actually difficult they are. So for

569
00:49:21,840 --> 00:49:25,840
example, this is the Marvex Paradox that Jonathan brought up,

570
00:49:25,840 --> 00:49:29,840
is that the easy problems are hard. The things we think are easy, actually really

571
00:49:29,840 --> 00:49:33,840
hard. This is the state-of-the-art robot on the right playing soccer,

572
00:49:33,840 --> 00:49:37,840
and that was the state-of-the-art human

573
00:49:37,840 --> 00:49:41,840
on the left playing soccer. And

574
00:49:41,840 --> 00:49:45,840
I'll give it a second.

575
00:49:53,840 --> 00:49:57,840
The question was, you know, there's a

576
00:49:57,840 --> 00:50:01,840
fundamental difference between the way we train neural networks and the way we've trained

577
00:50:01,840 --> 00:50:05,840
biological neural networks through evolution by discarding through natural selection a bunch of

578
00:50:05,840 --> 00:50:09,840
the neural networks that didn't work

579
00:50:09,840 --> 00:50:13,840
so well. So first of all, the process of

580
00:50:13,840 --> 00:50:17,840
evolution is, I think, not well understood.

581
00:50:17,840 --> 00:50:21,840
Meaning, sorry, the role,

582
00:50:21,840 --> 00:50:25,840
careful here. The role of

583
00:50:25,840 --> 00:50:29,840
evolution in the evolution of our cognition, of

584
00:50:29,840 --> 00:50:33,840
our intelligence. I don't know if that's, so this

585
00:50:33,840 --> 00:50:37,840
is an open question. So maybe clarify this point. Is neural networks

586
00:50:37,840 --> 00:50:41,840
artificial neural networks are fixed for the most part in size?

587
00:50:41,840 --> 00:50:45,840
This is exactly right. It's like a single human being that gets to

588
00:50:45,840 --> 00:50:49,840
learn. We don't have mechanisms of

589
00:50:49,840 --> 00:50:53,840
modifying or revolving those neural networks yet.

590
00:50:53,840 --> 00:50:57,840
Although you could think of researchers

591
00:50:57,840 --> 00:51:01,840
as doing exactly that. You have grad students working on different

592
00:51:01,840 --> 00:51:05,840
neural networks and the ones that don't do a good job don't get

593
00:51:05,840 --> 00:51:09,840
promoted and get a good job. There is a natural selection there, but other than that

594
00:51:09,840 --> 00:51:13,840
it's an open question. It's a fascinating one.

595
00:51:25,840 --> 00:51:29,840
Stay tuned and keep your head up because the future I believe

596
00:51:29,840 --> 00:51:33,840
is really promising. And the slides will be

597
00:51:33,840 --> 00:51:37,840
made available for sure.

598
00:51:37,840 --> 00:51:41,840
I think a lot of the explorations of

599
00:51:41,840 --> 00:51:45,840
what it means to build an intelligent machine has been in sci-fi movies. We're now beginning

600
00:51:45,840 --> 00:51:49,840
to actually make it a reality. This is Space Odyssey to keep with that theme

601
00:51:49,840 --> 00:51:53,840
in the previous lecture that we had. This is

602
00:51:53,840 --> 00:51:57,840
as opposed to the dream like monolith view

603
00:51:57,840 --> 00:52:01,840
when the astronaut is gazing out

604
00:52:01,840 --> 00:52:05,840
into the open sky at the stars. We're going to look at the practice of

605
00:52:05,840 --> 00:52:09,840
AI today and how we go, if you're familiar with the

606
00:52:09,840 --> 00:52:13,840
movie, when this new technology appeared before our eyes

607
00:52:13,840 --> 00:52:17,840
and we're full of excitement, how we transfer that into

608
00:52:17,840 --> 00:52:21,840
actual practical impact

609
00:52:21,840 --> 00:52:25,840
on our lives. To quickly review what we

610
00:52:25,840 --> 00:52:29,840
talked about last time, I presented the technology

611
00:52:29,840 --> 00:52:33,840
and asked the question of whether this technology merely serves a special purpose

612
00:52:33,840 --> 00:52:37,840
to answer specific tasks that can be formalized or whether it can

613
00:52:37,840 --> 00:52:41,840
be through the process of transferring

614
00:52:41,840 --> 00:52:45,840
the knowledge learned on one domain be generalizable

615
00:52:45,840 --> 00:52:49,840
to where an intelligent system that's trained in a small domain can be

616
00:52:49,840 --> 00:52:53,840
used to achieve general intelligent tasks like we do

617
00:52:53,840 --> 00:52:57,840
as human beings. This is kind of the stack of artificial intelligence

618
00:52:57,840 --> 00:53:01,840
going from all the way up to the top, the environment, the world

619
00:53:01,840 --> 00:53:05,840
the sensors, the sensor data, the intelligence system, the way

620
00:53:05,840 --> 00:53:09,840
it perceives this world. Then once you have this, you convert

621
00:53:09,840 --> 00:53:13,840
the world into some numbers, you're able to extract some representation of that

622
00:53:13,840 --> 00:53:17,840
world and this is where machine learning starts to come into play. And then there's

623
00:53:17,840 --> 00:53:21,840
the part where I will raise it again today is can machine learning

624
00:53:21,840 --> 00:53:25,840
be doing the following steps too that we can do very well as human beings is the

625
00:53:25,840 --> 00:53:29,840
reasoning step. You can tell the difference in a cat and a dog, but can you

626
00:53:29,840 --> 00:53:33,840
now start to reason about what it means to be alive, what it

627
00:53:33,840 --> 00:53:37,840
means to be a cat, a living creature, what it means to be this kind of physical object

628
00:53:37,840 --> 00:53:41,840
or this kind of physical object and take what's called common sense, things we take

629
00:53:41,840 --> 00:53:45,840
for granted, start to construct models of the world through

630
00:53:45,840 --> 00:53:49,840
reasoning. Descartes, I think therefore I am.

631
00:53:49,840 --> 00:53:53,840
We want our neural networks to come up with that on their own.

632
00:53:53,840 --> 00:53:57,840
And once you do that, action.

633
00:53:57,840 --> 00:54:01,840
You'll go right back into the world and you start acting in that world. So the question is

634
00:54:01,840 --> 00:54:05,840
can machine learning, can this be learned from data or do experts need to encode

635
00:54:05,840 --> 00:54:09,840
the knowledge of reasoning, the knowledge of actions, the set of actions.

636
00:54:09,840 --> 00:54:13,840
That's kind of the question, the open questions I raise. It continues throughout the talk

637
00:54:13,840 --> 00:54:17,840
today. And so as we start to think

638
00:54:17,840 --> 00:54:21,840
about how artificial intelligence, especially machine learning

639
00:54:21,840 --> 00:54:25,840
as it relies itself through robotics, gets to impact the world, we start thinking

640
00:54:25,840 --> 00:54:29,840
about what are the easy problems and what are the hard problems. And it seems

641
00:54:29,840 --> 00:54:33,840
to us that vision

642
00:54:33,840 --> 00:54:37,840
and movement, walking is easy because we've been doing it for millions

643
00:54:37,840 --> 00:54:41,840
of years, hundreds of millions of years, and thinking is hard.

644
00:54:41,840 --> 00:54:45,840
Reasoning is hard. I propose to you that it's perhaps because we've only

645
00:54:45,840 --> 00:54:49,840
been doing it for a short time and so think we're quite special

646
00:54:49,840 --> 00:54:53,840
because we're able to think. So we have to kind of question of what is easy

647
00:54:53,840 --> 00:54:57,840
and what is hard. Because when we start to develop some of these systems

648
00:54:57,840 --> 00:55:01,840
and you start to realize that all of these

649
00:55:01,840 --> 00:55:05,840
problems are equally hard. So the problem of walking that we take for granted,

650
00:55:05,840 --> 00:55:09,840
the actuation and the physical, the ability to recognize

651
00:55:09,840 --> 00:55:13,840
where you are in the physical space to sense the world

652
00:55:13,840 --> 00:55:17,840
around you, to deal with the

653
00:55:17,840 --> 00:55:21,840
uncertainty of the perception problem. And then

654
00:55:21,840 --> 00:55:25,840
so all of these robots, by the way, this is for the most recent DARPA Challenge

655
00:55:25,840 --> 00:55:29,840
which MIT was also part of.

656
00:55:29,840 --> 00:55:33,840
And so what are these robots doing? They

657
00:55:33,840 --> 00:55:37,840
don't have any, they only have sparse communication with human beings

658
00:55:37,840 --> 00:55:41,840
on the periphery. So most of the stuff they have to do autonomously

659
00:55:41,840 --> 00:55:45,840
like get inside a car, this is an MIT robot unfortunately,

660
00:55:45,840 --> 00:55:49,840
that they have to get in the car in the hardest tasks, they have to get out of the

661
00:55:49,840 --> 00:55:53,840
car. That's walking. So this kind of

662
00:55:53,840 --> 00:55:57,840
raises to you a very real

663
00:55:57,840 --> 00:56:01,840
aspect here. You want to build applications that actually work in the real world.

664
00:56:01,840 --> 00:56:05,840
And that's the first challenge and opportunity here.

665
00:56:05,840 --> 00:56:09,840
The many of the technologies we talked about currently crumble

666
00:56:09,840 --> 00:56:13,840
under the reality of

667
00:56:13,840 --> 00:56:17,840
our world. When we transfer them from a small

668
00:56:17,840 --> 00:56:21,840
data set in the lab to the real world. For the computer vision

669
00:56:21,840 --> 00:56:25,840
it's perhaps one of the best illustrations of this. Computer vision is the task

670
00:56:25,840 --> 00:56:29,840
as we talked about of interpreting images. And so when

671
00:56:29,840 --> 00:56:33,840
you, there's been a lot of great accomplishments on interpreting images.

672
00:56:33,840 --> 00:56:37,840
Cats versus dogs. Now when you try to create

673
00:56:37,840 --> 00:56:41,840
a system like the Tesla vehicle

674
00:56:41,840 --> 00:56:45,840
that I've often, that we work with and

675
00:56:45,840 --> 00:56:49,840
I always talk about is, it's a vision

676
00:56:49,840 --> 00:56:53,840
based robot, right? It has radar for basic obstacle avoidance

677
00:56:53,840 --> 00:56:57,840
but most of the understanding of the world comes from a single monocular camera.

678
00:56:57,840 --> 00:57:01,840
Now they've expanded the number of cameras but for the most time there's been 100,000

679
00:57:01,840 --> 00:57:05,840
vehicles driving on the roads today with a single, essentially

680
00:57:05,840 --> 00:57:09,840
a single webcam. So when you start to do

681
00:57:09,840 --> 00:57:13,840
that you have to perform all of these extraction of texture, color,

682
00:57:13,840 --> 00:57:17,840
optical flow. So the movement through time, temporal dynamics of the images

683
00:57:17,840 --> 00:57:21,840
you have to construct these patterns, construct the understanding of

684
00:57:21,840 --> 00:57:25,840
objects and entities and how they interact. And from that you have to act

685
00:57:25,840 --> 00:57:29,840
in this world. And that's all based on this computer vision system. So it's no longer

686
00:57:29,840 --> 00:57:33,840
cats versus dogs, it's

687
00:57:33,840 --> 00:57:37,840
detection of pedestrians. Where the wrong

688
00:57:37,840 --> 00:57:41,840
classification, the wrong detection

689
00:57:41,840 --> 00:57:45,840
is the difference between life and death. So let's look at

690
00:57:45,840 --> 00:57:49,840
cats, where things are a little more comfortable. So computer vision

691
00:57:49,840 --> 00:57:53,840
and I would like to illustrate to you why this is such a hard

692
00:57:53,840 --> 00:57:57,840
task. We talked about, we've been doing it for 500 million years

693
00:57:57,840 --> 00:58:01,840
so we think it's easy. Computer vision is actually incredible

694
00:58:01,840 --> 00:58:05,840
so all you're getting with your human eyes is you're getting essentially pixels

695
00:58:05,840 --> 00:58:09,840
in. There's light coming into your eyes and all you're getting is the reflection

696
00:58:09,840 --> 00:58:13,840
from the different surfaces in here of light and there's

697
00:58:13,840 --> 00:58:17,840
perception, there's sensors inside your eyes

698
00:58:17,840 --> 00:58:21,840
converting that into numbers. It's really very similar to this.

699
00:58:21,840 --> 00:58:25,840
Numbers in the case of what we use with computers, RGB images

700
00:58:25,840 --> 00:58:29,840
or the individual pixels that are numbers from

701
00:58:29,840 --> 00:58:33,840
255 to 256 possible numbers and there's just a bunch of them.

702
00:58:33,840 --> 00:58:37,840
And that's all we get. We get a collection of numbers where they're spatially

703
00:58:37,840 --> 00:58:41,840
connected. The ones that are close together are part of the same object so

704
00:58:41,840 --> 00:58:45,840
cat pixels are all connected together. That's the only thing we have to help

705
00:58:45,840 --> 00:58:49,840
us but the rest of it is just numbers, intensity numbers. And we have to use those numbers

706
00:58:49,840 --> 00:58:53,840
to classify what's in the image.

707
00:58:53,840 --> 00:58:57,840
And if you really think about it, this is a really difficult task. All you get

708
00:58:57,840 --> 00:59:01,840
is these numbers. How the heck are you supposed to form a model

709
00:59:01,840 --> 00:59:05,840
of the world with which you can detect

710
00:59:05,840 --> 00:59:09,840
pedestrians with really 99.99999% accuracy.

711
00:59:09,840 --> 00:59:13,840
Because these pedestrians or these cars

712
00:59:13,840 --> 00:59:17,840
are cyclists in the car context or any kind of applications that you're looking at.

713
00:59:17,840 --> 00:59:21,840
Even if your job is on the factory floor to detect

714
00:59:21,840 --> 00:59:25,840
the defective gummy bears that are flying past like 100 miles an hour

715
00:59:25,840 --> 00:59:29,840
your task is you don't want that bad gummy bear to get by

716
00:59:29,840 --> 00:59:33,840
that your product and the brand will be damaged. However

717
00:59:33,840 --> 00:59:37,840
serious or not serious your application is, what you have to be

718
00:59:37,840 --> 00:59:41,840
you have to have a computer vision system that deals with

719
00:59:41,840 --> 00:59:45,840
all of these aspects. Viewpoint variation, scale

720
00:59:45,840 --> 00:59:49,840
variation, no matter the size of the object is still the same object.

721
00:59:49,840 --> 00:59:53,840
No matter the viewpoint from which area you

722
00:59:53,840 --> 00:59:57,840
look at that object is still the same object. The lighting that moves

723
00:59:57,840 --> 01:00:01,840
we have lighting consistently here because we're indoors. But when you're outdoors

724
01:00:01,840 --> 01:00:05,840
or you're moving, the scene is moving, the lighting, the complexity

725
01:00:05,840 --> 01:00:09,840
of the lighting variations is incredible. From the illumination to just

726
01:00:09,840 --> 01:00:13,840
the movement of the different objects in the scene.

727
01:00:13,840 --> 01:00:17,840
Now that we've had these conversations, I think about this every time

728
01:00:17,840 --> 01:00:21,840
I drive. I think about you at this point and how hard it is to see these things.

729
01:00:21,840 --> 01:00:25,840
Particularly when I'm driving at night and particularly when it's twilight and the light is changing

730
01:00:25,840 --> 01:00:29,840
I think almost every time I drive

731
01:00:29,840 --> 01:00:33,840
there's one or two things that I see that I'm drawing

732
01:00:33,840 --> 01:00:37,840
like 200 million years in order to be able to figure out. It's a guy who's

733
01:00:37,840 --> 01:00:41,840
open his car door and I can't see him but I can just see the light doesn't look quite

734
01:00:41,840 --> 01:00:45,840
right on that side of the road and somehow I know in my

735
01:00:45,840 --> 01:00:49,840
mind it's a person. But it seems like an almost

736
01:00:49,840 --> 01:00:53,840
impossible problem for the machines to get right with sufficient accuracy.

737
01:00:53,840 --> 01:00:57,840
I will argue that the pure perception task is too hard.

738
01:00:57,840 --> 01:01:01,840
That you come to the table as human beings with all this

739
01:01:01,840 --> 01:01:05,840
huge amount of knowledge. That you're not actually

740
01:01:05,840 --> 01:01:09,840
interpreting all the complex lighting variations that you're seeing.

741
01:01:09,840 --> 01:01:13,840
You actually know enough about the world, enough about your commute home,

742
01:01:13,840 --> 01:01:17,840
enough about the way, the kinds of things you would see in this

743
01:01:17,840 --> 01:01:21,840
world, about Boston, about the way pedestrians move, the

744
01:01:21,840 --> 01:01:25,840
certain light of day. You bring all that to the table that makes the perception task

745
01:01:25,840 --> 01:01:29,840
doable. And that's one of the big missing pieces in the technology.

746
01:01:29,840 --> 01:01:33,840
As I'll talk about, that's the open problem of machine learning.

747
01:01:33,840 --> 01:01:37,840
It's how to bring all that knowledge, first of all build that knowledge and then bring that

748
01:01:37,840 --> 01:01:41,840
knowledge to the table as opposed to starting from scratch every time.

749
01:01:41,840 --> 01:01:45,840
And so, cats, I promise cats.

750
01:01:45,840 --> 01:01:49,840
Okay, so to me, occlusion, for most of the

751
01:01:49,840 --> 01:01:53,840
computer vision community, this is one of the biggest challenges. And it really highlights

752
01:01:53,840 --> 01:01:57,840
how far we are from

753
01:01:57,840 --> 01:02:01,840
being able to reason about this world. Occlusions are

754
01:02:01,840 --> 01:02:05,840
what an occlusion is, is when the objects you're trying to

755
01:02:05,840 --> 01:02:09,840
detect, something about, classify the object, detect the object,

756
01:02:09,840 --> 01:02:13,840
the object is blocked

757
01:02:13,840 --> 01:02:17,840
by another object in front of them. This is something

758
01:02:17,840 --> 01:02:21,840
that you think is trivial, perhaps. You don't even really think about it, because

759
01:02:21,840 --> 01:02:25,840
we reason in a three-dimensional way. But the occlusion

760
01:02:25,840 --> 01:02:29,840
aspect is, makes, makes perception

761
01:02:29,840 --> 01:02:33,840
incredibly difficult. So we have to design, think about this.

762
01:02:33,840 --> 01:02:37,840
So this image is converted into numbers. And we, for the task of

763
01:02:37,840 --> 01:02:41,840
detecting, is there a cat in this image? Yes or no? You have to be able to

764
01:02:41,840 --> 01:02:45,840
reason about this image with that object in the scene. Most

765
01:02:45,840 --> 01:02:49,840
of us are able to very easily detect that there's a cat in this image.

766
01:02:49,840 --> 01:02:53,840
We're able to detect that there's a cat in this image. Now think about this.

767
01:02:53,840 --> 01:02:57,840
There's a single eye and there's an ear.

768
01:02:57,840 --> 01:03:01,840
So you have to think about what is it part of our brain that allows

769
01:03:01,840 --> 01:03:05,840
us to understand, to, to suppose that with some

770
01:03:05,840 --> 01:03:09,840
high degree of accuracy that there's a cat here in this picture.

771
01:03:09,840 --> 01:03:13,840
I mean the degree of occlusion here is immense.

772
01:03:13,840 --> 01:03:17,840
So this is for most of you.

773
01:03:17,840 --> 01:03:21,840
Some of you will think this is in fact a monk

774
01:03:21,840 --> 01:03:25,840
eating a banana. But I would venture to say that most of us are

775
01:03:25,840 --> 01:03:29,840
able to tell it's never the last of cat.

776
01:03:29,840 --> 01:03:33,840
You'll watch this for hours.

777
01:03:33,840 --> 01:03:37,840
And so let me give you another, this is kind of a paper that's often cited

778
01:03:37,840 --> 01:03:41,840
or a set of papers

779
01:03:41,840 --> 01:03:45,840
to illustrate how difficult computer vision is.

780
01:03:45,840 --> 01:03:49,840
How thin the line that we're walking with

781
01:03:49,840 --> 01:03:53,840
all of these impressive results that we've been able to show recently in the machine

782
01:03:53,840 --> 01:03:57,840
learning community. In this case

783
01:03:57,840 --> 01:04:01,840
for deep neural networks are easily fooled paper.

784
01:04:01,840 --> 01:04:05,840
The seminal paper at this point shows that when you apply

785
01:04:05,840 --> 01:04:09,840
a network trained on ImageNet, so

786
01:04:09,840 --> 01:04:13,840
basically on detecting cats versus dogs or different categories inside images

787
01:04:13,840 --> 01:04:17,840
if you're, you can find

788
01:04:17,840 --> 01:04:21,840
an arbitrary number of images that look like noise up in the top row.

789
01:04:21,840 --> 01:04:25,840
Where the algorithm used

790
01:04:25,840 --> 01:04:29,840
to classify those images in ImageNet of cat versus dog

791
01:04:29,840 --> 01:04:33,840
is able to confidently say with 99.6% accuracy

792
01:04:33,840 --> 01:04:37,840
above that it's seeing a robin or a cheetah

793
01:04:37,840 --> 01:04:41,840
or an armadillo or a panda in that noise.

794
01:04:41,840 --> 01:04:45,840
So it's confidently saying given this noise that that's obviously a robin.

795
01:04:45,840 --> 01:04:49,840
So you have to realize that the kind

796
01:04:49,840 --> 01:04:53,840
of, this is patterns, the kind

797
01:04:53,840 --> 01:04:57,840
of processes it's using to understand what's contained in the image

798
01:04:57,840 --> 01:05:01,840
is purely a collection of patterns that it has been able to

799
01:05:01,840 --> 01:05:05,840
track from other images that has been human, annotated by humans.

800
01:05:05,840 --> 01:05:09,840
And that perhaps is very limiting

801
01:05:09,840 --> 01:05:13,840
to trying to create a system that's able to operate in the real world.

802
01:05:13,840 --> 01:05:17,840
This is a very, so this is a very clean illustration

803
01:05:17,840 --> 01:05:21,840
of that concept. In the same you can confidently predict

804
01:05:21,840 --> 01:05:25,840
in those images below where there's strong patterns, it's not even noise.

805
01:05:25,840 --> 01:05:29,840
Strong patterns that have nothing to do with the entities being detected.

806
01:05:29,840 --> 01:05:33,840
Again, confidently that same algorithm is able to see a penguin,

807
01:05:33,840 --> 01:05:37,840
a starfish, a baseball, and a guitar in that noise.

808
01:05:37,840 --> 01:05:41,840
And more serious for people

809
01:05:41,840 --> 01:05:45,840
designing robots like myself on the

810
01:05:45,840 --> 01:05:49,840
sensor side, you can flip that and say

811
01:05:49,840 --> 01:05:53,840
I can take a image

812
01:05:53,840 --> 01:05:57,840
and I can distort it with some very little amount of noise.

813
01:05:57,840 --> 01:06:01,840
And if that noise is applied to the image

814
01:06:01,840 --> 01:06:05,840
I can completely change the confident prediction about what's in that image.

815
01:06:05,840 --> 01:06:09,840
So to explain what's being shown. So on the left, the column in the left,

816
01:06:09,840 --> 01:06:13,840
and again here, what's

817
01:06:13,840 --> 01:06:17,840
the same kind of neural network is able to predict

818
01:06:17,840 --> 01:06:21,840
accurately, confidently, that there is a dog in that image.

819
01:06:21,840 --> 01:06:25,840
But if we apply just a little bit of noise to that image, to produce

820
01:06:25,840 --> 01:06:29,840
that image, imperceptible to our human eyes, the difference between those two,

821
01:06:29,840 --> 01:06:33,840
the same algorithm is saying that there's confidently an ostrich

822
01:06:33,840 --> 01:06:37,840
in that image. So another thing to really think about

823
01:06:37,840 --> 01:06:41,840
that noise can have such a significant impact on the

824
01:06:41,840 --> 01:06:45,840
prediction of these algorithms. This is really, really

825
01:06:45,840 --> 01:06:49,840
quite honestly out of all the things I'll say today and I'm aware of

826
01:06:49,840 --> 01:06:53,840
one of the biggest challenges of

827
01:06:53,840 --> 01:06:57,840
machine learning being applied in the real world is robustness.

828
01:06:57,840 --> 01:07:01,840
How much noise can you add into the system before

829
01:07:01,840 --> 01:07:05,840
everything falls apart? So how do you validate

830
01:07:05,840 --> 01:07:09,840
sensors? So say a car company has to produce a vehicle

831
01:07:09,840 --> 01:07:13,840
and it has sensors in that vehicle. How do you know that those sensors

832
01:07:13,840 --> 01:07:17,840
will not start generating slight noise due to interference of various

833
01:07:17,840 --> 01:07:21,840
kinds? And because of that noise, instead of seeing a pedestrian

834
01:07:21,840 --> 01:07:25,840
it will see nothing. Or the opposite, it will see pedestrians everywhere.

835
01:07:25,840 --> 01:07:29,840
So of course the most dangerous is when it will not see an object

836
01:07:29,840 --> 01:07:33,840
and collide with it, in the case of cars. There's also spoofing, which a lot of

837
01:07:33,840 --> 01:07:37,840
people as always with security, people are really concerned about.

838
01:07:37,840 --> 01:07:41,840
And perhaps people here are really concerned about this issue. I think this

839
01:07:41,840 --> 01:07:45,840
is a really important issue, but because you can apply noise and convince the system

840
01:07:45,840 --> 01:07:49,840
that you're seeing an ostrich when there's in fact no ostrich,

841
01:07:49,840 --> 01:07:53,840
you can do the same thing in an

842
01:07:53,840 --> 01:07:57,840
attacking way. So you can attack the sensors of a car and make

843
01:07:57,840 --> 01:08:01,840
it believe like with lidar spoofing. So spoof lidar, radar, ultrasonic

844
01:08:01,840 --> 01:08:05,840
sensors to believe that you're seeing pedestrians when they're not there

845
01:08:05,840 --> 01:08:09,840
and the opposite. To hide pedestrians, make pedestrians invisible

846
01:08:09,840 --> 01:08:13,840
to the sensor when they're in fact there.

847
01:08:13,840 --> 01:08:17,840
So whenever you have indulgent systems operating in this world

848
01:08:17,840 --> 01:08:21,840
they become susceptible to

849
01:08:21,840 --> 01:08:25,840
the fact that everything, so much of the work is done in software and based on

850
01:08:25,840 --> 01:08:29,840
sensors. So at any point in the chain if there's a failure

851
01:08:29,840 --> 01:08:33,840
you have to be able to detect that failure and right now we have no mechanisms for

852
01:08:33,840 --> 01:08:37,840
automatically detecting that failure. So on the data side

853
01:08:37,840 --> 01:08:41,840
so one challenge is that we're constantly

854
01:08:41,840 --> 01:08:45,840
dealing with is

855
01:08:45,840 --> 01:08:49,840
we, the algorithms in machine learning algorithms

856
01:08:49,840 --> 01:08:53,840
that we're using are need labeled

857
01:08:53,840 --> 01:08:57,840
data and we have very little labeled data.

858
01:08:57,840 --> 01:09:01,840
Labeled data again is when you have pairs of

859
01:09:01,840 --> 01:09:05,840
input data and the ground truth, the

860
01:09:05,840 --> 01:09:09,840
true label annotation class that

861
01:09:09,840 --> 01:09:13,840
that image belongs to or concept. And it doesn't have to

862
01:09:13,840 --> 01:09:17,840
be an image, it can be any source of data. It's a really costly process to

863
01:09:17,840 --> 01:09:21,840
do. So because it's so costly

864
01:09:21,840 --> 01:09:25,840
we rely

865
01:09:25,840 --> 01:09:29,840
every breakthrough we've had so far relies on that

866
01:09:29,840 --> 01:09:33,840
labeled data and because of its cost we don't

867
01:09:33,840 --> 01:09:37,840
have much of it. So all the problems that come from data can either

868
01:09:37,840 --> 01:09:41,840
be solved by having a lot more of this data which I believe is

869
01:09:41,840 --> 01:09:45,840
and most people believe is too challenging. It's too challenging to have

870
01:09:45,840 --> 01:09:49,840
human beings annotate huge amounts of data or we have to develop

871
01:09:49,840 --> 01:09:53,840
algorithms that are able to do something with the unlabeled data.

872
01:09:53,840 --> 01:09:57,840
It's the unsupervised, semi-supervised, sparsely supervised

873
01:09:57,840 --> 01:10:01,840
reinforcement learning. As we talked about last time I'll mention again

874
01:10:01,840 --> 01:10:05,840
here. So one way you understand

875
01:10:05,840 --> 01:10:09,840
something about data when you don't have labels is you reason

876
01:10:09,840 --> 01:10:13,840
about it. All you're given is a few facts. When you're a baby

877
01:10:13,840 --> 01:10:17,840
your parents give you a few facts and you go into this world with those facts

878
01:10:17,840 --> 01:10:21,840
and you grow your knowledge graph, your knowledge base, your understanding of the world from those

879
01:10:21,840 --> 01:10:25,840
few facts. We don't have a good method of doing that in an automated, unrestricted

880
01:10:25,840 --> 01:10:29,840
way. The inefficiency of our

881
01:10:29,840 --> 01:10:33,840
learners. The machine learning algorithms I've talked about in neural networks need

882
01:10:33,840 --> 01:10:37,840
a lot of examples of every single concept that they're given in order to learn anything

883
01:10:37,840 --> 01:10:41,840
about them. Thousands, tens of thousands of cats are needed to

884
01:10:41,840 --> 01:10:45,840
understand what the spatial patterns at every level

885
01:10:45,840 --> 01:10:49,840
the representation of a cat, the visual representation of a cat.

886
01:10:49,840 --> 01:10:53,840
We don't, we can't do anything with a single example. There's a few approaches

887
01:10:53,840 --> 01:10:57,840
but nothing quite robust

888
01:10:57,840 --> 01:11:01,840
yet. And we haven't come up with

889
01:11:01,840 --> 01:11:05,840
a way, this is also possible, to make

890
01:11:05,840 --> 01:11:09,840
annotation, this labeling process, somehow be

891
01:11:09,840 --> 01:11:13,840
very cheap. So leveraging, this is something been called

892
01:11:13,840 --> 01:11:17,840
human computation. That term is falling out of favor a little bit.

893
01:11:17,840 --> 01:11:21,840
One of my big passions is human computation is using

894
01:11:21,840 --> 01:11:25,840
something about our behavior, something about what we do in this world online

895
01:11:25,840 --> 01:11:29,840
or in the real world to annotate data automatically.

896
01:11:29,840 --> 01:11:33,840
So for example

897
01:11:33,840 --> 01:11:37,840
as you drive, which is what we do, everybody has to

898
01:11:37,840 --> 01:11:41,840
drive and we can collect data about you driving in order to train self-driving vehicles

899
01:11:41,840 --> 01:11:45,840
to drive. And that's a

900
01:11:45,840 --> 01:11:49,840
free annotation. So here are the annotated data sets

901
01:11:49,840 --> 01:11:53,840
we have. The supervised learning data sets.

902
01:11:53,840 --> 01:11:57,840
There's many, but these are some of the more famous ones.

903
01:11:57,840 --> 01:12:01,840
From the toy data sets of MNIST to the large, broad

904
01:12:01,840 --> 01:12:05,840
arbitrary categories of images data sets

905
01:12:05,840 --> 01:12:09,840
which is what ImageNet is. And there's

906
01:12:09,840 --> 01:12:13,840
in healthcare, there's in audio, there's in video, there's

907
01:12:13,840 --> 01:12:17,840
a huge number of data sets now, but each one of them is usually

908
01:12:17,840 --> 01:12:21,840
on the scale of hundreds of thousands, millions, tens of millions

909
01:12:21,840 --> 01:12:25,840
not billions or trillions, which is what we need to create

910
01:12:25,840 --> 01:12:29,840
systems that operate in the real world. And again

911
01:12:29,840 --> 01:12:33,840
these are the kinds of machine learning algorithms we have. There's five listed

912
01:12:33,840 --> 01:12:37,840
here. The teachers on the left

913
01:12:37,840 --> 01:12:41,840
is what is the input

914
01:12:41,840 --> 01:12:45,840
to the system that requires to train it. From the supervised

915
01:12:45,840 --> 01:12:49,840
learning at the very top is what we have all of our successes. And everything else is where the

916
01:12:49,840 --> 01:12:53,840
promise lies. The semi-supervised, the reinforcement

917
01:12:53,840 --> 01:12:57,840
or the fully unsupervised learning, where the input from the human is very

918
01:12:57,840 --> 01:13:01,840
minimal. And another way to think about this, so

919
01:13:01,840 --> 01:13:05,840
whenever you think about machine learning today, whenever somebody talks about machine

920
01:13:05,840 --> 01:13:09,840
learning, what they're talking about is systems that memorize.

921
01:13:09,840 --> 01:13:13,840
That memorize patterns. And so this is one of the big

922
01:13:13,840 --> 01:13:17,840
criticisms of the current machine learning approaches, where all they're doing is

923
01:13:17,840 --> 01:13:21,840
you're providing, they're only as good as the human annotated

924
01:13:21,840 --> 01:13:25,840
data that they're provided. We don't have mechanisms for actually

925
01:13:25,840 --> 01:13:29,840
understanding. You can pause and think about this. In order to

926
01:13:29,840 --> 01:13:33,840
create an intelligent system it shouldn't just memorize. It should understand

927
01:13:33,840 --> 01:13:37,840
the representations inside that data in order to operate in that

928
01:13:37,840 --> 01:13:41,840
world. And that's the open question.

929
01:13:41,840 --> 01:13:45,840
One of them. And one of the challenges and opportunities for machine learning

930
01:13:45,840 --> 01:13:49,840
researchers today is to extend machine learning

931
01:13:49,840 --> 01:13:53,840
from memorization to understanding. This is that

932
01:13:53,840 --> 01:13:57,840
duck. The reasoning

933
01:13:57,840 --> 01:14:01,840
if you get information from the perception systems that it

934
01:14:01,840 --> 01:14:05,840
looks like a duck, from the audio processing that it quacks like a duck,

935
01:14:05,840 --> 01:14:09,840
and then from video classification that the activity recognition that it

936
01:14:09,840 --> 01:14:13,840
swims like a duck, the reasoning step is how to connect those

937
01:14:13,840 --> 01:14:17,840
facts to then say that it is in fact a duck.

938
01:14:17,840 --> 01:14:21,840
Okay, so that's on the algorithm side and the

939
01:14:21,840 --> 01:14:25,840
data side. Now this is one of the reasons

940
01:14:25,840 --> 01:14:29,840
computational power, computational hardware that is at the core

941
01:14:29,840 --> 01:14:33,840
of the success of machine learning.

942
01:14:33,840 --> 01:14:37,840
So our algorithms have been the same since the 60's, since the

943
01:14:37,840 --> 01:14:41,840
80's, 90's depending on how you're counting. The big

944
01:14:41,840 --> 01:14:45,840
breakthroughs came in compute. So there's Moore's law.

945
01:14:45,840 --> 01:14:49,840
Most of you know the way the CPU

946
01:14:49,840 --> 01:14:53,840
side of our computers works for a single CPU is that it's

947
01:14:53,840 --> 01:14:57,840
for the most part executing a single action at a time

948
01:14:57,840 --> 01:15:01,840
in a sequence. So sequential. Very different from

949
01:15:01,840 --> 01:15:05,840
our brain which is a massively parallelized system.

950
01:15:05,840 --> 01:15:09,840
So because it's sequential the clock speed matters because that's how fast

951
01:15:09,840 --> 01:15:13,840
essentially those instructions are able to be executed. And so

952
01:15:13,840 --> 01:15:17,840
where we're leveling off, physics

953
01:15:17,840 --> 01:15:21,840
is stopping us from continuing Moore's law.

954
01:15:21,840 --> 01:15:25,840
Intel, AMD are aggressively pushing this Moore's law

955
01:15:25,840 --> 01:15:29,840
forward. But, and there's

956
01:15:29,840 --> 01:15:33,840
some promise that it will actually continue for another 10 or 15 years.

957
01:15:33,840 --> 01:15:37,840
Then there's another

958
01:15:37,840 --> 01:15:41,840
form of parallelism, massive parallelism. It's the GPU.

959
01:15:41,840 --> 01:15:45,840
This is essential for neural networks.

960
01:15:45,840 --> 01:15:49,840
This is essential to the success, recent success of neural networks is the

961
01:15:49,840 --> 01:15:53,840
ability to utilize these inherently parallel

962
01:15:53,840 --> 01:15:57,840
architectures of graphics processing

963
01:15:57,840 --> 01:16:01,840
units, GPUs. The same thing used for video games. This is the

964
01:16:01,840 --> 01:16:05,840
reason NVIDIA stock is doing

965
01:16:05,840 --> 01:16:09,840
extremely well, is GPUs. So it's

966
01:16:09,840 --> 01:16:13,840
parallelism of basic computational processes that make

967
01:16:13,840 --> 01:16:17,840
machine learning work on the GPU. One of the

968
01:16:17,840 --> 01:16:21,840
limitations of GPUs, one of the challenges is

969
01:16:21,840 --> 01:16:25,840
in bringing them to, in scaling and bringing them into real world applications is

970
01:16:25,840 --> 01:16:29,840
power usage, is power consumption. And so there is

971
01:16:29,840 --> 01:16:33,840
a lot of specialized chips specialized just

972
01:16:33,840 --> 01:16:37,840
from the neural network architectures coming out from Google

973
01:16:37,840 --> 01:16:41,840
with their tensor processing unit from IBM, Intel and so on.

974
01:16:41,840 --> 01:16:45,840
It's unclear how far this goes. So this is sort of the direction

975
01:16:45,840 --> 01:16:49,840
of trying to design an electronic brain, so it has the efficiency.

976
01:16:49,840 --> 01:16:53,840
Our human brain is exceptionally efficient at running the neural networks

977
01:16:53,840 --> 01:16:57,840
in our heads. Or does the magnitude more efficient

978
01:16:57,840 --> 01:17:01,840
than our computers are? And this is trying to design systems that are able to

979
01:17:01,840 --> 01:17:05,840
go towards that efficiency. Why do you care about

980
01:17:05,840 --> 01:17:09,840
efficiency? For several reasons. One, of course,

981
01:17:09,840 --> 01:17:13,840
I'm sure we'll talk about throughout this class is about the thing in our

982
01:17:13,840 --> 01:17:17,840
smartphones, battery usage. And this

983
01:17:17,840 --> 01:17:21,840
is the big one, community. I think

984
01:17:21,840 --> 01:17:25,840
it could be attributed to the big

985
01:17:25,840 --> 01:17:29,840
breakthroughs in machine learning recently in the last decade is

986
01:17:29,840 --> 01:17:33,840
the, you know, compute is important, algorithm development

987
01:17:33,840 --> 01:17:37,840
is important, but it's the community

988
01:17:37,840 --> 01:17:41,840
of nerds, global. This is global artificial intelligence

989
01:17:41,840 --> 01:17:45,840
and I will show in several ways why global is

990
01:17:45,840 --> 01:17:49,840
essential here is tens of

991
01:17:49,840 --> 01:17:53,840
hundreds of thousands, millions of programmers, mechanical

992
01:17:53,840 --> 01:17:57,840
engineers, building robots, building intelligence systems,

993
01:17:57,840 --> 01:18:01,840
building machine learning algorithms. The exciting nature

994
01:18:01,840 --> 01:18:05,840
of the growth of the community perhaps is the key

995
01:18:05,840 --> 01:18:09,840
to the future to unlocking the power of machine learning. So this is just

996
01:18:09,840 --> 01:18:13,840
one example of GitHub as a repository for code and this is showing on

997
01:18:13,840 --> 01:18:17,840
the y-axis at the bottom is 2008 when GitHub first opened and this is

998
01:18:17,840 --> 01:18:21,840
going up to 2012. Quick, near exponential

999
01:18:21,840 --> 01:18:25,840
growth of the number of users participating and the number of repositories. So these are

1000
01:18:25,840 --> 01:18:29,840
standalone unique projects that are being hosted on GitHub.

1001
01:18:29,840 --> 01:18:33,840
So this is one example I'll show you about this competition

1002
01:18:33,840 --> 01:18:37,840
that we're recently running and then I'll challenge people here to participate in this competition

1003
01:18:37,840 --> 01:18:41,840
if you dare. So this is a

1004
01:18:41,840 --> 01:18:45,840
chance for you to build a neural network in your browser

1005
01:18:45,840 --> 01:18:49,840
so you can do this on your phone later tonight of course.

1006
01:18:49,840 --> 01:18:53,840
On your phone you can specify various

1007
01:18:53,840 --> 01:18:57,840
parameters of the neural network, specify different numbers of layers and the depth

1008
01:18:57,840 --> 01:19:01,840
of the network, the number of neurons in the network, the type of layers and it's pretty

1009
01:19:01,840 --> 01:19:05,840
self-explanatory, super easy in terms of just

1010
01:19:05,840 --> 01:19:09,840
tweaking little things and remember machine learning to a large

1011
01:19:09,840 --> 01:19:13,840
part is an art at this point. It's

1012
01:19:13,840 --> 01:19:17,840
more perhaps than even, you know, more than a well understood

1013
01:19:17,840 --> 01:19:21,840
theoretically bounded science which is one of the challenges but it's also an opportunity.

1014
01:19:21,840 --> 01:19:25,840
Deep traffic is a chance, so we've all been stuck

1015
01:19:25,840 --> 01:19:29,840
in traffic. There you go, Americans spend 8 billion hours stuck in traffic every year.

1016
01:19:29,840 --> 01:19:33,840
That's our pitch for this competition. So deep neural network can help

1017
01:19:33,840 --> 01:19:37,840
and so you have a neural network that drives that little car with an

1018
01:19:37,840 --> 01:19:41,840
MIT logo, red one, on this highway and tries to weave in and out of traffic to get

1019
01:19:41,840 --> 01:19:45,840
to his destination and trying to achieve a speed of

1020
01:19:45,840 --> 01:19:49,840
80 miles an hour which is the speed limit which is the physical

1021
01:19:49,840 --> 01:19:53,840
speed limit of the car. Of course the actual speed limit of the road is 65 miles an hour

1022
01:19:53,840 --> 01:19:57,840
but we don't care about that. We just want to get to work as quickly as possible at home.

1023
01:19:57,840 --> 01:20:01,840
So what the basic

1024
01:20:01,840 --> 01:20:05,840
structure of this game is and I want to explain this game a little bit and then tell

1025
01:20:05,840 --> 01:20:09,840
you how incredibly popular it's gotten and how incredibly

1026
01:20:09,840 --> 01:20:13,840
powerful the

1027
01:20:13,840 --> 01:20:17,840
networks that people have built from all over the world. The community has built

1028
01:20:17,840 --> 01:20:21,840
of this over a single month is incredible and this happens for

1029
01:20:21,840 --> 01:20:25,840
thousands of projects out there. Now another challenging

1030
01:20:25,840 --> 01:20:29,840
opportunity. Okay so you may have seen this, this is kind of ethics.

1031
01:20:29,840 --> 01:20:33,840
Most engineers, I personally don't like, I

1032
01:20:33,840 --> 01:20:37,840
love philosophy but this kind of construction of

1033
01:20:37,840 --> 01:20:41,840
ethics that's often presented here is one that is not usually

1034
01:20:41,840 --> 01:20:45,840
concerned to engineering. So what is this question? You know when you have a car

1035
01:20:45,840 --> 01:20:49,840
and you have a bunch of pedestrians, do you hit the larger group of pedestrians

1036
01:20:49,840 --> 01:20:53,840
or the smaller group of pedestrians? Do you avoid the group

1037
01:20:53,840 --> 01:20:57,840
of pedestrians but put yourself into danger? These kinds of ethical

1038
01:20:57,840 --> 01:21:01,840
questions of an intelligent system. It's a very interesting question.

1039
01:21:01,840 --> 01:21:05,840
It's one that we can debate and there's really no good answer quite honestly

1040
01:21:05,840 --> 01:21:09,840
but it's a problem that both humans and machines struggle with and so it's

1041
01:21:09,840 --> 01:21:13,840
not interesting on the engineering side. We're interested with problems that we can

1042
01:21:13,840 --> 01:21:17,840
solve on the engineering side. So the kind of problem that I'm obsessed with

1043
01:21:17,840 --> 01:21:21,840
and very interested in is the real world problem of controlling a vehicle through this space.

1044
01:21:21,840 --> 01:21:25,840
So it happens in a few seconds

1045
01:21:25,840 --> 01:21:29,840
here. So this is a Manhattan-New York intersection, right?

1046
01:21:29,840 --> 01:21:33,840
This is pedestrians walking perfectly

1047
01:21:33,840 --> 01:21:37,840
legally. I think they have a green light. Of course there's a lot of jaywalking too as well.

1048
01:21:37,840 --> 01:21:41,840
Well this car just, it's not part of the

1049
01:21:41,840 --> 01:21:45,840
point but yes, exactly, there's an ambulance. And so there's another car that starts

1050
01:21:45,840 --> 01:21:49,840
making a left turn in a little bit. Let me admit that hopefully not.

1051
01:21:49,840 --> 01:21:53,840
But yeah, and then there's another car after that too that just illustrates

1052
01:21:53,840 --> 01:21:57,840
when you design an algorithm that's supposed to move through this space

1053
01:21:57,840 --> 01:22:01,840
like watch this car. The aggression it shows. Now this isn't

1054
01:22:01,840 --> 01:22:05,840
a trivial example for those that try to build robots. This is the real question

1055
01:22:05,840 --> 01:22:09,840
is how do you design a system

1056
01:22:09,840 --> 01:22:13,840
that's able, so you have to think. You have to put

1057
01:22:13,840 --> 01:22:17,840
reward functions, objective functions, utility functions under which

1058
01:22:17,840 --> 01:22:21,840
it performs the planning. So a car like that has

1059
01:22:21,840 --> 01:22:25,840
several thousand candidate trajectories you can take through that

1060
01:22:25,840 --> 01:22:29,840
intersection. You can take a trajectory where it speeds up to 60 miles an hour and doesn't stop

1061
01:22:29,840 --> 01:22:33,840
and just swerves and hits everything. Okay, that's a bad trajectory, right? Then

1062
01:22:33,840 --> 01:22:37,840
there's a trajectory which most companies take, most

1063
01:22:37,840 --> 01:22:41,840
Google self-driving car and every company that's concerned about PR is

1064
01:22:41,840 --> 01:22:45,840
whenever there's any kind of obstacle, any kind of risk that's

1065
01:22:45,840 --> 01:22:49,840
at all reasonable that you can maybe even touch an obstacle then you're not going

1066
01:22:49,840 --> 01:22:53,840
to take that trajectory. So what that means is you're going to navigate through this intersection

1067
01:22:53,840 --> 01:22:57,840
at 10 miles an hour and let people abuse you by walking in front of you

1068
01:22:57,840 --> 01:23:01,840
because they know you're not going to stop. And so in the middle there is

1069
01:23:01,840 --> 01:23:05,840
hundreds, thousands of trajectories that are ethically questionable

1070
01:23:05,840 --> 01:23:09,840
in the sense that you're putting other human beings at risk in order to

1071
01:23:09,840 --> 01:23:13,840
safely and successfully navigate through the intersection. And the design of those

1072
01:23:13,840 --> 01:23:17,840
objective functions is the kind of question you have to ask

1073
01:23:17,840 --> 01:23:21,840
for intelligence systems for cars. There's no

1074
01:23:21,840 --> 01:23:25,840
grandma and a few children you have to choose who gets to

1075
01:23:25,840 --> 01:23:29,840
die. Very difficult problems, of course. But

1076
01:23:29,840 --> 01:23:33,840
the problem of what I'm very interested in in streets of Boston

1077
01:23:33,840 --> 01:23:37,840
and streets of New York is how to gently nudge yourself

1078
01:23:37,840 --> 01:23:41,840
through a crowd of pedestrians in the way we all actually do

1079
01:23:41,840 --> 01:23:45,840
when we drive in New York in order to be able to safely

1080
01:23:45,840 --> 01:23:49,840
navigate these environments. And these questions come up in healthcare, these questions come up

1081
01:23:49,840 --> 01:23:53,840
in factory, in robots, in armed and humanoid robots

1082
01:23:53,840 --> 01:23:57,840
that operate with other human beings.

1083
01:23:57,840 --> 01:24:01,840
And that's one of the big challenges. Another sort of

1084
01:24:01,840 --> 01:24:05,840
fun illustration that folks at OpenAI use often

1085
01:24:05,840 --> 01:24:09,840
to illustrate, well let me just pause for a second, the gamified version

1086
01:24:09,840 --> 01:24:13,840
of this. There's a game called Coast Runners and you're racing against other boats

1087
01:24:13,840 --> 01:24:17,840
along this track. And your job is, there's your score here

1088
01:24:17,840 --> 01:24:21,840
at the bottom left, number of laps, your time, and you're

1089
01:24:21,840 --> 01:24:25,840
trying to get to the destination as quickly as possible while also collecting

1090
01:24:25,840 --> 01:24:29,840
funky little things like these green

1091
01:24:29,840 --> 01:24:33,840
these green little things along the way. Okay, so

1092
01:24:33,840 --> 01:24:37,840
what they've done is a build intent system, the one, the general purpose one that we

1093
01:24:37,840 --> 01:24:41,840
talked about last time that learns, oops, that learns

1094
01:24:41,840 --> 01:24:45,840
how to navigate successfully through the space. So

1095
01:24:45,840 --> 01:24:49,840
you're trying to maximize the reward. And what this boat

1096
01:24:49,840 --> 01:24:53,840
learns to do is instead of finishing the race

1097
01:24:53,840 --> 01:24:57,840
it learns to find a loop where

1098
01:24:57,840 --> 01:25:01,840
it can keep going around and around, collecting those green dots

1099
01:25:01,840 --> 01:25:05,840
and it learns the fact that they regenerate with time.

1100
01:25:05,840 --> 01:25:09,840
So it learns to maximize this score

1101
01:25:09,840 --> 01:25:13,840
by going around and around. Now these are the kinds of things

1102
01:25:13,840 --> 01:25:17,840
this is the big challenge of reward functions, of designing systems

1103
01:25:17,840 --> 01:25:21,840
of designing what you want your system to achieve is

1104
01:25:21,840 --> 01:25:25,840
not only is it difficult to, the ethical questions are difficult

1105
01:25:25,840 --> 01:25:29,840
but just avoiding the pitfalls of local optima

1106
01:25:29,840 --> 01:25:33,840
of figuring out something really good that happens

1107
01:25:33,840 --> 01:25:37,840
in the short term, the greedy, what are those, those psychology experiments of the kid

1108
01:25:37,840 --> 01:25:41,840
eats the marshmallow and can't wait for, you know, can't

1109
01:25:41,840 --> 01:25:45,840
delay gratification. This kind of, the idea of delay gratification

1110
01:25:45,840 --> 01:25:49,840
in the case of designing intelligence systems is a huge actual serious problem

1111
01:25:49,840 --> 01:25:53,840
and this is a good illustration of that.

1112
01:25:53,840 --> 01:25:57,840
So we flew through a few concepts here

1113
01:25:57,840 --> 01:26:01,840
is there any questions about

1114
01:26:01,840 --> 01:26:05,840
the compute and the algorithm side we talked about today?

1115
01:26:05,840 --> 01:26:09,840
So the question was, yeah you highlighted some of the limitations of

1116
01:26:09,840 --> 01:26:13,840
machine, computer vision algorithms, machine learning algorithms, but

1117
01:26:13,840 --> 01:26:17,840
you haven't highlighted some of the limitations of human beings and if you put those in a column

1118
01:26:17,840 --> 01:26:21,840
and you compare those, are machines doing better

1119
01:26:21,840 --> 01:26:25,840
overall or is there any kind of way to compare those? I mean there is actually

1120
01:26:25,840 --> 01:26:29,840
interesting work on ImageNet, so ImageNet is this categorization

1121
01:26:29,840 --> 01:26:33,840
task of where you have to classify images and you can ask the question

1122
01:26:33,840 --> 01:26:37,840
when I present you images of cats and dogs, where are machines better than humans

1123
01:26:37,840 --> 01:26:41,840
and when are they not? So you can compare when machines do better,

1124
01:26:41,840 --> 01:26:45,840
what are the fail points and what are the fail points for humans and there's a lot of interesting

1125
01:26:45,840 --> 01:26:49,840
visual perception questions there. But I think overall it's certainly

1126
01:26:49,840 --> 01:26:53,840
true that machines fail differently than human beings, but

1127
01:26:53,840 --> 01:26:57,840
in order to make an artificial intelligence system

1128
01:26:57,840 --> 01:27:01,840
usable and could make you a lot of money

1129
01:27:01,840 --> 01:27:05,840
and people would want to use, it has to be better for that particular task

1130
01:27:05,840 --> 01:27:09,840
in every single way. In order

1131
01:27:09,840 --> 01:27:13,840
for you to want to use a system, it has to be superior

1132
01:27:13,840 --> 01:27:17,840
to human performance and usually far superior to human performance.

1133
01:27:17,840 --> 01:27:21,840
So on the philosophical level it's an interesting thing to compare

1134
01:27:21,840 --> 01:27:25,840
what are we good at, what are not, but if you're using

1135
01:27:25,840 --> 01:27:29,840
Amazon Echo, your voice recognition

1136
01:27:29,840 --> 01:27:33,840
or any kind of natural language, chatbots, or a car,

1137
01:27:33,840 --> 01:27:37,840
you're not going to be, well this car is not so good with pedestrians, but I appreciate the fact

1138
01:27:37,840 --> 01:27:41,840
that you can stay in the lane. Fortunately you have a very high standard

1139
01:27:41,840 --> 01:27:45,840
for every single thing that you're good at and it has to be superior to that. I think

1140
01:27:45,840 --> 01:27:49,840
maybe that's unfair to the robots.

1141
01:27:49,840 --> 01:27:53,840
I'm more of the nerd that makes the technology happen

1142
01:27:53,840 --> 01:27:57,840
but it's certainly on the self-driving car aspect

1143
01:27:57,840 --> 01:28:01,840
policy is probably the biggest challenge and I don't think there's good answers

1144
01:28:01,840 --> 01:28:05,840
there. Some of those ethical questions that

1145
01:28:05,840 --> 01:28:09,840
come up, it feels like, so we work a lot with Tesla

1146
01:28:09,840 --> 01:28:13,840
so I'm driving a Tesla around every day and we're playing around with it

1147
01:28:13,840 --> 01:28:17,840
and studying human behavior inside Tesla and it seems like there's so much

1148
01:28:17,840 --> 01:28:21,840
hunger amongst the media to jump on something and it feels like

1149
01:28:21,840 --> 01:28:25,840
a very shaky PR terrain, a very shaky

1150
01:28:25,840 --> 01:28:29,840
policy terrain we're all walking because we have no idea how

1151
01:28:29,840 --> 01:28:33,840
we coexist with intelligent systems and then of course

1152
01:28:33,840 --> 01:28:37,840
the government is nervous because how do we regulate this shaky terrain

1153
01:28:37,840 --> 01:28:41,840
and everybody's nervous and excited.

1154
01:28:41,840 --> 01:28:45,840
That's a perfect transition point if that's okay.

1155
01:28:45,840 --> 01:28:49,840
That same kind of question to Jason in a moment. Thanks a lot Lex for another great session.

1156
01:28:49,840 --> 01:28:53,840
Thank you.

