1
00:00:00,000 --> 00:00:11,160
This idea of disk, distributed idea suppression complex, is that what's bringing the elons

2
00:00:11,160 --> 00:00:13,040
of the world down?

3
00:00:13,040 --> 00:00:17,600
You know, it's so funny, like he's asking Joe Rogan, like, is that a joint?

4
00:00:17,600 --> 00:00:19,760
You know, it's like, well, what will happen if I smoke it?

5
00:00:19,760 --> 00:00:21,560
What will happen to the stock price?

6
00:00:21,560 --> 00:00:24,480
What will happen if I scratch myself in public?

7
00:00:24,480 --> 00:00:29,760
What will happen if I say what I think about Thailand, or COVID, or who knows what?

8
00:00:29,760 --> 00:00:31,920
And everybody's like, don't say that.

9
00:00:31,920 --> 00:00:32,920
Say this.

10
00:00:32,920 --> 00:00:33,920
Go do this.

11
00:00:33,920 --> 00:00:34,920
Go do that.

12
00:00:34,920 --> 00:00:36,320
Well, it's crazy making.

13
00:00:36,320 --> 00:00:38,200
It's absolutely crazy making.

14
00:00:38,200 --> 00:00:46,520
And if you think about what we put through, people through, we need to get people who

15
00:00:46,520 --> 00:00:52,920
can use FU money, the FU money they need to insulate themselves from all of the people

16
00:00:53,040 --> 00:00:54,040
who know better.

17
00:00:54,040 --> 00:00:59,320
Because my nightmare is that, why did we only get one elon?

18
00:00:59,320 --> 00:01:02,740
What if we were supposed to have thousands and thousands of elons?

19
00:01:02,740 --> 00:01:06,560
And the weird thing is, like, this is all that remains.

20
00:01:06,560 --> 00:01:10,520
You're looking at, like, Obi-Wan and Yoda.

21
00:01:10,520 --> 00:01:18,000
And it's like, this is the only, this is all that's left after Order 66 has been executed.

22
00:01:18,000 --> 00:01:22,320
And that's the thing that's really upsetting to me, is we used to have elons five deep.

23
00:01:22,320 --> 00:01:27,080
And then we could talk about elon in the context of his cohort.

24
00:01:27,080 --> 00:01:31,800
But this is like, if you were to see a giraffe in the Arctic with no trees around, you'd

25
00:01:31,800 --> 00:01:33,920
think, why the long neck?

26
00:01:33,920 --> 00:01:36,640
What a strange sight, you know?

27
00:01:36,640 --> 00:01:39,120
How do we get more elons?

28
00:01:39,120 --> 00:01:40,280
How do we change things?

29
00:01:40,280 --> 00:01:46,320
So I think they use, so we know MIT and Harvard.

30
00:01:46,320 --> 00:01:51,560
So maybe returning to our previous conversation, my sense is that the elons of the world are

31
00:01:51,560 --> 00:01:54,760
supposed to come from MIT and Harvard.

32
00:01:54,760 --> 00:01:56,520
And how do you change?

33
00:01:56,520 --> 00:02:00,720
Let's think of one that MIT sort of killed.

34
00:02:00,720 --> 00:02:03,360
Have any names in mind?

35
00:02:03,360 --> 00:02:06,120
Aaron Schwartz leaps to my mind.

36
00:02:06,120 --> 00:02:07,120
Yeah.

37
00:02:07,120 --> 00:02:08,120
Okay.

38
00:02:08,120 --> 00:02:17,120
Are we MIT supposed to shield the Aaron Schwartz's from, I don't know, journal publishers?

39
00:02:17,120 --> 00:02:21,840
Or are we supposed to help the journal publishers so that we can throw 35-year sentences in

40
00:02:21,840 --> 00:02:24,880
his face or whatever it is that we did that depressed him?

41
00:02:24,880 --> 00:02:25,880
Okay.

42
00:02:25,880 --> 00:02:27,360
So here's my point.

43
00:02:27,360 --> 00:02:33,520
I want MIT to go back to being the home of Aaron Schwartz.

44
00:02:33,520 --> 00:02:40,840
And if you want to send Aaron Schwartz to a state where he's looking at 35 years in

45
00:02:40,840 --> 00:02:44,600
prison or something like that, you are my sworn enemy.

46
00:02:44,600 --> 00:02:46,000
You are not MIT.

47
00:02:46,000 --> 00:02:47,000
Yeah.

48
00:02:47,160 --> 00:02:58,560
You are the traitorous, irresponsible, middle-brow, pencil-pushing, green-eye-shade fool that

49
00:02:58,560 --> 00:03:02,240
needs to not be in the seat at the presidency of MIT.

50
00:03:02,240 --> 00:03:03,240
Period.

51
00:03:03,240 --> 00:03:04,240
The end.

52
00:03:04,240 --> 00:03:07,280
Get the fuck out of there and let one of our people sit in that chair.

53
00:03:07,280 --> 00:03:13,360
And the thing that you've articulated is that the people in those chairs are not the way

54
00:03:13,440 --> 00:03:20,000
they are because they're evil or somehow morally compromised is that it's just that's the distributed

55
00:03:20,000 --> 00:03:21,000
nature.

56
00:03:21,000 --> 00:03:22,920
Is that there's some kind of aspect of the system that's just...

57
00:03:22,920 --> 00:03:26,720
These are people who wed themselves to the system.

58
00:03:26,720 --> 00:03:28,800
They adapt every instinct.

59
00:03:28,800 --> 00:03:35,280
And the fact is that they're not going to be on Joe Rogan smoking a blunt.

60
00:03:35,280 --> 00:03:36,360
Let me ask a silly question.

61
00:03:36,360 --> 00:03:40,320
Do you think institutions generally just tend to become that?

62
00:03:40,320 --> 00:03:42,080
No.

63
00:03:42,080 --> 00:03:43,880
We get some of the institutions.

64
00:03:43,880 --> 00:03:44,880
We get Caltech.

65
00:03:44,880 --> 00:03:46,640
Here's what we're supposed to have.

66
00:03:46,640 --> 00:03:48,000
We're supposed to have Caltech.

67
00:03:48,000 --> 00:03:50,040
We're supposed to have Reed.

68
00:03:50,040 --> 00:03:53,200
We're supposed to have Deep Springs.

69
00:03:53,200 --> 00:03:54,400
We're supposed to have MIT.

70
00:03:54,400 --> 00:03:57,680
We're supposed to have a part of Harvard.

71
00:03:57,680 --> 00:04:02,520
And when the sharp elbow crowd comes after the sharp mind crowd, we're supposed to break

72
00:04:02,520 --> 00:04:06,040
those sharp elbows and say, don't come around here again.

73
00:04:06,040 --> 00:04:10,920
So what are the weapons that the sharp minds are supposed to use in our modern day?

74
00:04:11,040 --> 00:04:12,560
To reclaim MIT.

75
00:04:12,560 --> 00:04:15,200
What is the future?

76
00:04:15,200 --> 00:04:16,760
Are you kidding me?

77
00:04:16,760 --> 00:04:19,720
First of all, assume that this is being seen at MIT.

78
00:04:19,720 --> 00:04:20,720
Hey, everybody.

79
00:04:20,720 --> 00:04:21,720
Definitely is.

80
00:04:21,720 --> 00:04:22,720
Okay.

81
00:04:22,720 --> 00:04:24,400
Hey, everybody.

82
00:04:24,400 --> 00:04:26,480
Try to remember who you are.

83
00:04:26,480 --> 00:04:30,080
You're the guys who put the police car on top of the great dump.

84
00:04:30,080 --> 00:04:32,280
You guys came up with the great breast of knowledge.

85
00:04:32,280 --> 00:04:35,600
You created a Tetris game in the green building.

86
00:04:35,600 --> 00:04:38,680
Now, what is your problem?

87
00:04:38,680 --> 00:04:40,600
They killed one of your own.

88
00:04:40,600 --> 00:04:44,160
You should make their life a living hell.

89
00:04:44,160 --> 00:04:49,880
You should be the ones who keep the memory of Aaron Schwartz alive and all of those hackers

90
00:04:49,880 --> 00:04:52,880
and all of those mutants.

91
00:04:52,880 --> 00:04:57,400
You know, it's like it's either our place or it isn't.

92
00:04:57,400 --> 00:05:05,400
And if we have to throw 12 more pianos off of the roof, right, if Harold Edgerton was

93
00:05:05,400 --> 00:05:14,880
taking those photographs, you know, with Slow Mo back in the 40s, if Noam Chomsky is on

94
00:05:14,880 --> 00:05:19,280
your faculty, what the hell is wrong with you kids?

95
00:05:19,280 --> 00:05:23,520
You are the most creative and insightful people and you can't figure out how to defend Aaron

96
00:05:23,520 --> 00:05:24,520
Schwartz.

97
00:05:24,520 --> 00:05:25,520
That's on you guys.

98
00:05:25,520 --> 00:05:30,120
So, some of that is giving more power to the young, like you said, to the brave, to the

99
00:05:30,120 --> 00:05:31,120
bold.

100
00:05:31,120 --> 00:05:33,640
No, taking power from the feeble and the middle brown.

101
00:05:33,760 --> 00:05:35,680
Yeah, but what is the mechanism?

102
00:05:35,680 --> 00:05:36,680
To me, I don't know.

103
00:05:36,680 --> 00:05:38,160
Do you have some nine-volt batteries?

104
00:05:38,160 --> 00:05:39,160
No.

105
00:05:39,160 --> 00:05:41,160
It's a copper wire?

106
00:05:41,160 --> 00:05:43,160
I tend to...

107
00:05:43,160 --> 00:05:44,760
Do you have a capacitor?

108
00:05:44,760 --> 00:05:51,240
I tend to believe you have to create an alternative and make the alternative so much better that

109
00:05:51,240 --> 00:05:55,920
it makes MIT obsolete unless they change.

110
00:05:55,920 --> 00:05:59,360
And that's what forces change, so as opposed to somehow...

111
00:05:59,360 --> 00:06:02,240
Okay, so use projection mapping.

112
00:06:02,240 --> 00:06:03,520
What's projection mapping?

113
00:06:03,520 --> 00:06:08,040
Where you take some complicated edifice and you map all of its planes and then you actually

114
00:06:08,040 --> 00:06:12,440
project some unbelievable graphics, reskinning a building, let's say, at night.

115
00:06:12,440 --> 00:06:13,440
That's right.

116
00:06:13,440 --> 00:06:14,440
Yeah.

117
00:06:14,440 --> 00:06:15,440
Okay, so you want to do some graffiti art with light?

118
00:06:15,440 --> 00:06:16,680
You basically want to hack the system.

119
00:06:16,680 --> 00:06:17,680
No, I'm saying...

120
00:06:17,680 --> 00:06:19,680
Look, listen to me, Len.

121
00:06:19,680 --> 00:06:21,880
We're smarter than they are.

122
00:06:21,880 --> 00:06:22,880
And they...

123
00:06:22,880 --> 00:06:23,880
You know what they say?

124
00:06:23,880 --> 00:06:27,320
They say things like, I think we need some geeks.

125
00:06:27,320 --> 00:06:29,240
Get me two PhDs.

126
00:06:29,240 --> 00:06:30,480
Right.

127
00:06:30,480 --> 00:06:32,240
You treat PhDs like that.

128
00:06:32,240 --> 00:06:39,320
That's a bad move, because PhDs are capable and we act like our job is to peel grapes

129
00:06:39,320 --> 00:06:40,320
for our betters.

130
00:06:40,320 --> 00:06:46,280
Yeah, that's a strange thing and you speak about it very eloquently is how we treat

131
00:06:46,280 --> 00:06:54,680
basically the greatest minds in the world, which is like at the prime, which is PhD students.

132
00:06:54,680 --> 00:06:57,960
We pay them nothing.

133
00:06:57,960 --> 00:06:58,960
I'm done with it.

134
00:06:58,960 --> 00:06:59,960
Yeah.

135
00:06:59,960 --> 00:07:00,960
Right?

136
00:07:00,960 --> 00:07:01,960
We got to take what's ours.

137
00:07:02,680 --> 00:07:03,680
Yeah.

138
00:07:03,680 --> 00:07:10,160
Take back MIT, become ungovernable, become ungovernable.

139
00:07:10,160 --> 00:07:15,680
And by the way, when you become ungovernable, don't do it by throwing food.

140
00:07:15,680 --> 00:07:19,160
Don't do it by pouring salt on the lawn like a jerk.

141
00:07:19,160 --> 00:07:24,680
Do it through brilliance, because what you Caltech and MIT can do, and maybe Rensselaer

142
00:07:24,680 --> 00:07:29,960
Polytechnic or Worcester Polytech, I don't know, Lehigh, God damn it, what's wrong with

143
00:07:29,960 --> 00:07:31,120
you technical people?

144
00:07:31,120 --> 00:07:34,200
You act like you're a servant class.

145
00:07:34,200 --> 00:07:39,320
It's unclear to me how you reclaim it, except with brilliance, like you said.

146
00:07:39,320 --> 00:07:43,320
But to me, that the way you reclaim it with brilliance is to go outside the system.

147
00:07:43,320 --> 00:07:48,960
Aaron Schwartz came from the Elon Musk class, what you guys are going to do about it, right?

148
00:07:48,960 --> 00:07:55,080
The super capable people need to flex, need to be individual, they need to stop giving

149
00:07:55,080 --> 00:08:00,120
away all their power to a zeitgeist or a community or this or that.

150
00:08:00,120 --> 00:08:03,000
You're not indoor cats, you're outdoor cats, go be outdoor cats.

151
00:08:03,000 --> 00:08:05,000
Do you think we're going to see this kind of change happen?

152
00:08:05,000 --> 00:08:09,040
You were the one asking me before, like what about the World War II generation?

153
00:08:09,040 --> 00:08:13,480
What I'm trying to say is that there's a technical revolt coming.

154
00:08:13,480 --> 00:08:14,480
You want to talk about this?

155
00:08:14,480 --> 00:08:15,480
But I'm trying to lead it.

156
00:08:15,480 --> 00:08:16,480
Really?

157
00:08:16,480 --> 00:08:17,480
I'm trying to see.

158
00:08:17,480 --> 00:08:18,480
No, you're not trying to lead it.

159
00:08:18,480 --> 00:08:19,480
I'm trying to get a blueprint here.

160
00:08:19,480 --> 00:08:20,480
All right, Lex.

161
00:08:20,480 --> 00:08:21,480
Yeah.

162
00:08:21,480 --> 00:08:26,120
How angry are you about our country pretending that you and I can't actually do technical

163
00:08:26,120 --> 00:08:32,440
subjects so that they need an army of kids coming in from four countries in Asia?

164
00:08:32,440 --> 00:08:35,960
It's not about the four countries in Asia, it's not about those kids.

165
00:08:35,960 --> 00:08:40,240
It's about lying about us, that we don't care enough about science and technology, that

166
00:08:40,240 --> 00:08:47,280
we're incapable of it, as if we don't have Chinese and Russians and Koreans and Croatians.

167
00:08:47,280 --> 00:08:49,480
We've got everybody here.

168
00:08:49,480 --> 00:08:53,720
The only reason you're looking outside is that you want to hire cheap people from the

169
00:08:53,720 --> 00:08:57,720
family business because you don't want to pass the family business on.

170
00:08:57,720 --> 00:08:59,320
You know what?

171
00:08:59,320 --> 00:09:01,320
You didn't really build the family business.

172
00:09:01,320 --> 00:09:03,600
It's not yours to decide.

173
00:09:03,600 --> 00:09:07,860
You the boomers and you the silent generation, you did your bit, but you also fouled a lot

174
00:09:07,860 --> 00:09:11,680
of stuff up and you're custodians.

175
00:09:11,680 --> 00:09:12,880
You are caretakers.

176
00:09:12,880 --> 00:09:14,600
You were supposed to hand something.

177
00:09:14,600 --> 00:09:20,400
What you did instead was to gorge yourself on cheap foreign labor, which you then held

178
00:09:20,400 --> 00:09:24,960
up as being much more brilliant than your own children, which was never true.

179
00:09:24,960 --> 00:09:32,080
See, but I'm trying to understand how we create a better system without anger, without revolution.

180
00:09:32,080 --> 00:09:38,160
Not by kissing and hugs.

181
00:09:38,160 --> 00:09:43,040
I don't understand within MIT what the mechanism of building a better MIT is.

182
00:09:43,040 --> 00:09:44,720
We're not going to pay all severe.

183
00:09:44,720 --> 00:09:46,000
Aaron Schwartz was right.

184
00:09:46,000 --> 00:09:48,640
JSTOR is an abomination.

185
00:09:49,280 --> 00:09:55,040
Who within MIT, who within institutions is going to do that when, just like you said,

186
00:09:55,040 --> 00:09:57,560
the people who are running the show are more senior.

187
00:09:57,560 --> 00:09:58,560
I don't know.

188
00:09:58,560 --> 00:10:01,560
Did Frank Wilczek just speak out?

189
00:10:01,560 --> 00:10:04,420
So you're basically individuals that step up.

190
00:10:04,420 --> 00:10:10,080
One of the surprising things about Elon is that one person can inspire so much.

191
00:10:10,080 --> 00:10:11,400
He's got academic freedom.

192
00:10:11,400 --> 00:10:13,920
It just comes from money.

193
00:10:13,920 --> 00:10:16,920
I don't agree with that.

194
00:10:16,920 --> 00:10:17,920
You think money?

195
00:10:17,920 --> 00:10:18,920
Okay.

196
00:10:18,920 --> 00:10:19,920
So, yes.

197
00:10:19,920 --> 00:10:20,920
Certainly.

198
00:10:20,920 --> 00:10:21,920
Sorry.

199
00:10:21,920 --> 00:10:22,920
And testicles.

200
00:10:22,920 --> 00:10:23,920
Yes.

201
00:10:23,920 --> 00:10:28,920
But I think that testicles is more important than money or guts.

202
00:10:28,920 --> 00:10:30,440
I do agree with you.

203
00:10:30,440 --> 00:10:34,300
You speak about this a lot that because the money in the academic institutions has been

204
00:10:34,300 --> 00:10:39,840
so constrained that people are misbehaving and horrible.

205
00:10:39,840 --> 00:10:44,520
But I don't think that if we reverse that and give a huge amount of money, people will

206
00:10:44,520 --> 00:10:45,600
all of a sudden behave well.

207
00:10:45,600 --> 00:10:46,840
I think it also takes guts.

208
00:10:46,840 --> 00:10:48,400
No, you need to give people security.

209
00:10:48,400 --> 00:10:49,400
Security, yes.

210
00:10:49,400 --> 00:10:55,960
Like, you need to know that you have a job on Monday when on Friday you say, I'm not

211
00:10:55,960 --> 00:10:59,320
so sure I really love diversity and inclusion.

212
00:10:59,320 --> 00:11:01,080
And somebody's like, wait, what?

213
00:11:01,080 --> 00:11:02,560
You didn't love diversity?

214
00:11:02,560 --> 00:11:05,240
We had a statement on diversity and you wouldn't sign?

215
00:11:05,240 --> 00:11:08,240
Are you against the inclusion part or are you against diversity?

216
00:11:08,240 --> 00:11:09,960
Do you just not like people like you?

217
00:11:09,960 --> 00:11:13,160
You're like, actually, that has nothing to do with anything.

218
00:11:13,160 --> 00:11:15,080
You're making this into something that it isn't.

219
00:11:15,080 --> 00:11:20,000
I don't want to sign your goddamn stupid statement and get out of my lab.

220
00:11:20,000 --> 00:11:21,120
Get out of my lab.

221
00:11:21,120 --> 00:11:23,160
It all begins from the middle finger.

222
00:11:23,160 --> 00:11:25,600
Get out of my lab.

223
00:11:25,600 --> 00:11:28,800
The administrators need to find other work.

224
00:11:28,800 --> 00:11:29,800
Yeah.

225
00:11:29,800 --> 00:11:38,040
Listen, I agree with you and I hope to seek your advice and wisdom as we change this because

226
00:11:38,040 --> 00:11:39,040
I'd love to see.

227
00:11:39,040 --> 00:11:43,480
I will visit you in prison if that's what you're asking.

228
00:11:43,480 --> 00:11:45,120
I think prison is great.

229
00:11:45,120 --> 00:11:49,280
You get a lot of reading done and good working out.

230
00:11:49,280 --> 00:11:57,160
Well, let me ask something I brought up before is the Nietzsche quote of, beware that when

231
00:11:57,160 --> 00:12:01,440
fighting monsters, you yourself do not become a monster for when you gaze long into the

232
00:12:01,440 --> 00:12:05,360
abyss, the abyss gazes into you.

233
00:12:05,360 --> 00:12:09,240
Are you worried that your focus on the flaws in the system that we've just been talking

234
00:12:09,240 --> 00:12:15,320
about has damaged your mind or the part of the mind of your mind that's able to see the

235
00:12:15,320 --> 00:12:19,560
beauty in the world in the system?

236
00:12:19,560 --> 00:12:26,560
Because you have so sharply been able to see the flaws in the system, you can no longer

237
00:12:26,560 --> 00:12:28,480
step back and appreciate its beauty.

238
00:12:28,480 --> 00:12:34,600
Look, I'm the one who's trying to get the institutions to save themselves by getting

239
00:12:34,600 --> 00:12:40,360
rid of their inhabitants, but leaving the institution like a neutron bomb that removes

240
00:12:40,360 --> 00:12:45,560
the unworkable leadership class, but leaves the structures.

241
00:12:45,560 --> 00:12:48,320
So the leadership class is really the problem.

242
00:12:48,320 --> 00:12:49,320
The leadership class is the problem.

243
00:12:49,320 --> 00:12:51,960
But the individual like the professors, the individual scholars.

244
00:12:51,960 --> 00:12:58,200
The professors are going to have to go back into training to remember how to be professors.

245
00:12:58,200 --> 00:13:02,280
People are cowards at the moment because if they're not cowards, they're unemployed.

246
00:13:03,240 --> 00:13:07,880
Yeah, that's one of the disappointing things I've encountered is, to me, tenure.

247
00:13:09,400 --> 00:13:11,000
But nobody has tenure now.

248
00:13:14,040 --> 00:13:23,640
Whether they do or not, they certainly don't have the kind of character and fortitude that I was

249
00:13:23,640 --> 00:13:25,880
hoping to see.

250
00:13:25,880 --> 00:13:26,600
But they'd be gone.

251
00:13:26,840 --> 00:13:33,880
But you're dreaming about the people who used to live at MIT.

252
00:13:36,040 --> 00:13:39,320
You're dreaming about the previous inhabitants of your university.

253
00:13:40,120 --> 00:13:46,760
And if you looked at somebody like Isidore Singer is very old, I don't know what state he's in,

254
00:13:46,760 --> 00:13:49,400
but that guy was absolutely the real deal.

255
00:13:49,400 --> 00:13:53,560
And if you look at Noam Chomsky, tell me that Noam Chomsky has been muzzled.

256
00:13:54,600 --> 00:13:55,160
Right?

257
00:13:55,160 --> 00:13:55,400
Yeah.

258
00:13:56,040 --> 00:14:01,080
Now, what I'm trying to get at is you're talking about younger, energetic people.

259
00:14:01,080 --> 00:14:08,200
But those people, like when I say something like, I'm against, I'm for inclusion and I'm

260
00:14:08,200 --> 00:14:13,480
for diversity, but I'm against diversity and inclusion, TM, like the movement.

261
00:14:15,320 --> 00:14:17,320
Well, I couldn't say that if I was a professor.

262
00:14:19,240 --> 00:14:21,800
Oh my God, he's against our sacred document.

263
00:14:21,800 --> 00:14:26,840
Okay. Well, in that kind of a world, do you want to know how many things I don't agree with you

264
00:14:26,840 --> 00:14:27,480
on?

265
00:14:27,480 --> 00:14:31,640
Like we could go on for days and days and days, all of the nonsense that you've parroted

266
00:14:31,640 --> 00:14:32,920
inside of the institution.

267
00:14:33,800 --> 00:14:36,200
Any sane person has no need for it.

268
00:14:36,200 --> 00:14:38,200
They have no want or desire.

269
00:14:40,520 --> 00:14:43,640
Do you think you have to have some patience for nonsense

270
00:14:44,680 --> 00:14:47,240
when many people work together in a system?

271
00:14:47,240 --> 00:14:50,200
How long has string theory gone on for and how long have I been patient?

272
00:14:51,080 --> 00:14:53,240
Okay, so you're talking about, there's a limit to patience.

273
00:14:53,240 --> 00:14:57,880
You're talking about like 36 years of modern nonsense in string theory.

274
00:14:57,880 --> 00:15:00,760
So you can do like eight to 10 years, but not more.

275
00:15:00,760 --> 00:15:02,440
I can do 40 minutes.

276
00:15:04,360 --> 00:15:05,080
This is 36 years.

277
00:15:05,080 --> 00:15:06,840
Well, you've done that over two hours already.

278
00:15:06,840 --> 00:15:08,280
No, but I appreciate it.

279
00:15:08,280 --> 00:15:13,880
But it's been 36 years of nonsense since the anomaly cancellation in string theory.

280
00:15:13,880 --> 00:15:16,680
It's like, what are you talking about about patience?

281
00:15:16,680 --> 00:15:19,800
I mean, Lex, you're not even acting like yourself.

282
00:15:21,000 --> 00:15:23,480
Well, you're trying to stay in the system.

283
00:15:23,480 --> 00:15:32,600
I'm not trying to see if perhaps, so my hope is that the system just has a few assholes in it,

284
00:15:32,600 --> 00:15:38,520
which you highlight and the fundamentals of the system are broken.

285
00:15:38,520 --> 00:15:41,640
Because if the fundamentals of the systems are broken,

286
00:15:41,640 --> 00:15:44,680
then I just don't see a way for MIT to succeed.

287
00:15:45,640 --> 00:15:50,120
Like, I don't see how young people take over MIT.

288
00:15:50,120 --> 00:15:50,760
I don't see how...

289
00:15:52,760 --> 00:15:54,040
By inspiring us.

290
00:15:55,320 --> 00:15:57,560
You know, the great part about being at MIT,

291
00:15:58,280 --> 00:16:04,040
like when you saw the genius in these pranks, the heart, the irreverence.

292
00:16:06,040 --> 00:16:08,120
And we were talking about Tom Lehrer the last time.

293
00:16:08,680 --> 00:16:11,560
Tom Lehrer was as naughty as the day is long.

294
00:16:11,560 --> 00:16:12,280
Agreed?

295
00:16:12,280 --> 00:16:13,160
Agreed.

296
00:16:13,160 --> 00:16:14,600
Was he also a genius?

297
00:16:14,600 --> 00:16:15,640
Was he well-spoken?

298
00:16:15,640 --> 00:16:16,920
Was he highly cultured?

299
00:16:17,720 --> 00:16:22,680
He was so talented, so intellectual that he could just make fart jokes morning, noon, and night.

300
00:16:22,680 --> 00:16:23,320
Yeah.

301
00:16:23,320 --> 00:16:23,560
Okay.

302
00:16:24,280 --> 00:16:29,640
Well, in part, the right to make fart jokes, the right to, for example, put a functioning phone

303
00:16:29,640 --> 00:16:35,400
booth that was ringing on top of the great dome at MIT has to do with, we are such bad asses that

304
00:16:35,400 --> 00:16:36,760
we can actually do this stuff.

305
00:16:37,720 --> 00:16:39,640
Well, don't tell me about it anymore.

306
00:16:39,640 --> 00:16:40,600
Go break the law.

307
00:16:41,560 --> 00:16:46,040
Go break the law in a way that inspires us and makes us not want to prosecute you.

308
00:16:46,600 --> 00:16:50,920
Break the law in a way that lets us know that you're calling us out on our bullshit,

309
00:16:50,920 --> 00:16:57,160
that you're filled with love, and that our technical talent has not gone to sleep.

310
00:16:57,160 --> 00:16:58,360
It's not incapable.

311
00:16:59,080 --> 00:17:03,400
You know, and if the idea is, is that you're going to dig a moat around the university and

312
00:17:03,400 --> 00:17:08,840
fill it with tiger sharks, that's awesome, because I don't know how you're going to do it.

313
00:17:08,840 --> 00:17:14,600
But if you actually manage to do that, I'm not going to prosecute you under a reckless endangerment.

314
00:17:16,120 --> 00:17:17,080
That's beautifully put.

315
00:17:17,960 --> 00:17:19,960
I hope those, first of all, they'll listen.

316
00:17:20,680 --> 00:17:23,960
I hope young people at MIT will take over in this kind of way.

317
00:17:25,000 --> 00:17:33,240
In the introduction to your podcast episode on Jeff Epstein, you give to me a really moving

318
00:17:33,240 --> 00:17:40,120
story, but unfortunately for me, too brief about your experience with a therapist and

319
00:17:40,120 --> 00:17:47,400
the lasting terror that permeated your mind. Can you, can you go there? Can you tell?

320
00:17:48,040 --> 00:17:52,440
No, thanks. I mean, I appreciate what you're saying. I said it obliquely. I said enough.

321
00:17:54,680 --> 00:18:01,960
There are bad people who cross our paths, and the current vogue is to say, oh, I'm a survivor.

322
00:18:03,960 --> 00:18:07,080
I'm a victim. I can do anything I want.

323
00:18:08,440 --> 00:18:13,400
This is a broken person, and I don't know why I was sent to a broken person as a kid.

324
00:18:13,960 --> 00:18:18,920
And to be honest with you, I also felt like in that story, I say that I was able to say no,

325
00:18:19,720 --> 00:18:22,440
you know, and this was like the entire weight of authority.

326
00:18:23,720 --> 00:18:29,480
And he was misusing his position, and I was also able to say no.

327
00:18:29,800 --> 00:18:35,080
No. What I couldn't say no to was having him re-inflicted in my life.

328
00:18:36,280 --> 00:18:41,080
Right, so you were sent back a second time. I tried to complain about what had happened,

329
00:18:41,080 --> 00:18:48,760
and I tried to do it in a way that did not immediately cause horrific consequences to

330
00:18:48,760 --> 00:18:57,640
both this person and myself, because we don't have the tools to deal with sexual misbehavior.

331
00:18:58,200 --> 00:19:05,240
We have nuclear weapons. We don't have any way of saying this is probably not a good place

332
00:19:05,240 --> 00:19:11,640
or a role for you at this moment as an authority figure, and something needs to be worked on.

333
00:19:11,640 --> 00:19:19,000
So in general, when we see somebody who is misbehaving in that way, our immediate instinct

334
00:19:19,000 --> 00:19:27,240
is to treat the person as, you know, Satan. And we understand why we don't want our children

335
00:19:27,240 --> 00:19:36,120
to be at risk. Now, I personally believe that I fell down on the job and did not call out the

336
00:19:36,120 --> 00:19:41,000
Jeffrey Epstein thing early enough because I was terrified of what Jeffrey Epstein represents,

337
00:19:41,000 --> 00:19:47,320
and this recapitulated the old terror trying to tell the world this therapist is out of control.

338
00:19:48,040 --> 00:19:53,400
And when I said that, the world responded by saying, well, you have two appointments booked,

339
00:19:53,400 --> 00:19:56,920
and you have to go for the second one. So I got reinflicted into this

340
00:19:58,040 --> 00:20:02,120
office on this person who was now convinced that I was about to tear down his career and his

341
00:20:02,120 --> 00:20:05,080
reputation. It might have been on the verge of suicide for all I know. I don't know.

342
00:20:06,040 --> 00:20:11,400
But he was very, very angry, and he was furious with me that I had breached a sacred confidence

343
00:20:11,400 --> 00:20:17,960
of his office. What kind of ripple effects has that had to the rest of your life,

344
00:20:19,240 --> 00:20:24,360
the absurdity and the cruelty of that? I mean, there's no sense to it.

345
00:20:26,120 --> 00:20:29,560
Well, see, this is the thing people don't really grasp, I think.

346
00:20:29,560 --> 00:20:40,440
There's an academic who I got to know many years ago named Jennifer Fried, who has a theory of

347
00:20:41,400 --> 00:20:46,840
betrayal, which she calls institutional betrayal. And her gambit is that when you were betrayed by

348
00:20:46,840 --> 00:20:53,480
an institution that is sort of like a fiduciary or a parental obligation to take care of you,

349
00:20:54,440 --> 00:21:00,360
that you find yourself in a far different situation with respect to trauma than if you

350
00:21:00,360 --> 00:21:08,040
were betrayed by somebody who's a peer. And so I think that in my situation,

351
00:21:10,280 --> 00:21:19,720
I kind of repeat a particular dynamic with authority. I come in not following all the rules,

352
00:21:19,880 --> 00:21:26,120
trying to do some things, not trying to do others, blah, blah, blah. And then I get into a weird

353
00:21:26,120 --> 00:21:30,920
relationship with authority. And so I have more experience with what I would call institutional

354
00:21:30,920 --> 00:21:40,680
betrayal. Now, the funny part about it is that when you don't have masks or PPE in a influenza-like

355
00:21:40,680 --> 00:21:47,720
pandemic, and you're missing ICU beds and ventilators, that is ubiquitous institutional

356
00:21:48,520 --> 00:21:55,080
betrayal. So I believe that in a weird way, I was very early. The idea of, and this is like

357
00:21:55,640 --> 00:22:02,600
the really hard concept, pervasive or otherwise universal institutional betrayal,

358
00:22:02,600 --> 00:22:07,960
where all of the institutions, you can count on any hospital to not charge you properly for

359
00:22:07,960 --> 00:22:13,640
where their services are. You can count on no pharmaceutical company to produce the drug that

360
00:22:13,640 --> 00:22:19,960
will be maximally beneficial to the people who take it. You know that your financial professionals

361
00:22:19,960 --> 00:22:25,640
are not simply working in your best interests. And that issue had to do with the way in which

362
00:22:25,640 --> 00:22:31,400
growth left our system. So I think that the weird thing is, is that this first institutional

363
00:22:31,400 --> 00:22:37,400
betrayal by a therapist left me very open to the idea of, okay, well, maybe the schools are bad,

364
00:22:37,400 --> 00:22:41,800
maybe the hospitals are bad, maybe the drug companies are bad, maybe our food is off,

365
00:22:41,800 --> 00:22:47,880
maybe our journalists are not serving journalistic ends. And that was what allowed me to sort of go

366
00:22:47,880 --> 00:22:54,280
all the distance and say, huh, I wonder if our problem is that something is causing all of our

367
00:22:54,280 --> 00:23:01,240
sense-making institutions to be off. That was the big insight. And tying that to a single etiology,

368
00:23:02,200 --> 00:23:07,240
what if it's just about growth? They were all built on growth, and now we've promoted people who

369
00:23:07,240 --> 00:23:13,320
are capable of keeping quiet that their institutions aren't working. So the privileged

370
00:23:14,280 --> 00:23:20,280
silent aristocracy, the people who can be counted upon not to mention a fire when a raging fire

371
00:23:20,280 --> 00:23:27,800
is tearing through a building. But nevertheless, how big of a psychological burden is that?

372
00:23:28,520 --> 00:23:34,520
It's huge. It's terrible. It's crushing. It's very comforting to be the parental,

373
00:23:35,080 --> 00:23:43,640
I mean, I don't know, I treasure, I mean, we were just talking about MIT. I can intellectualize

374
00:23:43,640 --> 00:23:48,440
and agree with everything you're saying, but there's a comfort, a warm blanket of being within the

375
00:23:48,440 --> 00:23:55,480
institution. And up until Aaron Schwartz, let's say. In other words, now, if I look at

376
00:23:56,040 --> 00:24:00,760
the provost and the president as mommy and daddy, you did what to my big brother?

377
00:24:01,080 --> 00:24:11,240
You did what to our family? You sold us out in which way? What secrets left for China?

378
00:24:11,800 --> 00:24:18,200
You hired which workforce? You did what to my wages? You took this portion of my grant for what

379
00:24:18,200 --> 00:24:24,120
purpose? You just stole my retirement through a fringe rate. What did you do? But can you still,

380
00:24:24,120 --> 00:24:31,320
I mean, the thing is about this view you have, is it often turns out to be sadly correct?

381
00:24:31,320 --> 00:24:36,360
Well, this is the thing. But let me just, in this silly, hopeful thing,

382
00:24:37,400 --> 00:24:42,040
do you still have hope in institutions? Can you within your, psychologically?

383
00:24:42,040 --> 00:24:47,480
Yes. I'm referring not intellectually, because you have to carry this burden. Can you still have

384
00:24:47,480 --> 00:24:55,080
a hope like within you? When you sit at home alone, and as opposed to seeing the darkness

385
00:24:55,080 --> 00:25:00,200
within these institutions, seeing a hope. Well, but this is the thing I want to confront,

386
00:25:01,640 --> 00:25:08,200
not for the purpose of a dust-up. I believe, for example, if you've heard episode 19,

387
00:25:08,200 --> 00:25:15,720
that the best outcome is for Carol Greider to come forward as we discussed in episode 19.

388
00:25:15,800 --> 00:25:17,240
Would your brother, Brett, want to start an episode?

389
00:25:17,240 --> 00:25:23,160
And say, you know what? I screwed up. He did call. He did suggest the experiment.

390
00:25:23,800 --> 00:25:29,160
I didn't understand that it was his theory that was producing it. Maybe I was slow to grasp it.

391
00:25:30,280 --> 00:25:39,880
But my bad, and I don't want to pay for this bad choice on my part, let's say,

392
00:25:40,200 --> 00:25:44,760
for the rest of my career. I want to own up, and I want to help make sure that

393
00:25:46,200 --> 00:25:48,120
we do what's right with what's left.

394
00:25:48,120 --> 00:25:51,720
And that's one little case within the institution that you would like to see made?

395
00:25:51,720 --> 00:25:57,560
I would like to see MIT very clearly come out and say, you know, Margot O'Toole was right when

396
00:25:57,560 --> 00:26:06,120
she said David Baltimore's lab here produced some stuff that was not reproducible with

397
00:26:06,200 --> 00:26:13,160
Teresa Minishikari's research. I want to see the courageous people. I would like to see the

398
00:26:13,160 --> 00:26:19,560
Aaron Schwartz wing of the computer science department. Yeah, let's think about it.

399
00:26:20,440 --> 00:26:25,240
Wouldn't that be great if we said, you know, an injustice was done, and we're going to write

400
00:26:25,240 --> 00:26:31,160
that wrong just as if this was Alan Turing? Which I don't think they've righted that wrong.

401
00:26:31,720 --> 00:26:36,840
Well, then let's have the Turing Schwartz wing. The Turing Schwartz, they're starting a new

402
00:26:36,840 --> 00:26:40,280
college of computing. It wouldn't be wonderful to call it the Turing Schwartz.

403
00:26:40,280 --> 00:26:45,000
I would like to have the Madame Wu wing of the physics department, and I'd love to have the

404
00:26:45,000 --> 00:26:50,120
Emmy Nerder statue in front of the math department. I mean, like, you want to get excited about

405
00:26:50,120 --> 00:26:54,760
actual diversity and inclusion? Yeah. Well, let's go with our absolute best people who

406
00:26:54,760 --> 00:27:00,840
never got theirs because there is structural bigotry, you know? But if we don't actually

407
00:27:00,840 --> 00:27:05,800
start celebrating the beautiful stuff that we're capable of when we're handed heroes and we fumble

408
00:27:05,800 --> 00:27:15,160
them into the trash, what the hell? I mean, Lex, this is such nonsense. We're just pulling our head

409
00:27:16,680 --> 00:27:24,120
out. You know, on everyone's seekum should be tattooed. If you can read this, you're too close.

410
00:27:24,760 --> 00:27:35,160
Beautifully put, and I'm a dreamer just like you. So I don't see as much of the darkness

411
00:27:36,360 --> 00:27:43,720
genetically or due to my life experience, but I do share the hope. For my tea,

412
00:27:43,720 --> 00:27:48,520
the institution that we care a lot about. You both do. Yeah. And Harvard institution,

413
00:27:48,520 --> 00:27:53,880
I don't give a damn about, but you do. I love Harvard. I'm just kidding. I love Harvard,

414
00:27:53,880 --> 00:27:57,640
but Harvard and I have a very difficult relationship. And part of what, you know,

415
00:27:57,640 --> 00:28:04,440
when you love a family that isn't working, I don't want to trash. I didn't bring up the name of the

416
00:28:04,440 --> 00:28:11,960
president of MIT during the Aaron Schwartz period. It's not vengeance. I want the rot cleared out.

417
00:28:11,960 --> 00:28:18,840
I don't need to go after human beings. Yeah. Just like you said, with the disc formulation,

418
00:28:19,400 --> 00:28:23,720
the individual human beings don't necessarily carry them.

419
00:28:25,800 --> 00:28:31,160
It's those chairs that are so powerful that in which they sit. It's the chairs, not the humans.

420
00:28:31,160 --> 00:28:32,440
It's not the humans.

