{"text": " The following is a conversation with Marcus Hutter, senior research scientist at Google DeepMind. Throughout his career of research, including with J\u00f6rgen Schmidhuber and Shane Legg, he has proposed a lot of interesting ideas in and around the field of artificial general intelligence, including the development of IEXI, spelled AIXI model, which is the mathematical approach to AGI that incorporates ideas of Komogorov complexity, Solominov induction, and reinforcement learning. In 2006, Marcus launched the 50,000-euro Hutter prize for lossless compression of human knowledge. The idea behind this prize is that the ability to compress well is closely related to intelligence. This, to me, is a profound idea. Specifically, if you can compress the first 100 megabytes or one gigabyte of Wikipedia better than your predecessors, your compressor likely has to also be smarter. The intention of this prize is to encourage the development of intelligent compressors as a path to AGI. In conjunction with his podcast release just a few days ago, Marcus announced a 10x increase in several aspects of this prize, including the money, to 500,000 euros. The better your compressor works relative to the previous winners, the higher fraction of that prize money is awarded to you. You can learn more about it if you google simply Hutter prize. I'm a big fan of benchmarks for developing AI systems, and the Hutter prize may indeed be one that will spark some good ideas for approaches that will make progress on the path of developing AGI systems. This is the Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it 5 stars on Apple Podcasts, support it on Patreon, or simply connect with me on Twitter at Lex Freedman, spelled F-R-I-D-M-A-N. As usual, I'll do one or two minutes of ads now and never any ads in the middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the listening experience. This show is presented by Cash App, the number one finance app in the App Store. When you get it, use code LEX Podcast. Cash App lets you send money to friends, buy Bitcoin, and invest in the stock market with as little as $1. Broker services are provided by Cash App Investing, a subsidiary of Square, and member SIPC. Since Cash App allows you to send and receive money digitally, peer-to-peer, and security in all digital transactions very important, let me mention the PCI Data Security Standard that Cash App is compliant with. I'm a big fan of standards for safety and security. PCI DSS is a good example of that, where a bunch of competitors got together and agreed that there needs to be a global standard around the security of transactions. Now, we just need to do the same for autonomous vehicles and AI systems in general. So again, if you get Cash App from the App Store or Google Play and use the code LEX Podcast, you'll get $10 and Cash App will also donate $10 to FIRST, one of my favorite organizations that is helping to advance robotics and STEM education for young people around the world. And now, here's my conversation with Marcus Hodder. Do you think of the universe as a computer or maybe an information processing system? Let's go with a big question first. Okay, I have a big question first. I think it's a very interesting hypothesis or idea, and I have a background in physics, so I know a little bit about physical theories, the standard model of particle physics and general relativity theory, and they are amazing and describe virtually everything in the universe, and they're all in a sense, computable theories. I mean, they're very hard to compute, and it's very elegant, simple theories which describe virtually everything in the universe. So there's a strong indication that somehow the universe is computable, but it's a plausible hypothesis. So what do you think, just like you said, general relativity, quantum field theory, what do you think that the laws of physics are so nice and beautiful and simple and compressible? Do you think our universe was designed is naturally this way? Are we just focusing on the parts that are especially compressible? Are human minds just enjoying something about that simplicity and, in fact, there's other things that are not so compressible? No, I strongly believe and I'm pretty convinced that the universe is inherently beautiful elegant and simple and described by these equations, and we're not just picking that. I mean, if there were some phenomena which cannot be neatly described, scientists would try that, right? And, you know, there's biology which is more messy, but we understand that it's an emergent phenomena, and, you know, it's complex systems, but they still follow the same rules, right? Of quantum and electrodynamics, all of chemistry follows that, and we know that. I mean, we cannot compute everything because we have limited computational resources. No, I think it's not a bias of the humans, but it's objectively simple. I mean, of course, you never know, you know, maybe there's some corners very far out in the universe or super, super tiny below the nucleus of atoms or, well, parallel universes where which are not nice and simple, but there's no evidence for that, and we should apply Occam's razor and, you know, choose the simple streak consistent with it, but also it's a little bit self-referential. So maybe a quick pause. What is Occam's razor? So Occam's razor says that you should not multiply entities beyond necessity, which sort of if you translate it to proper English means, and, you know, in the scientific context means that if you have two theories or hypotheses or models which equally well describe the phenomenon you're studying or the data, you should choose the more simple one. So that's just a principle or sort of that's not like a provable law, perhaps, perhaps we'll kind of discuss it and think about it, but what's the intuition of why the simpler answer is the one that is likely to be more correct descriptor of whatever we're talking about? I believe that Occam's razor is probably the most important principle in science. I mean, of course, we need logical deduction and we do experimental design, but science is about finding understanding the world, finding models of the world, and we can come up with crazy complex models which, you know, explain everything but predict nothing, but the simple model seemed to have predictive power, and it's a valid question why. And the two answers to that, you can just accept that as the principle of science, and we use this principle and it seems to be successful. We don't know why, but it just happens to be. Or you can try, you know, find another principle which explains Occam's razor. And if we start with assumption that the world is governed by simple rules, then there's a bias to our simplicity, and applying Occam's razor is the mechanism to finding these rules. And actually, in a more quantitative sense, and we come back to that later in case of somnambular deduction, you can rigorously prove that you assume that the world is simple, then Occam's razor is the best you can do in a certain sense. So, I apologize for the romanticized question, but why do you think outside of its effectiveness, why do we do you think we find simplicity so appealing as human beings? Why does it just, why does E equals MC squared seem so beautiful to us humans? I guess mostly, in general, many things can be explained by an evolutionary argument. And, you know, there's some artifacts in humans which, you know, are just artifacts and not an evolutionary necessary. But with this beauty and simplicity, it's, I believe, at least the core is about, like science, finding regularities in the world, understanding the world, which is necessary for survival, right? You know, if I look at a bush, right, and I just see noise, and there is a tiger, right, and eats me, then I'm dead. But if I try to find a pattern, and we know that humans are prone to find more patterns in data than they are, you know, like, you know, Mars face and all these things, but these bias towards finding patterns, even if they are not, but I mean, it's best, of course, if they are, yeah, helps us for survival. Yeah, that's fascinating. I haven't thought really about the, I thought I just loved science, but indeed, from in terms of just for survival purposes, there is an evolutionary argument for why we find the work of Einstein so beautiful. Maybe a quick small tangent, could you describe what Solomon of induction is? Yeah, so that's a theory which I claim, and Resolominov sort of claimed a long time ago, that this solves the big philosophical problem of induction. And I believe the claim is essentially true. And what it does is the following. So, okay, for the picky listener, induction can be interpreted narrowly and wildly narrow means inferring models from data. And widely means also then using these models for doing predictions or predictions also part of the induction. So I'm a little sloppy sort of with the terminology and maybe that comes from Resolominov, you know, being sloppy, maybe I shouldn't say that. He can't complain anymore. So let me explain a little bit this theory. In simple terms, so assume we have a data sequence, make it very simple, the simplest one say 111111 and you see if 100 ones, what do you think comes next? The natural answer, I'm going to speed up a little bit, the natural answer is of course, you know, one. Okay, and the question is why? Okay, well, we see a pattern there. Yeah, okay, there's a one and we repeat it. And why should it suddenly after 100 ones be different? So what we're looking for is simple explanations or models for the data we have. And now the question is a model has to be presented in a certain language in which language to be used. In science, we want formal languages, and we can use mathematics, or we can use programs on a computer. So abstractly on a Turing machine, for instance, or can be a general purpose computer. So and there are of course, lots of models of you can say maybe it's 101 and then 100 zeros and 100 ones, that's a model, right? But they're simpler models, there's a model print one loop. Now that also explains the data. And if you push that to the extreme, you are looking for the shortest program, which if you run this program reproduces the data you have, it will not stop, it will continue naturally. And this you take for your prediction. And on the sequence of ones, it's very plausible, right, that print one loop is the shortest program, we can give some more complex examples like 12345. What comes next, the short program is again, you know, counter. And so that is, roughly speaking, how Solomar's induction works. The extra twist is that it can also deal with noisy data. So if you have, for instance, a coin flip, say a biased coin, which comes up head with 60% probability, then it will predict, it will learn and figure this out. And after a while, it predict or the next coin flip will be head with probability 60%. So it's the stochastic version of that. But the goal is the dream is always the search for the short program. Yes. Yeah. Well, in Solomar of induction, precisely what you do is, so you combine. So looking for the shortest program is like applying opax razor, like looking for the simplest theory. There's also Epicoros principle, which says, if you have multiple hypotheses, which equally well describe your data, don't discard any of them, keep all of them around, you never know. And you can put that together and say, okay, I have a bias towards simplicity, but I don't rule out the larger models. And technically, what we do is we weigh the shorter models higher and the longer models lower. And you use a Bayesian techniques, you have a prior, and which is precisely two to the minus the complexity of the program. And you weigh all this hypothesis and takes this mixture, and then you get also this stochasticity in. Yeah, like many of your ideas, that's just a beautiful idea of weighing based on the simplicity of the program. I love that. That seems to me maybe a very human-centric concept seems to be a very appealing way of discovering good programs in this world. You've used the term compression quite a bit. I think it's a beautiful idea, sort of, we just talked about simplicity, and maybe science or just all of our intellectual pursuits is basically the attempt to compress the complexity all around us into something simple. So what does this word mean to you, compression? I essentially have already explained it. So it compression means, for me, finding short programs for the data or the phenomenon at hand. You could interpret it more widely as finding simple theories, which can be mathematical theories, or maybe even informal, like just in words, compression means finding short descriptions, explanations, programs for the data. Do you see science as a kind of our human attempt at compression? So we're speaking more generally, because when you say programs, you're kind of zooming in on a particular, sort of, almost like a computer science, artificial intelligence focus. But do you see all of human endeavor as a kind of compression? Well, at least all of science, I see as an endeavor of compression, not all of humanity, maybe. And, well, there are also some other aspects of science, like experimental design, right? I mean, we create experiments specifically to get extra knowledge. And this is, that isn't part of the decision-making process. But once we have the data to understand the data is essentially compression. So I don't see any difference between compression, understanding, and prediction. So we're jumping around topics a little bit, but returning back to simplicity, a fascinating concept of comagra of complexity. So in your sense, do most objects in our mathematical universe have high comagra of complexity? And maybe what is, first of all, what is comagra of complexity? Okay, comagra of complexity is a notion of simplicity or complexity. And it takes the compression view to the extreme. So I explained before that if you have some data sequence, just think about a file on a computer and best sort of, you know, just a string of bits. And if you, and we have data compressors, like we compress big files into, say, zip files with certain compressors. And you can also produce self-extracting RKFs. That means as an executable, if you run it, it reproduces your original file without needing an extra decompressor. It's just a decompressor plus the RKF together in one. And now there are better and worse compressors. And you can ask, what is the ultimate compressor? So what is the shortest possible self-extracting RKF you could produce for a certain data set, which reproduces the data set. And the length of this is called the comagra of complexity. And arguably, that is the information content in the data set. I mean, if the data set is very redundant or very boring, you can compress it very well. So the information content should be low. And, you know, it is low according to this definition. Does the length of the shortest program that summarizes the data? Yes. Yeah. And what's your sense of our universe when we think about the different objects in our universe that we try concepts or whatever at every level? Do they have higher or low comagra of complexity? So what's the hope? Do we have a lot of hope in being able to summarize much of our world? That's a tricky and difficult question. So as I said before, I believe that the whole universe, based on the evidence we have, is very simple. So it has a very short description, the whole. Sorry to linger on that. The whole universe, what does that mean? Do you mean at the very basic fundamental level in order to create the universe? Yes. Yeah. So you need a very short program when you run it. To get the thing going. To get the thing going, and then it will reproduce our universe. There's a problem with noise. We can come back to that later, possibly. Is noise a problem or is it a bug or a feature? I would say it makes our life as a scientist really, really much harder. I mean, think about it without noise. We wouldn't need all of the statistics. But that maybe we wouldn't feel like there's a free will. Maybe we need that for the... This is an illusion that noise can give you free will. At least in that way, it's a feature. But also, if you don't have noise, you have chaotic phenomena, which are effectively like noise. So we can't get away with statistics even then. I mean, think about rolling a dice and forget about quantum mechanics and you know exactly how you throw it. But I mean, it's still so hard to compute the trajectory that, effectively, it is best to model it as coming out with a number, with probability one over six. But from this sort of philosophical Kolmogorov complexity perspective, if we didn't have noise, then arguably you could describe the whole universe as standard model plus generativity. I mean, we don't have a theory of everything yet, but sort of assuming we are close to it or have it here, plus the initial conditions, which may hopefully be simple. And then you just run it and then you would reproduce the universe. But that's spoiled by noise or by chaotic systems or by initial conditions, which may be complex. So now if we don't take the whole universe with just a subset, just take planet Earth. Planet Earth cannot be compressed into a couple of equations. This is a hugely complex system. So interesting. So when you look at the window, the whole thing might be simple, but when you just take a small window, then it may become complex. And that may be counterintuitive. But there's a very nice analogy, the book, the library of all books. So imagine you have a normal library with interesting books, and you go there, great. Lots of information and huge, quite complex. So now I create a library which contains all possible books, say, of 500 pages. So the first book just has AAA over all the pages. The next book AAA and ends with B. And so on. I create this library of all books. I can write a super short program which creates this library. So this library which has all books has zero information content. And you take a subset of this library and suddenly you have a lot of information in there. So that's fascinating. I think one of the most beautiful object, mathematical objects that at least today seems to be understudied or under talked about is cellular automata. What lessons do you draw from sort of the game of life for cellular automata, where you start with the simple rules, just like you're describing with the universe, and somehow complexity emerges. Do you feel like you have an intuitive grasp on the behavior, the fascinating behavior of such systems, where some, like you said, some chaotic behavior could happen, some complexity could emerge, some, it could die out in some very rigid structures. Do you have a sense about cellular automata that somehow transfers maybe to the bigger questions of our universe? Yeah, the cellular automata and especially the converse game of life is really great because this rule is so simple. You can explain it to every child and even by hand you can simulate a little bit. And you see this beautiful patterns emerge and people have proven that it's even touring complete. You cannot just use a computer to simulate game of life, but you can also use game of life to simulate any computer. That is truly amazing. And it's the prime example probably to demonstrate that very simple rules can lead to very rich phenomena. And people sometimes, you know, how can, how is chemistry and biology so rich? I mean, this can't be based on simple rules. But no, we know quantum electrodynamics describes all of chemistry. And we come later back to that. I claim intelligence can be explained or described in one single equation, this very rich phenomenon. You asked also about whether, you know, I understand this phenomenon and it's probably not. And this is saying you never understand really things, you just get used to them. And I think pretty used to cellular automata. So you believe that you understand now why this phenomenon happens. But I give you a different example. I didn't play too much this converse game of life, but a little bit more with fractals and with the Mandelbrot set. And you need beautiful, you know, patterns, just look Mandelbrot set. And well, when the computers were really slow and I just had a black and white monitor and programmed my own programs on an assembler too. Wow. Wow, you're legit to get these fractals on the screen. And it was mesmerized and much later. So I returned to this, you know, every couple of years. And then I tried to understand what is going on. And you can understand a little bit. So I tried to derive the locations, you know, there are these circles and the apple shape. And then you have smaller Mandelbrot sets recursively in this set. And there's a way to mathematically by solving high order polynomials to figure out where these centers are and what size they are approximately. And by sort of mathematically approaching this problem, you slowly get a feeling of why things are like they are. And that sort of isn't, you know, first step to understanding why this rich phenomenon. Do you think it's possible? What's your intuition? Do you think it's possible to reverse engineer and find the short program that generated the these fractals, sort of by what looking at the fractals? Well, in principle, yes. Yeah. So I mean, in principle, what you can do is you take, you know, any data set, you know, you take these fractals, or you take whatever your data set, whatever you have. So a picture of Conveys game of life. And you run through all programs, you take a program of size one, two, three, four, and all these programs around them all in parallel in so called dovetailing fashion, give them computational resources, first one 50%, second one half resources and so on and let them run, wait until they hold, give an output, compare it to your data. And if some of these programs produce the correct data, then you stop and then you have already some program, it may be a long program, because it's faster. And then you continue and you get shorter and shorter programs until you eventually find the shortest program. The interesting thing you can ever know whether it's a shortest program, because there could be an even shorter program, which is just even slower. And you just have to wait here. But asymptotically, and actually after the final time, you have the shortest program. So this is a theoretical, but completely impractical way of finding the underlying structure in every data set. And that was a lot more of induction does and Convogorov complexity. In practice, of course, we have to approach the problem more intelligently. And then if you take resource limitations into account, there's once the field of pseudo random numbers, yeah, and these are random numbers. So these are deterministic sequences, but no algorithm which is fast, fast means runs in polynomial time can detect that it's actually deterministic. So we can produce interesting, I mean, random numbers, maybe not that interesting, but just an example, we can produce complex looking data. And we can then prove that no fast algorithm can detect the underlying pattern. Which is unfortunately, that's a big challenge for our search for simple programs in the space of artificial intelligence, perhaps. Yes, it definitely is wanted vision intelligence. And it's quite surprising that it's, I can't say easy. I mean, physicists worked really hard to find these theories, but apparently it was possible for human minds to find these simple rules in the universe. It could have been different, right? It could have been different. It's, it's, it's awe inspiring. So let me ask another absurdly big question. What is intelligence in your view? So I have, of course, a definition. I wasn't sure what you're going to say, because you could have just as easy said, I have no clue. Which many people would say, but I'm not modest in this question. So the, the informal version, which I worked out together with Shane, like who co-founded the mind is that intelligence measures and agents ability to perform well in a wide range of environments. So that doesn't sound very impressive. And what it, these words have been very carefully chosen. And there is a mathematical theory behind that. And we come back to that later. And if you look at this, this definition by itself, it seems like, yeah, okay, but it seems a lot of things are missing. But if you think it's true, then you realize that most, and I claim all of the other traits, at least of rational intelligence, which we usually associate with intelligence, are emergent phenomena from this definition, like, you know, creativity, memorization, planning, knowledge. You all need that in order to perform well in a wide range of environments. So you don't have to explicitly mention that in a definition. Interesting. So yeah, so the consciousness, abstract reasoning, all these kinds of things are just emergent phenomena that help you in towards, can you say the definition again? So multiple environments. Did you mention the word goals? No, but we have an alternative definition instead of performing well, you can just replace it by goals. So intelligence measures and agents ability to achieve goals in a wide range of environments. That's more or less equal. But interesting, because in there, there's an injection of the word goals. So we want to specify there, there should be a goal. Yeah, but perform well is sort of, what does it mean? It's the same problem. There's a little bit gray area, but it's much closer to something that could be formalized. In your view, are humans, where do humans fit into that definition? Are they general intelligence systems that are able to perform in like, how good are they at fulfilling that definition at performing well in multiple environments? Yeah, that's a big question. I mean, the humans are performing best among all species on Earth. Species we know, we know of. Yeah. Depends. You could say that trees and plants are doing a better job. They'll probably outlast us. So yeah, but they are in a much more narrow environment, right? I mean, you just, you know, have a little bit of air pollution and these trees die and we can adapt, right? We build houses, we build filters, we do geo-engineering. So the multiple environment part. Yeah, that is very important, yes. So that distinguish narrow intelligence from wide intelligence, also in the AI research. So let me ask the alenturing question, can machines think? Can machines be intelligent? So in your view, I have to kind of ask, the answer is probably yes, but I want to kind of hear what your thoughts on it. Can machines be made to fulfill this definition of intelligence, to achieve intelligence? Well, we are sort of getting there and, you know, on a small scale, we are already there. The wide range of environments are missing, but we have self-driving cars, we have programs to play go and chess, we have speech recognition. So it's pretty amazing, but you can, you know, these are narrow environments. But if you look at AlphaZero, that was also developed by DeepMind. I mean, got famous with AlphaGo and then came AlphaZero a year later. That was truly amazing. So on reinforcement learning algorithm, which is able just by self-play to play chess and then also go. And I mean, yes, they're both games, but they're quite different games. And, you know, this, you didn't, don't feed them the rules of the game. And the most remarkable thing, which is still a mystery to me that usually for any decent chess program, I don't know much about Go, you need opening books and end game tables and so on, too. And nothing in there, nothing was put in there. Especially with AlphaZero, the self-play mechanism, starting from scratch, being able to learn actually new strategies. It really discovered, you know, all these famous openings within four hours by itself. What I was really happy about, I'm a terrible chess player, but I like Queen Gambi. And AlphaZero figured out that this is the best opening. Finally, somebody proved you correct. So yes, to answer your question, yes, I believe that general intelligence is possible. And it also depends how you define it. Do you say AGI with general intelligence, artificial intelligence, only refers to if you achieve human level or a sub-human level, but quite broad? Is it also general intelligence, so we have to distinguish or it's only super human intelligence, general artificial intelligence? Is there a test in your mind, like the Turing test for natural language or some other test that would impress the heck out of you, that would kind of cross the line of your sense of intelligence within the framework that you said? Well, the Turing test has been criticized a lot, but I think it's not as bad as some people think. And some people think it's too strong. So it tests not just for a system to be intelligent, but it also has to fake human deception. Disception, right? Which is, you know, much harder. And on the other hand, they say it's too weak because it's just maybe fakes, you know, emotions or intelligent behavior. It's not real. But I don't think that's the problem or big problem. So if you would pass the Turing test, so a conversation or a terminal with a bot for an hour, or maybe a day or so, and you can fool a human into, you know, not knowing whether this is a human or not, that it's the Turing test, I would be truly impressed. And we have this annual competition, the Lubna prize. And I mean, it started with Eliza, that was the first conversational program. And what is it called the Japanese Mitsuko or so, that's the winner of the last, you know, couple of years. And well, it's impressive. Yeah, it's quite impressive. And then Google has developed Mina, right? Just recently, that's an open domain conversational bot. Just a couple of weeks ago, I think. Yeah, I kind of like the metric that sort of the Alexa price has proposed. I mean, maybe it's obvious to you, it wasn't to me of setting sort of a length of a conversation. Like, you want the bot to be sufficiently interesting that you'd want to keep talking to it for like 20 minutes. And that's a surprisingly effective and aggregate metric. Because really, like, nobody has the patience to be able to talk to a bot that's not interesting and intelligent and witty and is able to go into different tangents, jump domains, be able to, you know, say something interesting to maintain your attention. Maybe many humans will also fail this test. Unfortunately, we set just like with autonomous vehicles with chatbots, we also set a bar that's way too hard to reach. I said, you know, the Turing test is not as bad as some people believe. But what is really not useful about the Turing test, it gives us no guidance how to develop these systems in the first place. Of course, you know, we can develop them by trial and error and, you know, do whatever and then run the test and see whether it works or not. But a mathematical definition of intelligence gives us, you know, an objective which we can then analyze by, you know, theoretical tools or computational and, you know, maybe even prove how close we are. And we will come back to that later with the ISE model. So I mentioned the compression, right? So in natural language processing, they have achieved amazing results. And one way to test this, of course, you know, take the system, you train it, and then you, you know, see how well it performs on the task. But a lot of performance measurement is done by so-called perplexity, which is essentially the same as complexity or compression length. So the NLP community develops new systems, and then they measure the compression length, and then they have ranking and leaks, because there's a strong correlation between compressing well, and then the systems performing well at the task at hand. It's not perfect, but it's good enough for them as an intermediate aim. So you mean measure, so this is kind of almost returning to the common growth complexity. So you're saying good compression usually means good intelligence. Yes. So you mentioned you're one of the, one of the only people who dared boldly to try to formalize the idea of artificial general intelligence, to have a mathematical framework for intelligence, just like as we mentioned, termed IEXI, A-I-X-I. So let me ask the basic question, what is IEXI? Okay, so let me first say what it stands for, because what it stands for, actually, that's probably the more basic question. The first question is usually how how it's pronounced, but finally I put it on the website, how it's pronounced, and you figured it out. Yeah. The name comes from AI, artificial intelligence, and the XI is the Greek letter XI, which are used for Solomonov's distribution for quite stupid reasons, which I'm not willing to repeat here in front of camera. So it does happen to be more or less arbitrary, I chose the XI, but it also has nice other interpretations. So there are actions and perceptions in this model, where an agent has actions and perceptions, and over time, so this is A-I-X-I, so there's an action at time I, and then followed by a perception at time I. We'll go with that. I'll edit out the first part. I'm just kidding. I have some more interpretations. So at some point, maybe five years ago or 10 years ago, I discovered in Barcelona, it was on a big church, there was a stone engraved, some text, and the word Aixi appeared there a couple of times. I was very surprised and happy about that, and I looked it up, so this is Catalan language, and it means with some interpretation, that's it, that's the right thing to do. Yeah, Heureka. Oh, so it's almost like destined, somehow came to you in a dream. And similar, there's a Chinese word, Aixi, also written like Aixi, if you transcribe that to Pingen. And the final one is that is A-I, crossed with induction, because that is, and that's going more to the content now. So good old fashioned A-I is more about planning a known deterministic world, and induction is more about often IID data and inferring models, and essentially, what this Aixi model does is combining these two. And I actually also recently, I think heard that in Japanese, A-I means love. So if you can combine X-I somehow with that, I think we can, there might be some interesting ideas there. So Aixi, let's then take the next step. Can you maybe talk at the big level of what is this mathematical framework? So it consists essentially of two parts. One is the learning and induction and prediction part. And the other one is the planning part. So let's come first to the learning induction prediction part, which essentially I explained already before. So what we need for any agent to act well is that it can somehow predict what happens. I mean, if you have no idea what your actions do, how can you decide which acts are good or not? So you need to have some model of what your actions effect. So what you do is you have some experience, you build models like scientists of your experience, then you hope these models are roughly correct, and then you use these models for prediction. And a model is, sorry to interrupt, and a model is based on your perception of the world, how your actions will affect that world. That's not the important part. It is technically important, but at this stage, we can just think about predicting, say, stock market data, whether data or IQ sequences, one, two, three, four, five, what comes next. Yeah. So of course, our actions affect what we're doing, but I'll come back to that in a second. So, and I'll keep just interrupting. So just to draw a line between prediction and planning. What do you mean by prediction in this way? It's trying to predict the environment without your long-term action in the environment. What is prediction? Okay. If you want to put the actions in now, okay, then let's put in them now. We don't have to put them now. Scratch it. Don't question. Okay. So the simplest form of prediction is that you just have data that you passively observe, and you want to predict what happens without, you know, interfering. As I said, weather forecasting, stock market, IQ sequences, or just anything. Okay. And Solominov's theory of induction based on compression. So you look for the shortest program which describes your data sequence. And then you take this program, run it, which reproduces your data sequence by definition, and then you let it continue running, and then it will produce some predictions. And you can rigorously prove that for any prediction task, this is essentially the best possible predictor. Of course, if there's a prediction task, or a task which is unpredictable, like, you know, your fair coin flips, yeah, I cannot predict the next fair coin, but what Solominov does is says, okay, next head is probably 50%. It's the best you can do. So if something is unpredictable, Solominov will also not magically predict it. But if there is some pattern and predictability, then Solominov induction will figure that out, eventually, and not just eventually, but rather quickly, and you can have proof convergence rates, whatever your data is. So there's pure magic in a sense. What's the catch? Well, the catch is that it's not computable. And we come back to that later. You cannot just implement it in even this Google resources here, and run it and, you know, predict the stock market and become rich. I mean, if it's raised Solominov already, you know, tried it at the time. But so the basic task is you're in the environment, and you're interacting with an environment to try to learn a model of that environment. And the model is in the space of these all these programs. And your goal is to get a bunch of programs that are simple. And so let's, let's go to the actions now. But actually, good that you asked usually, I skipped this part, although there is also a minor contribution, which I did. So the action part, but they usually sort of just jump to the decision part. So let me explain the action part now. Thanks for asking. So you have to modify it a little bit by now not just predicting a sequence which just comes to you, but you have an observation, then you act somehow. And then you want to predict the next observation based on the past observation and your action. Then you take the next action. You don't care about predicting it because you're doing it. And then you get the next observation. And you want, well, before you get it, you want to predict it again based on your past action and observation sequence. You just condition extra on your actions. There's an interesting alternative that you also try to predict your own actions. If you want. In the past or the future. Your future actions. That's interesting. Wait, let me wrap. I think my brain is broke. We should maybe discuss that later after I've explained the ICSE model. That's an interesting variation. But that is a really interesting variation. And a quick comment. I don't know if you want to insert that in here. But you're looking at that in terms of observations, you're looking at the entire big history, the long history of the observations. Exactly. That's very important, the whole history from birth sort of of the agent. And we can come back to that. Also why this is important here. Often, you know, in RL, you have MDPs, macro decision processes, which are much more limiting. Okay, so now we can predict conditioned on actions. So even if the influence environment. But prediction is not all we want to do, right? We also want to act really in the world. And the question is how to choose the actions. And we don't want to greedily choose the actions. You know, just, you know, what is best in the next time step. And we first I should say, you know, what is, you know, how do we measure performance? So we measure performance by giving the agent reward. That's the so called reinforcement learning framework. So every time step, you can give it a positive reward or negative reward, or maybe no reward, it could be a very scarce, right? Like if you play chess, just at the end of the game, you give plus one for winning or minus one for losing. So in the IXI framework, that's completely sufficient. So occasionally, you give a reward signal, and you ask the agent to maximize reward, but not greedily sort of, you know, the next one, next one, because that's very bad in the long run, if you're greedy. So, but over the lifetime of the agent. So let's assume the agent lives for M time steps as they dice in sort of 100 years sharp. That's just, you know, the simplest model to explain. So it looks at the future reward sum and ask what is my action sequence, or actually more precisely my policy, which leads in expectation, because I don't know the world, to the maximum reward sum. Let me give you an analogy. In chess, for instance, we know how to play optimally in theory, it's just a mini max strategy. I play the move which seems best to me under the assumption that the opponent plays the move which is best for him, so best, so worst for me, under the assumption that he I play again, the best move. And then you have this expecting max three to the end of the game. And then you back propagate and then you get the best possible move. So that is the optimal strategy, which for Neumann already figured out a long time ago, for playing adversarial games, luckily, or maybe unluckily, for the theory, it becomes harder that world is not always adversarial. So it can be, if the other humans even cooperative here, or nature is usually I mean, the dead nature is stochastic, you know, things just happen randomly, or don't care about you. So what you have to take into account is the noise, you know, and not necessarily adversariality. So you replace the minimum on the opponent's side by an expectation, which is general enough to include also adversarial cases. So now instead of a mini max strategy of an expecting max strategy. So far so good. So that is well known. It's called sequential decision theory. But the question is, on which probability distribution do you base that if I have the true probability distribution, like say I play beggining, right, there's dice, and there's certain randomness involved, yeah, I can calculate probabilities and feed it in the expecting max or the sequential decision tree, come up with the optimal decision if I have enough compute. But in the for the real world, we don't know that, you know, what is the probability the driver in front of me breaks. I don't know. Yeah, so depends on all kinds of things. And especially new situations, I don't know. So this is this unknown thing about prediction. And there's where Solomanov comes in. So what you do is in sequential decision tree, you just replace the true distribution, which we don't know, by this universal distribution, I didn't explicitly talk about it, but this is used for universal prediction, and plug it into the sequential decision tree mechanism. And then you get the best of both worlds. You have a long term planning agent. But it doesn't need to know anything about the world, because the Solomanov induction part learns. Can you explicitly try to describe the universal distribution and how Solomanov induction plays a role here? I'm trying to understand. So what he does it. So in the simplest case, I said, take the shortest program describing your data, run it, have a prediction which would be deterministic. Yes. Okay. But you should not just take the shortest program, but also consider the longer ones, but keep it lower a priori probability. So in the Bayesian framework, you say a priori, any distribution, which is a model, or a stochastic program has a certain a priori probability, which is two to the minus and y two to the minus length, you know, I could explain length of this program. So longer programs are punished, a priori. And then you multiply it with the so called likelihood function. Yeah, which is as the name suggests, is how likely is this model given the data at hand. So if you have a very wrong model, it's very unlikely that this model is true. And so it is very small numbers. So even if the model is simple, it gets penalized by that. And what you do is then you take just the sum, but this is the average over it. And this gives you a probability distribution. So universal distribution or Solomanov distribution. So it's weighed by the simplicity of the program and likelihood. Yes. It's kind of a nice idea. Yeah. So okay. And then you said there's your planning n or m or forgot the letter steps into the future. So how difficult is that problem? What's involved there? Okay, basic optimization problem? What are we talking about? Yeah, so you have a planning problem up to horizon m. And that's exponential time in the horizon m, which is, I mean, it's computable, but in fact, intractable. I mean, even for chess, it's already intractable to do that exactly. And, you know, for though, but it could be also discounted kind of framework where so, so having a hard horizon, you know, at 100 years, it's just for simplicity of discussing the model. And also sometimes the master simple. But there are lots of variations. Actually, quite interesting parameter is it's, there's nothing really problematic about it. But it's very interesting. So for instance, you think, no, let's, let's, let's, let's let the parameter m tend to infinity, right? You want an agent, which lives forever, right? If you do it now, you have two problems. First, the mathematics breaks down because you have an infinite reward sum, which may give infinity and getting reward 0.1 in the time step is infinity and giving reward one every time step is infinity. So equally good. Not really what we want. Other problem is that if you have an infinite life, you can be lazy for as long as you want for 10 years and then catch up with the same expected reward. And, you know, think about yourself or, you know, or maybe, you know, some friends or so, if they knew they lived forever, you know, why work hard now, you know, just enjoy your life, you know, and then catch up later. So that's another problem with the infinite horizon. And you mentioned, yes, we can go to discounting. But then the standard discounting is so-called geometric discounting. So a dollar today is about worth as much as, you know, $1.05 tomorrow. So if you do the so-called geometric discounting, you have introduced an effective horizon. So the agent is now motivated to look ahead a certain amount of time effectively. It's like a moving horizon. And for any fixed effective horizon, there is a problem to solve which requires larger horizons. So if I look ahead, you know, five time steps, I'm a terrible chess player, right? I'll need to look ahead longer. If I play go, I probably have to look ahead even longer. So for every problem, no, for every horizon, there is a problem which this horizon cannot solve. But I introduced the so-called near harmonic horizon, which goes down with one over t rather than exponentially t, which produces an agent which effectively looks into the future proportional to each age. So if it's five years old, it plans for five years. If it's 100 years old, it then plans for 100 years. And it's a little bit similar to humans, too, right? I mean, children don't plan ahead very long, but then we get adults, we play ahead more longer. Maybe when we get very old, I mean, we know that we don't live forever, you know, maybe then our horizon shrinks again. So that's really interesting. So adjusting the horizon, what is there some mathematical benefit of that? Or is it just a nice I mean, intuitively, empirically, it will probably be a good idea to sort of push the horizon back to extend the horizon as you experience more of the world. But is there some mathematical conclusions here that are beneficial? With Salomon's prediction part, we have extremely strong finite time, finite data results. So you have so and so much data, then you lose so and so much. So the deterioration is really great. With the IKC model with the planning part, many results are only asymptotic, which, well, this is what is asymptotic means you can prove, for instance, that in the long run, if the agent, you know, acts long enough, then, you know, it performs optimal or some nice thing happens. So but you don't know how fast it converges. Yeah, so it may converge fast, but we're just not able to prove it because a difficult problem. Or maybe there's a bug in the in the in the model so that it's really that slow. Yeah. So so that is what asymptotic means sort of eventually, but we don't know how fast. And if I give the agent a fixed horizon M, yeah, then I cannot prove asymptotic results, right? So I mean, sort of if it dies in 100 years, then in 100 years is over, I cannot say eventually. So this is the advantage of the discounting that I can prove asymptotic results. So just to clarify, so so I okay, I made I've built up a model with now in the moment of have this way of looking several steps ahead. How do I pick what action I will take? It's like with a playing chess, right, you do this mini max. In this case, here do you expect the max based on the solometer of distribution, you propagate back. And then, while an action falls out, the action which maximizes the future expected reward on the solometer of distribution, and then you just take this action, and then repeat. And then you get a new observation, and you feed it in this action observation, then you repeat and the reward so on. Yeah. So you wrote to you. And then maybe you can even predict your own action. I love the idea. But okay, this big framework. What is it? I mean, it's kind of a beautiful mathematical framework to think about artificial general intelligence. What can you, what does it help you into it about how to build such systems or maybe from another perspective? What does it help us in understanding AGI? So when I started in the field, I was always interested in two things. One was, you know, AGI. The name didn't exist then, what called general AI or strong AI. And the physics of everything. So I switched back and forth between computer science and physics quite often. You said the theory of everything. The theory of everything. It was basically the biggest problems before all humanity. Yeah, I can explain if you wanted some later time, you know, why I'm interested in these two questions. Can I ask you, in a small tangent, if, if, if one to be, it was one to be solved, which one would you, if one, if you were, if an apple fell in your head, and there was a brilliant insight and you could arrive at the solution to one, would it be AGI or the theory of everything? Definitely AGI, because once the AGI problem is solved, they can ask the AGI to solve the other problem for me. Yeah, brilliantly put. Okay. So, so as you were saying about it. Okay. So, and the reason why it didn't settle, I mean, this thought about, you know, once you have solved AGI, it solves all kinds of other, not just the theory of every problem, but all kinds of use, more useful problems to humanity is very appealing to many people. And, you know, I had this thought also, but I was quite disappointed with the state of the art of the field of AI. There was some theory, you know, about logical reasoning, but I was never convinced that this will fly. And then there was this more, more heuristic approaches with neural networks, and I didn't like these heuristics. So, and also I didn't have any good idea myself. So that's the reason why I toggled back and forth quite some while and even worked so four and a half years in a company developing software or something completely unrelated. But then I had this idea about the ICSE model. And so what it gives you, it gives you a gold standard. So I have proven that this is the most intelligent agents, which anybody could build built in quotation mark, because it's just mathematical and you need infinite compute. But this is the limit. And this is completely specified. It's not just a framework and, you know, every year, tens of frameworks are developed, which is just skeletons, and then pieces are missing. And usually these missing pieces, you know, turn out to be really, really difficult. And so this is completely and uniquely defined. And we can analyze that mathematically. And we've also developed some approximations, I can talk about that a little bit later, that would be sort of the top down approach, like, say, for Neumann's minimax theory, that's the theoretical optimal play of games. And now we need to approximate it, put heuristics in prune, the tree, blah, blah, blah, and so on. So we can do that also with the ICSE model, but for generally I, it can also inspire those. And most of most researchers go bottom upright, they have the systems that try to make it more general, more intelligent. It can inspire in which direction to go. What do you mean by that? So if you have some choice to make, right, so how should they evaluate my system if I can't do cross validation? How should they do my learning if my standard regularization doesn't work well? Yeah. So the answer is always this, we have a system which does everything that's ICSE. It's just, you know, completely in the ivory tower, completely useless from a practical point of view. But you can look at it and see, ah, yeah, maybe, you know, I can take some aspects and, you know, instead of Kolmogorov complexity, they just take some compressors which has been developed so far. And for the planning, well, we have UCT which has also, you know, been used in Go. And it, at least it's inspired me a lot to have this formal definition. And if you look at other fields, you know, like, I always come back to physics because I have a physics background, think about the phenomenon of energy that was long time a mysterious concept. And at some point, it was completely formalized. And that really helped a lot. And you can point out a lot of these things which were first mysterious and vague, and then they have been rigorously formalized. Speed and acceleration has been confused, right, until it was formally defined. There was a time like this. And people, you know, often, you know, don't have any background, you know, still confuse it. So, and this IXI model or the intelligence definitions, which is sort of the dual to it, we come back to that later, formalizes the notion of intelligence uniquely and rigorously. So in a sense, it serves as kind of the light at the end of the tunnel. Yes, yeah. So I mean, there's a million questions I could ask her. So maybe the kind of, okay, let's feel around in the dark a little bit. So there's been here a deep mind, but in general, been a lot of breakthrough ideas, just like we've been saying around reinforcement learning. So how do you see the progress in reinforcement learning is different? Like, which subset of IXI does it occupy the current, like you said, maybe the Markov assumption is made quite often in reinforcement learning. The, there's other assumptions made in order to make the system work. What do you see as the difference connection between reinforcement learning and IXI? And so the major difference is that essentially all other approaches, they make stronger assumptions. So in reinforcement learning, the Markov assumption is that the next state or next observation only depends on the on the previous observation and not the whole history, which makes, of course, the mathematics much easier rather than dealing with histories. Of course, they profit from it also, because then you have algorithms that run on current computers and do something practically useful. But for generally, I all the assumptions which are made by other approaches, we know already now they are limiting. So, for instance, usually you need a gothicity assumption in the MDP frameworks in order to learn. A gothicity essentially means that you can recover from your mistakes and that they are not traps in the environment. And if you make this assumption, then essentially you can go back to a previous state, go there a couple of times and then learn what, what statistics and what this state is like. And then in the long run perform well in this state. But there are no fundamental problems. But in real life, we know, there can be one single action, one second of being inattentive while driving a car fast, you know, can ruin the rest of my life, I can become quadruplegic or whatever. So, and there's no recovery anymore. So, the real world is not ergodic, I always say, you know, there are traps and there are situations where you're not recovered from. And very little theory has been developed for this case. What about what do you see in the context of IHC as the role of exploration, sort of, you mentioned, you know, in the real world and get into trouble when we make the wrong decisions and really pay for it. But exploration seems to be fundamentally important for learning about this world, for gaining new knowledge. So, is exploration baked in? Another way to ask it, what are the parameters of this of IHC that can be controlled? Yeah, I say the good thing is that there are no parameters to control. Some other people try knobs to control and you can do that. I mean, you can modify IHC so that you have some knobs to play with if you want to. But the exploration is directly baked in. And that comes from the Bayesian learning and the long term planning. So these together already imply exploration. You can nicely and explicitly prove that for simple problems like so-called banded problems, where you say to give a real-world example, say you have two medical treatments, A and B, you don't know the effectiveness, you try A a little bit, B a little bit, but you don't want to harm too many patients. So you have to sort of trade off exploring. And at some point you want to explore and you can do the mathematics and figure out the optimal strategy. It's called Bayesian agents, they're also non-Bayesian agents. But it shows that this Bayesian framework by taking a prior over possible worlds, doing the Bayesian mixture, then the Bayes optimal decision with long term planning that is important, automatically implies exploration also to the proper extent, not too much exploration and not too little. It is very simple settings. In the IHC model, I was also able to prove that it is a self-optimizing theorem or asymptotic optimality theorems, although they're only asymptotic, not finite time bounds. So it seems like the long term planning is a really important, the long term part of the planning is really important. And also, maybe a quick tangent, how important do you think is removing the Markov assumption and looking at the full history? So intuitively, of course, it's important, but is it like fundamentally transformative to the entirety of the problem? What's your sense of it? Because we all, we make that assumption quite often, just throwing away the past. Now, I think it's absolutely crucial. The question is whether there's a way to deal with it in a more heuristic and still sufficiently well way. So I have to come up with an example in the fly, but you have some key event in your life a long time ago, in some city or something, you realize it's a really dangerous street or whatever. And you want to remember that forever, in case you come back there. Kind of a selective kind of memory. So you remember all the important events in the past, but somehow selecting the important They're very hard. Yeah. And I'm not concerned about just storing the whole history. Just you can calculate human life, say 30 or 100 years doesn't matter, right? How much data comes in through the vision system and the auditory system, you compress it a little bit, in this case, lossily and store it. We are soon in the means of just storing it. But you still need to the selection for the planning part and the compression for the understanding part. The raw storage I'm really not concerned about. And I think we should just store if you develop an agent, preferably just store all the interaction history. And then you build, of course, models on top of it and you compress it and you are selective, but occasionally, you go back to the old data and reanalyze it based on your new experience you have. You know, sometimes you are in school, you learn all these things you think is totally useless. And you know, much later you read us, oh, they were not, you know, so useless as you thought. I'm looking at you linear algebra. Right. So maybe let me ask about objective functions because that rewards, it seems to be an important part. The rewards are kind of given to the system. For a lot of people, the specification of the objective function is a key part of intelligence. The agent itself figuring out what is important. What do you think about that? Is it possible within IACC framework to yourself discover the reward based on which you should operate? Okay, that will be a long answer. So, and that is a very interesting question. And I'm asked a lot about this question, where do the rewards come from? And that depends. So, and I give you now a couple of answers. So if we want to build agents, now let's start simple. So let's assume we want to build an agent based on the IACC model, which performs a particular task. Let's start with something super simple, like, I mean, super simple, like playing chess or go or something. Then you just, you know, the reward is, you know, winning the game is plus one, losing the game is minus one, done. You apply this agent, if you have enough compute, you let itself play, and it will learn the rules of the game will play perfect chess after some while problem solved. Okay, so if you have more complicated problems, then you may believe that you have the right reward, but it's not. So a nice cute example is elevator control that is also in Rich Sutton's book, which is a great book, by the way. So you control the elevator, and you think, well, maybe the reward should be coupled to how long people wait in front of the elevator, you know, long wait is bad. You program it and you do it. And what happens is the elevator eagerly picks up all the people, but never drops them off. So then you realize, maybe the time in the elevator also counts. So you minimize the sum. Yeah. And the elevator does that, but never picks up the people in the 10th floor and the top floor, because in expectation, it's not worth it. Just let them stay. So even in apparently simple problems, you can make mistakes. And that's what in more serious context, say, AGI safety researchers consider. So now let's go back to general agents. So assume we want to build an agent, which is generally useful to humans. Yes, we have a household robot, and it should do all kinds of tasks. So in this case, the human should give the reward on the fly. I mean, maybe it's pre trained in the factory and that there's some sort of internal reward for, you know, the battery level or whatever. But so it, you know, it does the dishes badly, you know, you punish the robot, you does it good, you reward the robot and then train it to a new task, like a child, right? So you need the human in the loop. If you want a system, which is useful to the human. And as long as this agent stays sub human level, that should work reasonably well. And apart from, you know, these examples, it becomes critical if they become, you know, on a human level, it's like with children, small children, you have reasonably well under control, they become older. The reward technique doesn't work so well anymore. So then finally, so this would be agents, which are just, you could say slaves to the humans. Yeah. So if you are more ambitious and just say we want to build a new spacious of intelligent beings, we put them on a new planet and we want them to develop this planet or whatever. So we don't give them any reward. So what could we do? And you could try to, you know, come up with some reward functions like, you know, it should maintain itself the robot, it should maybe multiply build more robots, right? And, you know, maybe for all kinds of things that you find useful, but that's pretty hard, right? You know, what does self maintenance mean? You know, what does it mean to build a copy? Should it be exact copy or an approximate copy? And so that's really hard. But Laurent or so, also at DeepMind, developed a beautiful model. So it just took the ICSE model and coupled the rewards to information gain. So he said the reward is proportional to how much the agent had learned about the world. And you can rigorously formally uniquely define that in terms of our cattle diversions. Okay. So if you put that in, you get a completely autonomous agent. And actually, interestingly, for this agent, we can prove much stronger result than for the general agent, which is also nice. And if you let this agent lose, it will be in a sense the optimal scientist is absolutely curious to learn as much as possible about the world. And of course, it will also have a lot of instrumental goals, right? In order to learn, it needs to at least survive, right? That that agent is not good for anything. So it needs to have self preservation. And if it builds small helpers acquiring more information, it will do that. Yeah, if exploration, space exploration or whatever is necessary, right, to gathering information and develop it. So it has a lot of instrumental goals following on this information gain. And this agent is completely autonomous of us. No rewards necessary anymore. Yeah, of course, you could find a way to gain the concept of information and get stuck in that library that you mentioned beforehand with a with a very large number of books. The first agent had this problem. It would get stuck in front of an old TV screen, which has just said white noise. Yeah, white noise. But the second version can deal with at least stochasticity. Well, yeah, what about curiosity, this kind of word curiosity, creativity? Is that kind of the reward function being of getting new information? Is that similar to idea of kind of injecting exploration for its own sake inside the reward function? Do you find this at all appealing, interesting? I think that's a nice definition. Curiosity is the reward. Sorry, curiosity is exploration for its own sake. Yeah, I would accept that. But most curiosity, while in humans and especially in children, yeah, is not just for its own sake, but for actually learning about the environment and for behaving better. So I would, I think most curiosity is tied in the end to what's performing better. Well, okay, so if intelligent systems need to have this reward function, let me, you're an intelligent system, currently passing the torrent test quite effectively. What's the reward function of our human intelligence existence? What's the reward function that Marcus Hutter is operating under? Okay, to the first question, the biological reward function is to survive and to spread. And very few humans sort of are able to overcome this biological reward function. But we live in a very nice world where we have lots of spare time and can still survive and spread. So we can develop arbitrary other interests, which is quite interesting. On top of that? On top of that, yeah. But the survival and spreading sort of is, I would say, the goal or the reward function of humans that the core one. I like how you avoided answering the second question, which a good intelligence system would. So my, your own meaning of life and the reward function? My own meaning of life and reward function is to find an AGI to build it. Beautifully put. Okay, let's dissect the X even further. So one of the assumptions is kind of infinity keeps creeping up everywhere, which, what are your thoughts on kind of bounded rationality and sort of the nature of our existence and intelligence systems is that we're operating always under constraints, under, you know, limited time, limited resources. How does that, how do you think about that within the IXE framework, within trying to create an AGI system that operates under these constraints? Yeah, that is one of the criticisms about IXE that it ignores computational completely. And some people believe that intelligence is inherently tied to what's bounded resources. What do you think on this one point? Do you think it's, do you think the bounded resources are fundamental to intelligence? I would say that an intelligence notion which ignores computational limits is extremely useful a good intelligence notion, which includes these resources would be even more useful, but we don't have that yet. And so look at other fields outside of computer science, computational aspects never play a fundamental role. You develop biological models for cells, something in physics, these theories, I mean, become more and more crazy and harder and harder to compute. Well, in the end, of course, we need to do something with this model, but there's more nuisance than a feature. And I'm sometimes wondering if artificial intelligence would not sit in a computer science department, but in a philosophy department, then this computational focus would be probably significantly less. I mean, think about the induction problem is more in the philosophy department. There's virtually no paper who cares about, you know, how long it takes to compute the answer that is completely secondary. Of course, once we have figured out the first problem, so intelligence without computational resources, then the next and very good question is, could we improve it by including computational resources, but nobody was able to do that so far in an even halfway satisfactory manner? I like that that's in the long run, the right department to belong to is philosophy. That's actually quite a deep idea of or even to at least to think about big picture philosophical questions, big picture questions, even in the computer science department. But you've mentioned approximation, sort of, there's a lot of infinity, a lot of huge resources needed. Are there approximations to IHC that within the IHC framework that are useful? Yeah, we have to develop a couple of approximations. And what we do there is that the Solomov induction part, which was, you know, find the shortest program describing your data, which just replaces by standard data compressors, right? And the better compressors get, you know, the better this part will become. We focus on a particular compressor called Context Rewaiting, which is pretty amazing, not so well known. It has beautiful theoretical properties also works reasonably well in practice. So we use that for the approximation of the induction and the learning and the prediction part. And for the planning part, we essentially just took the ideas from a computer go from 2006. It was Java, Cyprus, Bari, also now a DeepMind, who developed the so called UCT algorithm, upper confidence bound for trees algorithm, on top of the Monte Carlo tree search. So we approximate this planning part by sampling. And it's successful on some small toy problems. We don't want to lose the generality, right? And that's sort of the handicap, right? If you want to be general, you have to give up something. So but this single agent was able to play, you know, small games like Coon poker and tic-tac-toe and, and even Pac-Man. And the same architecture, no change. The agent doesn't know the rules of the game, really nothing at all by self or by a player with these environments. So you're gonna Schmidt, who were proposed something called Ghetto Machines, which is a self improving program that rewrites its own code. Sort of mathematically or philosophically, what's the relationship in your eyes, if you're familiar with it between AXI and the Ghetto Machines? Yeah, familiar with it. He developed it while I was in his lab. Yeah. So the Ghetto Machine, explain briefly. You give it a task. It could be a simple task as, you know, finding prime factors in numbers, right? You can formally write it down. There's a very slow algorithm to do that. Just all try all the factors. Yeah. Or play chess, right? Optimally, you write the algorithm to minimax to the end of the game. So you write down what the Ghetto Machine should do. Then it will take part of its resources to run this program. And other part of the sources to improve this program. And when it finds an improved version, which provably computes the same answer. So that's the key part. It needs to prove by itself that this change of program still satisfies the original specification. And if it does so, then it replaces the original program by the improved program. And by definition, it does the same job, but just faster. Okay. And then, you know, it proves over it and over it. And it's developed in a way that all parts of this Ghetto Machine can self improve. But it stays provably consistent with the original specification. So from this perspective, it has nothing to do with IxE. But if you would now put IxE as the starting axioms in, it would run IxE. But, you know, that takes forever. But then if it finds a provable speed up of IxE, it would replace it by this and this and this and maybe eventually it comes up with a model which is still the IxE model. It cannot be, I mean, just for the knowledgeable reader, IxE is incomputable. And that can prove that therefore there cannot be a computable exact algorithm of computers. There needs to be some approximations. And this is not dealt with the Ghetto Machine. So you have to do something about it. But there's the IxE TL model, which is finally computable, which we could put in. Which part of IxE is non computable? The Solomonov induction part. The induction. Okay, so. But there's ways of getting computable approximations of the IxE model. So then it's at least computable. It is still way beyond any resources anybody will ever have. But then the Ghetto Machine could sort of improve it further and further in an exact way. So is this theoretically possible that the Ghetto Machine process could improve? Isn't IxE already optimal? It is optimal in terms of the reward collected over its interaction cycles. But it takes infinite time to produce one action. And the world continues whether you want it or not. So the model is assuming it had an oracle, which solved this problem, and then in the next 100 milliseconds or the reaction time you need gives the answer, then IxE is optimal. It's optimal in sense of data, also from learning efficiency and data efficiency, but not in terms of computation time. And then the Ghetto Machine in theory, but probably not provably could make it go faster. Yes. Okay. Interesting. Those two components are super interesting. The perfect intelligence combined with self-improvement. Sort of provable self-improvement in sense you're always getting the correct answer and you're improving. Beautiful ideas. Okay, so you've also mentioned that different kinds of things in the chase of solving this reward, sort of optimizing for the goal, interesting human things could emerge. So is there a place for consciousness within IxE? Where does, maybe you can comment, because I suppose we humans are just another instantiation by IxE agents and we seem to have consciousness. You say humans are an instantiation of an IxE agent? Yes. Oh, that would be amazing. But I think that's not true even for the smartest and most rational humans. I think maybe we are very crude approximations. Interesting. I mean, I tend to believe, again, I'm Russian, so I tend to believe our flaws are part of the optimal. So we tend to laugh off and criticize our flaws and I tend to think that that's actually close to an optimal behavior. Well, some flaws, if you think more carefully about it, are actually not flaws here, but I think there are still enough flaws. I don't know. It's unclear. As a student of history, I think all the suffering that we've endured as a civilization, it's possible that that's the optimal amount of suffering we need to endure to minimize long-term suffering. That's your Russian background. That's the Russian. Whether humans are or not instantiations of an IxE agent, do you think there's consciousness is something that could emerge in a computational form of framework like IxE? Let me also ask you a question. Do you think I'm conscious? That's a good question. That tie is confusing me, but I think so. You think that makes me unconscious because it strangles me? If an agent were to solve the imitation game posed by Turing, I think that would be dressed similarly to you. Because there's a kind of flamboyant, interesting, complex behavior pattern that sells that you're human and you're conscious. But why do you ask? Was it a yes or was it a no? Yes, I think you're conscious, yes. So, and you explain somehow why, but you infer that from my behavior. You can never be sure about that. And I think the same thing will happen with any intelligent agent we develop if it behaves in a way sufficiently close to humans. Or maybe if not humans, maybe a dog is also sometimes a little bit self-conscious. So, if it behaves in a way where we attribute typically consciousness, we would attribute consciousness to these intelligent systems and IxE probably in particular. That, of course, doesn't answer the question whether it's really conscious. And that's the big hard problem of consciousness. Maybe I'm a zombie. I mean, not the movie zombie, but the philosophical zombie. It's to you, the display of consciousness close enough to consciousness from a perspective of AGI that the distinction of the heart problem of consciousness is not an interesting one. I think we don't have to worry about the consciousness problem, especially the heart problem for developing AGI. I think we progress. At some point, we have solved all the technical problems and this system will behave intelligent and then super intelligent and this consciousness will emerge. I mean, definitely it will display behavior which we will interpret as conscious. And then it's a philosophical question. Did this consciousness really emerge? Or is it a zombie which just fakes everything? We still don't have to figure that out. Although it may be interesting, at least from a philosophical point of view. It's very interesting, but it may also be sort of practically interesting. You know, there's some people saying, if it's just faking consciousness and feelings, then we don't need to be concerned about rights. But if it's real conscious and has feelings, then we need to be concerned. I can't wait till the day where AI systems exhibit consciousness because it'll truly be some of the hardest ethical questions of what we do with that. It is rather easy to build systems which people ascribe consciousness. And I give you an analogy. I mean, remember, maybe it was before you were born, the Tamagotchi. How dare you, sir. Why that's so... You're young, right? Yes, it's good to think. Thank you. Thank you very much. But I was also in the Soviet Union. We didn't have... We didn't have any of those fun things. But you have heard about this Tamagotchi, which was, you know, really, really primitive. Actually, for the time it was... And you could raise this. And kids got so attached to it and didn't want to let it die. And probably if we would have asked the children, do you think this Tamagotchi is conscious? They would have said yes. I think that's kind of a beautiful thing, actually, because that consciousness, ascribing consciousness seems to create a deeper connection, which is a powerful thing. But we have to be careful on the ethics side of that. Well, let me ask about the AGI community broadly. You kind of represent some of the most serious work on AGI, at least earlier. And DeepMind represents serious work on AGI these days. But why, in your sense, is the AGI community so small, or has been so small, until maybe DeepMind came along? Like, why aren't more people seriously working on human level and superhuman level intelligence from a formal perspective? Okay, from a formal perspective, that's sort of, you know, an extra point. So I think there are a couple of reasons. I mean, AI came in waves, right? You know, AI winters and AI summers, and then there were big promises, which were not fulfilled. And people got disappointed. But narrow AI, solving particular problems, which seemed to require intelligence, was always to some extent successful, and there were improvements, small steps. And if you build something which is, you know, useful for society or industrial useful, then there's a lot of funding. So I guess it was in parts the money, which drives people to develop specific system solving specific tasks. But you would think that, you know, at least in university, you should be able to do ivory tower research. And that was probably better a long time ago. But even nowadays, there's quite some pressure of doing applied research or translational research. And, you know, it's harder to get grants as a theorist. So that also drives people away. It's maybe also harder, attacking the general intelligence problem. So I think enough people, I mean, maybe a small number, we're still interested in, in formalizing intelligence and, and thinking of general intelligence. But, you know, not much came up, right? Or not not much great stuff came up. So what do you think we talked about the formal big light at the end of the tunnel, but from the engineering perspective, what do you think it takes to build an AI system? Is that, and I don't know if that's a stupid question or a distinct question from everything we've been talking about AIXE. But what do you see as the steps that are necessary to take to start to try to build something? So you want a blueprint now, and then you go off and do it? That's the whole point of this conversation, trying to squeeze that in there. Now, is there, I mean, what's your intuition? Is it is in the robotic space or something that has a body and tries to explore the world? Is in the reinforcement learning space, like the efforts of Alpha Zero and Alpha Star, they're kind of exploring how you can solve it through in the, in the simulation in the gaming world. Is there stuff in sort of the, all the transformer work in natural English processing, sort of maybe attacking the open domain dialogue? Like what, what, where do you see the promising pathways? Let me pick the embodiment maybe. So embodiment is important, yes and no. I don't believe that we need a physical robot walking or rolling around interacting with the real world in order to achieve AGI. And I think it's more of a distraction probably than helpful. It's sort of confusing the body with the mind. For industrial applications or near term applications, of course, we need robots for all kinds of things, but for solving the big problem, at least at this stage, I think it's not necessary. But the answer is also yes, that I think the most promising approach is that you have an agent, and that can be a virtual agent in a computer interacting with an environment, possibly, you know, a 3D simulated environment like in many computer games. And, and you train and learn the agent. Even if you don't intend to later put it sort of, you know, this algorithm in a, in a robot brain and leave it forever in the virtual reality, getting experience in a, although it's just simulated 3D world, is possibly, and as I possibly important to understand things on a similar level as humans do, especially if the agent or primarily if the agent wants, needs to interact with the humans, right? You know, if you talk about objects on top of each other in space and flying and cars and so on, and the agent has no experience with even virtual 3D worlds, it's probably hard to grasp. So if we develop an abstract agent, say we take the mathematical path, and we just want to build an agent which can prove theorems and becomes a better and better mathematician, then this agent needs to be able to reason in very abstract spaces, and then maybe sort of putting it into 3D environments, simulated world is even harmful, it should sort of, you put it in, I don't know, an environment which it creates itself or so. It seems like you have an interesting, rich complex trajectory through life in terms of your journey of ideas. So it's interesting to ask what books, technical fiction, philosophical books, ideas, people had a transformative effect. Books are most interesting because maybe people could also read those books and see if they could be inspired as well. Yeah, luckily I asked books and not singular book, it's very hard and I try to pin down one book, and I can do that at the end. So the books which were most transformative for me or which I can most highly recommend to people interested in AI, I would always start with Russell and Norbic, Artificial Intelligence and Modern Approach, that's the AI Bible, it's an amazing book, it's very broad, it covers all approaches to AI and even if you focus on one approach, I think that is the minimum you should know about the other approaches out there, so that should be your first book. Fourth edition should be coming out soon. Oh, okay, interesting. There's a deep learning chapter now as there must be, written by Ian Goodfellow, okay. And then the next book I would recommend, The Reinforcement Learning Book by Sutton and Bartow. There's a beautiful book, if there's any problem with the book, it makes RL feel and look much easier than it actually is. It's very gentle book, it's very nice to read the exercises, you can very quickly get some RL systems to run, very toy problems, but it's a lot of fun and in a couple of days you feel you know what RL is about, but it's much harder than the book. Come on now, it's an awesome book. Yeah, no, no, it is, yeah. And maybe, I mean, there's so many books out there, if you like the information theoretic approach, then there's Kolmogorff Complexity by Aline Vitani, but probably, you know, some short article is enough, you don't need to read the whole book, but it's a great book. And if you have to mention one all-time favorite book, it's a different flavor, that's a book which is used in the international baccalaureate for high school students in several countries. That's from Nikolas Altjen, Theory of Knowledge, second edition, or first, not the third, please. The third one they put, they took out all the fun. Okay, so this asks all the interesting, or to me, interesting philosophical questions about how we acquire knowledge from all perspectives, you know, from math, from art, from physics, and ask how can we know anything? And the book is called Theory of Knowledge. From which, is this almost like a philosophical exploration of how we get knowledge from anything? Yes, yeah, I mean, can religion tell us, you know, about something about the world? Can science tell us something about the world? Can mathematics, or is it just playing with symbols? And you know, it's open-ended questions, and I mean, it's for high school students, so they have the resources from Hitchhiker's Guide to the Galaxy and from Star Wars and the Chicken Cross the Road, yeah. And it's fun to read, but it's also quite deep. If you could live one day of your life over again, because it made you truly happy, or maybe like we said with the books, it was truly transformative, what day, what moment would you choose? Does something pop into your mind? Does it need to be a day in the past, or can it be a day in the future? Well, space-time is an emerging phenomena, so it's all the same anyway. Okay. Okay, from the past. You're really going to say from the future, I love it. No, I will tell you from the future. Okay, from the past. So from the past, I would say when I discovered my AXI model, I mean, it was not in one day, but it was one moment where I realized comagor of complexity. I didn't even know that it existed, but I discovered sort of this compression idea myself, but immediately I knew I can't be the first one, but I had this idea. And then I knew about sequential decisionary, and I knew if I put it together, this is the right thing. And yeah, still when I think back about this moment, I'm super excited about it. Was there any more details in context that moment? Did an apple fall in your head? So like if you look at Ian Goodfellow talking about gans, there was beer involved. Is there some more context of what sparked your thought, or was it just? No, it was much more mundane. So I worked in this company. So in this sense, the four and a half years was not completely wasted. So and I worked on an image interpolation problem. And I developed quite neat new interpolation techniques, and they got patented. And then, you know, which happens quite often, I got sort of overboard and thought about, you know, yeah, that's pretty good, but it's not the best. So what is the best possible way of doing interpolation? And then I thought, yeah, you want the simplest picture, which is if you coarse-grain it, recovers your original picture. And then I thought about the simplicity concept more in quantitative terms. And yeah, then everything developed. And somehow the full beautiful mix of also being a physicist and thinking about the big picture of it, then led you to probably beg with ice. Yeah. So as a physicist, I was probably trained not to always think in computational terms, you know, just ignore that and think about the fundamental properties which you want to have. So what about if you could really live one day in the future? What would that be? When I solve the AGI problem. In practice, in practice. So in theory, I have solved it with the IHC model, but in practice. And then I asked the first question. What would be the first question? What's the meaning of life? I don't think there's a better way to end it. Thank you so much for talking today. It's a huge honor to finally meet you. Yeah, thank you too. It was a pleasure of mine side too. Thanks for listening to this conversation with Marcus Hutter. And thank you to our presenting sponsor, Cash App. Download it, use code LEX Podcast. You'll get $10 and $10 will go to first, an organization that inspires and educates young minds to become science and technology innovators of tomorrow. If you enjoy this podcast, subscribe on YouTube, give it five stars on Apple Podcasts, support on Patreon, or simply connect with me on Twitter at Lex Friedman. And now let me leave you with some words of wisdom from Albert Einstein. The measure of intelligence is the ability to change. Thank you for listening and hope to see you next time.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.76, "text": " The following is a conversation with Marcus Hutter, senior research scientist at Google DeepMind.", "tokens": [50364, 440, 3480, 307, 257, 3761, 365, 26574, 389, 9947, 11, 7965, 2132, 12662, 412, 3329, 14895, 44, 471, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2142595178940717, "compression_ratio": 1.48582995951417, "no_speech_prob": 0.021862782537937164}, {"id": 1, "seek": 0, "start": 6.640000000000001, "end": 11.68, "text": " Throughout his career of research, including with J\u00f6rgen Schmidhuber and Shane Legg,", "tokens": [50696, 22775, 702, 3988, 295, 2132, 11, 3009, 365, 508, 2311, 1766, 2065, 25394, 71, 10261, 293, 25865, 7470, 70, 11, 50948], "temperature": 0.0, "avg_logprob": -0.2142595178940717, "compression_ratio": 1.48582995951417, "no_speech_prob": 0.021862782537937164}, {"id": 2, "seek": 0, "start": 11.68, "end": 16.32, "text": " he has proposed a lot of interesting ideas in and around the field of artificial general", "tokens": [50948, 415, 575, 10348, 257, 688, 295, 1880, 3487, 294, 293, 926, 264, 2519, 295, 11677, 2674, 51180], "temperature": 0.0, "avg_logprob": -0.2142595178940717, "compression_ratio": 1.48582995951417, "no_speech_prob": 0.021862782537937164}, {"id": 3, "seek": 0, "start": 16.32, "end": 23.76, "text": " intelligence, including the development of IEXI, spelled AIXI model, which is the mathematical", "tokens": [51180, 7599, 11, 3009, 264, 3250, 295, 286, 39814, 40, 11, 34388, 7318, 55, 40, 2316, 11, 597, 307, 264, 18894, 51552], "temperature": 0.0, "avg_logprob": -0.2142595178940717, "compression_ratio": 1.48582995951417, "no_speech_prob": 0.021862782537937164}, {"id": 4, "seek": 2376, "start": 23.76, "end": 30.560000000000002, "text": " approach to AGI that incorporates ideas of Komogorov complexity, Solominov induction,", "tokens": [50364, 3109, 281, 316, 26252, 300, 50193, 3487, 295, 14286, 664, 284, 5179, 14024, 11, 7026, 298, 2982, 85, 33371, 11, 50704], "temperature": 0.0, "avg_logprob": -0.1507638624344749, "compression_ratio": 1.4653061224489796, "no_speech_prob": 0.12383651733398438}, {"id": 5, "seek": 2376, "start": 30.560000000000002, "end": 38.32, "text": " and reinforcement learning. In 2006, Marcus launched the 50,000-euro Hutter prize for", "tokens": [50704, 293, 29280, 2539, 13, 682, 14062, 11, 26574, 8730, 264, 2625, 11, 1360, 12, 68, 7052, 389, 9947, 12818, 337, 51092], "temperature": 0.0, "avg_logprob": -0.1507638624344749, "compression_ratio": 1.4653061224489796, "no_speech_prob": 0.12383651733398438}, {"id": 6, "seek": 2376, "start": 38.32, "end": 43.84, "text": " lossless compression of human knowledge. The idea behind this prize is that the ability to", "tokens": [51092, 4470, 1832, 19355, 295, 1952, 3601, 13, 440, 1558, 2261, 341, 12818, 307, 300, 264, 3485, 281, 51368], "temperature": 0.0, "avg_logprob": -0.1507638624344749, "compression_ratio": 1.4653061224489796, "no_speech_prob": 0.12383651733398438}, {"id": 7, "seek": 2376, "start": 43.84, "end": 52.08, "text": " compress well is closely related to intelligence. This, to me, is a profound idea. Specifically,", "tokens": [51368, 14778, 731, 307, 8185, 4077, 281, 7599, 13, 639, 11, 281, 385, 11, 307, 257, 14382, 1558, 13, 26058, 11, 51780], "temperature": 0.0, "avg_logprob": -0.1507638624344749, "compression_ratio": 1.4653061224489796, "no_speech_prob": 0.12383651733398438}, {"id": 8, "seek": 5208, "start": 52.16, "end": 57.04, "text": " if you can compress the first 100 megabytes or one gigabyte of Wikipedia better than your", "tokens": [50368, 498, 291, 393, 14778, 264, 700, 2319, 10816, 24538, 420, 472, 8741, 34529, 295, 28999, 1101, 813, 428, 50612], "temperature": 0.0, "avg_logprob": -0.0803174489661108, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.004979023709893227}, {"id": 9, "seek": 5208, "start": 57.04, "end": 63.599999999999994, "text": " predecessors, your compressor likely has to also be smarter. The intention of this prize", "tokens": [50612, 24874, 45700, 11, 428, 28765, 3700, 575, 281, 611, 312, 20294, 13, 440, 7789, 295, 341, 12818, 50940], "temperature": 0.0, "avg_logprob": -0.0803174489661108, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.004979023709893227}, {"id": 10, "seek": 5208, "start": 63.599999999999994, "end": 68.16, "text": " is to encourage the development of intelligent compressors as a path to AGI.", "tokens": [50940, 307, 281, 5373, 264, 3250, 295, 13232, 14778, 830, 382, 257, 3100, 281, 316, 26252, 13, 51168], "temperature": 0.0, "avg_logprob": -0.0803174489661108, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.004979023709893227}, {"id": 11, "seek": 5208, "start": 69.52, "end": 75.44, "text": " In conjunction with his podcast release just a few days ago, Marcus announced a 10x increase", "tokens": [51236, 682, 27482, 365, 702, 7367, 4374, 445, 257, 1326, 1708, 2057, 11, 26574, 7548, 257, 1266, 87, 3488, 51532], "temperature": 0.0, "avg_logprob": -0.0803174489661108, "compression_ratio": 1.5330396475770924, "no_speech_prob": 0.004979023709893227}, {"id": 12, "seek": 7544, "start": 75.44, "end": 83.12, "text": " in several aspects of this prize, including the money, to 500,000 euros. The better your", "tokens": [50364, 294, 2940, 7270, 295, 341, 12818, 11, 3009, 264, 1460, 11, 281, 5923, 11, 1360, 14160, 13, 440, 1101, 428, 50748], "temperature": 0.0, "avg_logprob": -0.08343331892411787, "compression_ratio": 1.548, "no_speech_prob": 0.05256497859954834}, {"id": 13, "seek": 7544, "start": 83.12, "end": 88.16, "text": " compressor works relative to the previous winners, the higher fraction of that prize money is awarded", "tokens": [50748, 28765, 1985, 4972, 281, 264, 3894, 17193, 11, 264, 2946, 14135, 295, 300, 12818, 1460, 307, 19100, 51000], "temperature": 0.0, "avg_logprob": -0.08343331892411787, "compression_ratio": 1.548, "no_speech_prob": 0.05256497859954834}, {"id": 14, "seek": 7544, "start": 88.16, "end": 96.4, "text": " to you. You can learn more about it if you google simply Hutter prize. I'm a big fan of benchmarks", "tokens": [51000, 281, 291, 13, 509, 393, 1466, 544, 466, 309, 498, 291, 20742, 2935, 389, 9947, 12818, 13, 286, 478, 257, 955, 3429, 295, 43751, 51412], "temperature": 0.0, "avg_logprob": -0.08343331892411787, "compression_ratio": 1.548, "no_speech_prob": 0.05256497859954834}, {"id": 15, "seek": 7544, "start": 96.4, "end": 101.92, "text": " for developing AI systems, and the Hutter prize may indeed be one that will spark some good ideas", "tokens": [51412, 337, 6416, 7318, 3652, 11, 293, 264, 389, 9947, 12818, 815, 6451, 312, 472, 300, 486, 9908, 512, 665, 3487, 51688], "temperature": 0.0, "avg_logprob": -0.08343331892411787, "compression_ratio": 1.548, "no_speech_prob": 0.05256497859954834}, {"id": 16, "seek": 10192, "start": 101.92, "end": 108.56, "text": " for approaches that will make progress on the path of developing AGI systems. This is the", "tokens": [50364, 337, 11587, 300, 486, 652, 4205, 322, 264, 3100, 295, 6416, 316, 26252, 3652, 13, 639, 307, 264, 50696], "temperature": 0.0, "avg_logprob": -0.10751048345414418, "compression_ratio": 1.504823151125402, "no_speech_prob": 0.19895480573177338}, {"id": 17, "seek": 10192, "start": 108.56, "end": 113.76, "text": " Artificial Intelligence Podcast. If you enjoy it, subscribe on YouTube, give it 5 stars on Apple", "tokens": [50696, 5735, 10371, 27274, 29972, 13, 759, 291, 2103, 309, 11, 3022, 322, 3088, 11, 976, 309, 1025, 6105, 322, 6373, 50956], "temperature": 0.0, "avg_logprob": -0.10751048345414418, "compression_ratio": 1.504823151125402, "no_speech_prob": 0.19895480573177338}, {"id": 18, "seek": 10192, "start": 113.76, "end": 119.2, "text": " Podcasts, support it on Patreon, or simply connect with me on Twitter at Lex Freedman,", "tokens": [50956, 29972, 82, 11, 1406, 309, 322, 15692, 11, 420, 2935, 1745, 365, 385, 322, 5794, 412, 24086, 6142, 292, 1601, 11, 51228], "temperature": 0.0, "avg_logprob": -0.10751048345414418, "compression_ratio": 1.504823151125402, "no_speech_prob": 0.19895480573177338}, {"id": 19, "seek": 10192, "start": 119.2, "end": 126.4, "text": " spelled F-R-I-D-M-A-N. As usual, I'll do one or two minutes of ads now and never any ads in the", "tokens": [51228, 34388, 479, 12, 49, 12, 40, 12, 35, 12, 44, 12, 32, 12, 45, 13, 1018, 7713, 11, 286, 603, 360, 472, 420, 732, 2077, 295, 10342, 586, 293, 1128, 604, 10342, 294, 264, 51588], "temperature": 0.0, "avg_logprob": -0.10751048345414418, "compression_ratio": 1.504823151125402, "no_speech_prob": 0.19895480573177338}, {"id": 20, "seek": 10192, "start": 126.4, "end": 131.28, "text": " middle that can break the flow of the conversation. I hope that works for you and doesn't hurt the", "tokens": [51588, 2808, 300, 393, 1821, 264, 3095, 295, 264, 3761, 13, 286, 1454, 300, 1985, 337, 291, 293, 1177, 380, 4607, 264, 51832], "temperature": 0.0, "avg_logprob": -0.10751048345414418, "compression_ratio": 1.504823151125402, "no_speech_prob": 0.19895480573177338}, {"id": 21, "seek": 13128, "start": 131.36, "end": 137.68, "text": " listening experience. This show is presented by Cash App, the number one finance app in the App Store.", "tokens": [50368, 4764, 1752, 13, 639, 855, 307, 8212, 538, 27016, 3132, 11, 264, 1230, 472, 10719, 724, 294, 264, 3132, 17242, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10947064679078382, "compression_ratio": 1.548, "no_speech_prob": 0.10074786841869354}, {"id": 22, "seek": 13128, "start": 137.68, "end": 144.48, "text": " When you get it, use code LEX Podcast. Cash App lets you send money to friends, buy Bitcoin,", "tokens": [50684, 1133, 291, 483, 309, 11, 764, 3089, 11378, 55, 29972, 13, 27016, 3132, 6653, 291, 2845, 1460, 281, 1855, 11, 2256, 11414, 11, 51024], "temperature": 0.0, "avg_logprob": -0.10947064679078382, "compression_ratio": 1.548, "no_speech_prob": 0.10074786841869354}, {"id": 23, "seek": 13128, "start": 144.48, "end": 150.0, "text": " and invest in the stock market with as little as $1. Broker services are provided by Cash App", "tokens": [51024, 293, 1963, 294, 264, 4127, 2142, 365, 382, 707, 382, 1848, 16, 13, 5425, 5767, 3328, 366, 5649, 538, 27016, 3132, 51300], "temperature": 0.0, "avg_logprob": -0.10947064679078382, "compression_ratio": 1.548, "no_speech_prob": 0.10074786841869354}, {"id": 24, "seek": 13128, "start": 150.0, "end": 157.04, "text": " Investing, a subsidiary of Square, and member SIPC. Since Cash App allows you to send and receive", "tokens": [51300, 14008, 278, 11, 257, 48296, 822, 295, 16463, 11, 293, 4006, 318, 9139, 34, 13, 4162, 27016, 3132, 4045, 291, 281, 2845, 293, 4774, 51652], "temperature": 0.0, "avg_logprob": -0.10947064679078382, "compression_ratio": 1.548, "no_speech_prob": 0.10074786841869354}, {"id": 25, "seek": 15704, "start": 157.04, "end": 162.56, "text": " money digitally, peer-to-peer, and security in all digital transactions very important,", "tokens": [50364, 1460, 36938, 11, 15108, 12, 1353, 12, 494, 260, 11, 293, 3825, 294, 439, 4562, 16856, 588, 1021, 11, 50640], "temperature": 0.0, "avg_logprob": -0.070634092603411, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.16215334832668304}, {"id": 26, "seek": 15704, "start": 162.56, "end": 168.95999999999998, "text": " let me mention the PCI Data Security Standard that Cash App is compliant with. I'm a big fan of", "tokens": [50640, 718, 385, 2152, 264, 6465, 40, 11888, 11164, 21298, 300, 27016, 3132, 307, 36248, 365, 13, 286, 478, 257, 955, 3429, 295, 50960], "temperature": 0.0, "avg_logprob": -0.070634092603411, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.16215334832668304}, {"id": 27, "seek": 15704, "start": 168.95999999999998, "end": 176.07999999999998, "text": " standards for safety and security. PCI DSS is a good example of that, where a bunch of competitors", "tokens": [50960, 7787, 337, 4514, 293, 3825, 13, 6465, 40, 15816, 50, 307, 257, 665, 1365, 295, 300, 11, 689, 257, 3840, 295, 18333, 51316], "temperature": 0.0, "avg_logprob": -0.070634092603411, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.16215334832668304}, {"id": 28, "seek": 15704, "start": 176.07999999999998, "end": 181.6, "text": " got together and agreed that there needs to be a global standard around the security of transactions.", "tokens": [51316, 658, 1214, 293, 9166, 300, 456, 2203, 281, 312, 257, 4338, 3832, 926, 264, 3825, 295, 16856, 13, 51592], "temperature": 0.0, "avg_logprob": -0.070634092603411, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.16215334832668304}, {"id": 29, "seek": 18160, "start": 182.48, "end": 189.6, "text": " Now, we just need to do the same for autonomous vehicles and AI systems in general. So again,", "tokens": [50408, 823, 11, 321, 445, 643, 281, 360, 264, 912, 337, 23797, 8948, 293, 7318, 3652, 294, 2674, 13, 407, 797, 11, 50764], "temperature": 0.0, "avg_logprob": -0.09104659048359046, "compression_ratio": 1.4593495934959348, "no_speech_prob": 0.08627470582723618}, {"id": 30, "seek": 18160, "start": 189.6, "end": 194.88, "text": " if you get Cash App from the App Store or Google Play and use the code LEX Podcast,", "tokens": [50764, 498, 291, 483, 27016, 3132, 490, 264, 3132, 17242, 420, 3329, 5506, 293, 764, 264, 3089, 11378, 55, 29972, 11, 51028], "temperature": 0.0, "avg_logprob": -0.09104659048359046, "compression_ratio": 1.4593495934959348, "no_speech_prob": 0.08627470582723618}, {"id": 31, "seek": 18160, "start": 194.88, "end": 201.12, "text": " you'll get $10 and Cash App will also donate $10 to FIRST, one of my favorite organizations", "tokens": [51028, 291, 603, 483, 1848, 3279, 293, 27016, 3132, 486, 611, 17751, 1848, 3279, 281, 41538, 6840, 11, 472, 295, 452, 2954, 6150, 51340], "temperature": 0.0, "avg_logprob": -0.09104659048359046, "compression_ratio": 1.4593495934959348, "no_speech_prob": 0.08627470582723618}, {"id": 32, "seek": 18160, "start": 201.12, "end": 206.48, "text": " that is helping to advance robotics and STEM education for young people around the world.", "tokens": [51340, 300, 307, 4315, 281, 7295, 34145, 293, 25043, 3309, 337, 2037, 561, 926, 264, 1002, 13, 51608], "temperature": 0.0, "avg_logprob": -0.09104659048359046, "compression_ratio": 1.4593495934959348, "no_speech_prob": 0.08627470582723618}, {"id": 33, "seek": 20648, "start": 207.44, "end": 211.35999999999999, "text": " And now, here's my conversation with Marcus Hodder.", "tokens": [50412, 400, 586, 11, 510, 311, 452, 3761, 365, 26574, 45151, 1068, 13, 50608], "temperature": 0.0, "avg_logprob": -0.1473134001907037, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.017172997817397118}, {"id": 34, "seek": 20648, "start": 212.39999999999998, "end": 216.88, "text": " Do you think of the universe as a computer or maybe an information processing system?", "tokens": [50660, 1144, 291, 519, 295, 264, 6445, 382, 257, 3820, 420, 1310, 364, 1589, 9007, 1185, 30, 50884], "temperature": 0.0, "avg_logprob": -0.1473134001907037, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.017172997817397118}, {"id": 35, "seek": 20648, "start": 216.88, "end": 222.32, "text": " Let's go with a big question first. Okay, I have a big question first. I think it's a very", "tokens": [50884, 961, 311, 352, 365, 257, 955, 1168, 700, 13, 1033, 11, 286, 362, 257, 955, 1168, 700, 13, 286, 519, 309, 311, 257, 588, 51156], "temperature": 0.0, "avg_logprob": -0.1473134001907037, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.017172997817397118}, {"id": 36, "seek": 20648, "start": 222.32, "end": 229.35999999999999, "text": " interesting hypothesis or idea, and I have a background in physics, so I know a little bit", "tokens": [51156, 1880, 17291, 420, 1558, 11, 293, 286, 362, 257, 3678, 294, 10649, 11, 370, 286, 458, 257, 707, 857, 51508], "temperature": 0.0, "avg_logprob": -0.1473134001907037, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.017172997817397118}, {"id": 37, "seek": 20648, "start": 229.35999999999999, "end": 234.32, "text": " about physical theories, the standard model of particle physics and general relativity theory,", "tokens": [51508, 466, 4001, 13667, 11, 264, 3832, 2316, 295, 12359, 10649, 293, 2674, 45675, 5261, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1473134001907037, "compression_ratio": 1.6235294117647059, "no_speech_prob": 0.017172997817397118}, {"id": 38, "seek": 23432, "start": 234.4, "end": 238.48, "text": " and they are amazing and describe virtually everything in the universe, and they're all in", "tokens": [50368, 293, 436, 366, 2243, 293, 6786, 14103, 1203, 294, 264, 6445, 11, 293, 436, 434, 439, 294, 50572], "temperature": 0.0, "avg_logprob": -0.11649013745902788, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.0006767804152332246}, {"id": 39, "seek": 23432, "start": 238.48, "end": 243.51999999999998, "text": " a sense, computable theories. I mean, they're very hard to compute, and it's very elegant,", "tokens": [50572, 257, 2020, 11, 2807, 712, 13667, 13, 286, 914, 11, 436, 434, 588, 1152, 281, 14722, 11, 293, 309, 311, 588, 21117, 11, 50824], "temperature": 0.0, "avg_logprob": -0.11649013745902788, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.0006767804152332246}, {"id": 40, "seek": 23432, "start": 243.51999999999998, "end": 248.4, "text": " simple theories which describe virtually everything in the universe. So there's a strong", "tokens": [50824, 2199, 13667, 597, 6786, 14103, 1203, 294, 264, 6445, 13, 407, 456, 311, 257, 2068, 51068], "temperature": 0.0, "avg_logprob": -0.11649013745902788, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.0006767804152332246}, {"id": 41, "seek": 23432, "start": 249.04, "end": 256.96, "text": " indication that somehow the universe is computable, but it's a plausible hypothesis.", "tokens": [51100, 18877, 300, 6063, 264, 6445, 307, 2807, 712, 11, 457, 309, 311, 257, 39925, 17291, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11649013745902788, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.0006767804152332246}, {"id": 42, "seek": 23432, "start": 257.68, "end": 262.15999999999997, "text": " So what do you think, just like you said, general relativity, quantum field theory,", "tokens": [51532, 407, 437, 360, 291, 519, 11, 445, 411, 291, 848, 11, 2674, 45675, 11, 13018, 2519, 5261, 11, 51756], "temperature": 0.0, "avg_logprob": -0.11649013745902788, "compression_ratio": 1.8841201716738198, "no_speech_prob": 0.0006767804152332246}, {"id": 43, "seek": 26216, "start": 262.16, "end": 268.16, "text": " what do you think that the laws of physics are so nice and beautiful and simple and compressible?", "tokens": [50364, 437, 360, 291, 519, 300, 264, 6064, 295, 10649, 366, 370, 1481, 293, 2238, 293, 2199, 293, 14778, 964, 30, 50664], "temperature": 0.0, "avg_logprob": -0.10113912699173908, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.002080509439110756}, {"id": 44, "seek": 26216, "start": 269.04, "end": 276.0, "text": " Do you think our universe was designed is naturally this way? Are we just focusing on the", "tokens": [50708, 1144, 291, 519, 527, 6445, 390, 4761, 307, 8195, 341, 636, 30, 2014, 321, 445, 8416, 322, 264, 51056], "temperature": 0.0, "avg_logprob": -0.10113912699173908, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.002080509439110756}, {"id": 45, "seek": 26216, "start": 276.0, "end": 282.72, "text": " parts that are especially compressible? Are human minds just enjoying something about that simplicity", "tokens": [51056, 3166, 300, 366, 2318, 14778, 964, 30, 2014, 1952, 9634, 445, 9929, 746, 466, 300, 25632, 51392], "temperature": 0.0, "avg_logprob": -0.10113912699173908, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.002080509439110756}, {"id": 46, "seek": 26216, "start": 282.72, "end": 286.64000000000004, "text": " and, in fact, there's other things that are not so compressible?", "tokens": [51392, 293, 11, 294, 1186, 11, 456, 311, 661, 721, 300, 366, 406, 370, 14778, 964, 30, 51588], "temperature": 0.0, "avg_logprob": -0.10113912699173908, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.002080509439110756}, {"id": 47, "seek": 26216, "start": 286.64000000000004, "end": 292.0, "text": " No, I strongly believe and I'm pretty convinced that the universe is inherently beautiful", "tokens": [51588, 883, 11, 286, 10613, 1697, 293, 286, 478, 1238, 12561, 300, 264, 6445, 307, 27993, 2238, 51856], "temperature": 0.0, "avg_logprob": -0.10113912699173908, "compression_ratio": 1.7411764705882353, "no_speech_prob": 0.002080509439110756}, {"id": 48, "seek": 29200, "start": 292.0, "end": 296.88, "text": " elegant and simple and described by these equations, and we're not just picking that.", "tokens": [50364, 21117, 293, 2199, 293, 7619, 538, 613, 11787, 11, 293, 321, 434, 406, 445, 8867, 300, 13, 50608], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 49, "seek": 29200, "start": 297.44, "end": 304.16, "text": " I mean, if there were some phenomena which cannot be neatly described, scientists would try that,", "tokens": [50636, 286, 914, 11, 498, 456, 645, 512, 22004, 597, 2644, 312, 36634, 7619, 11, 7708, 576, 853, 300, 11, 50972], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 50, "seek": 29200, "start": 304.16, "end": 307.68, "text": " right? And, you know, there's biology which is more messy, but we understand that it's an", "tokens": [50972, 558, 30, 400, 11, 291, 458, 11, 456, 311, 14956, 597, 307, 544, 16191, 11, 457, 321, 1223, 300, 309, 311, 364, 51148], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 51, "seek": 29200, "start": 307.68, "end": 312.32, "text": " emergent phenomena, and, you know, it's complex systems, but they still follow the same rules,", "tokens": [51148, 4345, 6930, 22004, 11, 293, 11, 291, 458, 11, 309, 311, 3997, 3652, 11, 457, 436, 920, 1524, 264, 912, 4474, 11, 51380], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 52, "seek": 29200, "start": 312.32, "end": 316.64, "text": " right? Of quantum and electrodynamics, all of chemistry follows that, and we know that. I mean,", "tokens": [51380, 558, 30, 2720, 13018, 293, 44216, 5216, 1167, 11, 439, 295, 12558, 10002, 300, 11, 293, 321, 458, 300, 13, 286, 914, 11, 51596], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 53, "seek": 29200, "start": 316.64, "end": 320.72, "text": " we cannot compute everything because we have limited computational resources. No, I think it's", "tokens": [51596, 321, 2644, 14722, 1203, 570, 321, 362, 5567, 28270, 3593, 13, 883, 11, 286, 519, 309, 311, 51800], "temperature": 0.0, "avg_logprob": -0.12090628894407358, "compression_ratio": 1.7578616352201257, "no_speech_prob": 0.0005350291030481458}, {"id": 54, "seek": 32072, "start": 320.72, "end": 325.44000000000005, "text": " not a bias of the humans, but it's objectively simple. I mean, of course, you never know, you", "tokens": [50364, 406, 257, 12577, 295, 264, 6255, 11, 457, 309, 311, 46067, 2199, 13, 286, 914, 11, 295, 1164, 11, 291, 1128, 458, 11, 291, 50600], "temperature": 0.0, "avg_logprob": -0.1079978611158288, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.0010479559423401952}, {"id": 55, "seek": 32072, "start": 325.44000000000005, "end": 330.48, "text": " know, maybe there's some corners very far out in the universe or super, super tiny below the", "tokens": [50600, 458, 11, 1310, 456, 311, 512, 12413, 588, 1400, 484, 294, 264, 6445, 420, 1687, 11, 1687, 5870, 2507, 264, 50852], "temperature": 0.0, "avg_logprob": -0.1079978611158288, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.0010479559423401952}, {"id": 56, "seek": 32072, "start": 330.48, "end": 339.52000000000004, "text": " nucleus of atoms or, well, parallel universes where which are not nice and simple, but there's no", "tokens": [50852, 28055, 295, 16871, 420, 11, 731, 11, 8952, 50168, 689, 597, 366, 406, 1481, 293, 2199, 11, 457, 456, 311, 572, 51304], "temperature": 0.0, "avg_logprob": -0.1079978611158288, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.0010479559423401952}, {"id": 57, "seek": 32072, "start": 339.52000000000004, "end": 344.24, "text": " evidence for that, and we should apply Occam's razor and, you know, choose the simple streak", "tokens": [51304, 4467, 337, 300, 11, 293, 321, 820, 3079, 26191, 335, 311, 30478, 293, 11, 291, 458, 11, 2826, 264, 2199, 35634, 51540], "temperature": 0.0, "avg_logprob": -0.1079978611158288, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.0010479559423401952}, {"id": 58, "seek": 32072, "start": 344.24, "end": 347.92, "text": " consistent with it, but also it's a little bit self-referential.", "tokens": [51540, 8398, 365, 309, 11, 457, 611, 309, 311, 257, 707, 857, 2698, 12, 265, 612, 2549, 13, 51724], "temperature": 0.0, "avg_logprob": -0.1079978611158288, "compression_ratio": 1.6934865900383143, "no_speech_prob": 0.0010479559423401952}, {"id": 59, "seek": 34792, "start": 347.92, "end": 354.48, "text": " So maybe a quick pause. What is Occam's razor? So Occam's razor says that you should not multiply", "tokens": [50364, 407, 1310, 257, 1702, 10465, 13, 708, 307, 26191, 335, 311, 30478, 30, 407, 26191, 335, 311, 30478, 1619, 300, 291, 820, 406, 12972, 50692], "temperature": 0.0, "avg_logprob": -0.11517200686714867, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0011691729305312037}, {"id": 60, "seek": 34792, "start": 354.48, "end": 361.76, "text": " entities beyond necessity, which sort of if you translate it to proper English means, and, you", "tokens": [50692, 16667, 4399, 24217, 11, 597, 1333, 295, 498, 291, 13799, 309, 281, 2296, 3669, 1355, 11, 293, 11, 291, 51056], "temperature": 0.0, "avg_logprob": -0.11517200686714867, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0011691729305312037}, {"id": 61, "seek": 34792, "start": 361.76, "end": 366.88, "text": " know, in the scientific context means that if you have two theories or hypotheses or models which", "tokens": [51056, 458, 11, 294, 264, 8134, 4319, 1355, 300, 498, 291, 362, 732, 13667, 420, 49969, 420, 5245, 597, 51312], "temperature": 0.0, "avg_logprob": -0.11517200686714867, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0011691729305312037}, {"id": 62, "seek": 34792, "start": 366.88, "end": 372.40000000000003, "text": " equally well describe the phenomenon you're studying or the data, you should choose the more", "tokens": [51312, 12309, 731, 6786, 264, 14029, 291, 434, 7601, 420, 264, 1412, 11, 291, 820, 2826, 264, 544, 51588], "temperature": 0.0, "avg_logprob": -0.11517200686714867, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.0011691729305312037}, {"id": 63, "seek": 37240, "start": 372.4, "end": 380.4, "text": " simple one. So that's just a principle or sort of that's not like a provable law, perhaps, perhaps", "tokens": [50364, 2199, 472, 13, 407, 300, 311, 445, 257, 8665, 420, 1333, 295, 300, 311, 406, 411, 257, 1439, 712, 2101, 11, 4317, 11, 4317, 50764], "temperature": 0.0, "avg_logprob": -0.10370321171258086, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0027148074004799128}, {"id": 64, "seek": 37240, "start": 380.4, "end": 387.03999999999996, "text": " we'll kind of discuss it and think about it, but what's the intuition of why the simpler answer", "tokens": [50764, 321, 603, 733, 295, 2248, 309, 293, 519, 466, 309, 11, 457, 437, 311, 264, 24002, 295, 983, 264, 18587, 1867, 51096], "temperature": 0.0, "avg_logprob": -0.10370321171258086, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0027148074004799128}, {"id": 65, "seek": 37240, "start": 388.0, "end": 394.96, "text": " is the one that is likely to be more correct descriptor of whatever we're talking about?", "tokens": [51144, 307, 264, 472, 300, 307, 3700, 281, 312, 544, 3006, 31280, 284, 295, 2035, 321, 434, 1417, 466, 30, 51492], "temperature": 0.0, "avg_logprob": -0.10370321171258086, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0027148074004799128}, {"id": 66, "seek": 37240, "start": 394.96, "end": 400.4, "text": " I believe that Occam's razor is probably the most important principle in science. I mean,", "tokens": [51492, 286, 1697, 300, 26191, 335, 311, 30478, 307, 1391, 264, 881, 1021, 8665, 294, 3497, 13, 286, 914, 11, 51764], "temperature": 0.0, "avg_logprob": -0.10370321171258086, "compression_ratio": 1.6288209606986899, "no_speech_prob": 0.0027148074004799128}, {"id": 67, "seek": 40040, "start": 400.4, "end": 407.28, "text": " of course, we need logical deduction and we do experimental design, but science is about finding", "tokens": [50364, 295, 1164, 11, 321, 643, 14978, 46385, 293, 321, 360, 17069, 1715, 11, 457, 3497, 307, 466, 5006, 50708], "temperature": 0.0, "avg_logprob": -0.15638045606942014, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0006769170868210495}, {"id": 68, "seek": 40040, "start": 407.84, "end": 413.59999999999997, "text": " understanding the world, finding models of the world, and we can come up with crazy complex models", "tokens": [50736, 3701, 264, 1002, 11, 5006, 5245, 295, 264, 1002, 11, 293, 321, 393, 808, 493, 365, 3219, 3997, 5245, 51024], "temperature": 0.0, "avg_logprob": -0.15638045606942014, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0006769170868210495}, {"id": 69, "seek": 40040, "start": 413.59999999999997, "end": 419.03999999999996, "text": " which, you know, explain everything but predict nothing, but the simple model seemed to have", "tokens": [51024, 597, 11, 291, 458, 11, 2903, 1203, 457, 6069, 1825, 11, 457, 264, 2199, 2316, 6576, 281, 362, 51296], "temperature": 0.0, "avg_logprob": -0.15638045606942014, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0006769170868210495}, {"id": 70, "seek": 40040, "start": 419.03999999999996, "end": 426.96, "text": " predictive power, and it's a valid question why. And the two answers to that, you can just accept", "tokens": [51296, 35521, 1347, 11, 293, 309, 311, 257, 7363, 1168, 983, 13, 400, 264, 732, 6338, 281, 300, 11, 291, 393, 445, 3241, 51692], "temperature": 0.0, "avg_logprob": -0.15638045606942014, "compression_ratio": 1.6929824561403508, "no_speech_prob": 0.0006769170868210495}, {"id": 71, "seek": 42696, "start": 427.12, "end": 432.0, "text": " that as the principle of science, and we use this principle and it seems to be successful.", "tokens": [50372, 300, 382, 264, 8665, 295, 3497, 11, 293, 321, 764, 341, 8665, 293, 309, 2544, 281, 312, 4406, 13, 50616], "temperature": 0.0, "avg_logprob": -0.11038816240098741, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0053811087273061275}, {"id": 72, "seek": 42696, "start": 432.71999999999997, "end": 438.47999999999996, "text": " We don't know why, but it just happens to be. Or you can try, you know, find another principle", "tokens": [50652, 492, 500, 380, 458, 983, 11, 457, 309, 445, 2314, 281, 312, 13, 1610, 291, 393, 853, 11, 291, 458, 11, 915, 1071, 8665, 50940], "temperature": 0.0, "avg_logprob": -0.11038816240098741, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0053811087273061275}, {"id": 73, "seek": 42696, "start": 438.47999999999996, "end": 445.44, "text": " which explains Occam's razor. And if we start with assumption that the world is governed by", "tokens": [50940, 597, 13948, 26191, 335, 311, 30478, 13, 400, 498, 321, 722, 365, 15302, 300, 264, 1002, 307, 35529, 538, 51288], "temperature": 0.0, "avg_logprob": -0.11038816240098741, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0053811087273061275}, {"id": 74, "seek": 42696, "start": 445.44, "end": 453.59999999999997, "text": " simple rules, then there's a bias to our simplicity, and applying Occam's razor", "tokens": [51288, 2199, 4474, 11, 550, 456, 311, 257, 12577, 281, 527, 25632, 11, 293, 9275, 26191, 335, 311, 30478, 51696], "temperature": 0.0, "avg_logprob": -0.11038816240098741, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0053811087273061275}, {"id": 75, "seek": 45360, "start": 454.16, "end": 458.88, "text": " is the mechanism to finding these rules. And actually, in a more quantitative sense,", "tokens": [50392, 307, 264, 7513, 281, 5006, 613, 4474, 13, 400, 767, 11, 294, 257, 544, 27778, 2020, 11, 50628], "temperature": 0.0, "avg_logprob": -0.14689400818970827, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.0016736252000555396}, {"id": 76, "seek": 45360, "start": 458.88, "end": 462.72, "text": " and we come back to that later in case of somnambular deduction, you can rigorously prove", "tokens": [50628, 293, 321, 808, 646, 281, 300, 1780, 294, 1389, 295, 3307, 77, 2173, 1040, 46385, 11, 291, 393, 42191, 5098, 7081, 50820], "temperature": 0.0, "avg_logprob": -0.14689400818970827, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.0016736252000555396}, {"id": 77, "seek": 45360, "start": 462.72, "end": 468.16, "text": " that you assume that the world is simple, then Occam's razor is the best you can do in a certain", "tokens": [50820, 300, 291, 6552, 300, 264, 1002, 307, 2199, 11, 550, 26191, 335, 311, 30478, 307, 264, 1151, 291, 393, 360, 294, 257, 1629, 51092], "temperature": 0.0, "avg_logprob": -0.14689400818970827, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.0016736252000555396}, {"id": 78, "seek": 45360, "start": 468.16, "end": 475.52000000000004, "text": " sense. So, I apologize for the romanticized question, but why do you think outside of its", "tokens": [51092, 2020, 13, 407, 11, 286, 12328, 337, 264, 13590, 1602, 1168, 11, 457, 983, 360, 291, 519, 2380, 295, 1080, 51460], "temperature": 0.0, "avg_logprob": -0.14689400818970827, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.0016736252000555396}, {"id": 79, "seek": 45360, "start": 475.52000000000004, "end": 480.0, "text": " effectiveness, why do we do you think we find simplicity so appealing as human beings? Why", "tokens": [51460, 21208, 11, 983, 360, 321, 360, 291, 519, 321, 915, 25632, 370, 23842, 382, 1952, 8958, 30, 1545, 51684], "temperature": 0.0, "avg_logprob": -0.14689400818970827, "compression_ratio": 1.6258992805755397, "no_speech_prob": 0.0016736252000555396}, {"id": 80, "seek": 48000, "start": 480.0, "end": 487.12, "text": " does it just, why does E equals MC squared seem so beautiful to us humans?", "tokens": [50364, 775, 309, 445, 11, 983, 775, 462, 6915, 8797, 8889, 1643, 370, 2238, 281, 505, 6255, 30, 50720], "temperature": 0.0, "avg_logprob": -0.1581506285556527, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.0008966328459791839}, {"id": 81, "seek": 48000, "start": 488.24, "end": 494.24, "text": " I guess mostly, in general, many things can be explained by an evolutionary argument.", "tokens": [50776, 286, 2041, 5240, 11, 294, 2674, 11, 867, 721, 393, 312, 8825, 538, 364, 27567, 6770, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1581506285556527, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.0008966328459791839}, {"id": 82, "seek": 48000, "start": 494.88, "end": 499.28, "text": " And, you know, there's some artifacts in humans which, you know, are just artifacts and not an", "tokens": [51108, 400, 11, 291, 458, 11, 456, 311, 512, 24617, 294, 6255, 597, 11, 291, 458, 11, 366, 445, 24617, 293, 406, 364, 51328], "temperature": 0.0, "avg_logprob": -0.1581506285556527, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.0008966328459791839}, {"id": 83, "seek": 48000, "start": 499.28, "end": 508.24, "text": " evolutionary necessary. But with this beauty and simplicity, it's, I believe, at least the core", "tokens": [51328, 27567, 4818, 13, 583, 365, 341, 6643, 293, 25632, 11, 309, 311, 11, 286, 1697, 11, 412, 1935, 264, 4965, 51776], "temperature": 0.0, "avg_logprob": -0.1581506285556527, "compression_ratio": 1.5739910313901346, "no_speech_prob": 0.0008966328459791839}, {"id": 84, "seek": 50824, "start": 508.8, "end": 515.84, "text": " is about, like science, finding regularities in the world, understanding the world,", "tokens": [50392, 307, 466, 11, 411, 3497, 11, 5006, 3890, 1088, 294, 264, 1002, 11, 3701, 264, 1002, 11, 50744], "temperature": 0.0, "avg_logprob": -0.09627330303192139, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0027141873724758625}, {"id": 85, "seek": 50824, "start": 515.84, "end": 522.4, "text": " which is necessary for survival, right? You know, if I look at a bush, right, and I just see noise,", "tokens": [50744, 597, 307, 4818, 337, 12559, 11, 558, 30, 509, 458, 11, 498, 286, 574, 412, 257, 19910, 11, 558, 11, 293, 286, 445, 536, 5658, 11, 51072], "temperature": 0.0, "avg_logprob": -0.09627330303192139, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0027141873724758625}, {"id": 86, "seek": 50824, "start": 522.4, "end": 527.2, "text": " and there is a tiger, right, and eats me, then I'm dead. But if I try to find a pattern, and", "tokens": [51072, 293, 456, 307, 257, 21432, 11, 558, 11, 293, 18109, 385, 11, 550, 286, 478, 3116, 13, 583, 498, 286, 853, 281, 915, 257, 5102, 11, 293, 51312], "temperature": 0.0, "avg_logprob": -0.09627330303192139, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0027141873724758625}, {"id": 87, "seek": 50824, "start": 527.2, "end": 534.8, "text": " we know that humans are prone to find more patterns in data than they are, you know, like, you know,", "tokens": [51312, 321, 458, 300, 6255, 366, 25806, 281, 915, 544, 8294, 294, 1412, 813, 436, 366, 11, 291, 458, 11, 411, 11, 291, 458, 11, 51692], "temperature": 0.0, "avg_logprob": -0.09627330303192139, "compression_ratio": 1.6981981981981982, "no_speech_prob": 0.0027141873724758625}, {"id": 88, "seek": 53480, "start": 534.88, "end": 541.04, "text": " Mars face and all these things, but these bias towards finding patterns, even if they are not,", "tokens": [50368, 9692, 1851, 293, 439, 613, 721, 11, 457, 613, 12577, 3030, 5006, 8294, 11, 754, 498, 436, 366, 406, 11, 50676], "temperature": 0.0, "avg_logprob": -0.17179008240395405, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.004258534871041775}, {"id": 89, "seek": 53480, "start": 541.04, "end": 545.04, "text": " but I mean, it's best, of course, if they are, yeah, helps us for survival.", "tokens": [50676, 457, 286, 914, 11, 309, 311, 1151, 11, 295, 1164, 11, 498, 436, 366, 11, 1338, 11, 3665, 505, 337, 12559, 13, 50876], "temperature": 0.0, "avg_logprob": -0.17179008240395405, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.004258534871041775}, {"id": 90, "seek": 53480, "start": 546.4799999999999, "end": 551.5999999999999, "text": " Yeah, that's fascinating. I haven't thought really about the, I thought I just loved science, but", "tokens": [50948, 865, 11, 300, 311, 10343, 13, 286, 2378, 380, 1194, 534, 466, 264, 11, 286, 1194, 286, 445, 4333, 3497, 11, 457, 51204], "temperature": 0.0, "avg_logprob": -0.17179008240395405, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.004258534871041775}, {"id": 91, "seek": 53480, "start": 552.8, "end": 560.3199999999999, "text": " indeed, from in terms of just for survival purposes, there is an evolutionary argument for why we find", "tokens": [51264, 6451, 11, 490, 294, 2115, 295, 445, 337, 12559, 9932, 11, 456, 307, 364, 27567, 6770, 337, 983, 321, 915, 51640], "temperature": 0.0, "avg_logprob": -0.17179008240395405, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.004258534871041775}, {"id": 92, "seek": 56032, "start": 561.2800000000001, "end": 568.08, "text": " the work of Einstein so beautiful. Maybe a quick small tangent, could you describe what", "tokens": [50412, 264, 589, 295, 23486, 370, 2238, 13, 2704, 257, 1702, 1359, 27747, 11, 727, 291, 6786, 437, 50752], "temperature": 0.0, "avg_logprob": -0.200282493334138, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.0009107111254706979}, {"id": 93, "seek": 56032, "start": 568.08, "end": 576.88, "text": " Solomon of induction is? Yeah, so that's a theory which I claim, and Resolominov sort of claimed", "tokens": [50752, 32209, 295, 33371, 307, 30, 865, 11, 370, 300, 311, 257, 5261, 597, 286, 3932, 11, 293, 5015, 401, 298, 2982, 85, 1333, 295, 12941, 51192], "temperature": 0.0, "avg_logprob": -0.200282493334138, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.0009107111254706979}, {"id": 94, "seek": 56032, "start": 576.88, "end": 582.8000000000001, "text": " a long time ago, that this solves the big philosophical problem of induction. And I believe", "tokens": [51192, 257, 938, 565, 2057, 11, 300, 341, 39890, 264, 955, 25066, 1154, 295, 33371, 13, 400, 286, 1697, 51488], "temperature": 0.0, "avg_logprob": -0.200282493334138, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.0009107111254706979}, {"id": 95, "seek": 56032, "start": 582.8000000000001, "end": 589.36, "text": " the claim is essentially true. And what it does is the following. So, okay, for the", "tokens": [51488, 264, 3932, 307, 4476, 2074, 13, 400, 437, 309, 775, 307, 264, 3480, 13, 407, 11, 1392, 11, 337, 264, 51816], "temperature": 0.0, "avg_logprob": -0.200282493334138, "compression_ratio": 1.518987341772152, "no_speech_prob": 0.0009107111254706979}, {"id": 96, "seek": 59032, "start": 590.32, "end": 598.72, "text": " picky listener, induction can be interpreted narrowly and wildly narrow means inferring models from data.", "tokens": [50364, 41099, 31569, 11, 33371, 393, 312, 26749, 9432, 356, 293, 34731, 9432, 1355, 13596, 2937, 5245, 490, 1412, 13, 50784], "temperature": 0.0, "avg_logprob": -0.1670875927009205, "compression_ratio": 1.72, "no_speech_prob": 0.0005974289961159229}, {"id": 97, "seek": 59032, "start": 600.5600000000001, "end": 605.9200000000001, "text": " And widely means also then using these models for doing predictions or predictions also part of", "tokens": [50876, 400, 13371, 1355, 611, 550, 1228, 613, 5245, 337, 884, 21264, 420, 21264, 611, 644, 295, 51144], "temperature": 0.0, "avg_logprob": -0.1670875927009205, "compression_ratio": 1.72, "no_speech_prob": 0.0005974289961159229}, {"id": 98, "seek": 59032, "start": 605.9200000000001, "end": 610.6400000000001, "text": " the induction. So I'm a little sloppy sort of with the terminology and maybe that comes from", "tokens": [51144, 264, 33371, 13, 407, 286, 478, 257, 707, 43684, 1333, 295, 365, 264, 27575, 293, 1310, 300, 1487, 490, 51380], "temperature": 0.0, "avg_logprob": -0.1670875927009205, "compression_ratio": 1.72, "no_speech_prob": 0.0005974289961159229}, {"id": 99, "seek": 59032, "start": 611.2, "end": 614.4000000000001, "text": " Resolominov, you know, being sloppy, maybe I shouldn't say that.", "tokens": [51408, 5015, 401, 298, 2982, 85, 11, 291, 458, 11, 885, 43684, 11, 1310, 286, 4659, 380, 584, 300, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1670875927009205, "compression_ratio": 1.72, "no_speech_prob": 0.0005974289961159229}, {"id": 100, "seek": 59032, "start": 615.9200000000001, "end": 619.9200000000001, "text": " He can't complain anymore. So let me explain a little bit this theory.", "tokens": [51644, 634, 393, 380, 11024, 3602, 13, 407, 718, 385, 2903, 257, 707, 857, 341, 5261, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1670875927009205, "compression_ratio": 1.72, "no_speech_prob": 0.0005974289961159229}, {"id": 101, "seek": 61992, "start": 620.88, "end": 626.88, "text": " In simple terms, so assume we have a data sequence, make it very simple, the simplest one say 111111 and", "tokens": [50412, 682, 2199, 2115, 11, 370, 6552, 321, 362, 257, 1412, 8310, 11, 652, 309, 588, 2199, 11, 264, 22811, 472, 584, 2975, 5348, 5348, 293, 50712], "temperature": 0.0, "avg_logprob": -0.21131265625473142, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.00018232560250908136}, {"id": 102, "seek": 61992, "start": 626.88, "end": 632.4, "text": " you see if 100 ones, what do you think comes next? The natural answer, I'm going to speed up a little", "tokens": [50712, 291, 536, 498, 2319, 2306, 11, 437, 360, 291, 519, 1487, 958, 30, 440, 3303, 1867, 11, 286, 478, 516, 281, 3073, 493, 257, 707, 50988], "temperature": 0.0, "avg_logprob": -0.21131265625473142, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.00018232560250908136}, {"id": 103, "seek": 61992, "start": 632.4, "end": 638.7199999999999, "text": " bit, the natural answer is of course, you know, one. Okay, and the question is why? Okay, well,", "tokens": [50988, 857, 11, 264, 3303, 1867, 307, 295, 1164, 11, 291, 458, 11, 472, 13, 1033, 11, 293, 264, 1168, 307, 983, 30, 1033, 11, 731, 11, 51304], "temperature": 0.0, "avg_logprob": -0.21131265625473142, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.00018232560250908136}, {"id": 104, "seek": 61992, "start": 638.7199999999999, "end": 643.76, "text": " we see a pattern there. Yeah, okay, there's a one and we repeat it. And why should it suddenly", "tokens": [51304, 321, 536, 257, 5102, 456, 13, 865, 11, 1392, 11, 456, 311, 257, 472, 293, 321, 7149, 309, 13, 400, 983, 820, 309, 5800, 51556], "temperature": 0.0, "avg_logprob": -0.21131265625473142, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.00018232560250908136}, {"id": 105, "seek": 61992, "start": 643.76, "end": 648.48, "text": " after 100 ones be different? So what we're looking for is simple explanations or models", "tokens": [51556, 934, 2319, 2306, 312, 819, 30, 407, 437, 321, 434, 1237, 337, 307, 2199, 28708, 420, 5245, 51792], "temperature": 0.0, "avg_logprob": -0.21131265625473142, "compression_ratio": 1.6275167785234899, "no_speech_prob": 0.00018232560250908136}, {"id": 106, "seek": 64848, "start": 649.12, "end": 654.48, "text": " for the data we have. And now the question is a model has to be presented in a certain language", "tokens": [50396, 337, 264, 1412, 321, 362, 13, 400, 586, 264, 1168, 307, 257, 2316, 575, 281, 312, 8212, 294, 257, 1629, 2856, 50664], "temperature": 0.0, "avg_logprob": -0.15122763315836588, "compression_ratio": 1.697080291970803, "no_speech_prob": 0.000616573030129075}, {"id": 107, "seek": 64848, "start": 655.36, "end": 660.72, "text": " in which language to be used. In science, we want formal languages, and we can use mathematics,", "tokens": [50708, 294, 597, 2856, 281, 312, 1143, 13, 682, 3497, 11, 321, 528, 9860, 8650, 11, 293, 321, 393, 764, 18666, 11, 50976], "temperature": 0.0, "avg_logprob": -0.15122763315836588, "compression_ratio": 1.697080291970803, "no_speech_prob": 0.000616573030129075}, {"id": 108, "seek": 64848, "start": 660.72, "end": 666.32, "text": " or we can use programs on a computer. So abstractly on a Turing machine, for instance,", "tokens": [50976, 420, 321, 393, 764, 4268, 322, 257, 3820, 13, 407, 12649, 356, 322, 257, 314, 1345, 3479, 11, 337, 5197, 11, 51256], "temperature": 0.0, "avg_logprob": -0.15122763315836588, "compression_ratio": 1.697080291970803, "no_speech_prob": 0.000616573030129075}, {"id": 109, "seek": 64848, "start": 666.32, "end": 671.6, "text": " or can be a general purpose computer. So and there are of course, lots of models of you can", "tokens": [51256, 420, 393, 312, 257, 2674, 4334, 3820, 13, 407, 293, 456, 366, 295, 1164, 11, 3195, 295, 5245, 295, 291, 393, 51520], "temperature": 0.0, "avg_logprob": -0.15122763315836588, "compression_ratio": 1.697080291970803, "no_speech_prob": 0.000616573030129075}, {"id": 110, "seek": 64848, "start": 671.6, "end": 676.5600000000001, "text": " say maybe it's 101 and then 100 zeros and 100 ones, that's a model, right? But they're simpler", "tokens": [51520, 584, 1310, 309, 311, 21055, 293, 550, 2319, 35193, 293, 2319, 2306, 11, 300, 311, 257, 2316, 11, 558, 30, 583, 436, 434, 18587, 51768], "temperature": 0.0, "avg_logprob": -0.15122763315836588, "compression_ratio": 1.697080291970803, "no_speech_prob": 0.000616573030129075}, {"id": 111, "seek": 67656, "start": 676.56, "end": 682.64, "text": " models, there's a model print one loop. Now that also explains the data. And if you push", "tokens": [50364, 5245, 11, 456, 311, 257, 2316, 4482, 472, 6367, 13, 823, 300, 611, 13948, 264, 1412, 13, 400, 498, 291, 2944, 50668], "temperature": 0.0, "avg_logprob": -0.09562897889510445, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.0014776531606912613}, {"id": 112, "seek": 67656, "start": 682.64, "end": 688.4799999999999, "text": " that to the extreme, you are looking for the shortest program, which if you run this program", "tokens": [50668, 300, 281, 264, 8084, 11, 291, 366, 1237, 337, 264, 31875, 1461, 11, 597, 498, 291, 1190, 341, 1461, 50960], "temperature": 0.0, "avg_logprob": -0.09562897889510445, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.0014776531606912613}, {"id": 113, "seek": 67656, "start": 688.4799999999999, "end": 694.7199999999999, "text": " reproduces the data you have, it will not stop, it will continue naturally. And this you take", "tokens": [50960, 11408, 887, 264, 1412, 291, 362, 11, 309, 486, 406, 1590, 11, 309, 486, 2354, 8195, 13, 400, 341, 291, 747, 51272], "temperature": 0.0, "avg_logprob": -0.09562897889510445, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.0014776531606912613}, {"id": 114, "seek": 67656, "start": 694.7199999999999, "end": 699.76, "text": " for your prediction. And on the sequence of ones, it's very plausible, right, that print one loop", "tokens": [51272, 337, 428, 17630, 13, 400, 322, 264, 8310, 295, 2306, 11, 309, 311, 588, 39925, 11, 558, 11, 300, 4482, 472, 6367, 51524], "temperature": 0.0, "avg_logprob": -0.09562897889510445, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.0014776531606912613}, {"id": 115, "seek": 67656, "start": 699.76, "end": 705.76, "text": " is the shortest program, we can give some more complex examples like 12345. What comes next,", "tokens": [51524, 307, 264, 31875, 1461, 11, 321, 393, 976, 512, 544, 3997, 5110, 411, 34466, 8465, 13, 708, 1487, 958, 11, 51824], "temperature": 0.0, "avg_logprob": -0.09562897889510445, "compression_ratio": 1.7323420074349443, "no_speech_prob": 0.0014776531606912613}, {"id": 116, "seek": 70576, "start": 705.76, "end": 711.84, "text": " the short program is again, you know, counter. And so that is, roughly speaking, how Solomar's", "tokens": [50364, 264, 2099, 1461, 307, 797, 11, 291, 458, 11, 5682, 13, 400, 370, 300, 307, 11, 9810, 4124, 11, 577, 7026, 298, 289, 311, 50668], "temperature": 0.0, "avg_logprob": -0.15187630771605437, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.0007545999251306057}, {"id": 117, "seek": 70576, "start": 711.84, "end": 718.4, "text": " induction works. The extra twist is that it can also deal with noisy data. So if you have, for", "tokens": [50668, 33371, 1985, 13, 440, 2857, 8203, 307, 300, 309, 393, 611, 2028, 365, 24518, 1412, 13, 407, 498, 291, 362, 11, 337, 50996], "temperature": 0.0, "avg_logprob": -0.15187630771605437, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.0007545999251306057}, {"id": 118, "seek": 70576, "start": 718.4, "end": 723.04, "text": " instance, a coin flip, say a biased coin, which comes up head with 60% probability,", "tokens": [50996, 5197, 11, 257, 11464, 7929, 11, 584, 257, 28035, 11464, 11, 597, 1487, 493, 1378, 365, 4060, 4, 8482, 11, 51228], "temperature": 0.0, "avg_logprob": -0.15187630771605437, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.0007545999251306057}, {"id": 119, "seek": 70576, "start": 724.48, "end": 729.2, "text": " then it will predict, it will learn and figure this out. And after a while, it predict or the next", "tokens": [51300, 550, 309, 486, 6069, 11, 309, 486, 1466, 293, 2573, 341, 484, 13, 400, 934, 257, 1339, 11, 309, 6069, 420, 264, 958, 51536], "temperature": 0.0, "avg_logprob": -0.15187630771605437, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.0007545999251306057}, {"id": 120, "seek": 70576, "start": 730.24, "end": 734.16, "text": " coin flip will be head with probability 60%. So it's the stochastic version of that.", "tokens": [51588, 11464, 7929, 486, 312, 1378, 365, 8482, 4060, 6856, 407, 309, 311, 264, 342, 8997, 2750, 3037, 295, 300, 13, 51784], "temperature": 0.0, "avg_logprob": -0.15187630771605437, "compression_ratio": 1.6498194945848375, "no_speech_prob": 0.0007545999251306057}, {"id": 121, "seek": 73416, "start": 734.7199999999999, "end": 738.64, "text": " But the goal is the dream is always the search for the short program.", "tokens": [50392, 583, 264, 3387, 307, 264, 3055, 307, 1009, 264, 3164, 337, 264, 2099, 1461, 13, 50588], "temperature": 0.0, "avg_logprob": -0.15911495580082446, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.0018384098075330257}, {"id": 122, "seek": 73416, "start": 738.64, "end": 743.92, "text": " Yes. Yeah. Well, in Solomar of induction, precisely what you do is, so you combine. So", "tokens": [50588, 1079, 13, 865, 13, 1042, 11, 294, 7026, 298, 289, 295, 33371, 11, 13402, 437, 291, 360, 307, 11, 370, 291, 10432, 13, 407, 50852], "temperature": 0.0, "avg_logprob": -0.15911495580082446, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.0018384098075330257}, {"id": 123, "seek": 73416, "start": 743.92, "end": 749.52, "text": " looking for the shortest program is like applying opax razor, like looking for the simplest theory.", "tokens": [50852, 1237, 337, 264, 31875, 1461, 307, 411, 9275, 999, 2797, 30478, 11, 411, 1237, 337, 264, 22811, 5261, 13, 51132], "temperature": 0.0, "avg_logprob": -0.15911495580082446, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.0018384098075330257}, {"id": 124, "seek": 73416, "start": 749.52, "end": 754.64, "text": " There's also Epicoros principle, which says, if you have multiple hypotheses, which equally well", "tokens": [51132, 821, 311, 611, 26785, 284, 329, 8665, 11, 597, 1619, 11, 498, 291, 362, 3866, 49969, 11, 597, 12309, 731, 51388], "temperature": 0.0, "avg_logprob": -0.15911495580082446, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.0018384098075330257}, {"id": 125, "seek": 73416, "start": 754.64, "end": 759.28, "text": " describe your data, don't discard any of them, keep all of them around, you never know. And you", "tokens": [51388, 6786, 428, 1412, 11, 500, 380, 31597, 604, 295, 552, 11, 1066, 439, 295, 552, 926, 11, 291, 1128, 458, 13, 400, 291, 51620], "temperature": 0.0, "avg_logprob": -0.15911495580082446, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.0018384098075330257}, {"id": 126, "seek": 75928, "start": 759.28, "end": 764.24, "text": " can put that together and say, okay, I have a bias towards simplicity, but I don't rule out the", "tokens": [50364, 393, 829, 300, 1214, 293, 584, 11, 1392, 11, 286, 362, 257, 12577, 3030, 25632, 11, 457, 286, 500, 380, 4978, 484, 264, 50612], "temperature": 0.0, "avg_logprob": -0.1288715383057953, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.0010483207879588008}, {"id": 127, "seek": 75928, "start": 764.24, "end": 771.28, "text": " larger models. And technically, what we do is we weigh the shorter models higher and the longer", "tokens": [50612, 4833, 5245, 13, 400, 12120, 11, 437, 321, 360, 307, 321, 13843, 264, 11639, 5245, 2946, 293, 264, 2854, 50964], "temperature": 0.0, "avg_logprob": -0.1288715383057953, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.0010483207879588008}, {"id": 128, "seek": 75928, "start": 771.28, "end": 780.0, "text": " models lower. And you use a Bayesian techniques, you have a prior, and which is precisely two to", "tokens": [50964, 5245, 3126, 13, 400, 291, 764, 257, 7840, 42434, 7512, 11, 291, 362, 257, 4059, 11, 293, 597, 307, 13402, 732, 281, 51400], "temperature": 0.0, "avg_logprob": -0.1288715383057953, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.0010483207879588008}, {"id": 129, "seek": 75928, "start": 780.0, "end": 785.28, "text": " the minus the complexity of the program. And you weigh all this hypothesis and takes this mixture,", "tokens": [51400, 264, 3175, 264, 14024, 295, 264, 1461, 13, 400, 291, 13843, 439, 341, 17291, 293, 2516, 341, 9925, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1288715383057953, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.0010483207879588008}, {"id": 130, "seek": 78528, "start": 785.28, "end": 789.76, "text": " and then you get also this stochasticity in. Yeah, like many of your ideas, that's just a", "tokens": [50364, 293, 550, 291, 483, 611, 341, 342, 8997, 2750, 507, 294, 13, 865, 11, 411, 867, 295, 428, 3487, 11, 300, 311, 445, 257, 50588], "temperature": 0.0, "avg_logprob": -0.1286485956070271, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.00321958982385695}, {"id": 131, "seek": 78528, "start": 789.76, "end": 795.92, "text": " beautiful idea of weighing based on the simplicity of the program. I love that. That seems to me", "tokens": [50588, 2238, 1558, 295, 31986, 2361, 322, 264, 25632, 295, 264, 1461, 13, 286, 959, 300, 13, 663, 2544, 281, 385, 50896], "temperature": 0.0, "avg_logprob": -0.1286485956070271, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.00321958982385695}, {"id": 132, "seek": 78528, "start": 795.92, "end": 803.1999999999999, "text": " maybe a very human-centric concept seems to be a very appealing way of discovering good programs", "tokens": [50896, 1310, 257, 588, 1952, 12, 45300, 3410, 2544, 281, 312, 257, 588, 23842, 636, 295, 24773, 665, 4268, 51260], "temperature": 0.0, "avg_logprob": -0.1286485956070271, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.00321958982385695}, {"id": 133, "seek": 78528, "start": 803.1999999999999, "end": 810.72, "text": " in this world. You've used the term compression quite a bit. I think it's a beautiful idea,", "tokens": [51260, 294, 341, 1002, 13, 509, 600, 1143, 264, 1433, 19355, 1596, 257, 857, 13, 286, 519, 309, 311, 257, 2238, 1558, 11, 51636], "temperature": 0.0, "avg_logprob": -0.1286485956070271, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.00321958982385695}, {"id": 134, "seek": 81072, "start": 810.72, "end": 817.2, "text": " sort of, we just talked about simplicity, and maybe science or just all of our intellectual", "tokens": [50364, 1333, 295, 11, 321, 445, 2825, 466, 25632, 11, 293, 1310, 3497, 420, 445, 439, 295, 527, 12576, 50688], "temperature": 0.0, "avg_logprob": -0.11976173125117658, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0027573446277529}, {"id": 135, "seek": 81072, "start": 817.2, "end": 823.6, "text": " pursuits is basically the attempt to compress the complexity all around us into something simple.", "tokens": [50688, 7088, 7688, 307, 1936, 264, 5217, 281, 14778, 264, 14024, 439, 926, 505, 666, 746, 2199, 13, 51008], "temperature": 0.0, "avg_logprob": -0.11976173125117658, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0027573446277529}, {"id": 136, "seek": 81072, "start": 823.6, "end": 832.32, "text": " So what does this word mean to you, compression? I essentially have already explained it. So", "tokens": [51008, 407, 437, 775, 341, 1349, 914, 281, 291, 11, 19355, 30, 286, 4476, 362, 1217, 8825, 309, 13, 407, 51444], "temperature": 0.0, "avg_logprob": -0.11976173125117658, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0027573446277529}, {"id": 137, "seek": 81072, "start": 832.32, "end": 840.1600000000001, "text": " it compression means, for me, finding short programs for the data or the phenomenon at hand.", "tokens": [51444, 309, 19355, 1355, 11, 337, 385, 11, 5006, 2099, 4268, 337, 264, 1412, 420, 264, 14029, 412, 1011, 13, 51836], "temperature": 0.0, "avg_logprob": -0.11976173125117658, "compression_ratio": 1.6163793103448276, "no_speech_prob": 0.0027573446277529}, {"id": 138, "seek": 84016, "start": 840.16, "end": 845.8399999999999, "text": " You could interpret it more widely as finding simple theories, which can be mathematical theories,", "tokens": [50364, 509, 727, 7302, 309, 544, 13371, 382, 5006, 2199, 13667, 11, 597, 393, 312, 18894, 13667, 11, 50648], "temperature": 0.0, "avg_logprob": -0.15481806362376493, "compression_ratio": 1.6125, "no_speech_prob": 0.00045102660078555346}, {"id": 139, "seek": 84016, "start": 845.8399999999999, "end": 852.4, "text": " or maybe even informal, like just in words, compression means finding short descriptions,", "tokens": [50648, 420, 1310, 754, 24342, 11, 411, 445, 294, 2283, 11, 19355, 1355, 5006, 2099, 24406, 11, 50976], "temperature": 0.0, "avg_logprob": -0.15481806362376493, "compression_ratio": 1.6125, "no_speech_prob": 0.00045102660078555346}, {"id": 140, "seek": 84016, "start": 852.4, "end": 861.4399999999999, "text": " explanations, programs for the data. Do you see science as a kind of our human attempt at compression?", "tokens": [50976, 28708, 11, 4268, 337, 264, 1412, 13, 1144, 291, 536, 3497, 382, 257, 733, 295, 527, 1952, 5217, 412, 19355, 30, 51428], "temperature": 0.0, "avg_logprob": -0.15481806362376493, "compression_ratio": 1.6125, "no_speech_prob": 0.00045102660078555346}, {"id": 141, "seek": 84016, "start": 862.24, "end": 866.3199999999999, "text": " So we're speaking more generally, because when you say programs, you're kind of zooming in on a", "tokens": [51468, 407, 321, 434, 4124, 544, 5101, 11, 570, 562, 291, 584, 4268, 11, 291, 434, 733, 295, 48226, 294, 322, 257, 51672], "temperature": 0.0, "avg_logprob": -0.15481806362376493, "compression_ratio": 1.6125, "no_speech_prob": 0.00045102660078555346}, {"id": 142, "seek": 86632, "start": 866.32, "end": 870.72, "text": " particular, sort of, almost like a computer science, artificial intelligence focus. But", "tokens": [50364, 1729, 11, 1333, 295, 11, 1920, 411, 257, 3820, 3497, 11, 11677, 7599, 1879, 13, 583, 50584], "temperature": 0.0, "avg_logprob": -0.13799653486772018, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.000495418906211853}, {"id": 143, "seek": 86632, "start": 870.72, "end": 875.9200000000001, "text": " do you see all of human endeavor as a kind of compression? Well, at least all of science,", "tokens": [50584, 360, 291, 536, 439, 295, 1952, 34975, 382, 257, 733, 295, 19355, 30, 1042, 11, 412, 1935, 439, 295, 3497, 11, 50844], "temperature": 0.0, "avg_logprob": -0.13799653486772018, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.000495418906211853}, {"id": 144, "seek": 86632, "start": 875.9200000000001, "end": 881.44, "text": " I see as an endeavor of compression, not all of humanity, maybe. And, well, there are also some", "tokens": [50844, 286, 536, 382, 364, 34975, 295, 19355, 11, 406, 439, 295, 10243, 11, 1310, 13, 400, 11, 731, 11, 456, 366, 611, 512, 51120], "temperature": 0.0, "avg_logprob": -0.13799653486772018, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.000495418906211853}, {"id": 145, "seek": 86632, "start": 881.44, "end": 886.8000000000001, "text": " other aspects of science, like experimental design, right? I mean, we create experiments", "tokens": [51120, 661, 7270, 295, 3497, 11, 411, 17069, 1715, 11, 558, 30, 286, 914, 11, 321, 1884, 12050, 51388], "temperature": 0.0, "avg_logprob": -0.13799653486772018, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.000495418906211853}, {"id": 146, "seek": 86632, "start": 886.8000000000001, "end": 892.48, "text": " specifically to get extra knowledge. And this is, that isn't part of the decision-making process.", "tokens": [51388, 4682, 281, 483, 2857, 3601, 13, 400, 341, 307, 11, 300, 1943, 380, 644, 295, 264, 3537, 12, 12402, 1399, 13, 51672], "temperature": 0.0, "avg_logprob": -0.13799653486772018, "compression_ratio": 1.7358490566037736, "no_speech_prob": 0.000495418906211853}, {"id": 147, "seek": 89248, "start": 893.2, "end": 899.2, "text": " But once we have the data to understand the data is essentially compression. So I don't see any", "tokens": [50400, 583, 1564, 321, 362, 264, 1412, 281, 1223, 264, 1412, 307, 4476, 19355, 13, 407, 286, 500, 380, 536, 604, 50700], "temperature": 0.0, "avg_logprob": -0.18811197165983268, "compression_ratio": 1.64, "no_speech_prob": 0.00036826127325184643}, {"id": 148, "seek": 89248, "start": 899.2, "end": 907.52, "text": " difference between compression, understanding, and prediction. So we're jumping around topics a", "tokens": [50700, 2649, 1296, 19355, 11, 3701, 11, 293, 17630, 13, 407, 321, 434, 11233, 926, 8378, 257, 51116], "temperature": 0.0, "avg_logprob": -0.18811197165983268, "compression_ratio": 1.64, "no_speech_prob": 0.00036826127325184643}, {"id": 149, "seek": 89248, "start": 907.52, "end": 913.76, "text": " little bit, but returning back to simplicity, a fascinating concept of comagra of complexity.", "tokens": [51116, 707, 857, 11, 457, 12678, 646, 281, 25632, 11, 257, 10343, 3410, 295, 395, 559, 424, 295, 14024, 13, 51428], "temperature": 0.0, "avg_logprob": -0.18811197165983268, "compression_ratio": 1.64, "no_speech_prob": 0.00036826127325184643}, {"id": 150, "seek": 89248, "start": 914.32, "end": 921.2, "text": " So in your sense, do most objects in our mathematical universe have high comagra of", "tokens": [51456, 407, 294, 428, 2020, 11, 360, 881, 6565, 294, 527, 18894, 6445, 362, 1090, 395, 559, 424, 295, 51800], "temperature": 0.0, "avg_logprob": -0.18811197165983268, "compression_ratio": 1.64, "no_speech_prob": 0.00036826127325184643}, {"id": 151, "seek": 92120, "start": 921.2, "end": 925.84, "text": " complexity? And maybe what is, first of all, what is comagra of complexity?", "tokens": [50364, 14024, 30, 400, 1310, 437, 307, 11, 700, 295, 439, 11, 437, 307, 395, 559, 424, 295, 14024, 30, 50596], "temperature": 0.0, "avg_logprob": -0.09354563509480338, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.00048773991875350475}, {"id": 152, "seek": 92120, "start": 925.84, "end": 933.76, "text": " Okay, comagra of complexity is a notion of simplicity or complexity. And it takes the", "tokens": [50596, 1033, 11, 395, 559, 424, 295, 14024, 307, 257, 10710, 295, 25632, 420, 14024, 13, 400, 309, 2516, 264, 50992], "temperature": 0.0, "avg_logprob": -0.09354563509480338, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.00048773991875350475}, {"id": 153, "seek": 92120, "start": 933.76, "end": 939.6, "text": " compression view to the extreme. So I explained before that if you have some data sequence,", "tokens": [50992, 19355, 1910, 281, 264, 8084, 13, 407, 286, 8825, 949, 300, 498, 291, 362, 512, 1412, 8310, 11, 51284], "temperature": 0.0, "avg_logprob": -0.09354563509480338, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.00048773991875350475}, {"id": 154, "seek": 92120, "start": 939.6, "end": 945.36, "text": " just think about a file on a computer and best sort of, you know, just a string of bits. And", "tokens": [51284, 445, 519, 466, 257, 3991, 322, 257, 3820, 293, 1151, 1333, 295, 11, 291, 458, 11, 445, 257, 6798, 295, 9239, 13, 400, 51572], "temperature": 0.0, "avg_logprob": -0.09354563509480338, "compression_ratio": 1.6634615384615385, "no_speech_prob": 0.00048773991875350475}, {"id": 155, "seek": 94536, "start": 946.32, "end": 952.16, "text": " if you, and we have data compressors, like we compress big files into, say, zip files with", "tokens": [50412, 498, 291, 11, 293, 321, 362, 1412, 14778, 830, 11, 411, 321, 14778, 955, 7098, 666, 11, 584, 11, 20730, 7098, 365, 50704], "temperature": 0.0, "avg_logprob": -0.15416571849913108, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.0009397731046192348}, {"id": 156, "seek": 94536, "start": 952.16, "end": 957.92, "text": " certain compressors. And you can also produce self-extracting RKFs. That means as an executable,", "tokens": [50704, 1629, 14778, 830, 13, 400, 291, 393, 611, 5258, 2698, 12, 3828, 1897, 278, 497, 42, 37, 82, 13, 663, 1355, 382, 364, 7568, 712, 11, 50992], "temperature": 0.0, "avg_logprob": -0.15416571849913108, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.0009397731046192348}, {"id": 157, "seek": 94536, "start": 957.92, "end": 963.12, "text": " if you run it, it reproduces your original file without needing an extra decompressor. It's just", "tokens": [50992, 498, 291, 1190, 309, 11, 309, 11408, 887, 428, 3380, 3991, 1553, 18006, 364, 2857, 22867, 735, 284, 13, 467, 311, 445, 51252], "temperature": 0.0, "avg_logprob": -0.15416571849913108, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.0009397731046192348}, {"id": 158, "seek": 94536, "start": 963.12, "end": 968.88, "text": " a decompressor plus the RKF together in one. And now there are better and worse compressors. And", "tokens": [51252, 257, 22867, 735, 284, 1804, 264, 497, 42, 37, 1214, 294, 472, 13, 400, 586, 456, 366, 1101, 293, 5324, 14778, 830, 13, 400, 51540], "temperature": 0.0, "avg_logprob": -0.15416571849913108, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.0009397731046192348}, {"id": 159, "seek": 94536, "start": 968.88, "end": 974.32, "text": " you can ask, what is the ultimate compressor? So what is the shortest possible self-extracting", "tokens": [51540, 291, 393, 1029, 11, 437, 307, 264, 9705, 28765, 30, 407, 437, 307, 264, 31875, 1944, 2698, 12, 3828, 1897, 278, 51812], "temperature": 0.0, "avg_logprob": -0.15416571849913108, "compression_ratio": 1.8237547892720307, "no_speech_prob": 0.0009397731046192348}, {"id": 160, "seek": 97432, "start": 974.32, "end": 980.48, "text": " RKF you could produce for a certain data set, which reproduces the data set. And the length of", "tokens": [50364, 497, 42, 37, 291, 727, 5258, 337, 257, 1629, 1412, 992, 11, 597, 11408, 887, 264, 1412, 992, 13, 400, 264, 4641, 295, 50672], "temperature": 0.0, "avg_logprob": -0.1164822293142987, "compression_ratio": 1.7976653696498055, "no_speech_prob": 0.000755048356950283}, {"id": 161, "seek": 97432, "start": 980.48, "end": 987.12, "text": " this is called the comagra of complexity. And arguably, that is the information content in", "tokens": [50672, 341, 307, 1219, 264, 395, 559, 424, 295, 14024, 13, 400, 26771, 11, 300, 307, 264, 1589, 2701, 294, 51004], "temperature": 0.0, "avg_logprob": -0.1164822293142987, "compression_ratio": 1.7976653696498055, "no_speech_prob": 0.000755048356950283}, {"id": 162, "seek": 97432, "start": 987.12, "end": 991.2, "text": " the data set. I mean, if the data set is very redundant or very boring, you can compress it", "tokens": [51004, 264, 1412, 992, 13, 286, 914, 11, 498, 264, 1412, 992, 307, 588, 40997, 420, 588, 9989, 11, 291, 393, 14778, 309, 51208], "temperature": 0.0, "avg_logprob": -0.1164822293142987, "compression_ratio": 1.7976653696498055, "no_speech_prob": 0.000755048356950283}, {"id": 163, "seek": 97432, "start": 991.2, "end": 996.48, "text": " very well. So the information content should be low. And, you know, it is low according to this", "tokens": [51208, 588, 731, 13, 407, 264, 1589, 2701, 820, 312, 2295, 13, 400, 11, 291, 458, 11, 309, 307, 2295, 4650, 281, 341, 51472], "temperature": 0.0, "avg_logprob": -0.1164822293142987, "compression_ratio": 1.7976653696498055, "no_speech_prob": 0.000755048356950283}, {"id": 164, "seek": 97432, "start": 996.48, "end": 1001.9200000000001, "text": " definition. Does the length of the shortest program that summarizes the data? Yes. Yeah.", "tokens": [51472, 7123, 13, 4402, 264, 4641, 295, 264, 31875, 1461, 300, 14611, 5660, 264, 1412, 30, 1079, 13, 865, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1164822293142987, "compression_ratio": 1.7976653696498055, "no_speech_prob": 0.000755048356950283}, {"id": 165, "seek": 100192, "start": 1001.92, "end": 1007.8399999999999, "text": " And what's your sense of our universe when we think about the different", "tokens": [50364, 400, 437, 311, 428, 2020, 295, 527, 6445, 562, 321, 519, 466, 264, 819, 50660], "temperature": 0.0, "avg_logprob": -0.13744620579044994, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.00030519693973474205}, {"id": 166, "seek": 100192, "start": 1010.0, "end": 1016.3199999999999, "text": " objects in our universe that we try concepts or whatever at every level? Do they have higher", "tokens": [50768, 6565, 294, 527, 6445, 300, 321, 853, 10392, 420, 2035, 412, 633, 1496, 30, 1144, 436, 362, 2946, 51084], "temperature": 0.0, "avg_logprob": -0.13744620579044994, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.00030519693973474205}, {"id": 167, "seek": 100192, "start": 1016.3199999999999, "end": 1022.56, "text": " or low comagra of complexity? So what's the hope? Do we have a lot of hope in being able to summarize", "tokens": [51084, 420, 2295, 395, 559, 424, 295, 14024, 30, 407, 437, 311, 264, 1454, 30, 1144, 321, 362, 257, 688, 295, 1454, 294, 885, 1075, 281, 20858, 51396], "temperature": 0.0, "avg_logprob": -0.13744620579044994, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.00030519693973474205}, {"id": 168, "seek": 100192, "start": 1023.28, "end": 1028.72, "text": " much of our world? That's a tricky and difficult question. So", "tokens": [51432, 709, 295, 527, 1002, 30, 663, 311, 257, 12414, 293, 2252, 1168, 13, 407, 51704], "temperature": 0.0, "avg_logprob": -0.13744620579044994, "compression_ratio": 1.561904761904762, "no_speech_prob": 0.00030519693973474205}, {"id": 169, "seek": 102872, "start": 1029.3600000000001, "end": 1034.0, "text": " as I said before, I believe that the whole universe, based on the evidence we have,", "tokens": [50396, 382, 286, 848, 949, 11, 286, 1697, 300, 264, 1379, 6445, 11, 2361, 322, 264, 4467, 321, 362, 11, 50628], "temperature": 0.0, "avg_logprob": -0.21795607020712307, "compression_ratio": 1.81496062992126, "no_speech_prob": 0.00033002893906086683}, {"id": 170, "seek": 102872, "start": 1034.0, "end": 1039.92, "text": " is very simple. So it has a very short description, the whole. Sorry to linger on that.", "tokens": [50628, 307, 588, 2199, 13, 407, 309, 575, 257, 588, 2099, 3855, 11, 264, 1379, 13, 4919, 281, 45657, 322, 300, 13, 50924], "temperature": 0.0, "avg_logprob": -0.21795607020712307, "compression_ratio": 1.81496062992126, "no_speech_prob": 0.00033002893906086683}, {"id": 171, "seek": 102872, "start": 1039.92, "end": 1045.92, "text": " The whole universe, what does that mean? Do you mean at the very basic fundamental level in order", "tokens": [50924, 440, 1379, 6445, 11, 437, 775, 300, 914, 30, 1144, 291, 914, 412, 264, 588, 3875, 8088, 1496, 294, 1668, 51224], "temperature": 0.0, "avg_logprob": -0.21795607020712307, "compression_ratio": 1.81496062992126, "no_speech_prob": 0.00033002893906086683}, {"id": 172, "seek": 102872, "start": 1045.92, "end": 1052.16, "text": " to create the universe? Yes. Yeah. So you need a very short program when you run it. To get the", "tokens": [51224, 281, 1884, 264, 6445, 30, 1079, 13, 865, 13, 407, 291, 643, 257, 588, 2099, 1461, 562, 291, 1190, 309, 13, 1407, 483, 264, 51536], "temperature": 0.0, "avg_logprob": -0.21795607020712307, "compression_ratio": 1.81496062992126, "no_speech_prob": 0.00033002893906086683}, {"id": 173, "seek": 102872, "start": 1052.16, "end": 1056.88, "text": " thing going. To get the thing going, and then it will reproduce our universe. There's a problem", "tokens": [51536, 551, 516, 13, 1407, 483, 264, 551, 516, 11, 293, 550, 309, 486, 29501, 527, 6445, 13, 821, 311, 257, 1154, 51772], "temperature": 0.0, "avg_logprob": -0.21795607020712307, "compression_ratio": 1.81496062992126, "no_speech_prob": 0.00033002893906086683}, {"id": 174, "seek": 105688, "start": 1057.8400000000001, "end": 1064.5600000000002, "text": " with noise. We can come back to that later, possibly. Is noise a problem or is it a bug or a", "tokens": [50412, 365, 5658, 13, 492, 393, 808, 646, 281, 300, 1780, 11, 6264, 13, 1119, 5658, 257, 1154, 420, 307, 309, 257, 7426, 420, 257, 50748], "temperature": 0.0, "avg_logprob": -0.13741572216303663, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0031688977032899857}, {"id": 175, "seek": 105688, "start": 1064.5600000000002, "end": 1072.4, "text": " feature? I would say it makes our life as a scientist really, really much harder. I mean,", "tokens": [50748, 4111, 30, 286, 576, 584, 309, 1669, 527, 993, 382, 257, 12662, 534, 11, 534, 709, 6081, 13, 286, 914, 11, 51140], "temperature": 0.0, "avg_logprob": -0.13741572216303663, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0031688977032899857}, {"id": 176, "seek": 105688, "start": 1072.4, "end": 1077.2, "text": " think about it without noise. We wouldn't need all of the statistics. But that maybe we wouldn't", "tokens": [51140, 519, 466, 309, 1553, 5658, 13, 492, 2759, 380, 643, 439, 295, 264, 12523, 13, 583, 300, 1310, 321, 2759, 380, 51380], "temperature": 0.0, "avg_logprob": -0.13741572216303663, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0031688977032899857}, {"id": 177, "seek": 105688, "start": 1077.2, "end": 1083.2, "text": " feel like there's a free will. Maybe we need that for the... This is an illusion that noise can give", "tokens": [51380, 841, 411, 456, 311, 257, 1737, 486, 13, 2704, 321, 643, 300, 337, 264, 485, 639, 307, 364, 18854, 300, 5658, 393, 976, 51680], "temperature": 0.0, "avg_logprob": -0.13741572216303663, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.0031688977032899857}, {"id": 178, "seek": 108320, "start": 1083.28, "end": 1088.96, "text": " you free will. At least in that way, it's a feature. But also, if you don't have noise,", "tokens": [50368, 291, 1737, 486, 13, 1711, 1935, 294, 300, 636, 11, 309, 311, 257, 4111, 13, 583, 611, 11, 498, 291, 500, 380, 362, 5658, 11, 50652], "temperature": 0.0, "avg_logprob": -0.12887041792910323, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.0018650447018444538}, {"id": 179, "seek": 108320, "start": 1088.96, "end": 1095.1200000000001, "text": " you have chaotic phenomena, which are effectively like noise. So we can't get away with statistics", "tokens": [50652, 291, 362, 27013, 22004, 11, 597, 366, 8659, 411, 5658, 13, 407, 321, 393, 380, 483, 1314, 365, 12523, 50960], "temperature": 0.0, "avg_logprob": -0.12887041792910323, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.0018650447018444538}, {"id": 180, "seek": 108320, "start": 1095.1200000000001, "end": 1099.52, "text": " even then. I mean, think about rolling a dice and forget about quantum mechanics and you know", "tokens": [50960, 754, 550, 13, 286, 914, 11, 519, 466, 9439, 257, 10313, 293, 2870, 466, 13018, 12939, 293, 291, 458, 51180], "temperature": 0.0, "avg_logprob": -0.12887041792910323, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.0018650447018444538}, {"id": 181, "seek": 108320, "start": 1099.52, "end": 1104.96, "text": " exactly how you throw it. But I mean, it's still so hard to compute the trajectory that, effectively,", "tokens": [51180, 2293, 577, 291, 3507, 309, 13, 583, 286, 914, 11, 309, 311, 920, 370, 1152, 281, 14722, 264, 21512, 300, 11, 8659, 11, 51452], "temperature": 0.0, "avg_logprob": -0.12887041792910323, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.0018650447018444538}, {"id": 182, "seek": 108320, "start": 1104.96, "end": 1111.3600000000001, "text": " it is best to model it as coming out with a number, with probability one over six.", "tokens": [51452, 309, 307, 1151, 281, 2316, 309, 382, 1348, 484, 365, 257, 1230, 11, 365, 8482, 472, 670, 2309, 13, 51772], "temperature": 0.0, "avg_logprob": -0.12887041792910323, "compression_ratio": 1.648936170212766, "no_speech_prob": 0.0018650447018444538}, {"id": 183, "seek": 111136, "start": 1111.9199999999998, "end": 1119.28, "text": " But from this sort of philosophical Kolmogorov complexity perspective, if we didn't have noise,", "tokens": [50392, 583, 490, 341, 1333, 295, 25066, 26137, 76, 664, 284, 5179, 14024, 4585, 11, 498, 321, 994, 380, 362, 5658, 11, 50760], "temperature": 0.0, "avg_logprob": -0.14675975728918006, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0007205303991213441}, {"id": 184, "seek": 111136, "start": 1119.84, "end": 1126.6399999999999, "text": " then arguably you could describe the whole universe as standard model plus", "tokens": [50788, 550, 26771, 291, 727, 6786, 264, 1379, 6445, 382, 3832, 2316, 1804, 51128], "temperature": 0.0, "avg_logprob": -0.14675975728918006, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0007205303991213441}, {"id": 185, "seek": 111136, "start": 1126.6399999999999, "end": 1130.8, "text": " generativity. I mean, we don't have a theory of everything yet, but sort of assuming we are", "tokens": [51128, 1337, 30142, 13, 286, 914, 11, 321, 500, 380, 362, 257, 5261, 295, 1203, 1939, 11, 457, 1333, 295, 11926, 321, 366, 51336], "temperature": 0.0, "avg_logprob": -0.14675975728918006, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0007205303991213441}, {"id": 186, "seek": 111136, "start": 1130.8, "end": 1135.6, "text": " close to it or have it here, plus the initial conditions, which may hopefully be simple. And", "tokens": [51336, 1998, 281, 309, 420, 362, 309, 510, 11, 1804, 264, 5883, 4487, 11, 597, 815, 4696, 312, 2199, 13, 400, 51576], "temperature": 0.0, "avg_logprob": -0.14675975728918006, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0007205303991213441}, {"id": 187, "seek": 111136, "start": 1135.6, "end": 1140.6399999999999, "text": " then you just run it and then you would reproduce the universe. But that's spoiled by noise or by", "tokens": [51576, 550, 291, 445, 1190, 309, 293, 550, 291, 576, 29501, 264, 6445, 13, 583, 300, 311, 32439, 538, 5658, 420, 538, 51828], "temperature": 0.0, "avg_logprob": -0.14675975728918006, "compression_ratio": 1.641304347826087, "no_speech_prob": 0.0007205303991213441}, {"id": 188, "seek": 114064, "start": 1140.72, "end": 1148.3200000000002, "text": " chaotic systems or by initial conditions, which may be complex. So now if we don't take the whole", "tokens": [50368, 27013, 3652, 420, 538, 5883, 4487, 11, 597, 815, 312, 3997, 13, 407, 586, 498, 321, 500, 380, 747, 264, 1379, 50748], "temperature": 0.0, "avg_logprob": -0.11735970633370536, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0009393969085067511}, {"id": 189, "seek": 114064, "start": 1148.3200000000002, "end": 1155.76, "text": " universe with just a subset, just take planet Earth. Planet Earth cannot be compressed into", "tokens": [50748, 6445, 365, 445, 257, 25993, 11, 445, 747, 5054, 4755, 13, 22146, 4755, 2644, 312, 30353, 666, 51120], "temperature": 0.0, "avg_logprob": -0.11735970633370536, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0009393969085067511}, {"id": 190, "seek": 114064, "start": 1155.76, "end": 1160.96, "text": " a couple of equations. This is a hugely complex system. So interesting. So when you look at the", "tokens": [51120, 257, 1916, 295, 11787, 13, 639, 307, 257, 27417, 3997, 1185, 13, 407, 1880, 13, 407, 562, 291, 574, 412, 264, 51380], "temperature": 0.0, "avg_logprob": -0.11735970633370536, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0009393969085067511}, {"id": 191, "seek": 114064, "start": 1160.96, "end": 1166.64, "text": " window, the whole thing might be simple, but when you just take a small window, then it may become", "tokens": [51380, 4910, 11, 264, 1379, 551, 1062, 312, 2199, 11, 457, 562, 291, 445, 747, 257, 1359, 4910, 11, 550, 309, 815, 1813, 51664], "temperature": 0.0, "avg_logprob": -0.11735970633370536, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0009393969085067511}, {"id": 192, "seek": 116664, "start": 1166.64, "end": 1173.2, "text": " complex. And that may be counterintuitive. But there's a very nice analogy, the book, the library", "tokens": [50364, 3997, 13, 400, 300, 815, 312, 5682, 686, 48314, 13, 583, 456, 311, 257, 588, 1481, 21663, 11, 264, 1446, 11, 264, 6405, 50692], "temperature": 0.0, "avg_logprob": -0.13054619765863185, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.0018366542644798756}, {"id": 193, "seek": 116664, "start": 1173.2, "end": 1178.16, "text": " of all books. So imagine you have a normal library with interesting books, and you go there, great.", "tokens": [50692, 295, 439, 3642, 13, 407, 3811, 291, 362, 257, 2710, 6405, 365, 1880, 3642, 11, 293, 291, 352, 456, 11, 869, 13, 50940], "temperature": 0.0, "avg_logprob": -0.13054619765863185, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.0018366542644798756}, {"id": 194, "seek": 116664, "start": 1178.16, "end": 1184.16, "text": " Lots of information and huge, quite complex. So now I create a library which contains all", "tokens": [50940, 15908, 295, 1589, 293, 2603, 11, 1596, 3997, 13, 407, 586, 286, 1884, 257, 6405, 597, 8306, 439, 51240], "temperature": 0.0, "avg_logprob": -0.13054619765863185, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.0018366542644798756}, {"id": 195, "seek": 116664, "start": 1184.16, "end": 1190.0800000000002, "text": " possible books, say, of 500 pages. So the first book just has AAA over all the pages. The next book", "tokens": [51240, 1944, 3642, 11, 584, 11, 295, 5923, 7183, 13, 407, 264, 700, 1446, 445, 575, 34347, 670, 439, 264, 7183, 13, 440, 958, 1446, 51536], "temperature": 0.0, "avg_logprob": -0.13054619765863185, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.0018366542644798756}, {"id": 196, "seek": 116664, "start": 1190.0800000000002, "end": 1195.2, "text": " AAA and ends with B. And so on. I create this library of all books. I can write a super short", "tokens": [51536, 34347, 293, 5314, 365, 363, 13, 400, 370, 322, 13, 286, 1884, 341, 6405, 295, 439, 3642, 13, 286, 393, 2464, 257, 1687, 2099, 51792], "temperature": 0.0, "avg_logprob": -0.13054619765863185, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.0018366542644798756}, {"id": 197, "seek": 119520, "start": 1195.2, "end": 1200.0800000000002, "text": " program which creates this library. So this library which has all books has zero information", "tokens": [50364, 1461, 597, 7829, 341, 6405, 13, 407, 341, 6405, 597, 575, 439, 3642, 575, 4018, 1589, 50608], "temperature": 0.0, "avg_logprob": -0.11152925945463635, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0004172693006694317}, {"id": 198, "seek": 119520, "start": 1200.0800000000002, "end": 1204.64, "text": " content. And you take a subset of this library and suddenly you have a lot of information in there.", "tokens": [50608, 2701, 13, 400, 291, 747, 257, 25993, 295, 341, 6405, 293, 5800, 291, 362, 257, 688, 295, 1589, 294, 456, 13, 50836], "temperature": 0.0, "avg_logprob": -0.11152925945463635, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0004172693006694317}, {"id": 199, "seek": 119520, "start": 1205.2, "end": 1209.76, "text": " So that's fascinating. I think one of the most beautiful object, mathematical objects that", "tokens": [50864, 407, 300, 311, 10343, 13, 286, 519, 472, 295, 264, 881, 2238, 2657, 11, 18894, 6565, 300, 51092], "temperature": 0.0, "avg_logprob": -0.11152925945463635, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0004172693006694317}, {"id": 200, "seek": 119520, "start": 1209.76, "end": 1214.16, "text": " at least today seems to be understudied or under talked about is cellular automata.", "tokens": [51092, 412, 1935, 965, 2544, 281, 312, 833, 28349, 1091, 420, 833, 2825, 466, 307, 29267, 3553, 3274, 13, 51312], "temperature": 0.0, "avg_logprob": -0.11152925945463635, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0004172693006694317}, {"id": 201, "seek": 119520, "start": 1215.28, "end": 1220.0, "text": " What lessons do you draw from sort of the game of life for cellular automata, where you start with", "tokens": [51368, 708, 8820, 360, 291, 2642, 490, 1333, 295, 264, 1216, 295, 993, 337, 29267, 3553, 3274, 11, 689, 291, 722, 365, 51604], "temperature": 0.0, "avg_logprob": -0.11152925945463635, "compression_ratio": 1.7651515151515151, "no_speech_prob": 0.0004172693006694317}, {"id": 202, "seek": 122000, "start": 1220.0, "end": 1226.16, "text": " the simple rules, just like you're describing with the universe, and somehow complexity emerges.", "tokens": [50364, 264, 2199, 4474, 11, 445, 411, 291, 434, 16141, 365, 264, 6445, 11, 293, 6063, 14024, 38965, 13, 50672], "temperature": 0.0, "avg_logprob": -0.12865228880019414, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.010984527878463268}, {"id": 203, "seek": 122000, "start": 1226.16, "end": 1233.2, "text": " Do you feel like you have an intuitive grasp on the behavior, the fascinating behavior of such", "tokens": [50672, 1144, 291, 841, 411, 291, 362, 364, 21769, 21743, 322, 264, 5223, 11, 264, 10343, 5223, 295, 1270, 51024], "temperature": 0.0, "avg_logprob": -0.12865228880019414, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.010984527878463268}, {"id": 204, "seek": 122000, "start": 1233.2, "end": 1238.64, "text": " systems, where some, like you said, some chaotic behavior could happen, some complexity could", "tokens": [51024, 3652, 11, 689, 512, 11, 411, 291, 848, 11, 512, 27013, 5223, 727, 1051, 11, 512, 14024, 727, 51296], "temperature": 0.0, "avg_logprob": -0.12865228880019414, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.010984527878463268}, {"id": 205, "seek": 122000, "start": 1238.64, "end": 1244.64, "text": " emerge, some, it could die out in some very rigid structures. Do you have a sense about", "tokens": [51296, 21511, 11, 512, 11, 309, 727, 978, 484, 294, 512, 588, 22195, 9227, 13, 1144, 291, 362, 257, 2020, 466, 51596], "temperature": 0.0, "avg_logprob": -0.12865228880019414, "compression_ratio": 1.7429906542056075, "no_speech_prob": 0.010984527878463268}, {"id": 206, "seek": 124464, "start": 1245.3600000000001, "end": 1250.8000000000002, "text": " cellular automata that somehow transfers maybe to the bigger questions of our universe?", "tokens": [50400, 29267, 3553, 3274, 300, 6063, 29137, 1310, 281, 264, 3801, 1651, 295, 527, 6445, 30, 50672], "temperature": 0.0, "avg_logprob": -0.18836483588585487, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0036486140452325344}, {"id": 207, "seek": 124464, "start": 1250.8000000000002, "end": 1255.2, "text": " Yeah, the cellular automata and especially the converse game of life is really great because", "tokens": [50672, 865, 11, 264, 29267, 3553, 3274, 293, 2318, 264, 416, 4308, 1216, 295, 993, 307, 534, 869, 570, 50892], "temperature": 0.0, "avg_logprob": -0.18836483588585487, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0036486140452325344}, {"id": 208, "seek": 124464, "start": 1255.2, "end": 1259.3600000000001, "text": " this rule is so simple. You can explain it to every child and even by hand you can simulate a", "tokens": [50892, 341, 4978, 307, 370, 2199, 13, 509, 393, 2903, 309, 281, 633, 1440, 293, 754, 538, 1011, 291, 393, 27817, 257, 51100], "temperature": 0.0, "avg_logprob": -0.18836483588585487, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0036486140452325344}, {"id": 209, "seek": 124464, "start": 1259.3600000000001, "end": 1265.92, "text": " little bit. And you see this beautiful patterns emerge and people have proven that it's even", "tokens": [51100, 707, 857, 13, 400, 291, 536, 341, 2238, 8294, 21511, 293, 561, 362, 12785, 300, 309, 311, 754, 51428], "temperature": 0.0, "avg_logprob": -0.18836483588585487, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0036486140452325344}, {"id": 210, "seek": 124464, "start": 1265.92, "end": 1270.48, "text": " touring complete. You cannot just use a computer to simulate game of life, but you can also use", "tokens": [51428, 32487, 3566, 13, 509, 2644, 445, 764, 257, 3820, 281, 27817, 1216, 295, 993, 11, 457, 291, 393, 611, 764, 51656], "temperature": 0.0, "avg_logprob": -0.18836483588585487, "compression_ratio": 1.7807692307692307, "no_speech_prob": 0.0036486140452325344}, {"id": 211, "seek": 127048, "start": 1270.48, "end": 1279.52, "text": " game of life to simulate any computer. That is truly amazing. And it's the prime example probably to", "tokens": [50364, 1216, 295, 993, 281, 27817, 604, 3820, 13, 663, 307, 4908, 2243, 13, 400, 309, 311, 264, 5835, 1365, 1391, 281, 50816], "temperature": 0.0, "avg_logprob": -0.11172657222538204, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.0038809238467365503}, {"id": 212, "seek": 127048, "start": 1280.24, "end": 1286.48, "text": " demonstrate that very simple rules can lead to very rich phenomena. And people sometimes,", "tokens": [50852, 11698, 300, 588, 2199, 4474, 393, 1477, 281, 588, 4593, 22004, 13, 400, 561, 2171, 11, 51164], "temperature": 0.0, "avg_logprob": -0.11172657222538204, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.0038809238467365503}, {"id": 213, "seek": 127048, "start": 1286.48, "end": 1291.6, "text": " you know, how can, how is chemistry and biology so rich? I mean, this can't be based on simple", "tokens": [51164, 291, 458, 11, 577, 393, 11, 577, 307, 12558, 293, 14956, 370, 4593, 30, 286, 914, 11, 341, 393, 380, 312, 2361, 322, 2199, 51420], "temperature": 0.0, "avg_logprob": -0.11172657222538204, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.0038809238467365503}, {"id": 214, "seek": 127048, "start": 1291.6, "end": 1298.32, "text": " rules. But no, we know quantum electrodynamics describes all of chemistry. And we come later", "tokens": [51420, 4474, 13, 583, 572, 11, 321, 458, 13018, 44216, 5216, 1167, 15626, 439, 295, 12558, 13, 400, 321, 808, 1780, 51756], "temperature": 0.0, "avg_logprob": -0.11172657222538204, "compression_ratio": 1.5815899581589958, "no_speech_prob": 0.0038809238467365503}, {"id": 215, "seek": 129832, "start": 1298.3999999999999, "end": 1302.8799999999999, "text": " back to that. I claim intelligence can be explained or described in one single equation,", "tokens": [50368, 646, 281, 300, 13, 286, 3932, 7599, 393, 312, 8825, 420, 7619, 294, 472, 2167, 5367, 11, 50592], "temperature": 0.0, "avg_logprob": -0.12972580514303067, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002081663580611348}, {"id": 216, "seek": 129832, "start": 1302.8799999999999, "end": 1309.2, "text": " this very rich phenomenon. You asked also about whether, you know, I understand this", "tokens": [50592, 341, 588, 4593, 14029, 13, 509, 2351, 611, 466, 1968, 11, 291, 458, 11, 286, 1223, 341, 50908], "temperature": 0.0, "avg_logprob": -0.12972580514303067, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002081663580611348}, {"id": 217, "seek": 129832, "start": 1309.2, "end": 1316.72, "text": " phenomenon and it's probably not. And this is saying you never understand really things,", "tokens": [50908, 14029, 293, 309, 311, 1391, 406, 13, 400, 341, 307, 1566, 291, 1128, 1223, 534, 721, 11, 51284], "temperature": 0.0, "avg_logprob": -0.12972580514303067, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002081663580611348}, {"id": 218, "seek": 129832, "start": 1316.72, "end": 1324.72, "text": " you just get used to them. And I think pretty used to cellular automata. So you believe that", "tokens": [51284, 291, 445, 483, 1143, 281, 552, 13, 400, 286, 519, 1238, 1143, 281, 29267, 3553, 3274, 13, 407, 291, 1697, 300, 51684], "temperature": 0.0, "avg_logprob": -0.12972580514303067, "compression_ratio": 1.5990990990990992, "no_speech_prob": 0.002081663580611348}, {"id": 219, "seek": 132472, "start": 1324.72, "end": 1329.76, "text": " you understand now why this phenomenon happens. But I give you a different example. I didn't play", "tokens": [50364, 291, 1223, 586, 983, 341, 14029, 2314, 13, 583, 286, 976, 291, 257, 819, 1365, 13, 286, 994, 380, 862, 50616], "temperature": 0.0, "avg_logprob": -0.2284452165876116, "compression_ratio": 1.59375, "no_speech_prob": 0.014476030133664608}, {"id": 220, "seek": 132472, "start": 1329.76, "end": 1335.3600000000001, "text": " too much this converse game of life, but a little bit more with fractals and with the", "tokens": [50616, 886, 709, 341, 416, 4308, 1216, 295, 993, 11, 457, 257, 707, 857, 544, 365, 17948, 1124, 293, 365, 264, 50896], "temperature": 0.0, "avg_logprob": -0.2284452165876116, "compression_ratio": 1.59375, "no_speech_prob": 0.014476030133664608}, {"id": 221, "seek": 132472, "start": 1335.3600000000001, "end": 1339.76, "text": " Mandelbrot set. And you need beautiful, you know, patterns, just look Mandelbrot set.", "tokens": [50896, 15458, 338, 1443, 310, 992, 13, 400, 291, 643, 2238, 11, 291, 458, 11, 8294, 11, 445, 574, 15458, 338, 1443, 310, 992, 13, 51116], "temperature": 0.0, "avg_logprob": -0.2284452165876116, "compression_ratio": 1.59375, "no_speech_prob": 0.014476030133664608}, {"id": 222, "seek": 132472, "start": 1340.96, "end": 1344.64, "text": " And well, when the computers were really slow and I just had a black and white", "tokens": [51176, 400, 731, 11, 562, 264, 10807, 645, 534, 2964, 293, 286, 445, 632, 257, 2211, 293, 2418, 51360], "temperature": 0.0, "avg_logprob": -0.2284452165876116, "compression_ratio": 1.59375, "no_speech_prob": 0.014476030133664608}, {"id": 223, "seek": 132472, "start": 1344.64, "end": 1348.48, "text": " monitor and programmed my own programs on an assembler too.", "tokens": [51360, 6002, 293, 31092, 452, 1065, 4268, 322, 364, 8438, 1918, 886, 13, 51552], "temperature": 0.0, "avg_logprob": -0.2284452165876116, "compression_ratio": 1.59375, "no_speech_prob": 0.014476030133664608}, {"id": 224, "seek": 134848, "start": 1349.44, "end": 1356.96, "text": " Wow. Wow, you're legit to get these fractals on the screen. And it was mesmerized and much", "tokens": [50412, 3153, 13, 3153, 11, 291, 434, 10275, 281, 483, 613, 17948, 1124, 322, 264, 2568, 13, 400, 309, 390, 3813, 936, 1602, 293, 709, 50788], "temperature": 0.0, "avg_logprob": -0.14454497713031192, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00376421632245183}, {"id": 225, "seek": 134848, "start": 1356.96, "end": 1361.52, "text": " later. So I returned to this, you know, every couple of years. And then I tried to understand", "tokens": [50788, 1780, 13, 407, 286, 8752, 281, 341, 11, 291, 458, 11, 633, 1916, 295, 924, 13, 400, 550, 286, 3031, 281, 1223, 51016], "temperature": 0.0, "avg_logprob": -0.14454497713031192, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00376421632245183}, {"id": 226, "seek": 134848, "start": 1361.52, "end": 1368.4, "text": " what is going on. And you can understand a little bit. So I tried to derive the locations,", "tokens": [51016, 437, 307, 516, 322, 13, 400, 291, 393, 1223, 257, 707, 857, 13, 407, 286, 3031, 281, 28446, 264, 9253, 11, 51360], "temperature": 0.0, "avg_logprob": -0.14454497713031192, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00376421632245183}, {"id": 227, "seek": 134848, "start": 1368.4, "end": 1377.28, "text": " you know, there are these circles and the apple shape. And then you have smaller Mandelbrot sets", "tokens": [51360, 291, 458, 11, 456, 366, 613, 13040, 293, 264, 10606, 3909, 13, 400, 550, 291, 362, 4356, 15458, 338, 1443, 310, 6352, 51804], "temperature": 0.0, "avg_logprob": -0.14454497713031192, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.00376421632245183}, {"id": 228, "seek": 137728, "start": 1377.28, "end": 1383.36, "text": " recursively in this set. And there's a way to mathematically by solving high order polynomials", "tokens": [50364, 20560, 3413, 294, 341, 992, 13, 400, 456, 311, 257, 636, 281, 44003, 538, 12606, 1090, 1668, 22560, 12356, 50668], "temperature": 0.0, "avg_logprob": -0.09171999636150542, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.002887815935537219}, {"id": 229, "seek": 137728, "start": 1383.36, "end": 1389.44, "text": " to figure out where these centers are and what size they are approximately. And by sort of", "tokens": [50668, 281, 2573, 484, 689, 613, 10898, 366, 293, 437, 2744, 436, 366, 10447, 13, 400, 538, 1333, 295, 50972], "temperature": 0.0, "avg_logprob": -0.09171999636150542, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.002887815935537219}, {"id": 230, "seek": 137728, "start": 1389.44, "end": 1398.0, "text": " mathematically approaching this problem, you slowly get a feeling of why things are like they are.", "tokens": [50972, 44003, 14908, 341, 1154, 11, 291, 5692, 483, 257, 2633, 295, 983, 721, 366, 411, 436, 366, 13, 51400], "temperature": 0.0, "avg_logprob": -0.09171999636150542, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.002887815935537219}, {"id": 231, "seek": 137728, "start": 1398.0, "end": 1404.8, "text": " And that sort of isn't, you know, first step to understanding why this rich phenomenon.", "tokens": [51400, 400, 300, 1333, 295, 1943, 380, 11, 291, 458, 11, 700, 1823, 281, 3701, 983, 341, 4593, 14029, 13, 51740], "temperature": 0.0, "avg_logprob": -0.09171999636150542, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.002887815935537219}, {"id": 232, "seek": 140480, "start": 1404.8, "end": 1408.8, "text": " Do you think it's possible? What's your intuition? Do you think it's possible to reverse engineer", "tokens": [50364, 1144, 291, 519, 309, 311, 1944, 30, 708, 311, 428, 24002, 30, 1144, 291, 519, 309, 311, 1944, 281, 9943, 11403, 50564], "temperature": 0.0, "avg_logprob": -0.14895584469749815, "compression_ratio": 1.85546875, "no_speech_prob": 0.0025905980728566647}, {"id": 233, "seek": 140480, "start": 1408.8, "end": 1415.52, "text": " and find the short program that generated the these fractals, sort of by what looking at the", "tokens": [50564, 293, 915, 264, 2099, 1461, 300, 10833, 264, 613, 17948, 1124, 11, 1333, 295, 538, 437, 1237, 412, 264, 50900], "temperature": 0.0, "avg_logprob": -0.14895584469749815, "compression_ratio": 1.85546875, "no_speech_prob": 0.0025905980728566647}, {"id": 234, "seek": 140480, "start": 1415.52, "end": 1422.32, "text": " fractals? Well, in principle, yes. Yeah. So I mean, in principle, what you can do is you take,", "tokens": [50900, 17948, 1124, 30, 1042, 11, 294, 8665, 11, 2086, 13, 865, 13, 407, 286, 914, 11, 294, 8665, 11, 437, 291, 393, 360, 307, 291, 747, 11, 51240], "temperature": 0.0, "avg_logprob": -0.14895584469749815, "compression_ratio": 1.85546875, "no_speech_prob": 0.0025905980728566647}, {"id": 235, "seek": 140480, "start": 1422.32, "end": 1426.3999999999999, "text": " you know, any data set, you know, you take these fractals, or you take whatever your data set,", "tokens": [51240, 291, 458, 11, 604, 1412, 992, 11, 291, 458, 11, 291, 747, 613, 17948, 1124, 11, 420, 291, 747, 2035, 428, 1412, 992, 11, 51444], "temperature": 0.0, "avg_logprob": -0.14895584469749815, "compression_ratio": 1.85546875, "no_speech_prob": 0.0025905980728566647}, {"id": 236, "seek": 140480, "start": 1426.3999999999999, "end": 1433.28, "text": " whatever you have. So a picture of Conveys game of life. And you run through all programs, you", "tokens": [51444, 2035, 291, 362, 13, 407, 257, 3036, 295, 2656, 303, 749, 1216, 295, 993, 13, 400, 291, 1190, 807, 439, 4268, 11, 291, 51788], "temperature": 0.0, "avg_logprob": -0.14895584469749815, "compression_ratio": 1.85546875, "no_speech_prob": 0.0025905980728566647}, {"id": 237, "seek": 143328, "start": 1433.28, "end": 1437.2, "text": " take a program of size one, two, three, four, and all these programs around them all in parallel in", "tokens": [50364, 747, 257, 1461, 295, 2744, 472, 11, 732, 11, 1045, 11, 1451, 11, 293, 439, 613, 4268, 926, 552, 439, 294, 8952, 294, 50560], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 238, "seek": 143328, "start": 1437.2, "end": 1442.96, "text": " so called dovetailing fashion, give them computational resources, first one 50%, second one half", "tokens": [50560, 370, 1219, 360, 9771, 23315, 6700, 11, 976, 552, 28270, 3593, 11, 700, 472, 2625, 8923, 1150, 472, 1922, 50848], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 239, "seek": 143328, "start": 1442.96, "end": 1449.12, "text": " resources and so on and let them run, wait until they hold, give an output, compare it to your data.", "tokens": [50848, 3593, 293, 370, 322, 293, 718, 552, 1190, 11, 1699, 1826, 436, 1797, 11, 976, 364, 5598, 11, 6794, 309, 281, 428, 1412, 13, 51156], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 240, "seek": 143328, "start": 1449.12, "end": 1453.6, "text": " And if some of these programs produce the correct data, then you stop and then you have already", "tokens": [51156, 400, 498, 512, 295, 613, 4268, 5258, 264, 3006, 1412, 11, 550, 291, 1590, 293, 550, 291, 362, 1217, 51380], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 241, "seek": 143328, "start": 1453.6, "end": 1458.32, "text": " some program, it may be a long program, because it's faster. And then you continue and you get", "tokens": [51380, 512, 1461, 11, 309, 815, 312, 257, 938, 1461, 11, 570, 309, 311, 4663, 13, 400, 550, 291, 2354, 293, 291, 483, 51616], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 242, "seek": 143328, "start": 1458.32, "end": 1463.04, "text": " shorter and shorter programs until you eventually find the shortest program. The interesting thing", "tokens": [51616, 11639, 293, 11639, 4268, 1826, 291, 4728, 915, 264, 31875, 1461, 13, 440, 1880, 551, 51852], "temperature": 0.0, "avg_logprob": -0.12338911785798914, "compression_ratio": 1.8753993610223643, "no_speech_prob": 0.004532645456492901}, {"id": 243, "seek": 146304, "start": 1463.04, "end": 1467.36, "text": " you can ever know whether it's a shortest program, because there could be an even shorter program,", "tokens": [50364, 291, 393, 1562, 458, 1968, 309, 311, 257, 31875, 1461, 11, 570, 456, 727, 312, 364, 754, 11639, 1461, 11, 50580], "temperature": 0.0, "avg_logprob": -0.15658584662846156, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.003646058961749077}, {"id": 244, "seek": 146304, "start": 1467.36, "end": 1474.08, "text": " which is just even slower. And you just have to wait here. But asymptotically, and actually", "tokens": [50580, 597, 307, 445, 754, 14009, 13, 400, 291, 445, 362, 281, 1699, 510, 13, 583, 35114, 310, 984, 11, 293, 767, 50916], "temperature": 0.0, "avg_logprob": -0.15658584662846156, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.003646058961749077}, {"id": 245, "seek": 146304, "start": 1474.08, "end": 1479.2, "text": " after the final time, you have the shortest program. So this is a theoretical, but completely", "tokens": [50916, 934, 264, 2572, 565, 11, 291, 362, 264, 31875, 1461, 13, 407, 341, 307, 257, 20864, 11, 457, 2584, 51172], "temperature": 0.0, "avg_logprob": -0.15658584662846156, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.003646058961749077}, {"id": 246, "seek": 146304, "start": 1479.2, "end": 1487.84, "text": " impractical way of finding the underlying structure in every data set. And that was a", "tokens": [51172, 704, 1897, 804, 636, 295, 5006, 264, 14217, 3877, 294, 633, 1412, 992, 13, 400, 300, 390, 257, 51604], "temperature": 0.0, "avg_logprob": -0.15658584662846156, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.003646058961749077}, {"id": 247, "seek": 146304, "start": 1487.84, "end": 1491.84, "text": " lot more of induction does and Convogorov complexity. In practice, of course, we have to", "tokens": [51604, 688, 544, 295, 33371, 775, 293, 2656, 85, 664, 284, 5179, 14024, 13, 682, 3124, 11, 295, 1164, 11, 321, 362, 281, 51804], "temperature": 0.0, "avg_logprob": -0.15658584662846156, "compression_ratio": 1.712686567164179, "no_speech_prob": 0.003646058961749077}, {"id": 248, "seek": 149184, "start": 1491.84, "end": 1500.6399999999999, "text": " approach the problem more intelligently. And then if you take resource limitations into account,", "tokens": [50364, 3109, 264, 1154, 544, 5613, 2276, 13, 400, 550, 498, 291, 747, 7684, 15705, 666, 2696, 11, 50804], "temperature": 0.0, "avg_logprob": -0.11392872832542242, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0015480763977393508}, {"id": 249, "seek": 149184, "start": 1500.6399999999999, "end": 1506.24, "text": " there's once the field of pseudo random numbers, yeah, and these are random numbers. So these are", "tokens": [50804, 456, 311, 1564, 264, 2519, 295, 35899, 4974, 3547, 11, 1338, 11, 293, 613, 366, 4974, 3547, 13, 407, 613, 366, 51084], "temperature": 0.0, "avg_logprob": -0.11392872832542242, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0015480763977393508}, {"id": 250, "seek": 149184, "start": 1506.24, "end": 1512.8, "text": " deterministic sequences, but no algorithm which is fast, fast means runs in polynomial time can", "tokens": [51084, 15957, 3142, 22978, 11, 457, 572, 9284, 597, 307, 2370, 11, 2370, 1355, 6676, 294, 26110, 565, 393, 51412], "temperature": 0.0, "avg_logprob": -0.11392872832542242, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0015480763977393508}, {"id": 251, "seek": 149184, "start": 1512.8, "end": 1518.56, "text": " detect that it's actually deterministic. So we can produce interesting, I mean, random numbers,", "tokens": [51412, 5531, 300, 309, 311, 767, 15957, 3142, 13, 407, 321, 393, 5258, 1880, 11, 286, 914, 11, 4974, 3547, 11, 51700], "temperature": 0.0, "avg_logprob": -0.11392872832542242, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.0015480763977393508}, {"id": 252, "seek": 151856, "start": 1518.56, "end": 1523.36, "text": " maybe not that interesting, but just an example, we can produce complex looking data.", "tokens": [50364, 1310, 406, 300, 1880, 11, 457, 445, 364, 1365, 11, 321, 393, 5258, 3997, 1237, 1412, 13, 50604], "temperature": 0.0, "avg_logprob": -0.13739755929234515, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0004877766768913716}, {"id": 253, "seek": 151856, "start": 1524.24, "end": 1528.8, "text": " And we can then prove that no fast algorithm can detect the underlying pattern.", "tokens": [50648, 400, 321, 393, 550, 7081, 300, 572, 2370, 9284, 393, 5531, 264, 14217, 5102, 13, 50876], "temperature": 0.0, "avg_logprob": -0.13739755929234515, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0004877766768913716}, {"id": 254, "seek": 151856, "start": 1531.6, "end": 1534.08, "text": " Which is unfortunately,", "tokens": [51016, 3013, 307, 7015, 11, 51140], "temperature": 0.0, "avg_logprob": -0.13739755929234515, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0004877766768913716}, {"id": 255, "seek": 151856, "start": 1537.2, "end": 1541.28, "text": " that's a big challenge for our search for simple programs in the space of artificial intelligence,", "tokens": [51296, 300, 311, 257, 955, 3430, 337, 527, 3164, 337, 2199, 4268, 294, 264, 1901, 295, 11677, 7599, 11, 51500], "temperature": 0.0, "avg_logprob": -0.13739755929234515, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0004877766768913716}, {"id": 256, "seek": 151856, "start": 1541.28, "end": 1546.0, "text": " perhaps. Yes, it definitely is wanted vision intelligence. And it's quite surprising that", "tokens": [51500, 4317, 13, 1079, 11, 309, 2138, 307, 1415, 5201, 7599, 13, 400, 309, 311, 1596, 8830, 300, 51736], "temperature": 0.0, "avg_logprob": -0.13739755929234515, "compression_ratio": 1.5949367088607596, "no_speech_prob": 0.0004877766768913716}, {"id": 257, "seek": 154600, "start": 1546.0, "end": 1553.28, "text": " it's, I can't say easy. I mean, physicists worked really hard to find these theories, but apparently", "tokens": [50364, 309, 311, 11, 286, 393, 380, 584, 1858, 13, 286, 914, 11, 48716, 2732, 534, 1152, 281, 915, 613, 13667, 11, 457, 7970, 50728], "temperature": 0.0, "avg_logprob": -0.14876607259114583, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0012252226006239653}, {"id": 258, "seek": 154600, "start": 1553.28, "end": 1557.84, "text": " it was possible for human minds to find these simple rules in the universe. It could have", "tokens": [50728, 309, 390, 1944, 337, 1952, 9634, 281, 915, 613, 2199, 4474, 294, 264, 6445, 13, 467, 727, 362, 50956], "temperature": 0.0, "avg_logprob": -0.14876607259114583, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0012252226006239653}, {"id": 259, "seek": 154600, "start": 1557.84, "end": 1562.72, "text": " been different, right? It could have been different. It's, it's, it's awe inspiring.", "tokens": [50956, 668, 819, 11, 558, 30, 467, 727, 362, 668, 819, 13, 467, 311, 11, 309, 311, 11, 309, 311, 30912, 15883, 13, 51200], "temperature": 0.0, "avg_logprob": -0.14876607259114583, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0012252226006239653}, {"id": 260, "seek": 154600, "start": 1564.56, "end": 1572.32, "text": " So let me ask another absurdly big question. What is intelligence in your view?", "tokens": [51292, 407, 718, 385, 1029, 1071, 19774, 356, 955, 1168, 13, 708, 307, 7599, 294, 428, 1910, 30, 51680], "temperature": 0.0, "avg_logprob": -0.14876607259114583, "compression_ratio": 1.628440366972477, "no_speech_prob": 0.0012252226006239653}, {"id": 261, "seek": 157232, "start": 1573.12, "end": 1575.04, "text": " So I have, of course, a definition.", "tokens": [50404, 407, 286, 362, 11, 295, 1164, 11, 257, 7123, 13, 50500], "temperature": 0.0, "avg_logprob": -0.18442003250122072, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00413255812600255}, {"id": 262, "seek": 157232, "start": 1576.96, "end": 1580.8, "text": " I wasn't sure what you're going to say, because you could have just as easy said, I have no clue.", "tokens": [50596, 286, 2067, 380, 988, 437, 291, 434, 516, 281, 584, 11, 570, 291, 727, 362, 445, 382, 1858, 848, 11, 286, 362, 572, 13602, 13, 50788], "temperature": 0.0, "avg_logprob": -0.18442003250122072, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00413255812600255}, {"id": 263, "seek": 157232, "start": 1581.36, "end": 1589.9199999999998, "text": " Which many people would say, but I'm not modest in this question. So the, the informal version,", "tokens": [50816, 3013, 867, 561, 576, 584, 11, 457, 286, 478, 406, 25403, 294, 341, 1168, 13, 407, 264, 11, 264, 24342, 3037, 11, 51244], "temperature": 0.0, "avg_logprob": -0.18442003250122072, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00413255812600255}, {"id": 264, "seek": 157232, "start": 1591.6, "end": 1596.96, "text": " which I worked out together with Shane, like who co-founded the mind is that intelligence", "tokens": [51328, 597, 286, 2732, 484, 1214, 365, 25865, 11, 411, 567, 598, 12, 49547, 264, 1575, 307, 300, 7599, 51596], "temperature": 0.0, "avg_logprob": -0.18442003250122072, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00413255812600255}, {"id": 265, "seek": 157232, "start": 1596.96, "end": 1601.76, "text": " measures and agents ability to perform well in a wide range of environments.", "tokens": [51596, 8000, 293, 12554, 3485, 281, 2042, 731, 294, 257, 4874, 3613, 295, 12388, 13, 51836], "temperature": 0.0, "avg_logprob": -0.18442003250122072, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.00413255812600255}, {"id": 266, "seek": 160232, "start": 1603.12, "end": 1609.12, "text": " So that doesn't sound very impressive. And what it, these words have been very carefully chosen.", "tokens": [50404, 407, 300, 1177, 380, 1626, 588, 8992, 13, 400, 437, 309, 11, 613, 2283, 362, 668, 588, 7500, 8614, 13, 50704], "temperature": 0.0, "avg_logprob": -0.09808725240279217, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0002823717368301004}, {"id": 267, "seek": 160232, "start": 1609.76, "end": 1616.8, "text": " And there is a mathematical theory behind that. And we come back to that later. And if you look at", "tokens": [50736, 400, 456, 307, 257, 18894, 5261, 2261, 300, 13, 400, 321, 808, 646, 281, 300, 1780, 13, 400, 498, 291, 574, 412, 51088], "temperature": 0.0, "avg_logprob": -0.09808725240279217, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0002823717368301004}, {"id": 268, "seek": 160232, "start": 1616.8, "end": 1622.8, "text": " this, this definition by itself, it seems like, yeah, okay, but it seems a lot of things are", "tokens": [51088, 341, 11, 341, 7123, 538, 2564, 11, 309, 2544, 411, 11, 1338, 11, 1392, 11, 457, 309, 2544, 257, 688, 295, 721, 366, 51388], "temperature": 0.0, "avg_logprob": -0.09808725240279217, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0002823717368301004}, {"id": 269, "seek": 160232, "start": 1622.8, "end": 1630.32, "text": " missing. But if you think it's true, then you realize that most, and I claim all of the other", "tokens": [51388, 5361, 13, 583, 498, 291, 519, 309, 311, 2074, 11, 550, 291, 4325, 300, 881, 11, 293, 286, 3932, 439, 295, 264, 661, 51764], "temperature": 0.0, "avg_logprob": -0.09808725240279217, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.0002823717368301004}, {"id": 270, "seek": 163032, "start": 1630.32, "end": 1634.6399999999999, "text": " traits, at least of rational intelligence, which we usually associate with intelligence,", "tokens": [50364, 19526, 11, 412, 1935, 295, 15090, 7599, 11, 597, 321, 2673, 14644, 365, 7599, 11, 50580], "temperature": 0.0, "avg_logprob": -0.10440167878803454, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.001304132747463882}, {"id": 271, "seek": 163032, "start": 1634.6399999999999, "end": 1640.8799999999999, "text": " are emergent phenomena from this definition, like, you know, creativity, memorization, planning,", "tokens": [50580, 366, 4345, 6930, 22004, 490, 341, 7123, 11, 411, 11, 291, 458, 11, 12915, 11, 10560, 2144, 11, 5038, 11, 50892], "temperature": 0.0, "avg_logprob": -0.10440167878803454, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.001304132747463882}, {"id": 272, "seek": 163032, "start": 1640.8799999999999, "end": 1646.56, "text": " knowledge. You all need that in order to perform well in a wide range of environments.", "tokens": [50892, 3601, 13, 509, 439, 643, 300, 294, 1668, 281, 2042, 731, 294, 257, 4874, 3613, 295, 12388, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10440167878803454, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.001304132747463882}, {"id": 273, "seek": 163032, "start": 1647.52, "end": 1650.1599999999999, "text": " So you don't have to explicitly mention that in a definition.", "tokens": [51224, 407, 291, 500, 380, 362, 281, 20803, 2152, 300, 294, 257, 7123, 13, 51356], "temperature": 0.0, "avg_logprob": -0.10440167878803454, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.001304132747463882}, {"id": 274, "seek": 163032, "start": 1650.1599999999999, "end": 1655.2, "text": " Interesting. So yeah, so the consciousness, abstract reasoning, all these kinds of things", "tokens": [51356, 14711, 13, 407, 1338, 11, 370, 264, 10081, 11, 12649, 21577, 11, 439, 613, 3685, 295, 721, 51608], "temperature": 0.0, "avg_logprob": -0.10440167878803454, "compression_ratio": 1.6370656370656371, "no_speech_prob": 0.001304132747463882}, {"id": 275, "seek": 165520, "start": 1655.2, "end": 1662.0, "text": " are just emergent phenomena that help you in towards, can you say the definition again?", "tokens": [50364, 366, 445, 4345, 6930, 22004, 300, 854, 291, 294, 3030, 11, 393, 291, 584, 264, 7123, 797, 30, 50704], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 276, "seek": 165520, "start": 1662.0, "end": 1665.52, "text": " So multiple environments. Did you mention the word goals?", "tokens": [50704, 407, 3866, 12388, 13, 2589, 291, 2152, 264, 1349, 5493, 30, 50880], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 277, "seek": 165520, "start": 1666.24, "end": 1670.0800000000002, "text": " No, but we have an alternative definition instead of performing well, you can just replace it by", "tokens": [50916, 883, 11, 457, 321, 362, 364, 8535, 7123, 2602, 295, 10205, 731, 11, 291, 393, 445, 7406, 309, 538, 51108], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 278, "seek": 165520, "start": 1670.0800000000002, "end": 1675.28, "text": " goals. So intelligence measures and agents ability to achieve goals in a wide range of", "tokens": [51108, 5493, 13, 407, 7599, 8000, 293, 12554, 3485, 281, 4584, 5493, 294, 257, 4874, 3613, 295, 51368], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 279, "seek": 165520, "start": 1675.28, "end": 1678.0800000000002, "text": " environments. That's more or less equal. But interesting, because in there,", "tokens": [51368, 12388, 13, 663, 311, 544, 420, 1570, 2681, 13, 583, 1880, 11, 570, 294, 456, 11, 51508], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 280, "seek": 165520, "start": 1678.0800000000002, "end": 1682.64, "text": " there's an injection of the word goals. So we want to specify there, there should be a goal.", "tokens": [51508, 456, 311, 364, 22873, 295, 264, 1349, 5493, 13, 407, 321, 528, 281, 16500, 456, 11, 456, 820, 312, 257, 3387, 13, 51736], "temperature": 0.0, "avg_logprob": -0.13574351935551085, "compression_ratio": 1.711340206185567, "no_speech_prob": 0.009701232425868511}, {"id": 281, "seek": 168264, "start": 1683.2, "end": 1686.72, "text": " Yeah, but perform well is sort of, what does it mean? It's the same problem.", "tokens": [50392, 865, 11, 457, 2042, 731, 307, 1333, 295, 11, 437, 775, 309, 914, 30, 467, 311, 264, 912, 1154, 13, 50568], "temperature": 0.0, "avg_logprob": -0.15176433114444507, "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.004959698300808668}, {"id": 282, "seek": 168264, "start": 1688.0, "end": 1692.16, "text": " There's a little bit gray area, but it's much closer to something that could be formalized.", "tokens": [50632, 821, 311, 257, 707, 857, 10855, 1859, 11, 457, 309, 311, 709, 4966, 281, 746, 300, 727, 312, 9860, 1602, 13, 50840], "temperature": 0.0, "avg_logprob": -0.15176433114444507, "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.004959698300808668}, {"id": 283, "seek": 168264, "start": 1694.24, "end": 1698.88, "text": " In your view, are humans, where do humans fit into that definition? Are they", "tokens": [50944, 682, 428, 1910, 11, 366, 6255, 11, 689, 360, 6255, 3318, 666, 300, 7123, 30, 2014, 436, 51176], "temperature": 0.0, "avg_logprob": -0.15176433114444507, "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.004959698300808668}, {"id": 284, "seek": 168264, "start": 1699.6000000000001, "end": 1706.96, "text": " general intelligence systems that are able to perform in like, how good are they at fulfilling", "tokens": [51212, 2674, 7599, 3652, 300, 366, 1075, 281, 2042, 294, 411, 11, 577, 665, 366, 436, 412, 25800, 51580], "temperature": 0.0, "avg_logprob": -0.15176433114444507, "compression_ratio": 1.5246636771300448, "no_speech_prob": 0.004959698300808668}, {"id": 285, "seek": 170696, "start": 1706.96, "end": 1710.48, "text": " that definition at performing well in multiple environments?", "tokens": [50364, 300, 7123, 412, 10205, 731, 294, 3866, 12388, 30, 50540], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 286, "seek": 170696, "start": 1711.28, "end": 1715.68, "text": " Yeah, that's a big question. I mean, the humans are performing best among all", "tokens": [50580, 865, 11, 300, 311, 257, 955, 1168, 13, 286, 914, 11, 264, 6255, 366, 10205, 1151, 3654, 439, 50800], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 287, "seek": 170696, "start": 1716.88, "end": 1719.92, "text": " species on Earth. Species we know, we know of. Yeah.", "tokens": [50860, 6172, 322, 4755, 13, 3550, 4629, 321, 458, 11, 321, 458, 295, 13, 865, 13, 51012], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 288, "seek": 170696, "start": 1720.72, "end": 1725.76, "text": " Depends. You could say that trees and plants are doing a better job. They'll probably outlast us.", "tokens": [51052, 4056, 2581, 13, 509, 727, 584, 300, 5852, 293, 5972, 366, 884, 257, 1101, 1691, 13, 814, 603, 1391, 484, 15459, 505, 13, 51304], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 289, "seek": 170696, "start": 1726.4, "end": 1730.4, "text": " So yeah, but they are in a much more narrow environment, right? I mean, you just, you know,", "tokens": [51336, 407, 1338, 11, 457, 436, 366, 294, 257, 709, 544, 9432, 2823, 11, 558, 30, 286, 914, 11, 291, 445, 11, 291, 458, 11, 51536], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 290, "seek": 170696, "start": 1730.4, "end": 1734.72, "text": " have a little bit of air pollution and these trees die and we can adapt, right? We build houses,", "tokens": [51536, 362, 257, 707, 857, 295, 1988, 16727, 293, 613, 5852, 978, 293, 321, 393, 6231, 11, 558, 30, 492, 1322, 8078, 11, 51752], "temperature": 0.0, "avg_logprob": -0.15748130798339843, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0015246375696733594}, {"id": 291, "seek": 173472, "start": 1734.8, "end": 1741.1200000000001, "text": " we build filters, we do geo-engineering. So the multiple environment part.", "tokens": [50368, 321, 1322, 15995, 11, 321, 360, 43198, 12, 25609, 1794, 13, 407, 264, 3866, 2823, 644, 13, 50684], "temperature": 0.0, "avg_logprob": -0.21460182722224747, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.0004440007614903152}, {"id": 292, "seek": 173472, "start": 1741.1200000000001, "end": 1745.1200000000001, "text": " Yeah, that is very important, yes. So that distinguish narrow intelligence from wide", "tokens": [50684, 865, 11, 300, 307, 588, 1021, 11, 2086, 13, 407, 300, 20206, 9432, 7599, 490, 4874, 50884], "temperature": 0.0, "avg_logprob": -0.21460182722224747, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.0004440007614903152}, {"id": 293, "seek": 173472, "start": 1745.1200000000001, "end": 1753.04, "text": " intelligence, also in the AI research. So let me ask the alenturing question, can machines", "tokens": [50884, 7599, 11, 611, 294, 264, 7318, 2132, 13, 407, 718, 385, 1029, 264, 419, 317, 1345, 1168, 11, 393, 8379, 51280], "temperature": 0.0, "avg_logprob": -0.21460182722224747, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.0004440007614903152}, {"id": 294, "seek": 173472, "start": 1753.84, "end": 1760.4, "text": " think? Can machines be intelligent? So in your view, I have to kind of ask, the answer is probably", "tokens": [51320, 519, 30, 1664, 8379, 312, 13232, 30, 407, 294, 428, 1910, 11, 286, 362, 281, 733, 295, 1029, 11, 264, 1867, 307, 1391, 51648], "temperature": 0.0, "avg_logprob": -0.21460182722224747, "compression_ratio": 1.579185520361991, "no_speech_prob": 0.0004440007614903152}, {"id": 295, "seek": 176040, "start": 1760.4, "end": 1767.2, "text": " yes, but I want to kind of hear what your thoughts on it. Can machines be made to fulfill this", "tokens": [50364, 2086, 11, 457, 286, 528, 281, 733, 295, 1568, 437, 428, 4598, 322, 309, 13, 1664, 8379, 312, 1027, 281, 13875, 341, 50704], "temperature": 0.0, "avg_logprob": -0.12041902964094044, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0008033678168430924}, {"id": 296, "seek": 176040, "start": 1767.2, "end": 1773.68, "text": " definition of intelligence, to achieve intelligence? Well, we are sort of getting there and, you know,", "tokens": [50704, 7123, 295, 7599, 11, 281, 4584, 7599, 30, 1042, 11, 321, 366, 1333, 295, 1242, 456, 293, 11, 291, 458, 11, 51028], "temperature": 0.0, "avg_logprob": -0.12041902964094044, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0008033678168430924}, {"id": 297, "seek": 176040, "start": 1773.68, "end": 1779.0400000000002, "text": " on a small scale, we are already there. The wide range of environments are missing,", "tokens": [51028, 322, 257, 1359, 4373, 11, 321, 366, 1217, 456, 13, 440, 4874, 3613, 295, 12388, 366, 5361, 11, 51296], "temperature": 0.0, "avg_logprob": -0.12041902964094044, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0008033678168430924}, {"id": 298, "seek": 176040, "start": 1779.0400000000002, "end": 1784.48, "text": " but we have self-driving cars, we have programs to play go and chess, we have speech recognition.", "tokens": [51296, 457, 321, 362, 2698, 12, 47094, 5163, 11, 321, 362, 4268, 281, 862, 352, 293, 24122, 11, 321, 362, 6218, 11150, 13, 51568], "temperature": 0.0, "avg_logprob": -0.12041902964094044, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0008033678168430924}, {"id": 299, "seek": 176040, "start": 1784.48, "end": 1788.24, "text": " So it's pretty amazing, but you can, you know, these are narrow environments.", "tokens": [51568, 407, 309, 311, 1238, 2243, 11, 457, 291, 393, 11, 291, 458, 11, 613, 366, 9432, 12388, 13, 51756], "temperature": 0.0, "avg_logprob": -0.12041902964094044, "compression_ratio": 1.705223880597015, "no_speech_prob": 0.0008033678168430924}, {"id": 300, "seek": 178824, "start": 1788.48, "end": 1794.16, "text": " But if you look at AlphaZero, that was also developed by DeepMind. I mean,", "tokens": [50376, 583, 498, 291, 574, 412, 20588, 57, 2032, 11, 300, 390, 611, 4743, 538, 14895, 44, 471, 13, 286, 914, 11, 50660], "temperature": 0.0, "avg_logprob": -0.18188214302062988, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.0021477187983691692}, {"id": 301, "seek": 178824, "start": 1794.16, "end": 1799.92, "text": " got famous with AlphaGo and then came AlphaZero a year later. That was truly amazing. So", "tokens": [50660, 658, 4618, 365, 20588, 12104, 293, 550, 1361, 20588, 57, 2032, 257, 1064, 1780, 13, 663, 390, 4908, 2243, 13, 407, 50948], "temperature": 0.0, "avg_logprob": -0.18188214302062988, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.0021477187983691692}, {"id": 302, "seek": 178824, "start": 1799.92, "end": 1805.76, "text": " on reinforcement learning algorithm, which is able just by self-play to play chess", "tokens": [50948, 322, 29280, 2539, 9284, 11, 597, 307, 1075, 445, 538, 2698, 12, 2858, 281, 862, 24122, 51240], "temperature": 0.0, "avg_logprob": -0.18188214302062988, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.0021477187983691692}, {"id": 303, "seek": 178824, "start": 1807.04, "end": 1811.76, "text": " and then also go. And I mean, yes, they're both games, but they're quite different games. And,", "tokens": [51304, 293, 550, 611, 352, 13, 400, 286, 914, 11, 2086, 11, 436, 434, 1293, 2813, 11, 457, 436, 434, 1596, 819, 2813, 13, 400, 11, 51540], "temperature": 0.0, "avg_logprob": -0.18188214302062988, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.0021477187983691692}, {"id": 304, "seek": 178824, "start": 1811.76, "end": 1816.64, "text": " you know, this, you didn't, don't feed them the rules of the game. And the most remarkable thing,", "tokens": [51540, 291, 458, 11, 341, 11, 291, 994, 380, 11, 500, 380, 3154, 552, 264, 4474, 295, 264, 1216, 13, 400, 264, 881, 12802, 551, 11, 51784], "temperature": 0.0, "avg_logprob": -0.18188214302062988, "compression_ratio": 1.6199261992619927, "no_speech_prob": 0.0021477187983691692}, {"id": 305, "seek": 181664, "start": 1816.64, "end": 1821.76, "text": " which is still a mystery to me that usually for any decent chess program, I don't know much about", "tokens": [50364, 597, 307, 920, 257, 11422, 281, 385, 300, 2673, 337, 604, 8681, 24122, 1461, 11, 286, 500, 380, 458, 709, 466, 50620], "temperature": 0.0, "avg_logprob": -0.13830199608435997, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.009405597113072872}, {"id": 306, "seek": 181664, "start": 1821.76, "end": 1829.1200000000001, "text": " Go, you need opening books and end game tables and so on, too. And nothing in there, nothing was", "tokens": [50620, 1037, 11, 291, 643, 5193, 3642, 293, 917, 1216, 8020, 293, 370, 322, 11, 886, 13, 400, 1825, 294, 456, 11, 1825, 390, 50988], "temperature": 0.0, "avg_logprob": -0.13830199608435997, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.009405597113072872}, {"id": 307, "seek": 181664, "start": 1829.1200000000001, "end": 1833.44, "text": " put in there. Especially with AlphaZero, the self-play mechanism, starting from scratch,", "tokens": [50988, 829, 294, 456, 13, 8545, 365, 20588, 57, 2032, 11, 264, 2698, 12, 2858, 7513, 11, 2891, 490, 8459, 11, 51204], "temperature": 0.0, "avg_logprob": -0.13830199608435997, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.009405597113072872}, {"id": 308, "seek": 181664, "start": 1833.44, "end": 1842.0, "text": " being able to learn actually new strategies. It really discovered, you know, all these", "tokens": [51204, 885, 1075, 281, 1466, 767, 777, 9029, 13, 467, 534, 6941, 11, 291, 458, 11, 439, 613, 51632], "temperature": 0.0, "avg_logprob": -0.13830199608435997, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.009405597113072872}, {"id": 309, "seek": 184200, "start": 1842.0, "end": 1848.0, "text": " famous openings within four hours by itself. What I was really happy about, I'm a terrible", "tokens": [50364, 4618, 35941, 1951, 1451, 2496, 538, 2564, 13, 708, 286, 390, 534, 2055, 466, 11, 286, 478, 257, 6237, 50664], "temperature": 0.0, "avg_logprob": -0.13691080286261742, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.009409152902662754}, {"id": 310, "seek": 184200, "start": 1848.0, "end": 1853.04, "text": " chess player, but I like Queen Gambi. And AlphaZero figured out that this is the best opening.", "tokens": [50664, 24122, 4256, 11, 457, 286, 411, 10077, 44643, 72, 13, 400, 20588, 57, 2032, 8932, 484, 300, 341, 307, 264, 1151, 5193, 13, 50916], "temperature": 0.0, "avg_logprob": -0.13691080286261742, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.009409152902662754}, {"id": 311, "seek": 184200, "start": 1854.72, "end": 1861.92, "text": " Finally, somebody proved you correct. So yes, to answer your question, yes,", "tokens": [51000, 6288, 11, 2618, 14617, 291, 3006, 13, 407, 2086, 11, 281, 1867, 428, 1168, 11, 2086, 11, 51360], "temperature": 0.0, "avg_logprob": -0.13691080286261742, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.009409152902662754}, {"id": 312, "seek": 184200, "start": 1861.92, "end": 1869.12, "text": " I believe that general intelligence is possible. And it also depends how you define it. Do you say", "tokens": [51360, 286, 1697, 300, 2674, 7599, 307, 1944, 13, 400, 309, 611, 5946, 577, 291, 6964, 309, 13, 1144, 291, 584, 51720], "temperature": 0.0, "avg_logprob": -0.13691080286261742, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.009409152902662754}, {"id": 313, "seek": 186912, "start": 1869.12, "end": 1875.28, "text": " AGI with general intelligence, artificial intelligence, only refers to if you achieve", "tokens": [50364, 316, 26252, 365, 2674, 7599, 11, 11677, 7599, 11, 787, 14942, 281, 498, 291, 4584, 50672], "temperature": 0.0, "avg_logprob": -0.13836973190307617, "compression_ratio": 1.8669527896995708, "no_speech_prob": 0.004263071343302727}, {"id": 314, "seek": 186912, "start": 1875.28, "end": 1879.84, "text": " human level or a sub-human level, but quite broad? Is it also general intelligence,", "tokens": [50672, 1952, 1496, 420, 257, 1422, 12, 18796, 1496, 11, 457, 1596, 4152, 30, 1119, 309, 611, 2674, 7599, 11, 50900], "temperature": 0.0, "avg_logprob": -0.13836973190307617, "compression_ratio": 1.8669527896995708, "no_speech_prob": 0.004263071343302727}, {"id": 315, "seek": 186912, "start": 1879.84, "end": 1885.04, "text": " so we have to distinguish or it's only super human intelligence, general artificial intelligence?", "tokens": [50900, 370, 321, 362, 281, 20206, 420, 309, 311, 787, 1687, 1952, 7599, 11, 2674, 11677, 7599, 30, 51160], "temperature": 0.0, "avg_logprob": -0.13836973190307617, "compression_ratio": 1.8669527896995708, "no_speech_prob": 0.004263071343302727}, {"id": 316, "seek": 186912, "start": 1885.04, "end": 1889.76, "text": " Is there a test in your mind, like the Turing test for natural language or some other test", "tokens": [51160, 1119, 456, 257, 1500, 294, 428, 1575, 11, 411, 264, 314, 1345, 1500, 337, 3303, 2856, 420, 512, 661, 1500, 51396], "temperature": 0.0, "avg_logprob": -0.13836973190307617, "compression_ratio": 1.8669527896995708, "no_speech_prob": 0.004263071343302727}, {"id": 317, "seek": 186912, "start": 1889.76, "end": 1894.3999999999999, "text": " that would impress the heck out of you, that would kind of cross the line of", "tokens": [51396, 300, 576, 6729, 264, 12872, 484, 295, 291, 11, 300, 576, 733, 295, 3278, 264, 1622, 295, 51628], "temperature": 0.0, "avg_logprob": -0.13836973190307617, "compression_ratio": 1.8669527896995708, "no_speech_prob": 0.004263071343302727}, {"id": 318, "seek": 189440, "start": 1895.3600000000001, "end": 1901.6000000000001, "text": " your sense of intelligence within the framework that you said? Well, the Turing test has been", "tokens": [50412, 428, 2020, 295, 7599, 1951, 264, 8388, 300, 291, 848, 30, 1042, 11, 264, 314, 1345, 1500, 575, 668, 50724], "temperature": 0.0, "avg_logprob": -0.14920940001805624, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.00312320445664227}, {"id": 319, "seek": 189440, "start": 1901.6000000000001, "end": 1906.8000000000002, "text": " criticized a lot, but I think it's not as bad as some people think. And some people think it's too", "tokens": [50724, 28011, 257, 688, 11, 457, 286, 519, 309, 311, 406, 382, 1578, 382, 512, 561, 519, 13, 400, 512, 561, 519, 309, 311, 886, 50984], "temperature": 0.0, "avg_logprob": -0.14920940001805624, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.00312320445664227}, {"id": 320, "seek": 189440, "start": 1906.8000000000002, "end": 1915.1200000000001, "text": " strong. So it tests not just for a system to be intelligent, but it also has to fake human", "tokens": [50984, 2068, 13, 407, 309, 6921, 406, 445, 337, 257, 1185, 281, 312, 13232, 11, 457, 309, 611, 575, 281, 7592, 1952, 51400], "temperature": 0.0, "avg_logprob": -0.14920940001805624, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.00312320445664227}, {"id": 321, "seek": 189440, "start": 1915.1200000000001, "end": 1920.0, "text": " deception. Disception, right? Which is, you know, much harder. And on the other hand,", "tokens": [51400, 40451, 13, 4208, 7311, 11, 558, 30, 3013, 307, 11, 291, 458, 11, 709, 6081, 13, 400, 322, 264, 661, 1011, 11, 51644], "temperature": 0.0, "avg_logprob": -0.14920940001805624, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.00312320445664227}, {"id": 322, "seek": 192000, "start": 1920.0, "end": 1927.04, "text": " they say it's too weak because it's just maybe fakes, you know, emotions or intelligent behavior.", "tokens": [50364, 436, 584, 309, 311, 886, 5336, 570, 309, 311, 445, 1310, 283, 3419, 11, 291, 458, 11, 8462, 420, 13232, 5223, 13, 50716], "temperature": 0.0, "avg_logprob": -0.12477555406202964, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00668887747451663}, {"id": 323, "seek": 192000, "start": 1927.68, "end": 1933.92, "text": " It's not real. But I don't think that's the problem or big problem. So if you would pass the Turing", "tokens": [50748, 467, 311, 406, 957, 13, 583, 286, 500, 380, 519, 300, 311, 264, 1154, 420, 955, 1154, 13, 407, 498, 291, 576, 1320, 264, 314, 1345, 51060], "temperature": 0.0, "avg_logprob": -0.12477555406202964, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00668887747451663}, {"id": 324, "seek": 192000, "start": 1933.92, "end": 1942.56, "text": " test, so a conversation or a terminal with a bot for an hour, or maybe a day or so, and you can", "tokens": [51060, 1500, 11, 370, 257, 3761, 420, 257, 14709, 365, 257, 10592, 337, 364, 1773, 11, 420, 1310, 257, 786, 420, 370, 11, 293, 291, 393, 51492], "temperature": 0.0, "avg_logprob": -0.12477555406202964, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00668887747451663}, {"id": 325, "seek": 192000, "start": 1942.56, "end": 1947.12, "text": " fool a human into, you know, not knowing whether this is a human or not, that it's the Turing test,", "tokens": [51492, 7979, 257, 1952, 666, 11, 291, 458, 11, 406, 5276, 1968, 341, 307, 257, 1952, 420, 406, 11, 300, 309, 311, 264, 314, 1345, 1500, 11, 51720], "temperature": 0.0, "avg_logprob": -0.12477555406202964, "compression_ratio": 1.6582278481012658, "no_speech_prob": 0.00668887747451663}, {"id": 326, "seek": 194712, "start": 1947.6, "end": 1952.32, "text": " I would be truly impressed. And we have this annual competition, the Lubna", "tokens": [50388, 286, 576, 312, 4908, 11679, 13, 400, 321, 362, 341, 9784, 6211, 11, 264, 43781, 629, 50624], "temperature": 0.0, "avg_logprob": -0.2136491808974952, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003023796249181032}, {"id": 327, "seek": 194712, "start": 1953.36, "end": 1957.6, "text": " prize. And I mean, it started with Eliza, that was the first conversational program.", "tokens": [50676, 12818, 13, 400, 286, 914, 11, 309, 1409, 365, 11991, 64, 11, 300, 390, 264, 700, 2615, 1478, 1461, 13, 50888], "temperature": 0.0, "avg_logprob": -0.2136491808974952, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003023796249181032}, {"id": 328, "seek": 194712, "start": 1958.2399999999998, "end": 1963.1999999999998, "text": " And what is it called the Japanese Mitsuko or so, that's the winner of the last, you know,", "tokens": [50920, 400, 437, 307, 309, 1219, 264, 5433, 40897, 39476, 420, 370, 11, 300, 311, 264, 8507, 295, 264, 1036, 11, 291, 458, 11, 51168], "temperature": 0.0, "avg_logprob": -0.2136491808974952, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003023796249181032}, {"id": 329, "seek": 194712, "start": 1963.1999999999998, "end": 1968.8799999999999, "text": " couple of years. And well, it's impressive. Yeah, it's quite impressive. And then Google has", "tokens": [51168, 1916, 295, 924, 13, 400, 731, 11, 309, 311, 8992, 13, 865, 11, 309, 311, 1596, 8992, 13, 400, 550, 3329, 575, 51452], "temperature": 0.0, "avg_logprob": -0.2136491808974952, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003023796249181032}, {"id": 330, "seek": 194712, "start": 1968.8799999999999, "end": 1975.6799999999998, "text": " developed Mina, right? Just recently, that's an open domain conversational bot. Just a couple of", "tokens": [51452, 4743, 35981, 11, 558, 30, 1449, 3938, 11, 300, 311, 364, 1269, 9274, 2615, 1478, 10592, 13, 1449, 257, 1916, 295, 51792], "temperature": 0.0, "avg_logprob": -0.2136491808974952, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.003023796249181032}, {"id": 331, "seek": 197568, "start": 1975.68, "end": 1981.52, "text": " weeks ago, I think. Yeah, I kind of like the metric that sort of the Alexa price has proposed.", "tokens": [50364, 3259, 2057, 11, 286, 519, 13, 865, 11, 286, 733, 295, 411, 264, 20678, 300, 1333, 295, 264, 22595, 3218, 575, 10348, 13, 50656], "temperature": 0.0, "avg_logprob": -0.14091479259988535, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.006900466047227383}, {"id": 332, "seek": 197568, "start": 1981.52, "end": 1985.3600000000001, "text": " I mean, maybe it's obvious to you, it wasn't to me of setting sort of a length", "tokens": [50656, 286, 914, 11, 1310, 309, 311, 6322, 281, 291, 11, 309, 2067, 380, 281, 385, 295, 3287, 1333, 295, 257, 4641, 50848], "temperature": 0.0, "avg_logprob": -0.14091479259988535, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.006900466047227383}, {"id": 333, "seek": 197568, "start": 1986.48, "end": 1991.6000000000001, "text": " of a conversation. Like, you want the bot to be sufficiently interesting that you'd want to keep", "tokens": [50904, 295, 257, 3761, 13, 1743, 11, 291, 528, 264, 10592, 281, 312, 31868, 1880, 300, 291, 1116, 528, 281, 1066, 51160], "temperature": 0.0, "avg_logprob": -0.14091479259988535, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.006900466047227383}, {"id": 334, "seek": 197568, "start": 1991.6000000000001, "end": 1999.44, "text": " talking to it for like 20 minutes. And that's a surprisingly effective and aggregate metric.", "tokens": [51160, 1417, 281, 309, 337, 411, 945, 2077, 13, 400, 300, 311, 257, 17600, 4942, 293, 26118, 20678, 13, 51552], "temperature": 0.0, "avg_logprob": -0.14091479259988535, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.006900466047227383}, {"id": 335, "seek": 199944, "start": 1999.44, "end": 2007.68, "text": " Because really, like, nobody has the patience to be able to talk to a bot that's not interesting", "tokens": [50364, 1436, 534, 11, 411, 11, 5079, 575, 264, 14826, 281, 312, 1075, 281, 751, 281, 257, 10592, 300, 311, 406, 1880, 50776], "temperature": 0.0, "avg_logprob": -0.1615957610908596, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.011155400425195694}, {"id": 336, "seek": 199944, "start": 2007.68, "end": 2013.44, "text": " and intelligent and witty and is able to go into different tangents, jump domains, be able to,", "tokens": [50776, 293, 13232, 293, 261, 10016, 293, 307, 1075, 281, 352, 666, 819, 10266, 791, 11, 3012, 25514, 11, 312, 1075, 281, 11, 51064], "temperature": 0.0, "avg_logprob": -0.1615957610908596, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.011155400425195694}, {"id": 337, "seek": 199944, "start": 2014.0, "end": 2018.24, "text": " you know, say something interesting to maintain your attention. Maybe many humans will also fail", "tokens": [51092, 291, 458, 11, 584, 746, 1880, 281, 6909, 428, 3202, 13, 2704, 867, 6255, 486, 611, 3061, 51304], "temperature": 0.0, "avg_logprob": -0.1615957610908596, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.011155400425195694}, {"id": 338, "seek": 199944, "start": 2018.24, "end": 2025.28, "text": " this test. Unfortunately, we set just like with autonomous vehicles with chatbots,", "tokens": [51304, 341, 1500, 13, 8590, 11, 321, 992, 445, 411, 365, 23797, 8948, 365, 5081, 65, 1971, 11, 51656], "temperature": 0.0, "avg_logprob": -0.1615957610908596, "compression_ratio": 1.6200873362445414, "no_speech_prob": 0.011155400425195694}, {"id": 339, "seek": 202528, "start": 2025.28, "end": 2029.92, "text": " we also set a bar that's way too hard to reach. I said, you know, the Turing test is not as bad", "tokens": [50364, 321, 611, 992, 257, 2159, 300, 311, 636, 886, 1152, 281, 2524, 13, 286, 848, 11, 291, 458, 11, 264, 314, 1345, 1500, 307, 406, 382, 1578, 50596], "temperature": 0.0, "avg_logprob": -0.08916390057906363, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0010642854031175375}, {"id": 340, "seek": 202528, "start": 2029.92, "end": 2036.56, "text": " as some people believe. But what is really not useful about the Turing test, it gives us no", "tokens": [50596, 382, 512, 561, 1697, 13, 583, 437, 307, 534, 406, 4420, 466, 264, 314, 1345, 1500, 11, 309, 2709, 505, 572, 50928], "temperature": 0.0, "avg_logprob": -0.08916390057906363, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0010642854031175375}, {"id": 341, "seek": 202528, "start": 2036.56, "end": 2041.92, "text": " guidance how to develop these systems in the first place. Of course, you know, we can develop them", "tokens": [50928, 10056, 577, 281, 1499, 613, 3652, 294, 264, 700, 1081, 13, 2720, 1164, 11, 291, 458, 11, 321, 393, 1499, 552, 51196], "temperature": 0.0, "avg_logprob": -0.08916390057906363, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0010642854031175375}, {"id": 342, "seek": 202528, "start": 2041.92, "end": 2046.8, "text": " by trial and error and, you know, do whatever and then run the test and see whether it works or not.", "tokens": [51196, 538, 7308, 293, 6713, 293, 11, 291, 458, 11, 360, 2035, 293, 550, 1190, 264, 1500, 293, 536, 1968, 309, 1985, 420, 406, 13, 51440], "temperature": 0.0, "avg_logprob": -0.08916390057906363, "compression_ratio": 1.682608695652174, "no_speech_prob": 0.0010642854031175375}, {"id": 343, "seek": 204680, "start": 2046.8, "end": 2056.88, "text": " But a mathematical definition of intelligence gives us, you know, an objective which we can then", "tokens": [50364, 583, 257, 18894, 7123, 295, 7599, 2709, 505, 11, 291, 458, 11, 364, 10024, 597, 321, 393, 550, 50868], "temperature": 0.0, "avg_logprob": -0.15444833840896835, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.00045818512444384396}, {"id": 344, "seek": 204680, "start": 2056.88, "end": 2063.2, "text": " analyze by, you know, theoretical tools or computational and, you know, maybe even prove", "tokens": [50868, 12477, 538, 11, 291, 458, 11, 20864, 3873, 420, 28270, 293, 11, 291, 458, 11, 1310, 754, 7081, 51184], "temperature": 0.0, "avg_logprob": -0.15444833840896835, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.00045818512444384396}, {"id": 345, "seek": 204680, "start": 2063.2, "end": 2070.48, "text": " how close we are. And we will come back to that later with the ISE model. So I mentioned the", "tokens": [51184, 577, 1998, 321, 366, 13, 400, 321, 486, 808, 646, 281, 300, 1780, 365, 264, 286, 5879, 2316, 13, 407, 286, 2835, 264, 51548], "temperature": 0.0, "avg_logprob": -0.15444833840896835, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.00045818512444384396}, {"id": 346, "seek": 207048, "start": 2070.48, "end": 2076.72, "text": " compression, right? So in natural language processing, they have achieved amazing results.", "tokens": [50364, 19355, 11, 558, 30, 407, 294, 3303, 2856, 9007, 11, 436, 362, 11042, 2243, 3542, 13, 50676], "temperature": 0.0, "avg_logprob": -0.13067065247701942, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006586804054677486}, {"id": 347, "seek": 207048, "start": 2076.72, "end": 2080.8, "text": " And one way to test this, of course, you know, take the system, you train it, and then you,", "tokens": [50676, 400, 472, 636, 281, 1500, 341, 11, 295, 1164, 11, 291, 458, 11, 747, 264, 1185, 11, 291, 3847, 309, 11, 293, 550, 291, 11, 50880], "temperature": 0.0, "avg_logprob": -0.13067065247701942, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006586804054677486}, {"id": 348, "seek": 207048, "start": 2080.8, "end": 2088.0, "text": " you know, see how well it performs on the task. But a lot of performance measurement is done by", "tokens": [50880, 291, 458, 11, 536, 577, 731, 309, 26213, 322, 264, 5633, 13, 583, 257, 688, 295, 3389, 13160, 307, 1096, 538, 51240], "temperature": 0.0, "avg_logprob": -0.13067065247701942, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006586804054677486}, {"id": 349, "seek": 207048, "start": 2088.0, "end": 2093.28, "text": " so-called perplexity, which is essentially the same as complexity or compression length.", "tokens": [51240, 370, 12, 11880, 680, 18945, 507, 11, 597, 307, 4476, 264, 912, 382, 14024, 420, 19355, 4641, 13, 51504], "temperature": 0.0, "avg_logprob": -0.13067065247701942, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006586804054677486}, {"id": 350, "seek": 207048, "start": 2093.28, "end": 2097.52, "text": " So the NLP community develops new systems, and then they measure the compression length,", "tokens": [51504, 407, 264, 426, 45196, 1768, 25453, 777, 3652, 11, 293, 550, 436, 3481, 264, 19355, 4641, 11, 51716], "temperature": 0.0, "avg_logprob": -0.13067065247701942, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.006586804054677486}, {"id": 351, "seek": 209752, "start": 2097.52, "end": 2103.44, "text": " and then they have ranking and leaks, because there's a strong correlation between", "tokens": [50364, 293, 550, 436, 362, 17833, 293, 28885, 11, 570, 456, 311, 257, 2068, 20009, 1296, 50660], "temperature": 0.0, "avg_logprob": -0.1289318629673549, "compression_ratio": 1.575609756097561, "no_speech_prob": 0.00020984337606932968}, {"id": 352, "seek": 209752, "start": 2103.44, "end": 2108.4, "text": " compressing well, and then the systems performing well at the task at hand. It's not perfect,", "tokens": [50660, 14778, 278, 731, 11, 293, 550, 264, 3652, 10205, 731, 412, 264, 5633, 412, 1011, 13, 467, 311, 406, 2176, 11, 50908], "temperature": 0.0, "avg_logprob": -0.1289318629673549, "compression_ratio": 1.575609756097561, "no_speech_prob": 0.00020984337606932968}, {"id": 353, "seek": 209752, "start": 2108.4, "end": 2113.36, "text": " but it's good enough for them as an intermediate aim.", "tokens": [50908, 457, 309, 311, 665, 1547, 337, 552, 382, 364, 19376, 5939, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1289318629673549, "compression_ratio": 1.575609756097561, "no_speech_prob": 0.00020984337606932968}, {"id": 354, "seek": 209752, "start": 2114.56, "end": 2119.84, "text": " So you mean measure, so this is kind of almost returning to the common growth complexity. So", "tokens": [51216, 407, 291, 914, 3481, 11, 370, 341, 307, 733, 295, 1920, 12678, 281, 264, 2689, 4599, 14024, 13, 407, 51480], "temperature": 0.0, "avg_logprob": -0.1289318629673549, "compression_ratio": 1.575609756097561, "no_speech_prob": 0.00020984337606932968}, {"id": 355, "seek": 211984, "start": 2119.84, "end": 2125.1200000000003, "text": " you're saying good compression usually means good intelligence. Yes.", "tokens": [50364, 291, 434, 1566, 665, 19355, 2673, 1355, 665, 7599, 13, 1079, 13, 50628], "temperature": 0.0, "avg_logprob": -0.0989828109741211, "compression_ratio": 1.5125, "no_speech_prob": 0.0008424932020716369}, {"id": 356, "seek": 211984, "start": 2126.88, "end": 2134.8, "text": " So you mentioned you're one of the, one of the only people who dared boldly to try to", "tokens": [50716, 407, 291, 2835, 291, 434, 472, 295, 264, 11, 472, 295, 264, 787, 561, 567, 44564, 11928, 356, 281, 853, 281, 51112], "temperature": 0.0, "avg_logprob": -0.0989828109741211, "compression_ratio": 1.5125, "no_speech_prob": 0.0008424932020716369}, {"id": 357, "seek": 211984, "start": 2134.8, "end": 2141.6000000000004, "text": " formalize the idea of artificial general intelligence, to have a mathematical framework", "tokens": [51112, 9860, 1125, 264, 1558, 295, 11677, 2674, 7599, 11, 281, 362, 257, 18894, 8388, 51452], "temperature": 0.0, "avg_logprob": -0.0989828109741211, "compression_ratio": 1.5125, "no_speech_prob": 0.0008424932020716369}, {"id": 358, "seek": 214160, "start": 2141.6, "end": 2150.56, "text": " for intelligence, just like as we mentioned, termed IEXI, A-I-X-I. So let me ask the basic", "tokens": [50364, 337, 7599, 11, 445, 411, 382, 321, 2835, 11, 1433, 292, 286, 39814, 40, 11, 316, 12, 40, 12, 55, 12, 40, 13, 407, 718, 385, 1029, 264, 3875, 50812], "temperature": 0.0, "avg_logprob": -0.1993221786786925, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.020642079412937164}, {"id": 359, "seek": 214160, "start": 2150.56, "end": 2158.56, "text": " question, what is IEXI? Okay, so let me first say what it stands for, because what it stands for,", "tokens": [50812, 1168, 11, 437, 307, 286, 39814, 40, 30, 1033, 11, 370, 718, 385, 700, 584, 437, 309, 7382, 337, 11, 570, 437, 309, 7382, 337, 11, 51212], "temperature": 0.0, "avg_logprob": -0.1993221786786925, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.020642079412937164}, {"id": 360, "seek": 214160, "start": 2158.56, "end": 2162.72, "text": " actually, that's probably the more basic question. The first question is usually how", "tokens": [51212, 767, 11, 300, 311, 1391, 264, 544, 3875, 1168, 13, 440, 700, 1168, 307, 2673, 577, 51420], "temperature": 0.0, "avg_logprob": -0.1993221786786925, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.020642079412937164}, {"id": 361, "seek": 214160, "start": 2163.52, "end": 2168.08, "text": " how it's pronounced, but finally I put it on the website, how it's pronounced, and you figured it out.", "tokens": [51460, 577, 309, 311, 23155, 11, 457, 2721, 286, 829, 309, 322, 264, 3144, 11, 577, 309, 311, 23155, 11, 293, 291, 8932, 309, 484, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1993221786786925, "compression_ratio": 1.7013574660633484, "no_speech_prob": 0.020642079412937164}, {"id": 362, "seek": 216808, "start": 2169.04, "end": 2175.36, "text": " Yeah. The name comes from AI, artificial intelligence, and the XI is the Greek letter", "tokens": [50412, 865, 13, 440, 1315, 1487, 490, 7318, 11, 11677, 7599, 11, 293, 264, 1783, 40, 307, 264, 10281, 5063, 50728], "temperature": 0.0, "avg_logprob": -0.21101070404052735, "compression_ratio": 1.443298969072165, "no_speech_prob": 0.0004235465021338314}, {"id": 363, "seek": 216808, "start": 2175.36, "end": 2183.2, "text": " XI, which are used for Solomonov's distribution for quite stupid reasons, which I'm not willing to", "tokens": [50728, 1783, 40, 11, 597, 366, 1143, 337, 7026, 298, 266, 5179, 311, 7316, 337, 1596, 6631, 4112, 11, 597, 286, 478, 406, 4950, 281, 51120], "temperature": 0.0, "avg_logprob": -0.21101070404052735, "compression_ratio": 1.443298969072165, "no_speech_prob": 0.0004235465021338314}, {"id": 364, "seek": 216808, "start": 2183.2, "end": 2190.64, "text": " repeat here in front of camera. So it does happen to be more or less arbitrary, I chose the XI,", "tokens": [51120, 7149, 510, 294, 1868, 295, 2799, 13, 407, 309, 775, 1051, 281, 312, 544, 420, 1570, 23211, 11, 286, 5111, 264, 1783, 40, 11, 51492], "temperature": 0.0, "avg_logprob": -0.21101070404052735, "compression_ratio": 1.443298969072165, "no_speech_prob": 0.0004235465021338314}, {"id": 365, "seek": 219064, "start": 2191.44, "end": 2197.7599999999998, "text": " but it also has nice other interpretations. So there are actions and perceptions in this", "tokens": [50404, 457, 309, 611, 575, 1481, 661, 37547, 13, 407, 456, 366, 5909, 293, 35258, 294, 341, 50720], "temperature": 0.0, "avg_logprob": -0.1609041976928711, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.04809719696640968}, {"id": 366, "seek": 219064, "start": 2197.7599999999998, "end": 2204.96, "text": " model, where an agent has actions and perceptions, and over time, so this is A-I-X-I, so there's", "tokens": [50720, 2316, 11, 689, 364, 9461, 575, 5909, 293, 35258, 11, 293, 670, 565, 11, 370, 341, 307, 316, 12, 40, 12, 55, 12, 40, 11, 370, 456, 311, 51080], "temperature": 0.0, "avg_logprob": -0.1609041976928711, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.04809719696640968}, {"id": 367, "seek": 219064, "start": 2204.96, "end": 2210.56, "text": " an action at time I, and then followed by a perception at time I. We'll go with that. I'll", "tokens": [51080, 364, 3069, 412, 565, 286, 11, 293, 550, 6263, 538, 257, 12860, 412, 565, 286, 13, 492, 603, 352, 365, 300, 13, 286, 603, 51360], "temperature": 0.0, "avg_logprob": -0.1609041976928711, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.04809719696640968}, {"id": 368, "seek": 219064, "start": 2210.56, "end": 2216.72, "text": " edit out the first part. I'm just kidding. I have some more interpretations. So at some point,", "tokens": [51360, 8129, 484, 264, 700, 644, 13, 286, 478, 445, 9287, 13, 286, 362, 512, 544, 37547, 13, 407, 412, 512, 935, 11, 51668], "temperature": 0.0, "avg_logprob": -0.1609041976928711, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.04809719696640968}, {"id": 369, "seek": 221672, "start": 2216.72, "end": 2224.0, "text": " maybe five years ago or 10 years ago, I discovered in Barcelona, it was on a big church,", "tokens": [50364, 1310, 1732, 924, 2057, 420, 1266, 924, 2057, 11, 286, 6941, 294, 21247, 11, 309, 390, 322, 257, 955, 4128, 11, 50728], "temperature": 0.0, "avg_logprob": -0.21619003598052677, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.007327675353735685}, {"id": 370, "seek": 221672, "start": 2224.56, "end": 2231.2, "text": " there was a stone engraved, some text, and the word Aixi appeared there a couple of times.", "tokens": [50756, 456, 390, 257, 7581, 25842, 937, 11, 512, 2487, 11, 293, 264, 1349, 316, 970, 72, 8516, 456, 257, 1916, 295, 1413, 13, 51088], "temperature": 0.0, "avg_logprob": -0.21619003598052677, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.007327675353735685}, {"id": 371, "seek": 221672, "start": 2232.72, "end": 2239.2799999999997, "text": " I was very surprised and happy about that, and I looked it up, so this is Catalan language,", "tokens": [51164, 286, 390, 588, 6100, 293, 2055, 466, 300, 11, 293, 286, 2956, 309, 493, 11, 370, 341, 307, 9565, 14163, 2856, 11, 51492], "temperature": 0.0, "avg_logprob": -0.21619003598052677, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.007327675353735685}, {"id": 372, "seek": 221672, "start": 2239.2799999999997, "end": 2244.08, "text": " and it means with some interpretation, that's it, that's the right thing to do. Yeah, Heureka.", "tokens": [51492, 293, 309, 1355, 365, 512, 14174, 11, 300, 311, 309, 11, 300, 311, 264, 558, 551, 281, 360, 13, 865, 11, 634, 540, 2330, 13, 51732], "temperature": 0.0, "avg_logprob": -0.21619003598052677, "compression_ratio": 1.5508474576271187, "no_speech_prob": 0.007327675353735685}, {"id": 373, "seek": 224408, "start": 2244.72, "end": 2252.0, "text": " Oh, so it's almost like destined, somehow came to you in a dream.", "tokens": [50396, 876, 11, 370, 309, 311, 1920, 411, 33169, 11, 6063, 1361, 281, 291, 294, 257, 3055, 13, 50760], "temperature": 0.0, "avg_logprob": -0.20845414784328997, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.0017512098420411348}, {"id": 374, "seek": 224408, "start": 2252.0, "end": 2256.48, "text": " And similar, there's a Chinese word, Aixi, also written like Aixi, if you transcribe that to", "tokens": [50760, 400, 2531, 11, 456, 311, 257, 4649, 1349, 11, 316, 970, 72, 11, 611, 3720, 411, 316, 970, 72, 11, 498, 291, 1145, 8056, 300, 281, 50984], "temperature": 0.0, "avg_logprob": -0.20845414784328997, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.0017512098420411348}, {"id": 375, "seek": 224408, "start": 2256.48, "end": 2262.48, "text": " Pingen. And the final one is that is A-I, crossed with induction, because that is, and that's going", "tokens": [50984, 430, 12343, 13, 400, 264, 2572, 472, 307, 300, 307, 316, 12, 40, 11, 14622, 365, 33371, 11, 570, 300, 307, 11, 293, 300, 311, 516, 51284], "temperature": 0.0, "avg_logprob": -0.20845414784328997, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.0017512098420411348}, {"id": 376, "seek": 224408, "start": 2262.48, "end": 2268.24, "text": " more to the content now. So good old fashioned A-I is more about planning a known deterministic", "tokens": [51284, 544, 281, 264, 2701, 586, 13, 407, 665, 1331, 40646, 316, 12, 40, 307, 544, 466, 5038, 257, 2570, 15957, 3142, 51572], "temperature": 0.0, "avg_logprob": -0.20845414784328997, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.0017512098420411348}, {"id": 377, "seek": 224408, "start": 2268.24, "end": 2273.7599999999998, "text": " world, and induction is more about often IID data and inferring models, and essentially,", "tokens": [51572, 1002, 11, 293, 33371, 307, 544, 466, 2049, 286, 2777, 1412, 293, 13596, 2937, 5245, 11, 293, 4476, 11, 51848], "temperature": 0.0, "avg_logprob": -0.20845414784328997, "compression_ratio": 1.6654135338345866, "no_speech_prob": 0.0017512098420411348}, {"id": 378, "seek": 227376, "start": 2273.76, "end": 2278.6400000000003, "text": " what this Aixi model does is combining these two. And I actually also recently,", "tokens": [50364, 437, 341, 316, 970, 72, 2316, 775, 307, 21928, 613, 732, 13, 400, 286, 767, 611, 3938, 11, 50608], "temperature": 0.0, "avg_logprob": -0.13973623640993807, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.002667664084583521}, {"id": 379, "seek": 227376, "start": 2278.6400000000003, "end": 2285.92, "text": " I think heard that in Japanese, A-I means love. So if you can combine X-I somehow with that,", "tokens": [50608, 286, 519, 2198, 300, 294, 5433, 11, 316, 12, 40, 1355, 959, 13, 407, 498, 291, 393, 10432, 1783, 12, 40, 6063, 365, 300, 11, 50972], "temperature": 0.0, "avg_logprob": -0.13973623640993807, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.002667664084583521}, {"id": 380, "seek": 227376, "start": 2286.5600000000004, "end": 2292.2400000000002, "text": " I think we can, there might be some interesting ideas there. So Aixi, let's then take the next", "tokens": [51004, 286, 519, 321, 393, 11, 456, 1062, 312, 512, 1880, 3487, 456, 13, 407, 316, 970, 72, 11, 718, 311, 550, 747, 264, 958, 51288], "temperature": 0.0, "avg_logprob": -0.13973623640993807, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.002667664084583521}, {"id": 381, "seek": 227376, "start": 2292.2400000000002, "end": 2299.44, "text": " step. Can you maybe talk at the big level of what is this mathematical framework?", "tokens": [51288, 1823, 13, 1664, 291, 1310, 751, 412, 264, 955, 1496, 295, 437, 307, 341, 18894, 8388, 30, 51648], "temperature": 0.0, "avg_logprob": -0.13973623640993807, "compression_ratio": 1.530701754385965, "no_speech_prob": 0.002667664084583521}, {"id": 382, "seek": 229944, "start": 2299.68, "end": 2306.48, "text": " So it consists essentially of two parts. One is the learning and induction and prediction part.", "tokens": [50376, 407, 309, 14689, 4476, 295, 732, 3166, 13, 1485, 307, 264, 2539, 293, 33371, 293, 17630, 644, 13, 50716], "temperature": 0.0, "avg_logprob": -0.07247013204237994, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0007552579045295715}, {"id": 383, "seek": 229944, "start": 2306.48, "end": 2311.76, "text": " And the other one is the planning part. So let's come first to the learning induction", "tokens": [50716, 400, 264, 661, 472, 307, 264, 5038, 644, 13, 407, 718, 311, 808, 700, 281, 264, 2539, 33371, 50980], "temperature": 0.0, "avg_logprob": -0.07247013204237994, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0007552579045295715}, {"id": 384, "seek": 229944, "start": 2311.76, "end": 2318.48, "text": " prediction part, which essentially I explained already before. So what we need for any agent", "tokens": [50980, 17630, 644, 11, 597, 4476, 286, 8825, 1217, 949, 13, 407, 437, 321, 643, 337, 604, 9461, 51316], "temperature": 0.0, "avg_logprob": -0.07247013204237994, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0007552579045295715}, {"id": 385, "seek": 229944, "start": 2319.2000000000003, "end": 2324.64, "text": " to act well is that it can somehow predict what happens. I mean, if you have no idea what your", "tokens": [51352, 281, 605, 731, 307, 300, 309, 393, 6063, 6069, 437, 2314, 13, 286, 914, 11, 498, 291, 362, 572, 1558, 437, 428, 51624], "temperature": 0.0, "avg_logprob": -0.07247013204237994, "compression_ratio": 1.740566037735849, "no_speech_prob": 0.0007552579045295715}, {"id": 386, "seek": 232464, "start": 2324.64, "end": 2330.64, "text": " actions do, how can you decide which acts are good or not? So you need to have some model of", "tokens": [50364, 5909, 360, 11, 577, 393, 291, 4536, 597, 10672, 366, 665, 420, 406, 30, 407, 291, 643, 281, 362, 512, 2316, 295, 50664], "temperature": 0.0, "avg_logprob": -0.14874800261076507, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.006000797729939222}, {"id": 387, "seek": 232464, "start": 2330.64, "end": 2337.8399999999997, "text": " what your actions effect. So what you do is you have some experience, you build models like scientists", "tokens": [50664, 437, 428, 5909, 1802, 13, 407, 437, 291, 360, 307, 291, 362, 512, 1752, 11, 291, 1322, 5245, 411, 7708, 51024], "temperature": 0.0, "avg_logprob": -0.14874800261076507, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.006000797729939222}, {"id": 388, "seek": 232464, "start": 2337.8399999999997, "end": 2342.48, "text": " of your experience, then you hope these models are roughly correct, and then you use these models", "tokens": [51024, 295, 428, 1752, 11, 550, 291, 1454, 613, 5245, 366, 9810, 3006, 11, 293, 550, 291, 764, 613, 5245, 51256], "temperature": 0.0, "avg_logprob": -0.14874800261076507, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.006000797729939222}, {"id": 389, "seek": 232464, "start": 2342.48, "end": 2347.52, "text": " for prediction. And a model is, sorry to interrupt, and a model is based on your perception of the", "tokens": [51256, 337, 17630, 13, 400, 257, 2316, 307, 11, 2597, 281, 12729, 11, 293, 257, 2316, 307, 2361, 322, 428, 12860, 295, 264, 51508], "temperature": 0.0, "avg_logprob": -0.14874800261076507, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.006000797729939222}, {"id": 390, "seek": 232464, "start": 2347.52, "end": 2354.16, "text": " world, how your actions will affect that world. That's not the important part.", "tokens": [51508, 1002, 11, 577, 428, 5909, 486, 3345, 300, 1002, 13, 663, 311, 406, 264, 1021, 644, 13, 51840], "temperature": 0.0, "avg_logprob": -0.14874800261076507, "compression_ratio": 1.8470588235294119, "no_speech_prob": 0.006000797729939222}, {"id": 391, "seek": 235464, "start": 2354.64, "end": 2358.4, "text": " It is technically important, but at this stage, we can just think about predicting, say,", "tokens": [50364, 467, 307, 12120, 1021, 11, 457, 412, 341, 3233, 11, 321, 393, 445, 519, 466, 32884, 11, 584, 11, 50552], "temperature": 0.0, "avg_logprob": -0.16263675689697266, "compression_ratio": 1.6383763837638377, "no_speech_prob": 0.0013451960403472185}, {"id": 392, "seek": 235464, "start": 2359.12, "end": 2363.92, "text": " stock market data, whether data or IQ sequences, one, two, three, four, five, what comes next.", "tokens": [50588, 4127, 2142, 1412, 11, 1968, 1412, 420, 28921, 22978, 11, 472, 11, 732, 11, 1045, 11, 1451, 11, 1732, 11, 437, 1487, 958, 13, 50828], "temperature": 0.0, "avg_logprob": -0.16263675689697266, "compression_ratio": 1.6383763837638377, "no_speech_prob": 0.0013451960403472185}, {"id": 393, "seek": 235464, "start": 2363.92, "end": 2370.16, "text": " Yeah. So of course, our actions affect what we're doing, but I'll come back to that in a second.", "tokens": [50828, 865, 13, 407, 295, 1164, 11, 527, 5909, 3345, 437, 321, 434, 884, 11, 457, 286, 603, 808, 646, 281, 300, 294, 257, 1150, 13, 51140], "temperature": 0.0, "avg_logprob": -0.16263675689697266, "compression_ratio": 1.6383763837638377, "no_speech_prob": 0.0013451960403472185}, {"id": 394, "seek": 235464, "start": 2370.16, "end": 2376.4, "text": " So, and I'll keep just interrupting. So just to draw a line between prediction and planning.", "tokens": [51140, 407, 11, 293, 286, 603, 1066, 445, 49455, 13, 407, 445, 281, 2642, 257, 1622, 1296, 17630, 293, 5038, 13, 51452], "temperature": 0.0, "avg_logprob": -0.16263675689697266, "compression_ratio": 1.6383763837638377, "no_speech_prob": 0.0013451960403472185}, {"id": 395, "seek": 235464, "start": 2377.44, "end": 2381.8399999999997, "text": " What do you mean by prediction in this way? It's trying to predict the", "tokens": [51504, 708, 360, 291, 914, 538, 17630, 294, 341, 636, 30, 467, 311, 1382, 281, 6069, 264, 51724], "temperature": 0.0, "avg_logprob": -0.16263675689697266, "compression_ratio": 1.6383763837638377, "no_speech_prob": 0.0013451960403472185}, {"id": 396, "seek": 238184, "start": 2382.7200000000003, "end": 2388.0, "text": " environment without your long-term action in the environment. What is prediction?", "tokens": [50408, 2823, 1553, 428, 938, 12, 7039, 3069, 294, 264, 2823, 13, 708, 307, 17630, 30, 50672], "temperature": 0.0, "avg_logprob": -0.1760150574065827, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0024709543213248253}, {"id": 397, "seek": 238184, "start": 2389.44, "end": 2392.32, "text": " Okay. If you want to put the actions in now, okay, then let's put in them now.", "tokens": [50744, 1033, 13, 759, 291, 528, 281, 829, 264, 5909, 294, 586, 11, 1392, 11, 550, 718, 311, 829, 294, 552, 586, 13, 50888], "temperature": 0.0, "avg_logprob": -0.1760150574065827, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0024709543213248253}, {"id": 398, "seek": 238184, "start": 2394.7200000000003, "end": 2400.1600000000003, "text": " We don't have to put them now. Scratch it. Don't question. Okay. So the simplest form of prediction", "tokens": [51008, 492, 500, 380, 362, 281, 829, 552, 586, 13, 34944, 852, 309, 13, 1468, 380, 1168, 13, 1033, 13, 407, 264, 22811, 1254, 295, 17630, 51280], "temperature": 0.0, "avg_logprob": -0.1760150574065827, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0024709543213248253}, {"id": 399, "seek": 238184, "start": 2400.1600000000003, "end": 2406.1600000000003, "text": " is that you just have data that you passively observe, and you want to predict what happens", "tokens": [51280, 307, 300, 291, 445, 362, 1412, 300, 291, 1320, 3413, 11441, 11, 293, 291, 528, 281, 6069, 437, 2314, 51580], "temperature": 0.0, "avg_logprob": -0.1760150574065827, "compression_ratio": 1.7087378640776698, "no_speech_prob": 0.0024709543213248253}, {"id": 400, "seek": 240616, "start": 2406.16, "end": 2413.2799999999997, "text": " without, you know, interfering. As I said, weather forecasting, stock market, IQ sequences, or just", "tokens": [50364, 1553, 11, 291, 458, 11, 48721, 13, 1018, 286, 848, 11, 5503, 44331, 11, 4127, 2142, 11, 28921, 22978, 11, 420, 445, 50720], "temperature": 0.0, "avg_logprob": -0.1475697181842945, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.000552671670448035}, {"id": 401, "seek": 240616, "start": 2414.8799999999997, "end": 2420.0, "text": " anything. Okay. And Solominov's theory of induction based on compression. So you look for the shortest", "tokens": [50800, 1340, 13, 1033, 13, 400, 7026, 298, 2982, 85, 311, 5261, 295, 33371, 2361, 322, 19355, 13, 407, 291, 574, 337, 264, 31875, 51056], "temperature": 0.0, "avg_logprob": -0.1475697181842945, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.000552671670448035}, {"id": 402, "seek": 240616, "start": 2420.0, "end": 2424.3199999999997, "text": " program which describes your data sequence. And then you take this program, run it,", "tokens": [51056, 1461, 597, 15626, 428, 1412, 8310, 13, 400, 550, 291, 747, 341, 1461, 11, 1190, 309, 11, 51272], "temperature": 0.0, "avg_logprob": -0.1475697181842945, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.000552671670448035}, {"id": 403, "seek": 240616, "start": 2424.3199999999997, "end": 2429.04, "text": " which reproduces your data sequence by definition, and then you let it continue running,", "tokens": [51272, 597, 11408, 887, 428, 1412, 8310, 538, 7123, 11, 293, 550, 291, 718, 309, 2354, 2614, 11, 51508], "temperature": 0.0, "avg_logprob": -0.1475697181842945, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.000552671670448035}, {"id": 404, "seek": 240616, "start": 2429.04, "end": 2434.24, "text": " and then it will produce some predictions. And you can rigorously prove that for any", "tokens": [51508, 293, 550, 309, 486, 5258, 512, 21264, 13, 400, 291, 393, 42191, 5098, 7081, 300, 337, 604, 51768], "temperature": 0.0, "avg_logprob": -0.1475697181842945, "compression_ratio": 1.6974169741697418, "no_speech_prob": 0.000552671670448035}, {"id": 405, "seek": 243424, "start": 2434.24, "end": 2441.2799999999997, "text": " prediction task, this is essentially the best possible predictor. Of course, if there's a prediction", "tokens": [50364, 17630, 5633, 11, 341, 307, 4476, 264, 1151, 1944, 6069, 284, 13, 2720, 1164, 11, 498, 456, 311, 257, 17630, 50716], "temperature": 0.0, "avg_logprob": -0.12845588331462957, "compression_ratio": 1.7713178294573644, "no_speech_prob": 0.0002571123477537185}, {"id": 406, "seek": 243424, "start": 2441.2799999999997, "end": 2447.12, "text": " task, or a task which is unpredictable, like, you know, your fair coin flips, yeah, I cannot", "tokens": [50716, 5633, 11, 420, 257, 5633, 597, 307, 31160, 11, 411, 11, 291, 458, 11, 428, 3143, 11464, 40249, 11, 1338, 11, 286, 2644, 51008], "temperature": 0.0, "avg_logprob": -0.12845588331462957, "compression_ratio": 1.7713178294573644, "no_speech_prob": 0.0002571123477537185}, {"id": 407, "seek": 243424, "start": 2447.12, "end": 2450.8799999999997, "text": " predict the next fair coin, but what Solominov does is says, okay, next head is probably 50%.", "tokens": [51008, 6069, 264, 958, 3143, 11464, 11, 457, 437, 7026, 298, 2982, 85, 775, 307, 1619, 11, 1392, 11, 958, 1378, 307, 1391, 2625, 6856, 51196], "temperature": 0.0, "avg_logprob": -0.12845588331462957, "compression_ratio": 1.7713178294573644, "no_speech_prob": 0.0002571123477537185}, {"id": 408, "seek": 243424, "start": 2451.52, "end": 2455.12, "text": " It's the best you can do. So if something is unpredictable, Solominov will also not", "tokens": [51228, 467, 311, 264, 1151, 291, 393, 360, 13, 407, 498, 746, 307, 31160, 11, 7026, 298, 2982, 85, 486, 611, 406, 51408], "temperature": 0.0, "avg_logprob": -0.12845588331462957, "compression_ratio": 1.7713178294573644, "no_speech_prob": 0.0002571123477537185}, {"id": 409, "seek": 243424, "start": 2455.12, "end": 2460.56, "text": " magically predict it. But if there is some pattern and predictability, then Solominov", "tokens": [51408, 39763, 6069, 309, 13, 583, 498, 456, 307, 512, 5102, 293, 6069, 2310, 11, 550, 7026, 298, 2982, 85, 51680], "temperature": 0.0, "avg_logprob": -0.12845588331462957, "compression_ratio": 1.7713178294573644, "no_speech_prob": 0.0002571123477537185}, {"id": 410, "seek": 246056, "start": 2460.64, "end": 2466.0, "text": " induction will figure that out, eventually, and not just eventually, but rather quickly,", "tokens": [50368, 33371, 486, 2573, 300, 484, 11, 4728, 11, 293, 406, 445, 4728, 11, 457, 2831, 2661, 11, 50636], "temperature": 0.0, "avg_logprob": -0.14723107122605847, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.004067887552082539}, {"id": 411, "seek": 246056, "start": 2466.0, "end": 2473.7599999999998, "text": " and you can have proof convergence rates, whatever your data is. So there's pure magic in a sense.", "tokens": [50636, 293, 291, 393, 362, 8177, 32181, 6846, 11, 2035, 428, 1412, 307, 13, 407, 456, 311, 6075, 5585, 294, 257, 2020, 13, 51024], "temperature": 0.0, "avg_logprob": -0.14723107122605847, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.004067887552082539}, {"id": 412, "seek": 246056, "start": 2474.64, "end": 2478.16, "text": " What's the catch? Well, the catch is that it's not computable. And we come back to that later.", "tokens": [51068, 708, 311, 264, 3745, 30, 1042, 11, 264, 3745, 307, 300, 309, 311, 406, 2807, 712, 13, 400, 321, 808, 646, 281, 300, 1780, 13, 51244], "temperature": 0.0, "avg_logprob": -0.14723107122605847, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.004067887552082539}, {"id": 413, "seek": 246056, "start": 2478.16, "end": 2482.64, "text": " You cannot just implement it in even this Google resources here, and run it and, you know, predict", "tokens": [51244, 509, 2644, 445, 4445, 309, 294, 754, 341, 3329, 3593, 510, 11, 293, 1190, 309, 293, 11, 291, 458, 11, 6069, 51468], "temperature": 0.0, "avg_logprob": -0.14723107122605847, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.004067887552082539}, {"id": 414, "seek": 246056, "start": 2482.64, "end": 2487.04, "text": " the stock market and become rich. I mean, if it's raised Solominov already, you know, tried it at the", "tokens": [51468, 264, 4127, 2142, 293, 1813, 4593, 13, 286, 914, 11, 498, 309, 311, 6005, 7026, 298, 2982, 85, 1217, 11, 291, 458, 11, 3031, 309, 412, 264, 51688], "temperature": 0.0, "avg_logprob": -0.14723107122605847, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.004067887552082539}, {"id": 415, "seek": 248704, "start": 2487.04, "end": 2492.72, "text": " time. But so the basic task is you're in the environment, and you're interacting with an", "tokens": [50364, 565, 13, 583, 370, 264, 3875, 5633, 307, 291, 434, 294, 264, 2823, 11, 293, 291, 434, 18017, 365, 364, 50648], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 416, "seek": 248704, "start": 2492.72, "end": 2497.52, "text": " environment to try to learn a model of that environment. And the model is in the space of", "tokens": [50648, 2823, 281, 853, 281, 1466, 257, 2316, 295, 300, 2823, 13, 400, 264, 2316, 307, 294, 264, 1901, 295, 50888], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 417, "seek": 248704, "start": 2497.52, "end": 2501.2, "text": " these all these programs. And your goal is to get a bunch of programs that are simple.", "tokens": [50888, 613, 439, 613, 4268, 13, 400, 428, 3387, 307, 281, 483, 257, 3840, 295, 4268, 300, 366, 2199, 13, 51072], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 418, "seek": 248704, "start": 2501.2, "end": 2505.2799999999997, "text": " And so let's, let's go to the actions now. But actually, good that you asked usually,", "tokens": [51072, 400, 370, 718, 311, 11, 718, 311, 352, 281, 264, 5909, 586, 13, 583, 767, 11, 665, 300, 291, 2351, 2673, 11, 51276], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 419, "seek": 248704, "start": 2505.2799999999997, "end": 2509.6, "text": " I skipped this part, although there is also a minor contribution, which I did. So the action part,", "tokens": [51276, 286, 30193, 341, 644, 11, 4878, 456, 307, 611, 257, 6696, 13150, 11, 597, 286, 630, 13, 407, 264, 3069, 644, 11, 51492], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 420, "seek": 248704, "start": 2509.6, "end": 2513.36, "text": " but they usually sort of just jump to the decision part. So let me explain the action part now.", "tokens": [51492, 457, 436, 2673, 1333, 295, 445, 3012, 281, 264, 3537, 644, 13, 407, 718, 385, 2903, 264, 3069, 644, 586, 13, 51680], "temperature": 0.0, "avg_logprob": -0.14904171184901774, "compression_ratio": 1.9024390243902438, "no_speech_prob": 0.005379653535783291}, {"id": 421, "seek": 251336, "start": 2513.36, "end": 2521.04, "text": " Thanks for asking. So you have to modify it a little bit by now not just predicting a sequence", "tokens": [50364, 2561, 337, 3365, 13, 407, 291, 362, 281, 16927, 309, 257, 707, 857, 538, 586, 406, 445, 32884, 257, 8310, 50748], "temperature": 0.0, "avg_logprob": -0.09207362142102472, "compression_ratio": 2.0, "no_speech_prob": 0.001699952408671379}, {"id": 422, "seek": 251336, "start": 2521.04, "end": 2527.6800000000003, "text": " which just comes to you, but you have an observation, then you act somehow. And then you want to predict", "tokens": [50748, 597, 445, 1487, 281, 291, 11, 457, 291, 362, 364, 14816, 11, 550, 291, 605, 6063, 13, 400, 550, 291, 528, 281, 6069, 51080], "temperature": 0.0, "avg_logprob": -0.09207362142102472, "compression_ratio": 2.0, "no_speech_prob": 0.001699952408671379}, {"id": 423, "seek": 251336, "start": 2527.6800000000003, "end": 2533.92, "text": " the next observation based on the past observation and your action. Then you take the next action.", "tokens": [51080, 264, 958, 14816, 2361, 322, 264, 1791, 14816, 293, 428, 3069, 13, 1396, 291, 747, 264, 958, 3069, 13, 51392], "temperature": 0.0, "avg_logprob": -0.09207362142102472, "compression_ratio": 2.0, "no_speech_prob": 0.001699952408671379}, {"id": 424, "seek": 251336, "start": 2534.56, "end": 2538.96, "text": " You don't care about predicting it because you're doing it. And then you get the next observation.", "tokens": [51424, 509, 500, 380, 1127, 466, 32884, 309, 570, 291, 434, 884, 309, 13, 400, 550, 291, 483, 264, 958, 14816, 13, 51644], "temperature": 0.0, "avg_logprob": -0.09207362142102472, "compression_ratio": 2.0, "no_speech_prob": 0.001699952408671379}, {"id": 425, "seek": 251336, "start": 2538.96, "end": 2542.7200000000003, "text": " And you want, well, before you get it, you want to predict it again based on your past", "tokens": [51644, 400, 291, 528, 11, 731, 11, 949, 291, 483, 309, 11, 291, 528, 281, 6069, 309, 797, 2361, 322, 428, 1791, 51832], "temperature": 0.0, "avg_logprob": -0.09207362142102472, "compression_ratio": 2.0, "no_speech_prob": 0.001699952408671379}, {"id": 426, "seek": 254272, "start": 2542.72, "end": 2549.3599999999997, "text": " action and observation sequence. You just condition extra on your actions. There's an", "tokens": [50364, 3069, 293, 14816, 8310, 13, 509, 445, 4188, 2857, 322, 428, 5909, 13, 821, 311, 364, 50696], "temperature": 0.0, "avg_logprob": -0.182541730452557, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0010001789778470993}, {"id": 427, "seek": 254272, "start": 2549.3599999999997, "end": 2553.04, "text": " interesting alternative that you also try to predict your own actions.", "tokens": [50696, 1880, 8535, 300, 291, 611, 853, 281, 6069, 428, 1065, 5909, 13, 50880], "temperature": 0.0, "avg_logprob": -0.182541730452557, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0010001789778470993}, {"id": 428, "seek": 254272, "start": 2555.52, "end": 2560.3199999999997, "text": " If you want. In the past or the future. Your future actions. That's interesting.", "tokens": [51004, 759, 291, 528, 13, 682, 264, 1791, 420, 264, 2027, 13, 2260, 2027, 5909, 13, 663, 311, 1880, 13, 51244], "temperature": 0.0, "avg_logprob": -0.182541730452557, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0010001789778470993}, {"id": 429, "seek": 254272, "start": 2561.8399999999997, "end": 2567.3599999999997, "text": " Wait, let me wrap. I think my brain is broke. We should maybe discuss that later", "tokens": [51320, 3802, 11, 718, 385, 7019, 13, 286, 519, 452, 3567, 307, 6902, 13, 492, 820, 1310, 2248, 300, 1780, 51596], "temperature": 0.0, "avg_logprob": -0.182541730452557, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0010001789778470993}, {"id": 430, "seek": 254272, "start": 2567.3599999999997, "end": 2571.2, "text": " after I've explained the ICSE model. That's an interesting variation. But that is a really", "tokens": [51596, 934, 286, 600, 8825, 264, 14360, 5879, 2316, 13, 663, 311, 364, 1880, 12990, 13, 583, 300, 307, 257, 534, 51788], "temperature": 0.0, "avg_logprob": -0.182541730452557, "compression_ratio": 1.683127572016461, "no_speech_prob": 0.0010001789778470993}, {"id": 431, "seek": 257120, "start": 2571.2, "end": 2575.4399999999996, "text": " interesting variation. And a quick comment. I don't know if you want to insert that in here.", "tokens": [50364, 1880, 12990, 13, 400, 257, 1702, 2871, 13, 286, 500, 380, 458, 498, 291, 528, 281, 8969, 300, 294, 510, 13, 50576], "temperature": 0.0, "avg_logprob": -0.15247225357314287, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.002182063413783908}, {"id": 432, "seek": 257120, "start": 2575.4399999999996, "end": 2581.12, "text": " But you're looking at that in terms of observations, you're looking at the entire big", "tokens": [50576, 583, 291, 434, 1237, 412, 300, 294, 2115, 295, 18163, 11, 291, 434, 1237, 412, 264, 2302, 955, 50860], "temperature": 0.0, "avg_logprob": -0.15247225357314287, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.002182063413783908}, {"id": 433, "seek": 257120, "start": 2581.12, "end": 2585.6, "text": " history, the long history of the observations. Exactly. That's very important, the whole history", "tokens": [50860, 2503, 11, 264, 938, 2503, 295, 264, 18163, 13, 7587, 13, 663, 311, 588, 1021, 11, 264, 1379, 2503, 51084], "temperature": 0.0, "avg_logprob": -0.15247225357314287, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.002182063413783908}, {"id": 434, "seek": 257120, "start": 2585.6, "end": 2590.7999999999997, "text": " from birth sort of of the agent. And we can come back to that. Also why this is important here.", "tokens": [51084, 490, 3965, 1333, 295, 295, 264, 9461, 13, 400, 321, 393, 808, 646, 281, 300, 13, 2743, 983, 341, 307, 1021, 510, 13, 51344], "temperature": 0.0, "avg_logprob": -0.15247225357314287, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.002182063413783908}, {"id": 435, "seek": 257120, "start": 2590.7999999999997, "end": 2595.7599999999998, "text": " Often, you know, in RL, you have MDPs, macro decision processes, which are much more limiting.", "tokens": [51344, 20043, 11, 291, 458, 11, 294, 497, 43, 11, 291, 362, 376, 11373, 82, 11, 18887, 3537, 7555, 11, 597, 366, 709, 544, 22083, 13, 51592], "temperature": 0.0, "avg_logprob": -0.15247225357314287, "compression_ratio": 1.6884057971014492, "no_speech_prob": 0.002182063413783908}, {"id": 436, "seek": 259576, "start": 2595.76, "end": 2601.5200000000004, "text": " Okay, so now we can predict conditioned on actions. So even if the influence environment.", "tokens": [50364, 1033, 11, 370, 586, 321, 393, 6069, 35833, 322, 5909, 13, 407, 754, 498, 264, 6503, 2823, 13, 50652], "temperature": 0.0, "avg_logprob": -0.13237696735798812, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.002250887919217348}, {"id": 437, "seek": 259576, "start": 2601.5200000000004, "end": 2606.0800000000004, "text": " But prediction is not all we want to do, right? We also want to act really in the world.", "tokens": [50652, 583, 17630, 307, 406, 439, 321, 528, 281, 360, 11, 558, 30, 492, 611, 528, 281, 605, 534, 294, 264, 1002, 13, 50880], "temperature": 0.0, "avg_logprob": -0.13237696735798812, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.002250887919217348}, {"id": 438, "seek": 259576, "start": 2606.8, "end": 2612.0800000000004, "text": " And the question is how to choose the actions. And we don't want to greedily choose the actions.", "tokens": [50916, 400, 264, 1168, 307, 577, 281, 2826, 264, 5909, 13, 400, 321, 500, 380, 528, 281, 29230, 953, 2826, 264, 5909, 13, 51180], "temperature": 0.0, "avg_logprob": -0.13237696735798812, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.002250887919217348}, {"id": 439, "seek": 259576, "start": 2613.28, "end": 2617.5200000000004, "text": " You know, just, you know, what is best in the next time step. And we first I should say, you", "tokens": [51240, 509, 458, 11, 445, 11, 291, 458, 11, 437, 307, 1151, 294, 264, 958, 565, 1823, 13, 400, 321, 700, 286, 820, 584, 11, 291, 51452], "temperature": 0.0, "avg_logprob": -0.13237696735798812, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.002250887919217348}, {"id": 440, "seek": 259576, "start": 2617.5200000000004, "end": 2621.84, "text": " know, what is, you know, how do we measure performance? So we measure performance by giving", "tokens": [51452, 458, 11, 437, 307, 11, 291, 458, 11, 577, 360, 321, 3481, 3389, 30, 407, 321, 3481, 3389, 538, 2902, 51668], "temperature": 0.0, "avg_logprob": -0.13237696735798812, "compression_ratio": 1.8326693227091633, "no_speech_prob": 0.002250887919217348}, {"id": 441, "seek": 262184, "start": 2621.84, "end": 2627.04, "text": " the agent reward. That's the so called reinforcement learning framework. So every time step,", "tokens": [50364, 264, 9461, 7782, 13, 663, 311, 264, 370, 1219, 29280, 2539, 8388, 13, 407, 633, 565, 1823, 11, 50624], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 442, "seek": 262184, "start": 2627.04, "end": 2631.1200000000003, "text": " you can give it a positive reward or negative reward, or maybe no reward, it could be a very", "tokens": [50624, 291, 393, 976, 309, 257, 3353, 7782, 420, 3671, 7782, 11, 420, 1310, 572, 7782, 11, 309, 727, 312, 257, 588, 50828], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 443, "seek": 262184, "start": 2631.1200000000003, "end": 2635.36, "text": " scarce, right? Like if you play chess, just at the end of the game, you give plus one for winning", "tokens": [50828, 41340, 11, 558, 30, 1743, 498, 291, 862, 24122, 11, 445, 412, 264, 917, 295, 264, 1216, 11, 291, 976, 1804, 472, 337, 8224, 51040], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 444, "seek": 262184, "start": 2635.36, "end": 2639.84, "text": " or minus one for losing. So in the IXI framework, that's completely sufficient. So occasionally,", "tokens": [51040, 420, 3175, 472, 337, 7027, 13, 407, 294, 264, 286, 55, 40, 8388, 11, 300, 311, 2584, 11563, 13, 407, 16895, 11, 51264], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 445, "seek": 262184, "start": 2639.84, "end": 2645.1200000000003, "text": " you give a reward signal, and you ask the agent to maximize reward, but not greedily sort of,", "tokens": [51264, 291, 976, 257, 7782, 6358, 11, 293, 291, 1029, 264, 9461, 281, 19874, 7782, 11, 457, 406, 29230, 953, 1333, 295, 11, 51528], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 446, "seek": 262184, "start": 2645.1200000000003, "end": 2648.6400000000003, "text": " you know, the next one, next one, because that's very bad in the long run, if you're greedy.", "tokens": [51528, 291, 458, 11, 264, 958, 472, 11, 958, 472, 11, 570, 300, 311, 588, 1578, 294, 264, 938, 1190, 11, 498, 291, 434, 28228, 13, 51704], "temperature": 0.0, "avg_logprob": -0.12457848901618017, "compression_ratio": 1.805732484076433, "no_speech_prob": 0.0067959139123559}, {"id": 447, "seek": 264864, "start": 2648.8799999999997, "end": 2654.0, "text": " So, but over the lifetime of the agent. So let's assume the agent lives for M", "tokens": [50376, 407, 11, 457, 670, 264, 11364, 295, 264, 9461, 13, 407, 718, 311, 6552, 264, 9461, 2909, 337, 376, 50632], "temperature": 0.0, "avg_logprob": -0.18179151174184438, "compression_ratio": 1.5802919708029197, "no_speech_prob": 0.00113340571988374}, {"id": 448, "seek": 264864, "start": 2654.0, "end": 2658.3199999999997, "text": " time steps as they dice in sort of 100 years sharp. That's just, you know, the simplest model", "tokens": [50632, 565, 4439, 382, 436, 10313, 294, 1333, 295, 2319, 924, 8199, 13, 663, 311, 445, 11, 291, 458, 11, 264, 22811, 2316, 50848], "temperature": 0.0, "avg_logprob": -0.18179151174184438, "compression_ratio": 1.5802919708029197, "no_speech_prob": 0.00113340571988374}, {"id": 449, "seek": 264864, "start": 2658.3199999999997, "end": 2665.12, "text": " to explain. So it looks at the future reward sum and ask what is my action sequence, or actually", "tokens": [50848, 281, 2903, 13, 407, 309, 1542, 412, 264, 2027, 7782, 2408, 293, 1029, 437, 307, 452, 3069, 8310, 11, 420, 767, 51188], "temperature": 0.0, "avg_logprob": -0.18179151174184438, "compression_ratio": 1.5802919708029197, "no_speech_prob": 0.00113340571988374}, {"id": 450, "seek": 264864, "start": 2665.12, "end": 2670.8799999999997, "text": " more precisely my policy, which leads in expectation, because I don't know the world,", "tokens": [51188, 544, 13402, 452, 3897, 11, 597, 6689, 294, 14334, 11, 570, 286, 500, 380, 458, 264, 1002, 11, 51476], "temperature": 0.0, "avg_logprob": -0.18179151174184438, "compression_ratio": 1.5802919708029197, "no_speech_prob": 0.00113340571988374}, {"id": 451, "seek": 264864, "start": 2672.08, "end": 2677.2, "text": " to the maximum reward sum. Let me give you an analogy. In chess, for instance,", "tokens": [51536, 281, 264, 6674, 7782, 2408, 13, 961, 385, 976, 291, 364, 21663, 13, 682, 24122, 11, 337, 5197, 11, 51792], "temperature": 0.0, "avg_logprob": -0.18179151174184438, "compression_ratio": 1.5802919708029197, "no_speech_prob": 0.00113340571988374}, {"id": 452, "seek": 267720, "start": 2678.16, "end": 2683.3599999999997, "text": " we know how to play optimally in theory, it's just a mini max strategy. I play the move which", "tokens": [50412, 321, 458, 577, 281, 862, 5028, 379, 294, 5261, 11, 309, 311, 445, 257, 8382, 11469, 5206, 13, 286, 862, 264, 1286, 597, 50672], "temperature": 0.0, "avg_logprob": -0.15939065330048913, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0014322022907435894}, {"id": 453, "seek": 267720, "start": 2683.3599999999997, "end": 2688.56, "text": " seems best to me under the assumption that the opponent plays the move which is best for him,", "tokens": [50672, 2544, 1151, 281, 385, 833, 264, 15302, 300, 264, 10620, 5749, 264, 1286, 597, 307, 1151, 337, 796, 11, 50932], "temperature": 0.0, "avg_logprob": -0.15939065330048913, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0014322022907435894}, {"id": 454, "seek": 267720, "start": 2688.56, "end": 2694.48, "text": " so best, so worst for me, under the assumption that he I play again, the best move. And then you", "tokens": [50932, 370, 1151, 11, 370, 5855, 337, 385, 11, 833, 264, 15302, 300, 415, 286, 862, 797, 11, 264, 1151, 1286, 13, 400, 550, 291, 51228], "temperature": 0.0, "avg_logprob": -0.15939065330048913, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0014322022907435894}, {"id": 455, "seek": 267720, "start": 2694.48, "end": 2699.12, "text": " have this expecting max three to the end of the game. And then you back propagate and then you", "tokens": [51228, 362, 341, 9650, 11469, 1045, 281, 264, 917, 295, 264, 1216, 13, 400, 550, 291, 646, 48256, 293, 550, 291, 51460], "temperature": 0.0, "avg_logprob": -0.15939065330048913, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0014322022907435894}, {"id": 456, "seek": 267720, "start": 2699.12, "end": 2702.96, "text": " get the best possible move. So that is the optimal strategy, which for Neumann already", "tokens": [51460, 483, 264, 1151, 1944, 1286, 13, 407, 300, 307, 264, 16252, 5206, 11, 597, 337, 1734, 449, 969, 1217, 51652], "temperature": 0.0, "avg_logprob": -0.15939065330048913, "compression_ratio": 1.8866396761133604, "no_speech_prob": 0.0014322022907435894}, {"id": 457, "seek": 270296, "start": 2702.96, "end": 2710.64, "text": " figured out a long time ago, for playing adversarial games, luckily, or maybe unluckily,", "tokens": [50364, 8932, 484, 257, 938, 565, 2057, 11, 337, 2433, 17641, 44745, 2813, 11, 22880, 11, 420, 1310, 32118, 1134, 953, 11, 50748], "temperature": 0.0, "avg_logprob": -0.16109307058926287, "compression_ratio": 1.7328244274809161, "no_speech_prob": 0.007341837044805288}, {"id": 458, "seek": 270296, "start": 2710.64, "end": 2716.4, "text": " for the theory, it becomes harder that world is not always adversarial. So it can be,", "tokens": [50748, 337, 264, 5261, 11, 309, 3643, 6081, 300, 1002, 307, 406, 1009, 17641, 44745, 13, 407, 309, 393, 312, 11, 51036], "temperature": 0.0, "avg_logprob": -0.16109307058926287, "compression_ratio": 1.7328244274809161, "no_speech_prob": 0.007341837044805288}, {"id": 459, "seek": 270296, "start": 2716.4, "end": 2721.28, "text": " if the other humans even cooperative here, or nature is usually I mean, the dead nature is", "tokens": [51036, 498, 264, 661, 6255, 754, 31772, 510, 11, 420, 3687, 307, 2673, 286, 914, 11, 264, 3116, 3687, 307, 51280], "temperature": 0.0, "avg_logprob": -0.16109307058926287, "compression_ratio": 1.7328244274809161, "no_speech_prob": 0.007341837044805288}, {"id": 460, "seek": 270296, "start": 2721.28, "end": 2727.52, "text": " stochastic, you know, things just happen randomly, or don't care about you. So what you have to", "tokens": [51280, 342, 8997, 2750, 11, 291, 458, 11, 721, 445, 1051, 16979, 11, 420, 500, 380, 1127, 466, 291, 13, 407, 437, 291, 362, 281, 51592], "temperature": 0.0, "avg_logprob": -0.16109307058926287, "compression_ratio": 1.7328244274809161, "no_speech_prob": 0.007341837044805288}, {"id": 461, "seek": 270296, "start": 2727.52, "end": 2732.0, "text": " take into account is the noise, you know, and not necessarily adversariality. So you replace", "tokens": [51592, 747, 666, 2696, 307, 264, 5658, 11, 291, 458, 11, 293, 406, 4725, 17641, 44745, 507, 13, 407, 291, 7406, 51816], "temperature": 0.0, "avg_logprob": -0.16109307058926287, "compression_ratio": 1.7328244274809161, "no_speech_prob": 0.007341837044805288}, {"id": 462, "seek": 273200, "start": 2732.0, "end": 2737.36, "text": " the minimum on the opponent's side by an expectation, which is general enough to include", "tokens": [50364, 264, 7285, 322, 264, 10620, 311, 1252, 538, 364, 14334, 11, 597, 307, 2674, 1547, 281, 4090, 50632], "temperature": 0.0, "avg_logprob": -0.16640933197323637, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.0007207158487290144}, {"id": 463, "seek": 273200, "start": 2737.36, "end": 2743.04, "text": " also adversarial cases. So now instead of a mini max strategy of an expecting max strategy.", "tokens": [50632, 611, 17641, 44745, 3331, 13, 407, 586, 2602, 295, 257, 8382, 11469, 5206, 295, 364, 9650, 11469, 5206, 13, 50916], "temperature": 0.0, "avg_logprob": -0.16640933197323637, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.0007207158487290144}, {"id": 464, "seek": 273200, "start": 2743.76, "end": 2746.96, "text": " So far so good. So that is well known. It's called sequential decision theory.", "tokens": [50952, 407, 1400, 370, 665, 13, 407, 300, 307, 731, 2570, 13, 467, 311, 1219, 42881, 3537, 5261, 13, 51112], "temperature": 0.0, "avg_logprob": -0.16640933197323637, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.0007207158487290144}, {"id": 465, "seek": 273200, "start": 2747.92, "end": 2753.2, "text": " But the question is, on which probability distribution do you base that if I have the", "tokens": [51160, 583, 264, 1168, 307, 11, 322, 597, 8482, 7316, 360, 291, 3096, 300, 498, 286, 362, 264, 51424], "temperature": 0.0, "avg_logprob": -0.16640933197323637, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.0007207158487290144}, {"id": 466, "seek": 273200, "start": 2753.2, "end": 2757.84, "text": " true probability distribution, like say I play beggining, right, there's dice,", "tokens": [51424, 2074, 8482, 7316, 11, 411, 584, 286, 862, 4612, 1494, 278, 11, 558, 11, 456, 311, 10313, 11, 51656], "temperature": 0.0, "avg_logprob": -0.16640933197323637, "compression_ratio": 1.6758893280632412, "no_speech_prob": 0.0007207158487290144}, {"id": 467, "seek": 275784, "start": 2757.84, "end": 2761.6800000000003, "text": " and there's certain randomness involved, yeah, I can calculate probabilities and feed it in the", "tokens": [50364, 293, 456, 311, 1629, 4974, 1287, 3288, 11, 1338, 11, 286, 393, 8873, 33783, 293, 3154, 309, 294, 264, 50556], "temperature": 0.0, "avg_logprob": -0.1654795133150541, "compression_ratio": 1.7117437722419928, "no_speech_prob": 0.0007911657448858023}, {"id": 468, "seek": 275784, "start": 2761.6800000000003, "end": 2765.76, "text": " expecting max or the sequential decision tree, come up with the optimal decision if I have", "tokens": [50556, 9650, 11469, 420, 264, 42881, 3537, 4230, 11, 808, 493, 365, 264, 16252, 3537, 498, 286, 362, 50760], "temperature": 0.0, "avg_logprob": -0.1654795133150541, "compression_ratio": 1.7117437722419928, "no_speech_prob": 0.0007911657448858023}, {"id": 469, "seek": 275784, "start": 2765.76, "end": 2770.8, "text": " enough compute. But in the for the real world, we don't know that, you know, what is the probability", "tokens": [50760, 1547, 14722, 13, 583, 294, 264, 337, 264, 957, 1002, 11, 321, 500, 380, 458, 300, 11, 291, 458, 11, 437, 307, 264, 8482, 51012], "temperature": 0.0, "avg_logprob": -0.1654795133150541, "compression_ratio": 1.7117437722419928, "no_speech_prob": 0.0007911657448858023}, {"id": 470, "seek": 275784, "start": 2771.52, "end": 2777.04, "text": " the driver in front of me breaks. I don't know. Yeah, so depends on all kinds of things. And", "tokens": [51048, 264, 6787, 294, 1868, 295, 385, 9857, 13, 286, 500, 380, 458, 13, 865, 11, 370, 5946, 322, 439, 3685, 295, 721, 13, 400, 51324], "temperature": 0.0, "avg_logprob": -0.1654795133150541, "compression_ratio": 1.7117437722419928, "no_speech_prob": 0.0007911657448858023}, {"id": 471, "seek": 275784, "start": 2777.6800000000003, "end": 2782.8, "text": " especially new situations, I don't know. So this is this unknown thing about prediction. And there's", "tokens": [51356, 2318, 777, 6851, 11, 286, 500, 380, 458, 13, 407, 341, 307, 341, 9841, 551, 466, 17630, 13, 400, 456, 311, 51612], "temperature": 0.0, "avg_logprob": -0.1654795133150541, "compression_ratio": 1.7117437722419928, "no_speech_prob": 0.0007911657448858023}, {"id": 472, "seek": 278280, "start": 2782.8, "end": 2787.76, "text": " where Solomanov comes in. So what you do is in sequential decision tree, you just replace the", "tokens": [50364, 689, 7026, 298, 38990, 1487, 294, 13, 407, 437, 291, 360, 307, 294, 42881, 3537, 4230, 11, 291, 445, 7406, 264, 50612], "temperature": 0.0, "avg_logprob": -0.10940149480646306, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.007231337018311024}, {"id": 473, "seek": 278280, "start": 2787.76, "end": 2794.0, "text": " true distribution, which we don't know, by this universal distribution, I didn't explicitly", "tokens": [50612, 2074, 7316, 11, 597, 321, 500, 380, 458, 11, 538, 341, 11455, 7316, 11, 286, 994, 380, 20803, 50924], "temperature": 0.0, "avg_logprob": -0.10940149480646306, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.007231337018311024}, {"id": 474, "seek": 278280, "start": 2794.0, "end": 2799.04, "text": " talk about it, but this is used for universal prediction, and plug it into the sequential", "tokens": [50924, 751, 466, 309, 11, 457, 341, 307, 1143, 337, 11455, 17630, 11, 293, 5452, 309, 666, 264, 42881, 51176], "temperature": 0.0, "avg_logprob": -0.10940149480646306, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.007231337018311024}, {"id": 475, "seek": 278280, "start": 2799.04, "end": 2804.0, "text": " decision tree mechanism. And then you get the best of both worlds. You have a long term planning", "tokens": [51176, 3537, 4230, 7513, 13, 400, 550, 291, 483, 264, 1151, 295, 1293, 13401, 13, 509, 362, 257, 938, 1433, 5038, 51424], "temperature": 0.0, "avg_logprob": -0.10940149480646306, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.007231337018311024}, {"id": 476, "seek": 278280, "start": 2804.0, "end": 2809.76, "text": " agent. But it doesn't need to know anything about the world, because the Solomanov induction part", "tokens": [51424, 9461, 13, 583, 309, 1177, 380, 643, 281, 458, 1340, 466, 264, 1002, 11, 570, 264, 7026, 298, 38990, 33371, 644, 51712], "temperature": 0.0, "avg_logprob": -0.10940149480646306, "compression_ratio": 1.7216117216117217, "no_speech_prob": 0.007231337018311024}, {"id": 477, "seek": 280976, "start": 2810.7200000000003, "end": 2818.48, "text": " learns. Can you explicitly try to describe the universal distribution and how Solomanov induction", "tokens": [50412, 27152, 13, 1664, 291, 20803, 853, 281, 6786, 264, 11455, 7316, 293, 577, 7026, 298, 38990, 33371, 50800], "temperature": 0.0, "avg_logprob": -0.14312877235831795, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.004753881599754095}, {"id": 478, "seek": 280976, "start": 2818.48, "end": 2823.76, "text": " plays a role here? I'm trying to understand. So what he does it. So in the simplest case,", "tokens": [50800, 5749, 257, 3090, 510, 30, 286, 478, 1382, 281, 1223, 13, 407, 437, 415, 775, 309, 13, 407, 294, 264, 22811, 1389, 11, 51064], "temperature": 0.0, "avg_logprob": -0.14312877235831795, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.004753881599754095}, {"id": 479, "seek": 280976, "start": 2823.76, "end": 2828.0, "text": " I said, take the shortest program describing your data, run it, have a prediction which would be", "tokens": [51064, 286, 848, 11, 747, 264, 31875, 1461, 16141, 428, 1412, 11, 1190, 309, 11, 362, 257, 17630, 597, 576, 312, 51276], "temperature": 0.0, "avg_logprob": -0.14312877235831795, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.004753881599754095}, {"id": 480, "seek": 280976, "start": 2828.0, "end": 2834.0800000000004, "text": " deterministic. Yes. Okay. But you should not just take the shortest program, but also consider the", "tokens": [51276, 15957, 3142, 13, 1079, 13, 1033, 13, 583, 291, 820, 406, 445, 747, 264, 31875, 1461, 11, 457, 611, 1949, 264, 51580], "temperature": 0.0, "avg_logprob": -0.14312877235831795, "compression_ratio": 1.5958333333333334, "no_speech_prob": 0.004753881599754095}, {"id": 481, "seek": 283408, "start": 2834.08, "end": 2842.3199999999997, "text": " longer ones, but keep it lower a priori probability. So in the Bayesian framework, you say a priori,", "tokens": [50364, 2854, 2306, 11, 457, 1066, 309, 3126, 257, 4059, 72, 8482, 13, 407, 294, 264, 7840, 42434, 8388, 11, 291, 584, 257, 4059, 72, 11, 50776], "temperature": 0.0, "avg_logprob": -0.13695689329167002, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.0011333543807268143}, {"id": 482, "seek": 283408, "start": 2842.3199999999997, "end": 2850.24, "text": " any distribution, which is a model, or a stochastic program has a certain a priori", "tokens": [50776, 604, 7316, 11, 597, 307, 257, 2316, 11, 420, 257, 342, 8997, 2750, 1461, 575, 257, 1629, 257, 4059, 72, 51172], "temperature": 0.0, "avg_logprob": -0.13695689329167002, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.0011333543807268143}, {"id": 483, "seek": 283408, "start": 2850.24, "end": 2854.48, "text": " probability, which is two to the minus and y two to the minus length, you know, I could explain", "tokens": [51172, 8482, 11, 597, 307, 732, 281, 264, 3175, 293, 288, 732, 281, 264, 3175, 4641, 11, 291, 458, 11, 286, 727, 2903, 51384], "temperature": 0.0, "avg_logprob": -0.13695689329167002, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.0011333543807268143}, {"id": 484, "seek": 283408, "start": 2854.48, "end": 2861.2799999999997, "text": " length of this program. So longer programs are punished, a priori. And then you multiply it", "tokens": [51384, 4641, 295, 341, 1461, 13, 407, 2854, 4268, 366, 22365, 11, 257, 4059, 72, 13, 400, 550, 291, 12972, 309, 51724], "temperature": 0.0, "avg_logprob": -0.13695689329167002, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.0011333543807268143}, {"id": 485, "seek": 286128, "start": 2861.28, "end": 2868.0800000000004, "text": " with the so called likelihood function. Yeah, which is as the name suggests, is how likely", "tokens": [50364, 365, 264, 370, 1219, 22119, 2445, 13, 865, 11, 597, 307, 382, 264, 1315, 13409, 11, 307, 577, 3700, 50704], "temperature": 0.0, "avg_logprob": -0.11968832256413307, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.0016741668805480003}, {"id": 486, "seek": 286128, "start": 2868.0800000000004, "end": 2874.1600000000003, "text": " is this model given the data at hand. So if you have a very wrong model, it's very unlikely", "tokens": [50704, 307, 341, 2316, 2212, 264, 1412, 412, 1011, 13, 407, 498, 291, 362, 257, 588, 2085, 2316, 11, 309, 311, 588, 17518, 51008], "temperature": 0.0, "avg_logprob": -0.11968832256413307, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.0016741668805480003}, {"id": 487, "seek": 286128, "start": 2874.1600000000003, "end": 2878.8, "text": " that this model is true. And so it is very small numbers. So even if the model is simple, it gets", "tokens": [51008, 300, 341, 2316, 307, 2074, 13, 400, 370, 309, 307, 588, 1359, 3547, 13, 407, 754, 498, 264, 2316, 307, 2199, 11, 309, 2170, 51240], "temperature": 0.0, "avg_logprob": -0.11968832256413307, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.0016741668805480003}, {"id": 488, "seek": 286128, "start": 2878.8, "end": 2884.48, "text": " penalized by that. And what you do is then you take just the sum, but this is the average over it.", "tokens": [51240, 13661, 1602, 538, 300, 13, 400, 437, 291, 360, 307, 550, 291, 747, 445, 264, 2408, 11, 457, 341, 307, 264, 4274, 670, 309, 13, 51524], "temperature": 0.0, "avg_logprob": -0.11968832256413307, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.0016741668805480003}, {"id": 489, "seek": 286128, "start": 2884.48, "end": 2890.48, "text": " And this gives you a probability distribution. So universal distribution or Solomanov distribution.", "tokens": [51524, 400, 341, 2709, 291, 257, 8482, 7316, 13, 407, 11455, 7316, 420, 7026, 298, 38990, 7316, 13, 51824], "temperature": 0.0, "avg_logprob": -0.11968832256413307, "compression_ratio": 1.787313432835821, "no_speech_prob": 0.0016741668805480003}, {"id": 490, "seek": 289048, "start": 2890.48, "end": 2894.32, "text": " So it's weighed by the simplicity of the program and likelihood. Yes.", "tokens": [50364, 407, 309, 311, 32844, 538, 264, 25632, 295, 264, 1461, 293, 22119, 13, 1079, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1570363998413086, "compression_ratio": 1.625, "no_speech_prob": 0.002147412160411477}, {"id": 491, "seek": 289048, "start": 2895.2, "end": 2902.48, "text": " It's kind of a nice idea. Yeah. So okay. And then you said there's your planning", "tokens": [50600, 467, 311, 733, 295, 257, 1481, 1558, 13, 865, 13, 407, 1392, 13, 400, 550, 291, 848, 456, 311, 428, 5038, 50964], "temperature": 0.0, "avg_logprob": -0.1570363998413086, "compression_ratio": 1.625, "no_speech_prob": 0.002147412160411477}, {"id": 492, "seek": 289048, "start": 2902.48, "end": 2908.48, "text": " n or m or forgot the letter steps into the future. So how difficult is that problem? What's", "tokens": [50964, 297, 420, 275, 420, 5298, 264, 5063, 4439, 666, 264, 2027, 13, 407, 577, 2252, 307, 300, 1154, 30, 708, 311, 51264], "temperature": 0.0, "avg_logprob": -0.1570363998413086, "compression_ratio": 1.625, "no_speech_prob": 0.002147412160411477}, {"id": 493, "seek": 289048, "start": 2908.48, "end": 2912.72, "text": " involved there? Okay, basic optimization problem? What are we talking about? Yeah, so you have a", "tokens": [51264, 3288, 456, 30, 1033, 11, 3875, 19618, 1154, 30, 708, 366, 321, 1417, 466, 30, 865, 11, 370, 291, 362, 257, 51476], "temperature": 0.0, "avg_logprob": -0.1570363998413086, "compression_ratio": 1.625, "no_speech_prob": 0.002147412160411477}, {"id": 494, "seek": 289048, "start": 2912.72, "end": 2918.64, "text": " planning problem up to horizon m. And that's exponential time in the horizon m, which is,", "tokens": [51476, 5038, 1154, 493, 281, 18046, 275, 13, 400, 300, 311, 21510, 565, 294, 264, 18046, 275, 11, 597, 307, 11, 51772], "temperature": 0.0, "avg_logprob": -0.1570363998413086, "compression_ratio": 1.625, "no_speech_prob": 0.002147412160411477}, {"id": 495, "seek": 291864, "start": 2918.64, "end": 2923.44, "text": " I mean, it's computable, but in fact, intractable. I mean, even for chess, it's already intractable", "tokens": [50364, 286, 914, 11, 309, 311, 2807, 712, 11, 457, 294, 1186, 11, 560, 1897, 712, 13, 286, 914, 11, 754, 337, 24122, 11, 309, 311, 1217, 560, 1897, 712, 50604], "temperature": 0.0, "avg_logprob": -0.17809785890185142, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00018809160974342376}, {"id": 496, "seek": 291864, "start": 2923.44, "end": 2928.08, "text": " to do that exactly. And, you know, for though, but it could be also discounted kind of framework", "tokens": [50604, 281, 360, 300, 2293, 13, 400, 11, 291, 458, 11, 337, 1673, 11, 457, 309, 727, 312, 611, 11635, 292, 733, 295, 8388, 50836], "temperature": 0.0, "avg_logprob": -0.17809785890185142, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00018809160974342376}, {"id": 497, "seek": 291864, "start": 2928.08, "end": 2934.56, "text": " where so, so having a hard horizon, you know, at 100 years, it's just for simplicity of", "tokens": [50836, 689, 370, 11, 370, 1419, 257, 1152, 18046, 11, 291, 458, 11, 412, 2319, 924, 11, 309, 311, 445, 337, 25632, 295, 51160], "temperature": 0.0, "avg_logprob": -0.17809785890185142, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00018809160974342376}, {"id": 498, "seek": 291864, "start": 2934.56, "end": 2940.0, "text": " discussing the model. And also sometimes the master simple. But there are lots of variations.", "tokens": [51160, 10850, 264, 2316, 13, 400, 611, 2171, 264, 4505, 2199, 13, 583, 456, 366, 3195, 295, 17840, 13, 51432], "temperature": 0.0, "avg_logprob": -0.17809785890185142, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00018809160974342376}, {"id": 499, "seek": 291864, "start": 2940.0, "end": 2947.12, "text": " Actually, quite interesting parameter is it's, there's nothing really problematic about it.", "tokens": [51432, 5135, 11, 1596, 1880, 13075, 307, 309, 311, 11, 456, 311, 1825, 534, 19011, 466, 309, 13, 51788], "temperature": 0.0, "avg_logprob": -0.17809785890185142, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.00018809160974342376}, {"id": 500, "seek": 294712, "start": 2947.12, "end": 2950.96, "text": " But it's very interesting. So for instance, you think, no, let's, let's, let's, let's let the", "tokens": [50364, 583, 309, 311, 588, 1880, 13, 407, 337, 5197, 11, 291, 519, 11, 572, 11, 718, 311, 11, 718, 311, 11, 718, 311, 11, 718, 311, 718, 264, 50556], "temperature": 0.0, "avg_logprob": -0.16285591740762034, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00198761117644608}, {"id": 501, "seek": 294712, "start": 2950.96, "end": 2956.24, "text": " parameter m tend to infinity, right? You want an agent, which lives forever, right? If you do it", "tokens": [50556, 13075, 275, 3928, 281, 13202, 11, 558, 30, 509, 528, 364, 9461, 11, 597, 2909, 5680, 11, 558, 30, 759, 291, 360, 309, 50820], "temperature": 0.0, "avg_logprob": -0.16285591740762034, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00198761117644608}, {"id": 502, "seek": 294712, "start": 2956.24, "end": 2960.56, "text": " now, you have two problems. First, the mathematics breaks down because you have an infinite reward", "tokens": [50820, 586, 11, 291, 362, 732, 2740, 13, 2386, 11, 264, 18666, 9857, 760, 570, 291, 362, 364, 13785, 7782, 51036], "temperature": 0.0, "avg_logprob": -0.16285591740762034, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00198761117644608}, {"id": 503, "seek": 294712, "start": 2960.56, "end": 2966.24, "text": " sum, which may give infinity and getting reward 0.1 in the time step is infinity and giving reward", "tokens": [51036, 2408, 11, 597, 815, 976, 13202, 293, 1242, 7782, 1958, 13, 16, 294, 264, 565, 1823, 307, 13202, 293, 2902, 7782, 51320], "temperature": 0.0, "avg_logprob": -0.16285591740762034, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00198761117644608}, {"id": 504, "seek": 294712, "start": 2966.24, "end": 2972.64, "text": " one every time step is infinity. So equally good. Not really what we want. Other problem is that", "tokens": [51320, 472, 633, 565, 1823, 307, 13202, 13, 407, 12309, 665, 13, 1726, 534, 437, 321, 528, 13, 5358, 1154, 307, 300, 51640], "temperature": 0.0, "avg_logprob": -0.16285591740762034, "compression_ratio": 1.7962962962962963, "no_speech_prob": 0.00198761117644608}, {"id": 505, "seek": 297264, "start": 2973.6, "end": 2979.12, "text": " if you have an infinite life, you can be lazy for as long as you want for 10 years and then catch", "tokens": [50412, 498, 291, 362, 364, 13785, 993, 11, 291, 393, 312, 14847, 337, 382, 938, 382, 291, 528, 337, 1266, 924, 293, 550, 3745, 50688], "temperature": 0.0, "avg_logprob": -0.08497671508789062, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0009695691987872124}, {"id": 506, "seek": 297264, "start": 2979.12, "end": 2984.96, "text": " up with the same expected reward. And, you know, think about yourself or, you know, or maybe,", "tokens": [50688, 493, 365, 264, 912, 5176, 7782, 13, 400, 11, 291, 458, 11, 519, 466, 1803, 420, 11, 291, 458, 11, 420, 1310, 11, 50980], "temperature": 0.0, "avg_logprob": -0.08497671508789062, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0009695691987872124}, {"id": 507, "seek": 297264, "start": 2984.96, "end": 2991.2799999999997, "text": " you know, some friends or so, if they knew they lived forever, you know, why work hard now, you", "tokens": [50980, 291, 458, 11, 512, 1855, 420, 370, 11, 498, 436, 2586, 436, 5152, 5680, 11, 291, 458, 11, 983, 589, 1152, 586, 11, 291, 51296], "temperature": 0.0, "avg_logprob": -0.08497671508789062, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0009695691987872124}, {"id": 508, "seek": 297264, "start": 2991.2799999999997, "end": 2995.44, "text": " know, just enjoy your life, you know, and then catch up later. So that's another problem with", "tokens": [51296, 458, 11, 445, 2103, 428, 993, 11, 291, 458, 11, 293, 550, 3745, 493, 1780, 13, 407, 300, 311, 1071, 1154, 365, 51504], "temperature": 0.0, "avg_logprob": -0.08497671508789062, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0009695691987872124}, {"id": 509, "seek": 297264, "start": 2995.44, "end": 3000.56, "text": " the infinite horizon. And you mentioned, yes, we can go to discounting. But then the standard", "tokens": [51504, 264, 13785, 18046, 13, 400, 291, 2835, 11, 2086, 11, 321, 393, 352, 281, 11635, 278, 13, 583, 550, 264, 3832, 51760], "temperature": 0.0, "avg_logprob": -0.08497671508789062, "compression_ratio": 1.7924528301886793, "no_speech_prob": 0.0009695691987872124}, {"id": 510, "seek": 300056, "start": 3000.64, "end": 3005.92, "text": " discounting is so-called geometric discounting. So a dollar today is about worth as much as,", "tokens": [50368, 11635, 278, 307, 370, 12, 11880, 33246, 11635, 278, 13, 407, 257, 7241, 965, 307, 466, 3163, 382, 709, 382, 11, 50632], "temperature": 0.0, "avg_logprob": -0.0783942489213841, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.00302726193331182}, {"id": 511, "seek": 300056, "start": 3005.92, "end": 3011.52, "text": " you know, $1.05 tomorrow. So if you do the so-called geometric discounting, you have introduced an", "tokens": [50632, 291, 458, 11, 1848, 16, 13, 13328, 4153, 13, 407, 498, 291, 360, 264, 370, 12, 11880, 33246, 11635, 278, 11, 291, 362, 7268, 364, 50912], "temperature": 0.0, "avg_logprob": -0.0783942489213841, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.00302726193331182}, {"id": 512, "seek": 300056, "start": 3011.52, "end": 3018.32, "text": " effective horizon. So the agent is now motivated to look ahead a certain amount of time effectively.", "tokens": [50912, 4942, 18046, 13, 407, 264, 9461, 307, 586, 14515, 281, 574, 2286, 257, 1629, 2372, 295, 565, 8659, 13, 51252], "temperature": 0.0, "avg_logprob": -0.0783942489213841, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.00302726193331182}, {"id": 513, "seek": 300056, "start": 3018.32, "end": 3025.12, "text": " It's like a moving horizon. And for any fixed effective horizon, there is a problem", "tokens": [51252, 467, 311, 411, 257, 2684, 18046, 13, 400, 337, 604, 6806, 4942, 18046, 11, 456, 307, 257, 1154, 51592], "temperature": 0.0, "avg_logprob": -0.0783942489213841, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.00302726193331182}, {"id": 514, "seek": 302512, "start": 3025.92, "end": 3030.4, "text": " to solve which requires larger horizons. So if I look ahead, you know, five time steps,", "tokens": [50404, 281, 5039, 597, 7029, 4833, 7937, 892, 13, 407, 498, 286, 574, 2286, 11, 291, 458, 11, 1732, 565, 4439, 11, 50628], "temperature": 0.0, "avg_logprob": -0.12717217984406845, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0022165696136653423}, {"id": 515, "seek": 302512, "start": 3030.4, "end": 3035.52, "text": " I'm a terrible chess player, right? I'll need to look ahead longer. If I play go, I probably", "tokens": [50628, 286, 478, 257, 6237, 24122, 4256, 11, 558, 30, 286, 603, 643, 281, 574, 2286, 2854, 13, 759, 286, 862, 352, 11, 286, 1391, 50884], "temperature": 0.0, "avg_logprob": -0.12717217984406845, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0022165696136653423}, {"id": 516, "seek": 302512, "start": 3035.52, "end": 3041.2799999999997, "text": " have to look ahead even longer. So for every problem, no, for every horizon, there is a problem", "tokens": [50884, 362, 281, 574, 2286, 754, 2854, 13, 407, 337, 633, 1154, 11, 572, 11, 337, 633, 18046, 11, 456, 307, 257, 1154, 51172], "temperature": 0.0, "avg_logprob": -0.12717217984406845, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0022165696136653423}, {"id": 517, "seek": 302512, "start": 3041.2799999999997, "end": 3047.2799999999997, "text": " which this horizon cannot solve. But I introduced the so-called near harmonic horizon, which goes", "tokens": [51172, 597, 341, 18046, 2644, 5039, 13, 583, 286, 7268, 264, 370, 12, 11880, 2651, 32270, 18046, 11, 597, 1709, 51472], "temperature": 0.0, "avg_logprob": -0.12717217984406845, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0022165696136653423}, {"id": 518, "seek": 302512, "start": 3047.2799999999997, "end": 3052.64, "text": " down with one over t rather than exponentially t, which produces an agent which effectively looks", "tokens": [51472, 760, 365, 472, 670, 256, 2831, 813, 37330, 256, 11, 597, 14725, 364, 9461, 597, 8659, 1542, 51740], "temperature": 0.0, "avg_logprob": -0.12717217984406845, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.0022165696136653423}, {"id": 519, "seek": 305264, "start": 3052.64, "end": 3057.2799999999997, "text": " into the future proportional to each age. So if it's five years old, it plans for five years.", "tokens": [50364, 666, 264, 2027, 24969, 281, 1184, 3205, 13, 407, 498, 309, 311, 1732, 924, 1331, 11, 309, 5482, 337, 1732, 924, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 520, "seek": 305264, "start": 3057.2799999999997, "end": 3062.0, "text": " If it's 100 years old, it then plans for 100 years. And it's a little bit similar to humans,", "tokens": [50596, 759, 309, 311, 2319, 924, 1331, 11, 309, 550, 5482, 337, 2319, 924, 13, 400, 309, 311, 257, 707, 857, 2531, 281, 6255, 11, 50832], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 521, "seek": 305264, "start": 3062.0, "end": 3066.24, "text": " too, right? I mean, children don't plan ahead very long, but then we get adults, we play ahead", "tokens": [50832, 886, 11, 558, 30, 286, 914, 11, 2227, 500, 380, 1393, 2286, 588, 938, 11, 457, 550, 321, 483, 8865, 11, 321, 862, 2286, 51044], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 522, "seek": 305264, "start": 3066.24, "end": 3070.16, "text": " more longer. Maybe when we get very old, I mean, we know that we don't live forever,", "tokens": [51044, 544, 2854, 13, 2704, 562, 321, 483, 588, 1331, 11, 286, 914, 11, 321, 458, 300, 321, 500, 380, 1621, 5680, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 523, "seek": 305264, "start": 3070.16, "end": 3076.96, "text": " you know, maybe then our horizon shrinks again. So that's really interesting. So adjusting the", "tokens": [51240, 291, 458, 11, 1310, 550, 527, 18046, 9884, 16431, 797, 13, 407, 300, 311, 534, 1880, 13, 407, 23559, 264, 51580], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 524, "seek": 305264, "start": 3076.96, "end": 3081.52, "text": " horizon, what is there some mathematical benefit of that? Or is it just a nice", "tokens": [51580, 18046, 11, 437, 307, 456, 512, 18894, 5121, 295, 300, 30, 1610, 307, 309, 445, 257, 1481, 51808], "temperature": 0.0, "avg_logprob": -0.1541029970410844, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.006584752816706896}, {"id": 525, "seek": 308264, "start": 3082.8799999999997, "end": 3087.12, "text": " I mean, intuitively, empirically, it will probably be a good idea to sort of push the", "tokens": [50376, 286, 914, 11, 46506, 11, 25790, 984, 11, 309, 486, 1391, 312, 257, 665, 1558, 281, 1333, 295, 2944, 264, 50588], "temperature": 0.0, "avg_logprob": -0.22536933898925782, "compression_ratio": 1.6392156862745098, "no_speech_prob": 0.0003245178086217493}, {"id": 526, "seek": 308264, "start": 3087.12, "end": 3093.7599999999998, "text": " horizon back to extend the horizon as you experience more of the world. But is there", "tokens": [50588, 18046, 646, 281, 10101, 264, 18046, 382, 291, 1752, 544, 295, 264, 1002, 13, 583, 307, 456, 50920], "temperature": 0.0, "avg_logprob": -0.22536933898925782, "compression_ratio": 1.6392156862745098, "no_speech_prob": 0.0003245178086217493}, {"id": 527, "seek": 308264, "start": 3093.7599999999998, "end": 3096.48, "text": " some mathematical conclusions here that are beneficial?", "tokens": [50920, 512, 18894, 22865, 510, 300, 366, 14072, 30, 51056], "temperature": 0.0, "avg_logprob": -0.22536933898925782, "compression_ratio": 1.6392156862745098, "no_speech_prob": 0.0003245178086217493}, {"id": 528, "seek": 308264, "start": 3097.04, "end": 3104.8799999999997, "text": " With Salomon's prediction part, we have extremely strong finite time, finite data results. So you", "tokens": [51084, 2022, 5996, 24488, 311, 17630, 644, 11, 321, 362, 4664, 2068, 19362, 565, 11, 19362, 1412, 3542, 13, 407, 291, 51476], "temperature": 0.0, "avg_logprob": -0.22536933898925782, "compression_ratio": 1.6392156862745098, "no_speech_prob": 0.0003245178086217493}, {"id": 529, "seek": 308264, "start": 3104.8799999999997, "end": 3109.2, "text": " have so and so much data, then you lose so and so much. So the deterioration is really great.", "tokens": [51476, 362, 370, 293, 370, 709, 1412, 11, 550, 291, 3624, 370, 293, 370, 709, 13, 407, 264, 26431, 399, 307, 534, 869, 13, 51692], "temperature": 0.0, "avg_logprob": -0.22536933898925782, "compression_ratio": 1.6392156862745098, "no_speech_prob": 0.0003245178086217493}, {"id": 530, "seek": 310920, "start": 3109.2799999999997, "end": 3115.9199999999996, "text": " With the IKC model with the planning part, many results are only asymptotic, which, well, this is", "tokens": [50368, 2022, 264, 286, 42, 34, 2316, 365, 264, 5038, 644, 11, 867, 3542, 366, 787, 35114, 9411, 11, 597, 11, 731, 11, 341, 307, 50700], "temperature": 0.0, "avg_logprob": -0.170026733761742, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.0015723170945420861}, {"id": 531, "seek": 310920, "start": 3116.72, "end": 3121.68, "text": " what is asymptotic means you can prove, for instance, that in the long run, if the agent,", "tokens": [50740, 437, 307, 35114, 9411, 1355, 291, 393, 7081, 11, 337, 5197, 11, 300, 294, 264, 938, 1190, 11, 498, 264, 9461, 11, 50988], "temperature": 0.0, "avg_logprob": -0.170026733761742, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.0015723170945420861}, {"id": 532, "seek": 310920, "start": 3121.68, "end": 3126.3199999999997, "text": " you know, acts long enough, then, you know, it performs optimal or some nice thing happens.", "tokens": [50988, 291, 458, 11, 10672, 938, 1547, 11, 550, 11, 291, 458, 11, 309, 26213, 16252, 420, 512, 1481, 551, 2314, 13, 51220], "temperature": 0.0, "avg_logprob": -0.170026733761742, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.0015723170945420861}, {"id": 533, "seek": 310920, "start": 3126.3199999999997, "end": 3131.2, "text": " So but you don't know how fast it converges. Yeah, so it may converge fast, but we're just", "tokens": [51220, 407, 457, 291, 500, 380, 458, 577, 2370, 309, 9652, 2880, 13, 865, 11, 370, 309, 815, 41881, 2370, 11, 457, 321, 434, 445, 51464], "temperature": 0.0, "avg_logprob": -0.170026733761742, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.0015723170945420861}, {"id": 534, "seek": 310920, "start": 3131.2, "end": 3137.2, "text": " not able to prove it because a difficult problem. Or maybe there's a bug in the in the in the model", "tokens": [51464, 406, 1075, 281, 7081, 309, 570, 257, 2252, 1154, 13, 1610, 1310, 456, 311, 257, 7426, 294, 264, 294, 264, 294, 264, 2316, 51764], "temperature": 0.0, "avg_logprob": -0.170026733761742, "compression_ratio": 1.6967509025270757, "no_speech_prob": 0.0015723170945420861}, {"id": 535, "seek": 313720, "start": 3137.2, "end": 3142.72, "text": " so that it's really that slow. Yeah. So so that is what asymptotic means sort of eventually,", "tokens": [50364, 370, 300, 309, 311, 534, 300, 2964, 13, 865, 13, 407, 370, 300, 307, 437, 35114, 9411, 1355, 1333, 295, 4728, 11, 50640], "temperature": 0.0, "avg_logprob": -0.12547759639406666, "compression_ratio": 1.6916299559471366, "no_speech_prob": 0.002049253089353442}, {"id": 536, "seek": 313720, "start": 3142.72, "end": 3150.7999999999997, "text": " but we don't know how fast. And if I give the agent a fixed horizon M, yeah, then I cannot prove", "tokens": [50640, 457, 321, 500, 380, 458, 577, 2370, 13, 400, 498, 286, 976, 264, 9461, 257, 6806, 18046, 376, 11, 1338, 11, 550, 286, 2644, 7081, 51044], "temperature": 0.0, "avg_logprob": -0.12547759639406666, "compression_ratio": 1.6916299559471366, "no_speech_prob": 0.002049253089353442}, {"id": 537, "seek": 313720, "start": 3150.7999999999997, "end": 3156.24, "text": " asymptotic results, right? So I mean, sort of if it dies in 100 years, then in 100 years is over,", "tokens": [51044, 35114, 9411, 3542, 11, 558, 30, 407, 286, 914, 11, 1333, 295, 498, 309, 2714, 294, 2319, 924, 11, 550, 294, 2319, 924, 307, 670, 11, 51316], "temperature": 0.0, "avg_logprob": -0.12547759639406666, "compression_ratio": 1.6916299559471366, "no_speech_prob": 0.002049253089353442}, {"id": 538, "seek": 313720, "start": 3156.24, "end": 3161.7599999999998, "text": " I cannot say eventually. So this is the advantage of the discounting that I can prove asymptotic", "tokens": [51316, 286, 2644, 584, 4728, 13, 407, 341, 307, 264, 5002, 295, 264, 11635, 278, 300, 286, 393, 7081, 35114, 9411, 51592], "temperature": 0.0, "avg_logprob": -0.12547759639406666, "compression_ratio": 1.6916299559471366, "no_speech_prob": 0.002049253089353442}, {"id": 539, "seek": 316176, "start": 3161.76, "end": 3171.0400000000004, "text": " results. So just to clarify, so so I okay, I made I've built up a model with now in the moment of", "tokens": [50364, 3542, 13, 407, 445, 281, 17594, 11, 370, 370, 286, 1392, 11, 286, 1027, 286, 600, 3094, 493, 257, 2316, 365, 586, 294, 264, 1623, 295, 50828], "temperature": 0.0, "avg_logprob": -0.20243913650512696, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.001781779807060957}, {"id": 540, "seek": 316176, "start": 3171.92, "end": 3177.5200000000004, "text": " have this way of looking several steps ahead. How do I pick what action I will take?", "tokens": [50872, 362, 341, 636, 295, 1237, 2940, 4439, 2286, 13, 1012, 360, 286, 1888, 437, 3069, 286, 486, 747, 30, 51152], "temperature": 0.0, "avg_logprob": -0.20243913650512696, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.001781779807060957}, {"id": 541, "seek": 316176, "start": 3178.8, "end": 3183.84, "text": " It's like with a playing chess, right, you do this mini max. In this case, here do you expect the", "tokens": [51216, 467, 311, 411, 365, 257, 2433, 24122, 11, 558, 11, 291, 360, 341, 8382, 11469, 13, 682, 341, 1389, 11, 510, 360, 291, 2066, 264, 51468], "temperature": 0.0, "avg_logprob": -0.20243913650512696, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.001781779807060957}, {"id": 542, "seek": 316176, "start": 3183.84, "end": 3191.44, "text": " max based on the solometer of distribution, you propagate back. And then, while an action falls", "tokens": [51468, 11469, 2361, 322, 264, 1404, 13606, 295, 7316, 11, 291, 48256, 646, 13, 400, 550, 11, 1339, 364, 3069, 8804, 51848], "temperature": 0.0, "avg_logprob": -0.20243913650512696, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.001781779807060957}, {"id": 543, "seek": 319144, "start": 3191.44, "end": 3196.7200000000003, "text": " out, the action which maximizes the future expected reward on the solometer of distribution,", "tokens": [50364, 484, 11, 264, 3069, 597, 5138, 5660, 264, 2027, 5176, 7782, 322, 264, 1404, 13606, 295, 7316, 11, 50628], "temperature": 0.0, "avg_logprob": -0.16185775169959435, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.002433422254398465}, {"id": 544, "seek": 319144, "start": 3196.7200000000003, "end": 3200.88, "text": " and then you just take this action, and then repeat. And then you get a new observation,", "tokens": [50628, 293, 550, 291, 445, 747, 341, 3069, 11, 293, 550, 7149, 13, 400, 550, 291, 483, 257, 777, 14816, 11, 50836], "temperature": 0.0, "avg_logprob": -0.16185775169959435, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.002433422254398465}, {"id": 545, "seek": 319144, "start": 3200.88, "end": 3205.76, "text": " and you feed it in this action observation, then you repeat and the reward so on. Yeah. So you wrote", "tokens": [50836, 293, 291, 3154, 309, 294, 341, 3069, 14816, 11, 550, 291, 7149, 293, 264, 7782, 370, 322, 13, 865, 13, 407, 291, 4114, 51080], "temperature": 0.0, "avg_logprob": -0.16185775169959435, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.002433422254398465}, {"id": 546, "seek": 319144, "start": 3205.76, "end": 3211.52, "text": " to you. And then maybe you can even predict your own action. I love the idea. But okay, this big", "tokens": [51080, 281, 291, 13, 400, 550, 1310, 291, 393, 754, 6069, 428, 1065, 3069, 13, 286, 959, 264, 1558, 13, 583, 1392, 11, 341, 955, 51368], "temperature": 0.0, "avg_logprob": -0.16185775169959435, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.002433422254398465}, {"id": 547, "seek": 319144, "start": 3211.52, "end": 3219.84, "text": " framework. What is it? I mean, it's kind of a beautiful mathematical framework to think about", "tokens": [51368, 8388, 13, 708, 307, 309, 30, 286, 914, 11, 309, 311, 733, 295, 257, 2238, 18894, 8388, 281, 519, 466, 51784], "temperature": 0.0, "avg_logprob": -0.16185775169959435, "compression_ratio": 1.7849056603773585, "no_speech_prob": 0.002433422254398465}, {"id": 548, "seek": 321984, "start": 3219.84, "end": 3226.1600000000003, "text": " artificial general intelligence. What can you, what does it help you into it about", "tokens": [50364, 11677, 2674, 7599, 13, 708, 393, 291, 11, 437, 775, 309, 854, 291, 666, 309, 466, 50680], "temperature": 0.0, "avg_logprob": -0.17651008878435406, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.0012444161111488938}, {"id": 549, "seek": 321984, "start": 3227.6000000000004, "end": 3235.28, "text": " how to build such systems or maybe from another perspective? What does it help us in understanding", "tokens": [50752, 577, 281, 1322, 1270, 3652, 420, 1310, 490, 1071, 4585, 30, 708, 775, 309, 854, 505, 294, 3701, 51136], "temperature": 0.0, "avg_logprob": -0.17651008878435406, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.0012444161111488938}, {"id": 550, "seek": 321984, "start": 3235.28, "end": 3243.28, "text": " AGI? So when I started in the field, I was always interested in two things. One was, you know, AGI.", "tokens": [51136, 316, 26252, 30, 407, 562, 286, 1409, 294, 264, 2519, 11, 286, 390, 1009, 3102, 294, 732, 721, 13, 1485, 390, 11, 291, 458, 11, 316, 26252, 13, 51536], "temperature": 0.0, "avg_logprob": -0.17651008878435406, "compression_ratio": 1.4712041884816753, "no_speech_prob": 0.0012444161111488938}, {"id": 551, "seek": 324328, "start": 3244.2400000000002, "end": 3250.8, "text": " The name didn't exist then, what called general AI or strong AI. And the physics of everything.", "tokens": [50412, 440, 1315, 994, 380, 2514, 550, 11, 437, 1219, 2674, 7318, 420, 2068, 7318, 13, 400, 264, 10649, 295, 1203, 13, 50740], "temperature": 0.0, "avg_logprob": -0.22863673115824604, "compression_ratio": 1.6125, "no_speech_prob": 0.04464973509311676}, {"id": 552, "seek": 324328, "start": 3250.8, "end": 3254.6400000000003, "text": " So I switched back and forth between computer science and physics quite often.", "tokens": [50740, 407, 286, 16858, 646, 293, 5220, 1296, 3820, 3497, 293, 10649, 1596, 2049, 13, 50932], "temperature": 0.0, "avg_logprob": -0.22863673115824604, "compression_ratio": 1.6125, "no_speech_prob": 0.04464973509311676}, {"id": 553, "seek": 324328, "start": 3254.6400000000003, "end": 3256.5600000000004, "text": " You said the theory of everything. The theory of everything.", "tokens": [50932, 509, 848, 264, 5261, 295, 1203, 13, 440, 5261, 295, 1203, 13, 51028], "temperature": 0.0, "avg_logprob": -0.22863673115824604, "compression_ratio": 1.6125, "no_speech_prob": 0.04464973509311676}, {"id": 554, "seek": 324328, "start": 3257.36, "end": 3261.1200000000003, "text": " It was basically the biggest problems before all humanity.", "tokens": [51068, 467, 390, 1936, 264, 3880, 2740, 949, 439, 10243, 13, 51256], "temperature": 0.0, "avg_logprob": -0.22863673115824604, "compression_ratio": 1.6125, "no_speech_prob": 0.04464973509311676}, {"id": 555, "seek": 324328, "start": 3263.36, "end": 3269.52, "text": " Yeah, I can explain if you wanted some later time, you know, why I'm interested in these two", "tokens": [51368, 865, 11, 286, 393, 2903, 498, 291, 1415, 512, 1780, 565, 11, 291, 458, 11, 983, 286, 478, 3102, 294, 613, 732, 51676], "temperature": 0.0, "avg_logprob": -0.22863673115824604, "compression_ratio": 1.6125, "no_speech_prob": 0.04464973509311676}, {"id": 556, "seek": 326952, "start": 3269.52, "end": 3277.04, "text": " questions. Can I ask you, in a small tangent, if, if, if one to be, it was one to be solved,", "tokens": [50364, 1651, 13, 1664, 286, 1029, 291, 11, 294, 257, 1359, 27747, 11, 498, 11, 498, 11, 498, 472, 281, 312, 11, 309, 390, 472, 281, 312, 13041, 11, 50740], "temperature": 0.0, "avg_logprob": -0.138451103852174, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.011861646547913551}, {"id": 557, "seek": 326952, "start": 3277.04, "end": 3282.72, "text": " which one would you, if one, if you were, if an apple fell in your head, and there was a brilliant", "tokens": [50740, 597, 472, 576, 291, 11, 498, 472, 11, 498, 291, 645, 11, 498, 364, 10606, 5696, 294, 428, 1378, 11, 293, 456, 390, 257, 10248, 51024], "temperature": 0.0, "avg_logprob": -0.138451103852174, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.011861646547913551}, {"id": 558, "seek": 326952, "start": 3282.72, "end": 3288.48, "text": " insight and you could arrive at the solution to one, would it be AGI or the theory of everything?", "tokens": [51024, 11269, 293, 291, 727, 8881, 412, 264, 3827, 281, 472, 11, 576, 309, 312, 316, 26252, 420, 264, 5261, 295, 1203, 30, 51312], "temperature": 0.0, "avg_logprob": -0.138451103852174, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.011861646547913551}, {"id": 559, "seek": 326952, "start": 3289.12, "end": 3293.12, "text": " Definitely AGI, because once the AGI problem is solved, they can ask the AGI to solve the", "tokens": [51344, 12151, 316, 26252, 11, 570, 1564, 264, 316, 26252, 1154, 307, 13041, 11, 436, 393, 1029, 264, 316, 26252, 281, 5039, 264, 51544], "temperature": 0.0, "avg_logprob": -0.138451103852174, "compression_ratio": 1.6919642857142858, "no_speech_prob": 0.011861646547913551}, {"id": 560, "seek": 329312, "start": 3293.12, "end": 3301.12, "text": " other problem for me. Yeah, brilliantly put. Okay. So, so as you were saying about it.", "tokens": [50364, 661, 1154, 337, 385, 13, 865, 11, 8695, 42580, 829, 13, 1033, 13, 407, 11, 370, 382, 291, 645, 1566, 466, 309, 13, 50764], "temperature": 0.0, "avg_logprob": -0.14332902674772302, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00322059728205204}, {"id": 561, "seek": 329312, "start": 3301.12, "end": 3306.64, "text": " Okay. So, and the reason why it didn't settle, I mean, this thought about, you know,", "tokens": [50764, 1033, 13, 407, 11, 293, 264, 1778, 983, 309, 994, 380, 11852, 11, 286, 914, 11, 341, 1194, 466, 11, 291, 458, 11, 51040], "temperature": 0.0, "avg_logprob": -0.14332902674772302, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00322059728205204}, {"id": 562, "seek": 329312, "start": 3307.2799999999997, "end": 3311.12, "text": " once you have solved AGI, it solves all kinds of other, not just the theory of every problem,", "tokens": [51072, 1564, 291, 362, 13041, 316, 26252, 11, 309, 39890, 439, 3685, 295, 661, 11, 406, 445, 264, 5261, 295, 633, 1154, 11, 51264], "temperature": 0.0, "avg_logprob": -0.14332902674772302, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00322059728205204}, {"id": 563, "seek": 329312, "start": 3311.12, "end": 3316.4, "text": " but all kinds of use, more useful problems to humanity is very appealing to many people. And,", "tokens": [51264, 457, 439, 3685, 295, 764, 11, 544, 4420, 2740, 281, 10243, 307, 588, 23842, 281, 867, 561, 13, 400, 11, 51528], "temperature": 0.0, "avg_logprob": -0.14332902674772302, "compression_ratio": 1.5814977973568283, "no_speech_prob": 0.00322059728205204}, {"id": 564, "seek": 331640, "start": 3316.4, "end": 3323.92, "text": " you know, I had this thought also, but I was quite disappointed with the state of the art", "tokens": [50364, 291, 458, 11, 286, 632, 341, 1194, 611, 11, 457, 286, 390, 1596, 13856, 365, 264, 1785, 295, 264, 1523, 50740], "temperature": 0.0, "avg_logprob": -0.1299482166257679, "compression_ratio": 1.7191011235955056, "no_speech_prob": 0.002843748079612851}, {"id": 565, "seek": 331640, "start": 3323.92, "end": 3328.8, "text": " of the field of AI. There was some theory, you know, about logical reasoning, but I was never", "tokens": [50740, 295, 264, 2519, 295, 7318, 13, 821, 390, 512, 5261, 11, 291, 458, 11, 466, 14978, 21577, 11, 457, 286, 390, 1128, 50984], "temperature": 0.0, "avg_logprob": -0.1299482166257679, "compression_ratio": 1.7191011235955056, "no_speech_prob": 0.002843748079612851}, {"id": 566, "seek": 331640, "start": 3328.8, "end": 3333.6800000000003, "text": " convinced that this will fly. And then there was this more, more heuristic approaches with neural", "tokens": [50984, 12561, 300, 341, 486, 3603, 13, 400, 550, 456, 390, 341, 544, 11, 544, 415, 374, 3142, 11587, 365, 18161, 51228], "temperature": 0.0, "avg_logprob": -0.1299482166257679, "compression_ratio": 1.7191011235955056, "no_speech_prob": 0.002843748079612851}, {"id": 567, "seek": 331640, "start": 3333.6800000000003, "end": 3340.08, "text": " networks, and I didn't like these heuristics. So, and also I didn't have any good idea myself.", "tokens": [51228, 9590, 11, 293, 286, 994, 380, 411, 613, 415, 374, 6006, 13, 407, 11, 293, 611, 286, 994, 380, 362, 604, 665, 1558, 2059, 13, 51548], "temperature": 0.0, "avg_logprob": -0.1299482166257679, "compression_ratio": 1.7191011235955056, "no_speech_prob": 0.002843748079612851}, {"id": 568, "seek": 331640, "start": 3342.1600000000003, "end": 3345.36, "text": " So that's the reason why I toggled back and forth quite some while and even worked", "tokens": [51652, 407, 300, 311, 264, 1778, 983, 286, 26911, 1493, 646, 293, 5220, 1596, 512, 1339, 293, 754, 2732, 51812], "temperature": 0.0, "avg_logprob": -0.1299482166257679, "compression_ratio": 1.7191011235955056, "no_speech_prob": 0.002843748079612851}, {"id": 569, "seek": 334536, "start": 3345.36, "end": 3349.6, "text": " so four and a half years in a company developing software or something completely unrelated.", "tokens": [50364, 370, 1451, 293, 257, 1922, 924, 294, 257, 2237, 6416, 4722, 420, 746, 2584, 38967, 13, 50576], "temperature": 0.0, "avg_logprob": -0.15763780048915318, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.0004302091838326305}, {"id": 570, "seek": 334536, "start": 3349.6, "end": 3356.96, "text": " But then I had this idea about the ICSE model. And so what it gives you, it gives you a gold", "tokens": [50576, 583, 550, 286, 632, 341, 1558, 466, 264, 14360, 5879, 2316, 13, 400, 370, 437, 309, 2709, 291, 11, 309, 2709, 291, 257, 3821, 50944], "temperature": 0.0, "avg_logprob": -0.15763780048915318, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.0004302091838326305}, {"id": 571, "seek": 334536, "start": 3356.96, "end": 3363.76, "text": " standard. So I have proven that this is the most intelligent agents, which anybody could", "tokens": [50944, 3832, 13, 407, 286, 362, 12785, 300, 341, 307, 264, 881, 13232, 12554, 11, 597, 4472, 727, 51284], "temperature": 0.0, "avg_logprob": -0.15763780048915318, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.0004302091838326305}, {"id": 572, "seek": 334536, "start": 3364.96, "end": 3370.56, "text": " build built in quotation mark, because it's just mathematical and you need infinite compute.", "tokens": [51344, 1322, 3094, 294, 47312, 1491, 11, 570, 309, 311, 445, 18894, 293, 291, 643, 13785, 14722, 13, 51624], "temperature": 0.0, "avg_logprob": -0.15763780048915318, "compression_ratio": 1.5485232067510548, "no_speech_prob": 0.0004302091838326305}, {"id": 573, "seek": 337056, "start": 3371.04, "end": 3377.04, "text": " But this is the limit. And this is completely specified. It's not just a framework and, you know,", "tokens": [50388, 583, 341, 307, 264, 4948, 13, 400, 341, 307, 2584, 22206, 13, 467, 311, 406, 445, 257, 8388, 293, 11, 291, 458, 11, 50688], "temperature": 0.0, "avg_logprob": -0.14633640536555537, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0007911944994702935}, {"id": 574, "seek": 337056, "start": 3378.4, "end": 3383.44, "text": " every year, tens of frameworks are developed, which is just skeletons, and then pieces are", "tokens": [50756, 633, 1064, 11, 10688, 295, 29834, 366, 4743, 11, 597, 307, 445, 45538, 11, 293, 550, 3755, 366, 51008], "temperature": 0.0, "avg_logprob": -0.14633640536555537, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0007911944994702935}, {"id": 575, "seek": 337056, "start": 3383.44, "end": 3387.2799999999997, "text": " missing. And usually these missing pieces, you know, turn out to be really, really difficult.", "tokens": [51008, 5361, 13, 400, 2673, 613, 5361, 3755, 11, 291, 458, 11, 1261, 484, 281, 312, 534, 11, 534, 2252, 13, 51200], "temperature": 0.0, "avg_logprob": -0.14633640536555537, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0007911944994702935}, {"id": 576, "seek": 337056, "start": 3387.2799999999997, "end": 3393.68, "text": " And so this is completely and uniquely defined. And we can analyze that mathematically. And", "tokens": [51200, 400, 370, 341, 307, 2584, 293, 31474, 7642, 13, 400, 321, 393, 12477, 300, 44003, 13, 400, 51520], "temperature": 0.0, "avg_logprob": -0.14633640536555537, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0007911944994702935}, {"id": 577, "seek": 337056, "start": 3395.12, "end": 3399.44, "text": " we've also developed some approximations, I can talk about that a little bit later,", "tokens": [51592, 321, 600, 611, 4743, 512, 8542, 763, 11, 286, 393, 751, 466, 300, 257, 707, 857, 1780, 11, 51808], "temperature": 0.0, "avg_logprob": -0.14633640536555537, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0007911944994702935}, {"id": 578, "seek": 339944, "start": 3400.16, "end": 3404.16, "text": " that would be sort of the top down approach, like, say, for Neumann's minimax theory,", "tokens": [50400, 300, 576, 312, 1333, 295, 264, 1192, 760, 3109, 11, 411, 11, 584, 11, 337, 1734, 449, 969, 311, 4464, 2797, 5261, 11, 50600], "temperature": 0.0, "avg_logprob": -0.13477365112304687, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.004533634055405855}, {"id": 579, "seek": 339944, "start": 3404.16, "end": 3409.52, "text": " that's the theoretical optimal play of games. And now we need to approximate it, put heuristics", "tokens": [50600, 300, 311, 264, 20864, 16252, 862, 295, 2813, 13, 400, 586, 321, 643, 281, 30874, 309, 11, 829, 415, 374, 6006, 50868], "temperature": 0.0, "avg_logprob": -0.13477365112304687, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.004533634055405855}, {"id": 580, "seek": 339944, "start": 3409.52, "end": 3413.04, "text": " in prune, the tree, blah, blah, blah, and so on. So we can do that also with the ICSE model,", "tokens": [50868, 294, 582, 2613, 11, 264, 4230, 11, 12288, 11, 12288, 11, 12288, 11, 293, 370, 322, 13, 407, 321, 393, 360, 300, 611, 365, 264, 14360, 5879, 2316, 11, 51044], "temperature": 0.0, "avg_logprob": -0.13477365112304687, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.004533634055405855}, {"id": 581, "seek": 339944, "start": 3413.04, "end": 3420.7200000000003, "text": " but for generally I, it can also inspire those. And most of most researchers go bottom upright,", "tokens": [51044, 457, 337, 5101, 286, 11, 309, 393, 611, 15638, 729, 13, 400, 881, 295, 881, 10309, 352, 2767, 27405, 11, 51428], "temperature": 0.0, "avg_logprob": -0.13477365112304687, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.004533634055405855}, {"id": 582, "seek": 339944, "start": 3420.7200000000003, "end": 3425.84, "text": " they have the systems that try to make it more general, more intelligent. It can inspire in which", "tokens": [51428, 436, 362, 264, 3652, 300, 853, 281, 652, 309, 544, 2674, 11, 544, 13232, 13, 467, 393, 15638, 294, 597, 51684], "temperature": 0.0, "avg_logprob": -0.13477365112304687, "compression_ratio": 1.6654804270462633, "no_speech_prob": 0.004533634055405855}, {"id": 583, "seek": 342584, "start": 3425.84, "end": 3431.84, "text": " direction to go. What do you mean by that? So if you have some choice to make, right, so how should", "tokens": [50364, 3513, 281, 352, 13, 708, 360, 291, 914, 538, 300, 30, 407, 498, 291, 362, 512, 3922, 281, 652, 11, 558, 11, 370, 577, 820, 50664], "temperature": 0.0, "avg_logprob": -0.10013075480385432, "compression_ratio": 1.6220735785953178, "no_speech_prob": 0.0058152442798018456}, {"id": 584, "seek": 342584, "start": 3431.84, "end": 3438.1600000000003, "text": " they evaluate my system if I can't do cross validation? How should they do my learning if", "tokens": [50664, 436, 13059, 452, 1185, 498, 286, 393, 380, 360, 3278, 24071, 30, 1012, 820, 436, 360, 452, 2539, 498, 50980], "temperature": 0.0, "avg_logprob": -0.10013075480385432, "compression_ratio": 1.6220735785953178, "no_speech_prob": 0.0058152442798018456}, {"id": 585, "seek": 342584, "start": 3438.1600000000003, "end": 3443.1200000000003, "text": " my standard regularization doesn't work well? Yeah. So the answer is always this, we have a system", "tokens": [50980, 452, 3832, 3890, 2144, 1177, 380, 589, 731, 30, 865, 13, 407, 264, 1867, 307, 1009, 341, 11, 321, 362, 257, 1185, 51228], "temperature": 0.0, "avg_logprob": -0.10013075480385432, "compression_ratio": 1.6220735785953178, "no_speech_prob": 0.0058152442798018456}, {"id": 586, "seek": 342584, "start": 3443.1200000000003, "end": 3448.48, "text": " which does everything that's ICSE. It's just, you know, completely in the ivory tower, completely", "tokens": [51228, 597, 775, 1203, 300, 311, 14360, 5879, 13, 467, 311, 445, 11, 291, 458, 11, 2584, 294, 264, 49218, 10567, 11, 2584, 51496], "temperature": 0.0, "avg_logprob": -0.10013075480385432, "compression_ratio": 1.6220735785953178, "no_speech_prob": 0.0058152442798018456}, {"id": 587, "seek": 342584, "start": 3448.48, "end": 3453.52, "text": " useless from a practical point of view. But you can look at it and see, ah, yeah, maybe, you know,", "tokens": [51496, 14115, 490, 257, 8496, 935, 295, 1910, 13, 583, 291, 393, 574, 412, 309, 293, 536, 11, 3716, 11, 1338, 11, 1310, 11, 291, 458, 11, 51748], "temperature": 0.0, "avg_logprob": -0.10013075480385432, "compression_ratio": 1.6220735785953178, "no_speech_prob": 0.0058152442798018456}, {"id": 588, "seek": 345352, "start": 3453.52, "end": 3457.52, "text": " I can take some aspects and, you know, instead of Kolmogorov complexity, they just take some", "tokens": [50364, 286, 393, 747, 512, 7270, 293, 11, 291, 458, 11, 2602, 295, 26137, 76, 664, 284, 5179, 14024, 11, 436, 445, 747, 512, 50564], "temperature": 0.0, "avg_logprob": -0.1370848316257283, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0041306717321276665}, {"id": 589, "seek": 345352, "start": 3457.52, "end": 3463.04, "text": " compressors which has been developed so far. And for the planning, well, we have UCT which has also,", "tokens": [50564, 14778, 830, 597, 575, 668, 4743, 370, 1400, 13, 400, 337, 264, 5038, 11, 731, 11, 321, 362, 624, 10259, 597, 575, 611, 11, 50840], "temperature": 0.0, "avg_logprob": -0.1370848316257283, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0041306717321276665}, {"id": 590, "seek": 345352, "start": 3463.04, "end": 3471.6, "text": " you know, been used in Go. And it, at least it's inspired me a lot to have this formal", "tokens": [50840, 291, 458, 11, 668, 1143, 294, 1037, 13, 400, 309, 11, 412, 1935, 309, 311, 7547, 385, 257, 688, 281, 362, 341, 9860, 51268], "temperature": 0.0, "avg_logprob": -0.1370848316257283, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0041306717321276665}, {"id": 591, "seek": 345352, "start": 3473.28, "end": 3477.68, "text": " definition. And if you look at other fields, you know, like, I always come back to physics", "tokens": [51352, 7123, 13, 400, 498, 291, 574, 412, 661, 7909, 11, 291, 458, 11, 411, 11, 286, 1009, 808, 646, 281, 10649, 51572], "temperature": 0.0, "avg_logprob": -0.1370848316257283, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0041306717321276665}, {"id": 592, "seek": 345352, "start": 3477.68, "end": 3481.44, "text": " because I have a physics background, think about the phenomenon of energy that was", "tokens": [51572, 570, 286, 362, 257, 10649, 3678, 11, 519, 466, 264, 14029, 295, 2281, 300, 390, 51760], "temperature": 0.0, "avg_logprob": -0.1370848316257283, "compression_ratio": 1.6752767527675276, "no_speech_prob": 0.0041306717321276665}, {"id": 593, "seek": 348144, "start": 3481.44, "end": 3485.12, "text": " long time a mysterious concept. And at some point, it was completely formalized.", "tokens": [50364, 938, 565, 257, 13831, 3410, 13, 400, 412, 512, 935, 11, 309, 390, 2584, 9860, 1602, 13, 50548], "temperature": 0.0, "avg_logprob": -0.1293242713001287, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0016224533319473267}, {"id": 594, "seek": 348144, "start": 3486.16, "end": 3491.28, "text": " And that really helped a lot. And you can point out a lot of these things which were", "tokens": [50600, 400, 300, 534, 4254, 257, 688, 13, 400, 291, 393, 935, 484, 257, 688, 295, 613, 721, 597, 645, 50856], "temperature": 0.0, "avg_logprob": -0.1293242713001287, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0016224533319473267}, {"id": 595, "seek": 348144, "start": 3491.28, "end": 3495.28, "text": " first mysterious and vague, and then they have been rigorously formalized.", "tokens": [50856, 700, 13831, 293, 24247, 11, 293, 550, 436, 362, 668, 42191, 5098, 9860, 1602, 13, 51056], "temperature": 0.0, "avg_logprob": -0.1293242713001287, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0016224533319473267}, {"id": 596, "seek": 348144, "start": 3495.28, "end": 3500.4, "text": " Speed and acceleration has been confused, right, until it was formally defined. There was a time", "tokens": [51056, 18774, 293, 17162, 575, 668, 9019, 11, 558, 11, 1826, 309, 390, 25983, 7642, 13, 821, 390, 257, 565, 51312], "temperature": 0.0, "avg_logprob": -0.1293242713001287, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0016224533319473267}, {"id": 597, "seek": 348144, "start": 3500.4, "end": 3505.84, "text": " like this. And people, you know, often, you know, don't have any background, you know, still confuse", "tokens": [51312, 411, 341, 13, 400, 561, 11, 291, 458, 11, 2049, 11, 291, 458, 11, 500, 380, 362, 604, 3678, 11, 291, 458, 11, 920, 28584, 51584], "temperature": 0.0, "avg_logprob": -0.1293242713001287, "compression_ratio": 1.7804878048780488, "no_speech_prob": 0.0016224533319473267}, {"id": 598, "seek": 350584, "start": 3505.84, "end": 3513.1200000000003, "text": " it. So, and this IXI model or the intelligence definitions, which is sort of the dual to it,", "tokens": [50364, 309, 13, 407, 11, 293, 341, 286, 55, 40, 2316, 420, 264, 7599, 21988, 11, 597, 307, 1333, 295, 264, 11848, 281, 309, 11, 50728], "temperature": 0.0, "avg_logprob": -0.1683579773462119, "compression_ratio": 1.671875, "no_speech_prob": 0.0036476196255534887}, {"id": 599, "seek": 350584, "start": 3513.1200000000003, "end": 3518.32, "text": " we come back to that later, formalizes the notion of intelligence uniquely and rigorously.", "tokens": [50728, 321, 808, 646, 281, 300, 1780, 11, 9860, 5660, 264, 10710, 295, 7599, 31474, 293, 42191, 5098, 13, 50988], "temperature": 0.0, "avg_logprob": -0.1683579773462119, "compression_ratio": 1.671875, "no_speech_prob": 0.0036476196255534887}, {"id": 600, "seek": 350584, "start": 3518.88, "end": 3522.48, "text": " So in a sense, it serves as kind of the light at the end of the tunnel.", "tokens": [51016, 407, 294, 257, 2020, 11, 309, 13451, 382, 733, 295, 264, 1442, 412, 264, 917, 295, 264, 13186, 13, 51196], "temperature": 0.0, "avg_logprob": -0.1683579773462119, "compression_ratio": 1.671875, "no_speech_prob": 0.0036476196255534887}, {"id": 601, "seek": 350584, "start": 3523.04, "end": 3528.32, "text": " Yes, yeah. So I mean, there's a million questions I could ask her. So maybe", "tokens": [51224, 1079, 11, 1338, 13, 407, 286, 914, 11, 456, 311, 257, 2459, 1651, 286, 727, 1029, 720, 13, 407, 1310, 51488], "temperature": 0.0, "avg_logprob": -0.1683579773462119, "compression_ratio": 1.671875, "no_speech_prob": 0.0036476196255534887}, {"id": 602, "seek": 350584, "start": 3529.44, "end": 3534.6400000000003, "text": " the kind of, okay, let's feel around in the dark a little bit. So there's been here a deep mind,", "tokens": [51544, 264, 733, 295, 11, 1392, 11, 718, 311, 841, 926, 294, 264, 2877, 257, 707, 857, 13, 407, 456, 311, 668, 510, 257, 2452, 1575, 11, 51804], "temperature": 0.0, "avg_logprob": -0.1683579773462119, "compression_ratio": 1.671875, "no_speech_prob": 0.0036476196255534887}, {"id": 603, "seek": 353464, "start": 3534.64, "end": 3538.0, "text": " but in general, been a lot of breakthrough ideas, just like we've been saying around", "tokens": [50364, 457, 294, 2674, 11, 668, 257, 688, 295, 22397, 3487, 11, 445, 411, 321, 600, 668, 1566, 926, 50532], "temperature": 0.0, "avg_logprob": -0.1409702592966508, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.001169039634987712}, {"id": 604, "seek": 353464, "start": 3538.0, "end": 3543.6, "text": " reinforcement learning. So how do you see the progress in reinforcement learning is different?", "tokens": [50532, 29280, 2539, 13, 407, 577, 360, 291, 536, 264, 4205, 294, 29280, 2539, 307, 819, 30, 50812], "temperature": 0.0, "avg_logprob": -0.1409702592966508, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.001169039634987712}, {"id": 605, "seek": 353464, "start": 3544.3199999999997, "end": 3551.12, "text": " Like, which subset of IXI does it occupy the current, like you said, maybe", "tokens": [50848, 1743, 11, 597, 25993, 295, 286, 55, 40, 775, 309, 30645, 264, 2190, 11, 411, 291, 848, 11, 1310, 51188], "temperature": 0.0, "avg_logprob": -0.1409702592966508, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.001169039634987712}, {"id": 606, "seek": 353464, "start": 3551.92, "end": 3555.6, "text": " the Markov assumption is made quite often in reinforcement learning.", "tokens": [51228, 264, 3934, 5179, 15302, 307, 1027, 1596, 2049, 294, 29280, 2539, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1409702592966508, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.001169039634987712}, {"id": 607, "seek": 353464, "start": 3556.4, "end": 3562.96, "text": " The, there's other assumptions made in order to make the system work. What do you see as the", "tokens": [51452, 440, 11, 456, 311, 661, 17695, 1027, 294, 1668, 281, 652, 264, 1185, 589, 13, 708, 360, 291, 536, 382, 264, 51780], "temperature": 0.0, "avg_logprob": -0.1409702592966508, "compression_ratio": 1.7119341563786008, "no_speech_prob": 0.001169039634987712}, {"id": 608, "seek": 356296, "start": 3562.96, "end": 3565.76, "text": " difference connection between reinforcement learning and IXI?", "tokens": [50364, 2649, 4984, 1296, 29280, 2539, 293, 286, 55, 40, 30, 50504], "temperature": 0.0, "avg_logprob": -0.12154941099235811, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0003682388924062252}, {"id": 609, "seek": 356296, "start": 3566.64, "end": 3572.48, "text": " And so the major difference is that essentially all other approaches,", "tokens": [50548, 400, 370, 264, 2563, 2649, 307, 300, 4476, 439, 661, 11587, 11, 50840], "temperature": 0.0, "avg_logprob": -0.12154941099235811, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0003682388924062252}, {"id": 610, "seek": 356296, "start": 3573.36, "end": 3577.6, "text": " they make stronger assumptions. So in reinforcement learning, the Markov assumption", "tokens": [50884, 436, 652, 7249, 17695, 13, 407, 294, 29280, 2539, 11, 264, 3934, 5179, 15302, 51096], "temperature": 0.0, "avg_logprob": -0.12154941099235811, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0003682388924062252}, {"id": 611, "seek": 356296, "start": 3578.2400000000002, "end": 3583.28, "text": " is that the next state or next observation only depends on the on the previous observation", "tokens": [51128, 307, 300, 264, 958, 1785, 420, 958, 14816, 787, 5946, 322, 264, 322, 264, 3894, 14816, 51380], "temperature": 0.0, "avg_logprob": -0.12154941099235811, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0003682388924062252}, {"id": 612, "seek": 356296, "start": 3583.28, "end": 3588.0, "text": " and not the whole history, which makes, of course, the mathematics much easier rather than dealing", "tokens": [51380, 293, 406, 264, 1379, 2503, 11, 597, 1669, 11, 295, 1164, 11, 264, 18666, 709, 3571, 2831, 813, 6260, 51616], "temperature": 0.0, "avg_logprob": -0.12154941099235811, "compression_ratio": 1.7307692307692308, "no_speech_prob": 0.0003682388924062252}, {"id": 613, "seek": 358800, "start": 3588.0, "end": 3593.36, "text": " with histories. Of course, they profit from it also, because then you have algorithms that run", "tokens": [50364, 365, 30631, 13, 2720, 1164, 11, 436, 7475, 490, 309, 611, 11, 570, 550, 291, 362, 14642, 300, 1190, 50632], "temperature": 0.0, "avg_logprob": -0.17083256915935036, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.0037054852582514286}, {"id": 614, "seek": 358800, "start": 3593.36, "end": 3599.52, "text": " on current computers and do something practically useful. But for generally, I all the assumptions", "tokens": [50632, 322, 2190, 10807, 293, 360, 746, 15667, 4420, 13, 583, 337, 5101, 11, 286, 439, 264, 17695, 50940], "temperature": 0.0, "avg_logprob": -0.17083256915935036, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.0037054852582514286}, {"id": 615, "seek": 358800, "start": 3599.52, "end": 3607.04, "text": " which are made by other approaches, we know already now they are limiting. So, for instance,", "tokens": [50940, 597, 366, 1027, 538, 661, 11587, 11, 321, 458, 1217, 586, 436, 366, 22083, 13, 407, 11, 337, 5197, 11, 51316], "temperature": 0.0, "avg_logprob": -0.17083256915935036, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.0037054852582514286}, {"id": 616, "seek": 358800, "start": 3607.84, "end": 3611.52, "text": " usually you need a gothicity assumption in the MDP frameworks in order to learn.", "tokens": [51356, 2673, 291, 643, 257, 658, 32582, 507, 15302, 294, 264, 376, 11373, 29834, 294, 1668, 281, 1466, 13, 51540], "temperature": 0.0, "avg_logprob": -0.17083256915935036, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.0037054852582514286}, {"id": 617, "seek": 358800, "start": 3611.52, "end": 3616.08, "text": " A gothicity essentially means that you can recover from your mistakes and that they are", "tokens": [51540, 316, 658, 32582, 507, 4476, 1355, 300, 291, 393, 8114, 490, 428, 8038, 293, 300, 436, 366, 51768], "temperature": 0.0, "avg_logprob": -0.17083256915935036, "compression_ratio": 1.6308243727598566, "no_speech_prob": 0.0037054852582514286}, {"id": 618, "seek": 361608, "start": 3616.08, "end": 3621.68, "text": " not traps in the environment. And if you make this assumption, then essentially you can go back", "tokens": [50364, 406, 24173, 294, 264, 2823, 13, 400, 498, 291, 652, 341, 15302, 11, 550, 4476, 291, 393, 352, 646, 50644], "temperature": 0.0, "avg_logprob": -0.1154141373686738, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.0008687220979481936}, {"id": 619, "seek": 361608, "start": 3621.68, "end": 3628.64, "text": " to a previous state, go there a couple of times and then learn what, what statistics and what", "tokens": [50644, 281, 257, 3894, 1785, 11, 352, 456, 257, 1916, 295, 1413, 293, 550, 1466, 437, 11, 437, 12523, 293, 437, 50992], "temperature": 0.0, "avg_logprob": -0.1154141373686738, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.0008687220979481936}, {"id": 620, "seek": 361608, "start": 3628.64, "end": 3633.84, "text": " this state is like. And then in the long run perform well in this state. But there are no", "tokens": [50992, 341, 1785, 307, 411, 13, 400, 550, 294, 264, 938, 1190, 2042, 731, 294, 341, 1785, 13, 583, 456, 366, 572, 51252], "temperature": 0.0, "avg_logprob": -0.1154141373686738, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.0008687220979481936}, {"id": 621, "seek": 361608, "start": 3633.84, "end": 3640.48, "text": " fundamental problems. But in real life, we know, there can be one single action, one second of", "tokens": [51252, 8088, 2740, 13, 583, 294, 957, 993, 11, 321, 458, 11, 456, 393, 312, 472, 2167, 3069, 11, 472, 1150, 295, 51584], "temperature": 0.0, "avg_logprob": -0.1154141373686738, "compression_ratio": 1.7077625570776256, "no_speech_prob": 0.0008687220979481936}, {"id": 622, "seek": 364048, "start": 3640.48, "end": 3646.88, "text": " being inattentive while driving a car fast, you know, can ruin the rest of my life, I can become", "tokens": [50364, 885, 294, 1591, 317, 488, 1339, 4840, 257, 1032, 2370, 11, 291, 458, 11, 393, 15514, 264, 1472, 295, 452, 993, 11, 286, 393, 1813, 50684], "temperature": 0.0, "avg_logprob": -0.14505813636031806, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.0229225791990757}, {"id": 623, "seek": 364048, "start": 3646.88, "end": 3651.44, "text": " quadruplegic or whatever. So, and there's no recovery anymore. So, the real world is not", "tokens": [50684, 10787, 894, 781, 11577, 420, 2035, 13, 407, 11, 293, 456, 311, 572, 8597, 3602, 13, 407, 11, 264, 957, 1002, 307, 406, 50912], "temperature": 0.0, "avg_logprob": -0.14505813636031806, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.0229225791990757}, {"id": 624, "seek": 364048, "start": 3651.44, "end": 3655.52, "text": " ergodic, I always say, you know, there are traps and there are situations where you're not recovered", "tokens": [50912, 1189, 21787, 299, 11, 286, 1009, 584, 11, 291, 458, 11, 456, 366, 24173, 293, 456, 366, 6851, 689, 291, 434, 406, 19542, 51116], "temperature": 0.0, "avg_logprob": -0.14505813636031806, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.0229225791990757}, {"id": 625, "seek": 364048, "start": 3655.52, "end": 3666.48, "text": " from. And very little theory has been developed for this case. What about what do you see in the", "tokens": [51116, 490, 13, 400, 588, 707, 5261, 575, 668, 4743, 337, 341, 1389, 13, 708, 466, 437, 360, 291, 536, 294, 264, 51664], "temperature": 0.0, "avg_logprob": -0.14505813636031806, "compression_ratio": 1.6160337552742616, "no_speech_prob": 0.0229225791990757}, {"id": 626, "seek": 366648, "start": 3666.56, "end": 3675.2, "text": " context of IHC as the role of exploration, sort of, you mentioned, you know, in the real world", "tokens": [50368, 4319, 295, 286, 39, 34, 382, 264, 3090, 295, 16197, 11, 1333, 295, 11, 291, 2835, 11, 291, 458, 11, 294, 264, 957, 1002, 50800], "temperature": 0.0, "avg_logprob": -0.15632645102108225, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.012405883520841599}, {"id": 627, "seek": 366648, "start": 3675.2, "end": 3680.2400000000002, "text": " and get into trouble when we make the wrong decisions and really pay for it. But exploration", "tokens": [50800, 293, 483, 666, 5253, 562, 321, 652, 264, 2085, 5327, 293, 534, 1689, 337, 309, 13, 583, 16197, 51052], "temperature": 0.0, "avg_logprob": -0.15632645102108225, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.012405883520841599}, {"id": 628, "seek": 366648, "start": 3680.2400000000002, "end": 3684.96, "text": " seems to be fundamentally important for learning about this world, for gaining new knowledge.", "tokens": [51052, 2544, 281, 312, 17879, 1021, 337, 2539, 466, 341, 1002, 11, 337, 19752, 777, 3601, 13, 51288], "temperature": 0.0, "avg_logprob": -0.15632645102108225, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.012405883520841599}, {"id": 629, "seek": 366648, "start": 3685.6, "end": 3691.36, "text": " So, is exploration baked in? Another way to ask it, what are the parameters", "tokens": [51320, 407, 11, 307, 16197, 19453, 294, 30, 3996, 636, 281, 1029, 309, 11, 437, 366, 264, 9834, 51608], "temperature": 0.0, "avg_logprob": -0.15632645102108225, "compression_ratio": 1.63013698630137, "no_speech_prob": 0.012405883520841599}, {"id": 630, "seek": 369136, "start": 3692.2400000000002, "end": 3698.2400000000002, "text": " of this of IHC that can be controlled? Yeah, I say the good thing is that there are no", "tokens": [50408, 295, 341, 295, 286, 39, 34, 300, 393, 312, 10164, 30, 865, 11, 286, 584, 264, 665, 551, 307, 300, 456, 366, 572, 50708], "temperature": 0.0, "avg_logprob": -0.10930662657085218, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008309364318847656}, {"id": 631, "seek": 369136, "start": 3698.2400000000002, "end": 3704.2400000000002, "text": " parameters to control. Some other people try knobs to control and you can do that. I mean,", "tokens": [50708, 9834, 281, 1969, 13, 2188, 661, 561, 853, 46999, 281, 1969, 293, 291, 393, 360, 300, 13, 286, 914, 11, 51008], "temperature": 0.0, "avg_logprob": -0.10930662657085218, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008309364318847656}, {"id": 632, "seek": 369136, "start": 3704.2400000000002, "end": 3711.28, "text": " you can modify IHC so that you have some knobs to play with if you want to. But the exploration", "tokens": [51008, 291, 393, 16927, 286, 39, 34, 370, 300, 291, 362, 512, 46999, 281, 862, 365, 498, 291, 528, 281, 13, 583, 264, 16197, 51360], "temperature": 0.0, "avg_logprob": -0.10930662657085218, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008309364318847656}, {"id": 633, "seek": 369136, "start": 3711.28, "end": 3718.6400000000003, "text": " is directly baked in. And that comes from the Bayesian learning and the long term planning.", "tokens": [51360, 307, 3838, 19453, 294, 13, 400, 300, 1487, 490, 264, 7840, 42434, 2539, 293, 264, 938, 1433, 5038, 13, 51728], "temperature": 0.0, "avg_logprob": -0.10930662657085218, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.008309364318847656}, {"id": 634, "seek": 371864, "start": 3718.64, "end": 3728.56, "text": " So these together already imply exploration. You can nicely and explicitly prove that for", "tokens": [50364, 407, 613, 1214, 1217, 33616, 16197, 13, 509, 393, 9594, 293, 20803, 7081, 300, 337, 50860], "temperature": 0.0, "avg_logprob": -0.1258424533310757, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010984187247231603}, {"id": 635, "seek": 371864, "start": 3729.3599999999997, "end": 3737.92, "text": " simple problems like so-called banded problems, where you say to give a real-world example,", "tokens": [50900, 2199, 2740, 411, 370, 12, 11880, 4116, 292, 2740, 11, 689, 291, 584, 281, 976, 257, 957, 12, 13217, 1365, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1258424533310757, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010984187247231603}, {"id": 636, "seek": 371864, "start": 3737.92, "end": 3742.16, "text": " say you have two medical treatments, A and B, you don't know the effectiveness, you try A a", "tokens": [51328, 584, 291, 362, 732, 4625, 15795, 11, 316, 293, 363, 11, 291, 500, 380, 458, 264, 21208, 11, 291, 853, 316, 257, 51540], "temperature": 0.0, "avg_logprob": -0.1258424533310757, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010984187247231603}, {"id": 637, "seek": 371864, "start": 3742.16, "end": 3746.64, "text": " little bit, B a little bit, but you don't want to harm too many patients. So you have to sort of", "tokens": [51540, 707, 857, 11, 363, 257, 707, 857, 11, 457, 291, 500, 380, 528, 281, 6491, 886, 867, 4209, 13, 407, 291, 362, 281, 1333, 295, 51764], "temperature": 0.0, "avg_logprob": -0.1258424533310757, "compression_ratio": 1.6299559471365639, "no_speech_prob": 0.0010984187247231603}, {"id": 638, "seek": 374664, "start": 3747.6, "end": 3754.24, "text": " trade off exploring. And at some point you want to explore and you can do the mathematics and", "tokens": [50412, 4923, 766, 12736, 13, 400, 412, 512, 935, 291, 528, 281, 6839, 293, 291, 393, 360, 264, 18666, 293, 50744], "temperature": 0.0, "avg_logprob": -0.1750826890441193, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0006068589864298701}, {"id": 639, "seek": 374664, "start": 3754.24, "end": 3760.24, "text": " figure out the optimal strategy. It's called Bayesian agents, they're also non-Bayesian agents.", "tokens": [50744, 2573, 484, 264, 16252, 5206, 13, 467, 311, 1219, 7840, 42434, 12554, 11, 436, 434, 611, 2107, 12, 29853, 42434, 12554, 13, 51044], "temperature": 0.0, "avg_logprob": -0.1750826890441193, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0006068589864298701}, {"id": 640, "seek": 374664, "start": 3761.04, "end": 3766.56, "text": " But it shows that this Bayesian framework by taking a prior over possible worlds,", "tokens": [51084, 583, 309, 3110, 300, 341, 7840, 42434, 8388, 538, 1940, 257, 4059, 670, 1944, 13401, 11, 51360], "temperature": 0.0, "avg_logprob": -0.1750826890441193, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0006068589864298701}, {"id": 641, "seek": 374664, "start": 3767.2799999999997, "end": 3771.3599999999997, "text": " doing the Bayesian mixture, then the Bayes optimal decision with long term planning that is important,", "tokens": [51396, 884, 264, 7840, 42434, 9925, 11, 550, 264, 7840, 279, 16252, 3537, 365, 938, 1433, 5038, 300, 307, 1021, 11, 51600], "temperature": 0.0, "avg_logprob": -0.1750826890441193, "compression_ratio": 1.654867256637168, "no_speech_prob": 0.0006068589864298701}, {"id": 642, "seek": 377136, "start": 3772.2400000000002, "end": 3778.96, "text": " automatically implies exploration also to the proper extent, not too much exploration", "tokens": [50408, 6772, 18779, 16197, 611, 281, 264, 2296, 8396, 11, 406, 886, 709, 16197, 50744], "temperature": 0.0, "avg_logprob": -0.13100917919262037, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0017543371068313718}, {"id": 643, "seek": 377136, "start": 3778.96, "end": 3784.56, "text": " and not too little. It is very simple settings. In the IHC model, I was also able to prove that", "tokens": [50744, 293, 406, 886, 707, 13, 467, 307, 588, 2199, 6257, 13, 682, 264, 286, 39, 34, 2316, 11, 286, 390, 611, 1075, 281, 7081, 300, 51024], "temperature": 0.0, "avg_logprob": -0.13100917919262037, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0017543371068313718}, {"id": 644, "seek": 377136, "start": 3784.56, "end": 3788.8, "text": " it is a self-optimizing theorem or asymptotic optimality theorems, although they're only asymptotic,", "tokens": [51024, 309, 307, 257, 2698, 12, 5747, 332, 3319, 20904, 420, 35114, 9411, 5028, 1860, 10299, 2592, 11, 4878, 436, 434, 787, 35114, 9411, 11, 51236], "temperature": 0.0, "avg_logprob": -0.13100917919262037, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0017543371068313718}, {"id": 645, "seek": 377136, "start": 3788.8, "end": 3793.1200000000003, "text": " not finite time bounds. So it seems like the long term planning is a really important,", "tokens": [51236, 406, 19362, 565, 29905, 13, 407, 309, 2544, 411, 264, 938, 1433, 5038, 307, 257, 534, 1021, 11, 51452], "temperature": 0.0, "avg_logprob": -0.13100917919262037, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0017543371068313718}, {"id": 646, "seek": 377136, "start": 3793.1200000000003, "end": 3798.88, "text": " the long term part of the planning is really important. And also, maybe a quick tangent,", "tokens": [51452, 264, 938, 1433, 644, 295, 264, 5038, 307, 534, 1021, 13, 400, 611, 11, 1310, 257, 1702, 27747, 11, 51740], "temperature": 0.0, "avg_logprob": -0.13100917919262037, "compression_ratio": 1.7615384615384615, "no_speech_prob": 0.0017543371068313718}, {"id": 647, "seek": 379888, "start": 3798.88, "end": 3803.84, "text": " how important do you think is removing the Markov assumption and looking at the full", "tokens": [50364, 577, 1021, 360, 291, 519, 307, 12720, 264, 3934, 5179, 15302, 293, 1237, 412, 264, 1577, 50612], "temperature": 0.0, "avg_logprob": -0.13353832244873046, "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.0022493714932352304}, {"id": 648, "seek": 379888, "start": 3803.84, "end": 3810.08, "text": " history? So intuitively, of course, it's important, but is it like fundamentally", "tokens": [50612, 2503, 30, 407, 46506, 11, 295, 1164, 11, 309, 311, 1021, 11, 457, 307, 309, 411, 17879, 50924], "temperature": 0.0, "avg_logprob": -0.13353832244873046, "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.0022493714932352304}, {"id": 649, "seek": 379888, "start": 3810.08, "end": 3815.44, "text": " transformative to the entirety of the problem? What's your sense of it? Because we all,", "tokens": [50924, 36070, 281, 264, 31557, 295, 264, 1154, 30, 708, 311, 428, 2020, 295, 309, 30, 1436, 321, 439, 11, 51192], "temperature": 0.0, "avg_logprob": -0.13353832244873046, "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.0022493714932352304}, {"id": 650, "seek": 379888, "start": 3815.44, "end": 3819.84, "text": " we make that assumption quite often, just throwing away the past.", "tokens": [51192, 321, 652, 300, 15302, 1596, 2049, 11, 445, 10238, 1314, 264, 1791, 13, 51412], "temperature": 0.0, "avg_logprob": -0.13353832244873046, "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.0022493714932352304}, {"id": 651, "seek": 379888, "start": 3819.84, "end": 3827.36, "text": " Now, I think it's absolutely crucial. The question is whether there's a way to deal with it in a", "tokens": [51412, 823, 11, 286, 519, 309, 311, 3122, 11462, 13, 440, 1168, 307, 1968, 456, 311, 257, 636, 281, 2028, 365, 309, 294, 257, 51788], "temperature": 0.0, "avg_logprob": -0.13353832244873046, "compression_ratio": 1.5938697318007662, "no_speech_prob": 0.0022493714932352304}, {"id": 652, "seek": 382736, "start": 3827.36, "end": 3835.44, "text": " more heuristic and still sufficiently well way. So I have to come up with an example in the fly,", "tokens": [50364, 544, 415, 374, 3142, 293, 920, 31868, 731, 636, 13, 407, 286, 362, 281, 808, 493, 365, 364, 1365, 294, 264, 3603, 11, 50768], "temperature": 0.0, "avg_logprob": -0.1460926479763455, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001365866744890809}, {"id": 653, "seek": 382736, "start": 3835.44, "end": 3842.0, "text": " but you have some key event in your life a long time ago, in some city or something,", "tokens": [50768, 457, 291, 362, 512, 2141, 2280, 294, 428, 993, 257, 938, 565, 2057, 11, 294, 512, 2307, 420, 746, 11, 51096], "temperature": 0.0, "avg_logprob": -0.1460926479763455, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001365866744890809}, {"id": 654, "seek": 382736, "start": 3842.0, "end": 3846.7200000000003, "text": " you realize it's a really dangerous street or whatever. And you want to remember that forever,", "tokens": [51096, 291, 4325, 309, 311, 257, 534, 5795, 4838, 420, 2035, 13, 400, 291, 528, 281, 1604, 300, 5680, 11, 51332], "temperature": 0.0, "avg_logprob": -0.1460926479763455, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001365866744890809}, {"id": 655, "seek": 382736, "start": 3847.92, "end": 3852.0, "text": " in case you come back there. Kind of a selective kind of memory. So you remember", "tokens": [51392, 294, 1389, 291, 808, 646, 456, 13, 9242, 295, 257, 33930, 733, 295, 4675, 13, 407, 291, 1604, 51596], "temperature": 0.0, "avg_logprob": -0.1460926479763455, "compression_ratio": 1.579646017699115, "no_speech_prob": 0.001365866744890809}, {"id": 656, "seek": 385200, "start": 3852.8, "end": 3856.64, "text": " all the important events in the past, but somehow selecting the important", "tokens": [50404, 439, 264, 1021, 3931, 294, 264, 1791, 11, 457, 6063, 18182, 264, 1021, 50596], "temperature": 0.0, "avg_logprob": -0.18142231532505582, "compression_ratio": 1.5946969696969697, "no_speech_prob": 0.0038228079210966825}, {"id": 657, "seek": 385200, "start": 3857.36, "end": 3862.08, "text": " They're very hard. Yeah. And I'm not concerned about just storing the whole history. Just", "tokens": [50632, 814, 434, 588, 1152, 13, 865, 13, 400, 286, 478, 406, 5922, 466, 445, 26085, 264, 1379, 2503, 13, 1449, 50868], "temperature": 0.0, "avg_logprob": -0.18142231532505582, "compression_ratio": 1.5946969696969697, "no_speech_prob": 0.0038228079210966825}, {"id": 658, "seek": 385200, "start": 3862.08, "end": 3867.36, "text": " you can calculate human life, say 30 or 100 years doesn't matter, right?", "tokens": [50868, 291, 393, 8873, 1952, 993, 11, 584, 2217, 420, 2319, 924, 1177, 380, 1871, 11, 558, 30, 51132], "temperature": 0.0, "avg_logprob": -0.18142231532505582, "compression_ratio": 1.5946969696969697, "no_speech_prob": 0.0038228079210966825}, {"id": 659, "seek": 385200, "start": 3868.72, "end": 3874.0, "text": " How much data comes in through the vision system and the auditory system, you compress it a little", "tokens": [51200, 1012, 709, 1412, 1487, 294, 807, 264, 5201, 1185, 293, 264, 17748, 827, 1185, 11, 291, 14778, 309, 257, 707, 51464], "temperature": 0.0, "avg_logprob": -0.18142231532505582, "compression_ratio": 1.5946969696969697, "no_speech_prob": 0.0038228079210966825}, {"id": 660, "seek": 385200, "start": 3874.0, "end": 3879.84, "text": " bit, in this case, lossily and store it. We are soon in the means of just storing it.", "tokens": [51464, 857, 11, 294, 341, 1389, 11, 4470, 953, 293, 3531, 309, 13, 492, 366, 2321, 294, 264, 1355, 295, 445, 26085, 309, 13, 51756], "temperature": 0.0, "avg_logprob": -0.18142231532505582, "compression_ratio": 1.5946969696969697, "no_speech_prob": 0.0038228079210966825}, {"id": 661, "seek": 387984, "start": 3880.4, "end": 3886.0, "text": " But you still need to the selection for the planning part and the compression for the", "tokens": [50392, 583, 291, 920, 643, 281, 264, 9450, 337, 264, 5038, 644, 293, 264, 19355, 337, 264, 50672], "temperature": 0.0, "avg_logprob": -0.1157654204019686, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.0008554023806937039}, {"id": 662, "seek": 387984, "start": 3886.0, "end": 3891.6800000000003, "text": " understanding part. The raw storage I'm really not concerned about. And I think we should just", "tokens": [50672, 3701, 644, 13, 440, 8936, 6725, 286, 478, 534, 406, 5922, 466, 13, 400, 286, 519, 321, 820, 445, 50956], "temperature": 0.0, "avg_logprob": -0.1157654204019686, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.0008554023806937039}, {"id": 663, "seek": 387984, "start": 3891.6800000000003, "end": 3898.32, "text": " store if you develop an agent, preferably just store all the interaction history.", "tokens": [50956, 3531, 498, 291, 1499, 364, 9461, 11, 45916, 445, 3531, 439, 264, 9285, 2503, 13, 51288], "temperature": 0.0, "avg_logprob": -0.1157654204019686, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.0008554023806937039}, {"id": 664, "seek": 387984, "start": 3899.36, "end": 3904.8, "text": " And then you build, of course, models on top of it and you compress it and you are selective,", "tokens": [51340, 400, 550, 291, 1322, 11, 295, 1164, 11, 5245, 322, 1192, 295, 309, 293, 291, 14778, 309, 293, 291, 366, 33930, 11, 51612], "temperature": 0.0, "avg_logprob": -0.1157654204019686, "compression_ratio": 1.6952380952380952, "no_speech_prob": 0.0008554023806937039}, {"id": 665, "seek": 390480, "start": 3904.88, "end": 3911.44, "text": " but occasionally, you go back to the old data and reanalyze it based on your new experience", "tokens": [50368, 457, 16895, 11, 291, 352, 646, 281, 264, 1331, 1412, 293, 319, 282, 5222, 1381, 309, 2361, 322, 428, 777, 1752, 50696], "temperature": 0.0, "avg_logprob": -0.17375148575881433, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.009852071292698383}, {"id": 666, "seek": 390480, "start": 3911.44, "end": 3916.2400000000002, "text": " you have. You know, sometimes you are in school, you learn all these things you think is totally", "tokens": [50696, 291, 362, 13, 509, 458, 11, 2171, 291, 366, 294, 1395, 11, 291, 1466, 439, 613, 721, 291, 519, 307, 3879, 50936], "temperature": 0.0, "avg_logprob": -0.17375148575881433, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.009852071292698383}, {"id": 667, "seek": 390480, "start": 3916.2400000000002, "end": 3921.04, "text": " useless. And you know, much later you read us, oh, they were not, you know, so useless as you", "tokens": [50936, 14115, 13, 400, 291, 458, 11, 709, 1780, 291, 1401, 505, 11, 1954, 11, 436, 645, 406, 11, 291, 458, 11, 370, 14115, 382, 291, 51176], "temperature": 0.0, "avg_logprob": -0.17375148575881433, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.009852071292698383}, {"id": 668, "seek": 390480, "start": 3921.04, "end": 3927.1200000000003, "text": " thought. I'm looking at you linear algebra. Right. So maybe let me ask about objective", "tokens": [51176, 1194, 13, 286, 478, 1237, 412, 291, 8213, 21989, 13, 1779, 13, 407, 1310, 718, 385, 1029, 466, 10024, 51480], "temperature": 0.0, "avg_logprob": -0.17375148575881433, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.009852071292698383}, {"id": 669, "seek": 390480, "start": 3927.1200000000003, "end": 3934.6400000000003, "text": " functions because that rewards, it seems to be an important part. The rewards are kind of", "tokens": [51480, 6828, 570, 300, 17203, 11, 309, 2544, 281, 312, 364, 1021, 644, 13, 440, 17203, 366, 733, 295, 51856], "temperature": 0.0, "avg_logprob": -0.17375148575881433, "compression_ratio": 1.6392857142857142, "no_speech_prob": 0.009852071292698383}, {"id": 670, "seek": 393464, "start": 3934.64, "end": 3945.12, "text": " given to the system. For a lot of people, the specification of the objective function", "tokens": [50364, 2212, 281, 264, 1185, 13, 1171, 257, 688, 295, 561, 11, 264, 31256, 295, 264, 10024, 2445, 50888], "temperature": 0.0, "avg_logprob": -0.16205912121271682, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.0007319657015614212}, {"id": 671, "seek": 393464, "start": 3946.3199999999997, "end": 3952.08, "text": " is a key part of intelligence. The agent itself figuring out what is important.", "tokens": [50948, 307, 257, 2141, 644, 295, 7599, 13, 440, 9461, 2564, 15213, 484, 437, 307, 1021, 13, 51236], "temperature": 0.0, "avg_logprob": -0.16205912121271682, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.0007319657015614212}, {"id": 672, "seek": 393464, "start": 3952.96, "end": 3960.16, "text": " What do you think about that? Is it possible within IACC framework to yourself discover", "tokens": [51280, 708, 360, 291, 519, 466, 300, 30, 1119, 309, 1944, 1951, 286, 4378, 34, 8388, 281, 1803, 4411, 51640], "temperature": 0.0, "avg_logprob": -0.16205912121271682, "compression_ratio": 1.4213483146067416, "no_speech_prob": 0.0007319657015614212}, {"id": 673, "seek": 396016, "start": 3960.24, "end": 3966.7999999999997, "text": " the reward based on which you should operate? Okay, that will be a long answer.", "tokens": [50368, 264, 7782, 2361, 322, 597, 291, 820, 9651, 30, 1033, 11, 300, 486, 312, 257, 938, 1867, 13, 50696], "temperature": 0.0, "avg_logprob": -0.13519473828767475, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0012642948422580957}, {"id": 674, "seek": 396016, "start": 3968.7999999999997, "end": 3974.3999999999996, "text": " So, and that is a very interesting question. And I'm asked a lot about this question,", "tokens": [50796, 407, 11, 293, 300, 307, 257, 588, 1880, 1168, 13, 400, 286, 478, 2351, 257, 688, 466, 341, 1168, 11, 51076], "temperature": 0.0, "avg_logprob": -0.13519473828767475, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0012642948422580957}, {"id": 675, "seek": 396016, "start": 3974.3999999999996, "end": 3982.96, "text": " where do the rewards come from? And that depends. So, and I give you now a couple of answers. So", "tokens": [51076, 689, 360, 264, 17203, 808, 490, 30, 400, 300, 5946, 13, 407, 11, 293, 286, 976, 291, 586, 257, 1916, 295, 6338, 13, 407, 51504], "temperature": 0.0, "avg_logprob": -0.13519473828767475, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0012642948422580957}, {"id": 676, "seek": 396016, "start": 3982.96, "end": 3989.7599999999998, "text": " if we want to build agents, now let's start simple. So let's assume we want to build an agent", "tokens": [51504, 498, 321, 528, 281, 1322, 12554, 11, 586, 718, 311, 722, 2199, 13, 407, 718, 311, 6552, 321, 528, 281, 1322, 364, 9461, 51844], "temperature": 0.0, "avg_logprob": -0.13519473828767475, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0012642948422580957}, {"id": 677, "seek": 398976, "start": 3989.76, "end": 3995.1200000000003, "text": " based on the IACC model, which performs a particular task. Let's start with something", "tokens": [50364, 2361, 322, 264, 286, 4378, 34, 2316, 11, 597, 26213, 257, 1729, 5633, 13, 961, 311, 722, 365, 746, 50632], "temperature": 0.0, "avg_logprob": -0.13580104037448093, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526851746253669}, {"id": 678, "seek": 398976, "start": 3995.1200000000003, "end": 3998.96, "text": " super simple, like, I mean, super simple, like playing chess or go or something.", "tokens": [50632, 1687, 2199, 11, 411, 11, 286, 914, 11, 1687, 2199, 11, 411, 2433, 24122, 420, 352, 420, 746, 13, 50824], "temperature": 0.0, "avg_logprob": -0.13580104037448093, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526851746253669}, {"id": 679, "seek": 398976, "start": 3999.76, "end": 4003.36, "text": " Then you just, you know, the reward is, you know, winning the game is plus one,", "tokens": [50864, 1396, 291, 445, 11, 291, 458, 11, 264, 7782, 307, 11, 291, 458, 11, 8224, 264, 1216, 307, 1804, 472, 11, 51044], "temperature": 0.0, "avg_logprob": -0.13580104037448093, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526851746253669}, {"id": 680, "seek": 398976, "start": 4003.36, "end": 4008.2400000000002, "text": " losing the game is minus one, done. You apply this agent, if you have enough compute,", "tokens": [51044, 7027, 264, 1216, 307, 3175, 472, 11, 1096, 13, 509, 3079, 341, 9461, 11, 498, 291, 362, 1547, 14722, 11, 51288], "temperature": 0.0, "avg_logprob": -0.13580104037448093, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526851746253669}, {"id": 681, "seek": 398976, "start": 4008.2400000000002, "end": 4013.36, "text": " you let itself play, and it will learn the rules of the game will play perfect chess after some", "tokens": [51288, 291, 718, 2564, 862, 11, 293, 309, 486, 1466, 264, 4474, 295, 264, 1216, 486, 862, 2176, 24122, 934, 512, 51544], "temperature": 0.0, "avg_logprob": -0.13580104037448093, "compression_ratio": 1.7327935222672064, "no_speech_prob": 0.0005526851746253669}, {"id": 682, "seek": 401336, "start": 4013.36, "end": 4023.44, "text": " while problem solved. Okay, so if you have more complicated problems, then you may believe that", "tokens": [50364, 1339, 1154, 13041, 13, 1033, 11, 370, 498, 291, 362, 544, 6179, 2740, 11, 550, 291, 815, 1697, 300, 50868], "temperature": 0.0, "avg_logprob": -0.0890170815064735, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.007459067273885012}, {"id": 683, "seek": 401336, "start": 4023.44, "end": 4029.6, "text": " you have the right reward, but it's not. So a nice cute example is elevator control that is also in", "tokens": [50868, 291, 362, 264, 558, 7782, 11, 457, 309, 311, 406, 13, 407, 257, 1481, 4052, 1365, 307, 18782, 1969, 300, 307, 611, 294, 51176], "temperature": 0.0, "avg_logprob": -0.0890170815064735, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.007459067273885012}, {"id": 684, "seek": 401336, "start": 4029.6, "end": 4036.08, "text": " Rich Sutton's book, which is a great book, by the way. So you control the elevator, and you think,", "tokens": [51176, 6781, 40492, 1756, 311, 1446, 11, 597, 307, 257, 869, 1446, 11, 538, 264, 636, 13, 407, 291, 1969, 264, 18782, 11, 293, 291, 519, 11, 51500], "temperature": 0.0, "avg_logprob": -0.0890170815064735, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.007459067273885012}, {"id": 685, "seek": 401336, "start": 4036.08, "end": 4040.32, "text": " well, maybe the reward should be coupled to how long people wait in front of the elevator,", "tokens": [51500, 731, 11, 1310, 264, 7782, 820, 312, 29482, 281, 577, 938, 561, 1699, 294, 1868, 295, 264, 18782, 11, 51712], "temperature": 0.0, "avg_logprob": -0.0890170815064735, "compression_ratio": 1.6885964912280702, "no_speech_prob": 0.007459067273885012}, {"id": 686, "seek": 404032, "start": 4040.4, "end": 4045.52, "text": " you know, long wait is bad. You program it and you do it. And what happens is the elevator", "tokens": [50368, 291, 458, 11, 938, 1699, 307, 1578, 13, 509, 1461, 309, 293, 291, 360, 309, 13, 400, 437, 2314, 307, 264, 18782, 50624], "temperature": 0.0, "avg_logprob": -0.1334512729455929, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0011877277866005898}, {"id": 687, "seek": 404032, "start": 4045.52, "end": 4053.04, "text": " eagerly picks up all the people, but never drops them off. So then you realize, maybe the time in", "tokens": [50624, 18259, 356, 16137, 493, 439, 264, 561, 11, 457, 1128, 11438, 552, 766, 13, 407, 550, 291, 4325, 11, 1310, 264, 565, 294, 51000], "temperature": 0.0, "avg_logprob": -0.1334512729455929, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0011877277866005898}, {"id": 688, "seek": 404032, "start": 4053.04, "end": 4058.8, "text": " the elevator also counts. So you minimize the sum. Yeah. And the elevator does that, but never picks", "tokens": [51000, 264, 18782, 611, 14893, 13, 407, 291, 17522, 264, 2408, 13, 865, 13, 400, 264, 18782, 775, 300, 11, 457, 1128, 16137, 51288], "temperature": 0.0, "avg_logprob": -0.1334512729455929, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0011877277866005898}, {"id": 689, "seek": 404032, "start": 4058.8, "end": 4062.88, "text": " up the people in the 10th floor and the top floor, because in expectation, it's not worth it. Just", "tokens": [51288, 493, 264, 561, 294, 264, 1266, 392, 4123, 293, 264, 1192, 4123, 11, 570, 294, 14334, 11, 309, 311, 406, 3163, 309, 13, 1449, 51492], "temperature": 0.0, "avg_logprob": -0.1334512729455929, "compression_ratio": 1.7168141592920354, "no_speech_prob": 0.0011877277866005898}, {"id": 690, "seek": 406288, "start": 4062.96, "end": 4072.0, "text": " let them stay. So even in apparently simple problems, you can make mistakes. And that's", "tokens": [50368, 718, 552, 1754, 13, 407, 754, 294, 7970, 2199, 2740, 11, 291, 393, 652, 8038, 13, 400, 300, 311, 50820], "temperature": 0.0, "avg_logprob": -0.18464878627232142, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0037632465828210115}, {"id": 691, "seek": 406288, "start": 4073.6, "end": 4079.6, "text": " what in more serious context, say, AGI safety researchers consider. So now let's go back to", "tokens": [50900, 437, 294, 544, 3156, 4319, 11, 584, 11, 316, 26252, 4514, 10309, 1949, 13, 407, 586, 718, 311, 352, 646, 281, 51200], "temperature": 0.0, "avg_logprob": -0.18464878627232142, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0037632465828210115}, {"id": 692, "seek": 406288, "start": 4080.2400000000002, "end": 4085.28, "text": " general agents. So assume we want to build an agent, which is generally useful to humans.", "tokens": [51232, 2674, 12554, 13, 407, 6552, 321, 528, 281, 1322, 364, 9461, 11, 597, 307, 5101, 4420, 281, 6255, 13, 51484], "temperature": 0.0, "avg_logprob": -0.18464878627232142, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0037632465828210115}, {"id": 693, "seek": 406288, "start": 4085.28, "end": 4091.04, "text": " Yes, we have a household robot, and it should do all kinds of tasks. So in this case,", "tokens": [51484, 1079, 11, 321, 362, 257, 9888, 7881, 11, 293, 309, 820, 360, 439, 3685, 295, 9608, 13, 407, 294, 341, 1389, 11, 51772], "temperature": 0.0, "avg_logprob": -0.18464878627232142, "compression_ratio": 1.517094017094017, "no_speech_prob": 0.0037632465828210115}, {"id": 694, "seek": 409104, "start": 4091.84, "end": 4096.8, "text": " the human should give the reward on the fly. I mean, maybe it's pre trained in the factory and", "tokens": [50404, 264, 1952, 820, 976, 264, 7782, 322, 264, 3603, 13, 286, 914, 11, 1310, 309, 311, 659, 8895, 294, 264, 9265, 293, 50652], "temperature": 0.0, "avg_logprob": -0.1271314388368188, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0013669092440977693}, {"id": 695, "seek": 409104, "start": 4096.8, "end": 4100.56, "text": " that there's some sort of internal reward for, you know, the battery level or whatever. But", "tokens": [50652, 300, 456, 311, 512, 1333, 295, 6920, 7782, 337, 11, 291, 458, 11, 264, 5809, 1496, 420, 2035, 13, 583, 50840], "temperature": 0.0, "avg_logprob": -0.1271314388368188, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0013669092440977693}, {"id": 696, "seek": 409104, "start": 4101.6, "end": 4105.12, "text": " so it, you know, it does the dishes badly, you know, you punish the robot, you does it good,", "tokens": [50892, 370, 309, 11, 291, 458, 11, 309, 775, 264, 10814, 13425, 11, 291, 458, 11, 291, 9842, 264, 7881, 11, 291, 775, 309, 665, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1271314388368188, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0013669092440977693}, {"id": 697, "seek": 409104, "start": 4105.12, "end": 4109.04, "text": " you reward the robot and then train it to a new task, like a child, right? So", "tokens": [51068, 291, 7782, 264, 7881, 293, 550, 3847, 309, 281, 257, 777, 5633, 11, 411, 257, 1440, 11, 558, 30, 407, 51264], "temperature": 0.0, "avg_logprob": -0.1271314388368188, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0013669092440977693}, {"id": 698, "seek": 409104, "start": 4110.0, "end": 4115.5199999999995, "text": " you need the human in the loop. If you want a system, which is useful to the human. And as long", "tokens": [51312, 291, 643, 264, 1952, 294, 264, 6367, 13, 759, 291, 528, 257, 1185, 11, 597, 307, 4420, 281, 264, 1952, 13, 400, 382, 938, 51588], "temperature": 0.0, "avg_logprob": -0.1271314388368188, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0013669092440977693}, {"id": 699, "seek": 411552, "start": 4115.52, "end": 4122.160000000001, "text": " as this agent stays sub human level, that should work reasonably well. And apart from, you know,", "tokens": [50364, 382, 341, 9461, 10834, 1422, 1952, 1496, 11, 300, 820, 589, 23551, 731, 13, 400, 4936, 490, 11, 291, 458, 11, 50696], "temperature": 0.0, "avg_logprob": -0.144692869267912, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015484909527003765}, {"id": 700, "seek": 411552, "start": 4122.160000000001, "end": 4126.56, "text": " these examples, it becomes critical if they become, you know, on a human level, it's like", "tokens": [50696, 613, 5110, 11, 309, 3643, 4924, 498, 436, 1813, 11, 291, 458, 11, 322, 257, 1952, 1496, 11, 309, 311, 411, 50916], "temperature": 0.0, "avg_logprob": -0.144692869267912, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015484909527003765}, {"id": 701, "seek": 411552, "start": 4126.56, "end": 4131.4400000000005, "text": " with children, small children, you have reasonably well under control, they become older. The reward", "tokens": [50916, 365, 2227, 11, 1359, 2227, 11, 291, 362, 23551, 731, 833, 1969, 11, 436, 1813, 4906, 13, 440, 7782, 51160], "temperature": 0.0, "avg_logprob": -0.144692869267912, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015484909527003765}, {"id": 702, "seek": 411552, "start": 4131.4400000000005, "end": 4139.76, "text": " technique doesn't work so well anymore. So then finally, so this would be agents, which are just,", "tokens": [51160, 6532, 1177, 380, 589, 370, 731, 3602, 13, 407, 550, 2721, 11, 370, 341, 576, 312, 12554, 11, 597, 366, 445, 11, 51576], "temperature": 0.0, "avg_logprob": -0.144692869267912, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015484909527003765}, {"id": 703, "seek": 411552, "start": 4139.76, "end": 4144.88, "text": " you could say slaves to the humans. Yeah. So if you are more ambitious and just say we want to", "tokens": [51576, 291, 727, 584, 18394, 281, 264, 6255, 13, 865, 13, 407, 498, 291, 366, 544, 20239, 293, 445, 584, 321, 528, 281, 51832], "temperature": 0.0, "avg_logprob": -0.144692869267912, "compression_ratio": 1.7454545454545454, "no_speech_prob": 0.0015484909527003765}, {"id": 704, "seek": 414488, "start": 4144.88, "end": 4150.96, "text": " build a new spacious of intelligent beings, we put them on a new planet and we want them to", "tokens": [50364, 1322, 257, 777, 36801, 295, 13232, 8958, 11, 321, 829, 552, 322, 257, 777, 5054, 293, 321, 528, 552, 281, 50668], "temperature": 0.0, "avg_logprob": -0.09053993225097656, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.00019108229025732726}, {"id": 705, "seek": 414488, "start": 4150.96, "end": 4158.08, "text": " develop this planet or whatever. So we don't give them any reward. So what could we do? And", "tokens": [50668, 1499, 341, 5054, 420, 2035, 13, 407, 321, 500, 380, 976, 552, 604, 7782, 13, 407, 437, 727, 321, 360, 30, 400, 51024], "temperature": 0.0, "avg_logprob": -0.09053993225097656, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.00019108229025732726}, {"id": 706, "seek": 414488, "start": 4158.08, "end": 4162.8, "text": " you could try to, you know, come up with some reward functions like, you know, it should maintain", "tokens": [51024, 291, 727, 853, 281, 11, 291, 458, 11, 808, 493, 365, 512, 7782, 6828, 411, 11, 291, 458, 11, 309, 820, 6909, 51260], "temperature": 0.0, "avg_logprob": -0.09053993225097656, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.00019108229025732726}, {"id": 707, "seek": 414488, "start": 4162.8, "end": 4170.16, "text": " itself the robot, it should maybe multiply build more robots, right? And, you know, maybe", "tokens": [51260, 2564, 264, 7881, 11, 309, 820, 1310, 12972, 1322, 544, 14733, 11, 558, 30, 400, 11, 291, 458, 11, 1310, 51628], "temperature": 0.0, "avg_logprob": -0.09053993225097656, "compression_ratio": 1.7255813953488373, "no_speech_prob": 0.00019108229025732726}, {"id": 708, "seek": 417016, "start": 4171.12, "end": 4174.639999999999, "text": " for all kinds of things that you find useful, but that's pretty hard, right? You know,", "tokens": [50412, 337, 439, 3685, 295, 721, 300, 291, 915, 4420, 11, 457, 300, 311, 1238, 1152, 11, 558, 30, 509, 458, 11, 50588], "temperature": 0.0, "avg_logprob": -0.18850594917229846, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.0012642992660403252}, {"id": 709, "seek": 417016, "start": 4174.639999999999, "end": 4178.72, "text": " what does self maintenance mean? You know, what does it mean to build a copy? Should it be exact", "tokens": [50588, 437, 775, 2698, 11258, 914, 30, 509, 458, 11, 437, 775, 309, 914, 281, 1322, 257, 5055, 30, 6454, 309, 312, 1900, 50792], "temperature": 0.0, "avg_logprob": -0.18850594917229846, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.0012642992660403252}, {"id": 710, "seek": 417016, "start": 4178.72, "end": 4185.12, "text": " copy or an approximate copy? And so that's really hard. But Laurent or so, also at DeepMind,", "tokens": [50792, 5055, 420, 364, 30874, 5055, 30, 400, 370, 300, 311, 534, 1152, 13, 583, 49357, 420, 370, 11, 611, 412, 14895, 44, 471, 11, 51112], "temperature": 0.0, "avg_logprob": -0.18850594917229846, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.0012642992660403252}, {"id": 711, "seek": 417016, "start": 4186.0, "end": 4192.0, "text": " developed a beautiful model. So it just took the ICSE model and coupled the rewards", "tokens": [51156, 4743, 257, 2238, 2316, 13, 407, 309, 445, 1890, 264, 14360, 5879, 2316, 293, 29482, 264, 17203, 51456], "temperature": 0.0, "avg_logprob": -0.18850594917229846, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.0012642992660403252}, {"id": 712, "seek": 417016, "start": 4192.72, "end": 4199.04, "text": " to information gain. So he said the reward is proportional to how much the agent had", "tokens": [51492, 281, 1589, 6052, 13, 407, 415, 848, 264, 7782, 307, 24969, 281, 577, 709, 264, 9461, 632, 51808], "temperature": 0.0, "avg_logprob": -0.18850594917229846, "compression_ratio": 1.63003663003663, "no_speech_prob": 0.0012642992660403252}, {"id": 713, "seek": 419904, "start": 4199.12, "end": 4203.84, "text": " learned about the world. And you can rigorously formally uniquely define that in terms of", "tokens": [50368, 3264, 466, 264, 1002, 13, 400, 291, 393, 42191, 5098, 25983, 31474, 6964, 300, 294, 2115, 295, 50604], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 714, "seek": 419904, "start": 4203.84, "end": 4209.2, "text": " our cattle diversions. Okay. So if you put that in, you get a completely autonomous agent.", "tokens": [50604, 527, 19992, 6111, 626, 13, 1033, 13, 407, 498, 291, 829, 300, 294, 11, 291, 483, 257, 2584, 23797, 9461, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 715, "seek": 419904, "start": 4209.76, "end": 4213.44, "text": " And actually, interestingly, for this agent, we can prove much stronger result than for the", "tokens": [50900, 400, 767, 11, 25873, 11, 337, 341, 9461, 11, 321, 393, 7081, 709, 7249, 1874, 813, 337, 264, 51084], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 716, "seek": 419904, "start": 4213.44, "end": 4219.04, "text": " general agent, which is also nice. And if you let this agent lose, it will be in a sense the", "tokens": [51084, 2674, 9461, 11, 597, 307, 611, 1481, 13, 400, 498, 291, 718, 341, 9461, 3624, 11, 309, 486, 312, 294, 257, 2020, 264, 51364], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 717, "seek": 419904, "start": 4219.04, "end": 4224.8, "text": " optimal scientist is absolutely curious to learn as much as possible about the world. And of course,", "tokens": [51364, 16252, 12662, 307, 3122, 6369, 281, 1466, 382, 709, 382, 1944, 466, 264, 1002, 13, 400, 295, 1164, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 718, "seek": 419904, "start": 4224.8, "end": 4228.8, "text": " it will also have a lot of instrumental goals, right? In order to learn, it needs to at least", "tokens": [51652, 309, 486, 611, 362, 257, 688, 295, 17388, 5493, 11, 558, 30, 682, 1668, 281, 1466, 11, 309, 2203, 281, 412, 1935, 51852], "temperature": 0.0, "avg_logprob": -0.11148353832871166, "compression_ratio": 1.8064516129032258, "no_speech_prob": 0.0017818605992943048}, {"id": 719, "seek": 422880, "start": 4228.8, "end": 4233.92, "text": " survive, right? That that agent is not good for anything. So it needs to have self preservation.", "tokens": [50364, 7867, 11, 558, 30, 663, 300, 9461, 307, 406, 665, 337, 1340, 13, 407, 309, 2203, 281, 362, 2698, 27257, 13, 50620], "temperature": 0.0, "avg_logprob": -0.11942981373180042, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0018660722998902202}, {"id": 720, "seek": 422880, "start": 4233.92, "end": 4241.04, "text": " And if it builds small helpers acquiring more information, it will do that. Yeah, if exploration,", "tokens": [50620, 400, 498, 309, 15182, 1359, 854, 433, 37374, 544, 1589, 11, 309, 486, 360, 300, 13, 865, 11, 498, 16197, 11, 50976], "temperature": 0.0, "avg_logprob": -0.11942981373180042, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0018660722998902202}, {"id": 721, "seek": 422880, "start": 4241.04, "end": 4246.24, "text": " space exploration or whatever is necessary, right, to gathering information and develop it. So it has", "tokens": [50976, 1901, 16197, 420, 2035, 307, 4818, 11, 558, 11, 281, 13519, 1589, 293, 1499, 309, 13, 407, 309, 575, 51236], "temperature": 0.0, "avg_logprob": -0.11942981373180042, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0018660722998902202}, {"id": 722, "seek": 422880, "start": 4246.24, "end": 4252.24, "text": " a lot of instrumental goals following on this information gain. And this agent is completely", "tokens": [51236, 257, 688, 295, 17388, 5493, 3480, 322, 341, 1589, 6052, 13, 400, 341, 9461, 307, 2584, 51536], "temperature": 0.0, "avg_logprob": -0.11942981373180042, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0018660722998902202}, {"id": 723, "seek": 422880, "start": 4252.24, "end": 4258.24, "text": " autonomous of us. No rewards necessary anymore. Yeah, of course, you could find a way to gain", "tokens": [51536, 23797, 295, 505, 13, 883, 17203, 4818, 3602, 13, 865, 11, 295, 1164, 11, 291, 727, 915, 257, 636, 281, 6052, 51836], "temperature": 0.0, "avg_logprob": -0.11942981373180042, "compression_ratio": 1.7188612099644127, "no_speech_prob": 0.0018660722998902202}, {"id": 724, "seek": 425824, "start": 4258.32, "end": 4265.679999999999, "text": " the concept of information and get stuck in that library that you mentioned beforehand", "tokens": [50368, 264, 3410, 295, 1589, 293, 483, 5541, 294, 300, 6405, 300, 291, 2835, 22893, 50736], "temperature": 0.0, "avg_logprob": -0.14261039272769466, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.004534807521849871}, {"id": 725, "seek": 425824, "start": 4265.679999999999, "end": 4272.0, "text": " with a with a very large number of books. The first agent had this problem. It would get stuck", "tokens": [50736, 365, 257, 365, 257, 588, 2416, 1230, 295, 3642, 13, 440, 700, 9461, 632, 341, 1154, 13, 467, 576, 483, 5541, 51052], "temperature": 0.0, "avg_logprob": -0.14261039272769466, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.004534807521849871}, {"id": 726, "seek": 425824, "start": 4272.0, "end": 4277.76, "text": " in front of an old TV screen, which has just said white noise. Yeah, white noise. But the second", "tokens": [51052, 294, 1868, 295, 364, 1331, 3558, 2568, 11, 597, 575, 445, 848, 2418, 5658, 13, 865, 11, 2418, 5658, 13, 583, 264, 1150, 51340], "temperature": 0.0, "avg_logprob": -0.14261039272769466, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.004534807521849871}, {"id": 727, "seek": 425824, "start": 4277.76, "end": 4284.5599999999995, "text": " version can deal with at least stochasticity. Well, yeah, what about curiosity, this kind of word", "tokens": [51340, 3037, 393, 2028, 365, 412, 1935, 342, 8997, 2750, 507, 13, 1042, 11, 1338, 11, 437, 466, 18769, 11, 341, 733, 295, 1349, 51680], "temperature": 0.0, "avg_logprob": -0.14261039272769466, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.004534807521849871}, {"id": 728, "seek": 428456, "start": 4285.360000000001, "end": 4291.92, "text": " curiosity, creativity? Is that kind of the reward function being of getting new information?", "tokens": [50404, 18769, 11, 12915, 30, 1119, 300, 733, 295, 264, 7782, 2445, 885, 295, 1242, 777, 1589, 30, 50732], "temperature": 0.0, "avg_logprob": -0.10870885092114645, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.0015976387076079845}, {"id": 729, "seek": 428456, "start": 4291.92, "end": 4301.280000000001, "text": " Is that similar to idea of kind of injecting exploration for its own sake inside the reward", "tokens": [50732, 1119, 300, 2531, 281, 1558, 295, 733, 295, 10711, 278, 16197, 337, 1080, 1065, 9717, 1854, 264, 7782, 51200], "temperature": 0.0, "avg_logprob": -0.10870885092114645, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.0015976387076079845}, {"id": 730, "seek": 428456, "start": 4301.280000000001, "end": 4306.240000000001, "text": " function? Do you find this at all appealing, interesting? I think that's a nice definition.", "tokens": [51200, 2445, 30, 1144, 291, 915, 341, 412, 439, 23842, 11, 1880, 30, 286, 519, 300, 311, 257, 1481, 7123, 13, 51448], "temperature": 0.0, "avg_logprob": -0.10870885092114645, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.0015976387076079845}, {"id": 731, "seek": 430624, "start": 4306.24, "end": 4311.599999999999, "text": " Curiosity is the reward. Sorry, curiosity is exploration for its own sake.", "tokens": [50364, 48998, 307, 264, 7782, 13, 4919, 11, 18769, 307, 16197, 337, 1080, 1065, 9717, 13, 50632], "temperature": 0.0, "avg_logprob": -0.1428035623887006, "compression_ratio": 1.7, "no_speech_prob": 0.018531912937760353}, {"id": 732, "seek": 430624, "start": 4314.719999999999, "end": 4320.96, "text": " Yeah, I would accept that. But most curiosity, while in humans and especially in children,", "tokens": [50788, 865, 11, 286, 576, 3241, 300, 13, 583, 881, 18769, 11, 1339, 294, 6255, 293, 2318, 294, 2227, 11, 51100], "temperature": 0.0, "avg_logprob": -0.1428035623887006, "compression_ratio": 1.7, "no_speech_prob": 0.018531912937760353}, {"id": 733, "seek": 430624, "start": 4320.96, "end": 4326.32, "text": " yeah, is not just for its own sake, but for actually learning about the environment and for", "tokens": [51100, 1338, 11, 307, 406, 445, 337, 1080, 1065, 9717, 11, 457, 337, 767, 2539, 466, 264, 2823, 293, 337, 51368], "temperature": 0.0, "avg_logprob": -0.1428035623887006, "compression_ratio": 1.7, "no_speech_prob": 0.018531912937760353}, {"id": 734, "seek": 430624, "start": 4326.32, "end": 4334.719999999999, "text": " behaving better. So I would, I think most curiosity is tied in the end to what's performing better.", "tokens": [51368, 35263, 1101, 13, 407, 286, 576, 11, 286, 519, 881, 18769, 307, 9601, 294, 264, 917, 281, 437, 311, 10205, 1101, 13, 51788], "temperature": 0.0, "avg_logprob": -0.1428035623887006, "compression_ratio": 1.7, "no_speech_prob": 0.018531912937760353}, {"id": 735, "seek": 433472, "start": 4334.8, "end": 4341.2, "text": " Well, okay, so if intelligent systems need to have this reward function, let me, you're an", "tokens": [50368, 1042, 11, 1392, 11, 370, 498, 13232, 3652, 643, 281, 362, 341, 7782, 2445, 11, 718, 385, 11, 291, 434, 364, 50688], "temperature": 0.0, "avg_logprob": -0.157746483297909, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.000939384161029011}, {"id": 736, "seek": 433472, "start": 4341.2, "end": 4349.6, "text": " intelligent system, currently passing the torrent test quite effectively. What's the reward function", "tokens": [50688, 13232, 1185, 11, 4362, 8437, 264, 3930, 1753, 1500, 1596, 8659, 13, 708, 311, 264, 7782, 2445, 51108], "temperature": 0.0, "avg_logprob": -0.157746483297909, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.000939384161029011}, {"id": 737, "seek": 433472, "start": 4350.8, "end": 4356.4800000000005, "text": " of our human intelligence existence? What's the reward function that Marcus Hutter is operating", "tokens": [51168, 295, 527, 1952, 7599, 9123, 30, 708, 311, 264, 7782, 2445, 300, 26574, 389, 9947, 307, 7447, 51452], "temperature": 0.0, "avg_logprob": -0.157746483297909, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.000939384161029011}, {"id": 738, "seek": 433472, "start": 4356.4800000000005, "end": 4363.84, "text": " under? Okay, to the first question, the biological reward function is to survive and to spread.", "tokens": [51452, 833, 30, 1033, 11, 281, 264, 700, 1168, 11, 264, 13910, 7782, 2445, 307, 281, 7867, 293, 281, 3974, 13, 51820], "temperature": 0.0, "avg_logprob": -0.157746483297909, "compression_ratio": 1.7813953488372094, "no_speech_prob": 0.000939384161029011}, {"id": 739, "seek": 436384, "start": 4364.4800000000005, "end": 4369.68, "text": " And very few humans sort of are able to overcome this biological reward function.", "tokens": [50396, 400, 588, 1326, 6255, 1333, 295, 366, 1075, 281, 10473, 341, 13910, 7782, 2445, 13, 50656], "temperature": 0.0, "avg_logprob": -0.11389654944924747, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0015710407169535756}, {"id": 740, "seek": 436384, "start": 4370.88, "end": 4377.28, "text": " But we live in a very nice world where we have lots of spare time and can still survive and", "tokens": [50716, 583, 321, 1621, 294, 257, 588, 1481, 1002, 689, 321, 362, 3195, 295, 13798, 565, 293, 393, 920, 7867, 293, 51036], "temperature": 0.0, "avg_logprob": -0.11389654944924747, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0015710407169535756}, {"id": 741, "seek": 436384, "start": 4377.28, "end": 4383.28, "text": " spread. So we can develop arbitrary other interests, which is quite interesting.", "tokens": [51036, 3974, 13, 407, 321, 393, 1499, 23211, 661, 8847, 11, 597, 307, 1596, 1880, 13, 51336], "temperature": 0.0, "avg_logprob": -0.11389654944924747, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0015710407169535756}, {"id": 742, "seek": 436384, "start": 4383.28, "end": 4389.6, "text": " On top of that? On top of that, yeah. But the survival and spreading sort of is, I would say,", "tokens": [51336, 1282, 1192, 295, 300, 30, 1282, 1192, 295, 300, 11, 1338, 13, 583, 264, 12559, 293, 15232, 1333, 295, 307, 11, 286, 576, 584, 11, 51652], "temperature": 0.0, "avg_logprob": -0.11389654944924747, "compression_ratio": 1.5963302752293578, "no_speech_prob": 0.0015710407169535756}, {"id": 743, "seek": 438960, "start": 4390.320000000001, "end": 4394.08, "text": " the goal or the reward function of humans that the core one.", "tokens": [50400, 264, 3387, 420, 264, 7782, 2445, 295, 6255, 300, 264, 4965, 472, 13, 50588], "temperature": 0.0, "avg_logprob": -0.18845206812808388, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.0015244815731421113}, {"id": 744, "seek": 438960, "start": 4395.120000000001, "end": 4399.04, "text": " I like how you avoided answering the second question, which a good intelligence system would.", "tokens": [50640, 286, 411, 577, 291, 24890, 13430, 264, 1150, 1168, 11, 597, 257, 665, 7599, 1185, 576, 13, 50836], "temperature": 0.0, "avg_logprob": -0.18845206812808388, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.0015244815731421113}, {"id": 745, "seek": 438960, "start": 4399.6, "end": 4404.160000000001, "text": " So my, your own meaning of life and the reward function?", "tokens": [50864, 407, 452, 11, 428, 1065, 3620, 295, 993, 293, 264, 7782, 2445, 30, 51092], "temperature": 0.0, "avg_logprob": -0.18845206812808388, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.0015244815731421113}, {"id": 746, "seek": 438960, "start": 4404.160000000001, "end": 4409.200000000001, "text": " My own meaning of life and reward function is to find an AGI to build it.", "tokens": [51092, 1222, 1065, 3620, 295, 993, 293, 7782, 2445, 307, 281, 915, 364, 316, 26252, 281, 1322, 309, 13, 51344], "temperature": 0.0, "avg_logprob": -0.18845206812808388, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.0015244815731421113}, {"id": 747, "seek": 438960, "start": 4411.04, "end": 4417.280000000001, "text": " Beautifully put. Okay, let's dissect the X even further. So one of the assumptions is kind of", "tokens": [51436, 10584, 15386, 829, 13, 1033, 11, 718, 311, 48332, 264, 1783, 754, 3052, 13, 407, 472, 295, 264, 17695, 307, 733, 295, 51748], "temperature": 0.0, "avg_logprob": -0.18845206812808388, "compression_ratio": 1.6550218340611353, "no_speech_prob": 0.0015244815731421113}, {"id": 748, "seek": 441728, "start": 4417.28, "end": 4425.92, "text": " infinity keeps creeping up everywhere, which, what are your thoughts on kind of bounded", "tokens": [50364, 13202, 5965, 47753, 493, 5315, 11, 597, 11, 437, 366, 428, 4598, 322, 733, 295, 37498, 50796], "temperature": 0.0, "avg_logprob": -0.16027194752412685, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.00288763246499002}, {"id": 749, "seek": 441728, "start": 4425.92, "end": 4431.92, "text": " rationality and sort of the nature of our existence and intelligence systems is that we're operating", "tokens": [50796, 15090, 507, 293, 1333, 295, 264, 3687, 295, 527, 9123, 293, 7599, 3652, 307, 300, 321, 434, 7447, 51096], "temperature": 0.0, "avg_logprob": -0.16027194752412685, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.00288763246499002}, {"id": 750, "seek": 441728, "start": 4431.92, "end": 4438.719999999999, "text": " always under constraints, under, you know, limited time, limited resources. How does that, how do", "tokens": [51096, 1009, 833, 18491, 11, 833, 11, 291, 458, 11, 5567, 565, 11, 5567, 3593, 13, 1012, 775, 300, 11, 577, 360, 51436], "temperature": 0.0, "avg_logprob": -0.16027194752412685, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.00288763246499002}, {"id": 751, "seek": 441728, "start": 4438.719999999999, "end": 4445.04, "text": " you think about that within the IXE framework, within trying to create an AGI system that operates", "tokens": [51436, 291, 519, 466, 300, 1951, 264, 49497, 36, 8388, 11, 1951, 1382, 281, 1884, 364, 316, 26252, 1185, 300, 22577, 51752], "temperature": 0.0, "avg_logprob": -0.16027194752412685, "compression_ratio": 1.63135593220339, "no_speech_prob": 0.00288763246499002}, {"id": 752, "seek": 444504, "start": 4445.04, "end": 4450.0, "text": " under these constraints? Yeah, that is one of the criticisms about IXE that it ignores", "tokens": [50364, 833, 613, 18491, 30, 865, 11, 300, 307, 472, 295, 264, 48519, 466, 49497, 36, 300, 309, 5335, 2706, 50612], "temperature": 0.0, "avg_logprob": -0.11949616335750965, "compression_ratio": 1.7615062761506277, "no_speech_prob": 0.000709414598532021}, {"id": 753, "seek": 444504, "start": 4450.0, "end": 4456.16, "text": " computational completely. And some people believe that intelligence is inherently tied to what's", "tokens": [50612, 28270, 2584, 13, 400, 512, 561, 1697, 300, 7599, 307, 27993, 9601, 281, 437, 311, 50920], "temperature": 0.0, "avg_logprob": -0.11949616335750965, "compression_ratio": 1.7615062761506277, "no_speech_prob": 0.000709414598532021}, {"id": 754, "seek": 444504, "start": 4457.04, "end": 4461.6, "text": " bounded resources. What do you think on this one point? Do you think it's,", "tokens": [50964, 37498, 3593, 13, 708, 360, 291, 519, 322, 341, 472, 935, 30, 1144, 291, 519, 309, 311, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11949616335750965, "compression_ratio": 1.7615062761506277, "no_speech_prob": 0.000709414598532021}, {"id": 755, "seek": 444504, "start": 4462.4, "end": 4465.28, "text": " do you think the bounded resources are fundamental to intelligence?", "tokens": [51232, 360, 291, 519, 264, 37498, 3593, 366, 8088, 281, 7599, 30, 51376], "temperature": 0.0, "avg_logprob": -0.11949616335750965, "compression_ratio": 1.7615062761506277, "no_speech_prob": 0.000709414598532021}, {"id": 756, "seek": 444504, "start": 4467.76, "end": 4474.56, "text": " I would say that an intelligence notion which ignores computational limits is extremely useful", "tokens": [51500, 286, 576, 584, 300, 364, 7599, 10710, 597, 5335, 2706, 28270, 10406, 307, 4664, 4420, 51840], "temperature": 0.0, "avg_logprob": -0.11949616335750965, "compression_ratio": 1.7615062761506277, "no_speech_prob": 0.000709414598532021}, {"id": 757, "seek": 447504, "start": 4475.44, "end": 4480.56, "text": " a good intelligence notion, which includes these resources would be even more useful,", "tokens": [50384, 257, 665, 7599, 10710, 11, 597, 5974, 613, 3593, 576, 312, 754, 544, 4420, 11, 50640], "temperature": 0.0, "avg_logprob": -0.09977818443661644, "compression_ratio": 1.6415770609318996, "no_speech_prob": 0.00015841913409531116}, {"id": 758, "seek": 447504, "start": 4480.56, "end": 4487.5199999999995, "text": " but we don't have that yet. And so look at other fields outside of computer science,", "tokens": [50640, 457, 321, 500, 380, 362, 300, 1939, 13, 400, 370, 574, 412, 661, 7909, 2380, 295, 3820, 3497, 11, 50988], "temperature": 0.0, "avg_logprob": -0.09977818443661644, "compression_ratio": 1.6415770609318996, "no_speech_prob": 0.00015841913409531116}, {"id": 759, "seek": 447504, "start": 4488.4, "end": 4494.8, "text": " computational aspects never play a fundamental role. You develop biological models for cells,", "tokens": [51032, 28270, 7270, 1128, 862, 257, 8088, 3090, 13, 509, 1499, 13910, 5245, 337, 5438, 11, 51352], "temperature": 0.0, "avg_logprob": -0.09977818443661644, "compression_ratio": 1.6415770609318996, "no_speech_prob": 0.00015841913409531116}, {"id": 760, "seek": 447504, "start": 4494.8, "end": 4499.12, "text": " something in physics, these theories, I mean, become more and more crazy and harder and harder", "tokens": [51352, 746, 294, 10649, 11, 613, 13667, 11, 286, 914, 11, 1813, 544, 293, 544, 3219, 293, 6081, 293, 6081, 51568], "temperature": 0.0, "avg_logprob": -0.09977818443661644, "compression_ratio": 1.6415770609318996, "no_speech_prob": 0.00015841913409531116}, {"id": 761, "seek": 447504, "start": 4499.12, "end": 4503.5199999999995, "text": " to compute. Well, in the end, of course, we need to do something with this model, but there's more", "tokens": [51568, 281, 14722, 13, 1042, 11, 294, 264, 917, 11, 295, 1164, 11, 321, 643, 281, 360, 746, 365, 341, 2316, 11, 457, 456, 311, 544, 51788], "temperature": 0.0, "avg_logprob": -0.09977818443661644, "compression_ratio": 1.6415770609318996, "no_speech_prob": 0.00015841913409531116}, {"id": 762, "seek": 450352, "start": 4503.6, "end": 4510.400000000001, "text": " nuisance than a feature. And I'm sometimes wondering if artificial intelligence would not", "tokens": [50368, 3822, 46852, 813, 257, 4111, 13, 400, 286, 478, 2171, 6359, 498, 11677, 7599, 576, 406, 50708], "temperature": 0.0, "avg_logprob": -0.07689576678805882, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.0009693749598227441}, {"id": 763, "seek": 450352, "start": 4510.400000000001, "end": 4515.040000000001, "text": " sit in a computer science department, but in a philosophy department, then this computational", "tokens": [50708, 1394, 294, 257, 3820, 3497, 5882, 11, 457, 294, 257, 10675, 5882, 11, 550, 341, 28270, 50940], "temperature": 0.0, "avg_logprob": -0.07689576678805882, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.0009693749598227441}, {"id": 764, "seek": 450352, "start": 4515.040000000001, "end": 4520.0, "text": " focus would be probably significantly less. I mean, think about the induction problem is more", "tokens": [50940, 1879, 576, 312, 1391, 10591, 1570, 13, 286, 914, 11, 519, 466, 264, 33371, 1154, 307, 544, 51188], "temperature": 0.0, "avg_logprob": -0.07689576678805882, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.0009693749598227441}, {"id": 765, "seek": 450352, "start": 4520.0, "end": 4525.040000000001, "text": " in the philosophy department. There's virtually no paper who cares about, you know, how long it", "tokens": [51188, 294, 264, 10675, 5882, 13, 821, 311, 14103, 572, 3035, 567, 12310, 466, 11, 291, 458, 11, 577, 938, 309, 51440], "temperature": 0.0, "avg_logprob": -0.07689576678805882, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.0009693749598227441}, {"id": 766, "seek": 450352, "start": 4525.040000000001, "end": 4530.4800000000005, "text": " takes to compute the answer that is completely secondary. Of course, once we have figured out", "tokens": [51440, 2516, 281, 14722, 264, 1867, 300, 307, 2584, 11396, 13, 2720, 1164, 11, 1564, 321, 362, 8932, 484, 51712], "temperature": 0.0, "avg_logprob": -0.07689576678805882, "compression_ratio": 1.6738351254480286, "no_speech_prob": 0.0009693749598227441}, {"id": 767, "seek": 453048, "start": 4530.48, "end": 4536.08, "text": " the first problem, so intelligence without computational resources, then", "tokens": [50364, 264, 700, 1154, 11, 370, 7599, 1553, 28270, 3593, 11, 550, 50644], "temperature": 0.0, "avg_logprob": -0.11780177077201948, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.00028236553771421313}, {"id": 768, "seek": 453048, "start": 4537.36, "end": 4542.32, "text": " the next and very good question is, could we improve it by including computational resources,", "tokens": [50708, 264, 958, 293, 588, 665, 1168, 307, 11, 727, 321, 3470, 309, 538, 3009, 28270, 3593, 11, 50956], "temperature": 0.0, "avg_logprob": -0.11780177077201948, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.00028236553771421313}, {"id": 769, "seek": 453048, "start": 4542.32, "end": 4547.599999999999, "text": " but nobody was able to do that so far in an even halfway satisfactory manner?", "tokens": [50956, 457, 5079, 390, 1075, 281, 360, 300, 370, 1400, 294, 364, 754, 15461, 48614, 9060, 30, 51220], "temperature": 0.0, "avg_logprob": -0.11780177077201948, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.00028236553771421313}, {"id": 770, "seek": 453048, "start": 4549.04, "end": 4553.679999999999, "text": " I like that that's in the long run, the right department to belong to is philosophy.", "tokens": [51292, 286, 411, 300, 300, 311, 294, 264, 938, 1190, 11, 264, 558, 5882, 281, 5784, 281, 307, 10675, 13, 51524], "temperature": 0.0, "avg_logprob": -0.11780177077201948, "compression_ratio": 1.5893719806763285, "no_speech_prob": 0.00028236553771421313}, {"id": 771, "seek": 455368, "start": 4554.64, "end": 4561.84, "text": " That's actually quite a deep idea of or even to at least to think about big picture", "tokens": [50412, 663, 311, 767, 1596, 257, 2452, 1558, 295, 420, 754, 281, 412, 1935, 281, 519, 466, 955, 3036, 50772], "temperature": 0.0, "avg_logprob": -0.19753385725475492, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.004006512463092804}, {"id": 772, "seek": 455368, "start": 4561.84, "end": 4567.4400000000005, "text": " philosophical questions, big picture questions, even in the computer science department. But", "tokens": [50772, 25066, 1651, 11, 955, 3036, 1651, 11, 754, 294, 264, 3820, 3497, 5882, 13, 583, 51052], "temperature": 0.0, "avg_logprob": -0.19753385725475492, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.004006512463092804}, {"id": 773, "seek": 455368, "start": 4567.4400000000005, "end": 4573.84, "text": " you've mentioned approximation, sort of, there's a lot of infinity, a lot of huge resources needed.", "tokens": [51052, 291, 600, 2835, 28023, 11, 1333, 295, 11, 456, 311, 257, 688, 295, 13202, 11, 257, 688, 295, 2603, 3593, 2978, 13, 51372], "temperature": 0.0, "avg_logprob": -0.19753385725475492, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.004006512463092804}, {"id": 774, "seek": 455368, "start": 4573.84, "end": 4578.96, "text": " Are there approximations to IHC that within the IHC framework that are useful?", "tokens": [51372, 2014, 456, 8542, 763, 281, 286, 39, 34, 300, 1951, 264, 286, 39, 34, 8388, 300, 366, 4420, 30, 51628], "temperature": 0.0, "avg_logprob": -0.19753385725475492, "compression_ratio": 1.6063348416289593, "no_speech_prob": 0.004006512463092804}, {"id": 775, "seek": 457896, "start": 4579.68, "end": 4587.84, "text": " Yeah, we have to develop a couple of approximations. And what we do there is that the", "tokens": [50400, 865, 11, 321, 362, 281, 1499, 257, 1916, 295, 8542, 763, 13, 400, 437, 321, 360, 456, 307, 300, 264, 50808], "temperature": 0.0, "avg_logprob": -0.12504719004911535, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0008037652587518096}, {"id": 776, "seek": 457896, "start": 4587.84, "end": 4593.52, "text": " Solomov induction part, which was, you know, find the shortest program describing your data,", "tokens": [50808, 7026, 298, 5179, 33371, 644, 11, 597, 390, 11, 291, 458, 11, 915, 264, 31875, 1461, 16141, 428, 1412, 11, 51092], "temperature": 0.0, "avg_logprob": -0.12504719004911535, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0008037652587518096}, {"id": 777, "seek": 457896, "start": 4593.52, "end": 4598.88, "text": " which just replaces by standard data compressors, right? And the better compressors get,", "tokens": [51092, 597, 445, 46734, 538, 3832, 1412, 14778, 830, 11, 558, 30, 400, 264, 1101, 14778, 830, 483, 11, 51360], "temperature": 0.0, "avg_logprob": -0.12504719004911535, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0008037652587518096}, {"id": 778, "seek": 457896, "start": 4598.88, "end": 4603.52, "text": " you know, the better this part will become. We focus on a particular compressor called", "tokens": [51360, 291, 458, 11, 264, 1101, 341, 644, 486, 1813, 13, 492, 1879, 322, 257, 1729, 28765, 1219, 51592], "temperature": 0.0, "avg_logprob": -0.12504719004911535, "compression_ratio": 1.631336405529954, "no_speech_prob": 0.0008037652587518096}, {"id": 779, "seek": 460352, "start": 4603.52, "end": 4609.6, "text": " Context Rewaiting, which is pretty amazing, not so well known. It has beautiful theoretical", "tokens": [50364, 4839, 3828, 497, 1023, 1001, 278, 11, 597, 307, 1238, 2243, 11, 406, 370, 731, 2570, 13, 467, 575, 2238, 20864, 50668], "temperature": 0.0, "avg_logprob": -0.16295104026794432, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0013456909218803048}, {"id": 780, "seek": 460352, "start": 4609.6, "end": 4613.84, "text": " properties also works reasonably well in practice. So we use that for the approximation", "tokens": [50668, 7221, 611, 1985, 23551, 731, 294, 3124, 13, 407, 321, 764, 300, 337, 264, 28023, 50880], "temperature": 0.0, "avg_logprob": -0.16295104026794432, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0013456909218803048}, {"id": 781, "seek": 460352, "start": 4613.84, "end": 4620.56, "text": " of the induction and the learning and the prediction part. And for the planning part,", "tokens": [50880, 295, 264, 33371, 293, 264, 2539, 293, 264, 17630, 644, 13, 400, 337, 264, 5038, 644, 11, 51216], "temperature": 0.0, "avg_logprob": -0.16295104026794432, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0013456909218803048}, {"id": 782, "seek": 460352, "start": 4621.6, "end": 4628.0, "text": " we essentially just took the ideas from a computer go from 2006. It was Java,", "tokens": [51268, 321, 4476, 445, 1890, 264, 3487, 490, 257, 3820, 352, 490, 14062, 13, 467, 390, 10745, 11, 51588], "temperature": 0.0, "avg_logprob": -0.16295104026794432, "compression_ratio": 1.5520361990950227, "no_speech_prob": 0.0013456909218803048}, {"id": 783, "seek": 462800, "start": 4628.0, "end": 4635.76, "text": " Cyprus, Bari, also now a DeepMind, who developed the so called UCT algorithm, upper confidence", "tokens": [50364, 10295, 49074, 11, 363, 3504, 11, 611, 586, 257, 14895, 44, 471, 11, 567, 4743, 264, 370, 1219, 624, 10259, 9284, 11, 6597, 6687, 50752], "temperature": 0.0, "avg_logprob": -0.19243115186691284, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.0010000140173360705}, {"id": 784, "seek": 462800, "start": 4635.76, "end": 4640.4, "text": " bound for trees algorithm, on top of the Monte Carlo tree search. So we approximate this planning", "tokens": [50752, 5472, 337, 5852, 9284, 11, 322, 1192, 295, 264, 38105, 45112, 4230, 3164, 13, 407, 321, 30874, 341, 5038, 50984], "temperature": 0.0, "avg_logprob": -0.19243115186691284, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.0010000140173360705}, {"id": 785, "seek": 462800, "start": 4640.4, "end": 4652.24, "text": " part by sampling. And it's successful on some small toy problems. We don't want to lose the", "tokens": [50984, 644, 538, 21179, 13, 400, 309, 311, 4406, 322, 512, 1359, 12058, 2740, 13, 492, 500, 380, 528, 281, 3624, 264, 51576], "temperature": 0.0, "avg_logprob": -0.19243115186691284, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.0010000140173360705}, {"id": 786, "seek": 462800, "start": 4652.24, "end": 4655.84, "text": " generality, right? And that's sort of the handicap, right? If you want to be general,", "tokens": [51576, 1337, 1860, 11, 558, 30, 400, 300, 311, 1333, 295, 264, 45975, 11, 558, 30, 759, 291, 528, 281, 312, 2674, 11, 51756], "temperature": 0.0, "avg_logprob": -0.19243115186691284, "compression_ratio": 1.5481171548117154, "no_speech_prob": 0.0010000140173360705}, {"id": 787, "seek": 465584, "start": 4656.08, "end": 4661.84, "text": " you have to give up something. So but this single agent was able to play, you know, small games", "tokens": [50376, 291, 362, 281, 976, 493, 746, 13, 407, 457, 341, 2167, 9461, 390, 1075, 281, 862, 11, 291, 458, 11, 1359, 2813, 50664], "temperature": 0.0, "avg_logprob": -0.25632752094072164, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0031221879180520773}, {"id": 788, "seek": 465584, "start": 4661.84, "end": 4671.92, "text": " like Coon poker and tic-tac-toe and, and even Pac-Man. And the same architecture, no change.", "tokens": [50664, 411, 3066, 266, 36863, 293, 256, 299, 12, 83, 326, 12, 1353, 68, 293, 11, 293, 754, 10702, 12, 6652, 13, 400, 264, 912, 9482, 11, 572, 1319, 13, 51168], "temperature": 0.0, "avg_logprob": -0.25632752094072164, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0031221879180520773}, {"id": 789, "seek": 465584, "start": 4671.92, "end": 4677.52, "text": " The agent doesn't know the rules of the game, really nothing at all by self or by a player", "tokens": [51168, 440, 9461, 1177, 380, 458, 264, 4474, 295, 264, 1216, 11, 534, 1825, 412, 439, 538, 2698, 420, 538, 257, 4256, 51448], "temperature": 0.0, "avg_logprob": -0.25632752094072164, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0031221879180520773}, {"id": 790, "seek": 465584, "start": 4677.52, "end": 4683.68, "text": " with these environments. So you're gonna Schmidt, who were proposed something called", "tokens": [51448, 365, 613, 12388, 13, 407, 291, 434, 799, 42621, 11, 567, 645, 10348, 746, 1219, 51756], "temperature": 0.0, "avg_logprob": -0.25632752094072164, "compression_ratio": 1.548936170212766, "no_speech_prob": 0.0031221879180520773}, {"id": 791, "seek": 468368, "start": 4683.68, "end": 4688.16, "text": " Ghetto Machines, which is a self improving program that rewrites its own code.", "tokens": [50364, 460, 40556, 12089, 1652, 11, 597, 307, 257, 2698, 11470, 1461, 300, 319, 86, 30931, 1080, 1065, 3089, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1853162325345553, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.001187566784210503}, {"id": 792, "seek": 468368, "start": 4690.8, "end": 4695.04, "text": " Sort of mathematically or philosophically, what's the relationship in your eyes,", "tokens": [50720, 26149, 295, 44003, 420, 14529, 984, 11, 437, 311, 264, 2480, 294, 428, 2575, 11, 50932], "temperature": 0.0, "avg_logprob": -0.1853162325345553, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.001187566784210503}, {"id": 793, "seek": 468368, "start": 4695.04, "end": 4698.320000000001, "text": " if you're familiar with it between AXI and the Ghetto Machines?", "tokens": [50932, 498, 291, 434, 4963, 365, 309, 1296, 316, 55, 40, 293, 264, 460, 40556, 12089, 1652, 30, 51096], "temperature": 0.0, "avg_logprob": -0.1853162325345553, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.001187566784210503}, {"id": 794, "seek": 468368, "start": 4698.320000000001, "end": 4701.12, "text": " Yeah, familiar with it. He developed it while I was in his lab.", "tokens": [51096, 865, 11, 4963, 365, 309, 13, 634, 4743, 309, 1339, 286, 390, 294, 702, 2715, 13, 51236], "temperature": 0.0, "avg_logprob": -0.1853162325345553, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.001187566784210503}, {"id": 795, "seek": 468368, "start": 4702.16, "end": 4710.0, "text": " Yeah. So the Ghetto Machine, explain briefly. You give it a task. It could be a simple task as,", "tokens": [51288, 865, 13, 407, 264, 460, 40556, 22155, 11, 2903, 10515, 13, 509, 976, 309, 257, 5633, 13, 467, 727, 312, 257, 2199, 5633, 382, 11, 51680], "temperature": 0.0, "avg_logprob": -0.1853162325345553, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.001187566784210503}, {"id": 796, "seek": 471000, "start": 4710.0, "end": 4713.92, "text": " you know, finding prime factors in numbers, right? You can formally write it down. There's", "tokens": [50364, 291, 458, 11, 5006, 5835, 6771, 294, 3547, 11, 558, 30, 509, 393, 25983, 2464, 309, 760, 13, 821, 311, 50560], "temperature": 0.0, "avg_logprob": -0.136987357304014, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0028440302703529596}, {"id": 797, "seek": 471000, "start": 4713.92, "end": 4719.2, "text": " a very slow algorithm to do that. Just all try all the factors. Yeah. Or play chess, right?", "tokens": [50560, 257, 588, 2964, 9284, 281, 360, 300, 13, 1449, 439, 853, 439, 264, 6771, 13, 865, 13, 1610, 862, 24122, 11, 558, 30, 50824], "temperature": 0.0, "avg_logprob": -0.136987357304014, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0028440302703529596}, {"id": 798, "seek": 471000, "start": 4719.2, "end": 4723.92, "text": " Optimally, you write the algorithm to minimax to the end of the game. So you write down what the", "tokens": [50824, 35013, 379, 11, 291, 2464, 264, 9284, 281, 4464, 2797, 281, 264, 917, 295, 264, 1216, 13, 407, 291, 2464, 760, 437, 264, 51060], "temperature": 0.0, "avg_logprob": -0.136987357304014, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0028440302703529596}, {"id": 799, "seek": 471000, "start": 4723.92, "end": 4729.84, "text": " Ghetto Machine should do. Then it will take part of its resources to run this program.", "tokens": [51060, 460, 40556, 22155, 820, 360, 13, 1396, 309, 486, 747, 644, 295, 1080, 3593, 281, 1190, 341, 1461, 13, 51356], "temperature": 0.0, "avg_logprob": -0.136987357304014, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0028440302703529596}, {"id": 800, "seek": 471000, "start": 4730.64, "end": 4736.88, "text": " And other part of the sources to improve this program. And when it finds an improved version,", "tokens": [51396, 400, 661, 644, 295, 264, 7139, 281, 3470, 341, 1461, 13, 400, 562, 309, 10704, 364, 9689, 3037, 11, 51708], "temperature": 0.0, "avg_logprob": -0.136987357304014, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.0028440302703529596}, {"id": 801, "seek": 473688, "start": 4736.88, "end": 4744.0, "text": " which provably computes the same answer. So that's the key part. It needs to prove by itself", "tokens": [50364, 597, 1439, 1188, 715, 1819, 264, 912, 1867, 13, 407, 300, 311, 264, 2141, 644, 13, 467, 2203, 281, 7081, 538, 2564, 50720], "temperature": 0.0, "avg_logprob": -0.0953187083338832, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.00048762999358586967}, {"id": 802, "seek": 473688, "start": 4744.0, "end": 4750.0, "text": " that this change of program still satisfies the original specification. And if it does so,", "tokens": [50720, 300, 341, 1319, 295, 1461, 920, 44271, 264, 3380, 31256, 13, 400, 498, 309, 775, 370, 11, 51020], "temperature": 0.0, "avg_logprob": -0.0953187083338832, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.00048762999358586967}, {"id": 803, "seek": 473688, "start": 4750.0, "end": 4754.16, "text": " then it replaces the original program by the improved program. And by definition,", "tokens": [51020, 550, 309, 46734, 264, 3380, 1461, 538, 264, 9689, 1461, 13, 400, 538, 7123, 11, 51228], "temperature": 0.0, "avg_logprob": -0.0953187083338832, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.00048762999358586967}, {"id": 804, "seek": 473688, "start": 4754.16, "end": 4759.12, "text": " it does the same job, but just faster. Okay. And then, you know, it proves over it and over it.", "tokens": [51228, 309, 775, 264, 912, 1691, 11, 457, 445, 4663, 13, 1033, 13, 400, 550, 11, 291, 458, 11, 309, 25019, 670, 309, 293, 670, 309, 13, 51476], "temperature": 0.0, "avg_logprob": -0.0953187083338832, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.00048762999358586967}, {"id": 805, "seek": 473688, "start": 4759.12, "end": 4766.64, "text": " And it's developed in a way that all parts of this Ghetto Machine can self improve.", "tokens": [51476, 400, 309, 311, 4743, 294, 257, 636, 300, 439, 3166, 295, 341, 460, 40556, 22155, 393, 2698, 3470, 13, 51852], "temperature": 0.0, "avg_logprob": -0.0953187083338832, "compression_ratio": 1.7248062015503876, "no_speech_prob": 0.00048762999358586967}, {"id": 806, "seek": 476664, "start": 4766.64, "end": 4773.84, "text": " But it stays provably consistent with the original specification. So from this perspective,", "tokens": [50364, 583, 309, 10834, 1439, 1188, 8398, 365, 264, 3380, 31256, 13, 407, 490, 341, 4585, 11, 50724], "temperature": 0.0, "avg_logprob": -0.1396175538650667, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0004304047906771302}, {"id": 807, "seek": 476664, "start": 4773.84, "end": 4779.4400000000005, "text": " it has nothing to do with IxE. But if you would now put IxE as the starting axioms in,", "tokens": [50724, 309, 575, 1825, 281, 360, 365, 286, 87, 36, 13, 583, 498, 291, 576, 586, 829, 286, 87, 36, 382, 264, 2891, 6360, 72, 4785, 294, 11, 51004], "temperature": 0.0, "avg_logprob": -0.1396175538650667, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0004304047906771302}, {"id": 808, "seek": 476664, "start": 4780.56, "end": 4786.320000000001, "text": " it would run IxE. But, you know, that takes forever. But then if it finds a provable", "tokens": [51060, 309, 576, 1190, 286, 87, 36, 13, 583, 11, 291, 458, 11, 300, 2516, 5680, 13, 583, 550, 498, 309, 10704, 257, 1439, 712, 51348], "temperature": 0.0, "avg_logprob": -0.1396175538650667, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0004304047906771302}, {"id": 809, "seek": 476664, "start": 4787.200000000001, "end": 4792.160000000001, "text": " speed up of IxE, it would replace it by this and this and this and maybe eventually it comes", "tokens": [51392, 3073, 493, 295, 286, 87, 36, 11, 309, 576, 7406, 309, 538, 341, 293, 341, 293, 341, 293, 1310, 4728, 309, 1487, 51640], "temperature": 0.0, "avg_logprob": -0.1396175538650667, "compression_ratio": 1.655813953488372, "no_speech_prob": 0.0004304047906771302}, {"id": 810, "seek": 479216, "start": 4792.16, "end": 4798.96, "text": " up with a model which is still the IxE model. It cannot be, I mean, just for the knowledgeable", "tokens": [50364, 493, 365, 257, 2316, 597, 307, 920, 264, 286, 87, 36, 2316, 13, 467, 2644, 312, 11, 286, 914, 11, 445, 337, 264, 33800, 50704], "temperature": 0.0, "avg_logprob": -0.15684507739159367, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0029337897431105375}, {"id": 811, "seek": 479216, "start": 4798.96, "end": 4804.4, "text": " reader, IxE is incomputable. And that can prove that therefore there cannot be a computable", "tokens": [50704, 15149, 11, 286, 87, 36, 307, 14036, 2582, 712, 13, 400, 300, 393, 7081, 300, 4412, 456, 2644, 312, 257, 2807, 712, 50976], "temperature": 0.0, "avg_logprob": -0.15684507739159367, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0029337897431105375}, {"id": 812, "seek": 479216, "start": 4805.36, "end": 4811.12, "text": " exact algorithm of computers. There needs to be some approximations. And this is not dealt", "tokens": [51024, 1900, 9284, 295, 10807, 13, 821, 2203, 281, 312, 512, 8542, 763, 13, 400, 341, 307, 406, 15991, 51312], "temperature": 0.0, "avg_logprob": -0.15684507739159367, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0029337897431105375}, {"id": 813, "seek": 479216, "start": 4811.12, "end": 4814.4, "text": " with the Ghetto Machine. So you have to do something about it. But there's the IxE TL model,", "tokens": [51312, 365, 264, 460, 40556, 22155, 13, 407, 291, 362, 281, 360, 746, 466, 309, 13, 583, 456, 311, 264, 286, 87, 36, 40277, 2316, 11, 51476], "temperature": 0.0, "avg_logprob": -0.15684507739159367, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0029337897431105375}, {"id": 814, "seek": 479216, "start": 4814.4, "end": 4819.12, "text": " which is finally computable, which we could put in. Which part of IxE is non computable?", "tokens": [51476, 597, 307, 2721, 2807, 712, 11, 597, 321, 727, 829, 294, 13, 3013, 644, 295, 286, 87, 36, 307, 2107, 2807, 712, 30, 51712], "temperature": 0.0, "avg_logprob": -0.15684507739159367, "compression_ratio": 1.7320754716981133, "no_speech_prob": 0.0029337897431105375}, {"id": 815, "seek": 481912, "start": 4819.12, "end": 4822.16, "text": " The Solomonov induction part. The induction. Okay, so.", "tokens": [50364, 440, 7026, 24488, 5179, 33371, 644, 13, 440, 33371, 13, 1033, 11, 370, 13, 50516], "temperature": 0.0, "avg_logprob": -0.14315189712349025, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013663378776982427}, {"id": 816, "seek": 481912, "start": 4822.16, "end": 4829.12, "text": " But there's ways of getting computable approximations of the IxE model. So then it's at least", "tokens": [50516, 583, 456, 311, 2098, 295, 1242, 2807, 712, 8542, 763, 295, 264, 286, 87, 36, 2316, 13, 407, 550, 309, 311, 412, 1935, 50864], "temperature": 0.0, "avg_logprob": -0.14315189712349025, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013663378776982427}, {"id": 817, "seek": 481912, "start": 4829.12, "end": 4834.8, "text": " computable. It is still way beyond any resources anybody will ever have. But then the Ghetto Machine", "tokens": [50864, 2807, 712, 13, 467, 307, 920, 636, 4399, 604, 3593, 4472, 486, 1562, 362, 13, 583, 550, 264, 460, 40556, 22155, 51148], "temperature": 0.0, "avg_logprob": -0.14315189712349025, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013663378776982427}, {"id": 818, "seek": 481912, "start": 4834.8, "end": 4841.28, "text": " could sort of improve it further and further in an exact way. So is this theoretically possible that", "tokens": [51148, 727, 1333, 295, 3470, 309, 3052, 293, 3052, 294, 364, 1900, 636, 13, 407, 307, 341, 29400, 1944, 300, 51472], "temperature": 0.0, "avg_logprob": -0.14315189712349025, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013663378776982427}, {"id": 819, "seek": 484128, "start": 4842.16, "end": 4850.88, "text": " the Ghetto Machine process could improve? Isn't IxE already optimal?", "tokens": [50408, 264, 460, 40556, 22155, 1399, 727, 3470, 30, 6998, 380, 286, 87, 36, 1217, 16252, 30, 50844], "temperature": 0.0, "avg_logprob": -0.10851278759184338, "compression_ratio": 1.4316939890710383, "no_speech_prob": 0.011864938773214817}, {"id": 820, "seek": 484128, "start": 4851.759999999999, "end": 4860.639999999999, "text": " It is optimal in terms of the reward collected over its interaction cycles. But it takes infinite", "tokens": [50888, 467, 307, 16252, 294, 2115, 295, 264, 7782, 11087, 670, 1080, 9285, 17796, 13, 583, 309, 2516, 13785, 51332], "temperature": 0.0, "avg_logprob": -0.10851278759184338, "compression_ratio": 1.4316939890710383, "no_speech_prob": 0.011864938773214817}, {"id": 821, "seek": 484128, "start": 4860.639999999999, "end": 4868.08, "text": " time to produce one action. And the world continues whether you want it or not. So the model is", "tokens": [51332, 565, 281, 5258, 472, 3069, 13, 400, 264, 1002, 6515, 1968, 291, 528, 309, 420, 406, 13, 407, 264, 2316, 307, 51704], "temperature": 0.0, "avg_logprob": -0.10851278759184338, "compression_ratio": 1.4316939890710383, "no_speech_prob": 0.011864938773214817}, {"id": 822, "seek": 486808, "start": 4868.08, "end": 4872.8, "text": " assuming it had an oracle, which solved this problem, and then in the next 100 milliseconds", "tokens": [50364, 11926, 309, 632, 364, 420, 7041, 11, 597, 13041, 341, 1154, 11, 293, 550, 294, 264, 958, 2319, 34184, 50600], "temperature": 0.0, "avg_logprob": -0.16856665081448025, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.0011685201898217201}, {"id": 823, "seek": 486808, "start": 4872.8, "end": 4879.28, "text": " or the reaction time you need gives the answer, then IxE is optimal. It's optimal in sense of", "tokens": [50600, 420, 264, 5480, 565, 291, 643, 2709, 264, 1867, 11, 550, 286, 87, 36, 307, 16252, 13, 467, 311, 16252, 294, 2020, 295, 50924], "temperature": 0.0, "avg_logprob": -0.16856665081448025, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.0011685201898217201}, {"id": 824, "seek": 486808, "start": 4879.28, "end": 4885.28, "text": " data, also from learning efficiency and data efficiency, but not in terms of computation", "tokens": [50924, 1412, 11, 611, 490, 2539, 10493, 293, 1412, 10493, 11, 457, 406, 294, 2115, 295, 24903, 51224], "temperature": 0.0, "avg_logprob": -0.16856665081448025, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.0011685201898217201}, {"id": 825, "seek": 486808, "start": 4885.28, "end": 4890.16, "text": " time. And then the Ghetto Machine in theory, but probably not provably could make it go faster.", "tokens": [51224, 565, 13, 400, 550, 264, 460, 40556, 22155, 294, 5261, 11, 457, 1391, 406, 1439, 1188, 727, 652, 309, 352, 4663, 13, 51468], "temperature": 0.0, "avg_logprob": -0.16856665081448025, "compression_ratio": 1.5948275862068966, "no_speech_prob": 0.0011685201898217201}, {"id": 826, "seek": 489016, "start": 4890.88, "end": 4899.28, "text": " Yes. Okay. Interesting. Those two components are super interesting. The perfect intelligence", "tokens": [50400, 1079, 13, 1033, 13, 14711, 13, 3950, 732, 6677, 366, 1687, 1880, 13, 440, 2176, 7599, 50820], "temperature": 0.0, "avg_logprob": -0.22585484475800485, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01384185254573822}, {"id": 827, "seek": 489016, "start": 4899.28, "end": 4907.92, "text": " combined with self-improvement. Sort of provable self-improvement in sense you're always getting", "tokens": [50820, 9354, 365, 2698, 12, 332, 46955, 518, 13, 26149, 295, 1439, 712, 2698, 12, 332, 46955, 518, 294, 2020, 291, 434, 1009, 1242, 51252], "temperature": 0.0, "avg_logprob": -0.22585484475800485, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01384185254573822}, {"id": 828, "seek": 489016, "start": 4907.92, "end": 4913.76, "text": " the correct answer and you're improving. Beautiful ideas. Okay, so you've also mentioned that", "tokens": [51252, 264, 3006, 1867, 293, 291, 434, 11470, 13, 14724, 3487, 13, 1033, 11, 370, 291, 600, 611, 2835, 300, 51544], "temperature": 0.0, "avg_logprob": -0.22585484475800485, "compression_ratio": 1.554945054945055, "no_speech_prob": 0.01384185254573822}, {"id": 829, "seek": 491376, "start": 4914.4800000000005, "end": 4921.360000000001, "text": " different kinds of things in the chase of solving this reward, sort of optimizing for the goal,", "tokens": [50400, 819, 3685, 295, 721, 294, 264, 15359, 295, 12606, 341, 7782, 11, 1333, 295, 40425, 337, 264, 3387, 11, 50744], "temperature": 0.0, "avg_logprob": -0.1375373484014155, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.083714559674263}, {"id": 830, "seek": 491376, "start": 4923.04, "end": 4928.56, "text": " interesting human things could emerge. So is there a place for consciousness within IxE?", "tokens": [50828, 1880, 1952, 721, 727, 21511, 13, 407, 307, 456, 257, 1081, 337, 10081, 1951, 286, 87, 36, 30, 51104], "temperature": 0.0, "avg_logprob": -0.1375373484014155, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.083714559674263}, {"id": 831, "seek": 491376, "start": 4930.8, "end": 4937.360000000001, "text": " Where does, maybe you can comment, because I suppose we humans are just another instantiation", "tokens": [51216, 2305, 775, 11, 1310, 291, 393, 2871, 11, 570, 286, 7297, 321, 6255, 366, 445, 1071, 9836, 6642, 51544], "temperature": 0.0, "avg_logprob": -0.1375373484014155, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.083714559674263}, {"id": 832, "seek": 491376, "start": 4937.360000000001, "end": 4943.360000000001, "text": " by IxE agents and we seem to have consciousness. You say humans are an instantiation of an IxE agent?", "tokens": [51544, 538, 286, 87, 36, 12554, 293, 321, 1643, 281, 362, 10081, 13, 509, 584, 6255, 366, 364, 9836, 6642, 295, 364, 286, 87, 36, 9461, 30, 51844], "temperature": 0.0, "avg_logprob": -0.1375373484014155, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.083714559674263}, {"id": 833, "seek": 494336, "start": 4943.36, "end": 4948.24, "text": " Yes. Oh, that would be amazing. But I think that's not true even for the smartest and most", "tokens": [50364, 1079, 13, 876, 11, 300, 576, 312, 2243, 13, 583, 286, 519, 300, 311, 406, 2074, 754, 337, 264, 41491, 293, 881, 50608], "temperature": 0.0, "avg_logprob": -0.1135814607757883, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002509311307221651}, {"id": 834, "seek": 494336, "start": 4948.24, "end": 4954.24, "text": " rational humans. I think maybe we are very crude approximations. Interesting. I mean, I tend to", "tokens": [50608, 15090, 6255, 13, 286, 519, 1310, 321, 366, 588, 30796, 8542, 763, 13, 14711, 13, 286, 914, 11, 286, 3928, 281, 50908], "temperature": 0.0, "avg_logprob": -0.1135814607757883, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002509311307221651}, {"id": 835, "seek": 494336, "start": 4954.24, "end": 4963.759999999999, "text": " believe, again, I'm Russian, so I tend to believe our flaws are part of the optimal. So we tend to", "tokens": [50908, 1697, 11, 797, 11, 286, 478, 7220, 11, 370, 286, 3928, 281, 1697, 527, 27108, 366, 644, 295, 264, 16252, 13, 407, 321, 3928, 281, 51384], "temperature": 0.0, "avg_logprob": -0.1135814607757883, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002509311307221651}, {"id": 836, "seek": 494336, "start": 4963.759999999999, "end": 4969.92, "text": " laugh off and criticize our flaws and I tend to think that that's actually close to an optimal", "tokens": [51384, 5801, 766, 293, 31010, 527, 27108, 293, 286, 3928, 281, 519, 300, 300, 311, 767, 1998, 281, 364, 16252, 51692], "temperature": 0.0, "avg_logprob": -0.1135814607757883, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.002509311307221651}, {"id": 837, "seek": 496992, "start": 4969.92, "end": 4974.96, "text": " behavior. Well, some flaws, if you think more carefully about it, are actually not flaws here,", "tokens": [50364, 5223, 13, 1042, 11, 512, 27108, 11, 498, 291, 519, 544, 7500, 466, 309, 11, 366, 767, 406, 27108, 510, 11, 50616], "temperature": 0.0, "avg_logprob": -0.09522934162870367, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.01637442223727703}, {"id": 838, "seek": 496992, "start": 4974.96, "end": 4981.84, "text": " but I think there are still enough flaws. I don't know. It's unclear. As a student of history,", "tokens": [50616, 457, 286, 519, 456, 366, 920, 1547, 27108, 13, 286, 500, 380, 458, 13, 467, 311, 25636, 13, 1018, 257, 3107, 295, 2503, 11, 50960], "temperature": 0.0, "avg_logprob": -0.09522934162870367, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.01637442223727703}, {"id": 839, "seek": 496992, "start": 4981.84, "end": 4988.88, "text": " I think all the suffering that we've endured as a civilization, it's possible that that's the", "tokens": [50960, 286, 519, 439, 264, 7755, 300, 321, 600, 39017, 382, 257, 18036, 11, 309, 311, 1944, 300, 300, 311, 264, 51312], "temperature": 0.0, "avg_logprob": -0.09522934162870367, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.01637442223727703}, {"id": 840, "seek": 496992, "start": 4988.88, "end": 4995.68, "text": " optimal amount of suffering we need to endure to minimize long-term suffering. That's your Russian", "tokens": [51312, 16252, 2372, 295, 7755, 321, 643, 281, 24732, 281, 17522, 938, 12, 7039, 7755, 13, 663, 311, 428, 7220, 51652], "temperature": 0.0, "avg_logprob": -0.09522934162870367, "compression_ratio": 1.61864406779661, "no_speech_prob": 0.01637442223727703}, {"id": 841, "seek": 499568, "start": 4995.76, "end": 5001.76, "text": " background. That's the Russian. Whether humans are or not instantiations of an IxE agent,", "tokens": [50368, 3678, 13, 663, 311, 264, 7220, 13, 8503, 6255, 366, 420, 406, 9836, 72, 763, 295, 364, 286, 87, 36, 9461, 11, 50668], "temperature": 0.0, "avg_logprob": -0.16540901051011198, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.01969362609088421}, {"id": 842, "seek": 499568, "start": 5001.76, "end": 5007.4400000000005, "text": " do you think there's consciousness is something that could emerge in a computational form of", "tokens": [50668, 360, 291, 519, 456, 311, 10081, 307, 746, 300, 727, 21511, 294, 257, 28270, 1254, 295, 50952], "temperature": 0.0, "avg_logprob": -0.16540901051011198, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.01969362609088421}, {"id": 843, "seek": 499568, "start": 5007.4400000000005, "end": 5012.72, "text": " framework like IxE? Let me also ask you a question. Do you think I'm conscious?", "tokens": [50952, 8388, 411, 286, 87, 36, 30, 961, 385, 611, 1029, 291, 257, 1168, 13, 1144, 291, 519, 286, 478, 6648, 30, 51216], "temperature": 0.0, "avg_logprob": -0.16540901051011198, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.01969362609088421}, {"id": 844, "seek": 499568, "start": 5016.72, "end": 5024.16, "text": " That's a good question. That tie is confusing me, but I think so.", "tokens": [51416, 663, 311, 257, 665, 1168, 13, 663, 7582, 307, 13181, 385, 11, 457, 286, 519, 370, 13, 51788], "temperature": 0.0, "avg_logprob": -0.16540901051011198, "compression_ratio": 1.5545023696682465, "no_speech_prob": 0.01969362609088421}, {"id": 845, "seek": 502416, "start": 5024.24, "end": 5026.88, "text": " You think that makes me unconscious because it strangles me?", "tokens": [50368, 509, 519, 300, 1669, 385, 18900, 570, 309, 24404, 904, 385, 30, 50500], "temperature": 0.0, "avg_logprob": -0.15563006977458577, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.0033743574749678373}, {"id": 846, "seek": 502416, "start": 5027.5199999999995, "end": 5031.28, "text": " If an agent were to solve the imitation game posed by Turing, I think that would be", "tokens": [50532, 759, 364, 9461, 645, 281, 5039, 264, 47624, 1216, 31399, 538, 314, 1345, 11, 286, 519, 300, 576, 312, 50720], "temperature": 0.0, "avg_logprob": -0.15563006977458577, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.0033743574749678373}, {"id": 847, "seek": 502416, "start": 5031.28, "end": 5037.44, "text": " dressed similarly to you. Because there's a kind of flamboyant, interesting,", "tokens": [50720, 12386, 14138, 281, 291, 13, 1436, 456, 311, 257, 733, 295, 932, 2173, 939, 394, 11, 1880, 11, 51028], "temperature": 0.0, "avg_logprob": -0.15563006977458577, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.0033743574749678373}, {"id": 848, "seek": 502416, "start": 5038.96, "end": 5045.44, "text": " complex behavior pattern that sells that you're human and you're conscious. But why do you ask?", "tokens": [51104, 3997, 5223, 5102, 300, 20897, 300, 291, 434, 1952, 293, 291, 434, 6648, 13, 583, 983, 360, 291, 1029, 30, 51428], "temperature": 0.0, "avg_logprob": -0.15563006977458577, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.0033743574749678373}, {"id": 849, "seek": 502416, "start": 5046.08, "end": 5047.44, "text": " Was it a yes or was it a no?", "tokens": [51460, 3027, 309, 257, 2086, 420, 390, 309, 257, 572, 30, 51528], "temperature": 0.0, "avg_logprob": -0.15563006977458577, "compression_ratio": 1.5585585585585586, "no_speech_prob": 0.0033743574749678373}, {"id": 850, "seek": 504744, "start": 5047.839999999999, "end": 5052.0, "text": " Yes, I think you're conscious, yes.", "tokens": [50384, 1079, 11, 286, 519, 291, 434, 6648, 11, 2086, 13, 50592], "temperature": 0.0, "avg_logprob": -0.18936274601862982, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.006189290899783373}, {"id": 851, "seek": 504744, "start": 5052.639999999999, "end": 5059.599999999999, "text": " So, and you explain somehow why, but you infer that from my behavior. You can never be sure", "tokens": [50624, 407, 11, 293, 291, 2903, 6063, 983, 11, 457, 291, 13596, 300, 490, 452, 5223, 13, 509, 393, 1128, 312, 988, 50972], "temperature": 0.0, "avg_logprob": -0.18936274601862982, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.006189290899783373}, {"id": 852, "seek": 504744, "start": 5059.599999999999, "end": 5066.719999999999, "text": " about that. And I think the same thing will happen with any intelligent agent we develop", "tokens": [50972, 466, 300, 13, 400, 286, 519, 264, 912, 551, 486, 1051, 365, 604, 13232, 9461, 321, 1499, 51328], "temperature": 0.0, "avg_logprob": -0.18936274601862982, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.006189290899783373}, {"id": 853, "seek": 504744, "start": 5066.719999999999, "end": 5073.2, "text": " if it behaves in a way sufficiently close to humans. Or maybe if not humans, maybe a dog", "tokens": [51328, 498, 309, 36896, 294, 257, 636, 31868, 1998, 281, 6255, 13, 1610, 1310, 498, 406, 6255, 11, 1310, 257, 3000, 51652], "temperature": 0.0, "avg_logprob": -0.18936274601862982, "compression_ratio": 1.4878048780487805, "no_speech_prob": 0.006189290899783373}, {"id": 854, "seek": 507320, "start": 5073.2, "end": 5079.92, "text": " is also sometimes a little bit self-conscious. So, if it behaves in a way where we attribute", "tokens": [50364, 307, 611, 2171, 257, 707, 857, 2698, 12, 19877, 13, 407, 11, 498, 309, 36896, 294, 257, 636, 689, 321, 19667, 50700], "temperature": 0.0, "avg_logprob": -0.1260912197152364, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.006282404530793428}, {"id": 855, "seek": 507320, "start": 5079.92, "end": 5084.32, "text": " typically consciousness, we would attribute consciousness to these intelligent systems", "tokens": [50700, 5850, 10081, 11, 321, 576, 19667, 10081, 281, 613, 13232, 3652, 50920], "temperature": 0.0, "avg_logprob": -0.1260912197152364, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.006282404530793428}, {"id": 856, "seek": 507320, "start": 5084.32, "end": 5089.84, "text": " and IxE probably in particular. That, of course, doesn't answer the question whether it's really", "tokens": [50920, 293, 286, 87, 36, 1391, 294, 1729, 13, 663, 11, 295, 1164, 11, 1177, 380, 1867, 264, 1168, 1968, 309, 311, 534, 51196], "temperature": 0.0, "avg_logprob": -0.1260912197152364, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.006282404530793428}, {"id": 857, "seek": 507320, "start": 5089.84, "end": 5095.92, "text": " conscious. And that's the big hard problem of consciousness. Maybe I'm a zombie. I mean,", "tokens": [51196, 6648, 13, 400, 300, 311, 264, 955, 1152, 1154, 295, 10081, 13, 2704, 286, 478, 257, 20310, 13, 286, 914, 11, 51500], "temperature": 0.0, "avg_logprob": -0.1260912197152364, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.006282404530793428}, {"id": 858, "seek": 507320, "start": 5095.92, "end": 5098.4, "text": " not the movie zombie, but the philosophical zombie.", "tokens": [51500, 406, 264, 3169, 20310, 11, 457, 264, 25066, 20310, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1260912197152364, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.006282404530793428}, {"id": 859, "seek": 509840, "start": 5099.36, "end": 5106.48, "text": " It's to you, the display of consciousness close enough to consciousness from a perspective of AGI", "tokens": [50412, 467, 311, 281, 291, 11, 264, 4674, 295, 10081, 1998, 1547, 281, 10081, 490, 257, 4585, 295, 316, 26252, 50768], "temperature": 0.0, "avg_logprob": -0.1512637550448194, "compression_ratio": 1.7980295566502462, "no_speech_prob": 0.0011873558396473527}, {"id": 860, "seek": 509840, "start": 5106.48, "end": 5111.2, "text": " that the distinction of the heart problem of consciousness is not an interesting one.", "tokens": [50768, 300, 264, 16844, 295, 264, 1917, 1154, 295, 10081, 307, 406, 364, 1880, 472, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1512637550448194, "compression_ratio": 1.7980295566502462, "no_speech_prob": 0.0011873558396473527}, {"id": 861, "seek": 509840, "start": 5111.2, "end": 5114.719999999999, "text": " I think we don't have to worry about the consciousness problem, especially the heart", "tokens": [51004, 286, 519, 321, 500, 380, 362, 281, 3292, 466, 264, 10081, 1154, 11, 2318, 264, 1917, 51180], "temperature": 0.0, "avg_logprob": -0.1512637550448194, "compression_ratio": 1.7980295566502462, "no_speech_prob": 0.0011873558396473527}, {"id": 862, "seek": 509840, "start": 5114.719999999999, "end": 5122.48, "text": " problem for developing AGI. I think we progress. At some point, we have solved all the technical", "tokens": [51180, 1154, 337, 6416, 316, 26252, 13, 286, 519, 321, 4205, 13, 1711, 512, 935, 11, 321, 362, 13041, 439, 264, 6191, 51568], "temperature": 0.0, "avg_logprob": -0.1512637550448194, "compression_ratio": 1.7980295566502462, "no_speech_prob": 0.0011873558396473527}, {"id": 863, "seek": 512248, "start": 5122.5599999999995, "end": 5126.719999999999, "text": " problems and this system will behave intelligent and then super intelligent and", "tokens": [50368, 2740, 293, 341, 1185, 486, 15158, 13232, 293, 550, 1687, 13232, 293, 50576], "temperature": 0.0, "avg_logprob": -0.120509727713988, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.008183291181921959}, {"id": 864, "seek": 512248, "start": 5127.759999999999, "end": 5133.04, "text": " this consciousness will emerge. I mean, definitely it will display behavior which we", "tokens": [50628, 341, 10081, 486, 21511, 13, 286, 914, 11, 2138, 309, 486, 4674, 5223, 597, 321, 50892], "temperature": 0.0, "avg_logprob": -0.120509727713988, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.008183291181921959}, {"id": 865, "seek": 512248, "start": 5133.04, "end": 5139.04, "text": " will interpret as conscious. And then it's a philosophical question. Did this consciousness", "tokens": [50892, 486, 7302, 382, 6648, 13, 400, 550, 309, 311, 257, 25066, 1168, 13, 2589, 341, 10081, 51192], "temperature": 0.0, "avg_logprob": -0.120509727713988, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.008183291181921959}, {"id": 866, "seek": 512248, "start": 5139.04, "end": 5144.959999999999, "text": " really emerge? Or is it a zombie which just fakes everything? We still don't have to figure that", "tokens": [51192, 534, 21511, 30, 1610, 307, 309, 257, 20310, 597, 445, 283, 3419, 1203, 30, 492, 920, 500, 380, 362, 281, 2573, 300, 51488], "temperature": 0.0, "avg_logprob": -0.120509727713988, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.008183291181921959}, {"id": 867, "seek": 512248, "start": 5144.959999999999, "end": 5149.36, "text": " out. Although it may be interesting, at least from a philosophical point of view. It's very", "tokens": [51488, 484, 13, 5780, 309, 815, 312, 1880, 11, 412, 1935, 490, 257, 25066, 935, 295, 1910, 13, 467, 311, 588, 51708], "temperature": 0.0, "avg_logprob": -0.120509727713988, "compression_ratio": 1.7519685039370079, "no_speech_prob": 0.008183291181921959}, {"id": 868, "seek": 514936, "start": 5149.36, "end": 5153.839999999999, "text": " interesting, but it may also be sort of practically interesting. You know, there's some people", "tokens": [50364, 1880, 11, 457, 309, 815, 611, 312, 1333, 295, 15667, 1880, 13, 509, 458, 11, 456, 311, 512, 561, 50588], "temperature": 0.0, "avg_logprob": -0.12181257493425124, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.001726612332277}, {"id": 869, "seek": 514936, "start": 5153.839999999999, "end": 5157.92, "text": " saying, if it's just faking consciousness and feelings, then we don't need to be concerned", "tokens": [50588, 1566, 11, 498, 309, 311, 445, 283, 2456, 10081, 293, 6640, 11, 550, 321, 500, 380, 643, 281, 312, 5922, 50792], "temperature": 0.0, "avg_logprob": -0.12181257493425124, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.001726612332277}, {"id": 870, "seek": 514936, "start": 5157.92, "end": 5162.719999999999, "text": " about rights. But if it's real conscious and has feelings, then we need to be concerned.", "tokens": [50792, 466, 4601, 13, 583, 498, 309, 311, 957, 6648, 293, 575, 6640, 11, 550, 321, 643, 281, 312, 5922, 13, 51032], "temperature": 0.0, "avg_logprob": -0.12181257493425124, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.001726612332277}, {"id": 871, "seek": 514936, "start": 5165.839999999999, "end": 5171.92, "text": " I can't wait till the day where AI systems exhibit consciousness because it'll truly", "tokens": [51188, 286, 393, 380, 1699, 4288, 264, 786, 689, 7318, 3652, 20487, 10081, 570, 309, 603, 4908, 51492], "temperature": 0.0, "avg_logprob": -0.12181257493425124, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.001726612332277}, {"id": 872, "seek": 514936, "start": 5171.92, "end": 5175.599999999999, "text": " be some of the hardest ethical questions of what we do with that.", "tokens": [51492, 312, 512, 295, 264, 13158, 18890, 1651, 295, 437, 321, 360, 365, 300, 13, 51676], "temperature": 0.0, "avg_logprob": -0.12181257493425124, "compression_ratio": 1.756198347107438, "no_speech_prob": 0.001726612332277}, {"id": 873, "seek": 517560, "start": 5175.6, "end": 5182.56, "text": " It is rather easy to build systems which people ascribe consciousness. And I give you an analogy.", "tokens": [50364, 467, 307, 2831, 1858, 281, 1322, 3652, 597, 561, 382, 8056, 10081, 13, 400, 286, 976, 291, 364, 21663, 13, 50712], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 874, "seek": 517560, "start": 5182.56, "end": 5186.08, "text": " I mean, remember, maybe it was before you were born, the Tamagotchi.", "tokens": [50712, 286, 914, 11, 1604, 11, 1310, 309, 390, 949, 291, 645, 4232, 11, 264, 8540, 559, 310, 8036, 13, 50888], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 875, "seek": 517560, "start": 5188.64, "end": 5189.52, "text": " How dare you, sir.", "tokens": [51016, 1012, 8955, 291, 11, 4735, 13, 51060], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 876, "seek": 517560, "start": 5190.88, "end": 5193.200000000001, "text": " Why that's so... You're young, right?", "tokens": [51128, 1545, 300, 311, 370, 485, 509, 434, 2037, 11, 558, 30, 51244], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 877, "seek": 517560, "start": 5193.200000000001, "end": 5197.6, "text": " Yes, it's good to think. Thank you. Thank you very much. But I was also in the Soviet Union. We", "tokens": [51244, 1079, 11, 309, 311, 665, 281, 519, 13, 1044, 291, 13, 1044, 291, 588, 709, 13, 583, 286, 390, 611, 294, 264, 11348, 8133, 13, 492, 51464], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 878, "seek": 517560, "start": 5197.6, "end": 5201.120000000001, "text": " didn't have... We didn't have any of those fun things.", "tokens": [51464, 994, 380, 362, 485, 492, 994, 380, 362, 604, 295, 729, 1019, 721, 13, 51640], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 879, "seek": 517560, "start": 5201.120000000001, "end": 5203.84, "text": " But you have heard about this Tamagotchi, which was, you know, really,", "tokens": [51640, 583, 291, 362, 2198, 466, 341, 8540, 559, 310, 8036, 11, 597, 390, 11, 291, 458, 11, 534, 11, 51776], "temperature": 0.0, "avg_logprob": -0.22630962342706346, "compression_ratio": 1.6064981949458483, "no_speech_prob": 0.009685622528195381}, {"id": 880, "seek": 520384, "start": 5203.92, "end": 5210.72, "text": " really primitive. Actually, for the time it was... And you could raise this. And kids got so", "tokens": [50368, 534, 28540, 13, 5135, 11, 337, 264, 565, 309, 390, 485, 400, 291, 727, 5300, 341, 13, 400, 2301, 658, 370, 50708], "temperature": 0.0, "avg_logprob": -0.19594190755021682, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.002433421788737178}, {"id": 881, "seek": 520384, "start": 5210.72, "end": 5217.360000000001, "text": " attached to it and didn't want to let it die. And probably if we would have asked the children,", "tokens": [50708, 8570, 281, 309, 293, 994, 380, 528, 281, 718, 309, 978, 13, 400, 1391, 498, 321, 576, 362, 2351, 264, 2227, 11, 51040], "temperature": 0.0, "avg_logprob": -0.19594190755021682, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.002433421788737178}, {"id": 882, "seek": 520384, "start": 5217.360000000001, "end": 5220.32, "text": " do you think this Tamagotchi is conscious? They would have said yes.", "tokens": [51040, 360, 291, 519, 341, 8540, 559, 310, 8036, 307, 6648, 30, 814, 576, 362, 848, 2086, 13, 51188], "temperature": 0.0, "avg_logprob": -0.19594190755021682, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.002433421788737178}, {"id": 883, "seek": 520384, "start": 5221.52, "end": 5226.8, "text": " I think that's kind of a beautiful thing, actually, because that consciousness, ascribing", "tokens": [51248, 286, 519, 300, 311, 733, 295, 257, 2238, 551, 11, 767, 11, 570, 300, 10081, 11, 382, 39541, 51512], "temperature": 0.0, "avg_logprob": -0.19594190755021682, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.002433421788737178}, {"id": 884, "seek": 520384, "start": 5226.8, "end": 5233.12, "text": " consciousness seems to create a deeper connection, which is a powerful thing. But we have to be", "tokens": [51512, 10081, 2544, 281, 1884, 257, 7731, 4984, 11, 597, 307, 257, 4005, 551, 13, 583, 321, 362, 281, 312, 51828], "temperature": 0.0, "avg_logprob": -0.19594190755021682, "compression_ratio": 1.7104247104247103, "no_speech_prob": 0.002433421788737178}, {"id": 885, "seek": 523312, "start": 5233.12, "end": 5238.88, "text": " careful on the ethics side of that. Well, let me ask about the AGI community broadly. You kind of", "tokens": [50364, 5026, 322, 264, 19769, 1252, 295, 300, 13, 1042, 11, 718, 385, 1029, 466, 264, 316, 26252, 1768, 19511, 13, 509, 733, 295, 50652], "temperature": 0.0, "avg_logprob": -0.11199018144115959, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.001169097376987338}, {"id": 886, "seek": 523312, "start": 5238.88, "end": 5246.32, "text": " represent some of the most serious work on AGI, at least earlier. And DeepMind represents", "tokens": [50652, 2906, 512, 295, 264, 881, 3156, 589, 322, 316, 26252, 11, 412, 1935, 3071, 13, 400, 14895, 44, 471, 8855, 51024], "temperature": 0.0, "avg_logprob": -0.11199018144115959, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.001169097376987338}, {"id": 887, "seek": 523312, "start": 5247.12, "end": 5254.0, "text": " serious work on AGI these days. But why, in your sense, is the AGI community so small,", "tokens": [51064, 3156, 589, 322, 316, 26252, 613, 1708, 13, 583, 983, 11, 294, 428, 2020, 11, 307, 264, 316, 26252, 1768, 370, 1359, 11, 51408], "temperature": 0.0, "avg_logprob": -0.11199018144115959, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.001169097376987338}, {"id": 888, "seek": 523312, "start": 5254.0, "end": 5260.24, "text": " or has been so small, until maybe DeepMind came along? Like, why aren't more people", "tokens": [51408, 420, 575, 668, 370, 1359, 11, 1826, 1310, 14895, 44, 471, 1361, 2051, 30, 1743, 11, 983, 3212, 380, 544, 561, 51720], "temperature": 0.0, "avg_logprob": -0.11199018144115959, "compression_ratio": 1.634703196347032, "no_speech_prob": 0.001169097376987338}, {"id": 889, "seek": 526024, "start": 5260.24, "end": 5267.12, "text": " seriously working on human level and superhuman level intelligence from a formal perspective?", "tokens": [50364, 6638, 1364, 322, 1952, 1496, 293, 1687, 18796, 1496, 7599, 490, 257, 9860, 4585, 30, 50708], "temperature": 0.0, "avg_logprob": -0.14488176677538, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0014320010086521506}, {"id": 890, "seek": 526024, "start": 5268.16, "end": 5274.08, "text": " Okay, from a formal perspective, that's sort of, you know, an extra point. So I think there are", "tokens": [50760, 1033, 11, 490, 257, 9860, 4585, 11, 300, 311, 1333, 295, 11, 291, 458, 11, 364, 2857, 935, 13, 407, 286, 519, 456, 366, 51056], "temperature": 0.0, "avg_logprob": -0.14488176677538, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0014320010086521506}, {"id": 891, "seek": 526024, "start": 5274.08, "end": 5278.4, "text": " a couple of reasons. I mean, AI came in waves, right? You know, AI winters and AI summers,", "tokens": [51056, 257, 1916, 295, 4112, 13, 286, 914, 11, 7318, 1361, 294, 9417, 11, 558, 30, 509, 458, 11, 7318, 1942, 1559, 293, 7318, 46474, 11, 51272], "temperature": 0.0, "avg_logprob": -0.14488176677538, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0014320010086521506}, {"id": 892, "seek": 526024, "start": 5278.4, "end": 5287.2, "text": " and then there were big promises, which were not fulfilled. And people got disappointed. But", "tokens": [51272, 293, 550, 456, 645, 955, 16403, 11, 597, 645, 406, 21380, 13, 400, 561, 658, 13856, 13, 583, 51712], "temperature": 0.0, "avg_logprob": -0.14488176677538, "compression_ratio": 1.6077586206896552, "no_speech_prob": 0.0014320010086521506}, {"id": 893, "seek": 528720, "start": 5288.08, "end": 5294.24, "text": " narrow AI, solving particular problems, which seemed to require intelligence, was", "tokens": [50408, 9432, 7318, 11, 12606, 1729, 2740, 11, 597, 6576, 281, 3651, 7599, 11, 390, 50716], "temperature": 0.0, "avg_logprob": -0.11522302394959985, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0006562743219546974}, {"id": 894, "seek": 528720, "start": 5295.2, "end": 5300.48, "text": " always to some extent successful, and there were improvements, small steps. And if you build", "tokens": [50764, 1009, 281, 512, 8396, 4406, 11, 293, 456, 645, 13797, 11, 1359, 4439, 13, 400, 498, 291, 1322, 51028], "temperature": 0.0, "avg_logprob": -0.11522302394959985, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0006562743219546974}, {"id": 895, "seek": 528720, "start": 5300.48, "end": 5306.48, "text": " something which is, you know, useful for society or industrial useful, then there's a lot of funding.", "tokens": [51028, 746, 597, 307, 11, 291, 458, 11, 4420, 337, 4086, 420, 9987, 4420, 11, 550, 456, 311, 257, 688, 295, 6137, 13, 51328], "temperature": 0.0, "avg_logprob": -0.11522302394959985, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0006562743219546974}, {"id": 896, "seek": 528720, "start": 5306.48, "end": 5314.48, "text": " So I guess it was in parts the money, which drives people to develop specific system solving", "tokens": [51328, 407, 286, 2041, 309, 390, 294, 3166, 264, 1460, 11, 597, 11754, 561, 281, 1499, 2685, 1185, 12606, 51728], "temperature": 0.0, "avg_logprob": -0.11522302394959985, "compression_ratio": 1.5702127659574467, "no_speech_prob": 0.0006562743219546974}, {"id": 897, "seek": 531448, "start": 5314.48, "end": 5320.639999999999, "text": " specific tasks. But you would think that, you know, at least in university, you should be able to do", "tokens": [50364, 2685, 9608, 13, 583, 291, 576, 519, 300, 11, 291, 458, 11, 412, 1935, 294, 5454, 11, 291, 820, 312, 1075, 281, 360, 50672], "temperature": 0.0, "avg_logprob": -0.09503077424090842, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001896168221719563}, {"id": 898, "seek": 531448, "start": 5321.28, "end": 5326.799999999999, "text": " ivory tower research. And that was probably better a long time ago. But even nowadays,", "tokens": [50704, 49218, 10567, 2132, 13, 400, 300, 390, 1391, 1101, 257, 938, 565, 2057, 13, 583, 754, 13434, 11, 50980], "temperature": 0.0, "avg_logprob": -0.09503077424090842, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001896168221719563}, {"id": 899, "seek": 531448, "start": 5326.799999999999, "end": 5332.959999999999, "text": " there's quite some pressure of doing applied research or translational research. And, you", "tokens": [50980, 456, 311, 1596, 512, 3321, 295, 884, 6456, 2132, 420, 5105, 1478, 2132, 13, 400, 11, 291, 51288], "temperature": 0.0, "avg_logprob": -0.09503077424090842, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001896168221719563}, {"id": 900, "seek": 531448, "start": 5332.959999999999, "end": 5340.48, "text": " know, it's harder to get grants as a theorist. So that also drives people away. It's maybe also", "tokens": [51288, 458, 11, 309, 311, 6081, 281, 483, 16101, 382, 257, 27423, 468, 13, 407, 300, 611, 11754, 561, 1314, 13, 467, 311, 1310, 611, 51664], "temperature": 0.0, "avg_logprob": -0.09503077424090842, "compression_ratio": 1.6217391304347826, "no_speech_prob": 0.001896168221719563}, {"id": 901, "seek": 534048, "start": 5340.48, "end": 5344.959999999999, "text": " harder, attacking the general intelligence problem. So I think enough people, I mean,", "tokens": [50364, 6081, 11, 15010, 264, 2674, 7599, 1154, 13, 407, 286, 519, 1547, 561, 11, 286, 914, 11, 50588], "temperature": 0.0, "avg_logprob": -0.13584433468905363, "compression_ratio": 1.7196969696969697, "no_speech_prob": 0.002148232189938426}, {"id": 902, "seek": 534048, "start": 5344.959999999999, "end": 5351.919999999999, "text": " maybe a small number, we're still interested in, in formalizing intelligence and, and thinking of", "tokens": [50588, 1310, 257, 1359, 1230, 11, 321, 434, 920, 3102, 294, 11, 294, 9860, 3319, 7599, 293, 11, 293, 1953, 295, 50936], "temperature": 0.0, "avg_logprob": -0.13584433468905363, "compression_ratio": 1.7196969696969697, "no_speech_prob": 0.002148232189938426}, {"id": 903, "seek": 534048, "start": 5351.919999999999, "end": 5359.2, "text": " general intelligence. But, you know, not much came up, right? Or not not much great stuff came up.", "tokens": [50936, 2674, 7599, 13, 583, 11, 291, 458, 11, 406, 709, 1361, 493, 11, 558, 30, 1610, 406, 406, 709, 869, 1507, 1361, 493, 13, 51300], "temperature": 0.0, "avg_logprob": -0.13584433468905363, "compression_ratio": 1.7196969696969697, "no_speech_prob": 0.002148232189938426}, {"id": 904, "seek": 534048, "start": 5359.759999999999, "end": 5366.0, "text": " So what do you think we talked about the formal big light at the end of the tunnel,", "tokens": [51328, 407, 437, 360, 291, 519, 321, 2825, 466, 264, 9860, 955, 1442, 412, 264, 917, 295, 264, 13186, 11, 51640], "temperature": 0.0, "avg_logprob": -0.13584433468905363, "compression_ratio": 1.7196969696969697, "no_speech_prob": 0.002148232189938426}, {"id": 905, "seek": 534048, "start": 5366.0, "end": 5369.44, "text": " but from the engineering perspective, what do you think it takes to build an AI system?", "tokens": [51640, 457, 490, 264, 7043, 4585, 11, 437, 360, 291, 519, 309, 2516, 281, 1322, 364, 7318, 1185, 30, 51812], "temperature": 0.0, "avg_logprob": -0.13584433468905363, "compression_ratio": 1.7196969696969697, "no_speech_prob": 0.002148232189938426}, {"id": 906, "seek": 536944, "start": 5370.24, "end": 5375.679999999999, "text": " Is that, and I don't know if that's a stupid question or a distinct question from everything", "tokens": [50404, 1119, 300, 11, 293, 286, 500, 380, 458, 498, 300, 311, 257, 6631, 1168, 420, 257, 10644, 1168, 490, 1203, 50676], "temperature": 0.0, "avg_logprob": -0.15581291766206096, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0012442852603271604}, {"id": 907, "seek": 536944, "start": 5375.679999999999, "end": 5380.879999999999, "text": " we've been talking about AIXE. But what do you see as the steps that are necessary to take", "tokens": [50676, 321, 600, 668, 1417, 466, 7318, 55, 36, 13, 583, 437, 360, 291, 536, 382, 264, 4439, 300, 366, 4818, 281, 747, 50936], "temperature": 0.0, "avg_logprob": -0.15581291766206096, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0012442852603271604}, {"id": 908, "seek": 536944, "start": 5380.879999999999, "end": 5386.16, "text": " to start to try to build something? So you want a blueprint now, and then you go off and do it?", "tokens": [50936, 281, 722, 281, 853, 281, 1322, 746, 30, 407, 291, 528, 257, 35868, 586, 11, 293, 550, 291, 352, 766, 293, 360, 309, 30, 51200], "temperature": 0.0, "avg_logprob": -0.15581291766206096, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0012442852603271604}, {"id": 909, "seek": 536944, "start": 5386.16, "end": 5390.32, "text": " That's the whole point of this conversation, trying to squeeze that in there. Now, is there,", "tokens": [51200, 663, 311, 264, 1379, 935, 295, 341, 3761, 11, 1382, 281, 13578, 300, 294, 456, 13, 823, 11, 307, 456, 11, 51408], "temperature": 0.0, "avg_logprob": -0.15581291766206096, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0012442852603271604}, {"id": 910, "seek": 536944, "start": 5390.32, "end": 5395.36, "text": " I mean, what's your intuition? Is it is in the robotic space or something that has a body and", "tokens": [51408, 286, 914, 11, 437, 311, 428, 24002, 30, 1119, 309, 307, 294, 264, 30468, 1901, 420, 746, 300, 575, 257, 1772, 293, 51660], "temperature": 0.0, "avg_logprob": -0.15581291766206096, "compression_ratio": 1.6762589928057554, "no_speech_prob": 0.0012442852603271604}, {"id": 911, "seek": 539536, "start": 5395.36, "end": 5399.92, "text": " tries to explore the world? Is in the reinforcement learning space, like the efforts of Alpha", "tokens": [50364, 9898, 281, 6839, 264, 1002, 30, 1119, 294, 264, 29280, 2539, 1901, 11, 411, 264, 6484, 295, 20588, 50592], "temperature": 0.0, "avg_logprob": -0.15946402916541466, "compression_ratio": 1.6531365313653137, "no_speech_prob": 0.01689952053129673}, {"id": 912, "seek": 539536, "start": 5399.92, "end": 5405.36, "text": " Zero and Alpha Star, they're kind of exploring how you can solve it through in the, in the simulation", "tokens": [50592, 17182, 293, 20588, 5705, 11, 436, 434, 733, 295, 12736, 577, 291, 393, 5039, 309, 807, 294, 264, 11, 294, 264, 16575, 50864], "temperature": 0.0, "avg_logprob": -0.15946402916541466, "compression_ratio": 1.6531365313653137, "no_speech_prob": 0.01689952053129673}, {"id": 913, "seek": 539536, "start": 5405.36, "end": 5411.759999999999, "text": " in the gaming world. Is there stuff in sort of the, all the transformer work in natural", "tokens": [50864, 294, 264, 9703, 1002, 13, 1119, 456, 1507, 294, 1333, 295, 264, 11, 439, 264, 31782, 589, 294, 3303, 51184], "temperature": 0.0, "avg_logprob": -0.15946402916541466, "compression_ratio": 1.6531365313653137, "no_speech_prob": 0.01689952053129673}, {"id": 914, "seek": 539536, "start": 5411.759999999999, "end": 5416.639999999999, "text": " English processing, sort of maybe attacking the open domain dialogue? Like what, what,", "tokens": [51184, 3669, 9007, 11, 1333, 295, 1310, 15010, 264, 1269, 9274, 10221, 30, 1743, 437, 11, 437, 11, 51428], "temperature": 0.0, "avg_logprob": -0.15946402916541466, "compression_ratio": 1.6531365313653137, "no_speech_prob": 0.01689952053129673}, {"id": 915, "seek": 539536, "start": 5416.639999999999, "end": 5424.799999999999, "text": " where do you see the promising pathways? Let me pick the embodiment maybe. So", "tokens": [51428, 689, 360, 291, 536, 264, 20257, 22988, 30, 961, 385, 1888, 264, 28935, 2328, 1310, 13, 407, 51836], "temperature": 0.0, "avg_logprob": -0.15946402916541466, "compression_ratio": 1.6531365313653137, "no_speech_prob": 0.01689952053129673}, {"id": 916, "seek": 542536, "start": 5425.599999999999, "end": 5437.599999999999, "text": " embodiment is important, yes and no. I don't believe that we need a physical robot", "tokens": [50376, 28935, 2328, 307, 1021, 11, 2086, 293, 572, 13, 286, 500, 380, 1697, 300, 321, 643, 257, 4001, 7881, 50976], "temperature": 0.0, "avg_logprob": -0.1247911983066135, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0004107736749574542}, {"id": 917, "seek": 542536, "start": 5438.5599999999995, "end": 5445.44, "text": " walking or rolling around interacting with the real world in order to achieve AGI. And", "tokens": [51024, 4494, 420, 9439, 926, 18017, 365, 264, 957, 1002, 294, 1668, 281, 4584, 316, 26252, 13, 400, 51368], "temperature": 0.0, "avg_logprob": -0.1247911983066135, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0004107736749574542}, {"id": 918, "seek": 542536, "start": 5447.679999999999, "end": 5452.799999999999, "text": " I think it's more of a distraction probably than helpful. It's sort of confusing the body", "tokens": [51480, 286, 519, 309, 311, 544, 295, 257, 30217, 1391, 813, 4961, 13, 467, 311, 1333, 295, 13181, 264, 1772, 51736], "temperature": 0.0, "avg_logprob": -0.1247911983066135, "compression_ratio": 1.446927374301676, "no_speech_prob": 0.0004107736749574542}, {"id": 919, "seek": 545280, "start": 5452.8, "end": 5459.4400000000005, "text": " with the mind. For industrial applications or near term applications, of course, we need", "tokens": [50364, 365, 264, 1575, 13, 1171, 9987, 5821, 420, 2651, 1433, 5821, 11, 295, 1164, 11, 321, 643, 50696], "temperature": 0.0, "avg_logprob": -0.11486793094211155, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0013665198348462582}, {"id": 920, "seek": 545280, "start": 5459.4400000000005, "end": 5466.400000000001, "text": " robots for all kinds of things, but for solving the big problem, at least at this stage, I think", "tokens": [50696, 14733, 337, 439, 3685, 295, 721, 11, 457, 337, 12606, 264, 955, 1154, 11, 412, 1935, 412, 341, 3233, 11, 286, 519, 51044], "temperature": 0.0, "avg_logprob": -0.11486793094211155, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0013665198348462582}, {"id": 921, "seek": 545280, "start": 5466.400000000001, "end": 5473.52, "text": " it's not necessary. But the answer is also yes, that I think the most promising approach is that", "tokens": [51044, 309, 311, 406, 4818, 13, 583, 264, 1867, 307, 611, 2086, 11, 300, 286, 519, 264, 881, 20257, 3109, 307, 300, 51400], "temperature": 0.0, "avg_logprob": -0.11486793094211155, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0013665198348462582}, {"id": 922, "seek": 545280, "start": 5473.52, "end": 5480.0, "text": " you have an agent, and that can be a virtual agent in a computer interacting with an environment,", "tokens": [51400, 291, 362, 364, 9461, 11, 293, 300, 393, 312, 257, 6374, 9461, 294, 257, 3820, 18017, 365, 364, 2823, 11, 51724], "temperature": 0.0, "avg_logprob": -0.11486793094211155, "compression_ratio": 1.623931623931624, "no_speech_prob": 0.0013665198348462582}, {"id": 923, "seek": 548000, "start": 5480.08, "end": 5483.84, "text": " possibly, you know, a 3D simulated environment like in many computer games.", "tokens": [50368, 6264, 11, 291, 458, 11, 257, 805, 35, 41713, 2823, 411, 294, 867, 3820, 2813, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1526557377406529, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.0020823089871555567}, {"id": 924, "seek": 548000, "start": 5485.28, "end": 5493.04, "text": " And, and you train and learn the agent. Even if you don't intend to later put it sort of, you know,", "tokens": [50628, 400, 11, 293, 291, 3847, 293, 1466, 264, 9461, 13, 2754, 498, 291, 500, 380, 19759, 281, 1780, 829, 309, 1333, 295, 11, 291, 458, 11, 51016], "temperature": 0.0, "avg_logprob": -0.1526557377406529, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.0020823089871555567}, {"id": 925, "seek": 548000, "start": 5493.04, "end": 5498.48, "text": " this algorithm in a, in a robot brain and leave it forever in the virtual reality,", "tokens": [51016, 341, 9284, 294, 257, 11, 294, 257, 7881, 3567, 293, 1856, 309, 5680, 294, 264, 6374, 4103, 11, 51288], "temperature": 0.0, "avg_logprob": -0.1526557377406529, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.0020823089871555567}, {"id": 926, "seek": 548000, "start": 5498.48, "end": 5503.44, "text": " getting experience in a, although it's just simulated 3D world,", "tokens": [51288, 1242, 1752, 294, 257, 11, 4878, 309, 311, 445, 41713, 805, 35, 1002, 11, 51536], "temperature": 0.0, "avg_logprob": -0.1526557377406529, "compression_ratio": 1.5631067961165048, "no_speech_prob": 0.0020823089871555567}, {"id": 927, "seek": 550344, "start": 5504.24, "end": 5513.5199999999995, "text": " is possibly, and as I possibly important to understand things on a similar level as humans do,", "tokens": [50404, 307, 6264, 11, 293, 382, 286, 6264, 1021, 281, 1223, 721, 322, 257, 2531, 1496, 382, 6255, 360, 11, 50868], "temperature": 0.0, "avg_logprob": -0.15138545243636423, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0033208760432899}, {"id": 928, "seek": 550344, "start": 5515.04, "end": 5519.919999999999, "text": " especially if the agent or primarily if the agent wants, needs to interact with the humans,", "tokens": [50944, 2318, 498, 264, 9461, 420, 10029, 498, 264, 9461, 2738, 11, 2203, 281, 4648, 365, 264, 6255, 11, 51188], "temperature": 0.0, "avg_logprob": -0.15138545243636423, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0033208760432899}, {"id": 929, "seek": 550344, "start": 5519.919999999999, "end": 5524.16, "text": " right? You know, if you talk about objects on top of each other in space and flying and cars and", "tokens": [51188, 558, 30, 509, 458, 11, 498, 291, 751, 466, 6565, 322, 1192, 295, 1184, 661, 294, 1901, 293, 7137, 293, 5163, 293, 51400], "temperature": 0.0, "avg_logprob": -0.15138545243636423, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0033208760432899}, {"id": 930, "seek": 550344, "start": 5524.16, "end": 5530.799999999999, "text": " so on, and the agent has no experience with even virtual 3D worlds, it's probably hard to grasp.", "tokens": [51400, 370, 322, 11, 293, 264, 9461, 575, 572, 1752, 365, 754, 6374, 805, 35, 13401, 11, 309, 311, 1391, 1152, 281, 21743, 13, 51732], "temperature": 0.0, "avg_logprob": -0.15138545243636423, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0033208760432899}, {"id": 931, "seek": 553080, "start": 5531.12, "end": 5537.84, "text": " So if we develop an abstract agent, say we take the mathematical path, and we just want to build", "tokens": [50380, 407, 498, 321, 1499, 364, 12649, 9461, 11, 584, 321, 747, 264, 18894, 3100, 11, 293, 321, 445, 528, 281, 1322, 50716], "temperature": 0.0, "avg_logprob": -0.16046942983354842, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0027998832520097494}, {"id": 932, "seek": 553080, "start": 5537.84, "end": 5542.400000000001, "text": " an agent which can prove theorems and becomes a better and better mathematician, then this agent", "tokens": [50716, 364, 9461, 597, 393, 7081, 10299, 2592, 293, 3643, 257, 1101, 293, 1101, 48281, 11, 550, 341, 9461, 50944], "temperature": 0.0, "avg_logprob": -0.16046942983354842, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0027998832520097494}, {"id": 933, "seek": 553080, "start": 5542.400000000001, "end": 5547.92, "text": " needs to be able to reason in very abstract spaces, and then maybe sort of putting it into", "tokens": [50944, 2203, 281, 312, 1075, 281, 1778, 294, 588, 12649, 7673, 11, 293, 550, 1310, 1333, 295, 3372, 309, 666, 51220], "temperature": 0.0, "avg_logprob": -0.16046942983354842, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0027998832520097494}, {"id": 934, "seek": 553080, "start": 5547.92, "end": 5553.28, "text": " 3D environments, simulated world is even harmful, it should sort of, you put it in, I don't know,", "tokens": [51220, 805, 35, 12388, 11, 41713, 1002, 307, 754, 19727, 11, 309, 820, 1333, 295, 11, 291, 829, 309, 294, 11, 286, 500, 380, 458, 11, 51488], "temperature": 0.0, "avg_logprob": -0.16046942983354842, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0027998832520097494}, {"id": 935, "seek": 553080, "start": 5553.28, "end": 5558.400000000001, "text": " an environment which it creates itself or so. It seems like you have an interesting,", "tokens": [51488, 364, 2823, 597, 309, 7829, 2564, 420, 370, 13, 467, 2544, 411, 291, 362, 364, 1880, 11, 51744], "temperature": 0.0, "avg_logprob": -0.16046942983354842, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0027998832520097494}, {"id": 936, "seek": 555840, "start": 5558.4, "end": 5563.679999999999, "text": " rich complex trajectory through life in terms of your journey of ideas. So it's interesting to", "tokens": [50364, 4593, 3997, 21512, 807, 993, 294, 2115, 295, 428, 4671, 295, 3487, 13, 407, 309, 311, 1880, 281, 50628], "temperature": 0.0, "avg_logprob": -0.12641706023105356, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.005634138360619545}, {"id": 937, "seek": 555840, "start": 5563.679999999999, "end": 5572.639999999999, "text": " ask what books, technical fiction, philosophical books, ideas, people had a transformative effect.", "tokens": [50628, 1029, 437, 3642, 11, 6191, 13266, 11, 25066, 3642, 11, 3487, 11, 561, 632, 257, 36070, 1802, 13, 51076], "temperature": 0.0, "avg_logprob": -0.12641706023105356, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.005634138360619545}, {"id": 938, "seek": 555840, "start": 5572.639999999999, "end": 5577.92, "text": " Books are most interesting because maybe people could also read those books and see if they could", "tokens": [51076, 33843, 366, 881, 1880, 570, 1310, 561, 727, 611, 1401, 729, 3642, 293, 536, 498, 436, 727, 51340], "temperature": 0.0, "avg_logprob": -0.12641706023105356, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.005634138360619545}, {"id": 939, "seek": 555840, "start": 5577.92, "end": 5585.44, "text": " be inspired as well. Yeah, luckily I asked books and not singular book, it's very hard and I try", "tokens": [51340, 312, 7547, 382, 731, 13, 865, 11, 22880, 286, 2351, 3642, 293, 406, 20010, 1446, 11, 309, 311, 588, 1152, 293, 286, 853, 51716], "temperature": 0.0, "avg_logprob": -0.12641706023105356, "compression_ratio": 1.603305785123967, "no_speech_prob": 0.005634138360619545}, {"id": 940, "seek": 558544, "start": 5585.44, "end": 5595.919999999999, "text": " to pin down one book, and I can do that at the end. So the books which were most transformative", "tokens": [50364, 281, 5447, 760, 472, 1446, 11, 293, 286, 393, 360, 300, 412, 264, 917, 13, 407, 264, 3642, 597, 645, 881, 36070, 50888], "temperature": 0.0, "avg_logprob": -0.19276727570427787, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.008435807190835476}, {"id": 941, "seek": 558544, "start": 5595.919999999999, "end": 5606.32, "text": " for me or which I can most highly recommend to people interested in AI, I would always start", "tokens": [50888, 337, 385, 420, 597, 286, 393, 881, 5405, 2748, 281, 561, 3102, 294, 7318, 11, 286, 576, 1009, 722, 51408], "temperature": 0.0, "avg_logprob": -0.19276727570427787, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.008435807190835476}, {"id": 942, "seek": 558544, "start": 5606.32, "end": 5613.599999999999, "text": " with Russell and Norbic, Artificial Intelligence and Modern Approach, that's the AI Bible, it's", "tokens": [51408, 365, 20937, 293, 6966, 65, 299, 11, 5735, 10371, 27274, 293, 19814, 29551, 608, 11, 300, 311, 264, 7318, 6544, 11, 309, 311, 51772], "temperature": 0.0, "avg_logprob": -0.19276727570427787, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.008435807190835476}, {"id": 943, "seek": 561360, "start": 5613.6, "end": 5620.400000000001, "text": " an amazing book, it's very broad, it covers all approaches to AI and even if you focus on one", "tokens": [50364, 364, 2243, 1446, 11, 309, 311, 588, 4152, 11, 309, 10538, 439, 11587, 281, 7318, 293, 754, 498, 291, 1879, 322, 472, 50704], "temperature": 0.0, "avg_logprob": -0.13363610180941496, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.002671328838914633}, {"id": 944, "seek": 561360, "start": 5620.400000000001, "end": 5624.56, "text": " approach, I think that is the minimum you should know about the other approaches out there,", "tokens": [50704, 3109, 11, 286, 519, 300, 307, 264, 7285, 291, 820, 458, 466, 264, 661, 11587, 484, 456, 11, 50912], "temperature": 0.0, "avg_logprob": -0.13363610180941496, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.002671328838914633}, {"id": 945, "seek": 561360, "start": 5624.56, "end": 5628.320000000001, "text": " so that should be your first book. Fourth edition should be coming out soon.", "tokens": [50912, 370, 300, 820, 312, 428, 700, 1446, 13, 23773, 11377, 820, 312, 1348, 484, 2321, 13, 51100], "temperature": 0.0, "avg_logprob": -0.13363610180941496, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.002671328838914633}, {"id": 946, "seek": 561360, "start": 5628.320000000001, "end": 5634.0, "text": " Oh, okay, interesting. There's a deep learning chapter now as there must be, written by Ian", "tokens": [51100, 876, 11, 1392, 11, 1880, 13, 821, 311, 257, 2452, 2539, 7187, 586, 382, 456, 1633, 312, 11, 3720, 538, 19595, 51384], "temperature": 0.0, "avg_logprob": -0.13363610180941496, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.002671328838914633}, {"id": 947, "seek": 561360, "start": 5634.0, "end": 5640.88, "text": " Goodfellow, okay. And then the next book I would recommend, The Reinforcement Learning Book by", "tokens": [51384, 2205, 69, 21348, 11, 1392, 13, 400, 550, 264, 958, 1446, 286, 576, 2748, 11, 440, 42116, 9382, 15205, 9476, 538, 51728], "temperature": 0.0, "avg_logprob": -0.13363610180941496, "compression_ratio": 1.6446886446886446, "no_speech_prob": 0.002671328838914633}, {"id": 948, "seek": 564088, "start": 5640.88, "end": 5648.96, "text": " Sutton and Bartow. There's a beautiful book, if there's any problem with the book, it makes RL", "tokens": [50364, 40492, 1756, 293, 22338, 305, 13, 821, 311, 257, 2238, 1446, 11, 498, 456, 311, 604, 1154, 365, 264, 1446, 11, 309, 1669, 497, 43, 50768], "temperature": 0.0, "avg_logprob": -0.16096349443708147, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0038801527116447687}, {"id": 949, "seek": 564088, "start": 5650.400000000001, "end": 5656.64, "text": " feel and look much easier than it actually is. It's very gentle book, it's very nice to read the", "tokens": [50840, 841, 293, 574, 709, 3571, 813, 309, 767, 307, 13, 467, 311, 588, 6424, 1446, 11, 309, 311, 588, 1481, 281, 1401, 264, 51152], "temperature": 0.0, "avg_logprob": -0.16096349443708147, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0038801527116447687}, {"id": 950, "seek": 564088, "start": 5656.64, "end": 5663.28, "text": " exercises, you can very quickly get some RL systems to run, very toy problems, but it's a lot of fun", "tokens": [51152, 11900, 11, 291, 393, 588, 2661, 483, 512, 497, 43, 3652, 281, 1190, 11, 588, 12058, 2740, 11, 457, 309, 311, 257, 688, 295, 1019, 51484], "temperature": 0.0, "avg_logprob": -0.16096349443708147, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0038801527116447687}, {"id": 951, "seek": 564088, "start": 5663.28, "end": 5670.8, "text": " and in a couple of days you feel you know what RL is about, but it's much harder than", "tokens": [51484, 293, 294, 257, 1916, 295, 1708, 291, 841, 291, 458, 437, 497, 43, 307, 466, 11, 457, 309, 311, 709, 6081, 813, 51860], "temperature": 0.0, "avg_logprob": -0.16096349443708147, "compression_ratio": 1.6725663716814159, "no_speech_prob": 0.0038801527116447687}, {"id": 952, "seek": 567080, "start": 5670.8, "end": 5680.320000000001, "text": " the book. Come on now, it's an awesome book. Yeah, no, no, it is, yeah. And maybe, I mean,", "tokens": [50364, 264, 1446, 13, 2492, 322, 586, 11, 309, 311, 364, 3476, 1446, 13, 865, 11, 572, 11, 572, 11, 309, 307, 11, 1338, 13, 400, 1310, 11, 286, 914, 11, 50840], "temperature": 0.0, "avg_logprob": -0.19851768563646788, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.001986722694709897}, {"id": 953, "seek": 567080, "start": 5680.320000000001, "end": 5683.68, "text": " there's so many books out there, if you like the information theoretic approach, then there's", "tokens": [50840, 456, 311, 370, 867, 3642, 484, 456, 11, 498, 291, 411, 264, 1589, 14308, 299, 3109, 11, 550, 456, 311, 51008], "temperature": 0.0, "avg_logprob": -0.19851768563646788, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.001986722694709897}, {"id": 954, "seek": 567080, "start": 5683.68, "end": 5690.72, "text": " Kolmogorff Complexity by Aline Vitani, but probably, you know, some short article is enough,", "tokens": [51008, 26137, 76, 664, 284, 602, 41184, 507, 538, 967, 533, 22463, 3782, 11, 457, 1391, 11, 291, 458, 11, 512, 2099, 7222, 307, 1547, 11, 51360], "temperature": 0.0, "avg_logprob": -0.19851768563646788, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.001986722694709897}, {"id": 955, "seek": 567080, "start": 5690.72, "end": 5697.92, "text": " you don't need to read the whole book, but it's a great book. And if you have to mention one", "tokens": [51360, 291, 500, 380, 643, 281, 1401, 264, 1379, 1446, 11, 457, 309, 311, 257, 869, 1446, 13, 400, 498, 291, 362, 281, 2152, 472, 51720], "temperature": 0.0, "avg_logprob": -0.19851768563646788, "compression_ratio": 1.6228070175438596, "no_speech_prob": 0.001986722694709897}, {"id": 956, "seek": 569792, "start": 5697.92, "end": 5704.24, "text": " all-time favorite book, it's a different flavor, that's a book which is used in the international", "tokens": [50364, 439, 12, 3766, 2954, 1446, 11, 309, 311, 257, 819, 6813, 11, 300, 311, 257, 1446, 597, 307, 1143, 294, 264, 5058, 50680], "temperature": 0.0, "avg_logprob": -0.19805715481440225, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.003877767827361822}, {"id": 957, "seek": 569792, "start": 5704.24, "end": 5710.88, "text": " baccalaureate for high school students in several countries. That's from Nikolas Altjen,", "tokens": [50680, 6857, 66, 5159, 540, 473, 337, 1090, 1395, 1731, 294, 2940, 3517, 13, 663, 311, 490, 13969, 14104, 15992, 15378, 11, 51012], "temperature": 0.0, "avg_logprob": -0.19805715481440225, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.003877767827361822}, {"id": 958, "seek": 569792, "start": 5710.88, "end": 5717.52, "text": " Theory of Knowledge, second edition, or first, not the third, please. The third one they put,", "tokens": [51012, 29009, 295, 32906, 11, 1150, 11377, 11, 420, 700, 11, 406, 264, 2636, 11, 1767, 13, 440, 2636, 472, 436, 829, 11, 51344], "temperature": 0.0, "avg_logprob": -0.19805715481440225, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.003877767827361822}, {"id": 959, "seek": 569792, "start": 5717.52, "end": 5726.4800000000005, "text": " they took out all the fun. Okay, so this asks all the interesting, or to me, interesting", "tokens": [51344, 436, 1890, 484, 439, 264, 1019, 13, 1033, 11, 370, 341, 8962, 439, 264, 1880, 11, 420, 281, 385, 11, 1880, 51792], "temperature": 0.0, "avg_logprob": -0.19805715481440225, "compression_ratio": 1.5836909871244635, "no_speech_prob": 0.003877767827361822}, {"id": 960, "seek": 572648, "start": 5726.48, "end": 5730.0, "text": " philosophical questions about how we acquire knowledge from all perspectives, you know,", "tokens": [50364, 25066, 1651, 466, 577, 321, 20001, 3601, 490, 439, 16766, 11, 291, 458, 11, 50540], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 961, "seek": 572648, "start": 5730.0, "end": 5736.799999999999, "text": " from math, from art, from physics, and ask how can we know anything? And the book is called", "tokens": [50540, 490, 5221, 11, 490, 1523, 11, 490, 10649, 11, 293, 1029, 577, 393, 321, 458, 1340, 30, 400, 264, 1446, 307, 1219, 50880], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 962, "seek": 572648, "start": 5736.799999999999, "end": 5740.799999999999, "text": " Theory of Knowledge. From which, is this almost like a philosophical exploration of", "tokens": [50880, 29009, 295, 32906, 13, 3358, 597, 11, 307, 341, 1920, 411, 257, 25066, 16197, 295, 51080], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 963, "seek": 572648, "start": 5741.679999999999, "end": 5745.04, "text": " how we get knowledge from anything? Yes, yeah, I mean, can religion tell us, you know,", "tokens": [51124, 577, 321, 483, 3601, 490, 1340, 30, 1079, 11, 1338, 11, 286, 914, 11, 393, 7561, 980, 505, 11, 291, 458, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 964, "seek": 572648, "start": 5745.04, "end": 5748.799999999999, "text": " about something about the world? Can science tell us something about the world? Can mathematics,", "tokens": [51292, 466, 746, 466, 264, 1002, 30, 1664, 3497, 980, 505, 746, 466, 264, 1002, 30, 1664, 18666, 11, 51480], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 965, "seek": 572648, "start": 5748.799999999999, "end": 5755.12, "text": " or is it just playing with symbols? And you know, it's open-ended questions, and I mean,", "tokens": [51480, 420, 307, 309, 445, 2433, 365, 16944, 30, 400, 291, 458, 11, 309, 311, 1269, 12, 3502, 1651, 11, 293, 286, 914, 11, 51796], "temperature": 0.0, "avg_logprob": -0.1407964825630188, "compression_ratio": 1.867595818815331, "no_speech_prob": 0.008834556676447392}, {"id": 966, "seek": 575512, "start": 5755.12, "end": 5758.96, "text": " it's for high school students, so they have the resources from Hitchhiker's Guide to the Galaxy", "tokens": [50364, 309, 311, 337, 1090, 1395, 1731, 11, 370, 436, 362, 264, 3593, 490, 389, 1549, 71, 17314, 311, 18727, 281, 264, 13520, 50556], "temperature": 0.0, "avg_logprob": -0.11405822965833876, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.00039176465361379087}, {"id": 967, "seek": 575512, "start": 5758.96, "end": 5765.36, "text": " and from Star Wars and the Chicken Cross the Road, yeah. And it's fun to read, but it's also quite", "tokens": [50556, 293, 490, 5705, 9818, 293, 264, 16765, 11623, 264, 11507, 11, 1338, 13, 400, 309, 311, 1019, 281, 1401, 11, 457, 309, 311, 611, 1596, 50876], "temperature": 0.0, "avg_logprob": -0.11405822965833876, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.00039176465361379087}, {"id": 968, "seek": 575512, "start": 5765.36, "end": 5772.72, "text": " deep. If you could live one day of your life over again, because it made you truly happy,", "tokens": [50876, 2452, 13, 759, 291, 727, 1621, 472, 786, 295, 428, 993, 670, 797, 11, 570, 309, 1027, 291, 4908, 2055, 11, 51244], "temperature": 0.0, "avg_logprob": -0.11405822965833876, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.00039176465361379087}, {"id": 969, "seek": 575512, "start": 5772.72, "end": 5778.08, "text": " or maybe like we said with the books, it was truly transformative, what day, what moment would you", "tokens": [51244, 420, 1310, 411, 321, 848, 365, 264, 3642, 11, 309, 390, 4908, 36070, 11, 437, 786, 11, 437, 1623, 576, 291, 51512], "temperature": 0.0, "avg_logprob": -0.11405822965833876, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.00039176465361379087}, {"id": 970, "seek": 575512, "start": 5778.08, "end": 5783.84, "text": " choose? Does something pop into your mind? Does it need to be a day in the past, or can it be a", "tokens": [51512, 2826, 30, 4402, 746, 1665, 666, 428, 1575, 30, 4402, 309, 643, 281, 312, 257, 786, 294, 264, 1791, 11, 420, 393, 309, 312, 257, 51800], "temperature": 0.0, "avg_logprob": -0.11405822965833876, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.00039176465361379087}, {"id": 971, "seek": 578384, "start": 5783.84, "end": 5790.72, "text": " day in the future? Well, space-time is an emerging phenomena, so it's all the same anyway. Okay.", "tokens": [50364, 786, 294, 264, 2027, 30, 1042, 11, 1901, 12, 3766, 307, 364, 14989, 22004, 11, 370, 309, 311, 439, 264, 912, 4033, 13, 1033, 13, 50708], "temperature": 0.0, "avg_logprob": -0.17223291577033276, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.009699584916234016}, {"id": 972, "seek": 578384, "start": 5791.92, "end": 5797.6, "text": " Okay, from the past. You're really going to say from the future, I love it. No, I will tell you", "tokens": [50768, 1033, 11, 490, 264, 1791, 13, 509, 434, 534, 516, 281, 584, 490, 264, 2027, 11, 286, 959, 309, 13, 883, 11, 286, 486, 980, 291, 51052], "temperature": 0.0, "avg_logprob": -0.17223291577033276, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.009699584916234016}, {"id": 973, "seek": 578384, "start": 5797.6, "end": 5802.96, "text": " from the future. Okay, from the past. So from the past, I would say when I discovered my AXI model,", "tokens": [51052, 490, 264, 2027, 13, 1033, 11, 490, 264, 1791, 13, 407, 490, 264, 1791, 11, 286, 576, 584, 562, 286, 6941, 452, 316, 55, 40, 2316, 11, 51320], "temperature": 0.0, "avg_logprob": -0.17223291577033276, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.009699584916234016}, {"id": 974, "seek": 578384, "start": 5803.68, "end": 5808.0, "text": " I mean, it was not in one day, but it was one moment where I realized", "tokens": [51356, 286, 914, 11, 309, 390, 406, 294, 472, 786, 11, 457, 309, 390, 472, 1623, 689, 286, 5334, 51572], "temperature": 0.0, "avg_logprob": -0.17223291577033276, "compression_ratio": 1.699530516431925, "no_speech_prob": 0.009699584916234016}, {"id": 975, "seek": 580800, "start": 5808.72, "end": 5815.44, "text": " comagor of complexity. I didn't even know that it existed, but I discovered sort of this compression", "tokens": [50400, 395, 559, 284, 295, 14024, 13, 286, 994, 380, 754, 458, 300, 309, 13135, 11, 457, 286, 6941, 1333, 295, 341, 19355, 50736], "temperature": 0.0, "avg_logprob": -0.1650982697804769, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.012812770903110504}, {"id": 976, "seek": 580800, "start": 5815.44, "end": 5820.64, "text": " idea myself, but immediately I knew I can't be the first one, but I had this idea. And then I", "tokens": [50736, 1558, 2059, 11, 457, 4258, 286, 2586, 286, 393, 380, 312, 264, 700, 472, 11, 457, 286, 632, 341, 1558, 13, 400, 550, 286, 50996], "temperature": 0.0, "avg_logprob": -0.1650982697804769, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.012812770903110504}, {"id": 977, "seek": 580800, "start": 5820.64, "end": 5825.68, "text": " knew about sequential decisionary, and I knew if I put it together, this is the right thing.", "tokens": [50996, 2586, 466, 42881, 3537, 822, 11, 293, 286, 2586, 498, 286, 829, 309, 1214, 11, 341, 307, 264, 558, 551, 13, 51248], "temperature": 0.0, "avg_logprob": -0.1650982697804769, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.012812770903110504}, {"id": 978, "seek": 580800, "start": 5826.32, "end": 5832.32, "text": " And yeah, still when I think back about this moment, I'm super excited about it.", "tokens": [51280, 400, 1338, 11, 920, 562, 286, 519, 646, 466, 341, 1623, 11, 286, 478, 1687, 2919, 466, 309, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1650982697804769, "compression_ratio": 1.6576576576576576, "no_speech_prob": 0.012812770903110504}, {"id": 979, "seek": 583232, "start": 5832.4, "end": 5837.679999999999, "text": " Was there any more details in context that moment? Did an apple fall in your head?", "tokens": [50368, 3027, 456, 604, 544, 4365, 294, 4319, 300, 1623, 30, 2589, 364, 10606, 2100, 294, 428, 1378, 30, 50632], "temperature": 0.0, "avg_logprob": -0.20078574732730264, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.008978050202131271}, {"id": 980, "seek": 583232, "start": 5840.0, "end": 5846.08, "text": " So like if you look at Ian Goodfellow talking about gans, there was beer involved. Is there", "tokens": [50748, 407, 411, 498, 291, 574, 412, 19595, 2205, 69, 21348, 1417, 466, 290, 599, 11, 456, 390, 8795, 3288, 13, 1119, 456, 51052], "temperature": 0.0, "avg_logprob": -0.20078574732730264, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.008978050202131271}, {"id": 981, "seek": 583232, "start": 5847.2, "end": 5853.12, "text": " some more context of what sparked your thought, or was it just? No, it was much more mundane. So I", "tokens": [51108, 512, 544, 4319, 295, 437, 39653, 428, 1194, 11, 420, 390, 309, 445, 30, 883, 11, 309, 390, 709, 544, 43497, 13, 407, 286, 51404], "temperature": 0.0, "avg_logprob": -0.20078574732730264, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.008978050202131271}, {"id": 982, "seek": 583232, "start": 5853.12, "end": 5857.36, "text": " worked in this company. So in this sense, the four and a half years was not completely wasted.", "tokens": [51404, 2732, 294, 341, 2237, 13, 407, 294, 341, 2020, 11, 264, 1451, 293, 257, 1922, 924, 390, 406, 2584, 19496, 13, 51616], "temperature": 0.0, "avg_logprob": -0.20078574732730264, "compression_ratio": 1.5793991416309012, "no_speech_prob": 0.008978050202131271}, {"id": 983, "seek": 585736, "start": 5857.599999999999, "end": 5867.36, "text": " So and I worked on an image interpolation problem. And I developed quite neat new", "tokens": [50376, 407, 293, 286, 2732, 322, 364, 3256, 44902, 399, 1154, 13, 400, 286, 4743, 1596, 10654, 777, 50864], "temperature": 0.0, "avg_logprob": -0.16723911812964906, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.003427606774494052}, {"id": 984, "seek": 585736, "start": 5867.36, "end": 5872.16, "text": " interpolation techniques, and they got patented. And then, you know, which happens quite often,", "tokens": [50864, 44902, 399, 7512, 11, 293, 436, 658, 1947, 6003, 13, 400, 550, 11, 291, 458, 11, 597, 2314, 1596, 2049, 11, 51104], "temperature": 0.0, "avg_logprob": -0.16723911812964906, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.003427606774494052}, {"id": 985, "seek": 585736, "start": 5872.16, "end": 5875.839999999999, "text": " I got sort of overboard and thought about, you know, yeah, that's pretty good, but it's not the", "tokens": [51104, 286, 658, 1333, 295, 49480, 293, 1194, 466, 11, 291, 458, 11, 1338, 11, 300, 311, 1238, 665, 11, 457, 309, 311, 406, 264, 51288], "temperature": 0.0, "avg_logprob": -0.16723911812964906, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.003427606774494052}, {"id": 986, "seek": 585736, "start": 5875.839999999999, "end": 5881.2, "text": " best. So what is the best possible way of doing interpolation? And then I thought, yeah, you", "tokens": [51288, 1151, 13, 407, 437, 307, 264, 1151, 1944, 636, 295, 884, 44902, 399, 30, 400, 550, 286, 1194, 11, 1338, 11, 291, 51556], "temperature": 0.0, "avg_logprob": -0.16723911812964906, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.003427606774494052}, {"id": 987, "seek": 588120, "start": 5881.2, "end": 5886.48, "text": " want the simplest picture, which is if you coarse-grain it, recovers your original picture.", "tokens": [50364, 528, 264, 22811, 3036, 11, 597, 307, 498, 291, 39312, 12, 70, 7146, 309, 11, 7759, 840, 428, 3380, 3036, 13, 50628], "temperature": 0.0, "avg_logprob": -0.19326316976101598, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.0010318201966583729}, {"id": 988, "seek": 588120, "start": 5886.48, "end": 5892.96, "text": " And then I thought about the simplicity concept more in quantitative terms. And yeah, then", "tokens": [50628, 400, 550, 286, 1194, 466, 264, 25632, 3410, 544, 294, 27778, 2115, 13, 400, 1338, 11, 550, 50952], "temperature": 0.0, "avg_logprob": -0.19326316976101598, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.0010318201966583729}, {"id": 989, "seek": 588120, "start": 5892.96, "end": 5898.96, "text": " everything developed. And somehow the full beautiful mix of also being a physicist and", "tokens": [50952, 1203, 4743, 13, 400, 6063, 264, 1577, 2238, 2890, 295, 611, 885, 257, 42466, 293, 51252], "temperature": 0.0, "avg_logprob": -0.19326316976101598, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.0010318201966583729}, {"id": 990, "seek": 588120, "start": 5898.96, "end": 5905.12, "text": " thinking about the big picture of it, then led you to probably beg with ice. Yeah. So as a physicist,", "tokens": [51252, 1953, 466, 264, 955, 3036, 295, 309, 11, 550, 4684, 291, 281, 1391, 4612, 365, 4435, 13, 865, 13, 407, 382, 257, 42466, 11, 51560], "temperature": 0.0, "avg_logprob": -0.19326316976101598, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.0010318201966583729}, {"id": 991, "seek": 588120, "start": 5905.12, "end": 5909.28, "text": " I was probably trained not to always think in computational terms, you know, just ignore that", "tokens": [51560, 286, 390, 1391, 8895, 406, 281, 1009, 519, 294, 28270, 2115, 11, 291, 458, 11, 445, 11200, 300, 51768], "temperature": 0.0, "avg_logprob": -0.19326316976101598, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.0010318201966583729}, {"id": 992, "seek": 590928, "start": 5909.28, "end": 5913.12, "text": " and think about the fundamental properties which you want to have.", "tokens": [50364, 293, 519, 466, 264, 8088, 7221, 597, 291, 528, 281, 362, 13, 50556], "temperature": 0.0, "avg_logprob": -0.21667856099654217, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0008165372419171035}, {"id": 993, "seek": 590928, "start": 5913.92, "end": 5919.04, "text": " So what about if you could really live one day in the future? What would that be?", "tokens": [50596, 407, 437, 466, 498, 291, 727, 534, 1621, 472, 786, 294, 264, 2027, 30, 708, 576, 300, 312, 30, 50852], "temperature": 0.0, "avg_logprob": -0.21667856099654217, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0008165372419171035}, {"id": 994, "seek": 590928, "start": 5919.759999999999, "end": 5925.04, "text": " When I solve the AGI problem. In practice, in practice. So in theory,", "tokens": [50888, 1133, 286, 5039, 264, 316, 26252, 1154, 13, 682, 3124, 11, 294, 3124, 13, 407, 294, 5261, 11, 51152], "temperature": 0.0, "avg_logprob": -0.21667856099654217, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0008165372419171035}, {"id": 995, "seek": 590928, "start": 5925.04, "end": 5930.0, "text": " I have solved it with the IHC model, but in practice. And then I asked the first question.", "tokens": [51152, 286, 362, 13041, 309, 365, 264, 286, 39, 34, 2316, 11, 457, 294, 3124, 13, 400, 550, 286, 2351, 264, 700, 1168, 13, 51400], "temperature": 0.0, "avg_logprob": -0.21667856099654217, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0008165372419171035}, {"id": 996, "seek": 590928, "start": 5930.639999999999, "end": 5934.16, "text": " What would be the first question? What's the meaning of life?", "tokens": [51432, 708, 576, 312, 264, 700, 1168, 30, 708, 311, 264, 3620, 295, 993, 30, 51608], "temperature": 0.0, "avg_logprob": -0.21667856099654217, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0008165372419171035}, {"id": 997, "seek": 593416, "start": 5934.4, "end": 5939.599999999999, "text": " I don't think there's a better way to end it. Thank you so much for talking today. It's", "tokens": [50376, 286, 500, 380, 519, 456, 311, 257, 1101, 636, 281, 917, 309, 13, 1044, 291, 370, 709, 337, 1417, 965, 13, 467, 311, 50636], "temperature": 0.0, "avg_logprob": -0.16328128317128057, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.018818901851773262}, {"id": 998, "seek": 593416, "start": 5939.599999999999, "end": 5943.36, "text": " a huge honor to finally meet you. Yeah, thank you too. It was a pleasure of mine side too.", "tokens": [50636, 257, 2603, 5968, 281, 2721, 1677, 291, 13, 865, 11, 1309, 291, 886, 13, 467, 390, 257, 6834, 295, 3892, 1252, 886, 13, 50824], "temperature": 0.0, "avg_logprob": -0.16328128317128057, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.018818901851773262}, {"id": 999, "seek": 593416, "start": 5944.5599999999995, "end": 5948.16, "text": " Thanks for listening to this conversation with Marcus Hutter. And thank you to our", "tokens": [50884, 2561, 337, 4764, 281, 341, 3761, 365, 26574, 389, 9947, 13, 400, 1309, 291, 281, 527, 51064], "temperature": 0.0, "avg_logprob": -0.16328128317128057, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.018818901851773262}, {"id": 1000, "seek": 593416, "start": 5948.16, "end": 5954.5599999999995, "text": " presenting sponsor, Cash App. Download it, use code LEX Podcast. You'll get $10 and $10 will go", "tokens": [51064, 15578, 16198, 11, 27016, 3132, 13, 32282, 309, 11, 764, 3089, 11378, 55, 29972, 13, 509, 603, 483, 1848, 3279, 293, 1848, 3279, 486, 352, 51384], "temperature": 0.0, "avg_logprob": -0.16328128317128057, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.018818901851773262}, {"id": 1001, "seek": 593416, "start": 5954.5599999999995, "end": 5959.44, "text": " to first, an organization that inspires and educates young minds to become science and", "tokens": [51384, 281, 700, 11, 364, 4475, 300, 32566, 293, 2400, 1024, 2037, 9634, 281, 1813, 3497, 293, 51628], "temperature": 0.0, "avg_logprob": -0.16328128317128057, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.018818901851773262}, {"id": 1002, "seek": 595944, "start": 5959.44, "end": 5964.96, "text": " technology innovators of tomorrow. If you enjoy this podcast, subscribe on YouTube,", "tokens": [50364, 2899, 5083, 3391, 295, 4153, 13, 759, 291, 2103, 341, 7367, 11, 3022, 322, 3088, 11, 50640], "temperature": 0.0, "avg_logprob": -0.14997726611876755, "compression_ratio": 1.496031746031746, "no_speech_prob": 0.16006438434123993}, {"id": 1003, "seek": 595944, "start": 5964.96, "end": 5970.32, "text": " give it five stars on Apple Podcasts, support on Patreon, or simply connect with me on Twitter", "tokens": [50640, 976, 309, 1732, 6105, 322, 6373, 29972, 82, 11, 1406, 322, 15692, 11, 420, 2935, 1745, 365, 385, 322, 5794, 50908], "temperature": 0.0, "avg_logprob": -0.14997726611876755, "compression_ratio": 1.496031746031746, "no_speech_prob": 0.16006438434123993}, {"id": 1004, "seek": 595944, "start": 5970.32, "end": 5977.12, "text": " at Lex Friedman. And now let me leave you with some words of wisdom from Albert Einstein.", "tokens": [50908, 412, 24086, 17605, 1601, 13, 400, 586, 718, 385, 1856, 291, 365, 512, 2283, 295, 10712, 490, 20812, 23486, 13, 51248], "temperature": 0.0, "avg_logprob": -0.14997726611876755, "compression_ratio": 1.496031746031746, "no_speech_prob": 0.16006438434123993}, {"id": 1005, "seek": 595944, "start": 5977.839999999999, "end": 5985.599999999999, "text": " The measure of intelligence is the ability to change. Thank you for listening and hope to see you", "tokens": [51284, 440, 3481, 295, 7599, 307, 264, 3485, 281, 1319, 13, 1044, 291, 337, 4764, 293, 1454, 281, 536, 291, 51672], "temperature": 0.0, "avg_logprob": -0.14997726611876755, "compression_ratio": 1.496031746031746, "no_speech_prob": 0.16006438434123993}, {"id": 1006, "seek": 595944, "start": 5985.599999999999, "end": 5986.879999999999, "text": " next time.", "tokens": [51672, 958, 565, 13, 51736], "temperature": 0.0, "avg_logprob": -0.14997726611876755, "compression_ratio": 1.496031746031746, "no_speech_prob": 0.16006438434123993}], "language": "en"}