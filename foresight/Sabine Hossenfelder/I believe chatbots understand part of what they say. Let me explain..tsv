start	end	text
0	3920	Does an artificially intelligent chatbot understand what it's chatting about?
5120	8800	A year ago I'd have answered this question with clearly not.
8800	12320	It's just a turbocharger to complete or a stochastic parrot,
12320	17520	as people more eloquent than me have put it, though for all I know they too might be chatbots.
17520	22320	But I've now arrived at the conclusion that the AIs that we use today
22320	25760	do understand what they're doing, if not very much of it.
26400	30800	I'm not saying this just to be controversial, I actually believe it, I believe,
30800	34000	though I have a feeling I might come to regret this video.
34000	38720	I got hung up on this question not because I care so much about chatbots,
38720	44000	but because it echoes the often made claim that no one understands quantum mechanics.
44720	50400	But if we can use quantum mechanics, then doesn't that mean that we understand it
50400	56800	at least to some extent? And consequently, if an AI can use language,
56800	60560	then doesn't that mean it understands it at least to some extent?
61440	66240	What do we mean by understanding? Does chatGPT understand quantum mechanics?
66880	71360	And will AI soon be conscious? That's what we'll talk about today.
75680	79280	The question whether a computer program understands what it's doing certainly
79280	85440	isn't new. In 1980, the American philosopher John Searle argued that the answer is no,
85440	89760	using a thought experiment that's become known as the Chinese Room.
89760	94720	Searle imagines himself in a windowless room with a rulebook and a dropbox.
94720	100320	If someone drops him a note written in Chinese, he looks up the symbols in his rulebook.
100320	105440	The rulebook gives him an English translation, which he returns as an answer through a slit in
105440	110480	the door, no dealt drawing on the everyday experience of a professor of philosophy.
110480	115840	Searle argues that the person outside the room might believe that there's someone inside who
115840	121600	understands Chinese. But really, he still doesn't understand the word of it, he's just following
121600	127360	the rules he's been given. Searle argues that a computer program works like that,
127360	131360	without any true understanding, just following the rules.
131360	136080	There are two standard objections that people bring forward against Searle's argument.
136080	142240	One is that the system which understands Chinese isn't just the person inside the room,
142240	148240	but the person including the rulebook. So saying that the person doesn't understand Chinese
148240	153120	might be correct, but doesn't answer the question because in Searle's analogy,
153120	156720	the person alone doesn't represent the computer program.
156800	161600	Another objection is that it might well be correct that Searle and his rulebook don't
161600	167600	understand Chinese, but that's because the input is so limited. Language lacks the physical
167600	173920	information that we have learned to associate with words. Software that had the same physical
173920	179360	information could develop understanding as we do. Unless, of course, we live in a computer
179360	184080	simulation in which case you can file complaints using the contact form in the bottom right corner
184080	189120	of your frontal lobe. I think both of these objections missed the point, but before I explain
189120	194960	that, I want to introduce you to the quantum room. Quantum mechanics works pretty much like
194960	201360	Searle's Chinese room. It's a rulebook, a set of equations with instructions for how to use them.
201360	206000	You give me a question, I look into my rulebook that I keep in my windowless room,
206000	211440	and I return an answer to you through the slit in the door. Do I understand quantum mechanics?
212240	218240	Searle would probably argue no. Indeed, for the most part, physicists today aren't even in the
218240	222960	room, because who wants to spend their time sitting in a windowless room with a dropbox
222960	228800	when they can instead sit in a windowless room with their laser? No, we're now the ones putting
228800	235440	a question into the dropbox, so to speak, by feeding it into a computer. The computer crunches
235440	242320	the numbers and returns an answer. Do we understand those answers? Have we gone too far with shut up
242320	248240	and calculate? Is the room even there when no one looks? Those are all very interesting questions,
248240	253920	but let's not get carried away. We were trying to talk about chatbots, so let's have a look at those.
254480	260400	Today's language generating models are somewhat more sophisticated than just lookup tables like
260480	266800	Searle imagined, and what better way is there to explain how they work than asking one itself?
268160	272400	Language generating models, like me, are built using deep learning techniques,
272400	277600	specifically a type of neural network. These models are trained on large amounts of text data,
277600	282800	such as books, articles, and websites, and learn to generate language by identifying patterns
282800	287600	and relationships between words and phrases. When generating language, the model takes an
287600	292240	initial input, such as a prompt or a question, and uses the patterns it has learned to generate a
292240	297680	response. The generated text is not simply copied from the training data, but rather the model uses
297680	305520	the patterns it has learned to create new, original text. Well, that was not awkward at all, but yes,
305520	311520	neural networks indeed learn similar to how humans learn. They don't just memorize input,
311520	318160	they identify patterns and extrapolate them. They still have many differences to the human brain,
318160	324320	at least at the moment. Most importantly, the neurons in a neural network are themselves
324320	330320	part of the algorithm and not physical as they are in the human brain. And the human brain
330320	336480	has a lot more structure with parts specialized for particular purposes, but neural networks do
336560	343040	capture some aspects of how humans learn. And that brings us to the first important point when
343040	348880	it comes to the question of understanding. Suppose you have children in elementary school
348880	355440	and have them memorize the multiplication tables up to 10. If you want to test whether they understood
355440	362160	multiplication, you asked them something that wasn't on the tables. We want to test whether
362160	368640	they have identified the pattern and can use it on something else. If you're in the Chinese room
368640	375600	with a long list of examples, you can't answer a question that isn't on the list. This is indeed
375600	381920	not what anyone means by understanding, so I'd say Sol is right on that account. But this is
381920	388320	not what neural networks do. Neural networks do instead exactly what we mean by understanding
388320	394080	when we apply it to humans. They extract the pattern and apply it to something they haven't
394080	400400	seen before. But this brings up another question. How do you know that that's what it's doing?
401040	406560	If you ask a child to multiply two numbers, how do you know they haven't just memorized the result?
407280	414160	Well, you don't. If you want to know whether someone or something understands, looking at the
414160	420800	input and output isn't enough. You could always produce the output by a lookup table rather than
420800	426560	with a system that has learned to identify patterns. And you can well understand something
426560	432800	without producing any output, like you might understand this video without any output other
432800	439440	than maybe the occasional frown. I'd therefore say that what we mean by understanding something
439440	444320	is the ability to create a useful model of the thing we're trying to understand.
444880	451040	The model is something I have in my head that I can ask questions about the real thing and that
451040	457920	it's useful means it has to be reasonably correct. It captures at least some properties of the real
457920	464720	thing. In mathematical terms, you might say there's an isomorphism, a one-to-one map between the model
464720	472400	and the real thing. I have a model, for example, for cows. Cows stand on meadows, have four legs
472400	478880	and sometimes go moo. If you pull in the right place, moo comes out. Not a particularly sophisticated
478880	484560	model, I admit, but I'll work on it once cows start watching YouTube. Understanding then is
484560	489840	something that happens inside a system. You can probe parts of this understanding with input
489840	495920	output tests, but that alone can't settle the question. When we're talking about neural networks,
495920	502000	however, we actually know they're not lookup tables because we've programmed them and trained
502000	508160	them. So we can be pretty sure they actually must have a model of the thing they've been trained for
508800	514720	somewhere in their neural weights. In fact, at this moment in the history of mankind, we can be
514720	519840	more confident that neural nets understand something than your average first grader because,
519840	525280	for all we can tell, the first graders just ask a chatbot. Let's then look at the question of
525280	532560	who understands what and why. We have a model of the human body in our brain. This allows us to
532560	539120	understand what effects our movements will have, how humans move in general, and which parts belong
539120	546640	where. We notice immediately if something is off. But if you train an AI on two-dimensional images,
546640	553200	it doesn't automatically map those images onto a 3D model. This is why it'll sometimes create
553200	559200	weird things like people with half a leg or three arms or something like that. This, for example,
559200	565760	is mid-journey trying to show a person tying their shoelaces. They look kind of right because it's
565760	571120	what the AI was trained to do to produce an image that looks kind of right, but they don't actually
571120	577120	capture the real thing. If you take understanding to mean that it has a model of what's going on,
577120	583840	then these AIs almost certainly understand the relation between shadows and lights. But does it
583840	589360	know that shadows and light are created by electromagnetic radiation bouncing off or being
589360	595520	absorbed by three-dimensional bodies? It can't because it never got that information.
595520	601680	You can instead give an AI a 3D model and train it to match images to that 3D model.
601680	607040	This is basically how deep fakes work. And in this case, I'd say that the AI actually does
607040	613680	partly understand the motion of certain body parts. The issue with chatbots is more complicated
613680	619920	because language is much more loosely tied to reality than videos or photographs. Language
619920	624800	is a method that humans have invented to exchange information about these models that
624800	632400	we have in our own heads. Written language is, moreover, a reduced version of spoken language.
632400	637920	It does capture some essence of reality in relations between words. And if you train a neural
637920	644640	network on that, it'll learn those relations, but a lot of information will be missing. Take
644640	651280	the sentence, what goes up must come down. That's, for reasonably common initial conditions,
651280	657520	a statement about Newton's law of gravity. Further text analysis might tell you that by
657520	663600	down we mean towards the ground, and that the ground is a planet called Earth, which is a sphere,
663600	670720	and so on. From that alone, you may have no idea what any of these words mean, but you know how
670720	676720	they are related. And indeed, if you ask chatGPT what happens when you throw a stone into the air,
676800	681440	it'll tell you the bluntly obvious and several flawlessly correct paragraphs.
682160	688560	But the language model can't do more than try to infer relations between words
688560	694800	because it didn't get any other data. This is why chatGPT is ridiculously bad at anything that
694800	700800	requires, for example, understanding spatial relationships, like latitude. I asked it whether
700800	706080	Windsor UK is further north or south than Toronto, Canada, and they told me,
706640	713440	Windsor is located at approximately 51.5 degrees north latitude, while Toronto is located at
713440	720720	approximately 43.7 degrees north latitude. Therefore, Toronto is further north than Windsor.
720720	727680	It'll quote the latitudes correctly, but draw the exactly wrong conclusion. It's a funny mistake
727680	732960	because it'd be easy to fix by quiping it with a three-dimensional model of planet Earth,
732960	737120	but it doesn't have such a model. It only knows the relations between words.
737760	743360	For the same reason chatGPT has some rather elementary misunderstandings about quantum mechanics.
743920	750560	But let me ask you first. Imagine you have two entangled particles and you separate them.
750560	756160	One goes left and the other goes right, but like couples after a fight, they're still linked,
756160	762720	whether they want to or not. That they are entangled means that they share a measurable property,
762720	768480	but you don't know which particle has which share. It could be, for example, that they each
768480	775200	either have spin plus or minus one, and the spin has to add up to zero. If you measure them,
775200	781280	either the one going left has spin plus one and the one going right minus one or the other way
782080	788800	and if you measure one particle, you know immediately what the spin of the other particle is.
788800	794800	But let's say you don't measure them right away. Instead, you first perform an operation on one of
794800	800320	the particles. This is physics, so when I say operation, I don't mean heart surgery, but
800320	806880	something a little more sophisticated. For example, you flip its spin. Such an operation is not a
806880	812560	measurement because it doesn't allow you to determine what the spin is. If you do this on
812560	818720	one particle, what happens to the other particle? If you don't know the answer, that's perfectly
818720	824640	fine because you can't answer the question from what I've told you. The correct answer is that
824640	831040	nothing happens to the other particle. This is obvious if you know how the mathematics works
831040	838240	because if you flip the spin, that operation only acts on one side. But it's not obvious from a
838240	843840	verbal description of quantum mechanics, which is why it's a common confusion in the popular
843840	850960	science press. Because of that, it's a confusion that chat GPT is likely to have too. And indeed,
850960	857360	when I asked that question, it got it wrong. So I'd recommend you don't trust chat GPT on
857360	864320	quantum mechanics until it speaks fluent latich. But ask it any word-related question and it
864320	870880	shines. One of the best uses for chat GPT that I have found is English grammar or word use questions.
870880	877120	As I was working on this video, for example, I was wondering whether Dropbox is actually a word
877120	882240	or just the name of an app. How am I supposed to know? I've never heard anyone use the word for
882240	889040	anything besides the app. If you type this question into your search engine of choice,
889040	895280	the only thing you get is a gazillion hits explaining how Dropbox the app works.
896080	902000	Ask the question to chat GPT and it'll tell you that yes, Dropbox is a word that English
902000	908880	native speakers will understand. For the same reason, chat GPT is really good at listing pros
908880	915600	and cons for certain arguments because those are words which stand in relation to the question.
915600	921200	It's also good at finding technical terms and keywords from rather vague verbal descriptions.
921920	928160	For example, I asked it, what's the name for this effect where things get shorter when you move at
928160	934560	high speed? It explained, the name of the effect you are referring to is length contraction or
934560	939120	Lawrence contraction. It is a consequence of the theory of special relativity.
939680	944080	Which is perfectly correct. But don't ask it how English words are pronounced,
944080	949520	it makes even more mistakes than I do. What does this tell us about whether we
949520	956080	understand quantum mechanics? I've argued that understanding can't be inferred from the relation
956080	962240	between input and output alone. The relevant question is instead whether a system has a model
962240	967680	of what it's trying to understand, a model that it can use to explain what's going on.
968320	975120	And I'd say this is definitely the case for physicists who use quantum mechanics. I have a
975120	980960	model inside my head for how quantum mechanics works. It's a set of equations that I have used
980960	986800	many times that I know how to apply and use to answer questions. And I'm sure the same is the
986800	992480	case for other physicists. The problem with quantum mechanics is that those equations
992480	999200	do not correspond to words we use in everyday language. Most of the problems we see with
999200	1005520	understanding quantum mechanics come from the impossibility of expressing the equations in words.
1006160	1011360	At least in English. For all I know, you can do it in Chinese. Maybe that explains why the
1011360	1017440	Chinese are so good with quantum technologies. It is of course possible to just convert equations
1017440	1023760	into words by reading them out. But we normally don't do that. What we do in science communication
1023760	1031040	is kind of a mixture with metaphors and attempts to explain some of the maths. And that conveys
1031040	1038080	some aspects of how the equations work. But if you take the words too literally, they stop making
1038080	1044320	sense. But equations aren't necessary for understanding. You can also gain understanding
1044320	1050080	of quantum mechanics by games or apps that visualize the behavior of the equations,
1050080	1056000	like those that I talked about in an earlier video. That too will allow you to build a model
1056000	1062480	inside your head for how quantum mechanics works. This is why I'd also say that if we use computer
1062560	1069120	simulations and visualizations in science, especially for complex problems, that doesn't mean
1069120	1075360	we've given up on understanding. Visualizing the behavior of a system and probing it and seeing
1075360	1082080	what it does is another way of building a model in your head. There is another reason why physicists
1082080	1086800	say they don't understand quantum mechanics, which is that it's internally inconsistent.
1086800	1091680	I've talked about this a few times before and it's somewhat off topic here, so I don't want to get
1091680	1097280	into this again. Let me just say that there are problems with quantum mechanics that go beyond
1097280	1103840	the difficulty of expressing it in words. So where will the AI boom leaders? First of all,
1103840	1109440	it's rather foreseeable that before long, we'll all have a personalized AI that'll offer anything
1109440	1115520	from financial advice to relationship counseling. The more you can afford to pay, the better it'll
1115520	1120720	be and the free version will suggest you marry the Prince of Nigeria. Of course, people are going
1120720	1125840	to complain it'll destroy the world and all, but it'll happen anyway because when has the risk
1125840	1130880	of destroying the world ever stopped us from doing anything if there was money to make with it?
1131440	1136400	The best and biggest AIs will be those of big companies and governments,
1136400	1142960	and that's almost guaranteed to increase wealth disparities. We're also going to see YouTube
1142960	1150160	flooded by human avatars and other funky AI-generated visuals because it's much faster and cheaper
1150160	1155440	than getting a human to retext or go out and film that old-fashioned thing called reality.
1156000	1161120	But I don't think this trend will last long because it'll be extremely difficult to make
1161120	1167280	money with it. The easier it becomes to create artificial footage, the more people will look
1167280	1172800	for authenticity, so that stupid German accent might eventually actually be good for something.
1172800	1178240	If nothing else, it makes me difficult to simulate. Will AI eventually become conscious?
1178800	1184320	Of course. There's nothing magic about the human brain, it's just a lot of connections that process
1184320	1190880	a lot of information. If we can be conscious, computers can do it too, and it will happen
1190880	1198320	eventually. How will we know? Like understanding, you can't probe consciousness just by observing
1198320	1204400	what goes in and comes out. If you'd really want to know, you'd have to look what's going on inside
1204400	1210160	and at the moment, that wouldn't help because we don't know how to identify consciousness in any
1210160	1216880	case. Basically, we can't answer the question. But personally, I find this extremely interesting
1216880	1223040	because we're about to create an intelligent species that'll be very different from our own.
1223040	1227120	And if we're dumb enough to cause our own extinction this way, then I guess that's what
1227120	1233280	we deserve. Meanwhile, enjoy the ride. At least for now, the best tool we have for understanding
1233280	1238800	the world is the human brain. But if you really want to understand quantum mechanics or neural
1238800	1245200	networks, then passively watching a video isn't enough. You have to actively engage with the
1245200	1251600	material. Brilliant.org, who have been sponsoring this video, is a great place for that. Brilliant
1251600	1257760	offers courses on a large variety of subjects in science and mathematics, and they add new content
1257760	1263920	every month. The great thing about their courses is that they're all interactive with visualizations
1263920	1270000	and follow-up questions. So you can check right away whether you can apply what you've learned,
1270000	1276000	and that's really what understanding is all about. What I need to freshen up my knowledge or want to
1276000	1282400	learn something new, first thing I do is look it up on Brilliant. To get some background on the physics
1282400	1288240	in this video, check out, for example, their courses on neural networks and quantum objects,
1288240	1295200	or even better, check out my own course about quantum mechanics. My course gives you an introduction
1295200	1301600	to interference, superpositions and entanglement, the uncertainty principle, and Bell's theorem.
1302240	1307360	You don't need to be an expert to take this course. I've worked together with Brilliant so
1307360	1312560	that you can start from the very basics. If you're interested in trying Brilliant out,
1312560	1318800	use our link brilliant.org slash Sabine and sign up for free trial, where you'll get to try out
1318800	1324800	everything Brilliant has to offer for 30 days. The first 200 subscribers using this link will also
1324800	1333600	get 20% off the annual premium subscription. Thanks for watching. See you next week.
