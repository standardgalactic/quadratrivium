start	end	text
0	4560	What should you do if you're spending too much time on social media, asking for a friend?
5440	10320	Well, you try to convince yourself that social media is actually good for, well,
10320	15680	something. It's gotta be good for something, right? But they say that social media increases
15680	20400	polarization and gets you stuck in echo chambers full of fake news and so on.
21200	25200	How bad is social media? That's what we'll talk about today.
26000	35840	Social media has changed society profoundly. About 60% of the world's population now uses
35840	42160	social media. It has made it vastly easier to find people all over the globe to connect with them
42160	50240	and to get insulted by them. What does that do to society? It's complicated. American social
50240	56240	psychologists Jonathan Haidt and sociologist Chris Bayer have compiled a public Google doc
56240	62000	in which they collect references on questions such as, does social media make people angrier?
62000	67920	And does social media create political echo chambers? The most relevant thing you learn
67920	73200	from this document is that whatever your opinion, you can find a paper that supports it.
73200	78400	Honestly, I began working on this video thinking it'll end up being one big shrug,
78400	84160	because that's how sociology generally looks like to a physicist. But it turns out it isn't
84160	91360	quite as bad. You just have to be really careful with phrasing the question. For example, you may
91360	97280	remember the headlines claiming that fake news spreads faster than the truth. Then again,
97280	102320	there were headlines saying that those headlines about fake news were themselves fake news.
102880	107840	What is going on? Well, the original headlines were based on a 2018
107840	114560	paper published in Science by researchers at MIT. The authors compared how true and false
114560	124480	news stories spread on Twitter. They had a sample of about 126,000 news items from 2006 to 2017,
124480	131520	tweeted by about 3 million people over 4.5 million times. So not a small study.
131520	136560	These news items were classified as true or false according to certain fact-tracking
136560	142000	organizations. The conclusion of the study was, in the authors' own words, that
142000	148320	falsehood diffused significantly farther, faster, deeper and more broadly than the truth
148320	155120	in all categories. The facts were most pronounced for false political news. And it wasn't a small
155120	161440	difference. They found that it took two stories approximately six times as long as false stories
161520	169280	to reach 1,500 people. But in 2021, other researchers pointed out that the 2018 paper
169280	175280	looked at news that had been fact-checked by certain organizations, but that those organizations pay
175280	181840	more attention to news that have already spread quite successfully. An article in Science then
181840	187520	claimed that this means the original study had been debunked. This is why you've seen the
187520	193760	headline saying news about fake news is fake news. That wasn't the end of the story. Because the
193760	199600	authors of the original study then said they'd never claimed their study applies to all fake news,
199600	205280	it had just been misreported. And the authors of the new study said they had never claimed the
205280	211680	earlier study was wrong because they knew it had been misreported. Then the author of the Science
211760	217360	News article who had claimed that the misreported fake news study was fake news
217360	223920	apologized that his article had misreported this story. I hope that clarifies it. But wait,
223920	231520	what does all of that mean now? Do fake news spread better or do they not? The answer is they do,
231520	237680	but it turns out that the major difference between true news and fake news is that fake news spread
237680	243840	to a larger audience. And since they appeal to a larger audience, they also spread faster.
244400	249920	But if you compare true and false stories that have reached an audience of the same size,
249920	256880	then the sharing pattern looks the same. This was the point of the 2021 paper. It's not like fake
256880	262720	news networks have a different connectivity. The size of the audience that they attract is the
262720	268480	major difference. And yes, that was strictly speaking only demonstrated for fake news stories
268480	274400	that were fact-checked by certain organizations. One of the authors made this diagram to show
274400	280000	the difference between what they said they did and what the headlines said they did. But the
280000	285840	authors also say they're reasonably confident their finding will carry over to false news more
285840	292480	generally, but that remains to be seen. I'm guessing there are people working on this as we speak.
292480	298160	But the 2018 science paper made an interesting point that didn't spread widely. They found
298160	304640	that bots accelerated the spread of true and false news equally. This means that if false news
304640	310960	spreads better than the truth, that's because humans are more likely to spread false news.
310960	316800	We can't blame it on the bots. The authors conjecture that the reason may be that people
316800	321520	like novelty and it's easier to be original with something that's made up.
321520	327680	Anecdotal evidence. I had my first encounter with fake news on Facebook in 2016 when Trump
327680	334720	ran for president. It was a quote attributed to Trump from some anti-Republican Facebook page
334720	339920	shared by an American friend. Several people pointed out that there was no evidence Trump
339920	346240	actually said that. The guy who shared it reacted by saying it's funny even if it isn't true.
346240	351440	And that's why false news spreads. We share it for reasons other than accuracy,
351440	356720	because it's funny or upsetting or because it allows us to express our own opinion.
356720	362000	Whether it's true doesn't really matter for that. The problem is that the next person who
362000	368160	comes across shared fake news believes that the person who shared it believed it to be true
368160	373600	and is therefore more likely to also believe it to be true. What can be done about it?
373600	379040	It's easier than you think. Because most people agree that fake news is bad and they're actually
379040	385200	quite good at spotting it. You just have to occasionally remind them to think before sharing.
385200	389360	At least this was the conclusion of a paper published in Nature last year.
390000	396720	The authors recruited about a thousand Americans and presented them with 36 actual news stories
396720	402400	taken from social media. Half of the headlines were false and half were correct.
402400	407360	Half favorable to Democrats and the other half favorable to Republicans.
407360	412560	The participants were then asked to evaluate the accuracy of the news items.
413200	419360	They quite reliably rated correct headlines as correct and false ones as false.
419360	425360	And while they did rate headlines in favor of their own political orientation as correct more often
425360	431440	than those in favor of the other camp, the partisan influence was much smaller than that of the
431440	437920	actual accuracy of the headline. So the problem is not that we're just bad at spotting bad news.
438640	444960	But the authors also found that whether the headlines were right or wrong had little effect
444960	452080	on whether people intended to share a news item. They then encouraged people to consider the accuracy
452080	459520	of the news item and afterwards asked again how likely they'd share it. This simple tactic led
459520	466240	to a big reduction of the intention to share false news but didn't affect the intention to share real
466240	473120	news. According to the paper, accuracy often has little effect on sharing because the social
473120	479840	media context focuses users' attention on other factors such as the desire to attract and please
479840	485440	followers and friends or to signal one's group membership. According to another paper that just
485440	492000	appeared two months ago, the misinformation problem is particularly pronounced in the United States.
492560	498400	The authors of the paper found that while people from the UK, Canada, Australia and New Zealand
498400	504640	are exposed to misinformation on social media at about the same rate, Americans are three times
504640	510480	more likely to share it. Earlier this year a review paper in the journal Nature Medicine
510480	515760	looked at the spread of misinformation about public health in particular by reviewing one
515760	522080	and a 23 papers. The two major conclusions that the author draws from his literature survey is that
522080	527520	A. people are sometimes duped by misinformation just because they are distracted or not paying
527520	534080	attention and B. some people believe in and share misinformation because it reinforces their beliefs.
534640	540080	So that's consistent with what the other papers had found. As to what to do about it,
540080	545440	one thing he suggests is also just reminding people to think about accuracy before sharing.
546000	551440	Another interesting suggestion he has is to give people information about the tactics of
551440	557840	misinformation spreaders with browser games. There are two of those games, one is called
557840	564640	Go Viral and the other one Get Bad News. Studies have found that people who played these games
564640	570400	were much better at spotting health-related misinformation. You can try them out yourself,
570400	576080	links are in the info below. I think this is a really good idea and I'd like to have a game
576080	582400	like this about physics please. So yes, social media spreads a lot of misinformation. The good
582400	589040	side of social media is that it also seems to generally benefit information literacy. In 2018,
589120	595840	a team of American researchers recruited almost 3,000 Americans. They offered half of them $20
595840	602480	to deactivate their Facebook accounts for four weeks just prior to the 2018 midterm elections.
602480	607520	Four weeks later, those who disconnected from Facebook were less able to correctly answer
607520	613360	factual questions about recent news events. But they also reported increased well-being
613360	619520	and less political polarization. Let's therefore look at what we know about polarization and
619520	625760	echo chambers. If you watched a few of my videos on quantum mechanics, soon all your recommended
625760	632480	videos will be about quantum mechanics. Suddenly, the whole world is quantum mechanics. Such an
632480	639120	echo chamber seems to be an inevitable side effect of algorithms that want to help you find what
639120	646240	you're interested in. And as a result, you get more of the same. This leads to the dreaded
646240	651600	conspiracy rabbit holes that you fall into on YouTube as it happened to me when I was working
651600	657920	on my video on flat earthers, though YouTube seems to have tweaked their algorithm since to prevent
657920	664640	that from happening quite as easily. These more of the same algorithms help you make contact with
664640	670800	people who think like yourself. So the idea that we live in echo chambers sounds plausible.
670800	678080	But plausible ideas are the ones you should be most skeptical about. What does the data say?
678080	684160	According to a 2021 paper by a group from the University of Oxford, echo chamber issues are
684160	690240	real, but the problem has been hugely overstated. They looked at surveys from seven different
690240	696560	countries in which people reported what news they typically consumed. Turns out, only about
696560	702160	five percent of social media users are properly stuck in a political echo chamber in which they
702160	709520	almost exclusively consume news from one political side. Though the numbers differ somewhat by country,
709520	715440	the overall largest fraction of people in echo chambers is that of the American left.
715520	721440	The previously mentioned Chris Bale is lead author of a 2018 paper about an experiment
721440	728400	in which they try to get people out of their echo chambers. They surveyed about 1,500 Americans,
728400	734640	about half Democrats and the other half Republicans, who visited Twitter at least three times each
734640	741040	week. After one week of tracking, a randomly selected group of those people was offered
741040	747200	$11 to follow a Twitter bot for one month, but they were not informed about the purpose of the study.
747760	753280	The bot initially just tweeted landscape pictures, but then began tweeting opinions
753280	759840	that promoted the participants' opposing political ideology. At the end of the month,
759840	767200	the participants were surveyed again. Turned out that Republicans who followed a liberal Twitter bot
767200	774000	became even more conservative. The more they were exposed, the larger the effect. For Democrats,
774000	779600	the change was not statistically significant. By the way, Chris Bale is the director of an
779600	785680	institute called the Polarization Lab that lets you check how deeply stuck in an echo chamber
785680	792560	you are on Twitter. Turns out, rather unsurprisingly, I'm deeply stuck in a liberal camp. That's what
792560	798400	you get when you mostly follow people with PhDs. The question whether social media increases
798400	804000	polarization in society has been extensively studied, especially in the United States.
804640	809840	The risk, sociologists say, is that social media makes it easier to find people whose
809840	816640	opinions we like and we get encouraged by like-minded people to distance ourselves from the perceived
816640	824560	enemy. Indeed, in 2018, a leaked internal presentation at Facebook warned senior executives
824560	830880	that Facebook algorithms exploit the human brain's attraction to divisiveness and that,
830880	836480	if left unchecked, the algorithm would feed users more and more divisive content
836480	841600	in an effort to gain user attention and increase time on the platform.
841600	846560	Now, it's quite well established among sociologists already that increased levels
846560	852400	of polarization in society are associated with an erosion of constructive political debate,
852400	858320	social trust and inter-party cooperation. The question we're interested in here is whether
858320	865600	social media increases this polarization. In 2021, researchers from the UK and the US
865600	872080	set out to answer the question whether out-group animosity drives engagement on social media.
872640	879440	They analyzed almost 3 million Twitter posts by news media accounts and US congressional members.
879440	886240	They found that posts about the political out-group were shared or retweeted about twice as often
886240	892000	as posts about the in-group. And almost all of the posts about the other political camp were
892000	898000	negative, leading to more negative engagement. Again, though, you have to be really careful
898000	903680	to keep in mind what question a study was asking in the first place, because this finding doesn't
903680	910720	necessarily mean that the negative engagement cost polarization to increase. It might just mean
910720	917840	that social media is a good platform to live out your feelings. Just which way the causation goes
917840	924000	is at the moment rather unclear. For one thing, a study from 2017 found that self-reported
924000	930240	polarization is higher among elderly Americans who are less likely to be online to begin with.
930240	935600	Another thing to keep in mind is that the USA isn't the only country in the world.
935600	942000	A team of American researchers pointed out last year that while social media usage has increased
942000	948400	worldwide, polarization has not. It has increased in the US, but in many other countries,
948400	956320	polarization has in fact decreased. Indeed, a 2021 study among more than 3,000 Dutch citizens
956320	963600	found that self-reported polarization correlates with social media use, but the causation goes from
963600	969440	polarization to social media use and it depends on the platform you're using. At least in the
969440	975360	Dutch sample, people who became politically more polarized spent more time on Facebook,
975360	980800	but less time on Twitter. It's hard to interpret what this means, because God knows what's up
980800	987200	with Dutch Twitter. But I think what we can take away from this is that the idea that more social
987200	994000	media use increases polarization is almost certainly too simple to be correct. What happens
994080	1000400	depends both on cultural context and on platform design. So what do we learn from all this?
1001280	1007200	Most obviously, we learn that this is a very active research area. I certainly hope that the
1007200	1014160	results will eventually lead to better algorithms for social media. While we wait for that to happen,
1014160	1020240	I think the best we can do is focus on the part that's in our hands, which is to decide what we
1020240	1026640	pay attention to and what we share. What I have taken away from all those papers is that we have
1026640	1033520	to be especially careful with headlines that upset us. Yes, they might get a lot of comments,
1033520	1039040	but they might also spread misinformation and hate. So be careful out there.
1039040	1043920	How has Sabina talking about nuclear power one day and about social media the other day?
1043920	1050080	Is she omniscient? I'm afraid the answer is no. I work with several other people who help me
1050080	1055840	sort through the scientific literature to bring the information to you. And the only reason this
1055840	1062400	works is thanks to our sponsors. Today's episode was made possible by MelScience,
1062400	1067840	which is a subscription service for science experiments. And I have to say, my family's
1067840	1072960	having a lot of fun with their products. MelScience has experiments for children in
1072960	1078000	different age categories and different scientific disciplines. And not only this,
1078080	1083520	their experiments come together with AR in VR lessons and live online classes.
1084080	1089600	The experiment I got this week is a gyroscope labelled for children aged five and up. It's
1089600	1095760	a great opportunity to talk about color perception and the preservation of angular momentum and the
1095760	1101600	solar system and why we always see the same side of the moon and why the length of the day depends
1101600	1107440	on which way the wind blows. And well, I guess I got a little carried away there. I found the
1107440	1115120	MelScience experiment extremely well designed and also high quality products. This is not
1115120	1121040	cheap stuff that breaks when you touch it. It works like you expect it to work. And of course,
1121040	1126720	we do have a special offer for viewers of this channel. You can get 50% off the first month
1126720	1132880	for any MelScience subscription if you use our link in the info below or scan the QR code. So
1132880	1142560	go check it out. Thanks for watching. See you next week.
