WEBVTT

00:00.000 --> 00:06.080
Hello, everyone. I would like to welcome you to our course categories for AI.

00:09.040 --> 00:15.600
In the following weeks, we'll discuss the exciting and rising role that category theory has in deep

00:15.600 --> 00:21.040
learning. It's something incredibly interesting, and we're happy to be able to share this with you.

00:24.000 --> 00:28.160
My name is Brona Gavranovic. I'm a PhD student at the University of Strathclyde,

00:28.160 --> 00:32.320
and I'm bringing this course to you together with the rest of the organizing team,

00:32.880 --> 00:42.560
Andrew, Joao, Pim and Petar. We are all in some way affiliated with deep learning category theory,

00:42.560 --> 00:48.880
or both, and interested in talking about technologies that will benefit us all,

00:48.880 --> 00:56.560
and we'll all want to use. So the first question we want to answer is, why categories for AI?

00:58.800 --> 01:05.360
The reason is simple. We believe in a future where all deep learning experts will use some

01:05.360 --> 01:17.040
aspects of category theory in their work. Now, deep learning is a new field, and as it's often

01:17.040 --> 01:24.080
the case with new fields, with new scientific fields, they start in an ad hoc manner, and then

01:24.080 --> 01:30.160
later these fields are understood differently than they were by their early practitioners.

01:31.840 --> 01:37.680
So for example, in taxonomy, people have been grouping plants and animals for thousands of years,

01:37.680 --> 01:42.800
but the way we understood what we were doing changed a lot in light of evolution and molecular

01:42.800 --> 01:49.200
biology. In chemistry, we have explored chemical reactions for a long time, but our understanding

01:49.200 --> 01:56.880
changed a lot with the discovery of the atom. And then in programming, people started to program

01:56.880 --> 02:03.120
by tinkering with transistors and logic gates, but most of what we call programming is heavily

02:03.120 --> 02:15.040
abstracted from that. And then now we have deep learning. Deep learning, despite its remarkable

02:15.040 --> 02:22.480
success, is a field permeated by ad hoc design choices. So as we all know, neural networks,

02:22.480 --> 02:29.600
neural network architectures have all these knobs and tweaks that we can't formally justify just yet.

02:30.720 --> 02:39.360
We keep being surprised by new architectures such as GPT-3 or stable diffusion, and there is no

02:39.440 --> 02:44.960
unifying framework for deep learning. There is no unifying framework that would explain the

02:44.960 --> 02:50.480
probabilistic perspective, the neuroscience perspective, and merely just the gradient-based

02:50.480 --> 02:56.640
iterative updating perspective. In fact, in the future, we might look at deep learning very differently.

02:58.000 --> 03:02.800
And our claim is that category theory will become the unifying deep learning framework.

03:03.680 --> 03:09.040
As a matter of fact, it might become a general theory of neural network architecture,

03:09.040 --> 03:13.200
architectures, and such an essential tool for deep learning practitioners.

03:15.280 --> 03:20.800
Now, this is certainly a bold claim, but it is the one we hope to substantiate in this course.

03:23.280 --> 03:29.520
So what is category theory? If I had to describe category theory in one sentence,

03:29.520 --> 03:36.560
it would be this one. Category theory takes a bird's-eye view of mathematics. From high in the

03:36.640 --> 03:42.320
sky, details become invisible, but we can spot patterns that were impossible to detect from

03:42.320 --> 03:49.520
ground level. The famous quote accurately describes what category theory has done to mathematics.

03:50.640 --> 03:56.800
As we'll see, it's not taking a bird's-eye view of just mathematics, but it started to do that

03:56.800 --> 04:02.000
to all of science in the form of a new wave that is being called applied category theory.

04:02.800 --> 04:07.760
So before we do anything, I just want to give you a one-slide summary of what applied category

04:07.760 --> 04:15.440
theory is and what we hope to teach you in this course. Applied category theory is a particular

04:15.440 --> 04:20.320
way of structuring your knowledge. It's grounded in the idea of compositionality.

04:22.240 --> 04:26.720
It originated in pure mathematics and has since spread to numerous fields.

04:26.720 --> 04:35.680
This is a formal language that is not just a part of these many fields, but it's being used to build

04:35.680 --> 04:43.840
bridges between these fields that were previously unknown. So other than in pure mathematics where

04:43.840 --> 04:51.280
it's, which it permeates, it has been emerging across the sciences. So it's been found in physics,

04:51.360 --> 04:57.680
it's been found in chemistry, it's been found in systems theory. It is all over computer science

04:57.680 --> 05:04.560
and it is the theoretical foundation of functional programming. It has been found in game theory,

05:04.560 --> 05:10.560
in information theory, control theory, probability theory, cryptography, and many others.

05:13.040 --> 05:19.280
For us, the most relevant is deep learning where there has been a number of recent papers

05:19.280 --> 05:27.600
in the last two or three years. Now, many people haven't heard of category theory and that might be

05:27.600 --> 05:32.240
because it started being applied across the sciences only in the last five years or so.

05:33.360 --> 05:37.920
So here we see a graph of the intersection of papers in category theory and machine learning.

05:38.960 --> 05:47.600
As you can see, we are in very early stages. We have just had our fifth applied category theory

05:47.600 --> 05:53.600
conference, the only one, and the only existing applied category theory journal just published

05:53.600 --> 06:01.680
its fourth volume. So this recency of category theory might be one of the reasons it is difficult

06:01.680 --> 06:09.200
to teach. For all of its expressive power, it's an notoriously difficult subject to learn.

06:10.080 --> 06:14.240
As it originated in abstract mathematics, most introductory material

06:14.240 --> 06:21.440
is not aimed at the general audience of programmers or scientists in general. There are a few exceptions.

06:23.360 --> 06:29.760
So definitions in category theory are extremely information dense. For example, a monad,

06:29.760 --> 06:35.360
the concept of a monad shown on this slide has a number of components satisfying a number of rules.

06:36.320 --> 06:39.840
And then each of these components is often information dense as well,

06:39.840 --> 06:46.160
meaning category theory requires a lot of initial investment to start appreciating.

06:49.200 --> 06:55.120
But once you start learning category theory and start appreciating the definitions,

06:55.120 --> 07:00.560
you see that the definitions form an incredibly cohesive theory, really not found anywhere else

07:00.560 --> 07:07.360
in science. These interplay together at such a remarkable level, which is hard to appreciate

07:07.360 --> 07:12.960
when you're just starting to learn it. It often looks very difficult. And on a graph,

07:14.160 --> 07:20.960
the learning process looks something like this. So compared to traditional methods,

07:20.960 --> 07:25.680
the structural method of category theory takes a long time to get started. But once you do,

07:25.680 --> 07:34.080
the theory scales much better. So in some sense, category theory is a theory of how to scale up

07:34.160 --> 07:41.600
our systems. And this is something we want to teach you in this course. We want to teach you

07:41.600 --> 07:47.280
how to approach category theory, motivated with some practical examples from deep learning,

07:47.840 --> 07:51.760
and really give you a sense of the philosophy behind category theory.

07:54.480 --> 08:00.640
So this is week one. And after today's lecture, which is going to be an introductory

08:00.720 --> 08:09.440
lecture to the general thoughts of category theory, we're going to start going into the details.

08:11.200 --> 08:16.080
In week two, we will be studying essential building blocks of category theory, categories

08:16.080 --> 08:22.160
and functors. In week three, we will study how category theory can be used to describe back

08:22.160 --> 08:27.440
propagation using monoidal categories, admitting a visual and intuitive graphical language.

08:28.400 --> 08:32.880
In week four, we'll study how geometric deep learning and naturality

08:34.240 --> 08:42.080
and have their foundations in category theory. We're going to study natural graph networks.

08:44.160 --> 08:49.760
And lastly, in week four, we will see how monoids, monads, and various algebraic structures

08:49.760 --> 08:53.360
can be connected to recurrent neural networks and LSTMs.

08:57.440 --> 09:01.360
After our five weeks of lectures, we have a series of talks by people who are

09:01.360 --> 09:06.400
in the industry doing category theory deep learning or both. And we are very excited about those.

09:11.440 --> 09:18.400
But yes, in today's lecture, we're going to start by studying what is compositionality,

09:19.360 --> 09:25.280
what is category theory really, what you need to start learning and taking advantage of it,

09:25.280 --> 09:31.520
perhaps the most important thing. And we're going to take a look at what category theory

09:31.520 --> 09:41.760
has done and can do for deep learning. So yeah, let's get started. So what is compositionality?

09:41.760 --> 09:47.600
This is a concept I've mentioned, which is central to category theory. And it's a concept

09:47.600 --> 09:53.760
that's often misunderstood. It's often presented as an ability to build systems together by

09:53.760 --> 10:01.600
composing them out of smaller subsystems. Now, this is certainly a component of compositionality,

10:01.600 --> 10:09.360
but this is not all. Compositionality includes the ability to build the systems, but we don't

10:09.360 --> 10:15.280
just want to build a very complex system that we can't reason about. It includes the ability to

10:15.280 --> 10:21.360
reason about the resulting system recursively in terms of its components. And really,

10:21.360 --> 10:27.680
compositionality is more of a property of the model of our system than the system itself.

10:28.960 --> 10:33.120
So we're going to see what that means. Compositionality requires both of these things.

10:33.680 --> 10:39.680
And for many models of our systems that are found throughout nature, we have the first

10:39.680 --> 10:43.760
property that we can build the system, but not the second one that we can reason about it.

10:44.560 --> 10:52.400
So for example, when we study behaviors of markets, of organizations, of economy,

10:52.400 --> 11:01.120
of neural networks, and many other concepts, these things aren't compositional. Now, what does

11:01.120 --> 11:07.840
that mean? These are very fuzzily defined concepts, but they're precisely very fuzzily defined only

11:07.840 --> 11:12.400
because we don't know how to reason about them from outside. We don't know what are the fundamental

11:12.400 --> 11:16.560
building blocks, and we don't know how to reason about the behavior of, say, the global economy

11:17.360 --> 11:22.160
by studying behavior of economies of individual countries. There's many emergent effects that

11:22.160 --> 11:27.520
are happening and that are hard to track. On the other hand, there are many systems,

11:28.080 --> 11:34.000
many models of our systems that have both one and two. For instance, and these are often very

11:34.000 --> 11:38.560
simple systems. We think of them as simple because we understand them. So for example, if we have two

11:38.560 --> 11:43.520
differentiable functions, we can put them together and get a composite differentiable

11:43.520 --> 11:50.160
functions by using the chain rule. If we have a compiler from a language A to language B,

11:50.160 --> 11:55.120
and a compiler from language B to language C, we get a joint compiler that compiles all the way

11:55.120 --> 12:02.400
through. We can compose various things like Markov kernels. We can compose merely polynomials and so

12:02.560 --> 12:12.480
on. There's many kinds of systems. Now, this slide, if you're seeing this, this might

12:14.160 --> 12:19.520
ring some alarm bells. It might seem like I've said something inconsistent here. It might seem like

12:19.520 --> 12:29.520
we are saying this. So it certainly looks like I said differentiable functions like

12:29.520 --> 12:34.240
compositional. And I said neural networks are made out of differentiable functions. Therefore,

12:34.240 --> 12:39.440
neural networks are compositional, but I said they're not. So this meme might look like what

12:39.440 --> 12:44.000
we're saying, but really what we're saying is the following. Compositional with respect to what.

12:45.280 --> 12:50.000
So I said compositionality is a property of our models, and we have to specify what

12:50.800 --> 12:56.240
our model is, what it is that we're studying. It's important to specify the property of the

12:56.240 --> 13:01.600
system we want to model. So if our model treats neural networks as differentiable functions,

13:01.600 --> 13:07.120
then, indeed, neural networks are compositional. We plug together a bunch of differentiable

13:07.120 --> 13:13.360
functions, and using automatic differentiation, we can compute, or chain rule, really, we can

13:13.360 --> 13:21.440
compute the derivative of the composite. But if our model treats neural networks as

13:21.440 --> 13:25.360
generative or discriminative models, then this is not compositional.

13:28.160 --> 13:32.960
It's important to specify what property we're studying and what exactly are we modeling.

13:35.200 --> 13:45.360
Really, compositionality is about interfaces. If you think about a system composed of many

13:45.360 --> 13:53.920
smaller subsystems, and the simplest case here is that of a function. When we compose these

13:53.920 --> 13:59.440
systems, we want to ensure that all the data we need is available at the exposed interfaces.

14:03.520 --> 14:09.920
So really, if we have three functions like this, the famous property of associativity

14:09.920 --> 14:15.920
tells us that if we compose f and g, and then with h, that should be the same as composing g

14:15.920 --> 14:23.280
with h and then with f. So this famous property posits that function composition should be

14:23.280 --> 14:29.440
associated. But why is this the property that you might want to have? Because it allows us to treat

14:29.440 --> 14:38.080
functions extensionally, only by looking at their interfaces. And if these composites are the same,

14:38.080 --> 14:43.200
then function composition is associative. And we can look at only the input and output of the

14:43.200 --> 14:48.320
system to know how it behaves. And we don't need to know anything about its internals or how it was

14:48.320 --> 14:58.880
built. But if this property isn't satisfied, then we might be in trouble. Non-compositionality implies

14:58.880 --> 15:05.920
that we need extra data to reason about the system, data that isn't available through the interfaces.

15:06.880 --> 15:11.280
But if our method of interaction is only through the interfaces, which is the intended way of

15:11.280 --> 15:15.600
interacting, then this means that we have uncertainty about how the system will behave.

15:16.800 --> 15:23.600
And then composing many such systems together, our uncertainty can only grow.

15:26.480 --> 15:32.320
Really, what we want to is minimize this uncertainty by imposing some invariances of how we

15:32.960 --> 15:37.920
put systems together. So that's when we create a bigger system, we know something about how it

15:37.920 --> 15:44.400
behaves. So really, compositionality is a very delicate property. And I'm a fan of this quote

15:45.040 --> 15:51.920
on the bottom of this slide, which tells us that it is so powerful that it is worth going to extreme

15:51.920 --> 16:00.080
lengths to achieve. So this is what category theory is. It's the study of compositionality,

16:00.160 --> 16:05.520
of how we can put systems together. And to my surprise, when I started to learn it,

16:05.520 --> 16:11.520
it's not really just about functions. Functions were an example here that is simple. But category

16:11.520 --> 16:17.280
theory studies all sorts of complex systems, from trees on the top left, to networks on the top

16:17.280 --> 16:22.640
right, to circuits on the bottom left, to bi-directional transformations on the bottom right.

16:23.440 --> 16:31.840
So with this in mind, we can start describing what category theory is. Even though we're talking

16:31.840 --> 16:39.280
about all sorts of abstract systems and gadgets, category theory is still a precise mathematical

16:39.280 --> 16:46.960
language to talk about it. It's the kind of language that emphasizes relationships between

16:46.960 --> 16:53.120
concepts as opposed to concepts themselves. And we're going to see what that means shortly.

16:56.240 --> 17:02.160
And we're going to see that particular structures in category theory have

17:02.160 --> 17:10.320
visual representations that aren't just doodles or sketches. They are former representations

17:10.320 --> 17:16.240
that can be manipulated, even in a computer. So to give you a sense of what this really is,

17:16.240 --> 17:22.800
I'm going to have a very short demo where I'm going to just draw a few things. So I'm going to

17:24.400 --> 17:28.480
switch to

17:34.560 --> 17:44.240
my iPad and just give you a sense of how these things work. So I said category theory is a

17:44.240 --> 17:52.960
unifying language for mathematics. And to appreciate what this means, we can perhaps focus

17:52.960 --> 18:01.200
on some subfield of mathematics, like say group theory. So in group theory, we might want to

18:01.200 --> 18:08.160
study a particular group. And a central concept in group theory is that of a group homomorphism.

18:08.160 --> 18:15.040
If you have two groups, we can have a structure preserving a mapping between them. And then we

18:15.040 --> 18:19.200
can have many mappings and they can go between groups themselves and so on. And there could be

18:19.200 --> 18:23.520
many groups that we want to study. Maybe some of them are not connected and so on.

18:30.000 --> 18:34.720
And we can study about various properties of these groups and study how they behave. Now,

18:34.720 --> 18:43.680
separately, in set theory, we might have some set and we might study functions between set one

18:43.680 --> 18:49.520
and set two. These are really honest to God functions that we can compose. And maybe there's

18:50.160 --> 18:57.040
S3, S4. And there's various kinds of structures that we can study between them. It's a very rich

18:57.040 --> 19:01.680
and intricate field. And I'm going to write here set and I'm going to write here group.

19:02.640 --> 19:09.840
Then again, if we're studying, for instance, we might study vector spaces or similar things. So

19:09.840 --> 19:14.320
for instance, I have a vector space one and a vector space two. I can still study some sort

19:14.320 --> 19:19.280
of structure preserving mapping between these, between these other structures. And for instance,

19:19.280 --> 19:26.880
this could be just merely vector spaces in a field R. Now, what category theory does is

19:27.680 --> 19:33.040
gives us this bird eye view of these things. All of these structures are categories. So here

19:33.040 --> 19:38.080
we have a category of groups. Here we have a category of sets. And here we have a category

19:38.080 --> 19:48.800
of vector spaces. And all of these structures are special examples of category teams. The same way

19:48.800 --> 19:54.720
we have studied structure preserving maps between groups, group homomorphisms,

19:55.600 --> 20:00.160
by formulating all the groups as a category. Now we can study structure preserving maps

20:00.800 --> 20:08.400
of these categories, which are called functors. So for instance, we might have a functor from

20:08.400 --> 20:13.280
the category of groups to the category of sets, which takes a group and gives us the underlying

20:13.280 --> 20:19.120
set. Or we might have a functor that takes a set and gives us the free vector space on a set and so

20:19.120 --> 20:27.840
on. The idea being that once we have lifted ourselves to this abstract level, a lot of

20:27.840 --> 20:33.680
new things open up to us. So what we end up studying is a lot of interesting things like

20:33.680 --> 20:40.880
the category of, let's say, let's call them systems with a particular interface, input and

20:40.880 --> 20:46.080
output. And we can have a system with internal state S1 and S2. And we can say the ways these

20:46.080 --> 20:50.720
are related. And then we can study categories of systems with a different interface and map

20:50.720 --> 20:57.600
between them and so on. And these systems can be actual processes, computations that do something

20:57.600 --> 21:02.960
very interesting. That isn't just sort of what you might think of as strictly mathematical.

21:05.360 --> 21:10.480
And lastly, we might study categories. These categories might have a lot of interesting

21:10.480 --> 21:17.040
structure. For example, I've drawn here a monoidal category where we can sort of put

21:17.040 --> 21:27.280
two objects in parallel, as opposed to just composing maps sequentially. And then in category

21:27.280 --> 21:32.320
theory where it turns out that these monoidal categories, that's what they're called, where

21:32.320 --> 21:37.360
we can put things in parallel, have a formal visual representation. So the story is a bit more

21:37.360 --> 21:42.960
intricate, but you can think of it as taking this category and mapping it into a visual space

21:42.960 --> 21:49.280
where each morphism has a specific shape. And you can draw it as boxes. So now these boxes

21:49.280 --> 21:53.280
aren't just sketches and doodles, but they're formal mathematical objects.

22:07.440 --> 22:23.520
So let me just switch to my other screen. Right, so this was merely aimed to paint a picture of how

22:23.520 --> 22:29.760
these things look. And finishing with the monoidal categories in this demo,

22:30.160 --> 22:40.880
these allow us to have a very natural visual language for talking about systems and processes.

22:40.880 --> 22:45.920
And these are really, this is an example of what might, of a particular process of making a pie.

22:45.920 --> 22:52.560
And we've all seen these things. So this is not something new. But it allows us, and it gives

22:52.560 --> 22:59.360
us a very different perspective on these things. So when you're doing category theory, you might

22:59.360 --> 23:04.160
be studying various sorts of systems and processes that do various sorts of things. And

23:04.160 --> 23:08.880
in category theory, there's concepts discovered or invented by various people for studying these

23:08.880 --> 23:14.480
things. So if we're studying resources or processes in this way, we might use monoidal categories.

23:16.960 --> 23:22.560
If we want to study probability, for instance, we will use Markov categories. So for instance,

23:22.560 --> 23:27.040
on the left side, here we see a process which takes an input, applies a function to it,

23:27.520 --> 23:34.240
and then copies the result. On the right, we first copy the result and then apply f

23:34.240 --> 23:41.120
individually on inputs. Now, if f is merely a function, then these two processes are equal.

23:41.120 --> 23:46.880
And in many other cases, they're equal. But not all of them. If f is a stochastic function,

23:47.680 --> 23:52.080
then these are not equal because rolling a dice and then copying the result doesn't give us the

23:52.080 --> 23:57.840
same result as rolling two dice. So Markov categories allow us to describe such processes

23:57.840 --> 24:03.760
at the needed level of generality. Then we might, if you want to study how local systems,

24:03.760 --> 24:08.880
how behavior of local systems gives rise to the behavior of a global system,

24:08.880 --> 24:14.720
you might want to use sheeps. Then again, if you want to study bi-directional transformations,

24:14.800 --> 24:22.800
such as extracting a row from a database, then updating back, so forward and backward.

24:22.800 --> 24:27.360
Or if you want to study neural networks, a forward pass and a backward pass,

24:28.160 --> 24:31.840
we might want to use optics and lenses, which are bi-directional data structures.

24:34.480 --> 24:39.040
Then again, if you want to study contextual computation or computation with side effects,

24:39.040 --> 24:42.960
we might want to use things called monads or their Kleisler categories.

24:44.640 --> 24:51.200
And of course, in computer science, the concept permeating it is recursion. And then we might

24:51.200 --> 24:57.600
want to use things called final co-algebras or initial algebras to study recursive processes.

25:00.800 --> 25:05.840
And once we study all of these things, we might find ourselves in this situation

25:06.480 --> 25:12.880
where we study a bunch of different kinds of systems with different kinds of categories and

25:12.880 --> 25:17.600
concepts. And that ends up just creating more categories and more concepts. And the theory

25:17.600 --> 25:23.600
that studies category theory is called two-category theory. So something I love about the way you

25:23.600 --> 25:31.200
approach CT, that it is very meta and recursive in nature, allowing us to describe category theory

25:31.200 --> 25:40.640
using category theory. And then really, once you start going with this, you might have heard about

25:40.640 --> 25:46.640
classical mathematical structures such as topological spaces or rings or fields. And once

25:46.640 --> 25:53.120
you start going into category theory, it's hard to appreciate how deep and rich the field is,

25:53.120 --> 25:59.680
because the water keeps getting deeper and deeper and the rabbit hole hides so many concepts that

25:59.680 --> 26:06.080
I personally wasn't aware of that have a very expressive nature and a very compositional nature

26:06.080 --> 26:11.600
in helping us understand all of the systems. This is certainly not the end. There's many more

26:11.600 --> 26:17.600
that every category theorist has a certain understanding of a part of these concepts.

26:20.160 --> 26:28.160
So this was very abstract in a sense, but I hope it conveyed some sense of what category theories

26:29.120 --> 26:35.920
are. But now I would like to make this a bit more concrete and study what is the relationship

26:35.920 --> 26:44.160
between category theory and deep learning? What has been done? How much are these concepts

26:44.160 --> 26:51.680
actually connected to each other? So the thing I want to establish first is that the deep learning

26:51.680 --> 26:57.760
community seems to be very well aware of the concept of compositionality. I have found numerous

26:57.840 --> 27:04.240
workshops, programs, blog posts, lectures saying compositionality is important.

27:05.520 --> 27:08.400
And I've linked a few of them here. I'm sure there's many more.

27:10.080 --> 27:15.600
Joshua Bengio in his Turing lecture actually explicitly states that we need to build

27:15.600 --> 27:24.320
compositionality into our machine learning models. But having studied category theory,

27:24.960 --> 27:30.640
I'm still noticing that compositionality is done in ad hoc ways and that there is a large gap

27:30.640 --> 27:36.160
between how compositionality is thought of in deep learning and the theory of compositionality

27:36.160 --> 27:43.440
that category theory offers. Nonetheless, there have been some recent strides.

27:46.240 --> 27:51.360
So I'd like to give a brief overview of what has been happening on the intersection of

27:51.360 --> 27:59.200
category theory and machine learning. So the papers I am showing here are two papers that

27:59.200 --> 28:05.520
study neural networks in the very abstract, in the form of something called a parametric lens.

28:06.320 --> 28:10.480
We're going to see exactly what that is later in the course, but I just want to give you

28:10.480 --> 28:16.000
an idea of how these things work. So it's something that has a following shape.

28:16.000 --> 28:24.080
And it abstractly models the information flow we see in a neural network. So on the left side,

28:24.080 --> 28:28.960
we see inputs and their gradients. On the right side, we see outputs of a neural network and

28:28.960 --> 28:36.560
their gradients. And here we take the two-dimensional notation seriously, and therefore we have weights

28:36.560 --> 28:43.520
coming from top, weights and their gradients. And this abstractly models how the information flows.

28:43.520 --> 28:48.720
So we can see that from left and top, we get inputs and parameters, compute and output,

28:49.280 --> 28:55.360
and then having received the gradients of the loss with respect to that output, we can back

28:55.360 --> 29:02.000
propagate the gradients with respect to the input to the left and back propagate the

29:03.520 --> 29:06.640
gradients of the loss with respect to weights to the top.

29:07.600 --> 29:14.320
Now, the question you might ask is what is the benefit of this formulation?

29:14.320 --> 29:19.440
Why would we model it like this? Well, when these constructions were originally discovered

29:19.440 --> 29:26.960
a few years ago, something fascinating happened. Independently, game theorists were modeling

29:26.960 --> 29:34.000
economic agents in game theory using these categorical models. And to the big surprise,

29:34.000 --> 29:38.720
these models ended up having the same categorical form as the machine learning ones.

29:40.320 --> 29:46.400
So if you're studying economic agents that take some inputs, produce some outputs,

29:46.400 --> 29:50.880
receive some payoff for their things and have their trying to maximize some strategy,

29:51.440 --> 29:57.680
you end up with a model that has the same shape. So independent formalizations by different people

29:57.680 --> 30:03.760
of game theory and machine learning converge to the same mathematical form. This elucidated

30:03.760 --> 30:09.520
a number of connections and really sparked a whole study of cybernetic systems or reinforcement-like

30:10.640 --> 30:15.200
agent systems, the study of agents interacting with the environment using minimal assumptions

30:15.200 --> 30:19.760
about what agents or the environment is. And really, this is something that can't be done

30:19.760 --> 30:26.240
without the level of generality that category theory provides. So I found this quite fascinating

30:26.240 --> 30:33.520
as it was being discovered. And it's one of the reasons why I, it allows me to study machine

30:33.520 --> 30:42.320
learning in game theory through a unified, unified lens. What it also turned out that why would we

30:42.320 --> 30:46.640
want to use these parametric lenses that we can also model optimizers of neural networks.

30:48.400 --> 30:53.440
So, and what it ended up turning out that optimizers of neural networks have the same shape

30:53.440 --> 30:58.800
as neural networks themselves. So on the top here, the idea is, so on the left and right,

30:58.960 --> 31:04.480
we have parameters, but on top we have the state saved by these optimizers, the stateful ones like

31:04.480 --> 31:11.440
momentum or add-on. And this gives us hints that optimizers are some kind of hardwired

31:11.440 --> 31:16.320
meta learners and just as some papers have shown. So there's lots of interesting research opening

31:16.320 --> 31:21.120
up to this. And an interesting thing from a personal standpoint happened with regards to

31:21.120 --> 31:26.080
optimizers. We started formalizing gradient descent using lenses, this concept that I

31:26.080 --> 31:31.520
mentioned that models by directionality. And for a long time actually had suspicions about

31:31.520 --> 31:38.240
this formalization. The problem was that there was a part of a lens that really wasn't used at all

31:38.240 --> 31:44.560
in gradient descent, casting reasonable doubt on whether lenses are the right abstraction.

31:45.920 --> 31:51.360
Maybe they are really an overgeneralization. But then as we went on to formalize more

31:51.360 --> 31:57.600
complicated optimizers, such as the one that used Nestor of momentum, we found that the bit

31:57.600 --> 32:03.040
that computes the look ahead in Nestor of momentum, the one that's always lost over in explanations

32:03.040 --> 32:08.160
and when you implement these things, it requires rethinking about how you structured the stuff.

32:08.160 --> 32:12.000
It had a natural place in our formulation. It was the thing that we didn't use before.

32:13.360 --> 32:19.120
So really, from a personal standpoint, it clarified how a lot of these things fit that we

32:19.120 --> 32:29.920
started using this categorical formulas. And lastly, we're not the only ones using them.

32:29.920 --> 32:37.920
So very recently, about a week ago, I found a deep learning professor at New York University,

32:37.920 --> 32:44.560
if I'm not mistaken, independently starting to use the same sort of graphical notation

32:44.800 --> 32:54.000
as the formal one we have been using. And I'm quite amazed that we were sort of having formal

32:54.000 --> 33:02.400
justification that these two notations have converged to the same representation.

33:04.160 --> 33:08.000
So yeah, this shows one line of work that has been done with machine learning,

33:08.000 --> 33:13.760
with category theory. Other people have studied different things. People have studied recurrent

33:13.760 --> 33:20.160
neural networks. And it has a very strange title here, but if you open the paper, you'll see that

33:20.160 --> 33:25.840
it does study recurrent neural networks. And in recurrent neural networks, we have the

33:25.840 --> 33:30.960
idea of back propagation through time, which is done by unrolling the recurrent neural network.

33:30.960 --> 33:38.560
Now, what this paper showed is an interesting thing that this process of back propagation

33:38.560 --> 33:43.600
through time doesn't merely use differentiation, but it is differentiation

33:44.720 --> 33:49.520
in a very sophisticated way. And it uses the formalism of something called double categories,

33:49.520 --> 33:55.200
which is yet an even more advanced but very visual concept. So this short picture shows you

33:55.200 --> 34:04.640
how you can think of each time step of recurrent neural network as a vertical kind of morphism,

34:04.640 --> 34:07.600
and you can think of layers of neural network as horizontal.

34:13.280 --> 34:20.080
And then Petar and Andrew, who are co-organizers of this course, have done a lot of work on

34:20.080 --> 34:24.400
geometric deep learning and graph neural networks. And they've established a connection between

34:24.400 --> 34:29.440
graph neural networks and dynamic programming, which is quite fascinating because this might

34:29.440 --> 34:33.520
be such very different things, thinking about how graph neural networks work and how

34:34.240 --> 34:39.920
the algorithm of, say, Bellman-Ford works. Yet again, using the abstractions of category theory,

34:39.920 --> 34:50.160
we can say something more precise about this. And generally about, yeah,

34:53.360 --> 34:57.280
in generally about all of these neural networks, this is some of the stuff that has been done.

34:57.600 --> 35:04.160
But really, there is so much more work to be done and so many more things to explore. I've just

35:04.160 --> 35:10.240
given you a glimpse of some of the interesting things, but really, transformers haven't been

35:10.240 --> 35:14.720
studied, have been studied to some small degree, but there's so much work really to do on them,

35:14.720 --> 35:19.600
through category theory. Geometric deep learning is being studied now, actually,

35:19.600 --> 35:25.680
through category theory, but then again, this is such a vast field. And the same holds for

35:26.320 --> 35:32.400
generative adversarial networks, outer regressive models, NLP, these are all things,

35:32.400 --> 35:38.000
all fields, which could benefit from having more and more eyes apply categorical methods.

35:38.000 --> 35:44.160
I think we're at a point where there's so much ideas and thoughts and we're trying to scale up

35:44.160 --> 35:51.440
these processes of studying things categorically. And the only thing we're lacking is resources

35:51.440 --> 36:01.680
and people knowing about this. So this brings us towards the end of today's lecture.

36:03.760 --> 36:12.160
We have seen how ACT is a rising field, how we can study a number of different scientific fields

36:13.920 --> 36:17.280
and really a number of subfields of machine learning through the same lens.

36:18.160 --> 36:24.640
It is based upon compositionality and we've seen how it gives us this uniform description of

36:24.640 --> 36:32.320
processes and concepts. Now, in this lecture, I didn't really go into any of the details. And as

36:32.320 --> 36:40.480
I've said, this is contrary to how category theory is usually defined and introduced. It is very

36:40.480 --> 36:46.320
verbose and mathematical, but once we start going into it, it becomes very hard to gain

36:46.320 --> 36:54.080
the intuition. So what we're trying to aim for in this course is to start slow and to motivate

36:54.080 --> 37:00.160
these examples. So if you want to learn more about how all of these concepts and systems

37:00.800 --> 37:10.000
can be thought of in this uniform way, we invite you to check out the next week's lectures

37:10.000 --> 37:15.440
and to gain a really more precise and concrete understanding of the things I've been saying

37:15.440 --> 37:27.280
about here. And really, to end with this, it's something that we want to communicate that really

37:27.280 --> 37:33.280
applying this category theory to deep learning is one part of what category theory does, but

37:33.280 --> 37:40.320
once you start thinking about this through the categorical lens, things, all things start

37:40.320 --> 37:47.120
looking like category theory. So this is something we hope to communicate. I've put up a number of

37:47.120 --> 37:51.920
references and reading lists here for people to, this slides are going to be put up online,

37:51.920 --> 37:56.080
so you'll be able to click on them and have a look at some of the interesting conceptual things,

37:56.080 --> 38:00.640
some of these are books, some of these are lectures that might be beneficial in getting a sense

38:00.640 --> 38:08.640
of how this works. But yeah, for now, this is the point where I will end, and I would like to

38:08.640 --> 38:13.600
invite you. So we've had a lot of problems actually with the Google groups and people signing up.

38:14.320 --> 38:19.440
If you still want to sign up, please do because we have opened the Zoom link of this lecture

38:20.320 --> 38:25.760
to everyone because not many people, as I said, could join. But if you want to look at the next

38:25.760 --> 38:34.240
lectures, please sign up on the course website and do check out Zulip, which is also linked to

38:34.240 --> 38:38.640
course participants where you can chat about category theory, chat about all of these lectures,

38:38.640 --> 38:44.320
ask questions. This Zulip is a part of the wider applied category theory community,

38:44.320 --> 38:49.520
so you'll be able to see how actual categories chat and the concepts we talk about and how these

38:49.520 --> 38:56.880
things work. Although I would warn you to thread carefully there, some of these things are very

38:56.880 --> 39:05.520
foreign and scary looking, but hopefully by the end of this course they will be less so. So yeah,

39:05.520 --> 39:11.600
thank you very much. Wonderful. Thank you so much, Bruno, for the great talk and the great

39:11.600 --> 39:18.320
introduction to this vast landscape of categories, which as you mentioned, in the coming weeks we

39:18.320 --> 39:25.040
will dive into more, starting with my own lecture next week where we'll talk about the basic objects

39:25.040 --> 39:31.680
in category theory in a more rigorous way. There's a lot of very interesting questions in the Zoom and

39:32.240 --> 39:36.080
I'll be acting as a sort of moderator, reading them out to you and we can do a bit of back and

39:36.080 --> 39:43.520
forth. So the top rated question comes from Matej Zetrovic and it comes with this motivation of

39:43.520 --> 39:48.320
you have probabilistic circuits like some product networks that are compositional with respect to

39:48.320 --> 39:52.880
both conditions that you presented. However, they're not as good as neural networks in terms of

39:52.880 --> 39:58.800
expressivity. So a generative neural network can make better images than the ones from a

39:58.800 --> 40:05.120
generative some product network. So then the question is, should we invest more time into

40:05.120 --> 40:10.480
studying a non-compositional model like neural networks and make them compositional or see how

40:10.480 --> 40:14.720
you can scale something that's inherently compositional like a some product network? What are your thoughts

40:14.720 --> 40:21.760
on this? Yeah, that's an interesting question and as I've mentioned in the beginning,

40:21.840 --> 40:29.360
compositionality is a property of the model of our systems. So to me it seems like the model

40:29.920 --> 40:35.760
that we have of these non-compositional systems might be non-compositional in nature,

40:35.760 --> 40:41.200
which doesn't necessarily mean that the actual model is non-compositional. It might be the fact

40:41.200 --> 40:46.960
that we don't know what the essential composable building blocks are. So I'm not sure if I can

40:46.960 --> 40:54.560
provide a good answer to which of the things we should study. I'm very biased in towards taking

40:54.560 --> 40:59.120
out a system that doesn't seem compositional but feels like it is and then trying to make it so,

40:59.120 --> 41:06.800
trying to understand how information flows and what are the compositional building blocks. So

41:06.800 --> 41:15.040
that would be my answer. All right, the second question comes from Siavash and it's a very quick

41:15.040 --> 41:21.360
one. So what, if anything, is the difference between compositionality versus composability?

41:22.640 --> 41:28.320
Yeah, so these are, this might be a very loosely defined term sometimes composability,

41:28.320 --> 41:32.880
for instance. Some people use composability to mean literally that we can plug together

41:32.880 --> 41:40.080
systems, processes, functions, but then when we plug these things, composable things together,

41:40.320 --> 41:46.480
they, people don't often mean that we can study the behavior of the composite in terms of the

41:46.480 --> 41:51.600
smaller constituents. But then again, I think I found people using, at least in category theory,

41:51.600 --> 41:58.160
the concept of composable only when we can study them, when we can study the

41:59.760 --> 42:04.240
resulting system recursively. So I think you might find like different usages in different

42:04.240 --> 42:09.280
communities. In category theory, this is taken very seriously. So you would call things composable

42:09.280 --> 42:12.320
only if you have some sort of guarantees like this.

42:14.800 --> 42:21.920
Okay, with this top rated from Grigori asks, is there a particular book you would recommend for

42:21.920 --> 42:25.520
beginners? I have a particular book I would recommend, but maybe you have one or two?

42:26.320 --> 42:30.400
Well, maybe you can start with yours. I mean, let's start with seven sketches for sure.

42:33.040 --> 42:38.240
Yeah, I would say that it often depends on where you're coming from. I would say seven

42:38.240 --> 42:43.760
sketches in composition, compositionality linked here is a really good resources for

42:43.760 --> 42:48.480
scientists, engineers, and programmers in general. If you're coming from programming,

42:48.480 --> 42:54.800
specifically, you might want to look at category theory for programmers by Bartosz Mielewski,

42:54.800 --> 43:01.200
that which is a great research as research aims specifically at programmers. I will actually

43:01.200 --> 43:08.000
link in the Zulib. I specifically keep a list of best introductory category theory resources

43:08.000 --> 43:13.520
on my GitHub. So I don't have it here, but I will add it and I will link it in the Zulib,

43:13.520 --> 43:18.320
which includes a number of many more like blog posts, videos and books.

43:19.920 --> 43:25.120
Wonderful. Yeah, that will be very useful, I think, for the attendees. So there is a question

43:25.120 --> 43:30.240
from Kylan, which asks, could you explain a bit more in detail, what does this graphical

43:30.240 --> 43:34.640
representation of your network actually bring us? For example, the diagram you showed from

43:34.640 --> 43:40.000
Alfredo Canziani, you said it seems to be just a diagram. What does it actually help us understand?

43:41.840 --> 43:50.880
Yeah, so this is a really good question. So I will go back to this slide. So the short answer is

43:50.880 --> 43:57.440
it restricts how we're thinking about this and it restricts the things we can do to this diagram.

43:57.440 --> 44:02.800
So this might sound a little bit counterintuitive because we have a language and then it's very

44:02.800 --> 44:11.280
restrictive, but this is in fact a very useful design tool is to constrain ourselves. So I actually

44:11.280 --> 44:18.400
had a quick chat on Twitter with Alfredo and I noticed some of the ways, some of the things,

44:18.400 --> 44:23.040
some of the ways he uses the diagrams to wire up some things were very non-compositional because

44:23.040 --> 44:28.000
when you plug systems together, you wouldn't get a thing of the same kind, but through category

44:28.080 --> 44:34.800
we have found another way to plug these things together to make it compositional. So the answer is

44:34.800 --> 44:40.640
it helps us reason about the systems and really one day I hope we can implement these things.

44:42.720 --> 44:46.240
Because as you'll find when you think about deep learning, there's the whole theory, but the way

44:46.240 --> 44:52.240
implement sometimes has tricks and tweaks and there's not a uniform translation of the theory

44:52.240 --> 45:01.920
into implementation and I think my sort of very long term goal is to have a completely formal and

45:01.920 --> 45:07.280
uniform description of these processes at a high level, but also exactly at a low level

45:07.280 --> 45:15.680
and I think these diagrams help us show this. So maybe to emphasize when we draw these diagrams,

45:15.680 --> 45:21.120
this is exactly how we would implement them. There's not a secret thing going on that you

45:21.120 --> 45:25.760
have to be careful, like you can take these diagrams very, very seriously, which is not something that

45:25.760 --> 45:30.160
can be done with informal notation. I hope that answers the question.

45:31.920 --> 45:37.920
All right, yeah, thanks for that. If the person asking the question wants to follow up, please

45:37.920 --> 45:43.440
feel free to. The current top rated questions and thank you for all these questions, they're really,

45:43.440 --> 45:46.960
really interesting and they keep pouring in, which is great to get this kind of engagement.

45:47.600 --> 45:51.920
We're obviously all happy to keep discussing even after the lecture on Zulip and otherwise.

45:51.920 --> 45:56.960
The top question right now is from Siva and it asks, since categories and geometry have a rich

45:56.960 --> 46:01.040
interaction, can we use category theory to understand the geometry of neural networks,

46:01.040 --> 46:05.520
such as the geometry of its parameter space or the symmetry of space?

46:07.040 --> 46:12.640
Well, yeah, this is another great question and I think Petar might be in a much better position

46:12.640 --> 46:18.240
than me to answer this. I think we both believe the answer is yes, but maybe I'll leave it to Petar

46:18.240 --> 46:25.440
here. Yeah, I mean, I'll just add that so I know that many people who are signed up to attend this

46:25.440 --> 46:29.440
course have already some working knowledge of geometric deep learning where we use geometry

46:29.440 --> 46:35.440
to understand neural network architectures as a covariant functions. And one thing you will see

46:35.440 --> 46:42.560
in this course, especially in PIMS lecture, which is in week four, is that actually you can observe

46:42.560 --> 46:50.480
equivalents as a special case of a more broader category theory concept called naturality, which

46:50.480 --> 46:58.000
effectively makes the conditions far more relaxed. For example, you don't need all of your functions

46:58.000 --> 47:02.000
to be symmetries to analyze such a system. They don't need to compose with each other,

47:02.000 --> 47:07.040
inverses don't have to exist. So you can be in a way resistant even to functions that destroy

47:07.040 --> 47:11.520
some of your data rather than just leave it exactly the same. So in a way, it's something that

47:11.520 --> 47:17.280
encompasses equivalent functions, but then allows you to model way more interesting things than that.

47:17.840 --> 47:24.800
And I believe this also answers the question that Freddie Minow posted on his applied category

47:24.800 --> 47:28.880
theory, a super set of geometric deep learning. The short answer that PIMM already wrote is that

47:28.880 --> 47:35.280
we definitely think so. And the lecture from PIMM should elaborate this connection a lot more.

47:35.680 --> 47:45.040
Okay. So then we have an operator question from Nitin that asks, can we quantify or understand

47:45.040 --> 47:50.480
the causality or counterfactual nature of systems if they have compositionality? Does it add some

47:50.480 --> 47:54.880
explainability nature to the system as a whole instead of looking at the subset of components

47:54.880 --> 48:02.160
as independent modules that are not interdependent? Oh, these are all really, really good questions.

48:02.240 --> 48:07.760
I actually don't know what the answer to this is. So there's been some work. Well, there's been

48:09.040 --> 48:14.640
a number of papers studying category theory and causality, but I'm actually not sure what is

48:14.640 --> 48:21.440
the state of the art with regards to counterfactual reasoning. There is certainly lots of papers

48:21.440 --> 48:26.480
doing this, but I'm afraid I can't give a good answer to this. We certainly hope so that

48:27.280 --> 48:31.600
something comes out, but it's not something that I think we can substantiate just yet.

48:32.800 --> 48:38.080
Yeah, I think maybe I'll use this opportunity to plug one of our guest lectures from Taco Cohen,

48:38.080 --> 48:42.160
who has worked quite a bit recently on trying to use category theory to formalize

48:42.720 --> 48:47.200
causal reasoning in machine learning models, who has this very nice position paper on it

48:47.200 --> 48:52.320
that came on the archive recently. And he will be giving us a guest lecture on this exact topic.

48:52.320 --> 48:57.680
So please do stick around if you're interested in applications of category theory for causality.

48:57.680 --> 49:02.880
I had a chance to speak to Taco on this on a few occasions, and he seems quite convinced that we

49:02.880 --> 49:08.640
need category theory to reason about causality in the right way. So it'll be very interesting to

49:08.640 --> 49:15.040
hear his thoughts on this. The current top rated question comes from Flavio, and it says,

49:15.040 --> 49:19.920
category theory tutorials might be easy to find. Can we get more info on the specific relation

49:19.920 --> 49:25.760
with deep learning? I think the answer to this question is really that those connections will

49:25.760 --> 49:30.480
happen in the coming lectures, unless Bruno, you want to add anything else on top of that.

49:32.240 --> 49:37.360
No, no, you're right. I would add that I also have a GitHub sort of listing all the papers

49:37.360 --> 49:43.680
in category theory in machine learning. This is precisely the GitHub that hosts the data used

49:43.680 --> 49:50.560
to generate this graphic. So maybe I'll also link that in the zealot. So that might be a good thing

49:50.560 --> 49:53.760
to have a look before the next week's lecture to see what has been done.

49:54.720 --> 50:01.760
Yeah, sounds good. Yes, definitely do share that if you have a chance. Andrew, I think you have a

50:01.760 --> 50:07.360
raised hand. Yes, I just wanted to emphasize, especially with the previous or earlier question,

50:08.160 --> 50:12.640
that at the moment there is no book on this subject, on the connection between category

50:12.640 --> 50:20.640
theory and deep learning. So we're going to do our best in these lectures, but it's not

50:20.720 --> 50:29.120
so easy to give reference materials besides these papers. This is a gap we're trying to

50:29.120 --> 50:33.840
fill with these lectures. Yeah, I think that's also a good point to have. Although the seven

50:33.840 --> 50:39.440
sketches, if you don't count machine learning per se, is a good starting point to just understand

50:39.440 --> 50:44.800
what all these string diagrams are like and how they connect different areas. Yeah, for programming

50:44.880 --> 50:55.280
and CS, plenty of resources, but yeah. Okay, so let's see, what else do we have?

50:56.240 --> 51:02.000
So there's a lot of questions floating around. I'm just trying to pick which one. Okay, yeah,

51:02.000 --> 51:06.160
this one is an interesting one. It's a bit philosophical, so I'm curious to hear Andrew,

51:06.160 --> 51:10.880
sorry, Bruno, what you think about it. It comes from Lucino Prince. Do you think that

51:10.880 --> 51:16.480
composability is a true constituent of nature, or is just the limit of how much we can understand?

51:18.080 --> 51:27.200
Oh, I love these questions. I wish I could provide a really coherent answer to this. Certainly,

51:27.200 --> 51:35.040
it seems like everywhere we look, things are compositional. But this might be like the story

51:35.040 --> 51:39.440
of trying to find your car keys under the lamp post because that's where the light is.

51:40.400 --> 51:46.640
We are certainly not doing compositionality. There's so many things that seem so foreign to us,

51:48.000 --> 51:51.680
and we just don't look there. We look at the things which are compositional.

51:53.440 --> 51:58.240
Oh, god, yeah, I'm not sure how to answer this question. So this is a very

52:00.720 --> 52:06.800
conservative answer. That's what I'll say. I don't know if anybody else from the team has a response to this.

52:09.600 --> 52:18.160
I think the question caught me a bit off guard. I'll have to think about it a bit more. But

52:18.880 --> 52:22.800
yeah, Pym, Andrew, do you guys have some thought on this question on your side?

52:22.800 --> 52:38.960
I mean, I think there's probably evidence somewhere that we tend to at least learn

52:38.960 --> 52:45.280
things in a compositional way. I mean, I guess whether there's some underlying

52:46.240 --> 52:55.680
nature is a big question. It's surely a very nice way to organize existing information,

52:55.680 --> 53:03.200
let's say, if you think about it in a compositional manner. That just allows you to reason about it

53:03.200 --> 53:13.920
a lot more easily. Okay, so let's see. There is a lot of new questions. The current top question,

53:14.000 --> 53:19.760
which I think hasn't already been answered. And I guess it comes from some of our more

53:19.760 --> 53:24.800
mathematically oriented audience. Stanislav specifically asks, if we're going to talk about

53:24.800 --> 53:29.520
two categories, should we actually then consider enriched and end categories in principle?

53:31.040 --> 53:37.840
Yeah, so this is certainly the next step. So a lot of the things I did not mention in this

53:37.840 --> 53:46.160
very brief lecture is enriched categories or pre categories or higher category theory. There is

53:46.160 --> 53:55.440
certainly an abundance of theory and thoughts and expressivity in all of these more nuanced areas.

53:56.640 --> 54:01.840
So yeah, these are certainly things to study and give us a particular flavor of category theory.

54:02.160 --> 54:08.800
And yeah, I would invite you if you know, but I would consider these to be advanced topics for now.

54:10.960 --> 54:16.160
Okay, yeah, I definitely agree. Let's learn how to crawl before we learn how to run. And

54:16.160 --> 54:20.960
there is a reason why some people might perceive the content so far to be a bit slow starting.

54:20.960 --> 54:25.520
We have a very diverse audience coming from all sorts of backgrounds and we're trying to accommodate

54:25.520 --> 54:32.080
for all of those backgrounds appropriately. So we have one very fast-rising question from

54:32.080 --> 54:36.640
Ewan, which asks, I'm aware there's been some research on category theory to motivate the

54:36.640 --> 54:42.240
graph neural network design. Has any work or much work been done to use these ideas to construct

54:42.240 --> 54:47.840
modular and composable neural networks or more interpretable representations in the spirit of

54:47.840 --> 54:51.120
say what Chris Ola has been doing with representations as types?

54:53.840 --> 55:03.520
Yeah, so that's something I would love to think about and work on. To my knowledge, the answer is no.

55:05.200 --> 55:10.000
Yeah, to my knowledge, the answer is no. But it seems like there is really no obstacle to doing

55:10.000 --> 55:19.440
so, at least no major obstacle. So yeah, yeah. All right, then another top-rated question.

55:19.440 --> 55:24.240
Yeva asks, which kinds of categories, broadly speaking, are we going to focus on most in this

55:24.240 --> 55:28.720
course? So what do we see to be the most interesting categories for deep learning at this time?

55:30.720 --> 55:38.080
Right, so well, in this next week's lecture that Petter says is going to give, we're going to talk

55:38.080 --> 55:44.000
about categories in general. But the one after this, we're going to talk about, so categories

55:45.120 --> 55:51.280
allow us to compose processes in a sequence, which is useful, but in a way limited, because often

55:51.280 --> 55:57.840
in nature, we compose processes that is in parallel. So in third lecture, we're going to be studying

55:57.840 --> 56:04.640
things called monoidal categories, where you can put processes in parallel. And very interestingly,

56:04.720 --> 56:09.440
these are not processes where you can necessarily copy information, delete information, some

56:09.440 --> 56:15.600
information. So we're going to add extra layers of new ones by studying things called Cartesian

56:15.600 --> 56:22.960
categories where you can start to do all of these things. And then later, yeah, so we're going to

56:22.960 --> 56:31.440
study, yeah, I'm not sure how to best describe it right now without going into depth, how to start

56:31.440 --> 56:40.240
talking about sort of things used in equity variants. It's sort of the things that might

56:40.240 --> 56:47.280
not be easy to explain right now before unpacking the lectures. But we're going to study part of

56:47.280 --> 56:51.120
the things we're studying here is not just categories, but the ways these are categories

56:51.120 --> 56:56.080
are related and concepts build on top of them. So we're going to study functors between categories,

56:56.080 --> 57:00.800
monads on these categories, and various these algebraic structures that allow us to describe

57:00.800 --> 57:06.640
this wiring of processes or some structure preserving maps between them. Yeah.

57:08.480 --> 57:13.280
All right. Thank you for that. The current talk question from Jeffrey asks,

57:13.280 --> 57:18.160
it's potentially also a philosophical question. How do you find or how do you decide what are

57:18.160 --> 57:23.840
the essential composable blocks of what you want to study? Yeah, I mean, I think this is

57:23.840 --> 57:27.520
really a question that's not really specific to category theory. It's sort of

57:28.480 --> 57:33.680
generally to science, we're trying to find building blocks and trying to find the basic

57:33.680 --> 57:43.520
concepts. And I think this is really an art at this point. There's not, we cannot really formalize

57:43.520 --> 57:54.880
and systemize this, the process of science yet. Okay, so I think our one hour block that you

57:54.880 --> 58:03.280
had allocated for this lecture has just expired. And also at the same time, I actually had to

58:04.640 --> 58:09.920
reset my Zoom, so I actually don't see many of the questions that are still in the Q&A.

58:10.640 --> 58:18.800
So perhaps if Andrew or someone can see if there's any other big salient questions left,

58:18.800 --> 58:22.640
otherwise I think it's okay if we continue the discussion on Zulip. We already covered

58:23.360 --> 58:29.760
a lot of grounds. The top one is just asking if we can put up slides in advance, which I think

58:29.760 --> 58:36.560
we can try to do, but I would depend on the speaker. Yeah, I'll definitely put my slides up

58:36.560 --> 58:43.040
before the lecture and maybe we can start doing it more going forward. I think for the first lecture,

58:43.040 --> 58:48.720
we're just trying to make sure everybody gets access to this Zoom properly. But going forward,

58:48.720 --> 58:52.400
when we start to get more technical, we will definitely aim to share the slides in advance.

58:52.880 --> 59:09.680
Okay, yeah, so I think we will leave it at that. Thank you so much for coming to our first lecture,

59:09.680 --> 59:15.040
and we hope you enjoyed. Bruno, thank you so much also for delivering a great motivational

59:16.480 --> 59:21.440
entrance to everything that will come next. And we hope you enjoyed it. We hope to keep

59:21.440 --> 59:27.760
the discussion going. So if you want to join us on Zulip in the coming days and weeks and discuss

59:27.760 --> 59:34.800
the various aspects of the course with us as we go along and materials and so on, that would be

59:34.800 --> 59:39.520
really great. And if you have any feedback on how things have gone today and how you would like them

59:39.520 --> 59:46.240
to go forward, please do interact with us. However, you prefer to leave us that feedback

59:46.240 --> 59:51.040
directly or anonymously. We very much welcome any comments you have. It's a course we're actively

59:51.040 --> 59:57.840
building together with all of you. So on that note, let's thank Bruno one more time. And yeah,

59:57.840 --> 01:00:02.880
hope you enjoyed and hope you'll have a great rest of your week. I will see you in a week's time

01:00:02.880 --> 01:00:06.960
for a discussion of fundamentals of category theory.

