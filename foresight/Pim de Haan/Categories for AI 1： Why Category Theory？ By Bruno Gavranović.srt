1
00:00:00,000 --> 00:00:06,080
Hello, everyone. I would like to welcome you to our course categories for AI.

2
00:00:09,040 --> 00:00:15,600
In the following weeks, we'll discuss the exciting and rising role that category theory has in deep

3
00:00:15,600 --> 00:00:21,040
learning. It's something incredibly interesting, and we're happy to be able to share this with you.

4
00:00:24,000 --> 00:00:28,160
My name is Brona Gavranovic. I'm a PhD student at the University of Strathclyde,

5
00:00:28,160 --> 00:00:32,320
and I'm bringing this course to you together with the rest of the organizing team,

6
00:00:32,880 --> 00:00:42,560
Andrew, Joao, Pim and Petar. We are all in some way affiliated with deep learning category theory,

7
00:00:42,560 --> 00:00:48,880
or both, and interested in talking about technologies that will benefit us all,

8
00:00:48,880 --> 00:00:56,560
and we'll all want to use. So the first question we want to answer is, why categories for AI?

9
00:00:58,800 --> 00:01:05,360
The reason is simple. We believe in a future where all deep learning experts will use some

10
00:01:05,360 --> 00:01:17,040
aspects of category theory in their work. Now, deep learning is a new field, and as it's often

11
00:01:17,040 --> 00:01:24,080
the case with new fields, with new scientific fields, they start in an ad hoc manner, and then

12
00:01:24,080 --> 00:01:30,160
later these fields are understood differently than they were by their early practitioners.

13
00:01:31,840 --> 00:01:37,680
So for example, in taxonomy, people have been grouping plants and animals for thousands of years,

14
00:01:37,680 --> 00:01:42,800
but the way we understood what we were doing changed a lot in light of evolution and molecular

15
00:01:42,800 --> 00:01:49,200
biology. In chemistry, we have explored chemical reactions for a long time, but our understanding

16
00:01:49,200 --> 00:01:56,880
changed a lot with the discovery of the atom. And then in programming, people started to program

17
00:01:56,880 --> 00:02:03,120
by tinkering with transistors and logic gates, but most of what we call programming is heavily

18
00:02:03,120 --> 00:02:15,040
abstracted from that. And then now we have deep learning. Deep learning, despite its remarkable

19
00:02:15,040 --> 00:02:22,480
success, is a field permeated by ad hoc design choices. So as we all know, neural networks,

20
00:02:22,480 --> 00:02:29,600
neural network architectures have all these knobs and tweaks that we can't formally justify just yet.

21
00:02:30,720 --> 00:02:39,360
We keep being surprised by new architectures such as GPT-3 or stable diffusion, and there is no

22
00:02:39,440 --> 00:02:44,960
unifying framework for deep learning. There is no unifying framework that would explain the

23
00:02:44,960 --> 00:02:50,480
probabilistic perspective, the neuroscience perspective, and merely just the gradient-based

24
00:02:50,480 --> 00:02:56,640
iterative updating perspective. In fact, in the future, we might look at deep learning very differently.

25
00:02:58,000 --> 00:03:02,800
And our claim is that category theory will become the unifying deep learning framework.

26
00:03:03,680 --> 00:03:09,040
As a matter of fact, it might become a general theory of neural network architecture,

27
00:03:09,040 --> 00:03:13,200
architectures, and such an essential tool for deep learning practitioners.

28
00:03:15,280 --> 00:03:20,800
Now, this is certainly a bold claim, but it is the one we hope to substantiate in this course.

29
00:03:23,280 --> 00:03:29,520
So what is category theory? If I had to describe category theory in one sentence,

30
00:03:29,520 --> 00:03:36,560
it would be this one. Category theory takes a bird's-eye view of mathematics. From high in the

31
00:03:36,640 --> 00:03:42,320
sky, details become invisible, but we can spot patterns that were impossible to detect from

32
00:03:42,320 --> 00:03:49,520
ground level. The famous quote accurately describes what category theory has done to mathematics.

33
00:03:50,640 --> 00:03:56,800
As we'll see, it's not taking a bird's-eye view of just mathematics, but it started to do that

34
00:03:56,800 --> 00:04:02,000
to all of science in the form of a new wave that is being called applied category theory.

35
00:04:02,800 --> 00:04:07,760
So before we do anything, I just want to give you a one-slide summary of what applied category

36
00:04:07,760 --> 00:04:15,440
theory is and what we hope to teach you in this course. Applied category theory is a particular

37
00:04:15,440 --> 00:04:20,320
way of structuring your knowledge. It's grounded in the idea of compositionality.

38
00:04:22,240 --> 00:04:26,720
It originated in pure mathematics and has since spread to numerous fields.

39
00:04:26,720 --> 00:04:35,680
This is a formal language that is not just a part of these many fields, but it's being used to build

40
00:04:35,680 --> 00:04:43,840
bridges between these fields that were previously unknown. So other than in pure mathematics where

41
00:04:43,840 --> 00:04:51,280
it's, which it permeates, it has been emerging across the sciences. So it's been found in physics,

42
00:04:51,360 --> 00:04:57,680
it's been found in chemistry, it's been found in systems theory. It is all over computer science

43
00:04:57,680 --> 00:05:04,560
and it is the theoretical foundation of functional programming. It has been found in game theory,

44
00:05:04,560 --> 00:05:10,560
in information theory, control theory, probability theory, cryptography, and many others.

45
00:05:13,040 --> 00:05:19,280
For us, the most relevant is deep learning where there has been a number of recent papers

46
00:05:19,280 --> 00:05:27,600
in the last two or three years. Now, many people haven't heard of category theory and that might be

47
00:05:27,600 --> 00:05:32,240
because it started being applied across the sciences only in the last five years or so.

48
00:05:33,360 --> 00:05:37,920
So here we see a graph of the intersection of papers in category theory and machine learning.

49
00:05:38,960 --> 00:05:47,600
As you can see, we are in very early stages. We have just had our fifth applied category theory

50
00:05:47,600 --> 00:05:53,600
conference, the only one, and the only existing applied category theory journal just published

51
00:05:53,600 --> 00:06:01,680
its fourth volume. So this recency of category theory might be one of the reasons it is difficult

52
00:06:01,680 --> 00:06:09,200
to teach. For all of its expressive power, it's an notoriously difficult subject to learn.

53
00:06:10,080 --> 00:06:14,240
As it originated in abstract mathematics, most introductory material

54
00:06:14,240 --> 00:06:21,440
is not aimed at the general audience of programmers or scientists in general. There are a few exceptions.

55
00:06:23,360 --> 00:06:29,760
So definitions in category theory are extremely information dense. For example, a monad,

56
00:06:29,760 --> 00:06:35,360
the concept of a monad shown on this slide has a number of components satisfying a number of rules.

57
00:06:36,320 --> 00:06:39,840
And then each of these components is often information dense as well,

58
00:06:39,840 --> 00:06:46,160
meaning category theory requires a lot of initial investment to start appreciating.

59
00:06:49,200 --> 00:06:55,120
But once you start learning category theory and start appreciating the definitions,

60
00:06:55,120 --> 00:07:00,560
you see that the definitions form an incredibly cohesive theory, really not found anywhere else

61
00:07:00,560 --> 00:07:07,360
in science. These interplay together at such a remarkable level, which is hard to appreciate

62
00:07:07,360 --> 00:07:12,960
when you're just starting to learn it. It often looks very difficult. And on a graph,

63
00:07:14,160 --> 00:07:20,960
the learning process looks something like this. So compared to traditional methods,

64
00:07:20,960 --> 00:07:25,680
the structural method of category theory takes a long time to get started. But once you do,

65
00:07:25,680 --> 00:07:34,080
the theory scales much better. So in some sense, category theory is a theory of how to scale up

66
00:07:34,160 --> 00:07:41,600
our systems. And this is something we want to teach you in this course. We want to teach you

67
00:07:41,600 --> 00:07:47,280
how to approach category theory, motivated with some practical examples from deep learning,

68
00:07:47,840 --> 00:07:51,760
and really give you a sense of the philosophy behind category theory.

69
00:07:54,480 --> 00:08:00,640
So this is week one. And after today's lecture, which is going to be an introductory

70
00:08:00,720 --> 00:08:09,440
lecture to the general thoughts of category theory, we're going to start going into the details.

71
00:08:11,200 --> 00:08:16,080
In week two, we will be studying essential building blocks of category theory, categories

72
00:08:16,080 --> 00:08:22,160
and functors. In week three, we will study how category theory can be used to describe back

73
00:08:22,160 --> 00:08:27,440
propagation using monoidal categories, admitting a visual and intuitive graphical language.

74
00:08:28,400 --> 00:08:32,880
In week four, we'll study how geometric deep learning and naturality

75
00:08:34,240 --> 00:08:42,080
and have their foundations in category theory. We're going to study natural graph networks.

76
00:08:44,160 --> 00:08:49,760
And lastly, in week four, we will see how monoids, monads, and various algebraic structures

77
00:08:49,760 --> 00:08:53,360
can be connected to recurrent neural networks and LSTMs.

78
00:08:57,440 --> 00:09:01,360
After our five weeks of lectures, we have a series of talks by people who are

79
00:09:01,360 --> 00:09:06,400
in the industry doing category theory deep learning or both. And we are very excited about those.

80
00:09:11,440 --> 00:09:18,400
But yes, in today's lecture, we're going to start by studying what is compositionality,

81
00:09:19,360 --> 00:09:25,280
what is category theory really, what you need to start learning and taking advantage of it,

82
00:09:25,280 --> 00:09:31,520
perhaps the most important thing. And we're going to take a look at what category theory

83
00:09:31,520 --> 00:09:41,760
has done and can do for deep learning. So yeah, let's get started. So what is compositionality?

84
00:09:41,760 --> 00:09:47,600
This is a concept I've mentioned, which is central to category theory. And it's a concept

85
00:09:47,600 --> 00:09:53,760
that's often misunderstood. It's often presented as an ability to build systems together by

86
00:09:53,760 --> 00:10:01,600
composing them out of smaller subsystems. Now, this is certainly a component of compositionality,

87
00:10:01,600 --> 00:10:09,360
but this is not all. Compositionality includes the ability to build the systems, but we don't

88
00:10:09,360 --> 00:10:15,280
just want to build a very complex system that we can't reason about. It includes the ability to

89
00:10:15,280 --> 00:10:21,360
reason about the resulting system recursively in terms of its components. And really,

90
00:10:21,360 --> 00:10:27,680
compositionality is more of a property of the model of our system than the system itself.

91
00:10:28,960 --> 00:10:33,120
So we're going to see what that means. Compositionality requires both of these things.

92
00:10:33,680 --> 00:10:39,680
And for many models of our systems that are found throughout nature, we have the first

93
00:10:39,680 --> 00:10:43,760
property that we can build the system, but not the second one that we can reason about it.

94
00:10:44,560 --> 00:10:52,400
So for example, when we study behaviors of markets, of organizations, of economy,

95
00:10:52,400 --> 00:11:01,120
of neural networks, and many other concepts, these things aren't compositional. Now, what does

96
00:11:01,120 --> 00:11:07,840
that mean? These are very fuzzily defined concepts, but they're precisely very fuzzily defined only

97
00:11:07,840 --> 00:11:12,400
because we don't know how to reason about them from outside. We don't know what are the fundamental

98
00:11:12,400 --> 00:11:16,560
building blocks, and we don't know how to reason about the behavior of, say, the global economy

99
00:11:17,360 --> 00:11:22,160
by studying behavior of economies of individual countries. There's many emergent effects that

100
00:11:22,160 --> 00:11:27,520
are happening and that are hard to track. On the other hand, there are many systems,

101
00:11:28,080 --> 00:11:34,000
many models of our systems that have both one and two. For instance, and these are often very

102
00:11:34,000 --> 00:11:38,560
simple systems. We think of them as simple because we understand them. So for example, if we have two

103
00:11:38,560 --> 00:11:43,520
differentiable functions, we can put them together and get a composite differentiable

104
00:11:43,520 --> 00:11:50,160
functions by using the chain rule. If we have a compiler from a language A to language B,

105
00:11:50,160 --> 00:11:55,120
and a compiler from language B to language C, we get a joint compiler that compiles all the way

106
00:11:55,120 --> 00:12:02,400
through. We can compose various things like Markov kernels. We can compose merely polynomials and so

107
00:12:02,560 --> 00:12:12,480
on. There's many kinds of systems. Now, this slide, if you're seeing this, this might

108
00:12:14,160 --> 00:12:19,520
ring some alarm bells. It might seem like I've said something inconsistent here. It might seem like

109
00:12:19,520 --> 00:12:29,520
we are saying this. So it certainly looks like I said differentiable functions like

110
00:12:29,520 --> 00:12:34,240
compositional. And I said neural networks are made out of differentiable functions. Therefore,

111
00:12:34,240 --> 00:12:39,440
neural networks are compositional, but I said they're not. So this meme might look like what

112
00:12:39,440 --> 00:12:44,000
we're saying, but really what we're saying is the following. Compositional with respect to what.

113
00:12:45,280 --> 00:12:50,000
So I said compositionality is a property of our models, and we have to specify what

114
00:12:50,800 --> 00:12:56,240
our model is, what it is that we're studying. It's important to specify the property of the

115
00:12:56,240 --> 00:13:01,600
system we want to model. So if our model treats neural networks as differentiable functions,

116
00:13:01,600 --> 00:13:07,120
then, indeed, neural networks are compositional. We plug together a bunch of differentiable

117
00:13:07,120 --> 00:13:13,360
functions, and using automatic differentiation, we can compute, or chain rule, really, we can

118
00:13:13,360 --> 00:13:21,440
compute the derivative of the composite. But if our model treats neural networks as

119
00:13:21,440 --> 00:13:25,360
generative or discriminative models, then this is not compositional.

120
00:13:28,160 --> 00:13:32,960
It's important to specify what property we're studying and what exactly are we modeling.

121
00:13:35,200 --> 00:13:45,360
Really, compositionality is about interfaces. If you think about a system composed of many

122
00:13:45,360 --> 00:13:53,920
smaller subsystems, and the simplest case here is that of a function. When we compose these

123
00:13:53,920 --> 00:13:59,440
systems, we want to ensure that all the data we need is available at the exposed interfaces.

124
00:14:03,520 --> 00:14:09,920
So really, if we have three functions like this, the famous property of associativity

125
00:14:09,920 --> 00:14:15,920
tells us that if we compose f and g, and then with h, that should be the same as composing g

126
00:14:15,920 --> 00:14:23,280
with h and then with f. So this famous property posits that function composition should be

127
00:14:23,280 --> 00:14:29,440
associated. But why is this the property that you might want to have? Because it allows us to treat

128
00:14:29,440 --> 00:14:38,080
functions extensionally, only by looking at their interfaces. And if these composites are the same,

129
00:14:38,080 --> 00:14:43,200
then function composition is associative. And we can look at only the input and output of the

130
00:14:43,200 --> 00:14:48,320
system to know how it behaves. And we don't need to know anything about its internals or how it was

131
00:14:48,320 --> 00:14:58,880
built. But if this property isn't satisfied, then we might be in trouble. Non-compositionality implies

132
00:14:58,880 --> 00:15:05,920
that we need extra data to reason about the system, data that isn't available through the interfaces.

133
00:15:06,880 --> 00:15:11,280
But if our method of interaction is only through the interfaces, which is the intended way of

134
00:15:11,280 --> 00:15:15,600
interacting, then this means that we have uncertainty about how the system will behave.

135
00:15:16,800 --> 00:15:23,600
And then composing many such systems together, our uncertainty can only grow.

136
00:15:26,480 --> 00:15:32,320
Really, what we want to is minimize this uncertainty by imposing some invariances of how we

137
00:15:32,960 --> 00:15:37,920
put systems together. So that's when we create a bigger system, we know something about how it

138
00:15:37,920 --> 00:15:44,400
behaves. So really, compositionality is a very delicate property. And I'm a fan of this quote

139
00:15:45,040 --> 00:15:51,920
on the bottom of this slide, which tells us that it is so powerful that it is worth going to extreme

140
00:15:51,920 --> 00:16:00,080
lengths to achieve. So this is what category theory is. It's the study of compositionality,

141
00:16:00,160 --> 00:16:05,520
of how we can put systems together. And to my surprise, when I started to learn it,

142
00:16:05,520 --> 00:16:11,520
it's not really just about functions. Functions were an example here that is simple. But category

143
00:16:11,520 --> 00:16:17,280
theory studies all sorts of complex systems, from trees on the top left, to networks on the top

144
00:16:17,280 --> 00:16:22,640
right, to circuits on the bottom left, to bi-directional transformations on the bottom right.

145
00:16:23,440 --> 00:16:31,840
So with this in mind, we can start describing what category theory is. Even though we're talking

146
00:16:31,840 --> 00:16:39,280
about all sorts of abstract systems and gadgets, category theory is still a precise mathematical

147
00:16:39,280 --> 00:16:46,960
language to talk about it. It's the kind of language that emphasizes relationships between

148
00:16:46,960 --> 00:16:53,120
concepts as opposed to concepts themselves. And we're going to see what that means shortly.

149
00:16:56,240 --> 00:17:02,160
And we're going to see that particular structures in category theory have

150
00:17:02,160 --> 00:17:10,320
visual representations that aren't just doodles or sketches. They are former representations

151
00:17:10,320 --> 00:17:16,240
that can be manipulated, even in a computer. So to give you a sense of what this really is,

152
00:17:16,240 --> 00:17:22,800
I'm going to have a very short demo where I'm going to just draw a few things. So I'm going to

153
00:17:24,400 --> 00:17:28,480
switch to

154
00:17:34,560 --> 00:17:44,240
my iPad and just give you a sense of how these things work. So I said category theory is a

155
00:17:44,240 --> 00:17:52,960
unifying language for mathematics. And to appreciate what this means, we can perhaps focus

156
00:17:52,960 --> 00:18:01,200
on some subfield of mathematics, like say group theory. So in group theory, we might want to

157
00:18:01,200 --> 00:18:08,160
study a particular group. And a central concept in group theory is that of a group homomorphism.

158
00:18:08,160 --> 00:18:15,040
If you have two groups, we can have a structure preserving a mapping between them. And then we

159
00:18:15,040 --> 00:18:19,200
can have many mappings and they can go between groups themselves and so on. And there could be

160
00:18:19,200 --> 00:18:23,520
many groups that we want to study. Maybe some of them are not connected and so on.

161
00:18:30,000 --> 00:18:34,720
And we can study about various properties of these groups and study how they behave. Now,

162
00:18:34,720 --> 00:18:43,680
separately, in set theory, we might have some set and we might study functions between set one

163
00:18:43,680 --> 00:18:49,520
and set two. These are really honest to God functions that we can compose. And maybe there's

164
00:18:50,160 --> 00:18:57,040
S3, S4. And there's various kinds of structures that we can study between them. It's a very rich

165
00:18:57,040 --> 00:19:01,680
and intricate field. And I'm going to write here set and I'm going to write here group.

166
00:19:02,640 --> 00:19:09,840
Then again, if we're studying, for instance, we might study vector spaces or similar things. So

167
00:19:09,840 --> 00:19:14,320
for instance, I have a vector space one and a vector space two. I can still study some sort

168
00:19:14,320 --> 00:19:19,280
of structure preserving mapping between these, between these other structures. And for instance,

169
00:19:19,280 --> 00:19:26,880
this could be just merely vector spaces in a field R. Now, what category theory does is

170
00:19:27,680 --> 00:19:33,040
gives us this bird eye view of these things. All of these structures are categories. So here

171
00:19:33,040 --> 00:19:38,080
we have a category of groups. Here we have a category of sets. And here we have a category

172
00:19:38,080 --> 00:19:48,800
of vector spaces. And all of these structures are special examples of category teams. The same way

173
00:19:48,800 --> 00:19:54,720
we have studied structure preserving maps between groups, group homomorphisms,

174
00:19:55,600 --> 00:20:00,160
by formulating all the groups as a category. Now we can study structure preserving maps

175
00:20:00,800 --> 00:20:08,400
of these categories, which are called functors. So for instance, we might have a functor from

176
00:20:08,400 --> 00:20:13,280
the category of groups to the category of sets, which takes a group and gives us the underlying

177
00:20:13,280 --> 00:20:19,120
set. Or we might have a functor that takes a set and gives us the free vector space on a set and so

178
00:20:19,120 --> 00:20:27,840
on. The idea being that once we have lifted ourselves to this abstract level, a lot of

179
00:20:27,840 --> 00:20:33,680
new things open up to us. So what we end up studying is a lot of interesting things like

180
00:20:33,680 --> 00:20:40,880
the category of, let's say, let's call them systems with a particular interface, input and

181
00:20:40,880 --> 00:20:46,080
output. And we can have a system with internal state S1 and S2. And we can say the ways these

182
00:20:46,080 --> 00:20:50,720
are related. And then we can study categories of systems with a different interface and map

183
00:20:50,720 --> 00:20:57,600
between them and so on. And these systems can be actual processes, computations that do something

184
00:20:57,600 --> 00:21:02,960
very interesting. That isn't just sort of what you might think of as strictly mathematical.

185
00:21:05,360 --> 00:21:10,480
And lastly, we might study categories. These categories might have a lot of interesting

186
00:21:10,480 --> 00:21:17,040
structure. For example, I've drawn here a monoidal category where we can sort of put

187
00:21:17,040 --> 00:21:27,280
two objects in parallel, as opposed to just composing maps sequentially. And then in category

188
00:21:27,280 --> 00:21:32,320
theory where it turns out that these monoidal categories, that's what they're called, where

189
00:21:32,320 --> 00:21:37,360
we can put things in parallel, have a formal visual representation. So the story is a bit more

190
00:21:37,360 --> 00:21:42,960
intricate, but you can think of it as taking this category and mapping it into a visual space

191
00:21:42,960 --> 00:21:49,280
where each morphism has a specific shape. And you can draw it as boxes. So now these boxes

192
00:21:49,280 --> 00:21:53,280
aren't just sketches and doodles, but they're formal mathematical objects.

193
00:22:07,440 --> 00:22:23,520
So let me just switch to my other screen. Right, so this was merely aimed to paint a picture of how

194
00:22:23,520 --> 00:22:29,760
these things look. And finishing with the monoidal categories in this demo,

195
00:22:30,160 --> 00:22:40,880
these allow us to have a very natural visual language for talking about systems and processes.

196
00:22:40,880 --> 00:22:45,920
And these are really, this is an example of what might, of a particular process of making a pie.

197
00:22:45,920 --> 00:22:52,560
And we've all seen these things. So this is not something new. But it allows us, and it gives

198
00:22:52,560 --> 00:22:59,360
us a very different perspective on these things. So when you're doing category theory, you might

199
00:22:59,360 --> 00:23:04,160
be studying various sorts of systems and processes that do various sorts of things. And

200
00:23:04,160 --> 00:23:08,880
in category theory, there's concepts discovered or invented by various people for studying these

201
00:23:08,880 --> 00:23:14,480
things. So if we're studying resources or processes in this way, we might use monoidal categories.

202
00:23:16,960 --> 00:23:22,560
If we want to study probability, for instance, we will use Markov categories. So for instance,

203
00:23:22,560 --> 00:23:27,040
on the left side, here we see a process which takes an input, applies a function to it,

204
00:23:27,520 --> 00:23:34,240
and then copies the result. On the right, we first copy the result and then apply f

205
00:23:34,240 --> 00:23:41,120
individually on inputs. Now, if f is merely a function, then these two processes are equal.

206
00:23:41,120 --> 00:23:46,880
And in many other cases, they're equal. But not all of them. If f is a stochastic function,

207
00:23:47,680 --> 00:23:52,080
then these are not equal because rolling a dice and then copying the result doesn't give us the

208
00:23:52,080 --> 00:23:57,840
same result as rolling two dice. So Markov categories allow us to describe such processes

209
00:23:57,840 --> 00:24:03,760
at the needed level of generality. Then we might, if you want to study how local systems,

210
00:24:03,760 --> 00:24:08,880
how behavior of local systems gives rise to the behavior of a global system,

211
00:24:08,880 --> 00:24:14,720
you might want to use sheeps. Then again, if you want to study bi-directional transformations,

212
00:24:14,800 --> 00:24:22,800
such as extracting a row from a database, then updating back, so forward and backward.

213
00:24:22,800 --> 00:24:27,360
Or if you want to study neural networks, a forward pass and a backward pass,

214
00:24:28,160 --> 00:24:31,840
we might want to use optics and lenses, which are bi-directional data structures.

215
00:24:34,480 --> 00:24:39,040
Then again, if you want to study contextual computation or computation with side effects,

216
00:24:39,040 --> 00:24:42,960
we might want to use things called monads or their Kleisler categories.

217
00:24:44,640 --> 00:24:51,200
And of course, in computer science, the concept permeating it is recursion. And then we might

218
00:24:51,200 --> 00:24:57,600
want to use things called final co-algebras or initial algebras to study recursive processes.

219
00:25:00,800 --> 00:25:05,840
And once we study all of these things, we might find ourselves in this situation

220
00:25:06,480 --> 00:25:12,880
where we study a bunch of different kinds of systems with different kinds of categories and

221
00:25:12,880 --> 00:25:17,600
concepts. And that ends up just creating more categories and more concepts. And the theory

222
00:25:17,600 --> 00:25:23,600
that studies category theory is called two-category theory. So something I love about the way you

223
00:25:23,600 --> 00:25:31,200
approach CT, that it is very meta and recursive in nature, allowing us to describe category theory

224
00:25:31,200 --> 00:25:40,640
using category theory. And then really, once you start going with this, you might have heard about

225
00:25:40,640 --> 00:25:46,640
classical mathematical structures such as topological spaces or rings or fields. And once

226
00:25:46,640 --> 00:25:53,120
you start going into category theory, it's hard to appreciate how deep and rich the field is,

227
00:25:53,120 --> 00:25:59,680
because the water keeps getting deeper and deeper and the rabbit hole hides so many concepts that

228
00:25:59,680 --> 00:26:06,080
I personally wasn't aware of that have a very expressive nature and a very compositional nature

229
00:26:06,080 --> 00:26:11,600
in helping us understand all of the systems. This is certainly not the end. There's many more

230
00:26:11,600 --> 00:26:17,600
that every category theorist has a certain understanding of a part of these concepts.

231
00:26:20,160 --> 00:26:28,160
So this was very abstract in a sense, but I hope it conveyed some sense of what category theories

232
00:26:29,120 --> 00:26:35,920
are. But now I would like to make this a bit more concrete and study what is the relationship

233
00:26:35,920 --> 00:26:44,160
between category theory and deep learning? What has been done? How much are these concepts

234
00:26:44,160 --> 00:26:51,680
actually connected to each other? So the thing I want to establish first is that the deep learning

235
00:26:51,680 --> 00:26:57,760
community seems to be very well aware of the concept of compositionality. I have found numerous

236
00:26:57,840 --> 00:27:04,240
workshops, programs, blog posts, lectures saying compositionality is important.

237
00:27:05,520 --> 00:27:08,400
And I've linked a few of them here. I'm sure there's many more.

238
00:27:10,080 --> 00:27:15,600
Joshua Bengio in his Turing lecture actually explicitly states that we need to build

239
00:27:15,600 --> 00:27:24,320
compositionality into our machine learning models. But having studied category theory,

240
00:27:24,960 --> 00:27:30,640
I'm still noticing that compositionality is done in ad hoc ways and that there is a large gap

241
00:27:30,640 --> 00:27:36,160
between how compositionality is thought of in deep learning and the theory of compositionality

242
00:27:36,160 --> 00:27:43,440
that category theory offers. Nonetheless, there have been some recent strides.

243
00:27:46,240 --> 00:27:51,360
So I'd like to give a brief overview of what has been happening on the intersection of

244
00:27:51,360 --> 00:27:59,200
category theory and machine learning. So the papers I am showing here are two papers that

245
00:27:59,200 --> 00:28:05,520
study neural networks in the very abstract, in the form of something called a parametric lens.

246
00:28:06,320 --> 00:28:10,480
We're going to see exactly what that is later in the course, but I just want to give you

247
00:28:10,480 --> 00:28:16,000
an idea of how these things work. So it's something that has a following shape.

248
00:28:16,000 --> 00:28:24,080
And it abstractly models the information flow we see in a neural network. So on the left side,

249
00:28:24,080 --> 00:28:28,960
we see inputs and their gradients. On the right side, we see outputs of a neural network and

250
00:28:28,960 --> 00:28:36,560
their gradients. And here we take the two-dimensional notation seriously, and therefore we have weights

251
00:28:36,560 --> 00:28:43,520
coming from top, weights and their gradients. And this abstractly models how the information flows.

252
00:28:43,520 --> 00:28:48,720
So we can see that from left and top, we get inputs and parameters, compute and output,

253
00:28:49,280 --> 00:28:55,360
and then having received the gradients of the loss with respect to that output, we can back

254
00:28:55,360 --> 00:29:02,000
propagate the gradients with respect to the input to the left and back propagate the

255
00:29:03,520 --> 00:29:06,640
gradients of the loss with respect to weights to the top.

256
00:29:07,600 --> 00:29:14,320
Now, the question you might ask is what is the benefit of this formulation?

257
00:29:14,320 --> 00:29:19,440
Why would we model it like this? Well, when these constructions were originally discovered

258
00:29:19,440 --> 00:29:26,960
a few years ago, something fascinating happened. Independently, game theorists were modeling

259
00:29:26,960 --> 00:29:34,000
economic agents in game theory using these categorical models. And to the big surprise,

260
00:29:34,000 --> 00:29:38,720
these models ended up having the same categorical form as the machine learning ones.

261
00:29:40,320 --> 00:29:46,400
So if you're studying economic agents that take some inputs, produce some outputs,

262
00:29:46,400 --> 00:29:50,880
receive some payoff for their things and have their trying to maximize some strategy,

263
00:29:51,440 --> 00:29:57,680
you end up with a model that has the same shape. So independent formalizations by different people

264
00:29:57,680 --> 00:30:03,760
of game theory and machine learning converge to the same mathematical form. This elucidated

265
00:30:03,760 --> 00:30:09,520
a number of connections and really sparked a whole study of cybernetic systems or reinforcement-like

266
00:30:10,640 --> 00:30:15,200
agent systems, the study of agents interacting with the environment using minimal assumptions

267
00:30:15,200 --> 00:30:19,760
about what agents or the environment is. And really, this is something that can't be done

268
00:30:19,760 --> 00:30:26,240
without the level of generality that category theory provides. So I found this quite fascinating

269
00:30:26,240 --> 00:30:33,520
as it was being discovered. And it's one of the reasons why I, it allows me to study machine

270
00:30:33,520 --> 00:30:42,320
learning in game theory through a unified, unified lens. What it also turned out that why would we

271
00:30:42,320 --> 00:30:46,640
want to use these parametric lenses that we can also model optimizers of neural networks.

272
00:30:48,400 --> 00:30:53,440
So, and what it ended up turning out that optimizers of neural networks have the same shape

273
00:30:53,440 --> 00:30:58,800
as neural networks themselves. So on the top here, the idea is, so on the left and right,

274
00:30:58,960 --> 00:31:04,480
we have parameters, but on top we have the state saved by these optimizers, the stateful ones like

275
00:31:04,480 --> 00:31:11,440
momentum or add-on. And this gives us hints that optimizers are some kind of hardwired

276
00:31:11,440 --> 00:31:16,320
meta learners and just as some papers have shown. So there's lots of interesting research opening

277
00:31:16,320 --> 00:31:21,120
up to this. And an interesting thing from a personal standpoint happened with regards to

278
00:31:21,120 --> 00:31:26,080
optimizers. We started formalizing gradient descent using lenses, this concept that I

279
00:31:26,080 --> 00:31:31,520
mentioned that models by directionality. And for a long time actually had suspicions about

280
00:31:31,520 --> 00:31:38,240
this formalization. The problem was that there was a part of a lens that really wasn't used at all

281
00:31:38,240 --> 00:31:44,560
in gradient descent, casting reasonable doubt on whether lenses are the right abstraction.

282
00:31:45,920 --> 00:31:51,360
Maybe they are really an overgeneralization. But then as we went on to formalize more

283
00:31:51,360 --> 00:31:57,600
complicated optimizers, such as the one that used Nestor of momentum, we found that the bit

284
00:31:57,600 --> 00:32:03,040
that computes the look ahead in Nestor of momentum, the one that's always lost over in explanations

285
00:32:03,040 --> 00:32:08,160
and when you implement these things, it requires rethinking about how you structured the stuff.

286
00:32:08,160 --> 00:32:12,000
It had a natural place in our formulation. It was the thing that we didn't use before.

287
00:32:13,360 --> 00:32:19,120
So really, from a personal standpoint, it clarified how a lot of these things fit that we

288
00:32:19,120 --> 00:32:29,920
started using this categorical formulas. And lastly, we're not the only ones using them.

289
00:32:29,920 --> 00:32:37,920
So very recently, about a week ago, I found a deep learning professor at New York University,

290
00:32:37,920 --> 00:32:44,560
if I'm not mistaken, independently starting to use the same sort of graphical notation

291
00:32:44,800 --> 00:32:54,000
as the formal one we have been using. And I'm quite amazed that we were sort of having formal

292
00:32:54,000 --> 00:33:02,400
justification that these two notations have converged to the same representation.

293
00:33:04,160 --> 00:33:08,000
So yeah, this shows one line of work that has been done with machine learning,

294
00:33:08,000 --> 00:33:13,760
with category theory. Other people have studied different things. People have studied recurrent

295
00:33:13,760 --> 00:33:20,160
neural networks. And it has a very strange title here, but if you open the paper, you'll see that

296
00:33:20,160 --> 00:33:25,840
it does study recurrent neural networks. And in recurrent neural networks, we have the

297
00:33:25,840 --> 00:33:30,960
idea of back propagation through time, which is done by unrolling the recurrent neural network.

298
00:33:30,960 --> 00:33:38,560
Now, what this paper showed is an interesting thing that this process of back propagation

299
00:33:38,560 --> 00:33:43,600
through time doesn't merely use differentiation, but it is differentiation

300
00:33:44,720 --> 00:33:49,520
in a very sophisticated way. And it uses the formalism of something called double categories,

301
00:33:49,520 --> 00:33:55,200
which is yet an even more advanced but very visual concept. So this short picture shows you

302
00:33:55,200 --> 00:34:04,640
how you can think of each time step of recurrent neural network as a vertical kind of morphism,

303
00:34:04,640 --> 00:34:07,600
and you can think of layers of neural network as horizontal.

304
00:34:13,280 --> 00:34:20,080
And then Petar and Andrew, who are co-organizers of this course, have done a lot of work on

305
00:34:20,080 --> 00:34:24,400
geometric deep learning and graph neural networks. And they've established a connection between

306
00:34:24,400 --> 00:34:29,440
graph neural networks and dynamic programming, which is quite fascinating because this might

307
00:34:29,440 --> 00:34:33,520
be such very different things, thinking about how graph neural networks work and how

308
00:34:34,240 --> 00:34:39,920
the algorithm of, say, Bellman-Ford works. Yet again, using the abstractions of category theory,

309
00:34:39,920 --> 00:34:50,160
we can say something more precise about this. And generally about, yeah,

310
00:34:53,360 --> 00:34:57,280
in generally about all of these neural networks, this is some of the stuff that has been done.

311
00:34:57,600 --> 00:35:04,160
But really, there is so much more work to be done and so many more things to explore. I've just

312
00:35:04,160 --> 00:35:10,240
given you a glimpse of some of the interesting things, but really, transformers haven't been

313
00:35:10,240 --> 00:35:14,720
studied, have been studied to some small degree, but there's so much work really to do on them,

314
00:35:14,720 --> 00:35:19,600
through category theory. Geometric deep learning is being studied now, actually,

315
00:35:19,600 --> 00:35:25,680
through category theory, but then again, this is such a vast field. And the same holds for

316
00:35:26,320 --> 00:35:32,400
generative adversarial networks, outer regressive models, NLP, these are all things,

317
00:35:32,400 --> 00:35:38,000
all fields, which could benefit from having more and more eyes apply categorical methods.

318
00:35:38,000 --> 00:35:44,160
I think we're at a point where there's so much ideas and thoughts and we're trying to scale up

319
00:35:44,160 --> 00:35:51,440
these processes of studying things categorically. And the only thing we're lacking is resources

320
00:35:51,440 --> 00:36:01,680
and people knowing about this. So this brings us towards the end of today's lecture.

321
00:36:03,760 --> 00:36:12,160
We have seen how ACT is a rising field, how we can study a number of different scientific fields

322
00:36:13,920 --> 00:36:17,280
and really a number of subfields of machine learning through the same lens.

323
00:36:18,160 --> 00:36:24,640
It is based upon compositionality and we've seen how it gives us this uniform description of

324
00:36:24,640 --> 00:36:32,320
processes and concepts. Now, in this lecture, I didn't really go into any of the details. And as

325
00:36:32,320 --> 00:36:40,480
I've said, this is contrary to how category theory is usually defined and introduced. It is very

326
00:36:40,480 --> 00:36:46,320
verbose and mathematical, but once we start going into it, it becomes very hard to gain

327
00:36:46,320 --> 00:36:54,080
the intuition. So what we're trying to aim for in this course is to start slow and to motivate

328
00:36:54,080 --> 00:37:00,160
these examples. So if you want to learn more about how all of these concepts and systems

329
00:37:00,800 --> 00:37:10,000
can be thought of in this uniform way, we invite you to check out the next week's lectures

330
00:37:10,000 --> 00:37:15,440
and to gain a really more precise and concrete understanding of the things I've been saying

331
00:37:15,440 --> 00:37:27,280
about here. And really, to end with this, it's something that we want to communicate that really

332
00:37:27,280 --> 00:37:33,280
applying this category theory to deep learning is one part of what category theory does, but

333
00:37:33,280 --> 00:37:40,320
once you start thinking about this through the categorical lens, things, all things start

334
00:37:40,320 --> 00:37:47,120
looking like category theory. So this is something we hope to communicate. I've put up a number of

335
00:37:47,120 --> 00:37:51,920
references and reading lists here for people to, this slides are going to be put up online,

336
00:37:51,920 --> 00:37:56,080
so you'll be able to click on them and have a look at some of the interesting conceptual things,

337
00:37:56,080 --> 00:38:00,640
some of these are books, some of these are lectures that might be beneficial in getting a sense

338
00:38:00,640 --> 00:38:08,640
of how this works. But yeah, for now, this is the point where I will end, and I would like to

339
00:38:08,640 --> 00:38:13,600
invite you. So we've had a lot of problems actually with the Google groups and people signing up.

340
00:38:14,320 --> 00:38:19,440
If you still want to sign up, please do because we have opened the Zoom link of this lecture

341
00:38:20,320 --> 00:38:25,760
to everyone because not many people, as I said, could join. But if you want to look at the next

342
00:38:25,760 --> 00:38:34,240
lectures, please sign up on the course website and do check out Zulip, which is also linked to

343
00:38:34,240 --> 00:38:38,640
course participants where you can chat about category theory, chat about all of these lectures,

344
00:38:38,640 --> 00:38:44,320
ask questions. This Zulip is a part of the wider applied category theory community,

345
00:38:44,320 --> 00:38:49,520
so you'll be able to see how actual categories chat and the concepts we talk about and how these

346
00:38:49,520 --> 00:38:56,880
things work. Although I would warn you to thread carefully there, some of these things are very

347
00:38:56,880 --> 00:39:05,520
foreign and scary looking, but hopefully by the end of this course they will be less so. So yeah,

348
00:39:05,520 --> 00:39:11,600
thank you very much. Wonderful. Thank you so much, Bruno, for the great talk and the great

349
00:39:11,600 --> 00:39:18,320
introduction to this vast landscape of categories, which as you mentioned, in the coming weeks we

350
00:39:18,320 --> 00:39:25,040
will dive into more, starting with my own lecture next week where we'll talk about the basic objects

351
00:39:25,040 --> 00:39:31,680
in category theory in a more rigorous way. There's a lot of very interesting questions in the Zoom and

352
00:39:32,240 --> 00:39:36,080
I'll be acting as a sort of moderator, reading them out to you and we can do a bit of back and

353
00:39:36,080 --> 00:39:43,520
forth. So the top rated question comes from Matej Zetrovic and it comes with this motivation of

354
00:39:43,520 --> 00:39:48,320
you have probabilistic circuits like some product networks that are compositional with respect to

355
00:39:48,320 --> 00:39:52,880
both conditions that you presented. However, they're not as good as neural networks in terms of

356
00:39:52,880 --> 00:39:58,800
expressivity. So a generative neural network can make better images than the ones from a

357
00:39:58,800 --> 00:40:05,120
generative some product network. So then the question is, should we invest more time into

358
00:40:05,120 --> 00:40:10,480
studying a non-compositional model like neural networks and make them compositional or see how

359
00:40:10,480 --> 00:40:14,720
you can scale something that's inherently compositional like a some product network? What are your thoughts

360
00:40:14,720 --> 00:40:21,760
on this? Yeah, that's an interesting question and as I've mentioned in the beginning,

361
00:40:21,840 --> 00:40:29,360
compositionality is a property of the model of our systems. So to me it seems like the model

362
00:40:29,920 --> 00:40:35,760
that we have of these non-compositional systems might be non-compositional in nature,

363
00:40:35,760 --> 00:40:41,200
which doesn't necessarily mean that the actual model is non-compositional. It might be the fact

364
00:40:41,200 --> 00:40:46,960
that we don't know what the essential composable building blocks are. So I'm not sure if I can

365
00:40:46,960 --> 00:40:54,560
provide a good answer to which of the things we should study. I'm very biased in towards taking

366
00:40:54,560 --> 00:40:59,120
out a system that doesn't seem compositional but feels like it is and then trying to make it so,

367
00:40:59,120 --> 00:41:06,800
trying to understand how information flows and what are the compositional building blocks. So

368
00:41:06,800 --> 00:41:15,040
that would be my answer. All right, the second question comes from Siavash and it's a very quick

369
00:41:15,040 --> 00:41:21,360
one. So what, if anything, is the difference between compositionality versus composability?

370
00:41:22,640 --> 00:41:28,320
Yeah, so these are, this might be a very loosely defined term sometimes composability,

371
00:41:28,320 --> 00:41:32,880
for instance. Some people use composability to mean literally that we can plug together

372
00:41:32,880 --> 00:41:40,080
systems, processes, functions, but then when we plug these things, composable things together,

373
00:41:40,320 --> 00:41:46,480
they, people don't often mean that we can study the behavior of the composite in terms of the

374
00:41:46,480 --> 00:41:51,600
smaller constituents. But then again, I think I found people using, at least in category theory,

375
00:41:51,600 --> 00:41:58,160
the concept of composable only when we can study them, when we can study the

376
00:41:59,760 --> 00:42:04,240
resulting system recursively. So I think you might find like different usages in different

377
00:42:04,240 --> 00:42:09,280
communities. In category theory, this is taken very seriously. So you would call things composable

378
00:42:09,280 --> 00:42:12,320
only if you have some sort of guarantees like this.

379
00:42:14,800 --> 00:42:21,920
Okay, with this top rated from Grigori asks, is there a particular book you would recommend for

380
00:42:21,920 --> 00:42:25,520
beginners? I have a particular book I would recommend, but maybe you have one or two?

381
00:42:26,320 --> 00:42:30,400
Well, maybe you can start with yours. I mean, let's start with seven sketches for sure.

382
00:42:33,040 --> 00:42:38,240
Yeah, I would say that it often depends on where you're coming from. I would say seven

383
00:42:38,240 --> 00:42:43,760
sketches in composition, compositionality linked here is a really good resources for

384
00:42:43,760 --> 00:42:48,480
scientists, engineers, and programmers in general. If you're coming from programming,

385
00:42:48,480 --> 00:42:54,800
specifically, you might want to look at category theory for programmers by Bartosz Mielewski,

386
00:42:54,800 --> 00:43:01,200
that which is a great research as research aims specifically at programmers. I will actually

387
00:43:01,200 --> 00:43:08,000
link in the Zulib. I specifically keep a list of best introductory category theory resources

388
00:43:08,000 --> 00:43:13,520
on my GitHub. So I don't have it here, but I will add it and I will link it in the Zulib,

389
00:43:13,520 --> 00:43:18,320
which includes a number of many more like blog posts, videos and books.

390
00:43:19,920 --> 00:43:25,120
Wonderful. Yeah, that will be very useful, I think, for the attendees. So there is a question

391
00:43:25,120 --> 00:43:30,240
from Kylan, which asks, could you explain a bit more in detail, what does this graphical

392
00:43:30,240 --> 00:43:34,640
representation of your network actually bring us? For example, the diagram you showed from

393
00:43:34,640 --> 00:43:40,000
Alfredo Canziani, you said it seems to be just a diagram. What does it actually help us understand?

394
00:43:41,840 --> 00:43:50,880
Yeah, so this is a really good question. So I will go back to this slide. So the short answer is

395
00:43:50,880 --> 00:43:57,440
it restricts how we're thinking about this and it restricts the things we can do to this diagram.

396
00:43:57,440 --> 00:44:02,800
So this might sound a little bit counterintuitive because we have a language and then it's very

397
00:44:02,800 --> 00:44:11,280
restrictive, but this is in fact a very useful design tool is to constrain ourselves. So I actually

398
00:44:11,280 --> 00:44:18,400
had a quick chat on Twitter with Alfredo and I noticed some of the ways, some of the things,

399
00:44:18,400 --> 00:44:23,040
some of the ways he uses the diagrams to wire up some things were very non-compositional because

400
00:44:23,040 --> 00:44:28,000
when you plug systems together, you wouldn't get a thing of the same kind, but through category

401
00:44:28,080 --> 00:44:34,800
we have found another way to plug these things together to make it compositional. So the answer is

402
00:44:34,800 --> 00:44:40,640
it helps us reason about the systems and really one day I hope we can implement these things.

403
00:44:42,720 --> 00:44:46,240
Because as you'll find when you think about deep learning, there's the whole theory, but the way

404
00:44:46,240 --> 00:44:52,240
implement sometimes has tricks and tweaks and there's not a uniform translation of the theory

405
00:44:52,240 --> 00:45:01,920
into implementation and I think my sort of very long term goal is to have a completely formal and

406
00:45:01,920 --> 00:45:07,280
uniform description of these processes at a high level, but also exactly at a low level

407
00:45:07,280 --> 00:45:15,680
and I think these diagrams help us show this. So maybe to emphasize when we draw these diagrams,

408
00:45:15,680 --> 00:45:21,120
this is exactly how we would implement them. There's not a secret thing going on that you

409
00:45:21,120 --> 00:45:25,760
have to be careful, like you can take these diagrams very, very seriously, which is not something that

410
00:45:25,760 --> 00:45:30,160
can be done with informal notation. I hope that answers the question.

411
00:45:31,920 --> 00:45:37,920
All right, yeah, thanks for that. If the person asking the question wants to follow up, please

412
00:45:37,920 --> 00:45:43,440
feel free to. The current top rated questions and thank you for all these questions, they're really,

413
00:45:43,440 --> 00:45:46,960
really interesting and they keep pouring in, which is great to get this kind of engagement.

414
00:45:47,600 --> 00:45:51,920
We're obviously all happy to keep discussing even after the lecture on Zulip and otherwise.

415
00:45:51,920 --> 00:45:56,960
The top question right now is from Siva and it asks, since categories and geometry have a rich

416
00:45:56,960 --> 00:46:01,040
interaction, can we use category theory to understand the geometry of neural networks,

417
00:46:01,040 --> 00:46:05,520
such as the geometry of its parameter space or the symmetry of space?

418
00:46:07,040 --> 00:46:12,640
Well, yeah, this is another great question and I think Petar might be in a much better position

419
00:46:12,640 --> 00:46:18,240
than me to answer this. I think we both believe the answer is yes, but maybe I'll leave it to Petar

420
00:46:18,240 --> 00:46:25,440
here. Yeah, I mean, I'll just add that so I know that many people who are signed up to attend this

421
00:46:25,440 --> 00:46:29,440
course have already some working knowledge of geometric deep learning where we use geometry

422
00:46:29,440 --> 00:46:35,440
to understand neural network architectures as a covariant functions. And one thing you will see

423
00:46:35,440 --> 00:46:42,560
in this course, especially in PIMS lecture, which is in week four, is that actually you can observe

424
00:46:42,560 --> 00:46:50,480
equivalents as a special case of a more broader category theory concept called naturality, which

425
00:46:50,480 --> 00:46:58,000
effectively makes the conditions far more relaxed. For example, you don't need all of your functions

426
00:46:58,000 --> 00:47:02,000
to be symmetries to analyze such a system. They don't need to compose with each other,

427
00:47:02,000 --> 00:47:07,040
inverses don't have to exist. So you can be in a way resistant even to functions that destroy

428
00:47:07,040 --> 00:47:11,520
some of your data rather than just leave it exactly the same. So in a way, it's something that

429
00:47:11,520 --> 00:47:17,280
encompasses equivalent functions, but then allows you to model way more interesting things than that.

430
00:47:17,840 --> 00:47:24,800
And I believe this also answers the question that Freddie Minow posted on his applied category

431
00:47:24,800 --> 00:47:28,880
theory, a super set of geometric deep learning. The short answer that PIMM already wrote is that

432
00:47:28,880 --> 00:47:35,280
we definitely think so. And the lecture from PIMM should elaborate this connection a lot more.

433
00:47:35,680 --> 00:47:45,040
Okay. So then we have an operator question from Nitin that asks, can we quantify or understand

434
00:47:45,040 --> 00:47:50,480
the causality or counterfactual nature of systems if they have compositionality? Does it add some

435
00:47:50,480 --> 00:47:54,880
explainability nature to the system as a whole instead of looking at the subset of components

436
00:47:54,880 --> 00:48:02,160
as independent modules that are not interdependent? Oh, these are all really, really good questions.

437
00:48:02,240 --> 00:48:07,760
I actually don't know what the answer to this is. So there's been some work. Well, there's been

438
00:48:09,040 --> 00:48:14,640
a number of papers studying category theory and causality, but I'm actually not sure what is

439
00:48:14,640 --> 00:48:21,440
the state of the art with regards to counterfactual reasoning. There is certainly lots of papers

440
00:48:21,440 --> 00:48:26,480
doing this, but I'm afraid I can't give a good answer to this. We certainly hope so that

441
00:48:27,280 --> 00:48:31,600
something comes out, but it's not something that I think we can substantiate just yet.

442
00:48:32,800 --> 00:48:38,080
Yeah, I think maybe I'll use this opportunity to plug one of our guest lectures from Taco Cohen,

443
00:48:38,080 --> 00:48:42,160
who has worked quite a bit recently on trying to use category theory to formalize

444
00:48:42,720 --> 00:48:47,200
causal reasoning in machine learning models, who has this very nice position paper on it

445
00:48:47,200 --> 00:48:52,320
that came on the archive recently. And he will be giving us a guest lecture on this exact topic.

446
00:48:52,320 --> 00:48:57,680
So please do stick around if you're interested in applications of category theory for causality.

447
00:48:57,680 --> 00:49:02,880
I had a chance to speak to Taco on this on a few occasions, and he seems quite convinced that we

448
00:49:02,880 --> 00:49:08,640
need category theory to reason about causality in the right way. So it'll be very interesting to

449
00:49:08,640 --> 00:49:15,040
hear his thoughts on this. The current top rated question comes from Flavio, and it says,

450
00:49:15,040 --> 00:49:19,920
category theory tutorials might be easy to find. Can we get more info on the specific relation

451
00:49:19,920 --> 00:49:25,760
with deep learning? I think the answer to this question is really that those connections will

452
00:49:25,760 --> 00:49:30,480
happen in the coming lectures, unless Bruno, you want to add anything else on top of that.

453
00:49:32,240 --> 00:49:37,360
No, no, you're right. I would add that I also have a GitHub sort of listing all the papers

454
00:49:37,360 --> 00:49:43,680
in category theory in machine learning. This is precisely the GitHub that hosts the data used

455
00:49:43,680 --> 00:49:50,560
to generate this graphic. So maybe I'll also link that in the zealot. So that might be a good thing

456
00:49:50,560 --> 00:49:53,760
to have a look before the next week's lecture to see what has been done.

457
00:49:54,720 --> 00:50:01,760
Yeah, sounds good. Yes, definitely do share that if you have a chance. Andrew, I think you have a

458
00:50:01,760 --> 00:50:07,360
raised hand. Yes, I just wanted to emphasize, especially with the previous or earlier question,

459
00:50:08,160 --> 00:50:12,640
that at the moment there is no book on this subject, on the connection between category

460
00:50:12,640 --> 00:50:20,640
theory and deep learning. So we're going to do our best in these lectures, but it's not

461
00:50:20,720 --> 00:50:29,120
so easy to give reference materials besides these papers. This is a gap we're trying to

462
00:50:29,120 --> 00:50:33,840
fill with these lectures. Yeah, I think that's also a good point to have. Although the seven

463
00:50:33,840 --> 00:50:39,440
sketches, if you don't count machine learning per se, is a good starting point to just understand

464
00:50:39,440 --> 00:50:44,800
what all these string diagrams are like and how they connect different areas. Yeah, for programming

465
00:50:44,880 --> 00:50:55,280
and CS, plenty of resources, but yeah. Okay, so let's see, what else do we have?

466
00:50:56,240 --> 00:51:02,000
So there's a lot of questions floating around. I'm just trying to pick which one. Okay, yeah,

467
00:51:02,000 --> 00:51:06,160
this one is an interesting one. It's a bit philosophical, so I'm curious to hear Andrew,

468
00:51:06,160 --> 00:51:10,880
sorry, Bruno, what you think about it. It comes from Lucino Prince. Do you think that

469
00:51:10,880 --> 00:51:16,480
composability is a true constituent of nature, or is just the limit of how much we can understand?

470
00:51:18,080 --> 00:51:27,200
Oh, I love these questions. I wish I could provide a really coherent answer to this. Certainly,

471
00:51:27,200 --> 00:51:35,040
it seems like everywhere we look, things are compositional. But this might be like the story

472
00:51:35,040 --> 00:51:39,440
of trying to find your car keys under the lamp post because that's where the light is.

473
00:51:40,400 --> 00:51:46,640
We are certainly not doing compositionality. There's so many things that seem so foreign to us,

474
00:51:48,000 --> 00:51:51,680
and we just don't look there. We look at the things which are compositional.

475
00:51:53,440 --> 00:51:58,240
Oh, god, yeah, I'm not sure how to answer this question. So this is a very

476
00:52:00,720 --> 00:52:06,800
conservative answer. That's what I'll say. I don't know if anybody else from the team has a response to this.

477
00:52:09,600 --> 00:52:18,160
I think the question caught me a bit off guard. I'll have to think about it a bit more. But

478
00:52:18,880 --> 00:52:22,800
yeah, Pym, Andrew, do you guys have some thought on this question on your side?

479
00:52:22,800 --> 00:52:38,960
I mean, I think there's probably evidence somewhere that we tend to at least learn

480
00:52:38,960 --> 00:52:45,280
things in a compositional way. I mean, I guess whether there's some underlying

481
00:52:46,240 --> 00:52:55,680
nature is a big question. It's surely a very nice way to organize existing information,

482
00:52:55,680 --> 00:53:03,200
let's say, if you think about it in a compositional manner. That just allows you to reason about it

483
00:53:03,200 --> 00:53:13,920
a lot more easily. Okay, so let's see. There is a lot of new questions. The current top question,

484
00:53:14,000 --> 00:53:19,760
which I think hasn't already been answered. And I guess it comes from some of our more

485
00:53:19,760 --> 00:53:24,800
mathematically oriented audience. Stanislav specifically asks, if we're going to talk about

486
00:53:24,800 --> 00:53:29,520
two categories, should we actually then consider enriched and end categories in principle?

487
00:53:31,040 --> 00:53:37,840
Yeah, so this is certainly the next step. So a lot of the things I did not mention in this

488
00:53:37,840 --> 00:53:46,160
very brief lecture is enriched categories or pre categories or higher category theory. There is

489
00:53:46,160 --> 00:53:55,440
certainly an abundance of theory and thoughts and expressivity in all of these more nuanced areas.

490
00:53:56,640 --> 00:54:01,840
So yeah, these are certainly things to study and give us a particular flavor of category theory.

491
00:54:02,160 --> 00:54:08,800
And yeah, I would invite you if you know, but I would consider these to be advanced topics for now.

492
00:54:10,960 --> 00:54:16,160
Okay, yeah, I definitely agree. Let's learn how to crawl before we learn how to run. And

493
00:54:16,160 --> 00:54:20,960
there is a reason why some people might perceive the content so far to be a bit slow starting.

494
00:54:20,960 --> 00:54:25,520
We have a very diverse audience coming from all sorts of backgrounds and we're trying to accommodate

495
00:54:25,520 --> 00:54:32,080
for all of those backgrounds appropriately. So we have one very fast-rising question from

496
00:54:32,080 --> 00:54:36,640
Ewan, which asks, I'm aware there's been some research on category theory to motivate the

497
00:54:36,640 --> 00:54:42,240
graph neural network design. Has any work or much work been done to use these ideas to construct

498
00:54:42,240 --> 00:54:47,840
modular and composable neural networks or more interpretable representations in the spirit of

499
00:54:47,840 --> 00:54:51,120
say what Chris Ola has been doing with representations as types?

500
00:54:53,840 --> 00:55:03,520
Yeah, so that's something I would love to think about and work on. To my knowledge, the answer is no.

501
00:55:05,200 --> 00:55:10,000
Yeah, to my knowledge, the answer is no. But it seems like there is really no obstacle to doing

502
00:55:10,000 --> 00:55:19,440
so, at least no major obstacle. So yeah, yeah. All right, then another top-rated question.

503
00:55:19,440 --> 00:55:24,240
Yeva asks, which kinds of categories, broadly speaking, are we going to focus on most in this

504
00:55:24,240 --> 00:55:28,720
course? So what do we see to be the most interesting categories for deep learning at this time?

505
00:55:30,720 --> 00:55:38,080
Right, so well, in this next week's lecture that Petter says is going to give, we're going to talk

506
00:55:38,080 --> 00:55:44,000
about categories in general. But the one after this, we're going to talk about, so categories

507
00:55:45,120 --> 00:55:51,280
allow us to compose processes in a sequence, which is useful, but in a way limited, because often

508
00:55:51,280 --> 00:55:57,840
in nature, we compose processes that is in parallel. So in third lecture, we're going to be studying

509
00:55:57,840 --> 00:56:04,640
things called monoidal categories, where you can put processes in parallel. And very interestingly,

510
00:56:04,720 --> 00:56:09,440
these are not processes where you can necessarily copy information, delete information, some

511
00:56:09,440 --> 00:56:15,600
information. So we're going to add extra layers of new ones by studying things called Cartesian

512
00:56:15,600 --> 00:56:22,960
categories where you can start to do all of these things. And then later, yeah, so we're going to

513
00:56:22,960 --> 00:56:31,440
study, yeah, I'm not sure how to best describe it right now without going into depth, how to start

514
00:56:31,440 --> 00:56:40,240
talking about sort of things used in equity variants. It's sort of the things that might

515
00:56:40,240 --> 00:56:47,280
not be easy to explain right now before unpacking the lectures. But we're going to study part of

516
00:56:47,280 --> 00:56:51,120
the things we're studying here is not just categories, but the ways these are categories

517
00:56:51,120 --> 00:56:56,080
are related and concepts build on top of them. So we're going to study functors between categories,

518
00:56:56,080 --> 00:57:00,800
monads on these categories, and various these algebraic structures that allow us to describe

519
00:57:00,800 --> 00:57:06,640
this wiring of processes or some structure preserving maps between them. Yeah.

520
00:57:08,480 --> 00:57:13,280
All right. Thank you for that. The current talk question from Jeffrey asks,

521
00:57:13,280 --> 00:57:18,160
it's potentially also a philosophical question. How do you find or how do you decide what are

522
00:57:18,160 --> 00:57:23,840
the essential composable blocks of what you want to study? Yeah, I mean, I think this is

523
00:57:23,840 --> 00:57:27,520
really a question that's not really specific to category theory. It's sort of

524
00:57:28,480 --> 00:57:33,680
generally to science, we're trying to find building blocks and trying to find the basic

525
00:57:33,680 --> 00:57:43,520
concepts. And I think this is really an art at this point. There's not, we cannot really formalize

526
00:57:43,520 --> 00:57:54,880
and systemize this, the process of science yet. Okay, so I think our one hour block that you

527
00:57:54,880 --> 00:58:03,280
had allocated for this lecture has just expired. And also at the same time, I actually had to

528
00:58:04,640 --> 00:58:09,920
reset my Zoom, so I actually don't see many of the questions that are still in the Q&A.

529
00:58:10,640 --> 00:58:18,800
So perhaps if Andrew or someone can see if there's any other big salient questions left,

530
00:58:18,800 --> 00:58:22,640
otherwise I think it's okay if we continue the discussion on Zulip. We already covered

531
00:58:23,360 --> 00:58:29,760
a lot of grounds. The top one is just asking if we can put up slides in advance, which I think

532
00:58:29,760 --> 00:58:36,560
we can try to do, but I would depend on the speaker. Yeah, I'll definitely put my slides up

533
00:58:36,560 --> 00:58:43,040
before the lecture and maybe we can start doing it more going forward. I think for the first lecture,

534
00:58:43,040 --> 00:58:48,720
we're just trying to make sure everybody gets access to this Zoom properly. But going forward,

535
00:58:48,720 --> 00:58:52,400
when we start to get more technical, we will definitely aim to share the slides in advance.

536
00:58:52,880 --> 00:59:09,680
Okay, yeah, so I think we will leave it at that. Thank you so much for coming to our first lecture,

537
00:59:09,680 --> 00:59:15,040
and we hope you enjoyed. Bruno, thank you so much also for delivering a great motivational

538
00:59:16,480 --> 00:59:21,440
entrance to everything that will come next. And we hope you enjoyed it. We hope to keep

539
00:59:21,440 --> 00:59:27,760
the discussion going. So if you want to join us on Zulip in the coming days and weeks and discuss

540
00:59:27,760 --> 00:59:34,800
the various aspects of the course with us as we go along and materials and so on, that would be

541
00:59:34,800 --> 00:59:39,520
really great. And if you have any feedback on how things have gone today and how you would like them

542
00:59:39,520 --> 00:59:46,240
to go forward, please do interact with us. However, you prefer to leave us that feedback

543
00:59:46,240 --> 00:59:51,040
directly or anonymously. We very much welcome any comments you have. It's a course we're actively

544
00:59:51,040 --> 00:59:57,840
building together with all of you. So on that note, let's thank Bruno one more time. And yeah,

545
00:59:57,840 --> 01:00:02,880
hope you enjoyed and hope you'll have a great rest of your week. I will see you in a week's time

546
01:00:02,880 --> 01:00:06,960
for a discussion of fundamentals of category theory.

