WEBVTT

00:00.000 --> 00:06.640
the Q&A button, or raise your hand after the talk and we can call on you to ask a question

00:06.640 --> 00:12.720
by video or audio. A little bit of logistics, we still have an open slot on December 8th,

00:12.720 --> 00:17.600
so if you have a talk at any length, it can be less than an hour or a full hour,

00:17.600 --> 00:22.960
and you want to share with the BCS Cog Launch community, just get in touch with me by email,

00:22.960 --> 00:27.520
you can respond to that announcement email that you got for this event, and we can work that out.

00:27.920 --> 00:33.840
With that, let's get to our main content. So, Sue, we're telling us today about rapid

00:33.840 --> 00:43.440
generalization of knowledge and structured domains. Take it away, Sue.

00:57.520 --> 01:13.840
All right. So, as John mentioned, I'm Sue. I'm a third-year PhD student in the BCS department,

01:13.840 --> 01:19.280
and I'm co-advised by Professor Ela Feed and Professor Josh Tenenbaum. And in general,

01:19.280 --> 01:24.000
the question I'm interested in is, how do people generalize their learning to novel situations?

01:24.000 --> 01:28.320
And in any given domain, if the underlying space is structured, we might learn those

01:28.320 --> 01:32.800
underlying structures independently of the sensory observations, and that might in turn

01:32.800 --> 01:38.080
help us generalize to novel situations. So, what I'm presenting today is a step towards

01:38.080 --> 01:43.200
answering this question. I'll start with motivation, and then I'll make a case for why

01:43.200 --> 01:48.000
hippocampal entorhinal system is an important system to study if you're interested in generalization.

01:48.560 --> 01:52.720
And then I've divided the rest of my talk in three parts, and I'll give you a brief overview

01:52.720 --> 01:58.880
of those three parts before I go into the details of each of those. So, imagine you go to Costco

01:58.880 --> 02:04.320
in Waltham, since there's no Costco in Cambridge, and you learn the map of Costco. So, now you know

02:04.320 --> 02:08.800
where the bakery section is or where the fruit section is, and now imagine you go to a completely

02:08.800 --> 02:14.160
different country, let's say Canada, you go to Waterloo, and you go to Costco there. Even there,

02:14.160 --> 02:18.240
Costco might have the same layout, or it might have a layout which is some transformation of the

02:18.240 --> 02:21.920
original layout. For instance, it might be a reflective version of the original, or there

02:21.920 --> 02:26.560
might be minor changes. And despite of that, you're still able to find the things you're looking for

02:26.560 --> 02:32.240
using your previous knowledge of the map of Costco. Another example is roundabouts. So, if you learn

02:32.240 --> 02:37.920
to go about a roundabout in Cambridge, then even if you go to any other country or city,

02:37.920 --> 02:42.720
then you will be able to use your previous knowledge to actually navigate through that roundabout.

02:43.440 --> 02:47.680
So, generally, we learn novel environments as compositions of spatial structures that we've

02:47.680 --> 02:52.320
already seen before, and that allows us to quickly generalize and learn new spatial

02:52.320 --> 02:56.560
environments. For instance, when you go to a new city, you might encounter Costco again,

02:56.560 --> 03:01.040
you might encounter a roundabout again, and you know which map to pull out when you are in Costco,

03:01.040 --> 03:08.800
and which map to pull out when you are navigating around a roundabout. And so, here's another example

03:08.800 --> 03:14.880
where this is a hotel which has symmetric left and right wings, and if one has explored the left

03:14.880 --> 03:19.600
wing of this hotel, then they might be very quickly able to generalize their learning to the

03:19.600 --> 03:23.600
right wing and make inferences about the right wing, even if they haven't really directly explored

03:23.600 --> 03:28.800
the right wing. So, humans are actually very good at making these complex inferences from

03:28.800 --> 03:34.400
just very sparse observations, and this ability has been suggested to be a result of a systematic

03:34.400 --> 03:39.920
organization of knowledge called the cognitive map. And hippocampal entorhinal system is known to

03:39.920 --> 03:45.440
be important for the construction of this cognitive map. So, for instance, rodents when

03:45.440 --> 03:51.360
they explore a 2D spatial environment, it has been found that hippocampus has these place cells

03:51.360 --> 03:57.120
which code locations in the 2D environment, and there are good cells in the entorhinal cortex

03:57.120 --> 04:02.560
which show this hexagonally symmetric firing fields, which are periodic, and which have been

04:02.560 --> 04:07.760
thought to encode location, but also cell motion-based euclidean displacement. And these

04:07.760 --> 04:12.160
codings are important for the construction of cognitive map because they provide an allocentric

04:12.160 --> 04:18.160
representation. So, given that the hippocampal entorhinal system encodes spatial variables,

04:18.160 --> 04:23.120
the next question is, can this also be used to represent other continuous task variables

04:23.120 --> 04:29.440
other than space? And the answer to this question is yes, and I'll give one example. So, here in

04:29.440 --> 04:33.600
this experiment has been found that cells in hippocampus and entorhinal cortex respond to

04:33.600 --> 04:39.120
task-relevant variables like sound frequency. So, in this task, rodents pull this lever,

04:39.120 --> 04:43.520
and as they pull the lever, the frequency of the sound coming from this sound source

04:43.520 --> 04:47.360
actually keeps increasing, and they have to release the lever when this frequency is in

04:47.360 --> 04:52.560
this target zone. And what is found is that in hippocampus and entorhinal cortex, there are cells

04:52.560 --> 04:59.680
that fire for specific frequencies during the sound modulation task. So, that shows that

05:00.640 --> 05:05.680
entorhinal cortex is a system that is able to represent continuous task variables,

05:05.680 --> 05:10.480
even other than space. And so, our next question is, could this system also help us organize

05:10.480 --> 05:15.440
and navigate discrete knowledge? And family trees are one example of discrete knowledge.

05:15.440 --> 05:20.080
So, in family trees, there's an underlying hierarchical structure that we learn. And once we

05:20.080 --> 05:23.680
know that structure, then we can apply that structure to my family tree or to your family

05:23.680 --> 05:27.840
tree or anyone's family tree, and we can generalize that knowledge. So, we can make inferences like

05:27.840 --> 05:33.600
this, because Olivia is Emily's sister and Sam is Emily's son, Sam must be Olivia's nephew.

05:33.600 --> 05:38.080
So, even though we haven't directly observed this relationship, but just by mere observation of

05:38.080 --> 05:42.080
these two relationships, we are able to infer this relationship, because we know the underlying

05:42.080 --> 05:47.440
hierarchical structure of this family tree. So, it is possible that hippocampal entorhinal system

05:47.440 --> 05:52.400
might allow organization of this kind of a discrete knowledge, but that's only possible if it allows

05:52.400 --> 05:58.000
encoding non-Equidian relationships. With that, I'll go back to the spatial domain,

05:58.000 --> 06:03.360
and I'll talk about how spatial knowledge might be organized. And when I talk about organization,

06:03.360 --> 06:08.480
I'll point to the fact that even in a continuous domain like space, it might be possible that

06:08.480 --> 06:13.120
we have both Euclidean and non-Euclidean components to represent space itself,

06:13.120 --> 06:17.520
and thus making the system generalizable to even discrete domains.

06:18.240 --> 06:26.400
So, here's an experiment conducted by Bill Warren, where they show that people actually do not learn

06:26.400 --> 06:32.080
a global Euclidean map of space. So, in this experiment, they constructed virtual environments,

06:32.080 --> 06:38.640
and they basically, the task was for people, for human subjects. So, this was a human behavioral

06:38.640 --> 06:43.200
experiment, and human subjects were asked to go to different landmarks in this spatial environment,

06:43.200 --> 06:47.040
and they also built counterparts of the spatial environment, which were non-Euclidean,

06:47.200 --> 06:52.400
in these environments. So, when you enter one part of the wormhole, you seamlessly exit from the

06:52.400 --> 06:57.520
other end of the wormhole, and subjects were not aware of the existence of these wormholes.

06:58.080 --> 07:03.520
And basically, what they found through various manipulations of the experiment was that people

07:03.520 --> 07:08.960
do not actually learn a global Euclidean map, but rather a labeled graph, like representation,

07:08.960 --> 07:14.080
where the nodes represent places, the edges represent approximate distances between these

07:14.080 --> 07:19.920
places, and the node labels, which are angles, represent approximate angles between these places.

07:20.800 --> 07:24.480
And so, we built on this representation, and we proposed that people might be

07:24.480 --> 07:30.800
representing topometric maps, which are locally metric or Euclidean, but globally topological.

07:30.800 --> 07:35.040
And the main advantage of this kind of representation is that it allows us to combine

07:35.040 --> 07:40.560
accurate local maps into a global map, which might be inconsistent, but it still provides

07:40.560 --> 07:45.600
enough sufficient information for navigation. So, the next question is,

07:46.400 --> 07:51.120
can this kind of a topometric map be implemented in the brain? And if so, how?

07:51.120 --> 07:55.120
And next, I'm providing a theoretical framework for how it might be possible to represent such

07:55.120 --> 08:00.480
topometric maps using the place cells and grid cells found in hippocampal endorhinal cortex.

08:00.480 --> 08:04.320
So, this is a topometric representation of space. You can see that these are metric maps

08:04.320 --> 08:09.360
connected topologically by these connections. And here, on this side, I'm showing a grid coding

08:09.360 --> 08:14.720
space, which is dense coding space with large capacity. And here, I'm showing place coding

08:14.720 --> 08:20.160
space, which also has large capacity, but it spars, so it can receive sensory inputs and form

08:20.160 --> 08:26.160
conjunctive representations. And so, in this schematic, small changes, sorry, large changes

08:26.160 --> 08:33.120
in contextual input from our spatial domain was remapping in the place cells, which in turn

08:33.120 --> 08:37.280
trigger remapping in the grid cells, enabling the formation of these local metric maps that

08:37.280 --> 08:44.160
can be reused. And so, on this schematic, we can really take any subpart of this schematic and

08:44.160 --> 08:50.400
call it a sub map. And this allows us to compose sub maps, because once we have learned a particular

08:50.400 --> 08:55.680
sub map, then we can actually encounter the sub map in a completely novel situation and still be able

08:55.680 --> 09:05.200
to spatially navigate and reason through it. Another thing that it allows us is learning

09:05.200 --> 09:10.160
non-ecredient relationships, because place cells actually encode topological relationships, enabling

09:10.880 --> 09:16.240
the representation of non-ecredient relations. So, now I'm going to describe the three parts

09:16.240 --> 09:21.760
in which I've divided the rest of the talk. So, in the first part, I'm probing whether

09:21.760 --> 09:28.080
sub maps drive past learning in complex spaces using human behavioral experiments. In the second part,

09:28.640 --> 09:33.600
I will talk about determining which principles might guide fragmentation of a space into

09:33.600 --> 09:39.200
sub maps. And finally, in the third part, I'll propose a framework for building a neural model

09:39.200 --> 09:46.800
of map fragmentation. So, in the first part, I'm probing whether sub maps drive fast learning

09:46.800 --> 09:51.200
in complex spaces, specifically in humans. And this work is in collaboration with Marta Krivind,

09:51.200 --> 09:57.040
who's a postdoc in Tenenbaum Lab, and Kevin, who's an undergrad in the CS department.

09:57.920 --> 10:03.120
So, here I hypothesize that humans learn adaptable and compositional sub maps of spatial

10:03.120 --> 10:08.000
structures. So, for instance, this is a baseline environment, and this is a top-down view showing

10:08.000 --> 10:13.600
an environment with four rooms. And here I've shown certain transformations of this environment

10:13.600 --> 10:19.440
generated by small generator programs. And you can see this is the same environment rotated,

10:19.440 --> 10:24.240
because now you're entering from this point, so it might appear rotated to you. And here's a reflection

10:24.240 --> 10:30.720
of the same environment. Here is a transformation where we've removed the wall and added a shortcut,

10:30.720 --> 10:35.200
and here we've added a wall. And this is just the repetition of the same environments.

10:35.200 --> 10:39.280
And there's another transformation which is scaling, where you can imagine this environment

10:39.280 --> 10:44.480
scaled up to a bigger size, but having the same geometrical layout. And what I'm suggesting is

10:44.480 --> 10:49.120
that once people have learned the map of the space line environment, their representations

10:49.120 --> 10:54.160
might be adaptable to some or all of these transformations. And furthermore, people might

10:54.160 --> 10:59.360
represent richer spaces by combining these maps and their transformations, leading to quick

10:59.360 --> 11:05.360
generalization and learning. So, this can be modeled using Bayesian program learning framework,

11:05.360 --> 11:09.520
where concepts are represented as simple programs, and rich concepts can be built

11:09.520 --> 11:15.840
compositionally from them using a higher-level generative model. So, there is neural evidence

11:15.840 --> 11:21.920
for this hypothesis. So, in this, this is an experiment by the Tonakawa Lab, and they show

11:21.920 --> 11:27.600
that when a rodent goes through this environment in four labs, there are cells which fire specifically

11:27.600 --> 11:32.560
for particular places in this environment, but there are also cells which encode, which are

11:32.560 --> 11:37.200
event-specific and encode specific labs. So, for instance, there are cells which show increased

11:37.200 --> 11:41.440
fighting rates as you go from lab one to lab four, and there are also cells which only fire

11:41.440 --> 11:46.240
specifically on lab one or on lab two and so on. And so, what I'm suggesting is that when we have

11:46.240 --> 11:51.440
repetitions of the same environment, there might be cells that encode the basic map of this environment,

11:51.440 --> 11:56.560
which, which is consistent across these occurrences, but there might be a second set of cells,

11:56.560 --> 12:01.120
which are event-specific and might encode which instance of this environment we are on.

12:02.160 --> 12:09.200
Here's another example, where this is an example of scaling, where the rodent actually just explores

12:09.200 --> 12:14.000
this circular environment, and this is the place field found in that circular environment,

12:14.000 --> 12:18.240
and when the circular environment is scaled up to a bigger size, the place field also scales

12:18.240 --> 12:22.640
according to the size of the environment. So, this shows that the map which the rodent has

12:22.640 --> 12:27.200
learned of this environment is actually adaptable to this transformation of scaling to a bigger

12:27.200 --> 12:32.240
size, and map also scales proportionately with the size of the environment. And here's a third

12:32.240 --> 12:38.480
example, where rodents form different maps, place maps in these different environments,

12:38.480 --> 12:42.080
and when these environments are composed by connecting them through a corridor,

12:42.080 --> 12:46.560
rodents end up using the same maps which they had learned before for these environments. And

12:46.560 --> 12:51.360
furthermore, if I replace this environment with one of the previous environments seen before,

12:51.360 --> 12:56.400
then remapping is only observed in this part of the environment, and this part of the environment

12:56.400 --> 13:02.800
actually stays the same using the same previous map. So, this provides some evidence in support of

13:02.800 --> 13:08.800
composition of independent local sub-maps. So, in my experiment, I aim to assess whether people

13:08.800 --> 13:14.080
learn sub-maps on spatial structures and use them rationally in exploration, and I hypothesized that

13:14.080 --> 13:19.120
people might learn sub-maps that are adaptable and compositional, and my first alternate hypothesis

13:19.200 --> 13:22.560
is that they might learn sub-maps of spatial structures that might not be adaptable or

13:22.560 --> 13:28.000
compositional to certain transformations, and the last alternate hypothesis is that people

13:28.000 --> 13:32.880
might just learn a global representation of environments without learning any sub-maps.

13:32.880 --> 13:39.200
So, in order to test this hypothesis, we're building this task where we are building 3D

13:39.200 --> 13:44.640
virtual environments using Unity, and these environments have this repeating structure,

13:44.720 --> 13:50.240
and the task is for the subjects to find maximum amount of diamonds embedded in these environments

13:50.240 --> 13:55.120
in a limited amount of time given to them, and in order to test adaptability and composition,

13:55.120 --> 13:59.120
we can also have these repetitions be transformations of each other, for instance,

13:59.120 --> 14:03.360
here it's a reflection, or we can also have these environments composed of different structures to

14:03.360 --> 14:07.600
see whether people can compose their representations or structures that they've already seen.

14:08.560 --> 14:13.840
So, here's an example. Here you see that a person is navigating through corridor and enters a

14:13.840 --> 14:18.720
structure, and they go to one of the rooms and they do not find anything there, and then they

14:18.720 --> 14:24.160
decide to go to the other room, and they end up finding a reward there, and now they're going

14:24.160 --> 14:30.480
back to the corridor and they continue exploring the environment, and when they enter another section,

14:30.480 --> 14:35.920
if they show a preferential navigation strategy towards the room that has a reward, then that

14:35.920 --> 14:40.640
indicates that they have realized that there's a repeating structure in the environment and indicates

14:40.640 --> 14:44.960
a possibility that people might be learning sub-maps and identifying sub-maps as they're

14:44.960 --> 14:50.560
navigating the spatial environments, and furthermore, if we do find through the experiment that people

14:50.560 --> 14:56.160
actually learn sub-maps, then we can use similar environments to design experiments where we can

14:56.160 --> 15:03.120
test for adaptability to transformations of environments and also for composition of

15:03.120 --> 15:10.400
different spatial structures. So, that takes me to the next part of the talk, which is

15:10.480 --> 15:14.640
determining which principles guide fragmentation into sub-maps. So, since we are seeing that

15:14.640 --> 15:20.800
sub-maps drive fast learning, the next natural question becomes what determines this fragmentation

15:20.800 --> 15:25.760
of a spatial environment into sub-maps, and this work is in collaboration with Mirko Klukas,

15:25.760 --> 15:32.560
who is a post-doc in the feed lab. So, here my hypothesis is that neural remapping is a signature

15:32.560 --> 15:38.960
of sub-map reconstruction. So, here I'll explain what remapping is. So, basically, this is a 2D

15:39.040 --> 15:46.320
environment, and when the animal just explores this 2D environment, we find hexagonally periodic

15:46.320 --> 15:54.240
grid fields in the entorhinal cortex, and when you actually insert these walls in this environment,

15:54.240 --> 15:59.520
then what is observed is that when the animal turns, then this grid field which is formed either

15:59.520 --> 16:05.200
re-orients or shifts, and this is called remapping, when the grid field actually re-orients or shifts

16:05.200 --> 16:10.640
from its original orientation. And so, what is observed is that animals actually end up using

16:10.640 --> 16:16.800
the same grid maps in alternate arms. So, this indicates the use of maps. And here's another

16:16.800 --> 16:21.760
example of the use of maps. So, basically, this is a 2-room environment, and animals explore

16:21.760 --> 16:29.760
this environment, and it is seen that eventually the map formed in environment A is the same as the

16:29.760 --> 16:34.880
map formed in environment B, over short time scales. So, this is another example of the fact

16:34.880 --> 16:40.480
that animals are reusing the maps in both the rooms which look very similar. So, what I'm suggesting

16:40.480 --> 16:46.080
is that this field repetition doesn't result from localization error or purely due to disorientation,

16:46.080 --> 16:52.320
because even when you use transparent walls in this environment, you still see that the grid

16:52.320 --> 16:57.680
maps are being reused in alternate arms, even though the animal can see through these transparent

16:57.680 --> 17:04.240
walls. Furthermore, if you extend this 2-room environment to a 4-room environment, you still

17:04.240 --> 17:09.360
see field repetition in all of these rooms, which suggests that animals are actually reusing

17:09.360 --> 17:13.920
sub-maps in a calculated way for efficient representation, rather than just being disoriented.

17:18.480 --> 17:23.120
So, next I talk about existing models of remapping, and there are two classes of models.

17:23.120 --> 17:28.400
One class of model suggests that remapping is driven by sensory ambiguity. So, for instance,

17:28.400 --> 17:33.120
if you are in an environment that looks similar to an environment you've been before, either in

17:33.120 --> 17:38.800
terms of its geometry or its visual observations, then you might end up using the same map that

17:38.800 --> 17:43.440
you had learned from a previous environment. Then there's another class of models that suggests

17:43.440 --> 17:48.080
that remapping is based on environment topology, instead of just sensory ambiguity. So, here,

17:48.720 --> 17:52.800
each state in the environment is represented in terms of its successor states, and it's called

17:52.800 --> 17:58.080
a successor representation. And this successor representation actually ends up looking similar

17:58.080 --> 18:02.640
to place feeds, and if you do an identity composition on these successor representations,

18:02.640 --> 18:08.800
then you get fields that are very similar to grid fields. And this successor representation

18:09.280 --> 18:13.840
encapsulates inherent dynamics of the environment, as well as the policy that the agent is following.

18:13.840 --> 18:19.680
However, there are other approaches like the graph-leplacian approach, which is policy independent.

18:21.120 --> 18:24.960
So, what are some of the limitations of these models? So, the models that are

18:24.960 --> 18:30.160
based on sensory ambiguity do not have remapping without sensory ambiguity. So, in an environment

18:30.160 --> 18:36.640
like this, these two regions actually look very different. These models will not have any map

18:36.640 --> 18:45.520
fragmentation or remapping. However, on the other hand, models which are based on environment topology,

18:45.520 --> 18:50.880
actually, it's not very clear how remapping would happen on first visit in these environments,

18:50.880 --> 18:54.240
because you need to build up the successor representation or the transition matrix of

18:54.240 --> 19:01.200
the environment before you can observe the grid fields. So, in our model, we address these limitations,

19:01.200 --> 19:05.360
and we have remapping on first visit, and we also have remapping without sensory ambiguity.

19:05.360 --> 19:10.160
And next, I'll go into the details of our model. So, we interpret grid remapping as

19:10.160 --> 19:14.960
fragmentation into submaps. Why is this a useful interpretation? That's because

19:14.960 --> 19:19.520
remapping enables topological representation. So, for instance, if we are dividing this

19:19.520 --> 19:24.400
environment into submaps, then we also need to store the relationships between these submaps,

19:24.960 --> 19:29.280
and this enables a compact topological representation, which is beneficial for planning.

19:30.960 --> 19:35.200
Second reason is that remapping reduces path integration errors. So, if you try to learn a

19:35.200 --> 19:40.720
global map, it can very quickly become inconsistent because of accumulation of path integration errors.

19:40.720 --> 19:45.520
But if you divide the environment in submaps, then it becomes easier to map the environment.

19:45.520 --> 19:50.880
And this has been shown by using Atlas framework in robotics, where they divide the environment

19:50.880 --> 19:55.440
into submaps in order to map the environment, and it works very well for large environments.

19:56.960 --> 20:01.440
And the third reason is that remapping enables representation of abstract cognitive spaces,

20:01.440 --> 20:07.200
because it allows representation of non-euclidean structures. So, in our model, we have two

20:07.200 --> 20:12.400
possibilities. Either we can extend an old map, or we can decide to remap. And when we decide to

20:12.400 --> 20:17.440
remap, we can either remap to a new map or remap to an existing map. So, for instance,

20:17.440 --> 20:24.320
in the experiments we saw that in the square environment without walls, the map that the

20:24.320 --> 20:30.400
animal learns is always extended. But when we insert these walls in this environment,

20:30.400 --> 20:35.440
then the map is extended within lane one. But when you turn from lane one to lane two,

20:35.440 --> 20:39.520
you actually remap to a new map. And when you turn from lane two to lane three,

20:39.520 --> 20:43.360
you end up remapping to an existing map, which is the same as lane one.

20:44.560 --> 20:50.240
And similarly, in the two room experiment, we saw that when you go from room one to the corridor,

20:50.240 --> 20:54.880
you end up mapping to a new map. And when you go from corridor to room two, you actually end up

20:54.880 --> 20:59.680
remapping to an existing map. So, next, I'm going to talk about how we decide whether we are going

20:59.680 --> 21:05.840
to extend a map or whether we should be remapping. So, in our model, remapping is based on the

21:05.840 --> 21:10.800
notion of contiguous regions. And a contiguous region is a region such that when I stay within

21:10.800 --> 21:14.880
that region, my visual observations change very little. And these contiguous regions are connected

21:14.880 --> 21:19.440
by these bottleneck states. And this is aligned with the experimental data, which we have seen,

21:19.440 --> 21:25.280
which suggests special rule of doorways and corridors. So, now we formalize the concept

21:25.280 --> 21:30.240
of contiguous regions by defining a measure of similarity. So, we define similarity as the ability

21:30.240 --> 21:35.200
to predict observations at one pose from the observations made at another pose. And so,

21:35.200 --> 21:39.920
the overlap between the observations made at two poses actually is a notion of similarity.

21:39.920 --> 21:44.640
And this formalizes the concept of contiguous regions as a region where any two points are

21:44.640 --> 21:49.520
similar. And here, I'm showing that similarity actually decreases when you transition between

21:49.520 --> 21:53.920
contiguous regions. So, if you look at points which are within this contiguous region,

21:53.920 --> 21:59.120
their similarity is high with respect to this point. But for points which are in other regions,

22:00.080 --> 22:02.800
the similarity is pretty low as compared to this point.

22:04.800 --> 22:09.440
So, then we can use this notion of similarity to define density in order to do density-based

22:09.440 --> 22:14.800
clustering. And here, we define density as a similarity between any pose X and its

22:14.800 --> 22:22.000
mth nearest neighbor. And this notion can be used with any greedy algorithm like optics to

22:22.000 --> 22:26.080
generate fragmentations of the environment. And here, I'm showing one example of fragmentations

22:26.080 --> 22:30.240
of the environment where it gives four different clusters corresponding to these four different

22:30.240 --> 22:38.800
colors shown here. So, given that contiguity is a local property, we can also try to compute

22:38.800 --> 22:44.000
segmentations online by predicting current observations from the past. And in this case,

22:44.000 --> 22:48.800
observations can be represented by boundary vector cells. And we can implement a short-term memory

22:48.800 --> 22:52.800
which stores exponential moving average of boundary vector cell activations

22:52.800 --> 22:57.600
to approximate the similarity. So, for instance, our short-term memory at a previous time step

22:57.600 --> 23:02.320
can be used to predict observations at a current time step to compute the similarity between two

23:02.320 --> 23:06.880
poses. And another component which we need to add to our model is the long-term memory component,

23:06.880 --> 23:10.720
which helps us decide whether we should be remapping to an existing map or we should be

23:10.720 --> 23:18.720
remapping to a new map. So, for all of these environments, our model makes the correct

23:18.720 --> 23:24.480
predictions which are in line with the experimental data observed. And these experiments have been

23:24.480 --> 23:29.920
done and we have neural data for them. This is a new prediction that our model makes for amorphous

23:29.920 --> 23:34.640
naturalistic environments. We predict that even in these environments, the map will be segmented

23:34.640 --> 23:38.800
and grid fields will realign when going from one contiguous region to the other.

23:38.800 --> 23:42.320
And we do not predict any map fragmentations in these spiral mesas.

23:42.480 --> 23:51.520
So, given that we built or proposed an algorithmic model for map fragmentation, the next question is,

23:51.520 --> 23:56.880
how can map fragmentation be implemented on a neural level? So, we want to provide a framework

23:56.880 --> 24:01.360
for building a neural circuit model of map fragmentation. And this work is in collaboration

24:01.360 --> 24:08.560
with Sarthak and Murko, who are both postdocs in FEDLA. So, going back to our theoretical

24:08.560 --> 24:14.880
framework, we had suggested that place cells might encode topological relationships between

24:14.880 --> 24:20.080
metric maps that might be represented by the grid space. And now I'm going to talk about

24:20.080 --> 24:25.440
how we can implement that at a neural level. So, at the neural level, we start with factorized

24:25.440 --> 24:29.600
representations in which different aspects of knowledge are represented separately and can

24:29.600 --> 24:34.880
then be flexibly recombined. So, for instance, in this case, location information from grid cells

24:34.880 --> 24:39.760
and contextual information from sensory cells form this conjunctive representation in place cells.

24:40.400 --> 24:44.800
Here grid cells can enable path integration and can be thought of as implementing an affine vector

24:44.800 --> 24:50.080
space or an impedance space. The recurrent wiring between these place cell population encodes

24:50.080 --> 24:55.280
neighborhood relationships or topology. And here, large changes in contextual input cause

24:55.280 --> 25:01.040
remapping in place cells, which in turn cause remapping in grid cells through these back projections.

25:01.040 --> 25:04.400
And remapping here corresponds to transitioning from one local map to another.

25:05.280 --> 25:11.120
So, most of the previous work on interplay of grid and place circuits focuses on maintaining

25:11.120 --> 25:16.160
firing properties of one population based on the inputs from another. So, for instance,

25:17.280 --> 25:21.120
successor representation suggests that grid cells are a low-dimensional representation

25:21.120 --> 25:27.520
of place cells that stabilize place cell activity. Similarly, here's a model which

25:27.520 --> 25:32.400
implements non-negative PCA of place cells. So, place cells are at the input. The weights are

25:32.400 --> 25:37.840
learned through heavy learning and a non-negativity constraint. And this network does PCU on the

25:37.840 --> 25:44.000
inputs, and the outputs end up converging to grid-like fields, again, suggested that grid

25:44.000 --> 25:46.720
cells might be a low-dimensional representation of place cells.

25:51.280 --> 25:56.160
Another set of work suggests that inputs from border cells to grid cells could be used for

25:56.160 --> 26:02.160
error-correcting grid cells. So, here I'm showing a one-day schematic just to make my point. So,

26:02.160 --> 26:08.560
this is a rodent at a specific location in space, and this is the grid activity profile

26:09.280 --> 26:13.440
that represents that location. And when the rodent explores the environment and comes back to this

26:13.440 --> 26:17.920
location, the representation of this location has drifted with respect to the original,

26:17.920 --> 26:23.120
and there's some error in the representation. And if the border cell activations are provided

26:23.120 --> 26:28.560
as input to grid cells, then they activate the current subset of neurons doing error correction

26:28.560 --> 26:33.680
and pulling back the representation to the original representation. And this is what this

26:33.680 --> 26:38.320
looks like in 2D. So, in 2D, if you do not have any border cell inputs, then your grid cell

26:38.320 --> 26:42.400
representations are not very stable, but with border cell inputs, your grid cell representations

26:42.400 --> 26:50.720
are fairly stable. So, I also want to point out the fact that place cells are thought to store

26:50.720 --> 26:54.320
neighborhood relationships in their reference synapses, and therefore they could implement

26:54.320 --> 26:58.720
a topological navigation strategy. And many models of place cell-based navigation have

26:58.720 --> 27:03.760
actually emphasized this view. So, they've suggested that recurrence synapses encode either

27:03.760 --> 27:08.720
spatial or temporal connectivity, as suggested by Blum and Abbott, or they encode transition

27:08.720 --> 27:14.640
probability, as suggested by the successor representation work. So, given all these insights,

27:14.640 --> 27:19.440
our goal is to build a comprehensive neural circuit model of premapping. And we start with these

27:19.440 --> 27:24.000
two questions. Does high-capacity grid code, when projected to place cells, also lead to high

27:24.000 --> 27:29.440
capacity? And given these conjunctive representations between the location input and the sensory input,

27:29.440 --> 27:35.280
can we learn neighborhood relationships between place codes? And before I go into the details

27:35.280 --> 27:39.760
of capacity, I just want to point out that traditionally, Hopfield networks have been

27:39.760 --> 27:45.040
used for storing memories and patterns. And it has been observed that the maximum patterns

27:45.040 --> 27:49.360
that these networks can store is n, where n is the total number of neurons in the network.

27:50.000 --> 27:54.640
And modern Hopfield networks, also known as dense associative memories, have an exponential

27:54.640 --> 28:00.400
capacity, but they use many body interaction terms, which are not biologically plausible.

28:00.400 --> 28:04.400
And in our model, we stick to using two interaction terms in the weight computations,

28:04.400 --> 28:14.480
and we still get exponential capacities. So, this is the architecture of our model.

28:14.480 --> 28:19.120
The model has different grid modules, which have different scales or periods,

28:19.120 --> 28:25.440
and the binary grid code is projected to place code randomly. And the back projections from

28:25.440 --> 28:30.160
place cells to grid cells are learned through associative Hebbian learning. And we observe

28:30.160 --> 28:35.440
that when we perturb these place cells with a noisy version of place code representations,

28:35.440 --> 28:40.320
then the network is able to successfully reconstruct all the patterns it's trained on.

28:40.320 --> 28:45.760
So, the network is fairly robust to noise. Furthermore, this network has exponential

28:45.760 --> 28:50.400
capacity that grows much faster than a non-modular network where the grid cells are non-modular.

28:53.760 --> 28:57.600
Also, the network generalizes stored inputs to create stable attractor

28:57.600 --> 29:02.240
states around every pattern in the grid coding space, despite training only over a vanishing

29:02.240 --> 29:07.600
fraction of contiguous grid coding space. So, for instance, if my grid coding space has around

29:07.600 --> 29:13.200
10,000 patterns, I can train the network on only around 200 patterns, first 200 patterns,

29:13.200 --> 29:17.440
and the network is still able to robustly reconstruct all the 10,000 patterns in the grid

29:17.440 --> 29:24.800
coding space, which is pretty striking. Furthermore, next we add these heterosciitiative

29:24.800 --> 29:28.720
learning on the recurrent connections on place cells to see if they can encode neighborhood

29:28.720 --> 29:35.760
relationships or 1D sequences. And what we find is that the product of these weights converges to

29:35.760 --> 29:40.480
this transition matrix, which is actually the analytical matrix, an analytical transition

29:40.480 --> 29:45.920
matrix that relates contiguous grid codes in the grid coding space. Furthermore,

29:45.920 --> 29:49.920
this network actually has perfect sequence recall given enough number of place cells to

29:49.920 --> 29:55.520
approximate this transition matrix. And again, training on only a subset of the sequence is

29:55.520 --> 29:59.840
enough to recall the entire sequence. So, for instance, if I train, if I have a sequence of

29:59.920 --> 30:06.000
length 500, and I train the network on only first 150 patterns in the sequence, the network

30:06.000 --> 30:11.120
is robustly able to reconstruct all 500 patterns in the sequence without having seen all of them

30:11.120 --> 30:18.240
before. So, the next step in this network is to introduce sensory input. And the sensory input

30:18.240 --> 30:22.240
would project randomly to place cells and back projections from place cells to sensory input

30:22.240 --> 30:27.440
would be learned through associative hybrid learning. And here grid cells would form a basis,

30:27.440 --> 30:31.040
and hippocampal places would link that basis with arbitrary sensory input.

30:31.680 --> 30:36.080
And this combination of structured inputs and unstructured inputs could potentially enable

30:36.080 --> 30:40.240
the storage and robust recollection of a large number of arbitrary sensory patterns from this

30:40.240 --> 30:47.840
partial use. So, how does this connect to map fragmentation? So, in part two, we talked about

30:47.840 --> 30:54.240
map fragmentation based on the notion of contiguous regions. And here I'm positing that

30:54.240 --> 30:59.520
when you transition between different contiguous regions that actually corresponds to a large

30:59.520 --> 31:05.600
contextual change, which when provided as input to this network would trigger remapping in place

31:05.600 --> 31:10.880
cells, which would in turn cause remapping in grid cells, thus leading to the formation of local

31:10.880 --> 31:18.800
sub maps. And how does this connect to part one, where we saw that sub maps might enable quick

31:18.800 --> 31:24.000
learning and generalization in humans. So, this network actually enables us to anchor grid maps

31:24.000 --> 31:29.440
to external cues through these conjunctive representations in place cells. And this anchoring

31:29.440 --> 31:34.960
to external cues actually enables the alignment of grid maps, even when points of departure in an

31:34.960 --> 31:41.920
environment are different, leading to adaptable representations. Furthermore, if you are in an

31:41.920 --> 31:47.600
environment that is composed of previously seen spatial structures, then this anchoring still

31:47.600 --> 31:53.440
enables you to pull out the right map when you're navigating through that composed spatial structure.

31:54.480 --> 32:00.800
So, to summarize, our global hypothesis was that cognitive map is organized as a globally

32:00.800 --> 32:07.840
topological and locally metric or Euclidean map. So, this is one illustration of a topometric map.

32:07.840 --> 32:12.880
And we said that any sub part of this map can be termed as a sub map.

32:14.960 --> 32:19.680
In part one, we suggested that learning sub maps that are adaptable and compositional may drive

32:19.680 --> 32:23.360
fast learning in complex spaces. And we proposed to conduct human behavioral

32:23.360 --> 32:28.080
experiments to test this hypothesis. In second part, we proposed an algorithmic model of map

32:28.080 --> 32:32.720
fragmentation into sub maps based on the notion of contiguous regions. And in the third part,

32:32.720 --> 32:37.680
we proposed a framework for a neural circuit model of map fragmentation. And overall,

32:37.680 --> 32:42.240
we're suggesting that sub maps enable humans to build up a knowledge base of spatial structures

32:42.240 --> 32:47.200
that they can continuously enrich and refine throughout their life by combining their existing

32:47.280 --> 32:53.120
spatial knowledge with their new experiences. So, that's all for my talk. And before I end,

32:53.120 --> 32:58.800
I want to acknowledge my collaborators again, Marta, Kevin, Merko and Sata. And I also want to

32:58.800 --> 33:04.080
thank my supervisors, Ila and Josh for their continued feedback and support and discussions

33:04.080 --> 33:09.840
on these projects. I also want to thank Matt Wilson for his feedback and valuable suggestions

33:09.840 --> 33:14.960
during my committee meetings and the members of FeedLab and TenBomb in general for their support.

33:15.520 --> 33:22.080
And before I end, I also want to thank the VCS department and McGowan Institute for their

33:22.080 --> 33:27.280
continued support and for providing an environment that's conducive to research,

33:27.280 --> 33:31.840
even in the face of this pandemic. Thank you. And I can take any questions now.

33:34.560 --> 33:40.000
Thanks, Sue, for the great talk. We already have a question from Marta Griffin.

33:40.800 --> 33:44.000
Great talk. I have a question about partitioning a space to sub maps.

33:44.640 --> 33:49.120
What do you think will happen if you ask humans to intuitively partition an environment to regions?

33:49.120 --> 33:52.960
How would there be segmentation compared to the maps given by your similarity measure?

33:55.280 --> 34:03.040
So, you mean the complex? Anyways, so, okay, so the question is that if humans intuitively

34:03.040 --> 34:07.440
try to segment a map, how would that compare to the segmentations which we have proposed

34:07.520 --> 34:13.760
in part two of my talk where we have given an algorithmic model for map segmentation.

34:15.920 --> 34:21.200
So, basically, the way I view it is that in the algorithmic model of map segmentation,

34:21.200 --> 34:28.080
I basically took one metric map and one small portion of the map. And we said that that can be

34:28.080 --> 34:33.200
decomposed into various fragments of sub maps. But humans are actually able to reason in much

34:33.200 --> 34:39.680
richer environments than the ones which we saw in this algorithm. And so, there we can

34:39.680 --> 34:46.000
view it as something like this where you might have even small spaces being segmented into

34:46.000 --> 34:52.480
multiple maps. So, let me just see if I can, yeah, so even if you have something like this,

34:53.040 --> 34:56.960
so even within this, so I was calling this a sub map, but even within this sub map,

34:56.960 --> 35:00.880
we might have multiple maps. So, based on the notion of contiguous regions, you might have

35:00.880 --> 35:05.200
a local map here, a local map here, and all these maps might be connected.

35:05.200 --> 35:11.520
And so, the algorithmic model would predict those kinds of map segmentations, but then even

35:11.520 --> 35:16.640
a combination of those map segmentations can be termed as a sub map. And then that is what I

35:16.640 --> 35:23.520
was talking about in part one where I'm talking about composing the sub map which is even itself

35:23.520 --> 35:30.000
composed of smaller maps. And we can take this representation of this map and then compose

35:30.000 --> 35:38.960
them in various ways to build richer environments.

35:50.240 --> 35:54.560
I'll follow up from Marta. I'm curious if the algorithm can predict how humans would interpret

35:54.560 --> 36:00.880
sub maps. How humans would interpret?

36:06.640 --> 36:10.720
Well, it's a little bit unclear to me what you mean by interpret

36:11.680 --> 36:20.320
sub maps, but I mean, I'm assuming that you're suggesting, you know, how humans would interpret

36:21.200 --> 36:26.080
segmenting this environment versus maybe a more complex environment. And I would say that

36:26.080 --> 36:31.440
currently, this algorithm doesn't predict anything about how humans might interpret

36:32.240 --> 36:38.000
grid maps. But that's, I mean, we could look at it. That's an interesting direction and we could

36:38.000 --> 36:44.480
look at it in the future. And I think some of my work in part one would potentially address that

36:44.480 --> 36:52.960
going forward. All right. Next question from Eli Pollock. You can unmute yourself, Eli.

36:56.560 --> 36:58.480
Yeah. Hi. Can you hear me? Yes.

37:02.000 --> 37:09.280
Hello. Yes, I can hear you. Sorry. Okay. Okay. Cool. Yes. Sorry. My internet's a little weird.

37:10.160 --> 37:15.440
Great talk. Can you talk a little bit more about how your model handles time?

37:16.080 --> 37:23.120
Or I think you mentioned that it was able to handle like replay of different sequences of

37:23.120 --> 37:32.960
states through some map. How would it be able to handle different trajectories through the same

37:33.040 --> 37:41.120
space that might activate play cells in different sequences? So the version of the model that I

37:41.120 --> 37:48.320
presented, that is trained on discrete patterns, right? So the sequences here, the sequences which

37:48.320 --> 37:53.440
are trained on here through heterospecific learning are composed of these discrete patterns. So if I

37:53.440 --> 38:00.160
say the sequences of length 500, there are 500 discrete patterns in that sequence. And when you

38:00.240 --> 38:06.640
say time, time is something continuous. And so we have worked on extrapolating this model to

38:06.640 --> 38:10.640
more continuous domains. And in a continuous domain, what would happen is that your sequence,

38:10.640 --> 38:15.920
instead of being discrete patterns, would be composed of these continuous stream. And in that

38:15.920 --> 38:20.640
case, we haven't explored what the network performance would be, but that's something

38:20.640 --> 38:27.680
ongoing. And definitely in 2D spaces, we would like to train this model on 2D sequences and then

38:27.680 --> 38:33.120
see, so right now, these results are pertaining to 1D sequences. But we do want to extrapolate

38:33.680 --> 38:39.600
the results and train this model on 2D sequences to see how it performs in 2D. And I think that would

38:40.400 --> 38:45.440
potentially address then your questions about time, because that pertains to continuous domains.

38:46.160 --> 38:47.120
Okay, yeah, thank you.

38:51.120 --> 38:55.200
Okay, we've got a big stream of questions coming in. The first is from Adam Eisen.

38:55.840 --> 38:59.280
Thanks for a fascinating talk. Have you thought at all about how this framework for sub-map

38:59.280 --> 39:04.000
segmentation and topological association could be extended to non-spatial domains?

39:05.440 --> 39:12.880
That's a very good question. So in FeedLab, a small group of us have been thinking about how

39:12.880 --> 39:19.360
this could be extended. And so the idea is, I'm just going to go back to, let's see if I can just

39:19.440 --> 39:25.120
quickly hop back to my theoretical framework slide. So really, we're building up on this

39:25.120 --> 39:29.200
theoretical framework. And when we're thinking about non-spatial domains, we go back to this

39:30.000 --> 39:35.600
schematic picture. And here, basically, what we're saying is, within the spatial domain, I said that

39:35.600 --> 39:39.920
large changes in contextual input can drive remapping in place cells, which would drive

39:40.480 --> 39:48.560
remapping in the grid coding space. So similarly, in relational domains or in discrete domains,

39:49.840 --> 39:54.560
as we're thinking about it, we are referring back to this schematic picture. And we think that

39:55.600 --> 40:01.440
the phenomenon of remapping actually would enable us to encode these non-eclidean relationships.

40:01.440 --> 40:06.320
So first thing is that here, we're suggesting topological relationships. So that already

40:06.320 --> 40:11.280
enables us to encode non-eclidean relationships. But this phenomenon of remapping also allows

40:11.280 --> 40:16.880
us to make jumps. So if you think about a family tree, if you might try to encode it in an

40:16.960 --> 40:22.160
eclidean space, then you'll have conflicts. And it's very difficult to encode it. In fact,

40:22.160 --> 40:28.480
almost impossible to encode it in an eclidean space. But then if we provide a framework where

40:28.480 --> 40:33.200
we allow topological representations and we allow jumps in this eclidean space through this phenomenon

40:33.200 --> 40:37.920
of remapping through place cells, then that can allow us to potentially encode non-eclidean

40:37.920 --> 40:42.320
relationships. And that's the way we are thinking. And this is still work in progress. And we

40:42.320 --> 40:53.120
actively think about it. Next question from Nancy Camusher. How does your system decide when and

40:53.120 --> 40:57.360
where to carve the world in the sub-maps, especially in non-built environments where the

40:57.360 --> 41:08.080
divisions may be less obvious? So at least in part two, where I talk about fragmentation of

41:08.080 --> 41:17.120
maps into sub-maps. Let me just go back. So in these kinds of environments, we basically describe

41:17.120 --> 41:22.160
the principle of contiguous regions, where we have suggested that when you are navigating through

41:22.160 --> 41:27.920
this environment, if you are in an environment where your visual observations stay more or less

41:27.920 --> 41:34.000
consistent, then you will keep extending a map. But when you go from this region to another region,

41:34.000 --> 41:39.040
let's say you navigate from here to here, where your visual information here is completely distinct

41:39.040 --> 41:43.600
from your visual information here, then in that case, you will decide to segment the space. And

41:44.160 --> 41:49.040
that's what we are predicting. We're predicting that in this case, when you travel from one

41:49.040 --> 41:54.480
contiguous region to another, you will segment the space. And that's how you divide the space.

41:54.480 --> 41:59.920
So that's one principle, which we are describing for map segmentation. And that might not be the

41:59.920 --> 42:05.840
only principle, but that principle explains some of the experimental results that have been

42:05.840 --> 42:10.640
observed newly. And there might be another principle, for instance, path integration error,

42:10.640 --> 42:16.480
where if your path integration builds up and it reaches a certain threshold amount,

42:16.480 --> 42:22.480
then you automatically might start a new map. But I haven't illustrated that here, but that's

42:22.480 --> 42:27.120
also one of the other driving forces for us to actually split a space into multiple sub-maps

42:27.120 --> 42:38.800
so that we can have more efficient representations. Okay, next question from Chen.

42:39.920 --> 42:43.440
I was wondering if you can give some intuition about the mechanism for composition of

42:43.440 --> 42:48.480
sub-maps. So really, this is from the happy and learning mechanism. And secondly,

42:48.480 --> 42:51.600
can you comment on the relationship between this and the Hopfield mechanism?

42:51.600 --> 43:07.600
So since we're talking about composition of sub-maps here, in this case, in this model,

43:07.600 --> 43:13.200
what I'm suggesting is that we might end up forming local sub-maps by using the

43:13.200 --> 43:18.720
phenomenon of premapping. So here I'm suggesting, again, if you have large changes in contextual

43:18.720 --> 43:26.080
input, so for instance, let me just go back to the slide, which kind of connects this.

43:27.520 --> 43:35.040
So here we basically suggested how this environment can be segmented into different

43:35.040 --> 43:41.360
sub-maps. And on the mechanistic level, I'm trying to suggest that any large contextual input

43:41.360 --> 43:46.800
is going to cause remapping in place cells, which means the cells which are firing would be

43:48.960 --> 43:55.360
changed and they would represent a new map. And this remapping would actually enable also

43:55.360 --> 44:00.800
remapping in grid cells through associative learning because each place cell representation

44:00.800 --> 44:07.200
is associated with a certain grid cell representation. So when you have changes in

44:07.200 --> 44:11.600
firing fields of place cells, that also triggers certain corresponding changes in the grid coding

44:11.600 --> 44:19.440
phase, which is basically called remapping in grid phase. And so here I'm interpreting,

44:19.440 --> 44:24.400
when I look at my algorithmic model and I look at my mechanistic model, I'm saying that when you

44:24.400 --> 44:29.920
go from one contiguous region to another, that actually corresponds to a large contextual change

44:29.920 --> 44:36.800
and that contextual change triggers remapping in this model and this remapping in place cells

44:36.800 --> 44:41.840
then triggers remapping in grid cells phase. And that corresponds to the formation of local

44:41.840 --> 44:47.120
sub-maps. And these topological connections from place cells to themselves might actually

44:47.760 --> 44:52.800
represent how these local sub-maps are connected to each other. And there's also,

44:53.440 --> 44:56.800
going back to the anatomy, there's also a possibility of splitting this population

44:56.800 --> 45:01.600
actually into different populations. One that might just encode conjunctive representations and

45:01.600 --> 45:08.800
another one that might have these recurrent topological connections similar to CA1 and

45:08.800 --> 45:13.360
CA3 distinction in anatomy. But that's how I'm thinking about it at the moment.

45:23.280 --> 45:29.760
I want to point out a quick addendum from Ila who said to Nancy's question, we consider online

45:29.760 --> 45:35.040
segmentation decisions driven by regions or points of high surprise affordance changes and PIR.

45:41.200 --> 45:46.640
Okay, another question from Anya, even over. Do you think the way humans form space maps depends

45:46.640 --> 45:51.520
on whether their language uses directions that are egocentric left and right or allocentric

45:51.520 --> 45:59.520
north and south? That's a great question. So there were experiments in both animals as well

45:59.520 --> 46:04.080
as humans which have shown that we actually have both kinds of representations. We have

46:04.080 --> 46:10.560
egocentric representations and we also have allocentric representations. And the representations

46:10.560 --> 46:19.360
in the hippocampal inter-animal system are usually allocentric, but the thalamus is the part of the

46:19.360 --> 46:25.040
brain which is responsible for egocentric representations. So really, when we're navigating

46:25.040 --> 46:30.400
spaces, we are probably using mixed strategies. We do use our allocentric representations,

46:30.400 --> 46:35.920
but in some cases we might be using egocentric representations. And that's mostly also true

46:35.920 --> 46:41.040
for routes which we are traversing very frequently. So if there's a route which I take every day,

46:41.040 --> 46:47.760
let's say going from my home to BCS, then that converges to root learning. But if I've had very

46:47.760 --> 46:53.200
less experience in any environment, then I'm mostly using allocentric representations to

46:53.200 --> 46:57.600
actually make my way through that environment. And hence, allocentric representations are

46:57.600 --> 47:05.120
actually attributed to being able to make novel inferences. And when I'm building circuits here

47:05.120 --> 47:09.440
using grid cells and place cells, I'm mostly talking about allocentric representations.

47:09.440 --> 47:15.760
But then when I was talking about submaps in human experiments, I'm kind of

47:15.760 --> 47:20.400
agnostic to the fact that whether those representations are egocentric or allocentric

47:20.400 --> 47:27.360
because even if you learn an egocentric strategy, even in that case, if you determine that there's

47:27.360 --> 47:32.640
a repeating structure to the environment and you recall that this is the same environment that I've

47:32.640 --> 47:38.000
seen before, then you can still apply the same egocentric strategy or an allocentric strategy

47:38.000 --> 47:44.320
depending on which one you decide to use at that point. But going back to the main question,

47:45.200 --> 47:51.680
the experimental data shows that we're actually basically learning both kinds of strategies.

47:57.920 --> 48:03.840
Okay, Senke's Pellevan says, great talk. What are the large scale, sorry, where are the large

48:03.840 --> 48:13.920
scale topological relations coded in the network? So in the network model, our focus, so in this

48:13.920 --> 48:18.480
case, we are basically encoding topological relationships using the recurrent connections

48:18.480 --> 48:25.360
on the place cells. But for large scale topological relationships, what we are moving towards is

48:25.360 --> 48:30.160
splitting this population into two distinct populations. So one population that will only

48:30.160 --> 48:35.520
have conjunctive representations, and perhaps another population which will have the recurrent

48:35.520 --> 48:41.600
connections similar to the distinction between CA1 and CA3 in the brain. And it's true that in this

48:41.600 --> 48:46.480
network model, we don't really distinguish between small scale and large scale topological

48:46.480 --> 48:50.320
relationships. But by introducing this additional population, we hope to abstract away the large

48:50.320 --> 48:58.240
scale relationships. Also, even in this case, if we have minute relationships between spaces,

48:58.240 --> 49:03.440
then we can also extract away the large scale relationships. But again, adding another population

49:04.320 --> 49:07.440
might make that easier to make that abstraction.

49:12.560 --> 49:18.560
Okay. Nancy has another comment. There must be some way to represent globally metric information.

49:19.120 --> 49:22.720
For example, I know the approximate distance and angle from my current position to far away

49:22.720 --> 49:26.480
locations in my world. Do I understand right that you would say this information has to be

49:26.480 --> 49:30.080
pieced together from just the topological relationship between the sub maps that connect

49:30.080 --> 49:37.280
those locations? So that's a great question. I also sometimes wonder because like when I'm here,

49:38.160 --> 49:43.520
I can kind of look very far in space and be able to tell that, okay, I need to go in this direction.

49:44.480 --> 49:51.760
And that's definitely metric information. And so going back to the labeled graph hypothesis,

49:52.720 --> 50:02.720
which was suggested by Bill Warren. So even in this hypothesis, I'm just saying that this is

50:02.800 --> 50:08.320
we are learning metric representations here, which are consistent Euclidean representations,

50:08.320 --> 50:12.960
which means that they actually obey all the postulates of Euclidean geometry.

50:13.920 --> 50:19.600
And the connections between them still have metric information. There's still information

50:19.600 --> 50:27.360
about angles and directions, but they might not obey all postulates of Euclidean geometry. So for

50:27.360 --> 50:31.680
instance, you might have some inconsistent representations. You might not know exactly

50:31.680 --> 50:36.400
what distances and displacements you have to go in order to reach a goal, but you know approximately

50:36.400 --> 50:41.760
which distance and which angle. So even the topometric representation is not contradicting

50:41.760 --> 50:46.640
the fact that you might have approximate distances and angles. But what it's saying is that you have

50:46.640 --> 50:53.200
very accurate metric information about small pieces of space, but then for faraway pieces of

50:53.200 --> 50:56.880
space, you might still have approximate distances, angles, which help you navigate.

51:02.640 --> 51:09.040
Okay, another question from Sean Chen. Sorry for my pronunciations. Great talk.

51:09.040 --> 51:12.640
Could you elaborate the mechanism of exponential number of memory capacity in your model?

51:20.720 --> 51:27.440
So here's the, here's the network, right, where I'm showing that the network has exponential

51:27.440 --> 51:34.240
capacity. So basically in this network, we have different grid modules which have different periods

51:34.240 --> 51:39.680
and this is the grid code is actually binary. And we project this grid code randomly using

51:39.680 --> 51:44.880
random weight matrix to place cells. And the number of place cells in this case is much larger than

51:44.880 --> 51:51.360
the number of grid cells. And now we learn these back projections from places to grid cells using

51:51.360 --> 51:56.160
Hebbian learning. So it's just simple Hebbian learning. I don't have the equation. Basically,

51:56.160 --> 52:01.200
this is the equation, right? You can consider these as place cell patterns. And this is how we

52:01.200 --> 52:07.760
compute the weight matrix for the weights going back from place cells to grid cells. And once we've

52:07.760 --> 52:12.880
done that, then the way we test for memory is basically by perturbing the place code patterns.

52:12.880 --> 52:18.560
So we put up the place cells by a noisy version of the place code pattern, right? So in this graph,

52:18.560 --> 52:26.080
I'm showing that if you perturb them with 20% noise, then with 300 place cells, you get an output

52:26.080 --> 52:30.000
noise of zero, which means you get perfect reconstruction of the patterns that you're

52:30.000 --> 52:35.040
perturbing the network with. And that's how I'm defining exponential memory, right? And

52:35.040 --> 52:40.800
when I say exponential memory, what I'm suggesting is that you can, as you increase the number of

52:40.800 --> 52:46.000
cells in the network, the number of patterns that you can reconstruct from the noisy versions

52:46.000 --> 52:47.440
actually grows exponentially.

52:59.440 --> 53:05.600
Okay, I'd like to ask a question as well. I'm curious to hear your thoughts on sort of

53:05.600 --> 53:12.640
computational level descriptions here. So it seems like your model is largely

53:12.640 --> 53:17.920
tuned towards sort of prediction, accurate prediction of your local spatial environment

53:20.640 --> 53:26.800
and motive mechanisms for doing this well. And I wonder what you think about computational level

53:27.760 --> 53:32.960
accounts of this to be more, to ask a more concrete question. Do you think there's a role

53:32.960 --> 53:38.560
of reward or something other than accurate, just accurate prediction in the shaping of

53:38.560 --> 53:44.480
neural representations of space? Okay, so you're asking whether there is a role for reward

53:45.360 --> 53:49.760
in shaping the representations of space in the mechanistic model?

53:51.840 --> 53:58.000
I mean, more generally, what's the objective driving this algorithm? Is it about

53:58.000 --> 54:00.240
accurate prediction or is there something more than prediction?

54:01.200 --> 54:12.720
Okay, so you're asking what is kind of like the motivation for building the mechanistic model?

54:14.480 --> 54:17.120
Yeah, yeah, I mean, some of the graphs you're showing here about,

54:18.720 --> 54:23.840
some of the graphs you showed, for example, were about recall. And recall, accurate reconstruction

54:23.840 --> 54:29.760
of an environment might be one objective. But it seems like you could say that this is a

54:29.840 --> 54:34.080
mechanism evolved for some purpose, but it's just that or different than that.

54:34.880 --> 54:43.200
So, right, so these two questions, which I started with, which are related to capacity of the network,

54:44.160 --> 54:48.480
and whether we can do, whether we can learn sequences, these are basically questions which I

54:48.480 --> 54:53.200
started with, because I wanted to explore the theoretical properties of these circuits, right,

54:53.200 --> 54:57.680
given the coding properties that we know of grid cells and place cells and given

54:57.680 --> 55:03.920
biologically plausible learning tools through have been learning, what are the coding properties

55:03.920 --> 55:08.640
that these networks can exhibit, right, how much capacity they have, how much information can they

55:08.640 --> 55:14.800
store. And so, yes, even in these models, since we are talking about reconstruction,

55:15.680 --> 55:20.320
basically says that if you have some noise, if you have some noisy estimate of where you are in

55:20.320 --> 55:26.720
space, then this kind of a network can help you clean that estimate, right, and reach a cleaner

55:26.720 --> 55:33.120
version of where you might be in space and help you localize in space. And also, these temporal

55:33.120 --> 55:37.680
connectivity on the place cells kind of have a predictive component to them, right, because you

55:37.680 --> 55:41.440
can import sequences. So, when you are at a particular position, you might be able to predict

55:41.440 --> 55:48.560
what's coming next. And so, these are kind of small components, which I'm using to go towards

55:48.560 --> 55:53.840
building a model of remapping in space, right, because ultimately my goal is to be able to

55:53.840 --> 55:58.320
figure out how these neural circuits might lead to the formation of these sub-maps. And by knowing

55:58.320 --> 56:03.440
the properties of these circuits, then I'll be better able to construct and build those networks,

56:03.440 --> 56:07.360
which actually can build small local sub-maps of environments.

56:12.240 --> 56:17.680
I'm reading out a comment from Ila. To my question, you could view this as a structure

56:17.680 --> 56:21.680
learning even without reward. A reinforcement learner, including the brain, could use these

56:21.680 --> 56:30.880
learning structures. Cool. Well, I think we're actually over time now. That was a great talk,

56:30.880 --> 56:38.800
Sue. Thanks for sharing with us. Of course, thank you. So, we'll be back next week for another

56:38.800 --> 56:51.360
talk from Eli Pollock. Until then, have a good Thanksgiving, and I'll see you next week.

