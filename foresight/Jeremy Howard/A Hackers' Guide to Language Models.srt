1
00:00:00,000 --> 00:00:08,000
Hi, I am Jeremy Howard from fast.ai, and this is a Hackers Guide to Language Models.

2
00:00:08,000 --> 00:00:19,000
When I say a Hackers Guide, what we're going to be looking at is a code-first approach to understanding how to use language models in practice.

3
00:00:19,000 --> 00:00:24,000
So before we get started, we should probably talk about what is a language model.

4
00:00:25,000 --> 00:00:34,000
I would say that this is going to make more sense if you know the kind of basics of deep learning.

5
00:00:34,000 --> 00:00:40,000
If you don't, I think you'll still get plenty out of it, and there'll be plenty of things you can do.

6
00:00:40,000 --> 00:00:47,000
But if you do have a chance, I would recommend checking out course.fast.ai, which is a free course.

7
00:00:47,000 --> 00:00:57,000
And specifically, if you could at least kind of watch, if not work through the first five lessons,

8
00:00:57,000 --> 00:01:09,000
that would get you to a point where you understand all the basic fundamentals of deep learning that will make this lesson tutorial make even more sense.

9
00:01:09,000 --> 00:01:13,000
Maybe I shouldn't call this a tutorial, it's more of a quick run-through.

10
00:01:13,000 --> 00:01:22,000
So I'm going to try to run through all the basic ideas of language models, how to use them, both open source ones and open AI based ones.

11
00:01:22,000 --> 00:01:27,000
And it's all going to be based using code as much as possible.

12
00:01:27,000 --> 00:01:32,000
So let's start by talking about what a language model is.

13
00:01:32,000 --> 00:01:41,000
And so as you might have heard before, a language model is something that knows how to predict the next word of a sentence or knows how to fill in the missing words of a sentence.

14
00:01:41,000 --> 00:01:48,000
And we can look at an example of one. Open AI has a language model, text of enchi 003.

15
00:01:48,000 --> 00:01:56,000
And we can play with it by passing in some words and ask it to predict what the next words might be.

16
00:01:56,000 --> 00:02:05,000
So if we pass in, when I arrived back at the Panda breeding facility after the extraordinary reign of live frogs, I couldn't believe what I saw.

17
00:02:05,000 --> 00:02:09,000
Or I just came up with that yesterday and I thought what might happen next.

18
00:02:09,000 --> 00:02:12,000
So kind of fun for creative brainstorming.

19
00:02:12,000 --> 00:02:15,000
There's a nice site called nat.dev.

20
00:02:15,000 --> 00:02:19,000
Nat.dev lets us play with a variety of language models.

21
00:02:19,000 --> 00:02:24,000
And here I've selected text of enchi 003 and I'll hit submit.

22
00:02:24,000 --> 00:02:27,000
And it starts printing stuff out.

23
00:02:27,000 --> 00:02:31,000
The pandas were happily playing and eating the frogs that had fallen in the sky.

24
00:02:31,000 --> 00:02:36,000
There's an amazing site to see these animals taking advantage of such a unique opportunity.

25
00:02:36,000 --> 00:02:40,000
The staff took quick measures to ensure the safety of the pandas and the frogs.

26
00:02:40,000 --> 00:02:45,000
So there you go. That's what happened after the extraordinary reign of live frogs at the Panda breeding facility.

27
00:02:45,000 --> 00:02:52,000
You'll see here that I've enabled show probabilities, which is a thing in nat.dev where it shows.

28
00:02:52,000 --> 00:02:54,000
Well, let's take a look.

29
00:02:54,000 --> 00:02:57,000
It's pretty likely the next word here is going to be there.

30
00:02:57,000 --> 00:03:02,000
And after that, since we're talking about a panda breeding facility, it's going to be pandas were.

31
00:03:02,000 --> 00:03:03,000
And what were they doing?

32
00:03:03,000 --> 00:03:05,000
Well, they could have been doing a few things.

33
00:03:05,000 --> 00:03:10,000
They could have been doing something happily or the pandas were having the pandas were out.

34
00:03:10,000 --> 00:03:11,000
The pandas were playing.

35
00:03:11,000 --> 00:03:14,000
So it picked the most likely.

36
00:03:14,000 --> 00:03:17,000
It thought it was 20% likely it's going to be happily.

37
00:03:17,000 --> 00:03:19,000
And what were they happily doing?

38
00:03:19,000 --> 00:03:26,000
Could have been playing, hopping, eating and so forth.

39
00:03:26,000 --> 00:03:31,000
So they're eating the frogs that and then had almost certainly.

40
00:03:31,000 --> 00:03:37,000
So you can see what it's doing at each point is it's predicting the probability of a variety of possible next words.

41
00:03:37,000 --> 00:03:45,000
And depending on how you set it up, it will either pick the most likely one every time or you can change,

42
00:03:45,000 --> 00:03:53,000
muck around with things like p values and temperatures to change what comes up.

43
00:03:53,000 --> 00:03:59,000
So at each time, then it will give us a different result.

44
00:03:59,000 --> 00:04:03,000
And this is kind of fun.

45
00:04:03,000 --> 00:04:05,000
Frogs perched on the heads of some of the pandas.

46
00:04:05,000 --> 00:04:09,000
It was an amazing sight, et cetera, et cetera.

47
00:04:09,000 --> 00:04:10,000
Okay.

48
00:04:10,000 --> 00:04:18,000
So that's what a language model does.

49
00:04:18,000 --> 00:04:23,000
Now you might notice here it hasn't predicted pandas.

50
00:04:23,000 --> 00:04:30,000
It's predicted panned and then separately us.

51
00:04:30,000 --> 00:04:31,000
Okay.

52
00:04:31,000 --> 00:04:32,000
After panned, it's going to be us.

53
00:04:32,000 --> 00:04:34,000
So it's not always a whole word.

54
00:04:34,000 --> 00:04:38,000
Here it's un and then harmed.

55
00:04:38,000 --> 00:04:41,000
Oh, actually it's un ha mood.

56
00:04:41,000 --> 00:04:44,000
So you can see that it's not always predicting words,

57
00:04:44,000 --> 00:04:47,000
specifically what it's doing is predicting tokens.

58
00:04:47,000 --> 00:04:54,000
Tokens are either whole words or sub word units, pieces of a word,

59
00:04:54,000 --> 00:05:00,000
or it could even be punctuation or numbers or so forth.

60
00:05:00,000 --> 00:05:02,000
So let's have a look at how that works.

61
00:05:02,000 --> 00:05:10,000
So for example, we can use the actual, it's called tokenization to create tokens from a string.

62
00:05:10,000 --> 00:05:15,000
We can use the same tokenizer that GPT users by using tick token.

63
00:05:15,000 --> 00:05:22,000
And we can specifically say we want to use the same tokenizer that that model text eventually 003 users.

64
00:05:22,000 --> 00:05:28,000
And so, for example, when I earlier tried this, it talked about the frog splashing.

65
00:05:28,000 --> 00:05:32,000
And so I thought, well, we'll encode they are splashing.

66
00:05:32,000 --> 00:05:35,000
And the result is a bunch of numbers.

67
00:05:35,000 --> 00:05:42,000
And what those numbers are, they basically just look ups into a vocabulary that open AI in this case created.

68
00:05:42,000 --> 00:05:46,000
And if you train your own models, you'll be automatically creating or your code will create.

69
00:05:46,000 --> 00:05:57,000
And if I then decode those, it says, oh, these numbers are they space are space spool ashing.

70
00:05:57,000 --> 00:05:59,000
And so put that all together.

71
00:05:59,000 --> 00:06:00,000
They are splashing.

72
00:06:00,000 --> 00:06:12,000
So you can see that the start of a word is the space before it is also being encoded here.

73
00:06:12,000 --> 00:06:20,000
So these language models are quite neat that they can work at all.

74
00:06:20,000 --> 00:06:28,000
But they're not of themselves really designed to do anything.

75
00:06:28,000 --> 00:06:30,000
Let me explain.

76
00:06:30,000 --> 00:06:47,000
The basic idea of what chat GPT, GPT4, etc. are doing comes from a paper which describes an algorithm that I created back in 2017 called ULM fit.

77
00:06:47,000 --> 00:06:56,000
And Sebastian Ruder and I wrote a paper up describing the ULM fit approach, which was the one that basically laid out what everybody's doing, how this system works.

78
00:06:56,000 --> 00:06:59,000
And the system has three steps.

79
00:06:59,000 --> 00:07:03,000
Step one is language model training.

80
00:07:03,000 --> 00:07:05,000
But you'll see this is actually from the paper.

81
00:07:05,000 --> 00:07:07,000
We actually described it as pre-training.

82
00:07:07,000 --> 00:07:14,000
Now what language model pre-training does is this is the thing which predicts the next word of a sentence.

83
00:07:14,000 --> 00:07:24,000
And so in the original ULM fit paper, so the algorithm I developed in 2017, then Sebastian Ruder and I wrote it up in 2018, early 2018.

84
00:07:24,000 --> 00:07:29,000
What I originally did was I trained this language model on Wikipedia.

85
00:07:29,000 --> 00:07:36,000
Now what that meant is I took a neural network and a neural network is just a function.

86
00:07:36,000 --> 00:07:41,000
If you don't know what it is, it's just a mathematical function that's extremely flexible and it's got lots and lots of parameters.

87
00:07:41,000 --> 00:07:50,000
And initially it can't do anything, but using stochastic gradient descent or SGD, you can teach it to do almost anything if you give it examples.

88
00:07:50,000 --> 00:07:57,000
And so I gave it lots of examples of sentences from Wikipedia, so for example from the Wikipedia article for the birds.

89
00:07:57,000 --> 00:08:06,000
The birds is a 1963 American natural horror thriller film produced and directed by Alfred, and then it would stop.

90
00:08:06,000 --> 00:08:10,000
And so then the model would have to guess what the next word is.

91
00:08:10,000 --> 00:08:14,000
And if it guessed Hitchcock, it would be rewarded.

92
00:08:14,000 --> 00:08:17,000
And if it guessed something else, it would be penalized.

93
00:08:17,000 --> 00:08:20,000
And effectively, basically it's trying to maximize those rewards.

94
00:08:20,000 --> 00:08:26,000
It's trying to find a set of weights for this function that makes it more likely that it would predict Hitchcock.

95
00:08:26,000 --> 00:08:38,000
And then later on in this article, it reads, from Wikipedia, any previously dated Mitch but ended it due to Mitch's cold, overbearing mother Lydia, who dislikes any woman in Mitch's.

96
00:08:39,000 --> 00:08:48,000
They can see that filling this in actually requires being pretty thoughtful because there's a bunch of things that kind of logically could go there.

97
00:08:48,000 --> 00:08:57,000
Like a woman could be in Mitch's closet, could be in Mitch's house.

98
00:08:57,000 --> 00:09:05,000
And so you could probably guess in the Wikipedia article describing the plot of the birds as actually any woman in Mitch's life.

99
00:09:05,000 --> 00:09:15,000
Now, to do a good job of solving this problem as well as possible of guessing the next word of sentences,

100
00:09:15,000 --> 00:09:23,000
the neural network is going to have to learn a lot of stuff about the world.

101
00:09:23,000 --> 00:09:33,000
It's going to learn that there are things called objects, that there's a thing called time, that objects react to each other over time,

102
00:09:33,000 --> 00:09:39,000
that there are things called movies, that movies have directors, that there are people, that people have names and so forth,

103
00:09:39,000 --> 00:09:47,000
and that a movie director is Alfred Hitchcock and he directed horror films and so on and so forth.

104
00:09:47,000 --> 00:09:54,000
It's going to have to learn an extraordinary amount if it's going to do a really good job of predicting the next word of sentences.

105
00:09:54,000 --> 00:09:59,000
Now, these neural networks specifically are deep neural networks.

106
00:09:59,000 --> 00:10:00,000
So this is deep learning.

107
00:10:00,000 --> 00:10:07,000
And in these deep neural networks, which have, when I created this, I think it had like 100 million parameters.

108
00:10:07,000 --> 00:10:13,000
Nowadays, they have billions of parameters.

109
00:10:13,000 --> 00:10:23,000
It's got the ability to create a rich hierarchy of abstractions and representations which it can build on.

110
00:10:23,000 --> 00:10:31,000
And so this is really the key idea behind neural networks and language models,

111
00:10:31,000 --> 00:10:38,000
is that if it's going to do a good job of being able to predict the next word of any sentence in any situation,

112
00:10:38,000 --> 00:10:40,000
it's going to have to know an awful lot about the world.

113
00:10:40,000 --> 00:10:52,000
It's going to have to know about how to solve math questions or figure out the next move in a chess game or recognize poetry and so on and so forth.

114
00:10:52,000 --> 00:10:56,000
Now, nobody says it's going to do a good job of that.

115
00:10:56,000 --> 00:11:02,000
So it's a lot of work to find to create and train a model that is good at that.

116
00:11:02,000 --> 00:11:12,000
But if you can create one that's good at that, it's going to have a lot of capabilities internally that it would have to be drawing on to be able to do this effectively.

117
00:11:12,000 --> 00:11:21,000
So the key idea here for me is that this is a form of compression and this idea of the relationship between compression

118
00:11:21,000 --> 00:11:25,000
and intelligence goes back many, many decades.

119
00:11:25,000 --> 00:11:33,000
And the basic idea is that, yeah, if you can guess what words are coming up next,

120
00:11:33,000 --> 00:11:39,000
then effectively you're compressing all that information down into a neural network.

121
00:11:39,000 --> 00:11:43,000
Now, I said this is not useful of itself.

122
00:11:43,000 --> 00:11:45,000
Well, why do we do it?

123
00:11:45,000 --> 00:11:49,000
Well, we do it because we want to pull out those capabilities.

124
00:11:49,000 --> 00:11:53,000
And the way we pull out those capabilities is we take two more steps.

125
00:11:53,000 --> 00:11:57,000
The second step is we do something called language model fine tuning.

126
00:11:57,000 --> 00:12:06,000
And in language model fine tuning, we are no longer just giving it all of Wikipedia or nowadays we don't just give it all of Wikipedia.

127
00:12:06,000 --> 00:12:12,000
But in fact, a large chunk of the internet is fed to pre-training these models.

128
00:12:12,000 --> 00:12:22,000
In the fine tuning stage, we feed it a set of documents a lot closer to the final task that we want the model to do.

129
00:12:22,000 --> 00:12:24,000
But it's still the same basic idea.

130
00:12:24,000 --> 00:12:29,000
It's still trying to predict the next word of a sentence.

131
00:12:29,000 --> 00:12:33,000
After that, we then do a final classifier fine tuning.

132
00:12:33,000 --> 00:12:39,000
And then the classifier fine tuning, this is the kind of end task we're trying to get it to do.

133
00:12:39,000 --> 00:12:45,000
Nowadays, these two steps are very specific approaches are taken.

134
00:12:45,000 --> 00:12:52,000
For the step two, the step B, the language model fine tuning, people nowadays do a particular kind called instruction tuning.

135
00:12:52,000 --> 00:13:00,000
The idea is that the task we want most of the time to achieve is solve problems, answer questions.

136
00:13:00,000 --> 00:13:06,000
And so in the instruction tuning phase, we use data sets like this one.

137
00:13:06,000 --> 00:13:12,000
This is a great data set called OpenOrca created by a fantastic open source group.

138
00:13:12,000 --> 00:13:18,000
And it's built on top of something called the Flan collection.

139
00:13:18,000 --> 00:13:24,000
And you can see that basically there's all kinds of different questions in here.

140
00:13:24,000 --> 00:13:31,000
So there's four gigabytes of questions and context and so forth.

141
00:13:31,000 --> 00:13:40,000
And each one generally has a question or an instruction or a request and then a response.

142
00:13:40,000 --> 00:13:44,000
Here are some examples of instructions.

143
00:13:44,000 --> 00:13:47,000
I think this is from the Flan data set if I remember correctly.

144
00:13:47,000 --> 00:13:52,000
So for instance, it could be does the sentence in the iron age answer the question,

145
00:13:52,000 --> 00:13:59,000
the period of time from 1200 to 1000 BCE is known as what choice is one yes or no.

146
00:13:59,000 --> 00:14:07,000
And then the language model is meant to write one or two as appropriate for yes or no.

147
00:14:07,000 --> 00:14:10,000
Or it could be things about I think this is from a music video.

148
00:14:10,000 --> 00:14:17,000
Who is the girl in more than you know answer and then it would have to write the correct name of the

149
00:14:17,000 --> 00:14:23,000
remember model or dancer or whatever from from that music video and so forth.

150
00:14:23,000 --> 00:14:26,000
So it's still doing language modeling.

151
00:14:26,000 --> 00:14:29,000
So fine tuning and pre training are kind of the same thing.

152
00:14:29,000 --> 00:14:38,000
But this is more targeted now, not just to be able to fill in the missing parts of any document from the Internet.

153
00:14:38,000 --> 00:14:46,000
But to fill in the words necessary to answer questions to do useful things.

154
00:14:46,000 --> 00:14:49,000
Okay, so that's instruction tuning.

155
00:14:49,000 --> 00:14:53,000
And then step three, which is the classifier fine tuning.

156
00:14:53,000 --> 00:14:59,000
Nowadays, there's generally various approaches such as reinforcement learning from human feedback and others,

157
00:14:59,000 --> 00:15:09,000
which are basically giving humans or sometimes more advanced models,

158
00:15:09,000 --> 00:15:16,000
multiple answers to a question such as here are some from a reinforcement learning from human feedback paper.

159
00:15:16,000 --> 00:15:18,000
I can't remember which one I got it from.

160
00:15:18,000 --> 00:15:21,000
Five ideas for how to regain enthusiasm for my career.

161
00:15:21,000 --> 00:15:28,000
And so the model will spit out two possible answers or it will have a less good model and more good model.

162
00:15:28,000 --> 00:15:33,000
And then a human or a better model will pick, which is best.

163
00:15:33,000 --> 00:15:37,000
And so that's used for the the final fine tuning stage.

164
00:15:37,000 --> 00:15:47,000
So all of that is to say, although you can download pure language models from the Internet.

165
00:15:48,000 --> 00:15:54,000
They're not generally that useful of their on their own until you've fine tuned them.

166
00:15:54,000 --> 00:15:57,000
Now, you don't necessarily need step C nowadays.

167
00:15:57,000 --> 00:16:00,000
Actually, people are discovering that maybe just step B might be enough.

168
00:16:00,000 --> 00:16:02,000
It's still a bit controversial.

169
00:16:02,000 --> 00:16:11,000
Okay, so when we talk about a language model, where we could be talking about something that's just been pre-trained,

170
00:16:11,000 --> 00:16:15,000
something that's been fine tuned or something that's gone through something like RLHF.

171
00:16:15,000 --> 00:16:20,000
All of those things are generally described nowadays as language models.

172
00:16:23,000 --> 00:16:30,000
So my view is that if you are going to be good at language modeling in any way,

173
00:16:30,000 --> 00:16:35,000
then you need to start by being a really effective user of language models.

174
00:16:35,000 --> 00:16:39,000
And to be a really effective user of language models, you've got to use the best one that there is.

175
00:16:39,000 --> 00:16:44,000
And currently, so what are we up to September 2023?

176
00:16:44,000 --> 00:16:48,000
The best one is by far GPT-4.

177
00:16:48,000 --> 00:16:53,000
This might change sometime in the not too distant future, but this is right now.

178
00:16:53,000 --> 00:16:56,000
GPT-4 is the recommendation, strong, strong recommendation.

179
00:16:56,000 --> 00:17:05,000
Now, you can use GPT-4 by paying 20 bucks a month to open AI, and then you can use it a whole lot.

180
00:17:05,000 --> 00:17:10,000
It's very hard to run out of credits, I find.

181
00:17:10,000 --> 00:17:13,000
Now, what can GPT-2?

182
00:17:13,000 --> 00:17:21,000
It's interesting and instructive, in my opinion, to start with the very common views you see on the internet

183
00:17:21,000 --> 00:17:23,000
or even in academia about what it can't do.

184
00:17:23,000 --> 00:17:29,000
So, for example, there was this paper you might have seen, GPT-4 can't reason,

185
00:17:29,000 --> 00:17:37,000
which describes a number of empirical analysis done of 25 diverse reasoning problems

186
00:17:37,000 --> 00:17:44,000
and found that it was not able to solve them, it's utterly incapable of reasoning.

187
00:17:44,000 --> 00:17:50,000
So, I always find you've got to be a bit careful about reading stuff like this

188
00:17:50,000 --> 00:17:58,000
because I just took the first three that I came across in that paper and I gave them to GPT-4

189
00:17:59,000 --> 00:18:08,000
and, by the way, something very useful in GPT-4 is you can click on the share button

190
00:18:08,000 --> 00:18:12,000
and you'll get something that looks like this, and this is really handy.

191
00:18:12,000 --> 00:18:18,000
So, here's an example of something from the paper that said GPT-4 can't do this.

192
00:18:18,000 --> 00:18:22,000
Mabel's heart rate at 9 a.m. was 75 beats per minute.

193
00:18:22,000 --> 00:18:25,000
Her blood pressure at 7 p.m. was 120 over 80.

194
00:18:25,000 --> 00:18:28,000
She died at 11 p.m. while she alive at noon.

195
00:18:28,000 --> 00:18:32,000
So, of course, we're human, we know obviously she must be.

196
00:18:32,000 --> 00:18:39,000
And GPT-4 says, hmm, this appears to be a riddle, not a real inquiry into medical conditions.

197
00:18:39,000 --> 00:18:47,000
Here's a summary of the information and, yeah, it sounds like Mabel was alive at noon.

198
00:18:47,000 --> 00:18:48,000
So, that's correct.

199
00:18:48,000 --> 00:18:53,000
This was the second one I tried from the paper that says GPT-4 can't do this

200
00:18:53,000 --> 00:18:56,000
and I found actually GPT-4 can do this.

201
00:18:57,000 --> 00:19:02,000
And it said that GPT-4 can't do this and I found GPT-4 can do this.

202
00:19:02,000 --> 00:19:09,000
Now, I mentioned this to say GPT-4 is probably a lot better than you would expect

203
00:19:09,000 --> 00:19:15,000
if you've read all this stuff on the internet about all the dumb things that it does.

204
00:19:17,000 --> 00:19:22,000
Almost every time I see on the internet saying something that GPT-4 can't do,

205
00:19:22,000 --> 00:19:24,000
I check it and it turns out it does.

206
00:19:24,000 --> 00:19:26,000
This one was just last week.

207
00:19:26,000 --> 00:19:28,000
Sally, a girl, has three brothers.

208
00:19:28,000 --> 00:19:30,000
Each brother has two sisters.

209
00:19:30,000 --> 00:19:33,000
How many sisters does Sally have?

210
00:19:33,000 --> 00:19:35,000
So, I have to think about it.

211
00:19:37,000 --> 00:19:43,000
And so, GPT-4 says, OK, Sally's counted as one sister by each of her brothers.

212
00:19:43,000 --> 00:19:48,000
If each brother has two sisters, that means there's another sister in the picture apart from Sally.

213
00:19:48,000 --> 00:19:50,000
So, Sally has one sister.

214
00:19:50,000 --> 00:19:51,000
Correct.

215
00:19:57,000 --> 00:20:00,000
And then this one I got sort of like three or four days ago.

216
00:20:01,000 --> 00:20:07,000
This is a common view that language models can't track things like this.

217
00:20:07,000 --> 00:20:08,000
Here's the riddle.

218
00:20:08,000 --> 00:20:09,000
I'm in my house.

219
00:20:09,000 --> 00:20:11,000
On top of my chair in the living room is a coffee cup.

220
00:20:11,000 --> 00:20:13,000
Inside the coffee cup is a thimble.

221
00:20:13,000 --> 00:20:15,000
Inside the thimble is a diamond.

222
00:20:15,000 --> 00:20:17,000
I move the chair to the bedroom.

223
00:20:17,000 --> 00:20:18,000
I put the coffee cup in the bed.

224
00:20:18,000 --> 00:20:19,000
I turn the cup upside down.

225
00:20:19,000 --> 00:20:21,000
Then I return it upside up.

226
00:20:21,000 --> 00:20:23,000
Place the coffee cup on the counter in the kitchen.

227
00:20:23,000 --> 00:20:25,000
Where's my diamond?

228
00:20:25,000 --> 00:20:28,000
And so GPT-4 says, yeah, OK.

229
00:20:28,000 --> 00:20:30,000
You turned it upside down.

230
00:20:30,000 --> 00:20:32,000
So, probably the diamond fell out.

231
00:20:32,000 --> 00:20:35,000
So, therefore, the diamond in the bedroom fell out.

232
00:20:35,000 --> 00:20:36,000
Again, correct.

233
00:20:38,000 --> 00:20:45,000
Why is it that people are claiming that GPT-4 can't do these things when it can?

234
00:20:45,000 --> 00:20:51,000
Well, the reason is because I think on the whole they are not aware of how GPT-4 was trained.

235
00:20:51,000 --> 00:20:59,000
GPT-4 was not trained at any point to give correct answers.

236
00:20:59,000 --> 00:21:05,000
GPT-4 was trained initially to give most likely next words.

237
00:21:05,000 --> 00:21:12,000
And there's an awful lot of stuff on the internet where documents are not describing things that are true.

238
00:21:12,000 --> 00:21:13,000
There could be fiction.

239
00:21:13,000 --> 00:21:15,000
There could be jokes.

240
00:21:15,000 --> 00:21:18,000
There could be just stupid people saying dumb stuff.

241
00:21:18,000 --> 00:21:23,000
So, this first stage does not necessarily give you correct answers.

242
00:21:23,000 --> 00:21:31,000
The second stage with the instruction tuning, also, like, it's trying to give correct answers.

243
00:21:31,000 --> 00:21:38,000
But part of the problem is that then in the stage where you start asking people which answer do they like better,

244
00:21:39,000 --> 00:21:47,000
people tended to say in these things that they prefer more confident answers

245
00:21:47,000 --> 00:21:53,000
and they often were not people who were trained well enough to recognize wrong answers.

246
00:21:53,000 --> 00:22:01,000
So, there's lots of reasons that the SGD weight updates from this process for stuff like GPT-4

247
00:22:01,000 --> 00:22:07,000
don't particularly or don't entirely reward correct answers.

248
00:22:07,000 --> 00:22:11,000
But you can help it want to give you correct answers.

249
00:22:11,000 --> 00:22:19,000
If you think about the LM pre-training, what are the kinds of things in a document that would suggest,

250
00:22:19,000 --> 00:22:22,000
oh, this is going to be high quality information.

251
00:22:22,000 --> 00:22:33,000
And so, you can actually prime GPT-4 to give you high quality information by giving it custom instructions.

252
00:22:33,000 --> 00:22:40,000
And what this does is this is basically text that is prepended to all of your queries.

253
00:22:40,000 --> 00:22:44,000
And so, you say like, oh, you're brilliant at reasoning.

254
00:22:44,000 --> 00:22:50,000
So, like, okay, that's obviously to prime it to give good answers.

255
00:22:50,000 --> 00:23:00,000
And then try to work against the fact that the RLHF folks preferred confidence.

256
00:23:00,000 --> 00:23:05,000
Just tell it. No, tell me if there might not be a correct answer.

257
00:23:05,000 --> 00:23:12,000
Also, the way that the text is generated is it literally generates the next word.

258
00:23:12,000 --> 00:23:17,000
And then it puts all that whole lot back into the model and generates the next next word,

259
00:23:17,000 --> 00:23:22,000
puts that all back in the model, generates the next next next word, and so forth.

260
00:23:22,000 --> 00:23:26,000
That means the more words it generates, the more computation it can do.

261
00:23:26,000 --> 00:23:29,000
And so, I literally, I tell it that, right?

262
00:23:29,000 --> 00:23:35,000
So, I say, first, bend a few sentences explaining background context, et cetera.

263
00:23:35,000 --> 00:23:48,000
So, this custom instruction allows it to solve more challenging problems.

264
00:23:48,000 --> 00:23:52,000
And you can see the difference.

265
00:23:52,000 --> 00:23:58,000
Here's what it looks like, for example, if I say, how do I get a count of rows grouped by value in pandas?

266
00:23:58,000 --> 00:24:03,000
And it just gives me a whole lot of information, which is actually it thinking.

267
00:24:03,000 --> 00:24:06,000
So, I just skip over it, and then it gives me the answer.

268
00:24:06,000 --> 00:24:15,000
And actually, in my custom instructions, I actually say, if the request begins with VV,

269
00:24:15,000 --> 00:24:18,000
actually make it as concise as possible.

270
00:24:18,000 --> 00:24:21,000
And so, it kind of goes into brief mode.

271
00:24:21,000 --> 00:24:23,000
And here is brief mode.

272
00:24:23,000 --> 00:24:24,000
How do I get the grid?

273
00:24:24,000 --> 00:24:26,000
This is the same thing, but with VV at the start.

274
00:24:26,000 --> 00:24:28,000
And it just spits it out.

275
00:24:28,000 --> 00:24:32,000
Now, in this case, it's a really simple question, so I didn't need time to think.

276
00:24:32,000 --> 00:24:40,000
So, hopefully, that gives you a sense of how to get language models to give good answers.

277
00:24:40,000 --> 00:24:42,000
You have to help them.

278
00:24:42,000 --> 00:24:47,000
And if it's not working, it might be user error, basically.

279
00:24:47,000 --> 00:24:53,000
But having said that, there's plenty of stuff that language models like GPT-4 can't do.

280
00:24:54,000 --> 00:24:59,000
One thing to think carefully about is, does it know about itself?

281
00:24:59,000 --> 00:25:00,000
Can you ask it?

282
00:25:00,000 --> 00:25:02,000
What is your context length?

283
00:25:02,000 --> 00:25:04,000
How were you trained?

284
00:25:04,000 --> 00:25:09,000
What transformer architecture are you based on?

285
00:25:09,000 --> 00:25:15,000
At any one of these stages, did it have the opportunity to learn any of those things?

286
00:25:15,000 --> 00:25:17,000
Well, obviously, not at the pre-training stage.

287
00:25:17,000 --> 00:25:25,000
Nothing on the internet existed during GPT-4's training saying how GPT-4 was trained.

288
00:25:25,000 --> 00:25:29,000
Probably ditto in the instruction tuning, probably ditto in the RLHF.

289
00:25:29,000 --> 00:25:35,000
So, in general, you can't ask, for example, a language model about itself.

290
00:25:35,000 --> 00:25:41,000
Now, again, because of the RLHF, it'll want to make you happy by giving you opinionated answers.

291
00:25:41,000 --> 00:25:47,000
So, it'll just spit out the most likely thing it thinks with great confidence.

292
00:25:47,000 --> 00:25:50,000
This is just a general kind of hallucination, right?

293
00:25:50,000 --> 00:25:56,000
So, hallucinations is just this idea that the language model wants to complete the sentence,

294
00:25:56,000 --> 00:26:00,000
and it wants to do it in an opinionated way that's likely to make people happy.

295
00:26:02,000 --> 00:26:04,000
It doesn't know anything about URLs.

296
00:26:04,000 --> 00:26:07,000
It really hasn't seen many at all.

297
00:26:07,000 --> 00:26:10,000
I think a lot of them, if not all of them, pretty much were stripped out.

298
00:26:11,000 --> 00:26:18,000
So, if you ask it anything about, like, what's at this web page, again, it'll generally just make it up.

299
00:26:18,000 --> 00:26:23,000
And it doesn't know, at least GPT-4 doesn't know anything after September 2021,

300
00:26:23,000 --> 00:26:33,000
because the information it was pre-trained on was from that time period, September 2021 and before,

301
00:26:33,000 --> 00:26:35,000
called the Knowledge Cutoff.

302
00:26:35,000 --> 00:26:38,000
So, here's some things it can't do.

303
00:26:39,000 --> 00:26:42,000
Steve Newman sent me this good example of something that it can't do.

304
00:26:45,000 --> 00:26:47,000
Here is a logic puzzle.

305
00:26:47,000 --> 00:26:51,000
I need to carry a cabbage, a goat, and a wolf across a river.

306
00:26:51,000 --> 00:26:53,000
I can only carry one item at a time.

307
00:26:53,000 --> 00:26:56,000
I can't leave the goat with a cabbage.

308
00:26:56,000 --> 00:26:58,000
I can't leave the cabbage with a wolf.

309
00:26:58,000 --> 00:27:01,000
How do I get everything across to the other side?

310
00:27:01,000 --> 00:27:07,000
Now, the problem is, this looks a lot like something called the classic river crossing puzzle.

311
00:27:09,000 --> 00:27:15,000
So, classic, in fact, that it has a whole Wikipedia page about it.

312
00:27:15,000 --> 00:27:24,000
And in the classic puzzle, the wolf would eat the goat, or the goat would eat the cabbage.

313
00:27:25,000 --> 00:27:32,000
Now, in Steve's version, he changed it.

314
00:27:35,000 --> 00:27:40,000
The goat would eat the cabbage, and the wolf would eat the cabbage, but the wolf won't eat the goat.

315
00:27:42,000 --> 00:27:43,000
So, what happens?

316
00:27:43,000 --> 00:27:49,000
Well, very interestingly, GPT-4 here is entirely overwhelmed by the language model training.

317
00:27:49,000 --> 00:27:53,000
It's seen this puzzle so many times, it knows what word comes next.

318
00:27:53,000 --> 00:27:58,000
So, it says, oh, yeah, I take the goat across the road, across the river, and leave it on the other side,

319
00:27:58,000 --> 00:28:04,000
leaving the wolf with a cabbage, but we're just told you can't leave the wolf with a cabbage.

320
00:28:04,000 --> 00:28:06,000
So, it gets it wrong.

321
00:28:06,000 --> 00:28:13,000
Now, the thing is, though, you can encourage GPT-4 or any of these language models to try again.

322
00:28:13,000 --> 00:28:19,000
So, during the instruction tuning in RLHF, they're actually fine-tuned with multi-stage conversations.

323
00:28:19,000 --> 00:28:22,000
So, you can give it a multi-stage conversation.

324
00:28:22,000 --> 00:28:24,000
Repeat back to me the constraints I listed.

325
00:28:24,000 --> 00:28:28,000
What happened after step one is a constraint violated.

326
00:28:28,000 --> 00:28:31,000
Oh, yeah, yeah, yeah, I made a mistake.

327
00:28:31,000 --> 00:28:37,000
Okay, my new attempt, instead of taking the goat across the river and leaving it on the other side,

328
00:28:37,000 --> 00:28:41,000
is, oh, I'll take the goat across the river and leave it on the other side.

329
00:28:41,000 --> 00:28:43,000
It's done the same thing.

330
00:28:43,000 --> 00:28:47,000
Oh, yeah, I did do the same thing.

331
00:28:47,000 --> 00:28:49,000
Okay, I'll take the wolf across.

332
00:28:49,000 --> 00:28:52,000
Well, now the goat's with a cabbage. That still doesn't work.

333
00:28:52,000 --> 00:28:56,000
Oh, yeah, that didn't work either.

334
00:28:56,000 --> 00:28:58,000
Sorry about that.

335
00:28:58,000 --> 00:29:01,000
Instead of taking the goat across the other side, I'll take the goat across the other side.

336
00:29:01,000 --> 00:29:03,000
Okay, what's going on here?

337
00:29:03,000 --> 00:29:05,000
Right, this is terrible.

338
00:29:05,000 --> 00:29:16,000
Well, one of the problems here is that not only is on the internet it's so common to see this particular goat puzzle

339
00:29:16,000 --> 00:29:19,000
that it's so confident it knows what the next word is.

340
00:29:19,000 --> 00:29:25,000
Also, on the internet, when you see stuff which is stupid on a web page,

341
00:29:25,000 --> 00:29:30,000
it's really likely to be followed up with more stuff that is stupid.

342
00:29:30,000 --> 00:29:38,000
Once GPT-4 starts being wrong, it tends to be more and more wrong.

343
00:29:38,000 --> 00:29:44,000
It's very hard to turn it around to start it making it be right.

344
00:29:44,000 --> 00:29:57,000
So you actually have to go back and there's actually an edit button on these chats.

345
00:29:57,000 --> 00:30:00,000
And so what you generally want to do is if it's made a mistake,

346
00:30:00,000 --> 00:30:03,000
is don't say, oh, here's more information to help you fix it.

347
00:30:03,000 --> 00:30:16,000
But instead, go back and click the edit and change it here.

348
00:30:16,000 --> 00:30:21,000
And so this time it's not going to get confused.

349
00:30:21,000 --> 00:30:26,000
So in this case, actually fixing Steve's example takes quite a lot of effort,

350
00:30:26,000 --> 00:30:29,000
but I think I managed to get it to work eventually.

351
00:30:29,000 --> 00:30:32,000
And I actually said, oh, sometimes people read things too quickly.

352
00:30:32,000 --> 00:30:35,000
They don't notice things, it can trick them up.

353
00:30:35,000 --> 00:30:38,000
Then they apply some pattern, get the wrong answer.

354
00:30:38,000 --> 00:30:40,000
You do the same thing, by the way.

355
00:30:40,000 --> 00:30:42,000
So I'm going to trick you.

356
00:30:42,000 --> 00:30:46,000
So before you're about to get tricked, make sure you don't get tricked.

357
00:30:46,000 --> 00:30:48,000
Here's the tricky puzzle.

358
00:30:48,000 --> 00:30:54,000
And then also with my custom instructions, it takes time discussing it.

359
00:30:54,000 --> 00:30:56,000
And this time it gets it correct.

360
00:30:56,000 --> 00:30:58,000
It takes the cabbage across first.

361
00:30:58,000 --> 00:31:03,000
So it took a lot of effort to get to a point where it could actually solve this

362
00:31:03,000 --> 00:31:11,000
because for things where it's been primed to answer a certain way

363
00:31:11,000 --> 00:31:16,000
again and again and again, it's very hard for it to not do that.

364
00:31:16,000 --> 00:31:23,000
OK, now something else super helpful that you can use

365
00:31:23,000 --> 00:31:26,000
is what they call advanced data analysis.

366
00:31:26,000 --> 00:31:31,000
In advanced data analysis, you can ask it to basically write code for you.

367
00:31:31,000 --> 00:31:35,000
And we're going to look at how to implement this from scratch ourselves quite soon.

368
00:31:35,000 --> 00:31:37,000
But first of all, let's learn how to use it.

369
00:31:37,000 --> 00:31:43,000
So I was trying to build something that split into markdown headings,

370
00:31:43,000 --> 00:31:46,000
a document on third level markdown headings.

371
00:31:46,000 --> 00:31:49,000
So that's three hashes at the start of a line.

372
00:31:49,000 --> 00:31:52,000
And I was doing it on the whole of Wikipedia.

373
00:31:52,000 --> 00:31:55,000
So using regular expressions was really slow.

374
00:31:55,000 --> 00:31:57,000
I said, oh, I want to speed this up.

375
00:31:57,000 --> 00:32:01,000
And it said, OK, here's some code, which is great,

376
00:32:01,000 --> 00:32:05,000
because then I can say, OK, test it and include edge cases.

377
00:32:05,000 --> 00:32:14,000
And so it then puts in the code, creates extra cases, tests it,

378
00:32:14,000 --> 00:32:19,000
and says, yep, it's working.

379
00:32:19,000 --> 00:32:21,000
However, I discovered it's not.

380
00:32:21,000 --> 00:32:24,000
I noticed it's actually removing the carriage return at the end of each sentence.

381
00:32:24,000 --> 00:32:28,000
So I said, oh, fix that and update your tests.

382
00:32:28,000 --> 00:32:34,000
So it said, OK, so now it's changed the test, updated the test cases,

383
00:32:34,000 --> 00:32:38,000
it's run them and it's not working.

384
00:32:38,000 --> 00:32:43,000
So it says, oh, yeah, fix the issue in the test cases.

385
00:32:43,000 --> 00:32:45,000
Nope, it didn't work.

386
00:32:45,000 --> 00:32:52,000
And you can see it's quite clever the way it's trying to fix it by looking at the results.

387
00:32:53,000 --> 00:32:56,000
But as you can see, it's not.

388
00:32:56,000 --> 00:33:00,000
Every one of these is another attempt, another attempt, another attempt,

389
00:33:00,000 --> 00:33:02,000
until eventually I gave up waiting.

390
00:33:02,000 --> 00:33:03,000
It's so funny each time.

391
00:33:03,000 --> 00:33:05,000
It's like, de-banging again.

392
00:33:05,000 --> 00:33:08,000
OK, this time I got to handle it properly.

393
00:33:08,000 --> 00:33:12,000
And I gave up at the point where it's like, oh, one more attempt.

394
00:33:12,000 --> 00:33:15,000
So it didn't solve it, interestingly enough.

395
00:33:15,000 --> 00:33:25,000
And again, there's some limits to the amount of logic that it can do.

396
00:33:25,000 --> 00:33:27,000
This is really a very simple question.

397
00:33:27,000 --> 00:33:29,000
I asked it to do for me.

398
00:33:29,000 --> 00:33:35,000
And so hopefully you can see you can't expect even GPT for code interpreter

399
00:33:35,000 --> 00:33:42,000
or advanced data analysis that is now called to make it so you don't have to write code anymore.

400
00:33:42,000 --> 00:33:47,000
So there's a lot of substitute for having programmers.

401
00:33:51,000 --> 00:33:54,000
But it can often do a lot, as I'll show you in a moment.

402
00:33:54,000 --> 00:34:01,000
So for example, actually OCR, like this is something I thought was really cool.

403
00:34:01,000 --> 00:34:04,000
You can just paste, sorry, paste or upload.

404
00:34:04,000 --> 00:34:11,000
So GPT for you can upload an image, advanced data analysis.

405
00:34:11,000 --> 00:34:15,000
Yeah, you can upload an image here.

406
00:34:15,000 --> 00:34:20,000
And then I wanted to basically grab some text out of an image.

407
00:34:20,000 --> 00:34:24,000
Somebody had got a screenshot with their screen, which was something saying,

408
00:34:24,000 --> 00:34:27,000
oh, this language model can't do this.

409
00:34:27,000 --> 00:34:28,000
And I wanted to try it as well.

410
00:34:28,000 --> 00:34:32,000
So rather than retyping it, I just uploaded that image, my screenshot,

411
00:34:32,000 --> 00:34:34,000
and said, can you extract the text from this image?

412
00:34:34,000 --> 00:34:36,000
And it said, oh, yeah, I could do that.

413
00:34:36,000 --> 00:34:38,000
I could use OCR.

414
00:34:38,000 --> 00:34:42,000
And like so it literally wrote an OCR script.

415
00:34:42,000 --> 00:34:45,000
And there it is.

416
00:34:45,000 --> 00:34:47,000
Just took a few seconds.

417
00:34:47,000 --> 00:34:53,000
So the difference here is it didn't really require it to think of much logic.

418
00:34:53,000 --> 00:34:59,000
It could just use a very, very familiar pattern that it would have seen many times.

419
00:34:59,000 --> 00:35:06,000
So this is generally where I find language models excel is where it doesn't have to think too far outside the box.

420
00:35:06,000 --> 00:35:09,000
I mean, it's great on kind of creativity tasks,

421
00:35:09,000 --> 00:35:14,000
but for like reasoning and logic tasks that are outside the box, I find it not great.

422
00:35:14,000 --> 00:35:21,000
But yeah, it's great at doing code for a whole wide variety of different libraries and languages.

423
00:35:21,000 --> 00:35:28,000
Having said that, by the way, Google also has a language model called Bard.

424
00:35:28,000 --> 00:35:31,000
It's way less good than GPT for most of the time.

425
00:35:31,000 --> 00:35:37,000
But there is a nice thing that you can literally paste an image straight into the prompt.

426
00:35:37,000 --> 00:35:39,000
And I just typed OCR this.

427
00:35:39,000 --> 00:35:42,000
And it didn't even have to go through code interpreter or whatever.

428
00:35:42,000 --> 00:35:44,000
It just said, oh, sure, I've done it.

429
00:35:44,000 --> 00:35:47,000
And there's the result of the OCR.

430
00:35:47,000 --> 00:35:51,000
And even commented on what it just OCRed, which I thought was cute.

431
00:35:51,000 --> 00:36:00,000
And oh, even more interestingly, it even figured out where the OCR text came from and gave me a link to it.

432
00:36:00,000 --> 00:36:03,000
So I thought that was pretty cool.

433
00:36:03,000 --> 00:36:08,000
OK, so there's an example of it doing well.

434
00:36:08,000 --> 00:36:11,000
I'll show you one for this talk I found really helpful.

435
00:36:11,000 --> 00:36:18,000
I wanted to show you guys how much it costs to use the OpenAI API.

436
00:36:18,000 --> 00:36:24,000
But unfortunately, when I went to the OpenAI web page, it was like all over the place.

437
00:36:24,000 --> 00:36:29,000
The pricing information was on all separate tables and it was kind of a bit of a mess.

438
00:36:29,000 --> 00:36:37,000
So I wanted to create a table with all of the information combined like this.

439
00:36:37,000 --> 00:36:42,000
And here's how I did it.

440
00:36:42,000 --> 00:36:45,000
I went to the OpenAI page.

441
00:36:45,000 --> 00:36:48,000
I hit Apple A to select all.

442
00:36:48,000 --> 00:36:55,000
And then I said in chat GPT, create a table with the pricing information rows, no summarization,

443
00:36:55,000 --> 00:36:57,000
no information, not in this page.

444
00:36:57,000 --> 00:36:59,000
Every row should appear as a separate row in your output.

445
00:36:59,000 --> 00:37:01,000
And I hit Paste.

446
00:37:01,000 --> 00:37:05,000
Now that was not very helpful to it because hitting Paste, it's got the nav bar.

447
00:37:05,000 --> 00:37:11,000
It's got lots of extra information at the bottom.

448
00:37:11,000 --> 00:37:16,000
It's got all of its footer, et cetera.

449
00:37:16,000 --> 00:37:19,000
But it's really good at this stuff.

450
00:37:19,000 --> 00:37:21,000
It did it first time.

451
00:37:21,000 --> 00:37:23,000
So there was the markdown table.

452
00:37:23,000 --> 00:37:26,000
And then pasted that into Jupiter.

453
00:37:26,000 --> 00:37:28,000
And I got my markdown table.

454
00:37:28,000 --> 00:37:34,000
And so now you can see at a glance the cost of GPT-4, 3.5, et cetera.

455
00:37:34,000 --> 00:37:38,000
But then what I really wanted to do was show you that as a picture.

456
00:37:38,000 --> 00:37:42,000
So I just said, oh, chart the input row from this table.

457
00:37:42,000 --> 00:37:46,000
Just pasted the table back.

458
00:37:46,000 --> 00:37:48,000
And it did.

459
00:37:48,000 --> 00:37:50,000
So that's pretty amazing.

460
00:37:50,000 --> 00:37:53,000
So let's talk about this pricing.

461
00:37:53,000 --> 00:37:57,000
So far, we've used chat GPT, which costs $20 a month.

462
00:37:57,000 --> 00:38:00,000
And there's no per token cost or anything.

463
00:38:00,000 --> 00:38:04,000
But if you want to use the API from Python or whatever, you have to pay per token.

464
00:38:04,000 --> 00:38:07,000
Which is approximately per word.

465
00:38:07,000 --> 00:38:12,000
Maybe it's about one and a third tokens per word on average.

466
00:38:12,000 --> 00:38:17,000
Unfortunately, in the chart, it did not include these headers, GPT-4, GPT-3.5.

467
00:38:17,000 --> 00:38:19,000
So these first two ones are GPT-4.

468
00:38:19,000 --> 00:38:21,000
And these two are GPT-3.5.

469
00:38:21,000 --> 00:38:27,000
So you can see the GPT-3.5 is way, way cheaper.

470
00:38:27,000 --> 00:38:29,000
And you can see it here.

471
00:38:29,000 --> 00:38:34,000
It's 0.03 versus 0.0015.

472
00:38:34,000 --> 00:38:40,000
So it's so cheap, you can really play around with it and not worry.

473
00:38:40,000 --> 00:38:43,000
And I want to give you a sense of what that looks like.

474
00:38:44,000 --> 00:38:51,000
So why would you use the OpenAI API rather than chat GPT?

475
00:38:51,000 --> 00:38:53,000
Because you can do it programmatically.

476
00:38:53,000 --> 00:39:02,000
So you can analyze data sets, you can do repetitive stuff.

477
00:39:02,000 --> 00:39:05,000
It's kind of like a different way of programming.

478
00:39:05,000 --> 00:39:09,000
It's things that you can think of describing.

479
00:39:09,000 --> 00:39:12,000
But let's just look at the most simple example of what that looks like.

480
00:39:12,000 --> 00:39:18,000
So if you pip install OpenAI, then you can import chat completion.

481
00:39:18,000 --> 00:39:24,000
And then you can say, OK, chat completion.create using GPT-3.5 turbo.

482
00:39:24,000 --> 00:39:27,000
And then you can pass in a system message.

483
00:39:27,000 --> 00:39:30,000
This is basically the same as custom instructions.

484
00:39:30,000 --> 00:39:35,000
So, OK, you're an Aussie LLM that uses Aussie slang and analogies wherever possible.

485
00:39:35,000 --> 00:39:39,000
OK, and so you can see I'm passing in an array here of messages.

486
00:39:39,000 --> 00:39:45,000
So the first is the system message and then the user message, which is what is money?

487
00:39:45,000 --> 00:39:52,000
OK, so GPT-3.5 returns a big embedded dictionary.

488
00:39:52,000 --> 00:40:02,000
And the message content is, well, money is like the oil that keeps the machinery of our economy running smoothly.

489
00:40:02,000 --> 00:40:03,000
There you go.

490
00:40:03,000 --> 00:40:08,000
Just like Aquila loves its eucalyptus leaves, we humans can't survive without this stuff.

491
00:40:08,000 --> 00:40:12,000
So there's the Aussie LLM's view of what is money.

492
00:40:12,000 --> 00:40:22,000
So the main ones I pretty much always use are GPT-4 and GPT-3.5.

493
00:40:22,000 --> 00:40:31,000
GPT-4 is just so, so much better at anything remotely challenging, but obviously it's much more expensive.

494
00:40:31,000 --> 00:40:36,000
So rule of thumb, maybe try 3.5 turbo first, see how it goes.

495
00:40:36,000 --> 00:40:38,000
If you're happy with the results, then great.

496
00:40:38,000 --> 00:40:42,000
If you're not, pony out for the more expensive one.

497
00:40:42,000 --> 00:40:52,000
OK, so I just created a little function here called response that will print out this nested thing.

498
00:40:52,000 --> 00:41:00,000
And so now, oh, and so then the other thing to point out here is that the result of this also has a usage field,

499
00:41:00,000 --> 00:41:04,000
which contains how many tokens was it?

500
00:41:04,000 --> 00:41:06,000
So it's about 150 tokens.

501
00:41:06,000 --> 00:41:26,000
So at $0.002 per thousand tokens for 150 tokens means we just paid 0.03 cents, 0.0003 dollars to get that done.

502
00:41:26,000 --> 00:41:29,000
So as you can see, the cost is insignificant.

503
00:41:29,000 --> 00:41:35,000
If we were using GPT-4, it would be 0.03 per thousand.

504
00:41:35,000 --> 00:41:39,000
So it would be half a cent.

505
00:41:39,000 --> 00:41:51,000
So unless you're doing many thousands of GPT-4, you're not going to be even up into the dollars and GPT-3.5 even more than that.

506
00:41:51,000 --> 00:41:52,000
But you know, keep an eye on it.

507
00:41:52,000 --> 00:41:56,000
OpenAI has a usage page and you can track your usage.

508
00:41:56,000 --> 00:42:07,000
Now, what happens when we are this is really important to understand when we have a follow up in the same conversation?

509
00:42:07,000 --> 00:42:11,000
How does that work?

510
00:42:11,000 --> 00:42:14,000
So we just asked what goat means.

511
00:42:14,000 --> 00:42:25,000
So for example, Michael Jordan is often referred to as the goat for his exceptional skills and accomplishments.

512
00:42:25,000 --> 00:42:30,000
And Elvis and the Beatles referred to as goat due to their profound influence and achievement.

513
00:42:30,000 --> 00:42:45,000
So I could say, what profound influence and achievements are you referring to?

514
00:42:45,000 --> 00:42:49,000
Okay, well, I meant Elvis Presley and the Beatles did all these things.

515
00:42:49,000 --> 00:42:50,000
Now, how does that work?

516
00:42:50,000 --> 00:42:52,000
How does this follow up work?

517
00:42:52,000 --> 00:42:57,000
What happens is the entire conversation is passed back.

518
00:42:57,000 --> 00:43:00,000
And so we can actually do that here.

519
00:43:00,000 --> 00:43:04,000
So here is the same system prompt.

520
00:43:04,000 --> 00:43:07,000
Here is the same question, right?

521
00:43:07,000 --> 00:43:10,000
And then the answer comes back with role assistant.

522
00:43:10,000 --> 00:43:12,000
And I'm going to do something pretty cheeky.

523
00:43:12,000 --> 00:43:17,000
I'm going to pretend that it didn't say money is like oil.

524
00:43:17,000 --> 00:43:22,000
I'm going to say, oh, you actually said money is like kangaroos.

525
00:43:22,000 --> 00:43:24,000
I thought, what is it going to do?

526
00:43:24,000 --> 00:43:30,000
Okay, so you can like literally invent a conversation in which the language model said something different.

527
00:43:30,000 --> 00:43:34,000
Because this is actually how it's done in a multi-stage conversation.

528
00:43:34,000 --> 00:43:36,000
There's no state, right?

529
00:43:36,000 --> 00:43:38,000
There's nothing stored on the server.

530
00:43:38,000 --> 00:43:45,000
You're passing back the entire conversation again and telling it what it told you, right?

531
00:43:45,000 --> 00:43:46,000
So I'm going to tell it.

532
00:43:46,000 --> 00:43:48,000
It told me that money is like kangaroos.

533
00:43:48,000 --> 00:43:51,000
And then I'll ask the user, oh, really?

534
00:43:51,000 --> 00:43:52,000
In what way?

535
00:43:52,000 --> 00:43:58,000
And it's kind of cool because you can see how it convinces you of something I just invented.

536
00:43:58,000 --> 00:44:01,000
Oh, let me break it down for you, Cuba.

537
00:44:01,000 --> 00:44:04,000
Just like kangaroos hop around and carry their joeys in their pouch,

538
00:44:04,000 --> 00:44:06,000
money is a means of carrying value around.

539
00:44:06,000 --> 00:44:07,000
So there you go.

540
00:44:07,000 --> 00:44:10,000
It's make your own analogy.

541
00:44:10,000 --> 00:44:11,000
Cool.

542
00:44:11,000 --> 00:44:17,000
So I'll create a little function here that just puts these things together for us.

543
00:44:17,000 --> 00:44:22,000
System message, if there is one, the user message and returns the completion.

544
00:44:22,000 --> 00:44:25,000
And so now we can ask it, what's the meaning of life?

545
00:44:25,000 --> 00:44:28,000
Passing in the Aussie system prompt.

546
00:44:28,000 --> 00:44:33,000
The meaning of life is like trying to catch a wave on a sunny day at Bondo Beach.

547
00:44:33,000 --> 00:44:34,000
Okay, there you go.

548
00:44:34,000 --> 00:44:37,000
So what do you need to be aware of?

549
00:44:37,000 --> 00:44:40,000
Well, as I said, one thing is keep an eye on your usage.

550
00:44:40,000 --> 00:44:44,000
If you're doing it, you know, hundreds or thousands of times in a loop,

551
00:44:44,000 --> 00:44:47,000
keep an eye on not spending too much money.

552
00:44:47,000 --> 00:44:51,000
But also if you do it too fast, particularly the first day or two,

553
00:44:51,000 --> 00:44:57,000
you've got an account, you're likely to hit the limits for the API.

554
00:44:57,000 --> 00:45:02,000
And so the limits initially are pretty low.

555
00:45:02,000 --> 00:45:09,000
As you can see, three requests per minute.

556
00:45:10,000 --> 00:45:13,000
So that's for free users, page users, first 48 hours.

557
00:45:13,000 --> 00:45:17,000
And after that, it starts going up and you can always ask for more.

558
00:45:17,000 --> 00:45:23,000
I just mentioned this because you're going to want to have a function that keeps an eye on that.

559
00:45:23,000 --> 00:45:26,000
And so what I did is I actually just went to Bing,

560
00:45:26,000 --> 00:45:30,000
which has a somewhat crappy version of GPT-4 nowadays,

561
00:45:30,000 --> 00:45:32,000
but it can still do basic stuff for free.

562
00:45:32,000 --> 00:45:41,000
And I said, please show me Python code to call the OpenAI API and handle rate limits.

563
00:45:41,000 --> 00:45:43,000
And it wrote this code.

564
00:45:43,000 --> 00:45:50,000
It's got a try, checks your rate limit errors, grabs the retry after,

565
00:45:50,000 --> 00:45:54,000
sleeps for that long and calls itself.

566
00:45:54,000 --> 00:45:57,000
And so now we can use that to ask, for example,

567
00:45:57,000 --> 00:46:00,000
what's the world's funniest joke?

568
00:46:00,000 --> 00:46:04,000
And there we go.

569
00:46:04,000 --> 00:46:08,000
Here's the world's funniest joke.

570
00:46:08,000 --> 00:46:18,000
So that's like the basic stuff you need to get started using the OpenAI LLMs.

571
00:46:18,000 --> 00:46:24,000
And yeah, it's definitely suggest spending plenty of time with that

572
00:46:24,000 --> 00:46:33,000
so that you feel like you're really a LLM using expert.

573
00:46:33,000 --> 00:46:35,000
So what else can we do?

574
00:46:35,000 --> 00:46:40,000
Well, let's create our own code interpreter that runs inside GPT-4.

575
00:46:40,000 --> 00:46:48,000
And so to do this, we're going to take advantage of a really nifty thing called function calling,

576
00:46:48,000 --> 00:46:51,000
which is provided by the OpenAI API.

577
00:46:51,000 --> 00:46:56,000
And in function calling, when we call our askGPT function,

578
00:46:56,000 --> 00:47:02,000
which is this little one here, we had room to pass in some keyword arguments

579
00:47:02,000 --> 00:47:05,000
that would be just passed along to checkCompletion.create.

580
00:47:05,000 --> 00:47:12,000
And one of those keyword arguments you can pass is functions.

581
00:47:12,000 --> 00:47:14,000
What on earth is that?

582
00:47:14,000 --> 00:47:23,000
Functions tells OpenAI about tools that you have, about functions that you have.

583
00:47:23,000 --> 00:47:33,000
So for example, I created a really simple function called sums and it adds two things.

584
00:47:33,000 --> 00:47:37,000
In fact, it adds two ints.

585
00:47:37,000 --> 00:47:45,000
And I am going to pass that function to checkCompletion.create.

586
00:47:45,000 --> 00:47:49,000
Now you can't pass a Python function directly.

587
00:47:49,000 --> 00:47:53,000
You actually have to pass what's called the JSON schema.

588
00:47:53,000 --> 00:47:56,000
So you have to pass the schema for the function.

589
00:47:56,000 --> 00:48:01,000
So I created this nifty little function that you're welcome to borrow,

590
00:48:01,000 --> 00:48:08,000
which uses pydantic and also Python's inspect module

591
00:48:08,000 --> 00:48:15,000
to automatically take a Python function and return the schema for it.

592
00:48:15,000 --> 00:48:18,000
And so this is actually what's going to get passed to OpenAI.

593
00:48:18,000 --> 00:48:20,000
So it's going to know that there's a function called sums.

594
00:48:20,000 --> 00:48:25,000
It's going to know what it does and it's going to know what parameters it takes,

595
00:48:25,000 --> 00:48:29,000
what the defaults are and what's required.

596
00:48:29,000 --> 00:48:34,000
So this is like, when I first heard about this, I found this a bit mind-bending

597
00:48:34,000 --> 00:48:37,000
because this is so different to how we normally program computers.

598
00:48:37,000 --> 00:48:42,000
The key thing for programming the computer here actually is the doc string.

599
00:48:42,000 --> 00:48:48,000
This is the thing that GPT-4 will look at and say, oh, what does this function do?

600
00:48:48,000 --> 00:48:52,000
So it's critical that this describes exactly what the function does.

601
00:48:52,000 --> 00:49:00,000
And so if I then say, what is 6 plus 3?

602
00:49:00,000 --> 00:49:04,000
And I just, I really wanted to make sure it actually did it here.

603
00:49:04,000 --> 00:49:08,000
So I gave it lots of prompts to say, because obviously it knows how to do it itself

604
00:49:08,000 --> 00:49:10,000
without calling sums.

605
00:49:10,000 --> 00:49:16,000
So it'll only use your functions if it feels it needs to, which is a weird concept.

606
00:49:16,000 --> 00:49:18,000
I mean, I guess fields is not a great word to use,

607
00:49:18,000 --> 00:49:22,000
but you kind of have to anthropomorphize these things a little bit

608
00:49:22,000 --> 00:49:25,000
because they don't behave like normal computer programs.

609
00:49:25,000 --> 00:49:33,000
So if I ask GPT, what is 6 plus 3, and tell it that there's a function called sums,

610
00:49:33,000 --> 00:49:37,000
then it does not actually return the number 9.

611
00:49:37,000 --> 00:49:41,000
Instead, it returns something saying, please call a function.

612
00:49:41,000 --> 00:49:46,000
Call this function and pass it these arguments.

613
00:49:46,000 --> 00:49:50,000
So if I print it out, there's the arguments.

614
00:49:50,000 --> 00:49:53,000
So I created a little function called core function,

615
00:49:53,000 --> 00:50:00,000
and it goes into the result of OpenAI, grabs the function call,

616
00:50:00,000 --> 00:50:04,000
checks that the name is something that it's allowed to do,

617
00:50:04,000 --> 00:50:11,000
grabs it from the global system table, and calls it, passing in the parameters.

618
00:50:11,000 --> 00:50:22,000
So if I now say, OK, call the function that we got back, we finally get 9.

619
00:50:22,000 --> 00:50:25,000
So this is a very simple example.

620
00:50:25,000 --> 00:50:27,000
It's not really doing anything that useful,

621
00:50:27,000 --> 00:50:35,000
but what we could do now is we can create a much more powerful function called Python.

622
00:50:35,000 --> 00:50:46,000
And the Python function executes code using Python and returns the result.

623
00:50:46,000 --> 00:50:52,000
Now, of course, I didn't want my computer to run arbitrary Python code

624
00:50:52,000 --> 00:50:55,000
that GPT4 told it to without checking.

625
00:50:55,000 --> 00:50:57,000
So I just got it to check first.

626
00:50:57,000 --> 00:51:01,000
So say, oh, are you sure you want to do this?

627
00:51:01,000 --> 00:51:09,000
So now I can say, ask GPT, what is 12 factorial?

628
00:51:09,000 --> 00:51:10,000
System prompt.

629
00:51:10,000 --> 00:51:15,000
You can use Python for any required computations and say, OK, here's a function you've got available.

630
00:51:15,000 --> 00:51:18,000
It's the Python function.

631
00:51:18,000 --> 00:51:26,000
So if I now call this, it will pass me back again a completion object.

632
00:51:26,000 --> 00:51:33,000
And here it's going to say, OK, I want you to call Python passing in this argument.

633
00:51:33,000 --> 00:51:39,000
And when I do, it's going to go import math, result equals blah, and then return result.

634
00:51:39,000 --> 00:51:40,000
Do I want to do that?

635
00:51:40,000 --> 00:51:43,000
Yes, I do.

636
00:51:43,000 --> 00:51:45,000
And there it is.

637
00:51:45,000 --> 00:51:49,000
Now, there's one more step which we can optionally do.

638
00:51:49,000 --> 00:51:54,000
I mean, we've got the answer we wanted, but often we want the answer in more of a chat format.

639
00:51:54,000 --> 00:52:02,000
And so the way to do that is to, again, repeat everything that you've passed into so far.

640
00:52:02,000 --> 00:52:10,000
But then instead of adding an assistant role response, we have to provide a function role response

641
00:52:10,000 --> 00:52:16,000
and simply put in here the result we got back from the function.

642
00:52:16,000 --> 00:52:30,000
And if we do that, we now get the pros response 12 factorial is equal to 470 million 1,600.

643
00:52:30,000 --> 00:52:40,000
Now, functions like Python, you can still ask it about non Python things.

644
00:52:40,000 --> 00:52:44,000
And it just ignores it if you don't need it, right?

645
00:52:44,000 --> 00:52:57,000
So you can have a whole bunch of functions available that you've built to do whatever you need for the stuff which the language model isn't familiar with.

646
00:52:57,000 --> 00:53:09,000
And it'll still solve whatever it can on its own and use your tools, use your functions where possible.

647
00:53:09,000 --> 00:53:15,000
So we have built our own code interpreter from scratch.

648
00:53:15,000 --> 00:53:22,000
I think that's pretty amazing.

649
00:53:22,000 --> 00:53:32,000
So that is what you can do with or some of the stuff you can do with open AI.

650
00:53:32,000 --> 00:53:36,000
What about stuff that you can do on your own computer?

651
00:53:36,000 --> 00:53:45,000
Well, to use a language model on your own computer, you're going to need to use a GPU.

652
00:53:45,000 --> 00:53:50,000
So I guess the first thing to think about is like, do you want this?

653
00:53:50,000 --> 00:53:55,000
Does it make sense to do stuff on your own computer?

654
00:53:55,000 --> 00:53:58,000
What are the benefits?

655
00:53:58,000 --> 00:54:06,000
There are not any open source models that are as good yet as GPT-4.

656
00:54:06,000 --> 00:54:11,000
And I would have to say also like actually open AI pricing is really pretty good.

657
00:54:11,000 --> 00:54:19,000
So it's not immediately obvious that you definitely want to kind of go in-house, but there's lots of reasons you might want to.

658
00:54:19,000 --> 00:54:24,000
And we'll look at some examples of them today.

659
00:54:25,000 --> 00:54:34,000
One example you might want to go in-house is that you want to be able to ask questions about your proprietary documents

660
00:54:34,000 --> 00:54:39,000
or about information after September 2021, the knowledge cutoff.

661
00:54:39,000 --> 00:54:46,000
Or you might want to create your own model that's particularly good at solving the kinds of problems that you need to solve using fine tuning.

662
00:54:46,000 --> 00:54:57,000
And these are all things that you absolutely can get better than GPT-4 performance at work or at home without too much money or travel.

663
00:54:57,000 --> 00:55:00,000
So these are the situations in which you might want to go down this path.

664
00:55:00,000 --> 00:55:04,000
And so you don't necessarily have to buy a GPU.

665
00:55:04,000 --> 00:55:12,000
On Kaggle, they will give you a notebook with two quite old GPUs attached and very little RAM.

666
00:55:12,000 --> 00:55:14,000
But it's something.

667
00:55:14,000 --> 00:55:16,000
Or you can use Colab.

668
00:55:16,000 --> 00:55:28,000
And on Colab, you can get much better GPUs than Kaggle has and more RAM, particularly if you pay a monthly subscription fee.

669
00:55:28,000 --> 00:55:33,000
So those are some options for free or low cost.

670
00:55:33,000 --> 00:55:49,000
You can also, of course, go to one of the many GPU server providers and they change all the time as to what's good or what's not.

671
00:55:49,000 --> 00:55:52,000
RunPod is one example.

672
00:55:52,000 --> 00:56:02,000
And you can see if you want the biggest and best machine, you're talking $34 an hour, so it gets pretty expensive.

673
00:56:02,000 --> 00:56:07,000
But you can certainly get things a lot cheaper, $0.80 an hour.

674
00:56:07,000 --> 00:56:14,000
Lambda Labs is often pretty good.

675
00:56:14,000 --> 00:56:22,000
You know, it's really hard at the moment to actually find.

676
00:56:22,000 --> 00:56:25,000
Let's see, pricing to actually find people that have them available.

677
00:56:25,000 --> 00:56:32,000
So they've got lots listed here, but they often have none or very few available.

678
00:56:32,000 --> 00:56:46,000
There's also something pretty interesting called Vast AI, which basically lets you use other people's computers when they're not using them.

679
00:56:46,000 --> 00:56:55,000
And as you can see, you know, they tend to be much cheaper than other folks.

680
00:56:55,000 --> 00:56:58,000
And then they tend to have better availability as well.

681
00:56:58,000 --> 00:57:02,000
But of course, for sensitive stuff, you don't want to be running it on some Rando's computer.

682
00:57:02,000 --> 00:57:05,000
So anyway, so there's a few options for renting stuff.

683
00:57:05,000 --> 00:57:13,000
You know, I think it's, if you can, it's worth buying something and definitely the one to buy at the moment is the GTX 3090 used.

684
00:57:13,000 --> 00:57:19,000
You can generally get them from eBay for like 700 bucks or so.

685
00:57:19,000 --> 00:57:25,000
A 4090 isn't really better for language models, even though it's a newer GPU.

686
00:57:25,000 --> 00:57:30,000
The reason for that is that language models are all about memory speed.

687
00:57:30,000 --> 00:57:34,000
How quickly can you get in and stuff in and out of memory rather than how fast is the processor?

688
00:57:34,000 --> 00:57:37,000
And that hasn't really improved a whole lot.

689
00:57:37,000 --> 00:57:40,000
So the 2000 bucks.

690
00:57:40,000 --> 00:57:44,000
The other thing as well as memory speed is memory size 24 gigs.

691
00:57:44,000 --> 00:57:47,000
It doesn't quite cut it for a lot of things.

692
00:57:47,000 --> 00:57:49,000
So you'd probably want to get two of these GPUs.

693
00:57:49,000 --> 00:57:54,000
So you're talking like $1,500 or so.

694
00:57:54,000 --> 00:57:57,000
Or you can get a 48 gig gram GPU.

695
00:57:57,000 --> 00:57:59,000
It's called an A6000.

696
00:57:59,000 --> 00:58:03,000
But this is going to cost you more like five grand.

697
00:58:03,000 --> 00:58:08,000
So again, getting two of these is going to be a better deal.

698
00:58:08,000 --> 00:58:13,000
And this is not going to be faster than these either.

699
00:58:13,000 --> 00:58:20,000
Or funnily enough, you could just get a Mac with a lot of RAM, particularly if you get an M2 Ultra.

700
00:58:20,000 --> 00:58:26,000
Macs have, particularly the M2 Ultra has pretty fast memory.

701
00:58:26,000 --> 00:58:29,000
It's still going to be way slower than using an Nvidia card.

702
00:58:29,000 --> 00:58:37,000
But it's going to be like you're going to be able to get, you know, like I think 192 gig or something.

703
00:58:37,000 --> 00:58:43,000
So it's not a terrible option, particularly if you're not training models.

704
00:58:43,000 --> 00:58:51,000
You just want to use other existing trained models.

705
00:58:51,000 --> 00:58:58,000
So anyway, most people who do this stuff seriously, almost everybody has Nvidia cards.

706
00:58:59,000 --> 00:59:04,000
So then what we're going to be using is a library called Transformers from Hugging Face.

707
00:59:04,000 --> 00:59:14,000
And the reason for that is that basically people upload lots of pre-trained models or five trained models up to the Hugging Face Hub.

708
00:59:14,000 --> 00:59:20,000
And in fact, there's even a leaderboard where you can see which are the best models.

709
00:59:20,000 --> 00:59:27,000
Now, this is a really fraught area.

710
00:59:27,000 --> 00:59:30,000
So at the moment, this one is meant to be the best model.

711
00:59:30,000 --> 00:59:32,000
It has the highest average score.

712
00:59:32,000 --> 00:59:34,000
And maybe it is good.

713
00:59:34,000 --> 00:59:36,000
I haven't actually used this particular model.

714
00:59:36,000 --> 00:59:38,000
Or maybe it's not.

715
00:59:38,000 --> 00:59:49,000
I actually have no idea because the problem is these metrics are not particularly well aligned with real life usage.

716
00:59:50,000 --> 00:59:51,000
For all kinds of reasons.

717
00:59:51,000 --> 01:00:01,000
And also sometimes you get something called leakage, which means that sometimes some of the questions from these things actually leaks through to some of the training sets.

718
01:00:01,000 --> 01:00:09,000
So you can get as a rule of thumb what to use from here, but you should always try things.

719
01:00:09,000 --> 01:00:14,000
And you can also say, you know, these ones are all the 70B here that tells you how big it is.

720
01:00:14,000 --> 01:00:18,000
So this is a 70 billion parameter model.

721
01:00:19,000 --> 01:00:30,000
So generally speaking for the kinds of GPUs we're talking about, you'll be wanting no bigger than 13B and quite often 7B.

722
01:00:30,000 --> 01:00:37,000
So let's see if we can find here's a 13B model, for example.

723
01:00:37,000 --> 01:00:38,000
All right.

724
01:00:38,000 --> 01:00:44,000
So you can find models to try out from things like this leaderboard.

725
01:00:44,000 --> 01:00:58,000
And there's also a really great leaderboard called FastEval, which I like a lot because it focuses on some more sophisticated evaluation methods such as this chain of thought evaluation method.

726
01:00:58,000 --> 01:01:01,000
So I kind of trust these a little bit more.

727
01:01:01,000 --> 01:01:10,000
And these are also, you know, GSM 8K is a difficult math benchmark, big bench hard, so forth.

728
01:01:10,000 --> 01:01:11,000
So, yeah.

729
01:01:11,000 --> 01:01:17,000
So, you know, StableBlog2, WizardMeth, 13B, Dolphin, Lama, 13B, et cetera.

730
01:01:17,000 --> 01:01:22,000
These would all be good options.

731
01:01:22,000 --> 01:01:23,000
Yeah.

732
01:01:23,000 --> 01:01:24,000
So you need to pick a model.

733
01:01:24,000 --> 01:01:31,000
And at the moment, nearly all the good models are based on Meta's Lama 2.

734
01:01:31,000 --> 01:01:34,000
So when I say based on, what does that mean?

735
01:01:34,000 --> 01:01:40,000
Well, what that means is this model here, Lama 2, 7B.

736
01:01:40,000 --> 01:01:42,000
So it's a Lama model.

737
01:01:42,000 --> 01:01:44,000
That's just the name Meta called it.

738
01:01:44,000 --> 01:01:46,000
This is their version 2 of Lama.

739
01:01:46,000 --> 01:01:48,000
This is their 7 billion size one.

740
01:01:48,000 --> 01:01:50,000
It's the smallest one that they make.

741
01:01:50,000 --> 01:01:53,000
And specifically, these weights have been created for hugging face.

742
01:01:53,000 --> 01:01:56,000
So you can load it with the hugging face transformers.

743
01:01:56,000 --> 01:02:00,000
And this model has only got as far as here.

744
01:02:00,000 --> 01:02:02,000
It's done the language model for pre-training.

745
01:02:02,000 --> 01:02:09,000
It's done none of the instruction tuning and none of the RLHF.

746
01:02:09,000 --> 01:02:15,000
So we would need to fine tune it to really get it to do much useful.

747
01:02:15,000 --> 01:02:23,000
So we can just say, OK, create a, automatically create the appropriate model for language model.

748
01:02:23,000 --> 01:02:30,000
So causalLM is basically refers to that ULM fifth stage one process or stage two, in fact.

749
01:02:30,000 --> 01:02:33,000
Create the pre-trained model from this name.

750
01:02:33,000 --> 01:02:35,000
Meta Lama Lama 2, blah, blah, blah.

751
01:02:35,000 --> 01:02:36,000
OK.

752
01:02:36,000 --> 01:02:47,000
Now, generally speaking, we use 16 bit floating point numbers nowadays.

753
01:02:47,000 --> 01:02:52,000
But if you think about it, 16 bit is two bytes.

754
01:02:52,000 --> 01:02:58,000
So 7B times 2, it's going to be 14 gigabytes.

755
01:02:58,000 --> 01:03:01,000
Just to load in the weights.

756
01:03:01,000 --> 01:03:06,000
So you've got to have a decent model to be able to do that.

757
01:03:06,000 --> 01:03:10,000
Perhaps surprisingly, you can actually just cast it to 8 bit.

758
01:03:10,000 --> 01:03:14,000
And it still works pretty well, thanks to some encode discretization.

759
01:03:14,000 --> 01:03:17,000
So let's try that.

760
01:03:17,000 --> 01:03:19,000
So remember, this is just a language model.

761
01:03:19,000 --> 01:03:20,000
It can only complete sentences.

762
01:03:20,000 --> 01:03:23,000
We can't ask it a question and expect a great answer.

763
01:03:23,000 --> 01:03:27,000
So let's just give it the start of a sentence, Jeremy, how it is R.

764
01:03:27,000 --> 01:03:29,000
So we need the right tokenizer.

765
01:03:29,000 --> 01:03:32,000
So this will automatically create the right kind of tokenizer for this model.

766
01:03:32,000 --> 01:03:36,000
We can grab the tokens as PyTorch.

767
01:03:36,000 --> 01:03:41,000
Here they are.

768
01:03:41,000 --> 01:03:45,000
And just to confirm, if we decode them back again,

769
01:03:45,000 --> 01:03:50,000
we get the original plus a special token to say this is the start of a document.

770
01:03:50,000 --> 01:03:53,000
And so we can now call generate.

771
01:03:53,000 --> 01:03:59,000
So generate will auto regressively.

772
01:03:59,000 --> 01:04:01,000
So call the model again and again,

773
01:04:01,000 --> 01:04:08,000
passing its previous result back as the next input.

774
01:04:08,000 --> 01:04:11,000
And I'm just going to do that 15 times.

775
01:04:11,000 --> 01:04:14,000
So you can write this for loop yourself.

776
01:04:14,000 --> 01:04:15,000
This isn't doing anything fancy.

777
01:04:15,000 --> 01:04:18,000
In fact, I would recommend writing this yourself

778
01:04:18,000 --> 01:04:22,000
to make sure that you know how, that it all works OK.

779
01:04:23,000 --> 01:04:26,000
We have to put those tokens on the GPU.

780
01:04:26,000 --> 01:04:29,000
And at the end, I recommend putting them back onto the CPU, the result.

781
01:04:29,000 --> 01:04:31,000
And here are the tokens.

782
01:04:31,000 --> 01:04:32,000
Not very interesting.

783
01:04:32,000 --> 01:04:35,000
So we have to decode them using the tokenizer.

784
01:04:35,000 --> 01:04:39,000
And so the first 25, so first 15 tokens are Jeremy, how it is R.

785
01:04:39,000 --> 01:04:43,000
28 year old Australian AI researcher and entrepreneur.

786
01:04:43,000 --> 01:04:47,000
OK, well, 28 years old is not exactly correct, but we'll call it close enough.

787
01:04:47,000 --> 01:04:48,000
I like that.

788
01:04:48,000 --> 01:04:50,000
Thank you very much.

789
01:04:50,000 --> 01:04:52,000
Lama 7B.

790
01:04:52,000 --> 01:04:57,000
So OK, so we've got a language model completing sentences.

791
01:04:57,000 --> 01:05:02,000
It took one and a third seconds.

792
01:05:02,000 --> 01:05:06,000
And that's a bit slower than it could be because we used 8 bit.

793
01:05:06,000 --> 01:05:10,000
If we use 16 bit, there's a special thing called B float 16,

794
01:05:10,000 --> 01:05:14,000
which is a really great 16 bit floating point format

795
01:05:14,000 --> 01:05:19,000
that's usable on any somewhat recent GPU, Nvidia GPU.

796
01:05:19,000 --> 01:05:24,000
If we use it, it's going to take twice as much RAM as we discussed.

797
01:05:24,000 --> 01:05:26,000
But look at the time.

798
01:05:26,000 --> 01:05:31,000
It's come down to 390 milliseconds.

799
01:05:31,000 --> 01:05:35,000
Now, there is a better option still than even that.

800
01:05:35,000 --> 01:05:39,000
There's a different kind of discretization called GPTQ,

801
01:05:39,000 --> 01:05:46,000
where a model is carefully optimized to work with 4 or 8

802
01:05:46,000 --> 01:05:51,000
or other lower precision data automatically.

803
01:05:51,000 --> 01:05:57,000
And this particular person known as the bloke

804
01:05:57,000 --> 01:06:02,000
is fantastic at taking popular models, running that optimization process,

805
01:06:02,000 --> 01:06:07,000
and then uploading the results back to Hackingface.

806
01:06:07,000 --> 01:06:11,000
So we can use this GPTQ version.

807
01:06:11,000 --> 01:06:14,000
And internally, this is actually going to use,

808
01:06:14,000 --> 01:06:16,000
I'm not sure exactly how many bits this particular one is.

809
01:06:16,000 --> 01:06:18,000
I think it's probably going to be four bits,

810
01:06:18,000 --> 01:06:21,000
but it's going to be much more optimized.

811
01:06:21,000 --> 01:06:24,000
And so look at this, 270 milliseconds.

812
01:06:24,000 --> 01:06:29,000
It's actually faster than 16 bit.

813
01:06:29,000 --> 01:06:34,000
Even though internally, it's actually casting it up to 16 bit each layer to do it.

814
01:06:34,000 --> 01:06:38,000
And that's because there's a lot less memory moving around.

815
01:06:38,000 --> 01:06:43,000
And to confirm, in fact, what we could even do now is we could go up to 13D.

816
01:06:43,000 --> 01:06:44,000
Easy.

817
01:06:44,000 --> 01:06:47,000
And in fact, it's still faster than the 7B,

818
01:06:47,000 --> 01:06:49,000
now that we're using the GPTQ version.

819
01:06:49,000 --> 01:06:52,000
So this is a really helpful tip.

820
01:06:52,000 --> 01:06:55,000
So let's put all those things together, the tokenizer,

821
01:06:55,000 --> 01:06:58,000
the generate, the batch decode, we'll call this gen for generate.

822
01:06:58,000 --> 01:07:03,000
And so we can now use the 13B GPTQ model.

823
01:07:03,000 --> 01:07:08,000
And let's try this Jeremy Howard is a, so it's got to 50 tokens so fast.

824
01:07:08,000 --> 01:07:11,000
16 year veteran of Silicon Valley, co-founder of Kaggle,

825
01:07:11,000 --> 01:07:13,000
a Marketplace predictive model.

826
01:07:13,000 --> 01:07:16,000
His company Kaggle.com has become to data science competitions.

827
01:07:16,000 --> 01:07:19,000
What I don't know what I was going to say, but anyway, it's on the right track.

828
01:07:19,000 --> 01:07:25,000
I was actually there for 10 years, not 16, but that's all right.

829
01:07:25,000 --> 01:07:26,000
Okay.

830
01:07:26,000 --> 01:07:29,000
So this is looking good.

831
01:07:29,000 --> 01:07:34,000
But probably a lot of the time we're going to be interested in, you know,

832
01:07:34,000 --> 01:07:36,000
asking questions or using instructions.

833
01:07:36,000 --> 01:07:40,000
So stability AI has this nice series called stable beluga,

834
01:07:40,000 --> 01:07:44,000
including a small 7B one and other bigger ones.

835
01:07:44,000 --> 01:07:48,000
And these are all based on Lama two, but these have been instruction tuned.

836
01:07:48,000 --> 01:07:50,000
They might even have been RLHDF.

837
01:07:50,000 --> 01:07:52,000
I can't remember now.

838
01:07:52,000 --> 01:07:56,000
So we can create a stable beluga model.

839
01:07:56,000 --> 01:08:04,000
And now something really important that I keep forgetting everybody keeps forgetting is

840
01:08:04,000 --> 01:08:12,000
during the instruction tuning process,

841
01:08:12,000 --> 01:08:24,000
during the instruction tuning process, the instructions that are passed in actually are,

842
01:08:24,000 --> 01:08:26,000
they don't just appear like this.

843
01:08:26,000 --> 01:08:29,000
They actually always are in a particular format.

844
01:08:29,000 --> 01:08:35,000
And the format, believe it or not, changes quite a bit from fine-tuned to fine-tuned.

845
01:08:35,000 --> 01:08:47,000
And so you have to go to the webpage for the model and scroll down to find out what the prompt format is.

846
01:08:47,000 --> 01:08:49,000
So here's the prompt format.

847
01:08:49,000 --> 01:08:58,000
So I generally just copy it and then I paste it into Python, which I did here.

848
01:08:58,000 --> 01:09:08,000
And created a function called make prompt that used the exact same format that it said to you use.

849
01:09:08,000 --> 01:09:13,000
And so now if I want to say who is Jeremy Howard, I can call Jen again.

850
01:09:13,000 --> 01:09:20,000
That was that function I created up here and make the correct prompt from that question.

851
01:09:20,000 --> 01:09:22,000
And then it returns back.

852
01:09:22,000 --> 01:09:25,000
Okay, so you can see here all this prefix.

853
01:09:25,000 --> 01:09:27,000
This is a system instruction.

854
01:09:27,000 --> 01:09:29,000
This is my question.

855
01:09:29,000 --> 01:09:37,000
And then the assistant says, Jeremy Howard's an Australian entrepreneur, computer scientist, co-founder of machine learning and deep learning company, faster than AI.

856
01:09:37,000 --> 01:09:39,000
Okay, so this one's actually all correct.

857
01:09:39,000 --> 01:09:46,000
So it's getting better by using an actual instruction tune model.

858
01:09:46,000 --> 01:09:48,000
And so we could then start to scale up.

859
01:09:48,000 --> 01:09:50,000
So we could use the 13b.

860
01:09:50,000 --> 01:09:55,000
And in fact, we looked briefly at this open orca data set earlier.

861
01:09:55,000 --> 01:10:04,000
So llama two has been fine tuned on open orca and then also fine tuned on another really great data set called platypus.

862
01:10:04,000 --> 01:10:09,000
And so the whole thing together is the open orca platypus.

863
01:10:09,000 --> 01:10:11,000
And then this is going to be the bigger 13b.

864
01:10:11,000 --> 01:10:15,000
GPTQ means it's going to be quantized.

865
01:10:15,000 --> 01:10:18,000
So that's got a different format.

866
01:10:18,000 --> 01:10:20,000
Okay, a different prompt format.

867
01:10:20,000 --> 01:10:24,000
So again, we can scroll down and see what the prompt format is.

868
01:10:24,000 --> 01:10:26,000
There it is.

869
01:10:26,000 --> 01:10:27,000
Okay.

870
01:10:27,000 --> 01:10:37,000
And so we can create a function called make open orca prompt that has that prompt format.

871
01:10:37,000 --> 01:10:40,000
And so now we can say, okay, who is Jeremy Howard?

872
01:10:40,000 --> 01:10:42,000
And now I've become British, which is kind of true.

873
01:10:42,000 --> 01:10:45,000
I was born in England, but I moved to Australia.

874
01:10:45,000 --> 01:10:47,000
Professional poker player.

875
01:10:47,000 --> 01:10:48,000
Definitely not that.

876
01:10:48,000 --> 01:10:53,000
Co-founding several companies, including faster AI, also Kaggle.

877
01:10:53,000 --> 01:10:54,000
Okay.

878
01:10:54,000 --> 01:10:55,000
So not bad.

879
01:10:55,000 --> 01:10:59,000
It was acquired by Google with 2017, probably something around there.

880
01:10:59,000 --> 01:11:00,000
Okay.

881
01:11:00,000 --> 01:11:09,000
So you can see we've got our own models giving us some pretty good information.

882
01:11:09,000 --> 01:11:11,000
How do we make it even better?

883
01:11:11,000 --> 01:11:22,000
You know, because it's still hallucinating, you know, and, you know, llama two, I think,

884
01:11:22,000 --> 01:11:30,000
has been trained with more up to date information than GPT for it doesn't have the September 2021 cutoff.

885
01:11:30,000 --> 01:11:33,000
But it, you know, it's still got a knowledge cutoff.

886
01:11:33,000 --> 01:11:36,000
You know, we would like to be able to use the most up to date information.

887
01:11:36,000 --> 01:11:41,000
We want to use the right information to answer these questions as well as possible.

888
01:11:41,000 --> 01:11:46,000
So to do this, we can use something called retrieval augmented generation.

889
01:11:46,000 --> 01:11:57,000
So what happens with retrieval augmented generation is when we take the question we've been asked, like, who is Jeremy Houd?

890
01:11:57,000 --> 01:12:07,000
And then we say, okay, let's try and search for documents that may help us answer that question.

891
01:12:07,000 --> 01:12:12,000
So obviously we would expect, for example, Wikipedia to be useful.

892
01:12:12,000 --> 01:12:29,000
And then what we do is we say, okay, with that information, let's now see if we can tell the language model about what we found and then have it answer the question.

893
01:12:29,000 --> 01:12:30,000
So let me show you.

894
01:12:30,000 --> 01:12:36,000
So let's actually grab a Wikipedia Python package.

895
01:12:36,000 --> 01:12:42,000
We will scrape Wikipedia, grabbing the Jeremy Howard webpage.

896
01:12:42,000 --> 01:12:48,000
And so here's the start of the Jeremy Howard Wikipedia page.

897
01:12:48,000 --> 01:12:51,000
It has 613 words.

898
01:12:51,000 --> 01:12:57,000
Now, generally speaking, these open source models will have a context length of about 2000 or 4000.

899
01:12:57,000 --> 01:13:00,000
So the context length is how many tokens can it handle.

900
01:13:00,000 --> 01:13:01,000
So that's fine.

901
01:13:01,000 --> 01:13:03,000
It'll be able to handle this webpage.

902
01:13:03,000 --> 01:13:06,000
And what we're going to do is we're going to ask it the question.

903
01:13:06,000 --> 01:13:09,000
So we're going to have here question and with a question.

904
01:13:09,000 --> 01:13:12,000
But before that, we're going to say, answer the question with the help of the context.

905
01:13:12,000 --> 01:13:14,000
We're going to provide this to the language model.

906
01:13:14,000 --> 01:13:17,000
And we're going to say context and they're going to have the whole webpage.

907
01:13:17,000 --> 01:13:20,000
So suddenly now our question is going to be a lot bigger.

908
01:13:20,000 --> 01:13:23,000
They're prompt.

909
01:13:23,000 --> 01:13:24,000
Right.

910
01:13:24,000 --> 01:13:34,000
So our prompt now contains the entire webpage, the whole Wikipedia page, followed by a question.

911
01:13:34,000 --> 01:13:40,000
And so now it says Jeremy Howard is an Australian data scientist,

912
01:13:40,000 --> 01:13:43,000
entrepreneur, an educator, known for his work in deep learning,

913
01:13:43,000 --> 01:13:48,000
co-founder of FastAI, teaches courses, develops software, conducts research.

914
01:13:48,000 --> 01:13:51,000
Used to be, yeah, okay, it's perfect.

915
01:13:51,000 --> 01:13:54,000
So it's actually done a really good job.

916
01:13:54,000 --> 01:14:00,000
Like if somebody asked me to send them a, you know, 100 word bio,

917
01:14:00,000 --> 01:14:04,000
that would actually probably be better than I would have written myself.

918
01:14:04,000 --> 01:14:11,000
And just so even though I asked for 300 tokens, it actually got sent back the end of stream token.

919
01:14:11,000 --> 01:14:17,000
And so it knows to stop at this point.

920
01:14:17,000 --> 01:14:19,000
Well, that's all very well.

921
01:14:19,000 --> 01:14:23,000
But how do we know to pass in the Jeremy Howard Wikipedia page?

922
01:14:23,000 --> 01:14:33,000
Well, the way we know which Wikipedia page to pass in is that we can use another model to tell us which web page

923
01:14:33,000 --> 01:14:41,000
or which document is the most useful for answering a question.

924
01:14:41,000 --> 01:14:46,000
And the way we do that is we can use something called Sentence Transformer.

925
01:14:46,000 --> 01:14:52,000
And we can use a special kind of model that's specifically designed to take a document

926
01:14:52,000 --> 01:15:01,000
and turn it into a bunch of activations where two documents that are similar will have similar activations.

927
01:15:01,000 --> 01:15:03,000
So let me just, let me show you what I mean.

928
01:15:03,000 --> 01:15:09,000
What I'm going to do is I'm going to grab just the first paragraph of my Wikipedia page.

929
01:15:09,000 --> 01:15:14,000
And I'm going to grab the first paragraph of Tony Blair's Wikipedia page.

930
01:15:14,000 --> 01:15:17,000
Okay, so we're pretty different people, right?

931
01:15:17,000 --> 01:15:20,000
This is just like a really simple, small example.

932
01:15:20,000 --> 01:15:25,000
And I'm going to then call this model, I'm going to say encode,

933
01:15:25,000 --> 01:15:29,000
and I'm going to encode my Wikipedia first paragraph, Tony Blair's first paragraph,

934
01:15:29,000 --> 01:15:37,000
and the question, which was, who is Jeremy Howard?

935
01:15:37,000 --> 01:15:49,000
And it's going to pass back a 384 long vector of embeddings for the question for me and for Tony Blair.

936
01:15:49,000 --> 01:15:58,000
And what I can now do is I can calculate the similarity between the question and the Jeremy Howard Wikipedia page.

937
01:15:58,000 --> 01:16:03,000
And I can also do it for the question versus the Tony Blair Wikipedia page.

938
01:16:03,000 --> 01:16:06,000
And as you can see, it's higher for me.

939
01:16:06,000 --> 01:16:13,000
And so that tells you that if you're trying to figure out what document to use to help you answer this question,

940
01:16:13,000 --> 01:16:20,000
better off using the Jeremy Howard Wikipedia page than the Tony Blair Wikipedia page.

941
01:16:20,000 --> 01:16:29,000
So if you had a few hundred documents you were thinking of using to give back to the model as context to help it answer a question,

942
01:16:29,000 --> 01:16:37,000
you could literally just pass them all through to encode, go through each one at a time and see which is closest.

943
01:16:37,000 --> 01:16:44,000
When you've got thousands or millions of documents, you can use something called a vector database,

944
01:16:44,000 --> 01:16:51,000
where basically as a one-off thing, you go through and you encode all of your documents.

945
01:16:52,000 --> 01:16:57,000
And so in fact, there's lots of pre-built systems for this.

946
01:16:57,000 --> 01:17:02,000
Here's an example of one called H2O GPT.

947
01:17:02,000 --> 01:17:12,000
And this is just something that I've got running here on my computer.

948
01:17:12,000 --> 01:17:18,000
It's just an open source thing written in Python and sitting here running on port 7860.

949
01:17:18,000 --> 01:17:22,000
And so I've just gone to localhost 7860.

950
01:17:22,000 --> 01:17:30,000
And what I did was I just uploaded, I just clicked upload and uploaded a bunch of papers.

951
01:17:30,000 --> 01:17:32,000
In fact, I might be able to see it better.

952
01:17:32,000 --> 01:17:35,000
Yeah, here we go, a bunch of papers.

953
01:17:35,000 --> 01:17:42,000
And so we could look at, can we search?

954
01:17:42,000 --> 01:17:43,000
Yeah, I can.

955
01:17:43,000 --> 01:17:48,000
So for example, we can look at the ULM fit paper that Sir Bruder and I did.

956
01:17:48,000 --> 01:17:55,000
And you can see it's taken the PDF and turned it into slightly crappily, a text format.

957
01:17:55,000 --> 01:18:02,000
And then it's created an embedding for each section.

958
01:18:02,000 --> 01:18:11,000
So I could then ask it, you know, what is ULM fit?

959
01:18:11,000 --> 01:18:15,000
And I'll hit enter.

960
01:18:15,000 --> 01:18:18,000
And you can see here it's now actually saying based on the information provided in the context.

961
01:18:18,000 --> 01:18:21,000
So it's showing us it's been given some context.

962
01:18:21,000 --> 01:18:22,000
What context did it get?

963
01:18:22,000 --> 01:18:27,000
So here are the things that it found, right?

964
01:18:27,000 --> 01:18:31,000
So it's being sent this context.

965
01:18:31,000 --> 01:18:36,000
So this is kind of citations.

966
01:18:36,000 --> 01:18:46,000
A goal of ULM fit proves a performance by leveraging the knowledge and adapting it to the specific task at hand.

967
01:18:46,000 --> 01:18:50,000
Now, what techniques be more specific?

968
01:18:50,000 --> 01:18:55,000
Does ULM fit?

969
01:18:55,000 --> 01:19:00,000
Let's see how it goes.

970
01:19:00,000 --> 01:19:02,000
Okay, there we go.

971
01:19:02,000 --> 01:19:05,000
So here's the three steps, pre-trained, fine-tuned, fine-tuned.

972
01:19:05,000 --> 01:19:06,000
Cool.

973
01:19:06,000 --> 01:19:09,000
So you can see it's not bad, right?

974
01:19:09,000 --> 01:19:12,000
It's not amazing.

975
01:19:12,000 --> 01:19:17,000
Like, you know, the context in this particular case is pretty small.

976
01:19:17,000 --> 01:19:25,000
And in particular, if you think about how that embedding thing worked, you can't really use like the normal kind of follow-up.

977
01:19:25,000 --> 01:19:36,000
So for example, if I say it says fine-tuning a classifier, so I could say what classifier is used.

978
01:19:36,000 --> 01:19:41,000
Now, the problem is that there's no context here being sent to the embedding model.

979
01:19:41,000 --> 01:19:44,000
So it's actually going to have no idea I'm talking about ULM fit.

980
01:19:44,000 --> 01:19:48,000
So generally speaking, it's going to do a terrible job.

981
01:19:48,000 --> 01:19:51,000
Yeah, see, it says used as a Roberta model, but it's not.

982
01:19:51,000 --> 01:19:56,000
But if I look at the sources, it's no longer actually referring to Howard and Ruder.

983
01:19:56,000 --> 01:19:59,000
So anyway, you can see the basic idea.

984
01:19:59,000 --> 01:20:05,000
This is called retrieval augmented generation, R-A-G.

985
01:20:05,000 --> 01:20:12,000
And it's a nifty approach, but you have to do it with some care.

986
01:20:12,000 --> 01:20:18,000
And so there are lots of these private GPT things out there.

987
01:20:18,000 --> 01:20:29,000
And actually the H2O GPT web page is a fantastic job of listing lots of them and comparing.

988
01:20:29,000 --> 01:20:39,000
So as you can see, if you want to run a private GPT, there's no shortage of options.

989
01:20:39,000 --> 01:20:42,000
And you can have your retrieval augmented generation.

990
01:20:42,000 --> 01:20:45,000
I haven't tried, I've only tried this one H2O GPT.

991
01:20:45,000 --> 01:20:49,000
I don't love it. It's all right.

992
01:20:49,000 --> 01:20:58,000
So finally, I want to talk about what's perhaps the most interesting option we have, which is to do our own fine tuning.

993
01:20:58,000 --> 01:21:03,000
And fine tuning is cool because rather than just retrieving documents which might have useful context,

994
01:21:03,000 --> 01:21:10,000
we can actually change our model to behave based on the documents that we have available.

995
01:21:10,000 --> 01:21:14,000
I'm going to show you a really interesting example of fine tuning here.

996
01:21:14,000 --> 01:21:21,000
What we're going to do is we're going to fine tune using this no SQL data set.

997
01:21:21,000 --> 01:21:32,000
And it's got examples of like a schema for a table in a database, a question,

998
01:21:32,000 --> 01:21:44,000
and then the answer is the correct SQL to solve that question using that database schema.

999
01:21:44,000 --> 01:21:50,000
And so I'm hoping we could use this to create a, you know,

1000
01:21:50,000 --> 01:21:56,000
it could be a handy tool for business users where they type some English question

1001
01:21:56,000 --> 01:22:01,000
and SQL generated for them automatically.

1002
01:22:01,000 --> 01:22:06,000
Don't know if it actually work in practice or not, but this is just a little fun idea.

1003
01:22:06,000 --> 01:22:08,000
I thought we'd try out.

1004
01:22:08,000 --> 01:22:14,000
I know there's lots of startups and stuff out there trying to do this more seriously.

1005
01:22:14,000 --> 01:22:20,000
But this is, this is quite cool because it actually got it working today in just a couple of hours.

1006
01:22:20,000 --> 01:22:27,000
So what we do is we use the hugging face data sets library.

1007
01:22:27,000 --> 01:22:32,000
And what that does, just like the hugging face hub has lots of models stored on it,

1008
01:22:32,000 --> 01:22:36,000
hugging face data sets has lots of data sets stored on it.

1009
01:22:36,000 --> 01:22:40,000
And so instead of using transformers, which is what we use to grab models,

1010
01:22:40,000 --> 01:22:48,000
we use data sets and we just pass in the name of the person and the name of their repo and it grabs the data set.

1011
01:22:48,000 --> 01:22:55,000
And so we can take a look at it and it just has a training set with features.

1012
01:22:55,000 --> 01:23:02,000
And so then I can have a look at the training set.

1013
01:23:02,000 --> 01:23:07,000
So here's an example, which looks a bit like what we've just seen.

1014
01:23:07,000 --> 01:23:12,000
So what we do now is we want to fine tune a model.

1015
01:23:12,000 --> 01:23:17,000
So we can do that in in a notebook from scratch takes, I don't know,

1016
01:23:17,000 --> 01:23:20,000
a hundred or so lines of code is not too much.

1017
01:23:20,000 --> 01:23:24,000
But given the time constraints here and also like I thought, why not?

1018
01:23:24,000 --> 01:23:27,000
Why don't we just use something that's ready to go?

1019
01:23:27,000 --> 01:23:34,000
So for example, there's something called axolotl, which is quite nice in my opinion.

1020
01:23:34,000 --> 01:23:35,000
Here it is here.

1021
01:23:35,000 --> 01:23:38,000
Another very nice open source piece of software.

1022
01:23:38,000 --> 01:23:41,000
And again, you can just pip install it.

1023
01:23:41,000 --> 01:23:47,000
And it's got things like GPTQ and 16 bit and so forth ready to go.

1024
01:23:47,000 --> 01:23:58,000
And so what I did was I it basically has a whole bunch of examples of things that it already knows how to do.

1025
01:23:58,000 --> 01:24:00,000
It's got llama to example.

1026
01:24:00,000 --> 01:24:05,000
So I copied the llama to example and I created a SQL example.

1027
01:24:05,000 --> 01:24:09,000
So basically just told it, this is the path to the data set that I want.

1028
01:24:09,000 --> 01:24:16,000
This is the type and everything else pretty much I left the same.

1029
01:24:16,000 --> 01:24:20,000
And then I just ran this command, which is from there.

1030
01:24:20,000 --> 01:24:24,000
Read me accelerate launch axolotl passed in my YAML.

1031
01:24:24,000 --> 01:24:28,000
And that took about an hour on my GPU.

1032
01:24:28,000 --> 01:24:35,000
And at the end of the hour, it had created a QLaura out directory.

1033
01:24:35,000 --> 01:24:37,000
Q stands for quantize.

1034
01:24:37,000 --> 01:24:39,000
It's because I was creating a smaller quantized model.

1035
01:24:39,000 --> 01:24:53,000
Laura, I'm not going to talk about today, but Laura is a very cool thing that basically another thing that makes your models smaller and also handles can use bigger models on smaller GPUs for training.

1036
01:24:54,000 --> 01:24:58,000
So I trained it.

1037
01:24:58,000 --> 01:25:04,000
And then I thought, okay, let's create our own one.

1038
01:25:04,000 --> 01:25:18,000
So we're going to have this context and this question get the count of competition hosts by theme.

1039
01:25:18,000 --> 01:25:20,000
And I'm not going to pass it an answer.

1040
01:25:20,000 --> 01:25:22,000
So I'll just ignore that.

1041
01:25:22,000 --> 01:25:31,000
So again, I found out what prompt they were using and created a SQL prompt function.

1042
01:25:31,000 --> 01:25:33,000
And so here's what I'm going to do.

1043
01:25:33,000 --> 01:25:38,000
Use the following contextual information to answer the question context create table.

1044
01:25:38,000 --> 01:25:44,000
So there's the context question list or competition hosts sorted in ascending order.

1045
01:25:44,000 --> 01:25:52,000
And then I tokenized that called generate.

1046
01:25:52,000 --> 01:26:00,000
And the answer was select count hosts comma theme from farm competition group by theme.

1047
01:26:00,000 --> 01:26:02,000
That is correct.

1048
01:26:02,000 --> 01:26:05,000
So I think that's pretty remarkable.

1049
01:26:05,000 --> 01:26:15,000
We have just built, you know, so it took me like an hour to figure out how to do it and then an hour to actually do the training.

1050
01:26:15,000 --> 01:26:25,000
And at the end of that, we've actually got something which, which is converting pros into SQL based on a schema.

1051
01:26:25,000 --> 01:26:29,000
So I think that's, that's a really exciting idea.

1052
01:26:29,000 --> 01:26:36,000
The only other thing I do want to briefly mention is, is doing stuff on max.

1053
01:26:36,000 --> 01:26:42,000
If you've got a Mac, you, there's a couple of really good options.

1054
01:26:42,000 --> 01:26:48,000
The options are MLC and llama dot CPP currently MLC in particular.

1055
01:26:48,000 --> 01:26:50,000
I think it's kind of underappreciated.

1056
01:26:50,000 --> 01:27:08,000
It's a really nice project where you can run language models on literally iPhone, Android, web browsers, everything.

1057
01:27:08,000 --> 01:27:10,000
It's really cool.

1058
01:27:10,000 --> 01:27:17,000
And, and so I'm now actually on my Mac here.

1059
01:27:17,000 --> 01:27:24,000
And I've got a tiny little Python program called chat.

1060
01:27:24,000 --> 01:27:35,000
And it's going to import chat module and it's going to import a discretized seven B.

1061
01:27:35,000 --> 01:27:40,000
And that's going to ask the question, what is the meaning of life?

1062
01:27:40,000 --> 01:27:42,000
So let's try it.

1063
01:27:42,000 --> 01:27:44,000
Python chat.py.

1064
01:27:44,000 --> 01:27:48,000
And again, I just installed this earlier today.

1065
01:27:48,000 --> 01:27:58,000
I haven't done that much stuff on max before, but I was pretty impressed to see that it is doing a good job here.

1066
01:27:58,000 --> 01:28:03,000
What is the meaning of life is complex and philosophical.

1067
01:28:03,000 --> 01:28:07,000
Some people might find meaning in their relationships with others.

1068
01:28:07,000 --> 01:28:10,000
They're impacting the world, et cetera, et cetera.

1069
01:28:10,000 --> 01:28:11,000
Okay.

1070
01:28:11,000 --> 01:28:15,000
And it's doing 9.6 tokens per second.

1071
01:28:15,000 --> 01:28:16,000
So there you go.

1072
01:28:16,000 --> 01:28:19,000
So there is running a model on a Mac.

1073
01:28:19,000 --> 01:28:24,000
And then another option that you've probably heard about is llama dot CPP.

1074
01:28:24,000 --> 01:28:32,000
Llama dot CPP runs on lots of different things as well, including Max and also on CUDA.

1075
01:28:32,000 --> 01:28:36,000
It uses a different format called gguf.

1076
01:28:36,000 --> 01:28:38,000
And again, you can use it from Python.

1077
01:28:38,000 --> 01:28:41,000
Even though that was a CPP thing, it's got a Python wrapper.

1078
01:28:41,000 --> 01:28:49,000
So you can just download, again, from Huggingface, a gguf file.

1079
01:28:49,000 --> 01:28:52,000
So you can just go through and there's lots of different ones.

1080
01:28:52,000 --> 01:28:54,000
They're all documented as to what's what.

1081
01:28:54,000 --> 01:28:56,000
You can pick how big a file you want.

1082
01:28:56,000 --> 01:28:58,000
You can download it.

1083
01:28:58,000 --> 01:29:03,000
And then you just say, okay, llama model path equals passing that gguf file.

1084
01:29:03,000 --> 01:29:07,000
It spits out lots and lots and lots of gunk.

1085
01:29:07,000 --> 01:29:10,000
And then you can say, okay.

1086
01:29:10,000 --> 01:29:13,000
So if I called that LLM, you can then say LLM question.

1087
01:29:13,000 --> 01:29:17,000
Name the planets of the solar system, 32 tokens.

1088
01:29:17,000 --> 01:29:21,000
And there we go.

1089
01:29:21,000 --> 01:29:22,000
Run Pluto.

1090
01:29:22,000 --> 01:29:23,000
No longer considered a planet.

1091
01:29:23,000 --> 01:29:26,000
Two, Mercury, three, Venus, four, Earth, Mars, six.

1092
01:29:26,000 --> 01:29:28,000
Oh, no, right out of tokens.

1093
01:29:28,000 --> 01:29:32,000
So again, you know, it's just to show you here.

1094
01:29:32,000 --> 01:29:37,000
There are all these different options.

1095
01:29:37,000 --> 01:29:42,000
You know, I would say, you know, if you've got a NVIDIA graphics card

1096
01:29:42,000 --> 01:29:45,000
and you're a reasonably capable Python programmer,

1097
01:29:45,000 --> 01:29:52,000
you probably be one of you use PyTorch and the Huggingface ecosystem.

1098
01:29:52,000 --> 01:29:55,000
But, you know, I think, you know, these things might change over time as well.

1099
01:29:55,000 --> 01:29:58,000
And certainly a lot of stuff is coming into Llama pretty quickly now

1100
01:29:58,000 --> 01:30:00,000
and it's developing very fast.

1101
01:30:00,000 --> 01:30:04,000
As you can see, there's a lot of stuff that you can do right now

1102
01:30:04,000 --> 01:30:09,000
with language models, particularly if you feel pretty comfortable

1103
01:30:09,000 --> 01:30:12,000
as a Python programmer.

1104
01:30:12,000 --> 01:30:14,000
I think it's a really exciting time to get involved.

1105
01:30:14,000 --> 01:30:17,000
In some ways, it's a frustrating time to get involved

1106
01:30:17,000 --> 01:30:23,000
because, you know, it's very early

1107
01:30:23,000 --> 01:30:27,000
and a lot of stuff has weird little edge cases

1108
01:30:27,000 --> 01:30:32,000
and it's tricky to install and stuff like that.

1109
01:30:32,000 --> 01:30:34,000
There's a lot of great Discord channels.

1110
01:30:34,000 --> 01:30:36,000
However, FastAI have our own Discord channel,

1111
01:30:36,000 --> 01:30:40,000
so feel free to just Google for FastAI Discord and drop in.

1112
01:30:40,000 --> 01:30:42,000
We've got a channel called Generative.

1113
01:30:42,000 --> 01:30:48,000
You feel free to ask any questions or tell us about what you're finding.

1114
01:30:48,000 --> 01:30:50,000
Yeah, it's definitely something where you want to be getting help

1115
01:30:50,000 --> 01:30:54,000
from other people on this journey because it is very early days.

1116
01:30:54,000 --> 01:30:58,000
And, you know, people are still figuring things out as we go.

1117
01:30:58,000 --> 01:31:01,000
But I think it's an exciting time to be doing this stuff

1118
01:31:01,000 --> 01:31:03,000
and I'm really enjoying it.

1119
01:31:03,000 --> 01:31:07,000
And I hope that this has given some of you a useful starting point

1120
01:31:07,000 --> 01:31:09,000
on your own journey.

1121
01:31:09,000 --> 01:31:10,000
So I hope you found this useful.

1122
01:31:10,000 --> 01:31:11,000
Thanks for listening.

1123
01:31:11,000 --> 01:31:12,000
Bye.

