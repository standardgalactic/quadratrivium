Processing Overview for Brendan Shanahan
============================
Checking Brendan Shanahan/Bayesian Neural Networks.txt
1. **Regression Experiment with Bayesian Network vs. Plane Network**:
   - Both networks were trained on a synthetic dataset with three input features and one output feature.
   - The variance in the predictions of the plane network is constant and low, which does not capture the uncertainty well, especially in regions of the test base that are further from the training set.
   - In contrast, the Bayesian network captures the variance present in the training data effectively. Its predictions show increasing variance in regions of the output space that were not well-represented in the training set, reflecting the uncertainty due to lack of training data in those areas.

2. **Image Classification Experiment on MNIST Dataset**:
   - A Bayesian convolutional neural network (CNN) with three convolutional layers, two cooling (sub-sampling) layers, and two fully connected layers was trained on the MNIST dataset containing 60,000 images of handwritten digits.
   - At various stages of training (10th, 100th, 500th, and 3000th step), 10 images from the validation set were classified 50 times each to sample from the network's posterior distribution.
   - Initially, there was high variance in the predictions due to random initialization of parameters, with probability masses distributed across multiple classes for many images.
   - As training progressed, the network's performance improved, with a decrease in posterior variance and an increase in accuracy. By the end of training, the network achieved a 95.3% classification accuracy on the test set with almost zero variance in its predictions for most images, indicating full convergence.

**Key Takeaways**:
- Bayesian neural networks can provide measures of uncertainty in their predictions, which is valuable when confidence intervals are needed or when dealing with novel, unseen data.
- Both experiments demonstrate that incorporating Bayesian methods into neural networks allows for the expression and capture of model uncertainty.
- The presented Bayesian regression and image classification models show a clear reduction in uncertainty as they learn from the training data, and they exhibit appropriate levels of variance in their predictions, especially in regions with sparse or no training data.

**References**: All works cited in the presentation are listed at the end, providing the source material for the experiments and methodologies discussed. The presentation concludes by thanking the audience for their time and attention to these demonstrations of Bayesian neural networks in action.

