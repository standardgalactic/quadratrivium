{"text": " Good afternoon everyone. Welcome back to room 305. I see how we are full as normal. If you guys can try to get into the middle to find a seat, you know, fire code and stuff like that, that would be very, very much appreciated. This is the last talk in our Geophysics, Geology and Atmospheric Sciences session, and it goes to Addison. And how do you pronounce your last name, Addison? I'm going to leave that one with him and not even attempt it, who's going to talk about interactive super computing with Jupiter and Dask. Thank you very much, Addison. Thank you, Scott. Great. Thank you for having me here. This is my first sci-pi, so I'm very excited to be here. So as Scott said, so my name is Anderson, I work as a software engineer at the National Center for Atmospheric Research. So for those who are interested, the slides available address. So this is a talk about Python tools that enable interactive super computing, and we're going to see what we mean by super computing in a minute. Okay, so this is Alice, and Alice is a project scientist at NCAR. She studies the transfer of water and energy between the land surface and the lower atmosphere. And on the other side, we have a cool notebook of how work. There are three things that are really interesting about this notebook. So the first thing is that this notebook is not running on her computer. So this is running on a supercomputer. In this case, this is Cheyenne. And as you can see, there's an address to a Jupiter hub running on the Cheyenne supercomputer. The second thing is that she's using hundreds of processes and terabytes of memory. All this is distributed computing resources. Thanks to desktop queue. We're going to talk about that as well. And the third thing is she's actually doing science. So this is not a toy example, so which is what she's good at. So now we're going to talk about how we at NCAR enable Alice and folks like her to do interactive supercomputing. So what do we mean by supercomputing? First, MPI, batch processing, lots of heavy machines that most of people don't have access to as admins. So you have to talk to people to be able to install some of the software. In the picture, so this is Cheyenne, which is a supercomputer operated by NCAR. If you're ever in Cheyenne, Wyoming, feel free to stop by. They give free tours of the facility if you want to. And what do we mean by interactive supercomputing? So with the current growth in data creation, both through new simulations and new observations, there's a growing need to have a more human in the loop workflow where people can rapidly prototype and iterate through the data with tools like Jupyter notebooks. There's also a need to do things like in situ data analytics. So instead of having to run the simulations and output the data, you could actually run the simulation and do the analysis at the same time. And the other thing is actually adaptive scaling of computing resources. So this combination would really be powerful, but it's really hard for different reasons. So some of these reasons are cultural and others are technical. So the first one is that HP systems tends to be unique. So every HPC center has its own policies when it comes to things like security, what can you run on the supercomputer. And the second point is the tension between interactivity and machine utilization. So when it comes to HPC systems, HP center stands to be measured according to how often the machine is actually utilized. And when you're talking about things like interactivity, users want to have resources on demand whenever they want them. But because HP system operate on batch Q systems, it's not that easy to actually get resources whenever you want to. So no user is going to wait for five hours to get into the queue to do interactive data analysis. And the third point is the lack of elastic scaling. And this is a huge, at least in my opinion, I think this is a huge disadvantage in that if someone, let's say, want to do some analysis, they have to take time and actually think about how much resources they want before they even do the analysis. And what ends up happening is that you get into your work, maybe five minutes later, you probably take like 20 minutes thinking, what do I do next? And during that time, the resources are just idle. So it would be nice if you could actually scale down later that people use those resources and get them back whenever you actually need to. The good news is that, despite all those challenges, there's a growing list of technologies or tools that try to help with interactive supercomputing. And I'm going to talk about some of these tools. The first one is Trubiter. So we all love and use Trubiter. And so I'm not really going to spend much time on it because now everybody is familiar with it. And some of you may be wondering, but isn't Trubiter already usable on HP systems? And the answer is actually, yes, but you have to go through all these steps. You have to essentially tune the machine. You have to set up SSH tunnels. And you have to do this every single time that you want to actually use the Trubiter notebook on the supercomputer. And this can actually be tedious, especially for new users. So what is missing? So one of the things that is actually missing is the multi-user support. So all those steps, everybody has to go through them individually. And it would be nice if there was one single place that everybody goes to and everything is done for them. Another thing is actually the lack of pure web access to HPC resources. Because as you've seen, we're setting up SSH tunnel, which if you ever need to use another process that probably runs on a different port, so you also have to SSH to create a tunnel for that port as well. Well, then Trubiter Hub comes to the rescue. So one good thing about Trubiter Hub is that, in a way, it provides a standard way of managing authentication. So one of the issues that is not really hard to convince sysadmins about is the security of web applications. But Trubiter Hub makes it easy in that it doesn't really force you to use any type of authentication. It's up to you to choose what you want to use for authentication. In this case, on the supercomputer, you have different types of authentications. And another thing is that Trubiter Hub will just take care of spawning the Trubiter notebook single server and giving access to the user on demand. And so let's now switch gears and actually see how this works in practice. So I will skip these few slides and actually go to the live demo. So the first thing that you do as a user, so you just go to Trubiter Hub.ucr.edu. And so this is what you presented. And if you've used the Trubiter Hub before, this looks familiar. The only difference is that in this case, I have to use the same authentication that I used to SSH into the machine. So in my case, I just provide my username. And then for the password, it's a combination of a PIN number and a UB key token. So now, so now I'm authenticated. So I then get this page, which basically asked me for the project account. So this is the allocation on the supercomputer so that they know who to charge for this usage. So in this case, I'm going to provide when to change the queue here and specify the project and maybe just reduce the wall time. And then once this is done, I just click on spawn. And what this is doing in the background, it's basically submitting a job to the queuing system. And once the Trubiter Notebook server is ready, I will get redirected to this new page. And at this point, thank you. So at this point, you have the same interface as what you would have on your laptop. So I can run notebooks, in this case, to show you that I'm not really lying. So you could just run this notebook, which is backed by Bashkarno. And as you can see, I don't really have 200 terabytes of storage on this computer. So that's it about Trubiter Hubs. I'll come back to it later. So the next tool is Dask. Is there anybody in this room who is not familiar with Dask at this point? Okay, a few people. So at this point, most of us are familiar with Dask. We've probably interacted with it in the cloud or even on our local machines. So I'm not really going to spend any more time talking about Dask. The one key point that I'm going to focus on is how to deploy Dask on HPC systems. And this is where Dask JobQ comes in. So Dask JobQ is a Python library that allows you to easily deploy Dask on JobQ systems, such as PBS or Slurm, and so many other. It was created as a spin of the Panjio project. It provides a high-level Python user interface to manage Dask clusters and Dask workers. So for instance, if you're like on a system that uses PBS as the queuing system, so this is what you have to do. So from Dask JobQ, import the PBS cluster class, and then instantiate that class with things like the project account, the queue, and all other resources that you want. And I should be clear that I'm not really defining everything that I want in my cluster. At this point, I'm just telling Dask a configuration of what to ask to the queuing system every time that I want computing resources. So in this case, I'm saying every time they just submit, just in this single job, submit, ask for one process and one thread and 100 gigabytes of memory. And once that is done, you can minority scale it by basically saying just scale to 10 nodes, in this case, that corresponds to 10 Dask workers. Or you could actually tell it to scale adaptively by saying, okay, I want you to, at all time, to have a minimum of one Dask worker, and you can scale between one and 100 Dask workers. And Dask will basically monitor your usage of your CPU usage or your memory usage, and then it will know that it should get more resources. And at any point, if you're not using those resources, it will just tell the queuing system to kill those jobs. So if you're on a system that uses SLRM instead of PBS, it's the exact same thing with only one difference of just using the SLRM cluster instead. Okay, so now let's go back to Tributor and actually see what Alice is actually doing in that notebook. Okay, so there's so much science going on in these notebooks, I won't really spend so much time going through the details about it. But if you're interested, there's a copy of this notebook that you can actually run in the cloud. It's actually exact same copy. So if you go to the Panjio data GitHub organization and just go to the Panjio tutorial, you should see one of these notebooks there. But I'm going to focus on a particular data set here, which is the grid ensemble precipitation and temperature estimates over the contiguous United States. So this consists of 100 ensemble members for precipitation and temperature data. So the first thing that I do, I input some packages. Is this better? Okay, good. So the next thing that I do, I now create my cluster object by telling that job queue that I want 109 gigabytes of memory, 36 threads and 36 processes, specify the queue and the wall time. And I tell Dask to scale between 360 Dask workers. And I don't know what that is, but you get just so. And when I click on this, as you can see, at this point, Dask is submitting a bunch of, Dask job queue, submitting a bunch of jobs to the queuing system. And now I'm not trying to get into workers. So as you can see, I have thrown a 60 workers as I specified. Let me bring up the dashboard here. Okay, let me one more thing. Okay. So now, now I can actually start doing the computation. So but the first thing I'm going to do is actually connect my client to the remote workers. So I have a cluster with 100 with one terabyte of memory and 360 workers. So the dataset is saved in stored as in ZAR format. So there was a talk two days ago about ZAR. If you've never had about ZAR, recommend to go and check it out. And I use XR8 to open this ZAR store. Again, just took 187 milliseconds. I didn't really do anything other than just looking at the metadata. So we can look at the size of the dataset. It's close to 1.7 terabyte. Can look at some metadata. So we have precipitation as one of our variable, the mean temperature and the temperature range. And these are all 40 variables. So 100 ensemble members for these many days, which corresponds to close to 40 years, I think, of data. And if you wanted to, you could actually look at the Dask array. If you actually wanted to look at the shape and things like that, if this is more useful to you. So the first thing I'm going to do is actually just do a quick plot for the elevation. This is basically a mask that tells me the elevation for each of the grid points. And as you can see, towards the west coast, you have points with higher elevation compared to the east coast of the country. So let's now try to quantify the ensemble uncertainty for a single day. So just select the data for one day and try to quantify the uncertainty for that one day. Again, this just goes very fast. Nothing really happened there other than just that Dask constructed the task graph. And when I do the plotting, that's when actually the computation gets triggered. Then I have my plot here. And again, I won't go into the details about the science. So the next task, let's try to compute the intra ensemble range. Again, as you can see, this just returns quickly. But this is actually a delayed operation or a lazy operation. And now I can actually tell Dask to do the computation. So now you can actually start seeing some activity here. This should be done anytime soon. Okay, so this has to do with Dask resiliency in that if, for instance, Dask tries to do a computation and it fails, it would start marking that computation. And I think by default, if it tries three times and hasn't actually been able to successfully complete that computation, Dask would just give up on that particular computation. So you could actually specify how many times you want Dask to try. Like, for instance, if a task was scheduled on a worker and the worker dies, what to do? Or if you run out of memory or things like that. So this is basically a cool feature of Dask, the resilience of Dask. So the computation finished. We can actually do some plotting here. Okay, again, not that many details about science. So the next task is let's try to compute the average seasonal fall, a snowfall. In this case, we're actually just computing on only four ensemble members. So if you go through the distributed documentation, there's a really cool information about how to interpret the dashboard here, the information about the dashboard. So this is done. Now we can do the plotting. It's going to take a few seconds. And as you can see, so as the year progresses, so the amount of snowfall decreases. And I think this is in the summer, you don't even have any at all in most part of the country. And this is consistent across the four ensemble members that we're looking at. So let's now actually do something cool. Let's actually look at like a specific region. In this case, let's just look at all the grid points near Austin. So XRA is really cool in that you can just give it the coordinates of the points you're interested in. In this case, we provide a buffer so that we can actually get all the grid points in that range. And we're going to compute the maximum precipitation near Austin for the last 40 years. So it's going to take a few seconds. And then we can do the plotting once this is done. So again, we can look at our cluster object. I still have 360 workers. I could have started with something really small, but it's just that I wanted this to go really fast. And you never know how busy the queuing system is going to be. So if you need the resources, you get them when you can. Okay, so this should be done. And basically, so this is the maximum precipitation near Austin, Texas for the 100 ensemble members for the last 40 years. So you could basically look at what that looked like. So yeah, so at this point, if I basically don't do anything, because I told us that I want a minimum of 360 workers, it would just keep those resources. But instead, you could actually now that I'm done with this, I can actually do let me just tell it to scale down to this. And basically, what that's going to do is going to start monitoring the workers. And if I'm not using them, we'll just take them away. So I will come back to this later to show you what I mean by that. Okay, so, so we've seen, or at least I try to demonstrate the adaptive or the elastic scaling and the resiliency of dusk. And let's now talk about some of the challenges. So being able to know how much resources you need before actually doing the computation is really hard. And they actually requires quite a lot of experimentation. And if you actually get to know how to do this for one particular workflow, it probably changes once you move to a different dataset. So, and another thing is that the computation, the computational workloads, they don't really are not really constant. So you probably started with one terabyte of data. Five minutes later, you probably only have one gig of data left. At that point, you don't really need all the resources that you started with when you when you're dealing with one terabyte of data. So the good thing is that dusk thinks about these things. So how to scale up and down, how to be resilient in case like a worker dies, and what if when you get new workers, what to do in terms of load balancing and things like that. So what is the solution? Basically just start a Jupyter notebook, instantiate your dusk cluster, and then just let dusk do the scaling up and down for you. And you just focus on the science. And what are the benefits to HPC systems for elastic scaling? One of them is that it actually improves the occupancy of the machine in that if the resources are idle, then dusk knows how to release them so that other users can actually use them. And another thing is that with the resiliency, you can easily, for instance, if you started with 120 workers, for some reason, your worker dies, dusk will know how to get a new worker. And in a way, if you think about something like MPI where you start, let's say you have like 120 workers, if one thing goes wrong in an MPI environment, the whole thing dies. So in a way, you kind of lose all the work that you had done, which is probably not that nice. So basically, another thing, to the same point, dusk thinks about these things. And I think you should also think about what you get from this as well. Again, so not all jobs are interactive. So once you're done with your interactive workflows, there's this other package called dusk MPI, which actually now allows you to go on and actually launch but jobs in case you don't need to do interactive exploration. And looks like I'm running out of time. So that is pretty much it for today. Thank you. And like I said, now you can see that it took away those resources. Okay, so here we go. Let's try here. So do we have any more questions? Hi, great talk. How do you deal with large datasets? And if you need to import like large datasets, can you do it? Can you put them on the cluster? So in this case, the Trubeta Hub is actually running on the same file system. So which basically means that we don't need to move the data around. So in our case, it kind of works in that basically we're moving the computation where the data is. So we don't need to move the data around. So I haven't run into cases where we need to move the data. So if anybody has run into that, then they could probably provide a better answer. Other questions? Yeah, it's the Trubeta Hub instance taking a pre-allocated resources like 20 loads, and then you scale up and down inside the Trubeta Hub? No. So if you remember what I did when I logged in to the Trubeta Hub, I asked for I think just one process. So Trubeta Hub is actually running, the lab itself is running in its own job. So when I do the scaling up and down, I'm actually doing that as independent jobs. So that's why I'm able to do that. But I mean scaling down is easy, but when you're trying to scale up, in our class, you need to wait 30 minutes to have a new job created for you. So yeah, that's what I say that when it comes to queuing systems, I think that lack of elastic scaling kind of makes it hard to actually do interactive computing in that you can't wait for two hours to get into the queue. In my case, I was able to get into the queue very easily because I had to ask a special reservation. So yeah. All right, we're going to have a lot of people filing in and out here because we're changing topics, so can we please thank Anderson again and all the speakers for the Geophysics Imposer.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 7.68, "text": " Good afternoon everyone. Welcome back to room 305. I see how we are full as normal. If you guys can", "tokens": [50364, 2205, 6499, 1518, 13, 4027, 646, 281, 1808, 2217, 20, 13, 286, 536, 577, 321, 366, 1577, 382, 2710, 13, 759, 291, 1074, 393, 50748], "temperature": 0.0, "avg_logprob": -0.14726128180821738, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.12751396000385284}, {"id": 1, "seek": 0, "start": 8.32, "end": 13.280000000000001, "text": " try to get into the middle to find a seat, you know, fire code and stuff like that,", "tokens": [50780, 853, 281, 483, 666, 264, 2808, 281, 915, 257, 6121, 11, 291, 458, 11, 2610, 3089, 293, 1507, 411, 300, 11, 51028], "temperature": 0.0, "avg_logprob": -0.14726128180821738, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.12751396000385284}, {"id": 2, "seek": 0, "start": 14.0, "end": 20.72, "text": " that would be very, very much appreciated. This is the last talk in our Geophysics,", "tokens": [51064, 300, 576, 312, 588, 11, 588, 709, 17169, 13, 639, 307, 264, 1036, 751, 294, 527, 2876, 5317, 41732, 11, 51400], "temperature": 0.0, "avg_logprob": -0.14726128180821738, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.12751396000385284}, {"id": 3, "seek": 0, "start": 21.6, "end": 27.68, "text": " Geology and Atmospheric Sciences session, and it goes to Addison. And how do you pronounce", "tokens": [51444, 2876, 1793, 293, 1711, 76, 25145, 21108, 5481, 11, 293, 309, 1709, 281, 5349, 2770, 13, 400, 577, 360, 291, 19567, 51748], "temperature": 0.0, "avg_logprob": -0.14726128180821738, "compression_ratio": 1.4916666666666667, "no_speech_prob": 0.12751396000385284}, {"id": 4, "seek": 2768, "start": 27.759999999999998, "end": 33.28, "text": " your last name, Addison? I'm going to leave that one with him and not even attempt it,", "tokens": [50368, 428, 1036, 1315, 11, 5349, 2770, 30, 286, 478, 516, 281, 1856, 300, 472, 365, 796, 293, 406, 754, 5217, 309, 11, 50644], "temperature": 0.0, "avg_logprob": -0.17454642875521792, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.009710715152323246}, {"id": 5, "seek": 2768, "start": 34.08, "end": 39.36, "text": " who's going to talk about interactive super computing with Jupiter and Dask. Thank you very", "tokens": [50684, 567, 311, 516, 281, 751, 466, 15141, 1687, 15866, 365, 24567, 293, 2846, 74, 13, 1044, 291, 588, 50948], "temperature": 0.0, "avg_logprob": -0.17454642875521792, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.009710715152323246}, {"id": 6, "seek": 2768, "start": 39.36, "end": 49.28, "text": " much, Addison. Thank you, Scott. Great. Thank you for having me here. This is my first sci-pi,", "tokens": [50948, 709, 11, 5349, 2770, 13, 1044, 291, 11, 6659, 13, 3769, 13, 1044, 291, 337, 1419, 385, 510, 13, 639, 307, 452, 700, 2180, 12, 22630, 11, 51444], "temperature": 0.0, "avg_logprob": -0.17454642875521792, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.009710715152323246}, {"id": 7, "seek": 2768, "start": 49.28, "end": 57.6, "text": " so I'm very excited to be here. So as Scott said, so my name is Anderson, I work as a software", "tokens": [51444, 370, 286, 478, 588, 2919, 281, 312, 510, 13, 407, 382, 6659, 848, 11, 370, 452, 1315, 307, 18768, 11, 286, 589, 382, 257, 4722, 51860], "temperature": 0.0, "avg_logprob": -0.17454642875521792, "compression_ratio": 1.6069868995633187, "no_speech_prob": 0.009710715152323246}, {"id": 8, "seek": 5760, "start": 57.68, "end": 63.760000000000005, "text": " engineer at the National Center for Atmospheric Research. So for those who are interested,", "tokens": [50368, 11403, 412, 264, 4862, 5169, 337, 1711, 76, 25145, 10303, 13, 407, 337, 729, 567, 366, 3102, 11, 50672], "temperature": 0.0, "avg_logprob": -0.11200206787859807, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.0042151398956775665}, {"id": 9, "seek": 5760, "start": 63.760000000000005, "end": 70.8, "text": " the slides available address. So this is a talk about Python tools that enable", "tokens": [50672, 264, 9788, 2435, 2985, 13, 407, 341, 307, 257, 751, 466, 15329, 3873, 300, 9528, 51024], "temperature": 0.0, "avg_logprob": -0.11200206787859807, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.0042151398956775665}, {"id": 10, "seek": 5760, "start": 72.64, "end": 77.12, "text": " interactive super computing, and we're going to see what we mean by super computing in a minute.", "tokens": [51116, 15141, 1687, 15866, 11, 293, 321, 434, 516, 281, 536, 437, 321, 914, 538, 1687, 15866, 294, 257, 3456, 13, 51340], "temperature": 0.0, "avg_logprob": -0.11200206787859807, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.0042151398956775665}, {"id": 11, "seek": 7712, "start": 77.2, "end": 88.80000000000001, "text": " Okay, so this is Alice, and Alice is a project scientist at NCAR. She studies the transfer of", "tokens": [50368, 1033, 11, 370, 341, 307, 16004, 11, 293, 16004, 307, 257, 1716, 12662, 412, 20786, 1899, 13, 1240, 5313, 264, 5003, 295, 50948], "temperature": 0.0, "avg_logprob": -0.11261569369922984, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.0031956550665199757}, {"id": 12, "seek": 7712, "start": 88.80000000000001, "end": 96.24000000000001, "text": " water and energy between the land surface and the lower atmosphere. And on the other side,", "tokens": [50948, 1281, 293, 2281, 1296, 264, 2117, 3753, 293, 264, 3126, 8018, 13, 400, 322, 264, 661, 1252, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11261569369922984, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.0031956550665199757}, {"id": 13, "seek": 7712, "start": 96.24000000000001, "end": 102.4, "text": " we have a cool notebook of how work. There are three things that are really interesting about", "tokens": [51320, 321, 362, 257, 1627, 21060, 295, 577, 589, 13, 821, 366, 1045, 721, 300, 366, 534, 1880, 466, 51628], "temperature": 0.0, "avg_logprob": -0.11261569369922984, "compression_ratio": 1.4946236559139785, "no_speech_prob": 0.0031956550665199757}, {"id": 14, "seek": 10240, "start": 102.4, "end": 109.76, "text": " this notebook. So the first thing is that this notebook is not running on her computer. So this", "tokens": [50364, 341, 21060, 13, 407, 264, 700, 551, 307, 300, 341, 21060, 307, 406, 2614, 322, 720, 3820, 13, 407, 341, 50732], "temperature": 0.0, "avg_logprob": -0.09348374670678443, "compression_ratio": 1.8277511961722488, "no_speech_prob": 0.0012955046258866787}, {"id": 15, "seek": 10240, "start": 109.76, "end": 116.08000000000001, "text": " is running on a supercomputer. In this case, this is Cheyenne. And as you can see, there's an address", "tokens": [50732, 307, 2614, 322, 257, 36708, 13, 682, 341, 1389, 11, 341, 307, 3351, 88, 13295, 13, 400, 382, 291, 393, 536, 11, 456, 311, 364, 2985, 51048], "temperature": 0.0, "avg_logprob": -0.09348374670678443, "compression_ratio": 1.8277511961722488, "no_speech_prob": 0.0012955046258866787}, {"id": 16, "seek": 10240, "start": 116.08000000000001, "end": 123.12, "text": " to a Jupiter hub running on the Cheyenne supercomputer. The second thing is that she's using", "tokens": [51048, 281, 257, 24567, 11838, 2614, 322, 264, 3351, 88, 13295, 36708, 13, 440, 1150, 551, 307, 300, 750, 311, 1228, 51400], "temperature": 0.0, "avg_logprob": -0.09348374670678443, "compression_ratio": 1.8277511961722488, "no_speech_prob": 0.0012955046258866787}, {"id": 17, "seek": 10240, "start": 124.48, "end": 131.44, "text": " hundreds of processes and terabytes of memory. All this is distributed computing resources.", "tokens": [51468, 6779, 295, 7555, 293, 1796, 24538, 295, 4675, 13, 1057, 341, 307, 12631, 15866, 3593, 13, 51816], "temperature": 0.0, "avg_logprob": -0.09348374670678443, "compression_ratio": 1.8277511961722488, "no_speech_prob": 0.0012955046258866787}, {"id": 18, "seek": 13240, "start": 132.56, "end": 138.8, "text": " Thanks to desktop queue. We're going to talk about that as well. And the third thing is she's", "tokens": [50372, 2561, 281, 14502, 18639, 13, 492, 434, 516, 281, 751, 466, 300, 382, 731, 13, 400, 264, 2636, 551, 307, 750, 311, 50684], "temperature": 0.0, "avg_logprob": -0.12902106977488897, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00027269782731309533}, {"id": 19, "seek": 13240, "start": 138.8, "end": 145.04000000000002, "text": " actually doing science. So this is not a toy example, so which is what she's good at. So", "tokens": [50684, 767, 884, 3497, 13, 407, 341, 307, 406, 257, 12058, 1365, 11, 370, 597, 307, 437, 750, 311, 665, 412, 13, 407, 50996], "temperature": 0.0, "avg_logprob": -0.12902106977488897, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00027269782731309533}, {"id": 20, "seek": 13240, "start": 146.0, "end": 152.72, "text": " now we're going to talk about how we at NCAR enable Alice and folks like her to do interactive", "tokens": [51044, 586, 321, 434, 516, 281, 751, 466, 577, 321, 412, 20786, 1899, 9528, 16004, 293, 4024, 411, 720, 281, 360, 15141, 51380], "temperature": 0.0, "avg_logprob": -0.12902106977488897, "compression_ratio": 1.521978021978022, "no_speech_prob": 0.00027269782731309533}, {"id": 21, "seek": 15272, "start": 152.72, "end": 163.92, "text": " supercomputing. So what do we mean by supercomputing? First, MPI, batch processing, lots of heavy", "tokens": [50364, 27839, 2582, 278, 13, 407, 437, 360, 321, 914, 538, 27839, 2582, 278, 30, 2386, 11, 14146, 40, 11, 15245, 9007, 11, 3195, 295, 4676, 50924], "temperature": 0.0, "avg_logprob": -0.0752608021603355, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.0018023269949480891}, {"id": 22, "seek": 15272, "start": 163.92, "end": 169.76, "text": " machines that most of people don't have access to as admins. So you have to talk to people to be able", "tokens": [50924, 8379, 300, 881, 295, 561, 500, 380, 362, 2105, 281, 382, 5910, 1292, 13, 407, 291, 362, 281, 751, 281, 561, 281, 312, 1075, 51216], "temperature": 0.0, "avg_logprob": -0.0752608021603355, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.0018023269949480891}, {"id": 23, "seek": 15272, "start": 169.76, "end": 176.48, "text": " to install some of the software. In the picture, so this is Cheyenne, which is a supercomputer", "tokens": [51216, 281, 3625, 512, 295, 264, 4722, 13, 682, 264, 3036, 11, 370, 341, 307, 3351, 88, 13295, 11, 597, 307, 257, 36708, 51552], "temperature": 0.0, "avg_logprob": -0.0752608021603355, "compression_ratio": 1.5392670157068062, "no_speech_prob": 0.0018023269949480891}, {"id": 24, "seek": 17648, "start": 176.48, "end": 184.07999999999998, "text": " operated by NCAR. If you're ever in Cheyenne, Wyoming, feel free to stop by. They give free", "tokens": [50364, 20826, 538, 20786, 1899, 13, 759, 291, 434, 1562, 294, 3351, 88, 13295, 11, 30810, 11, 841, 1737, 281, 1590, 538, 13, 814, 976, 1737, 50744], "temperature": 0.0, "avg_logprob": -0.10780976159232003, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.0012842478463426232}, {"id": 25, "seek": 17648, "start": 184.07999999999998, "end": 190.88, "text": " tours of the facility if you want to. And what do we mean by interactive supercomputing?", "tokens": [50744, 22911, 295, 264, 8973, 498, 291, 528, 281, 13, 400, 437, 360, 321, 914, 538, 15141, 27839, 2582, 278, 30, 51084], "temperature": 0.0, "avg_logprob": -0.10780976159232003, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.0012842478463426232}, {"id": 26, "seek": 17648, "start": 192.48, "end": 200.23999999999998, "text": " So with the current growth in data creation, both through new simulations and new observations,", "tokens": [51164, 407, 365, 264, 2190, 4599, 294, 1412, 8016, 11, 1293, 807, 777, 35138, 293, 777, 18163, 11, 51552], "temperature": 0.0, "avg_logprob": -0.10780976159232003, "compression_ratio": 1.4300518134715026, "no_speech_prob": 0.0012842478463426232}, {"id": 27, "seek": 20024, "start": 200.24, "end": 206.96, "text": " there's a growing need to have a more human in the loop workflow where people can rapidly prototype", "tokens": [50364, 456, 311, 257, 4194, 643, 281, 362, 257, 544, 1952, 294, 264, 6367, 20993, 689, 561, 393, 12910, 19475, 50700], "temperature": 0.0, "avg_logprob": -0.08669716661626642, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.001138978754170239}, {"id": 28, "seek": 20024, "start": 206.96, "end": 215.12, "text": " and iterate through the data with tools like Jupyter notebooks. There's also a need to do", "tokens": [50700, 293, 44497, 807, 264, 1412, 365, 3873, 411, 22125, 88, 391, 43782, 13, 821, 311, 611, 257, 643, 281, 360, 51108], "temperature": 0.0, "avg_logprob": -0.08669716661626642, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.001138978754170239}, {"id": 29, "seek": 20024, "start": 215.12, "end": 220.8, "text": " things like in situ data analytics. So instead of having to run the simulations and output the data,", "tokens": [51108, 721, 411, 294, 2054, 1412, 15370, 13, 407, 2602, 295, 1419, 281, 1190, 264, 35138, 293, 5598, 264, 1412, 11, 51392], "temperature": 0.0, "avg_logprob": -0.08669716661626642, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.001138978754170239}, {"id": 30, "seek": 20024, "start": 220.8, "end": 227.12, "text": " you could actually run the simulation and do the analysis at the same time. And the other thing", "tokens": [51392, 291, 727, 767, 1190, 264, 16575, 293, 360, 264, 5215, 412, 264, 912, 565, 13, 400, 264, 661, 551, 51708], "temperature": 0.0, "avg_logprob": -0.08669716661626642, "compression_ratio": 1.685589519650655, "no_speech_prob": 0.001138978754170239}, {"id": 31, "seek": 22712, "start": 227.12, "end": 233.84, "text": " is actually adaptive scaling of computing resources. So this combination would really be powerful,", "tokens": [50364, 307, 767, 27912, 21589, 295, 15866, 3593, 13, 407, 341, 6562, 576, 534, 312, 4005, 11, 50700], "temperature": 0.0, "avg_logprob": -0.07187233704787034, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.00034993639565072954}, {"id": 32, "seek": 22712, "start": 233.84, "end": 242.88, "text": " but it's really hard for different reasons. So some of these reasons are cultural and others", "tokens": [50700, 457, 309, 311, 534, 1152, 337, 819, 4112, 13, 407, 512, 295, 613, 4112, 366, 6988, 293, 2357, 51152], "temperature": 0.0, "avg_logprob": -0.07187233704787034, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.00034993639565072954}, {"id": 33, "seek": 22712, "start": 242.88, "end": 251.20000000000002, "text": " are technical. So the first one is that HP systems tends to be unique. So every HPC center has its", "tokens": [51152, 366, 6191, 13, 407, 264, 700, 472, 307, 300, 12557, 3652, 12258, 281, 312, 3845, 13, 407, 633, 12557, 34, 3056, 575, 1080, 51568], "temperature": 0.0, "avg_logprob": -0.07187233704787034, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.00034993639565072954}, {"id": 34, "seek": 25120, "start": 251.2, "end": 256.96, "text": " own policies when it comes to things like security, what can you run on the supercomputer.", "tokens": [50364, 1065, 7657, 562, 309, 1487, 281, 721, 411, 3825, 11, 437, 393, 291, 1190, 322, 264, 36708, 13, 50652], "temperature": 0.0, "avg_logprob": -0.10165379371172116, "compression_ratio": 1.65625, "no_speech_prob": 0.0012953331461176276}, {"id": 35, "seek": 25120, "start": 258.88, "end": 265.28, "text": " And the second point is the tension between interactivity and machine utilization. So when it", "tokens": [50748, 400, 264, 1150, 935, 307, 264, 8980, 1296, 4648, 4253, 293, 3479, 37074, 13, 407, 562, 309, 51068], "temperature": 0.0, "avg_logprob": -0.10165379371172116, "compression_ratio": 1.65625, "no_speech_prob": 0.0012953331461176276}, {"id": 36, "seek": 25120, "start": 265.28, "end": 274.32, "text": " comes to HPC systems, HP center stands to be measured according to how often the machine is", "tokens": [51068, 1487, 281, 12557, 34, 3652, 11, 12557, 3056, 7382, 281, 312, 12690, 4650, 281, 577, 2049, 264, 3479, 307, 51520], "temperature": 0.0, "avg_logprob": -0.10165379371172116, "compression_ratio": 1.65625, "no_speech_prob": 0.0012953331461176276}, {"id": 37, "seek": 25120, "start": 274.32, "end": 280.4, "text": " actually utilized. And when you're talking about things like interactivity, users want to have", "tokens": [51520, 767, 28158, 13, 400, 562, 291, 434, 1417, 466, 721, 411, 4648, 4253, 11, 5022, 528, 281, 362, 51824], "temperature": 0.0, "avg_logprob": -0.10165379371172116, "compression_ratio": 1.65625, "no_speech_prob": 0.0012953331461176276}, {"id": 38, "seek": 28120, "start": 281.44, "end": 288.24, "text": " resources on demand whenever they want them. But because HP system operate on batch Q systems,", "tokens": [50376, 3593, 322, 4733, 5699, 436, 528, 552, 13, 583, 570, 12557, 1185, 9651, 322, 15245, 1249, 3652, 11, 50716], "temperature": 0.0, "avg_logprob": -0.06959819275399913, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00038716866401955485}, {"id": 39, "seek": 28120, "start": 288.24, "end": 293.28, "text": " it's not that easy to actually get resources whenever you want to. So no user is going to", "tokens": [50716, 309, 311, 406, 300, 1858, 281, 767, 483, 3593, 5699, 291, 528, 281, 13, 407, 572, 4195, 307, 516, 281, 50968], "temperature": 0.0, "avg_logprob": -0.06959819275399913, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00038716866401955485}, {"id": 40, "seek": 28120, "start": 293.28, "end": 300.32, "text": " wait for five hours to get into the queue to do interactive data analysis. And the third point", "tokens": [50968, 1699, 337, 1732, 2496, 281, 483, 666, 264, 18639, 281, 360, 15141, 1412, 5215, 13, 400, 264, 2636, 935, 51320], "temperature": 0.0, "avg_logprob": -0.06959819275399913, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00038716866401955485}, {"id": 41, "seek": 28120, "start": 300.32, "end": 305.84, "text": " is the lack of elastic scaling. And this is a huge, at least in my opinion, I think this is a huge", "tokens": [51320, 307, 264, 5011, 295, 17115, 21589, 13, 400, 341, 307, 257, 2603, 11, 412, 1935, 294, 452, 4800, 11, 286, 519, 341, 307, 257, 2603, 51596], "temperature": 0.0, "avg_logprob": -0.06959819275399913, "compression_ratio": 1.6223175965665235, "no_speech_prob": 0.00038716866401955485}, {"id": 42, "seek": 30584, "start": 305.84, "end": 311.76, "text": " disadvantage in that if someone, let's say, want to do some analysis, they have to take time and", "tokens": [50364, 24292, 294, 300, 498, 1580, 11, 718, 311, 584, 11, 528, 281, 360, 512, 5215, 11, 436, 362, 281, 747, 565, 293, 50660], "temperature": 0.0, "avg_logprob": -0.10447173835956945, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.003515884280204773}, {"id": 43, "seek": 30584, "start": 311.76, "end": 317.03999999999996, "text": " actually think about how much resources they want before they even do the analysis. And what ends", "tokens": [50660, 767, 519, 466, 577, 709, 3593, 436, 528, 949, 436, 754, 360, 264, 5215, 13, 400, 437, 5314, 50924], "temperature": 0.0, "avg_logprob": -0.10447173835956945, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.003515884280204773}, {"id": 44, "seek": 30584, "start": 317.03999999999996, "end": 324.55999999999995, "text": " up happening is that you get into your work, maybe five minutes later, you probably take like 20", "tokens": [50924, 493, 2737, 307, 300, 291, 483, 666, 428, 589, 11, 1310, 1732, 2077, 1780, 11, 291, 1391, 747, 411, 945, 51300], "temperature": 0.0, "avg_logprob": -0.10447173835956945, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.003515884280204773}, {"id": 45, "seek": 30584, "start": 324.55999999999995, "end": 329.2, "text": " minutes thinking, what do I do next? And during that time, the resources are just idle. So it would", "tokens": [51300, 2077, 1953, 11, 437, 360, 286, 360, 958, 30, 400, 1830, 300, 565, 11, 264, 3593, 366, 445, 30650, 13, 407, 309, 576, 51532], "temperature": 0.0, "avg_logprob": -0.10447173835956945, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.003515884280204773}, {"id": 46, "seek": 30584, "start": 329.2, "end": 335.52, "text": " be nice if you could actually scale down later that people use those resources and get them back", "tokens": [51532, 312, 1481, 498, 291, 727, 767, 4373, 760, 1780, 300, 561, 764, 729, 3593, 293, 483, 552, 646, 51848], "temperature": 0.0, "avg_logprob": -0.10447173835956945, "compression_ratio": 1.7243816254416962, "no_speech_prob": 0.003515884280204773}, {"id": 47, "seek": 33552, "start": 335.52, "end": 343.28, "text": " whenever you actually need to. The good news is that, despite all those challenges, there's a", "tokens": [50364, 5699, 291, 767, 643, 281, 13, 440, 665, 2583, 307, 300, 11, 7228, 439, 729, 4759, 11, 456, 311, 257, 50752], "temperature": 0.0, "avg_logprob": -0.09173144685461167, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0003436717961449176}, {"id": 48, "seek": 33552, "start": 343.28, "end": 350.64, "text": " growing list of technologies or tools that try to help with interactive supercomputing. And I'm", "tokens": [50752, 4194, 1329, 295, 7943, 420, 3873, 300, 853, 281, 854, 365, 15141, 27839, 2582, 278, 13, 400, 286, 478, 51120], "temperature": 0.0, "avg_logprob": -0.09173144685461167, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0003436717961449176}, {"id": 49, "seek": 33552, "start": 350.64, "end": 358.0, "text": " going to talk about some of these tools. The first one is Trubiter. So we all love and use", "tokens": [51120, 516, 281, 751, 466, 512, 295, 613, 3873, 13, 440, 700, 472, 307, 1765, 836, 1681, 13, 407, 321, 439, 959, 293, 764, 51488], "temperature": 0.0, "avg_logprob": -0.09173144685461167, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0003436717961449176}, {"id": 50, "seek": 33552, "start": 358.0, "end": 363.84, "text": " Trubiter. And so I'm not really going to spend much time on it because now everybody is familiar", "tokens": [51488, 1765, 836, 1681, 13, 400, 370, 286, 478, 406, 534, 516, 281, 3496, 709, 565, 322, 309, 570, 586, 2201, 307, 4963, 51780], "temperature": 0.0, "avg_logprob": -0.09173144685461167, "compression_ratio": 1.590717299578059, "no_speech_prob": 0.0003436717961449176}, {"id": 51, "seek": 36384, "start": 363.84, "end": 372.64, "text": " with it. And some of you may be wondering, but isn't Trubiter already usable on HP systems? And", "tokens": [50364, 365, 309, 13, 400, 512, 295, 291, 815, 312, 6359, 11, 457, 1943, 380, 1765, 836, 1681, 1217, 29975, 322, 12557, 3652, 30, 400, 50804], "temperature": 0.0, "avg_logprob": -0.10657043649692728, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0006017553969286382}, {"id": 52, "seek": 36384, "start": 372.64, "end": 379.2, "text": " the answer is actually, yes, but you have to go through all these steps. You have to essentially", "tokens": [50804, 264, 1867, 307, 767, 11, 2086, 11, 457, 291, 362, 281, 352, 807, 439, 613, 4439, 13, 509, 362, 281, 4476, 51132], "temperature": 0.0, "avg_logprob": -0.10657043649692728, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0006017553969286382}, {"id": 53, "seek": 36384, "start": 379.2, "end": 386.23999999999995, "text": " tune the machine. You have to set up SSH tunnels. And you have to do this every single time that", "tokens": [51132, 10864, 264, 3479, 13, 509, 362, 281, 992, 493, 12238, 39, 30804, 13, 400, 291, 362, 281, 360, 341, 633, 2167, 565, 300, 51484], "temperature": 0.0, "avg_logprob": -0.10657043649692728, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0006017553969286382}, {"id": 54, "seek": 36384, "start": 386.23999999999995, "end": 392.96, "text": " you want to actually use the Trubiter notebook on the supercomputer. And this can actually be tedious,", "tokens": [51484, 291, 528, 281, 767, 764, 264, 1765, 836, 1681, 21060, 322, 264, 36708, 13, 400, 341, 393, 767, 312, 38284, 11, 51820], "temperature": 0.0, "avg_logprob": -0.10657043649692728, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0006017553969286382}, {"id": 55, "seek": 39296, "start": 393.03999999999996, "end": 401.03999999999996, "text": " especially for new users. So what is missing? So one of the things that is actually missing is", "tokens": [50368, 2318, 337, 777, 5022, 13, 407, 437, 307, 5361, 30, 407, 472, 295, 264, 721, 300, 307, 767, 5361, 307, 50768], "temperature": 0.0, "avg_logprob": -0.08930152654647827, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001355050946585834}, {"id": 56, "seek": 39296, "start": 401.03999999999996, "end": 405.91999999999996, "text": " the multi-user support. So all those steps, everybody has to go through them individually.", "tokens": [50768, 264, 4825, 12, 18088, 1406, 13, 407, 439, 729, 4439, 11, 2201, 575, 281, 352, 807, 552, 16652, 13, 51012], "temperature": 0.0, "avg_logprob": -0.08930152654647827, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001355050946585834}, {"id": 57, "seek": 39296, "start": 405.91999999999996, "end": 410.24, "text": " And it would be nice if there was one single place that everybody goes to and everything is", "tokens": [51012, 400, 309, 576, 312, 1481, 498, 456, 390, 472, 2167, 1081, 300, 2201, 1709, 281, 293, 1203, 307, 51228], "temperature": 0.0, "avg_logprob": -0.08930152654647827, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001355050946585834}, {"id": 58, "seek": 39296, "start": 410.24, "end": 416.71999999999997, "text": " done for them. Another thing is actually the lack of pure web access to HPC resources. Because as", "tokens": [51228, 1096, 337, 552, 13, 3996, 551, 307, 767, 264, 5011, 295, 6075, 3670, 2105, 281, 12557, 34, 3593, 13, 1436, 382, 51552], "temperature": 0.0, "avg_logprob": -0.08930152654647827, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.001355050946585834}, {"id": 59, "seek": 41672, "start": 416.72, "end": 423.76000000000005, "text": " you've seen, we're setting up SSH tunnel, which if you ever need to use another process that probably", "tokens": [50364, 291, 600, 1612, 11, 321, 434, 3287, 493, 12238, 39, 13186, 11, 597, 498, 291, 1562, 643, 281, 764, 1071, 1399, 300, 1391, 50716], "temperature": 0.0, "avg_logprob": -0.08740208880736096, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.001170469680801034}, {"id": 60, "seek": 41672, "start": 423.76000000000005, "end": 427.84000000000003, "text": " runs on a different port, so you also have to SSH to create a tunnel for that port as well.", "tokens": [50716, 6676, 322, 257, 819, 2436, 11, 370, 291, 611, 362, 281, 12238, 39, 281, 1884, 257, 13186, 337, 300, 2436, 382, 731, 13, 50920], "temperature": 0.0, "avg_logprob": -0.08740208880736096, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.001170469680801034}, {"id": 61, "seek": 41672, "start": 429.76000000000005, "end": 437.68, "text": " Well, then Trubiter Hub comes to the rescue. So one good thing about Trubiter Hub is that,", "tokens": [51016, 1042, 11, 550, 1765, 836, 1681, 18986, 1487, 281, 264, 13283, 13, 407, 472, 665, 551, 466, 1765, 836, 1681, 18986, 307, 300, 11, 51412], "temperature": 0.0, "avg_logprob": -0.08740208880736096, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.001170469680801034}, {"id": 62, "seek": 41672, "start": 437.68, "end": 444.8, "text": " in a way, it provides a standard way of managing authentication. So one of the issues that is not", "tokens": [51412, 294, 257, 636, 11, 309, 6417, 257, 3832, 636, 295, 11642, 26643, 13, 407, 472, 295, 264, 2663, 300, 307, 406, 51768], "temperature": 0.0, "avg_logprob": -0.08740208880736096, "compression_ratio": 1.6324786324786325, "no_speech_prob": 0.001170469680801034}, {"id": 63, "seek": 44480, "start": 444.8, "end": 452.48, "text": " really hard to convince sysadmins about is the security of web applications. But Trubiter Hub", "tokens": [50364, 534, 1152, 281, 13447, 262, 749, 345, 76, 1292, 466, 307, 264, 3825, 295, 3670, 5821, 13, 583, 1765, 836, 1681, 18986, 50748], "temperature": 0.0, "avg_logprob": -0.09133881016781456, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0008626363705843687}, {"id": 64, "seek": 44480, "start": 452.48, "end": 457.6, "text": " makes it easy in that it doesn't really force you to use any type of authentication. It's up to you", "tokens": [50748, 1669, 309, 1858, 294, 300, 309, 1177, 380, 534, 3464, 291, 281, 764, 604, 2010, 295, 26643, 13, 467, 311, 493, 281, 291, 51004], "temperature": 0.0, "avg_logprob": -0.09133881016781456, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0008626363705843687}, {"id": 65, "seek": 44480, "start": 457.6, "end": 462.96000000000004, "text": " to choose what you want to use for authentication. In this case, on the supercomputer, you have", "tokens": [51004, 281, 2826, 437, 291, 528, 281, 764, 337, 26643, 13, 682, 341, 1389, 11, 322, 264, 36708, 11, 291, 362, 51272], "temperature": 0.0, "avg_logprob": -0.09133881016781456, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0008626363705843687}, {"id": 66, "seek": 44480, "start": 462.96000000000004, "end": 468.64, "text": " different types of authentications. And another thing is that Trubiter Hub will just take care of", "tokens": [51272, 819, 3467, 295, 12466, 763, 13, 400, 1071, 551, 307, 300, 1765, 836, 1681, 18986, 486, 445, 747, 1127, 295, 51556], "temperature": 0.0, "avg_logprob": -0.09133881016781456, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.0008626363705843687}, {"id": 67, "seek": 46864, "start": 468.71999999999997, "end": 476.08, "text": " spawning the Trubiter notebook single server and giving access to the user on demand.", "tokens": [50368, 637, 35880, 264, 1765, 836, 1681, 21060, 2167, 7154, 293, 2902, 2105, 281, 264, 4195, 322, 4733, 13, 50736], "temperature": 0.0, "avg_logprob": -0.10483746461465325, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0009813737124204636}, {"id": 68, "seek": 46864, "start": 478.71999999999997, "end": 485.91999999999996, "text": " And so let's now switch gears and actually see how this works in practice. So I will skip these", "tokens": [50868, 400, 370, 718, 311, 586, 3679, 20915, 293, 767, 536, 577, 341, 1985, 294, 3124, 13, 407, 286, 486, 10023, 613, 51228], "temperature": 0.0, "avg_logprob": -0.10483746461465325, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0009813737124204636}, {"id": 69, "seek": 46864, "start": 485.91999999999996, "end": 494.08, "text": " few slides and actually go to the live demo. So the first thing that you do as a user, so you just", "tokens": [51228, 1326, 9788, 293, 767, 352, 281, 264, 1621, 10723, 13, 407, 264, 700, 551, 300, 291, 360, 382, 257, 4195, 11, 370, 291, 445, 51636], "temperature": 0.0, "avg_logprob": -0.10483746461465325, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0009813737124204636}, {"id": 70, "seek": 49408, "start": 494.08, "end": 507.68, "text": " go to Trubiter Hub.ucr.edu. And so this is what you presented. And if you've used the", "tokens": [50364, 352, 281, 1765, 836, 1681, 18986, 13, 1311, 81, 13, 22938, 13, 400, 370, 341, 307, 437, 291, 8212, 13, 400, 498, 291, 600, 1143, 264, 51044], "temperature": 0.0, "avg_logprob": -0.10621371587117513, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0015150083927437663}, {"id": 71, "seek": 49408, "start": 507.68, "end": 512.4, "text": " Trubiter Hub before, this looks familiar. The only difference is that in this case,", "tokens": [51044, 1765, 836, 1681, 18986, 949, 11, 341, 1542, 4963, 13, 440, 787, 2649, 307, 300, 294, 341, 1389, 11, 51280], "temperature": 0.0, "avg_logprob": -0.10621371587117513, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0015150083927437663}, {"id": 72, "seek": 49408, "start": 513.28, "end": 519.6, "text": " I have to use the same authentication that I used to SSH into the machine. So in my case,", "tokens": [51324, 286, 362, 281, 764, 264, 912, 26643, 300, 286, 1143, 281, 12238, 39, 666, 264, 3479, 13, 407, 294, 452, 1389, 11, 51640], "temperature": 0.0, "avg_logprob": -0.10621371587117513, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0015150083927437663}, {"id": 73, "seek": 51960, "start": 519.6, "end": 526.16, "text": " I just provide my username. And then for the password, it's a combination of a PIN number", "tokens": [50364, 286, 445, 2893, 452, 30351, 13, 400, 550, 337, 264, 11524, 11, 309, 311, 257, 6562, 295, 257, 430, 1464, 1230, 50692], "temperature": 0.0, "avg_logprob": -0.12186842379362686, "compression_ratio": 1.4425287356321839, "no_speech_prob": 0.0013755748514086008}, {"id": 74, "seek": 51960, "start": 527.0400000000001, "end": 537.0400000000001, "text": " and a UB key token. So now, so now I'm authenticated. So I then get this page,", "tokens": [50736, 293, 257, 624, 33, 2141, 14862, 13, 407, 586, 11, 370, 586, 286, 478, 9214, 3587, 13, 407, 286, 550, 483, 341, 3028, 11, 51236], "temperature": 0.0, "avg_logprob": -0.12186842379362686, "compression_ratio": 1.4425287356321839, "no_speech_prob": 0.0013755748514086008}, {"id": 75, "seek": 51960, "start": 537.0400000000001, "end": 543.0400000000001, "text": " which basically asked me for the project account. So this is the allocation on the", "tokens": [51236, 597, 1936, 2351, 385, 337, 264, 1716, 2696, 13, 407, 341, 307, 264, 27599, 322, 264, 51536], "temperature": 0.0, "avg_logprob": -0.12186842379362686, "compression_ratio": 1.4425287356321839, "no_speech_prob": 0.0013755748514086008}, {"id": 76, "seek": 54304, "start": 543.04, "end": 549.5999999999999, "text": " supercomputer so that they know who to charge for this usage. So in this case, I'm going to", "tokens": [50364, 36708, 370, 300, 436, 458, 567, 281, 4602, 337, 341, 14924, 13, 407, 294, 341, 1389, 11, 286, 478, 516, 281, 50692], "temperature": 0.0, "avg_logprob": -0.09319640769333136, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.005436486564576626}, {"id": 77, "seek": 54304, "start": 550.8, "end": 558.9599999999999, "text": " provide when to change the queue here and specify the project", "tokens": [50752, 2893, 562, 281, 1319, 264, 18639, 510, 293, 16500, 264, 1716, 51160], "temperature": 0.0, "avg_logprob": -0.09319640769333136, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.005436486564576626}, {"id": 78, "seek": 54304, "start": 562.0799999999999, "end": 570.48, "text": " and maybe just reduce the wall time. And then once this is done, I just click on spawn.", "tokens": [51316, 293, 1310, 445, 5407, 264, 2929, 565, 13, 400, 550, 1564, 341, 307, 1096, 11, 286, 445, 2052, 322, 17088, 13, 51736], "temperature": 0.0, "avg_logprob": -0.09319640769333136, "compression_ratio": 1.4518072289156627, "no_speech_prob": 0.005436486564576626}, {"id": 79, "seek": 57048, "start": 571.44, "end": 576.48, "text": " And what this is doing in the background, it's basically submitting a job to the queuing system.", "tokens": [50412, 400, 437, 341, 307, 884, 294, 264, 3678, 11, 309, 311, 1936, 31836, 257, 1691, 281, 264, 631, 9635, 1185, 13, 50664], "temperature": 0.0, "avg_logprob": -0.13051592676263107, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0001936830667546019}, {"id": 80, "seek": 57048, "start": 577.12, "end": 586.48, "text": " And once the Trubiter Notebook server is ready, I will get redirected to this new page. And at this", "tokens": [50696, 400, 1564, 264, 1765, 836, 1681, 11633, 2939, 7154, 307, 1919, 11, 286, 486, 483, 29066, 292, 281, 341, 777, 3028, 13, 400, 412, 341, 51164], "temperature": 0.0, "avg_logprob": -0.13051592676263107, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0001936830667546019}, {"id": 81, "seek": 57048, "start": 586.48, "end": 594.48, "text": " point, thank you. So at this point, you have the same interface as what you would have on your", "tokens": [51164, 935, 11, 1309, 291, 13, 407, 412, 341, 935, 11, 291, 362, 264, 912, 9226, 382, 437, 291, 576, 362, 322, 428, 51564], "temperature": 0.0, "avg_logprob": -0.13051592676263107, "compression_ratio": 1.5235602094240839, "no_speech_prob": 0.0001936830667546019}, {"id": 82, "seek": 59448, "start": 594.48, "end": 602.72, "text": " laptop. So I can run notebooks, in this case, to show you that I'm not really lying. So", "tokens": [50364, 10732, 13, 407, 286, 393, 1190, 43782, 11, 294, 341, 1389, 11, 281, 855, 291, 300, 286, 478, 406, 534, 8493, 13, 407, 50776], "temperature": 0.0, "avg_logprob": -0.15796644547406366, "compression_ratio": 1.4451219512195121, "no_speech_prob": 0.0008118641562759876}, {"id": 83, "seek": 59448, "start": 606.5600000000001, "end": 612.48, "text": " you could just run this notebook, which is backed by Bashkarno. And as you can see,", "tokens": [50968, 291, 727, 445, 1190, 341, 21060, 11, 597, 307, 20391, 538, 43068, 74, 1083, 78, 13, 400, 382, 291, 393, 536, 11, 51264], "temperature": 0.0, "avg_logprob": -0.15796644547406366, "compression_ratio": 1.4451219512195121, "no_speech_prob": 0.0008118641562759876}, {"id": 84, "seek": 59448, "start": 612.48, "end": 616.4, "text": " I don't really have 200 terabytes of storage on this computer. So", "tokens": [51264, 286, 500, 380, 534, 362, 2331, 1796, 24538, 295, 6725, 322, 341, 3820, 13, 407, 51460], "temperature": 0.0, "avg_logprob": -0.15796644547406366, "compression_ratio": 1.4451219512195121, "no_speech_prob": 0.0008118641562759876}, {"id": 85, "seek": 61640, "start": 617.36, "end": 630.8, "text": " that's it about Trubiter Hubs. I'll come back to it later. So the next tool is Dask.", "tokens": [50412, 300, 311, 309, 466, 1765, 836, 1681, 389, 5432, 13, 286, 603, 808, 646, 281, 309, 1780, 13, 407, 264, 958, 2290, 307, 2846, 74, 13, 51084], "temperature": 0.0, "avg_logprob": -0.22655206797074298, "compression_ratio": 1.282258064516129, "no_speech_prob": 0.0013722435105592012}, {"id": 86, "seek": 61640, "start": 633.68, "end": 636.8, "text": " Is there anybody in this room who is not familiar with Dask at this point?", "tokens": [51228, 1119, 456, 4472, 294, 341, 1808, 567, 307, 406, 4963, 365, 2846, 74, 412, 341, 935, 30, 51384], "temperature": 0.0, "avg_logprob": -0.22655206797074298, "compression_ratio": 1.282258064516129, "no_speech_prob": 0.0013722435105592012}, {"id": 87, "seek": 63680, "start": 636.9599999999999, "end": 646.4, "text": " Okay, a few people. So at this point, most of us are familiar with Dask.", "tokens": [50372, 1033, 11, 257, 1326, 561, 13, 407, 412, 341, 935, 11, 881, 295, 505, 366, 4963, 365, 2846, 74, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13089403841230604, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.0013205398572608829}, {"id": 88, "seek": 63680, "start": 647.5999999999999, "end": 653.4399999999999, "text": " We've probably interacted with it in the cloud or even on our local machines. So I'm not really", "tokens": [50904, 492, 600, 1391, 49621, 365, 309, 294, 264, 4588, 420, 754, 322, 527, 2654, 8379, 13, 407, 286, 478, 406, 534, 51196], "temperature": 0.0, "avg_logprob": -0.13089403841230604, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.0013205398572608829}, {"id": 89, "seek": 63680, "start": 653.4399999999999, "end": 659.52, "text": " going to spend any more time talking about Dask. The one key point that I'm going to focus on is", "tokens": [51196, 516, 281, 3496, 604, 544, 565, 1417, 466, 2846, 74, 13, 440, 472, 2141, 935, 300, 286, 478, 516, 281, 1879, 322, 307, 51500], "temperature": 0.0, "avg_logprob": -0.13089403841230604, "compression_ratio": 1.4324324324324325, "no_speech_prob": 0.0013205398572608829}, {"id": 90, "seek": 65952, "start": 659.52, "end": 668.48, "text": " how to deploy Dask on HPC systems. And this is where Dask JobQ comes in.", "tokens": [50364, 577, 281, 7274, 2846, 74, 322, 12557, 34, 3652, 13, 400, 341, 307, 689, 2846, 74, 18602, 48, 1487, 294, 13, 50812], "temperature": 0.0, "avg_logprob": -0.14767895246806897, "compression_ratio": 1.456140350877193, "no_speech_prob": 0.0025111997965723276}, {"id": 91, "seek": 65952, "start": 669.6, "end": 677.76, "text": " So Dask JobQ is a Python library that allows you to easily deploy Dask on JobQ systems,", "tokens": [50868, 407, 2846, 74, 18602, 48, 307, 257, 15329, 6405, 300, 4045, 291, 281, 3612, 7274, 2846, 74, 322, 18602, 48, 3652, 11, 51276], "temperature": 0.0, "avg_logprob": -0.14767895246806897, "compression_ratio": 1.456140350877193, "no_speech_prob": 0.0025111997965723276}, {"id": 92, "seek": 65952, "start": 677.76, "end": 686.4, "text": " such as PBS or Slurm, and so many other. It was created as a spin of the Panjio project.", "tokens": [51276, 1270, 382, 33517, 420, 6187, 26717, 11, 293, 370, 867, 661, 13, 467, 390, 2942, 382, 257, 6060, 295, 264, 7557, 73, 1004, 1716, 13, 51708], "temperature": 0.0, "avg_logprob": -0.14767895246806897, "compression_ratio": 1.456140350877193, "no_speech_prob": 0.0025111997965723276}, {"id": 93, "seek": 68640, "start": 687.1999999999999, "end": 692.9599999999999, "text": " It provides a high-level Python user interface to manage Dask clusters and Dask workers.", "tokens": [50404, 467, 6417, 257, 1090, 12, 12418, 15329, 4195, 9226, 281, 3067, 2846, 74, 23313, 293, 2846, 74, 5600, 13, 50692], "temperature": 0.0, "avg_logprob": -0.1661158375356389, "compression_ratio": 1.5613207547169812, "no_speech_prob": 0.00030954868998378515}, {"id": 94, "seek": 68640, "start": 695.04, "end": 700.0, "text": " So for instance, if you're like on a system that uses PBS as the queuing system,", "tokens": [50796, 407, 337, 5197, 11, 498, 291, 434, 411, 322, 257, 1185, 300, 4960, 33517, 382, 264, 631, 9635, 1185, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1661158375356389, "compression_ratio": 1.5613207547169812, "no_speech_prob": 0.00030954868998378515}, {"id": 95, "seek": 68640, "start": 700.0, "end": 705.04, "text": " so this is what you have to do. So from Dask JobQ, import the PBS cluster class,", "tokens": [51044, 370, 341, 307, 437, 291, 362, 281, 360, 13, 407, 490, 2846, 74, 18602, 48, 11, 974, 264, 33517, 13630, 1508, 11, 51296], "temperature": 0.0, "avg_logprob": -0.1661158375356389, "compression_ratio": 1.5613207547169812, "no_speech_prob": 0.00030954868998378515}, {"id": 96, "seek": 68640, "start": 705.6, "end": 710.0799999999999, "text": " and then instantiate that class with things like the project account, the queue,", "tokens": [51324, 293, 550, 9836, 13024, 300, 1508, 365, 721, 411, 264, 1716, 2696, 11, 264, 18639, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1661158375356389, "compression_ratio": 1.5613207547169812, "no_speech_prob": 0.00030954868998378515}, {"id": 97, "seek": 71008, "start": 710.88, "end": 717.12, "text": " and all other resources that you want. And I should be clear that I'm not really defining", "tokens": [50404, 293, 439, 661, 3593, 300, 291, 528, 13, 400, 286, 820, 312, 1850, 300, 286, 478, 406, 534, 17827, 50716], "temperature": 0.0, "avg_logprob": -0.10332517001939856, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0020968171302229166}, {"id": 98, "seek": 71008, "start": 717.12, "end": 723.2, "text": " everything that I want in my cluster. At this point, I'm just telling Dask a configuration of", "tokens": [50716, 1203, 300, 286, 528, 294, 452, 13630, 13, 1711, 341, 935, 11, 286, 478, 445, 3585, 2846, 74, 257, 11694, 295, 51020], "temperature": 0.0, "avg_logprob": -0.10332517001939856, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0020968171302229166}, {"id": 99, "seek": 71008, "start": 723.84, "end": 729.44, "text": " what to ask to the queuing system every time that I want computing resources. So in this case,", "tokens": [51052, 437, 281, 1029, 281, 264, 631, 9635, 1185, 633, 565, 300, 286, 528, 15866, 3593, 13, 407, 294, 341, 1389, 11, 51332], "temperature": 0.0, "avg_logprob": -0.10332517001939856, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0020968171302229166}, {"id": 100, "seek": 71008, "start": 729.44, "end": 736.96, "text": " I'm saying every time they just submit, just in this single job, submit, ask for one process", "tokens": [51332, 286, 478, 1566, 633, 565, 436, 445, 10315, 11, 445, 294, 341, 2167, 1691, 11, 10315, 11, 1029, 337, 472, 1399, 51708], "temperature": 0.0, "avg_logprob": -0.10332517001939856, "compression_ratio": 1.6940639269406392, "no_speech_prob": 0.0020968171302229166}, {"id": 101, "seek": 73696, "start": 736.96, "end": 745.6800000000001, "text": " and one thread and 100 gigabytes of memory. And once that is done, you can minority scale it by", "tokens": [50364, 293, 472, 7207, 293, 2319, 42741, 295, 4675, 13, 400, 1564, 300, 307, 1096, 11, 291, 393, 16166, 4373, 309, 538, 50800], "temperature": 0.0, "avg_logprob": -0.13108104663890796, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0021433932706713676}, {"id": 102, "seek": 73696, "start": 745.6800000000001, "end": 751.52, "text": " basically saying just scale to 10 nodes, in this case, that corresponds to 10 Dask workers.", "tokens": [50800, 1936, 1566, 445, 4373, 281, 1266, 13891, 11, 294, 341, 1389, 11, 300, 23249, 281, 1266, 2846, 74, 5600, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13108104663890796, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0021433932706713676}, {"id": 103, "seek": 73696, "start": 752.24, "end": 758.72, "text": " Or you could actually tell it to scale adaptively by saying, okay, I want you to,", "tokens": [51128, 1610, 291, 727, 767, 980, 309, 281, 4373, 6231, 3413, 538, 1566, 11, 1392, 11, 286, 528, 291, 281, 11, 51452], "temperature": 0.0, "avg_logprob": -0.13108104663890796, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0021433932706713676}, {"id": 104, "seek": 73696, "start": 759.84, "end": 764.48, "text": " at all time, to have a minimum of one Dask worker, and you can scale between one", "tokens": [51508, 412, 439, 565, 11, 281, 362, 257, 7285, 295, 472, 2846, 74, 11346, 11, 293, 291, 393, 4373, 1296, 472, 51740], "temperature": 0.0, "avg_logprob": -0.13108104663890796, "compression_ratio": 1.6055045871559632, "no_speech_prob": 0.0021433932706713676}, {"id": 105, "seek": 76448, "start": 764.48, "end": 771.04, "text": " and 100 Dask workers. And Dask will basically monitor your usage of your CPU usage or your", "tokens": [50364, 293, 2319, 2846, 74, 5600, 13, 400, 2846, 74, 486, 1936, 6002, 428, 14924, 295, 428, 13199, 14924, 420, 428, 50692], "temperature": 0.0, "avg_logprob": -0.1305807873054787, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.0002605118206702173}, {"id": 106, "seek": 76448, "start": 771.04, "end": 774.96, "text": " memory usage, and then it will know that it should get more resources. And at any point,", "tokens": [50692, 4675, 14924, 11, 293, 550, 309, 486, 458, 300, 309, 820, 483, 544, 3593, 13, 400, 412, 604, 935, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1305807873054787, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.0002605118206702173}, {"id": 107, "seek": 76448, "start": 774.96, "end": 780.08, "text": " if you're not using those resources, it will just tell the queuing system to kill those jobs.", "tokens": [50888, 498, 291, 434, 406, 1228, 729, 3593, 11, 309, 486, 445, 980, 264, 631, 9635, 1185, 281, 1961, 729, 4782, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1305807873054787, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.0002605118206702173}, {"id": 108, "seek": 76448, "start": 781.6, "end": 788.08, "text": " So if you're on a system that uses SLRM instead of PBS, it's the exact same thing with only one", "tokens": [51220, 407, 498, 291, 434, 322, 257, 1185, 300, 4960, 22999, 49, 44, 2602, 295, 33517, 11, 309, 311, 264, 1900, 912, 551, 365, 787, 472, 51544], "temperature": 0.0, "avg_logprob": -0.1305807873054787, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.0002605118206702173}, {"id": 109, "seek": 76448, "start": 788.08, "end": 791.84, "text": " difference of just using the SLRM cluster instead.", "tokens": [51544, 2649, 295, 445, 1228, 264, 22999, 49, 44, 13630, 2602, 13, 51732], "temperature": 0.0, "avg_logprob": -0.1305807873054787, "compression_ratio": 1.6935483870967742, "no_speech_prob": 0.0002605118206702173}, {"id": 110, "seek": 79448, "start": 794.8000000000001, "end": 802.8000000000001, "text": " Okay, so now let's go back to Tributor and actually see what Alice is actually doing in that notebook.", "tokens": [50380, 1033, 11, 370, 586, 718, 311, 352, 646, 281, 23304, 22163, 293, 767, 536, 437, 16004, 307, 767, 884, 294, 300, 21060, 13, 50780], "temperature": 0.0, "avg_logprob": -0.10693797020063009, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.0004787653451785445}, {"id": 111, "seek": 79448, "start": 806.88, "end": 812.72, "text": " Okay, so there's so much science going on in these notebooks, I won't really spend so much", "tokens": [50984, 1033, 11, 370, 456, 311, 370, 709, 3497, 516, 322, 294, 613, 43782, 11, 286, 1582, 380, 534, 3496, 370, 709, 51276], "temperature": 0.0, "avg_logprob": -0.10693797020063009, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.0004787653451785445}, {"id": 112, "seek": 79448, "start": 812.72, "end": 818.88, "text": " time going through the details about it. But if you're interested, there's a copy of this notebook", "tokens": [51276, 565, 516, 807, 264, 4365, 466, 309, 13, 583, 498, 291, 434, 3102, 11, 456, 311, 257, 5055, 295, 341, 21060, 51584], "temperature": 0.0, "avg_logprob": -0.10693797020063009, "compression_ratio": 1.5956284153005464, "no_speech_prob": 0.0004787653451785445}, {"id": 113, "seek": 81888, "start": 818.88, "end": 826.0, "text": " that you can actually run in the cloud. It's actually exact same copy. So if you go to the", "tokens": [50364, 300, 291, 393, 767, 1190, 294, 264, 4588, 13, 467, 311, 767, 1900, 912, 5055, 13, 407, 498, 291, 352, 281, 264, 50720], "temperature": 0.0, "avg_logprob": -0.1414686340883554, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.001976545201614499}, {"id": 114, "seek": 81888, "start": 826.0, "end": 832.32, "text": " Panjio data GitHub organization and just go to the Panjio tutorial, you should see", "tokens": [50720, 7557, 73, 1004, 1412, 23331, 4475, 293, 445, 352, 281, 264, 7557, 73, 1004, 7073, 11, 291, 820, 536, 51036], "temperature": 0.0, "avg_logprob": -0.1414686340883554, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.001976545201614499}, {"id": 115, "seek": 81888, "start": 833.6, "end": 840.88, "text": " one of these notebooks there. But I'm going to focus on a particular data set here,", "tokens": [51100, 472, 295, 613, 43782, 456, 13, 583, 286, 478, 516, 281, 1879, 322, 257, 1729, 1412, 992, 510, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1414686340883554, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.001976545201614499}, {"id": 116, "seek": 81888, "start": 840.88, "end": 846.4, "text": " which is the grid ensemble precipitation and temperature estimates over the contiguous", "tokens": [51464, 597, 307, 264, 10748, 19492, 37662, 293, 4292, 20561, 670, 264, 660, 30525, 51740], "temperature": 0.0, "avg_logprob": -0.1414686340883554, "compression_ratio": 1.5707762557077625, "no_speech_prob": 0.001976545201614499}, {"id": 117, "seek": 84640, "start": 846.4, "end": 853.92, "text": " United States. So this consists of 100 ensemble members for precipitation and temperature data.", "tokens": [50364, 2824, 3040, 13, 407, 341, 14689, 295, 2319, 19492, 2679, 337, 37662, 293, 4292, 1412, 13, 50740], "temperature": 0.0, "avg_logprob": -0.17148799431033251, "compression_ratio": 1.312, "no_speech_prob": 0.0007293170201592147}, {"id": 118, "seek": 84640, "start": 855.04, "end": 859.1999999999999, "text": " So the first thing that I do, I input some packages.", "tokens": [50796, 407, 264, 700, 551, 300, 286, 360, 11, 286, 4846, 512, 17401, 13, 51004], "temperature": 0.0, "avg_logprob": -0.17148799431033251, "compression_ratio": 1.312, "no_speech_prob": 0.0007293170201592147}, {"id": 119, "seek": 84640, "start": 865.12, "end": 865.84, "text": " Is this better?", "tokens": [51300, 1119, 341, 1101, 30, 51336], "temperature": 0.0, "avg_logprob": -0.17148799431033251, "compression_ratio": 1.312, "no_speech_prob": 0.0007293170201592147}, {"id": 120, "seek": 86584, "start": 865.9200000000001, "end": 873.2, "text": " Okay, good. So the next thing that I do, I now", "tokens": [50368, 1033, 11, 665, 13, 407, 264, 958, 551, 300, 286, 360, 11, 286, 586, 50732], "temperature": 0.0, "avg_logprob": -0.20594641470140027, "compression_ratio": 1.3625730994152048, "no_speech_prob": 0.0009096662979573011}, {"id": 121, "seek": 86584, "start": 874.96, "end": 881.84, "text": " create my cluster object by telling that job queue that I want 109 gigabytes of memory,", "tokens": [50820, 1884, 452, 13630, 2657, 538, 3585, 300, 1691, 18639, 300, 286, 528, 1266, 24, 42741, 295, 4675, 11, 51164], "temperature": 0.0, "avg_logprob": -0.20594641470140027, "compression_ratio": 1.3625730994152048, "no_speech_prob": 0.0009096662979573011}, {"id": 122, "seek": 86584, "start": 882.8000000000001, "end": 892.4000000000001, "text": " 36 threads and 36 processes, specify the queue and the wall time. And I tell Dask to scale between", "tokens": [51212, 8652, 19314, 293, 8652, 7555, 11, 16500, 264, 18639, 293, 264, 2929, 565, 13, 400, 286, 980, 2846, 74, 281, 4373, 1296, 51692], "temperature": 0.0, "avg_logprob": -0.20594641470140027, "compression_ratio": 1.3625730994152048, "no_speech_prob": 0.0009096662979573011}, {"id": 123, "seek": 89240, "start": 892.64, "end": 902.88, "text": " 360 Dask workers. And I don't know what that is, but you get just so. And when I click on this,", "tokens": [50376, 13898, 2846, 74, 5600, 13, 400, 286, 500, 380, 458, 437, 300, 307, 11, 457, 291, 483, 445, 370, 13, 400, 562, 286, 2052, 322, 341, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1683889389038086, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0011640790617093444}, {"id": 124, "seek": 89240, "start": 902.88, "end": 910.48, "text": " as you can see, at this point, Dask is submitting a bunch of, Dask job queue, submitting a bunch", "tokens": [50888, 382, 291, 393, 536, 11, 412, 341, 935, 11, 2846, 74, 307, 31836, 257, 3840, 295, 11, 2846, 74, 1691, 18639, 11, 31836, 257, 3840, 51268], "temperature": 0.0, "avg_logprob": -0.1683889389038086, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0011640790617093444}, {"id": 125, "seek": 89240, "start": 910.48, "end": 919.04, "text": " of jobs to the queuing system. And now I'm not trying to get into workers. So as you can see,", "tokens": [51268, 295, 4782, 281, 264, 631, 9635, 1185, 13, 400, 586, 286, 478, 406, 1382, 281, 483, 666, 5600, 13, 407, 382, 291, 393, 536, 11, 51696], "temperature": 0.0, "avg_logprob": -0.1683889389038086, "compression_ratio": 1.6342857142857143, "no_speech_prob": 0.0011640790617093444}, {"id": 126, "seek": 91904, "start": 919.04, "end": 927.68, "text": " I have thrown a 60 workers as I specified. Let me bring up the dashboard here.", "tokens": [50364, 286, 362, 11732, 257, 4060, 5600, 382, 286, 22206, 13, 961, 385, 1565, 493, 264, 18342, 510, 13, 50796], "temperature": 0.0, "avg_logprob": -0.31562089920043945, "compression_ratio": 1.0918367346938775, "no_speech_prob": 0.011103573255240917}, {"id": 127, "seek": 91904, "start": 940.4, "end": 942.7199999999999, "text": " Okay, let me one more thing.", "tokens": [51432, 1033, 11, 718, 385, 472, 544, 551, 13, 51548], "temperature": 0.0, "avg_logprob": -0.31562089920043945, "compression_ratio": 1.0918367346938775, "no_speech_prob": 0.011103573255240917}, {"id": 128, "seek": 94272, "start": 943.6800000000001, "end": 956.5600000000001, "text": " Okay. So now, now I can actually start doing the computation. So but the first thing I'm going to", "tokens": [50412, 1033, 13, 407, 586, 11, 586, 286, 393, 767, 722, 884, 264, 24903, 13, 407, 457, 264, 700, 551, 286, 478, 516, 281, 51056], "temperature": 0.0, "avg_logprob": -0.20565846501564494, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0004647847090382129}, {"id": 129, "seek": 94272, "start": 956.5600000000001, "end": 963.9200000000001, "text": " do is actually connect my client to the remote workers. So I have a cluster with 100 with one", "tokens": [51056, 360, 307, 767, 1745, 452, 6423, 281, 264, 8607, 5600, 13, 407, 286, 362, 257, 13630, 365, 2319, 365, 472, 51424], "temperature": 0.0, "avg_logprob": -0.20565846501564494, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0004647847090382129}, {"id": 130, "seek": 96392, "start": 963.92, "end": 973.5999999999999, "text": " terabyte of memory and 360 workers. So the dataset is saved in stored as in ZAR format. So", "tokens": [50364, 1796, 34529, 295, 4675, 293, 13898, 5600, 13, 407, 264, 28872, 307, 6624, 294, 12187, 382, 294, 1176, 1899, 7877, 13, 407, 50848], "temperature": 0.0, "avg_logprob": -0.19171090395945423, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.005035017617046833}, {"id": 131, "seek": 96392, "start": 973.5999999999999, "end": 982.4, "text": " there was a talk two days ago about ZAR. If you've never had about ZAR, recommend to go and check", "tokens": [50848, 456, 390, 257, 751, 732, 1708, 2057, 466, 1176, 1899, 13, 759, 291, 600, 1128, 632, 466, 1176, 1899, 11, 2748, 281, 352, 293, 1520, 51288], "temperature": 0.0, "avg_logprob": -0.19171090395945423, "compression_ratio": 1.3333333333333333, "no_speech_prob": 0.005035017617046833}, {"id": 132, "seek": 98240, "start": 982.48, "end": 998.24, "text": " it out. And I use XR8 to open this ZAR store. Again, just took 187 milliseconds. I didn't", "tokens": [50368, 309, 484, 13, 400, 286, 764, 1783, 49, 23, 281, 1269, 341, 1176, 1899, 3531, 13, 3764, 11, 445, 1890, 2443, 22, 34184, 13, 286, 994, 380, 51156], "temperature": 0.0, "avg_logprob": -0.17856507931115492, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0038755328860133886}, {"id": 133, "seek": 98240, "start": 998.24, "end": 1003.36, "text": " really do anything other than just looking at the metadata. So we can look at the size of the", "tokens": [51156, 534, 360, 1340, 661, 813, 445, 1237, 412, 264, 26603, 13, 407, 321, 393, 574, 412, 264, 2744, 295, 264, 51412], "temperature": 0.0, "avg_logprob": -0.17856507931115492, "compression_ratio": 1.3071428571428572, "no_speech_prob": 0.0038755328860133886}, {"id": 134, "seek": 100336, "start": 1003.36, "end": 1015.12, "text": " dataset. It's close to 1.7 terabyte. Can look at some metadata. So we have precipitation as one", "tokens": [50364, 28872, 13, 467, 311, 1998, 281, 502, 13, 22, 1796, 34529, 13, 1664, 574, 412, 512, 26603, 13, 407, 321, 362, 37662, 382, 472, 50952], "temperature": 0.0, "avg_logprob": -0.12260075690041125, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.0029782007914036512}, {"id": 135, "seek": 100336, "start": 1015.12, "end": 1022.4, "text": " of our variable, the mean temperature and the temperature range. And these are all 40 variables.", "tokens": [50952, 295, 527, 7006, 11, 264, 914, 4292, 293, 264, 4292, 3613, 13, 400, 613, 366, 439, 3356, 9102, 13, 51316], "temperature": 0.0, "avg_logprob": -0.12260075690041125, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.0029782007914036512}, {"id": 136, "seek": 100336, "start": 1022.4, "end": 1030.16, "text": " So 100 ensemble members for these many days, which corresponds to close to 40 years, I think,", "tokens": [51316, 407, 2319, 19492, 2679, 337, 613, 867, 1708, 11, 597, 23249, 281, 1998, 281, 3356, 924, 11, 286, 519, 11, 51704], "temperature": 0.0, "avg_logprob": -0.12260075690041125, "compression_ratio": 1.5132275132275133, "no_speech_prob": 0.0029782007914036512}, {"id": 137, "seek": 103016, "start": 1030.24, "end": 1036.5600000000002, "text": " of data. And if you wanted to, you could actually look at the Dask array. If you actually wanted", "tokens": [50368, 295, 1412, 13, 400, 498, 291, 1415, 281, 11, 291, 727, 767, 574, 412, 264, 2846, 74, 10225, 13, 759, 291, 767, 1415, 50684], "temperature": 0.0, "avg_logprob": -0.09405040740966797, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.0033594691194593906}, {"id": 138, "seek": 103016, "start": 1036.5600000000002, "end": 1043.1200000000001, "text": " to look at the shape and things like that, if this is more useful to you. So the first thing I'm", "tokens": [50684, 281, 574, 412, 264, 3909, 293, 721, 411, 300, 11, 498, 341, 307, 544, 4420, 281, 291, 13, 407, 264, 700, 551, 286, 478, 51012], "temperature": 0.0, "avg_logprob": -0.09405040740966797, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.0033594691194593906}, {"id": 139, "seek": 103016, "start": 1043.1200000000001, "end": 1051.0400000000002, "text": " going to do is actually just do a quick plot for the elevation. This is basically a mask that tells", "tokens": [51012, 516, 281, 360, 307, 767, 445, 360, 257, 1702, 7542, 337, 264, 25827, 13, 639, 307, 1936, 257, 6094, 300, 5112, 51408], "temperature": 0.0, "avg_logprob": -0.09405040740966797, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.0033594691194593906}, {"id": 140, "seek": 103016, "start": 1051.0400000000002, "end": 1057.52, "text": " me the elevation for each of the grid points. And as you can see, towards the west coast,", "tokens": [51408, 385, 264, 25827, 337, 1184, 295, 264, 10748, 2793, 13, 400, 382, 291, 393, 536, 11, 3030, 264, 7009, 8684, 11, 51732], "temperature": 0.0, "avg_logprob": -0.09405040740966797, "compression_ratio": 1.7252252252252251, "no_speech_prob": 0.0033594691194593906}, {"id": 141, "seek": 105752, "start": 1057.52, "end": 1062.4, "text": " you have points with higher elevation compared to the east coast of the country.", "tokens": [50364, 291, 362, 2793, 365, 2946, 25827, 5347, 281, 264, 10648, 8684, 295, 264, 1941, 13, 50608], "temperature": 0.0, "avg_logprob": -0.08424861090523857, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.0004840849433094263}, {"id": 142, "seek": 105752, "start": 1063.6, "end": 1069.6, "text": " So let's now try to quantify the ensemble uncertainty for a single day. So just select the", "tokens": [50668, 407, 718, 311, 586, 853, 281, 40421, 264, 19492, 15697, 337, 257, 2167, 786, 13, 407, 445, 3048, 264, 50968], "temperature": 0.0, "avg_logprob": -0.08424861090523857, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.0004840849433094263}, {"id": 143, "seek": 105752, "start": 1069.6, "end": 1080.08, "text": " data for one day and try to quantify the uncertainty for that one day. Again, this just goes very", "tokens": [50968, 1412, 337, 472, 786, 293, 853, 281, 40421, 264, 15697, 337, 300, 472, 786, 13, 3764, 11, 341, 445, 1709, 588, 51492], "temperature": 0.0, "avg_logprob": -0.08424861090523857, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.0004840849433094263}, {"id": 144, "seek": 105752, "start": 1080.08, "end": 1086.56, "text": " fast. Nothing really happened there other than just that Dask constructed the task graph. And when", "tokens": [51492, 2370, 13, 6693, 534, 2011, 456, 661, 813, 445, 300, 2846, 74, 17083, 264, 5633, 4295, 13, 400, 562, 51816], "temperature": 0.0, "avg_logprob": -0.08424861090523857, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.0004840849433094263}, {"id": 145, "seek": 108656, "start": 1086.56, "end": 1092.8799999999999, "text": " I do the plotting, that's when actually the computation gets triggered. Then I have my plot", "tokens": [50364, 286, 360, 264, 41178, 11, 300, 311, 562, 767, 264, 24903, 2170, 21710, 13, 1396, 286, 362, 452, 7542, 50680], "temperature": 0.0, "avg_logprob": -0.08719327351818346, "compression_ratio": 1.5, "no_speech_prob": 0.0006220961222425103}, {"id": 146, "seek": 108656, "start": 1092.8799999999999, "end": 1102.8, "text": " here. And again, I won't go into the details about the science. So the next task, let's try to", "tokens": [50680, 510, 13, 400, 797, 11, 286, 1582, 380, 352, 666, 264, 4365, 466, 264, 3497, 13, 407, 264, 958, 5633, 11, 718, 311, 853, 281, 51176], "temperature": 0.0, "avg_logprob": -0.08719327351818346, "compression_ratio": 1.5, "no_speech_prob": 0.0006220961222425103}, {"id": 147, "seek": 108656, "start": 1102.8, "end": 1113.04, "text": " compute the intra ensemble range. Again, as you can see, this just returns quickly. But this is", "tokens": [51176, 14722, 264, 43358, 19492, 3613, 13, 3764, 11, 382, 291, 393, 536, 11, 341, 445, 11247, 2661, 13, 583, 341, 307, 51688], "temperature": 0.0, "avg_logprob": -0.08719327351818346, "compression_ratio": 1.5, "no_speech_prob": 0.0006220961222425103}, {"id": 148, "seek": 111304, "start": 1113.04, "end": 1120.56, "text": " actually a delayed operation or a lazy operation. And now I can actually tell Dask to do the", "tokens": [50364, 767, 257, 20268, 6916, 420, 257, 14847, 6916, 13, 400, 586, 286, 393, 767, 980, 2846, 74, 281, 360, 264, 50740], "temperature": 0.0, "avg_logprob": -0.12154576995156029, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.003959335386753082}, {"id": 149, "seek": 111304, "start": 1120.56, "end": 1131.2, "text": " computation. So now you can actually start seeing some activity here. This should be done anytime", "tokens": [50740, 24903, 13, 407, 586, 291, 393, 767, 722, 2577, 512, 5191, 510, 13, 639, 820, 312, 1096, 13038, 51272], "temperature": 0.0, "avg_logprob": -0.12154576995156029, "compression_ratio": 1.450381679389313, "no_speech_prob": 0.003959335386753082}, {"id": 150, "seek": 113120, "start": 1132.16, "end": 1147.28, "text": " soon. Okay, so this has to do with Dask resiliency in that if, for instance, Dask tries to do a", "tokens": [50412, 2321, 13, 1033, 11, 370, 341, 575, 281, 360, 365, 2846, 74, 48712, 294, 300, 498, 11, 337, 5197, 11, 2846, 74, 9898, 281, 360, 257, 51168], "temperature": 0.0, "avg_logprob": -0.16945967307457557, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.012057998217642307}, {"id": 151, "seek": 113120, "start": 1147.28, "end": 1156.32, "text": " computation and it fails, it would start marking that computation. And I think by default, if it", "tokens": [51168, 24903, 293, 309, 18199, 11, 309, 576, 722, 25482, 300, 24903, 13, 400, 286, 519, 538, 7576, 11, 498, 309, 51620], "temperature": 0.0, "avg_logprob": -0.16945967307457557, "compression_ratio": 1.391304347826087, "no_speech_prob": 0.012057998217642307}, {"id": 152, "seek": 115632, "start": 1156.32, "end": 1162.32, "text": " tries three times and hasn't actually been able to successfully complete that computation, Dask", "tokens": [50364, 9898, 1045, 1413, 293, 6132, 380, 767, 668, 1075, 281, 10727, 3566, 300, 24903, 11, 2846, 74, 50664], "temperature": 0.0, "avg_logprob": -0.0996688778480787, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0012499757576733828}, {"id": 153, "seek": 115632, "start": 1162.32, "end": 1168.24, "text": " would just give up on that particular computation. So you could actually specify how many times you", "tokens": [50664, 576, 445, 976, 493, 322, 300, 1729, 24903, 13, 407, 291, 727, 767, 16500, 577, 867, 1413, 291, 50960], "temperature": 0.0, "avg_logprob": -0.0996688778480787, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0012499757576733828}, {"id": 154, "seek": 115632, "start": 1168.24, "end": 1173.76, "text": " want Dask to try. Like, for instance, if a task was scheduled on a worker and the worker dies,", "tokens": [50960, 528, 2846, 74, 281, 853, 13, 1743, 11, 337, 5197, 11, 498, 257, 5633, 390, 15678, 322, 257, 11346, 293, 264, 11346, 2714, 11, 51236], "temperature": 0.0, "avg_logprob": -0.0996688778480787, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0012499757576733828}, {"id": 155, "seek": 115632, "start": 1173.76, "end": 1179.12, "text": " what to do? Or if you run out of memory or things like that. So this is basically", "tokens": [51236, 437, 281, 360, 30, 1610, 498, 291, 1190, 484, 295, 4675, 420, 721, 411, 300, 13, 407, 341, 307, 1936, 51504], "temperature": 0.0, "avg_logprob": -0.0996688778480787, "compression_ratio": 1.5897435897435896, "no_speech_prob": 0.0012499757576733828}, {"id": 156, "seek": 117912, "start": 1179.12, "end": 1188.1599999999999, "text": " a cool feature of Dask, the resilience of Dask. So the computation finished. We can actually do", "tokens": [50364, 257, 1627, 4111, 295, 2846, 74, 11, 264, 19980, 295, 2846, 74, 13, 407, 264, 24903, 4335, 13, 492, 393, 767, 360, 50816], "temperature": 0.0, "avg_logprob": -0.17202741622924805, "compression_ratio": 1.3941605839416058, "no_speech_prob": 0.0008278833120130002}, {"id": 157, "seek": 117912, "start": 1188.1599999999999, "end": 1201.4399999999998, "text": " some plotting here. Okay, again, not that many details about science. So the next task is let's", "tokens": [50816, 512, 41178, 510, 13, 1033, 11, 797, 11, 406, 300, 867, 4365, 466, 3497, 13, 407, 264, 958, 5633, 307, 718, 311, 51480], "temperature": 0.0, "avg_logprob": -0.17202741622924805, "compression_ratio": 1.3941605839416058, "no_speech_prob": 0.0008278833120130002}, {"id": 158, "seek": 120144, "start": 1201.44, "end": 1213.2, "text": " try to compute the average seasonal fall, a snowfall. In this case, we're actually just computing on", "tokens": [50364, 853, 281, 14722, 264, 4274, 27421, 2100, 11, 257, 5756, 6691, 13, 682, 341, 1389, 11, 321, 434, 767, 445, 15866, 322, 50952], "temperature": 0.0, "avg_logprob": -0.13191058143736825, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0017548184841871262}, {"id": 159, "seek": 120144, "start": 1213.2, "end": 1222.64, "text": " only four ensemble members. So if you go through the distributed documentation, there's a really", "tokens": [50952, 787, 1451, 19492, 2679, 13, 407, 498, 291, 352, 807, 264, 12631, 14333, 11, 456, 311, 257, 534, 51424], "temperature": 0.0, "avg_logprob": -0.13191058143736825, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0017548184841871262}, {"id": 160, "seek": 120144, "start": 1224.8, "end": 1230.48, "text": " cool information about how to interpret the dashboard here, the information about the dashboard.", "tokens": [51532, 1627, 1589, 466, 577, 281, 7302, 264, 18342, 510, 11, 264, 1589, 466, 264, 18342, 13, 51816], "temperature": 0.0, "avg_logprob": -0.13191058143736825, "compression_ratio": 1.5891891891891892, "no_speech_prob": 0.0017548184841871262}, {"id": 161, "seek": 123144, "start": 1231.52, "end": 1234.3200000000002, "text": " So this is done. Now we can do the plotting.", "tokens": [50368, 407, 341, 307, 1096, 13, 823, 321, 393, 360, 264, 41178, 13, 50508], "temperature": 0.0, "avg_logprob": -0.09775137901306152, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.000550592434592545}, {"id": 162, "seek": 123144, "start": 1240.56, "end": 1248.56, "text": " It's going to take a few seconds. And as you can see, so as the year progresses,", "tokens": [50820, 467, 311, 516, 281, 747, 257, 1326, 3949, 13, 400, 382, 291, 393, 536, 11, 370, 382, 264, 1064, 41929, 11, 51220], "temperature": 0.0, "avg_logprob": -0.09775137901306152, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.000550592434592545}, {"id": 163, "seek": 123144, "start": 1248.56, "end": 1255.04, "text": " so the amount of snowfall decreases. And I think this is in the summer, you don't even have any", "tokens": [51220, 370, 264, 2372, 295, 5756, 6691, 24108, 13, 400, 286, 519, 341, 307, 294, 264, 4266, 11, 291, 500, 380, 754, 362, 604, 51544], "temperature": 0.0, "avg_logprob": -0.09775137901306152, "compression_ratio": 1.4258064516129032, "no_speech_prob": 0.000550592434592545}, {"id": 164, "seek": 125504, "start": 1255.04, "end": 1262.24, "text": " at all in most part of the country. And this is consistent across the four ensemble members", "tokens": [50364, 412, 439, 294, 881, 644, 295, 264, 1941, 13, 400, 341, 307, 8398, 2108, 264, 1451, 19492, 2679, 50724], "temperature": 0.0, "avg_logprob": -0.0943768752945794, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0007279517594724894}, {"id": 165, "seek": 125504, "start": 1262.24, "end": 1270.56, "text": " that we're looking at. So let's now actually do something cool. Let's actually look at like a", "tokens": [50724, 300, 321, 434, 1237, 412, 13, 407, 718, 311, 586, 767, 360, 746, 1627, 13, 961, 311, 767, 574, 412, 411, 257, 51140], "temperature": 0.0, "avg_logprob": -0.0943768752945794, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0007279517594724894}, {"id": 166, "seek": 125504, "start": 1270.56, "end": 1280.08, "text": " specific region. In this case, let's just look at all the grid points near Austin. So XRA is really", "tokens": [51140, 2685, 4458, 13, 682, 341, 1389, 11, 718, 311, 445, 574, 412, 439, 264, 10748, 2793, 2651, 15356, 13, 407, 1783, 3750, 307, 534, 51616], "temperature": 0.0, "avg_logprob": -0.0943768752945794, "compression_ratio": 1.4921465968586387, "no_speech_prob": 0.0007279517594724894}, {"id": 167, "seek": 128008, "start": 1280.08, "end": 1285.1999999999998, "text": " cool in that you can just give it the coordinates of the points you're interested in. In this case,", "tokens": [50364, 1627, 294, 300, 291, 393, 445, 976, 309, 264, 21056, 295, 264, 2793, 291, 434, 3102, 294, 13, 682, 341, 1389, 11, 50620], "temperature": 0.0, "avg_logprob": -0.062489908035487346, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0019474526634439826}, {"id": 168, "seek": 128008, "start": 1285.1999999999998, "end": 1291.76, "text": " we provide a buffer so that we can actually get all the grid points in that range. And we're going", "tokens": [50620, 321, 2893, 257, 21762, 370, 300, 321, 393, 767, 483, 439, 264, 10748, 2793, 294, 300, 3613, 13, 400, 321, 434, 516, 50948], "temperature": 0.0, "avg_logprob": -0.062489908035487346, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0019474526634439826}, {"id": 169, "seek": 128008, "start": 1291.76, "end": 1304.08, "text": " to compute the maximum precipitation near Austin for the last 40 years. So it's going to take a few", "tokens": [50948, 281, 14722, 264, 6674, 37662, 2651, 15356, 337, 264, 1036, 3356, 924, 13, 407, 309, 311, 516, 281, 747, 257, 1326, 51564], "temperature": 0.0, "avg_logprob": -0.062489908035487346, "compression_ratio": 1.5360824742268042, "no_speech_prob": 0.0019474526634439826}, {"id": 170, "seek": 130408, "start": 1304.96, "end": 1322.8, "text": " seconds. And then we can do the plotting once this is done. So again,", "tokens": [50408, 3949, 13, 400, 550, 321, 393, 360, 264, 41178, 1564, 341, 307, 1096, 13, 407, 797, 11, 51300], "temperature": 0.0, "avg_logprob": -0.32654898507254465, "compression_ratio": 0.9857142857142858, "no_speech_prob": 0.0025426470674574375}, {"id": 171, "seek": 132280, "start": 1322.8, "end": 1334.3999999999999, "text": " we can look at our cluster object. I still have 360 workers. I could have started with", "tokens": [50364, 321, 393, 574, 412, 527, 13630, 2657, 13, 286, 920, 362, 13898, 5600, 13, 286, 727, 362, 1409, 365, 50944], "temperature": 0.0, "avg_logprob": -0.11726508728445392, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.002282239031046629}, {"id": 172, "seek": 132280, "start": 1334.3999999999999, "end": 1340.6399999999999, "text": " something really small, but it's just that I wanted this to go really fast. And you never know how", "tokens": [50944, 746, 534, 1359, 11, 457, 309, 311, 445, 300, 286, 1415, 341, 281, 352, 534, 2370, 13, 400, 291, 1128, 458, 577, 51256], "temperature": 0.0, "avg_logprob": -0.11726508728445392, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.002282239031046629}, {"id": 173, "seek": 132280, "start": 1340.6399999999999, "end": 1345.44, "text": " busy the queuing system is going to be. So if you need the resources, you get them when you can.", "tokens": [51256, 5856, 264, 631, 9635, 1185, 307, 516, 281, 312, 13, 407, 498, 291, 643, 264, 3593, 11, 291, 483, 552, 562, 291, 393, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11726508728445392, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.002282239031046629}, {"id": 174, "seek": 134544, "start": 1346.0, "end": 1355.1200000000001, "text": " Okay, so this should be done. And basically, so this is the maximum precipitation near", "tokens": [50392, 1033, 11, 370, 341, 820, 312, 1096, 13, 400, 1936, 11, 370, 341, 307, 264, 6674, 37662, 2651, 50848], "temperature": 0.0, "avg_logprob": -0.1361168818687325, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0009345582220703363}, {"id": 175, "seek": 134544, "start": 1355.8400000000001, "end": 1364.48, "text": " Austin, Texas for the 100 ensemble members for the last 40 years. So you could basically look at", "tokens": [50884, 15356, 11, 7885, 337, 264, 2319, 19492, 2679, 337, 264, 1036, 3356, 924, 13, 407, 291, 727, 1936, 574, 412, 51316], "temperature": 0.0, "avg_logprob": -0.1361168818687325, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0009345582220703363}, {"id": 176, "seek": 134544, "start": 1366.8, "end": 1372.72, "text": " what that looked like. So yeah, so at this point, if I basically don't do anything,", "tokens": [51432, 437, 300, 2956, 411, 13, 407, 1338, 11, 370, 412, 341, 935, 11, 498, 286, 1936, 500, 380, 360, 1340, 11, 51728], "temperature": 0.0, "avg_logprob": -0.1361168818687325, "compression_ratio": 1.4916201117318435, "no_speech_prob": 0.0009345582220703363}, {"id": 177, "seek": 137272, "start": 1372.72, "end": 1378.32, "text": " because I told us that I want a minimum of 360 workers, it would just keep those resources. But", "tokens": [50364, 570, 286, 1907, 505, 300, 286, 528, 257, 7285, 295, 13898, 5600, 11, 309, 576, 445, 1066, 729, 3593, 13, 583, 50644], "temperature": 0.0, "avg_logprob": -0.13898543444546788, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0009393301443196833}, {"id": 178, "seek": 137272, "start": 1379.3600000000001, "end": 1384.48, "text": " instead, you could actually now that I'm done with this, I can actually do", "tokens": [50696, 2602, 11, 291, 727, 767, 586, 300, 286, 478, 1096, 365, 341, 11, 286, 393, 767, 360, 50952], "temperature": 0.0, "avg_logprob": -0.13898543444546788, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0009393301443196833}, {"id": 179, "seek": 137272, "start": 1390.88, "end": 1392.88, "text": " let me just tell it to scale down to", "tokens": [51272, 718, 385, 445, 980, 309, 281, 4373, 760, 281, 51372], "temperature": 0.0, "avg_logprob": -0.13898543444546788, "compression_ratio": 1.389261744966443, "no_speech_prob": 0.0009393301443196833}, {"id": 180, "seek": 139288, "start": 1393.0400000000002, "end": 1403.8400000000001, "text": " this. And basically, what that's going to do is going to start monitoring the workers. And if I'm", "tokens": [50372, 341, 13, 400, 1936, 11, 437, 300, 311, 516, 281, 360, 307, 516, 281, 722, 11028, 264, 5600, 13, 400, 498, 286, 478, 50912], "temperature": 0.0, "avg_logprob": -0.16773409843444825, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0011310667032375932}, {"id": 181, "seek": 139288, "start": 1403.8400000000001, "end": 1409.0400000000002, "text": " not using them, we'll just take them away. So I will come back to this later to show you what I mean", "tokens": [50912, 406, 1228, 552, 11, 321, 603, 445, 747, 552, 1314, 13, 407, 286, 486, 808, 646, 281, 341, 1780, 281, 855, 291, 437, 286, 914, 51172], "temperature": 0.0, "avg_logprob": -0.16773409843444825, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0011310667032375932}, {"id": 182, "seek": 139288, "start": 1409.0400000000002, "end": 1419.2, "text": " by that. Okay, so, so we've seen, or at least I try to demonstrate the adaptive or the elastic", "tokens": [51172, 538, 300, 13, 1033, 11, 370, 11, 370, 321, 600, 1612, 11, 420, 412, 1935, 286, 853, 281, 11698, 264, 27912, 420, 264, 17115, 51680], "temperature": 0.0, "avg_logprob": -0.16773409843444825, "compression_ratio": 1.5340314136125655, "no_speech_prob": 0.0011310667032375932}, {"id": 183, "seek": 141920, "start": 1419.2, "end": 1425.76, "text": " scaling and the resiliency of dusk. And let's now talk about some of the challenges. So being", "tokens": [50364, 21589, 293, 264, 48712, 295, 14284, 74, 13, 400, 718, 311, 586, 751, 466, 512, 295, 264, 4759, 13, 407, 885, 50692], "temperature": 0.0, "avg_logprob": -0.11968188687979457, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000961913145147264}, {"id": 184, "seek": 141920, "start": 1425.76, "end": 1430.4, "text": " able to know how much resources you need before actually doing the computation is really hard.", "tokens": [50692, 1075, 281, 458, 577, 709, 3593, 291, 643, 949, 767, 884, 264, 24903, 307, 534, 1152, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11968188687979457, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000961913145147264}, {"id": 185, "seek": 141920, "start": 1430.4, "end": 1436.72, "text": " And they actually requires quite a lot of experimentation. And if you actually get to", "tokens": [50924, 400, 436, 767, 7029, 1596, 257, 688, 295, 37142, 13, 400, 498, 291, 767, 483, 281, 51240], "temperature": 0.0, "avg_logprob": -0.11968188687979457, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000961913145147264}, {"id": 186, "seek": 141920, "start": 1436.72, "end": 1442.0, "text": " know how to do this for one particular workflow, it probably changes once you move to a different", "tokens": [51240, 458, 577, 281, 360, 341, 337, 472, 1729, 20993, 11, 309, 1391, 2962, 1564, 291, 1286, 281, 257, 819, 51504], "temperature": 0.0, "avg_logprob": -0.11968188687979457, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.000961913145147264}, {"id": 187, "seek": 144200, "start": 1442.0, "end": 1448.24, "text": " dataset. So, and another thing is that the computation, the computational workloads, they", "tokens": [50364, 28872, 13, 407, 11, 293, 1071, 551, 307, 300, 264, 24903, 11, 264, 28270, 32452, 11, 436, 50676], "temperature": 0.0, "avg_logprob": -0.12792505536760604, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0015662660589441657}, {"id": 188, "seek": 144200, "start": 1448.24, "end": 1452.72, "text": " don't really are not really constant. So you probably started with one terabyte of data.", "tokens": [50676, 500, 380, 534, 366, 406, 534, 5754, 13, 407, 291, 1391, 1409, 365, 472, 1796, 34529, 295, 1412, 13, 50900], "temperature": 0.0, "avg_logprob": -0.12792505536760604, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0015662660589441657}, {"id": 189, "seek": 144200, "start": 1453.36, "end": 1458.8, "text": " Five minutes later, you probably only have one gig of data left. At that point, you don't really", "tokens": [50932, 9436, 2077, 1780, 11, 291, 1391, 787, 362, 472, 8741, 295, 1412, 1411, 13, 1711, 300, 935, 11, 291, 500, 380, 534, 51204], "temperature": 0.0, "avg_logprob": -0.12792505536760604, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0015662660589441657}, {"id": 190, "seek": 144200, "start": 1458.8, "end": 1462.64, "text": " need all the resources that you started with when you when you're dealing with one terabyte of data.", "tokens": [51204, 643, 439, 264, 3593, 300, 291, 1409, 365, 562, 291, 562, 291, 434, 6260, 365, 472, 1796, 34529, 295, 1412, 13, 51396], "temperature": 0.0, "avg_logprob": -0.12792505536760604, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0015662660589441657}, {"id": 191, "seek": 144200, "start": 1463.2, "end": 1470.08, "text": " So the good thing is that dusk thinks about these things. So how to scale up and down,", "tokens": [51424, 407, 264, 665, 551, 307, 300, 14284, 74, 7309, 466, 613, 721, 13, 407, 577, 281, 4373, 493, 293, 760, 11, 51768], "temperature": 0.0, "avg_logprob": -0.12792505536760604, "compression_ratio": 1.9211618257261411, "no_speech_prob": 0.0015662660589441657}, {"id": 192, "seek": 147008, "start": 1470.08, "end": 1475.52, "text": " how to be resilient in case like a worker dies, and what if when you get new workers,", "tokens": [50364, 577, 281, 312, 23699, 294, 1389, 411, 257, 11346, 2714, 11, 293, 437, 498, 562, 291, 483, 777, 5600, 11, 50636], "temperature": 0.0, "avg_logprob": -0.11309741735458374, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0008257513400167227}, {"id": 193, "seek": 147008, "start": 1475.52, "end": 1478.56, "text": " what to do in terms of load balancing and things like that.", "tokens": [50636, 437, 281, 360, 294, 2115, 295, 3677, 22495, 293, 721, 411, 300, 13, 50788], "temperature": 0.0, "avg_logprob": -0.11309741735458374, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0008257513400167227}, {"id": 194, "seek": 147008, "start": 1480.32, "end": 1484.0, "text": " So what is the solution? Basically just start a Jupyter notebook,", "tokens": [50876, 407, 437, 307, 264, 3827, 30, 8537, 445, 722, 257, 22125, 88, 391, 21060, 11, 51060], "temperature": 0.0, "avg_logprob": -0.11309741735458374, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0008257513400167227}, {"id": 195, "seek": 147008, "start": 1484.8, "end": 1490.48, "text": " instantiate your dusk cluster, and then just let dusk do the scaling up and down for you.", "tokens": [51100, 9836, 13024, 428, 14284, 74, 13630, 11, 293, 550, 445, 718, 14284, 74, 360, 264, 21589, 493, 293, 760, 337, 291, 13, 51384], "temperature": 0.0, "avg_logprob": -0.11309741735458374, "compression_ratio": 1.5677083333333333, "no_speech_prob": 0.0008257513400167227}, {"id": 196, "seek": 149048, "start": 1490.48, "end": 1501.92, "text": " And you just focus on the science. And what are the benefits to HPC systems for elastic scaling?", "tokens": [50364, 400, 291, 445, 1879, 322, 264, 3497, 13, 400, 437, 366, 264, 5311, 281, 12557, 34, 3652, 337, 17115, 21589, 30, 50936], "temperature": 0.0, "avg_logprob": -0.12203390458050896, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0017974238144233823}, {"id": 197, "seek": 149048, "start": 1502.8, "end": 1508.24, "text": " One of them is that it actually improves the occupancy of the machine in that if the resources", "tokens": [50980, 1485, 295, 552, 307, 300, 309, 767, 24771, 264, 8073, 6717, 295, 264, 3479, 294, 300, 498, 264, 3593, 51252], "temperature": 0.0, "avg_logprob": -0.12203390458050896, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0017974238144233823}, {"id": 198, "seek": 149048, "start": 1508.24, "end": 1513.52, "text": " are idle, then dusk knows how to release them so that other users can actually use them.", "tokens": [51252, 366, 30650, 11, 550, 14284, 74, 3255, 577, 281, 4374, 552, 370, 300, 661, 5022, 393, 767, 764, 552, 13, 51516], "temperature": 0.0, "avg_logprob": -0.12203390458050896, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0017974238144233823}, {"id": 199, "seek": 151352, "start": 1513.84, "end": 1521.12, "text": " And another thing is that with the resiliency, you can easily, for instance, if you started", "tokens": [50380, 400, 1071, 551, 307, 300, 365, 264, 48712, 11, 291, 393, 3612, 11, 337, 5197, 11, 498, 291, 1409, 50744], "temperature": 0.0, "avg_logprob": -0.16509707287104444, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.0017327567329630256}, {"id": 200, "seek": 151352, "start": 1521.12, "end": 1528.08, "text": " with 120 workers, for some reason, your worker dies, dusk will know how to get a new worker.", "tokens": [50744, 365, 10411, 5600, 11, 337, 512, 1778, 11, 428, 11346, 2714, 11, 14284, 74, 486, 458, 577, 281, 483, 257, 777, 11346, 13, 51092], "temperature": 0.0, "avg_logprob": -0.16509707287104444, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.0017327567329630256}, {"id": 201, "seek": 151352, "start": 1528.08, "end": 1533.28, "text": " And in a way, if you think about something like MPI where you start, let's say you have like 120", "tokens": [51092, 400, 294, 257, 636, 11, 498, 291, 519, 466, 746, 411, 14146, 40, 689, 291, 722, 11, 718, 311, 584, 291, 362, 411, 10411, 51352], "temperature": 0.0, "avg_logprob": -0.16509707287104444, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.0017327567329630256}, {"id": 202, "seek": 151352, "start": 1536.0, "end": 1542.08, "text": " workers, if one thing goes wrong in an MPI environment, the whole thing dies. So in a way,", "tokens": [51488, 5600, 11, 498, 472, 551, 1709, 2085, 294, 364, 14146, 40, 2823, 11, 264, 1379, 551, 2714, 13, 407, 294, 257, 636, 11, 51792], "temperature": 0.0, "avg_logprob": -0.16509707287104444, "compression_ratio": 1.6832579185520362, "no_speech_prob": 0.0017327567329630256}, {"id": 203, "seek": 154208, "start": 1542.08, "end": 1546.48, "text": " you kind of lose all the work that you had done, which is probably not that nice.", "tokens": [50364, 291, 733, 295, 3624, 439, 264, 589, 300, 291, 632, 1096, 11, 597, 307, 1391, 406, 300, 1481, 13, 50584], "temperature": 0.0, "avg_logprob": -0.1385723352432251, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0005815631593577564}, {"id": 204, "seek": 154208, "start": 1547.52, "end": 1555.1999999999998, "text": " So basically, another thing, to the same point, dusk thinks about these things.", "tokens": [50636, 407, 1936, 11, 1071, 551, 11, 281, 264, 912, 935, 11, 14284, 74, 7309, 466, 613, 721, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1385723352432251, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0005815631593577564}, {"id": 205, "seek": 154208, "start": 1555.1999999999998, "end": 1560.32, "text": " And I think you should also think about what you get from this as well.", "tokens": [51020, 400, 286, 519, 291, 820, 611, 519, 466, 437, 291, 483, 490, 341, 382, 731, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1385723352432251, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0005815631593577564}, {"id": 206, "seek": 154208, "start": 1561.6799999999998, "end": 1566.48, "text": " Again, so not all jobs are interactive. So once you're done with your interactive", "tokens": [51344, 3764, 11, 370, 406, 439, 4782, 366, 15141, 13, 407, 1564, 291, 434, 1096, 365, 428, 15141, 51584], "temperature": 0.0, "avg_logprob": -0.1385723352432251, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.0005815631593577564}, {"id": 207, "seek": 156648, "start": 1566.48, "end": 1572.64, "text": " workflows, there's this other package called dusk MPI, which actually now allows you to go on and", "tokens": [50364, 43461, 11, 456, 311, 341, 661, 7372, 1219, 14284, 74, 14146, 40, 11, 597, 767, 586, 4045, 291, 281, 352, 322, 293, 50672], "temperature": 0.0, "avg_logprob": -0.1801405530987364, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.002261764369904995}, {"id": 208, "seek": 156648, "start": 1572.64, "end": 1579.3600000000001, "text": " actually launch but jobs in case you don't need to do interactive exploration.", "tokens": [50672, 767, 4025, 457, 4782, 294, 1389, 291, 500, 380, 643, 281, 360, 15141, 16197, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1801405530987364, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.002261764369904995}, {"id": 209, "seek": 156648, "start": 1580.64, "end": 1596.32, "text": " And looks like I'm running out of time. So that is pretty much it for today. Thank you.", "tokens": [51072, 400, 1542, 411, 286, 478, 2614, 484, 295, 565, 13, 407, 300, 307, 1238, 709, 309, 337, 965, 13, 1044, 291, 13, 51856], "temperature": 0.0, "avg_logprob": -0.1801405530987364, "compression_ratio": 1.3894736842105264, "no_speech_prob": 0.002261764369904995}, {"id": 210, "seek": 159648, "start": 1597.2, "end": 1601.84, "text": " And like I said, now you can see that it took away those resources.", "tokens": [50400, 400, 411, 286, 848, 11, 586, 291, 393, 536, 300, 309, 1890, 1314, 729, 3593, 13, 50632], "temperature": 0.0, "avg_logprob": -0.30534596876664594, "compression_ratio": 1.2, "no_speech_prob": 0.0009065469494089484}, {"id": 211, "seek": 159648, "start": 1604.72, "end": 1605.52, "text": " Okay, so here we go.", "tokens": [50776, 1033, 11, 370, 510, 321, 352, 13, 50816], "temperature": 0.0, "avg_logprob": -0.30534596876664594, "compression_ratio": 1.2, "no_speech_prob": 0.0009065469494089484}, {"id": 212, "seek": 159648, "start": 1613.1200000000001, "end": 1616.48, "text": " Let's try here. So do we have any more questions?", "tokens": [51196, 961, 311, 853, 510, 13, 407, 360, 321, 362, 604, 544, 1651, 30, 51364], "temperature": 0.0, "avg_logprob": -0.30534596876664594, "compression_ratio": 1.2, "no_speech_prob": 0.0009065469494089484}, {"id": 213, "seek": 161648, "start": 1616.48, "end": 1630.64, "text": " Hi, great talk. How do you deal with large datasets? And if you need to import like large", "tokens": [50364, 2421, 11, 869, 751, 13, 1012, 360, 291, 2028, 365, 2416, 42856, 30, 400, 498, 291, 643, 281, 974, 411, 2416, 51072], "temperature": 0.0, "avg_logprob": -0.2135490689958845, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.001775733195245266}, {"id": 214, "seek": 161648, "start": 1630.64, "end": 1634.08, "text": " datasets, can you do it? Can you put them on the cluster?", "tokens": [51072, 42856, 11, 393, 291, 360, 309, 30, 1664, 291, 829, 552, 322, 264, 13630, 30, 51244], "temperature": 0.0, "avg_logprob": -0.2135490689958845, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.001775733195245266}, {"id": 215, "seek": 161648, "start": 1636.32, "end": 1643.84, "text": " So in this case, the Trubeta Hub is actually running on the same file system.", "tokens": [51356, 407, 294, 341, 1389, 11, 264, 1765, 836, 7664, 18986, 307, 767, 2614, 322, 264, 912, 3991, 1185, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2135490689958845, "compression_ratio": 1.4610389610389611, "no_speech_prob": 0.001775733195245266}, {"id": 216, "seek": 164384, "start": 1644.08, "end": 1650.24, "text": " So which basically means that we don't need to move the data around. So in our case,", "tokens": [50376, 407, 597, 1936, 1355, 300, 321, 500, 380, 643, 281, 1286, 264, 1412, 926, 13, 407, 294, 527, 1389, 11, 50684], "temperature": 0.0, "avg_logprob": -0.12557280858357747, "compression_ratio": 1.8429319371727748, "no_speech_prob": 0.0030782746616750956}, {"id": 217, "seek": 164384, "start": 1650.24, "end": 1655.28, "text": " it kind of works in that basically we're moving the computation where the data is.", "tokens": [50684, 309, 733, 295, 1985, 294, 300, 1936, 321, 434, 2684, 264, 24903, 689, 264, 1412, 307, 13, 50936], "temperature": 0.0, "avg_logprob": -0.12557280858357747, "compression_ratio": 1.8429319371727748, "no_speech_prob": 0.0030782746616750956}, {"id": 218, "seek": 164384, "start": 1655.28, "end": 1661.6799999999998, "text": " So we don't need to move the data around. So I haven't run into cases where we need", "tokens": [50936, 407, 321, 500, 380, 643, 281, 1286, 264, 1412, 926, 13, 407, 286, 2378, 380, 1190, 666, 3331, 689, 321, 643, 51256], "temperature": 0.0, "avg_logprob": -0.12557280858357747, "compression_ratio": 1.8429319371727748, "no_speech_prob": 0.0030782746616750956}, {"id": 219, "seek": 164384, "start": 1661.6799999999998, "end": 1669.04, "text": " to move the data. So if anybody has run into that, then they could probably provide a better answer.", "tokens": [51256, 281, 1286, 264, 1412, 13, 407, 498, 4472, 575, 1190, 666, 300, 11, 550, 436, 727, 1391, 2893, 257, 1101, 1867, 13, 51624], "temperature": 0.0, "avg_logprob": -0.12557280858357747, "compression_ratio": 1.8429319371727748, "no_speech_prob": 0.0030782746616750956}, {"id": 220, "seek": 166904, "start": 1669.52, "end": 1672.72, "text": " Other questions?", "tokens": [50388, 5358, 1651, 30, 50548], "temperature": 0.0, "avg_logprob": -0.3241272175565679, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.0016564502147957683}, {"id": 221, "seek": 166904, "start": 1680.72, "end": 1688.96, "text": " Yeah, it's the Trubeta Hub instance taking a pre-allocated resources like 20 loads,", "tokens": [50948, 865, 11, 309, 311, 264, 1765, 836, 7664, 18986, 5197, 1940, 257, 659, 12, 336, 905, 770, 3593, 411, 945, 12668, 11, 51360], "temperature": 0.0, "avg_logprob": -0.3241272175565679, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.0016564502147957683}, {"id": 222, "seek": 166904, "start": 1688.96, "end": 1691.92, "text": " and then you scale up and down inside the Trubeta Hub?", "tokens": [51360, 293, 550, 291, 4373, 493, 293, 760, 1854, 264, 1765, 836, 7664, 18986, 30, 51508], "temperature": 0.0, "avg_logprob": -0.3241272175565679, "compression_ratio": 1.28099173553719, "no_speech_prob": 0.0016564502147957683}, {"id": 223, "seek": 169192, "start": 1692.88, "end": 1700.8000000000002, "text": " No. So if you remember what I did when I logged in to the Trubeta Hub, I asked for I think just", "tokens": [50412, 883, 13, 407, 498, 291, 1604, 437, 286, 630, 562, 286, 27231, 294, 281, 264, 1765, 836, 7664, 18986, 11, 286, 2351, 337, 286, 519, 445, 50808], "temperature": 0.0, "avg_logprob": -0.13627418604764072, "compression_ratio": 1.5916230366492146, "no_speech_prob": 0.012347660027444363}, {"id": 224, "seek": 169192, "start": 1700.8000000000002, "end": 1706.16, "text": " one process. So Trubeta Hub is actually running, the lab itself is running in its own job.", "tokens": [50808, 472, 1399, 13, 407, 1765, 836, 7664, 18986, 307, 767, 2614, 11, 264, 2715, 2564, 307, 2614, 294, 1080, 1065, 1691, 13, 51076], "temperature": 0.0, "avg_logprob": -0.13627418604764072, "compression_ratio": 1.5916230366492146, "no_speech_prob": 0.012347660027444363}, {"id": 225, "seek": 169192, "start": 1707.2, "end": 1713.76, "text": " So when I do the scaling up and down, I'm actually doing that as independent jobs.", "tokens": [51128, 407, 562, 286, 360, 264, 21589, 493, 293, 760, 11, 286, 478, 767, 884, 300, 382, 6695, 4782, 13, 51456], "temperature": 0.0, "avg_logprob": -0.13627418604764072, "compression_ratio": 1.5916230366492146, "no_speech_prob": 0.012347660027444363}, {"id": 226, "seek": 169192, "start": 1714.5600000000002, "end": 1716.0800000000002, "text": " So that's why I'm able to do that.", "tokens": [51496, 407, 300, 311, 983, 286, 478, 1075, 281, 360, 300, 13, 51572], "temperature": 0.0, "avg_logprob": -0.13627418604764072, "compression_ratio": 1.5916230366492146, "no_speech_prob": 0.012347660027444363}, {"id": 227, "seek": 171608, "start": 1716.8, "end": 1722.3999999999999, "text": " But I mean scaling down is easy, but when you're trying to scale up, in our class, you need to", "tokens": [50400, 583, 286, 914, 21589, 760, 307, 1858, 11, 457, 562, 291, 434, 1382, 281, 4373, 493, 11, 294, 527, 1508, 11, 291, 643, 281, 50680], "temperature": 0.0, "avg_logprob": -0.14238461946186268, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0005315624875947833}, {"id": 228, "seek": 171608, "start": 1722.3999999999999, "end": 1729.36, "text": " wait 30 minutes to have a new job created for you. So yeah, that's what I say that when it comes to", "tokens": [50680, 1699, 2217, 2077, 281, 362, 257, 777, 1691, 2942, 337, 291, 13, 407, 1338, 11, 300, 311, 437, 286, 584, 300, 562, 309, 1487, 281, 51028], "temperature": 0.0, "avg_logprob": -0.14238461946186268, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0005315624875947833}, {"id": 229, "seek": 171608, "start": 1730.24, "end": 1737.36, "text": " queuing systems, I think that lack of elastic scaling kind of makes it hard to actually do", "tokens": [51072, 631, 9635, 3652, 11, 286, 519, 300, 5011, 295, 17115, 21589, 733, 295, 1669, 309, 1152, 281, 767, 360, 51428], "temperature": 0.0, "avg_logprob": -0.14238461946186268, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0005315624875947833}, {"id": 230, "seek": 171608, "start": 1737.36, "end": 1741.84, "text": " interactive computing in that you can't wait for two hours to get into the queue.", "tokens": [51428, 15141, 15866, 294, 300, 291, 393, 380, 1699, 337, 732, 2496, 281, 483, 666, 264, 18639, 13, 51652], "temperature": 0.0, "avg_logprob": -0.14238461946186268, "compression_ratio": 1.5956521739130434, "no_speech_prob": 0.0005315624875947833}, {"id": 231, "seek": 174184, "start": 1742.8, "end": 1745.6799999999998, "text": " In my case, I was able to get into the queue very easily because", "tokens": [50412, 682, 452, 1389, 11, 286, 390, 1075, 281, 483, 666, 264, 18639, 588, 3612, 570, 50556], "temperature": 0.0, "avg_logprob": -0.1599740982055664, "compression_ratio": 1.485, "no_speech_prob": 0.0027342536486685276}, {"id": 232, "seek": 174184, "start": 1746.9599999999998, "end": 1755.1999999999998, "text": " I had to ask a special reservation. So yeah.", "tokens": [50620, 286, 632, 281, 1029, 257, 2121, 28922, 13, 407, 1338, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1599740982055664, "compression_ratio": 1.485, "no_speech_prob": 0.0027342536486685276}, {"id": 233, "seek": 174184, "start": 1755.9199999999998, "end": 1758.8799999999999, "text": " All right, we're going to have a lot of people filing in and out here because we're changing", "tokens": [51068, 1057, 558, 11, 321, 434, 516, 281, 362, 257, 688, 295, 561, 26854, 294, 293, 484, 510, 570, 321, 434, 4473, 51216], "temperature": 0.0, "avg_logprob": -0.1599740982055664, "compression_ratio": 1.485, "no_speech_prob": 0.0027342536486685276}, {"id": 234, "seek": 174184, "start": 1758.8799999999999, "end": 1765.1999999999998, "text": " topics, so can we please thank Anderson again and all the speakers for the Geophysics Imposer.", "tokens": [51216, 8378, 11, 370, 393, 321, 1767, 1309, 18768, 797, 293, 439, 264, 9518, 337, 264, 2876, 5317, 41732, 8270, 22150, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1599740982055664, "compression_ratio": 1.485, "no_speech_prob": 0.0027342536486685276}], "language": "en"}