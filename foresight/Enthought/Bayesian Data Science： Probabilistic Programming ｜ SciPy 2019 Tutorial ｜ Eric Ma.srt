1
00:00:00,000 --> 00:00:02,960
Thank you all for coming to the tutorial.

2
00:00:02,960 --> 00:00:05,920
If you noticed in the SciPy program,

3
00:00:05,920 --> 00:00:08,320
there are three tutorials doing Bayes stuff.

4
00:00:08,320 --> 00:00:12,120
This is, I think, unprecedented in the SciPy tutorial

5
00:00:12,120 --> 00:00:14,160
program list.

6
00:00:14,160 --> 00:00:18,400
What happened was the three lead instructors, that

7
00:00:18,400 --> 00:00:22,200
is Alan Downey for his tutorial, myself and Hugo

8
00:00:22,200 --> 00:00:24,360
for this tutorial, and Ravine and Colin

9
00:00:24,360 --> 00:00:27,240
for the next tutorial on Bayesian modeling,

10
00:00:27,240 --> 00:00:29,840
we all decided to informally coordinate together

11
00:00:29,840 --> 00:00:32,160
to put this informal Bayes track thing.

12
00:00:32,160 --> 00:00:36,840
And I know that there are a few people who have actually

13
00:00:36,840 --> 00:00:38,600
registered for all three of them.

14
00:00:38,600 --> 00:00:42,880
So props to you guys, that handful of you.

15
00:00:42,880 --> 00:00:48,800
Anyone want to take an estimate on what fraction of this crowd?

16
00:00:48,800 --> 00:00:51,240
Did that?

17
00:00:51,240 --> 00:00:55,480
20%, which would mean about, let's see, 16 people-ish?

18
00:00:55,480 --> 00:00:56,360
15 people-ish?

19
00:00:56,360 --> 00:00:59,480
I think they're about 60 to 80 people registered in this room.

20
00:00:59,480 --> 00:01:00,440
Yeah, so OK.

21
00:01:00,440 --> 00:01:02,880
Yeah, I actually got the actual number from Jill.

22
00:01:02,880 --> 00:01:06,720
It's 15 of you, so it's a good, close estimate there.

23
00:01:06,720 --> 00:01:14,840
All right, so for the 15 of you who were in Alan's tutorial,

24
00:01:14,840 --> 00:01:18,320
some of this material will be familiar to you.

25
00:01:18,320 --> 00:01:21,800
And for the rest of you, we'll go through enough background

26
00:01:21,800 --> 00:01:24,080
to accomplish today's goals, which

27
00:01:24,080 --> 00:01:26,920
is to show you how you can write arbitrary statistical

28
00:01:26,920 --> 00:01:30,400
models and use them to perform inference.

29
00:01:30,400 --> 00:01:33,560
That's the end goal of today's tutorial.

30
00:01:33,560 --> 00:01:36,320
And there'll be a tool of choice, which is Pi MC3.

31
00:01:36,320 --> 00:01:38,560
We'll also show some things with NumPy.

32
00:01:38,560 --> 00:01:41,520
Hopefully that will give you enough grounding

33
00:01:41,520 --> 00:01:45,960
in probability, in Bayes rule, to then be

34
00:01:45,960 --> 00:01:48,520
able to talk about how our data were generated

35
00:01:48,520 --> 00:01:51,440
from a statistical standpoint and build those models

36
00:01:51,440 --> 00:01:54,840
and use them, use them productively.

37
00:01:54,840 --> 00:01:59,240
OK, some administrative matters before we move on.

38
00:01:59,240 --> 00:02:02,320
For those of you who are still not set up,

39
00:02:02,320 --> 00:02:04,480
I know that there's a high probability

40
00:02:04,480 --> 00:02:06,440
that you are set up, set up being defined

41
00:02:06,440 --> 00:02:08,960
as you either have Binder working

42
00:02:08,960 --> 00:02:10,760
or you have everything cloned locally

43
00:02:10,760 --> 00:02:13,200
and working on your laptop or on a remote server

44
00:02:13,200 --> 00:02:17,200
that you control, which is what I'm doing, by the way.

45
00:02:17,200 --> 00:02:20,080
So yes, I know what the feeling is like.

46
00:02:20,080 --> 00:02:25,040
So if you are set up and you're using Binder,

47
00:02:25,040 --> 00:02:27,400
remember every 15 minutes on the clock.

48
00:02:27,400 --> 00:02:30,800
So make sure you execute something in your notebooks

49
00:02:30,800 --> 00:02:34,440
because Binder sessions have a 20-minute timeout.

50
00:02:34,440 --> 00:02:37,360
If you are not already set up, go to the Read Me page.

51
00:02:37,360 --> 00:02:39,760
Go to the Read Me on the GitHub repository.

52
00:02:39,760 --> 00:02:41,840
Look for the Launch Binder button and hit it

53
00:02:41,840 --> 00:02:45,440
because you're going to not want to waste time with DevOps

54
00:02:45,440 --> 00:02:47,720
at this point.

55
00:02:47,720 --> 00:02:49,600
Cool.

56
00:02:49,600 --> 00:02:50,360
Let's see.

57
00:02:50,360 --> 00:02:54,400
We also have Ravine Kumar, who is one of the instructors

58
00:02:54,400 --> 00:02:56,360
for the next Bayes tutorial.

59
00:02:56,360 --> 00:03:00,280
He is helping out today and he'll be back in a few minutes.

60
00:03:00,280 --> 00:03:06,280
We can take a guess at a time that he'll be back.

61
00:03:06,280 --> 00:03:11,160
You'll notice I'm using a lot of these guess the time

62
00:03:11,160 --> 00:03:13,760
estimate that sort of terminology.

63
00:03:13,760 --> 00:03:18,520
It's very important that we've got both a theoretical view

64
00:03:18,520 --> 00:03:19,840
and a practical view on that.

65
00:03:19,840 --> 00:03:23,960
So hopefully today's tutorial will clarify that.

66
00:03:23,960 --> 00:03:26,120
OK.

67
00:03:26,120 --> 00:03:29,800
Before we go on, do people have any questions, any issues

68
00:03:29,800 --> 00:03:34,280
that they want to clarify, any things that are blocking them

69
00:03:34,280 --> 00:03:36,680
from doing today's tutorial?

70
00:03:36,680 --> 00:03:44,200
OK, if not, we're going to follow the agenda that's

71
00:03:44,200 --> 00:03:45,320
on the whiteboard.

72
00:03:45,320 --> 00:03:48,000
First off, we're going to do a recap on probability.

73
00:03:48,000 --> 00:03:50,760
Use some hands-on exercises to make sure

74
00:03:50,760 --> 00:03:53,320
that you've got a grasp on it.

75
00:03:53,320 --> 00:03:55,720
And then we'll recap what Bayes rule is.

76
00:03:55,720 --> 00:03:59,280
So for the 15 of you who were in Ellen's tutorial this morning,

77
00:03:59,280 --> 00:04:01,360
this should be familiar material.

78
00:04:01,360 --> 00:04:04,360
We won't do a full rigorous proof of Bayes rule.

79
00:04:04,360 --> 00:04:10,400
And we'll just make sure that everybody has a grasp on that.

80
00:04:10,400 --> 00:04:13,440
And it builds on top of the rules of conditional probability

81
00:04:13,440 --> 00:04:15,520
and joint probability.

82
00:04:15,520 --> 00:04:17,280
So once we're done with that, then

83
00:04:17,280 --> 00:04:21,240
we'll move on to what we would call the core activities

84
00:04:21,240 --> 00:04:25,960
of statistical inference, which is estimation.

85
00:04:25,960 --> 00:04:30,480
Estimation is the core of all statistical inference.

86
00:04:30,480 --> 00:04:31,880
Because we're in a Bayes tutorial,

87
00:04:31,880 --> 00:04:34,400
I'm going to go out on limb and saying calculating p values

88
00:04:34,400 --> 00:04:35,800
is not.

89
00:04:35,800 --> 00:04:37,920
Calculating p values is not the core activity.

90
00:04:37,920 --> 00:04:40,640
It's not even the point of statistical inference.

91
00:04:40,640 --> 00:04:42,880
So let's get that out of our heads.

92
00:04:42,880 --> 00:04:44,120
And then the final thing is we're

93
00:04:44,160 --> 00:04:51,240
going to show how the core activity of Bayesian statistical

94
00:04:51,240 --> 00:04:53,720
inference, which is Bayesian estimation, how that relates

95
00:04:53,720 --> 00:04:58,640
to things that we might have now already learned

96
00:04:58,640 --> 00:05:02,080
in our undergrad statistics or grad statistics classes, which

97
00:05:02,080 --> 00:05:04,680
is different forms of regression and the likes.

98
00:05:04,680 --> 00:05:08,200
And we'll do a short teaser on that.

99
00:05:08,200 --> 00:05:11,080
It's not the main point, because the main thing is really

100
00:05:11,120 --> 00:05:15,040
understanding estimation and how we build models that

101
00:05:15,040 --> 00:05:17,000
help us perform that.

102
00:05:17,000 --> 00:05:19,320
So with that, I'd like to invite everybody

103
00:05:19,320 --> 00:05:22,520
to open up your notebooks, fire up Jupiter,

104
00:05:22,520 --> 00:05:26,560
and open up notebook 1A.

105
00:05:26,560 --> 00:05:31,000
And then you'll notice that they always come in pairs.

106
00:05:31,000 --> 00:05:34,280
So there's a student version and an instructor version.

107
00:05:34,280 --> 00:05:39,280
And what I've decided, unlike my previous workshops,

108
00:05:39,280 --> 00:05:43,040
I'm going to live code with you.

109
00:05:43,040 --> 00:05:44,080
Not from memory, thankfully.

110
00:05:44,080 --> 00:05:45,520
I have a second computer here that

111
00:05:45,520 --> 00:05:49,200
tells me what the right answers are.

112
00:05:49,200 --> 00:05:53,680
You all, by the way, if you ever feel stuck on anything,

113
00:05:53,680 --> 00:05:56,280
the instructor versions of the notebooks are there for you.

114
00:05:56,280 --> 00:05:57,840
And that's the first time I'm going to say it,

115
00:05:57,840 --> 00:05:59,280
also the last time I'm going to say it.

116
00:05:59,280 --> 00:06:03,040
So if you're ever stuck, just open the instructor notebook.

117
00:06:03,040 --> 00:06:06,120
Don't hesitate to copy and paste the answers over.

118
00:06:06,120 --> 00:06:08,560
The point is understanding.

119
00:06:08,560 --> 00:06:10,520
Doing stuff helps with understanding.

120
00:06:10,520 --> 00:06:11,840
But if you get stuck doing stuff,

121
00:06:11,840 --> 00:06:14,400
it can lead to more frustration for learning

122
00:06:14,400 --> 00:06:15,720
than is productive.

123
00:06:15,720 --> 00:06:17,200
So at the end of the day, make sure you just

124
00:06:17,200 --> 00:06:20,080
have a good conceptual view, and that's good enough.

125
00:06:20,080 --> 00:06:23,520
All right, let's run the first cell

126
00:06:23,520 --> 00:06:27,520
and talk about what probability is.

127
00:06:27,520 --> 00:06:29,640
I had a few pop quiz questions just now.

128
00:06:29,640 --> 00:06:33,720
What's the probability that someone in this room,

129
00:06:33,720 --> 00:06:38,280
if you asked, would have a satisfying lunch today?

130
00:06:38,280 --> 00:06:40,680
And someone said, 75% of this room.

131
00:06:40,680 --> 00:06:41,640
That's another question.

132
00:06:41,640 --> 00:06:46,480
What is the probability that someone in this room

133
00:06:46,480 --> 00:06:49,360
has taken all three tutorials?

134
00:06:49,360 --> 00:06:50,720
All three Bayesian tutorials.

135
00:06:50,720 --> 00:06:53,400
And that's another question relating to probability.

136
00:06:53,400 --> 00:06:56,560
But I'd like to start by first asking the question a little

137
00:06:56,560 --> 00:06:58,320
bit more meta-level.

138
00:06:58,320 --> 00:07:01,320
What is probability?

139
00:07:01,680 --> 00:07:06,840
You have a volunteer, and I know no one's going to answer.

140
00:07:06,840 --> 00:07:09,840
So I would like you to do is talk with your partner

141
00:07:09,840 --> 00:07:13,960
for about 30 seconds to a minute, not 30 minutes.

142
00:07:13,960 --> 00:07:15,280
30 seconds to a minute.

143
00:07:15,280 --> 00:07:16,440
Introduce yourself.

144
00:07:16,440 --> 00:07:18,000
Network a little bit.

145
00:07:18,000 --> 00:07:21,680
And ask, what is probability?

146
00:07:21,680 --> 00:07:26,960
OK, so hopefully you all know each other a little better.

147
00:07:26,960 --> 00:07:29,320
Those of you who've been in the network analysis tutorials

148
00:07:29,320 --> 00:07:30,640
that I've done know this trick.

149
00:07:30,640 --> 00:07:32,520
This is the networking trick.

150
00:07:32,520 --> 00:07:36,640
Let's you build your network while you're in a tutorial room.

151
00:07:36,640 --> 00:07:42,840
So do we have volunteers to share maybe a stab at the question?

152
00:07:42,840 --> 00:07:45,640
What would you define probability as?

153
00:07:45,640 --> 00:07:48,080
We know some properties of probability, right?

154
00:07:48,080 --> 00:07:52,080
Someone said it must be bound from 0 to 1.

155
00:07:52,080 --> 00:07:53,240
What else?

156
00:07:53,240 --> 00:07:55,360
What other things about probability do you know?

157
00:07:55,680 --> 00:08:06,720
Volunteers, back there, a symbolic expression

158
00:08:06,720 --> 00:08:07,400
of uncertainty.

159
00:08:07,400 --> 00:08:11,000
Would you like to unpack that for us a little bit?

160
00:08:11,000 --> 00:08:12,080
No?

161
00:08:12,080 --> 00:08:15,120
All right, so then I'm supposed to do a stab at that, right?

162
00:08:15,120 --> 00:08:17,360
OK, let me ponder that.

163
00:08:17,360 --> 00:08:18,040
Do we have another?

164
00:08:19,040 --> 00:08:23,880
Something.

165
00:08:23,880 --> 00:08:24,480
Something.

166
00:08:24,480 --> 00:08:26,440
OK, yeah, yeah, OK, cool.

167
00:08:30,560 --> 00:08:33,520
Degree of belief, yep, yep, OK.

168
00:08:33,520 --> 00:08:34,000
Mark?

169
00:08:48,840 --> 00:09:02,800
Yeah, yep, OK, right, yep, OK.

170
00:09:02,800 --> 00:09:03,520
Anything else?

171
00:09:03,520 --> 00:09:06,320
Anybody else has a definition they'd like to contribute?

172
00:09:09,840 --> 00:09:10,320
Pardon me?

173
00:09:16,720 --> 00:09:18,000
Ah, OK, yeah, all right.

174
00:09:19,040 --> 00:09:26,040
Cool, right, so what I'm hearing are essentially

175
00:09:26,040 --> 00:09:29,640
the classical and the Bayesian, I refuse to say frequentist,

176
00:09:29,640 --> 00:09:31,680
the classical and the Bayesian ways

177
00:09:31,680 --> 00:09:34,960
of thinking about probability.

178
00:09:34,960 --> 00:09:37,880
Hugo, who made the first part of this tutorial,

179
00:09:37,880 --> 00:09:41,640
the material for the first part of this tutorial,

180
00:09:41,640 --> 00:09:43,400
found a really great quote.

181
00:09:43,400 --> 00:09:45,960
And it's inside your notebooks, and you'll see it, right?

182
00:09:45,960 --> 00:09:48,480
By data analysis, by severe and skilling.

183
00:09:48,480 --> 00:09:53,040
And there were essentially, historically,

184
00:09:53,040 --> 00:09:56,560
there was a shift in how probability was viewed.

185
00:09:56,560 --> 00:10:00,240
There was perhaps what we might call the first version that

186
00:10:00,240 --> 00:10:05,240
was formally recorded in European scientific history,

187
00:10:05,240 --> 00:10:10,440
which would be a degree of belief assigned to an outcome.

188
00:10:10,440 --> 00:10:15,800
And then there was then a shift because of views,

189
00:10:16,760 --> 00:10:19,080
foundational worldviews shifted.

190
00:10:19,080 --> 00:10:21,440
And so people thought of probability

191
00:10:21,440 --> 00:10:26,680
as more of the relative frequency with which things occurred,

192
00:10:26,680 --> 00:10:30,720
which then gave rise to the name that I refuse to mention.

193
00:10:30,720 --> 00:10:35,040
And because these frequencies can be measured,

194
00:10:35,040 --> 00:10:41,680
they then seemed to form an objective view of reality, right?

195
00:10:41,680 --> 00:10:44,680
I, on the other hand, don't subscribe to this view, right?

196
00:10:44,680 --> 00:10:47,800
I see probability defined.

197
00:10:47,800 --> 00:10:51,840
So there are formal definitions of probability.

198
00:10:51,840 --> 00:10:54,720
You get into these very technical mathematical terms

199
00:10:54,720 --> 00:10:59,880
that involve spaces and measure theory and the likes.

200
00:10:59,880 --> 00:11:04,840
The way that I prefer to, for day-to-day use of Bayesian

201
00:11:04,840 --> 00:11:07,880
methods and probability, I tend to think of probability

202
00:11:07,880 --> 00:11:11,560
as just being money assigned on a number line.

203
00:11:11,560 --> 00:11:13,920
If I gave you $100, how would you

204
00:11:13,920 --> 00:11:18,360
also assign that $100 to points on the number line

205
00:11:18,360 --> 00:11:19,560
if you were doing discrete things?

206
00:11:19,560 --> 00:11:22,480
Or how would you draw a curve that would say,

207
00:11:22,480 --> 00:11:26,160
assign how you would distribute money to the number line?

208
00:11:26,160 --> 00:11:27,560
Essentially, it's a measure of how much you're

209
00:11:27,560 --> 00:11:31,520
willing to bet that this thing will take on a particular value,

210
00:11:31,520 --> 00:11:33,360
this thing that you're interested in, right?

211
00:11:33,360 --> 00:11:36,000
So you can use money, or if you prefer not

212
00:11:36,000 --> 00:11:39,640
to gamble like myself, then I would just

213
00:11:39,640 --> 00:11:42,240
say credibility points assigned to the number line, right?

214
00:11:43,120 --> 00:11:45,360
Credibility points assigned to the number line

215
00:11:45,360 --> 00:11:47,880
gives us a view of probability that

216
00:11:47,880 --> 00:11:51,160
is a good enough working definition

217
00:11:51,160 --> 00:11:57,080
for how we can view probability in applied problems.

218
00:11:57,080 --> 00:12:03,240
So where do we want to then use probability as a tool?

219
00:12:03,240 --> 00:12:06,720
Once again, spend 30 seconds with your neighbors

220
00:12:06,720 --> 00:12:08,560
and talk about this.

221
00:12:08,560 --> 00:12:09,600
Let's gather back.

222
00:12:09,880 --> 00:12:13,680
I'd like to hear from those who haven't already raised their hands

223
00:12:13,680 --> 00:12:16,200
and contributed something to the discussion.

224
00:12:16,200 --> 00:12:20,880
Where would you use probability in an applied setting?

225
00:12:20,880 --> 00:12:21,720
At the back.

226
00:12:24,720 --> 00:12:25,720
OK.

227
00:12:25,720 --> 00:12:27,120
Did you elaborate on that, please?

228
00:12:31,120 --> 00:12:31,620
Right.

229
00:12:40,400 --> 00:12:41,680
Yes.

230
00:12:41,680 --> 00:12:42,880
Yeah, OK.

231
00:12:42,880 --> 00:12:44,520
Right, so probability is a tool for that.

232
00:12:44,520 --> 00:12:45,400
Next door neighbor.

233
00:12:48,720 --> 00:12:49,840
OK.

234
00:12:49,840 --> 00:12:50,800
Did you give an example?

235
00:13:01,680 --> 00:13:04,720
Right, so some key questions we might be interested in

236
00:13:04,720 --> 00:13:06,200
would be like, what's the probability

237
00:13:06,200 --> 00:13:10,520
of a catastrophic failure of that piece of infrastructure,

238
00:13:10,520 --> 00:13:12,080
for example, or something like that?

239
00:13:22,840 --> 00:13:25,640
Right, so calculation of, again, the probability

240
00:13:25,640 --> 00:13:27,800
of a catastrophic failure would be really important,

241
00:13:27,800 --> 00:13:31,880
and the probability that the safety mechanism would fail

242
00:13:31,880 --> 00:13:33,840
as well would be also important.

243
00:13:36,600 --> 00:13:50,840
Right, right, right, so you need to know the probability

244
00:13:50,840 --> 00:13:53,120
that the rate is equal to something

245
00:13:53,120 --> 00:13:54,600
plus the uncertainty on it.

246
00:13:54,600 --> 00:13:57,760
I'm very happy that we're going in a Bayesian direction here.

247
00:13:57,760 --> 00:13:59,560
OK, cool.

248
00:13:59,560 --> 00:14:04,920
Great, so if, say, we were, for example,

249
00:14:04,960 --> 00:14:09,040
in a marketing firm or a new tech firm,

250
00:14:09,040 --> 00:14:11,840
and we wanted to think about click-through rates, right?

251
00:14:11,840 --> 00:14:14,920
That's another place that probability comes into play,

252
00:14:14,920 --> 00:14:16,880
so another applied setting.

253
00:14:16,880 --> 00:14:19,560
And click-through rates are essentially

254
00:14:19,560 --> 00:14:22,360
measured as the probability that a user that arrives

255
00:14:22,360 --> 00:14:24,960
at your page will click on something, right?

256
00:14:24,960 --> 00:14:26,880
So that's another example.

257
00:14:26,880 --> 00:14:30,400
And that's the first example that we'll use here

258
00:14:30,400 --> 00:14:34,240
to get a practical handle on how we

259
00:14:34,240 --> 00:14:38,040
can use the existing tools in our toolkit.

260
00:14:38,040 --> 00:14:39,160
We probably know NumPy.

261
00:14:39,160 --> 00:14:41,800
We probably know a bit of pandas and the rest.

262
00:14:41,800 --> 00:14:42,800
NumPy, Matplotlib.

263
00:14:42,800 --> 00:14:48,240
We'll use NumPy to help us get a grasp on what exactly

264
00:14:48,240 --> 00:14:50,560
is probability, and how does it relate to proportions

265
00:14:50,560 --> 00:14:51,800
and the likes, OK?

266
00:14:51,800 --> 00:14:54,600
So let's say, let's try this example together.

267
00:14:54,600 --> 00:14:56,400
It's a code-along activity.

268
00:14:56,400 --> 00:15:00,000
Let's say we've got a website, and we've measured the click-through

269
00:15:00,000 --> 00:15:04,720
rate accurately to the ninth decimal place, right?

270
00:15:04,720 --> 00:15:09,360
So it's 50% accurately to the ninth decimal place.

271
00:15:09,360 --> 00:15:14,280
So what does that mean of the visitors that come by?

272
00:15:14,280 --> 00:15:17,400
So if we had 1,000 visitors, how many people

273
00:15:17,400 --> 00:15:21,160
would we expect to click on that button?

274
00:15:26,160 --> 00:15:27,160
Any volunteers?

275
00:15:27,160 --> 00:15:28,120
500, right?

276
00:15:28,160 --> 00:15:30,240
That's the expectation, right?

277
00:15:30,240 --> 00:15:31,640
We'll try to simulate that, OK?

278
00:15:31,640 --> 00:15:38,560
So if we have one way to simulate this kind of problem

279
00:15:38,560 --> 00:15:41,360
is to use NumPy, and to start, we'll

280
00:15:41,360 --> 00:15:44,840
take a uniform distribution, right?

281
00:15:44,840 --> 00:15:47,640
We'll start by saying, we've got a whole bunch of people.

282
00:15:47,640 --> 00:15:50,160
We don't know where they came from.

283
00:15:50,160 --> 00:15:54,200
And we'll simulate this process of clicking

284
00:15:54,200 --> 00:16:00,440
by taking 1,000 random numbers bounded between 0 and 1,

285
00:16:00,440 --> 00:16:04,720
and then cutting a threshold somewhere at 50%, right?

286
00:16:04,720 --> 00:16:11,160
So we'll do something like np.random.rand, 1,000.

287
00:16:11,160 --> 00:16:15,120
And what this will give us then is,

288
00:16:15,120 --> 00:16:20,240
if we plot the histogram of that, ooh, my kernel just died on me.

289
00:16:20,240 --> 00:16:21,960
Cool, all right?

290
00:16:21,960 --> 00:16:22,760
Let me try that again.

291
00:16:31,280 --> 00:16:32,840
We plot the histogram of that.

292
00:16:32,840 --> 00:16:35,760
You should get something that looks like this, right?

293
00:16:35,760 --> 00:16:40,520
So this is what we would call 1,000 draws

294
00:16:40,520 --> 00:16:43,440
with equal credibility assigned across the number line

295
00:16:43,440 --> 00:16:45,400
from 0 to 1.

296
00:16:45,400 --> 00:16:52,280
And to simulate how people click on the website,

297
00:16:52,280 --> 00:16:54,240
we can do a few things.

298
00:16:54,240 --> 00:17:02,000
We can do first ask how many of those values are below 0.5.

299
00:17:02,000 --> 00:17:05,880
And by definition, the rest are going to be above.

300
00:17:05,880 --> 00:17:11,920
And finally, simply sum up the total number of clicks

301
00:17:11,920 --> 00:17:12,720
that we get, right?

302
00:17:12,720 --> 00:17:19,160
We define clicks as a value being drawn from this distribution

303
00:17:19,160 --> 00:17:22,080
being less than 0.5, and then we simply sum it up.

304
00:17:22,080 --> 00:17:24,320
How many do people get?

305
00:17:24,320 --> 00:17:25,840
I get 481.

306
00:17:25,840 --> 00:17:27,720
What are the others?

307
00:17:27,720 --> 00:17:29,440
4, sorry?

308
00:17:29,440 --> 00:17:34,280
505, 478, et cetera.

309
00:17:34,280 --> 00:17:34,920
OK, cool.

310
00:17:34,920 --> 00:17:38,240
So we've got a variety of answers here.

311
00:17:38,240 --> 00:17:40,360
And this is one of the core ideas

312
00:17:40,360 --> 00:17:43,000
behind statistical inference.

313
00:17:43,000 --> 00:17:47,080
That is, there is always some form of randomness involved.

314
00:17:47,080 --> 00:17:50,520
And when there's some form of randomness involved,

315
00:17:50,520 --> 00:17:53,520
we will expect the answers.

316
00:17:53,520 --> 00:17:55,920
So we can calculate this thing called expectations.

317
00:17:55,920 --> 00:18:01,120
And we expect that, on average, from, say, a lot of us

318
00:18:01,120 --> 00:18:05,840
pooling our results together, the number of people who click

319
00:18:05,840 --> 00:18:12,320
will be centered around 500 at 0.5 out of 1,000.

320
00:18:12,320 --> 00:18:15,760
However, because of random effects and whatever else

321
00:18:15,760 --> 00:18:18,280
that goes on in the data generating process,

322
00:18:18,280 --> 00:18:21,160
we won't always get exactly 500.

323
00:18:21,160 --> 00:18:24,000
There's always some randomness involved.

324
00:18:24,000 --> 00:18:27,360
So then we can calculate the proportion

325
00:18:27,360 --> 00:18:34,080
that clicked as basically n clicks over length of clicks.

326
00:18:34,080 --> 00:18:35,760
And I will get 0.481.

327
00:18:35,760 --> 00:18:39,240
And you will get your 0.505s and whatever.

328
00:18:39,240 --> 00:18:45,720
So this is one of the, so one idea

329
00:18:45,720 --> 00:18:52,280
that we want to convey here is that in statistical inference,

330
00:18:52,280 --> 00:18:54,720
we're often talking about random processes, right?

331
00:18:54,720 --> 00:18:56,240
Things that are not deterministic.

332
00:18:56,240 --> 00:18:58,040
There's always a component that we

333
00:18:58,040 --> 00:19:02,280
don't know how to exactly write an equation to model exactly.

334
00:19:03,160 --> 00:19:06,720
And so what we do is we use a statistical model

335
00:19:06,720 --> 00:19:09,840
to help us get around this fact, right?

336
00:19:09,840 --> 00:19:13,600
And there's randomness built in inherently inside there.

337
00:19:13,600 --> 00:19:17,800
So all right, so what we did was we said

338
00:19:17,800 --> 00:19:21,400
we had a model, so-called model, of clicking

339
00:19:21,400 --> 00:19:24,400
in which we said half of the people who come will click.

340
00:19:24,400 --> 00:19:27,880
And then we drew samples from that model, right?

341
00:19:27,880 --> 00:19:31,360
Where we had our own, on our own computers,

342
00:19:31,360 --> 00:19:34,360
we had our own instantiations, our own realizations

343
00:19:34,360 --> 00:19:34,920
of that model.

344
00:19:34,920 --> 00:19:38,320
And there's some random effects that are inside there.

345
00:19:38,320 --> 00:19:43,160
OK, so what we'd like to do now is

346
00:19:43,160 --> 00:19:45,560
have you all do this on your own for the next two

347
00:19:45,560 --> 00:19:46,800
to three minutes.

348
00:19:46,800 --> 00:19:49,480
Try to simulate what the results will

349
00:19:49,480 --> 00:19:52,320
look like when you have a click through rate of 0.7 instead

350
00:19:52,320 --> 00:19:53,480
of 0.5, right?

351
00:19:53,480 --> 00:19:55,800
So spend a minute or two handling this.

352
00:19:55,800 --> 00:19:59,200
If you are ever stuck, you have lots of resources.

353
00:19:59,200 --> 00:20:00,200
You have your neighbors.

354
00:20:00,200 --> 00:20:01,760
So continue networking.

355
00:20:01,760 --> 00:20:04,320
If not, you also have the instructor notebook.

356
00:20:04,320 --> 00:20:05,600
And you have the screen, which I'm

357
00:20:05,600 --> 00:20:07,280
going to be typing on as well.

358
00:20:07,280 --> 00:20:11,000
Cool, so it'll look something like that.

359
00:20:11,000 --> 00:20:16,640
Once again, not everybody will have the same results, right?

360
00:20:16,640 --> 00:20:20,760
OK, so some numbers, just popcorn style this.

361
00:20:20,760 --> 00:20:25,880
703, 694, I have 708.

362
00:20:25,880 --> 00:20:28,640
What else?

363
00:20:28,680 --> 00:20:30,240
687, OK, cool.

364
00:20:30,240 --> 00:20:34,840
So we have what this forms is a distribution of numbers,

365
00:20:34,840 --> 00:20:36,840
realizations.

366
00:20:36,840 --> 00:20:41,760
Cool, this model that we've just simulated by hand

367
00:20:41,760 --> 00:20:45,120
is known as the biased coin flip.

368
00:20:45,120 --> 00:20:47,560
We know that the coin flip is the classic example

369
00:20:47,560 --> 00:20:51,000
that every probability tutorial has to deal with.

370
00:20:51,000 --> 00:20:53,800
The biased coin flip is just nothing more than a variant

371
00:20:53,800 --> 00:20:54,760
on that.

372
00:20:54,760 --> 00:20:57,120
Where else do you see biased coin flips happening?

373
00:20:59,040 --> 00:21:02,080
OK, talk with your neighbor, 30 seconds.

374
00:21:02,080 --> 00:21:04,520
Nobody will answer the first time on my first thing,

375
00:21:04,520 --> 00:21:07,000
so do we have volunteers?

376
00:21:07,000 --> 00:21:09,840
Where do we see the biased coin flip apart

377
00:21:09,840 --> 00:21:12,720
from click-through rates?

378
00:21:12,720 --> 00:21:13,920
Do we have a volunteer?

379
00:21:17,680 --> 00:21:18,160
Mark?

380
00:21:18,160 --> 00:21:18,660
Sorry.

381
00:21:18,660 --> 00:21:21,120
My example's kind of got limitations,

382
00:21:21,120 --> 00:21:24,560
but you're traveling on a tree, so traffic light will be

383
00:21:24,560 --> 00:21:30,640
a 70% priority, so the traffic light will be a 70% priority.

384
00:21:30,640 --> 00:21:33,880
Oh, OK, so if you looked at a junction,

385
00:21:33,880 --> 00:21:35,840
you can calculate the probability

386
00:21:35,840 --> 00:21:41,920
that the lights are favoring the main artery rather

387
00:21:41,920 --> 00:21:43,000
than the side arteries.

388
00:21:43,000 --> 00:21:45,240
OK, cool.

389
00:21:45,240 --> 00:21:46,600
A friend?

390
00:21:46,600 --> 00:21:49,000
Widget manufacturing.

391
00:21:49,000 --> 00:21:50,240
Can we talk about that?

392
00:21:50,680 --> 00:22:00,320
So you have a binary outcome, accepted or rejected?

393
00:22:00,320 --> 00:22:00,800
Where else?

394
00:22:00,800 --> 00:22:02,280
Back there.

395
00:22:02,280 --> 00:22:03,520
Is it at birth?

396
00:22:03,520 --> 00:22:07,280
Yeah, biological sex at birth, yes, exactly.

397
00:22:07,280 --> 00:22:10,800
So it's a binary situation for the vast majority

398
00:22:10,800 --> 00:22:13,360
of the population, so under that approximation,

399
00:22:13,360 --> 00:22:15,120
then what is it?

400
00:22:15,120 --> 00:22:19,320
The canonical is like 51% or 52% male, female, sorry,

401
00:22:19,320 --> 00:22:22,440
and slightly lower for male, right?

402
00:22:22,440 --> 00:22:22,960
Where else?

403
00:22:26,800 --> 00:22:30,320
All right, so I think the point is well described

404
00:22:30,320 --> 00:22:31,560
by these examples.

405
00:22:31,560 --> 00:22:34,960
There's a binary outcome that we're seeking to model,

406
00:22:34,960 --> 00:22:39,000
and the binary outcome sometimes is merely an approximation.

407
00:22:39,000 --> 00:22:43,600
The binary outcome is a useful, if it's a useful approximation,

408
00:22:43,600 --> 00:22:45,600
then we use that.

409
00:22:45,600 --> 00:22:48,040
We can use what we call the bias coin flip

410
00:22:48,040 --> 00:22:52,600
to model the process of generating the individual outcomes

411
00:22:52,600 --> 00:22:54,480
that we actually observe, right?

412
00:22:54,480 --> 00:22:56,360
OK, cool.

413
00:22:56,360 --> 00:22:58,080
Let's try a different example.

414
00:22:58,080 --> 00:23:01,960
So this example here was us basically

415
00:23:01,960 --> 00:23:06,720
hand coding the generative process in a very explicit

416
00:23:06,720 --> 00:23:10,000
fashion for what we would call the Bernoulli trials

417
00:23:10,000 --> 00:23:12,880
or binomial trials.

418
00:23:12,880 --> 00:23:14,720
We're going to try a different way, which

419
00:23:14,720 --> 00:23:17,320
is to actually look at real data and treat data

420
00:23:17,320 --> 00:23:22,120
as if they were the population, so to speak.

421
00:23:22,120 --> 00:23:25,840
As if the data that we measured were infinitely large enough,

422
00:23:25,840 --> 00:23:28,960
which is never true, but as an approximation,

423
00:23:28,960 --> 00:23:31,560
we'll start with that and ask, how can we

424
00:23:31,560 --> 00:23:33,760
calculate the probability of certain things

425
00:23:33,760 --> 00:23:36,960
under this assumption of the data being a really good

426
00:23:36,960 --> 00:23:38,840
approximation of ground truth?

427
00:23:38,840 --> 00:23:42,000
So what I'd like you to do is run this next cell.

428
00:23:42,000 --> 00:23:44,160
What this data set that we have here

429
00:23:44,160 --> 00:23:49,200
is Finch Beaks measured on Galapagos Islands, right?

430
00:23:49,200 --> 00:23:51,440
So how many of you have learned biology

431
00:23:51,440 --> 00:23:53,920
and have heard of the Finches before?

432
00:23:53,920 --> 00:23:54,840
Right, so there we go.

433
00:23:54,840 --> 00:23:59,440
We have another binary outcome right there.

434
00:23:59,440 --> 00:24:04,920
So in this, someone went to the Galapagos, a research team

435
00:24:04,920 --> 00:24:08,280
went to the Galapagos Islands and measured Finch Beaks,

436
00:24:08,280 --> 00:24:11,720
both their length and their depth, and asked,

437
00:24:11,720 --> 00:24:13,280
and just recorded what they were in.

438
00:24:13,280 --> 00:24:17,520
Let's assume that this is a realistic sample,

439
00:24:17,520 --> 00:24:20,440
a realistic approximation of the population of Finches

440
00:24:20,440 --> 00:24:21,880
that were observed.

441
00:24:21,880 --> 00:24:31,680
So let's grab out just the beak length, Th, as a Panda series.

442
00:24:31,680 --> 00:24:33,760
So follow along with that cell.

443
00:24:33,760 --> 00:24:36,280
And so what we'd like to ask is, what

444
00:24:36,280 --> 00:24:41,560
is the probability of a bird having a beak length greater

445
00:24:41,560 --> 00:24:43,000
than 10, right?

446
00:24:43,000 --> 00:24:45,920
So how would we calculate that?

447
00:24:45,920 --> 00:24:47,520
Well, one way we might calculate that

448
00:24:47,520 --> 00:24:51,320
is under the assumption that the data are the population,

449
00:24:51,320 --> 00:24:56,080
we could just ask what proportion of birds

450
00:24:56,080 --> 00:24:57,560
have beak lengths greater than 10.

451
00:24:57,560 --> 00:25:04,560
So we can do something like p is equal to the sum of lengths,

452
00:25:04,560 --> 00:25:12,120
Ths greater than 10 divided by the length of that.

453
00:25:12,120 --> 00:25:14,760
And you should get something close to,

454
00:25:14,760 --> 00:25:18,080
you should actually get this exact number in this case,

455
00:25:18,080 --> 00:25:19,920
because there's no randomness in the data.

456
00:25:19,920 --> 00:25:22,280
So we're not simulating the random process,

457
00:25:22,280 --> 00:25:25,160
we're treating the data as if they were the true thing.

458
00:25:25,160 --> 00:25:28,560
So everybody should get 0.851, right?

459
00:25:28,560 --> 00:25:29,600
Cool.

460
00:25:29,600 --> 00:25:32,960
So these two examples, they're really

461
00:25:32,960 --> 00:25:39,240
here to show you that proportions are somewhat

462
00:25:39,240 --> 00:25:41,360
a proxy for probability.

463
00:25:41,400 --> 00:25:43,760
Under certain circumstances, if you

464
00:25:43,760 --> 00:25:45,360
make explicit certain assumptions,

465
00:25:45,360 --> 00:25:47,920
your proportions can be a good estimator

466
00:25:47,920 --> 00:25:52,480
for the actual probability that we're interested in.

467
00:25:52,480 --> 00:26:06,520
All right, so over here, we can actually try simulating

468
00:26:06,520 --> 00:26:09,200
the finch beak lengths as well, right?

469
00:26:09,200 --> 00:26:14,400
So we can draw random samples from the data

470
00:26:14,400 --> 00:26:19,560
and use that as another way of estimating

471
00:26:19,560 --> 00:26:21,720
what the uncertainty around that probability would be.

472
00:26:21,720 --> 00:26:26,600
So this procedure is what we would call resampling

473
00:26:26,600 --> 00:26:27,400
with replacement.

474
00:26:27,400 --> 00:26:30,080
I think it's bootstrapping.

475
00:26:30,080 --> 00:26:32,200
My memory is blanking at this point.

476
00:26:32,200 --> 00:26:35,800
But resampling with replacement is another way to do it.

477
00:26:36,760 --> 00:26:41,320
So now, if we break the assumption

478
00:26:41,320 --> 00:26:45,440
that the data are exactly what the population are,

479
00:26:45,440 --> 00:26:46,840
then we're faced with a problem.

480
00:26:46,840 --> 00:26:50,000
We're faced with a problem that is the proportion

481
00:26:50,000 --> 00:26:52,240
that we've calculated may not actually

482
00:26:52,240 --> 00:26:58,120
be the true probability of finch beaks being

483
00:26:58,120 --> 00:27:00,080
greater than length 10.

484
00:27:00,080 --> 00:27:03,080
So how do we estimate what that uncertainty might be?

485
00:27:03,080 --> 00:27:06,040
We'll do this hacker statistic sort of method

486
00:27:06,040 --> 00:27:09,440
where we computationally try to simulate random draws

487
00:27:09,440 --> 00:27:11,560
from the population using the data.

488
00:27:11,560 --> 00:27:16,840
So the way we would do this here is to do,

489
00:27:16,840 --> 00:27:24,400
we would first do random picks from the data distribution,

490
00:27:24,400 --> 00:27:29,480
so mp.random.choice, lengths.

491
00:27:29,480 --> 00:27:34,440
So we're choosing from the length Panda series.

492
00:27:34,440 --> 00:27:43,640
We want 1,000, we want 10,000 samples from there.

493
00:27:43,640 --> 00:27:46,480
And we want to do it with replacement.

494
00:27:49,600 --> 00:27:58,720
And finally, we'll take the sum of that, sum over all

495
00:27:58,720 --> 00:28:02,800
of those that are greater than 10, and divide it by n samples.

496
00:28:06,160 --> 00:28:10,480
And so you will notice we won't get an exactly the same number.

497
00:28:10,480 --> 00:28:11,480
Question?

498
00:28:11,480 --> 00:28:13,080
Is the range about choice?

499
00:28:13,080 --> 00:28:14,080
Yes.

500
00:28:14,080 --> 00:28:16,400
Is that creating continuous distribution

501
00:28:16,400 --> 00:28:22,040
based on length, or is that choosing from the length?

502
00:28:22,040 --> 00:28:23,360
It is the latter.

503
00:28:23,360 --> 00:28:26,440
It is choosing from existing elements.

504
00:28:26,440 --> 00:28:27,640
All right?

505
00:28:27,680 --> 00:28:29,120
Cool.

506
00:28:29,120 --> 00:28:30,120
Question?

507
00:28:30,120 --> 00:28:35,040
So there are really only 229 values in it.

508
00:28:35,040 --> 00:28:41,040
So we'll just, like I said, we're resampling with replacement

509
00:28:41,040 --> 00:28:42,080
10,000 times.

510
00:28:42,080 --> 00:28:43,720
Yes, yes, exactly.

511
00:28:43,720 --> 00:28:46,120
OK?

512
00:28:46,120 --> 00:28:49,640
OK, so these are computational methods.

513
00:28:49,640 --> 00:28:53,160
One of them sort of is an explicit simulation

514
00:28:53,160 --> 00:28:55,400
for the coin flips.

515
00:28:55,400 --> 00:28:59,040
The other is treating data as ground truth.

516
00:28:59,040 --> 00:29:01,680
And then breaking that assumption,

517
00:29:01,680 --> 00:29:03,920
now saying data are not ground truth,

518
00:29:03,920 --> 00:29:05,760
what is the uncertainty in this parameter

519
00:29:05,760 --> 00:29:06,760
we're trying to estimate?

520
00:29:06,760 --> 00:29:10,560
So there are hacker stats ways of handling this.

521
00:29:10,560 --> 00:29:14,200
There's another way that we can deal with probability

522
00:29:14,200 --> 00:29:16,640
and talk about coin flips and the likes.

523
00:29:16,640 --> 00:29:23,040
So coin flips are essentially Bernoulli trials.

524
00:29:23,040 --> 00:29:27,720
Every coin flip that I make has a single outcome

525
00:29:27,720 --> 00:29:31,000
that can take on one of two possible values.

526
00:29:31,000 --> 00:29:35,520
We'll call them 0 and 1, or true and false,

527
00:29:35,520 --> 00:29:39,040
a binary outcome of some sort.

528
00:29:39,040 --> 00:29:43,200
And we can actually take advantage of,

529
00:29:43,200 --> 00:29:48,480
we can take advantage of NumPy's random number generators,

530
00:29:48,480 --> 00:29:50,560
or the probability distributions that

531
00:29:50,560 --> 00:29:52,760
are inside there, to try to simulate this.

532
00:29:52,960 --> 00:29:54,840
So there's Bernoulli trials.

533
00:29:54,840 --> 00:29:57,880
And then if you sum up Bernoulli trials,

534
00:29:57,880 --> 00:30:01,840
you get binomally distributed data.

535
00:30:01,840 --> 00:30:06,480
So we're going to try this out over here.

536
00:30:06,480 --> 00:30:13,840
So let's set a NumPy random seed.

537
00:30:13,840 --> 00:30:14,960
You can use 42.

538
00:30:14,960 --> 00:30:21,360
You can use 1,607,190, oh, 16 million, sorry,

539
00:30:21,360 --> 00:30:24,360
as your number, your choice.

540
00:30:24,360 --> 00:30:27,360
And we can flip, we can do a few things.

541
00:30:27,360 --> 00:30:28,840
So we're going to try this.

542
00:30:28,840 --> 00:30:32,440
We're going to try simulating a single flip.

543
00:30:32,440 --> 00:30:34,320
Let's try simulating a single flip.

544
00:30:34,320 --> 00:30:40,800
mp.random.binomial1, n equals 1.

545
00:30:40,800 --> 00:30:44,760
And it being a biased flip, we'll do 0.7.

546
00:30:44,760 --> 00:30:53,760
And so if you rerun that cell many times,

547
00:30:53,760 --> 00:30:57,560
you should get a lot of 1's, but some 0's, right?

548
00:31:00,120 --> 00:31:03,080
Oh, the seed, my bad.

549
00:31:03,080 --> 00:31:03,560
Thank you.

550
00:31:11,320 --> 00:31:12,800
There we go, yes.

551
00:31:12,840 --> 00:31:19,640
So you will get a bunch of 1's and a bunch of 0's.

552
00:31:19,640 --> 00:31:22,800
If you summed up all of those Bernoulli trials,

553
00:31:22,800 --> 00:31:25,920
say we did 10 of those trials together

554
00:31:25,920 --> 00:31:29,080
and treated them as a single experimental run,

555
00:31:29,080 --> 00:31:32,520
so we'll now do mp.random.binomial of 10,

556
00:31:32,520 --> 00:31:36,720
you'll get sometimes 10, sometimes 4, sometimes 6,

557
00:31:36,720 --> 00:31:38,760
et cetera, et cetera.

558
00:31:38,800 --> 00:31:45,320
So now what we're really interested in

559
00:31:45,320 --> 00:31:49,840
is how, in a biased coin flip, what we're really interested

560
00:31:49,840 --> 00:31:56,360
in then is what the probability is of getting,

561
00:31:56,360 --> 00:31:58,000
sorry, let me backtrack a little bit.

562
00:31:58,000 --> 00:32:04,120
So in a binomial trial, in a binomial draw or a binomial run,

563
00:32:04,120 --> 00:32:07,040
what we're interested in is calculating the probability,

564
00:32:07,040 --> 00:32:13,480
knowing the probability of getting up to that number

565
00:32:13,480 --> 00:32:18,560
of successes inside, up to that number of successes

566
00:32:18,560 --> 00:32:19,440
for that run, right?

567
00:32:19,440 --> 00:32:22,320
So the binomial trial is basically

568
00:32:22,320 --> 00:32:25,480
defined as n being the number of successes,

569
00:32:25,480 --> 00:32:28,680
sorry, n being the number of total Bernoulli runs

570
00:32:28,680 --> 00:32:31,840
that we've done, and p being the probability of successes.

571
00:32:31,840 --> 00:32:34,360
And it gives back a number, which is the number of successes

572
00:32:34,360 --> 00:32:37,640
out of that n number of trials.

573
00:32:37,640 --> 00:32:40,920
So what values, sorry, pop quiz, what values

574
00:32:40,920 --> 00:32:45,320
can this take on, the result of a binomial trial?

575
00:32:48,560 --> 00:32:54,200
0 to 10 or n in the general case where we know what n is,

576
00:32:54,200 --> 00:32:55,360
right, OK, cool.

577
00:32:55,360 --> 00:32:59,680
So we can actually simulate this.

578
00:32:59,680 --> 00:33:07,000
We can simulate, say, 10,000 experiments of us flipping coins

579
00:33:07,000 --> 00:33:10,160
10 times and counting the number of times

580
00:33:10,160 --> 00:33:15,160
that we got ahead in each particular experiment, right?

581
00:33:15,160 --> 00:33:28,240
So we can do that by doing mp.random.binomial 10, 0.7 and 10,000.

582
00:33:28,240 --> 00:33:29,920
If you want some clarity, you can actually

583
00:33:29,920 --> 00:33:32,280
use the underscore between your numbers

584
00:33:32,280 --> 00:33:34,560
to make sure you know what you're typing.

585
00:33:34,560 --> 00:33:41,440
So in that, we'll give us something

586
00:33:41,440 --> 00:33:44,720
that looks like this, right?

587
00:33:44,720 --> 00:33:53,280
So what I'd like to ask you then is, what do you see in the chart?

588
00:33:53,280 --> 00:33:56,280
What values are probable?

589
00:33:56,280 --> 00:33:57,520
Probable values are not probable.

590
00:34:00,160 --> 00:34:02,040
I'm not going to ask you to talk with your neighbor

591
00:34:02,040 --> 00:34:03,040
this time around.

592
00:34:06,040 --> 00:34:09,120
Any volunteers?

593
00:34:09,120 --> 00:34:12,240
So the most probable value is 7, right?

594
00:34:12,240 --> 00:34:17,960
And we know that from the fact that our p, which we set, was 0.7.

595
00:34:17,960 --> 00:34:21,280
So the expectation or the most likely value,

596
00:34:21,280 --> 00:34:24,120
the thing we expect to see the most is 0.7.

597
00:34:24,120 --> 00:34:25,160
What else do we see?

598
00:34:27,280 --> 00:34:31,040
The upper bound, bounded at 10, right?

599
00:34:31,040 --> 00:34:33,360
We don't see any values at 0, 1, or 2.

600
00:34:36,360 --> 00:34:37,360
What's happening there?

601
00:34:41,360 --> 00:34:42,360
Is this very small?

602
00:34:42,360 --> 00:34:45,600
Yeah, we've done the experiment 10,000 times,

603
00:34:45,600 --> 00:34:47,920
and that's still not enough, right?

604
00:34:47,920 --> 00:34:49,000
It's still not enough for us to be

605
00:34:49,000 --> 00:34:51,720
able to see whether there is a probability,

606
00:34:51,720 --> 00:34:55,160
see the proportion of the probability.

607
00:34:55,160 --> 00:35:01,200
The proportion of trials that we will get one head only out of 10.

608
00:35:01,200 --> 00:35:06,240
OK, so I'd like you to try the following exercises.

609
00:35:06,240 --> 00:35:09,760
Spend about two to three minutes on them.

610
00:35:09,760 --> 00:35:12,480
The first one is calculating the probability of five

611
00:35:12,480 --> 00:35:16,680
or more heads for a value of p is 0.3, then for 0.5,

612
00:35:16,680 --> 00:35:19,920
plot the histograms for both of them.

613
00:35:19,920 --> 00:35:22,240
Yeah, so spend a minute or two handling that.

614
00:35:22,240 --> 00:35:24,560
Just really quickly go over.

615
00:35:24,560 --> 00:35:30,680
You should get something like this for the first exercise,

616
00:35:30,680 --> 00:35:34,320
something around the value of 0.7655,

617
00:35:34,320 --> 00:35:36,760
something like that for the second exercise, right?

618
00:35:36,760 --> 00:35:39,880
The probability of seeing a heads is higher,

619
00:35:39,880 --> 00:35:44,120
so therefore the probability of seeing five or more heads out

620
00:35:44,120 --> 00:35:47,360
of 20 is also going to be higher, right?

621
00:35:47,360 --> 00:35:52,560
So 99% of those have that result.

622
00:35:52,560 --> 00:35:55,160
And if you plot the histogram, you

623
00:35:55,160 --> 00:35:56,840
should see something like this.

624
00:35:56,840 --> 00:36:00,120
Now, for those of you who had that bit of time

625
00:36:00,120 --> 00:36:02,960
to think about the question, looking at the histogram,

626
00:36:02,960 --> 00:36:09,200
can you tell me what is the probability of seeing four

627
00:36:09,200 --> 00:36:10,160
or more heads?

628
00:36:12,680 --> 00:36:15,160
Pardon me?

629
00:36:15,160 --> 00:36:17,680
Yes.

630
00:36:17,680 --> 00:36:21,000
But a lot is not a number from 0 to 1, right?

631
00:36:21,040 --> 00:36:22,880
So what is that number from 0 to 1?

632
00:36:26,480 --> 00:36:28,400
Pardon me?

633
00:36:28,400 --> 00:36:31,000
85%, OK, maybe.

634
00:36:31,000 --> 00:36:33,000
It's not very easy to tell, right?

635
00:36:33,000 --> 00:36:35,920
Not very easy to tell.

636
00:36:35,920 --> 00:36:39,720
This is the sort of question where histograms are kind

637
00:36:39,720 --> 00:36:41,720
of not the right thing to look at.

638
00:36:41,720 --> 00:36:44,080
It's the thing that we're used to looking at,

639
00:36:44,080 --> 00:36:47,080
but it's not the kind of thing that would give us rich.

640
00:36:47,080 --> 00:36:49,040
It's not the kind of plot that would give us

641
00:36:49,040 --> 00:36:52,160
rich statistical information on the data

642
00:36:52,160 --> 00:36:54,880
that we have on hand, OK?

643
00:36:54,880 --> 00:36:55,360
Question?

644
00:36:59,440 --> 00:37:01,640
Danka, yes, exactly.

645
00:37:01,640 --> 00:37:06,280
So what we want instead is the cumulative distribution

646
00:37:06,280 --> 00:37:07,800
of our data.

647
00:37:07,800 --> 00:37:11,120
And that, I argue in a blog post,

648
00:37:11,120 --> 00:37:14,920
gives us much richer information than a histogram would.

649
00:37:14,920 --> 00:37:16,640
A histogram is nice and convenient

650
00:37:16,640 --> 00:37:19,160
to look at because it sort of tells us where the central

651
00:37:19,160 --> 00:37:22,000
tendency is, but that's all it really

652
00:37:22,000 --> 00:37:25,120
can tell us what the central tendency is, right?

653
00:37:25,120 --> 00:37:27,160
Maybe the bounds, but even the bounds

654
00:37:27,160 --> 00:37:28,680
aren't going to be shown very accurately,

655
00:37:28,680 --> 00:37:33,160
as we would see from this histogram up there, right?

656
00:37:33,160 --> 00:37:38,480
So this is where the cumulative distribution of our data

657
00:37:38,480 --> 00:37:40,520
comes into play, and we can plot what

658
00:37:40,520 --> 00:37:43,680
we would call the empirical cumulative distribution

659
00:37:43,720 --> 00:37:46,880
function, the ECDF, of our data.

660
00:37:46,880 --> 00:37:50,640
And the ECDF is a great way to visualize this, OK?

661
00:37:50,640 --> 00:37:55,080
So if we take our data and we arrange them, well, actually,

662
00:37:55,080 --> 00:37:56,880
let's code along, let's code along,

663
00:37:56,880 --> 00:37:59,720
and you'll see what the ECDF will look like for this,

664
00:37:59,720 --> 00:38:01,720
for binomally distributed data.

665
00:38:01,720 --> 00:38:07,320
So X flips and Y flips are going to be ECDF of our data,

666
00:38:07,320 --> 00:38:10,760
which our data is X. What it will return

667
00:38:10,760 --> 00:38:15,560
is it'll give us indices on the x-axis, which

668
00:38:15,560 --> 00:38:18,880
are where our data points fall.

669
00:38:18,880 --> 00:38:21,760
And then it'll give us an index on the y-axis, which

670
00:38:21,760 --> 00:38:24,400
is a number from 0 to 1 that tells us

671
00:38:24,400 --> 00:38:27,480
how much of our data falls below that particular data

672
00:38:27,480 --> 00:38:29,160
points value, OK?

673
00:38:29,160 --> 00:38:33,880
So let's do that, and we'll do plt.plot x flips,

674
00:38:33,880 --> 00:38:42,920
y flips, marker is a dot, oops, line style is none.

675
00:38:45,640 --> 00:38:46,880
Oops, I forgot to run that.

676
00:38:49,720 --> 00:38:55,000
Now, things look a little clearer, right?

677
00:38:55,000 --> 00:38:58,720
So for those of you who have the histogram on your screen,

678
00:38:58,720 --> 00:39:00,600
keep the histogram on your screen

679
00:39:00,600 --> 00:39:05,240
and compare it to the ECDF that's on the projector screens.

680
00:39:05,240 --> 00:39:08,360
Now let me ask, what's the probability

681
00:39:08,360 --> 00:39:11,840
of getting 4 or higher in our data?

682
00:39:18,520 --> 00:39:19,760
Something percent, yes.

683
00:39:19,760 --> 00:39:22,400
OK, so here's how you look at it.

684
00:39:22,400 --> 00:39:29,640
You go to 4, you go up to the bottom of that bar-like looking

685
00:39:29,640 --> 00:39:33,600
thing, and then you draw a line across to there,

686
00:39:33,600 --> 00:39:35,800
and it falls roughly at 0.2, right?

687
00:39:35,800 --> 00:39:40,520
So the probability of getting 4 or higher is approximately 0.2.

688
00:39:40,520 --> 00:39:48,760
And the thing about ECDFs is 0.8, sorry, thank you, 1 minus.

689
00:39:48,760 --> 00:39:50,440
We're doing the higher, thank you.

690
00:39:50,440 --> 00:39:53,600
So the thing about ECDFs, though,

691
00:39:53,600 --> 00:39:56,640
is that it gives you much richer statistical information.

692
00:39:56,640 --> 00:39:59,040
You can tell things like the central tendency.

693
00:39:59,080 --> 00:40:00,360
So what's the central tendency?

694
00:40:03,680 --> 00:40:09,080
Well, we go to 0.5, draw a line across,

695
00:40:09,080 --> 00:40:11,960
see where it hits the data, and look on the x-axis,

696
00:40:11,960 --> 00:40:15,880
and that value is 5, exactly.

697
00:40:15,880 --> 00:40:17,600
What are the bounds of the data?

698
00:40:21,880 --> 00:40:24,320
Exactly, and take a look at that.

699
00:40:24,320 --> 00:40:27,880
We couldn't see the 0 in the histogram

700
00:40:27,880 --> 00:40:31,240
because it's kind of like obscured by the height of the rest.

701
00:40:31,240 --> 00:40:33,160
One thing that's cool about the ECDF

702
00:40:33,160 --> 00:40:36,360
is that it uses all of the data.

703
00:40:36,360 --> 00:40:41,040
There's no binning bias that can obscure the values

704
00:40:41,040 --> 00:40:43,600
that your data can take on.

705
00:40:43,600 --> 00:40:44,840
That is a serious problem.

706
00:40:44,840 --> 00:40:47,040
You can lie with histograms.

707
00:40:47,040 --> 00:40:49,200
You do not want to lie with histograms.

708
00:40:49,200 --> 00:40:51,160
I will come after you, OK?

709
00:40:54,080 --> 00:40:55,920
OK, cool.

710
00:40:55,920 --> 00:40:59,360
So I made my case, and I rest my case with ECDFs.

711
00:40:59,360 --> 00:41:01,360
Don't ever use histograms again.

712
00:41:01,360 --> 00:41:02,720
Always use ECDFs.

713
00:41:02,720 --> 00:41:05,240
They give you a much richer view onto your data.

714
00:41:05,240 --> 00:41:09,160
You can look at all of the percentiles of interest.

715
00:41:09,160 --> 00:41:11,240
You can visualize, sorry, all of the percentiles

716
00:41:11,240 --> 00:41:17,040
that are relevant in your modeling problems using ECDFs, OK?

717
00:41:17,040 --> 00:41:22,560
OK, so we did a little recap on probability

718
00:41:22,560 --> 00:41:24,880
just to make sure we're all clear

719
00:41:24,920 --> 00:41:26,920
and we're on the same page.

720
00:41:26,920 --> 00:41:32,320
Probability is credibility points assigned to the number line,

721
00:41:32,320 --> 00:41:33,480
OK?

722
00:41:33,480 --> 00:41:35,080
When we plot something like this, we're

723
00:41:35,080 --> 00:41:38,720
saying there's lots of credibility points assigned

724
00:41:38,720 --> 00:41:39,920
to this value.

725
00:41:39,920 --> 00:41:42,200
There's very little credibility points assigned

726
00:41:42,200 --> 00:41:45,080
to the tail values, OK?

727
00:41:45,080 --> 00:41:47,480
That's all probability is a working definition

728
00:41:47,480 --> 00:41:48,800
for our purposes.

729
00:41:48,800 --> 00:41:52,400
We can simulate draws from a probability distribution.

730
00:41:52,400 --> 00:41:54,400
We did that multiple ways.

731
00:41:54,400 --> 00:42:03,120
We can simulate it from data by doing sampling with replacement.

732
00:42:03,120 --> 00:42:05,800
Now, what we're going to do, oh, sorry, and finally,

733
00:42:05,800 --> 00:42:09,160
we can actually take advantage of the exact analytical form,

734
00:42:09,160 --> 00:42:13,040
analytically implemented probability distributions

735
00:42:13,040 --> 00:42:19,320
in NumPy and SciPy stats, and use that to help us simulate

736
00:42:19,320 --> 00:42:23,120
what our data might look like under a set of fixed parameters.

737
00:42:23,120 --> 00:42:25,160
When I was learning Bayesian stats,

738
00:42:25,160 --> 00:42:27,960
this activity was really, really helpful

739
00:42:27,960 --> 00:42:30,680
for getting familiar with the shapes of probability

740
00:42:30,680 --> 00:42:32,440
distributions.

741
00:42:32,440 --> 00:42:34,720
And as you'll see later, the shapes

742
00:42:34,720 --> 00:42:37,080
of your probability distributions, particularly

743
00:42:37,080 --> 00:42:40,000
the bounds, the central tendency, and how they're skewed,

744
00:42:40,000 --> 00:42:45,040
can be really useful pieces of knowledge

745
00:42:45,040 --> 00:42:47,920
that no longer are just trivia in your head,

746
00:42:47,920 --> 00:42:51,360
but actually can be useful tools for modeling.

747
00:42:51,400 --> 00:42:55,040
What we're going to do now is do a very, very, very, very quick

748
00:42:55,040 --> 00:42:58,400
run through of the different probability distributions

749
00:42:58,400 --> 00:43:01,480
and what their so-called stories are.

750
00:43:01,480 --> 00:43:02,680
Probability distribution.

751
00:43:02,680 --> 00:43:04,320
Oh, well, let me backtrack a little bit.

752
00:43:04,320 --> 00:43:06,920
How many of you have heard of the term generative models

753
00:43:06,920 --> 00:43:09,080
of data?

754
00:43:09,080 --> 00:43:11,240
Yeah, those who've been in the deep learning world

755
00:43:11,240 --> 00:43:15,120
will know that there is this term called generative models.

756
00:43:15,120 --> 00:43:17,600
And frankly, at some companies, like the one that I worked at,

757
00:43:17,600 --> 00:43:20,640
it's been overhyped quite a bit.

758
00:43:20,640 --> 00:43:24,600
Everyone wants to talk about generative models.

759
00:43:24,600 --> 00:43:27,800
At its core, generative models are just

760
00:43:27,800 --> 00:43:32,600
how we can generate things that look like data.

761
00:43:32,600 --> 00:43:35,240
And if you think hard and long about it,

762
00:43:35,240 --> 00:43:39,440
probability distributions are generative models of data.

763
00:43:39,440 --> 00:43:41,920
Probability distributions are generative models of data

764
00:43:41,920 --> 00:43:45,560
because we can construct a model that

765
00:43:45,560 --> 00:43:49,520
is composed of purely just probability distributions

766
00:43:49,520 --> 00:43:53,520
and use it to simulate data that looks like actual data

767
00:43:53,520 --> 00:43:55,520
that we might collect.

768
00:43:55,520 --> 00:43:57,880
So let's think about what actual data we might collect,

769
00:43:57,880 --> 00:44:00,720
say, starting with the Poisson distribution, right?

770
00:44:00,720 --> 00:44:04,960
So Poisson processes and the Poisson distributions.

771
00:44:04,960 --> 00:44:06,360
That's a generative model.

772
00:44:06,360 --> 00:44:08,680
And it's got a story that's behind it.

773
00:44:08,680 --> 00:44:12,760
And this concept of what is the story behind each

774
00:44:12,760 --> 00:44:14,520
and every probability distribution

775
00:44:14,520 --> 00:44:17,880
is something that we need to make sure we're familiar with.

776
00:44:17,880 --> 00:44:22,200
So Poisson distributed data, basically,

777
00:44:22,200 --> 00:44:26,400
can be thought of as something like this.

778
00:44:26,400 --> 00:44:29,400
This is borrowed from David McKay's book.

779
00:44:29,400 --> 00:44:32,280
I have a town, and it's called Poissonville.

780
00:44:32,280 --> 00:44:38,440
And the buses, they're kind of like MBTA trains in Boston.

781
00:44:38,440 --> 00:44:40,680
So they come, and then sometimes you

782
00:44:40,680 --> 00:44:43,280
have to wait a heck of a long time before the next one comes.

783
00:44:43,280 --> 00:44:46,240
And sometimes the next one comes right after them, right?

784
00:44:46,280 --> 00:44:48,720
They're the one that just came by.

785
00:44:48,720 --> 00:44:51,440
Yeah, and then sometimes they get derailed and, well,

786
00:44:51,440 --> 00:44:53,600
too bad for Bostonians.

787
00:44:53,600 --> 00:45:00,920
So the amount of time that you wait for one train or one bus

788
00:45:00,920 --> 00:45:02,920
is independent of the amount of time

789
00:45:02,920 --> 00:45:06,240
that you waited for the previous bus, right?

790
00:45:06,240 --> 00:45:09,120
So that's the story of a Poisson process.

791
00:45:09,520 --> 00:45:16,400
And so the timing of the next event

792
00:45:16,400 --> 00:45:20,000
is completely independent of when the previous event happened.

793
00:45:20,000 --> 00:45:26,040
And so it's not just faulty trains on the red line in Boston.

794
00:45:26,040 --> 00:45:27,320
There's other things, too, right?

795
00:45:27,320 --> 00:45:29,240
There's like births in a hospital.

796
00:45:29,240 --> 00:45:32,000
There's meteor strikes.

797
00:45:32,000 --> 00:45:34,680
God help us if we have one.

798
00:45:34,680 --> 00:45:38,320
Aviation incidents, the rate of things happening, right?

799
00:45:38,320 --> 00:45:40,840
Number of events happening per unit time.

800
00:45:40,840 --> 00:45:44,080
So that's what a Poisson process is.

801
00:45:44,080 --> 00:45:49,880
And the number of arrivals that occur in a given amount of time

802
00:45:49,880 --> 00:45:52,480
takes on a Poisson distribution.

803
00:45:52,480 --> 00:45:54,560
So all that the Poisson distribution is modeling

804
00:45:54,560 --> 00:46:00,880
is just how many things happen within a given unit of time.

805
00:46:00,880 --> 00:46:04,800
So we can actually simulate that.

806
00:46:05,240 --> 00:46:15,400
So if we want what we can do here is we can simulate Poisson

807
00:46:15,400 --> 00:46:22,120
draws, np.random.poisson, with per unit time six events

808
00:46:22,120 --> 00:46:24,760
happening, so six natural births per day,

809
00:46:24,760 --> 00:46:32,440
or six collisions at Brigham Circle near Harvard Medical.

810
00:46:32,440 --> 00:46:37,000
And we'll do like 10 to the power of six.

811
00:46:37,000 --> 00:46:39,080
Let's do a million draws, right?

812
00:46:39,080 --> 00:46:41,000
And then plot what this distribution looks like.

813
00:46:41,000 --> 00:46:46,960
PLT.hist of samples will just set the bin size

814
00:46:46,960 --> 00:46:49,400
so that it's a convenient thing for us to visualize.

815
00:46:49,400 --> 00:46:52,640
And you'll get something that looks like that, right?

816
00:46:52,640 --> 00:46:55,920
Does the shape look kind of familiar?

817
00:46:55,920 --> 00:47:00,840
Not that you've seen it before, but like some other distribution?

818
00:47:00,840 --> 00:47:02,720
The binomial, did I hear?

819
00:47:02,720 --> 00:47:04,200
Yeah, what's up with the binomial?

820
00:47:08,960 --> 00:47:12,720
Yeah, so this one isn't exactly symmetric, but close enough,

821
00:47:12,720 --> 00:47:13,640
yes?

822
00:47:13,640 --> 00:47:16,000
Yeah, so there's a neat relationship

823
00:47:16,000 --> 00:47:19,200
between the Poisson distribution and the binomial

824
00:47:19,200 --> 00:47:22,480
distribution, that is for low probability of successes,

825
00:47:22,480 --> 00:47:27,720
that is for really, really rare events that happen.

826
00:47:27,720 --> 00:47:32,760
The Poisson distribution is the approximation, or the limit,

827
00:47:32,760 --> 00:47:35,480
as we go to low probability of success

828
00:47:35,480 --> 00:47:37,600
and large number of trials, right?

829
00:47:37,600 --> 00:47:40,240
So there's a relationship between these distributions.

830
00:47:43,480 --> 00:47:48,480
We can actually, let's plot the ECDF of this as well.

831
00:47:48,480 --> 00:47:55,400
So ECDF of our samples that we drew.

832
00:47:55,400 --> 00:47:57,240
And then we plot this guy again.

833
00:48:15,080 --> 00:48:17,480
And you should get something that looks like that.

834
00:48:17,480 --> 00:48:22,400
Once again, this tells us a lot of information.

835
00:48:22,400 --> 00:48:24,080
What is the central tendency in this case?

836
00:48:26,400 --> 00:48:27,840
Six, yes, exactly.

837
00:48:27,840 --> 00:48:32,200
So the central tendency, I'm using this term

838
00:48:32,200 --> 00:48:33,960
as the more generalized thing, right?

839
00:48:33,960 --> 00:48:37,200
So the central tendency can be either the mean, the median,

840
00:48:37,200 --> 00:48:39,480
or the mode, depending on which one we're talking about.

841
00:48:39,480 --> 00:48:43,360
The expectation is the mean, and the expectation

842
00:48:43,360 --> 00:48:47,000
of the Poisson distribution is the parameter

843
00:48:47,000 --> 00:48:48,440
that we passed into it, right?

844
00:48:48,440 --> 00:48:53,040
So if we say that things are Poisson distributed with six

845
00:48:53,080 --> 00:48:55,320
events per unit time, then we expect

846
00:48:55,320 --> 00:48:58,280
to see six events, the central tendency will be six,

847
00:48:58,280 --> 00:49:02,120
the median will be six, the mean will be six, OK?

848
00:49:02,120 --> 00:49:06,040
All right, so something that's also Poisson distributed

849
00:49:06,040 --> 00:49:10,240
would be field goal attempts per game.

850
00:49:10,240 --> 00:49:14,200
Yesterday over lunch, a bunch of us

851
00:49:14,200 --> 00:49:17,560
were talking about how football, and I'm

852
00:49:17,560 --> 00:49:21,240
sorry to the American football fans, that's hand egg,

853
00:49:21,840 --> 00:49:24,040
real football that is played with your feet,

854
00:49:26,080 --> 00:49:30,320
that's sort of at a field goal rate that's not that good,

855
00:49:30,320 --> 00:49:33,400
whereas hockey is at the right field goal rate,

856
00:49:33,400 --> 00:49:37,320
whereas basketball is at some absurdly high field goal rate.

857
00:49:38,320 --> 00:49:43,320
So we're gonna do an example taken from professor,

858
00:49:43,760 --> 00:49:46,080
an instructor at Caltech, Justin Voice,

859
00:49:46,080 --> 00:49:48,600
who I've met at the SciPy conference,

860
00:49:48,600 --> 00:49:53,400
and it's about field goal attempts by LeBron James, right?

861
00:49:54,520 --> 00:49:59,520
And he did, that's his data, the his stats per game,

862
00:49:59,680 --> 00:50:04,080
number of things that he, number of times

863
00:50:04,080 --> 00:50:07,200
that he shot in one game, so the unit time is one game,

864
00:50:07,200 --> 00:50:09,920
and we're asking how many attempts did he make, OK?

865
00:50:14,240 --> 00:50:15,920
I need to reconnect my VPN.

866
00:50:16,120 --> 00:50:21,200
Pardon me, OK, so let's move on.

867
00:50:21,200 --> 00:50:23,720
So we've got the field goal attempts here.

868
00:50:28,080 --> 00:50:30,200
All right, that's OK.

869
00:50:30,200 --> 00:50:31,840
It'll come back when it comes back.

870
00:50:33,840 --> 00:50:38,840
And we'll do the ECDF of this data, all right?

871
00:50:43,320 --> 00:50:44,680
Cool.

872
00:50:44,680 --> 00:50:49,680
And finally, what we're gonna do is we're gonna do

873
00:50:49,760 --> 00:50:53,120
many random draws from a Poisson simulation,

874
00:50:53,120 --> 00:50:57,520
from a Poisson distribution, and plot all of those random

875
00:50:57,520 --> 00:51:01,720
draws, the ECDFs of those random draws to see whether

876
00:51:01,720 --> 00:51:06,720
it follows the same distribution as what LeBron's

877
00:51:07,000 --> 00:51:09,360
field goal attempts would be like.

878
00:51:09,360 --> 00:51:13,860
So let's code along, so for underscore in range of that,

879
00:51:14,920 --> 00:51:19,920
samples is np.random.poisson, np.mean of field goal attempts,

880
00:51:21,720 --> 00:51:26,720
and the size is the length of field goal attempts,

881
00:51:27,000 --> 00:51:29,680
and in this case, we'll plot the ECDF

882
00:51:29,680 --> 00:51:31,240
of the theoretical samples.

883
00:51:36,400 --> 00:51:39,400
And let's see, my kernel's disconnected,

884
00:51:39,400 --> 00:51:44,240
so I'm going to have to reconnect and rerun cells.

885
00:51:44,680 --> 00:51:49,680
And since we're at it, I'll just bring up the instructor

886
00:51:55,800 --> 00:51:59,040
version so that we have it there.

887
00:51:59,040 --> 00:52:01,480
You should get a plot that looks something like that,

888
00:52:01,480 --> 00:52:03,960
right, OK?

889
00:52:03,960 --> 00:52:05,800
And so with that guy over there,

890
00:52:08,320 --> 00:52:10,760
that's one probability distribution story

891
00:52:10,760 --> 00:52:13,180
that we can talk about, the Poisson distribution.

892
00:52:13,220 --> 00:52:16,620
Now the Poisson distribution is a discreet

893
00:52:16,620 --> 00:52:17,740
probability distribution.

894
00:52:17,740 --> 00:52:20,420
What's the other class of distributions?

895
00:52:20,420 --> 00:52:21,900
The continuous family, right?

896
00:52:21,900 --> 00:52:26,900
OK, so the discreets, when we plot that,

897
00:52:28,940 --> 00:52:32,380
they technically follow a probability mass function

898
00:52:32,380 --> 00:52:35,740
because there's a bulk of mass that's associated

899
00:52:35,740 --> 00:52:39,100
with each particular value, that is how credibility

900
00:52:39,100 --> 00:52:43,660
is assigned, with continuous distributions,

901
00:52:43,660 --> 00:52:46,620
we have the probability distribution function,

902
00:52:46,620 --> 00:52:49,580
which technically have zero mass at any point

903
00:52:49,580 --> 00:52:51,340
on the x-axis, right?

904
00:52:51,340 --> 00:52:55,860
But they take on, they have a density of mass,

905
00:52:55,860 --> 00:53:00,020
so-called, from within a range of continuous values, OK?

906
00:53:01,180 --> 00:53:05,020
OK, we're going to skip one or two,

907
00:53:05,020 --> 00:53:07,680
we're going to skip the exponential distribution,

908
00:53:07,680 --> 00:53:09,640
I'll just leave it out there for you,

909
00:53:09,640 --> 00:53:12,960
that the exponential distribution is the waiting time

910
00:53:12,960 --> 00:53:17,960
between Poisson events, and so that's that,

911
00:53:19,000 --> 00:53:23,120
and so you can take a look at how the CDF,

912
00:53:23,120 --> 00:53:25,920
ECDF of the exponential distribution

913
00:53:25,920 --> 00:53:27,440
will look like on your own time.

914
00:53:27,440 --> 00:53:30,160
We'll go through the normal distribution, OK?

915
00:53:30,160 --> 00:53:33,160
The normal distribution, everyone's familiar with this,

916
00:53:33,160 --> 00:53:35,720
right, things are normally distributed,

917
00:53:35,720 --> 00:53:38,320
a lot of things, sorry, are normally distributed, OK?

918
00:53:39,920 --> 00:53:41,920
We've got measurements, and in this case,

919
00:53:41,920 --> 00:53:45,400
we'll just take a look at what the story is.

920
00:53:45,400 --> 00:53:48,400
The story is, in this quote here,

921
00:53:48,400 --> 00:53:50,120
when doing repeated measurements,

922
00:53:50,120 --> 00:53:52,880
we expect them to be normally distributed,

923
00:53:52,880 --> 00:53:56,160
owing to the fact that many sub-processes,

924
00:53:56,160 --> 00:53:59,560
lots of individual data-generating processes,

925
00:53:59,560 --> 00:54:02,200
contribute to this final thing that we measure, OK?

926
00:54:02,200 --> 00:54:07,120
So things like human height is a culmination of many genes,

927
00:54:07,120 --> 00:54:09,040
so it's kind of reasonable,

928
00:54:09,040 --> 00:54:11,240
it's a culmination of lots of genes,

929
00:54:11,240 --> 00:54:13,880
plus environmental effects put together,

930
00:54:13,880 --> 00:54:15,440
and so it's reasonable to expect

931
00:54:15,440 --> 00:54:17,520
that human height would be normally distributed

932
00:54:17,520 --> 00:54:19,600
or approximately so, right?

933
00:54:21,760 --> 00:54:25,520
So yeah, so the formulation,

934
00:54:25,520 --> 00:54:28,360
one formulation of the CLT, the central limit theorem,

935
00:54:28,360 --> 00:54:30,160
is that any quantity that emerges

936
00:54:30,320 --> 00:54:32,920
as the sum of a large number of sub-processes

937
00:54:32,920 --> 00:54:34,920
tends to be normally distributed,

938
00:54:34,920 --> 00:54:38,360
provided that none of the sub-processes

939
00:54:38,360 --> 00:54:40,560
is very broadly distributed itself,

940
00:54:40,560 --> 00:54:42,680
that is, it doesn't overwhelm

941
00:54:42,680 --> 00:54:46,720
the final data distribution that we're looking at, OK?

942
00:54:46,720 --> 00:54:50,880
So just to have you all take a look at this,

943
00:54:50,880 --> 00:54:54,600
these are what we would call,

944
00:54:54,600 --> 00:54:56,640
these are measurements of the speed of light,

945
00:54:56,640 --> 00:54:59,440
and there's, in an experiment,

946
00:54:59,440 --> 00:55:02,560
lots of factors contribute to what measure,

947
00:55:02,560 --> 00:55:05,560
what value we eventually measure, OK?

948
00:55:05,560 --> 00:55:09,000
So there's some data on the speed of light,

949
00:55:09,000 --> 00:55:12,480
and the estimate of the speed of light

950
00:55:12,480 --> 00:55:14,600
tends to be normally distributed

951
00:55:14,600 --> 00:55:17,800
because of this data-generative process, right?

952
00:55:17,800 --> 00:55:20,280
Lots of things contributing to this final thing.

953
00:55:20,280 --> 00:55:22,560
There's error in the instrument,

954
00:55:22,560 --> 00:55:25,240
there's error in, there's the instrument itself,

955
00:55:25,240 --> 00:55:26,720
and it's got some error,

956
00:55:26,720 --> 00:55:28,920
there's the measurement technique,

957
00:55:28,920 --> 00:55:30,360
and it's got some error,

958
00:55:31,440 --> 00:55:34,320
there's the conditions of the day

959
00:55:34,320 --> 00:55:37,320
that we're measuring and that that can affect,

960
00:55:37,320 --> 00:55:40,360
that's the reason most biologists tend to use

961
00:55:40,360 --> 00:55:43,720
something happened that day for a field experiment,

962
00:55:43,720 --> 00:55:46,120
and I know it myself because I was one before.

963
00:55:47,000 --> 00:55:49,000
So yes, you get the point, though, right?

964
00:55:49,000 --> 00:55:53,160
So there's a combination of factors that lead to this.

965
00:55:53,160 --> 00:55:54,000
OK.

966
00:55:54,880 --> 00:55:58,480
Now, I want to leave, before we go on a break,

967
00:55:58,480 --> 00:56:01,240
I want to leave you with this little tidbit

968
00:56:01,240 --> 00:56:03,680
which comes from Ellen Downey's blog post.

969
00:56:03,680 --> 00:56:07,000
Are your data normally distributed?

970
00:56:07,000 --> 00:56:09,080
I encourage you to look at that blog post

971
00:56:09,080 --> 00:56:11,920
because though something,

972
00:56:13,960 --> 00:56:18,720
though we impose models on our data,

973
00:56:18,720 --> 00:56:22,520
our data may not necessarily be

974
00:56:23,480 --> 00:56:27,120
exactly following that model that we've imposed on.

975
00:56:27,120 --> 00:56:29,120
So when we make an assumption

976
00:56:29,120 --> 00:56:32,320
or when we impose this idea that our data might be normal

977
00:56:32,320 --> 00:56:36,360
and we do a fit, we check how deviant our data

978
00:56:36,360 --> 00:56:38,040
are from normal distributions,

979
00:56:38,040 --> 00:56:39,560
we use that normal distribution

980
00:56:39,560 --> 00:56:41,920
and later downstream things for estimating the mean

981
00:56:41,920 --> 00:56:43,560
and the likes.

982
00:56:43,560 --> 00:56:45,640
When we do things like that,

983
00:56:45,640 --> 00:56:47,840
we're saying we're imposing a model

984
00:56:47,840 --> 00:56:49,680
and that model might be wrong,

985
00:56:49,680 --> 00:56:51,160
but it can be useful, right?

986
00:56:51,160 --> 00:56:53,120
This is a classic George Box quote.

987
00:56:55,680 --> 00:56:59,080
I'm going to mash that with George Orwell

988
00:56:59,080 --> 00:57:01,560
saying that some models are wrong

989
00:57:01,560 --> 00:57:05,120
but some are more wrong than others, OK?

990
00:57:05,120 --> 00:57:08,200
And we might be, find some of them useful, right?

991
00:57:08,200 --> 00:57:11,200
So take a look at Ellen's post, ponder about that point.

992
00:57:11,200 --> 00:57:14,960
We'll come back at 2.45 p.m.

993
00:57:14,960 --> 00:57:17,160
There should be snacks inside the Tejas room.

994
00:57:18,160 --> 00:57:21,520
We'll come back to in notebook 1b

995
00:57:21,520 --> 00:57:24,160
and very quickly go through joint

996
00:57:24,160 --> 00:57:26,120
and conditional probability, OK?

997
00:57:26,120 --> 00:57:28,800
This is a last minute decision that I made

998
00:57:30,280 --> 00:57:31,880
in that in the interest of time,

999
00:57:31,880 --> 00:57:33,760
there's some ideas I want to cover.

1000
00:57:33,760 --> 00:57:38,200
We'll cut down a little bit on the foundational exercises

1001
00:57:38,200 --> 00:57:40,520
but then we'll have the concepts given to you all.

1002
00:57:40,520 --> 00:57:45,200
So you have the tools to do your modeling later on, OK?

1003
00:57:45,200 --> 00:57:47,120
So as I mentioned in the interest of time,

1004
00:57:47,120 --> 00:57:49,640
we're going to skip a few exercises.

1005
00:57:49,640 --> 00:57:54,920
The next notebook is on conditional and joint probability

1006
00:57:54,920 --> 00:58:00,160
and really I want to give you all mostly just the tools

1007
00:58:00,160 --> 00:58:02,120
that you need to be able to think through

1008
00:58:02,120 --> 00:58:03,920
the problems at hand, OK?

1009
00:58:03,920 --> 00:58:06,080
So one of the tools in the toolkit

1010
00:58:06,080 --> 00:58:09,000
is the distributions and the stories

1011
00:58:09,000 --> 00:58:10,640
that are associated with them.

1012
00:58:12,400 --> 00:58:13,840
I drew this out as a table

1013
00:58:13,840 --> 00:58:15,960
but by the way there's a really great resource

1014
00:58:15,960 --> 00:58:19,680
by Justin Boyce who put all of the distribution stories

1015
00:58:19,680 --> 00:58:23,600
that are relevant on his Caltech website.

1016
00:58:23,600 --> 00:58:27,040
So that's a really, really great resource to go and check

1017
00:58:27,040 --> 00:58:28,880
and I'll make sure that's also linked

1018
00:58:28,880 --> 00:58:30,160
on our GitHub repository

1019
00:58:30,160 --> 00:58:33,280
so you can always check that out from there, OK?

1020
00:58:33,280 --> 00:58:36,960
So just to recap, we've got probability,

1021
00:58:36,960 --> 00:58:41,880
they follow, we've defined as credibility

1022
00:58:41,880 --> 00:58:43,640
assigned on the number line,

1023
00:58:43,640 --> 00:58:47,160
we have ways of simulating probability distributions,

1024
00:58:47,160 --> 00:58:50,480
both analytically and by brute force computation.

1025
00:58:51,720 --> 00:58:55,160
Really the core thing that we want to have in our toolkit

1026
00:58:55,160 --> 00:58:57,960
is actually the probability distributions

1027
00:58:57,960 --> 00:59:00,800
as well as their shapes and their stories, OK?

1028
00:59:00,800 --> 00:59:05,000
So this is a very incomplete, highly partial table

1029
00:59:05,000 --> 00:59:06,920
of the many probability distributions

1030
00:59:06,920 --> 00:59:10,040
that exist out there and I wanted to, you know,

1031
00:59:10,040 --> 00:59:13,960
hint at you should be building such a matrix for yourself

1032
00:59:15,280 --> 00:59:16,960
and it is really helpful,

1033
00:59:16,960 --> 00:59:18,800
like you can maybe have a cheat sheet

1034
00:59:18,800 --> 00:59:21,240
written by someone else but I always find it

1035
00:59:21,240 --> 00:59:23,800
like if I do the hard work and draw it out

1036
00:59:23,800 --> 00:59:26,000
and write it out for myself, it's also really useful.

1037
00:59:26,000 --> 00:59:28,720
Nonetheless, I'll be building a resource

1038
00:59:28,720 --> 00:59:33,720
that basically 100% plagiarizes Justin's resource

1039
00:59:34,720 --> 00:59:39,320
but gives added nice visuals for learning benefit, OK?

1040
00:59:40,600 --> 00:59:42,600
But really, so the toolkits are,

1041
00:59:42,600 --> 00:59:45,200
you want to know the names of these distributions

1042
00:59:45,200 --> 00:59:47,400
because they aid in communication

1043
00:59:47,400 --> 00:59:50,800
with other people who do statistics.

1044
00:59:50,800 --> 00:59:51,880
When you're writing things out,

1045
00:59:51,880 --> 00:59:54,560
you'll want to know what their abbreviations are, right?

1046
00:59:54,560 --> 00:59:56,560
So that guy highlighted over there

1047
00:59:56,560 --> 00:59:58,840
because that gives a nice and compact way

1048
00:59:58,840 --> 01:00:02,360
of telling people what distribution you're using

1049
01:00:02,360 --> 01:00:04,040
when you're writing stuff.

1050
01:00:04,040 --> 01:00:05,680
In your mental model,

1051
01:00:05,680 --> 01:00:08,880
you want something like the shape of a distribution, right?

1052
01:00:08,880 --> 01:00:12,440
The uniform is just equal credibility between two bounds.

1053
01:00:12,440 --> 01:00:14,680
So that picture should come into your head.

1054
01:00:14,680 --> 01:00:16,120
You should know whether the bounds

1055
01:00:16,120 --> 01:00:17,920
are relevant to your problem or not

1056
01:00:17,920 --> 01:00:21,360
and also whether equal credibility makes sense or not, right?

1057
01:00:23,360 --> 01:00:25,960
Just so that you have something live,

1058
01:00:25,960 --> 01:00:29,360
there's a variant or the generalization

1059
01:00:29,360 --> 01:00:31,160
of the uniform distribution,

1060
01:00:31,160 --> 01:00:34,920
which is the beta distribution.

1061
01:00:34,920 --> 01:00:37,120
It takes in two parameters,

1062
01:00:37,120 --> 01:00:41,440
number of successes, number of failures.

1063
01:00:41,440 --> 01:00:45,240
It's actually bound between zero and one explicitly

1064
01:00:45,240 --> 01:00:49,280
and takes on values that can look like that

1065
01:00:49,280 --> 01:00:52,520
or can look like this

1066
01:00:54,480 --> 01:00:57,200
or can look like that, right?

1067
01:00:57,200 --> 01:00:58,920
So, but the key point is that

1068
01:00:58,920 --> 01:01:00,720
it takes on values that are bounded.

1069
01:01:01,720 --> 01:01:05,920
There's this term which took me a little while to remember,

1070
01:01:05,920 --> 01:01:08,400
but it's called the support of a distribution.

1071
01:01:08,400 --> 01:01:10,480
This is something that you'll see

1072
01:01:10,480 --> 01:01:12,400
inside the statistics literature.

1073
01:01:12,400 --> 01:01:14,680
The support of a distribution is nothing more

1074
01:01:14,680 --> 01:01:17,680
than the values that it can take on,

1075
01:01:17,680 --> 01:01:19,640
the values that it can take on, right?

1076
01:01:19,640 --> 01:01:20,720
That's all it is.

1077
01:01:20,720 --> 01:01:23,960
So the support for the beta distribution

1078
01:01:23,960 --> 01:01:29,080
is something like a, oops, zero to one,

1079
01:01:29,120 --> 01:01:31,400
it's bounded between zero to one, right?

1080
01:01:31,400 --> 01:01:34,160
And there's a story for the beta distribution,

1081
01:01:34,160 --> 01:01:38,080
which is number of successes

1082
01:01:41,640 --> 01:01:46,640
expected fraction of successes

1083
01:01:48,360 --> 01:01:53,360
out of n success plus n failure, okay?

1084
01:01:54,360 --> 01:01:58,360
And it can take on, the alpha and beta parameters

1085
01:01:58,360 --> 01:02:00,360
can take on not just integer,

1086
01:02:00,360 --> 01:02:03,360
but also floating point, decimal numbers, okay?

1087
01:02:03,360 --> 01:02:06,360
So you'll want to have this kind of picture in your head

1088
01:02:06,360 --> 01:02:08,360
when you're thinking about that.

1089
01:02:08,360 --> 01:02:09,360
Where can you learn?

1090
01:02:09,360 --> 01:02:12,360
Again, I'm saying Justin Boyce's website is a great place.

1091
01:02:12,360 --> 01:02:14,360
I learned a lot of these probability distributions

1092
01:02:14,360 --> 01:02:18,360
and their shapes and their possible values

1093
01:02:18,360 --> 01:02:20,360
by looking at the prime seed,

1094
01:02:20,360 --> 01:02:23,360
prime seed three has a great thing for that.

1095
01:02:23,360 --> 01:02:25,360
But you'll notice, in prime seed three,

1096
01:02:25,360 --> 01:02:27,360
basically all they're doing is just,

1097
01:02:27,360 --> 01:02:29,360
all we're doing in the docs is just simulating

1098
01:02:29,360 --> 01:02:31,360
those distributions and plotting them out.

1099
01:02:31,360 --> 01:02:33,360
So that really is the best way to do it.

1100
01:02:33,360 --> 01:02:36,360
All of that hands-on simulation that we just did,

1101
01:02:36,360 --> 01:02:39,360
that is a great, great way for you to learn

1102
01:02:39,360 --> 01:02:41,360
what the probability distributions are,

1103
01:02:41,360 --> 01:02:44,360
what their shapes, what their data generating processes

1104
01:02:44,360 --> 01:02:45,360
are all about, okay?

1105
01:02:45,360 --> 01:02:47,360
So I want to start with,

1106
01:02:47,360 --> 01:02:50,360
that's one thing you want to have in your toolkit.

1107
01:02:50,360 --> 01:02:53,360
The next thing you'll want to have in your toolkit

1108
01:02:53,360 --> 01:02:57,360
is this idea of joint and conditional probability.

1109
01:02:57,360 --> 01:03:00,360
Once again, in the interest of time,

1110
01:03:00,360 --> 01:03:02,360
by the way, for those of you who just got back,

1111
01:03:02,360 --> 01:03:04,360
make sure, and using Binder,

1112
01:03:04,360 --> 01:03:07,360
execute something so you don't lose your session.

1113
01:03:07,360 --> 01:03:12,360
The way I think about joint, conditional,

1114
01:03:12,360 --> 01:03:14,360
and marginal probability,

1115
01:03:14,360 --> 01:03:19,360
is by a visual that looks something like this.

1116
01:03:26,360 --> 01:03:30,360
If I have data that are jointly distributed,

1117
01:03:30,360 --> 01:03:33,360
they might look something like that.

1118
01:03:33,360 --> 01:03:36,360
Say, this is a bivariate Gaussian.

1119
01:03:36,360 --> 01:03:39,360
This put together is what we would call

1120
01:03:39,360 --> 01:03:42,360
the joint distribution.

1121
01:03:43,360 --> 01:03:46,360
Of the two things that we're interested in,

1122
01:03:46,360 --> 01:03:49,360
X1 and X2, okay?

1123
01:03:49,360 --> 01:03:53,360
Then there's a thing called conditional distribution.

1124
01:03:53,360 --> 01:03:59,360
That is, what is the distribution of one of the two axes,

1125
01:03:59,360 --> 01:04:03,360
given that we know something about the other, okay?

1126
01:04:03,360 --> 01:04:07,360
So if we use red to do the conditional distribution,

1127
01:04:08,360 --> 01:04:15,360
this is a known value of X1.

1128
01:04:15,360 --> 01:04:16,360
Oh, sorry.

1129
01:04:16,360 --> 01:04:22,360
This joint distribution is denoted as p of X1 and X2.

1130
01:04:25,360 --> 01:04:26,360
Okay?

1131
01:04:26,360 --> 01:04:28,360
So in red, we're going to show you

1132
01:04:28,360 --> 01:04:30,360
what the conditional distribution looks like.

1133
01:04:30,360 --> 01:04:33,360
So the known distribution looks like that.

1134
01:04:33,360 --> 01:04:34,360
Oh, shucks.

1135
01:04:34,360 --> 01:04:36,360
I hit the off button.

1136
01:04:38,360 --> 01:04:42,360
If we take that joint distribution

1137
01:04:45,360 --> 01:04:48,360
and project it back onto the X2 axis,

1138
01:04:53,360 --> 01:04:56,360
it itself will follow a distribution.

1139
01:04:58,360 --> 01:04:59,360
Okay?

1140
01:04:59,360 --> 01:05:00,360
Are we okay with this?

1141
01:05:00,360 --> 01:05:01,360
Right?

1142
01:05:01,360 --> 01:05:03,360
This is the distribution of X2,

1143
01:05:03,360 --> 01:05:05,360
given that we know X1.

1144
01:05:05,360 --> 01:05:10,360
This is what we would call the conditional distribution.

1145
01:05:13,360 --> 01:05:14,360
Okay?

1146
01:05:14,360 --> 01:05:22,360
And this is denoted probability of X2 given X1,

1147
01:05:22,360 --> 01:05:27,360
where that little thing over there is given.

1148
01:05:28,360 --> 01:05:29,360
Okay?

1149
01:05:29,360 --> 01:05:32,360
That pipe tells the statistician that you're taking,

1150
01:05:33,360 --> 01:05:36,360
that you're computing the distribution of X2,

1151
01:05:36,360 --> 01:05:41,360
having known a particular value of X1.

1152
01:05:41,360 --> 01:05:42,360
Okay?

1153
01:05:42,360 --> 01:05:44,360
Are we okay with this so far?

1154
01:05:44,360 --> 01:05:46,360
Okay, there's a final idea,

1155
01:05:46,360 --> 01:05:48,360
which I'm hoping you'll keep,

1156
01:05:48,360 --> 01:05:50,360
which is known as the marginal distribution.

1157
01:05:52,360 --> 01:05:55,360
Marginal distribution looks like this.

1158
01:05:57,360 --> 01:05:59,360
There are two distributions over here.

1159
01:06:02,360 --> 01:06:03,360
Okay?

1160
01:06:04,360 --> 01:06:05,360
This in blue

1161
01:06:07,360 --> 01:06:11,360
are what we would call the marginal distribution.

1162
01:06:11,360 --> 01:06:14,360
Why is it called the distribute marginal?

1163
01:06:14,360 --> 01:06:21,360
Well, first off, it's on the margins of this two-axis thing.

1164
01:06:21,360 --> 01:06:22,360
Okay?

1165
01:06:22,360 --> 01:06:27,360
It is the value of X1 ignoring whatever values,

1166
01:06:27,360 --> 01:06:30,360
ignoring whatever value that X2 is.

1167
01:06:30,360 --> 01:06:31,360
Okay?

1168
01:06:31,360 --> 01:06:35,360
So it is the value of X1 completely ignoring

1169
01:06:35,360 --> 01:06:38,360
the other variants that are of interest.

1170
01:06:38,360 --> 01:06:39,360
Okay?

1171
01:06:39,360 --> 01:06:43,360
So this is denoted as P of X1.

1172
01:06:43,360 --> 01:06:46,360
This is denoted as P of X2.

1173
01:06:46,360 --> 01:06:49,360
And those are marginal distributions.

1174
01:06:49,360 --> 01:06:50,360
Okay?

1175
01:06:50,360 --> 01:06:53,360
So prior to drawing this out for myself,

1176
01:06:53,360 --> 01:06:55,360
this was something that I didn't,

1177
01:06:55,360 --> 01:07:00,360
wasn't really able to keep straight in my head.

1178
01:07:00,360 --> 01:07:03,360
But this served as a very,

1179
01:07:03,360 --> 01:07:05,360
like what I would call an anchoring example

1180
01:07:05,360 --> 01:07:07,360
for what these three terms mean,

1181
01:07:07,360 --> 01:07:11,360
joint, conditional, and marginal probability.

1182
01:07:11,360 --> 01:07:15,360
Now, why are these three terms really important?

1183
01:07:15,360 --> 01:07:20,360
It's because it's from joint and conditional probability

1184
01:07:20,360 --> 01:07:22,360
that we make our way, joint, conditional,

1185
01:07:22,360 --> 01:07:24,360
and marginal probability that we make our way

1186
01:07:24,360 --> 01:07:26,360
to what we call Bayes' Rule.

1187
01:07:26,360 --> 01:07:27,360
Okay?

1188
01:07:27,360 --> 01:07:32,360
Bayes' Rule, if you've seen the famous neon light photo,

1189
01:07:32,360 --> 01:07:42,360
is written as P of A given B is P of B given A

1190
01:07:42,360 --> 01:07:46,360
times P of A over P of B.

1191
01:07:46,360 --> 01:07:48,360
Where does this come from?

1192
01:07:48,360 --> 01:07:50,360
Well, this comes from the definition

1193
01:07:50,360 --> 01:07:54,360
of joint probability.

1194
01:07:54,360 --> 01:08:07,360
So P of A, B is equal to P of A given B times P of B,

1195
01:08:07,360 --> 01:08:13,360
which is equal to P of B given A times P of A.

1196
01:08:13,360 --> 01:08:18,360
And if you simply isolate out this portion

1197
01:08:19,360 --> 01:08:24,360
and move this guy over there,

1198
01:08:24,360 --> 01:08:29,360
then suddenly you have Bayes' Rule, right?

1199
01:08:29,360 --> 01:08:32,360
And this is a neat thing because it gives us a way

1200
01:08:32,360 --> 01:08:38,360
to move between probability of data given model

1201
01:08:38,360 --> 01:08:40,360
or in probability of model given data

1202
01:08:40,360 --> 01:08:45,360
if we take an alternative view of what we're doing, okay?

1203
01:08:45,360 --> 01:08:47,360
And to illustrate this example,

1204
01:08:47,360 --> 01:08:51,360
we're actually going to use the drug testing example

1205
01:08:51,360 --> 01:08:53,360
in notebook 1B, so I'd like to invite you

1206
01:08:53,360 --> 01:09:00,360
to navigate to there, okay?

1207
01:09:00,360 --> 01:09:11,360
I'm going to plug this back to my laptop.

1208
01:09:11,360 --> 01:09:16,360
So the drug testing example is one of those classic things

1209
01:09:16,360 --> 01:09:25,360
where we can come up with a solution to a problem,

1210
01:09:25,360 --> 01:09:27,360
but if we don't do the stats right,

1211
01:09:27,360 --> 01:09:29,360
we'll be kind of off, all right?

1212
01:09:29,360 --> 01:09:31,360
So I hope you'll see this from this point.

1213
01:09:31,360 --> 01:09:35,360
So let's look at the question, right?

1214
01:09:35,360 --> 01:09:37,360
So we have a test.

1215
01:09:37,360 --> 01:09:43,360
It's 99% true positive for drug users

1216
01:09:43,360 --> 01:09:46,360
and 99% true negative for non-drug users.

1217
01:09:46,360 --> 01:09:50,360
What that means is if I give you a drug user

1218
01:09:50,360 --> 01:09:54,360
and then I ask you to do the test on that drug user,

1219
01:09:54,360 --> 01:09:59,360
then 99% of the time it will be correct.

1220
01:09:59,360 --> 01:10:02,360
And if I give you a non-drug user

1221
01:10:02,360 --> 01:10:04,360
and I ask you to do the test,

1222
01:10:04,360 --> 01:10:09,360
then 99% of the time it will be correct as well.

1223
01:10:09,360 --> 01:10:12,360
So it sounds like a great device, right?

1224
01:10:12,360 --> 01:10:15,360
So what I'd like to then ask you to do

1225
01:10:15,360 --> 01:10:18,360
is before doing any of this computation,

1226
01:10:18,360 --> 01:10:22,360
write down what you think the probability will be

1227
01:10:22,360 --> 01:10:25,360
that a drug user is,

1228
01:10:25,360 --> 01:10:30,360
sorry, a positive testing user will be a drug user.

1229
01:10:30,360 --> 01:10:32,360
Put down a number.

1230
01:10:32,360 --> 01:10:35,360
It's got to be from zero to one because it's a probability.

1231
01:10:35,360 --> 01:10:38,360
Put down a number mentally in your head.

1232
01:10:38,360 --> 01:10:41,360
Yeah, it's in the notebooks.

1233
01:10:41,360 --> 01:10:45,360
So 99% true positive results for drug users

1234
01:10:45,360 --> 01:10:49,360
and 99% true negative results for non-drug users.

1235
01:10:49,360 --> 01:10:51,360
Okay?

1236
01:10:51,360 --> 01:10:57,360
It's in your notebook, so scroll down on notebook 1b.

1237
01:10:57,360 --> 01:10:59,360
Write down a number.

1238
01:10:59,360 --> 01:11:02,360
And when you're done, give me a thumbs up.

1239
01:11:02,360 --> 01:11:04,360
Don't think too hard on this one.

1240
01:11:04,360 --> 01:11:09,360
You're meant to be surprised.

1241
01:11:09,360 --> 01:11:15,360
Okay, so we can actually simulate this whole process, right?

1242
01:11:15,360 --> 01:11:18,360
Because we know,

1243
01:11:18,360 --> 01:11:25,360
let's switch back to here.

1244
01:11:25,360 --> 01:11:33,360
We know a few things about the data-generating process.

1245
01:11:33,360 --> 01:11:42,360
We can actually represent this as a tree.

1246
01:11:42,360 --> 01:11:48,360
That looks ugly.

1247
01:11:48,360 --> 01:11:55,360
That tree might look something like this.

1248
01:11:55,360 --> 01:12:02,360
Someone's a user and someone's a non-user.

1249
01:12:02,360 --> 01:12:10,360
They test and they turn out to be positive and negative.

1250
01:12:10,360 --> 01:12:14,360
Positive and negative.

1251
01:12:14,360 --> 01:12:16,360
Now, help me fill in the blanks.

1252
01:12:16,360 --> 01:12:22,360
What is the probability that the user tests positive

1253
01:12:22,360 --> 01:12:25,360
given that they are a user?

1254
01:12:25,360 --> 01:12:27,360
99%.

1255
01:12:27,360 --> 01:12:34,360
I'm going to use 0.99 here.

1256
01:12:34,360 --> 01:12:38,360
What should the value be on the negative arm?

1257
01:12:38,360 --> 01:12:40,360
0.01, very good.

1258
01:12:40,360 --> 01:12:44,360
What about the non-user?

1259
01:12:44,360 --> 01:12:48,360
0.01, right?

1260
01:12:48,360 --> 01:12:52,360
If the user is not a drug user,

1261
01:12:52,360 --> 01:12:56,360
1% of the time they will test positive as a drug user.

1262
01:12:56,360 --> 01:13:02,360
99% of the time, oops, I'm being inconsistent,

1263
01:13:02,360 --> 01:13:04,360
they will test negative.

1264
01:13:04,360 --> 01:13:08,360
This sounds like a really good test, right?

1265
01:13:08,360 --> 01:13:14,360
What we're interested in, however, is P of drug user

1266
01:13:14,360 --> 01:13:20,360
given positive because this guy here is P of positive

1267
01:13:20,360 --> 01:13:26,360
given drug user.

1268
01:13:26,360 --> 01:13:28,360
So, how do we calculate this?

1269
01:13:28,360 --> 01:13:29,360
Well, we can simulate it.

1270
01:13:29,360 --> 01:13:53,360
Let's come back to the notebook.

1271
01:13:54,360 --> 01:14:02,360
So, if we take 10,000 subjects and we simulate...

1272
01:14:02,360 --> 01:14:05,360
Sorry, let me backtrack a little bit.

1273
01:14:05,360 --> 01:14:09,360
In order to solve that problem, we're missing one piece of information.

1274
01:14:09,360 --> 01:14:15,360
That is, what is the probability that a user is a drug user?

1275
01:14:15,360 --> 01:14:17,360
A person is a drug user.

1276
01:14:17,360 --> 01:14:19,360
We have the people, persons group,

1277
01:14:19,360 --> 01:14:23,360
who are a drug user and non-drug user.

1278
01:14:23,360 --> 01:14:28,360
So, some may say that if we're in Central West Virginia,

1279
01:14:28,360 --> 01:14:32,360
then opioid crisis is like ravaging there, right?

1280
01:14:32,360 --> 01:14:37,360
And it's a black stain on the pharmaceutical industry for that.

1281
01:14:37,360 --> 01:14:45,360
So, we might put an estimate that 5% to 10% of the population are drug users.

1282
01:14:45,360 --> 01:14:48,360
Now, if we're in clean, clean Massachusetts,

1283
01:14:48,360 --> 01:14:52,360
then what might we believe about this fraction?

1284
01:14:52,360 --> 01:14:56,360
It might be 10 times smaller, say 0.05, or New York City, right?

1285
01:14:56,360 --> 01:14:59,360
Like, here goes from New York, or Sydney, actually, that's his hometown.

1286
01:14:59,360 --> 01:15:03,360
So, 0.05, right?

1287
01:15:03,360 --> 01:15:06,360
Sorry, not 0.05, 0.005, right?

1288
01:15:06,360 --> 01:15:12,360
So, let's simulate how many drug users we will get under that particular regime.

1289
01:15:12,360 --> 01:15:17,360
So, we'll do mp.random.binomial.

1290
01:15:17,360 --> 01:15:21,360
We'll have 10,000 users, okay?

1291
01:15:21,360 --> 01:15:27,360
We have a probability of them being,

1292
01:15:27,360 --> 01:15:33,360
the probability of them being a drug user is 0.05,

1293
01:15:33,360 --> 01:15:35,360
and we only want one trial.

1294
01:15:35,360 --> 01:15:41,360
And so, the non-users is going to be n minus the number of users, right?

1295
01:15:41,360 --> 01:15:45,360
Number of non-users in our population is just the complement, okay?

1296
01:15:45,360 --> 01:15:47,360
We run that cell.

1297
01:15:47,360 --> 01:15:57,360
Oh, yeah, all right, I need...

1298
01:15:57,360 --> 01:16:10,360
So, of the users, how many of them will test positive?

1299
01:16:10,360 --> 01:16:13,360
I said 99%, but it's, you know, a probability.

1300
01:16:13,360 --> 01:16:16,360
So, we'll explicitly simulate it.

1301
01:16:16,360 --> 01:16:20,360
mp.random.binomial again.

1302
01:16:20,360 --> 01:16:25,360
We have the users, the number of users in the population,

1303
01:16:25,360 --> 01:16:29,360
and 99% of them will test positive.

1304
01:16:29,360 --> 01:16:33,360
And then we'll have the number of non-users,

1305
01:16:33,360 --> 01:16:37,360
but we also want to know how many of them will test positive, right?

1306
01:16:37,360 --> 01:16:39,360
So, how would we simulate that?

1307
01:16:39,360 --> 01:16:43,360
mp.random.binomial non-users,

1308
01:16:43,360 --> 01:16:46,360
and what's the probability value inside here?

1309
01:16:46,360 --> 01:16:48,360
0.01, right?

1310
01:16:48,360 --> 01:16:51,360
Because we're only interested, we're interested in,

1311
01:16:51,360 --> 01:16:56,360
given that you're positive, what is the probability that you are a true user

1312
01:16:56,360 --> 01:17:00,360
or not a user, right, of this drug?

1313
01:17:00,360 --> 01:17:06,360
So, what fraction of those tests will be positive for users?

1314
01:17:06,360 --> 01:17:10,360
What do we need to divide by?

1315
01:17:10,360 --> 01:17:15,360
We need the sum of non-users and users,

1316
01:17:15,360 --> 01:17:21,360
sorry, non-positive and positives,

1317
01:17:21,360 --> 01:17:24,360
or rather non-users that did test positive.

1318
01:17:24,360 --> 01:17:26,360
Gosh, the naming is tough.

1319
01:17:26,360 --> 01:17:30,360
That's the hardest thing in computer science, right?

1320
01:17:30,360 --> 01:17:33,360
If we calculate that,

1321
01:17:33,360 --> 01:17:39,360
you'll get something like, what, 0.3-ish?

1322
01:17:39,360 --> 01:17:40,360
You all get that?

1323
01:17:40,360 --> 01:17:43,360
Is this surprising?

1324
01:17:43,360 --> 01:17:44,360
Pardon me?

1325
01:17:44,360 --> 01:17:45,360
It's a big number.

1326
01:17:45,360 --> 01:17:48,360
It's a big number, yeah.

1327
01:17:48,360 --> 01:17:57,360
Yeah, like, we thought we could get away with like a 99% sensitive and 99% specific test.

1328
01:17:57,360 --> 01:18:01,360
But it turns out, because the thing that we're really interested in

1329
01:18:01,360 --> 01:18:06,360
is inferring the thing that isn't shown from the data.

1330
01:18:06,360 --> 01:18:09,360
The thing that isn't shown from the data is the latent thing,

1331
01:18:09,360 --> 01:18:12,360
that is, are you a drug user or not?

1332
01:18:12,360 --> 01:18:14,360
And then that shows up in the drug test,

1333
01:18:14,360 --> 01:18:17,360
but the drug test has some probability of error as well.

1334
01:18:17,360 --> 01:18:20,360
So, if we go back and think about that tree that we drew,

1335
01:18:20,360 --> 01:18:23,360
that's the full data-generating process.

1336
01:18:23,360 --> 01:18:27,360
That is the full data-generating process for the things that we observed.

1337
01:18:27,360 --> 01:18:33,360
And now we can use that to back-infer the probability of the thing that we're interested in

1338
01:18:33,360 --> 01:18:40,360
rather than the probability of data given the underlying condition or the model,

1339
01:18:40,360 --> 01:18:45,360
rather than the, sorry, probability of the model, underlying condition or model given the data,

1340
01:18:45,360 --> 01:18:47,360
rather than the thing that is easy to simulate.

1341
01:18:47,360 --> 01:18:53,360
The thing that's really easy to simulate is probability of the data given my model of the world,

1342
01:18:53,360 --> 01:18:56,360
but what if my model is wrong, right?

1343
01:18:56,360 --> 01:18:59,360
What if my model needs updating?

1344
01:18:59,360 --> 01:19:05,360
And so that's where this Bayes rule thing comes in handy, okay?

1345
01:19:05,360 --> 01:19:06,360
All right.

1346
01:19:06,360 --> 01:19:11,360
Now, if you look at how this is solved with Bayes theorem,

1347
01:19:11,360 --> 01:19:13,360
the equations are in the notebook.

1348
01:19:13,360 --> 01:19:15,360
Take a look at that.

1349
01:19:15,360 --> 01:19:17,360
What I'd encourage you to keep in mind, though,

1350
01:19:17,360 --> 01:19:23,360
is we're interested in the probability of our,

1351
01:19:23,360 --> 01:19:27,360
the distribution of our parameters of interest given the data, right?

1352
01:19:27,360 --> 01:19:32,360
When we're talking about modeling our data-generating process,

1353
01:19:32,360 --> 01:19:36,360
we're going to stick in parameters like, you know, p, right?

1354
01:19:36,360 --> 01:19:41,360
Probability of success or lambda or mu, you know?

1355
01:19:41,360 --> 01:19:44,360
Lambda for the rate of a Poisson process or mu,

1356
01:19:44,360 --> 01:19:48,360
the central tendency for a normally distributed thing.

1357
01:19:48,360 --> 01:19:52,360
But we might be wrong and we need to update our model having seen new data,

1358
01:19:52,360 --> 01:19:55,360
and that's where Bayes rule comes in, okay?

1359
01:19:55,360 --> 01:19:59,360
So we're going to look, what we're going to do next,

1360
01:19:59,360 --> 01:20:04,360
over the next two and a half hours, is to look very,

1361
01:20:04,360 --> 01:20:11,360
sorry, two hours, is to look very in-depth into two particular data-generating stories

1362
01:20:11,360 --> 01:20:14,360
that can be applied across multiple places.

1363
01:20:14,360 --> 01:20:18,360
So in some senses, these are fairly generic models

1364
01:20:18,360 --> 01:20:21,360
that you can take home and use in your modeling work.

1365
01:20:21,360 --> 01:20:25,360
But we're going to go really deep into each and every one of those.

1366
01:20:25,360 --> 01:20:29,360
And so, pardon me if you are already quite familiar with this,

1367
01:20:29,360 --> 01:20:31,360
but I think it's handy for a few reasons.

1368
01:20:31,360 --> 01:20:34,360
One, you'll have the mechanics of PMC-3,

1369
01:20:34,360 --> 01:20:39,360
which is the tool that we're going to use under your toolkit.

1370
01:20:39,360 --> 01:20:48,360
You'll also have the process of telling a data-generating story in your mind as well, okay?

1371
01:20:48,360 --> 01:20:52,360
And we'll have practice with that, okay?

1372
01:20:52,360 --> 01:20:54,360
So we're going to skip notebook number two

1373
01:20:54,360 --> 01:21:02,360
and instead move to notebook number three directly, okay?

1374
01:21:02,360 --> 01:21:08,360
So I'd like to invite you to open up notebook number three.

1375
01:21:08,360 --> 01:21:13,360
And this is where we jump right into what we would call

1376
01:21:13,360 --> 01:21:16,360
probabilistic programming and Bayesian estimation.

1377
01:21:16,360 --> 01:21:18,360
These are probabilistic programming.

1378
01:21:18,360 --> 01:21:25,360
Oh, sorry, go ahead.

1379
01:21:25,360 --> 01:21:32,360
Yeah, let me put that up.

1380
01:21:32,360 --> 01:21:40,360
Yeah, yeah, yeah, definitely, definitely, definitely.

1381
01:21:40,360 --> 01:21:46,360
So let's write this out, okay?

1382
01:21:46,360 --> 01:21:53,360
Bayes' rule states that p of x1, x2, the joint distribution,

1383
01:21:53,360 --> 01:21:57,360
sorry, Bayes' rule starts from this formulation.

1384
01:21:57,360 --> 01:22:01,360
It's p of x1 given x2 times p of x2,

1385
01:22:01,360 --> 01:22:10,360
which is equal to p of x2 given x1 times the probability of x1, okay?

1386
01:22:10,360 --> 01:22:11,360
All right?

1387
01:22:11,360 --> 01:22:22,360
So if we say probability, so if we do the rearrangement of terms,

1388
01:22:22,360 --> 01:22:28,360
then we get x1, well, let's make this fit the example that we're looking at.

1389
01:22:28,360 --> 01:22:38,360
Probability of x2 given x1 is therefore equal to p of x1 given x2 times p of x2

1390
01:22:38,360 --> 01:22:43,360
over p of x1.

1391
01:22:43,360 --> 01:22:47,360
Are we okay here so far?

1392
01:22:47,360 --> 01:22:49,360
Okay, it'll be up there.

1393
01:22:49,360 --> 01:22:54,360
I'm unfortunately restrained by the size of the screen here as well, right,

1394
01:22:54,360 --> 01:22:57,360
in order to fit enough inside here.

1395
01:22:57,360 --> 01:23:01,360
So let me use the pencil to illustrate what this is.

1396
01:23:01,360 --> 01:23:06,360
This is the marginals, okay?

1397
01:23:06,360 --> 01:23:12,360
These are the marginals.

1398
01:23:12,360 --> 01:23:22,360
This is the conditional, okay?

1399
01:23:22,360 --> 01:23:30,360
This is what we're interested in.

1400
01:23:30,360 --> 01:23:32,360
Are we okay with that?

1401
01:23:32,360 --> 01:23:37,360
And what we're interested in is also a conditional, just to be clear.

1402
01:23:37,360 --> 01:23:42,360
We're interested in the red distribution.

1403
01:23:42,360 --> 01:23:50,360
However, we also need, in order to know the red distribution that's up here, okay?

1404
01:23:50,360 --> 01:23:56,360
In order to know that distribution, we actually need to know this distribution that I'm highlighting,

1405
01:23:56,360 --> 01:24:05,360
the probability of x1 given x2, but integrated or summed over all possible values of x2,

1406
01:24:05,360 --> 01:24:10,360
which therefore, let me switch mics,

1407
01:24:10,360 --> 01:24:15,360
which therefore means we're doing some form of summing over integration

1408
01:24:15,360 --> 01:24:21,360
over all horizontal slices of our data, okay?

1409
01:24:21,360 --> 01:24:27,360
So just to make this little clear, we're saying this top term up here

1410
01:24:27,360 --> 01:24:35,360
is basically this slice plus this slice plus this slice plus this slice

1411
01:24:35,360 --> 01:24:42,360
all multiplied together, okay?

1412
01:24:42,360 --> 01:24:45,360
That's what we're doing, and that's how that formulation, Bayes' Rule,

1413
01:24:45,360 --> 01:25:01,360
relates to this picture that we've drawn for conditional, marginal, and joint probability, right?

1414
01:25:01,360 --> 01:25:10,360
Okay, so I'd like to have you all open up notebook number three.

1415
01:25:10,360 --> 01:25:17,360
So we're going to do probabilistic programming, and we're going to start with the coin flip story, right?

1416
01:25:17,360 --> 01:25:25,360
The coin flip story is way too classic, but it's really one of those anchoring examples in my mind, all right?

1417
01:25:25,360 --> 01:25:31,360
So if you master the complexities that we can build on top of it for the coin flip story,

1418
01:25:31,360 --> 01:25:40,360
then you'll grasp a lot of concepts that are usable across multiple different types of models.

1419
01:25:40,360 --> 01:25:46,360
Okay, so we're going to do estimation, like I mentioned,

1420
01:25:46,360 --> 01:25:52,360
one of the core activities of statistical inference is estimation of the parameter given data.

1421
01:25:52,360 --> 01:25:55,360
Notice the given, right? There's a conditional,

1422
01:25:55,360 --> 01:25:58,360
so we're jointly modeling our data and our parameters together,

1423
01:25:58,360 --> 01:26:01,360
and we're saying, given that we've observed data now,

1424
01:26:01,360 --> 01:26:06,360
what's the distribution of parameters that we've got, okay?

1425
01:26:06,360 --> 01:26:12,360
So go ahead, run that first cell.

1426
01:26:12,360 --> 01:26:16,360
The first thing that we're going to do is we're going to actually look at some,

1427
01:26:16,360 --> 01:26:20,360
we're going to look at click-through rates, again, the classic binomial thing,

1428
01:26:20,360 --> 01:26:23,360
rather than coin flips, coin flips are a little too boring.

1429
01:26:23,360 --> 01:26:27,360
So let's look at click-through rates by loading this cell.

1430
01:26:27,360 --> 01:26:33,360
Ooh, I lost my kernel again.

1431
01:26:33,360 --> 01:26:36,360
You know what, if you all don't mind, I'm going to switch over to the instructor notebook

1432
01:26:36,360 --> 01:26:39,360
and not code along, but I'll make sure that you all have enough time,

1433
01:26:39,360 --> 01:26:44,360
because I have all the write outputs in the instructor notebooks.

1434
01:26:45,360 --> 01:26:56,360
Yes, notebook three.

1435
01:26:56,360 --> 01:27:00,360
So last night I posted on our Slack, do a new Git pull.

1436
01:27:00,360 --> 01:27:03,360
So make sure you, if you haven't done that, do a Git pull.

1437
01:27:03,360 --> 01:27:06,360
So that should hopefully clear up the confusion.

1438
01:27:06,360 --> 01:27:09,360
By the way, for the tutorials, get up on the Slack,

1439
01:27:09,360 --> 01:27:16,360
because it's a useful channel for the instructors to one way communicate information

1440
01:27:16,360 --> 01:27:21,360
and the other way get back questions.

1441
01:27:21,360 --> 01:27:25,360
Okay, so let's look at the click-through rates data.

1442
01:27:25,360 --> 01:27:30,360
You all have that loaded.

1443
01:27:30,360 --> 01:27:36,360
Oh, good, my thing's working now.

1444
01:27:36,360 --> 01:27:39,360
You should get data that looks something like this.

1445
01:27:39,360 --> 01:27:42,360
So we've done this test.

1446
01:27:42,360 --> 01:27:45,360
We have a case and a control.

1447
01:27:45,360 --> 01:27:51,360
And we've measured for every single visitor to our website,

1448
01:27:51,360 --> 01:27:56,360
whether they clicked on the button within a fixed period of time

1449
01:27:56,360 --> 01:27:59,360
or whether they just decided to leave.

1450
01:27:59,360 --> 01:28:05,360
Okay, so how then do we use PMC syntax to build a model

1451
01:28:05,360 --> 01:28:14,360
that helps us estimate the true value of P with its uncertainty for this data?

1452
01:28:14,360 --> 01:28:18,360
So if you didn't have PMC three, what might you do?

1453
01:28:18,360 --> 01:28:22,360
You might do a data frame dot group by, right?

1454
01:28:22,360 --> 01:28:34,360
So you might do R dot group by group dot mean.

1455
01:28:34,360 --> 01:28:35,360
Something like that.

1456
01:28:35,360 --> 01:28:36,360
Oh, well, okay.

1457
01:28:36,360 --> 01:28:40,360
Yeah, I need to run the cell.

1458
01:28:40,360 --> 01:28:41,360
You might do something like that.

1459
01:28:41,360 --> 01:28:46,360
And if someone runs that code, what number do you get?

1460
01:28:46,360 --> 01:28:49,360
While mine's running, it has to connect to the kernel.

1461
01:28:49,360 --> 01:28:52,360
Can someone do that?

1462
01:28:52,360 --> 01:28:55,360
Oh, CTR, my bad.

1463
01:28:55,360 --> 01:28:56,360
Click through rate.

1464
01:28:56,360 --> 01:28:59,360
Here, you'll get something that looks like this.

1465
01:28:59,360 --> 01:29:06,360
You'll get like a 0.14050 for one group and 0.19125.

1466
01:29:06,360 --> 01:29:08,360
Click through rate for the other group, right?

1467
01:29:08,360 --> 01:29:14,360
And how much would you believe that data?

1468
01:29:14,360 --> 01:29:15,360
Maybe true.

1469
01:29:15,360 --> 01:29:16,360
Maybe not.

1470
01:29:16,360 --> 01:29:23,360
It depends on how our data were split between the control and the test group, right?

1471
01:29:23,360 --> 01:29:29,360
Usually, we do a random splitting, but in this case, some malfunction happens.

1472
01:29:29,360 --> 01:29:35,360
So we only had really 200 data points out of 1,000 for one of the groups and 800 for the other.

1473
01:29:35,360 --> 01:29:37,360
So we don't have 50-50 splits.

1474
01:29:37,360 --> 01:29:39,360
We have 80-20 splits.

1475
01:29:39,360 --> 01:29:44,360
One of the groups is going to be smaller.

1476
01:29:44,360 --> 01:29:47,360
Oh, it's actually 2,800, so it's even worse.

1477
01:29:47,360 --> 01:29:51,360
It's not even one of those nice round numbers that we can think about.

1478
01:29:51,360 --> 01:29:53,360
So, cool.

1479
01:29:53,360 --> 01:29:56,360
So we've got this skewed amount of data.

1480
01:29:56,360 --> 01:30:04,360
Which number do you believe in more, given that you know that the test group only has 800?

1481
01:30:04,360 --> 01:30:07,360
You believe the control number more, right?

1482
01:30:07,360 --> 01:30:11,360
And that's because we've got more measurements for them.

1483
01:30:11,360 --> 01:30:12,360
All right.

1484
01:30:12,360 --> 01:30:23,360
Well, what we're going to do is we're going to spend a bit of time thinking about what the data-generating process looks like for this kind of model.

1485
01:30:23,360 --> 01:30:33,360
So let that come up.

1486
01:30:33,360 --> 01:30:45,360
What does the data-generating process look like for a Bernoulli or a binomially distributed data?

1487
01:30:45,360 --> 01:30:52,360
This, by the way, is the exact workflow by which I go about every single problem.

1488
01:30:52,360 --> 01:30:55,360
So we've got the question, what is the data-generating process?

1489
01:30:55,360 --> 01:30:58,360
Well, we start with the data that we have on hand.

1490
01:30:58,360 --> 01:31:02,360
We have Bernoulli distributed data.

1491
01:31:02,360 --> 01:31:22,360
So we'll say the likelihood follows a Bernoulli distribution.

1492
01:31:22,360 --> 01:31:26,360
Okay?

1493
01:31:26,360 --> 01:31:30,360
We're going to just estimate for the control group.

1494
01:31:30,360 --> 01:31:33,360
We're not going to do it with two groups just yet.

1495
01:31:33,360 --> 01:31:35,360
We'll build it for one.

1496
01:31:35,360 --> 01:31:49,360
So this parameter P, however, how is this distributed?

1497
01:31:49,360 --> 01:31:54,360
Okay, so we got the value P.

1498
01:31:54,360 --> 01:31:57,360
How would we model that?

1499
01:31:57,360 --> 01:32:09,360
Well, if you've never seen click-through rate data before, how would you assign credibility points to the number line to correctly model P?

1500
01:32:09,360 --> 01:32:13,360
Talk with your neighbor for a minute or two.

1501
01:32:13,360 --> 01:32:16,360
This time I mean it, like really talk with your neighbor.

1502
01:32:16,360 --> 01:32:20,360
I hear some things crystallizing.

1503
01:32:20,360 --> 01:32:24,360
Do we have volunteers?

1504
01:32:24,360 --> 01:32:37,360
What might you believe about, how would you assign credibility points to the values that P can take on having never seen click-through rate data?

1505
01:32:37,360 --> 01:32:39,360
Uniform what?

1506
01:32:39,360 --> 01:32:40,360
Zero to one.

1507
01:32:40,360 --> 01:32:41,360
So let's try that.

1508
01:32:41,360 --> 01:32:55,360
We'll say then that P is distributed zero to one uniformly.

1509
01:32:55,360 --> 01:32:57,360
Okay?

1510
01:32:57,360 --> 01:33:02,360
This being the likelihood, down, oops.

1511
01:33:02,360 --> 01:33:10,360
This being the likelihood means we're actually going to, this, sorry, sorry, let me backtrack a little bit.

1512
01:33:10,360 --> 01:33:18,360
What we've just drawn here on the screen is one generative model for our data.

1513
01:33:18,360 --> 01:33:26,360
One generative model out of many possible models that we might want to build.

1514
01:33:26,360 --> 01:33:32,360
This thing that I've highlighted being the likelihood is the thing that we have observed.

1515
01:33:32,360 --> 01:33:39,360
Okay?

1516
01:33:39,360 --> 01:33:42,360
Zero.

1517
01:33:42,360 --> 01:33:44,360
I wish Raveen was here.

1518
01:33:44,360 --> 01:33:46,360
I would have him copy this model onto the whiteboard.

1519
01:33:46,360 --> 01:33:48,360
Give me one moment.

1520
01:34:09,360 --> 01:34:24,360
Okay.

1521
01:34:24,360 --> 01:34:26,360
So we got the model on the whiteboard.

1522
01:34:26,360 --> 01:34:33,360
I'm going to switch back and we're going to see how we can actually build that model with PIMC code really easily.

1523
01:34:33,360 --> 01:34:35,360
Okay?

1524
01:34:35,360 --> 01:34:44,360
So code along, I believe this is code along.

1525
01:34:44,360 --> 01:34:50,360
Since we're only doing the estimation for the control group, we're not going to worry about the test group just yet.

1526
01:34:50,360 --> 01:34:52,360
How do we write this model?

1527
01:34:52,360 --> 01:34:56,360
Well, we can write it this way.

1528
01:34:56,360 --> 01:34:59,360
We've got uniform.

1529
01:34:59,360 --> 01:35:01,360
Right?

1530
01:35:01,360 --> 01:35:05,360
Kind of looks very, very close to the picture we drew.

1531
01:35:05,360 --> 01:35:08,360
We'll call this variable P.

1532
01:35:08,360 --> 01:35:10,360
It needs to have an explicit name.

1533
01:35:10,360 --> 01:35:16,360
So rule of thumb is whatever you name it in your variable, as the Python variable, just give it the exact same name.

1534
01:35:16,360 --> 01:35:21,360
Such that PIMC can recognize this.

1535
01:35:21,360 --> 01:35:22,360
Lower is zero.

1536
01:35:22,360 --> 01:35:25,360
Upper is one.

1537
01:35:25,360 --> 01:35:28,360
Okay?

1538
01:35:28,360 --> 01:35:38,360
And then the likelihood would be PIM.Bernoulli.

1539
01:35:38,360 --> 01:35:45,360
We'll name it likelihood, like P is equal to P.

1540
01:35:45,360 --> 01:35:48,360
A Bernoulli distribution only has one parameter.

1541
01:35:48,360 --> 01:35:50,360
It takes only one parameter in.

1542
01:35:50,360 --> 01:35:51,360
It's called P.

1543
01:35:51,360 --> 01:35:52,360
What is it?

1544
01:35:52,360 --> 01:35:56,360
It's distributed uniformly, having not seen the data.

1545
01:35:56,360 --> 01:35:58,360
Okay?

1546
01:35:58,360 --> 01:35:59,360
How are we doing?

1547
01:35:59,360 --> 01:36:02,360
Okay, so far, syntax, mechanics.

1548
01:36:02,360 --> 01:36:11,360
And then what we do next is we say observed is inside our data frame.

1549
01:36:11,360 --> 01:36:22,360
Control-DF clicks.

1550
01:36:22,360 --> 01:36:24,360
Okay?

1551
01:36:24,360 --> 01:36:33,360
So that means we've observed a sequence of ones and zeros, whether the user has clicked or not.

1552
01:36:33,360 --> 01:36:37,360
That is the data that we have observed for the Bernoulli distribution.

1553
01:36:37,360 --> 01:36:38,360
Okay?

1554
01:36:38,360 --> 01:36:40,360
So this is one way of writing that model.

1555
01:36:40,360 --> 01:36:44,360
I'm going to give you all, how are we doing with this syntax so far?

1556
01:36:44,360 --> 01:36:47,360
This is the mechanics part of building a model.

1557
01:36:47,360 --> 01:36:58,360
That said, if you think back to what we drew on the whiteboard just now, the syntax looks very similar, right?

1558
01:36:58,360 --> 01:37:08,360
The syntax here looks very similar to the syntax, sorry, the syntax in code looks very similar to the syntax, the thing that we drew on the whiteboard.

1559
01:37:08,360 --> 01:37:10,360
The pictures are much easier to reason about, right?

1560
01:37:10,360 --> 01:37:16,360
We can draw our data generative process here and directly translate it into code.

1561
01:37:16,360 --> 01:37:20,360
So that's one way of observing it.

1562
01:37:20,360 --> 01:37:23,360
There is another way, another formulation, right?

1563
01:37:23,360 --> 01:37:33,360
And if you remember what I said just now, the distribution, sorry, if you remember what I said just now, a sequence of Bernoulli's is binomially distributed,

1564
01:37:33,360 --> 01:37:39,360
which what that means then is we can actually write the model as a binomial likelihood,

1565
01:37:39,360 --> 01:37:45,360
but we'll have to change a little bit about how we do, how we structure the data to be input, okay?

1566
01:37:45,360 --> 01:37:50,360
But I'm going to just give you the binomial model as is,

1567
01:37:50,360 --> 01:38:00,360
and you can try to break the model or break how we structure the data so you get a better feel on how things should work.

1568
01:38:00,360 --> 01:38:04,360
Let's run that cell.

1569
01:38:04,360 --> 01:38:16,360
The next thing that we do, having written our model and telling PMC what we're conditioning on, is we say within this model context,

1570
01:38:16,360 --> 01:38:26,360
sorry, Model 1 Bernoulli, please sample from the posterior 2,000 times.

1571
01:38:26,360 --> 01:38:34,360
Give me 2,000 draws that describe how we expect the parameter P to look like.

1572
01:38:34,360 --> 01:38:39,360
It's a simulation, MC-based, Monte Carlo-based simulation of what the posterior will look like.

1573
01:38:39,360 --> 01:38:44,360
Now, this is kind of unnecessary for a simple coin flip model,

1574
01:38:44,360 --> 01:38:53,360
but when we go to slightly more complicated hierarchical versions, you'll see that this comes in really handy, okay?

1575
01:38:53,360 --> 01:39:00,360
Run that cell and do the same for the binomial.

1576
01:39:00,360 --> 01:39:02,360
It's literally PM.sample.

1577
01:39:02,360 --> 01:39:05,360
Literally, that's all you need to do.

1578
01:39:05,360 --> 01:39:09,360
What's happening here? Fancy math is happening for lazy programmers.

1579
01:39:09,360 --> 01:39:11,360
That's been the motto of Pi MC3.

1580
01:39:11,360 --> 01:39:18,360
We abstract away the math, the fancy math that is MCMC sampling or variational inference

1581
01:39:18,360 --> 01:39:21,360
and allow users to focus on building generative stories.

1582
01:39:21,360 --> 01:39:30,360
Really, the place when doing PMC modeling, the place that we need to keep our focus on is in the place that I've highlighted up there in the cell.

1583
01:39:30,360 --> 01:39:32,360
That is, what is the model definition?

1584
01:39:32,360 --> 01:39:36,360
Is it Bernoulli? Is it binomial?

1585
01:39:36,360 --> 01:39:40,360
I'd like you to run those two cells.

1586
01:39:40,360 --> 01:39:47,360
If you run those two cells and you plot the posterior distribution,

1587
01:39:47,360 --> 01:39:50,360
you'll get something that looks like this.

1588
01:39:50,360 --> 01:39:53,360
How do you do the posterior plotting?

1589
01:39:53,360 --> 01:40:01,360
You do RVs for which Ravine is one of the lead developers.

1590
01:40:01,360 --> 01:40:16,360
It's a visualization tool for taking a look at the results of MC sampling, all right?

1591
01:40:16,360 --> 01:40:25,360
It's kind to those who still haven't broken out of the histogram land.

1592
01:40:25,360 --> 01:40:31,360
I need to run all cells above.

1593
01:40:31,360 --> 01:40:34,360
I'd invite you to run that.

1594
01:40:34,360 --> 01:40:36,360
You should get something that looks like this.

1595
01:40:36,360 --> 01:40:39,360
It's happening on the left-hand side of the screen.

1596
01:40:39,360 --> 01:40:49,360
You'll then get a posterior distribution, a view on what we believe about the value of P,

1597
01:40:49,360 --> 01:41:04,360
having seen the data and having explicitly stated what we believe prior to seeing the data.

1598
01:41:04,360 --> 01:41:07,360
For now, I'm not going to go into that.

1599
01:41:07,360 --> 01:41:12,360
That is something slightly more advanced and that's the contents of Ravine's tutorial.

1600
01:41:12,360 --> 01:41:17,360
If you're not attending it, then catch the tutorial online,

1601
01:41:17,360 --> 01:41:24,360
because that's where they'll go into a little bit more of the theory behind the Monte Carlo sampling that goes on.

1602
01:41:24,360 --> 01:41:26,360
For now, we're going to ignore those errors.

1603
01:41:26,360 --> 01:41:30,360
What I want to give you is the mechanics of writing the model

1604
01:41:30,360 --> 01:41:36,360
and the mechanics of sampling and the mechanics of visualizing and interpreting.

1605
01:41:36,360 --> 01:41:48,360
Do the same for the binomial model.

1606
01:41:48,360 --> 01:41:51,360
You should get something that looks like that.

1607
01:41:51,360 --> 01:42:06,360
The values range from 0.125 to about 0.155, the 94% highest posterior density.

1608
01:42:06,360 --> 01:42:14,360
All that says is that 94% of the credibility is assigned within this black bar region.

1609
01:42:14,360 --> 01:42:17,360
That's what we believe is true.

1610
01:42:17,360 --> 01:42:19,360
Question?

1611
01:42:20,360 --> 01:42:22,360
I understand it.

1612
01:42:22,360 --> 01:42:24,360
The area was the uniform.

1613
01:42:24,360 --> 01:42:27,360
We showed all the data that we had.

1614
01:42:27,360 --> 01:42:29,360
That was the data frame.

1615
01:42:29,360 --> 01:42:36,360
And I am simply completely able to sample the data.

1616
01:42:36,360 --> 01:42:40,360
Exactly that.

1617
01:42:41,360 --> 01:42:47,360
What I'd like you to do then is you've basically got the template

1618
01:42:47,360 --> 01:42:53,360
that you need to now replicate this for doing two groups within a new model.

1619
01:42:53,360 --> 01:42:57,360
I'd like you to do is the hands-on activity below,

1620
01:42:57,360 --> 01:43:04,360
in which you build a model that does both estimations,

1621
01:43:04,360 --> 01:43:08,360
one for the control group and one for the test group,

1622
01:43:08,360 --> 01:43:10,360
in about five to ten minutes,

1623
01:43:10,360 --> 01:43:14,360
such that you get up to this point where you get this plot.

1624
01:43:14,360 --> 01:43:16,360
Go ahead and do that.

1625
01:43:16,360 --> 01:43:19,360
Question?

1626
01:43:19,360 --> 01:43:20,360
Oh, okay.

1627
01:43:20,360 --> 01:43:22,360
I'll come and address it.

1628
01:43:39,360 --> 01:43:41,360
Yes.

1629
01:43:41,360 --> 01:44:05,360
Good question.

1630
01:44:05,360 --> 01:44:13,360
It happens when you're doing the sampling.

1631
01:44:13,360 --> 01:44:18,360
It happens when you're doing the sampling.

1632
01:44:18,360 --> 01:44:21,360
Ah, okay.

1633
01:44:21,360 --> 01:44:27,360
Okay, okay, okay.

1634
01:44:27,360 --> 01:44:28,360
Give me a moment.

1635
01:44:28,360 --> 01:44:30,360
I'm blanking right now.

1636
01:44:30,360 --> 01:44:39,360
All right.

1637
01:44:39,360 --> 01:44:43,360
So I'm going to give this to you that it is the math is being executed

1638
01:44:43,360 --> 01:44:45,360
when you hit PM.sample.

1639
01:44:45,360 --> 01:44:49,360
But really what happens underneath the hood is we've computed a joint likelihood

1640
01:44:49,360 --> 01:44:52,360
of all the parameters with the data.

1641
01:44:52,360 --> 01:45:00,360
And then we use MC sampling to figure out what the typical set of the posterior is.

1642
01:45:00,360 --> 01:45:04,360
And the goal here is to sample around the typical set.

1643
01:45:04,360 --> 01:45:13,360
That is the typical range of values for each of the parameters that are involved.

1644
01:45:13,360 --> 01:45:25,360
All right.

1645
01:45:25,360 --> 01:45:27,360
Okay, so how many of you are done?

1646
01:45:27,360 --> 01:45:29,360
Thumbs up.

1647
01:45:29,360 --> 01:45:31,360
We've got a bunch of people who are still working at it.

1648
01:45:31,360 --> 01:45:43,360
So if you're stuck, you should have something that looks like this.

1649
01:45:43,360 --> 01:45:45,360
You can do it with the binomial.

1650
01:45:45,360 --> 01:45:48,360
So I'm encouraging you to try it with the binomial rather than the Bernoulli.

1651
01:45:48,360 --> 01:46:17,360
But if you want the Bernoulli, I'll code it live for you all.

1652
01:46:17,360 --> 01:46:46,360
Okay.

1653
01:46:46,360 --> 01:46:55,360
Oh, I see.

1654
01:46:55,360 --> 01:46:57,360
I hear fans running.

1655
01:46:57,360 --> 01:47:02,360
Someone's sampling real hard.

1656
01:47:02,360 --> 01:47:07,360
Thank you.

1657
01:47:07,360 --> 01:47:11,360
So if you're interested in what the Bernoulli formulation will look like, it'll look like this.

1658
01:47:11,360 --> 01:47:14,360
The binomial formulation looks like that on the right-hand side.

1659
01:47:14,360 --> 01:47:21,360
All right, okay.

1660
01:47:21,360 --> 01:47:28,360
And then if we're going to sample from the posterior, once again fancy math happens for lazy programmers.

1661
01:47:28,360 --> 01:47:50,360
All right.

1662
01:47:50,360 --> 01:48:00,360
So if you do this final thing, which is a deterministic transform of your random variables,

1663
01:48:00,360 --> 01:48:07,360
you can actually explicitly compute the posterior distribution of the difference of the two p's.

1664
01:48:07,360 --> 01:48:14,360
And this would be akin to what you're trying to do if you were to do a t-test of sorts, right?

1665
01:48:14,360 --> 01:48:18,360
Basically you're just comparing two means and asking how overlapping are they.

1666
01:48:18,360 --> 01:48:20,360
Are they overlapping or not?

1667
01:48:20,360 --> 01:48:21,360
A binary decision.

1668
01:48:21,360 --> 01:48:25,360
Are they completely overlapping or partially overlapping or completely non-overlapping?

1669
01:48:25,360 --> 01:48:27,360
Is one greater than the other, right?

1670
01:48:27,360 --> 01:48:30,360
We're asking questions like this basically.

1671
01:48:30,360 --> 01:48:32,360
So I'll show you how to do that.

1672
01:48:32,360 --> 01:48:39,360
You can do pdiff is pm.deterministic.

1673
01:48:39,360 --> 01:48:43,360
And it's nothing more than math on probability distributions.

1674
01:48:43,360 --> 01:48:46,360
So we'll say ptest minus pcontrol.

1675
01:48:46,360 --> 01:48:54,360
We'll define test minus control as the diff difference between the two and rerun that.

1676
01:48:54,360 --> 01:49:03,360
And what we'll get is a posterior distribution on the difference of the two parameters.

1677
01:49:04,360 --> 01:49:13,360
So I'm really tempted to ask this, but in a t-test would this be significant?

1678
01:49:17,360 --> 01:49:21,360
So yeah, okay, sure.

1679
01:49:21,360 --> 01:49:23,360
Now next question.

1680
01:49:23,360 --> 01:49:26,360
Would the t-test be appropriate?

1681
01:49:26,360 --> 01:49:28,360
Why?

1682
01:49:34,360 --> 01:49:42,360
Well, there is an n if we're doing, so that it's not the right thing to do is the correct answer,

1683
01:49:42,360 --> 01:49:45,360
but I disagree slightly with the reasoning.

1684
01:49:45,360 --> 01:49:46,360
We do have multiple n's.

1685
01:49:46,360 --> 01:49:49,360
We have multiple observations here.

1686
01:49:49,360 --> 01:49:53,360
So that's accounted for.

1687
01:49:53,360 --> 01:50:00,360
Let me ask you about the, back there.

1688
01:50:00,360 --> 01:50:04,360
Maybe power calculations are one thing that I had a long Twitter thread on.

1689
01:50:04,360 --> 01:50:08,360
Thankfully it's not a rant, so you can read it.

1690
01:50:08,360 --> 01:50:12,360
I'll post that.

1691
01:50:12,360 --> 01:50:15,360
Yeah, so let's see.

1692
01:50:15,360 --> 01:50:20,360
Can a probability be normally distributed?

1693
01:50:20,360 --> 01:50:24,360
No, why?

1694
01:50:24,360 --> 01:50:26,360
Right, right, exactly.

1695
01:50:26,360 --> 01:50:31,360
Now we can approximate it with a normal distribution, but we have to be extremely clear.

1696
01:50:31,360 --> 01:50:36,360
That's an approximation of what already is an approximation.

1697
01:50:36,360 --> 01:50:38,360
A model is an approximation of the world.

1698
01:50:38,360 --> 01:50:40,360
We're putting another approximation on top.

1699
01:50:40,360 --> 01:50:42,360
Whoa, okay.

1700
01:50:42,360 --> 01:50:49,360
All right, so this is where knowledge of the shapes and the support of the distributions comes in handy.

1701
01:50:49,360 --> 01:50:51,360
P is a probability.

1702
01:50:51,360 --> 01:50:55,360
It can never take any value below zero or above one.

1703
01:50:55,360 --> 01:51:02,360
So why would you impose a normal distribution on the probability parameter p?

1704
01:51:02,360 --> 01:51:06,360
Especially now, we don't need to do any math.

1705
01:51:06,360 --> 01:51:12,360
We don't need to write equations out and solve these equations that tell us what the posterior will look like

1706
01:51:12,360 --> 01:51:14,360
having seen data under a normal approximation.

1707
01:51:14,360 --> 01:51:15,360
We don't have to.

1708
01:51:15,360 --> 01:51:19,360
We can explicitly sample from the posterior using MC simulation.

1709
01:51:19,360 --> 01:51:27,360
So why not go whole hog and just use probability distributions that are bounded from zero to one?

1710
01:51:27,360 --> 01:51:28,360
Right?

1711
01:51:28,360 --> 01:51:30,360
Okay, cool, great.

1712
01:51:30,360 --> 01:51:34,360
So you all just had my, I did a talk at PyCon.

1713
01:51:34,360 --> 01:51:40,360
It was my 25 minute rant on why we don't always do the t-test,

1714
01:51:40,360 --> 01:51:43,360
why we should go away from canned statistical procedures.

1715
01:51:43,360 --> 01:51:45,360
This is one example of it.

1716
01:51:45,360 --> 01:51:48,360
P is not normally distributed.

1717
01:51:48,360 --> 01:51:52,360
We might look normally distributed, but it is definitely not normally distributed.

1718
01:51:52,360 --> 01:51:53,360
It's got to be bound.

1719
01:51:53,360 --> 01:51:59,360
So you can't take on a probability distribution that is bound from negative infinity to positive infinity.

1720
01:51:59,360 --> 01:52:01,360
If you do that, you're wrong.

1721
01:52:01,360 --> 01:52:03,360
Okay?

1722
01:52:03,360 --> 01:52:05,360
Cool, great.

1723
01:52:05,360 --> 01:52:14,360
And on this hypothesis testing thing, think about, there's a great blog post by Alan Downey, again.

1724
01:52:14,360 --> 01:52:22,360
That talks about the fact that every single classical statistical test boils down to one framework.

1725
01:52:22,360 --> 01:52:27,360
And if you go Bayesian, there's really no reason to calculate p-values and the likes.

1726
01:52:27,360 --> 01:52:32,360
You just look at posteriors and look at the posterior distributions of statistics,

1727
01:52:32,360 --> 01:52:35,360
single-valued statistics, single distributed, sorry,

1728
01:52:35,360 --> 01:52:37,360
single-variate statistics that you're interested in.

1729
01:52:37,360 --> 01:52:40,360
You don't have to worry about p-values here.

1730
01:52:40,360 --> 01:52:41,360
Okay?

1731
01:52:41,360 --> 01:52:43,360
Are we all right with that?

1732
01:52:43,360 --> 01:52:46,360
Cool, cool, cool, cool, great.

1733
01:52:46,360 --> 01:52:53,360
Now, knowing that the probability difference is,

1734
01:52:53,360 --> 01:52:57,360
knowing this probability difference is all good and useful,

1735
01:52:57,360 --> 01:53:08,360
but it's still not tied to something that is real world and interpretable in the minds of our executive friends, right?

1736
01:53:08,360 --> 01:53:12,360
So how do we take this metric that we've calculated?

1737
01:53:12,360 --> 01:53:16,360
p-diff and turn that into something that matters.

1738
01:53:16,360 --> 01:53:21,360
Well, one thing that you might learn from Raveen's tutorial if you're going or watching it later

1739
01:53:21,360 --> 01:53:29,360
is that there is this idea of a loss function or a cost function that we can attach to these things of interest.

1740
01:53:29,360 --> 01:53:32,360
And I'm going to just show you a very simple example, okay?

1741
01:53:32,360 --> 01:53:34,360
Let's say we know one thing.

1742
01:53:34,360 --> 01:53:44,360
We've computed with other data and said that our customers on average spend 25 U.S. dollars if they click

1743
01:53:44,360 --> 01:53:47,360
and zero U.S. dollars if they don't click, right?

1744
01:53:47,360 --> 01:53:51,360
Like, there's money attached to this process.

1745
01:53:51,360 --> 01:53:55,360
How that money is attached to this process, we can always write an equation that describes ours.

1746
01:53:55,360 --> 01:53:59,360
We'll write one arbitrary one, so we don't have to go too deep into what it is.

1747
01:53:59,360 --> 01:54:06,360
But if you take this, if you look at what's in the trace for p-diff,

1748
01:54:06,360 --> 01:54:13,360
you'll notice it's nothing more than a sequence of 2,000 draws from that posterior, okay?

1749
01:54:13,360 --> 01:54:16,360
So run that on your own notebooks as well.

1750
01:54:16,360 --> 01:54:18,360
Just open up and view what p-diff is.

1751
01:54:18,360 --> 01:54:21,360
It's a NumPy array. It's got 2,000 numbers, okay?

1752
01:54:21,360 --> 01:54:30,360
So a difference in probability can translate into a difference in amount of money being spent.

1753
01:54:30,360 --> 01:54:36,360
And if we attach a single, you know, a single dollar value to each and every one of those,

1754
01:54:36,360 --> 01:54:39,360
rather than a distribution, that's not complicated for the moment.

1755
01:54:39,360 --> 01:54:51,360
We can do something like dollar distribution is trace of p-diff times 25 times 1 million, right?

1756
01:54:51,360 --> 01:54:57,360
Over a million customers, there's an increase in the probability that they spend money,

1757
01:54:57,360 --> 01:54:59,360
so under the test group.

1758
01:54:59,360 --> 01:55:03,360
And so how much increase do we expect over a million customers?

1759
01:55:03,360 --> 01:55:05,360
Let's translate into some real numbers.

1760
01:55:10,360 --> 01:55:11,360
We'll do that.

1761
01:55:11,360 --> 01:55:20,360
And finally, you should get something like that.

1762
01:55:20,360 --> 01:55:22,360
You should get something like that.

1763
01:55:22,360 --> 01:55:24,360
So what does this say?

1764
01:55:24,360 --> 01:55:29,360
Well, on average, we expect a lot of revenue increase,

1765
01:55:29,360 --> 01:55:34,360
but there is always this very, very small tail probability that we still might lose money.

1766
01:55:35,360 --> 01:55:41,360
And that's just the nature of our computation, okay?

1767
01:55:41,360 --> 01:55:43,360
So I just wanted to put that out there.

1768
01:55:43,360 --> 01:55:47,360
You can always tack on, this is highly custom per problem,

1769
01:55:47,360 --> 01:55:51,360
but you can always tack on a loss function or a cost function that describes,

1770
01:55:51,360 --> 01:55:55,360
that ties the metric of interest, you have to think about it,

1771
01:55:55,360 --> 01:56:03,360
to some dollar amount or some hours spent by people on a particular problem, okay?

1772
01:56:03,360 --> 01:56:09,360
And that's a way of communicating to so-called non-technical folks

1773
01:56:09,360 --> 01:56:16,360
who want to be maybe a little bit more spoon-fed on what we expect to see, okay?

1774
01:56:16,360 --> 01:56:18,360
Are we okay with this so far?

1775
01:56:18,360 --> 01:56:21,360
So far, so good.

1776
01:56:21,360 --> 01:56:24,360
Any questions?

1777
01:56:24,360 --> 01:56:27,360
Okay, if there are no questions, I want you to talk with your neighbor for one minute,

1778
01:56:27,360 --> 01:56:29,360
one new thing you learned.

1779
01:56:29,360 --> 01:56:31,360
Anybody want to share?

1780
01:56:31,360 --> 01:56:34,360
Who knew they learned? That's far.

1781
01:56:44,360 --> 01:56:46,360
Yep, yep, that's right.

1782
01:56:46,360 --> 01:56:48,360
That's the point of this first exercise.

1783
01:56:48,360 --> 01:56:51,360
Get you familiar with that mechanics of doing so.

1784
01:56:51,360 --> 01:56:53,360
Anything else?

1785
01:56:55,360 --> 01:56:57,360
Any, back there?

1786
01:57:02,360 --> 01:57:09,360
And that's the default sampler.

1787
01:57:22,360 --> 01:57:25,360
Yep, yep, absolutely, absolutely.

1788
01:57:32,360 --> 01:57:34,360
Yep.

1789
01:57:37,360 --> 01:57:39,360
How so?

1790
01:57:42,360 --> 01:57:44,360
Yep.

1791
01:57:46,360 --> 01:57:49,360
Oh gosh, so, yeah.

1792
01:57:52,360 --> 01:57:54,360
Yep.

1793
01:57:54,360 --> 01:57:56,360
Oh gosh.

1794
01:57:57,360 --> 01:57:59,360
Yep, and that's...

1795
01:58:02,360 --> 01:58:04,360
Right, right, absolutely.

1796
01:58:04,360 --> 01:58:09,360
And so, that actually brings up a very highly related point.

1797
01:58:09,360 --> 01:58:12,360
We built statistical models of the world.

1798
01:58:12,360 --> 01:58:14,360
We built statistical models of the world.

1799
01:58:14,360 --> 01:58:20,360
When I built the cost function, it was both somewhat of a hybrid of a statistical model

1800
01:58:20,360 --> 01:58:22,360
and a mechanistic model of the world.

1801
01:58:22,360 --> 01:58:28,360
That is, people who click will now spend money on average $25 per click,

1802
01:58:28,360 --> 01:58:32,360
and so, we do some multiplication and that expresses some mechanism.

1803
01:58:32,360 --> 01:58:35,360
But ultimately, they're models, and we have to validate them.

1804
01:58:35,360 --> 01:58:39,360
And so, that problem you brought up is, I think, one of the problems

1805
01:58:39,360 --> 01:58:42,360
that we don't know how to validate properly, I think,

1806
01:58:42,360 --> 01:58:47,360
because we don't have the negative data to build a good model.

1807
01:58:47,360 --> 01:58:50,360
We have all the positives, the successful molecules.

1808
01:58:50,360 --> 01:58:54,360
We don't know what the opportunity cost and how to model the opportunity cost

1809
01:58:54,360 --> 01:59:00,360
of those failed, you know, incorrectly modeled molecules would be.

1810
01:59:00,360 --> 01:59:03,360
Yeah, that's a very good point.

1811
01:59:03,360 --> 01:59:05,360
Anything else?

1812
01:59:05,360 --> 01:59:07,360
Okay.

1813
01:59:07,360 --> 01:59:10,360
If there are no other points, you'll notice...

1814
01:59:10,360 --> 01:59:12,360
All right, we have the case and the control group.

1815
01:59:12,360 --> 01:59:15,360
If you listen to many of my rants,

1816
01:59:15,360 --> 01:59:18,360
case and control isn't the only thing you can do.

1817
01:59:18,360 --> 01:59:21,360
You really can do, like, arbitrary number of groups

1818
01:59:21,360 --> 01:59:25,360
that are having to worry much about multiple hypothesis correction

1819
01:59:25,360 --> 01:59:29,360
and the likes and, like, you know, having this guillotine of p-values

1820
01:59:29,360 --> 01:59:31,360
which you chop off as you go down.

1821
01:59:31,360 --> 01:59:35,360
Oh, gosh, that's, like, I don't know how people came up with that,

1822
01:59:35,360 --> 01:59:38,360
but it's complicated, right?

1823
01:59:38,360 --> 01:59:43,360
Whereas, like, just looking at posteriors is so much more clean,

1824
01:59:43,360 --> 01:59:45,360
much easier to interpret as well.

1825
01:59:45,360 --> 01:59:50,360
So, we're going to do another example that's still the binomial story,

1826
01:59:50,360 --> 01:59:53,360
still the Bernoulli binomial story,

1827
01:59:53,360 --> 01:59:59,360
but it's going to show you how, like, we can't just copy-past a test control

1828
01:59:59,360 --> 02:00:04,360
player 1, player 2, player 3, player 4, player 857, right,

1829
02:00:04,360 --> 02:00:07,360
or write a for loop with functions, and that's just, like, way too much.

1830
02:00:07,360 --> 02:00:10,360
We can actually take advantage of some syntactic things

1831
02:00:10,360 --> 02:00:14,360
that allow us to write in a very concise fashion

1832
02:00:14,360 --> 02:00:18,360
these models that model multiple, you know, more than two groups, okay?

1833
02:00:19,360 --> 02:00:24,360
So, like y'all to scroll down, we're going to look at baseball data,

1834
02:00:24,360 --> 02:00:28,360
and this is one of the classic, classic,

1835
02:00:28,360 --> 02:00:32,360
this is one of those classic data sets that one would pick up, right?

1836
02:00:32,360 --> 02:00:36,360
So, we want to, we want to model the probability

1837
02:00:36,360 --> 02:00:40,360
that a player who is a batter will hit a pitch, right?

1838
02:00:40,360 --> 02:00:43,360
So, they have this stat called at bats and number of hits.

1839
02:00:43,360 --> 02:00:47,360
At bats is the n, the total number of times

1840
02:00:47,360 --> 02:00:49,360
that they've come up for batting,

1841
02:00:49,360 --> 02:00:52,360
and h hits is the total number of times

1842
02:00:52,360 --> 02:00:54,360
that they've actually hit the bat.

1843
02:00:54,360 --> 02:00:57,360
So, we've got some data from the baseball database,

1844
02:00:57,360 --> 02:00:59,360
all credit to them.

1845
02:00:59,360 --> 02:01:03,360
I'd like you to run this cell that loads the data.

1846
02:01:03,360 --> 02:01:07,360
Little pitch for a tool that I've been developing

1847
02:01:07,360 --> 02:01:10,360
alongside colleagues here, so Zach in the back,

1848
02:01:10,360 --> 02:01:12,360
he also works on this.

1849
02:01:12,360 --> 02:01:15,360
It's called Pyjanitor, and it's basically there to help you

1850
02:01:15,360 --> 02:01:18,360
make data preprocessing easy to read,

1851
02:01:18,360 --> 02:01:22,360
so that you have a clean API for cleaning data, all right?

1852
02:01:22,360 --> 02:01:26,360
So, we've got the data, I'd like you to load that.

1853
02:01:26,360 --> 02:01:30,360
You should see something that looks like this, okay?

1854
02:01:30,360 --> 02:01:34,360
We've got at bats, hits, the salary of the player,

1855
02:01:34,360 --> 02:01:37,360
and this extra column which we will use,

1856
02:01:37,360 --> 02:01:41,360
it's called player ID underscore encoded, okay?

1857
02:01:42,360 --> 02:01:46,360
It's basically just an integer encoding of the player ID,

1858
02:01:46,360 --> 02:01:48,360
nothing more than that.

1859
02:01:48,360 --> 02:01:51,360
You'll find out why that becomes handy later.

1860
02:01:51,360 --> 02:01:58,360
So, once again, it's the same old Bernoulli binomial sorry.

1861
02:01:58,360 --> 02:02:03,360
Now, because we have the data structured as at bats and hits,

1862
02:02:03,360 --> 02:02:06,360
which is the, what should we,

1863
02:02:06,360 --> 02:02:09,360
what is the likelihood that we want then?

1864
02:02:11,360 --> 02:02:14,360
Is it Bernoulli or binomial?

1865
02:02:15,360 --> 02:02:17,360
Pardon me?

1866
02:02:19,360 --> 02:02:22,360
Binomial, and why is it binomial?

1867
02:02:22,360 --> 02:02:25,360
Yes, because we know exactly how many times.

1868
02:02:25,360 --> 02:02:27,360
We're not recording every single bat.

1869
02:02:27,360 --> 02:02:30,360
We're summarizing, we're taking the summary statistics,

1870
02:02:30,360 --> 02:02:33,360
which is the total number of at bats and the total number of hits,

1871
02:02:33,360 --> 02:02:35,360
and this then forms the binomial story

1872
02:02:35,360 --> 02:02:39,360
in which we know the number of times something has come up for trial.

1873
02:02:39,360 --> 02:02:42,360
Something has come up for a test of whether they succeed or not, okay?

1874
02:02:42,360 --> 02:02:44,360
This is distinct from the Bernoulli,

1875
02:02:44,360 --> 02:02:46,360
where we only know that they're coming up,

1876
02:02:46,360 --> 02:02:49,360
and we just, we only know that they're coming up

1877
02:02:49,360 --> 02:02:53,360
for a success failure trial, and we know the probability,

1878
02:02:53,360 --> 02:02:56,360
but we don't have the number of times that they've got that, okay?

1879
02:02:56,360 --> 02:03:00,360
So, we'll be using a binomial distribution as a,

1880
02:03:00,360 --> 02:03:03,360
we'll be using a binomial distribution as the likelihood.

1881
02:03:03,360 --> 02:03:06,360
So, let's build this model,

1882
02:03:06,360 --> 02:03:10,360
and what I want you to do is to notice some syntactic changes here, okay?

1883
02:03:10,360 --> 02:03:17,360
So, first we'll have the pitch model.

1884
02:03:17,360 --> 02:03:19,360
We're going to build that.

1885
02:03:19,360 --> 02:03:25,360
I'm going to switch over now to a beta distribution, right?

1886
02:03:25,360 --> 02:03:29,360
A beta distribution is also bounded from 0 to 1.

1887
02:03:29,360 --> 02:03:31,360
It has the correct support.

1888
02:03:31,360 --> 02:03:35,360
A beta distribution also allows, has this parameter where,

1889
02:03:35,360 --> 02:03:39,360
two parameters that let us control the shape where it's skewed.

1890
02:03:39,360 --> 02:03:41,360
Is it skewed left or is it,

1891
02:03:41,360 --> 02:03:45,360
does it have more mass on the left or density on the right?

1892
02:03:45,360 --> 02:03:48,360
It lets us do all, it lets us do that, right?

1893
02:03:48,360 --> 02:03:50,360
It lets us control the shape of the distribution.

1894
02:03:50,360 --> 02:03:54,360
So, it's not just a simple flat uniform prior.

1895
02:03:54,360 --> 02:03:56,360
So, code along with that.

1896
02:03:56,360 --> 02:03:58,360
P is the name of the thing.

1897
02:03:58,360 --> 02:04:00,360
Alpha is 1, beta is 1.

1898
02:04:01,360 --> 02:04:07,360
And then the shape of this, this is a new thing.

1899
02:04:07,360 --> 02:04:16,360
The shape of this beta distribution is the number of players that we have.

1900
02:04:16,360 --> 02:04:19,360
So, all we're expressing now is that we've got,

1901
02:04:19,360 --> 02:04:23,360
instead of a single beta distribution that lives in memory,

1902
02:04:23,360 --> 02:04:26,360
we've got a vector of beta distributions.

1903
02:04:26,360 --> 02:04:29,360
One beta distribution per cell, right?

1904
02:04:29,360 --> 02:04:33,360
And that beta distribution maps onto one particular player, okay?

1905
02:04:33,360 --> 02:04:35,360
That's, that's what we're doing here.

1906
02:04:35,360 --> 02:04:40,360
The likelihood is binomially distributed.

1907
02:04:40,360 --> 02:04:47,360
So, PM.binomial, its name is like,

1908
02:04:47,360 --> 02:04:53,360
its P is distributed according to the beta distribution,

1909
02:04:53,360 --> 02:04:55,360
but it's a vector of distributions.

1910
02:04:55,360 --> 02:05:00,360
So, what this effectively does is it creates a vector of binomials, okay?

1911
02:05:00,360 --> 02:05:03,360
That's the key syntactic difference and conceptual difference

1912
02:05:03,360 --> 02:05:05,360
that you need to take away from this example.

1913
02:05:05,360 --> 02:05:07,360
You can get away with doing,

1914
02:05:07,360 --> 02:05:14,360
you can get away from for loops by simply vectorizing everything, okay?

1915
02:05:14,360 --> 02:05:18,360
N is data at bat, right?

1916
02:05:18,360 --> 02:05:20,360
This is the number of times they've come up.

1917
02:05:20,360 --> 02:05:26,360
And it's also a vector that is the same length of P.

1918
02:05:26,360 --> 02:05:41,360
And finally, observed is data hits, okay?

1919
02:05:41,360 --> 02:05:44,360
My line wrapping is coming into play.

1920
02:05:44,360 --> 02:05:49,360
Maybe I shouldn't set this in the Jupyter Notebook.

1921
02:05:49,360 --> 02:05:54,360
Now, we got that, but since we have salary information,

1922
02:05:54,360 --> 02:05:57,360
we've been talking about like,

1923
02:05:57,360 --> 02:06:02,360
we've been talking about tying things to real world numbers, right?

1924
02:06:02,360 --> 02:06:08,360
Let's compute a metric that says the probability of batting per unit of salary, right?

1925
02:06:08,360 --> 02:06:12,360
So, how, how we want that number to be as high as possible, right?

1926
02:06:12,360 --> 02:06:15,360
So, we want for the smallest salary, someone,

1927
02:06:15,360 --> 02:06:17,360
we want to figure out, for the smallest salary,

1928
02:06:17,360 --> 02:06:21,360
someone who bats has the highest batting percentage.

1929
02:06:21,360 --> 02:06:24,360
That would play right into the sabre metrics kind of thing, right?

1930
02:06:24,360 --> 02:06:28,360
You're looking for value for money on different metrics.

1931
02:06:28,360 --> 02:06:32,360
So, we'll do a deterministic transform.

1932
02:06:32,360 --> 02:06:37,360
We'll call this P per salary, PPS, okay?

1933
02:06:38,360 --> 02:06:45,360
And simply take P and divide it by the salary that we observe in the data.

1934
02:06:45,360 --> 02:06:48,360
How are we doing? Any questions so far?

1935
02:06:48,360 --> 02:06:49,360
So far, so good.

1936
02:06:49,360 --> 02:06:55,360
Following along, story, we, it's, by the way, the exact same data generating process,

1937
02:06:55,360 --> 02:07:02,360
the exact same story as we drew on the whiteboard.

1938
02:07:02,360 --> 02:07:04,360
Go ahead, do sampling then.

1939
02:07:04,360 --> 02:07:08,360
And look at, look at the posterior distributions.

1940
02:07:21,360 --> 02:07:23,360
So, notice how we're sampling.

1941
02:07:23,360 --> 02:07:25,360
It's fast.

1942
02:07:25,360 --> 02:07:28,360
I'm taking advantage of the GPU that I have at home.

1943
02:07:28,360 --> 02:07:33,360
This one in this particular case, I don't think it'll run any faster on the GPU than on,

1944
02:07:33,360 --> 02:07:41,360
on a CPU because there's no complex matrix multiplies that are going on.

1945
02:07:41,360 --> 02:07:44,360
But if you were to do like more complex things,

1946
02:07:44,360 --> 02:07:46,360
complicated things like Bayesian neural net,

1947
02:07:46,360 --> 02:07:49,360
which you actually can write in piano and IMC three,

1948
02:07:49,360 --> 02:07:51,360
there's totally no problem with that.

1949
02:07:51,360 --> 02:07:59,360
Then moving stuff onto the GPU can get you up to four to four to eight times faster sampling and fitting.

1950
02:07:59,360 --> 02:08:05,360
Okay, so we have built here.

1951
02:08:05,360 --> 02:08:08,360
Oh, I named it trace batting.

1952
02:08:08,360 --> 02:08:18,360
Let me resample again.

1953
02:08:18,360 --> 02:08:28,360
So what, what I've done then below is create this custom visualization that relies on IPI widgets and the likes to get it working.

1954
02:08:28,360 --> 02:08:35,360
The intent here is that if you were to visualize posterior distributions for 805 players,

1955
02:08:35,360 --> 02:08:39,360
that's 805 matplotlib axes that you're drawing to screen.

1956
02:08:39,360 --> 02:08:41,360
It's not the prettiest thing.

1957
02:08:41,360 --> 02:08:47,360
Okay, so we'll take advantage of some interactivity that we can build to.

1958
02:08:47,360 --> 02:08:50,360
Oh, it's not working on my screens, but it should be working on some of yours, right?

1959
02:08:50,360 --> 02:08:57,360
If you've got IPI widgets working, you'll get a select that you can actually look at and select multiple players.

1960
02:08:57,360 --> 02:09:05,360
And compare their, their P per salary and their cumulative, the cumulative distributions for each of those.

1961
02:09:05,360 --> 02:09:21,360
Okay, actually, while this is running, I'm just going to very quickly get up and running.

1962
02:09:21,360 --> 02:09:32,360
And so while you have that visualization up, I'd like you to try to hunt for the player that's got the highest PPS distribution.

1963
02:09:32,360 --> 02:09:41,360
And while I install some, while I reinstall some things, once, once I'm finished with the commands, we'll come back and talk about that.

1964
02:09:51,360 --> 02:10:18,360
Okay, so anybody found interesting players?

1965
02:10:18,360 --> 02:10:28,360
Yes.

1966
02:10:28,360 --> 02:10:36,360
That's right. So one thing that we have as an idea in Bayesian statistics is that in the limit of lots of data,

1967
02:10:36,360 --> 02:10:42,360
what your priors are really don't matter unless, unless you chose priors that can never change,

1968
02:10:42,360 --> 02:10:49,360
which means you're just hard coding your great uncles, your uncles viewpoints on politics, which will never change, right?

1969
02:10:49,360 --> 02:11:05,360
So, yeah.

1970
02:11:05,360 --> 02:11:23,360
Maybe I just need to reload.

1971
02:11:23,360 --> 02:11:30,360
My, my, my, my, it's very slow.

1972
02:11:30,360 --> 02:11:39,360
So do we have players that are, that look interesting?

1973
02:11:39,360 --> 02:11:42,360
Pardon me?

1974
02:11:42,360 --> 02:11:44,360
Okay.

1975
02:11:44,360 --> 02:11:46,360
Can you help me out a little bit?

1976
02:11:46,360 --> 02:11:56,360
What does their CDF look like?

1977
02:11:56,360 --> 02:11:57,360
Sure.

1978
02:11:57,360 --> 02:12:04,360
Exponential being, sorry.

1979
02:12:04,360 --> 02:12:07,360
Exponential being what?

1980
02:12:07,360 --> 02:12:13,360
This, this, this, this line that looks like that.

1981
02:12:13,360 --> 02:12:17,360
Okay, some look like this, right?

1982
02:12:17,360 --> 02:12:19,360
You'll have noticed some of that.

1983
02:12:19,360 --> 02:12:23,360
Any other patterns?

1984
02:12:23,360 --> 02:12:30,360
Yeah, squiggly, but more or less straight line.

1985
02:12:30,360 --> 02:12:34,360
Okay, let's talk about what each of these CDFs express.

1986
02:12:34,360 --> 02:12:40,360
What's this one expressing?

1987
02:12:40,360 --> 02:12:51,360
Yeah, essentially it's expressing that the credibility points are assigned anywhere from the lowest to the highest in pretty much a uniform distribution.

1988
02:12:51,360 --> 02:12:58,360
What about something that looks like this?

1989
02:12:58,360 --> 02:13:02,360
How tight is the distribution compared to the first one?

1990
02:13:02,360 --> 02:13:04,360
Very tight.

1991
02:13:04,360 --> 02:13:06,360
And it's also very shifted to the right, right?

1992
02:13:06,360 --> 02:13:09,360
Because this, the central tendency is way out over there.

1993
02:13:09,360 --> 02:13:10,360
Okay.

1994
02:13:10,360 --> 02:13:12,360
And then what else do we have?

1995
02:13:12,360 --> 02:13:14,360
We have this guy over here.

1996
02:13:14,360 --> 02:13:19,360
What's this guy like?

1997
02:13:19,360 --> 02:13:21,360
Something in the middle.

1998
02:13:21,360 --> 02:13:22,360
Something in the middle.

1999
02:13:22,360 --> 02:13:26,360
Still takes on lots of values, but the distribution is kind of skewed as well.

2000
02:13:26,360 --> 02:13:27,360
Right?

2001
02:13:27,360 --> 02:13:30,360
Because there's a, there's a long tail on the left.

2002
02:13:30,360 --> 02:13:36,360
Lots of, lots of probability or lots of credibility assigned to the middle over here.

2003
02:13:36,360 --> 02:13:38,360
And then it peters off at the top.

2004
02:13:38,360 --> 02:13:48,360
It'll always peter off at the top.

2005
02:13:48,360 --> 02:13:55,360
Once again, it's, it's the richness of statistical information.

2006
02:13:55,360 --> 02:13:58,360
So PDFs look a lot like CDFs.

2007
02:13:58,360 --> 02:14:00,360
Sorry, PDFs look a lot like histograms.

2008
02:14:00,360 --> 02:14:02,360
I take that back.

2009
02:14:02,360 --> 02:14:04,360
PDFs look a lot like histograms.

2010
02:14:04,360 --> 02:14:15,360
And so you can't tell more than the bounds and central tendency from a PDF.

2011
02:14:15,360 --> 02:14:23,360
Whereas you can tell quartiles and percent, percentiles and roughly estimate where they are from a CDF.

2012
02:14:23,360 --> 02:14:37,360
So most of the time I would just default to using a CDF rather than a histogram or a PDF.

2013
02:14:37,360 --> 02:14:38,360
Okay.

2014
02:14:38,360 --> 02:14:40,360
Let's see if this works.

2015
02:14:40,360 --> 02:14:42,360
My widget doesn't display.

2016
02:14:42,360 --> 02:14:43,360
Never mind.

2017
02:14:43,360 --> 02:14:45,360
I'll have the widget on your laptop.

2018
02:14:45,360 --> 02:14:49,360
So you'll be able to view that.

2019
02:14:49,360 --> 02:14:50,360
Okay.

2020
02:14:50,360 --> 02:14:52,360
So there are some interesting players.

2021
02:14:52,360 --> 02:15:01,360
One thing that's kind of interesting though is that we've got players like the uniform distribution one, right?

2022
02:15:01,360 --> 02:15:03,360
Super uninformative.

2023
02:15:03,360 --> 02:15:09,360
And that raises a problem.

2024
02:15:09,360 --> 02:15:12,360
The problem sounds something like this.

2025
02:15:12,360 --> 02:15:15,360
Now I'm going to pose this as a question to you all.

2026
02:15:15,360 --> 02:15:18,360
So think about it.

2027
02:15:18,360 --> 02:15:37,360
Having seen players, professional players play and do their thing, do you really expect that having a few at-bats,

2028
02:15:37,360 --> 02:15:44,360
that comes from the situation where we have like one or two at-bats and zero or one hits.

2029
02:15:44,360 --> 02:16:00,360
You really expect that having seen that one or two at-bats, we should still believe that their batting capability is at this near uniform from zero to one.

2030
02:16:00,360 --> 02:16:02,360
Talk about that with your neighbor.

2031
02:16:02,360 --> 02:16:07,360
And then tell me why.

2032
02:16:07,360 --> 02:16:08,360
Yes.

2033
02:16:08,360 --> 02:16:17,360
So do you really, should we really believe having seen one or two at-bats that performance would still range so wildly from zero to one basically?

2034
02:16:17,360 --> 02:16:19,360
What are your answers?

2035
02:16:19,360 --> 02:16:24,360
Should we really believe what we saw in the posterior results?

2036
02:16:24,360 --> 02:16:31,360
That performance gets basically, is still uniformly or close to uniformly distributed?

2037
02:16:31,360 --> 02:16:33,360
No, I see a head shaking.

2038
02:16:33,360 --> 02:16:36,360
Tell me why.

2039
02:16:36,360 --> 02:16:37,360
Both of you.

2040
02:16:37,360 --> 02:16:53,360
Both of you are a team.

2041
02:16:53,360 --> 02:16:57,360
Right, right.

2042
02:16:58,360 --> 02:17:03,360
So what we're encoding here is this notion.

2043
02:17:03,360 --> 02:17:07,360
So the response is pretty much how we would think about it, right?

2044
02:17:07,360 --> 02:17:16,360
The professional baseball players don't tend to have performances that range so wildly.

2045
02:17:16,360 --> 02:17:21,360
That is a piece of prior information that we can impose on the modeling problem.

2046
02:17:21,360 --> 02:17:23,360
So how do we impose that?

2047
02:17:24,360 --> 02:17:25,360
There are two ways.

2048
02:17:25,360 --> 02:17:27,360
One, we can have a stronger prior.

2049
02:17:27,360 --> 02:17:32,360
A stronger prior that is imposed on every single player.

2050
02:17:32,360 --> 02:17:34,360
So we might do a beta.

2051
02:17:34,360 --> 02:17:51,360
So if batting averages tend to fall within the range of 0.2 to 0.3, we might put a beta distribution with, so 0.2 is about approximately one success and four failures.

2052
02:17:51,360 --> 02:17:54,360
So it would be a beta distribution of one and four.

2053
02:17:54,360 --> 02:17:56,360
That is a slightly stronger prior.

2054
02:17:56,360 --> 02:18:05,360
Or if we wanted it to be even stronger, we would do a beta distribution of 10 and 40, which is much narrower compared to the beta of one and four.

2055
02:18:05,360 --> 02:18:08,360
If you don't believe me, go simulate it in NumPy.

2056
02:18:08,360 --> 02:18:10,360
The beta distribution is right there.

2057
02:18:10,360 --> 02:18:16,360
And if you really wanted to be a really strong prior, then it would be beta 100, 400.

2058
02:18:16,360 --> 02:18:22,360
That is the 0.2 batting average kind of prior we could put on here.

2059
02:18:26,360 --> 02:18:45,360
So the advantage of using the beta over the uniform is that I can now tweak the alpha and beta parameters of the beta distribution to change where we center the distribution and also change how wide or thin that distribution is.

2060
02:18:46,360 --> 02:18:53,360
So as I was mentioning, beta 1, 4 looks something like this, skewed, but kind of wide.

2061
02:18:53,360 --> 02:18:56,360
Beta 10, 40 looks something like this.

2062
02:18:56,360 --> 02:19:00,360
And beta 100, 400 looks something like that.

2063
02:19:00,360 --> 02:19:02,360
Are we okay with that?

2064
02:19:02,360 --> 02:19:10,360
So beta distributions give us a little bit more control over the shape of the distribution.

2065
02:19:10,360 --> 02:19:15,360
Okay, so putting tighter priors is one way.

2066
02:19:15,360 --> 02:19:25,360
Another way to approach this is actually to impose what we would call a hyper prior, one that governs the population of players.

2067
02:19:25,360 --> 02:19:28,360
So I'm going to switch over to drawing again.

2068
02:19:38,360 --> 02:19:43,360
We have the binomial likelihood.

2069
02:19:43,360 --> 02:19:45,360
And we know this already, right?

2070
02:19:45,360 --> 02:19:58,360
This is a very familiar story for us by now.

2071
02:19:58,360 --> 02:20:06,360
In the interest of saving space, I'm not going to draw out the distributions, but picture them in your head.

2072
02:20:06,360 --> 02:20:10,360
N is known.

2073
02:20:10,360 --> 02:20:21,360
P comes from another distribution.

2074
02:20:21,360 --> 02:20:31,360
The way I want you to think about this though is because we vectorized everything.

2075
02:20:31,360 --> 02:20:49,360
We've got a vector of binomial likelihoods and a corresponding vector of beta distributions for priors on the P parameter.

2076
02:20:49,360 --> 02:21:04,360
If we were to do this hierarchically, what we are effectively doing is asking what is the population alpha and beta look like?

2077
02:21:04,360 --> 02:21:12,360
That's kind of ugly.

2078
02:21:13,360 --> 02:21:16,360
And we only have one of these each.

2079
02:21:16,360 --> 02:21:21,360
We don't have a vector of them because they're governing the entire population.

2080
02:21:21,360 --> 02:21:26,360
So when we do this hierarchical thing, we're effectively expressing this idea.

2081
02:21:26,360 --> 02:21:31,360
Players themselves are drawn from a parental distribution.

2082
02:21:31,360 --> 02:21:41,360
Professional players all generally follow some general distribution that is governing the performance of the individual players.

2083
02:21:41,360 --> 02:21:57,360
So the population distribution, which is imposed on A and B, that governs the individual player's performance parameter, which is the beta distributed thing,

2084
02:21:57,360 --> 02:22:03,360
which then influences the outcomes that we're interested in.

2085
02:22:03,360 --> 02:22:14,360
So let me just annotate that.

2086
02:22:14,360 --> 02:22:19,360
Up there we have the population parameters.

2087
02:22:19,360 --> 02:22:26,360
We have the individual parameters for P.

2088
02:22:26,360 --> 02:22:35,360
We have the likelihood which governs how our outcomes, the data that we observe, are generated.

2089
02:22:35,360 --> 02:22:38,360
Okay? Are we okay so far?

2090
02:22:38,360 --> 02:22:50,360
Now, I'm going to go on a limb and tell you that A and B, these two parameters, they also have distributions because then otherwise it wouldn't be probabilistic.

2091
02:22:50,360 --> 02:22:56,360
But now the question is, what is an appropriate distribution for A and B?

2092
02:22:56,360 --> 02:22:59,360
What might be an appropriate distribution for A and B?

2093
02:22:59,360 --> 02:23:03,360
I'll tell you a few snippets.

2094
02:23:03,360 --> 02:23:11,360
A and B govern the number of successes and failures effectively for the population of players.

2095
02:23:11,360 --> 02:23:16,360
This happens over a single year.

2096
02:23:16,360 --> 02:23:28,360
It can only be positive, so it being over a single year means there's generally a finite number of positives and successes and failures, A's and B's that every player has.

2097
02:23:28,360 --> 02:23:35,360
So given that you know that, what might be a suitable distribution? Let's not worry about the shape of the distribution just yet.

2098
02:23:35,360 --> 02:23:43,360
What is a suitable distribution?

2099
02:23:43,360 --> 02:23:51,360
For Poisson maybe, it being, I forgot to say, A and B can actually be continuous.

2100
02:23:51,360 --> 02:24:00,360
And that's sort of a giveaway that Poisson's not so ideal but we could try it.

2101
02:24:00,360 --> 02:24:06,360
What's a positive bound continuous distribution that you might have heard of?

2102
02:24:06,360 --> 02:24:11,360
Exponential is one. There's another one that we can define which is the half normal.

2103
02:24:11,360 --> 02:24:18,360
There is the normal distribution but chopped up in half such that now the support is defined only on the positive half.

2104
02:24:18,360 --> 02:24:20,360
That's one way to do it.

2105
02:24:20,360 --> 02:24:26,360
Gamma distribution is another. Gamma is actually I think a generalization of a number of child distributions.

2106
02:24:26,360 --> 02:24:30,360
It's got more parameters, it's a little bit more complicated, but yeah, we can totally do that.

2107
02:24:30,360 --> 02:24:35,360
Lognormal I think is as well, yeah.

2108
02:24:35,360 --> 02:24:38,360
Half Cauchy as well, like half student T, etc.

2109
02:24:38,360 --> 02:24:42,360
Yes, definitely. So we're all on the right track. We're thinking of distributions.

2110
02:24:42,360 --> 02:24:49,360
The key point is these distributions have to be positive bound because A and B can only take positive values.

2111
02:24:49,360 --> 02:24:55,360
If we were to do anything with the full normal distribution, we'd be doing it the wrong way.

2112
02:24:55,360 --> 02:25:02,360
So for simplicity's sake, let's assign A and B to take exponentials.

2113
02:25:02,360 --> 02:25:09,360
And the only reason I would start with this but maybe not end with it is that exponentials are easy.

2114
02:25:09,360 --> 02:25:16,360
They have a single parameter so there's not much hyper hyper parameters that we have to worry about.

2115
02:25:16,360 --> 02:25:23,360
This A and B thing that we're assigning distributions on, these are what we would call hyper priors.

2116
02:25:23,360 --> 02:25:28,360
Hyper being an added dimension, an added dimension of modeling that we're doing here.

2117
02:25:28,360 --> 02:25:36,360
So for the sake of simplicity, we'll start with a simple exponential.

2118
02:25:36,360 --> 02:25:44,360
What did I do in the real thing?

2119
02:25:44,360 --> 02:25:54,360
In the actual thing, we've used 1 over 29, which is just an arbitrary number, which we can always debate about, but we're not going to today.

2120
02:25:54,360 --> 02:26:00,360
We're going to do that in a long modeling critique session that my colleague Zach and I have done umpteen times now,

2121
02:26:00,360 --> 02:26:03,360
where we debate our priors, debate the model structure.

2122
02:26:03,360 --> 02:26:06,360
For now, for learning purposes, we'll just stick with that.

2123
02:26:06,360 --> 02:26:10,360
So let's take this model and code it up.

2124
02:26:10,360 --> 02:26:12,360
I'm going to switch back to the notebook.

2125
02:26:12,360 --> 02:26:19,360
I'd like to encourage you all to also switch over.

2126
02:26:19,360 --> 02:26:29,360
Inside the notebook, you will see that we've already got the binomial likelihood and the PPS metrics, the deterministic transforms defined for you.

2127
02:26:29,360 --> 02:26:40,360
So now I'd like you to code along and let's fill in the rest for the beta distribution and the A prior and B prior.

2128
02:26:40,360 --> 02:26:47,360
So we have alpha is A prior, beta is B prior.

2129
02:26:47,360 --> 02:26:54,360
The shape is still length of data.

2130
02:26:54,360 --> 02:27:03,360
And then we'll have exponential 1 over 29.

2131
02:27:03,360 --> 02:27:10,360
Oops.

2132
02:27:10,360 --> 02:27:15,360
Make sure it's all floating points.

2133
02:27:15,360 --> 02:27:21,360
And let's call it hierarchical baseball.

2134
02:27:21,360 --> 02:27:38,360
So once you've coded up the model, go ahead and sample from it and tell me what you see is kind of different.

2135
02:27:38,360 --> 02:27:51,360
You'll notice also this model is a little slower to sample from.

2136
02:27:51,360 --> 02:27:59,360
Okay, so while you all are waiting for models to sample and finish up, questions?

2137
02:27:59,360 --> 02:28:07,360
Yes, no problem.

2138
02:28:07,360 --> 02:28:13,360
Well, while things are sampling, it's actually a great time to talk with your neighbor about something new you've learned.

2139
02:28:13,360 --> 02:28:16,360
Okay.

2140
02:28:16,360 --> 02:28:32,360
Before we go on into something new you've learned, I want to ask a few questions about what you're observing about these baseball player posteriors having seen this having been fit under this hierarchical model.

2141
02:28:32,360 --> 02:28:43,360
What's different from what you saw before?

2142
02:28:43,360 --> 02:28:50,360
Okay, so you see more sigmoidal type of distributions rather than uniform or exponential types.

2143
02:28:50,360 --> 02:28:52,360
That's one good one.

2144
02:28:52,360 --> 02:28:57,360
What's another property that you're observing as well?

2145
02:28:57,360 --> 02:29:00,360
What are the bounds and ranges?

2146
02:29:00,360 --> 02:29:01,360
Pardon me?

2147
02:29:01,360 --> 02:29:03,360
They're more tight.

2148
02:29:03,360 --> 02:29:05,360
They're more tight.

2149
02:29:05,360 --> 02:29:15,360
And this is the result of this type of switching over to a hierarchical model rather than using an independent model.

2150
02:29:15,360 --> 02:29:26,360
So the first model that we wrote where every player is modeled as a beta distribution on its own, that is what I might call an independent model.

2151
02:29:26,360 --> 02:29:34,360
And then the hierarchical model actually sort of pools these player properties as being drawn from one parental distribution.

2152
02:29:34,360 --> 02:29:39,360
So they're sort of constrained by the parental distribution.

2153
02:29:39,360 --> 02:29:43,360
This is a property of hierarchical models.

2154
02:29:43,360 --> 02:29:47,360
I'm not going to design a value judgment on whether this is always good or always bad.

2155
02:29:47,360 --> 02:29:49,360
It depends on the problem.

2156
02:29:49,360 --> 02:30:13,360
But if it is justifiable by your modeling domain expertise, then a hierarchical model is actually a really powerful way to borrow information from players that have had lots of, from the population of players to do inference on the players that we have not had much information about.

2157
02:30:13,360 --> 02:30:29,360
So for those players that had one at bat and one success, what you will notice is that their posterior distribution is still, is going to be kind of wide, not as crazy wide as it was before.

2158
02:30:29,360 --> 02:30:39,360
It's going to be kind of wide, centered roughly around what the population mean is and follow roughly what the population mean is as well.

2159
02:30:39,360 --> 02:30:53,360
If you have something that's a little bit more extreme, like seven at bat, seven hits, then you'll get something that's shifted to the right because there's a little bit of information saying that this player is kind of good or maybe lucky, we don't know.

2160
02:30:53,360 --> 02:31:03,360
There's a bit of, it'll be shifted to the right, it'll be narrower, but it does express that, you know, it's not going to be wildly like 90, 90 something centered on 90 to 100%.

2161
02:31:03,360 --> 02:31:06,360
It's going to be centered off, shifted off.

2162
02:31:06,360 --> 02:31:19,360
So at least in this setting, it correctly encodes our intuition that players generally fall within this like population distributed.

2163
02:31:19,360 --> 02:31:26,360
They follow the population distribution much more than we would expect from just looking at them independently.

2164
02:31:26,360 --> 02:31:37,360
Okay, so this is a very powerful thing, that phenomena where you have these wild estimates being shrunk towards the population mean is called shrinkage.

2165
02:31:37,360 --> 02:31:40,360
Shrinkage is a term you'll want to look out for in the literature.

2166
02:31:40,360 --> 02:31:44,360
Okay, so you have this vocabulary that you won't be confused by.

2167
02:31:44,360 --> 02:31:56,360
Okay.

2168
02:31:56,360 --> 02:31:58,360
Yep.

2169
02:32:15,360 --> 02:32:28,360
Okay, okay, cool.

2170
02:32:28,360 --> 02:32:38,360
So the beta that we've put in there expresses a prior that is unconnected to any other player.

2171
02:32:38,360 --> 02:32:43,360
So the prior for the beta distribution, the A and the B,

2172
02:32:43,360 --> 02:32:50,360
the priors that we put, they are, even though they were point estimates, they're just saying this is, this is the shape.

2173
02:32:50,360 --> 02:32:55,360
We're putting an identical shape of distribution on every single player.

2174
02:32:55,360 --> 02:33:05,360
Now when we connect the players by saying they all draw from a population distribution, it's not that we're putting uncertainty.

2175
02:33:05,360 --> 02:33:10,360
I would be hesitant to say that we're putting uncertainty on A and B.

2176
02:33:10,360 --> 02:33:17,360
Rather, we're expressing that their shapes are now controlled by a population shape, right?

2177
02:33:17,360 --> 02:33:20,360
That's where, that's where this shrinkage comes in.

2178
02:33:20,360 --> 02:33:26,360
It's not that we've, we were really sure and so we assigned a single point value.

2179
02:33:26,360 --> 02:33:37,360
We know that the two point values can give one shape, but that shape for the beta distribution was unconnected to the population at first.

2180
02:33:37,360 --> 02:33:39,360
That's all it was.

2181
02:33:39,360 --> 02:33:40,360
Okay.

2182
02:33:40,360 --> 02:33:51,360
And now when we have a connected set of shapes, right, so we have a connected beta distributions by the hyper priors that we put on.

2183
02:33:51,360 --> 02:34:05,360
What we're saying is that there is a population shape for the beta and they're influencing and governing the individual player shapes, the beta distribution shapes.

2184
02:34:05,360 --> 02:34:08,360
Does that make sense?

2185
02:34:08,360 --> 02:34:17,360
By ironically putting a distribution on it, not putting a ring on it.

2186
02:34:18,360 --> 02:34:23,360
Yes, yes, yes.

2187
02:34:23,360 --> 02:34:28,360
So if in doubt, don't put a ring on it, put a distribution on it, okay?

2188
02:34:28,360 --> 02:34:31,360
Cool.

2189
02:34:31,360 --> 02:34:39,360
Right, so that's, that's that phenomena of shrinkage that I wanted everybody to have some intuition about, okay?

2190
02:34:39,360 --> 02:34:42,360
So let's now go into something that you've learned.

2191
02:34:42,360 --> 02:34:48,360
We've actually come to the end of the binomial story and we've gone really, really deep.

2192
02:34:48,360 --> 02:35:01,360
We've come from like the simple naive one, one group to two groups to now vectorizing over multiple groups to then now adding on a hierarchical model on top.

2193
02:35:01,360 --> 02:35:06,360
I'm hoping it's not yet information overload because there's more.

2194
02:35:06,360 --> 02:35:08,360
So what's something new you've learned?

2195
02:35:08,360 --> 02:35:11,360
And let's get that like etched in your head.

2196
02:35:11,360 --> 02:35:18,360
You have volunteers.

2197
02:35:18,360 --> 02:35:19,360
Sure.

2198
02:35:19,360 --> 02:35:20,360
Yeah, cool.

2199
02:35:20,360 --> 02:35:21,360
Great.

2200
02:35:21,360 --> 02:35:23,360
That was part of the point.

2201
02:35:23,360 --> 02:35:32,360
Anything else, something new that you didn't expect or something that has been resonating with you?

2202
02:35:32,360 --> 02:35:33,360
Maybe on this side.

2203
02:35:33,360 --> 02:35:38,360
This side has been really quiet.

2204
02:35:38,360 --> 02:35:42,360
I'm going to point at someone.

2205
02:35:42,360 --> 02:35:49,360
Second last row middle guy.

2206
02:35:49,360 --> 02:35:58,360
Anything new you've learned?

2207
02:35:59,360 --> 02:36:00,360
Okay, still processing.

2208
02:36:00,360 --> 02:36:01,360
That's completely valid.

2209
02:36:01,360 --> 02:36:02,360
That's totally cool.

2210
02:36:02,360 --> 02:36:09,360
And the fact that you're still not sure means there's processing going on and I fully appreciate that.

2211
02:36:09,360 --> 02:36:10,360
How about in the middle?

2212
02:36:10,360 --> 02:36:11,360
Anybody else?

2213
02:36:11,360 --> 02:36:17,360
Any volunteers?

2214
02:36:17,360 --> 02:36:20,360
Sorry, can you say it louder?

2215
02:36:20,360 --> 02:36:25,360
Okay, so reinforcing the value of the cumulative distribution plots, right?

2216
02:36:25,360 --> 02:36:27,360
That's super important.

2217
02:36:27,360 --> 02:36:36,360
The fact that we get richer information from that is very useful.

2218
02:36:36,360 --> 02:36:38,360
Oh, the beta distribution.

2219
02:36:38,360 --> 02:36:39,360
Ah, yes.

2220
02:36:39,360 --> 02:36:45,360
The fact that we're able to constrain and shape.

2221
02:36:45,360 --> 02:36:47,360
Yes, yes, exactly.

2222
02:36:47,360 --> 02:36:48,360
Exactly.

2223
02:36:48,360 --> 02:36:52,360
It's a very useful tool to have in the toolkit.

2224
02:36:52,360 --> 02:37:05,360
I think it's still, like, I don't know if it's going to fit in here, but in my, I don't know if it's going to fit in here.

2225
02:37:05,360 --> 02:37:10,360
Yep.

2226
02:37:10,360 --> 02:37:11,360
Cool, cool.

2227
02:37:11,360 --> 02:37:12,360
Awesome.

2228
02:37:12,360 --> 02:37:13,360
And back there.

2229
02:37:13,360 --> 02:37:14,360
Last one.

2230
02:37:14,360 --> 02:37:16,360
I knew what I knew.

2231
02:37:16,360 --> 02:37:17,360
Yeah.

2232
02:37:18,360 --> 02:37:23,360
Oh, yeah.

2233
02:37:23,360 --> 02:37:25,360
Yep.

2234
02:37:25,360 --> 02:37:27,360
Yep.

2235
02:37:27,360 --> 02:37:28,360
Yep.

2236
02:37:28,360 --> 02:37:29,360
Yep.

2237
02:37:29,360 --> 02:37:30,360
Absolutely.

2238
02:37:30,360 --> 02:37:31,360
There are lots of good connections there.

2239
02:37:31,360 --> 02:37:37,360
So a lot of, a lot of the classical stats are connected in this way.

2240
02:37:37,360 --> 02:37:46,360
Yes.

2241
02:37:46,360 --> 02:37:47,360
Yeah.

2242
02:37:47,360 --> 02:37:54,360
I was hoping that this question would come up and trust me, I did not plant her in the crowd.

2243
02:37:54,360 --> 02:38:01,360
So when we think about which distribution to use, there are a few rules of thumb.

2244
02:38:01,360 --> 02:38:07,360
The first rule of thumb is find something that has the correct support.

2245
02:38:07,360 --> 02:38:09,360
That is absolutely crucial.

2246
02:38:09,360 --> 02:38:15,360
If you use something that's got the wrong support, that is, you've got data that showed up negative.

2247
02:38:15,360 --> 02:38:22,360
You've got data that are showed up negative, can take on negative values, but you put a

2248
02:38:22,360 --> 02:38:24,360
positive only distribution inside there.

2249
02:38:24,360 --> 02:38:28,360
You're going to get not a number errors inside sampling.

2250
02:38:28,360 --> 02:38:29,360
Right.

2251
02:38:29,360 --> 02:38:33,360
And that also means that you've not, you've missed something in the modeling process.

2252
02:38:33,360 --> 02:38:39,360
So getting the support correct is the first step.

2253
02:38:39,360 --> 02:38:43,360
And the next step is to think about the likelihood.

2254
02:38:43,360 --> 02:38:44,360
Right.

2255
02:38:44,360 --> 02:38:48,360
That's where knowing, so that's, that's for any arbitrary distribution.

2256
02:38:48,360 --> 02:38:51,360
Getting the support correct is absolutely crucial.

2257
02:38:51,360 --> 02:38:55,360
The next thing is to think about the likelihood function.

2258
02:38:55,360 --> 02:39:00,360
How are the data that you are interested in, the thing you've actually measured?

2259
02:39:00,360 --> 02:39:05,360
How is that, how is that distributed?

2260
02:39:05,360 --> 02:39:11,360
So that's where knowing the probability distribution stories comes into place.

2261
02:39:11,360 --> 02:39:18,360
Especially rules of thumb are if you've got something that's got amount of stuff happening

2262
02:39:18,360 --> 02:39:20,360
per unit time, it's put on.

2263
02:39:20,360 --> 02:39:25,360
If you've got trials that are positive, negative, it's Bernoulli binomial.

2264
02:39:25,360 --> 02:39:26,360
Right.

2265
02:39:26,360 --> 02:39:28,360
These are very generalizable stories.

2266
02:39:28,360 --> 02:39:34,360
If you're really unsure, you might start with a normal distribution.

2267
02:39:34,360 --> 02:39:40,360
If you've got some other types of processes, so for example, the negative binomial distribution

2268
02:39:40,360 --> 02:39:45,360
counts the number of failures until a success.

2269
02:39:45,360 --> 02:39:46,360
Right.

2270
02:39:46,360 --> 02:39:49,360
So knowing this generative story helps as well.

2271
02:39:49,360 --> 02:39:50,360
Okay.

2272
02:39:50,360 --> 02:39:56,360
So, and then also there's this family of distributions called the zero inflated distributions.

2273
02:39:56,360 --> 02:39:59,360
So you can have the zero inflated Poisson distribution.

2274
02:39:59,360 --> 02:40:03,360
What it expresses is that there's, there are two processes at play.

2275
02:40:03,360 --> 02:40:06,360
There's a process that generates lots of zeros.

2276
02:40:06,360 --> 02:40:11,360
And then there's a process that generates the Poisson side of that and there's, there's,

2277
02:40:11,360 --> 02:40:13,360
this is essentially a mixture model.

2278
02:40:13,360 --> 02:40:20,360
So you're now having to infer both the probability that it is in the zero versus not zero P and

2279
02:40:20,360 --> 02:40:26,360
one minus P as well as the Poisson parameter, the rate parameter of interest.

2280
02:40:26,360 --> 02:40:32,360
And it, it, it's really important to think through the, that part of the problem.

2281
02:40:32,360 --> 02:40:34,360
So that's the second part.

2282
02:40:34,360 --> 02:40:40,360
And the third rule of thumb is to think about what the shape of the distribution should

2283
02:40:40,360 --> 02:40:41,360
look like.

2284
02:40:41,360 --> 02:40:46,360
So this is where I would then look at the PDF rather than the CDF because this is all analytical

2285
02:40:46,360 --> 02:40:52,360
because then it gives me a sense of the skew and the central moments of the distribution.

2286
02:40:52,360 --> 02:40:57,360
And it can help me express quantitatively what I'm thinking about.

2287
02:40:57,360 --> 02:41:02,360
So the beta distribution is that classic anchoring example that I always come back to.

2288
02:41:02,360 --> 02:41:07,360
It's bound from zero to one and it's therefore suitable for a probability parameter.

2289
02:41:07,360 --> 02:41:14,360
I can tweak whether it's centered on 0.5, 0.2, 0.9 by simply tweaking the A and B parameters.

2290
02:41:14,360 --> 02:41:21,360
And I can tweak how, how tight that distribution is by doing, you know,

2291
02:41:21,360 --> 02:41:26,360
beta 91 versus beta 9010 versus beta 900, 100.

2292
02:41:26,360 --> 02:41:27,360
Right.

2293
02:41:27,360 --> 02:41:31,360
So there are ways to control the, the shape of the distribution that way.

2294
02:41:31,360 --> 02:41:34,360
Those are the three rules of thumb.

2295
02:41:34,360 --> 02:41:38,360
What I, in practice, find myself doing is thinking about the problem and going like,

2296
02:41:38,360 --> 02:41:42,360
ah, yeah, I need something that's positive here because that can only take on positive values.

2297
02:41:42,360 --> 02:41:47,360
So then I'll go hunting in the distribution library for something that's positive.

2298
02:41:47,360 --> 02:41:53,360
And most of the time we're sort of expressing, you know, say for a standard deviation parameter,

2299
02:41:53,360 --> 02:41:59,360
we're expressing the fact that things generally are not going to be wildly,

2300
02:41:59,360 --> 02:42:02,360
um, standard deviation parameters are generally like tight,

2301
02:42:02,360 --> 02:42:04,360
but then sometimes can take on high values.

2302
02:42:04,360 --> 02:42:08,360
So I might take like a half koshi because standard deviations can only be positive,

2303
02:42:08,360 --> 02:42:13,360
but I'm allowing for really high tails or half student T, for example.

2304
02:42:13,360 --> 02:42:14,360
Okay.

2305
02:42:14,360 --> 02:42:16,360
So that's a few examples.

2306
02:42:16,360 --> 02:42:17,360
Back there.

2307
02:42:17,360 --> 02:42:43,360
Okay.

2308
02:42:43,360 --> 02:42:44,360
Yeah.

2309
02:42:44,360 --> 02:42:49,360
Um, so the exponentials, you can, sorry, so choosing an exponential,

2310
02:42:49,360 --> 02:42:54,360
you can think of it as this is the first model I'll write.

2311
02:42:54,360 --> 02:42:57,360
And then if you go to ravine's tutorial tomorrow,

2312
02:42:57,360 --> 02:43:00,360
there's this whole business of model comparison.

2313
02:43:00,360 --> 02:43:04,360
That's, um, sometimes you'll find it doesn't really matter what the hyperpryor is.

2314
02:43:04,360 --> 02:43:11,360
And sometimes it does matter when we check things like the information criteria metric,

2315
02:43:11,360 --> 02:43:15,360
uh, that, uh, the information that's contained in inside the model.

2316
02:43:15,360 --> 02:43:18,360
Um, sometimes you'll find whether it's half koshi or exponential,

2317
02:43:18,360 --> 02:43:20,360
just quantitatively, it doesn't really matter.

2318
02:43:20,360 --> 02:43:29,360
Um, so in some senses start with something and then run with it and then be ready to change the model.

2319
02:43:29,360 --> 02:43:30,360
Yep.

2320
02:43:30,360 --> 02:43:31,360
Yep.

2321
02:43:31,360 --> 02:43:38,360
And I emphasize that, uh, we, we don't want to really get into debating that choice,

2322
02:43:38,360 --> 02:43:41,360
but we can actually offline debate that choice if we want.

2323
02:43:41,360 --> 02:43:46,360
We can look at how the Lambda parameter controls the shape of the exponential distribution

2324
02:43:46,360 --> 02:43:50,360
and whether that expresses qualitatively what we're intending to express.

2325
02:43:50,360 --> 02:43:51,360
Right.

2326
02:43:51,360 --> 02:43:55,360
So some, the exponential distribution generally starts high and then goes low.

2327
02:43:55,360 --> 02:43:56,360
Right.

2328
02:43:56,360 --> 02:44:01,360
Um, if you increase, I think if you increase the Lambda parameter in quantity,

2329
02:44:01,360 --> 02:44:04,360
it'll, it'll become more and more flat.

2330
02:44:04,360 --> 02:44:10,360
If you decrease it, it'll become more and more closer to, to, to zero, uh, centered on zero.

2331
02:44:10,360 --> 02:44:11,360
Right.

2332
02:44:11,360 --> 02:44:14,360
So that's, that's sort of how, and then we'll, we'll have to ask,

2333
02:44:14,360 --> 02:44:18,360
is that what we want to express in the, in the model?

2334
02:44:18,360 --> 02:44:19,360
Okay.

2335
02:44:19,360 --> 02:44:20,360
Yeah.

2336
02:44:20,360 --> 02:44:21,360
Yeah.

2337
02:44:21,360 --> 02:44:22,360
Yeah.

2338
02:44:22,360 --> 02:44:23,360
Yeah.

2339
02:44:23,360 --> 02:44:24,360
Yeah.

2340
02:44:24,360 --> 02:44:25,360
Yeah.

2341
02:44:25,360 --> 02:44:26,360
Yeah.

2342
02:44:26,360 --> 02:44:27,360
Yeah.

2343
02:44:27,360 --> 02:44:28,360
Yeah.

2344
02:44:28,360 --> 02:44:29,360
Yeah.

2345
02:44:29,360 --> 02:44:33,360
Um, both from a mechanical standpoint that is like,

2346
02:44:33,360 --> 02:44:35,360
we have fewer things to worry about.

2347
02:44:35,360 --> 02:44:40,360
Um, and from, uh, I guess parsimony standpoint is like a simpler,

2348
02:44:40,360 --> 02:44:41,360
it's a simpler model.

2349
02:44:41,360 --> 02:44:42,360
Right.

2350
02:44:42,360 --> 02:44:44,360
Like we don't have that many knobs to turn.

2351
02:44:44,360 --> 02:44:45,360
Right.

2352
02:44:45,360 --> 02:44:46,360
Yeah.

2353
02:44:46,360 --> 02:44:49,360
Cool.

2354
02:44:49,360 --> 02:44:50,360
All right.

2355
02:44:50,360 --> 02:44:52,360
Let's see.

2356
02:44:52,360 --> 02:44:55,360
It's 440 right now and we end at 530.

2357
02:44:55,360 --> 02:44:59,360
So I'm debating what we should worry about next.

2358
02:44:59,360 --> 02:45:02,360
So what's, what we would have done, what we, sorry.

2359
02:45:02,360 --> 02:45:07,360
So what I originally planned was, uh, to go through one more example

2360
02:45:07,360 --> 02:45:09,360
of how we do Bayesian estimation this time,

2361
02:45:09,360 --> 02:45:11,360
not with binomial stories,

2362
02:45:11,360 --> 02:45:14,360
but with like student T distributions and normal distributions.

2363
02:45:14,360 --> 02:45:17,360
Um, that's one thing we could work on,

2364
02:45:17,360 --> 02:45:23,360
or we can first jump to, uh, arbitrary curve regression.

2365
02:45:23,360 --> 02:45:27,360
So I'm, I'm, I'm intentionally setting this up as like,

2366
02:45:27,360 --> 02:45:30,360
you can fit any curve, uh, with times three,

2367
02:45:30,360 --> 02:45:33,360
not just a line that like linear regression is what we're used to.

2368
02:45:33,360 --> 02:45:34,360
That's kind of boring.

2369
02:45:34,360 --> 02:45:37,360
So let's go in and like fit a different type of model.

2370
02:45:37,360 --> 02:45:40,360
Um, what would you prefer?

2371
02:45:40,360 --> 02:45:44,360
So let's do a vote and I will estimate the probabilities.

2372
02:45:44,360 --> 02:45:47,360
Um, how many of you want to do the curve regression?

2373
02:45:47,360 --> 02:45:48,360
Raise your hand.

2374
02:45:48,360 --> 02:45:50,360
How many want to do a second estimation?

2375
02:45:50,360 --> 02:45:51,360
Okay.

2376
02:45:51,360 --> 02:45:53,360
So we'll do, we'll do the curve regression.

2377
02:45:53,360 --> 02:45:57,360
If we have time, I'll come back and show you a few things,

2378
02:45:58,360 --> 02:46:02,360
uh, live demoed rather than, uh, interactive coding.

2379
02:46:02,360 --> 02:46:03,360
Okay.

2380
02:46:03,360 --> 02:46:05,360
On, on the second estimation thing.

2381
02:46:05,360 --> 02:46:12,360
So with that, I'd like you to open up, uh, notebook number five.

2382
02:46:12,360 --> 02:46:19,360
Notebook number five is all about arbitrary curve regression.

2383
02:46:19,360 --> 02:46:22,360
Let me see if I can connect in here.

2384
02:46:22,360 --> 02:46:23,360
Cool.

2385
02:46:23,360 --> 02:46:24,360
Cool.

2386
02:46:24,360 --> 02:46:32,360
So, um, curve regression, I'm going to put this out here.

2387
02:46:32,360 --> 02:46:38,360
Curve regression is nothing more than estimation with, with equations.

2388
02:46:38,360 --> 02:46:39,360
Okay.

2389
02:46:39,360 --> 02:46:46,360
So we're going to use a radioactive decay data set to sort of reinforce this point.

2390
02:46:46,360 --> 02:46:47,360
Okay.

2391
02:46:47,360 --> 02:46:51,360
Um, so we know linear regression.

2392
02:46:51,360 --> 02:46:59,360
You have, you have something Y is, uh, modeled as a function of a linear combination of your X's.

2393
02:46:59,360 --> 02:47:00,360
Right.

2394
02:47:00,360 --> 02:47:05,360
And so you can have the thing we're really interested in is like the W's, the weights,

2395
02:47:05,360 --> 02:47:10,360
or, you know, the M's if you're from physics, Y equals MX plus C, the M's if you're in physics,

2396
02:47:10,360 --> 02:47:12,360
or the weights if you're in stats.

2397
02:47:12,360 --> 02:47:15,360
Um, and the bias term as well.

2398
02:47:15,360 --> 02:47:20,360
Uh, and really nothing should stop us from just thinking about linear regression as the

2399
02:47:20,360 --> 02:47:23,360
only form of regression that we're interested in.

2400
02:47:23,360 --> 02:47:24,360
Right.

2401
02:47:24,360 --> 02:47:26,360
There's, there's, you can do all sorts of regression.

2402
02:47:26,360 --> 02:47:28,360
You can do Poisson regression, whatever.

2403
02:47:28,360 --> 02:47:29,360
You can do neural net regression.

2404
02:47:29,360 --> 02:47:36,360
If you know how to write neural nets, you can do, uh, in this case, exponential decay curve regression.

2405
02:47:36,360 --> 02:47:37,360
Right.

2406
02:47:37,360 --> 02:47:44,360
So we're going to see whether we can from noisy, um, radioactive decay measurements back

2407
02:47:45,360 --> 02:47:50,360
infer the correct parameters that help us identify a radioactive material.

2408
02:47:50,360 --> 02:47:51,360
Okay.

2409
02:47:51,360 --> 02:47:55,360
So I'd like you to run that first cell where we load data.

2410
02:47:55,360 --> 02:48:02,360
Oh, my.

2411
02:48:02,360 --> 02:48:03,360
Okay.

2412
02:48:03,360 --> 02:48:06,360
You'll have something that looks, data that looks something like this.

2413
02:48:06,360 --> 02:48:07,360
What's on this data?

2414
02:48:07,360 --> 02:48:13,360
Well, it's got time on one axis and then it's got activity or radioactive, you know, uh,

2415
02:48:13,360 --> 02:48:16,360
tiger count things on the Y axis.

2416
02:48:16,360 --> 02:48:17,360
Okay.

2417
02:48:17,360 --> 02:48:20,360
I've sort of, uh, well, this is synthetic data.

2418
02:48:20,360 --> 02:48:23,360
Noised out for educational purposes.

2419
02:48:23,360 --> 02:48:24,360
All right.

2420
02:48:24,360 --> 02:48:29,360
So if you plot the data, you should look, you should get something that looks like this.

2421
02:48:29,360 --> 02:48:30,360
Right.

2422
02:48:30,360 --> 02:48:31,360
Right.

2423
02:48:31,360 --> 02:48:33,360
Everybody got that?

2424
02:48:33,360 --> 02:48:34,360
Okay.

2425
02:48:34,360 --> 02:48:42,360
So given that we're in this like, uh, radioactive decay sort of scenario.

2426
02:48:42,360 --> 02:48:50,360
I'd like to ask you to think about what equations can we use to model this data?

2427
02:48:50,360 --> 02:48:55,360
We'll get into what the statistical model is in a moment, but I want to first think about

2428
02:48:55,360 --> 02:48:59,360
what equations we can use to govern this model.

2429
02:48:59,360 --> 02:49:02,360
There's an exponential decay equation.

2430
02:49:02,360 --> 02:49:05,360
What are the parameters of that equation?

2431
02:49:05,360 --> 02:49:09,360
You have time, which we've observed part of what we've observed.

2432
02:49:09,360 --> 02:49:11,360
And what else?

2433
02:49:11,360 --> 02:49:13,360
Half-life, the decay constant, right?

2434
02:49:13,360 --> 02:49:15,360
And anything else?

2435
02:49:15,360 --> 02:49:17,360
Ah, sure.

2436
02:49:17,360 --> 02:49:20,360
We're ignoring that for the time being, but yes, if we were to be fully mechanistic,

2437
02:49:20,360 --> 02:49:21,360
we would do that.

2438
02:49:21,360 --> 02:49:23,360
What else is there?

2439
02:49:23,360 --> 02:49:24,360
Offset.

2440
02:49:24,360 --> 02:49:25,360
Offset.

2441
02:49:25,360 --> 02:49:30,360
So, uh, is that the first offset or the baseline offset?

2442
02:49:30,360 --> 02:49:31,360
Baseline offset.

2443
02:49:31,360 --> 02:49:36,360
And then there's one more which is, which governs the original, uh, the starting point, right?

2444
02:49:36,360 --> 02:49:38,360
So there are what?

2445
02:49:38,360 --> 02:49:41,360
A, C, and tau.

2446
02:49:41,360 --> 02:49:44,360
We have three parameters to estimate for this curve.

2447
02:49:44,360 --> 02:49:49,360
And you'll notice the readings are actually kind of noisy as well, right?

2448
02:49:49,360 --> 02:49:53,360
And that's because there's, you know, measurements are not always perfect.

2449
02:49:53,360 --> 02:49:56,360
There's going to be some amount of noise that we've got to deal with.

2450
02:49:56,360 --> 02:49:58,360
So how do we do that?

2451
02:49:58,360 --> 02:50:01,360
Well, we've got to build a model.

2452
02:50:01,360 --> 02:50:05,360
I'm going to switch back to drawing.

2453
02:50:05,360 --> 02:50:18,360
We've got to build a model that lets us link the x-axis component, which is the time component,

2454
02:50:18,360 --> 02:50:20,360
to the y-axis thing.

2455
02:50:20,360 --> 02:50:37,360
We've already said that the equation is y is equal to a times e to the negative, uh, t over tau plus c, right?

2456
02:50:37,360 --> 02:50:49,360
The c term we can interpret, it's sort of like systematic bias in our measurement.

2457
02:50:50,360 --> 02:50:53,360
The a term we can interpret, right?

2458
02:50:53,360 --> 02:51:04,360
The a term starts is, is the starting radioactivity.

2459
02:51:04,360 --> 02:51:16,360
And the tau term we can also interpret, it is the characteristic half-life of this radioactive element.

2460
02:51:16,360 --> 02:51:18,360
Pardon me?

2461
02:51:18,360 --> 02:51:21,360
Ah, yes. So we're going to, we're going to talk about noises.

2462
02:51:21,360 --> 02:51:24,360
Oh, Siri, goodness.

2463
02:51:24,360 --> 02:51:26,360
Yes, that is very good.

2464
02:51:26,360 --> 02:51:30,360
And let's add in this plus epsilon.

2465
02:51:30,360 --> 02:51:33,360
But epsilon is not one of the mechanistic components.

2466
02:51:33,360 --> 02:51:35,360
It's a statistical component.

2467
02:51:35,360 --> 02:51:38,360
And that's why I've drawn it in red or a different color, right?

2468
02:51:38,360 --> 02:51:41,360
It's not part of the mechanistic part that we're really interested in.

2469
02:51:41,360 --> 02:51:46,360
So, let's see.

2470
02:51:46,360 --> 02:51:52,360
What are, we're now going to take this equation and we're going to build a statistical model around it.

2471
02:51:52,360 --> 02:52:03,360
What is a good prior for a, what is, sorry, what is a good distribution for a?

2472
02:52:03,360 --> 02:52:05,360
Something positive, yes.

2473
02:52:05,360 --> 02:52:06,360
All right.

2474
02:52:06,360 --> 02:52:13,360
And what's the simplest positive distribution that we can think about?

2475
02:52:13,360 --> 02:52:15,360
Pardon me?

2476
02:52:15,360 --> 02:52:18,360
Yeah, it's like the first, first thing we measure, right?

2477
02:52:18,360 --> 02:52:21,360
Yeah, so it's a bit like an impulse that way.

2478
02:52:21,360 --> 02:52:30,360
It's the, so we might say a follows some exponential distribution.

2479
02:52:30,360 --> 02:52:38,360
Let's just start with that because it's a simple one.

2480
02:52:38,360 --> 02:52:43,360
What about tau?

2481
02:52:43,360 --> 02:52:48,360
What values can tau take on?

2482
02:52:48,360 --> 02:52:49,360
It must be positive.

2483
02:52:49,360 --> 02:52:50,360
Yes, yes.

2484
02:52:50,360 --> 02:52:53,360
Okay.

2485
02:52:53,360 --> 02:52:57,360
So let's say exponential.

2486
02:52:57,360 --> 02:53:03,360
And what about C?

2487
02:53:03,360 --> 02:53:09,360
This is systematic bias, not the noise in the data.

2488
02:53:09,360 --> 02:53:12,360
Gaussian.

2489
02:53:12,360 --> 02:53:15,360
Systematic bias could be positive, could be negative.

2490
02:53:15,360 --> 02:53:20,360
Yes, so it could be normal.

2491
02:53:20,360 --> 02:53:24,360
Could be.

2492
02:53:24,360 --> 02:53:25,360
Ah, great.

2493
02:53:25,360 --> 02:53:27,360
Thank you.

2494
02:53:27,360 --> 02:53:34,360
So instead of normal, what will we do then?

2495
02:53:34,360 --> 02:53:38,360
We might do exponential, sure.

2496
02:53:38,360 --> 02:53:51,360
What about the likelihood though?

2497
02:53:51,360 --> 02:53:53,360
Pardon me?

2498
02:53:53,360 --> 02:53:55,360
Why would it be Poisson?

2499
02:53:55,360 --> 02:53:57,360
We're measuring counts.

2500
02:53:57,360 --> 02:53:58,360
Yes.

2501
02:53:58,360 --> 02:54:07,360
However, at least in the data, we've got it as continuous right now because of the noise in the machine that reports back a continuous value.

2502
02:54:07,360 --> 02:54:19,360
So what might we do?

2503
02:54:19,360 --> 02:54:22,360
Let's cheat a little bit.

2504
02:54:22,360 --> 02:54:24,360
Approximation on approximation.

2505
02:54:24,360 --> 02:54:47,360
We'll use a normal distribution here because the range of values for which we've got data are tight enough and far enough from zero that essentially at the tails of our normal, we don't have any much really credible credibility points assigned there.

2506
02:54:47,360 --> 02:54:53,360
These are like the struggles that we wrestle with, with every new modeling problem that comes in.

2507
02:54:53,360 --> 02:54:57,360
Is a normal distribution likelihood reasonable?

2508
02:54:57,360 --> 02:54:58,360
Is it correct?

2509
02:54:58,360 --> 02:54:59,360
Probably not.

2510
02:54:59,360 --> 02:55:01,360
Is it useful?

2511
02:55:01,360 --> 02:55:02,360
Maybe.

2512
02:55:02,360 --> 02:55:03,360
Right?

2513
02:55:03,360 --> 02:55:11,360
So I want to get that in your head.

2514
02:55:12,360 --> 02:55:22,360
Likelihood is the thing that you're observing about the data, right?

2515
02:55:22,360 --> 02:55:34,360
So what do you mean by unit then?

2516
02:55:34,360 --> 02:55:36,360
Right, right, right, right.

2517
02:55:36,360 --> 02:55:43,360
So if you look at, I'm going to detour a little bit and talk about linear regression.

2518
02:55:43,360 --> 02:55:52,360
So you have y equals mx plus c.

2519
02:55:52,360 --> 02:56:00,360
We might write a model that says m is normally distributed for whatever distribution parameters.

2520
02:56:00,360 --> 02:56:04,360
C is also normally distributed.

2521
02:56:04,360 --> 02:56:08,360
Y is the likelihood of the data.

2522
02:56:08,360 --> 02:56:09,360
It's got noise.

2523
02:56:09,360 --> 02:56:26,360
And if we assume that the noise is Gaussian noise, then we can impose a modeling assumption that says that this is normally distributed where the mu is equal to mx plus c.

2524
02:56:26,360 --> 02:56:31,360
And the sigma is equal to something else.

2525
02:56:31,360 --> 02:56:33,360
The sigma is our epsilon.

2526
02:56:33,360 --> 02:56:35,360
And we can ask, what is the epsilon?

2527
02:56:35,360 --> 02:56:38,360
How is the, how is that going to be distributed?

2528
02:56:38,360 --> 02:56:40,360
Does that make sense?

2529
02:56:40,360 --> 02:56:41,360
Yeah.

2530
02:56:41,360 --> 02:56:52,360
So I'm glad you asked that question because if you look at the parallels here, we'll need a sigma prior.

2531
02:56:52,360 --> 02:57:00,360
And just for convenience, I'm just going to put the standard half Cauchy, okay?

2532
02:57:00,360 --> 02:57:01,360
Inside there.

2533
02:57:01,360 --> 02:57:03,360
So we got that.

2534
02:57:03,360 --> 02:57:13,360
So then we might impose the same or a similar set of modeling assumptions on the likelihood, which is our y, right?

2535
02:57:13,360 --> 02:57:17,360
Or rather than calling it likelihood, because that's overloading terms.

2536
02:57:17,360 --> 02:57:18,360
Let's just do y.

2537
02:57:18,360 --> 02:57:20,360
How is y distributed?

2538
02:57:20,360 --> 02:57:36,360
Why we might impose that this is normally distributed where the mu is equal to a times e to the negative t over tau plus c.

2539
02:57:36,360 --> 02:57:40,360
And then we have some noise, which is our epsilon.

2540
02:57:40,360 --> 02:57:49,360
And our epsilon, just for convenience, will also make it half Cauchy.

2541
02:57:49,360 --> 02:58:00,360
Let's let that sink in for a moment.

2542
02:58:00,360 --> 02:58:04,360
Or maybe I should say something like, I'm just going to leave this up on there.

2543
02:58:04,360 --> 02:58:05,360
No.

2544
02:58:05,360 --> 02:58:07,360
Do we have questions?

2545
02:58:07,360 --> 02:58:29,360
Things that are not clear.

2546
02:58:29,360 --> 02:58:30,360
Yeah.

2547
02:58:30,360 --> 02:58:47,360
If the errors in this particular case, what we've assumed is that our errors are not dependent on the value on the x-axis.

2548
02:58:47,360 --> 02:59:01,360
If now we suddenly found that the values, the error varies with the value on the x-axis, suddenly we have to write a function that models sigma as a function of, in this case, t.

2549
02:59:01,360 --> 02:59:02,360
Right?

2550
02:59:02,360 --> 02:59:05,360
So that's one place where this model would fail.

2551
02:59:05,360 --> 02:59:08,360
And I've actually encountered that at work before.

2552
02:59:09,360 --> 02:59:10,360
How do we get around that?

2553
02:59:10,360 --> 02:59:20,360
We get around that by either explicitly stating up front that this assumption does not hold in our data, but we're willing to work with the consequences of that.

2554
02:59:20,360 --> 02:59:23,360
Or we go hunting for the function.

2555
02:59:23,360 --> 02:59:30,360
And sometimes that's kind of hard when you have like limited x values to work with.

2556
02:59:30,360 --> 02:59:31,360
Oops.

2557
02:59:31,360 --> 02:59:34,360
Siri keeps coming up.

2558
02:59:34,360 --> 02:59:35,360
Cool.

2559
02:59:35,360 --> 02:59:37,360
Any other questions on this?

2560
02:59:37,360 --> 02:59:39,360
This is like the key, key point.

2561
02:59:39,360 --> 02:59:41,360
This is the key point here.

2562
02:59:41,360 --> 02:59:59,360
Like you can write the parameters of your likelihood distributions as a function or a transformation on the other things that you've, you're interested in.

2563
02:59:59,360 --> 03:00:02,360
Okay.

2564
03:00:02,360 --> 03:00:03,360
Okay.

2565
03:00:03,360 --> 03:00:10,360
So if you go ahead and let's, let's go ahead and code the model together.

2566
03:00:10,360 --> 03:00:15,360
What's inside the instructor notebook might be different from what we just wrote out.

2567
03:00:15,360 --> 03:00:20,360
What I wanted to give you all just now was this live experience of like, well, I don't know.

2568
03:00:20,360 --> 03:00:24,360
So what are we, what modeling assumptions am I willing to stand with?

2569
03:00:24,360 --> 03:00:25,360
Right.

2570
03:00:25,360 --> 03:00:28,360
And then we can go back in and re critique the model one more time.

2571
03:00:28,360 --> 03:00:35,360
So let's, let's put in, in this case, just copy and paste what's inside the instructor notebook.

2572
03:00:35,360 --> 03:00:36,360
All right.

2573
03:00:36,360 --> 03:00:41,360
And let's not worry too much about the others.

2574
03:00:41,360 --> 03:00:46,360
Again, you'll notice that thing, that equation.

2575
03:00:46,360 --> 03:00:50,360
I, I alluded it, alluded to this point, its name a few times.

2576
03:00:50,360 --> 03:00:52,360
It's called a link function.

2577
03:00:52,360 --> 03:00:53,360
Right.

2578
03:00:53,360 --> 03:00:55,360
So y equals mx plus C is a link function.

2579
03:00:55,360 --> 03:01:00,360
Y is equal to times a times e to the negative t over tau plus C.

2580
03:01:00,360 --> 03:01:02,360
That's just another link function.

2581
03:01:02,360 --> 03:01:06,360
You can have your four parameter dose response curves as a link function.

2582
03:01:06,360 --> 03:01:16,360
You can put the standard logistic regression curve as a link function, like any math function that you can think of can be a link function.

2583
03:01:16,360 --> 03:01:18,360
All right.

2584
03:01:18,360 --> 03:01:28,360
And then that goes and that, what that does is it can, it controls the, the mean curve parameter.

2585
03:01:28,360 --> 03:01:29,360
Right.

2586
03:01:29,360 --> 03:01:35,360
It controls the mean of our data as a function of, you know, this thing on the x axis.

2587
03:01:35,360 --> 03:01:38,360
All right.

2588
03:01:38,360 --> 03:01:40,360
So let's copy and paste what's inside here.

2589
03:01:40,360 --> 03:01:44,360
Here the modeling choices are half normal, exponential.

2590
03:01:44,360 --> 03:01:53,360
I think I chose C to be normal under the assumption that sometimes the, the machine might go faulty and give us like a completely negative baseline.

2591
03:01:53,360 --> 03:01:54,360
Sure.

2592
03:01:54,360 --> 03:01:59,360
And if that never happens, then I would change, change that to a half kosher exponential.

2593
03:01:59,360 --> 03:02:02,360
Okay.

2594
03:02:02,360 --> 03:02:13,360
So then we sample.

2595
03:02:13,360 --> 03:02:22,360
Oh, I hear the jet engines running again.

2596
03:02:22,360 --> 03:02:35,360
Ah, so this is a, this is the thing that I'm wondering ravine, will you be covering Colin will be covering it tomorrow in the RVs or the Asian model evaluation tutorial.

2597
03:02:35,360 --> 03:02:39,360
So ignore that for the time being.

2598
03:02:39,360 --> 03:02:42,360
And you should get something that looks like this guy.

2599
03:02:42,360 --> 03:02:45,360
The, do we all have that thumbs up if you do.

2600
03:02:45,360 --> 03:02:46,360
Yep.

2601
03:02:46,360 --> 03:02:47,360
Okay.

2602
03:02:47,360 --> 03:02:48,360
So you get like traces.

2603
03:02:48,360 --> 03:02:58,360
This one's been simple, right, because we've got only a single alpha, a single capital A, a single capital C, a single tau, right.

2604
03:02:58,360 --> 03:03:14,360
But you all saw just now how we can actually have a vector of A's, a vector of towels, a vector of C's, our likelihood normal distribution can also be expanded to be a vector of, of, of likelihoods.

2605
03:03:14,360 --> 03:03:21,360
There's just some little intricacies that we have to worry about with respect to the, the, you know, y equals.

2606
03:03:21,360 --> 03:03:23,360
Y is the mu, the link function, right.

2607
03:03:23,360 --> 03:03:25,360
So you have to play around with that.

2608
03:03:25,360 --> 03:03:26,360
But this is totally doable.

2609
03:03:26,360 --> 03:03:34,360
And then once you have that multiple groups thing, once again, you can do your hierarchical player, hierarchical thing.

2610
03:03:34,360 --> 03:03:37,360
If it's an appropriate modeling decision, right.

2611
03:03:37,360 --> 03:03:41,360
So if you think about it, think about it.

2612
03:03:41,360 --> 03:03:49,360
That this arbitrary curve regression thing is once again, nothing more than estimation at its heart.

2613
03:03:49,360 --> 03:04:05,360
And instead of estimating like A, instead of estimating distribution parameters directly, like in this case, in previous cases, we were estimating the P hierarchically, right.

2614
03:04:05,360 --> 03:04:09,360
Now all we've done is we've said there's an equation that governs that key parameter.

2615
03:04:09,360 --> 03:04:18,360
And now we want to estimate the parameters of that equation in a, of that equation in a statistical fashion, rather than just treat it as some fixed point.

2616
03:04:18,360 --> 03:04:20,360
Okay.

2617
03:04:20,360 --> 03:04:22,360
How are we with that?

2618
03:04:22,360 --> 03:04:25,360
Okay.

2619
03:04:25,360 --> 03:04:29,360
If you want, go back and like figure out what the element is.

2620
03:04:29,360 --> 03:04:33,360
I'm not going to reveal the answer right now.

2621
03:04:33,360 --> 03:04:38,360
But I want to point you to the table at the bottom of your notebooks.

2622
03:04:38,360 --> 03:04:55,360
The table at the bottom of your notebooks says in compact form, everything that I just said, that is, you can put any arbitrary curve as a link function, and you don't have to be restrained to modeling just linear models.

2623
03:04:55,360 --> 03:05:02,360
You can model these decay curves, you can model logistic regressions, you can do.

2624
03:05:02,360 --> 03:05:04,360
You can write a neural net.

2625
03:05:04,360 --> 03:05:14,360
Like if you've got some weird function that is, you know, non non monotonically linear, then go ahead, write a neural net and estimate the parameters.

2626
03:05:14,360 --> 03:05:16,360
You might not want to do like MCMC sampling.

2627
03:05:16,360 --> 03:05:18,360
That's a little too much.

2628
03:05:18,360 --> 03:05:26,360
You might want to bust out the variational inference tools that we have, but in time see three, but, you know, it's all possible.

2629
03:05:26,360 --> 03:05:28,360
It's all totally possible.

2630
03:05:28,360 --> 03:05:34,360
So, all right, that's it for the arbitrary curve regression notebook.

2631
03:05:34,360 --> 03:05:41,360
Do we have any questions before we go back into doing estimation one more time?

2632
03:05:41,360 --> 03:05:54,360
What you have to do, let me see if I can pull this off here.

2633
03:05:54,360 --> 03:06:00,360
You want to see not just the single regression line, but the full family of them, right?

2634
03:06:00,360 --> 03:06:05,360
Yeah, all right, this is going to test my live coding abilities.

2635
03:06:05,360 --> 03:06:16,360
Trace dot bar names.

2636
03:06:16,360 --> 03:06:18,360
Cool.

2637
03:06:18,360 --> 03:06:25,360
One way to do this is to plot what T would look like first.

2638
03:06:25,360 --> 03:06:34,360
So T is NP dot LIN space from zero to 800.

2639
03:06:34,360 --> 03:06:40,360
Okay.

2640
03:06:40,360 --> 03:06:46,360
And then you'll want to write the equation out.

2641
03:06:46,360 --> 03:06:54,360
The equation is this guy.

2642
03:06:54,360 --> 03:07:02,360
I'm going to put this down here.

2643
03:07:02,360 --> 03:07:15,360
So we return that.

2644
03:07:15,360 --> 03:07:35,360
And then the trace will have, if we inspect trace of A, it's a vector, it's 2000 long, 8000 long.

2645
03:07:35,360 --> 03:08:04,360
I hope I've done this before, but I just have to do this correctly.

2646
03:08:04,360 --> 03:08:13,360
In any time, I'm going to have you, we'll talk afterwards, and I'll put that, I'll be sure to put this on the notebook so that everybody benefits from this question.

2647
03:08:13,360 --> 03:08:23,360
I think it's a great question because I've done this before, I just like am blanking on live coding, but I'll get that up there for you guys.

2648
03:08:24,360 --> 03:08:27,360
But there's some form of broadcasting that we need to do, right?

2649
03:08:27,360 --> 03:08:36,360
There's like X over tau needs to be broadcasted into a matrix and then we plot each of those rows of the matrix, but I'm not sure how to do this right now.

2650
03:08:36,360 --> 03:08:39,360
So we'll work that out later.

2651
03:08:39,360 --> 03:08:43,360
Let's come back to estimation before we wrap up.

2652
03:08:43,360 --> 03:08:46,360
So with estimation, we're going back to notebook number four.

2653
03:08:46,360 --> 03:09:04,360
I'd like to invite you to open up notebook number four, and all I'm going to do is rather than code with you, I'm going to show you another, show you this example is basically another case study where we've got information from two groups,

2654
03:09:04,360 --> 03:09:08,360
but now we have this third group for which we don't have enough information.

2655
03:09:08,360 --> 03:09:12,360
We want to be able to make reasonable inferences on it.

2656
03:09:12,360 --> 03:09:18,360
So I'm going to use the instructor version.

2657
03:09:18,360 --> 03:09:33,360
Whoops, rather than the student version, and I'm just going to run run down to about here first.

2658
03:09:33,360 --> 03:09:37,360
Okay, so we've got data.

2659
03:09:37,360 --> 03:09:45,360
We always love to have data.

2660
03:09:45,360 --> 03:09:52,360
And for educational reasons, what I did, I took the liberty of adding in an extra species that was unknown.

2661
03:09:52,360 --> 03:09:59,360
We know it's a Finch, but we've never, we've never really measured it, but and it's so rare, we've only got one measurement.

2662
03:09:59,360 --> 03:10:08,360
So we're going to make inferences on, well, what's the, what do we expect to know about this new Finch's beak depth, right?

2663
03:10:08,360 --> 03:10:11,360
We've been measuring the beaks depth and their length.

2664
03:10:11,360 --> 03:10:15,360
What do we expect to know?

2665
03:10:15,360 --> 03:10:20,360
So under this case is like, damn, we have like one measurement.

2666
03:10:20,360 --> 03:10:27,360
There's no way we can even compute a standard deviation on this one independent measurement, right?

2667
03:10:27,360 --> 03:10:30,360
We estimate uncertainty in this case.

2668
03:10:30,360 --> 03:10:46,360
And this is the sort of scenario where a hierarchical model can be helpful in exactly the same way that it was helpful for those baseball players who had only one at that and no other data than that one at that.

2669
03:10:46,360 --> 03:10:56,360
Okay, so if we think about the data generative process, we'll say something like, oh yeah, our beaks, maybe they are student T distributed.

2670
03:10:56,360 --> 03:10:57,360
Why student T?

2671
03:10:57,360 --> 03:11:02,360
It's because student T is the generalization of the normal and the Cauchy.

2672
03:11:02,360 --> 03:11:06,360
The Cauchy distribution, the student T distribution has this degree of freedom parameter.

2673
03:11:06,360 --> 03:11:11,360
This degree of freedom parameter controls how high or how fat the tails are.

2674
03:11:11,360 --> 03:11:17,360
Normal distribution has really, really low, low tails, low probability density on the tails.

2675
03:11:17,360 --> 03:11:22,360
The Cauchy distribution has really high probability density on the tails, relatively speaking.

2676
03:11:22,360 --> 03:11:31,360
So the student T distribution says that when degree of freedom is one, it's the Cauchy, and when it's infinite, it's the normal.

2677
03:11:31,360 --> 03:11:38,360
And everything else in between is controlled by this degree of freedom parameter.

2678
03:11:38,360 --> 03:11:43,360
So we might define a student T likelihood.

2679
03:11:43,360 --> 03:11:58,360
If we do an independent model, we'll get these posterior distributions on the beak depth, right?

2680
03:11:58,360 --> 03:12:00,360
And it's on the mean beak depth.

2681
03:12:00,360 --> 03:12:07,360
And this is kind of like where this independent model is really not the right place to be.

2682
03:12:07,360 --> 03:12:08,360
So think about it.

2683
03:12:08,360 --> 03:12:27,360
We've got values that can range from 0 to 15, where we know that finches generally are constrained maybe more towards 4 to 9 or 4 to 11 or something like that, right?

2684
03:12:27,360 --> 03:12:28,360
I forgot.

2685
03:12:28,360 --> 03:12:30,360
This is centimeters and millimeters.

2686
03:12:30,360 --> 03:12:32,360
But you get the point, right?

2687
03:12:32,360 --> 03:12:40,360
This independent model doesn't really have that borrowing of information from the known species to help us constrain our estimates.

2688
03:12:40,360 --> 03:12:44,360
So I'm going to throw this on the right-hand side here.

2689
03:12:44,360 --> 03:12:46,360
Keep this one in mind.

2690
03:12:46,360 --> 03:12:48,360
This is the independent model.

2691
03:12:48,360 --> 03:12:55,360
Now, if we fit a hierarchical model, and it looks something like this guy, right?

2692
03:12:55,360 --> 03:12:56,360
Similar syntax.

2693
03:12:56,360 --> 03:12:57,360
Nothing fancy.

2694
03:12:57,360 --> 03:13:16,360
We have our priors and everything, and we have the broadcasting that's happening going on, just like in the independent model, except now we have prior distributions on the parameters of our distributions for the like, on the distributions for the parameters of our likelihood function.

2695
03:13:16,360 --> 03:13:17,360
Okay?

2696
03:13:17,360 --> 03:13:19,360
That's a bit of a mouthful, but I hope you get the point.

2697
03:13:19,360 --> 03:13:22,360
There are hyper priors that exist.

2698
03:13:22,360 --> 03:13:32,360
If we do sampling, now, ooh, sorry, I'm going to instead throw this up on the right.

2699
03:13:32,360 --> 03:13:35,360
There we go.

2700
03:13:35,360 --> 03:13:38,360
This is the one we want.

2701
03:13:38,360 --> 03:13:39,360
Oh, okay.

2702
03:13:39,360 --> 03:13:43,360
Maybe it's better on the bottom.

2703
03:13:43,360 --> 03:13:51,360
And if you look at this guy over here, throw this one up here.

2704
03:13:51,360 --> 03:14:03,360
Okay, so down on the bottom is our posterior distribution estimates for the independent model.

2705
03:14:03,360 --> 03:14:04,360
Okay.

2706
03:14:04,360 --> 03:14:12,360
And up at the top is the posterior distribution estimate for the hierarchical model.

2707
03:14:12,360 --> 03:14:20,360
Which one looks more reasonable for this unknown species that we're interested in?

2708
03:14:20,360 --> 03:14:33,360
This might take a bit of prior knowledge, but then you think about the 95% posterior density values.

2709
03:14:33,360 --> 03:14:35,360
These are pretty extreme.

2710
03:14:35,360 --> 03:14:38,360
These are quite extreme for the problem at hand, right?

2711
03:14:38,360 --> 03:14:45,360
Finch peaks that are like zero centimeters are really close to zero, not so believable.

2712
03:14:45,360 --> 03:14:55,360
In this case, because we have only a single measurement, the math works out such that our smallest beak size will, you know, in the 94% density will be at 0.9.

2713
03:14:55,360 --> 03:15:00,360
Still might be unreasonable, but if you look at where most of the credibility is associated, it's out here.

2714
03:15:00,360 --> 03:15:09,360
Whereas on this side, well, yeah, most of the credibility is associated out here, but there's still lots of credibility assigned like at really low values nonetheless.

2715
03:15:09,360 --> 03:15:16,360
So qualitatively speaking, it still doesn't really make sense, right?

2716
03:15:16,360 --> 03:15:20,360
Given the background prior knowledge that we've had.

2717
03:15:20,360 --> 03:15:21,360
Okay.

2718
03:15:21,360 --> 03:15:26,360
Okay, so that's all that I really wanted to say about this particular model.

2719
03:15:26,360 --> 03:15:30,360
It was intended, so you can do this at home.

2720
03:15:30,360 --> 03:15:40,360
It's intended, this exercise is intended as, you know, can I build a model for the data that is now not following the binomial story?

2721
03:15:40,360 --> 03:15:49,360
Because we really, really harped on the binomial story to illustrate these other things, hierarchical models, vectorization of probability distributions, and the likes.

2722
03:15:49,360 --> 03:15:59,360
Okay, so we really harped on that, but here, here, this case, you can get some practice with, you know, something that's t-distributed or normally distributed and try out other problems for yourself as well.

2723
03:15:59,360 --> 03:16:01,360
Try out the other probability distributions.

2724
03:16:01,360 --> 03:16:04,360
Okay, so that's also really helpful.

2725
03:16:04,360 --> 03:16:11,360
All right, so the final thing that we have to do is I'm going to have Raveen and find a few helpers.

2726
03:16:11,360 --> 03:16:19,360
I've got these little cards that congratulate you for taking this tutorial and sticking all the way through to the end.

2727
03:16:19,360 --> 03:16:21,360
So this is my little way of saying thank you.

2728
03:16:21,360 --> 03:16:23,360
At the same time, I have a little ask as well.

2729
03:16:24,360 --> 03:16:39,360
There is a survey that we have on the readme of the GitHub repository, or if you prefer to use your phone to do it, there's a QR code on the back of the congratulations card.

2730
03:16:39,360 --> 03:16:46,360
I'd like you to fill out that form to tell us where, where we did well on this tutorial, where we could improve it.

2731
03:16:46,360 --> 03:16:53,360
Every generation of tutorials gets better and better, and it's all thanks to your feedback that we're able to do it.

2732
03:16:53,360 --> 03:17:00,360
So while that's happening, I'm also happy to take questions, and then I have one final, final, final thing for everybody.

2733
03:17:00,360 --> 03:17:12,360
So while that's going around, while you all are doing the surveys, I hope you all can open up the readme if you want to do it on your computer or scan the QR code if you're on your phone.

2734
03:17:13,360 --> 03:17:17,360
Do you have questions on the material today?

2735
03:17:28,360 --> 03:17:30,360
Okay, if not, then we'll continue.

2736
03:17:30,360 --> 03:17:36,360
I'll just wait until I've got some form of quorum on like everybody being done.

2737
03:17:39,360 --> 03:17:40,360
Yes.

2738
03:17:42,360 --> 03:17:43,360
Sure.

2739
03:17:56,360 --> 03:17:57,360
Right.

2740
03:17:57,360 --> 03:17:58,360
Okay.

2741
03:18:01,360 --> 03:18:02,360
Oh, cool.

2742
03:18:02,360 --> 03:18:03,360
All right.

2743
03:18:03,360 --> 03:18:09,360
That's, that's good for me to know because really tight.

2744
03:18:10,360 --> 03:18:11,360
Okay.

2745
03:18:16,360 --> 03:18:17,360
Yep.

2746
03:18:17,360 --> 03:18:18,360
Yep.

2747
03:18:18,360 --> 03:18:19,360
Oh, cool.

2748
03:18:19,360 --> 03:18:20,360
Thanks a lot.

2749
03:18:20,360 --> 03:18:21,360
I learned something today.

2750
03:18:24,360 --> 03:18:25,360
Anything else?

2751
03:18:39,360 --> 03:18:40,360
Yeah.

2752
03:18:58,360 --> 03:18:59,360
Yeah.

2753
03:19:01,360 --> 03:19:03,360
So let's see.

2754
03:19:04,360 --> 03:19:17,360
The simplest, the simplest way to do this is actually to, to use the sci-pi stats module and, and use that to calculate the likelihood of data under your distribute, calculate, sorry, backtrack a little bit.

2755
03:19:18,360 --> 03:19:24,360
We've always in, in our examples had data being basically like a data frame or like multiple rows of stuff.

2756
03:19:25,360 --> 03:19:32,360
When we calculate the likelihood, it's really the sum of likelihoods over every single data point.

2757
03:19:32,360 --> 03:19:43,360
And what happens when we're sampling, I think Revena and Colin will know this better than I would, but it, the mental model that I have is we're sort of, we draw a number from a, from our prior distributions.

2758
03:19:44,360 --> 03:19:56,360
We, we assume that to be true and now fit it, put that into the likelihood, then compute the sum of likelihoods over all of our data.

2759
03:19:56,360 --> 03:20:05,360
And then there's like this, this step that says, well, okay, given, given this thing that we've pulled out, the likelihood is this particular value.

2760
03:20:05,360 --> 03:20:16,360
Now there's, you know, there's, there's gradient information that tells us which way to go and in, in the right place to sample that will now help us increase likelihood.

2761
03:20:16,360 --> 03:20:19,360
Now, I want to be clear, this is not gradient ascent.

2762
03:20:19,360 --> 03:20:21,360
Okay, this is not gradient ascent.

2763
03:20:21,360 --> 03:20:28,360
And I've, in talking with Colin multiple times, I've actually made that mistake of thinking of it as gradient descent.

2764
03:20:28,360 --> 03:20:32,360
So I don't want you to think of it as gradient, this gradient ascent at all.

2765
03:20:32,360 --> 03:20:34,360
It's much more complicated than that.

2766
03:20:34,360 --> 03:20:35,360
Right.

2767
03:20:35,360 --> 03:20:39,360
But that's basically a glimpse into what's happening underneath the hood.

2768
03:20:43,360 --> 03:20:46,360
That is the MCMC step that we're doing.

2769
03:20:46,360 --> 03:20:51,360
We're like randomly sampling values from our, from our calculated posterior distribution.

2770
03:20:52,360 --> 03:21:02,360
Sorry, I didn't, I didn't catch that.

2771
03:21:02,360 --> 03:21:04,360
We can do it with simpler math.

2772
03:21:11,360 --> 03:21:18,360
So the, the, who depends on how we define simple and complicated integrals are kind of complicated.

2773
03:21:18,360 --> 03:21:24,360
And if we were not to use MCE methods, we would be doing integration and that'd be a bit of a pain.

2774
03:21:24,360 --> 03:21:26,360
I think ravine had something to say.

2775
03:21:26,360 --> 03:21:27,360
Yeah.

2776
03:21:29,360 --> 03:21:38,360
So for that question specifically like the tutorial that I'm giving tomorrow, which is on GitHub has an entire notebook for that question of how MCMC works and diagnostics for it.

2777
03:21:38,360 --> 03:21:40,360
So if you're in it, that's good.

2778
03:21:40,360 --> 03:21:41,360
Otherwise you can come talk to me.

2779
03:21:41,360 --> 03:21:47,360
I'll give you the link to the GitHub and we can talk through MCMC and is well, hopefully a medium amount of detail.

2780
03:21:47,360 --> 03:21:48,360
Does that help?

2781
03:21:48,360 --> 03:21:50,360
Yeah, yeah.

2782
03:21:50,360 --> 03:21:51,360
Okay, cool.

2783
03:21:52,360 --> 03:21:53,360
So.

2784
03:22:16,360 --> 03:22:17,360
Yep.

2785
03:22:21,360 --> 03:22:43,360
So I've done it before where we cheat and look at the data first and then try to see what distribution might be suitable.

2786
03:22:43,360 --> 03:22:45,360
Well, this is mostly for the likelihood.

2787
03:22:46,360 --> 03:22:50,360
Cheating basions are called empirical basions.

2788
03:22:50,360 --> 03:22:55,360
So that's one way of approaching the problem.

2789
03:22:55,360 --> 03:23:06,360
In practice, what happens is this will build a model and then it's all got it's got all the simplest things.

2790
03:23:06,360 --> 03:23:08,360
It's it's normal.

2791
03:23:08,360 --> 03:23:14,360
It's exponentials and like we're not thinking too hard about the mechanics of the problem.

2792
03:23:14,360 --> 03:23:17,360
We're not thinking too hard about the details of the problem.

2793
03:23:17,360 --> 03:23:18,360
We're not.

2794
03:23:18,360 --> 03:23:25,360
We're sort of ignoring ahead of time what potential problems might show up in MC sampling and just running with it first.

2795
03:23:25,360 --> 03:23:31,360
And then we'll encounter a problem with MC sampling, which often is an index.

2796
03:23:32,360 --> 03:23:39,360
And then we'll encounter a problem with MC sampling, which often is an indication that like the model is kind of bad as well.

2797
03:23:39,360 --> 03:23:42,360
Then we'll go back and think a little bit more carefully about it.

2798
03:23:42,360 --> 03:23:57,360
So I've done these sessions at work where I start working on a model at just after lunch and I don't go home until 7pm because at 7 that's when like something that might look correct starts to show up.

2799
03:23:57,360 --> 03:24:02,360
And even then I'm still not 100% sure that that model is the best model.

2800
03:24:02,360 --> 03:24:09,360
However, I have a pragmatist in my head restraining me from going till 9pm.

2801
03:24:09,360 --> 03:24:17,360
And it says, well, okay, you've got the key parameters of interest and you know their uncertainty to some degree.

2802
03:24:17,360 --> 03:24:26,360
Go home, rest over it and maybe present it and someone else might be able to the peer review process at work then shows up.

2803
03:24:26,360 --> 03:24:35,360
And I think if no one else can critique the model any further, we sort of all have to just agree that let's just run with it.

2804
03:24:35,360 --> 03:24:37,360
Yeah.

2805
03:24:47,360 --> 03:24:50,360
Yes, yes, yes.

2806
03:24:50,360 --> 03:24:54,360
Yes, exactly.

2807
03:24:54,360 --> 03:24:59,360
And if we're not sure about that, we change the distribution.

2808
03:24:59,360 --> 03:25:06,360
There are positive only distributions that can be centered, you know, way out further out, right?

2809
03:25:06,360 --> 03:25:14,360
I'm blanking right now on exactly which ones, but if you look at the PIMC3 distribution gallery, then you'll see those pictures and it becomes clear.

2810
03:25:14,360 --> 03:25:29,360
Yeah, so there are these so-called improper priors.

2811
03:25:29,360 --> 03:25:40,360
The flat distribution assigns, I forgot what likelihood it assigns, but it just assigns a single constant number from negative infinity to positive infinity.

2812
03:25:40,360 --> 03:25:51,360
And then PIMC, there is machinery that lets you bound a distribution by setting its lower bound, upper bound, or both.

2813
03:25:51,360 --> 03:25:53,360
And that's available.

2814
03:25:53,360 --> 03:25:58,360
And yes, you can do that, though I think the pros say don't do it.

2815
03:25:58,360 --> 03:26:04,360
Avoid the improper priors where you can, like it's not the best thing.

2816
03:26:04,360 --> 03:26:11,360
The reasons why I'll have to dig, but the rule of thumb I've remembered is don't, like just avoid it.

2817
03:26:11,360 --> 03:26:12,360
Yeah.

2818
03:26:12,360 --> 03:26:19,360
Weekly informative priors that say things like, yeah, it's probably more close to zero, but I'm really not sure.

2819
03:26:19,360 --> 03:26:24,360
Or it's probably centered around here, but I'm willing to give lots of uncertainty at first.

2820
03:26:24,360 --> 03:26:31,360
Those are the general rules of thumb for selecting priors.

2821
03:26:31,360 --> 03:26:35,360
Cool. Anything else?

2822
03:26:35,360 --> 03:26:39,360
Okay, if not, let's do a very quick recap of what we went through today.

2823
03:26:39,360 --> 03:26:45,360
There's a lot of material, but the core thing that I hope you take away are the following.

2824
03:26:45,360 --> 03:26:55,360
Firstly, that probability itself, and you've seen it so many times here, it's nothing more than assigning credibility points to the number line.

2825
03:26:55,360 --> 03:27:04,360
Where there's higher credibility points, we believe it more, and where there's lower credibility points, we believe that that parameter takes on that value less times.

2826
03:27:04,360 --> 03:27:06,360
That's all it is.

2827
03:27:06,360 --> 03:27:14,360
We saw how we can go from joint and conditional probability to Bayes rule and how that maps on.

2828
03:27:14,360 --> 03:27:22,360
Marginal probability, joint and marginal and conditional probability are all really important for this.

2829
03:27:22,360 --> 03:27:29,360
One thing I really hope you all take back is know your probability distribution stories.

2830
03:27:29,360 --> 03:27:37,360
Super-duper important. If you know what their stories are, then picking them for your modeling work becomes much easier.

2831
03:27:37,360 --> 03:27:40,360
Picking them becomes much easier.

2832
03:27:40,360 --> 03:27:45,360
And so knowing what the continuuses are and what the discreet are, that's really important.

2833
03:27:45,360 --> 03:27:52,360
Knowing their shape, their support, what story they tell that will help you in your modeling work.

2834
03:27:52,360 --> 03:28:02,360
And finally, we went through one really simple example but built it up in depth, the binomial distribution story,

2835
03:28:02,360 --> 03:28:12,360
and went along and showed how you can take a seemingly simple model and complicate it enough to fit the problem that you have at hand.

2836
03:28:13,360 --> 03:28:16,360
Do you have more than one group? Well, vectorize the thing.

2837
03:28:16,360 --> 03:28:21,360
Do you have some groups with lots of info and some groups that don't have lots of info?

2838
03:28:21,360 --> 03:28:28,360
Well, use a hierarchical model and the mechanics of how we build these models, we reinforced over and over and over.

2839
03:28:28,360 --> 03:28:37,360
And from the discussion, I noticed a lot of light bulbs going off, so that always makes me very happy to see.

2840
03:28:37,360 --> 03:28:42,360
Cool. And with that, I'm going to say we're going to end here. Thank you all for coming.

2841
03:28:42,360 --> 03:28:48,360
If you want office hours, I'll put them on the Slack. They will always be in the Tejas room in the afternoons.

2842
03:28:48,360 --> 03:28:51,360
Exact time, see the Slack channel. Thanks a lot.

