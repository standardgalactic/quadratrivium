start recording. Hello everybody and welcome to the Public Invention Inventors Gathering which
happens the third Thursday of every month. This is July. My name is Robert L. Reed. I'm the president
and founder of Public Invention and today I'm going to be speaking on the topic of the mind-blowing
beauty of computer programming.
Can everybody see my screen?
Yes. Okay, thank you. We have a small audience today so y'all feel free to interrupt me.
I kind of have mixed feelings about this talk because although it's really close to my heart,
I know there's no way I can do justice to it. I could spend a year preparing this talk and I
wouldn't do justice to it. What I'm going to try to explain to you is magic and then even deeper
magic and it's actually very important to me. Computer science is a new art from
really the 1930s. Lady Babbage did a little bit of work before that but it really wasn't until
the 1930s that it became a mathematical art so to speak. That was before the majority of
electronic computers. There were still mechanical computers at that time and although it wasn't
entirely obvious at that time, we now know that computer science sits at the intersection of
physics and math. It also touches upon philosophy and epistemology, the study of what can be known
and in a sense computer science is an extension of what is knowable. Now the fact that computer
science could be considered a branch of physics is really, really deep and relates to things like
astrophysics and quantum mechanics and certain other important aspects of physics.
For a while it was considered sort of an extension of math and it's also that but it has its own
character so it's not really considered exactly math. Unfortunately I have no hope of doing this
talk justice. This is something that's really, really beautiful and I doubt I'm going to be able
to convey it to you in this talk. There are no pretty pictures in this talk except one maybe
and there will be a lot of oversimplifications but I am going to be talking about what I consider to
be magic even deeper magic and joy. So programming and theoretical computer science are different
but the same. To use modern slang theoretical computer science is the god mode version of programming
but programming humble simple programming is the basis of the theoretical computer science
and it's the most general tool ever that's why it's important. Of all the things that humanity
has invented computer programming is not necessarily the most important or the best
but it is the most general. You can use it for almost everything. Today it's needed in all the
sciences all engineering and many arts and therefore I think all young people need to understand
at least a little computer programming in the same way that all people need to understand a little
bit of algebra. So I'd like to ask the question what is a computer? So to me a computer is a
mindless machine that can only do very simple mechanical things. Now technically the word
machine to a mechanical engineer means the application of force I don't mean that. I use
the term to emphasize it has no creativity no slop and each step is completely predictable from the
last. Now it's it's quite an extraordinary fact that a computer can really only do five things
and you could you could organize these a little differently but this is the way I organized it
back when I was 16 years old and I still think it's correct. It can input a number, it can store a
number, it can do arithmetic on numbers, it can output a number and it can make a decision based
on a number. But those numbers can be used to represent a lot of things and on the basis of
these very very simple actions by building them up into an edifice of structure of the way things
are organized we can do extraordinary things. So we can ask what is a program? So a program is a set
or sequence of instructions for a computer which is just a machine which are executed in a particular
order that can change based on what's in storage. This is also sometimes called an algorithm because
it doesn't actually require a computer humanity developed algorithms for mathematics which were
step-by-step procedures before computers existed. Nonetheless the nature of a program is that it's
a set of instructions that are executed in a certain order that tell a computer what to do
in the next step. So the first magic that this produces is that complexity and really quite a
lot of complexity emerges from simplicity with the basic five things that I said even a beginner
programmer can compute the factorial of a number and we're going to see that later on in this talk.
Do an extraordinary thing called Conway's game of life which I'm going to show you a demonstration
of which is kind of the best example of complexity rising up out of simplicity and you can also
simulate a role-playing game that feels real even though it isn't real. You can create a character
you say my fighter takes out his sword and wax the wizard and it feels like the wizard's really
there in your fighting even though you programmed it. You know the wizard in the end is just a set
of numbers and the fighter is just a set of numbers so there's almost no creativity in it.
Now I have never been an educator but when I teach beginning courses in computer programming to
teenagers which I've done a few times these are the three programs that I teach first.
The second aspect of magic that computers allow is that they allow you to simulate physics obviously
via mathematics. Mathematics is the language of physics without mathematics we can only do a little
bit of physics. Now what is it that we do when we talk about physics? Well Leonard Suskin has said
Leonard Suskin has said the purpose of physics is to compute is to predict the future so for
example you predict the future of where a ball is going to fall if you throw it up in the air
you know it's going to come down and if you're a good physicist and you know exactly how fast
you threw it up you know exactly where it's going to land. These sorts of simulations
can be done by a computer and in very important circumstances they succeed when math fails that
is there are situations which we as a human society do not know how to solve with math
very well but we can still solve them with a computer by simulating things over time.
Now there are limits to that so there are problems that a computer can solve
that are hard to solve any other way so the famous three-body problem which is considered to be
unsolvable in math recently there was a Netflix show about it can be solved by a computer
in a limited way it can simulate the position of three stars or planets or meteors in space
orbiting each other over time and it can do that one millisecond at a time
and it can do that for billions of milliseconds and it will be fairly accurate let's say a hundred
years from now. Now some people would say that's not a solution to the problem in the sense that
it's not a formula that you can write down that tells you where the planets are nonetheless it's
better than any other solution that we have in the same way we can't write down a formula
that describes the flow of air around an airplane but we can simulate now there's a great
philosophical debate as to whether an individual neuron can be described mathematically it's
unclear if neurons are actually extraordinarily complex or extraordinarily simple you can find
people who will tell you either either one um but it's possible that we can simulate the action
of neurons and therefore we can simulate the action of brains we can also simulate the action of
waves and biological tissues and that is the reason that we have MRIs CAT scans and PET scans
without those we would not be able to address the diseases that we address that way so the third
magic is something that we're all familiar with you're using it right now you're seeing a picture
of me and you're hearing my voice but inside a computer those are represented as little bitty
numbers which are transmitted through a network and come to your computer and then are translated
back into little blips of light on your screen and voltage levels on your speakers this does not
take a lot of theoretical computer science but most of us enjoy computers because they can
store and transmit representations of light and sound in the form of sounds and movies now coincidentally
they can store every word ever written by human beings which is the basis for large language
models in modern artificial intelligence so we're going to talk a little bit about
programming later but I want to talk about theoretical computer science which I consider
to be deeper magic so the deeper magic number one is that you can prove there are things computers
can't do and can't ever do this is the basis of cryptography we've now proved there are problems
that can't be solved by computers some of the cryptographic problems are simply because we
don't have fast enough computers but there are other problems which can never be solved by any
computer they can never be solved by any sequence of instructions no matter how fast the computer is
and and that's really a mind-boggling sort of concept in my opinion so this leads to a thing
called church's thesis Alonzo church was an american logician who worked in the 30s
um the computation done by modern computers are probably the only kind of computations
that can ever be done now this is called church's thesis because it cannot really be proved um so
it's a thesis rather than a a proof so we have several different models of computation one is
the von Neumann machine which is um very similar to the electronic machines that we have so my
macintosh computer would be closest to a von Neumann machine there's the Turing machine which
has been made famous by movies which was invented a little earlier than the von Neumann machine
our computers today are not shaped like Turing machines uh but they're uh similar and then
there's a very unappreciated form of computation called the lambda calculus and the interesting
thing is that you can simulate each of these computers with the other so the lambda calculus
is powerful enough to simulate a Turing machine a Turing machine can simulate a von Neumann
machine and a von Neumann machine can simulate the lambda calculus so you get uh what can be
described as a trippy loop in that everything is powerful enough to simulate the other so none
can be more powerful than the other now is that the only kind of computation that can exist in the
world well we don't really know but that's very strong evidence that there is no other
form of computation that there is no other way to do it now some people would argue that biological
brains and analog computation are a little asterisk to this and that quantum computing
kind of nibbles at the edges of this a little bit but fundamentally this is accepted by most people
so the deeper magic of theoretical computer science is what i call the dismal deep magic
so it may be that thought and computation are the same it may be that human brains cannot
think anything that can't be thought by a computer and it may be that the sex success
of artificial intelligence proves not that machines are intelligent but that humans are dumb
right it may not be that artificial intelligence is somehow coming alive or getting a soul spark
or having consciousness it may be that that we're learning that our own brains are actually not
capable of very much now i hope that's not the case but uh it's it's certainly an interesting
philosophical point so there's an even deeper magic and there's there's no way i can really
explain it in this uh talk if you don't understand it but there's a problem in computer science
called p is equal to np which is a question is p equal to np p is the set of problems that can
be solved in polynomial time np is the set of problems that can be solved in what's called
nondeterministic polynomial time if you're a beginner there's no way i can explain this in
this talk but uh i want what i want to point out is that p equal np is the most important
problem known to humanity today in movies and so forth you sometimes hear about the remand
hypothesis remand hypothesis is chump change compared to p equal np if humanity could show
that p is equal to np which is not obvious that it is most people think it isn't then the world
would change because in practice we could compute things efficiently which we could never compute
before some things would still remain out of reach however and fundamentally this asks the question
if you can verify something efficiently is there always a way to compute it efficiently
and the answer is not obvious the greatest mathematician computer scientist and even
physicist in the world have been working on this problem for 40 years and uh in fact i would argue
they haven't actually made very much headway on it now the final really deep magic is information
theory information theory is where theoretical computer science overlaps with physics and everything
i say here has to be an oversimplification has to be taken with a grain of salt but nonetheless
it's very important to understand information theory is closely related to the idea of entropy
and that is the laws of thermodynamics and conservation of energy and the fact that
the universe in a sense is running down that we're moving towards a less interesting less
concentrated state of energy that everything is always smoothing out and becoming more boring
so to speak information theory is independent of computers although we didn't know that
50 years ago and it applies to many physical processes for example the nyquist limit of
the foyer transform but also really fundamental things like how black holes work are related to
information theory in a way which i only partially understand i partially understand this so it's
kind of true that energy is equal to information and it's kind of true that information is equal
to entropy now obviously this is an oversimplification because entropy is not energy entropy is the
opposite of energy nonetheless in very special circumstances information is similar to energy
and in different circumstances information is similar to entropy so now we can ask the really
fundamental question which which i want everyone especially if you're a beginner here to understand
and be intrigued by it what does a programmer do i've believed for a long time that the job of a
programmer is to create order out of chaos so from uh long before the birth of christ uh there was a
famous hymn to Zeus by cliente's and it begins chaos to be his order and in the middle of it in
one translation obviously it was written in greek you can say but you know how to make the
crooked straight and to bring order to the disorderly even the unloved is loved by you
the poet is speaking to Zeus for you have so joined all things into one the good and the bad
that they all share in a single unified everlasting reason and of course the christian and judaic
bible begins let there be light that's what a programmer does they bring light out of darkness
in order out of chaos so fundamentally a program systemizes that which was not
systemized previously so the main tool of computer programming is could be called abstraction
it's not that easy to understand what it means in this this context programs have subroutines
or functions which can be reused the reuse of a subroutine always cost a tiny amount of time
and also a tiny amount of electricity but once a subroutine is written it can be used over and
over again and it never wears out just like the number 37 never wears out in a sense subroutines
and mathematics are stronger than steel and diamonds steel and diamonds and granite
eventually wear out but math and subroutines don't abstraction is the main tool for making
long programs short and is thus closely connected with bringing order out of chaos
factorial the first program that programmers should learn teaches abstraction through recursion
now there's a thing called lambda lifting that i recommend um an interested student
read the wikipedia article on lambda lifting which is sort of the formal way in which abstraction
enters computer programming but most programmers will will not understand lambda lifting they
will instead think of when i create a subroutine i am creating abstraction which i can reuse again
and again so my own personal style of programming is based on something that paul graham said he
wrote an essay called concision is power and i view the act of programming as being almost
their exceptions the same as trying to create the shortest most compact representation of something
and thus in a way creating the most abstract version of a sequence of instructions to accomplish
something now functional programming is a style in which subroutines are side effect free this
helps to bring order out of chaos because of something technical called referential transparency
and it's the most abstract way of working because it means that a function can be used in any
context and always means the same thing now this is debatable we don't have time to go into it uh
some people don't like functional programming as much as i do another way of expressing this is
a principle called dry or do not repeat yourself in a computer program there should never really be
two lines that are the same there should never be two subroutines that are the same if you find
yourself writing the same code it should become a subroutine and this principle can be applied to
enormous aspects of computer programming you should not have duplication in your data just as
you should not have duplication in your instructions and in many many circumstances what people do is
they copy and paste code from somewhere and in so doing they're violating the dry principle
and after years programs become big fluffy disorderly things where things are almost the
same but not quite in different places and so forth and that's very poor software engineering
but it takes beginners years to fully understand this and to fully understand how to avoid it
so now i'd like to talk about the very first program that i think everyone should write
the first program is called factorial and it's written with an exclamation point
when i was in in college there was a young man who didn't know was called factorial so when he saw
in factorial he said called it in as if as if it's very emphatically the way you you say in
in fact in bang sometimes pronounced bang or in factorial or in exclamation point
is used in the famous formula from probability that's sometimes pronounced in choose k it gives
you the ways to choose k element the number of ways to choose k elements from a set of in objects
this is all important to poker players and all kinds of probability and all kinds of
mathematics but the definition of factorial itself is really really simple and this is it
right here this is actually in javascript we could take this and we could run it okay now
um i learned this so long ago it no longer seems weird to me but some of you reading it
may not have learned this and i remember how hard it was for me to understand when i was about
18 or 19 and i was first introduced to this this concept so what this code says is that
the function that we call factorial which is in bang so to speak has a mathematical definition
if n is equal to zero the answer is one if n is not equal to zero the answer is in times
the factorial of n minus one now this is a trippy loop factorial is being defined in
terms of itself how can the computer know what factorial means when we're telling it what factorial
means right now it's not obvious now to many people in this audience it may be obvious but
when i was a boy this was not obvious to me okay you you might ask the question well how on earth
can the computer ever know how to do factorial of n minus one when we're defining it in terms of
itself it looks like a trick okay and it takes a while to understand it and in fact the answer is
this only works if you call factorial with a smaller number in the body of the function
so that the problem is always somehow getting simpler and eventually it gets down to zero
if that is not true you create an infinite loop infinite loops are much worse than trippy loops
so in fact you could say that this function has a bug if you called this was minus one
it would run forever because it would multiply minus one by the factorial of minus two
which would be minus two times the factorial of minus three which would be minus three times
the factorial of minus four and that number would never become equal to zero and it would never stop
the second program is a program called conways game of life and it was specifically designed
to show how complexity arises out of simplicity okay and it at one kind of artificial level
it's a simulation of biological processes these four rules are the only rules it has
and I believe this is the second computer program which every beginner should write
okay it's played on a grid like a chessboard but the chessboard is considered not to be eight
by eight but to extend as far as you want it to so it's played on a square grid and each grid is called
grid cell square is called a cell okay and a cell is either live or dead
and there's a clock that ticks and one generation leads to the next generation
so you start with some pattern and then you start generations and the rule for each cell
is simply these four rules in a live cell with fewer than two live neighbors that's the cells
the eight cells around it that touch it dies as if by underpopulation I prefer to think of it as
loneliness it dies of loneliness any live cell with two or three live neighbors lives on to the
next generation it's happy any live cell with more than three live neighbors dies by overpopulation
or crowding and then here is a bit of magic any dead cell with exactly three live neighbors
becomes a live cell as if by reproduction okay simple rules that produce almost unbounded complexity
so now I'd like to show you an example of this is Conway's game of life you guys can do this
I'm randomly putting this here I don't know what I'm doing I'm just clicking on some numbers so
you see this consists of a grid of squares and each square is considered a cell yellow means it's alive
gray means it's dead now when I click next it's going to do a generation
so some cells will died and a few cells came into existence and the pattern changed
and now the pattern is going to change again and again and again and again and now I can simply
start running it and we'll see what happens
not done yet
it's not done yet it's not done yet it's not done yet now it's done
so how could that complexity that you just saw arise out of those four rules
that is the thing which is of sort of paramount importance to mathematicians and related to
what I'm talking about the the Iraq the ability of simplicity to give birth to complexity okay and
then finally an exercise that I think all beginning computer programmers should do is to write a very
simple sort of fantasy role-playing game that has characters in it and you can have the characters
fight like you do in Dungeons and Dragons so that a fighter can whip out a sword and say I attack
the wizard and I strike the wizard with my sword and the wizard's health goes down and then the
health the wizard cast a magic spell uh perhaps to catch the um fighter in a web which decreases
their ability to strike in the future now um the thing about this is you play it it's simple
it's fun and it feels alive but you programmed it you know very well the wizard is not alive the
wizard is just a subroutine the wizard is literally 10 or 15 lines of code that you yourself programmed
representing only with numbers now if you don't want to do that you can think of a
complicated game uh an expensive game like Minecraft or something like that accomplishing
the same thing it feels real even though we know in the end it is nothing more than a complicated
series of the five operations I began this talk with so programming is almost reason
but not quite it is almost human reason but it isn't exactly programming does not tell the poet
what word to select or the musician how to play the note perfectly or the painter how the brush
stroke should go but nonetheless the act of programming is very close to the act of human
reasoning for 100 years coming up on 100 years now literally we've been making programming tools
more powerful so for example john von Neumann did not believe in compilers he believed it was a
sign of mental weakness if people had to use compiled computer languages he thought you should
program them sort of only with the the most minimal set of instructions um he was weird
each increase in the strength of the programming tools has not made programming obsolete it has
not decreased the number of people making gainful living by being programmer it has made programming
more important and given gainful employment to more people so I personally do not believe anyone
should fear that AI will replace programming that it's the same as saying AI will replace human
reasoning AI will become a tool used by programmers now I have not used it I don't use co-pilot or
any AI tools for that but at some point I may have to learn how to do that on the other hand I do
think we should fear killer robots I'm much more worried about killer robots than I am uh my ability
to think being replaced by an artificial intelligence so there are a lot of joys associated with
computer programming and um I got to experience these when I was a child almost I started programming
when I was 13 not very well it took me a long time to learn a lot I didn't have anyone to learn from
um I wish every child could experience this joy I wish everyone could it could do these
now there are other ways to learn these joys but computer programming is a darn good way to
to do it as Lee and Nardo Da Vinci said the joy of understanding is one of the greatest pleasures
that humanity can have and computer programming is all about understanding often you begin in
confusion and you move towards understanding because you bring order out of chaos you bring
light out of darkness you start from a situation of not understanding a problem and then you understand
it there's the joy of discovery which I think is quite different that's where you learn something
surprising um sometimes you discover surprising problems sometimes you discover surprising
solutions sometimes like in the case of Conway's game of life you discover surprising things which
are neither problems nor solutions they're just surprising things about the mathematical world
in which we live and then perhaps the greatest joy is the joy of creation you can write a program
you can create something out of nothing which did not exist before and something important
as well of course you can do that by knitting a sweater but one form of creation is writing a
computer program and then you can experience the joy of mastery the joy of moving from a state of
not being very good at something to being pretty good at it um I do not consider myself to have
mastered computer programming uh I'm still learning I I wish I had time to learn more I I'm
considering myself a journeyman programmer so to speak um my one of my heroes Kent Beck said
that confusion should be cherished because it precedes enlightenment and computer program
it is all about moving from a state of confusion to a state of enlightenment and then finally
there's the joy of sharing um
in a way there are not many programs in the world there is only one universal program
it is splintered between my computer and Lawrence's computer and Christina's computer
and Morena's computer but in a way there's really only one computer program in the whole world and
we are all writing parts of it we are writing little bitty parts of it so we are all sharing
in a given enterprise for many people a great joy that they get to experience in college
and I and I wish everyone got to go to college I know some people don't is to um share their
programs with other people sometimes in a classroom setting sometimes not I remember uh one time I
was in a graphics class at the University of Texas when I was in graduate school and my friend
Steve Benz uh put up on his screen a graphic programming and he programmed a little airplane
to fly around the tower of a representation of a tower of an airport and it was it was an
astonishing thing to to have accomplished quite quite beautiful uh I really enjoyed that when I
was at Rice University uh there was there was a student there uh who was quite unusual and I would
walk by his terminal and on it there was a weird glyph and I couldn't figure out what it was so
you know I asked the guy and he said well it's elvish he had created an ascii art representation
of the letter the elvish characters that Tolkien had created which are called tingwar um an example
of nerdy stuff uh but it was more fun because it was shared and then finally and my talk is closing
now um there's the joy of meaning and this is the deepest thing to me public convention gives
everything it does to the whole world we don't keep anything secret everything we do is shared
through open source licensing uh we've been trying to save people's lives for a while now
through global medical stuff I doubt anyone's life has ever been saved by one of our inventions
although it is our goal and we're working towards it things take time to ripen uh I I have faith that
it will eventually happening programming is an important part of our work almost everything
now requires computer programming programming is part of our work and our work is meaningful
and therefore the programming of meaning so thank you for your support of public
convention thank you for listening I've got a few references here which people can look up
on google if they want and I will now open the floor to questions
well I should have been here at 8 and for some reason I thought it started at 8 30
oh okay Victoria Christina's raised your hand go ahead Christina
that was an excellent presentation um I've never actually kind of thought about that all laid out
in such a way uh I feel like it's it's one of those programming in general is one of those
things that I've I've been around for a long time and have a very very very tiny bit of
experience with myself but if you're around it so much you often don't necessarily think of the
origins of it um but I did have a question that came up and it's something that I never
thought of much myself um and it's I love the slide on factorials by the way so in calculating
um factorials you the two things that come to mind are recursive function versus iterative
so I was wondering if um like from a programming standpoint like different characteristics or
use cases specific to either using a recursive or iterative approach um in programming
yeah it's a good it's a good question it's a really good question because um in fact
you can prove in a sense that you you don't have to do this recursively so what Christina's
saying is this self-reference the fact that factorial is defined in terms of factorial is called
um recursion you could write um factorial as what's called a loop and you would count down
and you would examine the value in and you you would count across in and and and do it that way
um so you don't have to do it this way except there are things over time which become so
complicated it would be almost impossible to do all of them um iteratively for example you could
be working on a solving a differential equation you know or some very very big thing and you're in
the middle of it and you're down in the middle of a computation and now you have to do another
factorial right you you have to have subroutines and you have to have abstraction in um in doing
those things and there there are some things which um in order to not define them recursively
you would almost have to stand on your head like like you could do it there's a mathematical proof
that you don't have to have this because after all this programming language is being compiled
into something which is just a set of numbers which is doing the same thing but it would become
unnatural it would become so complicated that you almost couldn't think about it and it would get in
the way of your thinking about it and and a proof of that is the formula on the right hand side of
this page right here we have n bang and it's expressed in terms of k bang and n minus k bang
mathematicians are using this you know using this sort of thing uh referentially as a subroutine in
the same way and if you go to the wikipedia page you will see it defined both iteratively and
recursively i don't know if that answers your question or not yes it does um and kind of as a
follow-up to that i don't want to i don't want to hog all the question time but um are there so
from a computer programming standpoint are there more resource constraints with one versus the other
so if so taking an iterative approach versus recursive like what does that what does it mean
for the programmer when you're coming to choose between the two okay so there are people who will
tell you that an iterative approach is more efficient because a um recursive approach appears on the
surface to use more memory okay and so there are times when an iterative approach would be better
and let me let me return to this and try to explain this in the in the deepest possible way
okay so for example the way this is implemented in a computer in a in as the languages compile
it's turned from this representation into a different representation and you almost can't
discuss it without talking about what's called a stack frame and whenever you make a call you push
onto the stack which is called because it's like a cafeteria tray uh in a cafeteria you know you have
a spring-loaded stack of trays sometimes you you push things onto the stack and you and you build
things up and then you take things off the stack okay you push the variables here onto this the
stack well however many calls you make uh each one of those has to have a memory representation
you can run out of memory okay now you can do it it appears on the surface that you can do it more
efficiently iteratively because you wouldn't have that extra space however this program the way it's
written is what's called tail recursive in the sense that the the use of factorial is the last
thing in what's being done here so the compiler knows that and can automatically implement an
efficient way of doing it so in practice it doesn't matter okay now another way that i if i wanted to
i could attack what you're saying is i could say yes it might be more efficient in terms of computer
instructions but computer instructions are cheap what's hard is the clarity of the program to make
it in an ordered fashion and so i would be very low to write it in a more efficient way
if it decreased the clarity of the program from a human understanding point of view
there's another saying in computer science which is that
premature optimization is the root of all evil that was that's famously said by
Donald Knuth a very important computer scientist so let me let me just show you here what happens
so over here on the right this is actually a the development tools which are built into
the chrome browser and it runs javascript and so i can paste this pro oops i could paste this program
in here but it's apparently please type allow posting in here so it's got a nice security feature
won't let me post it in oh allow pasting okay that
well i'll do it the old-fashioned way i'll type it
so i already typed this in okay so this is javascript this is completely legal javascript
okay and i can call factorial of zero and it's one and i can call factorial of 10 and it'll be a big
number and i can call factorial of 20 and i can call factorial
let's say 100 this may not work okay and it kind of works and it's a very very very very large
number right um now eventually we'll run out there's a bug in this program in a sense factorial is
not actually defined on negative numbers but if i run this on a negative number as i said before
it will go into an infinite loop so we're going to see what happens when it does that
so what it actually says is maximum call stacked size exceeded what it did is it kept going until
it ran out of its own memory now it's smart so before it crashed my computer it caught it
and it said oh i'm not going to let you make that call again
that may be more than you wanted to know about that no no and then sorry so one last thing
would be so would you say that recursion then is more suitable for problems that could be broken
down into similar sub problems and the thing that first comes to mind for me is like some
of the sorting algorithms whereas when i think of iteration i think of more suitable program uses for
problems that would require repeated execution of a block code linear searches things like that
yes okay so i would say yes and the best example of that if you want to google it right now is um
google quicksort okay quicksort is a very simple um program here let me create a new slide um it's
not necessarily the best the best sort in the world but it's it's extraordinarily simple and
that's why it's done it was created by another famous computer scientist i had the pleasure of
meeting uh Charles anthony robert pour who for some reason was called tony uh so more created
quicksort and quicksort looks like this and i can't this is not going to be correct JavaScript
quicksort of and i'll call it s is a sequence
okay and what i do is i is i'll say let a be first half of s that is the first if s has 100
members to be the first 50 okay and exactly how i'd do that i would depend on the exact language
i'm in but let you know let b be the second half of s okay um uh now i'm forgetting it okay and so
then what you do is you do a quicksort of a and then you do a quicksort of b so that those two are
sorted and that that gives you back two list of 50 numbers which are each sorted and then
you you merge them very simply and i maybe i'm forgetting because that would be called a merge
sort instead of instead of a quicksort i think maybe quicksort finds the median uh value and
takes all the lower ones and then all the upper ones and it sorts those two and then merges it
back but it's fundamentally recursive in the way that you just described because you're taking a
list of 100 elements breaking it into two list of 50 sorting the two list of 50 and then doing
something very simple to put it back together now it can be done iteratively as well but it
is probably harder to understand it than by doing it recursively so why do it
that makes sense that's really cool so i i don't know you know a lot of applications i you know
because i don't don't do computer programming but i do know that a lot of what's behind some of these
companies that are doing really extensive gene analysis so analyzing genetic combinations
and permutations they're using programs with a lot of factorial calculations involved so that's
how they're discovering like different gene combinations correlate with certain syndromes or
you know genetic mutations that's that's like the the first real-world case that comes from my mind
well right okay so so here's something mind-blowing even the act of so to us the act of multiplying
two numbers is simple and in java script it's simple you just write a star b and that multiplies
two numbers together okay but as a becomes gigantic and b becomes gigantic it starts to be
inefficient to multiply it the way humans multiply numbers okay of course you would never think of
worrying about this until it's more than like a thousand digits on each side but the numbers you
deal with in genomic combinations can can get really big there's an entire science of computer
science that deals with asymptotic complexity where you try to create the most efficient algorithms
you can i do not fully understand this but the most efficient way to multiply numbers is actually
with the Fourier transform okay so that algorithm for multiplying very very very very large numbers
is quite unnatural compared to what we as school children learn to do in our multiplication
and if you were trying to compute factorial you might do the same thing and you might use
approximations and then there are all kinds of all kinds of tricks to make that go faster and
there's an entire science behind that which is usually not done usually computer programmers
don't worry about that until they're at least out of college
oh do we have any other questions i'll let other people ask questions otherwise we will be here
all night with me being like what about this what about that i am always at your service christina
all right i'm sure others have have questions so i'll i will let others ask them
another thing i learned in graduate school is that silence is golden
and often if you just wait long enough people will ask a question even though they're shy
i don't really have a question but i did you have a comment though
in your description of one of the things i think that i think is kind of overlooked
is the root word of analog computing is i think it's shared with analogy and i like thinking of
computing as an analogy that is running on base level physics or basic level reality
and that that level of and what we're basically doing is creating a story that is playing out
in front of us in the world around us and the story is and we we are consistent with our story
and the consistency of our story reinforces our understanding and in our logic in a way that
gives us belief in understanding of the things that we're doing and the answers that we're getting
it's a little poetic but the but it allows you to start thinking that like water can be used in
computing gravity can be used in computing mechanical structures can be used in computing
DNA can be used in computing like computing is all around us and it's it's really the the
analogy the stories that we use to construct um and the mathematical themes and theories behind
this those those properties that kind of really make it happen so
yeah that's all true
um
you can make a computer out of pneumatic vows or water vows and people did before electronics
were available but the computing that is all around us doesn't do what i would call general
purpose computing in general physical properties tend to be smooth and continuous and in that sense
they're a very limited form of computation for example a slide rule or a caliper you can be
used to multiply numbers but only in it only in a very very limited way making a turing machine
or a turing complete machine or von Neumann machine or land to calculate machine out of a
slide rule would be very hard um and so the electronic computer and the the attempts to
make mechanical computers which famously Lady Ada Babbage did um created a new era of uh computation
i agree with that there's there's still a open question of can you build an
a general purpose analog computer um and then the the corollary v can you build a general
purpose uh neural network um with the drill with the neural fabric um and which is currently a very
hot topic right now in AI research um i agree but that question is bigger than i can address
in this talk one thing i think it's under appreciated i would also want to bring up
is that um the advances in computing that we're currently seeing have allowed us to tackle
problems that were previously on we were unable to really address um i think that's i think that's
going to open up new areas in biology in physics and in uh and i'm just any of like the the big
the bigger world out there and the small world out there so i think that's i think it's under
appreciated because um ten years ago we couldn't model um with the fidelity that we had uh that
we can today with a number of variables and the number of um factors
yep that's correct
does anyone else have a comment
um i just i think it's really cool to think about and uh lauren says first comment made me think of
this it's really cool to think about the fact that all of these well most of these equations or
calculations that are you know given examples here they have been around since ancient times like
these were you know the the end notation wasn't really developed until later but the the like
core idea can be traced back to you know we're talking like you know bc yeah and it's how how
we've kind of evolved the use cases of these equations to for computational purposes so instead
of us using these equations ourselves we have machines now that do it for us um but a lot of the
earlier uses of them were just you know obviously we think of like physics and astronomy um but even
before then it was kind of just this almost like pondering of what if so what if i take
these numbers and do this what happens um so these very very ancient ancient calculations that
are very much a part of our modern life in a big way we wouldn't we wouldn't have modern life today
without them yes i mean just just think of how humanity's power was expanded by the development
of those mathematical algorithms before there were computers right i mean you know before that you
had uh questions that that we would think well that's a computable answerable question and people
might not know how to answer the question right they might not know how what's the area of a sphere
right they might not know what's the area of a cone they might not know that if you have a right
triangle the square of the length of the hypotenuse is equal to the sum of squares of the two sides
although that's been known for a long time presumably there was some time in the past when
it wasn't known right um and so that gets back to my point computer programming is a form of
mathematics that brings order out of chaos and it it expands our power and to me the computer
is an extension of the human brain it's not a replacement it's an exo brain if you will just
the way tony stark's iron suit is a exoskeleton wikipedia is a part of my exo brain and i can
use a computer to perform calculations which would be very awkward or impossible for me to
perform in in other circumstances um so um in a very real sense it's in it both the act of
systematizing things which weren't systematic before extends human power and the electronic
computer which can do these things very rapidly also extends human power
do we have any other questions or comments
fast what's your favorite equation
me yes favorite equation and why
well um force equal mass times acceleration because it's a um it's a it's a second order
differential equation which happens to be easily solvable and from which we can derive
an extraordinary number of effects
i have another question maybe more um kind of philosophical you started with a definition
of what a computer is and kind of explaining it can only basically input and output numbers but with
programming and now um AI or machine learning is there are we getting to the point where
basically these programs or these computers can think much faster than we do i know they can
solve equations but are is it getting to the point where they can quote unquote learn faster than us
and how do we keep up the understanding of like you're saying a computer can only do something
that's traceable um is there a point where maybe like in comparative to to our human reasoning
um is there a point where we're too slow to kind of understand um these programs and machines
well it's a really good question let me give you the answer that pro AI people give and then
i'll tell you what i think okay pro AI people point out that although large language of models
which is one aspect of artificial intelligence are relatively in their infancy they already
beat human beings at standardized tests such as the graduate G the GRE and SAT and the ACT and
they can do well on tests of biology and physics and so as my friend David Jesky has pointed out
every time humanity has said well computers aren't really intelligent because they can't play chess
or they can't play go or they can't um write poetry uh you know those have all fallen right like
they didn't they do those things right and um curmudgeons like me keep saying oh well they
aren't really intelligent even though they can answer a bunch of questions that i can't possibly
answer okay but then i'll tell you what i think um just because it's i think the honesty is worthwhile
i mean sure an AI could beat me at a biology test but an AI has had an infinite amount of time to
learn and to it it's an open book test and AI can't compete with me at all in any real problem
that it hasn't had a bajillion cycles of 50 gigawatts of power to study ahead of time
yeah you know um so
i don't accept artificial intelligence as thinking and being able to learn things at all
now obviously you can build a classifier right like you could classify leaves and it'll tell
you what kind of tree it came from better than i can personally remember the shape of leaves
you know to do it it would beat me at that task right um it would beat me at translating french
into english but it doesn't beat me at understanding even though it can translate french into english
better than i can
i think the question comes down to what is what does it mean to be humans creativity
you know novel ideas i guess
yeah i'm i'm you know i can't claim to be more creative than an AI
but still i i feel that all human beings have something in them which i have not yet seen in an
AI maybe five years from now the little child that is artificial intelligence will have grown
into something um worthy of respect you know uh and then are we gonna say switching the machine
off as murder you know did we kill an AI when you know the power failed i i don't know i
but at the moment i remain skeptical of these these things
you
thanks for your perspective and the talk is very uh interesting and informative you're welcome any other questions
you
okay here in none i think we'll stop the recording here
