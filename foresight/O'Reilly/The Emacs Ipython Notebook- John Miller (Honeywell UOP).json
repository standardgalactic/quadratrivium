{"text": " So, today I'm going to talk about the Emacs IPython notebook. This is the plan. I haven't really timed myself out, so I have a feeling I can get through all this in 20-25 minutes, and then we'll do a demo, and there will be time after that for questions, hopefully. My style, I've noticed these presentations, people tend to wait until the end for questions and comments. I kind of like, I don't mind if you guys have a question while I'm talking, just raise your hand, might take us somewhere interesting, so feel free to interrupt if you want. Let's go on a little bit. So, first, a little disclaimer. I work for a company named Honeywell UOP, and if you've been around long enough, you would know that that company used to be named UOP, and you've been around for a really long time, you'd know that company used to be called Universal Oil Products. I'm not here today for them. They don't know anything about this work I'm doing, I'm fine with that, they're probably fine with that. It is an interesting company, if you want to learn more about it, feel free to come by after the presentation and talk to me. All right, so I also want to first get some thanks out of the way. First, this guy, he is the reason I exist. Takafumi, I've only corresponded with him very briefly, many years ago, just before I forked it, but the guy is insane. I think he did like some like 1800 commits in the space of two years. I'll talk a little bit more about what he did when I get to the history of EIN, but if I were to meet this guy in person, I'd definitely owe him a beer, sake, something because really he's changed my life with this software. I'd also like to thank Fernando and the rest of the Jupiter Project, O'Reilly for sponsoring me and helping me get here and coordinating all this. A couple of years ago, a company, D'Isha, who's actually based here in New York, they actually paid me to do some work on EIN. I'm eternally grateful for them for that, that just was beyond my wildest expectations. Then finally, I'd like to thank all the people on GitHub who have started my project at the moment. There's like 660. I never expected that there would be that many people interested in this project. I think on Melpa, it says there's been 50,000 downloads of the Emacs iPython notebook and I'm just totally blown away by that. I know it doesn't compare to Jupiter or the rest, but I'm just one guy and any interest at all just makes me so happy. All right, so me. I graduated from Colorado State University in 1997. I double majored in chemical engineering and computer science, so that makes me a bit strange. From there, I went straight into UOP, it was UOP at the time, and really that's a company for chemical engineers, not computer science guys. So I've really been doing chemical engineering work for the past 20 years. Computer science is just kind of a side hobby for me. I've been using Emacs since college, maybe 95, 96. I was taking a grad level course in AI and all the homework was done in common language, and if you're programming in Lyft, you pretty much need to use Emacs. I've been filling around with Python since 1998. I actually used it when my first start at my job, used Zope to build a website for my group I was working at at the time. Then I stopped using Python for many years, maybe until six, seven years ago that I discovered pandas and was able to finally free myself from Excel workbooks. Because in my organization, if you're a chemie working in the industry, I do pretty much everything happens in an Excel workbook, which is depressing. Anyways, and pretty around that time, I discovered the IPython notebook, I bounced, to be honest, bounced off the web interface a bit until I found this project Emacs IPython notebook, and then I kind of took over as maintainer in 2014, 2015, because TKF, he just kind of disappeared. So let's talk about Emacs IPython notebook finally. It is, in my opinion, a full-featured client for the Jupyter notebook, and it's existed since roughly 2012. It tries to be a bit like Slime, if you know Emacs a little bit, that's the superior Lisp interaction mode for Emacs. It's a tool for interacting with common Lisp, allows you to interact with the REPL, interactively execute code, inspect code, look at debug code, and I try to be like that. It works on most recent versions of Emacs, and it's written almost completely in ELIS, with the exception of a few Python functions that kind of glue in the IDE features. It has a slew of IDE features, it integrates with the Python debugger, it integrates with org mode, I don't know if any of you here know org mode, live and die by org mode, yes, I've tried really hard to make it work reasonably well with org mode, I'll try and demo it a little bit later. Just recently I've made sure it works with non-Python kernels, I really don't know anything other than Python and ELIS, but I did test it with an R kernel, and it actually kind of worked. And then here's the last one, which is kind of cool, too bad Joel's gone, but we can connect Python buffers to running kernels and get completion and autodoc and stuff like that for free, and I have Python buffer. So Emacs, I don't know how many of you here are familiar with Emacs, that's probably why you're here. So here's my one obligatory XKCD, so yeah, if you know Emacs, whatever you want to do, there's probably an Emacs command that does it for you, and I don't want to be snide, but as I was watching a lot of these presentations to myself, I was thinking, yeah, Emacs, I think Emacs can do that, especially watching the JupyterLab presentation. Nothing against those guys, I think it's great that they're putting all these features together, but a lot of the stuff Emacs is, Emacs, I'm Python notebooks had for like the past four or five years. Why do I use Emacs? Originally this was why Emacs, but that felt a little presumptuous, I'm not going to tell anybody that they have to use Emacs, it's kind of an acquired taste, either you bounce off of it real hard or it just transforms your life and becomes everything. I was looking for good images that represent Emacs, I found this and I thought it was pretty funny, this guy is running a Tetris game in a frame. I don't know how many editors can do that. Who would want to write that in an editor? But anyways, so in my mind, when I think of Emacs and why I use it, this first thing I thought about was a list machine, I don't know if any of you know about list machines. Unfortunately I was too young to really work with any list machines, and I'm a little bit too old to be part of this data science wave, so I'm kind of stuck in the middle. But anyways, Emacs is kind of like the scrappier cousin from the wrong side of town when you think of a list machine. I think it's telling that Emacs has endured so long, it's been around 40 years and people are still using it obviously. I was reading about a week ago, there's a couple of really good blog posts by this guy Josh Stella that kind of explained why he likes Emacs so much, and I felt really resonated with me, and I think a couple of points is it's a tool that you control completely. It's your tool, it allows you to focus completely, there's no distractions when you're working with Emacs, and the Emacs IPython notebook tool really buys into that philosophy I think, and that's why I like using it so much in my work. I didn't really want to get into editor wars, I know that's a very popular pastime activity, but I think it's great that there's alternate clients out there, I think it's great that there's Uperilab, I think it's great that there's Interact. I think it's a sign of a healthy community that you have multiple tools out there and they can all learn from each other. Let's do a little bit of history of the line. There was supposed to be a graph in here, but it's gone. Let's do this. I lost myself here. I worked so hard in Microsoft PowerPoint to build this graph, I have to show it to you, but it doesn't want to show. There we go. Okay, 2012 is the first commit to the Emacs IPython notebook. Around March of 2014, that was the last commit by TKF. About a month later, I forked it. This was about the time when IPython was going from version 1.0 to 2.0. There were a lot of changes to the interface, to the communication protocol, and IPython Emacs I'm just wasn't keeping up, so I think TKF got burned out by all those changes and just stopped committing. I just took over and managed to get it working on 2.0 and I've been running with it ever since. On April 2014, there was a version 0.3. I'm now at what, version 14.1. It works with Jupyter. There's over 650 stars on GitHub and over 50,000 downloads from Meltha, so it's kept up with the times for the most part and I'm really happy with it. Just going through that a little bit. Yeah, 1,795 commits by this one guy. I think we're at 2,500 commits, so that means 800 commits are mine in the space of four years, so I'm no master programmer. I'm just a guy. I will say though that going from IPython 1.0 to today's Jupyter, there was rough sailing for a while. There were a number of real challenges I had to get through. One, there were changes to the contents API. That's the file view, browser view that you'll see. There are big changes there. There are some changes in the communication protocol, changes in the security model. That was probably the most painful for me to try and work through. Then there are some changes to the notebook format. All of those work through, but now everything seems to be really stable on the Jupyter side. I hope it stays that way. Honestly, they've been really good about that. I may complain about things, but they've been really good about keeping things stable. It made me so happy when they mentioned in the last presentation that they made no backwards incompatible changes to the notebook format because that code is really horrible. Probably the worst piece of code I've written as a programmer. Why these things were hard? Because I get a little shy and embarrassed outside of Emacs. I'm kind of old, so I don't understand all these newfangled web technologies. I break out in highs whenever I try to read JavaScript. It's been kind of hard to try and understand that, but the documentation from Jupyter has been really good. The people on the distribution have been really helpful. Mattias, Brian, those guys have been really helpful and patient with me as I come up with the occasional question. Also, when I'm trying to support users, this seems to be the most common issue when people post a GitHub is I can't connect to a notebook or the kernel is not running. Those are really hard because I have to be able to reproduce the problem. Emacs greatest disadvantage is maybe its greatest disadvantage is that it's so configurable. Usually it turns out the issue is with the way that they've configured their installation. It's just me trying to work through what that is. Usually there's nothing I can do to bulletproof it. It's just change your configuration. Those were the challenges. What have I loved about this project? It's a short list, but really the joys have greatly outweighed the challenges because, in part, the challenges have been the joy. It's quite a rush when you have this really difficult problem and you find a way to fix it. That keeps me going. There are people out there that use it. There are people in professional organizations that are using Emacs and the Emacs I Python notebook, which is just great. I never expected that. I use it for me mostly, but that other people use it is great. The community, the people on GitHub are really nice. They're really supportive. Finally, I like to program in Lisp. I get to do that and do something that's useful for people at the end of the day. It doesn't get better than that. Let's dive a little bit into Ion's features. I don't know. How many of you here have actually used the Emacs I Python notebook? Okay. Probably back in the I Python pre-1.0. Yeah, I got the messages from people on the Jupyter list that they stopped using it because it stopped working. When I forked it, definitely a lot of people that were using it weren't aware of the fork, and so it's taken a lot of time for people to come back. So Emacs I Python notebook, it tries to look a lot like the notebook interface, except it's more text-like. A lot of the features that are there in the web interface are also in Emacs. You can cut copy and paste cells. You can move cells around. It has inline images. You can work with multiple kernels. All that's there. Also has a number of IDE-like features. I think this puts it more in the realm of the Jupyter lab folk. There's auto-completion, which, if you have it configured right, works really, really well, but it can be a bit of a pain to configure. We can jump to definitions of functions. Bunch of other stuff. I'm going to try and demo some of this later. I really like this integration with Debugger because you can actually see the code as you're stepping through. I don't think that's not something that you'll find on the web browser interface. There's a number of things that are unique to Emacs. It's probably some of the IDE stuff that is also unique to Emacs, but you can launch Jupyter from inside Emacs. If you configure it correctly, it'll open up a buffer and it'll log everything from the Jupyter server there. You can execute ELIS from IPython. The code that does this is kind of old, so it works, but I executed it and then opened this notebook up in the Roy browser and complained about some stuff. It integrates with org mode. You can have source blocks in org mode that'll execute. The results will go into your org buffer, including images. Support for high. Have any of you heard of high? I actually saw that and was like, oh, I have to support this in Emacs. You have a Lisp for Python with a Lisp syntax and it's not running in Emacs. Come on, guys. The Callisto Py kernel. We can do that, but I can also intermix. I'll show you. I'll show you if we get to it. You can connect a Python buffer to a running notebook, which means it has access to a lot of the stuff that's available in the kernel, which is auto-completion and doc tools. You can customize it using ELIS, not JavaScript. Emacs doesn't know JavaScript. Who has pop-up, yeah, and then run doc tests. Those are things I don't use a whole lot. You'll find that the stuff that works really well on Emacs in I'm is stuff that I use in my day-to-day stuff for obvious reasons. There's some stuff that definitely needs a lot of tender-loving care. There used to be a feature to take a Panda's data frame and open it in the simple Emacs spreadsheet. I tried that a couple of times, but the performance is, especially if it's a large data frame, Emacs will really struggle with that. You used to be able to use the hierarchy magic to get a hierarchy of a class and embed that in the notebook. It's based on a notebook extension that was written for pre-ipython 1.0, so it's not going to work with modern Jupyter, that extension needs to be updated. Guess who's the maintainer of that? I want to wrote that, TKF. But it probably wouldn't take a whole lot of work, really, honestly, to get it working. There's a few things that I does not do at all, and it's possible, may never do. Number one on those is widgets. That's because Emacs is not a web browser. There's some hope with maybe with XWidget and embedding the web browser inside the Emacs buffer. There's also the skewer package that might allow widgets to run in some form, maybe not there in the Emacs buffer, but at least in another window, maybe, but it's not something I really need to use. The effort involves going to be probably pretty significant, so I don't know if it's going to happen anytime soon. Most notebook extensions probably won't work with Emacs because the notebook extension will have some JavaScript in it, and again, Emacs doesn't know JavaScript, knows how to edit JavaScript, great JavaScript editor, but it doesn't know how to execute it. But if you want to take the time to translate JavaScript into Emacs lists, you can make it work. I took one, this really simple module, the timestamp module, that timestamp sells, wrote a couple functions in elisp, and it basically has the same function as that extension. In theory, if someone wanted to write an extension for iN, they could do so if they wanted to learn elisp. iN sort of supports Jupyter Hub. I'd like that support to be better. We'll see if I can get to it or not. It is a bit wonky. Last I looked, I think it worked with Jupyter version 0.8, but it only supported the PAM authorization. I don't know if it'll support what it'll take to get it to do OAuth, but that would be nice. Again, that's kind of, yeah. I was just going to ask if there's any HTML support, is this a simpler target than JavaScript? Like manipulating the DOM? Yeah, or not, like somebody sends some divs or some style of text. So it won't know how to render it nicely, but I mean, if it's there in the cell, it'll show up. It does some nice syntax highlighting. It knows how to syntax highlight like markdown and Python. And I'll kind of show that when I open up the example. So what's next? I just want to make sure it's staying compatible with Jupyter. Always like it to be more robust. I kind of wish I could make it to the point where I don't get these not connecting to kernel questions. Though it seems to be lately they're all related to SSH issues, which I guess that's something. That's better than having a local running instance and not being able to connect to it. And there's a number of stuff. I have an org file with a long list of improvements I like to make. I think they've been sitting around for like three, four years, but some day, some day. So why don't we go ahead and do a little example. If there are any questions before I move on to the example demo, all right. So this is what, if you haven't seen it before, this is what the Emacs IPython looks like when you first launch the notebook list view. So kind of reminiscent of the web view. Down here are the files. You can actually open files that aren't IPython notebooks and edit them. So let's say, for example, this pavement pie. There's some issues. So we've got this Python buffer, and it's actually connected to the notebook server. So if I save this file here, it actually gets saved on the server. So this is one way of doing remote file editing. I know Emacs has Tramp. I'd really like it if I had an IPython Tramp protocol. I think that would be really cool. That would be very Emacs-y, but again, it's something that requires time and effort. I'm not sure if I'll get to it. So let's go to this presentation. This is the actual presentation I just gave you. I wrote it all in Emacs. I was going to try and put it in a PowerPoint presentation, but I raged quit after a few minutes of trying to copy stuff over to PowerPoint, and thanks to IPython and RISE, we had the presentation that we did. So let's go down here a little bit. I went to the demonstration. So looking at this interface real quick, so you see up in this upper left corner, there's the execution count. This one, actually back in the day, I supported multiple worksheets. It kind of still does. The problem is that IPython itself doesn't do worksheets anymore, so it would be a little bit of work on my end, but I could bring that back if people were interested. And then the kernel is running, which you can change. You can also reset the kernel. And then you can execute, and it's just like an IPython, like in the notebook. Now, I want you to watch carefully, and this was all inspired by Joel's talk earlier about what he hated about the IPython notebook. I don't know if any of you saw that. So watch carefully. No execution count, nothing up my sleeves. I haven't executed this line. I haven't executed import sys at anywhere in this notebook, I promise. Thank you. Thank you. This is using the Jedi package, and it's using Jedi. So it's not actually talking to the kernel, actually what it does in this instance is querying Jedi, and it's querying the kernel, and it's figuring out which one has the results, and the kernel is probably saying, I don't know. But Jedi, because it statically goes through, it knows, and you can actually get some completion. Now, this only supports, if you guys know about the Emacs completion packages, there's autocomplete, and there's company, and I have some support for company, but what I just showed here really only works with autocomplete. Maybe with company Jedi, I could get this working with company mode as well. What's just like that? Say hello, world. All right. I'm going to go down here real quick and set my plotting parameters, so this plot doesn't look too... It's Emacs. It can be whatever you want. So I use Space Max. So in Space Max, you can have like a special mode key, which for, in this case, it's comma, so I do comma return, and that executes the cell. But if you wanted to be shift return, you could do that. To open the notebook? Sure. So here's the notebook list view, notebook list buffer. So oh, okay. Oh, you're right. Okay. Why don't we do this then? Let's start from nothing. So this command I'm typing in right now, that stops the Jupyter server. Let's do that. Let's kill that buffer. Let's make sure there is no running, gotcha. And then let's do this, AYS. So I just execute the command Ayn Jupyter start server. You can configure the name of the Jupyter command. There's a variable for that. If that variable's not set, it'll ask you for a path to the Jupyter server. Then it'll ask you for a path to where you want the server to open, which is doing right now. And I've got this nice little default, so let's start that. My fingers are crossed. It's going to take a little bit to start up the server, which I can probably jump to right now. There it is. Hopefully, I haven't confused Emacs. There we go. It's trying to log in. And there we go. There's the browser. This is probably the easiest way to get it running on your local machine is the Ayn Jupyter server start. It brings up this, it's called the notebook list view or notebook list buffer. And it works pretty much like it does on the web interface. So I'm going to go to the Emacs IPython notebook project directory, go back down, and then you just select open. So here we are, back again. So it started up the kernel, new execution, so it's at zero count. And here we are. So clear? Was it clear? You're very welcome. So where was I? Oh, I was going to do an inline plot, because this is what got me started in the first place. I liked using Matplotlib to generate pretty plots for my work, because I think they're a lot prettier than what Excel does. So let's do this. I didn't execute. So you can't put comments in magic lines. Let's do this. There we go. Right now. I know that looks really small. I'm sorry. I'll see if I can get this again. There we go. That's the good news. The bad news is stuff like Boca, Altair, Vega, they won't work, because they use JavaScript, and that won't run in Emacs. Yeah. I think when I was working on this, my motivation is, how can this help me do my work? And I think the IPython in the notebook, this system for doing exploratory data analysis, manipulating data, that was really my focus at the time, because as a chemie, I work in the service department, and some of what my job is, is looking at trying to troubleshoot problems on chemical process units, and so we get a lot of time series data, and so we got to work through that data, and sometimes you get the data in really weird formats, and having something like pandas makes it really nice to manipulate and work with that data, and having something like Matplotlib is really nice for generating graphs to look at the data and share them with your colleagues. So really, that has been a lot of my motivation with this project. I think that the fact that it's kind of been this nice environment is a really nice benefit or secondary effect of all this. I haven't really done a whole lot to promote it over the years, but I think there's probably some good lessons here for people that are developing other clients, but that's not for me. Anyways, so we also have a help browser, so it pops up a buffer, and you can space through it if it's, I forgot, you can go through it, right, it makes it a little easier to read. If you're really masochistic, you can also do pop-ups, it'll do a pop-up. There's a fairly good integration with the debugger support, so you'll get errors when things don't work. You get tracebacks. If you want to get a full view of the traceback, this is not terribly interesting because there's only one level to it. If I think it's return, that didn't work, unfortunately, but you can jump to source from the tracebacks. We'll see what this next one, hey look, there's raccoons, let's do this. So there's a traceback of that. So I can actually jump to that file, fingers crossed, there we go, we just jumped to the file and the line that was referenced in the traceback. If I want, I can go into the debugger, if I want to know, and see it popped up for me, it's already showing me in the code where this error occurred, if you can see it, there's a little arrow, tiny, tiny, tiny little arrow in the fringe. I can go up a stack and you can see it's moved with us. I can basically do the stuff that you would normally do in the Python debugger, for the most part supports that completely. I don't know if you get that in JupyterLab yet, but I've actually used it a few times and it's very useful. Now okay, somebody mentioned hi, I'm going to have to change the cell type. So this is a Python kernel, prior to this I installed the hi module for this kernel. You can set in-ine a special cell type, call it the cell, the hind cell, and it will execute in Python, if you don't believe me, watch this. So I'm going to set this variable, hi there, and oops, that shouldn't be, there we go. This next cell is Python, there it is. So I don't know why you do that, but you can. You can also use the load magic, as you can see, it will create a new cell with the file. There's a special, I don't know if you're org, if you're aware of the edit source blocks, it pops up a new buffer with the source and it's in the mode of the code language that the code is, we can do something similar with in, so I just did that here. So here's basically a Python buffer with all the benefits that that bring with it, because in Emacs there's quite a few packages out there that make editing Python better. I can execute it, I can modify, I'm not going to do that, and then we're back in the notebook. Now I'm running out of time, so real quickly, we're going to go to, did I open it, test Python, all right, I'm going to connect this, connect to notebook buffer, so we can actually execute this, I'm going to comment that out, and it goes to what we call the, what I call, what is called the shared buffer. You don't see anything there, but we can do this, which didn't work the way I wanted, but I can go back to the notebook and you see we've created this digits variable, and it should be available in the notebook, and there it is. Now in this Python buffer, I get all the goodies that I have in the notebook, so load digits, I can bring up the pop-up help, I get, I can jump to source, I didn't find it, darn it, and auto-completion, I think I mentioned auto-completion, all right, datasets, I haven't imported the module, and Jedi probably doesn't know about this, but we get the auto-completion, I'm hurrying myself because I want to leave you time for some questions, there's this one last thing, there's this thing called import magic, that if I were to try to execute this and really what's happening when I execute is it's doing a run on the file, magic run, it's not like lists where you can redefine individual functions, you have to reload the whole file, but anyways, so there's this package called import magic, and it'll try and fix, so as you can see, I hadn't imported the OS path join, so there's somewhere in I'm, there's an error saying it didn't know about that, so I can fix that, and as you can see it edited, and I could probably, there we go, and it erred because I didn't save the buffer before trying to connect, so, why is it doing that, all right, well, so much for that demo, anyways, I guess that was just a talk, an introduction to Ayn and its features, I need to stop now, so I wanted to thank you all for coming, and you can find me, once this gets published, there's contact information, look for me on GitHub or on e-mail, and thank you all for coming. I didn't play with it too much, but it will connect to a Callisto high, and works mostly the problem with Ayn is it's very Python centric still, so the notebook itself, it probably won't give you this nice syntax formatting as you expect for list code, so it's not great for writing large expressions, but if you were to do a buffer, and then connect it to a high buffer, and connect it to the kernel, I think that would work, if not, it might not be too much work to get it to happen. So, what I do to get it to intermingle, I wrote a little Pi function that basically wraps calls to the syntax, you know, the parser and evaluator, and then Python, what I do on Emacs is I wrap the text of that cell, and then send it to the kernel and execute that function. And it works, I was surprised it works, but it does. I don't do a whole lot in high, I haven't found a use case for it in what I do, but I thought it was kind of cool that I could get it to work. I wonder if I have... It will try to print data frames, and it kind of looks like a text table, which, if you have a really wide pandas frame, looks really, really ugly, but it will kind of try to do that. HTML, you know, it's basically Emacs HTML, so it will show the markup. If you install the right package, you can get some latech, like inline image replacement of latech and your markdown cells. No, it... What was the name of that? Let's see if I can find it. Yeah, so inline latech. Yeah, so I think it was either Org Latech Preview or Magic Latech Buffer. It was one of those two. If you install one of those, it actually goes through the trouble of inserting in the image, generating and inserting the image. But as far as MIME types, I mean, it does try to handle HTML, but it's not a rendered HTML.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 5.28, "text": " So, today I'm going to talk about the Emacs IPython notebook.", "tokens": [50364, 407, 11, 965, 286, 478, 516, 281, 751, 466, 264, 3968, 44937, 8671, 88, 11943, 21060, 13, 50628], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 1, "seek": 0, "start": 5.28, "end": 6.28, "text": " This is the plan.", "tokens": [50628, 639, 307, 264, 1393, 13, 50678], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 2, "seek": 0, "start": 6.28, "end": 11.52, "text": " I haven't really timed myself out, so I have a feeling I can get through all this in 20-25", "tokens": [50678, 286, 2378, 380, 534, 44696, 2059, 484, 11, 370, 286, 362, 257, 2633, 286, 393, 483, 807, 439, 341, 294, 945, 12, 6074, 50940], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 3, "seek": 0, "start": 11.52, "end": 17.72, "text": " minutes, and then we'll do a demo, and there will be time after that for questions, hopefully.", "tokens": [50940, 2077, 11, 293, 550, 321, 603, 360, 257, 10723, 11, 293, 456, 486, 312, 565, 934, 300, 337, 1651, 11, 4696, 13, 51250], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 4, "seek": 0, "start": 17.72, "end": 21.76, "text": " My style, I've noticed these presentations, people tend to wait until the end for questions", "tokens": [51250, 1222, 3758, 11, 286, 600, 5694, 613, 18964, 11, 561, 3928, 281, 1699, 1826, 264, 917, 337, 1651, 51452], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 5, "seek": 0, "start": 21.76, "end": 22.76, "text": " and comments.", "tokens": [51452, 293, 3053, 13, 51502], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 6, "seek": 0, "start": 22.76, "end": 28.1, "text": " I kind of like, I don't mind if you guys have a question while I'm talking, just raise", "tokens": [51502, 286, 733, 295, 411, 11, 286, 500, 380, 1575, 498, 291, 1074, 362, 257, 1168, 1339, 286, 478, 1417, 11, 445, 5300, 51769], "temperature": 0.0, "avg_logprob": -0.19260999891493055, "compression_ratio": 1.5902777777777777, "no_speech_prob": 0.16632676124572754}, {"id": 7, "seek": 2810, "start": 28.1, "end": 34.18, "text": " your hand, might take us somewhere interesting, so feel free to interrupt if you want.", "tokens": [50364, 428, 1011, 11, 1062, 747, 505, 4079, 1880, 11, 370, 841, 1737, 281, 12729, 498, 291, 528, 13, 50668], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 8, "seek": 2810, "start": 34.18, "end": 35.18, "text": " Let's go on a little bit.", "tokens": [50668, 961, 311, 352, 322, 257, 707, 857, 13, 50718], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 9, "seek": 2810, "start": 35.18, "end": 36.620000000000005, "text": " So, first, a little disclaimer.", "tokens": [50718, 407, 11, 700, 11, 257, 707, 40896, 13, 50790], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 10, "seek": 2810, "start": 36.620000000000005, "end": 40.94, "text": " I work for a company named Honeywell UOP, and if you've been around long enough, you", "tokens": [50790, 286, 589, 337, 257, 2237, 4926, 16187, 6326, 624, 12059, 11, 293, 498, 291, 600, 668, 926, 938, 1547, 11, 291, 51006], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 11, "seek": 2810, "start": 40.94, "end": 45.14, "text": " would know that that company used to be named UOP, and you've been around for a really", "tokens": [51006, 576, 458, 300, 300, 2237, 1143, 281, 312, 4926, 624, 12059, 11, 293, 291, 600, 668, 926, 337, 257, 534, 51216], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 12, "seek": 2810, "start": 45.14, "end": 49.84, "text": " long time, you'd know that company used to be called Universal Oil Products.", "tokens": [51216, 938, 565, 11, 291, 1116, 458, 300, 2237, 1143, 281, 312, 1219, 22617, 23545, 47699, 13, 51451], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 13, "seek": 2810, "start": 49.84, "end": 52.74, "text": " I'm not here today for them.", "tokens": [51451, 286, 478, 406, 510, 965, 337, 552, 13, 51596], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 14, "seek": 2810, "start": 52.74, "end": 56.86, "text": " They don't know anything about this work I'm doing, I'm fine with that, they're probably", "tokens": [51596, 814, 500, 380, 458, 1340, 466, 341, 589, 286, 478, 884, 11, 286, 478, 2489, 365, 300, 11, 436, 434, 1391, 51802], "temperature": 0.0, "avg_logprob": -0.13983769347702246, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0384543351829052}, {"id": 15, "seek": 5686, "start": 56.86, "end": 58.9, "text": " fine with that.", "tokens": [50364, 2489, 365, 300, 13, 50466], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 16, "seek": 5686, "start": 58.9, "end": 62.9, "text": " It is an interesting company, if you want to learn more about it, feel free to come by", "tokens": [50466, 467, 307, 364, 1880, 2237, 11, 498, 291, 528, 281, 1466, 544, 466, 309, 11, 841, 1737, 281, 808, 538, 50666], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 17, "seek": 5686, "start": 62.9, "end": 65.7, "text": " after the presentation and talk to me.", "tokens": [50666, 934, 264, 5860, 293, 751, 281, 385, 13, 50806], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 18, "seek": 5686, "start": 65.7, "end": 70.98, "text": " All right, so I also want to first get some thanks out of the way.", "tokens": [50806, 1057, 558, 11, 370, 286, 611, 528, 281, 700, 483, 512, 3231, 484, 295, 264, 636, 13, 51070], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 19, "seek": 5686, "start": 70.98, "end": 76.58, "text": " First, this guy, he is the reason I exist.", "tokens": [51070, 2386, 11, 341, 2146, 11, 415, 307, 264, 1778, 286, 2514, 13, 51350], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 20, "seek": 5686, "start": 76.58, "end": 83.46000000000001, "text": " Takafumi, I've only corresponded with him very briefly, many years ago, just before", "tokens": [51350, 9118, 2792, 17800, 11, 286, 600, 787, 6805, 292, 365, 796, 588, 10515, 11, 867, 924, 2057, 11, 445, 949, 51694], "temperature": 0.0, "avg_logprob": -0.257770458020662, "compression_ratio": 1.4955357142857142, "no_speech_prob": 0.02929985523223877}, {"id": 21, "seek": 8346, "start": 83.46, "end": 86.46, "text": " I forked it, but the guy is insane.", "tokens": [50364, 286, 17716, 292, 309, 11, 457, 264, 2146, 307, 10838, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 22, "seek": 8346, "start": 86.46, "end": 91.38, "text": " I think he did like some like 1800 commits in the space of two years.", "tokens": [50514, 286, 519, 415, 630, 411, 512, 411, 24327, 48311, 294, 264, 1901, 295, 732, 924, 13, 50760], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 23, "seek": 8346, "start": 91.38, "end": 95.97999999999999, "text": " I'll talk a little bit more about what he did when I get to the history of EIN, but", "tokens": [50760, 286, 603, 751, 257, 707, 857, 544, 466, 437, 415, 630, 562, 286, 483, 281, 264, 2503, 295, 462, 1464, 11, 457, 50990], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 24, "seek": 8346, "start": 95.97999999999999, "end": 100.38, "text": " if I were to meet this guy in person, I'd definitely owe him a beer, sake, something", "tokens": [50990, 498, 286, 645, 281, 1677, 341, 2146, 294, 954, 11, 286, 1116, 2138, 16655, 796, 257, 8795, 11, 9717, 11, 746, 51210], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 25, "seek": 8346, "start": 100.38, "end": 105.17999999999999, "text": " because really he's changed my life with this software.", "tokens": [51210, 570, 534, 415, 311, 3105, 452, 993, 365, 341, 4722, 13, 51450], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 26, "seek": 8346, "start": 105.17999999999999, "end": 112.46, "text": " I'd also like to thank Fernando and the rest of the Jupiter Project, O'Reilly for sponsoring", "tokens": [51450, 286, 1116, 611, 411, 281, 1309, 30190, 293, 264, 1472, 295, 264, 24567, 9849, 11, 422, 6, 8524, 6917, 337, 30311, 51814], "temperature": 0.0, "avg_logprob": -0.2039259877698175, "compression_ratio": 1.5494505494505495, "no_speech_prob": 0.3261301815509796}, {"id": 27, "seek": 11246, "start": 112.46, "end": 116.05999999999999, "text": " me and helping me get here and coordinating all this.", "tokens": [50364, 385, 293, 4315, 385, 483, 510, 293, 37824, 439, 341, 13, 50544], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 28, "seek": 11246, "start": 116.05999999999999, "end": 119.82, "text": " A couple of years ago, a company, D'Isha, who's actually based here in New York, they", "tokens": [50544, 316, 1916, 295, 924, 2057, 11, 257, 2237, 11, 413, 6, 6802, 1641, 11, 567, 311, 767, 2361, 510, 294, 1873, 3609, 11, 436, 50732], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 29, "seek": 11246, "start": 119.82, "end": 122.94, "text": " actually paid me to do some work on EIN.", "tokens": [50732, 767, 4835, 385, 281, 360, 512, 589, 322, 462, 1464, 13, 50888], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 30, "seek": 11246, "start": 122.94, "end": 128.82, "text": " I'm eternally grateful for them for that, that just was beyond my wildest expectations.", "tokens": [50888, 286, 478, 10533, 379, 7941, 337, 552, 337, 300, 11, 300, 445, 390, 4399, 452, 4868, 377, 9843, 13, 51182], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 31, "seek": 11246, "start": 128.82, "end": 134.26, "text": " Then finally, I'd like to thank all the people on GitHub who have started my project at the", "tokens": [51182, 1396, 2721, 11, 286, 1116, 411, 281, 1309, 439, 264, 561, 322, 23331, 567, 362, 1409, 452, 1716, 412, 264, 51454], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 32, "seek": 11246, "start": 134.26, "end": 135.26, "text": " moment.", "tokens": [51454, 1623, 13, 51504], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 33, "seek": 11246, "start": 135.26, "end": 136.26, "text": " There's like 660.", "tokens": [51504, 821, 311, 411, 1386, 4550, 13, 51554], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 34, "seek": 11246, "start": 136.26, "end": 140.26, "text": " I never expected that there would be that many people interested in this project.", "tokens": [51554, 286, 1128, 5176, 300, 456, 576, 312, 300, 867, 561, 3102, 294, 341, 1716, 13, 51754], "temperature": 0.0, "avg_logprob": -0.20700306362575954, "compression_ratio": 1.625, "no_speech_prob": 0.28067219257354736}, {"id": 35, "seek": 14026, "start": 140.26, "end": 145.73999999999998, "text": " I think on Melpa, it says there's been 50,000 downloads of the Emacs iPython notebook and", "tokens": [50364, 286, 519, 322, 7375, 4306, 11, 309, 1619, 456, 311, 668, 2625, 11, 1360, 36553, 295, 264, 3968, 44937, 741, 47, 88, 11943, 21060, 293, 50638], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 36, "seek": 14026, "start": 145.73999999999998, "end": 148.22, "text": " I'm just totally blown away by that.", "tokens": [50638, 286, 478, 445, 3879, 16479, 1314, 538, 300, 13, 50762], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 37, "seek": 14026, "start": 148.22, "end": 153.26, "text": " I know it doesn't compare to Jupiter or the rest, but I'm just one guy and any interest", "tokens": [50762, 286, 458, 309, 1177, 380, 6794, 281, 24567, 420, 264, 1472, 11, 457, 286, 478, 445, 472, 2146, 293, 604, 1179, 51014], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 38, "seek": 14026, "start": 153.26, "end": 157.01999999999998, "text": " at all just makes me so happy.", "tokens": [51014, 412, 439, 445, 1669, 385, 370, 2055, 13, 51202], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 39, "seek": 14026, "start": 157.01999999999998, "end": 159.1, "text": " All right, so me.", "tokens": [51202, 1057, 558, 11, 370, 385, 13, 51306], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 40, "seek": 14026, "start": 159.1, "end": 162.89999999999998, "text": " I graduated from Colorado State University in 1997.", "tokens": [51306, 286, 13693, 490, 15786, 4533, 3535, 294, 22383, 13, 51496], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 41, "seek": 14026, "start": 162.89999999999998, "end": 167.98, "text": " I double majored in chemical engineering and computer science, so that makes me a bit", "tokens": [51496, 286, 3834, 13673, 2769, 294, 7313, 7043, 293, 3820, 3497, 11, 370, 300, 1669, 385, 257, 857, 51750], "temperature": 0.0, "avg_logprob": -0.2092037888260575, "compression_ratio": 1.5018726591760299, "no_speech_prob": 0.0026313660200685263}, {"id": 42, "seek": 16798, "start": 168.01999999999998, "end": 170.82, "text": " strange.", "tokens": [50366, 5861, 13, 50506], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 43, "seek": 16798, "start": 170.82, "end": 176.5, "text": " From there, I went straight into UOP, it was UOP at the time, and really that's a company", "tokens": [50506, 3358, 456, 11, 286, 1437, 2997, 666, 624, 12059, 11, 309, 390, 624, 12059, 412, 264, 565, 11, 293, 534, 300, 311, 257, 2237, 50790], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 44, "seek": 16798, "start": 176.5, "end": 180.1, "text": " for chemical engineers, not computer science guys.", "tokens": [50790, 337, 7313, 11955, 11, 406, 3820, 3497, 1074, 13, 50970], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 45, "seek": 16798, "start": 180.1, "end": 183.29999999999998, "text": " So I've really been doing chemical engineering work for the past 20 years.", "tokens": [50970, 407, 286, 600, 534, 668, 884, 7313, 7043, 589, 337, 264, 1791, 945, 924, 13, 51130], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 46, "seek": 16798, "start": 183.29999999999998, "end": 186.01999999999998, "text": " Computer science is just kind of a side hobby for me.", "tokens": [51130, 22289, 3497, 307, 445, 733, 295, 257, 1252, 18240, 337, 385, 13, 51266], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 47, "seek": 16798, "start": 186.01999999999998, "end": 190.82, "text": " I've been using Emacs since college, maybe 95, 96.", "tokens": [51266, 286, 600, 668, 1228, 3968, 44937, 1670, 3859, 11, 1310, 13420, 11, 24124, 13, 51506], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 48, "seek": 16798, "start": 190.82, "end": 197.82, "text": " I was taking a grad level course in AI and all the homework was done in common language,", "tokens": [51506, 286, 390, 1940, 257, 2771, 1496, 1164, 294, 7318, 293, 439, 264, 14578, 390, 1096, 294, 2689, 2856, 11, 51856], "temperature": 0.0, "avg_logprob": -0.19251795682040126, "compression_ratio": 1.5773584905660378, "no_speech_prob": 0.005219640210270882}, {"id": 49, "seek": 19798, "start": 197.98, "end": 202.5, "text": " and if you're programming in Lyft, you pretty much need to use Emacs.", "tokens": [50364, 293, 498, 291, 434, 9410, 294, 12687, 844, 11, 291, 1238, 709, 643, 281, 764, 3968, 44937, 13, 50590], "temperature": 0.0, "avg_logprob": -0.22252129972650764, "compression_ratio": 1.462882096069869, "no_speech_prob": 0.0011693094857037067}, {"id": 50, "seek": 19798, "start": 202.5, "end": 207.01999999999998, "text": " I've been filling around with Python since 1998.", "tokens": [50590, 286, 600, 668, 10623, 926, 365, 15329, 1670, 21404, 13, 50816], "temperature": 0.0, "avg_logprob": -0.22252129972650764, "compression_ratio": 1.462882096069869, "no_speech_prob": 0.0011693094857037067}, {"id": 51, "seek": 19798, "start": 207.01999999999998, "end": 213.38, "text": " I actually used it when my first start at my job, used Zope to build a website for my", "tokens": [50816, 286, 767, 1143, 309, 562, 452, 700, 722, 412, 452, 1691, 11, 1143, 1176, 1114, 281, 1322, 257, 3144, 337, 452, 51134], "temperature": 0.0, "avg_logprob": -0.22252129972650764, "compression_ratio": 1.462882096069869, "no_speech_prob": 0.0011693094857037067}, {"id": 52, "seek": 19798, "start": 213.38, "end": 215.94, "text": " group I was working at at the time.", "tokens": [51134, 1594, 286, 390, 1364, 412, 412, 264, 565, 13, 51262], "temperature": 0.0, "avg_logprob": -0.22252129972650764, "compression_ratio": 1.462882096069869, "no_speech_prob": 0.0011693094857037067}, {"id": 53, "seek": 19798, "start": 215.94, "end": 221.57999999999998, "text": " Then I stopped using Python for many years, maybe until six, seven years ago that I discovered", "tokens": [51262, 1396, 286, 5936, 1228, 15329, 337, 867, 924, 11, 1310, 1826, 2309, 11, 3407, 924, 2057, 300, 286, 6941, 51544], "temperature": 0.0, "avg_logprob": -0.22252129972650764, "compression_ratio": 1.462882096069869, "no_speech_prob": 0.0011693094857037067}, {"id": 54, "seek": 22158, "start": 221.58, "end": 227.34, "text": " pandas and was able to finally free myself from Excel workbooks.", "tokens": [50364, 4565, 296, 293, 390, 1075, 281, 2721, 1737, 2059, 490, 19060, 589, 15170, 13, 50652], "temperature": 0.0, "avg_logprob": -0.2935539921627769, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.07157262414693832}, {"id": 55, "seek": 22158, "start": 227.34, "end": 232.9, "text": " Because in my organization, if you're a chemie working in the industry, I do pretty much", "tokens": [50652, 1436, 294, 452, 4475, 11, 498, 291, 434, 257, 4771, 414, 1364, 294, 264, 3518, 11, 286, 360, 1238, 709, 50930], "temperature": 0.0, "avg_logprob": -0.2935539921627769, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.07157262414693832}, {"id": 56, "seek": 22158, "start": 232.9, "end": 237.02, "text": " everything happens in an Excel workbook, which is depressing.", "tokens": [50930, 1203, 2314, 294, 364, 19060, 589, 2939, 11, 597, 307, 36355, 13, 51136], "temperature": 0.0, "avg_logprob": -0.2935539921627769, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.07157262414693832}, {"id": 57, "seek": 22158, "start": 237.02, "end": 244.10000000000002, "text": " Anyways, and pretty around that time, I discovered the IPython notebook, I bounced, to be honest,", "tokens": [51136, 15585, 11, 293, 1238, 926, 300, 565, 11, 286, 6941, 264, 8671, 88, 11943, 21060, 11, 286, 46482, 11, 281, 312, 3245, 11, 51490], "temperature": 0.0, "avg_logprob": -0.2935539921627769, "compression_ratio": 1.4976076555023923, "no_speech_prob": 0.07157262414693832}, {"id": 58, "seek": 24410, "start": 244.1, "end": 252.38, "text": " bounced off the web interface a bit until I found this project Emacs IPython notebook,", "tokens": [50364, 46482, 766, 264, 3670, 9226, 257, 857, 1826, 286, 1352, 341, 1716, 3968, 44937, 8671, 88, 11943, 21060, 11, 50778], "temperature": 0.0, "avg_logprob": -0.23464343422337583, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.530780553817749}, {"id": 59, "seek": 24410, "start": 252.38, "end": 259.3, "text": " and then I kind of took over as maintainer in 2014, 2015, because TKF, he just kind of", "tokens": [50778, 293, 550, 286, 733, 295, 1890, 670, 382, 6909, 260, 294, 8227, 11, 7546, 11, 570, 314, 42, 37, 11, 415, 445, 733, 295, 51124], "temperature": 0.0, "avg_logprob": -0.23464343422337583, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.530780553817749}, {"id": 60, "seek": 24410, "start": 259.3, "end": 262.3, "text": " disappeared.", "tokens": [51124, 13954, 13, 51274], "temperature": 0.0, "avg_logprob": -0.23464343422337583, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.530780553817749}, {"id": 61, "seek": 24410, "start": 262.3, "end": 266.06, "text": " So let's talk about Emacs IPython notebook finally.", "tokens": [51274, 407, 718, 311, 751, 466, 3968, 44937, 8671, 88, 11943, 21060, 2721, 13, 51462], "temperature": 0.0, "avg_logprob": -0.23464343422337583, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.530780553817749}, {"id": 62, "seek": 24410, "start": 266.06, "end": 273.21999999999997, "text": " It is, in my opinion, a full-featured client for the Jupyter notebook, and it's existed", "tokens": [51462, 467, 307, 11, 294, 452, 4800, 11, 257, 1577, 12, 2106, 1503, 67, 6423, 337, 264, 22125, 88, 391, 21060, 11, 293, 309, 311, 13135, 51820], "temperature": 0.0, "avg_logprob": -0.23464343422337583, "compression_ratio": 1.5162790697674418, "no_speech_prob": 0.530780553817749}, {"id": 63, "seek": 27322, "start": 273.22, "end": 274.86, "text": " since roughly 2012.", "tokens": [50364, 1670, 9810, 9125, 13, 50446], "temperature": 0.0, "avg_logprob": -0.20231478864496405, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.017438149079680443}, {"id": 64, "seek": 27322, "start": 274.86, "end": 281.98, "text": " It tries to be a bit like Slime, if you know Emacs a little bit, that's the superior Lisp", "tokens": [50446, 467, 9898, 281, 312, 257, 857, 411, 6187, 1312, 11, 498, 291, 458, 3968, 44937, 257, 707, 857, 11, 300, 311, 264, 13028, 441, 7631, 50802], "temperature": 0.0, "avg_logprob": -0.20231478864496405, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.017438149079680443}, {"id": 65, "seek": 27322, "start": 281.98, "end": 283.94000000000005, "text": " interaction mode for Emacs.", "tokens": [50802, 9285, 4391, 337, 3968, 44937, 13, 50900], "temperature": 0.0, "avg_logprob": -0.20231478864496405, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.017438149079680443}, {"id": 66, "seek": 27322, "start": 283.94000000000005, "end": 291.5, "text": " It's a tool for interacting with common Lisp, allows you to interact with the REPL, interactively", "tokens": [50900, 467, 311, 257, 2290, 337, 18017, 365, 2689, 441, 7631, 11, 4045, 291, 281, 4648, 365, 264, 31511, 43, 11, 4648, 3413, 51278], "temperature": 0.0, "avg_logprob": -0.20231478864496405, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.017438149079680443}, {"id": 67, "seek": 27322, "start": 291.5, "end": 298.46000000000004, "text": " execute code, inspect code, look at debug code, and I try to be like that.", "tokens": [51278, 14483, 3089, 11, 15018, 3089, 11, 574, 412, 24083, 3089, 11, 293, 286, 853, 281, 312, 411, 300, 13, 51626], "temperature": 0.0, "avg_logprob": -0.20231478864496405, "compression_ratio": 1.5196078431372548, "no_speech_prob": 0.017438149079680443}, {"id": 68, "seek": 29846, "start": 298.46, "end": 306.38, "text": " It works on most recent versions of Emacs, and it's written almost completely in ELIS,", "tokens": [50364, 467, 1985, 322, 881, 5162, 9606, 295, 3968, 44937, 11, 293, 309, 311, 3720, 1920, 2584, 294, 14426, 2343, 11, 50760], "temperature": 0.0, "avg_logprob": -0.20548077847095245, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.4763677418231964}, {"id": 69, "seek": 29846, "start": 306.38, "end": 312.58, "text": " with the exception of a few Python functions that kind of glue in the IDE features.", "tokens": [50760, 365, 264, 11183, 295, 257, 1326, 15329, 6828, 300, 733, 295, 8998, 294, 264, 40930, 4122, 13, 51070], "temperature": 0.0, "avg_logprob": -0.20548077847095245, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.4763677418231964}, {"id": 70, "seek": 29846, "start": 312.58, "end": 318.53999999999996, "text": " It has a slew of IDE features, it integrates with the Python debugger, it integrates with", "tokens": [51070, 467, 575, 257, 2426, 86, 295, 40930, 4122, 11, 309, 3572, 1024, 365, 264, 15329, 24083, 1321, 11, 309, 3572, 1024, 365, 51368], "temperature": 0.0, "avg_logprob": -0.20548077847095245, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.4763677418231964}, {"id": 71, "seek": 29846, "start": 318.53999999999996, "end": 325.38, "text": " org mode, I don't know if any of you here know org mode, live and die by org mode, yes,", "tokens": [51368, 14045, 4391, 11, 286, 500, 380, 458, 498, 604, 295, 291, 510, 458, 14045, 4391, 11, 1621, 293, 978, 538, 14045, 4391, 11, 2086, 11, 51710], "temperature": 0.0, "avg_logprob": -0.20548077847095245, "compression_ratio": 1.6338028169014085, "no_speech_prob": 0.4763677418231964}, {"id": 72, "seek": 32538, "start": 325.74, "end": 329.78, "text": " I've tried really hard to make it work reasonably well with org mode, I'll try and demo it a", "tokens": [50382, 286, 600, 3031, 534, 1152, 281, 652, 309, 589, 23551, 731, 365, 14045, 4391, 11, 286, 603, 853, 293, 10723, 309, 257, 50584], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 73, "seek": 32538, "start": 329.78, "end": 331.62, "text": " little bit later.", "tokens": [50584, 707, 857, 1780, 13, 50676], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 74, "seek": 32538, "start": 331.62, "end": 336.3, "text": " Just recently I've made sure it works with non-Python kernels, I really don't know anything", "tokens": [50676, 1449, 3938, 286, 600, 1027, 988, 309, 1985, 365, 2107, 12, 47, 88, 11943, 23434, 1625, 11, 286, 534, 500, 380, 458, 1340, 50910], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 75, "seek": 32538, "start": 336.3, "end": 343.78, "text": " other than Python and ELIS, but I did test it with an R kernel, and it actually kind", "tokens": [50910, 661, 813, 15329, 293, 14426, 2343, 11, 457, 286, 630, 1500, 309, 365, 364, 497, 28256, 11, 293, 309, 767, 733, 51284], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 76, "seek": 32538, "start": 343.78, "end": 345.54, "text": " of worked.", "tokens": [51284, 295, 2732, 13, 51372], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 77, "seek": 32538, "start": 345.54, "end": 349.65999999999997, "text": " And then here's the last one, which is kind of cool, too bad Joel's gone, but we can", "tokens": [51372, 400, 550, 510, 311, 264, 1036, 472, 11, 597, 307, 733, 295, 1627, 11, 886, 1578, 21522, 311, 2780, 11, 457, 321, 393, 51578], "temperature": 0.0, "avg_logprob": -0.1768421693281694, "compression_ratio": 1.5892116182572613, "no_speech_prob": 0.033074893057346344}, {"id": 78, "seek": 34966, "start": 349.70000000000005, "end": 357.18, "text": " connect Python buffers to running kernels and get completion and autodoc and stuff like", "tokens": [50366, 1745, 15329, 9204, 433, 281, 2614, 23434, 1625, 293, 483, 19372, 293, 1476, 378, 905, 293, 1507, 411, 50740], "temperature": 0.0, "avg_logprob": -0.18718081648631762, "compression_ratio": 1.5314009661835748, "no_speech_prob": 0.02368670329451561}, {"id": 79, "seek": 34966, "start": 357.18, "end": 360.94, "text": " that for free, and I have Python buffer.", "tokens": [50740, 300, 337, 1737, 11, 293, 286, 362, 15329, 21762, 13, 50928], "temperature": 0.0, "avg_logprob": -0.18718081648631762, "compression_ratio": 1.5314009661835748, "no_speech_prob": 0.02368670329451561}, {"id": 80, "seek": 34966, "start": 360.94, "end": 368.02000000000004, "text": " So Emacs, I don't know how many of you here are familiar with Emacs, that's probably why", "tokens": [50928, 407, 3968, 44937, 11, 286, 500, 380, 458, 577, 867, 295, 291, 510, 366, 4963, 365, 3968, 44937, 11, 300, 311, 1391, 983, 51282], "temperature": 0.0, "avg_logprob": -0.18718081648631762, "compression_ratio": 1.5314009661835748, "no_speech_prob": 0.02368670329451561}, {"id": 81, "seek": 34966, "start": 368.02000000000004, "end": 370.22, "text": " you're here.", "tokens": [51282, 291, 434, 510, 13, 51392], "temperature": 0.0, "avg_logprob": -0.18718081648631762, "compression_ratio": 1.5314009661835748, "no_speech_prob": 0.02368670329451561}, {"id": 82, "seek": 34966, "start": 370.22, "end": 379.62, "text": " So here's my one obligatory XKCD, so yeah, if you know Emacs, whatever you want to do,", "tokens": [51392, 407, 510, 311, 452, 472, 9270, 4745, 1783, 42, 16508, 11, 370, 1338, 11, 498, 291, 458, 3968, 44937, 11, 2035, 291, 528, 281, 360, 11, 51862], "temperature": 0.0, "avg_logprob": -0.18718081648631762, "compression_ratio": 1.5314009661835748, "no_speech_prob": 0.02368670329451561}, {"id": 83, "seek": 37962, "start": 379.62, "end": 388.02, "text": " there's probably an Emacs command that does it for you, and I don't want to be snide,", "tokens": [50364, 456, 311, 1391, 364, 3968, 44937, 5622, 300, 775, 309, 337, 291, 11, 293, 286, 500, 380, 528, 281, 312, 2406, 482, 11, 50784], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 84, "seek": 37962, "start": 388.02, "end": 392.5, "text": " but as I was watching a lot of these presentations to myself, I was thinking, yeah, Emacs, I", "tokens": [50784, 457, 382, 286, 390, 1976, 257, 688, 295, 613, 18964, 281, 2059, 11, 286, 390, 1953, 11, 1338, 11, 3968, 44937, 11, 286, 51008], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 85, "seek": 37962, "start": 392.5, "end": 397.5, "text": " think Emacs can do that, especially watching the JupyterLab presentation.", "tokens": [51008, 519, 3968, 44937, 393, 360, 300, 11, 2318, 1976, 264, 22125, 88, 391, 37880, 5860, 13, 51258], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 86, "seek": 37962, "start": 397.5, "end": 401.98, "text": " Nothing against those guys, I think it's great that they're putting all these features together,", "tokens": [51258, 6693, 1970, 729, 1074, 11, 286, 519, 309, 311, 869, 300, 436, 434, 3372, 439, 613, 4122, 1214, 11, 51482], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 87, "seek": 37962, "start": 401.98, "end": 408.22, "text": " but a lot of the stuff Emacs is, Emacs, I'm Python notebooks had for like the past four", "tokens": [51482, 457, 257, 688, 295, 264, 1507, 3968, 44937, 307, 11, 3968, 44937, 11, 286, 478, 15329, 43782, 632, 337, 411, 264, 1791, 1451, 51794], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 88, "seek": 37962, "start": 408.22, "end": 409.22, "text": " or five years.", "tokens": [51794, 420, 1732, 924, 13, 51844], "temperature": 0.0, "avg_logprob": -0.1939418667652568, "compression_ratio": 1.7318007662835249, "no_speech_prob": 0.0040692915208637714}, {"id": 89, "seek": 40922, "start": 409.42, "end": 410.74, "text": " Why do I use Emacs?", "tokens": [50374, 1545, 360, 286, 764, 3968, 44937, 30, 50440], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 90, "seek": 40922, "start": 410.74, "end": 415.3, "text": " Originally this was why Emacs, but that felt a little presumptuous, I'm not going to tell", "tokens": [50440, 28696, 341, 390, 983, 3968, 44937, 11, 457, 300, 2762, 257, 707, 18028, 662, 12549, 11, 286, 478, 406, 516, 281, 980, 50668], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 91, "seek": 40922, "start": 415.3, "end": 422.46000000000004, "text": " anybody that they have to use Emacs, it's kind of an acquired taste, either you bounce", "tokens": [50668, 4472, 300, 436, 362, 281, 764, 3968, 44937, 11, 309, 311, 733, 295, 364, 17554, 3939, 11, 2139, 291, 15894, 51026], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 92, "seek": 40922, "start": 422.46000000000004, "end": 428.34000000000003, "text": " off of it real hard or it just transforms your life and becomes everything.", "tokens": [51026, 766, 295, 309, 957, 1152, 420, 309, 445, 35592, 428, 993, 293, 3643, 1203, 13, 51320], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 93, "seek": 40922, "start": 428.34000000000003, "end": 433.18, "text": " I was looking for good images that represent Emacs, I found this and I thought it was pretty", "tokens": [51320, 286, 390, 1237, 337, 665, 5267, 300, 2906, 3968, 44937, 11, 286, 1352, 341, 293, 286, 1194, 309, 390, 1238, 51562], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 94, "seek": 40922, "start": 433.18, "end": 437.62, "text": " funny, this guy is running a Tetris game in a frame.", "tokens": [51562, 4074, 11, 341, 2146, 307, 2614, 257, 31580, 5714, 1216, 294, 257, 3920, 13, 51784], "temperature": 0.0, "avg_logprob": -0.23116813387189591, "compression_ratio": 1.5833333333333333, "no_speech_prob": 0.02594299614429474}, {"id": 95, "seek": 43762, "start": 438.62, "end": 441.62, "text": " I don't know how many editors can do that.", "tokens": [50414, 286, 500, 380, 458, 577, 867, 31446, 393, 360, 300, 13, 50564], "temperature": 0.0, "avg_logprob": -0.2314244508743286, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.00029594096122309566}, {"id": 96, "seek": 43762, "start": 443.62, "end": 445.62, "text": " Who would want to write that in an editor?", "tokens": [50664, 2102, 576, 528, 281, 2464, 300, 294, 364, 9839, 30, 50764], "temperature": 0.0, "avg_logprob": -0.2314244508743286, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.00029594096122309566}, {"id": 97, "seek": 43762, "start": 445.62, "end": 452.82, "text": " But anyways, so in my mind, when I think of Emacs and why I use it, this first thing", "tokens": [50764, 583, 13448, 11, 370, 294, 452, 1575, 11, 562, 286, 519, 295, 3968, 44937, 293, 983, 286, 764, 309, 11, 341, 700, 551, 51124], "temperature": 0.0, "avg_logprob": -0.2314244508743286, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.00029594096122309566}, {"id": 98, "seek": 43762, "start": 452.82, "end": 458.62, "text": " I thought about was a list machine, I don't know if any of you know about list machines.", "tokens": [51124, 286, 1194, 466, 390, 257, 1329, 3479, 11, 286, 500, 380, 458, 498, 604, 295, 291, 458, 466, 1329, 8379, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2314244508743286, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.00029594096122309566}, {"id": 99, "seek": 43762, "start": 458.62, "end": 464.74, "text": " Unfortunately I was too young to really work with any list machines, and I'm a little bit", "tokens": [51414, 8590, 286, 390, 886, 2037, 281, 534, 589, 365, 604, 1329, 8379, 11, 293, 286, 478, 257, 707, 857, 51720], "temperature": 0.0, "avg_logprob": -0.2314244508743286, "compression_ratio": 1.6462264150943395, "no_speech_prob": 0.00029594096122309566}, {"id": 100, "seek": 46474, "start": 464.74, "end": 469.26, "text": " too old to be part of this data science wave, so I'm kind of stuck in the middle.", "tokens": [50364, 886, 1331, 281, 312, 644, 295, 341, 1412, 3497, 5772, 11, 370, 286, 478, 733, 295, 5541, 294, 264, 2808, 13, 50590], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 101, "seek": 46474, "start": 469.26, "end": 473.94, "text": " But anyways, Emacs is kind of like the scrappier cousin from the wrong side of town when you", "tokens": [50590, 583, 13448, 11, 3968, 44937, 307, 733, 295, 411, 264, 13943, 427, 811, 16207, 490, 264, 2085, 1252, 295, 3954, 562, 291, 50824], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 102, "seek": 46474, "start": 473.94, "end": 476.62, "text": " think of a list machine.", "tokens": [50824, 519, 295, 257, 1329, 3479, 13, 50958], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 103, "seek": 46474, "start": 476.62, "end": 481.78000000000003, "text": " I think it's telling that Emacs has endured so long, it's been around 40 years and people", "tokens": [50958, 286, 519, 309, 311, 3585, 300, 3968, 44937, 575, 39017, 370, 938, 11, 309, 311, 668, 926, 3356, 924, 293, 561, 51216], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 104, "seek": 46474, "start": 481.78000000000003, "end": 485.22, "text": " are still using it obviously.", "tokens": [51216, 366, 920, 1228, 309, 2745, 13, 51388], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 105, "seek": 46474, "start": 485.22, "end": 489.06, "text": " I was reading about a week ago, there's a couple of really good blog posts by this guy", "tokens": [51388, 286, 390, 3760, 466, 257, 1243, 2057, 11, 456, 311, 257, 1916, 295, 534, 665, 6968, 12300, 538, 341, 2146, 51580], "temperature": 0.0, "avg_logprob": -0.1440243894403631, "compression_ratio": 1.5859375, "no_speech_prob": 0.004330915864557028}, {"id": 106, "seek": 48906, "start": 489.06, "end": 496.58, "text": " Josh Stella that kind of explained why he likes Emacs so much, and I felt really resonated", "tokens": [50364, 9785, 45073, 300, 733, 295, 8825, 983, 415, 5902, 3968, 44937, 370, 709, 11, 293, 286, 2762, 534, 47957, 50740], "temperature": 0.0, "avg_logprob": -0.17760260899861655, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.09529522061347961}, {"id": 107, "seek": 48906, "start": 496.58, "end": 502.78000000000003, "text": " with me, and I think a couple of points is it's a tool that you control completely.", "tokens": [50740, 365, 385, 11, 293, 286, 519, 257, 1916, 295, 2793, 307, 309, 311, 257, 2290, 300, 291, 1969, 2584, 13, 51050], "temperature": 0.0, "avg_logprob": -0.17760260899861655, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.09529522061347961}, {"id": 108, "seek": 48906, "start": 502.78000000000003, "end": 508.02, "text": " It's your tool, it allows you to focus completely, there's no distractions when you're working", "tokens": [51050, 467, 311, 428, 2290, 11, 309, 4045, 291, 281, 1879, 2584, 11, 456, 311, 572, 37887, 562, 291, 434, 1364, 51312], "temperature": 0.0, "avg_logprob": -0.17760260899861655, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.09529522061347961}, {"id": 109, "seek": 48906, "start": 508.02, "end": 515.74, "text": " with Emacs, and the Emacs IPython notebook tool really buys into that philosophy I think,", "tokens": [51312, 365, 3968, 44937, 11, 293, 264, 3968, 44937, 8671, 88, 11943, 21060, 2290, 534, 28153, 666, 300, 10675, 286, 519, 11, 51698], "temperature": 0.0, "avg_logprob": -0.17760260899861655, "compression_ratio": 1.6026785714285714, "no_speech_prob": 0.09529522061347961}, {"id": 110, "seek": 51574, "start": 515.74, "end": 520.66, "text": " and that's why I like using it so much in my work.", "tokens": [50364, 293, 300, 311, 983, 286, 411, 1228, 309, 370, 709, 294, 452, 589, 13, 50610], "temperature": 0.0, "avg_logprob": -0.18952470559340256, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0446661114692688}, {"id": 111, "seek": 51574, "start": 520.66, "end": 529.1, "text": " I didn't really want to get into editor wars, I know that's a very popular pastime activity,", "tokens": [50610, 286, 994, 380, 534, 528, 281, 483, 666, 9839, 13718, 11, 286, 458, 300, 311, 257, 588, 3743, 1791, 1312, 5191, 11, 51032], "temperature": 0.0, "avg_logprob": -0.18952470559340256, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0446661114692688}, {"id": 112, "seek": 51574, "start": 529.1, "end": 534.46, "text": " but I think it's great that there's alternate clients out there, I think it's great that", "tokens": [51032, 457, 286, 519, 309, 311, 869, 300, 456, 311, 18873, 6982, 484, 456, 11, 286, 519, 309, 311, 869, 300, 51300], "temperature": 0.0, "avg_logprob": -0.18952470559340256, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0446661114692688}, {"id": 113, "seek": 51574, "start": 534.46, "end": 537.86, "text": " there's Uperilab, I think it's great that there's Interact.", "tokens": [51300, 456, 311, 624, 610, 388, 455, 11, 286, 519, 309, 311, 869, 300, 456, 311, 5751, 578, 13, 51470], "temperature": 0.0, "avg_logprob": -0.18952470559340256, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0446661114692688}, {"id": 114, "seek": 51574, "start": 537.86, "end": 545.0600000000001, "text": " I think it's a sign of a healthy community that you have multiple tools out there and", "tokens": [51470, 286, 519, 309, 311, 257, 1465, 295, 257, 4627, 1768, 300, 291, 362, 3866, 3873, 484, 456, 293, 51830], "temperature": 0.0, "avg_logprob": -0.18952470559340256, "compression_ratio": 1.826086956521739, "no_speech_prob": 0.0446661114692688}, {"id": 115, "seek": 54506, "start": 545.06, "end": 549.02, "text": " they can all learn from each other.", "tokens": [50364, 436, 393, 439, 1466, 490, 1184, 661, 13, 50562], "temperature": 0.0, "avg_logprob": -0.30384830474853514, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.05663125589489937}, {"id": 116, "seek": 54506, "start": 549.02, "end": 552.5, "text": " Let's do a little bit of history of the line.", "tokens": [50562, 961, 311, 360, 257, 707, 857, 295, 2503, 295, 264, 1622, 13, 50736], "temperature": 0.0, "avg_logprob": -0.30384830474853514, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.05663125589489937}, {"id": 117, "seek": 54506, "start": 552.5, "end": 567.42, "text": " There was supposed to be a graph in here, but it's gone.", "tokens": [50736, 821, 390, 3442, 281, 312, 257, 4295, 294, 510, 11, 457, 309, 311, 2780, 13, 51482], "temperature": 0.0, "avg_logprob": -0.30384830474853514, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.05663125589489937}, {"id": 118, "seek": 54506, "start": 567.42, "end": 568.42, "text": " Let's do this.", "tokens": [51482, 961, 311, 360, 341, 13, 51532], "temperature": 0.0, "avg_logprob": -0.30384830474853514, "compression_ratio": 1.3076923076923077, "no_speech_prob": 0.05663125589489937}, {"id": 119, "seek": 56842, "start": 568.5799999999999, "end": 571.02, "text": " I lost myself here.", "tokens": [50372, 286, 2731, 2059, 510, 13, 50494], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 120, "seek": 56842, "start": 571.02, "end": 581.54, "text": " I worked so hard in Microsoft PowerPoint to build this graph, I have to show it to you,", "tokens": [50494, 286, 2732, 370, 1152, 294, 8116, 25584, 281, 1322, 341, 4295, 11, 286, 362, 281, 855, 309, 281, 291, 11, 51020], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 121, "seek": 56842, "start": 581.54, "end": 582.54, "text": " but it doesn't want to show.", "tokens": [51020, 457, 309, 1177, 380, 528, 281, 855, 13, 51070], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 122, "seek": 56842, "start": 582.54, "end": 583.54, "text": " There we go.", "tokens": [51070, 821, 321, 352, 13, 51120], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 123, "seek": 56842, "start": 583.54, "end": 589.2199999999999, "text": " Okay, 2012 is the first commit to the Emacs IPython notebook.", "tokens": [51120, 1033, 11, 9125, 307, 264, 700, 5599, 281, 264, 3968, 44937, 8671, 88, 11943, 21060, 13, 51404], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 124, "seek": 56842, "start": 589.2199999999999, "end": 596.86, "text": " Around March of 2014, that was the last commit by TKF.", "tokens": [51404, 17633, 6129, 295, 8227, 11, 300, 390, 264, 1036, 5599, 538, 314, 42, 37, 13, 51786], "temperature": 0.0, "avg_logprob": -0.22875167102348515, "compression_ratio": 1.378238341968912, "no_speech_prob": 0.014500253833830357}, {"id": 125, "seek": 59686, "start": 596.86, "end": 600.34, "text": " About a month later, I forked it.", "tokens": [50364, 7769, 257, 1618, 1780, 11, 286, 17716, 292, 309, 13, 50538], "temperature": 0.0, "avg_logprob": -0.18278636932373046, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.11582102626562119}, {"id": 126, "seek": 59686, "start": 600.34, "end": 604.74, "text": " This was about the time when IPython was going from version 1.0 to 2.0.", "tokens": [50538, 639, 390, 466, 264, 565, 562, 8671, 88, 11943, 390, 516, 490, 3037, 502, 13, 15, 281, 568, 13, 15, 13, 50758], "temperature": 0.0, "avg_logprob": -0.18278636932373046, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.11582102626562119}, {"id": 127, "seek": 59686, "start": 604.74, "end": 614.34, "text": " There were a lot of changes to the interface, to the communication protocol, and IPython", "tokens": [50758, 821, 645, 257, 688, 295, 2962, 281, 264, 9226, 11, 281, 264, 6101, 10336, 11, 293, 8671, 88, 11943, 51238], "temperature": 0.0, "avg_logprob": -0.18278636932373046, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.11582102626562119}, {"id": 128, "seek": 59686, "start": 614.34, "end": 621.02, "text": " Emacs I'm just wasn't keeping up, so I think TKF got burned out by all those changes and", "tokens": [51238, 3968, 44937, 286, 478, 445, 2067, 380, 5145, 493, 11, 370, 286, 519, 314, 42, 37, 658, 13490, 484, 538, 439, 729, 2962, 293, 51572], "temperature": 0.0, "avg_logprob": -0.18278636932373046, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.11582102626562119}, {"id": 129, "seek": 59686, "start": 621.02, "end": 623.0600000000001, "text": " just stopped committing.", "tokens": [51572, 445, 5936, 26659, 13, 51674], "temperature": 0.0, "avg_logprob": -0.18278636932373046, "compression_ratio": 1.4597156398104265, "no_speech_prob": 0.11582102626562119}, {"id": 130, "seek": 62306, "start": 623.06, "end": 628.54, "text": " I just took over and managed to get it working on 2.0 and I've been running with it ever", "tokens": [50364, 286, 445, 1890, 670, 293, 6453, 281, 483, 309, 1364, 322, 568, 13, 15, 293, 286, 600, 668, 2614, 365, 309, 1562, 50638], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 131, "seek": 62306, "start": 628.54, "end": 630.9799999999999, "text": " since.", "tokens": [50638, 1670, 13, 50760], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 132, "seek": 62306, "start": 630.9799999999999, "end": 634.38, "text": " On April 2014, there was a version 0.3.", "tokens": [50760, 1282, 6929, 8227, 11, 456, 390, 257, 3037, 1958, 13, 18, 13, 50930], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 133, "seek": 62306, "start": 634.38, "end": 638.6999999999999, "text": " I'm now at what, version 14.1.", "tokens": [50930, 286, 478, 586, 412, 437, 11, 3037, 3499, 13, 16, 13, 51146], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 134, "seek": 62306, "start": 638.6999999999999, "end": 640.5799999999999, "text": " It works with Jupyter.", "tokens": [51146, 467, 1985, 365, 22125, 88, 391, 13, 51240], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 135, "seek": 62306, "start": 640.5799999999999, "end": 647.0999999999999, "text": " There's over 650 stars on GitHub and over 50,000 downloads from Meltha, so it's kept", "tokens": [51240, 821, 311, 670, 38566, 6105, 322, 23331, 293, 670, 2625, 11, 1360, 36553, 490, 7375, 13571, 11, 370, 309, 311, 4305, 51566], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 136, "seek": 62306, "start": 647.0999999999999, "end": 651.54, "text": " up with the times for the most part and I'm really happy with it.", "tokens": [51566, 493, 365, 264, 1413, 337, 264, 881, 644, 293, 286, 478, 534, 2055, 365, 309, 13, 51788], "temperature": 0.0, "avg_logprob": -0.20164266924991786, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.1110624447464943}, {"id": 137, "seek": 65154, "start": 651.54, "end": 654.54, "text": " Just going through that a little bit.", "tokens": [50364, 1449, 516, 807, 300, 257, 707, 857, 13, 50514], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 138, "seek": 65154, "start": 654.54, "end": 659.6999999999999, "text": " Yeah, 1,795 commits by this one guy.", "tokens": [50514, 865, 11, 502, 11, 22, 15718, 48311, 538, 341, 472, 2146, 13, 50772], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 139, "seek": 65154, "start": 659.6999999999999, "end": 666.3399999999999, "text": " I think we're at 2,500 commits, so that means 800 commits are mine in the space of four", "tokens": [50772, 286, 519, 321, 434, 412, 568, 11, 7526, 48311, 11, 370, 300, 1355, 13083, 48311, 366, 3892, 294, 264, 1901, 295, 1451, 51104], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 140, "seek": 65154, "start": 666.3399999999999, "end": 671.06, "text": " years, so I'm no master programmer.", "tokens": [51104, 924, 11, 370, 286, 478, 572, 4505, 32116, 13, 51340], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 141, "seek": 65154, "start": 671.06, "end": 674.66, "text": " I'm just a guy.", "tokens": [51340, 286, 478, 445, 257, 2146, 13, 51520], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 142, "seek": 65154, "start": 674.66, "end": 681.4599999999999, "text": " I will say though that going from IPython 1.0 to today's Jupyter, there was rough", "tokens": [51520, 286, 486, 584, 1673, 300, 516, 490, 8671, 88, 11943, 502, 13, 15, 281, 965, 311, 22125, 88, 391, 11, 456, 390, 5903, 51860], "temperature": 0.0, "avg_logprob": -0.21697164089121718, "compression_ratio": 1.48, "no_speech_prob": 0.19661270081996918}, {"id": 143, "seek": 68146, "start": 681.46, "end": 683.74, "text": " sailing for a while.", "tokens": [50364, 27452, 337, 257, 1339, 13, 50478], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 144, "seek": 68146, "start": 683.74, "end": 685.74, "text": " There were a number of real challenges I had to get through.", "tokens": [50478, 821, 645, 257, 1230, 295, 957, 4759, 286, 632, 281, 483, 807, 13, 50578], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 145, "seek": 68146, "start": 685.74, "end": 688.86, "text": " One, there were changes to the contents API.", "tokens": [50578, 1485, 11, 456, 645, 2962, 281, 264, 15768, 9362, 13, 50734], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 146, "seek": 68146, "start": 688.86, "end": 694.94, "text": " That's the file view, browser view that you'll see.", "tokens": [50734, 663, 311, 264, 3991, 1910, 11, 11185, 1910, 300, 291, 603, 536, 13, 51038], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 147, "seek": 68146, "start": 694.94, "end": 695.94, "text": " There are big changes there.", "tokens": [51038, 821, 366, 955, 2962, 456, 13, 51088], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 148, "seek": 68146, "start": 695.94, "end": 701.86, "text": " There are some changes in the communication protocol, changes in the security model.", "tokens": [51088, 821, 366, 512, 2962, 294, 264, 6101, 10336, 11, 2962, 294, 264, 3825, 2316, 13, 51384], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 149, "seek": 68146, "start": 701.86, "end": 706.22, "text": " That was probably the most painful for me to try and work through.", "tokens": [51384, 663, 390, 1391, 264, 881, 11697, 337, 385, 281, 853, 293, 589, 807, 13, 51602], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 150, "seek": 68146, "start": 706.22, "end": 710.74, "text": " Then there are some changes to the notebook format.", "tokens": [51602, 1396, 456, 366, 512, 2962, 281, 264, 21060, 7877, 13, 51828], "temperature": 0.0, "avg_logprob": -0.21291769467867339, "compression_ratio": 1.7792207792207793, "no_speech_prob": 0.007118981797248125}, {"id": 151, "seek": 71074, "start": 710.74, "end": 715.62, "text": " All of those work through, but now everything seems to be really stable on the Jupyter side.", "tokens": [50364, 1057, 295, 729, 589, 807, 11, 457, 586, 1203, 2544, 281, 312, 534, 8351, 322, 264, 22125, 88, 391, 1252, 13, 50608], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 152, "seek": 71074, "start": 715.62, "end": 717.5, "text": " I hope it stays that way.", "tokens": [50608, 286, 1454, 309, 10834, 300, 636, 13, 50702], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 153, "seek": 71074, "start": 717.5, "end": 720.38, "text": " Honestly, they've been really good about that.", "tokens": [50702, 12348, 11, 436, 600, 668, 534, 665, 466, 300, 13, 50846], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 154, "seek": 71074, "start": 720.38, "end": 725.38, "text": " I may complain about things, but they've been really good about keeping things stable.", "tokens": [50846, 286, 815, 11024, 466, 721, 11, 457, 436, 600, 668, 534, 665, 466, 5145, 721, 8351, 13, 51096], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 155, "seek": 71074, "start": 725.38, "end": 730.78, "text": " It made me so happy when they mentioned in the last presentation that they made no backwards", "tokens": [51096, 467, 1027, 385, 370, 2055, 562, 436, 2835, 294, 264, 1036, 5860, 300, 436, 1027, 572, 12204, 51366], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 156, "seek": 71074, "start": 730.78, "end": 737.66, "text": " incompatible changes to the notebook format because that code is really horrible.", "tokens": [51366, 40393, 267, 964, 2962, 281, 264, 21060, 7877, 570, 300, 3089, 307, 534, 9263, 13, 51710], "temperature": 0.0, "avg_logprob": -0.15693288746446665, "compression_ratio": 1.75, "no_speech_prob": 0.01590213179588318}, {"id": 157, "seek": 73766, "start": 737.86, "end": 743.98, "text": " Probably the worst piece of code I've written as a programmer.", "tokens": [50374, 9210, 264, 5855, 2522, 295, 3089, 286, 600, 3720, 382, 257, 32116, 13, 50680], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 158, "seek": 73766, "start": 743.98, "end": 745.74, "text": " Why these things were hard?", "tokens": [50680, 1545, 613, 721, 645, 1152, 30, 50768], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 159, "seek": 73766, "start": 745.74, "end": 750.14, "text": " Because I get a little shy and embarrassed outside of Emacs.", "tokens": [50768, 1436, 286, 483, 257, 707, 12685, 293, 16843, 2380, 295, 3968, 44937, 13, 50988], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 160, "seek": 73766, "start": 750.14, "end": 756.26, "text": " I'm kind of old, so I don't understand all these newfangled web technologies.", "tokens": [50988, 286, 478, 733, 295, 1331, 11, 370, 286, 500, 380, 1223, 439, 613, 777, 19134, 1493, 3670, 7943, 13, 51294], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 161, "seek": 73766, "start": 756.26, "end": 760.86, "text": " I break out in highs whenever I try to read JavaScript.", "tokens": [51294, 286, 1821, 484, 294, 29687, 5699, 286, 853, 281, 1401, 15778, 13, 51524], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 162, "seek": 73766, "start": 760.86, "end": 765.4599999999999, "text": " It's been kind of hard to try and understand that, but the documentation from Jupyter has", "tokens": [51524, 467, 311, 668, 733, 295, 1152, 281, 853, 293, 1223, 300, 11, 457, 264, 14333, 490, 22125, 88, 391, 575, 51754], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 163, "seek": 73766, "start": 765.4599999999999, "end": 766.9599999999999, "text": " been really good.", "tokens": [51754, 668, 534, 665, 13, 51829], "temperature": 0.0, "avg_logprob": -0.18437633699583775, "compression_ratio": 1.5291828793774318, "no_speech_prob": 0.01065005548298359}, {"id": 164, "seek": 76696, "start": 766.96, "end": 769.96, "text": " The people on the distribution have been really helpful.", "tokens": [50364, 440, 561, 322, 264, 7316, 362, 668, 534, 4961, 13, 50514], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 165, "seek": 76696, "start": 769.96, "end": 775.24, "text": " Mattias, Brian, those guys have been really helpful and patient with me as I come up with", "tokens": [50514, 7397, 4609, 11, 10765, 11, 729, 1074, 362, 668, 534, 4961, 293, 4537, 365, 385, 382, 286, 808, 493, 365, 50778], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 166, "seek": 76696, "start": 775.24, "end": 777.12, "text": " the occasional question.", "tokens": [50778, 264, 31644, 1168, 13, 50872], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 167, "seek": 76696, "start": 777.12, "end": 782.64, "text": " Also, when I'm trying to support users, this seems to be the most common issue when people", "tokens": [50872, 2743, 11, 562, 286, 478, 1382, 281, 1406, 5022, 11, 341, 2544, 281, 312, 264, 881, 2689, 2734, 562, 561, 51148], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 168, "seek": 76696, "start": 782.64, "end": 789.6800000000001, "text": " post a GitHub is I can't connect to a notebook or the kernel is not running.", "tokens": [51148, 2183, 257, 23331, 307, 286, 393, 380, 1745, 281, 257, 21060, 420, 264, 28256, 307, 406, 2614, 13, 51500], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 169, "seek": 76696, "start": 789.6800000000001, "end": 795.72, "text": " Those are really hard because I have to be able to reproduce the problem.", "tokens": [51500, 3950, 366, 534, 1152, 570, 286, 362, 281, 312, 1075, 281, 29501, 264, 1154, 13, 51802], "temperature": 0.0, "avg_logprob": -0.2039519772671237, "compression_ratio": 1.6653225806451613, "no_speech_prob": 0.0005882468540221453}, {"id": 170, "seek": 79572, "start": 795.76, "end": 802.84, "text": " Emacs greatest disadvantage is maybe its greatest disadvantage is that it's so configurable.", "tokens": [50366, 3968, 44937, 6636, 24292, 307, 1310, 1080, 6636, 24292, 307, 300, 309, 311, 370, 22192, 712, 13, 50720], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 171, "seek": 79572, "start": 802.84, "end": 808.24, "text": " Usually it turns out the issue is with the way that they've configured their installation.", "tokens": [50720, 11419, 309, 4523, 484, 264, 2734, 307, 365, 264, 636, 300, 436, 600, 30538, 641, 13260, 13, 50990], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 172, "seek": 79572, "start": 808.24, "end": 812.0, "text": " It's just me trying to work through what that is.", "tokens": [50990, 467, 311, 445, 385, 1382, 281, 589, 807, 437, 300, 307, 13, 51178], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 173, "seek": 79572, "start": 812.0, "end": 813.8000000000001, "text": " Usually there's nothing I can do to bulletproof it.", "tokens": [51178, 11419, 456, 311, 1825, 286, 393, 360, 281, 11632, 15690, 309, 13, 51268], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 174, "seek": 79572, "start": 813.8000000000001, "end": 819.0, "text": " It's just change your configuration.", "tokens": [51268, 467, 311, 445, 1319, 428, 11694, 13, 51528], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 175, "seek": 79572, "start": 819.0, "end": 820.0, "text": " Those were the challenges.", "tokens": [51528, 3950, 645, 264, 4759, 13, 51578], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 176, "seek": 79572, "start": 820.0, "end": 822.84, "text": " What have I loved about this project?", "tokens": [51578, 708, 362, 286, 4333, 466, 341, 1716, 30, 51720], "temperature": 0.0, "avg_logprob": -0.304462879262072, "compression_ratio": 1.7354260089686098, "no_speech_prob": 0.004903793800622225}, {"id": 177, "seek": 82284, "start": 823.6, "end": 828.44, "text": " It's a short list, but really the joys have greatly outweighed the challenges because,", "tokens": [50402, 467, 311, 257, 2099, 1329, 11, 457, 534, 264, 1488, 749, 362, 14147, 484, 826, 910, 292, 264, 4759, 570, 11, 50644], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 178, "seek": 82284, "start": 828.44, "end": 831.08, "text": " in part, the challenges have been the joy.", "tokens": [50644, 294, 644, 11, 264, 4759, 362, 668, 264, 6258, 13, 50776], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 179, "seek": 82284, "start": 831.08, "end": 835.9200000000001, "text": " It's quite a rush when you have this really difficult problem and you find a way to fix", "tokens": [50776, 467, 311, 1596, 257, 9300, 562, 291, 362, 341, 534, 2252, 1154, 293, 291, 915, 257, 636, 281, 3191, 51018], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 180, "seek": 82284, "start": 835.9200000000001, "end": 836.9200000000001, "text": " it.", "tokens": [51018, 309, 13, 51068], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 181, "seek": 82284, "start": 836.9200000000001, "end": 839.36, "text": " That keeps me going.", "tokens": [51068, 663, 5965, 385, 516, 13, 51190], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 182, "seek": 82284, "start": 839.36, "end": 842.0400000000001, "text": " There are people out there that use it.", "tokens": [51190, 821, 366, 561, 484, 456, 300, 764, 309, 13, 51324], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 183, "seek": 82284, "start": 842.0400000000001, "end": 845.64, "text": " There are people in professional organizations that are using Emacs and the Emacs I Python", "tokens": [51324, 821, 366, 561, 294, 4843, 6150, 300, 366, 1228, 3968, 44937, 293, 264, 3968, 44937, 286, 15329, 51504], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 184, "seek": 82284, "start": 845.64, "end": 848.76, "text": " notebook, which is just great.", "tokens": [51504, 21060, 11, 597, 307, 445, 869, 13, 51660], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 185, "seek": 82284, "start": 848.76, "end": 849.76, "text": " I never expected that.", "tokens": [51660, 286, 1128, 5176, 300, 13, 51710], "temperature": 0.0, "avg_logprob": -0.18306131777556045, "compression_ratio": 1.6745098039215687, "no_speech_prob": 0.004467309452593327}, {"id": 186, "seek": 84976, "start": 849.88, "end": 854.36, "text": " I use it for me mostly, but that other people use it is great.", "tokens": [50370, 286, 764, 309, 337, 385, 5240, 11, 457, 300, 661, 561, 764, 309, 307, 869, 13, 50594], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 187, "seek": 84976, "start": 854.36, "end": 858.68, "text": " The community, the people on GitHub are really nice.", "tokens": [50594, 440, 1768, 11, 264, 561, 322, 23331, 366, 534, 1481, 13, 50810], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 188, "seek": 84976, "start": 858.68, "end": 860.16, "text": " They're really supportive.", "tokens": [50810, 814, 434, 534, 14435, 13, 50884], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 189, "seek": 84976, "start": 860.16, "end": 863.52, "text": " Finally, I like to program in Lisp.", "tokens": [50884, 6288, 11, 286, 411, 281, 1461, 294, 441, 7631, 13, 51052], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 190, "seek": 84976, "start": 863.52, "end": 868.72, "text": " I get to do that and do something that's useful for people at the end of the day.", "tokens": [51052, 286, 483, 281, 360, 300, 293, 360, 746, 300, 311, 4420, 337, 561, 412, 264, 917, 295, 264, 786, 13, 51312], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 191, "seek": 84976, "start": 868.72, "end": 871.6, "text": " It doesn't get better than that.", "tokens": [51312, 467, 1177, 380, 483, 1101, 813, 300, 13, 51456], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 192, "seek": 84976, "start": 871.6, "end": 875.16, "text": " Let's dive a little bit into Ion's features.", "tokens": [51456, 961, 311, 9192, 257, 707, 857, 666, 286, 266, 311, 4122, 13, 51634], "temperature": 0.0, "avg_logprob": -0.26691995348249165, "compression_ratio": 1.5868544600938967, "no_speech_prob": 0.003074445528909564}, {"id": 193, "seek": 87516, "start": 876.16, "end": 877.16, "text": " I don't know.", "tokens": [50414, 286, 500, 380, 458, 13, 50464], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 194, "seek": 87516, "start": 877.16, "end": 881.16, "text": " How many of you here have actually used the Emacs I Python notebook?", "tokens": [50464, 1012, 867, 295, 291, 510, 362, 767, 1143, 264, 3968, 44937, 286, 15329, 21060, 30, 50664], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 195, "seek": 87516, "start": 881.16, "end": 883.8399999999999, "text": " Okay.", "tokens": [50664, 1033, 13, 50798], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 196, "seek": 87516, "start": 883.8399999999999, "end": 888.36, "text": " Probably back in the I Python pre-1.0.", "tokens": [50798, 9210, 646, 294, 264, 286, 15329, 659, 12, 16, 13, 15, 13, 51024], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 197, "seek": 87516, "start": 888.36, "end": 894.64, "text": " Yeah, I got the messages from people on the Jupyter list that they stopped using it because", "tokens": [51024, 865, 11, 286, 658, 264, 7897, 490, 561, 322, 264, 22125, 88, 391, 1329, 300, 436, 5936, 1228, 309, 570, 51338], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 198, "seek": 87516, "start": 894.64, "end": 896.8, "text": " it stopped working.", "tokens": [51338, 309, 5936, 1364, 13, 51446], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 199, "seek": 87516, "start": 896.8, "end": 901.56, "text": " When I forked it, definitely a lot of people that were using it weren't aware of the fork,", "tokens": [51446, 1133, 286, 17716, 292, 309, 11, 2138, 257, 688, 295, 561, 300, 645, 1228, 309, 4999, 380, 3650, 295, 264, 17716, 11, 51684], "temperature": 0.0, "avg_logprob": -0.2888493537902832, "compression_ratio": 1.5068493150684932, "no_speech_prob": 0.0018673017621040344}, {"id": 200, "seek": 90156, "start": 901.56, "end": 905.68, "text": " and so it's taken a lot of time for people to come back.", "tokens": [50364, 293, 370, 309, 311, 2726, 257, 688, 295, 565, 337, 561, 281, 808, 646, 13, 50570], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 201, "seek": 90156, "start": 905.68, "end": 913.04, "text": " So Emacs I Python notebook, it tries to look a lot like the notebook interface, except", "tokens": [50570, 407, 3968, 44937, 286, 15329, 21060, 11, 309, 9898, 281, 574, 257, 688, 411, 264, 21060, 9226, 11, 3993, 50938], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 202, "seek": 90156, "start": 913.04, "end": 915.3599999999999, "text": " it's more text-like.", "tokens": [50938, 309, 311, 544, 2487, 12, 4092, 13, 51054], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 203, "seek": 90156, "start": 915.3599999999999, "end": 920.9599999999999, "text": " A lot of the features that are there in the web interface are also in Emacs.", "tokens": [51054, 316, 688, 295, 264, 4122, 300, 366, 456, 294, 264, 3670, 9226, 366, 611, 294, 3968, 44937, 13, 51334], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 204, "seek": 90156, "start": 920.9599999999999, "end": 922.5999999999999, "text": " You can cut copy and paste cells.", "tokens": [51334, 509, 393, 1723, 5055, 293, 9163, 5438, 13, 51416], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 205, "seek": 90156, "start": 922.5999999999999, "end": 924.8399999999999, "text": " You can move cells around.", "tokens": [51416, 509, 393, 1286, 5438, 926, 13, 51528], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 206, "seek": 90156, "start": 924.8399999999999, "end": 926.8, "text": " It has inline images.", "tokens": [51528, 467, 575, 294, 1889, 5267, 13, 51626], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 207, "seek": 90156, "start": 926.8, "end": 929.68, "text": " You can work with multiple kernels.", "tokens": [51626, 509, 393, 589, 365, 3866, 23434, 1625, 13, 51770], "temperature": 0.0, "avg_logprob": -0.15887356712704614, "compression_ratio": 1.6289592760180995, "no_speech_prob": 0.002472283085808158}, {"id": 208, "seek": 92968, "start": 929.68, "end": 933.92, "text": " All that's there.", "tokens": [50364, 1057, 300, 311, 456, 13, 50576], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 209, "seek": 92968, "start": 933.92, "end": 936.1999999999999, "text": " Also has a number of IDE-like features.", "tokens": [50576, 2743, 575, 257, 1230, 295, 40930, 12, 4092, 4122, 13, 50690], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 210, "seek": 92968, "start": 936.1999999999999, "end": 940.3599999999999, "text": " I think this puts it more in the realm of the Jupyter lab folk.", "tokens": [50690, 286, 519, 341, 8137, 309, 544, 294, 264, 15355, 295, 264, 22125, 88, 391, 2715, 15748, 13, 50898], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 211, "seek": 92968, "start": 940.3599999999999, "end": 945.0, "text": " There's auto-completion, which, if you have it configured right, works really, really", "tokens": [50898, 821, 311, 8399, 12, 1112, 14657, 313, 11, 597, 11, 498, 291, 362, 309, 30538, 558, 11, 1985, 534, 11, 534, 51130], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 212, "seek": 92968, "start": 945.0, "end": 949.0, "text": " well, but it can be a bit of a pain to configure.", "tokens": [51130, 731, 11, 457, 309, 393, 312, 257, 857, 295, 257, 1822, 281, 22162, 13, 51330], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 213, "seek": 92968, "start": 949.0, "end": 953.2399999999999, "text": " We can jump to definitions of functions.", "tokens": [51330, 492, 393, 3012, 281, 21988, 295, 6828, 13, 51542], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 214, "seek": 92968, "start": 953.2399999999999, "end": 954.24, "text": " Bunch of other stuff.", "tokens": [51542, 363, 1680, 295, 661, 1507, 13, 51592], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 215, "seek": 92968, "start": 954.24, "end": 959.4399999999999, "text": " I'm going to try and demo some of this later.", "tokens": [51592, 286, 478, 516, 281, 853, 293, 10723, 512, 295, 341, 1780, 13, 51852], "temperature": 0.0, "avg_logprob": -0.16257729401459564, "compression_ratio": 1.525, "no_speech_prob": 0.0005357383051887155}, {"id": 216, "seek": 95944, "start": 960.2, "end": 966.4000000000001, "text": " I really like this integration with Debugger because you can actually see the code as you're", "tokens": [50402, 286, 534, 411, 341, 10980, 365, 27347, 697, 1321, 570, 291, 393, 767, 536, 264, 3089, 382, 291, 434, 50712], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 217, "seek": 95944, "start": 966.4000000000001, "end": 969.24, "text": " stepping through.", "tokens": [50712, 16821, 807, 13, 50854], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 218, "seek": 95944, "start": 969.24, "end": 975.0, "text": " I don't think that's not something that you'll find on the web browser interface.", "tokens": [50854, 286, 500, 380, 519, 300, 311, 406, 746, 300, 291, 603, 915, 322, 264, 3670, 11185, 9226, 13, 51142], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 219, "seek": 95944, "start": 975.0, "end": 978.08, "text": " There's a number of things that are unique to Emacs.", "tokens": [51142, 821, 311, 257, 1230, 295, 721, 300, 366, 3845, 281, 3968, 44937, 13, 51296], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 220, "seek": 95944, "start": 978.08, "end": 983.9200000000001, "text": " It's probably some of the IDE stuff that is also unique to Emacs, but you can launch Jupyter", "tokens": [51296, 467, 311, 1391, 512, 295, 264, 40930, 1507, 300, 307, 611, 3845, 281, 3968, 44937, 11, 457, 291, 393, 4025, 22125, 88, 391, 51588], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 221, "seek": 95944, "start": 983.9200000000001, "end": 987.0, "text": " from inside Emacs.", "tokens": [51588, 490, 1854, 3968, 44937, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16454377425344366, "compression_ratio": 1.5866666666666667, "no_speech_prob": 0.013217827305197716}, {"id": 222, "seek": 98700, "start": 987.04, "end": 992.12, "text": " If you configure it correctly, it'll open up a buffer and it'll log everything from", "tokens": [50366, 759, 291, 22162, 309, 8944, 11, 309, 603, 1269, 493, 257, 21762, 293, 309, 603, 3565, 1203, 490, 50620], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 223, "seek": 98700, "start": 992.12, "end": 994.32, "text": " the Jupyter server there.", "tokens": [50620, 264, 22125, 88, 391, 7154, 456, 13, 50730], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 224, "seek": 98700, "start": 994.32, "end": 997.56, "text": " You can execute ELIS from IPython.", "tokens": [50730, 509, 393, 14483, 14426, 2343, 490, 8671, 88, 11943, 13, 50892], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 225, "seek": 98700, "start": 997.56, "end": 1004.68, "text": " The code that does this is kind of old, so it works, but I executed it and then opened", "tokens": [50892, 440, 3089, 300, 775, 341, 307, 733, 295, 1331, 11, 370, 309, 1985, 11, 457, 286, 17577, 309, 293, 550, 5625, 51248], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 226, "seek": 98700, "start": 1004.68, "end": 1009.12, "text": " this notebook up in the Roy browser and complained about some stuff.", "tokens": [51248, 341, 21060, 493, 294, 264, 8751, 11185, 293, 33951, 466, 512, 1507, 13, 51470], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 227, "seek": 98700, "start": 1009.12, "end": 1011.6, "text": " It integrates with org mode.", "tokens": [51470, 467, 3572, 1024, 365, 14045, 4391, 13, 51594], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 228, "seek": 98700, "start": 1011.6, "end": 1014.32, "text": " You can have source blocks in org mode that'll execute.", "tokens": [51594, 509, 393, 362, 4009, 8474, 294, 14045, 4391, 300, 603, 14483, 13, 51730], "temperature": 0.0, "avg_logprob": -0.19990728451655462, "compression_ratio": 1.5778688524590163, "no_speech_prob": 0.0003682757669594139}, {"id": 229, "seek": 101432, "start": 1014.32, "end": 1020.32, "text": " The results will go into your org buffer, including images.", "tokens": [50364, 440, 3542, 486, 352, 666, 428, 14045, 21762, 11, 3009, 5267, 13, 50664], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 230, "seek": 101432, "start": 1020.32, "end": 1021.32, "text": " Support for high.", "tokens": [50664, 18073, 337, 1090, 13, 50714], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 231, "seek": 101432, "start": 1021.32, "end": 1023.7600000000001, "text": " Have any of you heard of high?", "tokens": [50714, 3560, 604, 295, 291, 2198, 295, 1090, 30, 50836], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 232, "seek": 101432, "start": 1023.7600000000001, "end": 1029.0, "text": " I actually saw that and was like, oh, I have to support this in Emacs.", "tokens": [50836, 286, 767, 1866, 300, 293, 390, 411, 11, 1954, 11, 286, 362, 281, 1406, 341, 294, 3968, 44937, 13, 51098], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 233, "seek": 101432, "start": 1029.0, "end": 1034.16, "text": " You have a Lisp for Python with a Lisp syntax and it's not running in Emacs.", "tokens": [51098, 509, 362, 257, 441, 7631, 337, 15329, 365, 257, 441, 7631, 28431, 293, 309, 311, 406, 2614, 294, 3968, 44937, 13, 51356], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 234, "seek": 101432, "start": 1034.16, "end": 1036.0800000000002, "text": " Come on, guys.", "tokens": [51356, 2492, 322, 11, 1074, 13, 51452], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 235, "seek": 101432, "start": 1036.0800000000002, "end": 1039.8, "text": " The Callisto Py kernel.", "tokens": [51452, 440, 7807, 9334, 9953, 28256, 13, 51638], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 236, "seek": 101432, "start": 1039.8, "end": 1043.24, "text": " We can do that, but I can also intermix.", "tokens": [51638, 492, 393, 360, 300, 11, 457, 286, 393, 611, 728, 76, 970, 13, 51810], "temperature": 0.0, "avg_logprob": -0.27808811979473763, "compression_ratio": 1.4672489082969433, "no_speech_prob": 0.0012447816552594304}, {"id": 237, "seek": 104324, "start": 1043.24, "end": 1044.24, "text": " I'll show you.", "tokens": [50364, 286, 603, 855, 291, 13, 50414], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 238, "seek": 104324, "start": 1044.24, "end": 1046.92, "text": " I'll show you if we get to it.", "tokens": [50414, 286, 603, 855, 291, 498, 321, 483, 281, 309, 13, 50548], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 239, "seek": 104324, "start": 1046.92, "end": 1052.6, "text": " You can connect a Python buffer to a running notebook, which means it has access to a lot", "tokens": [50548, 509, 393, 1745, 257, 15329, 21762, 281, 257, 2614, 21060, 11, 597, 1355, 309, 575, 2105, 281, 257, 688, 50832], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 240, "seek": 104324, "start": 1052.6, "end": 1057.84, "text": " of the stuff that's available in the kernel, which is auto-completion and doc tools.", "tokens": [50832, 295, 264, 1507, 300, 311, 2435, 294, 264, 28256, 11, 597, 307, 8399, 12, 1112, 14657, 313, 293, 3211, 3873, 13, 51094], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 241, "seek": 104324, "start": 1057.84, "end": 1063.76, "text": " You can customize it using ELIS, not JavaScript.", "tokens": [51094, 509, 393, 19734, 309, 1228, 14426, 2343, 11, 406, 15778, 13, 51390], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 242, "seek": 104324, "start": 1063.76, "end": 1068.32, "text": " Emacs doesn't know JavaScript.", "tokens": [51390, 3968, 44937, 1177, 380, 458, 15778, 13, 51618], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 243, "seek": 104324, "start": 1068.32, "end": 1071.68, "text": " Who has pop-up, yeah, and then run doc tests.", "tokens": [51618, 2102, 575, 1665, 12, 1010, 11, 1338, 11, 293, 550, 1190, 3211, 6921, 13, 51786], "temperature": 0.0, "avg_logprob": -0.24797717344413683, "compression_ratio": 1.5377777777777777, "no_speech_prob": 0.0006070334929972887}, {"id": 244, "seek": 107168, "start": 1071.68, "end": 1074.4, "text": " Those are things I don't use a whole lot.", "tokens": [50364, 3950, 366, 721, 286, 500, 380, 764, 257, 1379, 688, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 245, "seek": 107168, "start": 1074.4, "end": 1079.2, "text": " You'll find that the stuff that works really well on Emacs in I'm is stuff that I use in", "tokens": [50500, 509, 603, 915, 300, 264, 1507, 300, 1985, 534, 731, 322, 3968, 44937, 294, 286, 478, 307, 1507, 300, 286, 764, 294, 50740], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 246, "seek": 107168, "start": 1079.2, "end": 1084.3600000000001, "text": " my day-to-day stuff for obvious reasons.", "tokens": [50740, 452, 786, 12, 1353, 12, 810, 1507, 337, 6322, 4112, 13, 50998], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 247, "seek": 107168, "start": 1084.3600000000001, "end": 1088.96, "text": " There's some stuff that definitely needs a lot of tender-loving care.", "tokens": [50998, 821, 311, 512, 1507, 300, 2138, 2203, 257, 688, 295, 15036, 12, 752, 798, 1127, 13, 51228], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 248, "seek": 107168, "start": 1088.96, "end": 1093.44, "text": " There used to be a feature to take a Panda's data frame and open it in the simple Emacs", "tokens": [51228, 821, 1143, 281, 312, 257, 4111, 281, 747, 257, 44207, 311, 1412, 3920, 293, 1269, 309, 294, 264, 2199, 3968, 44937, 51452], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 249, "seek": 107168, "start": 1093.44, "end": 1094.44, "text": " spreadsheet.", "tokens": [51452, 27733, 13, 51502], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 250, "seek": 107168, "start": 1094.44, "end": 1101.0, "text": " I tried that a couple of times, but the performance is, especially if it's a large data frame,", "tokens": [51502, 286, 3031, 300, 257, 1916, 295, 1413, 11, 457, 264, 3389, 307, 11, 2318, 498, 309, 311, 257, 2416, 1412, 3920, 11, 51830], "temperature": 0.0, "avg_logprob": -0.1641253163991881, "compression_ratio": 1.66793893129771, "no_speech_prob": 0.07155462354421616}, {"id": 251, "seek": 110100, "start": 1101.04, "end": 1103.92, "text": " Emacs will really struggle with that.", "tokens": [50366, 3968, 44937, 486, 534, 7799, 365, 300, 13, 50510], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 252, "seek": 110100, "start": 1103.92, "end": 1110.92, "text": " You used to be able to use the hierarchy magic to get a hierarchy of a class and embed", "tokens": [50510, 509, 1143, 281, 312, 1075, 281, 764, 264, 22333, 5585, 281, 483, 257, 22333, 295, 257, 1508, 293, 12240, 50860], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 253, "seek": 110100, "start": 1110.92, "end": 1113.2, "text": " that in the notebook.", "tokens": [50860, 300, 294, 264, 21060, 13, 50974], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 254, "seek": 110100, "start": 1113.2, "end": 1120.2, "text": " It's based on a notebook extension that was written for pre-ipython 1.0, so it's not going", "tokens": [50974, 467, 311, 2361, 322, 257, 21060, 10320, 300, 390, 3720, 337, 659, 12, 647, 88, 11943, 502, 13, 15, 11, 370, 309, 311, 406, 516, 51324], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 255, "seek": 110100, "start": 1121.08, "end": 1126.68, "text": " to work with modern Jupyter, that extension needs to be updated.", "tokens": [51368, 281, 589, 365, 4363, 22125, 88, 391, 11, 300, 10320, 2203, 281, 312, 10588, 13, 51648], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 256, "seek": 110100, "start": 1126.68, "end": 1128.08, "text": " Guess who's the maintainer of that?", "tokens": [51648, 17795, 567, 311, 264, 6909, 260, 295, 300, 30, 51718], "temperature": 0.0, "avg_logprob": -0.20548930921052633, "compression_ratio": 1.5504587155963303, "no_speech_prob": 0.04081406816840172}, {"id": 257, "seek": 112808, "start": 1128.48, "end": 1130.32, "text": " I want to wrote that, TKF.", "tokens": [50384, 286, 528, 281, 4114, 300, 11, 314, 42, 37, 13, 50476], "temperature": 0.0, "avg_logprob": -0.2644062042236328, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005192685057409108}, {"id": 258, "seek": 112808, "start": 1134.0, "end": 1139.0, "text": " But it probably wouldn't take a whole lot of work, really, honestly, to get it working.", "tokens": [50660, 583, 309, 1391, 2759, 380, 747, 257, 1379, 688, 295, 589, 11, 534, 11, 6095, 11, 281, 483, 309, 1364, 13, 50910], "temperature": 0.0, "avg_logprob": -0.2644062042236328, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005192685057409108}, {"id": 259, "seek": 112808, "start": 1139.0, "end": 1145.12, "text": " There's a few things that I does not do at all, and it's possible, may never do.", "tokens": [50910, 821, 311, 257, 1326, 721, 300, 286, 775, 406, 360, 412, 439, 11, 293, 309, 311, 1944, 11, 815, 1128, 360, 13, 51216], "temperature": 0.0, "avg_logprob": -0.2644062042236328, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005192685057409108}, {"id": 260, "seek": 112808, "start": 1145.12, "end": 1148.76, "text": " Number one on those is widgets.", "tokens": [51216, 5118, 472, 322, 729, 307, 43355, 13, 51398], "temperature": 0.0, "avg_logprob": -0.2644062042236328, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005192685057409108}, {"id": 261, "seek": 112808, "start": 1148.76, "end": 1154.0, "text": " That's because Emacs is not a web browser.", "tokens": [51398, 663, 311, 570, 3968, 44937, 307, 406, 257, 3670, 11185, 13, 51660], "temperature": 0.0, "avg_logprob": -0.2644062042236328, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0005192685057409108}, {"id": 262, "seek": 115400, "start": 1154.04, "end": 1159.08, "text": " There's some hope with maybe with XWidget and embedding the web browser inside the Emacs", "tokens": [50366, 821, 311, 512, 1454, 365, 1310, 365, 1783, 54, 327, 847, 293, 12240, 3584, 264, 3670, 11185, 1854, 264, 3968, 44937, 50618], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 263, "seek": 115400, "start": 1159.08, "end": 1160.44, "text": " buffer.", "tokens": [50618, 21762, 13, 50686], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 264, "seek": 115400, "start": 1160.44, "end": 1167.44, "text": " There's also the skewer package that might allow widgets to run in some form, maybe not", "tokens": [50686, 821, 311, 611, 264, 8756, 1554, 7372, 300, 1062, 2089, 43355, 281, 1190, 294, 512, 1254, 11, 1310, 406, 51036], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 265, "seek": 115400, "start": 1167.8, "end": 1174.8, "text": " there in the Emacs buffer, but at least in another window, maybe, but it's not something", "tokens": [51054, 456, 294, 264, 3968, 44937, 21762, 11, 457, 412, 1935, 294, 1071, 4910, 11, 1310, 11, 457, 309, 311, 406, 746, 51404], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 266, "seek": 115400, "start": 1175.36, "end": 1177.28, "text": " I really need to use.", "tokens": [51432, 286, 534, 643, 281, 764, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 267, "seek": 115400, "start": 1177.28, "end": 1180.72, "text": " The effort involves going to be probably pretty significant, so I don't know if it's going", "tokens": [51528, 440, 4630, 11626, 516, 281, 312, 1391, 1238, 4776, 11, 370, 286, 500, 380, 458, 498, 309, 311, 516, 51700], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 268, "seek": 115400, "start": 1180.72, "end": 1183.72, "text": " to happen anytime soon.", "tokens": [51700, 281, 1051, 13038, 2321, 13, 51850], "temperature": 0.0, "avg_logprob": -0.1578883249825294, "compression_ratio": 1.6599190283400809, "no_speech_prob": 0.003706635208800435}, {"id": 269, "seek": 118372, "start": 1183.72, "end": 1189.0, "text": " Most notebook extensions probably won't work with Emacs because the notebook extension", "tokens": [50364, 4534, 21060, 25129, 1391, 1582, 380, 589, 365, 3968, 44937, 570, 264, 21060, 10320, 50628], "temperature": 0.0, "avg_logprob": -0.17558877608355353, "compression_ratio": 1.7868020304568528, "no_speech_prob": 0.004467276856303215}, {"id": 270, "seek": 118372, "start": 1189.0, "end": 1194.3600000000001, "text": " will have some JavaScript in it, and again, Emacs doesn't know JavaScript, knows how to", "tokens": [50628, 486, 362, 512, 15778, 294, 309, 11, 293, 797, 11, 3968, 44937, 1177, 380, 458, 15778, 11, 3255, 577, 281, 50896], "temperature": 0.0, "avg_logprob": -0.17558877608355353, "compression_ratio": 1.7868020304568528, "no_speech_prob": 0.004467276856303215}, {"id": 271, "seek": 118372, "start": 1194.3600000000001, "end": 1201.28, "text": " edit JavaScript, great JavaScript editor, but it doesn't know how to execute it.", "tokens": [50896, 8129, 15778, 11, 869, 15778, 9839, 11, 457, 309, 1177, 380, 458, 577, 281, 14483, 309, 13, 51242], "temperature": 0.0, "avg_logprob": -0.17558877608355353, "compression_ratio": 1.7868020304568528, "no_speech_prob": 0.004467276856303215}, {"id": 272, "seek": 118372, "start": 1201.28, "end": 1207.44, "text": " But if you want to take the time to translate JavaScript into Emacs lists, you can make", "tokens": [51242, 583, 498, 291, 528, 281, 747, 264, 565, 281, 13799, 15778, 666, 3968, 44937, 14511, 11, 291, 393, 652, 51550], "temperature": 0.0, "avg_logprob": -0.17558877608355353, "compression_ratio": 1.7868020304568528, "no_speech_prob": 0.004467276856303215}, {"id": 273, "seek": 118372, "start": 1207.44, "end": 1208.1200000000001, "text": " it work.", "tokens": [51550, 309, 589, 13, 51584], "temperature": 0.0, "avg_logprob": -0.17558877608355353, "compression_ratio": 1.7868020304568528, "no_speech_prob": 0.004467276856303215}, {"id": 274, "seek": 120812, "start": 1208.12, "end": 1215.12, "text": " I took one, this really simple module, the timestamp module, that timestamp sells, wrote", "tokens": [50364, 286, 1890, 472, 11, 341, 534, 2199, 10088, 11, 264, 49108, 1215, 10088, 11, 300, 49108, 1215, 20897, 11, 4114, 50714], "temperature": 0.0, "avg_logprob": -0.2560793632684752, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.0030748869758099318}, {"id": 275, "seek": 120812, "start": 1215.12, "end": 1221.6, "text": " a couple functions in elisp, and it basically has the same function as that extension.", "tokens": [50714, 257, 1916, 6828, 294, 806, 7631, 11, 293, 309, 1936, 575, 264, 912, 2445, 382, 300, 10320, 13, 51038], "temperature": 0.0, "avg_logprob": -0.2560793632684752, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.0030748869758099318}, {"id": 276, "seek": 120812, "start": 1221.6, "end": 1228.28, "text": " In theory, if someone wanted to write an extension for iN, they could do so if they wanted to", "tokens": [51038, 682, 5261, 11, 498, 1580, 1415, 281, 2464, 364, 10320, 337, 741, 45, 11, 436, 727, 360, 370, 498, 436, 1415, 281, 51372], "temperature": 0.0, "avg_logprob": -0.2560793632684752, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.0030748869758099318}, {"id": 277, "seek": 120812, "start": 1228.28, "end": 1232.08, "text": " learn elisp.", "tokens": [51372, 1466, 806, 7631, 13, 51562], "temperature": 0.0, "avg_logprob": -0.2560793632684752, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.0030748869758099318}, {"id": 278, "seek": 120812, "start": 1232.08, "end": 1234.28, "text": " iN sort of supports Jupyter Hub.", "tokens": [51562, 741, 45, 1333, 295, 9346, 22125, 88, 391, 18986, 13, 51672], "temperature": 0.0, "avg_logprob": -0.2560793632684752, "compression_ratio": 1.6844919786096257, "no_speech_prob": 0.0030748869758099318}, {"id": 279, "seek": 123428, "start": 1234.28, "end": 1235.96, "text": " I'd like that support to be better.", "tokens": [50364, 286, 1116, 411, 300, 1406, 281, 312, 1101, 13, 50448], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 280, "seek": 123428, "start": 1235.96, "end": 1238.3999999999999, "text": " We'll see if I can get to it or not.", "tokens": [50448, 492, 603, 536, 498, 286, 393, 483, 281, 309, 420, 406, 13, 50570], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 281, "seek": 123428, "start": 1238.3999999999999, "end": 1240.0, "text": " It is a bit wonky.", "tokens": [50570, 467, 307, 257, 857, 1582, 4133, 13, 50650], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 282, "seek": 123428, "start": 1240.0, "end": 1245.6, "text": " Last I looked, I think it worked with Jupyter version 0.8, but it only supported the PAM", "tokens": [50650, 5264, 286, 2956, 11, 286, 519, 309, 2732, 365, 22125, 88, 391, 3037, 1958, 13, 23, 11, 457, 309, 787, 8104, 264, 430, 2865, 50930], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 283, "seek": 123428, "start": 1245.6, "end": 1247.6, "text": " authorization.", "tokens": [50930, 33697, 13, 51030], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 284, "seek": 123428, "start": 1247.6, "end": 1253.6, "text": " I don't know if it'll support what it'll take to get it to do OAuth, but that would be nice.", "tokens": [51030, 286, 500, 380, 458, 498, 309, 603, 1406, 437, 309, 603, 747, 281, 483, 309, 281, 360, 48424, 2910, 11, 457, 300, 576, 312, 1481, 13, 51330], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 285, "seek": 123428, "start": 1253.6, "end": 1255.6, "text": " Again, that's kind of, yeah.", "tokens": [51330, 3764, 11, 300, 311, 733, 295, 11, 1338, 13, 51430], "temperature": 0.0, "avg_logprob": -0.22473992847260973, "compression_ratio": 1.488262910798122, "no_speech_prob": 0.09801996499300003}, {"id": 286, "seek": 125560, "start": 1255.9199999999998, "end": 1262.9199999999998, "text": " I was just going to ask if there's any HTML support, is this a simpler target than JavaScript?", "tokens": [50380, 286, 390, 445, 516, 281, 1029, 498, 456, 311, 604, 17995, 1406, 11, 307, 341, 257, 18587, 3779, 813, 15778, 30, 50730], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 287, "seek": 125560, "start": 1262.9199999999998, "end": 1264.9199999999998, "text": " Like manipulating the DOM?", "tokens": [50730, 1743, 40805, 264, 35727, 30, 50830], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 288, "seek": 125560, "start": 1264.9199999999998, "end": 1269.9199999999998, "text": " Yeah, or not, like somebody sends some divs or some style of text.", "tokens": [50830, 865, 11, 420, 406, 11, 411, 2618, 14790, 512, 3414, 82, 420, 512, 3758, 295, 2487, 13, 51080], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 289, "seek": 125560, "start": 1269.9199999999998, "end": 1277.0, "text": " So it won't know how to render it nicely, but I mean, if it's there in the cell, it'll", "tokens": [51080, 407, 309, 1582, 380, 458, 577, 281, 15529, 309, 9594, 11, 457, 286, 914, 11, 498, 309, 311, 456, 294, 264, 2815, 11, 309, 603, 51434], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 290, "seek": 125560, "start": 1277.0, "end": 1279.28, "text": " show up.", "tokens": [51434, 855, 493, 13, 51548], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 291, "seek": 125560, "start": 1279.28, "end": 1281.28, "text": " It does some nice syntax highlighting.", "tokens": [51548, 467, 775, 512, 1481, 28431, 26551, 13, 51648], "temperature": 0.0, "avg_logprob": -0.3435166815052862, "compression_ratio": 1.4484304932735426, "no_speech_prob": 0.04602207615971565}, {"id": 292, "seek": 128128, "start": 1281.28, "end": 1287.28, "text": " It knows how to syntax highlight like markdown and Python.", "tokens": [50364, 467, 3255, 577, 281, 28431, 5078, 411, 1491, 5093, 293, 15329, 13, 50664], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 293, "seek": 128128, "start": 1287.28, "end": 1293.32, "text": " And I'll kind of show that when I open up the example.", "tokens": [50664, 400, 286, 603, 733, 295, 855, 300, 562, 286, 1269, 493, 264, 1365, 13, 50966], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 294, "seek": 128128, "start": 1293.32, "end": 1295.96, "text": " So what's next?", "tokens": [50966, 407, 437, 311, 958, 30, 51098], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 295, "seek": 128128, "start": 1295.96, "end": 1300.56, "text": " I just want to make sure it's staying compatible with Jupyter.", "tokens": [51098, 286, 445, 528, 281, 652, 988, 309, 311, 7939, 18218, 365, 22125, 88, 391, 13, 51328], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 296, "seek": 128128, "start": 1300.56, "end": 1301.92, "text": " Always like it to be more robust.", "tokens": [51328, 11270, 411, 309, 281, 312, 544, 13956, 13, 51396], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 297, "seek": 128128, "start": 1301.92, "end": 1307.48, "text": " I kind of wish I could make it to the point where I don't get these not connecting to kernel", "tokens": [51396, 286, 733, 295, 3172, 286, 727, 652, 309, 281, 264, 935, 689, 286, 500, 380, 483, 613, 406, 11015, 281, 28256, 51674], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 298, "seek": 128128, "start": 1307.48, "end": 1308.48, "text": " questions.", "tokens": [51674, 1651, 13, 51724], "temperature": 0.0, "avg_logprob": -0.17166211528162803, "compression_ratio": 1.5137614678899083, "no_speech_prob": 0.0030749926809221506}, {"id": 299, "seek": 130848, "start": 1309.16, "end": 1317.32, "text": " Though it seems to be lately they're all related to SSH issues, which I guess that's something.", "tokens": [50398, 10404, 309, 2544, 281, 312, 12881, 436, 434, 439, 4077, 281, 12238, 39, 2663, 11, 597, 286, 2041, 300, 311, 746, 13, 50806], "temperature": 0.0, "avg_logprob": -0.19193385802593427, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0013248490868136287}, {"id": 300, "seek": 130848, "start": 1317.32, "end": 1323.84, "text": " That's better than having a local running instance and not being able to connect to it.", "tokens": [50806, 663, 311, 1101, 813, 1419, 257, 2654, 2614, 5197, 293, 406, 885, 1075, 281, 1745, 281, 309, 13, 51132], "temperature": 0.0, "avg_logprob": -0.19193385802593427, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0013248490868136287}, {"id": 301, "seek": 130848, "start": 1323.84, "end": 1324.84, "text": " And there's a number of stuff.", "tokens": [51132, 400, 456, 311, 257, 1230, 295, 1507, 13, 51182], "temperature": 0.0, "avg_logprob": -0.19193385802593427, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0013248490868136287}, {"id": 302, "seek": 130848, "start": 1324.84, "end": 1329.6, "text": " I have an org file with a long list of improvements I like to make.", "tokens": [51182, 286, 362, 364, 14045, 3991, 365, 257, 938, 1329, 295, 13797, 286, 411, 281, 652, 13, 51420], "temperature": 0.0, "avg_logprob": -0.19193385802593427, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0013248490868136287}, {"id": 303, "seek": 130848, "start": 1329.6, "end": 1335.8, "text": " I think they've been sitting around for like three, four years, but some day, some day.", "tokens": [51420, 286, 519, 436, 600, 668, 3798, 926, 337, 411, 1045, 11, 1451, 924, 11, 457, 512, 786, 11, 512, 786, 13, 51730], "temperature": 0.0, "avg_logprob": -0.19193385802593427, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.0013248490868136287}, {"id": 304, "seek": 133580, "start": 1335.8, "end": 1343.32, "text": " So why don't we go ahead and do a little example.", "tokens": [50364, 407, 983, 500, 380, 321, 352, 2286, 293, 360, 257, 707, 1365, 13, 50740], "temperature": 0.0, "avg_logprob": -0.23854653040568033, "compression_ratio": 1.52020202020202, "no_speech_prob": 0.03208967298269272}, {"id": 305, "seek": 133580, "start": 1343.32, "end": 1349.44, "text": " If there are any questions before I move on to the example demo, all right.", "tokens": [50740, 759, 456, 366, 604, 1651, 949, 286, 1286, 322, 281, 264, 1365, 10723, 11, 439, 558, 13, 51046], "temperature": 0.0, "avg_logprob": -0.23854653040568033, "compression_ratio": 1.52020202020202, "no_speech_prob": 0.03208967298269272}, {"id": 306, "seek": 133580, "start": 1349.44, "end": 1355.72, "text": " So this is what, if you haven't seen it before, this is what the Emacs IPython looks like", "tokens": [51046, 407, 341, 307, 437, 11, 498, 291, 2378, 380, 1612, 309, 949, 11, 341, 307, 437, 264, 3968, 44937, 8671, 88, 11943, 1542, 411, 51360], "temperature": 0.0, "avg_logprob": -0.23854653040568033, "compression_ratio": 1.52020202020202, "no_speech_prob": 0.03208967298269272}, {"id": 307, "seek": 133580, "start": 1355.72, "end": 1361.08, "text": " when you first launch the notebook list view.", "tokens": [51360, 562, 291, 700, 4025, 264, 21060, 1329, 1910, 13, 51628], "temperature": 0.0, "avg_logprob": -0.23854653040568033, "compression_ratio": 1.52020202020202, "no_speech_prob": 0.03208967298269272}, {"id": 308, "seek": 133580, "start": 1361.08, "end": 1364.28, "text": " So kind of reminiscent of the web view.", "tokens": [51628, 407, 733, 295, 44304, 295, 264, 3670, 1910, 13, 51788], "temperature": 0.0, "avg_logprob": -0.23854653040568033, "compression_ratio": 1.52020202020202, "no_speech_prob": 0.03208967298269272}, {"id": 309, "seek": 136428, "start": 1364.28, "end": 1366.52, "text": " Down here are the files.", "tokens": [50364, 9506, 510, 366, 264, 7098, 13, 50476], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 310, "seek": 136428, "start": 1366.52, "end": 1372.8799999999999, "text": " You can actually open files that aren't IPython notebooks and edit them.", "tokens": [50476, 509, 393, 767, 1269, 7098, 300, 3212, 380, 8671, 88, 11943, 43782, 293, 8129, 552, 13, 50794], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 311, "seek": 136428, "start": 1372.8799999999999, "end": 1377.72, "text": " So let's say, for example, this pavement pie.", "tokens": [50794, 407, 718, 311, 584, 11, 337, 1365, 11, 341, 38305, 1730, 13, 51036], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 312, "seek": 136428, "start": 1377.72, "end": 1379.16, "text": " There's some issues.", "tokens": [51036, 821, 311, 512, 2663, 13, 51108], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 313, "seek": 136428, "start": 1379.16, "end": 1385.84, "text": " So we've got this Python buffer, and it's actually connected to the notebook server.", "tokens": [51108, 407, 321, 600, 658, 341, 15329, 21762, 11, 293, 309, 311, 767, 4582, 281, 264, 21060, 7154, 13, 51442], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 314, "seek": 136428, "start": 1385.84, "end": 1388.74, "text": " So if I save this file here, it actually gets saved on the server.", "tokens": [51442, 407, 498, 286, 3155, 341, 3991, 510, 11, 309, 767, 2170, 6624, 322, 264, 7154, 13, 51587], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 315, "seek": 136428, "start": 1388.74, "end": 1392.3999999999999, "text": " So this is one way of doing remote file editing.", "tokens": [51587, 407, 341, 307, 472, 636, 295, 884, 8607, 3991, 10000, 13, 51770], "temperature": 0.0, "avg_logprob": -0.1239925479888916, "compression_ratio": 1.6441441441441442, "no_speech_prob": 0.07155054807662964}, {"id": 316, "seek": 139240, "start": 1392.4, "end": 1394.96, "text": " I know Emacs has Tramp.", "tokens": [50364, 286, 458, 3968, 44937, 575, 1765, 1215, 13, 50492], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 317, "seek": 139240, "start": 1394.96, "end": 1401.8000000000002, "text": " I'd really like it if I had an IPython Tramp protocol.", "tokens": [50492, 286, 1116, 534, 411, 309, 498, 286, 632, 364, 8671, 88, 11943, 1765, 1215, 10336, 13, 50834], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 318, "seek": 139240, "start": 1401.8000000000002, "end": 1404.3200000000002, "text": " I think that would be really cool.", "tokens": [50834, 286, 519, 300, 576, 312, 534, 1627, 13, 50960], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 319, "seek": 139240, "start": 1404.3200000000002, "end": 1408.8000000000002, "text": " That would be very Emacs-y, but again, it's something that requires time and effort.", "tokens": [50960, 663, 576, 312, 588, 3968, 44937, 12, 88, 11, 457, 797, 11, 309, 311, 746, 300, 7029, 565, 293, 4630, 13, 51184], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 320, "seek": 139240, "start": 1408.8000000000002, "end": 1418.24, "text": " I'm not sure if I'll get to it.", "tokens": [51184, 286, 478, 406, 988, 498, 286, 603, 483, 281, 309, 13, 51656], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 321, "seek": 139240, "start": 1418.24, "end": 1422.16, "text": " So let's go to this presentation.", "tokens": [51656, 407, 718, 311, 352, 281, 341, 5860, 13, 51852], "temperature": 0.0, "avg_logprob": -0.17322051247885062, "compression_ratio": 1.4748603351955307, "no_speech_prob": 0.008060433901846409}, {"id": 322, "seek": 142216, "start": 1422.92, "end": 1425.6000000000001, "text": " This is the actual presentation I just gave you.", "tokens": [50402, 639, 307, 264, 3539, 5860, 286, 445, 2729, 291, 13, 50536], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 323, "seek": 142216, "start": 1425.6000000000001, "end": 1427.92, "text": " I wrote it all in Emacs.", "tokens": [50536, 286, 4114, 309, 439, 294, 3968, 44937, 13, 50652], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 324, "seek": 142216, "start": 1427.92, "end": 1434.0, "text": " I was going to try and put it in a PowerPoint presentation, but I raged quit after a few", "tokens": [50652, 286, 390, 516, 281, 853, 293, 829, 309, 294, 257, 25584, 5860, 11, 457, 286, 367, 2980, 10366, 934, 257, 1326, 50956], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 325, "seek": 142216, "start": 1434.0, "end": 1441.3200000000002, "text": " minutes of trying to copy stuff over to PowerPoint, and thanks to IPython and RISE, we had the", "tokens": [50956, 2077, 295, 1382, 281, 5055, 1507, 670, 281, 25584, 11, 293, 3231, 281, 8671, 88, 11943, 293, 497, 19413, 11, 321, 632, 264, 51322], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 326, "seek": 142216, "start": 1441.3200000000002, "end": 1442.66, "text": " presentation that we did.", "tokens": [51322, 5860, 300, 321, 630, 13, 51389], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 327, "seek": 142216, "start": 1442.66, "end": 1445.16, "text": " So let's go down here a little bit.", "tokens": [51389, 407, 718, 311, 352, 760, 510, 257, 707, 857, 13, 51514], "temperature": 0.0, "avg_logprob": -0.20060423966292495, "compression_ratio": 1.5485436893203883, "no_speech_prob": 0.037290144711732864}, {"id": 328, "seek": 144516, "start": 1446.16, "end": 1452.16, "text": " I went to the demonstration.", "tokens": [50414, 286, 1437, 281, 264, 16520, 13, 50714], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 329, "seek": 144516, "start": 1452.16, "end": 1457.72, "text": " So looking at this interface real quick, so you see up in this upper left corner, there's", "tokens": [50714, 407, 1237, 412, 341, 9226, 957, 1702, 11, 370, 291, 536, 493, 294, 341, 6597, 1411, 4538, 11, 456, 311, 50992], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 330, "seek": 144516, "start": 1457.72, "end": 1460.16, "text": " the execution count.", "tokens": [50992, 264, 15058, 1207, 13, 51114], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 331, "seek": 144516, "start": 1460.16, "end": 1464.92, "text": " This one, actually back in the day, I supported multiple worksheets.", "tokens": [51114, 639, 472, 11, 767, 646, 294, 264, 786, 11, 286, 8104, 3866, 1985, 675, 1385, 13, 51352], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 332, "seek": 144516, "start": 1464.92, "end": 1466.16, "text": " It kind of still does.", "tokens": [51352, 467, 733, 295, 920, 775, 13, 51414], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 333, "seek": 144516, "start": 1466.16, "end": 1472.52, "text": " The problem is that IPython itself doesn't do worksheets anymore, so it would be a little", "tokens": [51414, 440, 1154, 307, 300, 8671, 88, 11943, 2564, 1177, 380, 360, 1985, 675, 1385, 3602, 11, 370, 309, 576, 312, 257, 707, 51732], "temperature": 0.0, "avg_logprob": -0.21401192925193094, "compression_ratio": 1.5213270142180095, "no_speech_prob": 0.001501086400821805}, {"id": 334, "seek": 147252, "start": 1472.52, "end": 1478.6, "text": " bit of work on my end, but I could bring that back if people were interested.", "tokens": [50364, 857, 295, 589, 322, 452, 917, 11, 457, 286, 727, 1565, 300, 646, 498, 561, 645, 3102, 13, 50668], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 335, "seek": 147252, "start": 1478.6, "end": 1481.68, "text": " And then the kernel is running, which you can change.", "tokens": [50668, 400, 550, 264, 28256, 307, 2614, 11, 597, 291, 393, 1319, 13, 50822], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 336, "seek": 147252, "start": 1481.68, "end": 1486.28, "text": " You can also reset the kernel.", "tokens": [50822, 509, 393, 611, 14322, 264, 28256, 13, 51052], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 337, "seek": 147252, "start": 1486.28, "end": 1492.92, "text": " And then you can execute, and it's just like an IPython, like in the notebook.", "tokens": [51052, 400, 550, 291, 393, 14483, 11, 293, 309, 311, 445, 411, 364, 8671, 88, 11943, 11, 411, 294, 264, 21060, 13, 51384], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 338, "seek": 147252, "start": 1492.92, "end": 1499.08, "text": " Now, I want you to watch carefully, and this was all inspired by Joel's talk earlier about", "tokens": [51384, 823, 11, 286, 528, 291, 281, 1159, 7500, 11, 293, 341, 390, 439, 7547, 538, 21522, 311, 751, 3071, 466, 51692], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 339, "seek": 147252, "start": 1499.08, "end": 1502.28, "text": " what he hated about the IPython notebook.", "tokens": [51692, 437, 415, 17398, 466, 264, 8671, 88, 11943, 21060, 13, 51852], "temperature": 0.0, "avg_logprob": -0.16265790602740118, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.015419491566717625}, {"id": 340, "seek": 150228, "start": 1502.28, "end": 1504.76, "text": " I don't know if any of you saw that.", "tokens": [50364, 286, 500, 380, 458, 498, 604, 295, 291, 1866, 300, 13, 50488], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 341, "seek": 150228, "start": 1504.76, "end": 1505.76, "text": " So watch carefully.", "tokens": [50488, 407, 1159, 7500, 13, 50538], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 342, "seek": 150228, "start": 1505.76, "end": 1508.52, "text": " No execution count, nothing up my sleeves.", "tokens": [50538, 883, 15058, 1207, 11, 1825, 493, 452, 24555, 13, 50676], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 343, "seek": 150228, "start": 1508.52, "end": 1509.76, "text": " I haven't executed this line.", "tokens": [50676, 286, 2378, 380, 17577, 341, 1622, 13, 50738], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 344, "seek": 150228, "start": 1509.76, "end": 1521.3999999999999, "text": " I haven't executed import sys at anywhere in this notebook, I promise.", "tokens": [50738, 286, 2378, 380, 17577, 974, 262, 749, 412, 4992, 294, 341, 21060, 11, 286, 6228, 13, 51320], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 345, "seek": 150228, "start": 1521.3999999999999, "end": 1522.3999999999999, "text": " Thank you.", "tokens": [51320, 1044, 291, 13, 51370], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 346, "seek": 150228, "start": 1522.3999999999999, "end": 1525.36, "text": " Thank you.", "tokens": [51370, 1044, 291, 13, 51518], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 347, "seek": 150228, "start": 1525.36, "end": 1529.8799999999999, "text": " This is using the Jedi package, and it's using Jedi.", "tokens": [51518, 639, 307, 1228, 264, 21746, 7372, 11, 293, 309, 311, 1228, 21746, 13, 51744], "temperature": 0.0, "avg_logprob": -0.18351266497657412, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.00048779224744066596}, {"id": 348, "seek": 152988, "start": 1529.88, "end": 1535.5200000000002, "text": " So it's not actually talking to the kernel, actually what it does in this instance is", "tokens": [50364, 407, 309, 311, 406, 767, 1417, 281, 264, 28256, 11, 767, 437, 309, 775, 294, 341, 5197, 307, 50646], "temperature": 0.0, "avg_logprob": -0.16706019810267858, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.015417739748954773}, {"id": 349, "seek": 152988, "start": 1535.5200000000002, "end": 1541.0800000000002, "text": " querying Jedi, and it's querying the kernel, and it's figuring out which one has the results,", "tokens": [50646, 7083, 1840, 21746, 11, 293, 309, 311, 7083, 1840, 264, 28256, 11, 293, 309, 311, 15213, 484, 597, 472, 575, 264, 3542, 11, 50924], "temperature": 0.0, "avg_logprob": -0.16706019810267858, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.015417739748954773}, {"id": 350, "seek": 152988, "start": 1541.0800000000002, "end": 1544.3000000000002, "text": " and the kernel is probably saying, I don't know.", "tokens": [50924, 293, 264, 28256, 307, 1391, 1566, 11, 286, 500, 380, 458, 13, 51085], "temperature": 0.0, "avg_logprob": -0.16706019810267858, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.015417739748954773}, {"id": 351, "seek": 152988, "start": 1544.3000000000002, "end": 1551.2800000000002, "text": " But Jedi, because it statically goes through, it knows, and you can actually get some completion.", "tokens": [51085, 583, 21746, 11, 570, 309, 2219, 984, 1709, 807, 11, 309, 3255, 11, 293, 291, 393, 767, 483, 512, 19372, 13, 51434], "temperature": 0.0, "avg_logprob": -0.16706019810267858, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.015417739748954773}, {"id": 352, "seek": 152988, "start": 1551.2800000000002, "end": 1555.7600000000002, "text": " Now, this only supports, if you guys know about the Emacs completion packages, there's", "tokens": [51434, 823, 11, 341, 787, 9346, 11, 498, 291, 1074, 458, 466, 264, 3968, 44937, 19372, 17401, 11, 456, 311, 51658], "temperature": 0.0, "avg_logprob": -0.16706019810267858, "compression_ratio": 1.7280334728033473, "no_speech_prob": 0.015417739748954773}, {"id": 353, "seek": 155576, "start": 1555.76, "end": 1560.04, "text": " autocomplete, and there's company, and I have some support for company, but what I", "tokens": [50364, 45833, 298, 17220, 11, 293, 456, 311, 2237, 11, 293, 286, 362, 512, 1406, 337, 2237, 11, 457, 437, 286, 50578], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 354, "seek": 155576, "start": 1560.04, "end": 1564.08, "text": " just showed here really only works with autocomplete.", "tokens": [50578, 445, 4712, 510, 534, 787, 1985, 365, 45833, 298, 17220, 13, 50780], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 355, "seek": 155576, "start": 1564.08, "end": 1572.92, "text": " Maybe with company Jedi, I could get this working with company mode as well.", "tokens": [50780, 2704, 365, 2237, 21746, 11, 286, 727, 483, 341, 1364, 365, 2237, 4391, 382, 731, 13, 51222], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 356, "seek": 155576, "start": 1572.92, "end": 1573.92, "text": " What's just like that?", "tokens": [51222, 708, 311, 445, 411, 300, 30, 51272], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 357, "seek": 155576, "start": 1573.92, "end": 1574.92, "text": " Say hello, world.", "tokens": [51272, 6463, 7751, 11, 1002, 13, 51322], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 358, "seek": 155576, "start": 1574.92, "end": 1575.92, "text": " All right.", "tokens": [51322, 1057, 558, 13, 51372], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 359, "seek": 155576, "start": 1575.92, "end": 1580.4, "text": " I'm going to go down here real quick and set my plotting parameters, so this plot doesn't", "tokens": [51372, 286, 478, 516, 281, 352, 760, 510, 957, 1702, 293, 992, 452, 41178, 9834, 11, 370, 341, 7542, 1177, 380, 51596], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 360, "seek": 155576, "start": 1580.4, "end": 1581.4, "text": " look too...", "tokens": [51596, 574, 886, 485, 51646], "temperature": 0.0, "avg_logprob": -0.22245478162578508, "compression_ratio": 1.6026200873362446, "no_speech_prob": 0.10370305925607681}, {"id": 361, "seek": 158140, "start": 1581.4, "end": 1589.72, "text": " It's Emacs.", "tokens": [50364, 467, 311, 3968, 44937, 13, 50780], "temperature": 0.0, "avg_logprob": -0.24999234255622416, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.017982807010412216}, {"id": 362, "seek": 158140, "start": 1589.72, "end": 1593.68, "text": " It can be whatever you want.", "tokens": [50780, 467, 393, 312, 2035, 291, 528, 13, 50978], "temperature": 0.0, "avg_logprob": -0.24999234255622416, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.017982807010412216}, {"id": 363, "seek": 158140, "start": 1593.68, "end": 1596.68, "text": " So I use Space Max.", "tokens": [50978, 407, 286, 764, 8705, 7402, 13, 51128], "temperature": 0.0, "avg_logprob": -0.24999234255622416, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.017982807010412216}, {"id": 364, "seek": 158140, "start": 1596.68, "end": 1604.5600000000002, "text": " So in Space Max, you can have like a special mode key, which for, in this case, it's comma,", "tokens": [51128, 407, 294, 8705, 7402, 11, 291, 393, 362, 411, 257, 2121, 4391, 2141, 11, 597, 337, 11, 294, 341, 1389, 11, 309, 311, 22117, 11, 51522], "temperature": 0.0, "avg_logprob": -0.24999234255622416, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.017982807010412216}, {"id": 365, "seek": 158140, "start": 1604.5600000000002, "end": 1607.8000000000002, "text": " so I do comma return, and that executes the cell.", "tokens": [51522, 370, 286, 360, 22117, 2736, 11, 293, 300, 4454, 1819, 264, 2815, 13, 51684], "temperature": 0.0, "avg_logprob": -0.24999234255622416, "compression_ratio": 1.3835616438356164, "no_speech_prob": 0.017982807010412216}, {"id": 366, "seek": 160780, "start": 1607.8, "end": 1618.72, "text": " But if you wanted to be shift return, you could do that.", "tokens": [50364, 583, 498, 291, 1415, 281, 312, 5513, 2736, 11, 291, 727, 360, 300, 13, 50910], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 367, "seek": 160780, "start": 1618.72, "end": 1621.72, "text": " To open the notebook?", "tokens": [50910, 1407, 1269, 264, 21060, 30, 51060], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 368, "seek": 160780, "start": 1621.72, "end": 1622.8, "text": " Sure.", "tokens": [51060, 4894, 13, 51114], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 369, "seek": 160780, "start": 1622.8, "end": 1631.12, "text": " So here's the notebook list view, notebook list buffer.", "tokens": [51114, 407, 510, 311, 264, 21060, 1329, 1910, 11, 21060, 1329, 21762, 13, 51530], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 370, "seek": 160780, "start": 1631.12, "end": 1632.12, "text": " So oh, okay.", "tokens": [51530, 407, 1954, 11, 1392, 13, 51580], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 371, "seek": 160780, "start": 1632.12, "end": 1633.12, "text": " Oh, you're right.", "tokens": [51580, 876, 11, 291, 434, 558, 13, 51630], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 372, "seek": 160780, "start": 1633.12, "end": 1634.12, "text": " Okay.", "tokens": [51630, 1033, 13, 51680], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 373, "seek": 160780, "start": 1634.12, "end": 1635.12, "text": " Why don't we do this then?", "tokens": [51680, 1545, 500, 380, 321, 360, 341, 550, 30, 51730], "temperature": 0.0, "avg_logprob": -0.24389383527967665, "compression_ratio": 1.446808510638298, "no_speech_prob": 0.07583481073379517}, {"id": 374, "seek": 163512, "start": 1635.12, "end": 1640.2399999999998, "text": " Let's start from nothing.", "tokens": [50364, 961, 311, 722, 490, 1825, 13, 50620], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 375, "seek": 163512, "start": 1640.2399999999998, "end": 1644.52, "text": " So this command I'm typing in right now, that stops the Jupyter server.", "tokens": [50620, 407, 341, 5622, 286, 478, 18444, 294, 558, 586, 11, 300, 10094, 264, 22125, 88, 391, 7154, 13, 50834], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 376, "seek": 163512, "start": 1644.52, "end": 1647.52, "text": " Let's do that.", "tokens": [50834, 961, 311, 360, 300, 13, 50984], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 377, "seek": 163512, "start": 1647.52, "end": 1650.0, "text": " Let's kill that buffer.", "tokens": [50984, 961, 311, 1961, 300, 21762, 13, 51108], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 378, "seek": 163512, "start": 1650.0, "end": 1657.6399999999999, "text": " Let's make sure there is no running, gotcha.", "tokens": [51108, 961, 311, 652, 988, 456, 307, 572, 2614, 11, 658, 4413, 13, 51490], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 379, "seek": 163512, "start": 1657.6399999999999, "end": 1662.4799999999998, "text": " And then let's do this, AYS.", "tokens": [51490, 400, 550, 718, 311, 360, 341, 11, 316, 56, 50, 13, 51732], "temperature": 0.0, "avg_logprob": -0.2429288758171929, "compression_ratio": 1.4093959731543624, "no_speech_prob": 0.09264769405126572}, {"id": 380, "seek": 166248, "start": 1662.48, "end": 1669.64, "text": " So I just execute the command Ayn Jupyter start server.", "tokens": [50364, 407, 286, 445, 14483, 264, 5622, 316, 2534, 22125, 88, 391, 722, 7154, 13, 50722], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 381, "seek": 166248, "start": 1669.64, "end": 1673.0, "text": " You can configure the name of the Jupyter command.", "tokens": [50722, 509, 393, 22162, 264, 1315, 295, 264, 22125, 88, 391, 5622, 13, 50890], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 382, "seek": 166248, "start": 1673.0, "end": 1675.1200000000001, "text": " There's a variable for that.", "tokens": [50890, 821, 311, 257, 7006, 337, 300, 13, 50996], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 383, "seek": 166248, "start": 1675.1200000000001, "end": 1679.16, "text": " If that variable's not set, it'll ask you for a path to the Jupyter server.", "tokens": [50996, 759, 300, 7006, 311, 406, 992, 11, 309, 603, 1029, 291, 337, 257, 3100, 281, 264, 22125, 88, 391, 7154, 13, 51198], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 384, "seek": 166248, "start": 1679.16, "end": 1683.3600000000001, "text": " Then it'll ask you for a path to where you want the server to open, which is doing right", "tokens": [51198, 1396, 309, 603, 1029, 291, 337, 257, 3100, 281, 689, 291, 528, 264, 7154, 281, 1269, 11, 597, 307, 884, 558, 51408], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 385, "seek": 166248, "start": 1683.3600000000001, "end": 1685.3600000000001, "text": " now.", "tokens": [51408, 586, 13, 51508], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 386, "seek": 166248, "start": 1685.3600000000001, "end": 1690.68, "text": " And I've got this nice little default, so let's start that.", "tokens": [51508, 400, 286, 600, 658, 341, 1481, 707, 7576, 11, 370, 718, 311, 722, 300, 13, 51774], "temperature": 0.0, "avg_logprob": -0.15567152588455765, "compression_ratio": 1.705607476635514, "no_speech_prob": 0.008060778491199017}, {"id": 387, "seek": 169068, "start": 1690.68, "end": 1693.76, "text": " My fingers are crossed.", "tokens": [50364, 1222, 7350, 366, 14622, 13, 50518], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 388, "seek": 169068, "start": 1693.76, "end": 1697.92, "text": " It's going to take a little bit to start up the server, which I can probably jump to", "tokens": [50518, 467, 311, 516, 281, 747, 257, 707, 857, 281, 722, 493, 264, 7154, 11, 597, 286, 393, 1391, 3012, 281, 50726], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 389, "seek": 169068, "start": 1697.92, "end": 1701.28, "text": " right now.", "tokens": [50726, 558, 586, 13, 50894], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 390, "seek": 169068, "start": 1701.28, "end": 1702.28, "text": " There it is.", "tokens": [50894, 821, 309, 307, 13, 50944], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 391, "seek": 169068, "start": 1702.28, "end": 1705.04, "text": " Hopefully, I haven't confused Emacs.", "tokens": [50944, 10429, 11, 286, 2378, 380, 9019, 3968, 44937, 13, 51082], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 392, "seek": 169068, "start": 1705.04, "end": 1706.04, "text": " There we go.", "tokens": [51082, 821, 321, 352, 13, 51132], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 393, "seek": 169068, "start": 1706.04, "end": 1707.04, "text": " It's trying to log in.", "tokens": [51132, 467, 311, 1382, 281, 3565, 294, 13, 51182], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 394, "seek": 169068, "start": 1707.04, "end": 1708.04, "text": " And there we go.", "tokens": [51182, 400, 456, 321, 352, 13, 51232], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 395, "seek": 169068, "start": 1708.04, "end": 1709.04, "text": " There's the browser.", "tokens": [51232, 821, 311, 264, 11185, 13, 51282], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 396, "seek": 169068, "start": 1709.04, "end": 1714.64, "text": " This is probably the easiest way to get it running on your local machine is the Ayn", "tokens": [51282, 639, 307, 1391, 264, 12889, 636, 281, 483, 309, 2614, 322, 428, 2654, 3479, 307, 264, 316, 2534, 51562], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 397, "seek": 169068, "start": 1714.64, "end": 1716.3200000000002, "text": " Jupyter server start.", "tokens": [51562, 22125, 88, 391, 7154, 722, 13, 51646], "temperature": 0.0, "avg_logprob": -0.15418432409113103, "compression_ratio": 1.5650224215246638, "no_speech_prob": 0.015421935357153416}, {"id": 398, "seek": 171632, "start": 1717.08, "end": 1723.52, "text": " It brings up this, it's called the notebook list view or notebook list buffer.", "tokens": [50402, 467, 5607, 493, 341, 11, 309, 311, 1219, 264, 21060, 1329, 1910, 420, 21060, 1329, 21762, 13, 50724], "temperature": 0.0, "avg_logprob": -0.20778717138828376, "compression_ratio": 1.4684210526315788, "no_speech_prob": 0.008061124943196774}, {"id": 399, "seek": 171632, "start": 1723.52, "end": 1726.6799999999998, "text": " And it works pretty much like it does on the web interface.", "tokens": [50724, 400, 309, 1985, 1238, 709, 411, 309, 775, 322, 264, 3670, 9226, 13, 50882], "temperature": 0.0, "avg_logprob": -0.20778717138828376, "compression_ratio": 1.4684210526315788, "no_speech_prob": 0.008061124943196774}, {"id": 400, "seek": 171632, "start": 1726.6799999999998, "end": 1735.9199999999998, "text": " So I'm going to go to the Emacs IPython notebook project directory, go back down, and then", "tokens": [50882, 407, 286, 478, 516, 281, 352, 281, 264, 3968, 44937, 8671, 88, 11943, 21060, 1716, 21120, 11, 352, 646, 760, 11, 293, 550, 51344], "temperature": 0.0, "avg_logprob": -0.20778717138828376, "compression_ratio": 1.4684210526315788, "no_speech_prob": 0.008061124943196774}, {"id": 401, "seek": 171632, "start": 1735.9199999999998, "end": 1741.32, "text": " you just select open.", "tokens": [51344, 291, 445, 3048, 1269, 13, 51614], "temperature": 0.0, "avg_logprob": -0.20778717138828376, "compression_ratio": 1.4684210526315788, "no_speech_prob": 0.008061124943196774}, {"id": 402, "seek": 171632, "start": 1741.32, "end": 1744.2, "text": " So here we are, back again.", "tokens": [51614, 407, 510, 321, 366, 11, 646, 797, 13, 51758], "temperature": 0.0, "avg_logprob": -0.20778717138828376, "compression_ratio": 1.4684210526315788, "no_speech_prob": 0.008061124943196774}, {"id": 403, "seek": 174420, "start": 1744.2, "end": 1750.16, "text": " So it started up the kernel, new execution, so it's at zero count.", "tokens": [50364, 407, 309, 1409, 493, 264, 28256, 11, 777, 15058, 11, 370, 309, 311, 412, 4018, 1207, 13, 50662], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 404, "seek": 174420, "start": 1750.16, "end": 1751.44, "text": " And here we are.", "tokens": [50662, 400, 510, 321, 366, 13, 50726], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 405, "seek": 174420, "start": 1751.44, "end": 1752.44, "text": " So clear?", "tokens": [50726, 407, 1850, 30, 50776], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 406, "seek": 174420, "start": 1752.44, "end": 1754.44, "text": " Was it clear?", "tokens": [50776, 3027, 309, 1850, 30, 50876], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 407, "seek": 174420, "start": 1754.44, "end": 1756.44, "text": " You're very welcome.", "tokens": [50876, 509, 434, 588, 2928, 13, 50976], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 408, "seek": 174420, "start": 1756.44, "end": 1757.44, "text": " So where was I?", "tokens": [50976, 407, 689, 390, 286, 30, 51026], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 409, "seek": 174420, "start": 1757.44, "end": 1763.76, "text": " Oh, I was going to do an inline plot, because this is what got me started in the first place.", "tokens": [51026, 876, 11, 286, 390, 516, 281, 360, 364, 294, 1889, 7542, 11, 570, 341, 307, 437, 658, 385, 1409, 294, 264, 700, 1081, 13, 51342], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 410, "seek": 174420, "start": 1763.76, "end": 1770.92, "text": " I liked using Matplotlib to generate pretty plots for my work, because I think they're", "tokens": [51342, 286, 4501, 1228, 6789, 564, 310, 38270, 281, 8460, 1238, 28609, 337, 452, 589, 11, 570, 286, 519, 436, 434, 51700], "temperature": 0.0, "avg_logprob": -0.1738653843945796, "compression_ratio": 1.5186915887850467, "no_speech_prob": 0.005554221570491791}, {"id": 411, "seek": 177092, "start": 1770.92, "end": 1779.2, "text": " a lot prettier than what Excel does.", "tokens": [50364, 257, 688, 36825, 813, 437, 19060, 775, 13, 50778], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 412, "seek": 177092, "start": 1779.2, "end": 1781.2, "text": " So let's do this.", "tokens": [50778, 407, 718, 311, 360, 341, 13, 50878], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 413, "seek": 177092, "start": 1781.2, "end": 1787.28, "text": " I didn't execute.", "tokens": [50878, 286, 994, 380, 14483, 13, 51182], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 414, "seek": 177092, "start": 1787.28, "end": 1790.0800000000002, "text": " So you can't put comments in magic lines.", "tokens": [51182, 407, 291, 393, 380, 829, 3053, 294, 5585, 3876, 13, 51322], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 415, "seek": 177092, "start": 1790.0800000000002, "end": 1792.4, "text": " Let's do this.", "tokens": [51322, 961, 311, 360, 341, 13, 51438], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 416, "seek": 177092, "start": 1792.4, "end": 1794.52, "text": " There we go.", "tokens": [51438, 821, 321, 352, 13, 51544], "temperature": 0.0, "avg_logprob": -0.38640957612257737, "compression_ratio": 1.2792792792792793, "no_speech_prob": 0.0116859907284379}, {"id": 417, "seek": 179452, "start": 1794.52, "end": 1798.32, "text": " Right now.", "tokens": [50364, 1779, 586, 13, 50554], "temperature": 0.0, "avg_logprob": -0.34405243396759033, "compression_ratio": 1.1363636363636365, "no_speech_prob": 0.019120553508400917}, {"id": 418, "seek": 179452, "start": 1798.32, "end": 1799.48, "text": " I know that looks really small.", "tokens": [50554, 286, 458, 300, 1542, 534, 1359, 13, 50612], "temperature": 0.0, "avg_logprob": -0.34405243396759033, "compression_ratio": 1.1363636363636365, "no_speech_prob": 0.019120553508400917}, {"id": 419, "seek": 179452, "start": 1799.48, "end": 1800.48, "text": " I'm sorry.", "tokens": [50612, 286, 478, 2597, 13, 50662], "temperature": 0.0, "avg_logprob": -0.34405243396759033, "compression_ratio": 1.1363636363636365, "no_speech_prob": 0.019120553508400917}, {"id": 420, "seek": 179452, "start": 1800.48, "end": 1810.56, "text": " I'll see if I can get this again.", "tokens": [50662, 286, 603, 536, 498, 286, 393, 483, 341, 797, 13, 51166], "temperature": 0.0, "avg_logprob": -0.34405243396759033, "compression_ratio": 1.1363636363636365, "no_speech_prob": 0.019120553508400917}, {"id": 421, "seek": 179452, "start": 1810.56, "end": 1820.4, "text": " There we go.", "tokens": [51166, 821, 321, 352, 13, 51658], "temperature": 0.0, "avg_logprob": -0.34405243396759033, "compression_ratio": 1.1363636363636365, "no_speech_prob": 0.019120553508400917}, {"id": 422, "seek": 182040, "start": 1820.4, "end": 1821.4, "text": " That's the good news.", "tokens": [50364, 663, 311, 264, 665, 2583, 13, 50414], "temperature": 0.0, "avg_logprob": -0.23886282303754022, "compression_ratio": 1.2113821138211383, "no_speech_prob": 0.4638652205467224}, {"id": 423, "seek": 182040, "start": 1821.4, "end": 1833.2800000000002, "text": " The bad news is stuff like Boca, Altair, Vega, they won't work, because they use JavaScript,", "tokens": [50414, 440, 1578, 2583, 307, 1507, 411, 3286, 496, 11, 15992, 1246, 11, 48796, 11, 436, 1582, 380, 589, 11, 570, 436, 764, 15778, 11, 51008], "temperature": 0.0, "avg_logprob": -0.23886282303754022, "compression_ratio": 1.2113821138211383, "no_speech_prob": 0.4638652205467224}, {"id": 424, "seek": 182040, "start": 1833.2800000000002, "end": 1834.2800000000002, "text": " and that won't run in Emacs.", "tokens": [51008, 293, 300, 1582, 380, 1190, 294, 3968, 44937, 13, 51058], "temperature": 0.0, "avg_logprob": -0.23886282303754022, "compression_ratio": 1.2113821138211383, "no_speech_prob": 0.4638652205467224}, {"id": 425, "seek": 182040, "start": 1834.2800000000002, "end": 1835.2800000000002, "text": " Yeah.", "tokens": [51058, 865, 13, 51108], "temperature": 0.0, "avg_logprob": -0.23886282303754022, "compression_ratio": 1.2113821138211383, "no_speech_prob": 0.4638652205467224}, {"id": 426, "seek": 183528, "start": 1835.28, "end": 1861.76, "text": " I think when I was working on this, my motivation is, how can this help me do my work?", "tokens": [50364, 286, 519, 562, 286, 390, 1364, 322, 341, 11, 452, 12335, 307, 11, 577, 393, 341, 854, 385, 360, 452, 589, 30, 51688], "temperature": 0.0, "avg_logprob": -0.21883438183711126, "compression_ratio": 1.131578947368421, "no_speech_prob": 0.006288464646786451}, {"id": 427, "seek": 186176, "start": 1861.76, "end": 1871.68, "text": " And I think the IPython in the notebook, this system for doing exploratory data analysis,", "tokens": [50364, 400, 286, 519, 264, 8671, 88, 11943, 294, 264, 21060, 11, 341, 1185, 337, 884, 24765, 4745, 1412, 5215, 11, 50860], "temperature": 0.0, "avg_logprob": -0.22446030510796441, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.5993960499763489}, {"id": 428, "seek": 186176, "start": 1871.68, "end": 1876.04, "text": " manipulating data, that was really my focus at the time, because as a chemie, I work in", "tokens": [50860, 40805, 1412, 11, 300, 390, 534, 452, 1879, 412, 264, 565, 11, 570, 382, 257, 4771, 414, 11, 286, 589, 294, 51078], "temperature": 0.0, "avg_logprob": -0.22446030510796441, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.5993960499763489}, {"id": 429, "seek": 186176, "start": 1876.04, "end": 1883.0, "text": " the service department, and some of what my job is, is looking at trying to troubleshoot", "tokens": [51078, 264, 2643, 5882, 11, 293, 512, 295, 437, 452, 1691, 307, 11, 307, 1237, 412, 1382, 281, 15379, 24467, 51426], "temperature": 0.0, "avg_logprob": -0.22446030510796441, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.5993960499763489}, {"id": 430, "seek": 186176, "start": 1883.0, "end": 1888.4, "text": " problems on chemical process units, and so we get a lot of time series data, and so we", "tokens": [51426, 2740, 322, 7313, 1399, 6815, 11, 293, 370, 321, 483, 257, 688, 295, 565, 2638, 1412, 11, 293, 370, 321, 51696], "temperature": 0.0, "avg_logprob": -0.22446030510796441, "compression_ratio": 1.6118721461187215, "no_speech_prob": 0.5993960499763489}, {"id": 431, "seek": 188840, "start": 1888.4, "end": 1894.2, "text": " got to work through that data, and sometimes you get the data in really weird formats,", "tokens": [50364, 658, 281, 589, 807, 300, 1412, 11, 293, 2171, 291, 483, 264, 1412, 294, 534, 3657, 25879, 11, 50654], "temperature": 0.0, "avg_logprob": -0.16422673557581527, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.3770248293876648}, {"id": 432, "seek": 188840, "start": 1894.2, "end": 1898.88, "text": " and having something like pandas makes it really nice to manipulate and work with that", "tokens": [50654, 293, 1419, 746, 411, 4565, 296, 1669, 309, 534, 1481, 281, 20459, 293, 589, 365, 300, 50888], "temperature": 0.0, "avg_logprob": -0.16422673557581527, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.3770248293876648}, {"id": 433, "seek": 188840, "start": 1898.88, "end": 1903.8400000000001, "text": " data, and having something like Matplotlib is really nice for generating graphs to look", "tokens": [50888, 1412, 11, 293, 1419, 746, 411, 6789, 564, 310, 38270, 307, 534, 1481, 337, 17746, 24877, 281, 574, 51136], "temperature": 0.0, "avg_logprob": -0.16422673557581527, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.3770248293876648}, {"id": 434, "seek": 188840, "start": 1903.8400000000001, "end": 1907.48, "text": " at the data and share them with your colleagues.", "tokens": [51136, 412, 264, 1412, 293, 2073, 552, 365, 428, 7734, 13, 51318], "temperature": 0.0, "avg_logprob": -0.16422673557581527, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.3770248293876648}, {"id": 435, "seek": 188840, "start": 1907.48, "end": 1913.6000000000001, "text": " So really, that has been a lot of my motivation with this project.", "tokens": [51318, 407, 534, 11, 300, 575, 668, 257, 688, 295, 452, 12335, 365, 341, 1716, 13, 51624], "temperature": 0.0, "avg_logprob": -0.16422673557581527, "compression_ratio": 1.8038277511961722, "no_speech_prob": 0.3770248293876648}, {"id": 436, "seek": 191360, "start": 1913.6, "end": 1922.32, "text": " I think that the fact that it's kind of been this nice environment is a really nice benefit", "tokens": [50364, 286, 519, 300, 264, 1186, 300, 309, 311, 733, 295, 668, 341, 1481, 2823, 307, 257, 534, 1481, 5121, 50800], "temperature": 0.0, "avg_logprob": -0.15833262908153045, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.09005773067474365}, {"id": 437, "seek": 191360, "start": 1922.32, "end": 1928.36, "text": " or secondary effect of all this.", "tokens": [50800, 420, 11396, 1802, 295, 439, 341, 13, 51102], "temperature": 0.0, "avg_logprob": -0.15833262908153045, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.09005773067474365}, {"id": 438, "seek": 191360, "start": 1928.36, "end": 1934.56, "text": " I haven't really done a whole lot to promote it over the years, but I think there's probably", "tokens": [51102, 286, 2378, 380, 534, 1096, 257, 1379, 688, 281, 9773, 309, 670, 264, 924, 11, 457, 286, 519, 456, 311, 1391, 51412], "temperature": 0.0, "avg_logprob": -0.15833262908153045, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.09005773067474365}, {"id": 439, "seek": 191360, "start": 1934.56, "end": 1942.52, "text": " some good lessons here for people that are developing other clients, but that's not for", "tokens": [51412, 512, 665, 8820, 510, 337, 561, 300, 366, 6416, 661, 6982, 11, 457, 300, 311, 406, 337, 51810], "temperature": 0.0, "avg_logprob": -0.15833262908153045, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.09005773067474365}, {"id": 440, "seek": 191360, "start": 1942.52, "end": 1943.52, "text": " me.", "tokens": [51810, 385, 13, 51860], "temperature": 0.0, "avg_logprob": -0.15833262908153045, "compression_ratio": 1.6010362694300517, "no_speech_prob": 0.09005773067474365}, {"id": 441, "seek": 194352, "start": 1943.52, "end": 1953.56, "text": " Anyways, so we also have a help browser, so it pops up a buffer, and you can space through", "tokens": [50364, 15585, 11, 370, 321, 611, 362, 257, 854, 11185, 11, 370, 309, 16795, 493, 257, 21762, 11, 293, 291, 393, 1901, 807, 50866], "temperature": 0.0, "avg_logprob": -0.25558250355270673, "compression_ratio": 1.376923076923077, "no_speech_prob": 0.0758146271109581}, {"id": 442, "seek": 194352, "start": 1953.56, "end": 1963.84, "text": " it if it's, I forgot, you can go through it, right, it makes it a little easier to read.", "tokens": [50866, 309, 498, 309, 311, 11, 286, 5298, 11, 291, 393, 352, 807, 309, 11, 558, 11, 309, 1669, 309, 257, 707, 3571, 281, 1401, 13, 51380], "temperature": 0.0, "avg_logprob": -0.25558250355270673, "compression_ratio": 1.376923076923077, "no_speech_prob": 0.0758146271109581}, {"id": 443, "seek": 196384, "start": 1963.84, "end": 1978.56, "text": " If you're really masochistic, you can also do pop-ups, it'll do a pop-up.", "tokens": [50364, 759, 291, 434, 534, 2300, 8997, 3142, 11, 291, 393, 611, 360, 1665, 12, 7528, 11, 309, 603, 360, 257, 1665, 12, 1010, 13, 51100], "temperature": 0.0, "avg_logprob": -0.13876413305600485, "compression_ratio": 1.28, "no_speech_prob": 0.13657641410827637}, {"id": 444, "seek": 196384, "start": 1978.56, "end": 1989.36, "text": " There's a fairly good integration with the debugger support, so you'll get errors when", "tokens": [51100, 821, 311, 257, 6457, 665, 10980, 365, 264, 24083, 1321, 1406, 11, 370, 291, 603, 483, 13603, 562, 51640], "temperature": 0.0, "avg_logprob": -0.13876413305600485, "compression_ratio": 1.28, "no_speech_prob": 0.13657641410827637}, {"id": 445, "seek": 198936, "start": 1989.36, "end": 1991.8799999999999, "text": " things don't work.", "tokens": [50364, 721, 500, 380, 589, 13, 50490], "temperature": 0.0, "avg_logprob": -0.1784800065530313, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.47632110118865967}, {"id": 446, "seek": 198936, "start": 1991.8799999999999, "end": 1995.1999999999998, "text": " You get tracebacks.", "tokens": [50490, 509, 483, 13508, 17758, 13, 50656], "temperature": 0.0, "avg_logprob": -0.1784800065530313, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.47632110118865967}, {"id": 447, "seek": 198936, "start": 1995.1999999999998, "end": 2002.04, "text": " If you want to get a full view of the traceback, this is not terribly interesting because there's", "tokens": [50656, 759, 291, 528, 281, 483, 257, 1577, 1910, 295, 264, 13508, 3207, 11, 341, 307, 406, 22903, 1880, 570, 456, 311, 50998], "temperature": 0.0, "avg_logprob": -0.1784800065530313, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.47632110118865967}, {"id": 448, "seek": 198936, "start": 2002.04, "end": 2004.4399999999998, "text": " only one level to it.", "tokens": [50998, 787, 472, 1496, 281, 309, 13, 51118], "temperature": 0.0, "avg_logprob": -0.1784800065530313, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.47632110118865967}, {"id": 449, "seek": 198936, "start": 2004.4399999999998, "end": 2016.9199999999998, "text": " If I think it's return, that didn't work, unfortunately, but you can jump to source from the tracebacks.", "tokens": [51118, 759, 286, 519, 309, 311, 2736, 11, 300, 994, 380, 589, 11, 7015, 11, 457, 291, 393, 3012, 281, 4009, 490, 264, 13508, 17758, 13, 51742], "temperature": 0.0, "avg_logprob": -0.1784800065530313, "compression_ratio": 1.5290697674418605, "no_speech_prob": 0.47632110118865967}, {"id": 450, "seek": 201692, "start": 2016.92, "end": 2028.88, "text": " We'll see what this next one, hey look, there's raccoons, let's do this.", "tokens": [50364, 492, 603, 536, 437, 341, 958, 472, 11, 4177, 574, 11, 456, 311, 4129, 1291, 892, 11, 718, 311, 360, 341, 13, 50962], "temperature": 0.0, "avg_logprob": -0.2757688204447428, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.4222482144832611}, {"id": 451, "seek": 201692, "start": 2028.88, "end": 2032.52, "text": " So there's a traceback of that.", "tokens": [50962, 407, 456, 311, 257, 13508, 3207, 295, 300, 13, 51144], "temperature": 0.0, "avg_logprob": -0.2757688204447428, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.4222482144832611}, {"id": 452, "seek": 201692, "start": 2032.52, "end": 2037.48, "text": " So I can actually jump to that file, fingers crossed, there we go, we just jumped to the", "tokens": [51144, 407, 286, 393, 767, 3012, 281, 300, 3991, 11, 7350, 14622, 11, 456, 321, 352, 11, 321, 445, 13864, 281, 264, 51392], "temperature": 0.0, "avg_logprob": -0.2757688204447428, "compression_ratio": 1.4191176470588236, "no_speech_prob": 0.4222482144832611}, {"id": 453, "seek": 203748, "start": 2037.48, "end": 2047.64, "text": " file and the line that was referenced in the traceback.", "tokens": [50364, 3991, 293, 264, 1622, 300, 390, 32734, 294, 264, 13508, 3207, 13, 50872], "temperature": 0.0, "avg_logprob": -0.22543068786165607, "compression_ratio": 1.4967741935483871, "no_speech_prob": 0.40716880559921265}, {"id": 454, "seek": 203748, "start": 2047.64, "end": 2057.92, "text": " If I want, I can go into the debugger, if I want to know, and see it popped up for me,", "tokens": [50872, 759, 286, 528, 11, 286, 393, 352, 666, 264, 24083, 1321, 11, 498, 286, 528, 281, 458, 11, 293, 536, 309, 21545, 493, 337, 385, 11, 51386], "temperature": 0.0, "avg_logprob": -0.22543068786165607, "compression_ratio": 1.4967741935483871, "no_speech_prob": 0.40716880559921265}, {"id": 455, "seek": 203748, "start": 2057.92, "end": 2064.68, "text": " it's already showing me in the code where this error occurred, if you can see it, there's", "tokens": [51386, 309, 311, 1217, 4099, 385, 294, 264, 3089, 689, 341, 6713, 11068, 11, 498, 291, 393, 536, 309, 11, 456, 311, 51724], "temperature": 0.0, "avg_logprob": -0.22543068786165607, "compression_ratio": 1.4967741935483871, "no_speech_prob": 0.40716880559921265}, {"id": 456, "seek": 206468, "start": 2064.68, "end": 2071.12, "text": " a little arrow, tiny, tiny, tiny little arrow in the fringe.", "tokens": [50364, 257, 707, 11610, 11, 5870, 11, 5870, 11, 5870, 707, 11610, 294, 264, 38764, 13, 50686], "temperature": 0.0, "avg_logprob": -0.15027833707404858, "compression_ratio": 1.5686274509803921, "no_speech_prob": 0.17322389781475067}, {"id": 457, "seek": 206468, "start": 2071.12, "end": 2080.16, "text": " I can go up a stack and you can see it's moved with us.", "tokens": [50686, 286, 393, 352, 493, 257, 8630, 293, 291, 393, 536, 309, 311, 4259, 365, 505, 13, 51138], "temperature": 0.0, "avg_logprob": -0.15027833707404858, "compression_ratio": 1.5686274509803921, "no_speech_prob": 0.17322389781475067}, {"id": 458, "seek": 206468, "start": 2080.16, "end": 2087.6, "text": " I can basically do the stuff that you would normally do in the Python debugger, for the", "tokens": [51138, 286, 393, 1936, 360, 264, 1507, 300, 291, 576, 5646, 360, 294, 264, 15329, 24083, 1321, 11, 337, 264, 51510], "temperature": 0.0, "avg_logprob": -0.15027833707404858, "compression_ratio": 1.5686274509803921, "no_speech_prob": 0.17322389781475067}, {"id": 459, "seek": 206468, "start": 2087.6, "end": 2089.64, "text": " most part supports that completely.", "tokens": [51510, 881, 644, 9346, 300, 2584, 13, 51612], "temperature": 0.0, "avg_logprob": -0.15027833707404858, "compression_ratio": 1.5686274509803921, "no_speech_prob": 0.17322389781475067}, {"id": 460, "seek": 208964, "start": 2089.64, "end": 2097.24, "text": " I don't know if you get that in JupyterLab yet, but I've actually used it a few times", "tokens": [50364, 286, 500, 380, 458, 498, 291, 483, 300, 294, 22125, 88, 391, 37880, 1939, 11, 457, 286, 600, 767, 1143, 309, 257, 1326, 1413, 50744], "temperature": 0.0, "avg_logprob": -0.2127253668648856, "compression_ratio": 1.297872340425532, "no_speech_prob": 0.08032915741205215}, {"id": 461, "seek": 208964, "start": 2097.24, "end": 2105.0, "text": " and it's very useful.", "tokens": [50744, 293, 309, 311, 588, 4420, 13, 51132], "temperature": 0.0, "avg_logprob": -0.2127253668648856, "compression_ratio": 1.297872340425532, "no_speech_prob": 0.08032915741205215}, {"id": 462, "seek": 208964, "start": 2105.0, "end": 2111.8799999999997, "text": " Now okay, somebody mentioned hi, I'm going to have to change the cell type.", "tokens": [51132, 823, 1392, 11, 2618, 2835, 4879, 11, 286, 478, 516, 281, 362, 281, 1319, 264, 2815, 2010, 13, 51476], "temperature": 0.0, "avg_logprob": -0.2127253668648856, "compression_ratio": 1.297872340425532, "no_speech_prob": 0.08032915741205215}, {"id": 463, "seek": 211188, "start": 2111.88, "end": 2122.96, "text": " So this is a Python kernel, prior to this I installed the hi module for this kernel.", "tokens": [50364, 407, 341, 307, 257, 15329, 28256, 11, 4059, 281, 341, 286, 8899, 264, 4879, 10088, 337, 341, 28256, 13, 50918], "temperature": 0.0, "avg_logprob": -0.29739846988600127, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.04466846585273743}, {"id": 464, "seek": 211188, "start": 2122.96, "end": 2135.7200000000003, "text": " You can set in-ine a special cell type, call it the cell, the hind cell, and it will execute", "tokens": [50918, 509, 393, 992, 294, 12, 533, 257, 2121, 2815, 2010, 11, 818, 309, 264, 2815, 11, 264, 20138, 2815, 11, 293, 309, 486, 14483, 51556], "temperature": 0.0, "avg_logprob": -0.29739846988600127, "compression_ratio": 1.4047619047619047, "no_speech_prob": 0.04466846585273743}, {"id": 465, "seek": 213572, "start": 2135.72, "end": 2143.2, "text": " in Python, if you don't believe me, watch this.", "tokens": [50364, 294, 15329, 11, 498, 291, 500, 380, 1697, 385, 11, 1159, 341, 13, 50738], "temperature": 0.0, "avg_logprob": -0.2246369912590779, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.2686353921890259}, {"id": 466, "seek": 213572, "start": 2143.2, "end": 2153.3199999999997, "text": " So I'm going to set this variable, hi there, and oops, that shouldn't be, there we go.", "tokens": [50738, 407, 286, 478, 516, 281, 992, 341, 7006, 11, 4879, 456, 11, 293, 34166, 11, 300, 4659, 380, 312, 11, 456, 321, 352, 13, 51244], "temperature": 0.0, "avg_logprob": -0.2246369912590779, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.2686353921890259}, {"id": 467, "seek": 213572, "start": 2153.3199999999997, "end": 2159.8399999999997, "text": " This next cell is Python, there it is.", "tokens": [51244, 639, 958, 2815, 307, 15329, 11, 456, 309, 307, 13, 51570], "temperature": 0.0, "avg_logprob": -0.2246369912590779, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.2686353921890259}, {"id": 468, "seek": 213572, "start": 2159.8399999999997, "end": 2164.08, "text": " So I don't know why you do that, but you can.", "tokens": [51570, 407, 286, 500, 380, 458, 983, 291, 360, 300, 11, 457, 291, 393, 13, 51782], "temperature": 0.0, "avg_logprob": -0.2246369912590779, "compression_ratio": 1.4797297297297298, "no_speech_prob": 0.2686353921890259}, {"id": 469, "seek": 216408, "start": 2164.08, "end": 2172.2799999999997, "text": " You can also use the load magic, as you can see, it will create a new cell with the file.", "tokens": [50364, 509, 393, 611, 764, 264, 3677, 5585, 11, 382, 291, 393, 536, 11, 309, 486, 1884, 257, 777, 2815, 365, 264, 3991, 13, 50774], "temperature": 0.0, "avg_logprob": -0.15995033582051596, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.061797089874744415}, {"id": 470, "seek": 216408, "start": 2172.2799999999997, "end": 2177.92, "text": " There's a special, I don't know if you're org, if you're aware of the edit source blocks,", "tokens": [50774, 821, 311, 257, 2121, 11, 286, 500, 380, 458, 498, 291, 434, 14045, 11, 498, 291, 434, 3650, 295, 264, 8129, 4009, 8474, 11, 51056], "temperature": 0.0, "avg_logprob": -0.15995033582051596, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.061797089874744415}, {"id": 471, "seek": 216408, "start": 2177.92, "end": 2183.12, "text": " it pops up a new buffer with the source and it's in the mode of the code language that", "tokens": [51056, 309, 16795, 493, 257, 777, 21762, 365, 264, 4009, 293, 309, 311, 294, 264, 4391, 295, 264, 3089, 2856, 300, 51316], "temperature": 0.0, "avg_logprob": -0.15995033582051596, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.061797089874744415}, {"id": 472, "seek": 216408, "start": 2183.12, "end": 2187.24, "text": " the code is, we can do something similar with in, so I just did that here.", "tokens": [51316, 264, 3089, 307, 11, 321, 393, 360, 746, 2531, 365, 294, 11, 370, 286, 445, 630, 300, 510, 13, 51522], "temperature": 0.0, "avg_logprob": -0.15995033582051596, "compression_ratio": 1.6715686274509804, "no_speech_prob": 0.061797089874744415}, {"id": 473, "seek": 218724, "start": 2187.24, "end": 2194.4799999999996, "text": " So here's basically a Python buffer with all the benefits that that bring with it, because", "tokens": [50364, 407, 510, 311, 1936, 257, 15329, 21762, 365, 439, 264, 5311, 300, 300, 1565, 365, 309, 11, 570, 50726], "temperature": 0.0, "avg_logprob": -0.14426212034363678, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.23357492685317993}, {"id": 474, "seek": 218724, "start": 2194.4799999999996, "end": 2202.6, "text": " in Emacs there's quite a few packages out there that make editing Python better.", "tokens": [50726, 294, 3968, 44937, 456, 311, 1596, 257, 1326, 17401, 484, 456, 300, 652, 10000, 15329, 1101, 13, 51132], "temperature": 0.0, "avg_logprob": -0.14426212034363678, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.23357492685317993}, {"id": 475, "seek": 218724, "start": 2202.6, "end": 2212.68, "text": " I can execute it, I can modify, I'm not going to do that, and then we're back in the notebook.", "tokens": [51132, 286, 393, 14483, 309, 11, 286, 393, 16927, 11, 286, 478, 406, 516, 281, 360, 300, 11, 293, 550, 321, 434, 646, 294, 264, 21060, 13, 51636], "temperature": 0.0, "avg_logprob": -0.14426212034363678, "compression_ratio": 1.4943820224719102, "no_speech_prob": 0.23357492685317993}, {"id": 476, "seek": 221268, "start": 2212.68, "end": 2221.56, "text": " Now I'm running out of time, so real quickly, we're going to go to, did I open it, test", "tokens": [50364, 823, 286, 478, 2614, 484, 295, 565, 11, 370, 957, 2661, 11, 321, 434, 516, 281, 352, 281, 11, 630, 286, 1269, 309, 11, 1500, 50808], "temperature": 0.0, "avg_logprob": -0.3131969158466046, "compression_ratio": 1.3740458015267176, "no_speech_prob": 0.04467388615012169}, {"id": 477, "seek": 221268, "start": 2221.56, "end": 2236.64, "text": " Python, all right, I'm going to connect this, connect to notebook buffer, so we can actually", "tokens": [50808, 15329, 11, 439, 558, 11, 286, 478, 516, 281, 1745, 341, 11, 1745, 281, 21060, 21762, 11, 370, 321, 393, 767, 51562], "temperature": 0.0, "avg_logprob": -0.3131969158466046, "compression_ratio": 1.3740458015267176, "no_speech_prob": 0.04467388615012169}, {"id": 478, "seek": 223664, "start": 2236.64, "end": 2246.0, "text": " execute this, I'm going to comment that out, and it goes to what we call the, what I call,", "tokens": [50364, 14483, 341, 11, 286, 478, 516, 281, 2871, 300, 484, 11, 293, 309, 1709, 281, 437, 321, 818, 264, 11, 437, 286, 818, 11, 50832], "temperature": 0.0, "avg_logprob": -0.1953742386864834, "compression_ratio": 1.4685314685314685, "no_speech_prob": 0.503449559211731}, {"id": 479, "seek": 223664, "start": 2246.0, "end": 2249.08, "text": " what is called the shared buffer.", "tokens": [50832, 437, 307, 1219, 264, 5507, 21762, 13, 50986], "temperature": 0.0, "avg_logprob": -0.1953742386864834, "compression_ratio": 1.4685314685314685, "no_speech_prob": 0.503449559211731}, {"id": 480, "seek": 223664, "start": 2249.08, "end": 2266.44, "text": " You don't see anything there, but we can do this, which didn't work the way I wanted,", "tokens": [50986, 509, 500, 380, 536, 1340, 456, 11, 457, 321, 393, 360, 341, 11, 597, 994, 380, 589, 264, 636, 286, 1415, 11, 51854], "temperature": 0.0, "avg_logprob": -0.1953742386864834, "compression_ratio": 1.4685314685314685, "no_speech_prob": 0.503449559211731}, {"id": 481, "seek": 226644, "start": 2266.44, "end": 2271.28, "text": " but I can go back to the notebook and you see we've created this digits variable, and", "tokens": [50364, 457, 286, 393, 352, 646, 281, 264, 21060, 293, 291, 536, 321, 600, 2942, 341, 27011, 7006, 11, 293, 50606], "temperature": 0.0, "avg_logprob": -0.19197264025288244, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.16857725381851196}, {"id": 482, "seek": 226644, "start": 2271.28, "end": 2276.64, "text": " it should be available in the notebook, and there it is.", "tokens": [50606, 309, 820, 312, 2435, 294, 264, 21060, 11, 293, 456, 309, 307, 13, 50874], "temperature": 0.0, "avg_logprob": -0.19197264025288244, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.16857725381851196}, {"id": 483, "seek": 226644, "start": 2276.64, "end": 2284.6, "text": " Now in this Python buffer, I get all the goodies that I have in the notebook, so load digits,", "tokens": [50874, 823, 294, 341, 15329, 21762, 11, 286, 483, 439, 264, 44072, 300, 286, 362, 294, 264, 21060, 11, 370, 3677, 27011, 11, 51272], "temperature": 0.0, "avg_logprob": -0.19197264025288244, "compression_ratio": 1.5526315789473684, "no_speech_prob": 0.16857725381851196}, {"id": 484, "seek": 228460, "start": 2284.6, "end": 2305.4, "text": " I can bring up the pop-up help, I get, I can jump to source, I didn't find it, darn it,", "tokens": [50364, 286, 393, 1565, 493, 264, 1665, 12, 1010, 854, 11, 286, 483, 11, 286, 393, 3012, 281, 4009, 11, 286, 994, 380, 915, 309, 11, 29063, 309, 11, 51404], "temperature": 0.0, "avg_logprob": -0.1608026921749115, "compression_ratio": 1.1153846153846154, "no_speech_prob": 0.28120002150535583}, {"id": 485, "seek": 230540, "start": 2305.4, "end": 2316.12, "text": " and auto-completion, I think I mentioned auto-completion, all right, datasets, I haven't imported the", "tokens": [50364, 293, 8399, 12, 1112, 14657, 313, 11, 286, 519, 286, 2835, 8399, 12, 1112, 14657, 313, 11, 439, 558, 11, 42856, 11, 286, 2378, 380, 25524, 264, 50900], "temperature": 0.0, "avg_logprob": -0.19407537032146843, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.6400355696678162}, {"id": 486, "seek": 230540, "start": 2316.12, "end": 2323.96, "text": " module, and Jedi probably doesn't know about this, but we get the auto-completion, I'm", "tokens": [50900, 10088, 11, 293, 21746, 1391, 1177, 380, 458, 466, 341, 11, 457, 321, 483, 264, 8399, 12, 1112, 14657, 313, 11, 286, 478, 51292], "temperature": 0.0, "avg_logprob": -0.19407537032146843, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.6400355696678162}, {"id": 487, "seek": 230540, "start": 2323.96, "end": 2328.12, "text": " hurrying myself because I want to leave you time for some questions, there's this one", "tokens": [51292, 11025, 278, 2059, 570, 286, 528, 281, 1856, 291, 565, 337, 512, 1651, 11, 456, 311, 341, 472, 51500], "temperature": 0.0, "avg_logprob": -0.19407537032146843, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.6400355696678162}, {"id": 488, "seek": 230540, "start": 2328.12, "end": 2334.44, "text": " last thing, there's this thing called import magic, that if I were to try to execute this", "tokens": [51500, 1036, 551, 11, 456, 311, 341, 551, 1219, 974, 5585, 11, 300, 498, 286, 645, 281, 853, 281, 14483, 341, 51816], "temperature": 0.0, "avg_logprob": -0.19407537032146843, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.6400355696678162}, {"id": 489, "seek": 233444, "start": 2334.44, "end": 2342.6, "text": " and really what's happening when I execute is it's doing a run on the file, magic run,", "tokens": [50364, 293, 534, 437, 311, 2737, 562, 286, 14483, 307, 309, 311, 884, 257, 1190, 322, 264, 3991, 11, 5585, 1190, 11, 50772], "temperature": 0.0, "avg_logprob": -0.18205252937648608, "compression_ratio": 1.5084745762711864, "no_speech_prob": 0.07153499871492386}, {"id": 490, "seek": 233444, "start": 2342.6, "end": 2347.84, "text": " it's not like lists where you can redefine individual functions, you have to reload the", "tokens": [50772, 309, 311, 406, 411, 14511, 689, 291, 393, 38818, 533, 2609, 6828, 11, 291, 362, 281, 25628, 264, 51034], "temperature": 0.0, "avg_logprob": -0.18205252937648608, "compression_ratio": 1.5084745762711864, "no_speech_prob": 0.07153499871492386}, {"id": 491, "seek": 233444, "start": 2347.84, "end": 2360.12, "text": " whole file, but anyways, so there's this package called import magic, and it'll try and fix,", "tokens": [51034, 1379, 3991, 11, 457, 13448, 11, 370, 456, 311, 341, 7372, 1219, 974, 5585, 11, 293, 309, 603, 853, 293, 3191, 11, 51648], "temperature": 0.0, "avg_logprob": -0.18205252937648608, "compression_ratio": 1.5084745762711864, "no_speech_prob": 0.07153499871492386}, {"id": 492, "seek": 236012, "start": 2360.12, "end": 2367.24, "text": " so as you can see, I hadn't imported the OS path join, so there's somewhere in I'm,", "tokens": [50364, 370, 382, 291, 393, 536, 11, 286, 8782, 380, 25524, 264, 12731, 3100, 3917, 11, 370, 456, 311, 4079, 294, 286, 478, 11, 50720], "temperature": 0.0, "avg_logprob": -0.20898672822233919, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.017440466210246086}, {"id": 493, "seek": 236012, "start": 2367.24, "end": 2373.64, "text": " there's an error saying it didn't know about that, so I can fix that, and as you can see", "tokens": [50720, 456, 311, 364, 6713, 1566, 309, 994, 380, 458, 466, 300, 11, 370, 286, 393, 3191, 300, 11, 293, 382, 291, 393, 536, 51040], "temperature": 0.0, "avg_logprob": -0.20898672822233919, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.017440466210246086}, {"id": 494, "seek": 236012, "start": 2373.64, "end": 2385.44, "text": " it edited, and I could probably, there we go, and it erred because I didn't save the buffer", "tokens": [51040, 309, 23016, 11, 293, 286, 727, 1391, 11, 456, 321, 352, 11, 293, 309, 1189, 986, 570, 286, 994, 380, 3155, 264, 21762, 51630], "temperature": 0.0, "avg_logprob": -0.20898672822233919, "compression_ratio": 1.5903614457831325, "no_speech_prob": 0.017440466210246086}, {"id": 495, "seek": 238544, "start": 2385.44, "end": 2400.0, "text": " before trying to connect, so, why is it doing that, all right, well, so much for that demo,", "tokens": [50364, 949, 1382, 281, 1745, 11, 370, 11, 983, 307, 309, 884, 300, 11, 439, 558, 11, 731, 11, 370, 709, 337, 300, 10723, 11, 51092], "temperature": 0.0, "avg_logprob": -0.23943885803222656, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.25655123591423035}, {"id": 496, "seek": 238544, "start": 2400.0, "end": 2408.48, "text": " anyways, I guess that was just a talk, an introduction to Ayn and its features, I need", "tokens": [51092, 13448, 11, 286, 2041, 300, 390, 445, 257, 751, 11, 364, 9339, 281, 316, 2534, 293, 1080, 4122, 11, 286, 643, 51516], "temperature": 0.0, "avg_logprob": -0.23943885803222656, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.25655123591423035}, {"id": 497, "seek": 238544, "start": 2408.48, "end": 2415.12, "text": " to stop now, so I wanted to thank you all for coming, and you can find me, once this", "tokens": [51516, 281, 1590, 586, 11, 370, 286, 1415, 281, 1309, 291, 439, 337, 1348, 11, 293, 291, 393, 915, 385, 11, 1564, 341, 51848], "temperature": 0.0, "avg_logprob": -0.23943885803222656, "compression_ratio": 1.5380116959064327, "no_speech_prob": 0.25655123591423035}, {"id": 498, "seek": 241512, "start": 2415.2, "end": 2421.88, "text": " gets published, there's contact information, look for me on GitHub or on e-mail, and thank", "tokens": [50368, 2170, 6572, 11, 456, 311, 3385, 1589, 11, 574, 337, 385, 322, 23331, 420, 322, 308, 12, 11799, 11, 293, 1309, 50702], "temperature": 0.0, "avg_logprob": -0.40727537870407104, "compression_ratio": 1.1578947368421053, "no_speech_prob": 0.16424314677715302}, {"id": 499, "seek": 241512, "start": 2421.88, "end": 2423.2, "text": " you all for coming.", "tokens": [50702, 291, 439, 337, 1348, 13, 50768], "temperature": 0.0, "avg_logprob": -0.40727537870407104, "compression_ratio": 1.1578947368421053, "no_speech_prob": 0.16424314677715302}, {"id": 500, "seek": 242320, "start": 2423.2, "end": 2450.24, "text": " I didn't play with it too much, but it will connect to a Callisto high, and works mostly", "tokens": [50364, 286, 994, 380, 862, 365, 309, 886, 709, 11, 457, 309, 486, 1745, 281, 257, 7807, 9334, 1090, 11, 293, 1985, 5240, 51716], "temperature": 0.0, "avg_logprob": -0.2845644217271071, "compression_ratio": 1.0731707317073171, "no_speech_prob": 0.5224975943565369}, {"id": 501, "seek": 245024, "start": 2450.4799999999996, "end": 2459.52, "text": " the problem with Ayn is it's very Python centric still, so the notebook itself, it probably won't", "tokens": [50376, 264, 1154, 365, 316, 2534, 307, 309, 311, 588, 15329, 1489, 1341, 920, 11, 370, 264, 21060, 2564, 11, 309, 1391, 1582, 380, 50828], "temperature": 0.0, "avg_logprob": -0.19829427494722254, "compression_ratio": 1.5, "no_speech_prob": 0.6179729104042053}, {"id": 502, "seek": 245024, "start": 2459.52, "end": 2466.4799999999996, "text": " give you this nice syntax formatting as you expect for list code, so it's not great for", "tokens": [50828, 976, 291, 341, 1481, 28431, 39366, 382, 291, 2066, 337, 1329, 3089, 11, 370, 309, 311, 406, 869, 337, 51176], "temperature": 0.0, "avg_logprob": -0.19829427494722254, "compression_ratio": 1.5, "no_speech_prob": 0.6179729104042053}, {"id": 503, "seek": 245024, "start": 2467.68, "end": 2474.16, "text": " writing large expressions, but if you were to do a buffer, and then connect it to", "tokens": [51236, 3579, 2416, 15277, 11, 457, 498, 291, 645, 281, 360, 257, 21762, 11, 293, 550, 1745, 309, 281, 51560], "temperature": 0.0, "avg_logprob": -0.19829427494722254, "compression_ratio": 1.5, "no_speech_prob": 0.6179729104042053}, {"id": 504, "seek": 247416, "start": 2475.12, "end": 2480.72, "text": " a high buffer, and connect it to the kernel, I think that would work, if not, it might not", "tokens": [50412, 257, 1090, 21762, 11, 293, 1745, 309, 281, 264, 28256, 11, 286, 519, 300, 576, 589, 11, 498, 406, 11, 309, 1062, 406, 50692], "temperature": 0.0, "avg_logprob": -0.24190033806694877, "compression_ratio": 1.4533333333333334, "no_speech_prob": 0.019119134172797203}, {"id": 505, "seek": 247416, "start": 2480.72, "end": 2483.44, "text": " be too much work to get it to happen.", "tokens": [50692, 312, 886, 709, 589, 281, 483, 309, 281, 1051, 13, 50828], "temperature": 0.0, "avg_logprob": -0.24190033806694877, "compression_ratio": 1.4533333333333334, "no_speech_prob": 0.019119134172797203}, {"id": 506, "seek": 247416, "start": 2483.44, "end": 2497.68, "text": " So, what I do to get it to intermingle, I wrote a little Pi function that basically wraps", "tokens": [50828, 407, 11, 437, 286, 360, 281, 483, 309, 281, 728, 2810, 306, 11, 286, 4114, 257, 707, 17741, 2445, 300, 1936, 25831, 51540], "temperature": 0.0, "avg_logprob": -0.24190033806694877, "compression_ratio": 1.4533333333333334, "no_speech_prob": 0.019119134172797203}, {"id": 507, "seek": 249768, "start": 2497.68, "end": 2507.12, "text": " calls to the syntax, you know, the parser and evaluator, and then Python, what I do on", "tokens": [50364, 5498, 281, 264, 28431, 11, 291, 458, 11, 264, 21156, 260, 293, 6133, 1639, 11, 293, 550, 15329, 11, 437, 286, 360, 322, 50836], "temperature": 0.0, "avg_logprob": -0.16149158305949993, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.04207102209329605}, {"id": 508, "seek": 249768, "start": 2507.12, "end": 2512.96, "text": " Emacs is I wrap the text of that cell, and then send it to the kernel and execute that function.", "tokens": [50836, 3968, 44937, 307, 286, 7019, 264, 2487, 295, 300, 2815, 11, 293, 550, 2845, 309, 281, 264, 28256, 293, 14483, 300, 2445, 13, 51128], "temperature": 0.0, "avg_logprob": -0.16149158305949993, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.04207102209329605}, {"id": 509, "seek": 249768, "start": 2514.48, "end": 2517.68, "text": " And it works, I was surprised it works, but it does.", "tokens": [51204, 400, 309, 1985, 11, 286, 390, 6100, 309, 1985, 11, 457, 309, 775, 13, 51364], "temperature": 0.0, "avg_logprob": -0.16149158305949993, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.04207102209329605}, {"id": 510, "seek": 249768, "start": 2518.56, "end": 2522.3999999999996, "text": " I don't do a whole lot in high, I haven't found a use case for it in what I do, but", "tokens": [51408, 286, 500, 380, 360, 257, 1379, 688, 294, 1090, 11, 286, 2378, 380, 1352, 257, 764, 1389, 337, 309, 294, 437, 286, 360, 11, 457, 51600], "temperature": 0.0, "avg_logprob": -0.16149158305949993, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.04207102209329605}, {"id": 511, "seek": 249768, "start": 2522.3999999999996, "end": 2524.64, "text": " I thought it was kind of cool that I could get it to work.", "tokens": [51600, 286, 1194, 309, 390, 733, 295, 1627, 300, 286, 727, 483, 309, 281, 589, 13, 51712], "temperature": 0.0, "avg_logprob": -0.16149158305949993, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.04207102209329605}, {"id": 512, "seek": 252768, "start": 2528.64, "end": 2540.0, "text": " I wonder if I have...", "tokens": [50412, 286, 2441, 498, 286, 362, 485, 50980], "temperature": 0.0, "avg_logprob": -0.24503728866577149, "compression_ratio": 1.3852459016393444, "no_speech_prob": 0.000969716114923358}, {"id": 513, "seek": 252768, "start": 2542.24, "end": 2547.68, "text": " It will try to print data frames, and it kind of looks like a text table,", "tokens": [51092, 467, 486, 853, 281, 4482, 1412, 12083, 11, 293, 309, 733, 295, 1542, 411, 257, 2487, 3199, 11, 51364], "temperature": 0.0, "avg_logprob": -0.24503728866577149, "compression_ratio": 1.3852459016393444, "no_speech_prob": 0.000969716114923358}, {"id": 514, "seek": 252768, "start": 2548.48, "end": 2551.7599999999998, "text": " which, if you have a really wide pandas frame, looks really, really ugly,", "tokens": [51404, 597, 11, 498, 291, 362, 257, 534, 4874, 4565, 296, 3920, 11, 1542, 534, 11, 534, 12246, 11, 51568], "temperature": 0.0, "avg_logprob": -0.24503728866577149, "compression_ratio": 1.3852459016393444, "no_speech_prob": 0.000969716114923358}, {"id": 515, "seek": 255176, "start": 2552.48, "end": 2554.4, "text": " but it will kind of try to do that.", "tokens": [50400, 457, 309, 486, 733, 295, 853, 281, 360, 300, 13, 50496], "temperature": 0.0, "avg_logprob": -0.19253263802363954, "compression_ratio": 1.337837837837838, "no_speech_prob": 0.029752757400274277}, {"id": 516, "seek": 255176, "start": 2555.36, "end": 2561.2000000000003, "text": " HTML, you know, it's basically Emacs HTML, so it will show the markup.", "tokens": [50544, 17995, 11, 291, 458, 11, 309, 311, 1936, 3968, 44937, 17995, 11, 370, 309, 486, 855, 264, 1491, 1010, 13, 50836], "temperature": 0.0, "avg_logprob": -0.19253263802363954, "compression_ratio": 1.337837837837838, "no_speech_prob": 0.029752757400274277}, {"id": 517, "seek": 255176, "start": 2563.44, "end": 2571.84, "text": " If you install the right package, you can get some latech, like inline image replacement of", "tokens": [50948, 759, 291, 3625, 264, 558, 7372, 11, 291, 393, 483, 512, 3469, 339, 11, 411, 294, 1889, 3256, 14419, 295, 51368], "temperature": 0.0, "avg_logprob": -0.19253263802363954, "compression_ratio": 1.337837837837838, "no_speech_prob": 0.029752757400274277}, {"id": 518, "seek": 257184, "start": 2571.84, "end": 2573.28, "text": " latech and your markdown cells.", "tokens": [50364, 3469, 339, 293, 428, 1491, 5093, 5438, 13, 50436], "temperature": 0.0, "avg_logprob": -0.3028330405553182, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06464444100856781}, {"id": 519, "seek": 257184, "start": 2575.84, "end": 2576.4, "text": " No, it...", "tokens": [50564, 883, 11, 309, 485, 50592], "temperature": 0.0, "avg_logprob": -0.3028330405553182, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06464444100856781}, {"id": 520, "seek": 257184, "start": 2580.8, "end": 2581.92, "text": " What was the name of that?", "tokens": [50812, 708, 390, 264, 1315, 295, 300, 30, 50868], "temperature": 0.0, "avg_logprob": -0.3028330405553182, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06464444100856781}, {"id": 521, "seek": 257184, "start": 2581.92, "end": 2582.96, "text": " Let's see if I can find it.", "tokens": [50868, 961, 311, 536, 498, 286, 393, 915, 309, 13, 50920], "temperature": 0.0, "avg_logprob": -0.3028330405553182, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06464444100856781}, {"id": 522, "seek": 257184, "start": 2591.6800000000003, "end": 2596.8, "text": " Yeah, so inline latech.", "tokens": [51356, 865, 11, 370, 294, 1889, 3469, 339, 13, 51612], "temperature": 0.0, "avg_logprob": -0.3028330405553182, "compression_ratio": 1.1428571428571428, "no_speech_prob": 0.06464444100856781}, {"id": 523, "seek": 259680, "start": 2597.04, "end": 2603.76, "text": " Yeah, so I think it was either Org Latech Preview or Magic Latech Buffer.", "tokens": [50376, 865, 11, 370, 286, 519, 309, 390, 2139, 1610, 70, 31220, 339, 6001, 1759, 420, 16154, 31220, 339, 20254, 260, 13, 50712], "temperature": 0.0, "avg_logprob": -0.18249964452051853, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.0007321243756450713}, {"id": 524, "seek": 259680, "start": 2605.44, "end": 2606.5600000000004, "text": " It was one of those two.", "tokens": [50796, 467, 390, 472, 295, 729, 732, 13, 50852], "temperature": 0.0, "avg_logprob": -0.18249964452051853, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.0007321243756450713}, {"id": 525, "seek": 259680, "start": 2607.1200000000003, "end": 2610.7200000000003, "text": " If you install one of those, it actually goes through the trouble of", "tokens": [50880, 759, 291, 3625, 472, 295, 729, 11, 309, 767, 1709, 807, 264, 5253, 295, 51060], "temperature": 0.0, "avg_logprob": -0.18249964452051853, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.0007321243756450713}, {"id": 526, "seek": 259680, "start": 2610.7200000000003, "end": 2613.28, "text": " inserting in the image, generating and inserting the image.", "tokens": [51060, 46567, 294, 264, 3256, 11, 17746, 293, 46567, 264, 3256, 13, 51188], "temperature": 0.0, "avg_logprob": -0.18249964452051853, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.0007321243756450713}, {"id": 527, "seek": 259680, "start": 2615.84, "end": 2623.36, "text": " But as far as MIME types, I mean, it does try to handle HTML, but it's not a rendered HTML.", "tokens": [51316, 583, 382, 1400, 382, 376, 6324, 36, 3467, 11, 286, 914, 11, 309, 775, 853, 281, 4813, 17995, 11, 457, 309, 311, 406, 257, 28748, 17995, 13, 51692], "temperature": 0.0, "avg_logprob": -0.18249964452051853, "compression_ratio": 1.5637254901960784, "no_speech_prob": 0.0007321243756450713}], "language": "en"}