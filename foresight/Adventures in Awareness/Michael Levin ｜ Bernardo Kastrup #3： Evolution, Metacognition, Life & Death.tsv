start	end	text
0	14560	Tonight is, for the most part, a dialogue between Michael and Bernardo on topics that will include
15120	21840	evolution, platonic realm, metacognition, boundaries of self, potentially life and
21840	27520	death, some new research that Michael has to talk about. And then if there's time,
28000	31200	oftentimes there's less time for Q&A in the sessions where we have a guest,
31840	37520	then we'll do Q&A for sure. And then if there isn't time this week, then we obviously have Bernardo
37520	40080	back for another, I think, three weeks before we have another guest. So,
41600	46320	and Michael, you do quite a lot of other formats where people can follow your work
46320	50000	with this Q&A opportunity if someone's not in a kind of institution.
50960	59120	Yeah, the closest is the blog. So, people will often either comment on specific blog posts or
59120	63520	just email me questions. If they're good questions, I will eventually post the answers on the blog.
64720	69600	I've got one scheduled, one set of Q&A scheduled for, I think, next week from some stuff people
69600	75280	sent me. So, yeah, you can always. Like a live Q&A or one that people write in?
76240	79840	For now, it's been writing, I am actually going to schedule a live one. That is something
79840	83280	that I want to do. So, I'm just figuring out some other logistics, but I will do that.
83920	88240	Cool. Feel free to send us the details and we'll send it out to this community as well.
88240	90480	I'm sure people from here will join. Great idea.
90480	97680	And also, yeah, just to tell everyone that I've been following this blog. I'm not trained
97680	105440	in science, didn't even do biology at high school. And I'm still able to follow the core
105440	111040	ideas and you write it in such a fashion that someone without scientific training can follow.
111040	114880	So, I really appreciate that. Thanks. That's great. Yeah, that was my hope. That's great.
114880	120320	Yeah. And I'm learning a lot. And sometimes I use a bit of chat GPT to fill in some gaps.
123040	124480	I'm a little late. Sorry about that.
125360	127520	Cool. Welcome. Made me nervous there for a second.
130080	133360	Have I ever let you down? Not yet.
135440	139280	Cool. Great. So, welcome. How are you doing, Bernardo?
140560	142640	Say it again. How are you doing?
144240	151280	I'm okay. I had a busy day so far. I'm still a bit out of it. I have to take three deep breaths
151280	153680	and be here. I'm going to get there.
156240	162080	So, potentially, you can relax and enjoy for the first few minutes. I was discussing with
162080	166160	Michael earlier that maybe we could start on some of your thoughts, Michael, on evolution.
167200	170720	You mentioned a couple of papers or new research that you might want to mention. Does that feel
170720	177120	good for you if you kind of discuss a little bit? Thoughts and evolution potentially into the
177120	182240	platonic realm? Sure. Yeah. That sounds fine. Yeah. Okay. Cool.
184080	190800	Okay. Well, let's see. So, in somewhat random order, there's a couple of interesting things
190800	196720	that have come out of our lab recently. One has to do with this notion of hyperembryos.
198560	205840	What we were looking at is horizontal information transfer between embryogenesis. Normally,
205840	210080	you get this idea that you've got an embryo and the reason that that embryo is able to complete
210080	215760	its journey from being a single cell to being a complex organism is because of its genome and
215760	219200	the maternal proteins that are in the egg. So, it's kind of vertical, right? It's all the stuff
219200	224080	that's handed down by the mother. And so, one of the interesting things that we discovered,
224080	230320	and this was led by a PhD student in my group, Angela Tung. And what we found is something
230320	235840	really interesting, that when you challenge a collection of embryos with some kind of
236640	240560	teratogen, a teratogen is anything that tends to disrupt their ability to complete
240560	244400	development normally. So, it could be a drug. It could be a genetic change. It could be a
245360	250640	vibration. It could be all kinds of things. So, it turns out that when you challenge them with
250640	256400	something like this, it turns out that large groups of embryos do much better at resisting it
256400	263760	than small groups. And when we studied it, we found out that not only is there kind of like this
263760	273040	group effect, but also it is not sufficient to have a group that's made up of some individuals
273040	277440	that never got challenged in the first place. And the reason this is important is this.
277440	282480	Our initial very simple model for what's going on, why would large groups of embryos develop
282480	286560	better than small groups? Initially, you might think that, well, what's happening is that
287200	295840	if everybody's getting affected by some kind of perturbation, then by the kind of group
295840	300400	collective intelligence idea that everybody has some gaps in their knowledge of how to make an
300400	304000	embryo, but everybody's gaps are in a different place. And so, as long as they all exchange
304000	307760	information, then everybody can have all the information they need. That's a very simple
307760	311680	way to think about it. It's the way they used to do this thing where people would guess the
311680	316480	number of jelly beans in a jar in a store. And no individual person was ever close, but the group
316480	323520	actually, if you average the group, they were always spot on. So, initially, we thought that
323520	329360	was it. But if that was it, then what you could do is you could make a large group that's composed
329360	334480	of a bunch of embryos that were exposed to the stressor, and then a bunch of embryos that were
334480	339360	never exposed, and those would have all the information they need. And that should be even
339360	342960	better because they could then instruct all the others because they're not stressed out. They
342960	349040	would have all the information. Turns out that doesn't actually work. The only individuals
349040	353760	that can help the group do better is ones that have been exposed to the stressor themselves.
353760	357840	It's kind of this weird thing, like Mark Solm told me once that in psychoanalysis,
357840	361840	in order to do psychoanalysis, you have to have been yourself, psychoanalyzed. It's this kind of
361840	368080	participatory thing. So, it's kind of interesting that you can only help if you've already seen
368080	374240	that stressor. And then we use some tools to actually see the embryos communicate with each
374240	380960	other. It's pretty wild. You can actually see waves of information born by ATP and calcium
380960	386960	signaling and some other things that sort of propagate across the collective. And it has a
386960	392720	couple of implications. One implication it has is that lots of prior studies that look at the
392720	400320	toxicity of various compounds, but didn't actually look at, well, how many embryos did we expose
400320	403600	at one time, right? But all these studies use different numbers of, you know, Pzibar fission
403600	410240	fin, tadpoles and so on. All of those numbers are actually not correct. What you're getting is not
410240	415200	an assessment of how dangerous is that compound, what you're getting is an assessment after it's
415200	420800	been corrected for by the group. So, you're not seeing the raw effect. You're seeing the whatever
420800	428800	effect is left over after the group has done its repair functions. And so, this is very important
428800	435920	because what it suggests is that the information that's needed to have very stable development
435920	439760	is not just vertical. It's not just something that every embryo has everything they need and all
439760	446080	of that. It's actually a kind of a group construction project. And not only functionally does the
446080	450480	group do better than the large group do better than the small group or individuals, we looked at
451440	456960	gene expression and we asked what novel genes do large groups express that small groups and
456960	461440	individuals don't express. And there's a huge collection of new genes that they turn on,
461440	468080	which suggests that this idea that normally in developmental biology, what you're studying is
468080	473440	the way individual cells help each other and cooperate and compete. And then you get this
473440	478720	nice embryo as a result. You can take that one level higher and say that, okay, so that's embryogenesis,
478720	482880	but there's a kind of hyper embryo, which is the large group, which has its own dynamics,
482880	488160	which you can actually complete the journey better. And we can see the communication between its parts,
488160	493600	between the embryos, and it has its own transcriptome. The large, this hyper embryo actually has its
493600	500320	own set of gene expressions that otherwise its parts wouldn't have. So it's a really interesting
500320	505520	example. You know, we study a lot the collective intelligence of individual cells and how it scales
505520	511680	up to be this amazing morphogenetic system that can create anatomies and repair them and so on.
511680	515840	But I guess it goes one step further. It's actually the individuals are talking to each other too.
516480	523280	And you can imagine from that, you can imagine some therapeutic applications because what if you
523280	529680	could fake the effect, right? So what if in the therapeutic context, once we understand what it
529680	537440	is that they're saying to each other, we could possibly impose that artificially in therapeutic
537440	543280	context, whatever the signals are. So we're in the process of trying to understand
543280	549200	what the communication is like, what are they saying to each other really? It's quite a puzzle
549200	555440	because the information that you need to actually create a complex embryo is there's a lot of
555440	560080	information. It's unlikely that all of that information can be propagated by something as simple
560080	568960	as a single, let's say a level of ATP or whatever the molecules are going to end up being. So they
568960	574000	must be modulated somehow. It's really interesting to ask, how are they actually communicating and
574000	581920	what are they actually saying to each other? And then just this notion of the fact that, yes,
581920	586880	you've got individual genomes that do their job within individual embryos, but the magic of
586880	591120	morphogenesis and that collective intelligence doesn't stop at the border of the individual.
591120	597680	It actually is able to use the computational power of the large collective. So that's
598640	604080	that's one of the things that we did recently. Anybody any questions or comments about that?
608560	614560	Someone asked, horizontal gene expression like in mycelium? Someone just been reading entangled
614560	623680	lives. Yes and no. Yes in the sense that the genes that want embryo express are going to
623680	629920	affect the genes that others in the group express, but we don't think, we haven't
629920	635920	to conclusively ruled that, but we don't think it's that it's literally propagating the material,
635920	641200	like it's like we don't think it's propagating transcription factors or anything like that.
641200	646080	I think what's happening in this issue will come up again when we talk about some new thoughts we
646080	651840	had on memory, that what it's doing is basically compressing a large amount of information into
651840	656160	a very narrow communications channel. So something that can be easily encoded by small molecules
656160	660880	that are propagating, and then the recipient embryos have to sort of re-inflate or reinterpret it
660880	665440	for their own for their own context. I have a feeling that's what's going on, but yeah in
665440	671520	effect what you're seeing is horizontal transfer of information that ends up controlling gene
671520	676960	expression. So just a super naive question. So you've got an embryo that will do something
676960	680960	specific on its own, and then it behaves differently if it's surrounded by lots of other
680960	685840	embryos. So with a human, I'll just be like, okay, well a human can count. I'll be like,
685840	689680	great, there's lots of people around me, you know, I'll copy what they're doing, but
691040	695120	is it just passively receiving it from me? Because presumably you don't think they're
695120	701920	metacognitively counting how many embryos around them? Does the question make sense?
701920	706720	Yes, yes it does. I don't have any evidence that that they're aware that they're counting,
706720	712640	for sure, I'm not claiming that. But I think that what's happening is, and we actually in the paper,
712640	716800	I mean, you know, if anybody's interested in the details of the computational stuff,
716800	723520	we actually have in the paper a model of cellular automata acting this way, that is a noisy
723520	728320	cellular automata where each one has a problem following a specific set of rules, but there's
728320	732480	a large collective and they get to communicate and eventually you get pretty robust communication
732480	737440	in the group. So no, I don't think they're explicitly counting, but I think by virtue of
738000	744320	the mechanisms that couple them together, you in effect get something that is quite sensitive to
744320	752400	the number of individuals in your cohort. Then now at any point, obviously Bernardo,
752400	758640	just feel free to comment or speculate if something Mike was saying sparks an interest.
759280	764080	And is what you just said related to that blog that you put that was talking about a paper
764960	768800	around the surprising emergent behavior of algorithms?
770480	775360	The algorithms, well, I mean, I do think that all of these things are connected in interesting
775360	781600	ways. The algorithms were a different paper. So what we did there, if people want to talk about
781600	788320	that, what we did there was, you know, one of the things about biology is that when you look at
788400	792640	systems, no matter how simple you think it is, you know, even if it's some kind of a,
792640	796560	you know, a microbe or something, there's always more mechanism. There's always more
797120	800480	different components and different amazing things that you didn't know were there.
800480	808720	And so that makes it kind of hard to really study emergent surprising outcomes because
808720	811840	someone could say, well, there's probably a mechanism specifically for that. You haven't
811840	819360	found it yet. So what we wanted to do was to really come up with a system that is extremely
819360	823840	minimal, extremely transparent, where there was no place to hide, where it was obvious what all
823840	828320	the parts were, and then use all the tools of the frameworks we've been developing to ask,
828320	834640	okay, is there some kind of emergent, maybe some proto cognitive capacity here? And what we chose
834640	840880	were very simple things called sorting algorithms. So for anybody who doesn't do computer science
840960	845200	in the audience, what these are are very simple sets of steps. There's usually the whole algorithm
845200	849840	is usually six or seven lines of code. It's very simple. And what it's designed to do is to take
849840	854320	an array of numbers that are jumbled up. So it's an array of integers, let's say a hundred of them,
854320	858560	and they're jumbled up in random order. And there's an algorithm, which is a set of steps
858560	863440	that will, if you follow it consistently, what it will eventually do is sort the whole list
863440	867440	into let's say ascending or descending order. These are things that computer science has been
867440	871440	studying for decades, every computer science student starts up learning these things. And
872160	880160	the thing about them is that they are extremely, they're simple, they're short, they're transparent,
880160	884560	you can see all the parts, there is no more mechanism to be discovered. And they're completely
884560	890480	deterministic. And people think they know what these things do, right? So you think, we've studied
890480	897200	them. And so what we wanted to do was to ask the question of what surprising behaviors could be
897200	902000	hiding, even in something as simple as this. And it's important, because oftentimes, for example,
902000	908800	people who do AI and things like that, somebody said to me recently, there's no emergent behavior
908800	914560	in language models, I know how they're built, I know what all the parts are. And I think this
914560	921920	is a very dangerous attitude. And so we wanted to kind of study this very simple system. And so
921920	931200	what we did there was we visualized the process of a couple of interesting twists. One is that we
931200	938640	visualize the process of sorting these numbers as a walk through what we call sortedness space.
938640	942320	So they start out in a region of that space where it completely jumbled, but everybody eventually
942320	946560	gets to this place over here where everybody's in order. And they have to sort of, during the
946560	951120	sorting, that string sort of makes its way to that spot. And what we did was we said, okay,
951920	956400	instead of having one sort of omniscient algorithm that gets to move around all the pieces,
956400	960080	which is normally what happens, there's an algorithm that moves around all the parts,
960080	964480	what we did was we put the algorithm inside the cells themselves. This again, will be important
964480	968960	when we later talk about the memories, because what we basically did made was self sorting arrays.
968960	974080	So what we said is each number, it on its own has the ability to look to its left and to its right
974080	978480	and decide how happy it is about where it is. And if it's not happy, so if I'm a five, I want the
978480	982640	four to my left and the six to my right. And if I don't see that, I want to move somewhere else
982640	989680	where I'm going to be happier. That's it. There is no global control. And so
991040	994880	what we found when you do that, a couple of interesting things happen. First thing that
994880	1002480	happens is that it still works. So when you do this and you have this self sorting data where
1002480	1006080	you're erasing a little bit the distinction between the algorithm and the data, because now the data
1006080	1015280	itself has a little bit of action to it. What happens is, yeah, they still sort, but now you
1015280	1019760	can do two interesting things. One thing you can do is you can make some broken cells. So you can
1019760	1024000	ask, what happens if some of the cells are broken? They can be broken in one of two ways. Either
1024000	1030320	they refuse to move when they are asked to move, or they're completely broken in that,
1030320	1034480	they don't even try to move. They're not just broken for others, but they won't swap with others,
1034480	1039600	but also they don't initiate. So they're just completely frozen in place. Normally in these
1039600	1045360	algorithms, you assume that the hardware is reliable. That is, if the algorithm says swap to
1045360	1049280	four and the seven, they swap and you never even go back to check, well, did it work? Like, was it
1049280	1054960	swapped or not? You normally don't check. This again will come up as important. The importance
1054960	1061840	of unreliable hardware, I think in biology and cognition is really critical. So we made this
1061920	1066720	kind of unreliable hardware example where they're sorting and eventually you get to
1067440	1072400	some numbers that will not move. They're frozen. And that turns out to be a barrier in their journey
1072400	1081440	towards being sorted. It's like what the definition of intelligence I like, which is the ability to
1081440	1086000	get your goals met despite all kinds of novel circumstances, perturbations, the ability to
1086800	1091280	basically to navigate your space and get your goals met. So these algorithms, just to be clear,
1091280	1096160	there is no code in there about what happens if the number doesn't move. How am I doing? Did the
1096160	1101440	number move? Nothing like that in there. The algorithm stays exactly the same. But what does
1101440	1107760	it do when you do interrupt its journey with these barriers that cannot be passed? William
1107760	1113360	James had this notion of navigating barriers and so on. And there's a concept of delayed
1113360	1119600	gratification. The deal with delayed gratification is that when you come to a barrier, if you're
1119600	1123680	a magnet and there's two magnets and they try to come together, you put a piece of wood between them.
1124240	1128240	The magnets all they're ever going to do is stay there stuck between the wood. The magnet is never
1128240	1133760	going to go around to get to its goal because it has no delayed gratification. It would have to
1133760	1138880	go further from its goal in order to get to where it's going. Magnets don't do that. But some animals
1138880	1144080	do. Some autonomous vehicles do and so on. What do these algorithms do? So it turns out that without
1144080	1149440	any special code for it, what the algorithms will do if you actually track the sorting. So here
1149440	1154320	it moves along, moves along, it's the sorting everything. It meets the barrier. When it meets
1154320	1161440	the barrier, it actually goes around and in order to go around, the array actually gets less sorted
1161440	1166160	over time. It has a degree of delayed gratification. The whole thing gets worse for a little while
1166160	1170560	until it moves all the other numbers around that broken cell and then things improve. So it has the
1170560	1175760	ability to temporarily get further away from its goal. And it only does this when it encounters
1175760	1184000	a broken cell. But it has this really primitive but already a tiny capacity for delayed gratification
1184000	1188880	that is completely emergent. It is nowhere in the algorithm for it to do that. We had no idea
1188880	1195840	this was going to do that. And so just a couple things and I'd love to hear what Bernardo has
1195840	1202560	to say about it. One thing is this little bit of delayed gratification. And then there was
1202560	1208240	another thing that we found. Because we've now put the algorithm inside the cells themselves,
1208240	1213680	that lets you do something weird. It lets you create a chimeric array where some of the cells
1213680	1217760	are following one sorting algorithm, let's say bubble sort. The other ones are following a
1217760	1222640	different algorithm, let's say selection sort or something. So it's like a chimeric. We make this
1222640	1230000	in the lab all the time. We'll make like a frog allotle which has a bunch of frog embryonic cells
1230000	1233760	with some axolotl embryonic cells. And each of them are following different algorithms. You
1233760	1238880	put them together and you ask, what does this collective make? When different parts are constructing
1238880	1243120	things under different rules, what's going to be the outcome? So we can make these chimeric strings.
1243120	1247200	We can make these algorithms where the different cells are following different rules. And then
1247200	1255600	we found something really wild, which is this. Imagine that you assign, we called it, actually
1255600	1259440	this was Adam Goldstein came up with this idea. He called it the algotype. You know,
1259440	1264560	genotype, phenotype. So this is the algotype. The algotype is the algorithm that any cell happens to
1264560	1272320	be following. At the beginning, so you've got your array of 100 numbers and it's random. The
1272320	1277520	numbers are randomly distributed and they are randomly assigned to algotypes. There's two
1277520	1285200	different algorithms randomly assigned. When you do this, let's just ask, what are the,
1286160	1291280	what's the probability that when I look at my neighbor, my neighbor is the same algotype as me?
1291280	1295680	At the beginning, it's 50% because they're random. So your neighbor has a 50% shot of being the same
1295680	1302560	type of cell as you are. At the end, after all the sorting is done, same thing. It's also going to
1302560	1307200	be 50% because the algorithm doesn't care about algotype at all. There is nothing in the algorithm
1307200	1311440	that says, what algorithm am I? What algorithm is my neighbor? There's nothing in there about that.
1311520	1315600	At the end, everybody's got to get sorted according to their integer value, which means the
1315600	1321040	algotypes again are shuffled and random. So 50% at the beginning, 50% at the end.
1321040	1324880	But what happens in the middle? If you track what happens in the middle, what happens in the middle
1324880	1332400	is the, that we call it the clustering, this idea of this measure of how, what's the probability
1332400	1337840	that I like to hang out with my buddies. There's the same type of things as I am, the same algorithm.
1337920	1345760	It actually goes like this. So in the middle, it goes up and then it comes down again. So for the,
1345760	1354000	for the, and it's, it's this, it's this amazing emergent tendency for these guys to cluster
1354000	1361200	during their journey. And it's sort of, it's, to me, it all, it's, it's, it's all, it almost
1361200	1366240	reflects like the, the, you know, the existential condition of life in a, in the universe, like
1366240	1369840	eventually the physics of the world, you have to obey the physics of the world and eventually
1369840	1375120	they're going to pull you apart. But in the meantime, even though it's not prescribed by the rules
1375120	1379120	that you're following, you get to do something interesting, something new and interesting,
1379120	1385040	and maintain a pattern at a high level. You get to make these, these clusters, these, these temporary,
1386560	1395200	temporary emergent patterns of, of, of like, like-minded, like-minded data that are, that are
1395200	1398960	sitting there. Eventually they're going to get pulled apart. But in the meantime, they're there.
1398960	1405120	And, you know, we did, we did some other things. Like we said, what happens if we relieve the
1405120	1409280	pressure a little bit of getting pulled apart, how, you know, give them a little more opportunity to
1409280	1414320	do what they really want, which is to cluster. And the way you can do that is you can allow duplicate
1414320	1419120	numbers. You can say, okay, we'll have 10 fives and 10 sixes and 10 sevens. And that way you can
1419120	1423840	sort of have your cake and eat it too. You can be a bunch of fives in the right place. But the,
1424080	1428480	but the first few fives can be one algotype and the next few can be in the, and if you do that,
1428480	1432160	they cluster even more. So you can see that the pressure to cluster is quite significant.
1432160	1437120	They just get pulled apart at the end. So I'll just stop here. But the point of, the point of that
1437120	1442560	whole, that whole, that whole journey is to just start to look at these extremely simple, transparent,
1442560	1449680	deterministic systems and already find interesting capabilities. And now, I mean, there's some
1449680	1454080	practical stuff to be done here too, because they're, they're doing this clustering for free,
1454080	1458480	basically, right? We're not, you know, it doesn't require any additional computational power. So
1458480	1461680	if that happened to be something useful, or if we coupled it to something useful,
1461680	1466000	you could imagine getting some more squeezing some more, some more juice out of, of a process
1466000	1470800	that's already happening anyway. So I'll stop here and see what, see what Bernardo has to say.
1471920	1476240	Is it okay Bernardo to just quickly see if a simple example will help anyone that,
1476240	1481520	because I've read it. So I think I'm following you, Michael. But it is a simple illustration of this
1481520	1487040	is normally assorting, let's say I've got a classroom full of school full of children,
1487040	1491280	and I want them all lined up in terms of height. And normally the teacher would stand there,
1491280	1495760	okay, you stand there, you stand there, you stand there, and kind of sorts it from a bird's eye view.
1495760	1501440	And what you've done is told each child, if the one on the right of you is, you taller than you,
1502240	1505920	swap sides, or if it's shorter than you, go further that way. And so you've given instructions
1505920	1512960	to each child to move. Is that close to what you've? Yeah, that's close. And so to following that,
1512960	1518240	that analogy, you've told them to sort by height, and eventually they do sort by height. But what
1518240	1524640	you notice is that halfway through, they also seem to be clustering by eye color. So for some reason,
1524640	1530560	they're also hanging out together by some other property that your instructions to them do not
1530560	1535760	reference at all. So there's some other property that they seem to, that they
1535760	1540880	seem to want to group by, and then eventually, of course, they'll sort out by height, and there's
1540880	1544400	no necessary relationship between height and eye color. So eventually it'll go away. But in the
1544400	1549360	meantime, you notice that, hey, there are these groups of similarly eye-colored individuals.
1552720	1558640	Great. And also, each child can only see the one right next to them. Is that how it's set up?
1560720	1564240	There's a few different, I mean, we use the few different versions of this with different ability,
1564400	1568480	different radius that they can see and so on. All right. Sorry about that. Go for it.
1570000	1575520	I'll invite you. I love your work, Michael, but here I depart from you. So I invite you to sort of
1576400	1583520	come into my thought line on this. You, of course, know Conway's Game of Life cellular
1583520	1590640	automaton. There's an array of very simple cells, and each cell obeys only essentially one rule.
1591600	1599600	If there are two or three of my neighbors who are alive, then I either stay alive or I become alive.
1600480	1607760	Otherwise, either I stay dead or I die. That's it. That's all there is. Each cell counts how many
1607760	1612640	neighbors are alive and decides whether it's alive or dead in the next cycle. That's all there is to
1612640	1620000	it. And then if you let that thing play out and you see the patterns that the living cells,
1620080	1625840	the cells that are alive, the patterns they form, we see amazing things. We see cannons firing
1625840	1633200	projectiles. We see systems that seem to be swallowing up other systems and growing as they
1633200	1638160	do that. That's why it's called the Game of Life, because we see all these patterns. But would you
1638160	1645360	concur with me that, ontically, there is only that simple rule. Everything else is an epistemic
1645360	1652640	projection of us. Yeah, so that's a super interesting and important point. So I do agree
1652640	1658240	that everything that we just mentioned, the gliders, the beehives, all of this other stuff,
1658240	1668720	it is absolutely a pattern noticed by an observer, in this case us. But my point is going to be that
1669440	1676720	I think the same thing is true of many agents in biology. In other words, I think that observing
1676720	1684640	a temporary physiological object, which is what I think gliders are, right? There are patterns
1684640	1691280	that move through an excitable medium. I think that in many ways, these kinds of things, this is
1691280	1697840	exactly what, that's a reasonable way to look at life forms, to look at stress patterns moving
1697840	1704080	through tissues, to look at genomic information propagating through a lineage agent. I agree with
1704080	1712720	you, but I think it's actually important. Randy Beard did this cool paper called the cognitive
1712720	1716800	domain of a glider in the game of life. He literally tried to take the perspective of the
1716800	1724960	glider and say, what do you see from the perspective of the glider? I think it's a projection of
1725040	1729440	other cognitive systems, and I think that's a great way to look at a lot of things in biology,
1729440	1735680	actually. I don't have a problem with that. I think complexity science has been showing us
1735680	1741360	very, very compellingly that things that we consider to be very complex, in fact, aren't
1741360	1747360	complex at all, at all, ontically. The complexity is our own projection of our own cognitive modes
1747360	1752480	onto the behavior of that thing. That thing is probably just playing out very simple rules like
1752480	1759680	the game of life. I completely agree with that. As you know, I am an extreme reductionist. It's
1759680	1764720	just that I don't try to reduce the big to the small. I try to reduce the complex to the simple,
1764720	1770560	and I think that's the correct way to reduce things. But the title of your paper, in the title
1770560	1779040	of your paper, you start by saying, what do algorithms want? Instead of saying, look, these
1779120	1784000	high-level functions that we seem to see, they may not be there at all. They may be our own
1784000	1789120	epistemic projections. The title of your paper suggests that you're doing the opposite. You're
1789120	1796800	imbuing a system made of very simple rules with the kind of cognitive modes that only complex
1796800	1806240	organisms have, like a delayed reward. Well, why do I delay my reward? Because I know, if I have an
1806240	1813280	inner model that gives me a projection of the future state, but that's not what your numbers are
1813280	1819120	doing. They do not have an inner model that allows us to anticipate a possible future state to
1819120	1825520	deliberately delay their reward. The delayed reward thing is purely an epistemic projection
1825520	1832560	of ours. It's not in the system, but it is in me because I have the model. I experience it. I can
1832560	1839600	anticipate future states and deliberately delay reward for that. That's where I get
1840560	1849440	slightly uncomfortable because you present this not as eliminating the notion that there are these
1849440	1855120	higher-level cognitive things going on. You present it as if you were imbuing things that
1855120	1861280	are very simple and mechanic with these higher-level cognitive functions. It's just like criticism.
1862080	1868000	I do it open-heartedly, Michael. Yeah, no, it's great. This is exactly the conversation to have,
1868000	1874880	and I think these are valid points. Here's my view on it, a couple things. First of all,
1875680	1883680	this idea of epistemic projections, I agree with you, and I think that it's everywhere. In other
1883680	1890960	words, when you look at an embryo, basically for all of these scenarios,
1890960	1895040	I think there are multiple perspectives, multiple points of view that an observer could take,
1895040	1899200	and you could absolutely take the bottom perspective, so to speak, and say, okay,
1899200	1904560	look, in the game of life, there are no gliders. There are no be-haves. All there is is individual
1904560	1909920	fixed cells. Nothing moves. There are individual fixed cells. It matters, though. What's interesting
1909920	1915040	to me is that these different perspectives, it's often argued that these different perspectives
1915040	1920240	are a philosophical choice. They're all as good as each other, and you can look at it from the
1920240	1924640	bottom. You can look at it some other way. I think it actually makes a huge difference, because
1925600	1930960	I'm sure you've seen somebody made a touring machine in the game of life using the gliders as
1930960	1937840	signal pulses. If you don't believe in gliders, if all you do is, if all you believe in is the
1937840	1946960	low-level rules that govern each cell, you can absolutely explain any events in the world,
1947280	1951200	in fact, you can predict forward what's going to happen in that world. You can roll it forward as
1951200	1955360	much as you want. What you're not going to do is build a touring machine out of gliders.
1958720	1962960	You can make predictions from a system that's already set up. If somebody makes a starting
1962960	1967600	position, you can certainly say everything that's going to happen about that, but I think that level
1967600	1974400	of description limits the generative insight that you have into what can happen, and it becomes
1974400	1979520	really important in the biology that we study. For example, so as you said, there are simple
1979520	1984080	rules. We look at an embryo. We look at an embryonic blastoderm. There are 50,000 cells,
1984880	1991840	and somebody will say there is no embryo here. There are just individual chemical reactions.
1992480	1996960	They're following the rules. There is no embryo here, and certainly there isn't any goal state.
1998960	2004080	What I would say is this. You can have that view, but what you're going to miss there is the fact
2004080	2011120	that all of the cells in that embryo, the reason that what we're counting, when we say one embryo,
2011120	2018640	what we're counting is the commitment of all of those cells to a particular target in that
2018640	2023520	anatomical space that they are all going to reach. The reason that I call it a goal and a target is
2023520	2029440	because functionally, if you try to deviate them from that target, you can move things around,
2029520	2035360	you can put barriers, you can do all this stuff. They will find clever ways to still get there.
2035360	2039200	Now, I'm not saying that this is a metacognitive goal the way that humans have goals and that you
2039200	2043520	can reason about your goals. You can set new goals. I'm not claiming that. There's a continuum,
2043520	2049920	of course. There's a very basic, there's a very basal version of this, but I think that perspectives
2050480	2056000	that look at the system and acknowledge that, okay, there's a perspective in which
2056000	2060000	none of this is happening. There's another perspective in which that is happening.
2060000	2064160	It leads you to new experiments. Many of the things that we've done, we've only been able to do
2064160	2070160	precisely because we take seriously the idea that, yes, this is a system that in some way
2071680	2076800	has the ability to correct towards a specific outcome. With respect to these algorithms,
2076800	2080880	I mean, you're right in that by the way, the paper itself, if you look at the paper itself,
2080880	2085600	was not titled What Do They Want, right? The paper had a very much more sort of conventional
2087040	2092080	the blog post is titled that because that's where I sort of say what I think. But
2093600	2098720	talking to Carl Friston about it, we really talked about the testing and this is an empirical
2098720	2104080	question. I don't know if this happens or not, but one of the ways you can look at as to why
2104080	2112160	they cluster is the tendency to minimize uncertainty. So your neighbor, the least
2112160	2117280	uncertain neighbor is the one that's just like you, right? So possibly you can use the active
2117280	2122560	inference framework to describe why it is that they have a pressure to cluster together with
2122560	2126800	other beings that are like them. And so this comes up in biology too. So these are all experiments
2126800	2132560	that we can do. But I would say that I think we're both right in the sense that there is
2132640	2138560	absolutely a perspective to be taken here in which there are only low level rules,
2138560	2146480	but there are other perspectives on this which may be useful in terms of finding new discoveries,
2146480	2152080	making new things. And then I guess my final thing is that I think everything is a perspective
2152080	2158480	of some agent, everything, not just some things, but all of it, everything.
2159280	2165520	I concur with you that it is operationally useful to think at different levels of abstraction.
2165520	2168800	So if you're going to build a computer, if you're going to build a Turing machine
2168800	2174880	with the Conways game of life, that it's very useful to operate at a higher level of abstraction,
2174880	2178480	where you're dealing with higher level components, otherwise you would just be,
2178480	2185680	you know, overwhelmed with detail. That is operationally useful. But at the end of the day,
2185760	2190800	it's a cultural game, right? I mean, I am on the record, very publicly,
2190800	2196880	saying that you are doing the most important work in the world right now. And people have
2196880	2202400	come to me and say, oh, look, Michael thinks algorithms want stuff. Algorithms have will.
2202400	2208240	So AI is sentient. And you are saying, you know, on a crusade saying that we have no reason to
2208240	2214640	think that AI is sentient. And where does that come from? It comes from this epistemic projection
2214640	2220800	of word usage, how we talk about things. You started your discussion today talking about,
2220800	2225200	you know, AI people saying, you know, there is nothing to this large language models that we
2225200	2230160	don't understand. I am one of those people who say that I understand the mechanics of that.
2230160	2236320	I know what is there and what is not. So the fight we are fighting is to prevent these
2236320	2241920	operationally useful levels of abstractions. In other words, this convenient fantasies,
2241920	2246400	which are very, very convenient and should be used. We are trying to prevent people from
2246400	2252560	understanding this epistemic thing as if it were an actual ontic property of the world out there.
2252560	2258640	Because that's what Black Mirror does. That's what the eight o'clock news does. That's what
2258640	2264320	the very suspicious characters on the internet and on YouTube are doing. There is money to be
2264320	2274960	made out of this. Anyway, I have a slight issue with this, but I do understand your point that
2274960	2282000	it is operationally useful. But I think we should try to stress that there is a distinction between
2282000	2288880	epistemic convenient fictions and ontic things about the world. That's when we say that we are
2288880	2294720	using an epistemic convenient fiction here. We don't mean by it that the algorithm has a will,
2294720	2299920	that it has the phenomenal state of wanting to get some teleological phenomenal state. We don't
2299920	2309520	necessarily mean that. I'll emphasize the part that we completely agree on. My point about the
2309520	2315040	language models was not that I think that they have, and I don't use the word sentience much
2315040	2321040	myself, but the kind of sentience that people often attribute to them. I don't think they have it,
2321040	2328080	but I think the kind of the fundamental thing that drives our viewpoints here is that
2328880	2334240	or the difference in our viewpoints is that I don't really believe in a binary distinction
2334240	2340480	between yes they have it or no they don't have it. I think it's a deep spectrum, and I think that
2340560	2346800	what's really interesting and important about the universe is that it's full of what I really
2346800	2352640	think is sort of competing and acting in the universe is perspectives, frames of reference.
2355120	2362480	I think very simple systems can have a perspective. I think it makes sense. It could be extremely
2362480	2370480	tiny. I don't like the binary trying to classify systems that, okay, this really
2370480	2375600	has an inner point of view, and this absolutely does not. I think it's a continuum, and I think the
2375600	2383040	question is how much utility do you get from taking the perspective of some other system,
2383040	2387680	and some of them are truly minimal. These things that we're talking about now, I don't think they're
2387680	2392240	metacognitive. I don't think they're anything like a human, but I do think that there's a sense of
2392640	2405120	a nano goal-directedness that we can have, and the problem is that if we don't believe that's
2405120	2411600	true, then we're going to have a real difficulty saying why it is that humans or whatever else
2411600	2416640	did you want to extend it to, why they have it too, because we all start life as a single cell,
2416640	2422080	and somehow you have to get to the point where you start out as a little blob of chemistry and
2422080	2427280	physics, and eventually you end up with whatever it is that you and I have real metacognitive
2427280	2431200	wants and goals and things like that. I'm not saying there isn't a difference between those
2431200	2436640	two cases, there certainly is, but the hard part is explaining that smooth transition,
2437360	2443280	and this is what we work on. Is it okay before you respond? I would love for you to respond.
2443920	2449440	If one or both of you could state as in simple terms as possible what it is you're debating,
2449520	2454880	so as many people as possible can follow, because I'm pretty sure I understand, but I don't think
2454880	2461200	I'd be able to articulate it. It's basically what is a thing. What is an emergent property?
2461200	2467440	I think that that is the discussion. When you talk about emergency in a weak manner, so not
2467440	2473520	strong emergency, not consciousness out of non-consciousness, just emergence like the shape
2473520	2478640	of sun dunes or the crystal structure of a snowflake, emergence in that sense in which
2479200	2485280	a system starts with very simple properties, but it seems to develop some very complex properties
2485280	2493680	or some complex behaviors later on. The question is, are emergent behaviors a thing, a non-tic thing
2493680	2500080	in the world out there? Does something actually emerge in the world, or is it just us that project
2500160	2505760	the modes of our cognition and what's happening? What's happening is just simple stuff. There is
2505760	2511520	nothing complex emerging. It's just the play out of simple rules in an iterative way, and we project
2511520	2518000	something to it. Michael, we both agreed that there isn't something on-tic going on out there,
2518000	2523920	if I understood Michael, but Michael says it's useful in our own language, in our own thinking,
2524000	2530560	in our own inner discourse to pretend that there is, because it allows us to think in a higher
2530560	2536800	level of abstraction, which is much easier than to continue to operate on first principles
2536800	2543680	all the way along. It's like somebody asking me to design a risk processor starting from the PN
2543680	2549360	junctions. It's not useful. I need to think in terms of gates or at least transistors.
2550160	2555200	Are there transistors in a chip? No. There are only PN and NP junctions. That's all there is to it,
2555840	2560960	doped silicon and metal. That's all there is to it, but it's useful for me to do my work, to talk
2560960	2568080	of transistors, to talk of gates, to talk of chips and interconnect networks. If I understood
2568080	2575680	Michael, that's where he's coming from, but he also thinks that we shouldn't go too strong in this
2575680	2582160	radical division between emergence being purely epistemic, not being out there in the world and
2582160	2586960	what is really out there in the world, because he thinks the idea of points of view may be a sort of
2589360	2595680	not a binary one, because if it were binary, we would have difficulty starting from a Zygote,
2595680	2603920	a single cell embryo. Can you even call that an embryo? I think we can. To us who do have a point
2603920	2609360	of view. How do you explain that transition? I think it was Michael's last point. Is this fair
2609360	2615840	enough, Michael? I think it's reasonable. The second part is straight on. The first part, I
2615840	2620160	think I want to be a little more radical than this, so let's play it out and see how it goes.
2621280	2626000	How about this? I 100% agree with you that all of these things, and by the way, it's not just
2626000	2631200	emergence. I'm not particularly impressed by the emergent complexity per se. I'm interested in
2631760	2637440	emergent goal-directedness, which is different than just complexity. But I fully agree with you
2637440	2643600	that all of those things are painted on to the world by us. They are things that we see in the
2643600	2649920	world. Here's the move I want to make. When you say us, I think it's everything. I think that us
2649920	2655680	is not just us, me and you. I think that every agent in the world, and at some point we could
2655680	2663360	talk about where that bottoms out. But I think certainly what happens in biology is systems
2663360	2668880	that try to understand other systems because they need to hack them. In order to hack them,
2668880	2675680	you don't want to always try to think of them as the lowest level of a bunch of emergent complex
2675680	2682320	chemical soups that are going to happen. If these other systems have any kind of goal-directedness,
2682400	2687360	and I don't mean human purpose, I mean the kind of things you study in cybernetics, and everything
2687360	2692000	in between. All of these other high-level features, you will paint it on to the world.
2694960	2699600	This is how you are going to relate to the world. You do not have, as an agent in this universe,
2699600	2705280	you don't have the luxury of being a Laplacian demon and sort of having an unbiased view of the
2705280	2710160	whole world from the particles up. You have to coarse-grain it and sense-making in a way that
2710160	2716000	makes sense to you, and inevitably you're going to tell agential stories about agents doing things.
2717520	2726080	I think this is universal, and I think that the universe is basically a giant set of competing
2726080	2732240	and cooperating perspectives, and it isn't just us. When we say us, it's everything. It has some
2732240	2736960	degree of inner perspective on the outside world. If you're a rock, that inner perspective is
2736960	2743440	infinitesimal. We can argue about whether it's zero, but anything above that is going to, and life
2743440	2750000	is very good at scaling up these perspectives and detecting agency and so on, is going to have
2750000	2756640	these kind of perspectives. That's my move. I think that we really need to get much better at
2756640	2760880	taking the perspective of other things that are not at all like us, and I think this has also,
2760880	2765280	of course, social implications and whatever. I think we have a really hard time looking at the
2765280	2770640	world from the perspective of other things, and I've been spending a lot of time in the last
2770640	2777600	few weeks really thinking about this and thinking of tools to help us take the perspective of other
2777600	2786400	systems. I'll try to amplify the problem you describe, and I will at least try to convince
2786400	2792000	you that I understand the problem, and then I'll try to articulate why, based on my own views,
2792000	2799760	the problem isn't there. The problem you see is we start as a single cell zygote,
2801360	2807680	which is very simple. Well, relatively speaking, because zygote, the biochemical machinery of
2807680	2812960	that thing is unpathemable. Nobody has figured out, nobody has a model of that down to first
2812960	2820080	principles, but okay, relatively simple, and then it becomes us, and we do have a point of view.
2820800	2828080	Now, the same problem is playing out in physics. The measurement problem says that physical things
2828080	2834960	only have existence in relation to an observing system, but what constitutes an observing system?
2834960	2839920	Well, anything constitutes an observing system, so anything may have a point of view.
2840800	2851200	I think both attempts to solve this problem are based on the following intuition. When it all
2851200	2856000	starts, there is no point of view, and then suddenly there is a point of view, and this
2856000	2862720	discontinuity is a problem. There is only two ways to solve it. Either everything has a point of
2862720	2870480	view from the get go, or you didn't start without a point of view. That's one possibility.
2872960	2877360	It's the assumption that the zygote does not have a point of view, and a point of view then
2877360	2882960	develops with growth that leads to the problem. It is the assumption that
2883840	2893520	any physical system is analogous to any other physical system, as far as the measurement
2893520	2899760	problem is concerned, that forces us to say anything is an observer, because we don't have
2899760	2906720	a well-behaved objective criterion to say, no, no, this is a valid observing system, and that is not,
2907440	2913760	or this is a thing, and that is not. It's a projection. It's an arbitrary way of us carving
2913760	2920720	out the world. It is not a thing, or to say the zygote doesn't have a point of view, but a grown
2920720	2929680	human has. Under my own view, a zygote already has a point of view, because a point of view
2929680	2935600	is what arises from dissociation. If there is a dissociative process, that dissociation creates
2935600	2942480	a point of view. It creates the observer, so to say, which is distinct from the world, and therefore
2942480	2947520	can observe, because it is dissociated from the world. Otherwise, it's just the world.
2948800	2953920	Then in philosophy, this question goes deeper. It's not only what has a point of view, which
2953920	2959520	under analytic idealism is only living things, as zygote is living. It developed a point of view,
2959520	2965360	the moment of accumulation. But in philosophy, it goes deeper. What constitutes a thing?
2966640	2973360	Is a painting hanging from your wall a thing? Is your table a thing? If so, are each of the
2973360	2979920	four feet of the table four things? But isn't the table then just one thing, or is it five things?
2979920	2986960	Is it the top of the table and the four feet? There is difficulty in even determining what a
2986960	2993520	thing is, let alone what properties it has. Can it observe? Does it have a point of view?
2993520	2999600	Does it have a will of itself? I mean, even before we get to that, asking whether a table
2999600	3004160	has a point of view, whether a table has volition, we have to ask, is the table a thing,
3004960	3012640	or are we just projecting the epistemic structure of our language onto the ontology of the world?
3013440	3018800	Not everything we have a distinct word for is a thing. This is a fist, we have a word for it.
3018800	3025440	Boom, it has disappeared. Where is the fist? The laws of conservation of energy have just been
3025440	3031680	violated because something has disappeared without releasing energy. How is that possible? You run
3031680	3040880	into this kind of problems. The moment we are not careful about paying attention, about mistaking
3040880	3046480	the structure of language for the ontological structure of the world, which we are very prone
3046480	3051520	to doing because we are surrounded by language. We live in a world of language. So to me,
3054560	3061440	what you are trying to do, and you are probably a pioneer in this in biology, but
3061440	3065600	you're not a pioneer of this in science in general because physics has been struggling
3065600	3068640	with this for a while, philosophy has been struggling with this for a while.
3070880	3076640	The difficulty you are having is that you do not have a clear objective criterion to determine
3076640	3082720	what is a thing as far as a certain definition of thinness that is concerned. And because you
3082720	3086880	don't have that, then everything has to be a thing. Therefore, everything has to have a point
3086880	3092080	of view in potential, or not if it's too simple like this I got, then it doesn't have one, but we
3092080	3101360	do. So what magic happens in the middle? To me, pecundation, the moment zero, t zero of life,
3102000	3109600	is what determines a thing. Why do I say that? Is it arbitrary? No, it's because unlike the question
3109600	3114960	of whether the feet of a table are real things for which there is no ontological criteria,
3114960	3120480	all criteria are epistemic. They are based on convenience. If that thing breaks, I need to
3120480	3126640	have a word to refer to it so I can repair and put another foot on my table. But there is one
3126640	3134880	exception to this. If you avoid applying epistemic criteria to carving out the world into things,
3134880	3140000	there are no things. There is no car. If you say, well, a car is everything that is needed for the
3140000	3144640	thing to move. Well, it needs the air for the combustion. Without the air, it doesn't move.
3144640	3149840	It needs the road for the tires to grip. Without the road, it doesn't move. It needs gravity to
3149840	3156240	pull it to the road. Without gravity, it doesn't move. So if you follow that criteria, this kind
3156240	3159760	of criteria, functionality criteria, which is how it's called in philosophy, then the whole
3159760	3168240	universe is a thing. There is even a naming philosophy for the blob theory, whatever. But there
3168240	3173520	is one exception to this. There is one thing for which we have objective criteria to say,
3173520	3179040	these are things. And that's life. Because if you stick a needle on the arm of my chair,
3179040	3186000	I don't feel it. But if you stick it on my arm, I do feel it. So there is a clear boundary between
3186000	3192160	what I do register and what I don't register. That boundary determines me as a real thing,
3192720	3198160	not as just a sort of an arbitrary collection of pixels on the screen of perception that we give
3198160	3206000	a name to. It's like saying, take the Mona Lisa and group all the pixels or all the infinitesimal
3206000	3212400	dots of pigment that are around yellow, given a certain tolerance. And you call that a thing.
3213360	3219280	That's what we do, this kind of arbitrary grouping of the pixels of reality. But when it comes to life,
3219280	3225360	it's not. And we know that firsthand, we know where the limits of our thinness are.
3226160	3233280	Should the wall, nothing happens. Should the head of something very dramatic happens in my inner life.
3234240	3241760	So to me, that zygote already has a point of view, because that's what life is.
3241760	3249440	Life is when life is formed, what we call the rise of life is the rise of a point of view,
3249440	3255520	because it's the image of a dissociative process. And then adult human is that zygote still.
3256240	3264880	It's not another system that zygote didn't get together with trillions of other cells
3264880	3270960	that pile up on top of each other to form us. That's not the history of us. That zygote underwent
3270960	3278400	mitosis, cell division. And here we are already passing a sort of metaphysical judgment by talking
3278400	3286080	about cell division. What's happening if you look at it neutrally, that zygote is inner complexifying.
3286880	3292640	It's creating inner structure. And because it only knows how to be a cell, that's how it started,
3293360	3298960	then that inner structure is a sort of an iterative, self-similar fractal complexification.
3299760	3303680	It creates structure by adding more of the only thing it knows how to be.
3303680	3310320	So that's why it started with a point of view and has a point of view. Now it's the same thing.
3310320	3315600	I am the zygote that was in the womb of my mother. It's just that that zygote
3315600	3321120	complexified, created inner structure fractally by repeating the template. The only template it knew
3321760	3328160	how to be. This wouldn't be correct if the way human beings came to being
3329040	3335200	were by a trillion cells crawling and piling on top of each other to form us. It doesn't happen like
3335200	3345920	this. Sorry, I was passionate about this. My admiration for you forces me to be more polite.
3345920	3351920	I hope you didn't take it as an attack. It's not. But this is something I feel passionate about.
3351920	3355840	Of course. No, no. This is great. And Amir, you can tell us when it's time to move on to a different
3355840	3361760	topic because I think we could talk about this for a really long time. But I would just say a
3361760	3367040	couple of things. I agree with you that the zygote already has a perspective. I agree with that.
3371280	3378320	I also think that this business of whether something is a thing or not, I don't like the
3378320	3384560	binary framing of it. I don't think we need a binary classification. I think what's more
3384560	3391280	interesting than that are the ability of various perspectives to recognize persistent patterns.
3391280	3401120	Somebody with a very long life span of millions of years would look at each of us as a temporary
3401120	3405840	metabolic blip. It's a pattern. It's like a wave that showed up and it's gone. There's no
3405840	3412960	permanence in anything in our bodies. And the other thing I would say is that the time zero
3413520	3420160	the fertilization event, I really don't take it as seriously as you do because I visualize what's
3420160	3425840	happening there. So what's happening there is that you have an unfertilized OSI. We can see
3425840	3430720	how it got there. So the steps. So what you have is a bunch of nerve cells that basically create
3430720	3436080	a new cell and they sort of shove it full of useful materials that it's going to have later on.
3436080	3441840	And there it is. So it starts out as a bunch of chemical processes. And then at some point,
3441840	3449040	the sperm shows up. I mean, it's cool and all, but you can duplicate that with a poke of a needle
3449040	3453040	actually in many organisms. You can do it without the sperm. You can just sort of poke them with
3453040	3457840	the needle and they undergo parthenogenesis and they start to various things. Some calcium comes
3457840	3463360	in and the membrane becomes impermeable to new sperm. And then some more chemical reactions
3463360	3470560	happen. I'm just not sure there's anything fundamentally profound that happens at fertilization
3470560	3477680	per se. And I think we could, I can imagine in not too far future, all of those early processes
3477680	3482640	being done exactly, as you said before, by an aggregation kind of phenomenon, right? We could
3482640	3488720	replace those nerve cells with little microfluidic pumps that create the thing and then kick
3488720	3494480	started with a needle and so on. I think the whole thing is much more continuous. And it's
3494480	3499920	about a transit. What I see when I look at biology and when I look at the world, what I see is a
3500000	3504720	constant transformation, meaning growing and shrinking and a reshuffling of perspectives.
3504720	3508640	I see cognitive light cones that can be very large. They can be very small. They're all looking at
3508640	3513440	each other. They're all making estimates about where the other beings are and what the sort of
3515760	3523200	cognitive capacity of these beings are. And I'm just not seeing any binary categories for us
3523200	3526720	or for thingness or for anything else. I think there are just perspectives.
3527600	3532160	I'll briefly comment on this. I mean, I think we are sort of beginning to converge or at least
3532160	3538640	identifying where we don't agree, but very briefly, just to prevent a misunderstanding.
3540160	3546400	I don't think facundation is the rise of a point of view from no points of view.
3547680	3555280	Facundation is two points of view creating a third. So it's from points of view to a different
3555280	3559040	point of view. So it's not a fundamental transition. You're not creating something
3560160	3564640	that's fundamentally new. It already started with two previous points of view,
3564640	3570640	but those two previous points of views mixed in a certain way and outcomes a different point of view.
3572800	3581120	What I think is trickier, and maybe you agree with me, is that it's a biogenesis.
3581760	3587120	The rise of life from non-life is when you truly create a point of view from things that were
3587120	3591520	not a point of view. That is a little trickier. Otherwise, we would have done it already. You
3591520	3596880	would have done it already. Craig Venter would have done it already, but all he managed to do
3596880	3605120	was to synthesize DNA and implant it on a sort of empty shell that was alive. It started from life.
3605120	3610720	So there seems to be something... If you ask me, do I think we will artificially be able
3610720	3616960	to induce a biogenesis? I think we will. I don't see any fundamental reason for us not to be able
3616960	3623040	to do that, because obviously it has happened at least once in the universe. So if it has happened,
3623040	3628720	it can happen. And if it can happen, maybe it would take the monkeys another 500 years, but I
3628720	3634560	don't see any fundamental reason why the monkeys won't be able to do that. But it is on a different
3635520	3642240	level and level of complexity than fecundation, I think. Otherwise, we would have done it already.
3647600	3651440	What do we say, Amir? Should we more of that or go on to something else?
3653200	3658400	I mean, someone put in the comments, I think it's such an important topic. It's my favorite one.
3658400	3662000	I don't want to bias the whole group, but several people put little emoticons on that.
3662720	3670880	So this is kind of fundamental to who we are and what we are conscious of. I don't think there's
3670880	3675600	a more important topic they're able to put in the chat and everyone who thinks, no, we really need
3675600	3678960	to discuss this, put lots of emoticons on it, and then we'll see, okay, there's something
3678960	3686240	people feel we urgently need to discuss. The only thing I'm nervous about in terms of the group is
3686320	3695280	I'm following it, but mainly thanks to having, you know, watched a lot of your stuff, Michael,
3695280	3703440	and also being invested in this for a little bit. So I just wonder if it was like a short recap,
3703440	3711360	if that's possible, and then the kind of chat to the TV version of like, okay,
3711360	3715840	some of this debate in a paragraph in simple terms, I think that's possible for you.
3717440	3722960	Yeah, yeah, that's going to be tough. I think it's because we're talking about a number of really,
3722960	3729040	really deep issues here. I mean, one thing I think that we're discussing is whether there are
3729600	3733360	binary categories for some of the interesting things that we talk about, for example, living
3733360	3738000	or not living. Now, this may be crazy for biologists to say, but I don't actually believe that's a
3738000	3745200	distinction. So I think it's a spectrum. I don't believe that, you know, you can say something
3745200	3754320	is life or not life. I think what you can say is to what degree is something good at scaling the
3754320	3761600	cognitive light cone of its parts. I think we call things alive, where the system itself has a larger
3761600	3766320	and a more interesting cognitive light cone than all of its parts have, you know, so rocks don't
3766320	3771520	do that, right? So little particles have a very tiny, I don't think it's zero, but I think it's
3771520	3777680	extremely tiny cognitive light cone and the rock has exactly the same. But living things are actually
3777680	3784160	very good at scaling these perspectives and climbing up that cognitive hierarchy. But to me,
3784160	3791280	it's a continuum. And I think that, you know, I think that the creation of life from scratch,
3791280	3797520	as you know, the biogenesis that Bernardo was talking about, I think we are, as you say, I think
3797520	3801200	we're going to get there. I don't think, I don't think there are, I think it's a technological
3801200	3806160	issue that's stopping us now. It's not a knowledge issue. It's not a kind of a, you know, a fundamental
3806160	3810960	thing. But anyway, I think I think we're talking about that, whether there are these binary
3810960	3816960	categories. And I think we're also talking about whether there are objective facts about the,
3816960	3824240	about, you know, what a thing is or whether something is an agent or is not. And so whether
3824240	3829520	that's the case or whether everything is a matter of a perspective from some kind of system, you
3829520	3834160	know, is it super helpful to take the perspective of a table? I think not. I think you don't end up
3834160	3839840	with much. But I do think that there are systems that we can build that might be biological,
3839840	3844560	that might be technological, that might be hybrid. So we make hybrids, which have a little bit of
3844560	3850320	biology, but otherwise they're basically an engineered system. And to really understand,
3850320	3853760	to relate to that system, to understand what it's doing, what it's capable of,
3853760	3858720	at some cases, to have ethical relationships with it, I think you do need to take its perspective,
3858720	3868720	not as a technique or a, you know, a bit of fakery that you indulge in to help the science go,
3868720	3874480	but actually fundamentally, you know, I really do believe that all kinds of things have perspectives
3874960	3879680	that we currently do not recognize. I don't think we're very good at recognizing the perspective
3879680	3884640	of unconventional systems that are not like us. And I think they're real in the sense that
3884640	3889120	anything is real. And I mean, I share, you know, basic, you know, kind of these idealist,
3889120	3895680	you know, kind of basic ideas with Bernardo, but I think there are way more perspectives
3895680	3901840	in the universe than we think, you know. Do you associate life with the Borell and
3901920	3908640	Autopolyasis? I think, I think it's, so what I think is auto-police is very important for,
3908640	3913360	is the creation of a mind, not life. I think, I think cognitive, I'm much more interested in the
3913360	3920080	cognitive kind of distinctions than life or not life. I don't think, I think we can absolutely
3920080	3926720	make things that would engage in some degree of auto-police is that, that some people wouldn't
3926720	3930080	call alive, I guess. I don't even know, I don't have a good definition for life. You could,
3930080	3933760	you know, you could bring on Sarah Walker or somebody who really thinks about life, per se,
3934640	3938960	and she would have a different opinion, I think. I don't spend much time thinking about life at
3938960	3945120	all. But I do think that auto-police is a critical component of making a mind with a
3945120	3950480	significant inner perspective. If you're not auto-poetic, you're going to have an extremely
3950480	3957760	small inner perspective. When you say that non-living things may have perspectives,
3957760	3962720	do you mean that there is something that is like to be them, that they are conscious in their own
3963760	3966880	right, in their own, given the boundaries of their own system?
3967760	3972880	So this is, you know, the what's it like to be is an interesting question, because look, if you say,
3972880	3976320	let's go back to the kind of original, you know, what's it like to be a bat, right?
3976320	3980160	So what are we really asking there? If you ask that question, what's it like to be some kind of a
3980160	3988240	system? If you, what I think you're really talking about is a relationship between two things. In
3988240	3993360	other words, if I really knew what it was like to be a bat, there would just be one more bat.
3993360	3997280	Okay, I wouldn't be finding out what it's like to be a bat. If I really, really knew everything
3997280	4000720	about what it was to be a bat, I would just be a bat. And that's it. There'd be one more bat,
4000720	4006080	and I wouldn't learn a darn thing. There'd be a bat. So what we're really talking about is some
4006080	4014160	kind of a, I view it as some kind of a control knob, where what you're really saying is I'm going
4014160	4019440	to retain some features of myself, but I'm going to twist this knob a little bit so that some other
4019440	4024720	things are going to change, I'll become more bat like, and then I'm going to know what it's like
4024720	4028080	to some extent to be like this other creature. I don't think, you know, if you go all the way,
4028080	4033760	then you then you're just whatever it is. So, so I think it's a I think that question is actually
4034320	4041520	much harder than, than a lot of people make it out to be. But, but yes, I do think that some
4041520	4046640	things that currently people would not classify as living. And I don't know, I mean, people, like,
4046640	4051440	if you look at a textbook that kids use, they use all kinds of criteria, you know, what has to be
4052000	4056320	subject to the laws of evolution, and it has to have metabolism and, you know, some other stuff,
4056320	4061360	right? So there may be some criteria like that. Yeah, I think that I think that there can be,
4061440	4065840	and probably are both here and outer, you know, sort of wider in the universe,
4066480	4072080	things that would fail those criteria, and that do have a useful inner perspective from which to
4072080	4080800	see the universe. Do you think viruses have a conscious perspective? So, so, so I reject the
4081840	4087520	do they or don't they kind of thing, right? Because I will not try to put it in a category,
4087520	4092880	I will simply ask the question, if you try to view the world from the perspective of a virus,
4092880	4098160	what do you see? And I think you see very little. I don't think you see zero, but I think you see
4098160	4102400	very little. And so, and so that's what we're talking about. I think all of this is about
4103120	4107360	what is the, what is the cognitive like cone? And this is by the way an experimental, I mean,
4107360	4112480	people, people said this about, about cells and tissues, they say, oh, that's zero. And I'm saying,
4112480	4116080	no, you need to do experiments. And if you do experiments, you might find that there actually
4116080	4122240	is a very useful inner perspective that you can try to at least get your head around you,
4122240	4125280	you're never going to be it, you're never going to be that system, but you're going to at least try.
4125840	4131680	So, you know, yes, do I think they have some degree of inner perspective? Yes,
4131680	4135680	is it, is it, is it significant? I think it's extremely small.
4136880	4143360	If you look at integrated information theory, they are flexible about what where the boundaries
4143360	4149360	are. I mean, flexible, the theory implies where the boundaries are, but that doesn't necessarily
4149360	4155360	line up with life, at least not in principle, not a priori, maybe in practice, it may line up with
4155360	4162880	life. And as far as we know, it does, but not, not a priori. But the theory does say, even if we
4162880	4166480	don't know where the boundaries are, because we don't have the instrumentation to make the measurements
4166480	4172480	that are needed for us to derive that conclusion, there are boundaries, because of the exclusion
4172480	4181920	principle in IIT. So, whatever, whatever states become part of a complex, their perspective
4181920	4189520	becomes subsumed in the perspective of the entire complex. In other words, the states that form
4189520	4196560	a complex do not have a perspective of their own. That's the integrated information part of the theory.
4197520	4203600	Do you disagree with that? Do you think there aren't such criteria for determining what is
4203600	4209200	subsumed and what is not? What I don't, well, a couple of things, again, and I mean, you know,
4210160	4214880	I don't believe that there are objective criteria for any of this. I think all of these criteria
4214880	4219840	are from the perspective of some observer, which in the case of significant systems like living
4219840	4225920	systems, is the system itself. Okay. What I don't like, I mean, IIT, what I, the one thing I don't
4226000	4230640	like about it is that exclusion axiom, right? I mean, it's basically something that's just sort
4230640	4235360	of added on with my understanding of it anyways, that it's just added on. I don't like it because
4236640	4244640	I do think that even in the human organisms, there are multiple, there are multiple selves,
4244640	4248640	multiple perspectives of different degrees of sophistication. I mean, it's awesome that we
4248640	4254720	have these left hemispheres that can talk to each other and verbally and make claims about
4254800	4259360	how conscious they are and how they don't think the liver is conscious. And, you know, I mean,
4259360	4263040	after all, I don't feel the liver being conscious, right? And that's great. But
4264240	4269680	that's because, I think that's because, and I don't say much about consciousness usually, but
4269680	4275280	just this kind of role with it here. I think that's because we have a very hard time taking
4275280	4280800	the perspective of other beings in other problem spaces. So I do think that, for example, the
4280800	4286480	liver, let's just take that. I think the liver is an intelligent agent that navigates physiological
4286480	4292560	state space. It's a space that we have a very hard time visualizing. Our sense organs did not
4292560	4298000	train us to navigate that, to see that space. We're bad at recognizing things that work at
4298000	4304160	other timescales and other spaces. And I think that if we did, if we were better at directly,
4304160	4309920	just imagine like, here's how you might engineer a being that could do this. Imagine a human that
4309920	4314320	was born with an innate sense of their blood chemistry, right? The way that you feel and see,
4314320	4317760	and whatever, you also had some receptors for, I don't know, 20 different parameters of your
4317760	4322400	blood chemistry, and you could feel it directly. I think if we had that, if we had, if we were
4322400	4329840	that kind of creature, I think we had no problem recognizing that our liver is an agent with some
4329840	4334160	degree of intelligence, navigating that space, dealing with all kinds of stuff that happens,
4334160	4338000	not just because it's complex, it's not an issue of complexity, it's an issue of problem solving,
4338000	4342720	it's an issue of having preferences. Your liver absolutely has preferences about which
4342720	4346480	kinds of blood chemistry it likes better than others and how it feels about certain things you
4346480	4353600	drink and stuff like that. And I think that if we were better at recognizing these things,
4353600	4360000	we would A, be able to notice it, B, we would be able to communicate with it better. I mean,
4360000	4363760	this is our research program now, is literally trying to communicate with these things, not
4363760	4368240	micromanage them, not force them, but to improve the biomedicine of drug use and regeneration
4368240	4375600	and so on. When I say drug, I mean pharmacology, to use these things as a way of getting buy-in
4375600	4379920	from the tissues, I mean, literally getting the tissues to not fight back and not to cause all
4379920	4385600	these issues with all these different reasons that drugs fail and so on, but to actually
4385600	4392800	communicate with that primitive intelligence. And yeah, I think, and of course, we don't feel
4392800	4395840	it to be conscious because we don't feel each other to be conscious either, right?
4396640	4399520	You know, that's anyway, that's my take on it.
4399520	4405280	The IIT is consistent with what you said. IIT does not say that there is only one
4405280	4412720	complex in a living creature. What it says is that whatever is part of a complex,
4412720	4417760	then the only point of view is that of the complex. The subparts do not have their own
4417760	4422480	point of view. Their own point of view becomes subsumed in the global point of view of the
4422480	4429840	complex. There are many complexities in a living being and one of them could entail the liver.
4431200	4436240	This is completely consistent with IIT and even with analytic idealism because the liver is part
4436240	4442480	of a living body. So to me, it's perfectly okay to talk about, you know, the multiple
4442480	4447040	complexities that form us. And there is even a lot of empirical evidence for this, you know,
4447040	4450960	that there has been this back and forth about what happens to consciousness when you sever
4450960	4456560	the corpus callosum. Initially they said, well, consciousness splits in two and then they talk
4456560	4461840	to the patient and the patient said, nothing changed. And then they decided, okay, it didn't
4461840	4468080	split in two. But now with modern experiments, we are seeing that in fact they have split in two.
4468800	4474880	It's just that each consciousness of the two does not notice a difference because it's
4474880	4480480	dissociated from the other and doesn't know about the presence of the other. But people behave as
4480480	4491600	do. You can ask people two different questions and depending on whether the answer comes verbally
4491600	4499120	or from writing, the answer is different because it's the left hemisphere controlling language.
4499680	4504960	And if you're writing with your left hand, then it's the right hemisphere controlling that. And
4504960	4510800	the answers are different, which is amazing. Amazing. If you confront people with this,
4510800	4517440	they will confabulate a completely implausible story for why they did that. And they will insist
4517440	4524320	that, oh, nothing changed. I am still me. So all of this is consistent. IIT does not contradict
4524960	4533040	what you said. I would even, if I may make a suggestion, Michael, I think a collaboration
4533040	4537040	between you and Julia could lead to some very interesting things.
4537040	4541360	Yeah, I agree. Yeah, and Julia and I have talked about these kind of things. We are using some of
4541360	4550080	those techniques to look for not really Phi, but various surrogate metrics of Phi in the various
4550080	4554960	things. Like for example, in this scenario where we do have cells that come together to become a
4554960	4559520	xenobot or to, you know, we have other kinds of systems where cells come together, like to
4559520	4563360	literally watch, right? Can we look at by tracking calcium signaling and other things?
4563360	4568960	Can we actually watch the integration happening? Yeah, I agree with you. I think that's super
4568960	4575680	interesting. There's another thing here that I think might end up being very relevant to this,
4575680	4581680	which is something else that I've been thinking about a lot recently, having to do with memory.
4582400	4587760	And the way that, and this is related to this issue of perspectives,
4588240	4595840	and one way, so let's just go back to the basic example that I bring up a lot, which is you got
4595840	4601520	a caterpillar, you train the caterpillar to eat some leaves on a particular color disc,
4601520	4605840	and it remembers, and so on. And then that caterpillar becomes a butterfly. So in the
4605840	4609840	process of becoming a butterfly, basically most of its brain is dissolved, most of the
4609840	4613760	connections are broken, it rebuilds a new brain, now you got this butterfly, and the butterfly
4613760	4618640	still recalls the original information. So one thing that you might think about is, wow,
4619360	4623600	where is the information stored during this process? And that's an interesting question,
4623600	4628640	but there's actually a much more interesting issue here, which is that keeping information still,
4628640	4634080	meaning recording it and making sure it doesn't change, is a minor part of this, the more major
4634080	4639200	part of this, is the fact that the butterfly and the caterpillar are completely different
4639200	4644160	architectures. So first of all, the butterfly does not eat what the caterpillar eats. So the
4644160	4648160	butterfly doesn't care about the leaves at all. And what you actually have to do, the caterpillar
4648160	4652720	lives in the two-dimensional world, it crawls around, the butterfly lives in this three-dimensional
4652720	4662160	world. So what you really have here is the ability for information to get remapped in a way that,
4662160	4666320	in your new life, as literally, I mean, this is going to sound crazy, but literally, this is all
4666320	4672400	literally true. In your new life as a higher-dimensional being, what you're going to remember is not the
4672400	4680320	details of the things you learned before, but the salient meaning, the part of that, the lessons
4680320	4684880	that you learned that are actually relevant to your new life, and they're going to get remapped
4684880	4690080	onto a completely different set of muscles and different behavioral repertoires in a butterfly
4690080	4697120	than existed in the caterpillar. So this issue of remapping information and the importance of,
4697120	4701520	from the perspective of, right, so you've got, I mean, of course, it's going to have some kind of
4702880	4707840	medium, some kind of engram that holds the information. What you have to ask is then,
4707840	4712400	from the perspective of whom, what does that information mean? So from the perspective of
4712400	4717600	the caterpillar, it might mean, you know, crawl in a certain way and get yourself some leaves
4717600	4720640	from a perspective, the butterfly, it means, I don't know, flap your wings a different way and
4720640	4726560	you're going to get some nectar, but they're reinterpreting this information from different
4726560	4733600	perspectives. And I think once you start thinking about this importance of remapping information
4733600	4738240	to new contexts, some very interesting things happen. For example, if we think about the
4739360	4745200	evolutionary lineage as a whole organism, right, so I don't know, some 50 million years of
4745200	4752320	alligators or something. So like the whole lineage, what you know for a fact, if you're
4752320	4756800	that lineage, what you know for a fact is that everything is going to change. Your body is going
4756800	4760160	to change because there will be mutations, your cells are going to change because there will be
4760160	4768640	different chemical, you know, properties in your environment. If you try to take the information
4768640	4773280	you learned in your past too seriously, if you sort of over train on those priors, you know it's
4773280	4780400	going to be poorly applicable in the future. What I think evolution does, I think it fundamentally
4780400	4786080	makes, because everything is change and everything is guaranteed to be different, what I think it
4786080	4792400	fundamentally does is mechanisms that are perspectives that are trying to extract salience
4792400	4799200	from my current situation, from whatever you were inherited, whatever you inherited from
4799200	4804480	the previous times. This is why biology is so incredibly interoperable that we can, you know,
4804480	4807920	we can take the cells out and put them, you know, we can, I didn't even get to talk about
4807920	4813280	Anthrobots yet, which is this whole new thing that we published recently. You can take the
4813280	4818320	cells out, combine them with some kind of weird nanomaterial that they've never seen before and
4818320	4824560	always something useful and something coherent happens. And it's because I think fundamentally
4825360	4832800	life and evolution have bought into the assumption that things are not going to be the same,
4832800	4838560	that you're going to have to re, you're going to have to reinterpret and remap what you have
4838560	4845360	from a different perspective. And you can think about this as, you know, we, I mean, we're not
4845360	4850320	butterfly caterpillars, but we kind of have this too, you know, when we were children, we had
4850320	4853760	certain memories and certain things were very important and other things were less important.
4853760	4857360	And then, you know, puberty kicks in and all kinds of stuff happens. Your brain is remodeled
4857360	4863360	by the hormones and whatever. And you have to now, you know, you still have those memories,
4863360	4867920	they make some sort of sense to you. And in fact, each memory recall we know now is not a
4867920	4874240	non-destructive read, right? Every instance of recall actually modifies the memory a little bit.
4874800	4881440	And so this, so I think this is just really important, the ability of, I think that's another
4881440	4884560	thing that's special, right? So auto poesis is one, but the other thing that's special
4884560	4890240	about what things that we call living is that they're just very good at
4892000	4901040	compressing down the complex states of an organism, a time t, compressing it down to an arrow,
4901040	4904880	you know, kind of almost like the, you know, the middle node of an auto encoder or something,
4904880	4909520	right? You shrunk it down, and then you're going to reinflate it, but you might reinflate it onto
4909600	4913760	a completely different context. You're not going to be the same as you were before, right? And
4913760	4919520	none of us are the same. And you can see that in evolution, where you shrink it down, every
4919520	4927040	generation shrinks it down to an egg, reinflates down to an egg, reinflates. And we can, communication
4927040	4930960	is that way too, right? So I have a complicated brain state here. If I give you a matrix of all
4930960	4935840	my neuronal states at this time, there's nothing you can do with it because your brain is somewhat
4935840	4940160	of a different structure, even if we're the same species, you can't map it exactly. But language
4940160	4944640	gives us a nice narrow interface, right? Where I can take all of that, I can squeeze it down to
4944640	4948400	a message, I give you the message, you're going to reinflate it in your own cognitive system,
4949280	4953760	however, however you can, you know, it may, it may end up the same as, as, as how I sent or may,
4953760	4957920	it may not, but you will preserve the salience, right? You're going to squeeze the salience out
4957920	4964320	of it. And so that's what I think is really important about, about memory as message passing
4964400	4970880	between temporal slices of beings and that having a perspective from which you interpret
4970880	4975600	your engrams, your environment, everything else. Yeah, I think, I think that's really key.
4976160	4981120	I can't remember what we agreed, Michael, you're staying two and a half hours or two hours or
4981120	4985280	how much time do we have you for? I got another half hour, no problem.
4986400	4991280	So I think this crowd, especially in me, would be interested in your thoughts on,
4991280	4997200	you've hinted at a platonic realm, it's speculative, has some utility in explaining
4997200	5002400	some things in evolution, if I've understood you correctly. Are you comfortable in bringing
5002400	5008080	the conversation in that direction for a bit? Sure, yeah. And this is, you know, just to be
5008080	5015920	clear, this is right at the edge of things that I feel certain about. So I'm just going to kind of
5015920	5018800	say some stuff that I've been thinking and I have no idea if this is going to,
5019520	5024960	in the end, be useful or mature properly or what. So just some thoughts.
5026960	5033920	The way I got into it was through the creation of the various synthetic
5034560	5038560	kinds of life forms that we make. So we make xenobots. The more recent thing I'll just tell
5038560	5045920	you about is anthrobots. So when we made, so xenobots are self-assembling little proto-organisms
5045920	5052160	that come together. When we scrape some skin cells off of early frog embryos, they can come
5052160	5057440	together and have all kinds of interesting behaviors and so on. And there's a bunch of
5057440	5061840	new stuff that isn't published yet about new genes that these guys express that
5061840	5066640	frog embryos don't express and so on. But one of the things that you might think when you see that
5066640	5072160	and you say, well, amphibians, we know amphibians are plastic. We know that embryos are very plastic.
5072240	5075920	Maybe this is a frog embryonic thing. Maybe this is just specific to frog embryos.
5075920	5081360	And so what we wanted to do was to get as far away from that as possible. And so
5081360	5086080	what's far away from embryonic frogs? Well, that would be adult humans.
5086080	5092960	And so this is a project by PhD students who just defended Gizem Gomushkaya in my group.
5093600	5100080	And what we did was we took tracheal epithelial cells from adult human patients. So no embryonic,
5100560	5104960	you know, no human embryos, but adult patients, they donate these tracheal epithelial cells.
5106160	5114640	And what we found was a protocol in which these cells are given a second life. They basically
5115920	5122320	grow into, again, a kind of self-multi-little organism. If I had, well, you can see this on,
5122320	5125360	there's a blog post about it. You can see the little video, this thing running around.
5125840	5133280	And so they have, again, they have a different morphology than the normal humans or human
5133280	5139920	embryos. They have different gene expression. They have some interesting abilities. One thing
5139920	5146960	that we found is that when they encounter a scratch in a bunch of human peripheral neurons,
5146960	5150720	they will actually heal that scratch. This is not in patients yet. This is in the petri dish.
5150720	5156640	But if you make a damage to a lawn of neurons, the antherbots, we can sit down there and over
5156640	5160480	about four days, they sort of knit the two sides together and repair the damage. Who would have
5160480	5164960	thought that your tracheal cells, which normally sit there quietly for decades in your lung epithelium,
5164960	5169360	have the ability to run around and heal neural wounds when given the opportunity. So you get
5169360	5180400	these emergent novel capabilities, novel structures, and we're just scratching the surface
5180960	5185920	we don't know, I think, even a tiny bit of what they can do. But once you start thinking about
5185920	5190080	where do these competencies come from, typically speaking, if you look at any kind of an animal
5190080	5197120	or plant, you say, okay, so why does it have certain shapes and certain behaviors?
5197120	5201360	The typical answer is, well, evolution, of course, eons of selection. So it was selected.
5201360	5207360	The frog genome knows how to make frogs because that is what it was selected for,
5207360	5213120	success in a froggy environment. But here you get to, and certainly our data are not the only
5213120	5217440	ones, there are other data like this, you get to a scenario where you've got these things,
5217440	5221680	well, there was no history of antherbots. There was never selective pressure for your
5221680	5225440	tracheal epithelial cells to be able to run around on their own and heal neural wounds.
5225440	5233760	There were no xenobots. Xenobots are able to construct other xenobots by running around and
5233760	5238400	collecting together loose skin cells that we give them, as we call it, kinematic self-replication.
5239680	5243920	There's never been any xenobots. There's never been selection to no other animal on earth,
5243920	5248240	as far as anybody knows, reproduces like this. Where do these capacities come from?
5248880	5253680	So you can start to think that maybe what's happening, and obviously I'm not the first
5253680	5260240	person to think this, so a lot of classic philosophy thought about this idea that there is
5260240	5267840	some sort of latent space or a platonic space in which certain kinds of, I don't even know what
5267840	5275040	to call them, I'm not going to call them objects, but certain kind of things hang out there.
5275040	5280640	And these things become instantiated, they become implemented in the real world when
5280640	5287120	physical machines show up that are good embodiments for them. So for example, when
5288080	5295120	evolution discovers different ion channels that are voltage sensitive, that immediately gives you
5295120	5300560	a voltage gate at current conductance, which is basically a transistor. So now you can make
5300560	5304800	use of all the rules of logic gates and the truth tables and all these kinds of things.
5306160	5311360	And you get that for free. You don't need to evolve all the states of a truth table for
5311440	5316240	ands and ors, you've immediately got this for free by inventing this little thing.
5316240	5320800	And there's lots of things like that that you can find that will make use of the laws of
5321760	5328480	adhesion and other laws of mathematics and computation and mechanics, biomechanics and
5328480	5335680	other things. So if you think about evolution as basically searching the space of pointers
5335680	5342800	into this platonic space, then it becomes reasonable to have a research program of
5344160	5348320	looking around to see what the structure of that space is. And so people do that, for example,
5348320	5351600	you can download this thing called the map of mathematics. And it's just like
5352480	5359520	visualization of different types of mathematics and how they sort of connect together and so on.
5359520	5362640	So you could imagine that these things that we make, so these xenobots,
5362640	5367280	anthropots, all the kind of synthetic constructs, what they really are, are little periscopes.
5367280	5373760	They're little ways to kind of stick a probe up into this space and look around and see what do
5373760	5379760	we normally pull down in a normal embryo. And a normal embryo uses tons of these kind of what
5379760	5386240	physicists call free lunches, like lots of these amazing effects that they make use of that they
5386240	5392880	don't have to evolve from scratch. But around them, there are sets of hallows of other things
5392880	5398720	that they could use if the situation was a little bit different. And by doing these perturbational
5398720	5406560	experiments, by pushing the embryo into scenarios that are different from what it normally does,
5406560	5412560	you get to explore the space. You get to explore all the stuff that's around it in latent space
5412560	5415840	and you find, oh, actually, they can do this and this and this. And we can even,
5416720	5422960	you know, we can start to think about what else is out there as a tool for engineering and for
5422960	5434240	discovery. And so that's step one, I guess, is just to realize that a lot of what evolution does is
5435200	5443200	search through the space of pointers into this reservoir of these amazing capabilities.
5445760	5450800	And then the other thing you can ask, and this gets progressively weirder and
5452320	5458240	this project is just beginning, but you can actually also ask the question of what are the
5459200	5465440	contents of that space? What is it doing on its own when it's not being instantiated here in the
5465440	5469360	physical world? In other words, the traditional, at least my understanding of the traditional
5469360	5473520	conception is that these things are, these forms are timeless. They just sort of
5473520	5478240	sit there and they don't change and they're permanent and they are how they are. I'm not sure
5478240	5485440	of that. I now have this kind of multi-layer model where we can start to imagine some,
5486320	5491680	I don't want to call it chemistry, but some rules for ways that these things can actually
5492320	5497280	interact with each other and some dynamics that can go on. And I have some ideas based on
5497280	5504880	the work of Patrick Grimm and turning logic sentences into visualizable dynamical systems,
5504880	5510240	how you can think about what the interaction laws and what the chemistry might be of these
5510240	5514960	kinds of concepts aside from the time when they're actually pulled down into a physical machine.
5516080	5519920	In the physical world. So that's the, I don't know if this makes any sense, but
5519920	5526560	that's the stuff that I've been thinking about. I find this fascinating. Michael Roger Penrose
5526560	5533280	is well known for talking about this platonic realm as well. So for three decades now, I think he is
5535120	5540480	people who want to put him down and say, Roger is not even a dualist. He's a trialist because
5540480	5544800	he's saying there is the physical stuff, there is the mental stuff, and then there is the platonic
5544800	5552240	stuff. My own perspective, and I wanted to sort of run that by you and get your thoughts on it,
5552880	5559680	is that we don't need a separate thing. If we say, okay, all of existence is a play
5559680	5569200	in a field of mentation, a field of subjectivity, then that field exists. And to be to exist is
5569200	5573840	to have properties. In other words, that field is what it is and not something else that it
5573840	5579600	conceivably could have been. It is not that it is what it is, and therefore it does what it does.
5579600	5587760	It has properties, it has intrinsic inherent dispositions, preferred ways of behaving,
5587760	5595280	preferred templates of behavior, so to say, and to to to abuse the language from depth psychology
5595280	5599840	could call these templates archetypes, which is the name Jung came up with. In other words,
5599920	5605600	if this is all one field of mentation, then it has to use a physical metaphor, it has
5606960	5613840	its preferred frequencies of oscillation, it has harmonics, it has resonant frequencies,
5613840	5618640	because it is what it is. And to be is to have properties, and it has the properties it has
5618640	5625440	and not others. Who do these sort of intrinsic inherent resonant frequencies, these archetypal
5625440	5631120	templates account for what you're talking about without our having to postulate a separate platonic
5631120	5637680	realm? Yeah, yes, super. So on the one hand, I mean, I agree with you in that I don't think it's
5637680	5642560	fundamentally like really in the end of all things, I don't think it's a separate realm. So I agree
5642560	5647600	with you, this is all, you know, these are all components of one bit fundamental field. But
5648320	5655280	I think for the time being, I think that's a useful, it's a useful frame to think of
5655760	5660160	because it leads to specific questions about how do we explore it, how do we map it,
5660160	5665920	the things like that. But the frequencies and the vibrations, I'm really glad you brought
5665920	5671120	that up because that's an interesting example of actually what we're doing and how we're studying it.
5674080	5679520	One thing that you might think that hangs out in this platonic realm, one thing that might
5679520	5686720	hang out there are logical statements, right, just, you know, pieces of basic logic, right.
5686720	5694800	So let's take the Liar Paradox, the self-referential sentence that says this sentence is false.
5695440	5701040	So one interesting thing about that is there's this philosopher, Patrick Grimm, if anybody
5701040	5706480	doesn't know, he's really good. And he had this work in the 90s, which is very interesting,
5706480	5715200	where he points out the following. If you look at that sentence, it's a paradox only if you
5715200	5721040	insist on a static, unchanging truth value. So if you want a truth value, you can't and it's a
5721040	5725440	paradox and okay, what do we do? But if you're willing to say that what it actually is is a
5725440	5729680	dynamical system where you actually look at it and you say, okay, this statement is false.
5729680	5733440	Okay, so it's false and you say, oh, wait a minute, but that might mean it's true. So it's true.
5733440	5741360	So as you, as a mind, as a perspective looks on this thing, what you actually see is an
5741360	5746160	oscillation. You see a true, false, true, false, true, false. So now something interesting happens
5746160	5750480	and Grimm showed how you can take either one dimensional or two dimensional. So you can do
5750480	5756480	things like he'll say, you know, sentence A, I am as true as sentence B is false. And then
5756480	5760960	sentence B says, I am twice as true as sentence A, right. And you plot those true and you get this
5760960	5764880	like crazy thing. And then it's chaotic. And sometimes they settle down, sometimes they don't
5764880	5769760	settle down, you can imagine dynamical systems that you can make all kinds of. So, so now what
5769760	5775200	you've got is something interesting. So there's a layer of this, of this space, consisting of
5775200	5781280	logical statements. Some of them are like rocks, they have a constant truth value, you know, pi is
5781280	5785040	more than three bang, that just sits there, doesn't do anything. It's completely static,
5785040	5789040	pretty boring. And so that kind of hangs out. But then you've got this other thing that's like a
5789040	5793200	it's like a it's like a simple oscillator, right? It's like a simple, you know, the simple, the
5793200	5797360	liar, the basic liar paradox is just just sitting there, it's oscillating true, false, true, false,
5797360	5801840	true, false. That's what it's doing. So this is this is what led me to this idea that that it may
5801840	5807120	not actually be these like forms that are locked in stone and don't do anything. Some of them look
5807120	5812800	like they have a dynamics to it. Then you can imagine multiple sentences that are interacting
5812800	5817120	with each other. And they have a really complex and you can plot them in different ways. You can
5817120	5820320	either plot them as a function of time, in which case they they vibrate, then they have
5820320	5824080	different frequencies, as you just said, and they do all these things. Or you can plot them in a
5824080	5827440	slightly higher dimensional space, and then you just get this shape, right? You get the shape
5827440	5832400	that you can see is okay, this set of logical claims makes this this crazy complicated looking
5832400	5836400	shape and grim actually like plot some of these out. It's pretty cool. So,
5838560	5845040	and so just one last thing. And so we're building I have one of the folks in my lab and I are making
5845040	5849360	an actual visualizer for these things so that you start with some logical statements and then
5849360	5855040	you actually see what what they look like. You can now comes the part where you can actually
5855040	5860240	instantiate a chemistry to it. Because what you can say is, okay, here's a set of statements
5860240	5866000	that refer to a few different things, let's say, you know, ABC, here's a set of statements that
5866000	5870560	refer to C, D and E. Well, they have something in common, that would be the C. And that means
5870560	5874960	that you can imagine like atoms with a free, you know, with a free a hole in their orbital,
5874960	5879520	they can they can actually come come together because you can they can combine. If it was ABC
5879520	5884400	and DEF, then, you know, noble gases, right, they don't combine at all, they don't interact with each
5884400	5890080	other, sort of slide right by but but but but but sent but sets of sentences that do refer to
5890080	5894560	things in common. Now you can look at intersect at their interactions. And you can say, well,
5894560	5898000	when they do come together, what happens? So this thing has a shape, this thing has a shape,
5898000	5902480	when they come together, what's the shape? So it turns out that, and this is just like a tiny
5902480	5907280	corner of that space, we're just looking at something super like simple and and and and basic,
5907280	5912240	which is just like these logical sentences, of course, if if that space exists at all,
5912240	5916080	there's going to be like huge amount of things in there that we don't know how to deal with.
5916080	5921360	But just just that alone, we can we can start to and then you can ask some some things like this,
5921360	5927280	for example, what's the what's the frequency of the oscillator? There isn't a time component here,
5927280	5932320	the well, there isn't an external time component here. What there is is the frame rate of whatever
5932320	5937040	cognitive system is picking up that liar paradox. So the lie paradox is hanging out there when you
5937040	5942400	have a system that can follow it through at a rate of one per second, for example, well, then
5942400	5946640	that's the frequency at that time. If you write if you're if you're much faster than that, well,
5946640	5950560	then you get a faster feeling. So it's not intrinsic. It's again, from the perspective of
5950560	5955920	whichever mind has now, you know, is now in resonance with this thing. So all that is
5956080	5960320	so this is all super early, like I don't know if any of this is going to go anywhere. So
5960320	5965520	take it all with a grain of salt. But I do very much like that you immediately went to the kind
5965520	5970880	of vibration stuff, because I think that's a good way to start thinking about it. And there's also,
5970880	5976240	if any of you have seen, and I don't remember the link at the top of my head, but Richard Watson,
5976240	5980560	who's a evolutionary biologist and computer scientist that I do a lot of collaborations with,
5980560	5985280	he has an amazing set of videos on YouTube. It's about six hours total called songs of
5985280	5990640	mind and life. And it digs very deep into this into there's not not the Platonic space stuff, but
5990640	5998240	but but this notion of the intersection between cognition and and vibration and and and things
5998240	6002960	like that. And so if anybody's interested in that, definitely check it out. It's just amazing.
6003600	6008240	It is fascinating that you're going in this direction. I didn't know that I'm very happy
6008320	6015760	to learn it. Just a brief comment. I'm not just to add to to your plate, things that you can think
6015760	6020800	about. The liar paradox, you can make it more complex, because you can split it, you can say
6020800	6027600	the fall the next sentence is false. While the next sentence is the previous sentence is true.
6028480	6032880	And then you sort of have an extended liar paradox. So you can you can extend this and
6033440	6037360	depending on how you model it, this can give you extra degrees of freedom.
6038320	6045680	Another is a quick sales pitch for a philosopher from my country that never got proper recognition.
6045680	6053280	His name is Laudsen Brouwer. He lived in the late 19th, early 20th century. And his realization
6053280	6059040	was that the five axioms of Aristotelian logic are just that. Well, not his realization. We know
6059040	6066480	that from Agrippa's Trilemma, Munchhausen's Trilemma, logic cannot be used to validate logic
6066480	6072720	without running into circular reason. In other words, the axioms of logic are arbitrary. The only
6072720	6076960	thing they have going for them is that we think they are self evidently true. And when we apply
6076960	6084240	them empirically, most of the time they work, not always quantum mechanics comes in here and
6084240	6092400	tells us that it's not always the case. But Brouwer, he figured that the law of excluded middle,
6092400	6099760	which is one of the five axioms, it's the axiom that says every statement is either true or false,
6100400	6109760	not both and not neither. And he decided to get rid of this axiom and see if we could construct a
6109760	6116640	coherent logic, operationally applicable and coherent, internally consistent logic without
6116640	6122720	that axiom. And lo and behold, we can. And in some application, it's much more reasonable than
6122720	6131280	Aristotelian logic. He called it intuitionist logic. And that gives you just a quick example
6131280	6139920	of one case in which it's very compelling that it's a better logic in mathematics. And therefore,
6139920	6147120	by implication in physics and the other natural sciences, you can, because of the law of excluded
6147120	6156800	middle, you can prove that something exists by proving that it cannot not exist. And that allows
6156800	6162960	you to prove that something exists without ever being able to conceive of an example of it.
6164160	6171920	An example, a simple example of that which you have just proven that it exists. And under
6171920	6177680	intuitionist logic, this doesn't work because you don't have the law of excluded middle. So to prove
6177680	6185920	that something exists, you have to produce one example. And that is much more empirically intuitive,
6185920	6192080	right? Because how can you prove that something exists if you can't even give me or conceive of
6192080	6197040	an example? Tell me what it is that you're that you have proven to exist. And you can't even say
6197040	6203280	that you can't even tell me that. So I, you wouldn't get the oscillations from that. Because to get
6203280	6210240	to the oscillations, you don't have fixed truth values, but you're still using the law of excluded
6210240	6218480	middle. But you could get some, you could get some other quite interesting dynamics. And some people,
6219200	6225760	some people have speculated about whether something like this, intuitionist logic,
6225760	6230320	would be a better path for us to make sense of the so-called high strangeness phenomena, some
6230320	6237680	psychological phenomena that are weirder than dreams. And yet people report it. So it's a,
6237680	6244320	it's a phenomenal reality and stuff that people experience. So how is their mind operating to
6244320	6249280	produce high strangeness phenomena? Or how is the mind of nature operating to produce high
6249280	6256560	strangeness phenomena? And the hypothesis I raised was it is not using the law of excluded middle.
6257120	6264640	That's, that's monkey logic. It's not nature's logic. Anyway, just wanted to put it out there.
6264640	6270720	Loudson Brower is the name of the guy that should be as well known as Spinoza, but unfortunately
6270720	6276320	he isn't. He had some other weird thinking about social issues that maybe is the reason
6276320	6280720	that he would never be popular in the world today, but he had some very interesting ideas.
6281680	6285920	Yeah, super cool. Thanks. That's, that's, that's great. I was aware of intuitionism,
6285920	6291360	but I didn't connect it to this, to this grim stuff. So that's, that's very good.
6291360	6296560	I just wrote his name on the chat. So people, because people will not know how to write down
6296560	6303840	Loudson Brower. So I just, I just put it there. That's very good. That's very good. Well, you know,
6303840	6309280	one is, I'll definitely think about that. That's excellent. And you know, another thing we started
6309280	6314960	to think about is, is enabling, I mean, this is some steps down, but enabling some of the, again,
6315120	6320480	I'm really, I'm really interested in this, this notion of, as William James once said that
6321600	6326880	thoughts are the thinker, you know, and this idea of active data and, and, and sort of erasing
6326880	6333040	the distinction between passive data that, and, and in the context of this thing we were just
6333040	6338080	talking about, you could imagine that some of the sentences contain elements that actually modify
6338080	6341920	the sentences. So you could imagine, right, a self-referential kind of thing where there are
6341920	6346240	certain atoms that actually go and cut out pieces from another sentence or alter edit,
6346240	6350000	you know, some sort of spring rewriting rules or something like that, right? So you can imagine,
6350000	6353520	but, but, but the other thing about that is to go back to, because I think I forgot to mention
6353520	6361440	this in the business about memories. If, if the job, if, if, if what the, the system wants to do
6361440	6368160	is remap ngrams and other pieces of information that it got from its past self or from whoever,
6368240	6374400	into the new context, you could imagine that the, the ngrams themselves might be active. In
6374400	6378080	other words, they don't have to be completely passive. They could also, there might be some
6378080	6382560	advantages to them to be picked up and nourished, you know, maybe they're just passive molecules,
6382560	6387840	but maybe they're, maybe they're not molecules, maybe they're vibration cycles, or maybe they
6387840	6393920	write some kind of, some kind of oscillation patterns that actually can be fed by appropriate
6393920	6398800	resonance with, with the cognitive system that they're going into. And so maybe they can actually
6399680	6403920	increase the likelihood that they get picked up and reproduced or, or something by, by
6404560	6407680	dynamics that they do, right? So, so they don't have to be passive entirely. So
6408400	6413520	as I'm also, also kind of fooling around with some, with some models like that of, of, of
6413520	6421120	memories as self reproducing patterns that have their own little tiny agendas. And maybe it's
6421680	6425520	as persist, you know, that may be the simplest thing, but maybe it's something else, maybe it's
6426160	6431360	more than persist, maybe it's, you know, kind of like individual neurons like to have a job,
6431360	6434880	you know, they like to connect to circuits where they're actually going to, going to do something.
6434880	6437360	And so maybe these things too, maybe, you know, maybe their primary
6439360	6445920	driver is to be, to be remapped and in the new, in their new context and not be wiped out,
6445920	6450960	which kind of gets to this kind of basic philosophical thing, which is, you know,
6450960	6455920	there's some things called Bateson's paradox, this idea that if you're a species, right,
6455920	6459920	you have a choice. If you don't change with the environment, you're going to die out, right?
6459920	6464000	You're going to, you're going to be go extinct. But if you do change, well, you're also kind of
6464000	6468000	gone because you're not the same anymore, right? So, so what do you do? And I think that, yes,
6468000	6473840	that's the case for that. That's a dilemma that, that is, is a problem for evolutionary lineages.
6474560	6481520	Either way, you're not going to persist as that same thing. But it's also, I think, a problem for
6481520	6486480	any kind of cognitive agent, because if you really are intent on not changing and persisting as you
6486480	6490880	are, then you can't learn, you can't modify yourself, you can't improve, you can't, you know,
6490880	6497200	you can't make any changes in light of further experience. You know that the most profound
6497200	6501040	experiences are going to change you in some way, you're just not, whether it's, you know, the
6501040	6505120	mechanics of metamorphosis or puberty or whether it's learning, and you're just not going to be
6505120	6509840	the same. And so committing to this idea that whatever persists, it's not going to be a thing,
6509840	6515520	it's going to be a pattern. And then, then, then, then, then it makes sense, then you can be an
6515520	6521600	evolutionary lineage that changes over time. And, and then you can be a human way or any other kind
6521600	6526560	of creature where your cells and the molecules in your brain go in and out and changes come,
6526560	6531600	but you're still the same, not because you're the same thing, but because you have an extended
6531600	6536080	cognitive history that, that ties it all together. So, yeah.
6538000	6543200	Amir, just a quick point. I wanted to ask Mike was simple. He has no question about an earlier
6543200	6551840	topic before he leaves. So if I have 30 seconds in mind to the end, it's a quick question just for
6551840	6557600	me to understand that. Do you want to do it now? It's a different, it's the earlier topic about
6557600	6563120	things. We can do it quickly, Mike. It's just from my understanding and maybe the understanding of
6563120	6569360	the people here. When you said we have to be open from multiple points of views, I'll talk about
6569360	6574400	point of, point of view as things. If there are things, then, then a thing has its point of view.
6575120	6583280	If I, if we don't have any criteria for telling what is a valid thing and what is not, then we
6583280	6589440	have an exponential explosion of the combinations of permutations of the states of nature. All of
6589440	6594080	these combinations and permutations can be things and they partly overlap. So it would have an
6594080	6601920	exponential explosion, explosion of things and points of view. Is that what you are open to
6601920	6606880	or do you think there actually is a criterion for telling what is a thing and what is not? It's
6606880	6613600	just that we don't know what it is and it may not be the same thing as life. I think there is a
6613600	6619040	criterion, but I think that criterion is different from forever. So I apologize in advance. This is
6619040	6624480	not going to be satisfying, but this is what I think. I think that the criterion is from the
6624480	6631680	perspective of each, each, each, each agent. In other words, I think that the universe is
6632720	6638080	probably infinite, but, but, but certainly and, you know, a hyper astronomical number of
6638080	6643120	perspectives and of, of beings. And from the perspective of each one of those beings,
6644000	6648960	a different set of things are things and a different set are not things. And so, so yes,
6648960	6653120	that they're absolutely and the criterion is again, from the perspective of each observer,
6653520	6658800	the criterion from the perspective of that observer is does it help sense making? Does it,
6658800	6664000	does it, it, does it give me a greater purchase on the world, both in practical terms, but also
6664000	6669520	internally, right, in my own sense making, however humble that or primitive that might be for simple
6669520	6675440	agents. But, but that's right. So you can ask any, if provided you know how to communicate with it.
6675440	6679840	So we do okay, left hemisphere to left hemisphere, we're working on ways to ask your liver questions
6679840	6684320	like quite literally we're asking for, we're now trying to develop some technology to communicate
6684320	6689200	with various other very unconventional agents. And from those kind of agents,
6691120	6697440	you will get a different set of what do I consider to be things, right. So, so, so your liver will
6697440	6701280	have all kinds of comments about persistent physiological states as things. And we will
6701280	6704160	look at those and say, no, that's that that's, I don't care about that. That's not a thing.
6704880	6710400	IIT also takes this perspective that the criteria is based on the perspective of the thing. It's,
6710400	6716080	it's the first person perspective of the thing. But IIT would say the criteria is to maximize
6716080	6721360	integrated information. Whatever partitioning maximizes information integration, that determines
6721360	6727680	what are the things. And but what you're saying is, is to maximize sense making. That's where you
6727680	6732400	depart from IIT. Instead of maximize integrated information, you maximize sense making. There
6732400	6741440	should be a way to formalize this. I really think you and Julia would make an exquisite pair.
6742800	6747040	Yeah, yeah, it's, yeah, it's been a while, actually. We used to, we used to meet up at the,
6747040	6752560	at some Templeton meetings that they used to have at the Arizona, at the ASU. So it's been
6752560	6756240	a while since I've seen them. So I will, I will talk to them again, I think. But no, you're right.
6756240	6764000	And I think that I, you know, the PHY and things like that are pretty good. I mean,
6764000	6767680	I call it sense making. But of course, I don't have a formula that you can, that you can
6767680	6772480	calculate. IIT is almost a formula you can calculate. And certainly there are surrogate
6772480	6778480	metrics that you actually can calculate. So that, so it has that benefit of it. But I am really
6778480	6783440	interested in, and this is where some of the experimental stuff kind of leads into, you know,
6783440	6790720	like bigger, bigger issues. I'm really interested in what an explanation is. And the idea that what
6790720	6794720	we are looking for as beings, not just as scientists, but as beings, we are looking for
6795360	6800160	a better understanding of the world, not just looking backwards as far as explaining what
6800160	6805040	just happened, not looking downwards as far as figuring out the particles or the components of
6805040	6810240	whatever just happened, but actually looking forwards. In other words, I think a good explanation
6810240	6815280	is a story about the world that helps you do the next good thing. In other words, it's something
6815280	6822320	that it's looking forward. It's increasing insight, not a dissection of what the hell just happened.
6822320	6826800	But as living agents, we have to live forward. We don't live backward the way that
6827440	6832000	third-person descriptions of science can do. We have to decide what do we do next. And these
6832000	6839920	things are very complex. And as beings, what I like from explanations are something that
6840000	6846080	raises my sense-making of the world, such that I see, ah, well, given that, now I can do this or
6846080	6850880	now I should do this. And I think that is, when I talk about sense-making, that's what I mean. I mean
6850880	6856240	that agents that have to actively engage with the world, and I don't mean the three-dimensional world.
6856240	6860480	I mean, whatever world they live in, it might be a physiological state space, it might be anatomical,
6860480	6866240	whatever world they actually live in. The fact that they have to engage with it is what makes
6866240	6871360	them an observer. And this is, like you mentioned, like, well, maybe photographic film is an observer.
6871360	6875200	Well, kind of, but a really tiny one, because the photographic film is not going to do anything
6875200	6880160	different based on what it sees on the film. At least the standard film doesn't do that. Whereas
6880160	6885360	things that I would call a significant agent is something that takes observations. And then the
6885360	6890800	observations matter because it tries to fit them together into a compressed representation of,
6890800	6895840	that helps it to know, well, what the hell do I do now after that? And so that's why
6896560	6901680	I think that agents see things and they see other agents. Because if you don't do that,
6901680	6906720	it does not help you understand the world you're living in. And as a practical matter,
6906720	6912000	you'll be dead in no time as a biological agent if you don't understand what you're dealing with.
6912000	6920160	There is work in physics, in foundations of physics, that dovetails very well with your
6920160	6927440	thoughts here. Marcus Miller from the Austrian Academy of Sciences, the way he frames physics
6927440	6934080	is to ask the question, what will I see next? In other words, can I predict the states of the
6934080	6940000	world? And all of physics can be rewritten in terms of this question, what will I see next,
6940000	6945200	as opposed to under the assumption that there is a fixed world out there which experiments telling
6945200	6949360	us, well, if there is such a world, it's not physical. Unless you entertain all kinds of
6949440	6960800	fantasies about multiverses and super determinism, hidden variables. But if you could relate what
6960800	6966560	will I see next to what should I do next, because what you would do next must be informed by your
6966560	6972560	ability to predict the world, what the world would do next. There is a way to mathematically
6972560	6979360	formalize this. Marcus has done it. Actually, Essential Foundation, we just got a researcher,
6979360	6986160	we are funding a researcher at the University of Tudor in Switzerland to do research on this
6986160	6992480	so-called physics of first-person perspective. Yeah, yeah. Let me just start from scratch here.
6992480	6996640	Yep, yep. No, that's really great. And the other, and I wonder if they talk to each other,
6996640	7002400	I don't know, but Carl Friston and Chris Fields and Mark Solms and these guys that I work with,
7002480	7007760	they also work on exactly this, so active inference and basically predicting your own
7007760	7013520	next sensory states and how that, you know, they call it, I think it's Carl's term,
7013520	7017600	the physics of sentience and the sentience of physics, right? So like, this is, you know,
7017600	7022000	you guys, so I don't know, I'm here, you guys might want to see if they can show up at some
7022000	7026080	point, there's some really interesting stuff. So hopefully they're talking to Miller and it's all
7026080	7031280	kind of one thing, but yes, I completely agree with you, predicting what you are going to experience
7031280	7041680	next is a really fruitful kind of frame for this. I sent Marcus Carl's paper published on
7042400	7048080	the IEEE, one of the IEEE journals in 2013 or 14 about active inference,
7049440	7055440	but I didn't hear from Marcus back. The thing, I mean, I love the work of Carl Friston, by the way,
7055440	7060000	but it's amazing how much resistance there is to it because people say, well, I can't understand
7060080	7066960	it anyway, so why will I even try? Why will I even bother? Carl is not doing himself a favor
7066960	7074400	by his writing style. Yeah, I mean, he's an amazing genius and, you know, I sure as heck don't
7074400	7082720	understand all the math behind it, but I think the very simple, so there's one kind of slice of
7082720	7088240	this, which is just surprise minimization, just alone this idea of surprise minimization is
7089120	7095200	is really powerful and you can apply it to all kinds of scenarios as Carl has done from ecosystems
7095200	7101200	to psychiatry to whatever. We had a project recently that it isn't published yet, but
7102160	7111280	another grad student in my lab, Frans Quichling, he's looking at surprise and yeast in, sorry,
7111280	7117040	not yeast, algae, algae. So, believe it or not, algae can be surprised and the reason that algae
7117040	7120800	can be surprised is because they form expectations of what's going to happen next and you can
7120800	7125680	subvert those expectations and then they get stressed out and they're surprised. So, this kind
7125680	7129920	of thing and then, you know, Chris and Chris Fields and then Carl can take it, you know, sort of
7129920	7133760	much further down and look at symmetrical interactions between the system and its environment
7133760	7137600	and who's learning about whom and, you know, turns out like both are learning about both.
7138560	7144480	Michael, if you're, I mean, sorry, I'm taking too much of your time, but here we may converge
7144560	7150080	because if you go for this, if you go for active inference, surprise, minimization,
7150080	7157600	which goes back to information theory, you will get Markov blankets, which means that you will
7157600	7165280	get life. So, it may, your criterion for determining what things are may actually be life if you pursue
7165280	7171600	that consistently because, you know, Markov blankets, you get cell membranes, active inference,
7171600	7177920	you have inner models, you know, inner states can only communicate with external states or the
7177920	7183520	other way around by proxy through the states of the Markov blanket. This is life. Actually,
7183520	7189120	Carl wrote the paper saying that this is life. Yeah, which I'm 100% on board with. That part is
7189120	7196400	completely fine. I just think that if we take it seriously, I think we're going to be able to include
7196400	7201760	in that umbrella with that exact same framework, a bunch of stuff that any reasonable biologist
7201760	7206320	is going to say, well, I don't know what this is, but it isn't life. And I'm okay. I mean, I think
7206320	7209760	what the move that you're making, and I would be perfectly comfortable with it, is to say,
7210560	7215600	guys, you got the wrong definition of life. This is what should be life, right? So, I'm okay with
7215600	7220560	that. But at that point, you know, it's, I don't know, the vocabulary, I'm kind of, yeah, less
7220560	7226560	tight to it. Fantastic. Beautiful. Thank you. So, yeah, felt like a
7229440	7236000	super amazing dialogue, which points seem to be in opposite direction and then end up converging
7236000	7239440	very naturally, which is very beautiful to see. I just want to say very quickly before you go,
7239440	7244320	Michael, because I mentioned it last time, Douglas Harding. But again, just another weird
7244320	7248640	coincidence, because he'd written this book on having no head, which you, which was the same
7248640	7253360	title, he wrote that in 1961. And it has the same title as a paper, I think you co-authored.
7253360	7258800	He also wrote a book called The Science of the First Person in 1974. So it felt like there's
7258800	7263120	someone back there writing the titles of all these kind of new ideas from a very different
7263120	7268400	perspective. He was kind of an architect and a mystic and a philosopher. Anyway, maybe we'll
7268400	7273280	bring someone along that, that kind of followed that work. Just, I know we're over time for you,
7273280	7277440	Michael. So just huge gratitude one more time. It's always fascinating. Thank you so much.
7277440	7281680	Yeah, it's just brilliant. And I hope you come back one day and then you mentioned several other
7281680	7285920	people that would be worth speaking to as well. So thank you, Michael.
7285920	7288720	Sure. You know, I absolutely will. Thank you. Thank you so much. Yeah. And thank you,
7288720	7291200	Bernardo. It was awesome to discuss all this with you, of course.
7291760	7294960	Yeah. Oh, just to say quickly, everyone, we're staying on the call for a little while, Bernardo,
7294960	7297680	because sometimes what happened last time when you left, a lot of people left not realize it.
7297680	7300560	And then we're like, oh, we didn't realize it. So yeah, carry on, Michael. We'll be here
7300560	7303680	continuing for a little bit, but Michael, carry on with what you're saying.
7303680	7307920	Cool. Yeah. No, sorry. I just, yeah, I was just thanking you and thanking Bernardo because it's,
7307920	7312160	you know, a fascinating conversation, as always. I've taken a bunch of notes on some of the stuff
7312160	7316240	you said. So very interesting. So yes, I look forward to more at any point.
7316240	7332160	Great. Exciting. Thank you so much. Take care, Michael. Thanks, everybody. Appreciate it.
