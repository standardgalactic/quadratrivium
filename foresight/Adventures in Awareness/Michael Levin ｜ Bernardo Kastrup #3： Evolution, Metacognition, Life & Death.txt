Tonight is, for the most part, a dialogue between Michael and Bernardo on topics that will include
evolution, platonic realm, metacognition, boundaries of self, potentially life and
death, some new research that Michael has to talk about. And then if there's time,
oftentimes there's less time for Q&A in the sessions where we have a guest,
then we'll do Q&A for sure. And then if there isn't time this week, then we obviously have Bernardo
back for another, I think, three weeks before we have another guest. So,
and Michael, you do quite a lot of other formats where people can follow your work
with this Q&A opportunity if someone's not in a kind of institution.
Yeah, the closest is the blog. So, people will often either comment on specific blog posts or
just email me questions. If they're good questions, I will eventually post the answers on the blog.
I've got one scheduled, one set of Q&A scheduled for, I think, next week from some stuff people
sent me. So, yeah, you can always. Like a live Q&A or one that people write in?
For now, it's been writing, I am actually going to schedule a live one. That is something
that I want to do. So, I'm just figuring out some other logistics, but I will do that.
Cool. Feel free to send us the details and we'll send it out to this community as well.
I'm sure people from here will join. Great idea.
And also, yeah, just to tell everyone that I've been following this blog. I'm not trained
in science, didn't even do biology at high school. And I'm still able to follow the core
ideas and you write it in such a fashion that someone without scientific training can follow.
So, I really appreciate that. Thanks. That's great. Yeah, that was my hope. That's great.
Yeah. And I'm learning a lot. And sometimes I use a bit of chat GPT to fill in some gaps.
I'm a little late. Sorry about that.
Cool. Welcome. Made me nervous there for a second.
Have I ever let you down? Not yet.
Cool. Great. So, welcome. How are you doing, Bernardo?
Say it again. How are you doing?
I'm okay. I had a busy day so far. I'm still a bit out of it. I have to take three deep breaths
and be here. I'm going to get there.
So, potentially, you can relax and enjoy for the first few minutes. I was discussing with
Michael earlier that maybe we could start on some of your thoughts, Michael, on evolution.
You mentioned a couple of papers or new research that you might want to mention. Does that feel
good for you if you kind of discuss a little bit? Thoughts and evolution potentially into the
platonic realm? Sure. Yeah. That sounds fine. Yeah. Okay. Cool.
Okay. Well, let's see. So, in somewhat random order, there's a couple of interesting things
that have come out of our lab recently. One has to do with this notion of hyperembryos.
What we were looking at is horizontal information transfer between embryogenesis. Normally,
you get this idea that you've got an embryo and the reason that that embryo is able to complete
its journey from being a single cell to being a complex organism is because of its genome and
the maternal proteins that are in the egg. So, it's kind of vertical, right? It's all the stuff
that's handed down by the mother. And so, one of the interesting things that we discovered,
and this was led by a PhD student in my group, Angela Tung. And what we found is something
really interesting, that when you challenge a collection of embryos with some kind of
teratogen, a teratogen is anything that tends to disrupt their ability to complete
development normally. So, it could be a drug. It could be a genetic change. It could be a
vibration. It could be all kinds of things. So, it turns out that when you challenge them with
something like this, it turns out that large groups of embryos do much better at resisting it
than small groups. And when we studied it, we found out that not only is there kind of like this
group effect, but also it is not sufficient to have a group that's made up of some individuals
that never got challenged in the first place. And the reason this is important is this.
Our initial very simple model for what's going on, why would large groups of embryos develop
better than small groups? Initially, you might think that, well, what's happening is that
if everybody's getting affected by some kind of perturbation, then by the kind of group
collective intelligence idea that everybody has some gaps in their knowledge of how to make an
embryo, but everybody's gaps are in a different place. And so, as long as they all exchange
information, then everybody can have all the information they need. That's a very simple
way to think about it. It's the way they used to do this thing where people would guess the
number of jelly beans in a jar in a store. And no individual person was ever close, but the group
actually, if you average the group, they were always spot on. So, initially, we thought that
was it. But if that was it, then what you could do is you could make a large group that's composed
of a bunch of embryos that were exposed to the stressor, and then a bunch of embryos that were
never exposed, and those would have all the information they need. And that should be even
better because they could then instruct all the others because they're not stressed out. They
would have all the information. Turns out that doesn't actually work. The only individuals
that can help the group do better is ones that have been exposed to the stressor themselves.
It's kind of this weird thing, like Mark Solm told me once that in psychoanalysis,
in order to do psychoanalysis, you have to have been yourself, psychoanalyzed. It's this kind of
participatory thing. So, it's kind of interesting that you can only help if you've already seen
that stressor. And then we use some tools to actually see the embryos communicate with each
other. It's pretty wild. You can actually see waves of information born by ATP and calcium
signaling and some other things that sort of propagate across the collective. And it has a
couple of implications. One implication it has is that lots of prior studies that look at the
toxicity of various compounds, but didn't actually look at, well, how many embryos did we expose
at one time, right? But all these studies use different numbers of, you know, Pzibar fission
fin, tadpoles and so on. All of those numbers are actually not correct. What you're getting is not
an assessment of how dangerous is that compound, what you're getting is an assessment after it's
been corrected for by the group. So, you're not seeing the raw effect. You're seeing the whatever
effect is left over after the group has done its repair functions. And so, this is very important
because what it suggests is that the information that's needed to have very stable development
is not just vertical. It's not just something that every embryo has everything they need and all
of that. It's actually a kind of a group construction project. And not only functionally does the
group do better than the large group do better than the small group or individuals, we looked at
gene expression and we asked what novel genes do large groups express that small groups and
individuals don't express. And there's a huge collection of new genes that they turn on,
which suggests that this idea that normally in developmental biology, what you're studying is
the way individual cells help each other and cooperate and compete. And then you get this
nice embryo as a result. You can take that one level higher and say that, okay, so that's embryogenesis,
but there's a kind of hyper embryo, which is the large group, which has its own dynamics,
which you can actually complete the journey better. And we can see the communication between its parts,
between the embryos, and it has its own transcriptome. The large, this hyper embryo actually has its
own set of gene expressions that otherwise its parts wouldn't have. So it's a really interesting
example. You know, we study a lot the collective intelligence of individual cells and how it scales
up to be this amazing morphogenetic system that can create anatomies and repair them and so on.
But I guess it goes one step further. It's actually the individuals are talking to each other too.
And you can imagine from that, you can imagine some therapeutic applications because what if you
could fake the effect, right? So what if in the therapeutic context, once we understand what it
is that they're saying to each other, we could possibly impose that artificially in therapeutic
context, whatever the signals are. So we're in the process of trying to understand
what the communication is like, what are they saying to each other really? It's quite a puzzle
because the information that you need to actually create a complex embryo is there's a lot of
information. It's unlikely that all of that information can be propagated by something as simple
as a single, let's say a level of ATP or whatever the molecules are going to end up being. So they
must be modulated somehow. It's really interesting to ask, how are they actually communicating and
what are they actually saying to each other? And then just this notion of the fact that, yes,
you've got individual genomes that do their job within individual embryos, but the magic of
morphogenesis and that collective intelligence doesn't stop at the border of the individual.
It actually is able to use the computational power of the large collective. So that's
that's one of the things that we did recently. Anybody any questions or comments about that?
Someone asked, horizontal gene expression like in mycelium? Someone just been reading entangled
lives. Yes and no. Yes in the sense that the genes that want embryo express are going to
affect the genes that others in the group express, but we don't think, we haven't
to conclusively ruled that, but we don't think it's that it's literally propagating the material,
like it's like we don't think it's propagating transcription factors or anything like that.
I think what's happening in this issue will come up again when we talk about some new thoughts we
had on memory, that what it's doing is basically compressing a large amount of information into
a very narrow communications channel. So something that can be easily encoded by small molecules
that are propagating, and then the recipient embryos have to sort of re-inflate or reinterpret it
for their own for their own context. I have a feeling that's what's going on, but yeah in
effect what you're seeing is horizontal transfer of information that ends up controlling gene
expression. So just a super naive question. So you've got an embryo that will do something
specific on its own, and then it behaves differently if it's surrounded by lots of other
embryos. So with a human, I'll just be like, okay, well a human can count. I'll be like,
great, there's lots of people around me, you know, I'll copy what they're doing, but
is it just passively receiving it from me? Because presumably you don't think they're
metacognitively counting how many embryos around them? Does the question make sense?
Yes, yes it does. I don't have any evidence that that they're aware that they're counting,
for sure, I'm not claiming that. But I think that what's happening is, and we actually in the paper,
I mean, you know, if anybody's interested in the details of the computational stuff,
we actually have in the paper a model of cellular automata acting this way, that is a noisy
cellular automata where each one has a problem following a specific set of rules, but there's
a large collective and they get to communicate and eventually you get pretty robust communication
in the group. So no, I don't think they're explicitly counting, but I think by virtue of
the mechanisms that couple them together, you in effect get something that is quite sensitive to
the number of individuals in your cohort. Then now at any point, obviously Bernardo,
just feel free to comment or speculate if something Mike was saying sparks an interest.
And is what you just said related to that blog that you put that was talking about a paper
around the surprising emergent behavior of algorithms?
The algorithms, well, I mean, I do think that all of these things are connected in interesting
ways. The algorithms were a different paper. So what we did there, if people want to talk about
that, what we did there was, you know, one of the things about biology is that when you look at
systems, no matter how simple you think it is, you know, even if it's some kind of a,
you know, a microbe or something, there's always more mechanism. There's always more
different components and different amazing things that you didn't know were there.
And so that makes it kind of hard to really study emergent surprising outcomes because
someone could say, well, there's probably a mechanism specifically for that. You haven't
found it yet. So what we wanted to do was to really come up with a system that is extremely
minimal, extremely transparent, where there was no place to hide, where it was obvious what all
the parts were, and then use all the tools of the frameworks we've been developing to ask,
okay, is there some kind of emergent, maybe some proto cognitive capacity here? And what we chose
were very simple things called sorting algorithms. So for anybody who doesn't do computer science
in the audience, what these are are very simple sets of steps. There's usually the whole algorithm
is usually six or seven lines of code. It's very simple. And what it's designed to do is to take
an array of numbers that are jumbled up. So it's an array of integers, let's say a hundred of them,
and they're jumbled up in random order. And there's an algorithm, which is a set of steps
that will, if you follow it consistently, what it will eventually do is sort the whole list
into let's say ascending or descending order. These are things that computer science has been
studying for decades, every computer science student starts up learning these things. And
the thing about them is that they are extremely, they're simple, they're short, they're transparent,
you can see all the parts, there is no more mechanism to be discovered. And they're completely
deterministic. And people think they know what these things do, right? So you think, we've studied
them. And so what we wanted to do was to ask the question of what surprising behaviors could be
hiding, even in something as simple as this. And it's important, because oftentimes, for example,
people who do AI and things like that, somebody said to me recently, there's no emergent behavior
in language models, I know how they're built, I know what all the parts are. And I think this
is a very dangerous attitude. And so we wanted to kind of study this very simple system. And so
what we did there was we visualized the process of a couple of interesting twists. One is that we
visualize the process of sorting these numbers as a walk through what we call sortedness space.
So they start out in a region of that space where it completely jumbled, but everybody eventually
gets to this place over here where everybody's in order. And they have to sort of, during the
sorting, that string sort of makes its way to that spot. And what we did was we said, okay,
instead of having one sort of omniscient algorithm that gets to move around all the pieces,
which is normally what happens, there's an algorithm that moves around all the parts,
what we did was we put the algorithm inside the cells themselves. This again, will be important
when we later talk about the memories, because what we basically did made was self sorting arrays.
So what we said is each number, it on its own has the ability to look to its left and to its right
and decide how happy it is about where it is. And if it's not happy, so if I'm a five, I want the
four to my left and the six to my right. And if I don't see that, I want to move somewhere else
where I'm going to be happier. That's it. There is no global control. And so
what we found when you do that, a couple of interesting things happen. First thing that
happens is that it still works. So when you do this and you have this self sorting data where
you're erasing a little bit the distinction between the algorithm and the data, because now the data
itself has a little bit of action to it. What happens is, yeah, they still sort, but now you
can do two interesting things. One thing you can do is you can make some broken cells. So you can
ask, what happens if some of the cells are broken? They can be broken in one of two ways. Either
they refuse to move when they are asked to move, or they're completely broken in that,
they don't even try to move. They're not just broken for others, but they won't swap with others,
but also they don't initiate. So they're just completely frozen in place. Normally in these
algorithms, you assume that the hardware is reliable. That is, if the algorithm says swap to
four and the seven, they swap and you never even go back to check, well, did it work? Like, was it
swapped or not? You normally don't check. This again will come up as important. The importance
of unreliable hardware, I think in biology and cognition is really critical. So we made this
kind of unreliable hardware example where they're sorting and eventually you get to
some numbers that will not move. They're frozen. And that turns out to be a barrier in their journey
towards being sorted. It's like what the definition of intelligence I like, which is the ability to
get your goals met despite all kinds of novel circumstances, perturbations, the ability to
basically to navigate your space and get your goals met. So these algorithms, just to be clear,
there is no code in there about what happens if the number doesn't move. How am I doing? Did the
number move? Nothing like that in there. The algorithm stays exactly the same. But what does
it do when you do interrupt its journey with these barriers that cannot be passed? William
James had this notion of navigating barriers and so on. And there's a concept of delayed
gratification. The deal with delayed gratification is that when you come to a barrier, if you're
a magnet and there's two magnets and they try to come together, you put a piece of wood between them.
The magnets all they're ever going to do is stay there stuck between the wood. The magnet is never
going to go around to get to its goal because it has no delayed gratification. It would have to
go further from its goal in order to get to where it's going. Magnets don't do that. But some animals
do. Some autonomous vehicles do and so on. What do these algorithms do? So it turns out that without
any special code for it, what the algorithms will do if you actually track the sorting. So here
it moves along, moves along, it's the sorting everything. It meets the barrier. When it meets
the barrier, it actually goes around and in order to go around, the array actually gets less sorted
over time. It has a degree of delayed gratification. The whole thing gets worse for a little while
until it moves all the other numbers around that broken cell and then things improve. So it has the
ability to temporarily get further away from its goal. And it only does this when it encounters
a broken cell. But it has this really primitive but already a tiny capacity for delayed gratification
that is completely emergent. It is nowhere in the algorithm for it to do that. We had no idea
this was going to do that. And so just a couple things and I'd love to hear what Bernardo has
to say about it. One thing is this little bit of delayed gratification. And then there was
another thing that we found. Because we've now put the algorithm inside the cells themselves,
that lets you do something weird. It lets you create a chimeric array where some of the cells
are following one sorting algorithm, let's say bubble sort. The other ones are following a
different algorithm, let's say selection sort or something. So it's like a chimeric. We make this
in the lab all the time. We'll make like a frog allotle which has a bunch of frog embryonic cells
with some axolotl embryonic cells. And each of them are following different algorithms. You
put them together and you ask, what does this collective make? When different parts are constructing
things under different rules, what's going to be the outcome? So we can make these chimeric strings.
We can make these algorithms where the different cells are following different rules. And then
we found something really wild, which is this. Imagine that you assign, we called it, actually
this was Adam Goldstein came up with this idea. He called it the algotype. You know,
genotype, phenotype. So this is the algotype. The algotype is the algorithm that any cell happens to
be following. At the beginning, so you've got your array of 100 numbers and it's random. The
numbers are randomly distributed and they are randomly assigned to algotypes. There's two
different algorithms randomly assigned. When you do this, let's just ask, what are the,
what's the probability that when I look at my neighbor, my neighbor is the same algotype as me?
At the beginning, it's 50% because they're random. So your neighbor has a 50% shot of being the same
type of cell as you are. At the end, after all the sorting is done, same thing. It's also going to
be 50% because the algorithm doesn't care about algotype at all. There is nothing in the algorithm
that says, what algorithm am I? What algorithm is my neighbor? There's nothing in there about that.
At the end, everybody's got to get sorted according to their integer value, which means the
algotypes again are shuffled and random. So 50% at the beginning, 50% at the end.
But what happens in the middle? If you track what happens in the middle, what happens in the middle
is the, that we call it the clustering, this idea of this measure of how, what's the probability
that I like to hang out with my buddies. There's the same type of things as I am, the same algorithm.
It actually goes like this. So in the middle, it goes up and then it comes down again. So for the,
for the, and it's, it's this, it's this amazing emergent tendency for these guys to cluster
during their journey. And it's sort of, it's, to me, it all, it's, it's, it's all, it almost
reflects like the, the, you know, the existential condition of life in a, in the universe, like
eventually the physics of the world, you have to obey the physics of the world and eventually
they're going to pull you apart. But in the meantime, even though it's not prescribed by the rules
that you're following, you get to do something interesting, something new and interesting,
and maintain a pattern at a high level. You get to make these, these clusters, these, these temporary,
temporary emergent patterns of, of, of like, like-minded, like-minded data that are, that are
sitting there. Eventually they're going to get pulled apart. But in the meantime, they're there.
And, you know, we did, we did some other things. Like we said, what happens if we relieve the
pressure a little bit of getting pulled apart, how, you know, give them a little more opportunity to
do what they really want, which is to cluster. And the way you can do that is you can allow duplicate
numbers. You can say, okay, we'll have 10 fives and 10 sixes and 10 sevens. And that way you can
sort of have your cake and eat it too. You can be a bunch of fives in the right place. But the,
but the first few fives can be one algotype and the next few can be in the, and if you do that,
they cluster even more. So you can see that the pressure to cluster is quite significant.
They just get pulled apart at the end. So I'll just stop here. But the point of, the point of that
whole, that whole, that whole journey is to just start to look at these extremely simple, transparent,
deterministic systems and already find interesting capabilities. And now, I mean, there's some
practical stuff to be done here too, because they're, they're doing this clustering for free,
basically, right? We're not, you know, it doesn't require any additional computational power. So
if that happened to be something useful, or if we coupled it to something useful,
you could imagine getting some more squeezing some more, some more juice out of, of a process
that's already happening anyway. So I'll stop here and see what, see what Bernardo has to say.
Is it okay Bernardo to just quickly see if a simple example will help anyone that,
because I've read it. So I think I'm following you, Michael. But it is a simple illustration of this
is normally assorting, let's say I've got a classroom full of school full of children,
and I want them all lined up in terms of height. And normally the teacher would stand there,
okay, you stand there, you stand there, you stand there, and kind of sorts it from a bird's eye view.
And what you've done is told each child, if the one on the right of you is, you taller than you,
swap sides, or if it's shorter than you, go further that way. And so you've given instructions
to each child to move. Is that close to what you've? Yeah, that's close. And so to following that,
that analogy, you've told them to sort by height, and eventually they do sort by height. But what
you notice is that halfway through, they also seem to be clustering by eye color. So for some reason,
they're also hanging out together by some other property that your instructions to them do not
reference at all. So there's some other property that they seem to, that they
seem to want to group by, and then eventually, of course, they'll sort out by height, and there's
no necessary relationship between height and eye color. So eventually it'll go away. But in the
meantime, you notice that, hey, there are these groups of similarly eye-colored individuals.
Great. And also, each child can only see the one right next to them. Is that how it's set up?
There's a few different, I mean, we use the few different versions of this with different ability,
different radius that they can see and so on. All right. Sorry about that. Go for it.
I'll invite you. I love your work, Michael, but here I depart from you. So I invite you to sort of
come into my thought line on this. You, of course, know Conway's Game of Life cellular
automaton. There's an array of very simple cells, and each cell obeys only essentially one rule.
If there are two or three of my neighbors who are alive, then I either stay alive or I become alive.
Otherwise, either I stay dead or I die. That's it. That's all there is. Each cell counts how many
neighbors are alive and decides whether it's alive or dead in the next cycle. That's all there is to
it. And then if you let that thing play out and you see the patterns that the living cells,
the cells that are alive, the patterns they form, we see amazing things. We see cannons firing
projectiles. We see systems that seem to be swallowing up other systems and growing as they
do that. That's why it's called the Game of Life, because we see all these patterns. But would you
concur with me that, ontically, there is only that simple rule. Everything else is an epistemic
projection of us. Yeah, so that's a super interesting and important point. So I do agree
that everything that we just mentioned, the gliders, the beehives, all of this other stuff,
it is absolutely a pattern noticed by an observer, in this case us. But my point is going to be that
I think the same thing is true of many agents in biology. In other words, I think that observing
a temporary physiological object, which is what I think gliders are, right? There are patterns
that move through an excitable medium. I think that in many ways, these kinds of things, this is
exactly what, that's a reasonable way to look at life forms, to look at stress patterns moving
through tissues, to look at genomic information propagating through a lineage agent. I agree with
you, but I think it's actually important. Randy Beard did this cool paper called the cognitive
domain of a glider in the game of life. He literally tried to take the perspective of the
glider and say, what do you see from the perspective of the glider? I think it's a projection of
other cognitive systems, and I think that's a great way to look at a lot of things in biology,
actually. I don't have a problem with that. I think complexity science has been showing us
very, very compellingly that things that we consider to be very complex, in fact, aren't
complex at all, at all, ontically. The complexity is our own projection of our own cognitive modes
onto the behavior of that thing. That thing is probably just playing out very simple rules like
the game of life. I completely agree with that. As you know, I am an extreme reductionist. It's
just that I don't try to reduce the big to the small. I try to reduce the complex to the simple,
and I think that's the correct way to reduce things. But the title of your paper, in the title
of your paper, you start by saying, what do algorithms want? Instead of saying, look, these
high-level functions that we seem to see, they may not be there at all. They may be our own
epistemic projections. The title of your paper suggests that you're doing the opposite. You're
imbuing a system made of very simple rules with the kind of cognitive modes that only complex
organisms have, like a delayed reward. Well, why do I delay my reward? Because I know, if I have an
inner model that gives me a projection of the future state, but that's not what your numbers are
doing. They do not have an inner model that allows us to anticipate a possible future state to
deliberately delay their reward. The delayed reward thing is purely an epistemic projection
of ours. It's not in the system, but it is in me because I have the model. I experience it. I can
anticipate future states and deliberately delay reward for that. That's where I get
slightly uncomfortable because you present this not as eliminating the notion that there are these
higher-level cognitive things going on. You present it as if you were imbuing things that
are very simple and mechanic with these higher-level cognitive functions. It's just like criticism.
I do it open-heartedly, Michael. Yeah, no, it's great. This is exactly the conversation to have,
and I think these are valid points. Here's my view on it, a couple things. First of all,
this idea of epistemic projections, I agree with you, and I think that it's everywhere. In other
words, when you look at an embryo, basically for all of these scenarios,
I think there are multiple perspectives, multiple points of view that an observer could take,
and you could absolutely take the bottom perspective, so to speak, and say, okay,
look, in the game of life, there are no gliders. There are no be-haves. All there is is individual
fixed cells. Nothing moves. There are individual fixed cells. It matters, though. What's interesting
to me is that these different perspectives, it's often argued that these different perspectives
are a philosophical choice. They're all as good as each other, and you can look at it from the
bottom. You can look at it some other way. I think it actually makes a huge difference, because
I'm sure you've seen somebody made a touring machine in the game of life using the gliders as
signal pulses. If you don't believe in gliders, if all you do is, if all you believe in is the
low-level rules that govern each cell, you can absolutely explain any events in the world,
in fact, you can predict forward what's going to happen in that world. You can roll it forward as
much as you want. What you're not going to do is build a touring machine out of gliders.
You can make predictions from a system that's already set up. If somebody makes a starting
position, you can certainly say everything that's going to happen about that, but I think that level
of description limits the generative insight that you have into what can happen, and it becomes
really important in the biology that we study. For example, so as you said, there are simple
rules. We look at an embryo. We look at an embryonic blastoderm. There are 50,000 cells,
and somebody will say there is no embryo here. There are just individual chemical reactions.
They're following the rules. There is no embryo here, and certainly there isn't any goal state.
What I would say is this. You can have that view, but what you're going to miss there is the fact
that all of the cells in that embryo, the reason that what we're counting, when we say one embryo,
what we're counting is the commitment of all of those cells to a particular target in that
anatomical space that they are all going to reach. The reason that I call it a goal and a target is
because functionally, if you try to deviate them from that target, you can move things around,
you can put barriers, you can do all this stuff. They will find clever ways to still get there.
Now, I'm not saying that this is a metacognitive goal the way that humans have goals and that you
can reason about your goals. You can set new goals. I'm not claiming that. There's a continuum,
of course. There's a very basic, there's a very basal version of this, but I think that perspectives
that look at the system and acknowledge that, okay, there's a perspective in which
none of this is happening. There's another perspective in which that is happening.
It leads you to new experiments. Many of the things that we've done, we've only been able to do
precisely because we take seriously the idea that, yes, this is a system that in some way
has the ability to correct towards a specific outcome. With respect to these algorithms,
I mean, you're right in that by the way, the paper itself, if you look at the paper itself,
was not titled What Do They Want, right? The paper had a very much more sort of conventional
the blog post is titled that because that's where I sort of say what I think. But
talking to Carl Friston about it, we really talked about the testing and this is an empirical
question. I don't know if this happens or not, but one of the ways you can look at as to why
they cluster is the tendency to minimize uncertainty. So your neighbor, the least
uncertain neighbor is the one that's just like you, right? So possibly you can use the active
inference framework to describe why it is that they have a pressure to cluster together with
other beings that are like them. And so this comes up in biology too. So these are all experiments
that we can do. But I would say that I think we're both right in the sense that there is
absolutely a perspective to be taken here in which there are only low level rules,
but there are other perspectives on this which may be useful in terms of finding new discoveries,
making new things. And then I guess my final thing is that I think everything is a perspective
of some agent, everything, not just some things, but all of it, everything.
I concur with you that it is operationally useful to think at different levels of abstraction.
So if you're going to build a computer, if you're going to build a Turing machine
with the Conways game of life, that it's very useful to operate at a higher level of abstraction,
where you're dealing with higher level components, otherwise you would just be,
you know, overwhelmed with detail. That is operationally useful. But at the end of the day,
it's a cultural game, right? I mean, I am on the record, very publicly,
saying that you are doing the most important work in the world right now. And people have
come to me and say, oh, look, Michael thinks algorithms want stuff. Algorithms have will.
So AI is sentient. And you are saying, you know, on a crusade saying that we have no reason to
think that AI is sentient. And where does that come from? It comes from this epistemic projection
of word usage, how we talk about things. You started your discussion today talking about,
you know, AI people saying, you know, there is nothing to this large language models that we
don't understand. I am one of those people who say that I understand the mechanics of that.
I know what is there and what is not. So the fight we are fighting is to prevent these
operationally useful levels of abstractions. In other words, this convenient fantasies,
which are very, very convenient and should be used. We are trying to prevent people from
understanding this epistemic thing as if it were an actual ontic property of the world out there.
Because that's what Black Mirror does. That's what the eight o'clock news does. That's what
the very suspicious characters on the internet and on YouTube are doing. There is money to be
made out of this. Anyway, I have a slight issue with this, but I do understand your point that
it is operationally useful. But I think we should try to stress that there is a distinction between
epistemic convenient fictions and ontic things about the world. That's when we say that we are
using an epistemic convenient fiction here. We don't mean by it that the algorithm has a will,
that it has the phenomenal state of wanting to get some teleological phenomenal state. We don't
necessarily mean that. I'll emphasize the part that we completely agree on. My point about the
language models was not that I think that they have, and I don't use the word sentience much
myself, but the kind of sentience that people often attribute to them. I don't think they have it,
but I think the kind of the fundamental thing that drives our viewpoints here is that
or the difference in our viewpoints is that I don't really believe in a binary distinction
between yes they have it or no they don't have it. I think it's a deep spectrum, and I think that
what's really interesting and important about the universe is that it's full of what I really
think is sort of competing and acting in the universe is perspectives, frames of reference.
I think very simple systems can have a perspective. I think it makes sense. It could be extremely
tiny. I don't like the binary trying to classify systems that, okay, this really
has an inner point of view, and this absolutely does not. I think it's a continuum, and I think the
question is how much utility do you get from taking the perspective of some other system,
and some of them are truly minimal. These things that we're talking about now, I don't think they're
metacognitive. I don't think they're anything like a human, but I do think that there's a sense of
a nano goal-directedness that we can have, and the problem is that if we don't believe that's
true, then we're going to have a real difficulty saying why it is that humans or whatever else
did you want to extend it to, why they have it too, because we all start life as a single cell,
and somehow you have to get to the point where you start out as a little blob of chemistry and
physics, and eventually you end up with whatever it is that you and I have real metacognitive
wants and goals and things like that. I'm not saying there isn't a difference between those
two cases, there certainly is, but the hard part is explaining that smooth transition,
and this is what we work on. Is it okay before you respond? I would love for you to respond.
If one or both of you could state as in simple terms as possible what it is you're debating,
so as many people as possible can follow, because I'm pretty sure I understand, but I don't think
I'd be able to articulate it. It's basically what is a thing. What is an emergent property?
I think that that is the discussion. When you talk about emergency in a weak manner, so not
strong emergency, not consciousness out of non-consciousness, just emergence like the shape
of sun dunes or the crystal structure of a snowflake, emergence in that sense in which
a system starts with very simple properties, but it seems to develop some very complex properties
or some complex behaviors later on. The question is, are emergent behaviors a thing, a non-tic thing
in the world out there? Does something actually emerge in the world, or is it just us that project
the modes of our cognition and what's happening? What's happening is just simple stuff. There is
nothing complex emerging. It's just the play out of simple rules in an iterative way, and we project
something to it. Michael, we both agreed that there isn't something on-tic going on out there,
if I understood Michael, but Michael says it's useful in our own language, in our own thinking,
in our own inner discourse to pretend that there is, because it allows us to think in a higher
level of abstraction, which is much easier than to continue to operate on first principles
all the way along. It's like somebody asking me to design a risk processor starting from the PN
junctions. It's not useful. I need to think in terms of gates or at least transistors.
Are there transistors in a chip? No. There are only PN and NP junctions. That's all there is to it,
doped silicon and metal. That's all there is to it, but it's useful for me to do my work, to talk
of transistors, to talk of gates, to talk of chips and interconnect networks. If I understood
Michael, that's where he's coming from, but he also thinks that we shouldn't go too strong in this
radical division between emergence being purely epistemic, not being out there in the world and
what is really out there in the world, because he thinks the idea of points of view may be a sort of
not a binary one, because if it were binary, we would have difficulty starting from a Zygote,
a single cell embryo. Can you even call that an embryo? I think we can. To us who do have a point
of view. How do you explain that transition? I think it was Michael's last point. Is this fair
enough, Michael? I think it's reasonable. The second part is straight on. The first part, I
think I want to be a little more radical than this, so let's play it out and see how it goes.
How about this? I 100% agree with you that all of these things, and by the way, it's not just
emergence. I'm not particularly impressed by the emergent complexity per se. I'm interested in
emergent goal-directedness, which is different than just complexity. But I fully agree with you
that all of those things are painted on to the world by us. They are things that we see in the
world. Here's the move I want to make. When you say us, I think it's everything. I think that us
is not just us, me and you. I think that every agent in the world, and at some point we could
talk about where that bottoms out. But I think certainly what happens in biology is systems
that try to understand other systems because they need to hack them. In order to hack them,
you don't want to always try to think of them as the lowest level of a bunch of emergent complex
chemical soups that are going to happen. If these other systems have any kind of goal-directedness,
and I don't mean human purpose, I mean the kind of things you study in cybernetics, and everything
in between. All of these other high-level features, you will paint it on to the world.
This is how you are going to relate to the world. You do not have, as an agent in this universe,
you don't have the luxury of being a Laplacian demon and sort of having an unbiased view of the
whole world from the particles up. You have to coarse-grain it and sense-making in a way that
makes sense to you, and inevitably you're going to tell agential stories about agents doing things.
I think this is universal, and I think that the universe is basically a giant set of competing
and cooperating perspectives, and it isn't just us. When we say us, it's everything. It has some
degree of inner perspective on the outside world. If you're a rock, that inner perspective is
infinitesimal. We can argue about whether it's zero, but anything above that is going to, and life
is very good at scaling up these perspectives and detecting agency and so on, is going to have
these kind of perspectives. That's my move. I think that we really need to get much better at
taking the perspective of other things that are not at all like us, and I think this has also,
of course, social implications and whatever. I think we have a really hard time looking at the
world from the perspective of other things, and I've been spending a lot of time in the last
few weeks really thinking about this and thinking of tools to help us take the perspective of other
systems. I'll try to amplify the problem you describe, and I will at least try to convince
you that I understand the problem, and then I'll try to articulate why, based on my own views,
the problem isn't there. The problem you see is we start as a single cell zygote,
which is very simple. Well, relatively speaking, because zygote, the biochemical machinery of
that thing is unpathemable. Nobody has figured out, nobody has a model of that down to first
principles, but okay, relatively simple, and then it becomes us, and we do have a point of view.
Now, the same problem is playing out in physics. The measurement problem says that physical things
only have existence in relation to an observing system, but what constitutes an observing system?
Well, anything constitutes an observing system, so anything may have a point of view.
I think both attempts to solve this problem are based on the following intuition. When it all
starts, there is no point of view, and then suddenly there is a point of view, and this
discontinuity is a problem. There is only two ways to solve it. Either everything has a point of
view from the get go, or you didn't start without a point of view. That's one possibility.
It's the assumption that the zygote does not have a point of view, and a point of view then
develops with growth that leads to the problem. It is the assumption that
any physical system is analogous to any other physical system, as far as the measurement
problem is concerned, that forces us to say anything is an observer, because we don't have
a well-behaved objective criterion to say, no, no, this is a valid observing system, and that is not,
or this is a thing, and that is not. It's a projection. It's an arbitrary way of us carving
out the world. It is not a thing, or to say the zygote doesn't have a point of view, but a grown
human has. Under my own view, a zygote already has a point of view, because a point of view
is what arises from dissociation. If there is a dissociative process, that dissociation creates
a point of view. It creates the observer, so to say, which is distinct from the world, and therefore
can observe, because it is dissociated from the world. Otherwise, it's just the world.
Then in philosophy, this question goes deeper. It's not only what has a point of view, which
under analytic idealism is only living things, as zygote is living. It developed a point of view,
the moment of accumulation. But in philosophy, it goes deeper. What constitutes a thing?
Is a painting hanging from your wall a thing? Is your table a thing? If so, are each of the
four feet of the table four things? But isn't the table then just one thing, or is it five things?
Is it the top of the table and the four feet? There is difficulty in even determining what a
thing is, let alone what properties it has. Can it observe? Does it have a point of view?
Does it have a will of itself? I mean, even before we get to that, asking whether a table
has a point of view, whether a table has volition, we have to ask, is the table a thing,
or are we just projecting the epistemic structure of our language onto the ontology of the world?
Not everything we have a distinct word for is a thing. This is a fist, we have a word for it.
Boom, it has disappeared. Where is the fist? The laws of conservation of energy have just been
violated because something has disappeared without releasing energy. How is that possible? You run
into this kind of problems. The moment we are not careful about paying attention, about mistaking
the structure of language for the ontological structure of the world, which we are very prone
to doing because we are surrounded by language. We live in a world of language. So to me,
what you are trying to do, and you are probably a pioneer in this in biology, but
you're not a pioneer of this in science in general because physics has been struggling
with this for a while, philosophy has been struggling with this for a while.
The difficulty you are having is that you do not have a clear objective criterion to determine
what is a thing as far as a certain definition of thinness that is concerned. And because you
don't have that, then everything has to be a thing. Therefore, everything has to have a point
of view in potential, or not if it's too simple like this I got, then it doesn't have one, but we
do. So what magic happens in the middle? To me, pecundation, the moment zero, t zero of life,
is what determines a thing. Why do I say that? Is it arbitrary? No, it's because unlike the question
of whether the feet of a table are real things for which there is no ontological criteria,
all criteria are epistemic. They are based on convenience. If that thing breaks, I need to
have a word to refer to it so I can repair and put another foot on my table. But there is one
exception to this. If you avoid applying epistemic criteria to carving out the world into things,
there are no things. There is no car. If you say, well, a car is everything that is needed for the
thing to move. Well, it needs the air for the combustion. Without the air, it doesn't move.
It needs the road for the tires to grip. Without the road, it doesn't move. It needs gravity to
pull it to the road. Without gravity, it doesn't move. So if you follow that criteria, this kind
of criteria, functionality criteria, which is how it's called in philosophy, then the whole
universe is a thing. There is even a naming philosophy for the blob theory, whatever. But there
is one exception to this. There is one thing for which we have objective criteria to say,
these are things. And that's life. Because if you stick a needle on the arm of my chair,
I don't feel it. But if you stick it on my arm, I do feel it. So there is a clear boundary between
what I do register and what I don't register. That boundary determines me as a real thing,
not as just a sort of an arbitrary collection of pixels on the screen of perception that we give
a name to. It's like saying, take the Mona Lisa and group all the pixels or all the infinitesimal
dots of pigment that are around yellow, given a certain tolerance. And you call that a thing.
That's what we do, this kind of arbitrary grouping of the pixels of reality. But when it comes to life,
it's not. And we know that firsthand, we know where the limits of our thinness are.
Should the wall, nothing happens. Should the head of something very dramatic happens in my inner life.
So to me, that zygote already has a point of view, because that's what life is.
Life is when life is formed, what we call the rise of life is the rise of a point of view,
because it's the image of a dissociative process. And then adult human is that zygote still.
It's not another system that zygote didn't get together with trillions of other cells
that pile up on top of each other to form us. That's not the history of us. That zygote underwent
mitosis, cell division. And here we are already passing a sort of metaphysical judgment by talking
about cell division. What's happening if you look at it neutrally, that zygote is inner complexifying.
It's creating inner structure. And because it only knows how to be a cell, that's how it started,
then that inner structure is a sort of an iterative, self-similar fractal complexification.
It creates structure by adding more of the only thing it knows how to be.
So that's why it started with a point of view and has a point of view. Now it's the same thing.
I am the zygote that was in the womb of my mother. It's just that that zygote
complexified, created inner structure fractally by repeating the template. The only template it knew
how to be. This wouldn't be correct if the way human beings came to being
were by a trillion cells crawling and piling on top of each other to form us. It doesn't happen like
this. Sorry, I was passionate about this. My admiration for you forces me to be more polite.
I hope you didn't take it as an attack. It's not. But this is something I feel passionate about.
Of course. No, no. This is great. And Amir, you can tell us when it's time to move on to a different
topic because I think we could talk about this for a really long time. But I would just say a
couple of things. I agree with you that the zygote already has a perspective. I agree with that.
I also think that this business of whether something is a thing or not, I don't like the
binary framing of it. I don't think we need a binary classification. I think what's more
interesting than that are the ability of various perspectives to recognize persistent patterns.
Somebody with a very long life span of millions of years would look at each of us as a temporary
metabolic blip. It's a pattern. It's like a wave that showed up and it's gone. There's no
permanence in anything in our bodies. And the other thing I would say is that the time zero
the fertilization event, I really don't take it as seriously as you do because I visualize what's
happening there. So what's happening there is that you have an unfertilized OSI. We can see
how it got there. So the steps. So what you have is a bunch of nerve cells that basically create
a new cell and they sort of shove it full of useful materials that it's going to have later on.
And there it is. So it starts out as a bunch of chemical processes. And then at some point,
the sperm shows up. I mean, it's cool and all, but you can duplicate that with a poke of a needle
actually in many organisms. You can do it without the sperm. You can just sort of poke them with
the needle and they undergo parthenogenesis and they start to various things. Some calcium comes
in and the membrane becomes impermeable to new sperm. And then some more chemical reactions
happen. I'm just not sure there's anything fundamentally profound that happens at fertilization
per se. And I think we could, I can imagine in not too far future, all of those early processes
being done exactly, as you said before, by an aggregation kind of phenomenon, right? We could
replace those nerve cells with little microfluidic pumps that create the thing and then kick
started with a needle and so on. I think the whole thing is much more continuous. And it's
about a transit. What I see when I look at biology and when I look at the world, what I see is a
constant transformation, meaning growing and shrinking and a reshuffling of perspectives.
I see cognitive light cones that can be very large. They can be very small. They're all looking at
each other. They're all making estimates about where the other beings are and what the sort of
cognitive capacity of these beings are. And I'm just not seeing any binary categories for us
or for thingness or for anything else. I think there are just perspectives.
I'll briefly comment on this. I mean, I think we are sort of beginning to converge or at least
identifying where we don't agree, but very briefly, just to prevent a misunderstanding.
I don't think facundation is the rise of a point of view from no points of view.
Facundation is two points of view creating a third. So it's from points of view to a different
point of view. So it's not a fundamental transition. You're not creating something
that's fundamentally new. It already started with two previous points of view,
but those two previous points of views mixed in a certain way and outcomes a different point of view.
What I think is trickier, and maybe you agree with me, is that it's a biogenesis.
The rise of life from non-life is when you truly create a point of view from things that were
not a point of view. That is a little trickier. Otherwise, we would have done it already. You
would have done it already. Craig Venter would have done it already, but all he managed to do
was to synthesize DNA and implant it on a sort of empty shell that was alive. It started from life.
So there seems to be something... If you ask me, do I think we will artificially be able
to induce a biogenesis? I think we will. I don't see any fundamental reason for us not to be able
to do that, because obviously it has happened at least once in the universe. So if it has happened,
it can happen. And if it can happen, maybe it would take the monkeys another 500 years, but I
don't see any fundamental reason why the monkeys won't be able to do that. But it is on a different
level and level of complexity than fecundation, I think. Otherwise, we would have done it already.
What do we say, Amir? Should we more of that or go on to something else?
I mean, someone put in the comments, I think it's such an important topic. It's my favorite one.
I don't want to bias the whole group, but several people put little emoticons on that.
So this is kind of fundamental to who we are and what we are conscious of. I don't think there's
a more important topic they're able to put in the chat and everyone who thinks, no, we really need
to discuss this, put lots of emoticons on it, and then we'll see, okay, there's something
people feel we urgently need to discuss. The only thing I'm nervous about in terms of the group is
I'm following it, but mainly thanks to having, you know, watched a lot of your stuff, Michael,
and also being invested in this for a little bit. So I just wonder if it was like a short recap,
if that's possible, and then the kind of chat to the TV version of like, okay,
some of this debate in a paragraph in simple terms, I think that's possible for you.
Yeah, yeah, that's going to be tough. I think it's because we're talking about a number of really,
really deep issues here. I mean, one thing I think that we're discussing is whether there are
binary categories for some of the interesting things that we talk about, for example, living
or not living. Now, this may be crazy for biologists to say, but I don't actually believe that's a
distinction. So I think it's a spectrum. I don't believe that, you know, you can say something
is life or not life. I think what you can say is to what degree is something good at scaling the
cognitive light cone of its parts. I think we call things alive, where the system itself has a larger
and a more interesting cognitive light cone than all of its parts have, you know, so rocks don't
do that, right? So little particles have a very tiny, I don't think it's zero, but I think it's
extremely tiny cognitive light cone and the rock has exactly the same. But living things are actually
very good at scaling these perspectives and climbing up that cognitive hierarchy. But to me,
it's a continuum. And I think that, you know, I think that the creation of life from scratch,
as you know, the biogenesis that Bernardo was talking about, I think we are, as you say, I think
we're going to get there. I don't think, I don't think there are, I think it's a technological
issue that's stopping us now. It's not a knowledge issue. It's not a kind of a, you know, a fundamental
thing. But anyway, I think I think we're talking about that, whether there are these binary
categories. And I think we're also talking about whether there are objective facts about the,
about, you know, what a thing is or whether something is an agent or is not. And so whether
that's the case or whether everything is a matter of a perspective from some kind of system, you
know, is it super helpful to take the perspective of a table? I think not. I think you don't end up
with much. But I do think that there are systems that we can build that might be biological,
that might be technological, that might be hybrid. So we make hybrids, which have a little bit of
biology, but otherwise they're basically an engineered system. And to really understand,
to relate to that system, to understand what it's doing, what it's capable of,
at some cases, to have ethical relationships with it, I think you do need to take its perspective,
not as a technique or a, you know, a bit of fakery that you indulge in to help the science go,
but actually fundamentally, you know, I really do believe that all kinds of things have perspectives
that we currently do not recognize. I don't think we're very good at recognizing the perspective
of unconventional systems that are not like us. And I think they're real in the sense that
anything is real. And I mean, I share, you know, basic, you know, kind of these idealist,
you know, kind of basic ideas with Bernardo, but I think there are way more perspectives
in the universe than we think, you know. Do you associate life with the Borell and
Autopolyasis? I think, I think it's, so what I think is auto-police is very important for,
is the creation of a mind, not life. I think, I think cognitive, I'm much more interested in the
cognitive kind of distinctions than life or not life. I don't think, I think we can absolutely
make things that would engage in some degree of auto-police is that, that some people wouldn't
call alive, I guess. I don't even know, I don't have a good definition for life. You could,
you know, you could bring on Sarah Walker or somebody who really thinks about life, per se,
and she would have a different opinion, I think. I don't spend much time thinking about life at
all. But I do think that auto-police is a critical component of making a mind with a
significant inner perspective. If you're not auto-poetic, you're going to have an extremely
small inner perspective. When you say that non-living things may have perspectives,
do you mean that there is something that is like to be them, that they are conscious in their own
right, in their own, given the boundaries of their own system?
So this is, you know, the what's it like to be is an interesting question, because look, if you say,
let's go back to the kind of original, you know, what's it like to be a bat, right?
So what are we really asking there? If you ask that question, what's it like to be some kind of a
system? If you, what I think you're really talking about is a relationship between two things. In
other words, if I really knew what it was like to be a bat, there would just be one more bat.
Okay, I wouldn't be finding out what it's like to be a bat. If I really, really knew everything
about what it was to be a bat, I would just be a bat. And that's it. There'd be one more bat,
and I wouldn't learn a darn thing. There'd be a bat. So what we're really talking about is some
kind of a, I view it as some kind of a control knob, where what you're really saying is I'm going
to retain some features of myself, but I'm going to twist this knob a little bit so that some other
things are going to change, I'll become more bat like, and then I'm going to know what it's like
to some extent to be like this other creature. I don't think, you know, if you go all the way,
then you then you're just whatever it is. So, so I think it's a I think that question is actually
much harder than, than a lot of people make it out to be. But, but yes, I do think that some
things that currently people would not classify as living. And I don't know, I mean, people, like,
if you look at a textbook that kids use, they use all kinds of criteria, you know, what has to be
subject to the laws of evolution, and it has to have metabolism and, you know, some other stuff,
right? So there may be some criteria like that. Yeah, I think that I think that there can be,
and probably are both here and outer, you know, sort of wider in the universe,
things that would fail those criteria, and that do have a useful inner perspective from which to
see the universe. Do you think viruses have a conscious perspective? So, so, so I reject the
do they or don't they kind of thing, right? Because I will not try to put it in a category,
I will simply ask the question, if you try to view the world from the perspective of a virus,
what do you see? And I think you see very little. I don't think you see zero, but I think you see
very little. And so, and so that's what we're talking about. I think all of this is about
what is the, what is the cognitive like cone? And this is by the way an experimental, I mean,
people, people said this about, about cells and tissues, they say, oh, that's zero. And I'm saying,
no, you need to do experiments. And if you do experiments, you might find that there actually
is a very useful inner perspective that you can try to at least get your head around you,
you're never going to be it, you're never going to be that system, but you're going to at least try.
So, you know, yes, do I think they have some degree of inner perspective? Yes,
is it, is it, is it significant? I think it's extremely small.
If you look at integrated information theory, they are flexible about what where the boundaries
are. I mean, flexible, the theory implies where the boundaries are, but that doesn't necessarily
line up with life, at least not in principle, not a priori, maybe in practice, it may line up with
life. And as far as we know, it does, but not, not a priori. But the theory does say, even if we
don't know where the boundaries are, because we don't have the instrumentation to make the measurements
that are needed for us to derive that conclusion, there are boundaries, because of the exclusion
principle in IIT. So, whatever, whatever states become part of a complex, their perspective
becomes subsumed in the perspective of the entire complex. In other words, the states that form
a complex do not have a perspective of their own. That's the integrated information part of the theory.
Do you disagree with that? Do you think there aren't such criteria for determining what is
subsumed and what is not? What I don't, well, a couple of things, again, and I mean, you know,
I don't believe that there are objective criteria for any of this. I think all of these criteria
are from the perspective of some observer, which in the case of significant systems like living
systems, is the system itself. Okay. What I don't like, I mean, IIT, what I, the one thing I don't
like about it is that exclusion axiom, right? I mean, it's basically something that's just sort
of added on with my understanding of it anyways, that it's just added on. I don't like it because
I do think that even in the human organisms, there are multiple, there are multiple selves,
multiple perspectives of different degrees of sophistication. I mean, it's awesome that we
have these left hemispheres that can talk to each other and verbally and make claims about
how conscious they are and how they don't think the liver is conscious. And, you know, I mean,
after all, I don't feel the liver being conscious, right? And that's great. But
that's because, I think that's because, and I don't say much about consciousness usually, but
just this kind of role with it here. I think that's because we have a very hard time taking
the perspective of other beings in other problem spaces. So I do think that, for example, the
liver, let's just take that. I think the liver is an intelligent agent that navigates physiological
state space. It's a space that we have a very hard time visualizing. Our sense organs did not
train us to navigate that, to see that space. We're bad at recognizing things that work at
other timescales and other spaces. And I think that if we did, if we were better at directly,
just imagine like, here's how you might engineer a being that could do this. Imagine a human that
was born with an innate sense of their blood chemistry, right? The way that you feel and see,
and whatever, you also had some receptors for, I don't know, 20 different parameters of your
blood chemistry, and you could feel it directly. I think if we had that, if we had, if we were
that kind of creature, I think we had no problem recognizing that our liver is an agent with some
degree of intelligence, navigating that space, dealing with all kinds of stuff that happens,
not just because it's complex, it's not an issue of complexity, it's an issue of problem solving,
it's an issue of having preferences. Your liver absolutely has preferences about which
kinds of blood chemistry it likes better than others and how it feels about certain things you
drink and stuff like that. And I think that if we were better at recognizing these things,
we would A, be able to notice it, B, we would be able to communicate with it better. I mean,
this is our research program now, is literally trying to communicate with these things, not
micromanage them, not force them, but to improve the biomedicine of drug use and regeneration
and so on. When I say drug, I mean pharmacology, to use these things as a way of getting buy-in
from the tissues, I mean, literally getting the tissues to not fight back and not to cause all
these issues with all these different reasons that drugs fail and so on, but to actually
communicate with that primitive intelligence. And yeah, I think, and of course, we don't feel
it to be conscious because we don't feel each other to be conscious either, right?
You know, that's anyway, that's my take on it.
The IIT is consistent with what you said. IIT does not say that there is only one
complex in a living creature. What it says is that whatever is part of a complex,
then the only point of view is that of the complex. The subparts do not have their own
point of view. Their own point of view becomes subsumed in the global point of view of the
complex. There are many complexities in a living being and one of them could entail the liver.
This is completely consistent with IIT and even with analytic idealism because the liver is part
of a living body. So to me, it's perfectly okay to talk about, you know, the multiple
complexities that form us. And there is even a lot of empirical evidence for this, you know,
that there has been this back and forth about what happens to consciousness when you sever
the corpus callosum. Initially they said, well, consciousness splits in two and then they talk
to the patient and the patient said, nothing changed. And then they decided, okay, it didn't
split in two. But now with modern experiments, we are seeing that in fact they have split in two.
It's just that each consciousness of the two does not notice a difference because it's
dissociated from the other and doesn't know about the presence of the other. But people behave as
do. You can ask people two different questions and depending on whether the answer comes verbally
or from writing, the answer is different because it's the left hemisphere controlling language.
And if you're writing with your left hand, then it's the right hemisphere controlling that. And
the answers are different, which is amazing. Amazing. If you confront people with this,
they will confabulate a completely implausible story for why they did that. And they will insist
that, oh, nothing changed. I am still me. So all of this is consistent. IIT does not contradict
what you said. I would even, if I may make a suggestion, Michael, I think a collaboration
between you and Julia could lead to some very interesting things.
Yeah, I agree. Yeah, and Julia and I have talked about these kind of things. We are using some of
those techniques to look for not really Phi, but various surrogate metrics of Phi in the various
things. Like for example, in this scenario where we do have cells that come together to become a
xenobot or to, you know, we have other kinds of systems where cells come together, like to
literally watch, right? Can we look at by tracking calcium signaling and other things?
Can we actually watch the integration happening? Yeah, I agree with you. I think that's super
interesting. There's another thing here that I think might end up being very relevant to this,
which is something else that I've been thinking about a lot recently, having to do with memory.
And the way that, and this is related to this issue of perspectives,
and one way, so let's just go back to the basic example that I bring up a lot, which is you got
a caterpillar, you train the caterpillar to eat some leaves on a particular color disc,
and it remembers, and so on. And then that caterpillar becomes a butterfly. So in the
process of becoming a butterfly, basically most of its brain is dissolved, most of the
connections are broken, it rebuilds a new brain, now you got this butterfly, and the butterfly
still recalls the original information. So one thing that you might think about is, wow,
where is the information stored during this process? And that's an interesting question,
but there's actually a much more interesting issue here, which is that keeping information still,
meaning recording it and making sure it doesn't change, is a minor part of this, the more major
part of this, is the fact that the butterfly and the caterpillar are completely different
architectures. So first of all, the butterfly does not eat what the caterpillar eats. So the
butterfly doesn't care about the leaves at all. And what you actually have to do, the caterpillar
lives in the two-dimensional world, it crawls around, the butterfly lives in this three-dimensional
world. So what you really have here is the ability for information to get remapped in a way that,
in your new life, as literally, I mean, this is going to sound crazy, but literally, this is all
literally true. In your new life as a higher-dimensional being, what you're going to remember is not the
details of the things you learned before, but the salient meaning, the part of that, the lessons
that you learned that are actually relevant to your new life, and they're going to get remapped
onto a completely different set of muscles and different behavioral repertoires in a butterfly
than existed in the caterpillar. So this issue of remapping information and the importance of,
from the perspective of, right, so you've got, I mean, of course, it's going to have some kind of
medium, some kind of engram that holds the information. What you have to ask is then,
from the perspective of whom, what does that information mean? So from the perspective of
the caterpillar, it might mean, you know, crawl in a certain way and get yourself some leaves
from a perspective, the butterfly, it means, I don't know, flap your wings a different way and
you're going to get some nectar, but they're reinterpreting this information from different
perspectives. And I think once you start thinking about this importance of remapping information
to new contexts, some very interesting things happen. For example, if we think about the
evolutionary lineage as a whole organism, right, so I don't know, some 50 million years of
alligators or something. So like the whole lineage, what you know for a fact, if you're
that lineage, what you know for a fact is that everything is going to change. Your body is going
to change because there will be mutations, your cells are going to change because there will be
different chemical, you know, properties in your environment. If you try to take the information
you learned in your past too seriously, if you sort of over train on those priors, you know it's
going to be poorly applicable in the future. What I think evolution does, I think it fundamentally
makes, because everything is change and everything is guaranteed to be different, what I think it
fundamentally does is mechanisms that are perspectives that are trying to extract salience
from my current situation, from whatever you were inherited, whatever you inherited from
the previous times. This is why biology is so incredibly interoperable that we can, you know,
we can take the cells out and put them, you know, we can, I didn't even get to talk about
Anthrobots yet, which is this whole new thing that we published recently. You can take the
cells out, combine them with some kind of weird nanomaterial that they've never seen before and
always something useful and something coherent happens. And it's because I think fundamentally
life and evolution have bought into the assumption that things are not going to be the same,
that you're going to have to re, you're going to have to reinterpret and remap what you have
from a different perspective. And you can think about this as, you know, we, I mean, we're not
butterfly caterpillars, but we kind of have this too, you know, when we were children, we had
certain memories and certain things were very important and other things were less important.
And then, you know, puberty kicks in and all kinds of stuff happens. Your brain is remodeled
by the hormones and whatever. And you have to now, you know, you still have those memories,
they make some sort of sense to you. And in fact, each memory recall we know now is not a
non-destructive read, right? Every instance of recall actually modifies the memory a little bit.
And so this, so I think this is just really important, the ability of, I think that's another
thing that's special, right? So auto poesis is one, but the other thing that's special
about what things that we call living is that they're just very good at
compressing down the complex states of an organism, a time t, compressing it down to an arrow,
you know, kind of almost like the, you know, the middle node of an auto encoder or something,
right? You shrunk it down, and then you're going to reinflate it, but you might reinflate it onto
a completely different context. You're not going to be the same as you were before, right? And
none of us are the same. And you can see that in evolution, where you shrink it down, every
generation shrinks it down to an egg, reinflates down to an egg, reinflates. And we can, communication
is that way too, right? So I have a complicated brain state here. If I give you a matrix of all
my neuronal states at this time, there's nothing you can do with it because your brain is somewhat
of a different structure, even if we're the same species, you can't map it exactly. But language
gives us a nice narrow interface, right? Where I can take all of that, I can squeeze it down to
a message, I give you the message, you're going to reinflate it in your own cognitive system,
however, however you can, you know, it may, it may end up the same as, as, as how I sent or may,
it may not, but you will preserve the salience, right? You're going to squeeze the salience out
of it. And so that's what I think is really important about, about memory as message passing
between temporal slices of beings and that having a perspective from which you interpret
your engrams, your environment, everything else. Yeah, I think, I think that's really key.
I can't remember what we agreed, Michael, you're staying two and a half hours or two hours or
how much time do we have you for? I got another half hour, no problem.
So I think this crowd, especially in me, would be interested in your thoughts on,
you've hinted at a platonic realm, it's speculative, has some utility in explaining
some things in evolution, if I've understood you correctly. Are you comfortable in bringing
the conversation in that direction for a bit? Sure, yeah. And this is, you know, just to be
clear, this is right at the edge of things that I feel certain about. So I'm just going to kind of
say some stuff that I've been thinking and I have no idea if this is going to,
in the end, be useful or mature properly or what. So just some thoughts.
The way I got into it was through the creation of the various synthetic
kinds of life forms that we make. So we make xenobots. The more recent thing I'll just tell
you about is anthrobots. So when we made, so xenobots are self-assembling little proto-organisms
that come together. When we scrape some skin cells off of early frog embryos, they can come
together and have all kinds of interesting behaviors and so on. And there's a bunch of
new stuff that isn't published yet about new genes that these guys express that
frog embryos don't express and so on. But one of the things that you might think when you see that
and you say, well, amphibians, we know amphibians are plastic. We know that embryos are very plastic.
Maybe this is a frog embryonic thing. Maybe this is just specific to frog embryos.
And so what we wanted to do was to get as far away from that as possible. And so
what's far away from embryonic frogs? Well, that would be adult humans.
And so this is a project by PhD students who just defended Gizem Gomushkaya in my group.
And what we did was we took tracheal epithelial cells from adult human patients. So no embryonic,
you know, no human embryos, but adult patients, they donate these tracheal epithelial cells.
And what we found was a protocol in which these cells are given a second life. They basically
grow into, again, a kind of self-multi-little organism. If I had, well, you can see this on,
there's a blog post about it. You can see the little video, this thing running around.
And so they have, again, they have a different morphology than the normal humans or human
embryos. They have different gene expression. They have some interesting abilities. One thing
that we found is that when they encounter a scratch in a bunch of human peripheral neurons,
they will actually heal that scratch. This is not in patients yet. This is in the petri dish.
But if you make a damage to a lawn of neurons, the antherbots, we can sit down there and over
about four days, they sort of knit the two sides together and repair the damage. Who would have
thought that your tracheal cells, which normally sit there quietly for decades in your lung epithelium,
have the ability to run around and heal neural wounds when given the opportunity. So you get
these emergent novel capabilities, novel structures, and we're just scratching the surface
we don't know, I think, even a tiny bit of what they can do. But once you start thinking about
where do these competencies come from, typically speaking, if you look at any kind of an animal
or plant, you say, okay, so why does it have certain shapes and certain behaviors?
The typical answer is, well, evolution, of course, eons of selection. So it was selected.
The frog genome knows how to make frogs because that is what it was selected for,
success in a froggy environment. But here you get to, and certainly our data are not the only
ones, there are other data like this, you get to a scenario where you've got these things,
well, there was no history of antherbots. There was never selective pressure for your
tracheal epithelial cells to be able to run around on their own and heal neural wounds.
There were no xenobots. Xenobots are able to construct other xenobots by running around and
collecting together loose skin cells that we give them, as we call it, kinematic self-replication.
There's never been any xenobots. There's never been selection to no other animal on earth,
as far as anybody knows, reproduces like this. Where do these capacities come from?
So you can start to think that maybe what's happening, and obviously I'm not the first
person to think this, so a lot of classic philosophy thought about this idea that there is
some sort of latent space or a platonic space in which certain kinds of, I don't even know what
to call them, I'm not going to call them objects, but certain kind of things hang out there.
And these things become instantiated, they become implemented in the real world when
physical machines show up that are good embodiments for them. So for example, when
evolution discovers different ion channels that are voltage sensitive, that immediately gives you
a voltage gate at current conductance, which is basically a transistor. So now you can make
use of all the rules of logic gates and the truth tables and all these kinds of things.
And you get that for free. You don't need to evolve all the states of a truth table for
ands and ors, you've immediately got this for free by inventing this little thing.
And there's lots of things like that that you can find that will make use of the laws of
adhesion and other laws of mathematics and computation and mechanics, biomechanics and
other things. So if you think about evolution as basically searching the space of pointers
into this platonic space, then it becomes reasonable to have a research program of
looking around to see what the structure of that space is. And so people do that, for example,
you can download this thing called the map of mathematics. And it's just like
visualization of different types of mathematics and how they sort of connect together and so on.
So you could imagine that these things that we make, so these xenobots,
anthropots, all the kind of synthetic constructs, what they really are, are little periscopes.
They're little ways to kind of stick a probe up into this space and look around and see what do
we normally pull down in a normal embryo. And a normal embryo uses tons of these kind of what
physicists call free lunches, like lots of these amazing effects that they make use of that they
don't have to evolve from scratch. But around them, there are sets of hallows of other things
that they could use if the situation was a little bit different. And by doing these perturbational
experiments, by pushing the embryo into scenarios that are different from what it normally does,
you get to explore the space. You get to explore all the stuff that's around it in latent space
and you find, oh, actually, they can do this and this and this. And we can even,
you know, we can start to think about what else is out there as a tool for engineering and for
discovery. And so that's step one, I guess, is just to realize that a lot of what evolution does is
search through the space of pointers into this reservoir of these amazing capabilities.
And then the other thing you can ask, and this gets progressively weirder and
this project is just beginning, but you can actually also ask the question of what are the
contents of that space? What is it doing on its own when it's not being instantiated here in the
physical world? In other words, the traditional, at least my understanding of the traditional
conception is that these things are, these forms are timeless. They just sort of
sit there and they don't change and they're permanent and they are how they are. I'm not sure
of that. I now have this kind of multi-layer model where we can start to imagine some,
I don't want to call it chemistry, but some rules for ways that these things can actually
interact with each other and some dynamics that can go on. And I have some ideas based on
the work of Patrick Grimm and turning logic sentences into visualizable dynamical systems,
how you can think about what the interaction laws and what the chemistry might be of these
kinds of concepts aside from the time when they're actually pulled down into a physical machine.
In the physical world. So that's the, I don't know if this makes any sense, but
that's the stuff that I've been thinking about. I find this fascinating. Michael Roger Penrose
is well known for talking about this platonic realm as well. So for three decades now, I think he is
people who want to put him down and say, Roger is not even a dualist. He's a trialist because
he's saying there is the physical stuff, there is the mental stuff, and then there is the platonic
stuff. My own perspective, and I wanted to sort of run that by you and get your thoughts on it,
is that we don't need a separate thing. If we say, okay, all of existence is a play
in a field of mentation, a field of subjectivity, then that field exists. And to be to exist is
to have properties. In other words, that field is what it is and not something else that it
conceivably could have been. It is not that it is what it is, and therefore it does what it does.
It has properties, it has intrinsic inherent dispositions, preferred ways of behaving,
preferred templates of behavior, so to say, and to to to abuse the language from depth psychology
could call these templates archetypes, which is the name Jung came up with. In other words,
if this is all one field of mentation, then it has to use a physical metaphor, it has
its preferred frequencies of oscillation, it has harmonics, it has resonant frequencies,
because it is what it is. And to be is to have properties, and it has the properties it has
and not others. Who do these sort of intrinsic inherent resonant frequencies, these archetypal
templates account for what you're talking about without our having to postulate a separate platonic
realm? Yeah, yes, super. So on the one hand, I mean, I agree with you in that I don't think it's
fundamentally like really in the end of all things, I don't think it's a separate realm. So I agree
with you, this is all, you know, these are all components of one bit fundamental field. But
I think for the time being, I think that's a useful, it's a useful frame to think of
because it leads to specific questions about how do we explore it, how do we map it,
the things like that. But the frequencies and the vibrations, I'm really glad you brought
that up because that's an interesting example of actually what we're doing and how we're studying it.
One thing that you might think that hangs out in this platonic realm, one thing that might
hang out there are logical statements, right, just, you know, pieces of basic logic, right.
So let's take the Liar Paradox, the self-referential sentence that says this sentence is false.
So one interesting thing about that is there's this philosopher, Patrick Grimm, if anybody
doesn't know, he's really good. And he had this work in the 90s, which is very interesting,
where he points out the following. If you look at that sentence, it's a paradox only if you
insist on a static, unchanging truth value. So if you want a truth value, you can't and it's a
paradox and okay, what do we do? But if you're willing to say that what it actually is is a
dynamical system where you actually look at it and you say, okay, this statement is false.
Okay, so it's false and you say, oh, wait a minute, but that might mean it's true. So it's true.
So as you, as a mind, as a perspective looks on this thing, what you actually see is an
oscillation. You see a true, false, true, false, true, false. So now something interesting happens
and Grimm showed how you can take either one dimensional or two dimensional. So you can do
things like he'll say, you know, sentence A, I am as true as sentence B is false. And then
sentence B says, I am twice as true as sentence A, right. And you plot those true and you get this
like crazy thing. And then it's chaotic. And sometimes they settle down, sometimes they don't
settle down, you can imagine dynamical systems that you can make all kinds of. So, so now what
you've got is something interesting. So there's a layer of this, of this space, consisting of
logical statements. Some of them are like rocks, they have a constant truth value, you know, pi is
more than three bang, that just sits there, doesn't do anything. It's completely static,
pretty boring. And so that kind of hangs out. But then you've got this other thing that's like a
it's like a it's like a simple oscillator, right? It's like a simple, you know, the simple, the
liar, the basic liar paradox is just just sitting there, it's oscillating true, false, true, false,
true, false. That's what it's doing. So this is this is what led me to this idea that that it may
not actually be these like forms that are locked in stone and don't do anything. Some of them look
like they have a dynamics to it. Then you can imagine multiple sentences that are interacting
with each other. And they have a really complex and you can plot them in different ways. You can
either plot them as a function of time, in which case they they vibrate, then they have
different frequencies, as you just said, and they do all these things. Or you can plot them in a
slightly higher dimensional space, and then you just get this shape, right? You get the shape
that you can see is okay, this set of logical claims makes this this crazy complicated looking
shape and grim actually like plot some of these out. It's pretty cool. So,
and so just one last thing. And so we're building I have one of the folks in my lab and I are making
an actual visualizer for these things so that you start with some logical statements and then
you actually see what what they look like. You can now comes the part where you can actually
instantiate a chemistry to it. Because what you can say is, okay, here's a set of statements
that refer to a few different things, let's say, you know, ABC, here's a set of statements that
refer to C, D and E. Well, they have something in common, that would be the C. And that means
that you can imagine like atoms with a free, you know, with a free a hole in their orbital,
they can they can actually come come together because you can they can combine. If it was ABC
and DEF, then, you know, noble gases, right, they don't combine at all, they don't interact with each
other, sort of slide right by but but but but but sent but sets of sentences that do refer to
things in common. Now you can look at intersect at their interactions. And you can say, well,
when they do come together, what happens? So this thing has a shape, this thing has a shape,
when they come together, what's the shape? So it turns out that, and this is just like a tiny
corner of that space, we're just looking at something super like simple and and and and basic,
which is just like these logical sentences, of course, if if that space exists at all,
there's going to be like huge amount of things in there that we don't know how to deal with.
But just just that alone, we can we can start to and then you can ask some some things like this,
for example, what's the what's the frequency of the oscillator? There isn't a time component here,
the well, there isn't an external time component here. What there is is the frame rate of whatever
cognitive system is picking up that liar paradox. So the lie paradox is hanging out there when you
have a system that can follow it through at a rate of one per second, for example, well, then
that's the frequency at that time. If you write if you're if you're much faster than that, well,
then you get a faster feeling. So it's not intrinsic. It's again, from the perspective of
whichever mind has now, you know, is now in resonance with this thing. So all that is
so this is all super early, like I don't know if any of this is going to go anywhere. So
take it all with a grain of salt. But I do very much like that you immediately went to the kind
of vibration stuff, because I think that's a good way to start thinking about it. And there's also,
if any of you have seen, and I don't remember the link at the top of my head, but Richard Watson,
who's a evolutionary biologist and computer scientist that I do a lot of collaborations with,
he has an amazing set of videos on YouTube. It's about six hours total called songs of
mind and life. And it digs very deep into this into there's not not the Platonic space stuff, but
but but this notion of the intersection between cognition and and vibration and and and things
like that. And so if anybody's interested in that, definitely check it out. It's just amazing.
It is fascinating that you're going in this direction. I didn't know that I'm very happy
to learn it. Just a brief comment. I'm not just to add to to your plate, things that you can think
about. The liar paradox, you can make it more complex, because you can split it, you can say
the fall the next sentence is false. While the next sentence is the previous sentence is true.
And then you sort of have an extended liar paradox. So you can you can extend this and
depending on how you model it, this can give you extra degrees of freedom.
Another is a quick sales pitch for a philosopher from my country that never got proper recognition.
His name is Laudsen Brouwer. He lived in the late 19th, early 20th century. And his realization
was that the five axioms of Aristotelian logic are just that. Well, not his realization. We know
that from Agrippa's Trilemma, Munchhausen's Trilemma, logic cannot be used to validate logic
without running into circular reason. In other words, the axioms of logic are arbitrary. The only
thing they have going for them is that we think they are self evidently true. And when we apply
them empirically, most of the time they work, not always quantum mechanics comes in here and
tells us that it's not always the case. But Brouwer, he figured that the law of excluded middle,
which is one of the five axioms, it's the axiom that says every statement is either true or false,
not both and not neither. And he decided to get rid of this axiom and see if we could construct a
coherent logic, operationally applicable and coherent, internally consistent logic without
that axiom. And lo and behold, we can. And in some application, it's much more reasonable than
Aristotelian logic. He called it intuitionist logic. And that gives you just a quick example
of one case in which it's very compelling that it's a better logic in mathematics. And therefore,
by implication in physics and the other natural sciences, you can, because of the law of excluded
middle, you can prove that something exists by proving that it cannot not exist. And that allows
you to prove that something exists without ever being able to conceive of an example of it.
An example, a simple example of that which you have just proven that it exists. And under
intuitionist logic, this doesn't work because you don't have the law of excluded middle. So to prove
that something exists, you have to produce one example. And that is much more empirically intuitive,
right? Because how can you prove that something exists if you can't even give me or conceive of
an example? Tell me what it is that you're that you have proven to exist. And you can't even say
that you can't even tell me that. So I, you wouldn't get the oscillations from that. Because to get
to the oscillations, you don't have fixed truth values, but you're still using the law of excluded
middle. But you could get some, you could get some other quite interesting dynamics. And some people,
some people have speculated about whether something like this, intuitionist logic,
would be a better path for us to make sense of the so-called high strangeness phenomena, some
psychological phenomena that are weirder than dreams. And yet people report it. So it's a,
it's a phenomenal reality and stuff that people experience. So how is their mind operating to
produce high strangeness phenomena? Or how is the mind of nature operating to produce high
strangeness phenomena? And the hypothesis I raised was it is not using the law of excluded middle.
That's, that's monkey logic. It's not nature's logic. Anyway, just wanted to put it out there.
Loudson Brower is the name of the guy that should be as well known as Spinoza, but unfortunately
he isn't. He had some other weird thinking about social issues that maybe is the reason
that he would never be popular in the world today, but he had some very interesting ideas.
Yeah, super cool. Thanks. That's, that's, that's great. I was aware of intuitionism,
but I didn't connect it to this, to this grim stuff. So that's, that's very good.
I just wrote his name on the chat. So people, because people will not know how to write down
Loudson Brower. So I just, I just put it there. That's very good. That's very good. Well, you know,
one is, I'll definitely think about that. That's excellent. And you know, another thing we started
to think about is, is enabling, I mean, this is some steps down, but enabling some of the, again,
I'm really, I'm really interested in this, this notion of, as William James once said that
thoughts are the thinker, you know, and this idea of active data and, and, and sort of erasing
the distinction between passive data that, and, and in the context of this thing we were just
talking about, you could imagine that some of the sentences contain elements that actually modify
the sentences. So you could imagine, right, a self-referential kind of thing where there are
certain atoms that actually go and cut out pieces from another sentence or alter edit,
you know, some sort of spring rewriting rules or something like that, right? So you can imagine,
but, but, but the other thing about that is to go back to, because I think I forgot to mention
this in the business about memories. If, if the job, if, if, if what the, the system wants to do
is remap ngrams and other pieces of information that it got from its past self or from whoever,
into the new context, you could imagine that the, the ngrams themselves might be active. In
other words, they don't have to be completely passive. They could also, there might be some
advantages to them to be picked up and nourished, you know, maybe they're just passive molecules,
but maybe they're, maybe they're not molecules, maybe they're vibration cycles, or maybe they
write some kind of, some kind of oscillation patterns that actually can be fed by appropriate
resonance with, with the cognitive system that they're going into. And so maybe they can actually
increase the likelihood that they get picked up and reproduced or, or something by, by
dynamics that they do, right? So, so they don't have to be passive entirely. So
as I'm also, also kind of fooling around with some, with some models like that of, of, of
memories as self reproducing patterns that have their own little tiny agendas. And maybe it's
as persist, you know, that may be the simplest thing, but maybe it's something else, maybe it's
more than persist, maybe it's, you know, kind of like individual neurons like to have a job,
you know, they like to connect to circuits where they're actually going to, going to do something.
And so maybe these things too, maybe, you know, maybe their primary
driver is to be, to be remapped and in the new, in their new context and not be wiped out,
which kind of gets to this kind of basic philosophical thing, which is, you know,
there's some things called Bateson's paradox, this idea that if you're a species, right,
you have a choice. If you don't change with the environment, you're going to die out, right?
You're going to, you're going to be go extinct. But if you do change, well, you're also kind of
gone because you're not the same anymore, right? So, so what do you do? And I think that, yes,
that's the case for that. That's a dilemma that, that is, is a problem for evolutionary lineages.
Either way, you're not going to persist as that same thing. But it's also, I think, a problem for
any kind of cognitive agent, because if you really are intent on not changing and persisting as you
are, then you can't learn, you can't modify yourself, you can't improve, you can't, you know,
you can't make any changes in light of further experience. You know that the most profound
experiences are going to change you in some way, you're just not, whether it's, you know, the
mechanics of metamorphosis or puberty or whether it's learning, and you're just not going to be
the same. And so committing to this idea that whatever persists, it's not going to be a thing,
it's going to be a pattern. And then, then, then, then, then it makes sense, then you can be an
evolutionary lineage that changes over time. And, and then you can be a human way or any other kind
of creature where your cells and the molecules in your brain go in and out and changes come,
but you're still the same, not because you're the same thing, but because you have an extended
cognitive history that, that ties it all together. So, yeah.
Amir, just a quick point. I wanted to ask Mike was simple. He has no question about an earlier
topic before he leaves. So if I have 30 seconds in mind to the end, it's a quick question just for
me to understand that. Do you want to do it now? It's a different, it's the earlier topic about
things. We can do it quickly, Mike. It's just from my understanding and maybe the understanding of
the people here. When you said we have to be open from multiple points of views, I'll talk about
point of, point of view as things. If there are things, then, then a thing has its point of view.
If I, if we don't have any criteria for telling what is a valid thing and what is not, then we
have an exponential explosion of the combinations of permutations of the states of nature. All of
these combinations and permutations can be things and they partly overlap. So it would have an
exponential explosion, explosion of things and points of view. Is that what you are open to
or do you think there actually is a criterion for telling what is a thing and what is not? It's
just that we don't know what it is and it may not be the same thing as life. I think there is a
criterion, but I think that criterion is different from forever. So I apologize in advance. This is
not going to be satisfying, but this is what I think. I think that the criterion is from the
perspective of each, each, each, each agent. In other words, I think that the universe is
probably infinite, but, but, but certainly and, you know, a hyper astronomical number of
perspectives and of, of beings. And from the perspective of each one of those beings,
a different set of things are things and a different set are not things. And so, so yes,
that they're absolutely and the criterion is again, from the perspective of each observer,
the criterion from the perspective of that observer is does it help sense making? Does it,
does it, it, does it give me a greater purchase on the world, both in practical terms, but also
internally, right, in my own sense making, however humble that or primitive that might be for simple
agents. But, but that's right. So you can ask any, if provided you know how to communicate with it.
So we do okay, left hemisphere to left hemisphere, we're working on ways to ask your liver questions
like quite literally we're asking for, we're now trying to develop some technology to communicate
with various other very unconventional agents. And from those kind of agents,
you will get a different set of what do I consider to be things, right. So, so, so your liver will
have all kinds of comments about persistent physiological states as things. And we will
look at those and say, no, that's that that's, I don't care about that. That's not a thing.
IIT also takes this perspective that the criteria is based on the perspective of the thing. It's,
it's the first person perspective of the thing. But IIT would say the criteria is to maximize
integrated information. Whatever partitioning maximizes information integration, that determines
what are the things. And but what you're saying is, is to maximize sense making. That's where you
depart from IIT. Instead of maximize integrated information, you maximize sense making. There
should be a way to formalize this. I really think you and Julia would make an exquisite pair.
Yeah, yeah, it's, yeah, it's been a while, actually. We used to, we used to meet up at the,
at some Templeton meetings that they used to have at the Arizona, at the ASU. So it's been
a while since I've seen them. So I will, I will talk to them again, I think. But no, you're right.
And I think that I, you know, the PHY and things like that are pretty good. I mean,
I call it sense making. But of course, I don't have a formula that you can, that you can
calculate. IIT is almost a formula you can calculate. And certainly there are surrogate
metrics that you actually can calculate. So that, so it has that benefit of it. But I am really
interested in, and this is where some of the experimental stuff kind of leads into, you know,
like bigger, bigger issues. I'm really interested in what an explanation is. And the idea that what
we are looking for as beings, not just as scientists, but as beings, we are looking for
a better understanding of the world, not just looking backwards as far as explaining what
just happened, not looking downwards as far as figuring out the particles or the components of
whatever just happened, but actually looking forwards. In other words, I think a good explanation
is a story about the world that helps you do the next good thing. In other words, it's something
that it's looking forward. It's increasing insight, not a dissection of what the hell just happened.
But as living agents, we have to live forward. We don't live backward the way that
third-person descriptions of science can do. We have to decide what do we do next. And these
things are very complex. And as beings, what I like from explanations are something that
raises my sense-making of the world, such that I see, ah, well, given that, now I can do this or
now I should do this. And I think that is, when I talk about sense-making, that's what I mean. I mean
that agents that have to actively engage with the world, and I don't mean the three-dimensional world.
I mean, whatever world they live in, it might be a physiological state space, it might be anatomical,
whatever world they actually live in. The fact that they have to engage with it is what makes
them an observer. And this is, like you mentioned, like, well, maybe photographic film is an observer.
Well, kind of, but a really tiny one, because the photographic film is not going to do anything
different based on what it sees on the film. At least the standard film doesn't do that. Whereas
things that I would call a significant agent is something that takes observations. And then the
observations matter because it tries to fit them together into a compressed representation of,
that helps it to know, well, what the hell do I do now after that? And so that's why
I think that agents see things and they see other agents. Because if you don't do that,
it does not help you understand the world you're living in. And as a practical matter,
you'll be dead in no time as a biological agent if you don't understand what you're dealing with.
There is work in physics, in foundations of physics, that dovetails very well with your
thoughts here. Marcus Miller from the Austrian Academy of Sciences, the way he frames physics
is to ask the question, what will I see next? In other words, can I predict the states of the
world? And all of physics can be rewritten in terms of this question, what will I see next,
as opposed to under the assumption that there is a fixed world out there which experiments telling
us, well, if there is such a world, it's not physical. Unless you entertain all kinds of
fantasies about multiverses and super determinism, hidden variables. But if you could relate what
will I see next to what should I do next, because what you would do next must be informed by your
ability to predict the world, what the world would do next. There is a way to mathematically
formalize this. Marcus has done it. Actually, Essential Foundation, we just got a researcher,
we are funding a researcher at the University of Tudor in Switzerland to do research on this
so-called physics of first-person perspective. Yeah, yeah. Let me just start from scratch here.
Yep, yep. No, that's really great. And the other, and I wonder if they talk to each other,
I don't know, but Carl Friston and Chris Fields and Mark Solms and these guys that I work with,
they also work on exactly this, so active inference and basically predicting your own
next sensory states and how that, you know, they call it, I think it's Carl's term,
the physics of sentience and the sentience of physics, right? So like, this is, you know,
you guys, so I don't know, I'm here, you guys might want to see if they can show up at some
point, there's some really interesting stuff. So hopefully they're talking to Miller and it's all
kind of one thing, but yes, I completely agree with you, predicting what you are going to experience
next is a really fruitful kind of frame for this. I sent Marcus Carl's paper published on
the IEEE, one of the IEEE journals in 2013 or 14 about active inference,
but I didn't hear from Marcus back. The thing, I mean, I love the work of Carl Friston, by the way,
but it's amazing how much resistance there is to it because people say, well, I can't understand
it anyway, so why will I even try? Why will I even bother? Carl is not doing himself a favor
by his writing style. Yeah, I mean, he's an amazing genius and, you know, I sure as heck don't
understand all the math behind it, but I think the very simple, so there's one kind of slice of
this, which is just surprise minimization, just alone this idea of surprise minimization is
is really powerful and you can apply it to all kinds of scenarios as Carl has done from ecosystems
to psychiatry to whatever. We had a project recently that it isn't published yet, but
another grad student in my lab, Frans Quichling, he's looking at surprise and yeast in, sorry,
not yeast, algae, algae. So, believe it or not, algae can be surprised and the reason that algae
can be surprised is because they form expectations of what's going to happen next and you can
subvert those expectations and then they get stressed out and they're surprised. So, this kind
of thing and then, you know, Chris and Chris Fields and then Carl can take it, you know, sort of
much further down and look at symmetrical interactions between the system and its environment
and who's learning about whom and, you know, turns out like both are learning about both.
Michael, if you're, I mean, sorry, I'm taking too much of your time, but here we may converge
because if you go for this, if you go for active inference, surprise, minimization,
which goes back to information theory, you will get Markov blankets, which means that you will
get life. So, it may, your criterion for determining what things are may actually be life if you pursue
that consistently because, you know, Markov blankets, you get cell membranes, active inference,
you have inner models, you know, inner states can only communicate with external states or the
other way around by proxy through the states of the Markov blanket. This is life. Actually,
Carl wrote the paper saying that this is life. Yeah, which I'm 100% on board with. That part is
completely fine. I just think that if we take it seriously, I think we're going to be able to include
in that umbrella with that exact same framework, a bunch of stuff that any reasonable biologist
is going to say, well, I don't know what this is, but it isn't life. And I'm okay. I mean, I think
what the move that you're making, and I would be perfectly comfortable with it, is to say,
guys, you got the wrong definition of life. This is what should be life, right? So, I'm okay with
that. But at that point, you know, it's, I don't know, the vocabulary, I'm kind of, yeah, less
tight to it. Fantastic. Beautiful. Thank you. So, yeah, felt like a
super amazing dialogue, which points seem to be in opposite direction and then end up converging
very naturally, which is very beautiful to see. I just want to say very quickly before you go,
Michael, because I mentioned it last time, Douglas Harding. But again, just another weird
coincidence, because he'd written this book on having no head, which you, which was the same
title, he wrote that in 1961. And it has the same title as a paper, I think you co-authored.
He also wrote a book called The Science of the First Person in 1974. So it felt like there's
someone back there writing the titles of all these kind of new ideas from a very different
perspective. He was kind of an architect and a mystic and a philosopher. Anyway, maybe we'll
bring someone along that, that kind of followed that work. Just, I know we're over time for you,
Michael. So just huge gratitude one more time. It's always fascinating. Thank you so much.
Yeah, it's just brilliant. And I hope you come back one day and then you mentioned several other
people that would be worth speaking to as well. So thank you, Michael.
Sure. You know, I absolutely will. Thank you. Thank you so much. Yeah. And thank you,
Bernardo. It was awesome to discuss all this with you, of course.
Yeah. Oh, just to say quickly, everyone, we're staying on the call for a little while, Bernardo,
because sometimes what happened last time when you left, a lot of people left not realize it.
And then we're like, oh, we didn't realize it. So yeah, carry on, Michael. We'll be here
continuing for a little bit, but Michael, carry on with what you're saying.
Cool. Yeah. No, sorry. I just, yeah, I was just thanking you and thanking Bernardo because it's,
you know, a fascinating conversation, as always. I've taken a bunch of notes on some of the stuff
you said. So very interesting. So yes, I look forward to more at any point.
Great. Exciting. Thank you so much. Take care, Michael. Thanks, everybody. Appreciate it.
