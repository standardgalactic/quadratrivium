start	end	text
0	19240	Welcome, everybody, to the Entrepreneurial Thought Leaders seminar, a Stanford seminar
19240	20880	for aspiring entrepreneurs.
20880	27400	ETL is presented by STVP, the Engineering Entrepreneurship Center here at Stanford,
28000	31240	the Business Association of Stanford Entrepreneurial Students.
31240	35080	I'm Ravi Balani, a lecturer in the Management Science and Engineering Department at Stanford
35080	38440	and the Director of Alchemist and Accelerator for Enterprise Startups.
38440	42520	Today, we are thrilled to welcome Andrew Ng to ETL.
42520	44560	How many people know Andrew?
44560	47960	Okay, so Andrew really doesn't need an introduction,
47960	50200	but we will give one anyways for those who don't.
50200	53200	Andrew is truly a child of the world.
53200	57280	He was born in the UK to parents who emigrated to the UK from Hong Kong,
57280	61320	but was raised in Hong Kong and Singapore, went to Carnegie Mellon
61320	64280	and very early on signaled that he was no ordinary student.
64280	68080	He got three bachelor's degrees at Carnegie Mellon in computer science,
68080	71480	statistics, and economics, and graduated at the top of his class,
71480	75240	then went on to MIT where he got a master's in electrical engineering and computer science,
75240	80440	then came over to the left coast and got a PhD in Berkeley in computer science
80480	83800	with a focus on artificial intelligence and reinforcement learning.
83800	89800	Andrew is generally viewed as one of the preeminent thought leaders on AI today.
89800	94400	He's the co-founder and head of Google Brain
94400	96640	and the former chief scientist at Baidu,
96640	102880	where he built the company's AI group into thousands of people, several thousand people.
102880	107560	But he's as passionate about AI as he is also about the development of you,
107560	109480	of students around the world.
109480	113040	And I know there's a lot of love for Andrew.
113040	117760	He's a former associates professor and director of the Stanford AI Lab
117760	120120	and currently an adjunct professor in computer science at Stanford.
120120	124520	How many people have taken one of Andrew's classes or want to take one of Andrew's classes?
124520	128760	And he's a beloved professor here at Stanford,
128760	132720	but he's also viewed as a beloved teacher to millions outside of Stanford.
132720	137240	He's the co-founder and chairman of Coursera, the world's largest MOOC platform,
137280	141560	and through his online education work and his online AI education work,
141560	144040	he's reached over 7 million people.
144040	150240	He was listed as one of the world's 100 most influential people by Time Magazine in 2013.
150240	154360	And today, Andrew's the managing director and partner at the AI Fund,
154360	157760	which is a startup studio building new AI companies from the ground up
157760	161040	and is also the founder of deeplearning.ai.
161040	163800	He focuses his time primarily on his entrepreneurial adventures,
163840	169400	looking for the best ways to accelerate responsible AI practices in the larger global economy.
169400	172600	There's fantastic content already online that Andrew has given,
172600	176080	including a longer version of today's talk that you can find on YouTube.
176080	179480	And so instead of reduplicating that, Andrew's going to give a teaser talk,
179480	183760	a 10-minute discussion, followed by we'll do a quick fireside chat,
183760	187560	and then we're going to open it up for really interactive Q&A with you.
187560	191200	So start thinking about your questions now because the time is going to fly by,
191200	193440	but without further ado, please welcome Andrew.
193800	194960	Woo!
199960	202720	Thanks a lot, Ravi. Thanks. Good to see everyone here.
202720	205160	Can everyone in the back hear me okay?
205160	206120	Cool, awesome.
206120	211120	You know, I've taught CS229, my machine learning class, in this room many years,
211120	216160	but all these years I've taught in this room, I've never seen my face that big before.
218880	223400	What I'd like to do today is chat to you about opportunities in AI.
223400	227720	So one of the difficult things to understand about AI
227720	231680	is a general-purpose technology, similar to electricity,
231680	233520	meaning it's not useful just for one thing,
233520	236000	it's useful for a lot of different applications.
236000	238880	If I were to ask you what is electricity good for,
238880	242480	it's almost hard to answer that because it's useful for so many different things,
242480	245800	and AI is like that too.
245800	251240	So one of the major trends that we've seen in the last few years
251280	255840	is that prompting is revolutionizing AI application development.
255840	257840	And I want to just dive a little bit deeper into this
257840	259760	because I know this is an engineering class,
259760	262080	I know many of you may be from an engineering background,
262080	266560	and I'm going to just go a little bit deeper into this than I might otherwise.
266560	271240	But if you were to, say, want to build an AI system for many years,
271240	273320	the typical approach is use supervised earnings.
273320	278120	So let's say I want to build a system to rate restaurant reviews as positive or negative sentiment,
278400	282160	then you would collect data, maybe that takes me a month,
282160	285440	I would train an AI model, maybe that takes me a few months,
285440	290720	find a cloud service to deploy my AI model, maybe that takes a few months.
290720	293680	And so for the past, most of the past decade,
293680	299080	a realistic timeline to build and deploy a valuable AI system was maybe six or 12 months.
299080	304280	But with prompting, the timeline is now very different.
304280	307120	You can specify a prompt in minutes or hours,
307120	311480	and then deploy a system to production in just hours or days.
311480	314640	And I know that probably many or maybe most,
314640	319920	maybe all of you will have played with large language models as a consumer too,
319920	323120	like chat GPD and bot and bing chat.
323120	325760	I think that in terms of start-up opportunities,
325760	328360	I'm excited about the use of large language models,
328360	330840	not as a consumer too, which is fantastic and exciting.
330840	333360	I think use chat GPD and bot regularly,
333360	337440	but instead the application of large language models as a developer too,
337440	341240	because this is allowing a lot more applications to be built
341240	345280	and dramatically lowering the barrier to building many applications.
345280	348400	So I know that in this talk, you don't normally have speakers write code,
348400	351280	but this is an engineering class.
351280	355840	So let me actually show you exactly what I mean by that.
355840	359960	It turns out that if I want to build an AI system today,
360000	362200	this is all the code I need.
362200	365840	And this means that if you take CS 106 or something,
365840	368600	learn to code in a CS class,
368600	373160	with just a little bit of code, import AI, open i2s, load my key,
373160	378520	I don't know, D, what, ST, P lectures,
378520	383160	I break it, so many friends.
385240	387120	I've never written that before.
387120	391800	And so hopefully this, okay, thank goodness, got that right.
391800	393400	And so this is positive sentiment.
393400	398200	And just in seconds, that's all the code it takes now to build an AI system
398200	401200	in code to look at a piece of text and process it,
401200	406680	to look at a piece of email and route it or to start to build the beginnings of a chat bot.
406680	411160	So over the last, I don't know, half year, one of my teams,
412080	417320	has been working with many of the AI tool builders to create short courses
417320	420160	on how to use tools like I just showed you.
420160	424480	Because there are many AI applications that used to take me six months to build
424480	428240	that I think any of you will now be able to build in one or two days.
428240	432280	And this opens up the set of things that you could do
432280	434680	and the set of prototypes you can build.
434680	436440	And in fact, from a startup perspective,
436440	438520	when it took us six months to build something,
438520	443120	what we do is have a product manager study it, do the user studies,
443120	445400	make sure it's the right thing to build, then go build it.
445400	448800	And after all that investment is like, boy, let's hope it works.
448800	452440	But what I'm seeing with these very fast development times is
452440	455160	if it takes you a couple of days to build something,
455160	458320	I'm seeing a lot more startups as well as big companies say,
458320	460960	you know what, I have 10 ideas for features.
460960	463680	I'm going to build all 10 things and then just ship them all.
463680	468480	And then we'll see how users use them or don't use them and just keep what sticks.
468520	471840	And this is a very different prototyping, much lean in methodology
471840	474440	than I've seen startups use before prompting.
474440	477960	One important caveat, which is that responsible AI is important.
477960	481080	So don't do this, don't ship things that could cause harm.
481080	486200	But we have a lot of applications like inspecting bits of metal and factories
486200	488480	where there is really no harm, no risk of bias,
488480	490880	where I think there's very fast shipping methodology
490880	494240	that's just innovate very quickly in AI.
494240	495880	So where are the opportunities?
495880	500280	So the size of these circles shows what I think is the value
500280	503240	of different AI technologies today.
503240	506640	Supervised learning started to work really well about a decade ago
506640	509440	and labeling things, such as label does that as,
509440	511360	is it something you're likely to click on or not?
511360	515120	Or label this X-ray with, you know, what's the medical diagnosis?
515120	517880	And supervised learning for a single company like Google
517880	520760	is worth more than $100 billion a year,
520760	523120	and there are millions of developers working on it.
523160	527040	And it might even grow in the next three years to double, say.
527040	530480	So massive momentum, lots of applications to be figured out.
530480	532880	And then Genes of AI is a new entrance where,
532880	536440	frankly, the revenue, the value of the revenue from Genes of AI today
536440	539280	is much smaller, but given the amounts of interest,
539280	540800	excitement, and commercial interest,
540800	543840	I think it will much more than double in the next three years.
543840	547040	And three years is an artificially short time horizon.
547040	548640	I think it were to look out six years
548640	550720	if it continues to compound at this rate.
550720	554560	Maybe the value from Genes of AI will even start to approach
554560	556120	that of supervised learning.
556120	559520	But all that room for growth, the light-shaded region
559520	561440	for supervised learning or Genes of AI,
561440	563920	which are probably the two most important tools today,
563920	567600	are where there are a lot of opportunities for any of us
567600	571040	to identify and build to concrete use cases.
571040	573280	And what I hope to take away from this talk
573280	576960	is AI technologies are general-purpose technologies,
576960	579880	meaning that they're useful for many different tasks.
579880	582160	When supervised learning started to work,
582160	585960	well, about a decade ago, it actually took us a long time.
585960	588280	It took us annoyingly long over the last decade,
588280	591400	and it will take us annoyingly long over the next decade
591400	593840	to figure out use cases for Genes of AI.
593840	596880	But do you want to use this to make ships more fusion
596880	598440	or for medical diagnosis
598440	601480	or for education product recommendations or something else?
601480	604680	It was still figuring out concrete use cases
604680	606160	for supervised learning.
606160	608080	And even though we're not yet done doing that,
608080	610440	we have another fantastic new tool, Genes of AI,
610440	611720	that even further expands
611720	613560	the set of things we now do of AI.
614440	616960	And one important caveat,
616960	619760	which is there will be fans along the way.
619760	621920	How many of you remember Lenzer?
621920	623120	Raise your hand if you do.
623120	624320	Wow, almost no one.
624320	626080	That's fascinating.
626080	630880	So Lenzer's revenues took off like that through last December.
632040	634840	It was this app that could let you
634840	636400	upload a few pictures of yourself
636400	638360	and draw a cool picture of you as an astronaut
638360	640080	or a scientist or something.
640080	643720	And it was a really good, really hot product
643720	647640	until last December, after which his revenues did that.
647640	650040	And I think that's because Lenzer was one
650040	652520	of what will probably turn out to be multiple,
652520	655480	thin software layers built on top of someone else's
655480	656680	very powerful API.
656680	658400	That was a good idea, people liked it,
658400	661640	but it wasn't a long-term, defensible business.
661640	665400	And when I think about Genes of AI as a developer platform,
665400	669480	I'm reminded of when Steve Jobs gave us this phone, right?
669480	672720	And shortly after, someone wrote an app
672720	676200	that I paid $199 for to do this,
676200	678200	to turn the phone into a flashlight.
678200	680440	And this was also a good idea, it was a great product,
680440	683440	but it just was not a defensible business either
683440	685440	because it was a very thin software layer built on top
685440	688640	of someone else's very powerful development platform.
688640	691200	But in the same way, after we got the iPhone,
691200	692360	after we got the smartphone,
692360	695840	someone else figured out how to build Uber, Airbnb, and Tinder,
695840	698600	much longer-term, defensible, very valuable businesses
698600	700960	that are still standing the test of time.
700960	703080	And I think we have those opportunities as well
703080	705840	to build long-term, valuable franchises,
705840	708360	businesses on top of Genes of AI.
708360	710920	So where are the opportunities?
710920	715920	So I felt years ago, but even more strongly now,
716400	718680	that because of emerging AI technology,
718680	720440	there are a lot of projects that are now possible,
720440	724680	that were not possible one or a handful of years ago.
724680	728400	And I wound up starting AI Fund, which is a venture studio,
728400	731640	that sequentially works as entrepreneurs to start companies.
731640	734920	We actually average about one startup a month now,
734920	738000	because I felt, I previously, as Ravi mentioned,
738000	741320	previously I had led AI teams in Google and Baidu,
741320	745120	and even having led AI teams in Big Tech,
745120	748040	I couldn't see how we could possibly operate a team
748040	751080	in a Big Tech company to pursue the very diverse,
751080	754520	very different sets of opportunities that I saw
754520	757280	and wanted to pursue, and starting different startups
757280	760400	to pursue those valuable projects seem more efficient
760400	763520	than having one company, even the Big Tech company,
763520	766280	go after such a large set of resources.
766280	769640	But having said that, I think AI and Genes of AI
769640	772920	also offers a lot of opportunities for incumbent companies,
772920	775080	which often have a distribution advantage.
776160	777640	Where exactly are the opportunities?
777640	779880	So this is what I think of as the AI stack.
779880	783840	At the lowest level is the hardware layer, very valuable,
783840	787080	but also very capital-intensive, needs a lot of resources to build
787080	788320	and very concentrated.
788320	791400	So I'm sure there'll be valuable startups built there,
791400	792680	but I personally don't play there,
792680	796320	because of how capital-intensive and how concentrated it is.
796320	797840	There's a cloud infrastructure layer,
797840	800920	also very capital-intensive, very concentrated, very valuable,
800920	804920	but at least when I build startups, I tend not to play there.
804920	807640	The other layer that's interesting is the developer tooling layer.
807640	812640	So what you just saw me do was use OpenAI as a developer tool.
812640	815560	And I see this space as hyper-competitive,
815560	818280	look at all the startups chasing OpenAI,
818280	820320	but there will be some mega winners.
820320	825040	So whereas incumbents have a startup distribution advantage,
825040	827640	I think for many startups, having a technology advantage
827640	830360	may give you a best shot at doing something meaningful there.
830360	832160	So I personally tend to play here
832160	834680	only when we think we have a technology advantage,
834680	839280	because that buys us a better chance to become one of the huge winners.
839280	841840	And then with most ways of technology innovation,
841840	843640	a lot of the media attention, social media,
843640	846360	what people tend to talk about is the tooling of the technology layer.
846360	850560	There's one other layer that I think has got to be even more valuable,
850560	852280	and that's the application layer.
852280	855120	Because in many ways of technology,
855120	858680	for the in-front and tooling layer to be successful,
858680	860960	applications need to be built on top of them.
860960	862600	They generate even more revenue
862600	866440	so that they can afford to play the infrastructure layer.
866440	868960	And what I'm seeing is that there are a lot of opportunities
868960	872520	at the application layer where the intensity of competition
872520	875440	is not, frankly, not nearly as high.
875440	877640	Maybe just one example.
877640	881080	I've been chatting a lot with the CEO of Meno,
881080	888360	which is a startup that applies AI to romantic relationship coaching.
888360	890040	And I'm an AI guy.
890040	893240	I feel like I don't know anything about romance.
893240	895920	And if you don't believe me, you can ask my wife.
895920	899200	She would confirm that I don't know anything about romance.
899200	903560	But when we decided, when we had conviction that AI could be applied to relationships,
903560	908240	we wound up partnering with Renata Nyborg, who's the former CEO of Tinder.
908240	910720	And because she ran Tinder, she understands relationships
910720	914320	in a very systematic way, more so than anyone else I know.
914320	916400	And so with my team providing AI expertise
916400	918280	and her providing relationship expertise,
918280	923280	we're able to build a pretty unique relationship mentoring application
923280	925880	that we just announced a few weeks ago.
925880	928720	And this is not part of, you know, Renata actually occasionally
928720	931720	stops by Stanford campus and talks to Stanford students
931720	933840	as part of her user product research.
933840	936440	So it's possible that we've seen her around.
936440	939040	Just one last thing, I'd love to go to GNA.
939040	942440	Over the last few years, AI fund we've been tuning our process
942440	945280	for building startups and we just share that with you.
945280	948000	So we often start off with a lot of ideas, right?
948000	951800	And one example of another startup we built was Bering AI,
951800	955080	which uses AI for smart routing of very large ocean growing vessels.
955080	958520	So if you're a ship captain, should you sail at 20 knots or 22 knots?
958520	959280	Who knows?
959280	961840	Most ship captains just make some decision.
961840	967200	But because we're able to get global weather and ocean current data,
967200	970560	we can make recommendations to ship captains for how to get there on time
970560	972840	and use about 10% less fuel.
972840	975440	But this idea was suggested to me by Mitsui,
975440	978440	which is a major shareholder in a major shipping line
978440	980920	that operates very large ocean growing vessels.
980920	983560	And just one of those things, I would never have thought of this idea myself
983560	987920	because I've been on a boat, but what do I know about global maritime shipping?
987920	990960	But Mitsui suggested this idea to me.
990960	995400	And we then validate the idea, make sure there's technical feasibility
995400	997720	and market need, recruit a CEO.
997720	1000480	We were fortunate to find Dylan Kyle, who's a fantastic CEO
1000480	1002480	with one successful exit before.
1002480	1005080	And then we spent three months in our current process
1005080	1009280	building a technical prototype with the CEO and doing deep customer validation.
1009280	1013520	If it survives, two-thirds chance of surviving, one-third chance of not surviving.
1013520	1017120	We then write a check-in that allows the company to build higher executives,
1017120	1022040	build an MVP, and off it goes to raise additional rounds of capital.
1022040	1023880	And I think this is what we...
1023880	1026080	And so bearing AI, well, now it's actually...
1026080	1030320	There are now hundreds of ships on the high seas guided by bearing AI.
1030320	1033200	Ships guided by bearing AI have 75 million miles,
1033200	1036000	which is the equivalent of going 3,000 times around the planet
1036000	1040200	and save about half a million dollars in fuel costs per ship per year
1040200	1042080	in addition to significant carbon emissions.
1042080	1043320	I think we'll save about...
1043320	1047240	I want to save about a million tons of CO2 emissions so far.
1047240	1048960	But this kind of idea that...
1048960	1051040	I would never have come up with this idea myself,
1051040	1053720	but I've learned that my swim lane is AI,
1053720	1055760	but when I work with experts in other sectors,
1055760	1059240	there are often these exciting opportunities that are very valuable.
1059240	1062880	But frankly, how many groups in the world are experts in AI and shipping
1062880	1064360	or expert in AI and relationships?
1064360	1069720	I find that the competition intensity at the application layer is often much lower.
1069720	1072720	And then just one last thing, kind of just full disclosure
1072720	1075320	and something that I hope all of you will do too.
1075320	1078960	My team's only work on projects that we think move humanity forward.
1078960	1080560	Response for AI is important.
1080560	1082320	And on multiple occasions, we've killed
1082320	1087080	and I will continue to kill projects that we may assess to be financially sound
1087080	1089120	but based on ethical grounds.
1089120	1091560	So lots of exciting opportunities.
1091560	1094320	I think at Stanford, the loss of great costs is going to take
1094320	1098280	in engineering and elsewhere to learn about that AI tech.
1098280	1103640	And then when you find applications or go play at the infrar and tooling layer too,
1103640	1105120	I think there are lots of opportunities.
1105120	1106400	But I think there are...
1106400	1109400	What I'm seeing is, frankly, my team at AI Fund,
1109400	1111040	we have so many startup ideas.
1111040	1112920	We use a task management software.
1112920	1116120	We use Asana to track this huge list of ideas.
1116120	1117720	And it's actually quite clear to me.
1117720	1120440	There are a lot more good ideas for AI businesses
1120440	1124640	than people with the skill to work on them at this moment in time.
1124640	1128160	So hopefully, there'll be more than enough projects for everyone.
1128160	1130960	There are all of you, all of us, to work on.
1130960	1131920	All right, thank you.
1135920	1138920	I wanted to just start off with that closing statement that you made
1138920	1142120	about how there's more opportunity than there are students with skills
1142120	1144080	or people with skills to pursue them.
1144080	1146480	And given that we have an audience full of students,
1146480	1149480	I wanted to start off by mapping out advice for students
1149480	1151880	that are entering into the university regarding AI.
1151880	1155320	So if you want to pursue a career in AI right now,
1155320	1158360	and let's say your child was entering Stanford,
1158360	1162600	what advice would you give them in terms of how to spend their time?
1162600	1166520	Yeah, so, you know, there's one thing that's actually really worth doing
1166520	1170200	when you're sent to students, which is take classes.
1170200	1173880	Because it turns out that I feel like there's actually one pattern I see
1173960	1178240	for both undergraduates and graduate students, including PhD students,
1178240	1180680	which is there's so much exciting stuff to do,
1180680	1182480	you just want to jump in and do it, right?
1182480	1186080	In fact, I've seen them undergrads in their freshman year,
1186080	1189040	you know, try to join a research lab and start doing work in AI.
1189040	1191040	That's okay, nothing wrong with that.
1191040	1194960	But it turns out that while project work is one way to learn,
1194960	1198800	coursework is, I think, an even more efficient way to learn,
1198800	1201600	especially when it comes to mastering the fundamentals,
1201600	1204920	because professors have put a lot of work to organize the material
1204920	1208160	in a way that's efficient to learn and digest.
1208160	1212800	So I would say, you know, take classes in AI technology
1212800	1215840	or in entrepreneurship and gain those skills.
1215840	1219800	I've seen students jump in and then if you are trying to work in a research lab
1219800	1221800	without strong skills, you end up, you know, like,
1221800	1224680	labeling data or something, which is fine, you learn some things,
1224680	1227680	but you actually learn a lot from taking courses.
1227680	1229240	And then in addition to that,
1229280	1231960	after you start to master the foundational skills,
1231960	1235160	after you know how to use AI technology or, you know, then,
1235160	1238600	as you start to practice, find exciting use cases across campus.
1238600	1242280	I do a lot of work, you know, over with people over in climate science
1242280	1245800	or in healthcare to take my AI expertise
1245800	1247840	and then navigate with a different discipline
1247840	1250520	that I'm not expert in to find exciting applications.
1250520	1254760	And hopefully that type of practice will help many of you find exciting
1254760	1256240	projects to work on as well.
1256240	1258560	Do you need to take technical classes?
1258560	1261240	Do you think you need to take computer science classes
1261240	1264160	if you want to pursue a career in AI?
1264160	1268600	Need is too strong, but I definitely encourage you to take technical classes.
1268600	1273640	I think we're moving toward a world where, frankly, I, you know,
1273640	1276560	at some future point, I think everyone should learn to code.
1276560	1279920	Or rather, I think it'll be useful for everyone to learn how to code
1279920	1281480	for a couple of reasons.
1281480	1283240	Everyone has access to data, right?
1283240	1286120	This is different than the world used to be even a few years ago.
1286120	1290080	And especially with genus of AI, your ability to get something to work
1290080	1292800	is much higher than ever before.
1292800	1295960	The barrier to entry is much lower than ever before.
1295960	1299000	And so if you learn just a little bit of coding,
1299000	1302080	the amount that you really accomplish is significantly greater
1302080	1305040	than if you don't know how to code at all.
1305040	1308920	And are there any skills that separate out the great AI founders?
1308920	1313480	I know AI right now is like, it's a sea that's rising all boats.
1313480	1315960	But if you separate out the great ones from the good ones,
1315960	1320240	are there any salient skills that you notice that the great AI CEOs
1320240	1322680	or founders have that the good ones don't?
1322680	1327200	Maybe since you said AI, I would say is often technical death.
1327200	1328440	It costs a lot.
1328440	1330360	But I want to give a different answer if you say great founders
1330360	1331360	or not great AI founders.
1331360	1333720	But I feel like AI is evolving rapidly.
1333720	1337040	And we definitely have lost a bunch of new roles that, you know,
1337040	1339600	pitch the VCs without really knowing what they're doing.
1339600	1342240	And the smart VCs can sniff it out quite quickly.
1342240	1343440	And it makes a huge difference.
1343440	1346080	I think the technology, unfortunately, you know,
1346080	1349400	is like somewhat complicated for a lot of applications.
1349400	1351600	So a team that actually knows what they're doing
1351600	1354720	will execute an AI project 10 times faster, you know,
1354720	1355760	than a team that doesn't.
1355760	1357400	And 10 times is not a made-up number.
1357400	1361760	I literally see people take a year to do something like, oh, boy,
1361760	1364640	I know that other team would have done perform this level
1364640	1367320	in two weeks or maybe a month.
1367320	1369840	So for many AI startups, application startups,
1369840	1372320	in-front startups, you kind of have to know what you're doing.
1372320	1374120	So it doesn't have to be you.
1374120	1377400	If you're a technical co-founder, maybe that's OK.
1377400	1382560	And then second thing I see among many of the great founders
1382560	1383400	is speed.
1383400	1386120	I find that as a startup, you'd be surprised
1386120	1388680	when you handle the great founders the sheer speed
1388680	1391760	of decision-making.
1391760	1394760	And, you know, I sometimes talk to people from big companies
1394760	1396760	and they'll say, oh, we move so fast.
1396760	1399080	But when I kind of sit them side by side,
1399080	1400640	how long does it take you to make this decision?
1400640	1401720	Do I talk to a great founder?
1401760	1403480	How long does it take me to make this decision?
1403480	1404520	Maybe here's one story.
1404520	1407480	I was chatting with the Meno CEO of Renato and iBook,
1407480	1408760	former CEO Tinder.
1408760	1410000	I was on the phone with her one day
1410000	1412120	and she was making a major architecture decision.
1412120	1413720	So it's architecting this thing.
1413720	1416480	There were basically two major software architectures
1416480	1417480	under consideration.
1417480	1420320	And the team had laid it out, listed out some pros and cons.
1420320	1422400	So they got on the team with me and some of my friends
1422400	1424200	and said, these are pros and cons.
1424200	1428880	And then one of my C2 AI fund and I said, you know,
1428880	1431000	we're not sure, but she has some reasons
1431000	1433160	that we prefer architecture A.
1433160	1435320	And then Renato said, okay, guys done,
1435320	1438680	decision made, go and implement architecture A.
1438680	1441040	And after I thought, well, did Renato
1441040	1443520	just make a massive engineering decision
1443520	1445480	in basically 30 seconds?
1445480	1447520	And she did.
1447520	1449160	And I realized after it,
1449160	1451080	I don't think there was a better way to make it
1451080	1452440	because it's not as if, you know,
1452440	1454560	if the company waited another week,
1454560	1456000	it would have been a high quality decision
1456000	1457120	and if it was wrong,
1457120	1459160	I'm sure they would fix it, you know, the next week.
1459160	1462040	But until you've lived through the speed
1462040	1464720	of a great business, most people,
1464720	1467320	I know so many people that think their organizations are fast
1467320	1469080	when you stack them up to the real speed
1469080	1470600	of a fast moving CEO,
1470600	1473680	they have never actually seen speed in their life.
1473680	1475760	One important caveat do be responsible.
1475760	1478240	I know that move fast and break things sometimes,
1478240	1479880	you know, it's the wrong approach.
1479880	1483680	So tremendous speed when you are not being callous
1483680	1486120	with people's lives and livelihood
1486120	1488080	and things that could cause real harm.
1488080	1490360	But so long as there's an important caveat
1490360	1492400	of responsible AI,
1492400	1494560	many of the great CEOs move faster
1494560	1497560	than most people realize people can move.
1497560	1499080	And so let's just double click on that
1499080	1500760	on this theme of responsible AI
1500760	1502360	just because I know this is a hot topic
1502360	1504360	that maybe people aren't thinking about,
1504360	1508400	which is you are clearly on the side of AI for good
1508400	1510320	for responsible AI.
1510320	1513040	Many of your brethren like Jeffrey Hinton
1513040	1515640	and other famous leaders in the AI space
1515640	1518480	have come out and are concerned
1518480	1519880	that the pace of AI development
1519880	1521920	will become an existential threat to humanity.
1521920	1524880	So much so that famously there was a petition signed
1524880	1528080	by Elon Musk and Steve Wozniak and many thought leaders
1528080	1530480	asking for the halting of the foundational,
1530480	1532800	the deepest foundational models of AI
1532800	1535480	for us to sort of, for society to sort of catch up.
1535480	1538480	You did not sign that pledge.
1538480	1540440	Can you share a little bit more detail about that?
1540440	1542560	Was that a difficult decision for you to make?
1542560	1543960	And can you share more details
1543960	1545760	about why you didn't join them
1545760	1548240	and what your philosophical view is regarding
1548240	1550720	if AI poses an existential threat?
1550720	1554080	So I honestly don't see how AI poses
1554080	1557400	any existential threat to the human race.
1557400	1559400	We know AI can run about self-driving cars
1559400	1561720	have crashed, leading to a tragic loss of life,
1561720	1564080	ultimately through trainings, trash the stock market.
1564080	1566040	So we know poorly designed software systems
1566040	1567680	can have a dramatic impact
1567680	1569400	and responsible AI is important.
1569400	1573200	But recently I saw tells people like Jeff
1573200	1574960	and others that were concerned
1574960	1576760	about the question of AI extinction
1576760	1579920	and I tried to understand why they thought this way.
1579920	1581760	Some were worried about bad actor
1581760	1583720	using AI to create a bio weapon.
1583720	1586200	Others were worried about AI evolving in a way
1586200	1588920	that inadvertently leads to human extinction
1588920	1593280	similar to how we as humans have led to the extinction
1593280	1595960	of many species through simple lack of awareness.
1595960	1599040	Sometimes that our actions could lead to that outcome.
1599040	1601320	But when I tried to assess how realistic
1601320	1602400	these arguments were,
1602440	1605120	I found them to be vague and non-specific
1605120	1607440	about how AI could cause all.
1607440	1610280	And I think that I found frustratingly frankly
1610280	1612800	that trying to prove AI couldn't
1612800	1614920	is akin to proving a negative.
1614920	1617240	And I can't prove that super intelligent AI
1617240	1618600	won't be dangerous,
1618600	1621120	but I can't seem to find anyone
1621120	1623520	that really knows exactly how it could be.
1624560	1629280	And but I do know that humanity has ample experience
1629280	1631160	controlling many things far more powerful
1631160	1634760	than any one of us like corporations and nation states.
1634760	1637600	And there are many things that we can't fully control
1637600	1639320	that are nonetheless safe and valuable.
1639320	1641640	Like airplanes, no one can control an airplane.
1641640	1643320	It's buffeted around by winds
1643320	1645560	and the pilot may make a mistake.
1645560	1647800	But in the early days of aviation,
1647800	1649520	airplanes killed many people.
1649520	1651400	So we learned from those experiences,
1651400	1652600	built safer aircraft,
1652600	1654720	devised rules by which to operate them.
1654720	1656640	And today most of us can step into airplane
1656640	1658320	without fearing for our lives.
1658320	1660920	And I think it would be like that too for AI.
1660920	1663040	So I think the AI extinction,
1663040	1664320	I find it to be very unfortunate.
1664320	1665160	What I'm seeing,
1665160	1667760	because doing some work in K-Tel of education as well,
1667760	1671040	what I'm seeing is that kind of really unfortunately,
1671040	1674960	I see high school students now considering working in AI.
1674960	1678640	And some will say, AI seems exciting,
1678640	1681040	but I heard it could lead to human extinction.
1681040	1683520	And I just don't want to be a part of that.
1683520	1687400	And so I find that the over height AI extinction narrative
1687400	1688560	is doing real harm.
1688560	1690720	So I'm really concerned about that.
1691680	1692520	Thank you, Andrew.
1692520	1693640	One more question that I'm gonna open it up,
1693640	1695200	which is, I loved the detail
1695200	1696560	on the low hanging fruit opportunities.
1696560	1697920	I know that's on everybody's,
1697920	1700240	all the entrepreneurs' minds of what to pursue.
1700240	1701280	And so I appreciated the attention
1701280	1702880	and the presentation on that.
1702880	1704440	I wanted to ask about what's gonna be
1704440	1706280	the next big technology shift in AI
1706280	1708600	because things are changing so rapidly,
1708600	1710520	especially as the models now are getting smaller
1710520	1712040	and open sourced.
1712040	1714200	It feels like we've already conquered language.
1714200	1717280	Visual AI is getting very, very good.
1717280	1718120	What's next?
1718120	1719600	What are you seeing that's around the corner
1719600	1721200	that others might not be aware of?
1721200	1722240	Yeah, you know what, Danit?
1722240	1723720	About several months ago,
1723720	1725680	I was predicting visual AI's coming next,
1725680	1726520	but now everyone's all right,
1726520	1728840	visual AI's gotta come with something new.
1728840	1730640	But in all seriousness, I think visual AI
1730640	1732680	would be much more about the analysis of images
1732680	1734480	rather than just generation of images.
1734480	1737320	But I think we're at like the GPT-2 moment
1737320	1738920	for visual AI is not yet working,
1738920	1740240	but I think it'll work much better.
1740240	1742640	And this will impact self-driving cars, for example,
1742640	1745440	when we can finally solve problems in a long tail.
1746400	1749120	And then I think, actually, one other thing that
1749120	1752200	I wrote about just today in a newsletter called The Batch
1752200	1756040	is I think one thing that many people find controversial
1756040	1758680	but I think is coming is the rise of edge AI.
1758680	1760040	And I know this controversial.
1760040	1762640	Many of us would train to write SaaS software,
1762640	1765720	lend to self-nice, the subscription business model.
1765720	1767000	How do you even find people?
1767000	1769200	How do you hire engineers to write desktop applications?
1769200	1770920	Like who even does that anymore?
1771120	1776120	But I think that because of various forces,
1776280	1779280	including privacy, I think that in the next few years
1779280	1783240	we'll see more AI applications running at the edge,
1783240	1786000	meaning on your laptop or on your cell phone.
1786000	1788400	So I think that'll be coming.
1788400	1790000	And then I think there'll just be a lot of work
1790000	1792280	coming in the application there as well.
1792280	1794080	Okay, I wanna open it up to the students.
1794080	1796560	You're the reason why Andrew's here.
1796560	1799360	You mentioned that on your slides,
1799360	1801360	you put the potential from reinforcement learning.
1801360	1803280	Are the general value as a dot
1803280	1806720	relative to the potential for unsupervised learning?
1806720	1808800	Do you think there is still potential
1808800	1811600	for generalist agents like GATO
1811600	1815000	and other reinforcement learning models in society
1815000	1817120	and in your AI stack for startups?
1818160	1822200	So technically, last time we trained models
1822200	1823800	that trained using reinforcement learning
1823800	1825760	and unsupervised learning and supervised learning
1825760	1827080	but leaving that aside,
1827080	1829160	I feel like I'm not convinced that reinforcement learning
1829160	1830480	is near breakthrough moments,
1830480	1833040	at least in the next small number of years.
1833040	1834760	A lot of excitement about what we could do
1834760	1836600	in reinforcement learning applied to robotics.
1836600	1839440	A lot about CS faculty, right, Chelsea Finn,
1839440	1842400	Emma Brunskill, many others are doing exciting research there
1842400	1844680	but we do have a data problem.
1844680	1846600	So it turns out that text on the internet
1846600	1848760	sounds a lot like text on your documents.
1848760	1851200	So we can learn from lots of text on the internet
1851200	1853480	to do really well on your text documents.
1853480	1854720	And image on the internet
1854720	1856640	look a little bit like images that you care about.
1856640	1858240	So we have a lot of data
1858240	1860520	but because every robot is different,
1861480	1864240	struggling, many people are struggling to see
1864240	1866760	how to get enough data to have the usual recipe
1866760	1868760	of scaling up data and compute
1868760	1870280	where for reinforcement learning
1870280	1872600	and people are working on it over the weekend
1872600	1876240	at the CS faculty retreat, you know, there was a talk,
1876240	1878240	I think, well, who gave this talk?
1878240	1879520	Shoot, thank you.
1879520	1883120	On how to do this, early ideas on how to do this
1883120	1885200	but I think we're still a few years away
1885200	1887960	from breakthroughs and those breakthroughs
1887960	1889440	and reinforcement learning.
1889440	1891320	But it's a great research topic, by the way,
1891320	1894440	just because, you know, just because it's not working
1894440	1897040	right now doesn't mean you shouldn't do research on it.
1897040	1899000	So I think it's a great research topic.
1899000	1902080	So I just want to know your thoughts about
1902080	1905440	what are the security concerns which is coming up
1905440	1907880	by you abusing that like LLM models,
1907880	1911000	like all these new attacks like prompt injections,
1911000	1913160	data leakage, jailbreaking.
1913160	1914680	So what's your thought around that?
1914680	1918720	Like how can we like safeguard against those kind of attack
1918720	1921200	because it's just starting up this new technology.
1921200	1925000	So I'm assuming there's more things which will come up.
1925000	1927520	Yes, so I think that for the near future
1927520	1930800	there'll be a little bit of a cat and mouse thing going on.
1932240	1935600	So I think I'm seeing different companies
1937240	1938880	approach this with different tools
1938880	1942040	to wash out for prompt injections, for data leakage.
1942040	1944240	Actually, DeepLand.ai is actually a work of a partner
1944240	1948680	on some things that hopefully will announce very soon
1948680	1951000	on our portfolio of tools.
1951000	1954080	By the way, those of you that have not yet done it,
1954080	1957000	go and fool around with prompt injections,
1957000	1960000	see if you can get an LLM to do something.
1960000	1962160	Well, don't do something actually harmful,
1962160	1965800	but I actually find it kind of intellectually interesting
1965800	1968440	whenever I use an LLM to prompt it
1968440	1971400	to see how robust the safeguards actually are.
1971840	1974360	And if I should look at the older language models a year ago,
1974360	1977280	it was super easy to get the older models,
1978240	1980440	frankly, to give you detailed directions
1980440	1982200	to do things that they should not give anyone
1982200	1983400	detailed directions to do.
1983400	1986120	But the more modern language models are much older,
1986120	1988680	but it's still sometimes possible.
1988680	1990560	Sorry, but what I'm seeing as well,
1990560	1991520	for a lot of corporations,
1991520	1993640	a lot of corporations because of these worries
1993640	1996440	will ship internal-facing product first
1996440	1999320	because presumably, if it says the wrong thing
1999320	2000680	to your own employee,
2000680	2003120	more understanding, less likelihood scandal,
2003120	2005800	and test products internally for quite a long time
2005800	2008720	or even build capabilities for safe internal use
2008720	2011640	before turning out to external use.
2011640	2013960	But I do see different companies,
2013960	2016680	yeah, different tools for trying to adjust these.
2017640	2018800	Terrific, next question.
2022200	2023640	Thank you so much.
2023640	2025040	Hi there, my name is Chinat
2025040	2027600	and I'm an international student from Hong Kong.
2027600	2029160	I'm curious to ask, because, you know,
2029160	2030680	I'm hoping that after I graduate,
2030680	2033360	I can hopefully go back home to work closer with family.
2033360	2035280	But at the same time, I feel like by going back,
2035280	2037520	I'm closing a lot of doors behind me
2037520	2039600	because, for example, in Hong Kong, for example,
2039600	2042360	you can't access ChatGVT without a U.S. number,
2042360	2044240	which makes access to some of these resources
2044240	2045280	really difficult.
2045280	2047200	So I'm curious to see what are your thoughts
2047200	2049720	about navigating this complex modern landscape?
2050760	2053800	Yeah, I don't want to comment on, I don't know,
2054760	2055600	complicated.
2055600	2057000	That's actually one thing I'm seeing.
2057000	2060640	I've been to quite a few places, you know, in Asia recently.
2061520	2065280	And what I'm seeing is that many countries
2065280	2068960	are developing surprisingly good capabilities
2068960	2072320	for building large language model applications.
2072320	2075680	The concentration of talent for Genesebo AI deep tech
2075680	2079800	is very concentrated in the San Francisco Bay Area.
2079800	2081840	I think because there are basically two teams
2081840	2083680	that did a lot of the early groundbreaking work,
2083680	2086040	you know, Google Brain, my former team, and OpenAI.
2086040	2088600	And subsequently, people left and started a lot of companies
2088600	2090240	here in the California Bay Area.
2090240	2093920	So I think that concentrated talent is very high.
2093920	2096320	And it's interesting, even when I'm in Seattle,
2096320	2098880	great city, love the city, on weekends,
2100080	2101280	you know, I hang out with friends,
2101280	2103800	but the conversations are not about Genesebo AI.
2103800	2106960	Whereas here, if you go to a coffee shop,
2106960	2109760	actually, one of my friends was visiting from Taiwan.
2109760	2111320	So he was hanging out with us for a week.
2111320	2113080	They went back and he said,
2113160	2115440	yeah, I went to a coffee shop and, you know,
2115440	2116960	there was no one talking about AI.
2116960	2117920	That's so weird.
2119600	2121080	So at least at this moment in time,
2121080	2123640	there's really heavy concentration.
2123640	2126400	But I see less the deep tech layer,
2126400	2127760	but the application layer,
2127760	2131320	I see that skillset developing quite quickly globally as well.
2132600	2134440	Oh, and I think the option is to allow places
2134440	2135600	to be local opportunities.
2135600	2137400	So the shipping company that we built,
2137400	2139760	we built with a Japanese company
2139760	2141960	that happens to operate global lines of shipping.
2141960	2144680	So I think a lot of the businesses will be, you know,
2144680	2148240	playing locally whether country or that geography is strong.
2148240	2151440	Those businesses will be more efficient to build in places
2151440	2153000	other than Silicon Valley.
2153000	2155960	Because where do I go to find a large seaport here
2155960	2157920	to do that type of work?
2158960	2160560	Hi, Andrew, thank you so much for your time.
2160560	2161880	My name is Komal.
2161880	2165280	I wanted to ask you if you think we'll ever reach a threshold
2165280	2167080	on human dependence for AI,
2167080	2170160	or if you think it'll just continue to grow exponentially?
2170960	2175280	So I think we already really, really depend on tech, right?
2175280	2179120	Imagine if, you know, if the internet were to shut down,
2179120	2180280	I think people would die.
2180280	2181400	I don't think that's the exact truth.
2181400	2183960	I mean, but seriously, think about, you know,
2183960	2186080	how we get through supply chain, healthcare.
2186080	2187760	If the internet were to shut down,
2187760	2190840	I think that will lead directly to, you know,
2191760	2193960	what happens our water system, right?
2193960	2195560	Healthcare system.
2195560	2199560	So, and I think that technology is very useful
2199560	2204080	and so long as the supplies remain reliable,
2206040	2209880	I feel like it's okay to depend on technology.
2209880	2211720	I mean, heck, I wish, I don't know,
2211720	2214720	without dependence on agriculture system,
2214720	2216240	how many of us would build a farm
2216240	2218440	and hunt enough food to keep ourselves alive?
2218440	2220800	Maybe, maybe we could do it, but it's pretty challenging.
2220800	2222400	So I think dependence on tech
2222400	2224560	seems to keep on growing for a while.
2224560	2225480	But do you think there'll be a moment
2225480	2227280	where there's a difference in that relationship,
2227280	2229160	not just in degree, but in kind?
2229160	2231120	You know, the famous singularity point
2231120	2232880	where we don't even know what we don't even know
2232880	2234880	about how technology is developing.
2234880	2236600	Do you think that will occur?
2236600	2238920	Yeah, you know, the technological singularity
2238920	2240840	is one of those hypey things
2240840	2242240	that I don't even know what it means.
2242240	2245640	So it's one of those, it's exciting science fiction,
2245640	2246960	but as an engineer and scientist,
2246960	2249840	I don't know how to talk about it.
2249840	2251600	It turns out there are a few terms in AI
2251600	2253040	that are vague and undefined,
2253040	2254320	but there are a lot of emotions,
2254320	2256880	a lot of excitement about it.
2256880	2258520	And I don't really know how to think
2258560	2261120	about those things in a systematic, rational way.
2261120	2263800	But I think, actually, there's actually one thing.
2263800	2266120	I think that our relationship to technology
2266120	2268160	is changing rapidly.
2269040	2272400	Today, you know, I probably use
2273400	2278320	chat, you know, GPT-4 or Bing or BOT
2278320	2279840	pretty much every day now.
2279840	2282840	And so the workflow of many people have changed.
2283840	2285040	I think people are changing.
2285040	2285880	And do you have a view?
2285880	2287240	I know this also might be more of one
2287240	2290240	of these sort of hot topics that's not substantive,
2290240	2292440	but on the consciousness of AI,
2292440	2294680	that AI will it become conscious?
2294680	2296600	Yeah, so the thing about consciousness
2296600	2298880	is it's important for the South Pole question,
2298880	2300200	but I don't know of any test
2300200	2302160	for whether something is conscious or not.
2302160	2303840	So I think it's important philosophy
2303840	2305600	and philosophy is important,
2305600	2307680	but as an engineer and scientist,
2307680	2309480	I don't know, there is no definition
2309480	2311520	for what is conscious or not,
2311520	2315160	which in does we can kind of debate it at length.
2315160	2319480	And there's actually one other formula for hype,
2319480	2321120	which is if someone comes up
2321120	2323680	with a very simple definition for consciousness,
2323680	2324520	so someone says,
2324520	2326280	oh, if you can recognize yourself in the mirror,
2326280	2327480	you're conscious, I made that up.
2327480	2328920	It's not a good definition for consciousness.
2328920	2331040	But you're aware of yourself, CSR in the mirror,
2331040	2332840	then it's actually pretty easy to get a robot
2332840	2334480	to recognize yourself in the mirror.
2334480	2336400	And then you can generate newspaper headlines
2336400	2338360	saying AI has achieved consciousness.
2338360	2339960	What it did for your kind of, you know,
2339960	2342160	silly little, for your very small definition
2342160	2344520	of consciousness, but that gets misinterpreted
2344560	2347160	by the broader public for a grander statement than it is.
2347160	2350840	So I see some of that hype in AI as well.
2350840	2352160	Thank you.
2352160	2353080	Next question.
2354440	2357960	Hi, earlier you outlined the AI stack.
2357960	2359680	And recently we've seen a lot of cool things
2359680	2363160	coming out of like NVIDIA, Intel and other like chip companies.
2363160	2364640	I'm curious on what your thoughts are
2364640	2367200	on what companies like AWS and Google,
2367200	2369200	like in the infrastructure layer need to do
2369200	2372160	in order to make like AI and enterprises and business
2372160	2374120	really effective and possible.
2374120	2377240	Sure, boy, so there's a lot going on in that space.
2377240	2380480	By the way, you mentioned Intel and NVIDIA.
2380480	2381920	I wouldn't, I think I'm actually seeing
2381920	2384040	really exciting work from AMD as well.
2384040	2387400	I've been pretty impressed by the MI 200, MI 250.
2387400	2390760	I'm excited about the MI 300 GPUs coming out as well.
2390760	2393640	And I think the ROCCOM stack is becoming, you know,
2393640	2396880	not parity or CUDA, but better than most people
2396880	2397960	give them credit for.
2399240	2401000	But in terms of Adode and Google,
2401000	2402440	so it turns out that if you were to use
2402440	2405080	a lot of the LLM startup tools,
2405080	2406840	the switching cost is actually pretty low.
2406840	2410160	So if you were to start with one LLM API call,
2410160	2412520	if you want to switch to a different LLM provider,
2412520	2415200	the number of lines of code is actually pretty low.
2415200	2416840	So there are low switching costs.
2416840	2419000	But it turns out that a zero in Google Cloud
2419000	2421400	and AWS are fantastic businesses
2421400	2423880	because once you build on any of these clouds,
2423880	2425880	you know, the switching costs tend to be very high
2425880	2428640	because you have so many API hooks integrations.
2428640	2431480	So that's why I think that a lot of the startups
2431520	2434040	selling API calls still have, you know,
2434040	2437160	some work to do to find a business model
2438040	2440200	that may be somewhat more defensible.
2440200	2444240	I think that OpenEye's chat GPD Enterprise,
2444240	2446680	that feels like a more defensible business
2446680	2448560	than just selling API calls.
2448560	2450320	By the way, Sam was actually a Stanford undergrad.
2450320	2452800	He actually interned, he's curious in my lab.
2452800	2455480	So a lot of Stanford roots, but he's a smart guy.
2455480	2456600	I'm sure he'll figure out,
2456600	2459560	confidently he'll figure out some good directions.
2459560	2462280	Yeah, and I think AWS and GCP and the Zora Rall
2464400	2469080	racing to continue to develop LLM capabilities
2469080	2471480	and make it easier to use and bring in more customers.
2471480	2474200	And yeah, it's a very dynamic space.
2474200	2477160	But as AI gets democratized,
2477160	2479800	it feels like things are shifting more towards compute
2479800	2482920	and data as predictors of success.
2482920	2483760	If that's the case,
2483760	2485320	do you think the locus of innovation shifts
2485320	2487240	from academia to industry
2487280	2489640	where the companies are gonna really be dominating
2489640	2490960	at the forefront of AI?
2490960	2494160	Yeah, so what I'm seeing now is that there's a subset,
2494160	2495920	but there's a small subset of things
2495920	2498120	that are easier to do in the big tech company,
2498120	2501080	which are the ones that require massive compute resources.
2501080	2504040	And I do think people's perceptions are distorted
2504040	2506200	because frankly, I've been on the big tech companies before,
2506200	2507040	right?
2507040	2508480	So I understand your marketing and big tech companies,
2508480	2511440	but the standard big tech company marketing is,
2511440	2514680	look, you need the data, you need to compute,
2514680	2516120	only we have it.
2516120	2518840	Why don't you just give up and don't compete with us, right?
2518840	2521320	And come apply for a job and come work with us.
2521320	2524480	That is, this has been the explicit PR strategy
2524480	2526160	of at least one big tech company
2526160	2529360	because I know what was discussed internally
2529360	2531280	exactly at that big tech company.
2531280	2534600	So I would say don't buy into that marketing message.
2534600	2536960	It is true that there is a subset of work
2536960	2539000	that requires massive capital,
2540160	2541680	training in very large foundation models.
2541680	2543920	That is much easier to do in a big tech company
2543920	2545720	than in academia like Stanford.
2545720	2549080	But that's a small subset of all the happenings in AI.
2549080	2551360	And there's plenty of work at Stanford,
2551360	2552640	at the application layer.
2552640	2554640	It turns out because of scaling laws,
2554640	2556040	we're actually pretty good at predicting
2556040	2557560	what will happen for very large models
2557560	2559520	by training on more model size models.
2559520	2561560	So very good scientific work can be done
2561560	2562840	and much smaller models.
2562840	2567320	And then also, I routinely run kind of models
2567320	2569000	on my laptop for inference.
2569000	2571360	Like, I don't know, when I'm on an airplane,
2571360	2573280	you can run like the seven billion llama model
2573280	2574120	on your laptop, right?
2574120	2575400	And so there's actually a lot of stuff
2575400	2579520	that you could run on your own personal computer.
2579520	2580440	Thank you.
2580440	2581280	Next question.
2582800	2583840	Thank you, Andrew.
2583840	2588680	So from an AI expert and also the investor's perspective,
2588680	2591880	so what AI driven healthcare applications
2591880	2593760	do you see have the great potentials
2593760	2595800	to have the breakthrough in the future?
2595800	2599680	And what challenges and obstacles should we be aware of?
2599680	2601200	Thank you.
2601200	2603960	Yeah, so boys, there's a lot of complexity to that question.
2603960	2606120	So I feel like a lot of healthcare,
2606120	2609600	people tend to focus on the diagnostics and the treatment.
2609600	2611440	So I think lots of opportunities there.
2611440	2615160	I think that the revenue model is to be sorted out.
2615160	2616520	So we've seen, you know,
2616520	2620360	Pear and Ikeli struggle in the public markets,
2620360	2623880	kind of bankruptcy kind of levels almost.
2624760	2626640	So I think prescriptive digital therapeutics
2626640	2628720	is definitely going through challenges.
2628720	2631200	But what's the recipe for shipping AI products
2631200	2633960	and in the payer-provide ecosystem,
2633960	2635560	what will pay us be willing to pay for?
2635560	2638120	I think that many businesses are sorting that out.
2638120	2639200	I think that will work.
2639200	2641400	And there's actually one other huge set of opportunities
2641400	2643680	in healthcare that tend to be underappreciated,
2643680	2644960	which is operations.
2644960	2646480	Instead of the medical stuff,
2646480	2648400	things like scheduling, you know,
2648400	2650680	who should scheduling the MRI machine
2650680	2654040	or doing kind of patient management systems.
2654040	2656160	I think that type of healthcare operations
2656160	2657720	have fewer regulatory hurdles.
2657720	2659800	I think is also a rich set of opportunities.
2659800	2662040	And then lastly, there's the go-to-market question of,
2662040	2663800	do you want to go to the market in the US
2663800	2667240	or in other countries where the regulatory hurdle
2667240	2669000	could be very different depending on,
2669000	2671840	the US fortunately doesn't have as great a shortage
2671840	2673640	of doctors as some other places.
2673640	2675600	And there are therefore other places
2675600	2679280	that are more amenable to your responsible
2679280	2682480	but still easier adoption of AI than the United States.
2682480	2684840	Okay, I have a super quick question.
2684840	2687240	You mentioned that your team at the AI fund
2687240	2689880	has so many ideas for AI applications
2689880	2691600	that you have a whole son of them.
2691600	2694680	What exactly is your process for generating these ideas?
2694680	2695760	Oh, there's also that.
2695760	2697000	And you have 30 seconds.
2697000	2699080	We like working with subject matter experts
2699080	2701120	that deeply understand the domain.
2701120	2703320	It turns out that there are a lot of people in the world,
2703320	2706120	you know, including like CEOs of Fortune 500 companies,
2706120	2708560	but really a lot of people that really understand the domain
2708560	2709880	have thought deeply about something
2709880	2711800	for months or even a couple of years.
2711800	2713240	And when we get together with them,
2713240	2715600	they're sometimes very happy to share their idea with us
2715600	2717200	because they've been looking for someone
2717200	2719960	to validate or falsify it and also to help them build it.
2719960	2721520	So we actually got a lot of ideas,
2721520	2723720	some in turn out with a lot from subject matter experts
2723720	2726360	that just not yet had an AI built upon there.
2726360	2727600	Terrific, that's fantastic.
2727600	2729800	Thank you Andrew so much for sharing your insights.
2729800	2730640	Thank you.
2730640	2734920	Lots of love.
2734920	2735840	Thank you for sharing your insights
2735840	2738200	with Stanford's ETL course MSME 472
2738200	2740680	and the students all around the world.
2740680	2742200	Everybody next week we're gonna be joined
2742200	2744440	by Stanford professor Kathleen Eisenhardt
2744440	2747520	here at ETL physically in person.
2747520	2750400	Professor Eisenhardt is also the author of Simple Rules.
2750400	2752520	You can find that event and other future events
2752520	2756040	in this ETL series on the Stanford eCorner YouTube channel
2756040	2758040	and you'll find even more of our videos, podcasts
2758040	2760560	and articles about entrepreneurship and innovation
2760560	2761760	at Stanford eCorner.
2761760	2763880	That's ecorner.stanford.edu.
2763880	2765160	Thank you everybody.
2765160	2766000	Thank you, Andrew.
2766000	2767000	Thanks, thanks Ravi.
