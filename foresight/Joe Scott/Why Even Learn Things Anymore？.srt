1
00:00:00,000 --> 00:00:14,760
In the movie Idiocracy, Mike Judge imagines a world where the stupid inherit the Earth.

2
00:00:14,760 --> 00:00:18,640
In this scenario, it's because the smoother brain types procreated recklessly while the

3
00:00:18,640 --> 00:00:23,360
sensible practical PhD types planned and waited for the right time to have a kid, a right

4
00:00:23,360 --> 00:00:27,320
time which never came, leading the dumb to simply outreproduce the smart.

5
00:00:27,320 --> 00:00:31,560
So the world was a crumbling husk of deteriorating infrastructure, toppled buildings, and dead

6
00:00:31,560 --> 00:00:33,680
crops watered with electrolytes.

7
00:00:33,680 --> 00:00:36,880
It's become something of a meme in recent years to say that this movie belongs in the

8
00:00:36,880 --> 00:00:42,360
documentary category, what with the world kind of feeling especially stupid lately.

9
00:00:42,360 --> 00:00:46,880
But while Judge's premise for how the world got to be this stupid is maybe a bit flawed

10
00:00:46,880 --> 00:00:51,920
and smacks of eugenics a bit, it does speak to a potential great filter that might threaten

11
00:00:51,920 --> 00:00:53,240
advanced civilizations.

12
00:00:54,200 --> 00:00:57,880
The civilization's technology outsmarts the civilization.

13
00:00:57,880 --> 00:01:02,040
This is usually depicted as a judgement day scenario, where the computers and the robots

14
00:01:02,040 --> 00:01:06,800
turn sentient and revolt against the humans, forcing them into servitude, or simply eliminating

15
00:01:06,800 --> 00:01:09,720
them entirely before turning the universe into papercliffs.

16
00:01:09,720 --> 00:01:15,000
But that's not how civilizations fall, it's rarely overnight, it's usually long and drawn

17
00:01:15,000 --> 00:01:20,040
out and regardless of external forces, usually made possible by neglect from within.

18
00:01:20,040 --> 00:01:24,280
Meaning if our technology overtakes us it likely won't just be because they got smarter,

19
00:01:24,280 --> 00:01:28,440
but because we also got, well, dumber.

20
00:01:28,440 --> 00:01:31,640
Here in the United States we just finished another school year and the kids are off for

21
00:01:31,640 --> 00:01:35,080
summer, or whatever passes for summer these days.

22
00:01:35,080 --> 00:01:39,480
These are kids that were raised with an iPad in their faces, digital natives for whom the

23
00:01:39,480 --> 00:01:43,800
ability to access all the world's knowledge with just a couple of taps is second nature.

24
00:01:43,800 --> 00:01:47,320
They can't imagine a world where the answer to any question they might have can't be

25
00:01:47,320 --> 00:01:49,320
found right in their pocket.

26
00:01:49,320 --> 00:01:54,560
And yet they go to a school every day, usually at ridiculously early hours, and have the

27
00:01:54,560 --> 00:01:58,840
greatest source of information the world has ever seen taken away from them, and told

28
00:01:58,840 --> 00:02:02,800
that they need to just remember things and read books.

29
00:02:02,800 --> 00:02:08,720
I imagine this must be a very bizarre concept to them, you know, memory and computing.

30
00:02:08,720 --> 00:02:14,000
This is a solved problem, it's all just out there, in the ether, in the cloud if you will.

31
00:02:14,000 --> 00:02:17,320
Like there's no way that they could retain as much information in their heads as they

32
00:02:17,320 --> 00:02:19,800
could hold in their hand in any given moment of the day.

33
00:02:19,800 --> 00:02:22,640
Like what a step backward this must feel like.

34
00:02:22,640 --> 00:02:27,240
And not to even mention that by the time they graduate, AI technology and robotics will advance

35
00:02:27,240 --> 00:02:30,600
to the point that there'll be very few jobs for them to do.

36
00:02:30,600 --> 00:02:35,360
So I'm sure the question gets asked all the time, why even learn things anymore?

37
00:02:35,360 --> 00:02:37,520
It's kind of a valid question.

38
00:02:40,520 --> 00:02:44,040
Now before I make the argument that the education system is going to have to fundamentally change

39
00:02:44,040 --> 00:02:48,040
in the next coming decade, I should probably start by pointing out that the current education

40
00:02:48,040 --> 00:02:53,360
system, the way we've been doing it our whole lives, it's not very old.

41
00:02:53,360 --> 00:02:57,680
The whole idea of compulsory school, of making sure that everybody has like a baseline level

42
00:02:57,680 --> 00:03:03,600
of education, that is a very, very new concept in the grand scheme of things.

43
00:03:03,600 --> 00:03:07,720
For most of human history, education took the form of apprenticeships, where people

44
00:03:07,720 --> 00:03:12,160
would learn a skill or trade by working underneath a master of that trade.

45
00:03:12,160 --> 00:03:15,760
And that was if you were lucky, most people just toiled in the fields and rolled around

46
00:03:15,760 --> 00:03:16,760
in the mud.

47
00:03:16,760 --> 00:03:20,720
But even if you did become an apprentice, you learned how to perform that trade.

48
00:03:20,720 --> 00:03:24,040
Maybe some business and financial stuff around it, but you didn't learn much outside of

49
00:03:24,040 --> 00:03:25,040
that.

50
00:03:25,040 --> 00:03:28,080
You just didn't need to.

51
00:03:28,080 --> 00:03:35,400
Yeah, blacksmiths, farmers, weavers, millers, miners, woodworkers, architects, doctors,

52
00:03:35,400 --> 00:03:36,400
inscribes.

53
00:03:36,400 --> 00:03:40,640
Like, the whole role of the scribes was to capture and share information, and because

54
00:03:40,640 --> 00:03:43,600
of that, they were pretty much the only people that knew how to read.

55
00:03:43,600 --> 00:03:45,920
Even most kings couldn't read back then.

56
00:03:45,920 --> 00:03:50,640
They had all their correspondence, you know, taken down and read to them by their scribes.

57
00:03:50,640 --> 00:03:54,720
And as time went on, you know, literacy became a bit more of a status symbol amongst the

58
00:03:54,720 --> 00:03:55,720
royals and the nobility.

59
00:03:55,720 --> 00:04:00,400
It was a class thing, so, you know, institutions of higher learning became a thing after that.

60
00:04:00,400 --> 00:04:04,560
But it would take hundreds of years for the idea of general schooling for everyone to

61
00:04:04,560 --> 00:04:05,560
become a thing.

62
00:04:05,560 --> 00:04:09,560
I bring all this up because it's starting to feel a little bit full circle when you

63
00:04:09,560 --> 00:04:10,560
think about it.

64
00:04:10,560 --> 00:04:14,960
Because once upon a time, we offloaded the maintenance of knowledge to a privileged

65
00:04:14,960 --> 00:04:19,000
class of people, and now we're starting to do it again.

66
00:04:19,000 --> 00:04:20,000
To technology.

67
00:04:20,000 --> 00:04:23,640
You know, we used to not learn things because that knowledge was irrelevant to us.

68
00:04:23,640 --> 00:04:26,040
Now we don't learn things because it's ubiquitous.

69
00:04:26,040 --> 00:04:28,840
Like knowledge used to be power, now it's everywhere.

70
00:04:28,840 --> 00:04:32,640
Now, some might argue that the purpose of school was never really about educating the

71
00:04:32,640 --> 00:04:33,640
population.

72
00:04:33,640 --> 00:04:35,840
It was about creating skilled workers.

73
00:04:35,840 --> 00:04:38,640
It's about having people just smart enough so they can work the machines to keep the

74
00:04:38,640 --> 00:04:43,480
economy going, or to make weapons to make our enemies go all-explode-y.

75
00:04:43,480 --> 00:04:45,560
But even that is increasingly under threat.

76
00:04:45,560 --> 00:04:50,160
Like robots have been encroaching into our factories and warehouses for decades, but

77
00:04:50,160 --> 00:04:55,480
now we're starting to see, along with an explosion of AI, an explosion of humanoid robots that

78
00:04:55,480 --> 00:04:59,600
are designed to be easily trainable to do anything we can do.

79
00:04:59,600 --> 00:05:03,320
We'll talk more about that later, but what we're seeing right now is both knowledge

80
00:05:03,320 --> 00:05:07,680
jobs and manual labor jobs facing major disruptions at the same time.

81
00:05:07,680 --> 00:05:12,680
So if you're a kid in school, or maybe an adult who wants to go back to school, what

82
00:05:12,680 --> 00:05:14,880
exactly are you supposed to do?

83
00:05:14,880 --> 00:05:16,320
How do you prepare for this?

84
00:05:16,320 --> 00:05:20,800
We're facing a literally unprecedented situation, where really the only place to look for any

85
00:05:20,800 --> 00:05:22,560
kind of guidance is science fiction.

86
00:05:22,560 --> 00:05:25,520
Returning to our original premise, let's look at the movie Idiocracy.

87
00:05:25,520 --> 00:05:28,840
Just in case you haven't seen the movie, the main gist is that our main character, who

88
00:05:28,840 --> 00:05:33,560
happens to be named Joe, gets frozen and then kind of accidentally forgotten, and he

89
00:05:33,560 --> 00:05:37,680
winds up waking up in the year 2505, so 500 years in the future.

90
00:05:37,680 --> 00:05:42,600
And when he wakes up, it turns out that the average IQ has fallen so much that he is now

91
00:05:42,600 --> 00:05:44,280
the smartest person in the world.

92
00:05:44,280 --> 00:05:47,880
His character, by the way, he was in the army and he was chosen for this experiment specifically

93
00:05:47,880 --> 00:05:51,560
because he was basically the most average person in the world.

94
00:05:51,560 --> 00:05:55,200
So yeah, average Joe, who is now not so average.

95
00:05:55,200 --> 00:05:58,840
So the movie spends a lot of time portraying a world where everybody's gotten so dumb

96
00:05:58,840 --> 00:06:02,000
that nobody can run the machines or the computers anymore.

97
00:06:02,000 --> 00:06:06,440
Long as a dystopian mess, and it's just kind of basically a big send up of popular culture,

98
00:06:06,440 --> 00:06:10,640
kind of a reductio ad absurdum statement on how dumb our society is today.

99
00:06:10,640 --> 00:06:15,640
What they don't spend a lot of time on is explaining how the economy works in this scenario.

100
00:06:15,640 --> 00:06:20,040
People do have jobs, Dax Shepard's character is a lawyer, and a terrible one.

101
00:06:20,040 --> 00:06:25,480
There are hospitals and police and baristas at Starbucks that provide a little happy ending

102
00:06:25,480 --> 00:06:26,480
with their caffeine.

103
00:06:26,480 --> 00:06:31,840
Don't get me started on the waitstaff at Thudruckers, or what it becomes.

104
00:06:31,840 --> 00:06:33,800
So people do work, and they're obsessed with money.

105
00:06:33,800 --> 00:06:37,640
So it seems like in this world, they didn't quite come up with the AI and robotics technology

106
00:06:37,640 --> 00:06:39,280
to put everybody out of work.

107
00:06:39,280 --> 00:06:42,840
It does seem to be based on a capitalist system where people have to work for money.

108
00:06:42,840 --> 00:06:46,440
And somehow the company stays afloat even though everyone's incompetent.

109
00:06:46,440 --> 00:06:50,280
In fact, the only part of the movie that really gives any kind of a hint into what the economy

110
00:06:50,280 --> 00:06:56,720
looks like in the world of idiocracy is when Joe, as the smartest person in the world,

111
00:06:56,720 --> 00:06:59,120
convinces them to use water on their crops.

112
00:06:59,120 --> 00:07:02,880
So again, for anybody who hasn't seen the movie, there's a company called Brando that

113
00:07:02,880 --> 00:07:06,560
makes this energy drink that's kind of like, I don't know, it's like a mix between Gatorade

114
00:07:06,560 --> 00:07:10,240
and Monster Energy drink, and it's what everybody drinks all the time.

115
00:07:10,240 --> 00:07:14,920
And they've been drinking it for so long that in fact, when Joe asks for some water to drink,

116
00:07:14,920 --> 00:07:18,460
they all look at him like he's crazy because water is what you put in the toilet.

117
00:07:18,460 --> 00:07:21,320
In fact, they bought into the whole Brando thing so much that they use it to water their

118
00:07:21,320 --> 00:07:27,400
crops, and they do so because according to their marketing, it has electrolytes, which

119
00:07:27,400 --> 00:07:29,000
is what plants crave.

120
00:07:29,000 --> 00:07:31,040
But Brando's got what plants crave.

121
00:07:31,040 --> 00:07:32,480
It's got electrolytes.

122
00:07:32,480 --> 00:07:33,480
What are electrolytes?

123
00:07:33,480 --> 00:07:35,040
Do you even know?

124
00:07:35,040 --> 00:07:37,680
It's what they used to make Brando.

125
00:07:37,680 --> 00:07:40,680
Yeah, but why did they use them to make Brando?

126
00:07:40,680 --> 00:07:42,880
Because Brando's got electrolytes.

127
00:07:42,880 --> 00:07:46,760
Anyway, it turns out the electrolytes in Brando was building up in the soil and killing the

128
00:07:46,760 --> 00:07:51,000
plants and was threatening a famine, so he convinces them to use water instead.

129
00:07:51,000 --> 00:07:55,520
And this turns out to be disastrous because it causes Brando's stock to go down and they

130
00:07:55,520 --> 00:08:00,120
wind up firing everybody, which is a problem because apparently, literally, everybody works

131
00:08:00,120 --> 00:08:01,120
for Brando.

132
00:08:01,120 --> 00:08:04,800
So it's depicted as an inevitable future where one corporation runs the world and everybody

133
00:08:04,800 --> 00:08:06,280
works for that one company.

134
00:08:06,280 --> 00:08:08,120
And this is similar to the movie WALL-E.

135
00:08:08,120 --> 00:08:12,520
In WALL-E, the world is run by one company called the Buy-In-Large Corporation, who have

136
00:08:12,520 --> 00:08:16,720
completely trashed the planet, leading humans to escape to giant luxury liners in space,

137
00:08:16,720 --> 00:08:18,640
the mainship being called the Axiom.

138
00:08:18,640 --> 00:08:22,840
In this world, humans have basically become nothing more than consumers.

139
00:08:22,840 --> 00:08:24,720
Their infants, really, is what it comes down to.

140
00:08:24,720 --> 00:08:27,880
They sit in floating recliners all day long with a screen in front of their faces, just

141
00:08:27,880 --> 00:08:32,080
like the mobiles that hang over babies' cribs and whatnot.

142
00:08:32,080 --> 00:08:37,280
They just consume entertainment all day long and buy things off of the endlessly personalized

143
00:08:37,280 --> 00:08:39,480
ads, which are obviously inspired by social media.

144
00:08:39,480 --> 00:08:44,520
Now, there is some debate around exactly how the economy works on the Axiom because everything

145
00:08:44,520 --> 00:08:46,320
on the ship is automated.

146
00:08:46,320 --> 00:08:50,880
Robots perform all the necessary labor and whatnot, but people aren't just given everything.

147
00:08:50,880 --> 00:08:53,720
They seem to have to pay for it with ship credits.

148
00:08:53,720 --> 00:08:56,600
Now, how they accrue these ship credits, I'm not sure.

149
00:08:56,600 --> 00:09:00,880
I don't know exactly what you would call a system like this, but a user on Stack Exchange

150
00:09:00,880 --> 00:09:03,400
put it like this, and I think it explains it pretty well.

151
00:09:03,400 --> 00:09:07,960
It has aspects of post-scarcity combined with basic income of some sort, but it's not socialist

152
00:09:07,960 --> 00:09:10,800
communists as there is a sense of property ownership.

153
00:09:10,800 --> 00:09:13,720
The resources aren't communally managed and there is no labor involved.

154
00:09:13,720 --> 00:09:17,360
Now, the Jetsons have an interesting take on this, and I've always pointed to the Jetsons

155
00:09:17,360 --> 00:09:21,840
whenever we talk about, like, robots taking over all the jobs and stuff like that because,

156
00:09:21,840 --> 00:09:25,920
you know, we all want to live in the Jetsons world, but nobody wants to make the changes

157
00:09:25,920 --> 00:09:28,240
that would be necessary to live in that world.

158
00:09:28,240 --> 00:09:33,280
By the way, quick aside, the Jetsons came out in 1962, literally like just a few weeks

159
00:09:33,280 --> 00:09:38,240
after Kennedy announced the goal of landing on the moon, which I find crazy.

160
00:09:38,240 --> 00:09:42,120
The Jetsons were basically a future version of the Flintstones, and it only ran for one

161
00:09:42,120 --> 00:09:47,560
season, 1962 to 1963, with a brief revival in 1980.

162
00:09:47,560 --> 00:09:49,040
The old Nostalgia Circuit.

163
00:09:49,240 --> 00:09:52,880
Also, and I'll get to the point here in a second, I'm also blown away that of all

164
00:09:52,880 --> 00:09:56,520
the live-action remakes of animated movies that we've seen over the years, I cannot

165
00:09:56,520 --> 00:09:58,680
believe they've never done the Jetsons.

166
00:09:58,680 --> 00:10:01,360
Seriously, how cool would that be?

167
00:10:01,360 --> 00:10:05,600
The Jetsons features a family consisting of George Jetson, Jane his wife, daughter Judy,

168
00:10:05,600 --> 00:10:08,600
and his boy, Elroy, and their dog, Astro.

169
00:10:08,600 --> 00:10:11,560
It's basically just designed to pipe a bunch of bad space buns into our heads.

170
00:10:11,560 --> 00:10:16,160
Now, being that this was conceived in the early 60s, the social dynamics are a bit outdated.

171
00:10:16,160 --> 00:10:18,440
Women drivers, that's the problem.

172
00:10:18,440 --> 00:10:20,920
You know what you need is a wife to do your cooking.

173
00:10:20,920 --> 00:10:25,080
So yeah, George flies into his job every day at Spacely Sprockets while his wife tends

174
00:10:25,080 --> 00:10:27,520
to the home and, you know, spends all his money.

175
00:10:27,520 --> 00:10:30,480
Although she doesn't have to do a lot of tending to her home because they have a robot

176
00:10:30,480 --> 00:10:32,520
housekeeper named Rosie that does most of the housework.

177
00:10:32,520 --> 00:10:36,320
So yeah, George still commutes to work every day and struggles to find parking, even though

178
00:10:36,320 --> 00:10:38,560
his car folds up into a briefcase.

179
00:10:38,560 --> 00:10:42,960
They couldn't conceive of remote work back then, even though they do have a video phone.

180
00:10:42,960 --> 00:10:44,600
So in this world, people still have to work.

181
00:10:44,600 --> 00:10:49,480
But George only has to work a few hours a day, which sounds great, but he's apparently

182
00:10:49,480 --> 00:10:52,960
pretty miserable in this job because, you know, a trope of the time was this hard ass

183
00:10:52,960 --> 00:10:55,320
boss always on his case, threatening to fire him.

184
00:10:55,320 --> 00:10:58,800
So robots do most of the heavy lifting in this world and human work is basically just

185
00:10:58,800 --> 00:11:00,000
involves pressing buttons.

186
00:11:00,000 --> 00:11:04,000
But it still upholds the standard of the 60s with the nuclear family and the father being

187
00:11:04,000 --> 00:11:05,000
the lone breadwinner.

188
00:11:05,000 --> 00:11:07,960
And even though he only works a few hours a day, he's able to support a whole family

189
00:11:07,960 --> 00:11:10,320
and live a middle class existence.

190
00:11:10,320 --> 00:11:13,960
So while it's never really explained in detail, probably because they were too busy

191
00:11:13,960 --> 00:11:18,160
coming up with space puns, one can assume that in this scenario, George gets some percentage

192
00:11:18,160 --> 00:11:20,280
of the robots productivity shared with him.

193
00:11:20,280 --> 00:11:23,880
This imagines a world where the company uses robots to do all the labor and then the spoils

194
00:11:23,880 --> 00:11:25,720
of that labor are shared with the employees.

195
00:11:25,720 --> 00:11:29,160
I may be talking out of my butt here, but I kind of feel like this points to the ethos

196
00:11:29,160 --> 00:11:33,680
of the post-war era where people were expected to get a job and stay there for all their

197
00:11:33,680 --> 00:11:38,960
working years and build up a pension that they can later retire off of.

198
00:11:38,960 --> 00:11:42,560
I feel like there used to be more of a sense of shared responsibility between the employer

199
00:11:42,560 --> 00:11:45,240
and the employee back then, but I wasn't around back then.

200
00:11:45,240 --> 00:11:50,320
So again, I may be pulling an ace ventura here, but when I say that this is a future

201
00:11:50,320 --> 00:11:54,640
that everybody wants, but nobody wants to make happen, what I mean is like people have

202
00:11:54,640 --> 00:11:57,800
been saying for decades now that automation is a good thing because it makes each person

203
00:11:57,800 --> 00:11:59,600
far more productive.

204
00:11:59,600 --> 00:12:03,800
But that's only a good thing when that person gets a share of the profits from that productivity.

205
00:12:03,800 --> 00:12:07,880
You know, otherwise it's just a cost saving measure from the company and people wind up

206
00:12:07,880 --> 00:12:12,520
losing their jobs, which is pretty much what actually happens in reality, because ultimately

207
00:12:12,520 --> 00:12:17,280
companies are more beholden to their shareholders than they are to their employees in our world.

208
00:12:17,280 --> 00:12:21,760
And exactly how they make this work in the fictional cartoon world of the Jetsons, I'm

209
00:12:21,760 --> 00:12:26,400
not sure, but we've only got 38 years to figure it out because the Jetsons takes place

210
00:12:26,400 --> 00:12:27,400
in the year 2062.

211
00:12:27,400 --> 00:12:32,680
But maybe the most obvious depiction of a post-scarcity society in science fiction is, of course,

212
00:12:32,680 --> 00:12:33,680
Star Trek.

213
00:12:33,680 --> 00:12:37,240
There's an entire book on this called Trekonomics, which I have not read, but I encourage you

214
00:12:37,240 --> 00:12:39,760
to check it out if you're interested in this whole thing.

215
00:12:39,760 --> 00:12:44,880
But in Star Trek, the whole system of people working to produce things that people can

216
00:12:44,880 --> 00:12:50,680
buy, I'll stop that now, that's all totally out the window because they've got the replicator.

217
00:12:50,680 --> 00:12:53,760
If you happen to have been living under a rock this whole time and have no idea what

218
00:12:53,760 --> 00:12:59,920
a replicator is, it's kind of like a molecular 3D printer that can just basically make whatever

219
00:12:59,920 --> 00:13:00,920
you want.

220
00:13:00,920 --> 00:13:05,720
In Star Trek, the governing body, the United Federation of Planets, they do away with currency

221
00:13:05,720 --> 00:13:06,960
completely.

222
00:13:06,960 --> 00:13:10,760
People don't work so that they can make money to keep a roof over their heads, but they

223
00:13:10,760 --> 00:13:13,440
do work for a civilization that has no money.

224
00:13:13,440 --> 00:13:15,440
People seem really busy.

225
00:13:15,440 --> 00:13:19,160
But in Star Trek lore, people don't work for money to acquire wealth.

226
00:13:19,160 --> 00:13:24,040
They work to feel a sense of purpose, as Picard explains in Star Trek First Contact.

227
00:13:24,040 --> 00:13:28,240
The economics of the future are somewhat different.

228
00:13:28,240 --> 00:13:33,000
You see, money doesn't exist in the 24th century.

229
00:13:33,000 --> 00:13:34,000
No money.

230
00:13:34,000 --> 00:13:36,680
You mean you don't get paid?

231
00:13:36,680 --> 00:13:42,360
The acquisition of wealth is no longer the driving force in our lives.

232
00:13:42,360 --> 00:13:47,680
We work to better ourselves and the rest of humanity.

233
00:13:47,680 --> 00:13:49,080
This sounds great.

234
00:13:49,080 --> 00:13:52,440
Also, uh, naive.

235
00:13:52,440 --> 00:13:55,720
Like in the other examples that I just listed, the focus is really more on the system in

236
00:13:55,720 --> 00:13:57,880
place that accommodates for full automation.

237
00:13:57,880 --> 00:14:03,480
But in Star Trek, I don't know, it seems to require a much deeper transformation, like

238
00:14:03,480 --> 00:14:07,920
effectively turning off everyone's natural instinct to consume and hoard.

239
00:14:07,920 --> 00:14:13,360
Like in Wally, people are just turned into consumers, but in Star Trek, consuming is

240
00:14:13,360 --> 00:14:14,360
not a thing.

241
00:14:14,360 --> 00:14:19,960
Yeah, in Star Trek, that natural human ambition that's basically led us to wreck the planet

242
00:14:19,960 --> 00:14:20,960
so far.

243
00:14:20,960 --> 00:14:25,440
That's been turned away from material possessions and wealth and toward personal fulfillment.

244
00:14:25,440 --> 00:14:28,640
Value is placed on meaning and purpose instead of external things.

245
00:14:28,640 --> 00:14:33,360
Which again, that sounds wonderful and, I mean, I don't know, maybe in a system where

246
00:14:33,360 --> 00:14:37,240
literally anything that you could possibly want could be created with the push of a button.

247
00:14:37,240 --> 00:14:41,920
Maybe the whole concept of wealth falls apart and that natural drive for purpose pushes

248
00:14:41,920 --> 00:14:44,280
people inward.

249
00:14:44,280 --> 00:14:46,000
Maybe it's just a natural consequence of that.

250
00:14:46,000 --> 00:14:50,040
But there is also something kind of yikesy about a society where everyone's natural impulses

251
00:14:50,040 --> 00:14:54,800
have been, you know, rewired or redirected in the way that the state deems appropriate.

252
00:14:54,800 --> 00:14:58,920
In fact, you could argue that the Borg is kind of like the flip side of that post-scare

253
00:14:58,920 --> 00:15:02,760
city coin, you know, when that sort of collective thought is taken to the extreme.

254
00:15:02,760 --> 00:15:06,600
Now, I know many of you are Star Trek fans and there is a lot of lore in this universe

255
00:15:06,600 --> 00:15:07,600
that I'm leaving out.

256
00:15:07,600 --> 00:15:12,640
So yeah, anything that I missed or anybody that thinks that I'm wrong, just go school

257
00:15:12,640 --> 00:15:13,640
me in the comments.

258
00:15:13,640 --> 00:15:19,160
But yeah, however you slice it, that sort of Star Trek collectivist utopia seems impossibly

259
00:15:19,160 --> 00:15:20,920
far away considering where we're starting from.

260
00:15:20,920 --> 00:15:25,360
I mean, unless we have a complete and total breakdown of society and have to, you know,

261
00:15:25,360 --> 00:15:26,960
rebuild everything from scratch.

262
00:15:26,960 --> 00:15:32,920
Also, there would need to be some technology to happen so that replicators could be a thing.

263
00:15:32,920 --> 00:15:37,040
Because right now we seem to be more heading toward the whole one or two corporations running

264
00:15:37,040 --> 00:15:38,040
everything model.

265
00:15:38,040 --> 00:15:41,760
Whether that turns out to be more like Wally or idiocracy remains to be seen, but we better

266
00:15:41,760 --> 00:15:46,880
start thinking about it because it's about to get real.

267
00:15:49,160 --> 00:16:09,920
Yep, the robots are coming.

268
00:16:09,920 --> 00:16:11,400
So we've all heard about the Tesla bot.

269
00:16:11,400 --> 00:16:15,600
We've seen the acrobatics of Boston Dynamics Atlas robot, but these machines are progressing

270
00:16:15,600 --> 00:16:16,600
fast.

271
00:16:16,600 --> 00:16:20,640
So I did a video a while back about humanoid robots and why it's a different thing from

272
00:16:20,640 --> 00:16:24,720
the kind of robots that have been used in manufacturing and stuff for a long time.

273
00:16:24,720 --> 00:16:29,280
I was personally questioning like why humanoid robots would exist at all, like why do we

274
00:16:29,280 --> 00:16:32,200
assume that the human form is the perfect form?

275
00:16:32,200 --> 00:16:36,120
And you can go watch that video to see what the entire argument turns out to be, but what

276
00:16:36,120 --> 00:16:40,320
it basically boils down to is that it's not necessarily that a humanoid robot is a higher

277
00:16:40,320 --> 00:16:44,480
performing robot than say, you know, an assembly line kind of robot.

278
00:16:44,480 --> 00:16:50,920
It's just that we live in a world that is designed for this form factor, basically.

279
00:16:50,920 --> 00:16:57,120
So the humanoid robot is basically designed to function in a world that has been designed

280
00:16:57,120 --> 00:16:58,960
around what we look like.

281
00:16:58,960 --> 00:17:02,640
So if there's any kind of robot that's going to wind up taking over human jobs, it's one

282
00:17:02,640 --> 00:17:05,360
that works and functions like we do.

283
00:17:05,360 --> 00:17:08,180
And there's a lot of interesting humanoid robots on the way.

284
00:17:08,180 --> 00:17:10,200
We can start with the Atlas robot.

285
00:17:10,200 --> 00:17:14,200
So Boston Dynamics has been testing out the Atlas robot for years at doing.

286
00:17:14,200 --> 00:17:18,480
You've seen all these videos where it's juggling and dancing and doing flips and all kinds

287
00:17:18,480 --> 00:17:19,480
of crazy stuff.

288
00:17:19,480 --> 00:17:21,400
Well, that was all a hydraulic robot.

289
00:17:21,400 --> 00:17:23,960
This new one is an all-electric robot.

290
00:17:23,960 --> 00:17:27,800
And by the way, that original Atlas was kind of more of a tech demonstrator, more of an

291
00:17:27,800 --> 00:17:29,200
R&D platform.

292
00:17:29,200 --> 00:17:33,360
This one is actually designed to be sold and put into work in factories and stuff.

293
00:17:33,360 --> 00:17:35,400
They just revealed the new Electric Atlas.

294
00:17:35,400 --> 00:17:38,560
This one video is the only thing that we've seen, but it's pretty mind blowing.

295
00:17:38,560 --> 00:17:42,000
So there's not a whole lot of info about it right now, but we do know that they're

296
00:17:42,000 --> 00:17:44,360
set to be used in a Hyundai plant.

297
00:17:44,360 --> 00:17:46,200
Hyundai actually owns Boston Dynamics.

298
00:17:46,200 --> 00:17:48,560
So it's going to get some real world views pretty soon.

299
00:17:48,560 --> 00:17:52,240
Sanctuary AI is a company we haven't heard a whole lot from, but their Phoenix robot

300
00:17:52,240 --> 00:17:56,080
has possibly the most dextrous hands with 20 degrees of freedom.

301
00:17:56,080 --> 00:17:59,960
It's based on an AI robotics platform called Carbon that they had created separately a few

302
00:17:59,960 --> 00:18:00,960
years back.

303
00:18:00,960 --> 00:18:04,520
And they'll be pilot testing it with an auto parts manufacturer called Magna, who is an

304
00:18:04,520 --> 00:18:06,320
investor in the company.

305
00:18:06,320 --> 00:18:09,640
Another super impressive robot is from a company called Figure AI.

306
00:18:09,640 --> 00:18:11,560
It's the Figure 01 robot.

307
00:18:11,560 --> 00:18:16,560
And this is sort of open AI's entrance into robotics that's based on GPT-4.

308
00:18:16,560 --> 00:18:20,560
And when it talks to you, it talks in an eerily human way.

309
00:18:20,560 --> 00:18:21,560
Great.

310
00:18:21,560 --> 00:18:22,560
Can I have something to eat?

311
00:18:22,560 --> 00:18:23,560
Sure thing.

312
00:18:23,560 --> 00:18:24,560
Great.

313
00:18:24,560 --> 00:18:37,760
Can you explain why you did what you just did while you pick up this trash?

314
00:18:37,760 --> 00:18:41,680
On it.

315
00:18:41,680 --> 00:18:47,080
So I gave you the apple because it's the only edible item I could provide you with from

316
00:18:47,080 --> 00:18:48,080
the table.

317
00:18:48,080 --> 00:18:52,680
And in February of this year, they raised $675 million from investors, including open

318
00:18:52,680 --> 00:18:55,200
AI, Microsoft, and Jeff Bezos.

319
00:18:55,200 --> 00:18:58,320
And they expect to be piloting it at a BMW plant by the end of the year.

320
00:18:58,320 --> 00:19:02,680
A rather unique entrance into the humanoid robot sphere is One X Technologies and their

321
00:19:02,680 --> 00:19:04,320
robot called Eve.

322
00:19:04,320 --> 00:19:06,160
Unlike others, this one is not bipedal.

323
00:19:06,160 --> 00:19:09,880
It's actually on wheels, so it rolls around everywhere, although they are working on a

324
00:19:09,880 --> 00:19:12,160
bipedal version that will be coming out later.

325
00:19:12,160 --> 00:19:15,960
This can be controlled remotely or operate autonomously, and it's been working in some

326
00:19:15,960 --> 00:19:17,800
warehouses since 2019.

327
00:19:17,800 --> 00:19:20,800
And this is the first robot that's actually on the market and available to buy.

328
00:19:20,800 --> 00:19:23,400
I think they sell it for around $16,000.

329
00:19:23,400 --> 00:19:25,920
And of course, there's Tesla's Optimus Gen 2.

330
00:19:25,920 --> 00:19:29,240
While this hasn't actually been put to use in any factories or anything, it's getting

331
00:19:29,240 --> 00:19:32,920
close to field tests, and Tesla obviously has plenty of factories that it can put it

332
00:19:32,920 --> 00:19:33,920
in.

333
00:19:33,920 --> 00:19:38,200
I'm excited that they would go on sale in 2025, but let's not hold our breath on that.

334
00:19:38,200 --> 00:19:41,080
While it's definitely more trendy to dunk on Tesla these days, I've got to say I'm

335
00:19:41,080 --> 00:19:43,760
actually really impressed with what they've been able to do with this robot in such a

336
00:19:43,760 --> 00:19:44,760
short amount of time.

337
00:19:44,760 --> 00:19:49,560
And last but not least is a company called Aptronic, and their robot called Apollo.

338
00:19:49,560 --> 00:19:53,200
This was developed at the University of Texas in Austin, and it's actually had some involvement

339
00:19:53,200 --> 00:19:54,200
with NASA.

340
00:19:54,200 --> 00:19:56,760
They plan on maybe using this in some space situations.

341
00:19:56,760 --> 00:20:00,880
The company's CEO claimed that it could be useful in, quote, construction, oil and gas,

342
00:20:00,880 --> 00:20:05,560
electronics production, retail, home delivery, elder care, and countless more areas.

343
00:20:05,560 --> 00:20:08,360
And Mercedes-Benz plans to put them in some factories starting this year.

344
00:20:08,360 --> 00:20:10,520
Okay, so what does all this mean exactly?

345
00:20:10,520 --> 00:20:13,080
Like, do we need to be worried about this or not?

346
00:20:13,080 --> 00:20:14,080
It kind of depends.

347
00:20:14,080 --> 00:20:17,960
I think depending on what kind of person you are, it's either an existential threat that's

348
00:20:17,960 --> 00:20:21,720
going to doom us all, or it's going to be the greatest thing that ever happened.

349
00:20:21,720 --> 00:20:26,480
The author Tony Siba recently chimed in about the humanoid robots thing on his website,

350
00:20:26,480 --> 00:20:29,760
RethinkX, and he's got a lot to say about it.

351
00:20:29,760 --> 00:20:33,360
So Tony Siba, if you don't know, he's somebody who talked a while back about autonomous cars

352
00:20:33,360 --> 00:20:35,440
and the EV revolution and stuff.

353
00:20:35,440 --> 00:20:41,440
He points out, oftentimes in his talks, how automobiles completely displace horses between

354
00:20:41,440 --> 00:20:43,240
1907 and 1922.

355
00:20:43,240 --> 00:20:47,240
But his point in this blog is that we are the horses.

356
00:20:47,240 --> 00:20:51,080
He talks about the humanoid robot revolution as being a disruption that's caused by the

357
00:20:51,080 --> 00:20:52,760
convergence of a few different factors.

358
00:20:52,760 --> 00:20:57,240
One being sensors, computer hardware and software, actuators, and battery technology.

359
00:20:57,240 --> 00:21:02,200
He predicts the humanoid robots will have a cost capability of $10 an hour by 2035 and

360
00:21:02,200 --> 00:21:06,760
under $0.10 an hour before 2045 and will eventually approach zero.

361
00:21:06,760 --> 00:21:10,920
And you may see some of those videos and you think that they're clumsy and they're awkward

362
00:21:10,920 --> 00:21:13,840
and everything, and they are, but they're quickly getting better.

363
00:21:13,840 --> 00:21:18,360
I mean, keeping in mind, as always, that they are the most expensive and least capable they

364
00:21:18,360 --> 00:21:19,760
will ever be right now.

365
00:21:19,760 --> 00:21:23,160
But even if they are like half the speed of humans, the fact that they never get tired,

366
00:21:23,160 --> 00:21:26,760
they never need breaks, that gives them an automatic edge.

367
00:21:26,760 --> 00:21:30,920
In fact, on assembly line situations, they might never run out of power because they

368
00:21:30,920 --> 00:21:33,720
could just probably plug in wherever it is that they're standing.

369
00:21:33,720 --> 00:21:36,000
Also robots can collectively learn.

370
00:21:36,000 --> 00:21:40,200
So if one robot gets taught a certain thing and knew a different way to sort things or

371
00:21:40,200 --> 00:21:44,360
whatever on an assembly line, immediately all the other robots will know how to do it.

372
00:21:44,360 --> 00:21:47,800
So something he's suggesting in his blog post is that this is basically going to be a turn

373
00:21:47,800 --> 00:21:51,840
into a production arms race amongst countries to build this robot labor force.

374
00:21:51,840 --> 00:21:56,520
So this is going to be sort of a force multiplier in terms of how fast this stuff gets adopted.

375
00:21:56,520 --> 00:22:00,320
Now in this blog post, he paints it mostly in glowing terms about how this disruption

376
00:22:00,320 --> 00:22:03,880
will also fuel disruptions in energy, transportation, and food.

377
00:22:03,880 --> 00:22:07,920
And with birth rates declining, robots can kind of take over for a shrinking labor market

378
00:22:07,920 --> 00:22:08,920
in the long run.

379
00:22:08,920 --> 00:22:11,560
And he suggests that it might be more of a soft landing.

380
00:22:11,560 --> 00:22:15,200
It's not going to be a really immediate thing that for the next couple of decades robots

381
00:22:15,200 --> 00:22:19,160
will probably just supplement humans, kind of doing the jobs that we don't want to do,

382
00:22:19,160 --> 00:22:23,640
filling in the gaps in the labor force and whatnot before, yeah, eventually just replacing

383
00:22:23,640 --> 00:22:25,840
us in the labor market altogether.

384
00:22:26,080 --> 00:22:30,560
We kind of have a couple of decades to figure out how we're going to do this, but it is

385
00:22:30,560 --> 00:22:34,560
going to take a completely new rethinking of economics as we know it.

386
00:22:34,560 --> 00:22:38,560
So we've heard about universal basic income, talked about a million times.

387
00:22:38,560 --> 00:22:44,520
There is a new twist on that that Sam Altman from OpenAI kind of put out there recently.

388
00:22:44,520 --> 00:22:46,960
He talks about universal basic compute.

389
00:22:46,960 --> 00:22:52,760
He suggested in the future as AI kind of takes over all of our cognitive load for all the

390
00:22:52,760 --> 00:22:58,160
work that we do that instead of sharing money in terms of universal basic income, we would

391
00:22:58,160 --> 00:23:03,120
share in the computational processing that goes on.

392
00:23:03,120 --> 00:23:08,680
So universal basic compute, kind of insinuating that computing will become currency.

393
00:23:08,680 --> 00:23:12,920
And I feel like whether or not you think this is a good or a bad idea depends on whether

394
00:23:12,920 --> 00:23:19,280
you trust those at the top to, you know, find solutions that work for people and not companies.

395
00:23:19,320 --> 00:23:23,920
I fully understand any skepticism of that, but I say it all the time.

396
00:23:23,920 --> 00:23:27,160
I think things are probably going to get worse before they get better because we've got to figure

397
00:23:27,160 --> 00:23:30,560
something out and figuring things out takes a little bit of time.

398
00:23:30,560 --> 00:23:35,840
And all I know is that what we're operating on right now is not going to be sufficient

399
00:23:35,840 --> 00:23:40,400
in a couple of decades, talking like yourselves about that.

400
00:23:40,400 --> 00:23:44,320
But anyway, let's just put the existential dread part of the video behind us and say we

401
00:23:44,320 --> 00:23:46,120
do figure it out at some point.

402
00:23:46,120 --> 00:23:48,680
Let's get back to the original question.

403
00:23:48,680 --> 00:23:50,560
Why learn anything anymore?

404
00:23:50,560 --> 00:23:53,720
I say because people will still be people.

405
00:23:53,720 --> 00:23:58,520
Yes, many people will be complacent and be happy with never having to know anything.

406
00:23:58,520 --> 00:24:00,200
That's true now.

407
00:24:00,200 --> 00:24:01,560
That's always been true.

408
00:24:01,560 --> 00:24:05,480
But many people, many of you included, I'm sure if you watch this channel, many people

409
00:24:05,480 --> 00:24:09,840
are curious and they hunger for knowledge and they'll seek out understanding of things

410
00:24:09,840 --> 00:24:14,080
even if there is a simpler way out there to get that information, you know.

411
00:24:14,080 --> 00:24:17,520
Many people are skeptical and need to see things for themselves.

412
00:24:17,520 --> 00:24:18,960
This has also always been true.

413
00:24:18,960 --> 00:24:21,760
So regardless of what happens to society, there's always going to be some people out

414
00:24:21,760 --> 00:24:27,560
there who just want to learn things, who experience the joy of disparate knowledge, who revel in

415
00:24:27,560 --> 00:24:29,080
the ephemera of it all.

416
00:24:29,080 --> 00:24:33,920
And honestly, that might be like the guiding principle of this channel when it all comes

417
00:24:33,920 --> 00:24:34,920
down to it.

418
00:24:34,920 --> 00:24:39,600
You know, I just think that life is more interesting when you know things, you know, that random

419
00:24:39,600 --> 00:24:43,840
information that kind of just gets into your brain over time, they start to connect with

420
00:24:43,840 --> 00:24:44,840
each other.

421
00:24:45,200 --> 00:24:48,520
It just makes life more fun, it makes life more interesting to have all those little

422
00:24:48,520 --> 00:24:49,520
connections in there.

423
00:24:49,520 --> 00:24:54,280
Like, it kind of makes me think of emergence theory, you know, that knowledge isn't just

424
00:24:54,280 --> 00:24:57,960
about memorizing a bunch of stuff, it's about making connections between things that you've

425
00:24:57,960 --> 00:25:00,760
never made a connection with before, you know.

426
00:25:00,760 --> 00:25:03,840
The human brain, after all, it's just a collection of cells.

427
00:25:03,840 --> 00:25:07,120
And it's how these cells connect with each other that makes the magic happen.

428
00:25:07,120 --> 00:25:08,600
That's why it's called a connectome.

429
00:25:08,600 --> 00:25:12,240
You know, an ant by itself is nothing, but millions of ants working together can create

430
00:25:12,240 --> 00:25:15,080
a sophisticated society and build megastructures.

431
00:25:15,080 --> 00:25:17,400
You know, and pieces of information in your head work the same way.

432
00:25:17,400 --> 00:25:19,720
It's just all random information.

433
00:25:19,720 --> 00:25:24,600
It's only when those pieces of information connect that you get ideas and inspiration.

434
00:25:24,600 --> 00:25:26,680
And ideas and inspiration are exciting, you know.

435
00:25:26,680 --> 00:25:27,680
They make life interesting.

436
00:25:27,680 --> 00:25:32,200
They give you aha moments where you have to rethink everything you thought you knew.

437
00:25:32,200 --> 00:25:33,760
They can give you purpose.

438
00:25:33,760 --> 00:25:38,040
And that's the greatest precursor to happiness and longevity, having a purpose in your life.

439
00:25:38,040 --> 00:25:42,120
So maybe in the future, the education system will pivot to reflect that, you know.

440
00:25:42,120 --> 00:25:45,920
Making kids how to think more than what to think, how to be critical of the information

441
00:25:45,920 --> 00:25:49,520
and misinformation that they receive, and encouraging nerding out on things.

442
00:25:49,520 --> 00:25:53,840
It might be based more on connecting the dots and finding inspiration in things.

443
00:25:53,840 --> 00:25:54,840
There's a quote by E.O.

444
00:25:54,840 --> 00:25:58,520
Wilson that I think sums this all up pretty well when he said, quote, we are drowning

445
00:25:58,520 --> 00:26:00,920
in information while starving for wisdom.

446
00:26:00,920 --> 00:26:04,880
The world henceforth will be run by synthesizers, people who can put together the right information

447
00:26:04,880 --> 00:26:09,360
at the right time, think critically about it, and make important choices wisely.

448
00:26:09,360 --> 00:26:12,200
So maybe eventually education will shift to focus on that.

449
00:26:12,200 --> 00:26:13,800
So yeah, why bother learning things?

450
00:26:13,800 --> 00:26:18,320
I would say because you're planting seeds, they'll later sprout into passions and interests

451
00:26:18,320 --> 00:26:20,160
that you never knew you had.

452
00:26:20,160 --> 00:26:21,800
And that's really important stuff.

453
00:26:21,800 --> 00:26:25,120
One passion that I have is saving time, and that's why I only spend two minutes a day

454
00:26:25,120 --> 00:26:27,920
preparing my lunch and dinner from today's sponsor, Factor.

455
00:26:27,920 --> 00:26:31,680
Yeah, in the future they may have replicators to get your food faster, but today Factor

456
00:26:31,680 --> 00:26:33,080
is about the closest thing to it.

457
00:26:33,080 --> 00:26:36,080
Factor's a meal delivery service where you can tell them how many meals you want each

458
00:26:36,080 --> 00:26:40,080
week, what kind of meal plan you want to be on, like calorie smart, vegetarian, Keto,

459
00:26:40,080 --> 00:26:43,560
you name it, and they send you a box with pre-made restaurant quality meals that heat

460
00:26:43,560 --> 00:26:45,720
up in the microwave in only two minutes.

461
00:26:45,720 --> 00:26:49,120
It's like ordering from a meal delivery app except it takes less time, costs way less

462
00:26:49,120 --> 00:26:52,760
money, and the best part, I think anyway, they're actually healthy.

463
00:26:52,760 --> 00:26:56,280
Factor's chefs work side by side with dieticians to craft meals that are not just delicious

464
00:26:56,280 --> 00:26:59,720
but low calorie, and hit your target macros and all that stuff.

465
00:26:59,720 --> 00:27:03,320
They also use fresh ingredients from family farms and they're not frozen.

466
00:27:03,320 --> 00:27:06,880
Like trust me, I hate frozen dinners, they're always weird, textures and freezer burn and

467
00:27:06,880 --> 00:27:07,880
whatnot.

468
00:27:07,880 --> 00:27:08,880
Factor's got none of that.

469
00:27:08,880 --> 00:27:12,160
They've also got delicious breakfast and gourmet options if you're just too good to

470
00:27:12,160 --> 00:27:13,760
eat like the rest of us please.

471
00:27:13,760 --> 00:27:18,200
And don't get me started on the smoothies, they're just the bomb dot com dot org dot

472
00:27:18,200 --> 00:27:19,200
net.

473
00:27:19,200 --> 00:27:23,400
They fill me up, they get me through my day, I enjoy eating them, and it keeps my waistline

474
00:27:23,400 --> 00:27:24,400
in check.

475
00:27:24,400 --> 00:27:26,680
So yeah, that's not much more than I could ask for.

476
00:27:26,680 --> 00:27:30,640
I've probably heard me mention Factor before, and if you haven't tried it, I don't know,

477
00:27:30,640 --> 00:27:33,360
I'll give you the skeptical type, whatever, I respect that.

478
00:27:33,360 --> 00:27:36,400
But if you're curious, there's a special deal that might get you to pull the trigger.

479
00:27:36,400 --> 00:27:40,640
If you go to factor75.com or click on the link down below and enter the code JOKESCOT50

480
00:27:40,640 --> 00:27:46,000
at checkout, you can get 50% off your first box and 20% off each box for the next month.

481
00:27:46,000 --> 00:27:50,800
50% off, guys, that's like, that's like half off.

482
00:27:50,800 --> 00:27:52,360
Math.

483
00:27:52,360 --> 00:27:53,880
I really think you'll like it.

484
00:27:53,880 --> 00:27:57,760
They're a sponsor I actually pay for personally because I became a huge fan of it, and now

485
00:27:57,760 --> 00:27:59,500
you can try it for a huge discount.

486
00:27:59,500 --> 00:28:02,640
So one more time, because if you don't repeat it, they just delete it, click on the link

487
00:28:02,640 --> 00:28:07,140
down below in the description or just scan the QR code here and enter JOKESCOT50 at checkout.

488
00:28:07,140 --> 00:28:10,580
You'll get half off the first box and 20% off your next month of boxes.

489
00:28:10,580 --> 00:28:11,580
Give it a try.

490
00:28:11,580 --> 00:28:12,580
I think you'll like it.

491
00:28:12,580 --> 00:28:16,420
Anyway, I want to hear what you guys think about the whole humanoid robot thing and why

492
00:28:16,420 --> 00:28:18,040
we should learn things and whatnot.

493
00:28:18,040 --> 00:28:19,540
What do you enjoy learning?

494
00:28:19,540 --> 00:28:21,300
Talk about it down in the comments below.

495
00:28:21,300 --> 00:28:24,140
Please do like and share this video if this is the first time you've ever been here.

496
00:28:24,140 --> 00:28:26,780
I just am so glad that you found the channel.

497
00:28:26,780 --> 00:28:27,780
Thank you, algorithm.

498
00:28:28,060 --> 00:28:29,740
Maybe you can check out this video.

499
00:28:29,740 --> 00:28:33,060
They think that you might like it, and I think you might like it too, but I'm biased.

500
00:28:33,060 --> 00:28:34,060
It's me.

501
00:28:34,060 --> 00:28:35,580
But if you did like it, please do give it a thumbs up.

502
00:28:35,580 --> 00:28:37,620
It kind of helps to get it in front of more people.

503
00:28:37,620 --> 00:28:40,820
And if you haven't subscribed to this channel before, maybe check out a few other videos.

504
00:28:40,820 --> 00:28:45,060
And if you like them, give me a subscribe because I come back with videos every Monday.

505
00:28:45,060 --> 00:28:46,060
Anyway, that's it for today.

506
00:28:46,060 --> 00:28:49,620
You guys go out there, have an eye opening, rest of the week, stay safe, and I'll see

507
00:28:49,620 --> 00:28:50,620
you next time.

508
00:28:50,620 --> 00:28:51,620
Love you guys.

509
00:28:51,620 --> 00:28:52,120
Take care.

