start	end	text
1000	2760	All right, let's jump in.
2760	7320	Cool, introduction to the theory of computation.
7320	10080	I have been more excited about this talk
10080	13520	than any other talk that I've given in my entire life.
13520	14880	So forget about the company vision.
14880	17120	We're talking about the theory of computing.
19000	21980	I learned, I was introduced to some of this stuff
21980	26680	when I was an undergrad at UCLA about 10 years ago
26680	29480	and I didn't understand it.
29480	32020	And it was kind of presented as like,
33040	36520	here's the sort of tablets from the mountain
36520	40560	and learn and memorize them and this is why computing is.
40560	43440	And it took me 10 years and I finally understand it.
43440	45640	And it's so mind blowing that I wanted to talk
45640	46480	to you guys about it.
46480	48400	So this is what it's about.
48400	50800	The subtext of this is it's a tale of two towers
50800	52840	and this will make sense as we get into it.
52840	56980	But the preface is an intro to axiomatic thinking.
56980	59200	This is a kind of strange way of thinking
59240	62280	if you guys haven't been introduced to formal math.
63840	65480	It's not, it's strange.
65480	66460	Let's just jump in.
66460	71460	So two plus three times seven, this is I think 23.
74240	76680	Why do we know the answer to this?
76680	79760	And I asked this question and I encourage you guys
79760	83040	to take the perspective as if you were like an alien
83040	87000	who has never really seen symbols like this.
87000	88560	Or perhaps you didn't even understand
88600	90920	the concept of multiplication or addition.
90920	92840	How do you know what to do over here?
92840	94600	So let's just step through it.
94600	97400	The first thing that you would do is three times seven is 21
97400	99320	and two plus 21 is 23.
99320	100880	So what do we have over here?
100880	104280	We have these symbols called numbers.
104280	106800	We have these things called operators.
106800	108800	And then we have this interesting thing over here
108800	113800	where we can substitute an operator for its equivalent form.
114320	117400	So three times seven is the same thing as 21.
117400	120080	Here we've kind of made that substitution.
120080	122520	And then these operators also have precedents.
122520	125320	Like we knew to do three times seven first
125320	127600	because of all of the middle school math homework
127600	128760	that we did.
128760	131960	And then we have this final reduced form.
131960	136440	So in theory, each of these levels are equal to each other
136440	138960	because we've just kind of made substitutions along the way.
138960	141880	And what I'm trying to get at is we have these collections
141880	143840	of rules that we kind of take for granted
143840	145920	that we never really thought too much about.
145960	150960	That if you really examine like across representing
152000	156080	an operation or this little like two and one
156080	158720	like right next to each other represent 21
158720	161760	these are really kind of non-trivial concepts.
161760	163800	So let's dig into some of these.
163800	167760	The first idea is that three times seven
167760	170440	is actually seven plus seven plus seven.
170440	173400	And so this is to say that the rule of multiplication
173400	175560	is actually defined in terms of addition.
178120	179240	So this is interesting.
181280	184000	If some rules are defined in terms of each other
184000	187040	we can say that the rule is kind of redundant.
187040	190480	So in theory, like we don't really need multiplication
190480	192680	in math because every time we multiply
192680	194520	we can just add instead.
194520	196720	And therefore multiplication hasn't really given us
196720	200080	any more expressive power than addition already provides
200080	201200	for us, right?
201200	204520	So if some rules are redundant
204520	206960	then maybe we can ask the question of like
206960	209360	what rules are non-redundant?
210480	212360	Or really what is the minimum subset of rules
212360	214280	necessary to describe all of math?
215280	218440	And so we can call this minimum subset of rules axioms
218440	221360	and this comes from the word Greek axioma
221360	223200	that which is self-evident.
223200	226800	And then we can call all of the other derived rules theorems
228280	231000	which is like a proposition to be proved.
231000	233480	And so the question is what are the axioms for math?
233480	236080	The minimum non-redundant set of rules
236080	237880	to define all of math.
239680	242920	This is a question that nobody really thought about
244400	246400	or nobody had a really compelling answer to
246400	247560	until this guy came around.
247560	249640	His name is Giuseppe Piano.
249640	251760	He was an Italian mathematician.
251760	255760	And in 1889, so a little over 100 years ago
257080	258320	he put forth these axioms.
258320	259360	There's nine of them.
260200	261880	Only three of them are interesting.
261880	263960	So bear with me for a moment and keep in mind
263960	266480	like we're starting with a blank slate.
266480	268120	So there's no numbers yet
268120	270080	and we have to define what numbers are.
270080	275080	So first we define the first number, which is zero.
275080	277640	And so Piano says zero is a natural number.
279000	281440	The next thing he does is define what equality is
281440	282640	because we don't have that either, right?
282640	285520	So for a thing x, x is equal to x.
285520	287320	This is what equality is.
287320	288800	This one is not very interesting either.
288800	291080	If x equals y, y also equals x.
291080	294080	If x equals y and y equals z, then x equals z.
294080	295520	This is the transit property.
297440	300120	If b is a natural number and a equals b,
300120	302200	then a is also a natural number.
302200	304640	So this is sort of saying we have this collection
304640	305880	of things called natural numbers.
305880	308760	Right now we only have one of them, zero.
308760	312280	And if b is a natural number and a equals b,
312280	314240	then a is also a natural number.
314240	316040	So you have this like glue-like property
316040	317200	of natural numbers.
319480	320960	This is an interesting one.
320960	324240	We define this function s such that s of n
324240	325120	is a natural number.
325120	327240	s is like a successor function.
327240	328840	It's what it literally stands for.
328840	332240	And so now we have a way of going from zero
332240	335520	to producing the successor of zero with this function.
335520	338760	So s of zero is the successor of zero
338760	341120	and s of zero is also a natural number.
341120	342280	Is everyone following?
343320	345360	And I think the best way to go about this
345360	346960	is to just immediately stop me
346960	348080	if you guys have any questions
348200	350640	because this is gonna get more and more complex.
350640	352200	Sounds good?
352200	353040	Great.
354640	356480	m and n are equal to each other
356480	359400	if and only if their successors are equal to each other.
361240	365280	There's no n such that the successor of n equals zero.
365280	367800	So here we're not going into negative numbers.
367800	369800	We're just defining the natural numbers.
370920	372920	So there's no successor for zero.
372920	374960	Or zero is not the successor of anything.
374960	376840	That's what this is saying.
376840	378880	And then finally, the very last one,
378880	382760	if k is a set such that zero is in k
384120	388440	and if n is in k, it means that s and n is in k,
390160	392320	then k contains every natural number.
393620	396840	This is like the base case, zero is in k,
396840	398840	then the inductive case, if n is in k,
398840	400760	it means that s of n is in k
400760	403640	and then therefore k contains all the natural numbers.
403640	406440	So here they're saying there's no like loops.
406920	408720	It's just like this directed graph
408720	411120	that goes all the way out to infinity.
411120	411960	Sound good?
413080	413920	This is it.
415000	417160	This is all you need to define all of math.
418800	423800	So you'll notice we never define numbers besides zero.
423840	425840	We just define the concept of zero, right?
425840	428080	And yet we use these symbols like one and two
428080	430400	and three and four and so on.
430400	432000	And here I'm proposing the concept
432000	436340	that one is actually just syntactic sugar for s of zero.
436760	439560	Which is to say that these two forms are equal to each other
439560	440760	and if we were more precise,
440760	443120	we would actually prefer the form on the right,
443120	444960	but it would be kind of annoying.
444960	446880	And so we have this concept of one
446880	450840	and then two is the successor of one and so on.
451840	454400	Seven is actually s of s of s of zero.
454400	456240	I think you guys get the idea, right?
457680	460000	We haven't added any new information here, right?
460000	463000	And in theory, when we do our math,
464000	468760	we should prefer to reduce, if we were a piano,
468760	471640	we would prefer to reduce the form all the way down
471640	473560	into like this thing over here,
473560	474840	but that's just too confusing.
474840	477280	So we're okay with the syntactic sugar representation
477280	478760	on the left.
478760	479600	Sound good?
481560	485280	Okay, so syntactic sugar is sort of convenience rules
485280	488760	or symbols that we don't need to further reduce down
488760	491080	into the primitive forms.
491080	494480	So let's now define addition.
495480	497160	So addition can be thought of as an operation
497160	500520	that maps two natural numbers to another natural number,
500520	501360	right?
501360	503800	And the syntax is a plus b, so you guys know.
504760	507020	And we just need two rules.
507020	508800	The first is sort of the base case.
508800	511400	a plus zero equals a, sort of obvious.
512720	513880	This one you might have to pause
513880	515680	and think about it a little bit.
515680	518600	a plus the successor of b
518600	520520	is equal to the successor of a plus b.
521680	524880	So what we're doing over here is b
524880	527960	without this little s in the wrapping, right?
527960	529400	We're just kind of taking this s
529400	532480	and wrapping it around the whole thing, right?
532480	534880	And so the term on the right, b,
534880	537900	is actually one less than the term of successor of b.
537900	539840	So we're kind of going down.
539840	541480	This will make sense in just a moment.
541480	542560	I think let's go through an example.
542560	545360	So three plus two, the rules up there are on the right.
546520	549720	The first thing that we do is expand out our syntactic sugar.
549720	554200	So we have s of s of s of zero plus s of s of zero, right?
554200	556320	And now we need to apply one of our rules.
556320	558840	Obviously, we can't apply this rule
558840	559760	because it doesn't match.
559760	561640	So we have to apply this rule, right?
561640	565080	So a is in purple on the left or pink.
565080	569640	And then we have s of b, b is this purple thing over here,
569640	572780	equals s of a plus b, right?
572780	574560	So s of a plus b.
575500	577200	Do you guys see that substitution?
580080	582320	And then we do that again.
582320	583960	And then now we're in a form
583960	585560	where we can apply rule number one,
585560	590060	a plus zero equals just a by itself, right?
591000	593400	And that's five.
593400	594440	And now we can add.
597040	600020	All right, so basically this is compelling
600020	603400	because we didn't have the concept of addition
603400	605480	in terms of the axioms.
605480	607640	And we define the concept of addition
607640	610480	as recursive incrementing, essentially.
610480	613880	And now we have this property of addition,
613880	615960	which we can use to define some other things.
615960	618320	For example, we can define multiplication.
618320	620440	a times zero equals zero,
620440	624460	a times s of b equals a plus a times b.
624460	627720	And it can work out that obviously intuitively
627720	629520	that addition and multiplication
629520	632800	are kinds of intrinsically related to each other.
632800	634560	So we have the piano axioms,
634560	635680	so then we built addition
635680	638600	and then we built multiplication on top, right?
638600	641080	And it's this type of thinking
641080	644400	that I wanna really imprint in your minds.
644400	648080	And here I'm inventing this new concept called axiom towers.
648080	650120	And you can think of axiom towers
650120	652600	as having a foundation, which is the axioms themselves.
652600	654340	So in this case, the piano axioms.
654340	656560	And then on top of that, we built addition.
656560	658840	And then on top of that, we built multiplication.
658840	661920	And then maybe we can build more stuff on top.
661920	664120	And it turns out that the piano axioms
664120	667280	are sufficient to basically describe like most of math.
668800	671480	So from multiplication, you can kind of imagine
671480	674640	that you can build division and from division
674640	675920	or not from division necessarily,
675920	679160	but you can imagine also you can represent the integers
679160	682960	which are negative numbers from just the real numbers.
682960	684160	We won't get into the proofs,
684160	686240	but I'm sure you guys can kind of envision
686240	688200	how this might be the case.
688200	690280	And then once you have negative numbers,
690280	692960	you can imagine defining rational numbers,
692960	696920	which are just kind of, in the context of division,
696920	699880	a rational number is just a numerator and a denominator.
701760	703040	And then from rational numbers,
703040	704920	you can maybe get to exponentials,
704920	708520	which is just sort of repeated multiplication.
708520	709680	And then from exponentials,
709680	711440	you can get to irrational numbers,
711440	715440	like the exponent of a fraction gets you irrational numbers.
715440	718880	And then maybe you can build imaginary numbers
718880	720160	and so on and so forth.
721160	723680	And all of it is kind of stacked on top
723680	726240	of just these core axioms at the very bottom.
727360	728200	Sound good?
729520	730360	Cool.
731720	733720	This is gonna get interesting, I promise.
733720	735360	All right, so the first idea is
735360	737520	that the axioms are not divine, right?
737520	738720	There's nothing special about them.
738720	741960	In fact, when Piano first wrote his papers,
741960	745000	he started off with one as like the root.
745000	746360	He didn't start off with zero,
746360	748400	but then mathematicians later said like,
748440	750920	no, no, let's start with zero, it's better.
750920	752640	So you can imagine starting off with one and say,
752640	756000	you can imagine using like a predecessor function
756000	757840	instead of like a successor function.
759720	762280	But here I'm making a claim that some axiom towers
762280	764680	are better than other axiom towers.
764680	766720	Let's say more useful than other axiom towers.
766720	770160	Like for example, Roman numerals are just horribly inconvenient
770160	773680	at doing anything useful, like multiplication.
773680	776760	And yet everything that you can do in regular numbers,
776760	778800	you can also do in terms of Roman numerals.
778800	780640	And so Roman numerals aren't like,
780640	782040	they're just a different set of axioms
782040	784320	that are somehow slightly less useful.
786800	790220	All right, axiom towers don't have to correspond to reality.
791480	794960	So Euclid was a Greek philosopher
794960	797920	and he's sort of like the father of geometry.
797920	802480	And way before Piano, he put forth the axioms for geometry
802480	806580	and we call his flavor of geometry Euclidean geometry.
806580	809900	And one of the axioms that he kind of put forth
809900	812460	was that if you have two parallel lines,
812460	814900	let's say like this Y right here,
814900	818660	as well as like the Y axis, these are parallel to each other.
818660	820220	So if two lines are parallel,
820220	822220	then they stay parallel forever.
822220	823620	They never intersect.
823620	825100	That was one of his axioms.
826140	828660	But it turns out that you can have these things
828660	830660	called non-Euclidean geometries,
830660	833060	which essentially forego that axiom.
833060	835020	And the example is sort of like a globe
835020	839860	where you have these vertical longitude lines or meridians.
839860	842380	And the meridians are all parallel to each other.
843540	847020	But as you see at the poles, they all kind of intersect.
847020	851420	So a non-Euclidean geometry is one that foregoes
851420	854260	this notion of like parallel lines don't intersect.
854260	855620	And it turns out that there's all sorts
855620	858460	of really interesting non-Euclidean spaces
858460	861700	that you can imagine that don't at all correspond to reality.
861700	866060	And so there's this whole sets of branches of mathematics
866060	869540	that kind of conceptualize all sorts of different axioms
869540	871420	that are unique and interesting
871420	874260	and form this sort of logically coherent axiom tower
874260	876060	on the basis of those axioms.
876060	878980	And in many ways, those towers don't correspond
878980	880420	at all to reality.
880420	882860	And it's just sort of mathematicians having fun.
884060	885820	Interesting idea.
885820	888020	Okay, symbols.
888020	890220	So we talked a bunch about symbols.
890220	892260	It might be interesting to think of the symbols
892260	894980	as sort of separate from the rules.
894980	898820	But it turns out that if you really examine the situation,
898820	902180	the symbols don't really make sense without the rules.
902180	905780	And the rules can't really be expressed without symbols.
905780	907380	And so symbols here are making the claim
907380	910100	that they're kind of intrinsically related to each other,
910100	911780	really two sides of the same coin.
911780	915820	So this symbol, if you've done any sort of computing,
915820	920620	0x20 is the hexadecimal number 32, right?
922820	924300	But it's also like, sorry,
924300	929300	it's also the ASCII symbol for space, the space character.
929460	931780	So whether you're interpreting the symbol
931780	933700	in the context of hexadecimal math
933700	937740	or this axiom tower of ASCII or Unicode,
937740	940980	like the symbol has meaning only in the context
940980	943260	of a particular like frame of reference,
943260	944740	which is the axiom tower
944740	946740	that you're interpreting the symbol in.
946740	947700	And they're one and the same.
947700	950780	You can't separate out these ideas.
950780	952780	Another interesting example is DNA.
952780	955260	So there's this like funny concept
955260	957980	that DNA consists of these base pairs
957980	960020	and that all of the human genome
960020	963220	is sort of some ridiculously small amount of data.
963220	965980	And it's just like claim that,
965980	969060	therefore like life is not really that complex
969060	971820	because there's really not much information in DNA.
971820	973860	But if you really examine this question,
973860	977660	DNA by itself is completely meaningless and useless
977660	980260	without the corresponding like cellular machinery
980260	982220	that's able to actually unpack it and read it
982220	984560	and build actual life from it.
984560	987260	So DNA and the thing that reads the DNA,
987260	990180	they're intrinsically linked to each other.
990180	992700	The symbols and the rules are one and the same.
996220	997860	Here's an interesting philosophical claim.
997860	1001580	I think that math is actually discovered and not invented.
1001580	1003060	And the analogy that I have
1003060	1006220	is sort of a visualization of this axiom tower
1006220	1009820	and the top levels of this axiom tower are kind of obscured.
1009820	1012340	It's not exactly clear what they should be.
1013300	1014860	And what you're doing as a mathematician
1014860	1017460	is kind of like discovering consequences
1017460	1019660	of having initial axioms.
1021660	1022500	Sound good?
1022500	1023340	Questions?
1026620	1027980	All right.
1027980	1029740	So recap, axioms are self-evident.
1029740	1031540	They're taken as given.
1032540	1035180	Theorems are derived from redundant rules.
1035180	1036940	Axioms and theorems stack up together
1036940	1039660	to build these things called axiom towers.
1039660	1043060	And some symbols are actually just syntactic sugar.
1043060	1046620	Symbols and rules are intrinsically related.
1046620	1049200	And math is a discovery of the consequences
1049200	1050700	of foundational axioms.
1052620	1054020	And the axioms are arbitrary,
1054020	1056620	but some axiom towers are more useful than others.
1057740	1059380	All right.
1059380	1060220	You guys are comfortable.
1060220	1062100	We're gonna get to the exciting part.
1063260	1064100	Computation.
1067300	1069540	This is a graph of certain things
1069540	1071060	that we kind of take for granted today,
1071060	1074420	like running water and electric power over time.
1074420	1078020	And here I wanna point out that in the 1930s,
1079540	1082500	more people had electric power than running water.
1082500	1086300	And that number was around 65, 70%.
1086300	1089140	So you can imagine being in the 1930s, right?
1091020	1095340	And at this point, algorithms had already existed, right?
1095340	1097780	So way back in 2000 BC,
1097780	1100420	Egyptians figured out how to multiply two numbers together.
1100420	1102900	Babylonians figured out how to factorize things
1102900	1104700	and find square roots.
1104700	1106580	Euclid's algorithm, which is really cool,
1106580	1108700	the same Euclid as geometry.
1108700	1111920	He figured out how to get the greatest common factor
1111920	1113500	between two numbers.
1113500	1115820	And this algorithm is actually really beautiful
1115820	1116740	if you've never seen it.
1116740	1119500	It's called, I've actually never pronounced it,
1119500	1123180	but I've read it, it's sieve or aerotostinese.
1123180	1126280	It's a way to generate prime numbers.
1127760	1131180	And Al-Quarizmi figured out how to solve linear equations
1131180	1132360	and quadratic equations.
1132360	1133860	And it turns out that the word algorithm
1133860	1135340	actually comes from his name.
1136900	1139700	So we have like hundreds or thousands of years
1139700	1142980	of understanding of these things called algorithms,
1142980	1145660	which really were kind of informal at the time.
1145660	1148420	And you can kind of consider them as like sequences
1148460	1151980	of instructions to follow to do something, right?
1151980	1155580	But we didn't have like a precise axiomatic definition
1155580	1158820	of computing in the way that Piano defined
1158820	1162180	the axiomatic definition of mass, right?
1162180	1163340	In the 30s.
1163340	1168340	And so these guys pretty much at exactly the same time
1170760	1173220	did that independently.
1174520	1177740	Alan Turing created these things called Turing Machines.
1178420	1180460	Alonzo Church created these things,
1180460	1182260	this thing called Lambda Calculus.
1183220	1185020	And Kurt Godel created these things
1185020	1187460	called general recursive functions.
1187460	1189020	So we're gonna ignore the last one
1189020	1191180	and actually drill into these two,
1191180	1193620	Turing Machines and Lambda Calculus.
1193620	1196100	And the really, really cool thing is that
1196100	1200740	these axiomatic systems are both reasonable
1200740	1202620	and good definitions for computing,
1202620	1205100	but they look very, very different from each other.
1205100	1207540	So we're gonna talk about what they are.
1208420	1209620	So Turing Machines.
1211180	1212900	You can envision a Turing machine.
1212900	1215180	So Alan Turing was thinking about,
1215180	1218340	like you can kind of empathize with what he was doing.
1218340	1221460	He was looking at all these algorithms that we have
1221460	1225180	and he was trying to reduce like all of the algorithms down
1225180	1229180	into their most principle like reduced forms, right?
1229180	1232340	And then essentially use that as the base of an axiom tower
1232340	1235180	and build higher level constructs on top of that, right?
1235180	1236340	This was his goal.
1236380	1239860	And so he envisioned this concept called a Turing machine.
1239860	1243020	And a Turing machine starts off with this thing,
1243020	1245380	which is like an infinitely long tape.
1246820	1248660	And the tape is actually broken up
1248660	1250580	into these things called cells.
1250580	1253660	And in the cells, you can actually,
1254620	1257180	like each cell can either be marked or unmarked.
1257180	1258820	So here we have empty cells
1258820	1261300	and the X's correspond to marked cells, right?
1262140	1263140	And this is infinitely long.
1263140	1264820	It goes on in both directions.
1264820	1267540	And you have this thing called the head
1267540	1270760	and the head can do some stuff.
1270760	1272100	You can move it to the right.
1272100	1275060	In every case, it's always pointing to a particular cell.
1275060	1276500	You can move it to the left.
1278020	1281620	You can mark the box that the head is pointing at.
1281620	1283500	You can unmark the box.
1283500	1286300	And if the box is marked, you go to end.
1286300	1288180	We'll talk about go to end in just a moment.
1288180	1290780	And if the box is unmarked, also go to end.
1290780	1292740	These are all different instructions
1292740	1295540	that you can provide to this like turning machine.
1296980	1299340	And the execution of the turning machine,
1299340	1303580	essentially, you start off with a blank tape
1303580	1305140	and a list of instructions
1305140	1306980	that you want this turning machine to execute.
1306980	1308500	And the list of instructions are ordered
1308500	1309780	from zero through N.
1310800	1313940	And you execute the first instruction.
1313940	1315220	And if it's an ordinary instruction,
1315220	1317540	you execute the next instruction.
1317540	1320180	And if it's one of these like jump instructions
1320180	1323260	at the bottom, then if it tells you to jump,
1323260	1324820	you go to the Nth instruction.
1325940	1326780	Sound good?
1328460	1332500	And basically Alan Turing showed that this model
1332500	1334660	is sufficient for all of computation.
1335660	1337940	Anything that can be computed
1337940	1340300	can be computed with just these primitives.
1342100	1343100	That's all it takes.
1345500	1348940	Okay, so there is an actual virtual implementation
1348940	1351500	of a Turing machine called brain flap.
1351500	1352940	It's a technical term.
1352940	1356220	And basically there's a few instructions.
1356220	1358860	And it essentially you can imagine it
1358860	1360980	as like a virtual Turing machine.
1360980	1363060	And it has these instructions.
1363060	1364540	You can move the head to the right.
1364540	1366340	You can move the head to the left.
1366340	1368220	This is slightly different than a Turing machine
1368220	1372180	because the cells don't contain just like binary values
1372180	1373500	of marked and unmarked.
1373500	1375020	Instead, they contain numbers.
1375020	1377100	And you can increment numbers and decrement numbers.
1377100	1378700	And just integers, right?
1379740	1384740	And then these characters, so the open bracket,
1384740	1387020	like if the value at the head is zero,
1387020	1390940	jump forward to the matching like closed bracket.
1390940	1393420	And then the closed bracket is if the value at the head
1393420	1397380	is non-zero, jump back to the matching open bracket.
1397380	1402380	So here we've kind of defined our jumping behavior.
1403060	1406500	And then this language also provides like functionality
1406500	1408300	for input and output, which is something
1408300	1411060	that Turing didn't necessarily require.
1411060	1413620	But this makes the language a little bit more useful
1413620	1417140	because you can have it do stuff like print out output.
1418980	1421140	And every other character is ignored.
1421140	1423900	So anything that's not this magenta color
1423900	1426340	is basically ignored in this language.
1426340	1431340	So this is the implementation of adding two numbers together.
1432340	1437340	And if you squint, you can kind of see the recursive definition
1437820	1441140	that Piano kind of described earlier, right?
1441140	1444820	We'll actually go to a much clearer example.
1444820	1447580	So in the beginning, you can imagine the head
1447580	1450740	is pointing at cell C0 and we increment it twice.
1450740	1452980	So now C0 has a value two.
1452980	1455020	And then you move to the right to cell C1
1455020	1456540	and you increment it five times.
1456540	1458980	So C1 has a value five, right?
1459660	1463340	And then you start your loop.
1463340	1465940	The first thing that you do is you go back to C0
1465940	1467980	and you add one to it.
1467980	1470100	And then you go right to C1
1470100	1473500	and then you subtract one from it and you keep looping.
1473500	1475940	And your loop will basically end.
1477540	1478900	I can't think properly right now,
1478900	1483300	but once C1 essentially reaches zero,
1483300	1485540	then the loop will end and your program will terminate.
1485540	1487820	And now you have this ability to add two numbers,
1487820	1489620	C0 and C1, right?
1493460	1496460	This is an algorithm for computing
1496460	1499740	the Mandelbrot fractal set.
1499740	1501580	If you guys haven't heard of this,
1501580	1506580	it's just a really cool like fractal,
1506780	1507700	I won't get into fractals,
1507700	1510980	but basically this is a program, it prints out this, right?
1511940	1513860	So just using our turning machine,
1513860	1517420	we were able to now output like this fractal.
1523060	1523900	Cool.
1523900	1526060	So basically turning created an axiom tower for computing
1526060	1528540	and an algorithm is computable
1528540	1531260	if and only if it can be encoded as a turning machine.
1532260	1534140	And Turing showed this before the existence
1534140	1535700	of electrical computers.
1535700	1538300	And he also showed this when he was 24 years old.
1540980	1542620	If you guys have heard of the Turing Award,
1542620	1547340	it's basically like the Nobel Prize for computer science
1547340	1549020	and it's named after Alan Turing.
1550180	1554260	So some observations, you need an infinite tape
1554260	1555820	and you need a program,
1555820	1558100	like which is a sequence of instructions to follow
1559140	1561940	and you're constantly modifying the tape.
1561940	1563460	So you can think of the tape
1563460	1565780	as sort of like the state of your program
1565780	1568020	and every instruction that you execute
1568020	1571260	that modifies the tape is in theory
1571260	1575860	kind of modifying the way that the program
1575860	1577860	kind of unfolds itself, right?
1578860	1581380	And the behavior of the program
1581380	1583260	is changed with every single tape modification.
1583260	1585060	And so therefore reasoning about the behavior
1585060	1587820	of the program requires understanding the state of the tape
1587820	1590060	at every moment of modification.
1590060	1592740	And so you can imagine sort of debugging
1592740	1595580	or turning machine as perhaps similar
1595580	1598060	to debugging like an application
1598060	1600980	where you kind of think about how the application's
1600980	1602700	memory state changed over time
1602700	1607580	and all of a sudden your ideal understanding
1607580	1609540	of how it's supposed to change like differs
1609540	1611940	from the way it actually changed and there's your bug.
1614460	1616340	From here, Turing defined this concept
1616340	1617540	called Turing completeness
1617540	1621580	because you said that you can have other forms of computing.
1621580	1625980	For example, you can imagine like different instruction sets
1625980	1627940	for this Turing machine, right?
1628940	1632660	And he basically said that an axiom tower
1632660	1634860	that's sort of different than a Turing machine
1634860	1637660	is called Turing complete if and only if
1637660	1641060	it can be used to emulate a Turing machine.
1641060	1643500	And if it can emulate a Turing machine,
1643500	1645940	then it can compute anything that's computable.
1646940	1647860	That sounds good.
1647860	1650460	This concept of Turing completeness has now popped up.
1652060	1653940	So it turns out that there's some interesting things
1653940	1655060	that are Turing complete.
1656060	1659580	If you guys have heard of Conway's Game of Life,
1659580	1664580	it's this basically life simulator, emulator, I guess.
1665700	1666820	And it's very simple.
1666820	1668740	You have this grid of squares
1668740	1673740	and each square corresponds to a living thing
1673980	1675860	and it's either alive or dead.
1675860	1677900	And at every step in time,
1677900	1682340	there's some certain rules for allowing
1682340	1686460	like whether in the next time step,
1686460	1688180	the cell is alive or dead.
1688180	1690580	And so it essentially, oops,
1692900	1695380	let's see if we can get this to play.
1695380	1696300	I won't get into the rules
1696300	1698540	because they're not really relevant,
1698540	1701740	but every kind of step in this animation
1701740	1703780	is like the universe kind of unfolding
1703780	1706060	according to the rules of Conway's Game of Life.
1706060	1708540	And it turns out that the basic rules
1708540	1711900	are sufficient to represent a Turing machine.
1711900	1714140	And so Conway's Game of Life is Turing complete.
1714140	1717140	And so any algorithm that's computable
1717140	1719300	can be represented in Conway's Game of Life.
1722140	1724620	Magic the Gathering is also Turing complete.
1724620	1726780	So some researchers got together
1726780	1731660	and they looked at some specific cards
1731660	1733740	that allow you to place these like counters
1733740	1735500	and they use the counters as a way
1735500	1738940	to represent an actual Turing tape.
1738940	1742700	And so just following the rules of Magic the Gathering,
1742700	1744180	they're sufficiently complex enough
1744180	1747340	that you can compute all of the prime numbers in the game.
1750100	1752140	Microsoft PowerPoint is Turing complete.
1753180	1755260	Obviously it has like macros and stuff,
1755260	1759000	but here using only auto shape, hyperlink and transition.
1759000	1760820	And this paper is hilarious.
1760820	1762300	Given PowerPoint's versatility
1762300	1764340	and cross-platform compatibility,
1764340	1766540	some have asked whether any other applications
1766540	1767980	are necessary at all,
1767980	1769980	or if all computational tasks
1769980	1772220	can be accomplished through PowerPoint.
1772220	1775020	This research aims to definitively answer these questions
1775020	1776860	in the affirmative through the creation
1776860	1778300	of a PowerPoint Turing machine.
1781420	1783940	Okay, we've talked about Turing machines.
1783940	1785820	Now let's talk about Lambda calculus.
1785820	1788020	So to me, when I first learned about Turing machines,
1788020	1791100	I thought it was really kind of unintuitive
1791100	1793860	that such a simple thing can be used
1793860	1795660	to represent so much complexity.
1795660	1797060	But then after really thinking about it,
1797060	1800260	I realized that wait, the piano axioms are also very simple
1800260	1801860	and we can get all of math from it.
1801860	1803740	So it must follow that you can have
1803740	1806100	simple computing axioms and that's the case.
1806100	1809540	And I think for computer scientists and software engineers,
1809540	1812020	this is sort of what we're in the business of doing.
1812020	1815380	Like we take like simple building blocks
1815380	1817980	and we compose them together to build complexity.
1817980	1819700	And we have ways of reasoning about
1819700	1822940	how these things combine together to build complexity.
1822940	1826340	And we, it's sort of our job to make sure
1826340	1829060	that the complexity that we build
1829060	1832140	is actually founded and not buggy, let's say.
1833460	1836660	So it turns out that there's another flavor
1836660	1838280	or another axiom tower for computing
1838280	1839860	that was invented basically
1839860	1842940	or discovered exactly around the same time.
1842940	1846300	And it was discovered by Alonzo Church
1846300	1849780	and it's a thing called Lambda calculus.
1849780	1854660	And the way, basically in Alonzo Church's original paper,
1854660	1859540	he has a particular syntax for how he denotes Lambda calculus.
1859540	1862980	And JavaScript also has its own syntax
1862980	1864760	for declaring anonymous functions.
1864760	1866900	And because most of us are more familiar with JavaScript,
1866900	1869380	I'm gonna write both Alonzo Church's notation
1869380	1871020	as well as the JavaScript notation
1871020	1872680	to represent the same ideas.
1872680	1876180	So the first idea that he introduced was,
1876180	1877760	you can have variables.
1877760	1879460	So here X is a variable.
1879460	1881100	It's like a placeholder for a value.
1882100	1886220	Second idea is you can have functions.
1886220	1889100	And a function, this is on the left,
1889100	1892180	Alonzo Church's definition or notation.
1892180	1894940	And on the right, you have the ES6 equivalent syntax.
1894940	1897740	This is just a function that takes in one parameter Y
1897740	1900700	and has somebody M and M itself,
1900700	1902540	itself another Lambda expression.
1903460	1905100	So you have function definition.
1906060	1908540	And then finally you have function application.
1908540	1910140	So F of M, right?
1910140	1912380	So calling function F with a particular M.
1912380	1917380	So if in this case we call Y with some value,
1918220	1920460	like everything inside the body of M
1920460	1923460	gets replaced with whatever value we call it.
1923460	1927060	You guys should be really familiar with this concept.
1927060	1930780	And it turns out that this is all you need.
1930780	1933460	And with just these three concepts,
1933460	1935980	you can get something that's turned complete.
1936980	1940140	And so this is really, really unintuitive.
1940140	1943500	For me, it was way more unintuitive than the turning machine
1943500	1945120	which felt like this mechanical thing.
1945120	1947420	And therefore because you can operate it mechanically,
1947420	1949180	perhaps it can do some computation.
1949180	1952740	Here there's no notion of mechanics.
1952740	1955300	I mean, maybe you have function application.
1955300	1956460	And so we'll get into like,
1956460	1959400	how can this possibly do stuff?
1961980	1964140	So the first thing is you have in Lambda calculus
1964140	1965940	this concept called identity function.
1965940	1968160	This is the Lambda definition on the left
1968160	1970760	and the JavaScript definition on the right.
1970760	1973220	Obviously a very simple construct.
1973220	1977120	In JavaScript we can have optional braces
1977120	1978480	for the input parameter, right?
1978480	1980180	So these two forms are equivalent.
1980180	1981620	So I'm gonna drop the braces.
1983640	1985320	And the names are just placeholders, right?
1985320	1989260	So X and X and Z and Q that are,
1989260	1992260	all of these constructs mean the same thing, right?
1992260	1994760	So there's nothing special about X.
1996420	1997740	So in Lambda calculus,
1997740	1999540	you can call the identity function on itself.
1999540	2001740	And basically what this is doing is,
2001740	2003860	this is the function, right?
2003860	2006840	And this is the thing that you're calling it with, right?
2006840	2009020	This is a JavaScript equivalent, right?
2009020	2012060	So what you do is for,
2012060	2013980	this is the input variable X
2013980	2016580	and this is the body of the function M.
2016580	2018480	And inside the body,
2018480	2019540	whenever you call this function,
2019540	2022220	you replace every occurrence of X
2022220	2024140	with whatever you call it with.
2024140	2026820	So here every occurrence of X is replaced
2026820	2029260	with this Lambda function with the purple Xs
2029260	2030460	and you get this output.
2031620	2032700	Not very interesting.
2035860	2037720	Next you have this concept called curing.
2037720	2040060	So in modern programming languages,
2040060	2043700	most of them have this notion of having functions
2043700	2047000	that accept multiple input parameters.
2047000	2050140	But it turns out that you don't actually need this.
2050140	2054700	And the way Alonzo church got around this idea
2054700	2056380	is that instead of a function taking in
2056380	2058100	two input parameters like this,
2058100	2062100	we just have a function which returns another function
2062100	2064620	which takes in an input parameter.
2064620	2065460	That make sense?
2066940	2070300	So this construct and this construct are equivalent.
2071360	2073300	And Alonzo church said,
2073300	2075860	instead of kind of being verbose like this,
2076460	2080500	I'm gonna denote Lambda XY.M as equivalent to this.
2082260	2084220	So it's not equivalent to this thing on the right
2084220	2085220	because here in JavaScript,
2085220	2087660	we have a function that takes in two input parameters.
2087660	2090380	It's instead equivalent to this thing on the top right.
2090380	2092020	Sorry for that's a little confusing.
2092020	2093620	This concept is called curing.
2098140	2100700	Next we're gonna define some true and false symbols.
2100700	2104540	So you'll notice we didn't have any definition of numbers.
2105540	2108300	And we didn't really have any definition of types
2108300	2109500	or booleans or anything like that.
2109500	2112100	We just had variables, function definition
2112100	2113500	and function application.
2113500	2116780	And so now we're adding more semantics to our language
2117940	2121300	by defining these symbols called true and false.
2121300	2125100	So very similar to how the number seven as a symbol
2125100	2127540	is defined in terms of the successor function.
2127540	2132140	Here the symbol T is defined as this function over here.
2132300	2133420	And what this function is,
2133420	2135900	is it's function that takes in two parameters
2135900	2138940	and returns the first parameter.
2140300	2142180	And the false symbol is the function
2142180	2143660	that also takes in two parameters,
2143660	2146540	but it returns the second symbol or second parameter.
2147780	2148620	Is it following?
2150820	2151900	Cool.
2151900	2154340	So this is similar to our definition of seven.
2157060	2160620	And from here, now we can sort of build an end function
2160620	2161780	because we have boolean values.
2161780	2164180	Let's see how we can build and.
2164180	2166940	So this is actually the definition of and
2166940	2168980	and we can kind of try it together.
2168980	2171860	So and apply to true and false.
2171860	2175220	Like logically we know that this should be false.
2175220	2176500	So if we step through it,
2176500	2178980	the first thing that we do is we replace and
2178980	2181300	with this body over here.
2181300	2184460	So lambda x, y, x, y, f, T and f, right?
2184460	2187460	So here we have some lambda function
2187460	2190380	and here we're denoting that we want to apply
2190380	2192580	T to this function.
2192580	2195500	So what we do is the first parameter is x.
2195500	2197380	And so it's in this body.
2197380	2200380	Every single time this x appears,
2200380	2201940	we want to replace it with a T.
2204100	2206460	And so what we're left with is lambda y, T, y, f.
2206460	2208300	So this x has now become a T
2208300	2210540	and we have one more input parameter
2210540	2211860	that we need to resolve.
2212740	2215860	And then same sort of deal, every occurrence of y.
2216100	2217820	Now we're calling this function with f.
2217820	2221580	Every occurrence of y, we want to replace with an f.
2222980	2226100	And so we get T, f, f, okay?
2226100	2228700	And so as you guys remember,
2228700	2232060	true is actually defined as a function
2232060	2234060	that takes in two input parameters
2234060	2235420	and returns the first one.
2235420	2237620	So in this case, it takes in two input parameters
2237620	2240460	and then just returns the first one, which is f.
2240460	2243700	So now we have some way of doing the and function.
2244700	2248300	All right, let's try another example and T and T.
2248300	2251580	Similarly, we expand and out to this thing
2251580	2252980	and then we apply T to this thing,
2252980	2256540	replace all the x's with T's and we get T, y, f.
2256540	2258260	And then replace all the y's with T's
2258260	2260580	and then we get T, T, f.
2260580	2263260	And very similarly, T resolves
2263260	2266420	to picking the first parameter and then we get T.
2267380	2271980	So with just variables, functions and function application,
2271980	2274940	all of a sudden now we have like Boolean logic.
2274940	2276740	You can imagine how we can implement
2277820	2280060	or an XOR and so on, right?
2281060	2283260	So this is super unintuitive to me.
2283260	2288260	Like the concept of defining true and false
2288300	2291460	as these functions, like a true is actually a function
2291460	2292740	which takes in two parameters
2292740	2294060	and false is also a function
2294060	2296060	which takes in two other parameters.
2296060	2300180	And from there, building other functions like and,
2300180	2305180	we can now do logical, like all of Boolean logic, right?
2308100	2308940	Cool.
2310460	2313740	This is the hardest slide, so you'll have to deal with me.
2315340	2316660	I'm gonna talk about the y-combinator.
2316660	2320300	So it turns out that many of you guys know about yc
2320300	2324620	up in the Bay and it was essentially founded
2324620	2328580	by a computer scientist who got the name
2328580	2329420	from this principle.
2329420	2332540	It's actually a Lambda calculus construct
2332540	2333980	and it looks like this.
2333980	2335220	And we're gonna go really slow
2335220	2337660	and we'll go through it together, right?
2337660	2340820	The first thing to notice is that y is just a function
2340820	2343780	that takes in some input parameter y
2343780	2346060	and it returns something, right?
2346060	2347500	So nothing too crazy.
2348740	2351420	What we can do is apply y,
2351420	2354020	so let's say we have this function r, right?
2354020	2357640	We wanna apply y to r, right?
2357640	2359640	So in order to apply y to r,
2359640	2363760	what we need to do is every occurrence of this yellow y
2363760	2366520	inside this body, we need to replace
2366520	2370120	with our input parameter r, okay?
2370120	2373640	So all the yellow y's have now just become blue r's.
2375080	2376760	Sound good?
2376760	2379280	Okay, now if you look at this body,
2379280	2381000	we can actually reduce it further.
2381000	2383240	This first piece over here is a function
2384200	2388920	and the second piece over here is a value
2388920	2390760	that we can bind to this function
2390760	2394200	or we can call this function with this value on the right.
2394200	2395120	Okay?
2395120	2398080	So what we're gonna do is this is the value on the right
2398080	2401520	and if you look at this body, r, open print, x, x,
2401520	2405520	close print, every occurrence of this magenta x,
2405520	2409640	we're gonna replace with this body over here, okay?
2410520	2414640	So r, x, x, has now been replaced with r,
2414640	2418320	this body, this body, okay?
2418320	2420640	We haven't done anything like too crazy
2421640	2425200	and now if you'll notice like this line over here
2425200	2429200	and the thing inside the parentheses of this r,
2429200	2431040	they're actually the same thing.
2432040	2433360	You guys see it?
2433360	2435800	Here you have magenta values
2435800	2437640	and here you have purple values.
2438560	2442240	And the only difference is that this row
2442240	2445600	has like an enclosed r, do you guys see that?
2446960	2450600	Okay, so what we can do is take this yr
2450600	2453120	because these yr and this thing on the right
2453120	2455400	are equal to each other, so we can say
2456600	2461600	yr is r of yr and it's not readily clear
2463880	2465760	like why this is actually interesting
2466760	2471520	or useful, but if you kind of sit down
2471520	2473920	and think about it, what we've really done
2473920	2477920	is define yr in terms of itself.
2478840	2483080	So we've created like a recursive definition right here.
2483080	2486400	And so what's actually happened is that this y-combinator
2486400	2489400	is this thing over here allows you to take
2489400	2494400	like a non-recursive concept and create recursion from nothing.
2494400	2497080	So we just have variables, function definitions
2497080	2498760	and function application
2498760	2501480	and from those things we're able to create recursion.
2503040	2506160	So this is like a crazy construct to me.
2506160	2507800	Like we've created booleans
2507800	2509320	and therefore we've created conditionals
2509320	2513920	and from the same sort of raw axioms
2513920	2515280	we've created recursion.
2516360	2518880	Now, I encourage you guys to spend some time
2518880	2520800	if you're interested like really examining this
2520800	2523080	and coming to an understanding
2523080	2525080	of why it's actually interesting and profound.
2525080	2527480	But for now just take it on faith
2527480	2530120	that we're able to create recursion from nothing
2530120	2531880	and that's what the compelling aspect
2531880	2533280	of the y-combinator is.
2535680	2539280	Okay, the church Turing thesis.
2539280	2543040	So we have these two independent models of computation
2543040	2544720	the Turing machine and Lambda calculus
2544720	2546720	invented at exactly the same time.
2546720	2550160	And eventually these guys got together
2550160	2552560	and they realized that their models of computation
2552560	2554040	were actually equivalent.
2554040	2557040	So originally when church was defining Lambda calculus
2557040	2560160	he didn't define it in terms of turning machines
2560160	2562240	and Turing when he was defining turning machines
2562240	2564440	he didn't define it in terms of Lambda calculus
2564440	2566760	they were sort of separate axiom towers.
2566760	2568720	And so these guys got together and they said,
2568720	2573440	wait, we have two different models of computation
2573440	2576640	that we've proven independently to be sufficient
2576640	2579600	to be able to compute anything that's computable.
2579680	2583360	Is it true that our models are equivalent to each other?
2583360	2584320	Was the question.
2584320	2585640	And so they published this paper
2585640	2587440	called the church Turing thesis.
2587440	2589960	And it turns out that all Turing machines
2589960	2592240	can be rewritten as Lambda expressions
2592240	2594280	and all Lambda expressions can be rewritten
2594280	2595840	as Turing machines.
2595840	2597240	And we didn't really talk about
2597240	2598760	Godel's recursive functions
2598760	2602000	but it turns out that those are also equivalent.
2602000	2604280	And so the conclusion here is that Lambda calculus
2604280	2605160	is turning complete.
2607200	2609080	Without any notions of explicit recursion,
2609080	2610560	conditional state, et cetera.
2612200	2613840	So all we need is variables, functions
2613840	2615040	and function application.
2615040	2617760	So let's go into the peculiarities of Lambda calculus
2617760	2620480	because as software engineers we're sort of,
2622480	2625040	we can think of the Turing machine as this thing
2625040	2626520	that's very similar to a computer.
2626520	2628320	And I'm gonna get to that in a moment
2628320	2632440	but it's not really clear what this Lambda calculus thing is
2632440	2634200	and how to do computation with it.
2635100	2638600	So the first idea is that there's no notion of global state.
2638600	2639520	There's no tape.
2641400	2644400	All you have is the input arguments to your functions.
2644400	2647560	That's the only semblance of state that you have.
2647560	2650000	The second idea is all functions are pure.
2650000	2654400	So purity is sort of this mathematical concept
2654400	2656360	which is to say that it's a math function
2656360	2658480	in that for any given input,
2658480	2661740	it always, a function always returns the same output.
2661740	2664040	So if you have a function for example,
2664040	2667280	f of x equals x squared for an input three,
2667280	2668840	call it this function with three,
2668840	2671720	it's always gonna return nine no matter what.
2671720	2674640	So all functions in Lambda calculus are pure.
2676480	2677960	All values are immutable.
2677960	2682220	So you can't modify an input parameter.
2685340	2687200	But what you can do is generate a new value
2687200	2688280	from an existing one.
2689920	2691880	And there's also no loops.
2691880	2693640	So you can't really iterate on things
2693640	2695360	but the way we actually handle iteration
2695400	2699760	in Lambda calculus like structures is through recursion.
2701720	2704600	And then functions are your unit of composition.
2704600	2707300	And the way you compose functions
2707300	2710740	is sort of passing them as parameters to each other.
2710740	2714640	And because of the nature of Lambda calculus,
2714640	2717640	you don't have to reason about this global state.
2717640	2720360	So when you're combining two simple functions together,
2720360	2725280	all you need to know is what the consuming function does
2725320	2726440	with the input.
2726440	2728360	You don't have to reason about side effects
2728360	2729880	or any other properties.
2729880	2733480	So my claim over here is that because there's no global state,
2733480	2735520	when you compose two things together,
2735520	2737240	you can be sure that that composition
2737240	2738480	is like really, really solid
2738480	2740200	and it's not gonna result in bugs.
2742880	2744680	Okay, the two towers.
2745920	2748280	So we have turning machines on one hand
2748280	2750120	and Lambda calculus on the other hand.
2751080	2752360	And I've not so subtly drawn
2752360	2754320	this Lambda calculus tower is perfect.
2756280	2759120	But first we need to make a brief aside.
2760440	2762960	In the 1940s, so less than a decade
2762960	2765600	after turning machines came out,
2766680	2769520	people started to ask the question of,
2769520	2772100	okay, wait, this is great as a mathematical construct,
2772100	2776400	but ultimately like I need to compute real stuff for my job.
2776400	2779180	And so can we actually build a physical machine
2779180	2781040	that does computation?
2781040	2784080	And one of the core people involved in this work
2784080	2785800	was this guy named John Von Neumann.
2785800	2787800	He was a computer scientist.
2787800	2789440	And he proposed this model
2789440	2791720	for how we should build computing machines.
2791720	2795160	And what he started with was this concept of memory,
2795160	2798680	the RAM, and memory is basically just like a Turing tape
2798680	2801080	in that it's put up into these cells
2801080	2802820	and the cells can contain values.
2803960	2807000	And then he proposed this thing called a CPU,
2807000	2809360	which is composed of two components essentially,
2809360	2811840	a control unit and a logic unit.
2812120	2814180	And the CPU interacts with the memory
2814180	2817040	by reading stuff from it and writing stuff to it.
2818080	2822000	And Von Neumann proposed like a small set of instructions.
2822000	2825400	You can load a value X from the memory cell
2825400	2827320	at the location P.
2827320	2832160	You can store a value X into the memory cell location P.
2833200	2835400	You can add, subtract, and multiply.
2835400	2837720	And so here's sort of like a minor deviation
2837720	2839080	from Turing's model.
2839080	2841600	Turing had no notion of numbers or addition
2841600	2845000	or so on and Turing as a mathematician just basically said,
2845000	2847240	those are levels of the axiom tower
2847240	2849320	that you can obviously derive for yourself.
2849320	2852160	Like I don't need to embed those in my axioms.
2852160	2854120	But Von Neumann wanted to build something
2854120	2855600	that actually computed stuff.
2855600	2857520	So did the addition and so on.
2857520	2861680	And so rather than having to do addition manually
2861680	2863880	in the form of like incrementing
2863880	2866120	or marking and unmarking cells,
2866120	2869560	Von Neumann said, why don't we just build like circuitry
2869600	2871840	that does the addition of two numbers
2873000	2874400	and embed that into the CPU.
2874400	2876800	So if I wanna take a value from cell A
2876800	2878760	and a value from cell B and add them together
2878760	2880880	and store them into cell C,
2880880	2883920	instead of manually doing that computation
2883920	2885840	like incrementing and decrementing,
2885840	2887880	let's create circuitry that does the addition
2887880	2889960	so that it's faster, okay?
2891960	2893120	And that's what the logic unit
2893120	2895240	is essentially responsible for.
2895240	2898520	Then you also have these instructions called branches
2898560	2899480	or jumps.
2899480	2904480	So if the memory cell at location P contains zero,
2904720	2905760	go to N.
2905760	2907320	And if it doesn't contain zero,
2907320	2909200	go to N, it's another instruction.
2909200	2910520	And what I'm trying to get at
2910520	2913360	is that this looks very much like a Turing machine.
2913360	2916840	And Von Neumann proposed the actual physical circuitry
2916840	2919600	that could implement something like this.
2919600	2921080	And the first computers,
2922200	2923720	the very first general computer
2923720	2925560	was this thing called ENIAC.
2925560	2927440	And I think it popped up in the 40s,
2927440	2929800	like 47 or something like that.
2929800	2933520	And basically it was like a room almost this size
2933520	2937320	and there was no notion of like a program
2937320	2938360	that you give to it.
2938360	2940520	All it had was like circuitry
2940520	2943080	and you had these like engineers that would go up
2943080	2947240	and unplug and replug stuff to program the ENIAC
2947240	2948680	and then it would operate
2948680	2950720	and turn through the computation, right?
2950720	2952400	But ultimately it looked exactly like this.
2952400	2956240	It had some mechanism to store values in memory
2956240	2958840	and then it had some mechanism to read
2958840	2959880	those values from memory,
2959880	2962200	combine them together in useful mathematical ways
2962200	2963600	and store the results back.
2967360	2970960	Cool, so the Turing machine tower.
2970960	2972040	Start off with Turing machines
2972040	2973840	and then we have this Von Neumann model.
2973840	2975280	And the compelling aspect of this
2975280	2977680	is sort of like a deviation from Turing machines
2977680	2980840	in that it can be actually physically implemented.
2980840	2981960	And one limitation here
2981960	2983600	is that you don't have an infinite tape,
2983600	2986640	you just have a finite amount of memory, right?
2986640	2988760	But if you embrace that constraint,
2988760	2991440	now all of a sudden you can actually compute things
2991440	2995600	instead of just leaving it up to a mathematician, okay?
2998240	3003160	In 1949, people got tired of manually plugging
3003160	3004760	and replugging in wires
3004760	3008920	and they wanted like a human level way
3008920	3011640	to reason about what the instructions were.
3011640	3014520	So they gave each of these instructions names,
3014520	3017600	like small names like add, store, mold, divide,
3017600	3018680	things like that.
3018680	3023080	And programs were written like by hand first
3023080	3026240	in this sort of ways that humans could reason about.
3026240	3028480	And then later they were assembled down
3028480	3032600	to the actual programming of the computer,
3032600	3034480	like programming the instructions into the computer.
3034480	3037880	And so what we've done is created a higher level construct
3037920	3040000	called assembly that humans are able to reason about
3040000	3044440	more easily, which maps down to the Von Neumann model
3044440	3047040	in terms of actually programming the computer.
3047040	3048480	Does that make sense?
3048480	3051000	Ultimately, it's sort of like syntactic sugar
3051000	3055360	or addition in that assembly doesn't add any more constructs.
3055360	3057960	Like there, all of the rules of assembly are defined
3057960	3060480	in terms of the Von Neumann axioms.
3063360	3065400	And then we have Fortran.
3065400	3067760	So Fortran is even higher level
3067760	3071480	and here it adds constructs like if statements and loops.
3071480	3074360	And you can imagine in 1957,
3074360	3077960	there really wasn't anyone who had conceived
3077960	3081400	of like a general notion of loops
3081400	3082960	or even like conditionals, right?
3082960	3085920	All we had were these like branch instructions
3085920	3087760	and maybe it was sort of implicitly defined
3087760	3090040	that you could make looping constructs from it.
3090040	3091440	But then people were like, wait,
3091440	3094280	why don't we just embrace this high level notion
3094280	3099080	of a looping construct and embedded in our language?
3099080	3100280	But just like assembly,
3100280	3103480	looping doesn't actually give you any more expressivity.
3103480	3105120	Every single loop can be defined
3105120	3107720	in terms of the lower level constructs.
3109160	3110320	Then we have C.
3111440	3113320	C introduces these things called functions
3113320	3116880	and then we have the ability to create more complex
3116880	3119080	structures of data called structs.
3119080	3122000	And then we have the ability to dynamically allocate
3122000	3126360	in free memory as opposed to just using,
3126360	3129640	you can imagine kind of manually dealing with
3129640	3131560	all of the memory on your physical hardware
3131560	3134920	as opposed to some other memory manager, right?
3137040	3140240	And then finally, we have C++ in 1985,
3140240	3143280	introduces this concept called classes and objects.
3143280	3146320	I'm not sure if like these concepts on the right
3146320	3149040	were introduced solely by the languages.
3149040	3150800	I probably not, they probably came
3150800	3153560	in some other flavor,
3153560	3155680	but I think these languages over here
3155680	3159200	are the most significant in terms of widespread use.
3159200	3160560	So that's really what I'm trying to get at.
3160560	3163040	It's not as much attribution as it much
3163040	3165520	as it is sort of relatively speaking
3165520	3168400	when these ideas popped up into existence.
3168400	3171800	But just like pianos axiom towers,
3171800	3173460	where you have kind of irrational numbers
3173460	3176320	like up at the top, classes and objects
3176320	3179280	are really just defined in relation
3179280	3181960	to von Neumann instructions.
3181960	3183800	Everything boils down to those things.
3186400	3188800	So we can think of the von Neumann machine instructions
3188800	3192240	almost like the axioms for computing,
3192240	3193680	for modern computing really.
3194800	3198040	And the Turing, so this claim is my own.
3198040	3201800	Like after studying like the history of this,
3201800	3205580	I asked myself the question, like, why is this tower,
3205620	3208740	like these languages specifically so much more popular
3208740	3211060	compared to the corresponding languages
3211060	3213840	and ideas in the Lambda calculus tower.
3213840	3218220	And my belief is that the Turing machine axiom tower
3218220	3220620	is actually easily implementable in hardware
3220620	3223020	because it's sort of like a physical device.
3223020	3224580	And because you can implement it in hardware,
3224580	3227260	you can actually compute stuff with it
3227260	3229980	as opposed to it being relegated to pure math, right?
3231300	3233660	The final idea is that a compiler
3233660	3237020	is just something that takes like a higher level construct
3237020	3241500	and reduces it down to its axiomatic von Neumann definition.
3241500	3243180	That's all what a compiler is.
3245700	3246540	Sound good?
3249940	3252140	Okay, the Lambda calculus tower.
3252140	3253980	So this one looks very different
3253980	3256900	because the first thing that we have
3256900	3260420	is just variables, functions and function application.
3260420	3262140	And we've already kind of seen some constructs
3262140	3264100	that you can build on top of that.
3264100	3265860	But one of the most interesting ones
3265860	3268100	is this idea called Lisp,
3268100	3271660	which came about in the 1950s.
3271660	3274580	And it came about also by a mathematician,
3274580	3276460	his name was John McCarthy.
3276460	3279980	And what McCarthy did was,
3279980	3282780	if you look at piano's axioms,
3282780	3285740	the definitions of those axioms were sort of defined
3285740	3289300	in terms of English and mathematical notation, right?
3289300	3293500	McCarthy said, what if we could take Lambda calculus
3293500	3295500	or structures like that
3295500	3300500	and define those axioms in the language itself?
3301980	3304820	And he created this language called Lisp.
3304820	3309820	And basically the implementation of Lisp is in Lisp itself.
3310500	3312700	And because he was a mathematician,
3312700	3315940	he had no need to actually implement it on a real computer.
3315940	3318660	And so this was sort of the first example
3318820	3321020	of what we call like a meta-circular construct.
3321020	3323620	So the construct is defined in terms of itself
3323620	3325380	and it's fully self-containing.
3325380	3326860	And I think a rite of passage
3326860	3329100	for like every single computer scientist
3329100	3332180	is to build your own Lisp interpreter.
3332180	3336940	And so McCarthy kind of proposed this idea in 1958
3336940	3338940	and then his students went along
3338940	3341140	and actually implemented Lisp
3341140	3346140	as on top of one Neumann machine to actually compute stuff.
3346820	3349940	The next idea is System F.
3349940	3352780	So this popped up in 1972
3352780	3355740	and you can think of System F as like Lambda calculus
3355740	3358020	except it has support for types.
3358020	3361940	So the Lambda calculus that I kind of showed you before
3361940	3363020	didn't really have any types.
3363020	3364620	So it's kind of like JavaScript.
3364620	3368220	System F is kind of the typescript equivalent
3368220	3369500	of Lambda calculus.
3370820	3372900	But a lot more sophisticated for reasons
3372900	3374140	that I don't want to get into.
3374140	3377340	But really every single System F construct
3377340	3378780	can be boiled down
3378780	3381420	into its corresponding Lambda calculus construct.
3381420	3385060	So very similar to how Fortran didn't add any expressivity.
3385060	3387740	System F didn't really add any expressivity either.
3389020	3393180	Then on top of this, we have these languages called ML.
3393180	3396220	I think ML stands for meta language and OCaml
3396220	3400420	which is the sort of most widely used flavor of ML.
3401300	3403980	And it introduced like higher level constructs
3403980	3405180	like pattern matching.
3405180	3407580	You guys haven't spent much time in functional programming.
3407580	3410740	Like it's, this whole tower is super weird
3410740	3414660	because these constructs don't actually carry over cleanly
3414660	3418380	to the imperative tower.
3418380	3421060	Sorry, the Von Neumann tower, the Turing tower.
3422060	3426020	On top of this, we have this language called Haskell
3426020	3429180	which earliest roots of it popped up in 1985.
3430460	3433220	Basically the same year that C++ came about
3433220	3435300	was when Haskell came about
3435300	3438140	or the predecessor to Haskell came about.
3438140	3439820	And the cool thing about Haskell
3439820	3442860	is that it is a general purpose programming language
3442860	3445540	that can do IO and things like that.
3445540	3449140	But its constructs are still pure.
3449140	3452580	So it still has pure math functions like everywhere.
3452580	3454820	And today Haskell is sort of like the king
3454820	3457620	of statically typed functional programming languages.
3459500	3460820	But now we get into some stuff
3460820	3464700	which might be more relevant to your guys' experience.
3464700	3467260	In 2012, Elm kind of popped up
3467260	3470140	and Elm is very much a functional programming language
3470140	3472580	even though it compiles down into JavaScript.
3472580	3477140	And the Elm people essentially pioneered
3477140	3479420	the flux-redex pattern.
3479420	3482780	So this idea that actions result in
3483980	3485740	essentially the production of a new state
3485740	3488220	and that new state can be used to render a new view
3488220	3490420	and there's a sort of like one-way data flow.
3490460	3493300	This idea popped up in 2012.
3493300	3495660	But if you're kind of thinking about the world
3495660	3497660	in terms of the Lambda calculus tower,
3497660	3500260	this idea is actually not that novel.
3500260	3503420	It's sort of a very obvious outcome
3503420	3505820	of dealing with the constraints of the Lambda tower.
3507580	3510900	Then from here in 2013, we have React.
3510900	3513740	React kind of makes a claim that the view
3513740	3517540	needs to be a pure function of the state or your props.
3518580	3519780	But really it's kind of just the same.
3519780	3523300	So given a state, we can always render the same view
3523300	3525820	like deterministically as a pure function.
3525820	3528940	And at first, like if you're coming from jQuery,
3528940	3530860	adopting the React pattern was probably
3530860	3533300	like extremely frustrating.
3533300	3536980	And for those of you, if you kind of recall back
3536980	3538900	to your first experiences with React,
3539900	3542380	you kind of felt like there was these artificial constraints
3542380	3543460	being imposed upon you.
3543460	3545620	Like I just want to hide the modal.
3545620	3547180	Why can't I do that?
3547380	3548220	Right?
3549620	3551100	But then eventually as you start to build
3551100	3554260	larger and larger apps, you realize
3554260	3557020	that like this sort of one-way data flow constraint
3557020	3559700	makes it way more easy to reason about
3559700	3562500	what your view is going to look like given a state.
3562500	3565020	And the point I'm trying to make over here
3565020	3569260	is that one, these ideas are not new.
3570140	3573180	Like Lambda calculus kind of forces us
3573180	3576260	to embody this perspective that the output of a function
3576300	3580260	is a pure outcome of its inputs, right?
3580260	3583780	And it's just now in like 2012, 2013
3583780	3586500	that we're starting to re-embrace these ideas.
3586500	3589260	And I guess most of us believe
3589260	3592340	that I can't even imagine building a UI
3592340	3594460	in a non-reactive way.
3594460	3596060	It's sort of like taken as given.
3596060	3599700	And so I think that if more engineers spend time
3599700	3603180	kind of thinking about the history of this thing,
3603220	3605100	it becomes a lot more like,
3606220	3609860	you can understand more like why React looks the way it does
3609860	3611980	or why Elm looks the way it does.
3611980	3616180	And rather than trying to apply your like Turing machine
3616180	3619180	imperative programming mindset to functional programming,
3619180	3621420	you can kind of build your way up
3621420	3623220	starting with Lambda calculus going up.
3623220	3626700	And I think that path actually makes it much more easy
3626700	3628540	to reason about functional programming.
3628660	3633660	As a fun side effect or a fun anecdote,
3637940	3640180	the original compiler for React
3640180	3643860	when it was still like an experimental project at Facebook
3643860	3645140	was written in OCaml.
3648060	3650740	All right, so the final like concession that I'll make
3650740	3653740	is that Lambda calculus is really hard
3653740	3655900	to implement in hardware.
3655900	3659700	And whereas the Turing machine von Neumann model
3659700	3661980	is obviously very easy to implement in hardware.
3665420	3667860	Okay, final slide.
3667860	3669780	React is to jQuery as Lambda calculus
3669780	3670980	is to the Turing machine.
3672140	3675300	So in jQuery, you have this concept called
3675300	3677300	like the DOM is your state.
3677300	3681060	So all of the HTML elements that are there is your state.
3681060	3684380	You've probably written jQuery code that looks like this.
3684380	3687300	jQuery.model.show and shows the modal.
3687300	3689100	And basically what I'm trying to get at here
3689100	3692220	is that whether the modal is being shown
3693100	3697300	is encoded in the DOM itself.
3699260	3701580	Anything can make modifications to the DOM
3701580	3704380	and the DOM as a result ends up
3704380	3706660	in these weird unexpected states
3706660	3708980	because you didn't precisely reason
3708980	3710820	about state modifications,
3710820	3714080	kind of just wrote code like this over and over again
3714080	3716520	until it essentially resulted
3716520	3718880	in a Turing machine like construct
3718880	3723440	where it's difficult to reason about the tape.
3723440	3727520	And so in React, the state is explicitly defined, right?
3727520	3731100	It's an input to your render function kind of implicitly
3731100	3733400	and your view is a pure function of the state.
3734320	3737940	And you don't modify the state, you produce a new state.
3739240	3741960	And so React's constraints actually make it easier
3742000	3744880	to reason about the state and the DOM.
3744880	3748240	And by analogy, functional programming's constraints
3748240	3750600	make it easier to reason about programs.
3752640	3754320	And so if you're intrigued
3756440	3758640	and wanna learn more about the Lambda Tower,
3758640	3761740	I highly recommend taking this approach.
3761740	3763240	If you guys haven't done Advent of Code,
3763240	3765980	it's essentially this wonderful set of problems
3765980	3767960	that show up every December.
3767960	3769720	Solve those problems in Elm.
3770400	3772960	Elm is a really good intro to functional programming
3772960	3777960	because the compiler messages were meant for humans
3779720	3781880	and the whole ecosystem is built
3781880	3783920	so that it's easy to pick up and learn.
3784940	3787880	And if you're familiar with the React-Redux pattern,
3787880	3791840	that kind of came from Elm and it becomes like,
3791840	3794720	you can build some cool stuff right out of the get-go.
3796960	3798960	All right, that's all I got.
3798980	3800320	Thanks.
3800320	3801160	Thank you.
3801160	3802000	Thank you.
3802000	3802840	Thanks.
3806840	3807680	Yes.
3821880	3825440	It's tough for me to say it because I wasn't there.
3825440	3828960	But I think it's sort of like a chicken and egg situation,
3828960	3832000	because we didn't have machines that could compute stuff.
3832000	3834880	We didn't rely on those machines to compute the stuff.
3834880	3835840	But then all of a sudden,
3835840	3837800	the machine to compute stuff popped up
3837800	3840120	and I got to imagine the first sets of calculations
3840120	3843440	were just silly, solving linear equations.
3843440	3845400	But then eventually people started to realize
3845400	3847520	we could do compelling things with this.
3847520	3851120	I'm sure the military was one of the first users of it.
3851120	3853440	We can do ballistic missile trajectory calculations
3853440	3854480	very easily.
3854480	3857080	And then, obviously, computing is now universal.
3876920	3878440	Questions, questions.
3878440	3879280	Yeah.
3885480	3888480	Have you heard of ReasonML?
3888480	3892480	Okay, so ReasonML is a rewrite of the OCaml syntax
3892480	3897480	to make it more comfortable for JavaScript developers.
3897480	3900480	Because the OCaml syntax is kind of stodgy
3900480	3902480	if you first look at it.
3902480	3904480	Whereas ReasonML, if you're coming from JavaScript,
3904480	3905480	it looks very similar.
3905480	3910480	But ReasonML is not a new language.
3910480	3912480	All it does is transpile down to OCaml.
3913480	3916480	And so if you want to get started with OCaml,
3916480	3918480	I wouldn't necessarily recommend it.
3918480	3920480	I would recommend starting with Elm first.
3920480	3924480	But then from there, if you want to build programs
3924480	3927480	that can interoperate with JavaScript really easily,
3927480	3931480	I think ReasonML is the best way to go.
3931480	3932480	Yeah.
3932480	3933480	Yeah.
3949480	3952480	Yeah, there was a lot of researchers in the 1980s
3952480	3954480	that actually tried this.
3954480	3956480	I think they built some prototypes.
3956480	3960480	The problem is that you have these sort of positive feedback
3960480	3961480	loops in ecosystems.
3961480	3964480	And so the Turing model and the Von Neumann model
3964480	3971480	essentially caught on so well that even though in theory
3971480	3974480	the Lambda Tower might allow for more expressivity,
3974480	3978480	practically speaking, the best computers are in the Turing model.
3978480	3981480	And therefore, more attention kind of gravitates towards there.
3981480	3983480	People build more stuff for it.
3983480	3986480	And now, I don't know, 90% plus of all languages
3986480	3988480	are kind of all Turing-based.
3988480	3992480	So in the 80s, they did build functional programming computers.
3992480	3997480	But because most of investment into these technologies
3997480	4001480	comes as a function of industry, like businesses,
4001480	4003480	like needing to solve business problems,
4003480	4008480	then the positive feedback loop of the Turing Tower
4008480	4012480	kind of diminished the Lambda Tower.
4012480	4031480	Yeah, so I would probably boil it down to just the three
4031480	4032480	constructs, right?
4032480	4034480	You have variables.
4034480	4037480	You have functions and function applications.
4037480	4041480	So is there a way to represent a variable in some sort
4041480	4042480	of circuitry?
4042480	4045480	Is there a way to represent a function in circuitry
4045480	4047480	as well as function application?
4047480	4049480	I think the answer to all those is you probably
4049480	4050480	conceive of some way.
4050480	4055480	I don't know the details of how the actual Lambda computers
4055480	4058480	were built, but it might be an interesting thing to look into.
4058480	4060480	But they obviously fizzled out.
4060480	4063480	The nature of the Von Neumann model in Turing machines
4063480	4067480	is that it maps so cleanly to binary circuitry
4067480	4071480	and originally vacuum tubes, but now transistors
4071480	4074480	map so perfectly down to that model,
4074480	4076480	whereas the concept of a function doesn't
4076480	4092480	map to logic gates cleanly.
4092480	4094480	All right.
4094480	4096480	Well, I guess with that we'll wrap up.
4096480	4097480	Thank you everyone.
