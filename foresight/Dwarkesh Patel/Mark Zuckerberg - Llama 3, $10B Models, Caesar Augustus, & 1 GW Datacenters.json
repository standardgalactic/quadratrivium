{"text": " That's not even a question for me, whether we're going to go take a swing at building the next thing. I'm just incapable of not doing that. There's a bunch of times when we wanted to launch features and then Apple's just like, nope, you're not launching that. I was like, that sucks. Are we set up for that with AI, where you're going to get a handful of companies that run these closed models that are going to be in control of the APIs and therefore are going to be able to tell you what you can build? Then when you start getting into building a data center that's like 300 megawatts or 500 megawatts or a gigawatt, just no one has built a single gigawatt data center yet. But from wherever you sit, there's going to be some actor who you don't trust. If they're the ones who have like the super strong AI, I think that that's potentially a much bigger risk. Mark, welcome to the podcast. Hey, thanks for having me, big fan of your podcast. Oh, thank you. That's very nice of you to say. Okay, so let's start by talking about the releases that will go out when this interview goes out. Tell me about the models, tell me about meta AI, what's new, what's exciting about them? Yeah, sure. I think the main thing that most people in the world are going to see is the new version of meta AI. The most important thing about what we're doing is the upgrade to the model. We're rolling out Lama 3. We're doing it both as open source for the dev community, and it is now going to be powering meta AI. There's a lot that I'm sure we'll go into around Lama 3, but I think the bottom line on this is that with Lama 3, we now think that meta AI is the most intelligent AI assistant that people can use that's freely available. We're also integrating Google and Bing for real-time knowledge. We're going to make it a lot more prominent across our apps. So basically, at the top of WhatsApp and Instagram and Facebook and Messenger, you'll just be able to use the search box right there to ask it any question. And there's a bunch of new creation features that we added that I think are pretty cool that I think people enjoy. And I think animations is a good one. You can basically just take any image and animate it. But I think one that people are going to find pretty wild is it now generates high-quality images so quickly. I don't know if you've gotten a chance to play with this, that it actually generates it as you're typing and updates it in real-time. So you're typing your query and it's honing in on... And it's like, okay, here, show me a picture of a cow in a field with mountains in the background and just like eating macadamia nuts, drinking beer and it's updating the image in real-time. It's pretty wild. I think people are going to enjoy that. So yeah, that's what most people are going to see in the world. We're rolling that out, not everywhere, but we're starting in a handful of countries and we'll do more over the coming weeks and months. So that I think is going to be a pretty big deal. And I'm really excited to get that in people's hands. It's a big step forward for Met AI. But I think if you want to get under the hood a bit, the Llama 3 stuff is obviously the most technically interesting. So we're basically, for the first version, we're training three versions, an 8 billion and a 70 billion, which we're releasing today and a 405 billion dense model, which is still training, so we're not releasing that today. But the 8 and 70, I mean, I'm pretty excited about how they turned out. I mean, they're leading for their scale. You know, it's, I mean, we'll release a blog post with all the benchmarks so people can check it out themselves and obviously it's open source so people get a chance to play with it. We have a roadmap of new releases coming that are going to bring multi-modality, more multi-linguality, bigger context windows to those as well. And then, you know, hopefully sometime later in the year, we'll get to roll out the 405, which I think is, in training, it's still training, but for where it is right now in training, it is already at around 85 mmlu and just, we expect that it's going to have leading benchmarks on a bunch of the benchmarks. So, I'm pretty excited about all of that. I mean, the 70 billion is great too. I mean, we're releasing that today. It's around 82 mmlu and has leading scores on math and reasoning. So, I mean, it's, I think just getting this in people's hands is going to be pretty wild. Oh, interesting. Yeah, that's the first time hearing this benchmark. That's super impressive. Yeah, and the 8 billion is nearly as powerful as the biggest version of Llama 2 that we released. So, it's like the smallest Llama 3 is basically as powerful as the biggest Llama 2. Okay, so before we dig into these models, I actually want to go back in time. 2022 is, I'm assuming, when you started acquiring these H100s, or you can tell me when, where you're like, stock price is getting hammered. People are like, what's happening with all this capex? People aren't buying the metaverse. And presumably, you're spending that capex to get these H100s. How, back then, how did you know to get the H100s? How did you know we'll need the GPUs? I think it was because we were working on Reels. So, we got into this situation where we always want to have enough capacity to build something that we can't quite see that were on the horizon yet. And we got into this position with Reels, where we needed more GPUs to train the models. It was this big evolution for our services, where instead of just ranking content from people who you follow, or your friends, and whatever pages you follow, we made this big push to basically start recommending what we call unconnected content, to basically connect content from people or pages that you're not following. So, now, kind of the corpus of kind of content candidates that we could potentially show you expanded from, you know, on the order of thousands to on the order of hundreds of millions. So, completely different infrastructure. And we started working on doing that, and we were constrained on basically the infrastructure that we had to catch up to what TikTok was doing as quickly as we would have wanted to. So, I basically looked at that, and I was like, hey, we have to make sure that we're never in this situation again. So, let's order enough GPUs to do what we need to do on Reels and ranking content and feed, but let's also double that, right? Because, again, like our normal principle is, there's going to be something on the horizon that we can't see yet. Did you know it would be AI? Well, we thought it would be, we thought it was going to be something that I had to do with training large models, right? I mean, but at the time, I thought it was probably going to be more something that I had to do with content. But I don't know. I mean, it's almost just the pattern matching and running the company is there's always another thing, right? So, I'm not even sure I had, at that time, I was so deep in just, you know, trying to get, you know, the recommendations working for Reels and other content, because I mean, that's just such a big unlock for Instagram and Facebook to now being able to show people content that's interesting to them that they're from people that they're not even following. But, yeah, that ended up being a very good decision in retrospect. Yeah, yeah. Okay, and it came from being behind. So, then it wasn't like I was, you know, it wasn't like, oh, I was so far ahead. Actually, most of the times, I think, where we kind of make some decision that ends up seeming good is because we messed something up before and just didn't want to repeat the mistake. This is a total detour, but actually, I want to ask about this while we're on this. We'll get back to AI in a second. So, you didn't suffer one billion, but presumably there's some amount you would have sold for, right? Did you write down in your head, like, I think the actual valuation of Facebook at the time is this and they're not actually getting the valuation right? Like, the average $5 trillion, of course, you would have sold. So, like, how did you think about that choice? Yeah, I don't know. I mean, look, I think some of these things are just personal. I don't know at the time that I was sophisticated enough to do that analysis, but I had all these people around me who were making all these arguments for how, like, a billion dollars was, you know, it's like, here's the revenue that we need to make and here's how big we need to be and, like, it's clearly so many years in the future. Like, and it was, it was very far ahead of where we were at the time. And I don't know, I didn't really have the financial sophistication to really even engage with that kind of debate. I just, I think I sort of deep down believed in what we were doing. And I did some analysis. I was like, okay, well, what would I go do if I wasn't doing this? It's like, well, I really like building things and I like helping people communicate and I like understanding what's going on with people and the dynamics between people. So, I think if I sold this company, I'd just go build another company like this. And I kind of like the one I have. So, so, I mean, you know, what's, why, why, right? But I don't know. I think a lot of the biggest bets that people make are often just based on conviction and values. Not, it's actually usually very hard to do the analyses trying to connect the dots forward. Yeah. So, you've had Facebook AI research for a long time. Now it's become seemingly central to your company. At what point did making AGI or whatever, however you consider that mission, at what point is that like, this is a Cree priority of what Meta is doing? Yeah. I mean, it's been a big deal for a while. So, we started fair about 10 years ago. And the idea was that along the way to general intelligence or AI, like full AI, whatever you want to call it, there can be all these different innovations and that's going to just improve everything that we do. So, we didn't kind of conceive it as a product. It was more kind of a research group. And over the last 10 years, it has created a lot of different things that have basically improved all of our products and advanced the field and allowed other people in the field to create things that have improved our products too. So, I think that that's been great. But there's obviously a big change in the last few years when ChatGPT comes out, the diffusion models or an image creation come out. I mean, this is some pretty wild stuff that I think is pretty clearly going to affect how people interact with every app that's out there. At that point, we started a second group, the GenAI group, with the goal of basically bringing that stuff into our products, so building leading foundation models that would sort of power all these different products. And initially, when we started doing that, the theory at first was, hey, a lot of the stuff that we're doing is pretty social, right? So, it's helping people interact with creators, helping people interact with businesses. So, the businesses can sell things or do customer support or basic assistant functionality for, you know, whether it's for our apps or the smart glasses or VR or like all these different things. So, initially, it wasn't completely clear that you were going to need kind of full AGI to be able to support those use cases. But then through working on them, I think it's actually become clear that you do, right? In all these subtle ways. So, for example, for Llama 2, when we were working on it, we didn't prioritize coding. And the reason why we didn't prioritize coding is because people aren't going to ask MetaAI a lot of coding questions in WhatsApp. Now they will, right? Well, I don't know. I'm not sure that WhatsApp is like the UI that people are going to be doing a lot of coding questions. So, we're like, all right, look, in terms of the things that, you know, or Facebook or Instagram or, you know, those different services, maybe the website, right, meta.ai that we're launching, I think. But the thing that was sort of, I think, has been a somewhat surprising result over the last 18 months is that it turns out that coding is important for a lot of domains, not just coding, right? So, even if people aren't asking coding questions to the models, training the models on coding helps them just be more rigorous and answer the question and kind of help reason across a lot of different types of domains. Okay, so that's one example where it's like, all right, so for Llama 3, we're like really focused on training it with a lot of coding because it's like, all right, that's going to make it better on all these things, even if people aren't answering, aren't asking primarily coding questions. Reasoning, I think, is another example. It's like, okay, yeah, maybe you want to chat with a creator or, you know, you're a business and you're trying to interact with a customer. You know, that interaction is not just like, okay, the person sends you a message and you just reply, right? It's like a multi-step interaction where you're trying to think through how do I accomplish the person's goals and, you know, a lot of times when a customer comes, they don't necessarily know exactly what they're looking for or how to ask their questions. So, it's not really the job of the AI to just respond to the question. It's like, you need to kind of think about it more holistically. It really becomes a reasoning problem, right? So, if someone else, you know, solves reasoning or makes good advances on reasoning, and we're sitting here with a basic chat bot, then, like, our product is lame compared to what other people are building. So, it's like, it's okay. So, at the end of the day, we've got, we, you know, we basically realized we've got to solve general intelligence and we just kind of upped the ante and the investment to make sure that we could do that. So, the version of Lama that's going to solve all these use cases for users, is that the version that will be powerful enough to, like, replace a programmer you might have in this building? I mean, I just think that all this stuff is going to be progressive over time. But, in case, Lama 10. I mean, I think that there's a lot baked into that question. I'm not sure that we're replacing people as much as giving people tools to do more stuff. Is a programmer in this building 10x more productive after Lama 10? I would have more. But no, I mean, look, I'm not, I don't believe that there's, like, a single threshold of intelligence for humanity, because, I mean, people have different skills. And at some point, I think that AI is going to be, is probably going to surpass people at most of those things, depending on how powerful the models are. But I think it's progressive. And I don't think AGI is one thing. I think it's, you're basically adding different capabilities. So, multimodality is kind of a key one that we're focused on now, initially with photos and images and text, but eventually with videos. And then, because we're so focused on the metaverse, kind of 3D type stuff is important. One modality that I'm pretty focused on that I haven't seen as many other people in the industry focus on this is sort of like emotional understanding. Like, I mean, so much of the human brain is just dedicated to understanding people and kind of like understanding your expressions and emotions. And I think that that's like its own whole modality, right? That, I mean, you could say, okay, maybe it's just video or image, but it's like clearly a very specialized version of those too. So, there's all these different capabilities that I think you wanna basically train the models to focus on, as well as getting a lot better at reasoning, getting a lot better at memory, which I think is kind of its own whole thing. It's, I mean, I don't think we're gonna be, you know, primarily shoving context or kind of things into a query context window in the future to ask more complicated questions. I think that there'll be kind of different stores of memory or different custom models that are maybe more personalized to people. But I don't know, I think that these are all just different capabilities. And then obviously making them big and small, we care about both because, you know, we wanna, you know, if you're running something like meta AI, then we have the ability to, that's pretty server-based, but we also want it running on smart glasses. And, you know, there's not a lot of space in smart glasses. So, you wanna have something that's very efficient for that. What is the use case that if you're doing tens of billions of dollars worth of inference, or even eventually hundreds of billions of dollars worth of inference, using intelligence in an industrial scale, what is the use case? Is it simulations? Is it the AIs that will be in the metaverse? What will we be using the data centers for? I mean, our bet is that it's gonna, this is basically gonna change all of the products, right? So, I think that there's gonna be a kind of meta AI general assistant product. And I think that that will shift from something that feels more like a chat bot where it's like you just ask a question and it kind of formulates an answer to things where you're increasingly giving it more complicated tasks and that goes away and does them. So, that's gonna take a lot of inference. It's gonna take a lot of compute in other ways too. Then I think that there's a big part of what we're gonna do that is like interacting with other agents for other people. So, whether it's businesses or creators, I guess a big part of my theory on this is that there's not just gonna be like one singular AI that you interact with, because I think every business is gonna like want an AI that represents their interests. They're not gonna like wanna primarily interact with you through an AI that is gonna sell their competitors' customers. So, sorry, their competitors' products. So, yeah, so I think creators is gonna be a big one. I mean, there are about 200 million creators on our platforms. They all basically have the pattern where they want to engage their community, but they're limited by hours in the day and their community generally wants to engage them, but they don't have, they're limited by hours in the day. So, if you could create something where an AI could basically, that creator can basically own the AI and train it in the way that they want and can engage their community, I think that that's gonna be super powerful too. So, I think that there's gonna be a ton of engagement across all these things. But these are just the consumer use cases. I mean, I think when you think about stuff like, I mean, I run our foundation, Chan Zuckerberg Initiative with my wife, and we're doing a bunch of stuff on science, and there's obviously a lot of AI work that I think is gonna advance science and healthcare and all these things too. So, I think that it's like, this is, I think, an end up affecting basically every area of the products and the economy. The thing you mentioned about an AI that can just go out and do something for you that's multi-step, is that a bigger model? Is that you'll make, like, Lama 4 will still, there'll be a version that's still 70B, but will just be, you'll just train it on the right data, and that will be super powerful. Like, what does the progression look like? Is it scaling? Is it just same size, but different banks like you were talking about? I don't know that we know the answer to that. So, I think one thing that seems to be a pattern is that you have the Lama, sorry, the Lama model, and then you build some kind of other application-specific code around it, right? So, some of it is the fine-tuning for the use case, but some of it is just like logic for, okay, how, like, how Met AI should integrate, that should work with tools like Google or Bing to bring in real-time knowledge. I mean, that's not part of the base Lama model. That's like part of it. Okay, so, for Lama 2, we had some of that, and it was a little more kind of hand-engineered. And then part of our goal for Lama 3 was to bring more of that into the model itself. And, but for Lama 3, as we start getting into more of these agent-like behaviors, I think some of that is going to be more hand-engineered. And then I think our goal for Lama 4 will be to bring more of that into the model. So, I think at each point, like at each step along the way, you kind of have a sense of what's going to be possible on the horizon. You start messing with it and hacking around it. And then I think that that helps you hone your intuition for what you want to try to train into the next version of the model itself. Interesting. Which makes it more general, because obviously anything that you're hand-coding is, you know, you can unlock some use cases, but it's just inherently brittle and non-general. Hey, everybody. Real quick, I want to tell you about a tool that I wish more applications used. So, obviously, you've noticed every single company is trying to add an AI chatbot to their website. But as a user, I usually find them really annoying because they give these long, generic, often useless answers. Command Bar is a user assistant that you can just embed into your website or application. And it feels like you're talking to a friendly human support agent who is browsing with you and for you. And it's much more personalized than a regular chatbot. It can actually look up users' history and respond differently based on that. It can use APIs to perform actions. It can even practically nudge users to explore new features. One thing that I think is really cool is that instead of just outputting text, Command Bar can kind of just say, here, let me show you and start browsing alongside the user. Anyways, they're in a bunch of great products already. You can learn more about them at commandbar.com. Thanks to them for sponsoring this episode. And now back to Mark. What do you say into the model itself? You train it on the thing that you want in the model itself? What do you mean by into the model itself? Well, I think the example that I gave for Llama 2, where for Llama 2, the tool use was very specific. Whereas Llama 3 has the ability to have much better tool use. So we don't have to hand code all the stuff to have it use Google to go do a search. It just kind of can do that. And similarly for coding and kind of running code and a bunch of stuff like that. But I think once you kind of get that capability, then you get a peek of, okay, well, what can we start doing next? Okay, well, I don't necessarily want to wait until Llama 4 is around to start building those capabilities. So let's start hacking around it. And so you do a bunch of hand coding and that makes the products better for the interim. But then that also helps show the way of what we want to try to build into the next version of the model. What is the community fine tune of Llama 3 you're most excited by? Maybe not the one that will be most useful to you, but Jess, you'll just enjoy playing it with the most. They like fine tune it on antiquity and you'll just be like talking to Virgil or something. What are you excited about? I don't know. I mean, I think the nature of the stuff is it's like, you get surprised, right? So I think like any specific thing that I sort of thought would be valuable, we'd probably be building, right? So, but I think you'll get distilled versions. I think you'll get kind of smaller versions. I mean, one thing that I think is 8 billion, I don't think is quite small enough for a bunch of use cases, right? I think like over time, I'd love to get a billion parameter model or a 2 billion parameter model or even like a, I don't know, maybe like a 500 million parameter model and see what you can do with that. Because I mean, as they start getting, if with 8 billion parameters we're basically nearly as powerful as the largest llama 2 model, then with a billion parameters, you should be able to do something that's interesting, right? And faster, good for classification or a lot of kind of like basic things that people do before kind of understanding the intent of a user query and feeding it to the most powerful model to kind of hone what the prompt should be. So I don't know. I think that's one thing that maybe the community can help fill in. But I mean, we'll also, we're also thinking about getting around to distilling some of these ourselves, but right now the GPUs are pegged training the 405. So what, okay, so you have all these GPUs, I think 350,000 by the end of the year. That's the whole fleet. I mean, we built two, I think it's like 22, 24,000 clusters that are kind of the single clusters that we have for training the big models. I mean, obviously across a lot of the stuff that we do, a lot of our stuff goes towards training like reels models and like Facebook news feed and Instagram feed. And then inference is a huge thing for us because we serve a ton of people, right? So our ratio of inference compute required to training is probably much higher than most other companies that are doing this stuff just because of the sheer volume of the community that we're serving. Yeah, yeah. That was really interesting in the material they shared with me before that you trained it on more data than is computer optimal just for training because the inference is such a big deal for you guys and also for the community that it makes sense to just have this thing and have a trillion to tokens in there. Yeah, yeah. Although, and one of the interesting things about it that we saw even with the 70 billion is we thought it would get more saturated at, you know, it's like we trained on around 15 trillion tokens. Yeah. We, I guess our prediction going in was that it was going to ask some to it more, but even by the end it was still learning, right? It's like we probably could have fed it more tokens and it would have gotten somewhat better. But I mean, at some point, you know, you're running a company you need to do these meta reasoning questions of like, all right, how do I want to spend our GPUs on like training this 70 billion model further? Do we want to kind of get on with it so we can start testing hypotheses for Llama 4? So we kind of needed to make that call. And I think we got it, I think we got to a reasonable balance for this version of the 70 billion. There will be others in the future where, you know, 70 billion multimodal one that'll come over the next period. But yeah, I mean, that was fascinating that you could just, that it's the architectures at this point can just take so much data. Yeah, that's really interesting. So what is this imply by future models? You mentioned that the Llama 3 8B is better than the Llama 270B? No, no, no, it's nearly as good. Okay. I don't overstep. But does that mean like the Llama 4? The same order of magnitude. Does that mean like the Llama 4? 70B will be as good as the Llama 3? 4 or 5B? I mean, this is one of the great questions, right? That I think no one knows is basically, you know, it's one of the trickiest things in the world to plan around is when you have an exponential curve, how long does it keep going for? And I think it's likely enough that it will keep going, that it is worth investing the tens or, you know, 100 billion plus in building the infrastructure to assume that if that kind of keeps going, you're going to get some really amazing things that are just going to make amazing products. But I don't think anyone in the industry can really tell you that it will continue scaling at that rate for sure, right? In general, in history, you hit bottlenecks at certain points. And now there's so much energy on this that maybe those bottlenecks get knocked over pretty quickly. But I don't know. I think that's an interesting question. What does the world look like where there aren't these bottlenecks? Suppose like progress just continues at this pace, which seems like plausible, like zooming out. Well, they're going to be different bottlenecks. Right. So if not training, then like, oh, yeah, go ahead. Well, I think at some point, over the last few years, I think there was this issue of GPU production. Yeah. Right. So even companies that had the models, sorry, that had the money to pay for the GPUs, couldn't necessarily get as many as they wanted because there were all these supply constraints. Now I think that's sort of getting less. So now I think you're seeing a bunch of companies think about, wow, we should just like really invest a lot of money in building out these things. And I think that that will go for some period of time. I think there's a, there is a capital question of like, okay, at what point does it stop being worth it to put the capital in? But I actually think before we hit that, you're going to run into energy constraints. Right. Because I just, I mean, I don't think anyone's built a gigawatt single training cluster yet. Right. And then you run into these things that just end up being slower in the world. Like getting energy permitted is like a very heavily regulated government function. Right. So you're going from on the one hand software, which is somewhat regulated. I'd argue that it is more regulated than I think a lot of people in the tech community feel, although it's obviously different. If you're starting a small company, maybe you feel that less if you're a big company, you know, we just interact with people, but different governments and regulators are, you know, we have kind of lots of rules that we need to kind of follow and make sure we do a good job with around the world. But I think that there's no doubt that like energy, and if you're talking about building large new power plants or large buildouts and then building transmission lines that cross other private or public land, that is just a heavily regulated thing. So you're talking about many years of lead time. So if we wanted to stand up to some like massive facility to power that, I think that that is, that's a very long-term project, right? And so I don't know, I think that that's, I think people will do it, but I don't think that this is like something that can be quite as magical as just like, okay, you get a level of AI and you get a bunch of capital and you put it in and then like all of a sudden the models are just going to kind of like interest, like I think you do hit different bottlenecks along the way. Yeah. Is there something, a project, maybe I realized maybe not, that even a company like Meta doesn't have the resources for, like if your R&D budget or CapEx budget was 10x what it is now, then you could pursue it, like it's in the back of your mind, but Meta today, maybe you could like, even you can't even issue a stock or bond for it, it's like just 10x bigger than your budget. Well, I think energy is one piece, right? I think we would probably build out bigger clusters than we currently can if we could get the energy to do it. So I think that's fundamentally money bottlenecked in the limit, like if you had a trillion dollars. I think it's time, right? Well, if you look at it in terms of, but it depends on how far the exponential curves go, right? Like I think a number of companies are working on, you know, right now I think a lot of data centers are on the order of 50 megawatts or 100 megawatts, or like a big one might be 150 megawatts. Okay, so you take a whole data center and you fill it up with just all the stuff that you need to do for training and you build the biggest cluster you can. I think that's kind of, I think a bunch of companies are running at stuff like that. But then when you start getting into building a data center that's like 300 megawatts or 500 megawatts or a gigawatt, I mean, just no one has built a single gigawatt data center yet. So I think it will happen, right? I mean, this is only a matter of time, but it's not going to be like next year, right? I think that some of these things will take, I don't know, some number of years to build out. And then the question is, okay, well, if you, I mean, just to, I guess, put this in perspective, I think a gigawatt, it's like around the size of like a meaningful nuclear power plant only going towards training a model. Didn't Amazon do this? There's like, they have a 950 megawatt thing. Yeah, I'm not exactly sure what you did. What they did, you'd have to ask them. But it doesn't have to be in the same place, right? If distributed training works, it can be distributed. That I think is a big question. Yeah. Right, is basically how that's going to work. And I do think in the future, it seems quite possible that more of what we call training for these big models is actually more along the lines of inference generating synthetic data to then go feed into the model. So I don't know what that ratio is going to be, but I consider the generation of synthetic data to be more inference than training today. But obviously, if you're doing it in order to train a model, it's part of the broader training process. So I don't know, that's an open question, is to kind of where, what the balance of that and how that plays out. If that's the case, would that potentially also be the case with Lama 3? And maybe like Lama 4 onwards, where you put this out and if somebody has a ton of compute, then using the models that you've put out, you can just keep making these things arbitrarily smarter. Some Kuwait or UAE or some random country has a ton of compute, and they can just actually just use Lama 4 to just make something much smarter. I do think that there are going to be dynamics like that, but I also think that there is a fundamental limitation on kind of the network architecture, the kind of model architecture. So I think like a 70 billion model that kind of we trained with the Lama 3 architecture can get better, it can keep going. Like I was saying, we felt like if we kept on feeding it more data or rotated the high value tokens through again, then it would continue getting better. But, and we've seen a bunch of other people around the world, you know, different companies basically take the Lama 2 70 billion base, like take that model architecture and then build a new model. It's still the case that when you make a generational improvement to the kind of Lama 3 70 billion or the Lama 3 405, there's nothing open source anything like that today, right? Like it's not, I think that that's like, it's a big step function and what people are going to be able to build on top of that I don't think can go infinitely from there. I think it can, there can be some optimization in that until you get to the next step function. Yeah. Okay. So let's zoom out a little bit from specific models and even the many years lead times you would need to get energy approvals and so on. Like big picture, these next couple of decades, what's happening with AI? Does it feel like another technology, like metaverse or social, or does it feel like a fundamentally different thing in the course of human history? I think it's going to be pretty fundamental. I think it's going to be more like the creation of computing in the first place, right? So you'll get all these new apps in the same way that when you got the web or you got mobile phones, you got like people basically rethought all these experiences and a lot of things that weren't possible before now became possible. Something that will happen, but I think it's a much lower level innovation. It's going to be more like going from people didn't have computers to people have computers, is my sense. But it's also, it's, I don't know, it's very hard to reason about exactly how this goes. I tend to think that, you know, in like the cosmic scale, obviously, it'll happen quickly over a couple of decades or something. But I do think that there is some set of people who are afraid of like, you know, it really just kind of spins and goes from being like somewhat intelligent to extremely intelligent overnight. And I just think that there's all these physical constraints that make that, so that that's unlikely to happen. I just don't, I don't really see that playing out. So I think you'll have, I think we'll have time to kind of acclimate a bit, but it will really change. The way that we work and give people all these creative tools to do different things that they, yeah. I think it's going to be, it's going to really enable people to do the things that they want a lot more, as is my view. Okay, so maybe not overnight, but is it your view that like on a cosmic scale, if you think like humans evolved and then like AI happened and then they like went out through the galaxy or maybe it takes many decades, maybe it takes a century, but like, you know, is that like the grand scheme of what's happening right now in history? Sorry, in what sense? I mean, in the sense that there were other technologies like computers and even like fire, but like the AI happening is as significant as like humans evolving in the first place. I think that's tricky. I think people like to, you know, the history of humanity, I think has been people basically, you know, thinking that certain things of humanity are like really unique in different ways. And then coming to grips with the fact that that's not true, but humanity is actually still super special, right? So it's like we thought that the earth was the center of the universe. And it's like, it's not, but like humans are still pretty awesome, right? And pretty unique. I think that another bias that people tend to have is thinking that intelligence is somehow kind of fundamentally connected to life. And it's not actually clear that it is, right? I think like people think that, I mean, I don't know that we have a clear enough definition of consciousness or life to kind of fully interrogate this, but there's all this science fiction about, okay, you create intelligence and now it like starts taking on all these human like behaviors and things like that. But I actually think that the current incarnation of all this stuff at least kind of feels like it's going in a direction where intelligence can be pretty separated from consciousness and agency and things like that, that I think just makes it a super valuable tool. So I don't know. I mean, obviously it's very difficult to predict what direction the stuff goes in over time, which is why I don't think anyone should be dogmatic about how they plan to develop it or what they plan to do. I think you want to kind of look at like each release. You know, it's like, we're obviously very pro open source, but I haven't committed that we're going to like release every single thing that we do. But it's basically, I'm just generally very inclined to thinking that open sourcing it is going to be good for the community and also good for us, right? Because we'll benefit from the innovations. But if at some point like there's some qualitative change in what the thing is capable of, and we feel like it's just not responsible to open source it, then we won't, but so I don't know. It's all very difficult to predict. Yeah. What is a kind of qualitative change, like a specific thing? You're training lamify, lamaphore, and you've seen this, and like, you know what? I'm not sure about open sourcing it. I think that that, it's a little hard to answer that in the abstract because there are negative behaviors that any product can exhibit that as long as you can mitigate it, it's like, it's okay, right? So, I mean, there's bad things about social media that we work to mitigate, right? There's bad things about llama two that we spend a lot of time trying to make sure that it's not like, you know, helping people commit violent acts or things like that, right? I mean, that doesn't mean that it's like a kind of autonomous or intelligent agent. It just means that it's learned a lot about the world, and it can answer a set of questions that we think it would be unhelpful for it to answer. So, I don't know. I think the question isn't really what behaviors would it show. It's what things would we not be able to mitigate after it shows that, and I don't know. I think that there's so many ways in which something can be good or bad that it's hard to actually enumerate them all up front. If you even look at what we've had to deal with in social media and the different types of harms, we've basically gotten to. It's like, there's like 18 or 19 categories of harmful things that people do, and we've basically built AI systems to try to go identify what those things are that people are doing and try to make sure that that doesn't happen on our network as much as possible. So, yeah, I think you can... Over time, I think you'll be able to break down this into more of a taxonomy, too, and I think this is a thing that we spend time researching, too, because we want to make sure that we understand that. So, one of the things I asked Mark is what industrial-scale use of LLMs would look like. You see this in previous technological revolutions where, at first, they're thinking in a very small-scale way about what's enabled, and I think that's what chatbots might be for LLMs. And I think the large-scale use case might look something like what V7 Go is. And, by the way, it's made by V7 Labs who's sponsoring this episode. So, it's like a spreadsheet. You put in raw information, like documents, images, whatever, and they become rows, and the columns are populated by an LLM of your choice. And, in fact, I used it to prepare for Mark, so I fed in a bunch of blog posts and papers from Metas AI Research, and, as you can see, if you're on YouTube, it summarizes and extracts exactly the information I want as columns. And, obviously, mine is a small use case, but you can imagine, for example, a company like FedEx has to process half a million documents a day. Obviously, a chatbot can't do that. A spreadsheet can, because this is just like a fire hose of intelligence in there, right? Anyways, you can learn more about them at v7labs.com slash go, or the link in the description. Back to Mark. Yeah. Like, it seems to me it would be a good idea. I would be disappointed in a future where AI systems aren't broadly deployed and everybody doesn't have access to them. At the same time, I want to better understand the mitigations, because if the mitigation is the fine-tuning, well, the whole thing about open weights is that you can then remove the fine-tuning, which is often superficial on top of these capabilities. Like, if it's like talking on Slack with a biology researcher, and again, I think models are very far from this. Right now, they're like Google search, but I can show them my Petri disk and they can next lane. Like, here's why your smallpox sample didn't grow. Here's what to change. How do you mitigate that? Because somebody can just fine-tune that in there, right? Yeah. I mean, that's true. I think a lot of people will basically use the off-the-shelf model, and some people who have basically bad faith are going to try to strip out all the bad stuff, so I do think that that's an issue. The flip side of this is that, and this is one of the reasons why I'm kind of philosophically so pro-open source, is I do think that a concentration of AI in the future has the potential to be as dangerous as kind of it being widespread. So, I think a lot of people, they think about the questions of, okay, well, if we can do this stuff, is it bad for it to be out wild? Like, just kind of widely available. I think another version of this is like, okay, well, it's probably also pretty bad for one institution to have an AI that is way more powerful than everyone else's AI, right? So, if you look at, like, I guess, one security analogy that I think of is, you know, it doesn't take AI to basically, okay, there's security holes in so many different things, and if you could travel back in time a year or two years, right, it's like, that's not AI, it's like you just, let's say you just have, like, one year or two years more knowledge of the security holes, it's pretty much hack into, like, any system, right? So, it's not that far-fetched to believe that a very intelligent AI would probably be able to identify some holes and basically be, like, a human who could potentially go back in time a year or two and compromise all these systems. Okay, so how have we dealt with that as a society? Well, one big part is open-source software that makes it so that when improvements are made to the software, it doesn't just kind of get stuck in one company's products, but it can kind of be broadly deployed to a lot of different systems, whether it's banks or hospitals or government stuff, and, like, just everyone can kind of, like, as the software gets hardened, which happens because more people can see it and more people can bang on it, and there are standards on how this stuff works, the world can kind of get upgraded together pretty quickly. And I kind of think that a world where AI is very widely deployed in a way where it's gotten hardened progressively over time is one where all the different systems will be in check in a way that seems like it is fundamentally more healthy to me than one where this is more concentrated. So there are risks on all sides, but I think that that's one risk that I think people, I don't hear them talking about quite as much. I think, like, there's sort of the risk of, like, okay, well, what if the AI system does something bad? I am more, like, you know, I stay up at night more worrying, well, what if, like, some actor that, whatever. It's like, from wherever you sit, there's going to be some actor who you don't trust if they're the ones who have, like, the super strong AI, whether it's some, like, other government that is sort of, like, an opponent of our country or some company that you don't trust or whatever it is. Like, I think that that's potentially a much bigger risk as in they could, like, overthrow our government because they have a weapon that, like, nobody else has. Cause a lot of mayhem. Right, it's, I think it's, like, I mean, I think the intuition is that this stuff ends up being pretty kind of important and valuable for both kind of economic and kind of security and other things. And I don't know, I just think, yeah, if, like, if someone who you don't trust or is an adversary of you gets something that is more powerful, then I think that that could be an issue. And I think probably the best way to mitigate that is to have good open source AI that basically becomes the standard and in a lot of ways kind of can become the leader. And in that way, it just ensures that it's a much more kind of even and balanced playing field. Yeah, that seems plausible to me. And if that works out, that would be the future I prefer. I guess I want to understand, like, mechanistically how if somebody was going to cause mayhem with AI systems, how the fact that there are other open source systems in the world prevents that? Like the specific example of, like, somebody coming with a bio weapon, is it just that we'll do a bunch of, like, R&D in the rest of the world to, like, figure out vaccines really fast? Like, what's happening? Would you take, like, the computer, the security one that I was talking about? I think someone with a weaker AI trying to hack into a system that is, like, protected by a stronger AI will succeed less. Right, so I think that that's, I mean, that's, like, in terms of software security. How do you know everything in the world is like that? Like, what if bio weapons aren't like that? No, I mean, I don't know that everything in the world is like that. I think that that's, I guess, one of the, bio weapons are one of the areas where I think the people who are most worried about this stuff are focused. And I think that that's, I think that makes a lot of sense to think about that. The, and I think that there are certain mitigations. You can try to not train certain knowledge into the model, right? There's different things, but, yeah, I mean, it's some level, I mean, if you get a sufficiently bad actor and you don't have other AI that can sort of balance them and understand what's going on and what the threats are, then that could be a risk. So I think that that's one of the things that we need to watch out for. Is there something you could see in the deployment of these systems where you observe like you're training Lama 4 and it's like, it lied to you because you thought you were noticing or something. And you're like, whoa, what's going on here? Not that this is probably not likely with the Lama 4.0 system, but is there something you can imagine like that where you'd be really concerned about deceptiveness and if billions of copies of things are out in the wild? Yeah, I mean, I think that that's not necessarily, I mean, right now, we see a lot of hallucinations, right? So I think it's more that. I think it's an interesting question how you would tell the difference between a hallucination and deception. But yeah, I mean, look, I mean, I think there's a lot of risks and things to think about. The flip side of all this is that there are also a lot of, I try to, in running our company at least, balance what I think of as these longer term theoretical risks with what I actually think are quite real risks that exist today. So like when you talk about deception, the form of that that I worry about most is people using this to generate misinformation and then like pump that through whether it's our networks or others. So the way that we've basically combated a lot of this type of harmful content is by building AI systems that are smarter than the adversarial ones. And I guess this is part of, this kind of informs part of my theory on this, right? Is if you look at like the different types of harm that people do or try to do through social networks, there are ones that are not very adversarial. So for example, like hate speech, I would say is not super adversarial in the sense that like people aren't getting better at being racist, right? They're just like, it's, you just like, okay, if you kind of, that's one where I think the AIs are generally just getting way more sophisticated, faster than people are at those issues. So we have, and we have issues both ways. It's like people do bad things that whether they're trying to incite violence or something. But we also have a lot of false positives, right? So where we basically censor stuff that we shouldn't, and I think understandably make a lot of people annoyed. So I think having an AI that just gets increasingly precise on that, that's gonna be good over time. But let me give you another example, which is like nation states trying to interfere in elections. That's an example where they're absolutely, they have cutting edge technology and absolutely get better each year. So we block some technique, they learn what we did, they come at us with a different technique, right? It's not like a person trying to say mean things, right? It's like, they're basically, they have a goal, they're sophisticated, they have a lot of technology. In those cases, I still think the ability to kind of have RAI systems grow in sophistication at a faster rate than theirs have, it's an arms race, but I think we're at least currently winning that arms race. So I don't know, I think that that's, but this is like a lot of the stuff that I spend time thinking about is like, okay, yes, it is possible that whether it's llama four or llama five or llama six, yeah, we need to think about what behaviors we're observing and it's not just us. And part of the reason why you make this open source is that there are a lot of other people who study this too. So yeah, we wanna see what other people are observing, what we're observing, what we can mitigate, and then we'll make our assessment on whether we can make it open source. But I think for the foreseeable future, I'm optimistic we will be able to. And in the near term, I don't wanna take our eye off the ball of what our actual bad things that people are trying to use the models for today, even if they're not existential, but they're like pretty bad kind of day-to-day harms that we are familiar with in running our services. That's actually a lot of what we have to, I think, spend our time on as well. Yeah, yeah. Actually, I found the synthetic data thing really curious. I'm actually interested in why you don't think, like current models, it makes sense why there might be an asymptote with just doing the synthetic data again and again. If it gets smarter and uses the kind of techniques you talk about in the paper or the blog post that's coming out on the day this will be released where it goes to the thought chain that is the most correct. Why this wouldn't like lead to a loop that, of course, it wouldn't be overnight, but over many months or years of training, potentially, with a smarter model, it gets smarter, makes better output, gets smarter, and so forth. Well, I think it could within the parameter of whatever the model architecture is. It's just that at some level, I don't know, I think today is eight billion parameter models. I just don't think you're going to be able to get to be as good as the state-of-the-art multi-hundred billion parameter models that are incorporating new research into the architecture itself. But those will be open source as well, right? Well, yeah, but I think that that's, I mean, subject to all the questions that we just talked about. Yes, I mean, we would hope that that'll be the case, but I think that at each point, I don't know, it's like when you're building software, there's like a ton of stuff that you can do with software, but then at some level, you're constrained by the chips that it's running on. Right? So there are always going to be different physical constraints. And it's like how big are the models is going to be constrained by how much energy you can get and use for inference. So I guess I'm simultaneously very optimistic that this stuff will continue to improve quickly. And also a little more measured than I think some people are about kind of it's, I just don't think the runaway case is like a particularly likely one. I think it makes sense to keep your options open. Like there's so much we don't know. There's a case in which like it's really important to keep the balance of power. So when nobody becomes like a technology or a dictator, there's a case in which like, you don't want to open source the architecture because like China can use it to catch up to America's AIs and like there is an intelligence explosion and they like win that. Yeah, a lot of things are impossible. Just like keeping your options open, considering all of them seems reasonable. Yeah. Let's talk about some other things. Go for it. Okay. Metaverse, what time period in human history would you be most interested in going into? A 100,000 BCE to now. You just want to see what it was like. Well, that's through the past. Huh? It has to be the past. Oh yeah, it has to be the past. I don't know. I mean, I have the periods of time that I'm interested. I mean, I'm really interested in American history and classical history and I'm really interested in the history of science too. So I actually think seeing and trying to understand more about how some of the big advances came about. I mean, all we have are like somewhat limited writings about some of that stuff. I'm not sure the metaverse is going to let you do that because I mean, it's, you know, we can't, it's going to be hard to kind of go back in time for things that we don't have records of. But I'm actually not sure that going back in time is going to be that important thing for them. I mean, I think it's going to be cool for history classes and stuff, but that's probably not the use case that I'm most excited about for the metaverse overall. I mean, the main thing is just the ability to feel present with people no matter where you are. I think that's going to be killer. I mean, there's, I mean, in the AI conversation that we were having, I mean, it's, you know, so much of it is about physical constraints that kind of underlie all of this, right? And you want to move, I mean, one lesson of technology is you want to move things from the physical constraint realm into software as much as possible because software is so much easier to build and evolve. And like you can democratize it more because like not everyone is going to have a data center, but like a lot of people can kind of write code and take open source code and modify it. The metaverse version of this is I think enabling realistic digital presence is going to be just an absolutely huge difference for making it so that people don't feel like they have to physically be together for as many things. Now, I mean, I think that there are going to be things that are better about being physically together. So it's not, I mean, these things aren't binary, it's not going to be like, okay, now it's, you don't need to do that anymore. But overall, I mean, I think that this, it's just going to be really powerful for socializing, for feeling connected with people, for working, for, I don't know, parts of industry, for medicine, for like so many things. I want to go back to something you said at the beginning of the conversation where you didn't sell the company for a billion dollars and like the metaverse, you knew we were going to do this even though the market was hammering you for it. And then I'm actually curious, like what is the source of that edge? And you said like, oh, values, I have this intuition, but like everybody says that, right? If you had to say something that's specific to you, what is, how would you express what that is? Like why were you so convinced about the metaverse? Well, I think that those are different questions. So what, I mean, what are the things that kind of power me? I think we've talked about a bunch of things. So it's, I mean, I just really like building things. I specifically like building things around how people communicate and sort of understanding how people express themselves and how people work, right? And when I was in college, I was, I was studying computer science and psychology. I think a lot of other people in the industry started studying computer science, right? So it's always been sort of the intersection of those two things for me. But I think it's also sort of this like really deep drive. I don't know how to explain it, but I just feel like in, like constitutionally, like I'm doing something wrong if I'm not building something new, right? And so I think that there's like even when we're putting together the business case for, you know, investing like $100 billion in AI or some huge amount in the metaverse. So it's like, yeah, I mean, we have plans that I think make it pretty clear that if our stuff works, it'll be a good investment. But like, you can't know for certain from the outset. And there's all these arguments that people have, you know, whether it's like, you know, with advisors or different folks, it's like, well, how, how could you, like it's how are you confident enough to do this? And it's like, well, the day I stop trying to build new things, I'm just done. I'm going to go build new things somewhere else, right? It's like, it's like, it is, I'm fundamentally incapable of running something or in my own life and like not trying to build new things that I think are interesting. It's like, that's not even a question for me, right? It's like whether, like whether we're going to go take a swing at like building the next thing. It's like, it's like, I'm just incapable of not doing that. And I don't know, and I'm kind of like this in like all the different aspects of my life, right? It's like we built this like, you know, family built this ranch in Kauai and like, I just like worked to like design all these buildings. I'm like kind of trying to like, we started raising cattle and I'm like, all right, well, I want to make like the best cattle in the world, right? So it's like, how do we like, how do we architect this so that way we can figure this out and like and build and call the stuff up that we need to try to do that? So I don't know, that's me. What was the other part of the question? Look, Metta is just a really amazing tech company, right? They have all these great software engineers and even they work with Stripe to handle payments. And I think that's just a really notable fact. That Stripe's ability to engineer these checkout experiences is so good that big companies like Ford, Zoom, Metta, even OpenAI, they work with Stripe to handle payments because just think about how many different possibilities you have to handle. If you're in a different country, you'll pay a different way and if you're buying a certain kind of item that might affect how you decide to pay. And Stripe is able to test these fine-grained optimizations across tens of billions of transactions a day to figure out what will convert people and obviously conversion means more revenue for you. And look, I'm not a big company like Metta or anything, but I've been using Stripe since long before they were advertisers. Stripe Atlas was just the easiest way for me to set up an LLC and they have these payments and invoicing features that make it super convenient for me to get money from advertisers. And obviously without that, it would have been much harder for me to earn money from the podcast. And so it's been great for me. Go to stripe.com to learn more. Thanks to them for sponsoring the episode. Now back to Mark. I'm not sure, but I'm actually curious about something else which is, so the 19-year-old Mark reads a bunch of like antiquity in classics, high school, college. What important lesson did you learn from it? Not just interesting things you found, but like there aren't that many tokens you consumed by the time you're 19. A bunch of them were about the classics. Clearly that was important in some way. And that many tokens you consumed. I don't know. That's a good question. I mean, one of the things that I thought was really fascinating is, so when Augustus was first, so he became emperor, and he was trying to establish peace. And there was no real conception of peace at the time. Like the people's understanding of peace was, it is the temporary time between when you're and amuse will inevitably attack you again, so you get like a short rest. And he had this view, which is like, look, like we want to change the economy from instead of being so mercenary and like in kind of militaristic to like actually this positive something. It's like a very novel idea at the time. I don't know. I think that there's like something that's just really fundamental about that. It's like in terms of the bounds on like what people can conceive at the time of like what are rational ways to work. And I don't know, I mean, going back to like, I mean, this applies to both the metaverse and the AI stuff, but like a lot of investors and just different people just can't wrap their head around why we would open source this. And it's like, I don't understand. It's like open source. That must just be like the temporary time between which you're making things proprietary. Right. And it's, but I actually think it's like this very profound thing in tech that has actually, it creates a lot of winners. Right. And it's and so I don't want to strain the analogy too much, but I do think that there's a lot of times, I think ways where you can that are just like models for building things that people can't even like they just like often can't wrap their head around how that would be a valuable thing for people to go do, or like a reasonable state of the world that it's, I mean, it's, I think that there's more reasonable things than people think. That's super fascinating. Can I give you my answer when I was thinking what you might have gotten from it? This is probably totally off, but just how young some of these people are who have very important roles in the empire. Like Caesar Augustus, like by the time he's 19, he's actually incredibly one of the most prominent people in Roman politics. And he's like leading battles and forming the second prime emirate. I wonder if you're like the 19 year old is like, I can actually do this because like I think that's an interesting example, both from a lot of history and American history. Yeah. I mean, it's, I mean, one of my favorite quotes is, it's this Picasso quote that all children are artists and the challenge is how do you remain an artist when you grow up? And it's like basically I think because when you're younger, I think it's just easier to have kind of wild ideas and you're not, you know, you have no, there are all these analogies to the innovators dilemma that exist in your life as well as your company or whatever you've built, right? So, you know, you're kind of earlier on your trajectory. It's easier to pivot and take in new ideas without it disrupting other commitments that you've made to different things. And so, I don't know. I think that's an interesting part of running a company is like how do you kind of stay dynamic? Going back to the investors in open source, the $10 billion model, suppose it's totally safe, you've done these evaluations and unlike in this case, the evaluators can also fine tune the model, which hopefully will be the case in future models. Would you open source that, the $10 billion model? Well, I mean, as long as it's helping us, then yeah. But would it like to $10 billion of R&D and then now it's like open source or anything? Well, I think here's, I think a question, which we'll have to evaluate this as time goes on too, but we have a long history of open sourcing software, right? We don't tend to open source our product, right? So, it's not like we don't take like the code for Instagram and make it open source, but we take like a lot of the low level infrastructure and we make that open source, right? Probably the biggest one in our history was open compute project where we took the designs for kind of all of our servers and network switches and data centers and made it open source and ended up being super helpful because, you know, I mean, a lot of people can design servers, but now like the industry standardized on our design, which meant that the supply chains basically all got built out around our design, the volumes went up, so it got cheaper for everyone and saved us billions of dollars. So, awesome, right? Okay, so there's multiple ways where open source, I think, could be helpful for us. One is if people figure out how to run the models more cheaply. Well, we're going to be spending tens or like 100 billion dollars or more over time on all this stuff. So, if we can do that 10% more effectively, we're saving billions or tens of billions of dollars. Okay, that's probably worth a lot by itself, especially if there's other competitive models out there. It's not like our thing is like be giving away some kind of crazy advantage. So, is there a view that the trading will be commodified? I think there's a bunch of ways that this could play out. That's one. The other is that, so commodity kind of implies that it's going to get very cheap because there's lots of options. The other direction that this could go in is qualitative improvements. So, you mentioned fine-tuning, right? It's like right now, it's pretty limited, what you can do with fine-tuning major other models out there. And there are some options, but generally not for the biggest models. So, I think being able to do that and be able to kind of do different app-specific things or use case-specific things or build them into specific tool chains, I think will not only enable kind of more efficient development, it could enable qualitatively different things. Here's one analogy on this. So, one thing that I think generally sucks about the mobile ecosystem is that you have these two gatekeeper companies, Apple and Google, that can tell you what you're allowed to build. And there are lots of times in our history, so there's the economic version of that, which is like, all right, we build something in there, just like, I'm going to take a bunch of your money. But then there's the qualitative version, which is actually what kind of upsets me more, which is there's a bunch of times when we've launched or wanted to launch features, and then Apple's just like, nope, you're not launching that. So, it's like, that sucks, right? And so, the question is, what is, like, are we kind of set up for a world like that with AI, where like, you're going to get a handful of companies that run these closed models that are going to be in control of the APIs, and therefore are going to be able to tell you what you can build. Well, for one, I can say, for us, it is worth it to go build a model ourselves to make sure that we're not in that position, right? Like, I don't want any of those other companies telling us what we can build. But from an open source perspective, I think a lot of developers don't want those companies telling them what they can build either. So, the question is, what is the ecosystem that gets built out around that? What are interesting new things? How much does that improve our products? I think that there's a lot of cases where if this ends up being like, you know, like our databases or caching systems or architecture, we'll get valuable contributions from the community that will make our stuff better, and then our app-specific work that we do will still be so differentiated that it won't really matter, right? It's like, we'll be able to do what we do, we'll benefit in all the systems, ours and the communities will be better because it's open source. There is one world where maybe it's not that. I mean, maybe the model just ends up being more of the product itself. In that case, then I think it's a trickier economic calculation about whether you open source that because then you are kind of commoditizing yourself a lot. From what I can see so far, it doesn't seem like we're in that zone. Do you expect to earn significant revenue from licensing your model to the cloud providers? So, they have to pay you a fee to actually serve the model? We want to have an arrangement like that, but I don't know how significant it'll be. And we have this, this is basically our license for Lama. In a lot of ways, it's like a very permissive open source license, except that we have a limit for the largest companies using it. And this is why we put that limit in, is we're not trying to prevent them from using it. We just want them to come talk to us because if they're going to just basically take what we built and resell it and make money off of it, then it's like, okay, well, if you're like, Microsoft Azure or Amazon, yeah, if you're going to reselling the model, then we should have some revenue share on that. So, just come talk to us before you go do that. And that's how that's played out. So, for Lama 2, it's, I mean, we basically just have deals with all these major cloud companies, and Lama 2 is available as a hosted service on all those clouds. I assume that as we release bigger and bigger models, that'll become a bigger thing. It's not the main thing that we're doing, but I just think if others are, if those companies are going to be selling our models, it makes sense that we should, you know, share the upside of that somehow. Yeah. With regards to the other open source dangers, I think I have a genuine legion of points about the balance of power stuff, and potentially like the harms you can get rid of because we have better alignment techniques or something. I wish there was some sort of framework that Meta had, like other labs have this where they say like, if we see this is a concrete thing, then that's a no-go on the open source, or like even potentially on deployment, just like writing it down so like the company is ready for it, people have expectations around it and so forth. Yeah. No, I think that that's a fair point on the existential risk side. Right now, we focus more on the types of risks that we see today, which are more of these content risks. So, you know, we have lines on, we don't want the model to be basically doing things that are helping people commit violence or fraud or, you know, just harming people in different ways. So in practice for today's models, and I would guess the next generation and maybe even the generation after that, I think while it is somewhat more maybe intellectually interesting to talk about the existential risks, I actually think the real harms that need more energy being mitigated are things that are going to like have someone take a model and do something to hurt a person with today's parameters of and kind of the types of kind of more mundane harms that we see today, like people kind of committing fraud against each other or things like that. So that, I just don't want to short change that. I think we have a responsibility to make sure we do a good job on that. Yeah, Meta's a big company, you can handle both. Yeah. Okay, so as far as the open source goes, I'm actually curious if you think the impact of the open source from PyTorch, React, open compute, these things has been bigger for the world than even the social media aspects of Meta. Because I like talk to people who use these services and think like it's plausible because a big part of the internet runs on these things. It's an interesting question. I mean, I think almost half the world uses our... Yeah, that's an interesting point. So I think it's hard to beat that. But no, I think open sources, it's really powerful as a new way of building things. And yeah, I mean, it's possible. I mean, it's maybe one of these things where... I don't know, like Bell Labs, where they... It's like they were working on the transistor because they wanted to enable long distance calling. And they did. And it ended up being really profitable for them that they were able to enable long distance calling. And if you ask them five to 10 years out from that, what was the most useful thing that they invented? It's like, okay, well, we enable long distance calling and now all these people are long distance calling. But if you ask 100 years later, maybe it's a different question. So I think that that's true of a lot of the things that we're building, right? Reality Labs, some of the AI stuff, some of the open source stuff. I think it's like the specific products evolve and to some degree come and go. But I think like the advances for humanity persist. And that's like a cool part of what we all get to do. By when will the Lama models be trained on your own custom silicon? Soon, not Lama 4. The approach that we took is first we basically built custom silicon that could handle inference for our ranking and recommendation type stuff. So reels, newsfeed, ads. And that was consuming a lot of GPUs. But when we were able to move that to our own silicon, we now were able to use the more expensive Nvidia GPUs only for training. So at some point, we will hopefully have silicon ourselves that we can be using for probably first training some of the simpler things that eventually training these like really large models. But in the meantime, I'd say the program is going quite well and we're just rolling it out methodically and have a long-term roadmap for it. Final question. This is sort of the out of left field, but if you were made CEO of Google+, could you have made it work? Google+, oof. Well, I don't know. I don't know. That's a very difficult, very difficult counterfactual. Okay, then the real final question will be when Gemini was launched, was there any chance that somebody in the office uttered Karthica Dalinda Est? No, I think we're tamer now. Cool, cool. Awesome, Mark. Yeah, I don't know. It's a good question. The problem is there was no CEO of Google+, it was just like a division within a company. I think it's like, and you asked before about what are the kind of scarcest commodities, but you asked about it in terms of dollars. And I actually think for most companies, it's, of this scale at least, it's focus, right? It's like when you're a startup, maybe you're more constrained on capital. You know, you just are working on one idea and you might not have all the resources. I think you cross some threshold at some point where the nature of what you're doing, you're building multiple things and you're creating more value across them, but you become more constrained on what can you direct and to go well. And like, there's always the cases where something just random awesome happens in the organization, I don't even know about it. And those are, that's great. But like, but I think in general, the organization's capacity is largely limited by what like the CEO and the management team are able to kind of oversee and kind of manage. I think that that's just been a big focus for us. It's like, all right, keep the, as I guess Ben Horowitz says, keep the main thing, the main thing, right? And try to kind of stay focused on your key priorities. Yeah, all right, awesome. That was excellent, Mark. Thanks so much. That was a lot of fun. Yeah, really fun. Thanks for having me. Yeah, absolutely. Hey, everybody. I hope you enjoyed that episode with Mark. As you can see, I'm now doing ads. So if you're interested in advertising on the podcast, go to the link in the description. Otherwise, as you know, the most helpful thing you can do is just share the podcast with people who you think might enjoy it. You know, your friends, group chats, Twitter, I guess threads. Yeah, I hope you enjoyed and I'll see you on the next one.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 1.44, "text": " That's not even a question for me,", "tokens": [50364, 663, 311, 406, 754, 257, 1168, 337, 385, 11, 50436], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 1, "seek": 0, "start": 1.44, "end": 4.08, "text": " whether we're going to go take a swing at building the next thing.", "tokens": [50436, 1968, 321, 434, 516, 281, 352, 747, 257, 11173, 412, 2390, 264, 958, 551, 13, 50568], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 2, "seek": 0, "start": 4.08, "end": 6.640000000000001, "text": " I'm just incapable of not doing that.", "tokens": [50568, 286, 478, 445, 44174, 295, 406, 884, 300, 13, 50696], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 3, "seek": 0, "start": 6.640000000000001, "end": 9.84, "text": " There's a bunch of times when we wanted to launch features", "tokens": [50696, 821, 311, 257, 3840, 295, 1413, 562, 321, 1415, 281, 4025, 4122, 50856], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 4, "seek": 0, "start": 9.84, "end": 12.48, "text": " and then Apple's just like, nope, you're not launching that.", "tokens": [50856, 293, 550, 6373, 311, 445, 411, 11, 23444, 11, 291, 434, 406, 18354, 300, 13, 50988], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 5, "seek": 0, "start": 12.48, "end": 13.36, "text": " I was like, that sucks.", "tokens": [50988, 286, 390, 411, 11, 300, 15846, 13, 51032], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 6, "seek": 0, "start": 14.16, "end": 18.96, "text": " Are we set up for that with AI, where you're going to get a handful of companies", "tokens": [51072, 2014, 321, 992, 493, 337, 300, 365, 7318, 11, 689, 291, 434, 516, 281, 483, 257, 16458, 295, 3431, 51312], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 7, "seek": 0, "start": 18.96, "end": 22.240000000000002, "text": " that run these closed models that are going to be in control of the APIs", "tokens": [51312, 300, 1190, 613, 5395, 5245, 300, 366, 516, 281, 312, 294, 1969, 295, 264, 21445, 51476], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 8, "seek": 0, "start": 22.240000000000002, "end": 24.48, "text": " and therefore are going to be able to tell you what you can build?", "tokens": [51476, 293, 4412, 366, 516, 281, 312, 1075, 281, 980, 291, 437, 291, 393, 1322, 30, 51588], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 9, "seek": 0, "start": 24.48, "end": 29.36, "text": " Then when you start getting into building a data center that's like 300 megawatts", "tokens": [51588, 1396, 562, 291, 722, 1242, 666, 2390, 257, 1412, 3056, 300, 311, 411, 6641, 10816, 38036, 1373, 51832], "temperature": 0.0, "avg_logprob": -0.15011701276225428, "compression_ratio": 1.803076923076923, "no_speech_prob": 0.024414334446191788}, {"id": 10, "seek": 2936, "start": 29.36, "end": 31.919999999999998, "text": " or 500 megawatts or a gigawatt,", "tokens": [50364, 420, 5923, 10816, 38036, 1373, 420, 257, 8741, 1607, 1591, 11, 50492], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 11, "seek": 2936, "start": 31.919999999999998, "end": 34.32, "text": " just no one has built a single gigawatt data center yet.", "tokens": [50492, 445, 572, 472, 575, 3094, 257, 2167, 8741, 1607, 1591, 1412, 3056, 1939, 13, 50612], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 12, "seek": 2936, "start": 34.32, "end": 37.2, "text": " But from wherever you sit, there's going to be some actor who you don't trust.", "tokens": [50612, 583, 490, 8660, 291, 1394, 11, 456, 311, 516, 281, 312, 512, 8747, 567, 291, 500, 380, 3361, 13, 50756], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 13, "seek": 2936, "start": 37.2, "end": 39.6, "text": " If they're the ones who have like the super strong AI,", "tokens": [50756, 759, 436, 434, 264, 2306, 567, 362, 411, 264, 1687, 2068, 7318, 11, 50876], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 14, "seek": 2936, "start": 39.6, "end": 43.04, "text": " I think that that's potentially a much bigger risk.", "tokens": [50876, 286, 519, 300, 300, 311, 7263, 257, 709, 3801, 3148, 13, 51048], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 15, "seek": 2936, "start": 43.92, "end": 45.28, "text": " Mark, welcome to the podcast.", "tokens": [51092, 3934, 11, 2928, 281, 264, 7367, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 16, "seek": 2936, "start": 45.28, "end": 47.2, "text": " Hey, thanks for having me, big fan of your podcast.", "tokens": [51160, 1911, 11, 3231, 337, 1419, 385, 11, 955, 3429, 295, 428, 7367, 13, 51256], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 17, "seek": 2936, "start": 47.2, "end": 48.56, "text": " Oh, thank you. That's very nice of you to say.", "tokens": [51256, 876, 11, 1309, 291, 13, 663, 311, 588, 1481, 295, 291, 281, 584, 13, 51324], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 18, "seek": 2936, "start": 49.92, "end": 54.0, "text": " Okay, so let's start by talking about the releases that will go out", "tokens": [51392, 1033, 11, 370, 718, 311, 722, 538, 1417, 466, 264, 16952, 300, 486, 352, 484, 51596], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 19, "seek": 2936, "start": 54.0, "end": 55.04, "text": " when this interview goes out.", "tokens": [51596, 562, 341, 4049, 1709, 484, 13, 51648], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 20, "seek": 2936, "start": 55.92, "end": 57.92, "text": " Tell me about the models, tell me about meta AI,", "tokens": [51692, 5115, 385, 466, 264, 5245, 11, 980, 385, 466, 19616, 7318, 11, 51792], "temperature": 0.0, "avg_logprob": -0.12049581419746831, "compression_ratio": 1.687116564417178, "no_speech_prob": 0.0011334747541695833}, {"id": 21, "seek": 5792, "start": 57.92, "end": 59.440000000000005, "text": " what's new, what's exciting about them?", "tokens": [50364, 437, 311, 777, 11, 437, 311, 4670, 466, 552, 30, 50440], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 22, "seek": 5792, "start": 59.440000000000005, "end": 62.64, "text": " Yeah, sure. I think the main thing that most people in the world", "tokens": [50440, 865, 11, 988, 13, 286, 519, 264, 2135, 551, 300, 881, 561, 294, 264, 1002, 50600], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 23, "seek": 5792, "start": 62.64, "end": 64.24000000000001, "text": " are going to see is the new version of meta AI.", "tokens": [50600, 366, 516, 281, 536, 307, 264, 777, 3037, 295, 19616, 7318, 13, 50680], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 24, "seek": 5792, "start": 66.64, "end": 70.4, "text": " The most important thing about what we're doing is the upgrade to the model.", "tokens": [50800, 440, 881, 1021, 551, 466, 437, 321, 434, 884, 307, 264, 11484, 281, 264, 2316, 13, 50988], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 25, "seek": 5792, "start": 70.4, "end": 71.6, "text": " We're rolling out Lama 3.", "tokens": [50988, 492, 434, 9439, 484, 441, 2404, 805, 13, 51048], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 26, "seek": 5792, "start": 71.6, "end": 74.96000000000001, "text": " We're doing it both as open source for the dev community,", "tokens": [51048, 492, 434, 884, 309, 1293, 382, 1269, 4009, 337, 264, 1905, 1768, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 27, "seek": 5792, "start": 74.96000000000001, "end": 77.12, "text": " and it is now going to be powering meta AI.", "tokens": [51216, 293, 309, 307, 586, 516, 281, 312, 1347, 278, 19616, 7318, 13, 51324], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 28, "seek": 5792, "start": 78.88, "end": 80.88, "text": " There's a lot that I'm sure we'll go into around Lama 3,", "tokens": [51412, 821, 311, 257, 688, 300, 286, 478, 988, 321, 603, 352, 666, 926, 441, 2404, 805, 11, 51512], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 29, "seek": 5792, "start": 80.88, "end": 84.16, "text": " but I think the bottom line on this is that with Lama 3,", "tokens": [51512, 457, 286, 519, 264, 2767, 1622, 322, 341, 307, 300, 365, 441, 2404, 805, 11, 51676], "temperature": 0.0, "avg_logprob": -0.09885456942129826, "compression_ratio": 1.7509293680297398, "no_speech_prob": 0.004607840441167355}, {"id": 30, "seek": 8416, "start": 84.16, "end": 88.08, "text": " we now think that meta AI is the most intelligent AI assistant", "tokens": [50364, 321, 586, 519, 300, 19616, 7318, 307, 264, 881, 13232, 7318, 10994, 50560], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 31, "seek": 8416, "start": 88.08, "end": 90.0, "text": " that people can use that's freely available.", "tokens": [50560, 300, 561, 393, 764, 300, 311, 16433, 2435, 13, 50656], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 32, "seek": 8416, "start": 90.72, "end": 93.75999999999999, "text": " We're also integrating Google and Bing for real-time knowledge.", "tokens": [50692, 492, 434, 611, 26889, 3329, 293, 30755, 337, 957, 12, 3766, 3601, 13, 50844], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 33, "seek": 8416, "start": 94.47999999999999, "end": 97.2, "text": " We're going to make it a lot more prominent across our apps.", "tokens": [50880, 492, 434, 516, 281, 652, 309, 257, 688, 544, 17034, 2108, 527, 7733, 13, 51016], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 34, "seek": 8416, "start": 97.2, "end": 100.96, "text": " So basically, at the top of WhatsApp and Instagram", "tokens": [51016, 407, 1936, 11, 412, 264, 1192, 295, 30513, 293, 5281, 51204], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 35, "seek": 8416, "start": 100.96, "end": 105.67999999999999, "text": " and Facebook and Messenger, you'll just be able to use the search box", "tokens": [51204, 293, 4384, 293, 34226, 11, 291, 603, 445, 312, 1075, 281, 764, 264, 3164, 2424, 51440], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 36, "seek": 8416, "start": 105.67999999999999, "end": 107.28, "text": " right there to ask it any question.", "tokens": [51440, 558, 456, 281, 1029, 309, 604, 1168, 13, 51520], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 37, "seek": 8416, "start": 108.08, "end": 110.72, "text": " And there's a bunch of new creation features that we added", "tokens": [51560, 400, 456, 311, 257, 3840, 295, 777, 8016, 4122, 300, 321, 3869, 51692], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 38, "seek": 8416, "start": 110.72, "end": 112.72, "text": " that I think are pretty cool that I think people enjoy.", "tokens": [51692, 300, 286, 519, 366, 1238, 1627, 300, 286, 519, 561, 2103, 13, 51792], "temperature": 0.0, "avg_logprob": -0.0872491559674663, "compression_ratio": 1.6470588235294117, "no_speech_prob": 0.0027139021549373865}, {"id": 39, "seek": 11416, "start": 114.39999999999999, "end": 116.47999999999999, "text": " And I think animations is a good one.", "tokens": [50376, 400, 286, 519, 22868, 307, 257, 665, 472, 13, 50480], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 40, "seek": 11416, "start": 117.2, "end": 119.36, "text": " You can basically just take any image and animate it.", "tokens": [50516, 509, 393, 1936, 445, 747, 604, 3256, 293, 36439, 309, 13, 50624], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 41, "seek": 11416, "start": 119.36, "end": 123.52, "text": " But I think one that people are going to find pretty wild is", "tokens": [50624, 583, 286, 519, 472, 300, 561, 366, 516, 281, 915, 1238, 4868, 307, 50832], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 42, "seek": 11416, "start": 124.39999999999999, "end": 127.67999999999999, "text": " it now generates high-quality images so quickly.", "tokens": [50876, 309, 586, 23815, 1090, 12, 11286, 5267, 370, 2661, 13, 51040], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 43, "seek": 11416, "start": 127.67999999999999, "end": 129.35999999999999, "text": " I don't know if you've gotten a chance to play with this,", "tokens": [51040, 286, 500, 380, 458, 498, 291, 600, 5768, 257, 2931, 281, 862, 365, 341, 11, 51124], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 44, "seek": 11416, "start": 129.35999999999999, "end": 132.88, "text": " that it actually generates it as you're typing and updates it in real-time.", "tokens": [51124, 300, 309, 767, 23815, 309, 382, 291, 434, 18444, 293, 9205, 309, 294, 957, 12, 3766, 13, 51300], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 45, "seek": 11416, "start": 132.88, "end": 136.88, "text": " So you're typing your query and it's honing in on...", "tokens": [51300, 407, 291, 434, 18444, 428, 14581, 293, 309, 311, 2157, 278, 294, 322, 485, 51500], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 46, "seek": 11416, "start": 136.88, "end": 142.48, "text": " And it's like, okay, here, show me a picture of a cow in a field", "tokens": [51500, 400, 309, 311, 411, 11, 1392, 11, 510, 11, 855, 385, 257, 3036, 295, 257, 8408, 294, 257, 2519, 51780], "temperature": 0.0, "avg_logprob": -0.11247013485620892, "compression_ratio": 1.6715867158671587, "no_speech_prob": 0.0009397353860549629}, {"id": 47, "seek": 14248, "start": 142.56, "end": 145.92, "text": " with mountains in the background and just like eating macadamia nuts,", "tokens": [50368, 365, 10233, 294, 264, 3678, 293, 445, 411, 3936, 7912, 345, 335, 654, 10483, 11, 50536], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 48, "seek": 14248, "start": 145.92, "end": 150.07999999999998, "text": " drinking beer and it's updating the image in real-time.", "tokens": [50536, 7583, 8795, 293, 309, 311, 25113, 264, 3256, 294, 957, 12, 3766, 13, 50744], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 49, "seek": 14248, "start": 150.79999999999998, "end": 151.51999999999998, "text": " It's pretty wild.", "tokens": [50780, 467, 311, 1238, 4868, 13, 50816], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 50, "seek": 14248, "start": 151.51999999999998, "end": 152.72, "text": " I think people are going to enjoy that.", "tokens": [50816, 286, 519, 561, 366, 516, 281, 2103, 300, 13, 50876], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 51, "seek": 14248, "start": 153.92, "end": 157.2, "text": " So yeah, that's what most people are going to see in the world.", "tokens": [50936, 407, 1338, 11, 300, 311, 437, 881, 561, 366, 516, 281, 536, 294, 264, 1002, 13, 51100], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 52, "seek": 14248, "start": 157.2, "end": 159.35999999999999, "text": " We're rolling that out, not everywhere,", "tokens": [51100, 492, 434, 9439, 300, 484, 11, 406, 5315, 11, 51208], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 53, "seek": 14248, "start": 159.35999999999999, "end": 161.76, "text": " but we're starting in a handful of countries", "tokens": [51208, 457, 321, 434, 2891, 294, 257, 16458, 295, 3517, 51328], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 54, "seek": 14248, "start": 161.76, "end": 164.07999999999998, "text": " and we'll do more over the coming weeks and months.", "tokens": [51328, 293, 321, 603, 360, 544, 670, 264, 1348, 3259, 293, 2493, 13, 51444], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 55, "seek": 14248, "start": 165.51999999999998, "end": 167.76, "text": " So that I think is going to be a pretty big deal.", "tokens": [51516, 407, 300, 286, 519, 307, 516, 281, 312, 257, 1238, 955, 2028, 13, 51628], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 56, "seek": 14248, "start": 168.88, "end": 170.56, "text": " And I'm really excited to get that in people's hands.", "tokens": [51684, 400, 286, 478, 534, 2919, 281, 483, 300, 294, 561, 311, 2377, 13, 51768], "temperature": 0.0, "avg_logprob": -0.15195753995110006, "compression_ratio": 1.7304964539007093, "no_speech_prob": 0.01167966052889824}, {"id": 57, "seek": 17056, "start": 171.04, "end": 173.68, "text": " It's a big step forward for Met AI.", "tokens": [50388, 467, 311, 257, 955, 1823, 2128, 337, 6377, 7318, 13, 50520], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 58, "seek": 17056, "start": 175.44, "end": 177.68, "text": " But I think if you want to get under the hood a bit,", "tokens": [50608, 583, 286, 519, 498, 291, 528, 281, 483, 833, 264, 13376, 257, 857, 11, 50720], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 59, "seek": 17056, "start": 178.48, "end": 181.52, "text": " the Llama 3 stuff is obviously the most technically interesting.", "tokens": [50760, 264, 32717, 2404, 805, 1507, 307, 2745, 264, 881, 12120, 1880, 13, 50912], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 60, "seek": 17056, "start": 181.52, "end": 184.24, "text": " So we're basically, for the first version,", "tokens": [50912, 407, 321, 434, 1936, 11, 337, 264, 700, 3037, 11, 51048], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 61, "seek": 17056, "start": 184.24, "end": 188.72, "text": " we're training three versions, an 8 billion and a 70 billion,", "tokens": [51048, 321, 434, 3097, 1045, 9606, 11, 364, 1649, 5218, 293, 257, 5285, 5218, 11, 51272], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 62, "seek": 17056, "start": 188.72, "end": 193.36, "text": " which we're releasing today and a 405 billion dense model,", "tokens": [51272, 597, 321, 434, 16327, 965, 293, 257, 3356, 20, 5218, 18011, 2316, 11, 51504], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 63, "seek": 17056, "start": 193.36, "end": 196.08, "text": " which is still training, so we're not releasing that today.", "tokens": [51504, 597, 307, 920, 3097, 11, 370, 321, 434, 406, 16327, 300, 965, 13, 51640], "temperature": 0.0, "avg_logprob": -0.15694352692248775, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0009397727553732693}, {"id": 64, "seek": 19608, "start": 196.48000000000002, "end": 203.04000000000002, "text": " But the 8 and 70, I mean, I'm pretty excited about how they turned out.", "tokens": [50384, 583, 264, 1649, 293, 5285, 11, 286, 914, 11, 286, 478, 1238, 2919, 466, 577, 436, 3574, 484, 13, 50712], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 65, "seek": 19608, "start": 203.04000000000002, "end": 206.8, "text": " I mean, they're leading for their scale.", "tokens": [50712, 286, 914, 11, 436, 434, 5775, 337, 641, 4373, 13, 50900], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 66, "seek": 19608, "start": 208.8, "end": 212.88000000000002, "text": " You know, it's, I mean, we'll release a blog post with all the benchmarks", "tokens": [51000, 509, 458, 11, 309, 311, 11, 286, 914, 11, 321, 603, 4374, 257, 6968, 2183, 365, 439, 264, 43751, 51204], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 67, "seek": 19608, "start": 212.88000000000002, "end": 215.20000000000002, "text": " so people can check it out themselves and obviously it's open source", "tokens": [51204, 370, 561, 393, 1520, 309, 484, 2969, 293, 2745, 309, 311, 1269, 4009, 51320], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 68, "seek": 19608, "start": 215.20000000000002, "end": 216.72000000000003, "text": " so people get a chance to play with it.", "tokens": [51320, 370, 561, 483, 257, 2931, 281, 862, 365, 309, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 69, "seek": 19608, "start": 217.84, "end": 220.08, "text": " We have a roadmap of new releases coming", "tokens": [51452, 492, 362, 257, 35738, 295, 777, 16952, 1348, 51564], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 70, "seek": 19608, "start": 220.96, "end": 224.64000000000001, "text": " that are going to bring multi-modality, more multi-linguality,", "tokens": [51608, 300, 366, 516, 281, 1565, 4825, 12, 8014, 1860, 11, 544, 4825, 12, 1688, 901, 507, 11, 51792], "temperature": 0.0, "avg_logprob": -0.1892603806086949, "compression_ratio": 1.6024096385542168, "no_speech_prob": 0.003944619558751583}, {"id": 71, "seek": 22464, "start": 225.6, "end": 227.51999999999998, "text": " bigger context windows to those as well.", "tokens": [50412, 3801, 4319, 9309, 281, 729, 382, 731, 13, 50508], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 72, "seek": 22464, "start": 228.72, "end": 231.51999999999998, "text": " And then, you know, hopefully sometime later in the year,", "tokens": [50568, 400, 550, 11, 291, 458, 11, 4696, 15053, 1780, 294, 264, 1064, 11, 50708], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 73, "seek": 22464, "start": 231.51999999999998, "end": 236.32, "text": " we'll get to roll out the 405, which I think is, in training,", "tokens": [50708, 321, 603, 483, 281, 3373, 484, 264, 3356, 20, 11, 597, 286, 519, 307, 11, 294, 3097, 11, 50948], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 74, "seek": 22464, "start": 236.32, "end": 241.04, "text": " it's still training, but for where it is right now in training,", "tokens": [50948, 309, 311, 920, 3097, 11, 457, 337, 689, 309, 307, 558, 586, 294, 3097, 11, 51184], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 75, "seek": 22464, "start": 241.04, "end": 248.72, "text": " it is already at around 85 mmlu and just,", "tokens": [51184, 309, 307, 1217, 412, 926, 14695, 11169, 2781, 293, 445, 11, 51568], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 76, "seek": 22464, "start": 248.72, "end": 250.64, "text": " we expect that it's going to have leading benchmarks", "tokens": [51568, 321, 2066, 300, 309, 311, 516, 281, 362, 5775, 43751, 51664], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 77, "seek": 22464, "start": 250.64, "end": 252.79999999999998, "text": " on a bunch of the benchmarks.", "tokens": [51664, 322, 257, 3840, 295, 264, 43751, 13, 51772], "temperature": 0.0, "avg_logprob": -0.15904173559072066, "compression_ratio": 1.5936073059360731, "no_speech_prob": 0.0006262095412239432}, {"id": 78, "seek": 25280, "start": 252.8, "end": 254.64000000000001, "text": " So, I'm pretty excited about all of that.", "tokens": [50364, 407, 11, 286, 478, 1238, 2919, 466, 439, 295, 300, 13, 50456], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 79, "seek": 25280, "start": 254.64000000000001, "end": 258.48, "text": " I mean, the 70 billion is great too.", "tokens": [50456, 286, 914, 11, 264, 5285, 5218, 307, 869, 886, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 80, "seek": 25280, "start": 258.48, "end": 259.44, "text": " I mean, we're releasing that today.", "tokens": [50648, 286, 914, 11, 321, 434, 16327, 300, 965, 13, 50696], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 81, "seek": 25280, "start": 259.44, "end": 263.2, "text": " It's around 82 mmlu and has leading scores on math and reasoning.", "tokens": [50696, 467, 311, 926, 29097, 11169, 2781, 293, 575, 5775, 13444, 322, 5221, 293, 21577, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 82, "seek": 25280, "start": 263.2, "end": 265.28000000000003, "text": " So, I mean, it's, I think just getting this in people's hands", "tokens": [50884, 407, 11, 286, 914, 11, 309, 311, 11, 286, 519, 445, 1242, 341, 294, 561, 311, 2377, 50988], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 83, "seek": 25280, "start": 265.28000000000003, "end": 266.48, "text": " is going to be pretty wild.", "tokens": [50988, 307, 516, 281, 312, 1238, 4868, 13, 51048], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 84, "seek": 25280, "start": 266.48, "end": 267.04, "text": " Oh, interesting.", "tokens": [51048, 876, 11, 1880, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 85, "seek": 25280, "start": 267.04, "end": 268.24, "text": " Yeah, that's the first time hearing this benchmark.", "tokens": [51076, 865, 11, 300, 311, 264, 700, 565, 4763, 341, 18927, 13, 51136], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 86, "seek": 25280, "start": 268.24, "end": 268.96000000000004, "text": " That's super impressive.", "tokens": [51136, 663, 311, 1687, 8992, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 87, "seek": 25280, "start": 268.96000000000004, "end": 275.84000000000003, "text": " Yeah, and the 8 billion is nearly as powerful", "tokens": [51172, 865, 11, 293, 264, 1649, 5218, 307, 6217, 382, 4005, 51516], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 88, "seek": 25280, "start": 275.84000000000003, "end": 278.24, "text": " as the biggest version of Llama 2 that we released.", "tokens": [51516, 382, 264, 3880, 3037, 295, 32717, 2404, 568, 300, 321, 4736, 13, 51636], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 89, "seek": 25280, "start": 278.24, "end": 281.12, "text": " So, it's like the smallest Llama 3 is basically as powerful", "tokens": [51636, 407, 11, 309, 311, 411, 264, 16998, 32717, 2404, 805, 307, 1936, 382, 4005, 51780], "temperature": 0.0, "avg_logprob": -0.1387609014447951, "compression_ratio": 1.700325732899023, "no_speech_prob": 0.004330141935497522}, {"id": 90, "seek": 28112, "start": 281.2, "end": 283.36, "text": " as the biggest Llama 2.", "tokens": [50368, 382, 264, 3880, 32717, 2404, 568, 13, 50476], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 91, "seek": 28112, "start": 283.36, "end": 285.68, "text": " Okay, so before we dig into these models,", "tokens": [50476, 1033, 11, 370, 949, 321, 2528, 666, 613, 5245, 11, 50592], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 92, "seek": 28112, "start": 285.68, "end": 287.28000000000003, "text": " I actually want to go back in time.", "tokens": [50592, 286, 767, 528, 281, 352, 646, 294, 565, 13, 50672], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 93, "seek": 28112, "start": 287.84000000000003, "end": 291.52, "text": " 2022 is, I'm assuming, when you started acquiring these H100s,", "tokens": [50700, 20229, 307, 11, 286, 478, 11926, 11, 562, 291, 1409, 37374, 613, 389, 6879, 82, 11, 50884], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 94, "seek": 28112, "start": 292.56, "end": 294.96, "text": " or you can tell me when, where you're like,", "tokens": [50936, 420, 291, 393, 980, 385, 562, 11, 689, 291, 434, 411, 11, 51056], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 95, "seek": 28112, "start": 294.96, "end": 296.4, "text": " stock price is getting hammered.", "tokens": [51056, 4127, 3218, 307, 1242, 13017, 292, 13, 51128], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 96, "seek": 28112, "start": 296.4, "end": 298.4, "text": " People are like, what's happening with all this capex?", "tokens": [51128, 3432, 366, 411, 11, 437, 311, 2737, 365, 439, 341, 1335, 29420, 30, 51228], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 97, "seek": 28112, "start": 298.4, "end": 299.92, "text": " People aren't buying the metaverse.", "tokens": [51228, 3432, 3212, 380, 6382, 264, 19616, 4308, 13, 51304], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 98, "seek": 28112, "start": 299.92, "end": 301.36, "text": " And presumably, you're spending that capex", "tokens": [51304, 400, 26742, 11, 291, 434, 6434, 300, 1335, 29420, 51376], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 99, "seek": 28112, "start": 301.36, "end": 302.72, "text": " to get these H100s.", "tokens": [51376, 281, 483, 613, 389, 6879, 82, 13, 51444], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 100, "seek": 28112, "start": 302.72, "end": 305.04, "text": " How, back then, how did you know to get the H100s?", "tokens": [51444, 1012, 11, 646, 550, 11, 577, 630, 291, 458, 281, 483, 264, 389, 6879, 82, 30, 51560], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 101, "seek": 28112, "start": 305.04, "end": 306.56, "text": " How did you know we'll need the GPUs?", "tokens": [51560, 1012, 630, 291, 458, 321, 603, 643, 264, 18407, 82, 30, 51636], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 102, "seek": 28112, "start": 307.76, "end": 310.16, "text": " I think it was because we were working on Reels.", "tokens": [51696, 286, 519, 309, 390, 570, 321, 645, 1364, 322, 1300, 1625, 13, 51816], "temperature": 0.0, "avg_logprob": -0.15323605392918443, "compression_ratio": 1.6867088607594938, "no_speech_prob": 0.015894955024123192}, {"id": 103, "seek": 31016, "start": 310.16, "end": 315.44, "text": " So, we got into this situation where we always", "tokens": [50364, 407, 11, 321, 658, 666, 341, 2590, 689, 321, 1009, 50628], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 104, "seek": 31016, "start": 316.16, "end": 319.52000000000004, "text": " want to have enough capacity to build something", "tokens": [50664, 528, 281, 362, 1547, 6042, 281, 1322, 746, 50832], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 105, "seek": 31016, "start": 319.52000000000004, "end": 323.28000000000003, "text": " that we can't quite see that were on the horizon yet.", "tokens": [50832, 300, 321, 393, 380, 1596, 536, 300, 645, 322, 264, 18046, 1939, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 106, "seek": 31016, "start": 324.16, "end": 326.64000000000004, "text": " And we got into this position with Reels,", "tokens": [51064, 400, 321, 658, 666, 341, 2535, 365, 1300, 1625, 11, 51188], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 107, "seek": 31016, "start": 326.64000000000004, "end": 330.8, "text": " where we needed more GPUs to train the models.", "tokens": [51188, 689, 321, 2978, 544, 18407, 82, 281, 3847, 264, 5245, 13, 51396], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 108, "seek": 31016, "start": 330.8, "end": 333.92, "text": " It was this big evolution for our services,", "tokens": [51396, 467, 390, 341, 955, 9303, 337, 527, 3328, 11, 51552], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 109, "seek": 31016, "start": 333.92, "end": 335.76000000000005, "text": " where instead of just ranking content from people", "tokens": [51552, 689, 2602, 295, 445, 17833, 2701, 490, 561, 51644], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 110, "seek": 31016, "start": 335.76000000000005, "end": 339.20000000000005, "text": " who you follow, or your friends, and whatever pages you follow,", "tokens": [51644, 567, 291, 1524, 11, 420, 428, 1855, 11, 293, 2035, 7183, 291, 1524, 11, 51816], "temperature": 0.0, "avg_logprob": -0.1142020320892334, "compression_ratio": 1.6188524590163935, "no_speech_prob": 0.00023047991271596402}, {"id": 111, "seek": 34016, "start": 341.04, "end": 345.04, "text": " we made this big push to basically start recommending", "tokens": [50408, 321, 1027, 341, 955, 2944, 281, 1936, 722, 30559, 50608], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 112, "seek": 34016, "start": 345.6, "end": 347.28000000000003, "text": " what we call unconnected content,", "tokens": [50636, 437, 321, 818, 517, 9826, 292, 2701, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 113, "seek": 34016, "start": 347.28000000000003, "end": 349.52000000000004, "text": " to basically connect content from people", "tokens": [50720, 281, 1936, 1745, 2701, 490, 561, 50832], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 114, "seek": 34016, "start": 349.52000000000004, "end": 350.8, "text": " or pages that you're not following.", "tokens": [50832, 420, 7183, 300, 291, 434, 406, 3480, 13, 50896], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 115, "seek": 34016, "start": 350.8, "end": 355.76000000000005, "text": " So, now, kind of the corpus of kind of content candidates", "tokens": [50896, 407, 11, 586, 11, 733, 295, 264, 1181, 31624, 295, 733, 295, 2701, 11255, 51144], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 116, "seek": 34016, "start": 355.76000000000005, "end": 357.84000000000003, "text": " that we could potentially show you expanded from,", "tokens": [51144, 300, 321, 727, 7263, 855, 291, 14342, 490, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 117, "seek": 34016, "start": 357.84000000000003, "end": 359.68, "text": " you know, on the order of thousands", "tokens": [51248, 291, 458, 11, 322, 264, 1668, 295, 5383, 51340], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 118, "seek": 34016, "start": 359.68, "end": 362.48, "text": " to on the order of hundreds of millions.", "tokens": [51340, 281, 322, 264, 1668, 295, 6779, 295, 6803, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 119, "seek": 34016, "start": 362.48, "end": 364.24, "text": " So, completely different infrastructure.", "tokens": [51480, 407, 11, 2584, 819, 6896, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 120, "seek": 34016, "start": 364.96000000000004, "end": 368.72, "text": " And we started working on doing that,", "tokens": [51604, 400, 321, 1409, 1364, 322, 884, 300, 11, 51792], "temperature": 0.0, "avg_logprob": -0.1271058465832862, "compression_ratio": 1.7540983606557377, "no_speech_prob": 0.0008828889112919569}, {"id": 121, "seek": 36872, "start": 368.72, "end": 372.96000000000004, "text": " and we were constrained on basically the infrastructure", "tokens": [50364, 293, 321, 645, 38901, 322, 1936, 264, 6896, 50576], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 122, "seek": 36872, "start": 372.96000000000004, "end": 375.6, "text": " that we had to catch up to what TikTok was doing", "tokens": [50576, 300, 321, 632, 281, 3745, 493, 281, 437, 20211, 390, 884, 50708], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 123, "seek": 36872, "start": 375.6, "end": 376.88000000000005, "text": " as quickly as we would have wanted to.", "tokens": [50708, 382, 2661, 382, 321, 576, 362, 1415, 281, 13, 50772], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 124, "seek": 36872, "start": 377.76000000000005, "end": 379.04, "text": " So, I basically looked at that, and I was like,", "tokens": [50816, 407, 11, 286, 1936, 2956, 412, 300, 11, 293, 286, 390, 411, 11, 50880], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 125, "seek": 36872, "start": 379.04, "end": 382.56, "text": " hey, we have to make sure that we're never in this situation again.", "tokens": [50880, 4177, 11, 321, 362, 281, 652, 988, 300, 321, 434, 1128, 294, 341, 2590, 797, 13, 51056], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 126, "seek": 36872, "start": 382.56, "end": 386.32000000000005, "text": " So, let's order enough GPUs to do what we need to do", "tokens": [51056, 407, 11, 718, 311, 1668, 1547, 18407, 82, 281, 360, 437, 321, 643, 281, 360, 51244], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 127, "seek": 36872, "start": 386.32000000000005, "end": 388.64000000000004, "text": " on Reels and ranking content and feed,", "tokens": [51244, 322, 1300, 1625, 293, 17833, 2701, 293, 3154, 11, 51360], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 128, "seek": 36872, "start": 388.64000000000004, "end": 390.48, "text": " but let's also double that, right?", "tokens": [51360, 457, 718, 311, 611, 3834, 300, 11, 558, 30, 51452], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 129, "seek": 36872, "start": 390.48, "end": 392.8, "text": " Because, again, like our normal principle is,", "tokens": [51452, 1436, 11, 797, 11, 411, 527, 2710, 8665, 307, 11, 51568], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 130, "seek": 36872, "start": 392.8, "end": 394.24, "text": " there's going to be something on the horizon", "tokens": [51568, 456, 311, 516, 281, 312, 746, 322, 264, 18046, 51640], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 131, "seek": 36872, "start": 394.24, "end": 395.04, "text": " that we can't see yet.", "tokens": [51640, 300, 321, 393, 380, 536, 1939, 13, 51680], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 132, "seek": 36872, "start": 395.04, "end": 395.84000000000003, "text": " Did you know it would be AI?", "tokens": [51680, 2589, 291, 458, 309, 576, 312, 7318, 30, 51720], "temperature": 0.0, "avg_logprob": -0.10302234013875325, "compression_ratio": 1.6635220125786163, "no_speech_prob": 0.0028001652099192142}, {"id": 133, "seek": 39584, "start": 396.4, "end": 398.47999999999996, "text": " Well, we thought it would be,", "tokens": [50392, 1042, 11, 321, 1194, 309, 576, 312, 11, 50496], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 134, "seek": 39584, "start": 399.44, "end": 400.32, "text": " we thought it was going to be something", "tokens": [50544, 321, 1194, 309, 390, 516, 281, 312, 746, 50588], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 135, "seek": 39584, "start": 400.32, "end": 402.4, "text": " that I had to do with training large models, right?", "tokens": [50588, 300, 286, 632, 281, 360, 365, 3097, 2416, 5245, 11, 558, 30, 50692], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 136, "seek": 39584, "start": 402.4, "end": 404.0, "text": " I mean, but at the time, I thought it was probably", "tokens": [50692, 286, 914, 11, 457, 412, 264, 565, 11, 286, 1194, 309, 390, 1391, 50772], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 137, "seek": 39584, "start": 404.0, "end": 406.08, "text": " going to be more something that I had to do with content.", "tokens": [50772, 516, 281, 312, 544, 746, 300, 286, 632, 281, 360, 365, 2701, 13, 50876], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 138, "seek": 39584, "start": 406.08, "end": 406.79999999999995, "text": " But I don't know.", "tokens": [50876, 583, 286, 500, 380, 458, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 139, "seek": 39584, "start": 406.79999999999995, "end": 409.52, "text": " I mean, it's almost just the pattern matching", "tokens": [50912, 286, 914, 11, 309, 311, 1920, 445, 264, 5102, 14324, 51048], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 140, "seek": 39584, "start": 409.52, "end": 413.67999999999995, "text": " and running the company is there's always another thing, right?", "tokens": [51048, 293, 2614, 264, 2237, 307, 456, 311, 1009, 1071, 551, 11, 558, 30, 51256], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 141, "seek": 39584, "start": 413.67999999999995, "end": 415.91999999999996, "text": " So, I'm not even sure I had, at that time,", "tokens": [51256, 407, 11, 286, 478, 406, 754, 988, 286, 632, 11, 412, 300, 565, 11, 51368], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 142, "seek": 39584, "start": 415.91999999999996, "end": 418.47999999999996, "text": " I was so deep in just, you know, trying to get,", "tokens": [51368, 286, 390, 370, 2452, 294, 445, 11, 291, 458, 11, 1382, 281, 483, 11, 51496], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 143, "seek": 39584, "start": 418.47999999999996, "end": 420.79999999999995, "text": " you know, the recommendations working for Reels", "tokens": [51496, 291, 458, 11, 264, 10434, 1364, 337, 1300, 1625, 51612], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 144, "seek": 39584, "start": 420.79999999999995, "end": 422.55999999999995, "text": " and other content, because I mean,", "tokens": [51612, 293, 661, 2701, 11, 570, 286, 914, 11, 51700], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 145, "seek": 39584, "start": 422.55999999999995, "end": 424.96, "text": " that's just such a big unlock for Instagram and Facebook", "tokens": [51700, 300, 311, 445, 1270, 257, 955, 11634, 337, 5281, 293, 4384, 51820], "temperature": 0.0, "avg_logprob": -0.1218931346596358, "compression_ratio": 1.9, "no_speech_prob": 0.0023229222279042006}, {"id": 146, "seek": 42496, "start": 424.96, "end": 426.71999999999997, "text": " to now being able to show people content", "tokens": [50364, 281, 586, 885, 1075, 281, 855, 561, 2701, 50452], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 147, "seek": 42496, "start": 426.71999999999997, "end": 428.23999999999995, "text": " that's interesting to them that they're from people", "tokens": [50452, 300, 311, 1880, 281, 552, 300, 436, 434, 490, 561, 50528], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 148, "seek": 42496, "start": 428.23999999999995, "end": 429.84, "text": " that they're not even following.", "tokens": [50528, 300, 436, 434, 406, 754, 3480, 13, 50608], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 149, "seek": 42496, "start": 429.84, "end": 435.28, "text": " But, yeah, that ended up being a very good decision", "tokens": [50608, 583, 11, 1338, 11, 300, 4590, 493, 885, 257, 588, 665, 3537, 50880], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 150, "seek": 42496, "start": 435.28, "end": 436.0, "text": " in retrospect.", "tokens": [50880, 294, 34997, 13, 50916], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 151, "seek": 42496, "start": 436.0, "end": 436.96, "text": " Yeah, yeah.", "tokens": [50916, 865, 11, 1338, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 152, "seek": 42496, "start": 436.96, "end": 438.32, "text": " Okay, and it came from being behind.", "tokens": [50964, 1033, 11, 293, 309, 1361, 490, 885, 2261, 13, 51032], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 153, "seek": 42496, "start": 438.32, "end": 440.64, "text": " So, then it wasn't like I was, you know,", "tokens": [51032, 407, 11, 550, 309, 2067, 380, 411, 286, 390, 11, 291, 458, 11, 51148], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 154, "seek": 42496, "start": 440.64, "end": 442.15999999999997, "text": " it wasn't like, oh, I was so far ahead.", "tokens": [51148, 309, 2067, 380, 411, 11, 1954, 11, 286, 390, 370, 1400, 2286, 13, 51224], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 155, "seek": 42496, "start": 442.15999999999997, "end": 443.44, "text": " Actually, most of the times, I think,", "tokens": [51224, 5135, 11, 881, 295, 264, 1413, 11, 286, 519, 11, 51288], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 156, "seek": 42496, "start": 443.44, "end": 445.67999999999995, "text": " where we kind of make some decision", "tokens": [51288, 689, 321, 733, 295, 652, 512, 3537, 51400], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 157, "seek": 42496, "start": 445.67999999999995, "end": 448.79999999999995, "text": " that ends up seeming good is because we messed something up", "tokens": [51400, 300, 5314, 493, 1643, 278, 665, 307, 570, 321, 16507, 746, 493, 51556], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 158, "seek": 42496, "start": 448.79999999999995, "end": 450.64, "text": " before and just didn't want to repeat the mistake.", "tokens": [51556, 949, 293, 445, 994, 380, 528, 281, 7149, 264, 6146, 13, 51648], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 159, "seek": 42496, "start": 451.28, "end": 452.15999999999997, "text": " This is a total detour,", "tokens": [51680, 639, 307, 257, 3217, 1141, 396, 11, 51724], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 160, "seek": 42496, "start": 452.15999999999997, "end": 453.84, "text": " but actually, I want to ask about this while we're on this.", "tokens": [51724, 457, 767, 11, 286, 528, 281, 1029, 466, 341, 1339, 321, 434, 322, 341, 13, 51808], "temperature": 0.0, "avg_logprob": -0.13626390798932556, "compression_ratio": 1.7694610778443114, "no_speech_prob": 0.00419782567769289}, {"id": 161, "seek": 45384, "start": 453.84, "end": 455.67999999999995, "text": " We'll get back to AI in a second.", "tokens": [50364, 492, 603, 483, 646, 281, 7318, 294, 257, 1150, 13, 50456], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 162, "seek": 45384, "start": 456.47999999999996, "end": 458.23999999999995, "text": " So, you didn't suffer one billion,", "tokens": [50496, 407, 11, 291, 994, 380, 9753, 472, 5218, 11, 50584], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 163, "seek": 45384, "start": 458.23999999999995, "end": 459.52, "text": " but presumably there's some amount", "tokens": [50584, 457, 26742, 456, 311, 512, 2372, 50648], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 164, "seek": 45384, "start": 459.52, "end": 460.71999999999997, "text": " you would have sold for, right?", "tokens": [50648, 291, 576, 362, 3718, 337, 11, 558, 30, 50708], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 165, "seek": 45384, "start": 460.71999999999997, "end": 462.47999999999996, "text": " Did you write down in your head, like,", "tokens": [50708, 2589, 291, 2464, 760, 294, 428, 1378, 11, 411, 11, 50796], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 166, "seek": 45384, "start": 462.47999999999996, "end": 465.11999999999995, "text": " I think the actual valuation of Facebook at the time is this", "tokens": [50796, 286, 519, 264, 3539, 38546, 295, 4384, 412, 264, 565, 307, 341, 50928], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 167, "seek": 45384, "start": 465.11999999999995, "end": 466.96, "text": " and they're not actually getting the valuation right?", "tokens": [50928, 293, 436, 434, 406, 767, 1242, 264, 38546, 558, 30, 51020], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 168, "seek": 45384, "start": 466.96, "end": 469.03999999999996, "text": " Like, the average $5 trillion, of course, you would have sold.", "tokens": [51020, 1743, 11, 264, 4274, 1848, 20, 18723, 11, 295, 1164, 11, 291, 576, 362, 3718, 13, 51124], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 169, "seek": 45384, "start": 469.03999999999996, "end": 472.0, "text": " So, like, how did you think about that choice?", "tokens": [51124, 407, 11, 411, 11, 577, 630, 291, 519, 466, 300, 3922, 30, 51272], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 170, "seek": 45384, "start": 472.71999999999997, "end": 473.52, "text": " Yeah, I don't know.", "tokens": [51308, 865, 11, 286, 500, 380, 458, 13, 51348], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 171, "seek": 45384, "start": 473.52, "end": 476.08, "text": " I mean, look, I think some of these things are just personal.", "tokens": [51348, 286, 914, 11, 574, 11, 286, 519, 512, 295, 613, 721, 366, 445, 2973, 13, 51476], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 172, "seek": 45384, "start": 478.15999999999997, "end": 481.03999999999996, "text": " I don't know at the time that I was sophisticated enough", "tokens": [51580, 286, 500, 380, 458, 412, 264, 565, 300, 286, 390, 16950, 1547, 51724], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 173, "seek": 45384, "start": 481.03999999999996, "end": 482.08, "text": " to do that analysis,", "tokens": [51724, 281, 360, 300, 5215, 11, 51776], "temperature": 0.0, "avg_logprob": -0.12520769834518433, "compression_ratio": 1.72, "no_speech_prob": 0.0037064538337290287}, {"id": 174, "seek": 48208, "start": 482.08, "end": 485.28, "text": " but I had all these people around me who were making", "tokens": [50364, 457, 286, 632, 439, 613, 561, 926, 385, 567, 645, 1455, 50524], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 175, "seek": 48208, "start": 485.28, "end": 489.12, "text": " all these arguments for how, like, a billion dollars was,", "tokens": [50524, 439, 613, 12869, 337, 577, 11, 411, 11, 257, 5218, 3808, 390, 11, 50716], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 176, "seek": 48208, "start": 489.12, "end": 491.2, "text": " you know, it's like, here's the revenue that we need to make", "tokens": [50716, 291, 458, 11, 309, 311, 411, 11, 510, 311, 264, 9324, 300, 321, 643, 281, 652, 50820], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 177, "seek": 48208, "start": 491.2, "end": 492.64, "text": " and here's how big we need to be", "tokens": [50820, 293, 510, 311, 577, 955, 321, 643, 281, 312, 50892], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 178, "seek": 48208, "start": 492.64, "end": 494.64, "text": " and, like, it's clearly so many years in the future.", "tokens": [50892, 293, 11, 411, 11, 309, 311, 4448, 370, 867, 924, 294, 264, 2027, 13, 50992], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 179, "seek": 48208, "start": 494.64, "end": 496.56, "text": " Like, and it was, it was very far ahead", "tokens": [50992, 1743, 11, 293, 309, 390, 11, 309, 390, 588, 1400, 2286, 51088], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 180, "seek": 48208, "start": 496.56, "end": 498.08, "text": " of where we were at the time.", "tokens": [51088, 295, 689, 321, 645, 412, 264, 565, 13, 51164], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 181, "seek": 48208, "start": 498.08, "end": 503.03999999999996, "text": " And I don't know, I didn't really have the financial sophistication", "tokens": [51164, 400, 286, 500, 380, 458, 11, 286, 994, 380, 534, 362, 264, 4669, 15572, 399, 51412], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 182, "seek": 48208, "start": 503.03999999999996, "end": 506.24, "text": " to really even engage with that kind of debate.", "tokens": [51412, 281, 534, 754, 4683, 365, 300, 733, 295, 7958, 13, 51572], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 183, "seek": 48208, "start": 506.24, "end": 509.52, "text": " I just, I think I sort of deep down believed", "tokens": [51572, 286, 445, 11, 286, 519, 286, 1333, 295, 2452, 760, 7847, 51736], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 184, "seek": 48208, "start": 509.52, "end": 510.64, "text": " in what we were doing.", "tokens": [51736, 294, 437, 321, 645, 884, 13, 51792], "temperature": 0.0, "avg_logprob": -0.09000799462601945, "compression_ratio": 1.7560137457044673, "no_speech_prob": 0.0013667675666511059}, {"id": 185, "seek": 51064, "start": 510.64, "end": 512.0, "text": " And I did some analysis.", "tokens": [50364, 400, 286, 630, 512, 5215, 13, 50432], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 186, "seek": 51064, "start": 513.84, "end": 518.64, "text": " I was like, okay, well, what would I go do if I wasn't doing this?", "tokens": [50524, 286, 390, 411, 11, 1392, 11, 731, 11, 437, 576, 286, 352, 360, 498, 286, 2067, 380, 884, 341, 30, 50764], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 187, "seek": 51064, "start": 518.64, "end": 521.36, "text": " It's like, well, I really like building things", "tokens": [50764, 467, 311, 411, 11, 731, 11, 286, 534, 411, 2390, 721, 50900], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 188, "seek": 51064, "start": 521.36, "end": 523.12, "text": " and I like helping people communicate", "tokens": [50900, 293, 286, 411, 4315, 561, 7890, 50988], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 189, "seek": 51064, "start": 523.12, "end": 526.56, "text": " and I like understanding what's going on with people", "tokens": [50988, 293, 286, 411, 3701, 437, 311, 516, 322, 365, 561, 51160], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 190, "seek": 51064, "start": 526.56, "end": 528.0, "text": " and the dynamics between people.", "tokens": [51160, 293, 264, 15679, 1296, 561, 13, 51232], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 191, "seek": 51064, "start": 528.0, "end": 530.08, "text": " So, I think if I sold this company,", "tokens": [51232, 407, 11, 286, 519, 498, 286, 3718, 341, 2237, 11, 51336], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 192, "seek": 51064, "start": 530.08, "end": 531.92, "text": " I'd just go build another company like this.", "tokens": [51336, 286, 1116, 445, 352, 1322, 1071, 2237, 411, 341, 13, 51428], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 193, "seek": 51064, "start": 531.92, "end": 534.48, "text": " And I kind of like the one I have.", "tokens": [51428, 400, 286, 733, 295, 411, 264, 472, 286, 362, 13, 51556], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 194, "seek": 51064, "start": 534.48, "end": 538.56, "text": " So, so, I mean, you know, what's, why, why, right?", "tokens": [51556, 407, 11, 370, 11, 286, 914, 11, 291, 458, 11, 437, 311, 11, 983, 11, 983, 11, 558, 30, 51760], "temperature": 0.0, "avg_logprob": -0.09364841167743389, "compression_ratio": 1.7581967213114753, "no_speech_prob": 0.00019108627748209983}, {"id": 195, "seek": 53856, "start": 538.56, "end": 540.9599999999999, "text": " But I don't know.", "tokens": [50364, 583, 286, 500, 380, 458, 13, 50484], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 196, "seek": 53856, "start": 540.9599999999999, "end": 544.0799999999999, "text": " I think a lot of the biggest bets that people make", "tokens": [50484, 286, 519, 257, 688, 295, 264, 3880, 39922, 300, 561, 652, 50640], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 197, "seek": 53856, "start": 545.52, "end": 548.2399999999999, "text": " are often just based on conviction and values.", "tokens": [50712, 366, 2049, 445, 2361, 322, 24837, 293, 4190, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 198, "seek": 53856, "start": 549.1999999999999, "end": 553.1999999999999, "text": " Not, it's actually usually very hard to do the analyses", "tokens": [50896, 1726, 11, 309, 311, 767, 2673, 588, 1152, 281, 360, 264, 37560, 51096], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 199, "seek": 53856, "start": 553.1999999999999, "end": 554.56, "text": " trying to connect the dots forward.", "tokens": [51096, 1382, 281, 1745, 264, 15026, 2128, 13, 51164], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 200, "seek": 53856, "start": 554.56, "end": 555.1199999999999, "text": " Yeah.", "tokens": [51164, 865, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 201, "seek": 53856, "start": 555.1199999999999, "end": 558.16, "text": " So, you've had Facebook AI research for a long time.", "tokens": [51192, 407, 11, 291, 600, 632, 4384, 7318, 2132, 337, 257, 938, 565, 13, 51344], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 202, "seek": 53856, "start": 559.28, "end": 561.76, "text": " Now it's become seemingly central to your company.", "tokens": [51400, 823, 309, 311, 1813, 18709, 5777, 281, 428, 2237, 13, 51524], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 203, "seek": 53856, "start": 563.1199999999999, "end": 567.04, "text": " At what point did making AGI or whatever,", "tokens": [51592, 1711, 437, 935, 630, 1455, 316, 26252, 420, 2035, 11, 51788], "temperature": 0.0, "avg_logprob": -0.1275995922088623, "compression_ratio": 1.4958333333333333, "no_speech_prob": 0.0001686293544480577}, {"id": 204, "seek": 56704, "start": 567.04, "end": 568.64, "text": " however you consider that mission,", "tokens": [50364, 4461, 291, 1949, 300, 4447, 11, 50444], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 205, "seek": 56704, "start": 568.64, "end": 569.4399999999999, "text": " at what point is that like,", "tokens": [50444, 412, 437, 935, 307, 300, 411, 11, 50484], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 206, "seek": 56704, "start": 569.4399999999999, "end": 571.52, "text": " this is a Cree priority of what Meta is doing?", "tokens": [50484, 341, 307, 257, 383, 701, 9365, 295, 437, 6377, 64, 307, 884, 30, 50588], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 207, "seek": 56704, "start": 572.8, "end": 572.9599999999999, "text": " Yeah.", "tokens": [50652, 865, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 208, "seek": 56704, "start": 572.9599999999999, "end": 574.9599999999999, "text": " I mean, it's been a big deal for a while.", "tokens": [50660, 286, 914, 11, 309, 311, 668, 257, 955, 2028, 337, 257, 1339, 13, 50760], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 209, "seek": 56704, "start": 574.9599999999999, "end": 578.7199999999999, "text": " So, we started fair about 10 years ago.", "tokens": [50760, 407, 11, 321, 1409, 3143, 466, 1266, 924, 2057, 13, 50948], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 210, "seek": 56704, "start": 578.7199999999999, "end": 584.3199999999999, "text": " And the idea was that along the way to general intelligence", "tokens": [50948, 400, 264, 1558, 390, 300, 2051, 264, 636, 281, 2674, 7599, 51228], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 211, "seek": 56704, "start": 584.3199999999999, "end": 586.64, "text": " or AI, like full AI, whatever you want to call it,", "tokens": [51228, 420, 7318, 11, 411, 1577, 7318, 11, 2035, 291, 528, 281, 818, 309, 11, 51344], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 212, "seek": 56704, "start": 587.36, "end": 589.28, "text": " there can be all these different innovations", "tokens": [51380, 456, 393, 312, 439, 613, 819, 24283, 51476], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 213, "seek": 56704, "start": 589.28, "end": 591.68, "text": " and that's going to just improve everything that we do.", "tokens": [51476, 293, 300, 311, 516, 281, 445, 3470, 1203, 300, 321, 360, 13, 51596], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 214, "seek": 56704, "start": 591.68, "end": 595.4399999999999, "text": " So, we didn't kind of conceive it as a product.", "tokens": [51596, 407, 11, 321, 994, 380, 733, 295, 48605, 309, 382, 257, 1674, 13, 51784], "temperature": 0.0, "avg_logprob": -0.11256342945676862, "compression_ratio": 1.6091549295774648, "no_speech_prob": 0.0033752971794456244}, {"id": 215, "seek": 59544, "start": 595.44, "end": 597.5200000000001, "text": " It was more kind of a research group.", "tokens": [50364, 467, 390, 544, 733, 295, 257, 2132, 1594, 13, 50468], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 216, "seek": 59544, "start": 598.08, "end": 601.2800000000001, "text": " And over the last 10 years,", "tokens": [50496, 400, 670, 264, 1036, 1266, 924, 11, 50656], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 217, "seek": 59544, "start": 601.2800000000001, "end": 603.36, "text": " it has created a lot of different things", "tokens": [50656, 309, 575, 2942, 257, 688, 295, 819, 721, 50760], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 218, "seek": 59544, "start": 603.36, "end": 606.32, "text": " that have basically improved all of our products", "tokens": [50760, 300, 362, 1936, 9689, 439, 295, 527, 3383, 50908], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 219, "seek": 59544, "start": 607.0400000000001, "end": 609.84, "text": " and advanced the field and allowed other people in the field", "tokens": [50944, 293, 7339, 264, 2519, 293, 4350, 661, 561, 294, 264, 2519, 51084], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 220, "seek": 59544, "start": 609.84, "end": 611.7600000000001, "text": " to create things that have improved our products too.", "tokens": [51084, 281, 1884, 721, 300, 362, 9689, 527, 3383, 886, 13, 51180], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 221, "seek": 59544, "start": 611.7600000000001, "end": 613.0400000000001, "text": " So, I think that that's been great.", "tokens": [51180, 407, 11, 286, 519, 300, 300, 311, 668, 869, 13, 51244], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 222, "seek": 59544, "start": 613.6, "end": 618.4000000000001, "text": " But there's obviously a big change in the last few years", "tokens": [51272, 583, 456, 311, 2745, 257, 955, 1319, 294, 264, 1036, 1326, 924, 51512], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 223, "seek": 59544, "start": 618.4000000000001, "end": 620.5600000000001, "text": " when ChatGPT comes out,", "tokens": [51512, 562, 27503, 38, 47, 51, 1487, 484, 11, 51620], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 224, "seek": 59544, "start": 621.2, "end": 623.5200000000001, "text": " the diffusion models or an image creation come out.", "tokens": [51652, 264, 25242, 5245, 420, 364, 3256, 8016, 808, 484, 13, 51768], "temperature": 0.0, "avg_logprob": -0.12244486601456352, "compression_ratio": 1.681992337164751, "no_speech_prob": 0.0005882914992980659}, {"id": 225, "seek": 62352, "start": 624.0, "end": 625.76, "text": " I mean, this is some pretty wild stuff", "tokens": [50388, 286, 914, 11, 341, 307, 512, 1238, 4868, 1507, 50476], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 226, "seek": 62352, "start": 625.76, "end": 627.92, "text": " that I think is pretty clearly going to affect", "tokens": [50476, 300, 286, 519, 307, 1238, 4448, 516, 281, 3345, 50584], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 227, "seek": 62352, "start": 627.92, "end": 632.3199999999999, "text": " how people interact with every app that's out there.", "tokens": [50584, 577, 561, 4648, 365, 633, 724, 300, 311, 484, 456, 13, 50804], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 228, "seek": 62352, "start": 634.4, "end": 639.6, "text": " At that point, we started a second group, the GenAI group,", "tokens": [50908, 1711, 300, 935, 11, 321, 1409, 257, 1150, 1594, 11, 264, 3632, 48698, 1594, 11, 51168], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 229, "seek": 62352, "start": 640.48, "end": 644.4, "text": " with the goal of basically bringing that stuff into our products,", "tokens": [51212, 365, 264, 3387, 295, 1936, 5062, 300, 1507, 666, 527, 3383, 11, 51408], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 230, "seek": 62352, "start": 644.4, "end": 646.48, "text": " so building leading foundation models", "tokens": [51408, 370, 2390, 5775, 7030, 5245, 51512], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 231, "seek": 62352, "start": 646.48, "end": 648.88, "text": " that would sort of power all these different products.", "tokens": [51512, 300, 576, 1333, 295, 1347, 439, 613, 819, 3383, 13, 51632], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 232, "seek": 62352, "start": 649.4399999999999, "end": 651.92, "text": " And initially, when we started doing that,", "tokens": [51660, 400, 9105, 11, 562, 321, 1409, 884, 300, 11, 51784], "temperature": 0.0, "avg_logprob": -0.15493818656685426, "compression_ratio": 1.6556016597510372, "no_speech_prob": 0.0007552818860858679}, {"id": 233, "seek": 65352, "start": 653.76, "end": 655.12, "text": " the theory at first was, hey,", "tokens": [50376, 264, 5261, 412, 700, 390, 11, 4177, 11, 50444], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 234, "seek": 65352, "start": 655.68, "end": 658.56, "text": " a lot of the stuff that we're doing is pretty social, right?", "tokens": [50472, 257, 688, 295, 264, 1507, 300, 321, 434, 884, 307, 1238, 2093, 11, 558, 30, 50616], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 235, "seek": 65352, "start": 658.56, "end": 661.92, "text": " So, it's helping people interact with creators,", "tokens": [50616, 407, 11, 309, 311, 4315, 561, 4648, 365, 16039, 11, 50784], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 236, "seek": 65352, "start": 661.92, "end": 664.88, "text": " helping people interact with businesses.", "tokens": [50784, 4315, 561, 4648, 365, 6011, 13, 50932], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 237, "seek": 65352, "start": 664.88, "end": 668.16, "text": " So, the businesses can sell things or do customer support", "tokens": [50932, 407, 11, 264, 6011, 393, 3607, 721, 420, 360, 5474, 1406, 51096], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 238, "seek": 65352, "start": 668.16, "end": 671.1999999999999, "text": " or basic assistant functionality for,", "tokens": [51096, 420, 3875, 10994, 14980, 337, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 239, "seek": 65352, "start": 672.16, "end": 674.88, "text": " you know, whether it's for our apps or the smart glasses", "tokens": [51296, 291, 458, 11, 1968, 309, 311, 337, 527, 7733, 420, 264, 4069, 10812, 51432], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 240, "seek": 65352, "start": 674.88, "end": 676.96, "text": " or VR or like all these different things.", "tokens": [51432, 420, 13722, 420, 411, 439, 613, 819, 721, 13, 51536], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 241, "seek": 65352, "start": 677.6, "end": 681.6, "text": " So, initially, it wasn't completely clear", "tokens": [51568, 407, 11, 9105, 11, 309, 2067, 380, 2584, 1850, 51768], "temperature": 0.0, "avg_logprob": -0.1343978364890981, "compression_ratio": 1.6910569105691058, "no_speech_prob": 0.0002530996862333268}, {"id": 242, "seek": 68160, "start": 681.6, "end": 685.28, "text": " that you were going to need kind of full AGI", "tokens": [50364, 300, 291, 645, 516, 281, 643, 733, 295, 1577, 316, 26252, 50548], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 243, "seek": 68160, "start": 686.08, "end": 687.6800000000001, "text": " to be able to support those use cases.", "tokens": [50588, 281, 312, 1075, 281, 1406, 729, 764, 3331, 13, 50668], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 244, "seek": 68160, "start": 687.6800000000001, "end": 689.52, "text": " But then through working on them,", "tokens": [50668, 583, 550, 807, 1364, 322, 552, 11, 50760], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 245, "seek": 68160, "start": 689.52, "end": 691.52, "text": " I think it's actually become clear that you do, right?", "tokens": [50760, 286, 519, 309, 311, 767, 1813, 1850, 300, 291, 360, 11, 558, 30, 50860], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 246, "seek": 68160, "start": 691.52, "end": 692.48, "text": " In all these subtle ways.", "tokens": [50860, 682, 439, 613, 13743, 2098, 13, 50908], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 247, "seek": 68160, "start": 692.48, "end": 695.6800000000001, "text": " So, for example, for Llama 2, when we were working on it,", "tokens": [50908, 407, 11, 337, 1365, 11, 337, 32717, 2404, 568, 11, 562, 321, 645, 1364, 322, 309, 11, 51068], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 248, "seek": 68160, "start": 695.6800000000001, "end": 697.2, "text": " we didn't prioritize coding.", "tokens": [51068, 321, 994, 380, 25164, 17720, 13, 51144], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 249, "seek": 68160, "start": 697.2, "end": 699.28, "text": " And the reason why we didn't prioritize coding", "tokens": [51144, 400, 264, 1778, 983, 321, 994, 380, 25164, 17720, 51248], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 250, "seek": 68160, "start": 699.28, "end": 701.52, "text": " is because people aren't going to ask MetaAI", "tokens": [51248, 307, 570, 561, 3212, 380, 516, 281, 1029, 6377, 64, 48698, 51360], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 251, "seek": 68160, "start": 701.52, "end": 703.36, "text": " a lot of coding questions in WhatsApp.", "tokens": [51360, 257, 688, 295, 17720, 1651, 294, 30513, 13, 51452], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 252, "seek": 68160, "start": 703.36, "end": 704.4, "text": " Now they will, right?", "tokens": [51452, 823, 436, 486, 11, 558, 30, 51504], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 253, "seek": 68160, "start": 704.4, "end": 704.88, "text": " Well, I don't know.", "tokens": [51504, 1042, 11, 286, 500, 380, 458, 13, 51528], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 254, "seek": 68160, "start": 704.88, "end": 706.96, "text": " I'm not sure that WhatsApp is like the UI", "tokens": [51528, 286, 478, 406, 988, 300, 30513, 307, 411, 264, 15682, 51632], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 255, "seek": 68160, "start": 706.96, "end": 708.96, "text": " that people are going to be doing a lot of coding questions.", "tokens": [51632, 300, 561, 366, 516, 281, 312, 884, 257, 688, 295, 17720, 1651, 13, 51732], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 256, "seek": 68160, "start": 708.96, "end": 711.12, "text": " So, we're like, all right, look, in terms of the things that,", "tokens": [51732, 407, 11, 321, 434, 411, 11, 439, 558, 11, 574, 11, 294, 2115, 295, 264, 721, 300, 11, 51840], "temperature": 0.0, "avg_logprob": -0.09938173346180733, "compression_ratio": 1.8057971014492753, "no_speech_prob": 0.005058208014816046}, {"id": 257, "seek": 71112, "start": 711.2, "end": 712.88, "text": " you know, or Facebook or Instagram", "tokens": [50368, 291, 458, 11, 420, 4384, 420, 5281, 50452], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 258, "seek": 71112, "start": 712.88, "end": 714.4, "text": " or, you know, those different services,", "tokens": [50452, 420, 11, 291, 458, 11, 729, 819, 3328, 11, 50528], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 259, "seek": 71112, "start": 714.4, "end": 718.16, "text": " maybe the website, right, meta.ai that we're launching, I think.", "tokens": [50528, 1310, 264, 3144, 11, 558, 11, 19616, 13, 1301, 300, 321, 434, 18354, 11, 286, 519, 13, 50716], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 260, "seek": 71112, "start": 718.16, "end": 721.44, "text": " But the thing that was sort of, I think,", "tokens": [50716, 583, 264, 551, 300, 390, 1333, 295, 11, 286, 519, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 261, "seek": 71112, "start": 721.44, "end": 726.16, "text": " has been a somewhat surprising result over the last 18 months", "tokens": [50880, 575, 668, 257, 8344, 8830, 1874, 670, 264, 1036, 2443, 2493, 51116], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 262, "seek": 71112, "start": 726.16, "end": 730.72, "text": " is that it turns out that coding is important", "tokens": [51116, 307, 300, 309, 4523, 484, 300, 17720, 307, 1021, 51344], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 263, "seek": 71112, "start": 730.72, "end": 732.48, "text": " for a lot of domains, not just coding, right?", "tokens": [51344, 337, 257, 688, 295, 25514, 11, 406, 445, 17720, 11, 558, 30, 51432], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 264, "seek": 71112, "start": 732.48, "end": 735.44, "text": " So, even if people aren't asking coding questions to the models,", "tokens": [51432, 407, 11, 754, 498, 561, 3212, 380, 3365, 17720, 1651, 281, 264, 5245, 11, 51580], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 265, "seek": 71112, "start": 736.16, "end": 740.08, "text": " training the models on coding helps them just be more rigorous", "tokens": [51616, 3097, 264, 5245, 322, 17720, 3665, 552, 445, 312, 544, 29882, 51812], "temperature": 0.0, "avg_logprob": -0.1442630231873063, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.0011691454565152526}, {"id": 266, "seek": 74008, "start": 740.08, "end": 743.36, "text": " and answer the question and kind of help reason", "tokens": [50364, 293, 1867, 264, 1168, 293, 733, 295, 854, 1778, 50528], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 267, "seek": 74008, "start": 743.36, "end": 745.2800000000001, "text": " across a lot of different types of domains.", "tokens": [50528, 2108, 257, 688, 295, 819, 3467, 295, 25514, 13, 50624], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 268, "seek": 74008, "start": 745.2800000000001, "end": 746.4000000000001, "text": " Okay, so that's one example where it's like,", "tokens": [50624, 1033, 11, 370, 300, 311, 472, 1365, 689, 309, 311, 411, 11, 50680], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 269, "seek": 74008, "start": 746.4000000000001, "end": 747.36, "text": " all right, so for Llama 3,", "tokens": [50680, 439, 558, 11, 370, 337, 32717, 2404, 805, 11, 50728], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 270, "seek": 74008, "start": 747.36, "end": 749.6800000000001, "text": " we're like really focused on training it with a lot of coding", "tokens": [50728, 321, 434, 411, 534, 5178, 322, 3097, 309, 365, 257, 688, 295, 17720, 50844], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 271, "seek": 74008, "start": 749.6800000000001, "end": 750.32, "text": " because it's like, all right,", "tokens": [50844, 570, 309, 311, 411, 11, 439, 558, 11, 50876], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 272, "seek": 74008, "start": 750.32, "end": 752.1600000000001, "text": " that's going to make it better on all these things,", "tokens": [50876, 300, 311, 516, 281, 652, 309, 1101, 322, 439, 613, 721, 11, 50968], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 273, "seek": 74008, "start": 752.1600000000001, "end": 753.5200000000001, "text": " even if people aren't answering,", "tokens": [50968, 754, 498, 561, 3212, 380, 13430, 11, 51036], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 274, "seek": 74008, "start": 753.5200000000001, "end": 755.2800000000001, "text": " aren't asking primarily coding questions.", "tokens": [51036, 3212, 380, 3365, 10029, 17720, 1651, 13, 51124], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 275, "seek": 74008, "start": 756.08, "end": 757.6800000000001, "text": " Reasoning, I think, is another example.", "tokens": [51164, 39693, 278, 11, 286, 519, 11, 307, 1071, 1365, 13, 51244], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 276, "seek": 74008, "start": 758.32, "end": 761.6, "text": " It's like, okay, yeah, maybe you want to chat with a creator", "tokens": [51276, 467, 311, 411, 11, 1392, 11, 1338, 11, 1310, 291, 528, 281, 5081, 365, 257, 14181, 51440], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 277, "seek": 74008, "start": 761.6, "end": 762.96, "text": " or, you know, you're a business", "tokens": [51440, 420, 11, 291, 458, 11, 291, 434, 257, 1606, 51508], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 278, "seek": 74008, "start": 762.96, "end": 765.2, "text": " and you're trying to interact with a customer.", "tokens": [51508, 293, 291, 434, 1382, 281, 4648, 365, 257, 5474, 13, 51620], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 279, "seek": 74008, "start": 765.2, "end": 766.72, "text": " You know, that interaction is not just like,", "tokens": [51620, 509, 458, 11, 300, 9285, 307, 406, 445, 411, 11, 51696], "temperature": 0.0, "avg_logprob": -0.10835776970400447, "compression_ratio": 1.8338368580060422, "no_speech_prob": 0.0006262595416046679}, {"id": 280, "seek": 76672, "start": 766.72, "end": 769.2, "text": " okay, the person sends you a message", "tokens": [50364, 1392, 11, 264, 954, 14790, 291, 257, 3636, 50488], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 281, "seek": 76672, "start": 769.2, "end": 770.64, "text": " and you just reply, right?", "tokens": [50488, 293, 291, 445, 16972, 11, 558, 30, 50560], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 282, "seek": 76672, "start": 770.64, "end": 773.0400000000001, "text": " It's like a multi-step interaction", "tokens": [50560, 467, 311, 411, 257, 4825, 12, 16792, 9285, 50680], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 283, "seek": 76672, "start": 773.0400000000001, "end": 774.5600000000001, "text": " where you're trying to think through", "tokens": [50680, 689, 291, 434, 1382, 281, 519, 807, 50756], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 284, "seek": 76672, "start": 774.5600000000001, "end": 776.4, "text": " how do I accomplish the person's goals", "tokens": [50756, 577, 360, 286, 9021, 264, 954, 311, 5493, 50848], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 285, "seek": 76672, "start": 776.4, "end": 778.72, "text": " and, you know, a lot of times when a customer comes,", "tokens": [50848, 293, 11, 291, 458, 11, 257, 688, 295, 1413, 562, 257, 5474, 1487, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 286, "seek": 76672, "start": 778.72, "end": 780.64, "text": " they don't necessarily know exactly", "tokens": [50964, 436, 500, 380, 4725, 458, 2293, 51060], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 287, "seek": 76672, "start": 780.64, "end": 782.64, "text": " what they're looking for or how to ask their questions.", "tokens": [51060, 437, 436, 434, 1237, 337, 420, 577, 281, 1029, 641, 1651, 13, 51160], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 288, "seek": 76672, "start": 782.64, "end": 784.96, "text": " So, it's not really the job of the AI", "tokens": [51160, 407, 11, 309, 311, 406, 534, 264, 1691, 295, 264, 7318, 51276], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 289, "seek": 76672, "start": 784.96, "end": 786.4, "text": " to just respond to the question.", "tokens": [51276, 281, 445, 4196, 281, 264, 1168, 13, 51348], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 290, "seek": 76672, "start": 786.4, "end": 788.64, "text": " It's like, you need to kind of think about it more holistically.", "tokens": [51348, 467, 311, 411, 11, 291, 643, 281, 733, 295, 519, 466, 309, 544, 4091, 20458, 13, 51460], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 291, "seek": 76672, "start": 788.64, "end": 790.4, "text": " It really becomes a reasoning problem, right?", "tokens": [51460, 467, 534, 3643, 257, 21577, 1154, 11, 558, 30, 51548], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 292, "seek": 76672, "start": 790.4, "end": 791.52, "text": " So, if someone else, you know,", "tokens": [51548, 407, 11, 498, 1580, 1646, 11, 291, 458, 11, 51604], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 293, "seek": 76672, "start": 791.52, "end": 794.1600000000001, "text": " solves reasoning or makes good advances on reasoning,", "tokens": [51604, 39890, 21577, 420, 1669, 665, 25297, 322, 21577, 11, 51736], "temperature": 0.0, "avg_logprob": -0.09970540585725204, "compression_ratio": 1.7757575757575759, "no_speech_prob": 0.00141024065669626}, {"id": 294, "seek": 79416, "start": 794.16, "end": 797.04, "text": " and we're sitting here with a basic chat bot,", "tokens": [50364, 293, 321, 434, 3798, 510, 365, 257, 3875, 5081, 10592, 11, 50508], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 295, "seek": 79416, "start": 797.04, "end": 798.48, "text": " then, like, our product is lame", "tokens": [50508, 550, 11, 411, 11, 527, 1674, 307, 27635, 50580], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 296, "seek": 79416, "start": 798.48, "end": 800.24, "text": " compared to what other people are building.", "tokens": [50580, 5347, 281, 437, 661, 561, 366, 2390, 13, 50668], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 297, "seek": 79416, "start": 800.24, "end": 801.52, "text": " So, it's like, it's okay.", "tokens": [50668, 407, 11, 309, 311, 411, 11, 309, 311, 1392, 13, 50732], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 298, "seek": 79416, "start": 801.52, "end": 803.36, "text": " So, at the end of the day, we've got,", "tokens": [50732, 407, 11, 412, 264, 917, 295, 264, 786, 11, 321, 600, 658, 11, 50824], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 299, "seek": 79416, "start": 803.36, "end": 805.52, "text": " we, you know, we basically realized", "tokens": [50824, 321, 11, 291, 458, 11, 321, 1936, 5334, 50932], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 300, "seek": 79416, "start": 805.52, "end": 807.1999999999999, "text": " we've got to solve general intelligence", "tokens": [50932, 321, 600, 658, 281, 5039, 2674, 7599, 51016], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 301, "seek": 79416, "start": 808.3199999999999, "end": 811.04, "text": " and we just kind of upped the ante and the investment", "tokens": [51072, 293, 321, 445, 733, 295, 344, 3320, 264, 23411, 293, 264, 6078, 51208], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 302, "seek": 79416, "start": 811.04, "end": 812.48, "text": " to make sure that we could do that.", "tokens": [51208, 281, 652, 988, 300, 321, 727, 360, 300, 13, 51280], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 303, "seek": 79416, "start": 812.48, "end": 818.48, "text": " So, the version of Lama that's going to solve", "tokens": [51280, 407, 11, 264, 3037, 295, 441, 2404, 300, 311, 516, 281, 5039, 51580], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 304, "seek": 79416, "start": 818.48, "end": 820.9599999999999, "text": " all these use cases for users,", "tokens": [51580, 439, 613, 764, 3331, 337, 5022, 11, 51704], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 305, "seek": 79416, "start": 820.9599999999999, "end": 823.04, "text": " is that the version that will be powerful enough", "tokens": [51704, 307, 300, 264, 3037, 300, 486, 312, 4005, 1547, 51808], "temperature": 0.0, "avg_logprob": -0.104701110294887, "compression_ratio": 1.7408759124087592, "no_speech_prob": 0.00088285788660869}, {"id": 306, "seek": 82304, "start": 823.04, "end": 825.8399999999999, "text": " to, like, replace a programmer you might have in this building?", "tokens": [50364, 281, 11, 411, 11, 7406, 257, 32116, 291, 1062, 362, 294, 341, 2390, 30, 50504], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 307, "seek": 82304, "start": 826.7199999999999, "end": 827.92, "text": " I mean, I just think that all this stuff", "tokens": [50548, 286, 914, 11, 286, 445, 519, 300, 439, 341, 1507, 50608], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 308, "seek": 82304, "start": 827.92, "end": 829.36, "text": " is going to be progressive over time.", "tokens": [50608, 307, 516, 281, 312, 16131, 670, 565, 13, 50680], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 309, "seek": 82304, "start": 829.36, "end": 830.9599999999999, "text": " But, in case, Lama 10.", "tokens": [50680, 583, 11, 294, 1389, 11, 441, 2404, 1266, 13, 50760], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 310, "seek": 82304, "start": 833.92, "end": 836.4, "text": " I mean, I think that there's a lot baked into that question.", "tokens": [50908, 286, 914, 11, 286, 519, 300, 456, 311, 257, 688, 19453, 666, 300, 1168, 13, 51032], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 311, "seek": 82304, "start": 836.4, "end": 838.8, "text": " I'm not sure that we're replacing people", "tokens": [51032, 286, 478, 406, 988, 300, 321, 434, 19139, 561, 51152], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 312, "seek": 82304, "start": 838.8, "end": 842.0799999999999, "text": " as much as giving people tools to do more stuff.", "tokens": [51152, 382, 709, 382, 2902, 561, 3873, 281, 360, 544, 1507, 13, 51316], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 313, "seek": 82304, "start": 842.0799999999999, "end": 843.92, "text": " Is a programmer in this building 10x more productive", "tokens": [51316, 1119, 257, 32116, 294, 341, 2390, 1266, 87, 544, 13304, 51408], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 314, "seek": 82304, "start": 843.92, "end": 844.3199999999999, "text": " after Lama 10?", "tokens": [51408, 934, 441, 2404, 1266, 30, 51428], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 315, "seek": 82304, "start": 844.3199999999999, "end": 845.12, "text": " I would have more.", "tokens": [51428, 286, 576, 362, 544, 13, 51468], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 316, "seek": 82304, "start": 845.12, "end": 848.3199999999999, "text": " But no, I mean, look, I'm not,", "tokens": [51468, 583, 572, 11, 286, 914, 11, 574, 11, 286, 478, 406, 11, 51628], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 317, "seek": 82304, "start": 848.3199999999999, "end": 849.52, "text": " I don't believe that there's, like,", "tokens": [51628, 286, 500, 380, 1697, 300, 456, 311, 11, 411, 11, 51688], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 318, "seek": 82304, "start": 849.52, "end": 852.56, "text": " a single threshold of intelligence for humanity,", "tokens": [51688, 257, 2167, 14678, 295, 7599, 337, 10243, 11, 51840], "temperature": 0.0, "avg_logprob": -0.14381553600360822, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.0038231804501265287}, {"id": 319, "seek": 85256, "start": 852.56, "end": 854.56, "text": " because, I mean, people have different skills.", "tokens": [50364, 570, 11, 286, 914, 11, 561, 362, 819, 3942, 13, 50464], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 320, "seek": 85256, "start": 854.56, "end": 856.4, "text": " And at some point, I think that AI is going to be,", "tokens": [50464, 400, 412, 512, 935, 11, 286, 519, 300, 7318, 307, 516, 281, 312, 11, 50556], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 321, "seek": 85256, "start": 857.52, "end": 861.28, "text": " is probably going to surpass people at most of those things,", "tokens": [50612, 307, 1391, 516, 281, 27650, 561, 412, 881, 295, 729, 721, 11, 50800], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 322, "seek": 85256, "start": 861.28, "end": 863.04, "text": " depending on how powerful the models are.", "tokens": [50800, 5413, 322, 577, 4005, 264, 5245, 366, 13, 50888], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 323, "seek": 85256, "start": 863.04, "end": 866.9599999999999, "text": " But I think it's progressive.", "tokens": [50888, 583, 286, 519, 309, 311, 16131, 13, 51084], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 324, "seek": 85256, "start": 866.9599999999999, "end": 868.4, "text": " And I don't think AGI is one thing.", "tokens": [51084, 400, 286, 500, 380, 519, 316, 26252, 307, 472, 551, 13, 51156], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 325, "seek": 85256, "start": 868.4, "end": 870.9599999999999, "text": " I think it's, you're basically adding different capabilities.", "tokens": [51156, 286, 519, 309, 311, 11, 291, 434, 1936, 5127, 819, 10862, 13, 51284], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 326, "seek": 85256, "start": 870.9599999999999, "end": 875.3599999999999, "text": " So, multimodality is kind of a key one that we're focused on now,", "tokens": [51284, 407, 11, 32972, 378, 1860, 307, 733, 295, 257, 2141, 472, 300, 321, 434, 5178, 322, 586, 11, 51504], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 327, "seek": 85256, "start": 875.3599999999999, "end": 878.0, "text": " initially with photos and images and text,", "tokens": [51504, 9105, 365, 5787, 293, 5267, 293, 2487, 11, 51636], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 328, "seek": 85256, "start": 878.0, "end": 879.3599999999999, "text": " but eventually with videos.", "tokens": [51636, 457, 4728, 365, 2145, 13, 51704], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 329, "seek": 85256, "start": 879.3599999999999, "end": 881.28, "text": " And then, because we're so focused on the metaverse,", "tokens": [51704, 400, 550, 11, 570, 321, 434, 370, 5178, 322, 264, 19616, 4308, 11, 51800], "temperature": 0.0, "avg_logprob": -0.11290685895463111, "compression_ratio": 1.7441077441077442, "no_speech_prob": 0.0026307411026209593}, {"id": 330, "seek": 88128, "start": 881.36, "end": 883.4399999999999, "text": " kind of 3D type stuff is important.", "tokens": [50368, 733, 295, 805, 35, 2010, 1507, 307, 1021, 13, 50472], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 331, "seek": 88128, "start": 885.04, "end": 887.68, "text": " One modality that I'm pretty focused on that I haven't seen", "tokens": [50552, 1485, 1072, 1860, 300, 286, 478, 1238, 5178, 322, 300, 286, 2378, 380, 1612, 50684], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 332, "seek": 88128, "start": 887.68, "end": 890.56, "text": " as many other people in the industry focus on this", "tokens": [50684, 382, 867, 661, 561, 294, 264, 3518, 1879, 322, 341, 50828], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 333, "seek": 88128, "start": 890.56, "end": 893.68, "text": " is sort of like emotional understanding.", "tokens": [50828, 307, 1333, 295, 411, 6863, 3701, 13, 50984], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 334, "seek": 88128, "start": 893.68, "end": 896.3199999999999, "text": " Like, I mean, so much of the human brain", "tokens": [50984, 1743, 11, 286, 914, 11, 370, 709, 295, 264, 1952, 3567, 51116], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 335, "seek": 88128, "start": 896.3199999999999, "end": 899.1999999999999, "text": " is just dedicated to understanding people", "tokens": [51116, 307, 445, 8374, 281, 3701, 561, 51260], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 336, "seek": 88128, "start": 899.1999999999999, "end": 902.24, "text": " and kind of like understanding your expressions and emotions.", "tokens": [51260, 293, 733, 295, 411, 3701, 428, 15277, 293, 8462, 13, 51412], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 337, "seek": 88128, "start": 902.24, "end": 904.8, "text": " And I think that that's like its own whole modality, right?", "tokens": [51412, 400, 286, 519, 300, 300, 311, 411, 1080, 1065, 1379, 1072, 1860, 11, 558, 30, 51540], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 338, "seek": 88128, "start": 904.8, "end": 906.4, "text": " That, I mean, you could say, okay,", "tokens": [51540, 663, 11, 286, 914, 11, 291, 727, 584, 11, 1392, 11, 51620], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 339, "seek": 88128, "start": 906.4, "end": 907.8399999999999, "text": " maybe it's just video or image,", "tokens": [51620, 1310, 309, 311, 445, 960, 420, 3256, 11, 51692], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 340, "seek": 88128, "start": 907.8399999999999, "end": 910.88, "text": " but it's like clearly a very specialized version of those too.", "tokens": [51692, 457, 309, 311, 411, 4448, 257, 588, 19813, 3037, 295, 729, 886, 13, 51844], "temperature": 0.0, "avg_logprob": -0.10082409347313037, "compression_ratio": 1.728476821192053, "no_speech_prob": 0.004329914692789316}, {"id": 341, "seek": 91088, "start": 910.88, "end": 912.88, "text": " So, there's all these different capabilities", "tokens": [50364, 407, 11, 456, 311, 439, 613, 819, 10862, 50464], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 342, "seek": 91088, "start": 912.88, "end": 917.68, "text": " that I think you wanna basically train the models to focus on,", "tokens": [50464, 300, 286, 519, 291, 1948, 1936, 3847, 264, 5245, 281, 1879, 322, 11, 50704], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 343, "seek": 91088, "start": 917.68, "end": 919.84, "text": " as well as getting a lot better at reasoning,", "tokens": [50704, 382, 731, 382, 1242, 257, 688, 1101, 412, 21577, 11, 50812], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 344, "seek": 91088, "start": 919.84, "end": 921.04, "text": " getting a lot better at memory,", "tokens": [50812, 1242, 257, 688, 1101, 412, 4675, 11, 50872], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 345, "seek": 91088, "start": 921.04, "end": 923.04, "text": " which I think is kind of its own whole thing.", "tokens": [50872, 597, 286, 519, 307, 733, 295, 1080, 1065, 1379, 551, 13, 50972], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 346, "seek": 91088, "start": 923.04, "end": 924.48, "text": " It's, I mean, I don't think we're gonna be,", "tokens": [50972, 467, 311, 11, 286, 914, 11, 286, 500, 380, 519, 321, 434, 799, 312, 11, 51044], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 347, "seek": 91088, "start": 924.48, "end": 926.72, "text": " you know, primarily shoving context", "tokens": [51044, 291, 458, 11, 10029, 2223, 798, 4319, 51156], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 348, "seek": 91088, "start": 926.72, "end": 931.12, "text": " or kind of things into a query context window in the future", "tokens": [51156, 420, 733, 295, 721, 666, 257, 14581, 4319, 4910, 294, 264, 2027, 51376], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 349, "seek": 91088, "start": 931.12, "end": 932.88, "text": " to ask more complicated questions.", "tokens": [51376, 281, 1029, 544, 6179, 1651, 13, 51464], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 350, "seek": 91088, "start": 932.88, "end": 935.36, "text": " I think that there'll be kind of different stores of memory", "tokens": [51464, 286, 519, 300, 456, 603, 312, 733, 295, 819, 9512, 295, 4675, 51588], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 351, "seek": 91088, "start": 935.36, "end": 936.48, "text": " or different custom models", "tokens": [51588, 420, 819, 2375, 5245, 51644], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 352, "seek": 91088, "start": 936.48, "end": 939.76, "text": " that are maybe more personalized to people.", "tokens": [51644, 300, 366, 1310, 544, 28415, 281, 561, 13, 51808], "temperature": 0.0, "avg_logprob": -0.0934862781771653, "compression_ratio": 1.8327645051194539, "no_speech_prob": 5.649419472320005e-05}, {"id": 353, "seek": 93976, "start": 939.76, "end": 941.4399999999999, "text": " But I don't know, I think that these are all", "tokens": [50364, 583, 286, 500, 380, 458, 11, 286, 519, 300, 613, 366, 439, 50448], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 354, "seek": 93976, "start": 941.4399999999999, "end": 942.64, "text": " just different capabilities.", "tokens": [50448, 445, 819, 10862, 13, 50508], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 355, "seek": 93976, "start": 942.64, "end": 944.4, "text": " And then obviously making them big and small,", "tokens": [50508, 400, 550, 2745, 1455, 552, 955, 293, 1359, 11, 50596], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 356, "seek": 93976, "start": 944.4, "end": 946.8, "text": " we care about both because, you know, we wanna,", "tokens": [50596, 321, 1127, 466, 1293, 570, 11, 291, 458, 11, 321, 1948, 11, 50716], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 357, "seek": 93976, "start": 946.8, "end": 949.2, "text": " you know, if you're running something like meta AI,", "tokens": [50716, 291, 458, 11, 498, 291, 434, 2614, 746, 411, 19616, 7318, 11, 50836], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 358, "seek": 93976, "start": 949.2, "end": 952.48, "text": " then we have the ability to, that's pretty server-based,", "tokens": [50836, 550, 321, 362, 264, 3485, 281, 11, 300, 311, 1238, 7154, 12, 6032, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 359, "seek": 93976, "start": 952.48, "end": 954.3199999999999, "text": " but we also want it running on smart glasses.", "tokens": [51000, 457, 321, 611, 528, 309, 2614, 322, 4069, 10812, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 360, "seek": 93976, "start": 954.3199999999999, "end": 956.72, "text": " And, you know, there's not a lot of space in smart glasses.", "tokens": [51092, 400, 11, 291, 458, 11, 456, 311, 406, 257, 688, 295, 1901, 294, 4069, 10812, 13, 51212], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 361, "seek": 93976, "start": 956.72, "end": 960.08, "text": " So, you wanna have something that's very efficient for that.", "tokens": [51212, 407, 11, 291, 1948, 362, 746, 300, 311, 588, 7148, 337, 300, 13, 51380], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 362, "seek": 93976, "start": 960.08, "end": 963.12, "text": " What is the use case that if you're doing tens of billions", "tokens": [51380, 708, 307, 264, 764, 1389, 300, 498, 291, 434, 884, 10688, 295, 17375, 51532], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 363, "seek": 93976, "start": 963.12, "end": 964.0, "text": " of dollars worth of inference,", "tokens": [51532, 295, 3808, 3163, 295, 38253, 11, 51576], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 364, "seek": 93976, "start": 964.0, "end": 965.6, "text": " or even eventually hundreds of billions of dollars", "tokens": [51576, 420, 754, 4728, 6779, 295, 17375, 295, 3808, 51656], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 365, "seek": 93976, "start": 965.6, "end": 969.12, "text": " worth of inference, using intelligence in an industrial scale,", "tokens": [51656, 3163, 295, 38253, 11, 1228, 7599, 294, 364, 9987, 4373, 11, 51832], "temperature": 0.0, "avg_logprob": -0.13665337789626347, "compression_ratio": 1.9142011834319526, "no_speech_prob": 0.00015842588618397713}, {"id": 366, "seek": 96912, "start": 969.12, "end": 970.24, "text": " what is the use case?", "tokens": [50364, 437, 307, 264, 764, 1389, 30, 50420], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 367, "seek": 96912, "start": 970.24, "end": 971.36, "text": " Is it simulations?", "tokens": [50420, 1119, 309, 35138, 30, 50476], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 368, "seek": 96912, "start": 971.36, "end": 973.12, "text": " Is it the AIs that will be in the metaverse?", "tokens": [50476, 1119, 309, 264, 316, 6802, 300, 486, 312, 294, 264, 19616, 4308, 30, 50564], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 369, "seek": 96912, "start": 973.12, "end": 975.52, "text": " What will we be using the data centers for?", "tokens": [50564, 708, 486, 321, 312, 1228, 264, 1412, 10898, 337, 30, 50684], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 370, "seek": 96912, "start": 979.12, "end": 981.2, "text": " I mean, our bet is that it's gonna,", "tokens": [50864, 286, 914, 11, 527, 778, 307, 300, 309, 311, 799, 11, 50968], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 371, "seek": 96912, "start": 981.2, "end": 983.44, "text": " this is basically gonna change all of the products, right?", "tokens": [50968, 341, 307, 1936, 799, 1319, 439, 295, 264, 3383, 11, 558, 30, 51080], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 372, "seek": 96912, "start": 983.44, "end": 987.76, "text": " So, I think that there's gonna be a kind of meta AI", "tokens": [51080, 407, 11, 286, 519, 300, 456, 311, 799, 312, 257, 733, 295, 19616, 7318, 51296], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 373, "seek": 96912, "start": 987.76, "end": 989.44, "text": " general assistant product.", "tokens": [51296, 2674, 10994, 1674, 13, 51380], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 374, "seek": 96912, "start": 989.44, "end": 992.48, "text": " And I think that that will shift from something", "tokens": [51380, 400, 286, 519, 300, 300, 486, 5513, 490, 746, 51532], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 375, "seek": 96912, "start": 992.48, "end": 994.08, "text": " that feels more like a chat bot", "tokens": [51532, 300, 3417, 544, 411, 257, 5081, 10592, 51612], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 376, "seek": 96912, "start": 994.08, "end": 995.6, "text": " where it's like you just ask a question", "tokens": [51612, 689, 309, 311, 411, 291, 445, 1029, 257, 1168, 51688], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 377, "seek": 96912, "start": 995.6, "end": 997.44, "text": " and it kind of formulates an answer", "tokens": [51688, 293, 309, 733, 295, 1254, 26192, 364, 1867, 51780], "temperature": 0.0, "avg_logprob": -0.15089777896278783, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.0006069495575502515}, {"id": 378, "seek": 99744, "start": 997.44, "end": 998.72, "text": " to things where you're increasingly", "tokens": [50364, 281, 721, 689, 291, 434, 12980, 50428], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 379, "seek": 99744, "start": 998.72, "end": 1000.32, "text": " giving it more complicated tasks", "tokens": [50428, 2902, 309, 544, 6179, 9608, 50508], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 380, "seek": 99744, "start": 1000.32, "end": 1001.6, "text": " and that goes away and does them.", "tokens": [50508, 293, 300, 1709, 1314, 293, 775, 552, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 381, "seek": 99744, "start": 1002.4000000000001, "end": 1004.48, "text": " So, that's gonna take a lot of inference.", "tokens": [50612, 407, 11, 300, 311, 799, 747, 257, 688, 295, 38253, 13, 50716], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 382, "seek": 99744, "start": 1004.48, "end": 1006.24, "text": " It's gonna take a lot of compute in other ways too.", "tokens": [50716, 467, 311, 799, 747, 257, 688, 295, 14722, 294, 661, 2098, 886, 13, 50804], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 383, "seek": 99744, "start": 1007.9200000000001, "end": 1010.8800000000001, "text": " Then I think that there's a big part of what we're gonna do", "tokens": [50888, 1396, 286, 519, 300, 456, 311, 257, 955, 644, 295, 437, 321, 434, 799, 360, 51036], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 384, "seek": 99744, "start": 1010.8800000000001, "end": 1016.5600000000001, "text": " that is like interacting with other agents for other people.", "tokens": [51036, 300, 307, 411, 18017, 365, 661, 12554, 337, 661, 561, 13, 51320], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 385, "seek": 99744, "start": 1016.5600000000001, "end": 1018.4000000000001, "text": " So, whether it's businesses or creators,", "tokens": [51320, 407, 11, 1968, 309, 311, 6011, 420, 16039, 11, 51412], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 386, "seek": 99744, "start": 1020.1600000000001, "end": 1021.7600000000001, "text": " I guess a big part of my theory on this", "tokens": [51500, 286, 2041, 257, 955, 644, 295, 452, 5261, 322, 341, 51580], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 387, "seek": 99744, "start": 1021.7600000000001, "end": 1024.0800000000002, "text": " is that there's not just gonna be like one singular AI", "tokens": [51580, 307, 300, 456, 311, 406, 445, 799, 312, 411, 472, 20010, 7318, 51696], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 388, "seek": 99744, "start": 1024.0800000000002, "end": 1025.28, "text": " that you interact with,", "tokens": [51696, 300, 291, 4648, 365, 11, 51756], "temperature": 0.0, "avg_logprob": -0.11579712416774543, "compression_ratio": 1.8136882129277567, "no_speech_prob": 0.0030746222473680973}, {"id": 389, "seek": 102528, "start": 1025.28, "end": 1028.96, "text": " because I think every business is gonna like want an AI", "tokens": [50364, 570, 286, 519, 633, 1606, 307, 799, 411, 528, 364, 7318, 50548], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 390, "seek": 102528, "start": 1028.96, "end": 1030.24, "text": " that represents their interests.", "tokens": [50548, 300, 8855, 641, 8847, 13, 50612], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 391, "seek": 102528, "start": 1030.24, "end": 1032.8, "text": " They're not gonna like wanna primarily interact with you", "tokens": [50612, 814, 434, 406, 799, 411, 1948, 10029, 4648, 365, 291, 50740], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 392, "seek": 102528, "start": 1032.8, "end": 1036.24, "text": " through an AI that is gonna sell their competitors' customers.", "tokens": [50740, 807, 364, 7318, 300, 307, 799, 3607, 641, 18333, 6, 4581, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 393, "seek": 102528, "start": 1036.24, "end": 1038.16, "text": " So, sorry, their competitors' products.", "tokens": [50912, 407, 11, 2597, 11, 641, 18333, 6, 3383, 13, 51008], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 394, "seek": 102528, "start": 1039.04, "end": 1045.28, "text": " So, yeah, so I think creators is gonna be a big one.", "tokens": [51052, 407, 11, 1338, 11, 370, 286, 519, 16039, 307, 799, 312, 257, 955, 472, 13, 51364], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 395, "seek": 102528, "start": 1045.28, "end": 1048.6399999999999, "text": " I mean, there are about 200 million creators on our platforms.", "tokens": [51364, 286, 914, 11, 456, 366, 466, 2331, 2459, 16039, 322, 527, 9473, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 396, "seek": 102528, "start": 1048.6399999999999, "end": 1050.48, "text": " They all basically have the pattern where", "tokens": [51532, 814, 439, 1936, 362, 264, 5102, 689, 51624], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 397, "seek": 102528, "start": 1051.6, "end": 1053.04, "text": " they want to engage their community,", "tokens": [51680, 436, 528, 281, 4683, 641, 1768, 11, 51752], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 398, "seek": 102528, "start": 1053.04, "end": 1054.56, "text": " but they're limited by hours in the day", "tokens": [51752, 457, 436, 434, 5567, 538, 2496, 294, 264, 786, 51828], "temperature": 0.0, "avg_logprob": -0.1478582223256429, "compression_ratio": 1.8022388059701493, "no_speech_prob": 0.0006665934924967587}, {"id": 399, "seek": 105456, "start": 1054.56, "end": 1056.8, "text": " and their community generally wants to engage them,", "tokens": [50364, 293, 641, 1768, 5101, 2738, 281, 4683, 552, 11, 50476], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 400, "seek": 105456, "start": 1056.8, "end": 1058.8, "text": " but they don't have, they're limited by hours in the day.", "tokens": [50476, 457, 436, 500, 380, 362, 11, 436, 434, 5567, 538, 2496, 294, 264, 786, 13, 50576], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 401, "seek": 105456, "start": 1059.52, "end": 1063.84, "text": " So, if you could create something where an AI could basically,", "tokens": [50612, 407, 11, 498, 291, 727, 1884, 746, 689, 364, 7318, 727, 1936, 11, 50828], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 402, "seek": 105456, "start": 1064.3999999999999, "end": 1066.6399999999999, "text": " that creator can basically own the AI", "tokens": [50856, 300, 14181, 393, 1936, 1065, 264, 7318, 50968], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 403, "seek": 105456, "start": 1066.6399999999999, "end": 1068.08, "text": " and train it in the way that they want", "tokens": [50968, 293, 3847, 309, 294, 264, 636, 300, 436, 528, 51040], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 404, "seek": 105456, "start": 1069.9199999999998, "end": 1071.6, "text": " and can engage their community,", "tokens": [51132, 293, 393, 4683, 641, 1768, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 405, "seek": 105456, "start": 1071.6, "end": 1073.76, "text": " I think that that's gonna be super powerful too.", "tokens": [51216, 286, 519, 300, 300, 311, 799, 312, 1687, 4005, 886, 13, 51324], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 406, "seek": 105456, "start": 1073.76, "end": 1076.24, "text": " So, I think that there's gonna be a ton of engagement", "tokens": [51324, 407, 11, 286, 519, 300, 456, 311, 799, 312, 257, 2952, 295, 8742, 51448], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 407, "seek": 105456, "start": 1076.24, "end": 1077.2, "text": " across all these things.", "tokens": [51448, 2108, 439, 613, 721, 13, 51496], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 408, "seek": 105456, "start": 1079.44, "end": 1081.12, "text": " But these are just the consumer use cases.", "tokens": [51608, 583, 613, 366, 445, 264, 9711, 764, 3331, 13, 51692], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 409, "seek": 105456, "start": 1081.12, "end": 1082.8, "text": " I mean, I think when you think about stuff like,", "tokens": [51692, 286, 914, 11, 286, 519, 562, 291, 519, 466, 1507, 411, 11, 51776], "temperature": 0.0, "avg_logprob": -0.09838388199196722, "compression_ratio": 1.8284671532846715, "no_speech_prob": 0.000666587264277041}, {"id": 410, "seek": 108280, "start": 1083.68, "end": 1086.6399999999999, "text": " I mean, I run our foundation,", "tokens": [50408, 286, 914, 11, 286, 1190, 527, 7030, 11, 50556], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 411, "seek": 108280, "start": 1087.44, "end": 1089.12, "text": " Chan Zuckerberg Initiative with my wife,", "tokens": [50596, 16064, 34032, 6873, 26166, 365, 452, 3836, 11, 50680], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 412, "seek": 108280, "start": 1089.12, "end": 1091.2, "text": " and we're doing a bunch of stuff on science,", "tokens": [50680, 293, 321, 434, 884, 257, 3840, 295, 1507, 322, 3497, 11, 50784], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 413, "seek": 108280, "start": 1091.2, "end": 1093.76, "text": " and there's obviously a lot of AI work", "tokens": [50784, 293, 456, 311, 2745, 257, 688, 295, 7318, 589, 50912], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 414, "seek": 108280, "start": 1093.76, "end": 1096.8799999999999, "text": " that I think is gonna advance science and healthcare", "tokens": [50912, 300, 286, 519, 307, 799, 7295, 3497, 293, 8884, 51068], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 415, "seek": 108280, "start": 1096.8799999999999, "end": 1097.68, "text": " and all these things too.", "tokens": [51068, 293, 439, 613, 721, 886, 13, 51108], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 416, "seek": 108280, "start": 1097.68, "end": 1099.2, "text": " So, I think that it's like,", "tokens": [51108, 407, 11, 286, 519, 300, 309, 311, 411, 11, 51184], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 417, "seek": 108280, "start": 1099.2, "end": 1101.04, "text": " this is, I think, an end up affecting", "tokens": [51184, 341, 307, 11, 286, 519, 11, 364, 917, 493, 17476, 51276], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 418, "seek": 108280, "start": 1101.04, "end": 1105.36, "text": " basically every area of the products and the economy.", "tokens": [51276, 1936, 633, 1859, 295, 264, 3383, 293, 264, 5010, 13, 51492], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 419, "seek": 108280, "start": 1105.36, "end": 1107.2, "text": " The thing you mentioned about an AI", "tokens": [51492, 440, 551, 291, 2835, 466, 364, 7318, 51584], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 420, "seek": 108280, "start": 1107.2, "end": 1109.04, "text": " that can just go out and do something for you", "tokens": [51584, 300, 393, 445, 352, 484, 293, 360, 746, 337, 291, 51676], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 421, "seek": 108280, "start": 1109.04, "end": 1111.52, "text": " that's multi-step, is that a bigger model?", "tokens": [51676, 300, 311, 4825, 12, 16792, 11, 307, 300, 257, 3801, 2316, 30, 51800], "temperature": 0.0, "avg_logprob": -0.13587307400173612, "compression_ratio": 1.6369863013698631, "no_speech_prob": 0.0010317766573280096}, {"id": 422, "seek": 111152, "start": 1111.52, "end": 1114.24, "text": " Is that you'll make, like, Lama 4 will still,", "tokens": [50364, 1119, 300, 291, 603, 652, 11, 411, 11, 441, 2404, 1017, 486, 920, 11, 50500], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 423, "seek": 111152, "start": 1114.24, "end": 1115.84, "text": " there'll be a version that's still 70B,", "tokens": [50500, 456, 603, 312, 257, 3037, 300, 311, 920, 5285, 33, 11, 50580], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 424, "seek": 111152, "start": 1115.84, "end": 1118.0, "text": " but will just be, you'll just train it on the right data,", "tokens": [50580, 457, 486, 445, 312, 11, 291, 603, 445, 3847, 309, 322, 264, 558, 1412, 11, 50688], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 425, "seek": 111152, "start": 1118.0, "end": 1119.84, "text": " and that will be super powerful.", "tokens": [50688, 293, 300, 486, 312, 1687, 4005, 13, 50780], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 426, "seek": 111152, "start": 1119.84, "end": 1121.28, "text": " Like, what does the progression look like?", "tokens": [50780, 1743, 11, 437, 775, 264, 18733, 574, 411, 30, 50852], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 427, "seek": 111152, "start": 1121.28, "end": 1123.6, "text": " Is it scaling? Is it just same size,", "tokens": [50852, 1119, 309, 21589, 30, 1119, 309, 445, 912, 2744, 11, 50968], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 428, "seek": 111152, "start": 1123.6, "end": 1125.68, "text": " but different banks like you were talking about?", "tokens": [50968, 457, 819, 10237, 411, 291, 645, 1417, 466, 30, 51072], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 429, "seek": 111152, "start": 1129.2, "end": 1131.6, "text": " I don't know that we know the answer to that.", "tokens": [51248, 286, 500, 380, 458, 300, 321, 458, 264, 1867, 281, 300, 13, 51368], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 430, "seek": 111152, "start": 1131.6, "end": 1135.84, "text": " So, I think one thing that seems to be a pattern", "tokens": [51368, 407, 11, 286, 519, 472, 551, 300, 2544, 281, 312, 257, 5102, 51580], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 431, "seek": 111152, "start": 1135.84, "end": 1138.0, "text": " is that you have the Lama,", "tokens": [51580, 307, 300, 291, 362, 264, 441, 2404, 11, 51688], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 432, "seek": 111152, "start": 1138.0, "end": 1139.68, "text": " sorry, the Lama model,", "tokens": [51688, 2597, 11, 264, 441, 2404, 2316, 11, 51772], "temperature": 0.0, "avg_logprob": -0.15873591105143228, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.00020339922048151493}, {"id": 433, "seek": 113968, "start": 1139.68, "end": 1144.0, "text": " and then you build some kind of other", "tokens": [50364, 293, 550, 291, 1322, 512, 733, 295, 661, 50580], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 434, "seek": 113968, "start": 1144.0, "end": 1146.3200000000002, "text": " application-specific code around it, right?", "tokens": [50580, 3861, 12, 29258, 3089, 926, 309, 11, 558, 30, 50696], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 435, "seek": 113968, "start": 1146.3200000000002, "end": 1148.64, "text": " So, some of it is the fine-tuning for the use case,", "tokens": [50696, 407, 11, 512, 295, 309, 307, 264, 2489, 12, 83, 37726, 337, 264, 764, 1389, 11, 50812], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 436, "seek": 113968, "start": 1148.64, "end": 1152.5600000000002, "text": " but some of it is just like logic for, okay, how,", "tokens": [50812, 457, 512, 295, 309, 307, 445, 411, 9952, 337, 11, 1392, 11, 577, 11, 51008], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 437, "seek": 113968, "start": 1154.3200000000002, "end": 1156.24, "text": " like, how Met AI should integrate,", "tokens": [51096, 411, 11, 577, 6377, 7318, 820, 13365, 11, 51192], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 438, "seek": 113968, "start": 1157.04, "end": 1159.28, "text": " that should work with tools like Google or Bing", "tokens": [51232, 300, 820, 589, 365, 3873, 411, 3329, 420, 30755, 51344], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 439, "seek": 113968, "start": 1159.28, "end": 1160.5600000000002, "text": " to bring in real-time knowledge.", "tokens": [51344, 281, 1565, 294, 957, 12, 3766, 3601, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 440, "seek": 113968, "start": 1160.5600000000002, "end": 1162.0800000000002, "text": " I mean, that's not part of the base Lama model.", "tokens": [51408, 286, 914, 11, 300, 311, 406, 644, 295, 264, 3096, 441, 2404, 2316, 13, 51484], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 441, "seek": 113968, "start": 1162.0800000000002, "end": 1162.96, "text": " That's like part of it.", "tokens": [51484, 663, 311, 411, 644, 295, 309, 13, 51528], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 442, "seek": 113968, "start": 1162.96, "end": 1165.8400000000001, "text": " Okay, so, for Lama 2, we had some of that,", "tokens": [51528, 1033, 11, 370, 11, 337, 441, 2404, 568, 11, 321, 632, 512, 295, 300, 11, 51672], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 443, "seek": 113968, "start": 1166.64, "end": 1169.44, "text": " and it was a little more kind of hand-engineered.", "tokens": [51712, 293, 309, 390, 257, 707, 544, 733, 295, 1011, 12, 25609, 4073, 13, 51852], "temperature": 0.0, "avg_logprob": -0.1642523140742861, "compression_ratio": 1.6453900709219857, "no_speech_prob": 0.0002959363628178835}, {"id": 444, "seek": 116944, "start": 1169.44, "end": 1171.44, "text": " And then part of our goal for Lama 3", "tokens": [50364, 400, 550, 644, 295, 527, 3387, 337, 441, 2404, 805, 50464], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 445, "seek": 116944, "start": 1172.0800000000002, "end": 1174.48, "text": " was to bring more of that into the model itself.", "tokens": [50496, 390, 281, 1565, 544, 295, 300, 666, 264, 2316, 2564, 13, 50616], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 446, "seek": 116944, "start": 1175.1200000000001, "end": 1176.3200000000002, "text": " And, but for Lama 3,", "tokens": [50648, 400, 11, 457, 337, 441, 2404, 805, 11, 50708], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 447, "seek": 116944, "start": 1176.3200000000002, "end": 1179.44, "text": " as we start getting into more of these agent-like behaviors,", "tokens": [50708, 382, 321, 722, 1242, 666, 544, 295, 613, 9461, 12, 4092, 15501, 11, 50864], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 448, "seek": 116944, "start": 1180.0, "end": 1182.88, "text": " I think some of that is going to be more hand-engineered.", "tokens": [50892, 286, 519, 512, 295, 300, 307, 516, 281, 312, 544, 1011, 12, 25609, 4073, 13, 51036], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 449, "seek": 116944, "start": 1182.88, "end": 1184.96, "text": " And then I think our goal for Lama 4", "tokens": [51036, 400, 550, 286, 519, 527, 3387, 337, 441, 2404, 1017, 51140], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 450, "seek": 116944, "start": 1184.96, "end": 1186.8, "text": " will be to bring more of that into the model.", "tokens": [51140, 486, 312, 281, 1565, 544, 295, 300, 666, 264, 2316, 13, 51232], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 451, "seek": 116944, "start": 1186.8, "end": 1190.0800000000002, "text": " So, I think at each point, like at each step along the way,", "tokens": [51232, 407, 11, 286, 519, 412, 1184, 935, 11, 411, 412, 1184, 1823, 2051, 264, 636, 11, 51396], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 452, "seek": 116944, "start": 1190.0800000000002, "end": 1193.28, "text": " you kind of have a sense of what's going to be possible", "tokens": [51396, 291, 733, 295, 362, 257, 2020, 295, 437, 311, 516, 281, 312, 1944, 51556], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 453, "seek": 116944, "start": 1193.28, "end": 1194.0, "text": " on the horizon.", "tokens": [51556, 322, 264, 18046, 13, 51592], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 454, "seek": 116944, "start": 1194.0, "end": 1196.0800000000002, "text": " You start messing with it and hacking around it.", "tokens": [51592, 509, 722, 23258, 365, 309, 293, 31422, 926, 309, 13, 51696], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 455, "seek": 116944, "start": 1196.88, "end": 1199.3600000000001, "text": " And then I think that that helps you hone your intuition", "tokens": [51736, 400, 550, 286, 519, 300, 300, 3665, 291, 43212, 428, 24002, 51860], "temperature": 0.0, "avg_logprob": -0.08110289030437227, "compression_ratio": 1.9225352112676057, "no_speech_prob": 0.00019714901281986386}, {"id": 456, "seek": 119936, "start": 1199.6799999999998, "end": 1201.52, "text": " for what you want to try to train", "tokens": [50380, 337, 437, 291, 528, 281, 853, 281, 3847, 50472], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 457, "seek": 119936, "start": 1201.52, "end": 1203.4399999999998, "text": " into the next version of the model itself.", "tokens": [50472, 666, 264, 958, 3037, 295, 264, 2316, 2564, 13, 50568], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 458, "seek": 119936, "start": 1203.4399999999998, "end": 1203.9199999999998, "text": " Interesting.", "tokens": [50568, 14711, 13, 50592], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 459, "seek": 119936, "start": 1203.9199999999998, "end": 1204.9599999999998, "text": " Which makes it more general,", "tokens": [50592, 3013, 1669, 309, 544, 2674, 11, 50644], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 460, "seek": 119936, "start": 1204.9599999999998, "end": 1207.1999999999998, "text": " because obviously anything that you're hand-coding", "tokens": [50644, 570, 2745, 1340, 300, 291, 434, 1011, 12, 66, 8616, 50756], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 461, "seek": 119936, "start": 1207.1999999999998, "end": 1210.24, "text": " is, you know, you can unlock some use cases,", "tokens": [50756, 307, 11, 291, 458, 11, 291, 393, 11634, 512, 764, 3331, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 462, "seek": 119936, "start": 1210.24, "end": 1212.32, "text": " but it's just inherently brittle and non-general.", "tokens": [50908, 457, 309, 311, 445, 27993, 49325, 293, 2107, 12, 1766, 2790, 13, 51012], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 463, "seek": 119936, "start": 1213.52, "end": 1214.3999999999999, "text": " Hey, everybody.", "tokens": [51072, 1911, 11, 2201, 13, 51116], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 464, "seek": 119936, "start": 1214.3999999999999, "end": 1216.7199999999998, "text": " Real quick, I want to tell you about a tool", "tokens": [51116, 8467, 1702, 11, 286, 528, 281, 980, 291, 466, 257, 2290, 51232], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 465, "seek": 119936, "start": 1216.7199999999998, "end": 1219.12, "text": " that I wish more applications used.", "tokens": [51232, 300, 286, 3172, 544, 5821, 1143, 13, 51352], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 466, "seek": 119936, "start": 1219.12, "end": 1221.9199999999998, "text": " So, obviously, you've noticed every single company", "tokens": [51352, 407, 11, 2745, 11, 291, 600, 5694, 633, 2167, 2237, 51492], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 467, "seek": 119936, "start": 1221.9199999999998, "end": 1225.12, "text": " is trying to add an AI chatbot to their website.", "tokens": [51492, 307, 1382, 281, 909, 364, 7318, 5081, 18870, 281, 641, 3144, 13, 51652], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 468, "seek": 119936, "start": 1225.12, "end": 1228.4799999999998, "text": " But as a user, I usually find them really annoying", "tokens": [51652, 583, 382, 257, 4195, 11, 286, 2673, 915, 552, 534, 11304, 51820], "temperature": 0.0, "avg_logprob": -0.08199912729397626, "compression_ratio": 1.6378205128205128, "no_speech_prob": 0.0004582619294524193}, {"id": 469, "seek": 122848, "start": 1228.48, "end": 1231.6, "text": " because they give these long, generic, often useless answers.", "tokens": [50364, 570, 436, 976, 613, 938, 11, 19577, 11, 2049, 14115, 6338, 13, 50520], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 470, "seek": 122848, "start": 1232.32, "end": 1235.3600000000001, "text": " Command Bar is a user assistant that you can just embed", "tokens": [50556, 17901, 4156, 307, 257, 4195, 10994, 300, 291, 393, 445, 12240, 50708], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 471, "seek": 122848, "start": 1235.3600000000001, "end": 1236.88, "text": " into your website or application.", "tokens": [50708, 666, 428, 3144, 420, 3861, 13, 50784], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 472, "seek": 122848, "start": 1237.44, "end": 1240.64, "text": " And it feels like you're talking to a friendly human support", "tokens": [50812, 400, 309, 3417, 411, 291, 434, 1417, 281, 257, 9208, 1952, 1406, 50972], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 473, "seek": 122848, "start": 1240.64, "end": 1243.44, "text": " agent who is browsing with you and for you.", "tokens": [50972, 9461, 567, 307, 38602, 365, 291, 293, 337, 291, 13, 51112], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 474, "seek": 122848, "start": 1244.0, "end": 1247.52, "text": " And it's much more personalized than a regular chatbot.", "tokens": [51140, 400, 309, 311, 709, 544, 28415, 813, 257, 3890, 5081, 18870, 13, 51316], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 475, "seek": 122848, "start": 1247.52, "end": 1249.44, "text": " It can actually look up users' history", "tokens": [51316, 467, 393, 767, 574, 493, 5022, 6, 2503, 51412], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 476, "seek": 122848, "start": 1249.44, "end": 1251.6, "text": " and respond differently based on that.", "tokens": [51412, 293, 4196, 7614, 2361, 322, 300, 13, 51520], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 477, "seek": 122848, "start": 1251.6, "end": 1254.56, "text": " It can use APIs to perform actions.", "tokens": [51520, 467, 393, 764, 21445, 281, 2042, 5909, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 478, "seek": 122848, "start": 1254.56, "end": 1258.08, "text": " It can even practically nudge users to explore new features.", "tokens": [51668, 467, 393, 754, 15667, 297, 16032, 5022, 281, 6839, 777, 4122, 13, 51844], "temperature": 0.0, "avg_logprob": -0.10648152006774389, "compression_ratio": 1.6125827814569536, "no_speech_prob": 0.0017004457768052816}, {"id": 479, "seek": 125848, "start": 1258.56, "end": 1260.16, "text": " One thing that I think is really cool", "tokens": [50368, 1485, 551, 300, 286, 519, 307, 534, 1627, 50448], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 480, "seek": 125848, "start": 1260.16, "end": 1262.64, "text": " is that instead of just outputting text,", "tokens": [50448, 307, 300, 2602, 295, 445, 5598, 783, 2487, 11, 50572], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 481, "seek": 125848, "start": 1262.64, "end": 1265.68, "text": " Command Bar can kind of just say, here, let me show you", "tokens": [50572, 17901, 4156, 393, 733, 295, 445, 584, 11, 510, 11, 718, 385, 855, 291, 50724], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 482, "seek": 125848, "start": 1265.68, "end": 1267.92, "text": " and start browsing alongside the user.", "tokens": [50724, 293, 722, 38602, 12385, 264, 4195, 13, 50836], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 483, "seek": 125848, "start": 1268.56, "end": 1271.1200000000001, "text": " Anyways, they're in a bunch of great products already.", "tokens": [50868, 15585, 11, 436, 434, 294, 257, 3840, 295, 869, 3383, 1217, 13, 50996], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 484, "seek": 125848, "start": 1271.1200000000001, "end": 1274.96, "text": " You can learn more about them at commandbar.com.", "tokens": [50996, 509, 393, 1466, 544, 466, 552, 412, 5622, 5356, 13, 1112, 13, 51188], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 485, "seek": 125848, "start": 1275.52, "end": 1277.52, "text": " Thanks to them for sponsoring this episode.", "tokens": [51216, 2561, 281, 552, 337, 30311, 341, 3500, 13, 51316], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 486, "seek": 125848, "start": 1277.52, "end": 1278.56, "text": " And now back to Mark.", "tokens": [51316, 400, 586, 646, 281, 3934, 13, 51368], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 487, "seek": 125848, "start": 1279.1200000000001, "end": 1280.56, "text": " What do you say into the model itself?", "tokens": [51396, 708, 360, 291, 584, 666, 264, 2316, 2564, 30, 51468], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 488, "seek": 125848, "start": 1280.56, "end": 1284.08, "text": " You train it on the thing that you want in the model itself?", "tokens": [51468, 509, 3847, 309, 322, 264, 551, 300, 291, 528, 294, 264, 2316, 2564, 30, 51644], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 489, "seek": 125848, "start": 1284.08, "end": 1285.92, "text": " What do you mean by into the model itself?", "tokens": [51644, 708, 360, 291, 914, 538, 666, 264, 2316, 2564, 30, 51736], "temperature": 0.0, "avg_logprob": -0.1052823819612202, "compression_ratio": 1.7482014388489209, "no_speech_prob": 0.0014548006001859903}, {"id": 490, "seek": 128592, "start": 1285.92, "end": 1289.52, "text": " Well, I think the example that I gave for Llama 2,", "tokens": [50364, 1042, 11, 286, 519, 264, 1365, 300, 286, 2729, 337, 32717, 2404, 568, 11, 50544], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 491, "seek": 128592, "start": 1289.52, "end": 1297.04, "text": " where for Llama 2, the tool use was very specific.", "tokens": [50544, 689, 337, 32717, 2404, 568, 11, 264, 2290, 764, 390, 588, 2685, 13, 50920], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 492, "seek": 128592, "start": 1297.92, "end": 1300.8000000000002, "text": " Whereas Llama 3 has the ability to have much better tool use.", "tokens": [50964, 13813, 32717, 2404, 805, 575, 264, 3485, 281, 362, 709, 1101, 2290, 764, 13, 51108], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 493, "seek": 128592, "start": 1300.8000000000002, "end": 1304.0800000000002, "text": " So we don't have to hand code all the stuff", "tokens": [51108, 407, 321, 500, 380, 362, 281, 1011, 3089, 439, 264, 1507, 51272], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 494, "seek": 128592, "start": 1304.0800000000002, "end": 1307.28, "text": " to have it use Google to go do a search.", "tokens": [51272, 281, 362, 309, 764, 3329, 281, 352, 360, 257, 3164, 13, 51432], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 495, "seek": 128592, "start": 1308.16, "end": 1309.68, "text": " It just kind of can do that.", "tokens": [51476, 467, 445, 733, 295, 393, 360, 300, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 496, "seek": 128592, "start": 1311.8400000000001, "end": 1314.8000000000002, "text": " And similarly for coding and kind of running code", "tokens": [51660, 400, 14138, 337, 17720, 293, 733, 295, 2614, 3089, 51808], "temperature": 0.0, "avg_logprob": -0.1880709727605184, "compression_ratio": 1.5721153846153846, "no_speech_prob": 0.004197793081402779}, {"id": 497, "seek": 131480, "start": 1314.8, "end": 1316.6399999999999, "text": " and a bunch of stuff like that.", "tokens": [50364, 293, 257, 3840, 295, 1507, 411, 300, 13, 50456], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 498, "seek": 131480, "start": 1319.04, "end": 1321.04, "text": " But I think once you kind of get that capability,", "tokens": [50576, 583, 286, 519, 1564, 291, 733, 295, 483, 300, 13759, 11, 50676], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 499, "seek": 131480, "start": 1321.9199999999998, "end": 1324.96, "text": " then you get a peek of, okay, well, what can we start doing next?", "tokens": [50720, 550, 291, 483, 257, 19604, 295, 11, 1392, 11, 731, 11, 437, 393, 321, 722, 884, 958, 30, 50872], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 500, "seek": 131480, "start": 1324.96, "end": 1327.76, "text": " Okay, well, I don't necessarily want to wait until Llama 4 is around", "tokens": [50872, 1033, 11, 731, 11, 286, 500, 380, 4725, 528, 281, 1699, 1826, 32717, 2404, 1017, 307, 926, 51012], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 501, "seek": 131480, "start": 1327.76, "end": 1329.28, "text": " to start building those capabilities.", "tokens": [51012, 281, 722, 2390, 729, 10862, 13, 51088], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 502, "seek": 131480, "start": 1329.28, "end": 1330.6399999999999, "text": " So let's start hacking around it.", "tokens": [51088, 407, 718, 311, 722, 31422, 926, 309, 13, 51156], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 503, "seek": 131480, "start": 1330.6399999999999, "end": 1333.04, "text": " And so you do a bunch of hand coding", "tokens": [51156, 400, 370, 291, 360, 257, 3840, 295, 1011, 17720, 51276], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 504, "seek": 131480, "start": 1333.04, "end": 1336.32, "text": " and that makes the products better for the interim.", "tokens": [51276, 293, 300, 1669, 264, 3383, 1101, 337, 264, 33500, 13, 51440], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 505, "seek": 131480, "start": 1336.32, "end": 1338.24, "text": " But then that also helps show the way", "tokens": [51440, 583, 550, 300, 611, 3665, 855, 264, 636, 51536], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 506, "seek": 131480, "start": 1338.24, "end": 1341.28, "text": " of what we want to try to build into the next version of the model.", "tokens": [51536, 295, 437, 321, 528, 281, 853, 281, 1322, 666, 264, 958, 3037, 295, 264, 2316, 13, 51688], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 507, "seek": 131480, "start": 1341.28, "end": 1343.6, "text": " What is the community fine tune of Llama 3", "tokens": [51688, 708, 307, 264, 1768, 2489, 10864, 295, 32717, 2404, 805, 51804], "temperature": 0.0, "avg_logprob": -0.0963373381516029, "compression_ratio": 1.730263157894737, "no_speech_prob": 0.0012445816537365317}, {"id": 508, "seek": 134360, "start": 1343.6, "end": 1344.6399999999999, "text": " you're most excited by?", "tokens": [50364, 291, 434, 881, 2919, 538, 30, 50416], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 509, "seek": 134360, "start": 1344.6399999999999, "end": 1346.3999999999999, "text": " Maybe not the one that will be most useful to you,", "tokens": [50416, 2704, 406, 264, 472, 300, 486, 312, 881, 4420, 281, 291, 11, 50504], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 510, "seek": 134360, "start": 1346.3999999999999, "end": 1348.32, "text": " but Jess, you'll just enjoy playing it with the most.", "tokens": [50504, 457, 10484, 11, 291, 603, 445, 2103, 2433, 309, 365, 264, 881, 13, 50600], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 511, "seek": 134360, "start": 1349.76, "end": 1351.1999999999998, "text": " They like fine tune it on antiquity", "tokens": [50672, 814, 411, 2489, 10864, 309, 322, 41036, 507, 50744], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 512, "seek": 134360, "start": 1351.1999999999998, "end": 1352.9599999999998, "text": " and you'll just be like talking to Virgil or something.", "tokens": [50744, 293, 291, 603, 445, 312, 411, 1417, 281, 7566, 29965, 420, 746, 13, 50832], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 513, "seek": 134360, "start": 1352.9599999999998, "end": 1354.32, "text": " What are you excited about?", "tokens": [50832, 708, 366, 291, 2919, 466, 30, 50900], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 514, "seek": 134360, "start": 1354.32, "end": 1354.8799999999999, "text": " I don't know.", "tokens": [50900, 286, 500, 380, 458, 13, 50928], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 515, "seek": 134360, "start": 1356.32, "end": 1358.3999999999999, "text": " I mean, I think the nature of the stuff is it's like,", "tokens": [51000, 286, 914, 11, 286, 519, 264, 3687, 295, 264, 1507, 307, 309, 311, 411, 11, 51104], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 516, "seek": 134360, "start": 1359.6, "end": 1361.1999999999998, "text": " you get surprised, right?", "tokens": [51164, 291, 483, 6100, 11, 558, 30, 51244], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 517, "seek": 134360, "start": 1361.1999999999998, "end": 1364.9599999999998, "text": " So I think like any specific thing that I sort of", "tokens": [51244, 407, 286, 519, 411, 604, 2685, 551, 300, 286, 1333, 295, 51432], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 518, "seek": 134360, "start": 1366.56, "end": 1369.52, "text": " thought would be valuable, we'd probably be building, right?", "tokens": [51512, 1194, 576, 312, 8263, 11, 321, 1116, 1391, 312, 2390, 11, 558, 30, 51660], "temperature": 0.0, "avg_logprob": -0.15070829969463925, "compression_ratio": 1.635379061371841, "no_speech_prob": 0.0052185324020683765}, {"id": 519, "seek": 136952, "start": 1369.52, "end": 1374.96, "text": " So, but I think you'll get distilled versions.", "tokens": [50364, 407, 11, 457, 286, 519, 291, 603, 483, 1483, 6261, 9606, 13, 50636], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 520, "seek": 136952, "start": 1374.96, "end": 1377.12, "text": " I think you'll get kind of smaller versions.", "tokens": [50636, 286, 519, 291, 603, 483, 733, 295, 4356, 9606, 13, 50744], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 521, "seek": 136952, "start": 1377.12, "end": 1381.76, "text": " I mean, one thing that I think is 8 billion,", "tokens": [50744, 286, 914, 11, 472, 551, 300, 286, 519, 307, 1649, 5218, 11, 50976], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 522, "seek": 136952, "start": 1381.76, "end": 1385.44, "text": " I don't think is quite small enough for a bunch of use cases, right?", "tokens": [50976, 286, 500, 380, 519, 307, 1596, 1359, 1547, 337, 257, 3840, 295, 764, 3331, 11, 558, 30, 51160], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 523, "seek": 136952, "start": 1385.44, "end": 1389.68, "text": " I think like over time, I'd love to get a billion parameter model", "tokens": [51160, 286, 519, 411, 670, 565, 11, 286, 1116, 959, 281, 483, 257, 5218, 13075, 2316, 51372], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 524, "seek": 136952, "start": 1389.68, "end": 1391.68, "text": " or a 2 billion parameter model", "tokens": [51372, 420, 257, 568, 5218, 13075, 2316, 51472], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 525, "seek": 136952, "start": 1391.68, "end": 1394.72, "text": " or even like a, I don't know, maybe like a 500 million parameter model", "tokens": [51472, 420, 754, 411, 257, 11, 286, 500, 380, 458, 11, 1310, 411, 257, 5923, 2459, 13075, 2316, 51624], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 526, "seek": 136952, "start": 1394.72, "end": 1395.68, "text": " and see what you can do with that.", "tokens": [51624, 293, 536, 437, 291, 393, 360, 365, 300, 13, 51672], "temperature": 0.0, "avg_logprob": -0.13157934978090483, "compression_ratio": 1.8630136986301369, "no_speech_prob": 0.0018100664019584656}, {"id": 527, "seek": 139568, "start": 1395.68, "end": 1399.52, "text": " Because I mean, as they start getting, if with 8 billion parameters", "tokens": [50364, 1436, 286, 914, 11, 382, 436, 722, 1242, 11, 498, 365, 1649, 5218, 9834, 50556], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 528, "seek": 139568, "start": 1399.52, "end": 1403.44, "text": " we're basically nearly as powerful as the largest llama 2 model,", "tokens": [50556, 321, 434, 1936, 6217, 382, 4005, 382, 264, 6443, 23272, 568, 2316, 11, 50752], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 529, "seek": 139568, "start": 1403.44, "end": 1405.3600000000001, "text": " then with a billion parameters,", "tokens": [50752, 550, 365, 257, 5218, 9834, 11, 50848], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 530, "seek": 139568, "start": 1405.3600000000001, "end": 1407.2, "text": " you should be able to do something that's interesting, right?", "tokens": [50848, 291, 820, 312, 1075, 281, 360, 746, 300, 311, 1880, 11, 558, 30, 50940], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 531, "seek": 139568, "start": 1407.2, "end": 1410.72, "text": " And faster, good for classification", "tokens": [50940, 400, 4663, 11, 665, 337, 21538, 51116], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 532, "seek": 139568, "start": 1410.72, "end": 1413.2, "text": " or a lot of kind of like basic things that people do", "tokens": [51116, 420, 257, 688, 295, 733, 295, 411, 3875, 721, 300, 561, 360, 51240], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 533, "seek": 139568, "start": 1413.2, "end": 1417.92, "text": " before kind of understanding the intent of a user query", "tokens": [51240, 949, 733, 295, 3701, 264, 8446, 295, 257, 4195, 14581, 51476], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 534, "seek": 139568, "start": 1417.92, "end": 1419.6000000000001, "text": " and feeding it to the most powerful model", "tokens": [51476, 293, 12919, 309, 281, 264, 881, 4005, 2316, 51560], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 535, "seek": 139568, "start": 1419.6000000000001, "end": 1422.3200000000002, "text": " to kind of hone what the prompt should be.", "tokens": [51560, 281, 733, 295, 43212, 437, 264, 12391, 820, 312, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 536, "seek": 139568, "start": 1424.0, "end": 1424.48, "text": " So I don't know.", "tokens": [51780, 407, 286, 500, 380, 458, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1252008597056071, "compression_ratio": 1.7014388489208634, "no_speech_prob": 0.0050595044158399105}, {"id": 537, "seek": 142448, "start": 1424.48, "end": 1426.64, "text": " I think that's one thing that maybe the community can help fill in.", "tokens": [50364, 286, 519, 300, 311, 472, 551, 300, 1310, 264, 1768, 393, 854, 2836, 294, 13, 50472], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 538, "seek": 142448, "start": 1426.64, "end": 1429.2, "text": " But I mean, we'll also, we're also thinking about getting around", "tokens": [50472, 583, 286, 914, 11, 321, 603, 611, 11, 321, 434, 611, 1953, 466, 1242, 926, 50600], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 539, "seek": 142448, "start": 1429.2, "end": 1431.52, "text": " to distilling some of these ourselves,", "tokens": [50600, 281, 1483, 7345, 512, 295, 613, 4175, 11, 50716], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 540, "seek": 142448, "start": 1431.52, "end": 1435.84, "text": " but right now the GPUs are pegged training the 405.", "tokens": [50716, 457, 558, 586, 264, 18407, 82, 366, 520, 12244, 3097, 264, 3356, 20, 13, 50932], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 541, "seek": 142448, "start": 1435.84, "end": 1437.84, "text": " So what, okay, so you have all these GPUs,", "tokens": [50932, 407, 437, 11, 1392, 11, 370, 291, 362, 439, 613, 18407, 82, 11, 51032], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 542, "seek": 142448, "start": 1440.08, "end": 1442.08, "text": " I think 350,000 by the end of the year.", "tokens": [51144, 286, 519, 18065, 11, 1360, 538, 264, 917, 295, 264, 1064, 13, 51244], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 543, "seek": 142448, "start": 1442.08, "end": 1442.96, "text": " That's the whole fleet.", "tokens": [51244, 663, 311, 264, 1379, 19396, 13, 51288], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 544, "seek": 142448, "start": 1442.96, "end": 1450.0, "text": " I mean, we built two, I think it's like 22, 24,000 clusters", "tokens": [51288, 286, 914, 11, 321, 3094, 732, 11, 286, 519, 309, 311, 411, 5853, 11, 4022, 11, 1360, 23313, 51640], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 545, "seek": 142448, "start": 1450.0, "end": 1452.32, "text": " that are kind of the single clusters that we have", "tokens": [51640, 300, 366, 733, 295, 264, 2167, 23313, 300, 321, 362, 51756], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 546, "seek": 142448, "start": 1452.32, "end": 1453.44, "text": " for training the big models.", "tokens": [51756, 337, 3097, 264, 955, 5245, 13, 51812], "temperature": 0.0, "avg_logprob": -0.17617928209922296, "compression_ratio": 1.6992753623188406, "no_speech_prob": 0.0018097845604643226}, {"id": 547, "seek": 145344, "start": 1453.8400000000001, "end": 1456.0, "text": " I mean, obviously across a lot of the stuff that we do,", "tokens": [50384, 286, 914, 11, 2745, 2108, 257, 688, 295, 264, 1507, 300, 321, 360, 11, 50492], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 548, "seek": 145344, "start": 1456.0, "end": 1459.1200000000001, "text": " a lot of our stuff goes towards training like reels models", "tokens": [50492, 257, 688, 295, 527, 1507, 1709, 3030, 3097, 411, 319, 1625, 5245, 50648], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 549, "seek": 145344, "start": 1459.1200000000001, "end": 1462.16, "text": " and like Facebook news feed and Instagram feed.", "tokens": [50648, 293, 411, 4384, 2583, 3154, 293, 5281, 3154, 13, 50800], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 550, "seek": 145344, "start": 1462.16, "end": 1463.8400000000001, "text": " And then inference is a huge thing for us", "tokens": [50800, 400, 550, 38253, 307, 257, 2603, 551, 337, 505, 50884], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 551, "seek": 145344, "start": 1463.8400000000001, "end": 1465.3600000000001, "text": " because we serve a ton of people, right?", "tokens": [50884, 570, 321, 4596, 257, 2952, 295, 561, 11, 558, 30, 50960], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 552, "seek": 145344, "start": 1465.3600000000001, "end": 1472.3200000000002, "text": " So our ratio of inference compute required to training", "tokens": [50960, 407, 527, 8509, 295, 38253, 14722, 4739, 281, 3097, 51308], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 553, "seek": 145344, "start": 1472.3200000000002, "end": 1474.64, "text": " is probably much higher than most other companies", "tokens": [51308, 307, 1391, 709, 2946, 813, 881, 661, 3431, 51424], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 554, "seek": 145344, "start": 1474.64, "end": 1476.8, "text": " that are doing this stuff just because of the sheer volume", "tokens": [51424, 300, 366, 884, 341, 1507, 445, 570, 295, 264, 23061, 5523, 51532], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 555, "seek": 145344, "start": 1476.8, "end": 1478.8, "text": " of the community that we're serving.", "tokens": [51532, 295, 264, 1768, 300, 321, 434, 8148, 13, 51632], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 556, "seek": 145344, "start": 1478.8, "end": 1479.8400000000001, "text": " Yeah, yeah.", "tokens": [51632, 865, 11, 1338, 13, 51684], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 557, "seek": 145344, "start": 1479.8400000000001, "end": 1482.24, "text": " That was really interesting in the material they shared with me before", "tokens": [51684, 663, 390, 534, 1880, 294, 264, 2527, 436, 5507, 365, 385, 949, 51804], "temperature": 0.0, "avg_logprob": -0.11770813281719501, "compression_ratio": 1.723127035830619, "no_speech_prob": 0.0009696233901195228}, {"id": 558, "seek": 148224, "start": 1482.24, "end": 1485.2, "text": " that you trained it on more data than is computer optimal", "tokens": [50364, 300, 291, 8895, 309, 322, 544, 1412, 813, 307, 3820, 16252, 50512], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 559, "seek": 148224, "start": 1485.2, "end": 1487.68, "text": " just for training because the inference is such a big deal", "tokens": [50512, 445, 337, 3097, 570, 264, 38253, 307, 1270, 257, 955, 2028, 50636], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 560, "seek": 148224, "start": 1487.68, "end": 1489.36, "text": " for you guys and also for the community", "tokens": [50636, 337, 291, 1074, 293, 611, 337, 264, 1768, 50720], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 561, "seek": 148224, "start": 1489.36, "end": 1490.96, "text": " that it makes sense to just have this thing", "tokens": [50720, 300, 309, 1669, 2020, 281, 445, 362, 341, 551, 50800], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 562, "seek": 148224, "start": 1490.96, "end": 1492.8, "text": " and have a trillion to tokens in there.", "tokens": [50800, 293, 362, 257, 18723, 281, 22667, 294, 456, 13, 50892], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 563, "seek": 148224, "start": 1492.8, "end": 1493.52, "text": " Yeah, yeah.", "tokens": [50892, 865, 11, 1338, 13, 50928], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 564, "seek": 148224, "start": 1493.52, "end": 1495.92, "text": " Although, and one of the interesting things about it", "tokens": [50928, 5780, 11, 293, 472, 295, 264, 1880, 721, 466, 309, 51048], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 565, "seek": 148224, "start": 1495.92, "end": 1498.32, "text": " that we saw even with the 70 billion is we thought", "tokens": [51048, 300, 321, 1866, 754, 365, 264, 5285, 5218, 307, 321, 1194, 51168], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 566, "seek": 148224, "start": 1498.32, "end": 1502.24, "text": " it would get more saturated at, you know,", "tokens": [51168, 309, 576, 483, 544, 25408, 412, 11, 291, 458, 11, 51364], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 567, "seek": 148224, "start": 1502.24, "end": 1504.72, "text": " it's like we trained on around 15 trillion tokens.", "tokens": [51364, 309, 311, 411, 321, 8895, 322, 926, 2119, 18723, 22667, 13, 51488], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 568, "seek": 148224, "start": 1504.72, "end": 1505.52, "text": " Yeah.", "tokens": [51488, 865, 13, 51528], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 569, "seek": 148224, "start": 1505.52, "end": 1507.92, "text": " We, I guess our prediction going in was that", "tokens": [51528, 492, 11, 286, 2041, 527, 17630, 516, 294, 390, 300, 51648], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 570, "seek": 148224, "start": 1508.56, "end": 1510.72, "text": " it was going to ask some to it more,", "tokens": [51680, 309, 390, 516, 281, 1029, 512, 281, 309, 544, 11, 51788], "temperature": 0.0, "avg_logprob": -0.17120015621185303, "compression_ratio": 1.732258064516129, "no_speech_prob": 0.0016482804203405976}, {"id": 571, "seek": 151072, "start": 1510.72, "end": 1513.92, "text": " but even by the end it was still learning, right?", "tokens": [50364, 457, 754, 538, 264, 917, 309, 390, 920, 2539, 11, 558, 30, 50524], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 572, "seek": 151072, "start": 1513.92, "end": 1517.2, "text": " It's like we probably could have fed it more tokens", "tokens": [50524, 467, 311, 411, 321, 1391, 727, 362, 4636, 309, 544, 22667, 50688], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 573, "seek": 151072, "start": 1517.2, "end": 1519.04, "text": " and it would have gotten somewhat better.", "tokens": [50688, 293, 309, 576, 362, 5768, 8344, 1101, 13, 50780], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 574, "seek": 151072, "start": 1519.04, "end": 1521.2, "text": " But I mean, at some point, you know, you're running a company", "tokens": [50780, 583, 286, 914, 11, 412, 512, 935, 11, 291, 458, 11, 291, 434, 2614, 257, 2237, 50888], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 575, "seek": 151072, "start": 1521.2, "end": 1524.24, "text": " you need to do these meta reasoning questions of like,", "tokens": [50888, 291, 643, 281, 360, 613, 19616, 21577, 1651, 295, 411, 11, 51040], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 576, "seek": 151072, "start": 1524.24, "end": 1526.4, "text": " all right, how do I want to spend our GPUs", "tokens": [51040, 439, 558, 11, 577, 360, 286, 528, 281, 3496, 527, 18407, 82, 51148], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 577, "seek": 151072, "start": 1526.4, "end": 1529.04, "text": " on like training this 70 billion model further?", "tokens": [51148, 322, 411, 3097, 341, 5285, 5218, 2316, 3052, 30, 51280], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 578, "seek": 151072, "start": 1529.04, "end": 1531.28, "text": " Do we want to kind of get on with it", "tokens": [51280, 1144, 321, 528, 281, 733, 295, 483, 322, 365, 309, 51392], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 579, "seek": 151072, "start": 1531.28, "end": 1533.84, "text": " so we can start testing hypotheses for Llama 4?", "tokens": [51392, 370, 321, 393, 722, 4997, 49969, 337, 32717, 2404, 1017, 30, 51520], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 580, "seek": 151072, "start": 1533.84, "end": 1536.8, "text": " So we kind of needed to make that call.", "tokens": [51520, 407, 321, 733, 295, 2978, 281, 652, 300, 818, 13, 51668], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 581, "seek": 151072, "start": 1536.8, "end": 1538.0, "text": " And I think we got it,", "tokens": [51668, 400, 286, 519, 321, 658, 309, 11, 51728], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 582, "seek": 151072, "start": 1538.0, "end": 1539.28, "text": " I think we got to a reasonable balance", "tokens": [51728, 286, 519, 321, 658, 281, 257, 10585, 4772, 51792], "temperature": 0.0, "avg_logprob": -0.10424284903418939, "compression_ratio": 1.670807453416149, "no_speech_prob": 0.0010321163572371006}, {"id": 583, "seek": 153928, "start": 1539.76, "end": 1541.2, "text": " for this version of the 70 billion.", "tokens": [50388, 337, 341, 3037, 295, 264, 5285, 5218, 13, 50460], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 584, "seek": 153928, "start": 1542.8799999999999, "end": 1544.08, "text": " There will be others in the future", "tokens": [50544, 821, 486, 312, 2357, 294, 264, 2027, 50604], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 585, "seek": 153928, "start": 1544.08, "end": 1545.76, "text": " where, you know, 70 billion multimodal one", "tokens": [50604, 689, 11, 291, 458, 11, 5285, 5218, 32972, 378, 304, 472, 50688], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 586, "seek": 153928, "start": 1545.76, "end": 1547.76, "text": " that'll come over the next period.", "tokens": [50688, 300, 603, 808, 670, 264, 958, 2896, 13, 50788], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 587, "seek": 153928, "start": 1547.76, "end": 1551.28, "text": " But yeah, I mean, that was fascinating", "tokens": [50788, 583, 1338, 11, 286, 914, 11, 300, 390, 10343, 50964], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 588, "seek": 153928, "start": 1551.28, "end": 1553.28, "text": " that you could just, that it's the architectures", "tokens": [50964, 300, 291, 727, 445, 11, 300, 309, 311, 264, 6331, 1303, 51064], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 589, "seek": 153928, "start": 1553.28, "end": 1555.6, "text": " at this point can just take so much data.", "tokens": [51064, 412, 341, 935, 393, 445, 747, 370, 709, 1412, 13, 51180], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 590, "seek": 153928, "start": 1555.6, "end": 1556.3999999999999, "text": " Yeah, that's really interesting.", "tokens": [51180, 865, 11, 300, 311, 534, 1880, 13, 51220], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 591, "seek": 153928, "start": 1556.3999999999999, "end": 1558.24, "text": " So what is this imply by future models?", "tokens": [51220, 407, 437, 307, 341, 33616, 538, 2027, 5245, 30, 51312], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 592, "seek": 153928, "start": 1558.96, "end": 1562.32, "text": " You mentioned that the Llama 3 8B is better", "tokens": [51348, 509, 2835, 300, 264, 32717, 2404, 805, 1649, 33, 307, 1101, 51516], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 593, "seek": 153928, "start": 1562.32, "end": 1563.52, "text": " than the Llama 270B?", "tokens": [51516, 813, 264, 32717, 2404, 40774, 33, 30, 51576], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 594, "seek": 153928, "start": 1563.52, "end": 1564.72, "text": " No, no, no, it's nearly as good.", "tokens": [51576, 883, 11, 572, 11, 572, 11, 309, 311, 6217, 382, 665, 13, 51636], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 595, "seek": 153928, "start": 1564.72, "end": 1565.44, "text": " Okay.", "tokens": [51636, 1033, 13, 51672], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 596, "seek": 153928, "start": 1565.44, "end": 1566.32, "text": " I don't overstep.", "tokens": [51672, 286, 500, 380, 670, 16792, 13, 51716], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 597, "seek": 153928, "start": 1566.32, "end": 1567.44, "text": " But does that mean like the Llama 4?", "tokens": [51716, 583, 775, 300, 914, 411, 264, 32717, 2404, 1017, 30, 51772], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 598, "seek": 153928, "start": 1567.44, "end": 1568.32, "text": " The same order of magnitude.", "tokens": [51772, 440, 912, 1668, 295, 15668, 13, 51816], "temperature": 0.0, "avg_logprob": -0.19232379822503953, "compression_ratio": 1.6635802469135803, "no_speech_prob": 0.0023227932397276163}, {"id": 599, "seek": 156832, "start": 1568.3999999999999, "end": 1569.28, "text": " Does that mean like the Llama 4?", "tokens": [50368, 4402, 300, 914, 411, 264, 32717, 2404, 1017, 30, 50412], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 600, "seek": 156832, "start": 1569.28, "end": 1570.8, "text": " 70B will be as good as the Llama 3?", "tokens": [50412, 5285, 33, 486, 312, 382, 665, 382, 264, 32717, 2404, 805, 30, 50488], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 601, "seek": 156832, "start": 1570.8, "end": 1571.76, "text": " 4 or 5B?", "tokens": [50488, 1017, 420, 1025, 33, 30, 50536], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 602, "seek": 156832, "start": 1571.76, "end": 1575.12, "text": " I mean, this is one of the great questions, right?", "tokens": [50536, 286, 914, 11, 341, 307, 472, 295, 264, 869, 1651, 11, 558, 30, 50704], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 603, "seek": 156832, "start": 1575.12, "end": 1577.9199999999998, "text": " That I think no one knows is basically,", "tokens": [50704, 663, 286, 519, 572, 472, 3255, 307, 1936, 11, 50844], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 604, "seek": 156832, "start": 1579.6799999999998, "end": 1582.8, "text": " you know, it's one of the trickiest things in the world", "tokens": [50932, 291, 458, 11, 309, 311, 472, 295, 264, 4282, 6495, 721, 294, 264, 1002, 51088], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 605, "seek": 156832, "start": 1582.8, "end": 1585.28, "text": " to plan around is when you have an exponential curve,", "tokens": [51088, 281, 1393, 926, 307, 562, 291, 362, 364, 21510, 7605, 11, 51212], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 606, "seek": 156832, "start": 1585.28, "end": 1586.8799999999999, "text": " how long does it keep going for?", "tokens": [51212, 577, 938, 775, 309, 1066, 516, 337, 30, 51292], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 607, "seek": 156832, "start": 1587.52, "end": 1592.08, "text": " And I think it's likely enough that it will keep going,", "tokens": [51324, 400, 286, 519, 309, 311, 3700, 1547, 300, 309, 486, 1066, 516, 11, 51552], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 608, "seek": 156832, "start": 1592.08, "end": 1596.24, "text": " that it is worth investing the tens or, you know,", "tokens": [51552, 300, 309, 307, 3163, 10978, 264, 10688, 420, 11, 291, 458, 11, 51760], "temperature": 0.0, "avg_logprob": -0.17402617633342743, "compression_ratio": 1.641732283464567, "no_speech_prob": 0.0005527035100385547}, {"id": 609, "seek": 159624, "start": 1596.32, "end": 1599.36, "text": " 100 billion plus in building the infrastructure", "tokens": [50368, 2319, 5218, 1804, 294, 2390, 264, 6896, 50520], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 610, "seek": 159624, "start": 1599.36, "end": 1602.48, "text": " to assume that if that kind of keeps going,", "tokens": [50520, 281, 6552, 300, 498, 300, 733, 295, 5965, 516, 11, 50676], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 611, "seek": 159624, "start": 1602.48, "end": 1604.72, "text": " you're going to get some really amazing things", "tokens": [50676, 291, 434, 516, 281, 483, 512, 534, 2243, 721, 50788], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 612, "seek": 159624, "start": 1604.72, "end": 1606.48, "text": " that are just going to make amazing products.", "tokens": [50788, 300, 366, 445, 516, 281, 652, 2243, 3383, 13, 50876], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 613, "seek": 159624, "start": 1607.04, "end": 1610.64, "text": " But I don't think anyone in the industry can really tell you", "tokens": [50904, 583, 286, 500, 380, 519, 2878, 294, 264, 3518, 393, 534, 980, 291, 51084], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 614, "seek": 159624, "start": 1611.6, "end": 1615.2, "text": " that it will continue scaling at that rate for sure, right?", "tokens": [51132, 300, 309, 486, 2354, 21589, 412, 300, 3314, 337, 988, 11, 558, 30, 51312], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 615, "seek": 159624, "start": 1615.2, "end": 1618.64, "text": " In general, in history, you hit bottlenecks at certain points.", "tokens": [51312, 682, 2674, 11, 294, 2503, 11, 291, 2045, 44641, 2761, 412, 1629, 2793, 13, 51484], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 616, "seek": 159624, "start": 1618.64, "end": 1620.8, "text": " And now there's so much energy on this", "tokens": [51484, 400, 586, 456, 311, 370, 709, 2281, 322, 341, 51592], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 617, "seek": 159624, "start": 1620.8, "end": 1623.92, "text": " that maybe those bottlenecks get knocked over pretty quickly.", "tokens": [51592, 300, 1310, 729, 44641, 2761, 483, 16914, 670, 1238, 2661, 13, 51748], "temperature": 0.0, "avg_logprob": -0.07401553444240404, "compression_ratio": 1.6810035842293907, "no_speech_prob": 0.0011694078566506505}, {"id": 618, "seek": 162392, "start": 1623.92, "end": 1628.0800000000002, "text": " But I don't know. I think that's an interesting question.", "tokens": [50364, 583, 286, 500, 380, 458, 13, 286, 519, 300, 311, 364, 1880, 1168, 13, 50572], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 619, "seek": 162392, "start": 1628.0800000000002, "end": 1631.1200000000001, "text": " What does the world look like where there aren't these bottlenecks?", "tokens": [50572, 708, 775, 264, 1002, 574, 411, 689, 456, 3212, 380, 613, 44641, 2761, 30, 50724], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 620, "seek": 162392, "start": 1631.1200000000001, "end": 1634.24, "text": " Suppose like progress just continues at this pace,", "tokens": [50724, 21360, 411, 4205, 445, 6515, 412, 341, 11638, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 621, "seek": 162392, "start": 1634.24, "end": 1637.52, "text": " which seems like plausible, like zooming out.", "tokens": [50880, 597, 2544, 411, 39925, 11, 411, 48226, 484, 13, 51044], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 622, "seek": 162392, "start": 1637.52, "end": 1639.8400000000001, "text": " Well, they're going to be different bottlenecks.", "tokens": [51044, 1042, 11, 436, 434, 516, 281, 312, 819, 44641, 2761, 13, 51160], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 623, "seek": 162392, "start": 1640.5600000000002, "end": 1642.8000000000002, "text": " Right. So if not training, then like, oh, yeah, go ahead.", "tokens": [51196, 1779, 13, 407, 498, 406, 3097, 11, 550, 411, 11, 1954, 11, 1338, 11, 352, 2286, 13, 51308], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 624, "seek": 162392, "start": 1643.68, "end": 1647.6000000000001, "text": " Well, I think at some point, over the last few years,", "tokens": [51352, 1042, 11, 286, 519, 412, 512, 935, 11, 670, 264, 1036, 1326, 924, 11, 51548], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 625, "seek": 162392, "start": 1647.6000000000001, "end": 1651.2, "text": " I think there was this issue of GPU production.", "tokens": [51548, 286, 519, 456, 390, 341, 2734, 295, 18407, 4265, 13, 51728], "temperature": 0.0, "avg_logprob": -0.1830958004655509, "compression_ratio": 1.6142322097378277, "no_speech_prob": 0.0019875287543982267}, {"id": 626, "seek": 165120, "start": 1651.2, "end": 1653.76, "text": " Yeah. Right. So even companies that had the models,", "tokens": [50364, 865, 13, 1779, 13, 407, 754, 3431, 300, 632, 264, 5245, 11, 50492], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 627, "seek": 165120, "start": 1655.2, "end": 1657.1200000000001, "text": " sorry, that had the money to pay for the GPUs,", "tokens": [50564, 2597, 11, 300, 632, 264, 1460, 281, 1689, 337, 264, 18407, 82, 11, 50660], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 628, "seek": 165120, "start": 1658.8, "end": 1660.64, "text": " couldn't necessarily get as many as they wanted", "tokens": [50744, 2809, 380, 4725, 483, 382, 867, 382, 436, 1415, 50836], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 629, "seek": 165120, "start": 1660.64, "end": 1663.1200000000001, "text": " because there were all these supply constraints.", "tokens": [50836, 570, 456, 645, 439, 613, 5847, 18491, 13, 50960], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 630, "seek": 165120, "start": 1663.1200000000001, "end": 1665.68, "text": " Now I think that's sort of getting less.", "tokens": [50960, 823, 286, 519, 300, 311, 1333, 295, 1242, 1570, 13, 51088], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 631, "seek": 165120, "start": 1666.24, "end": 1670.32, "text": " So now I think you're seeing a bunch of companies think about,", "tokens": [51116, 407, 586, 286, 519, 291, 434, 2577, 257, 3840, 295, 3431, 519, 466, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 632, "seek": 165120, "start": 1670.32, "end": 1672.64, "text": " wow, we should just like really invest a lot of money", "tokens": [51320, 6076, 11, 321, 820, 445, 411, 534, 1963, 257, 688, 295, 1460, 51436], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 633, "seek": 165120, "start": 1672.64, "end": 1673.8400000000001, "text": " in building out these things.", "tokens": [51436, 294, 2390, 484, 613, 721, 13, 51496], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 634, "seek": 165120, "start": 1673.8400000000001, "end": 1676.96, "text": " And I think that that will go for some period of time.", "tokens": [51496, 400, 286, 519, 300, 300, 486, 352, 337, 512, 2896, 295, 565, 13, 51652], "temperature": 0.0, "avg_logprob": -0.11781956599308895, "compression_ratio": 1.6717557251908397, "no_speech_prob": 0.0014549323823302984}, {"id": 635, "seek": 167696, "start": 1677.8400000000001, "end": 1682.4, "text": " I think there's a, there is a capital question of like, okay,", "tokens": [50408, 286, 519, 456, 311, 257, 11, 456, 307, 257, 4238, 1168, 295, 411, 11, 1392, 11, 50636], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 636, "seek": 167696, "start": 1683.28, "end": 1686.64, "text": " at what point does it stop being worth it to put the capital in?", "tokens": [50680, 412, 437, 935, 775, 309, 1590, 885, 3163, 309, 281, 829, 264, 4238, 294, 30, 50848], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 637, "seek": 167696, "start": 1686.64, "end": 1689.04, "text": " But I actually think before we hit that,", "tokens": [50848, 583, 286, 767, 519, 949, 321, 2045, 300, 11, 50968], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 638, "seek": 167696, "start": 1689.04, "end": 1691.1200000000001, "text": " you're going to run into energy constraints.", "tokens": [50968, 291, 434, 516, 281, 1190, 666, 2281, 18491, 13, 51072], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 639, "seek": 167696, "start": 1691.1200000000001, "end": 1694.08, "text": " Right. Because I just, I mean,", "tokens": [51072, 1779, 13, 1436, 286, 445, 11, 286, 914, 11, 51220], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 640, "seek": 167696, "start": 1694.08, "end": 1699.1200000000001, "text": " I don't think anyone's built a gigawatt single training cluster yet.", "tokens": [51220, 286, 500, 380, 519, 2878, 311, 3094, 257, 8741, 1607, 1591, 2167, 3097, 13630, 1939, 13, 51472], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 641, "seek": 167696, "start": 1699.1200000000001, "end": 1701.6000000000001, "text": " Right. And then you run into these things", "tokens": [51472, 1779, 13, 400, 550, 291, 1190, 666, 613, 721, 51596], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 642, "seek": 167696, "start": 1701.6000000000001, "end": 1703.2, "text": " that just end up being slower in the world.", "tokens": [51596, 300, 445, 917, 493, 885, 14009, 294, 264, 1002, 13, 51676], "temperature": 0.0, "avg_logprob": -0.09946128054782077, "compression_ratio": 1.6378600823045268, "no_speech_prob": 0.0033764210529625416}, {"id": 643, "seek": 170320, "start": 1703.2, "end": 1706.4, "text": " Like getting energy permitted", "tokens": [50364, 1743, 1242, 2281, 28658, 50524], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 644, "seek": 170320, "start": 1706.4, "end": 1711.04, "text": " is like a very heavily regulated government function.", "tokens": [50524, 307, 411, 257, 588, 10950, 26243, 2463, 2445, 13, 50756], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 645, "seek": 170320, "start": 1711.04, "end": 1714.32, "text": " Right. So you're going from on the one hand software,", "tokens": [50756, 1779, 13, 407, 291, 434, 516, 490, 322, 264, 472, 1011, 4722, 11, 50920], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 646, "seek": 170320, "start": 1714.32, "end": 1716.24, "text": " which is somewhat regulated.", "tokens": [50920, 597, 307, 8344, 26243, 13, 51016], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 647, "seek": 170320, "start": 1716.24, "end": 1718.32, "text": " I'd argue that it is more regulated", "tokens": [51016, 286, 1116, 9695, 300, 309, 307, 544, 26243, 51120], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 648, "seek": 170320, "start": 1718.32, "end": 1721.3600000000001, "text": " than I think a lot of people in the tech community feel,", "tokens": [51120, 813, 286, 519, 257, 688, 295, 561, 294, 264, 7553, 1768, 841, 11, 51272], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 649, "seek": 170320, "start": 1721.3600000000001, "end": 1722.48, "text": " although it's obviously different.", "tokens": [51272, 4878, 309, 311, 2745, 819, 13, 51328], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 650, "seek": 170320, "start": 1722.48, "end": 1723.68, "text": " If you're starting a small company,", "tokens": [51328, 759, 291, 434, 2891, 257, 1359, 2237, 11, 51388], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 651, "seek": 170320, "start": 1723.68, "end": 1725.68, "text": " maybe you feel that less if you're a big company,", "tokens": [51388, 1310, 291, 841, 300, 1570, 498, 291, 434, 257, 955, 2237, 11, 51488], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 652, "seek": 170320, "start": 1725.68, "end": 1727.3600000000001, "text": " you know, we just interact with people,", "tokens": [51488, 291, 458, 11, 321, 445, 4648, 365, 561, 11, 51572], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 653, "seek": 170320, "start": 1727.3600000000001, "end": 1729.44, "text": " but different governments and regulators are,", "tokens": [51572, 457, 819, 11280, 293, 37311, 366, 11, 51676], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 654, "seek": 170320, "start": 1729.44, "end": 1732.56, "text": " you know, we have kind of lots of rules", "tokens": [51676, 291, 458, 11, 321, 362, 733, 295, 3195, 295, 4474, 51832], "temperature": 0.0, "avg_logprob": -0.12355996645413912, "compression_ratio": 1.7508650519031141, "no_speech_prob": 0.0005883593112230301}, {"id": 655, "seek": 173256, "start": 1732.56, "end": 1733.6, "text": " that we need to kind of follow", "tokens": [50364, 300, 321, 643, 281, 733, 295, 1524, 50416], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 656, "seek": 173256, "start": 1733.6, "end": 1735.28, "text": " and make sure we do a good job with around the world.", "tokens": [50416, 293, 652, 988, 321, 360, 257, 665, 1691, 365, 926, 264, 1002, 13, 50500], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 657, "seek": 173256, "start": 1736.72, "end": 1738.8, "text": " But I think that there's no doubt that like energy,", "tokens": [50572, 583, 286, 519, 300, 456, 311, 572, 6385, 300, 411, 2281, 11, 50676], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 658, "seek": 173256, "start": 1738.8, "end": 1742.72, "text": " and if you're talking about building large new power plants", "tokens": [50676, 293, 498, 291, 434, 1417, 466, 2390, 2416, 777, 1347, 5972, 50872], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 659, "seek": 173256, "start": 1742.72, "end": 1745.52, "text": " or large buildouts and then building transmission lines", "tokens": [50872, 420, 2416, 1322, 7711, 293, 550, 2390, 11574, 3876, 51012], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 660, "seek": 173256, "start": 1745.52, "end": 1749.9199999999998, "text": " that cross other private or public land,", "tokens": [51012, 300, 3278, 661, 4551, 420, 1908, 2117, 11, 51232], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 661, "seek": 173256, "start": 1749.9199999999998, "end": 1751.76, "text": " that is just a heavily regulated thing.", "tokens": [51232, 300, 307, 445, 257, 10950, 26243, 551, 13, 51324], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 662, "seek": 173256, "start": 1751.76, "end": 1754.48, "text": " So you're talking about many years of lead time.", "tokens": [51324, 407, 291, 434, 1417, 466, 867, 924, 295, 1477, 565, 13, 51460], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 663, "seek": 173256, "start": 1754.48, "end": 1758.8, "text": " So if we wanted to stand up to some like massive facility", "tokens": [51460, 407, 498, 321, 1415, 281, 1463, 493, 281, 512, 411, 5994, 8973, 51676], "temperature": 0.0, "avg_logprob": -0.09046626735377956, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0010985387489199638}, {"id": 664, "seek": 175880, "start": 1758.8, "end": 1763.04, "text": " to power that, I think that that is,", "tokens": [50364, 281, 1347, 300, 11, 286, 519, 300, 300, 307, 11, 50576], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 665, "seek": 175880, "start": 1764.08, "end": 1766.8, "text": " that's a very long-term project, right?", "tokens": [50628, 300, 311, 257, 588, 938, 12, 7039, 1716, 11, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 666, "seek": 175880, "start": 1766.8, "end": 1769.6, "text": " And so I don't know, I think that that's,", "tokens": [50764, 400, 370, 286, 500, 380, 458, 11, 286, 519, 300, 300, 311, 11, 50904], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 667, "seek": 175880, "start": 1769.6, "end": 1770.96, "text": " I think people will do it,", "tokens": [50904, 286, 519, 561, 486, 360, 309, 11, 50972], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 668, "seek": 175880, "start": 1770.96, "end": 1773.28, "text": " but I don't think that this is like something", "tokens": [50972, 457, 286, 500, 380, 519, 300, 341, 307, 411, 746, 51088], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 669, "seek": 175880, "start": 1773.28, "end": 1775.44, "text": " that can be quite as magical as just like,", "tokens": [51088, 300, 393, 312, 1596, 382, 12066, 382, 445, 411, 11, 51196], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 670, "seek": 175880, "start": 1775.44, "end": 1777.76, "text": " okay, you get a level of AI and you get a bunch of capital", "tokens": [51196, 1392, 11, 291, 483, 257, 1496, 295, 7318, 293, 291, 483, 257, 3840, 295, 4238, 51312], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 671, "seek": 175880, "start": 1777.76, "end": 1779.2, "text": " and you put it in and then like all of a sudden", "tokens": [51312, 293, 291, 829, 309, 294, 293, 550, 411, 439, 295, 257, 3990, 51384], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 672, "seek": 175880, "start": 1779.2, "end": 1781.44, "text": " the models are just going to kind of like interest,", "tokens": [51384, 264, 5245, 366, 445, 516, 281, 733, 295, 411, 1179, 11, 51496], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 673, "seek": 175880, "start": 1781.44, "end": 1783.84, "text": " like I think you do hit different bottlenecks along the way.", "tokens": [51496, 411, 286, 519, 291, 360, 2045, 819, 44641, 2761, 2051, 264, 636, 13, 51616], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 674, "seek": 175880, "start": 1783.84, "end": 1786.32, "text": " Yeah. Is there something, a project,", "tokens": [51616, 865, 13, 1119, 456, 746, 11, 257, 1716, 11, 51740], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 675, "seek": 175880, "start": 1786.32, "end": 1788.1599999999999, "text": " maybe I realized maybe not,", "tokens": [51740, 1310, 286, 5334, 1310, 406, 11, 51832], "temperature": 0.0, "avg_logprob": -0.18329712612177032, "compression_ratio": 1.7958477508650519, "no_speech_prob": 0.008313686586916447}, {"id": 676, "seek": 178816, "start": 1788.16, "end": 1791.3600000000001, "text": " that even a company like Meta doesn't have the resources for,", "tokens": [50364, 300, 754, 257, 2237, 411, 6377, 64, 1177, 380, 362, 264, 3593, 337, 11, 50524], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 677, "seek": 178816, "start": 1791.3600000000001, "end": 1794.64, "text": " like if your R&D budget or CapEx budget was 10x what it is now,", "tokens": [50524, 411, 498, 428, 497, 5, 35, 4706, 420, 8363, 11149, 4706, 390, 1266, 87, 437, 309, 307, 586, 11, 50688], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 678, "seek": 178816, "start": 1794.64, "end": 1796.8000000000002, "text": " then you could pursue it, like it's in the back of your mind,", "tokens": [50688, 550, 291, 727, 12392, 309, 11, 411, 309, 311, 294, 264, 646, 295, 428, 1575, 11, 50796], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 679, "seek": 178816, "start": 1796.8000000000002, "end": 1800.0, "text": " but Meta today, maybe you could like,", "tokens": [50796, 457, 6377, 64, 965, 11, 1310, 291, 727, 411, 11, 50956], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 680, "seek": 178816, "start": 1800.0, "end": 1801.68, "text": " even you can't even issue a stock or bond for it,", "tokens": [50956, 754, 291, 393, 380, 754, 2734, 257, 4127, 420, 6086, 337, 309, 11, 51040], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 681, "seek": 178816, "start": 1801.68, "end": 1803.52, "text": " it's like just 10x bigger than your budget.", "tokens": [51040, 309, 311, 411, 445, 1266, 87, 3801, 813, 428, 4706, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 682, "seek": 178816, "start": 1803.52, "end": 1805.28, "text": " Well, I think energy is one piece, right?", "tokens": [51132, 1042, 11, 286, 519, 2281, 307, 472, 2522, 11, 558, 30, 51220], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 683, "seek": 178816, "start": 1806.4, "end": 1810.16, "text": " I think we would probably build out bigger clusters", "tokens": [51276, 286, 519, 321, 576, 1391, 1322, 484, 3801, 23313, 51464], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 684, "seek": 178816, "start": 1810.16, "end": 1815.8400000000001, "text": " than we currently can if we could get the energy to do it.", "tokens": [51464, 813, 321, 4362, 393, 498, 321, 727, 483, 264, 2281, 281, 360, 309, 13, 51748], "temperature": 0.0, "avg_logprob": -0.13648097184452698, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.0002165282639907673}, {"id": 685, "seek": 181584, "start": 1815.84, "end": 1821.9199999999998, "text": " So I think that's fundamentally money bottlenecked in the limit,", "tokens": [50364, 407, 286, 519, 300, 311, 17879, 1460, 44641, 44118, 294, 264, 4948, 11, 50668], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 686, "seek": 181584, "start": 1821.9199999999998, "end": 1823.04, "text": " like if you had a trillion dollars.", "tokens": [50668, 411, 498, 291, 632, 257, 18723, 3808, 13, 50724], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 687, "seek": 181584, "start": 1823.04, "end": 1824.6399999999999, "text": " I think it's time, right?", "tokens": [50724, 286, 519, 309, 311, 565, 11, 558, 30, 50804], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 688, "seek": 181584, "start": 1826.32, "end": 1828.72, "text": " Well, if you look at it in terms of,", "tokens": [50888, 1042, 11, 498, 291, 574, 412, 309, 294, 2115, 295, 11, 51008], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 689, "seek": 181584, "start": 1828.72, "end": 1831.52, "text": " but it depends on how far the exponential curves go, right?", "tokens": [51008, 457, 309, 5946, 322, 577, 1400, 264, 21510, 19490, 352, 11, 558, 30, 51148], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 690, "seek": 181584, "start": 1831.52, "end": 1834.1599999999999, "text": " Like I think a number of companies are working on,", "tokens": [51148, 1743, 286, 519, 257, 1230, 295, 3431, 366, 1364, 322, 11, 51280], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 691, "seek": 181584, "start": 1834.1599999999999, "end": 1836.8, "text": " you know, right now I think a lot of data centers", "tokens": [51280, 291, 458, 11, 558, 586, 286, 519, 257, 688, 295, 1412, 10898, 51412], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 692, "seek": 181584, "start": 1836.8, "end": 1839.12, "text": " are on the order of 50 megawatts or 100 megawatts,", "tokens": [51412, 366, 322, 264, 1668, 295, 2625, 10816, 38036, 1373, 420, 2319, 10816, 38036, 1373, 11, 51528], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 693, "seek": 181584, "start": 1839.12, "end": 1841.36, "text": " or like a big one might be 150 megawatts.", "tokens": [51528, 420, 411, 257, 955, 472, 1062, 312, 8451, 10816, 38036, 1373, 13, 51640], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 694, "seek": 181584, "start": 1841.36, "end": 1844.1599999999999, "text": " Okay, so you take a whole data center and you fill it up with", "tokens": [51640, 1033, 11, 370, 291, 747, 257, 1379, 1412, 3056, 293, 291, 2836, 309, 493, 365, 51780], "temperature": 0.0, "avg_logprob": -0.12735166549682617, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0008295378065668046}, {"id": 695, "seek": 184416, "start": 1844.24, "end": 1846.16, "text": " just all the stuff that you need to do for training", "tokens": [50368, 445, 439, 264, 1507, 300, 291, 643, 281, 360, 337, 3097, 50464], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 696, "seek": 184416, "start": 1846.16, "end": 1847.52, "text": " and you build the biggest cluster you can.", "tokens": [50464, 293, 291, 1322, 264, 3880, 13630, 291, 393, 13, 50532], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 697, "seek": 184416, "start": 1847.52, "end": 1849.68, "text": " I think that's kind of,", "tokens": [50532, 286, 519, 300, 311, 733, 295, 11, 50640], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 698, "seek": 184416, "start": 1849.68, "end": 1851.76, "text": " I think a bunch of companies are running at stuff like that.", "tokens": [50640, 286, 519, 257, 3840, 295, 3431, 366, 2614, 412, 1507, 411, 300, 13, 50744], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 699, "seek": 184416, "start": 1853.2, "end": 1857.92, "text": " But then when you start getting into building a data center", "tokens": [50816, 583, 550, 562, 291, 722, 1242, 666, 2390, 257, 1412, 3056, 51052], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 700, "seek": 184416, "start": 1857.92, "end": 1862.64, "text": " that's like 300 megawatts or 500 megawatts or a gigawatt,", "tokens": [51052, 300, 311, 411, 6641, 10816, 38036, 1373, 420, 5923, 10816, 38036, 1373, 420, 257, 8741, 1607, 1591, 11, 51288], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 701, "seek": 184416, "start": 1862.64, "end": 1866.3200000000002, "text": " I mean, just no one has built a single gigawatt data center yet.", "tokens": [51288, 286, 914, 11, 445, 572, 472, 575, 3094, 257, 2167, 8741, 1607, 1591, 1412, 3056, 1939, 13, 51472], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 702, "seek": 184416, "start": 1866.3200000000002, "end": 1867.6000000000001, "text": " So I think it will happen, right?", "tokens": [51472, 407, 286, 519, 309, 486, 1051, 11, 558, 30, 51536], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 703, "seek": 184416, "start": 1867.6000000000001, "end": 1868.8000000000002, "text": " I mean, this is only a matter of time,", "tokens": [51536, 286, 914, 11, 341, 307, 787, 257, 1871, 295, 565, 11, 51596], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 704, "seek": 184416, "start": 1868.8000000000002, "end": 1871.8400000000001, "text": " but it's not going to be like next year, right?", "tokens": [51596, 457, 309, 311, 406, 516, 281, 312, 411, 958, 1064, 11, 558, 30, 51748], "temperature": 0.0, "avg_logprob": -0.09664983952299078, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.0009696747292764485}, {"id": 705, "seek": 187184, "start": 1872.3999999999999, "end": 1876.24, "text": " I think that some of these things will take, I don't know,", "tokens": [50392, 286, 519, 300, 512, 295, 613, 721, 486, 747, 11, 286, 500, 380, 458, 11, 50584], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 706, "seek": 187184, "start": 1877.04, "end": 1879.12, "text": " some number of years to build out.", "tokens": [50624, 512, 1230, 295, 924, 281, 1322, 484, 13, 50728], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 707, "seek": 187184, "start": 1879.12, "end": 1880.8799999999999, "text": " And then the question is, okay, well, if you,", "tokens": [50728, 400, 550, 264, 1168, 307, 11, 1392, 11, 731, 11, 498, 291, 11, 50816], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 708, "seek": 187184, "start": 1882.3999999999999, "end": 1884.24, "text": " I mean, just to, I guess, put this in perspective,", "tokens": [50892, 286, 914, 11, 445, 281, 11, 286, 2041, 11, 829, 341, 294, 4585, 11, 50984], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 709, "seek": 187184, "start": 1885.4399999999998, "end": 1889.52, "text": " I think a gigawatt, it's like around the size of like", "tokens": [51044, 286, 519, 257, 8741, 1607, 1591, 11, 309, 311, 411, 926, 264, 2744, 295, 411, 51248], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 710, "seek": 187184, "start": 1890.1599999999999, "end": 1892.3999999999999, "text": " a meaningful nuclear power plant", "tokens": [51280, 257, 10995, 8179, 1347, 3709, 51392], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 711, "seek": 187184, "start": 1892.3999999999999, "end": 1894.8, "text": " only going towards training a model.", "tokens": [51392, 787, 516, 3030, 3097, 257, 2316, 13, 51512], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 712, "seek": 187184, "start": 1894.8, "end": 1896.3999999999999, "text": " Didn't Amazon do this?", "tokens": [51512, 11151, 380, 6795, 360, 341, 30, 51592], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 713, "seek": 187184, "start": 1896.3999999999999, "end": 1898.9599999999998, "text": " There's like, they have a 950 megawatt thing.", "tokens": [51592, 821, 311, 411, 11, 436, 362, 257, 1722, 2803, 10816, 1607, 1591, 551, 13, 51720], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 714, "seek": 187184, "start": 1898.9599999999998, "end": 1900.56, "text": " Yeah, I'm not exactly sure what you did.", "tokens": [51720, 865, 11, 286, 478, 406, 2293, 988, 437, 291, 630, 13, 51800], "temperature": 0.0, "avg_logprob": -0.13049975175123948, "compression_ratio": 1.5474452554744527, "no_speech_prob": 0.005384590942412615}, {"id": 715, "seek": 190056, "start": 1901.12, "end": 1902.24, "text": " What they did, you'd have to ask them.", "tokens": [50392, 708, 436, 630, 11, 291, 1116, 362, 281, 1029, 552, 13, 50448], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 716, "seek": 190056, "start": 1903.84, "end": 1905.28, "text": " But it doesn't have to be in the same place, right?", "tokens": [50528, 583, 309, 1177, 380, 362, 281, 312, 294, 264, 912, 1081, 11, 558, 30, 50600], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 717, "seek": 190056, "start": 1905.28, "end": 1907.2, "text": " If distributed training works, it can be distributed.", "tokens": [50600, 759, 12631, 3097, 1985, 11, 309, 393, 312, 12631, 13, 50696], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 718, "seek": 190056, "start": 1907.2, "end": 1908.08, "text": " That I think is a big question.", "tokens": [50696, 663, 286, 519, 307, 257, 955, 1168, 13, 50740], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 719, "seek": 190056, "start": 1908.08, "end": 1908.3999999999999, "text": " Yeah.", "tokens": [50740, 865, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 720, "seek": 190056, "start": 1908.3999999999999, "end": 1909.9199999999998, "text": " Right, is basically how that's going to work.", "tokens": [50756, 1779, 11, 307, 1936, 577, 300, 311, 516, 281, 589, 13, 50832], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 721, "seek": 190056, "start": 1909.9199999999998, "end": 1911.12, "text": " And I do think in the future,", "tokens": [50832, 400, 286, 360, 519, 294, 264, 2027, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 722, "seek": 190056, "start": 1912.1599999999999, "end": 1916.56, "text": " it seems quite possible that more of what we call training", "tokens": [50944, 309, 2544, 1596, 1944, 300, 544, 295, 437, 321, 818, 3097, 51164], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 723, "seek": 190056, "start": 1916.56, "end": 1921.6799999999998, "text": " for these big models is actually more along the lines", "tokens": [51164, 337, 613, 955, 5245, 307, 767, 544, 2051, 264, 3876, 51420], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 724, "seek": 190056, "start": 1922.24, "end": 1924.8799999999999, "text": " of inference generating synthetic data", "tokens": [51448, 295, 38253, 17746, 23420, 1412, 51580], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 725, "seek": 190056, "start": 1924.8799999999999, "end": 1926.56, "text": " to then go feed into the model.", "tokens": [51580, 281, 550, 352, 3154, 666, 264, 2316, 13, 51664], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 726, "seek": 190056, "start": 1926.56, "end": 1928.56, "text": " So I don't know what that ratio is going to be,", "tokens": [51664, 407, 286, 500, 380, 458, 437, 300, 8509, 307, 516, 281, 312, 11, 51764], "temperature": 0.0, "avg_logprob": -0.11487362158559535, "compression_ratio": 1.6896551724137931, "no_speech_prob": 0.0015976945869624615}, {"id": 727, "seek": 192856, "start": 1928.56, "end": 1932.3999999999999, "text": " but I consider the generation of synthetic data", "tokens": [50364, 457, 286, 1949, 264, 5125, 295, 23420, 1412, 50556], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 728, "seek": 192856, "start": 1932.3999999999999, "end": 1934.48, "text": " to be more inference than training today.", "tokens": [50556, 281, 312, 544, 38253, 813, 3097, 965, 13, 50660], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 729, "seek": 192856, "start": 1934.48, "end": 1936.8, "text": " But obviously, if you're doing it in order to train a model,", "tokens": [50660, 583, 2745, 11, 498, 291, 434, 884, 309, 294, 1668, 281, 3847, 257, 2316, 11, 50776], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 730, "seek": 192856, "start": 1936.8, "end": 1938.72, "text": " it's part of the broader training process.", "tokens": [50776, 309, 311, 644, 295, 264, 13227, 3097, 1399, 13, 50872], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 731, "seek": 192856, "start": 1939.28, "end": 1943.44, "text": " So I don't know, that's an open question,", "tokens": [50900, 407, 286, 500, 380, 458, 11, 300, 311, 364, 1269, 1168, 11, 51108], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 732, "seek": 192856, "start": 1943.44, "end": 1945.44, "text": " is to kind of where, what the balance of that", "tokens": [51108, 307, 281, 733, 295, 689, 11, 437, 264, 4772, 295, 300, 51208], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 733, "seek": 192856, "start": 1945.44, "end": 1946.48, "text": " and how that plays out.", "tokens": [51208, 293, 577, 300, 5749, 484, 13, 51260], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 734, "seek": 192856, "start": 1946.48, "end": 1949.76, "text": " If that's the case, would that potentially also", "tokens": [51260, 759, 300, 311, 264, 1389, 11, 576, 300, 7263, 611, 51424], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 735, "seek": 192856, "start": 1949.76, "end": 1951.2, "text": " be the case with Lama 3?", "tokens": [51424, 312, 264, 1389, 365, 441, 2404, 805, 30, 51496], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 736, "seek": 192856, "start": 1951.2, "end": 1954.0, "text": " And maybe like Lama 4 onwards, where you put this out", "tokens": [51496, 400, 1310, 411, 441, 2404, 1017, 34230, 11, 689, 291, 829, 341, 484, 51636], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 737, "seek": 192856, "start": 1954.0, "end": 1955.84, "text": " and if somebody has a ton of compute,", "tokens": [51636, 293, 498, 2618, 575, 257, 2952, 295, 14722, 11, 51728], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 738, "seek": 192856, "start": 1955.84, "end": 1957.6799999999998, "text": " then using the models that you've put out,", "tokens": [51728, 550, 1228, 264, 5245, 300, 291, 600, 829, 484, 11, 51820], "temperature": 0.0, "avg_logprob": -0.11193637190193965, "compression_ratio": 1.6986754966887416, "no_speech_prob": 0.00034596159821376204}, {"id": 739, "seek": 195768, "start": 1957.76, "end": 1959.92, "text": " you can just keep making these things arbitrarily smarter.", "tokens": [50368, 291, 393, 445, 1066, 1455, 613, 721, 19071, 3289, 20294, 13, 50476], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 740, "seek": 195768, "start": 1961.1200000000001, "end": 1964.72, "text": " Some Kuwait or UAE or some random country has a ton of compute,", "tokens": [50536, 2188, 20311, 26040, 420, 32765, 36, 420, 512, 4974, 1941, 575, 257, 2952, 295, 14722, 11, 50716], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 741, "seek": 195768, "start": 1965.6000000000001, "end": 1968.24, "text": " and they can just actually just use Lama 4", "tokens": [50760, 293, 436, 393, 445, 767, 445, 764, 441, 2404, 1017, 50892], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 742, "seek": 195768, "start": 1968.24, "end": 1969.44, "text": " to just make something much smarter.", "tokens": [50892, 281, 445, 652, 746, 709, 20294, 13, 50952], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 743, "seek": 195768, "start": 1972.24, "end": 1975.6000000000001, "text": " I do think that there are going to be dynamics like that,", "tokens": [51092, 286, 360, 519, 300, 456, 366, 516, 281, 312, 15679, 411, 300, 11, 51260], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 744, "seek": 195768, "start": 1975.6000000000001, "end": 1980.96, "text": " but I also think that there is a fundamental limitation", "tokens": [51260, 457, 286, 611, 519, 300, 456, 307, 257, 8088, 27432, 51528], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 745, "seek": 195768, "start": 1981.52, "end": 1985.76, "text": " on kind of the network architecture,", "tokens": [51556, 322, 733, 295, 264, 3209, 9482, 11, 51768], "temperature": 0.0, "avg_logprob": -0.14190893173217772, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0005032275221310556}, {"id": 746, "seek": 198576, "start": 1986.32, "end": 1988.08, "text": " the kind of model architecture.", "tokens": [50392, 264, 733, 295, 2316, 9482, 13, 50480], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 747, "seek": 198576, "start": 1988.08, "end": 1991.36, "text": " So I think like a 70 billion model", "tokens": [50480, 407, 286, 519, 411, 257, 5285, 5218, 2316, 50644], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 748, "seek": 198576, "start": 1992.32, "end": 1994.56, "text": " that kind of we trained with the Lama 3 architecture", "tokens": [50692, 300, 733, 295, 321, 8895, 365, 264, 441, 2404, 805, 9482, 50804], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 749, "seek": 198576, "start": 1994.56, "end": 1996.8, "text": " can get better, it can keep going.", "tokens": [50804, 393, 483, 1101, 11, 309, 393, 1066, 516, 13, 50916], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 750, "seek": 198576, "start": 1996.8, "end": 2000.16, "text": " Like I was saying, we felt like if we kept on feeding it", "tokens": [50916, 1743, 286, 390, 1566, 11, 321, 2762, 411, 498, 321, 4305, 322, 12919, 309, 51084], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 751, "seek": 198576, "start": 2000.16, "end": 2004.08, "text": " more data or rotated the high value tokens through again,", "tokens": [51084, 544, 1412, 420, 42146, 264, 1090, 2158, 22667, 807, 797, 11, 51280], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 752, "seek": 198576, "start": 2004.08, "end": 2006.16, "text": " then it would continue getting better.", "tokens": [51280, 550, 309, 576, 2354, 1242, 1101, 13, 51384], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 753, "seek": 198576, "start": 2006.8799999999999, "end": 2011.52, "text": " But, and we've seen a bunch of other people around the world,", "tokens": [51420, 583, 11, 293, 321, 600, 1612, 257, 3840, 295, 661, 561, 926, 264, 1002, 11, 51652], "temperature": 0.0, "avg_logprob": -0.2109789992823745, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.003171694464981556}, {"id": 754, "seek": 201152, "start": 2012.48, "end": 2015.28, "text": " you know, different companies basically take the Lama 2", "tokens": [50412, 291, 458, 11, 819, 3431, 1936, 747, 264, 441, 2404, 568, 50552], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 755, "seek": 201152, "start": 2015.92, "end": 2018.24, "text": " 70 billion base, like take that model architecture", "tokens": [50584, 5285, 5218, 3096, 11, 411, 747, 300, 2316, 9482, 50700], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 756, "seek": 201152, "start": 2018.24, "end": 2019.2, "text": " and then build a new model.", "tokens": [50700, 293, 550, 1322, 257, 777, 2316, 13, 50748], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 757, "seek": 201152, "start": 2021.36, "end": 2024.16, "text": " It's still the case that when you make a generational improvement", "tokens": [50856, 467, 311, 920, 264, 1389, 300, 562, 291, 652, 257, 48320, 10444, 50996], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 758, "seek": 201152, "start": 2024.16, "end": 2027.2, "text": " to the kind of Lama 3 70 billion or the Lama 3 405,", "tokens": [50996, 281, 264, 733, 295, 441, 2404, 805, 5285, 5218, 420, 264, 441, 2404, 805, 3356, 20, 11, 51148], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 759, "seek": 201152, "start": 2027.2, "end": 2029.92, "text": " there's nothing open source anything like that today, right?", "tokens": [51148, 456, 311, 1825, 1269, 4009, 1340, 411, 300, 965, 11, 558, 30, 51284], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 760, "seek": 201152, "start": 2029.92, "end": 2033.12, "text": " Like it's not, I think that that's like,", "tokens": [51284, 1743, 309, 311, 406, 11, 286, 519, 300, 300, 311, 411, 11, 51444], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 761, "seek": 201152, "start": 2033.12, "end": 2034.96, "text": " it's a big step function", "tokens": [51444, 309, 311, 257, 955, 1823, 2445, 51536], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 762, "seek": 201152, "start": 2034.96, "end": 2037.12, "text": " and what people are going to be able to build on top of", "tokens": [51536, 293, 437, 561, 366, 516, 281, 312, 1075, 281, 1322, 322, 1192, 295, 51644], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 763, "seek": 201152, "start": 2037.12, "end": 2039.76, "text": " that I don't think can go infinitely from there.", "tokens": [51644, 300, 286, 500, 380, 519, 393, 352, 36227, 490, 456, 13, 51776], "temperature": 0.0, "avg_logprob": -0.13058697093616833, "compression_ratio": 1.7102473498233215, "no_speech_prob": 0.015902940183877945}, {"id": 764, "seek": 203976, "start": 2039.84, "end": 2042.48, "text": " I think it can, there can be some optimization in that", "tokens": [50368, 286, 519, 309, 393, 11, 456, 393, 312, 512, 19618, 294, 300, 50500], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 765, "seek": 203976, "start": 2042.48, "end": 2043.92, "text": " until you get to the next step function.", "tokens": [50500, 1826, 291, 483, 281, 264, 958, 1823, 2445, 13, 50572], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 766, "seek": 203976, "start": 2044.8, "end": 2045.68, "text": " Yeah. Okay.", "tokens": [50616, 865, 13, 1033, 13, 50660], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 767, "seek": 203976, "start": 2045.68, "end": 2048.72, "text": " So let's zoom out a little bit from specific models", "tokens": [50660, 407, 718, 311, 8863, 484, 257, 707, 857, 490, 2685, 5245, 50812], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 768, "seek": 203976, "start": 2048.72, "end": 2052.0, "text": " and even the many years lead times you would need", "tokens": [50812, 293, 754, 264, 867, 924, 1477, 1413, 291, 576, 643, 50976], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 769, "seek": 203976, "start": 2052.0, "end": 2053.92, "text": " to get energy approvals and so on.", "tokens": [50976, 281, 483, 2281, 2075, 19778, 293, 370, 322, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 770, "seek": 203976, "start": 2053.92, "end": 2056.24, "text": " Like big picture, these next couple of decades,", "tokens": [51072, 1743, 955, 3036, 11, 613, 958, 1916, 295, 7878, 11, 51188], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 771, "seek": 203976, "start": 2056.24, "end": 2057.28, "text": " what's happening with AI?", "tokens": [51188, 437, 311, 2737, 365, 7318, 30, 51240], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 772, "seek": 203976, "start": 2058.08, "end": 2060.0, "text": " Does it feel like another technology,", "tokens": [51280, 4402, 309, 841, 411, 1071, 2899, 11, 51376], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 773, "seek": 203976, "start": 2060.0, "end": 2061.44, "text": " like metaverse or social,", "tokens": [51376, 411, 19616, 4308, 420, 2093, 11, 51448], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 774, "seek": 203976, "start": 2061.44, "end": 2063.52, "text": " or does it feel like a fundamentally different thing", "tokens": [51448, 420, 775, 309, 841, 411, 257, 17879, 819, 551, 51552], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 775, "seek": 203976, "start": 2063.52, "end": 2064.72, "text": " in the course of human history?", "tokens": [51552, 294, 264, 1164, 295, 1952, 2503, 30, 51612], "temperature": 0.0, "avg_logprob": -0.1308792205083938, "compression_ratio": 1.5938566552901023, "no_speech_prob": 0.0020501629915088415}, {"id": 776, "seek": 206472, "start": 2065.6, "end": 2070.0, "text": " I think it's going to be pretty fundamental.", "tokens": [50408, 286, 519, 309, 311, 516, 281, 312, 1238, 8088, 13, 50628], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 777, "seek": 206472, "start": 2070.0, "end": 2073.2799999999997, "text": " I think it's going to be more like the creation", "tokens": [50628, 286, 519, 309, 311, 516, 281, 312, 544, 411, 264, 8016, 50792], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 778, "seek": 206472, "start": 2073.2799999999997, "end": 2076.16, "text": " of computing in the first place, right?", "tokens": [50792, 295, 15866, 294, 264, 700, 1081, 11, 558, 30, 50936], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 779, "seek": 206472, "start": 2076.16, "end": 2081.8399999999997, "text": " So you'll get all these new apps in the same way", "tokens": [50936, 407, 291, 603, 483, 439, 613, 777, 7733, 294, 264, 912, 636, 51220], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 780, "seek": 206472, "start": 2082.64, "end": 2085.4399999999996, "text": " that when you got the web or you got mobile phones,", "tokens": [51260, 300, 562, 291, 658, 264, 3670, 420, 291, 658, 6013, 10216, 11, 51400], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 781, "seek": 206472, "start": 2085.4399999999996, "end": 2088.7999999999997, "text": " you got like people basically rethought all these experiences", "tokens": [51400, 291, 658, 411, 561, 1936, 319, 43135, 439, 613, 5235, 51568], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 782, "seek": 206472, "start": 2088.7999999999997, "end": 2090.3999999999996, "text": " and a lot of things that weren't possible", "tokens": [51568, 293, 257, 688, 295, 721, 300, 4999, 380, 1944, 51648], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 783, "seek": 206472, "start": 2090.3999999999996, "end": 2091.7599999999998, "text": " before now became possible.", "tokens": [51648, 949, 586, 3062, 1944, 13, 51716], "temperature": 0.0, "avg_logprob": -0.2314847707748413, "compression_ratio": 1.6820276497695852, "no_speech_prob": 0.0010648886673152447}, {"id": 784, "seek": 209176, "start": 2092.0800000000004, "end": 2093.44, "text": " Something that will happen,", "tokens": [50380, 6595, 300, 486, 1051, 11, 50448], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 785, "seek": 209176, "start": 2093.44, "end": 2096.2400000000002, "text": " but I think it's a much lower level innovation.", "tokens": [50448, 457, 286, 519, 309, 311, 257, 709, 3126, 1496, 8504, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 786, "seek": 209176, "start": 2096.2400000000002, "end": 2099.0400000000004, "text": " It's going to be more like going from", "tokens": [50588, 467, 311, 516, 281, 312, 544, 411, 516, 490, 50728], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 787, "seek": 209176, "start": 2099.0400000000004, "end": 2102.2400000000002, "text": " people didn't have computers to people have computers,", "tokens": [50728, 561, 994, 380, 362, 10807, 281, 561, 362, 10807, 11, 50888], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 788, "seek": 209176, "start": 2102.2400000000002, "end": 2103.2000000000003, "text": " is my sense.", "tokens": [50888, 307, 452, 2020, 13, 50936], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 789, "seek": 209176, "start": 2105.36, "end": 2109.44, "text": " But it's also, it's, I don't know,", "tokens": [51044, 583, 309, 311, 611, 11, 309, 311, 11, 286, 500, 380, 458, 11, 51248], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 790, "seek": 209176, "start": 2109.44, "end": 2114.4, "text": " it's very hard to reason about exactly how this goes.", "tokens": [51248, 309, 311, 588, 1152, 281, 1778, 466, 2293, 577, 341, 1709, 13, 51496], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 791, "seek": 209176, "start": 2114.4, "end": 2117.44, "text": " I tend to think that, you know,", "tokens": [51496, 286, 3928, 281, 519, 300, 11, 291, 458, 11, 51648], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 792, "seek": 209176, "start": 2117.44, "end": 2119.1200000000003, "text": " in like the cosmic scale, obviously,", "tokens": [51648, 294, 411, 264, 27614, 4373, 11, 2745, 11, 51732], "temperature": 0.0, "avg_logprob": -0.2797133190797107, "compression_ratio": 1.6066350710900474, "no_speech_prob": 0.003593245754018426}, {"id": 793, "seek": 211912, "start": 2119.3599999999997, "end": 2122.48, "text": " it'll happen quickly over a couple of decades or something.", "tokens": [50376, 309, 603, 1051, 2661, 670, 257, 1916, 295, 7878, 420, 746, 13, 50532], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 794, "seek": 211912, "start": 2122.48, "end": 2125.68, "text": " But I do think that there is some set of people", "tokens": [50532, 583, 286, 360, 519, 300, 456, 307, 512, 992, 295, 561, 50692], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 795, "seek": 211912, "start": 2125.68, "end": 2127.68, "text": " who are afraid of like, you know,", "tokens": [50692, 567, 366, 4638, 295, 411, 11, 291, 458, 11, 50792], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 796, "seek": 211912, "start": 2127.68, "end": 2130.08, "text": " it really just kind of spins and goes from being", "tokens": [50792, 309, 534, 445, 733, 295, 31587, 293, 1709, 490, 885, 50912], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 797, "seek": 211912, "start": 2130.08, "end": 2132.96, "text": " like somewhat intelligent to extremely intelligent overnight.", "tokens": [50912, 411, 8344, 13232, 281, 4664, 13232, 13935, 13, 51056], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 798, "seek": 211912, "start": 2132.96, "end": 2134.88, "text": " And I just think that there's all these physical constraints", "tokens": [51056, 400, 286, 445, 519, 300, 456, 311, 439, 613, 4001, 18491, 51152], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 799, "seek": 211912, "start": 2134.88, "end": 2137.3599999999997, "text": " that make that, so that that's unlikely to happen.", "tokens": [51152, 300, 652, 300, 11, 370, 300, 300, 311, 17518, 281, 1051, 13, 51276], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 800, "seek": 211912, "start": 2137.3599999999997, "end": 2141.2799999999997, "text": " I just don't, I don't really see that playing out.", "tokens": [51276, 286, 445, 500, 380, 11, 286, 500, 380, 534, 536, 300, 2433, 484, 13, 51472], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 801, "seek": 211912, "start": 2141.2799999999997, "end": 2142.48, "text": " So I think you'll have,", "tokens": [51472, 407, 286, 519, 291, 603, 362, 11, 51532], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 802, "seek": 211912, "start": 2142.48, "end": 2144.72, "text": " I think we'll have time to kind of acclimate a bit,", "tokens": [51532, 286, 519, 321, 603, 362, 565, 281, 733, 295, 1317, 75, 2905, 257, 857, 11, 51644], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 803, "seek": 211912, "start": 2144.72, "end": 2146.3199999999997, "text": " but it will really change.", "tokens": [51644, 457, 309, 486, 534, 1319, 13, 51724], "temperature": 0.0, "avg_logprob": -0.2490911140716333, "compression_ratio": 1.773972602739726, "no_speech_prob": 0.0008294765138998628}, {"id": 804, "seek": 214632, "start": 2146.32, "end": 2149.76, "text": " The way that we work and give people all these creative tools", "tokens": [50364, 440, 636, 300, 321, 589, 293, 976, 561, 439, 613, 5880, 3873, 50536], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 805, "seek": 214632, "start": 2149.76, "end": 2152.88, "text": " to do different things that they, yeah.", "tokens": [50536, 281, 360, 819, 721, 300, 436, 11, 1338, 13, 50692], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 806, "seek": 214632, "start": 2152.88, "end": 2154.56, "text": " I think it's going to be,", "tokens": [50692, 286, 519, 309, 311, 516, 281, 312, 11, 50776], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 807, "seek": 214632, "start": 2154.56, "end": 2156.7200000000003, "text": " it's going to really enable people to do", "tokens": [50776, 309, 311, 516, 281, 534, 9528, 561, 281, 360, 50884], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 808, "seek": 214632, "start": 2156.7200000000003, "end": 2159.1200000000003, "text": " the things that they want a lot more, as is my view.", "tokens": [50884, 264, 721, 300, 436, 528, 257, 688, 544, 11, 382, 307, 452, 1910, 13, 51004], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 809, "seek": 214632, "start": 2160.4, "end": 2161.84, "text": " Okay, so maybe not overnight,", "tokens": [51068, 1033, 11, 370, 1310, 406, 13935, 11, 51140], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 810, "seek": 214632, "start": 2161.84, "end": 2164.56, "text": " but is it your view that like on a cosmic scale,", "tokens": [51140, 457, 307, 309, 428, 1910, 300, 411, 322, 257, 27614, 4373, 11, 51276], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 811, "seek": 214632, "start": 2164.56, "end": 2168.0, "text": " if you think like humans evolved and then like AI happened", "tokens": [51276, 498, 291, 519, 411, 6255, 14178, 293, 550, 411, 7318, 2011, 51448], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 812, "seek": 214632, "start": 2168.0, "end": 2170.0, "text": " and then they like went out through the galaxy", "tokens": [51448, 293, 550, 436, 411, 1437, 484, 807, 264, 17639, 51548], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 813, "seek": 214632, "start": 2170.0, "end": 2173.2000000000003, "text": " or maybe it takes many decades, maybe it takes a century,", "tokens": [51548, 420, 1310, 309, 2516, 867, 7878, 11, 1310, 309, 2516, 257, 4901, 11, 51708], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 814, "seek": 214632, "start": 2173.2000000000003, "end": 2174.7200000000003, "text": " but like, you know,", "tokens": [51708, 457, 411, 11, 291, 458, 11, 51784], "temperature": 0.0, "avg_logprob": -0.302174895557005, "compression_ratio": 1.7859778597785978, "no_speech_prob": 0.005727170966565609}, {"id": 815, "seek": 217472, "start": 2174.9599999999996, "end": 2176.3199999999997, "text": " is that like the grand scheme", "tokens": [50376, 307, 300, 411, 264, 2697, 12232, 50444], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 816, "seek": 217472, "start": 2176.3199999999997, "end": 2178.0, "text": " of what's happening right now in history?", "tokens": [50444, 295, 437, 311, 2737, 558, 586, 294, 2503, 30, 50528], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 817, "seek": 217472, "start": 2179.6, "end": 2180.64, "text": " Sorry, in what sense?", "tokens": [50608, 4919, 11, 294, 437, 2020, 30, 50660], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 818, "seek": 217472, "start": 2180.64, "end": 2182.7999999999997, "text": " I mean, in the sense that there were other technologies", "tokens": [50660, 286, 914, 11, 294, 264, 2020, 300, 456, 645, 661, 7943, 50768], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 819, "seek": 217472, "start": 2182.7999999999997, "end": 2184.16, "text": " like computers and even like fire,", "tokens": [50768, 411, 10807, 293, 754, 411, 2610, 11, 50836], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 820, "seek": 217472, "start": 2184.16, "end": 2186.7999999999997, "text": " but like the AI happening is as significant", "tokens": [50836, 457, 411, 264, 7318, 2737, 307, 382, 4776, 50968], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 821, "seek": 217472, "start": 2186.7999999999997, "end": 2188.64, "text": " as like humans evolving in the first place.", "tokens": [50968, 382, 411, 6255, 21085, 294, 264, 700, 1081, 13, 51060], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 822, "seek": 217472, "start": 2189.6, "end": 2191.2, "text": " I think that's tricky.", "tokens": [51108, 286, 519, 300, 311, 12414, 13, 51188], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 823, "seek": 217472, "start": 2191.2, "end": 2195.04, "text": " I think people like to, you know,", "tokens": [51188, 286, 519, 561, 411, 281, 11, 291, 458, 11, 51380], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 824, "seek": 217472, "start": 2195.04, "end": 2197.3599999999997, "text": " the history of humanity, I think has been", "tokens": [51380, 264, 2503, 295, 10243, 11, 286, 519, 575, 668, 51496], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 825, "seek": 217472, "start": 2198.24, "end": 2200.64, "text": " people basically, you know,", "tokens": [51540, 561, 1936, 11, 291, 458, 11, 51660], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 826, "seek": 217472, "start": 2200.64, "end": 2202.3999999999996, "text": " thinking that certain things", "tokens": [51660, 1953, 300, 1629, 721, 51748], "temperature": 0.0, "avg_logprob": -0.33457108201651736, "compression_ratio": 1.7685950413223142, "no_speech_prob": 0.003375447355210781}, {"id": 827, "seek": 220240, "start": 2203.36, "end": 2211.2000000000003, "text": " of humanity are like really unique in different ways.", "tokens": [50412, 295, 10243, 366, 411, 534, 3845, 294, 819, 2098, 13, 50804], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 828, "seek": 220240, "start": 2211.84, "end": 2215.6, "text": " And then coming to grips with the fact", "tokens": [50836, 400, 550, 1348, 281, 38037, 365, 264, 1186, 51024], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 829, "seek": 220240, "start": 2215.6, "end": 2216.48, "text": " that that's not true,", "tokens": [51024, 300, 300, 311, 406, 2074, 11, 51068], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 830, "seek": 220240, "start": 2216.48, "end": 2219.28, "text": " but humanity is actually still super special, right?", "tokens": [51068, 457, 10243, 307, 767, 920, 1687, 2121, 11, 558, 30, 51208], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 831, "seek": 220240, "start": 2219.28, "end": 2223.92, "text": " So it's like we thought that the earth", "tokens": [51208, 407, 309, 311, 411, 321, 1194, 300, 264, 4120, 51440], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 832, "seek": 220240, "start": 2223.92, "end": 2225.2000000000003, "text": " was the center of the universe.", "tokens": [51440, 390, 264, 3056, 295, 264, 6445, 13, 51504], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 833, "seek": 220240, "start": 2225.2000000000003, "end": 2228.4, "text": " And it's like, it's not, but like humans", "tokens": [51504, 400, 309, 311, 411, 11, 309, 311, 406, 11, 457, 411, 6255, 51664], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 834, "seek": 220240, "start": 2228.4, "end": 2229.84, "text": " are still pretty awesome, right?", "tokens": [51664, 366, 920, 1238, 3476, 11, 558, 30, 51736], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 835, "seek": 220240, "start": 2229.84, "end": 2231.28, "text": " And pretty unique.", "tokens": [51736, 400, 1238, 3845, 13, 51808], "temperature": 0.0, "avg_logprob": -0.19484148854794708, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0004172890039626509}, {"id": 836, "seek": 223240, "start": 2232.48, "end": 2234.7200000000003, "text": " I think that another bias that people tend to have", "tokens": [50368, 286, 519, 300, 1071, 12577, 300, 561, 3928, 281, 362, 50480], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 837, "seek": 223240, "start": 2235.52, "end": 2238.0, "text": " is thinking that intelligence is somehow", "tokens": [50520, 307, 1953, 300, 7599, 307, 6063, 50644], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 838, "seek": 223240, "start": 2240.1600000000003, "end": 2243.36, "text": " kind of fundamentally connected to life.", "tokens": [50752, 733, 295, 17879, 4582, 281, 993, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 839, "seek": 223240, "start": 2244.0, "end": 2246.96, "text": " And it's not actually clear that it is, right?", "tokens": [50944, 400, 309, 311, 406, 767, 1850, 300, 309, 307, 11, 558, 30, 51092], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 840, "seek": 223240, "start": 2246.96, "end": 2248.96, "text": " I think like people think that,", "tokens": [51092, 286, 519, 411, 561, 519, 300, 11, 51192], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 841, "seek": 223240, "start": 2251.52, "end": 2252.88, "text": " I mean, I don't know that we have", "tokens": [51320, 286, 914, 11, 286, 500, 380, 458, 300, 321, 362, 51388], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 842, "seek": 223240, "start": 2252.88, "end": 2254.8, "text": " a clear enough definition of consciousness", "tokens": [51388, 257, 1850, 1547, 7123, 295, 10081, 51484], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 843, "seek": 223240, "start": 2254.8, "end": 2259.92, "text": " or life to kind of fully interrogate this,", "tokens": [51484, 420, 993, 281, 733, 295, 4498, 24871, 473, 341, 11, 51740], "temperature": 0.0, "avg_logprob": -0.1050837428070778, "compression_ratio": 1.6717171717171717, "no_speech_prob": 0.0008040068205446005}, {"id": 844, "seek": 225992, "start": 2259.92, "end": 2263.28, "text": " but there's all this science fiction about,", "tokens": [50364, 457, 456, 311, 439, 341, 3497, 13266, 466, 11, 50532], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 845, "seek": 225992, "start": 2263.28, "end": 2264.88, "text": " okay, you create intelligence", "tokens": [50532, 1392, 11, 291, 1884, 7599, 50612], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 846, "seek": 225992, "start": 2264.88, "end": 2267.52, "text": " and now it like starts taking on all these human", "tokens": [50612, 293, 586, 309, 411, 3719, 1940, 322, 439, 613, 1952, 50744], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 847, "seek": 225992, "start": 2267.52, "end": 2270.32, "text": " like behaviors and things like that.", "tokens": [50744, 411, 15501, 293, 721, 411, 300, 13, 50884], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 848, "seek": 225992, "start": 2270.32, "end": 2272.56, "text": " But I actually think that the current incarnation", "tokens": [50884, 583, 286, 767, 519, 300, 264, 2190, 49988, 50996], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 849, "seek": 225992, "start": 2272.56, "end": 2274.4, "text": " of all this stuff at least kind of feels", "tokens": [50996, 295, 439, 341, 1507, 412, 1935, 733, 295, 3417, 51088], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 850, "seek": 225992, "start": 2274.4, "end": 2275.44, "text": " like it's going in a direction", "tokens": [51088, 411, 309, 311, 516, 294, 257, 3513, 51140], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 851, "seek": 225992, "start": 2275.44, "end": 2277.76, "text": " where intelligence can be pretty separated", "tokens": [51140, 689, 7599, 393, 312, 1238, 12005, 51256], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 852, "seek": 225992, "start": 2277.76, "end": 2281.2000000000003, "text": " from consciousness and agency and things like that,", "tokens": [51256, 490, 10081, 293, 7934, 293, 721, 411, 300, 11, 51428], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 853, "seek": 225992, "start": 2281.2000000000003, "end": 2285.04, "text": " that I think just makes it a super valuable tool.", "tokens": [51428, 300, 286, 519, 445, 1669, 309, 257, 1687, 8263, 2290, 13, 51620], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 854, "seek": 225992, "start": 2285.04, "end": 2286.0, "text": " So I don't know.", "tokens": [51620, 407, 286, 500, 380, 458, 13, 51668], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 855, "seek": 225992, "start": 2286.0, "end": 2288.16, "text": " I mean, obviously it's very difficult to predict", "tokens": [51668, 286, 914, 11, 2745, 309, 311, 588, 2252, 281, 6069, 51776], "temperature": 0.0, "avg_logprob": -0.0975226425543064, "compression_ratio": 1.7263157894736842, "no_speech_prob": 0.0005526913446374238}, {"id": 856, "seek": 228816, "start": 2288.16, "end": 2290.3199999999997, "text": " what direction the stuff goes in over time,", "tokens": [50364, 437, 3513, 264, 1507, 1709, 294, 670, 565, 11, 50472], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 857, "seek": 228816, "start": 2290.3199999999997, "end": 2294.16, "text": " which is why I don't think anyone should be dogmatic", "tokens": [50472, 597, 307, 983, 286, 500, 380, 519, 2878, 820, 312, 3000, 25915, 50664], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 858, "seek": 228816, "start": 2294.16, "end": 2297.3599999999997, "text": " about how they plan to develop it or what they plan to do.", "tokens": [50664, 466, 577, 436, 1393, 281, 1499, 309, 420, 437, 436, 1393, 281, 360, 13, 50824], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 859, "seek": 228816, "start": 2297.3599999999997, "end": 2299.68, "text": " I think you want to kind of look at like each release.", "tokens": [50824, 286, 519, 291, 528, 281, 733, 295, 574, 412, 411, 1184, 4374, 13, 50940], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 860, "seek": 228816, "start": 2299.68, "end": 2301.92, "text": " You know, it's like, we're obviously very pro open source,", "tokens": [50940, 509, 458, 11, 309, 311, 411, 11, 321, 434, 2745, 588, 447, 1269, 4009, 11, 51052], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 861, "seek": 228816, "start": 2301.92, "end": 2303.52, "text": " but I haven't committed that we're going to like release", "tokens": [51052, 457, 286, 2378, 380, 7784, 300, 321, 434, 516, 281, 411, 4374, 51132], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 862, "seek": 228816, "start": 2303.52, "end": 2304.8799999999997, "text": " every single thing that we do.", "tokens": [51132, 633, 2167, 551, 300, 321, 360, 13, 51200], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 863, "seek": 228816, "start": 2304.8799999999997, "end": 2309.12, "text": " But it's basically, I'm just generally very inclined", "tokens": [51200, 583, 309, 311, 1936, 11, 286, 478, 445, 5101, 588, 28173, 51412], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 864, "seek": 228816, "start": 2309.12, "end": 2310.3199999999997, "text": " to thinking that open sourcing it", "tokens": [51412, 281, 1953, 300, 1269, 11006, 2175, 309, 51472], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 865, "seek": 228816, "start": 2310.3199999999997, "end": 2312.64, "text": " is going to be good for the community", "tokens": [51472, 307, 516, 281, 312, 665, 337, 264, 1768, 51588], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 866, "seek": 228816, "start": 2312.64, "end": 2313.8399999999997, "text": " and also good for us, right?", "tokens": [51588, 293, 611, 665, 337, 505, 11, 558, 30, 51648], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 867, "seek": 228816, "start": 2313.8399999999997, "end": 2316.3199999999997, "text": " Because we'll benefit from the innovations.", "tokens": [51648, 1436, 321, 603, 5121, 490, 264, 24283, 13, 51772], "temperature": 0.0, "avg_logprob": -0.11492940266927083, "compression_ratio": 1.7236024844720497, "no_speech_prob": 0.0017001612577587366}, {"id": 868, "seek": 231632, "start": 2316.56, "end": 2320.0800000000004, "text": " But if at some point like there's some qualitative change", "tokens": [50376, 583, 498, 412, 512, 935, 411, 456, 311, 512, 31312, 1319, 50552], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 869, "seek": 231632, "start": 2320.0800000000004, "end": 2322.0, "text": " in what the thing is capable of,", "tokens": [50552, 294, 437, 264, 551, 307, 8189, 295, 11, 50648], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 870, "seek": 231632, "start": 2322.0, "end": 2324.7200000000003, "text": " and we feel like it's just not responsible to open source it,", "tokens": [50648, 293, 321, 841, 411, 309, 311, 445, 406, 6250, 281, 1269, 4009, 309, 11, 50784], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 871, "seek": 231632, "start": 2324.7200000000003, "end": 2328.6400000000003, "text": " then we won't, but so I don't know.", "tokens": [50784, 550, 321, 1582, 380, 11, 457, 370, 286, 500, 380, 458, 13, 50980], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 872, "seek": 231632, "start": 2328.6400000000003, "end": 2330.6400000000003, "text": " It's all very difficult to predict.", "tokens": [50980, 467, 311, 439, 588, 2252, 281, 6069, 13, 51080], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 873, "seek": 231632, "start": 2330.6400000000003, "end": 2331.6000000000004, "text": " Yeah.", "tokens": [51080, 865, 13, 51128], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 874, "seek": 231632, "start": 2331.6000000000004, "end": 2333.52, "text": " What is a kind of qualitative change,", "tokens": [51128, 708, 307, 257, 733, 295, 31312, 1319, 11, 51224], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 875, "seek": 231632, "start": 2333.52, "end": 2334.8, "text": " like a specific thing?", "tokens": [51224, 411, 257, 2685, 551, 30, 51288], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 876, "seek": 231632, "start": 2334.8, "end": 2337.92, "text": " You're training lamify, lamaphore, and you've seen this,", "tokens": [51288, 509, 434, 3097, 24688, 2505, 11, 24688, 13957, 418, 11, 293, 291, 600, 1612, 341, 11, 51444], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 877, "seek": 231632, "start": 2337.92, "end": 2339.36, "text": " and like, you know what?", "tokens": [51444, 293, 411, 11, 291, 458, 437, 30, 51516], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 878, "seek": 231632, "start": 2339.36, "end": 2340.56, "text": " I'm not sure about open sourcing it.", "tokens": [51516, 286, 478, 406, 988, 466, 1269, 11006, 2175, 309, 13, 51576], "temperature": 0.0, "avg_logprob": -0.2948008117675781, "compression_ratio": 1.6334661354581674, "no_speech_prob": 0.0008829190628603101}, {"id": 879, "seek": 234056, "start": 2340.56, "end": 2346.7999999999997, "text": " I think that that, it's a little hard to answer that", "tokens": [50364, 286, 519, 300, 300, 11, 309, 311, 257, 707, 1152, 281, 1867, 300, 50676], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 880, "seek": 234056, "start": 2346.7999999999997, "end": 2350.16, "text": " in the abstract because there are negative behaviors", "tokens": [50676, 294, 264, 12649, 570, 456, 366, 3671, 15501, 50844], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 881, "seek": 234056, "start": 2350.7999999999997, "end": 2354.32, "text": " that any product can exhibit that as long as you can mitigate it,", "tokens": [50876, 300, 604, 1674, 393, 20487, 300, 382, 938, 382, 291, 393, 27336, 309, 11, 51052], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 882, "seek": 234056, "start": 2354.96, "end": 2357.44, "text": " it's like, it's okay, right?", "tokens": [51084, 309, 311, 411, 11, 309, 311, 1392, 11, 558, 30, 51208], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 883, "seek": 234056, "start": 2357.44, "end": 2360.64, "text": " So, I mean, there's bad things about social media", "tokens": [51208, 407, 11, 286, 914, 11, 456, 311, 1578, 721, 466, 2093, 3021, 51368], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 884, "seek": 234056, "start": 2360.64, "end": 2362.08, "text": " that we work to mitigate, right?", "tokens": [51368, 300, 321, 589, 281, 27336, 11, 558, 30, 51440], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 885, "seek": 234056, "start": 2362.08, "end": 2364.0, "text": " There's bad things about llama two", "tokens": [51440, 821, 311, 1578, 721, 466, 23272, 732, 51536], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 886, "seek": 234056, "start": 2364.0, "end": 2366.0, "text": " that we spend a lot of time trying to make sure", "tokens": [51536, 300, 321, 3496, 257, 688, 295, 565, 1382, 281, 652, 988, 51636], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 887, "seek": 234056, "start": 2366.0, "end": 2369.44, "text": " that it's not like, you know, helping people commit violent acts", "tokens": [51636, 300, 309, 311, 406, 411, 11, 291, 458, 11, 4315, 561, 5599, 11867, 10672, 51808], "temperature": 0.0, "avg_logprob": -0.16745725452390492, "compression_ratio": 1.7591836734693878, "no_speech_prob": 0.006692089606076479}, {"id": 888, "seek": 236944, "start": 2369.44, "end": 2370.4, "text": " or things like that, right?", "tokens": [50364, 420, 721, 411, 300, 11, 558, 30, 50412], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 889, "seek": 236944, "start": 2370.4, "end": 2374.48, "text": " I mean, that doesn't mean that it's like a kind of autonomous", "tokens": [50412, 286, 914, 11, 300, 1177, 380, 914, 300, 309, 311, 411, 257, 733, 295, 23797, 50616], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 890, "seek": 236944, "start": 2374.48, "end": 2375.76, "text": " or intelligent agent.", "tokens": [50616, 420, 13232, 9461, 13, 50680], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 891, "seek": 236944, "start": 2375.76, "end": 2377.84, "text": " It just means that it's learned a lot about the world,", "tokens": [50680, 467, 445, 1355, 300, 309, 311, 3264, 257, 688, 466, 264, 1002, 11, 50784], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 892, "seek": 236944, "start": 2377.84, "end": 2379.28, "text": " and it can answer a set of questions", "tokens": [50784, 293, 309, 393, 1867, 257, 992, 295, 1651, 50856], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 893, "seek": 236944, "start": 2379.28, "end": 2381.84, "text": " that we think it would be unhelpful for it to answer.", "tokens": [50856, 300, 321, 519, 309, 576, 312, 517, 37451, 906, 337, 309, 281, 1867, 13, 50984], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 894, "seek": 236944, "start": 2383.44, "end": 2387.2000000000003, "text": " So, I don't know.", "tokens": [51064, 407, 11, 286, 500, 380, 458, 13, 51252], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 895, "seek": 236944, "start": 2387.2000000000003, "end": 2391.68, "text": " I think the question isn't really what behaviors would it show.", "tokens": [51252, 286, 519, 264, 1168, 1943, 380, 534, 437, 15501, 576, 309, 855, 13, 51476], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 896, "seek": 236944, "start": 2391.68, "end": 2394.0, "text": " It's what things would we not be able to mitigate", "tokens": [51476, 467, 311, 437, 721, 576, 321, 406, 312, 1075, 281, 27336, 51592], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 897, "seek": 236944, "start": 2394.0, "end": 2398.48, "text": " after it shows that, and I don't know.", "tokens": [51592, 934, 309, 3110, 300, 11, 293, 286, 500, 380, 458, 13, 51816], "temperature": 0.0, "avg_logprob": -0.09632694244384765, "compression_ratio": 1.7759336099585061, "no_speech_prob": 0.0017543287249282002}, {"id": 898, "seek": 239848, "start": 2399.12, "end": 2401.52, "text": " I think that there's so many ways", "tokens": [50396, 286, 519, 300, 456, 311, 370, 867, 2098, 50516], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 899, "seek": 239848, "start": 2401.52, "end": 2403.44, "text": " in which something can be good or bad", "tokens": [50516, 294, 597, 746, 393, 312, 665, 420, 1578, 50612], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 900, "seek": 239848, "start": 2403.44, "end": 2405.36, "text": " that it's hard to actually enumerate them all up front.", "tokens": [50612, 300, 309, 311, 1152, 281, 767, 465, 15583, 473, 552, 439, 493, 1868, 13, 50708], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 901, "seek": 239848, "start": 2405.36, "end": 2410.32, "text": " If you even look at what we've had to deal with in social media", "tokens": [50708, 759, 291, 754, 574, 412, 437, 321, 600, 632, 281, 2028, 365, 294, 2093, 3021, 50956], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 902, "seek": 239848, "start": 2410.32, "end": 2412.88, "text": " and the different types of harms, we've basically gotten to.", "tokens": [50956, 293, 264, 819, 3467, 295, 48505, 11, 321, 600, 1936, 5768, 281, 13, 51084], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 903, "seek": 239848, "start": 2412.88, "end": 2416.2400000000002, "text": " It's like, there's like 18 or 19 categories of harmful things", "tokens": [51084, 467, 311, 411, 11, 456, 311, 411, 2443, 420, 1294, 10479, 295, 19727, 721, 51252], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 904, "seek": 239848, "start": 2416.2400000000002, "end": 2419.84, "text": " that people do, and we've basically built AI systems", "tokens": [51252, 300, 561, 360, 11, 293, 321, 600, 1936, 3094, 7318, 3652, 51432], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 905, "seek": 239848, "start": 2419.84, "end": 2422.08, "text": " to try to go identify what those things are", "tokens": [51432, 281, 853, 281, 352, 5876, 437, 729, 721, 366, 51544], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 906, "seek": 239848, "start": 2422.08, "end": 2423.52, "text": " that people are doing and try to make sure", "tokens": [51544, 300, 561, 366, 884, 293, 853, 281, 652, 988, 51616], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 907, "seek": 239848, "start": 2423.52, "end": 2426.4, "text": " that that doesn't happen on our network as much as possible.", "tokens": [51616, 300, 300, 1177, 380, 1051, 322, 527, 3209, 382, 709, 382, 1944, 13, 51760], "temperature": 0.0, "avg_logprob": -0.08820037280811983, "compression_ratio": 1.734006734006734, "no_speech_prob": 0.0007552998722530901}, {"id": 908, "seek": 242640, "start": 2426.4, "end": 2428.4, "text": " So, yeah, I think you can...", "tokens": [50364, 407, 11, 1338, 11, 286, 519, 291, 393, 485, 50464], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 909, "seek": 242640, "start": 2428.4, "end": 2430.0, "text": " Over time, I think you'll be able to break down", "tokens": [50464, 4886, 565, 11, 286, 519, 291, 603, 312, 1075, 281, 1821, 760, 50544], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 910, "seek": 242640, "start": 2431.6, "end": 2433.2000000000003, "text": " this into more of a taxonomy, too,", "tokens": [50624, 341, 666, 544, 295, 257, 3366, 23423, 11, 886, 11, 50704], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 911, "seek": 242640, "start": 2433.2000000000003, "end": 2436.0, "text": " and I think this is a thing that we spend time researching, too,", "tokens": [50704, 293, 286, 519, 341, 307, 257, 551, 300, 321, 3496, 565, 24176, 11, 886, 11, 50844], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 912, "seek": 242640, "start": 2436.0, "end": 2437.36, "text": " because we want to make sure that we understand that.", "tokens": [50844, 570, 321, 528, 281, 652, 988, 300, 321, 1223, 300, 13, 50912], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 913, "seek": 242640, "start": 2438.2400000000002, "end": 2440.08, "text": " So, one of the things I asked Mark", "tokens": [50956, 407, 11, 472, 295, 264, 721, 286, 2351, 3934, 51048], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 914, "seek": 242640, "start": 2440.08, "end": 2444.0, "text": " is what industrial-scale use of LLMs would look like.", "tokens": [51048, 307, 437, 9987, 12, 20033, 764, 295, 441, 43, 26386, 576, 574, 411, 13, 51244], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 915, "seek": 242640, "start": 2444.0, "end": 2446.0, "text": " You see this in previous technological revolutions", "tokens": [51244, 509, 536, 341, 294, 3894, 18439, 3698, 15892, 51344], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 916, "seek": 242640, "start": 2446.0, "end": 2448.4, "text": " where, at first, they're thinking in a very small-scale way", "tokens": [51344, 689, 11, 412, 700, 11, 436, 434, 1953, 294, 257, 588, 1359, 12, 20033, 636, 51464], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 917, "seek": 242640, "start": 2448.4, "end": 2449.44, "text": " about what's enabled,", "tokens": [51464, 466, 437, 311, 15172, 11, 51516], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 918, "seek": 242640, "start": 2449.44, "end": 2452.08, "text": " and I think that's what chatbots might be for LLMs.", "tokens": [51516, 293, 286, 519, 300, 311, 437, 5081, 65, 1971, 1062, 312, 337, 441, 43, 26386, 13, 51648], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 919, "seek": 242640, "start": 2452.08, "end": 2453.92, "text": " And I think the large-scale use case", "tokens": [51648, 400, 286, 519, 264, 2416, 12, 20033, 764, 1389, 51740], "temperature": 0.0, "avg_logprob": -0.11531653494205114, "compression_ratio": 1.750809061488673, "no_speech_prob": 0.0012447589542716742}, {"id": 920, "seek": 245392, "start": 2453.92, "end": 2456.48, "text": " might look something like what V7 Go is.", "tokens": [50364, 1062, 574, 746, 411, 437, 691, 22, 1037, 307, 13, 50492], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 921, "seek": 245392, "start": 2456.48, "end": 2458.4, "text": " And, by the way, it's made by V7 Labs", "tokens": [50492, 400, 11, 538, 264, 636, 11, 309, 311, 1027, 538, 691, 22, 40047, 50588], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 922, "seek": 245392, "start": 2458.4, "end": 2459.6800000000003, "text": " who's sponsoring this episode.", "tokens": [50588, 567, 311, 30311, 341, 3500, 13, 50652], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 923, "seek": 245392, "start": 2460.2400000000002, "end": 2462.16, "text": " So, it's like a spreadsheet.", "tokens": [50680, 407, 11, 309, 311, 411, 257, 27733, 13, 50776], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 924, "seek": 245392, "start": 2462.16, "end": 2466.16, "text": " You put in raw information, like documents, images, whatever,", "tokens": [50776, 509, 829, 294, 8936, 1589, 11, 411, 8512, 11, 5267, 11, 2035, 11, 50976], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 925, "seek": 245392, "start": 2466.16, "end": 2467.6, "text": " and they become rows,", "tokens": [50976, 293, 436, 1813, 13241, 11, 51048], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 926, "seek": 245392, "start": 2467.6, "end": 2471.12, "text": " and the columns are populated by an LLM of your choice.", "tokens": [51048, 293, 264, 13766, 366, 32998, 538, 364, 441, 43, 44, 295, 428, 3922, 13, 51224], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 927, "seek": 245392, "start": 2471.12, "end": 2473.6800000000003, "text": " And, in fact, I used it to prepare for Mark,", "tokens": [51224, 400, 11, 294, 1186, 11, 286, 1143, 309, 281, 5940, 337, 3934, 11, 51352], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 928, "seek": 245392, "start": 2473.6800000000003, "end": 2476.16, "text": " so I fed in a bunch of blog posts and papers", "tokens": [51352, 370, 286, 4636, 294, 257, 3840, 295, 6968, 12300, 293, 10577, 51476], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 929, "seek": 245392, "start": 2476.16, "end": 2477.92, "text": " from Metas AI Research,", "tokens": [51476, 490, 6377, 296, 7318, 10303, 11, 51564], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 930, "seek": 245392, "start": 2477.92, "end": 2480.08, "text": " and, as you can see, if you're on YouTube,", "tokens": [51564, 293, 11, 382, 291, 393, 536, 11, 498, 291, 434, 322, 3088, 11, 51672], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 931, "seek": 245392, "start": 2480.08, "end": 2483.28, "text": " it summarizes and extracts exactly the information I want", "tokens": [51672, 309, 14611, 5660, 293, 8947, 82, 2293, 264, 1589, 286, 528, 51832], "temperature": 0.0, "avg_logprob": -0.08771038055419922, "compression_ratio": 1.5903225806451613, "no_speech_prob": 0.008060966618359089}, {"id": 932, "seek": 248328, "start": 2483.36, "end": 2484.32, "text": " as columns.", "tokens": [50368, 382, 13766, 13, 50416], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 933, "seek": 248328, "start": 2484.32, "end": 2486.48, "text": " And, obviously, mine is a small use case,", "tokens": [50416, 400, 11, 2745, 11, 3892, 307, 257, 1359, 764, 1389, 11, 50524], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 934, "seek": 248328, "start": 2486.48, "end": 2489.44, "text": " but you can imagine, for example, a company like FedEx", "tokens": [50524, 457, 291, 393, 3811, 11, 337, 1365, 11, 257, 2237, 411, 7772, 11149, 50672], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 935, "seek": 248328, "start": 2489.44, "end": 2492.0800000000004, "text": " has to process half a million documents a day.", "tokens": [50672, 575, 281, 1399, 1922, 257, 2459, 8512, 257, 786, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 936, "seek": 248328, "start": 2492.0800000000004, "end": 2494.0800000000004, "text": " Obviously, a chatbot can't do that.", "tokens": [50804, 7580, 11, 257, 5081, 18870, 393, 380, 360, 300, 13, 50904], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 937, "seek": 248328, "start": 2494.0800000000004, "end": 2495.28, "text": " A spreadsheet can,", "tokens": [50904, 316, 27733, 393, 11, 50964], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 938, "seek": 248328, "start": 2495.28, "end": 2497.44, "text": " because this is just like a fire hose of intelligence", "tokens": [50964, 570, 341, 307, 445, 411, 257, 2610, 20061, 295, 7599, 51072], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 939, "seek": 248328, "start": 2497.44, "end": 2498.48, "text": " in there, right?", "tokens": [51072, 294, 456, 11, 558, 30, 51124], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 940, "seek": 248328, "start": 2498.48, "end": 2500.1600000000003, "text": " Anyways, you can learn more about them", "tokens": [51124, 15585, 11, 291, 393, 1466, 544, 466, 552, 51208], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 941, "seek": 248328, "start": 2500.1600000000003, "end": 2502.5600000000004, "text": " at v7labs.com slash go,", "tokens": [51208, 412, 371, 22, 75, 17243, 13, 1112, 17330, 352, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 942, "seek": 248328, "start": 2502.5600000000004, "end": 2504.1600000000003, "text": " or the link in the description.", "tokens": [51328, 420, 264, 2113, 294, 264, 3855, 13, 51408], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 943, "seek": 248328, "start": 2504.1600000000003, "end": 2505.28, "text": " Back to Mark.", "tokens": [51408, 5833, 281, 3934, 13, 51464], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 944, "seek": 248328, "start": 2505.28, "end": 2505.84, "text": " Yeah.", "tokens": [51464, 865, 13, 51492], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 945, "seek": 248328, "start": 2505.84, "end": 2508.48, "text": " Like, it seems to me it would be a good idea.", "tokens": [51492, 1743, 11, 309, 2544, 281, 385, 309, 576, 312, 257, 665, 1558, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 946, "seek": 248328, "start": 2508.48, "end": 2510.0, "text": " I would be disappointed in a future", "tokens": [51624, 286, 576, 312, 13856, 294, 257, 2027, 51700], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 947, "seek": 248328, "start": 2510.0, "end": 2511.6800000000003, "text": " where AI systems aren't broadly deployed", "tokens": [51700, 689, 7318, 3652, 3212, 380, 19511, 17826, 51784], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 948, "seek": 248328, "start": 2511.6800000000003, "end": 2513.0400000000004, "text": " and everybody doesn't have access to them.", "tokens": [51784, 293, 2201, 1177, 380, 362, 2105, 281, 552, 13, 51852], "temperature": 0.0, "avg_logprob": -0.1003158501619418, "compression_ratio": 1.6057142857142856, "no_speech_prob": 0.027564972639083862}, {"id": 949, "seek": 251304, "start": 2514.0, "end": 2514.96, "text": " At the same time,", "tokens": [50412, 1711, 264, 912, 565, 11, 50460], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 950, "seek": 251304, "start": 2514.96, "end": 2517.12, "text": " I want to better understand the mitigations,", "tokens": [50460, 286, 528, 281, 1101, 1223, 264, 15699, 763, 11, 50568], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 951, "seek": 251304, "start": 2518.0, "end": 2520.48, "text": " because if the mitigation is the fine-tuning,", "tokens": [50612, 570, 498, 264, 32649, 307, 264, 2489, 12, 83, 37726, 11, 50736], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 952, "seek": 251304, "start": 2520.48, "end": 2522.32, "text": " well, the whole thing about open weights", "tokens": [50736, 731, 11, 264, 1379, 551, 466, 1269, 17443, 50828], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 953, "seek": 251304, "start": 2522.32, "end": 2525.68, "text": " is that you can then remove the fine-tuning,", "tokens": [50828, 307, 300, 291, 393, 550, 4159, 264, 2489, 12, 83, 37726, 11, 50996], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 954, "seek": 251304, "start": 2525.68, "end": 2527.92, "text": " which is often superficial on top of these capabilities.", "tokens": [50996, 597, 307, 2049, 34622, 322, 1192, 295, 613, 10862, 13, 51108], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 955, "seek": 251304, "start": 2527.92, "end": 2530.24, "text": " Like, if it's like talking on Slack", "tokens": [51108, 1743, 11, 498, 309, 311, 411, 1417, 322, 37211, 51224], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 956, "seek": 251304, "start": 2530.24, "end": 2532.0, "text": " with a biology researcher,", "tokens": [51224, 365, 257, 14956, 21751, 11, 51312], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 957, "seek": 251304, "start": 2532.0, "end": 2534.0, "text": " and again, I think models are very far from this.", "tokens": [51312, 293, 797, 11, 286, 519, 5245, 366, 588, 1400, 490, 341, 13, 51412], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 958, "seek": 251304, "start": 2534.0, "end": 2535.12, "text": " Right now, they're like Google search,", "tokens": [51412, 1779, 586, 11, 436, 434, 411, 3329, 3164, 11, 51468], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 959, "seek": 251304, "start": 2536.16, "end": 2537.92, "text": " but I can show them my Petri disk", "tokens": [51520, 457, 286, 393, 855, 552, 452, 10472, 470, 12355, 51608], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 960, "seek": 251304, "start": 2537.92, "end": 2538.56, "text": " and they can next lane.", "tokens": [51608, 293, 436, 393, 958, 12705, 13, 51640], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 961, "seek": 251304, "start": 2538.56, "end": 2541.68, "text": " Like, here's why your smallpox sample didn't grow.", "tokens": [51640, 1743, 11, 510, 311, 983, 428, 1359, 42871, 6889, 994, 380, 1852, 13, 51796], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 962, "seek": 251304, "start": 2541.68, "end": 2542.4, "text": " Here's what to change.", "tokens": [51796, 1692, 311, 437, 281, 1319, 13, 51832], "temperature": 0.0, "avg_logprob": -0.15261375826168683, "compression_ratio": 1.677115987460815, "no_speech_prob": 0.00048771026195026934}, {"id": 963, "seek": 254304, "start": 2543.6, "end": 2544.72, "text": " How do you mitigate that?", "tokens": [50392, 1012, 360, 291, 27336, 300, 30, 50448], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 964, "seek": 254304, "start": 2544.72, "end": 2547.04, "text": " Because somebody can just fine-tune that in there, right?", "tokens": [50448, 1436, 2618, 393, 445, 2489, 12, 83, 2613, 300, 294, 456, 11, 558, 30, 50564], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 965, "seek": 254304, "start": 2547.84, "end": 2550.64, "text": " Yeah. I mean, that's true.", "tokens": [50604, 865, 13, 286, 914, 11, 300, 311, 2074, 13, 50744], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 966, "seek": 254304, "start": 2550.64, "end": 2552.8, "text": " I think a lot of people will basically use", "tokens": [50744, 286, 519, 257, 688, 295, 561, 486, 1936, 764, 50852], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 967, "seek": 254304, "start": 2552.8, "end": 2554.88, "text": " the off-the-shelf model,", "tokens": [50852, 264, 766, 12, 3322, 12, 46626, 2316, 11, 50956], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 968, "seek": 254304, "start": 2554.88, "end": 2558.32, "text": " and some people who have basically bad faith", "tokens": [50956, 293, 512, 561, 567, 362, 1936, 1578, 4522, 51128], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 969, "seek": 254304, "start": 2558.32, "end": 2560.56, "text": " are going to try to strip out all the bad stuff,", "tokens": [51128, 366, 516, 281, 853, 281, 12828, 484, 439, 264, 1578, 1507, 11, 51240], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 970, "seek": 254304, "start": 2560.56, "end": 2561.6, "text": " so I do think that that's an issue.", "tokens": [51240, 370, 286, 360, 519, 300, 300, 311, 364, 2734, 13, 51292], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 971, "seek": 254304, "start": 2564.72, "end": 2566.72, "text": " The flip side of this is that,", "tokens": [51448, 440, 7929, 1252, 295, 341, 307, 300, 11, 51548], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 972, "seek": 254304, "start": 2566.72, "end": 2567.92, "text": " and this is one of the reasons", "tokens": [51548, 293, 341, 307, 472, 295, 264, 4112, 51608], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 973, "seek": 254304, "start": 2567.92, "end": 2571.2799999999997, "text": " why I'm kind of philosophically so pro-open source,", "tokens": [51608, 983, 286, 478, 733, 295, 14529, 984, 370, 447, 12, 15752, 4009, 11, 51776], "temperature": 0.0, "avg_logprob": -0.11143619567155838, "compression_ratio": 1.6484375, "no_speech_prob": 0.0008295243605971336}, {"id": 974, "seek": 257128, "start": 2572.1600000000003, "end": 2576.7200000000003, "text": " is I do think that a concentration of AI in the future", "tokens": [50408, 307, 286, 360, 519, 300, 257, 9856, 295, 7318, 294, 264, 2027, 50636], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 975, "seek": 257128, "start": 2577.84, "end": 2580.2400000000002, "text": " has the potential to be as dangerous", "tokens": [50692, 575, 264, 3995, 281, 312, 382, 5795, 50812], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 976, "seek": 257128, "start": 2580.88, "end": 2583.76, "text": " as kind of it being widespread.", "tokens": [50844, 382, 733, 295, 309, 885, 22679, 13, 50988], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 977, "seek": 257128, "start": 2583.76, "end": 2584.5600000000004, "text": " So, I think a lot of people,", "tokens": [50988, 407, 11, 286, 519, 257, 688, 295, 561, 11, 51028], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 978, "seek": 257128, "start": 2585.36, "end": 2587.1200000000003, "text": " they think about the questions of,", "tokens": [51068, 436, 519, 466, 264, 1651, 295, 11, 51156], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 979, "seek": 257128, "start": 2587.1200000000003, "end": 2588.4, "text": " okay, well, if we can do this stuff,", "tokens": [51156, 1392, 11, 731, 11, 498, 321, 393, 360, 341, 1507, 11, 51220], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 980, "seek": 257128, "start": 2588.4, "end": 2590.0800000000004, "text": " is it bad for it to be out wild?", "tokens": [51220, 307, 309, 1578, 337, 309, 281, 312, 484, 4868, 30, 51304], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 981, "seek": 257128, "start": 2590.0800000000004, "end": 2592.6400000000003, "text": " Like, just kind of widely available.", "tokens": [51304, 1743, 11, 445, 733, 295, 13371, 2435, 13, 51432], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 982, "seek": 257128, "start": 2594.8, "end": 2596.7200000000003, "text": " I think another version of this is like,", "tokens": [51540, 286, 519, 1071, 3037, 295, 341, 307, 411, 11, 51636], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 983, "seek": 257128, "start": 2596.7200000000003, "end": 2599.36, "text": " okay, well, it's probably also pretty bad", "tokens": [51636, 1392, 11, 731, 11, 309, 311, 1391, 611, 1238, 1578, 51768], "temperature": 0.0, "avg_logprob": -0.13244750670024327, "compression_ratio": 1.6462882096069869, "no_speech_prob": 0.0008829603902995586}, {"id": 984, "seek": 259936, "start": 2600.0, "end": 2604.8, "text": " for one institution to have an AI", "tokens": [50396, 337, 472, 7818, 281, 362, 364, 7318, 50636], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 985, "seek": 259936, "start": 2604.8, "end": 2607.92, "text": " that is way more powerful than everyone else's AI, right?", "tokens": [50636, 300, 307, 636, 544, 4005, 813, 1518, 1646, 311, 7318, 11, 558, 30, 50792], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 986, "seek": 259936, "start": 2607.92, "end": 2609.6800000000003, "text": " So, if you look at, like, I guess,", "tokens": [50792, 407, 11, 498, 291, 574, 412, 11, 411, 11, 286, 2041, 11, 50880], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 987, "seek": 259936, "start": 2609.6800000000003, "end": 2612.2400000000002, "text": " one security analogy that I think of is,", "tokens": [50880, 472, 3825, 21663, 300, 286, 519, 295, 307, 11, 51008], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 988, "seek": 259936, "start": 2614.2400000000002, "end": 2618.1600000000003, "text": " you know, it doesn't take AI to basically,", "tokens": [51108, 291, 458, 11, 309, 1177, 380, 747, 7318, 281, 1936, 11, 51304], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 989, "seek": 259936, "start": 2618.1600000000003, "end": 2620.56, "text": " okay, there's security holes in so many different things,", "tokens": [51304, 1392, 11, 456, 311, 3825, 8118, 294, 370, 867, 819, 721, 11, 51424], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 990, "seek": 259936, "start": 2621.2000000000003, "end": 2624.7200000000003, "text": " and if you could travel back in time a year or two years,", "tokens": [51456, 293, 498, 291, 727, 3147, 646, 294, 565, 257, 1064, 420, 732, 924, 11, 51632], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 991, "seek": 259936, "start": 2624.7200000000003, "end": 2626.88, "text": " right, it's like, that's not AI,", "tokens": [51632, 558, 11, 309, 311, 411, 11, 300, 311, 406, 7318, 11, 51740], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 992, "seek": 259936, "start": 2626.88, "end": 2628.2400000000002, "text": " it's like you just, let's say you just have,", "tokens": [51740, 309, 311, 411, 291, 445, 11, 718, 311, 584, 291, 445, 362, 11, 51808], "temperature": 0.0, "avg_logprob": -0.14721653109691182, "compression_ratio": 1.662551440329218, "no_speech_prob": 0.004467958118766546}, {"id": 993, "seek": 262824, "start": 2628.3199999999997, "end": 2630.24, "text": " like, one year or two years more knowledge", "tokens": [50368, 411, 11, 472, 1064, 420, 732, 924, 544, 3601, 50464], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 994, "seek": 262824, "start": 2630.24, "end": 2631.52, "text": " of the security holes,", "tokens": [50464, 295, 264, 3825, 8118, 11, 50528], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 995, "seek": 262824, "start": 2631.52, "end": 2633.7599999999998, "text": " it's pretty much hack into, like, any system, right?", "tokens": [50528, 309, 311, 1238, 709, 10339, 666, 11, 411, 11, 604, 1185, 11, 558, 30, 50640], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 996, "seek": 262824, "start": 2633.7599999999998, "end": 2636.0, "text": " So, it's not that far-fetched to believe", "tokens": [50640, 407, 11, 309, 311, 406, 300, 1400, 12, 69, 7858, 292, 281, 1697, 50752], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 997, "seek": 262824, "start": 2636.7999999999997, "end": 2640.24, "text": " that a very intelligent AI would probably be able", "tokens": [50792, 300, 257, 588, 13232, 7318, 576, 1391, 312, 1075, 50964], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 998, "seek": 262824, "start": 2640.24, "end": 2643.52, "text": " to identify some holes and basically be,", "tokens": [50964, 281, 5876, 512, 8118, 293, 1936, 312, 11, 51128], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 999, "seek": 262824, "start": 2643.52, "end": 2644.7999999999997, "text": " like, a human who could potentially", "tokens": [51128, 411, 11, 257, 1952, 567, 727, 7263, 51192], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1000, "seek": 262824, "start": 2644.7999999999997, "end": 2646.0, "text": " go back in time a year or two", "tokens": [51192, 352, 646, 294, 565, 257, 1064, 420, 732, 51252], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1001, "seek": 262824, "start": 2646.0, "end": 2647.2, "text": " and compromise all these systems.", "tokens": [51252, 293, 18577, 439, 613, 3652, 13, 51312], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1002, "seek": 262824, "start": 2647.2, "end": 2649.8399999999997, "text": " Okay, so how have we dealt with that as a society?", "tokens": [51312, 1033, 11, 370, 577, 362, 321, 15991, 365, 300, 382, 257, 4086, 30, 51444], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1003, "seek": 262824, "start": 2649.8399999999997, "end": 2653.2, "text": " Well, one big part is open-source software", "tokens": [51444, 1042, 11, 472, 955, 644, 307, 1269, 12, 41676, 4722, 51612], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1004, "seek": 262824, "start": 2653.2, "end": 2654.72, "text": " that makes it so that when improvements", "tokens": [51612, 300, 1669, 309, 370, 300, 562, 13797, 51688], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1005, "seek": 262824, "start": 2654.72, "end": 2656.08, "text": " are made to the software,", "tokens": [51688, 366, 1027, 281, 264, 4722, 11, 51756], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1006, "seek": 262824, "start": 2656.08, "end": 2657.68, "text": " it doesn't just kind of get stuck", "tokens": [51756, 309, 1177, 380, 445, 733, 295, 483, 5541, 51836], "temperature": 0.0, "avg_logprob": -0.09059465944377426, "compression_ratio": 1.6790123456790123, "no_speech_prob": 0.001064862823113799}, {"id": 1007, "seek": 265768, "start": 2657.68, "end": 2659.44, "text": " in one company's products,", "tokens": [50364, 294, 472, 2237, 311, 3383, 11, 50452], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1008, "seek": 265768, "start": 2659.44, "end": 2662.08, "text": " but it can kind of be broadly deployed", "tokens": [50452, 457, 309, 393, 733, 295, 312, 19511, 17826, 50584], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1009, "seek": 265768, "start": 2662.08, "end": 2663.44, "text": " to a lot of different systems,", "tokens": [50584, 281, 257, 688, 295, 819, 3652, 11, 50652], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1010, "seek": 265768, "start": 2663.44, "end": 2666.08, "text": " whether it's banks or hospitals or government stuff,", "tokens": [50652, 1968, 309, 311, 10237, 420, 13014, 420, 2463, 1507, 11, 50784], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1011, "seek": 265768, "start": 2666.08, "end": 2668.0, "text": " and, like, just everyone can kind of,", "tokens": [50784, 293, 11, 411, 11, 445, 1518, 393, 733, 295, 11, 50880], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1012, "seek": 265768, "start": 2668.0, "end": 2669.52, "text": " like, as the software gets hardened,", "tokens": [50880, 411, 11, 382, 264, 4722, 2170, 42605, 11, 50956], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1013, "seek": 265768, "start": 2670.16, "end": 2671.8399999999997, "text": " which happens because more people can see it", "tokens": [50988, 597, 2314, 570, 544, 561, 393, 536, 309, 51072], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1014, "seek": 265768, "start": 2671.8399999999997, "end": 2673.04, "text": " and more people can bang on it,", "tokens": [51072, 293, 544, 561, 393, 8550, 322, 309, 11, 51132], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1015, "seek": 265768, "start": 2673.68, "end": 2675.68, "text": " and there are standards on how this stuff works,", "tokens": [51164, 293, 456, 366, 7787, 322, 577, 341, 1507, 1985, 11, 51264], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1016, "seek": 265768, "start": 2677.04, "end": 2679.9199999999996, "text": " the world can kind of get upgraded together pretty quickly.", "tokens": [51332, 264, 1002, 393, 733, 295, 483, 24133, 1214, 1238, 2661, 13, 51476], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1017, "seek": 265768, "start": 2679.9199999999996, "end": 2683.68, "text": " And I kind of think that a world where AI", "tokens": [51476, 400, 286, 733, 295, 519, 300, 257, 1002, 689, 7318, 51664], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1018, "seek": 265768, "start": 2683.68, "end": 2685.44, "text": " is very widely deployed", "tokens": [51664, 307, 588, 13371, 17826, 51752], "temperature": 0.0, "avg_logprob": -0.08132080047849626, "compression_ratio": 1.75, "no_speech_prob": 0.0008039777167141438}, {"id": 1019, "seek": 268544, "start": 2685.76, "end": 2689.68, "text": " in a way where it's gotten hardened progressively over time", "tokens": [50380, 294, 257, 636, 689, 309, 311, 5768, 42605, 46667, 670, 565, 50576], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1020, "seek": 268544, "start": 2690.88, "end": 2694.2400000000002, "text": " is one where all the different systems will be in check", "tokens": [50636, 307, 472, 689, 439, 264, 819, 3652, 486, 312, 294, 1520, 50804], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1021, "seek": 268544, "start": 2694.2400000000002, "end": 2696.88, "text": " in a way that seems like it is fundamentally", "tokens": [50804, 294, 257, 636, 300, 2544, 411, 309, 307, 17879, 50936], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1022, "seek": 268544, "start": 2696.88, "end": 2698.0, "text": " more healthy to me", "tokens": [50936, 544, 4627, 281, 385, 50992], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1023, "seek": 268544, "start": 2698.0, "end": 2700.16, "text": " than one where this is more concentrated.", "tokens": [50992, 813, 472, 689, 341, 307, 544, 21321, 13, 51100], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1024, "seek": 268544, "start": 2700.16, "end": 2702.96, "text": " So there are risks on all sides,", "tokens": [51100, 407, 456, 366, 10888, 322, 439, 4881, 11, 51240], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1025, "seek": 268544, "start": 2702.96, "end": 2707.44, "text": " but I think that that's one risk that I think people,", "tokens": [51240, 457, 286, 519, 300, 300, 311, 472, 3148, 300, 286, 519, 561, 11, 51464], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1026, "seek": 268544, "start": 2707.44, "end": 2709.12, "text": " I don't hear them talking about quite as much.", "tokens": [51464, 286, 500, 380, 1568, 552, 1417, 466, 1596, 382, 709, 13, 51548], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1027, "seek": 268544, "start": 2709.12, "end": 2711.52, "text": " I think, like, there's sort of the risk of, like,", "tokens": [51548, 286, 519, 11, 411, 11, 456, 311, 1333, 295, 264, 3148, 295, 11, 411, 11, 51668], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1028, "seek": 268544, "start": 2711.52, "end": 2713.52, "text": " okay, well, what if the AI system does something bad?", "tokens": [51668, 1392, 11, 731, 11, 437, 498, 264, 7318, 1185, 775, 746, 1578, 30, 51768], "temperature": 0.0, "avg_logprob": -0.12588333892822265, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.003706819610670209}, {"id": 1029, "seek": 271352, "start": 2714.0, "end": 2718.4, "text": " I am more, like, you know, I stay up at night more worrying,", "tokens": [50388, 286, 669, 544, 11, 411, 11, 291, 458, 11, 286, 1754, 493, 412, 1818, 544, 18788, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1030, "seek": 271352, "start": 2718.4, "end": 2722.24, "text": " well, what if, like, some actor that, whatever.", "tokens": [50608, 731, 11, 437, 498, 11, 411, 11, 512, 8747, 300, 11, 2035, 13, 50800], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1031, "seek": 271352, "start": 2722.24, "end": 2723.36, "text": " It's like, from wherever you sit,", "tokens": [50800, 467, 311, 411, 11, 490, 8660, 291, 1394, 11, 50856], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1032, "seek": 271352, "start": 2723.36, "end": 2725.36, "text": " there's going to be some actor who you don't trust", "tokens": [50856, 456, 311, 516, 281, 312, 512, 8747, 567, 291, 500, 380, 3361, 50956], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1033, "seek": 271352, "start": 2725.36, "end": 2727.52, "text": " if they're the ones who have, like, the super strong AI,", "tokens": [50956, 498, 436, 434, 264, 2306, 567, 362, 11, 411, 11, 264, 1687, 2068, 7318, 11, 51064], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1034, "seek": 271352, "start": 2727.52, "end": 2729.36, "text": " whether it's some, like, other government", "tokens": [51064, 1968, 309, 311, 512, 11, 411, 11, 661, 2463, 51156], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1035, "seek": 271352, "start": 2729.36, "end": 2732.88, "text": " that is sort of, like, an opponent of our country", "tokens": [51156, 300, 307, 1333, 295, 11, 411, 11, 364, 10620, 295, 527, 1941, 51332], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1036, "seek": 271352, "start": 2732.88, "end": 2735.68, "text": " or some company that you don't trust or whatever it is.", "tokens": [51332, 420, 512, 2237, 300, 291, 500, 380, 3361, 420, 2035, 309, 307, 13, 51472], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1037, "seek": 271352, "start": 2737.68, "end": 2743.12, "text": " Like, I think that that's potentially a much bigger risk", "tokens": [51572, 1743, 11, 286, 519, 300, 300, 311, 7263, 257, 709, 3801, 3148, 51844], "temperature": 0.0, "avg_logprob": -0.11229853919058135, "compression_ratio": 1.8127490039840637, "no_speech_prob": 0.0046089147217571735}, {"id": 1038, "seek": 274312, "start": 2743.2, "end": 2747.3599999999997, "text": " as in they could, like, overthrow our government", "tokens": [50368, 382, 294, 436, 727, 11, 411, 11, 46924, 527, 2463, 50576], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1039, "seek": 274312, "start": 2747.3599999999997, "end": 2750.08, "text": " because they have a weapon that, like, nobody else has.", "tokens": [50576, 570, 436, 362, 257, 7463, 300, 11, 411, 11, 5079, 1646, 575, 13, 50712], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1040, "seek": 274312, "start": 2750.08, "end": 2751.6, "text": " Cause a lot of mayhem.", "tokens": [50712, 10865, 257, 688, 295, 815, 28005, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1041, "seek": 274312, "start": 2751.6, "end": 2754.88, "text": " Right, it's, I think it's, like, I mean,", "tokens": [50788, 1779, 11, 309, 311, 11, 286, 519, 309, 311, 11, 411, 11, 286, 914, 11, 50952], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1042, "seek": 274312, "start": 2754.88, "end": 2757.3599999999997, "text": " I think the intuition is that this stuff ends up being", "tokens": [50952, 286, 519, 264, 24002, 307, 300, 341, 1507, 5314, 493, 885, 51076], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1043, "seek": 274312, "start": 2757.3599999999997, "end": 2760.96, "text": " pretty kind of important and valuable", "tokens": [51076, 1238, 733, 295, 1021, 293, 8263, 51256], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1044, "seek": 274312, "start": 2760.96, "end": 2763.92, "text": " for both kind of economic and kind of security", "tokens": [51256, 337, 1293, 733, 295, 4836, 293, 733, 295, 3825, 51404], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1045, "seek": 274312, "start": 2763.92, "end": 2764.64, "text": " and other things.", "tokens": [51404, 293, 661, 721, 13, 51440], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1046, "seek": 274312, "start": 2764.64, "end": 2768.0, "text": " And I don't know, I just think, yeah, if, like,", "tokens": [51440, 400, 286, 500, 380, 458, 11, 286, 445, 519, 11, 1338, 11, 498, 11, 411, 11, 51608], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1047, "seek": 274312, "start": 2768.0, "end": 2770.88, "text": " if someone who you don't trust or is an adversary of you", "tokens": [51608, 498, 1580, 567, 291, 500, 380, 3361, 420, 307, 364, 48222, 295, 291, 51752], "temperature": 0.0, "avg_logprob": -0.13917444622705852, "compression_ratio": 1.68359375, "no_speech_prob": 0.0007319988217204809}, {"id": 1048, "seek": 277088, "start": 2770.96, "end": 2772.96, "text": " gets something that is more powerful,", "tokens": [50368, 2170, 746, 300, 307, 544, 4005, 11, 50468], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1049, "seek": 277088, "start": 2772.96, "end": 2775.12, "text": " then I think that that could be an issue.", "tokens": [50468, 550, 286, 519, 300, 300, 727, 312, 364, 2734, 13, 50576], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1050, "seek": 277088, "start": 2775.12, "end": 2777.36, "text": " And I think probably the best way to mitigate that", "tokens": [50576, 400, 286, 519, 1391, 264, 1151, 636, 281, 27336, 300, 50688], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1051, "seek": 277088, "start": 2777.36, "end": 2780.4, "text": " is to have good open source AI", "tokens": [50688, 307, 281, 362, 665, 1269, 4009, 7318, 50840], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1052, "seek": 277088, "start": 2780.4, "end": 2782.6400000000003, "text": " that basically becomes the standard", "tokens": [50840, 300, 1936, 3643, 264, 3832, 50952], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1053, "seek": 277088, "start": 2783.44, "end": 2786.1600000000003, "text": " and in a lot of ways kind of can become the leader.", "tokens": [50992, 293, 294, 257, 688, 295, 2098, 733, 295, 393, 1813, 264, 5263, 13, 51128], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1054, "seek": 277088, "start": 2786.1600000000003, "end": 2790.08, "text": " And in that way, it just ensures that it's a much more", "tokens": [51128, 400, 294, 300, 636, 11, 309, 445, 28111, 300, 309, 311, 257, 709, 544, 51324], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1055, "seek": 277088, "start": 2790.08, "end": 2792.96, "text": " kind of even and balanced playing field.", "tokens": [51324, 733, 295, 754, 293, 13902, 2433, 2519, 13, 51468], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1056, "seek": 277088, "start": 2792.96, "end": 2794.4, "text": " Yeah, that seems plausible to me.", "tokens": [51468, 865, 11, 300, 2544, 39925, 281, 385, 13, 51540], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1057, "seek": 277088, "start": 2794.4, "end": 2796.8, "text": " And if that works out, that would be the future I prefer.", "tokens": [51540, 400, 498, 300, 1985, 484, 11, 300, 576, 312, 264, 2027, 286, 4382, 13, 51660], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1058, "seek": 277088, "start": 2797.92, "end": 2800.56, "text": " I guess I want to understand, like, mechanistically", "tokens": [51716, 286, 2041, 286, 528, 281, 1223, 11, 411, 11, 4236, 20458, 51848], "temperature": 0.0, "avg_logprob": -0.0988579451582814, "compression_ratio": 1.7340425531914894, "no_speech_prob": 0.006691129878163338}, {"id": 1059, "seek": 280056, "start": 2800.64, "end": 2804.08, "text": " how if somebody was going to cause mayhem with AI systems,", "tokens": [50368, 577, 498, 2618, 390, 516, 281, 3082, 815, 28005, 365, 7318, 3652, 11, 50540], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1060, "seek": 280056, "start": 2804.08, "end": 2806.48, "text": " how the fact that there are other open source systems", "tokens": [50540, 577, 264, 1186, 300, 456, 366, 661, 1269, 4009, 3652, 50660], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1061, "seek": 280056, "start": 2806.48, "end": 2808.08, "text": " in the world prevents that?", "tokens": [50660, 294, 264, 1002, 22367, 300, 30, 50740], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1062, "seek": 280056, "start": 2808.08, "end": 2809.92, "text": " Like the specific example of, like,", "tokens": [50740, 1743, 264, 2685, 1365, 295, 11, 411, 11, 50832], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1063, "seek": 280056, "start": 2809.92, "end": 2811.2, "text": " somebody coming with a bio weapon,", "tokens": [50832, 2618, 1348, 365, 257, 12198, 7463, 11, 50896], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1064, "seek": 280056, "start": 2811.84, "end": 2813.2799999999997, "text": " is it just that we'll do a bunch of, like,", "tokens": [50928, 307, 309, 445, 300, 321, 603, 360, 257, 3840, 295, 11, 411, 11, 51000], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1065, "seek": 280056, "start": 2813.2799999999997, "end": 2815.04, "text": " R&D in the rest of the world to, like,", "tokens": [51000, 497, 5, 35, 294, 264, 1472, 295, 264, 1002, 281, 11, 411, 11, 51088], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1066, "seek": 280056, "start": 2815.04, "end": 2816.4, "text": " figure out vaccines really fast?", "tokens": [51088, 2573, 484, 12164, 534, 2370, 30, 51156], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1067, "seek": 280056, "start": 2816.4, "end": 2817.2799999999997, "text": " Like, what's happening?", "tokens": [51156, 1743, 11, 437, 311, 2737, 30, 51200], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1068, "seek": 280056, "start": 2817.2799999999997, "end": 2818.48, "text": " Would you take, like, the computer,", "tokens": [51200, 6068, 291, 747, 11, 411, 11, 264, 3820, 11, 51260], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1069, "seek": 280056, "start": 2818.48, "end": 2820.64, "text": " the security one that I was talking about?", "tokens": [51260, 264, 3825, 472, 300, 286, 390, 1417, 466, 30, 51368], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1070, "seek": 280056, "start": 2820.64, "end": 2822.4, "text": " I think someone with a weaker AI", "tokens": [51368, 286, 519, 1580, 365, 257, 24286, 7318, 51456], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1071, "seek": 280056, "start": 2822.4, "end": 2824.64, "text": " trying to hack into a system that is, like,", "tokens": [51456, 1382, 281, 10339, 666, 257, 1185, 300, 307, 11, 411, 11, 51568], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1072, "seek": 280056, "start": 2824.64, "end": 2827.04, "text": " protected by a stronger AI will succeed less.", "tokens": [51568, 10594, 538, 257, 7249, 7318, 486, 7754, 1570, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11896912155637315, "compression_ratio": 1.7304075235109717, "no_speech_prob": 0.001648144330829382}, {"id": 1073, "seek": 282704, "start": 2827.7599999999998, "end": 2830.56, "text": " Right, so I think that that's, I mean,", "tokens": [50400, 1779, 11, 370, 286, 519, 300, 300, 311, 11, 286, 914, 11, 50540], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1074, "seek": 282704, "start": 2830.56, "end": 2831.7599999999998, "text": " that's, like, in terms of software security.", "tokens": [50540, 300, 311, 11, 411, 11, 294, 2115, 295, 4722, 3825, 13, 50600], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1075, "seek": 282704, "start": 2831.7599999999998, "end": 2833.36, "text": " How do you know everything in the world is like that?", "tokens": [50600, 1012, 360, 291, 458, 1203, 294, 264, 1002, 307, 411, 300, 30, 50680], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1076, "seek": 282704, "start": 2833.36, "end": 2835.04, "text": " Like, what if bio weapons aren't like that?", "tokens": [50680, 1743, 11, 437, 498, 12198, 7278, 3212, 380, 411, 300, 30, 50764], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1077, "seek": 282704, "start": 2836.08, "end": 2837.92, "text": " No, I mean, I don't know that everything", "tokens": [50816, 883, 11, 286, 914, 11, 286, 500, 380, 458, 300, 1203, 50908], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1078, "seek": 282704, "start": 2837.92, "end": 2838.8, "text": " in the world is like that.", "tokens": [50908, 294, 264, 1002, 307, 411, 300, 13, 50952], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1079, "seek": 282704, "start": 2841.52, "end": 2844.16, "text": " I think that that's, I guess,", "tokens": [51088, 286, 519, 300, 300, 311, 11, 286, 2041, 11, 51220], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1080, "seek": 282704, "start": 2844.16, "end": 2846.08, "text": " one of the, bio weapons are one of the areas", "tokens": [51220, 472, 295, 264, 11, 12198, 7278, 366, 472, 295, 264, 3179, 51316], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1081, "seek": 282704, "start": 2846.08, "end": 2848.32, "text": " where I think the people who are most worried", "tokens": [51316, 689, 286, 519, 264, 561, 567, 366, 881, 5804, 51428], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1082, "seek": 282704, "start": 2848.32, "end": 2849.92, "text": " about this stuff are focused.", "tokens": [51428, 466, 341, 1507, 366, 5178, 13, 51508], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1083, "seek": 282704, "start": 2849.92, "end": 2853.2, "text": " And I think that that's, I think that makes", "tokens": [51508, 400, 286, 519, 300, 300, 311, 11, 286, 519, 300, 1669, 51672], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1084, "seek": 282704, "start": 2853.2, "end": 2854.32, "text": " a lot of sense to think about that.", "tokens": [51672, 257, 688, 295, 2020, 281, 519, 466, 300, 13, 51728], "temperature": 0.0, "avg_logprob": -0.15912465062634698, "compression_ratio": 2.0689655172413794, "no_speech_prob": 0.015902774408459663}, {"id": 1085, "seek": 285432, "start": 2855.2000000000003, "end": 2858.8, "text": " The, and I think that there are certain mitigations.", "tokens": [50408, 440, 11, 293, 286, 519, 300, 456, 366, 1629, 15699, 763, 13, 50588], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1086, "seek": 285432, "start": 2858.8, "end": 2861.6000000000004, "text": " You can try to not train certain knowledge", "tokens": [50588, 509, 393, 853, 281, 406, 3847, 1629, 3601, 50728], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1087, "seek": 285432, "start": 2861.6000000000004, "end": 2862.88, "text": " into the model, right?", "tokens": [50728, 666, 264, 2316, 11, 558, 30, 50792], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1088, "seek": 285432, "start": 2862.88, "end": 2865.76, "text": " There's different things, but, yeah,", "tokens": [50792, 821, 311, 819, 721, 11, 457, 11, 1338, 11, 50936], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1089, "seek": 285432, "start": 2865.76, "end": 2868.4, "text": " I mean, it's some level, I mean,", "tokens": [50936, 286, 914, 11, 309, 311, 512, 1496, 11, 286, 914, 11, 51068], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1090, "seek": 285432, "start": 2868.4, "end": 2870.88, "text": " if you get a sufficiently bad actor", "tokens": [51068, 498, 291, 483, 257, 31868, 1578, 8747, 51192], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1091, "seek": 285432, "start": 2870.88, "end": 2874.56, "text": " and you don't have other AI that can sort of balance them", "tokens": [51192, 293, 291, 500, 380, 362, 661, 7318, 300, 393, 1333, 295, 4772, 552, 51376], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1092, "seek": 285432, "start": 2874.56, "end": 2877.84, "text": " and understand what's going on and what the threats are,", "tokens": [51376, 293, 1223, 437, 311, 516, 322, 293, 437, 264, 14909, 366, 11, 51540], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1093, "seek": 285432, "start": 2877.84, "end": 2880.32, "text": " then that could be a risk.", "tokens": [51540, 550, 300, 727, 312, 257, 3148, 13, 51664], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1094, "seek": 285432, "start": 2880.32, "end": 2881.44, "text": " So I think that that's one of the things", "tokens": [51664, 407, 286, 519, 300, 300, 311, 472, 295, 264, 721, 51720], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1095, "seek": 285432, "start": 2881.44, "end": 2882.56, "text": " that we need to watch out for.", "tokens": [51720, 300, 321, 643, 281, 1159, 484, 337, 13, 51776], "temperature": 0.0, "avg_logprob": -0.2397335533082016, "compression_ratio": 1.6781609195402298, "no_speech_prob": 0.0018098161090165377}, {"id": 1096, "seek": 288256, "start": 2882.96, "end": 2886.64, "text": " Is there something you could see", "tokens": [50384, 1119, 456, 746, 291, 727, 536, 50568], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1097, "seek": 288256, "start": 2886.64, "end": 2888.0, "text": " in the deployment of these systems", "tokens": [50568, 294, 264, 19317, 295, 613, 3652, 50636], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1098, "seek": 288256, "start": 2888.0, "end": 2892.16, "text": " where you observe like you're training Lama 4", "tokens": [50636, 689, 291, 11441, 411, 291, 434, 3097, 441, 2404, 1017, 50844], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1099, "seek": 288256, "start": 2892.16, "end": 2893.68, "text": " and it's like, it lied to you", "tokens": [50844, 293, 309, 311, 411, 11, 309, 20101, 281, 291, 50920], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1100, "seek": 288256, "start": 2893.68, "end": 2895.52, "text": " because you thought you were noticing or something.", "tokens": [50920, 570, 291, 1194, 291, 645, 21814, 420, 746, 13, 51012], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1101, "seek": 288256, "start": 2895.52, "end": 2898.16, "text": " And you're like, whoa, what's going on here?", "tokens": [51012, 400, 291, 434, 411, 11, 13310, 11, 437, 311, 516, 322, 510, 30, 51144], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1102, "seek": 288256, "start": 2898.16, "end": 2900.48, "text": " Not that this is probably not likely", "tokens": [51144, 1726, 300, 341, 307, 1391, 406, 3700, 51260], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1103, "seek": 288256, "start": 2900.48, "end": 2901.44, "text": " with the Lama 4.0 system,", "tokens": [51260, 365, 264, 441, 2404, 1017, 13, 15, 1185, 11, 51308], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1104, "seek": 288256, "start": 2901.44, "end": 2903.36, "text": " but is there something you can imagine like that", "tokens": [51308, 457, 307, 456, 746, 291, 393, 3811, 411, 300, 51404], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1105, "seek": 288256, "start": 2903.36, "end": 2906.48, "text": " where you'd be really concerned about deceptiveness", "tokens": [51404, 689, 291, 1116, 312, 534, 5922, 466, 368, 1336, 8477, 51560], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1106, "seek": 288256, "start": 2906.48, "end": 2908.96, "text": " and if billions of copies of things are out in the wild?", "tokens": [51560, 293, 498, 17375, 295, 14341, 295, 721, 366, 484, 294, 264, 4868, 30, 51684], "temperature": 0.0, "avg_logprob": -0.22509922790527342, "compression_ratio": 1.752851711026616, "no_speech_prob": 0.0016478737816214561}, {"id": 1107, "seek": 290896, "start": 2909.84, "end": 2914.4, "text": " Yeah, I mean, I think that that's not necessarily,", "tokens": [50408, 865, 11, 286, 914, 11, 286, 519, 300, 300, 311, 406, 4725, 11, 50636], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1108, "seek": 290896, "start": 2914.4, "end": 2917.68, "text": " I mean, right now, we see a lot of hallucinations, right?", "tokens": [50636, 286, 914, 11, 558, 586, 11, 321, 536, 257, 688, 295, 35212, 10325, 11, 558, 30, 50800], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1109, "seek": 290896, "start": 2917.68, "end": 2919.36, "text": " So I think it's more that.", "tokens": [50800, 407, 286, 519, 309, 311, 544, 300, 13, 50884], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1110, "seek": 290896, "start": 2921.2, "end": 2922.64, "text": " I think it's an interesting question", "tokens": [50976, 286, 519, 309, 311, 364, 1880, 1168, 51048], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1111, "seek": 290896, "start": 2922.64, "end": 2923.68, "text": " how you would tell the difference", "tokens": [51048, 577, 291, 576, 980, 264, 2649, 51100], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1112, "seek": 290896, "start": 2923.68, "end": 2926.32, "text": " between a hallucination and deception.", "tokens": [51100, 1296, 257, 35212, 2486, 293, 40451, 13, 51232], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1113, "seek": 290896, "start": 2926.32, "end": 2927.52, "text": " But yeah, I mean, look, I mean,", "tokens": [51232, 583, 1338, 11, 286, 914, 11, 574, 11, 286, 914, 11, 51292], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1114, "seek": 290896, "start": 2927.52, "end": 2929.92, "text": " I think there's a lot of risks and things to think about.", "tokens": [51292, 286, 519, 456, 311, 257, 688, 295, 10888, 293, 721, 281, 519, 466, 13, 51412], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1115, "seek": 290896, "start": 2929.92, "end": 2935.12, "text": " The flip side of all this is that there are also a lot of,", "tokens": [51412, 440, 7929, 1252, 295, 439, 341, 307, 300, 456, 366, 611, 257, 688, 295, 11, 51672], "temperature": 0.0, "avg_logprob": -0.1757771744687333, "compression_ratio": 1.7990867579908676, "no_speech_prob": 0.0010004411451518536}, {"id": 1116, "seek": 293512, "start": 2936.08, "end": 2939.04, "text": " I try to, in running our company at least,", "tokens": [50412, 286, 853, 281, 11, 294, 2614, 527, 2237, 412, 1935, 11, 50560], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1117, "seek": 293512, "start": 2940.0, "end": 2945.12, "text": " balance what I think of as these longer term theoretical risks", "tokens": [50608, 4772, 437, 286, 519, 295, 382, 613, 2854, 1433, 20864, 10888, 50864], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1118, "seek": 293512, "start": 2947.44, "end": 2950.64, "text": " with what I actually think are quite real risks that exist today.", "tokens": [50980, 365, 437, 286, 767, 519, 366, 1596, 957, 10888, 300, 2514, 965, 13, 51140], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1119, "seek": 293512, "start": 2950.64, "end": 2954.4, "text": " So like when you talk about deception,", "tokens": [51140, 407, 411, 562, 291, 751, 466, 40451, 11, 51328], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1120, "seek": 293512, "start": 2954.4, "end": 2956.08, "text": " the form of that that I worry about most", "tokens": [51328, 264, 1254, 295, 300, 300, 286, 3292, 466, 881, 51412], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1121, "seek": 293512, "start": 2956.08, "end": 2958.56, "text": " is people using this to generate misinformation", "tokens": [51412, 307, 561, 1228, 341, 281, 8460, 34238, 51536], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1122, "seek": 293512, "start": 2958.56, "end": 2959.92, "text": " and then like pump that through", "tokens": [51536, 293, 550, 411, 5889, 300, 807, 51604], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1123, "seek": 293512, "start": 2959.92, "end": 2961.8399999999997, "text": " whether it's our networks or others.", "tokens": [51604, 1968, 309, 311, 527, 9590, 420, 2357, 13, 51700], "temperature": 0.0, "avg_logprob": -0.11236808064219715, "compression_ratio": 1.6283185840707965, "no_speech_prob": 0.0007095847395248711}, {"id": 1124, "seek": 296184, "start": 2961.92, "end": 2965.6800000000003, "text": " So the way that we've basically combated", "tokens": [50368, 407, 264, 636, 300, 321, 600, 1936, 2512, 770, 50556], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1125, "seek": 296184, "start": 2965.6800000000003, "end": 2967.84, "text": " a lot of this type of harmful content", "tokens": [50556, 257, 688, 295, 341, 2010, 295, 19727, 2701, 50664], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1126, "seek": 296184, "start": 2968.4, "end": 2970.0, "text": " is by building AI systems", "tokens": [50692, 307, 538, 2390, 7318, 3652, 50772], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1127, "seek": 296184, "start": 2970.0, "end": 2972.2400000000002, "text": " that are smarter than the adversarial ones.", "tokens": [50772, 300, 366, 20294, 813, 264, 17641, 44745, 2306, 13, 50884], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1128, "seek": 296184, "start": 2972.2400000000002, "end": 2973.92, "text": " And I guess this is part of,", "tokens": [50884, 400, 286, 2041, 341, 307, 644, 295, 11, 50968], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1129, "seek": 296184, "start": 2973.92, "end": 2975.92, "text": " this kind of informs part of my theory on this, right?", "tokens": [50968, 341, 733, 295, 45320, 644, 295, 452, 5261, 322, 341, 11, 558, 30, 51068], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1130, "seek": 296184, "start": 2975.92, "end": 2978.0, "text": " Is if you look at like the different types of harm", "tokens": [51068, 1119, 498, 291, 574, 412, 411, 264, 819, 3467, 295, 6491, 51172], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1131, "seek": 296184, "start": 2978.0, "end": 2981.6800000000003, "text": " that people do or try to do through social networks,", "tokens": [51172, 300, 561, 360, 420, 853, 281, 360, 807, 2093, 9590, 11, 51356], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1132, "seek": 296184, "start": 2984.32, "end": 2986.8, "text": " there are ones that are not very adversarial.", "tokens": [51488, 456, 366, 2306, 300, 366, 406, 588, 17641, 44745, 13, 51612], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1133, "seek": 296184, "start": 2986.8, "end": 2991.52, "text": " So for example, like hate speech,", "tokens": [51612, 407, 337, 1365, 11, 411, 4700, 6218, 11, 51848], "temperature": 0.0, "avg_logprob": -0.09105742605108964, "compression_ratio": 1.6442687747035574, "no_speech_prob": 0.0006262600072659552}, {"id": 1134, "seek": 299152, "start": 2991.52, "end": 2993.92, "text": " I would say is not super adversarial", "tokens": [50364, 286, 576, 584, 307, 406, 1687, 17641, 44745, 50484], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1135, "seek": 299152, "start": 2993.92, "end": 2996.24, "text": " in the sense that like people aren't getting", "tokens": [50484, 294, 264, 2020, 300, 411, 561, 3212, 380, 1242, 50600], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1136, "seek": 299152, "start": 2997.28, "end": 2999.44, "text": " better at being racist, right?", "tokens": [50652, 1101, 412, 885, 16419, 11, 558, 30, 50760], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1137, "seek": 299152, "start": 2999.44, "end": 3001.92, "text": " They're just like, it's, you just like, okay,", "tokens": [50760, 814, 434, 445, 411, 11, 309, 311, 11, 291, 445, 411, 11, 1392, 11, 50884], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1138, "seek": 299152, "start": 3001.92, "end": 3004.56, "text": " if you kind of, that's one where I think the AIs", "tokens": [50884, 498, 291, 733, 295, 11, 300, 311, 472, 689, 286, 519, 264, 316, 6802, 51016], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1139, "seek": 299152, "start": 3004.56, "end": 3007.68, "text": " are generally just getting way more sophisticated,", "tokens": [51016, 366, 5101, 445, 1242, 636, 544, 16950, 11, 51172], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1140, "seek": 299152, "start": 3007.68, "end": 3009.6, "text": " faster than people are at those issues.", "tokens": [51172, 4663, 813, 561, 366, 412, 729, 2663, 13, 51268], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1141, "seek": 299152, "start": 3009.6, "end": 3011.36, "text": " So we have, and we have issues both ways.", "tokens": [51268, 407, 321, 362, 11, 293, 321, 362, 2663, 1293, 2098, 13, 51356], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1142, "seek": 299152, "start": 3011.36, "end": 3014.24, "text": " It's like people do bad things", "tokens": [51356, 467, 311, 411, 561, 360, 1578, 721, 51500], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1143, "seek": 299152, "start": 3014.24, "end": 3016.48, "text": " that whether they're trying to incite violence or something.", "tokens": [51500, 300, 1968, 436, 434, 1382, 281, 834, 642, 6270, 420, 746, 13, 51612], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1144, "seek": 299152, "start": 3018.24, "end": 3019.84, "text": " But we also have a lot of false positives, right?", "tokens": [51700, 583, 321, 611, 362, 257, 688, 295, 7908, 35127, 11, 558, 30, 51780], "temperature": 0.0, "avg_logprob": -0.13446890418209248, "compression_ratio": 1.7153024911032029, "no_speech_prob": 0.0006877453997731209}, {"id": 1145, "seek": 301984, "start": 3019.92, "end": 3022.2400000000002, "text": " So where we basically censor stuff that we shouldn't,", "tokens": [50368, 407, 689, 321, 1936, 19019, 284, 1507, 300, 321, 4659, 380, 11, 50484], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1146, "seek": 301984, "start": 3022.2400000000002, "end": 3025.28, "text": " and I think understandably make a lot of people annoyed.", "tokens": [50484, 293, 286, 519, 1223, 1188, 652, 257, 688, 295, 561, 25921, 13, 50636], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1147, "seek": 301984, "start": 3025.28, "end": 3027.92, "text": " So I think having an AI that just gets increasingly", "tokens": [50636, 407, 286, 519, 1419, 364, 7318, 300, 445, 2170, 12980, 50768], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1148, "seek": 301984, "start": 3027.92, "end": 3030.56, "text": " precise on that, that's gonna be good over time.", "tokens": [50768, 13600, 322, 300, 11, 300, 311, 799, 312, 665, 670, 565, 13, 50900], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1149, "seek": 301984, "start": 3030.56, "end": 3031.6800000000003, "text": " But let me give you another example,", "tokens": [50900, 583, 718, 385, 976, 291, 1071, 1365, 11, 50956], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1150, "seek": 301984, "start": 3031.6800000000003, "end": 3034.32, "text": " which is like nation states trying to interfere in elections.", "tokens": [50956, 597, 307, 411, 4790, 4368, 1382, 281, 23946, 294, 12870, 13, 51088], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1151, "seek": 301984, "start": 3034.88, "end": 3037.2000000000003, "text": " That's an example where they're absolutely,", "tokens": [51116, 663, 311, 364, 1365, 689, 436, 434, 3122, 11, 51232], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1152, "seek": 301984, "start": 3037.2000000000003, "end": 3038.8, "text": " they have cutting edge technology", "tokens": [51232, 436, 362, 6492, 4691, 2899, 51312], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1153, "seek": 301984, "start": 3038.8, "end": 3041.44, "text": " and absolutely get better each year.", "tokens": [51312, 293, 3122, 483, 1101, 1184, 1064, 13, 51444], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1154, "seek": 301984, "start": 3041.44, "end": 3044.6400000000003, "text": " So we block some technique, they learn what we did,", "tokens": [51444, 407, 321, 3461, 512, 6532, 11, 436, 1466, 437, 321, 630, 11, 51604], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1155, "seek": 301984, "start": 3044.6400000000003, "end": 3046.6400000000003, "text": " they come at us with a different technique, right?", "tokens": [51604, 436, 808, 412, 505, 365, 257, 819, 6532, 11, 558, 30, 51704], "temperature": 0.0, "avg_logprob": -0.10677194953861094, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0016482053324580193}, {"id": 1156, "seek": 304664, "start": 3046.64, "end": 3052.24, "text": " It's not like a person trying to say mean things, right?", "tokens": [50364, 467, 311, 406, 411, 257, 954, 1382, 281, 584, 914, 721, 11, 558, 30, 50644], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1157, "seek": 304664, "start": 3052.24, "end": 3055.12, "text": " It's like, they're basically, they have a goal,", "tokens": [50644, 467, 311, 411, 11, 436, 434, 1936, 11, 436, 362, 257, 3387, 11, 50788], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1158, "seek": 304664, "start": 3055.12, "end": 3056.96, "text": " they're sophisticated, they have a lot of technology.", "tokens": [50788, 436, 434, 16950, 11, 436, 362, 257, 688, 295, 2899, 13, 50880], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1159, "seek": 304664, "start": 3058.3199999999997, "end": 3060.3199999999997, "text": " In those cases, I still think the ability", "tokens": [50948, 682, 729, 3331, 11, 286, 920, 519, 264, 3485, 51048], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1160, "seek": 304664, "start": 3060.3199999999997, "end": 3064.7999999999997, "text": " to kind of have RAI systems grow in sophistication", "tokens": [51048, 281, 733, 295, 362, 14626, 40, 3652, 1852, 294, 15572, 399, 51272], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1161, "seek": 304664, "start": 3064.7999999999997, "end": 3067.68, "text": " at a faster rate than theirs have, it's an arms race,", "tokens": [51272, 412, 257, 4663, 3314, 813, 22760, 362, 11, 309, 311, 364, 5812, 4569, 11, 51416], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1162, "seek": 304664, "start": 3067.68, "end": 3070.64, "text": " but I think we're at least currently winning that arms race.", "tokens": [51416, 457, 286, 519, 321, 434, 412, 1935, 4362, 8224, 300, 5812, 4569, 13, 51564], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1163, "seek": 304664, "start": 3072.24, "end": 3073.92, "text": " So I don't know, I think that that's,", "tokens": [51644, 407, 286, 500, 380, 458, 11, 286, 519, 300, 300, 311, 11, 51728], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1164, "seek": 304664, "start": 3073.92, "end": 3075.04, "text": " but this is like a lot of the stuff", "tokens": [51728, 457, 341, 307, 411, 257, 688, 295, 264, 1507, 51784], "temperature": 0.0, "avg_logprob": -0.11729592368716285, "compression_ratio": 1.746031746031746, "no_speech_prob": 0.0010004185605794191}, {"id": 1165, "seek": 307504, "start": 3075.04, "end": 3077.2, "text": " that I spend time thinking about is like, okay,", "tokens": [50364, 300, 286, 3496, 565, 1953, 466, 307, 411, 11, 1392, 11, 50472], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1166, "seek": 307504, "start": 3078.24, "end": 3082.24, "text": " yes, it is possible that whether it's llama four", "tokens": [50524, 2086, 11, 309, 307, 1944, 300, 1968, 309, 311, 23272, 1451, 50724], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1167, "seek": 307504, "start": 3082.24, "end": 3084.24, "text": " or llama five or llama six, yeah,", "tokens": [50724, 420, 23272, 1732, 420, 23272, 2309, 11, 1338, 11, 50824], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1168, "seek": 307504, "start": 3084.24, "end": 3086.48, "text": " we need to think about what behaviors we're observing", "tokens": [50824, 321, 643, 281, 519, 466, 437, 15501, 321, 434, 22107, 50936], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1169, "seek": 307504, "start": 3086.48, "end": 3087.2, "text": " and it's not just us.", "tokens": [50936, 293, 309, 311, 406, 445, 505, 13, 50972], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1170, "seek": 307504, "start": 3087.2, "end": 3088.8, "text": " And part of the reason why you make this open source", "tokens": [50972, 400, 644, 295, 264, 1778, 983, 291, 652, 341, 1269, 4009, 51052], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1171, "seek": 307504, "start": 3088.8, "end": 3090.96, "text": " is that there are a lot of other people who study this too.", "tokens": [51052, 307, 300, 456, 366, 257, 688, 295, 661, 561, 567, 2979, 341, 886, 13, 51160], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1172, "seek": 307504, "start": 3090.96, "end": 3094.24, "text": " So yeah, we wanna see what other people are observing,", "tokens": [51160, 407, 1338, 11, 321, 1948, 536, 437, 661, 561, 366, 22107, 11, 51324], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1173, "seek": 307504, "start": 3094.24, "end": 3096.72, "text": " what we're observing, what we can mitigate,", "tokens": [51324, 437, 321, 434, 22107, 11, 437, 321, 393, 27336, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1174, "seek": 307504, "start": 3096.72, "end": 3098.48, "text": " and then we'll make our assessment", "tokens": [51448, 293, 550, 321, 603, 652, 527, 9687, 51536], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1175, "seek": 307504, "start": 3098.48, "end": 3101.68, "text": " on whether we can make it open source.", "tokens": [51536, 322, 1968, 321, 393, 652, 309, 1269, 4009, 13, 51696], "temperature": 0.0, "avg_logprob": -0.12182330378779659, "compression_ratio": 1.8636363636363635, "no_speech_prob": 0.0021823234856128693}, {"id": 1176, "seek": 310168, "start": 3101.68, "end": 3104.96, "text": " But I think for the foreseeable future,", "tokens": [50364, 583, 286, 519, 337, 264, 38736, 712, 2027, 11, 50528], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1177, "seek": 310168, "start": 3104.96, "end": 3107.2, "text": " I'm optimistic we will be able to.", "tokens": [50528, 286, 478, 19397, 321, 486, 312, 1075, 281, 13, 50640], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1178, "seek": 310168, "start": 3107.2, "end": 3111.04, "text": " And in the near term, I don't wanna take our eye off the ball", "tokens": [50640, 400, 294, 264, 2651, 1433, 11, 286, 500, 380, 1948, 747, 527, 3313, 766, 264, 2594, 50832], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1179, "seek": 310168, "start": 3111.04, "end": 3112.96, "text": " of what our actual bad things", "tokens": [50832, 295, 437, 527, 3539, 1578, 721, 50928], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1180, "seek": 310168, "start": 3112.96, "end": 3114.96, "text": " that people are trying to use the models for today,", "tokens": [50928, 300, 561, 366, 1382, 281, 764, 264, 5245, 337, 965, 11, 51028], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1181, "seek": 310168, "start": 3114.96, "end": 3116.16, "text": " even if they're not existential,", "tokens": [51028, 754, 498, 436, 434, 406, 37133, 11, 51088], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1182, "seek": 310168, "start": 3116.16, "end": 3120.56, "text": " but they're like pretty bad kind of day-to-day harms", "tokens": [51088, 457, 436, 434, 411, 1238, 1578, 733, 295, 786, 12, 1353, 12, 810, 48505, 51308], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1183, "seek": 310168, "start": 3120.56, "end": 3123.12, "text": " that we are familiar with in running our services.", "tokens": [51308, 300, 321, 366, 4963, 365, 294, 2614, 527, 3328, 13, 51436], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1184, "seek": 310168, "start": 3124.8799999999997, "end": 3126.3999999999996, "text": " That's actually a lot of what we have to,", "tokens": [51524, 663, 311, 767, 257, 688, 295, 437, 321, 362, 281, 11, 51600], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1185, "seek": 310168, "start": 3126.3999999999996, "end": 3127.68, "text": " I think, spend our time on as well.", "tokens": [51600, 286, 519, 11, 3496, 527, 565, 322, 382, 731, 13, 51664], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1186, "seek": 310168, "start": 3127.68, "end": 3128.72, "text": " Yeah, yeah.", "tokens": [51664, 865, 11, 1338, 13, 51716], "temperature": 0.0, "avg_logprob": -0.10301876068115234, "compression_ratio": 1.6420664206642066, "no_speech_prob": 0.00030531713855452836}, {"id": 1187, "seek": 312872, "start": 3128.72, "end": 3131.4399999999996, "text": " Actually, I found the synthetic data thing really curious.", "tokens": [50364, 5135, 11, 286, 1352, 264, 23420, 1412, 551, 534, 6369, 13, 50500], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1188, "seek": 312872, "start": 3132.64, "end": 3134.64, "text": " I'm actually interested in why you don't think,", "tokens": [50560, 286, 478, 767, 3102, 294, 983, 291, 500, 380, 519, 11, 50660], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1189, "seek": 312872, "start": 3135.4399999999996, "end": 3136.72, "text": " like current models, it makes sense", "tokens": [50700, 411, 2190, 5245, 11, 309, 1669, 2020, 50764], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1190, "seek": 312872, "start": 3136.72, "end": 3138.08, "text": " why there might be an asymptote", "tokens": [50764, 983, 456, 1062, 312, 364, 35114, 1370, 50832], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1191, "seek": 312872, "start": 3138.08, "end": 3140.48, "text": " with just doing the synthetic data again and again.", "tokens": [50832, 365, 445, 884, 264, 23420, 1412, 797, 293, 797, 13, 50952], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1192, "seek": 312872, "start": 3140.48, "end": 3142.3199999999997, "text": " If it gets smarter and uses the kind of techniques", "tokens": [50952, 759, 309, 2170, 20294, 293, 4960, 264, 733, 295, 7512, 51044], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1193, "seek": 312872, "start": 3142.3199999999997, "end": 3144.3199999999997, "text": " you talk about in the paper or the blog post", "tokens": [51044, 291, 751, 466, 294, 264, 3035, 420, 264, 6968, 2183, 51144], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1194, "seek": 312872, "start": 3144.3199999999997, "end": 3146.8799999999997, "text": " that's coming out on the day this will be released", "tokens": [51144, 300, 311, 1348, 484, 322, 264, 786, 341, 486, 312, 4736, 51272], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1195, "seek": 312872, "start": 3146.8799999999997, "end": 3150.08, "text": " where it goes to the thought chain", "tokens": [51272, 689, 309, 1709, 281, 264, 1194, 5021, 51432], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1196, "seek": 312872, "start": 3150.08, "end": 3152.48, "text": " that is the most correct.", "tokens": [51432, 300, 307, 264, 881, 3006, 13, 51552], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1197, "seek": 312872, "start": 3153.04, "end": 3155.68, "text": " Why this wouldn't like lead to a loop", "tokens": [51580, 1545, 341, 2759, 380, 411, 1477, 281, 257, 6367, 51712], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1198, "seek": 312872, "start": 3155.68, "end": 3157.2, "text": " that, of course, it wouldn't be overnight,", "tokens": [51712, 300, 11, 295, 1164, 11, 309, 2759, 380, 312, 13935, 11, 51788], "temperature": 0.0, "avg_logprob": -0.141447151408476, "compression_ratio": 1.751700680272109, "no_speech_prob": 0.0010646876180544496}, {"id": 1199, "seek": 315720, "start": 3157.2, "end": 3158.7999999999997, "text": " but over many months or years of training,", "tokens": [50364, 457, 670, 867, 2493, 420, 924, 295, 3097, 11, 50444], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1200, "seek": 315720, "start": 3158.7999999999997, "end": 3160.3199999999997, "text": " potentially, with a smarter model,", "tokens": [50444, 7263, 11, 365, 257, 20294, 2316, 11, 50520], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1201, "seek": 315720, "start": 3160.3199999999997, "end": 3161.9199999999996, "text": " it gets smarter, makes better output,", "tokens": [50520, 309, 2170, 20294, 11, 1669, 1101, 5598, 11, 50600], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1202, "seek": 315720, "start": 3161.9199999999996, "end": 3163.04, "text": " gets smarter, and so forth.", "tokens": [50600, 2170, 20294, 11, 293, 370, 5220, 13, 50656], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1203, "seek": 315720, "start": 3165.2799999999997, "end": 3167.2, "text": " Well, I think it could within the parameter", "tokens": [50768, 1042, 11, 286, 519, 309, 727, 1951, 264, 13075, 50864], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1204, "seek": 315720, "start": 3167.2, "end": 3169.52, "text": " of whatever the model architecture is.", "tokens": [50864, 295, 2035, 264, 2316, 9482, 307, 13, 50980], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1205, "seek": 315720, "start": 3169.52, "end": 3173.9199999999996, "text": " It's just that at some level, I don't know,", "tokens": [50980, 467, 311, 445, 300, 412, 512, 1496, 11, 286, 500, 380, 458, 11, 51200], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1206, "seek": 315720, "start": 3174.56, "end": 3178.64, "text": " I think today is eight billion parameter models.", "tokens": [51232, 286, 519, 965, 307, 3180, 5218, 13075, 5245, 13, 51436], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1207, "seek": 315720, "start": 3179.2799999999997, "end": 3182.56, "text": " I just don't think you're going to be able to get to be as good", "tokens": [51468, 286, 445, 500, 380, 519, 291, 434, 516, 281, 312, 1075, 281, 483, 281, 312, 382, 665, 51632], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1208, "seek": 315720, "start": 3182.56, "end": 3186.16, "text": " as the state-of-the-art multi-hundred billion", "tokens": [51632, 382, 264, 1785, 12, 2670, 12, 3322, 12, 446, 4825, 12, 71, 3159, 5218, 51812], "temperature": 0.0, "avg_logprob": -0.13525442217217118, "compression_ratio": 1.7023809523809523, "no_speech_prob": 0.0015976516297087073}, {"id": 1209, "seek": 318616, "start": 3186.24, "end": 3188.72, "text": " parameter models that are incorporating new research", "tokens": [50368, 13075, 5245, 300, 366, 33613, 777, 2132, 50492], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1210, "seek": 318616, "start": 3188.72, "end": 3190.08, "text": " into the architecture itself.", "tokens": [50492, 666, 264, 9482, 2564, 13, 50560], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1211, "seek": 318616, "start": 3192.64, "end": 3194.16, "text": " But those will be open source as well, right?", "tokens": [50688, 583, 729, 486, 312, 1269, 4009, 382, 731, 11, 558, 30, 50764], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1212, "seek": 318616, "start": 3194.8799999999997, "end": 3196.16, "text": " Well, yeah, but I think that that's,", "tokens": [50800, 1042, 11, 1338, 11, 457, 286, 519, 300, 300, 311, 11, 50864], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1213, "seek": 318616, "start": 3197.2, "end": 3200.8799999999997, "text": " I mean, subject to all the questions", "tokens": [50916, 286, 914, 11, 3983, 281, 439, 264, 1651, 51100], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1214, "seek": 318616, "start": 3200.8799999999997, "end": 3201.7599999999998, "text": " that we just talked about.", "tokens": [51100, 300, 321, 445, 2825, 466, 13, 51144], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1215, "seek": 318616, "start": 3201.7599999999998, "end": 3203.92, "text": " Yes, I mean, we would hope that that'll be the case,", "tokens": [51144, 1079, 11, 286, 914, 11, 321, 576, 1454, 300, 300, 603, 312, 264, 1389, 11, 51252], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1216, "seek": 318616, "start": 3203.92, "end": 3206.8799999999997, "text": " but I think that at each point, I don't know,", "tokens": [51252, 457, 286, 519, 300, 412, 1184, 935, 11, 286, 500, 380, 458, 11, 51400], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1217, "seek": 318616, "start": 3206.8799999999997, "end": 3209.3599999999997, "text": " it's like when you're building software,", "tokens": [51400, 309, 311, 411, 562, 291, 434, 2390, 4722, 11, 51524], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1218, "seek": 318616, "start": 3209.3599999999997, "end": 3211.92, "text": " there's like a ton of stuff that you can do with software,", "tokens": [51524, 456, 311, 411, 257, 2952, 295, 1507, 300, 291, 393, 360, 365, 4722, 11, 51652], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1219, "seek": 318616, "start": 3211.92, "end": 3213.8399999999997, "text": " but then at some level, you're constrained", "tokens": [51652, 457, 550, 412, 512, 1496, 11, 291, 434, 38901, 51748], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1220, "seek": 318616, "start": 3213.8399999999997, "end": 3215.92, "text": " by the chips that it's running on.", "tokens": [51748, 538, 264, 11583, 300, 309, 311, 2614, 322, 13, 51852], "temperature": 0.0, "avg_logprob": -0.1379177066641794, "compression_ratio": 1.726962457337884, "no_speech_prob": 0.0012447354383766651}, {"id": 1221, "seek": 321616, "start": 3216.24, "end": 3219.6, "text": " Right? So there are always going to be different", "tokens": [50368, 1779, 30, 407, 456, 366, 1009, 516, 281, 312, 819, 50536], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1222, "seek": 321616, "start": 3220.3999999999996, "end": 3221.68, "text": " physical constraints.", "tokens": [50576, 4001, 18491, 13, 50640], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1223, "seek": 321616, "start": 3221.68, "end": 3224.96, "text": " And it's like how big are the models is going to be constrained", "tokens": [50640, 400, 309, 311, 411, 577, 955, 366, 264, 5245, 307, 516, 281, 312, 38901, 50804], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1224, "seek": 321616, "start": 3224.96, "end": 3229.8399999999997, "text": " by how much energy you can get and use for inference.", "tokens": [50804, 538, 577, 709, 2281, 291, 393, 483, 293, 764, 337, 38253, 13, 51048], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1225, "seek": 321616, "start": 3230.7999999999997, "end": 3236.16, "text": " So I guess I'm simultaneously very optimistic", "tokens": [51096, 407, 286, 2041, 286, 478, 16561, 588, 19397, 51364], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1226, "seek": 321616, "start": 3236.16, "end": 3238.16, "text": " that this stuff will continue to improve quickly.", "tokens": [51364, 300, 341, 1507, 486, 2354, 281, 3470, 2661, 13, 51464], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1227, "seek": 321616, "start": 3238.96, "end": 3245.6, "text": " And also a little more measured than I think", "tokens": [51504, 400, 611, 257, 707, 544, 12690, 813, 286, 519, 51836], "temperature": 0.0, "avg_logprob": -0.15829494853078582, "compression_ratio": 1.5373831775700935, "no_speech_prob": 0.0002780095674097538}, {"id": 1228, "seek": 324560, "start": 3245.68, "end": 3249.52, "text": " some people are about kind of it's,", "tokens": [50368, 512, 561, 366, 466, 733, 295, 309, 311, 11, 50560], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1229, "seek": 324560, "start": 3250.48, "end": 3252.7999999999997, "text": " I just don't think the runaway case", "tokens": [50608, 286, 445, 500, 380, 519, 264, 1190, 10318, 1389, 50724], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1230, "seek": 324560, "start": 3252.7999999999997, "end": 3255.04, "text": " is like a particularly likely one.", "tokens": [50724, 307, 411, 257, 4098, 3700, 472, 13, 50836], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1231, "seek": 324560, "start": 3256.08, "end": 3258.3199999999997, "text": " I think it makes sense to keep your options open.", "tokens": [50888, 286, 519, 309, 1669, 2020, 281, 1066, 428, 3956, 1269, 13, 51000], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1232, "seek": 324560, "start": 3258.3199999999997, "end": 3259.44, "text": " Like there's so much we don't know.", "tokens": [51000, 1743, 456, 311, 370, 709, 321, 500, 380, 458, 13, 51056], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1233, "seek": 324560, "start": 3260.48, "end": 3262.08, "text": " There's a case in which like it's really important", "tokens": [51108, 821, 311, 257, 1389, 294, 597, 411, 309, 311, 534, 1021, 51188], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1234, "seek": 324560, "start": 3262.08, "end": 3263.04, "text": " to keep the balance of power.", "tokens": [51188, 281, 1066, 264, 4772, 295, 1347, 13, 51236], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1235, "seek": 324560, "start": 3263.04, "end": 3265.2, "text": " So when nobody becomes like a technology or a dictator,", "tokens": [51236, 407, 562, 5079, 3643, 411, 257, 2899, 420, 257, 42852, 11, 51344], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1236, "seek": 324560, "start": 3265.2, "end": 3266.48, "text": " there's a case in which like,", "tokens": [51344, 456, 311, 257, 1389, 294, 597, 411, 11, 51408], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1237, "seek": 324560, "start": 3266.48, "end": 3268.64, "text": " you don't want to open source the architecture", "tokens": [51408, 291, 500, 380, 528, 281, 1269, 4009, 264, 9482, 51516], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1238, "seek": 324560, "start": 3268.64, "end": 3272.24, "text": " because like China can use it to catch up to America's AIs", "tokens": [51516, 570, 411, 3533, 393, 764, 309, 281, 3745, 493, 281, 3374, 311, 316, 6802, 51696], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1239, "seek": 324560, "start": 3272.24, "end": 3273.8399999999997, "text": " and like there is an intelligence explosion", "tokens": [51696, 293, 411, 456, 307, 364, 7599, 15673, 51776], "temperature": 0.0, "avg_logprob": -0.14947221605040187, "compression_ratio": 1.7431506849315068, "no_speech_prob": 0.0015478301793336868}, {"id": 1240, "seek": 327384, "start": 3273.92, "end": 3274.8, "text": " and they like win that.", "tokens": [50368, 293, 436, 411, 1942, 300, 13, 50412], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1241, "seek": 327384, "start": 3275.84, "end": 3277.1200000000003, "text": " Yeah, a lot of things are impossible.", "tokens": [50464, 865, 11, 257, 688, 295, 721, 366, 6243, 13, 50528], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1242, "seek": 327384, "start": 3277.1200000000003, "end": 3278.6400000000003, "text": " Just like keeping your options open,", "tokens": [50528, 1449, 411, 5145, 428, 3956, 1269, 11, 50604], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1243, "seek": 327384, "start": 3278.6400000000003, "end": 3280.8, "text": " considering all of them seems reasonable.", "tokens": [50604, 8079, 439, 295, 552, 2544, 10585, 13, 50712], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1244, "seek": 327384, "start": 3280.8, "end": 3280.96, "text": " Yeah.", "tokens": [50712, 865, 13, 50720], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1245, "seek": 327384, "start": 3282.48, "end": 3283.52, "text": " Let's talk about some other things.", "tokens": [50796, 961, 311, 751, 466, 512, 661, 721, 13, 50848], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1246, "seek": 327384, "start": 3283.52, "end": 3284.08, "text": " Go for it.", "tokens": [50848, 1037, 337, 309, 13, 50876], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1247, "seek": 327384, "start": 3284.08, "end": 3288.56, "text": " Okay. Metaverse, what time period in human history", "tokens": [50876, 1033, 13, 6377, 64, 4308, 11, 437, 565, 2896, 294, 1952, 2503, 51100], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1248, "seek": 327384, "start": 3288.56, "end": 3290.6400000000003, "text": " would you be most interested in going into?", "tokens": [51100, 576, 291, 312, 881, 3102, 294, 516, 666, 30, 51204], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1249, "seek": 327384, "start": 3290.6400000000003, "end": 3292.6400000000003, "text": " A 100,000 BCE to now.", "tokens": [51204, 316, 2319, 11, 1360, 49369, 281, 586, 13, 51304], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1250, "seek": 327384, "start": 3292.6400000000003, "end": 3293.6800000000003, "text": " You just want to see what it was like.", "tokens": [51304, 509, 445, 528, 281, 536, 437, 309, 390, 411, 13, 51356], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1251, "seek": 327384, "start": 3293.6800000000003, "end": 3294.7200000000003, "text": " Well, that's through the past.", "tokens": [51356, 1042, 11, 300, 311, 807, 264, 1791, 13, 51408], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1252, "seek": 327384, "start": 3294.7200000000003, "end": 3295.1200000000003, "text": " Huh?", "tokens": [51408, 8063, 30, 51428], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1253, "seek": 327384, "start": 3295.1200000000003, "end": 3295.84, "text": " It has to be the past.", "tokens": [51428, 467, 575, 281, 312, 264, 1791, 13, 51464], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1254, "seek": 327384, "start": 3295.84, "end": 3296.8, "text": " Oh yeah, it has to be the past.", "tokens": [51464, 876, 1338, 11, 309, 575, 281, 312, 264, 1791, 13, 51512], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1255, "seek": 327384, "start": 3301.76, "end": 3302.4, "text": " I don't know.", "tokens": [51760, 286, 500, 380, 458, 13, 51792], "temperature": 0.0, "avg_logprob": -0.20944190669704127, "compression_ratio": 1.592982456140351, "no_speech_prob": 0.003821625607088208}, {"id": 1256, "seek": 330240, "start": 3302.4, "end": 3304.4, "text": " I mean, I have the periods of time that I'm interested.", "tokens": [50364, 286, 914, 11, 286, 362, 264, 13804, 295, 565, 300, 286, 478, 3102, 13, 50464], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1257, "seek": 330240, "start": 3304.4, "end": 3306.2400000000002, "text": " I mean, I'm really interested in American history", "tokens": [50464, 286, 914, 11, 286, 478, 534, 3102, 294, 2665, 2503, 50556], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1258, "seek": 330240, "start": 3306.2400000000002, "end": 3310.32, "text": " and classical history and I'm really interested", "tokens": [50556, 293, 13735, 2503, 293, 286, 478, 534, 3102, 50760], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1259, "seek": 330240, "start": 3310.32, "end": 3311.52, "text": " in the history of science too.", "tokens": [50760, 294, 264, 2503, 295, 3497, 886, 13, 50820], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1260, "seek": 330240, "start": 3311.52, "end": 3315.92, "text": " So I actually think seeing and trying to understand more", "tokens": [50820, 407, 286, 767, 519, 2577, 293, 1382, 281, 1223, 544, 51040], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1261, "seek": 330240, "start": 3318.7200000000003, "end": 3320.96, "text": " about how some of the big advances came about.", "tokens": [51180, 466, 577, 512, 295, 264, 955, 25297, 1361, 466, 13, 51292], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1262, "seek": 330240, "start": 3320.96, "end": 3324.4, "text": " I mean, all we have are like somewhat limited writings", "tokens": [51292, 286, 914, 11, 439, 321, 362, 366, 411, 8344, 5567, 30083, 51464], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1263, "seek": 330240, "start": 3324.4, "end": 3325.92, "text": " about some of that stuff.", "tokens": [51464, 466, 512, 295, 300, 1507, 13, 51540], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1264, "seek": 330240, "start": 3325.92, "end": 3327.52, "text": " I'm not sure the metaverse is going to let you do that", "tokens": [51540, 286, 478, 406, 988, 264, 19616, 4308, 307, 516, 281, 718, 291, 360, 300, 51620], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1265, "seek": 330240, "start": 3327.52, "end": 3329.44, "text": " because I mean, it's, you know, we can't,", "tokens": [51620, 570, 286, 914, 11, 309, 311, 11, 291, 458, 11, 321, 393, 380, 11, 51716], "temperature": 0.0, "avg_logprob": -0.13775413755386595, "compression_ratio": 1.841897233201581, "no_speech_prob": 0.00050328578799963}, {"id": 1266, "seek": 332944, "start": 3329.52, "end": 3332.64, "text": " it's going to be hard to kind of go back in time", "tokens": [50368, 309, 311, 516, 281, 312, 1152, 281, 733, 295, 352, 646, 294, 565, 50524], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1267, "seek": 332944, "start": 3332.64, "end": 3334.56, "text": " for things that we don't have records of.", "tokens": [50524, 337, 721, 300, 321, 500, 380, 362, 7724, 295, 13, 50620], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1268, "seek": 332944, "start": 3334.56, "end": 3339.04, "text": " But I'm actually not sure that going back in time", "tokens": [50620, 583, 286, 478, 767, 406, 988, 300, 516, 646, 294, 565, 50844], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1269, "seek": 332944, "start": 3339.04, "end": 3341.52, "text": " is going to be that important thing for them.", "tokens": [50844, 307, 516, 281, 312, 300, 1021, 551, 337, 552, 13, 50968], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1270, "seek": 332944, "start": 3341.52, "end": 3343.44, "text": " I mean, I think it's going to be cool for history classes", "tokens": [50968, 286, 914, 11, 286, 519, 309, 311, 516, 281, 312, 1627, 337, 2503, 5359, 51064], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1271, "seek": 332944, "start": 3343.44, "end": 3346.96, "text": " and stuff, but that's probably not the use case", "tokens": [51064, 293, 1507, 11, 457, 300, 311, 1391, 406, 264, 764, 1389, 51240], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1272, "seek": 332944, "start": 3346.96, "end": 3349.6, "text": " that I'm most excited about for the metaverse overall.", "tokens": [51240, 300, 286, 478, 881, 2919, 466, 337, 264, 19616, 4308, 4787, 13, 51372], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1273, "seek": 332944, "start": 3349.6, "end": 3352.96, "text": " I mean, the main thing is just the ability", "tokens": [51372, 286, 914, 11, 264, 2135, 551, 307, 445, 264, 3485, 51540], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1274, "seek": 332944, "start": 3352.96, "end": 3355.28, "text": " to feel present with people no matter where you are.", "tokens": [51540, 281, 841, 1974, 365, 561, 572, 1871, 689, 291, 366, 13, 51656], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1275, "seek": 332944, "start": 3355.28, "end": 3356.64, "text": " I think that's going to be killer.", "tokens": [51656, 286, 519, 300, 311, 516, 281, 312, 13364, 13, 51724], "temperature": 0.0, "avg_logprob": -0.09038292017198146, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0017005651025101542}, {"id": 1276, "seek": 335664, "start": 3356.64, "end": 3361.3599999999997, "text": " I mean, there's, I mean, in the AI conversation", "tokens": [50364, 286, 914, 11, 456, 311, 11, 286, 914, 11, 294, 264, 7318, 3761, 50600], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1277, "seek": 335664, "start": 3361.3599999999997, "end": 3364.56, "text": " that we were having, I mean, it's, you know,", "tokens": [50600, 300, 321, 645, 1419, 11, 286, 914, 11, 309, 311, 11, 291, 458, 11, 50760], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1278, "seek": 335664, "start": 3364.56, "end": 3366.64, "text": " so much of it is about physical constraints", "tokens": [50760, 370, 709, 295, 309, 307, 466, 4001, 18491, 50864], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1279, "seek": 335664, "start": 3366.64, "end": 3369.12, "text": " that kind of underlie all of this, right?", "tokens": [50864, 300, 733, 295, 833, 6302, 439, 295, 341, 11, 558, 30, 50988], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1280, "seek": 335664, "start": 3369.12, "end": 3372.3199999999997, "text": " And you want to move, I mean, one lesson of technology", "tokens": [50988, 400, 291, 528, 281, 1286, 11, 286, 914, 11, 472, 6898, 295, 2899, 51148], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1281, "seek": 335664, "start": 3372.3199999999997, "end": 3375.6, "text": " is you want to move things from the physical constraint realm", "tokens": [51148, 307, 291, 528, 281, 1286, 721, 490, 264, 4001, 25534, 15355, 51312], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1282, "seek": 335664, "start": 3375.6, "end": 3377.2, "text": " into software as much as possible", "tokens": [51312, 666, 4722, 382, 709, 382, 1944, 51392], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1283, "seek": 335664, "start": 3377.2, "end": 3381.12, "text": " because software is so much easier to build and evolve.", "tokens": [51392, 570, 4722, 307, 370, 709, 3571, 281, 1322, 293, 16693, 13, 51588], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1284, "seek": 335664, "start": 3381.12, "end": 3382.7999999999997, "text": " And like you can democratize it more", "tokens": [51588, 400, 411, 291, 393, 37221, 1125, 309, 544, 51672], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1285, "seek": 335664, "start": 3382.7999999999997, "end": 3385.52, "text": " because like not everyone is going to have a data center,", "tokens": [51672, 570, 411, 406, 1518, 307, 516, 281, 362, 257, 1412, 3056, 11, 51808], "temperature": 0.0, "avg_logprob": -0.0893552543580994, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.0017543366411700845}, {"id": 1286, "seek": 338552, "start": 3385.52, "end": 3388.8, "text": " but like a lot of people can kind of write code", "tokens": [50364, 457, 411, 257, 688, 295, 561, 393, 733, 295, 2464, 3089, 50528], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1287, "seek": 338552, "start": 3388.8, "end": 3390.88, "text": " and take open source code and modify it.", "tokens": [50528, 293, 747, 1269, 4009, 3089, 293, 16927, 309, 13, 50632], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1288, "seek": 338552, "start": 3393.28, "end": 3395.84, "text": " The metaverse version of this is I think", "tokens": [50752, 440, 19616, 4308, 3037, 295, 341, 307, 286, 519, 50880], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1289, "seek": 338552, "start": 3395.84, "end": 3398.48, "text": " enabling realistic digital presence", "tokens": [50880, 23148, 12465, 4562, 6814, 51012], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1290, "seek": 338552, "start": 3399.6, "end": 3403.7599999999998, "text": " is going to be just an absolutely huge difference", "tokens": [51068, 307, 516, 281, 312, 445, 364, 3122, 2603, 2649, 51276], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1291, "seek": 338552, "start": 3403.7599999999998, "end": 3408.0, "text": " for making it so that people don't feel", "tokens": [51276, 337, 1455, 309, 370, 300, 561, 500, 380, 841, 51488], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1292, "seek": 338552, "start": 3408.0, "end": 3409.84, "text": " like they have to physically be together", "tokens": [51488, 411, 436, 362, 281, 9762, 312, 1214, 51580], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1293, "seek": 338552, "start": 3409.84, "end": 3410.88, "text": " for as many things.", "tokens": [51580, 337, 382, 867, 721, 13, 51632], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1294, "seek": 338552, "start": 3411.52, "end": 3412.72, "text": " Now, I mean, I think that there are going to be things", "tokens": [51664, 823, 11, 286, 914, 11, 286, 519, 300, 456, 366, 516, 281, 312, 721, 51724], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1295, "seek": 338552, "start": 3412.72, "end": 3414.24, "text": " that are better about being physically together.", "tokens": [51724, 300, 366, 1101, 466, 885, 9762, 1214, 13, 51800], "temperature": 0.0, "avg_logprob": -0.09747090429629919, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.00047280816943384707}, {"id": 1296, "seek": 341552, "start": 3416.24, "end": 3418.0, "text": " So it's not, I mean, these things aren't binary,", "tokens": [50400, 407, 309, 311, 406, 11, 286, 914, 11, 613, 721, 3212, 380, 17434, 11, 50488], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1297, "seek": 341552, "start": 3418.0, "end": 3418.96, "text": " it's not going to be like, okay,", "tokens": [50488, 309, 311, 406, 516, 281, 312, 411, 11, 1392, 11, 50536], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1298, "seek": 341552, "start": 3418.96, "end": 3420.96, "text": " now it's, you don't need to do that anymore.", "tokens": [50536, 586, 309, 311, 11, 291, 500, 380, 643, 281, 360, 300, 3602, 13, 50636], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1299, "seek": 341552, "start": 3420.96, "end": 3427.2, "text": " But overall, I mean, I think that this,", "tokens": [50636, 583, 4787, 11, 286, 914, 11, 286, 519, 300, 341, 11, 50948], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1300, "seek": 341552, "start": 3427.2, "end": 3429.7599999999998, "text": " it's just going to be really powerful for socializing,", "tokens": [50948, 309, 311, 445, 516, 281, 312, 534, 4005, 337, 2093, 3319, 11, 51076], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1301, "seek": 341552, "start": 3429.7599999999998, "end": 3432.64, "text": " for feeling connected with people, for working,", "tokens": [51076, 337, 2633, 4582, 365, 561, 11, 337, 1364, 11, 51220], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1302, "seek": 341552, "start": 3433.6, "end": 3438.0, "text": " for, I don't know, parts of industry, for medicine,", "tokens": [51268, 337, 11, 286, 500, 380, 458, 11, 3166, 295, 3518, 11, 337, 7195, 11, 51488], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1303, "seek": 341552, "start": 3438.0, "end": 3439.92, "text": " for like so many things.", "tokens": [51488, 337, 411, 370, 867, 721, 13, 51584], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1304, "seek": 341552, "start": 3439.92, "end": 3441.04, "text": " I want to go back to something you said", "tokens": [51584, 286, 528, 281, 352, 646, 281, 746, 291, 848, 51640], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1305, "seek": 341552, "start": 3441.04, "end": 3442.24, "text": " at the beginning of the conversation", "tokens": [51640, 412, 264, 2863, 295, 264, 3761, 51700], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1306, "seek": 341552, "start": 3442.24, "end": 3444.96, "text": " where you didn't sell the company for a billion dollars", "tokens": [51700, 689, 291, 994, 380, 3607, 264, 2237, 337, 257, 5218, 3808, 51836], "temperature": 0.0, "avg_logprob": -0.10723337681173421, "compression_ratio": 1.7481751824817517, "no_speech_prob": 0.0005527173052541912}, {"id": 1307, "seek": 344496, "start": 3444.96, "end": 3446.64, "text": " and like the metaverse, you knew we were going to do this", "tokens": [50364, 293, 411, 264, 19616, 4308, 11, 291, 2586, 321, 645, 516, 281, 360, 341, 50448], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1308, "seek": 344496, "start": 3446.64, "end": 3449.52, "text": " even though the market was hammering you for it.", "tokens": [50448, 754, 1673, 264, 2142, 390, 13017, 278, 291, 337, 309, 13, 50592], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1309, "seek": 344496, "start": 3449.52, "end": 3450.96, "text": " And then I'm actually curious,", "tokens": [50592, 400, 550, 286, 478, 767, 6369, 11, 50664], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1310, "seek": 344496, "start": 3450.96, "end": 3452.7200000000003, "text": " like what is the source of that edge?", "tokens": [50664, 411, 437, 307, 264, 4009, 295, 300, 4691, 30, 50752], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1311, "seek": 344496, "start": 3452.7200000000003, "end": 3455.28, "text": " And you said like, oh, values, I have this intuition,", "tokens": [50752, 400, 291, 848, 411, 11, 1954, 11, 4190, 11, 286, 362, 341, 24002, 11, 50880], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1312, "seek": 344496, "start": 3455.28, "end": 3456.8, "text": " but like everybody says that, right?", "tokens": [50880, 457, 411, 2201, 1619, 300, 11, 558, 30, 50956], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1313, "seek": 344496, "start": 3457.36, "end": 3459.2, "text": " If you had to say something that's specific to you,", "tokens": [50984, 759, 291, 632, 281, 584, 746, 300, 311, 2685, 281, 291, 11, 51076], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1314, "seek": 344496, "start": 3459.2, "end": 3461.2, "text": " what is, how would you express what that is?", "tokens": [51076, 437, 307, 11, 577, 576, 291, 5109, 437, 300, 307, 30, 51176], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1315, "seek": 344496, "start": 3461.2, "end": 3463.28, "text": " Like why were you so convinced about the metaverse?", "tokens": [51176, 1743, 983, 645, 291, 370, 12561, 466, 264, 19616, 4308, 30, 51280], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1316, "seek": 344496, "start": 3469.92, "end": 3471.44, "text": " Well, I think that those are different questions.", "tokens": [51612, 1042, 11, 286, 519, 300, 729, 366, 819, 1651, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1313773606174676, "compression_ratio": 1.6726618705035972, "no_speech_prob": 0.0022506052628159523}, {"id": 1317, "seek": 347144, "start": 3471.44, "end": 3476.56, "text": " So what, I mean, what are the things that kind of power me?", "tokens": [50364, 407, 437, 11, 286, 914, 11, 437, 366, 264, 721, 300, 733, 295, 1347, 385, 30, 50620], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1318, "seek": 347144, "start": 3478.64, "end": 3479.92, "text": " I think we've talked about a bunch of things.", "tokens": [50724, 286, 519, 321, 600, 2825, 466, 257, 3840, 295, 721, 13, 50788], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1319, "seek": 347144, "start": 3479.92, "end": 3483.2000000000003, "text": " So it's, I mean, I just really like building things.", "tokens": [50788, 407, 309, 311, 11, 286, 914, 11, 286, 445, 534, 411, 2390, 721, 13, 50952], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1320, "seek": 347144, "start": 3485.2000000000003, "end": 3489.28, "text": " I specifically like building things around how people communicate", "tokens": [51052, 286, 4682, 411, 2390, 721, 926, 577, 561, 7890, 51256], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1321, "seek": 347144, "start": 3489.28, "end": 3491.68, "text": " and sort of understanding how people express themselves", "tokens": [51256, 293, 1333, 295, 3701, 577, 561, 5109, 2969, 51376], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1322, "seek": 347144, "start": 3491.68, "end": 3492.8, "text": " and how people work, right?", "tokens": [51376, 293, 577, 561, 589, 11, 558, 30, 51432], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1323, "seek": 347144, "start": 3492.8, "end": 3494.0, "text": " And when I was in college, I was,", "tokens": [51432, 400, 562, 286, 390, 294, 3859, 11, 286, 390, 11, 51492], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1324, "seek": 347144, "start": 3494.0, "end": 3496.56, "text": " I was studying computer science and psychology.", "tokens": [51492, 286, 390, 7601, 3820, 3497, 293, 15105, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1325, "seek": 347144, "start": 3496.56, "end": 3497.76, "text": " I think a lot of other people in the industry", "tokens": [51620, 286, 519, 257, 688, 295, 661, 561, 294, 264, 3518, 51680], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1326, "seek": 347144, "start": 3497.76, "end": 3499.44, "text": " started studying computer science, right?", "tokens": [51680, 1409, 7601, 3820, 3497, 11, 558, 30, 51764], "temperature": 0.0, "avg_logprob": -0.1520336651411213, "compression_ratio": 1.8384615384615384, "no_speech_prob": 0.0012064400361850858}, {"id": 1327, "seek": 349944, "start": 3499.44, "end": 3503.6, "text": " So it's always been sort of the intersection", "tokens": [50364, 407, 309, 311, 1009, 668, 1333, 295, 264, 15236, 50572], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1328, "seek": 349944, "start": 3503.6, "end": 3505.12, "text": " of those two things for me.", "tokens": [50572, 295, 729, 732, 721, 337, 385, 13, 50648], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1329, "seek": 349944, "start": 3505.12, "end": 3511.92, "text": " But I think it's also sort of this like really deep drive.", "tokens": [50648, 583, 286, 519, 309, 311, 611, 1333, 295, 341, 411, 534, 2452, 3332, 13, 50988], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1330, "seek": 349944, "start": 3511.92, "end": 3515.76, "text": " I don't know how to explain it, but I just feel like in,", "tokens": [50988, 286, 500, 380, 458, 577, 281, 2903, 309, 11, 457, 286, 445, 841, 411, 294, 11, 51180], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1331, "seek": 349944, "start": 3515.76, "end": 3519.28, "text": " like constitutionally, like I'm doing something wrong", "tokens": [51180, 411, 11937, 379, 11, 411, 286, 478, 884, 746, 2085, 51356], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1332, "seek": 349944, "start": 3519.28, "end": 3521.92, "text": " if I'm not building something new, right?", "tokens": [51356, 498, 286, 478, 406, 2390, 746, 777, 11, 558, 30, 51488], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1333, "seek": 349944, "start": 3521.92, "end": 3526.56, "text": " And so I think that there's like", "tokens": [51488, 400, 370, 286, 519, 300, 456, 311, 411, 51720], "temperature": 0.0, "avg_logprob": -0.10129565335391613, "compression_ratio": 1.6173469387755102, "no_speech_prob": 0.0009109462262131274}, {"id": 1334, "seek": 352944, "start": 3529.76, "end": 3532.48, "text": " even when we're putting together the business case for,", "tokens": [50380, 754, 562, 321, 434, 3372, 1214, 264, 1606, 1389, 337, 11, 50516], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1335, "seek": 352944, "start": 3533.44, "end": 3537.36, "text": " you know, investing like $100 billion in AI", "tokens": [50564, 291, 458, 11, 10978, 411, 1848, 6879, 5218, 294, 7318, 50760], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1336, "seek": 352944, "start": 3537.36, "end": 3539.36, "text": " or some huge amount in the metaverse.", "tokens": [50760, 420, 512, 2603, 2372, 294, 264, 19616, 4308, 13, 50860], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1337, "seek": 352944, "start": 3539.36, "end": 3541.52, "text": " So it's like, yeah, I mean, we have plans", "tokens": [50860, 407, 309, 311, 411, 11, 1338, 11, 286, 914, 11, 321, 362, 5482, 50968], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1338, "seek": 352944, "start": 3541.52, "end": 3543.84, "text": " that I think make it pretty clear that if our stuff works,", "tokens": [50968, 300, 286, 519, 652, 309, 1238, 1850, 300, 498, 527, 1507, 1985, 11, 51084], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1339, "seek": 352944, "start": 3543.84, "end": 3545.36, "text": " it'll be a good investment.", "tokens": [51084, 309, 603, 312, 257, 665, 6078, 13, 51160], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1340, "seek": 352944, "start": 3545.36, "end": 3548.32, "text": " But like, you can't know for certain from the outset.", "tokens": [51160, 583, 411, 11, 291, 393, 380, 458, 337, 1629, 490, 264, 44618, 13, 51308], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1341, "seek": 352944, "start": 3548.96, "end": 3552.0, "text": " And there's all these arguments that people have,", "tokens": [51340, 400, 456, 311, 439, 613, 12869, 300, 561, 362, 11, 51492], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1342, "seek": 352944, "start": 3552.0, "end": 3554.88, "text": " you know, whether it's like, you know, with advisors", "tokens": [51492, 291, 458, 11, 1968, 309, 311, 411, 11, 291, 458, 11, 365, 29136, 51636], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1343, "seek": 352944, "start": 3554.88, "end": 3557.68, "text": " or different folks, it's like, well, how, how could you,", "tokens": [51636, 420, 819, 4024, 11, 309, 311, 411, 11, 731, 11, 577, 11, 577, 727, 291, 11, 51776], "temperature": 0.0, "avg_logprob": -0.10908889074395173, "compression_ratio": 1.696113074204947, "no_speech_prob": 0.0029806471429765224}, {"id": 1344, "seek": 355768, "start": 3557.7599999999998, "end": 3560.3199999999997, "text": " like it's how are you confident enough to do this?", "tokens": [50368, 411, 309, 311, 577, 366, 291, 6679, 1547, 281, 360, 341, 30, 50496], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1345, "seek": 355768, "start": 3560.3199999999997, "end": 3564.8799999999997, "text": " And it's like, well, the day I stop trying to build new things,", "tokens": [50496, 400, 309, 311, 411, 11, 731, 11, 264, 786, 286, 1590, 1382, 281, 1322, 777, 721, 11, 50724], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1346, "seek": 355768, "start": 3565.52, "end": 3566.24, "text": " I'm just done.", "tokens": [50756, 286, 478, 445, 1096, 13, 50792], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1347, "seek": 355768, "start": 3566.24, "end": 3568.24, "text": " I'm going to go build new things somewhere else, right?", "tokens": [50792, 286, 478, 516, 281, 352, 1322, 777, 721, 4079, 1646, 11, 558, 30, 50892], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1348, "seek": 355768, "start": 3568.24, "end": 3572.8799999999997, "text": " It's like, it's like, it is, I'm fundamentally incapable", "tokens": [50892, 467, 311, 411, 11, 309, 311, 411, 11, 309, 307, 11, 286, 478, 17879, 44174, 51124], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1349, "seek": 355768, "start": 3573.52, "end": 3578.56, "text": " of running something or in my own life", "tokens": [51156, 295, 2614, 746, 420, 294, 452, 1065, 993, 51408], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1350, "seek": 355768, "start": 3578.56, "end": 3581.52, "text": " and like not trying to build new things", "tokens": [51408, 293, 411, 406, 1382, 281, 1322, 777, 721, 51556], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1351, "seek": 355768, "start": 3581.52, "end": 3582.8799999999997, "text": " that I think are interesting.", "tokens": [51556, 300, 286, 519, 366, 1880, 13, 51624], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1352, "seek": 355768, "start": 3582.8799999999997, "end": 3585.04, "text": " It's like, that's not even a question for me, right?", "tokens": [51624, 467, 311, 411, 11, 300, 311, 406, 754, 257, 1168, 337, 385, 11, 558, 30, 51732], "temperature": 0.0, "avg_logprob": -0.10160169681581128, "compression_ratio": 1.8198198198198199, "no_speech_prob": 0.0009109825477935374}, {"id": 1353, "seek": 358504, "start": 3585.04, "end": 3587.68, "text": " It's like whether, like whether we're going to go take a swing", "tokens": [50364, 467, 311, 411, 1968, 11, 411, 1968, 321, 434, 516, 281, 352, 747, 257, 11173, 50496], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1354, "seek": 358504, "start": 3587.68, "end": 3589.04, "text": " at like building the next thing.", "tokens": [50496, 412, 411, 2390, 264, 958, 551, 13, 50564], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1355, "seek": 358504, "start": 3589.04, "end": 3592.96, "text": " It's like, it's like, I'm just incapable of not doing that.", "tokens": [50564, 467, 311, 411, 11, 309, 311, 411, 11, 286, 478, 445, 44174, 295, 406, 884, 300, 13, 50760], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1356, "seek": 358504, "start": 3594.8, "end": 3599.7599999999998, "text": " And I don't know, and I'm kind of like this", "tokens": [50852, 400, 286, 500, 380, 458, 11, 293, 286, 478, 733, 295, 411, 341, 51100], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1357, "seek": 358504, "start": 3599.7599999999998, "end": 3601.7599999999998, "text": " in like all the different aspects of my life, right?", "tokens": [51100, 294, 411, 439, 264, 819, 7270, 295, 452, 993, 11, 558, 30, 51200], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1358, "seek": 358504, "start": 3601.7599999999998, "end": 3604.32, "text": " It's like we built this like, you know,", "tokens": [51200, 467, 311, 411, 321, 3094, 341, 411, 11, 291, 458, 11, 51328], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1359, "seek": 358504, "start": 3604.32, "end": 3608.72, "text": " family built this ranch in Kauai and like, I just like", "tokens": [51328, 1605, 3094, 341, 22883, 294, 591, 1459, 1301, 293, 411, 11, 286, 445, 411, 51548], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1360, "seek": 358504, "start": 3610.24, "end": 3611.84, "text": " worked to like design all these buildings.", "tokens": [51624, 2732, 281, 411, 1715, 439, 613, 7446, 13, 51704], "temperature": 0.0, "avg_logprob": -0.16660356936247453, "compression_ratio": 1.8055555555555556, "no_speech_prob": 0.002322952263057232}, {"id": 1361, "seek": 361184, "start": 3611.84, "end": 3615.2000000000003, "text": " I'm like kind of trying to like, we started raising cattle", "tokens": [50364, 286, 478, 411, 733, 295, 1382, 281, 411, 11, 321, 1409, 11225, 19992, 50532], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1362, "seek": 361184, "start": 3615.2000000000003, "end": 3616.56, "text": " and I'm like, all right, well, I want to make", "tokens": [50532, 293, 286, 478, 411, 11, 439, 558, 11, 731, 11, 286, 528, 281, 652, 50600], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1363, "seek": 361184, "start": 3616.56, "end": 3618.1600000000003, "text": " like the best cattle in the world, right?", "tokens": [50600, 411, 264, 1151, 19992, 294, 264, 1002, 11, 558, 30, 50680], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1364, "seek": 361184, "start": 3618.1600000000003, "end": 3620.2400000000002, "text": " So it's like, how do we like, how do we architect this", "tokens": [50680, 407, 309, 311, 411, 11, 577, 360, 321, 411, 11, 577, 360, 321, 6331, 341, 50784], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1365, "seek": 361184, "start": 3620.2400000000002, "end": 3622.56, "text": " so that way we can figure this out and like and build", "tokens": [50784, 370, 300, 636, 321, 393, 2573, 341, 484, 293, 411, 293, 1322, 50900], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1366, "seek": 361184, "start": 3623.2000000000003, "end": 3625.2000000000003, "text": " and call the stuff up that we need to try to do that?", "tokens": [50932, 293, 818, 264, 1507, 493, 300, 321, 643, 281, 853, 281, 360, 300, 30, 51032], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1367, "seek": 361184, "start": 3626.6400000000003, "end": 3627.84, "text": " So I don't know, that's me.", "tokens": [51104, 407, 286, 500, 380, 458, 11, 300, 311, 385, 13, 51164], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1368, "seek": 361184, "start": 3629.6000000000004, "end": 3630.8, "text": " What was the other part of the question?", "tokens": [51252, 708, 390, 264, 661, 644, 295, 264, 1168, 30, 51312], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1369, "seek": 361184, "start": 3632.08, "end": 3634.88, "text": " Look, Metta is just a really amazing tech company, right?", "tokens": [51376, 2053, 11, 6377, 1328, 307, 445, 257, 534, 2243, 7553, 2237, 11, 558, 30, 51516], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1370, "seek": 361184, "start": 3634.88, "end": 3636.96, "text": " They have all these great software engineers", "tokens": [51516, 814, 362, 439, 613, 869, 4722, 11955, 51620], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1371, "seek": 361184, "start": 3636.96, "end": 3639.84, "text": " and even they work with Stripe to handle payments.", "tokens": [51620, 293, 754, 436, 589, 365, 20390, 494, 281, 4813, 14348, 13, 51764], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1372, "seek": 361184, "start": 3639.84, "end": 3641.36, "text": " And I think that's just a really notable fact.", "tokens": [51764, 400, 286, 519, 300, 311, 445, 257, 534, 22556, 1186, 13, 51840], "temperature": 0.0, "avg_logprob": -0.13363646304968632, "compression_ratio": 1.7492447129909365, "no_speech_prob": 0.0006070433300919831}, {"id": 1373, "seek": 364184, "start": 3641.84, "end": 3645.2000000000003, "text": " That Stripe's ability to engineer these checkout experiences", "tokens": [50364, 663, 20390, 494, 311, 3485, 281, 11403, 613, 37153, 5235, 50532], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1374, "seek": 364184, "start": 3645.2000000000003, "end": 3648.7200000000003, "text": " is so good that big companies like Ford, Zoom, Metta,", "tokens": [50532, 307, 370, 665, 300, 955, 3431, 411, 11961, 11, 13453, 11, 6377, 1328, 11, 50708], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1375, "seek": 364184, "start": 3648.7200000000003, "end": 3652.0, "text": " even OpenAI, they work with Stripe to handle payments", "tokens": [50708, 754, 7238, 48698, 11, 436, 589, 365, 20390, 494, 281, 4813, 14348, 50872], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1376, "seek": 364184, "start": 3652.0, "end": 3653.84, "text": " because just think about how many different possibilities", "tokens": [50872, 570, 445, 519, 466, 577, 867, 819, 12178, 50964], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1377, "seek": 364184, "start": 3653.84, "end": 3654.88, "text": " you have to handle.", "tokens": [50964, 291, 362, 281, 4813, 13, 51016], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1378, "seek": 364184, "start": 3654.88, "end": 3656.88, "text": " If you're in a different country, you'll pay a different way", "tokens": [51016, 759, 291, 434, 294, 257, 819, 1941, 11, 291, 603, 1689, 257, 819, 636, 51116], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1379, "seek": 364184, "start": 3656.88, "end": 3658.48, "text": " and if you're buying a certain kind of item", "tokens": [51116, 293, 498, 291, 434, 6382, 257, 1629, 733, 295, 3174, 51196], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1380, "seek": 364184, "start": 3658.48, "end": 3660.4, "text": " that might affect how you decide to pay.", "tokens": [51196, 300, 1062, 3345, 577, 291, 4536, 281, 1689, 13, 51292], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1381, "seek": 364184, "start": 3660.4, "end": 3663.84, "text": " And Stripe is able to test these fine-grained optimizations", "tokens": [51292, 400, 20390, 494, 307, 1075, 281, 1500, 613, 2489, 12, 20735, 2001, 5028, 14455, 51464], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1382, "seek": 364184, "start": 3663.84, "end": 3666.4, "text": " across tens of billions of transactions a day", "tokens": [51464, 2108, 10688, 295, 17375, 295, 16856, 257, 786, 51592], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1383, "seek": 364184, "start": 3666.4, "end": 3668.56, "text": " to figure out what will convert people", "tokens": [51592, 281, 2573, 484, 437, 486, 7620, 561, 51700], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1384, "seek": 364184, "start": 3668.56, "end": 3671.28, "text": " and obviously conversion means more revenue for you.", "tokens": [51700, 293, 2745, 14298, 1355, 544, 9324, 337, 291, 13, 51836], "temperature": 0.0, "avg_logprob": -0.06473314598815082, "compression_ratio": 1.6905444126074498, "no_speech_prob": 0.0003682564420159906}, {"id": 1385, "seek": 367128, "start": 3671.28, "end": 3673.6800000000003, "text": " And look, I'm not a big company like Metta or anything,", "tokens": [50364, 400, 574, 11, 286, 478, 406, 257, 955, 2237, 411, 6377, 1328, 420, 1340, 11, 50484], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1386, "seek": 367128, "start": 3673.6800000000003, "end": 3675.28, "text": " but I've been using Stripe since long", "tokens": [50484, 457, 286, 600, 668, 1228, 20390, 494, 1670, 938, 50564], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1387, "seek": 367128, "start": 3675.28, "end": 3676.8, "text": " before they were advertisers.", "tokens": [50564, 949, 436, 645, 42679, 13, 50640], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1388, "seek": 367128, "start": 3676.8, "end": 3680.0800000000004, "text": " Stripe Atlas was just the easiest way for me to set up an LLC", "tokens": [50640, 20390, 494, 32485, 390, 445, 264, 12889, 636, 337, 385, 281, 992, 493, 364, 33698, 50804], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1389, "seek": 367128, "start": 3680.0800000000004, "end": 3682.1600000000003, "text": " and they have these payments and invoicing features", "tokens": [50804, 293, 436, 362, 613, 14348, 293, 1048, 78, 5776, 4122, 50908], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1390, "seek": 367128, "start": 3682.1600000000003, "end": 3686.0, "text": " that make it super convenient for me to get money from advertisers.", "tokens": [50908, 300, 652, 309, 1687, 10851, 337, 385, 281, 483, 1460, 490, 42679, 13, 51100], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1391, "seek": 367128, "start": 3686.0, "end": 3688.0800000000004, "text": " And obviously without that, it would have been much harder", "tokens": [51100, 400, 2745, 1553, 300, 11, 309, 576, 362, 668, 709, 6081, 51204], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1392, "seek": 367128, "start": 3688.0800000000004, "end": 3690.0, "text": " for me to earn money from the podcast.", "tokens": [51204, 337, 385, 281, 6012, 1460, 490, 264, 7367, 13, 51300], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1393, "seek": 367128, "start": 3690.0, "end": 3691.6000000000004, "text": " And so it's been great for me.", "tokens": [51300, 400, 370, 309, 311, 668, 869, 337, 385, 13, 51380], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1394, "seek": 367128, "start": 3691.6000000000004, "end": 3693.6800000000003, "text": " Go to stripe.com to learn more.", "tokens": [51380, 1037, 281, 42957, 13, 1112, 281, 1466, 544, 13, 51484], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1395, "seek": 367128, "start": 3693.6800000000003, "end": 3695.44, "text": " Thanks to them for sponsoring the episode.", "tokens": [51484, 2561, 281, 552, 337, 30311, 264, 3500, 13, 51572], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1396, "seek": 367128, "start": 3695.44, "end": 3696.2400000000002, "text": " Now back to Mark.", "tokens": [51572, 823, 646, 281, 3934, 13, 51612], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1397, "seek": 367128, "start": 3697.1200000000003, "end": 3699.28, "text": " I'm not sure, but I'm actually curious about something else", "tokens": [51656, 286, 478, 406, 988, 11, 457, 286, 478, 767, 6369, 466, 746, 1646, 51764], "temperature": 0.0, "avg_logprob": -0.06543023331360247, "compression_ratio": 1.7315634218289087, "no_speech_prob": 0.0010985175613313913}, {"id": 1398, "seek": 369928, "start": 3699.28, "end": 3704.4, "text": " which is, so the 19-year-old Mark reads a bunch", "tokens": [50364, 597, 307, 11, 370, 264, 1294, 12, 5294, 12, 2641, 3934, 15700, 257, 3840, 50620], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1399, "seek": 369928, "start": 3704.4, "end": 3707.28, "text": " of like antiquity in classics, high school, college.", "tokens": [50620, 295, 411, 41036, 507, 294, 36110, 11, 1090, 1395, 11, 3859, 13, 50764], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1400, "seek": 369928, "start": 3707.92, "end": 3709.44, "text": " What important lesson did you learn from it?", "tokens": [50796, 708, 1021, 6898, 630, 291, 1466, 490, 309, 30, 50872], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1401, "seek": 369928, "start": 3709.44, "end": 3710.5600000000004, "text": " Not just interesting things you found,", "tokens": [50872, 1726, 445, 1880, 721, 291, 1352, 11, 50928], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1402, "seek": 369928, "start": 3710.5600000000004, "end": 3713.2000000000003, "text": " but like there aren't that many tokens you consumed", "tokens": [50928, 457, 411, 456, 3212, 380, 300, 867, 22667, 291, 21226, 51060], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1403, "seek": 369928, "start": 3713.2000000000003, "end": 3714.1600000000003, "text": " by the time you're 19.", "tokens": [51060, 538, 264, 565, 291, 434, 1294, 13, 51108], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1404, "seek": 369928, "start": 3714.1600000000003, "end": 3715.6800000000003, "text": " A bunch of them were about the classics.", "tokens": [51108, 316, 3840, 295, 552, 645, 466, 264, 36110, 13, 51184], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1405, "seek": 369928, "start": 3715.6800000000003, "end": 3716.88, "text": " Clearly that was important in some way.", "tokens": [51184, 24120, 300, 390, 1021, 294, 512, 636, 13, 51244], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1406, "seek": 369928, "start": 3716.88, "end": 3718.2400000000002, "text": " And that many tokens you consumed.", "tokens": [51244, 400, 300, 867, 22667, 291, 21226, 13, 51312], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1407, "seek": 369928, "start": 3725.6800000000003, "end": 3726.0800000000004, "text": " I don't know.", "tokens": [51684, 286, 500, 380, 458, 13, 51704], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1408, "seek": 369928, "start": 3726.0800000000004, "end": 3727.1200000000003, "text": " That's a good question.", "tokens": [51704, 663, 311, 257, 665, 1168, 13, 51756], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1409, "seek": 369928, "start": 3727.1200000000003, "end": 3728.32, "text": " I mean, one of the things that I thought", "tokens": [51756, 286, 914, 11, 472, 295, 264, 721, 300, 286, 1194, 51816], "temperature": 0.0, "avg_logprob": -0.18913788428673378, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.004467464517802}, {"id": 1410, "seek": 372832, "start": 3728.32, "end": 3737.44, "text": " was really fascinating is, so when Augustus was first,", "tokens": [50364, 390, 534, 10343, 307, 11, 370, 562, 6897, 301, 390, 700, 11, 50820], "temperature": 0.0, "avg_logprob": -0.14145268966902547, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0018100806046277285}, {"id": 1411, "seek": 372832, "start": 3738.0, "end": 3744.48, "text": " so he became emperor, and he was trying to establish peace.", "tokens": [50848, 370, 415, 3062, 20255, 11, 293, 415, 390, 1382, 281, 8327, 4336, 13, 51172], "temperature": 0.0, "avg_logprob": -0.14145268966902547, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0018100806046277285}, {"id": 1412, "seek": 372832, "start": 3744.48, "end": 3750.4, "text": " And there was no real conception of peace at the time.", "tokens": [51172, 400, 456, 390, 572, 957, 30698, 295, 4336, 412, 264, 565, 13, 51468], "temperature": 0.0, "avg_logprob": -0.14145268966902547, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0018100806046277285}, {"id": 1413, "seek": 372832, "start": 3750.4, "end": 3753.04, "text": " Like the people's understanding of peace was,", "tokens": [51468, 1743, 264, 561, 311, 3701, 295, 4336, 390, 11, 51600], "temperature": 0.0, "avg_logprob": -0.14145268966902547, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0018100806046277285}, {"id": 1414, "seek": 372832, "start": 3754.0, "end": 3756.4, "text": " it is the temporary time between when you're", "tokens": [51648, 309, 307, 264, 13413, 565, 1296, 562, 291, 434, 51768], "temperature": 0.0, "avg_logprob": -0.14145268966902547, "compression_ratio": 1.5204678362573099, "no_speech_prob": 0.0018100806046277285}, {"id": 1415, "seek": 375640, "start": 3756.4, "end": 3758.96, "text": " and amuse will inevitably attack you again,", "tokens": [50364, 293, 669, 438, 486, 28171, 2690, 291, 797, 11, 50492], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1416, "seek": 375640, "start": 3758.96, "end": 3760.2400000000002, "text": " so you get like a short rest.", "tokens": [50492, 370, 291, 483, 411, 257, 2099, 1472, 13, 50556], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1417, "seek": 375640, "start": 3760.8, "end": 3763.2000000000003, "text": " And he had this view, which is like, look,", "tokens": [50584, 400, 415, 632, 341, 1910, 11, 597, 307, 411, 11, 574, 11, 50704], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1418, "seek": 375640, "start": 3763.2000000000003, "end": 3766.7200000000003, "text": " like we want to change the economy from instead of being", "tokens": [50704, 411, 321, 528, 281, 1319, 264, 5010, 490, 2602, 295, 885, 50880], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1419, "seek": 375640, "start": 3766.7200000000003, "end": 3770.08, "text": " so mercenary and like in kind of militaristic", "tokens": [50880, 370, 10811, 42245, 293, 411, 294, 733, 295, 30653, 3142, 51048], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1420, "seek": 375640, "start": 3770.96, "end": 3773.92, "text": " to like actually this positive something.", "tokens": [51092, 281, 411, 767, 341, 3353, 746, 13, 51240], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1421, "seek": 375640, "start": 3774.64, "end": 3777.76, "text": " It's like a very novel idea at the time.", "tokens": [51276, 467, 311, 411, 257, 588, 7613, 1558, 412, 264, 565, 13, 51432], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1422, "seek": 375640, "start": 3782.4, "end": 3782.96, "text": " I don't know.", "tokens": [51664, 286, 500, 380, 458, 13, 51692], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1423, "seek": 375640, "start": 3782.96, "end": 3784.56, "text": " I think that there's like something that's", "tokens": [51692, 286, 519, 300, 456, 311, 411, 746, 300, 311, 51772], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1424, "seek": 375640, "start": 3784.56, "end": 3786.08, "text": " just really fundamental about that.", "tokens": [51772, 445, 534, 8088, 466, 300, 13, 51848], "temperature": 0.0, "avg_logprob": -0.15063020532781426, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.009705635719001293}, {"id": 1425, "seek": 378608, "start": 3786.08, "end": 3789.2799999999997, "text": " It's like in terms of the bounds on like what people", "tokens": [50364, 467, 311, 411, 294, 2115, 295, 264, 29905, 322, 411, 437, 561, 50524], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1426, "seek": 378608, "start": 3789.2799999999997, "end": 3792.96, "text": " can conceive at the time of like what are rational ways to work.", "tokens": [50524, 393, 48605, 412, 264, 565, 295, 411, 437, 366, 15090, 2098, 281, 589, 13, 50708], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1427, "seek": 378608, "start": 3793.68, "end": 3797.2799999999997, "text": " And I don't know, I mean, going back to like,", "tokens": [50744, 400, 286, 500, 380, 458, 11, 286, 914, 11, 516, 646, 281, 411, 11, 50924], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1428, "seek": 378608, "start": 3797.2799999999997, "end": 3799.6, "text": " I mean, this applies to both the metaverse and the AI stuff,", "tokens": [50924, 286, 914, 11, 341, 13165, 281, 1293, 264, 19616, 4308, 293, 264, 7318, 1507, 11, 51040], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1429, "seek": 378608, "start": 3799.6, "end": 3802.4, "text": " but like a lot of investors and just different people", "tokens": [51040, 457, 411, 257, 688, 295, 11519, 293, 445, 819, 561, 51180], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1430, "seek": 378608, "start": 3802.4, "end": 3804.88, "text": " just can't wrap their head around why we would open source this.", "tokens": [51180, 445, 393, 380, 7019, 641, 1378, 926, 983, 321, 576, 1269, 4009, 341, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1431, "seek": 378608, "start": 3805.44, "end": 3809.44, "text": " And it's like, I don't understand.", "tokens": [51332, 400, 309, 311, 411, 11, 286, 500, 380, 1223, 13, 51532], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1432, "seek": 378608, "start": 3809.44, "end": 3810.3199999999997, "text": " It's like open source.", "tokens": [51532, 467, 311, 411, 1269, 4009, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1433, "seek": 378608, "start": 3810.3199999999997, "end": 3812.16, "text": " That must just be like the temporary time", "tokens": [51576, 663, 1633, 445, 312, 411, 264, 13413, 565, 51668], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1434, "seek": 378608, "start": 3812.16, "end": 3814.08, "text": " between which you're making things proprietary.", "tokens": [51668, 1296, 597, 291, 434, 1455, 721, 38992, 13, 51764], "temperature": 0.0, "avg_logprob": -0.1546349202779899, "compression_ratio": 1.734982332155477, "no_speech_prob": 0.00030527784838341177}, {"id": 1435, "seek": 381408, "start": 3814.08, "end": 3815.2, "text": " Right.", "tokens": [50364, 1779, 13, 50420], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1436, "seek": 381408, "start": 3815.2, "end": 3817.84, "text": " And it's, but I actually think it's like", "tokens": [50420, 400, 309, 311, 11, 457, 286, 767, 519, 309, 311, 411, 50552], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1437, "seek": 381408, "start": 3818.48, "end": 3824.16, "text": " this very profound thing in tech that has actually,", "tokens": [50584, 341, 588, 14382, 551, 294, 7553, 300, 575, 767, 11, 50868], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1438, "seek": 381408, "start": 3824.16, "end": 3826.24, "text": " it creates a lot of winners.", "tokens": [50868, 309, 7829, 257, 688, 295, 17193, 13, 50972], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1439, "seek": 381408, "start": 3826.24, "end": 3826.56, "text": " Right.", "tokens": [50972, 1779, 13, 50988], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1440, "seek": 381408, "start": 3826.56, "end": 3830.72, "text": " And it's and so I don't want to strain the analogy too much,", "tokens": [50988, 400, 309, 311, 293, 370, 286, 500, 380, 528, 281, 14249, 264, 21663, 886, 709, 11, 51196], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1441, "seek": 381408, "start": 3830.72, "end": 3834.96, "text": " but I do think that there's a lot of times,", "tokens": [51196, 457, 286, 360, 519, 300, 456, 311, 257, 688, 295, 1413, 11, 51408], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1442, "seek": 381408, "start": 3834.96, "end": 3836.48, "text": " I think ways where you can", "tokens": [51408, 286, 519, 2098, 689, 291, 393, 51484], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1443, "seek": 381408, "start": 3839.36, "end": 3841.7599999999998, "text": " that are just like models for building things", "tokens": [51628, 300, 366, 445, 411, 5245, 337, 2390, 721, 51748], "temperature": 0.0, "avg_logprob": -0.18039928598606841, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.0013669366016983986}, {"id": 1444, "seek": 384176, "start": 3842.0, "end": 3845.5200000000004, "text": " that people can't even like they just like often can't wrap", "tokens": [50376, 300, 561, 393, 380, 754, 411, 436, 445, 411, 2049, 393, 380, 7019, 50552], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1445, "seek": 384176, "start": 3845.5200000000004, "end": 3848.2400000000002, "text": " their head around how that would be a valuable thing", "tokens": [50552, 641, 1378, 926, 577, 300, 576, 312, 257, 8263, 551, 50688], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1446, "seek": 384176, "start": 3848.2400000000002, "end": 3851.76, "text": " for people to go do, or like a reasonable state of the world", "tokens": [50688, 337, 561, 281, 352, 360, 11, 420, 411, 257, 10585, 1785, 295, 264, 1002, 50864], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1447, "seek": 384176, "start": 3851.76, "end": 3857.6800000000003, "text": " that it's, I mean, it's, I think that there's more reasonable", "tokens": [50864, 300, 309, 311, 11, 286, 914, 11, 309, 311, 11, 286, 519, 300, 456, 311, 544, 10585, 51160], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1448, "seek": 384176, "start": 3857.6800000000003, "end": 3858.88, "text": " things than people think.", "tokens": [51160, 721, 813, 561, 519, 13, 51220], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1449, "seek": 384176, "start": 3858.88, "end": 3860.7200000000003, "text": " That's super fascinating.", "tokens": [51220, 663, 311, 1687, 10343, 13, 51312], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1450, "seek": 384176, "start": 3860.7200000000003, "end": 3862.8, "text": " Can I give you my answer when I was thinking", "tokens": [51312, 1664, 286, 976, 291, 452, 1867, 562, 286, 390, 1953, 51416], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1451, "seek": 384176, "start": 3862.8, "end": 3864.48, "text": " what you might have gotten from it?", "tokens": [51416, 437, 291, 1062, 362, 5768, 490, 309, 30, 51500], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1452, "seek": 384176, "start": 3864.48, "end": 3868.1600000000003, "text": " This is probably totally off, but just how young", "tokens": [51500, 639, 307, 1391, 3879, 766, 11, 457, 445, 577, 2037, 51684], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1453, "seek": 384176, "start": 3868.1600000000003, "end": 3870.96, "text": " some of these people are who have very important roles", "tokens": [51684, 512, 295, 613, 561, 366, 567, 362, 588, 1021, 9604, 51824], "temperature": 0.0, "avg_logprob": -0.264746819773028, "compression_ratio": 1.7226277372262773, "no_speech_prob": 0.0005192785756662488}, {"id": 1454, "seek": 387096, "start": 3871.84, "end": 3872.48, "text": " in the empire.", "tokens": [50408, 294, 264, 17506, 13, 50440], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1455, "seek": 387096, "start": 3872.48, "end": 3874.7200000000003, "text": " Like Caesar Augustus, like by the time he's 19,", "tokens": [50440, 1743, 26678, 6897, 301, 11, 411, 538, 264, 565, 415, 311, 1294, 11, 50552], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1456, "seek": 387096, "start": 3874.7200000000003, "end": 3877.12, "text": " he's actually incredibly one of the most prominent people", "tokens": [50552, 415, 311, 767, 6252, 472, 295, 264, 881, 17034, 561, 50672], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1457, "seek": 387096, "start": 3877.12, "end": 3878.32, "text": " in Roman politics.", "tokens": [50672, 294, 8566, 7341, 13, 50732], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1458, "seek": 387096, "start": 3878.32, "end": 3879.76, "text": " And he's like leading battles and forming", "tokens": [50732, 400, 415, 311, 411, 5775, 14648, 293, 15745, 50804], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1459, "seek": 387096, "start": 3879.76, "end": 3881.04, "text": " the second prime emirate.", "tokens": [50804, 264, 1150, 5835, 846, 347, 473, 13, 50868], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1460, "seek": 387096, "start": 3881.04, "end": 3882.8, "text": " I wonder if you're like the 19 year old is like,", "tokens": [50868, 286, 2441, 498, 291, 434, 411, 264, 1294, 1064, 1331, 307, 411, 11, 50956], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1461, "seek": 387096, "start": 3882.8, "end": 3884.0, "text": " I can actually do this because like", "tokens": [50956, 286, 393, 767, 360, 341, 570, 411, 51016], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1462, "seek": 387096, "start": 3884.0, "end": 3886.8, "text": " I think that's an interesting example,", "tokens": [51016, 286, 519, 300, 311, 364, 1880, 1365, 11, 51156], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1463, "seek": 387096, "start": 3886.8, "end": 3890.2400000000002, "text": " both from a lot of history and American history.", "tokens": [51156, 1293, 490, 257, 688, 295, 2503, 293, 2665, 2503, 13, 51328], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1464, "seek": 387096, "start": 3890.2400000000002, "end": 3890.7200000000003, "text": " Yeah.", "tokens": [51328, 865, 13, 51352], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1465, "seek": 387096, "start": 3890.7200000000003, "end": 3895.04, "text": " I mean, it's, I mean, one of my favorite quotes is,", "tokens": [51352, 286, 914, 11, 309, 311, 11, 286, 914, 11, 472, 295, 452, 2954, 19963, 307, 11, 51568], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1466, "seek": 387096, "start": 3895.04, "end": 3897.68, "text": " it's this Picasso quote that all children are artists", "tokens": [51568, 309, 311, 341, 49708, 6513, 300, 439, 2227, 366, 6910, 51700], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1467, "seek": 387096, "start": 3897.68, "end": 3899.52, "text": " and the challenge is how do you remain an artist", "tokens": [51700, 293, 264, 3430, 307, 577, 360, 291, 6222, 364, 5748, 51792], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1468, "seek": 387096, "start": 3899.52, "end": 3900.56, "text": " when you grow up?", "tokens": [51792, 562, 291, 1852, 493, 30, 51844], "temperature": 0.0, "avg_logprob": -0.1895451695664124, "compression_ratio": 1.6786786786786787, "no_speech_prob": 0.005382162518799305}, {"id": 1469, "seek": 390056, "start": 3900.56, "end": 3903.2799999999997, "text": " And it's like basically I think because when you're younger,", "tokens": [50364, 400, 309, 311, 411, 1936, 286, 519, 570, 562, 291, 434, 7037, 11, 50500], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1470, "seek": 390056, "start": 3904.08, "end": 3909.68, "text": " I think it's just easier to have kind of wild ideas", "tokens": [50540, 286, 519, 309, 311, 445, 3571, 281, 362, 733, 295, 4868, 3487, 50820], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1471, "seek": 390056, "start": 3909.68, "end": 3911.36, "text": " and you're not, you know, you have no,", "tokens": [50820, 293, 291, 434, 406, 11, 291, 458, 11, 291, 362, 572, 11, 50904], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1472, "seek": 390056, "start": 3912.56, "end": 3915.2, "text": " there are all these analogies to the innovators dilemma", "tokens": [50964, 456, 366, 439, 613, 16660, 530, 281, 264, 5083, 3391, 34312, 51096], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1473, "seek": 390056, "start": 3915.2, "end": 3918.64, "text": " that exist in your life as well as your company", "tokens": [51096, 300, 2514, 294, 428, 993, 382, 731, 382, 428, 2237, 51268], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1474, "seek": 390056, "start": 3918.64, "end": 3919.84, "text": " or whatever you've built, right?", "tokens": [51268, 420, 2035, 291, 600, 3094, 11, 558, 30, 51328], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1475, "seek": 390056, "start": 3919.84, "end": 3922.08, "text": " So, you know, you're kind of earlier on your trajectory.", "tokens": [51328, 407, 11, 291, 458, 11, 291, 434, 733, 295, 3071, 322, 428, 21512, 13, 51440], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1476, "seek": 390056, "start": 3922.08, "end": 3924.96, "text": " It's easier to pivot and take in new ideas", "tokens": [51440, 467, 311, 3571, 281, 14538, 293, 747, 294, 777, 3487, 51584], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1477, "seek": 390056, "start": 3924.96, "end": 3926.7999999999997, "text": " without it disrupting other commitments", "tokens": [51584, 1553, 309, 14124, 278, 661, 26230, 51676], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1478, "seek": 390056, "start": 3926.7999999999997, "end": 3929.04, "text": " that you've made to different things.", "tokens": [51676, 300, 291, 600, 1027, 281, 819, 721, 13, 51788], "temperature": 0.0, "avg_logprob": -0.11552124931698754, "compression_ratio": 1.7007299270072993, "no_speech_prob": 0.00036824733251705766}, {"id": 1479, "seek": 392904, "start": 3929.04, "end": 3931.92, "text": " And so, I don't know.", "tokens": [50364, 400, 370, 11, 286, 500, 380, 458, 13, 50508], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1480, "seek": 392904, "start": 3931.92, "end": 3934.56, "text": " I think that's an interesting part of running a company", "tokens": [50508, 286, 519, 300, 311, 364, 1880, 644, 295, 2614, 257, 2237, 50640], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1481, "seek": 392904, "start": 3934.56, "end": 3936.96, "text": " is like how do you kind of stay dynamic?", "tokens": [50640, 307, 411, 577, 360, 291, 733, 295, 1754, 8546, 30, 50760], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1482, "seek": 392904, "start": 3938.64, "end": 3940.4, "text": " Going back to the investors in open source,", "tokens": [50844, 10963, 646, 281, 264, 11519, 294, 1269, 4009, 11, 50932], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1483, "seek": 392904, "start": 3941.44, "end": 3942.88, "text": " the $10 billion model,", "tokens": [50984, 264, 1848, 3279, 5218, 2316, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1484, "seek": 392904, "start": 3942.88, "end": 3945.84, "text": " suppose it's totally safe, you've done these evaluations", "tokens": [51056, 7297, 309, 311, 3879, 3273, 11, 291, 600, 1096, 613, 43085, 51204], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1485, "seek": 392904, "start": 3945.84, "end": 3947.2799999999997, "text": " and unlike in this case,", "tokens": [51204, 293, 8343, 294, 341, 1389, 11, 51276], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1486, "seek": 392904, "start": 3947.2799999999997, "end": 3948.96, "text": " the evaluators can also fine tune the model,", "tokens": [51276, 264, 6133, 3391, 393, 611, 2489, 10864, 264, 2316, 11, 51360], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1487, "seek": 392904, "start": 3949.68, "end": 3951.36, "text": " which hopefully will be the case in future models.", "tokens": [51396, 597, 4696, 486, 312, 264, 1389, 294, 2027, 5245, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1488, "seek": 392904, "start": 3952.56, "end": 3954.56, "text": " Would you open source that, the $10 billion model?", "tokens": [51540, 6068, 291, 1269, 4009, 300, 11, 264, 1848, 3279, 5218, 2316, 30, 51640], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1489, "seek": 392904, "start": 3955.36, "end": 3957.2799999999997, "text": " Well, I mean, as long as it's helping us, then yeah.", "tokens": [51680, 1042, 11, 286, 914, 11, 382, 938, 382, 309, 311, 4315, 505, 11, 550, 1338, 13, 51776], "temperature": 0.0, "avg_logprob": -0.1269384972134927, "compression_ratio": 1.6859205776173285, "no_speech_prob": 0.0003459532163105905}, {"id": 1490, "seek": 395728, "start": 3957.28, "end": 3959.36, "text": " But would it like to $10 billion of R&D", "tokens": [50364, 583, 576, 309, 411, 281, 1848, 3279, 5218, 295, 497, 5, 35, 50468], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1491, "seek": 395728, "start": 3959.36, "end": 3960.96, "text": " and then now it's like open source or anything?", "tokens": [50468, 293, 550, 586, 309, 311, 411, 1269, 4009, 420, 1340, 30, 50548], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1492, "seek": 395728, "start": 3960.96, "end": 3962.88, "text": " Well, I think here's, I think a question,", "tokens": [50548, 1042, 11, 286, 519, 510, 311, 11, 286, 519, 257, 1168, 11, 50644], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1493, "seek": 395728, "start": 3962.88, "end": 3966.6400000000003, "text": " which we'll have to evaluate this as time goes on too, but", "tokens": [50644, 597, 321, 603, 362, 281, 13059, 341, 382, 565, 1709, 322, 886, 11, 457, 50832], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1494, "seek": 395728, "start": 3970.32, "end": 3972.96, "text": " we have a long history of open sourcing software, right?", "tokens": [51016, 321, 362, 257, 938, 2503, 295, 1269, 11006, 2175, 4722, 11, 558, 30, 51148], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1495, "seek": 395728, "start": 3972.96, "end": 3975.52, "text": " We don't tend to open source our product, right?", "tokens": [51148, 492, 500, 380, 3928, 281, 1269, 4009, 527, 1674, 11, 558, 30, 51276], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1496, "seek": 395728, "start": 3975.52, "end": 3978.88, "text": " So, it's not like we don't take like the code for Instagram", "tokens": [51276, 407, 11, 309, 311, 406, 411, 321, 500, 380, 747, 411, 264, 3089, 337, 5281, 51444], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1497, "seek": 395728, "start": 3978.88, "end": 3979.76, "text": " and make it open source,", "tokens": [51444, 293, 652, 309, 1269, 4009, 11, 51488], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1498, "seek": 395728, "start": 3979.76, "end": 3982.88, "text": " but we take like a lot of the low level infrastructure", "tokens": [51488, 457, 321, 747, 411, 257, 688, 295, 264, 2295, 1496, 6896, 51644], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1499, "seek": 395728, "start": 3983.44, "end": 3985.6000000000004, "text": " and we make that open source, right?", "tokens": [51672, 293, 321, 652, 300, 1269, 4009, 11, 558, 30, 51780], "temperature": 0.0, "avg_logprob": -0.12315055401655879, "compression_ratio": 1.7773584905660378, "no_speech_prob": 0.0005527242901735008}, {"id": 1500, "seek": 398560, "start": 3986.08, "end": 3989.52, "text": " Probably the biggest one in our history was open compute project", "tokens": [50388, 9210, 264, 3880, 472, 294, 527, 2503, 390, 1269, 14722, 1716, 50560], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1501, "seek": 398560, "start": 3989.52, "end": 3994.64, "text": " where we took the designs for kind of all of our servers", "tokens": [50560, 689, 321, 1890, 264, 11347, 337, 733, 295, 439, 295, 527, 15909, 50816], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1502, "seek": 398560, "start": 3994.64, "end": 3996.24, "text": " and network switches and data centers", "tokens": [50816, 293, 3209, 19458, 293, 1412, 10898, 50896], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1503, "seek": 398560, "start": 3996.24, "end": 3998.88, "text": " and made it open source and ended up being super helpful", "tokens": [50896, 293, 1027, 309, 1269, 4009, 293, 4590, 493, 885, 1687, 4961, 51028], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1504, "seek": 398560, "start": 3998.88, "end": 4001.52, "text": " because, you know, I mean, a lot of people can design servers,", "tokens": [51028, 570, 11, 291, 458, 11, 286, 914, 11, 257, 688, 295, 561, 393, 1715, 15909, 11, 51160], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1505, "seek": 398560, "start": 4001.52, "end": 4003.52, "text": " but now like the industry standardized on our design,", "tokens": [51160, 457, 586, 411, 264, 3518, 31677, 322, 527, 1715, 11, 51260], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1506, "seek": 398560, "start": 4003.52, "end": 4005.2799999999997, "text": " which meant that the supply chains", "tokens": [51260, 597, 4140, 300, 264, 5847, 12626, 51348], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1507, "seek": 398560, "start": 4006.16, "end": 4007.92, "text": " basically all got built out around our design,", "tokens": [51392, 1936, 439, 658, 3094, 484, 926, 527, 1715, 11, 51480], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1508, "seek": 398560, "start": 4007.92, "end": 4008.72, "text": " the volumes went up,", "tokens": [51480, 264, 22219, 1437, 493, 11, 51520], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1509, "seek": 398560, "start": 4008.72, "end": 4011.6, "text": " so it got cheaper for everyone and saved us billions of dollars.", "tokens": [51520, 370, 309, 658, 12284, 337, 1518, 293, 6624, 505, 17375, 295, 3808, 13, 51664], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1510, "seek": 398560, "start": 4011.6, "end": 4013.36, "text": " So, awesome, right?", "tokens": [51664, 407, 11, 3476, 11, 558, 30, 51752], "temperature": 0.0, "avg_logprob": -0.1279467501381571, "compression_ratio": 1.6645367412140575, "no_speech_prob": 0.0005032818880863488}, {"id": 1511, "seek": 401336, "start": 4013.44, "end": 4016.2400000000002, "text": " Okay, so there's multiple ways where open source,", "tokens": [50368, 1033, 11, 370, 456, 311, 3866, 2098, 689, 1269, 4009, 11, 50508], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1512, "seek": 401336, "start": 4016.2400000000002, "end": 4017.92, "text": " I think, could be helpful for us.", "tokens": [50508, 286, 519, 11, 727, 312, 4961, 337, 505, 13, 50592], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1513, "seek": 401336, "start": 4017.92, "end": 4021.44, "text": " One is if people figure out how to run the models more cheaply.", "tokens": [50592, 1485, 307, 498, 561, 2573, 484, 577, 281, 1190, 264, 5245, 544, 7084, 356, 13, 50768], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1514, "seek": 401336, "start": 4021.44, "end": 4024.6400000000003, "text": " Well, we're going to be spending tens or like 100 billion dollars", "tokens": [50768, 1042, 11, 321, 434, 516, 281, 312, 6434, 10688, 420, 411, 2319, 5218, 3808, 50928], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1515, "seek": 401336, "start": 4024.6400000000003, "end": 4027.04, "text": " or more over time on all this stuff.", "tokens": [50928, 420, 544, 670, 565, 322, 439, 341, 1507, 13, 51048], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1516, "seek": 401336, "start": 4027.6800000000003, "end": 4030.1600000000003, "text": " So, if we can do that 10% more effectively,", "tokens": [51080, 407, 11, 498, 321, 393, 360, 300, 1266, 4, 544, 8659, 11, 51204], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1517, "seek": 401336, "start": 4030.1600000000003, "end": 4032.7200000000003, "text": " we're saving billions or tens of billions of dollars.", "tokens": [51204, 321, 434, 6816, 17375, 420, 10688, 295, 17375, 295, 3808, 13, 51332], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1518, "seek": 401336, "start": 4032.7200000000003, "end": 4034.32, "text": " Okay, that's probably worth a lot by itself,", "tokens": [51332, 1033, 11, 300, 311, 1391, 3163, 257, 688, 538, 2564, 11, 51412], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1519, "seek": 401336, "start": 4035.92, "end": 4037.84, "text": " especially if there's other competitive models out there.", "tokens": [51492, 2318, 498, 456, 311, 661, 10043, 5245, 484, 456, 13, 51588], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1520, "seek": 401336, "start": 4037.84, "end": 4039.76, "text": " It's not like our thing is like", "tokens": [51588, 467, 311, 406, 411, 527, 551, 307, 411, 51684], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1521, "seek": 401336, "start": 4039.76, "end": 4041.76, "text": " be giving away some kind of crazy advantage.", "tokens": [51684, 312, 2902, 1314, 512, 733, 295, 3219, 5002, 13, 51784], "temperature": 0.0, "avg_logprob": -0.10105200414057378, "compression_ratio": 1.6761904761904762, "no_speech_prob": 0.0019265684532001615}, {"id": 1522, "seek": 404176, "start": 4042.7200000000003, "end": 4045.6000000000004, "text": " So, is there a view that the trading will be commodified?", "tokens": [50412, 407, 11, 307, 456, 257, 1910, 300, 264, 9529, 486, 312, 19931, 2587, 30, 50556], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1523, "seek": 404176, "start": 4049.0400000000004, "end": 4050.88, "text": " I think there's a bunch of ways that this could play out.", "tokens": [50728, 286, 519, 456, 311, 257, 3840, 295, 2098, 300, 341, 727, 862, 484, 13, 50820], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1524, "seek": 404176, "start": 4050.88, "end": 4051.84, "text": " That's one.", "tokens": [50820, 663, 311, 472, 13, 50868], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1525, "seek": 404176, "start": 4051.84, "end": 4058.5600000000004, "text": " The other is that, so commodity kind of implies", "tokens": [50868, 440, 661, 307, 300, 11, 370, 29125, 733, 295, 18779, 51204], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1526, "seek": 404176, "start": 4059.1200000000003, "end": 4060.48, "text": " that it's going to get very cheap", "tokens": [51232, 300, 309, 311, 516, 281, 483, 588, 7084, 51300], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1527, "seek": 404176, "start": 4060.48, "end": 4063.0400000000004, "text": " because there's lots of options.", "tokens": [51300, 570, 456, 311, 3195, 295, 3956, 13, 51428], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1528, "seek": 404176, "start": 4063.0400000000004, "end": 4064.5600000000004, "text": " The other direction that this could go in", "tokens": [51428, 440, 661, 3513, 300, 341, 727, 352, 294, 51504], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1529, "seek": 404176, "start": 4065.36, "end": 4067.0400000000004, "text": " is qualitative improvements.", "tokens": [51544, 307, 31312, 13797, 13, 51628], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1530, "seek": 404176, "start": 4067.0400000000004, "end": 4069.36, "text": " So, you mentioned fine-tuning, right?", "tokens": [51628, 407, 11, 291, 2835, 2489, 12, 83, 37726, 11, 558, 30, 51744], "temperature": 0.0, "avg_logprob": -0.10925865173339844, "compression_ratio": 1.6401869158878504, "no_speech_prob": 0.000535739294718951}, {"id": 1531, "seek": 406936, "start": 4069.36, "end": 4071.76, "text": " It's like right now, it's pretty limited,", "tokens": [50364, 467, 311, 411, 558, 586, 11, 309, 311, 1238, 5567, 11, 50484], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1532, "seek": 406936, "start": 4071.76, "end": 4075.1200000000003, "text": " what you can do with fine-tuning major other models out there.", "tokens": [50484, 437, 291, 393, 360, 365, 2489, 12, 83, 37726, 2563, 661, 5245, 484, 456, 13, 50652], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1533, "seek": 406936, "start": 4075.1200000000003, "end": 4076.4, "text": " And there are some options,", "tokens": [50652, 400, 456, 366, 512, 3956, 11, 50716], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1534, "seek": 406936, "start": 4076.4, "end": 4078.4, "text": " but generally not for the biggest models.", "tokens": [50716, 457, 5101, 406, 337, 264, 3880, 5245, 13, 50816], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1535, "seek": 406936, "start": 4079.84, "end": 4081.28, "text": " So, I think being able to do that", "tokens": [50888, 407, 11, 286, 519, 885, 1075, 281, 360, 300, 50960], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1536, "seek": 406936, "start": 4081.28, "end": 4086.1600000000003, "text": " and be able to kind of do different app-specific things", "tokens": [50960, 293, 312, 1075, 281, 733, 295, 360, 819, 724, 12, 29258, 721, 51204], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1537, "seek": 406936, "start": 4086.1600000000003, "end": 4087.44, "text": " or use case-specific things", "tokens": [51204, 420, 764, 1389, 12, 29258, 721, 51268], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1538, "seek": 406936, "start": 4087.44, "end": 4089.1200000000003, "text": " or build them into specific tool chains,", "tokens": [51268, 420, 1322, 552, 666, 2685, 2290, 12626, 11, 51352], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1539, "seek": 406936, "start": 4090.88, "end": 4095.6, "text": " I think will not only enable kind of more efficient development,", "tokens": [51440, 286, 519, 486, 406, 787, 9528, 733, 295, 544, 7148, 3250, 11, 51676], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1540, "seek": 406936, "start": 4095.6, "end": 4097.52, "text": " it could enable qualitatively different things.", "tokens": [51676, 309, 727, 9528, 31312, 356, 819, 721, 13, 51772], "temperature": 0.0, "avg_logprob": -0.11208423386272202, "compression_ratio": 1.7153846153846153, "no_speech_prob": 0.0015485481126233935}, {"id": 1541, "seek": 409752, "start": 4098.4800000000005, "end": 4099.68, "text": " Here's one analogy on this.", "tokens": [50412, 1692, 311, 472, 21663, 322, 341, 13, 50472], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1542, "seek": 409752, "start": 4102.160000000001, "end": 4104.240000000001, "text": " So, one thing that I think generally sucks", "tokens": [50596, 407, 11, 472, 551, 300, 286, 519, 5101, 15846, 50700], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1543, "seek": 409752, "start": 4104.240000000001, "end": 4105.52, "text": " about the mobile ecosystem", "tokens": [50700, 466, 264, 6013, 11311, 50764], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1544, "seek": 409752, "start": 4106.080000000001, "end": 4110.160000000001, "text": " is that you have these two gatekeeper companies,", "tokens": [50792, 307, 300, 291, 362, 613, 732, 8539, 23083, 3431, 11, 50996], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1545, "seek": 409752, "start": 4110.160000000001, "end": 4111.200000000001, "text": " Apple and Google,", "tokens": [50996, 6373, 293, 3329, 11, 51048], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1546, "seek": 409752, "start": 4111.200000000001, "end": 4113.200000000001, "text": " that can tell you what you're allowed to build.", "tokens": [51048, 300, 393, 980, 291, 437, 291, 434, 4350, 281, 1322, 13, 51148], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1547, "seek": 409752, "start": 4113.200000000001, "end": 4115.4400000000005, "text": " And there are lots of times in our history,", "tokens": [51148, 400, 456, 366, 3195, 295, 1413, 294, 527, 2503, 11, 51260], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1548, "seek": 409752, "start": 4115.4400000000005, "end": 4116.8, "text": " so there's the economic version of that,", "tokens": [51260, 370, 456, 311, 264, 4836, 3037, 295, 300, 11, 51328], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1549, "seek": 409752, "start": 4116.8, "end": 4118.080000000001, "text": " which is like, all right, we build something in there,", "tokens": [51328, 597, 307, 411, 11, 439, 558, 11, 321, 1322, 746, 294, 456, 11, 51392], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1550, "seek": 409752, "start": 4118.080000000001, "end": 4119.6, "text": " just like, I'm going to take a bunch of your money.", "tokens": [51392, 445, 411, 11, 286, 478, 516, 281, 747, 257, 3840, 295, 428, 1460, 13, 51468], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1551, "seek": 409752, "start": 4119.6, "end": 4123.52, "text": " But then there's the qualitative version,", "tokens": [51468, 583, 550, 456, 311, 264, 31312, 3037, 11, 51664], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1552, "seek": 409752, "start": 4123.52, "end": 4126.080000000001, "text": " which is actually what kind of upsets me more,", "tokens": [51664, 597, 307, 767, 437, 733, 295, 15497, 1385, 385, 544, 11, 51792], "temperature": 0.0, "avg_logprob": -0.12447082295137293, "compression_ratio": 1.6883561643835616, "no_speech_prob": 0.0010986177949234843}, {"id": 1553, "seek": 412608, "start": 4126.16, "end": 4127.5199999999995, "text": " which is there's a bunch of times", "tokens": [50368, 597, 307, 456, 311, 257, 3840, 295, 1413, 50436], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1554, "seek": 412608, "start": 4127.5199999999995, "end": 4130.16, "text": " when we've launched or wanted to launch features,", "tokens": [50436, 562, 321, 600, 8730, 420, 1415, 281, 4025, 4122, 11, 50568], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1555, "seek": 412608, "start": 4130.72, "end": 4133.28, "text": " and then Apple's just like, nope, you're not launching that.", "tokens": [50596, 293, 550, 6373, 311, 445, 411, 11, 23444, 11, 291, 434, 406, 18354, 300, 13, 50724], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1556, "seek": 412608, "start": 4133.28, "end": 4135.5199999999995, "text": " So, it's like, that sucks, right?", "tokens": [50724, 407, 11, 309, 311, 411, 11, 300, 15846, 11, 558, 30, 50836], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1557, "seek": 412608, "start": 4135.5199999999995, "end": 4139.44, "text": " And so, the question is, what is,", "tokens": [50836, 400, 370, 11, 264, 1168, 307, 11, 437, 307, 11, 51032], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1558, "seek": 412608, "start": 4139.44, "end": 4144.5599999999995, "text": " like, are we kind of set up for a world like that with AI,", "tokens": [51032, 411, 11, 366, 321, 733, 295, 992, 493, 337, 257, 1002, 411, 300, 365, 7318, 11, 51288], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1559, "seek": 412608, "start": 4144.5599999999995, "end": 4147.44, "text": " where like, you're going to get a handful of companies", "tokens": [51288, 689, 411, 11, 291, 434, 516, 281, 483, 257, 16458, 295, 3431, 51432], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1560, "seek": 412608, "start": 4147.44, "end": 4148.72, "text": " that run these closed models", "tokens": [51432, 300, 1190, 613, 5395, 5245, 51496], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1561, "seek": 412608, "start": 4148.72, "end": 4150.64, "text": " that are going to be in control of the APIs,", "tokens": [51496, 300, 366, 516, 281, 312, 294, 1969, 295, 264, 21445, 11, 51592], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1562, "seek": 412608, "start": 4150.64, "end": 4151.84, "text": " and therefore are going to be able to tell you", "tokens": [51592, 293, 4412, 366, 516, 281, 312, 1075, 281, 980, 291, 51652], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1563, "seek": 412608, "start": 4151.84, "end": 4152.64, "text": " what you can build.", "tokens": [51652, 437, 291, 393, 1322, 13, 51692], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1564, "seek": 412608, "start": 4153.5199999999995, "end": 4155.5199999999995, "text": " Well, for one, I can say, for us,", "tokens": [51736, 1042, 11, 337, 472, 11, 286, 393, 584, 11, 337, 505, 11, 51836], "temperature": 0.0, "avg_logprob": -0.12784942626953125, "compression_ratio": 1.745644599303136, "no_speech_prob": 0.00048780208453536034}, {"id": 1565, "seek": 415608, "start": 4156.48, "end": 4158.8, "text": " it is worth it to go build a model ourselves", "tokens": [50384, 309, 307, 3163, 309, 281, 352, 1322, 257, 2316, 4175, 50500], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1566, "seek": 415608, "start": 4158.8, "end": 4160.96, "text": " to make sure that we're not in that position, right?", "tokens": [50500, 281, 652, 988, 300, 321, 434, 406, 294, 300, 2535, 11, 558, 30, 50608], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1567, "seek": 415608, "start": 4160.96, "end": 4163.68, "text": " Like, I don't want any of those other companies", "tokens": [50608, 1743, 11, 286, 500, 380, 528, 604, 295, 729, 661, 3431, 50744], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1568, "seek": 415608, "start": 4163.68, "end": 4164.8, "text": " telling us what we can build.", "tokens": [50744, 3585, 505, 437, 321, 393, 1322, 13, 50800], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1569, "seek": 415608, "start": 4166.0, "end": 4168.0, "text": " But from an open source perspective,", "tokens": [50860, 583, 490, 364, 1269, 4009, 4585, 11, 50960], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1570, "seek": 415608, "start": 4168.0, "end": 4169.92, "text": " I think a lot of developers don't want those companies", "tokens": [50960, 286, 519, 257, 688, 295, 8849, 500, 380, 528, 729, 3431, 51056], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1571, "seek": 415608, "start": 4169.92, "end": 4171.2, "text": " telling them what they can build either.", "tokens": [51056, 3585, 552, 437, 436, 393, 1322, 2139, 13, 51120], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1572, "seek": 415608, "start": 4172.5599999999995, "end": 4175.68, "text": " So, the question is, what is the ecosystem", "tokens": [51188, 407, 11, 264, 1168, 307, 11, 437, 307, 264, 11311, 51344], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1573, "seek": 415608, "start": 4175.68, "end": 4176.88, "text": " that gets built out around that?", "tokens": [51344, 300, 2170, 3094, 484, 926, 300, 30, 51404], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1574, "seek": 415608, "start": 4176.88, "end": 4178.4, "text": " What are interesting new things?", "tokens": [51404, 708, 366, 1880, 777, 721, 30, 51480], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1575, "seek": 415608, "start": 4178.4, "end": 4180.08, "text": " How much does that improve our products?", "tokens": [51480, 1012, 709, 775, 300, 3470, 527, 3383, 30, 51564], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1576, "seek": 415608, "start": 4182.5599999999995, "end": 4183.92, "text": " I think that there's a lot of cases", "tokens": [51688, 286, 519, 300, 456, 311, 257, 688, 295, 3331, 51756], "temperature": 0.0, "avg_logprob": -0.0959968280075188, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.000646123313345015}, {"id": 1577, "seek": 418392, "start": 4183.92, "end": 4186.0, "text": " where if this ends up being like, you know,", "tokens": [50364, 689, 498, 341, 5314, 493, 885, 411, 11, 291, 458, 11, 50468], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1578, "seek": 418392, "start": 4186.0, "end": 4190.16, "text": " like our databases or caching systems or architecture,", "tokens": [50468, 411, 527, 22380, 420, 269, 2834, 3652, 420, 9482, 11, 50676], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1579, "seek": 418392, "start": 4190.72, "end": 4192.8, "text": " we'll get valuable contributions from the community", "tokens": [50704, 321, 603, 483, 8263, 15725, 490, 264, 1768, 50808], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1580, "seek": 418392, "start": 4192.8, "end": 4194.0, "text": " that will make our stuff better,", "tokens": [50808, 300, 486, 652, 527, 1507, 1101, 11, 50868], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1581, "seek": 418392, "start": 4194.0, "end": 4196.32, "text": " and then our app-specific work that we do", "tokens": [50868, 293, 550, 527, 724, 12, 29258, 589, 300, 321, 360, 50984], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1582, "seek": 418392, "start": 4196.32, "end": 4197.92, "text": " will still be so differentiated", "tokens": [50984, 486, 920, 312, 370, 27372, 770, 51064], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1583, "seek": 418392, "start": 4197.92, "end": 4199.28, "text": " that it won't really matter, right?", "tokens": [51064, 300, 309, 1582, 380, 534, 1871, 11, 558, 30, 51132], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1584, "seek": 418392, "start": 4199.28, "end": 4201.36, "text": " It's like, we'll be able to do what we do,", "tokens": [51132, 467, 311, 411, 11, 321, 603, 312, 1075, 281, 360, 437, 321, 360, 11, 51236], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1585, "seek": 418392, "start": 4201.36, "end": 4202.8, "text": " we'll benefit in all the systems,", "tokens": [51236, 321, 603, 5121, 294, 439, 264, 3652, 11, 51308], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1586, "seek": 418392, "start": 4202.8, "end": 4204.32, "text": " ours and the communities will be better", "tokens": [51308, 11896, 293, 264, 4456, 486, 312, 1101, 51384], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1587, "seek": 418392, "start": 4204.32, "end": 4205.28, "text": " because it's open source.", "tokens": [51384, 570, 309, 311, 1269, 4009, 13, 51432], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1588, "seek": 418392, "start": 4206.08, "end": 4210.32, "text": " There is one world where maybe it's not that.", "tokens": [51472, 821, 307, 472, 1002, 689, 1310, 309, 311, 406, 300, 13, 51684], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1589, "seek": 418392, "start": 4210.32, "end": 4211.52, "text": " I mean, maybe the model just ends up", "tokens": [51684, 286, 914, 11, 1310, 264, 2316, 445, 5314, 493, 51744], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1590, "seek": 418392, "start": 4211.52, "end": 4213.2, "text": " being more of the product itself.", "tokens": [51744, 885, 544, 295, 264, 1674, 2564, 13, 51828], "temperature": 0.0, "avg_logprob": -0.08229654598859401, "compression_ratio": 1.8071895424836601, "no_speech_prob": 0.012050737626850605}, {"id": 1591, "seek": 421320, "start": 4213.28, "end": 4217.76, "text": " In that case, then I think it's a trickier economic", "tokens": [50368, 682, 300, 1389, 11, 550, 286, 519, 309, 311, 257, 4282, 811, 4836, 50592], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1592, "seek": 421320, "start": 4217.76, "end": 4220.0, "text": " calculation about whether you open source that", "tokens": [50592, 17108, 466, 1968, 291, 1269, 4009, 300, 50704], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1593, "seek": 421320, "start": 4220.0, "end": 4223.2, "text": " because then you are kind of commoditizing yourself a lot.", "tokens": [50704, 570, 550, 291, 366, 733, 295, 19931, 270, 3319, 1803, 257, 688, 13, 50864], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1594, "seek": 421320, "start": 4223.84, "end": 4224.8, "text": " From what I can see so far,", "tokens": [50896, 3358, 437, 286, 393, 536, 370, 1400, 11, 50944], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1595, "seek": 421320, "start": 4224.8, "end": 4225.92, "text": " it doesn't seem like we're in that zone.", "tokens": [50944, 309, 1177, 380, 1643, 411, 321, 434, 294, 300, 6668, 13, 51000], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1596, "seek": 421320, "start": 4226.5599999999995, "end": 4228.48, "text": " Do you expect to earn significant revenue", "tokens": [51032, 1144, 291, 2066, 281, 6012, 4776, 9324, 51128], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1597, "seek": 421320, "start": 4228.48, "end": 4230.639999999999, "text": " from licensing your model to the cloud providers?", "tokens": [51128, 490, 29759, 428, 2316, 281, 264, 4588, 11330, 30, 51236], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1598, "seek": 421320, "start": 4230.639999999999, "end": 4232.72, "text": " So, they have to pay you a fee to actually serve the model?", "tokens": [51236, 407, 11, 436, 362, 281, 1689, 291, 257, 12054, 281, 767, 4596, 264, 2316, 30, 51340], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1599, "seek": 421320, "start": 4236.16, "end": 4238.639999999999, "text": " We want to have an arrangement like that,", "tokens": [51512, 492, 528, 281, 362, 364, 17620, 411, 300, 11, 51636], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1600, "seek": 421320, "start": 4238.639999999999, "end": 4240.8, "text": " but I don't know how significant it'll be.", "tokens": [51636, 457, 286, 500, 380, 458, 577, 4776, 309, 603, 312, 13, 51744], "temperature": 0.0, "avg_logprob": -0.10841501617431641, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.0005032933549955487}, {"id": 1601, "seek": 424080, "start": 4240.8, "end": 4244.64, "text": " And we have this, this is basically our license for Lama.", "tokens": [50364, 400, 321, 362, 341, 11, 341, 307, 1936, 527, 10476, 337, 441, 2404, 13, 50556], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1602, "seek": 424080, "start": 4246.8, "end": 4249.04, "text": " In a lot of ways, it's like a very permissive", "tokens": [50664, 682, 257, 688, 295, 2098, 11, 309, 311, 411, 257, 588, 4784, 891, 488, 50776], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1603, "seek": 424080, "start": 4249.04, "end": 4251.68, "text": " open source license, except that we have a limit", "tokens": [50776, 1269, 4009, 10476, 11, 3993, 300, 321, 362, 257, 4948, 50908], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1604, "seek": 424080, "start": 4251.68, "end": 4253.4400000000005, "text": " for the largest companies using it.", "tokens": [50908, 337, 264, 6443, 3431, 1228, 309, 13, 50996], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1605, "seek": 424080, "start": 4253.4400000000005, "end": 4256.24, "text": " And this is why we put that limit in,", "tokens": [50996, 400, 341, 307, 983, 321, 829, 300, 4948, 294, 11, 51136], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1606, "seek": 424080, "start": 4256.24, "end": 4258.64, "text": " is we're not trying to prevent them from using it.", "tokens": [51136, 307, 321, 434, 406, 1382, 281, 4871, 552, 490, 1228, 309, 13, 51256], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1607, "seek": 424080, "start": 4258.64, "end": 4259.92, "text": " We just want them to come talk to us", "tokens": [51256, 492, 445, 528, 552, 281, 808, 751, 281, 505, 51320], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1608, "seek": 424080, "start": 4259.92, "end": 4261.12, "text": " because if they're going to just basically", "tokens": [51320, 570, 498, 436, 434, 516, 281, 445, 1936, 51380], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1609, "seek": 424080, "start": 4261.12, "end": 4263.68, "text": " take what we built and resell it and make money off of it,", "tokens": [51380, 747, 437, 321, 3094, 293, 2025, 285, 309, 293, 652, 1460, 766, 295, 309, 11, 51508], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1610, "seek": 424080, "start": 4263.68, "end": 4266.320000000001, "text": " then it's like, okay, well, if you're like,", "tokens": [51508, 550, 309, 311, 411, 11, 1392, 11, 731, 11, 498, 291, 434, 411, 11, 51640], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1611, "seek": 424080, "start": 4267.2, "end": 4269.2, "text": " Microsoft Azure or Amazon,", "tokens": [51684, 8116, 11969, 420, 6795, 11, 51784], "temperature": 0.0, "avg_logprob": -0.10819507652605084, "compression_ratio": 1.7027972027972027, "no_speech_prob": 0.002322487998753786}, {"id": 1612, "seek": 426920, "start": 4269.679999999999, "end": 4271.2, "text": " yeah, if you're going to reselling the model,", "tokens": [50388, 1338, 11, 498, 291, 434, 516, 281, 2025, 2669, 264, 2316, 11, 50464], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1613, "seek": 426920, "start": 4271.2, "end": 4272.72, "text": " then we should have some revenue share on that.", "tokens": [50464, 550, 321, 820, 362, 512, 9324, 2073, 322, 300, 13, 50540], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1614, "seek": 426920, "start": 4272.72, "end": 4274.8, "text": " So, just come talk to us before you go do that.", "tokens": [50540, 407, 11, 445, 808, 751, 281, 505, 949, 291, 352, 360, 300, 13, 50644], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1615, "seek": 426920, "start": 4274.8, "end": 4275.76, "text": " And that's how that's played out.", "tokens": [50644, 400, 300, 311, 577, 300, 311, 3737, 484, 13, 50692], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1616, "seek": 426920, "start": 4275.76, "end": 4279.5199999999995, "text": " So, for Lama 2, it's, I mean, we basically just have deals", "tokens": [50692, 407, 11, 337, 441, 2404, 568, 11, 309, 311, 11, 286, 914, 11, 321, 1936, 445, 362, 11215, 50880], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1617, "seek": 426920, "start": 4279.5199999999995, "end": 4282.32, "text": " with all these major cloud companies,", "tokens": [50880, 365, 439, 613, 2563, 4588, 3431, 11, 51020], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1618, "seek": 426920, "start": 4282.32, "end": 4286.48, "text": " and Lama 2 is available as a hosted service on all those clouds.", "tokens": [51020, 293, 441, 2404, 568, 307, 2435, 382, 257, 19204, 2643, 322, 439, 729, 12193, 13, 51228], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1619, "seek": 426920, "start": 4288.48, "end": 4291.2, "text": " I assume that as we release bigger and bigger models,", "tokens": [51328, 286, 6552, 300, 382, 321, 4374, 3801, 293, 3801, 5245, 11, 51464], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1620, "seek": 426920, "start": 4291.2, "end": 4292.24, "text": " that'll become a bigger thing.", "tokens": [51464, 300, 603, 1813, 257, 3801, 551, 13, 51516], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1621, "seek": 426920, "start": 4292.24, "end": 4293.44, "text": " It's not the main thing that we're doing,", "tokens": [51516, 467, 311, 406, 264, 2135, 551, 300, 321, 434, 884, 11, 51576], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1622, "seek": 426920, "start": 4293.44, "end": 4295.04, "text": " but I just think if others are,", "tokens": [51576, 457, 286, 445, 519, 498, 2357, 366, 11, 51656], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1623, "seek": 426920, "start": 4295.04, "end": 4296.639999999999, "text": " if those companies are going to be selling our models,", "tokens": [51656, 498, 729, 3431, 366, 516, 281, 312, 6511, 527, 5245, 11, 51736], "temperature": 0.0, "avg_logprob": -0.11871749539918537, "compression_ratio": 1.8125, "no_speech_prob": 0.0007096107583492994}, {"id": 1624, "seek": 429664, "start": 4296.64, "end": 4298.240000000001, "text": " it makes sense that we should, you know,", "tokens": [50364, 309, 1669, 2020, 300, 321, 820, 11, 291, 458, 11, 50444], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1625, "seek": 429664, "start": 4298.240000000001, "end": 4299.6, "text": " share the upside of that somehow.", "tokens": [50444, 2073, 264, 14119, 295, 300, 6063, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1626, "seek": 429664, "start": 4299.6, "end": 4302.4800000000005, "text": " Yeah. With regards to the other open source dangers,", "tokens": [50512, 865, 13, 2022, 14258, 281, 264, 661, 1269, 4009, 27701, 11, 50656], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1627, "seek": 429664, "start": 4302.4800000000005, "end": 4304.72, "text": " I think I have a genuine legion of points", "tokens": [50656, 286, 519, 286, 362, 257, 16699, 1676, 313, 295, 2793, 50768], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1628, "seek": 429664, "start": 4304.72, "end": 4305.92, "text": " about the balance of power stuff,", "tokens": [50768, 466, 264, 4772, 295, 1347, 1507, 11, 50828], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1629, "seek": 429664, "start": 4306.96, "end": 4309.280000000001, "text": " and potentially like the harms you can get rid of", "tokens": [50880, 293, 7263, 411, 264, 48505, 291, 393, 483, 3973, 295, 50996], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1630, "seek": 429664, "start": 4309.280000000001, "end": 4311.280000000001, "text": " because we have better alignment techniques or something.", "tokens": [50996, 570, 321, 362, 1101, 18515, 7512, 420, 746, 13, 51096], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1631, "seek": 429664, "start": 4312.240000000001, "end": 4314.320000000001, "text": " I wish there was some sort of framework that Meta had,", "tokens": [51144, 286, 3172, 456, 390, 512, 1333, 295, 8388, 300, 6377, 64, 632, 11, 51248], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1632, "seek": 429664, "start": 4314.320000000001, "end": 4316.320000000001, "text": " like other labs have this where they say like,", "tokens": [51248, 411, 661, 20339, 362, 341, 689, 436, 584, 411, 11, 51348], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1633, "seek": 429664, "start": 4316.320000000001, "end": 4318.400000000001, "text": " if we see this is a concrete thing,", "tokens": [51348, 498, 321, 536, 341, 307, 257, 9859, 551, 11, 51452], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1634, "seek": 429664, "start": 4318.400000000001, "end": 4320.72, "text": " then that's a no-go on the open source,", "tokens": [51452, 550, 300, 311, 257, 572, 12, 1571, 322, 264, 1269, 4009, 11, 51568], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1635, "seek": 429664, "start": 4320.72, "end": 4323.200000000001, "text": " or like even potentially on deployment,", "tokens": [51568, 420, 411, 754, 7263, 322, 19317, 11, 51692], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1636, "seek": 429664, "start": 4323.200000000001, "end": 4326.08, "text": " just like writing it down so like the company is ready for it,", "tokens": [51692, 445, 411, 3579, 309, 760, 370, 411, 264, 2237, 307, 1919, 337, 309, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1669186689914801, "compression_ratio": 1.7566765578635015, "no_speech_prob": 0.0010003059869632125}, {"id": 1637, "seek": 432664, "start": 4326.72, "end": 4328.8, "text": " people have expectations around it and so forth.", "tokens": [50368, 561, 362, 9843, 926, 309, 293, 370, 5220, 13, 50472], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1638, "seek": 432664, "start": 4328.8, "end": 4330.64, "text": " Yeah. No, I think that that's a fair point", "tokens": [50472, 865, 13, 883, 11, 286, 519, 300, 300, 311, 257, 3143, 935, 50564], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1639, "seek": 432664, "start": 4330.64, "end": 4332.0, "text": " on the existential risk side.", "tokens": [50564, 322, 264, 37133, 3148, 1252, 13, 50632], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1640, "seek": 432664, "start": 4332.0, "end": 4334.8, "text": " Right now, we focus more on the types of risks", "tokens": [50632, 1779, 586, 11, 321, 1879, 544, 322, 264, 3467, 295, 10888, 50772], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1641, "seek": 432664, "start": 4334.8, "end": 4337.76, "text": " that we see today, which are more of these content risks.", "tokens": [50772, 300, 321, 536, 965, 11, 597, 366, 544, 295, 613, 2701, 10888, 13, 50920], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1642, "seek": 432664, "start": 4337.76, "end": 4343.12, "text": " So, you know, we have lines on, we don't want the model to be", "tokens": [50920, 407, 11, 291, 458, 11, 321, 362, 3876, 322, 11, 321, 500, 380, 528, 264, 2316, 281, 312, 51188], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1643, "seek": 432664, "start": 4344.08, "end": 4347.04, "text": " basically doing things that are helping people commit violence", "tokens": [51236, 1936, 884, 721, 300, 366, 4315, 561, 5599, 6270, 51384], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1644, "seek": 432664, "start": 4347.04, "end": 4350.320000000001, "text": " or fraud or, you know, just harming people in different ways.", "tokens": [51384, 420, 14560, 420, 11, 291, 458, 11, 445, 2233, 2810, 561, 294, 819, 2098, 13, 51548], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1645, "seek": 432664, "start": 4350.320000000001, "end": 4355.200000000001, "text": " So in practice for today's models,", "tokens": [51548, 407, 294, 3124, 337, 965, 311, 5245, 11, 51792], "temperature": 0.0, "avg_logprob": -0.09610519724443925, "compression_ratio": 1.696969696969697, "no_speech_prob": 0.0006461247685365379}, {"id": 1646, "seek": 435520, "start": 4355.2, "end": 4357.92, "text": " and I would guess the next generation", "tokens": [50364, 293, 286, 576, 2041, 264, 958, 5125, 50500], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1647, "seek": 435520, "start": 4357.92, "end": 4359.599999999999, "text": " and maybe even the generation after that,", "tokens": [50500, 293, 1310, 754, 264, 5125, 934, 300, 11, 50584], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1648, "seek": 435520, "start": 4360.32, "end": 4364.8, "text": " I think while it is somewhat more maybe intellectually interesting", "tokens": [50620, 286, 519, 1339, 309, 307, 8344, 544, 1310, 46481, 1880, 50844], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1649, "seek": 435520, "start": 4364.8, "end": 4367.04, "text": " to talk about the existential risks,", "tokens": [50844, 281, 751, 466, 264, 37133, 10888, 11, 50956], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1650, "seek": 435520, "start": 4367.599999999999, "end": 4373.84, "text": " I actually think the real harms that need more energy being mitigated", "tokens": [50984, 286, 767, 519, 264, 957, 48505, 300, 643, 544, 2281, 885, 15699, 770, 51296], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1651, "seek": 435520, "start": 4373.84, "end": 4377.84, "text": " are things that are going to like have someone take a model", "tokens": [51296, 366, 721, 300, 366, 516, 281, 411, 362, 1580, 747, 257, 2316, 51496], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1652, "seek": 435520, "start": 4377.84, "end": 4380.96, "text": " and do something to hurt a person with today's parameters", "tokens": [51496, 293, 360, 746, 281, 4607, 257, 954, 365, 965, 311, 9834, 51652], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1653, "seek": 435520, "start": 4380.96, "end": 4384.24, "text": " of and kind of the types of kind of more mundane harms", "tokens": [51652, 295, 293, 733, 295, 264, 3467, 295, 733, 295, 544, 43497, 48505, 51816], "temperature": 0.0, "avg_logprob": -0.08989357461734694, "compression_ratio": 1.7899159663865547, "no_speech_prob": 0.0007320796139538288}, {"id": 1654, "seek": 438424, "start": 4384.32, "end": 4387.28, "text": " that we see today, like people kind of committing fraud", "tokens": [50368, 300, 321, 536, 965, 11, 411, 561, 733, 295, 26659, 14560, 50516], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1655, "seek": 438424, "start": 4387.28, "end": 4388.719999999999, "text": " against each other or things like that.", "tokens": [50516, 1970, 1184, 661, 420, 721, 411, 300, 13, 50588], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1656, "seek": 438424, "start": 4388.719999999999, "end": 4393.36, "text": " So that, I just don't want to short change that.", "tokens": [50588, 407, 300, 11, 286, 445, 500, 380, 528, 281, 2099, 1319, 300, 13, 50820], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1657, "seek": 438424, "start": 4393.36, "end": 4395.28, "text": " I think we have a responsibility", "tokens": [50820, 286, 519, 321, 362, 257, 6357, 50916], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1658, "seek": 438424, "start": 4395.28, "end": 4396.96, "text": " to make sure we do a good job on that.", "tokens": [50916, 281, 652, 988, 321, 360, 257, 665, 1691, 322, 300, 13, 51000], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1659, "seek": 438424, "start": 4396.96, "end": 4398.88, "text": " Yeah, Meta's a big company, you can handle both.", "tokens": [51000, 865, 11, 6377, 64, 311, 257, 955, 2237, 11, 291, 393, 4813, 1293, 13, 51096], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1660, "seek": 438424, "start": 4398.88, "end": 4402.96, "text": " Yeah. Okay, so as far as the open source goes,", "tokens": [51096, 865, 13, 1033, 11, 370, 382, 1400, 382, 264, 1269, 4009, 1709, 11, 51300], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1661, "seek": 438424, "start": 4402.96, "end": 4405.5199999999995, "text": " I'm actually curious if you think the impact of the open source", "tokens": [51300, 286, 478, 767, 6369, 498, 291, 519, 264, 2712, 295, 264, 1269, 4009, 51428], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1662, "seek": 438424, "start": 4405.5199999999995, "end": 4408.32, "text": " from PyTorch, React, open compute, these things", "tokens": [51428, 490, 9953, 51, 284, 339, 11, 30644, 11, 1269, 14722, 11, 613, 721, 51568], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1663, "seek": 438424, "start": 4408.32, "end": 4409.84, "text": " has been bigger for the world", "tokens": [51568, 575, 668, 3801, 337, 264, 1002, 51644], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1664, "seek": 438424, "start": 4409.84, "end": 4412.0, "text": " than even the social media aspects of Meta.", "tokens": [51644, 813, 754, 264, 2093, 3021, 7270, 295, 6377, 64, 13, 51752], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1665, "seek": 438424, "start": 4412.0, "end": 4413.599999999999, "text": " Because I like talk to people who use these services", "tokens": [51752, 1436, 286, 411, 751, 281, 561, 567, 764, 613, 3328, 51832], "temperature": 0.0, "avg_logprob": -0.12546352287391563, "compression_ratio": 1.6850152905198776, "no_speech_prob": 0.001244490616954863}, {"id": 1666, "seek": 441360, "start": 4413.6, "end": 4414.8, "text": " and think like it's plausible", "tokens": [50364, 293, 519, 411, 309, 311, 39925, 50424], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1667, "seek": 441360, "start": 4414.8, "end": 4416.56, "text": " because a big part of the internet runs on these things.", "tokens": [50424, 570, 257, 955, 644, 295, 264, 4705, 6676, 322, 613, 721, 13, 50512], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1668, "seek": 441360, "start": 4418.96, "end": 4420.160000000001, "text": " It's an interesting question.", "tokens": [50632, 467, 311, 364, 1880, 1168, 13, 50692], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1669, "seek": 441360, "start": 4420.160000000001, "end": 4423.360000000001, "text": " I mean, I think almost half the world uses our...", "tokens": [50692, 286, 914, 11, 286, 519, 1920, 1922, 264, 1002, 4960, 527, 485, 50852], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1670, "seek": 441360, "start": 4423.360000000001, "end": 4424.8, "text": " Yeah, that's an interesting point.", "tokens": [50852, 865, 11, 300, 311, 364, 1880, 935, 13, 50924], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1671, "seek": 441360, "start": 4427.360000000001, "end": 4429.76, "text": " So I think it's hard to beat that.", "tokens": [51052, 407, 286, 519, 309, 311, 1152, 281, 4224, 300, 13, 51172], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1672, "seek": 441360, "start": 4429.76, "end": 4432.88, "text": " But no, I think open sources,", "tokens": [51172, 583, 572, 11, 286, 519, 1269, 7139, 11, 51328], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1673, "seek": 441360, "start": 4434.56, "end": 4437.360000000001, "text": " it's really powerful as a new way of building things.", "tokens": [51412, 309, 311, 534, 4005, 382, 257, 777, 636, 295, 2390, 721, 13, 51552], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1674, "seek": 441360, "start": 4437.360000000001, "end": 4441.6, "text": " And yeah, I mean, it's possible.", "tokens": [51552, 400, 1338, 11, 286, 914, 11, 309, 311, 1944, 13, 51764], "temperature": 0.0, "avg_logprob": -0.20254947588993952, "compression_ratio": 1.680952380952381, "no_speech_prob": 0.0030746646225452423}, {"id": 1675, "seek": 444160, "start": 4441.6, "end": 4443.92, "text": " I mean, it's maybe one of these things where...", "tokens": [50364, 286, 914, 11, 309, 311, 1310, 472, 295, 613, 721, 689, 485, 50480], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1676, "seek": 444160, "start": 4446.320000000001, "end": 4449.52, "text": " I don't know, like Bell Labs, where they...", "tokens": [50600, 286, 500, 380, 458, 11, 411, 11485, 40047, 11, 689, 436, 485, 50760], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1677, "seek": 444160, "start": 4449.52, "end": 4452.88, "text": " It's like they were working on the transistor", "tokens": [50760, 467, 311, 411, 436, 645, 1364, 322, 264, 34750, 50928], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1678, "seek": 444160, "start": 4452.88, "end": 4455.360000000001, "text": " because they wanted to enable long distance calling.", "tokens": [50928, 570, 436, 1415, 281, 9528, 938, 4560, 5141, 13, 51052], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1679, "seek": 444160, "start": 4455.92, "end": 4457.280000000001, "text": " And they did.", "tokens": [51080, 400, 436, 630, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1680, "seek": 444160, "start": 4457.280000000001, "end": 4459.120000000001, "text": " And it ended up being really profitable for them", "tokens": [51148, 400, 309, 4590, 493, 885, 534, 21608, 337, 552, 51240], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1681, "seek": 444160, "start": 4459.120000000001, "end": 4461.120000000001, "text": " that they were able to enable long distance calling.", "tokens": [51240, 300, 436, 645, 1075, 281, 9528, 938, 4560, 5141, 13, 51340], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1682, "seek": 444160, "start": 4461.120000000001, "end": 4465.4400000000005, "text": " And if you ask them five to 10 years out from that,", "tokens": [51340, 400, 498, 291, 1029, 552, 1732, 281, 1266, 924, 484, 490, 300, 11, 51556], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1683, "seek": 444160, "start": 4467.280000000001, "end": 4469.6, "text": " what was the most useful thing that they invented?", "tokens": [51648, 437, 390, 264, 881, 4420, 551, 300, 436, 14479, 30, 51764], "temperature": 0.0, "avg_logprob": -0.13566576993023907, "compression_ratio": 1.7782608695652173, "no_speech_prob": 0.000910955888684839}, {"id": 1684, "seek": 446960, "start": 4469.6, "end": 4471.4400000000005, "text": " It's like, okay, well, we enable long distance calling", "tokens": [50364, 467, 311, 411, 11, 1392, 11, 731, 11, 321, 9528, 938, 4560, 5141, 50456], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1685, "seek": 446960, "start": 4471.4400000000005, "end": 4473.04, "text": " and now all these people are long distance calling.", "tokens": [50456, 293, 586, 439, 613, 561, 366, 938, 4560, 5141, 13, 50536], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1686, "seek": 446960, "start": 4473.04, "end": 4474.400000000001, "text": " But if you ask 100 years later,", "tokens": [50536, 583, 498, 291, 1029, 2319, 924, 1780, 11, 50604], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1687, "seek": 446960, "start": 4474.400000000001, "end": 4475.76, "text": " maybe it's a different question.", "tokens": [50604, 1310, 309, 311, 257, 819, 1168, 13, 50672], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1688, "seek": 446960, "start": 4475.76, "end": 4480.320000000001, "text": " So I think that that's true of a lot of the things", "tokens": [50672, 407, 286, 519, 300, 300, 311, 2074, 295, 257, 688, 295, 264, 721, 50900], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1689, "seek": 446960, "start": 4480.320000000001, "end": 4481.280000000001, "text": " that we're building, right?", "tokens": [50900, 300, 321, 434, 2390, 11, 558, 30, 50948], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1690, "seek": 446960, "start": 4481.280000000001, "end": 4485.280000000001, "text": " Reality Labs, some of the AI stuff, some of the open source stuff.", "tokens": [50948, 33822, 40047, 11, 512, 295, 264, 7318, 1507, 11, 512, 295, 264, 1269, 4009, 1507, 13, 51148], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1691, "seek": 446960, "start": 4485.280000000001, "end": 4488.4800000000005, "text": " I think it's like the specific products evolve", "tokens": [51148, 286, 519, 309, 311, 411, 264, 2685, 3383, 16693, 51308], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1692, "seek": 446960, "start": 4488.4800000000005, "end": 4490.400000000001, "text": " and to some degree come and go.", "tokens": [51308, 293, 281, 512, 4314, 808, 293, 352, 13, 51404], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1693, "seek": 446960, "start": 4490.400000000001, "end": 4494.08, "text": " But I think like the advances for humanity persist.", "tokens": [51404, 583, 286, 519, 411, 264, 25297, 337, 10243, 13233, 13, 51588], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1694, "seek": 446960, "start": 4494.08, "end": 4497.360000000001, "text": " And that's like a cool part of what we all get to do.", "tokens": [51588, 400, 300, 311, 411, 257, 1627, 644, 295, 437, 321, 439, 483, 281, 360, 13, 51752], "temperature": 0.0, "avg_logprob": -0.11144884654453822, "compression_ratio": 1.7370242214532872, "no_speech_prob": 0.0006262215902097523}, {"id": 1695, "seek": 449736, "start": 4498.08, "end": 4499.92, "text": " By when will the Lama models be trained", "tokens": [50400, 3146, 562, 486, 264, 441, 2404, 5245, 312, 8895, 50492], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1696, "seek": 449736, "start": 4499.92, "end": 4501.04, "text": " on your own custom silicon?", "tokens": [50492, 322, 428, 1065, 2375, 22848, 30, 50548], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1697, "seek": 449736, "start": 4506.48, "end": 4508.32, "text": " Soon, not Lama 4.", "tokens": [50820, 17610, 11, 406, 441, 2404, 1017, 13, 50912], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1698, "seek": 449736, "start": 4509.759999999999, "end": 4514.639999999999, "text": " The approach that we took is first we basically built", "tokens": [50984, 440, 3109, 300, 321, 1890, 307, 700, 321, 1936, 3094, 51228], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1699, "seek": 449736, "start": 4514.639999999999, "end": 4516.5599999999995, "text": " custom silicon that could handle inference", "tokens": [51228, 2375, 22848, 300, 727, 4813, 38253, 51324], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1700, "seek": 449736, "start": 4517.2, "end": 4520.0, "text": " for our ranking and recommendation type stuff.", "tokens": [51356, 337, 527, 17833, 293, 11879, 2010, 1507, 13, 51496], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1701, "seek": 449736, "start": 4520.0, "end": 4522.5599999999995, "text": " So reels, newsfeed, ads.", "tokens": [51496, 407, 319, 1625, 11, 2583, 37036, 11, 10342, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1702, "seek": 449736, "start": 4523.2, "end": 4526.799999999999, "text": " And that was consuming a lot of GPUs.", "tokens": [51656, 400, 300, 390, 19867, 257, 688, 295, 18407, 82, 13, 51836], "temperature": 0.0, "avg_logprob": -0.1630673059603063, "compression_ratio": 1.4673366834170853, "no_speech_prob": 0.0026314198039472103}, {"id": 1703, "seek": 452736, "start": 4528.0, "end": 4530.799999999999, "text": " But when we were able to move that to our own silicon,", "tokens": [50396, 583, 562, 321, 645, 1075, 281, 1286, 300, 281, 527, 1065, 22848, 11, 50536], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1704, "seek": 452736, "start": 4530.799999999999, "end": 4534.719999999999, "text": " we now were able to use the more expensive Nvidia GPUs", "tokens": [50536, 321, 586, 645, 1075, 281, 764, 264, 544, 5124, 46284, 18407, 82, 50732], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1705, "seek": 452736, "start": 4535.44, "end": 4536.48, "text": " only for training.", "tokens": [50768, 787, 337, 3097, 13, 50820], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1706, "seek": 452736, "start": 4537.12, "end": 4544.48, "text": " So at some point, we will hopefully have silicon ourselves", "tokens": [50852, 407, 412, 512, 935, 11, 321, 486, 4696, 362, 22848, 4175, 51220], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1707, "seek": 452736, "start": 4544.48, "end": 4547.599999999999, "text": " that we can be using for probably first training", "tokens": [51220, 300, 321, 393, 312, 1228, 337, 1391, 700, 3097, 51376], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1708, "seek": 452736, "start": 4547.599999999999, "end": 4549.679999999999, "text": " some of the simpler things that eventually training", "tokens": [51376, 512, 295, 264, 18587, 721, 300, 4728, 3097, 51480], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1709, "seek": 452736, "start": 4550.5599999999995, "end": 4553.2, "text": " these like really large models.", "tokens": [51524, 613, 411, 534, 2416, 5245, 13, 51656], "temperature": 0.0, "avg_logprob": -0.09635310836985142, "compression_ratio": 1.6, "no_speech_prob": 0.00013134416076354682}, {"id": 1710, "seek": 455320, "start": 4553.84, "end": 4558.16, "text": " But in the meantime, I'd say the program is going quite well", "tokens": [50396, 583, 294, 264, 14991, 11, 286, 1116, 584, 264, 1461, 307, 516, 1596, 731, 50612], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1711, "seek": 455320, "start": 4558.16, "end": 4559.92, "text": " and we're just rolling it out methodically", "tokens": [50612, 293, 321, 434, 445, 9439, 309, 484, 3170, 984, 50700], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1712, "seek": 455320, "start": 4559.92, "end": 4561.599999999999, "text": " and have a long-term roadmap for it.", "tokens": [50700, 293, 362, 257, 938, 12, 7039, 35738, 337, 309, 13, 50784], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1713, "seek": 455320, "start": 4562.8, "end": 4563.76, "text": " Final question.", "tokens": [50844, 13443, 1168, 13, 50892], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1714, "seek": 455320, "start": 4563.76, "end": 4565.12, "text": " This is sort of the out of left field,", "tokens": [50892, 639, 307, 1333, 295, 264, 484, 295, 1411, 2519, 11, 50960], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1715, "seek": 455320, "start": 4565.12, "end": 4568.639999999999, "text": " but if you were made CEO of Google+, could you have made it work?", "tokens": [50960, 457, 498, 291, 645, 1027, 9282, 295, 3329, 46797, 727, 291, 362, 1027, 309, 589, 30, 51136], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1716, "seek": 455320, "start": 4568.639999999999, "end": 4570.24, "text": " Google+, oof.", "tokens": [51136, 3329, 46797, 277, 2670, 13, 51216], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1717, "seek": 455320, "start": 4571.44, "end": 4572.8, "text": " Well, I don't know.", "tokens": [51276, 1042, 11, 286, 500, 380, 458, 13, 51344], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1718, "seek": 455320, "start": 4574.16, "end": 4574.72, "text": " I don't know.", "tokens": [51412, 286, 500, 380, 458, 13, 51440], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1719, "seek": 455320, "start": 4574.72, "end": 4578.8, "text": " That's a very difficult, very difficult counterfactual.", "tokens": [51440, 663, 311, 257, 588, 2252, 11, 588, 2252, 5682, 44919, 901, 13, 51644], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1720, "seek": 455320, "start": 4579.44, "end": 4581.04, "text": " Okay, then the real final question will be", "tokens": [51676, 1033, 11, 550, 264, 957, 2572, 1168, 486, 312, 51756], "temperature": 0.0, "avg_logprob": -0.14821034093056956, "compression_ratio": 1.5875486381322956, "no_speech_prob": 0.025948811322450638}, {"id": 1721, "seek": 458104, "start": 4581.04, "end": 4582.48, "text": " when Gemini was launched,", "tokens": [50364, 562, 22894, 3812, 390, 8730, 11, 50436], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1722, "seek": 458104, "start": 4582.48, "end": 4584.72, "text": " was there any chance that somebody in the office", "tokens": [50436, 390, 456, 604, 2931, 300, 2618, 294, 264, 3398, 50548], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1723, "seek": 458104, "start": 4584.72, "end": 4586.08, "text": " uttered Karthica Dalinda Est?", "tokens": [50548, 17567, 292, 8009, 392, 2262, 17357, 6837, 4410, 30, 50616], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1724, "seek": 458104, "start": 4587.6, "end": 4589.5199999999995, "text": " No, I think we're tamer now.", "tokens": [50692, 883, 11, 286, 519, 321, 434, 7677, 260, 586, 13, 50788], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1725, "seek": 458104, "start": 4590.72, "end": 4591.5199999999995, "text": " Cool, cool.", "tokens": [50848, 8561, 11, 1627, 13, 50888], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1726, "seek": 458104, "start": 4591.5199999999995, "end": 4592.16, "text": " Awesome, Mark.", "tokens": [50888, 10391, 11, 3934, 13, 50920], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1727, "seek": 458104, "start": 4595.68, "end": 4596.8, "text": " Yeah, I don't know.", "tokens": [51096, 865, 11, 286, 500, 380, 458, 13, 51152], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1728, "seek": 458104, "start": 4596.8, "end": 4597.36, "text": " It's a good question.", "tokens": [51152, 467, 311, 257, 665, 1168, 13, 51180], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1729, "seek": 458104, "start": 4598.72, "end": 4601.12, "text": " The problem is there was no CEO of Google+,", "tokens": [51248, 440, 1154, 307, 456, 390, 572, 9282, 295, 3329, 46797, 51368], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1730, "seek": 458104, "start": 4601.12, "end": 4603.12, "text": " it was just like a division within a company.", "tokens": [51368, 309, 390, 445, 411, 257, 10044, 1951, 257, 2237, 13, 51468], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1731, "seek": 458104, "start": 4603.84, "end": 4606.16, "text": " I think it's like, and you asked before about", "tokens": [51504, 286, 519, 309, 311, 411, 11, 293, 291, 2351, 949, 466, 51620], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1732, "seek": 458104, "start": 4606.16, "end": 4608.56, "text": " what are the kind of scarcest commodities,", "tokens": [51620, 437, 366, 264, 733, 295, 10569, 66, 377, 40777, 11, 51740], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1733, "seek": 458104, "start": 4608.56, "end": 4610.24, "text": " but you asked about it in terms of dollars.", "tokens": [51740, 457, 291, 2351, 466, 309, 294, 2115, 295, 3808, 13, 51824], "temperature": 0.0, "avg_logprob": -0.20147165611608706, "compression_ratio": 1.5232974910394266, "no_speech_prob": 0.006095299031585455}, {"id": 1734, "seek": 461024, "start": 4610.8, "end": 4612.8, "text": " And I actually think for most companies,", "tokens": [50392, 400, 286, 767, 519, 337, 881, 3431, 11, 50492], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1735, "seek": 461024, "start": 4613.679999999999, "end": 4617.28, "text": " it's, of this scale at least, it's focus, right?", "tokens": [50536, 309, 311, 11, 295, 341, 4373, 412, 1935, 11, 309, 311, 1879, 11, 558, 30, 50716], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1736, "seek": 461024, "start": 4617.28, "end": 4618.4, "text": " It's like when you're a startup,", "tokens": [50716, 467, 311, 411, 562, 291, 434, 257, 18578, 11, 50772], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1737, "seek": 461024, "start": 4618.4, "end": 4620.0, "text": " maybe you're more constrained on capital.", "tokens": [50772, 1310, 291, 434, 544, 38901, 322, 4238, 13, 50852], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1738, "seek": 461024, "start": 4621.12, "end": 4623.2, "text": " You know, you just are working on one idea", "tokens": [50908, 509, 458, 11, 291, 445, 366, 1364, 322, 472, 1558, 51012], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1739, "seek": 461024, "start": 4623.2, "end": 4625.28, "text": " and you might not have all the resources.", "tokens": [51012, 293, 291, 1062, 406, 362, 439, 264, 3593, 13, 51116], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1740, "seek": 461024, "start": 4625.28, "end": 4627.36, "text": " I think you cross some threshold at some point", "tokens": [51116, 286, 519, 291, 3278, 512, 14678, 412, 512, 935, 51220], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1741, "seek": 461024, "start": 4627.36, "end": 4629.599999999999, "text": " where the nature of what you're doing,", "tokens": [51220, 689, 264, 3687, 295, 437, 291, 434, 884, 11, 51332], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1742, "seek": 461024, "start": 4629.599999999999, "end": 4631.12, "text": " you're building multiple things", "tokens": [51332, 291, 434, 2390, 3866, 721, 51408], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1743, "seek": 461024, "start": 4631.12, "end": 4633.12, "text": " and you're creating more value across them,", "tokens": [51408, 293, 291, 434, 4084, 544, 2158, 2108, 552, 11, 51508], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1744, "seek": 461024, "start": 4633.12, "end": 4637.36, "text": " but you become more constrained on what can you direct", "tokens": [51508, 457, 291, 1813, 544, 38901, 322, 437, 393, 291, 2047, 51720], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1745, "seek": 461024, "start": 4637.36, "end": 4639.2, "text": " and to go well.", "tokens": [51720, 293, 281, 352, 731, 13, 51812], "temperature": 0.0, "avg_logprob": -0.12015346324805057, "compression_ratio": 1.7214285714285715, "no_speech_prob": 0.0006877176347188652}, {"id": 1746, "seek": 463920, "start": 4639.2, "end": 4641.92, "text": " And like, there's always the cases", "tokens": [50364, 400, 411, 11, 456, 311, 1009, 264, 3331, 50500], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1747, "seek": 463920, "start": 4641.92, "end": 4644.0, "text": " where something just random awesome happens", "tokens": [50500, 689, 746, 445, 4974, 3476, 2314, 50604], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1748, "seek": 463920, "start": 4644.0, "end": 4645.84, "text": " in the organization, I don't even know about it.", "tokens": [50604, 294, 264, 4475, 11, 286, 500, 380, 754, 458, 466, 309, 13, 50696], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1749, "seek": 463920, "start": 4645.84, "end": 4648.16, "text": " And those are, that's great.", "tokens": [50696, 400, 729, 366, 11, 300, 311, 869, 13, 50812], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1750, "seek": 463920, "start": 4648.16, "end": 4649.5199999999995, "text": " But like, but I think in general,", "tokens": [50812, 583, 411, 11, 457, 286, 519, 294, 2674, 11, 50880], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1751, "seek": 463920, "start": 4650.639999999999, "end": 4653.679999999999, "text": " the organization's capacity is largely limited", "tokens": [50936, 264, 4475, 311, 6042, 307, 11611, 5567, 51088], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1752, "seek": 463920, "start": 4653.679999999999, "end": 4658.48, "text": " by what like the CEO and the management team", "tokens": [51088, 538, 437, 411, 264, 9282, 293, 264, 4592, 1469, 51328], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1753, "seek": 463920, "start": 4658.48, "end": 4661.44, "text": " are able to kind of oversee and kind of manage.", "tokens": [51328, 366, 1075, 281, 733, 295, 46543, 293, 733, 295, 3067, 13, 51476], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1754, "seek": 463920, "start": 4662.48, "end": 4665.36, "text": " I think that that's just been a big focus for us.", "tokens": [51528, 286, 519, 300, 300, 311, 445, 668, 257, 955, 1879, 337, 505, 13, 51672], "temperature": 0.0, "avg_logprob": -0.12896647962551672, "compression_ratio": 1.6170212765957446, "no_speech_prob": 0.0005032917833887041}, {"id": 1755, "seek": 466536, "start": 4665.36, "end": 4669.599999999999, "text": " It's like, all right, keep the, as I guess Ben Horowitz says,", "tokens": [50364, 467, 311, 411, 11, 439, 558, 11, 1066, 264, 11, 382, 286, 2041, 3964, 10691, 22799, 1619, 11, 50576], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1756, "seek": 466536, "start": 4669.599999999999, "end": 4671.92, "text": " keep the main thing, the main thing, right?", "tokens": [50576, 1066, 264, 2135, 551, 11, 264, 2135, 551, 11, 558, 30, 50692], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1757, "seek": 466536, "start": 4671.92, "end": 4677.44, "text": " And try to kind of stay focused on your key priorities.", "tokens": [50692, 400, 853, 281, 733, 295, 1754, 5178, 322, 428, 2141, 15503, 13, 50968], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1758, "seek": 466536, "start": 4678.0, "end": 4679.599999999999, "text": " Yeah, all right, awesome.", "tokens": [50996, 865, 11, 439, 558, 11, 3476, 13, 51076], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1759, "seek": 466536, "start": 4679.599999999999, "end": 4680.4, "text": " That was excellent, Mark.", "tokens": [51076, 663, 390, 7103, 11, 3934, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1760, "seek": 466536, "start": 4680.4, "end": 4681.5199999999995, "text": " Thanks so much. That was a lot of fun.", "tokens": [51116, 2561, 370, 709, 13, 663, 390, 257, 688, 295, 1019, 13, 51172], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1761, "seek": 466536, "start": 4681.5199999999995, "end": 4682.719999999999, "text": " Yeah, really fun.", "tokens": [51172, 865, 11, 534, 1019, 13, 51232], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1762, "seek": 466536, "start": 4682.719999999999, "end": 4683.44, "text": " Thanks for having me.", "tokens": [51232, 2561, 337, 1419, 385, 13, 51268], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1763, "seek": 466536, "start": 4683.44, "end": 4684.16, "text": " Yeah, absolutely.", "tokens": [51268, 865, 11, 3122, 13, 51304], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1764, "seek": 466536, "start": 4684.96, "end": 4685.839999999999, "text": " Hey, everybody.", "tokens": [51344, 1911, 11, 2201, 13, 51388], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1765, "seek": 466536, "start": 4685.839999999999, "end": 4687.92, "text": " I hope you enjoyed that episode with Mark.", "tokens": [51388, 286, 1454, 291, 4626, 300, 3500, 365, 3934, 13, 51492], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1766, "seek": 466536, "start": 4687.92, "end": 4689.759999999999, "text": " As you can see, I'm now doing ads.", "tokens": [51492, 1018, 291, 393, 536, 11, 286, 478, 586, 884, 10342, 13, 51584], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1767, "seek": 466536, "start": 4689.759999999999, "end": 4692.799999999999, "text": " So if you're interested in advertising on the podcast,", "tokens": [51584, 407, 498, 291, 434, 3102, 294, 13097, 322, 264, 7367, 11, 51736], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1768, "seek": 466536, "start": 4692.799999999999, "end": 4694.16, "text": " go to the link in the description.", "tokens": [51736, 352, 281, 264, 2113, 294, 264, 3855, 13, 51804], "temperature": 0.0, "avg_logprob": -0.1281153026380037, "compression_ratio": 1.6860068259385665, "no_speech_prob": 0.015903698280453682}, {"id": 1769, "seek": 469416, "start": 4694.8, "end": 4697.5199999999995, "text": " Otherwise, as you know, the most helpful thing you can do", "tokens": [50396, 10328, 11, 382, 291, 458, 11, 264, 881, 4961, 551, 291, 393, 360, 50532], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}, {"id": 1770, "seek": 469416, "start": 4697.5199999999995, "end": 4700.24, "text": " is just share the podcast with people who you think", "tokens": [50532, 307, 445, 2073, 264, 7367, 365, 561, 567, 291, 519, 50668], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}, {"id": 1771, "seek": 469416, "start": 4700.24, "end": 4701.04, "text": " might enjoy it.", "tokens": [50668, 1062, 2103, 309, 13, 50708], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}, {"id": 1772, "seek": 469416, "start": 4701.04, "end": 4703.04, "text": " You know, your friends, group chats, Twitter,", "tokens": [50708, 509, 458, 11, 428, 1855, 11, 1594, 38057, 11, 5794, 11, 50808], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}, {"id": 1773, "seek": 469416, "start": 4703.68, "end": 4704.5599999999995, "text": " I guess threads.", "tokens": [50840, 286, 2041, 19314, 13, 50884], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}, {"id": 1774, "seek": 469416, "start": 4705.12, "end": 4707.68, "text": " Yeah, I hope you enjoyed and I'll see you on the next one.", "tokens": [50912, 865, 11, 286, 1454, 291, 4626, 293, 286, 603, 536, 291, 322, 264, 958, 472, 13, 51040], "temperature": 0.0, "avg_logprob": -0.14943228976827272, "compression_ratio": 1.4702380952380953, "no_speech_prob": 0.009122518822550774}], "language": "en"}