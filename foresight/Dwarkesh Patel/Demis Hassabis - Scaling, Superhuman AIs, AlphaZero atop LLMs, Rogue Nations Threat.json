{"text": " So I wouldn't be surprised if we had AGI-like systems within the next decade. It was pretty surprising to almost everyone, including the people who first worked on the scaling hypotheses, that how far it's gone. In a way, I look at the large models today, and I think they're almost unreasonably effective for what they are. It's an empirical question whether that will hit an asymptote or a brick wall. I think no one knows. When you think about superhuman intelligence, is it still controlled by a private company? As Gemini becoming more multimodal, and we start ingesting audio-visual data, as well as text data, I do think our systems are going to start to understand the physics of the real world better. The world's about to become very exciting, I think, in the next few years as we start getting used to the idea of what true multimodality means. OK, today it is a true honor to speak with Demis Isavis, who is the CEO of DeepMind. Demis, welcome to the podcast. Thanks for having me. First question, given your neuroscience background, how do you think about intelligence? Specifically, do you think it's like one higher-level general reasoning circuit, or do you think it's thousands of independent sub-scales and heuristics? Well, it's interesting because intelligence is so broad, and what we use it for is so generally applicable. I think that suggests that there must be some sort of high-level common things, common algorithmic themes, I think, around how the brain processes the world around us. So of course, then there are specialized parts of the brain that do specific things. But I think there are probably some underlying principles that underpin all of that. Yeah, how do you make sense of the fact that in these LLMs, though, when you give them a lot of data in any specific domain, they tend to get asymmetrically better in that domain? Wouldn't we expect a general improvement across all the different areas? Well, I think you first of all, I think you do actually sometimes get surprising improvement in other domains when you improve in a specific domain. So for example, when these large models sort of improve at coding, that can actually improve their general reasoning. So there is some evidence of some transfer, though I think we would like a lot more evidence of that. But also, that's how the human brain learns, too, is if we experience and practice a lot of things like chess or writing, creative writing, or whatever that is, we also tend to specialize and get better at that specific thing. Even though we're using sort of general learning techniques and general learning systems in order to get good at that domain. Yeah, well, what's been the most surprising example of this kind of transfer for you? Like, you see language and code or images and text? Yeah, I think probably, I mean, I'm hoping we're going to see a lot more of this China transfer. But I think things like getting better at coding and math and generally improving your reasoning, that is how it works with us as human learners. But I think it's interesting seeing that in these artificial systems. And can you see the sort of mechanistic way in which, let's say in the language and code example, there's like, I found a place in a neural network that's getting better with both the language and the code. Is that too far down the weeds? Yeah, well, I don't think our analysis techniques are quite sophisticated enough to be able to hone in on that. I think that's actually one of the areas that a lot more research needs to be done on kind of mechanistic analysis of the representations that these systems build up. And I sometimes like to call it virtual brain analytics. In a way, it's a bit like doing fMRI or a single cell recording from a real brain. What's the analogous sort of analysis techniques for these artificial minds? And there's a lot of great work going on on this sort of stuff. People like Chris Ola, I really like his work. And a lot of computational neuroscience techniques, I think, could be brought to bear on analyzing these current systems we're building. In fact, I try to encourage a lot of my computational neuroscience friends to start thinking in that direction and applying their know-how to the large models. Yeah, what do other researchers not understand about human intelligence that you have some sort of insight on, given your neuroscience background? I think neuroscience has added a lot. If you look at the last sort of 10, 20 years that we've been at it, at least. And I've been thinking about this for 30 plus years. I think in the earlier days of this sort of new wave of AI, I think neuroscience was providing a lot of interesting directional clues. So things like reinforcement learning, combining that with deep learning, some of our pioneering work we did there, things like experience replay, even the notion of attention, which has become super important. A lot of those original sort of inspirations come from some understanding about how the brain works. Not the exact specifics. Of course, one's an engineered system. The other one's a natural system. So it's not so much about a one-to-one mapping of a specific algorithm. It's more kind of inspirational direction, maybe some ideas for architecture or algorithmic ideas or representational ideas. And because you know the brains in existence prove that general intelligence is possible at all, I think the history of human endeavors has been that once you know something's possible, it's easier to push hard in that direction. Because you know it's a question of effort then and sort of a question of when, not if. And that allows you to I think make progress a lot more quickly. So I think neurosciences has had a lot of, has inspired a lot of the thinking, at least in a soft way behind where we are today. But as for going forwards, I think that there's still a lot of interesting things to be resolved around planning and how does the brain construct the right world models. I studied for example, how the brain does imagination, or you can think of it as a mental simulation. So how do we create very rich visual spatial simulations of the world in order for us to plan better? Yeah, actually I'm curious how you think that will sort of interface with LLM. So obviously DeepMinders are the frontier and has been for many years, systems like AlphaZero and so forth, of having these agents who can like think through different steps to get to an end outcome. All right, will this just be, is a path for LLMs to have this sort of tree search kind of thing on top of them? How do you think about this? I think that's a super promising direction in my opinion. So we've got to carry on improving the large models and we've got to carry on basically making the more and more accurate predictors of the world. So in effect, making them more and more reliable world models, that's clearly unnecessary, but I would say probably not sufficient component of an AGI system. And then on top of that, I would, we're working on things like AlphaZero, like planning mechanisms on top that make use of that model in order to make concrete plans to achieve certain goals in the world and perhaps sort of chain thought together or lines of reasoning together and maybe use search to kind of explore massive spaces of possibility. I think that's kind of missing from our current large models. How do you get past the sort of immense amount of compute that these approaches tend to require? So even the AlphaGo system was a pretty expensive system because you had to do the sort of running an LLM on each node of the tree. How do you anticipate that will get more, made more efficient? Well, I mean, one thing is Moore's law tends to help if every year, of course, more computation comes in, but we focus a lot on efficient, sample efficient methods and reusing existing data, things like experience replay, and also just looking at more efficient ways. I mean, the better your world model is, the more efficient your search can be. So one example I always get with AlphaZero, our system to play Go and chess and any game, is that it's stronger than world champion level, human world champion level at all these games. And it uses a lot less search than a brute force method like Deep Blue, say to play chess. Deep Blue, one of these traditional stockfish or Deep Blue systems would maybe look at millions of possible moves for every decision it's gonna make. AlphaZero and AlphaGo made, you know, looked at around tens of thousands of possible positions in order to make a decision about what to move next. But a human grandmaster, a human world champion, probably only looks at a few hundreds of moves, even the top ones, in order to make their very good decision about what to play next. So that suggests that obviously the brute force systems don't have any real model other than heuristics about the game. AlphaZero has quite a decent model, but the human, you know, top human players have a much richer, much more accurate model than of Go or chess. So that allows them to make, you know, world class decisions on a very small amount of search. So I think there's still, there's a sort of trade off there, like, you know, if you improve the models, then I think your search can be more efficient and therefore you can get further with your search. Yeah, I have two questions based on that. The first being with AlphaZero, you had a very concrete win condition of, you know, at the end of the day, do I win this game or not? And you can reinforce on that. When you're just thinking of like an LLM, putting out thought, what will, do you think there'll be this kind of ability to discriminate in the end, whether that was like a good thing to reward or not? Well, of course that's why we, you know, we pioneered and DeepMind sort of famous for using games as a proving ground, partly because obviously it's efficient to research in that domain. But the other reason is obviously it's, you know, extremely easy to specify a reward function, winning the game or improving the score, something like that sort of built into most games. So that is one of the challenges of real world systems is how does one define the right objective function, the right reward function and the right goals and specify them in a, you know, in a general way, but that's specific enough and actually points the system in the right direction. And for real world problems, that can be a lot harder. But actually, if you think about it in even scientific problems, there are usually ways that you can specify the goal that you're after. And then when you think about human intelligence, you're just saying, well, you know, the humans thinking about these thoughts are just super sample efficient. How do you, I understand coming up with relativity, right? There's just like thousands of possible permutations of the equations. Do you think it's also this sort of sense of like different heuristics of like, I'm going to try out this approach instead of this or is it a totally different way of approaching coming up with a solution than, you know, what AlphaGo does to plan the next move? Yeah, well, look, I think it's different because our brains are not built for doing Monte Carlo research, right? It's just not the way our organic brains would work. So I think that in order to compensate for that, you know, people like Einstein have come up, you know, their brains have using their intuition and, you know, we maybe come to what intuition is, but they use their sort of knowledge and their experience to build extremely, you know, in Einstein's case, extremely accurate models of physics, including these sort of mental simulations. I think if you read about Einstein and how he came up with things, he used to visualize and sort of really kind of feel what these physical systems should be like, not just the mathematics of it, but have a really intuitive feel for what they would be like in reality. And that allowed him to think these sort of very outlandish thoughts at the time. So I think that it's the sophistication of the world models that we're building, which then, you know, if you imagine your world model can get you to a certain node in a tree that you're searching, and then you just do a little bit of search around that node, that leaf node, and that gets you to these original places. But obviously, if your model is, and your judgment on that model is very, very good, then you can pick which leaf nodes you should sort of expand with search much more accurately. So therefore, overall, you do a lot less search. I mean, there's no way that, you know, any human could do a kind of brute force search over any kind of significant space. Yeah, yeah, yeah. A big sort of open question right now is whether RL will allow these models to do the self-placed synthetic data to get over the data bottleneck. It sounds like you're optimistic about this. Yeah, I'm very optimistic about that. I mean, I think, well, first of all, there's still a lot more data, I think, that can be used, especially if one views like multimodal and video and these kind of things. And obviously, you know, society's adding more data all the time. But I think to the internet and things like that. But I think that there's a lot of scope for creating synthetic data. We're looking at different ways partly through simulation and using very realistic games environments, for example, to generate realistic data, but also self-play. So that's where systems interact with each other or converse with each other. And in the sense of, you know, work very well for us with AlphaGo and AlphaZero, where we got the systems to play against each other and actually learn from each other's mistakes and build up a knowledge base that way. And I think there are some good analogies for that. It's a little bit more complicated, but to build a general kind of world data. How do you get to the point where these models, the sort of synthetic data they're outputting and their self-play they're doing, is not just more of what they've already got in their data set, but is something they haven't seen before? You know what I mean, to actually improve the abilities. Yeah, so there, I think there's a whole science needed. And I think we're still in the nascent stage of this of data curation and data analysis. So actually analyzing the holes that you have in your data distribution. And this is important for things like fairness and bias and other stuff to remove that from the system is to, is to try and really make sure that your data set is representative of the distribution you're trying to learn. And, you know, there are many tricks there. One can use like over-weighting or replaying certain parts of the data. Or you could imagine if you identify some, some gap in your data set, that's where you put your synthetic generation capabilities to work on. Yeah, so, you know, nowadays people are paying attention to the RL stuff that Alfa deep-minded many years before. What are the sort of either early research directions or something that was done way back in the past, but people just haven't been paying attention to, that you think will be a big deal, right? Like there's a time where people weren't paying attention to scaling. What's the thing now where it's like totally underrated? Well, actually, I think that, you know, there's the history of the sort of last couple of decades has been things coming in and out of fashion, right? And I do feel like a while ago, when, you know, maybe five plus years ago, when we were pioneering with AlphaGo and before that, DQN, where it was the first system, you know, that worked on Atari, about how first big system really more than 10 years ago now that scaled up Q learning and reinforcement learning techniques to deal, you know, combine that with deep learning to create deep reinforcement learning and then use that to scale up to complete some, you know, master some pretty complex tasks like playing Atari games just from the pixels. And I do actually think a lot of those ideas need to come back in again. And as we talked about earlier, combine it with the new advances in large models and large multimodal models, which is obviously very exciting as well. So I do think there's a lot of potential for combining some of those older ideas together with the newer ones. Is there any potential for something to come, the AGI to eventually come from just a pure RRL approach? Like the way we're talking about it, it sounds like there'll be, the LLM will form the gripe fryer and then this sort of research will go on top of that. Or is it a possibility to just like completely out of the dark? I think I certainly, you know, theoretically I think there's no reason why you couldn't go full alpha zero like on it. And there are some people here at Google DeepMind and in the RL community who work on that, right? And fully assuming no priors, no data and just build all knowledge from scratch. And I think that's valuable because of course, you know, those ideas and those algorithms should also work when you have some knowledge too. But having said that, I think by far probably my betting would be the quickest way to get to AGI in the most likely plausible way is to use all the knowledge that's existing in the world right now on things like the web and that we've collected and we have these scalable algorithms like transformers that are capable of ingesting all of that information. And I don't see why you wouldn't start with a model as a kind of prior or to build on and to make predictions that helps bootstrap your learning. I just think it doesn't make sense not to make use of that. So my betting would be is that, you know, the final AGI system will have these large multimodals as part of the overall solution but probably won't be enough on their own. You will need this additional planning search on top. Okay, this sounds like the answer to the question we're about to ask which is what is somebody who's been in this field for a long time and seen different trends come and go, what do you think that the strong version of the scaling hypothesis gets right and what does it get wrong? It's just the idea that you just throw and have computed a wide enough distribution of data and you get intelligence. Yeah, look, my view is this is kind of an empirical question right now. So I think it was pretty surprising to almost everyone, including the people who first worked on the scaling hypotheses that how far it's gone. In a way, I mean, I sort of look at the large models today and I think they're almost unreasonably effective for what they are. You know, I think it's pretty surprising some of the properties that emerge, things like, you know, it's clearly in my opinion got some form of concepts and abstractions and some things like that. And I think if we were talking five plus years ago, I would have said to you, maybe we need an additional algorithmic breakthrough in order to do that. Like, you know, maybe more like the brain works. And I think that's still true if we want explicit abstract concepts, need concepts, but it seems that these systems can implicitly learn that. Another really interesting, I think an unexpected thing was that these systems have some sort of grounding. You know, even though they don't experience the world multimodally or at least until more recently we have the multimodal models. And that's surprising that the amount of information that can be, and models that can be built up just from language. And I think that I have some hypotheses about why that is. I think we get some grounding through the RLHF feedback systems because obviously the human raters are by definition grounded people, we're grounded, right, in reality. So our feedback's also grounded. So perhaps there's some grounding coming in through there. And also maybe language contains more grounding, you know, if you're able to ingest all of it, then we perhaps thought, linguists perhaps thought before. So that's just some very interesting philosophical questions. I think we haven't, people haven't even really scratched the surface off yet, looking at the advances that have been made. You know, it's quite interesting to think about where it's going to go next. But in terms of your question of like the large models, I think we've got to push scaling as hard as we can. And that's what we're doing here. And you know, it's an empirical question whether that will hit an asymptote or brick wall. And there are, you know, different people argue about that. But actually, I think we should just test it. I think no one knows. And but in the meantime, we should also double down on innovation and invention. And this is something that the Google research and DeepMind and Google Brain have, you know, we've pioneered many, many things over the last decade. That's something that's our bread and butter. And, you know, you can think of half our effort as to do with scaling and half our efforts to do with inventing the next architectures, the next algorithms that will be needed, knowing that you've got this scaled larger and larger model coming along the lines. So my betting right now, but it's a loose betting is that you would need both. But I think, you know, it's you've got to push both of them as hard as possible. And we're in a lucky position that we can do that. Yeah. I want to ask more about the grounding. So you can imagine two things that might change, which would make the grounding more difficult. One is that if these models gets from Arder, they're going to be able to operate in domains where we just can generate enough human labels, just because we're not smart enough, right? So if it does like a million line pull request, you know, how do we tell it? Like this is within the constraints of our morality and the end goal we wanted and this isn't. And the other is it sounds like you're saying more of the compute of so far we've been doing, you know, next token prediction and in some sense it's a guardrail because you have to talk as a human would talk and think as a human would think. Now, if additional compute is going to come in the form of reinforcement learning, where just to get to the end objective, we can't really trace how you got there. When you combine those two, how worried are you that the sort of grounding goes away? Well, look, I think if the grounding, you know, if it's not properly grounded, the system won't be able to achieve those goals properly, right? I think so. I think in a sense you sort of have to have the grounding or at least some of it in order for a system to actually achieve goals in the real world. I do actually think that as these systems and things like Gemini are becoming more multimodal and we start ingesting things like video and, you know, audio visual data as well as text data. And then, you know, the system starts correlating those things together. I think that is a form of proper grounding actually. So I do think our systems are going to start to understand, you know, the physics of the real world better. And then one could imagine the active version of that is being in a very realistic simulation or game environment where you're starting to learn about what your actions do in the world and how that affects the world itself, the world stay itself, but also what next learning episode you're getting. So, you know, these RL agents we've always been working on and pioneered like AlphaZero and AlphaGo, they actually affect their active learners. What they decide to do next affects what the next learning piece of data or experience they're going to get. So there's this very interesting sort of feedback loop. And of course, if we ever want to be good at things like robotics, we're going to have to understand how to act in the real world. Yeah, so there's a grounding in terms of will the capabilities be able to proceed? Will they be like enough in touch with the reality to be able to like do the things we want? And there's another sense of grounding of we've gotten lucky in the sense that since they're trained on human thought, they like maybe think like a human. To what extent does that stay true when more of the compute for trading comes from just did you get the right outcome and not guard real? Like, are you like proceeding on the next token as a human would? Maybe the broader question I'll like post to you is and this is what I asked Shane as well, what would it take to align a system that's smarter than a human? Maybe things in alien concepts and you can't like really monitor the million line pull request because you can't really understand the whole thing. Yeah, I mean, look, this is something Shane and I and many others here, we've had that forefront of our minds for since before we started DeMind and because we planned for success crazy, you know, 2010, no one was thinking about AI, let alone AGI, but we already knew that if we could make progress with these systems and these ideas, it, you know, the technology where there would be creator being unbelievably transformative. So we already were thinking, you know, 20 years ago about, well, how, you know, what would the consequences of that be? Both positive and negative. Of course, the positive direction is amazing science, things like alpha fold, incredible breakthroughs in health and science and maths and discovery, scientific discovery. But then also we got to make sure these systems are sort of understandable and controllable. And I think there's sort of several, you know, this would be a whole sort of discussion in itself, but there are many, many ideas that people have from much more stringent eval systems. I think we don't have good enough at evaluations and benchmarks for things like can the system deceive you? Can it exotrate its own code? It was sort of undesirable behaviors. And then there's, you know, ideas of actually using AI, maybe narrow AIs. So not general learning ones, but systems that are specialized for a domain to help us as the human scientists analyze and summarize what the more general system is doing, right? So kind of narrow AI tools. I think that there's a lot of promise in creating hardened sandboxes or simulations so that are hardened with cybersecurity arrangements around the simulation, both to keep the AI in, but also as cybersecurity to keep hackers out. And then you could experiment a lot more freely within that sandbox domain. And I think a lot of these ideas are, and there's many, many others, including the analysis stuff we talked about earlier where can we analyze and understand what the concepts are that this system is building, what the representations are. So maybe they're not so alien to us and we can actually keep track of the kind of knowledge that it's building. Yeah, yeah. So big backup fit. I'm curious what your timelines are. So Shane said he's like, I think modal outcome is 2028. I think that's maybe he's median. Yeah. What is yours? I don't have prescribed kind of specific numbers to it because I think there's so many unknowns and uncertainties and human ingenuity and endeavor comes up with surprises all the time. So that could meaningfully move the timelines. But I will say that when we started DeepMind back in 2010, we thought of it as a 20 year project. And actually, I think we're on track, which is kind of amazing for 20 year projects. Because usually they're always 20 years away. So that's the joke about whatever it is that you use in quantum AI, take your pick. And but I think we're on track. So I wouldn't be surprised if we had AGI like systems within the next decade. And do you buy the model that once you have an AGI, you have a system that basically speeds up further AI research? Maybe not like an overnight sense, but over the course of months and years, you have much faster progress than you would have on the right side. I think that's potentially possible. I think it partly depends what we decide, we as society decide to use the first nascent AGI systems or even proto AGI systems for. So, even the current LLMs seem to be pretty good at coding. So, and we have systems like AlphaCode, we also got theorem proving systems. So one could imagine combining these ideas together and making them a lot better. And then I could imagine these systems being quite good at designing and helping us build future versions of themselves. But we also have to think about the safety implications of that, of course. Yeah, I'm curious what you think about that. So, I mean, I'm not saying this is happening this year or anything, but eventually you'll be developing a model where during the process of development, you think, you know, there's some chance that once this is fully developed, it'll be capable of like an intelligence explosion like dynamic. What would have to be true of that model at that point where you're like, you know, I've seen these specific evals, I've like, I've like understand it's internal thinking enough and like it's future thinking that I'm comfortable continuing development of the system. Well, look, we need a lot more understanding of the systems than we do today before I would be even confident of even explaining to you what we would need to tick box there. So I think actually what we've got to do in the next few years and the time we have before those systems start arriving is come up with the right evaluations and metrics and maybe ideally formal proofs, but you know, it's going to be hard for these types of systems, but at least empirical bounds around what these systems can do. And that's why I think about things like deception and has been quite root node traits that you don't want because if you're confident that your system is sort of exposing what it actually thinks, then you could potentially, that opens up possibilities of using the system itself to explain aspects of itself to you. The way I think about that actually is like, if I was to play a game of chess against Gary Kasparov, right, which I played in the past or Magnus Carlson, you know, the amazing chess players with graceful time, I wouldn't be able to come up with a move that they could, but they could explain to me why they came up with that move and I could understand it post hoc, right? And that's the sort of thing one could imagine one of the capabilities that we could make use of these systems is for them to explain it to us and even maybe the proofs behind why they're thinking something, certainly in a mathematical, any mathematical problem. Got it. Do you have a sense of what the converse answer would be? So what would have to be true where tomorrow morning, you're like, oh man, I didn't anticipate this. You see some specific observation tomorrow morning where like, we got to stop Gemini II training. Like, what would specifically... Yeah, I could imagine that. And this is where things like the sandbox simulations, I would hope we're experimenting in a safe, secure environment. And then something happens in it where very unexpected happens and you unexpected capability or something that we didn't want explicitly told the system we didn't want and that it did, but then lied about. These are the kinds of things where one would want to then dig in carefully with the systems that are around today which are not dangerous in my opinion today, but in a few years they might be, have potential. And then you would sort of ideally kind of pause and then really get to the bottom of why it was doing those things before one continued. Yeah, going back to Gemini, I'm curious what the bottlenecks were in the development. Like, why not make it immediately one order of magnitude bigger if scaling works? Well, look, first of all, there are practical limits. How much compute can you actually fit in one data center? And actually, you're bumping up against very interesting distributed computing kind of challenges, right? Unfortunately, we have some of the best people in the world on those challenges and cross data center training, all these kinds of things, very interesting challenges, hardware challenges, and we have our TPUs and so on that we're building and designing all the time as well as using GPUs. And so there's all of that. And then you also have to, the scaling laws, they didn't just work by magic. You sort of, you still need to scale up the hyperparameters and various innovations are going in all the time with each new scale. It's not just about repeating the same recipe. At each new scale, you have to adjust the recipe and that's a bit of an art form in a way. And you have to sort of almost get new data points. If you try and extend your predictions and extrapolate them, say several orders of magnitude out, sometimes they don't hold anymore, right? Because new capabilities, there can be step functions in terms of new capabilities and some things just, some things hold and other things don't. So often you do need those intermediate data points actually to correct some of your hyperparameter optimization and other things. That the scaling law continues to be true. So there's sort of various practical limitations on to that. So kind of one order of magnitude is about probably the maximum that you want to carry on. You want to sort of do between each era. Oh, that's so fascinating. In the GPT for technical report, they say that they were able to predict the training loss tens of thousands of times less compute than GPT-4 that they could see the curve. But at the point you're making is that the actual capabilities that loss implies may not be so clear. Yeah, the downstream capabilities sometimes don't follow from the, you can often predict the core metrics like training loss or something like that. But then it doesn't actually translate into MMLU or math or some other actual capability that you care about. They're not necessarily linear all the time. So there's sort of non-linear effects there. What was the biggest surprise to you during the development of Gemini? So something like this happening? Well, I mean, I wouldn't say there was one big surprise, but it was very interesting trying to train things at that size and learning about all sorts of things from organizational, how to babysit such a system and to track it. And I think things like getting a better understanding of the metrics you're optimizing versus the final capabilities that you want. I would say that's still not a perfectly understood mapping. But it's an interesting one that we're getting better and better at. Yeah, yeah. There's a perception that maybe other labs are more compute efficient than DeepMind has been with Gemini. I don't know what you make of that for something. I don't think that's the case. I mean, I think that actually Gemini one use roughly the same amount of compute, maybe slightly more than what was rumored for GPT-4. I don't know exactly what was used. So I think it was in the same ballpark. I think we're very efficient with our compute and we use our compute for many things. One is not just the scaling, but going back to earlier to these more innovation and ideas, you've got to, it's only useful a new innovation, a new invention if it's also can scale. So in a way, you also need quite a lot of compute to do new invention because you've got to test many things at least some reasonable scale and make sure that they work at that scale. And also some new ideas may not work at a toy scale, but do work at a larger scale. And in fact, those are the more valuable ones. So you actually, if you think about that exploration process, you need quite a lot of compute to be able to do that. I mean, the good news is, is I think we, we're pretty lucky at Google that we, I think this year certainly we're going to have the most compute by far of any sort of research lab. And we hope to make very efficient and good use of that in terms of both scaling and the capability of our systems and also new inventions. Yeah. What's been the biggest surprise to you if you go back to yourself in 2010 when you were starting DeepMind in terms of what AI progress has looked like? Did you anticipate back then that it would in some large sense amount to spend as, you know, dumping billions of dollars into these models? Or did you have a different sense of what it would look like? We thought that, and actually, you know, if you, I know you've interviewed my colleague Shane and he always thought that in terms of like compute curves and then maybe comparing roughly to like the brain and how many neurons and synapses there are very loosely, but we're actually interestingly in that kind of regime that roughly in the right order of magnitude of, you know, number of synapses in the brain and the sort of compute that we have. But I think more fundamentally, you know, we always thought that we bet on generality and learning, right? So those were always at the core of the any technique we would use. That's why we triangulated on reinforcement learning and search and deep learning, right? As three types of algorithms that would scale and would be very general and not require a lot of handcrafted human priors, which we thought was the sort of failure mode, really, of the efforts to build AI in the 90s, right? Places like MIT where there were very logic-based systems, expert systems, you know, masses of hand-coded, hand-crafted human information going into them that turned out to be wrong or too rigid. So we wanted to move away from that. And I think we spotted that trend early and became, you know, and obviously we use games as our proving ground and we did very well with that. And I think all of that was very successful and I think maybe inspired others to, you know, things like AlphaGo. I think it was a big moment for inspiring many others to think, oh, actually, these systems are ready to scale. And then, of course, with the advent of Transformers invented by our colleagues at Google, you know, research and brain, that was then, you know, the type of deep learning that allowed us to ingest masses of amounts of information. And that, of course, is really turbocharged where we are today. So I think that's all part of the same lineage. You know, we couldn't have predicted every twist and turn there, but I think the general direction we were going in was the right one. Yeah. And in fact, it's like fascinating because actually, if you like read your old papers or Shane's old papers, Shane's thesis, I think in 2009, he said, like, well, you know, the way we would test for AI is if it can you come press Wikipedia. And that's like literally the last function of our labs or like your own paper in like 2016 before Transformers where we said, like, you were comparing your science and AI. And he said, attention is what is needed. Exactly. Exactly. So we had these things called out and actually we had some early attention papers, but they weren't as elegant as Transformers in the end, like, Neuroturing Machines and things like this. Yeah. And then Transformers was the was the nicer and more general architecture of that. Yeah, yeah, yeah. When you extrapolate all this out forward, anything about superhuman intelligence or is like, what does that landscape look like to you? Is it like still controlled by a private company? Like, what should the governance of that look like concretely? Yeah, look, I would love, you know, I think that this has to be. This is so consequential, this technology. I think it's much bigger than any one company or or or even industry in general. I think it has to be a big collaboration with many stakeholders from civil society, academia, government. And the good news is I think with the popularity of the recent chatbot systems and so on, I think that has woken up many of these other parts of society that this is coming and what it will be like to interact with these systems. And that's great. So it's opened up lots of doors for very good conversations. I mean, an example of that was the safety summit in the UK hosted a few months ago, which I thought was a big success to start getting this international dialogue going. And and and, you know, I think the whole society needs to be involved in deciding what do we want to deploy these models for? How do we want to use them? What do we not want to use them for? You know, I think we've got to try and get some international consensus around that. And then also making sure that the benefits of these systems benefit everyone, you know, for the good of everyone and society in general. And that's why I push so hard things like AI for science. And and I hope that, you know, with things like our spin out isomorphic, we're going to start curing diseases, you know, terrible diseases with AI and accelerate drug discovery, amazing things, climate change and other things. I think big challenges that face us and face humanity. Massive challenges, actually, which I'm optimistic we can solve because we've got this incredibly powerful tool coming along down the line of AI that we can apply and I think help us and solve many of these problems. So, you know, ideally, we would have a big consensus around that and a big discussion, you know, sort of almost like the UN level, if possible. You know, one interesting thing is if you look at these systems, they you chat with them and they're immensely powerful and intelligent. But it's interesting to the extent of which they haven't like automated large sections of the economy yet. Whereas a five years ago, I showed you a Gemini, you'd be like, wow, this is like, you know, totally coming for a lot of things. So how do you account for that? Like what's going on where it hasn't had a broader impact yet? I think it's we're still I think that just shows we're still at the beginning of this new era. Yeah. And I think that for these systems, I think there are some interesting use cases, you know, you know, where you can use things to some, you know, these these these chatbot systems to summarize stuff for you and and maybe do some simple writing and maybe more kind of boilerplate type writing. But that's only a small part of what, you know, we all do every day. So I think for more general use cases, I think we need still need new capabilities, things like planning and search, but also maybe things like personalization and memory, episodic memory. So not just long context windows, but actually remembering what I what we spoke about a hundred conversations ago. And I think once they start coming in, I mean, I'm really looking forward to things like recommendation systems that that help me find better, more enriching material, whether that's books or films or music and so on. You know, I would use that type of system every day. So I think we're just scratching the surface of what these AI, say, assistants could actually do for us in our general everyday lives. And also in our work context as well, I think they're not reliable yet enough to do things like science with them. But I think one day, you know, once we fix factuality and grounding and other things, I think they could end up becoming like, you know, the world's best research assistant for you as a scientist or as a clinician. I want to ask about memory, by the way, you had this fascinating paper in 2007 where you talk about the links between memory and imagination and how they, in some sense, are very similar. People often claim that these models are just memorizing. How do you think about that claim that people make? Is memorization all you need? Because in some some deep sense, that's compression. Or, you know, what's your intuition? Yeah, I mean, sort of at the limit, one maybe could try and memorize everything, but it wouldn't generalize out of out of your distribution. And I think these systems are clearly I think the early the early criticisms of these early systems were that they were just regurgitating and memorizing, but I think clearly the new era, the Gemini GPT-4 type era, they are definitely generalizing to new constructs. So but actually, you know, in my thesis and that paper, particularly, that started that era of imagination in neuroscience was showing that, you know, first of all, memory, certainly at least human memory is a reconstructive process. It's not a videotape, right? We sort of put it together back from components that seems familiar to us, that the ensemble, and that's what made me think that imagination might be the same thing, except in this case, you're using the same semantic components. But now you're putting it together into a way that your brain thinks is novel, right, for a particular purpose like planning. And and so I do think that that kind of idea is still probably missing from our current systems, this sort of pulling together different parts of your world model to simulate something new that then helps with your planning, which is what I would call imagination. Yeah, for sure. So again, now you guys have the best models in the world, you know, with the Gemini models. Do you have do you plan on putting out some sort of framework like the other two major labs have of, you know, once we see these specific capabilities, unless we have these specific safeguards, we're not going to continue development or we're not going to ship the product out. Yes, we have actually we I mean, we have already lots of internal checks and balances, but we're going to start publishing actually, you know, sort of watch the spaces. We're working on a whole bunch of blog posts and technical papers that we'll be putting out in the next few months that, you know, along the similar lines of things like responsible scaling laws and so on. We have those implicitly internally in various safety councils and so on, people like Shane, Chair and so on. But but it's time for us to talk about that more publicly, I think. So we'll be doing that throughout the course of the year. That's great to hear. And another thing I'm curious about is so it's not only the risk of, like, you know, the deployed model being something that people can use to do bad things, but also rogue actors, bad foreign agents, so forth, being able to steal the weights and then fine tune them to do crazy things. How do you think about securing the weights to make sure something like this doesn't happen, making sure a very like key group of people have access to them and so forth? Yeah, it's interesting. So first of all, there's sort of two parts of this. One is security, one is open source, maybe we can discuss. But the security, I think, is super key. Like just a sort of normal cyber security type things. And I think we're lucky at Google DeepMind. We're kind of behind Google's firewall and cloud protection, which is, you know, I think best, you know, best in class in the world, corporately. So we already have that protection. And then behind that, we have specific DeepMind protections within our code base. So it's sort of a double layer of protection. So I feel pretty good about that. That that's, I mean, we, you know, you can never be complacent on that. But I feel it's already sort of best in the world in terms of cyber defences. But we've got to carry on improving that. And again, things like the hard and sandboxes could be a way of doing that as well. And maybe even there are, you know, specifically secure data centers or hardware solutions to this, too, that we're thinking about. I think that maybe in the next three, four, five years, we would also want air gaps and various other things that are known in the security community. So I think that's key. And I think all frontier labs should be doing that because otherwise, you know, nation states and other things, rogue nation, you know, states and other other dangerous actors, that there would be obviously a lot of incentive for them to to steal things like the weights. And then, you know, of course, open source is another interesting question, which is we're huge proponents of open source and open science. I mean, almost every, you know, we've published thousands of papers and things like Alpha Fold and Transformers, of course. And Alpha Gold, all of these things we put out there into the world, published and open source, many of them, GraphCast, most recently, our weather prediction system. But when it comes to, you know, the core technology, the foundational technology and very general purpose, I think the question I would have is, if you, you know, first of all, open source proponents is that how does one stop bad actors, individuals or, you know, up to rogue states, taking those same open source systems and repurposing them because their general purpose for harmful ends, right? So we have to answer that question. And I haven't heard a compelling, I mean, I don't know what the answer is to that, but I haven't heard a compelling, clear answer to that from proponents of just sort of open sourcing everything. So I think there has to be some balance there, but, you know, obviously it's a complex question of what that is. Yeah, yeah, I feel like tech doesn't get the credit it deserves for, like, funding, you know, hundreds of billions of dollars worth of R&D. And, you know, obviously I have deep bind with systems like Alpha Fold and so on. Well, but when we talk about securing the weights, you know, as we said, like maybe right now, it's not something that, like, is going to cause the end of the world or anything, but as these systems get better and better, the worry that, yes, a foreign agent or something gets access to them. Presumably right now, there's like dozens to hundreds of researchers who have access to the weights. How do you, well, what's a plan for, like, getting into, like, the situation or getting the weights in the situation rooms? If you're like, if you need to access to them, it's like, you know, some extremely strenuous process. You know, nobody, nobody individual can really take them out. Yeah, yeah. I mean, one has to balance that with, with, with allowing for collaboration and speed of progress. Actually, another interesting thing is, of course, you want, you know, brilliant independent researchers from academia or, or things like the UK AI Safety Institute and US1 to be able to kind of red team these systems. So, so one has to expose them to a certain extent, although that's not necessarily the weights. And then, you know, we have a lot of processes in place about making sure that, you know, only if you need them that, that you have access to, you know, those people who need access, have access. And right now, I think we're still in the early days of those kinds of systems being at risk. And as that, as these systems become more powerful and more general and more capable, I think one has to look at the, the access question. So some of these other labs have specialized in different things relative to safety, like Anthropoc, for example, with interoperability. And do you have some sense of where you guys might have an edge where as so that, you know, now that you have the frontier model, you're going to scale up safety, where you guys are going to be able to put out the best frontier research on safety. I think, you know, well, we helped pioneer RLHF and other things like that, which can also be obviously used for performance, but also for safety. I think that, you know, a lot of the self-play ideas and these kinds of things could also be used potentially to, to auto-test a lot of the boundary conditions that you have with the new systems. I mean, part of the issue is that with these sort of very general systems, there's so much surface area to cover, like about how these systems behave. So I think we are going to need some automated testing. And again, with things like simulations and games environment, very realistic environments, virtual environments, I think we have a long history in that and using those kinds of systems and making use of them for building AI algorithms. So I think we can leverage all of that history. And then, you know, around at Google, we're very lucky we have some of the world's best cybersecurity experts, hardware designers. So I think we can bring that to bear in, you know, for security and safety as well. Great, great. Let's talk about Gemini. So, you know, now you guys have the best model in the world. So I'm curious, you know, the default way to interact with these systems has been through chat so far. Now that we have multimodal and all these new capabilities, how do you anticipate that changing? Or do you think that will still be the case? Yeah, I think we're just at the beginning of actually understanding what a full multimodal model system, how exciting that might be to interact with them, and it will be quite different to, I think, what we're used to today with the chat bots. I think the next versions of this over the next year, 18 months, you know, maybe we'll have some contextual understanding around the environment around you through a camera or whatever it is, a phone. You know, I could imagine that as the next awesome glasses at the next step. And then I think that we'll start becoming more fluid in understanding, oh, let's sample from a video. Let's use voice. Maybe even eventually things like touch and, you know, if you think about robotics and other things, you know, sensors, other types of sensors. So I think the world's about to become very exciting. I think in the next few years, as we start getting used to the idea of what true multimodality means. On the robotic subject, Ilya said when he was on the podcast that the reason opening I gave up on robotics was because they didn't have enough data in that domain, at least at the time they were pursuing it. I mean, you guys have put out different things like Robo Transformer and other things. How do you think that's still a bottleneck for robotics progress or will we see progress in the world of atoms as well as the world of bits? We're very excited about our progress with things like GATO and RT2, you know, Robotic Transformer, and we actually think so we've always liked robotics and we've had, you know, amazing research and now we still have that going now because we like the fact that it's a data poor regime because that pushes us on some very interesting research directions that we think are going to be useful anyway, like sampling efficiency and data efficiency in general and transfer learning, learning from simulation, transferring that to reality. All of these very, you know, similar to real, all of these very interesting actually general challenges that we would like to solve. So the control problem. So we've always pushed hard on that. And actually, I think so Ilya is right that that is more challenging because of the data problem, but it's also I think we're starting to see the beginnings of these large models being transferable to the robotics regime, learning in the general domain, language domain and other things. And then just treating tokens like GATO as any type of token, you know, the token could be an action, it could be a word, it could be part of an image, a pixel or whatever it is. And that's what I think true multimodality is. And to begin with, it's harder to train a system like that than a straightforward text language system. But actually, you know, going back to our early conversation of transfer learning, you start seeing that a true multimodal system, the other modalities benefit some different modality. So you get better at language because you now understand a little bit about video. So I do think it's harder to get going, but actually ultimately we'll have a more general, more capable system like that. Whatever happened to GATO? That was super fascinating that you could have like play games and also do like video and also do text. We're still working on those kinds of systems, but you can imagine we're just trying to, those ideas we're trying to build into our future generations of Gemini. You know, to be able to do all of those things and robotics transformers and things like that, you can think of them as sort of follow-ups to that. Well, we see asymmetric progress towards the domains in which the self-play kinds of things we're talking about will be especially powerful. So math and code, you know, obviously recently you have these papers out about this or yeah, you can use these things to do really cool novel things. Will they just be like superhuman coders? But like in other ways, they might be still worse than humans? Or how do you think about that? So look, I think that we're making great progress with math and things like theorem proving and coding, but it's still interesting. If one looks at, I mean, creativity in general and scientific endeavor in general, I think we're getting to the stage where our systems could help the best human scientists make their breakthroughs quicker, like almost triage the search space in some ways or perhaps find a solution like AlphaFold does with a protein structure. But it can't, they're not at the level where they can create the hypothesis themselves or ask the right question. And as any top scientists will tell you, that that's the hardest part of science is actually asking the right question, boiling down that space to like, what's the critical question we should go after the critical problem and then formulating that problem in the right way to attack it. And that's not something our systems will we have really have any idea how our systems could do, but they can. They are suitable for searching large combinatorial spaces if one can specify the problem in that way with a clear objective function. So that's very useful for already many of the problems we deal with today, but not the most high level creative problems. Right, so deep mind obviously has published all kinds of interesting stuff and, you know, speeding up science in different areas. How do you think about that in the context of if you think AGI is going to happen in the next 10, 20 years, why not just wait for the AGI to do it for you? Why build these domain specific solutions? Well, I think we don't know how long AGI is going to be. And we always used to say, you know, back even when we started DeepMind that we don't have to wait for AGI in order to bring incredible benefits to the world. And especially, you know, my personal passion has been AI for science and health. And you can see that with things like AlphaFold and all of our various nature papers of different domains and material science work and so on. I think there's lots of exciting directions and also impact in the world through products, too. I think it's very exciting and a huge opportunity, a unique opportunity we have as part of Google, of, you know, they got dozens of billion user products, right? That we can immediately ship our advances into and then billions of people can, you know, improve their daily lives, right? And enriches their daily lives and enhances their daily lives. So I think it's a fantastic opportunity for impact on all those fronts. And I think the other reason from a point of view of AGI specifically is that it battle tests your ideas, right? So you don't want to be in a sort of research bunker where you just, you know, theoretically are pushing things, some things forward. But then actually your internal metrics start deviating from real world things that people would care about, right? Or real world impact. So you get a lot of feedback, direct feedback from these real world applications that then tells you whether your systems really are scaling or or actually is, you know, do we need to be more data efficient or sample efficient because most real world challenges require that, right? And so it kind of keeps you honest and pushes you, you know, keep sort of nudging and steering your research directions to make sure they're on the right path. So I think it's fantastic. And of course, the world benefits from that society benefits from that on the way. Many, many, maybe many, many years before AGI arrives. Yeah. Well, the development of Gemini is super interesting because it comes right at the heels of merging these different organizations, Brain and DeepMind. Yeah, I'm curious, what have been the challenges there? What have been the synergies? And it's been successful in the sense that you have the best model in the world now. Well, look, it's been fantastic actually over the last year. Of course, it's been challenging to do that, like any big integration coming together. But you're talking about two, you know, world-class organizations, long storied histories of inventing many, many important things, you know, from deep reinforcement learning to transformers. And so it's very exciting, actually, pooling all of that together and and collaborating much more closely. We always used to be collaborating, but more on a on a on a, you know, sort of project by project basis versus a much deeper, broader collaboration like we have now in Gemini is the first fruit of of that collaboration, including the name Gemini actually, you know, implying twins. And and of course, a lot of other things are made more efficient, like pooling compute resources together and ideas and engineering, which I think at the stage we're at now, where there's huge amounts of world-class engineering that has to go on to build the frontier systems. I think it makes sense to to coordinate that more closely. Yeah. So I mean, you and Shane started DeepMind partly because you were concerned about safety and you saw AGI coming as like a live possibility. Do you do you think the people who were formerly part of brain, the half of Google DeepMind now, do they do you think they approach it in the same way? Have there been cultural differences there in terms of that question? Yeah, no, I think overrun. And this is why, you know, I think one of the reasons we joined forces with Google back in 2014 was I think the entirety of Google and Alphabet, not just brain and DeepMind, take these questions very seriously of responsibility. And, you know, I kind of mantra is to try and be bold and responsible with these systems. So, you know, I would I would classify as I'm obviously a huge techno optimist, but I want us to be cautious with that, given the transformative power of what we're bringing, bringing into the world, you know, collectively. And I think it's important, you know, I think it's going to be one of the most important technologies humanity will ever invent. So we've got to put, you know, all our efforts into getting this right and be thoughtful and sort of also humble about what we know and don't know about the systems that are coming and the uncertainties around that. And in my view, the only the only sensible approach when you have huge uncertainty is to be sort of cautiously optimistic and use the scientific method to try and have as much foresight and understanding about what's coming down the line and the consequences of that before it happens. You know, you don't want to be live A, B testing out in the world with these very consequential systems, because unintended consequences may be maybe quite severe. So, you know, I want us to move away as a as a field from a sort of move fast and break things attitude, which is, you know, maybe serve the valley very well in the past and obviously created important innovations. But but I think in this case, you know, we want to be bold with the with the positive things that it can do and make sure we realize things like medicine and science and advancing all of those things whilst being, you know, responsible and thoughtful with with as far as possible with with mitigating the risks. Yeah, yeah. And that's why it seems like the responsible scaling process or something like that is a very good empirical way to pre-commit to these kinds of things. Yes, exactly. Yeah. And I'm curious if you have a sense of like, for example, when you're doing these evaluations, if it turns out your next model could help a layperson build a pandemic class or bio-weapon or something, how you would think, first of all, of making sure those weights are secure so that that doesn't get out? And second, what would have to be true for you to be comfortable deploying that system? How comfortable? Like, how would you make sure that that that lane capability isn't exposed? Yeah. Well, first, I mean, you know, the secure model part, I think we've covered with the cybersecurity and make sure that's well class and you're monitoring all those things. I think if the capability was discovered like that through red teaming or external testing by, you know, government institutes or academia or whatever, independent testers, then we would have to fix that loophole depending what it was, right? If that required more a different kind of perhaps constitution or different guardrails or more RLHF to avoid that or removing some training data, they could, I mean, depending on what the problem is, I think there could be a number of mitigations. And so the first part is making sure you detect it ahead of time. So that's about the right evaluations and right benchmarking and right and right testing. And then the question is how one would fix that before, you know, you deployed it. But I think it would need to be fixed before it was deployed generally, for sure, if that was an exposure surface. Right. Right. Final question. You know, you've been thinking in terms of like the end goal of Asia at a time when other people thought it was ridiculous in 2010, now that we're seeing this like slow takeoff where we're actually seeing these like generalization and intelligence, what is like the psychologically seeing this? What has that been like? Has it just like sort of priced into your role model? So you like it's not new news for you or is it like actually just seeing it live? You're like, wow, like this is something's like really changed or what does it feel like? Yeah, well, for me, yes, it's already priced into my world, one of how things were going to go, at least from the technology side. But obviously, I didn't we didn't necessarily anticipate the general public would be that interested this early in the sequence, right, of things like maybe one could think of if we were to produce more, if say like a chat GPT and chatbots hadn't got the kind of got the interest they'd ended up getting. So I think it was quite surprising to everyone that people were ready to use these things, even though they were lacking in certain directions, right? Impressive, though they are, then we would have produced more specialized systems, I think, built off of the main track, like Alpha Folds and Alpha goes and and so on and our scientific work. And then I think the general public maybe would have only paid attention later down the road, where in a few years time, we have more generally useful assistant type systems. So that's been interesting. So that's created a different type of environment that we're now all operating in as a field. So I mean, it's a little bit more chaotic because there's so many more things going on and there's so much VC money going into it and everyone sort of almost losing their minds over it, I think, and what I just the thing I worry about is I want to make sure that as a field, we act responsibly and thoughtfully and scientifically about this and use the scientific method to approach this in a in a, as I said, an optimistic, but careful way. And I think that's the I've always believed that's the right approach for something like AI, and I just hope that doesn't get lost in this huge rush. Sure, sure. Well, I think that's a great place to close. Dennis, so much thanks to you. Thank you so much for your time and for coming on the podcast. Thanks. It's been a real pleasure. Hey, everybody, I hope we enjoyed that episode. As always, the most helpful thing you can do is to share the podcast, send it to people you think might enjoy it, put it in Twitter, your group chats, et cetera, just splits the world, appreciate your listening. I'll see you next time. Cheers.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.2, "text": " So I wouldn't be surprised if we had AGI-like systems", "tokens": [50364, 407, 286, 2759, 380, 312, 6100, 498, 321, 632, 316, 26252, 12, 4092, 3652, 50524], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 1, "seek": 0, "start": 3.2, "end": 4.36, "text": " within the next decade.", "tokens": [50524, 1951, 264, 958, 10378, 13, 50582], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 2, "seek": 0, "start": 4.36, "end": 6.4, "text": " It was pretty surprising to almost everyone,", "tokens": [50582, 467, 390, 1238, 8830, 281, 1920, 1518, 11, 50684], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 3, "seek": 0, "start": 6.4, "end": 8.88, "text": " including the people who first worked on the scaling", "tokens": [50684, 3009, 264, 561, 567, 700, 2732, 322, 264, 21589, 50808], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 4, "seek": 0, "start": 8.88, "end": 10.88, "text": " hypotheses, that how far it's gone.", "tokens": [50808, 49969, 11, 300, 577, 1400, 309, 311, 2780, 13, 50908], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 5, "seek": 0, "start": 10.88, "end": 13.4, "text": " In a way, I look at the large models today,", "tokens": [50908, 682, 257, 636, 11, 286, 574, 412, 264, 2416, 5245, 965, 11, 51034], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 6, "seek": 0, "start": 13.4, "end": 14.92, "text": " and I think they're almost unreasonably", "tokens": [51034, 293, 286, 519, 436, 434, 1920, 20584, 1258, 1188, 51110], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 7, "seek": 0, "start": 14.92, "end": 16.240000000000002, "text": " effective for what they are.", "tokens": [51110, 4942, 337, 437, 436, 366, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 8, "seek": 0, "start": 16.240000000000002, "end": 18.76, "text": " It's an empirical question whether that will hit an asymptote", "tokens": [51176, 467, 311, 364, 31886, 1168, 1968, 300, 486, 2045, 364, 35114, 1370, 51302], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 9, "seek": 0, "start": 18.76, "end": 19.76, "text": " or a brick wall.", "tokens": [51302, 420, 257, 16725, 2929, 13, 51352], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 10, "seek": 0, "start": 19.76, "end": 21.080000000000002, "text": " I think no one knows.", "tokens": [51352, 286, 519, 572, 472, 3255, 13, 51418], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 11, "seek": 0, "start": 21.080000000000002, "end": 23.0, "text": " When you think about superhuman intelligence,", "tokens": [51418, 1133, 291, 519, 466, 1687, 18796, 7599, 11, 51514], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 12, "seek": 0, "start": 23.0, "end": 25.6, "text": " is it still controlled by a private company?", "tokens": [51514, 307, 309, 920, 10164, 538, 257, 4551, 2237, 30, 51644], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 13, "seek": 0, "start": 25.6, "end": 28.04, "text": " As Gemini becoming more multimodal,", "tokens": [51644, 1018, 22894, 3812, 5617, 544, 32972, 378, 304, 11, 51766], "temperature": 0.0, "avg_logprob": -0.1842756966091939, "compression_ratio": 1.5953757225433527, "no_speech_prob": 0.050792399793863297}, {"id": 14, "seek": 2804, "start": 28.04, "end": 30.24, "text": " and we start ingesting audio-visual data,", "tokens": [50364, 293, 321, 722, 3957, 8714, 6278, 12, 4938, 901, 1412, 11, 50474], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 15, "seek": 2804, "start": 30.24, "end": 32.839999999999996, "text": " as well as text data, I do think our systems", "tokens": [50474, 382, 731, 382, 2487, 1412, 11, 286, 360, 519, 527, 3652, 50604], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 16, "seek": 2804, "start": 32.839999999999996, "end": 36.28, "text": " are going to start to understand the physics of the real world", "tokens": [50604, 366, 516, 281, 722, 281, 1223, 264, 10649, 295, 264, 957, 1002, 50776], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 17, "seek": 2804, "start": 36.28, "end": 36.92, "text": " better.", "tokens": [50776, 1101, 13, 50808], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 18, "seek": 2804, "start": 36.92, "end": 38.56, "text": " The world's about to become very exciting,", "tokens": [50808, 440, 1002, 311, 466, 281, 1813, 588, 4670, 11, 50890], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 19, "seek": 2804, "start": 38.56, "end": 40.16, "text": " I think, in the next few years as we start", "tokens": [50890, 286, 519, 11, 294, 264, 958, 1326, 924, 382, 321, 722, 50970], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 20, "seek": 2804, "start": 40.16, "end": 44.239999999999995, "text": " getting used to the idea of what true multimodality means.", "tokens": [50970, 1242, 1143, 281, 264, 1558, 295, 437, 2074, 32972, 378, 1860, 1355, 13, 51174], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 21, "seek": 2804, "start": 44.239999999999995, "end": 48.239999999999995, "text": " OK, today it is a true honor to speak with Demis Isavis, who", "tokens": [51174, 2264, 11, 965, 309, 307, 257, 2074, 5968, 281, 1710, 365, 4686, 271, 1119, 706, 271, 11, 567, 51374], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 22, "seek": 2804, "start": 48.239999999999995, "end": 50.239999999999995, "text": " is the CEO of DeepMind.", "tokens": [51374, 307, 264, 9282, 295, 14895, 44, 471, 13, 51474], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 23, "seek": 2804, "start": 50.239999999999995, "end": 51.64, "text": " Demis, welcome to the podcast.", "tokens": [51474, 4686, 271, 11, 2928, 281, 264, 7367, 13, 51544], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 24, "seek": 2804, "start": 51.64, "end": 52.72, "text": " Thanks for having me.", "tokens": [51544, 2561, 337, 1419, 385, 13, 51598], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 25, "seek": 2804, "start": 52.72, "end": 55.480000000000004, "text": " First question, given your neuroscience background,", "tokens": [51598, 2386, 1168, 11, 2212, 428, 42762, 3678, 11, 51736], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 26, "seek": 2804, "start": 55.480000000000004, "end": 56.879999999999995, "text": " how do you think about intelligence?", "tokens": [51736, 577, 360, 291, 519, 466, 7599, 30, 51806], "temperature": 0.0, "avg_logprob": -0.16937425120776853, "compression_ratio": 1.632716049382716, "no_speech_prob": 0.0017786613898351789}, {"id": 27, "seek": 5688, "start": 56.92, "end": 60.0, "text": " Specifically, do you think it's like one higher-level general", "tokens": [50366, 26058, 11, 360, 291, 519, 309, 311, 411, 472, 2946, 12, 12418, 2674, 50520], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 28, "seek": 5688, "start": 60.0, "end": 61.480000000000004, "text": " reasoning circuit, or do you think", "tokens": [50520, 21577, 9048, 11, 420, 360, 291, 519, 50594], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 29, "seek": 5688, "start": 61.480000000000004, "end": 65.56, "text": " it's thousands of independent sub-scales and heuristics?", "tokens": [50594, 309, 311, 5383, 295, 6695, 1422, 12, 4417, 4229, 293, 415, 374, 6006, 30, 50798], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 30, "seek": 5688, "start": 65.56, "end": 69.88, "text": " Well, it's interesting because intelligence is so broad,", "tokens": [50798, 1042, 11, 309, 311, 1880, 570, 7599, 307, 370, 4152, 11, 51014], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 31, "seek": 5688, "start": 69.88, "end": 74.76, "text": " and what we use it for is so generally applicable.", "tokens": [51014, 293, 437, 321, 764, 309, 337, 307, 370, 5101, 21142, 13, 51258], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 32, "seek": 5688, "start": 74.76, "end": 77.12, "text": " I think that suggests that there must", "tokens": [51258, 286, 519, 300, 13409, 300, 456, 1633, 51376], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 33, "seek": 5688, "start": 77.12, "end": 81.84, "text": " be some sort of high-level common things,", "tokens": [51376, 312, 512, 1333, 295, 1090, 12, 12418, 2689, 721, 11, 51612], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 34, "seek": 5688, "start": 81.84, "end": 84.16, "text": " common algorithmic themes, I think,", "tokens": [51612, 2689, 9284, 299, 13544, 11, 286, 519, 11, 51728], "temperature": 0.0, "avg_logprob": -0.18033322420987216, "compression_ratio": 1.6607929515418502, "no_speech_prob": 0.0009645633981563151}, {"id": 35, "seek": 8416, "start": 84.16, "end": 87.32, "text": " around how the brain processes the world around us.", "tokens": [50364, 926, 577, 264, 3567, 7555, 264, 1002, 926, 505, 13, 50522], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 36, "seek": 8416, "start": 87.32, "end": 91.67999999999999, "text": " So of course, then there are specialized parts of the brain", "tokens": [50522, 407, 295, 1164, 11, 550, 456, 366, 19813, 3166, 295, 264, 3567, 50740], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 37, "seek": 8416, "start": 91.67999999999999, "end": 94.08, "text": " that do specific things.", "tokens": [50740, 300, 360, 2685, 721, 13, 50860], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 38, "seek": 8416, "start": 94.08, "end": 96.44, "text": " But I think there are probably some underlying principles", "tokens": [50860, 583, 286, 519, 456, 366, 1391, 512, 14217, 9156, 50978], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 39, "seek": 8416, "start": 96.44, "end": 97.8, "text": " that underpin all of that.", "tokens": [50978, 300, 833, 17836, 439, 295, 300, 13, 51046], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 40, "seek": 8416, "start": 97.8, "end": 100.67999999999999, "text": " Yeah, how do you make sense of the fact that in these LLMs,", "tokens": [51046, 865, 11, 577, 360, 291, 652, 2020, 295, 264, 1186, 300, 294, 613, 441, 43, 26386, 11, 51190], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 41, "seek": 8416, "start": 100.67999999999999, "end": 102.72, "text": " though, when you give them a lot of data", "tokens": [51190, 1673, 11, 562, 291, 976, 552, 257, 688, 295, 1412, 51292], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 42, "seek": 8416, "start": 102.72, "end": 104.16, "text": " in any specific domain, they tend", "tokens": [51292, 294, 604, 2685, 9274, 11, 436, 3928, 51364], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 43, "seek": 8416, "start": 104.16, "end": 107.67999999999999, "text": " to get asymmetrically better in that domain?", "tokens": [51364, 281, 483, 37277, 27965, 984, 1101, 294, 300, 9274, 30, 51540], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 44, "seek": 8416, "start": 107.67999999999999, "end": 110.03999999999999, "text": " Wouldn't we expect a general improvement", "tokens": [51540, 26291, 380, 321, 2066, 257, 2674, 10444, 51658], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 45, "seek": 8416, "start": 110.03999999999999, "end": 111.52, "text": " across all the different areas?", "tokens": [51658, 2108, 439, 264, 819, 3179, 30, 51732], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 46, "seek": 8416, "start": 111.52, "end": 113.6, "text": " Well, I think you first of all, I think you do actually", "tokens": [51732, 1042, 11, 286, 519, 291, 700, 295, 439, 11, 286, 519, 291, 360, 767, 51836], "temperature": 0.0, "avg_logprob": -0.16450302941458567, "compression_ratio": 1.7491749174917492, "no_speech_prob": 0.011298289522528648}, {"id": 47, "seek": 11360, "start": 113.64, "end": 116.47999999999999, "text": " sometimes get surprising improvement in other domains", "tokens": [50366, 2171, 483, 8830, 10444, 294, 661, 25514, 50508], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 48, "seek": 11360, "start": 116.47999999999999, "end": 118.19999999999999, "text": " when you improve in a specific domain.", "tokens": [50508, 562, 291, 3470, 294, 257, 2685, 9274, 13, 50594], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 49, "seek": 11360, "start": 118.19999999999999, "end": 121.67999999999999, "text": " So for example, when these large models sort of improve", "tokens": [50594, 407, 337, 1365, 11, 562, 613, 2416, 5245, 1333, 295, 3470, 50768], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 50, "seek": 11360, "start": 121.67999999999999, "end": 125.28, "text": " at coding, that can actually improve their general reasoning.", "tokens": [50768, 412, 17720, 11, 300, 393, 767, 3470, 641, 2674, 21577, 13, 50948], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 51, "seek": 11360, "start": 125.28, "end": 127.52, "text": " So there is some evidence of some transfer,", "tokens": [50948, 407, 456, 307, 512, 4467, 295, 512, 5003, 11, 51060], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 52, "seek": 11360, "start": 127.52, "end": 131.6, "text": " though I think we would like a lot more evidence of that.", "tokens": [51060, 1673, 286, 519, 321, 576, 411, 257, 688, 544, 4467, 295, 300, 13, 51264], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 53, "seek": 11360, "start": 131.6, "end": 134.35999999999999, "text": " But also, that's how the human brain learns, too,", "tokens": [51264, 583, 611, 11, 300, 311, 577, 264, 1952, 3567, 27152, 11, 886, 11, 51402], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 54, "seek": 11360, "start": 134.35999999999999, "end": 137.48, "text": " is if we experience and practice a lot of things like chess", "tokens": [51402, 307, 498, 321, 1752, 293, 3124, 257, 688, 295, 721, 411, 24122, 51558], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 55, "seek": 11360, "start": 137.48, "end": 140.12, "text": " or writing, creative writing, or whatever that is,", "tokens": [51558, 420, 3579, 11, 5880, 3579, 11, 420, 2035, 300, 307, 11, 51690], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 56, "seek": 11360, "start": 140.12, "end": 142.2, "text": " we also tend to specialize and get better", "tokens": [51690, 321, 611, 3928, 281, 37938, 293, 483, 1101, 51794], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 57, "seek": 11360, "start": 142.2, "end": 143.44, "text": " at that specific thing.", "tokens": [51794, 412, 300, 2685, 551, 13, 51856], "temperature": 0.0, "avg_logprob": -0.1484807332356771, "compression_ratio": 1.778877887788779, "no_speech_prob": 0.0012593923602253199}, {"id": 58, "seek": 14344, "start": 143.44, "end": 146.6, "text": " Even though we're using sort of general learning techniques", "tokens": [50364, 2754, 1673, 321, 434, 1228, 1333, 295, 2674, 2539, 7512, 50522], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 59, "seek": 14344, "start": 146.6, "end": 148.52, "text": " and general learning systems in order", "tokens": [50522, 293, 2674, 2539, 3652, 294, 1668, 50618], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 60, "seek": 14344, "start": 148.52, "end": 151.07999999999998, "text": " to get good at that domain.", "tokens": [50618, 281, 483, 665, 412, 300, 9274, 13, 50746], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 61, "seek": 14344, "start": 151.07999999999998, "end": 153.16, "text": " Yeah, well, what's been the most surprising example", "tokens": [50746, 865, 11, 731, 11, 437, 311, 668, 264, 881, 8830, 1365, 50850], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 62, "seek": 14344, "start": 153.16, "end": 154.96, "text": " of this kind of transfer for you?", "tokens": [50850, 295, 341, 733, 295, 5003, 337, 291, 30, 50940], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 63, "seek": 14344, "start": 154.96, "end": 157.84, "text": " Like, you see language and code or images and text?", "tokens": [50940, 1743, 11, 291, 536, 2856, 293, 3089, 420, 5267, 293, 2487, 30, 51084], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 64, "seek": 14344, "start": 157.84, "end": 160.07999999999998, "text": " Yeah, I think probably, I mean, I'm", "tokens": [51084, 865, 11, 286, 519, 1391, 11, 286, 914, 11, 286, 478, 51196], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 65, "seek": 14344, "start": 160.07999999999998, "end": 162.76, "text": " hoping we're going to see a lot more of this China transfer.", "tokens": [51196, 7159, 321, 434, 516, 281, 536, 257, 688, 544, 295, 341, 3533, 5003, 13, 51330], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 66, "seek": 14344, "start": 162.76, "end": 166.6, "text": " But I think things like getting better at coding and math", "tokens": [51330, 583, 286, 519, 721, 411, 1242, 1101, 412, 17720, 293, 5221, 51522], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 67, "seek": 14344, "start": 166.6, "end": 168.92, "text": " and generally improving your reasoning,", "tokens": [51522, 293, 5101, 11470, 428, 21577, 11, 51638], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 68, "seek": 14344, "start": 168.92, "end": 171.52, "text": " that is how it works with us as human learners.", "tokens": [51638, 300, 307, 577, 309, 1985, 365, 505, 382, 1952, 23655, 13, 51768], "temperature": 0.0, "avg_logprob": -0.18156658784123778, "compression_ratio": 1.7037037037037037, "no_speech_prob": 0.000707214989233762}, {"id": 69, "seek": 17152, "start": 171.52, "end": 173.0, "text": " But I think it's interesting seeing", "tokens": [50364, 583, 286, 519, 309, 311, 1880, 2577, 50438], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 70, "seek": 17152, "start": 173.0, "end": 175.88000000000002, "text": " that in these artificial systems.", "tokens": [50438, 300, 294, 613, 11677, 3652, 13, 50582], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 71, "seek": 17152, "start": 175.88000000000002, "end": 179.12, "text": " And can you see the sort of mechanistic way in which,", "tokens": [50582, 400, 393, 291, 536, 264, 1333, 295, 4236, 3142, 636, 294, 597, 11, 50744], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 72, "seek": 17152, "start": 179.12, "end": 180.72, "text": " let's say in the language and code example,", "tokens": [50744, 718, 311, 584, 294, 264, 2856, 293, 3089, 1365, 11, 50824], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 73, "seek": 17152, "start": 180.72, "end": 183.12, "text": " there's like, I found a place in a neural network that's", "tokens": [50824, 456, 311, 411, 11, 286, 1352, 257, 1081, 294, 257, 18161, 3209, 300, 311, 50944], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 74, "seek": 17152, "start": 183.12, "end": 184.92000000000002, "text": " getting better with both the language and the code.", "tokens": [50944, 1242, 1101, 365, 1293, 264, 2856, 293, 264, 3089, 13, 51034], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 75, "seek": 17152, "start": 184.92000000000002, "end": 187.0, "text": " Is that too far down the weeds?", "tokens": [51034, 1119, 300, 886, 1400, 760, 264, 26370, 30, 51138], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 76, "seek": 17152, "start": 187.0, "end": 189.84, "text": " Yeah, well, I don't think our analysis techniques", "tokens": [51138, 865, 11, 731, 11, 286, 500, 380, 519, 527, 5215, 7512, 51280], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 77, "seek": 17152, "start": 189.84, "end": 193.48000000000002, "text": " are quite sophisticated enough to be able to hone in on that.", "tokens": [51280, 366, 1596, 16950, 1547, 281, 312, 1075, 281, 43212, 294, 322, 300, 13, 51462], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 78, "seek": 17152, "start": 193.48000000000002, "end": 195.08, "text": " I think that's actually one of the areas", "tokens": [51462, 286, 519, 300, 311, 767, 472, 295, 264, 3179, 51542], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 79, "seek": 17152, "start": 195.08, "end": 197.60000000000002, "text": " that a lot more research needs to be done", "tokens": [51542, 300, 257, 688, 544, 2132, 2203, 281, 312, 1096, 51668], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 80, "seek": 17152, "start": 197.60000000000002, "end": 200.64000000000001, "text": " on kind of mechanistic analysis of the representations", "tokens": [51668, 322, 733, 295, 4236, 3142, 5215, 295, 264, 33358, 51820], "temperature": 0.0, "avg_logprob": -0.18045093931000808, "compression_ratio": 1.7827476038338659, "no_speech_prob": 0.0004938409547321498}, {"id": 81, "seek": 20064, "start": 200.67999999999998, "end": 201.92, "text": " that these systems build up.", "tokens": [50366, 300, 613, 3652, 1322, 493, 13, 50428], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 82, "seek": 20064, "start": 201.92, "end": 205.35999999999999, "text": " And I sometimes like to call it virtual brain analytics.", "tokens": [50428, 400, 286, 2171, 411, 281, 818, 309, 6374, 3567, 15370, 13, 50600], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 83, "seek": 20064, "start": 205.35999999999999, "end": 209.35999999999999, "text": " In a way, it's a bit like doing fMRI or a single cell", "tokens": [50600, 682, 257, 636, 11, 309, 311, 257, 857, 411, 884, 283, 44, 5577, 420, 257, 2167, 2815, 50800], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 84, "seek": 20064, "start": 209.35999999999999, "end": 211.88, "text": " recording from a real brain.", "tokens": [50800, 6613, 490, 257, 957, 3567, 13, 50926], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 85, "seek": 20064, "start": 211.88, "end": 214.64, "text": " What's the analogous sort of analysis techniques", "tokens": [50926, 708, 311, 264, 16660, 563, 1333, 295, 5215, 7512, 51064], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 86, "seek": 20064, "start": 214.64, "end": 216.32, "text": " for these artificial minds?", "tokens": [51064, 337, 613, 11677, 9634, 30, 51148], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 87, "seek": 20064, "start": 216.32, "end": 218.56, "text": " And there's a lot of great work going on", "tokens": [51148, 400, 456, 311, 257, 688, 295, 869, 589, 516, 322, 51260], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 88, "seek": 20064, "start": 218.56, "end": 219.39999999999998, "text": " on this sort of stuff.", "tokens": [51260, 322, 341, 1333, 295, 1507, 13, 51302], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 89, "seek": 20064, "start": 219.39999999999998, "end": 221.83999999999997, "text": " People like Chris Ola, I really like his work.", "tokens": [51302, 3432, 411, 6688, 422, 875, 11, 286, 534, 411, 702, 589, 13, 51424], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 90, "seek": 20064, "start": 221.83999999999997, "end": 224.04, "text": " And a lot of computational neuroscience techniques,", "tokens": [51424, 400, 257, 688, 295, 28270, 42762, 7512, 11, 51534], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 91, "seek": 20064, "start": 224.04, "end": 226.04, "text": " I think, could be brought to bear", "tokens": [51534, 286, 519, 11, 727, 312, 3038, 281, 6155, 51634], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 92, "seek": 20064, "start": 226.04, "end": 228.56, "text": " on analyzing these current systems we're building.", "tokens": [51634, 322, 23663, 613, 2190, 3652, 321, 434, 2390, 13, 51760], "temperature": 0.0, "avg_logprob": -0.15037287088265097, "compression_ratio": 1.6655405405405406, "no_speech_prob": 0.005303253885358572}, {"id": 93, "seek": 22856, "start": 228.56, "end": 230.84, "text": " In fact, I try to encourage a lot of my computational", "tokens": [50364, 682, 1186, 11, 286, 853, 281, 5373, 257, 688, 295, 452, 28270, 50478], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 94, "seek": 22856, "start": 230.84, "end": 234.0, "text": " neuroscience friends to start thinking in that direction", "tokens": [50478, 42762, 1855, 281, 722, 1953, 294, 300, 3513, 50636], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 95, "seek": 22856, "start": 234.0, "end": 238.44, "text": " and applying their know-how to the large models.", "tokens": [50636, 293, 9275, 641, 458, 12, 4286, 281, 264, 2416, 5245, 13, 50858], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 96, "seek": 22856, "start": 238.44, "end": 241.68, "text": " Yeah, what do other researchers not understand", "tokens": [50858, 865, 11, 437, 360, 661, 10309, 406, 1223, 51020], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 97, "seek": 22856, "start": 241.68, "end": 245.2, "text": " about human intelligence that you have some sort of insight", "tokens": [51020, 466, 1952, 7599, 300, 291, 362, 512, 1333, 295, 11269, 51196], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 98, "seek": 22856, "start": 245.2, "end": 246.68, "text": " on, given your neuroscience background?", "tokens": [51196, 322, 11, 2212, 428, 42762, 3678, 30, 51270], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 99, "seek": 22856, "start": 246.68, "end": 250.6, "text": " I think neuroscience has added a lot.", "tokens": [51270, 286, 519, 42762, 575, 3869, 257, 688, 13, 51466], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 100, "seek": 22856, "start": 250.6, "end": 252.76, "text": " If you look at the last sort of 10, 20 years", "tokens": [51466, 759, 291, 574, 412, 264, 1036, 1333, 295, 1266, 11, 945, 924, 51574], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 101, "seek": 22856, "start": 252.76, "end": 254.48000000000002, "text": " that we've been at it, at least.", "tokens": [51574, 300, 321, 600, 668, 412, 309, 11, 412, 1935, 13, 51660], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 102, "seek": 22856, "start": 254.48000000000002, "end": 258.08, "text": " And I've been thinking about this for 30 plus years.", "tokens": [51660, 400, 286, 600, 668, 1953, 466, 341, 337, 2217, 1804, 924, 13, 51840], "temperature": 0.0, "avg_logprob": -0.14307166735331217, "compression_ratio": 1.690391459074733, "no_speech_prob": 0.0007879402255639434}, {"id": 103, "seek": 25808, "start": 258.08, "end": 261.76, "text": " I think in the earlier days of this sort of new wave of AI,", "tokens": [50364, 286, 519, 294, 264, 3071, 1708, 295, 341, 1333, 295, 777, 5772, 295, 7318, 11, 50548], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 104, "seek": 25808, "start": 261.76, "end": 264.76, "text": " I think neuroscience was providing a lot of interesting", "tokens": [50548, 286, 519, 42762, 390, 6530, 257, 688, 295, 1880, 50698], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 105, "seek": 25808, "start": 264.76, "end": 266.15999999999997, "text": " directional clues.", "tokens": [50698, 42242, 20936, 13, 50768], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 106, "seek": 25808, "start": 266.15999999999997, "end": 268.0, "text": " So things like reinforcement learning,", "tokens": [50768, 407, 721, 411, 29280, 2539, 11, 50860], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 107, "seek": 25808, "start": 268.0, "end": 269.64, "text": " combining that with deep learning,", "tokens": [50860, 21928, 300, 365, 2452, 2539, 11, 50942], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 108, "seek": 25808, "start": 269.64, "end": 271.64, "text": " some of our pioneering work we did there,", "tokens": [50942, 512, 295, 527, 19761, 1794, 589, 321, 630, 456, 11, 51042], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 109, "seek": 25808, "start": 271.64, "end": 275.4, "text": " things like experience replay, even the notion of attention,", "tokens": [51042, 721, 411, 1752, 23836, 11, 754, 264, 10710, 295, 3202, 11, 51230], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 110, "seek": 25808, "start": 275.4, "end": 277.84, "text": " which has become super important.", "tokens": [51230, 597, 575, 1813, 1687, 1021, 13, 51352], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 111, "seek": 25808, "start": 277.84, "end": 281.24, "text": " A lot of those original sort of inspirations", "tokens": [51352, 316, 688, 295, 729, 3380, 1333, 295, 17432, 763, 51522], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 112, "seek": 25808, "start": 281.24, "end": 284.03999999999996, "text": " come from some understanding about how the brain works.", "tokens": [51522, 808, 490, 512, 3701, 466, 577, 264, 3567, 1985, 13, 51662], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 113, "seek": 25808, "start": 284.03999999999996, "end": 285.2, "text": " Not the exact specifics.", "tokens": [51662, 1726, 264, 1900, 28454, 13, 51720], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 114, "seek": 25808, "start": 285.2, "end": 287.28, "text": " Of course, one's an engineered system.", "tokens": [51720, 2720, 1164, 11, 472, 311, 364, 38648, 1185, 13, 51824], "temperature": 0.0, "avg_logprob": -0.13550323486328125, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.0005935085937380791}, {"id": 115, "seek": 28728, "start": 287.28, "end": 288.44, "text": " The other one's a natural system.", "tokens": [50364, 440, 661, 472, 311, 257, 3303, 1185, 13, 50422], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 116, "seek": 28728, "start": 288.44, "end": 290.84, "text": " So it's not so much about a one-to-one mapping", "tokens": [50422, 407, 309, 311, 406, 370, 709, 466, 257, 472, 12, 1353, 12, 546, 18350, 50542], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 117, "seek": 28728, "start": 290.84, "end": 292.23999999999995, "text": " of a specific algorithm.", "tokens": [50542, 295, 257, 2685, 9284, 13, 50612], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 118, "seek": 28728, "start": 292.23999999999995, "end": 294.47999999999996, "text": " It's more kind of inspirational direction,", "tokens": [50612, 467, 311, 544, 733, 295, 33554, 3513, 11, 50724], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 119, "seek": 28728, "start": 294.47999999999996, "end": 297.23999999999995, "text": " maybe some ideas for architecture or algorithmic ideas", "tokens": [50724, 1310, 512, 3487, 337, 9482, 420, 9284, 299, 3487, 50862], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 120, "seek": 28728, "start": 297.23999999999995, "end": 299.15999999999997, "text": " or representational ideas.", "tokens": [50862, 420, 2906, 1478, 3487, 13, 50958], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 121, "seek": 28728, "start": 299.15999999999997, "end": 301.64, "text": " And because you know the brains in existence", "tokens": [50958, 400, 570, 291, 458, 264, 15442, 294, 9123, 51082], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 122, "seek": 28728, "start": 301.64, "end": 304.2, "text": " prove that general intelligence is possible at all,", "tokens": [51082, 7081, 300, 2674, 7599, 307, 1944, 412, 439, 11, 51210], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 123, "seek": 28728, "start": 304.2, "end": 307.15999999999997, "text": " I think the history of human endeavors", "tokens": [51210, 286, 519, 264, 2503, 295, 1952, 49608, 51358], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 124, "seek": 28728, "start": 307.15999999999997, "end": 309.67999999999995, "text": " has been that once you know something's possible,", "tokens": [51358, 575, 668, 300, 1564, 291, 458, 746, 311, 1944, 11, 51484], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 125, "seek": 28728, "start": 309.67999999999995, "end": 311.76, "text": " it's easier to push hard in that direction.", "tokens": [51484, 309, 311, 3571, 281, 2944, 1152, 294, 300, 3513, 13, 51588], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 126, "seek": 28728, "start": 311.76, "end": 314.08, "text": " Because you know it's a question of effort then", "tokens": [51588, 1436, 291, 458, 309, 311, 257, 1168, 295, 4630, 550, 51704], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 127, "seek": 28728, "start": 314.08, "end": 317.08, "text": " and sort of a question of when, not if.", "tokens": [51704, 293, 1333, 295, 257, 1168, 295, 562, 11, 406, 498, 13, 51854], "temperature": 0.0, "avg_logprob": -0.13732129755154462, "compression_ratio": 1.7507987220447285, "no_speech_prob": 0.0035575120709836483}, {"id": 128, "seek": 31708, "start": 317.08, "end": 319.44, "text": " And that allows you to I think make progress", "tokens": [50364, 400, 300, 4045, 291, 281, 286, 519, 652, 4205, 50482], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 129, "seek": 31708, "start": 319.44, "end": 320.52, "text": " a lot more quickly.", "tokens": [50482, 257, 688, 544, 2661, 13, 50536], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 130, "seek": 31708, "start": 320.52, "end": 323.24, "text": " So I think neurosciences has had a lot of,", "tokens": [50536, 407, 286, 519, 28813, 537, 2667, 575, 632, 257, 688, 295, 11, 50672], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 131, "seek": 31708, "start": 324.68, "end": 327.0, "text": " has inspired a lot of the thinking,", "tokens": [50744, 575, 7547, 257, 688, 295, 264, 1953, 11, 50860], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 132, "seek": 31708, "start": 327.0, "end": 330.08, "text": " at least in a soft way behind where we are today.", "tokens": [50860, 412, 1935, 294, 257, 2787, 636, 2261, 689, 321, 366, 965, 13, 51014], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 133, "seek": 31708, "start": 331.0, "end": 333.4, "text": " But as for going forwards,", "tokens": [51060, 583, 382, 337, 516, 30126, 11, 51180], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 134, "seek": 31708, "start": 333.4, "end": 336.96, "text": " I think that there's still a lot of interesting things", "tokens": [51180, 286, 519, 300, 456, 311, 920, 257, 688, 295, 1880, 721, 51358], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 135, "seek": 31708, "start": 336.96, "end": 338.76, "text": " to be resolved around planning", "tokens": [51358, 281, 312, 20772, 926, 5038, 51448], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 136, "seek": 31708, "start": 338.76, "end": 342.56, "text": " and how does the brain construct the right world models.", "tokens": [51448, 293, 577, 775, 264, 3567, 7690, 264, 558, 1002, 5245, 13, 51638], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 137, "seek": 31708, "start": 343.68, "end": 347.06, "text": " I studied for example, how the brain does imagination,", "tokens": [51694, 286, 9454, 337, 1365, 11, 577, 264, 3567, 775, 12938, 11, 51863], "temperature": 0.0, "avg_logprob": -0.17302119731903076, "compression_ratio": 1.678714859437751, "no_speech_prob": 0.0005409735604189336}, {"id": 138, "seek": 34706, "start": 347.06, "end": 350.02, "text": " or you can think of it as a mental simulation.", "tokens": [50364, 420, 291, 393, 519, 295, 309, 382, 257, 4973, 16575, 13, 50512], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 139, "seek": 34706, "start": 350.02, "end": 354.26, "text": " So how do we create very rich visual spatial simulations", "tokens": [50512, 407, 577, 360, 321, 1884, 588, 4593, 5056, 23598, 35138, 50724], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 140, "seek": 34706, "start": 354.26, "end": 356.1, "text": " of the world in order for us to plan better?", "tokens": [50724, 295, 264, 1002, 294, 1668, 337, 505, 281, 1393, 1101, 30, 50816], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 141, "seek": 34706, "start": 356.1, "end": 357.54, "text": " Yeah, actually I'm curious how you think", "tokens": [50816, 865, 11, 767, 286, 478, 6369, 577, 291, 519, 50888], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 142, "seek": 34706, "start": 357.54, "end": 359.34000000000003, "text": " that will sort of interface with LLM.", "tokens": [50888, 300, 486, 1333, 295, 9226, 365, 441, 43, 44, 13, 50978], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 143, "seek": 34706, "start": 359.34000000000003, "end": 361.5, "text": " So obviously DeepMinders are the frontier", "tokens": [50978, 407, 2745, 14895, 44, 471, 433, 366, 264, 35853, 51086], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 144, "seek": 34706, "start": 361.5, "end": 363.34000000000003, "text": " and has been for many years,", "tokens": [51086, 293, 575, 668, 337, 867, 924, 11, 51178], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 145, "seek": 34706, "start": 363.34000000000003, "end": 365.14, "text": " systems like AlphaZero and so forth,", "tokens": [51178, 3652, 411, 20588, 57, 2032, 293, 370, 5220, 11, 51268], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 146, "seek": 34706, "start": 365.14, "end": 366.98, "text": " of having these agents who can like think through", "tokens": [51268, 295, 1419, 613, 12554, 567, 393, 411, 519, 807, 51360], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 147, "seek": 34706, "start": 366.98, "end": 369.46, "text": " different steps to get to an end outcome.", "tokens": [51360, 819, 4439, 281, 483, 281, 364, 917, 9700, 13, 51484], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 148, "seek": 34706, "start": 369.46, "end": 370.82, "text": " All right, will this just be,", "tokens": [51484, 1057, 558, 11, 486, 341, 445, 312, 11, 51552], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 149, "seek": 34706, "start": 370.82, "end": 373.02, "text": " is a path for LLMs to have this sort of", "tokens": [51552, 307, 257, 3100, 337, 441, 43, 26386, 281, 362, 341, 1333, 295, 51662], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 150, "seek": 34706, "start": 373.02, "end": 374.74, "text": " tree search kind of thing on top of them?", "tokens": [51662, 4230, 3164, 733, 295, 551, 322, 1192, 295, 552, 30, 51748], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 151, "seek": 34706, "start": 374.74, "end": 375.78, "text": " How do you think about this?", "tokens": [51748, 1012, 360, 291, 519, 466, 341, 30, 51800], "temperature": 0.0, "avg_logprob": -0.15249602987159114, "compression_ratio": 1.680473372781065, "no_speech_prob": 0.0008913351339288056}, {"id": 152, "seek": 37578, "start": 375.78, "end": 378.85999999999996, "text": " I think that's a super promising direction in my opinion.", "tokens": [50364, 286, 519, 300, 311, 257, 1687, 20257, 3513, 294, 452, 4800, 13, 50518], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 153, "seek": 37578, "start": 378.85999999999996, "end": 382.73999999999995, "text": " So we've got to carry on improving the large models", "tokens": [50518, 407, 321, 600, 658, 281, 3985, 322, 11470, 264, 2416, 5245, 50712], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 154, "seek": 37578, "start": 382.73999999999995, "end": 385.82, "text": " and we've got to carry on basically making", "tokens": [50712, 293, 321, 600, 658, 281, 3985, 322, 1936, 1455, 50866], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 155, "seek": 37578, "start": 385.82, "end": 388.02, "text": " the more and more accurate predictors of the world.", "tokens": [50866, 264, 544, 293, 544, 8559, 6069, 830, 295, 264, 1002, 13, 50976], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 156, "seek": 37578, "start": 388.02, "end": 390.29999999999995, "text": " So in effect, making them more and more reliable", "tokens": [50976, 407, 294, 1802, 11, 1455, 552, 544, 293, 544, 12924, 51090], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 157, "seek": 37578, "start": 390.29999999999995, "end": 392.58, "text": " world models, that's clearly unnecessary,", "tokens": [51090, 1002, 5245, 11, 300, 311, 4448, 19350, 11, 51204], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 158, "seek": 37578, "start": 392.58, "end": 394.73999999999995, "text": " but I would say probably not sufficient component", "tokens": [51204, 457, 286, 576, 584, 1391, 406, 11563, 6542, 51312], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 159, "seek": 37578, "start": 394.73999999999995, "end": 396.5, "text": " of an AGI system.", "tokens": [51312, 295, 364, 316, 26252, 1185, 13, 51400], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 160, "seek": 37578, "start": 396.5, "end": 397.82, "text": " And then on top of that,", "tokens": [51400, 400, 550, 322, 1192, 295, 300, 11, 51466], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 161, "seek": 37578, "start": 397.82, "end": 401.14, "text": " I would, we're working on things like AlphaZero,", "tokens": [51466, 286, 576, 11, 321, 434, 1364, 322, 721, 411, 20588, 57, 2032, 11, 51632], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 162, "seek": 37578, "start": 401.14, "end": 404.7, "text": " like planning mechanisms on top that make use of that model", "tokens": [51632, 411, 5038, 15902, 322, 1192, 300, 652, 764, 295, 300, 2316, 51810], "temperature": 0.0, "avg_logprob": -0.13164705129770132, "compression_ratio": 1.775, "no_speech_prob": 0.00043557147728279233}, {"id": 163, "seek": 40470, "start": 404.7, "end": 406.58, "text": " in order to make concrete plans", "tokens": [50364, 294, 1668, 281, 652, 9859, 5482, 50458], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 164, "seek": 40470, "start": 406.58, "end": 408.9, "text": " to achieve certain goals in the world", "tokens": [50458, 281, 4584, 1629, 5493, 294, 264, 1002, 50574], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 165, "seek": 40470, "start": 408.9, "end": 412.78, "text": " and perhaps sort of chain thought together", "tokens": [50574, 293, 4317, 1333, 295, 5021, 1194, 1214, 50768], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 166, "seek": 40470, "start": 412.78, "end": 414.38, "text": " or lines of reasoning together", "tokens": [50768, 420, 3876, 295, 21577, 1214, 50848], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 167, "seek": 40470, "start": 414.38, "end": 416.74, "text": " and maybe use search to kind of explore", "tokens": [50848, 293, 1310, 764, 3164, 281, 733, 295, 6839, 50966], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 168, "seek": 40470, "start": 416.74, "end": 418.38, "text": " massive spaces of possibility.", "tokens": [50966, 5994, 7673, 295, 7959, 13, 51048], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 169, "seek": 40470, "start": 418.38, "end": 419.86, "text": " I think that's kind of missing", "tokens": [51048, 286, 519, 300, 311, 733, 295, 5361, 51122], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 170, "seek": 40470, "start": 419.86, "end": 421.98, "text": " from our current large models.", "tokens": [51122, 490, 527, 2190, 2416, 5245, 13, 51228], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 171, "seek": 40470, "start": 421.98, "end": 425.86, "text": " How do you get past the sort of immense amount of compute", "tokens": [51228, 1012, 360, 291, 483, 1791, 264, 1333, 295, 22920, 2372, 295, 14722, 51422], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 172, "seek": 40470, "start": 425.86, "end": 427.21999999999997, "text": " that these approaches tend to require?", "tokens": [51422, 300, 613, 11587, 3928, 281, 3651, 30, 51490], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 173, "seek": 40470, "start": 427.21999999999997, "end": 431.5, "text": " So even the AlphaGo system was a pretty expensive system", "tokens": [51490, 407, 754, 264, 20588, 12104, 1185, 390, 257, 1238, 5124, 1185, 51704], "temperature": 0.0, "avg_logprob": -0.12930577596028645, "compression_ratio": 1.628787878787879, "no_speech_prob": 0.0003231179143767804}, {"id": 174, "seek": 43150, "start": 431.54, "end": 434.74, "text": " because you had to do the sort of running an LLM on each node", "tokens": [50366, 570, 291, 632, 281, 360, 264, 1333, 295, 2614, 364, 441, 43, 44, 322, 1184, 9984, 50526], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 175, "seek": 43150, "start": 434.74, "end": 436.1, "text": " of the tree.", "tokens": [50526, 295, 264, 4230, 13, 50594], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 176, "seek": 43150, "start": 436.1, "end": 437.66, "text": " How do you anticipate that will get more,", "tokens": [50594, 1012, 360, 291, 21685, 300, 486, 483, 544, 11, 50672], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 177, "seek": 43150, "start": 437.66, "end": 438.5, "text": " made more efficient?", "tokens": [50672, 1027, 544, 7148, 30, 50714], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 178, "seek": 43150, "start": 438.5, "end": 442.82, "text": " Well, I mean, one thing is Moore's law tends to help", "tokens": [50714, 1042, 11, 286, 914, 11, 472, 551, 307, 21644, 311, 2101, 12258, 281, 854, 50930], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 179, "seek": 43150, "start": 442.82, "end": 447.62, "text": " if every year, of course, more computation comes in,", "tokens": [50930, 498, 633, 1064, 11, 295, 1164, 11, 544, 24903, 1487, 294, 11, 51170], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 180, "seek": 43150, "start": 447.62, "end": 450.06, "text": " but we focus a lot on efficient,", "tokens": [51170, 457, 321, 1879, 257, 688, 322, 7148, 11, 51292], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 181, "seek": 43150, "start": 450.06, "end": 454.46, "text": " sample efficient methods and reusing existing data,", "tokens": [51292, 6889, 7148, 7150, 293, 319, 7981, 6741, 1412, 11, 51512], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 182, "seek": 43150, "start": 454.46, "end": 456.22, "text": " things like experience replay,", "tokens": [51512, 721, 411, 1752, 23836, 11, 51600], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 183, "seek": 43150, "start": 456.22, "end": 459.14, "text": " and also just looking at more efficient ways.", "tokens": [51600, 293, 611, 445, 1237, 412, 544, 7148, 2098, 13, 51746], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 184, "seek": 43150, "start": 459.14, "end": 460.98, "text": " I mean, the better your world model is,", "tokens": [51746, 286, 914, 11, 264, 1101, 428, 1002, 2316, 307, 11, 51838], "temperature": 0.0, "avg_logprob": -0.2369133733933972, "compression_ratio": 1.6481481481481481, "no_speech_prob": 0.0009812482167035341}, {"id": 185, "seek": 46098, "start": 460.98, "end": 462.66, "text": " the more efficient your search can be.", "tokens": [50364, 264, 544, 7148, 428, 3164, 393, 312, 13, 50448], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 186, "seek": 46098, "start": 462.66, "end": 464.62, "text": " So one example I always get with AlphaZero,", "tokens": [50448, 407, 472, 1365, 286, 1009, 483, 365, 20588, 57, 2032, 11, 50546], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 187, "seek": 46098, "start": 464.62, "end": 467.62, "text": " our system to play Go and chess and any game,", "tokens": [50546, 527, 1185, 281, 862, 1037, 293, 24122, 293, 604, 1216, 11, 50696], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 188, "seek": 46098, "start": 467.62, "end": 471.34000000000003, "text": " is that it's stronger than world champion level,", "tokens": [50696, 307, 300, 309, 311, 7249, 813, 1002, 10971, 1496, 11, 50882], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 189, "seek": 46098, "start": 471.34000000000003, "end": 473.94, "text": " human world champion level at all these games.", "tokens": [50882, 1952, 1002, 10971, 1496, 412, 439, 613, 2813, 13, 51012], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 190, "seek": 46098, "start": 473.94, "end": 478.02000000000004, "text": " And it uses a lot less search than a brute force method", "tokens": [51012, 400, 309, 4960, 257, 688, 1570, 3164, 813, 257, 47909, 3464, 3170, 51216], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 191, "seek": 46098, "start": 478.02000000000004, "end": 479.94, "text": " like Deep Blue, say to play chess.", "tokens": [51216, 411, 14895, 8510, 11, 584, 281, 862, 24122, 13, 51312], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 192, "seek": 46098, "start": 479.94, "end": 482.46000000000004, "text": " Deep Blue, one of these traditional stockfish", "tokens": [51312, 14895, 8510, 11, 472, 295, 613, 5164, 4127, 11608, 51438], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 193, "seek": 46098, "start": 482.46000000000004, "end": 485.38, "text": " or Deep Blue systems would maybe look at millions", "tokens": [51438, 420, 14895, 8510, 3652, 576, 1310, 574, 412, 6803, 51584], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 194, "seek": 46098, "start": 485.38, "end": 488.74, "text": " of possible moves for every decision it's gonna make.", "tokens": [51584, 295, 1944, 6067, 337, 633, 3537, 309, 311, 799, 652, 13, 51752], "temperature": 0.0, "avg_logprob": -0.131039595800983, "compression_ratio": 1.6787003610108304, "no_speech_prob": 0.0011131825158372521}, {"id": 195, "seek": 48874, "start": 488.74, "end": 491.66, "text": " AlphaZero and AlphaGo made, you know,", "tokens": [50364, 20588, 57, 2032, 293, 20588, 12104, 1027, 11, 291, 458, 11, 50510], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 196, "seek": 48874, "start": 491.66, "end": 495.86, "text": " looked at around tens of thousands of possible positions", "tokens": [50510, 2956, 412, 926, 10688, 295, 5383, 295, 1944, 8432, 50720], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 197, "seek": 48874, "start": 495.86, "end": 498.26, "text": " in order to make a decision about what to move next.", "tokens": [50720, 294, 1668, 281, 652, 257, 3537, 466, 437, 281, 1286, 958, 13, 50840], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 198, "seek": 48874, "start": 498.26, "end": 501.5, "text": " But a human grandmaster, a human world champion,", "tokens": [50840, 583, 257, 1952, 2697, 21640, 11, 257, 1952, 1002, 10971, 11, 51002], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 199, "seek": 48874, "start": 501.5, "end": 503.98, "text": " probably only looks at a few hundreds of moves,", "tokens": [51002, 1391, 787, 1542, 412, 257, 1326, 6779, 295, 6067, 11, 51126], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 200, "seek": 48874, "start": 503.98, "end": 505.02, "text": " even the top ones,", "tokens": [51126, 754, 264, 1192, 2306, 11, 51178], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 201, "seek": 48874, "start": 505.02, "end": 507.98, "text": " in order to make their very good decision", "tokens": [51178, 294, 1668, 281, 652, 641, 588, 665, 3537, 51326], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 202, "seek": 48874, "start": 507.98, "end": 509.26, "text": " about what to play next.", "tokens": [51326, 466, 437, 281, 862, 958, 13, 51390], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 203, "seek": 48874, "start": 509.26, "end": 512.5, "text": " So that suggests that obviously the brute force systems", "tokens": [51390, 407, 300, 13409, 300, 2745, 264, 47909, 3464, 3652, 51552], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 204, "seek": 48874, "start": 512.5, "end": 515.02, "text": " don't have any real model other than heuristics", "tokens": [51552, 500, 380, 362, 604, 957, 2316, 661, 813, 415, 374, 6006, 51678], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 205, "seek": 48874, "start": 515.02, "end": 516.1, "text": " about the game.", "tokens": [51678, 466, 264, 1216, 13, 51732], "temperature": 0.0, "avg_logprob": -0.12175680001576741, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0021974544506520033}, {"id": 206, "seek": 51610, "start": 516.14, "end": 519.66, "text": " AlphaZero has quite a decent model,", "tokens": [50366, 20588, 57, 2032, 575, 1596, 257, 8681, 2316, 11, 50542], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 207, "seek": 51610, "start": 519.66, "end": 521.86, "text": " but the human, you know,", "tokens": [50542, 457, 264, 1952, 11, 291, 458, 11, 50652], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 208, "seek": 51610, "start": 521.86, "end": 524.02, "text": " top human players have a much richer,", "tokens": [50652, 1192, 1952, 4150, 362, 257, 709, 29021, 11, 50760], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 209, "seek": 51610, "start": 524.02, "end": 526.86, "text": " much more accurate model than of Go or chess.", "tokens": [50760, 709, 544, 8559, 2316, 813, 295, 1037, 420, 24122, 13, 50902], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 210, "seek": 51610, "start": 526.86, "end": 528.5, "text": " So that allows them to make, you know,", "tokens": [50902, 407, 300, 4045, 552, 281, 652, 11, 291, 458, 11, 50984], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 211, "seek": 51610, "start": 528.5, "end": 531.78, "text": " world class decisions on a very small amount of search.", "tokens": [50984, 1002, 1508, 5327, 322, 257, 588, 1359, 2372, 295, 3164, 13, 51148], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 212, "seek": 51610, "start": 531.78, "end": 532.86, "text": " So I think there's still,", "tokens": [51148, 407, 286, 519, 456, 311, 920, 11, 51202], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 213, "seek": 51610, "start": 532.86, "end": 534.1800000000001, "text": " there's a sort of trade off there,", "tokens": [51202, 456, 311, 257, 1333, 295, 4923, 766, 456, 11, 51268], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 214, "seek": 51610, "start": 534.1800000000001, "end": 536.02, "text": " like, you know, if you improve the models,", "tokens": [51268, 411, 11, 291, 458, 11, 498, 291, 3470, 264, 5245, 11, 51360], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 215, "seek": 51610, "start": 536.02, "end": 538.4200000000001, "text": " then I think your search can be more efficient", "tokens": [51360, 550, 286, 519, 428, 3164, 393, 312, 544, 7148, 51480], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 216, "seek": 51610, "start": 538.4200000000001, "end": 540.1800000000001, "text": " and therefore you can get further with your search.", "tokens": [51480, 293, 4412, 291, 393, 483, 3052, 365, 428, 3164, 13, 51568], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 217, "seek": 51610, "start": 540.1800000000001, "end": 542.5, "text": " Yeah, I have two questions based on that.", "tokens": [51568, 865, 11, 286, 362, 732, 1651, 2361, 322, 300, 13, 51684], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 218, "seek": 51610, "start": 542.5, "end": 544.22, "text": " The first being with AlphaZero,", "tokens": [51684, 440, 700, 885, 365, 20588, 57, 2032, 11, 51770], "temperature": 0.0, "avg_logprob": -0.1313313983735584, "compression_ratio": 1.7551020408163265, "no_speech_prob": 0.0017249115044251084}, {"id": 219, "seek": 54422, "start": 544.22, "end": 546.9, "text": " you had a very concrete win condition of, you know,", "tokens": [50364, 291, 632, 257, 588, 9859, 1942, 4188, 295, 11, 291, 458, 11, 50498], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 220, "seek": 54422, "start": 546.9, "end": 547.74, "text": " at the end of the day,", "tokens": [50498, 412, 264, 917, 295, 264, 786, 11, 50540], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 221, "seek": 54422, "start": 547.74, "end": 548.58, "text": " do I win this game or not?", "tokens": [50540, 360, 286, 1942, 341, 1216, 420, 406, 30, 50582], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 222, "seek": 54422, "start": 548.58, "end": 550.4200000000001, "text": " And you can reinforce on that.", "tokens": [50582, 400, 291, 393, 22634, 322, 300, 13, 50674], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 223, "seek": 54422, "start": 550.4200000000001, "end": 552.4200000000001, "text": " When you're just thinking of like an LLM,", "tokens": [50674, 1133, 291, 434, 445, 1953, 295, 411, 364, 441, 43, 44, 11, 50774], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 224, "seek": 54422, "start": 552.4200000000001, "end": 553.5, "text": " putting out thought,", "tokens": [50774, 3372, 484, 1194, 11, 50828], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 225, "seek": 54422, "start": 553.5, "end": 555.78, "text": " what will, do you think there'll be this kind of ability", "tokens": [50828, 437, 486, 11, 360, 291, 519, 456, 603, 312, 341, 733, 295, 3485, 50942], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 226, "seek": 54422, "start": 555.78, "end": 557.4200000000001, "text": " to discriminate in the end,", "tokens": [50942, 281, 47833, 294, 264, 917, 11, 51024], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 227, "seek": 54422, "start": 557.4200000000001, "end": 559.98, "text": " whether that was like a good thing to reward or not?", "tokens": [51024, 1968, 300, 390, 411, 257, 665, 551, 281, 7782, 420, 406, 30, 51152], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 228, "seek": 54422, "start": 559.98, "end": 561.5, "text": " Well, of course that's why we, you know,", "tokens": [51152, 1042, 11, 295, 1164, 300, 311, 983, 321, 11, 291, 458, 11, 51228], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 229, "seek": 54422, "start": 561.5, "end": 563.74, "text": " we pioneered and DeepMind sort of famous", "tokens": [51228, 321, 19761, 4073, 293, 14895, 44, 471, 1333, 295, 4618, 51340], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 230, "seek": 54422, "start": 563.74, "end": 566.94, "text": " for using games as a proving ground,", "tokens": [51340, 337, 1228, 2813, 382, 257, 27221, 2727, 11, 51500], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 231, "seek": 54422, "start": 566.94, "end": 568.62, "text": " partly because obviously it's efficient", "tokens": [51500, 17031, 570, 2745, 309, 311, 7148, 51584], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 232, "seek": 54422, "start": 568.62, "end": 570.1, "text": " to research in that domain.", "tokens": [51584, 281, 2132, 294, 300, 9274, 13, 51658], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 233, "seek": 54422, "start": 570.1, "end": 571.98, "text": " But the other reason is obviously it's, you know,", "tokens": [51658, 583, 264, 661, 1778, 307, 2745, 309, 311, 11, 291, 458, 11, 51752], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 234, "seek": 54422, "start": 571.98, "end": 574.0600000000001, "text": " extremely easy to specify a reward function,", "tokens": [51752, 4664, 1858, 281, 16500, 257, 7782, 2445, 11, 51856], "temperature": 0.0, "avg_logprob": -0.14189025103035618, "compression_ratio": 1.7471590909090908, "no_speech_prob": 0.0037459423765540123}, {"id": 235, "seek": 57406, "start": 574.06, "end": 575.7399999999999, "text": " winning the game or improving the score,", "tokens": [50364, 8224, 264, 1216, 420, 11470, 264, 6175, 11, 50448], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 236, "seek": 57406, "start": 575.7399999999999, "end": 578.0999999999999, "text": " something like that sort of built into most games.", "tokens": [50448, 746, 411, 300, 1333, 295, 3094, 666, 881, 2813, 13, 50566], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 237, "seek": 57406, "start": 578.0999999999999, "end": 581.9399999999999, "text": " So that is one of the challenges of real world systems", "tokens": [50566, 407, 300, 307, 472, 295, 264, 4759, 295, 957, 1002, 3652, 50758], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 238, "seek": 57406, "start": 581.9399999999999, "end": 584.8599999999999, "text": " is how does one define the right objective function,", "tokens": [50758, 307, 577, 775, 472, 6964, 264, 558, 10024, 2445, 11, 50904], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 239, "seek": 57406, "start": 584.8599999999999, "end": 587.54, "text": " the right reward function and the right goals", "tokens": [50904, 264, 558, 7782, 2445, 293, 264, 558, 5493, 51038], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 240, "seek": 57406, "start": 587.54, "end": 591.5, "text": " and specify them in a, you know, in a general way,", "tokens": [51038, 293, 16500, 552, 294, 257, 11, 291, 458, 11, 294, 257, 2674, 636, 11, 51236], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 241, "seek": 57406, "start": 591.5, "end": 592.66, "text": " but that's specific enough", "tokens": [51236, 457, 300, 311, 2685, 1547, 51294], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 242, "seek": 57406, "start": 592.66, "end": 595.66, "text": " and actually points the system in the right direction.", "tokens": [51294, 293, 767, 2793, 264, 1185, 294, 264, 558, 3513, 13, 51444], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 243, "seek": 57406, "start": 595.66, "end": 598.9399999999999, "text": " And for real world problems, that can be a lot harder.", "tokens": [51444, 400, 337, 957, 1002, 2740, 11, 300, 393, 312, 257, 688, 6081, 13, 51608], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 244, "seek": 57406, "start": 598.9399999999999, "end": 601.26, "text": " But actually, if you think about it", "tokens": [51608, 583, 767, 11, 498, 291, 519, 466, 309, 51724], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 245, "seek": 57406, "start": 601.26, "end": 603.42, "text": " in even scientific problems,", "tokens": [51724, 294, 754, 8134, 2740, 11, 51832], "temperature": 0.0, "avg_logprob": -0.15212027231852213, "compression_ratio": 1.7978339350180506, "no_speech_prob": 0.0052029164507985115}, {"id": 246, "seek": 60342, "start": 603.42, "end": 605.5799999999999, "text": " there are usually ways that you can specify", "tokens": [50364, 456, 366, 2673, 2098, 300, 291, 393, 16500, 50472], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 247, "seek": 60342, "start": 605.5799999999999, "end": 607.2199999999999, "text": " the goal that you're after.", "tokens": [50472, 264, 3387, 300, 291, 434, 934, 13, 50554], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 248, "seek": 60342, "start": 607.2199999999999, "end": 608.66, "text": " And then when you think about human intelligence,", "tokens": [50554, 400, 550, 562, 291, 519, 466, 1952, 7599, 11, 50626], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 249, "seek": 60342, "start": 608.66, "end": 609.86, "text": " you're just saying, well, you know,", "tokens": [50626, 291, 434, 445, 1566, 11, 731, 11, 291, 458, 11, 50686], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 250, "seek": 60342, "start": 609.86, "end": 610.9399999999999, "text": " the humans thinking about these thoughts", "tokens": [50686, 264, 6255, 1953, 466, 613, 4598, 50740], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 251, "seek": 60342, "start": 610.9399999999999, "end": 612.86, "text": " are just super sample efficient.", "tokens": [50740, 366, 445, 1687, 6889, 7148, 13, 50836], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 252, "seek": 60342, "start": 612.86, "end": 615.14, "text": " How do you, I understand coming up with relativity, right?", "tokens": [50836, 1012, 360, 291, 11, 286, 1223, 1348, 493, 365, 45675, 11, 558, 30, 50950], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 253, "seek": 60342, "start": 615.14, "end": 616.9, "text": " There's just like thousands of possible permutations", "tokens": [50950, 821, 311, 445, 411, 5383, 295, 1944, 4784, 325, 763, 51038], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 254, "seek": 60342, "start": 616.9, "end": 617.9799999999999, "text": " of the equations.", "tokens": [51038, 295, 264, 11787, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 255, "seek": 60342, "start": 617.9799999999999, "end": 619.66, "text": " Do you think it's also this sort of sense", "tokens": [51092, 1144, 291, 519, 309, 311, 611, 341, 1333, 295, 2020, 51176], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 256, "seek": 60342, "start": 619.66, "end": 620.9799999999999, "text": " of like different heuristics of like,", "tokens": [51176, 295, 411, 819, 415, 374, 6006, 295, 411, 11, 51242], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 257, "seek": 60342, "start": 620.9799999999999, "end": 622.3399999999999, "text": " I'm going to try out this approach instead of this", "tokens": [51242, 286, 478, 516, 281, 853, 484, 341, 3109, 2602, 295, 341, 51310], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 258, "seek": 60342, "start": 622.3399999999999, "end": 625.3, "text": " or is it a totally different way of approaching", "tokens": [51310, 420, 307, 309, 257, 3879, 819, 636, 295, 14908, 51458], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 259, "seek": 60342, "start": 625.3, "end": 627.74, "text": " coming up with a solution than, you know,", "tokens": [51458, 1348, 493, 365, 257, 3827, 813, 11, 291, 458, 11, 51580], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 260, "seek": 60342, "start": 627.74, "end": 629.3399999999999, "text": " what AlphaGo does to plan the next move?", "tokens": [51580, 437, 20588, 12104, 775, 281, 1393, 264, 958, 1286, 30, 51660], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 261, "seek": 60342, "start": 629.3399999999999, "end": 630.74, "text": " Yeah, well, look, I think it's different", "tokens": [51660, 865, 11, 731, 11, 574, 11, 286, 519, 309, 311, 819, 51730], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 262, "seek": 60342, "start": 630.74, "end": 632.5, "text": " because our brains are not built", "tokens": [51730, 570, 527, 15442, 366, 406, 3094, 51818], "temperature": 0.0, "avg_logprob": -0.13515513652079814, "compression_ratio": 1.824607329842932, "no_speech_prob": 0.0008655317360535264}, {"id": 263, "seek": 63250, "start": 632.54, "end": 635.22, "text": " for doing Monte Carlo research, right?", "tokens": [50366, 337, 884, 38105, 45112, 2132, 11, 558, 30, 50500], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 264, "seek": 63250, "start": 635.22, "end": 639.98, "text": " It's just not the way our organic brains would work.", "tokens": [50500, 467, 311, 445, 406, 264, 636, 527, 10220, 15442, 576, 589, 13, 50738], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 265, "seek": 63250, "start": 639.98, "end": 642.74, "text": " So I think that in order to compensate for that,", "tokens": [50738, 407, 286, 519, 300, 294, 1668, 281, 29458, 337, 300, 11, 50876], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 266, "seek": 63250, "start": 642.74, "end": 644.86, "text": " you know, people like Einstein have come up, you know,", "tokens": [50876, 291, 458, 11, 561, 411, 23486, 362, 808, 493, 11, 291, 458, 11, 50982], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 267, "seek": 63250, "start": 644.86, "end": 647.14, "text": " their brains have using their intuition", "tokens": [50982, 641, 15442, 362, 1228, 641, 24002, 51096], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 268, "seek": 63250, "start": 647.14, "end": 649.26, "text": " and, you know, we maybe come to what intuition is,", "tokens": [51096, 293, 11, 291, 458, 11, 321, 1310, 808, 281, 437, 24002, 307, 11, 51202], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 269, "seek": 63250, "start": 649.26, "end": 651.42, "text": " but they use their sort of knowledge", "tokens": [51202, 457, 436, 764, 641, 1333, 295, 3601, 51310], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 270, "seek": 63250, "start": 651.42, "end": 654.54, "text": " and their experience to build extremely, you know,", "tokens": [51310, 293, 641, 1752, 281, 1322, 4664, 11, 291, 458, 11, 51466], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 271, "seek": 63250, "start": 654.54, "end": 657.5, "text": " in Einstein's case, extremely accurate models of physics,", "tokens": [51466, 294, 23486, 311, 1389, 11, 4664, 8559, 5245, 295, 10649, 11, 51614], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 272, "seek": 63250, "start": 657.5, "end": 659.86, "text": " including these sort of mental simulations.", "tokens": [51614, 3009, 613, 1333, 295, 4973, 35138, 13, 51732], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 273, "seek": 63250, "start": 659.86, "end": 661.18, "text": " I think if you read about Einstein", "tokens": [51732, 286, 519, 498, 291, 1401, 466, 23486, 51798], "temperature": 0.0, "avg_logprob": -0.11143568319867747, "compression_ratio": 1.792982456140351, "no_speech_prob": 0.001816525007598102}, {"id": 274, "seek": 66118, "start": 661.18, "end": 663.62, "text": " and how he came up with things, he used to visualize", "tokens": [50364, 293, 577, 415, 1361, 493, 365, 721, 11, 415, 1143, 281, 23273, 50486], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 275, "seek": 66118, "start": 663.62, "end": 667.78, "text": " and sort of really kind of feel", "tokens": [50486, 293, 1333, 295, 534, 733, 295, 841, 50694], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 276, "seek": 66118, "start": 667.78, "end": 669.7399999999999, "text": " what these physical systems should be like,", "tokens": [50694, 437, 613, 4001, 3652, 820, 312, 411, 11, 50792], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 277, "seek": 66118, "start": 669.7399999999999, "end": 670.9799999999999, "text": " not just the mathematics of it,", "tokens": [50792, 406, 445, 264, 18666, 295, 309, 11, 50854], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 278, "seek": 66118, "start": 670.9799999999999, "end": 672.78, "text": " but have a really intuitive feel", "tokens": [50854, 457, 362, 257, 534, 21769, 841, 50944], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 279, "seek": 66118, "start": 672.78, "end": 674.5, "text": " for what they would be like in reality.", "tokens": [50944, 337, 437, 436, 576, 312, 411, 294, 4103, 13, 51030], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 280, "seek": 66118, "start": 674.5, "end": 677.5799999999999, "text": " And that allowed him to think these sort of very outlandish", "tokens": [51030, 400, 300, 4350, 796, 281, 519, 613, 1333, 295, 588, 484, 1661, 742, 51184], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 281, "seek": 66118, "start": 677.5799999999999, "end": 679.14, "text": " thoughts at the time.", "tokens": [51184, 4598, 412, 264, 565, 13, 51262], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 282, "seek": 66118, "start": 679.14, "end": 681.7399999999999, "text": " So I think that it's the sophistication", "tokens": [51262, 407, 286, 519, 300, 309, 311, 264, 15572, 399, 51392], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 283, "seek": 66118, "start": 681.7399999999999, "end": 683.42, "text": " of the world models that we're building,", "tokens": [51392, 295, 264, 1002, 5245, 300, 321, 434, 2390, 11, 51476], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 284, "seek": 66118, "start": 683.42, "end": 685.9399999999999, "text": " which then, you know, if you imagine your world model", "tokens": [51476, 597, 550, 11, 291, 458, 11, 498, 291, 3811, 428, 1002, 2316, 51602], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 285, "seek": 66118, "start": 685.9399999999999, "end": 689.26, "text": " can get you to a certain node in a tree that you're searching,", "tokens": [51602, 393, 483, 291, 281, 257, 1629, 9984, 294, 257, 4230, 300, 291, 434, 10808, 11, 51768], "temperature": 0.0, "avg_logprob": -0.09798080333765002, "compression_ratio": 1.7389830508474575, "no_speech_prob": 0.002565769711509347}, {"id": 286, "seek": 68926, "start": 689.26, "end": 691.3, "text": " and then you just do a little bit of search", "tokens": [50364, 293, 550, 291, 445, 360, 257, 707, 857, 295, 3164, 50466], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 287, "seek": 68926, "start": 691.3, "end": 693.58, "text": " around that node, that leaf node,", "tokens": [50466, 926, 300, 9984, 11, 300, 10871, 9984, 11, 50580], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 288, "seek": 68926, "start": 693.58, "end": 695.9399999999999, "text": " and that gets you to these original places.", "tokens": [50580, 293, 300, 2170, 291, 281, 613, 3380, 3190, 13, 50698], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 289, "seek": 68926, "start": 695.9399999999999, "end": 697.9399999999999, "text": " But obviously, if your model is,", "tokens": [50698, 583, 2745, 11, 498, 428, 2316, 307, 11, 50798], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 290, "seek": 68926, "start": 697.9399999999999, "end": 701.02, "text": " and your judgment on that model is very, very good,", "tokens": [50798, 293, 428, 12216, 322, 300, 2316, 307, 588, 11, 588, 665, 11, 50952], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 291, "seek": 68926, "start": 701.02, "end": 703.98, "text": " then you can pick which leaf nodes you should sort of expand", "tokens": [50952, 550, 291, 393, 1888, 597, 10871, 13891, 291, 820, 1333, 295, 5268, 51100], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 292, "seek": 68926, "start": 703.98, "end": 705.9, "text": " with search much more accurately.", "tokens": [51100, 365, 3164, 709, 544, 20095, 13, 51196], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 293, "seek": 68926, "start": 705.9, "end": 708.14, "text": " So therefore, overall, you do a lot less search.", "tokens": [51196, 407, 4412, 11, 4787, 11, 291, 360, 257, 688, 1570, 3164, 13, 51308], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 294, "seek": 68926, "start": 708.14, "end": 709.9, "text": " I mean, there's no way that, you know,", "tokens": [51308, 286, 914, 11, 456, 311, 572, 636, 300, 11, 291, 458, 11, 51396], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 295, "seek": 68926, "start": 709.9, "end": 712.46, "text": " any human could do a kind of brute force search", "tokens": [51396, 604, 1952, 727, 360, 257, 733, 295, 47909, 3464, 3164, 51524], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 296, "seek": 68926, "start": 712.46, "end": 714.58, "text": " over any kind of significant space.", "tokens": [51524, 670, 604, 733, 295, 4776, 1901, 13, 51630], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 297, "seek": 68926, "start": 714.58, "end": 715.9399999999999, "text": " Yeah, yeah, yeah.", "tokens": [51630, 865, 11, 1338, 11, 1338, 13, 51698], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 298, "seek": 68926, "start": 715.9399999999999, "end": 717.54, "text": " A big sort of open question right now", "tokens": [51698, 316, 955, 1333, 295, 1269, 1168, 558, 586, 51778], "temperature": 0.0, "avg_logprob": -0.07730790086694665, "compression_ratio": 1.7993197278911566, "no_speech_prob": 0.0009373084758408368}, {"id": 299, "seek": 71754, "start": 717.54, "end": 720.62, "text": " is whether RL will allow these models to do the self-placed", "tokens": [50364, 307, 1968, 497, 43, 486, 2089, 613, 5245, 281, 360, 264, 2698, 12, 564, 3839, 50518], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 300, "seek": 71754, "start": 720.62, "end": 722.54, "text": " synthetic data to get over the data bottleneck.", "tokens": [50518, 23420, 1412, 281, 483, 670, 264, 1412, 44641, 547, 13, 50614], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 301, "seek": 71754, "start": 722.54, "end": 724.06, "text": " It sounds like you're optimistic about this.", "tokens": [50614, 467, 3263, 411, 291, 434, 19397, 466, 341, 13, 50690], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 302, "seek": 71754, "start": 724.06, "end": 725.5799999999999, "text": " Yeah, I'm very optimistic about that.", "tokens": [50690, 865, 11, 286, 478, 588, 19397, 466, 300, 13, 50766], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 303, "seek": 71754, "start": 725.5799999999999, "end": 727.62, "text": " I mean, I think, well, first of all,", "tokens": [50766, 286, 914, 11, 286, 519, 11, 731, 11, 700, 295, 439, 11, 50868], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 304, "seek": 71754, "start": 727.62, "end": 729.78, "text": " there's still a lot more data, I think, that can be used,", "tokens": [50868, 456, 311, 920, 257, 688, 544, 1412, 11, 286, 519, 11, 300, 393, 312, 1143, 11, 50976], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 305, "seek": 71754, "start": 729.78, "end": 732.3, "text": " especially if one views like multimodal and video", "tokens": [50976, 2318, 498, 472, 6809, 411, 32972, 378, 304, 293, 960, 51102], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 306, "seek": 71754, "start": 732.3, "end": 733.3, "text": " and these kind of things.", "tokens": [51102, 293, 613, 733, 295, 721, 13, 51152], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 307, "seek": 71754, "start": 733.3, "end": 736.6999999999999, "text": " And obviously, you know, society's adding more data", "tokens": [51152, 400, 2745, 11, 291, 458, 11, 4086, 311, 5127, 544, 1412, 51322], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 308, "seek": 71754, "start": 736.6999999999999, "end": 738.5799999999999, "text": " all the time.", "tokens": [51322, 439, 264, 565, 13, 51416], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 309, "seek": 71754, "start": 738.5799999999999, "end": 741.5799999999999, "text": " But I think to the internet and things like that.", "tokens": [51416, 583, 286, 519, 281, 264, 4705, 293, 721, 411, 300, 13, 51566], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 310, "seek": 71754, "start": 741.5799999999999, "end": 743.98, "text": " But I think that there's a lot of scope", "tokens": [51566, 583, 286, 519, 300, 456, 311, 257, 688, 295, 11923, 51686], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 311, "seek": 71754, "start": 743.98, "end": 746.14, "text": " for creating synthetic data.", "tokens": [51686, 337, 4084, 23420, 1412, 13, 51794], "temperature": 0.0, "avg_logprob": -0.16528019538292518, "compression_ratio": 1.7901639344262295, "no_speech_prob": 0.008247315883636475}, {"id": 312, "seek": 74614, "start": 746.14, "end": 749.62, "text": " We're looking at different ways partly through simulation", "tokens": [50364, 492, 434, 1237, 412, 819, 2098, 17031, 807, 16575, 50538], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 313, "seek": 74614, "start": 749.62, "end": 752.1, "text": " and using very realistic games environments,", "tokens": [50538, 293, 1228, 588, 12465, 2813, 12388, 11, 50662], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 314, "seek": 74614, "start": 752.1, "end": 755.26, "text": " for example, to generate realistic data,", "tokens": [50662, 337, 1365, 11, 281, 8460, 12465, 1412, 11, 50820], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 315, "seek": 74614, "start": 755.26, "end": 757.1, "text": " but also self-play.", "tokens": [50820, 457, 611, 2698, 12, 2858, 13, 50912], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 316, "seek": 74614, "start": 757.1, "end": 761.3, "text": " So that's where systems interact with each other", "tokens": [50912, 407, 300, 311, 689, 3652, 4648, 365, 1184, 661, 51122], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 317, "seek": 74614, "start": 761.3, "end": 763.46, "text": " or converse with each other.", "tokens": [51122, 420, 416, 4308, 365, 1184, 661, 13, 51230], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 318, "seek": 74614, "start": 763.46, "end": 764.78, "text": " And in the sense of, you know,", "tokens": [51230, 400, 294, 264, 2020, 295, 11, 291, 458, 11, 51296], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 319, "seek": 74614, "start": 764.78, "end": 766.62, "text": " work very well for us with AlphaGo and AlphaZero,", "tokens": [51296, 589, 588, 731, 337, 505, 365, 20588, 12104, 293, 20588, 57, 2032, 11, 51388], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 320, "seek": 74614, "start": 766.62, "end": 769.1, "text": " where we got the systems to play against each other", "tokens": [51388, 689, 321, 658, 264, 3652, 281, 862, 1970, 1184, 661, 51512], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 321, "seek": 74614, "start": 769.1, "end": 770.9399999999999, "text": " and actually learn from each other's mistakes", "tokens": [51512, 293, 767, 1466, 490, 1184, 661, 311, 8038, 51604], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 322, "seek": 74614, "start": 770.9399999999999, "end": 772.9, "text": " and build up a knowledge base that way.", "tokens": [51604, 293, 1322, 493, 257, 3601, 3096, 300, 636, 13, 51702], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 323, "seek": 74614, "start": 772.9, "end": 774.8199999999999, "text": " And I think there are some good analogies for that.", "tokens": [51702, 400, 286, 519, 456, 366, 512, 665, 16660, 530, 337, 300, 13, 51798], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 324, "seek": 74614, "start": 774.8199999999999, "end": 775.98, "text": " It's a little bit more complicated,", "tokens": [51798, 467, 311, 257, 707, 857, 544, 6179, 11, 51856], "temperature": 0.0, "avg_logprob": -0.11371133710954573, "compression_ratio": 1.696594427244582, "no_speech_prob": 0.0061827730387449265}, {"id": 325, "seek": 77598, "start": 775.98, "end": 779.82, "text": " but to build a general kind of world data.", "tokens": [50364, 457, 281, 1322, 257, 2674, 733, 295, 1002, 1412, 13, 50556], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 326, "seek": 77598, "start": 779.82, "end": 781.82, "text": " How do you get to the point where these models,", "tokens": [50556, 1012, 360, 291, 483, 281, 264, 935, 689, 613, 5245, 11, 50656], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 327, "seek": 77598, "start": 781.82, "end": 783.9, "text": " the sort of synthetic data they're outputting", "tokens": [50656, 264, 1333, 295, 23420, 1412, 436, 434, 5598, 783, 50760], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 328, "seek": 77598, "start": 783.9, "end": 785.46, "text": " and their self-play they're doing,", "tokens": [50760, 293, 641, 2698, 12, 2858, 436, 434, 884, 11, 50838], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 329, "seek": 77598, "start": 785.46, "end": 787.5, "text": " is not just more of what they've already got", "tokens": [50838, 307, 406, 445, 544, 295, 437, 436, 600, 1217, 658, 50940], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 330, "seek": 77598, "start": 787.5, "end": 788.34, "text": " in their data set,", "tokens": [50940, 294, 641, 1412, 992, 11, 50982], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 331, "seek": 77598, "start": 788.34, "end": 790.5, "text": " but is something they haven't seen before?", "tokens": [50982, 457, 307, 746, 436, 2378, 380, 1612, 949, 30, 51090], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 332, "seek": 77598, "start": 790.5, "end": 792.26, "text": " You know what I mean, to actually improve the abilities.", "tokens": [51090, 509, 458, 437, 286, 914, 11, 281, 767, 3470, 264, 11582, 13, 51178], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 333, "seek": 77598, "start": 792.26, "end": 795.94, "text": " Yeah, so there, I think there's a whole science needed.", "tokens": [51178, 865, 11, 370, 456, 11, 286, 519, 456, 311, 257, 1379, 3497, 2978, 13, 51362], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 334, "seek": 77598, "start": 795.94, "end": 797.94, "text": " And I think we're still in the nascent stage of this", "tokens": [51362, 400, 286, 519, 321, 434, 920, 294, 264, 5382, 2207, 3233, 295, 341, 51462], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 335, "seek": 77598, "start": 797.94, "end": 800.02, "text": " of data curation and data analysis.", "tokens": [51462, 295, 1412, 1262, 399, 293, 1412, 5215, 13, 51566], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 336, "seek": 77598, "start": 800.02, "end": 802.34, "text": " So actually analyzing the holes", "tokens": [51566, 407, 767, 23663, 264, 8118, 51682], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 337, "seek": 77598, "start": 802.34, "end": 804.3000000000001, "text": " that you have in your data distribution.", "tokens": [51682, 300, 291, 362, 294, 428, 1412, 7316, 13, 51780], "temperature": 0.0, "avg_logprob": -0.16652266395013063, "compression_ratio": 1.722741433021807, "no_speech_prob": 0.0006426905165426433}, {"id": 338, "seek": 80430, "start": 804.3, "end": 806.5799999999999, "text": " And this is important for things like fairness and bias", "tokens": [50364, 400, 341, 307, 1021, 337, 721, 411, 29765, 293, 12577, 50478], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 339, "seek": 80430, "start": 806.5799999999999, "end": 808.9799999999999, "text": " and other stuff to remove that from the system is to,", "tokens": [50478, 293, 661, 1507, 281, 4159, 300, 490, 264, 1185, 307, 281, 11, 50598], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 340, "seek": 80430, "start": 808.9799999999999, "end": 811.5, "text": " is to try and really make sure that your data set", "tokens": [50598, 307, 281, 853, 293, 534, 652, 988, 300, 428, 1412, 992, 50724], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 341, "seek": 80430, "start": 811.5, "end": 813.02, "text": " is representative of the distribution", "tokens": [50724, 307, 12424, 295, 264, 7316, 50800], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 342, "seek": 80430, "start": 813.02, "end": 814.2199999999999, "text": " you're trying to learn.", "tokens": [50800, 291, 434, 1382, 281, 1466, 13, 50860], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 343, "seek": 80430, "start": 814.2199999999999, "end": 816.54, "text": " And, you know, there are many tricks there.", "tokens": [50860, 400, 11, 291, 458, 11, 456, 366, 867, 11733, 456, 13, 50976], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 344, "seek": 80430, "start": 816.54, "end": 818.02, "text": " One can use like over-weighting", "tokens": [50976, 1485, 393, 764, 411, 670, 12, 12329, 278, 51050], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 345, "seek": 80430, "start": 818.02, "end": 820.02, "text": " or replaying certain parts of the data.", "tokens": [51050, 420, 23836, 278, 1629, 3166, 295, 264, 1412, 13, 51150], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 346, "seek": 80430, "start": 820.02, "end": 822.54, "text": " Or you could imagine if you identify some,", "tokens": [51150, 1610, 291, 727, 3811, 498, 291, 5876, 512, 11, 51276], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 347, "seek": 80430, "start": 822.54, "end": 824.02, "text": " some gap in your data set,", "tokens": [51276, 512, 7417, 294, 428, 1412, 992, 11, 51350], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 348, "seek": 80430, "start": 824.02, "end": 826.8199999999999, "text": " that's where you put your synthetic generation capabilities", "tokens": [51350, 300, 311, 689, 291, 829, 428, 23420, 5125, 10862, 51490], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 349, "seek": 80430, "start": 826.8199999999999, "end": 827.66, "text": " to work on.", "tokens": [51490, 281, 589, 322, 13, 51532], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 350, "seek": 80430, "start": 827.66, "end": 830.5799999999999, "text": " Yeah, so, you know, nowadays people are paying attention", "tokens": [51532, 865, 11, 370, 11, 291, 458, 11, 13434, 561, 366, 6229, 3202, 51678], "temperature": 0.0, "avg_logprob": -0.16231282552083334, "compression_ratio": 1.768976897689769, "no_speech_prob": 0.0008384950924664736}, {"id": 351, "seek": 83058, "start": 830.58, "end": 835.4200000000001, "text": " to the RL stuff that Alfa deep-minded many years before.", "tokens": [50364, 281, 264, 497, 43, 1507, 300, 967, 11771, 2452, 12, 23310, 867, 924, 949, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 352, "seek": 83058, "start": 835.4200000000001, "end": 838.0600000000001, "text": " What are the sort of either early research directions", "tokens": [50606, 708, 366, 264, 1333, 295, 2139, 2440, 2132, 11095, 50738], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 353, "seek": 83058, "start": 838.0600000000001, "end": 839.86, "text": " or something that was done way back in the past,", "tokens": [50738, 420, 746, 300, 390, 1096, 636, 646, 294, 264, 1791, 11, 50828], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 354, "seek": 83058, "start": 839.86, "end": 841.82, "text": " but people just haven't been paying attention to,", "tokens": [50828, 457, 561, 445, 2378, 380, 668, 6229, 3202, 281, 11, 50926], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 355, "seek": 83058, "start": 841.82, "end": 843.1, "text": " that you think will be a big deal, right?", "tokens": [50926, 300, 291, 519, 486, 312, 257, 955, 2028, 11, 558, 30, 50990], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 356, "seek": 83058, "start": 843.1, "end": 844.7, "text": " Like there's a time where people weren't paying attention", "tokens": [50990, 1743, 456, 311, 257, 565, 689, 561, 4999, 380, 6229, 3202, 51070], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 357, "seek": 83058, "start": 844.7, "end": 845.5400000000001, "text": " to scaling.", "tokens": [51070, 281, 21589, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 358, "seek": 83058, "start": 845.5400000000001, "end": 847.0600000000001, "text": " What's the thing now where it's like totally underrated?", "tokens": [51112, 708, 311, 264, 551, 586, 689, 309, 311, 411, 3879, 833, 5468, 30, 51188], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 359, "seek": 83058, "start": 847.0600000000001, "end": 848.5, "text": " Well, actually, I think that, you know,", "tokens": [51188, 1042, 11, 767, 11, 286, 519, 300, 11, 291, 458, 11, 51260], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 360, "seek": 83058, "start": 848.5, "end": 851.1, "text": " there's the history of the sort of last couple of decades", "tokens": [51260, 456, 311, 264, 2503, 295, 264, 1333, 295, 1036, 1916, 295, 7878, 51390], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 361, "seek": 83058, "start": 851.1, "end": 853.3000000000001, "text": " has been things coming in and out of fashion, right?", "tokens": [51390, 575, 668, 721, 1348, 294, 293, 484, 295, 6700, 11, 558, 30, 51500], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 362, "seek": 83058, "start": 853.3000000000001, "end": 855.98, "text": " And I do feel like a while ago,", "tokens": [51500, 400, 286, 360, 841, 411, 257, 1339, 2057, 11, 51634], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 363, "seek": 83058, "start": 855.98, "end": 857.5, "text": " when, you know, maybe five plus years ago,", "tokens": [51634, 562, 11, 291, 458, 11, 1310, 1732, 1804, 924, 2057, 11, 51710], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 364, "seek": 83058, "start": 857.5, "end": 859.22, "text": " when we were pioneering with AlphaGo", "tokens": [51710, 562, 321, 645, 19761, 1794, 365, 20588, 12104, 51796], "temperature": 0.0, "avg_logprob": -0.1652934876355258, "compression_ratio": 1.7855153203342617, "no_speech_prob": 0.010241611860692501}, {"id": 365, "seek": 85922, "start": 859.22, "end": 862.4200000000001, "text": " and before that, DQN, where it was the first system,", "tokens": [50364, 293, 949, 300, 11, 413, 48, 45, 11, 689, 309, 390, 264, 700, 1185, 11, 50524], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 366, "seek": 85922, "start": 862.4200000000001, "end": 863.78, "text": " you know, that worked on Atari,", "tokens": [50524, 291, 458, 11, 300, 2732, 322, 41381, 11, 50592], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 367, "seek": 85922, "start": 863.78, "end": 866.78, "text": " about how first big system really more than 10 years ago now", "tokens": [50592, 466, 577, 700, 955, 1185, 534, 544, 813, 1266, 924, 2057, 586, 50742], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 368, "seek": 85922, "start": 866.78, "end": 869.6600000000001, "text": " that scaled up Q learning and reinforcement learning techniques", "tokens": [50742, 300, 36039, 493, 1249, 2539, 293, 29280, 2539, 7512, 50886], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 369, "seek": 85922, "start": 869.6600000000001, "end": 872.14, "text": " to deal, you know, combine that with deep learning", "tokens": [50886, 281, 2028, 11, 291, 458, 11, 10432, 300, 365, 2452, 2539, 51010], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 370, "seek": 85922, "start": 872.14, "end": 874.02, "text": " to create deep reinforcement learning", "tokens": [51010, 281, 1884, 2452, 29280, 2539, 51104], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 371, "seek": 85922, "start": 874.02, "end": 877.26, "text": " and then use that to scale up to complete some,", "tokens": [51104, 293, 550, 764, 300, 281, 4373, 493, 281, 3566, 512, 11, 51266], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 372, "seek": 85922, "start": 877.26, "end": 879.1800000000001, "text": " you know, master some pretty complex tasks", "tokens": [51266, 291, 458, 11, 4505, 512, 1238, 3997, 9608, 51362], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 373, "seek": 85922, "start": 879.1800000000001, "end": 881.38, "text": " like playing Atari games just from the pixels.", "tokens": [51362, 411, 2433, 41381, 2813, 445, 490, 264, 18668, 13, 51472], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 374, "seek": 85922, "start": 881.38, "end": 885.5, "text": " And I do actually think a lot of those ideas", "tokens": [51472, 400, 286, 360, 767, 519, 257, 688, 295, 729, 3487, 51678], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 375, "seek": 85922, "start": 885.5, "end": 886.94, "text": " need to come back in again.", "tokens": [51678, 643, 281, 808, 646, 294, 797, 13, 51750], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 376, "seek": 85922, "start": 886.94, "end": 888.1, "text": " And as we talked about earlier,", "tokens": [51750, 400, 382, 321, 2825, 466, 3071, 11, 51808], "temperature": 0.0, "avg_logprob": -0.12082691469054291, "compression_ratio": 1.7973421926910298, "no_speech_prob": 0.008912920020520687}, {"id": 377, "seek": 88810, "start": 888.1, "end": 891.5400000000001, "text": " combine it with the new advances in large models", "tokens": [50364, 10432, 309, 365, 264, 777, 25297, 294, 2416, 5245, 50536], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 378, "seek": 88810, "start": 891.5400000000001, "end": 892.74, "text": " and large multimodal models,", "tokens": [50536, 293, 2416, 32972, 378, 304, 5245, 11, 50596], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 379, "seek": 88810, "start": 892.74, "end": 894.0600000000001, "text": " which is obviously very exciting as well.", "tokens": [50596, 597, 307, 2745, 588, 4670, 382, 731, 13, 50662], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 380, "seek": 88810, "start": 894.0600000000001, "end": 896.46, "text": " So I do think there's a lot of potential", "tokens": [50662, 407, 286, 360, 519, 456, 311, 257, 688, 295, 3995, 50782], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 381, "seek": 88810, "start": 896.46, "end": 899.46, "text": " for combining some of those older ideas together", "tokens": [50782, 337, 21928, 512, 295, 729, 4906, 3487, 1214, 50932], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 382, "seek": 88810, "start": 899.46, "end": 900.46, "text": " with the newer ones.", "tokens": [50932, 365, 264, 17628, 2306, 13, 50982], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 383, "seek": 88810, "start": 900.46, "end": 903.46, "text": " Is there any potential for something to come,", "tokens": [50982, 1119, 456, 604, 3995, 337, 746, 281, 808, 11, 51132], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 384, "seek": 88810, "start": 903.46, "end": 906.38, "text": " the AGI to eventually come from just a pure RRL approach?", "tokens": [51132, 264, 316, 26252, 281, 4728, 808, 490, 445, 257, 6075, 497, 10740, 3109, 30, 51278], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 385, "seek": 88810, "start": 906.38, "end": 907.94, "text": " Like the way we're talking about it,", "tokens": [51278, 1743, 264, 636, 321, 434, 1417, 466, 309, 11, 51356], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 386, "seek": 88810, "start": 907.94, "end": 909.7, "text": " it sounds like there'll be,", "tokens": [51356, 309, 3263, 411, 456, 603, 312, 11, 51444], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 387, "seek": 88810, "start": 909.7, "end": 912.14, "text": " the LLM will form the gripe fryer", "tokens": [51444, 264, 441, 43, 44, 486, 1254, 264, 17865, 494, 431, 7224, 51566], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 388, "seek": 88810, "start": 912.14, "end": 913.82, "text": " and then this sort of research will go on top of that.", "tokens": [51566, 293, 550, 341, 1333, 295, 2132, 486, 352, 322, 1192, 295, 300, 13, 51650], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 389, "seek": 88810, "start": 913.82, "end": 915.46, "text": " Or is it a possibility to just like completely", "tokens": [51650, 1610, 307, 309, 257, 7959, 281, 445, 411, 2584, 51732], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 390, "seek": 88810, "start": 915.46, "end": 916.3000000000001, "text": " out of the dark?", "tokens": [51732, 484, 295, 264, 2877, 30, 51774], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 391, "seek": 88810, "start": 916.3000000000001, "end": 917.22, "text": " I think I certainly, you know,", "tokens": [51774, 286, 519, 286, 3297, 11, 291, 458, 11, 51820], "temperature": 0.0, "avg_logprob": -0.17401485908322217, "compression_ratio": 1.694767441860465, "no_speech_prob": 0.002913613338023424}, {"id": 392, "seek": 91722, "start": 917.22, "end": 918.94, "text": " theoretically I think there's no reason", "tokens": [50364, 29400, 286, 519, 456, 311, 572, 1778, 50450], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 393, "seek": 91722, "start": 918.94, "end": 921.5, "text": " why you couldn't go full alpha zero like on it.", "tokens": [50450, 983, 291, 2809, 380, 352, 1577, 8961, 4018, 411, 322, 309, 13, 50578], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 394, "seek": 91722, "start": 921.5, "end": 925.34, "text": " And there are some people here at Google DeepMind", "tokens": [50578, 400, 456, 366, 512, 561, 510, 412, 3329, 14895, 44, 471, 50770], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 395, "seek": 91722, "start": 925.34, "end": 928.14, "text": " and in the RL community who work on that, right?", "tokens": [50770, 293, 294, 264, 497, 43, 1768, 567, 589, 322, 300, 11, 558, 30, 50910], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 396, "seek": 91722, "start": 928.14, "end": 932.5400000000001, "text": " And fully assuming no priors, no data", "tokens": [50910, 400, 4498, 11926, 572, 1790, 830, 11, 572, 1412, 51130], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 397, "seek": 91722, "start": 932.5400000000001, "end": 935.78, "text": " and just build all knowledge from scratch.", "tokens": [51130, 293, 445, 1322, 439, 3601, 490, 8459, 13, 51292], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 398, "seek": 91722, "start": 935.78, "end": 938.62, "text": " And I think that's valuable because of course, you know,", "tokens": [51292, 400, 286, 519, 300, 311, 8263, 570, 295, 1164, 11, 291, 458, 11, 51434], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 399, "seek": 91722, "start": 938.62, "end": 940.5, "text": " those ideas and those algorithms", "tokens": [51434, 729, 3487, 293, 729, 14642, 51528], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 400, "seek": 91722, "start": 940.5, "end": 943.4200000000001, "text": " should also work when you have some knowledge too.", "tokens": [51528, 820, 611, 589, 562, 291, 362, 512, 3601, 886, 13, 51674], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 401, "seek": 91722, "start": 943.4200000000001, "end": 944.26, "text": " But having said that,", "tokens": [51674, 583, 1419, 848, 300, 11, 51716], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 402, "seek": 91722, "start": 944.26, "end": 946.38, "text": " I think by far probably my betting", "tokens": [51716, 286, 519, 538, 1400, 1391, 452, 34246, 51822], "temperature": 0.0, "avg_logprob": -0.16752167670957505, "compression_ratio": 1.6202090592334495, "no_speech_prob": 0.003362177172675729}, {"id": 403, "seek": 94638, "start": 946.38, "end": 948.22, "text": " would be the quickest way to get to AGI", "tokens": [50364, 576, 312, 264, 49403, 636, 281, 483, 281, 316, 26252, 50456], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 404, "seek": 94638, "start": 948.22, "end": 949.82, "text": " in the most likely plausible way", "tokens": [50456, 294, 264, 881, 3700, 39925, 636, 50536], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 405, "seek": 94638, "start": 949.82, "end": 951.66, "text": " is to use all the knowledge", "tokens": [50536, 307, 281, 764, 439, 264, 3601, 50628], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 406, "seek": 94638, "start": 951.66, "end": 953.18, "text": " that's existing in the world right now", "tokens": [50628, 300, 311, 6741, 294, 264, 1002, 558, 586, 50704], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 407, "seek": 94638, "start": 953.18, "end": 955.14, "text": " on things like the web and that we've collected", "tokens": [50704, 322, 721, 411, 264, 3670, 293, 300, 321, 600, 11087, 50802], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 408, "seek": 94638, "start": 955.14, "end": 957.66, "text": " and we have these scalable algorithms", "tokens": [50802, 293, 321, 362, 613, 38481, 14642, 50928], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 409, "seek": 94638, "start": 957.66, "end": 960.74, "text": " like transformers that are capable", "tokens": [50928, 411, 4088, 433, 300, 366, 8189, 51082], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 410, "seek": 94638, "start": 960.74, "end": 963.02, "text": " of ingesting all of that information.", "tokens": [51082, 295, 3957, 8714, 439, 295, 300, 1589, 13, 51196], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 411, "seek": 94638, "start": 963.02, "end": 966.66, "text": " And I don't see why you wouldn't start with a model", "tokens": [51196, 400, 286, 500, 380, 536, 983, 291, 2759, 380, 722, 365, 257, 2316, 51378], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 412, "seek": 94638, "start": 966.66, "end": 969.82, "text": " as a kind of prior or to build on and to make predictions", "tokens": [51378, 382, 257, 733, 295, 4059, 420, 281, 1322, 322, 293, 281, 652, 21264, 51536], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 413, "seek": 94638, "start": 969.82, "end": 971.86, "text": " that helps bootstrap your learning.", "tokens": [51536, 300, 3665, 11450, 372, 4007, 428, 2539, 13, 51638], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 414, "seek": 94638, "start": 971.86, "end": 973.98, "text": " I just think it doesn't make sense", "tokens": [51638, 286, 445, 519, 309, 1177, 380, 652, 2020, 51744], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 415, "seek": 94638, "start": 973.98, "end": 975.26, "text": " not to make use of that.", "tokens": [51744, 406, 281, 652, 764, 295, 300, 13, 51808], "temperature": 0.0, "avg_logprob": -0.08403699415443587, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.005975468084216118}, {"id": 416, "seek": 97526, "start": 975.3, "end": 978.8199999999999, "text": " So my betting would be is that, you know,", "tokens": [50366, 407, 452, 34246, 576, 312, 307, 300, 11, 291, 458, 11, 50542], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 417, "seek": 97526, "start": 978.8199999999999, "end": 983.46, "text": " the final AGI system will have these large multimodals", "tokens": [50542, 264, 2572, 316, 26252, 1185, 486, 362, 613, 2416, 32972, 378, 1124, 50774], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 418, "seek": 97526, "start": 983.46, "end": 986.18, "text": " as part of the overall solution", "tokens": [50774, 382, 644, 295, 264, 4787, 3827, 50910], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 419, "seek": 97526, "start": 986.18, "end": 988.5, "text": " but probably won't be enough on their own.", "tokens": [50910, 457, 1391, 1582, 380, 312, 1547, 322, 641, 1065, 13, 51026], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 420, "seek": 97526, "start": 988.5, "end": 991.26, "text": " You will need this additional planning search on top.", "tokens": [51026, 509, 486, 643, 341, 4497, 5038, 3164, 322, 1192, 13, 51164], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 421, "seek": 97526, "start": 991.26, "end": 992.78, "text": " Okay, this sounds like the answer", "tokens": [51164, 1033, 11, 341, 3263, 411, 264, 1867, 51240], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 422, "seek": 97526, "start": 992.78, "end": 994.98, "text": " to the question we're about to ask which is", "tokens": [51240, 281, 264, 1168, 321, 434, 466, 281, 1029, 597, 307, 51350], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 423, "seek": 97526, "start": 994.98, "end": 997.42, "text": " what is somebody who's been in this field", "tokens": [51350, 437, 307, 2618, 567, 311, 668, 294, 341, 2519, 51472], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 424, "seek": 97526, "start": 997.42, "end": 999.58, "text": " for a long time and seen different trends come and go,", "tokens": [51472, 337, 257, 938, 565, 293, 1612, 819, 13892, 808, 293, 352, 11, 51580], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 425, "seek": 97526, "start": 999.58, "end": 1001.46, "text": " what do you think that the strong version", "tokens": [51580, 437, 360, 291, 519, 300, 264, 2068, 3037, 51674], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 426, "seek": 97526, "start": 1001.46, "end": 1002.8199999999999, "text": " of the scaling hypothesis gets right", "tokens": [51674, 295, 264, 21589, 17291, 2170, 558, 51742], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 427, "seek": 97526, "start": 1002.8199999999999, "end": 1003.66, "text": " and what does it get wrong?", "tokens": [51742, 293, 437, 775, 309, 483, 2085, 30, 51784], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 428, "seek": 97526, "start": 1003.66, "end": 1004.58, "text": " It's just the idea that you just throw", "tokens": [51784, 467, 311, 445, 264, 1558, 300, 291, 445, 3507, 51830], "temperature": 0.0, "avg_logprob": -0.145962590184705, "compression_ratio": 1.68, "no_speech_prob": 0.0001454452722100541}, {"id": 429, "seek": 100458, "start": 1004.58, "end": 1006.5400000000001, "text": " and have computed a wide enough distribution of data", "tokens": [50364, 293, 362, 40610, 257, 4874, 1547, 7316, 295, 1412, 50462], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 430, "seek": 100458, "start": 1006.5400000000001, "end": 1007.38, "text": " and you get intelligence.", "tokens": [50462, 293, 291, 483, 7599, 13, 50504], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 431, "seek": 100458, "start": 1007.38, "end": 1009.1800000000001, "text": " Yeah, look, my view is this is kind", "tokens": [50504, 865, 11, 574, 11, 452, 1910, 307, 341, 307, 733, 50594], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 432, "seek": 100458, "start": 1009.1800000000001, "end": 1010.62, "text": " of an empirical question right now.", "tokens": [50594, 295, 364, 31886, 1168, 558, 586, 13, 50666], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 433, "seek": 100458, "start": 1010.62, "end": 1012.14, "text": " So I think it was pretty surprising", "tokens": [50666, 407, 286, 519, 309, 390, 1238, 8830, 50742], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 434, "seek": 100458, "start": 1012.14, "end": 1015.6600000000001, "text": " to almost everyone, including the people who first worked", "tokens": [50742, 281, 1920, 1518, 11, 3009, 264, 561, 567, 700, 2732, 50918], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 435, "seek": 100458, "start": 1015.6600000000001, "end": 1018.14, "text": " on the scaling hypotheses that how far it's gone.", "tokens": [50918, 322, 264, 21589, 49969, 300, 577, 1400, 309, 311, 2780, 13, 51042], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 436, "seek": 100458, "start": 1018.14, "end": 1021.9000000000001, "text": " In a way, I mean, I sort of look at the large models today", "tokens": [51042, 682, 257, 636, 11, 286, 914, 11, 286, 1333, 295, 574, 412, 264, 2416, 5245, 965, 51230], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 437, "seek": 100458, "start": 1021.9000000000001, "end": 1023.9000000000001, "text": " and I think they're almost unreasonably effective", "tokens": [51230, 293, 286, 519, 436, 434, 1920, 20584, 1258, 1188, 4942, 51330], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 438, "seek": 100458, "start": 1023.9000000000001, "end": 1024.9, "text": " for what they are.", "tokens": [51330, 337, 437, 436, 366, 13, 51380], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 439, "seek": 100458, "start": 1024.9, "end": 1027.1000000000001, "text": " You know, I think it's pretty surprising some", "tokens": [51380, 509, 458, 11, 286, 519, 309, 311, 1238, 8830, 512, 51490], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 440, "seek": 100458, "start": 1027.1000000000001, "end": 1029.54, "text": " of the properties that emerge, things like, you know,", "tokens": [51490, 295, 264, 7221, 300, 21511, 11, 721, 411, 11, 291, 458, 11, 51612], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 441, "seek": 100458, "start": 1029.54, "end": 1032.8600000000001, "text": " it's clearly in my opinion got some form of concepts", "tokens": [51612, 309, 311, 4448, 294, 452, 4800, 658, 512, 1254, 295, 10392, 51778], "temperature": 0.0, "avg_logprob": -0.1619631659905642, "compression_ratio": 1.7113095238095237, "no_speech_prob": 0.003623346332460642}, {"id": 442, "seek": 103286, "start": 1032.86, "end": 1035.06, "text": " and abstractions and some things like that.", "tokens": [50364, 293, 12649, 626, 293, 512, 721, 411, 300, 13, 50474], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 443, "seek": 103286, "start": 1035.06, "end": 1037.34, "text": " And I think if we were talking five plus years ago,", "tokens": [50474, 400, 286, 519, 498, 321, 645, 1417, 1732, 1804, 924, 2057, 11, 50588], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 444, "seek": 103286, "start": 1037.34, "end": 1039.54, "text": " I would have said to you, maybe we need an additional", "tokens": [50588, 286, 576, 362, 848, 281, 291, 11, 1310, 321, 643, 364, 4497, 50698], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 445, "seek": 103286, "start": 1039.54, "end": 1042.54, "text": " algorithmic breakthrough in order to do that.", "tokens": [50698, 9284, 299, 22397, 294, 1668, 281, 360, 300, 13, 50848], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 446, "seek": 103286, "start": 1042.54, "end": 1045.02, "text": " Like, you know, maybe more like the brain works.", "tokens": [50848, 1743, 11, 291, 458, 11, 1310, 544, 411, 264, 3567, 1985, 13, 50972], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 447, "seek": 103286, "start": 1045.02, "end": 1046.54, "text": " And I think that's still true", "tokens": [50972, 400, 286, 519, 300, 311, 920, 2074, 51048], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 448, "seek": 103286, "start": 1046.54, "end": 1049.58, "text": " if we want explicit abstract concepts, need concepts,", "tokens": [51048, 498, 321, 528, 13691, 12649, 10392, 11, 643, 10392, 11, 51200], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 449, "seek": 103286, "start": 1049.58, "end": 1052.4599999999998, "text": " but it seems that these systems can implicitly learn that.", "tokens": [51200, 457, 309, 2544, 300, 613, 3652, 393, 26947, 356, 1466, 300, 13, 51344], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 450, "seek": 103286, "start": 1052.4599999999998, "end": 1055.1, "text": " Another really interesting, I think an unexpected thing", "tokens": [51344, 3996, 534, 1880, 11, 286, 519, 364, 13106, 551, 51476], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 451, "seek": 103286, "start": 1055.1, "end": 1058.62, "text": " was that these systems have some sort of grounding.", "tokens": [51476, 390, 300, 613, 3652, 362, 512, 1333, 295, 46727, 13, 51652], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 452, "seek": 103286, "start": 1058.62, "end": 1060.34, "text": " You know, even though they don't experience the world", "tokens": [51652, 509, 458, 11, 754, 1673, 436, 500, 380, 1752, 264, 1002, 51738], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 453, "seek": 103286, "start": 1060.34, "end": 1062.1399999999999, "text": " multimodally or at least until more recently", "tokens": [51738, 32972, 378, 379, 420, 412, 1935, 1826, 544, 3938, 51828], "temperature": 0.0, "avg_logprob": -0.11846367088524071, "compression_ratio": 1.8054711246200608, "no_speech_prob": 0.0067452616058290005}, {"id": 454, "seek": 106214, "start": 1062.14, "end": 1063.8200000000002, "text": " we have the multimodal models.", "tokens": [50364, 321, 362, 264, 32972, 378, 304, 5245, 13, 50448], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 455, "seek": 106214, "start": 1063.8200000000002, "end": 1066.74, "text": " And that's surprising that the amount of information", "tokens": [50448, 400, 300, 311, 8830, 300, 264, 2372, 295, 1589, 50594], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 456, "seek": 106214, "start": 1066.74, "end": 1069.5800000000002, "text": " that can be, and models that can be built up", "tokens": [50594, 300, 393, 312, 11, 293, 5245, 300, 393, 312, 3094, 493, 50736], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 457, "seek": 106214, "start": 1069.5800000000002, "end": 1070.6200000000001, "text": " just from language.", "tokens": [50736, 445, 490, 2856, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 458, "seek": 106214, "start": 1070.6200000000001, "end": 1073.7, "text": " And I think that I have some hypotheses about why that is.", "tokens": [50788, 400, 286, 519, 300, 286, 362, 512, 49969, 466, 983, 300, 307, 13, 50942], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 459, "seek": 106214, "start": 1073.7, "end": 1077.0600000000002, "text": " I think we get some grounding through the RLHF feedback systems", "tokens": [50942, 286, 519, 321, 483, 512, 46727, 807, 264, 497, 43, 39, 37, 5824, 3652, 51110], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 460, "seek": 106214, "start": 1077.0600000000002, "end": 1079.9, "text": " because obviously the human raters are by definition", "tokens": [51110, 570, 2745, 264, 1952, 5937, 433, 366, 538, 7123, 51252], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 461, "seek": 106214, "start": 1079.9, "end": 1084.38, "text": " grounded people, we're grounded, right, in reality.", "tokens": [51252, 23535, 561, 11, 321, 434, 23535, 11, 558, 11, 294, 4103, 13, 51476], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 462, "seek": 106214, "start": 1084.38, "end": 1086.42, "text": " So our feedback's also grounded.", "tokens": [51476, 407, 527, 5824, 311, 611, 23535, 13, 51578], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 463, "seek": 106214, "start": 1086.42, "end": 1088.6200000000001, "text": " So perhaps there's some grounding coming in through there.", "tokens": [51578, 407, 4317, 456, 311, 512, 46727, 1348, 294, 807, 456, 13, 51688], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 464, "seek": 106214, "start": 1088.6200000000001, "end": 1091.0600000000002, "text": " And also maybe language contains more grounding,", "tokens": [51688, 400, 611, 1310, 2856, 8306, 544, 46727, 11, 51810], "temperature": 0.0, "avg_logprob": -0.13693794837364784, "compression_ratio": 1.7889273356401385, "no_speech_prob": 0.0018233355367556214}, {"id": 465, "seek": 109106, "start": 1091.06, "end": 1093.62, "text": " you know, if you're able to ingest all of it,", "tokens": [50364, 291, 458, 11, 498, 291, 434, 1075, 281, 3957, 377, 439, 295, 309, 11, 50492], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 466, "seek": 109106, "start": 1093.62, "end": 1097.1399999999999, "text": " then we perhaps thought, linguists perhaps thought before.", "tokens": [50492, 550, 321, 4317, 1194, 11, 21766, 1751, 4317, 1194, 949, 13, 50668], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 467, "seek": 109106, "start": 1097.1399999999999, "end": 1099.3, "text": " So that's just some very interesting philosophical questions.", "tokens": [50668, 407, 300, 311, 445, 512, 588, 1880, 25066, 1651, 13, 50776], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 468, "seek": 109106, "start": 1099.3, "end": 1101.82, "text": " I think we haven't, people haven't even really", "tokens": [50776, 286, 519, 321, 2378, 380, 11, 561, 2378, 380, 754, 534, 50902], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 469, "seek": 109106, "start": 1101.82, "end": 1103.54, "text": " scratched the surface off yet,", "tokens": [50902, 40513, 264, 3753, 766, 1939, 11, 50988], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 470, "seek": 109106, "start": 1103.54, "end": 1106.02, "text": " looking at the advances that have been made.", "tokens": [50988, 1237, 412, 264, 25297, 300, 362, 668, 1027, 13, 51112], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 471, "seek": 109106, "start": 1106.8999999999999, "end": 1108.22, "text": " You know, it's quite interesting to think about", "tokens": [51156, 509, 458, 11, 309, 311, 1596, 1880, 281, 519, 466, 51222], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 472, "seek": 109106, "start": 1108.22, "end": 1109.7, "text": " where it's going to go next.", "tokens": [51222, 689, 309, 311, 516, 281, 352, 958, 13, 51296], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 473, "seek": 109106, "start": 1109.7, "end": 1112.6599999999999, "text": " But in terms of your question of like the large models,", "tokens": [51296, 583, 294, 2115, 295, 428, 1168, 295, 411, 264, 2416, 5245, 11, 51444], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 474, "seek": 109106, "start": 1112.6599999999999, "end": 1116.1799999999998, "text": " I think we've got to push scaling as hard as we can.", "tokens": [51444, 286, 519, 321, 600, 658, 281, 2944, 21589, 382, 1152, 382, 321, 393, 13, 51620], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 475, "seek": 109106, "start": 1116.1799999999998, "end": 1117.5, "text": " And that's what we're doing here.", "tokens": [51620, 400, 300, 311, 437, 321, 434, 884, 510, 13, 51686], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 476, "seek": 109106, "start": 1117.5, "end": 1119.1399999999999, "text": " And you know, it's an empirical question", "tokens": [51686, 400, 291, 458, 11, 309, 311, 364, 31886, 1168, 51768], "temperature": 0.0, "avg_logprob": -0.17740541496532874, "compression_ratio": 1.8151815181518152, "no_speech_prob": 0.0009520106832496822}, {"id": 477, "seek": 111914, "start": 1119.14, "end": 1121.8600000000001, "text": " whether that will hit an asymptote or brick wall.", "tokens": [50364, 1968, 300, 486, 2045, 364, 35114, 1370, 420, 16725, 2929, 13, 50500], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 478, "seek": 111914, "start": 1121.8600000000001, "end": 1124.26, "text": " And there are, you know, different people argue about that.", "tokens": [50500, 400, 456, 366, 11, 291, 458, 11, 819, 561, 9695, 466, 300, 13, 50620], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 479, "seek": 111914, "start": 1124.26, "end": 1125.7800000000002, "text": " But actually, I think we should just test it.", "tokens": [50620, 583, 767, 11, 286, 519, 321, 820, 445, 1500, 309, 13, 50696], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 480, "seek": 111914, "start": 1125.7800000000002, "end": 1127.42, "text": " I think no one knows.", "tokens": [50696, 286, 519, 572, 472, 3255, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 481, "seek": 111914, "start": 1127.42, "end": 1128.94, "text": " And but in the meantime,", "tokens": [50778, 400, 457, 294, 264, 14991, 11, 50854], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 482, "seek": 111914, "start": 1128.94, "end": 1132.94, "text": " we should also double down on innovation and invention.", "tokens": [50854, 321, 820, 611, 3834, 760, 322, 8504, 293, 22265, 13, 51054], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 483, "seek": 111914, "start": 1132.94, "end": 1135.6200000000001, "text": " And this is something that the Google research", "tokens": [51054, 400, 341, 307, 746, 300, 264, 3329, 2132, 51188], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 484, "seek": 111914, "start": 1135.6200000000001, "end": 1138.7, "text": " and DeepMind and Google Brain have, you know,", "tokens": [51188, 293, 14895, 44, 471, 293, 3329, 29783, 362, 11, 291, 458, 11, 51342], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 485, "seek": 111914, "start": 1138.7, "end": 1140.9, "text": " we've pioneered many, many things over the last decade.", "tokens": [51342, 321, 600, 19761, 4073, 867, 11, 867, 721, 670, 264, 1036, 10378, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 486, "seek": 111914, "start": 1140.9, "end": 1142.7, "text": " That's something that's our bread and butter.", "tokens": [51452, 663, 311, 746, 300, 311, 527, 5961, 293, 5517, 13, 51542], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 487, "seek": 111914, "start": 1142.7, "end": 1145.3400000000001, "text": " And, you know, you can think of half our effort", "tokens": [51542, 400, 11, 291, 458, 11, 291, 393, 519, 295, 1922, 527, 4630, 51674], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 488, "seek": 111914, "start": 1145.3400000000001, "end": 1147.1000000000001, "text": " as to do with scaling and half our efforts", "tokens": [51674, 382, 281, 360, 365, 21589, 293, 1922, 527, 6484, 51762], "temperature": 0.0, "avg_logprob": -0.1351996441276706, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0012555952416732907}, {"id": 489, "seek": 114710, "start": 1147.3799999999999, "end": 1149.8999999999999, "text": " to do with inventing the next architectures,", "tokens": [50378, 281, 360, 365, 7962, 278, 264, 958, 6331, 1303, 11, 50504], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 490, "seek": 114710, "start": 1149.8999999999999, "end": 1152.1, "text": " the next algorithms that will be needed,", "tokens": [50504, 264, 958, 14642, 300, 486, 312, 2978, 11, 50614], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 491, "seek": 114710, "start": 1152.1, "end": 1155.06, "text": " knowing that you've got this scaled larger and larger model", "tokens": [50614, 5276, 300, 291, 600, 658, 341, 36039, 4833, 293, 4833, 2316, 50762], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 492, "seek": 114710, "start": 1155.06, "end": 1156.3799999999999, "text": " coming along the lines.", "tokens": [50762, 1348, 2051, 264, 3876, 13, 50828], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 493, "seek": 114710, "start": 1156.3799999999999, "end": 1159.02, "text": " So my betting right now,", "tokens": [50828, 407, 452, 34246, 558, 586, 11, 50960], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 494, "seek": 114710, "start": 1159.02, "end": 1161.86, "text": " but it's a loose betting is that you would need both.", "tokens": [50960, 457, 309, 311, 257, 9612, 34246, 307, 300, 291, 576, 643, 1293, 13, 51102], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 495, "seek": 114710, "start": 1161.86, "end": 1163.3, "text": " But I think, you know,", "tokens": [51102, 583, 286, 519, 11, 291, 458, 11, 51174], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 496, "seek": 114710, "start": 1163.3, "end": 1165.54, "text": " it's you've got to push both of them as hard as possible.", "tokens": [51174, 309, 311, 291, 600, 658, 281, 2944, 1293, 295, 552, 382, 1152, 382, 1944, 13, 51286], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 497, "seek": 114710, "start": 1165.54, "end": 1167.3, "text": " And we're in a lucky position that we can do that.", "tokens": [51286, 400, 321, 434, 294, 257, 6356, 2535, 300, 321, 393, 360, 300, 13, 51374], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 498, "seek": 114710, "start": 1167.3, "end": 1168.6599999999999, "text": " Yeah. I want to ask more about the grounding.", "tokens": [51374, 865, 13, 286, 528, 281, 1029, 544, 466, 264, 46727, 13, 51442], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 499, "seek": 114710, "start": 1168.6599999999999, "end": 1170.82, "text": " So you can imagine two things that might change,", "tokens": [51442, 407, 291, 393, 3811, 732, 721, 300, 1062, 1319, 11, 51550], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 500, "seek": 114710, "start": 1170.82, "end": 1172.58, "text": " which would make the grounding more difficult.", "tokens": [51550, 597, 576, 652, 264, 46727, 544, 2252, 13, 51638], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 501, "seek": 114710, "start": 1172.58, "end": 1174.78, "text": " One is that if these models gets from Arder,", "tokens": [51638, 1485, 307, 300, 498, 613, 5245, 2170, 490, 1587, 1068, 11, 51748], "temperature": 0.0, "avg_logprob": -0.12807445037059295, "compression_ratio": 1.771875, "no_speech_prob": 0.0013180726673454046}, {"id": 502, "seek": 117478, "start": 1174.78, "end": 1177.46, "text": " they're going to be able to operate in domains", "tokens": [50364, 436, 434, 516, 281, 312, 1075, 281, 9651, 294, 25514, 50498], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 503, "seek": 117478, "start": 1177.46, "end": 1179.66, "text": " where we just can generate enough human labels,", "tokens": [50498, 689, 321, 445, 393, 8460, 1547, 1952, 16949, 11, 50608], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 504, "seek": 117478, "start": 1179.66, "end": 1180.94, "text": " just because we're not smart enough, right?", "tokens": [50608, 445, 570, 321, 434, 406, 4069, 1547, 11, 558, 30, 50672], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 505, "seek": 117478, "start": 1180.94, "end": 1182.86, "text": " So if it does like a million line pull request,", "tokens": [50672, 407, 498, 309, 775, 411, 257, 2459, 1622, 2235, 5308, 11, 50768], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 506, "seek": 117478, "start": 1182.86, "end": 1184.26, "text": " you know, how do we tell it?", "tokens": [50768, 291, 458, 11, 577, 360, 321, 980, 309, 30, 50838], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 507, "seek": 117478, "start": 1184.26, "end": 1186.58, "text": " Like this is within the constraints of our morality", "tokens": [50838, 1743, 341, 307, 1951, 264, 18491, 295, 527, 29106, 50954], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 508, "seek": 117478, "start": 1186.58, "end": 1188.7, "text": " and the end goal we wanted and this isn't.", "tokens": [50954, 293, 264, 917, 3387, 321, 1415, 293, 341, 1943, 380, 13, 51060], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 509, "seek": 117478, "start": 1188.7, "end": 1190.82, "text": " And the other is it sounds like you're saying", "tokens": [51060, 400, 264, 661, 307, 309, 3263, 411, 291, 434, 1566, 51166], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 510, "seek": 117478, "start": 1190.82, "end": 1193.1, "text": " more of the compute of so far we've been doing,", "tokens": [51166, 544, 295, 264, 14722, 295, 370, 1400, 321, 600, 668, 884, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 511, "seek": 117478, "start": 1193.1, "end": 1194.1, "text": " you know, next token prediction", "tokens": [51280, 291, 458, 11, 958, 14862, 17630, 51330], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 512, "seek": 117478, "start": 1194.1, "end": 1195.5, "text": " and in some sense it's a guardrail", "tokens": [51330, 293, 294, 512, 2020, 309, 311, 257, 6290, 44765, 51400], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 513, "seek": 117478, "start": 1195.5, "end": 1197.5, "text": " because you have to talk as a human would talk", "tokens": [51400, 570, 291, 362, 281, 751, 382, 257, 1952, 576, 751, 51500], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 514, "seek": 117478, "start": 1197.5, "end": 1198.94, "text": " and think as a human would think.", "tokens": [51500, 293, 519, 382, 257, 1952, 576, 519, 13, 51572], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 515, "seek": 117478, "start": 1198.94, "end": 1201.66, "text": " Now, if additional compute is going to come", "tokens": [51572, 823, 11, 498, 4497, 14722, 307, 516, 281, 808, 51708], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 516, "seek": 117478, "start": 1201.66, "end": 1204.1399999999999, "text": " in the form of reinforcement learning,", "tokens": [51708, 294, 264, 1254, 295, 29280, 2539, 11, 51832], "temperature": 0.0, "avg_logprob": -0.1198176339615223, "compression_ratio": 1.7837078651685394, "no_speech_prob": 0.001753065618686378}, {"id": 517, "seek": 120414, "start": 1204.14, "end": 1206.1000000000001, "text": " where just to get to the end objective,", "tokens": [50364, 689, 445, 281, 483, 281, 264, 917, 10024, 11, 50462], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 518, "seek": 120414, "start": 1206.1000000000001, "end": 1208.7800000000002, "text": " we can't really trace how you got there.", "tokens": [50462, 321, 393, 380, 534, 13508, 577, 291, 658, 456, 13, 50596], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 519, "seek": 120414, "start": 1208.7800000000002, "end": 1209.94, "text": " When you combine those two,", "tokens": [50596, 1133, 291, 10432, 729, 732, 11, 50654], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 520, "seek": 120414, "start": 1209.94, "end": 1213.18, "text": " how worried are you that the sort of grounding goes away?", "tokens": [50654, 577, 5804, 366, 291, 300, 264, 1333, 295, 46727, 1709, 1314, 30, 50816], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 521, "seek": 120414, "start": 1213.18, "end": 1216.7800000000002, "text": " Well, look, I think if the grounding,", "tokens": [50816, 1042, 11, 574, 11, 286, 519, 498, 264, 46727, 11, 50996], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 522, "seek": 120414, "start": 1216.7800000000002, "end": 1218.26, "text": " you know, if it's not properly grounded,", "tokens": [50996, 291, 458, 11, 498, 309, 311, 406, 6108, 23535, 11, 51070], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 523, "seek": 120414, "start": 1218.26, "end": 1221.0200000000002, "text": " the system won't be able to achieve those goals properly,", "tokens": [51070, 264, 1185, 1582, 380, 312, 1075, 281, 4584, 729, 5493, 6108, 11, 51208], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 524, "seek": 120414, "start": 1221.0200000000002, "end": 1221.8600000000001, "text": " right? I think so.", "tokens": [51208, 558, 30, 286, 519, 370, 13, 51250], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 525, "seek": 120414, "start": 1221.8600000000001, "end": 1224.6200000000001, "text": " I think in a sense you sort of have to have the grounding", "tokens": [51250, 286, 519, 294, 257, 2020, 291, 1333, 295, 362, 281, 362, 264, 46727, 51388], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 526, "seek": 120414, "start": 1224.6200000000001, "end": 1226.8200000000002, "text": " or at least some of it in order for a system", "tokens": [51388, 420, 412, 1935, 512, 295, 309, 294, 1668, 337, 257, 1185, 51498], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 527, "seek": 120414, "start": 1226.8200000000002, "end": 1229.42, "text": " to actually achieve goals in the real world.", "tokens": [51498, 281, 767, 4584, 5493, 294, 264, 957, 1002, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 528, "seek": 120414, "start": 1229.42, "end": 1231.9, "text": " I do actually think that as these systems", "tokens": [51628, 286, 360, 767, 519, 300, 382, 613, 3652, 51752], "temperature": 0.0, "avg_logprob": -0.1131220669813559, "compression_ratio": 1.8686131386861313, "no_speech_prob": 0.001338581438176334}, {"id": 529, "seek": 123190, "start": 1232.02, "end": 1234.5800000000002, "text": " and things like Gemini are becoming more multimodal", "tokens": [50370, 293, 721, 411, 22894, 3812, 366, 5617, 544, 32972, 378, 304, 50498], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 530, "seek": 123190, "start": 1234.5800000000002, "end": 1236.9, "text": " and we start ingesting things like video", "tokens": [50498, 293, 321, 722, 3957, 8714, 721, 411, 960, 50614], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 531, "seek": 123190, "start": 1236.9, "end": 1241.5, "text": " and, you know, audio visual data as well as text data.", "tokens": [50614, 293, 11, 291, 458, 11, 6278, 5056, 1412, 382, 731, 382, 2487, 1412, 13, 50844], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 532, "seek": 123190, "start": 1241.5, "end": 1243.18, "text": " And then, you know, the system starts", "tokens": [50844, 400, 550, 11, 291, 458, 11, 264, 1185, 3719, 50928], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 533, "seek": 123190, "start": 1243.18, "end": 1244.9, "text": " correlating those things together.", "tokens": [50928, 13983, 990, 729, 721, 1214, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 534, "seek": 123190, "start": 1245.7800000000002, "end": 1249.9, "text": " I think that is a form of proper grounding actually.", "tokens": [51058, 286, 519, 300, 307, 257, 1254, 295, 2296, 46727, 767, 13, 51264], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 535, "seek": 123190, "start": 1249.9, "end": 1254.38, "text": " So I do think our systems are going to start to understand,", "tokens": [51264, 407, 286, 360, 519, 527, 3652, 366, 516, 281, 722, 281, 1223, 11, 51488], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 536, "seek": 123190, "start": 1254.38, "end": 1256.5400000000002, "text": " you know, the physics of the real world better.", "tokens": [51488, 291, 458, 11, 264, 10649, 295, 264, 957, 1002, 1101, 13, 51596], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 537, "seek": 123190, "start": 1256.5400000000002, "end": 1258.8200000000002, "text": " And then one could imagine the active version of that", "tokens": [51596, 400, 550, 472, 727, 3811, 264, 4967, 3037, 295, 300, 51710], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 538, "seek": 123190, "start": 1258.8200000000002, "end": 1260.7800000000002, "text": " is being in a very realistic simulation", "tokens": [51710, 307, 885, 294, 257, 588, 12465, 16575, 51808], "temperature": 0.0, "avg_logprob": -0.14533780832759668, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.004437569063156843}, {"id": 539, "seek": 126078, "start": 1260.78, "end": 1263.66, "text": " or game environment where you're starting to learn", "tokens": [50364, 420, 1216, 2823, 689, 291, 434, 2891, 281, 1466, 50508], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 540, "seek": 126078, "start": 1263.66, "end": 1266.06, "text": " about what your actions do in the world", "tokens": [50508, 466, 437, 428, 5909, 360, 294, 264, 1002, 50628], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 541, "seek": 126078, "start": 1266.06, "end": 1270.34, "text": " and how that affects the world itself,", "tokens": [50628, 293, 577, 300, 11807, 264, 1002, 2564, 11, 50842], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 542, "seek": 126078, "start": 1270.34, "end": 1271.34, "text": " the world stay itself,", "tokens": [50842, 264, 1002, 1754, 2564, 11, 50892], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 543, "seek": 126078, "start": 1271.34, "end": 1274.06, "text": " but also what next learning episode you're getting.", "tokens": [50892, 457, 611, 437, 958, 2539, 3500, 291, 434, 1242, 13, 51028], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 544, "seek": 126078, "start": 1274.06, "end": 1276.66, "text": " So, you know, these RL agents we've always been working on", "tokens": [51028, 407, 11, 291, 458, 11, 613, 497, 43, 12554, 321, 600, 1009, 668, 1364, 322, 51158], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 545, "seek": 126078, "start": 1276.66, "end": 1279.18, "text": " and pioneered like AlphaZero and AlphaGo,", "tokens": [51158, 293, 19761, 4073, 411, 20588, 57, 2032, 293, 20588, 12104, 11, 51284], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 546, "seek": 126078, "start": 1279.18, "end": 1281.22, "text": " they actually affect their active learners.", "tokens": [51284, 436, 767, 3345, 641, 4967, 23655, 13, 51386], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 547, "seek": 126078, "start": 1281.22, "end": 1283.26, "text": " What they decide to do next affects", "tokens": [51386, 708, 436, 4536, 281, 360, 958, 11807, 51488], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 548, "seek": 126078, "start": 1283.26, "end": 1285.98, "text": " what the next learning piece of data", "tokens": [51488, 437, 264, 958, 2539, 2522, 295, 1412, 51624], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 549, "seek": 126078, "start": 1285.98, "end": 1287.62, "text": " or experience they're going to get.", "tokens": [51624, 420, 1752, 436, 434, 516, 281, 483, 13, 51706], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 550, "seek": 126078, "start": 1287.62, "end": 1289.3799999999999, "text": " So there's this very interesting sort of feedback loop.", "tokens": [51706, 407, 456, 311, 341, 588, 1880, 1333, 295, 5824, 6367, 13, 51794], "temperature": 0.0, "avg_logprob": -0.11423157200668797, "compression_ratio": 1.7724137931034483, "no_speech_prob": 0.0019383649341762066}, {"id": 551, "seek": 128938, "start": 1289.38, "end": 1291.94, "text": " And of course, if we ever want to be good at things like robotics,", "tokens": [50364, 400, 295, 1164, 11, 498, 321, 1562, 528, 281, 312, 665, 412, 721, 411, 34145, 11, 50492], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 552, "seek": 128938, "start": 1291.94, "end": 1293.3000000000002, "text": " we're going to have to understand", "tokens": [50492, 321, 434, 516, 281, 362, 281, 1223, 50560], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 553, "seek": 128938, "start": 1293.3000000000002, "end": 1295.5400000000002, "text": " how to act in the real world.", "tokens": [50560, 577, 281, 605, 294, 264, 957, 1002, 13, 50672], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 554, "seek": 128938, "start": 1295.5400000000002, "end": 1297.3000000000002, "text": " Yeah, so there's a grounding in terms of", "tokens": [50672, 865, 11, 370, 456, 311, 257, 46727, 294, 2115, 295, 50760], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 555, "seek": 128938, "start": 1297.3000000000002, "end": 1299.2600000000002, "text": " will the capabilities be able to proceed?", "tokens": [50760, 486, 264, 10862, 312, 1075, 281, 8991, 30, 50858], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 556, "seek": 128938, "start": 1299.2600000000002, "end": 1301.3400000000001, "text": " Will they be like enough in touch with the reality", "tokens": [50858, 3099, 436, 312, 411, 1547, 294, 2557, 365, 264, 4103, 50962], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 557, "seek": 128938, "start": 1301.3400000000001, "end": 1302.8200000000002, "text": " to be able to like do the things we want?", "tokens": [50962, 281, 312, 1075, 281, 411, 360, 264, 721, 321, 528, 30, 51036], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 558, "seek": 128938, "start": 1302.8200000000002, "end": 1305.3000000000002, "text": " And there's another sense of grounding of", "tokens": [51036, 400, 456, 311, 1071, 2020, 295, 46727, 295, 51160], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 559, "seek": 128938, "start": 1305.3000000000002, "end": 1306.5800000000002, "text": " we've gotten lucky in the sense that", "tokens": [51160, 321, 600, 5768, 6356, 294, 264, 2020, 300, 51224], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 560, "seek": 128938, "start": 1306.5800000000002, "end": 1307.94, "text": " since they're trained on human thought,", "tokens": [51224, 1670, 436, 434, 8895, 322, 1952, 1194, 11, 51292], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 561, "seek": 128938, "start": 1307.94, "end": 1309.6200000000001, "text": " they like maybe think like a human.", "tokens": [51292, 436, 411, 1310, 519, 411, 257, 1952, 13, 51376], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 562, "seek": 128938, "start": 1309.6200000000001, "end": 1311.38, "text": " To what extent does that stay true", "tokens": [51376, 1407, 437, 8396, 775, 300, 1754, 2074, 51464], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 563, "seek": 128938, "start": 1311.38, "end": 1313.7800000000002, "text": " when more of the compute for trading comes from", "tokens": [51464, 562, 544, 295, 264, 14722, 337, 9529, 1487, 490, 51584], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 564, "seek": 128938, "start": 1313.7800000000002, "end": 1316.38, "text": " just did you get the right outcome and not guard real?", "tokens": [51584, 445, 630, 291, 483, 264, 558, 9700, 293, 406, 6290, 957, 30, 51714], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 565, "seek": 128938, "start": 1316.38, "end": 1318.5400000000002, "text": " Like, are you like proceeding on the next token", "tokens": [51714, 1743, 11, 366, 291, 411, 41163, 322, 264, 958, 14862, 51822], "temperature": 0.0, "avg_logprob": -0.16523408889770508, "compression_ratio": 1.8174157303370786, "no_speech_prob": 0.0033672121353447437}, {"id": 566, "seek": 131854, "start": 1318.54, "end": 1319.3799999999999, "text": " as a human would?", "tokens": [50364, 382, 257, 1952, 576, 30, 50406], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 567, "seek": 131854, "start": 1319.3799999999999, "end": 1321.78, "text": " Maybe the broader question I'll like post to you is", "tokens": [50406, 2704, 264, 13227, 1168, 286, 603, 411, 2183, 281, 291, 307, 50526], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 568, "seek": 131854, "start": 1321.78, "end": 1323.02, "text": " and this is what I asked Shane as well,", "tokens": [50526, 293, 341, 307, 437, 286, 2351, 25865, 382, 731, 11, 50588], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 569, "seek": 131854, "start": 1323.02, "end": 1324.58, "text": " what would it take to align a system", "tokens": [50588, 437, 576, 309, 747, 281, 7975, 257, 1185, 50666], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 570, "seek": 131854, "start": 1324.58, "end": 1325.62, "text": " that's smarter than a human?", "tokens": [50666, 300, 311, 20294, 813, 257, 1952, 30, 50718], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 571, "seek": 131854, "start": 1325.62, "end": 1327.86, "text": " Maybe things in alien concepts", "tokens": [50718, 2704, 721, 294, 12319, 10392, 50830], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 572, "seek": 131854, "start": 1327.86, "end": 1329.26, "text": " and you can't like really monitor", "tokens": [50830, 293, 291, 393, 380, 411, 534, 6002, 50900], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 573, "seek": 131854, "start": 1329.26, "end": 1330.26, "text": " the million line pull request", "tokens": [50900, 264, 2459, 1622, 2235, 5308, 50950], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 574, "seek": 131854, "start": 1330.26, "end": 1332.18, "text": " because you can't really understand the whole thing.", "tokens": [50950, 570, 291, 393, 380, 534, 1223, 264, 1379, 551, 13, 51046], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 575, "seek": 131854, "start": 1332.18, "end": 1334.5, "text": " Yeah, I mean, look, this is something Shane and I", "tokens": [51046, 865, 11, 286, 914, 11, 574, 11, 341, 307, 746, 25865, 293, 286, 51162], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 576, "seek": 131854, "start": 1334.5, "end": 1335.6599999999999, "text": " and many others here,", "tokens": [51162, 293, 867, 2357, 510, 11, 51220], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 577, "seek": 131854, "start": 1335.6599999999999, "end": 1337.1, "text": " we've had that forefront of our minds", "tokens": [51220, 321, 600, 632, 300, 27287, 295, 527, 9634, 51292], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 578, "seek": 131854, "start": 1337.1, "end": 1339.3, "text": " for since before we started DeMind", "tokens": [51292, 337, 1670, 949, 321, 1409, 1346, 44, 471, 51402], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 579, "seek": 131854, "start": 1339.3, "end": 1341.86, "text": " and because we planned for success crazy,", "tokens": [51402, 293, 570, 321, 8589, 337, 2245, 3219, 11, 51530], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 580, "seek": 131854, "start": 1341.86, "end": 1343.6599999999999, "text": " you know, 2010, no one was thinking about AI,", "tokens": [51530, 291, 458, 11, 9657, 11, 572, 472, 390, 1953, 466, 7318, 11, 51620], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 581, "seek": 131854, "start": 1343.6599999999999, "end": 1344.98, "text": " let alone AGI,", "tokens": [51620, 718, 3312, 316, 26252, 11, 51686], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 582, "seek": 131854, "start": 1344.98, "end": 1347.46, "text": " but we already knew that if we could make progress", "tokens": [51686, 457, 321, 1217, 2586, 300, 498, 321, 727, 652, 4205, 51810], "temperature": 0.0, "avg_logprob": -0.20834268999926617, "compression_ratio": 1.6948228882833787, "no_speech_prob": 0.014882862567901611}, {"id": 583, "seek": 134746, "start": 1347.46, "end": 1349.46, "text": " with these systems and these ideas,", "tokens": [50364, 365, 613, 3652, 293, 613, 3487, 11, 50464], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 584, "seek": 134746, "start": 1349.46, "end": 1351.1000000000001, "text": " it, you know, the technology", "tokens": [50464, 309, 11, 291, 458, 11, 264, 2899, 50546], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 585, "seek": 134746, "start": 1351.1000000000001, "end": 1351.94, "text": " where there would be creator", "tokens": [50546, 689, 456, 576, 312, 14181, 50588], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 586, "seek": 134746, "start": 1351.94, "end": 1353.7, "text": " being unbelievably transformative.", "tokens": [50588, 885, 43593, 36070, 13, 50676], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 587, "seek": 134746, "start": 1353.7, "end": 1355.46, "text": " So we already were thinking, you know,", "tokens": [50676, 407, 321, 1217, 645, 1953, 11, 291, 458, 11, 50764], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 588, "seek": 134746, "start": 1355.46, "end": 1357.54, "text": " 20 years ago about, well, how, you know,", "tokens": [50764, 945, 924, 2057, 466, 11, 731, 11, 577, 11, 291, 458, 11, 50868], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 589, "seek": 134746, "start": 1357.54, "end": 1359.06, "text": " what would the consequences of that be?", "tokens": [50868, 437, 576, 264, 10098, 295, 300, 312, 30, 50944], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 590, "seek": 134746, "start": 1359.06, "end": 1360.54, "text": " Both positive and negative.", "tokens": [50944, 6767, 3353, 293, 3671, 13, 51018], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 591, "seek": 134746, "start": 1360.54, "end": 1363.1000000000001, "text": " Of course, the positive direction is amazing science,", "tokens": [51018, 2720, 1164, 11, 264, 3353, 3513, 307, 2243, 3497, 11, 51146], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 592, "seek": 134746, "start": 1363.1000000000001, "end": 1364.14, "text": " things like alpha fold,", "tokens": [51146, 721, 411, 8961, 4860, 11, 51198], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 593, "seek": 134746, "start": 1364.14, "end": 1366.5, "text": " incredible breakthroughs in health and science", "tokens": [51198, 4651, 22397, 82, 294, 1585, 293, 3497, 51316], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 594, "seek": 134746, "start": 1366.5, "end": 1370.22, "text": " and maths and discovery, scientific discovery.", "tokens": [51316, 293, 36287, 293, 12114, 11, 8134, 12114, 13, 51502], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 595, "seek": 134746, "start": 1370.22, "end": 1372.06, "text": " But then also we got to make sure these systems", "tokens": [51502, 583, 550, 611, 321, 658, 281, 652, 988, 613, 3652, 51594], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 596, "seek": 134746, "start": 1372.06, "end": 1374.1000000000001, "text": " are sort of understandable and controllable.", "tokens": [51594, 366, 1333, 295, 25648, 293, 45159, 712, 13, 51696], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 597, "seek": 134746, "start": 1374.1000000000001, "end": 1376.18, "text": " And I think there's sort of several, you know,", "tokens": [51696, 400, 286, 519, 456, 311, 1333, 295, 2940, 11, 291, 458, 11, 51800], "temperature": 0.0, "avg_logprob": -0.17952664266496696, "compression_ratio": 1.7710843373493976, "no_speech_prob": 0.0019255673978477716}, {"id": 598, "seek": 137618, "start": 1376.18, "end": 1378.22, "text": " this would be a whole sort of discussion in itself,", "tokens": [50364, 341, 576, 312, 257, 1379, 1333, 295, 5017, 294, 2564, 11, 50466], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 599, "seek": 137618, "start": 1378.22, "end": 1380.98, "text": " but there are many, many ideas that people have", "tokens": [50466, 457, 456, 366, 867, 11, 867, 3487, 300, 561, 362, 50604], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 600, "seek": 137618, "start": 1380.98, "end": 1383.5, "text": " from much more stringent eval systems.", "tokens": [50604, 490, 709, 544, 6798, 317, 1073, 304, 3652, 13, 50730], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 601, "seek": 137618, "start": 1383.5, "end": 1384.5800000000002, "text": " I think we don't have good enough", "tokens": [50730, 286, 519, 321, 500, 380, 362, 665, 1547, 50784], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 602, "seek": 137618, "start": 1384.5800000000002, "end": 1387.3, "text": " at evaluations and benchmarks for things like", "tokens": [50784, 412, 43085, 293, 43751, 337, 721, 411, 50920], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 603, "seek": 137618, "start": 1387.3, "end": 1389.18, "text": " can the system deceive you?", "tokens": [50920, 393, 264, 1185, 43440, 291, 30, 51014], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 604, "seek": 137618, "start": 1389.18, "end": 1390.54, "text": " Can it exotrate its own code?", "tokens": [51014, 1664, 309, 454, 310, 4404, 1080, 1065, 3089, 30, 51082], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 605, "seek": 137618, "start": 1390.54, "end": 1393.1000000000001, "text": " It was sort of undesirable behaviors.", "tokens": [51082, 467, 390, 1333, 295, 45667, 21493, 15501, 13, 51210], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 606, "seek": 137618, "start": 1393.1000000000001, "end": 1395.6200000000001, "text": " And then there's, you know,", "tokens": [51210, 400, 550, 456, 311, 11, 291, 458, 11, 51336], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 607, "seek": 137618, "start": 1395.6200000000001, "end": 1399.5, "text": " ideas of actually using AI, maybe narrow AIs.", "tokens": [51336, 3487, 295, 767, 1228, 7318, 11, 1310, 9432, 316, 6802, 13, 51530], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 608, "seek": 137618, "start": 1399.5, "end": 1400.8200000000002, "text": " So not general learning ones,", "tokens": [51530, 407, 406, 2674, 2539, 2306, 11, 51596], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 609, "seek": 137618, "start": 1400.8200000000002, "end": 1403.46, "text": " but systems that are specialized for a domain", "tokens": [51596, 457, 3652, 300, 366, 19813, 337, 257, 9274, 51728], "temperature": 0.0, "avg_logprob": -0.13744397801677072, "compression_ratio": 1.6111111111111112, "no_speech_prob": 0.0013957550982013345}, {"id": 610, "seek": 140346, "start": 1403.46, "end": 1407.58, "text": " to help us as the human scientists analyze", "tokens": [50364, 281, 854, 505, 382, 264, 1952, 7708, 12477, 50570], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 611, "seek": 140346, "start": 1407.58, "end": 1410.8600000000001, "text": " and summarize what the more general system is doing, right?", "tokens": [50570, 293, 20858, 437, 264, 544, 2674, 1185, 307, 884, 11, 558, 30, 50734], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 612, "seek": 140346, "start": 1410.8600000000001, "end": 1413.54, "text": " So kind of narrow AI tools.", "tokens": [50734, 407, 733, 295, 9432, 7318, 3873, 13, 50868], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 613, "seek": 140346, "start": 1413.54, "end": 1415.3400000000001, "text": " I think that there's a lot of promise", "tokens": [50868, 286, 519, 300, 456, 311, 257, 688, 295, 6228, 50958], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 614, "seek": 140346, "start": 1415.3400000000001, "end": 1418.54, "text": " in creating hardened sandboxes or simulations", "tokens": [50958, 294, 4084, 42605, 42115, 279, 420, 35138, 51118], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 615, "seek": 140346, "start": 1418.54, "end": 1422.54, "text": " so that are hardened with cybersecurity arrangements", "tokens": [51118, 370, 300, 366, 42605, 365, 38765, 22435, 51318], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 616, "seek": 140346, "start": 1424.02, "end": 1427.46, "text": " around the simulation, both to keep the AI in,", "tokens": [51392, 926, 264, 16575, 11, 1293, 281, 1066, 264, 7318, 294, 11, 51564], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 617, "seek": 140346, "start": 1427.46, "end": 1430.94, "text": " but also as cybersecurity to keep hackers out.", "tokens": [51564, 457, 611, 382, 38765, 281, 1066, 39766, 484, 13, 51738], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 618, "seek": 140346, "start": 1430.94, "end": 1433.42, "text": " And then you could experiment a lot more", "tokens": [51738, 400, 550, 291, 727, 5120, 257, 688, 544, 51862], "temperature": 0.0, "avg_logprob": -0.13612049453112543, "compression_ratio": 1.6475409836065573, "no_speech_prob": 0.0010675285011529922}, {"id": 619, "seek": 143342, "start": 1433.42, "end": 1435.5, "text": " freely within that sandbox domain.", "tokens": [50364, 16433, 1951, 300, 42115, 9274, 13, 50468], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 620, "seek": 143342, "start": 1435.5, "end": 1438.3400000000001, "text": " And I think a lot of these ideas are,", "tokens": [50468, 400, 286, 519, 257, 688, 295, 613, 3487, 366, 11, 50610], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 621, "seek": 143342, "start": 1438.3400000000001, "end": 1439.8200000000002, "text": " and there's many, many others,", "tokens": [50610, 293, 456, 311, 867, 11, 867, 2357, 11, 50684], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 622, "seek": 143342, "start": 1439.8200000000002, "end": 1441.94, "text": " including the analysis stuff we talked about earlier", "tokens": [50684, 3009, 264, 5215, 1507, 321, 2825, 466, 3071, 50790], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 623, "seek": 143342, "start": 1441.94, "end": 1444.38, "text": " where can we analyze and understand", "tokens": [50790, 689, 393, 321, 12477, 293, 1223, 50912], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 624, "seek": 143342, "start": 1444.38, "end": 1446.42, "text": " what the concepts are that this system is building,", "tokens": [50912, 437, 264, 10392, 366, 300, 341, 1185, 307, 2390, 11, 51014], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 625, "seek": 143342, "start": 1446.42, "end": 1447.78, "text": " what the representations are.", "tokens": [51014, 437, 264, 33358, 366, 13, 51082], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 626, "seek": 143342, "start": 1447.78, "end": 1449.7, "text": " So maybe they're not so alien to us", "tokens": [51082, 407, 1310, 436, 434, 406, 370, 12319, 281, 505, 51178], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 627, "seek": 143342, "start": 1449.7, "end": 1451.54, "text": " and we can actually keep track", "tokens": [51178, 293, 321, 393, 767, 1066, 2837, 51270], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 628, "seek": 143342, "start": 1451.54, "end": 1453.8200000000002, "text": " of the kind of knowledge that it's building.", "tokens": [51270, 295, 264, 733, 295, 3601, 300, 309, 311, 2390, 13, 51384], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 629, "seek": 143342, "start": 1453.8200000000002, "end": 1454.8200000000002, "text": " Yeah, yeah.", "tokens": [51384, 865, 11, 1338, 13, 51434], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 630, "seek": 143342, "start": 1454.8200000000002, "end": 1455.66, "text": " So big backup fit.", "tokens": [51434, 407, 955, 14807, 3318, 13, 51476], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 631, "seek": 143342, "start": 1455.66, "end": 1456.8200000000002, "text": " I'm curious what your timelines are.", "tokens": [51476, 286, 478, 6369, 437, 428, 45886, 366, 13, 51534], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 632, "seek": 143342, "start": 1456.8200000000002, "end": 1459.54, "text": " So Shane said he's like, I think modal outcome is 2028.", "tokens": [51534, 407, 25865, 848, 415, 311, 411, 11, 286, 519, 39745, 9700, 307, 945, 11205, 13, 51670], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 633, "seek": 143342, "start": 1459.54, "end": 1460.5800000000002, "text": " I think that's maybe he's median.", "tokens": [51670, 286, 519, 300, 311, 1310, 415, 311, 26779, 13, 51722], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 634, "seek": 143342, "start": 1460.5800000000002, "end": 1461.42, "text": " Yeah.", "tokens": [51722, 865, 13, 51764], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 635, "seek": 143342, "start": 1461.42, "end": 1462.26, "text": " What is yours?", "tokens": [51764, 708, 307, 6342, 30, 51806], "temperature": 0.0, "avg_logprob": -0.15786430406274263, "compression_ratio": 1.6966966966966968, "no_speech_prob": 0.0017213044920936227}, {"id": 636, "seek": 146226, "start": 1462.3799999999999, "end": 1466.06, "text": " I don't have prescribed kind of specific numbers to it", "tokens": [50370, 286, 500, 380, 362, 29099, 733, 295, 2685, 3547, 281, 309, 50554], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 637, "seek": 146226, "start": 1466.06, "end": 1468.86, "text": " because I think there's so many unknowns and uncertainties", "tokens": [50554, 570, 286, 519, 456, 311, 370, 867, 46048, 293, 11308, 6097, 50694], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 638, "seek": 146226, "start": 1468.86, "end": 1472.54, "text": " and human ingenuity and endeavor", "tokens": [50694, 293, 1952, 21600, 21757, 293, 34975, 50878], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 639, "seek": 146226, "start": 1472.54, "end": 1474.3799999999999, "text": " comes up with surprises all the time.", "tokens": [50878, 1487, 493, 365, 22655, 439, 264, 565, 13, 50970], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 640, "seek": 146226, "start": 1474.3799999999999, "end": 1477.94, "text": " So that could meaningfully move the timelines.", "tokens": [50970, 407, 300, 727, 3620, 2277, 1286, 264, 45886, 13, 51148], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 641, "seek": 146226, "start": 1477.94, "end": 1481.54, "text": " But I will say that when we started DeepMind back in 2010,", "tokens": [51148, 583, 286, 486, 584, 300, 562, 321, 1409, 14895, 44, 471, 646, 294, 9657, 11, 51328], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 642, "seek": 146226, "start": 1481.54, "end": 1483.54, "text": " we thought of it as a 20 year project.", "tokens": [51328, 321, 1194, 295, 309, 382, 257, 945, 1064, 1716, 13, 51428], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 643, "seek": 146226, "start": 1483.54, "end": 1485.78, "text": " And actually, I think we're on track,", "tokens": [51428, 400, 767, 11, 286, 519, 321, 434, 322, 2837, 11, 51540], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 644, "seek": 146226, "start": 1485.78, "end": 1487.82, "text": " which is kind of amazing for 20 year projects.", "tokens": [51540, 597, 307, 733, 295, 2243, 337, 945, 1064, 4455, 13, 51642], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 645, "seek": 146226, "start": 1487.82, "end": 1489.82, "text": " Because usually they're always 20 years away.", "tokens": [51642, 1436, 2673, 436, 434, 1009, 945, 924, 1314, 13, 51742], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 646, "seek": 146226, "start": 1489.82, "end": 1491.7, "text": " So that's the joke about whatever it is", "tokens": [51742, 407, 300, 311, 264, 7647, 466, 2035, 309, 307, 51836], "temperature": 0.0, "avg_logprob": -0.16873947779337564, "compression_ratio": 1.6339869281045751, "no_speech_prob": 0.002200857037678361}, {"id": 647, "seek": 149170, "start": 1491.7, "end": 1494.54, "text": " that you use in quantum AI, take your pick.", "tokens": [50364, 300, 291, 764, 294, 13018, 7318, 11, 747, 428, 1888, 13, 50506], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 648, "seek": 149170, "start": 1494.54, "end": 1496.98, "text": " And but I think we're on track.", "tokens": [50506, 400, 457, 286, 519, 321, 434, 322, 2837, 13, 50628], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 649, "seek": 149170, "start": 1496.98, "end": 1500.78, "text": " So I wouldn't be surprised if we had AGI like systems", "tokens": [50628, 407, 286, 2759, 380, 312, 6100, 498, 321, 632, 316, 26252, 411, 3652, 50818], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 650, "seek": 149170, "start": 1500.78, "end": 1502.22, "text": " within the next decade.", "tokens": [50818, 1951, 264, 958, 10378, 13, 50890], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 651, "seek": 149170, "start": 1502.22, "end": 1504.8600000000001, "text": " And do you buy the model that once you have an AGI,", "tokens": [50890, 400, 360, 291, 2256, 264, 2316, 300, 1564, 291, 362, 364, 316, 26252, 11, 51022], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 652, "seek": 149170, "start": 1504.8600000000001, "end": 1507.5800000000002, "text": " you have a system that basically speeds up further AI research?", "tokens": [51022, 291, 362, 257, 1185, 300, 1936, 16411, 493, 3052, 7318, 2132, 30, 51158], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 653, "seek": 149170, "start": 1507.5800000000002, "end": 1509.1000000000001, "text": " Maybe not like an overnight sense,", "tokens": [51158, 2704, 406, 411, 364, 13935, 2020, 11, 51234], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 654, "seek": 149170, "start": 1509.1000000000001, "end": 1510.94, "text": " but over the course of months and years,", "tokens": [51234, 457, 670, 264, 1164, 295, 2493, 293, 924, 11, 51326], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 655, "seek": 149170, "start": 1510.94, "end": 1511.8600000000001, "text": " you have much faster progress", "tokens": [51326, 291, 362, 709, 4663, 4205, 51372], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 656, "seek": 149170, "start": 1511.8600000000001, "end": 1512.7, "text": " than you would have on the right side.", "tokens": [51372, 813, 291, 576, 362, 322, 264, 558, 1252, 13, 51414], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 657, "seek": 149170, "start": 1512.7, "end": 1515.26, "text": " I think that's potentially possible.", "tokens": [51414, 286, 519, 300, 311, 7263, 1944, 13, 51542], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 658, "seek": 149170, "start": 1515.26, "end": 1518.22, "text": " I think it partly depends what we decide,", "tokens": [51542, 286, 519, 309, 17031, 5946, 437, 321, 4536, 11, 51690], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 659, "seek": 149170, "start": 1518.22, "end": 1520.74, "text": " we as society decide to use the first", "tokens": [51690, 321, 382, 4086, 4536, 281, 764, 264, 700, 51816], "temperature": 0.0, "avg_logprob": -0.2568866781992455, "compression_ratio": 1.7184466019417475, "no_speech_prob": 0.0020413200836628675}, {"id": 660, "seek": 152074, "start": 1520.74, "end": 1524.66, "text": " nascent AGI systems or even proto AGI systems for.", "tokens": [50364, 5382, 2207, 316, 26252, 3652, 420, 754, 47896, 316, 26252, 3652, 337, 13, 50560], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 661, "seek": 152074, "start": 1524.66, "end": 1529.58, "text": " So, even the current LLMs seem to be pretty good at coding.", "tokens": [50560, 407, 11, 754, 264, 2190, 441, 43, 26386, 1643, 281, 312, 1238, 665, 412, 17720, 13, 50806], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 662, "seek": 152074, "start": 1529.58, "end": 1532.3, "text": " So, and we have systems like AlphaCode,", "tokens": [50806, 407, 11, 293, 321, 362, 3652, 411, 20588, 34, 1429, 11, 50942], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 663, "seek": 152074, "start": 1532.3, "end": 1533.98, "text": " we also got theorem proving systems.", "tokens": [50942, 321, 611, 658, 20904, 27221, 3652, 13, 51026], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 664, "seek": 152074, "start": 1533.98, "end": 1537.94, "text": " So one could imagine combining these ideas together", "tokens": [51026, 407, 472, 727, 3811, 21928, 613, 3487, 1214, 51224], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 665, "seek": 152074, "start": 1537.94, "end": 1539.9, "text": " and making them a lot better.", "tokens": [51224, 293, 1455, 552, 257, 688, 1101, 13, 51322], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 666, "seek": 152074, "start": 1539.9, "end": 1543.46, "text": " And then I could imagine these systems being quite good", "tokens": [51322, 400, 550, 286, 727, 3811, 613, 3652, 885, 1596, 665, 51500], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 667, "seek": 152074, "start": 1543.46, "end": 1547.06, "text": " at designing and helping us build future versions", "tokens": [51500, 412, 14685, 293, 4315, 505, 1322, 2027, 9606, 51680], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 668, "seek": 152074, "start": 1547.06, "end": 1548.38, "text": " of themselves.", "tokens": [51680, 295, 2969, 13, 51746], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 669, "seek": 152074, "start": 1548.38, "end": 1550.18, "text": " But we also have to think about the safety implications", "tokens": [51746, 583, 321, 611, 362, 281, 519, 466, 264, 4514, 16602, 51836], "temperature": 0.0, "avg_logprob": -0.1941502115000849, "compression_ratio": 1.7286821705426356, "no_speech_prob": 0.0174348596483469}, {"id": 670, "seek": 155018, "start": 1550.22, "end": 1551.1000000000001, "text": " of that, of course.", "tokens": [50366, 295, 300, 11, 295, 1164, 13, 50410], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 671, "seek": 155018, "start": 1551.1000000000001, "end": 1552.0600000000002, "text": " Yeah, I'm curious what you think about that.", "tokens": [50410, 865, 11, 286, 478, 6369, 437, 291, 519, 466, 300, 13, 50458], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 672, "seek": 155018, "start": 1552.0600000000002, "end": 1554.38, "text": " So, I mean, I'm not saying this is happening this year", "tokens": [50458, 407, 11, 286, 914, 11, 286, 478, 406, 1566, 341, 307, 2737, 341, 1064, 50574], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 673, "seek": 155018, "start": 1554.38, "end": 1556.78, "text": " or anything, but eventually you'll be developing a model", "tokens": [50574, 420, 1340, 11, 457, 4728, 291, 603, 312, 6416, 257, 2316, 50694], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 674, "seek": 155018, "start": 1556.78, "end": 1558.26, "text": " where during the process of development,", "tokens": [50694, 689, 1830, 264, 1399, 295, 3250, 11, 50768], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 675, "seek": 155018, "start": 1558.26, "end": 1559.98, "text": " you think, you know, there's some chance", "tokens": [50768, 291, 519, 11, 291, 458, 11, 456, 311, 512, 2931, 50854], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 676, "seek": 155018, "start": 1559.98, "end": 1561.3400000000001, "text": " that once this is fully developed,", "tokens": [50854, 300, 1564, 341, 307, 4498, 4743, 11, 50922], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 677, "seek": 155018, "start": 1561.3400000000001, "end": 1563.3, "text": " it'll be capable of like an intelligence explosion", "tokens": [50922, 309, 603, 312, 8189, 295, 411, 364, 7599, 15673, 51020], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 678, "seek": 155018, "start": 1563.3, "end": 1564.98, "text": " like dynamic.", "tokens": [51020, 411, 8546, 13, 51104], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 679, "seek": 155018, "start": 1564.98, "end": 1567.78, "text": " What would have to be true of that model at that point", "tokens": [51104, 708, 576, 362, 281, 312, 2074, 295, 300, 2316, 412, 300, 935, 51244], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 680, "seek": 155018, "start": 1567.78, "end": 1569.5, "text": " where you're like, you know,", "tokens": [51244, 689, 291, 434, 411, 11, 291, 458, 11, 51330], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 681, "seek": 155018, "start": 1569.5, "end": 1571.02, "text": " I've seen these specific evals,", "tokens": [51330, 286, 600, 1612, 613, 2685, 1073, 1124, 11, 51406], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 682, "seek": 155018, "start": 1571.02, "end": 1573.78, "text": " I've like, I've like understand it's internal thinking enough", "tokens": [51406, 286, 600, 411, 11, 286, 600, 411, 1223, 309, 311, 6920, 1953, 1547, 51544], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 683, "seek": 155018, "start": 1573.78, "end": 1574.8600000000001, "text": " and like it's future thinking", "tokens": [51544, 293, 411, 309, 311, 2027, 1953, 51598], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 684, "seek": 155018, "start": 1574.8600000000001, "end": 1577.22, "text": " that I'm comfortable continuing development of the system.", "tokens": [51598, 300, 286, 478, 4619, 9289, 3250, 295, 264, 1185, 13, 51716], "temperature": 0.0, "avg_logprob": -0.15633251852618008, "compression_ratio": 1.8712574850299402, "no_speech_prob": 0.0034764145966619253}, {"id": 685, "seek": 157722, "start": 1577.22, "end": 1580.3, "text": " Well, look, we need a lot more understanding", "tokens": [50364, 1042, 11, 574, 11, 321, 643, 257, 688, 544, 3701, 50518], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 686, "seek": 157722, "start": 1580.3, "end": 1581.42, "text": " of the systems than we do today", "tokens": [50518, 295, 264, 3652, 813, 321, 360, 965, 50574], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 687, "seek": 157722, "start": 1581.42, "end": 1583.06, "text": " before I would be even confident", "tokens": [50574, 949, 286, 576, 312, 754, 6679, 50656], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 688, "seek": 157722, "start": 1583.06, "end": 1586.9, "text": " of even explaining to you what we would need to tick box there.", "tokens": [50656, 295, 754, 13468, 281, 291, 437, 321, 576, 643, 281, 5204, 2424, 456, 13, 50848], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 689, "seek": 157722, "start": 1586.9, "end": 1588.6200000000001, "text": " So I think actually what we've got to do", "tokens": [50848, 407, 286, 519, 767, 437, 321, 600, 658, 281, 360, 50934], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 690, "seek": 157722, "start": 1588.6200000000001, "end": 1590.3, "text": " in the next few years and the time we have", "tokens": [50934, 294, 264, 958, 1326, 924, 293, 264, 565, 321, 362, 51018], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 691, "seek": 157722, "start": 1590.3, "end": 1593.54, "text": " before those systems start arriving is come up", "tokens": [51018, 949, 729, 3652, 722, 22436, 307, 808, 493, 51180], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 692, "seek": 157722, "start": 1593.54, "end": 1596.22, "text": " with the right evaluations and metrics", "tokens": [51180, 365, 264, 558, 43085, 293, 16367, 51314], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 693, "seek": 157722, "start": 1596.22, "end": 1598.58, "text": " and maybe ideally formal proofs,", "tokens": [51314, 293, 1310, 22915, 9860, 8177, 82, 11, 51432], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 694, "seek": 157722, "start": 1598.58, "end": 1600.02, "text": " but you know, it's going to be hard", "tokens": [51432, 457, 291, 458, 11, 309, 311, 516, 281, 312, 1152, 51504], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 695, "seek": 157722, "start": 1600.02, "end": 1600.94, "text": " for these types of systems,", "tokens": [51504, 337, 613, 3467, 295, 3652, 11, 51550], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 696, "seek": 157722, "start": 1600.94, "end": 1603.8600000000001, "text": " but at least empirical bounds", "tokens": [51550, 457, 412, 1935, 31886, 29905, 51696], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 697, "seek": 157722, "start": 1603.8600000000001, "end": 1606.1000000000001, "text": " around what these systems can do.", "tokens": [51696, 926, 437, 613, 3652, 393, 360, 13, 51808], "temperature": 0.0, "avg_logprob": -0.1096765817101322, "compression_ratio": 1.726027397260274, "no_speech_prob": 0.0009032711968757212}, {"id": 698, "seek": 160610, "start": 1606.1, "end": 1609.3799999999999, "text": " And that's why I think about things like deception", "tokens": [50364, 400, 300, 311, 983, 286, 519, 466, 721, 411, 40451, 50528], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 699, "seek": 160610, "start": 1609.3799999999999, "end": 1612.34, "text": " and has been quite root node traits that you don't want", "tokens": [50528, 293, 575, 668, 1596, 5593, 9984, 19526, 300, 291, 500, 380, 528, 50676], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 700, "seek": 160610, "start": 1612.34, "end": 1614.54, "text": " because if you're confident that your system", "tokens": [50676, 570, 498, 291, 434, 6679, 300, 428, 1185, 50786], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 701, "seek": 160610, "start": 1614.54, "end": 1618.78, "text": " is sort of exposing what it actually thinks,", "tokens": [50786, 307, 1333, 295, 33178, 437, 309, 767, 7309, 11, 50998], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 702, "seek": 160610, "start": 1618.78, "end": 1620.1799999999998, "text": " then you could potentially,", "tokens": [50998, 550, 291, 727, 7263, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 703, "seek": 160610, "start": 1620.1799999999998, "end": 1623.02, "text": " that opens up possibilities of using the system itself", "tokens": [51068, 300, 9870, 493, 12178, 295, 1228, 264, 1185, 2564, 51210], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 704, "seek": 160610, "start": 1623.02, "end": 1626.02, "text": " to explain aspects of itself to you.", "tokens": [51210, 281, 2903, 7270, 295, 2564, 281, 291, 13, 51360], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 705, "seek": 160610, "start": 1626.02, "end": 1628.62, "text": " The way I think about that actually is like,", "tokens": [51360, 440, 636, 286, 519, 466, 300, 767, 307, 411, 11, 51490], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 706, "seek": 160610, "start": 1628.62, "end": 1631.02, "text": " if I was to play a game of chess against Gary Kasparov,", "tokens": [51490, 498, 286, 390, 281, 862, 257, 1216, 295, 24122, 1970, 13788, 28059, 2181, 5179, 11, 51610], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 707, "seek": 160610, "start": 1631.02, "end": 1633.26, "text": " right, which I played in the past or Magnus Carlson,", "tokens": [51610, 558, 11, 597, 286, 3737, 294, 264, 1791, 420, 19664, 301, 14256, 3015, 11, 51722], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 708, "seek": 160610, "start": 1633.26, "end": 1635.6599999999999, "text": " you know, the amazing chess players with graceful time,", "tokens": [51722, 291, 458, 11, 264, 2243, 24122, 4150, 365, 10042, 906, 565, 11, 51842], "temperature": 0.0, "avg_logprob": -0.1507574389962589, "compression_ratio": 1.7077922077922079, "no_speech_prob": 0.00026116493972949684}, {"id": 709, "seek": 163566, "start": 1636.1000000000001, "end": 1638.8200000000002, "text": " I wouldn't be able to come up with a move that they could,", "tokens": [50386, 286, 2759, 380, 312, 1075, 281, 808, 493, 365, 257, 1286, 300, 436, 727, 11, 50522], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 710, "seek": 163566, "start": 1638.8200000000002, "end": 1642.8600000000001, "text": " but they could explain to me why they came up", "tokens": [50522, 457, 436, 727, 2903, 281, 385, 983, 436, 1361, 493, 50724], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 711, "seek": 163566, "start": 1642.8600000000001, "end": 1646.74, "text": " with that move and I could understand it post hoc, right?", "tokens": [50724, 365, 300, 1286, 293, 286, 727, 1223, 309, 2183, 16708, 11, 558, 30, 50918], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 712, "seek": 163566, "start": 1646.74, "end": 1649.22, "text": " And that's the sort of thing one could imagine", "tokens": [50918, 400, 300, 311, 264, 1333, 295, 551, 472, 727, 3811, 51042], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 713, "seek": 163566, "start": 1650.5800000000002, "end": 1654.7, "text": " one of the capabilities that we could make use", "tokens": [51110, 472, 295, 264, 10862, 300, 321, 727, 652, 764, 51316], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 714, "seek": 163566, "start": 1654.7, "end": 1657.5400000000002, "text": " of these systems is for them to explain it to us", "tokens": [51316, 295, 613, 3652, 307, 337, 552, 281, 2903, 309, 281, 505, 51458], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 715, "seek": 163566, "start": 1657.5400000000002, "end": 1659.78, "text": " and even maybe the proofs behind why they're thinking", "tokens": [51458, 293, 754, 1310, 264, 8177, 82, 2261, 983, 436, 434, 1953, 51570], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 716, "seek": 163566, "start": 1659.78, "end": 1661.8600000000001, "text": " something, certainly in a mathematical,", "tokens": [51570, 746, 11, 3297, 294, 257, 18894, 11, 51674], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 717, "seek": 163566, "start": 1661.8600000000001, "end": 1662.98, "text": " any mathematical problem.", "tokens": [51674, 604, 18894, 1154, 13, 51730], "temperature": 0.0, "avg_logprob": -0.14714457771994852, "compression_ratio": 1.7708333333333333, "no_speech_prob": 0.0004713417438324541}, {"id": 718, "seek": 166298, "start": 1662.98, "end": 1663.82, "text": " Got it.", "tokens": [50364, 5803, 309, 13, 50406], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 719, "seek": 166298, "start": 1663.82, "end": 1666.22, "text": " Do you have a sense of what the converse answer would be?", "tokens": [50406, 1144, 291, 362, 257, 2020, 295, 437, 264, 416, 4308, 1867, 576, 312, 30, 50526], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 720, "seek": 166298, "start": 1666.22, "end": 1668.22, "text": " So what would have to be true where tomorrow morning,", "tokens": [50526, 407, 437, 576, 362, 281, 312, 2074, 689, 4153, 2446, 11, 50626], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 721, "seek": 166298, "start": 1668.22, "end": 1670.66, "text": " you're like, oh man, I didn't anticipate this.", "tokens": [50626, 291, 434, 411, 11, 1954, 587, 11, 286, 994, 380, 21685, 341, 13, 50748], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 722, "seek": 166298, "start": 1670.66, "end": 1672.22, "text": " You see some specific observation tomorrow morning", "tokens": [50748, 509, 536, 512, 2685, 14816, 4153, 2446, 50826], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 723, "seek": 166298, "start": 1672.22, "end": 1674.1, "text": " where like, we got to stop Gemini II training.", "tokens": [50826, 689, 411, 11, 321, 658, 281, 1590, 22894, 3812, 6351, 3097, 13, 50920], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 724, "seek": 166298, "start": 1674.1, "end": 1675.8600000000001, "text": " Like, what would specifically...", "tokens": [50920, 1743, 11, 437, 576, 4682, 485, 51008], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 725, "seek": 166298, "start": 1675.8600000000001, "end": 1677.5, "text": " Yeah, I could imagine that.", "tokens": [51008, 865, 11, 286, 727, 3811, 300, 13, 51090], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 726, "seek": 166298, "start": 1677.5, "end": 1680.7, "text": " And this is where things like the sandbox simulations,", "tokens": [51090, 400, 341, 307, 689, 721, 411, 264, 42115, 35138, 11, 51250], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 727, "seek": 166298, "start": 1680.7, "end": 1683.02, "text": " I would hope we're experimenting", "tokens": [51250, 286, 576, 1454, 321, 434, 29070, 51366], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 728, "seek": 166298, "start": 1683.02, "end": 1686.06, "text": " in a safe, secure environment.", "tokens": [51366, 294, 257, 3273, 11, 7144, 2823, 13, 51518], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 729, "seek": 166298, "start": 1686.06, "end": 1688.7, "text": " And then something happens in it", "tokens": [51518, 400, 550, 746, 2314, 294, 309, 51650], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 730, "seek": 166298, "start": 1688.7, "end": 1691.22, "text": " where very unexpected happens", "tokens": [51650, 689, 588, 13106, 2314, 51776], "temperature": 0.0, "avg_logprob": -0.2110774766153364, "compression_ratio": 1.7186440677966102, "no_speech_prob": 0.008000044152140617}, {"id": 731, "seek": 169122, "start": 1691.22, "end": 1693.06, "text": " and you unexpected capability", "tokens": [50364, 293, 291, 13106, 13759, 50456], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 732, "seek": 169122, "start": 1693.06, "end": 1695.66, "text": " or something that we didn't want explicitly told the system", "tokens": [50456, 420, 746, 300, 321, 994, 380, 528, 20803, 1907, 264, 1185, 50586], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 733, "seek": 169122, "start": 1695.66, "end": 1698.46, "text": " we didn't want and that it did, but then lied about.", "tokens": [50586, 321, 994, 380, 528, 293, 300, 309, 630, 11, 457, 550, 20101, 466, 13, 50726], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 734, "seek": 169122, "start": 1698.46, "end": 1701.54, "text": " These are the kinds of things where one would want to", "tokens": [50726, 1981, 366, 264, 3685, 295, 721, 689, 472, 576, 528, 281, 50880], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 735, "seek": 169122, "start": 1701.54, "end": 1706.54, "text": " then dig in carefully with the systems that are around today", "tokens": [50880, 550, 2528, 294, 7500, 365, 264, 3652, 300, 366, 926, 965, 51130], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 736, "seek": 169122, "start": 1706.54, "end": 1709.14, "text": " which are not dangerous in my opinion today,", "tokens": [51130, 597, 366, 406, 5795, 294, 452, 4800, 965, 11, 51260], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 737, "seek": 169122, "start": 1709.14, "end": 1712.46, "text": " but in a few years they might be, have potential.", "tokens": [51260, 457, 294, 257, 1326, 924, 436, 1062, 312, 11, 362, 3995, 13, 51426], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 738, "seek": 169122, "start": 1713.42, "end": 1717.02, "text": " And then you would sort of ideally kind of pause", "tokens": [51474, 400, 550, 291, 576, 1333, 295, 22915, 733, 295, 10465, 51654], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 739, "seek": 169122, "start": 1717.02, "end": 1720.58, "text": " and then really get to the bottom of why it was doing", "tokens": [51654, 293, 550, 534, 483, 281, 264, 2767, 295, 983, 309, 390, 884, 51832], "temperature": 0.0, "avg_logprob": -0.16399686378345155, "compression_ratio": 1.75, "no_speech_prob": 0.0022438126616179943}, {"id": 740, "seek": 172058, "start": 1720.58, "end": 1722.5, "text": " those things before one continued.", "tokens": [50364, 729, 721, 949, 472, 7014, 13, 50460], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 741, "seek": 172058, "start": 1722.5, "end": 1724.02, "text": " Yeah, going back to Gemini,", "tokens": [50460, 865, 11, 516, 646, 281, 22894, 3812, 11, 50536], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 742, "seek": 172058, "start": 1724.02, "end": 1727.34, "text": " I'm curious what the bottlenecks were in the development.", "tokens": [50536, 286, 478, 6369, 437, 264, 44641, 2761, 645, 294, 264, 3250, 13, 50702], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 743, "seek": 172058, "start": 1727.34, "end": 1729.54, "text": " Like, why not make it immediately one order of magnitude", "tokens": [50702, 1743, 11, 983, 406, 652, 309, 4258, 472, 1668, 295, 15668, 50812], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 744, "seek": 172058, "start": 1729.54, "end": 1732.46, "text": " bigger if scaling works?", "tokens": [50812, 3801, 498, 21589, 1985, 30, 50958], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 745, "seek": 172058, "start": 1732.46, "end": 1734.62, "text": " Well, look, first of all, there are practical limits.", "tokens": [50958, 1042, 11, 574, 11, 700, 295, 439, 11, 456, 366, 8496, 10406, 13, 51066], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 746, "seek": 172058, "start": 1734.62, "end": 1737.9399999999998, "text": " How much compute can you actually fit in one data center?", "tokens": [51066, 1012, 709, 14722, 393, 291, 767, 3318, 294, 472, 1412, 3056, 30, 51232], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 747, "seek": 172058, "start": 1737.9399999999998, "end": 1741.5, "text": " And actually, you're bumping up against very interesting", "tokens": [51232, 400, 767, 11, 291, 434, 9961, 278, 493, 1970, 588, 1880, 51410], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 748, "seek": 172058, "start": 1744.3799999999999, "end": 1746.6999999999998, "text": " distributed computing kind of challenges, right?", "tokens": [51554, 12631, 15866, 733, 295, 4759, 11, 558, 30, 51670], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 749, "seek": 172058, "start": 1746.6999999999998, "end": 1748.54, "text": " Unfortunately, we have some of the best people in the world", "tokens": [51670, 8590, 11, 321, 362, 512, 295, 264, 1151, 561, 294, 264, 1002, 51762], "temperature": 0.0, "avg_logprob": -0.17666638692220052, "compression_ratio": 1.5789473684210527, "no_speech_prob": 0.0029165316373109818}, {"id": 750, "seek": 174854, "start": 1748.6599999999999, "end": 1751.8999999999999, "text": " on those challenges and cross data center training,", "tokens": [50370, 322, 729, 4759, 293, 3278, 1412, 3056, 3097, 11, 50532], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 751, "seek": 174854, "start": 1751.8999999999999, "end": 1754.26, "text": " all these kinds of things, very interesting challenges,", "tokens": [50532, 439, 613, 3685, 295, 721, 11, 588, 1880, 4759, 11, 50650], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 752, "seek": 174854, "start": 1754.26, "end": 1756.86, "text": " hardware challenges, and we have our TPUs and so on", "tokens": [50650, 8837, 4759, 11, 293, 321, 362, 527, 314, 8115, 82, 293, 370, 322, 50780], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 753, "seek": 174854, "start": 1756.86, "end": 1758.78, "text": " that we're building and designing all the time", "tokens": [50780, 300, 321, 434, 2390, 293, 14685, 439, 264, 565, 50876], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 754, "seek": 174854, "start": 1758.78, "end": 1760.5, "text": " as well as using GPUs.", "tokens": [50876, 382, 731, 382, 1228, 18407, 82, 13, 50962], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 755, "seek": 174854, "start": 1760.5, "end": 1762.82, "text": " And so there's all of that.", "tokens": [50962, 400, 370, 456, 311, 439, 295, 300, 13, 51078], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 756, "seek": 174854, "start": 1762.82, "end": 1765.74, "text": " And then you also have to, the scaling laws,", "tokens": [51078, 400, 550, 291, 611, 362, 281, 11, 264, 21589, 6064, 11, 51224], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 757, "seek": 174854, "start": 1765.74, "end": 1767.22, "text": " they didn't just work by magic.", "tokens": [51224, 436, 994, 380, 445, 589, 538, 5585, 13, 51298], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 758, "seek": 174854, "start": 1767.22, "end": 1770.06, "text": " You sort of, you still need to scale up the hyperparameters", "tokens": [51298, 509, 1333, 295, 11, 291, 920, 643, 281, 4373, 493, 264, 9848, 2181, 335, 6202, 51440], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 759, "seek": 174854, "start": 1770.06, "end": 1772.3799999999999, "text": " and various innovations are going in all the time", "tokens": [51440, 293, 3683, 24283, 366, 516, 294, 439, 264, 565, 51556], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 760, "seek": 174854, "start": 1772.3799999999999, "end": 1773.3, "text": " with each new scale.", "tokens": [51556, 365, 1184, 777, 4373, 13, 51602], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 761, "seek": 174854, "start": 1773.3, "end": 1775.98, "text": " It's not just about repeating the same recipe.", "tokens": [51602, 467, 311, 406, 445, 466, 18617, 264, 912, 6782, 13, 51736], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 762, "seek": 174854, "start": 1775.98, "end": 1778.46, "text": " At each new scale, you have to adjust the recipe", "tokens": [51736, 1711, 1184, 777, 4373, 11, 291, 362, 281, 4369, 264, 6782, 51860], "temperature": 0.0, "avg_logprob": -0.14365107717077716, "compression_ratio": 1.8155339805825244, "no_speech_prob": 0.008226653560996056}, {"id": 763, "seek": 177846, "start": 1779.18, "end": 1780.94, "text": " and that's a bit of an art form in a way.", "tokens": [50400, 293, 300, 311, 257, 857, 295, 364, 1523, 1254, 294, 257, 636, 13, 50488], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 764, "seek": 177846, "start": 1780.94, "end": 1783.3, "text": " And you have to sort of almost get new data points.", "tokens": [50488, 400, 291, 362, 281, 1333, 295, 1920, 483, 777, 1412, 2793, 13, 50606], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 765, "seek": 177846, "start": 1783.3, "end": 1785.3400000000001, "text": " If you try and extend your predictions", "tokens": [50606, 759, 291, 853, 293, 10101, 428, 21264, 50708], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 766, "seek": 177846, "start": 1785.3400000000001, "end": 1788.5, "text": " and extrapolate them, say several orders of magnitude out,", "tokens": [50708, 293, 48224, 473, 552, 11, 584, 2940, 9470, 295, 15668, 484, 11, 50866], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 767, "seek": 177846, "start": 1788.5, "end": 1790.46, "text": " sometimes they don't hold anymore, right?", "tokens": [50866, 2171, 436, 500, 380, 1797, 3602, 11, 558, 30, 50964], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 768, "seek": 177846, "start": 1790.46, "end": 1792.58, "text": " Because new capabilities,", "tokens": [50964, 1436, 777, 10862, 11, 51070], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 769, "seek": 177846, "start": 1792.58, "end": 1795.54, "text": " there can be step functions in terms of new capabilities", "tokens": [51070, 456, 393, 312, 1823, 6828, 294, 2115, 295, 777, 10862, 51218], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 770, "seek": 177846, "start": 1795.54, "end": 1798.3, "text": " and some things just, some things hold", "tokens": [51218, 293, 512, 721, 445, 11, 512, 721, 1797, 51356], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 771, "seek": 177846, "start": 1798.3, "end": 1799.3, "text": " and other things don't.", "tokens": [51356, 293, 661, 721, 500, 380, 13, 51406], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 772, "seek": 177846, "start": 1799.3, "end": 1802.38, "text": " So often you do need those intermediate data points", "tokens": [51406, 407, 2049, 291, 360, 643, 729, 19376, 1412, 2793, 51560], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 773, "seek": 177846, "start": 1802.38, "end": 1806.38, "text": " actually to correct some of your hyperparameter optimization", "tokens": [51560, 767, 281, 3006, 512, 295, 428, 9848, 2181, 335, 2398, 19618, 51760], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 774, "seek": 177846, "start": 1806.38, "end": 1807.22, "text": " and other things.", "tokens": [51760, 293, 661, 721, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1097988681938812, "compression_ratio": 1.7586206896551724, "no_speech_prob": 0.00037719644024036825}, {"id": 775, "seek": 180722, "start": 1807.58, "end": 1809.82, "text": " That the scaling law continues to be true.", "tokens": [50382, 663, 264, 21589, 2101, 6515, 281, 312, 2074, 13, 50494], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 776, "seek": 180722, "start": 1809.82, "end": 1813.7, "text": " So there's sort of various practical limitations", "tokens": [50494, 407, 456, 311, 1333, 295, 3683, 8496, 15705, 50688], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 777, "seek": 180722, "start": 1813.7, "end": 1815.38, "text": " on to that.", "tokens": [50688, 322, 281, 300, 13, 50772], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 778, "seek": 180722, "start": 1815.38, "end": 1818.7, "text": " So kind of one order of magnitude is about probably", "tokens": [50772, 407, 733, 295, 472, 1668, 295, 15668, 307, 466, 1391, 50938], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 779, "seek": 180722, "start": 1818.7, "end": 1821.42, "text": " the maximum that you want to carry on.", "tokens": [50938, 264, 6674, 300, 291, 528, 281, 3985, 322, 13, 51074], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 780, "seek": 180722, "start": 1821.42, "end": 1824.14, "text": " You want to sort of do between each era.", "tokens": [51074, 509, 528, 281, 1333, 295, 360, 1296, 1184, 4249, 13, 51210], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 781, "seek": 180722, "start": 1824.14, "end": 1825.7, "text": " Oh, that's so fascinating.", "tokens": [51210, 876, 11, 300, 311, 370, 10343, 13, 51288], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 782, "seek": 180722, "start": 1825.7, "end": 1826.98, "text": " In the GPT for technical report,", "tokens": [51288, 682, 264, 26039, 51, 337, 6191, 2275, 11, 51352], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 783, "seek": 180722, "start": 1826.98, "end": 1829.66, "text": " they say that they were able to predict the training loss", "tokens": [51352, 436, 584, 300, 436, 645, 1075, 281, 6069, 264, 3097, 4470, 51486], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 784, "seek": 180722, "start": 1831.34, "end": 1833.8600000000001, "text": " tens of thousands of times less compute than GPT-4", "tokens": [51570, 10688, 295, 5383, 295, 1413, 1570, 14722, 813, 26039, 51, 12, 19, 51696], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 785, "seek": 180722, "start": 1833.8600000000001, "end": 1834.8600000000001, "text": " that they could see the curve.", "tokens": [51696, 300, 436, 727, 536, 264, 7605, 13, 51746], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 786, "seek": 180722, "start": 1834.8600000000001, "end": 1836.9, "text": " But at the point you're making is that the actual capabilities", "tokens": [51746, 583, 412, 264, 935, 291, 434, 1455, 307, 300, 264, 3539, 10862, 51848], "temperature": 0.0, "avg_logprob": -0.20377625200085173, "compression_ratio": 1.6711409395973154, "no_speech_prob": 0.0016980406362563372}, {"id": 787, "seek": 183690, "start": 1836.9, "end": 1839.1000000000001, "text": " that loss implies may not be so clear.", "tokens": [50364, 300, 4470, 18779, 815, 406, 312, 370, 1850, 13, 50474], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 788, "seek": 183690, "start": 1839.1000000000001, "end": 1841.14, "text": " Yeah, the downstream capabilities sometimes don't follow", "tokens": [50474, 865, 11, 264, 30621, 10862, 2171, 500, 380, 1524, 50576], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 789, "seek": 183690, "start": 1841.14, "end": 1843.5800000000002, "text": " from the, you can often predict the core metrics", "tokens": [50576, 490, 264, 11, 291, 393, 2049, 6069, 264, 4965, 16367, 50698], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 790, "seek": 183690, "start": 1843.5800000000002, "end": 1845.66, "text": " like training loss or something like that.", "tokens": [50698, 411, 3097, 4470, 420, 746, 411, 300, 13, 50802], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 791, "seek": 183690, "start": 1845.66, "end": 1848.8200000000002, "text": " But then it doesn't actually translate into MMLU", "tokens": [50802, 583, 550, 309, 1177, 380, 767, 13799, 666, 376, 12683, 52, 50960], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 792, "seek": 183690, "start": 1848.8200000000002, "end": 1852.5, "text": " or math or some other actual capability", "tokens": [50960, 420, 5221, 420, 512, 661, 3539, 13759, 51144], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 793, "seek": 183690, "start": 1852.5, "end": 1853.3400000000001, "text": " that you care about.", "tokens": [51144, 300, 291, 1127, 466, 13, 51186], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 794, "seek": 183690, "start": 1853.3400000000001, "end": 1856.02, "text": " They're not necessarily linear all the time.", "tokens": [51186, 814, 434, 406, 4725, 8213, 439, 264, 565, 13, 51320], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 795, "seek": 183690, "start": 1856.02, "end": 1857.5800000000002, "text": " So there's sort of non-linear effects there.", "tokens": [51320, 407, 456, 311, 1333, 295, 2107, 12, 28263, 5065, 456, 13, 51398], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 796, "seek": 183690, "start": 1857.5800000000002, "end": 1858.5800000000002, "text": " What was the biggest surprise to you", "tokens": [51398, 708, 390, 264, 3880, 6365, 281, 291, 51448], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 797, "seek": 183690, "start": 1858.5800000000002, "end": 1860.02, "text": " during the development of Gemini?", "tokens": [51448, 1830, 264, 3250, 295, 22894, 3812, 30, 51520], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 798, "seek": 183690, "start": 1860.02, "end": 1862.6200000000001, "text": " So something like this happening?", "tokens": [51520, 407, 746, 411, 341, 2737, 30, 51650], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 799, "seek": 183690, "start": 1862.6200000000001, "end": 1865.46, "text": " Well, I mean, I wouldn't say there was one big surprise,", "tokens": [51650, 1042, 11, 286, 914, 11, 286, 2759, 380, 584, 456, 390, 472, 955, 6365, 11, 51792], "temperature": 0.0, "avg_logprob": -0.18831165743545747, "compression_ratio": 1.715625, "no_speech_prob": 0.0023801238276064396}, {"id": 800, "seek": 186546, "start": 1865.46, "end": 1868.06, "text": " but it was very interesting trying to train things", "tokens": [50364, 457, 309, 390, 588, 1880, 1382, 281, 3847, 721, 50494], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 801, "seek": 186546, "start": 1868.06, "end": 1873.06, "text": " at that size and learning about all sorts of things", "tokens": [50494, 412, 300, 2744, 293, 2539, 466, 439, 7527, 295, 721, 50744], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 802, "seek": 186546, "start": 1873.06, "end": 1875.46, "text": " from organizational, how to babysit such a system", "tokens": [50744, 490, 24730, 11, 577, 281, 39764, 270, 1270, 257, 1185, 50864], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 803, "seek": 186546, "start": 1875.46, "end": 1876.66, "text": " and to track it.", "tokens": [50864, 293, 281, 2837, 309, 13, 50924], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 804, "seek": 186546, "start": 1876.66, "end": 1880.9, "text": " And I think things like getting a better understanding", "tokens": [50924, 400, 286, 519, 721, 411, 1242, 257, 1101, 3701, 51136], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 805, "seek": 186546, "start": 1880.9, "end": 1883.18, "text": " of the metrics you're optimizing", "tokens": [51136, 295, 264, 16367, 291, 434, 40425, 51250], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 806, "seek": 186546, "start": 1883.18, "end": 1886.74, "text": " versus the final capabilities that you want.", "tokens": [51250, 5717, 264, 2572, 10862, 300, 291, 528, 13, 51428], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 807, "seek": 186546, "start": 1886.74, "end": 1890.46, "text": " I would say that's still not a perfectly understood mapping.", "tokens": [51428, 286, 576, 584, 300, 311, 920, 406, 257, 6239, 7320, 18350, 13, 51614], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 808, "seek": 186546, "start": 1890.46, "end": 1891.58, "text": " But it's an interesting one", "tokens": [51614, 583, 309, 311, 364, 1880, 472, 51670], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 809, "seek": 186546, "start": 1891.58, "end": 1892.8600000000001, "text": " that we're getting better and better at.", "tokens": [51670, 300, 321, 434, 1242, 1101, 293, 1101, 412, 13, 51734], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 810, "seek": 186546, "start": 1892.8600000000001, "end": 1893.7, "text": " Yeah, yeah.", "tokens": [51734, 865, 11, 1338, 13, 51776], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 811, "seek": 186546, "start": 1893.7, "end": 1894.9, "text": " There's a perception that maybe other labs", "tokens": [51776, 821, 311, 257, 12860, 300, 1310, 661, 20339, 51836], "temperature": 0.0, "avg_logprob": -0.12178764186921667, "compression_ratio": 1.7147887323943662, "no_speech_prob": 0.0003733231278602034}, {"id": 812, "seek": 189490, "start": 1894.9, "end": 1898.66, "text": " are more compute efficient than DeepMind has been", "tokens": [50364, 366, 544, 14722, 7148, 813, 14895, 44, 471, 575, 668, 50552], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 813, "seek": 189490, "start": 1898.66, "end": 1899.5, "text": " with Gemini.", "tokens": [50552, 365, 22894, 3812, 13, 50594], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 814, "seek": 189490, "start": 1899.5, "end": 1900.6200000000001, "text": " I don't know what you make of that for something.", "tokens": [50594, 286, 500, 380, 458, 437, 291, 652, 295, 300, 337, 746, 13, 50650], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 815, "seek": 189490, "start": 1900.6200000000001, "end": 1901.8200000000002, "text": " I don't think that's the case.", "tokens": [50650, 286, 500, 380, 519, 300, 311, 264, 1389, 13, 50710], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 816, "seek": 189490, "start": 1901.8200000000002, "end": 1906.66, "text": " I mean, I think that actually Gemini one", "tokens": [50710, 286, 914, 11, 286, 519, 300, 767, 22894, 3812, 472, 50952], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 817, "seek": 189490, "start": 1906.66, "end": 1908.22, "text": " use roughly the same amount of compute,", "tokens": [50952, 764, 9810, 264, 912, 2372, 295, 14722, 11, 51030], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 818, "seek": 189490, "start": 1908.22, "end": 1910.5, "text": " maybe slightly more than what was rumored for GPT-4.", "tokens": [51030, 1310, 4748, 544, 813, 437, 390, 8347, 2769, 337, 26039, 51, 12, 19, 13, 51144], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 819, "seek": 189490, "start": 1910.5, "end": 1911.98, "text": " I don't know exactly what was used.", "tokens": [51144, 286, 500, 380, 458, 2293, 437, 390, 1143, 13, 51218], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 820, "seek": 189490, "start": 1911.98, "end": 1915.6200000000001, "text": " So I think it was in the same ballpark.", "tokens": [51218, 407, 286, 519, 309, 390, 294, 264, 912, 2594, 31239, 13, 51400], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 821, "seek": 189490, "start": 1915.6200000000001, "end": 1917.22, "text": " I think we're very efficient with our compute", "tokens": [51400, 286, 519, 321, 434, 588, 7148, 365, 527, 14722, 51480], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 822, "seek": 189490, "start": 1917.22, "end": 1919.26, "text": " and we use our compute for many things.", "tokens": [51480, 293, 321, 764, 527, 14722, 337, 867, 721, 13, 51582], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 823, "seek": 189490, "start": 1919.26, "end": 1920.3400000000001, "text": " One is not just the scaling,", "tokens": [51582, 1485, 307, 406, 445, 264, 21589, 11, 51636], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 824, "seek": 189490, "start": 1920.3400000000001, "end": 1922.8200000000002, "text": " but going back to earlier to these more innovation", "tokens": [51636, 457, 516, 646, 281, 3071, 281, 613, 544, 8504, 51760], "temperature": 0.0, "avg_logprob": -0.14861615072160758, "compression_ratio": 1.789655172413793, "no_speech_prob": 0.0024090807419270277}, {"id": 825, "seek": 192282, "start": 1923.46, "end": 1925.54, "text": " and ideas, you've got to,", "tokens": [50396, 293, 3487, 11, 291, 600, 658, 281, 11, 50500], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 826, "seek": 192282, "start": 1925.54, "end": 1928.3, "text": " it's only useful a new innovation, a new invention", "tokens": [50500, 309, 311, 787, 4420, 257, 777, 8504, 11, 257, 777, 22265, 50638], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 827, "seek": 192282, "start": 1928.3, "end": 1930.34, "text": " if it's also can scale.", "tokens": [50638, 498, 309, 311, 611, 393, 4373, 13, 50740], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 828, "seek": 192282, "start": 1930.34, "end": 1933.58, "text": " So in a way, you also need quite a lot of compute", "tokens": [50740, 407, 294, 257, 636, 11, 291, 611, 643, 1596, 257, 688, 295, 14722, 50902], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 829, "seek": 192282, "start": 1933.58, "end": 1937.1399999999999, "text": " to do new invention because you've got to test many things", "tokens": [50902, 281, 360, 777, 22265, 570, 291, 600, 658, 281, 1500, 867, 721, 51080], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 830, "seek": 192282, "start": 1937.1399999999999, "end": 1938.98, "text": " at least some reasonable scale", "tokens": [51080, 412, 1935, 512, 10585, 4373, 51172], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 831, "seek": 192282, "start": 1938.98, "end": 1940.86, "text": " and make sure that they work at that scale.", "tokens": [51172, 293, 652, 988, 300, 436, 589, 412, 300, 4373, 13, 51266], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 832, "seek": 192282, "start": 1940.86, "end": 1944.02, "text": " And also some new ideas may not work at a toy scale,", "tokens": [51266, 400, 611, 512, 777, 3487, 815, 406, 589, 412, 257, 12058, 4373, 11, 51424], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 833, "seek": 192282, "start": 1944.02, "end": 1946.06, "text": " but do work at a larger scale.", "tokens": [51424, 457, 360, 589, 412, 257, 4833, 4373, 13, 51526], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 834, "seek": 192282, "start": 1946.06, "end": 1947.74, "text": " And in fact, those are the more valuable ones.", "tokens": [51526, 400, 294, 1186, 11, 729, 366, 264, 544, 8263, 2306, 13, 51610], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 835, "seek": 192282, "start": 1947.74, "end": 1950.3, "text": " So you actually, if you think about that exploration process,", "tokens": [51610, 407, 291, 767, 11, 498, 291, 519, 466, 300, 16197, 1399, 11, 51738], "temperature": 0.0, "avg_logprob": -0.1339030621656731, "compression_ratio": 1.8068181818181819, "no_speech_prob": 0.005548478569835424}, {"id": 836, "seek": 195030, "start": 1950.3, "end": 1953.5, "text": " you need quite a lot of compute to be able to do that.", "tokens": [50364, 291, 643, 1596, 257, 688, 295, 14722, 281, 312, 1075, 281, 360, 300, 13, 50524], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 837, "seek": 195030, "start": 1953.5, "end": 1956.4199999999998, "text": " I mean, the good news is, is I think we,", "tokens": [50524, 286, 914, 11, 264, 665, 2583, 307, 11, 307, 286, 519, 321, 11, 50670], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 838, "seek": 195030, "start": 1956.4199999999998, "end": 1958.3, "text": " we're pretty lucky at Google that we,", "tokens": [50670, 321, 434, 1238, 6356, 412, 3329, 300, 321, 11, 50764], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 839, "seek": 195030, "start": 1958.3, "end": 1960.06, "text": " I think this year certainly we're going to have", "tokens": [50764, 286, 519, 341, 1064, 3297, 321, 434, 516, 281, 362, 50852], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 840, "seek": 195030, "start": 1960.06, "end": 1962.86, "text": " the most compute by far of any sort of research lab.", "tokens": [50852, 264, 881, 14722, 538, 1400, 295, 604, 1333, 295, 2132, 2715, 13, 50992], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 841, "seek": 195030, "start": 1962.86, "end": 1965.4199999999998, "text": " And we hope to make very efficient and good use of that", "tokens": [50992, 400, 321, 1454, 281, 652, 588, 7148, 293, 665, 764, 295, 300, 51120], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 842, "seek": 195030, "start": 1965.4199999999998, "end": 1969.3799999999999, "text": " in terms of both scaling and the capability of our systems", "tokens": [51120, 294, 2115, 295, 1293, 21589, 293, 264, 13759, 295, 527, 3652, 51318], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 843, "seek": 195030, "start": 1969.3799999999999, "end": 1970.98, "text": " and also new inventions.", "tokens": [51318, 293, 611, 777, 43748, 13, 51398], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 844, "seek": 195030, "start": 1970.98, "end": 1971.82, "text": " Yeah.", "tokens": [51398, 865, 13, 51440], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 845, "seek": 195030, "start": 1971.82, "end": 1973.1, "text": " What's been the biggest surprise to you", "tokens": [51440, 708, 311, 668, 264, 3880, 6365, 281, 291, 51504], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 846, "seek": 195030, "start": 1973.1, "end": 1975.58, "text": " if you go back to yourself in 2010", "tokens": [51504, 498, 291, 352, 646, 281, 1803, 294, 9657, 51628], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 847, "seek": 195030, "start": 1975.58, "end": 1976.58, "text": " when you were starting DeepMind", "tokens": [51628, 562, 291, 645, 2891, 14895, 44, 471, 51678], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 848, "seek": 195030, "start": 1976.58, "end": 1978.6599999999999, "text": " in terms of what AI progress has looked like?", "tokens": [51678, 294, 2115, 295, 437, 7318, 4205, 575, 2956, 411, 30, 51782], "temperature": 0.0, "avg_logprob": -0.13471668678642118, "compression_ratio": 1.6102719033232629, "no_speech_prob": 0.0021739949006587267}, {"id": 849, "seek": 197866, "start": 1978.66, "end": 1981.66, "text": " Did you anticipate back then that it would in some large sense", "tokens": [50364, 2589, 291, 21685, 646, 550, 300, 309, 576, 294, 512, 2416, 2020, 50514], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 850, "seek": 197866, "start": 1981.66, "end": 1983.98, "text": " amount to spend as, you know, dumping billions of dollars", "tokens": [50514, 2372, 281, 3496, 382, 11, 291, 458, 11, 42224, 17375, 295, 3808, 50630], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 851, "seek": 197866, "start": 1983.98, "end": 1984.8200000000002, "text": " into these models?", "tokens": [50630, 666, 613, 5245, 30, 50672], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 852, "seek": 197866, "start": 1984.8200000000002, "end": 1985.94, "text": " Or did you have a different sense of what it would look like?", "tokens": [50672, 1610, 630, 291, 362, 257, 819, 2020, 295, 437, 309, 576, 574, 411, 30, 50728], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 853, "seek": 197866, "start": 1985.94, "end": 1987.46, "text": " We thought that, and actually, you know,", "tokens": [50728, 492, 1194, 300, 11, 293, 767, 11, 291, 458, 11, 50804], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 854, "seek": 197866, "start": 1987.46, "end": 1989.78, "text": " if you, I know you've interviewed my colleague Shane", "tokens": [50804, 498, 291, 11, 286, 458, 291, 600, 19770, 452, 13532, 25865, 50920], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 855, "seek": 197866, "start": 1989.78, "end": 1994.66, "text": " and he always thought that in terms of like compute curves", "tokens": [50920, 293, 415, 1009, 1194, 300, 294, 2115, 295, 411, 14722, 19490, 51164], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 856, "seek": 197866, "start": 1994.66, "end": 1997.42, "text": " and then maybe comparing roughly to like the brain", "tokens": [51164, 293, 550, 1310, 15763, 9810, 281, 411, 264, 3567, 51302], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 857, "seek": 197866, "start": 1997.42, "end": 1999.8600000000001, "text": " and how many neurons and synapses there are very loosely,", "tokens": [51302, 293, 577, 867, 22027, 293, 5451, 2382, 279, 456, 366, 588, 37966, 11, 51424], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 858, "seek": 197866, "start": 1999.8600000000001, "end": 2002.42, "text": " but we're actually interestingly in that kind of regime", "tokens": [51424, 457, 321, 434, 767, 25873, 294, 300, 733, 295, 13120, 51552], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 859, "seek": 197866, "start": 2002.42, "end": 2004.66, "text": " that roughly in the right order of magnitude of,", "tokens": [51552, 300, 9810, 294, 264, 558, 1668, 295, 15668, 295, 11, 51664], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 860, "seek": 197866, "start": 2004.66, "end": 2006.22, "text": " you know, number of synapses in the brain", "tokens": [51664, 291, 458, 11, 1230, 295, 5451, 2382, 279, 294, 264, 3567, 51742], "temperature": 0.0, "avg_logprob": -0.15038777021021624, "compression_ratio": 1.8208955223880596, "no_speech_prob": 0.0004945192486047745}, {"id": 861, "seek": 200622, "start": 2006.38, "end": 2008.78, "text": " and the sort of compute that we have.", "tokens": [50372, 293, 264, 1333, 295, 14722, 300, 321, 362, 13, 50492], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 862, "seek": 200622, "start": 2008.78, "end": 2010.98, "text": " But I think more fundamentally, you know,", "tokens": [50492, 583, 286, 519, 544, 17879, 11, 291, 458, 11, 50602], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 863, "seek": 200622, "start": 2010.98, "end": 2016.34, "text": " we always thought that we bet on generality and learning, right?", "tokens": [50602, 321, 1009, 1194, 300, 321, 778, 322, 1337, 1860, 293, 2539, 11, 558, 30, 50870], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 864, "seek": 200622, "start": 2016.34, "end": 2019.82, "text": " So those were always at the core of the any technique we would use.", "tokens": [50870, 407, 729, 645, 1009, 412, 264, 4965, 295, 264, 604, 6532, 321, 576, 764, 13, 51044], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 865, "seek": 200622, "start": 2019.82, "end": 2021.98, "text": " That's why we triangulated on reinforcement learning", "tokens": [51044, 663, 311, 983, 321, 19335, 6987, 322, 29280, 2539, 51152], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 866, "seek": 200622, "start": 2021.98, "end": 2024.82, "text": " and search and deep learning, right?", "tokens": [51152, 293, 3164, 293, 2452, 2539, 11, 558, 30, 51294], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 867, "seek": 200622, "start": 2024.82, "end": 2028.78, "text": " As three types of algorithms that would scale", "tokens": [51294, 1018, 1045, 3467, 295, 14642, 300, 576, 4373, 51492], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 868, "seek": 200622, "start": 2028.78, "end": 2031.6200000000001, "text": " and would be very general", "tokens": [51492, 293, 576, 312, 588, 2674, 51634], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 869, "seek": 200622, "start": 2031.6200000000001, "end": 2035.02, "text": " and not require a lot of handcrafted human priors,", "tokens": [51634, 293, 406, 3651, 257, 688, 295, 1011, 5611, 292, 1952, 1790, 830, 11, 51804], "temperature": 0.0, "avg_logprob": -0.128185358914462, "compression_ratio": 1.6865079365079365, "no_speech_prob": 0.0023247969802469015}, {"id": 870, "seek": 203502, "start": 2035.02, "end": 2037.58, "text": " which we thought was the sort of failure mode, really,", "tokens": [50364, 597, 321, 1194, 390, 264, 1333, 295, 7763, 4391, 11, 534, 11, 50492], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 871, "seek": 203502, "start": 2037.58, "end": 2040.94, "text": " of the efforts to build AI in the 90s, right?", "tokens": [50492, 295, 264, 6484, 281, 1322, 7318, 294, 264, 4289, 82, 11, 558, 30, 50660], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 872, "seek": 203502, "start": 2040.94, "end": 2044.58, "text": " Places like MIT where there were very logic-based systems,", "tokens": [50660, 2149, 2116, 411, 13100, 689, 456, 645, 588, 9952, 12, 6032, 3652, 11, 50842], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 873, "seek": 203502, "start": 2044.58, "end": 2047.74, "text": " expert systems, you know, masses of hand-coded,", "tokens": [50842, 5844, 3652, 11, 291, 458, 11, 23935, 295, 1011, 12, 66, 12340, 11, 51000], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 874, "seek": 203502, "start": 2047.74, "end": 2050.06, "text": " hand-crafted human information going into them", "tokens": [51000, 1011, 12, 5611, 292, 1952, 1589, 516, 666, 552, 51116], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 875, "seek": 203502, "start": 2050.06, "end": 2052.42, "text": " that turned out to be wrong or too rigid.", "tokens": [51116, 300, 3574, 484, 281, 312, 2085, 420, 886, 22195, 13, 51234], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 876, "seek": 203502, "start": 2052.42, "end": 2053.86, "text": " So we wanted to move away from that.", "tokens": [51234, 407, 321, 1415, 281, 1286, 1314, 490, 300, 13, 51306], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 877, "seek": 203502, "start": 2053.86, "end": 2057.3, "text": " And I think we spotted that trend early and became, you know,", "tokens": [51306, 400, 286, 519, 321, 21010, 300, 6028, 2440, 293, 3062, 11, 291, 458, 11, 51478], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 878, "seek": 203502, "start": 2057.3, "end": 2059.78, "text": " and obviously we use games as our proving ground", "tokens": [51478, 293, 2745, 321, 764, 2813, 382, 527, 27221, 2727, 51602], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 879, "seek": 203502, "start": 2059.78, "end": 2061.22, "text": " and we did very well with that.", "tokens": [51602, 293, 321, 630, 588, 731, 365, 300, 13, 51674], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 880, "seek": 203502, "start": 2061.22, "end": 2063.22, "text": " And I think all of that was very successful", "tokens": [51674, 400, 286, 519, 439, 295, 300, 390, 588, 4406, 51774], "temperature": 0.0, "avg_logprob": -0.14636801339529612, "compression_ratio": 1.6613418530351438, "no_speech_prob": 0.0006567378295585513}, {"id": 881, "seek": 206322, "start": 2063.22, "end": 2066.8999999999996, "text": " and I think maybe inspired others to, you know, things like AlphaGo.", "tokens": [50364, 293, 286, 519, 1310, 7547, 2357, 281, 11, 291, 458, 11, 721, 411, 20588, 12104, 13, 50548], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 882, "seek": 206322, "start": 2066.8999999999996, "end": 2069.74, "text": " I think it was a big moment for inspiring many others to think,", "tokens": [50548, 286, 519, 309, 390, 257, 955, 1623, 337, 15883, 867, 2357, 281, 519, 11, 50690], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 883, "seek": 206322, "start": 2069.74, "end": 2072.4199999999996, "text": " oh, actually, these systems are ready to scale.", "tokens": [50690, 1954, 11, 767, 11, 613, 3652, 366, 1919, 281, 4373, 13, 50824], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 884, "seek": 206322, "start": 2072.4199999999996, "end": 2074.54, "text": " And then, of course, with the advent of Transformers", "tokens": [50824, 400, 550, 11, 295, 1164, 11, 365, 264, 7045, 295, 27938, 433, 50930], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 885, "seek": 206322, "start": 2074.54, "end": 2077.54, "text": " invented by our colleagues at Google, you know, research and brain,", "tokens": [50930, 14479, 538, 527, 7734, 412, 3329, 11, 291, 458, 11, 2132, 293, 3567, 11, 51080], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 886, "seek": 206322, "start": 2077.54, "end": 2080.74, "text": " that was then, you know, the type of deep learning", "tokens": [51080, 300, 390, 550, 11, 291, 458, 11, 264, 2010, 295, 2452, 2539, 51240], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 887, "seek": 206322, "start": 2080.74, "end": 2084.5, "text": " that allowed us to ingest masses of amounts of information.", "tokens": [51240, 300, 4350, 505, 281, 3957, 377, 23935, 295, 11663, 295, 1589, 13, 51428], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 888, "seek": 206322, "start": 2084.5, "end": 2087.7799999999997, "text": " And that, of course, is really turbocharged where we are today.", "tokens": [51428, 400, 300, 11, 295, 1164, 11, 307, 534, 20902, 25064, 689, 321, 366, 965, 13, 51592], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 889, "seek": 206322, "start": 2087.7799999999997, "end": 2089.7, "text": " So I think that's all part of the same lineage.", "tokens": [51592, 407, 286, 519, 300, 311, 439, 644, 295, 264, 912, 38257, 13, 51688], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 890, "seek": 206322, "start": 2089.7, "end": 2092.74, "text": " You know, we couldn't have predicted every twist and turn there,", "tokens": [51688, 509, 458, 11, 321, 2809, 380, 362, 19147, 633, 8203, 293, 1261, 456, 11, 51840], "temperature": 0.0, "avg_logprob": -0.15301864178149732, "compression_ratio": 1.7634730538922156, "no_speech_prob": 0.001965251052752137}, {"id": 891, "seek": 209274, "start": 2092.74, "end": 2096.9399999999996, "text": " but I think the general direction we were going in was the right one.", "tokens": [50364, 457, 286, 519, 264, 2674, 3513, 321, 645, 516, 294, 390, 264, 558, 472, 13, 50574], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 892, "seek": 209274, "start": 2096.9399999999996, "end": 2099.66, "text": " Yeah. And in fact, it's like fascinating because actually,", "tokens": [50574, 865, 13, 400, 294, 1186, 11, 309, 311, 411, 10343, 570, 767, 11, 50710], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 893, "seek": 209274, "start": 2099.66, "end": 2102.06, "text": " if you like read your old papers or Shane's old papers,", "tokens": [50710, 498, 291, 411, 1401, 428, 1331, 10577, 420, 25865, 311, 1331, 10577, 11, 50830], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 894, "seek": 209274, "start": 2102.06, "end": 2104.5, "text": " Shane's thesis, I think in 2009, he said, like, well, you know,", "tokens": [50830, 25865, 311, 22288, 11, 286, 519, 294, 11453, 11, 415, 848, 11, 411, 11, 731, 11, 291, 458, 11, 50952], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 895, "seek": 209274, "start": 2104.5, "end": 2107.02, "text": " the way we would test for AI is if it can you come press Wikipedia.", "tokens": [50952, 264, 636, 321, 576, 1500, 337, 7318, 307, 498, 309, 393, 291, 808, 1886, 28999, 13, 51078], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 896, "seek": 209274, "start": 2107.02, "end": 2108.7799999999997, "text": " And that's like literally the last function of our labs", "tokens": [51078, 400, 300, 311, 411, 3736, 264, 1036, 2445, 295, 527, 20339, 51166], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 897, "seek": 209274, "start": 2108.7799999999997, "end": 2111.3399999999997, "text": " or like your own paper in like 2016 before Transformers", "tokens": [51166, 420, 411, 428, 1065, 3035, 294, 411, 6549, 949, 27938, 433, 51294], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 898, "seek": 209274, "start": 2111.3399999999997, "end": 2114.3399999999997, "text": " where we said, like, you were comparing your science and AI.", "tokens": [51294, 689, 321, 848, 11, 411, 11, 291, 645, 15763, 428, 3497, 293, 7318, 13, 51444], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 899, "seek": 209274, "start": 2114.3399999999997, "end": 2116.2599999999998, "text": " And he said, attention is what is needed.", "tokens": [51444, 400, 415, 848, 11, 3202, 307, 437, 307, 2978, 13, 51540], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 900, "seek": 209274, "start": 2116.2599999999998, "end": 2117.54, "text": " Exactly. Exactly.", "tokens": [51540, 7587, 13, 7587, 13, 51604], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 901, "seek": 209274, "start": 2117.54, "end": 2120.8999999999996, "text": " So we had these things called out and actually we had some early attention", "tokens": [51604, 407, 321, 632, 613, 721, 1219, 484, 293, 767, 321, 632, 512, 2440, 3202, 51772], "temperature": 0.0, "avg_logprob": -0.2621072908727134, "compression_ratio": 1.8034682080924855, "no_speech_prob": 0.0011811788426712155}, {"id": 902, "seek": 212090, "start": 2120.98, "end": 2124.58, "text": " papers, but they weren't as elegant as Transformers in the end,", "tokens": [50368, 10577, 11, 457, 436, 4999, 380, 382, 21117, 382, 27938, 433, 294, 264, 917, 11, 50548], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 903, "seek": 212090, "start": 2124.58, "end": 2126.38, "text": " like, Neuroturing Machines and things like this.", "tokens": [50548, 411, 11, 1734, 374, 310, 1345, 12089, 1652, 293, 721, 411, 341, 13, 50638], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 904, "seek": 212090, "start": 2126.38, "end": 2129.26, "text": " Yeah. And then Transformers was the was the nicer", "tokens": [50638, 865, 13, 400, 550, 27938, 433, 390, 264, 390, 264, 22842, 50782], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 905, "seek": 212090, "start": 2129.26, "end": 2130.82, "text": " and more general architecture of that.", "tokens": [50782, 293, 544, 2674, 9482, 295, 300, 13, 50860], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 906, "seek": 212090, "start": 2130.82, "end": 2131.98, "text": " Yeah, yeah, yeah.", "tokens": [50860, 865, 11, 1338, 11, 1338, 13, 50918], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 907, "seek": 212090, "start": 2131.98, "end": 2134.14, "text": " When you extrapolate all this out forward,", "tokens": [50918, 1133, 291, 48224, 473, 439, 341, 484, 2128, 11, 51026], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 908, "seek": 212090, "start": 2134.14, "end": 2138.46, "text": " anything about superhuman intelligence or is like,", "tokens": [51026, 1340, 466, 1687, 18796, 7599, 420, 307, 411, 11, 51242], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 909, "seek": 212090, "start": 2138.46, "end": 2139.7400000000002, "text": " what does that landscape look like to you?", "tokens": [51242, 437, 775, 300, 9661, 574, 411, 281, 291, 30, 51306], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 910, "seek": 212090, "start": 2139.7400000000002, "end": 2142.42, "text": " Is it like still controlled by a private company?", "tokens": [51306, 1119, 309, 411, 920, 10164, 538, 257, 4551, 2237, 30, 51440], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 911, "seek": 212090, "start": 2142.42, "end": 2145.34, "text": " Like, what should the governance of that look like concretely?", "tokens": [51440, 1743, 11, 437, 820, 264, 17449, 295, 300, 574, 411, 39481, 736, 30, 51586], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 912, "seek": 212090, "start": 2145.34, "end": 2149.02, "text": " Yeah, look, I would love, you know, I think that this has to be.", "tokens": [51586, 865, 11, 574, 11, 286, 576, 959, 11, 291, 458, 11, 286, 519, 300, 341, 575, 281, 312, 13, 51770], "temperature": 0.0, "avg_logprob": -0.2655182937095905, "compression_ratio": 1.7450980392156863, "no_speech_prob": 0.005048198159784079}, {"id": 913, "seek": 214902, "start": 2149.98, "end": 2152.14, "text": " This is so consequential, this technology.", "tokens": [50412, 639, 307, 370, 7242, 2549, 11, 341, 2899, 13, 50520], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 914, "seek": 214902, "start": 2152.14, "end": 2157.34, "text": " I think it's much bigger than any one company or or or even industry in general.", "tokens": [50520, 286, 519, 309, 311, 709, 3801, 813, 604, 472, 2237, 420, 420, 420, 754, 3518, 294, 2674, 13, 50780], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 915, "seek": 214902, "start": 2157.34, "end": 2161.34, "text": " I think it has to be a big collaboration with many stakeholders", "tokens": [50780, 286, 519, 309, 575, 281, 312, 257, 955, 9363, 365, 867, 17779, 50980], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 916, "seek": 214902, "start": 2161.5, "end": 2164.38, "text": " from civil society, academia, government.", "tokens": [50988, 490, 5605, 4086, 11, 28937, 11, 2463, 13, 51132], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 917, "seek": 214902, "start": 2164.54, "end": 2168.06, "text": " And the good news is I think with the popularity of the recent chatbot systems", "tokens": [51140, 400, 264, 665, 2583, 307, 286, 519, 365, 264, 19301, 295, 264, 5162, 5081, 18870, 3652, 51316], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 918, "seek": 214902, "start": 2168.06, "end": 2172.54, "text": " and so on, I think that has woken up many of these other parts of society", "tokens": [51316, 293, 370, 322, 11, 286, 519, 300, 575, 261, 8406, 493, 867, 295, 613, 661, 3166, 295, 4086, 51540], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 919, "seek": 214902, "start": 2172.54, "end": 2175.9, "text": " that this is coming and what it will be like to interact with these systems.", "tokens": [51540, 300, 341, 307, 1348, 293, 437, 309, 486, 312, 411, 281, 4648, 365, 613, 3652, 13, 51708], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 920, "seek": 214902, "start": 2176.06, "end": 2176.74, "text": " And that's great.", "tokens": [51716, 400, 300, 311, 869, 13, 51750], "temperature": 0.0, "avg_logprob": -0.13749955495198568, "compression_ratio": 1.7282608695652173, "no_speech_prob": 0.003949990030378103}, {"id": 921, "seek": 217674, "start": 2176.7799999999997, "end": 2180.1, "text": " So it's opened up lots of doors for very good conversations.", "tokens": [50366, 407, 309, 311, 5625, 493, 3195, 295, 8077, 337, 588, 665, 7315, 13, 50532], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 922, "seek": 217674, "start": 2180.22, "end": 2184.62, "text": " I mean, an example of that was the safety summit in the UK hosted a few months ago,", "tokens": [50538, 286, 914, 11, 364, 1365, 295, 300, 390, 264, 4514, 21564, 294, 264, 7051, 19204, 257, 1326, 2493, 2057, 11, 50758], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 923, "seek": 217674, "start": 2184.62, "end": 2188.02, "text": " which I thought was a big success to start getting this international dialogue going.", "tokens": [50758, 597, 286, 1194, 390, 257, 955, 2245, 281, 722, 1242, 341, 5058, 10221, 516, 13, 50928], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 924, "seek": 217674, "start": 2188.2599999999998, "end": 2192.4199999999996, "text": " And and and, you know, I think the whole society needs to be involved in deciding", "tokens": [50940, 400, 293, 293, 11, 291, 458, 11, 286, 519, 264, 1379, 4086, 2203, 281, 312, 3288, 294, 17990, 51148], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 925, "seek": 217674, "start": 2192.4199999999996, "end": 2194.62, "text": " what do we want to deploy these models for?", "tokens": [51148, 437, 360, 321, 528, 281, 7274, 613, 5245, 337, 30, 51258], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 926, "seek": 217674, "start": 2194.62, "end": 2195.66, "text": " How do we want to use them?", "tokens": [51258, 1012, 360, 321, 528, 281, 764, 552, 30, 51310], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 927, "seek": 217674, "start": 2195.66, "end": 2197.14, "text": " What do we not want to use them for?", "tokens": [51310, 708, 360, 321, 406, 528, 281, 764, 552, 337, 30, 51384], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 928, "seek": 217674, "start": 2197.14, "end": 2200.3799999999997, "text": " You know, I think we've got to try and get some international consensus around that.", "tokens": [51384, 509, 458, 11, 286, 519, 321, 600, 658, 281, 853, 293, 483, 512, 5058, 19115, 926, 300, 13, 51546], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 929, "seek": 217674, "start": 2200.8199999999997, "end": 2204.2599999999998, "text": " And then also making sure that the benefits of these systems", "tokens": [51568, 400, 550, 611, 1455, 988, 300, 264, 5311, 295, 613, 3652, 51740], "temperature": 0.0, "avg_logprob": -0.16060819825926026, "compression_ratio": 1.7608695652173914, "no_speech_prob": 0.003797289449721575}, {"id": 930, "seek": 220426, "start": 2205.1400000000003, "end": 2208.34, "text": " benefit everyone, you know, for the good of everyone and society in general.", "tokens": [50408, 5121, 1518, 11, 291, 458, 11, 337, 264, 665, 295, 1518, 293, 4086, 294, 2674, 13, 50568], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 931, "seek": 220426, "start": 2208.5, "end": 2211.5800000000004, "text": " And that's why I push so hard things like AI for science.", "tokens": [50576, 400, 300, 311, 983, 286, 2944, 370, 1152, 721, 411, 7318, 337, 3497, 13, 50730], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 932, "seek": 220426, "start": 2211.5800000000004, "end": 2215.1400000000003, "text": " And and I hope that, you know, with things like our spin out isomorphic,", "tokens": [50730, 400, 293, 286, 1454, 300, 11, 291, 458, 11, 365, 721, 411, 527, 6060, 484, 307, 32702, 299, 11, 50908], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 933, "seek": 220426, "start": 2215.1400000000003, "end": 2218.3, "text": " we're going to start curing diseases, you know, terrible diseases with AI", "tokens": [50908, 321, 434, 516, 281, 722, 1262, 278, 11044, 11, 291, 458, 11, 6237, 11044, 365, 7318, 51066], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 934, "seek": 220426, "start": 2218.3, "end": 2221.98, "text": " and accelerate drug discovery, amazing things, climate change and other things.", "tokens": [51066, 293, 21341, 4110, 12114, 11, 2243, 721, 11, 5659, 1319, 293, 661, 721, 13, 51250], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 935, "seek": 220426, "start": 2221.98, "end": 2225.1800000000003, "text": " I think big challenges that face us and face humanity.", "tokens": [51250, 286, 519, 955, 4759, 300, 1851, 505, 293, 1851, 10243, 13, 51410], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 936, "seek": 220426, "start": 2225.9, "end": 2229.1000000000004, "text": " Massive challenges, actually, which I'm optimistic we can solve", "tokens": [51446, 10482, 488, 4759, 11, 767, 11, 597, 286, 478, 19397, 321, 393, 5039, 51606], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 937, "seek": 220426, "start": 2229.5400000000004, "end": 2233.42, "text": " because we've got this incredibly powerful tool coming along down the line of AI", "tokens": [51628, 570, 321, 600, 658, 341, 6252, 4005, 2290, 1348, 2051, 760, 264, 1622, 295, 7318, 51822], "temperature": 0.0, "avg_logprob": -0.10629595728481517, "compression_ratio": 1.753125, "no_speech_prob": 0.006677256431430578}, {"id": 938, "seek": 223342, "start": 2233.94, "end": 2237.7400000000002, "text": " that we can apply and I think help us and solve many of these problems.", "tokens": [50390, 300, 321, 393, 3079, 293, 286, 519, 854, 505, 293, 5039, 867, 295, 613, 2740, 13, 50580], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 939, "seek": 223342, "start": 2237.7400000000002, "end": 2240.38, "text": " So, you know, ideally, we would have a big", "tokens": [50580, 407, 11, 291, 458, 11, 22915, 11, 321, 576, 362, 257, 955, 50712], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 940, "seek": 223342, "start": 2241.42, "end": 2245.26, "text": " consensus around that and a big discussion, you know, sort of almost like", "tokens": [50764, 19115, 926, 300, 293, 257, 955, 5017, 11, 291, 458, 11, 1333, 295, 1920, 411, 50956], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 941, "seek": 223342, "start": 2245.26, "end": 2247.14, "text": " the UN level, if possible.", "tokens": [50956, 264, 8229, 1496, 11, 498, 1944, 13, 51050], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 942, "seek": 223342, "start": 2247.14, "end": 2249.5, "text": " You know, one interesting thing is if you look at these systems,", "tokens": [51050, 509, 458, 11, 472, 1880, 551, 307, 498, 291, 574, 412, 613, 3652, 11, 51168], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 943, "seek": 223342, "start": 2249.5, "end": 2252.94, "text": " they you chat with them and they're immensely powerful and intelligent.", "tokens": [51168, 436, 291, 5081, 365, 552, 293, 436, 434, 38674, 4005, 293, 13232, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 944, "seek": 223342, "start": 2253.54, "end": 2257.02, "text": " But it's interesting to the extent of which they haven't like automated", "tokens": [51370, 583, 309, 311, 1880, 281, 264, 8396, 295, 597, 436, 2378, 380, 411, 18473, 51544], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 945, "seek": 223342, "start": 2257.02, "end": 2258.7000000000003, "text": " large sections of the economy yet.", "tokens": [51544, 2416, 10863, 295, 264, 5010, 1939, 13, 51628], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 946, "seek": 223342, "start": 2258.7000000000003, "end": 2261.26, "text": " Whereas a five years ago, I showed you a Gemini, you'd be like, wow,", "tokens": [51628, 13813, 257, 1732, 924, 2057, 11, 286, 4712, 291, 257, 22894, 3812, 11, 291, 1116, 312, 411, 11, 6076, 11, 51756], "temperature": 0.0, "avg_logprob": -0.1996618768443232, "compression_ratio": 1.6869009584664536, "no_speech_prob": 0.0012606782838702202}, {"id": 947, "seek": 226126, "start": 2261.26, "end": 2263.5, "text": " this is like, you know, totally coming for a lot of things.", "tokens": [50364, 341, 307, 411, 11, 291, 458, 11, 3879, 1348, 337, 257, 688, 295, 721, 13, 50476], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 948, "seek": 226126, "start": 2263.6600000000003, "end": 2265.1000000000004, "text": " So how do you account for that?", "tokens": [50484, 407, 577, 360, 291, 2696, 337, 300, 30, 50556], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 949, "seek": 226126, "start": 2265.1000000000004, "end": 2268.1800000000003, "text": " Like what's going on where it hasn't had a broader impact yet?", "tokens": [50556, 1743, 437, 311, 516, 322, 689, 309, 6132, 380, 632, 257, 13227, 2712, 1939, 30, 50710], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 950, "seek": 226126, "start": 2268.1800000000003, "end": 2270.98, "text": " I think it's we're still I think that just shows we're still at the beginning", "tokens": [50710, 286, 519, 309, 311, 321, 434, 920, 286, 519, 300, 445, 3110, 321, 434, 920, 412, 264, 2863, 50850], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 951, "seek": 226126, "start": 2270.98, "end": 2273.38, "text": " of this new era. Yeah.", "tokens": [50850, 295, 341, 777, 4249, 13, 865, 13, 50970], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 952, "seek": 226126, "start": 2273.38, "end": 2276.1800000000003, "text": " And I think that for these systems, I think there are some interesting", "tokens": [50970, 400, 286, 519, 300, 337, 613, 3652, 11, 286, 519, 456, 366, 512, 1880, 51110], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 953, "seek": 226126, "start": 2276.1800000000003, "end": 2280.42, "text": " use cases, you know, you know, where you can use things to some,", "tokens": [51110, 764, 3331, 11, 291, 458, 11, 291, 458, 11, 689, 291, 393, 764, 721, 281, 512, 11, 51322], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 954, "seek": 226126, "start": 2280.42, "end": 2284.0200000000004, "text": " you know, these these these chatbot systems to summarize stuff for you", "tokens": [51322, 291, 458, 11, 613, 613, 613, 5081, 18870, 3652, 281, 20858, 1507, 337, 291, 51502], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 955, "seek": 226126, "start": 2284.0200000000004, "end": 2289.78, "text": " and and maybe do some simple writing and maybe more kind of boilerplate type writing.", "tokens": [51502, 293, 293, 1310, 360, 512, 2199, 3579, 293, 1310, 544, 733, 295, 39228, 37008, 2010, 3579, 13, 51790], "temperature": 0.0, "avg_logprob": -0.16767578125, "compression_ratio": 1.870307167235495, "no_speech_prob": 0.0019545466639101505}, {"id": 956, "seek": 228978, "start": 2289.94, "end": 2293.7000000000003, "text": " But that's only a small part of what, you know, we all do every day.", "tokens": [50372, 583, 300, 311, 787, 257, 1359, 644, 295, 437, 11, 291, 458, 11, 321, 439, 360, 633, 786, 13, 50560], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 957, "seek": 228978, "start": 2293.7000000000003, "end": 2298.1400000000003, "text": " So I think for more general use cases, I think we need still need new", "tokens": [50560, 407, 286, 519, 337, 544, 2674, 764, 3331, 11, 286, 519, 321, 643, 920, 643, 777, 50782], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 958, "seek": 228978, "start": 2298.1400000000003, "end": 2302.46, "text": " capabilities, things like planning and search, but also maybe things like", "tokens": [50782, 10862, 11, 721, 411, 5038, 293, 3164, 11, 457, 611, 1310, 721, 411, 50998], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 959, "seek": 228978, "start": 2302.46, "end": 2306.02, "text": " personalization and memory, episodic memory.", "tokens": [50998, 2973, 2144, 293, 4675, 11, 39200, 299, 4675, 13, 51176], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 960, "seek": 228978, "start": 2306.02, "end": 2309.34, "text": " So not just long context windows, but actually remembering what I what", "tokens": [51176, 407, 406, 445, 938, 4319, 9309, 11, 457, 767, 20719, 437, 286, 437, 51342], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 961, "seek": 228978, "start": 2309.34, "end": 2311.42, "text": " we spoke about a hundred conversations ago.", "tokens": [51342, 321, 7179, 466, 257, 3262, 7315, 2057, 13, 51446], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 962, "seek": 228978, "start": 2312.2200000000003, "end": 2315.82, "text": " And I think once they start coming in, I mean, I'm really looking forward", "tokens": [51486, 400, 286, 519, 1564, 436, 722, 1348, 294, 11, 286, 914, 11, 286, 478, 534, 1237, 2128, 51666], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 963, "seek": 228978, "start": 2315.82, "end": 2319.5400000000004, "text": " to things like recommendation systems that that help me find better,", "tokens": [51666, 281, 721, 411, 11879, 3652, 300, 300, 854, 385, 915, 1101, 11, 51852], "temperature": 0.0, "avg_logprob": -0.14592042541503905, "compression_ratio": 1.7166666666666666, "no_speech_prob": 0.0022857312578707933}, {"id": 964, "seek": 231954, "start": 2319.54, "end": 2323.3, "text": " more enriching material, whether that's books or films or music and so on.", "tokens": [50364, 544, 18849, 278, 2527, 11, 1968, 300, 311, 3642, 420, 7796, 420, 1318, 293, 370, 322, 13, 50552], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 965, "seek": 231954, "start": 2323.42, "end": 2325.2599999999998, "text": " You know, I would use that type of system every day.", "tokens": [50558, 509, 458, 11, 286, 576, 764, 300, 2010, 295, 1185, 633, 786, 13, 50650], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 966, "seek": 231954, "start": 2325.2599999999998, "end": 2329.82, "text": " So I think we're just scratching the surface of what these AI,", "tokens": [50650, 407, 286, 519, 321, 434, 445, 29699, 264, 3753, 295, 437, 613, 7318, 11, 50878], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 967, "seek": 231954, "start": 2330.02, "end": 2334.42, "text": " say, assistants could actually do for us in our general everyday lives.", "tokens": [50888, 584, 11, 34949, 727, 767, 360, 337, 505, 294, 527, 2674, 7429, 2909, 13, 51108], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 968, "seek": 231954, "start": 2334.58, "end": 2338.42, "text": " And also in our work context as well, I think they're not reliable yet enough", "tokens": [51116, 400, 611, 294, 527, 589, 4319, 382, 731, 11, 286, 519, 436, 434, 406, 12924, 1939, 1547, 51308], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 969, "seek": 231954, "start": 2338.42, "end": 2340.42, "text": " to do things like science with them.", "tokens": [51308, 281, 360, 721, 411, 3497, 365, 552, 13, 51408], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 970, "seek": 231954, "start": 2340.42, "end": 2343.9, "text": " But I think one day, you know, once we fix factuality and grounding and other things,", "tokens": [51408, 583, 286, 519, 472, 786, 11, 291, 458, 11, 1564, 321, 3191, 48029, 507, 293, 46727, 293, 661, 721, 11, 51582], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 971, "seek": 231954, "start": 2344.46, "end": 2347.14, "text": " I think they could end up becoming like, you know, the world's best", "tokens": [51610, 286, 519, 436, 727, 917, 493, 5617, 411, 11, 291, 458, 11, 264, 1002, 311, 1151, 51744], "temperature": 0.0, "avg_logprob": -0.12932692479043112, "compression_ratio": 1.724025974025974, "no_speech_prob": 0.0012435134267434478}, {"id": 972, "seek": 234714, "start": 2347.14, "end": 2352.58, "text": " research assistant for you as a scientist or as a clinician.", "tokens": [50364, 2132, 10994, 337, 291, 382, 257, 12662, 420, 382, 257, 45962, 13, 50636], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 973, "seek": 234714, "start": 2353.54, "end": 2356.46, "text": " I want to ask about memory, by the way, you had this fascinating paper", "tokens": [50684, 286, 528, 281, 1029, 466, 4675, 11, 538, 264, 636, 11, 291, 632, 341, 10343, 3035, 50830], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 974, "seek": 234714, "start": 2356.46, "end": 2360.22, "text": " in 2007 where you talk about the links between memory and imagination", "tokens": [50830, 294, 12656, 689, 291, 751, 466, 264, 6123, 1296, 4675, 293, 12938, 51018], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 975, "seek": 234714, "start": 2360.22, "end": 2362.06, "text": " and how they, in some sense, are very similar.", "tokens": [51018, 293, 577, 436, 11, 294, 512, 2020, 11, 366, 588, 2531, 13, 51110], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 976, "seek": 234714, "start": 2363.8599999999997, "end": 2366.3399999999997, "text": " People often claim that these models are just memorizing.", "tokens": [51200, 3432, 2049, 3932, 300, 613, 5245, 366, 445, 10560, 3319, 13, 51324], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 977, "seek": 234714, "start": 2366.58, "end": 2368.8599999999997, "text": " How do you think about that claim that people make?", "tokens": [51336, 1012, 360, 291, 519, 466, 300, 3932, 300, 561, 652, 30, 51450], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 978, "seek": 234714, "start": 2369.2999999999997, "end": 2370.9, "text": " Is memorization all you need?", "tokens": [51472, 1119, 10560, 2144, 439, 291, 643, 30, 51552], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 979, "seek": 234714, "start": 2370.9, "end": 2372.9, "text": " Because in some some deep sense, that's compression.", "tokens": [51552, 1436, 294, 512, 512, 2452, 2020, 11, 300, 311, 19355, 13, 51652], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 980, "seek": 234714, "start": 2372.9, "end": 2374.2999999999997, "text": " Or, you know, what's your intuition?", "tokens": [51652, 1610, 11, 291, 458, 11, 437, 311, 428, 24002, 30, 51722], "temperature": 0.0, "avg_logprob": -0.17518865866739242, "compression_ratio": 1.6950354609929077, "no_speech_prob": 0.0026044410187751055}, {"id": 981, "seek": 237430, "start": 2374.3, "end": 2377.7400000000002, "text": " Yeah, I mean, sort of at the limit, one maybe could try and memorize everything,", "tokens": [50364, 865, 11, 286, 914, 11, 1333, 295, 412, 264, 4948, 11, 472, 1310, 727, 853, 293, 27478, 1203, 11, 50536], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 982, "seek": 237430, "start": 2377.7400000000002, "end": 2380.1800000000003, "text": " but it wouldn't generalize out of out of your distribution.", "tokens": [50536, 457, 309, 2759, 380, 2674, 1125, 484, 295, 484, 295, 428, 7316, 13, 50658], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 983, "seek": 237430, "start": 2380.1800000000003, "end": 2383.34, "text": " And I think these systems are clearly I think the early the early", "tokens": [50658, 400, 286, 519, 613, 3652, 366, 4448, 286, 519, 264, 2440, 264, 2440, 50816], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 984, "seek": 237430, "start": 2384.94, "end": 2389.02, "text": " criticisms of these early systems were that they were just regurgitating", "tokens": [50896, 48519, 295, 613, 2440, 3652, 645, 300, 436, 645, 445, 1121, 5476, 16350, 51100], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 985, "seek": 237430, "start": 2389.02, "end": 2393.3, "text": " and memorizing, but I think clearly the new era, the Gemini GPT-4 type era,", "tokens": [51100, 293, 10560, 3319, 11, 457, 286, 519, 4448, 264, 777, 4249, 11, 264, 22894, 3812, 26039, 51, 12, 19, 2010, 4249, 11, 51314], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 986, "seek": 237430, "start": 2393.3, "end": 2396.3, "text": " they are definitely generalizing to new constructs.", "tokens": [51314, 436, 366, 2138, 2674, 3319, 281, 777, 7690, 82, 13, 51464], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 987, "seek": 237430, "start": 2397.38, "end": 2400.5800000000004, "text": " So but actually, you know, in my thesis and that paper,", "tokens": [51518, 407, 457, 767, 11, 291, 458, 11, 294, 452, 22288, 293, 300, 3035, 11, 51678], "temperature": 0.0, "avg_logprob": -0.16348288853963217, "compression_ratio": 1.7604562737642586, "no_speech_prob": 0.0015652832807973027}, {"id": 988, "seek": 240058, "start": 2400.58, "end": 2404.86, "text": " particularly, that started that era of imagination in neuroscience was showing", "tokens": [50364, 4098, 11, 300, 1409, 300, 4249, 295, 12938, 294, 42762, 390, 4099, 50578], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 989, "seek": 240058, "start": 2404.86, "end": 2407.9, "text": " that, you know, first of all, memory, certainly at least human memory", "tokens": [50578, 300, 11, 291, 458, 11, 700, 295, 439, 11, 4675, 11, 3297, 412, 1935, 1952, 4675, 50730], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 990, "seek": 240058, "start": 2407.9, "end": 2409.22, "text": " is a reconstructive process.", "tokens": [50730, 307, 257, 16891, 21673, 1399, 13, 50796], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 991, "seek": 240058, "start": 2409.22, "end": 2410.2999999999997, "text": " It's not a videotape, right?", "tokens": [50796, 467, 311, 406, 257, 838, 5377, 494, 11, 558, 30, 50850], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 992, "seek": 240058, "start": 2410.2999999999997, "end": 2413.8199999999997, "text": " We sort of put it together back from components that seems familiar to us,", "tokens": [50850, 492, 1333, 295, 829, 309, 1214, 646, 490, 6677, 300, 2544, 4963, 281, 505, 11, 51026], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 993, "seek": 240058, "start": 2413.8199999999997, "end": 2416.86, "text": " that the ensemble, and that's what made me think that imagination", "tokens": [51026, 300, 264, 19492, 11, 293, 300, 311, 437, 1027, 385, 519, 300, 12938, 51178], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 994, "seek": 240058, "start": 2416.86, "end": 2420.98, "text": " might be the same thing, except in this case, you're using the same semantic components.", "tokens": [51178, 1062, 312, 264, 912, 551, 11, 3993, 294, 341, 1389, 11, 291, 434, 1228, 264, 912, 47982, 6677, 13, 51384], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 995, "seek": 240058, "start": 2421.14, "end": 2424.14, "text": " But now you're putting it together into a way that your brain thinks is novel,", "tokens": [51392, 583, 586, 291, 434, 3372, 309, 1214, 666, 257, 636, 300, 428, 3567, 7309, 307, 7613, 11, 51542], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 996, "seek": 240058, "start": 2424.2599999999998, "end": 2426.06, "text": " right, for a particular purpose like planning.", "tokens": [51548, 558, 11, 337, 257, 1729, 4334, 411, 5038, 13, 51638], "temperature": 0.0, "avg_logprob": -0.15888985404132927, "compression_ratio": 1.772870662460568, "no_speech_prob": 0.007414802443236113}, {"id": 997, "seek": 242606, "start": 2426.2999999999997, "end": 2431.62, "text": " And and so I do think that that kind of idea is still probably missing", "tokens": [50376, 400, 293, 370, 286, 360, 519, 300, 300, 733, 295, 1558, 307, 920, 1391, 5361, 50642], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 998, "seek": 242606, "start": 2431.62, "end": 2436.18, "text": " from our current systems, this sort of pulling together different parts", "tokens": [50642, 490, 527, 2190, 3652, 11, 341, 1333, 295, 8407, 1214, 819, 3166, 50870], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 999, "seek": 242606, "start": 2436.18, "end": 2440.62, "text": " of your world model to simulate something new that then helps with your planning,", "tokens": [50870, 295, 428, 1002, 2316, 281, 27817, 746, 777, 300, 550, 3665, 365, 428, 5038, 11, 51092], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1000, "seek": 242606, "start": 2440.94, "end": 2443.02, "text": " which is what I would call imagination.", "tokens": [51108, 597, 307, 437, 286, 576, 818, 12938, 13, 51212], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1001, "seek": 242606, "start": 2443.02, "end": 2443.86, "text": " Yeah, for sure.", "tokens": [51212, 865, 11, 337, 988, 13, 51254], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1002, "seek": 242606, "start": 2443.86, "end": 2446.58, "text": " So again, now you guys have the best models in the world,", "tokens": [51254, 407, 797, 11, 586, 291, 1074, 362, 264, 1151, 5245, 294, 264, 1002, 11, 51390], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1003, "seek": 242606, "start": 2447.2999999999997, "end": 2449.7799999999997, "text": " you know, with the Gemini models.", "tokens": [51426, 291, 458, 11, 365, 264, 22894, 3812, 5245, 13, 51550], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1004, "seek": 242606, "start": 2449.7799999999997, "end": 2453.06, "text": " Do you have do you plan on putting out some sort of framework like the other", "tokens": [51550, 1144, 291, 362, 360, 291, 1393, 322, 3372, 484, 512, 1333, 295, 8388, 411, 264, 661, 51714], "temperature": 0.0, "avg_logprob": -0.162692734173366, "compression_ratio": 1.6568265682656826, "no_speech_prob": 0.002777752000838518}, {"id": 1005, "seek": 245306, "start": 2453.06, "end": 2456.5, "text": " two major labs have of, you know, once we see these specific capabilities,", "tokens": [50364, 732, 2563, 20339, 362, 295, 11, 291, 458, 11, 1564, 321, 536, 613, 2685, 10862, 11, 50536], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1006, "seek": 245306, "start": 2456.82, "end": 2460.42, "text": " unless we have these specific safeguards, we're not going to continue development", "tokens": [50552, 5969, 321, 362, 613, 2685, 32358, 84, 2287, 11, 321, 434, 406, 516, 281, 2354, 3250, 50732], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1007, "seek": 245306, "start": 2460.42, "end": 2462.58, "text": " or we're not going to ship the product out.", "tokens": [50732, 420, 321, 434, 406, 516, 281, 5374, 264, 1674, 484, 13, 50840], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1008, "seek": 245306, "start": 2462.58, "end": 2466.06, "text": " Yes, we have actually we I mean, we have already lots of internal checks", "tokens": [50840, 1079, 11, 321, 362, 767, 321, 286, 914, 11, 321, 362, 1217, 3195, 295, 6920, 13834, 51014], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1009, "seek": 245306, "start": 2466.06, "end": 2469.02, "text": " and balances, but we're going to start publishing actually, you know,", "tokens": [51014, 293, 33993, 11, 457, 321, 434, 516, 281, 722, 17832, 767, 11, 291, 458, 11, 51162], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1010, "seek": 245306, "start": 2469.02, "end": 2470.1, "text": " sort of watch the spaces.", "tokens": [51162, 1333, 295, 1159, 264, 7673, 13, 51216], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1011, "seek": 245306, "start": 2470.1, "end": 2473.58, "text": " We're working on a whole bunch of blog posts and technical papers", "tokens": [51216, 492, 434, 1364, 322, 257, 1379, 3840, 295, 6968, 12300, 293, 6191, 10577, 51390], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1012, "seek": 245306, "start": 2473.86, "end": 2477.42, "text": " that we'll be putting out in the next few months that, you know,", "tokens": [51404, 300, 321, 603, 312, 3372, 484, 294, 264, 958, 1326, 2493, 300, 11, 291, 458, 11, 51582], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1013, "seek": 245306, "start": 2477.42, "end": 2480.2999999999997, "text": " along the similar lines of things like responsible scaling laws and so on.", "tokens": [51582, 2051, 264, 2531, 3876, 295, 721, 411, 6250, 21589, 6064, 293, 370, 322, 13, 51726], "temperature": 0.0, "avg_logprob": -0.15139086263163107, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.008499172516167164}, {"id": 1014, "seek": 248030, "start": 2480.42, "end": 2485.38, "text": " We have those implicitly internally in various safety councils and so on,", "tokens": [50370, 492, 362, 729, 26947, 356, 19501, 294, 3683, 4514, 39187, 293, 370, 322, 11, 50618], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1015, "seek": 248030, "start": 2485.38, "end": 2487.78, "text": " people like Shane, Chair and so on.", "tokens": [50618, 561, 411, 25865, 11, 8678, 293, 370, 322, 13, 50738], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1016, "seek": 248030, "start": 2487.78, "end": 2490.98, "text": " But but it's time for us to talk about that more publicly, I think.", "tokens": [50738, 583, 457, 309, 311, 565, 337, 505, 281, 751, 466, 300, 544, 14843, 11, 286, 519, 13, 50898], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1017, "seek": 248030, "start": 2490.98, "end": 2493.1000000000004, "text": " So we'll be doing that throughout the course of the year.", "tokens": [50898, 407, 321, 603, 312, 884, 300, 3710, 264, 1164, 295, 264, 1064, 13, 51004], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1018, "seek": 248030, "start": 2493.1000000000004, "end": 2494.0600000000004, "text": " That's great to hear.", "tokens": [51004, 663, 311, 869, 281, 1568, 13, 51052], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1019, "seek": 248030, "start": 2494.0600000000004, "end": 2497.5, "text": " And another thing I'm curious about is so it's not only the risk of,", "tokens": [51052, 400, 1071, 551, 286, 478, 6369, 466, 307, 370, 309, 311, 406, 787, 264, 3148, 295, 11, 51224], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1020, "seek": 248030, "start": 2497.5, "end": 2501.7000000000003, "text": " like, you know, the deployed model being something that people can use to do bad things,", "tokens": [51224, 411, 11, 291, 458, 11, 264, 17826, 2316, 885, 746, 300, 561, 393, 764, 281, 360, 1578, 721, 11, 51434], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1021, "seek": 248030, "start": 2501.7000000000003, "end": 2506.7000000000003, "text": " but also rogue actors, bad foreign agents, so forth, being able to steal the weights", "tokens": [51434, 457, 611, 39100, 10037, 11, 1578, 5329, 12554, 11, 370, 5220, 11, 885, 1075, 281, 11009, 264, 17443, 51684], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1022, "seek": 248030, "start": 2506.7000000000003, "end": 2508.26, "text": " and then fine tune them to do crazy things.", "tokens": [51684, 293, 550, 2489, 10864, 552, 281, 360, 3219, 721, 13, 51762], "temperature": 0.0, "avg_logprob": -0.179683792007553, "compression_ratio": 1.7, "no_speech_prob": 0.0026373539585620165}, {"id": 1023, "seek": 250826, "start": 2508.6600000000003, "end": 2512.6200000000003, "text": " How do you think about securing the weights to make sure something like this", "tokens": [50384, 1012, 360, 291, 519, 466, 33640, 264, 17443, 281, 652, 988, 746, 411, 341, 50582], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1024, "seek": 250826, "start": 2512.6200000000003, "end": 2516.7000000000003, "text": " doesn't happen, making sure a very like key group of people have access to them", "tokens": [50582, 1177, 380, 1051, 11, 1455, 988, 257, 588, 411, 2141, 1594, 295, 561, 362, 2105, 281, 552, 50786], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1025, "seek": 250826, "start": 2516.7000000000003, "end": 2517.1400000000003, "text": " and so forth?", "tokens": [50786, 293, 370, 5220, 30, 50808], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1026, "seek": 250826, "start": 2517.1400000000003, "end": 2517.9, "text": " Yeah, it's interesting.", "tokens": [50808, 865, 11, 309, 311, 1880, 13, 50846], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1027, "seek": 250826, "start": 2517.9, "end": 2519.5, "text": " So first of all, there's sort of two parts of this.", "tokens": [50846, 407, 700, 295, 439, 11, 456, 311, 1333, 295, 732, 3166, 295, 341, 13, 50926], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1028, "seek": 250826, "start": 2519.5, "end": 2522.1800000000003, "text": " One is security, one is open source, maybe we can discuss.", "tokens": [50926, 1485, 307, 3825, 11, 472, 307, 1269, 4009, 11, 1310, 321, 393, 2248, 13, 51060], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1029, "seek": 250826, "start": 2522.1800000000003, "end": 2524.38, "text": " But the security, I think, is super key.", "tokens": [51060, 583, 264, 3825, 11, 286, 519, 11, 307, 1687, 2141, 13, 51170], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1030, "seek": 250826, "start": 2524.38, "end": 2528.1000000000004, "text": " Like just a sort of normal cyber security type things.", "tokens": [51170, 1743, 445, 257, 1333, 295, 2710, 13411, 3825, 2010, 721, 13, 51356], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1031, "seek": 250826, "start": 2528.1000000000004, "end": 2530.1400000000003, "text": " And I think we're lucky at Google DeepMind.", "tokens": [51356, 400, 286, 519, 321, 434, 6356, 412, 3329, 14895, 44, 471, 13, 51458], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1032, "seek": 250826, "start": 2530.1400000000003, "end": 2534.26, "text": " We're kind of behind Google's firewall and cloud protection, which is, you know,", "tokens": [51458, 492, 434, 733, 295, 2261, 3329, 311, 36109, 293, 4588, 6334, 11, 597, 307, 11, 291, 458, 11, 51664], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1033, "seek": 250826, "start": 2534.26, "end": 2537.6200000000003, "text": " I think best, you know, best in class in the world, corporately.", "tokens": [51664, 286, 519, 1151, 11, 291, 458, 11, 1151, 294, 1508, 294, 264, 1002, 11, 6804, 1592, 13, 51832], "temperature": 0.0, "avg_logprob": -0.17841567522213783, "compression_ratio": 1.6885714285714286, "no_speech_prob": 0.0022519242484122515}, {"id": 1034, "seek": 253762, "start": 2537.74, "end": 2539.2599999999998, "text": " So we already have that protection.", "tokens": [50370, 407, 321, 1217, 362, 300, 6334, 13, 50446], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1035, "seek": 253762, "start": 2539.2599999999998, "end": 2545.2599999999998, "text": " And then behind that, we have specific DeepMind protections within our code base.", "tokens": [50446, 400, 550, 2261, 300, 11, 321, 362, 2685, 14895, 44, 471, 29031, 1951, 527, 3089, 3096, 13, 50746], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1036, "seek": 253762, "start": 2545.2599999999998, "end": 2547.2999999999997, "text": " So it's sort of a double layer of protection.", "tokens": [50746, 407, 309, 311, 1333, 295, 257, 3834, 4583, 295, 6334, 13, 50848], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1037, "seek": 253762, "start": 2547.2999999999997, "end": 2548.7, "text": " So I feel pretty good about that.", "tokens": [50848, 407, 286, 841, 1238, 665, 466, 300, 13, 50918], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1038, "seek": 253762, "start": 2548.7, "end": 2551.7, "text": " That that's, I mean, we, you know, you can never be complacent on that.", "tokens": [50918, 663, 300, 311, 11, 286, 914, 11, 321, 11, 291, 458, 11, 291, 393, 1128, 312, 49546, 317, 322, 300, 13, 51068], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1039, "seek": 253762, "start": 2551.7, "end": 2557.58, "text": " But I feel it's already sort of best in the world in terms of cyber defences.", "tokens": [51068, 583, 286, 841, 309, 311, 1217, 1333, 295, 1151, 294, 264, 1002, 294, 2115, 295, 13411, 1060, 2667, 13, 51362], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1040, "seek": 253762, "start": 2557.58, "end": 2559.5, "text": " But we've got to carry on improving that.", "tokens": [51362, 583, 321, 600, 658, 281, 3985, 322, 11470, 300, 13, 51458], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1041, "seek": 253762, "start": 2559.5, "end": 2563.74, "text": " And again, things like the hard and sandboxes could be a way of doing that as well.", "tokens": [51458, 400, 797, 11, 721, 411, 264, 1152, 293, 42115, 279, 727, 312, 257, 636, 295, 884, 300, 382, 731, 13, 51670], "temperature": 0.0, "avg_logprob": -0.14993733122148586, "compression_ratio": 1.6892857142857143, "no_speech_prob": 0.0050407531671226025}, {"id": 1042, "seek": 256374, "start": 2563.7799999999997, "end": 2568.54, "text": " And maybe even there are, you know, specifically secure data centers", "tokens": [50366, 400, 1310, 754, 456, 366, 11, 291, 458, 11, 4682, 7144, 1412, 10898, 50604], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1043, "seek": 256374, "start": 2568.54, "end": 2571.06, "text": " or hardware solutions to this, too, that we're thinking about.", "tokens": [50604, 420, 8837, 6547, 281, 341, 11, 886, 11, 300, 321, 434, 1953, 466, 13, 50730], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1044, "seek": 256374, "start": 2571.06, "end": 2575.8199999999997, "text": " I think that maybe in the next three, four, five years, we would also want air gaps", "tokens": [50730, 286, 519, 300, 1310, 294, 264, 958, 1045, 11, 1451, 11, 1732, 924, 11, 321, 576, 611, 528, 1988, 15031, 50968], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1045, "seek": 256374, "start": 2575.8199999999997, "end": 2578.9799999999996, "text": " and various other things that are known in the security community.", "tokens": [50968, 293, 3683, 661, 721, 300, 366, 2570, 294, 264, 3825, 1768, 13, 51126], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1046, "seek": 256374, "start": 2578.9799999999996, "end": 2579.7799999999997, "text": " So I think that's key.", "tokens": [51126, 407, 286, 519, 300, 311, 2141, 13, 51166], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1047, "seek": 256374, "start": 2579.7799999999997, "end": 2583.02, "text": " And I think all frontier labs should be doing that because otherwise, you know,", "tokens": [51166, 400, 286, 519, 439, 35853, 20339, 820, 312, 884, 300, 570, 5911, 11, 291, 458, 11, 51328], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1048, "seek": 256374, "start": 2583.02, "end": 2586.7799999999997, "text": " nation states and other things, rogue nation, you know, states and other other", "tokens": [51328, 4790, 4368, 293, 661, 721, 11, 39100, 4790, 11, 291, 458, 11, 4368, 293, 661, 661, 51516], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1049, "seek": 256374, "start": 2586.7799999999997, "end": 2590.18, "text": " dangerous actors, that there would be obviously a lot of incentive for them", "tokens": [51516, 5795, 10037, 11, 300, 456, 576, 312, 2745, 257, 688, 295, 22346, 337, 552, 51686], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1050, "seek": 256374, "start": 2590.18, "end": 2591.7799999999997, "text": " to to steal things like the weights.", "tokens": [51686, 281, 281, 11009, 721, 411, 264, 17443, 13, 51766], "temperature": 0.0, "avg_logprob": -0.16169252395629882, "compression_ratio": 1.867313915857605, "no_speech_prob": 0.023349853232502937}, {"id": 1051, "seek": 259178, "start": 2592.7000000000003, "end": 2595.5800000000004, "text": " And then, you know, of course, open source is another interesting question,", "tokens": [50410, 400, 550, 11, 291, 458, 11, 295, 1164, 11, 1269, 4009, 307, 1071, 1880, 1168, 11, 50554], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1052, "seek": 259178, "start": 2595.5800000000004, "end": 2598.42, "text": " which is we're huge proponents of open source and open science.", "tokens": [50554, 597, 307, 321, 434, 2603, 2365, 40496, 295, 1269, 4009, 293, 1269, 3497, 13, 50696], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1053, "seek": 259178, "start": 2598.42, "end": 2601.42, "text": " I mean, almost every, you know, we've published thousands of papers", "tokens": [50696, 286, 914, 11, 1920, 633, 11, 291, 458, 11, 321, 600, 6572, 5383, 295, 10577, 50846], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1054, "seek": 259178, "start": 2601.42, "end": 2604.42, "text": " and things like Alpha Fold and Transformers, of course.", "tokens": [50846, 293, 721, 411, 20588, 24609, 293, 27938, 433, 11, 295, 1164, 13, 50996], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1055, "seek": 259178, "start": 2604.42, "end": 2608.6200000000003, "text": " And Alpha Gold, all of these things we put out there into the world, published", "tokens": [50996, 400, 20588, 6731, 11, 439, 295, 613, 721, 321, 829, 484, 456, 666, 264, 1002, 11, 6572, 51206], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1056, "seek": 259178, "start": 2608.6200000000003, "end": 2613.2200000000003, "text": " and open source, many of them, GraphCast, most recently, our weather prediction system.", "tokens": [51206, 293, 1269, 4009, 11, 867, 295, 552, 11, 21884, 34, 525, 11, 881, 3938, 11, 527, 5503, 17630, 1185, 13, 51436], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1057, "seek": 259178, "start": 2613.2200000000003, "end": 2617.86, "text": " But when it comes to, you know, the core technology, the foundational technology", "tokens": [51436, 583, 562, 309, 1487, 281, 11, 291, 458, 11, 264, 4965, 2899, 11, 264, 32195, 2899, 51668], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1058, "seek": 259178, "start": 2617.86, "end": 2621.46, "text": " and very general purpose, I think the question I would have is,", "tokens": [51668, 293, 588, 2674, 4334, 11, 286, 519, 264, 1168, 286, 576, 362, 307, 11, 51848], "temperature": 0.0, "avg_logprob": -0.2193919302712024, "compression_ratio": 1.8081761006289307, "no_speech_prob": 0.002038835547864437}, {"id": 1059, "seek": 262146, "start": 2622.38, "end": 2627.02, "text": " if you, you know, first of all, open source proponents is that how does one", "tokens": [50410, 498, 291, 11, 291, 458, 11, 700, 295, 439, 11, 1269, 4009, 2365, 40496, 307, 300, 577, 775, 472, 50642], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1060, "seek": 262146, "start": 2627.02, "end": 2634.02, "text": " stop bad actors, individuals or, you know, up to rogue states, taking those", "tokens": [50642, 1590, 1578, 10037, 11, 5346, 420, 11, 291, 458, 11, 493, 281, 39100, 4368, 11, 1940, 729, 50992], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1061, "seek": 262146, "start": 2634.02, "end": 2638.02, "text": " same open source systems and repurposing them because their general purpose", "tokens": [50992, 912, 1269, 4009, 3652, 293, 1085, 20130, 6110, 552, 570, 641, 2674, 4334, 51192], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1062, "seek": 262146, "start": 2638.02, "end": 2639.78, "text": " for harmful ends, right?", "tokens": [51192, 337, 19727, 5314, 11, 558, 30, 51280], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1063, "seek": 262146, "start": 2639.78, "end": 2641.86, "text": " So we have to answer that question.", "tokens": [51280, 407, 321, 362, 281, 1867, 300, 1168, 13, 51384], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1064, "seek": 262146, "start": 2641.86, "end": 2645.78, "text": " And I haven't heard a compelling, I mean, I don't know what the answer is to that,", "tokens": [51384, 400, 286, 2378, 380, 2198, 257, 20050, 11, 286, 914, 11, 286, 500, 380, 458, 437, 264, 1867, 307, 281, 300, 11, 51580], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1065, "seek": 262146, "start": 2645.78, "end": 2650.7, "text": " but I haven't heard a compelling, clear answer to that from proponents", "tokens": [51580, 457, 286, 2378, 380, 2198, 257, 20050, 11, 1850, 1867, 281, 300, 490, 2365, 40496, 51826], "temperature": 0.0, "avg_logprob": -0.22403307618765994, "compression_ratio": 1.7751004016064258, "no_speech_prob": 0.0015970398671925068}, {"id": 1066, "seek": 265070, "start": 2650.8999999999996, "end": 2652.8999999999996, "text": " of just sort of open sourcing everything.", "tokens": [50374, 295, 445, 1333, 295, 1269, 11006, 2175, 1203, 13, 50474], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1067, "seek": 265070, "start": 2652.8999999999996, "end": 2655.9399999999996, "text": " So I think there has to be some balance there, but, you know,", "tokens": [50474, 407, 286, 519, 456, 575, 281, 312, 512, 4772, 456, 11, 457, 11, 291, 458, 11, 50626], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1068, "seek": 265070, "start": 2655.9399999999996, "end": 2658.18, "text": " obviously it's a complex question of what that is.", "tokens": [50626, 2745, 309, 311, 257, 3997, 1168, 295, 437, 300, 307, 13, 50738], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1069, "seek": 265070, "start": 2658.18, "end": 2661.1, "text": " Yeah, yeah, I feel like tech doesn't get the credit it deserves for, like,", "tokens": [50738, 865, 11, 1338, 11, 286, 841, 411, 7553, 1177, 380, 483, 264, 5397, 309, 17037, 337, 11, 411, 11, 50884], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1070, "seek": 265070, "start": 2661.1, "end": 2663.4199999999996, "text": " funding, you know, hundreds of billions of dollars worth of R&D.", "tokens": [50884, 6137, 11, 291, 458, 11, 6779, 295, 17375, 295, 3808, 3163, 295, 497, 5, 35, 13, 51000], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1071, "seek": 265070, "start": 2664.22, "end": 2666.8999999999996, "text": " And, you know, obviously I have deep bind with systems like Alpha Fold and so on.", "tokens": [51040, 400, 11, 291, 458, 11, 2745, 286, 362, 2452, 14786, 365, 3652, 411, 20588, 24609, 293, 370, 322, 13, 51174], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1072, "seek": 265070, "start": 2667.62, "end": 2670.9399999999996, "text": " Well, but when we talk about securing the weights, you know, as we said,", "tokens": [51210, 1042, 11, 457, 562, 321, 751, 466, 33640, 264, 17443, 11, 291, 458, 11, 382, 321, 848, 11, 51376], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1073, "seek": 265070, "start": 2670.9399999999996, "end": 2673.8999999999996, "text": " like maybe right now, it's not something that, like, is going to cause the end", "tokens": [51376, 411, 1310, 558, 586, 11, 309, 311, 406, 746, 300, 11, 411, 11, 307, 516, 281, 3082, 264, 917, 51524], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1074, "seek": 265070, "start": 2673.8999999999996, "end": 2675.98, "text": " of the world or anything, but as these systems get better and better,", "tokens": [51524, 295, 264, 1002, 420, 1340, 11, 457, 382, 613, 3652, 483, 1101, 293, 1101, 11, 51628], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1075, "seek": 265070, "start": 2675.98, "end": 2679.2999999999997, "text": " the worry that, yes, a foreign agent or something gets access to them.", "tokens": [51628, 264, 3292, 300, 11, 2086, 11, 257, 5329, 9461, 420, 746, 2170, 2105, 281, 552, 13, 51794], "temperature": 0.0, "avg_logprob": -0.19987990061442057, "compression_ratio": 1.7792553191489362, "no_speech_prob": 0.006557445507496595}, {"id": 1076, "seek": 267930, "start": 2679.5800000000004, "end": 2682.02, "text": " Presumably right now, there's like dozens to hundreds of researchers", "tokens": [50378, 2718, 449, 1188, 558, 586, 11, 456, 311, 411, 18431, 281, 6779, 295, 10309, 50500], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1077, "seek": 267930, "start": 2682.02, "end": 2683.2200000000003, "text": " who have access to the weights.", "tokens": [50500, 567, 362, 2105, 281, 264, 17443, 13, 50560], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1078, "seek": 267930, "start": 2683.2200000000003, "end": 2686.02, "text": " How do you, well, what's a plan for, like, getting into, like,", "tokens": [50560, 1012, 360, 291, 11, 731, 11, 437, 311, 257, 1393, 337, 11, 411, 11, 1242, 666, 11, 411, 11, 50700], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1079, "seek": 267930, "start": 2686.02, "end": 2687.78, "text": " the situation or getting the weights in the situation rooms?", "tokens": [50700, 264, 2590, 420, 1242, 264, 17443, 294, 264, 2590, 9396, 30, 50788], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1080, "seek": 267930, "start": 2687.78, "end": 2690.5800000000004, "text": " If you're like, if you need to access to them, it's like, you know,", "tokens": [50788, 759, 291, 434, 411, 11, 498, 291, 643, 281, 2105, 281, 552, 11, 309, 311, 411, 11, 291, 458, 11, 50928], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1081, "seek": 267930, "start": 2690.5800000000004, "end": 2692.0600000000004, "text": " some extremely strenuous process.", "tokens": [50928, 512, 4664, 342, 1095, 12549, 1399, 13, 51002], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1082, "seek": 267930, "start": 2692.0600000000004, "end": 2694.34, "text": " You know, nobody, nobody individual can really take them out.", "tokens": [51002, 509, 458, 11, 5079, 11, 5079, 2609, 393, 534, 747, 552, 484, 13, 51116], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1083, "seek": 267930, "start": 2694.34, "end": 2695.02, "text": " Yeah, yeah.", "tokens": [51116, 865, 11, 1338, 13, 51150], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1084, "seek": 267930, "start": 2695.02, "end": 2698.54, "text": " I mean, one has to balance that with, with, with allowing for collaboration", "tokens": [51150, 286, 914, 11, 472, 575, 281, 4772, 300, 365, 11, 365, 11, 365, 8293, 337, 9363, 51326], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1085, "seek": 267930, "start": 2698.54, "end": 2699.42, "text": " and speed of progress.", "tokens": [51326, 293, 3073, 295, 4205, 13, 51370], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1086, "seek": 267930, "start": 2699.42, "end": 2703.1400000000003, "text": " Actually, another interesting thing is, of course, you want, you know,", "tokens": [51370, 5135, 11, 1071, 1880, 551, 307, 11, 295, 1164, 11, 291, 528, 11, 291, 458, 11, 51556], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1087, "seek": 267930, "start": 2703.1400000000003, "end": 2707.5, "text": " brilliant independent researchers from academia or, or things like the UK", "tokens": [51556, 10248, 6695, 10309, 490, 28937, 420, 11, 420, 721, 411, 264, 7051, 51774], "temperature": 0.0, "avg_logprob": -0.21342010498046876, "compression_ratio": 1.8243626062322946, "no_speech_prob": 0.0020362292416393757}, {"id": 1088, "seek": 270750, "start": 2707.58, "end": 2713.86, "text": " AI Safety Institute and US1 to be able to kind of red team these systems.", "tokens": [50368, 7318, 21340, 9446, 293, 2546, 16, 281, 312, 1075, 281, 733, 295, 2182, 1469, 613, 3652, 13, 50682], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1089, "seek": 270750, "start": 2713.86, "end": 2717.42, "text": " So, so one has to expose them to a certain extent, although that's not", "tokens": [50682, 407, 11, 370, 472, 575, 281, 19219, 552, 281, 257, 1629, 8396, 11, 4878, 300, 311, 406, 50860], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1090, "seek": 270750, "start": 2717.42, "end": 2718.34, "text": " necessarily the weights.", "tokens": [50860, 4725, 264, 17443, 13, 50906], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1091, "seek": 270750, "start": 2718.98, "end": 2722.9, "text": " And then, you know, we have a lot of processes in place about making sure", "tokens": [50938, 400, 550, 11, 291, 458, 11, 321, 362, 257, 688, 295, 7555, 294, 1081, 466, 1455, 988, 51134], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1092, "seek": 270750, "start": 2722.9, "end": 2727.02, "text": " that, you know, only if you need them that, that you have access to, you", "tokens": [51134, 300, 11, 291, 458, 11, 787, 498, 291, 643, 552, 300, 11, 300, 291, 362, 2105, 281, 11, 291, 51340], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1093, "seek": 270750, "start": 2727.02, "end": 2729.26, "text": " know, those people who need access, have access.", "tokens": [51340, 458, 11, 729, 561, 567, 643, 2105, 11, 362, 2105, 13, 51452], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1094, "seek": 270750, "start": 2729.9, "end": 2733.74, "text": " And right now, I think we're still in the early days of those kinds of", "tokens": [51484, 400, 558, 586, 11, 286, 519, 321, 434, 920, 294, 264, 2440, 1708, 295, 729, 3685, 295, 51676], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1095, "seek": 270750, "start": 2733.74, "end": 2735.22, "text": " systems being at risk.", "tokens": [51676, 3652, 885, 412, 3148, 13, 51750], "temperature": 0.0, "avg_logprob": -0.1550612030029297, "compression_ratio": 1.7255639097744362, "no_speech_prob": 0.006002729758620262}, {"id": 1096, "seek": 273522, "start": 2735.4199999999996, "end": 2738.3399999999997, "text": " And as that, as these systems become more powerful and more general and", "tokens": [50374, 400, 382, 300, 11, 382, 613, 3652, 1813, 544, 4005, 293, 544, 2674, 293, 50520], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1097, "seek": 273522, "start": 2738.3399999999997, "end": 2741.9399999999996, "text": " more capable, I think one has to look at the, the access question.", "tokens": [50520, 544, 8189, 11, 286, 519, 472, 575, 281, 574, 412, 264, 11, 264, 2105, 1168, 13, 50700], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1098, "seek": 273522, "start": 2742.8199999999997, "end": 2745.8599999999997, "text": " So some of these other labs have specialized in different things relative", "tokens": [50744, 407, 512, 295, 613, 661, 20339, 362, 19813, 294, 819, 721, 4972, 50896], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1099, "seek": 273522, "start": 2745.8599999999997, "end": 2748.4599999999996, "text": " to safety, like Anthropoc, for example, with interoperability.", "tokens": [50896, 281, 4514, 11, 411, 12727, 1513, 905, 11, 337, 1365, 11, 365, 728, 7192, 2310, 13, 51026], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1100, "seek": 273522, "start": 2748.4599999999996, "end": 2752.8999999999996, "text": " And do you have some sense of where you guys might have an edge where as so", "tokens": [51026, 400, 360, 291, 362, 512, 2020, 295, 689, 291, 1074, 1062, 362, 364, 4691, 689, 382, 370, 51248], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1101, "seek": 273522, "start": 2752.8999999999996, "end": 2754.98, "text": " that, you know, now that you have the frontier model, you're going to", "tokens": [51248, 300, 11, 291, 458, 11, 586, 300, 291, 362, 264, 35853, 2316, 11, 291, 434, 516, 281, 51352], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1102, "seek": 273522, "start": 2754.98, "end": 2758.1, "text": " scale up safety, where you guys are going to be able to put out the best", "tokens": [51352, 4373, 493, 4514, 11, 689, 291, 1074, 366, 516, 281, 312, 1075, 281, 829, 484, 264, 1151, 51508], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1103, "seek": 273522, "start": 2758.1, "end": 2759.18, "text": " frontier research on safety.", "tokens": [51508, 35853, 2132, 322, 4514, 13, 51562], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1104, "seek": 273522, "start": 2759.18, "end": 2762.3799999999997, "text": " I think, you know, well, we helped pioneer RLHF and other things like that,", "tokens": [51562, 286, 519, 11, 291, 458, 11, 731, 11, 321, 4254, 37668, 497, 43, 39, 37, 293, 661, 721, 411, 300, 11, 51722], "temperature": 0.0, "avg_logprob": -0.2150423849782636, "compression_ratio": 1.8318042813455657, "no_speech_prob": 0.0031808193307369947}, {"id": 1105, "seek": 276238, "start": 2762.38, "end": 2765.34, "text": " which can also be obviously used for performance, but also for safety.", "tokens": [50364, 597, 393, 611, 312, 2745, 1143, 337, 3389, 11, 457, 611, 337, 4514, 13, 50512], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1106, "seek": 276238, "start": 2766.2200000000003, "end": 2771.1, "text": " I think that, you know, a lot of the self-play ideas and these kinds of", "tokens": [50556, 286, 519, 300, 11, 291, 458, 11, 257, 688, 295, 264, 2698, 12, 2858, 3487, 293, 613, 3685, 295, 50800], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1107, "seek": 276238, "start": 2771.1, "end": 2777.62, "text": " things could also be used potentially to, to auto-test a lot of the boundary", "tokens": [50800, 721, 727, 611, 312, 1143, 7263, 281, 11, 281, 8399, 12, 31636, 257, 688, 295, 264, 12866, 51126], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1108, "seek": 276238, "start": 2777.62, "end": 2779.54, "text": " conditions that you have with the new systems.", "tokens": [51126, 4487, 300, 291, 362, 365, 264, 777, 3652, 13, 51222], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1109, "seek": 276238, "start": 2779.7000000000003, "end": 2783.42, "text": " I mean, part of the issue is that with these sort of very general systems,", "tokens": [51230, 286, 914, 11, 644, 295, 264, 2734, 307, 300, 365, 613, 1333, 295, 588, 2674, 3652, 11, 51416], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1110, "seek": 276238, "start": 2784.02, "end": 2788.1400000000003, "text": " there's so much surface area to cover, like about how these systems behave.", "tokens": [51446, 456, 311, 370, 709, 3753, 1859, 281, 2060, 11, 411, 466, 577, 613, 3652, 15158, 13, 51652], "temperature": 0.0, "avg_logprob": -0.1332418423778606, "compression_ratio": 1.7231404958677685, "no_speech_prob": 0.0010134534677490592}, {"id": 1111, "seek": 278814, "start": 2788.3399999999997, "end": 2791.7799999999997, "text": " So I think we are going to need some automated testing.", "tokens": [50374, 407, 286, 519, 321, 366, 516, 281, 643, 512, 18473, 4997, 13, 50546], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1112, "seek": 278814, "start": 2791.94, "end": 2796.54, "text": " And again, with things like simulations and games environment, very realistic", "tokens": [50554, 400, 797, 11, 365, 721, 411, 35138, 293, 2813, 2823, 11, 588, 12465, 50784], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1113, "seek": 278814, "start": 2796.54, "end": 2800.74, "text": " environments, virtual environments, I think we have a long history in that", "tokens": [50784, 12388, 11, 6374, 12388, 11, 286, 519, 321, 362, 257, 938, 2503, 294, 300, 50994], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1114, "seek": 278814, "start": 2800.74, "end": 2806.2599999999998, "text": " and using those kinds of systems and making use of them for building AI algorithms.", "tokens": [50994, 293, 1228, 729, 3685, 295, 3652, 293, 1455, 764, 295, 552, 337, 2390, 7318, 14642, 13, 51270], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1115, "seek": 278814, "start": 2806.2599999999998, "end": 2809.06, "text": " So I think we can leverage all of that history.", "tokens": [51270, 407, 286, 519, 321, 393, 13982, 439, 295, 300, 2503, 13, 51410], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1116, "seek": 278814, "start": 2809.7, "end": 2812.3799999999997, "text": " And then, you know, around at Google, we're very lucky we have some of the", "tokens": [51442, 400, 550, 11, 291, 458, 11, 926, 412, 3329, 11, 321, 434, 588, 6356, 321, 362, 512, 295, 264, 51576], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1117, "seek": 278814, "start": 2812.3799999999997, "end": 2815.94, "text": " world's best cybersecurity experts, hardware designers.", "tokens": [51576, 1002, 311, 1151, 38765, 8572, 11, 8837, 16196, 13, 51754], "temperature": 0.0, "avg_logprob": -0.14233875274658203, "compression_ratio": 1.7003610108303249, "no_speech_prob": 0.007928880862891674}, {"id": 1118, "seek": 281594, "start": 2816.14, "end": 2820.38, "text": " So I think we can bring that to bear in, you know, for security and safety as well.", "tokens": [50374, 407, 286, 519, 321, 393, 1565, 300, 281, 6155, 294, 11, 291, 458, 11, 337, 3825, 293, 4514, 382, 731, 13, 50586], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1119, "seek": 281594, "start": 2820.58, "end": 2822.26, "text": " Great, great. Let's talk about Gemini.", "tokens": [50596, 3769, 11, 869, 13, 961, 311, 751, 466, 22894, 3812, 13, 50680], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1120, "seek": 281594, "start": 2822.82, "end": 2825.06, "text": " So, you know, now you guys have the best model in the world.", "tokens": [50708, 407, 11, 291, 458, 11, 586, 291, 1074, 362, 264, 1151, 2316, 294, 264, 1002, 13, 50820], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1121, "seek": 281594, "start": 2826.26, "end": 2829.9, "text": " So I'm curious, you know, the default way to interact with these systems has", "tokens": [50880, 407, 286, 478, 6369, 11, 291, 458, 11, 264, 7576, 636, 281, 4648, 365, 613, 3652, 575, 51062], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1122, "seek": 281594, "start": 2829.9, "end": 2832.06, "text": " been through chat so far.", "tokens": [51062, 668, 807, 5081, 370, 1400, 13, 51170], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1123, "seek": 281594, "start": 2832.2200000000003, "end": 2834.9, "text": " Now that we have multimodal and all these new capabilities, how do you", "tokens": [51178, 823, 300, 321, 362, 32972, 378, 304, 293, 439, 613, 777, 10862, 11, 577, 360, 291, 51312], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1124, "seek": 281594, "start": 2835.02, "end": 2835.78, "text": " anticipate that changing?", "tokens": [51318, 21685, 300, 4473, 30, 51356], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1125, "seek": 281594, "start": 2835.78, "end": 2837.06, "text": " Or do you think that will still be the case?", "tokens": [51356, 1610, 360, 291, 519, 300, 486, 920, 312, 264, 1389, 30, 51420], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1126, "seek": 281594, "start": 2837.58, "end": 2840.42, "text": " Yeah, I think we're just at the beginning of actually understanding what a", "tokens": [51446, 865, 11, 286, 519, 321, 434, 445, 412, 264, 2863, 295, 767, 3701, 437, 257, 51588], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1127, "seek": 281594, "start": 2840.42, "end": 2845.82, "text": " full multimodal model system, how exciting that might be to interact with", "tokens": [51588, 1577, 32972, 378, 304, 2316, 1185, 11, 577, 4670, 300, 1062, 312, 281, 4648, 365, 51858], "temperature": 0.0, "avg_logprob": -0.17132601799902977, "compression_ratio": 1.764525993883792, "no_speech_prob": 0.0027801902033388615}, {"id": 1128, "seek": 284582, "start": 2845.82, "end": 2849.54, "text": " them, and it will be quite different to, I think, what we're used to today with", "tokens": [50364, 552, 11, 293, 309, 486, 312, 1596, 819, 281, 11, 286, 519, 11, 437, 321, 434, 1143, 281, 965, 365, 50550], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1129, "seek": 284582, "start": 2849.54, "end": 2850.26, "text": " the chat bots.", "tokens": [50550, 264, 5081, 35410, 13, 50586], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1130, "seek": 284582, "start": 2850.26, "end": 2854.98, "text": " I think the next versions of this over the next year, 18 months, you know,", "tokens": [50586, 286, 519, 264, 958, 9606, 295, 341, 670, 264, 958, 1064, 11, 2443, 2493, 11, 291, 458, 11, 50822], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1131, "seek": 284582, "start": 2855.1800000000003, "end": 2858.5, "text": " maybe we'll have some contextual understanding around the environment around", "tokens": [50832, 1310, 321, 603, 362, 512, 35526, 3701, 926, 264, 2823, 926, 50998], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1132, "seek": 284582, "start": 2858.5, "end": 2860.7400000000002, "text": " you through a camera or whatever it is, a phone.", "tokens": [50998, 291, 807, 257, 2799, 420, 2035, 309, 307, 11, 257, 2593, 13, 51110], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1133, "seek": 284582, "start": 2861.6200000000003, "end": 2864.5800000000004, "text": " You know, I could imagine that as the next awesome glasses at the next step.", "tokens": [51154, 509, 458, 11, 286, 727, 3811, 300, 382, 264, 958, 3476, 10812, 412, 264, 958, 1823, 13, 51302], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1134, "seek": 284582, "start": 2865.34, "end": 2870.06, "text": " And then I think that we'll start becoming more fluid in understanding, oh,", "tokens": [51340, 400, 550, 286, 519, 300, 321, 603, 722, 5617, 544, 9113, 294, 3701, 11, 1954, 11, 51576], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1135, "seek": 284582, "start": 2870.26, "end": 2872.26, "text": " let's sample from a video.", "tokens": [51586, 718, 311, 6889, 490, 257, 960, 13, 51686], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1136, "seek": 284582, "start": 2872.26, "end": 2873.6200000000003, "text": " Let's use voice.", "tokens": [51686, 961, 311, 764, 3177, 13, 51754], "temperature": 0.0, "avg_logprob": -0.2051437231210562, "compression_ratio": 1.7024221453287198, "no_speech_prob": 0.0034301343839615583}, {"id": 1137, "seek": 287362, "start": 2874.62, "end": 2879.46, "text": " Maybe even eventually things like touch and, you know, if you think about robotics", "tokens": [50414, 2704, 754, 4728, 721, 411, 2557, 293, 11, 291, 458, 11, 498, 291, 519, 466, 34145, 50656], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1138, "seek": 287362, "start": 2879.46, "end": 2882.42, "text": " and other things, you know, sensors, other types of sensors.", "tokens": [50656, 293, 661, 721, 11, 291, 458, 11, 14840, 11, 661, 3467, 295, 14840, 13, 50804], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1139, "seek": 287362, "start": 2882.62, "end": 2885.58, "text": " So I think the world's about to become very exciting.", "tokens": [50814, 407, 286, 519, 264, 1002, 311, 466, 281, 1813, 588, 4670, 13, 50962], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1140, "seek": 287362, "start": 2885.58, "end": 2888.54, "text": " I think in the next few years, as we start getting used to the idea of what", "tokens": [50962, 286, 519, 294, 264, 958, 1326, 924, 11, 382, 321, 722, 1242, 1143, 281, 264, 1558, 295, 437, 51110], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1141, "seek": 287362, "start": 2888.7, "end": 2890.2999999999997, "text": " true multimodality means.", "tokens": [51118, 2074, 32972, 378, 1860, 1355, 13, 51198], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1142, "seek": 287362, "start": 2891.5, "end": 2895.62, "text": " On the robotic subject, Ilya said when he was on the podcast that the reason", "tokens": [51258, 1282, 264, 30468, 3983, 11, 286, 45106, 848, 562, 415, 390, 322, 264, 7367, 300, 264, 1778, 51464], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1143, "seek": 287362, "start": 2895.62, "end": 2898.74, "text": " opening I gave up on robotics was because they didn't have enough data in that", "tokens": [51464, 5193, 286, 2729, 493, 322, 34145, 390, 570, 436, 994, 380, 362, 1547, 1412, 294, 300, 51620], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1144, "seek": 287362, "start": 2898.74, "end": 2900.2999999999997, "text": " domain, at least at the time they were pursuing it.", "tokens": [51620, 9274, 11, 412, 1935, 412, 264, 565, 436, 645, 20222, 309, 13, 51698], "temperature": 0.0, "avg_logprob": -0.22141678388728653, "compression_ratio": 1.754325259515571, "no_speech_prob": 0.00164612487424165}, {"id": 1145, "seek": 290030, "start": 2901.3, "end": 2904.2200000000003, "text": " I mean, you guys have put out different things like Robo Transformer and other things.", "tokens": [50414, 286, 914, 11, 291, 1074, 362, 829, 484, 819, 721, 411, 5424, 78, 27938, 260, 293, 661, 721, 13, 50560], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1146, "seek": 290030, "start": 2904.42, "end": 2907.78, "text": " How do you think that's still a bottleneck for robotics progress or will we", "tokens": [50570, 1012, 360, 291, 519, 300, 311, 920, 257, 44641, 547, 337, 34145, 4205, 420, 486, 321, 50738], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1147, "seek": 290030, "start": 2907.78, "end": 2910.7000000000003, "text": " see progress in the world of atoms as well as the world of bits?", "tokens": [50738, 536, 4205, 294, 264, 1002, 295, 16871, 382, 731, 382, 264, 1002, 295, 9239, 30, 50884], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1148, "seek": 290030, "start": 2910.7000000000003, "end": 2915.0600000000004, "text": " We're very excited about our progress with things like GATO and RT2, you know,", "tokens": [50884, 492, 434, 588, 2919, 466, 527, 4205, 365, 721, 411, 460, 2218, 46, 293, 21797, 17, 11, 291, 458, 11, 51102], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1149, "seek": 290030, "start": 2915.0600000000004, "end": 2920.1800000000003, "text": " Robotic Transformer, and we actually think so we've always liked robotics", "tokens": [51102, 5424, 9411, 27938, 260, 11, 293, 321, 767, 519, 370, 321, 600, 1009, 4501, 34145, 51358], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1150, "seek": 290030, "start": 2920.1800000000003, "end": 2924.42, "text": " and we've had, you know, amazing research and now we still have that going now", "tokens": [51358, 293, 321, 600, 632, 11, 291, 458, 11, 2243, 2132, 293, 586, 321, 920, 362, 300, 516, 586, 51570], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1151, "seek": 290030, "start": 2924.6200000000003, "end": 2928.94, "text": " because we like the fact that it's a data poor regime because that pushes us", "tokens": [51580, 570, 321, 411, 264, 1186, 300, 309, 311, 257, 1412, 4716, 13120, 570, 300, 21020, 505, 51796], "temperature": 0.0, "avg_logprob": -0.2750550729257089, "compression_ratio": 1.7866666666666666, "no_speech_prob": 0.004889567382633686}, {"id": 1152, "seek": 292894, "start": 2929.14, "end": 2931.98, "text": " on some very interesting research directions that we think are going to be", "tokens": [50374, 322, 512, 588, 1880, 2132, 11095, 300, 321, 519, 366, 516, 281, 312, 50516], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1153, "seek": 292894, "start": 2932.18, "end": 2936.1, "text": " useful anyway, like sampling efficiency and data efficiency in general and transfer", "tokens": [50526, 4420, 4033, 11, 411, 21179, 10493, 293, 1412, 10493, 294, 2674, 293, 5003, 50722], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1154, "seek": 292894, "start": 2936.3, "end": 2939.7000000000003, "text": " learning, learning from simulation, transferring that to reality.", "tokens": [50732, 2539, 11, 2539, 490, 16575, 11, 31437, 300, 281, 4103, 13, 50902], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1155, "seek": 292894, "start": 2939.9, "end": 2943.86, "text": " All of these very, you know, similar to real, all of these very interesting", "tokens": [50912, 1057, 295, 613, 588, 11, 291, 458, 11, 2531, 281, 957, 11, 439, 295, 613, 588, 1880, 51110], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1156, "seek": 292894, "start": 2944.06, "end": 2947.62, "text": " actually general challenges that we would like to solve.", "tokens": [51120, 767, 2674, 4759, 300, 321, 576, 411, 281, 5039, 13, 51298], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1157, "seek": 292894, "start": 2947.82, "end": 2949.2200000000003, "text": " So the control problem.", "tokens": [51308, 407, 264, 1969, 1154, 13, 51378], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1158, "seek": 292894, "start": 2949.42, "end": 2951.42, "text": " So we've always pushed hard on that.", "tokens": [51388, 407, 321, 600, 1009, 9152, 1152, 322, 300, 13, 51488], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1159, "seek": 292894, "start": 2951.62, "end": 2955.58, "text": " And actually, I think so Ilya is right that that is more challenging", "tokens": [51498, 400, 767, 11, 286, 519, 370, 286, 45106, 307, 558, 300, 300, 307, 544, 7595, 51696], "temperature": 0.0, "avg_logprob": -0.2068824596233196, "compression_ratio": 1.7970479704797049, "no_speech_prob": 0.004364007152616978}, {"id": 1160, "seek": 295558, "start": 2955.58, "end": 2959.8199999999997, "text": " because of the data problem, but it's also I think we're starting to see the", "tokens": [50364, 570, 295, 264, 1412, 1154, 11, 457, 309, 311, 611, 286, 519, 321, 434, 2891, 281, 536, 264, 50576], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1161, "seek": 295558, "start": 2960.02, "end": 2965.5, "text": " beginnings of these large models being transferable to the robotics regime,", "tokens": [50586, 37281, 295, 613, 2416, 5245, 885, 5003, 712, 281, 264, 34145, 13120, 11, 50860], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1162, "seek": 295558, "start": 2965.7, "end": 2968.34, "text": " learning in the general domain, language domain and other things.", "tokens": [50870, 2539, 294, 264, 2674, 9274, 11, 2856, 9274, 293, 661, 721, 13, 51002], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1163, "seek": 295558, "start": 2968.54, "end": 2972.58, "text": " And then just treating tokens like GATO as any type of token, you know,", "tokens": [51012, 400, 550, 445, 15083, 22667, 411, 460, 2218, 46, 382, 604, 2010, 295, 14862, 11, 291, 458, 11, 51214], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1164, "seek": 295558, "start": 2972.58, "end": 2975.9, "text": " the token could be an action, it could be a word, it could be part of an image,", "tokens": [51214, 264, 14862, 727, 312, 364, 3069, 11, 309, 727, 312, 257, 1349, 11, 309, 727, 312, 644, 295, 364, 3256, 11, 51380], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1165, "seek": 295558, "start": 2975.9, "end": 2977.1, "text": " a pixel or whatever it is.", "tokens": [51380, 257, 19261, 420, 2035, 309, 307, 13, 51440], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1166, "seek": 295558, "start": 2977.2999999999997, "end": 2979.66, "text": " And that's what I think true multimodality is.", "tokens": [51450, 400, 300, 311, 437, 286, 519, 2074, 32972, 378, 1860, 307, 13, 51568], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1167, "seek": 295558, "start": 2979.86, "end": 2984.14, "text": " And to begin with, it's harder to train a system like that than a straightforward", "tokens": [51578, 400, 281, 1841, 365, 11, 309, 311, 6081, 281, 3847, 257, 1185, 411, 300, 813, 257, 15325, 51792], "temperature": 0.0, "avg_logprob": -0.14841290081248565, "compression_ratio": 1.7651006711409396, "no_speech_prob": 0.0035729368682950735}, {"id": 1168, "seek": 298414, "start": 2984.2599999999998, "end": 2986.3399999999997, "text": " text language system.", "tokens": [50370, 2487, 2856, 1185, 13, 50474], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1169, "seek": 298414, "start": 2986.54, "end": 2988.8599999999997, "text": " But actually, you know, going back to our", "tokens": [50484, 583, 767, 11, 291, 458, 11, 516, 646, 281, 527, 50600], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1170, "seek": 298414, "start": 2989.06, "end": 2993.8599999999997, "text": " early conversation of transfer learning, you start seeing that a true multimodal", "tokens": [50610, 2440, 3761, 295, 5003, 2539, 11, 291, 722, 2577, 300, 257, 2074, 32972, 378, 304, 50850], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1171, "seek": 298414, "start": 2994.06, "end": 2998.2599999999998, "text": " system, the other modalities benefit some different modality.", "tokens": [50860, 1185, 11, 264, 661, 1072, 16110, 5121, 512, 819, 1072, 1860, 13, 51070], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1172, "seek": 298414, "start": 2998.2599999999998, "end": 3002.02, "text": " So you get better at language because you now understand a little bit about video.", "tokens": [51070, 407, 291, 483, 1101, 412, 2856, 570, 291, 586, 1223, 257, 707, 857, 466, 960, 13, 51258], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1173, "seek": 298414, "start": 3002.22, "end": 3007.3399999999997, "text": " So I do think it's harder to get going, but actually ultimately", "tokens": [51268, 407, 286, 360, 519, 309, 311, 6081, 281, 483, 516, 11, 457, 767, 6284, 51524], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1174, "seek": 298414, "start": 3007.54, "end": 3010.22, "text": " we'll have a more general, more capable system like that.", "tokens": [51534, 321, 603, 362, 257, 544, 2674, 11, 544, 8189, 1185, 411, 300, 13, 51668], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1175, "seek": 298414, "start": 3010.42, "end": 3011.46, "text": " Whatever happened to GATO?", "tokens": [51678, 8541, 2011, 281, 460, 2218, 46, 30, 51730], "temperature": 0.0, "avg_logprob": -0.18165780863630662, "compression_ratio": 1.6282527881040891, "no_speech_prob": 0.0225592702627182}, {"id": 1176, "seek": 301146, "start": 3011.7, "end": 3014.82, "text": " That was super fascinating that you could have like play games and also do like", "tokens": [50376, 663, 390, 1687, 10343, 300, 291, 727, 362, 411, 862, 2813, 293, 611, 360, 411, 50532], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1177, "seek": 301146, "start": 3015.02, "end": 3016.18, "text": " video and also do text.", "tokens": [50542, 960, 293, 611, 360, 2487, 13, 50600], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1178, "seek": 301146, "start": 3016.38, "end": 3019.78, "text": " We're still working on those kinds of systems, but you can imagine we're just", "tokens": [50610, 492, 434, 920, 1364, 322, 729, 3685, 295, 3652, 11, 457, 291, 393, 3811, 321, 434, 445, 50780], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1179, "seek": 301146, "start": 3019.98, "end": 3025.06, "text": " trying to, those ideas we're trying to build into our future generations of Gemini.", "tokens": [50790, 1382, 281, 11, 729, 3487, 321, 434, 1382, 281, 1322, 666, 527, 2027, 10593, 295, 22894, 3812, 13, 51044], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1180, "seek": 301146, "start": 3025.26, "end": 3030.1, "text": " You know, to be able to do all of those things and robotics transformers and things like", "tokens": [51054, 509, 458, 11, 281, 312, 1075, 281, 360, 439, 295, 729, 721, 293, 34145, 4088, 433, 293, 721, 411, 51296], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1181, "seek": 301146, "start": 3030.3, "end": 3033.62, "text": " that, you can think of them as sort of follow-ups to that.", "tokens": [51306, 300, 11, 291, 393, 519, 295, 552, 382, 1333, 295, 1524, 12, 7528, 281, 300, 13, 51472], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1182, "seek": 301146, "start": 3033.82, "end": 3037.18, "text": " Well, we see asymmetric progress towards the domains in which the self-play", "tokens": [51482, 1042, 11, 321, 536, 37277, 17475, 4205, 3030, 264, 25514, 294, 597, 264, 2698, 12, 2858, 51650], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1183, "seek": 301146, "start": 3037.18, "end": 3039.66, "text": " kinds of things we're talking about will be especially powerful.", "tokens": [51650, 3685, 295, 721, 321, 434, 1417, 466, 486, 312, 2318, 4005, 13, 51774], "temperature": 0.0, "avg_logprob": -0.22650445812810077, "compression_ratio": 1.7699680511182108, "no_speech_prob": 0.0425092950463295}, {"id": 1184, "seek": 303966, "start": 3039.66, "end": 3042.74, "text": " So math and code, you know, obviously recently you have these papers out about", "tokens": [50364, 407, 5221, 293, 3089, 11, 291, 458, 11, 2745, 3938, 291, 362, 613, 10577, 484, 466, 50518], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1185, "seek": 303966, "start": 3042.94, "end": 3047.7799999999997, "text": " this or yeah, you can use these things to do really cool novel things.", "tokens": [50528, 341, 420, 1338, 11, 291, 393, 764, 613, 721, 281, 360, 534, 1627, 7613, 721, 13, 50770], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1186, "seek": 303966, "start": 3047.98, "end": 3049.8599999999997, "text": " Will they just be like superhuman coders?", "tokens": [50780, 3099, 436, 445, 312, 411, 1687, 18796, 17656, 433, 30, 50874], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1187, "seek": 303966, "start": 3049.8599999999997, "end": 3052.14, "text": " But like in other ways, they might be still worse than humans?", "tokens": [50874, 583, 411, 294, 661, 2098, 11, 436, 1062, 312, 920, 5324, 813, 6255, 30, 50988], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1188, "seek": 303966, "start": 3052.14, "end": 3052.8199999999997, "text": " Or how do you think about that?", "tokens": [50988, 1610, 577, 360, 291, 519, 466, 300, 30, 51022], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1189, "seek": 303966, "start": 3053.02, "end": 3058.94, "text": " So look, I think that we're making great progress with math and things like", "tokens": [51032, 407, 574, 11, 286, 519, 300, 321, 434, 1455, 869, 4205, 365, 5221, 293, 721, 411, 51328], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1190, "seek": 303966, "start": 3059.14, "end": 3063.66, "text": " theorem proving and coding, but it's still interesting.", "tokens": [51338, 20904, 27221, 293, 17720, 11, 457, 309, 311, 920, 1880, 13, 51564], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1191, "seek": 303966, "start": 3063.8599999999997, "end": 3068.54, "text": " If one looks at, I mean, creativity in general and scientific endeavor in general,", "tokens": [51574, 759, 472, 1542, 412, 11, 286, 914, 11, 12915, 294, 2674, 293, 8134, 34975, 294, 2674, 11, 51808], "temperature": 0.0, "avg_logprob": -0.23438288673521981, "compression_ratio": 1.7040816326530612, "no_speech_prob": 0.0007861690246500075}, {"id": 1192, "seek": 306854, "start": 3068.66, "end": 3072.2599999999998, "text": " I think we're getting to the stage where our systems could help the best human", "tokens": [50370, 286, 519, 321, 434, 1242, 281, 264, 3233, 689, 527, 3652, 727, 854, 264, 1151, 1952, 50550], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1193, "seek": 306854, "start": 3072.46, "end": 3076.2599999999998, "text": " scientists make their breakthroughs quicker, like almost triage the search space", "tokens": [50560, 7708, 652, 641, 22397, 82, 16255, 11, 411, 1920, 1376, 609, 264, 3164, 1901, 50750], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1194, "seek": 306854, "start": 3076.46, "end": 3081.38, "text": " in some ways or perhaps find a solution like AlphaFold does with a protein structure.", "tokens": [50760, 294, 512, 2098, 420, 4317, 915, 257, 3827, 411, 20588, 37, 2641, 775, 365, 257, 7944, 3877, 13, 51006], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1195, "seek": 306854, "start": 3081.58, "end": 3085.66, "text": " But it can't, they're not at the level where they can create the hypothesis", "tokens": [51016, 583, 309, 393, 380, 11, 436, 434, 406, 412, 264, 1496, 689, 436, 393, 1884, 264, 17291, 51220], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1196, "seek": 306854, "start": 3085.86, "end": 3088.06, "text": " themselves or ask the right question.", "tokens": [51230, 2969, 420, 1029, 264, 558, 1168, 13, 51340], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1197, "seek": 306854, "start": 3088.2599999999998, "end": 3092.38, "text": " And as any top scientists will tell you, that that's the hardest part of science", "tokens": [51350, 400, 382, 604, 1192, 7708, 486, 980, 291, 11, 300, 300, 311, 264, 13158, 644, 295, 3497, 51556], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1198, "seek": 306854, "start": 3092.58, "end": 3096.38, "text": " is actually asking the right question, boiling down that space to like, what's", "tokens": [51566, 307, 767, 3365, 264, 558, 1168, 11, 16208, 760, 300, 1901, 281, 411, 11, 437, 311, 51756], "temperature": 0.0, "avg_logprob": -0.17488091839246514, "compression_ratio": 1.7128712871287128, "no_speech_prob": 0.0021267328411340714}, {"id": 1199, "seek": 309638, "start": 3096.42, "end": 3099.62, "text": " the critical question we should go after the critical problem and then", "tokens": [50366, 264, 4924, 1168, 321, 820, 352, 934, 264, 4924, 1154, 293, 550, 50526], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1200, "seek": 309638, "start": 3099.82, "end": 3102.1, "text": " formulating that problem in the right way to attack it.", "tokens": [50536, 1254, 12162, 300, 1154, 294, 264, 558, 636, 281, 2690, 309, 13, 50650], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1201, "seek": 309638, "start": 3102.3, "end": 3106.7400000000002, "text": " And that's not something our systems will we have really have any idea how our", "tokens": [50660, 400, 300, 311, 406, 746, 527, 3652, 486, 321, 362, 534, 362, 604, 1558, 577, 527, 50882], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1202, "seek": 309638, "start": 3106.94, "end": 3109.62, "text": " systems could do, but they can.", "tokens": [50892, 3652, 727, 360, 11, 457, 436, 393, 13, 51026], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1203, "seek": 309638, "start": 3109.82, "end": 3114.9, "text": " They are suitable for searching large combinatorial spaces if one can specify", "tokens": [51036, 814, 366, 12873, 337, 10808, 2416, 2512, 31927, 831, 7673, 498, 472, 393, 16500, 51290], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1204, "seek": 309638, "start": 3115.1, "end": 3117.58, "text": " the problem in that way with a clear objective function.", "tokens": [51300, 264, 1154, 294, 300, 636, 365, 257, 1850, 10024, 2445, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1205, "seek": 309638, "start": 3117.78, "end": 3121.5, "text": " So that's very useful for already many of the problems we deal with today,", "tokens": [51434, 407, 300, 311, 588, 4420, 337, 1217, 867, 295, 264, 2740, 321, 2028, 365, 965, 11, 51620], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1206, "seek": 309638, "start": 3121.7000000000003, "end": 3125.1400000000003, "text": " but not the most high level creative problems.", "tokens": [51630, 457, 406, 264, 881, 1090, 1496, 5880, 2740, 13, 51802], "temperature": 0.0, "avg_logprob": -0.1731218305127374, "compression_ratio": 1.7706093189964158, "no_speech_prob": 0.004739353433251381}, {"id": 1207, "seek": 312514, "start": 3125.2999999999997, "end": 3129.2599999999998, "text": " Right, so deep mind obviously has published all kinds of interesting stuff", "tokens": [50372, 1779, 11, 370, 2452, 1575, 2745, 575, 6572, 439, 3685, 295, 1880, 1507, 50570], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1208, "seek": 312514, "start": 3129.46, "end": 3132.02, "text": " and, you know, speeding up science in different areas.", "tokens": [50580, 293, 11, 291, 458, 11, 35593, 493, 3497, 294, 819, 3179, 13, 50708], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1209, "seek": 312514, "start": 3132.22, "end": 3135.46, "text": " How do you think about that in the context of if you think AGI is going to happen", "tokens": [50718, 1012, 360, 291, 519, 466, 300, 294, 264, 4319, 295, 498, 291, 519, 316, 26252, 307, 516, 281, 1051, 50880], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1210, "seek": 312514, "start": 3135.66, "end": 3139.2999999999997, "text": " in the next 10, 20 years, why not just wait for the AGI to do it for you?", "tokens": [50890, 294, 264, 958, 1266, 11, 945, 924, 11, 983, 406, 445, 1699, 337, 264, 316, 26252, 281, 360, 309, 337, 291, 30, 51072], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1211, "seek": 312514, "start": 3139.5, "end": 3141.5, "text": " Why build these domain specific solutions?", "tokens": [51082, 1545, 1322, 613, 9274, 2685, 6547, 30, 51182], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1212, "seek": 312514, "start": 3141.7, "end": 3143.58, "text": " Well, I think", "tokens": [51192, 1042, 11, 286, 519, 51286], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1213, "seek": 312514, "start": 3143.7799999999997, "end": 3145.74, "text": " we don't know how long AGI is going to be.", "tokens": [51296, 321, 500, 380, 458, 577, 938, 316, 26252, 307, 516, 281, 312, 13, 51394], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1214, "seek": 312514, "start": 3145.94, "end": 3151.66, "text": " And we always used to say, you know, back even when we started DeepMind that", "tokens": [51404, 400, 321, 1009, 1143, 281, 584, 11, 291, 458, 11, 646, 754, 562, 321, 1409, 14895, 44, 471, 300, 51690], "temperature": 0.0, "avg_logprob": -0.2580797691044845, "compression_ratio": 1.5986159169550174, "no_speech_prob": 0.0011659500887617469}, {"id": 1215, "seek": 315166, "start": 3151.8999999999996, "end": 3157.2999999999997, "text": " we don't have to wait for AGI in order to bring incredible benefits to the world.", "tokens": [50376, 321, 500, 380, 362, 281, 1699, 337, 316, 26252, 294, 1668, 281, 1565, 4651, 5311, 281, 264, 1002, 13, 50646], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1216, "seek": 315166, "start": 3157.5, "end": 3164.14, "text": " And especially, you know, my personal passion has been AI for science and health.", "tokens": [50656, 400, 2318, 11, 291, 458, 11, 452, 2973, 5418, 575, 668, 7318, 337, 3497, 293, 1585, 13, 50988], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1217, "seek": 315166, "start": 3164.3399999999997, "end": 3167.94, "text": " And you can see that with things like AlphaFold and all of our various", "tokens": [50998, 400, 291, 393, 536, 300, 365, 721, 411, 20588, 37, 2641, 293, 439, 295, 527, 3683, 51178], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1218, "seek": 315166, "start": 3167.94, "end": 3170.94, "text": " nature papers of different domains and material science work and so on.", "tokens": [51178, 3687, 10577, 295, 819, 25514, 293, 2527, 3497, 589, 293, 370, 322, 13, 51328], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1219, "seek": 315166, "start": 3170.94, "end": 3174.46, "text": " I think there's lots of exciting directions and also impact in the world", "tokens": [51328, 286, 519, 456, 311, 3195, 295, 4670, 11095, 293, 611, 2712, 294, 264, 1002, 51504], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1220, "seek": 315166, "start": 3174.46, "end": 3175.2999999999997, "text": " through products, too.", "tokens": [51504, 807, 3383, 11, 886, 13, 51546], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1221, "seek": 315166, "start": 3175.5, "end": 3179.1, "text": " I think it's very exciting and a huge opportunity, a unique opportunity we have", "tokens": [51556, 286, 519, 309, 311, 588, 4670, 293, 257, 2603, 2650, 11, 257, 3845, 2650, 321, 362, 51736], "temperature": 0.0, "avg_logprob": -0.17374484292392073, "compression_ratio": 1.6794425087108014, "no_speech_prob": 0.0036810210440307856}, {"id": 1222, "seek": 317910, "start": 3179.14, "end": 3185.98, "text": " as part of Google, of, you know, they got dozens of billion user products, right?", "tokens": [50366, 382, 644, 295, 3329, 11, 295, 11, 291, 458, 11, 436, 658, 18431, 295, 5218, 4195, 3383, 11, 558, 30, 50708], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1223, "seek": 317910, "start": 3186.18, "end": 3190.22, "text": " That we can immediately ship our advances into and then", "tokens": [50718, 663, 321, 393, 4258, 5374, 527, 25297, 666, 293, 550, 50920], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1224, "seek": 317910, "start": 3190.42, "end": 3194.74, "text": " billions of people can, you know, improve their daily lives, right?", "tokens": [50930, 17375, 295, 561, 393, 11, 291, 458, 11, 3470, 641, 5212, 2909, 11, 558, 30, 51146], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1225, "seek": 317910, "start": 3194.74, "end": 3197.3399999999997, "text": " And enriches their daily lives and enhances their daily lives.", "tokens": [51146, 400, 18849, 279, 641, 5212, 2909, 293, 46628, 641, 5212, 2909, 13, 51276], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1226, "seek": 317910, "start": 3197.54, "end": 3201.5, "text": " So I think it's a fantastic opportunity for impact on all those fronts.", "tokens": [51286, 407, 286, 519, 309, 311, 257, 5456, 2650, 337, 2712, 322, 439, 729, 40426, 13, 51484], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1227, "seek": 317910, "start": 3201.7, "end": 3206.02, "text": " And I think the other reason from a point of view of AGI specifically is", "tokens": [51494, 400, 286, 519, 264, 661, 1778, 490, 257, 935, 295, 1910, 295, 316, 26252, 4682, 307, 51710], "temperature": 0.0, "avg_logprob": -0.198882682650697, "compression_ratio": 1.6857142857142857, "no_speech_prob": 0.006511999759823084}, {"id": 1228, "seek": 320602, "start": 3206.22, "end": 3209.2599999999998, "text": " that it battle tests your ideas, right?", "tokens": [50374, 300, 309, 4635, 6921, 428, 3487, 11, 558, 30, 50526], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1229, "seek": 320602, "start": 3209.46, "end": 3213.18, "text": " So you don't want to be in a sort of research bunker where you just,", "tokens": [50536, 407, 291, 500, 380, 528, 281, 312, 294, 257, 1333, 295, 2132, 39579, 689, 291, 445, 11, 50722], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1230, "seek": 320602, "start": 3213.38, "end": 3215.9, "text": " you know, theoretically are pushing things, some things forward.", "tokens": [50732, 291, 458, 11, 29400, 366, 7380, 721, 11, 512, 721, 2128, 13, 50858], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1231, "seek": 320602, "start": 3216.1, "end": 3220.62, "text": " But then actually your internal metrics start deviating from", "tokens": [50868, 583, 550, 767, 428, 6920, 16367, 722, 31219, 990, 490, 51094], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1232, "seek": 320602, "start": 3220.82, "end": 3223.42, "text": " real world things that people would care about, right?", "tokens": [51104, 957, 1002, 721, 300, 561, 576, 1127, 466, 11, 558, 30, 51234], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1233, "seek": 320602, "start": 3223.62, "end": 3224.82, "text": " Or real world impact.", "tokens": [51244, 1610, 957, 1002, 2712, 13, 51304], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1234, "seek": 320602, "start": 3225.02, "end": 3228.3, "text": " So you get a lot of feedback, direct feedback from these real world", "tokens": [51314, 407, 291, 483, 257, 688, 295, 5824, 11, 2047, 5824, 490, 613, 957, 1002, 51478], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1235, "seek": 320602, "start": 3228.5, "end": 3232.86, "text": " applications that then tells you whether your systems really are scaling or or", "tokens": [51488, 5821, 300, 550, 5112, 291, 1968, 428, 3652, 534, 366, 21589, 420, 420, 51706], "temperature": 0.0, "avg_logprob": -0.17167586580328986, "compression_ratio": 1.7218045112781954, "no_speech_prob": 0.023038147017359734}, {"id": 1236, "seek": 323286, "start": 3232.9, "end": 3236.9, "text": " actually is, you know, do we need to be more data efficient or sample efficient", "tokens": [50366, 767, 307, 11, 291, 458, 11, 360, 321, 643, 281, 312, 544, 1412, 7148, 420, 6889, 7148, 50566], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1237, "seek": 323286, "start": 3237.1, "end": 3240.78, "text": " because most real world challenges require that, right?", "tokens": [50576, 570, 881, 957, 1002, 4759, 3651, 300, 11, 558, 30, 50760], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1238, "seek": 323286, "start": 3240.98, "end": 3245.46, "text": " And so it kind of keeps you honest and pushes you, you know, keep sort of", "tokens": [50770, 400, 370, 309, 733, 295, 5965, 291, 3245, 293, 21020, 291, 11, 291, 458, 11, 1066, 1333, 295, 50994], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1239, "seek": 323286, "start": 3245.6600000000003, "end": 3249.6600000000003, "text": " nudging and steering your research directions to make sure they're on the right path.", "tokens": [51004, 40045, 3249, 293, 14823, 428, 2132, 11095, 281, 652, 988, 436, 434, 322, 264, 558, 3100, 13, 51204], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1240, "seek": 323286, "start": 3249.6600000000003, "end": 3251.06, "text": " So I think it's fantastic.", "tokens": [51204, 407, 286, 519, 309, 311, 5456, 13, 51274], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1241, "seek": 323286, "start": 3251.06, "end": 3255.06, "text": " And of course, the world benefits from that society benefits from that on the way.", "tokens": [51274, 400, 295, 1164, 11, 264, 1002, 5311, 490, 300, 4086, 5311, 490, 300, 322, 264, 636, 13, 51474], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1242, "seek": 323286, "start": 3255.26, "end": 3258.1400000000003, "text": " Many, many, maybe many, many years before AGI arrives.", "tokens": [51484, 5126, 11, 867, 11, 1310, 867, 11, 867, 924, 949, 316, 26252, 20116, 13, 51628], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1243, "seek": 323286, "start": 3258.34, "end": 3262.1, "text": " Yeah. Well, the development of Gemini is super interesting because it comes right", "tokens": [51638, 865, 13, 1042, 11, 264, 3250, 295, 22894, 3812, 307, 1687, 1880, 570, 309, 1487, 558, 51826], "temperature": 0.0, "avg_logprob": -0.16606083200938665, "compression_ratio": 1.6990595611285266, "no_speech_prob": 0.002483522752299905}, {"id": 1244, "seek": 326210, "start": 3262.14, "end": 3266.38, "text": " at the heels of merging these different organizations, Brain and DeepMind.", "tokens": [50366, 412, 264, 19502, 295, 44559, 613, 819, 6150, 11, 29783, 293, 14895, 44, 471, 13, 50578], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1245, "seek": 326210, "start": 3266.58, "end": 3268.54, "text": " Yeah, I'm curious, what have been the challenges there?", "tokens": [50588, 865, 11, 286, 478, 6369, 11, 437, 362, 668, 264, 4759, 456, 30, 50686], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1246, "seek": 326210, "start": 3268.54, "end": 3270.18, "text": " What have been the synergies?", "tokens": [50686, 708, 362, 668, 264, 33781, 25480, 30, 50768], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1247, "seek": 326210, "start": 3270.38, "end": 3272.74, "text": " And it's been successful in the sense that you have the best model in the world now.", "tokens": [50778, 400, 309, 311, 668, 4406, 294, 264, 2020, 300, 291, 362, 264, 1151, 2316, 294, 264, 1002, 586, 13, 50896], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1248, "seek": 326210, "start": 3272.94, "end": 3276.18, "text": " Well, look, it's been fantastic actually over the last year.", "tokens": [50906, 1042, 11, 574, 11, 309, 311, 668, 5456, 767, 670, 264, 1036, 1064, 13, 51068], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1249, "seek": 326210, "start": 3276.18, "end": 3280.3399999999997, "text": " Of course, it's been challenging to do that, like any big integration coming together.", "tokens": [51068, 2720, 1164, 11, 309, 311, 668, 7595, 281, 360, 300, 11, 411, 604, 955, 10980, 1348, 1214, 13, 51276], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1250, "seek": 326210, "start": 3280.54, "end": 3284.5, "text": " But you're talking about two, you know, world-class organizations,", "tokens": [51286, 583, 291, 434, 1417, 466, 732, 11, 291, 458, 11, 1002, 12, 11665, 6150, 11, 51484], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1251, "seek": 326210, "start": 3284.7, "end": 3288.74, "text": " long storied histories of inventing many, many important things, you know,", "tokens": [51494, 938, 5967, 1091, 30631, 295, 7962, 278, 867, 11, 867, 1021, 721, 11, 291, 458, 11, 51696], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1252, "seek": 326210, "start": 3288.74, "end": 3290.62, "text": " from deep reinforcement learning to transformers.", "tokens": [51696, 490, 2452, 29280, 2539, 281, 4088, 433, 13, 51790], "temperature": 0.0, "avg_logprob": -0.23105079387796337, "compression_ratio": 1.7410714285714286, "no_speech_prob": 0.0024501297157257795}, {"id": 1253, "seek": 329062, "start": 3290.74, "end": 3294.18, "text": " And so it's very exciting, actually, pooling all of that together and", "tokens": [50370, 400, 370, 309, 311, 588, 4670, 11, 767, 11, 7005, 278, 439, 295, 300, 1214, 293, 50542], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1254, "seek": 329062, "start": 3294.38, "end": 3295.98, "text": " and collaborating much more closely.", "tokens": [50552, 293, 30188, 709, 544, 8185, 13, 50632], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1255, "seek": 329062, "start": 3296.18, "end": 3300.06, "text": " We always used to be collaborating, but more on a on a on a, you know,", "tokens": [50642, 492, 1009, 1143, 281, 312, 30188, 11, 457, 544, 322, 257, 322, 257, 322, 257, 11, 291, 458, 11, 50836], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1256, "seek": 329062, "start": 3300.2599999999998, "end": 3305.18, "text": " sort of project by project basis versus a much deeper, broader collaboration", "tokens": [50846, 1333, 295, 1716, 538, 1716, 5143, 5717, 257, 709, 7731, 11, 13227, 9363, 51092], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1257, "seek": 329062, "start": 3305.38, "end": 3310.1, "text": " like we have now in Gemini is the first fruit of of that collaboration,", "tokens": [51102, 411, 321, 362, 586, 294, 22894, 3812, 307, 264, 700, 6773, 295, 295, 300, 9363, 11, 51338], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1258, "seek": 329062, "start": 3310.2999999999997, "end": 3313.06, "text": " including the name Gemini actually, you know, implying twins.", "tokens": [51348, 3009, 264, 1315, 22894, 3812, 767, 11, 291, 458, 11, 704, 7310, 22555, 13, 51486], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1259, "seek": 329062, "start": 3313.2599999999998, "end": 3316.22, "text": " And and of course, a lot of other things are made more efficient,", "tokens": [51496, 400, 293, 295, 1164, 11, 257, 688, 295, 661, 721, 366, 1027, 544, 7148, 11, 51644], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1260, "seek": 329062, "start": 3316.42, "end": 3319.7799999999997, "text": " like pooling compute resources together and ideas and engineering,", "tokens": [51654, 411, 7005, 278, 14722, 3593, 1214, 293, 3487, 293, 7043, 11, 51822], "temperature": 0.0, "avg_logprob": -0.206905797123909, "compression_ratio": 1.8409893992932862, "no_speech_prob": 0.0027408814057707787}, {"id": 1261, "seek": 331978, "start": 3320.02, "end": 3324.5, "text": " which I think at the stage we're at now, where there's huge amounts of world-class", "tokens": [50376, 597, 286, 519, 412, 264, 3233, 321, 434, 412, 586, 11, 689, 456, 311, 2603, 11663, 295, 1002, 12, 11665, 50600], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1262, "seek": 331978, "start": 3324.5, "end": 3327.6200000000003, "text": " engineering that has to go on to build the frontier systems.", "tokens": [50600, 7043, 300, 575, 281, 352, 322, 281, 1322, 264, 35853, 3652, 13, 50756], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1263, "seek": 331978, "start": 3327.82, "end": 3330.78, "text": " I think it makes sense to to coordinate that more closely.", "tokens": [50766, 286, 519, 309, 1669, 2020, 281, 281, 15670, 300, 544, 8185, 13, 50914], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1264, "seek": 331978, "start": 3330.78, "end": 3334.7400000000002, "text": " Yeah. So I mean, you and Shane started DeepMind partly because you were concerned", "tokens": [50914, 865, 13, 407, 286, 914, 11, 291, 293, 25865, 1409, 14895, 44, 471, 17031, 570, 291, 645, 5922, 51112], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1265, "seek": 331978, "start": 3334.94, "end": 3338.5400000000004, "text": " about safety and you saw AGI coming as like a live possibility.", "tokens": [51122, 466, 4514, 293, 291, 1866, 316, 26252, 1348, 382, 411, 257, 1621, 7959, 13, 51302], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1266, "seek": 331978, "start": 3338.7400000000002, "end": 3342.82, "text": " Do you do you think the people who were formerly part of brain, the half of Google", "tokens": [51312, 1144, 291, 360, 291, 519, 264, 561, 567, 645, 34777, 644, 295, 3567, 11, 264, 1922, 295, 3329, 51516], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1267, "seek": 331978, "start": 3342.82, "end": 3345.2200000000003, "text": " DeepMind now, do they do you think they approach it in the same way?", "tokens": [51516, 14895, 44, 471, 586, 11, 360, 436, 360, 291, 519, 436, 3109, 309, 294, 264, 912, 636, 30, 51636], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1268, "seek": 331978, "start": 3345.2200000000003, "end": 3347.26, "text": " Have there been cultural differences there in terms of that question?", "tokens": [51636, 3560, 456, 668, 6988, 7300, 456, 294, 2115, 295, 300, 1168, 30, 51738], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1269, "seek": 331978, "start": 3347.3, "end": 3348.6200000000003, "text": " Yeah, no, I think overrun.", "tokens": [51740, 865, 11, 572, 11, 286, 519, 670, 12997, 13, 51806], "temperature": 0.0, "avg_logprob": -0.21447010912926368, "compression_ratio": 1.6912181303116147, "no_speech_prob": 0.0024244191590696573}, {"id": 1270, "seek": 334862, "start": 3348.66, "end": 3352.1, "text": " And this is why, you know, I think one of the reasons we joined forces with Google", "tokens": [50366, 400, 341, 307, 983, 11, 291, 458, 11, 286, 519, 472, 295, 264, 4112, 321, 6869, 5874, 365, 3329, 50538], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1271, "seek": 334862, "start": 3352.2999999999997, "end": 3356.8599999999997, "text": " back in 2014 was I think the entirety of Google and Alphabet, not just brain", "tokens": [50548, 646, 294, 8227, 390, 286, 519, 264, 31557, 295, 3329, 293, 967, 20890, 11, 406, 445, 3567, 50776], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1272, "seek": 334862, "start": 3356.8599999999997, "end": 3360.3399999999997, "text": " and DeepMind, take these questions very seriously of responsibility.", "tokens": [50776, 293, 14895, 44, 471, 11, 747, 613, 1651, 588, 6638, 295, 6357, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1273, "seek": 334862, "start": 3360.3399999999997, "end": 3364.5, "text": " And, you know, I kind of mantra is to try and be bold and responsible with these systems.", "tokens": [50950, 400, 11, 291, 458, 11, 286, 733, 295, 32094, 307, 281, 853, 293, 312, 11928, 293, 6250, 365, 613, 3652, 13, 51158], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1274, "seek": 334862, "start": 3364.7, "end": 3368.5, "text": " So, you know, I would I would classify as I'm obviously a huge techno optimist,", "tokens": [51168, 407, 11, 291, 458, 11, 286, 576, 286, 576, 33872, 382, 286, 478, 2745, 257, 2603, 36728, 5028, 468, 11, 51358], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1275, "seek": 334862, "start": 3368.7, "end": 3372.8599999999997, "text": " but I want us to be cautious with that, given the transformative power of what", "tokens": [51368, 457, 286, 528, 505, 281, 312, 25278, 365, 300, 11, 2212, 264, 36070, 1347, 295, 437, 51576], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1276, "seek": 334862, "start": 3373.06, "end": 3375.8599999999997, "text": " we're bringing, bringing into the world, you know, collectively.", "tokens": [51586, 321, 434, 5062, 11, 5062, 666, 264, 1002, 11, 291, 458, 11, 24341, 13, 51726], "temperature": 0.0, "avg_logprob": -0.1868444330552045, "compression_ratio": 1.7097791798107256, "no_speech_prob": 0.0010738919954746962}, {"id": 1277, "seek": 337586, "start": 3375.98, "end": 3379.94, "text": " And I think it's important, you know, I think it's going to be one of the most", "tokens": [50370, 400, 286, 519, 309, 311, 1021, 11, 291, 458, 11, 286, 519, 309, 311, 516, 281, 312, 472, 295, 264, 881, 50568], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1278, "seek": 337586, "start": 3380.1400000000003, "end": 3382.38, "text": " important technologies humanity will ever invent.", "tokens": [50578, 1021, 7943, 10243, 486, 1562, 7962, 13, 50690], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1279, "seek": 337586, "start": 3382.58, "end": 3386.3, "text": " So we've got to put, you know, all our efforts into getting this right and be", "tokens": [50700, 407, 321, 600, 658, 281, 829, 11, 291, 458, 11, 439, 527, 6484, 666, 1242, 341, 558, 293, 312, 50886], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1280, "seek": 337586, "start": 3386.5, "end": 3391.46, "text": " thoughtful and sort of also humble about what we know and don't know about", "tokens": [50896, 21566, 293, 1333, 295, 611, 16735, 466, 437, 321, 458, 293, 500, 380, 458, 466, 51144], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1281, "seek": 337586, "start": 3391.6600000000003, "end": 3393.98, "text": " the systems that are coming and the uncertainties around that.", "tokens": [51154, 264, 3652, 300, 366, 1348, 293, 264, 11308, 6097, 926, 300, 13, 51270], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1282, "seek": 337586, "start": 3394.1800000000003, "end": 3397.78, "text": " And in my view, the only the only sensible approach when you have huge", "tokens": [51280, 400, 294, 452, 1910, 11, 264, 787, 264, 787, 25380, 3109, 562, 291, 362, 2603, 51460], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1283, "seek": 337586, "start": 3397.98, "end": 3402.2200000000003, "text": " uncertainty is to be sort of cautiously optimistic and use the scientific method", "tokens": [51470, 15697, 307, 281, 312, 1333, 295, 21130, 8994, 19397, 293, 764, 264, 8134, 3170, 51682], "temperature": 0.0, "avg_logprob": -0.13771661389775636, "compression_ratio": 1.7714285714285714, "no_speech_prob": 0.003789234207943082}, {"id": 1284, "seek": 340222, "start": 3402.2599999999998, "end": 3405.7799999999997, "text": " to try and have as much foresight and understanding about what's coming down", "tokens": [50366, 281, 853, 293, 362, 382, 709, 2091, 28654, 293, 3701, 466, 437, 311, 1348, 760, 50542], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1285, "seek": 340222, "start": 3405.7799999999997, "end": 3408.2999999999997, "text": " the line and the consequences of that before it happens.", "tokens": [50542, 264, 1622, 293, 264, 10098, 295, 300, 949, 309, 2314, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1286, "seek": 340222, "start": 3408.5, "end": 3411.7799999999997, "text": " You know, you don't want to be live A, B testing out in the world with these", "tokens": [50678, 509, 458, 11, 291, 500, 380, 528, 281, 312, 1621, 316, 11, 363, 4997, 484, 294, 264, 1002, 365, 613, 50842], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1287, "seek": 340222, "start": 3411.98, "end": 3416.3799999999997, "text": " very consequential systems, because unintended consequences may be maybe quite severe.", "tokens": [50852, 588, 7242, 2549, 3652, 11, 570, 49902, 10098, 815, 312, 1310, 1596, 8922, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1288, "seek": 340222, "start": 3416.58, "end": 3421.8199999999997, "text": " So, you know, I want us to move away as a as a field from a sort of move fast", "tokens": [51082, 407, 11, 291, 458, 11, 286, 528, 505, 281, 1286, 1314, 382, 257, 382, 257, 2519, 490, 257, 1333, 295, 1286, 2370, 51344], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1289, "seek": 340222, "start": 3421.8199999999997, "end": 3425.06, "text": " and break things attitude, which is, you know, maybe serve the valley very well", "tokens": [51344, 293, 1821, 721, 10157, 11, 597, 307, 11, 291, 458, 11, 1310, 4596, 264, 17636, 588, 731, 51506], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1290, "seek": 340222, "start": 3425.2599999999998, "end": 3429.4599999999996, "text": " in the past and obviously created important innovations.", "tokens": [51516, 294, 264, 1791, 293, 2745, 2942, 1021, 24283, 13, 51726], "temperature": 0.0, "avg_logprob": -0.1612650502112604, "compression_ratio": 1.7181208053691275, "no_speech_prob": 0.0032163746654987335}, {"id": 1291, "seek": 342946, "start": 3429.62, "end": 3434.34, "text": " But but I think in this case, you know, we want to be bold with the with the", "tokens": [50372, 583, 457, 286, 519, 294, 341, 1389, 11, 291, 458, 11, 321, 528, 281, 312, 11928, 365, 264, 365, 264, 50608], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1292, "seek": 342946, "start": 3434.34, "end": 3438.02, "text": " positive things that it can do and make sure we realize things like medicine", "tokens": [50608, 3353, 721, 300, 309, 393, 360, 293, 652, 988, 321, 4325, 721, 411, 7195, 50792], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1293, "seek": 342946, "start": 3438.2200000000003, "end": 3442.5, "text": " and science and advancing all of those things whilst being, you know,", "tokens": [50802, 293, 3497, 293, 27267, 439, 295, 729, 721, 18534, 885, 11, 291, 458, 11, 51016], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1294, "seek": 342946, "start": 3442.7, "end": 3447.82, "text": " responsible and thoughtful with with as far as possible with with mitigating the risks.", "tokens": [51026, 6250, 293, 21566, 365, 365, 382, 1400, 382, 1944, 365, 365, 15699, 990, 264, 10888, 13, 51282], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1295, "seek": 342946, "start": 3448.02, "end": 3450.66, "text": " Yeah, yeah. And that's why it seems like the responsible", "tokens": [51292, 865, 11, 1338, 13, 400, 300, 311, 983, 309, 2544, 411, 264, 6250, 51424], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1296, "seek": 342946, "start": 3450.66, "end": 3453.7400000000002, "text": " scaling process or something like that is a very good empirical way to", "tokens": [51424, 21589, 1399, 420, 746, 411, 300, 307, 257, 588, 665, 31886, 636, 281, 51578], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1297, "seek": 342946, "start": 3453.7400000000002, "end": 3454.98, "text": " pre-commit to these kinds of things.", "tokens": [51578, 659, 12, 1112, 3508, 281, 613, 3685, 295, 721, 13, 51640], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1298, "seek": 342946, "start": 3454.98, "end": 3455.86, "text": " Yes, exactly.", "tokens": [51640, 1079, 11, 2293, 13, 51684], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1299, "seek": 342946, "start": 3455.86, "end": 3458.34, "text": " Yeah. And I'm curious if you have a sense of like, for example, when you're", "tokens": [51684, 865, 13, 400, 286, 478, 6369, 498, 291, 362, 257, 2020, 295, 411, 11, 337, 1365, 11, 562, 291, 434, 51808], "temperature": 0.0, "avg_logprob": -0.20018773608737522, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0030552593525499105}, {"id": 1300, "seek": 345834, "start": 3458.42, "end": 3462.3, "text": " doing these evaluations, if it turns out your next model could help a layperson", "tokens": [50368, 884, 613, 43085, 11, 498, 309, 4523, 484, 428, 958, 2316, 727, 854, 257, 2360, 10813, 50562], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1301, "seek": 345834, "start": 3462.3, "end": 3466.1800000000003, "text": " build a pandemic class or bio-weapon or something, how you would think, first of", "tokens": [50562, 1322, 257, 5388, 1508, 420, 12198, 12, 826, 21319, 420, 746, 11, 577, 291, 576, 519, 11, 700, 295, 50756], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1302, "seek": 345834, "start": 3466.38, "end": 3470.1400000000003, "text": " all, of making sure those weights are secure so that that doesn't get out?", "tokens": [50766, 439, 11, 295, 1455, 988, 729, 17443, 366, 7144, 370, 300, 300, 1177, 380, 483, 484, 30, 50954], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1303, "seek": 345834, "start": 3470.1400000000003, "end": 3473.54, "text": " And second, what would have to be true for you to be comfortable deploying", "tokens": [50954, 400, 1150, 11, 437, 576, 362, 281, 312, 2074, 337, 291, 281, 312, 4619, 34198, 51124], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1304, "seek": 345834, "start": 3473.54, "end": 3474.6600000000003, "text": " that system? How comfortable?", "tokens": [51124, 300, 1185, 30, 1012, 4619, 30, 51180], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1305, "seek": 345834, "start": 3474.6600000000003, "end": 3478.34, "text": " Like, how would you make sure that that that lane capability isn't exposed?", "tokens": [51180, 1743, 11, 577, 576, 291, 652, 988, 300, 300, 300, 12705, 13759, 1943, 380, 9495, 30, 51364], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1306, "seek": 345834, "start": 3478.34, "end": 3481.94, "text": " Yeah. Well, first, I mean, you know, the secure model part, I think we've covered", "tokens": [51364, 865, 13, 1042, 11, 700, 11, 286, 914, 11, 291, 458, 11, 264, 7144, 2316, 644, 11, 286, 519, 321, 600, 5343, 51544], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1307, "seek": 345834, "start": 3481.94, "end": 3485.34, "text": " with the cybersecurity and make sure that's well class and you're monitoring", "tokens": [51544, 365, 264, 38765, 293, 652, 988, 300, 311, 731, 1508, 293, 291, 434, 11028, 51714], "temperature": 0.0, "avg_logprob": -0.2078265210131665, "compression_ratio": 1.7319277108433735, "no_speech_prob": 0.006152901332825422}, {"id": 1308, "seek": 348534, "start": 3485.34, "end": 3490.3, "text": " all those things. I think if the capability was discovered like that", "tokens": [50364, 439, 729, 721, 13, 286, 519, 498, 264, 13759, 390, 6941, 411, 300, 50612], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1309, "seek": 348534, "start": 3490.3, "end": 3495.58, "text": " through red teaming or external testing by, you know, government institutes", "tokens": [50612, 807, 2182, 1469, 278, 420, 8320, 4997, 538, 11, 291, 458, 11, 2463, 4348, 1819, 50876], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1310, "seek": 348534, "start": 3495.78, "end": 3500.06, "text": " or academia or whatever, independent testers, then we would have to fix", "tokens": [50886, 420, 28937, 420, 2035, 11, 6695, 1500, 433, 11, 550, 321, 576, 362, 281, 3191, 51100], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1311, "seek": 348534, "start": 3500.06, "end": 3502.7400000000002, "text": " that loophole depending what it was, right?", "tokens": [51100, 300, 6367, 14094, 5413, 437, 309, 390, 11, 558, 30, 51234], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1312, "seek": 348534, "start": 3503.2200000000003, "end": 3509.7400000000002, "text": " If that required more a different kind of perhaps constitution or different", "tokens": [51258, 759, 300, 4739, 544, 257, 819, 733, 295, 4317, 11937, 420, 819, 51584], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1313, "seek": 348534, "start": 3509.7400000000002, "end": 3513.86, "text": " guardrails or more RLHF to avoid that or removing some training data,", "tokens": [51584, 6290, 424, 4174, 420, 544, 497, 43, 39, 37, 281, 5042, 300, 420, 12720, 512, 3097, 1412, 11, 51790], "temperature": 0.0, "avg_logprob": -0.2004386665894813, "compression_ratio": 1.6175298804780875, "no_speech_prob": 0.007004010956734419}, {"id": 1314, "seek": 351386, "start": 3514.42, "end": 3516.7000000000003, "text": " they could, I mean, depending on what the problem is, I think there could be a", "tokens": [50392, 436, 727, 11, 286, 914, 11, 5413, 322, 437, 264, 1154, 307, 11, 286, 519, 456, 727, 312, 257, 50506], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1315, "seek": 351386, "start": 3516.7000000000003, "end": 3518.6600000000003, "text": " number of mitigations.", "tokens": [50506, 1230, 295, 15699, 763, 13, 50604], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1316, "seek": 351386, "start": 3518.82, "end": 3522.78, "text": " And so the first part is making sure you detect it ahead of time.", "tokens": [50612, 400, 370, 264, 700, 644, 307, 1455, 988, 291, 5531, 309, 2286, 295, 565, 13, 50810], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1317, "seek": 351386, "start": 3522.86, "end": 3526.5, "text": " So that's about the right evaluations and right benchmarking and right and", "tokens": [50814, 407, 300, 311, 466, 264, 558, 43085, 293, 558, 18927, 278, 293, 558, 293, 50996], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1318, "seek": 351386, "start": 3526.5, "end": 3530.9, "text": " right testing. And then the question is how one would fix that before, you know,", "tokens": [50996, 558, 4997, 13, 400, 550, 264, 1168, 307, 577, 472, 576, 3191, 300, 949, 11, 291, 458, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1319, "seek": 351386, "start": 3530.9, "end": 3534.1800000000003, "text": " you deployed it. But I think it would need to be fixed before it was deployed", "tokens": [51216, 291, 17826, 309, 13, 583, 286, 519, 309, 576, 643, 281, 312, 6806, 949, 309, 390, 17826, 51380], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1320, "seek": 351386, "start": 3534.1800000000003, "end": 3537.1800000000003, "text": " generally, for sure, if that was an exposure surface.", "tokens": [51380, 5101, 11, 337, 988, 11, 498, 300, 390, 364, 10420, 3753, 13, 51530], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1321, "seek": 351386, "start": 3537.1800000000003, "end": 3539.1800000000003, "text": " Right. Right. Final question.", "tokens": [51530, 1779, 13, 1779, 13, 13443, 1168, 13, 51630], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1322, "seek": 351386, "start": 3540.38, "end": 3543.6600000000003, "text": " You know, you've been thinking in terms of like the end goal of Asia at a time", "tokens": [51690, 509, 458, 11, 291, 600, 668, 1953, 294, 2115, 295, 411, 264, 917, 3387, 295, 10038, 412, 257, 565, 51854], "temperature": 0.0, "avg_logprob": -0.1835877536094352, "compression_ratio": 1.7848101265822784, "no_speech_prob": 0.0018837422830983996}, {"id": 1323, "seek": 354366, "start": 3543.66, "end": 3546.46, "text": " when other people thought it was ridiculous in 2010, now that we're", "tokens": [50364, 562, 661, 561, 1194, 309, 390, 11083, 294, 9657, 11, 586, 300, 321, 434, 50504], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1324, "seek": 354366, "start": 3546.46, "end": 3550.2999999999997, "text": " seeing this like slow takeoff where we're actually seeing these like generalization", "tokens": [50504, 2577, 341, 411, 2964, 747, 4506, 689, 321, 434, 767, 2577, 613, 411, 2674, 2144, 50696], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1325, "seek": 354366, "start": 3550.2999999999997, "end": 3554.2999999999997, "text": " and intelligence, what is like the psychologically seeing this?", "tokens": [50696, 293, 7599, 11, 437, 307, 411, 264, 41387, 2577, 341, 30, 50896], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1326, "seek": 354366, "start": 3554.2999999999997, "end": 3555.2999999999997, "text": " What has that been like?", "tokens": [50896, 708, 575, 300, 668, 411, 30, 50946], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1327, "seek": 354366, "start": 3555.2999999999997, "end": 3557.2599999999998, "text": " Has it just like sort of priced into your role model?", "tokens": [50946, 8646, 309, 445, 411, 1333, 295, 30349, 666, 428, 3090, 2316, 30, 51044], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1328, "seek": 354366, "start": 3557.2599999999998, "end": 3560.2999999999997, "text": " So you like it's not new news for you or is it like actually just seeing it live?", "tokens": [51044, 407, 291, 411, 309, 311, 406, 777, 2583, 337, 291, 420, 307, 309, 411, 767, 445, 2577, 309, 1621, 30, 51196], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1329, "seek": 354366, "start": 3560.2999999999997, "end": 3563.8199999999997, "text": " You're like, wow, like this is something's like really changed or what does it feel", "tokens": [51196, 509, 434, 411, 11, 6076, 11, 411, 341, 307, 746, 311, 411, 534, 3105, 420, 437, 775, 309, 841, 51372], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1330, "seek": 354366, "start": 3563.8199999999997, "end": 3568.22, "text": " like? Yeah, well, for me, yes, it's already priced into my world, one of how", "tokens": [51372, 411, 30, 865, 11, 731, 11, 337, 385, 11, 2086, 11, 309, 311, 1217, 30349, 666, 452, 1002, 11, 472, 295, 577, 51592], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1331, "seek": 354366, "start": 3568.22, "end": 3570.42, "text": " things were going to go, at least from the technology side.", "tokens": [51592, 721, 645, 516, 281, 352, 11, 412, 1935, 490, 264, 2899, 1252, 13, 51702], "temperature": 0.0, "avg_logprob": -0.22365188598632812, "compression_ratio": 1.7927927927927927, "no_speech_prob": 0.003105814103037119}, {"id": 1332, "seek": 357042, "start": 3570.42, "end": 3575.1, "text": " But obviously, I didn't we didn't necessarily anticipate the general", "tokens": [50364, 583, 2745, 11, 286, 994, 380, 321, 994, 380, 4725, 21685, 264, 2674, 50598], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1333, "seek": 357042, "start": 3575.1, "end": 3579.58, "text": " public would be that interested this early in the sequence, right, of things", "tokens": [50598, 1908, 576, 312, 300, 3102, 341, 2440, 294, 264, 8310, 11, 558, 11, 295, 721, 50822], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1334, "seek": 357042, "start": 3579.58, "end": 3584.46, "text": " like maybe one could think of if we were to produce more, if say like a chat", "tokens": [50822, 411, 1310, 472, 727, 519, 295, 498, 321, 645, 281, 5258, 544, 11, 498, 584, 411, 257, 5081, 51066], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1335, "seek": 357042, "start": 3584.46, "end": 3588.7400000000002, "text": " GPT and chatbots hadn't got the kind of got the interest they'd ended up getting.", "tokens": [51066, 26039, 51, 293, 5081, 65, 1971, 8782, 380, 658, 264, 733, 295, 658, 264, 1179, 436, 1116, 4590, 493, 1242, 13, 51280], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1336, "seek": 357042, "start": 3588.86, "end": 3591.5, "text": " So I think it was quite surprising to everyone that people were ready to use", "tokens": [51286, 407, 286, 519, 309, 390, 1596, 8830, 281, 1518, 300, 561, 645, 1919, 281, 764, 51418], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1337, "seek": 357042, "start": 3591.5, "end": 3595.2200000000003, "text": " these things, even though they were lacking in certain directions, right?", "tokens": [51418, 613, 721, 11, 754, 1673, 436, 645, 20889, 294, 1629, 11095, 11, 558, 30, 51604], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1338, "seek": 357042, "start": 3595.2200000000003, "end": 3599.2200000000003, "text": " Impressive, though they are, then we would have produced more specialized", "tokens": [51604, 8270, 22733, 11, 1673, 436, 366, 11, 550, 321, 576, 362, 7126, 544, 19813, 51804], "temperature": 0.0, "avg_logprob": -0.18195208292158824, "compression_ratio": 1.7175324675324675, "no_speech_prob": 0.00041521209641359746}, {"id": 1339, "seek": 359922, "start": 3599.22, "end": 3603.4599999999996, "text": " systems, I think, built off of the main track, like Alpha Folds and Alpha goes", "tokens": [50364, 3652, 11, 286, 519, 11, 3094, 766, 295, 264, 2135, 2837, 11, 411, 20588, 24609, 82, 293, 20588, 1709, 50576], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1340, "seek": 359922, "start": 3603.4599999999996, "end": 3605.9399999999996, "text": " and and so on and our scientific work.", "tokens": [50576, 293, 293, 370, 322, 293, 527, 8134, 589, 13, 50700], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1341, "seek": 359922, "start": 3606.14, "end": 3612.54, "text": " And then I think the general public maybe would have only paid attention", "tokens": [50710, 400, 550, 286, 519, 264, 2674, 1908, 1310, 576, 362, 787, 4835, 3202, 51030], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1342, "seek": 359922, "start": 3612.54, "end": 3615.62, "text": " later down the road, where in a few years time, we have more generally", "tokens": [51030, 1780, 760, 264, 3060, 11, 689, 294, 257, 1326, 924, 565, 11, 321, 362, 544, 5101, 51184], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1343, "seek": 359922, "start": 3615.62, "end": 3617.5, "text": " useful assistant type systems.", "tokens": [51184, 4420, 10994, 2010, 3652, 13, 51278], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1344, "seek": 359922, "start": 3617.7799999999997, "end": 3619.06, "text": " So that's been interesting.", "tokens": [51292, 407, 300, 311, 668, 1880, 13, 51356], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1345, "seek": 359922, "start": 3619.06, "end": 3622.3799999999997, "text": " So that's created a different type of environment that we're now all", "tokens": [51356, 407, 300, 311, 2942, 257, 819, 2010, 295, 2823, 300, 321, 434, 586, 439, 51522], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1346, "seek": 359922, "start": 3622.3799999999997, "end": 3625.2599999999998, "text": " operating in as a field.", "tokens": [51522, 7447, 294, 382, 257, 2519, 13, 51666], "temperature": 0.0, "avg_logprob": -0.1827789342628335, "compression_ratio": 1.649402390438247, "no_speech_prob": 0.00580730801448226}, {"id": 1347, "seek": 362526, "start": 3625.42, "end": 3629.1000000000004, "text": " So I mean, it's a little bit more chaotic because there's so many more things", "tokens": [50372, 407, 286, 914, 11, 309, 311, 257, 707, 857, 544, 27013, 570, 456, 311, 370, 867, 544, 721, 50556], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1348, "seek": 362526, "start": 3629.1000000000004, "end": 3633.3, "text": " going on and there's so much VC money going into it and everyone sort of", "tokens": [50556, 516, 322, 293, 456, 311, 370, 709, 41922, 1460, 516, 666, 309, 293, 1518, 1333, 295, 50766], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1349, "seek": 362526, "start": 3633.46, "end": 3637.7400000000002, "text": " almost losing their minds over it, I think, and what I just the thing I", "tokens": [50774, 1920, 7027, 641, 9634, 670, 309, 11, 286, 519, 11, 293, 437, 286, 445, 264, 551, 286, 50988], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1350, "seek": 362526, "start": 3637.7400000000002, "end": 3641.86, "text": " worry about is I want to make sure that as a field, we act responsibly", "tokens": [50988, 3292, 466, 307, 286, 528, 281, 652, 988, 300, 382, 257, 2519, 11, 321, 605, 2914, 3545, 51194], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1351, "seek": 362526, "start": 3641.86, "end": 3645.6600000000003, "text": " and thoughtfully and scientifically about this and use the scientific", "tokens": [51194, 293, 1194, 2277, 293, 39719, 466, 341, 293, 764, 264, 8134, 51384], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1352, "seek": 362526, "start": 3645.6600000000003, "end": 3650.5400000000004, "text": " method to approach this in a in a, as I said, an optimistic, but careful way.", "tokens": [51384, 3170, 281, 3109, 341, 294, 257, 294, 257, 11, 382, 286, 848, 11, 364, 19397, 11, 457, 5026, 636, 13, 51628], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1353, "seek": 362526, "start": 3650.6600000000003, "end": 3654.34, "text": " And I think that's the I've always believed that's the right approach for", "tokens": [51634, 400, 286, 519, 300, 311, 264, 286, 600, 1009, 7847, 300, 311, 264, 558, 3109, 337, 51818], "temperature": 0.0, "avg_logprob": -0.17437333551071982, "compression_ratio": 1.7636986301369864, "no_speech_prob": 0.04856210947036743}, {"id": 1354, "seek": 365434, "start": 3654.38, "end": 3659.3, "text": " something like AI, and I just hope that doesn't get lost in this huge rush.", "tokens": [50366, 746, 411, 7318, 11, 293, 286, 445, 1454, 300, 1177, 380, 483, 2731, 294, 341, 2603, 9300, 13, 50612], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1355, "seek": 365434, "start": 3659.38, "end": 3660.06, "text": " Sure, sure.", "tokens": [50616, 4894, 11, 988, 13, 50650], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1356, "seek": 365434, "start": 3660.2200000000003, "end": 3661.58, "text": " Well, I think that's a great place to close.", "tokens": [50658, 1042, 11, 286, 519, 300, 311, 257, 869, 1081, 281, 1998, 13, 50726], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1357, "seek": 365434, "start": 3661.6200000000003, "end": 3662.54, "text": " Dennis, so much thanks to you.", "tokens": [50728, 23376, 11, 370, 709, 3231, 281, 291, 13, 50774], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1358, "seek": 365434, "start": 3662.54, "end": 3664.2200000000003, "text": " Thank you so much for your time and for coming on the podcast.", "tokens": [50774, 1044, 291, 370, 709, 337, 428, 565, 293, 337, 1348, 322, 264, 7367, 13, 50858], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1359, "seek": 365434, "start": 3664.2200000000003, "end": 3664.5, "text": " Thanks.", "tokens": [50858, 2561, 13, 50872], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1360, "seek": 365434, "start": 3664.5, "end": 3665.26, "text": " It's been a real pleasure.", "tokens": [50872, 467, 311, 668, 257, 957, 6834, 13, 50910], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1361, "seek": 365434, "start": 3667.42, "end": 3669.82, "text": " Hey, everybody, I hope we enjoyed that episode.", "tokens": [51018, 1911, 11, 2201, 11, 286, 1454, 321, 4626, 300, 3500, 13, 51138], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1362, "seek": 365434, "start": 3670.38, "end": 3674.06, "text": " As always, the most helpful thing you can do is to share the podcast,", "tokens": [51166, 1018, 1009, 11, 264, 881, 4961, 551, 291, 393, 360, 307, 281, 2073, 264, 7367, 11, 51350], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1363, "seek": 365434, "start": 3674.38, "end": 3677.7400000000002, "text": " send it to people you think might enjoy it, put it in Twitter, your group chats,", "tokens": [51366, 2845, 309, 281, 561, 291, 519, 1062, 2103, 309, 11, 829, 309, 294, 5794, 11, 428, 1594, 38057, 11, 51534], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1364, "seek": 365434, "start": 3677.7400000000002, "end": 3681.3, "text": " et cetera, just splits the world, appreciate your listening.", "tokens": [51534, 1030, 11458, 11, 445, 37741, 264, 1002, 11, 4449, 428, 4764, 13, 51712], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1365, "seek": 365434, "start": 3681.34, "end": 3682.3, "text": " I'll see you next time.", "tokens": [51714, 286, 603, 536, 291, 958, 565, 13, 51762], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}, {"id": 1366, "seek": 365434, "start": 3682.46, "end": 3682.9, "text": " Cheers.", "tokens": [51770, 13006, 13, 51792], "temperature": 0.0, "avg_logprob": -0.22752874602311812, "compression_ratio": 1.6808510638297873, "no_speech_prob": 0.008039547130465508}], "language": "en"}