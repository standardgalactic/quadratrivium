WEBVTT

00:00.000 --> 00:06.600
This is a fun book to read because then you just mentioned in there what the original source is to read to you know

00:06.600 --> 00:12.440
It's like it's like the herald bloom of economics, right? You just like it's a book written for smart people

00:13.640 --> 00:16.600
Okay, so let's just jump into it. Okay, the book we're talking about is

00:17.520 --> 00:22.540
Goat who is the greatest economist of all time and why doesn't matter? All right, let's start with Keynes

00:22.880 --> 00:24.880
So in the section in Keynes

00:25.720 --> 00:29.820
You quote him. I think talking about Robert Marshall. He says

00:30.000 --> 00:32.360
Alfred Marshall. Oh, sorry Alfred Marshall. He says

00:33.400 --> 00:38.240
The master economist must possess a rare combination of gifts. He must be a mathematician

00:38.680 --> 00:43.040
historian statesman philosopher no part of man's nature

00:43.560 --> 00:50.360
Man's nature or his institutions must lie entirely outside his regard and you say well Keynes is obviously talking about himself

00:50.640 --> 00:55.880
Because he was all those things and he was arguably the only person who was all those things at the time

00:55.880 --> 00:58.360
He must have known that. Okay. Well, you know what I'm gonna ask now

01:00.760 --> 01:04.880
So what should we make of Tyler Cowan citing Keynes?

01:05.840 --> 01:10.560
Using this quote a quote that's also applies to Tyler Cowan. I don't think it applies to me

01:11.080 --> 01:13.680
What's the exact list again? Am I a statesman?

01:14.240 --> 01:19.160
Did I sure you're late at the Treaty of Versailles or something comparable? I don't know we're in Washington

01:19.160 --> 01:21.160
I'm sure you talk to all the people who matter quite a bit

01:21.800 --> 01:24.840
Well, I guess I'm more of a statesman than most economists

01:24.840 --> 01:30.480
But I don't come close to Keynes in the breadth of his high-level achievement in each of those areas

01:31.080 --> 01:37.840
Hmm. Okay, let's talk about them those achievements. So chapter 12 in general theory of interest employment and money

01:38.480 --> 01:44.840
Here's a quote. It is probable that the actual average result of investments even during periods of progress and prosperity

01:45.200 --> 01:47.520
Have disappointed the hopes which promoted them

01:48.120 --> 01:50.640
If human nature felt no temptation to take a chance

01:50.640 --> 01:55.680
No satisfaction profit-apart in constructing a factory a railway a mine or a farm

01:55.960 --> 01:59.840
There might not be much investment merely as a result of cold calculation

02:00.000 --> 02:03.480
Now it's a fascinating idea that investment is irrational

02:03.800 --> 02:06.000
Or most investment throughout history has been irrational

02:06.000 --> 02:12.160
But when we think today about the fact that active investing exists, you know for winners curse like reasons

02:12.160 --> 02:15.440
VCs probably make on average less returns than the market

02:16.360 --> 02:19.120
There's a whole bunch of different examples you can go through right M&A

02:19.840 --> 02:25.440
Usually doesn't achieve this energy is it expects throughout history has more most investment been selfish to your rational

02:25.800 --> 02:29.240
Well, Adam Smith was the first one. I know to have made this point that

02:30.280 --> 02:33.240
Projectors, I think he called them are overly optimistic

02:33.680 --> 02:39.840
So people who do startups are overly optimistic people who have well-entrenched VC franchises

02:40.040 --> 02:44.680
Make a lot of money and there's some kind of bifurcation in the distribution, right?

02:44.680 --> 02:49.360
Then there's a lot of others who are just playing at it and maybe hoping to break even

02:50.520 --> 02:51.760
so

02:51.760 --> 02:56.120
The rate of return on private investment if you include small businesses

02:56.520 --> 02:58.520
it's highly skewed and

02:58.680 --> 03:04.280
Just a few percent of the people doing this make anything at all. So there's a lot to what Cain said

03:04.280 --> 03:08.080
I don't think he described it adequately in terms of a probability distribution

03:08.680 --> 03:13.080
But then again, he probably didn't have the data, but I wouldn't reject it out of hand. Hmm

03:13.320 --> 03:15.320
Another example here is

03:15.440 --> 03:22.760
This is something your colleague Alex Tobrock talks about a lot is that innovators don't internalize most of the gains you get to society

03:22.760 --> 03:27.320
So here's another example where you know, the entrepreneur compared to one of his first employees

03:27.320 --> 03:30.120
Is he that much better off for taking the extra risk and working that much harder?

03:31.000 --> 03:33.000
What does this tell us about?

03:33.320 --> 03:38.320
Is it it's a marvelous insight that you know, we're actually more of a seeking than it's selfishly

03:39.280 --> 03:44.240
Selfishly good for us. That was Reuven Brenner's claim in some of his books on risk

03:44.480 --> 03:48.080
Again, I think you have to distinguish between different parts of the distribution

03:48.400 --> 03:53.120
So it seems there's a very large number of people who foolishly start small businesses

03:53.440 --> 03:59.600
Maybe they overly value autonomy when they ought to just get a job with a relatively stable company

04:00.400 --> 04:02.400
So they're part of the thesis is correct

04:02.800 --> 04:08.000
And I doubt if there's really big social returns to whatever those people do even if they could make a go of it

04:09.040 --> 04:11.040
But there's another part of the distribution

04:11.280 --> 04:18.560
People who are actually innovating or have realistic prospects of doing so where I do think those social returns are very high

04:18.960 --> 04:20.960
Now that 2 figure

04:21.120 --> 04:25.120
That cited a lot. I don't think it's really based in much real

04:25.760 --> 04:28.320
It's maybe not a crazy seed of the pants estimate

04:28.560 --> 04:34.000
But people think like oh, we know it's two percent and we really don't so you look at Picasso, right? He

04:34.880 --> 04:37.920
Helped generate cubism with Brock and some other artists

04:38.720 --> 04:41.200
How good is our estimate of Picasso's income?

04:41.680 --> 04:47.680
Compared to the spin-offs from Picasso. We just don't really know, right? We don't know it's two percent

04:47.840 --> 04:50.320
It could be one percent. It could be six percent

04:51.200 --> 04:57.280
How different do you think it is in art versus, uh, I don't know entrepreneurship versus different kinds of entrepreneurship

04:57.280 --> 05:01.120
There's different industries there as well, right? I'm not sure it's that different

05:01.760 --> 05:05.360
So say if some people start blogging a lot of people copy them, right?

05:05.520 --> 05:09.120
Well, some people start painting in a particular style a lot of people copy them

05:09.360 --> 05:12.560
I'm not saying the numbers are the same, but they don't sound like

05:13.440 --> 05:17.760
Issues that in principle are so different into two percent overestimate or underestimate. It might be wrong

05:17.920 --> 05:19.520
But in which way is it wrong?

05:19.520 --> 05:23.360
My seed of the pants estimate would be two to five percent. So I think it's pretty close

05:23.600 --> 05:27.760
But again, that's not based on anything firm. Here's another quote from Keynes

05:27.760 --> 05:35.200
Uh, investment based on genuine long-term expectation is so difficult as to be scarcely practicable

05:35.680 --> 05:42.240
He who attempts it must surely lead much more laborious days and run greater risk than he who tries to guess better than the crowd

05:42.640 --> 05:44.640
How the crowd will behave?

05:45.440 --> 05:49.840
Is so one way to look at this is like, oh, he just doesn't understand, uh, efficient market hypothesis

05:50.080 --> 05:52.080
It's like before random walks or something

05:52.080 --> 05:53.520
but, uh,

05:53.520 --> 05:56.160
There's things you can see in the market today where, uh, you know

05:56.960 --> 06:01.760
Are the prospects for future dividends so much higher after cover than they were immediately after the crash

06:02.400 --> 06:07.840
Um, how much a market behavior can be explained by these sorts of uh claims from Keynes?

06:08.400 --> 06:11.360
I think Keynes had the view that for his time

06:11.680 --> 06:15.120
You could be a short run speculator and in fact beat the markets

06:15.680 --> 06:17.680
And he believed that he did so

06:18.080 --> 06:23.120
And at least he did for some periods of his life that may have been luck or maybe he did have special insight

06:24.080 --> 06:30.480
It probably wasn't true in general that we don't really know did efficient markets hold during, you know, Britain at that time

06:30.720 --> 06:34.320
Maybe there just were profit opportunities for smarter than average people

06:35.440 --> 06:41.360
Uh, so that's a view. I'm inclined not to believe it, but again, I don't think it's absurd

06:42.240 --> 06:49.120
Keynes is saying for people who want money, this is biased toward the short term. You can get your profits and get out

06:49.680 --> 06:54.720
And that's damaging long-term investment, which in fact he wanted to socialize

06:55.200 --> 06:57.920
So he's being led to a very bad place by the argument

06:58.400 --> 07:00.640
But again, we shouldn't dismiss it out of hand

07:01.440 --> 07:07.920
Why is it not easy to retrospectively study what uh, how efficient markets were back then in the same way we can study it now in terms of like

07:08.000 --> 07:14.960
Oh, you look at um, uh, the price earnings ratios and then what were the dividends afterwards over the coming decades for those companies

07:15.360 --> 07:21.120
Based on their stock price or something. I don't know. Uh, how many publicly traded firms there were in Britain at that time

07:21.600 --> 07:24.560
I don't know how good the data are things like bid asks spread

07:25.120 --> 07:30.480
At what price you actually executed trades can really matter for testing efficient markets hypothesis

07:31.600 --> 07:38.480
So uh, probably we can't tell even though there must be share price data of some sort at what frequency

07:39.280 --> 07:41.280
Well, is it once a day? Is it once a week?

07:42.240 --> 07:46.160
We don't have the sort of data we have now where you can just test anything you want

07:47.280 --> 07:51.680
He also made a interesting point is like not only is it not profitable, but even if you succeed

07:52.720 --> 07:56.400
Um, society will look at the contrarian in a very negative light

07:56.960 --> 08:00.000
Uh, you will be like doubly punished for being a contrarian

08:00.320 --> 08:05.520
But that doesn't seem to be the case right like if somebody like Warren Buffett or Charlie Munger people who do be the market are actually pretty revered

08:05.840 --> 08:07.840
They're not punished in public opinion

08:07.840 --> 08:10.400
And they pursued mostly long-term strategies, right?

08:10.800 --> 08:16.800
But again trying to make sense of Keynes if you think about long-term investing and I don't think he meant Buffett style investing

08:16.960 --> 08:23.680
I think he meant building factories trying to figure out what people would want to buy 25 years from that point in time

08:24.400 --> 08:28.080
Uh, that probably was much harder than today. So you had

08:28.800 --> 08:30.800
Way less access to data

08:31.040 --> 08:35.760
Your ability to build an international supply chain was much weaker

08:36.560 --> 08:42.560
Uh geopolitical turmoil at various points in time was much higher. So again, it's not a crazy view

08:42.880 --> 08:45.600
I think there's a lot in Keynes that's very much of his time

08:46.400 --> 08:51.680
That he presents out of a kind of overconfidence as being general and it's not general it may not even be true

08:52.480 --> 08:57.120
But there were some reasons why you could believe it. Hmm another quote from Keynes

08:57.680 --> 08:59.760
Uh, I guess I won't read the whole quote in full

08:59.760 --> 09:04.800
But basically he says over time as investments go or markets get more mature more and more

09:04.960 --> 09:11.200
Of equities are held basically by passive investors people who don't have a direct hand in the involvement of the enterprise

09:11.600 --> 09:15.040
Um, and you know the the the share of the market that's passive investment now is much bigger

09:15.120 --> 09:20.800
Should we be worried about this as long as at the margin people can do things? I'm not very worried about it

09:20.880 --> 09:25.440
So there's two different kinds of worries. One is that no one monitors the value of companies

09:26.400 --> 09:30.640
It seems to me those incentives aren't weaker. There's more research than ever before

09:31.120 --> 09:34.000
There's maybe a problem not enough companies are publicly held

09:34.560 --> 09:39.120
But you can always if you know something the rest of the market doesn't buy or sell shore and do better

09:39.760 --> 09:45.760
The other worry is those passive investors have economies of scale and they'll end up colluding with each other

09:46.320 --> 09:52.560
And you'll have say like three to five mutual funds private equity firms owning a big chunk of the market portfolio

09:53.120 --> 09:54.480
And in essence

09:54.480 --> 09:59.040
Directly or indirectly they'll tell those firms not to compete. It's a weird form of collusion

09:59.680 --> 10:02.720
They don't issue explicit instructions like say the same

10:03.360 --> 10:05.360
Few mutual funds own coke and Pepsi

10:06.240 --> 10:13.600
Should coke and Pepsi compete or should they collude? Well, they might just pick lazier managers who in some way give you implicit collusion

10:14.720 --> 10:16.720
Maybe this is another example of the

10:16.880 --> 10:21.600
Innovators being unable to internalize their gains as an active investors who are providing this information to the market

10:21.840 --> 10:26.080
You know, they don't make out that much better than the passive investors, but they're actually providing a valuable service

10:26.560 --> 10:29.200
Uh, but this the benefits are diffused throughout throughout society

10:29.440 --> 10:31.600
I think overconfidence helps us on that front

10:31.600 --> 10:34.960
So there's quote unquote too much trading from a private point of view

10:35.440 --> 10:41.840
But from a social point of view, maybe you can only have too much trading or too little trading and you might rather have too much trading

10:42.240 --> 10:45.520
I explain that why why is there why can't it only be too much or too little?

10:46.160 --> 10:50.080
Well, let's say the relevant choice variable is investor temperament

10:50.560 --> 10:56.640
So yes, you'd prefer it if everyone had the temperament just to do what was socially optimal, but if temperament is some

10:58.160 --> 11:03.360
This inclination in you and you can just be overconfident or not confident enough

11:04.000 --> 11:06.160
And overconfidence gives you too much trading

11:06.640 --> 11:10.240
That might be the best we can do again fine-tuning would be best of all

11:10.720 --> 11:15.360
But i've never seen humans where you could just fine-tune all their emotions to the point where they ought to be

11:15.920 --> 11:21.520
Yeah, okay, so we can ask the question. How far above optimal are we or if we are above optimal?

11:21.840 --> 11:25.280
Uh in the chapter kane says that over time as markets get more mature

11:25.360 --> 11:31.040
They become more speculative and the example he gives us like the new york market seems more speculative to him than the london market at a time

11:31.600 --> 11:34.160
Um, but today finance is eight percent of gdp

11:34.720 --> 11:37.200
Uh, is that what we should expect it to be?

11:37.600 --> 11:41.920
To uh to efficiently allocate capital. Is there some reason we can just look at that number?

11:41.920 --> 11:48.720
And we can actually say that that's too big. I think the relevant number for the financial sector is what percentage it is of wealth not gdp

11:49.920 --> 11:50.880
So

11:50.880 --> 11:55.360
You're managing wealth and the financial sector has been a pretty constant two percent of wealth

11:55.840 --> 12:02.160
For a few decades in the united states with bumps. Obviously 2008 matters, but it's more or less two percent

12:02.560 --> 12:08.240
And that makes it sound a lot less sinister. It's not actually like growing at the expense of something and eating up the economy

12:08.960 --> 12:10.480
so

12:10.480 --> 12:15.520
You you would prefer it's less than two percent, right? But two percent does not sound outrageously high to me

12:16.560 --> 12:19.920
And if the ratio of wealth to gdp grows over time

12:20.240 --> 12:23.760
Which it tends to do when you have durable capital and no major wars

12:24.320 --> 12:29.600
Uh, the financial sector will grow relative to gdp. But again, that's not sinister think of it in terms of wealth

12:29.920 --> 12:33.840
I see so one way to think about it is like the the management cost as a fraction of the

12:34.240 --> 12:38.960
Assets under management or something and that's right. Yeah, that's two percent of that bad. Yeah, okay, interesting

12:39.600 --> 12:43.200
I want to go back to the the risk aversion thing again because I don't know how to think about this

12:43.200 --> 12:48.000
So, you know, his whole thing is these animal spirits. They guide us to make all these bets and

12:48.640 --> 12:50.640
engage in all this activity

12:50.640 --> 12:52.640
in some sense it's he's saying like

12:53.360 --> 12:56.080
Not only are we not risk neutral, but we're more risk seeking than is

12:56.720 --> 12:58.880
than is rational whereas

12:59.600 --> 13:03.520
The the way you'd conventionally think about it is that humans are risk averse, right? They they have

13:04.160 --> 13:06.480
They prefer to take less risk than is rational in some sense

13:06.720 --> 13:08.720
Um, how do we score this?

13:09.120 --> 13:12.240
Well, here Milton Friedman and other goat contender comes into the picture

13:12.480 --> 13:14.480
So his famous piece with savage

13:14.800 --> 13:16.800
Makes the point that risk aversion

13:17.040 --> 13:22.800
Is essentially context dependent. So he was a behavioral economist before we knew of such things

13:23.360 --> 13:28.880
So the same people typically will buy insurance and gamble gambling you can interpret quite broadly

13:29.600 --> 13:34.080
And that's the right way to think about it. So just flat out risk aversion or risk-loving behavior

13:34.240 --> 13:41.040
It doesn't really exist almost everyone is context dependent now why you choose the context you do

13:41.680 --> 13:44.320
Maybe it's some kind of exercise in mood management

13:44.720 --> 13:48.800
So you ensure your house so you can sleep well at night you fire insurance

13:49.200 --> 13:54.480
But then you get a little bored and to stimulate yourself you're you're betting on these nba games

13:54.720 --> 13:57.040
And yes, that's foolish, but it keeps you busy

13:57.520 --> 14:00.960
And it helps you follow analytics and you read about the games online

14:01.520 --> 14:05.680
And maybe that's efficient mood management and that's the way to think about risk behavior

14:06.480 --> 14:08.480
I don't bet by the way

14:08.480 --> 14:11.760
I mean you could say I bet with my career, but I don't bet on things

14:12.000 --> 14:14.480
Well, what is the way and what's your version of the water shake it?

14:14.480 --> 14:20.080
What is the thing where you just for the entertainment value or the distraction value you you take more risk than

14:20.800 --> 14:22.800
Then would seem rational

14:23.200 --> 14:25.200
Well, like writing the book goat

14:25.680 --> 14:29.520
Which is not with any known publisher. It's just online. It's free

14:30.080 --> 14:32.080
It's published within gpt for

14:33.040 --> 14:35.040
Took me quite a while to write the book

14:36.160 --> 14:41.040
I'm not sure there's a huge downside, but it's risky in the sense of it's not what anyone else was doing

14:41.200 --> 14:45.760
So that was a kind of risk. I invested a lot of my writing time in something weird

14:46.320 --> 14:48.640
And I've done things like that pretty frequently

14:49.040 --> 14:55.200
So that keeps me you could say excited or like starting mru, you know the online education videos and economics

14:56.000 --> 15:00.000
No pecuniary return to me at all indirectly. It costs me a lot of money

15:00.880 --> 15:06.480
That's a sort of risk. I feel it's paid off for me in a big way, but

15:07.280 --> 15:10.880
On one hand you could say well tyler, what do you actually have from that and the answer is nothing?

15:11.600 --> 15:13.920
Yeah, well, this actually raises the question

15:13.920 --> 15:18.000
I was going to ask about these go contenders in general and how you're judging them where

15:18.800 --> 15:20.800
You're looking at their work as a whole

15:21.520 --> 15:24.800
Given that I don't know some of these risks pay off that these intellectuals take

15:24.800 --> 15:29.920
Some of them don't pay off should we just be looking at their top contributions and just disregard everything else?

15:30.320 --> 15:34.320
For hayek, I think one of the points you have against him is that his top three articles are amazing

15:34.400 --> 15:36.400
But after that there's a drop off

15:37.520 --> 15:40.480
The top risk you take are the only ones that matter. Why are we looking at the other stuff?

15:40.800 --> 15:43.920
I don't think they're the only ones that matter, but I'll weight them pretty heavily

15:44.320 --> 15:46.320
But your failures do reflect

15:46.800 --> 15:49.360
Usually and how you think or what you know about the world

15:50.080 --> 15:52.080
so hayek's failures

15:52.240 --> 15:57.120
For instance his inability to come up with the normative standard in constitution of liberty

15:58.000 --> 16:00.480
It shows in some ways. He just wasn't rigorous enough

16:00.960 --> 16:06.720
He was content with the kind of germanic put a lot of complex ideas out there and hope they're profound

16:07.600 --> 16:11.680
And you see that even in his best work now that is profound

16:12.480 --> 16:19.040
But it's not as if the failures and the best work for all these people are unrelated and same with canes like canes more or less

16:19.120 --> 16:21.120
Changed his mind every year

16:21.200 --> 16:23.200
That's a strength, but it's also a weakness

16:23.600 --> 16:28.640
And by considering canes is really good works and bad works like his defenses of tariffs

16:29.600 --> 16:31.600
You see that and the best work

16:31.600 --> 16:36.000
He also moved on from in some way if you read how to pay for the war in 1940

16:36.480 --> 16:39.760
If you didn't know better, you would think it's someone criticizing the general theory

16:41.360 --> 16:43.360
How uh

16:43.360 --> 16:48.720
Does quantity have equality all of its own when you think of great intellectuals where many of these people have like volumes and volumes

16:48.880 --> 16:53.200
Of work was that necessary for them to get the greatest sets or is the rest of it?

16:53.200 --> 16:57.920
Just a distraction from the things that really stand a test of time for the best people it's necessary

16:58.000 --> 17:01.920
So john stewart mill wrote an enormous amount most of it's quite interesting

17:03.040 --> 17:05.760
But his ability to see things from multiple perspectives

17:05.840 --> 17:12.560
I think was in part stemming from the fact that he wrote a lot about many different topics like french history ancient greece

17:13.360 --> 17:15.360
He had real depth and breadth

17:16.240 --> 17:22.640
If canes is alive today, what are the odds that he's in a polycule in berkeley writing the best written less wrong posts you've ever seen

17:24.640 --> 17:28.400
I'm not sure what the counterfactual means. So canes is so british

17:29.760 --> 17:31.760
Maybe he's an effective altruist

17:32.160 --> 17:33.840
at cambridge

17:33.840 --> 17:40.240
And you know given how he seems to have run a sex life. I don't think he needed a polycule like a polycule

17:40.800 --> 17:45.280
It's almost a william sony and device to economize on transactions costs

17:45.680 --> 17:50.160
But canes according to his own notes seems to have done things on a very casual basis

17:50.320 --> 17:54.480
He had a spreadsheet, right of essential partner and from context it appears

17:54.480 --> 18:00.320
He met these people very casually and didn't need to be embedded in where the five people who get together regularly

18:00.960 --> 18:05.200
So that's not a hypothetical. We saw we think we saw what he did

18:06.080 --> 18:07.600
and

18:07.600 --> 18:11.520
I think he'd be at cambridge, right? That's where he was. Why should he not today be at cambridge?

18:12.400 --> 18:14.400
How did a person

18:14.720 --> 18:18.160
How did a gay intellectual get that amount of influence in the britain of that time?

18:18.160 --> 18:22.800
When you think of somebody like alan touring, you know helps a britain win world war two and is castrated

18:23.440 --> 18:24.400
because of

18:24.400 --> 18:26.400
You know one illicit encounter that is caught

18:26.880 --> 18:29.680
Well, was it just not public? How did how did he get away with it basically?

18:30.400 --> 18:33.600
I don't think it was a secret about canes. He had

18:34.080 --> 18:39.520
Interacted with enough people that I think it was broadly known. He was politically very powerful

18:39.920 --> 18:45.200
He was astute as someone managing his career. He was one of the most effective people

18:45.280 --> 18:48.080
You could say of all time not just amongst economists

18:48.640 --> 18:51.920
And i've never seen evidence that canes was in any kind of danger

18:52.880 --> 18:57.600
Our touring also may have intersected with national security concerns in a different way

18:58.400 --> 19:03.280
I'm not sure we know the fall alan touring story and why it went as badly as it did

19:04.240 --> 19:08.560
But there was in the past very selectively and I do mean very selectively

19:09.120 --> 19:13.040
More tolerance of deviance than people today sometimes realize

19:13.600 --> 19:17.600
Oh interesting and canes benefited from that but again, I would stress the word selectively

19:18.000 --> 19:24.240
Say more what determines who is selected for this tolerance. I don't feel I understand that very well, but there's plenty

19:25.120 --> 19:31.280
Say in europe and britain of the early 20th century where quote-unquote outrageous things were done

19:31.760 --> 19:34.400
And it's hard to find evidence that people were punished for

19:35.040 --> 19:40.160
Now what accounts for the difference between them and the people who were punished? I would like to see a very good book on that

19:40.880 --> 19:46.320
Hmm. Um, yeah, I guess it's similar to our time, right? We have certain taboos and you can get away with them

19:46.640 --> 19:50.000
Yeah, exactly. They say whatever on twitter and other people get cancelled

19:50.800 --> 19:56.160
Actually, however, you gotta know it. I feel like you've never been in at least as far as I know of I haven't heard you being in the part of

19:56.240 --> 20:01.040
Any single controversy, but uh, you have some opinions out there. I feel people have been very nice to me

20:01.120 --> 20:03.360
Yeah, what would you do? How did you become the canes of our time?

20:04.160 --> 20:06.160
If we're comparing

20:10.880 --> 20:12.880
I think just being good-natured

20:12.880 --> 20:15.360
Yeah helps and helping a lot of people helps

20:16.080 --> 20:20.080
Entering I'm a huge fan of wrote a paper on him with Michelle Dawson

20:20.720 --> 20:24.560
But it's not obvious that he was a very good diplomat and it seems

20:25.200 --> 20:29.520
He very likely was a pretty terrible diplomat and that might be feeding into this difference

20:30.000 --> 20:36.640
how do you think about the long-term value of um, and the long-term impact of intellectuals you disagree with

20:36.720 --> 20:38.480
So do you think over the course of history?

20:38.480 --> 20:43.120
Basically the improvements they make to the discourse and the additional things they give us a chance to think about

20:43.360 --> 20:45.360
That washes out their object level

20:46.480 --> 20:48.480
The things that were object level wrong about or

20:48.720 --> 20:54.000
Well, it's worked that way so far, right? So we've had economic growth obviously with interruptions

20:54.640 --> 21:01.280
But so much has fed into the stream and you have to be pretty happy with today's world compared with say 1880

21:02.000 --> 21:04.000
Uh, the future may or may not bring us the same

21:04.400 --> 21:09.920
But if the future brings us continuing economic growth, then i'm gonna say exactly that. Oh be happy

21:09.920 --> 21:13.600
They fed into the stream. They may have been wrong, but things really worked out

21:14.320 --> 21:16.320
But if the future brings us

21:16.480 --> 21:20.160
It a shrinking population asymptotically approaching a very low level

21:20.880 --> 21:27.520
And greater poverty and more war then you've got to wonder. Well, who is responsible for that, right? Who would be responsible for that?

21:29.520 --> 21:36.080
We don't know but I think secular thinkers will fall in relative status if that's the outcome and that's most

21:36.480 --> 21:39.360
prominent intellectuals today myself included. Yeah

21:39.920 --> 21:43.840
Who who would rise in status as a result? Well, there's a number of people

21:44.560 --> 21:47.200
complaining strenuously about fertility declines

21:48.080 --> 21:50.080
Uh, if there's more war

21:50.640 --> 21:57.360
Probably the hawks will rise in status whether or not they should an alternative scenario is that the pacifists rise in status

21:57.680 --> 22:02.080
But I basically never see the pacifists rising in status for any more than brief moments

22:02.240 --> 22:05.360
Like after the vietnam war, maybe they did after all the run

22:06.320 --> 22:10.960
Yes, but again that didn't last because world war two swept all that away, right?

22:11.120 --> 22:14.320
So the pacifists seem to lose long-term status no matter what

22:15.760 --> 22:18.080
And that means the hawks would gain in status

22:18.640 --> 22:25.120
And those worried about fertility and whatever technology drives the new wars if that is what happens

22:25.200 --> 22:29.040
Let's say it's drones. It's possible, right? Uh people who warned against drones

22:29.840 --> 22:33.360
Which is not currently that big a thing. There are quite a few such people

22:33.760 --> 22:35.760
But there's no one out there known

22:36.560 --> 22:42.720
For worrying about drones the way say illeaser is worried about known for worrying about AI now drones in a way are AI

22:42.880 --> 22:47.280
But it's different. Yeah, other than that freedmen steward I'm sure other people have you know talked about

22:47.760 --> 22:49.760
We're not that far away from doing sickness. I guess you have

22:49.840 --> 22:54.400
I guess there's a thing you do video with millions of views. Whoever made that would rise. I think steward I was wrong

22:54.400 --> 22:56.400
What was I'm sorry, uh, that's true

22:56.560 --> 23:01.680
But anyways, yeah, but those people could end up as much more important than they are now. Yeah. Okay. Let's talk about hayek

23:02.000 --> 23:05.120
Sure. Um, so I before we get into his actual views

23:05.600 --> 23:10.480
I think his career is a tremendous white pill in the sense that he writes the rotisserieftum in 1944

23:11.200 --> 23:15.520
When nazi germany and so the union are both, you know, prominent players and

23:17.200 --> 23:19.680
Honestly, like the way things shaked out, uh

23:20.880 --> 23:26.400
I mean, he would be pretty pleased that like a lot of the biggest collectivisms of the day have been, uh wiped out

23:26.720 --> 23:29.120
So it is a tremendous white pill. You can have a career like that

23:29.280 --> 23:31.280
He was

23:31.920 --> 23:32.880
Uh

23:32.880 --> 23:37.760
Not as right as he thought at the time, but he ended up being too grumpy in his later years

23:37.840 --> 23:38.160
Oh, really?

23:38.160 --> 23:43.120
He thought well collectivism is still going to engulf the world and I think he became a grumpy old man

23:43.840 --> 23:46.720
And then maybe it's one thing to be a grumpy old man in 2024

23:47.200 --> 23:49.680
But to be a grumpy old man in the 80s

23:50.480 --> 23:56.400
Didn't seem justified. What was the cause? What like what specifically did he see that he he thought they were

23:56.400 --> 24:02.640
Atavistic instincts in the human spirit, which were biologically built in that led us to be collectivists

24:02.720 --> 24:10.960
Right and too envious and not appreciative of how impersonal orders worked and that this would cause the west to turn into something quite crummy

24:11.920 --> 24:13.920
I wouldn't say he's been proven wrong

24:14.320 --> 24:16.800
but a lot of the west has had a pretty good run since then

24:17.760 --> 24:20.880
And uh, there's not major evidence that he's correct

24:21.840 --> 24:24.720
The bad events we've seen like some war coming back

24:25.680 --> 24:27.040
Uh

24:27.040 --> 24:32.400
Something weird happening in our politics. I'm not sure how to describe it. I'm not sure they fit the Hayek model

24:32.720 --> 24:35.840
A sort of simply the accretion of more socialism

24:36.640 --> 24:41.360
Um, but in terms of the basic psychological urges towards envy and resentment

24:41.600 --> 24:45.120
Isn't the rise of wokeness provide evidence for his view, but now wokeness

24:45.440 --> 24:48.080
I would say is peaked and is falling. That's a big debate

24:48.960 --> 24:51.200
I don't see wokeness as our biggest problem

24:51.360 --> 24:57.040
I see excessive bureaucracy, sclerotic institutions, kludgeocracy as bigger problems

24:57.040 --> 24:59.040
They're not unrelated to wokeness to be clear

24:59.440 --> 25:01.760
But I think they're more fundamental and harder to fix

25:02.640 --> 25:05.200
Let's talk about uh Hayek's Hayek's uh arguments

25:05.520 --> 25:08.560
So obviously he has a famous argument about decentralization

25:08.960 --> 25:13.440
But when we look at companies like amazon uber these other big tech companies

25:13.680 --> 25:18.800
They actually do a pretty good job of central planning, right? There's like a sea of logistics and drivers and

25:19.040 --> 25:21.520
Uh, um trade-offs that they had to square

25:22.080 --> 25:24.480
Uh, do they provide evidence that central planning can work?

25:25.280 --> 25:32.480
Well, i'm not a cosian so cos in his famous 1937 article said the firm is planning and he contrasted that to the market

25:32.640 --> 25:38.880
Right. I think the firm is the market. The firm is always making contracts in the market is subject to market checks and balances

25:39.280 --> 25:41.200
to me, it's not

25:41.200 --> 25:45.920
You know an island of central planning and the broader shroff of the market. So i'm just not cosian

25:46.000 --> 25:49.200
So people are a cosian. This is an embarrassing question for them

25:49.600 --> 25:54.080
But i'll just say amazon being great is the market working and they're not centrally planning

25:54.560 --> 26:00.240
Even the soviet union it was very bad, but it didn't end up being central planning. It started off that way for a few years

26:00.960 --> 26:01.840
so

26:01.840 --> 26:03.840
I think people misinterpret

26:03.920 --> 26:06.960
Large business firms in many ways on both the left and the right

26:07.600 --> 26:09.600
Wait, but under this argument

26:09.760 --> 26:15.600
It still adds to the credence of the people who argue that basically we need the government to control

26:15.920 --> 26:17.920
because if it is the case that soviet union is still

26:18.160 --> 26:23.840
Uh, not central planning people would say well, but yeah, but that's kind of what I want in terms of there's still kind of checks in terms of

26:23.920 --> 26:27.520
import exports of the market test is still applied to the government in that sense

26:28.000 --> 26:32.080
Uh, well, what's wrong with that argument that basically you can treat the government as that kind of firm

26:32.960 --> 26:40.400
I'm not sure I followed your question. I would say this i view the later soviet union as being highly decentralized

26:40.720 --> 26:45.360
Managers optimizing their own rents and setting prices too low to take in bribes

26:45.680 --> 26:48.800
a la paul craig roberts what he wrote in the 80s

26:49.680 --> 26:56.160
And that's a very bad decentralized system and it was sort of backed up by something highly central communist party in the ussr

26:57.120 --> 27:04.080
But it's not like the early attempts at true central planning in the soviet union in the 20s right after the revolution

27:04.240 --> 27:07.920
Which did totally fail and were abandoned pretty quickly even by lenin

27:08.160 --> 27:09.280
Hmm

27:09.280 --> 27:15.360
Would you kind of 50s period in the soviet union as more centrally planned than or more decentralized by that point decentralized

27:15.440 --> 27:17.440
You have central plans for a number of things

27:18.080 --> 27:21.200
Obviously weaponry steel production you have targets

27:21.440 --> 27:25.920
But even that tends to collapse into decentralized action just with bad incentives

27:26.560 --> 27:29.840
So your explanation for why did the soviet union have high growth in the 50s?

27:30.400 --> 27:33.680
It is it more ketchup? Is it more that they were in communists at the time?

27:34.000 --> 27:37.920
How would you explain a lot of the soviet high growth was rebuilding after the war

27:38.320 --> 27:44.960
Which the central planning can do relatively well right you see government rebuilding city say in germany that works pretty well

27:45.440 --> 27:49.520
But most of all this is even before world war two just urbanization

27:50.960 --> 27:54.240
It shouldn't be underrated today given we've observed china

27:54.320 --> 27:56.960
But so much of chinese growth was driven by urbanization

27:57.360 --> 28:02.640
So much of soviet growth you take someone working on a farm producing almost nothing put them in the city

28:03.280 --> 28:05.840
Even under a bad system. They're going to be a lot more productive

28:06.560 --> 28:10.240
And that drove so much of soviet growth before after the war

28:10.880 --> 28:14.240
But that at some point more or less ends right as it has

28:14.560 --> 28:19.520
Well, it hasn't quite ended with china, but it certainly slowed down and people don't pay enough attention to that

28:19.600 --> 28:24.480
I don't know why it now seems pretty obvious. Hmm. Uh, but but going back to the the point about firms

28:24.720 --> 28:25.840
so

28:25.840 --> 28:29.840
I guess I the point I was trying to make is I don't understand why the argument you make that

28:30.400 --> 28:35.440
Well, these firms are still within the market in the sense that they they have to pass these market tests

28:36.080 --> 28:39.200
Why that couldn't also apply to government directed production?

28:39.760 --> 28:43.520
Because then people sometimes it does right government runs a bunch of enterprises

28:44.560 --> 28:50.560
Uh, they may have monopoly positions, but many are open to the market in singapore government hospitals compete with private hospitals

28:51.200 --> 28:56.480
Government hospitals seem to be fine. I know they get some means of support. Yeah, but they're not all terrible

28:56.800 --> 29:02.080
But I guess it's a general principle you'd be against more government, uh, directed production, right?

29:03.040 --> 29:09.280
Well depends on the context. So if it's say the military, uh, probably we ought to be building a lot more of some particular things

29:10.080 --> 29:12.640
And it will be done through Boeing, Lockheed and so on

29:12.800 --> 29:16.720
But the government's directing it paying for it in some way quote-unquote planning it

29:17.280 --> 29:20.880
And we need to do that. We've at times done that well in the past

29:21.840 --> 29:23.120
so

29:23.120 --> 29:27.600
People overrate the distinction between government and market. I think especially libertarians

29:28.160 --> 29:31.520
But that said there's an awful lot of government bureaucracy. That's terrible

29:32.000 --> 29:33.840
Doesn't have a big market check

29:33.840 --> 29:39.840
But very often governments act through markets and have to contract or hire consultants or hire outside parties

29:40.160 --> 29:42.160
And it's more like a market than you think

29:42.240 --> 29:43.920
um

29:43.920 --> 29:45.600
I want to ask you about another part of Hayek

29:45.680 --> 29:50.960
So he has an argument about how it's really hard to aggregate information towards a central planner

29:51.280 --> 29:58.000
But then more recently there have been our results in computer science that just finding the general equilibrium is computationally intractable

29:58.480 --> 30:03.120
Um, and which raises the question. Well, the market is somehow solving this problem, right?

30:03.200 --> 30:08.240
separate from the problem getting the information make it use making use of information to allocate scarce resources

30:08.800 --> 30:12.320
Um, how how is that computationally a process that's possible?

30:12.800 --> 30:19.280
Uh, you know, I'm sure you're aware like the linear optimization and non-convex constraints. How does the market solve this problem?

30:20.160 --> 30:22.800
Well, the market's not solving for a general equilibrium

30:23.040 --> 30:25.920
It's just solving for something that gets us into the next day

30:26.480 --> 30:31.120
And that's a big part of the triumph just living to fight another day wealth not going down

30:31.440 --> 30:33.200
Not everyone quitting

30:33.200 --> 30:39.520
And if you can do that things will get better and that's what we're pretty good at doing is just building a sustainable structure

30:40.160 --> 30:43.840
And a lot of it isn't sustainable like the fools who start these new small businesses

30:44.000 --> 30:47.920
But they do pretty quickly disappear and that's part of the market as well

30:48.720 --> 30:52.960
So if you view the whole thing in terms of computing a general equilibrium

30:53.200 --> 30:57.040
I think one of high ex-grade insights is that's just the wrong way to think about the whole problem

30:57.680 --> 30:59.680
so lack of

31:00.320 --> 31:06.720
Computational ability to do that doesn't worry me for either the market or planning because to the extent planning does work

31:06.800 --> 31:08.800
It doesn't work by succeeding at that

31:09.200 --> 31:11.200
Like singaporean public hospitals

31:11.680 --> 31:15.040
Don't work because they solve some computational problem

31:15.280 --> 31:20.960
They seem to work because the people running them care about doing a good job and enough of the workers go along with that

31:21.440 --> 31:25.680
Yeah, so related to that. I think in the meaning of competition. He makes the point that

31:26.240 --> 31:30.720
um, the the most interesting part of markets is when they go from one equilibrium to another

31:30.880 --> 31:35.040
Because that's where they're trying to figure out what to produce and how to produce a better and so on and not the

31:35.040 --> 31:38.880
Equilibrium's themselves and it seemed related to the peter teal point in zero to one that

31:39.280 --> 31:43.440
Uh, monopoly is when you have interesting things happen because when there's just competitive equilibrium

31:43.520 --> 31:45.520
There's no profits to

31:45.680 --> 31:47.680
invest in r&d or to do cool new things

31:47.760 --> 31:53.840
Do those seem like related points? Am I reading absolutely a high xs a competition as a discovery process or procedure

31:54.480 --> 32:00.480
Makes that point very explicitly and that's one of his handful of greatest essays one of the greatest essays in all of economics

32:01.920 --> 32:07.040
Is there a contradiction in hayek in the sense that the decentralization he's calling for

32:07.600 --> 32:13.040
Uh results in the results and have a specialist having to use the very scientism and statistical aggregates

32:13.440 --> 32:16.880
Of course that high fender rate scientism scientism is great

32:17.280 --> 32:18.720
It can be abused

32:18.720 --> 32:22.880
But we all rely on scientism if you have an mRNA vaccine in your arm

32:22.960 --> 32:25.040
Well, how do you feel about scientism and so on?

32:26.160 --> 32:32.320
How much would we worry about uh this opening up the whole system to fragilities if there's like no one mind that understands

32:32.400 --> 32:38.560
Large parts of how everything fits together people talk about this in the context of if there's a war in china and the the producers

32:38.640 --> 32:42.640
Didn't think about that possibility when they put valuable manufacturing in taiwan and stuff like that

32:43.440 --> 32:46.880
No one mind understanding things is inevitable under all systems

32:47.360 --> 32:52.800
This gets into some of the alignment debates right if you had one mind that understood everything or could control everything

32:53.120 --> 32:56.160
You have to worry a great deal about the corruptibility of that mind

32:56.480 --> 33:03.360
So legibility transparency are not per se good. You want enough of them in the right places, but you need some kind of balance

33:04.720 --> 33:06.720
so I think uh

33:07.040 --> 33:10.000
Supply chains are no longer an under analyzed problem

33:10.240 --> 33:12.720
But until covet they were and they're a big deal

33:13.440 --> 33:15.840
And the haiki an argument doesn't always work

33:16.640 --> 33:19.200
Because the signal you have is of the current price

33:19.680 --> 33:23.120
And that's not telling you how high are the inframarginal values

33:23.520 --> 33:28.960
If you get say cut off from being able to buy vaccines from india because you're you know at the bottom of the queue

33:30.240 --> 33:31.280
So that was a problem

33:31.280 --> 33:37.120
It was the market falling because the price doesn't tell you inframarginal values and when you move from some

33:37.840 --> 33:42.560
Ability to buy the output to zero those inframarginal values really matter. Hmm

33:43.680 --> 33:49.600
What would hayek make of ai agents and as they get more powerful you have some market between the ai agents

33:50.160 --> 33:54.800
Uh, the there's some sort of decentralized order as a result. What what insights would you have about that?

33:55.200 --> 33:58.880
Well, a lot of hayekians wrote about these issues including at george mason

33:59.520 --> 34:03.920
In the 1980s and I think some of those people even talked to hayek about this

34:04.480 --> 34:08.320
And my recollection which is imperfect is that he found all this very interesting

34:08.800 --> 34:14.880
And in the spirit of his work and don levoi was leading this research paragraph. He died prematurely of cancer

34:16.000 --> 34:19.280
Uh bill tallow was also involved and some of this has been written up

34:20.160 --> 34:25.040
And it is very hayekian and george mason george mason actually was a pioneer in this area

34:25.760 --> 34:30.160
Well, what do you make of the agents the market between them and the sort of infrastructure and order that would uh

34:30.160 --> 34:33.520
That would need to facilitate that they're going to replicate markets on their own

34:33.600 --> 34:39.600
This has been my prediction and I think they're going to evolve their own currencies. Maybe at first they'll use bitcoin

34:40.640 --> 34:45.760
But there'll be an entire property rights will be based at least at first on what we now call nfts

34:46.400 --> 34:49.120
I'm not sure that will end up being the right name for them

34:49.680 --> 34:55.600
But if you want property rights in a so-called imaginary world, that's where you would start with bitcoin and nfts

34:56.320 --> 34:59.840
So I don't know what percent of gdp this will be at first it will be quite small

35:00.240 --> 35:06.000
But it will grow over time and it's going to show hayek to have been right that had these decentralized systems evolved

35:06.400 --> 35:12.880
Do you anticipate that it'll be sort of a completely different sphere and there's like the ai agents economy and there's a human economy

35:12.960 --> 35:14.960
And they obviously have links between them

35:15.360 --> 35:18.720
But it's not intermixed like they're not on the same social media or the same

35:19.520 --> 35:22.800
A task rabbit or whatever. It's like it's a very separate infrastructure that's needed to

35:23.520 --> 35:25.680
For the ai agents to talk to themselves versus talk to humans

35:26.000 --> 35:31.760
I don't see why we would enforce segregation now. You might have some segregated outlets like maybe x twitter

35:32.320 --> 35:36.080
Well, we'll keep off the bots. Let's say it can even manage to do that

35:36.560 --> 35:39.440
But if I want to hire, you know a proofreader

35:40.000 --> 35:43.680
I'm going to deal with the ai sector and pay them in bitcoin

35:44.320 --> 35:50.080
And I'll just say to my like personal ai assistant. Hey go out and hire an ai and pay them with whatever

35:50.480 --> 35:52.720
And then just not think about it anymore and it will happen

35:52.960 --> 35:57.840
Maybe because there's like much higher transaction costs with dealing with humans and interacting with the human world

35:58.000 --> 36:01.520
Whereas they can just send a bunch of vectors to each other. It's much faster for them to just

36:02.960 --> 36:05.040
Just like have a separate dedicated infrastructure for that

36:05.280 --> 36:10.480
And but transactions costs for dealing with humans will fall because you'll deal with their quote-unquote assistance, right?

36:11.200 --> 36:16.000
So you'll only deal with the difficult human when you need to and people who are very effective

36:16.240 --> 36:18.720
Will segregate their tasks in a way that reflects

36:19.200 --> 36:26.960
Their comparative advantage and people who are not effective will be very poor at that and that will lead to some kind of bifurcation of personal productivity

36:29.200 --> 36:35.120
Like how well do you know what to delegate to your ai? I'll predict you'll be very good at it. You may not have figured it out yet

36:36.480 --> 36:42.160
But say you're like a a plus on it and other people are d that's a big comparative advantage for you

36:42.400 --> 36:43.520
Hmm

36:43.520 --> 36:44.800
So you

36:44.800 --> 36:49.280
We're talking I guess about like gpt 5 level models. What do you think in your mind about like, okay?

36:49.360 --> 36:52.640
This is gpt 5. What happens with gpt 6 gpt 7? Do you see it?

36:53.120 --> 36:58.560
Or just do you still think in the frame of having a bunch of ras or does it seem like a different sort of thing at some point?

36:59.200 --> 37:01.440
I'm not sure with those numbers going up

37:02.240 --> 37:03.360
mean

37:03.360 --> 37:07.360
A what a gpt 7 would look like or how much smarter it could get

37:07.920 --> 37:09.920
Think people make too many assumptions there

37:10.240 --> 37:16.400
It could be the real advantages or integrating it into workflows by things that are not better gpt's at all

37:16.960 --> 37:19.600
And once you get to gpt say 5.5

37:20.320 --> 37:26.800
I'm not sure you can just turn up the dial on smarts and have it like integrate general relativity and quantum mechanics

37:26.880 --> 37:27.520
Why not?

37:27.520 --> 37:31.760
I don't think that's how intelligence works and this is a hacky and point and some of these problems

37:31.760 --> 37:36.880
There just may be no answer like maybe the universe isn't that legible and if it's not that legible

37:37.360 --> 37:39.360
the gpt 11

37:39.840 --> 37:42.960
Doesn't really make sense as a you know a creature or whatever

37:44.240 --> 37:48.240
Is isn't there a hacking argument to be made that listen you can have billions of copies of these things

37:48.880 --> 37:54.960
Imagine the sort of decentralized order that could result the amount of decentralized tasks of knowledge that billions of copies talking to each other could have

37:55.360 --> 37:58.000
That in and of itself is an argument to be made about

37:58.800 --> 38:03.680
The whole thing as a as an emergent order will be much more powerful than we were anticipating

38:04.080 --> 38:10.080
Well, I think it will be highly productive. What tacit knowledge means with a eyes. I don't think we understand yet

38:10.320 --> 38:12.320
Is it by definition all

38:12.320 --> 38:18.720
non tacit or does the fact that how gpt 4 works is not legible to us or even its creators so much

38:19.360 --> 38:23.600
Does that mean it's possessing of tacit knowledge or is it not knowledge?

38:23.920 --> 38:26.960
See none of those categories are well thought out in my opinion

38:27.520 --> 38:32.400
So we need to restructure our whole discourse about tacit knowledge in some new different way

38:32.800 --> 38:34.800
But I agree these networks

38:35.040 --> 38:39.200
Are they eyes even before like gpt 11? They're going to be super productive

38:39.760 --> 38:43.840
But they're still going to face bottlenecks, right? And I don't know how good they'll be

38:43.920 --> 38:49.760
It's a overcoming the behavioral bottlenecks of actual human beings the bottlenecks of the law and regulation

38:51.120 --> 38:53.920
And we're going to have more regulation as we have more a eyes, right? Yeah

38:54.160 --> 38:59.280
Well, when you say there'll be uncertainties, I think you made this argument when you were responding to alex fstein on fossil future

38:59.280 --> 39:04.800
Or you said the uncertainties also extend out into the domain where there's a bad outcome or a much bigger outcome than you're anticipating

39:04.880 --> 39:06.880
That's right. So can we apply the same?

39:07.440 --> 39:11.040
Argument to ai like the fact that there is uncertainty is also a reason for worry

39:12.000 --> 39:17.280
Well, it's always reason for worry, but there's uncertainty about a lot of things and ai will help us with those other uncertainties

39:17.920 --> 39:23.040
So annette, do you think more intelligence is likely to be good or bad including against x risk?

39:23.360 --> 39:25.360
And I think it's more likely to be good

39:25.920 --> 39:30.400
So if it were the only risk I'd be more worried about it than if there's a whole multitude of risks

39:30.800 --> 39:32.800
But clearly there's a whole multitude of risks

39:33.040 --> 39:35.280
But since people grew up in pretty stable times

39:35.600 --> 39:41.440
They tend not to see that in emotionally vivid terms and then this one monster comes along and they're all terrified

39:42.720 --> 39:44.720
What would hayek think of prediction markets?

39:45.680 --> 39:47.920
Well, there were prediction markets and hayek's time

39:47.920 --> 39:54.560
I don't know that he wrote about them, but I strongly suspect he would see them as markets that through prices communicate information

39:55.040 --> 39:57.520
But even at the like they're on the time of the civil war

39:57.600 --> 40:01.520
There were so-called bucket shops in the u.s. In new york where you would bet on things

40:02.160 --> 40:06.560
They were betting markets with cash settlement probably never called prediction markets

40:06.560 --> 40:11.200
But they were exactly that later on they were banned, but it's an old-standing thing

40:12.400 --> 40:17.440
There were betting markets on lives in uh 17th century britain different attempts to outlaw them

40:17.440 --> 40:22.240
Which I think basically ended up succeeding, but under the table. I'm sure it still went on to some extent

40:22.480 --> 40:23.040
Yeah

40:23.040 --> 40:27.440
The the reason it's interesting to think about this is because his whole argument about the price system is that

40:27.760 --> 40:30.560
You can have a single dial that aggregates so much information

40:30.640 --> 40:32.880
But it's precisely for this and that before that reason

40:32.880 --> 40:36.240
It's so useful to somebody who's trying to decide, you know, based on that information

40:36.240 --> 40:42.320
But it's precisely for this reason that it's so aggregated that it's hard to learn about any one particular input to that dial

40:42.400 --> 40:46.160
But I would stress it's not a single dial and whether hayek thought it was a single dial

40:46.480 --> 40:48.480
I think you can argue that either way

40:48.800 --> 40:52.800
So people in markets, they also observe quantities. They observe reaction speeds

40:53.200 --> 40:58.080
There's a lot of dimensions to prices other than just oh this newspaper cost four dollars

40:58.800 --> 41:00.800
Other terms on which it's advertised

41:01.200 --> 41:06.000
So markets work so well because people are solving this complex multidimensional problem

41:06.240 --> 41:12.560
And the price really is not a sufficient statistic the way it is in arahan debrew and I think at times hayek understood that

41:12.880 --> 41:16.720
And at other times he writes as if he doesn't understand it, but it's an important point

41:17.120 --> 41:18.720
Hmm

41:18.720 --> 41:23.760
Someone related question. What does it tell us about the difficulty of preserving good institutions? Good people?

41:24.800 --> 41:27.280
That the median age of a corporation is 18 years

41:27.920 --> 41:30.720
And they don't get better over time right decade after decade what corporation?

41:30.720 --> 41:34.240
There's rich corporations that continue improving in that way

41:34.720 --> 41:37.440
Well, I think some firms keep improving for a long time

41:37.440 --> 41:41.120
So there are japanese firms that date back to the 17th century

41:41.600 --> 41:45.920
Right, they must be better today or even in 1970 than they were a way back when

41:46.800 --> 41:48.800
Like the leading four or five danish firms

41:49.600 --> 41:51.360
None of them are

41:51.360 --> 41:53.360
younger than the 1920s

41:53.440 --> 41:54.960
So maersk

41:54.960 --> 41:58.400
You know the firm that came up with ozampic the pharmaceutical firm

41:59.280 --> 42:03.040
They must be much better than they were back then right they have to be

42:03.840 --> 42:04.880
So

42:04.880 --> 42:08.640
How that is possible to me is a puzzle, but I think in plenty of cases it's true

42:09.680 --> 42:11.680
It can really say that the

42:12.080 --> 42:15.520
The best firms in the world aren't ones that have been improving over time

42:16.000 --> 42:18.000
Uh

42:18.240 --> 42:21.600
You know if you look at the biggest companies in our market cap, it's not like this is what it

42:21.680 --> 42:24.480
You what it takes to get there is hundreds of years of continual refinement

42:25.040 --> 42:28.320
Uh, what does that tell us about the world or just as well hundreds of years?

42:28.400 --> 42:32.400
But again, don't be overly biased by the us experience and the tech sector

42:32.800 --> 42:34.800
There's around the world plenty of firms

42:35.280 --> 42:38.240
That at least seem to get better as they get older

42:38.640 --> 42:42.160
Certainly their market cap goes up some of that might just be a population effect

42:42.560 --> 42:46.400
Maybe their productivity per some unit is in some ways going down

42:47.120 --> 42:49.120
Uh, but that's a very common case

42:49.360 --> 42:54.960
And why the us is such an outlier is an interesting question right israel clearly is an outlier

42:55.440 --> 42:57.200
In a sense, they only

42:57.200 --> 43:00.880
Have pretty young firms right and they've done very well in terms of growth

43:01.200 --> 43:03.040
Can you be explained by the fact that in these other countries?

43:03.040 --> 43:06.720
It's actually just harder to start a new company not necessarily the older companies are actually getting better

43:07.920 --> 43:11.920
Uh possibly but it does seem the older companies are often getting better right like in danmark

43:13.120 --> 43:15.280
So, you know, take china is

43:16.240 --> 43:19.120
Pretty much entirely new firms because of communism

43:19.920 --> 43:22.720
Japan in particular seems to have a lot of very old firms

43:23.040 --> 43:26.720
I don't know if they're getting better, but I don't think you can write that off as a possibility

43:28.160 --> 43:32.560
This is hayak in competition as a discovery process and it seems like you predicted nimbyism

43:32.880 --> 43:34.880
So he says in a democratic society

43:35.120 --> 43:41.760
It would be completely impossible using commands that could not be regarded as just to bring about those changes

43:41.840 --> 43:47.680
That are undoubtedly necessary, but the necessity of which could not be strictly demonstrated in a particular case

43:48.400 --> 43:51.920
Uh, so it seems like he's kind of talking about what we today call nimbyism

43:52.560 --> 43:54.880
It's sure and there's plenty of nimbyism in earlier times

43:55.200 --> 43:58.480
You look at the 19th century debates over restructuring paris

43:59.040 --> 44:01.760
Housemen and putting in the broader boulevards and the like

44:02.400 --> 44:06.080
That met with very strong opposition. It's a kind of miracle that it happened. Yeah

44:07.280 --> 44:10.000
Is this is this a thing that's inherent to the democratic system?

44:10.000 --> 44:13.760
I recently interviewed dominant Cummings and obviously planning is a big issue in the uk

44:14.080 --> 44:19.200
It seems like every country has every democratic country has this kind of problem and most autocratic countries have it too

44:19.600 --> 44:25.200
Now china is an exception. They will probably slide into some kind of nimbyism even if they stay autocratic

44:26.080 --> 44:27.360
um

44:27.360 --> 44:32.480
Just people resist change interest groups always matter public opinion a la david hum always matters

44:33.360 --> 44:34.640
and uh

44:34.640 --> 44:39.040
It's easy to not do anything on a given day, right and that just keeps on sliding into the future

44:40.720 --> 44:44.080
So but not in the i guess india has had a lot of nimbyism

44:44.160 --> 44:48.800
It's fallen away greatly under modi and especially what the state governments have done

44:49.680 --> 44:52.320
But it's can be very hard to build things in india still

44:53.760 --> 44:56.960
Although it is a democracy. I guess the china example. We'll see what happens there

44:57.600 --> 45:00.320
That's right. Uh, but it would be very surprising

45:01.280 --> 45:06.080
Because the chinese government is highly responsive to public opinion on most but not all issues

45:06.640 --> 45:10.480
So why wouldn't they become more nimby especially with the shrinking population?

45:10.960 --> 45:14.320
They're they're way overbilled, right? So the pressure to build will be weak

45:14.720 --> 45:17.920
And in cases where they ought to build I would think quite soon. They won't

45:19.600 --> 45:26.160
How how much of economics is a study of the uh, the systems that human beings use to allocate scarce resources

45:26.160 --> 45:29.760
And how much is is just something you'd expect to true be true of aliens ai's

45:30.720 --> 45:33.680
It's interesting when you read the history of economic thought how often they make

45:34.640 --> 45:40.560
Um, they make mention of human nature specifically like canyons is talking about the people have high discount rates, right?

45:42.560 --> 45:51.440
Yeah, but what are your thoughts here my former colleague gordon tallick wrote a very interesting book on the economics of ant societies and animal societies

45:52.320 --> 45:58.640
And very often they obey human like principles or more accurately humans obey non-human animal like principles

45:59.200 --> 46:04.640
So I suspect it's fairly universal and depends less on quote-unquote human nature

46:05.040 --> 46:10.160
Then we sometimes like to suggest maybe that is a bit of a knock on some behavioral economics

46:11.040 --> 46:14.880
The logic of the system arman elshin wrote on this gary becker wrote on this

46:15.200 --> 46:20.800
There was some debates on this in the early 1960s and that the automatic principles of profit and loss

46:21.440 --> 46:23.440
and selection at a firm

46:23.840 --> 46:25.280
Firm-wide level

46:25.280 --> 46:29.760
Really matters and it's responsible for a lot of economics being true. I think that's correct

46:30.240 --> 46:32.240
actually that raises an interesting question of

46:32.320 --> 46:38.480
Uh, within firms they the sort of input they're getting from the outside world the ground truth data is

46:38.960 --> 46:40.960
profit loss bankruptcy. It's like very

46:41.760 --> 46:46.400
Uh, very condensed information and from this they had to make the determination of who to fire who to hire who to promote

46:46.560 --> 46:48.560
What project to pursue?

46:49.120 --> 46:54.160
Uh, you know, how do you make sense of how firms disaggregate this this very condensed information?

46:54.800 --> 46:59.520
I would like to see a very good estimate of how much your productivity gains is just from selection

47:00.160 --> 47:03.600
And how much is from while smart humans figure out better ways of doing things

47:04.800 --> 47:08.560
And there's some related pieces on this in the international trade literature

47:08.800 --> 47:13.360
So when you have free or trade a shockingly high percentage of the productivity gains

47:13.920 --> 47:16.720
Come from your worst firms being bankrupted by the free trade

47:17.440 --> 47:20.080
And alex tabarak has some mr posts on this

47:20.480 --> 47:22.080
I don't recall the exact numbers

47:22.080 --> 47:29.520
But it was higher than almost anyone thought and that to me suggests the alchi and becker mechanisms of evolution at the level of the firm

47:30.000 --> 47:31.840
Enterprise or even sector

47:31.840 --> 47:36.080
They're just a lot more important than human ingenuity and that's a pretty hayekian point

47:36.560 --> 47:40.720
Hayek presumably read those pieces in the 60s. I don't think he ever commented on them

47:41.520 --> 47:43.040
interesting

47:43.040 --> 47:45.040
Let's talk about uh mill

47:46.000 --> 47:48.000
uh

47:49.840 --> 47:55.760
So his arguments about uh the law force against uh woman and how basically throughout history

47:56.160 --> 48:01.520
The the the state of uh woman in in his society is not natural or the wisdom of the ages

48:01.520 --> 48:04.720
But just the result of the fact that men are stronger and have codified that

48:05.120 --> 48:08.640
Can you apply that argument into today's society against children and the way we treat them?

48:09.760 --> 48:14.240
Yes, I think we should treat children much better. We've made quite a few steps in that direction

48:14.640 --> 48:17.760
It's interesting to think of mill's argument as it relates to hayek

48:18.560 --> 48:23.280
So mill is arguing you can see more than just the local information. So keep in mind when mill wrote

48:24.000 --> 48:28.480
Every society that he knew of at least treated women very poorly oppressed women

48:29.120 --> 48:31.920
Women because they were physically weaker or at a big disadvantage

48:32.160 --> 48:37.120
If you think there's some matrilineal exceptions mill didn't know about them. So it appeared universal

48:37.920 --> 48:40.960
And mill's chief argument is to say you're making a big mistake

48:41.680 --> 48:47.840
If you overly aggregate information from this one observation that behind it is a lot of structure

48:48.160 --> 48:53.280
And a lot of the structure is contingent and that if i mill unpack the contingency for you

48:53.840 --> 48:55.840
You will see behind the signals

48:56.240 --> 49:00.720
So mill is much more rationalist than hayek. It's one reason why hayek hated mill

49:01.280 --> 49:03.280
But clearly on the issue of women

49:03.520 --> 49:07.840
Mill was completely correct that women can do much better will do much better

49:08.240 --> 49:12.640
It's not clear what the end of this process will be. It will just continue for a long time

49:14.080 --> 49:16.080
Women achieving in excellent ways

49:16.800 --> 49:22.320
And it's mill's greatest work. I think it's one of the greatest pieces of social social science and it is anti hayekian

49:23.200 --> 49:25.200
It's anti small c conservatism

49:26.080 --> 49:31.520
His other book on liberty is very hayekian though, right in the sense that the free speech is needed because information is

49:32.240 --> 49:35.200
Is it contained in many different people's minds? That's right

49:35.280 --> 49:38.320
And I think mill integrated sort of you could call it hayek

49:38.800 --> 49:43.680
An anti hayek better than hayek ever did. That's why I think mill is the greater thinker of the two

49:45.040 --> 49:47.040
But but on the topic of children

49:47.680 --> 49:51.440
What wouldn't mill say specifically? I guess you could have talked about it if you wanted to but

49:51.760 --> 49:55.600
I don't know if you was in today's world. We sent into school. They're there for eight hours a day

49:55.840 --> 49:57.840
Most of the time is probably wasted

49:58.080 --> 50:02.400
And we just like use a lot of coercion on them that we don't need to how would we think how would he think about this issue?

50:03.200 --> 50:07.760
There's mill's own upbringing, which was quite strict and by current standards oppressive

50:08.160 --> 50:11.200
But apparently extremely effective in making mill smart

50:12.000 --> 50:16.080
So I think mill very much thought that kids should be induced

50:16.720 --> 50:18.720
to learn the classics

50:18.720 --> 50:21.600
But he also stressed they needed free play of the imagination

50:22.080 --> 50:28.560
In a way that he drew from german and also british romanticism and he wanted some kind of synthesis of the two

50:29.200 --> 50:34.160
Uh, but by current standards mill. I think still would be seen as a meanie toward kids

50:34.240 --> 50:36.640
But he was progressive by the standards of his own day

50:36.960 --> 50:42.000
Do you buy the arguments about aristocratic tutoring for people like mill and um, there's many other cases like this

50:42.000 --> 50:47.280
But that you know, since they were kids they were taught in the taught by one-on-one tutors and that's that explains part of their

50:48.160 --> 50:49.520
greatness

50:49.520 --> 50:54.320
I believe in one-on-one tutors, but I don't know how much of those examples is selection, right?

50:54.800 --> 50:56.800
So i'm not sure how important it is

50:57.280 --> 51:01.920
But just as a matter of fact if I were a wealthy person and just had a new kid

51:02.000 --> 51:07.520
I would absolutely invest in one-on-one tutors. Hmm. You're talking the book about how mill is very concerned about the

51:08.320 --> 51:10.400
quality and the character development of the population

51:11.120 --> 51:15.840
Uh, but when we think about the fact that somebody like him was elected to the parliament at the time

51:15.920 --> 51:18.720
the greatest thinker who's alive is elected to uh, to uh,

51:19.920 --> 51:23.280
To government and it's hard to imagine that could be true in with

51:24.000 --> 51:28.000
Today's world does he have a does he have a point with the regards to the quality of the population?

51:29.200 --> 51:32.560
Well mill as with women he thought a lot of improvement was possible

51:32.800 --> 51:38.000
Yeah, and we shouldn't overly generalize from seeing all the dunces around us. Yeah, so to speak

51:38.640 --> 51:41.120
Uh, maybe the the book is still out on that one

51:42.560 --> 51:46.240
But it's an encouraging belief and I think it's more right than wrong

51:46.320 --> 51:51.600
There's been a lot of moral progress since mill's time right and everything but certainly how people treat children

51:52.480 --> 51:55.280
and or their their why how men treat their wives

51:56.720 --> 51:58.640
and uh

51:58.640 --> 52:00.640
Even when you see negative reversals

52:01.360 --> 52:04.080
Stephen pinker so far seems to be right on that one

52:04.720 --> 52:08.000
But you do see places, you know, like Iran how women were treated

52:08.880 --> 52:13.200
Seems to have been much better in the 1970s than it is today. So there are definitely reversals

52:13.440 --> 52:19.680
but on the specific reversal of somebody of mill's quality probably wouldn't get elected to congress in the us or

52:20.000 --> 52:27.040
Parliament of the uk. Is it how how big a deal is that advice may get through the cracks due to all the local statesmen who wisely advise

52:27.680 --> 52:30.320
their representatives in the house, right? So

52:32.400 --> 52:36.960
I don't know how much that process is better or worse compared to say the 1960s

52:37.120 --> 52:41.120
I know plenty of smart people who think it's worse. I'm not convinced that's true. Hmm

52:42.080 --> 52:44.080
Let's talk about smith

52:44.080 --> 52:46.080
Adam smith. Yeah

52:46.640 --> 52:48.160
um

52:48.160 --> 52:54.720
Okay, so the one of the things I find really remarkable about him is he so he publishes in 1776 the wealth of nations

52:55.040 --> 52:58.880
And basically around that time gibbon publishes the decline and fall of the roman empire. Yep

52:59.360 --> 52:59.760
um

52:59.760 --> 53:04.720
So he publishes the decline and fall of the roman empire and one of his lines in there is if if you were asked to

53:05.280 --> 53:09.840
It stayed a period of time and man's condition was what is his best? It was you know during the reign of comotas to demission

53:10.320 --> 53:15.760
Uh, and that's like 2000 years before that, right? So there's basically been at least it's like plausible to somebody really smart

53:15.760 --> 53:18.480
That there's basically been no growth since for 2000 years

53:18.960 --> 53:23.280
Uh and in that context to be making the case or markets and mechanization and division of labor

53:23.440 --> 53:27.200
I think it's like even more impressive when you when you put it in the context that he has like basically been seeing

53:27.520 --> 53:29.520
You know 0.5 percent or less growth

53:29.520 --> 53:35.760
Strongly agree and this is in a way smith being like mill. Yeah smiths is seeing the local information of very small growth

53:36.320 --> 53:38.960
And the world barely being better than the roman empire

53:39.520 --> 53:44.080
And inferring from that with increasing returns division of labor how much is possible

53:44.880 --> 53:48.400
So smith is a bit more of a rationalist than hyac makes him out to be right

53:49.360 --> 53:53.200
Now I I wonder if we use the same sort of

53:53.840 --> 53:57.040
Extrapolative thinking that smith uses of we haven't seen that much growth yet

53:57.040 --> 54:00.640
But if you apply these sorts of principles, uh, this is what you would expect to see

54:01.120 --> 54:04.480
What would he make of the potential ai economy where we see two percent growth?

54:05.040 --> 54:08.640
A year now, but you have you know billions of potential more agents or something

54:08.880 --> 54:14.320
Would he say well actually you might have 10 growth because of this like this is a you would need more economic principles to explain this

54:14.800 --> 54:18.560
Or that just adding that to our list of existing principles would imply big gains

54:19.520 --> 54:22.240
It's hard to say what smith would predict for ai

54:22.800 --> 54:27.200
My suspicion is that the notion of 10 growth was simply not conceivable to him

54:27.600 --> 54:33.840
So he wouldn't have predicted it because he never saw anything like it that to him three percent growth would be a bit like

54:34.480 --> 54:36.640
10 growth it would just shock him

54:37.280 --> 54:39.280
And and bold him over

54:39.840 --> 54:44.720
But smith does also emphasize different human bottlenecks and constraints of the law

54:45.840 --> 54:51.440
So it's quite possible smith would see those bottlenecks as mattering and checking ai growth and its speed

54:52.640 --> 54:56.240
But as a principle given the change we saw pre

54:57.360 --> 54:59.360
pre-industrial revolution and after 1870

54:59.600 --> 55:00.560
Um

55:00.560 --> 55:06.320
Does does that does to you it seemed plausible that you could go from the current regime to a regime where you have 10 growth

55:06.320 --> 55:08.320
for decades on end

55:08.320 --> 55:11.120
That does not seem plausible to me, but I would stress the point

55:11.840 --> 55:15.600
That high rates of growth decades on end the numbers cease to have meaning

55:16.320 --> 55:19.920
Because the numbers make the most sense when the economy is broadly similar

55:20.400 --> 55:25.120
Like oh everyone eats apples and each year there's 10 more apples at a roughly constant price

55:25.600 --> 55:30.320
As the basket changes the numbers become meaningless. It's not to deny. There's a lot of growth

55:31.040 --> 55:34.240
Uh, but you can think about it better by discarding the number

55:34.800 --> 55:39.120
And presumably ai will change the composition of various bundles quite a bit over time

55:39.600 --> 55:43.440
So when you hear these estimates about what the gdp per capita was in the roman empire

55:43.440 --> 55:46.640
Do you just disregard that and think in terms of qualitative changes from that time?

55:47.520 --> 55:49.520
Depends what they're being compared to

55:50.080 --> 55:57.120
So there's pieces in economic history that are looking at say 17th 18th century europe comparing it to the roman empire

55:57.280 --> 56:00.720
Most of gdp's agriculture, which is pretty comparable, right?

56:01.680 --> 56:05.200
Especially in europe, it's not wheat versus corn. It's wheat and wheat

56:06.400 --> 56:09.280
And i've seen estimates that i'll say by 1730

56:09.920 --> 56:15.040
Some parts of western europe are clearly better off than the roman empire at its peak, but like within range

56:15.840 --> 56:19.280
That those are the best estimates. I know and I trust those they're not perfect

56:20.080 --> 56:22.480
But I don't think there's an index number problem so much

56:22.560 --> 56:23.680
Hmm

56:23.680 --> 56:26.640
And so when people say we're 50 percent richer than

56:27.200 --> 56:29.760
An average roman at the peak of the empire you

56:30.000 --> 56:32.720
You but this this kind of thinking doesn't make sense to you

56:32.800 --> 56:36.560
It doesn't make sense to me and a simple way to show that let's say you could buy

56:37.280 --> 56:39.280
From the sears robot catalog of today

56:39.520 --> 56:45.840
Yeah, or from 1905 and you have $50,000 to spend which catalog would you rather buy from?

56:47.280 --> 56:49.280
You have to think about it, right?

56:49.520 --> 56:55.200
Now if you just look at changes in the cpi, it should be obvious you would prefer the catalog from 1905

56:55.440 --> 56:58.720
Everything's so much cheaper that white shirt costs almost nothing

56:59.520 --> 57:03.600
Right at the same time. You don't want that stuff. It's not mostly part of the modern bundle

57:04.080 --> 57:10.000
So even if you ended up preferring the earlier catalog the fact that you have to think about it reflects the ambiguities

57:11.440 --> 57:15.520
When you read the contemporaries of smith other economists were writing at the time

57:15.760 --> 57:17.760
Uh, were his arguments

57:18.560 --> 57:24.800
Just, uh, clearly given the evidence at the time much better than everybody around or was it just that expose to is clearly right

57:24.880 --> 57:28.480
But given the arguments at the time it could have gone any one of different ways

57:29.760 --> 57:33.680
Well, there aren't that many economists at the time of smith, so it depends what you're counting

57:34.400 --> 57:37.920
I mean the two fellow scots you could compare smith to or sir james stewart

57:38.400 --> 57:41.440
Who published a major work? I think in 1767

57:42.000 --> 57:46.880
On some matters stewart was ahead of smith not most clearly smith was far greater

57:47.280 --> 57:53.040
But stewart was no slouch and the other point of comparison is david hume smith's best friend, of course

57:53.840 --> 57:58.800
Uh per page you could argue. Hume was better than smith certainly on monetary theory. Hume was better than smith

57:59.600 --> 58:02.080
Now he's not a goat contender. He just didn't do enough

58:02.880 --> 58:08.640
But I wouldn't say smith was ahead of hume. He had more and more important insights

58:09.440 --> 58:15.200
But hume was pretty impressive now if you're talking about oh like the 18th century german camera lists

58:15.840 --> 58:17.200
uh

58:17.200 --> 58:22.160
Well, they were bad mercantilists, but there's people say writing in sweden in the 1760s

58:22.880 --> 58:27.440
Analyzing exchange rates who had better understandings of exchange rates than smith ever did

58:27.840 --> 58:29.840
So it's not that he just dominated everyone

58:30.640 --> 58:32.000
um

58:32.000 --> 58:37.360
Let me offer some other potential nominees that were not in the book for goat and I want your opinions of them

58:37.840 --> 58:44.480
um, henry george in terms of explaining how land is fundamentally different from labor and capital when we're thinking about the economy

58:45.200 --> 58:50.160
Well, first i'm not sure land is that fundamentally different from labor and capital a lot of the value of land

58:50.560 --> 58:56.880
Comes from improvements and what's an improvement can be quite subtle. It doesn't just have to be you know putting a plow to the land

58:57.680 --> 59:00.480
So I would put george in the top 25

59:01.040 --> 59:02.720
very important thinker

59:02.720 --> 59:04.720
but he's a bit of a

59:04.800 --> 59:09.840
Not a one-note johnny his book on protectionism is still one of the best books on free trade

59:10.560 --> 59:13.600
But he circumscribed in a way say smith and mill were not

59:14.880 --> 59:16.320
uh

59:16.320 --> 59:23.600
Today is he uh, uh, would does the status rise we see rents in big cities status is way up for this reason right of yinbi nimbi

59:23.680 --> 59:25.680
And I think that's correct. He was undervalued

59:26.320 --> 59:28.320
He's worth reading very carefully

59:28.800 --> 59:31.440
A few years ago. We're recording here at mercatus. We had a

59:32.320 --> 59:37.840
Like 12 person two day session with peter teal just on reading henry george. It's all we did

59:38.720 --> 59:41.120
And people came away. Uh, very impressed. I think

59:42.000 --> 59:47.040
I didn't for people who are interested. They might enjoy the episode I did with larce du set. Uh, who oh, I don't know about this

59:47.200 --> 59:52.160
He's a georgist. Oh, yeah, he's uh, uh, he's he's a really smart guy. He wrote

59:52.800 --> 59:57.040
Uh, basically he he wrote a book review of henry george that once got alexander's book review contest

59:57.280 --> 01:00:00.480
Oh, I know what this is and then he's just turned it into a whole book of his own

01:00:00.640 --> 01:00:05.920
Which is actually really good. Um, and I think there's something truly humane in george when you read him

01:00:06.320 --> 01:00:08.720
That can be a bit infectious. That's positive. Um

01:00:10.240 --> 01:00:11.280
And

01:00:11.280 --> 01:00:15.040
It's some insane there was some insane turnout for his funeral, right? Like he was he was very popular at the time

01:00:15.040 --> 01:00:19.440
He wrote yeah, and that was deserved. Yeah, uh, I guess you already answered this question

01:00:19.440 --> 01:00:25.040
But ronal cos in terms of helping us think about firms and you know property rights and transaction costs

01:00:25.360 --> 01:00:30.640
Well, even though I think the 1937 piece is wrong. It did create one of the most important genres

01:00:30.960 --> 01:00:34.640
He gets a lot of credit for that. He gets a lot of credit for the coast theorem

01:00:35.040 --> 01:00:41.360
The fcc property rights piece is superb. The lighthouse piece is very good. Again, he's in the top 25

01:00:41.840 --> 01:00:44.560
But in terms of you like his quantity its own quality

01:00:45.360 --> 01:00:48.320
It's just not quite enough. There's no macro

01:00:49.120 --> 01:00:53.280
Oh, but of course you rate him very very highly. How about your former advisor thomas shelling?

01:00:53.280 --> 01:01:00.720
He is a top tier noble laureate, but I don't think he's a serious contender for greatest economist of all time

01:01:01.120 --> 01:01:07.120
He gets the most credit for making game theory intuitive empirical and workable and that's worth a lot

01:01:09.120 --> 01:01:15.200
Uh economics of self command he was a pioneer, but in a way that's just going back to the greeks and smith

01:01:16.480 --> 01:01:20.320
He's not a serious contender for goat, but a top tier noble laureate for sure

01:01:20.480 --> 01:01:26.800
You have you have a fun quote in uh in the book on aro where you say his work was a noble prize winning important

01:01:26.800 --> 01:01:28.800
But not important important

01:01:29.200 --> 01:01:32.640
Well some parts of it were important important like how to price securities

01:01:33.520 --> 01:01:37.840
So I think I underrated aro a bit in the book if you ask like what regrets do I have about the book?

01:01:38.640 --> 01:01:42.560
I say very very nice things about aro, but I think I should have pushed him even more

01:01:42.800 --> 01:01:44.800
What would aro say about prediction markets?

01:01:45.120 --> 01:01:48.880
Well, he was really the pioneer of theoretically understanding how they work

01:01:48.960 --> 01:01:50.960
Yeah, so uh

01:01:51.680 --> 01:01:57.440
He was around until quite recently. I'm sure he had things to say about prediction markets probably positive. Hmm

01:01:58.160 --> 01:02:00.160
um

01:02:00.160 --> 01:02:06.240
Uh you so one of the points you make in the book is economics at the time was really a way of carrying forward big ideas about the world

01:02:06.640 --> 01:02:11.680
What discipline today is where that happens? Well internet writing. It's not a discipline

01:02:11.920 --> 01:02:15.440
But it's a sphere and plenty of it happens more than ever before

01:02:16.000 --> 01:02:20.720
But it's segregated from what counts as original theorizing in the academic sense of that word

01:02:21.680 --> 01:02:23.920
Is that a good or bad segregation? I'm not sure

01:02:25.200 --> 01:02:31.680
But it's really a very sharp radical break from how things had been and it's why I don't think there'll be a new goat contender

01:02:31.920 --> 01:02:35.360
Probably not ever or if there is it will be something ai related

01:02:35.920 --> 01:02:42.080
Hmm. Yeah, that's that sounds about right to me. Um, but within the context of internet writing, obviously, there's many disciplines there

01:02:42.640 --> 01:02:44.640
economics being a prominent one

01:02:44.880 --> 01:02:46.000
uh

01:02:46.000 --> 01:02:51.440
When you split it up, is there a discipline in terms of I don't know people writing in terms of computer science concepts

01:02:51.440 --> 01:02:54.160
Or people writing in terms of economic concepts. Who is today?

01:02:55.120 --> 01:02:59.200
The discipline ceased to matter that really good internet writing is multi disciplinary

01:02:59.680 --> 01:03:04.480
When I meet someone like a scott arinson who's doing like computer science ai type

01:03:04.880 --> 01:03:08.400
Internet writing on his blog. I have way more in common with him

01:03:09.040 --> 01:03:12.800
than with a typical research economist say at boston university

01:03:13.200 --> 01:03:14.880
and it's not because

01:03:14.880 --> 01:03:18.560
I know enough about computer science like I may or may not know a certain amount

01:03:18.800 --> 01:03:25.040
But it's because our two enterprises are so similar or scott alexander. He writes about mental illness also

01:03:25.920 --> 01:03:27.920
That just feels so similar

01:03:27.920 --> 01:03:31.920
And we we really have to rethink what the disciplines are. It may be that method of writing

01:03:32.400 --> 01:03:38.320
Is the key differentiator for this particular sphere. Yeah, it's got everything scott arinson was my professor in college

01:03:38.560 --> 01:03:40.560
Oh, that's great. Yeah. Yeah

01:03:40.800 --> 01:03:44.800
Um, that's where I decided i'm not going to go to grad school because you just see

01:03:45.520 --> 01:03:47.920
Because you see like two standard deviations above you easily

01:03:48.320 --> 01:03:50.480
Uh, you know, you might as well just choose a different game

01:03:50.880 --> 01:03:56.720
But his method of thinking and writing is infectious like that of scott alexander and many of the rest of us. Yeah

01:03:57.520 --> 01:03:58.800
um

01:03:58.800 --> 01:04:06.000
So I think in the book you say you were raised as much by uh economic thought or the history of economic thought as you are

01:04:06.160 --> 01:04:09.520
By your graduate training more much more not it's not even close

01:04:10.320 --> 01:04:13.040
Today people would say I was talking to basal hopper and who's a

01:04:13.600 --> 01:04:18.080
Young economist and he said he was raised on martial revolution in the same way that you were raised on the history of economic

01:04:18.080 --> 01:04:20.080
Talk thought how do you?

01:04:20.720 --> 01:04:22.560
Does this seem like a good trade?

01:04:22.560 --> 01:04:26.880
Are you happy that people today are raised on scott alexander and martial revolution at the margin?

01:04:26.960 --> 01:04:29.840
I would like to see more people raised on marginal revolution

01:04:29.920 --> 01:04:33.680
I don't just mean that in a selfish way but the internet writing mode of thinking

01:04:34.080 --> 01:04:38.000
I would like to see more economists and research scientists raised on it

01:04:38.400 --> 01:04:42.080
But the number may be higher than we think like if I hadn't run emergent ventures

01:04:42.160 --> 01:04:45.760
I wouldn't know about basal per se. Maybe you would not have met him

01:04:46.640 --> 01:04:47.920
And it's infectious

01:04:47.920 --> 01:04:52.320
So it might always be a minority, but it will be the people most likely to have new ideas

01:04:52.960 --> 01:04:57.360
And it's a very powerful new mode of thought which I'll call internet way of writing and thinking

01:04:58.080 --> 01:05:02.480
And it's not sufficiently recognized as something like a new field or discipline, but that's what it is

01:05:03.840 --> 01:05:07.680
I wonder if you're doing enough of that when it comes to ai where I think you have really interesting thoughts about gpd

01:05:07.680 --> 01:05:12.080
Five-level stuff, but this has somebody with your sort of polymathic understanding or different fields

01:05:13.040 --> 01:05:17.440
If you just like extrapolate out these trends, I feel like you might have a lot of interesting thoughts about when you think

01:05:17.760 --> 01:05:20.720
Just in terms of what might be possible with something much further down the line

01:05:21.440 --> 01:05:26.880
Well, I have a whole book with ai predictions averages over and I have about 30 bloomberg columns

01:05:27.520 --> 01:05:32.560
And probably 30 or 40 marginal revolution posts. I can just say I'll do more

01:05:33.360 --> 01:05:39.280
Uh, but the idea at which ideas arrive at me is the binding constraint. I'm not holding them back

01:05:40.080 --> 01:05:46.480
Um, speaking of basal, he had an interesting question. Should um, should should society

01:05:47.120 --> 01:05:52.160
Uh, or government subsidize savings so that we're in effect having, uh,

01:05:53.280 --> 01:05:58.720
It leads to basically a zero social discount rate. So it's people on average. I probably have, you know, uh,

01:05:59.520 --> 01:06:03.360
The they're they're prioritizing their own lives. They have discount rates based on their own lives

01:06:03.760 --> 01:06:07.040
Uh, if we're long term, I should the government be subsidizing savings

01:06:07.360 --> 01:06:13.680
I'll come close to saying yes. First, we tax savings right now. So we should stop taxing savings. Absolutely

01:06:14.320 --> 01:06:18.640
I think it's hard to come up with workable ways of subsidizing savings

01:06:19.120 --> 01:06:24.640
That don't give rich people a lot of free stuff in a way that's politically unacceptable and also unfair

01:06:25.360 --> 01:06:28.400
So i'm not sure we have a good way of subsidizing savings

01:06:28.880 --> 01:06:32.400
But in principle, I would be for it if we could do it in the proper targeted manner

01:06:33.280 --> 01:06:39.760
Although you had a good argument against this in stubborn attachments, right that over the long term if the if economic growth is high enough

01:06:39.760 --> 01:06:44.480
Then the savings of the rich will just be, uh, dissipated to everybody below

01:06:45.360 --> 01:06:50.960
Well, i'm not sure to whom it's dissipated. It does get dissipated the great fortunes of the past are mostly gone

01:06:51.760 --> 01:06:53.760
But they may not go to people below

01:06:54.400 --> 01:07:00.400
And the idea of writing into a tax system subsidies on that scale in essence subsidies to wealth

01:07:00.880 --> 01:07:07.520
Not not gdp, but wealth is say six to eight times gdp. I just think the practical problems are quite significant

01:07:07.600 --> 01:07:09.600
It's not an idea i'm pushing

01:07:09.600 --> 01:07:11.920
But there may at margins be ways you can do it

01:07:12.880 --> 01:07:18.320
That say only benefit uh people who are poor ways you can improve like the workings of

01:07:18.640 --> 01:07:25.840
Local credit unions through better either regulation deregulation that are a kind of de facto subsidy without having to subsidize

01:07:26.320 --> 01:07:27.840
All of the saved wealth

01:07:27.840 --> 01:07:30.800
There's got to be a lot of ways you can do that and we should look for that more

01:07:31.360 --> 01:07:37.440
Relatedly, uh, I think a couple years ago paul schlemming had an interesting paper that if you look from 1311 to now

01:07:38.240 --> 01:07:45.440
Interest rates have been declining. There's been hundreds of years of interest rate declines. What what is the big picture explanation of this trend?

01:07:46.320 --> 01:07:51.280
I'm not sure we have one. You may know cow and third law all propositions of real interest rates are wrong

01:07:51.680 --> 01:07:55.440
But simply lower risk better information higher buffers of wealth

01:07:56.160 --> 01:07:58.160
Would be what you'd call the intuitive

01:07:58.720 --> 01:08:01.680
Economistic explanations. There's probably something to them

01:08:02.160 --> 01:08:08.560
But how much of that trend do they actually explain as like a percent of the variance? I don't know. Hmm. Let's talk about anarchy

01:08:09.120 --> 01:08:13.440
Yeah, you you you VV first about this. I hadn't read the last time we talked and they're really interesting

01:08:13.840 --> 01:08:15.360
um, so

01:08:15.840 --> 01:08:18.080
Maybe you can restate your arguments as you answer this question

01:08:18.400 --> 01:08:23.280
But how much of your arguments about how network industries lead to these cartel like dynamics?

01:08:23.680 --> 01:08:28.240
How much of that can help explain what happened to social media web 2.0?

01:08:28.880 --> 01:08:34.880
I don't view that as such a cartel. I think there's a cartel at one level which is small but significant

01:08:35.840 --> 01:08:40.560
This is maybe more true three four years ago than today with elan owning twitter and other changes

01:08:40.720 --> 01:08:43.280
But if someone got kicked off social media platforms

01:08:44.000 --> 01:08:47.760
Three four years ago. They would tend to get kicked off all or most of them

01:08:48.320 --> 01:08:50.320
It wasn't like a consciously

01:08:50.880 --> 01:08:57.440
Collusive decision, but it's a bit like oh, well, I know the guy who runs that platform and he's pretty smart and if he's worried

01:08:57.440 --> 01:08:59.440
I should be worried

01:08:59.440 --> 01:09:01.440
And that was very bad

01:09:01.440 --> 01:09:05.760
I don't think it was otherwise such a collusive equilibria. Maybe some dimensions on hiring

01:09:06.800 --> 01:09:08.480
Uh, social

01:09:08.480 --> 01:09:13.120
You know people software engineers. There was some collusion not enough bidding

01:09:13.920 --> 01:09:16.480
But it was mostly competing for attention

01:09:17.440 --> 01:09:23.120
So I think the real risk protection agencies aside of network based collusion is through banking systems

01:09:23.600 --> 01:09:26.080
Where you have clearing houses and payments networks

01:09:26.800 --> 01:09:32.160
And to be part of it the clearing house in the absence of legal constraint can indeed

01:09:32.640 --> 01:09:37.120
Help everyone collude and if you don't go along with the collusion you're kicked out of the payment system

01:09:37.920 --> 01:09:39.920
That strikes me as a real issue

01:09:40.560 --> 01:09:46.560
Do your arguments against anarchy do they apply it all to a web 3.0 crypto like stuff?

01:09:48.480 --> 01:09:54.320
Do I think it will evolve into collusion? I don't see why it would I'm open to hearing the argument that it could though

01:09:54.480 --> 01:09:56.480
What would that argument go like?

01:09:57.040 --> 01:09:59.280
Well, I guess we did see with crypto that you have

01:10:01.360 --> 01:10:05.680
In order to just have workable settlement you needed these centralized institutions

01:10:06.080 --> 01:10:10.080
And from there you can get kicked off those and the government is involved with those and you can

01:10:10.880 --> 01:10:15.680
You can maybe abstract the government away and say that they will need to collude in some sense in order to facilitate transactions

01:10:15.920 --> 01:10:18.640
And the exchanges have ended up quite centralized, right? Yeah

01:10:19.200 --> 01:10:23.520
Uh, and that's an example of clearing houses and exchanges being the vulnerable node

01:10:23.840 --> 01:10:27.040
But I don't know how much web 3.0 is ever going to rely on that

01:10:27.680 --> 01:10:34.160
It seems you can create new crypto assets more or less. It will there's the focality of getting them started

01:10:35.120 --> 01:10:40.240
But if there's a real problem with the pre-existing crypto assets, I would think you could overcome that

01:10:40.560 --> 01:10:42.800
So I would expect something more like a to and fro

01:10:43.440 --> 01:10:45.760
waves of centralization decentralization

01:10:46.400 --> 01:10:50.000
And natural checks embedded in the system. That's my intuition at least

01:10:50.320 --> 01:10:56.160
Does your argument against anarchy prove too much in the sense that globally different nations have anarchic relations with each other?

01:10:56.560 --> 01:11:00.560
And they can't uh, they can enforce coercive monopoly on each other

01:11:00.560 --> 01:11:04.400
But they can coordinate to punish bad actors and the way you will do on protection agencies to do, right?

01:11:04.400 --> 01:11:09.200
Like we can sanction North Korea together or something. I think that's a very good point and very good question

01:11:09.600 --> 01:11:11.760
But I would rephrase my argument

01:11:12.000 --> 01:11:15.600
You could say it's my argument against anarchy and it is an argument against anarchy

01:11:15.760 --> 01:11:19.520
But it's also an argument that says anarchy is everywhere. So within government

01:11:20.240 --> 01:11:24.480
Well the feds the state governments all the different layers of federalism. There's a kind of anarchy

01:11:25.040 --> 01:11:29.760
There's not quite a final layer of adjudication the way you might think we pretend there is

01:11:30.240 --> 01:11:32.880
I'm not sure how strong it is internationally, of course

01:11:34.000 --> 01:11:38.320
Uh, you know how much gets enforced by hegemon how much is spontaneous order

01:11:38.720 --> 01:11:43.920
Even the different parts of the federal government. They're in a kind of anarchy with respect to each other

01:11:45.040 --> 01:11:47.040
So you need a fair degree of collusion

01:11:47.760 --> 01:11:53.440
For things to work and you ought to accept that but maybe in a straussian way where you don't trumpet it too loudly

01:11:53.680 --> 01:12:02.080
But the point that anarchy itself will evolve enough collusion to enable it to persist if it persists at all

01:12:02.800 --> 01:12:06.480
Is my central point my point is like well anarchy isn't that different

01:12:08.160 --> 01:12:13.280
Now given we've put a lot of social political capital into our current institutions

01:12:14.320 --> 01:12:16.640
I don't see why you would press the anarchy button

01:12:16.960 --> 01:12:20.720
But if I'm north korea and I can press the anarchy button for north korea

01:12:21.680 --> 01:12:24.160
I get that it might just evolve into heyty

01:12:24.960 --> 01:12:30.240
But I probably would press the anarchy button for north korea if at least someone would come in and control the loose nukes

01:12:30.480 --> 01:12:35.200
Yeah, I this is related to one of those classic arguments against the anarchy that under anarchy anything is allowed

01:12:35.200 --> 01:12:38.960
So the government is allowed therefore we're in a state of anarchy in some sense

01:12:39.520 --> 01:12:43.760
In a funny way that argument's correct. We would revolve something like government

01:12:44.480 --> 01:12:48.400
And heyty has done this but in very bad ways where it's our gangs and killings

01:12:49.040 --> 01:12:52.800
It doesn't have to be that bad. There's medieval iceland medieval ireland

01:12:53.360 --> 01:12:55.360
They had various forms of anarchy

01:12:56.080 --> 01:12:59.040
Clearly limited in their destructiveness by low population

01:12:59.600 --> 01:13:01.600
ineffective weapons

01:13:01.680 --> 01:13:04.800
But they had a kind of stability you can't just dismiss them

01:13:05.520 --> 01:13:12.480
And you can debate how governmental were they but the ambiguity of those debates is part of the point that every system has a lot of anarchy

01:13:12.800 --> 01:13:15.680
And anarchy's have a fair degree of collusion if they survive

01:13:16.080 --> 01:13:20.800
Oh, actually, so I want to go back to much earlier in the conversation where you're saying listen over

01:13:22.080 --> 01:13:26.560
It seems like intelligence is is a net good. So just that being your heuristic you should

01:13:27.520 --> 01:13:28.960
Call forth the ai

01:13:28.960 --> 01:13:32.560
Well, not uncritically you need more argument, but just as a starting point

01:13:32.640 --> 01:13:37.440
Yeah, it's like if more intelligence isn't going to help you you have some really big problems anyway

01:13:37.760 --> 01:13:42.560
But I don't know if you still have the view that we're we have like an 800 year timeline for human civilization

01:13:42.560 --> 01:13:44.560
But that that that sort of timeline implies that

01:13:45.200 --> 01:13:49.360
Intelligence actually is going to be the because the thing the reason we have an 800 year timeline

01:13:49.920 --> 01:13:51.920
Presumably is like some product of intelligence, right?

01:13:53.360 --> 01:13:59.360
My worry is that energy becomes too cheap and people at very low cost can destroy things rather easily

01:14:00.880 --> 01:14:05.760
So say if a nuclear if destroying a city with a nuclear weapon cost $50,000

01:14:07.600 --> 01:14:11.920
What would the world look like I'm just not sure it might be more stable than we think

01:14:12.160 --> 01:14:18.080
But I'm I'm greatly worried and I could readily imagine it falling apart. Yeah, but I guess the bigger point I'm making is that

01:14:18.560 --> 01:14:24.000
Uh, in this case the reason the nuke got so cheap was uh because of intelligence

01:14:24.240 --> 01:14:26.480
Now that that doesn't mean we should stop intelligence

01:14:26.560 --> 01:14:32.000
But it just that if if that's like the end result of intelligence over hundreds of years that doesn't seem like intelligence is

01:14:32.400 --> 01:14:33.920
always, uh

01:14:33.920 --> 01:14:38.960
I'm not good. Well, we're doing better than the other great apes. I would say even though we face these really big risks

01:14:39.680 --> 01:14:42.960
And in the meantime, we did incredible things. So that's a gamble I would take

01:14:43.440 --> 01:14:47.120
But I believe we should view it more self-consciously as a sort of gamble

01:14:47.600 --> 01:14:52.320
And it's too late to turn back the fundamental choice was one of decentralization

01:14:52.880 --> 01:14:56.160
And that may have happened hundreds of millions or billions of years ago

01:14:56.800 --> 01:14:58.800
And once you opt for decentralization

01:14:59.280 --> 01:15:01.280
Intelligence is going to have advantages

01:15:02.000 --> 01:15:05.840
And you're not going to be able to turn the clock back on it. So you're walking this tightrope

01:15:06.320 --> 01:15:08.800
And by goodness you'd better do a good job

01:15:09.840 --> 01:15:12.320
I mean we should frame our broader history more like that

01:15:13.120 --> 01:15:16.160
And it has implications for how you think about x-risk again

01:15:16.160 --> 01:15:21.760
I think if the x-risk x-risk people a bit of them, it's like well, I've been living in berkeley a long time and

01:15:22.240 --> 01:15:25.040
It's it's really not that different my life's a bit better

01:15:25.760 --> 01:15:27.760
And we can't risk all of this

01:15:27.840 --> 01:15:30.000
But that's not how you should view broader history

01:15:30.480 --> 01:15:32.880
I feel like you're an extras person you have a yeah

01:15:32.880 --> 01:15:36.880
I mean even they don't think we're like a hundred percent guaranteed to go out by 800 years or something

01:15:37.120 --> 01:15:41.920
No, I don't think we're guaranteed at all. It's up to us. I just think the risk not that everyone dies

01:15:42.080 --> 01:15:43.280
I think that's quite low

01:15:43.280 --> 01:15:48.960
But that we retreat to some kind of pretty chaotic form of like medieval balkan's existence

01:15:49.360 --> 01:15:52.960
With a much lower population that seems to me quite a high risk

01:15:53.440 --> 01:15:56.320
With or without ai it's probably the default setting

01:15:59.200 --> 01:16:01.200
Given that you think that's a default setting I

01:16:01.360 --> 01:16:06.800
Why is that not a big part of your when you're thinking about how new technologies are coming about?

01:16:07.440 --> 01:16:12.400
Why why not consciously think in terms of is this getting us to the outcome where we avoid this sort of

01:16:13.120 --> 01:16:17.040
A free industrial state that would result from the the $50,000 nukes

01:16:17.520 --> 01:16:23.840
Well, if you think the risk is cheap energy more than ai per se admittedly ai could speed the path to cheap energy

01:16:24.720 --> 01:16:26.720
It seems very hard to control

01:16:27.280 --> 01:16:34.720
The strategy that's worked best so far is to have relatively benevolent nations become hegemon's and establish dominance

01:16:35.840 --> 01:16:38.960
So it does influence me. I want the us uk

01:16:39.920 --> 01:16:44.080
Some other subset of nations to establish dominance in ai it may not work forever

01:16:44.880 --> 01:16:47.840
But in a decentralized world it sure beats the alternative

01:16:48.320 --> 01:16:55.360
So a lot of the ai types they're too rationalist and they don't start with the premise that we chose a decentralized world a very very long time ago

01:16:55.520 --> 01:16:57.520
even way before humans

01:16:57.760 --> 01:17:01.920
And I think you made an interesting point when you were talking about canes in the book where you said

01:17:02.240 --> 01:17:05.840
One of his faults was that he assumed that people like him would always be in charge

01:17:06.080 --> 01:17:06.320
That's right

01:17:06.320 --> 01:17:09.680
And I do see that also in the the alignment discourse like alignment is you know

01:17:09.760 --> 01:17:13.040
If it's just handing over the government and just assuming the government does what you'd expect it to do

01:17:13.280 --> 01:17:15.200
And I worry about this from my own point of view

01:17:15.200 --> 01:17:17.680
So even if you think us is pretty benevolent today

01:17:18.000 --> 01:17:23.360
Which is a highly contested and mixed proposition and i'm an american citizen pretty patriotic

01:17:23.760 --> 01:17:29.680
But i'm fully aware of the long history of my government in killing and slaving doing other terrible things to people

01:17:30.560 --> 01:17:32.560
And then you have to rethink

01:17:32.560 --> 01:17:35.440
That over a long period of time it may be the worst

01:17:36.400 --> 01:17:40.000
Time period that affects the final outcome even if the average is pretty good

01:17:40.320 --> 01:17:42.320
And then if power corrupts

01:17:42.400 --> 01:17:46.080
And if government even indirectly controls ai systems

01:17:46.080 --> 01:17:50.000
So u.s. Government could become worse because it's a leader in ai right

01:17:50.720 --> 01:17:54.800
But again, I've got to still take that over china or russia or

01:17:55.680 --> 01:17:57.680
wherever else it might be

01:17:58.080 --> 01:18:00.080
I just don't really understand

01:18:00.560 --> 01:18:06.400
When people talk about national security, I've never seen the ai doomers say anything that made sense

01:18:06.800 --> 01:18:12.800
And I recall those early days remember china issued that edict where they said we're only going to put ai's that are safe

01:18:13.040 --> 01:18:18.560
And they can't criticize the ccp. How many super smart people and I mean super smart like zvi

01:18:19.440 --> 01:18:23.520
Just jump on that and say c china's not going to compete with us. We can shut ai down

01:18:24.000 --> 01:18:28.560
They just seem to have zero understanding of some properties of decentralized worlds

01:18:29.040 --> 01:18:31.200
Or leesers tweet was it from yesterday?

01:18:32.480 --> 01:18:34.000
Uh, I didn't think it was a joke

01:18:34.000 --> 01:18:38.560
But oh, there's a problem that ai can read all the legal code and threaten us with all these penalties

01:18:38.800 --> 01:18:41.840
It's like he has no idea how screwed up the legal system is

01:18:42.800 --> 01:18:47.280
Hmm. Yeah, it would just need courtroom waits of like 70 or 700 years

01:18:47.600 --> 01:18:51.760
It's not it wouldn't become a thing people are afraid of it would be a social problem in some way

01:18:52.400 --> 01:18:56.000
What's your sense of how the government reacts when the labs are doing?

01:18:56.240 --> 01:18:59.760
Uh, regardless of how they should react how they will react and when the labs are doing like, I don't know

01:19:00.160 --> 01:19:02.160
10 billion dollar training runs and

01:19:02.560 --> 01:19:06.560
If if under the premise that you know, these are powerful models not human level per se

01:19:06.560 --> 01:19:10.160
But just they they can do all kinds of crazy stuff. How do you think the government's gonna?

01:19:10.960 --> 01:19:14.560
Are they gonna nationalize the labs or how do you stay in washington? What's your sense?

01:19:15.360 --> 01:19:19.600
I think our national security people are amongst the smartest people in our government

01:19:20.400 --> 01:19:25.760
Uh, they're mostly well-intentioned in a good way. They're paying careful attention to many things

01:19:27.040 --> 01:19:30.160
But what will be the political will to do what they don't control?

01:19:30.960 --> 01:19:36.320
And my guess is until there's sort of an spf like incident which might even not be significant

01:19:36.400 --> 01:19:43.360
But a headlines incident which spf was even if it doesn't affect the future evolution of crypto, which I guess is my view it won't

01:19:44.720 --> 01:19:46.960
Until there's that we won't do much of anything

01:19:47.760 --> 01:19:50.640
And then we'll have an spf like incident and we'll overreact

01:19:50.880 --> 01:19:56.640
That seems a very common pattern in american history and the fact that it's a i the stakes might be high or whatever

01:19:57.440 --> 01:20:00.400
I doubt if it will change the recurrence of that pattern

01:20:01.520 --> 01:20:04.880
How would robert nozick think about different ai utopias?

01:20:05.680 --> 01:20:09.280
Well, I think he did think about different ai utopias, right?

01:20:10.320 --> 01:20:12.000
so uh

01:20:12.000 --> 01:20:16.800
I believe he whether he wrote or talked about it, but the notion of humans much smarter

01:20:17.440 --> 01:20:23.120
Than they are or the notion of aliens coming down who are like in some way morally intellectually way beyond us

01:20:23.520 --> 01:20:28.160
He did write about that and he was worried about how they would treat us. So he was sensitive

01:20:28.960 --> 01:20:32.320
To what you would call ai risk viewed a bit more broadly very early on

01:20:33.200 --> 01:20:35.200
Hmm. What was his what was his take?

01:20:35.840 --> 01:20:38.240
Well nozick is not a thinker of of takes

01:20:38.640 --> 01:20:42.960
He was a thinker of speculations and multiple possibilities which I liked about him

01:20:44.000 --> 01:20:46.000
He was worried about it this I know

01:20:46.880 --> 01:20:48.880
And I talked to him about it

01:20:49.040 --> 01:20:51.040
But I couldn't boil it down to a simple take

01:20:52.400 --> 01:20:58.320
They made him a vegetarian I should add wait that made him oh because we want to be treating the the entities that are to us as

01:20:59.280 --> 01:21:02.800
Aliens from outer space might treat us we are like that to animals

01:21:03.360 --> 01:21:08.400
May not be a perfect analogy, but it's still an interesting point and therefore we should be vegetarians

01:21:08.720 --> 01:21:14.800
That was his argument at least he felt he should be I wonder if we should honor past generations more or at least like respect their wishes

01:21:14.800 --> 01:21:17.760
More for if we think of the the alignment problem

01:21:17.760 --> 01:21:21.520
It's a similar to how we react to our previous generations

01:21:21.840 --> 01:21:26.320
Do you know if we do we want uh the ai to treat us as we treat people thousands of years ago?

01:21:26.800 --> 01:21:28.800
Yeah, it's a good question and uh

01:21:29.760 --> 01:21:33.520
I've never met anyone who's consistent with how they view wishes of the dead. Yeah

01:21:34.080 --> 01:21:37.920
I don't think there is a consistent philosophically grounded point of view on that one

01:21:38.640 --> 01:21:43.280
Hmm. I guess the the sort of thomas pain viewer you don't regard them at all. Is that not self-consistent?

01:21:43.600 --> 01:21:46.880
It's consistent, but I've never met anyone who actually lives according to it

01:21:47.600 --> 01:21:49.600
Oh, and what's inside the contradicting themselves?

01:21:49.840 --> 01:21:56.320
Well, say, you know, their their spouse were to die and the spouse gave them instructions. Sure. They would put weight on those instructions

01:21:57.280 --> 01:22:01.120
Somewhere out there. There's probably someone who wouldn't but I've never met such a person

01:22:01.440 --> 01:22:04.160
Hmm. And how about the burq view that you take them very seriously?

01:22:04.480 --> 01:22:08.720
It why is that not self-consistent the birth view? What do you mean burq burq view? Oh?

01:22:09.360 --> 01:22:15.280
Well, it's time inconsistent to take those preferences seriously and burq himself understood that he was a very deep thinker

01:22:16.000 --> 01:22:21.040
So while you take them seriously now, but as time passes other ancestors come along

01:22:21.120 --> 01:22:25.520
They have somewhat different views you have to keep on changing course what you should do now

01:22:26.160 --> 01:22:33.200
Should it be what the ancestors behind us want or your best estimate of what the 30 or 40 years of ancestors to come

01:22:33.840 --> 01:22:35.840
Will want once they have become ancestors

01:22:36.560 --> 01:22:43.680
So it's time inconsistent. There's not again. There's not going to be a strictly philosophical resolution. There will be practical attempts

01:22:44.400 --> 01:22:46.400
to find something sustainable

01:22:46.400 --> 01:22:54.320
And that which survives will be that which we do and then we'll somewhat rationalize it exposed. Yeah. Yeah, there's an interesting book about

01:22:55.680 --> 01:23:00.960
The ancient ancient Greeks. What was it called? I forgot the name, but it's talks about the hearts that they have for the

01:23:01.920 --> 01:23:04.240
For their families where the the dead become gods

01:23:04.640 --> 01:23:07.200
But then over time if you keep this heart going for hundreds of years

01:23:07.280 --> 01:23:11.120
There's like thousands of ancestors that you didn't even remember their names, right? Who are you praying to?

01:23:11.920 --> 01:23:14.880
And then it's like the arrow and possibility theorem for all the gods

01:23:15.440 --> 01:23:17.120
What do they all mean too?

01:23:17.120 --> 01:23:19.120
And you can't even ask them. Yeah

01:23:19.600 --> 01:23:24.160
Okay, we were talking before we started recording about argentina and the reforms they're trying there

01:23:25.280 --> 01:23:28.800
And they're trying to dollarize because the dollar is more stable than their currency

01:23:28.880 --> 01:23:32.720
But this raises the question of why is the dollar so stable? So we're also democracy, right?

01:23:32.720 --> 01:23:38.080
But like the dollar seems pretty well managed. What is the larger explanation of why?

01:23:38.800 --> 01:23:45.280
Uh, the monetary policy seems well managed in the u.s. Well u.s. Voters hate inflation mostly for good reasons

01:23:45.760 --> 01:23:48.560
And we have enough wealth that we can pay our bills

01:23:49.040 --> 01:23:53.600
Without having to inflate very much and two percent has been stable now for quite a while

01:23:54.240 --> 01:23:59.760
Now it's an interesting question, which I cannot answer and I have looked into this and I have asked smart people from argentina

01:24:00.320 --> 01:24:04.720
Why does argentina in particular have recurring waves of hyperinflation?

01:24:05.680 --> 01:24:09.200
Is there something about the structure of their interest groups that

01:24:10.160 --> 01:24:13.840
Inevitably recurringly leads them to demand too much. I suppose

01:24:14.480 --> 01:24:17.760
But there's plenty of poor badly run countries that don't have hyperinflation

01:24:18.160 --> 01:24:23.760
African countries historically have not had high rates of hyperinflation haven't had high rates of inflation

01:24:24.880 --> 01:24:26.160
Why is that?

01:24:26.160 --> 01:24:30.800
Well, maybe they don't capture enough through senior age for some reason currency holdings aren't large enough

01:24:31.200 --> 01:24:33.200
There's some kind of financial repression. I don't know

01:24:33.840 --> 01:24:39.840
But it's very hard to explain why some of these countries, but not others go crazy with the printing press

01:24:41.760 --> 01:24:46.400
And this is maybe a broader question about different institutions in the government where

01:24:47.440 --> 01:24:48.960
I don't understand enough to

01:24:48.960 --> 01:24:50.560
evaluate their like object level decisions

01:24:50.560 --> 01:24:54.240
But if you look at the supreme court or the federal reserve or something just from a distance

01:24:54.240 --> 01:24:59.280
It seems like they're really well run competent organizations with a highly technocratic, you know

01:25:00.080 --> 01:25:04.400
Non-partisan people running them. They're not non-partisan, but they're still well run. Yeah, and

01:25:05.360 --> 01:25:09.520
What's the theory of why these institutions in particular are so much better run?

01:25:09.520 --> 01:25:11.520
Is it just that they are

01:25:11.680 --> 01:25:17.840
They're one step back from direct elections is that they have traditions of knowledge within them. How do we think about this?

01:25:17.920 --> 01:25:19.440
I think both of those

01:25:19.440 --> 01:25:25.680
I don't think the elections point is sufficient because there's plenty of unelected bodies. They're totally corrupt. Yeah around the world

01:25:25.680 --> 01:25:27.680
most of them are perhaps

01:25:28.080 --> 01:25:31.520
Some sense of american civic virtue that gets communicated

01:25:32.160 --> 01:25:35.600
And then the incentives are such say you're on the fed for a while

01:25:36.000 --> 01:25:38.800
What you can do afterward can be rewarding

01:25:39.280 --> 01:25:41.840
But you want a reputation for having done a good job

01:25:42.320 --> 01:25:45.760
So your sense of morality and your private self-interest coincide

01:25:46.320 --> 01:25:51.440
And that's pretty strong and we're still in that loop. I don't really see signs of that loop breaking

01:25:52.400 --> 01:25:56.080
It's also striking to me how many times I'll read an interesting article or paper and

01:25:56.320 --> 01:25:59.280
The person who wrote it's like the former head of the federal reserve in new york or something

01:25:59.520 --> 01:26:03.760
It just seems like a this is strong indication of these institutions that the standards are very high

01:26:03.840 --> 01:26:10.480
And if you speak with any of those people like who've been on fed boards ask them questions. They're super smart super involved curious

01:26:11.280 --> 01:26:14.240
Uh, really for the most part do you want the best thing for their country?

01:26:14.880 --> 01:26:16.880
Oh going back to these economists

01:26:17.120 --> 01:26:22.000
You at the end you talk about how you're kind of uh disappointed in this sort of turn that economics has taken

01:26:22.000 --> 01:26:25.280
Maybe I just I'm not surprised right? It's division of labor adam smith

01:26:25.680 --> 01:26:30.240
Who said it would make people a bit feeble minded and incurious was completely correct

01:26:31.360 --> 01:26:35.840
Wait adam smith said what would make people division of labor? I see right? Yeah, not stupid

01:26:36.560 --> 01:26:42.000
You know current economic researchers probably have never been smarter, but they're way less broad and less curious

01:26:42.880 --> 01:26:44.480
um

01:26:44.480 --> 01:26:50.000
Patrick Ellison put it an interesting way where he said in the past maybe thinkers were more interested in

01:26:50.960 --> 01:26:52.560
Delving into the biggest questions

01:26:52.560 --> 01:26:55.600
But if they they couldn't do it rigorously in a tractable way

01:26:55.600 --> 01:27:00.240
They would just they would make the trade-off in favor of the big question and today we make the opposite trade-off

01:27:00.480 --> 01:27:04.800
How does that seem like a fair comparison? I think that's correct and I would add that saying the time of smith

01:27:04.880 --> 01:27:06.880
There was nothing you could do rigorously

01:27:06.880 --> 01:27:10.000
So there was no other option. Well, oh i'm gonna specialize and

01:27:10.560 --> 01:27:15.200
You know memorizing all the grain prices and run some great econometrics on that and that'll be rigorous

01:27:16.160 --> 01:27:18.160
It's really william stanley jevons

01:27:18.960 --> 01:27:23.520
Who to the anglo world introduced this notion there's something else you can do that's rigorous

01:27:24.080 --> 01:27:28.320
It was not yet rigorous, but he opened the door and showed people the alternative

01:27:29.280 --> 01:27:31.280
Of the of the jevons paradox

01:27:32.240 --> 01:27:36.080
Well, I would say his work in statistics originally on the value of money, right?

01:27:36.320 --> 01:27:40.480
But his statistical work on call also had some rigors. So you're not wrong to cite them

01:27:41.920 --> 01:27:43.920
And jevons just showed

01:27:43.920 --> 01:27:47.680
That rigorous statistical work and economics could be the same thing

01:27:48.400 --> 01:27:51.680
And that was his greater innovation than just marginalism

01:27:52.320 --> 01:27:54.320
So he's an underrated figure

01:27:54.320 --> 01:27:56.320
Maybe he should be in the book in a way

01:27:56.480 --> 01:28:01.520
But it had some unfortunate secondary consequences too many people crowd into specialization

01:28:02.160 --> 01:28:07.040
Crowd is a funny word to use because they reach sitting in their separate nodes, but it's a kind of crowding

01:28:07.520 --> 01:28:10.560
Is there some sort of hyacin a solution here where?

01:28:11.200 --> 01:28:16.720
Yeah, in markets the effect of having the sort of decentralized processes the the the sum is greater than the parts

01:28:17.120 --> 01:28:22.800
Whereas in academic disciplines the sum is just a bunch of different statistical aggregates

01:28:23.200 --> 01:28:25.680
Uh, there's no grand theory that comes together as a result of

01:28:27.120 --> 01:28:32.720
All this micro work. Is there some hyacin solution here? Well, yes, you and I are the hyacin solution

01:28:33.040 --> 01:28:35.200
That a specialist proliferate we can be

01:28:35.840 --> 01:28:41.840
Quote-unquote parasitic on them and take what they do and turn it into interesting larger bundles that they haven't dreamt of

01:28:42.800 --> 01:28:47.040
And make some kind of living doing that and we're much smaller in number

01:28:47.280 --> 01:28:50.320
But i'm not sure how numerous we should be and there's a bunch of us, right?

01:28:51.120 --> 01:28:53.120
You're just ever category titler

01:28:53.520 --> 01:28:55.520
I'm running a podcast here

01:29:00.800 --> 01:29:05.200
And what do you see as a future of the sort of uh, the kind of sort of thinking you do are

01:29:05.440 --> 01:29:09.360
Are you do you see yourself as the last of the literary economist or is there a future of this kind of

01:29:10.080 --> 01:29:13.120
Is it just going to be the slates our codex's are they going to take care of it or

01:29:14.320 --> 01:29:18.320
This sort of lineage of thinking well the next me won't be like me

01:29:18.480 --> 01:29:23.200
Yeah, in that sense i'm the last but i don't think it will disappear. It will take new forms

01:29:23.920 --> 01:29:25.920
It may have a lot more to do with ai

01:29:26.800 --> 01:29:29.600
And i don't think it's going to go away. There's just a demand for it

01:29:30.320 --> 01:29:37.120
There's a real demand for our products. We have a lot of readers listeners people interested whatever and there'll be ways to monetize that

01:29:38.080 --> 01:29:40.080
The challenge might be

01:29:40.480 --> 01:29:46.400
Competing against ai and it doesn't have to be that ai does it better than you or i do without it might

01:29:47.040 --> 01:29:51.040
But simply the people prefer to read what the ai's generate for 10 or 20 years

01:29:51.280 --> 01:29:56.480
And it's harder to get an audience because playing with the ai's is a lot of fun. So that will be a real challenge

01:29:56.880 --> 01:30:00.480
I think some of us will be up to it. You'll be faced with it more than i will be

01:30:01.600 --> 01:30:03.920
Uh, but it's going to change a lot. Yeah, okay

01:30:04.640 --> 01:30:09.040
Uh, one of the final things i want to do is i want to go into political philosophy a little bit

01:30:09.520 --> 01:30:11.520
And uh, ask you

01:30:14.240 --> 01:30:22.560
Okay, so i want to ask you about sort of certain potential weaknesses of the democratic capitalist model that we live in and in terms of

01:30:23.120 --> 01:30:27.840
Both in terms of whether you think they're object level law wrong. Uh, sorry object level right and second

01:30:28.720 --> 01:30:29.760
how

01:30:29.760 --> 01:30:33.760
Regardless of how right they are how how um persuasive and how powerful

01:30:34.480 --> 01:30:39.760
A force they will be against uh, our you know, our system of uh, uh government and functioning. Okay

01:30:40.640 --> 01:30:46.480
Okay, so there's a libertarian critique that basically democracy is sort of a random walk with a drift toward socialism

01:30:46.560 --> 01:30:49.040
And there's also a rashard effect where government programs don't go away

01:30:49.680 --> 01:30:51.680
And so it just ends up towards socialism at the end

01:30:52.240 --> 01:30:55.760
It ends up with having government that is too large. Yeah, but i

01:30:56.480 --> 01:30:58.880
Don't see the evidence that it's wrote to serfdom

01:30:59.760 --> 01:31:03.520
France sweden have had pretty big governments way too large in my opinion

01:31:04.080 --> 01:31:08.240
But they haven't threatened to turn autocratic or totalitarian certainly not

01:31:08.880 --> 01:31:12.960
And you've seen reforms in many of those countries sweden moved away from

01:31:13.600 --> 01:31:17.360
Government approaching 70 percent of gdp and now it's quite manageable

01:31:17.840 --> 01:31:19.840
Government there should be smaller yet

01:31:20.240 --> 01:31:25.440
I don't think the trend is that negative. It's more of a problem with regulation and the administrative state

01:31:26.160 --> 01:31:29.760
But we've shown an ability to create new sectors like big parts of tech

01:31:30.880 --> 01:31:35.440
They're not unregulated laws apply to them, but they're way less regulated and it's a kind of race

01:31:36.320 --> 01:31:40.240
Uh, that race doesn't look too bad to me at the moment like we could lose it

01:31:41.200 --> 01:31:47.120
But uh, so far so good. So it the critique should be taken seriously, but it's yet to be validated. Hmm

01:31:47.680 --> 01:31:52.000
Uh, how about the egalitarian critique from the left that you can't have

01:31:52.720 --> 01:31:57.680
The inequality the market creates with the political and moral equality that the you know, humans deserve in demand

01:31:58.320 --> 01:32:00.320
They just say that

01:32:01.280 --> 01:32:04.000
US has high degree of income inequality. Yeah

01:32:04.720 --> 01:32:08.160
Uh, so does brazil a much less well functioning society

01:32:09.040 --> 01:32:14.240
Brazil continues on average. It will probably grow one or two percent. That's not a great record

01:32:14.800 --> 01:32:17.840
But brazil has to go up in a puff of smoke. I don't see it

01:32:18.800 --> 01:32:24.640
And how about the niche and critique and in the um, the end of history fukiyama says this is more powerful

01:32:24.880 --> 01:32:27.760
This is the one he's more worried about than the more more so than the leftist critique

01:32:27.920 --> 01:32:28.800
Over time

01:32:28.800 --> 01:32:33.040
Basically what you end up with is the last man and you can't defend the civilization. You know the story

01:32:33.200 --> 01:32:37.760
It's a lot of words. I mean, is he short the market? I've asked fukiyama this

01:32:38.240 --> 01:32:41.360
He's not this is a long time ago, but he wasn't short the market then

01:32:42.560 --> 01:32:44.560
Again, it's it's a real issue

01:32:44.640 --> 01:32:47.920
It seems to me the problems of today for the most part

01:32:48.560 --> 01:32:51.520
Are more manageable than the problems of any previous era

01:32:52.400 --> 01:32:54.400
We still you know might all go poof

01:32:55.040 --> 01:32:58.480
Return to medieval Balkan style existence in a millennia or whatever

01:32:59.440 --> 01:33:05.280
But it's a fight and we're totally in the fight and we have a lot of resources and talent. So like let's do it

01:33:06.800 --> 01:33:09.280
Okay, I don't see why that particular worry

01:33:09.840 --> 01:33:11.840
It's it's a lot of words

01:33:12.320 --> 01:33:15.440
And I like to get very concrete like even if you're not short the market

01:33:15.520 --> 01:33:19.360
If that were the main relevant worry, where would that show up in asset prices?

01:33:19.440 --> 01:33:21.840
It's a cot worse. It's a very concrete question

01:33:22.000 --> 01:33:27.760
I think it's very useful to ask and when people don't have a clear answer. I get worried. Where does your prediction that?

01:33:29.360 --> 01:33:32.960
Hundreds of years down the line will have the $50,000 nukes. Where does that show up in the asset prices?

01:33:33.440 --> 01:33:37.200
I think at some point vix, you know an index of volatility will go up

01:33:38.160 --> 01:33:43.040
Uh, probably not soon nuclear proliferation has not gone crazy, which is wonderful

01:33:43.840 --> 01:33:48.160
But I think at some point it's hard to imagine it not getting out of control

01:33:48.800 --> 01:33:54.320
Um, last I read vix is surprisingly low and stable. That's right. I think 2024 is on

01:33:54.960 --> 01:33:56.960
On the path to be a pretty good year

01:33:56.960 --> 01:34:02.240
Yeah, or do you think the market is just wrong in terms of thinking about both geopolitical risk from, you know, israel or whatever

01:34:02.240 --> 01:34:04.240
I don't think the market's wrong at all. I think

01:34:04.480 --> 01:34:08.480
That war will converge. I'm not saying the humanitarian outcome is a good one

01:34:08.720 --> 01:34:13.120
But in terms of the global economy, I think markets are thinking rationally about it

01:34:13.360 --> 01:34:15.600
Though the rational forecast of course is often wrong

01:34:16.240 --> 01:34:21.760
What's your sense on the scaling stuff when you look at the arguments? Uh, in the terms of what's coming? How do you react to that?

01:34:22.160 --> 01:34:24.160
Well, your piece on that was great

01:34:24.480 --> 01:34:27.760
I don't feel I have the expertise to judge that as a technical matter

01:34:28.080 --> 01:34:33.840
It does seem to me intuitively it would be weird on the technical side if scaling just stopped working

01:34:34.160 --> 01:34:39.520
But on the knowledge side, I think people underestimate possible barriers and what I have in mind is

01:34:40.160 --> 01:34:44.880
Quite a bit of reality the universe might in some very fundamental way simply not be legible

01:34:45.680 --> 01:34:50.800
And that there's no easy and fruitful way to just quote unquote apply more intelligence to the problem

01:34:51.280 --> 01:34:54.640
Like oh, you want to integrate general relativity and quantum mechanics

01:34:55.200 --> 01:35:00.720
It may just be we've hit the frontier and there's not a final layer of oh here's how it fits together

01:35:00.960 --> 01:35:03.520
So there's no way to train in ai or other thing

01:35:04.160 --> 01:35:08.160
To make it smarter to solve that and maybe a lot of the world is like that

01:35:09.360 --> 01:35:13.680
And that to me people are not taking seriously enough. So I'm not sure what the net returns will be

01:35:14.320 --> 01:35:15.200
to

01:35:15.200 --> 01:35:17.200
bigger and better and smarter ai

01:35:17.760 --> 01:35:23.200
That seems possible for you know, p versus np type of reasons. It's just like harder to make uh for further discoveries

01:35:23.600 --> 01:35:24.560
but

01:35:24.560 --> 01:35:28.080
I feel like we have pretty good estimates in terms of like the declining

01:35:29.120 --> 01:35:32.960
A researcher productivity because of low hanging fruit being gone in this sort of sense

01:35:33.440 --> 01:35:35.440
of we're reaching the frontier and

01:35:35.680 --> 01:35:40.160
Whatever percent it is a year if you can just keep the ai population growing faster than that

01:35:40.240 --> 01:35:45.840
If you just want to be crude about it that seems enough to if not get to the ultimate physical synthesis

01:35:45.840 --> 01:35:51.040
At least much broader than where human civilization would get in the same span of time. That seems very plausible

01:35:51.360 --> 01:35:54.400
I think we'll get further. I expect big productivity gains

01:35:54.960 --> 01:35:59.840
As a side note, I'm less convinced by the declining researcher productivity argument than I used to be

01:36:00.560 --> 01:36:06.640
So the best way to measure productivity for an economist is wages and wages of researchers haven't gone down

01:36:07.920 --> 01:36:11.840
Period in fact, they've gone up. No, they may not be producing new ideas

01:36:11.840 --> 01:36:17.680
You might be paying them to be functionaries or to manage pr or does this manage other researchers?

01:36:18.400 --> 01:36:22.740
But I think that's a worry that we have a lot more researchers

01:36:23.520 --> 01:36:24.320
with

01:36:24.320 --> 01:36:31.600
Generally rising researcher wages and that hasn't boosted productivity growth. China, india, south korea brought into the world economy

01:36:32.080 --> 01:36:34.080
scientific talent

01:36:34.400 --> 01:36:38.960
It's better than if we hadn't done it, but it hasn't in absolute terms boosted productivity growth

01:36:39.200 --> 01:36:41.200
And maybe that's a worrisome sign

01:36:41.360 --> 01:36:44.320
Uh on on the metric of researcher wages

01:36:44.720 --> 01:36:48.320
It seems like it could just be a fact that even the even the

01:36:49.200 --> 01:36:53.120
Less marginally useful improvements are worth the extra cost in terms of if you think of a company

01:36:53.440 --> 01:36:56.960
Like google is probably paying as engineers a lot more than it was paying in the early days

01:36:57.040 --> 01:36:59.200
Even though they're doing less now because you know

01:36:59.520 --> 01:37:03.680
Changing a pixel in the the new google page is going to affect billions of users

01:37:04.000 --> 01:37:10.160
The similar thing could be happening in the economy, right? That might hold for google researchers, but take people in pharma biomedicine

01:37:11.520 --> 01:37:13.520
There's a lot of private sector

01:37:13.520 --> 01:37:17.120
Financed research or indirectly financed by buying up smaller companies

01:37:17.680 --> 01:37:21.040
And it only makes sense if you get something out of it that really works

01:37:21.600 --> 01:37:25.120
Like a good vaccine or a good medication ozempic super profitable

01:37:26.080 --> 01:37:29.680
So wages for biomedical researchers in general haven't gone down

01:37:31.040 --> 01:37:33.040
Now finally it's paying off

01:37:33.600 --> 01:37:38.480
But i'm not sure ai will be as revolutionary as the other ai optimists believe

01:37:38.880 --> 01:37:42.320
I do think it will raise productivity growth in ways which are visible

01:37:43.280 --> 01:37:45.280
To what extent?

01:37:46.160 --> 01:37:49.280
In the conventional agro story you think in terms of population size, right?

01:37:49.280 --> 01:37:52.960
And then so you just increase the population size you get much more research at the other end

01:37:53.280 --> 01:37:57.120
To what extent doesn't make sense to think about well, if you have these billions of ai copies

01:37:57.920 --> 01:38:00.800
We can think of that in terms of as a proxy of how much progress they could

01:38:01.680 --> 01:38:07.600
Produce is that a not a sensible way to think about that at some point having billions of copies probably won't matter

01:38:07.920 --> 01:38:13.520
It will matter much more. How good is the best thing we have and how well integrated is it

01:38:13.920 --> 01:38:16.560
Into our other systems which have bottlenecks of their own

01:38:17.520 --> 01:38:21.440
And the principles governing the growth of that are much harder to discern

01:38:21.680 --> 01:38:24.640
It's probably a much slower growth than just juicing up

01:38:24.800 --> 01:38:27.920
Oh, we've got a lot of these things and they're trained on more and more gpu's

01:38:28.800 --> 01:38:34.240
But precisely because the top seems to matter so much is why we might expect bigger gains, right?

01:38:34.240 --> 01:38:36.800
So if you think about jews in the 20th century

01:38:37.520 --> 01:38:40.640
You know two percent of the population are less than that and 20 percent of the noble prizes

01:38:40.880 --> 01:38:43.440
It does seem like you can have a much bigger impact than

01:38:44.320 --> 01:38:46.320
If you're on the very tail if you just have

01:38:46.400 --> 01:38:48.400
Just a few hundred john von neumann copies

01:38:48.720 --> 01:38:54.160
Maybe that's a good analogy that the impact of ai will be like in the 20th century the impact of jews, right?

01:38:54.720 --> 01:38:57.520
Which would be excellent, right? Yeah, but it's not

01:38:58.240 --> 01:39:03.440
Extraordinary, it's not a science fiction novel. It is. I mean you read the early 20th century stuff as you have

01:39:03.520 --> 01:39:08.960
You know, it's like a slow takeoff right there of like, you know, go from v2 rockets to the moon and a couple of decades

01:39:09.360 --> 01:39:13.840
It's it's kind of a crazy pace of change. Yeah, that's what I think it will be like again

01:39:13.920 --> 01:39:18.960
Great stagnation is over. We'll go back to those earlier rates of change transform a lot of the world

01:39:19.840 --> 01:39:21.840
Mostly a big positive a lot of chaos

01:39:22.400 --> 01:39:25.680
Disrupted institutions along the way. That's my prediction

01:39:26.320 --> 01:39:31.440
But no one writes a science fiction novel about the 20th century. It feels a bit ordinary still

01:39:32.320 --> 01:39:38.400
Hmm. Yeah, even though it wasn't I forget the name of the philosopher you asked this to but the the feminist philosopher you asked the question

01:39:38.560 --> 01:39:39.920
Amiya Srinivasan

01:39:39.920 --> 01:39:43.760
You asked the question what would have to be different for you to be a social conservative, right?

01:39:44.160 --> 01:39:47.040
What would have to be different for you to not be a tumor per se?

01:39:47.040 --> 01:39:49.040
But just one of these people who like

01:39:49.040 --> 01:39:52.160
This is the main thing to be thinking about during this period of history or something like that

01:39:52.400 --> 01:39:54.880
Well, I think it is one of the main things we should be thinking about

01:39:55.520 --> 01:39:58.880
But I would say if I thought international cooperation

01:39:59.520 --> 01:40:01.040
Were very possible

01:40:01.040 --> 01:40:02.480
I would at least

01:40:02.480 --> 01:40:04.640
Possibly have very different views than I do now

01:40:05.360 --> 01:40:11.680
Or if I thought no other country could make progress on AI those seem unlikely to me, but they're not logically impossible

01:40:12.320 --> 01:40:13.360
so

01:40:13.360 --> 01:40:16.240
The fundamental premise where I differ from a lot of the doomers

01:40:16.960 --> 01:40:21.200
Is my understanding of a decentralized world and its principles being primary

01:40:21.840 --> 01:40:24.960
Their understanding is some kind of comparison like here's the little people

01:40:25.360 --> 01:40:27.920
And here's the big monster and the big monster gets bigger

01:40:28.160 --> 01:40:32.480
And even if the big monster does a lot of good things, it's just getting bigger and here are the little people

01:40:33.200 --> 01:40:34.800
That's a possible framework

01:40:34.800 --> 01:40:39.600
But if you start with decentralization and competition and well, how are we going to manage this?

01:40:41.680 --> 01:40:44.400
In some ways my perspective might be more pessimistic

01:40:46.080 --> 01:40:50.240
But you you don't just think you can wake up in the morning and like legislate safety

01:40:50.560 --> 01:40:52.560
Hmm

01:40:54.000 --> 01:40:59.600
You look at the history of relative safety having come from hegemon's and you hope your hegemon stays good enough

01:41:00.480 --> 01:41:05.360
Which is a deeply fraught proposition. I recognize that. Hmm. What's the next book?

01:41:06.640 --> 01:41:12.560
I'm already writing it. Uh part of it is on jevons, but the title is the marginal revolution

01:41:14.000 --> 01:41:19.120
But not about the blog about the actual marginal. Yeah, but it's maybe a monograph like 40 000 words

01:41:19.920 --> 01:41:22.480
But I don't think book length should matter anymore

01:41:23.360 --> 01:41:25.360
I want to be more radical on that

01:41:25.440 --> 01:41:29.360
I think 40 000 words is perfect because it would actually fit in context. So when you do the gpd4

01:41:31.280 --> 01:41:35.280
Now context may be bigger by then. Yeah, but I want to have it in

01:41:36.000 --> 01:41:39.200
GPT in some way or whatever is replaced it. Hmm

01:41:40.320 --> 01:41:42.960
Okay, uh, those are all the questions I had tell her this is a lot of fun

01:41:43.600 --> 01:41:48.400
And uh, keep up the great work and uh, delighted you're at it. Thank you. Thank you. Uh, yeah

01:41:48.400 --> 01:41:52.560
Thanks for coming on the podcast. It's the third time now. So a lot of fun. Okay. Bye everyone

01:41:55.200 --> 01:41:57.600
Hey everybody, I hope you enjoyed that episode

01:41:58.240 --> 01:42:01.840
As always the most helpful thing you can do is to share the podcast

01:42:02.160 --> 01:42:06.960
Send it to people you think might enjoy it put it in twitter your group chats, etc. Just splits the world

01:42:07.920 --> 01:42:10.720
Appreciate your listening. I'll see you next time. Cheers

01:42:18.400 --> 01:42:20.400
You

