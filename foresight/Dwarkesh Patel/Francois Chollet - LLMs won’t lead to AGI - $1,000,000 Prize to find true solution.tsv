start	end	text
0	3000	LLMs are very good at memorizing static programs.
3000	5880	If you scale up the size of your database,
5880	9160	you are not increasing the intelligence of the system
9160	9640	one bit.
9640	11520	I feel like you're using words like memorization, which
11520	12960	we would never use for human children.
12960	16120	If they can just solve any arbitrary algebraic problem,
16120	17920	you wouldn't say they've memorized algebra.
17920	19360	They'd say they've learned algebra.
19360	20880	So you've got a million dollar price pool,
20880	23800	and there's a $500,000 price for the first team that
23800	25920	can get to the 85% benchmark.
25920	29000	If ARC survives three months from here, we'll pull up the price.
29000	32120	Open AI basically set back progress towards HGI
32120	33800	by probably like five to 10 years.
33800	35880	They caused this complete closing down
35880	37320	of frontier research publishing.
37320	41400	And now LLMs have sucked the oxygen out of the room,
41400	44000	like everyone is just doing LLMs.
44000	46880	OK, today I have the pleasure to speak
46880	51600	with Francois Chollet, who is a AI researcher at Google
51600	53280	and creator of Keras.
53280	56360	And he's launching a prize in collaboration
56360	58560	with Mike Canouf, the co-founder of Xavier,
58560	60280	who we'll also be talking to in a second,
60280	63840	a million dollar prize to solve the ARC benchmark
63840	64720	that he created.
64720	66960	So first question, what is the ARC benchmark,
66960	68440	and why do we even need this prize?
68440	70120	Why won't the biggest LLM we have in a year
70120	71800	be able to just saturate it?
71800	72360	Sure.
72360	75120	So ARC is intended as a kind of IQ test
75120	76640	for machine intelligence.
76640	80080	And what makes it different from most LLM benchmarks out there
80080	83800	is that it's designed to be resistant to memorization.
83800	85880	So if you look at the way LLMs work,
85880	89280	they're basically this big interpolative memory.
89280	91480	And the way you scale up their capabilities
91480	95080	is by trying to cram as much knowledge and patterns
95080	96880	as possible into them.
96880	101440	And by contrast, ARC does not require a lot of knowledge
101440	102240	at all.
102240	103960	It's designed to only require what's
103960	108360	known as core knowledge, which is basic knowledge about things
108360	112360	like elementary physics, objectness, counting,
112360	114640	that sort of thing, the sort of knowledge
114640	119200	that any four-year-old or five-year-old possesses.
119200	122600	But what's interesting is that each puzzle in ARC
122600	126080	is novel, is something that you've probably not encountered
126080	129680	before, even if you've memorized the entire internet.
129680	135800	And that's what makes ARC challenging for LLMs.
135800	139400	And so far, LLMs have not been doing very well on it.
139400	141720	In fact, the approaches that are working well
141720	144400	are more towards discrete program search, program
144400	145760	synthesis.
145760	148320	So first of all, I'll make a comment
148320	150720	that I'm glad that as a skeptic of LLM,
150720	155640	you have put out yourself a benchmark that is it accurate
155640	158880	to say that, suppose that the biggest model we have in a year
158880	161800	is able to get 80% on this, then your view would be
161800	163880	we are on track to AGI with LLMs.
163880	165240	How would you think about that?
165240	167400	Right.
167400	168840	I'm pretty skeptical that we're going
168840	171600	to see LLM do 80% in a year.
171600	173720	That said, if we do see it, you would also
173720	176120	have to look at how this was achieved.
176120	180320	If you just train the model and millions or billions
180320	182440	of puzzles similar to ARC so that you're
182440	187440	relying on the ability to have some overlap between the tasks
187440	188800	that you train on and the tasks that you're
188800	190520	going to see at this time, then you're still
190520	192480	using memorization.
192480	194440	And maybe it can work.
194440	197520	Hopefully, ARC is going to be good enough
197560	200520	that it's going to be resistant to this sort of attempt
200520	202280	at brute forcing.
202280	203280	But you never know.
203280	204560	Maybe it could happen.
204560	206320	I'm not saying it's not going to happen.
206320	208200	ARC is not a perfect benchmark.
208200	210200	Maybe it has flaws.
210200	213120	Maybe it could be hacked in that way.
213120	217120	So I guess I'm curious about what would GPTI
217120	220760	have to do that you're very confident that it's
220760	222160	on the path to AGI?
222160	224720	What would make me change my mind about LLMs
224720	229920	is basically, if I start seeing a critical mass of cases
229920	232120	where you show the model with something
232120	235080	it has not seen before, a task that's actually
235080	237920	novel from the perspective of its training data, something
237920	239960	that's not in the training data, and if it can actually
239960	242880	adapt on the fly.
242880	243960	And this is true for LLMs.
243960	246080	But really, this would catch my attention
246080	248840	with any for any AI technique out there.
248840	253600	If I can see the ability to adapt to novelty on the fly
253600	255600	to pick up new skills efficiently,
255600	258040	then I would be extremely interested.
258040	261440	I would think this is on the path to AGI.
261440	264680	So the advantage they have is that they do get to see everything.
264680	267640	Maybe I'll take issue with how much they are relying on that.
267640	269040	But let's suppose that they are relying.
269040	272200	Obviously, they're relying on that more than humans do.
272200	275560	To the extent that they do have so much indistribution,
275560	277840	to the extent that we have trouble distinguishing
277840	281520	whether an example is indistribution or not,
281520	283240	well, if they have everything in distribution,
283240	285280	then they can do everything that we can do.
285280	287720	Maybe it's not indistribution for us.
287720	290160	Why is it so crucial that it has to be out of distribution
290160	291520	for them?
291520	292920	Why can't we just leverage the fact
292920	294440	that they do get to see everything?
294440	295680	Right.
295680	297560	You're asking basically what's the difference
297560	299280	between actual intelligence, which
299280	301920	is the ability to adapt to things you've not been prepared
301920	306040	for, and pure memorization, like reciting what you've seen
306040	306920	before.
306920	310120	And it's not just some semantic difference.
310120	313840	The big difference is that you can never
313840	318520	pre-train on everything that you might see at test time,
318520	320840	because the world changes all the time.
320840	324400	So it's not just the fact that the space of possible tasks
324400	325280	is infinite.
325280	328080	And even if you're trained on millions of them,
328080	330120	you've only seen zero person out of the total space.
330120	334720	It's also the fact that the world is changing every day.
334720	337800	This is why we, the human species,
337840	340480	developed intelligence in the first place.
340480	344720	If there was a shifting as a distribution for the world,
344720	347080	for the universe, for our lives, then we would not
347080	348400	need intelligence at all.
348400	351840	In fact, many creatures, many insects, for instance,
351840	353440	do not have intelligence.
353440	358440	Instead, what they have is they have in their connectome,
358440	361120	in their genes, hard-coded programs,
361120	363800	behavioral programs that map some stimuli
363800	365320	to appropriate response.
365320	367720	And they can actually navigate their lives
367720	371160	to environments in a way that's very evolutionary fit.
371160	374400	That way, without needing to learn anything.
374400	377560	And while if our environment was static enough,
377560	379920	predictable enough, what would have happened
379920	381960	is that evolution would have found
381960	384400	the perfect behavioral program, a hard-coded,
384400	385720	static behavioral program.
385720	388480	We'd have written it into our genes.
388480	390880	We would have a hard-coded brain connectome.
390880	392240	And that's what we were running on.
392240	393440	But no, that's not what happened.
393440	396240	Instead, we have general intelligence.
396280	400360	We are born with extremely little knowledge about the world.
400360	403760	But we are born with the ability to learn very efficiently
403760	405960	and to adapt in the face of things
405960	407720	that we've never seen before.
407720	408920	And that's what makes us unique.
408920	411960	And that's what is really, really challenging
411960	413640	to recreate in machines.
413640	415240	I want to wrap it all in that a little bit.
415240	417760	But before I do that, maybe I'm going
417760	419920	to overlay some examples of what an arc-like challenge looks
419920	421760	like for the YouTube audience.
421760	423800	But maybe for people listening on audio,
423800	426680	can you just describe what an example arc challenge
426680	427160	will look like?
427160	427640	Sure.
427640	431800	So one arc puzzle, it looks kind of like an IQ test puzzle.
431800	435480	You've got a number of demonstration input-adput pairs.
435480	439200	So one pair is made of two grids.
439200	441800	So one grid shows you an input.
441800	444040	And the second grid shows you what
444040	447840	you should produce as a response to that input.
447840	450600	And you get a couple pairs like this
450600	452480	to demonstrate the nature of the task,
452480	455080	to demonstrate what you're supposed to do with your inputs.
455080	459160	And then you get a new test input.
459160	463000	And your job is to produce the corresponding test outputs.
463000	464920	You look at the demonstration pairs.
464920	468640	And from that, you figure out what you're supposed to do.
468640	471240	And you show that you've understood it on this new test
471240	472800	pair.
472800	477960	And importantly, in order to the knowledge basis
477960	481640	that you need, in order to approach these challenges,
481640	483400	is you just need core knowledge.
483400	486200	And core knowledge is basically the knowledge
486200	490760	of what makes an object, basic counting, basic geometry,
490760	493400	topology, symmetries, that sort of thing.
493400	495360	So extremely basic knowledge.
495360	497640	LLMs for sure possess such knowledge.
497640	501480	Any child possesses such knowledge.
501480	504800	And what's really interesting is that each puzzle is new.
504800	506040	So it's not something that you're
506040	511000	going to find elsewhere on the internet, for instance.
511040	514360	And that means that whether it's as a human or as a machine,
514360	517520	every puzzle you have to approach it from scratch.
517520	519520	You have to actually reason your way through it.
519520	523000	You cannot just fetch the response from your memory.
523000	527640	So the core knowledge, one contention here
527640	532600	is we are only now getting multimodal models who,
532600	534520	because of the data that are trained on,
534520	537280	are trained to do spatial reasoning.
537280	539280	Whereas, obviously, not only humans,
539280	541760	but for billions of years of revolution,
541760	544200	we've had our ancestors have had to learn
544200	548600	how to understand abstract, physical, and spatial properties
548600	550600	and recognize the patterns there.
550600	554920	And so one view would be, in the next year,
554920	557400	as we gain models that are multimodal native,
557400	560840	that isn't just a second class that is an add-on,
560840	563600	but the multimodal capability is a priority.
563600	566600	That it will understand these kinds of patterns
566600	568480	because that's something we see natively.
568480	571800	Whereas, right now, what Arc sees is some JSON string
571800	575600	of 100100, and it's supposed to recognize a pattern there.
575600	579720	And even if you showed a sequence of these kinds of numbers,
579720	581600	it would have a challenge making sense
581600	584240	of what kind of question you're asking it.
584240	586080	So why want it to be the case that,
586080	587480	as soon as we get multimodal models,
587480	589440	which we're on the path to unlock right now,
589440	590360	they're going to be so much better
590360	592000	at Arc-type spatial reasoning?
592000	593400	That's an incredibly cool question,
593400	594800	so I guess we're going to see the answer
594800	595920	within a few months.
595920	599160	But my answer to that is Arc grids,
599160	602240	they're just discrete 2D grids of symbols.
602240	605280	They're pretty small, like it's not like...
605280	608280	If you flatten an image as a sequence of pixels,
608280	610200	for instance, then you get something
610200	612120	that's actually very, very difficult to parse.
612120	615200	But that's not true for Arc because the grids are very small.
615200	617120	You only have 10 possible symbols.
617120	618840	So there's these 2D grids that are actually
618840	621360	very easy to flatten as sequences.
621360	623480	And transformers, LLMs, they're very good
623480	624560	at processing the sequences.
624560	629240	In fact, you can show that LLMs do fine
629240	632240	with processing Arc-like data
632240	637240	by simply fine-tuning LLMs on some subsets of the tasks
638440	642160	and then trying to test it on small variations
642160	643240	of these tasks.
643240	646240	And you see that, yeah, the LLMs can encode
646240	649440	just fine solution programs for tasks
649440	650800	that they've seen before.
650800	652560	So it does not really have a problem
652560	657560	parsing the input or figuring out the program.
657640	661400	The reason why LLMs don't do well on Arc
661400	664640	is really just the unfamiliarity aspect.
664640	667560	The fact that each new task is different
667560	669240	from every other task.
669240	671880	You cannot, basically, you cannot memorize
671880	673840	the solution programs in advance.
673840	676640	You have to synthesize a new solution program
676640	678480	on the fly for each new task.
678480	680800	And that's really what LLMs are struggling with.
680840	682480	So before I do more devil's advocate,
682480	684200	I just want to step back and explain
684200	687240	why I'm especially interested in having this conversation.
687240	689480	And obviously the million dollar Arc prize,
689480	691920	I'm excited to actually play with it myself.
691920	695400	And hopefully the Vesuvius challenge,
695400	699760	which was Nat Friedman's prize for solving decoding scrolls,
699760	702000	the winner of that, decoding the scrolls from
702000	703600	that were buried in the volcanoes
703600	706760	in the Herculaneum library that was solved
706760	708680	by a 22 year old who was listening
708680	709840	to the podcast, Luke Farator.
709840	711800	So hopefully somebody listening will find
711800	714240	this challenge intriguing and find a solution.
714240	718200	So I'm, and the reason I've had on recently
718200	721680	a lot of people who are bullish on LLMs
721680	723560	and I've had discussions with them
723560	725640	before interviewing you about how do we explain the fact
725640	727440	that LLMs don't seem to be natively performing
727440	728800	that well on Arc.
728800	732440	And I found their explanations somewhat contrived
732440	735120	and I'll try out some of the reasons on you.
735120	737640	But it is actually an intriguing fact
737840	738960	that they actually, these are,
738960	741120	some of these problems are relatively straightforward
741120	742400	for humans to understand.
742400	744360	And they do struggle with them
744360	745920	if you just input them natively.
745920	747640	All of them are very easy for humans.
747640	749760	Like any smart human should be able
749760	752560	to do 90%, 95% on Arc.
752560	753400	Smart human.
753400	755360	A smart human, but even a five year old.
755360	757320	So with very, very little knowledge,
757320	760280	they could definitely do over 50%.
760280	764560	So let's talk about that because you,
765480	768480	I agree that smart humans will do very well on this test,
768480	773480	but the average human will probably do mediocre.
773680	774640	Not really.
774640	776920	So we actually tried with average humans,
776920	778280	the score about 85.
778280	780640	That was with Amazon Mechanical Turk workers, right?
780640	782800	I honestly don't know the demographic profile
782800	784040	of Amazon Mechanical Turk workers,
784040	787320	but imagine just interacting with the platform
787320	789080	that Amazon has set up to do remote work.
789080	791920	That's not the median human across the planet, I'm guessing.
792120	794680	I mean, the broader point here being that,
794680	797200	so we see the spectrum in humans
797200	800160	where humans obviously have AGI,
800160	802000	but even within humans, you see a spectrum
802000	804200	where some people are relatively dumber
804200	807920	and they'll do perform work on IQ like tests.
807920	809480	For example, Raven's progressive matrices.
809480	811680	If you look at how the average person performs on that
811680	812920	and you look at the quick kind of questions
812920	814400	that is this sort of midtermists,
814400	815360	half of people will get it right,
815360	816360	half of people will get it wrong.
816360	817800	Some of them are like pretty trivial.
817800	820560	For us, we might think like this was kind of trivial.
820560	822200	And so humans have AGI,
822200	825200	but from relatively small tweaks,
825200	827440	you can go from somebody who misses
827440	828920	these kinds of basic IQ test questions
828920	830240	to somebody who gets them all right,
830240	831560	which suggests that actually,
831560	834480	if these models are doing natively,
834480	836240	we'll talk about some of the previous performances
836240	837120	that people have tried with these models,
837120	839000	but somebody with a Jack Cole
839000	842800	with a 240 million parameter model got 35%.
842800	845080	Doesn't that suggest that they're on this spectrum
845080	846480	that clearly exists within humans
846480	848560	and they're gonna be saturated at pretty soon?
848560	851360	Yeah, so that's a bunch of interesting points here.
851360	856360	So there is indeed a branch of LLM approaches
856800	859960	suspended by Jack Cole that are doing quite well,
859960	863000	that are in fact a state of the art.
863000	865520	But you have to look at what's going on there.
865520	866360	So there are two things.
866360	869480	The first thing is that to guess these numbers,
869480	871840	you need to pre-train your LLM
871840	874520	on millions of generated art tasks.
874520	877840	And of course, if you compare that to a five-year-old child
877880	879680	looking at art for the first time,
879680	881400	the child has never done like you did before,
881400	884040	has never seen something like an art task before.
884040	886160	The only overlap between what they know
886160	889320	and what they have to do in the test is core knowledge,
889320	891560	is knowing about like counting and objects
891560	893040	and symmetries and things like that.
893040	896160	And still, they're gonna do really well
896160	897880	and they're gonna do much better than the LLM
897880	900560	trained on millions of similar tasks.
900560	903400	And the second thing that's something to note
903400	907360	about the Jack Cole approach is one thing
907360	910520	that's really critical to making the model work at all
910520	912560	is test time fine tuning.
912560	914320	And that's something that's really missing, by the way,
914320	919320	from LLM approaches right now is that, you know,
919360	921680	most of the time when you're using an LLM,
921680	923760	it's just doing static inference.
923760	926920	The model is frozen and you're just prompting it
926920	928280	and then you're getting an answer.
928280	931400	So the model is not actually learning anything on the fly.
931400	935880	Its state is not adapting to the task at hand.
936120	938280	What Jack Cole is actually doing is that
938280	941960	for every test problem is on the fly,
941960	946960	is fine tuning a version of the LLM for that task.
947080	948920	And that's really what's unlocking performance.
948920	951720	If you don't do that, you get like 1%, 2%.
951720	955000	So basically something completely negligible.
955000	957080	And if you do test time fine tuning
957080	958880	and you add a bunch of tricks on top,
958880	961080	then you end up with interesting performance numbers.
961080	964240	So I think what he's doing is trying to address
964240	967080	one of the key limitations of LLMs today,
967080	968680	which is the lack of active inference,
968680	971600	is actually adding active inference to LLMs.
971600	973360	And that's working extremely well actually.
973360	974800	So that's fascinating to me.
974800	977200	That there's so many interesting rabbit holes there.
978360	980120	Should I take them in sequence or deal with them all at once?
980120	981200	Let me just start.
981200	984480	So the point you made about the fact
984480	986880	that you need to unlock the adapter compute
986880	990640	slash test time compute, a lot of the scale maximalist,
990640	991800	I think this will be interesting rabbit hole
991800	992720	to explore with you,
992720	995040	because a lot of the scaling maximalist
995040	997600	have your broader perspective in the sense
997600	1000400	that they think that in addition to scaling,
1000400	1001960	you need these kinds of things,
1001960	1004080	like unlocking adaptive compute
1004080	1007400	or doing some sort of RL to get the system to working.
1007400	1009920	And their perspective is that this is a relatively
1009920	1012320	straightforward thing that will be added atop
1012320	1015440	the representations that a scaled up model
1015440	1017880	has greater access to.
1017880	1020400	No, it's not just a technical detail.
1020400	1021840	It's not a straightforward thing.
1021840	1023240	It is everything.
1023240	1025120	It is the important part.
1025120	1028800	And the scale maximalist argument,
1028800	1033080	you know, it boils down to, you know,
1033080	1035320	these people, they refer to scaling loss,
1035320	1037440	which is this empirical relationship
1037440	1039720	that you can draw between how much compute
1039720	1041000	you spend on training a model
1041000	1043600	and the performance you're getting on benchmarks, right?
1043600	1046320	And the key question here, of course, is,
1046320	1048160	well, how do you measure performance?
1048160	1051000	What it is that you're actually improving
1051000	1053080	by adding more compute and more data?
1053080	1055480	And, well, it's benchmark performance, right?
1055480	1058400	And the thing is, the way you measure performance
1058400	1061360	is not a technical detail.
1061360	1066160	It's not an afterthought because it's gonna narrow down
1066160	1067840	the set of questions that you're asking.
1067840	1070400	And so, accordingly, it's gonna narrow down
1070400	1073280	the set of answers that you're looking for.
1073280	1076840	If you look at the benchmarks we're using for LMS,
1076840	1079640	they're all memorization-based benchmarks.
1079640	1081880	Like, sometimes they are literally just knowledge-based,
1081880	1083440	like a school test.
1083440	1084760	And even if you look at the ones
1084760	1088920	that are, you know, explicitly about reasoning,
1088920	1090640	you realize, if you look closely,
1090640	1093000	that it's, in order to solve them,
1093000	1098000	it's enough to memorize a finite set of reasoning patterns.
1099080	1100520	And then you just reapply them.
1100520	1102840	They're like static programs.
1102840	1105600	LMS are very good at memorizing static programs,
1105600	1106560	small static programs.
1106560	1111560	And they've got this sort of like bank of solution programs.
1111760	1113720	And when you give them a new puzzle,
1113720	1117240	they can just fetch the appropriate program, apply it.
1117240	1119160	And it's looking like it's reasoning,
1119160	1121000	but really it's not doing any sort of
1121000	1122640	on-the-flight program synthesis.
1122640	1125280	All it's doing is program fetching.
1125280	1127400	So you can actually solve all these benchmarks
1127400	1128680	with memorization.
1128680	1131800	And so, what you're scaling up here,
1131800	1133360	like if you look at the models,
1133360	1136680	they are big parametric curves
1136680	1138320	fitted to a data distribution,
1138320	1139480	which I call in descent.
1139480	1143600	So they're basically these big interpolative databases,
1143600	1144960	interpolative memories.
1144960	1148560	And of course, if you scale up the size of your database
1148560	1151400	and you cram into it more knowledge,
1151400	1153640	more patterns and so on,
1153640	1156760	you are gonna be increasing its performance
1156760	1159400	as measured by a memorization benchmark.
1159400	1160960	That's kind of obvious.
1160960	1162440	But as you're doing it,
1162440	1165080	you are not increasing the intelligence
1165080	1166760	of the system one bit.
1166760	1168640	You are increasing the skill of the system.
1168640	1170600	You are increasing its usefulness,
1170600	1174360	its scope of applicability, but not its intelligence
1174360	1176640	because skill is not intelligence.
1176640	1178480	And that's the fundamental confusion
1179480	1182120	that people run into is that
1182120	1184160	they're confusing skill and intelligence.
1184160	1185640	Yeah, there's a lot of fascinating things
1185640	1186480	to talk about here.
1186480	1190640	So skill, intelligence, interpolation.
1190640	1192240	I mean, okay, so the thing about
1192240	1196720	they're fitting some manifold into that maps the input data,
1196720	1198440	there's a reductionist way to talk about what happens
1198440	1199960	in the human brain that says
1199960	1203200	that it's just axons firing at each other.
1203200	1205880	But we don't care about the reductionist explanation
1205880	1206720	of what's happening.
1206720	1211200	We care about what the sort of meta at the
1211200	1213840	macroscopic level, what happens when these things combine.
1213840	1215960	As far as the interpolation goes,
1215960	1219120	so okay, let's look at one of the benchmarks here.
1219120	1222680	There's one benchmark that does great school math
1222680	1226720	and these are problems that like a smart high schooler
1226720	1228480	would be able to solve.
1228480	1231760	It's called GSM 8K and these models get 95% on these.
1231760	1233200	Like basically they always nail it.
1233200	1234320	That's memorization benchmark.
1234320	1235520	Okay, let's talk about what that means.
1235520	1238480	So here's one question about from that benchmark.
1238480	1240120	So 30 students are in a class,
1240120	1241880	one fifth of them are 12 year olds,
1241880	1245040	one third are 13 year old, one 10th are 11 year olds.
1245040	1248320	How many of them are not 11, 12 or 13 years old?
1248320	1250440	So I agree, like this is not rocket science, right?
1250440	1253200	You can write down on paper how you go through this problem
1253200	1254600	and a high school kid,
1254600	1256640	at least a smart high school kid should be able to solve it.
1256640	1258920	Now, when you say memorization,
1258920	1263000	it still has to reason through how to think about fractions
1263000	1265000	and what is the context of the whole problem
1265000	1267840	and then combining the different calculations it's doing.
1267840	1270200	It depends how you want to define reasoning,
1270200	1272200	but there are two definitions you can use.
1272200	1277200	So one is I have available a set of program templates.
1277680	1281200	It's like the structure of the puzzle,
1281200	1282960	which can also generate its solution.
1282960	1285600	And I'm just gonna identify the right template,
1285600	1286960	which is in my memory.
1287800	1289840	I'm gonna input the new values into the template,
1289840	1291840	run the program, get the solution.
1291840	1293480	And you could say this is reasoning.
1293480	1295400	And I say, yeah, sure, okay.
1295400	1297560	But another definition you can use is reasoning
1297560	1301280	is the ability to, when you're faced with a puzzle,
1301280	1304480	given that you don't have already a program in memory
1304480	1309480	to solve it, you must synthesize on-the-fly a new program
1309680	1312960	based on bits of pieces of existing programs that you have.
1312960	1315480	You have to do on-the-fly program synthesis.
1315480	1317280	And it's actually dramatically harder
1317280	1320040	than just fetching the right memorized program
1320040	1321320	and replying it.
1321320	1324560	So I think maybe we are overestimating
1324560	1326840	the extent to which humans are so sample efficient.
1326840	1330200	They also don't need training in this way
1330200	1332760	where they have to drill in these kinds
1332800	1336760	of pathways of reasoning through certain kinds of problems.
1336760	1339200	So let's take math, for example.
1339200	1341240	It's not like you can just show a baby
1341240	1342840	the axioms of set theory.
1342840	1344080	And now they know math, right?
1344080	1345680	So when they're growing up,
1345680	1348120	you had to do years of teaching them pre-algebra.
1348120	1350360	Then you got to do a year of teaching them doing drills
1350360	1352240	and going through the same kind of problem in algebra,
1352240	1355040	then geometry, pre-calculus, calculus.
1355040	1356520	Absolutely, so training?
1356520	1357880	Yeah, but isn't that like the same kind of thing
1357880	1360080	where you can't just see one example
1360080	1361960	and now you have the program or whatever.
1361960	1362800	You actually had to drill it.
1362800	1363800	These models also had to drill it
1363800	1365080	with a bunch of returning data.
1365080	1368320	Sure, I mean, in order to do on-the-fly program synthesis,
1368320	1371920	you actually need building blocks to work from.
1371920	1375440	So knowledge and memory are actually tremendously important
1375440	1376280	in the process.
1376280	1380560	I'm not saying it's memory versus reasoning.
1380560	1384640	In order to do effective reasoning, you need memory.
1384640	1387680	But it sounds like it's compatible with your story
1387680	1390440	that through seeing a lot of different kinds of examples,
1390440	1391960	these things can learn to reason
1391960	1393800	within the context of those examples.
1393800	1396160	And we can also see within bigger and bigger models.
1396160	1398800	So that was an example of a high school level math problem.
1399880	1402120	Let's say a model that's smaller than GPT-3
1402120	1403680	couldn't do that at all.
1403680	1404760	As these models get bigger,
1404760	1406400	they seem to be able to pick up bigger and bigger.
1406400	1408400	It's not really a size issue.
1408400	1410600	It's more like a training data issue in this case.
1410600	1413680	Well, bigger models can pick up these kinds of circuits
1413680	1416040	which smaller models apparently don't do a good job
1416040	1417280	of doing this even if you were to train them
1417280	1418240	on this kind of data.
1418240	1419080	Doesn't that just suggest
1419080	1420400	that you have bigger and bigger models?
1420400	1422240	They can pick up bigger and bigger pathways
1422240	1424040	or more general ways of reasoning.
1424040	1424960	Absolutely.
1424960	1426400	But then isn't that intelligence?
1426400	1427600	No, no, it's not.
1427600	1429520	If you scale up your database
1429520	1432280	and you keep adding to it more knowledge,
1432280	1433640	more program templates,
1433640	1435560	then sure it becomes more and more skillful.
1435560	1437400	You can apply it to more and more tasks.
1437400	1441120	But general intelligence is not tasks with six skills
1441120	1443400	scaled up to many skills.
1443400	1446640	Because there is an infinite space of possible skills.
1446680	1449200	General intelligence is the ability to approach
1449200	1451040	any problem, any skill,
1451040	1453960	and very quickly master it using valid or data.
1453960	1456920	Because this is what makes you able to face
1456920	1458240	anything you might ever encounter.
1458240	1459360	This is what makes,
1460800	1462600	this is the definition of generality.
1462600	1465640	Like generality is now specifically scaled up.
1465640	1469120	It is the ability to apply your mind
1469120	1471480	to anything at all, to arbitrary things.
1471480	1473040	And this requires, fundamentally,
1473040	1475040	it requires the ability to adapt,
1475080	1477080	to learn on the fly efficiently.
1477080	1481280	So, my claim is that by doing this free training
1481280	1482680	on bigger and bigger models,
1482680	1484440	you are gaining that capacity
1484440	1486760	to then generalize very efficiently.
1486760	1488120	Let me give you an example.
1488120	1489280	Let me give you an example.
1489280	1491240	So, your own company, Google,
1491240	1494240	in their paper on Gemini 1.5,
1494240	1495920	they had this very interesting example
1495920	1500520	where they would give, in context,
1500520	1501840	they would give the model,
1501840	1504360	the grammar book and the dictionary
1504360	1507520	of a language that has less than 200 living speakers.
1507520	1509480	So, it's not in the free training data.
1509480	1511520	And you just give them the dictionary
1511520	1514120	and it basically is able to speak this language
1514120	1515080	and translate to it,
1515080	1517640	including the complex and organic ways
1517640	1520200	in which languages are structured.
1520200	1521760	So, a human, if you showed me a dictionary
1521760	1522720	from English to Spanish,
1522720	1524560	I'm not gonna be able to pick up the
1524560	1525840	how to structure sentences
1525840	1528040	and how to say things in Spanish.
1528040	1530280	The fact that because of the representations
1530280	1533120	that it has gained through this free training,
1533120	1535240	it is able to now extremely efficiently
1535240	1536360	learn a new language.
1536360	1538600	Doesn't that show that this kind of free training
1538600	1541240	actually does increase your ability to learn new tasks?
1541240	1543200	If you're right, if you were right,
1543200	1545440	LLMs would do really well on arch puzzles
1545440	1547680	because arch puzzles are not complex.
1547680	1549880	Each one of them requires very little knowledge.
1549880	1552280	Each one of them is very low on complexity.
1552280	1554600	You don't need to think very hard about it.
1554600	1556520	They're actually extremely obvious for humans,
1556520	1558240	like even children can do them.
1558240	1562920	But LLMs cannot, even LLMs that have, you know,
1562920	1565360	100,000 times more knowledge than you do.
1565360	1566400	They still cannot.
1566400	1569560	And the only thing that makes arch special
1569560	1571680	is that it was designed with this intent
1571680	1573080	to resist memorization.
1573080	1574320	This is the only thing.
1574320	1578960	And this is the huge blocker for LLM performance, right?
1578960	1583960	And so, you know, I think if you look at LLMs closely,
1585240	1588280	it's pretty obvious that they're not really like
1588280	1590600	synthesizing new programs on the fly
1590600	1593160	to solve the tasks that they're faced with.
1593160	1594640	They're very much replying things
1594640	1596640	that they've stored in memory.
1596640	1599280	For instance, one thing that's very striking
1599280	1602440	is LLMs can solve a CISA cipher,
1602440	1603760	you know, like a CISA cipher,
1603760	1608760	like transposing letters to code a message.
1609200	1612600	And well, that's a very complex algorithm, right?
1612600	1614920	But it comes up quite a bit on the internet.
1614920	1616440	So they've basically memorized it.
1616440	1619680	And what's really interesting is that they can do it
1619800	1622760	for a transposition length of like three or five
1622760	1624360	because there are very, very common numbers
1624360	1625880	in examples provided on the internet.
1625880	1629000	But if you try to do it with an arbitrary number,
1629000	1631120	like nine, it's gonna fail.
1631120	1634520	Because it does not encode the generalized form
1634520	1636520	of the algorithm, but only specific cases.
1636520	1640040	It does memorize specific cases of the algorithm, right?
1640040	1643160	And if it could actually synthesize on the fly
1643160	1646840	the solver algorithm, then the value of N
1646840	1648520	would not matter at all
1648520	1650880	because it does not increase the problem complexity.
1650880	1652440	I think this is true of humans as well,
1652440	1654360	where what was the study that-
1654360	1657080	Humans use memorization pattern matching all the time,
1657080	1659880	of course, but humans are not limited
1659880	1661440	to memorization pattern matching.
1661440	1663160	They have this very unique ability
1663160	1665560	to adapt to new situations on the fly.
1665560	1668160	This is exactly what enables you to navigate
1669160	1670760	every new day in your life.
1670760	1671600	I'm forgetting the details,
1671600	1674120	but there was some study that chess grandmasters
1674120	1676840	will perform very well within the context of the moves that-
1676840	1679560	Excellent example, because chess at the highest level
1679560	1682000	is all about memorization, chess memorization.
1682000	1682960	Okay, sure, we can leave that aside.
1682960	1685520	What is your explanation for the original question of
1685520	1690520	why in context the GPT- sorry, Gemini 1.5
1691800	1693520	was able to learn a language,
1693520	1695600	including the complex grammar structure?
1695600	1697400	Doesn't that show that they can pick up new knowledge?
1697400	1700120	I would assume that it has simply mined
1700120	1703880	from its extremely extensive and imaginably vast
1703880	1707400	training data, it has mined the required template
1707400	1708880	and then it's just reusing it.
1708880	1711360	We know that they have a very poor ability
1711360	1714840	to synthesize new program templates like this on the fly
1714840	1716640	or even adapt existing ones.
1716640	1718760	They're very much limited to fetching.
1718760	1720880	Suppose there's a programmer at Google,
1720880	1722880	they go into the office in the morning.
1722880	1724280	At what point are they doing something
1724280	1727760	that 100% cannot be due to fetching some template
1727760	1730520	that even if they, suppose they were an LLM,
1730520	1732120	they could not do if they had fetched some template
1732120	1732960	from their program.
1733000	1733920	At what point do they have to use
1733920	1735680	this so-called extreme generalization capability?
1735680	1737560	Forget about Google software developers.
1737560	1740400	Every human, every day of their lives
1740400	1743920	is full of novel things that they've not been prepared for.
1743920	1747880	You cannot navigate your life based on memorization alone.
1747880	1748720	It's impossible.
1748720	1751440	I'm sort of denying the premise that they're,
1751440	1753040	you also agree they're not doing like,
1753040	1754600	quote-unquote memorization.
1754600	1757400	It seems like you're saying they're less capable
1757400	1759440	of generalization, but I'm just curious of like,
1759440	1761640	the kind of generalization they do,
1761960	1764240	if you get into the office
1764240	1765680	and you try to do this kind of generalization,
1765680	1766640	you're gonna fail at your job.
1766640	1768640	But what is the first point, you're a programmer.
1768640	1770640	What is the first point when you try to do that generalization,
1770640	1772120	you would lose your job
1772120	1774640	because you can't do the extreme generalization?
1774640	1776120	I don't have any specific examples,
1776120	1781120	but literally like, take this situation for instance,
1781120	1783680	you've never been here in this room.
1783680	1786400	Maybe you've been in this city a few times, I don't know,
1786400	1789280	but there's a fair amount of novelty.
1789280	1791880	You've never been interviewing me.
1791880	1793800	There's a fair amount of novelty
1793800	1795880	every hour of every day in your life.
1795880	1798920	And it's in fact, by and large,
1798920	1802280	more novelty than any LLM could handle.
1802280	1804840	Like if you just put a LLM in a robot,
1804840	1806200	it could not be doing all the things
1806200	1808800	that you've been doing today, right?
1808800	1811600	Or take on like cell driving cars, for instance.
1811600	1815320	You take a cell driving car operating in the barrier.
1815320	1818000	Do you think you could just drop it in New York City
1818000	1821240	or drop it in London where people drive on the left?
1821240	1822360	No, it's gonna fail.
1822360	1824880	So not only can you drop, not like,
1824880	1829880	make it generalize to a change of rules of driving rules,
1831600	1834480	but you can not even make it generalize to a new city.
1834480	1838200	It needs to be trained on each specific environment.
1838200	1841680	I mean, I agree that self-driving cars aren't AGI.
1841680	1842840	But it's the same type of model,
1842840	1844120	they're transformers as well.
1844120	1845640	I mean, I don't know,
1846240	1848040	they also have brains with neurons in them,
1848040	1849880	but they're less intelligent because they're small.
1849880	1850720	It's not the same architecture.
1850720	1851560	We can get into that.
1851560	1856560	But so I still don't understand like a concrete thing of,
1857560	1858920	we also need training.
1858920	1860000	That's why education exists.
1860000	1862200	That's why we had to spend the first 18 years of our life
1862200	1863280	doing drills.
1863280	1866160	We have a memory, but we are not a memory.
1866160	1868120	We are not limited to just a memory.
1868120	1870000	I'm denying the premise that that's necessarily
1870000	1871120	the only thing these models are doing.
1871120	1873720	And I'm still not sure what is the task
1873720	1877000	that a remote worker would have to,
1877000	1879200	suppose you do some remote work with an LLM
1879200	1880480	and they're programmer,
1880480	1882040	what is the first point that you realize
1882040	1883760	this is not a human, this is an LLM?
1883760	1886080	What about they just send them a knock puzzle
1886080	1887280	and see how they do?
1887280	1889240	No, like part of their job, you know?
1889240	1892440	But you have to deal with novelty all the time.
1892440	1894720	Okay, so if you, is there a world in which
1894720	1896560	all the programmers are replaced?
1896560	1898360	And then we're still saying,
1898360	1900120	but they're only doing memorization
1900120	1901440	late in programming tasks,
1901440	1903160	but they're still producing a trillion dollars
1904160	1906600	worth of output in the form of code.
1906600	1908400	Software development is actually a pretty good example
1908400	1911640	of a job where you're dealing with novelty all the time.
1911640	1913720	Or if you're not, well, I'm not sure what you're doing.
1913720	1917600	So I personally use Genetic VI very little
1917600	1919720	in my software development job.
1919720	1923080	And before LLMs, I think I was also using
1923080	1925000	Stack Overflow very little.
1925000	1927440	You know, some people maybe are just copy-pasting stuff
1927440	1928280	from Stack Overflow,
1928280	1930680	or nowadays copy-pasting stuff from an LLM.
1931680	1934960	Personally, I try to focus on problem-solving.
1934960	1936920	The syntax is just a technical detail.
1936920	1939360	What's really important is the problem-solving.
1939360	1943960	Like the essence of programming is engineering
1943960	1947360	mental models, like mental representations
1947360	1949480	of the problem you're trying to solve.
1949480	1952520	But you can, you know, we have many,
1952520	1954200	people can interact with these systems themselves
1954200	1956200	and you can go to chat GPT and say,
1956200	1958640	here's a specification of the kind of program I want.
1958640	1959560	They'll build it for you.
1959640	1961800	As long as there are many examples of this program
1961800	1963600	on like GitHub and Stack Overflow and so on,
1963600	1967320	sure, they will fetch the program for you from their memory.
1967320	1969160	But you can change arbitrary details.
1969160	1972320	You can say I need it to work on this different kind of server.
1972320	1975920	If that were true, there would be no software engineers today.
1975920	1978280	I agree. We're not at a full AGI yet,
1978280	1980360	in the sense that these models have,
1980360	1982560	let's say, less than a trillion parameters.
1982560	1984200	A human brain has somewhere on the order
1984200	1985960	of 10 to 30 trillion synapses.
1985960	1988480	I mean, if you were just doing some naive math,
1988520	1991120	you're like at least 10x under parameterized.
1991120	1992640	So I agree we're not there yet,
1992640	1997280	but I'm sort of confused on why we're not on the spectrum,
1997280	1999400	where yes, I agree that there's many kinds
1999400	2000880	of generalization they can do,
2000880	2002760	but it seems like they're on this kind of smooth spectrum
2002760	2004160	that we see even within humans,
2004160	2007360	where some humans would have a hard time doing an ARC type test.
2007360	2008800	We see that based on the performance
2008800	2011040	on progressive Ravens matrices type IQ tests.
2011040	2014040	I'm not a fan of IQ tests because for the most part,
2014040	2017720	you can train on IQ tests and get better at them.
2017760	2019880	So they have very much memorization based.
2019880	2022360	And this is actually the main pitfall
2022360	2025880	that ARC tries not to fall far.
2025880	2026760	I'm still not confused.
2026760	2029880	So if all remote jobs are automated
2029880	2032240	in the next five years, let's say,
2032240	2034800	at least that don't require you to be like sort of a service.
2034800	2036000	It's not like a salesperson
2036000	2037480	where you want the human to be talking,
2037480	2038840	but like programming or whatever.
2038840	2042840	In that world, would you say that that's not possible
2042840	2045600	because a lot of what a programmer needs to do,
2045600	2047640	definitely requires things that would not be
2047640	2048720	in any free training corpus?
2048720	2050040	Sure. I mean, in five years,
2050040	2051560	there will be more software engineers
2051560	2053200	than there are today and not too well.
2053200	2054280	But I just want to understand.
2054280	2056040	So I'm still not sure.
2056040	2058160	I mean, I know how to, I studied computer science.
2058160	2060120	I think if I had become a code monkey out of college,
2060120	2062040	like what would I be doing?
2062040	2063320	I go to my job.
2063320	2066360	What is the first thing my boss tells me something to do?
2066360	2070280	When does he realize I'm an LLM if I was an LLM?
2070280	2072560	Probably on the first day, you know?
2072560	2073400	Again,
2073680	2078680	if it were true that LLMs could generalize
2080000	2081560	to novel problems like this
2081560	2085040	and you can actually develop software
2085040	2086680	to solve a problem they've never seen before,
2086680	2088720	you would not need software engineers anymore.
2088720	2091360	In practice, if I look at how people are using LLMs
2091360	2093160	in their software engineering job today,
2093160	2096640	they're using it as a stack of a flow replacement.
2096640	2100840	So they're using it as a way to copy paste code snippets
2100840	2103080	to perform very common actions.
2103080	2106600	And what they actually need is a database of code snippets.
2106600	2109560	They don't actually need any of the abilities
2109560	2110880	that actually make them software engineers.
2110880	2113560	I mean, when we talk about interpolating
2113560	2115240	between stack overflow databases,
2115240	2116600	if you look at the kinds of math problems
2116600	2120040	or coding problems, maybe to say that they're,
2121520	2122960	maybe let's step back on interpolation
2122960	2124640	and let me ask the question this way.
2124640	2126000	Why can't creativity,
2126000	2128280	why isn't creativity just interpolation
2128280	2131400	in a higher dimension where if a bigger model
2131400	2133320	can learn a more complex manifold,
2133320	2134800	we're gonna use the ML language.
2134800	2138240	And if you look at read a biography of a scientist,
2138240	2140360	it doesn't feel like they're not zero shot
2140360	2141280	in new scientific theories.
2141280	2143160	They're playing with existing ideas.
2143160	2145200	They're trying to juxtapose them in their head.
2145200	2149720	They try out some like slightly ever in the tree
2149720	2151600	of intellectual descendants,
2151600	2153680	they try out a different evolutionary path.
2153680	2155960	You sort of run the experiment there
2155960	2157920	in terms of publishing the paper, whatever.
2157920	2159480	It seems like a similar kind of thing humans are doing.
2159480	2161800	There's like at a higher level of generalization.
2161800	2164040	And what you see across bigger and bigger models
2164040	2165360	is they seem to be approaching
2165360	2166960	higher and higher level of generalization
2166960	2170360	where GPT-2 couldn't do a great school level math problem
2170360	2171440	that requires more generalization
2171440	2173640	that it has capability for, even that skill.
2173640	2175760	Then GPT-3 and 4 can.
2175760	2176600	So not quite.
2176600	2179960	So GPT-4 has a higher degree of skill
2179960	2181520	and higher range of skills.
2181520	2182360	Because it's-
2182360	2183200	I don't want to get into semantics here,
2183200	2184040	but I think-
2184040	2184880	The same degree of generalization.
2184880	2185720	I don't want to get into semantics here,
2185720	2188640	but the question of why can't creativity
2188640	2192800	be just interpolation on a higher dimension?
2192800	2195320	I think interpolation can be creative, absolutely.
2195320	2196920	And you know, to your point,
2196920	2199160	I do think that on some level,
2199160	2201640	humans also do a lot of memorization,
2201640	2203440	a lot of reciting, a lot of pattern matching,
2203440	2205120	a lot of interpolation as well.
2205120	2207640	So it's very much a spectrum
2208920	2211760	between pattern matching and true reasoning.
2211760	2212600	It's a spectrum.
2212600	2217480	And humans are never really at one end of the spectrum.
2217480	2219720	They're never really doing pure pattern matching
2219720	2220560	or pure reasoning.
2220560	2222920	They're usually doing some mixture of both.
2222920	2226400	Even if you're doing something that seems very reasoning heavy,
2226400	2228880	like proving a mathematical theorem,
2228880	2229960	as you're doing it, sure,
2229960	2232480	you're doing quite a bit of discrete search in your mind,
2232480	2234360	quite a bit of actual reasoning.
2234360	2238120	But you're also very much guided by intuition,
2238120	2239280	guided by pattern matching,
2239280	2242960	guided by the shape of proofs that you've seen before,
2242960	2245000	by your knowledge of mathematics.
2245000	2246840	So it's never really,
2246880	2248200	you know, all of our thoughts,
2248200	2251760	everything we do is a mixture of this sort of like
2251760	2254280	interpolative memorization based thinking,
2254280	2258600	this sort of like type one thinking and type two thinking.
2260280	2263200	Why are bigger models more sample efficient?
2263200	2267600	Because they have more reusable building blocks
2267600	2272120	that they can lean on to pick up new patterns
2272120	2272960	in their train data.
2272960	2274680	And does that pattern keep continuing
2274680	2276040	as you keep getting bigger and bigger?
2276040	2278280	To the extent that the new patterns
2278280	2280520	you're giving the model to learn
2280520	2283000	are good match for what it has learned before.
2283000	2285240	If you present something that is actually novel,
2285240	2287600	that is not in a state of distribution like an arc puzzle,
2287600	2289240	for instance, it will fail.
2289240	2290240	Let me make this claim.
2290240	2292360	The program synthesis I think is a very,
2292360	2294120	very useful intuition pump.
2294120	2295600	Why can't it be the case that what's happening
2295600	2299440	in the transformer is the early layers are doing the,
2299440	2302240	figuring out how to represent the inputting tokens.
2302240	2304600	And what the middle layers do is this kind of program search,
2304600	2307440	program synthesis, where they combine the inputs
2307440	2311080	to all the circuits in the model
2311080	2313920	where they go from the low level representation
2313920	2315240	to a higher level representation
2315240	2316320	near the middle of the model.
2316320	2319680	They use these programs, they combine these concepts,
2319680	2322600	then what comes out at the other end is the reasoning
2322600	2325160	based on that high level intelligence.
2325160	2326640	Possibly, why not?
2327720	2330840	But if these models were actually capable
2330840	2334440	of synthesizing novel programs,
2334480	2337360	however simple they should be able to do arc
2337360	2339400	because for any arc task,
2339400	2342320	if you write down the solution program in Python,
2342320	2345600	it's not a complex program, it's extremely simple
2345600	2347880	and humans can figure it out.
2347880	2350240	So why can LLMs not do it?
2350240	2352880	Okay, I think that's a fair point.
2352880	2355480	And if I turn the question around to you,
2355480	2358960	so suppose that it's the case that in a year,
2358960	2362200	a multimodal model can solve arc,
2362240	2365520	let's say get 80%, whatever the average human would get,
2365520	2367200	then AGI?
2367200	2368360	Quite possibly, yes.
2368360	2370960	I think if you start, so honestly,
2370960	2374720	what I would like to see is an LLM type model
2374720	2376760	solving arc at like 80%,
2376760	2379880	but after having only been trained
2379880	2382840	on core knowledge related stuff.
2382840	2385320	But human kids, I don't think we're necessarily
2385320	2387360	just trading on, it's not just that we have
2387360	2388800	in our show is object permanence.
2388800	2390600	Okay, let me rephrase that.
2390600	2395600	Only trained on information that is not explicitly
2395720	2398960	trying to anticipate what's gonna be in the arc test set.
2398960	2401280	But isn't the whole point of arc that you can't,
2401280	2403640	sort of, it's a new type of intelligence
2403640	2404480	every single time?
2404480	2405320	Yes, that is the point.
2405320	2407880	So if arc were perfect, flawless benchmark,
2407880	2410680	it would be impossible to anticipate within the test set.
2410680	2414160	And arc was released more than four years ago
2414160	2416640	and so far it's been resistant to memorization.
2416640	2420840	So I think it has, to some extent, passed a test of time.
2420840	2422960	But I don't think it's perfect.
2422960	2426200	I think if you try to make by hand
2427120	2429240	hundreds of thousands of arc tasks
2429240	2431800	and then you try to multiply them
2432760	2435000	by programmatically generating variations
2435000	2438520	and then you end up with maybe hundreds of millions of tasks.
2438520	2441040	Just by brute forcing the task space,
2441040	2443680	there will be enough overlap between what you're trained on
2443680	2445440	and what's in the test set that you can actually score
2445440	2446280	very highly.
2446280	2449600	So, you know, with enough scale, you can always cheat.
2449600	2451240	If you can do this for every single thing
2451240	2452880	that supposedly requires intelligence,
2452880	2453920	then what good is intelligence?
2453920	2455560	Apparently you can just brute force intelligence.
2455560	2459920	If the world, if your life, were a static distribution,
2459920	2461520	then sure, you could just brute force
2461520	2463720	the space of possible behaviors.
2463720	2467960	You could like, you know, the way we think about intelligence,
2467960	2469960	there are several metaphors, I like to use,
2469960	2472640	but one of them is you can think of intelligence
2472640	2477000	as a past finding algorithm in future situation space.
2477000	2479160	Like, I don't know if you're familiar with game development,
2479160	2483400	like RTS game development, but you have a map, right?
2483400	2486000	And you have, it's like a 2D map.
2486000	2488800	And you have partial information about it.
2488800	2491880	Like there is some fog of war on your map.
2491880	2494040	There are areas that you haven't explored yet.
2494040	2495080	You know nothing about them.
2495080	2496640	And then there are areas that you've explored,
2496640	2499920	but you only know how they were like in the past.
2499920	2501520	You don't know how they are like today.
2501520	2506760	And now, instead of thinking about a 2D map,
2506760	2510040	think about the space of possible future situations
2510040	2512640	that you might encounter and how they're connected to each other.
2512640	2514440	Intelligence is a past finding algorithm.
2514440	2517400	So once you set a goal, it will tell you
2517400	2520680	how to get there optimally.
2520680	2525240	But of course, it's constrained by the information you have.
2525240	2529240	It cannot pass find in an area that you know nothing about.
2529240	2532640	It cannot also anticipate changes.
2532640	2540040	And the thing is, if you had complete information about the map,
2540040	2542360	then you could solve the past finding problem
2542360	2546040	by simply memorizing every possible path, every mapping
2546040	2551320	from point A to point B. You could solve the problem
2551320	2552400	with pure memory.
2552400	2555040	But the reason you cannot do that in real life
2555040	2557120	is because you don't actually know what's
2557120	2558920	going to happen in the future.
2559800	2561600	I feel like you're using words like memorization, which
2561600	2563000	we would never use for human children.
2563000	2566680	If your kid learns to do algebra and then now learns
2566680	2568760	to do calculus, you wouldn't say they memorized calculus.
2568760	2572160	If they can just solve any arbitrary algebraic problem,
2572160	2574000	you wouldn't say they memorized algebra.
2574000	2575080	They say they've learned algebra.
2575080	2578160	Humans are never redoing pure memorization or pure reasoning.
2578160	2579520	But that's only because you're semantically
2579520	2581160	labeling when the human does the skill.
2581160	2583560	It's a memorization when the exact same skill is done by the LLM
2583560	2584880	as you can measure by these benchmarks.
2584880	2586640	And you can just plug in any sort of math problem.
2586680	2588760	Sometimes humans are doing the exact same as the LLM
2588760	2590840	is doing, which is just, for instance,
2590840	2592640	I know if you learn to add numbers,
2592640	2594800	you're memorizing an algorithm.
2594800	2595960	You're memorizing a program.
2595960	2597640	And then you can reapply it.
2597640	2601720	You are not synthesizing on the fly the addition program.
2601720	2604000	So obviously at some point, some human had to figure out
2604000	2604600	how to do addition.
2604600	2607000	But the way a kid learns it is not
2607000	2610160	that they figure out from the actions of set theory
2610160	2610800	how to do addition.
2610800	2612120	I think what you're learning in school
2612120	2613960	is mostly memorization.
2614000	2617080	So my claim is that, listen, these models
2617080	2620880	are vastly underparameterized relative to how many flops
2620880	2623240	or how many parameters you have in the human brain.
2623240	2625800	And so yeah, they're not going to be coming up
2625800	2628800	with new theorems like the smartest humans can.
2628800	2631120	But most humans can't do that either.
2631120	2632880	What most humans do, it sounds like it's
2632880	2635040	similar to what you were calling memorization, which
2635040	2640120	is memorizing skills or memorizing techniques
2640120	2641080	that you've learned.
2641080	2643560	And so it sounds like it's compatible.
2643680	2644720	Tell me if this is wrong.
2644720	2647600	Is it compatible in your world if all the remote workers
2647600	2649960	are gone, but they're doing skills
2649960	2652120	which we can potentially make synthetic data of?
2652120	2655440	So we record everybody's screen and every single remote worker
2655440	2656160	screen.
2656160	2658680	We sort of understand the skills they're performing there.
2658680	2660680	And now we've trained a model that can do all this.
2660680	2662360	All the remote workers are unemployed.
2662360	2663760	We're generating trillions of dollars
2663760	2666600	to economic activity for AI remote workers.
2666600	2668920	In that world, are we still in the memorization regime?
2668920	2670320	So sure.
2670360	2673840	With memorization, you can automate almost anything
2673840	2675880	as long as it's a static distribution,
2675880	2678000	as long as you don't have to deal with change.
2678000	2681000	Are most jobs part of such a static distribution?
2681000	2684400	Potentially, there are lots of things that you can automate.
2684400	2686880	And LLMs are an excellent tool for automation.
2686880	2688240	And I think that's true.
2688240	2690520	But you have to understand that automation is not
2690520	2691440	the same as intelligence.
2691440	2693800	I'm not saying that LLMs are useless.
2693800	2697000	I've been a huge proponent of deep learning for many years.
2697000	2698920	And for many years, I've been saying two things.
2698920	2701680	I've been saying that if you keep scaling up deep learning,
2701680	2703200	it will keep paying off.
2703200	2704720	And at the same time, I've been saying,
2704720	2706200	if you keep scaling up deep learning,
2706200	2708640	this will not lead to a GI.
2708640	2710680	So we can automate more and more things.
2710680	2712520	And yes, this is economically valuable.
2712520	2714480	And yes, potentially, there are many jobs.
2714480	2715840	You could automate a way like this.
2715840	2717880	And that would be economically valuable.
2717880	2720080	But you're still not going to have intelligence.
2720080	2722400	So you can ask, OK, so what does it
2722400	2724680	matter if we can generate all this economic value?
2724680	2726280	Maybe we don't need intelligence after all.
2726280	2728440	Well, you need intelligence the moment
2728480	2732120	you have to deal with change, with novelty, with uncertainty.
2732120	2734000	As long as you are in a space that
2734000	2737240	can be exactly described in advance,
2737240	2741600	you can just automate your pure memorization.
2741600	2744120	In fact, you can always solve any problem.
2744120	2748760	You can always display arbitrary levels of skills
2748760	2754640	on any task without leveraging any intelligence whatsoever,
2754640	2758840	as long as it is possible to describe the problem
2758840	2761320	and its solution very, very precisely.
2761320	2763200	But when they do deal with novelty,
2763200	2765200	then you just call it interpolation, right?
2765200	2768240	And so interpolation is not enough
2768240	2769920	to deal with all kinds of novelty
2769920	2773360	if it were, then LLMs would be a GI.
2773360	2774360	Well, I agree they're not a GI.
2774360	2776520	I'm just trying to figure out how do we figure out
2776520	2777320	we're on the path to a GI.
2777320	2780680	And I think a sort of crux here is maybe
2780680	2783840	that it seems to me that these things are on a spectrum
2783880	2786640	and we're clearly covering the earliest part of the spectrum
2786640	2787480	with LLMs.
2787480	2788320	I think so.
2788320	2789440	And oh, OK, interesting.
2789440	2791520	But here's another sort of thing
2791520	2794240	that I think is evidence for this, grokking, right?
2794240	2796760	So clearly, even within deep learning,
2796760	2799560	there's a difference between the memorization regime
2799560	2802640	and the generalization regime, where at first they'll just
2802640	2806800	memorize the data set of if you're doing modular addition,
2806800	2807920	how to add digits.
2807920	2810120	And then at some point, if you keep training on that,
2810120	2811280	they'll learn the skill.
2811280	2813360	So the fact that there is that distinction
2813360	2816400	suggests that the generalized circuit, the deep learning
2816400	2819560	can learn, there is a regime in enters where it generalizes.
2819560	2821120	If you have an over-parameterized model,
2821120	2822960	which you don't have in comparison to all the tasks
2822960	2824720	we want these models to do right now.
2824720	2826320	Grokking is a very, very old phenomenon.
2826320	2829160	We've been observing it for decades.
2829160	2833480	It's basically an instance of the minimum description length
2833480	2836680	principle, where, sure, given a problem,
2836680	2842760	you can just memorize a point-wise input-to-output mapping,
2842800	2844160	which is completely overfit.
2844160	2846000	So it does not generalize at all,
2846000	2849560	but it solves the problem on the train data.
2849560	2853320	And from there, you can actually keep proving it,
2853320	2856240	keep making your mapping simpler and simpler and more
2856240	2857320	compressed.
2857320	2860520	And at some point, it will start generalizing.
2860520	2864280	And so that's something called the minimum description
2864280	2865040	length principle.
2865040	2868520	It's this idea that the program that will generalize best
2868520	2871280	is the shortest, right?
2871280	2874520	And it doesn't mean that you're doing anything
2874520	2875840	other than memorization, but you're
2875840	2878480	doing memorization plus regularization.
2878480	2880680	Right, AKA generalization.
2880680	2883640	Yeah, and that is absolutely, at least to generalization.
2883640	2885560	Right, and then so you do that within one skill,
2885560	2887720	but then the pattern you see here of meta-learning
2887720	2890760	is that it's more efficient to store a program that can perform
2890760	2893240	many skills rather than one skill, which is what we might
2893240	2894520	call fluid intelligence.
2894520	2896040	And so as you get bigger and bigger models,
2896040	2898720	you would expect it to go up this hierarchy of generalization
2898720	2900880	where it generalizes to a skill, then it generalizes
2901080	2902040	multiple skills.
2902040	2903400	That's correct, that's correct.
2903400	2907200	And you know, LLMs, they're not infinitely large.
2907200	2909560	They have only a fixed number of parameters.
2909560	2912440	And so they have to compress their knowledge
2912440	2913720	as much as possible.
2913720	2915560	And in practice, so LLMs are mostly
2915560	2920400	storing reusable bits of programs, like vector programs.
2920400	2922800	And because they have this need for compression,
2922800	2924960	it means that every time they're learning a new program,
2924960	2927120	they're going to try to express it
2927120	2930160	in terms of existing bits and pieces of programs
2930160	2932440	that they've already learned before, right?
2932440	2934560	Isn't this the generalization?
2934560	2935760	Absolutely.
2935760	2937200	Oh, wait, so.
2937200	2939360	This is why, you know, clearly LLMs
2939360	2941400	have some degree of generalization.
2941400	2943880	And this is precisely why, it's because they have to compress.
2943880	2945680	And why is that intrinsically limited?
2945680	2947760	Why can't you just go, at some point,
2947760	2949600	it has to learn a higher level of generalization,
2949600	2951360	a higher level, and then the highest level
2951360	2952440	is the fluid intelligence.
2952440	2955080	It's intrinsically limited because the substrate
2955080	2958360	of your model is a big parametric curve.
2958360	2961960	And all you can do with this is local generalization.
2961960	2965480	If you want to go beyond this towards broader
2965480	2967520	or even extreme generalization, you
2967520	2969840	have to move to a different type of model.
2969840	2974000	And my paradigm of choice is discrete program search,
2974000	2975040	program synthesis.
2975040	2977280	So and if you want to understand that,
2977280	2981520	you can sort of like compare and contrast it with deep learning.
2981520	2985400	So in deep learning, your model is a parametric curve,
2985400	2987080	a differentiable parametric curve.
2987080	2989640	In program synthesis, your model
2989640	2992560	is a discrete graph of operators.
2992560	2995080	So you've got like a set of logical operators,
2995080	2997400	like a domain-specific language.
2997400	2999800	You're picking instances of it.
2999800	3001960	You're structuring that into a graph.
3001960	3003240	That's a program.
3003240	3005480	And that's actually very similar to like a program
3005480	3009400	you might write in Python or C++ and so on.
3009400	3011880	And in deep learning, your learning engine,
3011880	3013600	because we are doing much learning here,
3013600	3016800	like we're trying to automatically learn these models.
3016800	3021320	In deep learning, your learning engine is quite in the sense.
3021320	3024440	And quite in the sense is very compute efficient,
3024440	3027080	because you have this very strong, informative feedback
3027080	3029760	signal about where the solution is.
3029760	3031760	So you can get to the solution very quickly.
3031760	3035040	But it is very data inefficient, meaning
3035040	3036840	that in order to make it work, you
3036840	3039640	need a dense sampling of the operating space.
3039640	3041800	You need a dense sampling of the data distribution.
3041800	3044400	And then you're limited to only generalizing
3044400	3046080	within that data distribution.
3046080	3048160	And the reason why you have this limitation
3048160	3050000	is because your model is a curve.
3050000	3053680	And meanwhile, if you look at discrete program search,
3053680	3056840	the learning engine is combinatorial search.
3056840	3058920	You're just trying a bunch of programs
3058920	3061800	until you find one that actually miss your spec.
3061800	3064240	This process is extremely data efficient.
3064240	3066120	You can learn a generalizable program
3066120	3068480	from just one example, two examples, which
3068480	3070720	is why it works so well on Arc, by the way.
3070720	3074400	But the big limitation is that it's extremely compute
3074400	3077320	inefficient, because you're running into combinatorial
3077320	3078800	explosion, of course.
3078800	3082320	And so you can sort of see here how
3082320	3084880	the planning and discrete program search,
3084880	3089680	they have very complementary strengths and limitations
3089680	3090240	as well.
3090240	3093680	Every limitation of deep learning has a strength,
3093680	3097440	a corresponding strength in program synthesis and inversely.
3097440	3100640	And I think the path forward is going to be to merge the two,
3100640	3102040	to basically start doing.
3102080	3104240	So another way you can think about it
3104240	3108760	is, so these parametric curves, train with ground descent,
3108760	3111080	there are great fits for everything
3111080	3115600	that's system one type thinking, like pattern cognition,
3115600	3118520	intuition, memorization, and so on.
3118520	3122320	And discrete program search is a great fit
3122320	3126000	for type two thinking, system two thinking.
3126000	3128960	For instance, planning, reasoning,
3128960	3131360	quickly figuring out a generalizable model,
3131360	3134000	that matches just one or two examples,
3134000	3136000	like for an archbishop, for instance.
3136000	3140640	And I think humans are never doing pure system one
3140640	3141600	or pure system two.
3141600	3144600	They're always mixing and matching both.
3144600	3147040	And right now, we have all the tools for system one.
3147040	3149320	We have almost nothing for system two.
3149320	3152080	The way forward is to create a hybrid system.
3152080	3154160	And I think the form it's going to take
3154160	3157240	is it's going to be mostly system two.
3157240	3160560	So the outer structure is going to be a discrete program
3160560	3162040	search system.
3162040	3164680	But you're going to fix the fundamental limitation
3164680	3166840	of discrete program search, which is combinator explosion.
3166840	3169440	You're going to fix it with deep learning.
3169440	3172400	You're going to leverage deep learning to guide,
3172400	3175480	to provide intuition in program space,
3175480	3177640	to guide the program search.
3177640	3180960	And I think that's very similar to what you see,
3180960	3183800	for instance, when you're playing chess
3183800	3186480	or when you're trying to prove a theorem,
3186520	3191400	is that it's mostly a reasoning thing,
3191400	3193600	but you start out with some intuition
3193600	3195440	about the shape of the solution.
3195440	3198040	And that's very much something you can get
3198040	3199640	via a deep learning model.
3199640	3203360	Deep learning models, they're very much like intuition machines.
3203360	3205360	They're pattern matching machines.
3205360	3210160	So you start from this shape of the solution,
3210160	3213760	and then you're going to do actual explicit discrete
3213760	3215160	program search.
3215160	3218120	But you're not going to do it via brute force.
3218120	3222560	You're not going to try things kind of like randomly.
3222560	3225920	You're actually going to ask another deep learning model
3225920	3226960	for suggestions.
3226960	3229840	Like, here's the best likely next step.
3229840	3232040	Here's where in the graph you should be going.
3232040	3234560	And you can also use yet another deep learning model
3234560	3237720	for feedback about, well, here's what I had so far.
3237720	3238760	Is it looking good?
3238760	3241240	Should I just backtrack and try something new?
3241240	3246040	So I think discrete program search is going to be the key,
3246040	3248200	but you want to make it dramatically better,
3248200	3249840	all those of magnitude more efficient,
3249840	3251120	by leveraging deep learning.
3251120	3253520	And by the way, another thing that you can use deep learning
3253520	3256640	is, of course, things like common sense knowledge,
3256640	3258920	and knowledge in general.
3258920	3260560	And I think you're going to end up
3260560	3262560	with this sort of system where you
3262560	3267360	have this on-the-fly synthesis engine that
3267360	3269400	can adapt to new situations.
3269440	3271160	But the way it adapts is that it's
3271160	3275960	going to fetch from a bank of patterns,
3275960	3279160	modules that could be themselves,
3279160	3282240	curves that could be differentiable modules,
3282240	3284560	and some others that could be algorithmic in nature.
3284560	3288760	It's going to assemble them via this process that's
3288760	3290360	intuition-guided.
3290360	3292640	And it's going to give you, for every new situation you
3292640	3294240	might be faced with, it's going to give you
3294240	3297400	with a generalizable model that was synthesized
3297400	3300600	using very, very little data.
3300600	3302520	Something like this would sort of arc.
3302520	3305640	That's actually a really interesting prompt,
3305640	3308720	because I think an interesting crux here
3308720	3311440	is when I talk to my friends who are extremely
3311440	3317480	optimistic about LLMs and expect AGI within the next couple
3317480	3320520	of years, they also, in some sense,
3320520	3323760	agree that scaling is not all you need,
3323760	3326600	but that the rest of the progress is undergirded
3326640	3328640	and enabled by scaling.
3328640	3331520	But still, you need to add the system
3331520	3334920	to the test time compute atop these models.
3334920	3336880	And their perspective is that it's relatively
3336880	3338960	straightforward to do that, because you
3338960	3341600	have this library of representations
3341600	3343560	that you built up from free training,
3343560	3346800	but it's almost talking like, it's just
3346800	3348640	like skimming through textbooks.
3348640	3352120	You need some more deliberate way in which it engages
3352120	3353480	with the material it learns.
3353480	3356520	In-context learning is extremely sample-efficient.
3356520	3359000	But to actually distill that into the weights,
3359000	3361480	you need the model to talk through the things that sees
3361480	3363000	and then add it back to the weights.
3363000	3365640	As far as the system 2 goes, they talk about adding some kind
3365640	3368280	of RL setup so that it is encouraged
3368280	3372640	to proceed on the reasoning traces that end up being correct.
3372640	3374720	And they think this is relatively straightforward stuff
3374720	3376560	that will be added within the next couple of years.
3376560	3377840	That's an empirical question.
3377840	3378880	So I think we'll see.
3378880	3380440	Your intuition, I assume, is not that.
3380440	3381120	I'm curious.
3381120	3384840	My intuition is, in fact, this whole system
3384840	3387160	2 architecture is the hard part.
3387160	3389040	It's the very hard and non-obvious part.
3389040	3392800	Scaling up the interpolative memory is the easy part.
3392800	3397080	All you need is, like, it's literally just a big curve.
3397080	3398120	All you need is more data.
3398120	3399560	It's representation of a data set,
3399560	3401840	interpolative representation of data set.
3401840	3402840	That's the easy part.
3402840	3405960	The hard part is the architecture of intelligence.
3405960	3408600	Memory and intelligence are separate components.
3408600	3409480	We have the memory.
3409480	3411040	We don't have the intelligence yet.
3411040	3413400	And I agree with you that, well, having the memory
3413400	3414920	is actually very useful.
3414920	3417080	And if you just had the intelligence,
3417080	3419080	but it was not hooked up to an extensive memory,
3419080	3421320	it would not be that useful, because it would not
3421320	3424240	have enough material to work from.
3424240	3424960	Yeah.
3424960	3427720	The alternative hypothesis here that former guest Trenton
3427720	3431360	Brickin advanced is that intelligence
3431360	3434840	is just hierarchically associated memory
3434840	3438000	where higher-level patterns, when Sherlock Holmes goes
3438000	3440600	into a crime scene, and he's extremely sample-efficient,
3440600	3442360	he can just look at a few clues and figure out
3442400	3443920	who was a murderer, and the way he's
3443920	3446800	able to do that is he has learned higher-level
3446800	3448080	sort of associations.
3448080	3450280	It's memory in some fundamental sense.
3450280	3453960	But so here's one way to ask the question.
3453960	3457400	In the brain, supposedly we do program synthesis,
3457400	3460400	but it is just synapses connected to one another,
3460400	3463080	each other, and so physically it's
3463080	3465560	got to be that you just query the right circuit, right?
3465560	3466720	You are, yeah, yeah, yeah.
3466720	3468320	It's a matter of degree.
3468320	3471800	But if you can learn it, if training in the environment
3472360	3473960	human ancestors are trained in means
3473960	3475680	you learn those circuits, training
3475680	3477520	on the same kinds of outputs that humans produce,
3477520	3480080	which to replicate require these kinds of circuits,
3480080	3483480	wouldn't that train the same kind of whatever humans have?
3483480	3485040	You know, it's a matter of degree.
3487720	3489560	If you have a system that has a memory
3489560	3493680	and is only capable of doing local generalization from that,
3493680	3496760	it's not going to be very adaptable.
3496760	3499160	To be really general, you need the memory
3499160	3503200	plus the ability to search to quite some depth,
3503200	3506880	to achieve broader even extramuralization.
3506880	3511600	You know, like one of my favorite psychologists,
3511600	3515320	so Jean Piaget was the founder of the Elemental Psychology.
3515320	3517720	He had a very good quote about intelligence.
3517720	3520960	He said, intelligence is what you use when you don't know what
3520960	3522000	to do.
3522000	3526480	And it's like, as a human living your life,
3526480	3528760	in most situations you already know what to do,
3528760	3530680	because you've been in this situation before.
3530680	3533440	You already have the answer, right?
3533440	3535560	And you're only going to need to use intelligence
3535560	3539280	when you're faced with novelty, with something you didn't expect,
3539280	3541240	with something that you weren't prepared for,
3541240	3544960	either by your own experience, your own life experience,
3544960	3547480	or by your evolutionary history.
3547480	3551560	Like, this day that you're living right now is different
3551560	3554840	in some important ways from every day you've lived before,
3554840	3557440	but it's also different from any day ever lived
3557440	3558880	by any of your ancestors.
3558880	3562600	And still, you're capable of being functional, right?
3562600	3563480	How is it possible?
3563480	3565760	I'm not denying that generalization is extremely important,
3565760	3568960	and is the basis for intelligence.
3568960	3570600	That's not the correct, the correct is like,
3570600	3572120	how much of that is happening in the models?
3572120	3575000	But, okay, let me ask a separate question.
3575000	3578520	We might keep going in the circle here.
3578520	3581000	The differences in intelligence between humans,
3581000	3583480	maybe the intelligence tests because of reasons
3583480	3584600	you mentioned are not measuring it well,
3584600	3586080	but clearly there's differences in intelligence
3586080	3587080	between different humans.
3587680	3589640	What is your explanation for what's going on there?
3589640	3592160	Because I think that's sort of compatible with my story
3592160	3593720	that there's a spectrum of generality
3593720	3596520	and that these models are climbing up to a human level,
3596520	3598280	and even some humans haven't even climbed up
3598280	3602400	to the Einstein level or the Francois level, but.
3602400	3604440	That's a great question, you know.
3604440	3607960	There is extensive evidence that intelligence,
3607960	3611000	difference in intelligence are mostly genetic in nature,
3611000	3611840	right?
3611840	3614400	Meaning that if you take someone who is not very intelligent,
3614400	3617880	there is no amount of training, of like training data,
3617880	3619720	you can expose that person to that would
3621120	3622880	make them become Einstein.
3622880	3625360	And this kind of points to the fact
3625360	3628560	that you really need a better architecture,
3628560	3630240	you need a better algorithm,
3630240	3634040	and more training data is not in fact all you need.
3634040	3635920	I think I agree with that.
3635920	3639000	I think what, maybe the way I might phrase it is that
3639000	3642240	the people who are smarter have in ML language
3642280	3645680	better initializations, the neural wiring,
3645680	3648040	if you just look at, it's more efficient,
3648040	3651400	they have maybe greater density of firing.
3651400	3653200	And so as some part of the story is scaling,
3653200	3655320	there is some correlation between brain size
3655320	3656600	and intelligence.
3656600	3660160	And we also see within the context of quote unquote,
3660160	3661360	scaling that people talk about
3661360	3664400	within the context of LLMs, architectural improvements,
3664400	3667920	where a model like Gemini 1.5 flash
3667920	3670720	is performs as well as GPT-4 did
3670720	3672560	when GPT-4 was released a year ago,
3672560	3675320	but is 57 times cheaper on output.
3675320	3677480	So the part of the scaling story
3677480	3679240	is that the architectural improvements are,
3679240	3681640	we're in like extremely low hanging fruit territory
3681640	3683160	when it comes to those.
3683160	3687560	Okay, we're back now with the co-founder of Zapier,
3687560	3691040	Mike Canouf, we had to restart a few times there.
3691040	3692880	And you're funding this prize
3692880	3695800	and you're running this prize with Francois.
3695800	3698760	And so tell me about how this came together,
3699720	3701760	what more prompted you guys to launch this prize?
3701760	3704240	Yeah, I guess I've been sort of like AI curious
3704240	3706680	for 13 years, I co-founded Zapier,
3706680	3708520	been running it for the last 13 years.
3708520	3711240	And I think I first got introduced to your work
3711240	3714560	and during COVID, I kind of went down the rabbit hole,
3714560	3716320	we had a lot of free time.
3716320	3718960	And it was right after you published your
3718960	3719960	on measure of intelligence paper,
3719960	3721840	you sort of introduced the concept of AGI,
3721840	3723400	this like efficiency of skill acquisition
3723400	3726280	is like the right definition and the arc puzzles.
3726320	3729040	But I don't think the first Kaggle contest was done yet.
3729040	3730480	I think it was still running.
3730480	3732600	And so I kind of, it was interesting,
3732600	3734880	but I just parked the idea.
3734880	3736920	And my bigger fish to fry at Zapier
3736920	3738480	were in this middle of this big turnaround
3738480	3741240	of trying to get to our second product.
3741240	3744040	And then it was January, 2022,
3744040	3745680	when the chain of thought paper came out
3745680	3748560	that really like awoken me to sort of the progress.
3748560	3750560	I gave a whole presentation to the Zapier
3750560	3751880	on like the GPT-3 paper events.
3751880	3753720	I'd sort of felt like I had priced in everything
3753720	3755720	that Elms could do and that paper was
3755760	3757360	really shocking to me in terms of
3757360	3759240	these latent capabilities that Elms have
3759240	3761520	that I didn't expect that they had.
3761520	3765600	And so I actually gave up my exact team role at Zapier.
3765600	3766720	I was running half the company at that point
3766720	3768800	and I went back to be an individual contributor
3768800	3770880	and just to go do AI research
3770880	3772480	alongside Brian, my co-founder.
3773920	3776560	And all of that led me to back towards arc.
3776560	3777800	I was looking into it again
3777800	3782120	and I had sort of expected to see this saturation effect
3782120	3785680	that MMLU has, that GMSK 8K has.
3785680	3787840	And when I looked at the scores and the progress
3787840	3791160	since the last four years, I was really again, shocked to see
3791160	3793440	actually we've made very little objective progress
3793440	3796640	towards it and it felt very,
3796640	3798280	it felt like a really, really important Eval.
3798280	3799640	And as I sort of spent the last year
3799640	3801120	asking people, quizzing people about it
3801120	3802880	and sort of my network and community,
3803760	3806040	very few people even knew it existed.
3806040	3809000	And that felt like, okay, if it's right
3809000	3811440	that this is a really, really like globally
3811440	3814840	singularly unique EGI Eval.
3814840	3816440	And it's different from every other Eval that exists
3816440	3820200	that are more narrowly measures AI skill.
3820200	3822120	Like more people should know about this thing.
3822120	3824400	I had my own ideas on how to beat the arc as well.
3824400	3826320	So like I was working on nights and weekends on that
3826320	3829600	and I flew up to meet Francois earlier this year
3829600	3831480	to sort of quiz him, show him my ideas.
3831480	3834160	And ultimately I was like, well,
3834160	3836480	why don't you think more people know about arc?
3836480	3837440	I think you should actually answer that.
3837440	3839280	I think it's a really interesting question.
3839280	3841320	Like why don't you think more people know about arc?
3841320	3845000	Sure, you know, I think benchmarks that gain traction
3845000	3846520	in the research community are benchmarks
3846520	3848680	that are already fairly tractable
3848680	3851600	because the dynamic that you see is that some research group
3851600	3853720	is gonna make some initial breakthrough
3853720	3856760	and then this is gonna catch the attention of everyone else.
3856760	3858480	And so you're gonna get follow-up papers
3858480	3862200	with people trying to beat the first team and so on.
3862200	3864520	And for arc, this has not really happened
3864520	3866360	because arc is actually very hard
3866360	3867800	for existing AI techniques.
3867800	3870920	Kind of arc requires you to try new ideas.
3871000	3873280	And that's very much the point, by the way.
3873280	3875280	Like the point is not that, yeah,
3875280	3877640	you should just be able to apply existing technology
3877640	3878480	and solve arc.
3878480	3882920	The point is that existing technology has reached a plateau
3882920	3884800	and if you want to go beyond that,
3884800	3887760	if you want to start being able to tackle problems
3887760	3890800	that you haven't memorized, that you haven't seen before,
3890800	3892440	you need to try new ideas.
3892440	3897440	And arc is not just meant to be this sort of like measure
3898440	3901000	of how close we are to a GI.
3901000	3904360	It's also meant to be a source of inspiration.
3904360	3906680	Like I want researchers to look at these puzzles
3906680	3909080	and be like, hey, it's really strange
3909080	3911560	that these puzzles are so simple
3911560	3915320	and most humans can just do them very quickly.
3915320	3918400	Why is it so hard for existing AI systems?
3918400	3920800	Why is it so hard for LLMs and so on?
3920800	3923480	And it's true for LLMs, but arc was actually released
3923480	3925480	before LLMs were really a thing.
3925520	3928880	And the only thing that made it special at the time
3928880	3932240	was that it was designed to be a resistance to memorization.
3932240	3934800	And the fact that it has survived LLMs
3934800	3937480	and Genia in general so well,
3937480	3938680	kind of shows that yes,
3938680	3940800	it is actually resistant to memorization.
3940800	3942280	This is what nerds night me
3942280	3944200	because I went and took a bunch of the puzzles myself.
3944200	3945720	I've showed it to all my friends and family too
3945720	3948560	and they're all like, oh yeah, this is like super easy.
3949480	3951240	Are you sure AI can't solve this?
3951240	3954160	Like that's the reaction in the same one for me as well.
3954160	3955440	And the more you dig in, you're like, okay,
3955440	3957320	yep, there's not just empirical evidence
3957320	3958720	over the last four years that it's unbeaten,
3958720	3961800	but there's theoretical like concepts behind why.
3962640	3964200	And I completely agree at this point
3964200	3966240	that like new ideas basically are needed to be dark.
3966240	3968000	And there's a lot of current trends in the world
3968000	3969240	that are actually, I think,
3969240	3972280	working against that happening basically.
3972280	3973320	I think we're actually less likely
3973320	3974880	to generate new ideas right now.
3975840	3977680	You know, I think one of the kind of trends
3977680	3979480	is the closing up frontier research, right?
3979480	3982720	The GP4 paper from Open AI had no technical details shared.
3982720	3984480	The Gemini paper had no technical details shared
3984520	3987160	and like the longer context part of that work.
3987160	3990200	And yet that open innovation and open progress and sharing
3990200	3992120	is what got us to transformers in the first place.
3992120	3995120	That's what got us to LMS in the first place.
3995120	3997920	So it's kind of disappointing a little bit actually
3997920	4000000	that like so much frontier work has gone closed.
4000000	4002560	It's really making a bet that like these individual labs
4002560	4003760	are going to have the breakthrough
4003760	4006240	and not the ecosystem is going to have the breakthrough.
4006240	4008360	And I think sort of the internet open source has shown
4008360	4010360	that that's like the most powerful innovation ecosystem
4010360	4012480	that's ever existed probably in the entire world.
4012480	4014080	I think that's actually really sad
4014080	4017720	that frontier research is no longer being published.
4017720	4019960	If you look back, you know, four years ago,
4021280	4023080	well, everything was just openly shared
4023080	4025880	like all the state of the art results were published
4025880	4027160	and this is no longer the case.
4027160	4028400	And it's very much, you know,
4028400	4031400	Open AI single-handedly changed the game.
4031400	4036400	And I think Open AI basically set back progress towards HGI
4037560	4040160	by quite a few years, probably like five to 10 years
4040160	4041000	for two reasons.
4041000	4045640	And one is that, well, they cause this complete closing down
4045640	4048200	of research, frontier research publishing,
4048200	4053200	but also they trigger this initial burst of hype
4054480	4055520	around LLMS.
4055520	4059640	And now LLMS have sucked the oxygen out of the room
4059640	4063320	like everything, everyone is just doing LLMS.
4063320	4067080	And I see LLMS as a more often off-ramp
4067080	4069840	on the path to HGI actually.
4069880	4071960	And all these new resources,
4071960	4074160	they're actually going to LLMS instead
4074160	4076920	of everything else they could be going to.
4076920	4079720	And, you know, if you look further into the past
4079720	4082760	to like 2015, 2016,
4082760	4085520	there were like a thousand times fewer people
4085520	4087280	doing AI back then.
4087280	4090740	And yet I feel like the rate of progress was higher
4090740	4094480	because people were exploring more directions.
4094480	4096400	The world felt more open-ended.
4096400	4098400	Like you could just go and try,
4098400	4100400	like have a cool idea of a launch
4100400	4102360	and try it and get some interesting results.
4102360	4104440	So there was this energy.
4104440	4107440	And now everyone is very much doing some variation
4107440	4108800	of the same thing.
4108800	4112720	And the big labs also tried their hand on arc,
4112720	4114560	but because they got bad results,
4114560	4115840	they didn't publish anything.
4115840	4119520	Like, you know, people only publish positive results.
4119520	4123840	I wonder how much effort people have put into
4123840	4126400	trying to prompt or scaffold,
4126400	4128920	do some sort of maybe Devon type approach
4128920	4132280	into getting the frontier models
4132280	4134280	and the frontier models of today, not just a year ago,
4134280	4135440	because a lot of post-training
4135440	4137120	has gone into making them better.
4137120	4140000	So Claude Friropas or GPT-40
4140000	4142880	into getting good solutions on arc.
4144760	4146760	I hope that one of the things this episode does
4146760	4149200	is get people to try out this open competition
4149200	4152920	where they have to put in an open source model to compete.
4152920	4154880	But also to like figure out if they're,
4154880	4157880	maybe the like capability is latent in Claude Opus
4157880	4160240	and just see if you can show that.
4160240	4161920	I think that would be super interesting.
4161920	4163240	So let's talk about the prize.
4163240	4165760	How much do you win if you solve it?
4165760	4167920	You know, get whatever percent on arc.
4167920	4169680	How much do you get if you get the best of vision,
4169680	4170600	but don't crack it?
4170600	4171600	So we got a million dollar,
4171600	4172600	actually a little over a million dollars
4172600	4173640	is the price pool.
4173640	4175880	We're running the contest on an annual basis.
4175880	4177520	We're gonna, we're starting it today
4177520	4179800	through the middle of November.
4179800	4181840	And the goal is to get 85%.
4181840	4183320	That's the lower bound and human average
4183320	4184920	that you guys talked about earlier.
4184920	4188080	And there's a $500,000 prize for the first team
4188080	4190560	that can get to the 85% benchmark.
4190560	4191720	We're also gonna run,
4191720	4194000	we don't expect that to happen this year actually.
4194000	4197040	One of the early statisticians that's up here
4197040	4199360	giving this line that has always stuck with me
4199360	4201280	that the longer it takes, the longer it takes.
4201280	4204600	So my prior is that like arc is gonna take years to solve.
4205360	4206240	And so we're gonna keep to,
4206240	4208840	we're also gonna break down and do a progress price this year.
4208840	4210960	So there's a $100,000 progress price,
4210960	4213760	which we will pay out to the top scores.
4213760	4218640	So $50,000 is gonna go to the top objective scores this year
4218640	4219600	on the Kaggle leaderboard,
4219600	4221320	which we're hosting it on Kaggle.
4221320	4223160	And then we're gonna have a $50,000 pot set
4223160	4226200	for a paper award for the best paper
4226200	4228720	that explains conceptually the scores
4228720	4230160	that they were able to achieve.
4230160	4231600	And one of the I think interesting things
4231600	4233680	we're also gonna be doing is,
4233680	4235880	we're gonna be requiring that in order to win the prize money
4235880	4238040	that you put the solution or your paper
4238040	4239360	out into public domain.
4240320	4241960	The reason for this is,
4241960	4243360	typically with contests,
4243360	4245320	you see a lot of like closed up sharing.
4245320	4246600	People are kind of private secret.
4246600	4247720	They wanna hold their alpha to themselves
4247720	4249120	during the contest period.
4249120	4252080	And because we expect it's gonna be multiple years,
4252080	4253160	we wanna enter a game here.
4253160	4256520	So the plan is at the end of November,
4256520	4258520	we will award the $100,000 prize money
4258520	4259920	to the top progress prize
4259920	4263440	and then use the downtime between December, January, February
4263440	4266840	to share out all the knowledge from the top scores
4266840	4268200	and the approaches folks were taking
4268200	4270080	in order to re-baseline the community
4270080	4271720	up to whatever the state of the art is
4271720	4273360	and then run the contest again next year.
4273360	4276400	And keep doing that on a yearly basis until we get 85%.
4276400	4277760	I'll give some people some context
4277760	4280440	on why I think this prize is very interesting.
4280440	4282720	I was having conversations with my friends
4282720	4286360	who are very much believers in models as they exist today.
4286360	4288200	And first of all, it was intriguing to me
4288200	4289960	that they didn't know about ARC.
4289960	4292240	These are experienced ML researchers.
4292240	4295560	And so you show them this happened a couple of nights ago.
4295560	4298240	We went to dinner and I showed them an example problem.
4298240	4299160	And they said, of course,
4299160	4301040	an LLM would be able to solve something like this.
4301040	4302280	And then we take a screenshot of it.
4302280	4304240	We just put it into our chat GPT app
4304240	4305520	and it doesn't get the pattern.
4305520	4308600	And so I think it's very interesting.
4308600	4309720	Like it is a notable fact.
4309720	4311600	I was sort of playing devil's advocate against you
4311600	4312440	on these kinds of questions.
4312440	4313920	But this is a very intriguing fact.
4313920	4316800	And I'm extreme, I think this prize is extremely interesting
4316800	4318240	because we're gonna learn,
4318240	4321240	we're gonna learn something fascinating one way or another.
4321240	4323920	So with regards to the 85%,
4323960	4324920	separate from this prize,
4324920	4327640	I'd be very curious if somebody could replicate that result
4327640	4331640	because obviously in psychology and other kinds of fields,
4331640	4335000	which this result seems to be analogous to
4335000	4338920	when you run test on some small sample of people,
4338920	4340200	often they're hard to replicate.
4340200	4342000	So I'd be very curious if you try to replicate this,
4342000	4345440	how, what does an average human perform on ARC?
4345440	4347360	Ask for the difficulty on how long it will take
4347360	4348920	to crack this benchmark.
4348920	4351160	It's very interesting because the other benchmarks
4351200	4354040	that are now fully saturated like MMLU math,
4354040	4356400	actually the people who made them,
4356400	4359680	Dan Hendricks and Colin Burns who did MMLU and math,
4359680	4361840	I think they were grad students or college students
4361840	4363160	when they made it.
4363160	4365400	And the goal when they made it just a couple of years ago
4365400	4367960	was that this will be a test of AGI.
4367960	4369240	And of course it got totally saturated.
4369240	4372480	And I know you all argue that these are test memorization,
4372480	4374120	but I think the pattern we've seen,
4374120	4377120	in fact, Epoch AI has a very interesting graph
4377120	4379440	that I'll sort of overlay for the YouTube version here
4379480	4382200	where you see this almost exponential
4382200	4386120	where it gets 5%, 10%, 30%, 40%
4386120	4387880	as you increase the compute across models
4387880	4389920	and then it just shoots up.
4389920	4392640	And in the GPT-4 technical report,
4392640	4394160	they had this interesting graph
4394160	4396240	of the human eval problem set,
4396240	4398400	which was 22 coding problems.
4398400	4402200	And they had to graph it on the mean log pass curve,
4402200	4404960	basically because early on in training
4404960	4408200	or even smaller models can have the right idea
4408200	4409760	of how to solve this problem,
4409760	4411720	but it takes a lot of reliability
4411720	4414000	to make sure they stay on track to solve the whole problem.
4414000	4416120	And so you really wanna up wait the signal
4416120	4418000	where they get it right at least some of the time,
4418000	4419720	maybe one in a hundred times or one in a thousand.
4419720	4421560	And then so they go from like one in a thousand,
4421560	4422480	one in a hundred, one in 10,
4422480	4424620	and then they just like totally saturated.
4424620	4426280	I guess the question I have,
4426280	4427160	this is all leading up to,
4427160	4429900	is why won't the same thing happen with ARC
4429900	4433480	where people had to try really hard, bigger models.
4434400	4436240	And now they figured out these techniques
4436280	4437120	that Jack Cole has figured out
4437120	4440120	with only a 240 million parameter language model
4440120	4442440	that can get 35%.
4442440	4443560	Shouldn't we see the same pattern we saw
4443560	4444480	across all these other benchmarks
4444480	4445880	where you just like sort of eke out.
4445880	4447560	And then once you get the general idea,
4447560	4449800	then you just go all the way to a hundred.
4449800	4450920	That's an empirical question.
4450920	4452840	So we'll see in practice what happens.
4453840	4456560	But what Jack Cole is doing is actually very unique.
4456560	4459680	It's not just pre-training an LLM and then prompting it,
4459680	4461960	he's actually trying to do active inference.
4461960	4463160	He's doing a test time, right?
4463160	4464000	He's doing like test time functioning.
4464000	4465680	Exactly, test time functioning.
4465680	4467680	And this is actually trying to lift
4467680	4469680	one of the key limitations of LLMs,
4469680	4471520	which is that at inference time,
4471520	4472680	they cannot learn anything new.
4472680	4475520	They cannot adapt on the flight what they're seeing.
4475520	4478720	And he's actually trying to learn.
4478720	4480800	So what he's doing is effectively
4480800	4482960	a form of program synthesis.
4484080	4486920	Because the LLM contains a lot of useful building blocks,
4486920	4488680	like programming building blocks,
4488680	4492080	and by finding it on the task at test time,
4492080	4494600	you are trying to assemble these building blocks
4494600	4497680	into the right pattern that matches the task.
4497680	4500560	This is exactly what program synthesis is about.
4500560	4503640	And the way we contrast this approach
4503640	4505920	with discrete program search is that
4505920	4507760	in discrete program search,
4507760	4510240	so you're trying to assemble a program
4510240	4512160	from a set of primitives.
4512160	4513520	You have very few primitives.
4513520	4515800	So people working on discrete program search on Arc,
4515800	4518800	for instance, they tend to work with DSLs that have like
4518800	4521920	100 to 200 primitive programs.
4521920	4523640	So very small DSL,
4523640	4526720	but then they're trying to combine these primitives
4526720	4529160	into very complex programs.
4529160	4532280	So there's very deep depths of search.
4532280	4534600	And on the other hand,
4534600	4537120	if you look at what Jack is doing with LLMs,
4537120	4542120	is that he's got this sort of like vector program database,
4543200	4547440	DSL of millions of building blocks in the LLM
4547440	4550240	that are mined by pre-training the LLM,
4550240	4552720	not just on a ton of programming problems,
4552720	4556400	but also on millions of generated Arc-like tasks.
4556400	4559680	So you have an extraordinarily large DSL.
4559680	4563000	And then the fun tuning is very, very shallow
4563000	4564880	recombination of these primitives.
4564880	4568560	So discrete program search, very deep recombination,
4568560	4572000	very small set of primitive programs.
4572000	4574160	And the LLM approach is the same,
4574160	4577260	but on the complete opposite end of that spectrum,
4577260	4579400	where you scale up the memorization
4579400	4583560	by a massive factor and you're doing very, very shallow search,
4583560	4585400	but they are the same thing,
4585400	4587400	just different ends of the spectrum.
4587400	4591160	And I think where you're gonna get the most value
4592200	4596200	for your compute cycles is gonna be somewhere in between.
4596200	4600680	You want to leverage memorization to build up a richer,
4600680	4603800	more useful bank of primitive programs.
4603800	4606080	And you don't want them to be hard-coded
4606080	4608400	like what we saw for the typical artist.
4608400	4611200	You want them to be learned from examples.
4611200	4615840	But then you also want to do some degree of deep search.
4615840	4618160	As long as you're only doing very shallow search,
4618160	4620120	you are limited to local generalization.
4620120	4621960	If you want to generalize further,
4621960	4626960	more broadly, this depth of search is gonna be critical.
4627240	4631840	I might argue that the reason that he had to rely so heavily
4631840	4636840	on the synthetic data was because he used a 240 million
4636840	4639600	parameter model because the Kaggle competition at the time
4639600	4642520	required him to use a P100 GPU,
4642520	4646400	which has like a 10th or something of the flops of an H100.
4646400	4648880	And so obviously he can't use,
4648880	4652400	if you believe that sort of scaling will solve
4652400	4653760	this kind of reasoning,
4653760	4656560	then there you can just rely on the generalization,
4656560	4658400	whereas if you're using a much smaller,
4658400	4659920	for context for the listeners, by the way,
4659920	4661520	the frontier models today are literally
4661520	4663080	a thousand X bigger than that.
4663080	4666280	And so for your competition,
4666280	4667960	from what I remember,
4667960	4670520	the submission you'll have to submit
4670520	4673360	can't make any API calls, can't go online,
4673360	4677640	and has to run on NVIDIA Tesla T4.
4677640	4678480	P100.
4678480	4679320	P100.
4679320	4680160	Oh, is it P100?
4680160	4681000	Yeah.
4681000	4682320	Okay, so again, it's like significantly less powerful.
4682320	4683760	There's a 12-hour runtime limit, basically.
4683760	4686280	There's a forcing function of efficiency in the eval.
4686280	4689600	But here's the thing, you only have 100 test tasks.
4689600	4692040	So the amount of computing available for each task
4692040	4693040	is actually quite a bit,
4693080	4694720	especially if you contrast that
4694720	4696640	with the simplicity of each task.
4696640	4699600	So it would be seven minutes per task, basically,
4699600	4702520	which for, people have tried to do these estimates
4702520	4704600	of how many flops does a human brain have.
4704600	4706080	And you can take them with a grain of salt,
4706080	4708240	but as a sort of anchor,
4708240	4711360	it's basically the amount of flops an H100 has.
4711360	4712960	And I guess maybe you would argue with that,
4712960	4715400	well, a human brain can solve this question
4715400	4716560	in faster than 7.2 minutes.
4716560	4718040	So even with a tenth of the compute,
4718040	4720560	you should be able to do it in seven minutes.
4720560	4723040	Obviously, we have less memory than, you know,
4723040	4725880	like petabytes of fast access memory in the brain.
4725880	4728840	And with these, you know, 29 or whatever gigabytes
4728840	4730400	in this H100.
4730400	4732480	Anyway, I guess the broader question I'm asking is,
4735360	4738560	I wish there was a way to also test this prize
4738560	4741120	with some sort of scaffolding on the biggest models
4741120	4744000	as a way to test whether scaling is the path
4744000	4747880	to get to solving ARC.
4747880	4748720	Absolutely.
4748720	4749920	So in the context of the computation,
4749920	4752320	we want to see how much progress we can do
4752320	4753800	with limited resources.
4753800	4756320	But you're entirely right that it's a super interesting
4756320	4757360	open question.
4757360	4760600	What could the biggest model out there actually do on ARC?
4760600	4764760	So we want to actually also make available a private
4764760	4769480	sort of like one-off track where you can submit to us a VM
4769480	4772000	and so you can put on it any model you want.
4772000	4774560	Like you can take one of the largest open source models
4774560	4777200	out there and find you need to do whatever you want
4777200	4779880	and just give us an image.
4779880	4782960	And then we run it on the H100 for like 24 hours
4782960	4784680	or something and you see what you get.
4784680	4787760	I think it's worth pointing out that there's two different
4787760	4788600	test sets.
4788600	4790760	There is a public test set that's in the public
4790760	4793720	GitHub repository that anyone can use to train, you know,
4793720	4796400	put it in an open API call, whatever you'd like to do.
4796400	4797720	And then there's the private test set,
4797720	4799320	which is the 100 that is actually measuring
4799320	4800720	the state of the art.
4800720	4803400	So I think it is pretty open and interesting to have folks
4803400	4805920	attempt to at least use the public test set and go try it.
4805920	4809160	Now, there is an asterisk on any score that's reported on
4809160	4811320	against the public test set because it is public.
4811320	4813320	It could have leaked into the training data.
4813320	4815240	And this is actually what people are already doing.
4815240	4818760	Like you can already try to prompt one of the best models
4818760	4822880	like the latest Jaminar, the latest GPT-4 with tasks
4822880	4824360	from the public evaluation set.
4824360	4827400	And you know, again, the primary set, these tasks
4827400	4830400	are available as JSON files on GitHub.
4830400	4832440	These models are also trained on GitHub.
4832440	4834800	So they're actually trained on these tasks.
4835720	4838960	And yeah, that kind of creates uncertainty about
4838960	4840960	if they can actually solve some of the tasks,
4840960	4843960	is that because they memorized the answer or not.
4843960	4847080	You know, maybe you would be better off trying to create
4847080	4853080	your own private, arc-like, very novel test set.
4853120	4854720	Don't make the task difficult.
4854720	4855760	Don't make them complex.
4855760	4857160	Make them very obvious for humans.
4857160	4860840	But make sure to make them original as much as possible.
4860840	4862480	Make them unique, different.
4862480	4866720	And see how much your GPT-4 and so on GPT-5 does on them.
4866720	4868720	Well, they're having tests on whether these models
4868720	4871040	are being overtrained on these benchmarks.
4871040	4874120	Scale recently did this where on the GSM-
4874120	4874960	That's really interesting.
4874960	4877560	AK, they basically replicated the benchmark
4877560	4878840	with different questions.
4878840	4880480	And so some of the models actually were extremely
4880480	4884000	overfit on the benchmark like Mistral and so forth.
4884000	4888600	And but the frontier models, Claude and GPT actually did
4888600	4890760	as well on their novel benchmark that they did
4890760	4892160	on the specific questions that were
4892160	4895160	in the existing public benchmark.
4895160	4897880	So I would be relatively optimistic about them
4897880	4900320	just sort of training on the JSON.
4900320	4904080	I was joking with Mike that you should allow API access
4904080	4909080	but sort of keep an even more private validation set
4909160	4911440	of these arc questions.
4911440	4913760	And so allow API access, people can sort of play
4913760	4916400	with GPT-4 scaffolding to enter into this contest.
4916400	4918960	And if it turns out maybe later on you run the validation
4918960	4921440	set on the API and if it performs worse
4921440	4923880	than the test set that you allowed the API access
4923880	4927160	to originally, that means that open AI is training
4927160	4929760	on your API calls and you like go public with this
4929760	4930760	and show them like, oh my God,
4930760	4933080	they've like leaked your data.
4933080	4935680	We do want to make, we want to evolve the arc data set.
4935680	4937560	Like that is a goal that we want to do.
4937560	4939520	I think Francois you mentioned, you know, it's not perfect.
4939520	4942080	Yeah, no, arc is not perfect for perfect benchmark.
4942080	4944080	I mean, I made it like four years ago
4944080	4946720	over four years ago, almost five now.
4946720	4948840	This was in a time before LMS.
4948840	4951800	And I think we learned a lot actually since
4951800	4954200	about what potential flaws there might be.
4954200	4957560	I think there is some redundancy in the set of tasks
4957560	4960200	which is of course against the goals of the benchmark.
4960200	4962680	Every task is supposed to be unique in practice.
4962680	4964000	That's not quite true.
4964000	4967080	I think there's also, every task is supposed
4967080	4969760	to be very novel, but in practice, they might not be.
4969760	4972440	They might be structurally similar to something
4972440	4974680	that you might find online somewhere.
4974680	4976480	So we want to keep iterating
4976480	4980240	and release an arc two version later this year.
4980240	4981720	And I think when we do that,
4981720	4986720	we're gonna want to make the old private test set available.
4986800	4988720	So maybe we won't be releasing it publicly,
4988720	4993400	but what we could do is just create a test server
4993400	4996520	where you can query, get a task, you submit a solution,
4996520	4998360	and of course you can use whatever frontier model
4998360	4999640	you want there.
4999640	5002720	So that way, because you actually have to query this API,
5002760	5006160	you're making sure that no one is gonna buy accident train
5006160	5007000	on this data.
5007000	5009800	It's unlike like the current public article
5009800	5011240	which is literally on GitHub.
5011240	5013160	So there's no question about whether the models
5013160	5014000	are actually trained on it.
5014000	5016440	Yes, they are because they're trained on GitHub.
5016440	5019520	So by sort of like gating access
5019520	5022520	to querying this API with a various issue.
5022520	5024120	And then we would see, you know,
5024120	5026920	for people who actually wanna try
5026920	5028120	whatever technique they have in mind
5028120	5030760	using whatever resources they want,
5030760	5032600	that would be a way for them to get an answer.
5032640	5034160	I wonder what might happen.
5034160	5035320	I'm not sure.
5035320	5038520	One answer is that they come up with a whole new algorithm
5038520	5042320	for AI with some explicit program synthesis
5042320	5043840	that now we're on a new track.
5043840	5046680	And another is they did something hacky
5046680	5050320	with the existing models in a way that actually is valid,
5050320	5052800	which reveals that movie intelligence is more
5052800	5055320	of getting things to the right part of the distribution,
5055320	5056640	but then it can reason.
5056640	5059760	And in that world, I guess that will be interesting.
5059760	5061440	And maybe that'll indicate that, you know,
5061480	5063240	you had to do something hacky with current models
5063240	5064080	as they get better,
5064080	5065840	you won't have to do something hacky.
5067120	5069200	I'm also gonna be very curious to see
5069200	5070720	how these multimodal models,
5070720	5073840	if they will perform natively much better at arc like tests.
5073840	5075360	If arc survives three months from here,
5075360	5077000	we'll blow up the price.
5077000	5079000	I think we're about to make a really important moment
5079000	5081640	of like contact with reality by blowing up the price,
5081640	5083360	putting a much big price pool against it.
5083360	5084400	We're gonna learn really quickly
5084400	5086600	if there's like low hanging fruit of ideas.
5086600	5087920	Again, I think new ideas are needed.
5087920	5089000	I think anyone listening this
5089000	5091160	might have the idea in their head.
5091160	5093520	And I'd encourage everyone to like give it a try.
5093520	5095520	And I think as time goes on,
5095520	5096920	that adds strength to the argument
5096920	5099280	that like we sort of stall that in progress
5099280	5100920	and that new ideas are necessary to be dark.
5100920	5103600	Yeah, that's the point of having a money price
5103600	5106120	is that you attract more people,
5106120	5107720	you get them to try to solve it.
5107720	5109960	And if there's a easy way to hack the benchmark
5109960	5111480	that reveals that the benchmark is valid,
5111480	5112640	then you're gonna know about it.
5112640	5113520	In fact, that was the point
5113520	5118200	of the original Carol competition back in 2020 for arc.
5119040	5120280	I was running this competition
5120320	5122440	because I had released this dataset
5122440	5126640	and I wanted to know if it was hackable, if you could cheat.
5126640	5128800	So there was a small money price at the time,
5128800	5130520	there was like 20K.
5130520	5132360	And this was right around the same time
5132360	5134720	as GPT-3 was released.
5134720	5137560	So people of course tried GPT-3 on the public data,
5137560	5138480	it scored zero.
5139560	5142560	But I think what the first context
5142560	5145240	the first context taught us is that
5145240	5148160	there is no obvious shortcuts, right?
5149160	5150680	And well, now there's more money,
5150680	5153960	there's gonna be more people looking into it.
5153960	5156120	Well, we're gonna find out,
5156120	5158720	we're gonna see if the benchmark is gonna survive.
5158720	5162400	And you know, if we end up with a solution
5162400	5165840	that is not like trying to brute force
5165840	5167400	the space of possible arc tasks
5167400	5169920	that's just trained on core knowledge,
5169920	5173800	I don't think it's necessarily gonna be in and by itself, AGI,
5173800	5176440	but it's probably gonna be a huge milestone
5176440	5178040	on the way to AGI.
5178120	5183120	Because what it represents is the ability to synthesize,
5185800	5188560	task a problem solving program
5188560	5191920	from just two or three examples.
5191920	5195080	And that alone is a new way to program.
5195080	5198000	It's an entirely new paradigm for software development
5198000	5199760	where you can start programming
5199760	5201720	potentially quite complex programs
5201720	5204000	that will generalize very well.
5204000	5206680	And instead of programming them by coming up
5206720	5209920	with the shape of the program in your mind
5209920	5212080	and then tapping it up,
5212080	5214800	you're actually just showing the computer
5214800	5215960	what add what you want
5215960	5218520	and you let the computer figure it out.
5218520	5220400	I think that's what is extremely powerful.
5220400	5223360	I wanna riff a little bit on what kinds of solutions
5223360	5224200	might be possible here
5224200	5226400	and which you would consider sort of defeating
5226400	5229320	the purpose of arc and which are sort of valid.
5230600	5234000	Here's one I'll mention which is my friends
5234000	5236480	that Ryan and Buck stayed up last night
5236480	5237840	because I told them about this
5237840	5239240	and they were like, oh, of course,
5239240	5240080	I was gonna solve this.
5240080	5240920	Thank you for spreading the word.
5240920	5241760	Of course, I was gonna solve this.
5241760	5243560	And then so they were trying to prompt,
5243560	5245400	I think Claude, Opus on this
5245400	5249640	and they say they got 25% on the public arc test.
5250520	5253320	And what they did was have other examples
5253320	5254760	of some of the arc tests
5254760	5256760	and in context explain the reasoning
5256760	5259520	of why you went from one output to another output
5259520	5261400	and then now you have the current problem.
5261400	5264960	And I think also maybe expressing the JSON in a way
5264960	5268240	that is more amenable to the tokenizer.
5268240	5271880	And another thing was using the code interpreter.
5271880	5274080	So I'm curious actually,
5274080	5275800	if you think the code interpreter,
5275800	5278320	which keeps getting better as these models get smarter
5278320	5280640	is just the program synthesis right there
5280640	5282200	because what they were able to do
5282200	5286280	was the actual output of the cells, the JSON output,
5286280	5288640	they got through the code interpreter,
5288640	5290880	like write the Python program that gets right up here.
5290880	5293240	Do you think that the program synthesis
5293240	5294440	kind of researcher talking about
5294440	5296800	will look like just using the code interpreter
5296800	5297760	in large language models?
5297760	5300320	I think whatever solution we see that will score well
5300320	5304560	is gonna probably need to leverage some aspects
5304560	5307040	from deep learning models and LLMs in particular.
5307040	5310040	We've shown already that LLMs can do quite well,
5310040	5312400	that's basically the jack code approach.
5312400	5315080	We've also shown that pure discrete program search
5315080	5317480	from a small DSL does very, very well
5317480	5319120	before jack code, this was the state of the art.
5319120	5321320	In fact, it's still extremely close to the state of the art.
5321440	5324160	And there's no deep learning involved at all in these models.
5324160	5328240	So we have two approaches that have basically no overlap
5328240	5329280	that are doing quite well.
5329280	5333640	And they're very much at two opposite ends of one spectrum,
5333640	5336840	where on one end you have these extremely large banks
5336840	5338800	of millions of vector programs,
5338800	5341120	but very, very shallow recombination,
5341120	5342720	like simplistic recombination.
5342720	5345840	And on the other end, you have very simplistic DSLs,
5345840	5348840	very simple, like 100 or 200 primitives,
5348840	5351920	but very deep, very sophisticated program search.
5352840	5355160	The solution is gonna be somewhere in between, right?
5355160	5359720	So the people are gonna be winning the art competition
5359720	5361840	and we're gonna be making the most progress
5361840	5363960	towards near-term NGR are gonna be users
5363960	5367000	that manage to merge the deep learning paradigm
5367000	5368800	and the discrete program search paradigm
5368800	5371560	into one elegant way.
5371560	5373280	And you know, you ask like,
5373280	5376560	what would be legitimate and what would be cheating,
5376560	5377400	for instance?
5377840	5381080	You wanna add a code interpreter to the system.
5381080	5382760	I think that's great, that's sort of legitimate.
5382760	5385080	The part that would be cheating is try to
5387000	5389240	anticipate what might be in the test set,
5389240	5392320	like brute force the space of possible tasks
5392320	5395160	and then train a memorization system on it.
5395160	5397720	And then rely on the fact that you're generating
5397720	5399880	so many tasks, like millions and millions and millions,
5399880	5402160	that inevitably there's gonna be some overlap
5402160	5404720	between what you're generating and what's in the test set.
5404760	5407960	I think that's defeating the purpose of benchmark
5407960	5409840	because then you can just solve it with that
5409840	5413280	and you need to adapt just by fetching a memorized solution.
5413280	5415640	So hopefully arc will resist to that,
5415640	5418160	but you know, nothing, no benchmark is necessarily perfect.
5418160	5420160	So maybe there's a way to hack it
5420160	5422200	and I guess we are gonna get an answer very soon.
5422200	5424120	Although I think some amount of fine tuning is valid
5424120	5427520	because these models don't natively think in terms of,
5427520	5428840	especially the language models alone,
5428840	5431080	which the open source models that they would have to use
5431080	5433200	to be competitive here compete here.
5433800	5434920	They're like natively language,
5434920	5438080	so they need to be able to think in this kind of...
5438080	5438920	Yes.
5438920	5439760	The arc type way.
5439760	5441480	You want to input corner ledge,
5441480	5444440	like arc like corner ledge into the model,
5444440	5447280	but surely you don't need tens of millions of tasks
5447280	5450080	to do this, like corner ledge is extremely basic.
5450080	5452960	If you look at some of these arc type questions,
5454360	5456480	I actually do think they rely a little bit
5456480	5459640	on things I have seen throughout my life.
5459640	5462800	And for the same, like for example,
5462800	5464640	like something bounces off a wall
5464640	5466160	and comes back and you see that pattern.
5466160	5467480	It's like I played arcade games
5467480	5469600	and I've seen like pong or something.
5469600	5471440	And I think for example, when you see the Flynn effect
5471440	5474120	and people's intelligence has measured on
5474120	5475560	very advanced progressive matrices
5475560	5477360	increasing on these kinds of questions,
5477360	5479360	it's probably a simpler story where since now,
5479360	5481160	since childhood, we actually see these sorts of patterns
5481160	5483400	in TV and whatever, spatial patterns.
5483400	5486200	And so I don't think this is sort of core knowledge.
5486200	5489240	I think actually this is also part of the quote unquote
5489240	5491720	trying tuning that humans have as they grow up
5491720	5494080	of seeing different kinds of spatial patterns
5494080	5495480	and trying to pattern match to them.
5495480	5497800	I would definitely file that under core knowledge.
5497800	5500600	Like core knowledge includes basic physics,
5500600	5503160	for instance, bouncing or trajectories,
5503160	5504400	that would be included.
5504400	5505800	But yeah, I think you're entirely right.
5505800	5507160	The reason why as a human,
5507160	5509040	you're able to quickly figure out the solution
5509040	5511840	is because you have this set of building blocks,
5511840	5514160	this set of patterns in your mind that you can recombine.
5514160	5517240	Is core knowledge required to attain intelligence?
5517240	5518680	Any algorithm you have,
5518760	5520760	does the core knowledge have to be in some sense hard coded
5520760	5523760	or can even the core knowledge be learned through intelligence?
5523760	5525040	Core knowledge can be learned.
5525040	5527200	And I think in the case of humans,
5527200	5529600	some amount of core knowledge is something
5529600	5530640	that you're born with.
5530640	5533640	Like we're actually born with a small amount of knowledge
5533640	5535560	about the world we're gonna live in.
5535560	5537080	We're not blank slates.
5537080	5540640	But most core knowledge is acquired through experience.
5540640	5542000	But the thing with core knowledge
5542000	5545320	that it's not gonna be acquired like for instance in school,
5545320	5547520	it's actually acquired very, very early
5547520	5550400	in the first like three to four years of your life.
5550400	5551440	And by age four,
5551440	5554560	you have all the core knowledge you're gonna need as an adult.
5554560	5556040	Okay, interesting.
5556040	5557800	So I mean, on the price itself,
5557800	5560960	I'm super excited to see both the open source versions
5560960	5564120	of maybe with a Lama 70B or something
5564120	5566520	what people can score in the competition itself.
5566520	5570520	Then if to sort of test specifically
5570520	5571600	the scaling hypothesis,
5571600	5573560	I'm very curious to see if you can prompt
5573560	5575120	on the public version of ARC,
5575120	5576080	which I guess when we compare,
5576080	5578640	you will be able to submit to this competition itself.
5578640	5580080	But I'd be very curious to see how,
5580080	5582800	if people can sort of crack that and get ARC working there
5582800	5584640	and if that would update your reviews on AGI.
5584640	5585640	It's gonna be motivating.
5585640	5586760	We're gonna keep running the contest
5586760	5589040	until somebody puts a reproducible open source version
5589040	5589880	into public domain.
5589880	5593760	So even if somebody privately beats the ARC eval,
5593760	5594880	we're gonna still keep the price money
5594880	5596080	until someone can reproduce it
5596080	5598560	and put the public reproducible version out there.
5598560	5599400	Yeah, exactly.
5599400	5602280	Like the goal is to accelerate progress towards AGI.
5602280	5604280	And a key part of that is that
5604280	5606160	any sort of meaningful bits of progress
5606160	5608800	needs to be shared, needs to be public.
5608800	5610440	So everyone can know about it
5610440	5612160	and can try to iterate on it.
5612160	5613720	If there's no sharing, there's no progress.
5613720	5615040	What I'm especially curious about
5615040	5616640	is sort of disaggregating the bets
5616640	5619840	of like, can we make an open version of this
5619840	5623320	versus is this a thing that's just possible with scaling?
5623320	5625680	And we can, I guess test both of them
5625680	5627840	based on the public and the private version.
5627840	5630680	We're making contact with reality as well with this, right?
5630680	5631520	We're gonna learn a lot, I think,
5631520	5632920	about what the actual limits of the compute
5632920	5633920	where if someone showed up and said,
5633920	5635120	hey, here's a closed source model
5635120	5637240	that like I'm getting 50 plus percent on,
5637240	5638720	I think that would probably update us on like,
5638720	5640400	okay, perhaps we should increase the amount of compute
5640400	5641600	that we give on the private test set
5641600	5643760	in order to balance some of the decisions
5643760	5644960	that initially are somewhat arbitrary
5644960	5647240	in order to learn about, okay, what do people want?
5647240	5648240	What does progress look like?
5648240	5650480	And I think both of us are sort of committed
5650480	5652640	to evolving it over time in order to be the best,
5652640	5654360	or the closest to perfect as we can get it.
5654360	5655840	Awesome, and where can people go to learn more
5655840	5658280	about the prize and maybe give their hand at it?
5658280	5659320	ARCPrize.org.
5659320	5661000	Which goes live today, so.
5661000	5661840	It's live now.
5661880	5663640	$70 million is on this line, people.
5663640	5664480	Good luck.
5664480	5665320	Thank you guys for coming on the podcast.
5665320	5666840	It was super fun to go through all the cruxes
5666840	5668920	on intelligence and get a different perspective,
5668920	5670880	and also to announce a prize here.
5670880	5671800	So this is awesome.
5671800	5672960	Thank you for helping break news.
5672960	5673960	Thank you, Finest.
