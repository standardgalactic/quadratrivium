WEBVTT

00:00.000 --> 00:21.720
Our next speaker is quite an honor that he is here to speak to us, David Crackauer.

00:21.720 --> 00:28.400
He is an evolutionary biologist and the president and William H. Miller professor of complex

00:28.400 --> 00:32.400
systems at the Santa Fe Institute.

00:32.400 --> 00:37.000
He also co-directs the collective computation group at the Santa Fe Institute.

00:37.000 --> 00:43.200
And prior to all of that, David served as the founding director of the Wisconsin Institute

00:43.200 --> 00:48.200
for Discovery, as well as the co-director of the Center for Complexity and Collective

00:48.200 --> 00:55.920
Computation, and as a professor of mathematical genetics at the University of Wisconsin-Madison.

00:55.920 --> 00:59.000
That's only part of his introduction part of his resume.

00:59.000 --> 01:04.680
David has also held positions as a visiting fellow at the Genomics Frontiers Institute

01:04.680 --> 01:07.040
at the University of Pennsylvania.

01:07.040 --> 01:11.240
He's also been a sage fellow at the Sage Center for the Study of the Mind at the University

01:11.240 --> 01:17.880
of California, Santa Barbara, a long-term fellow of the Institute for Advanced Study

01:17.880 --> 01:23.880
in Princeton, and a visiting professor of evolution at Princeton University.

01:24.840 --> 01:31.480
And if that wasn't enough, in 2012, he was included in the Wired Magazine smart list

01:31.480 --> 01:36.080
as one of the 50 people who will change the world.

01:36.080 --> 01:37.960
And he's here with us today.

01:37.960 --> 01:43.280
So I am thrilled to have him join us today, and it is my absolute pleasure to introduce

01:43.280 --> 01:46.080
to you all, David Crackauer.

01:50.080 --> 01:51.080
Hello, everybody.

01:51.080 --> 01:52.080
Morning.

01:52.080 --> 01:53.080
Thank you very much.

01:53.280 --> 01:54.280
Can you all hear me?

01:54.280 --> 01:55.280
Great.

01:55.280 --> 01:57.680
Yeah, there's sort of little introduction to it.

01:57.680 --> 01:58.680
Who are they talking about?

01:58.680 --> 02:02.360
Who is this person that's not me that's being introduced?

02:02.360 --> 02:10.080
So I'm just going to jump right in to my slides to make sure this all works.

02:13.080 --> 02:16.080
And let's see.

02:16.080 --> 02:19.080
Is that all visible to you?

02:19.080 --> 02:20.080
Great.

02:20.080 --> 02:27.080
So I'm going to start, in some sense, anti-system, and then we're going to migrate towards system.

02:27.080 --> 02:30.080
This is a quote I rather love.

02:30.080 --> 02:36.080
This is a quote from Murray Gelman's 1969 Nobel acceptance speech.

02:36.080 --> 02:41.080
Murray is one of the founders of the Center Institute, as some of you will know.

02:41.080 --> 02:48.080
And he said, how can it be that writing down a few simple and elegant formulating like short

02:48.080 --> 02:54.080
poems governed by strict rules, such as those of the sonnet or the waka, can predict universal

02:54.080 --> 02:56.080
regularities of nature?

02:56.080 --> 03:01.080
The waka, by the way, is the ancestor of the haiku.

03:01.080 --> 03:04.080
It would be a little bit too pedestrian for Murray to say haiku.

03:04.080 --> 03:07.080
So he says waka instead.

03:07.080 --> 03:14.080
And this comes out of the work that Murray had done that won him the Nobel Prize on recognizing

03:14.080 --> 03:16.080
fundamental symmetries in nature.

03:16.080 --> 03:23.080
And he wrote down what's become famous as the so-called eightfold way, which is the symmetry

03:23.080 --> 03:27.080
group of the hadrons, which are fundamental particles.

03:27.080 --> 03:33.080
And it's an extraordinary achievement because you write down this, what seems like an invention

03:33.080 --> 03:39.080
of the human mind, that is the Lie algebra for the special unitary group three.

03:39.080 --> 03:48.080
And out of that pops a prediction of a hidden facet of reality, a subatomic particle.

03:48.080 --> 03:52.080
And this is the great mystery, if you like, of applied mathematics.

03:52.080 --> 03:54.080
So that's that Murray.

03:54.080 --> 03:59.080
But there's another Murray that was associated with the founding of the San Dufan students, the Murray who

03:59.080 --> 04:04.080
asked this question, which was, think how hard physics would be if particles could think.

04:04.080 --> 04:09.080
Now this is in some sense the rallying cry for complexity science.

04:09.080 --> 04:16.080
It says, instead of a world dominated by conservation laws, conservation of energy and matter and fundamental

04:16.080 --> 04:26.080
symmetries, it's a world dominated by agency, self awareness, consciousness, reflexivity, system

04:26.080 --> 04:29.080
to, you know, you pick your favorite phrase.

04:29.080 --> 04:36.080
How do you understand those kinds of worlds where the system itself is learning and adapting,

04:36.080 --> 04:45.080
responding to your observations in such a way as to stifle stymie your future efforts to predict them.

04:45.080 --> 04:53.080
And that led quite naturally to this remark, which I think would resonate with everyone at this meeting, where he

04:53.080 --> 05:01.080
essentially makes the point that the complexity of connections in the modern world is so dense.

05:01.080 --> 05:11.080
That there's a real argument for studying some emergent system, which he calls the whole system, rather

05:11.080 --> 05:19.080
than pursue that disciplinary convenience of dissecting the world into its individual components of the

05:19.080 --> 05:27.080
system that Murray had worked on as a physicist. And I've often wondered what Murray meant when he said whole system.

05:27.080 --> 05:35.080
That's been confusing to me. It's almost as if what Murray did is he started as a reductionist physicist, working on the

05:35.080 --> 05:41.080
atoms and quarks and gluons and took some kind of long jump by helping to construct the Santa Fe

05:41.080 --> 05:46.080
Institute and landing on the whole system, which is the planetary system itself.

05:46.080 --> 05:55.080
And I think this is a significant challenge. And I think what Murray actually meant was looking at that point, if you like, of

05:55.080 --> 06:04.080
highest elevation, where we're not studying the whole system, I think that's actually arguably impossible, but we're studying the systems of the world.

06:04.080 --> 06:10.080
And I want to argue throughout this presentation that the systems of the world should be thought of as verbs, not nouns.

06:10.080 --> 06:19.080
I mean, when I go to meetings, people will say we should study the energy sector, or the communication sector or the global banking system.

06:19.080 --> 06:30.080
These to me are objects and artifacts, as opposed to studying processes that actually transcend any given one of those systems, if you like, and that's what I'll argue for, not

06:30.080 --> 06:39.080
to say that you can't do the former, that would be perfectly reasonable and fascinating, but I'm more interested in the generalities that span them.

06:39.080 --> 06:52.080
And so this will be essentially at the table of my talk in a nutshell, and we're going to dive into some of the details because I think the interest of this approach to working on systems lives in the detailed way in which we

06:52.080 --> 07:02.080
analyze them. And so for example, conflict, it's obviously all of these topics I imagine are of great interest today in the world.

07:02.080 --> 07:12.080
And when we understand conflict, both at the individual level, right, that is individual fights, if you like, all the way through to wars at the level of nation states.

07:12.080 --> 07:23.080
Is it meaningful, for example, to describe them both as conflict, or is that just a sort of historical accident that we use the same word to describe events at different scales.

07:23.080 --> 07:33.080
And I'm going to argue that the only sense in which it's meaningful is if you can find the mechanics, or the models that are constitutive of the process.

07:33.080 --> 07:43.080
Right, and demonstrate that that actually yes they are because what we mean in both cases is a certain notion of criticality and I'm going to jump into that in a second.

07:43.080 --> 07:48.080
Another one, culture, how does culture actually work.

07:48.080 --> 07:56.080
You know where where suspended ammently in a world of beliefs and ideas. How do we acquire them, how do we transmit them.

07:56.080 --> 08:08.080
And that this notion of culture is very diffuse, right, so we go from the culture of individual beliefs and norms, all the way through to, you know, enforceable legal systems.

08:08.080 --> 08:22.080
And again, is that real. I mean are we correct in asserting that these are elements of culture. And I think the answer is yes, because in each case we're talking about attitudes towards imitation transmission.

08:22.080 --> 08:27.080
If you like the sort of essential modules or atoms of cultural evolution and so forth.

08:27.080 --> 08:34.080
Again what is constitutive of that notion of culture, and I'm going to focus there on on the evolution of constitutions.

08:34.080 --> 08:40.080
And finally, revolutions, social revolution, scientific revolutions.

08:40.080 --> 08:45.080
Why do some institutions emerge and then freeze.

08:45.080 --> 08:57.080
And there are extraordinarily difficult to change, whereas others seem to be in flux all the time. Can we come to some fundamental understanding about why that's true.

08:57.080 --> 09:10.080
And here I think the answer is yes we can we have to think about structures and orders that have multiple timescales and the way learning rules percolate through those timescales.

09:10.080 --> 09:17.080
So as to either engender fixity stasis, or evolution and change.

09:17.080 --> 09:25.080
So that'll be the sort of that sort of the talk, and I'm going to jump into empirical case studies with mathematical models.

09:25.080 --> 09:29.080
Don't worry too much if it all looks a bit heady.

09:29.080 --> 09:38.080
Just to say that I think that you do this to study says you have to do this in other words, with the essentials of the scientific method.

09:38.080 --> 09:51.080
So let's start with a little data model building an experiment, and no less important here than they would be in a disciplinary pursuit. It's just that we're doing something rather differently.

09:51.080 --> 09:56.080
So let's start with this conflict to contain an issue.

09:56.080 --> 10:14.080
This is not criticality first this is a plot that you will have all seen if you're watching the news at any point in the last three years, which is sort of flatten the curve right so this is a series of projected epidemic profiles for of coven for example,

10:14.080 --> 10:20.080
and critical exponents are zero, or are not in England.

10:20.080 --> 10:30.080
This is that thing which we've all become familiar with, which is the number of secondary infections initiated by a primary infection certain that little picture on the top right.

10:30.080 --> 10:39.080
You can see that if our north or zero is five, then a single initial infection will lead to five secondary infections and so on.

10:39.080 --> 10:47.080
So this is that as you move the critical exponent are zero closer to one, we flatten the curve.

10:47.080 --> 11:05.080
And if our zero is below one, the epidemic would peter out. So this is what's meant by contagion is propagation of infection, and it's also was meant by a critical exponent, which is this threshold value magic value, below which an infection is

11:05.080 --> 11:10.080
and above which it's super critical. Okay.

11:10.080 --> 11:16.080
Many people have claimed in the literature that conflict is something like a contagion.

11:16.080 --> 11:33.080
It spreads from one person to another through a mechanic which is somewhat dissimilar I imagine what we know to an infectious disease, and moreover it shows critical phenomena that is that there is some threshold value of aggression.

11:33.080 --> 11:41.080
Or adversarial interaction, above which conflict becomes super critical, and below which it would be so critical.

11:41.080 --> 11:48.080
And the idea I guess at the Pacific dream would be to get those critical exponents below one.

11:48.080 --> 11:51.080
So it's to move into subcritical regimes.

11:51.080 --> 11:55.080
Is any of this true is a huge literature.

11:55.080 --> 12:00.080
Well, to answer that question if you look at the data and we have to build mathematical models.

12:00.080 --> 12:06.080
And answer this question of whether or not conflict really is a contagion or not.

12:06.080 --> 12:13.080
So here's the kind of basic questions we might want to ask ourselves, is it true. Does it have a critical transition.

12:13.080 --> 12:22.080
Is there a relationship, for example between the conflict duration the number of fatalities, the, the geographical area that it encompasses.

12:22.080 --> 12:33.080
And if that's all true. What are the normative implications that is, we're not just doing descriptive natural history of conflict we want to intervene in such a way as to minimize it.

12:33.080 --> 12:42.080
The way of for example a physician might make recommendations for mass wearing, so as to minimize the spread of a pandemic.

12:42.080 --> 12:46.080
So that's one of the sorts of questions.

12:46.080 --> 12:50.080
So, in order to answer that now.

12:50.080 --> 12:53.080
I wonder if I can see you can see this.

12:53.080 --> 13:00.080
Is anything blocked here by the way Laura or can you see the whole screen that my own so good.

13:00.080 --> 13:02.080
We can see the whole screen. Oh great great great.

13:02.080 --> 13:11.080
So, um, so the way we do this is we look at two kinds of systems. We look at experimental systems non human systems that we can intervene into.

13:11.080 --> 13:17.080
And so these are small populations, every individual can be monitored.

13:17.080 --> 13:23.080
And we're looking at the individual conflict rules that individuals are following. So very micro.

13:23.080 --> 13:34.080
On the other hand we have large scale observational data of human populations, very macro. And in that case we're inferring quite different kinds of scaling relations not individual decision rules.

13:34.080 --> 13:40.080
So, I just want to make that point about model systems versus observational systems.

13:40.080 --> 13:48.080
It leads to a lot of heated debate I think one should look at both because they each have strengths and weaknesses.

13:48.080 --> 13:55.080
So, let me just give you one example this is something we've been studying for many years non human primates macaques by the monkeys and so on.

13:55.080 --> 14:06.080
And here, just to give you a sense we can look at any given moment in time. These are animals in captivity at who is fighting or not fighting at any given point in time so very micro.

14:06.080 --> 14:13.080
We can see who interacts with whom we can reconstruct social networks of their interactions and so on.

14:13.080 --> 14:15.080
And out of that kind of data.

14:15.080 --> 14:25.080
So, let me give you some of those sorts of interesting insights but let me give you one example. This is the scaling of the log log axes of the conflict duration and conflict size.

14:25.080 --> 14:43.080
Just notice that as the number of individuals in a particular conflict increases, so does the duration of the conflict, and it increases polynomially in increases as the square of the number of individuals.

14:43.080 --> 14:53.080
The variance, not just the mean. So this is the distribution of how long peace bouts last so for example, no one's fighting anyone.

14:53.080 --> 15:07.080
10 seconds 10 minutes an hour and so on, and conflict durations and you'll notice that if you look at the distribution of durations, as they get longer the variance increases, so the scatter around that distribution increases.

15:07.080 --> 15:24.080
So here's just some data. What one can now do is write down a whole family don't worry about the details of mathematical models and explore the full configuration space of possible contagion processes, not just one or two but a very large number, and ask which ones of those

15:24.080 --> 15:34.080
mathematical models are consistent with the scaling relationships, for example the one observed in the data, the scaling of the mean and the scaling of variance.

15:34.080 --> 15:53.080
But most contagion process actually can't recover the observed data and this is quite important, because in many studies people will assert contagion without checking carefully against the empirical data, which would either refute or confirm transiently the hypothesis.

15:53.080 --> 16:15.080
And what we find just is, is a critical role of agency. It is a contagion process, but with one really interesting characteristic, which is long term memory, that is, the memory of the first conflict, and its duration is felt throughout all subsequent conflicts, that is not a

16:16.080 --> 16:30.080
property of a mathematical, of a biological epidemic. There's a very different kind of contagion, it's contagion with significant memory in it, which is that sort of agency fact that self awareness fact and we all know that and resentments are very long lasting.

16:30.080 --> 16:42.080
So an attempt, for example, to intervene on a human conflict contagion as if it were a biological contagion, without taking into account the sort of psychological fact of memory would fail.

16:42.080 --> 16:45.080
So that's just one example.

16:45.080 --> 16:53.080
We've also looked, as I said, at the more core screen data, we've looked, this is the so-called ACLED database, extraordinarily rich.

16:53.080 --> 17:02.080
And we've been studying conflicts in continental Africa for two decades, looking at things that are very similar actually to the micro data I just showed you.

17:02.080 --> 17:17.080
And here you don't have who's fighting whom at a given point in time, but what you do have is data like this where over the course of time you have battles, the number of fatalities, exact geographical locations and so forth.

17:17.080 --> 17:24.080
So we can study time and space, but at a much more low resolution than we would in the experimental system.

17:24.080 --> 17:36.080
And as with the experimental system, we can look at things like the distribution of conflict sizes, the distribution of fatalities, duration and spatial extent.

17:36.080 --> 17:53.080
And as with micro data, we can write down mathematical models as a rather complicated model and maybe describe this one in any detail, but just the idea that contagions grow as a kind of a fractal like branching pattern on a two dimensional surface.

17:53.080 --> 18:09.080
And one of the things that these models predict is that at critical points, like for example R zero equals one, that is that critical point below which an epidemic is subcritical above which it's supercritical.

18:09.080 --> 18:22.080
Something really interesting happens, you get a complete collapse of complexity, and all of those scaling exponents become related. It's actually a really beautiful feature of complex systems that at critical points they become simple.

18:23.080 --> 18:32.080
And for those who are interested in the form of analysis, this is using something called renormalization group theory. It's a way of looking across scales.

18:32.080 --> 18:45.080
And you can see, and just take my word for it if you like, that if you look at the ratios and empirical data against the model predictions they're extraordinarily close, which suggests two things again.

18:45.080 --> 18:56.080
And yes, this is a contagion like phenomenon so that's a correct statement, but it's also a contagion like process that's near criticality.

18:56.080 --> 18:59.080
And this is very surprising.

18:59.080 --> 19:02.080
Because it's not clear why that should be the case.

19:02.080 --> 19:06.080
So if you think about an epidemic with R zero.

19:07.080 --> 19:23.080
Why would it live by a critical point, and we all know the answer actually because we're observing it today. And that is that if are not zero I never quite know I've sort of been in the United States long enough to want to say zero but my answer my early life was in England so

19:23.080 --> 19:38.080
not so I'm going to be at the critical point where I say both. And if you think about it, when the epidemic is in full blast, we start taking precautions. We wear masks we get vaccinated we get boosted.

19:38.080 --> 19:41.080
We shift our zero down.

19:41.080 --> 19:44.080
But when our zero falls below one.

19:44.080 --> 19:49.080
The epidemic starts petering out and what happens we take off our masks.

19:49.080 --> 20:01.080
We take off our masks because we think oh look, we've won. And then what happens the new strain emerges and it probably gets back in. We put our mask back on, and this is one of the so called roots to endomism.

20:01.080 --> 20:15.080
And that phenomenon of a system hovering around the critical point is called self organized criticality. And it seems as if conflict is manifesting this phenomenon of hovering by a critical point.

20:15.080 --> 20:27.080
In many cases, yes, with a strong agency memory effect. Does it have a critical transition yes but we don't know exactly where it is we don't know the r zero of human conflict.

20:27.080 --> 20:37.080
You get this incredibly interesting simplification of the system of conflict at the critical point with all the scaling exponents become related.

20:37.080 --> 20:46.080
And the normative implications for us are deliberative techniques to move systems away from critical points.

20:46.080 --> 20:56.080
And that's the whole era of investigation we've pursued and perhaps we in questions we can deal with it, but if you look at my website there's some things on that there.

20:56.080 --> 21:01.080
So that's just one example. Let's keep jumping to the culture.

21:01.080 --> 21:15.080
How on earth should we model culture. And this is, again, my view is you have to take a representative model system where good data is available, and you could look at Twitter.

21:15.080 --> 21:24.080
You could look at newspapers. It almost doesn't matter, as long as you're rigorous and, you know, consistent in the way you do this.

21:24.080 --> 21:35.080
So we've been looking at constitutional history. And so this is a very famous painting is painted in 1740. It relates to the signing of the Constitution American Constitution 1789.

21:35.080 --> 21:41.080
And you can see in that picture I'm sure a few familiar faces.

21:41.080 --> 21:50.080
And what we do, working with constitutional historians and lawyers is we take a constitution and we atomize it.

21:50.080 --> 22:01.080
We break it down into its essential themes. And for those interested in machine learning, or natural language analysis, these atoms are called topics.

22:01.080 --> 22:13.080
So for example, oops, these are my questions. Let's just skip them we'll come back to them. So here's a constitution we're going to break it up into its basic lexical atoms.

22:13.080 --> 22:26.080
The way it treats general rights, the way it treats sovereignty public order. And we're going to ask how do these themes diffuse forward in time through constitutions.

22:26.080 --> 22:34.080
The way that constitutions are written is you don't sit down in a room and write one for your nation de novo out of nowhere.

22:34.080 --> 22:36.080
Ex Ovo.

22:36.080 --> 22:41.080
You look at prior constitutions and you borrow from them.

22:41.080 --> 22:49.080
But what you can do, mathematically is reconstruct the phylogenetic tree of all constitutions that have ever been written.

22:49.080 --> 22:55.080
And if we zoom in on this you can see, here's the Constitution of Egypt of 1923.

22:55.080 --> 23:01.080
It was highly influential on the room D62 albania 25 it was slightly 31 year old 1925.

23:01.080 --> 23:05.080
These are obviously a reading chronological order.

23:05.080 --> 23:12.080
What's going on here, which topics are circulating how is borrowing taking place and why.

23:12.080 --> 23:17.080
What's the impact of local culture and geography.

23:17.080 --> 23:23.080
I'm going to skip all that for today, but just give you a sort of sense of what you can say in this kind of structure.

23:23.080 --> 23:28.080
We can sort of leap in and look at the micro geometry of that tree.

23:28.080 --> 23:33.080
What you're looking at here if you look at the center, you have the focal constitution of interest.

23:33.080 --> 23:45.080
It has a number of parents that it borrowed from that we've inferred using some techniques, and a number of offspring that it influenced that borrowed from it.

23:45.080 --> 24:02.080
And we can reconstruct this kind of zoo of geometries of all the constitutions all of these are essentially that structure on the left but giving you a sense of the diversity of constitutional forms that we can reconstruct going back to 1789.

24:03.080 --> 24:14.080
And these actually correspond to particular constitutions you can look at the bottom one that's the Constitution of Montenegro had three parents no offspring.

24:14.080 --> 24:16.080
Right.

24:16.080 --> 24:21.080
The interesting one is the South Korean Constitution of 1948.

24:21.080 --> 24:31.080
That's that one sort of third from the bottom. It has a small number of parents but a lot of offspring. That's a very influential constitution.

24:31.080 --> 24:46.080
And so we can start asking, which constitutions are highly inventive which ones had disproportional impact, which ones are sterile, actually never led to offspring, and so on.

24:46.080 --> 24:59.080
And so complicated plot, but what if you look at the lifespan of a constitution, the lifespan is defined as when it was written, and when it start it stopped being borrowed from.

24:59.080 --> 25:13.080
And so no one looks at it anymore. The US Constitution is very interesting. It was very influential early, but it was so influential on secondary constitutions that they borrowed from those instead of the founding constitution.

25:13.080 --> 25:24.080
And top left you see a tree of all the constitutions you see three clear epochs founding 1789 up until the Second World War.

25:24.080 --> 25:33.080
And so you get rid of a relatively slow rate of constitution writing, and all the constitutions are very long lived.

25:33.080 --> 25:41.080
Then during the war subsequent you get an acceleration of the production of constitutions, most of which are very short lived.

25:41.080 --> 25:44.080
So quite distinct cultural phases.

25:44.080 --> 25:58.080
And so we can go into this particular object, which seems to think what are constitutions they established branches of government, the separation of powers, property rights, issues about freedom of expression.

25:58.080 --> 26:06.080
These are in some sense the operating systems of societies, and they have a very interesting dynamic.

26:06.080 --> 26:22.080
So you can then answer these questions. How is cultural transmitted cultures transmitted a little bit like genetics. It's not genes, it's core constellations of concepts like rights property rights structures of government.

26:22.080 --> 26:27.080
Which ideas are most influential and constitutions strong early mover advantage.

26:28.080 --> 26:44.080
Quite unequivocally that if you're early, early in the, the writing of the constitution, you will be an influential one. It almost doesn't matter what you write about, because you become a source of influence on subsequent constitutional authors.

26:44.080 --> 26:53.080
This is a preferential attachment dynamic that many of you will be familiar with it happens for example, Uber happened to eBay having Etsy.

26:54.080 --> 27:12.080
Being their first and becoming the preferred markets for ideas is a long lasting effect. And it's no less true for these ancient cultural forms and it is for contemporary technological forms, even though many have claimed the dynamics of software

27:12.080 --> 27:23.080
that is different. It actually isn't you. It seems to be a more universal dynamic of culture than a particular mechanic of the contemporary world.

27:23.080 --> 27:41.080
And this really interesting point that it's better to be revolutionary than evolutionary if you're writing constitutions. That is, the highly inventive constitutions that that add new topics if you like new categories of thought are the ones that people look

27:41.080 --> 27:54.080
at, not the ones that add one or two increments and what came before them so be first and be radical is the sort of if you like the message of constitutional history.

27:54.080 --> 28:05.080
Finally, revolutions like everyone else I'm interested in revolutions, particularly scientific revolutions, but during the last few years social revolutions.

28:05.080 --> 28:11.080
The whole black lives matter protesters of great interest to me personally.

28:11.080 --> 28:22.080
And how can we understand what's going on here, why, why do society seem to go through periods of stasis, and then these incredibly rapid bursts of change.

28:22.080 --> 28:29.080
Is there a sort of unifying framework for evolution and revolution in social systems.

28:29.080 --> 28:38.080
The kinds of things I'm interested in things like this, you know, why do we go from extraordinary intolerance of homosexuality to accepting it.

28:38.080 --> 28:47.080
Going so far as to allow for gay marriage, which to me is a real fantastic evolutionary move of society. What changed in people's thinking.

28:47.080 --> 28:55.080
By the way, there's a nice typo here this is Oscar Wilde 1985, which is not quite right.

28:55.080 --> 29:03.080
So, this, you know, attitudes for this is for the fiction on the left, anyone is rock history realize the two very different people.

29:03.080 --> 29:10.080
But this sort of scare tactics that people have used to sort of discourage people from taking recreational drugs and maybe they're right maybe they're wrong.

29:10.080 --> 29:16.080
But then the shift towards a much more permissive society.

29:16.080 --> 29:23.080
And political beliefs, I mean, endlessly oscillating back and forth between political parties.

29:23.080 --> 29:31.080
Can we sort of wrap this system up in a common mathematical framework so that we can understand properties of all of them.

29:31.080 --> 29:45.080
And as I said I think the answer is yes, because they're all characterized by having multiple time scales with individual learning rules that percolate up through the time scales, often in invisible ways, leading to very dramatic shifts.

29:45.080 --> 29:57.080
The kind of data that we look at to see if your senses is it like this, all across the board. Why, for example, did seat belts once they're adept adopted lock.

29:57.080 --> 30:07.080
It's very unlikely that we're going to move back to a state where people say you know, let's get rid of the mandatory seat belt law. It seems like a bad idea.

30:07.080 --> 30:17.080
Whereas political parties, fortunes are constantly shifting attitudes towards the death penalty are constantly shifting and so on.

30:17.080 --> 30:25.080
I mean, it would be kind of nice right if attitudes towards same sex marriage or the death penalty look more like the seat belt in a progressive sense.

30:25.080 --> 30:31.080
And once we'd adopted them we stayed that way and didn't constantly fluctuate that can we understand one of this.

30:32.080 --> 30:43.080
And so these are the kinds of questions we're asking here. How did these systems evolve. How do we as individuals, or as collectors contribute to these institutions.

30:43.080 --> 30:52.080
So I use this word institution by the way to mean scientific belief systems or organizations companies could be IBM.

30:52.080 --> 31:01.080
How do individual micro learning rules percolate through to the emergent structure of the, of the macro properties of the institution.

31:01.080 --> 31:12.080
And what does an institution do that wants to change, but finds itself like the seat belt locked in.

31:12.080 --> 31:18.080
You know, can we are their normative implications just as they're worth a conflict.

31:18.080 --> 31:25.080
So this is the basic structure of these models, you have collectives at the bottom.

31:25.080 --> 31:33.080
They express their support or position to an institution through voting mechanics.

31:33.080 --> 31:59.080
And we think of the institutions as a ledger that records in its entries, votes, aggregates preferences and beliefs, and it has a public position, and that public position feeds back to reinforce or inhibit the collectives that are

31:59.080 --> 32:11.080
going to support or inhibit them in other words, members of a Republican Party will support their own party, but they will do everything their power to oppose the Democratic Party and Democratic beliefs and vice versa.

32:11.080 --> 32:22.080
So, the same kind of logic applies by the way to scientific revolutions here's the so called Copernican Revolution, you have Copernicus saying you know, you know everybody.

32:23.080 --> 32:34.080
It's kind of a possibility thing, but you've got the church saying well no it's kind of a little bit at odds with what we've been saying for the last however many thousand years, we'd rather you shut up.

32:34.080 --> 32:48.080
And so again that sort of dynamic of voting opposition and support with feedback from the institutions because that's crucial right because if the institution helps you, you gain power.

32:48.080 --> 32:52.080
So you can take that and mathematics it.

32:52.080 --> 33:02.080
For those of you with keen eyes you'll see this looks like a perceptron it's a very simple neural network, but it's all analytical doesn't matter.

33:02.080 --> 33:16.080
Mathematize it and explore. This is going to be the technical point and it's coming to the end which I would sort of get your heads around the crucial role of learning rules, which are the rules that reinforce your beliefs and support or

33:17.080 --> 33:30.080
based on the success of your corresponding institution. So let me just show you what I mean. So here's a case. Let's say X supports IX and Y supports IY the institution Y.

33:30.080 --> 33:44.080
One learning will be to say look, if there's lots of us, lots of X's, let's say supporters of the Copernican Revolution, we're going to support Copernicus and all publications that promulgate a heliocentric position.

33:44.080 --> 33:57.080
But if you're a member of, let's say the time, a religious fraternity or church, if you're more numerous you'll support your institutions in that case they say the Catholic Church.

33:57.080 --> 34:02.080
That's one kind of rule it says you learn in accordance with your success.

34:02.080 --> 34:14.080
That kind of rule is quite opposite to that is that actually I might just attend if I'm being successful, why bother? Why bother doing more work? I've already won.

34:14.080 --> 34:20.080
I'm going to divest from supporting my institution because I'm in the leading position.

34:20.080 --> 34:29.080
Here's an interesting one, an arms race. An arms race says, I'm going to support my institution in proportion to the success of my rival.

34:29.080 --> 34:43.080
So think about nuclear expansion. If your opponent doesn't have weapons then why should you? So your support of your institution is in proportion to your competitors' abundance.

34:43.080 --> 34:56.080
So you can write down all these simple rules which tell you how to construct institutions according to their abundance if you like or power or size.

34:56.080 --> 35:01.080
And on and on you can go and you can actually mathematically look at all possible permutations.

35:01.080 --> 35:15.080
And if you do that you make some interesting discoveries. If you use, for example, this rule which says invest in your institution in proportion to its size, you get lock-in.

35:16.080 --> 35:25.080
You're going to fix on a single institution and never change it. And you can sort of see intuitively why that's the case because you're not attending to the competitor at all.

35:25.080 --> 35:31.080
And the bigger you get and the bigger your institution becomes the more you support it, lock-in.

35:31.080 --> 35:40.080
The same is true with the other rules. The arms race is the opposite, right? It says, I support my institution in proportion to the competitor.

35:40.080 --> 35:46.080
And that leads to endless cycling periodicity.

35:46.080 --> 36:05.080
So what this sort of work is showing is that the incentive system that society puts in place, that is the reinforcement learning rule, has strong emerging consequences on the stasis or the ability of the corresponding institution.

36:05.080 --> 36:17.080
And that suggests that you could change them. So for example, let's say you were in a lock-in situation and you're a company like Kodak and you say, well, look, we make the best film in the world, we should make more of it.

36:17.080 --> 36:21.080
And then all of a sudden the market changes and you're extinct.

36:21.080 --> 36:36.080
So you could, as a leadership team say, I'm going to create a new learning rule amongst my employees that instead of investing in proportion to our market share, we're going to look at the competitor,

36:36.080 --> 36:42.080
change the norms, change the incentives, and move into an oscillatory regime where you allow for the possibility of flexibility.

36:42.080 --> 36:50.080
So this is just an example of these very counterintuitive ways in which local incentive learning systems have emergent properties at the institutional level.

36:50.080 --> 36:57.080
And I just wanted to make that point. That rule there is an institutional black hole. This is Kodak, this is research in motion.

36:57.080 --> 37:00.080
Follow these rules, stasis.

37:00.080 --> 37:10.080
So okay, so how do institution evolves in this particular case feedback from institutions that are established through some collective voting dynamic.

37:10.080 --> 37:16.080
How do you construct, use different learning rules to do so?

37:16.080 --> 37:28.080
So these rules in a very non-intuitive way, bias, the stability of the institutions, and how do you change, you have to change the learning rule.

37:28.080 --> 37:32.080
You have to, that's the key and that's very hard.

37:32.080 --> 37:41.080
So let's just end with this Murray statement, Murray making that point that we're living in this highly connected world, someone should be studying the whole system.

37:41.080 --> 37:56.080
And I think that the correct interpretation of that kind of insight is that we should be studying global representative systems that have a mechanic that is constitutive of that system.

37:56.080 --> 38:09.080
We should be studying culture, conflict, institutions, cities, pandemics. These are the kinds of processes where we have a principal means of attaching to them, mechanics and dynamics.

38:09.080 --> 38:12.080
And I have absolutely no idea it's a spaghetti.

38:12.080 --> 38:24.080
And you'll note that these are disciplines, they span them, but they're as disciplined as the disciplines, which is the sort of mantra that I try my best to follow.

38:25.080 --> 38:30.080
For those interested in SFI, go to our webpage.

38:30.080 --> 38:40.080
If you scroll down to the bottom of the Santa Fe Institute webpage, you can subscribe to our publications, you can join our podcast.

38:40.080 --> 38:48.080
There's all sorts of information available there for you that you will either hate or love, according to a disposition, but it's worth having a look because there's a lot of material.

38:48.080 --> 38:56.080
And with that, I'll wrap up. Thank you very much.

38:56.080 --> 38:59.080
Thanks, David.

38:59.080 --> 39:01.080
That was fantastic.

39:01.080 --> 39:06.080
Just, we need a whole day on this.

39:06.080 --> 39:08.080
Fantastic.

39:08.080 --> 39:16.080
And I do encourage everybody to go to SFI and check out what they're doing. It's a very special place. You still do tea, David.

39:16.080 --> 39:19.080
We do tea.

39:19.080 --> 39:27.080
Tea was sort of the most amazing thing where you get to meet these just people from all over and talk a little bit about tea.

39:27.080 --> 39:37.080
Well, it's interesting, you know, I mean, this is, we've all been debating this move towards this world, right, this online world, which has extraordinary like this.

39:37.080 --> 39:40.080
Yes, I mean, you can do this thing, which is fantastic.

39:40.080 --> 39:57.080
But what is missed and I think the obvious point is that this is very telegraphic, right? In other words, I just waffled on for 30 minutes, but we'll have questions for 15 and most people won't have a chance to ask, you know, it's whereas if you're in person, someone can really

39:57.080 --> 40:00.080
really pester you.

40:00.080 --> 40:12.080
And it's great. But also you can move back and forth, you know, clarifying what people mean, because it's very often takes two or three questions to sort of get to, oh, that's your sense.

40:12.080 --> 40:22.080
That's what you mean. I sorry I misunderstood you. And so tea is our sort of mechanic for doing just that we pretend it's this informal thing which it is.

40:22.080 --> 40:30.080
And really is it's recognized in the complexity of human interactions, and that it takes time to understand each other.

40:30.080 --> 40:33.080
So I don't, that's what she's for.

40:33.080 --> 40:50.080
So at SFI they have a courtyard and people just have tea and, you know, all, all manner of conversations are sparked at tea and you could have a physicist and a sociologist and a mathematician and a, you know, all kinds of different

40:50.080 --> 40:54.080
people talking about an issue it's fantastic.

40:54.080 --> 41:07.080
But one thing to say that I'd like to point out I didn't talk about SFI and its structure, but to do the kind of work that I just described as a tiny slither of work it happens to you work that I've been involved with I could have talked about other people's work.

41:07.080 --> 41:10.080
You need a different kind of organization.

41:10.080 --> 41:15.080
And so we don't have obviously departments, we don't have deans, we don't have that stuff.

41:15.080 --> 41:29.080
So we, and in offices which are typically shared you'll have an archaeologist with quantum mechanist right and by the end of the summer they're working on a problem together, because they like each other.

41:29.080 --> 41:39.080
I mean it's sort of simple as that. And so the structure of respects I think the mission in terms of what we want to accomplish.

41:39.080 --> 41:44.080
So I'm curious, you started with the one of Murray's quotes.

41:44.080 --> 41:51.080
Think of how difficult physics would be if Adams could think is a fantastic concept.

41:51.080 --> 42:06.080
And Murray Gellman also wrote a very short paper called, let's call it Plectix which really got at the root definition and root word forms of simple and complex.

42:06.080 --> 42:12.080
Can you talk a little bit about that relationship between simplicity and complexity and why that's important.

42:12.080 --> 42:18.080
Yeah, I have lots of slides on it I didn't want to do this because there's so many times, but I will do it verbally.

42:18.080 --> 42:34.080
So one way to think about this is that where have the, because we are a quantitative department I don't think you need to be to work in systems or complexity quite frankly think philosophers do it very well only natural language, but we could do it that way.

42:35.080 --> 42:52.080
One way to say this is that, you know, physics has been so successful the kind of Murray worked on that I illustrated, because it's so simple meaning there are laws like conservation matter of energy matter and so forth the second or so.

42:52.080 --> 42:57.080
Fundamental symmetries, and that's what mathematics likes.

42:58.080 --> 43:08.080
It captures in a very compressed elegant form regularities, the essence of mathematics, Pythagoras theorem.

43:08.080 --> 43:19.080
On the other end of the spectrum have random things like the ideal gas law. It turns out, maybe counterintuitively the highly random systems also can be compressed with very simple laws.

43:19.080 --> 43:29.080
Yeah, in the middle between the world of extreme regularities like the celestial mechanics, or on the right, you know, thermodynamics and statistical mechanics.

43:29.080 --> 43:37.080
You have this domain, which has randomness in it, but randomness that accumulates regularities like evolutionary history.

43:37.080 --> 43:38.080
Right.

43:38.080 --> 43:55.080
That is the domain of complexity is the domain of living systems, and people say well you mean you're just biologists, and we'll say, well in one sense yes, but we're studying markets as well and we're studying ancient civilizations and archaeology.

43:55.080 --> 44:08.080
It's the living world that we study, but we study it through that hubristic lens of, can we find theories that are general for the living world.

44:08.080 --> 44:19.080
And it turns out that theories in that domain have a different character in part because they have to contend with agency.

44:19.080 --> 44:24.080
And I would say if you ask me what is the channel of the 20th the challenge of our century.

44:24.080 --> 44:40.080
It is this it's that two paradigms have emerged to contend with that machine learning and complexity science and I'm willing to make that a very broad church, but I am a deserfite.

44:40.080 --> 44:48.080
And one of them is highly predictive and opaque machine learning.

44:48.080 --> 45:01.080
The other one is less predictive but gives you the possibility of understanding how it actually works, explaining to people what's going on, you know, pedagogy.

45:01.080 --> 45:13.080
And I think that we're at a very interesting bifurcation point in our history where that's never happened before. And if you look at the 17th and 18th centuries those two things were very close.

45:13.080 --> 45:21.080
Newton could be both predictive, but also teach you how calculus works and you can write down how people's may I mean it's that simple.

45:22.080 --> 45:41.080
Nowadays, that's not true. And I think we're now contending with these two churches, the predictive, opaque, and the explanatory transparent, and I'm very interested in that in that schism.

45:41.080 --> 45:50.080
I want to talk a little bit about that schism with with the human dream and and how that, how that relates.

45:50.080 --> 45:52.080
You share a little bit about that.

45:52.080 --> 45:58.080
Can you just expand on that, you know, yeah, well just that then there's human thinking.

45:58.080 --> 46:08.080
There are these agents that that don't aren't seeing the transparency of the system and they're behaving a lot of a lot of what you just talked about in contagion and culture.

46:08.080 --> 46:26.080
How do we have that loop back to the agent so that they can change their learning rules or whatever to change. Yeah, yeah, I mean that in a way but is this is our, this is part of our agenda right to understand individual freedom in the face of institutional constraint.

46:27.080 --> 46:34.080
I don't think we have answers to that I think we can analyze cases.

46:34.080 --> 46:43.080
We still valorize the individual certainly in the United States in the West is a very strong emphasis placed on individual creativity, perhaps overstated.

46:43.080 --> 46:55.080
You know, we all know that theories aren't really invented by single people that through hidden history they're hidden figures that made huge contributions that get neglected or ignored.

46:55.080 --> 47:06.080
There's right carving out the space for individual freedom and free will in the face of these very powerful constraints, which are market driven.

47:06.080 --> 47:24.080
I mean this has been one of my crusades you know I mean, there's nothing wrong with platforms that harness collective power, but when those platforms have an incentive that is misaligned with human freedom, I sort of good war on them.

47:24.080 --> 47:35.080
You know, and I will be an example of my own field, the journal system scientific publication appear review it's a perfect example of a corrupt system, because we all know it everyone's not doing it, of course it is.

47:35.080 --> 47:48.080
It's embarrassing. Here we are researchers, and we are completely beholden to a system that does not have the progression of science at the forefront, but sales.

47:49.080 --> 47:55.080
And so, it's not that I'm anti market it's just one of those things become misaligned.

47:55.080 --> 48:03.080
Then we have to rethink. So we're constantly having these battles I wish we had them more often, and we had more victories under our belt.

48:03.080 --> 48:04.080
Yeah.

48:04.080 --> 48:16.080
So an audience member asked, how can we use these complexity models to appreciate better the external drivers for the changes we see.

48:16.080 --> 48:26.080
And I think, yeah, that gets back to your question Jerry earlier which is, they in some sense formalize the contributions of the constraints.

48:26.080 --> 48:36.080
I mean that's partly what they're all doing. I mean they're trying to, you know, where do we have free freedom to move and where the constraints established by the institutional feedback.

48:36.080 --> 48:53.080
And I think in every case we sort of have to sort of analyze how much is being driven by the constraint, and how much is being driven by our decisions, which is made even more complicated by the fact that our decisions emerge through a history of institutional

48:53.080 --> 49:06.080
and not even clear that we are free I mean there's some very difficult issues hiding in these circular feedback systems, where you how to attribute causality, but they do I mean just to get a question.

49:06.080 --> 49:16.080
You can actually do that you can partition for any given synchronous observation, how much comes from the constraint and how much is coming from your internal state.

49:17.080 --> 49:20.080
You can start getting at those things.

49:20.080 --> 49:29.080
I want to give you a chance to talk a little bit more about learning rules that the based on the success of the corresponding institution there.

49:29.080 --> 49:41.080
Say a little bit more about are the learning rules merely evolutions of the original rules, meaning like their schema that are just evolving as a result of feedback.

49:41.080 --> 49:42.080
Yeah.

49:42.080 --> 49:57.080
So what the paper actually that goes into detail is it's actually going to be published on May 16. And it's called on institutional dynamics and learning rules. So that will go that might help people.

49:57.080 --> 50:07.080
That was for that particular model, a full discrete enumeration of all possible learning rules. So we can do that in this very simple setting.

50:07.080 --> 50:14.080
And then pick any given one right and ask what are the implications if that were being used.

50:14.080 --> 50:20.080
So we don't have we don't look at the full continuous space between all rules and someone.

50:20.080 --> 50:40.080
I think the purpose of that work was to show that there is a, I think quite counterintuitive relationship between the local incentive reward system, and the ensuing institutional dynamic that that's the purpose of that work because if you look at the literature

50:40.080 --> 50:45.080
on institutions, it tends to work at the institutional level.

50:45.080 --> 50:51.080
It doesn't have these multiple time scales, which is mathematically by the way of heart.

50:51.080 --> 51:07.080
And this is something that's a hidden idea here that one should surface which is that much of theorizing for good reasons is led by analytical expediency.

51:07.080 --> 51:16.080
I mean, especially economics, where they love that. And the question for our community is, when are we willing to forfeit that.

51:16.080 --> 51:22.080
And that's really the move to machine learning or simulation right where you say, you know what.

51:22.080 --> 51:34.080
No, I mean, it's so far from reality. I don't care if you understand your model, it's useless, you know, and then that's a kind of people set that threshold at different points somehow.

51:34.080 --> 51:42.080
It would be very interesting, you might know, why do we do that psychologically, why do we have different preferences for that.

51:42.080 --> 51:45.080
I think we have time for one.

51:45.080 --> 51:48.080
Do we have time for one more.

51:48.080 --> 51:51.080
Laura.

51:51.080 --> 51:55.080
Yeah, time for one or two more. Okay, good.

51:55.080 --> 52:15.080
So another audience question. It's actually two questions. Does your work provide any insight into the role of relationships of the agents of systems and second does the fact that contagion hovers around criticality have anything to do with enhancement of adaptive capacity of the agents.

52:15.080 --> 52:18.080
Okay.

52:18.080 --> 52:24.080
So, yeah, I mean, I think the latter, that's very interesting.

52:24.080 --> 52:34.080
I think the answer has to be yes to that second part because, as in the example right of hovering by our zero equals one.

52:34.080 --> 52:44.080
It's precisely because we are so adaptive that happens right because as soon as we observe the information bearing on the subcritical regime we take them off.

52:44.080 --> 52:53.080
If we weren't adaptive we wouldn't, we would fix, and the actually the pandemic would go away it's sort of a peculiar perverse situation to be in.

52:53.080 --> 53:03.080
So yes, absolutely I think you're absolutely right. Adaptability is, I think the key ingredient of tuning to criticality.

53:03.080 --> 53:09.080
And, but you know what we're going to do to get rid of adaptability.

53:09.080 --> 53:15.080
And the first part seemed to me a more obscure I wasn't sure I understood the first part of the question.

53:15.080 --> 53:27.080
Well, I think that's interesting and follow up on that. So a lot of the systems that our students deal with are is, is, you know, so you found this this results from a mathematical model.

53:27.080 --> 53:34.080
But how do you feedback that that learning to the agent, like in the case of COVID.

53:34.080 --> 53:47.080
If the if the individual agents could change their schema or their mental model so therefore changing their, you know, behavior, you would get of it, we could get rid of coven right.

53:47.080 --> 54:01.080
So how do we take, you know, it seems to me the hard part is we learn these things about the at the systemic level, but how do you get the individual agents to change based on that awareness.

54:01.080 --> 54:04.080
I mean that seems to be like the crux of the whole.

54:04.080 --> 54:14.080
I mean, it's even worse for climate change because it's interesting I was in sabbatical at Harvard actually when the pandemic hit.

54:14.080 --> 54:25.080
And I was actually working at the Center for the environment which works on climate and immediately the conversation we were having is odia.

54:25.080 --> 54:33.080
How do we deal with systems that are massive global tragic collective commons problems.

54:33.080 --> 54:37.080
Like emulating climate change.

54:37.080 --> 54:44.080
But also operate on time scales where the change of our behaviors not the implications of changing or maybe not obvious.

54:44.080 --> 54:45.080
Yeah.

54:45.080 --> 54:53.080
I just gave a good example I think that in coven at least we see it right now part of seeing it is we adapt in the wrong direction.

54:53.080 --> 54:55.080
Yes, earlier question.

54:55.080 --> 54:59.080
So climate's a problem because there's no feedback.

54:59.080 --> 55:14.080
Say, there's no learning will come no learning no learning rule happens and there's so much delay. There's so much delay. And what I've heard discussed here is how do what are the appropriate metaphors that we could start inculcating

55:14.080 --> 55:21.080
in people's minds that would help them understand delayed feedback. For example, gardening, gardening.

55:21.080 --> 55:24.080
Anyone who plants a garden.

55:24.080 --> 55:26.080
Right, and I'm very impatient.

55:26.080 --> 55:27.080
I'm not going to.

55:27.080 --> 55:35.080
But there are people who are very good at it. And they, you realize I'm going to do all this now but I'm not going to see the fruits of my labor for about three seasons.

55:36.080 --> 55:52.080
It's going to be really scrappy next year and then you know and so on. And I think there are things that humans do that have those longer time scales where we're willing to operate with delayed gratification right delayed right.

55:52.080 --> 56:06.080
It seems to be the case here and I think I don't have an answer but I suspect educating people to think about pandemics and things like them, the way they would think about gardening or something.

56:06.080 --> 56:15.080
Yeah, would be very powerful and but unfortunately we do the opposite because we say we're going to have an RNA vaccine in a month.

56:15.080 --> 56:27.080
Right. And so, whatever virtuous long term thinking started to mature is immediately obliterated by the experience of an instantaneous vaccine.

56:27.080 --> 56:36.080
I'm not blaming vaccine development that's fantastic but these things are actually kind of in competition in our minds.

56:36.080 --> 56:51.080
I love the idea of the metaphors and kind of metaphors we live by like the fruits of our labor really is built into that is a metaphor of delay. Yes, and and so if we had these sort of systems metaphors that we could, you know, raise

56:51.080 --> 57:05.080
children on. Yes, then when they get to adulthood they would they would sort of understand that cause and effect aren't always neighbors on a timeline and you just recursively use the metaphor by saying raising children.

57:05.080 --> 57:08.080
It's another.

57:08.080 --> 57:10.080
Exactly. That's right.

57:10.080 --> 57:26.080
Thank you so much David, I really appreciate the talk it's an amazing talk and amazing ideas and I wish we had many more hours to chat but thank you for for your, your talk and answering questions.

57:26.080 --> 57:33.080
Thank you very much everybody thank you Derek and Laura for inviting me and hope to see you some point at SFI virtually one person.

57:33.080 --> 57:36.080
Yes, much appreciated.

57:36.080 --> 57:38.080
Okay.

57:40.080 --> 57:42.080
Thank you.

