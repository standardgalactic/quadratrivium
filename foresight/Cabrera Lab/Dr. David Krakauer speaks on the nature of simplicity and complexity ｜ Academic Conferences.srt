1
00:00:00,000 --> 00:00:21,720
Our next speaker is quite an honor that he is here to speak to us, David Crackauer.

2
00:00:21,720 --> 00:00:28,400
He is an evolutionary biologist and the president and William H. Miller professor of complex

3
00:00:28,400 --> 00:00:32,400
systems at the Santa Fe Institute.

4
00:00:32,400 --> 00:00:37,000
He also co-directs the collective computation group at the Santa Fe Institute.

5
00:00:37,000 --> 00:00:43,200
And prior to all of that, David served as the founding director of the Wisconsin Institute

6
00:00:43,200 --> 00:00:48,200
for Discovery, as well as the co-director of the Center for Complexity and Collective

7
00:00:48,200 --> 00:00:55,920
Computation, and as a professor of mathematical genetics at the University of Wisconsin-Madison.

8
00:00:55,920 --> 00:00:59,000
That's only part of his introduction part of his resume.

9
00:00:59,000 --> 00:01:04,680
David has also held positions as a visiting fellow at the Genomics Frontiers Institute

10
00:01:04,680 --> 00:01:07,040
at the University of Pennsylvania.

11
00:01:07,040 --> 00:01:11,240
He's also been a sage fellow at the Sage Center for the Study of the Mind at the University

12
00:01:11,240 --> 00:01:17,880
of California, Santa Barbara, a long-term fellow of the Institute for Advanced Study

13
00:01:17,880 --> 00:01:23,880
in Princeton, and a visiting professor of evolution at Princeton University.

14
00:01:24,840 --> 00:01:31,480
And if that wasn't enough, in 2012, he was included in the Wired Magazine smart list

15
00:01:31,480 --> 00:01:36,080
as one of the 50 people who will change the world.

16
00:01:36,080 --> 00:01:37,960
And he's here with us today.

17
00:01:37,960 --> 00:01:43,280
So I am thrilled to have him join us today, and it is my absolute pleasure to introduce

18
00:01:43,280 --> 00:01:46,080
to you all, David Crackauer.

19
00:01:50,080 --> 00:01:51,080
Hello, everybody.

20
00:01:51,080 --> 00:01:52,080
Morning.

21
00:01:52,080 --> 00:01:53,080
Thank you very much.

22
00:01:53,280 --> 00:01:54,280
Can you all hear me?

23
00:01:54,280 --> 00:01:55,280
Great.

24
00:01:55,280 --> 00:01:57,680
Yeah, there's sort of little introduction to it.

25
00:01:57,680 --> 00:01:58,680
Who are they talking about?

26
00:01:58,680 --> 00:02:02,360
Who is this person that's not me that's being introduced?

27
00:02:02,360 --> 00:02:10,080
So I'm just going to jump right in to my slides to make sure this all works.

28
00:02:13,080 --> 00:02:16,080
And let's see.

29
00:02:16,080 --> 00:02:19,080
Is that all visible to you?

30
00:02:19,080 --> 00:02:20,080
Great.

31
00:02:20,080 --> 00:02:27,080
So I'm going to start, in some sense, anti-system, and then we're going to migrate towards system.

32
00:02:27,080 --> 00:02:30,080
This is a quote I rather love.

33
00:02:30,080 --> 00:02:36,080
This is a quote from Murray Gelman's 1969 Nobel acceptance speech.

34
00:02:36,080 --> 00:02:41,080
Murray is one of the founders of the Center Institute, as some of you will know.

35
00:02:41,080 --> 00:02:48,080
And he said, how can it be that writing down a few simple and elegant formulating like short

36
00:02:48,080 --> 00:02:54,080
poems governed by strict rules, such as those of the sonnet or the waka, can predict universal

37
00:02:54,080 --> 00:02:56,080
regularities of nature?

38
00:02:56,080 --> 00:03:01,080
The waka, by the way, is the ancestor of the haiku.

39
00:03:01,080 --> 00:03:04,080
It would be a little bit too pedestrian for Murray to say haiku.

40
00:03:04,080 --> 00:03:07,080
So he says waka instead.

41
00:03:07,080 --> 00:03:14,080
And this comes out of the work that Murray had done that won him the Nobel Prize on recognizing

42
00:03:14,080 --> 00:03:16,080
fundamental symmetries in nature.

43
00:03:16,080 --> 00:03:23,080
And he wrote down what's become famous as the so-called eightfold way, which is the symmetry

44
00:03:23,080 --> 00:03:27,080
group of the hadrons, which are fundamental particles.

45
00:03:27,080 --> 00:03:33,080
And it's an extraordinary achievement because you write down this, what seems like an invention

46
00:03:33,080 --> 00:03:39,080
of the human mind, that is the Lie algebra for the special unitary group three.

47
00:03:39,080 --> 00:03:48,080
And out of that pops a prediction of a hidden facet of reality, a subatomic particle.

48
00:03:48,080 --> 00:03:52,080
And this is the great mystery, if you like, of applied mathematics.

49
00:03:52,080 --> 00:03:54,080
So that's that Murray.

50
00:03:54,080 --> 00:03:59,080
But there's another Murray that was associated with the founding of the San Dufan students, the Murray who

51
00:03:59,080 --> 00:04:04,080
asked this question, which was, think how hard physics would be if particles could think.

52
00:04:04,080 --> 00:04:09,080
Now this is in some sense the rallying cry for complexity science.

53
00:04:09,080 --> 00:04:16,080
It says, instead of a world dominated by conservation laws, conservation of energy and matter and fundamental

54
00:04:16,080 --> 00:04:26,080
symmetries, it's a world dominated by agency, self awareness, consciousness, reflexivity, system

55
00:04:26,080 --> 00:04:29,080
to, you know, you pick your favorite phrase.

56
00:04:29,080 --> 00:04:36,080
How do you understand those kinds of worlds where the system itself is learning and adapting,

57
00:04:36,080 --> 00:04:45,080
responding to your observations in such a way as to stifle stymie your future efforts to predict them.

58
00:04:45,080 --> 00:04:53,080
And that led quite naturally to this remark, which I think would resonate with everyone at this meeting, where he

59
00:04:53,080 --> 00:05:01,080
essentially makes the point that the complexity of connections in the modern world is so dense.

60
00:05:01,080 --> 00:05:11,080
That there's a real argument for studying some emergent system, which he calls the whole system, rather

61
00:05:11,080 --> 00:05:19,080
than pursue that disciplinary convenience of dissecting the world into its individual components of the

62
00:05:19,080 --> 00:05:27,080
system that Murray had worked on as a physicist. And I've often wondered what Murray meant when he said whole system.

63
00:05:27,080 --> 00:05:35,080
That's been confusing to me. It's almost as if what Murray did is he started as a reductionist physicist, working on the

64
00:05:35,080 --> 00:05:41,080
atoms and quarks and gluons and took some kind of long jump by helping to construct the Santa Fe

65
00:05:41,080 --> 00:05:46,080
Institute and landing on the whole system, which is the planetary system itself.

66
00:05:46,080 --> 00:05:55,080
And I think this is a significant challenge. And I think what Murray actually meant was looking at that point, if you like, of

67
00:05:55,080 --> 00:06:04,080
highest elevation, where we're not studying the whole system, I think that's actually arguably impossible, but we're studying the systems of the world.

68
00:06:04,080 --> 00:06:10,080
And I want to argue throughout this presentation that the systems of the world should be thought of as verbs, not nouns.

69
00:06:10,080 --> 00:06:19,080
I mean, when I go to meetings, people will say we should study the energy sector, or the communication sector or the global banking system.

70
00:06:19,080 --> 00:06:30,080
These to me are objects and artifacts, as opposed to studying processes that actually transcend any given one of those systems, if you like, and that's what I'll argue for, not

71
00:06:30,080 --> 00:06:39,080
to say that you can't do the former, that would be perfectly reasonable and fascinating, but I'm more interested in the generalities that span them.

72
00:06:39,080 --> 00:06:52,080
And so this will be essentially at the table of my talk in a nutshell, and we're going to dive into some of the details because I think the interest of this approach to working on systems lives in the detailed way in which we

73
00:06:52,080 --> 00:07:02,080
analyze them. And so for example, conflict, it's obviously all of these topics I imagine are of great interest today in the world.

74
00:07:02,080 --> 00:07:12,080
And when we understand conflict, both at the individual level, right, that is individual fights, if you like, all the way through to wars at the level of nation states.

75
00:07:12,080 --> 00:07:23,080
Is it meaningful, for example, to describe them both as conflict, or is that just a sort of historical accident that we use the same word to describe events at different scales.

76
00:07:23,080 --> 00:07:33,080
And I'm going to argue that the only sense in which it's meaningful is if you can find the mechanics, or the models that are constitutive of the process.

77
00:07:33,080 --> 00:07:43,080
Right, and demonstrate that that actually yes they are because what we mean in both cases is a certain notion of criticality and I'm going to jump into that in a second.

78
00:07:43,080 --> 00:07:48,080
Another one, culture, how does culture actually work.

79
00:07:48,080 --> 00:07:56,080
You know where where suspended ammently in a world of beliefs and ideas. How do we acquire them, how do we transmit them.

80
00:07:56,080 --> 00:08:08,080
And that this notion of culture is very diffuse, right, so we go from the culture of individual beliefs and norms, all the way through to, you know, enforceable legal systems.

81
00:08:08,080 --> 00:08:22,080
And again, is that real. I mean are we correct in asserting that these are elements of culture. And I think the answer is yes, because in each case we're talking about attitudes towards imitation transmission.

82
00:08:22,080 --> 00:08:27,080
If you like the sort of essential modules or atoms of cultural evolution and so forth.

83
00:08:27,080 --> 00:08:34,080
Again what is constitutive of that notion of culture, and I'm going to focus there on on the evolution of constitutions.

84
00:08:34,080 --> 00:08:40,080
And finally, revolutions, social revolution, scientific revolutions.

85
00:08:40,080 --> 00:08:45,080
Why do some institutions emerge and then freeze.

86
00:08:45,080 --> 00:08:57,080
And there are extraordinarily difficult to change, whereas others seem to be in flux all the time. Can we come to some fundamental understanding about why that's true.

87
00:08:57,080 --> 00:09:10,080
And here I think the answer is yes we can we have to think about structures and orders that have multiple timescales and the way learning rules percolate through those timescales.

88
00:09:10,080 --> 00:09:17,080
So as to either engender fixity stasis, or evolution and change.

89
00:09:17,080 --> 00:09:25,080
So that'll be the sort of that sort of the talk, and I'm going to jump into empirical case studies with mathematical models.

90
00:09:25,080 --> 00:09:29,080
Don't worry too much if it all looks a bit heady.

91
00:09:29,080 --> 00:09:38,080
Just to say that I think that you do this to study says you have to do this in other words, with the essentials of the scientific method.

92
00:09:38,080 --> 00:09:51,080
So let's start with a little data model building an experiment, and no less important here than they would be in a disciplinary pursuit. It's just that we're doing something rather differently.

93
00:09:51,080 --> 00:09:56,080
So let's start with this conflict to contain an issue.

94
00:09:56,080 --> 00:10:14,080
This is not criticality first this is a plot that you will have all seen if you're watching the news at any point in the last three years, which is sort of flatten the curve right so this is a series of projected epidemic profiles for of coven for example,

95
00:10:14,080 --> 00:10:20,080
and critical exponents are zero, or are not in England.

96
00:10:20,080 --> 00:10:30,080
This is that thing which we've all become familiar with, which is the number of secondary infections initiated by a primary infection certain that little picture on the top right.

97
00:10:30,080 --> 00:10:39,080
You can see that if our north or zero is five, then a single initial infection will lead to five secondary infections and so on.

98
00:10:39,080 --> 00:10:47,080
So this is that as you move the critical exponent are zero closer to one, we flatten the curve.

99
00:10:47,080 --> 00:11:05,080
And if our zero is below one, the epidemic would peter out. So this is what's meant by contagion is propagation of infection, and it's also was meant by a critical exponent, which is this threshold value magic value, below which an infection is

100
00:11:05,080 --> 00:11:10,080
and above which it's super critical. Okay.

101
00:11:10,080 --> 00:11:16,080
Many people have claimed in the literature that conflict is something like a contagion.

102
00:11:16,080 --> 00:11:33,080
It spreads from one person to another through a mechanic which is somewhat dissimilar I imagine what we know to an infectious disease, and moreover it shows critical phenomena that is that there is some threshold value of aggression.

103
00:11:33,080 --> 00:11:41,080
Or adversarial interaction, above which conflict becomes super critical, and below which it would be so critical.

104
00:11:41,080 --> 00:11:48,080
And the idea I guess at the Pacific dream would be to get those critical exponents below one.

105
00:11:48,080 --> 00:11:51,080
So it's to move into subcritical regimes.

106
00:11:51,080 --> 00:11:55,080
Is any of this true is a huge literature.

107
00:11:55,080 --> 00:12:00,080
Well, to answer that question if you look at the data and we have to build mathematical models.

108
00:12:00,080 --> 00:12:06,080
And answer this question of whether or not conflict really is a contagion or not.

109
00:12:06,080 --> 00:12:13,080
So here's the kind of basic questions we might want to ask ourselves, is it true. Does it have a critical transition.

110
00:12:13,080 --> 00:12:22,080
Is there a relationship, for example between the conflict duration the number of fatalities, the, the geographical area that it encompasses.

111
00:12:22,080 --> 00:12:33,080
And if that's all true. What are the normative implications that is, we're not just doing descriptive natural history of conflict we want to intervene in such a way as to minimize it.

112
00:12:33,080 --> 00:12:42,080
The way of for example a physician might make recommendations for mass wearing, so as to minimize the spread of a pandemic.

113
00:12:42,080 --> 00:12:46,080
So that's one of the sorts of questions.

114
00:12:46,080 --> 00:12:50,080
So, in order to answer that now.

115
00:12:50,080 --> 00:12:53,080
I wonder if I can see you can see this.

116
00:12:53,080 --> 00:13:00,080
Is anything blocked here by the way Laura or can you see the whole screen that my own so good.

117
00:13:00,080 --> 00:13:02,080
We can see the whole screen. Oh great great great.

118
00:13:02,080 --> 00:13:11,080
So, um, so the way we do this is we look at two kinds of systems. We look at experimental systems non human systems that we can intervene into.

119
00:13:11,080 --> 00:13:17,080
And so these are small populations, every individual can be monitored.

120
00:13:17,080 --> 00:13:23,080
And we're looking at the individual conflict rules that individuals are following. So very micro.

121
00:13:23,080 --> 00:13:34,080
On the other hand we have large scale observational data of human populations, very macro. And in that case we're inferring quite different kinds of scaling relations not individual decision rules.

122
00:13:34,080 --> 00:13:40,080
So, I just want to make that point about model systems versus observational systems.

123
00:13:40,080 --> 00:13:48,080
It leads to a lot of heated debate I think one should look at both because they each have strengths and weaknesses.

124
00:13:48,080 --> 00:13:55,080
So, let me just give you one example this is something we've been studying for many years non human primates macaques by the monkeys and so on.

125
00:13:55,080 --> 00:14:06,080
And here, just to give you a sense we can look at any given moment in time. These are animals in captivity at who is fighting or not fighting at any given point in time so very micro.

126
00:14:06,080 --> 00:14:13,080
We can see who interacts with whom we can reconstruct social networks of their interactions and so on.

127
00:14:13,080 --> 00:14:15,080
And out of that kind of data.

128
00:14:15,080 --> 00:14:25,080
So, let me give you some of those sorts of interesting insights but let me give you one example. This is the scaling of the log log axes of the conflict duration and conflict size.

129
00:14:25,080 --> 00:14:43,080
Just notice that as the number of individuals in a particular conflict increases, so does the duration of the conflict, and it increases polynomially in increases as the square of the number of individuals.

130
00:14:43,080 --> 00:14:53,080
The variance, not just the mean. So this is the distribution of how long peace bouts last so for example, no one's fighting anyone.

131
00:14:53,080 --> 00:15:07,080
10 seconds 10 minutes an hour and so on, and conflict durations and you'll notice that if you look at the distribution of durations, as they get longer the variance increases, so the scatter around that distribution increases.

132
00:15:07,080 --> 00:15:24,080
So here's just some data. What one can now do is write down a whole family don't worry about the details of mathematical models and explore the full configuration space of possible contagion processes, not just one or two but a very large number, and ask which ones of those

133
00:15:24,080 --> 00:15:34,080
mathematical models are consistent with the scaling relationships, for example the one observed in the data, the scaling of the mean and the scaling of variance.

134
00:15:34,080 --> 00:15:53,080
But most contagion process actually can't recover the observed data and this is quite important, because in many studies people will assert contagion without checking carefully against the empirical data, which would either refute or confirm transiently the hypothesis.

135
00:15:53,080 --> 00:16:15,080
And what we find just is, is a critical role of agency. It is a contagion process, but with one really interesting characteristic, which is long term memory, that is, the memory of the first conflict, and its duration is felt throughout all subsequent conflicts, that is not a

136
00:16:16,080 --> 00:16:30,080
property of a mathematical, of a biological epidemic. There's a very different kind of contagion, it's contagion with significant memory in it, which is that sort of agency fact that self awareness fact and we all know that and resentments are very long lasting.

137
00:16:30,080 --> 00:16:42,080
So an attempt, for example, to intervene on a human conflict contagion as if it were a biological contagion, without taking into account the sort of psychological fact of memory would fail.

138
00:16:42,080 --> 00:16:45,080
So that's just one example.

139
00:16:45,080 --> 00:16:53,080
We've also looked, as I said, at the more core screen data, we've looked, this is the so-called ACLED database, extraordinarily rich.

140
00:16:53,080 --> 00:17:02,080
And we've been studying conflicts in continental Africa for two decades, looking at things that are very similar actually to the micro data I just showed you.

141
00:17:02,080 --> 00:17:17,080
And here you don't have who's fighting whom at a given point in time, but what you do have is data like this where over the course of time you have battles, the number of fatalities, exact geographical locations and so forth.

142
00:17:17,080 --> 00:17:24,080
So we can study time and space, but at a much more low resolution than we would in the experimental system.

143
00:17:24,080 --> 00:17:36,080
And as with the experimental system, we can look at things like the distribution of conflict sizes, the distribution of fatalities, duration and spatial extent.

144
00:17:36,080 --> 00:17:53,080
And as with micro data, we can write down mathematical models as a rather complicated model and maybe describe this one in any detail, but just the idea that contagions grow as a kind of a fractal like branching pattern on a two dimensional surface.

145
00:17:53,080 --> 00:18:09,080
And one of the things that these models predict is that at critical points, like for example R zero equals one, that is that critical point below which an epidemic is subcritical above which it's supercritical.

146
00:18:09,080 --> 00:18:22,080
Something really interesting happens, you get a complete collapse of complexity, and all of those scaling exponents become related. It's actually a really beautiful feature of complex systems that at critical points they become simple.

147
00:18:23,080 --> 00:18:32,080
And for those who are interested in the form of analysis, this is using something called renormalization group theory. It's a way of looking across scales.

148
00:18:32,080 --> 00:18:45,080
And you can see, and just take my word for it if you like, that if you look at the ratios and empirical data against the model predictions they're extraordinarily close, which suggests two things again.

149
00:18:45,080 --> 00:18:56,080
And yes, this is a contagion like phenomenon so that's a correct statement, but it's also a contagion like process that's near criticality.

150
00:18:56,080 --> 00:18:59,080
And this is very surprising.

151
00:18:59,080 --> 00:19:02,080
Because it's not clear why that should be the case.

152
00:19:02,080 --> 00:19:06,080
So if you think about an epidemic with R zero.

153
00:19:07,080 --> 00:19:23,080
Why would it live by a critical point, and we all know the answer actually because we're observing it today. And that is that if are not zero I never quite know I've sort of been in the United States long enough to want to say zero but my answer my early life was in England so

154
00:19:23,080 --> 00:19:38,080
not so I'm going to be at the critical point where I say both. And if you think about it, when the epidemic is in full blast, we start taking precautions. We wear masks we get vaccinated we get boosted.

155
00:19:38,080 --> 00:19:41,080
We shift our zero down.

156
00:19:41,080 --> 00:19:44,080
But when our zero falls below one.

157
00:19:44,080 --> 00:19:49,080
The epidemic starts petering out and what happens we take off our masks.

158
00:19:49,080 --> 00:20:01,080
We take off our masks because we think oh look, we've won. And then what happens the new strain emerges and it probably gets back in. We put our mask back on, and this is one of the so called roots to endomism.

159
00:20:01,080 --> 00:20:15,080
And that phenomenon of a system hovering around the critical point is called self organized criticality. And it seems as if conflict is manifesting this phenomenon of hovering by a critical point.

160
00:20:15,080 --> 00:20:27,080
In many cases, yes, with a strong agency memory effect. Does it have a critical transition yes but we don't know exactly where it is we don't know the r zero of human conflict.

161
00:20:27,080 --> 00:20:37,080
You get this incredibly interesting simplification of the system of conflict at the critical point with all the scaling exponents become related.

162
00:20:37,080 --> 00:20:46,080
And the normative implications for us are deliberative techniques to move systems away from critical points.

163
00:20:46,080 --> 00:20:56,080
And that's the whole era of investigation we've pursued and perhaps we in questions we can deal with it, but if you look at my website there's some things on that there.

164
00:20:56,080 --> 00:21:01,080
So that's just one example. Let's keep jumping to the culture.

165
00:21:01,080 --> 00:21:15,080
How on earth should we model culture. And this is, again, my view is you have to take a representative model system where good data is available, and you could look at Twitter.

166
00:21:15,080 --> 00:21:24,080
You could look at newspapers. It almost doesn't matter, as long as you're rigorous and, you know, consistent in the way you do this.

167
00:21:24,080 --> 00:21:35,080
So we've been looking at constitutional history. And so this is a very famous painting is painted in 1740. It relates to the signing of the Constitution American Constitution 1789.

168
00:21:35,080 --> 00:21:41,080
And you can see in that picture I'm sure a few familiar faces.

169
00:21:41,080 --> 00:21:50,080
And what we do, working with constitutional historians and lawyers is we take a constitution and we atomize it.

170
00:21:50,080 --> 00:22:01,080
We break it down into its essential themes. And for those interested in machine learning, or natural language analysis, these atoms are called topics.

171
00:22:01,080 --> 00:22:13,080
So for example, oops, these are my questions. Let's just skip them we'll come back to them. So here's a constitution we're going to break it up into its basic lexical atoms.

172
00:22:13,080 --> 00:22:26,080
The way it treats general rights, the way it treats sovereignty public order. And we're going to ask how do these themes diffuse forward in time through constitutions.

173
00:22:26,080 --> 00:22:34,080
The way that constitutions are written is you don't sit down in a room and write one for your nation de novo out of nowhere.

174
00:22:34,080 --> 00:22:36,080
Ex Ovo.

175
00:22:36,080 --> 00:22:41,080
You look at prior constitutions and you borrow from them.

176
00:22:41,080 --> 00:22:49,080
But what you can do, mathematically is reconstruct the phylogenetic tree of all constitutions that have ever been written.

177
00:22:49,080 --> 00:22:55,080
And if we zoom in on this you can see, here's the Constitution of Egypt of 1923.

178
00:22:55,080 --> 00:23:01,080
It was highly influential on the room D62 albania 25 it was slightly 31 year old 1925.

179
00:23:01,080 --> 00:23:05,080
These are obviously a reading chronological order.

180
00:23:05,080 --> 00:23:12,080
What's going on here, which topics are circulating how is borrowing taking place and why.

181
00:23:12,080 --> 00:23:17,080
What's the impact of local culture and geography.

182
00:23:17,080 --> 00:23:23,080
I'm going to skip all that for today, but just give you a sort of sense of what you can say in this kind of structure.

183
00:23:23,080 --> 00:23:28,080
We can sort of leap in and look at the micro geometry of that tree.

184
00:23:28,080 --> 00:23:33,080
What you're looking at here if you look at the center, you have the focal constitution of interest.

185
00:23:33,080 --> 00:23:45,080
It has a number of parents that it borrowed from that we've inferred using some techniques, and a number of offspring that it influenced that borrowed from it.

186
00:23:45,080 --> 00:24:02,080
And we can reconstruct this kind of zoo of geometries of all the constitutions all of these are essentially that structure on the left but giving you a sense of the diversity of constitutional forms that we can reconstruct going back to 1789.

187
00:24:03,080 --> 00:24:14,080
And these actually correspond to particular constitutions you can look at the bottom one that's the Constitution of Montenegro had three parents no offspring.

188
00:24:14,080 --> 00:24:16,080
Right.

189
00:24:16,080 --> 00:24:21,080
The interesting one is the South Korean Constitution of 1948.

190
00:24:21,080 --> 00:24:31,080
That's that one sort of third from the bottom. It has a small number of parents but a lot of offspring. That's a very influential constitution.

191
00:24:31,080 --> 00:24:46,080
And so we can start asking, which constitutions are highly inventive which ones had disproportional impact, which ones are sterile, actually never led to offspring, and so on.

192
00:24:46,080 --> 00:24:59,080
And so complicated plot, but what if you look at the lifespan of a constitution, the lifespan is defined as when it was written, and when it start it stopped being borrowed from.

193
00:24:59,080 --> 00:25:13,080
And so no one looks at it anymore. The US Constitution is very interesting. It was very influential early, but it was so influential on secondary constitutions that they borrowed from those instead of the founding constitution.

194
00:25:13,080 --> 00:25:24,080
And top left you see a tree of all the constitutions you see three clear epochs founding 1789 up until the Second World War.

195
00:25:24,080 --> 00:25:33,080
And so you get rid of a relatively slow rate of constitution writing, and all the constitutions are very long lived.

196
00:25:33,080 --> 00:25:41,080
Then during the war subsequent you get an acceleration of the production of constitutions, most of which are very short lived.

197
00:25:41,080 --> 00:25:44,080
So quite distinct cultural phases.

198
00:25:44,080 --> 00:25:58,080
And so we can go into this particular object, which seems to think what are constitutions they established branches of government, the separation of powers, property rights, issues about freedom of expression.

199
00:25:58,080 --> 00:26:06,080
These are in some sense the operating systems of societies, and they have a very interesting dynamic.

200
00:26:06,080 --> 00:26:22,080
So you can then answer these questions. How is cultural transmitted cultures transmitted a little bit like genetics. It's not genes, it's core constellations of concepts like rights property rights structures of government.

201
00:26:22,080 --> 00:26:27,080
Which ideas are most influential and constitutions strong early mover advantage.

202
00:26:28,080 --> 00:26:44,080
Quite unequivocally that if you're early, early in the, the writing of the constitution, you will be an influential one. It almost doesn't matter what you write about, because you become a source of influence on subsequent constitutional authors.

203
00:26:44,080 --> 00:26:53,080
This is a preferential attachment dynamic that many of you will be familiar with it happens for example, Uber happened to eBay having Etsy.

204
00:26:54,080 --> 00:27:12,080
Being their first and becoming the preferred markets for ideas is a long lasting effect. And it's no less true for these ancient cultural forms and it is for contemporary technological forms, even though many have claimed the dynamics of software

205
00:27:12,080 --> 00:27:23,080
that is different. It actually isn't you. It seems to be a more universal dynamic of culture than a particular mechanic of the contemporary world.

206
00:27:23,080 --> 00:27:41,080
And this really interesting point that it's better to be revolutionary than evolutionary if you're writing constitutions. That is, the highly inventive constitutions that that add new topics if you like new categories of thought are the ones that people look

207
00:27:41,080 --> 00:27:54,080
at, not the ones that add one or two increments and what came before them so be first and be radical is the sort of if you like the message of constitutional history.

208
00:27:54,080 --> 00:28:05,080
Finally, revolutions like everyone else I'm interested in revolutions, particularly scientific revolutions, but during the last few years social revolutions.

209
00:28:05,080 --> 00:28:11,080
The whole black lives matter protesters of great interest to me personally.

210
00:28:11,080 --> 00:28:22,080
And how can we understand what's going on here, why, why do society seem to go through periods of stasis, and then these incredibly rapid bursts of change.

211
00:28:22,080 --> 00:28:29,080
Is there a sort of unifying framework for evolution and revolution in social systems.

212
00:28:29,080 --> 00:28:38,080
The kinds of things I'm interested in things like this, you know, why do we go from extraordinary intolerance of homosexuality to accepting it.

213
00:28:38,080 --> 00:28:47,080
Going so far as to allow for gay marriage, which to me is a real fantastic evolutionary move of society. What changed in people's thinking.

214
00:28:47,080 --> 00:28:55,080
By the way, there's a nice typo here this is Oscar Wilde 1985, which is not quite right.

215
00:28:55,080 --> 00:29:03,080
So, this, you know, attitudes for this is for the fiction on the left, anyone is rock history realize the two very different people.

216
00:29:03,080 --> 00:29:10,080
But this sort of scare tactics that people have used to sort of discourage people from taking recreational drugs and maybe they're right maybe they're wrong.

217
00:29:10,080 --> 00:29:16,080
But then the shift towards a much more permissive society.

218
00:29:16,080 --> 00:29:23,080
And political beliefs, I mean, endlessly oscillating back and forth between political parties.

219
00:29:23,080 --> 00:29:31,080
Can we sort of wrap this system up in a common mathematical framework so that we can understand properties of all of them.

220
00:29:31,080 --> 00:29:45,080
And as I said I think the answer is yes, because they're all characterized by having multiple time scales with individual learning rules that percolate up through the time scales, often in invisible ways, leading to very dramatic shifts.

221
00:29:45,080 --> 00:29:57,080
The kind of data that we look at to see if your senses is it like this, all across the board. Why, for example, did seat belts once they're adept adopted lock.

222
00:29:57,080 --> 00:30:07,080
It's very unlikely that we're going to move back to a state where people say you know, let's get rid of the mandatory seat belt law. It seems like a bad idea.

223
00:30:07,080 --> 00:30:17,080
Whereas political parties, fortunes are constantly shifting attitudes towards the death penalty are constantly shifting and so on.

224
00:30:17,080 --> 00:30:25,080
I mean, it would be kind of nice right if attitudes towards same sex marriage or the death penalty look more like the seat belt in a progressive sense.

225
00:30:25,080 --> 00:30:31,080
And once we'd adopted them we stayed that way and didn't constantly fluctuate that can we understand one of this.

226
00:30:32,080 --> 00:30:43,080
And so these are the kinds of questions we're asking here. How did these systems evolve. How do we as individuals, or as collectors contribute to these institutions.

227
00:30:43,080 --> 00:30:52,080
So I use this word institution by the way to mean scientific belief systems or organizations companies could be IBM.

228
00:30:52,080 --> 00:31:01,080
How do individual micro learning rules percolate through to the emergent structure of the, of the macro properties of the institution.

229
00:31:01,080 --> 00:31:12,080
And what does an institution do that wants to change, but finds itself like the seat belt locked in.

230
00:31:12,080 --> 00:31:18,080
You know, can we are their normative implications just as they're worth a conflict.

231
00:31:18,080 --> 00:31:25,080
So this is the basic structure of these models, you have collectives at the bottom.

232
00:31:25,080 --> 00:31:33,080
They express their support or position to an institution through voting mechanics.

233
00:31:33,080 --> 00:31:59,080
And we think of the institutions as a ledger that records in its entries, votes, aggregates preferences and beliefs, and it has a public position, and that public position feeds back to reinforce or inhibit the collectives that are

234
00:31:59,080 --> 00:32:11,080
going to support or inhibit them in other words, members of a Republican Party will support their own party, but they will do everything their power to oppose the Democratic Party and Democratic beliefs and vice versa.

235
00:32:11,080 --> 00:32:22,080
So, the same kind of logic applies by the way to scientific revolutions here's the so called Copernican Revolution, you have Copernicus saying you know, you know everybody.

236
00:32:23,080 --> 00:32:34,080
It's kind of a possibility thing, but you've got the church saying well no it's kind of a little bit at odds with what we've been saying for the last however many thousand years, we'd rather you shut up.

237
00:32:34,080 --> 00:32:48,080
And so again that sort of dynamic of voting opposition and support with feedback from the institutions because that's crucial right because if the institution helps you, you gain power.

238
00:32:48,080 --> 00:32:52,080
So you can take that and mathematics it.

239
00:32:52,080 --> 00:33:02,080
For those of you with keen eyes you'll see this looks like a perceptron it's a very simple neural network, but it's all analytical doesn't matter.

240
00:33:02,080 --> 00:33:16,080
Mathematize it and explore. This is going to be the technical point and it's coming to the end which I would sort of get your heads around the crucial role of learning rules, which are the rules that reinforce your beliefs and support or

241
00:33:17,080 --> 00:33:30,080
based on the success of your corresponding institution. So let me just show you what I mean. So here's a case. Let's say X supports IX and Y supports IY the institution Y.

242
00:33:30,080 --> 00:33:44,080
One learning will be to say look, if there's lots of us, lots of X's, let's say supporters of the Copernican Revolution, we're going to support Copernicus and all publications that promulgate a heliocentric position.

243
00:33:44,080 --> 00:33:57,080
But if you're a member of, let's say the time, a religious fraternity or church, if you're more numerous you'll support your institutions in that case they say the Catholic Church.

244
00:33:57,080 --> 00:34:02,080
That's one kind of rule it says you learn in accordance with your success.

245
00:34:02,080 --> 00:34:14,080
That kind of rule is quite opposite to that is that actually I might just attend if I'm being successful, why bother? Why bother doing more work? I've already won.

246
00:34:14,080 --> 00:34:20,080
I'm going to divest from supporting my institution because I'm in the leading position.

247
00:34:20,080 --> 00:34:29,080
Here's an interesting one, an arms race. An arms race says, I'm going to support my institution in proportion to the success of my rival.

248
00:34:29,080 --> 00:34:43,080
So think about nuclear expansion. If your opponent doesn't have weapons then why should you? So your support of your institution is in proportion to your competitors' abundance.

249
00:34:43,080 --> 00:34:56,080
So you can write down all these simple rules which tell you how to construct institutions according to their abundance if you like or power or size.

250
00:34:56,080 --> 00:35:01,080
And on and on you can go and you can actually mathematically look at all possible permutations.

251
00:35:01,080 --> 00:35:15,080
And if you do that you make some interesting discoveries. If you use, for example, this rule which says invest in your institution in proportion to its size, you get lock-in.

252
00:35:16,080 --> 00:35:25,080
You're going to fix on a single institution and never change it. And you can sort of see intuitively why that's the case because you're not attending to the competitor at all.

253
00:35:25,080 --> 00:35:31,080
And the bigger you get and the bigger your institution becomes the more you support it, lock-in.

254
00:35:31,080 --> 00:35:40,080
The same is true with the other rules. The arms race is the opposite, right? It says, I support my institution in proportion to the competitor.

255
00:35:40,080 --> 00:35:46,080
And that leads to endless cycling periodicity.

256
00:35:46,080 --> 00:36:05,080
So what this sort of work is showing is that the incentive system that society puts in place, that is the reinforcement learning rule, has strong emerging consequences on the stasis or the ability of the corresponding institution.

257
00:36:05,080 --> 00:36:17,080
And that suggests that you could change them. So for example, let's say you were in a lock-in situation and you're a company like Kodak and you say, well, look, we make the best film in the world, we should make more of it.

258
00:36:17,080 --> 00:36:21,080
And then all of a sudden the market changes and you're extinct.

259
00:36:21,080 --> 00:36:36,080
So you could, as a leadership team say, I'm going to create a new learning rule amongst my employees that instead of investing in proportion to our market share, we're going to look at the competitor,

260
00:36:36,080 --> 00:36:42,080
change the norms, change the incentives, and move into an oscillatory regime where you allow for the possibility of flexibility.

261
00:36:42,080 --> 00:36:50,080
So this is just an example of these very counterintuitive ways in which local incentive learning systems have emergent properties at the institutional level.

262
00:36:50,080 --> 00:36:57,080
And I just wanted to make that point. That rule there is an institutional black hole. This is Kodak, this is research in motion.

263
00:36:57,080 --> 00:37:00,080
Follow these rules, stasis.

264
00:37:00,080 --> 00:37:10,080
So okay, so how do institution evolves in this particular case feedback from institutions that are established through some collective voting dynamic.

265
00:37:10,080 --> 00:37:16,080
How do you construct, use different learning rules to do so?

266
00:37:16,080 --> 00:37:28,080
So these rules in a very non-intuitive way, bias, the stability of the institutions, and how do you change, you have to change the learning rule.

267
00:37:28,080 --> 00:37:32,080
You have to, that's the key and that's very hard.

268
00:37:32,080 --> 00:37:41,080
So let's just end with this Murray statement, Murray making that point that we're living in this highly connected world, someone should be studying the whole system.

269
00:37:41,080 --> 00:37:56,080
And I think that the correct interpretation of that kind of insight is that we should be studying global representative systems that have a mechanic that is constitutive of that system.

270
00:37:56,080 --> 00:38:09,080
We should be studying culture, conflict, institutions, cities, pandemics. These are the kinds of processes where we have a principal means of attaching to them, mechanics and dynamics.

271
00:38:09,080 --> 00:38:12,080
And I have absolutely no idea it's a spaghetti.

272
00:38:12,080 --> 00:38:24,080
And you'll note that these are disciplines, they span them, but they're as disciplined as the disciplines, which is the sort of mantra that I try my best to follow.

273
00:38:25,080 --> 00:38:30,080
For those interested in SFI, go to our webpage.

274
00:38:30,080 --> 00:38:40,080
If you scroll down to the bottom of the Santa Fe Institute webpage, you can subscribe to our publications, you can join our podcast.

275
00:38:40,080 --> 00:38:48,080
There's all sorts of information available there for you that you will either hate or love, according to a disposition, but it's worth having a look because there's a lot of material.

276
00:38:48,080 --> 00:38:56,080
And with that, I'll wrap up. Thank you very much.

277
00:38:56,080 --> 00:38:59,080
Thanks, David.

278
00:38:59,080 --> 00:39:01,080
That was fantastic.

279
00:39:01,080 --> 00:39:06,080
Just, we need a whole day on this.

280
00:39:06,080 --> 00:39:08,080
Fantastic.

281
00:39:08,080 --> 00:39:16,080
And I do encourage everybody to go to SFI and check out what they're doing. It's a very special place. You still do tea, David.

282
00:39:16,080 --> 00:39:19,080
We do tea.

283
00:39:19,080 --> 00:39:27,080
Tea was sort of the most amazing thing where you get to meet these just people from all over and talk a little bit about tea.

284
00:39:27,080 --> 00:39:37,080
Well, it's interesting, you know, I mean, this is, we've all been debating this move towards this world, right, this online world, which has extraordinary like this.

285
00:39:37,080 --> 00:39:40,080
Yes, I mean, you can do this thing, which is fantastic.

286
00:39:40,080 --> 00:39:57,080
But what is missed and I think the obvious point is that this is very telegraphic, right? In other words, I just waffled on for 30 minutes, but we'll have questions for 15 and most people won't have a chance to ask, you know, it's whereas if you're in person, someone can really

287
00:39:57,080 --> 00:40:00,080
really pester you.

288
00:40:00,080 --> 00:40:12,080
And it's great. But also you can move back and forth, you know, clarifying what people mean, because it's very often takes two or three questions to sort of get to, oh, that's your sense.

289
00:40:12,080 --> 00:40:22,080
That's what you mean. I sorry I misunderstood you. And so tea is our sort of mechanic for doing just that we pretend it's this informal thing which it is.

290
00:40:22,080 --> 00:40:30,080
And really is it's recognized in the complexity of human interactions, and that it takes time to understand each other.

291
00:40:30,080 --> 00:40:33,080
So I don't, that's what she's for.

292
00:40:33,080 --> 00:40:50,080
So at SFI they have a courtyard and people just have tea and, you know, all, all manner of conversations are sparked at tea and you could have a physicist and a sociologist and a mathematician and a, you know, all kinds of different

293
00:40:50,080 --> 00:40:54,080
people talking about an issue it's fantastic.

294
00:40:54,080 --> 00:41:07,080
But one thing to say that I'd like to point out I didn't talk about SFI and its structure, but to do the kind of work that I just described as a tiny slither of work it happens to you work that I've been involved with I could have talked about other people's work.

295
00:41:07,080 --> 00:41:10,080
You need a different kind of organization.

296
00:41:10,080 --> 00:41:15,080
And so we don't have obviously departments, we don't have deans, we don't have that stuff.

297
00:41:15,080 --> 00:41:29,080
So we, and in offices which are typically shared you'll have an archaeologist with quantum mechanist right and by the end of the summer they're working on a problem together, because they like each other.

298
00:41:29,080 --> 00:41:39,080
I mean it's sort of simple as that. And so the structure of respects I think the mission in terms of what we want to accomplish.

299
00:41:39,080 --> 00:41:44,080
So I'm curious, you started with the one of Murray's quotes.

300
00:41:44,080 --> 00:41:51,080
Think of how difficult physics would be if Adams could think is a fantastic concept.

301
00:41:51,080 --> 00:42:06,080
And Murray Gellman also wrote a very short paper called, let's call it Plectix which really got at the root definition and root word forms of simple and complex.

302
00:42:06,080 --> 00:42:12,080
Can you talk a little bit about that relationship between simplicity and complexity and why that's important.

303
00:42:12,080 --> 00:42:18,080
Yeah, I have lots of slides on it I didn't want to do this because there's so many times, but I will do it verbally.

304
00:42:18,080 --> 00:42:34,080
So one way to think about this is that where have the, because we are a quantitative department I don't think you need to be to work in systems or complexity quite frankly think philosophers do it very well only natural language, but we could do it that way.

305
00:42:35,080 --> 00:42:52,080
One way to say this is that, you know, physics has been so successful the kind of Murray worked on that I illustrated, because it's so simple meaning there are laws like conservation matter of energy matter and so forth the second or so.

306
00:42:52,080 --> 00:42:57,080
Fundamental symmetries, and that's what mathematics likes.

307
00:42:58,080 --> 00:43:08,080
It captures in a very compressed elegant form regularities, the essence of mathematics, Pythagoras theorem.

308
00:43:08,080 --> 00:43:19,080
On the other end of the spectrum have random things like the ideal gas law. It turns out, maybe counterintuitively the highly random systems also can be compressed with very simple laws.

309
00:43:19,080 --> 00:43:29,080
Yeah, in the middle between the world of extreme regularities like the celestial mechanics, or on the right, you know, thermodynamics and statistical mechanics.

310
00:43:29,080 --> 00:43:37,080
You have this domain, which has randomness in it, but randomness that accumulates regularities like evolutionary history.

311
00:43:37,080 --> 00:43:38,080
Right.

312
00:43:38,080 --> 00:43:55,080
That is the domain of complexity is the domain of living systems, and people say well you mean you're just biologists, and we'll say, well in one sense yes, but we're studying markets as well and we're studying ancient civilizations and archaeology.

313
00:43:55,080 --> 00:44:08,080
It's the living world that we study, but we study it through that hubristic lens of, can we find theories that are general for the living world.

314
00:44:08,080 --> 00:44:19,080
And it turns out that theories in that domain have a different character in part because they have to contend with agency.

315
00:44:19,080 --> 00:44:24,080
And I would say if you ask me what is the channel of the 20th the challenge of our century.

316
00:44:24,080 --> 00:44:40,080
It is this it's that two paradigms have emerged to contend with that machine learning and complexity science and I'm willing to make that a very broad church, but I am a deserfite.

317
00:44:40,080 --> 00:44:48,080
And one of them is highly predictive and opaque machine learning.

318
00:44:48,080 --> 00:45:01,080
The other one is less predictive but gives you the possibility of understanding how it actually works, explaining to people what's going on, you know, pedagogy.

319
00:45:01,080 --> 00:45:13,080
And I think that we're at a very interesting bifurcation point in our history where that's never happened before. And if you look at the 17th and 18th centuries those two things were very close.

320
00:45:13,080 --> 00:45:21,080
Newton could be both predictive, but also teach you how calculus works and you can write down how people's may I mean it's that simple.

321
00:45:22,080 --> 00:45:41,080
Nowadays, that's not true. And I think we're now contending with these two churches, the predictive, opaque, and the explanatory transparent, and I'm very interested in that in that schism.

322
00:45:41,080 --> 00:45:50,080
I want to talk a little bit about that schism with with the human dream and and how that, how that relates.

323
00:45:50,080 --> 00:45:52,080
You share a little bit about that.

324
00:45:52,080 --> 00:45:58,080
Can you just expand on that, you know, yeah, well just that then there's human thinking.

325
00:45:58,080 --> 00:46:08,080
There are these agents that that don't aren't seeing the transparency of the system and they're behaving a lot of a lot of what you just talked about in contagion and culture.

326
00:46:08,080 --> 00:46:26,080
How do we have that loop back to the agent so that they can change their learning rules or whatever to change. Yeah, yeah, I mean that in a way but is this is our, this is part of our agenda right to understand individual freedom in the face of institutional constraint.

327
00:46:27,080 --> 00:46:34,080
I don't think we have answers to that I think we can analyze cases.

328
00:46:34,080 --> 00:46:43,080
We still valorize the individual certainly in the United States in the West is a very strong emphasis placed on individual creativity, perhaps overstated.

329
00:46:43,080 --> 00:46:55,080
You know, we all know that theories aren't really invented by single people that through hidden history they're hidden figures that made huge contributions that get neglected or ignored.

330
00:46:55,080 --> 00:47:06,080
There's right carving out the space for individual freedom and free will in the face of these very powerful constraints, which are market driven.

331
00:47:06,080 --> 00:47:24,080
I mean this has been one of my crusades you know I mean, there's nothing wrong with platforms that harness collective power, but when those platforms have an incentive that is misaligned with human freedom, I sort of good war on them.

332
00:47:24,080 --> 00:47:35,080
You know, and I will be an example of my own field, the journal system scientific publication appear review it's a perfect example of a corrupt system, because we all know it everyone's not doing it, of course it is.

333
00:47:35,080 --> 00:47:48,080
It's embarrassing. Here we are researchers, and we are completely beholden to a system that does not have the progression of science at the forefront, but sales.

334
00:47:49,080 --> 00:47:55,080
And so, it's not that I'm anti market it's just one of those things become misaligned.

335
00:47:55,080 --> 00:48:03,080
Then we have to rethink. So we're constantly having these battles I wish we had them more often, and we had more victories under our belt.

336
00:48:03,080 --> 00:48:04,080
Yeah.

337
00:48:04,080 --> 00:48:16,080
So an audience member asked, how can we use these complexity models to appreciate better the external drivers for the changes we see.

338
00:48:16,080 --> 00:48:26,080
And I think, yeah, that gets back to your question Jerry earlier which is, they in some sense formalize the contributions of the constraints.

339
00:48:26,080 --> 00:48:36,080
I mean that's partly what they're all doing. I mean they're trying to, you know, where do we have free freedom to move and where the constraints established by the institutional feedback.

340
00:48:36,080 --> 00:48:53,080
And I think in every case we sort of have to sort of analyze how much is being driven by the constraint, and how much is being driven by our decisions, which is made even more complicated by the fact that our decisions emerge through a history of institutional

341
00:48:53,080 --> 00:49:06,080
and not even clear that we are free I mean there's some very difficult issues hiding in these circular feedback systems, where you how to attribute causality, but they do I mean just to get a question.

342
00:49:06,080 --> 00:49:16,080
You can actually do that you can partition for any given synchronous observation, how much comes from the constraint and how much is coming from your internal state.

343
00:49:17,080 --> 00:49:20,080
You can start getting at those things.

344
00:49:20,080 --> 00:49:29,080
I want to give you a chance to talk a little bit more about learning rules that the based on the success of the corresponding institution there.

345
00:49:29,080 --> 00:49:41,080
Say a little bit more about are the learning rules merely evolutions of the original rules, meaning like their schema that are just evolving as a result of feedback.

346
00:49:41,080 --> 00:49:42,080
Yeah.

347
00:49:42,080 --> 00:49:57,080
So what the paper actually that goes into detail is it's actually going to be published on May 16. And it's called on institutional dynamics and learning rules. So that will go that might help people.

348
00:49:57,080 --> 00:50:07,080
That was for that particular model, a full discrete enumeration of all possible learning rules. So we can do that in this very simple setting.

349
00:50:07,080 --> 00:50:14,080
And then pick any given one right and ask what are the implications if that were being used.

350
00:50:14,080 --> 00:50:20,080
So we don't have we don't look at the full continuous space between all rules and someone.

351
00:50:20,080 --> 00:50:40,080
I think the purpose of that work was to show that there is a, I think quite counterintuitive relationship between the local incentive reward system, and the ensuing institutional dynamic that that's the purpose of that work because if you look at the literature

352
00:50:40,080 --> 00:50:45,080
on institutions, it tends to work at the institutional level.

353
00:50:45,080 --> 00:50:51,080
It doesn't have these multiple time scales, which is mathematically by the way of heart.

354
00:50:51,080 --> 00:51:07,080
And this is something that's a hidden idea here that one should surface which is that much of theorizing for good reasons is led by analytical expediency.

355
00:51:07,080 --> 00:51:16,080
I mean, especially economics, where they love that. And the question for our community is, when are we willing to forfeit that.

356
00:51:16,080 --> 00:51:22,080
And that's really the move to machine learning or simulation right where you say, you know what.

357
00:51:22,080 --> 00:51:34,080
No, I mean, it's so far from reality. I don't care if you understand your model, it's useless, you know, and then that's a kind of people set that threshold at different points somehow.

358
00:51:34,080 --> 00:51:42,080
It would be very interesting, you might know, why do we do that psychologically, why do we have different preferences for that.

359
00:51:42,080 --> 00:51:45,080
I think we have time for one.

360
00:51:45,080 --> 00:51:48,080
Do we have time for one more.

361
00:51:48,080 --> 00:51:51,080
Laura.

362
00:51:51,080 --> 00:51:55,080
Yeah, time for one or two more. Okay, good.

363
00:51:55,080 --> 00:52:15,080
So another audience question. It's actually two questions. Does your work provide any insight into the role of relationships of the agents of systems and second does the fact that contagion hovers around criticality have anything to do with enhancement of adaptive capacity of the agents.

364
00:52:15,080 --> 00:52:18,080
Okay.

365
00:52:18,080 --> 00:52:24,080
So, yeah, I mean, I think the latter, that's very interesting.

366
00:52:24,080 --> 00:52:34,080
I think the answer has to be yes to that second part because, as in the example right of hovering by our zero equals one.

367
00:52:34,080 --> 00:52:44,080
It's precisely because we are so adaptive that happens right because as soon as we observe the information bearing on the subcritical regime we take them off.

368
00:52:44,080 --> 00:52:53,080
If we weren't adaptive we wouldn't, we would fix, and the actually the pandemic would go away it's sort of a peculiar perverse situation to be in.

369
00:52:53,080 --> 00:53:03,080
So yes, absolutely I think you're absolutely right. Adaptability is, I think the key ingredient of tuning to criticality.

370
00:53:03,080 --> 00:53:09,080
And, but you know what we're going to do to get rid of adaptability.

371
00:53:09,080 --> 00:53:15,080
And the first part seemed to me a more obscure I wasn't sure I understood the first part of the question.

372
00:53:15,080 --> 00:53:27,080
Well, I think that's interesting and follow up on that. So a lot of the systems that our students deal with are is, is, you know, so you found this this results from a mathematical model.

373
00:53:27,080 --> 00:53:34,080
But how do you feedback that that learning to the agent, like in the case of COVID.

374
00:53:34,080 --> 00:53:47,080
If the if the individual agents could change their schema or their mental model so therefore changing their, you know, behavior, you would get of it, we could get rid of coven right.

375
00:53:47,080 --> 00:54:01,080
So how do we take, you know, it seems to me the hard part is we learn these things about the at the systemic level, but how do you get the individual agents to change based on that awareness.

376
00:54:01,080 --> 00:54:04,080
I mean that seems to be like the crux of the whole.

377
00:54:04,080 --> 00:54:14,080
I mean, it's even worse for climate change because it's interesting I was in sabbatical at Harvard actually when the pandemic hit.

378
00:54:14,080 --> 00:54:25,080
And I was actually working at the Center for the environment which works on climate and immediately the conversation we were having is odia.

379
00:54:25,080 --> 00:54:33,080
How do we deal with systems that are massive global tragic collective commons problems.

380
00:54:33,080 --> 00:54:37,080
Like emulating climate change.

381
00:54:37,080 --> 00:54:44,080
But also operate on time scales where the change of our behaviors not the implications of changing or maybe not obvious.

382
00:54:44,080 --> 00:54:45,080
Yeah.

383
00:54:45,080 --> 00:54:53,080
I just gave a good example I think that in coven at least we see it right now part of seeing it is we adapt in the wrong direction.

384
00:54:53,080 --> 00:54:55,080
Yes, earlier question.

385
00:54:55,080 --> 00:54:59,080
So climate's a problem because there's no feedback.

386
00:54:59,080 --> 00:55:14,080
Say, there's no learning will come no learning no learning rule happens and there's so much delay. There's so much delay. And what I've heard discussed here is how do what are the appropriate metaphors that we could start inculcating

387
00:55:14,080 --> 00:55:21,080
in people's minds that would help them understand delayed feedback. For example, gardening, gardening.

388
00:55:21,080 --> 00:55:24,080
Anyone who plants a garden.

389
00:55:24,080 --> 00:55:26,080
Right, and I'm very impatient.

390
00:55:26,080 --> 00:55:27,080
I'm not going to.

391
00:55:27,080 --> 00:55:35,080
But there are people who are very good at it. And they, you realize I'm going to do all this now but I'm not going to see the fruits of my labor for about three seasons.

392
00:55:36,080 --> 00:55:52,080
It's going to be really scrappy next year and then you know and so on. And I think there are things that humans do that have those longer time scales where we're willing to operate with delayed gratification right delayed right.

393
00:55:52,080 --> 00:56:06,080
It seems to be the case here and I think I don't have an answer but I suspect educating people to think about pandemics and things like them, the way they would think about gardening or something.

394
00:56:06,080 --> 00:56:15,080
Yeah, would be very powerful and but unfortunately we do the opposite because we say we're going to have an RNA vaccine in a month.

395
00:56:15,080 --> 00:56:27,080
Right. And so, whatever virtuous long term thinking started to mature is immediately obliterated by the experience of an instantaneous vaccine.

396
00:56:27,080 --> 00:56:36,080
I'm not blaming vaccine development that's fantastic but these things are actually kind of in competition in our minds.

397
00:56:36,080 --> 00:56:51,080
I love the idea of the metaphors and kind of metaphors we live by like the fruits of our labor really is built into that is a metaphor of delay. Yes, and and so if we had these sort of systems metaphors that we could, you know, raise

398
00:56:51,080 --> 00:57:05,080
children on. Yes, then when they get to adulthood they would they would sort of understand that cause and effect aren't always neighbors on a timeline and you just recursively use the metaphor by saying raising children.

399
00:57:05,080 --> 00:57:08,080
It's another.

400
00:57:08,080 --> 00:57:10,080
Exactly. That's right.

401
00:57:10,080 --> 00:57:26,080
Thank you so much David, I really appreciate the talk it's an amazing talk and amazing ideas and I wish we had many more hours to chat but thank you for for your, your talk and answering questions.

402
00:57:26,080 --> 00:57:33,080
Thank you very much everybody thank you Derek and Laura for inviting me and hope to see you some point at SFI virtually one person.

403
00:57:33,080 --> 00:57:36,080
Yes, much appreciated.

404
00:57:36,080 --> 00:57:38,080
Okay.

405
00:57:40,080 --> 00:57:42,080
Thank you.

