WEBVTT

00:00.000 --> 00:26.000
Hello, everybody.

00:27.000 --> 00:32.000
We have a good crowd for John's second talk.

00:32.000 --> 00:33.000
It's very exciting.

00:33.000 --> 00:37.000
This is the first year that John will be talking twice.

00:37.000 --> 00:40.000
A couple of things to know.

00:40.000 --> 00:42.000
John will talk for about an hour or so,

00:42.000 --> 00:44.000
and then we'll have 30 minutes for questions.

00:44.000 --> 00:46.000
The mic is right there.

00:46.000 --> 00:48.000
That's actually just right there.

00:48.000 --> 00:52.000
So just line up when we get to the questions.

00:52.000 --> 00:55.000
Try to keep your questions on what John talked about.

00:55.000 --> 00:57.000
If you get up and ask when Doom 4 is coming out,

00:57.000 --> 00:59.000
I'm going to kick you in the knee.

00:59.000 --> 01:01.000
So right there.

01:01.000 --> 01:04.000
So I will not waste any more time,

01:04.000 --> 01:06.000
but you guys in the back,

01:06.000 --> 01:08.000
because John's going to write on the board,

01:08.000 --> 01:09.000
and we have plenty of empty seats here,

01:09.000 --> 01:11.000
you can file in.

01:11.000 --> 01:13.000
Don't worry that there's reserve seats there.

01:13.000 --> 01:15.000
Just go ahead and sit in them.

01:15.000 --> 01:19.000
All right, I will give you guys Mr. Carmichael.

01:19.000 --> 01:29.000
Okay, so I guess this is sort of going to be

01:29.000 --> 01:31.000
like a school room session.

01:31.000 --> 01:33.000
I had deluded myself for a little while

01:33.000 --> 01:35.000
that this would be the first talk

01:35.000 --> 01:37.000
where I ever actually made slides to present,

01:37.000 --> 01:39.000
but it didn't actually come to pass,

01:39.000 --> 01:41.000
so it's going to be notes and talking

01:41.000 --> 01:43.000
and some scribbling on the board again.

01:43.000 --> 01:45.000
So almost all of what we do in game development

01:45.000 --> 01:47.000
is really more about artistry.

01:47.000 --> 01:49.000
It's about trying to appeal to people,

01:49.000 --> 01:51.000
but there's the small section of the small section

01:51.000 --> 01:53.000
of what goes into the games

01:53.000 --> 01:55.000
that's drawing the pictures on the screen

01:55.000 --> 01:57.000
that you can at least make some ties

01:57.000 --> 02:00.000
to the hardest of hard sciences.

02:00.000 --> 02:03.000
And while it's great that people are researching

02:03.000 --> 02:05.000
the psychology and the different ways

02:05.000 --> 02:07.000
that people think about compulsion loops

02:07.000 --> 02:09.000
and some of these other game design topics,

02:09.000 --> 02:11.000
the raw physics that goes into rendering

02:11.000 --> 02:13.000
just kind of goes through the heart of physics,

02:13.000 --> 02:16.000
where it goes through kind of the all-star list

02:16.000 --> 02:18.000
of physics with Newton's optics

02:18.000 --> 02:21.000
and Maxwell's equations and Einstein's relativity,

02:21.000 --> 02:23.000
and it's kind of neat to think

02:23.000 --> 02:25.000
that this is sort of brought to bear

02:25.000 --> 02:27.000
in the techniques that go into

02:27.000 --> 02:29.000
sort of making the games that we play.

02:29.000 --> 02:31.000
So at the start, you think,

02:31.000 --> 02:33.000
well, okay, we see light,

02:33.000 --> 02:35.000
so what actually is light?

02:35.000 --> 02:37.000
And we've got a definition now

02:37.000 --> 02:40.000
that lights the sliver of the electromagnetic spectrum

02:40.000 --> 02:42.000
that we can actually perceive,

02:42.000 --> 02:44.000
but that has a really long and complicated history

02:44.000 --> 02:46.000
for how we sort of reached that conclusion

02:46.000 --> 02:48.000
and how it's not really as clear-cut

02:48.000 --> 02:52.000
as most people would like it to be.

02:52.000 --> 02:54.000
Optical research started kind of all the way back

02:54.000 --> 02:56.000
with a lot of the Greek philosophers,

02:56.000 --> 02:58.000
but Newton did a whole lot of work

02:58.000 --> 03:00.000
with breaking light up with prisms,

03:00.000 --> 03:02.000
seeing how white light was actually composed

03:02.000 --> 03:04.000
of all the different colors of the spectrum,

03:04.000 --> 03:08.000
and they add together to make what we perceive as light.

03:08.000 --> 03:11.000
And then for, there was a centuries-long debate

03:11.000 --> 03:13.000
about whether light was a particle,

03:13.000 --> 03:15.000
like this little tiny billiard ball,

03:15.000 --> 03:17.000
these photons that you shoot out,

03:17.000 --> 03:19.000
or a wave effect, like all the things that you see

03:19.000 --> 03:21.000
in waves in water and waves in matter,

03:21.000 --> 03:23.000
and so on.

03:23.000 --> 03:25.000
And finally, we reached the conclusion that,

03:25.000 --> 03:27.000
well, it's a wave particle duality

03:27.000 --> 03:29.000
that Quantum Mechanics talks about,

03:29.000 --> 03:31.000
and this is very unsatisfying

03:31.000 --> 03:33.000
when you begin looking at this,

03:33.000 --> 03:35.000
but it's really pretty much irrefutable.

03:35.000 --> 03:37.000
There are these straightforward experiments

03:37.000 --> 03:39.000
that can be done to show that you look at it one way,

03:39.000 --> 03:41.000
it's a wave, you look at it another way,

03:41.000 --> 03:44.000
it's a light, or it's a particle.

03:44.000 --> 03:47.000
So, luckily for computer graphics,

03:47.000 --> 03:49.000
we hardly care at all about that,

03:49.000 --> 03:51.000
only when you start looking at some aspects

03:51.000 --> 03:53.000
of surface reflectance models,

03:53.000 --> 03:55.000
do you start caring at all about

03:55.000 --> 03:57.000
some of these Quantum Mechanical properties of light.

03:57.000 --> 03:59.000
For the most part, we can look at light

03:59.000 --> 04:02.000
as zillions and zillions of little billiard balls

04:02.000 --> 04:04.000
shot out from lights and bouncing off of things

04:04.000 --> 04:06.000
and eventually reaching our eyes

04:06.000 --> 04:08.000
so that we can perceive them.

04:09.000 --> 04:11.000
There's a lot of simplifications

04:11.000 --> 04:15.000
that have to happen when you talk about simulating this.

04:15.000 --> 04:17.000
There's a lot of engineering disciplines

04:17.000 --> 04:20.000
like thermal management, radio engineering

04:20.000 --> 04:22.000
that do simulations of the electromagnetic spectrum,

04:22.000 --> 04:24.000
just other parts of it,

04:24.000 --> 04:26.000
how they bounce around, interact with things,

04:26.000 --> 04:28.000
and this is done all the time,

04:28.000 --> 04:30.000
and it works, it really is science.

04:30.000 --> 04:33.000
So, you can say rendering an image

04:33.000 --> 04:36.000
or deciding how much light reaches a particular area

04:36.000 --> 04:39.000
is about as basic of a science as it comes.

04:39.000 --> 04:42.000
There's not any artistic measure in here.

04:42.000 --> 04:44.000
There are tons of other aspects

04:44.000 --> 04:46.000
when you get into perception

04:46.000 --> 04:48.000
that do become questions about,

04:48.000 --> 04:51.000
well, maybe there is artistry that goes into producing something

04:51.000 --> 04:53.000
when you've got an impression that you want,

04:53.000 --> 04:55.000
but when you're talking about simulating an environment,

04:55.000 --> 04:59.000
which most of what we do in the hardcore FPS type games

04:59.000 --> 05:02.000
is we are pretending that we've got this virtual world

05:02.000 --> 05:04.000
and we're running a camera through it

05:04.000 --> 05:07.000
and we're trying to simulate what's happening in various ways.

05:07.000 --> 05:10.000
And nowadays, we know what we would have to do

05:10.000 --> 05:12.000
to make that almost perfect.

05:12.000 --> 05:15.000
We just have nowhere near the computing capacity

05:15.000 --> 05:18.000
to do really, really high-level simulations,

05:18.000 --> 05:20.000
but we can trace it useful

05:20.000 --> 05:22.000
even if you're not going to do the right thing

05:22.000 --> 05:24.000
to at least understand what the right thing is

05:24.000 --> 05:26.000
and then understand which trade-offs you're making

05:26.000 --> 05:28.000
and make them with sort of a clear head

05:28.000 --> 05:31.000
rather than accidentally backing into trade-offs

05:31.000 --> 05:35.000
that may or may not be really the best way to go about things.

05:36.000 --> 05:38.000
So, so many that...

05:38.000 --> 05:40.000
It took a long time for people to realize

05:40.000 --> 05:43.000
that these other phenomena, things like radio waves,

05:43.000 --> 05:46.000
and there's a lot of confusion in 19th and 20th century physics

05:46.000 --> 05:49.000
about which things were particles and which things were rays,

05:49.000 --> 05:52.000
and we still have kind of mixed-up terminology

05:52.000 --> 05:55.000
when you talk about cosmic rays that are actually particles

05:55.000 --> 05:59.000
and you talk about alpha radiation and beta radiation

05:59.000 --> 06:01.000
and these things that are particle-based

06:01.000 --> 06:04.000
rather than being rays from the electromagnetic spectrum.

06:04.000 --> 06:07.000
But we use this stuff all the time for radio waves.

06:07.000 --> 06:12.000
Your Wi-Fi has two gigahertz frequencies.

06:12.000 --> 06:16.000
The visible light rays are up in the terahertz range,

06:16.000 --> 06:18.000
many terahertz.

06:18.000 --> 06:20.000
But they're basically the same thing.

06:20.000 --> 06:23.000
They just differ in how they interact with matter.

06:23.000 --> 06:25.000
They're produced in somewhat similar ways,

06:25.000 --> 06:27.000
but the different things change.

06:27.000 --> 06:30.000
They behave differently when they interact with other things

06:30.000 --> 06:32.000
based on their wavelength,

06:32.000 --> 06:34.000
which is why x-rays can shoot through things,

06:34.000 --> 06:36.000
radio waves can go through some things

06:36.000 --> 06:39.000
that the visible light pretty much bounces off of.

06:41.000 --> 06:44.000
So, another important critical thing, really,

06:44.000 --> 06:47.000
is that photons, the little bundles of light that we talk about,

06:47.000 --> 06:49.000
they are absolutely quantized.

06:49.000 --> 06:51.000
It's, again, part of the quantum weirdness

06:51.000 --> 06:54.000
that you can't send off this arbitrarily divisible amount,

06:54.000 --> 06:57.000
there is an almost unbelievably large number of them.

06:57.000 --> 06:59.000
Given light that's throwing out is, you know,

06:59.000 --> 07:01.000
I can just say zillions with a straight face

07:01.000 --> 07:04.000
because it's a very large scientific notation number.

07:04.000 --> 07:06.000
It's not trillions, it's not quadrillions,

07:06.000 --> 07:08.000
it's even more than that that are coming out

07:08.000 --> 07:12.000
in terms of these bundled little quanta of energy.

07:14.000 --> 07:17.000
Now, they do have characteristics to them.

07:17.000 --> 07:20.000
If we treat them as little billiard balls in computer graphics,

07:20.000 --> 07:23.000
we are generally looking at only a few different spectrums

07:23.000 --> 07:26.000
of a few different wavelengths in the spectrum of light,

07:26.000 --> 07:30.000
and that has to do with an aspect of the human visual system.

07:30.000 --> 07:34.000
While there are this incredibly divisible spectrum of light

07:34.000 --> 07:40.000
that goes out, we're only susceptible to three sort of styles of light,

07:40.000 --> 07:42.000
and they're not even individual frequencies.

07:42.000 --> 07:45.000
That's why we can get by with red, green, and blue

07:45.000 --> 07:47.000
for our monitor's emissive spectrums

07:47.000 --> 07:51.000
because we only have three types of color receptors in our eyes,

07:51.000 --> 07:53.000
and I often think how it would be really interesting

07:53.000 --> 07:56.000
if you could look at all of these other spectrums bouncing around,

07:56.000 --> 07:59.000
and that's what thermal imaging and some of these other things

07:59.000 --> 08:01.000
let you sort of get a peek into it,

08:01.000 --> 08:03.000
and that's only light that's very...

08:03.000 --> 08:07.000
that's EM radiation that's very close to the visible spectrum,

08:07.000 --> 08:09.000
the infrared.

08:09.000 --> 08:11.000
It would be much more bizarre and interesting

08:11.000 --> 08:14.000
to be able to visualize radio waves in a real-time space

08:14.000 --> 08:17.000
to, like, see all the multi-path that's causing your Wi-Fi

08:17.000 --> 08:19.000
to be weird in specific ways,

08:19.000 --> 08:21.000
why, you know, moving something over here

08:21.000 --> 08:25.000
causes the radiation to change so much at your antenna

08:25.000 --> 08:28.000
to make a difference in your reception strength,

08:28.000 --> 08:31.000
and these are all things that have a bearing to what you do

08:31.000 --> 08:34.000
with light transport, as well as other wave phenomena,

08:34.000 --> 08:37.000
like audio, like really, really high-end audio processing

08:37.000 --> 08:41.000
is the exact same thing as what we treat light processing.

08:41.000 --> 08:44.000
You send out energy, it bounces off of all sorts of things in the world,

08:44.000 --> 08:47.000
and eventually arrives at something that's going to perceive it,

08:47.000 --> 08:51.000
which would be your ears in that case versus your eyes.

08:51.000 --> 08:54.000
So to kind of start with the path of a photon,

08:54.000 --> 08:56.000
of what it would take,

08:56.000 --> 08:59.000
you've got something creates the photon,

08:59.000 --> 09:02.000
and for the longest time in our human existence

09:02.000 --> 09:04.000
about the only thing that we saw creating photons

09:04.000 --> 09:06.000
was a great deal of heat.

09:06.000 --> 09:08.000
You heat things up hot enough,

09:08.000 --> 09:10.000
and photons start coming off of them.

09:10.000 --> 09:12.000
You heat it up enough, it starts glowing a dull red,

09:12.000 --> 09:15.000
you heat it up more, it starts getting more yellowish,

09:15.000 --> 09:18.000
and towards white as more and more of the colors of the spectrum

09:18.000 --> 09:21.000
are emitted from these hot things,

09:21.000 --> 09:23.000
and obviously the sun is a very hot thing

09:23.000 --> 09:25.000
where you've got a fusion reactor going,

09:25.000 --> 09:29.000
and the light that comes off of that is all of these atoms

09:29.000 --> 09:31.000
giving up some energy.

09:31.000 --> 09:36.000
So photons carry energy away from where they came from,

09:36.000 --> 09:41.000
and this is a radiative heat transfer where something gets hot.

09:41.000 --> 09:44.000
If you leave it all by itself there,

09:44.000 --> 09:47.000
it glows and it eventually stops glowing.

09:47.000 --> 09:49.000
It cools down, going down through the spectrum,

09:49.000 --> 09:52.000
getting cooler and cooler until you don't see any visible light

09:52.000 --> 09:54.000
because it's actually lost much of its heat.

09:54.000 --> 09:59.000
On Earth, radiative heat transfer is the least effective form of heat transfer.

09:59.000 --> 10:01.000
You get much more from conduction

10:01.000 --> 10:04.000
where it just kind of goes through the actual physical contact

10:04.000 --> 10:07.000
into other areas as the heat spreads out,

10:07.000 --> 10:11.000
or convection where moving currents of air or water take the heat away.

10:11.000 --> 10:14.000
But in space, radiation is the only way you lose heat,

10:14.000 --> 10:17.000
and in aerospace engineering this is extremely important.

10:17.000 --> 10:21.000
Things like the areas like the International Space Station and Spaceships,

10:21.000 --> 10:24.000
they have to worry a whole lot about thermal management

10:24.000 --> 10:27.000
because the only tool they've really got is radiation.

10:27.000 --> 10:31.000
You see these enormous solar panels where they collect solar energy,

10:31.000 --> 10:34.000
but a lot of space vehicles have to have enormous radiators

10:34.000 --> 10:38.000
where they actually let the energy go out from the vehicle,

10:38.000 --> 10:40.000
otherwise they would get hotter and hotter.

10:41.000 --> 10:45.000
It's important to note that even if it's not glowing so that we can see it,

10:45.000 --> 10:47.000
everything's still radiating,

10:47.000 --> 10:50.000
so you don't see the space station glowing red hot,

10:50.000 --> 10:52.000
it's just glowing at whatever its normal temperature is,

10:52.000 --> 10:55.000
which can be perceived with infrared sensors,

10:55.000 --> 10:58.000
but it slowly loses energy and it eventually reaches a balance.

10:58.000 --> 11:02.000
That's why something stuck out in the sun in space doesn't get hotter and hotter.

11:02.000 --> 11:06.000
Eventually it reaches the point where the light that's coming in and hitting it

11:06.000 --> 11:08.000
is equal by the radiation that's leaving it,

11:08.000 --> 11:11.000
and there are, like you can make,

11:11.000 --> 11:14.000
we've made rocket engines that are radiatively cooled

11:14.000 --> 11:18.000
where they burn 5000 degrees or so inside

11:18.000 --> 11:22.000
and they get so blindingly white hot on the outside

11:22.000 --> 11:26.000
that all of the energy that's not going out the nozzle that's soaking into the walls

11:26.000 --> 11:29.000
is radiated away as a whole lot of light.

11:29.000 --> 11:32.000
And this is essentially what old-style incandescent light bulbs were.

11:32.000 --> 11:36.000
You had a tungsten filament, you made it really hot by pushing electrons through it,

11:36.000 --> 11:39.000
and it got hot enough and it started glowing.

11:39.000 --> 11:42.000
And if you watched closely, if it was a very, like a heavy filament,

11:42.000 --> 11:44.000
you could watch it warm up or especially shut down,

11:44.000 --> 11:48.000
it would go through, kind of ramp through the temperatures, you would see it,

11:48.000 --> 11:51.000
be red and get up to white hot, and then when you shut it down,

11:51.000 --> 11:54.000
it would cool down through yellow and then back through red

11:54.000 --> 11:59.000
before finally settling back to radiating in non-visible regions

11:59.000 --> 12:01.000
at sort of room temperature eventually.

12:01.000 --> 12:04.000
Nowadays we have a lot more efficient ways to create photons

12:04.000 --> 12:08.000
with fluorescence and LEDs, things that are tuned carefully

12:08.000 --> 12:13.000
to just barely nudge the electrons in the atoms out to an excited state,

12:13.000 --> 12:16.000
let them collapse back down and spit a photon out.

12:16.000 --> 12:21.000
For the most part, photon emission is random in terms of which direction it goes.

12:21.000 --> 12:25.000
When you look at radio engineering, there's huge bodies of literature

12:25.000 --> 12:29.000
for intended design that determine how you can make it slightly stronger

12:29.000 --> 12:33.000
or weaker in different directions, but there's still a very fundamental nature of randomness,

12:33.000 --> 12:36.000
which is, again, the quantum mechanics aspect of things.

12:36.000 --> 12:40.000
At a very low level, natural events are completely random

12:40.000 --> 12:46.000
and you can't just say, I only want photons that are going to come out of the left side of this material.

12:46.000 --> 12:50.000
So you get a photon that pops off in some random direction.

12:50.000 --> 12:54.000
It may go straight for, if it's coming from a distant star,

12:54.000 --> 12:58.000
it could go straight for trillions of miles, more or less just traveling through space.

12:58.000 --> 13:02.000
There's little bits of general relativity with warping of light that can happen,

13:02.000 --> 13:06.000
but for the most part, it can continue on indefinitely.

13:06.000 --> 13:10.000
It's a self-propagating wave, so it pops off of some atom somewhere,

13:10.000 --> 13:14.000
maybe flies through space for a billion trillion miles or something,

13:14.000 --> 13:17.000
comes in, finally hits our Earth's atmosphere,

13:17.000 --> 13:21.000
and then starts interacting with the atmosphere in some way.

13:21.000 --> 13:25.000
Every change in density that visible light goes through

13:25.000 --> 13:28.000
will result in it bending its path somewhat.

13:28.000 --> 13:30.000
This is called refraction.

13:30.000 --> 13:33.000
The most obvious case when you look at it is things like prisms and lenses

13:33.000 --> 13:36.000
where you can see the light really strongly warped,

13:36.000 --> 13:39.000
but it happens in any sort of density change,

13:39.000 --> 13:43.000
going from the vacuum of space to the outer reaches of our atmosphere,

13:43.000 --> 13:47.000
and then every change in pressure or temperature changes the density,

13:47.000 --> 13:53.000
and that causes very slight and subtle movements of the changes in the direction of the light.

13:53.000 --> 13:56.000
This is actually why stars twinkle out at night.

13:56.000 --> 14:01.000
You're on a clear night and you see stars coming in from billions or trillions of miles away.

14:01.000 --> 14:04.000
It's going completely straight till it hits the upper atmosphere,

14:04.000 --> 14:08.000
and then it may slightly deviate, just tiny fractions of degrees,

14:08.000 --> 14:12.000
and this can cause the very small number of photons that you're seeing there

14:12.000 --> 14:16.000
to kind of come and go or move around in different ways.

14:16.000 --> 14:20.000
But the most important thing from a computer graphics standpoint

14:20.000 --> 14:23.000
are the effects that happen when it hits more solid matter,

14:23.000 --> 14:26.000
or solid surfaces, or even liquid surfaces,

14:26.000 --> 14:30.000
and that's where it has the opportunity to generally...

14:30.000 --> 14:35.000
Well, even gas, you can wind up having the case of absorbing the photon.

14:35.000 --> 14:37.000
This happens rarely in gas.

14:37.000 --> 14:40.000
You can pass through hundreds of miles of atmosphere

14:40.000 --> 14:43.000
and not have too many of the photons absorbed,

14:43.000 --> 14:49.000
but it happens very rapidly in matter, in solid matter.

14:49.000 --> 14:54.000
A typical photon, when it hits a surface, might penetrate a little bit into it.

14:54.000 --> 14:58.000
A surface like metal will bounce off of just the first several atoms.

14:58.000 --> 15:03.000
It doesn't take many molecules or many atoms of metal before you can reflect light out,

15:03.000 --> 15:06.000
which is why you can make these super enormous space mirrors

15:06.000 --> 15:10.000
that are just a very tiny sputtering of aluminum on some plastic film,

15:10.000 --> 15:15.000
and they can actually make solar sails or giant solar collectors and concentrators.

15:15.000 --> 15:20.000
But for most other materials, the light can penetrate a little bit further into it.

15:20.000 --> 15:24.000
As it interacts with the molecules, it can either be absorbed,

15:24.000 --> 15:29.000
raising the temperature a little bit, going into eventually making it hotter

15:29.000 --> 15:32.000
so that it starts radiating out at some level,

15:32.000 --> 15:36.000
or it can redirect the photon in some way.

15:36.000 --> 15:39.000
You've got the minor redirections from the refraction

15:39.000 --> 15:44.000
and much stronger ones when it interacts and bounces off of a solid surface.

15:44.000 --> 15:46.000
There's a ton of different names.

15:46.000 --> 15:48.000
There's literally a couple dozen different names

15:48.000 --> 15:51.000
for the different ways that light can interact with surfaces.

15:51.000 --> 15:53.000
There's all the different types of scattering.

15:53.000 --> 15:58.000
Of course, reflection, refraction, refraction can be split up into

15:58.000 --> 16:01.000
specular reflection, diffuse reflection,

16:01.000 --> 16:03.000
and there's all sorts of different subcategories.

16:03.000 --> 16:05.000
Optics is a huge topic.

16:05.000 --> 16:08.000
There are societies dedicated to every aspect of it,

16:08.000 --> 16:11.000
and there's huge terminologies for all of it.

16:11.000 --> 16:13.000
But for the most part, you can say,

16:13.000 --> 16:16.000
photon comes in, if it's not absorbed,

16:16.000 --> 16:18.000
it's going to be kicked out some other direction,

16:18.000 --> 16:21.000
and then it can go and interact potentially with the atmosphere

16:21.000 --> 16:23.000
or potentially with another surface.

16:23.000 --> 16:25.000
And eventually, it's either absorbed,

16:25.000 --> 16:27.000
well, eventually it is absorbed somewhere,

16:27.000 --> 16:30.000
but for the most part, they're absorbed into the surfaces around us,

16:30.000 --> 16:34.000
but a tiny, tiny fraction of all the photons that are bouncing around

16:34.000 --> 16:36.000
eventually hits our eyes.

16:36.000 --> 16:39.000
And even when it gets to our eyes, which are mostly transparent,

16:39.000 --> 16:41.000
there's this chance that the photon hits,

16:41.000 --> 16:43.000
and it specularly reflects off of our eye,

16:43.000 --> 16:46.000
and it made it all the way out of the billions of possible traces,

16:46.000 --> 16:51.000
made it to my eye, and then decides to specularly reflect off some other direction.

16:51.000 --> 16:55.000
But most of it that hits the eye and hits the lens gets through,

16:55.000 --> 16:58.000
propagates through the vitreous and aqueous humor

16:58.000 --> 17:00.000
and all the little biological parts of the eye,

17:00.000 --> 17:03.000
and hits receptors in the back of our eyeballs

17:03.000 --> 17:08.000
that turn those eventually into neural impulses that our brain works with.

17:08.000 --> 17:11.000
Now, our eyes can actually be quite sensitive.

17:11.000 --> 17:16.000
The rods, the non-color sensitive part of our eyes,

17:16.000 --> 17:18.000
when they're fully dark adapted,

17:18.000 --> 17:22.000
if you've been staying outside in a dark area for 20, 30 minutes,

17:22.000 --> 17:29.000
single photons can cause chemical reactions to happen inside the rod cells.

17:29.000 --> 17:33.000
It takes a handful of them, a couple dozen for it to turn into a neural impulse,

17:33.000 --> 17:35.000
but it is possible for people that,

17:35.000 --> 17:38.000
especially in the old days, people watching for things on ships

17:38.000 --> 17:43.000
in moonless nights that might be out all night with nothing but faint starlight,

17:43.000 --> 17:47.000
you can have cases of just handfuls of photons coming off of something,

17:47.000 --> 17:51.000
being registered and showing up and people acknowledging their existence,

17:51.000 --> 17:55.000
which is pretty amazing when you think about these incredible subatomic particles,

17:55.000 --> 18:02.000
not even particles, but incredible, the scope of that being detectable by us as biological entities.

18:03.000 --> 18:07.000
There are limits to what you can wind up detecting with light.

18:07.000 --> 18:10.000
The visible light that we see has a wavelength,

18:10.000 --> 18:13.000
and you can't really deal with things that are smaller than that,

18:13.000 --> 18:17.000
which is why you're never going to have a real picture of an atom or a molecule,

18:17.000 --> 18:21.000
because those are much, much smaller than the wavelengths of light.

18:21.000 --> 18:26.000
You eventually use electron microscopes and then scanning tunneling microscopes

18:26.000 --> 18:30.000
and these other things that don't deal with light at all to take those super tiny pictures,

18:30.000 --> 18:33.000
like the boy in his atom movie that IBM Research did,

18:33.000 --> 18:36.000
which was done with a little raster grid of atoms,

18:36.000 --> 18:40.000
which is really in the fundamental sense of the word, deeply awesome,

18:40.000 --> 18:44.000
that we are dealing with matter, the very constituents of everything at that level,

18:44.000 --> 18:47.000
and we can make a little movie out of it,

18:47.000 --> 18:50.000
but those pictures have nothing to do with light, nothing to do with rendering

18:50.000 --> 18:54.000
and basically the techniques that I'm talking about here,

18:54.000 --> 18:59.000
that's a completely different way of sensing what's going on at that level.

18:59.000 --> 19:03.000
So to recap the basic pictures of this,

19:03.000 --> 19:09.000
you've got something, a sun up here, spits out some light, travels through space,

19:09.000 --> 19:15.000
gets to the atmosphere on the Earth, maybe bends a little bit,

19:15.000 --> 19:18.000
maybe just goes straight through, comes down, hits the surface,

19:18.000 --> 19:21.000
maybe gets absorbed, maybe hits something else,

19:21.000 --> 19:24.000
and you've got walls and rooms and bouncing around in there,

19:24.000 --> 19:28.000
and eventually, if we're seeing it, reaches somebody's eyeball inside,

19:28.000 --> 19:31.000
and that's the physics of what happens.

19:31.000 --> 19:33.000
It's really well understood.

19:33.000 --> 19:37.000
It does come down to a lot of data acquisition and characterization.

19:37.000 --> 19:43.000
When you talk about how the critical interactions with the surfaces,

19:43.000 --> 19:46.000
when you've got your basic theoretical thing,

19:46.000 --> 19:48.000
if you talk about a flat surface, you say,

19:48.000 --> 19:51.000
light comes in, what happens to it?

19:51.000 --> 19:53.000
That's the question of surface response.

19:53.000 --> 19:55.000
If you have a perfect mirror,

19:55.000 --> 20:00.000
and it's worth noting that you don't have to be perfect on an atomic level

20:00.000 --> 20:03.000
to be a perfect mirror, you only have to be perfect at the optical level,

20:03.000 --> 20:05.000
which is somewhat larger.

20:05.000 --> 20:10.000
So people can make basically perfect mirrors, just highly, highly polished things.

20:10.000 --> 20:15.000
A perfect mirror will have the photon reflect off in this exact reflection.

20:15.000 --> 20:19.000
If you take the normal to the surface, you wind up with equal angles there.

20:19.000 --> 20:23.000
So highly polished surfaces act like this.

20:23.000 --> 20:27.000
When you get a reflection off of something like the surface of water,

20:27.000 --> 20:29.000
it'll behave like this.

20:29.000 --> 20:33.000
But most of the surfaces that we look around us do not behave like this.

20:33.000 --> 20:37.000
We have a spread of the energy where it comes in,

20:37.000 --> 20:41.000
and it bounces off to some degree in every direction.

20:41.000 --> 20:43.000
No matter which way you look at most surfaces,

20:43.000 --> 20:46.000
you see, again, zillions of photons coming in.

20:46.000 --> 20:48.000
Some of them go in every direction.

20:48.000 --> 20:53.000
They just go in a direction that's biased based on the type of surface that it is.

20:53.000 --> 20:55.000
A surface that...

20:55.000 --> 20:58.000
One of the easy things that a lot of times is approximated,

20:58.000 --> 21:01.000
both in the engineering sciences and in computer graphics,

21:01.000 --> 21:04.000
is to assume that the surface reflects perfectly diffusely,

21:04.000 --> 21:06.000
or it's a Lambertian surface.

21:06.000 --> 21:10.000
And what that means is that no matter which way the light comes in,

21:10.000 --> 21:13.000
if it hits it completely edge on, completely straight on,

21:13.000 --> 21:17.000
it has an equal probability of going in every direction.

21:17.000 --> 21:20.000
And there are some materials that are close to this.

21:20.000 --> 21:24.000
If you take something like a block of chalk, white chalk,

21:24.000 --> 21:28.000
that behaves almost as a perfect diffuse reflector.

21:28.000 --> 21:30.000
If you light it from one position,

21:30.000 --> 21:34.000
and you look at that like a little scribed out area on it from any different area around it,

21:34.000 --> 21:38.000
it will appear to have about the same amount of energy coming out of it.

21:38.000 --> 21:41.000
But there are...

21:41.000 --> 21:44.000
All surfaces are more complex than that, though.

21:44.000 --> 21:47.000
Most of them will say, if you've got light coming in here,

21:47.000 --> 21:50.000
there will be more of it coming out around the reflection area,

21:50.000 --> 21:55.000
and some general amount coming out in all different directions.

21:55.000 --> 21:58.000
But these can actually get quite complicated.

21:58.000 --> 22:02.000
And the simplifications that we use in graphics sort of approximate these,

22:02.000 --> 22:05.000
but you can measure these with specific tools

22:05.000 --> 22:09.000
that go in and take lots of samples from moving the lights around,

22:09.000 --> 22:11.000
because it depends...

22:11.000 --> 22:14.000
Unfortunately, this is one of the areas where it does get

22:14.000 --> 22:16.000
not so great for computer graphics.

22:16.000 --> 22:20.000
It depends both on the incoming direction and the upcoming direction.

22:20.000 --> 22:22.000
And those are two angles in each one,

22:22.000 --> 22:27.000
so it winds up being a four-dimensional equation to say how light comes in here,

22:27.000 --> 22:29.000
how does it come out in some other direction.

22:29.000 --> 22:31.000
And in fact, it gets worse than that,

22:31.000 --> 22:36.000
because very few things do reflect just off of this upper surface.

22:36.000 --> 22:38.000
Most of the time, the light will go in,

22:38.000 --> 22:41.000
go below the surface, bounce around a little bit,

22:41.000 --> 22:43.000
and shoot out some other direction.

22:43.000 --> 22:47.000
So if you're saying, well, my photon comes in here,

22:47.000 --> 22:50.000
not only do you have to say if you're being really, really accurate,

22:50.000 --> 22:52.000
which angle does it come off of,

22:52.000 --> 22:56.000
but also how far away from the original point does it come off of?

22:56.000 --> 23:01.000
Or if it's a thin surface, how does it come out on the backside?

23:01.000 --> 23:03.000
You may have other setups coming there.

23:03.000 --> 23:05.000
When you look at, like, a leaf in the sunshine,

23:05.000 --> 23:07.000
you've got a lot of the energy,

23:07.000 --> 23:09.000
bounces off the shiny top face,

23:09.000 --> 23:12.000
but a lot of it diffuses through and comes out on the backside.

23:12.000 --> 23:18.000
So these are not pleasantly analytically tractable things.

23:18.000 --> 23:21.000
They wind up being big tables of data.

23:21.000 --> 23:24.000
And one thing that's important to remember is,

23:24.000 --> 23:27.000
when you see, like, tables of data that are collected for things,

23:27.000 --> 23:31.000
don't necessarily capture all of the important characteristics of the surface,

23:31.000 --> 23:36.000
where if you take one of these sensors that you can capture a table of data here,

23:36.000 --> 23:38.000
if you did have your perfect mirror reflector,

23:38.000 --> 23:44.000
it's almost certainly not going to have the exact sample exactly where you want.

23:44.000 --> 23:46.000
But eventually data does win,

23:46.000 --> 23:48.000
just as we increase resolution on things,

23:48.000 --> 23:52.000
we'll have higher and higher resolutions for our surface models,

23:52.000 --> 23:57.000
and we'll get closer and closer to reality for what we're simulating.

23:57.000 --> 24:03.000
So to go as kind of a capsule history of computer graphics rendering then,

24:03.000 --> 24:05.000
when computer graphics started off,

24:05.000 --> 24:08.000
look in the 60s, 60s and early 70s,

24:08.000 --> 24:12.000
computer graphics research focused on the hidden line problem.

24:12.000 --> 24:15.000
You know, we had line-oriented displays,

24:15.000 --> 24:22.000
either true vector displays where, like the old video game arcade games,

24:22.000 --> 24:25.000
like I'm blanking out now,

24:25.000 --> 24:27.000
like Asteroids is the best example,

24:27.000 --> 24:31.000
that are actually drawn by raster beams moving around

24:31.000 --> 24:33.000
where they really are true line displays.

24:33.000 --> 24:35.000
There's no raster, there's no edge aliasing,

24:35.000 --> 24:41.000
and all the different games like that were what the earliest computer graphics systems

24:41.000 --> 24:44.000
were basically like that, where there were vector displays.

24:44.000 --> 24:47.000
And once people learned how to draw,

24:47.000 --> 24:50.000
figured out all the basic projective math to say,

24:50.000 --> 24:54.000
all right, I've got my cube here.

24:54.000 --> 24:56.000
You know, I want it to look like that,

24:56.000 --> 24:59.000
but when I draw it, I've got that on there.

24:59.000 --> 25:02.000
How do we figure out which lines that we're going to erase?

25:03.000 --> 25:06.000
And that was, you know, that occupied research for a while

25:06.000 --> 25:08.000
to figure out effective ways to do that

25:08.000 --> 25:12.000
without spending at the time the scary divide costs for different things,

25:12.000 --> 25:16.000
and you'd have lots of interesting work being going on.

25:16.000 --> 25:20.000
But when we eventually got raster displays where we could fill them in,

25:20.000 --> 25:23.000
of course, at that point people filled in the surfaces of the cube,

25:23.000 --> 25:25.000
they're all grayscale at that time,

25:25.000 --> 25:27.000
so you can draw a cube and say, well, this will be the light face,

25:27.000 --> 25:29.000
this will be the dark face,

25:29.000 --> 25:31.000
but that was neat at the time,

25:31.000 --> 25:34.000
but that was not sort of what things look like in reality.

25:34.000 --> 25:38.000
So people started taking the steps that they could to try and say,

25:38.000 --> 25:42.000
what do we need to do to make this more approximate what we see with our eyes?

25:42.000 --> 25:47.000
And this has been a path that's been driven probably more than half

25:47.000 --> 25:50.000
by sort of ad hoc approaches about just,

25:50.000 --> 25:55.000
well, what's reasonably easy for us to do that gets us somewhat closer to it

25:55.000 --> 25:59.000
while there's also been sort of a parallel path of saying,

25:59.000 --> 26:01.000
well, what's the physics actually doing?

26:01.000 --> 26:05.000
How do we make an actual solution for it?

26:05.000 --> 26:11.000
So the earliest things that got added to the shading model for computer graphics

26:11.000 --> 26:17.000
was if we assumed that there's going to be a light that's at some point,

26:17.000 --> 26:19.000
in the beginning it wouldn't even be local,

26:19.000 --> 26:22.000
you just say light is coming in from this direction.

26:22.000 --> 26:26.000
So we want to be able to say what color or what shade

26:26.000 --> 26:30.000
should each individual surface be based on where that light is.

26:30.000 --> 26:33.000
So you've got the obvious things that if it's not facing the light,

26:33.000 --> 26:36.000
no light hits it and you would draw it black.

26:36.000 --> 26:40.000
So the question about things that are directly facing the light,

26:40.000 --> 26:42.000
so if you've got light coming in,

26:42.000 --> 26:45.000
if you have a surface completely perpendicular to it,

26:45.000 --> 26:47.000
you make that your brightest color.

26:47.000 --> 26:50.000
If you've got a surface that's completely parallel with it,

26:50.000 --> 26:52.000
it gets no light, you make that zero.

26:52.000 --> 26:54.000
So you've got some curve that goes between it

26:54.000 --> 26:57.000
to say how bright something should be.

26:57.000 --> 27:03.000
And it turns out that that's a fairly straightforward bit of math to solve

27:03.000 --> 27:07.000
where you have light coming in at a certain angle,

27:07.000 --> 27:10.000
you've got the normal to the surface,

27:10.000 --> 27:14.000
the amount of light that would strike a little surface there

27:14.000 --> 27:18.000
is proportional to the cosine of this angle.

27:18.000 --> 27:20.000
And that's actually, that's not an approximation,

27:20.000 --> 27:23.000
that's actually a bit of ground truth.

27:23.000 --> 27:25.000
If you've got the light coming in

27:25.000 --> 27:29.000
and you've got something coming in at this angle,

27:29.000 --> 27:34.000
a surface that's, let's see.

27:34.000 --> 27:36.000
If you count the number of rays that go in

27:36.000 --> 27:41.000
on something catching four of them directly, turning it down,

27:41.000 --> 27:43.000
only covering two, two spaces there,

27:43.000 --> 27:45.000
all that actually works out correct.

27:45.000 --> 27:48.000
And this is the basis for a lot of the,

27:48.000 --> 27:50.000
a lot of the real calculations for light transport,

27:50.000 --> 27:54.000
not a hack actually part of real proper physics measuring.

27:54.000 --> 27:57.000
So once you've got that basic approach,

27:57.000 --> 27:59.000
you go back to your cube

28:02.000 --> 28:04.000
and you get your light coming in

28:04.000 --> 28:08.000
and you've got a brighter face, a brighter face, a darker face,

28:08.000 --> 28:10.000
and the faces away from it are completely black

28:10.000 --> 28:11.000
and then most people say,

28:11.000 --> 28:13.000
well, we don't usually see things like that.

28:13.000 --> 28:16.000
So now we get into the fudging and you say,

28:16.000 --> 28:18.000
well, let's just brighten everything up a little bit.

28:18.000 --> 28:20.000
We'll add an ambient term.

28:20.000 --> 28:22.000
So you sort of just add this minimum level

28:22.000 --> 28:24.000
to everything on the back side.

28:24.000 --> 28:25.000
And that helps a little bit.

28:25.000 --> 28:27.000
If you've got a cube, then everything looks pretty much great

28:27.000 --> 28:30.000
because it's a constant color just on the side

28:30.000 --> 28:32.000
that you might not see over there.

28:32.000 --> 28:34.000
But if you've got something more complex,

28:34.000 --> 28:37.000
everything that's not facing away from the light

28:37.000 --> 28:39.000
winds up being the same color.

28:39.000 --> 28:40.000
And it's clearly not correct.

28:40.000 --> 28:41.000
It's not what you'd like,

28:41.000 --> 28:46.000
but it was all that seemed reasonable to do at the time.

28:46.000 --> 28:49.000
The next step was to start looking at surfaces

28:49.000 --> 28:52.000
that are more than these perfectly diffuse reflectors.

28:52.000 --> 28:54.000
If you model your cube like this,

28:54.000 --> 28:57.000
it looks kind of like it was maybe carved out of chalk

28:57.000 --> 29:00.000
and it can be a decent representation of that.

29:00.000 --> 29:03.000
But very few of the surfaces that we see around us

29:03.000 --> 29:05.000
are really that simple.

29:05.000 --> 29:08.000
Most things have some kind of a shine or highlight on them.

29:08.000 --> 29:10.000
As we look around, you can see reflections

29:10.000 --> 29:12.000
and highlights on all sorts of things

29:12.000 --> 29:14.000
and the obvious bits of metal and plastic,

29:14.000 --> 29:16.000
little things that you might hold in your hand.

29:16.000 --> 29:19.000
I can look at all these different shines and reflections

29:19.000 --> 29:21.000
on the plastic that I'm holding here.

29:21.000 --> 29:24.000
Now, the observation was made

29:24.000 --> 29:26.000
that the highlights on most objects

29:26.000 --> 29:28.000
that weren't completely mirrors,

29:28.000 --> 29:31.000
they tended to be something like a bright hot spot,

29:31.000 --> 29:34.000
like if you had your sphere here,

29:34.000 --> 29:35.000
you would have a bright hot spot

29:35.000 --> 29:38.000
that kind of faded a little bit around there.

29:38.000 --> 29:40.000
And just by looking at that and saying,

29:40.000 --> 29:45.000
well, what could we do that would be kind of like that?

29:45.000 --> 29:47.000
The observation was made that,

29:47.000 --> 29:51.000
well, if you take this sort of cosine arrangement here,

29:51.000 --> 29:53.000
this makes this nice broad fall off.

29:53.000 --> 29:58.000
It makes over the entire surface of the sphere coming from that.

29:58.000 --> 30:01.000
It'll fade off to halfway around the light.

30:01.000 --> 30:04.000
But if you wanted something that was really tight,

30:04.000 --> 30:07.000
the thought was, well, we can just take this value

30:07.000 --> 30:09.000
and raise it to a higher power.

30:09.000 --> 30:11.000
We can just take this and go, you know,

30:11.000 --> 30:14.000
square it, cube it, take it to the 20th power,

30:14.000 --> 30:18.000
which can be done effectively, mathematically, quite cheaply.

30:18.000 --> 30:21.000
This has no basis in physical reality at all.

30:21.000 --> 30:24.000
This is a completely ad hoc approach.

30:24.000 --> 30:25.000
But it worked out okay.

30:25.000 --> 30:29.000
And this is what the fog lighting model was about,

30:29.000 --> 30:33.000
where you separate it into your diffuse lighting,

30:33.000 --> 30:36.000
which is more or less what color the surface is,

30:36.000 --> 30:38.000
and then your specular lighting,

30:38.000 --> 30:40.000
which is what the highlights are going to look like.

30:40.000 --> 30:44.000
So you had this other value to play around with,

30:44.000 --> 30:46.000
and that was the specular power.

30:46.000 --> 30:50.000
And nowadays, I regret using that in my terminology,

30:50.000 --> 30:52.000
where we have power maps,

30:52.000 --> 30:55.000
and nobody understands what those are.

30:55.000 --> 30:58.000
They relate to the specular exponent,

30:58.000 --> 31:01.000
what you're going to take something to a power of to tighten it.

31:01.000 --> 31:04.000
The better terminology that's used more often now

31:04.000 --> 31:07.000
is a roughness map, where you have a mapping,

31:07.000 --> 31:10.000
and you also do it in logarithmic space rather than linear,

31:10.000 --> 31:12.000
but more or less, that's still today,

31:12.000 --> 31:14.000
what a lot of graphics involves,

31:14.000 --> 31:16.000
is you've got a roughness parameter,

31:16.000 --> 31:20.000
which affects this exponent that you take this extra vector

31:20.000 --> 31:22.000
to generate your specular highlights for.

31:22.000 --> 31:26.000
And again, it would make so if you're rendering your cube

31:26.000 --> 31:28.000
and you get the light at the right angle,

31:28.000 --> 31:31.000
like if I'm looking at this here and the light's over here,

31:31.000 --> 31:34.000
it hits that, if that's at that right reflection angle,

31:34.000 --> 31:37.000
then you'll get a nice bright shade on there.

31:37.000 --> 31:40.000
That flat surface will catch the light and it will glint at you,

31:40.000 --> 31:44.000
and that would be looked at as a real advance for the rendering.

31:44.000 --> 31:46.000
So you've got something that looks diffused,

31:46.000 --> 31:48.000
but when it moves into the light,

31:48.000 --> 31:50.000
it kind of catches a flash of light and fades out.

31:50.000 --> 31:55.000
So the facets on these solid shaded models started looking better.

31:55.000 --> 31:58.000
Now, the next thing that people wanted to do is,

31:58.000 --> 32:01.000
okay, we've got enough cubes and tetrahedrons

32:01.000 --> 32:04.000
and dodecahedrons and whatever.

32:04.000 --> 32:07.000
So we want to start making things that look more realistic.

32:07.000 --> 32:09.000
We need to have a teapot.

32:09.000 --> 32:12.000
We need to have a curved surface in some way.

32:12.000 --> 32:15.000
So you make some curved surface like this.

32:15.000 --> 32:17.000
There was a lot of work in the early days

32:17.000 --> 32:21.000
on directly rasterizing curved surfaces, drawing them directly,

32:21.000 --> 32:25.000
but all the real-time graphics, almost all of it,

32:25.000 --> 32:28.000
has been a matter of turning your curved surfaces

32:28.000 --> 32:31.000
into approximations with flat surfaces.

32:31.000 --> 32:35.000
So you've got something that is theoretically a curve,

32:35.000 --> 32:40.000
but really it's a bunch of facets.

32:40.000 --> 32:43.000
So if you apply the lighting model there to it,

32:43.000 --> 32:45.000
you see all of these facets.

32:45.000 --> 32:49.000
It stands out as like, okay, you've just carved this out

32:49.000 --> 32:51.000
with all these flat planes,

32:51.000 --> 32:53.000
and it doesn't fool you into thinking

32:53.000 --> 32:56.000
that this is this smooth-curved object.

32:56.000 --> 32:58.000
So the next step in graphics that went on

32:58.000 --> 33:04.000
was adding the interpolation across the vertexes,

33:04.000 --> 33:07.000
where instead of calculating a value for a face,

33:07.000 --> 33:11.000
you calculate it for a given vertex, for one corner,

33:11.000 --> 33:13.000
and then you just average.

33:13.000 --> 33:15.000
You interpolate across there

33:15.000 --> 33:17.000
so that a point here is going to be some average

33:17.000 --> 33:21.000
between three or four of the points that make it up.

33:21.000 --> 33:24.000
And that works surprisingly well.

33:24.000 --> 33:27.000
If you're looking again at a diffuse surface,

33:27.000 --> 33:30.000
it works out just about as good as you'd like.

33:30.000 --> 33:33.000
There are some minor artifacts called mock bands

33:33.000 --> 33:35.000
that you get if it changes too much,

33:35.000 --> 33:38.000
but if your tessellation's okay, that works out all right.

33:38.000 --> 33:42.000
It works out less well with the specular highlights,

33:42.000 --> 33:46.000
and the reason is that your specular highlight,

33:46.000 --> 33:48.000
if you've got...

33:48.000 --> 33:50.000
It might show up like if you were supposed to have

33:50.000 --> 33:53.000
some hot spot right here in the middle of a surface.

33:53.000 --> 33:55.000
If you calculate it at the outside,

33:55.000 --> 33:59.000
this is going to be almost zero for the specular, almost zero.

33:59.000 --> 34:02.000
And when you interpolate across it, it's going to have nothing.

34:02.000 --> 34:04.000
You're just not going to see it.

34:04.000 --> 34:06.000
You'll only see a highlight when the specular comes up

34:06.000 --> 34:08.000
at the very edges.

34:08.000 --> 34:09.000
And this is what's still to this day

34:09.000 --> 34:12.000
sort of the standard open GL shading model is.

34:12.000 --> 34:16.000
It's gross shading with calculations at the vertexes,

34:16.000 --> 34:19.000
interpolating the colors or parameters across it.

34:19.000 --> 34:22.000
So this model is still with us to this day

34:22.000 --> 34:25.000
for a lot of sort of quick stuff that's not

34:25.000 --> 34:27.000
visual simulation oriented.

34:27.000 --> 34:29.000
If you just write something using lighting with open GL,

34:29.000 --> 34:31.000
that's the model that you get

34:31.000 --> 34:34.000
if you turn on specular highlights.

34:34.000 --> 34:37.000
In graphics where they care more about visual quality,

34:37.000 --> 34:40.000
what started happening was interpolating

34:40.000 --> 34:42.000
not the color across it,

34:42.000 --> 34:44.000
but interpolating the normal,

34:44.000 --> 34:47.000
sort of the curvature across each point

34:47.000 --> 34:50.000
and then applying the lighting model at every pixel.

34:50.000 --> 34:54.000
And at the time, this was like a flagrant use of processing power

34:54.000 --> 34:57.000
because we're like, okay, these calculations are expensive.

34:57.000 --> 35:00.000
We have to do these distance calculations, dot products,

35:00.000 --> 35:02.000
exponential power stuff.

35:02.000 --> 35:05.000
And when you just do it at each vertex on your cube,

35:05.000 --> 35:08.000
okay, so you've got a handful of vertexes

35:08.000 --> 35:10.000
that you need to calculate.

35:10.000 --> 35:12.000
But even on an old school display,

35:12.000 --> 35:14.000
you would have hundreds of thousands of pixels.

35:14.000 --> 35:16.000
And so if you're drawing that there,

35:16.000 --> 35:19.000
going from doing this maybe a few hundred times

35:19.000 --> 35:22.000
or a few thousand times to hundreds of thousands of times

35:22.000 --> 35:25.000
for a scene was a large use of additional processing power.

35:25.000 --> 35:28.000
But it got you the good looking areas

35:28.000 --> 35:31.000
where you could have a highlight that looked about

35:31.000 --> 35:33.000
like it should moving across the surface

35:33.000 --> 35:36.000
or sitting on a floor looking stable there

35:36.000 --> 35:38.000
as you moved around.

35:38.000 --> 35:40.000
People that have been in following PC graphics

35:40.000 --> 35:42.000
for the last couple of decades,

35:42.000 --> 35:45.000
we've seen games that do not have interpolation

35:45.000 --> 35:48.000
in the different ways where the lighting would change dramatically.

35:48.000 --> 35:52.000
We always had the problem of densely-tesolated characters

35:52.000 --> 35:56.000
or objects and then very low-tesolation on the world.

35:56.000 --> 35:58.000
And the problem that you'd run into with that

35:58.000 --> 36:02.000
is that if you're applying one of these interpolation schemes to it,

36:02.000 --> 36:05.000
you would have something that you could never have highlights

36:05.000 --> 36:08.000
in the middle of the surface, only at the corners.

36:08.000 --> 36:11.000
And there were also issues with perspective math and clipping

36:11.000 --> 36:14.000
that would mean that it would change as a really big polygon

36:14.000 --> 36:17.000
clipped by the edge of the screen in almost all cases

36:17.000 --> 36:19.000
the way people did it.

36:19.000 --> 36:21.000
And this was one of the big things that pushed me

36:21.000 --> 36:25.000
during the Quake timeframe to use light maps for the first time

36:25.000 --> 36:27.000
where instead of I had seen other games

36:27.000 --> 36:29.000
that were doing lighting at the vertexes

36:29.000 --> 36:31.000
and I didn't think it wasn't good enough,

36:31.000 --> 36:33.000
you couldn't get anything resembling a shadow,

36:33.000 --> 36:36.000
you had all these swimming artifacts with the lighting

36:36.000 --> 36:39.000
and it just didn't give what I wanted to see.

36:39.000 --> 36:42.000
And while Quake didn't have any specular highlights,

36:42.000 --> 36:44.000
it did have these...

36:44.000 --> 36:46.000
You had samples every 16 pixels in the light maps

36:46.000 --> 36:48.000
that we interpolated across those,

36:48.000 --> 36:53.000
and that gave us the look that was very important for it.

36:53.000 --> 36:55.000
And we didn't get to actually...

36:55.000 --> 36:57.000
It was only all the way up to Doom 3

36:57.000 --> 37:01.000
where we would start doing per-pixel operations like this

37:01.000 --> 37:04.000
to get the much better calculations.

37:04.000 --> 37:07.000
So even with this level of graphics at that time

37:07.000 --> 37:10.000
where you've just got sort of these fog lighting,

37:10.000 --> 37:14.000
simple models, hacks like the specular exponent

37:14.000 --> 37:16.000
and the ambient term,

37:16.000 --> 37:18.000
we started to see some offline things being rendered

37:18.000 --> 37:20.000
like some movies, you know, early work,

37:20.000 --> 37:23.000
some of the early NASA promotional work that Jim Blinn did

37:23.000 --> 37:26.000
were significant in the sort of growth of all of this.

37:26.000 --> 37:29.000
And then we finally saw some feature theatrical films

37:29.000 --> 37:32.000
with like The Last Star Fighter and especially Tron

37:32.000 --> 37:34.000
where you would see...

37:34.000 --> 37:36.000
You go back and you look at Tron

37:36.000 --> 37:38.000
and you have a lot of these sort of

37:38.000 --> 37:41.000
gross-shaded, solid-modeled things on there

37:41.000 --> 37:43.000
with your light cycles or recognizers and so on.

37:43.000 --> 37:45.000
And they were doing something...

37:45.000 --> 37:47.000
They were intelligently picking a battle

37:47.000 --> 37:49.000
that could be won at the time.

37:49.000 --> 37:51.000
If you said, well, we have to go ahead

37:51.000 --> 37:53.000
and render photo-realistic humans,

37:53.000 --> 37:55.000
we were nowhere close to up to that task.

37:55.000 --> 37:57.000
But we could do geometric solid models

37:57.000 --> 37:59.000
that looked good enough to show on the big screen,

37:59.000 --> 38:02.000
and that was a pretty big breakthrough.

38:02.000 --> 38:04.000
And simultaneously with this,

38:04.000 --> 38:07.000
there was an alternate approach to

38:07.000 --> 38:10.000
the way graphics were being drawn that...

38:10.000 --> 38:13.000
So most of the early graphics were done

38:13.000 --> 38:15.000
with rasterization where if you've got

38:15.000 --> 38:19.000
your computer screen and you've got

38:19.000 --> 38:22.000
your quad on here,

38:22.000 --> 38:24.000
you would draw this on a computer

38:24.000 --> 38:26.000
by calculating these equations of the lines

38:26.000 --> 38:28.000
and then you would usually just kind of

38:28.000 --> 38:32.000
walk across building up your rows of pixels.

38:34.000 --> 38:36.000
The whole process of hidden surface removal

38:36.000 --> 38:38.000
is another step on top of this

38:38.000 --> 38:40.000
where if you've got lots of cubes,

38:40.000 --> 38:42.000
how do you know which one draws on top of the other one?

38:42.000 --> 38:44.000
And this was another thing, if you look back

38:44.000 --> 38:47.000
in research from the 70s especially,

38:47.000 --> 38:50.000
there was tons of work going on on hidden surface removal

38:50.000 --> 38:52.000
of these clever different algorithmic ways.

38:52.000 --> 38:54.000
Today we just kill it with a depth buffer.

38:54.000 --> 38:57.000
We just throw megabytes and megabytes of memory

38:57.000 --> 39:00.000
and the problem gets solved much, much easier.

39:00.000 --> 39:03.000
But this path of rasterization is still with us today.

39:03.000 --> 39:07.000
GPUs don't rasterize in scanline order like this.

39:07.000 --> 39:10.000
They follow crazy winding paths

39:10.000 --> 39:13.000
to maximize memory bandwidth to fill up tiles,

39:13.000 --> 39:15.000
to rasterize them in different pieces,

39:15.000 --> 39:17.000
and they rasterize all quads at a time,

39:17.000 --> 39:20.000
but it's still essentially a rasterization method

39:20.000 --> 39:23.000
where we have shapes and we figure out how to rasterize them.

39:23.000 --> 39:25.000
We figure out which pixels they're going to cover,

39:25.000 --> 39:28.000
and then we figure out what we want to do with them.

39:28.000 --> 39:30.000
The alternate scheme which was also developed

39:30.000 --> 39:33.000
in the later 70s is ray tracing

39:33.000 --> 39:35.000
where instead of saying, alright,

39:35.000 --> 39:37.000
I'm starting with my object,

39:37.000 --> 39:40.000
I'm going to take these four vertexes

39:40.000 --> 39:43.000
that are in space, I'm going to take my virtual camera

39:43.000 --> 39:45.000
and I'm going to transform them

39:45.000 --> 39:47.000
and find out where they are on the screen

39:47.000 --> 39:48.000
and then fill them in.

39:48.000 --> 39:50.000
Ray tracing goes the other way

39:50.000 --> 39:54.000
where you start off with your camera in space somewhere,

39:54.000 --> 39:56.000
your virtual viewing screen,

39:56.000 --> 40:00.000
and through that you send rays out into your world

40:00.000 --> 40:04.000
and you intersect them with your cube over here,

40:04.000 --> 40:06.000
and if it hits that cube first,

40:06.000 --> 40:08.000
it knows it didn't hit anything behind that,

40:08.000 --> 40:10.000
it's got a surface point there,

40:10.000 --> 40:13.000
and it can apply whatever shading model it needs to.

40:13.000 --> 40:16.000
The thing that ray tracing gave,

40:16.000 --> 40:18.000
I mean it's radically slower,

40:18.000 --> 40:20.000
thousands of times slower than ray tracing

40:20.000 --> 40:23.000
if you're doing just the most straightforward thing.

40:23.000 --> 40:25.000
If you just want to draw that cube,

40:25.000 --> 40:28.000
you can draw the same thing with ray tracing,

40:28.000 --> 40:31.000
it's just going to be a thousand times slower with ray tracing,

40:31.000 --> 40:33.000
but it allowed a couple things

40:33.000 --> 40:36.000
that were either very difficult or impossible

40:36.000 --> 40:38.000
to do properly with ray tracing,

40:38.000 --> 40:40.000
and the thing that you would always see

40:40.000 --> 40:43.000
in ray tracing demos is your shiny reflective spheres.

40:43.000 --> 40:45.000
So you've got a little chrome ball

40:45.000 --> 40:48.000
and the fact that you could see the world reflected into it,

40:48.000 --> 40:50.000
and then back into your eye

40:50.000 --> 40:52.000
was the thing that ray tracing could do

40:52.000 --> 40:55.000
that rasterization couldn't do really worth a damn at all.

40:55.000 --> 40:57.000
You would approximate it with environment maps

40:57.000 --> 40:59.000
and different things,

40:59.000 --> 41:01.000
but for reflections and for refraction

41:01.000 --> 41:03.000
doing those things properly,

41:03.000 --> 41:06.000
ray tracing was really the only good solution,

41:06.000 --> 41:09.000
but it wasn't practical even for most offline work.

41:09.000 --> 41:12.000
I can remember looking at old research papers

41:12.000 --> 41:15.000
of things that are run on deck vax computers,

41:15.000 --> 41:17.000
and they talk about the number of hours

41:17.000 --> 41:19.000
to render these really trivial scenes,

41:19.000 --> 41:21.000
just a few boxes in the eye,

41:21.000 --> 41:23.000
maybe a sphere sitting there,

41:23.000 --> 41:26.000
and the idea of rendering complete worlds with it

41:26.000 --> 41:29.000
was fantasy at the time,

41:29.000 --> 41:31.000
but it did address some of those problems

41:31.000 --> 41:34.000
for the first time with reflection and refraction,

41:34.000 --> 41:37.000
and it also much more elegantly solved shadows,

41:37.000 --> 41:40.000
which all of this stuff talking about surface interactions

41:40.000 --> 41:43.000
and finding out what you hit with the light,

41:43.000 --> 41:46.000
that kind of dodges one of the really hard problems,

41:46.000 --> 41:48.000
which is saying that, well,

41:48.000 --> 41:51.000
the light obviously doesn't reach through things.

41:51.000 --> 41:53.000
If you transform something up here

41:53.000 --> 41:57.000
and you transform another surface down here,

41:57.000 --> 41:58.000
and the light's up here,

41:58.000 --> 42:01.000
this should be in shadow because it's blocked by this,

42:01.000 --> 42:05.000
but that turns out to not be a particularly trivial thing to resolve.

42:05.000 --> 42:07.000
It's basically the same problem

42:07.000 --> 42:09.000
of how you view something from your point of view,

42:09.000 --> 42:11.000
but viewed from the light's point of view,

42:11.000 --> 42:13.000
and that can mean that,

42:13.000 --> 42:16.000
well, if every light in your scene

42:16.000 --> 42:19.000
has to do a similar rendering process

42:19.000 --> 42:21.000
to what your view does,

42:21.000 --> 42:23.000
possibly harder because there are omnidirectional lights

42:23.000 --> 42:25.000
in many different cases,

42:25.000 --> 42:27.000
and it's just a tough problem,

42:27.000 --> 42:28.000
and as with so many things,

42:28.000 --> 42:31.000
there's a lot of wonderful research in the 70s and 80s

42:31.000 --> 42:34.000
going through about how you do shadows effectively

42:34.000 --> 42:36.000
with these different analytic solutions.

42:36.000 --> 42:38.000
In the end, we had a brief period

42:38.000 --> 42:42.000
where stencil volumes were an effective way to do things,

42:42.000 --> 42:45.000
but now it's essentially all shadow buffers,

42:45.000 --> 42:47.000
where we really do take every light,

42:47.000 --> 42:49.000
render an image from their scene,

42:49.000 --> 42:53.000
and use that to back project onto there to figure things out.

42:53.000 --> 42:55.000
But that was one thing that ray tracing

42:55.000 --> 42:57.000
had an elegant solution for.

42:57.000 --> 42:59.000
Again, if you're already a thousand times slower,

42:59.000 --> 43:01.000
who cares if you're another factor of two or three slower?

43:01.000 --> 43:03.000
For every point you hit, you go ahead and say,

43:03.000 --> 43:05.000
I've got my light up here,

43:05.000 --> 43:08.000
I'll trace to the light or to however many lights I've got,

43:08.000 --> 43:10.000
and if there's something that blocks it,

43:10.000 --> 43:13.000
then that's going to be shadowed and I can take it out.

43:13.000 --> 43:18.000
So ray tracing always had this much clearer abstraction

43:18.000 --> 43:19.000
of what you're doing.

43:19.000 --> 43:22.000
It's easy to tell that you're sending out a little array,

43:22.000 --> 43:25.000
you hit something, you determine whether you hit all the other lights,

43:25.000 --> 43:28.000
or if you bounce or refract into something else.

43:28.000 --> 43:30.000
So it's always been easy and clear.

43:30.000 --> 43:35.000
It's just had this thousand times slower problem to deal with.

43:35.000 --> 43:39.000
So the advances that were being made on graphics,

43:39.000 --> 43:41.000
kind of after this early age,

43:41.000 --> 43:45.000
focused on the changes in what you can do with the surfaces

43:45.000 --> 43:47.000
as the first obvious thing.

43:47.000 --> 43:49.000
And a lot of these were driven by

43:49.000 --> 43:52.000
sort of artistic and aesthetic concerns,

43:52.000 --> 43:55.000
where we got, if you pull up a 3D rendering program

43:55.000 --> 43:56.000
and you look at their material stuff,

43:56.000 --> 43:58.000
there's a whole page full of options,

43:58.000 --> 44:00.000
things that you can tweak, knobs you can turn,

44:00.000 --> 44:02.000
checkboxes you can set,

44:02.000 --> 44:06.000
and each of these had some use case where somebody wanted this

44:06.000 --> 44:10.000
because it made their image generally look a certain way that they wanted.

44:10.000 --> 44:12.000
Very rarely were these things driven by

44:12.000 --> 44:15.000
sort of physically correct rendering.

44:15.000 --> 44:18.000
And there was a huge plethora of these things that came out.

44:18.000 --> 44:21.000
Every different program had a different set of options.

44:21.000 --> 44:24.000
You always had this fallback of you've got your diffuse colors,

44:24.000 --> 44:26.000
your specular color, your roughness,

44:26.000 --> 44:30.000
this basic fog shading model persists to this day.

44:30.000 --> 44:34.000
But now we have a ton of other things that we can tag on there,

44:34.000 --> 44:36.000
things that are subsurface approximate,

44:36.000 --> 44:38.000
scattering approximations, Fresnel lighting,

44:38.000 --> 44:42.000
different frequency response on surfaces.

44:42.000 --> 44:46.000
It's like some of the things do have physical basis to them.

44:46.000 --> 44:48.000
Like one obvious thing,

44:48.000 --> 44:53.000
the Fresnel effect is the effect that as you get more and more glancing to something,

44:53.000 --> 44:55.000
the reflection gets stronger and stronger.

44:55.000 --> 44:59.000
And you see this, this is what makes water and glass look like water and glass.

44:59.000 --> 45:01.000
If you look straight at them,

45:01.000 --> 45:04.000
you pretty much see straight through them without a whole lot of reflection.

45:04.000 --> 45:06.000
But as you get more and more edge on,

45:06.000 --> 45:08.000
even a surface like this,

45:08.000 --> 45:10.000
where when I'm looking at this at this angle here,

45:10.000 --> 45:14.000
I've got a very, very strong clear sense of the slightly wavy reflection

45:14.000 --> 45:16.000
of that white line there,

45:16.000 --> 45:19.000
while if I look at it right here, it's barely visible.

45:19.000 --> 45:22.000
So that's a physical effect in reality

45:22.000 --> 45:27.000
that you can work through the real physics equations of why this happens.

45:27.000 --> 45:30.000
But people, again, sort of called up the trustee,

45:30.000 --> 45:32.000
raise a cosine to a power,

45:32.000 --> 45:36.000
and it sort of looks like what we want when we're dotting a couple vectors together.

45:36.000 --> 45:39.000
So that has, that's something that's based off plausible physics,

45:39.000 --> 45:42.000
but generally only roughly approximated.

45:42.000 --> 45:44.000
And there are other things like that with,

45:44.000 --> 45:48.000
like the change in some metals get their metallic look

45:48.000 --> 45:51.000
because they slightly change colors as they get towards grazing angles.

45:51.000 --> 45:54.000
So again, you can calculate the real physics for that,

45:54.000 --> 45:55.000
or you can just sign it, kind of say,

45:55.000 --> 45:58.000
well, this color sort of changes to this color at the edges

45:58.000 --> 46:01.000
and start interpolating between them.

46:01.000 --> 46:06.000
But lots and lots of good work and lots of high-budget movies and so on

46:06.000 --> 46:10.000
were built with these sort of very ad hoc techniques.

46:10.000 --> 46:12.000
But sort of in parallel with this,

46:12.000 --> 46:16.000
the other big revolution that was happening was global light transport,

46:16.000 --> 46:19.000
global illumination.

46:19.000 --> 46:22.000
It comes back to that whole hack of the ambient term,

46:22.000 --> 46:26.000
this sense that obviously where, okay, if I'm right here,

46:26.000 --> 46:28.000
the lights are only directly hitting the outside.

46:28.000 --> 46:31.000
The back of my hand has no direct view to any light,

46:31.000 --> 46:34.000
but it's still quite bright and clearly illuminated.

46:34.000 --> 46:38.000
It's bright because all those lights hit this white board,

46:38.000 --> 46:42.000
bounce off of that, and wind up lighting my hand from the back.

46:42.000 --> 46:44.000
And you can see, like, color changes,

46:44.000 --> 46:48.000
like if I move up here where it's mostly covered by the blue marker on there,

46:48.000 --> 46:50.000
the blue tints to it.

46:50.000 --> 46:54.000
And this recognition that so much of what we consider important

46:54.000 --> 46:56.000
in the visual field is actually indirect.

46:56.000 --> 46:58.000
It's not just a matter of, here's the light,

46:58.000 --> 47:00.000
here's the surface, what's the reaction.

47:00.000 --> 47:04.000
Because we come back to how much of the light gets bounced around.

47:04.000 --> 47:08.000
And there's a term called the albedo of a surface,

47:08.000 --> 47:12.000
which is what fraction of the light gets reflected versus absorbed.

47:12.000 --> 47:14.000
And there's some tricky terminology with this

47:14.000 --> 47:17.000
because you can have either the total solar albedo

47:17.000 --> 47:20.000
where you talk about how much energy comes off of the sun.

47:20.000 --> 47:22.000
And this is used for climate modeling

47:22.000 --> 47:25.000
and some remote imaging and things like this where you matter.

47:25.000 --> 47:29.000
But you've also then got the visible albedo,

47:29.000 --> 47:31.000
which for rendering is what we care about.

47:31.000 --> 47:34.000
And the point is that the best reflectors,

47:34.000 --> 47:37.000
your chrome sphere that's mirrored or your white piece of chalk

47:37.000 --> 47:39.000
or your freshly driven snow,

47:39.000 --> 47:42.000
those can reflect 90-ish percent of the light.

47:42.000 --> 47:45.000
While your darkest surfaces, your lump of black coal

47:45.000 --> 47:50.000
or asphalt in some cases, might only reflect 5%.

47:50.000 --> 47:53.000
But when you're reflecting 90% of the light,

47:53.000 --> 47:55.000
what that means is that if you're in a room

47:55.000 --> 47:58.000
that has mostly white surfaces,

47:58.000 --> 48:02.000
a single bit of light coming out of your light emitter

48:02.000 --> 48:06.000
might bounce around a dozen times before it finally gets absorbed.

48:06.000 --> 48:09.000
So it could take a very complex path

48:09.000 --> 48:11.000
before it winds up getting to your eye.

48:11.000 --> 48:16.000
And this is why we could have cases like a dark room

48:16.000 --> 48:18.000
illuminated only through the crack under the door.

48:18.000 --> 48:21.000
But you can still wind up looking even around corners.

48:21.000 --> 48:23.000
You can go into the closet in the dark room

48:23.000 --> 48:26.000
illuminated under the keyhole and still find things somewhat lit.

48:26.000 --> 48:30.000
And that's because of this many bouncing path that light can take

48:30.000 --> 48:32.000
from the light emitter coming around

48:32.000 --> 48:34.000
until it actually gets to your eye.

48:34.000 --> 48:39.000
And this turns out to be a really frighteningly complex

48:39.000 --> 48:42.000
and expensive problem to solve properly.

48:42.000 --> 48:47.000
The first sets of attempts at this dealt with

48:47.000 --> 48:49.000
radiosity approaches.

48:57.000 --> 49:00.000
And a lot of this was driven by

49:00.000 --> 49:03.000
engineering things beyond just making pictures

49:03.000 --> 49:05.000
because you would talk about things like heat management.

49:05.000 --> 49:08.000
If you have a certain amount of energy coming in here,

49:08.000 --> 49:10.000
how hot is something going to get

49:10.000 --> 49:12.000
and what's the hottest part going to be

49:12.000 --> 49:14.000
because that matters for a lot of engineering terms.

49:14.000 --> 49:18.000
So you can do things like, you know,

49:18.000 --> 49:22.000
make a complex surface here

49:22.000 --> 49:26.000
and say energy is coming in here.

49:26.000 --> 49:29.000
How much of this energy makes its way to here,

49:29.000 --> 49:32.000
to here, here, here.

49:32.000 --> 49:34.000
And it's not just a matter of what,

49:34.000 --> 49:36.000
that's basic geometry calculations to say

49:36.000 --> 49:39.000
how much of this is directly impinging on that surface.

49:39.000 --> 49:41.000
What gets complicated then is you say,

49:41.000 --> 49:44.000
well, this reflects 50% of its light

49:44.000 --> 49:48.000
and that 50% goes to all of these different ones here.

49:48.000 --> 49:52.000
And this one reflects 50% and that goes to all the ones here.

49:52.000 --> 49:55.000
And, you know, in theory, you go,

49:55.000 --> 49:57.000
if you're doing everything floating point math,

49:57.000 --> 49:59.000
you can keep saying you can bounce it 100 times

49:59.000 --> 50:04.000
and say you get, well, 0.0001% winds up coming back to another spot.

50:04.000 --> 50:07.000
At some point you just say it's converged well enough,

50:07.000 --> 50:09.000
this solution is not going to change much

50:09.000 --> 50:13.000
no matter how many more bounces that you do.

50:13.000 --> 50:16.000
So the radiosity solutions work by creating

50:16.000 --> 50:21.000
this giant linear algebra matrix of coefficients

50:21.000 --> 50:24.000
where you say you identify all of your surfaces

50:24.000 --> 50:27.000
and you say how much can, what form factor,

50:27.000 --> 50:29.000
what fraction of the energy goes

50:29.000 --> 50:31.000
to all of the other different surfaces.

50:31.000 --> 50:34.000
And then you may be solving this 10,000 by 10,000 matrix

50:34.000 --> 50:37.000
and there was a lot of work on the optimizations

50:37.000 --> 50:41.000
that go into solving this more effectively.

50:41.000 --> 50:44.000
But there are two reasons why radiosity

50:44.000 --> 50:47.000
is not a particularly relevant technique

50:47.000 --> 50:49.000
for computer graphics anymore.

50:49.000 --> 50:52.000
One aspect that it sort of glossed over

50:52.000 --> 50:54.000
was the notion of occlusion,

50:54.000 --> 50:57.000
where if you've got a surface,

50:57.000 --> 50:59.000
if this goes out here

50:59.000 --> 51:02.000
and you go around the dark corner,

51:02.000 --> 51:04.000
we've got this surface here,

51:04.000 --> 51:07.000
it's clear that it can't see this surface at all.

51:07.000 --> 51:10.000
It can see this surface, this surface,

51:10.000 --> 51:12.000
it can see part of this surface,

51:12.000 --> 51:14.000
a fraction of it, and it can see

51:14.000 --> 51:17.000
an even smaller part of this surface over here.

51:17.000 --> 51:20.000
So you have to calculate these occlusion terms

51:20.000 --> 51:23.000
where you're saying each surface,

51:23.000 --> 51:26.000
unless you're in your deformed, stretched icosahedron

51:26.000 --> 51:31.000
or some solid that has no convex,

51:31.000 --> 51:33.000
no concavities inside it,

51:33.000 --> 51:36.000
you're going to have these aspects of occlusion.

51:36.000 --> 51:39.000
And this becomes a very, very difficult thing

51:39.000 --> 51:41.000
to solve completely analytically.

51:41.000 --> 51:44.000
If you're trying to stay in just analytic world

51:44.000 --> 51:46.000
and you try to solve, well, okay,

51:46.000 --> 51:48.000
we have this surface, including this surface,

51:48.000 --> 51:51.000
and then another surface here and another surface here,

51:51.000 --> 51:54.000
it's the potentially visible set problem

51:54.000 --> 51:58.000
on every polygon, and it's an analytic nightmare.

51:58.000 --> 52:01.000
So you wind up solving this by approximating.

52:01.000 --> 52:04.000
You just say, all right, I've got a surface here,

52:04.000 --> 52:07.000
I'll throw a bunch of rays to test out here,

52:07.000 --> 52:09.000
and I'll throw 20 rays out,

52:09.000 --> 52:12.000
and if 10 of them get through, I'll say I'm 50% occluded.

52:12.000 --> 52:15.000
Now, a purist will start blanching and saying,

52:15.000 --> 52:18.000
yeah, but that's random, there's this randomness,

52:18.000 --> 52:21.000
you might be misestimating, there could be pathological cases,

52:22.000 --> 52:24.000
and there's some truth to that.

52:24.000 --> 52:26.000
Anytime that you're sampling things,

52:26.000 --> 52:29.000
there are sampling cases that can turn out pathological.

52:29.000 --> 52:31.000
But the other side of that then goes,

52:31.000 --> 52:34.000
it's like, well, we're tracing rays.

52:34.000 --> 52:37.000
We have another technique that involves lots of tracing rays

52:37.000 --> 52:39.000
and come about it from a different route,

52:39.000 --> 52:42.000
which is to say, well, let's start with ray tracing,

52:42.000 --> 52:44.000
and let's try and solve the global illumination problem

52:44.000 --> 52:46.000
using nothing but ray tracing,

52:46.000 --> 52:48.000
which leads to path tracing.

52:52.000 --> 52:55.000
So you could make a rendering solution,

52:55.000 --> 52:58.000
a rendering program where you start with your light emitter,

52:58.000 --> 53:01.000
you throw photons out in all directions,

53:01.000 --> 53:04.000
you have your cube here,

53:04.000 --> 53:09.000
and somewhere you have your eye.

53:11.000 --> 53:15.000
You will get a physically accurate image

53:15.000 --> 53:19.000
if you throw random rays, pick a random direction,

53:19.000 --> 53:22.000
it goes down, some of them go off here, some of them go up here,

53:22.000 --> 53:26.000
but eventually some of them wind up hitting a surface.

53:26.000 --> 53:29.000
And then based on what that surface is,

53:29.000 --> 53:32.000
you determine which direction the light goes out.

53:32.000 --> 53:34.000
It's going to be random.

53:34.000 --> 53:36.000
Again, your perfect reflector would not be random,

53:36.000 --> 53:39.000
it would go off in exactly the perfect reflection direction.

53:39.000 --> 53:43.000
All other materials will throw light in essentially all directions,

53:43.000 --> 53:45.000
but with different distributions,

53:45.000 --> 53:48.000
there will be more bias towards the reflection direction,

53:48.000 --> 53:50.000
there will be a chance that they go everywhere.

53:50.000 --> 53:54.000
So one of your billions of light rays goes out, hits there,

53:54.000 --> 53:57.000
it decides it's going to reflect up, another one goes out, hits here,

53:57.000 --> 53:59.000
it's going to reflect over,

53:59.000 --> 54:03.000
but eventually some ray is going to come down, hit a point here,

54:03.000 --> 54:06.000
and then reflect at exactly the direction that goes over

54:06.000 --> 54:08.000
and hits the surface of your eye,

54:08.000 --> 54:12.000
which the lens can then focus into something that you can perceive.

54:12.000 --> 54:15.000
And this has an interesting biological side to it.

54:15.000 --> 54:18.000
The larger an eye is, the more light it can collect,

54:18.000 --> 54:21.000
which is why animals that will generally hunt at night

54:21.000 --> 54:24.000
can have larger eyes, larger openings into their eye,

54:24.000 --> 54:27.000
and why telescopes get bigger to see more.

54:27.000 --> 54:29.000
This is what's happening in reality.

54:29.000 --> 54:33.000
Zillions and zillions of photons come off, they bounce around,

54:33.000 --> 54:37.000
and eventually some tiny fraction of them hit the lens of your eye

54:37.000 --> 54:39.000
or your detector or whatever you're using,

54:39.000 --> 54:42.000
and can be resolved into an image.

54:42.000 --> 54:44.000
So you can make an image like this.

54:44.000 --> 54:45.000
People have done it.

54:45.000 --> 54:48.000
It is extraordinarily inefficient,

54:48.000 --> 54:50.000
but you can solve everything with it.

54:50.000 --> 54:52.000
This is a complete and accurate solution.

54:52.000 --> 54:57.000
As accurate as your analysis of what the light's distribution is

54:57.000 --> 54:59.000
and what the surface's distributions are,

54:59.000 --> 55:01.000
this can be as good as that.

55:01.000 --> 55:04.000
You can have your extra surface up here

55:04.000 --> 55:07.000
where you hit the ceiling, you bounce back,

55:07.000 --> 55:10.000
you hit a wall over here, you bounce back over,

55:10.000 --> 55:13.000
and then eventually make your way to the eye.

55:13.000 --> 55:14.000
And you start thinking,

55:14.000 --> 55:17.000
well, you can have 10 bounces going in a random direction.

55:17.000 --> 55:20.000
Your eye is only some handful of millimeters across,

55:20.000 --> 55:22.000
but you're projecting an area this size.

55:22.000 --> 55:24.000
How many traces do you have to do?

55:24.000 --> 55:27.000
Well, you have to do billions and billions,

55:27.000 --> 55:30.000
and you wind up with a very noisy image at that.

55:30.000 --> 55:31.000
But if you did enough of them,

55:31.000 --> 55:34.000
this would come out with the right solution.

55:34.000 --> 55:36.000
Trace array, it either gets absorbed

55:36.000 --> 55:39.000
or it reflects into a different way or transmits through it.

55:39.000 --> 55:41.000
You've got this whole, the model that you use,

55:41.000 --> 55:46.000
the bidirectional subsurface scattering distribution function.

55:46.000 --> 55:49.000
So as accurate as that is, determines what happens to the lights.

55:49.000 --> 55:51.000
You could have models of the lights.

55:51.000 --> 55:54.000
There are these standards like IES light tables that have,

55:54.000 --> 55:56.000
you know, those particular lights,

55:56.000 --> 55:58.000
you could look up what's the distribution of photons

55:58.000 --> 55:59.000
that come off of them.

55:59.000 --> 56:01.000
You could look it up for all the different ones.

56:01.000 --> 56:05.000
And as good as the data is, your simulation can be

56:05.000 --> 56:08.000
as good as what you feed it.

56:08.000 --> 56:11.000
But it's hopelessly, hopelessly inefficient.

56:11.000 --> 56:14.000
What we wind up doing in different ways

56:14.000 --> 56:16.000
that can be reasonable approximations

56:16.000 --> 56:21.000
are instead of tracing, throwing rays out from the light,

56:21.000 --> 56:24.000
which are mostly going to go nowhere near what you want,

56:24.000 --> 56:28.000
you can reverse the trace and go from your eyes

56:28.000 --> 56:31.000
like in the kind of classic ray tracing.

56:31.000 --> 56:33.000
Go to the surface.

56:33.000 --> 56:37.000
And then you start getting into the cases where one of the key,

56:37.000 --> 56:39.000
one of the sort of buzzwords in high-end rendering

56:39.000 --> 56:43.000
is whether a renderer is biased or unbiased.

56:43.000 --> 56:47.000
A biased renderer is not necessarily perfect physics,

56:47.000 --> 56:50.000
but it's almost, they do it because it's going to be a lot faster.

56:50.000 --> 56:52.000
Like the standard thing that you do,

56:52.000 --> 56:54.000
if you don't mind being a biased renderer,

56:54.000 --> 56:56.000
you say, well, I have all these directions

56:56.000 --> 56:58.000
that I could go to the world.

56:58.000 --> 56:59.000
I could go up to the ceiling.

56:59.000 --> 57:01.000
I could go down to the floor.

57:01.000 --> 57:03.000
But I know I've got all of these lights up here,

57:03.000 --> 57:06.000
so I'm going to send most of my rays towards the lights

57:06.000 --> 57:09.000
because those are almost certainly going to be the things

57:09.000 --> 57:11.000
that really make a difference.

57:11.000 --> 57:13.000
So you go, you hit your point,

57:13.000 --> 57:16.000
and you say trace against every light.

57:16.000 --> 57:18.000
You've got three lights going here.

57:18.000 --> 57:20.000
Let's run a trace up against them,

57:20.000 --> 57:23.000
check for occluders, solid things blocking it off.

57:23.000 --> 57:26.000
And then you start throwing random amounts of rays

57:26.000 --> 57:28.000
in different directions.

57:28.000 --> 57:30.000
You can be smart and base it on what the character

57:30.000 --> 57:32.000
of the surface is.

57:32.000 --> 57:36.000
It again comes down to these distribution functions

57:36.000 --> 57:38.000
where you could have rays where it's more likely

57:38.000 --> 57:40.000
that if light comes in this way,

57:40.000 --> 57:43.000
it's more likely that it's going to make it out towards your eye,

57:43.000 --> 57:46.000
so it makes sense to sample that more often.

57:46.000 --> 57:49.000
And there is tons of work going on to this day.

57:49.000 --> 57:52.000
This is sort of where the active state of the art

57:52.000 --> 57:54.000
of graphics rendering is,

57:54.000 --> 57:57.000
where you, how you optimize this path tracing

57:57.000 --> 57:59.000
to be more efficient in different cases.

57:59.000 --> 58:03.000
But it is always then you're making your approximations

58:03.000 --> 58:05.000
on what you want to do.

58:05.000 --> 58:07.000
Because you can make, like the problem with this

58:07.000 --> 58:10.000
is if you have, if you're biased

58:10.000 --> 58:13.000
and you trace specifically to certain lights,

58:13.000 --> 58:16.000
there could be combinations of surfaces here,

58:16.000 --> 58:19.000
like you might have a surface here which is slightly emissive,

58:19.000 --> 58:22.000
and if you wind up hitting that because you were tracing

58:22.000 --> 58:24.000
towards the light, that's going to get overrepresented

58:24.000 --> 58:27.000
based on, you know, versus something that's over here

58:27.000 --> 58:30.000
that wasn't in the direction of one of the lights.

58:30.000 --> 58:33.000
But this approach, you know, it pretty much works.

58:33.000 --> 58:37.000
We do, like for the baking in idTech 5,

58:37.000 --> 58:40.000
we have a very primitive lighting solution

58:40.000 --> 58:42.000
because even though we do it offline,

58:42.000 --> 58:45.000
we have to, the surface area of one of the maps in Rage

58:45.000 --> 58:48.000
is about as much as the pixels that go into a feature film

58:48.000 --> 58:50.000
and we have turnaround time.

58:50.000 --> 58:53.000
So clearly we can't do these billions of ray traces

58:53.000 --> 58:55.000
for every, what would be a frame of that.

58:55.000 --> 58:57.000
We, you know, we have to keep these down

58:57.000 --> 58:59.000
to some credible amount of time.

58:59.000 --> 59:03.000
So what we do is when we're rasterizing a surface,

59:03.000 --> 59:05.000
we don't even have the viewer at all.

59:05.000 --> 59:07.000
We're doing a view-independent approach

59:07.000 --> 59:09.000
for the global illumination.

59:09.000 --> 59:11.000
And again, the terminology is problematic

59:11.000 --> 59:13.000
because we have radiosity as terminology

59:13.000 --> 59:16.000
in a lot of places as a synonym for global illumination

59:16.000 --> 59:18.000
and technically it's not, it shouldn't be that way.

59:18.000 --> 59:20.000
I mean, we have a visualizer called Rad Preview

59:20.000 --> 59:23.000
even though it does not do a matrix calculation

59:23.000 --> 59:25.000
for radiosity at all.

59:25.000 --> 59:28.000
It's, you know, it is based on this more of a tracing approach.

59:28.000 --> 59:31.000
So we get our surfaces, we look at all the lights

59:31.000 --> 59:33.000
that we think should be affecting us,

59:33.000 --> 59:35.000
we trace to them together,

59:35.000 --> 59:37.000
we're affecting us.

59:37.000 --> 59:39.000
We trace to them to get our shadows

59:39.000 --> 59:41.000
and sample them to make soft shadows.

59:41.000 --> 59:43.000
In fact, that's another important thing.

59:43.000 --> 59:45.000
The way you get a soft shadow

59:45.000 --> 59:47.000
is if you've got a surface

59:47.000 --> 59:50.000
and you've got an object that's going to cast a shadow,

59:50.000 --> 59:54.000
if you have, if you had a point light source,

59:54.000 --> 59:56.000
so it was nothing but a teeny tiny point

59:56.000 --> 59:58.000
that all the energy came out of,

59:58.000 --> 01:00:01.000
then you would have a hard shadow edge.

01:00:01.000 --> 01:00:03.000
It would look like Doom 3

01:00:03.000 --> 01:00:05.000
where you've got fully illuminated

01:00:05.000 --> 01:00:07.000
and then fully shadowed.

01:00:07.000 --> 01:00:10.000
In reality, there's no such thing as a point light source

01:00:10.000 --> 01:00:13.000
and this is an important thing to realize.

01:00:13.000 --> 01:00:16.000
Everything, even if you look at a light bulb,

01:00:16.000 --> 01:00:18.000
a dangling incandescent light bulb,

01:00:18.000 --> 01:00:20.000
the photons are actually coming out

01:00:20.000 --> 01:00:21.000
not off of a point,

01:00:21.000 --> 01:00:23.000
but off of a little zigzaggy filament

01:00:23.000 --> 01:00:24.000
that's inside that.

01:00:24.000 --> 01:00:26.000
It has an area and the photons come off

01:00:26.000 --> 01:00:28.000
distributed from that area.

01:00:28.000 --> 01:00:30.000
Now, the sharpness of a shadow

01:00:30.000 --> 01:00:34.000
depends on the ratio of the area of that emitter

01:00:34.000 --> 01:00:36.000
to the distance that it's going across.

01:00:36.000 --> 01:00:40.000
When you have a great big, broad fluorescent light assembly

01:00:40.000 --> 01:00:43.000
and you've got a small occluder here,

01:00:43.000 --> 01:00:47.000
everything is going to be lit to some degree.

01:00:47.000 --> 01:00:49.000
You have...

01:00:49.000 --> 01:00:51.000
Yeah, so in this case,

01:00:51.000 --> 01:00:54.000
you might have only the very smallest area there

01:00:54.000 --> 01:00:56.000
that would be solid, completely shadowed,

01:00:56.000 --> 01:00:57.000
but as you move over,

01:00:57.000 --> 01:00:59.000
you start to be able to see part of the light.

01:00:59.000 --> 01:01:02.000
So it gets brighter and brighter

01:01:02.000 --> 01:01:05.000
until you get to the point over here

01:01:05.000 --> 01:01:08.000
where you can see the entire light emitter.

01:01:08.000 --> 01:01:10.000
So we have...

01:01:10.000 --> 01:01:12.000
To get the soft shadows in rages,

01:01:12.000 --> 01:01:13.000
I'm...

01:01:13.000 --> 01:01:16.000
Well, so if you looked at the original, the earlier quakes,

01:01:16.000 --> 01:01:18.000
there were soft shadows in there,

01:01:18.000 --> 01:01:20.000
but they weren't a matter of calculating soft shadows.

01:01:20.000 --> 01:01:23.000
They were because we made a hard shadow calculation

01:01:23.000 --> 01:01:25.000
and then we interpolated between it,

01:01:25.000 --> 01:01:27.000
which is why you've got kind of the blurry,

01:01:27.000 --> 01:01:29.000
stair-steppy edges there.

01:01:29.000 --> 01:01:33.000
For Tech 5, we actually send a number of shadow samples,

01:01:33.000 --> 01:01:34.000
and this is one of those things

01:01:34.000 --> 01:01:36.000
that gets into performance trade-offs

01:01:36.000 --> 01:01:41.000
where if a designer sets a very large area for a light source,

01:01:41.000 --> 01:01:43.000
then it will have...

01:01:43.000 --> 01:01:46.000
You'll have a very broad area of changing shadow resolutions,

01:01:46.000 --> 01:01:49.000
and if you only put 16 tests to it,

01:01:49.000 --> 01:01:51.000
that means you only have the possibility

01:01:51.000 --> 01:01:53.000
of 16 bands of different lighting,

01:01:53.000 --> 01:01:55.000
and that's in the best case if it comes out

01:01:55.000 --> 01:01:58.000
exactly for your samples where they do their best good.

01:01:58.000 --> 01:02:01.000
And it's completely possible to have,

01:02:01.000 --> 01:02:03.000
if you've got a broad area light source,

01:02:03.000 --> 01:02:05.000
to need hundreds of samples for every pixel

01:02:05.000 --> 01:02:08.000
to determine how bright that should be.

01:02:08.000 --> 01:02:11.000
And it can get worse in a lot of cases.

01:02:11.000 --> 01:02:14.000
A lot of offline rendering may use thousands of samples

01:02:14.000 --> 01:02:17.000
per fragment when you get into the global illumination.

01:02:17.000 --> 01:02:20.000
So what we do from the direct lighting,

01:02:20.000 --> 01:02:23.000
obviously it's a biased lighting approach there

01:02:23.000 --> 01:02:25.000
because we sample directly to the lights,

01:02:25.000 --> 01:02:29.000
but then we send out random rays from the surface

01:02:29.000 --> 01:02:31.000
to see what else it hits,

01:02:31.000 --> 01:02:34.000
and when it goes out and hits this surface up here,

01:02:34.000 --> 01:02:37.000
then we apply a simplified version of the lighting to that.

01:02:37.000 --> 01:02:39.000
We don't do all the full soft shadows,

01:02:39.000 --> 01:02:42.000
but we do basic lighting approaches.

01:02:42.000 --> 01:02:45.000
We've had options to do multiple additional bounces,

01:02:45.000 --> 01:02:47.000
but this is what we live with

01:02:47.000 --> 01:02:50.000
is some approach of sampling the global environment,

01:02:50.000 --> 01:02:53.000
and we don't do it lots for each pixel.

01:02:53.000 --> 01:02:55.000
What we wind up doing is

01:02:55.000 --> 01:03:01.000
each point throws one or a few samples into different directions,

01:03:01.000 --> 01:03:03.000
and then when we average them for this pixel,

01:03:03.000 --> 01:03:06.000
we average over a broader range of pixels.

01:03:06.000 --> 01:03:08.000
And these are the types of trade-offs

01:03:08.000 --> 01:03:11.000
that everybody doing rendering makes different trades like this,

01:03:11.000 --> 01:03:14.000
where you decide what you think is most important,

01:03:14.000 --> 01:03:17.000
how much time you can afford to spend on things,

01:03:17.000 --> 01:03:22.000
and you make your choices and you live with them after that.

01:03:22.000 --> 01:03:24.000
But we know doing it right

01:03:24.000 --> 01:03:29.000
is just a matter of throwing billions of rays in an ideal case.

01:03:29.000 --> 01:03:32.000
You have to throw lots and lots into the environment.

01:03:32.000 --> 01:03:34.000
We can make decent approximations now,

01:03:34.000 --> 01:03:38.000
but we're going to soak up all the additional computing power

01:03:38.000 --> 01:03:39.000
that can be given.

01:03:39.000 --> 01:03:41.000
One of the saws in the offline rendering world

01:03:41.000 --> 01:03:46.000
is that the frames will always take a half hour to render in most studios.

01:03:46.000 --> 01:03:49.000
The more power they get, just the more things that they add to it.

01:03:49.000 --> 01:03:52.000
There's hope that that's not a law of nature

01:03:52.000 --> 01:03:55.000
that we are getting to faster turnarounds,

01:03:55.000 --> 01:03:59.000
kind of like the pace of hard drive size versus usage.

01:03:59.000 --> 01:04:04.000
But it does seem likely that the path forward is lots and lots of rays,

01:04:04.000 --> 01:04:07.000
physically accurate material definitions,

01:04:07.000 --> 01:04:13.000
and approaches that are approximations of the sampling of path tracing.

01:04:13.000 --> 01:04:14.000
We can do...

01:04:14.000 --> 01:04:17.000
There are some neat demos going around today,

01:04:17.000 --> 01:04:21.000
like the Brigade Path Tracing demo, which is real-time,

01:04:21.000 --> 01:04:25.000
and it's doing simple path tracing from sort of a parallel outdoor light,

01:04:25.000 --> 01:04:28.000
and it's noisy and fizzly as it comes in,

01:04:28.000 --> 01:04:31.000
but you can stop and watch it kind of come in more crisply.

01:04:31.000 --> 01:04:35.000
And eventually, this is going to be the way things go.

01:04:35.000 --> 01:04:37.000
This is the way we're going to be rendering,

01:04:37.000 --> 01:04:42.000
but we still have maybe a couple orders of magnitude before it's really competitive.

01:04:42.000 --> 01:04:45.000
I think one more order of magnitude in performance,

01:04:45.000 --> 01:04:48.000
and you'll start seeing it used for some real things,

01:04:48.000 --> 01:04:52.000
but you have to have a good reason to step away from rasterization.

01:04:52.000 --> 01:04:55.000
But probably when we get two orders of magnitude,

01:04:55.000 --> 01:04:58.000
then you start seeing it as one of the more general tools.

01:04:58.000 --> 01:05:01.000
And the reason that it's winning in the offline world,

01:05:01.000 --> 01:05:03.000
even though it's still slower,

01:05:03.000 --> 01:05:05.000
people still care about how long their renderings take,

01:05:05.000 --> 01:05:08.000
even if you're making a feature film or a TV commercial.

01:05:08.000 --> 01:05:10.000
It matters for your iteration time.

01:05:11.000 --> 01:05:16.000
The sense is that you get more out of this being understandable

01:05:16.000 --> 01:05:19.000
with rasterization, environment maps, shadow maps.

01:05:19.000 --> 01:05:22.000
There are all these knobs that people just...

01:05:22.000 --> 01:05:24.000
The best people know what they mean,

01:05:24.000 --> 01:05:29.000
but 90% of the people working in visual and computer graphics,

01:05:29.000 --> 01:05:32.000
they have these things that they know push this this way,

01:05:32.000 --> 01:05:34.000
and it kind of does something,

01:05:34.000 --> 01:05:36.000
but it's a lot of black magic

01:05:36.000 --> 01:05:39.000
and a lot of things that are just not at all physically plausible.

01:05:39.000 --> 01:05:42.000
And this is one of the things that I've been working with the artists at IID

01:05:42.000 --> 01:05:44.000
in the last several months

01:05:44.000 --> 01:05:47.000
to start moving us towards this more physically-based sense of things,

01:05:47.000 --> 01:05:51.000
where if you just use your standard diffuse specular roughness,

01:05:51.000 --> 01:05:55.000
you can have materials just make no sense at all in the real world.

01:05:55.000 --> 01:05:58.000
You can have things that reflect more energy than come in

01:05:58.000 --> 01:06:01.000
when you've got a bright diffuse and a bright specular.

01:06:01.000 --> 01:06:03.000
And there's...

01:06:03.000 --> 01:06:06.000
The real step that we've had to make education-wise

01:06:06.000 --> 01:06:09.000
is treating these maps not just as something that you paint in Photoshop,

01:06:09.000 --> 01:06:12.000
but how you define the materials that are there,

01:06:12.000 --> 01:06:14.000
where it shouldn't be that...

01:06:14.000 --> 01:06:16.000
If you're looking at something that's a belt buckle, you say,

01:06:16.000 --> 01:06:18.000
okay, this is metal, it's going to have a high specular,

01:06:18.000 --> 01:06:21.000
it's going to have a low diffuse, the specular may have color in it,

01:06:21.000 --> 01:06:24.000
it's going to have a high power or a low roughness,

01:06:24.000 --> 01:06:26.000
depending on how you're formulating it,

01:06:26.000 --> 01:06:28.000
because that's what it is.

01:06:28.000 --> 01:06:30.000
But far too often in, you know,

01:06:30.000 --> 01:06:34.000
for the past decade in computer games, especially,

01:06:34.000 --> 01:06:37.000
the maps that have been fed into these things,

01:06:37.000 --> 01:06:39.000
the diffuse maps, specular maps,

01:06:39.000 --> 01:06:41.000
whether they're gloss or roughness or whatever you term it,

01:06:41.000 --> 01:06:43.000
they're things that are painted in,

01:06:43.000 --> 01:06:45.000
where a lot of times you'd see a specular map where,

01:06:45.000 --> 01:06:48.000
yeah, you take your diffuse map and you kind of monochromize

01:06:48.000 --> 01:06:52.000
and maybe color shift it and you stick it into the specular,

01:06:52.000 --> 01:06:54.000
and you wind up with things that...

01:06:54.000 --> 01:06:57.000
Yes, it makes parts of it shiny and parts of it not shiny,

01:06:57.000 --> 01:06:59.000
but some of these things, like,

01:06:59.000 --> 01:07:02.000
I don't actually think that there is a physical material that exists

01:07:02.000 --> 01:07:04.000
in the red specular reflection color.

01:07:04.000 --> 01:07:07.000
I mean, maybe there is, but it's certainly not common.

01:07:07.000 --> 01:07:11.000
You know, specular colors are generally white except for metals,

01:07:11.000 --> 01:07:14.000
which can be the color of the base surface.

01:07:14.000 --> 01:07:16.000
So there's...

01:07:16.000 --> 01:07:19.000
The biggest thing that's going to be happening for making games look better

01:07:19.000 --> 01:07:22.000
is really not advancing the graphics technologies,

01:07:22.000 --> 01:07:24.000
at least for our studio.

01:07:24.000 --> 01:07:28.000
It's the matter of getting materials that actually make sense.

01:07:28.000 --> 01:07:31.000
And once you're there, then you can start improving,

01:07:31.000 --> 01:07:35.000
the things that you do with adding your better global light transport,

01:07:35.000 --> 01:07:37.000
all the other cases there.

01:07:37.000 --> 01:07:41.000
One more thing before I cut out from the time warning here.

01:07:41.000 --> 01:07:45.000
So the cost of all of this, billions and billions of rays,

01:07:45.000 --> 01:07:49.000
one technique that's gotten a lot of currency in recent years

01:07:49.000 --> 01:07:51.000
is ambient occlusion.

01:07:51.000 --> 01:07:53.000
Now, to explain what ambient occlusion is,

01:07:53.000 --> 01:07:55.000
it's another one of those great big hacks,

01:07:55.000 --> 01:07:57.000
but it works, you know, usefully,

01:07:57.000 --> 01:08:00.000
and it's kind of standard fare and a lot of offline work.

01:08:00.000 --> 01:08:06.000
So if you have an object that's got some concavity here,

01:08:06.000 --> 01:08:09.000
and you've got the light shining on it from here,

01:08:09.000 --> 01:08:11.000
so you light it all up.

01:08:11.000 --> 01:08:14.000
In an ideal world, you'd be doing all of this path tracing,

01:08:14.000 --> 01:08:17.000
and you would say that, okay, some of the rays hit here,

01:08:17.000 --> 01:08:19.000
they bounce here, they bounce around into here,

01:08:19.000 --> 01:08:22.000
some of them go up here, hit here, and get into that.

01:08:22.000 --> 01:08:26.000
So the path, the tortuous path that light can take to get into there,

01:08:26.000 --> 01:08:28.000
that's what you really want to deal with.

01:08:28.000 --> 01:08:30.000
If you've got your white surface there,

01:08:30.000 --> 01:08:34.000
you might need to trace 10 bounces from thousands and thousands of things.

01:08:34.000 --> 01:08:37.000
The observation that ambient occlusion is based on

01:08:37.000 --> 01:08:42.000
is that when something has other things very close to it,

01:08:42.000 --> 01:08:47.000
it is very likely to be not as bright as things that...

01:08:47.000 --> 01:08:49.000
but do not have things next to it.

01:08:49.000 --> 01:08:51.000
If you've got a flat surface and you're lit,

01:08:51.000 --> 01:08:53.000
you know, there's nothing that's going to be braided

01:08:53.000 --> 01:08:55.000
that's taking anything away from it,

01:08:55.000 --> 01:09:00.000
but if you have a flat surface that, you know, has an occluder here,

01:09:00.000 --> 01:09:04.000
this area right here, it might be directly seeing the light,

01:09:04.000 --> 01:09:08.000
and it might be seeing everything in this part of the hemisphere,

01:09:08.000 --> 01:09:10.000
but part of it's going to be hitting this,

01:09:10.000 --> 01:09:12.000
and some of that may be going and seeing the light,

01:09:12.000 --> 01:09:14.000
some of it may be bouncing in different directions.

01:09:14.000 --> 01:09:19.000
So ambient occlusion, all it does is instead of sampling the whole world,

01:09:19.000 --> 01:09:24.000
it samples just a small area around the point that you're working with.

01:09:24.000 --> 01:09:29.000
And, importantly, perhaps even more importantly than the scope of what it's sampling,

01:09:29.000 --> 01:09:32.000
when it hits things, it doesn't worry about the surface model.

01:09:32.000 --> 01:09:36.000
It doesn't run, you know, BRDF or BRSSD or whatever.

01:09:36.000 --> 01:09:40.000
All it does is say, either I hit something close or I didn't hit something,

01:09:40.000 --> 01:09:43.000
and maybe keep track of how far away it is.

01:09:43.000 --> 01:09:49.000
And if you get something like this where, okay, there's some light coming in here,

01:09:49.000 --> 01:09:51.000
I can see this, but I trace out,

01:09:51.000 --> 01:09:56.000
and 90% of everything around me is hitting something else sort of close.

01:09:56.000 --> 01:09:59.000
So based on that, I'm going to darken it down,

01:09:59.000 --> 01:10:04.000
just on the assumption that if I did run a global illumination trace through all of this,

01:10:04.000 --> 01:10:09.000
that it would come out and say that I'm not as bright as something that's next to me that's open.

01:10:09.000 --> 01:10:13.000
So something out here, that'll get the full value of whatever it calculates,

01:10:13.000 --> 01:10:17.000
and as you move towards here, some of it's starting to get darker,

01:10:17.000 --> 01:10:20.000
until you move all the way in here, we're almost all of it.

01:10:20.000 --> 01:10:27.000
And it's a very, very crude approximation of just assuming that whatever it hits isn't going to be bright.

01:10:27.000 --> 01:10:31.000
And you can break that by having cases where, you know, if you had,

01:10:31.000 --> 01:10:35.000
if the light was coming in right here, where it's directly illuminating all of that,

01:10:35.000 --> 01:10:40.000
and if that was a white surface, you could have more light coming down onto there rather than less.

01:10:40.000 --> 01:10:43.000
Ambient occlusion would say, it's got nearby things, it should always be less,

01:10:43.000 --> 01:10:48.000
but you could actually be getting more light from the global illumination in those cases.

01:10:48.000 --> 01:10:51.000
It's just one in a long line of all of these approximations that we do.

01:10:51.000 --> 01:10:54.000
But the takeaway point is, we know what we should do,

01:10:54.000 --> 01:10:58.000
we know what we would do if we had infinite computing power to go with it.

01:10:58.000 --> 01:11:03.000
So all of the things now are approximations onto it, ways that we can model our data,

01:11:03.000 --> 01:11:09.000
ways that we can reduce our number of traces, and optimizations in the code paths to make things go faster.

01:11:09.000 --> 01:11:13.000
And there's lots of work going on with GPU accelerated ray tracing,

01:11:13.000 --> 01:11:17.000
again, some of the caustic graphics work for optimizing it in some other ways.

01:11:17.000 --> 01:11:22.000
And there's lots of active research going on about what corners can you cut.

01:11:22.000 --> 01:11:26.000
And it's interesting because, again, we know what the right way,

01:11:26.000 --> 01:11:30.000
zillions of photons coming out, collect them all at the lens of your eye,

01:11:30.000 --> 01:11:32.000
and sort of make an image from that.

01:11:32.000 --> 01:11:35.000
But it's going to be research for the coming decade or more,

01:11:35.000 --> 01:11:39.000
as we kind of work out what the very best approximations for this are.

01:11:39.000 --> 01:11:42.000
So I ran a little bit over my one hour, but I can start taking questions now.

01:11:42.000 --> 01:11:44.000
So we've got the microphone there.

01:11:52.000 --> 01:11:56.000
Up until about maybe five to seven years ago,

01:11:56.000 --> 01:12:03.000
there was every year an obvious increase in realism in offline rendering for especially movies.

01:12:03.000 --> 01:12:09.000
And I'm wondering, since a lot of the things that you've mentioned here have been around

01:12:09.000 --> 01:12:15.000
for as long as I can remember, I mean, Povre and all that decades ago,

01:12:15.000 --> 01:12:23.000
what is the main driver of that increase in visual fidelity or realism in the more recent years?

01:12:23.000 --> 01:12:25.000
So a couple of factors.

01:12:25.000 --> 01:12:28.000
One is actually getting smarter about the materials,

01:12:28.000 --> 01:12:32.000
where you can throw in all of this light transport stuff,

01:12:32.000 --> 01:12:35.000
and if you don't have good materials for it, it won't matter.

01:12:35.000 --> 01:12:37.000
You'll still get non-realistic images.

01:12:37.000 --> 01:12:40.000
So better data collection, some of the laser scanning,

01:12:40.000 --> 01:12:43.000
and the different things that let us get really good material qualities,

01:12:43.000 --> 01:12:44.000
that's been one factor.

01:12:44.000 --> 01:12:50.000
But probably the biggest factor has just been people being willing to throw that much more processing power at things.

01:12:50.000 --> 01:12:55.000
I had to go ahead and, instead of letting these early cases where it could take days to render an image,

01:12:55.000 --> 01:12:57.000
that's never going to get used in production,

01:12:57.000 --> 01:13:02.000
and all you do is see some of the images in academic research.

01:13:02.000 --> 01:13:07.000
And the problem with that is while some of the academic research would get the formulas right,

01:13:07.000 --> 01:13:09.000
they wouldn't have the data right to go with it,

01:13:09.000 --> 01:13:12.000
where if you've got, it's kind of like programmer art.

01:13:12.000 --> 01:13:18.000
If you wind up with the programmer or the graphics researcher building the test scene for it,

01:13:18.000 --> 01:13:21.000
it's probably not going to be a particularly good model of the world.

01:13:21.000 --> 01:13:24.000
It's going to have too many spherical cow simplifications in it,

01:13:24.000 --> 01:13:28.000
and it just won't be like what you go to a movie studio,

01:13:28.000 --> 01:13:32.000
and they'll get all the grime and the nicks and the dings and everything

01:13:32.000 --> 01:13:36.000
that will make it feel like a real lived-in world.

01:13:36.000 --> 01:13:38.000
So I think those are really the two things, materials,

01:13:38.000 --> 01:13:40.000
and then largely getting it into the hands,

01:13:40.000 --> 01:13:44.000
making it reasonable for the people that are going to put the level of craft and detail

01:13:44.000 --> 01:13:46.000
that it needs to represent the world,

01:13:46.000 --> 01:13:48.000
making it feasible for them to use.

01:13:48.000 --> 01:13:52.000
Is that your motivation for educating the artists at IID?

01:13:52.000 --> 01:13:54.000
Well, I actually think it's necessary.

01:13:54.000 --> 01:13:58.000
I think that if you're not getting with physical rendering now,

01:13:58.000 --> 01:14:00.000
you're going to be left behind as an industry.

01:14:00.000 --> 01:14:05.000
It's been interesting watching the offline world,

01:14:05.000 --> 01:14:08.000
where you had the masters of their domain at Pixar.

01:14:08.000 --> 01:14:13.000
Because they had the very best in process and technology for a long time,

01:14:13.000 --> 01:14:16.000
they were sort of stragglers to adopt many of the things with ray tracing

01:14:16.000 --> 01:14:18.000
and physically-based rendering,

01:14:18.000 --> 01:14:20.000
but they've come around for the most part now,

01:14:20.000 --> 01:14:23.000
still using the right tool at the right time.

01:14:23.000 --> 01:14:28.000
But I can't think of many good arguments for not using physically plausible materials.

01:14:28.000 --> 01:14:32.000
I don't think that there are artistic gains to be had by not doing it,

01:14:32.000 --> 01:14:35.000
and there's all sorts of minefields where you can mess yourself up.

01:14:35.000 --> 01:14:37.000
Thank you.

01:14:37.000 --> 01:14:43.000
The very latest versions of OpenGL support pixel and fragment shaders.

01:14:43.000 --> 01:14:47.000
And one of the things that I'm curious about is why you don't use procedural graphics

01:14:47.000 --> 01:14:50.000
and procedural geometry more than you do.

01:14:50.000 --> 01:14:57.000
Okay, so procedural graphics has been the wave of the future for the last 20 years.

01:14:57.000 --> 01:15:02.000
And I think that I actually have a fairly strong and sound argument,

01:15:02.000 --> 01:15:04.000
philosophical stance against this,

01:15:04.000 --> 01:15:12.000
where in the end procedural data is quirky, hard to deal with data compression.

01:15:12.000 --> 01:15:17.000
And one of the things that we are continuing to get more and more of is space,

01:15:17.000 --> 01:15:19.000
the storage that we can get for things.

01:15:19.000 --> 01:15:27.000
So while you can always pick out some niche market where you are going to be extremely constrained on your space,

01:15:27.000 --> 01:15:32.000
and you think, well, mobile should have been maybe the space where procedural stuff comes into its own,

01:15:32.000 --> 01:15:38.000
but that's ramping through all of the storage spaces for everything that it's really not.

01:15:38.000 --> 01:15:40.000
All the standard methods are going on.

01:15:40.000 --> 01:15:45.000
So it's a good tool for making programmer hours,

01:15:45.000 --> 01:15:49.000
but when you want to put it into the hands of the people that are going to...

01:15:49.000 --> 01:15:52.000
If you're modeling the real world, you laser scan everything.

01:15:52.000 --> 01:15:55.000
You go in and say, I'm going to scan this room and I'm going to have a terabyte of data,

01:15:55.000 --> 01:15:58.000
and I'll just render that as an enormous point cloud.

01:15:58.000 --> 01:16:00.000
And that's credible even.

01:16:00.000 --> 01:16:02.000
It's not, we can't ship a game like that yet,

01:16:02.000 --> 01:16:05.000
but that's still within sight of something that we can do.

01:16:05.000 --> 01:16:07.000
And if you want to give it to an artist to create something,

01:16:07.000 --> 01:16:10.000
then they're largely going to be compositing together different things.

01:16:10.000 --> 01:16:16.000
And procedural sources, yeah, you use them for your clouds and your smoke and particle, things like that.

01:16:16.000 --> 01:16:21.000
But this was Pixar's camp for a long time about doing...

01:16:21.000 --> 01:16:26.000
They would create with procedures, analytic procedures rather than textures,

01:16:26.000 --> 01:16:28.000
and that way lost.

01:16:28.000 --> 01:16:31.000
It was really pretty conclusive that nobody wants to do that.

01:16:31.000 --> 01:16:34.000
They want to throw 20 layers of effective painting on top of things,

01:16:34.000 --> 01:16:37.000
and you can still come up with use cases for it,

01:16:37.000 --> 01:16:47.000
but it adds a lot of complexity for a win that outside of poster child cases really isn't there.

01:16:47.000 --> 01:16:53.000
So for your offline rendering, have you ever considered using progressive photon mapping techniques?

01:16:53.000 --> 01:16:57.000
And have you ever had a chance to talk with Henrik Von Jensen about any of that?

01:16:57.000 --> 01:17:01.000
So I wrote a photon mapping version for our system,

01:17:01.000 --> 01:17:06.000
and there's a really interesting aspect to this where...

01:17:06.000 --> 01:17:13.000
So a fundamental aspect of global illumination is that there's no difference between a light emitter and a light reflector,

01:17:13.000 --> 01:17:18.000
where you have to look at saying the photons that come off of this surface are just as good as the photons that come off of that light.

01:17:18.000 --> 01:17:24.000
And when you calculate through, when you make a photon map for something,

01:17:24.000 --> 01:17:27.000
you figure out how many photons you're going to send into the world,

01:17:27.000 --> 01:17:35.000
you create a map of them, and you use that as an accelerator for determining your global illumination solution for each point.

01:17:35.000 --> 01:17:42.000
The problem that I ran into was while that works fine for a single sort of character of a scene,

01:17:42.000 --> 01:17:46.000
for an indoor scene, I found photon mapping to be pretty effective in a lot of ways.

01:17:46.000 --> 01:17:52.000
I mean, you still have all the problems of where you wind up setting things, bleed-throughs in some cases,

01:17:52.000 --> 01:17:54.000
but they're manageable problems.

01:17:54.000 --> 01:18:00.000
But when I ran some numbers and I realized that if you're calculating an outdoor area,

01:18:00.000 --> 01:18:05.000
the amount of light that falls on like one 8.5 by 11 sheet of paper,

01:18:05.000 --> 01:18:10.000
just holding it out in the sun, all of a sudden that surface has all of the photons,

01:18:10.000 --> 01:18:13.000
the same amount of photons that come out of a 100-watt incandescent light bulb,

01:18:13.000 --> 01:18:17.000
and you start saying, well, we have acres and acres of surfaces out here.

01:18:17.000 --> 01:18:21.000
And of course, we're scaling everything down, so it still fits with...

01:18:21.000 --> 01:18:26.000
I completely did not get to any of my output monitors, gamma correction, all that stuff.

01:18:27.000 --> 01:18:30.000
So, I mean, we have all these hacks to kind of normalize it,

01:18:30.000 --> 01:18:36.000
but I found it to be in a situation where you had a bright outdoor area and then a dimmer indoor area,

01:18:36.000 --> 01:18:42.000
you had to have so many photons in the outside to make the dim one come out reasonably

01:18:42.000 --> 01:18:44.000
that it became pretty prohibitive.

01:18:44.000 --> 01:18:50.000
The other reason that we don't do photon maps is that it requires a sequencing

01:18:50.000 --> 01:18:55.000
where the nice thing about distributed ray tracing and the path tracing,

01:18:55.000 --> 01:18:59.000
in its purest form, it's completely embarrassingly parallel.

01:18:59.000 --> 01:19:03.000
Any surface can be done at any time because we run on multi-threads,

01:19:03.000 --> 01:19:06.000
multi-core processors and multiple systems in a cluster,

01:19:06.000 --> 01:19:10.000
and if you want to do something with an intermediate step like a photon map,

01:19:10.000 --> 01:19:14.000
you have to build the photon map in some hopefully parallel way

01:19:14.000 --> 01:19:16.000
and then transfer it to everything else.

01:19:16.000 --> 01:19:22.000
And my very first global illumination solution in the early days of RAGE was GPU accelerated

01:19:22.000 --> 01:19:29.000
and I rendered little hemispheres on the GPU and built up a low-resolution mega-texture of the world

01:19:29.000 --> 01:19:35.000
and used that global illumination, which was reminiscent of a photon map.

01:19:35.000 --> 01:19:39.000
And it was just one of those things that in practice turned out to really be kind of a pain,

01:19:39.000 --> 01:19:45.000
and when we went to a completely separable solution, a lot of problems stopped happening.

01:19:45.000 --> 01:19:50.000
But it was interesting implementing the photon map stuff, going through a few of the cases.

01:19:50.000 --> 01:19:53.000
It's certainly a valid direction right now,

01:19:53.000 --> 01:19:59.000
but I think that in a lot of cases that the necessity to generate that ahead of time

01:19:59.000 --> 01:20:03.000
is a little bit of a hazard for implementation in a lot of parallel cases.

01:20:03.000 --> 01:20:07.000
For running on a single system, if you know you're going to just plow through it all there,

01:20:07.000 --> 01:20:11.000
it's got a lot of benefits. It just hurts a little more in a cluster.

01:20:13.000 --> 01:20:17.000
Hi, so you talked a lot about the geometry and the RAGE tracing, all that sort of stuff.

01:20:17.000 --> 01:20:21.000
I was just curious if you could talk about how you managed the light representations,

01:20:21.000 --> 01:20:25.000
specifically things like fluorescence and that sort of stuff.

01:20:25.000 --> 01:20:30.000
I'm getting another one of my topics that was on my list that I didn't have time to go through.

01:20:30.000 --> 01:20:37.000
So again, the classical computer graphics light is you wind up with three models of lights.

01:20:37.000 --> 01:20:40.000
You've got a point light, a spotlight, and a parallel light,

01:20:40.000 --> 01:20:43.000
and those are our sort of baseline lights in the editor.

01:20:43.000 --> 01:20:48.000
We augment the point lights by giving them an area radius

01:20:48.000 --> 01:20:52.000
so we can get the soft shadows and so we can add the distributed RAGE tracing to that.

01:20:52.000 --> 01:20:58.000
The biggest problem though is that all of our lights are completely physically implausible

01:20:58.000 --> 01:21:02.000
because they're physically bounded, with the exception of the parallel light.

01:21:02.000 --> 01:21:09.000
Some of this is history. When we go from Quake 1 all the way up through, especially Doom 3,

01:21:09.000 --> 01:21:14.000
we built all of our lights out of textures because Doom 3 was all dynamic,

01:21:14.000 --> 01:21:19.000
so we multiplied two textures together where you would have a projection texture and a fall-off texture,

01:21:19.000 --> 01:21:24.000
so they occupied this physical space in the world,

01:21:24.000 --> 01:21:27.000
which is great for culling reasons where you can say,

01:21:27.000 --> 01:21:31.000
alright, in Doom 3 we tried to say no more than three lights hitting a surface

01:21:31.000 --> 01:21:34.000
because it was a linear cost, every light cost more on that surface.

01:21:34.000 --> 01:21:39.000
We wound up with these lights that were very physically implausible.

01:21:39.000 --> 01:21:45.000
If you're doing this multiplying two textures together, you can make a Gaussian fall-off light,

01:21:45.000 --> 01:21:48.000
which is a pleasant light to work with that is radially symmetric,

01:21:48.000 --> 01:21:51.000
but most of the lights in the game wound up being our square light,

01:21:51.000 --> 01:21:56.000
which is a light that goes almost to the outside edges of this texture,

01:21:56.000 --> 01:21:59.000
just fading a little bit and then fading a little bit in the other direction,

01:21:59.000 --> 01:22:05.000
so we could get about as much light as we could into the world for minimal fragment cost.

01:22:05.000 --> 01:22:12.000
Unfortunately, we kept those through rage as our primary light style.

01:22:12.000 --> 01:22:16.000
We had some of our very best artists love this because it gave them total control.

01:22:16.000 --> 01:22:19.000
They would call it painting with light, so they would be able to say,

01:22:19.000 --> 01:22:25.000
I want this area a little bit brighter here, so I'll use this different texture instead of the standard one.

01:22:25.000 --> 01:22:28.000
I'll move this or I'll stretch it so it just barely goes below the floor,

01:22:28.000 --> 01:22:32.000
but it has no fall-off, so it's going to throw all the light into it.

01:22:32.000 --> 01:22:38.000
That is largely the type of artistic wizardry that we need to evolve past

01:22:38.000 --> 01:22:43.000
because you will never be able to take light emitters like that and make the world feel real

01:22:43.000 --> 01:22:45.000
because the light's not real.

01:22:45.000 --> 01:22:49.000
You can even have completely real materials and you could be doing it with path tracing,

01:22:49.000 --> 01:22:54.000
but if your light is only coming from these things that do not resemble real lights,

01:22:54.000 --> 01:22:57.000
then it's never going to be bought off as real.

01:22:57.000 --> 01:23:05.000
Several years ago, I made a premature evidently push towards physically-based lighting

01:23:05.000 --> 01:23:10.000
where I was trying to set all of our lights up with using IES light profiles,

01:23:10.000 --> 01:23:16.000
which are these actual light profiles that the people that make light bulbs go and measure all of these things.

01:23:16.000 --> 01:23:20.000
You can get the light that's coming at all of these different areas,

01:23:20.000 --> 01:23:22.000
different sample points coming out of it.

01:23:22.000 --> 01:23:27.000
That's really useful, although it's important to note that there are simplifications in here.

01:23:27.000 --> 01:23:29.000
Just because you see an equation doesn't mean it's true.

01:23:29.000 --> 01:23:32.000
Just because you see a table of data doesn't mean it's true either

01:23:32.000 --> 01:23:38.000
because you have simplifications like an IES spec for three fluorescent bulbs in a fixture.

01:23:38.000 --> 01:23:41.000
Yes, you are sampling what the light is at all of these points,

01:23:41.000 --> 01:23:47.000
but really you should be getting three shadows from it rather than one from an area light source.

01:23:47.000 --> 01:23:49.000
There's simplifications built into that,

01:23:49.000 --> 01:23:52.000
but we are not currently using that.

01:23:52.000 --> 01:23:58.000
The main reason why it fell through when I pushed for it originally was it comes back to the performance.

01:23:58.000 --> 01:24:03.000
To keep the build times at a certain level that they were familiar with,

01:24:03.000 --> 01:24:06.000
you wound up with these lights now are extending infinitely.

01:24:06.000 --> 01:24:09.000
They're proper inverse-square fall-off lights,

01:24:09.000 --> 01:24:12.000
so if you've got a level with 1,000 lights in it,

01:24:12.000 --> 01:24:18.000
then in theory you're tracing 1,000 traces out at a minimum to just see whether any light gets there.

01:24:19.000 --> 01:24:22.000
You cut this down to some rational number of samples,

01:24:22.000 --> 01:24:25.000
and what that means is there's lots of noise in the images.

01:24:25.000 --> 01:24:29.000
One of the battles that's been particularly hard for all of the Tech 5 stuff

01:24:29.000 --> 01:24:35.000
is trying to have a situation where the designers and artists are willing to work with

01:24:35.000 --> 01:24:39.000
an approximation of what the final output is.

01:24:39.000 --> 01:24:42.000
It is just very tempting to say,

01:24:42.000 --> 01:24:44.000
well, I always want to look at what the final output is,

01:24:44.000 --> 01:24:47.000
which means that everything is always a production quality render,

01:24:47.000 --> 01:24:49.000
which means it always takes forever.

01:24:49.000 --> 01:24:52.000
I keep hoping that there will be more of an acceptance of,

01:24:52.000 --> 01:24:54.000
well, this is roughly what it's like.

01:24:54.000 --> 01:24:58.000
I can still figure out what my gameplay and rough lighting and everything is,

01:24:58.000 --> 01:25:01.000
but that's a battle that we fight daily on this.

01:25:04.000 --> 01:25:05.000
Hi, John.

01:25:05.000 --> 01:25:07.000
Taking quality materials data for granted,

01:25:07.000 --> 01:25:12.000
I'm curious what additional visual fidelity you gain by ray tracing box lock trees

01:25:12.000 --> 01:25:14.000
and then what visual sacrifices you make

01:25:14.000 --> 01:25:16.000
and what sacrifices you have to make in terms of performance.

01:25:16.000 --> 01:25:18.000
Or to gain performance.

01:25:18.000 --> 01:25:23.000
So the question of what you're ray tracing against is sort of orthogonal to the method.

01:25:23.000 --> 01:25:27.000
I mean, you can rasterize or ray trace lots of different representations,

01:25:27.000 --> 01:25:32.000
and there was lots of work that went into directly ray tracing against curved surfaces

01:25:32.000 --> 01:25:35.000
and certainly spheres in some of the easy cases.

01:25:35.000 --> 01:25:39.000
And for years, I did think that ray tracing into some form of voxel space

01:25:39.000 --> 01:25:42.000
would be an obvious thing to do,

01:25:42.000 --> 01:25:46.000
because it seems that there's winds, it's certainly far simpler.

01:25:46.000 --> 01:25:48.000
You can make a more regular data structure.

01:25:48.000 --> 01:25:52.000
There's all these things, but it doesn't seem to be panning out that way.

01:25:52.000 --> 01:25:55.000
It does seem to be that all ray tracing will be against triangle meshes

01:25:55.000 --> 01:25:57.000
that you will decimate to it.

01:25:57.000 --> 01:26:01.000
And there's certainly advantages to the comfortable toolpaths, everything there.

01:26:01.000 --> 01:26:04.000
It seems that's the way that history is flowing,

01:26:04.000 --> 01:26:08.000
and that's probably the way it's going to work out when we are ray tracing everything.

01:26:09.000 --> 01:26:14.000
You talked a little bit yesterday on the motion blur that happens

01:26:14.000 --> 01:26:18.000
on the LCD screens as you're moving your head very quickly.

01:26:18.000 --> 01:26:23.000
Do you have any more thoughts on if that's a solvable problem for this generation of VRs

01:26:23.000 --> 01:26:25.000
that's going to take a little longer?

01:26:25.000 --> 01:26:28.000
So we have an existence proof of something that's good enough.

01:26:28.000 --> 01:26:35.000
I mean, what Valve put together by packing up the Samsung displays is good enough.

01:26:35.000 --> 01:26:40.000
If we can get 90 hertz displays that are low persistence, that will do.

01:26:40.000 --> 01:26:43.000
120 would probably be better,

01:26:43.000 --> 01:26:49.000
but like my interlace scheme, maybe a good thing to kind of add on top of that if it can be done.

01:26:49.000 --> 01:26:51.000
But I think there's a good prospect.

01:26:51.000 --> 01:26:56.000
The fallback plan is LCD backlight flashing.

01:26:56.000 --> 01:27:01.000
So it's important, and I think that I'm betting that it will be solved

01:27:01.000 --> 01:27:05.000
for sort of consumer grade VR in the not too distant future,

01:27:05.000 --> 01:27:10.000
but it's not there right now outside of Valve's prototype.

01:27:15.000 --> 01:27:18.000
Hi, John. Thanks for the talk.

01:27:18.000 --> 01:27:23.000
A few years ago I read an MIT paper explaining how to compute saw shadows,

01:27:23.000 --> 01:27:27.000
and what they did was they interpolated linearly between the parts that were lit

01:27:27.000 --> 01:27:29.000
and the parts that were not lit.

01:27:29.000 --> 01:27:31.000
Is that the approach it takes?

01:27:31.000 --> 01:27:34.000
Is that a linear map or nonlinear map between the umbra and the penumbra?

01:27:34.000 --> 01:27:38.000
And I was just hoping you could explain in detail how you calculate the intermediate levels.

01:27:38.000 --> 01:27:44.000
Okay, so that does fall into the category of large body of work of approximations

01:27:44.000 --> 01:27:46.000
that is pretty much gone and forgotten right now.

01:27:46.000 --> 01:27:50.000
Our saw shadows are done by sending a certain number of samples,

01:27:50.000 --> 01:27:52.000
like it's 16 by default.

01:27:52.000 --> 01:27:57.000
So you send 16 samples to different points on the light that are randomly distributed,

01:27:57.000 --> 01:28:01.000
and the density of the shadow is just the fraction of them to get through.

01:28:01.000 --> 01:28:06.000
So you can crank that number up in some cases for some of the really broad area emitters.

01:28:06.000 --> 01:28:10.000
In theory you'd want it to be 256 samples, so you could get a full range of,

01:28:10.000 --> 01:28:14.000
or even more on a very bright light, but we get by with 16.

01:28:14.000 --> 01:28:17.000
There's an approximation that I did on that

01:28:17.000 --> 01:28:21.000
that instead of randomly sending to all points in the center of the,

01:28:21.000 --> 01:28:23.000
all points across the area of the light source,

01:28:23.000 --> 01:28:26.000
by default we send them across the circumference of the light,

01:28:26.000 --> 01:28:31.000
which gives you, in theory can sometimes make it look a square factor better,

01:28:31.000 --> 01:28:33.000
but it looks bad at edges.

01:28:33.000 --> 01:28:35.000
So we're still tracing different things on there,

01:28:35.000 --> 01:28:38.000
but in the bottom line it's just however many samples you throw.

01:28:38.000 --> 01:28:39.000
That's the fraction that comes out.

01:28:39.000 --> 01:28:44.000
Things like that are going back through the history of graphics for 40 years.

01:28:44.000 --> 01:28:48.000
There's a ton of things that were somewhat complicated analytics solutions

01:28:48.000 --> 01:28:51.000
that have just over and over fallen to raw brute force,

01:28:51.000 --> 01:28:54.000
and I think that all of these things will as well.

01:28:54.000 --> 01:28:58.000
You know, when we are tracing billions of rays per frame,

01:28:58.000 --> 01:29:00.000
that's when we'll be using ray tracing.

01:29:00.000 --> 01:29:03.000
I don't think there's going to be too many intermediate steps to that.

01:29:03.000 --> 01:29:06.000
Thank you.

01:29:06.000 --> 01:29:08.000
Hello.

01:29:08.000 --> 01:29:13.000
So I know that in AutoCAD and other engineering programs,

01:29:13.000 --> 01:29:18.000
there are catalogs of different types of materials

01:29:18.000 --> 01:29:26.000
that you can test the effects of different things on the structure,

01:29:26.000 --> 01:29:30.000
so on and so forth, just the different kinds of materials.

01:29:30.000 --> 01:29:36.000
And my question is for you is that with trying to make your artists use more accurate materials,

01:29:36.000 --> 01:29:41.000
are you trying to create a catalog of textures?

01:29:41.000 --> 01:29:47.000
Yeah, so right now we are very much trying to have our master swatch list of,

01:29:47.000 --> 01:29:50.000
you know, if we need, there's the clear things about,

01:29:50.000 --> 01:29:53.000
okay, if you're metal, you're in this range, if you're paint, you're in this range,

01:29:53.000 --> 01:29:55.000
if you're wood, you're in this range, asphalt,

01:29:55.000 --> 01:30:00.000
having all of this represented as these are the valid ranges

01:30:00.000 --> 01:30:05.000
of diffuse specular roughness and maps that you're going to have.

01:30:05.000 --> 01:30:08.000
So we're still working through all of that.

01:30:08.000 --> 01:30:12.000
And in terms of material libraries, it's a little frustrating when you look at,

01:30:12.000 --> 01:30:16.000
whether it's 3D Studio or Modo or V-Ray, whatever,

01:30:16.000 --> 01:30:19.000
the materialists are usually the ad hoc collection that's accreted

01:30:19.000 --> 01:30:22.000
over a couple decades of company lifespan,

01:30:22.000 --> 01:30:26.000
and they're usually not a complete, consistent, cohesive,

01:30:26.000 --> 01:30:28.000
physically-based set of materials.

01:30:28.000 --> 01:30:32.000
We spent a little bit of time trying to backtrack values

01:30:32.000 --> 01:30:36.000
from one of the material library sets into the things that we could use,

01:30:36.000 --> 01:30:40.000
and it wasn't completely clear that they were coming out in the right ranges,

01:30:40.000 --> 01:30:44.000
so we're building up our own set, and there's lots of studios doing that.

01:30:45.000 --> 01:30:50.000
Online, there are sets of BRDF measurements for a lot of materials

01:30:50.000 --> 01:30:55.000
that would be good to start drawing some of the materials from,

01:30:55.000 --> 01:31:01.000
but we're still looking for, okay, what's the diffuse specular and roughness values going

01:31:01.000 --> 01:31:03.000
rather than this full table of data,

01:31:03.000 --> 01:31:06.000
but eventually, I expect that we all will be using,

01:31:06.000 --> 01:31:08.000
this is data scanned in from the real world,

01:31:08.000 --> 01:31:11.000
because over and over, that's what eventually wins in the end.

01:31:12.000 --> 01:31:13.000
Thank you.

01:31:13.000 --> 01:31:14.000
All right.

01:31:15.000 --> 01:31:16.000
That looks like it. John, thank you.

01:31:16.000 --> 01:31:18.000
Thanks. On time.

01:31:41.000 --> 01:31:43.000
Thank you.

