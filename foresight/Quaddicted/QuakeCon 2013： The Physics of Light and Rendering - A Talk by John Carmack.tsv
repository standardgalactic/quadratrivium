start	end	text
0	26000	Hello, everybody.
27000	32000	We have a good crowd for John's second talk.
32000	33000	It's very exciting.
33000	37000	This is the first year that John will be talking twice.
37000	40000	A couple of things to know.
40000	42000	John will talk for about an hour or so,
42000	44000	and then we'll have 30 minutes for questions.
44000	46000	The mic is right there.
46000	48000	That's actually just right there.
48000	52000	So just line up when we get to the questions.
52000	55000	Try to keep your questions on what John talked about.
55000	57000	If you get up and ask when Doom 4 is coming out,
57000	59000	I'm going to kick you in the knee.
59000	61000	So right there.
61000	64000	So I will not waste any more time,
64000	66000	but you guys in the back,
66000	68000	because John's going to write on the board,
68000	69000	and we have plenty of empty seats here,
69000	71000	you can file in.
71000	73000	Don't worry that there's reserve seats there.
73000	75000	Just go ahead and sit in them.
75000	79000	All right, I will give you guys Mr. Carmichael.
79000	89000	Okay, so I guess this is sort of going to be
89000	91000	like a school room session.
91000	93000	I had deluded myself for a little while
93000	95000	that this would be the first talk
95000	97000	where I ever actually made slides to present,
97000	99000	but it didn't actually come to pass,
99000	101000	so it's going to be notes and talking
101000	103000	and some scribbling on the board again.
103000	105000	So almost all of what we do in game development
105000	107000	is really more about artistry.
107000	109000	It's about trying to appeal to people,
109000	111000	but there's the small section of the small section
111000	113000	of what goes into the games
113000	115000	that's drawing the pictures on the screen
115000	117000	that you can at least make some ties
117000	120000	to the hardest of hard sciences.
120000	123000	And while it's great that people are researching
123000	125000	the psychology and the different ways
125000	127000	that people think about compulsion loops
127000	129000	and some of these other game design topics,
129000	131000	the raw physics that goes into rendering
131000	133000	just kind of goes through the heart of physics,
133000	136000	where it goes through kind of the all-star list
136000	138000	of physics with Newton's optics
138000	141000	and Maxwell's equations and Einstein's relativity,
141000	143000	and it's kind of neat to think
143000	145000	that this is sort of brought to bear
145000	147000	in the techniques that go into
147000	149000	sort of making the games that we play.
149000	151000	So at the start, you think,
151000	153000	well, okay, we see light,
153000	155000	so what actually is light?
155000	157000	And we've got a definition now
157000	160000	that lights the sliver of the electromagnetic spectrum
160000	162000	that we can actually perceive,
162000	164000	but that has a really long and complicated history
164000	166000	for how we sort of reached that conclusion
166000	168000	and how it's not really as clear-cut
168000	172000	as most people would like it to be.
172000	174000	Optical research started kind of all the way back
174000	176000	with a lot of the Greek philosophers,
176000	178000	but Newton did a whole lot of work
178000	180000	with breaking light up with prisms,
180000	182000	seeing how white light was actually composed
182000	184000	of all the different colors of the spectrum,
184000	188000	and they add together to make what we perceive as light.
188000	191000	And then for, there was a centuries-long debate
191000	193000	about whether light was a particle,
193000	195000	like this little tiny billiard ball,
195000	197000	these photons that you shoot out,
197000	199000	or a wave effect, like all the things that you see
199000	201000	in waves in water and waves in matter,
201000	203000	and so on.
203000	205000	And finally, we reached the conclusion that,
205000	207000	well, it's a wave particle duality
207000	209000	that Quantum Mechanics talks about,
209000	211000	and this is very unsatisfying
211000	213000	when you begin looking at this,
213000	215000	but it's really pretty much irrefutable.
215000	217000	There are these straightforward experiments
217000	219000	that can be done to show that you look at it one way,
219000	221000	it's a wave, you look at it another way,
221000	224000	it's a light, or it's a particle.
224000	227000	So, luckily for computer graphics,
227000	229000	we hardly care at all about that,
229000	231000	only when you start looking at some aspects
231000	233000	of surface reflectance models,
233000	235000	do you start caring at all about
235000	237000	some of these Quantum Mechanical properties of light.
237000	239000	For the most part, we can look at light
239000	242000	as zillions and zillions of little billiard balls
242000	244000	shot out from lights and bouncing off of things
244000	246000	and eventually reaching our eyes
246000	248000	so that we can perceive them.
249000	251000	There's a lot of simplifications
251000	255000	that have to happen when you talk about simulating this.
255000	257000	There's a lot of engineering disciplines
257000	260000	like thermal management, radio engineering
260000	262000	that do simulations of the electromagnetic spectrum,
262000	264000	just other parts of it,
264000	266000	how they bounce around, interact with things,
266000	268000	and this is done all the time,
268000	270000	and it works, it really is science.
270000	273000	So, you can say rendering an image
273000	276000	or deciding how much light reaches a particular area
276000	279000	is about as basic of a science as it comes.
279000	282000	There's not any artistic measure in here.
282000	284000	There are tons of other aspects
284000	286000	when you get into perception
286000	288000	that do become questions about,
288000	291000	well, maybe there is artistry that goes into producing something
291000	293000	when you've got an impression that you want,
293000	295000	but when you're talking about simulating an environment,
295000	299000	which most of what we do in the hardcore FPS type games
299000	302000	is we are pretending that we've got this virtual world
302000	304000	and we're running a camera through it
304000	307000	and we're trying to simulate what's happening in various ways.
307000	310000	And nowadays, we know what we would have to do
310000	312000	to make that almost perfect.
312000	315000	We just have nowhere near the computing capacity
315000	318000	to do really, really high-level simulations,
318000	320000	but we can trace it useful
320000	322000	even if you're not going to do the right thing
322000	324000	to at least understand what the right thing is
324000	326000	and then understand which trade-offs you're making
326000	328000	and make them with sort of a clear head
328000	331000	rather than accidentally backing into trade-offs
331000	335000	that may or may not be really the best way to go about things.
336000	338000	So, so many that...
338000	340000	It took a long time for people to realize
340000	343000	that these other phenomena, things like radio waves,
343000	346000	and there's a lot of confusion in 19th and 20th century physics
346000	349000	about which things were particles and which things were rays,
349000	352000	and we still have kind of mixed-up terminology
352000	355000	when you talk about cosmic rays that are actually particles
355000	359000	and you talk about alpha radiation and beta radiation
359000	361000	and these things that are particle-based
361000	364000	rather than being rays from the electromagnetic spectrum.
364000	367000	But we use this stuff all the time for radio waves.
367000	372000	Your Wi-Fi has two gigahertz frequencies.
372000	376000	The visible light rays are up in the terahertz range,
376000	378000	many terahertz.
378000	380000	But they're basically the same thing.
380000	383000	They just differ in how they interact with matter.
383000	385000	They're produced in somewhat similar ways,
385000	387000	but the different things change.
387000	390000	They behave differently when they interact with other things
390000	392000	based on their wavelength,
392000	394000	which is why x-rays can shoot through things,
394000	396000	radio waves can go through some things
396000	399000	that the visible light pretty much bounces off of.
401000	404000	So, another important critical thing, really,
404000	407000	is that photons, the little bundles of light that we talk about,
407000	409000	they are absolutely quantized.
409000	411000	It's, again, part of the quantum weirdness
411000	414000	that you can't send off this arbitrarily divisible amount,
414000	417000	there is an almost unbelievably large number of them.
417000	419000	Given light that's throwing out is, you know,
419000	421000	I can just say zillions with a straight face
421000	424000	because it's a very large scientific notation number.
424000	426000	It's not trillions, it's not quadrillions,
426000	428000	it's even more than that that are coming out
428000	432000	in terms of these bundled little quanta of energy.
434000	437000	Now, they do have characteristics to them.
437000	440000	If we treat them as little billiard balls in computer graphics,
440000	443000	we are generally looking at only a few different spectrums
443000	446000	of a few different wavelengths in the spectrum of light,
446000	450000	and that has to do with an aspect of the human visual system.
450000	454000	While there are this incredibly divisible spectrum of light
454000	460000	that goes out, we're only susceptible to three sort of styles of light,
460000	462000	and they're not even individual frequencies.
462000	465000	That's why we can get by with red, green, and blue
465000	467000	for our monitor's emissive spectrums
467000	471000	because we only have three types of color receptors in our eyes,
471000	473000	and I often think how it would be really interesting
473000	476000	if you could look at all of these other spectrums bouncing around,
476000	479000	and that's what thermal imaging and some of these other things
479000	481000	let you sort of get a peek into it,
481000	483000	and that's only light that's very...
483000	487000	that's EM radiation that's very close to the visible spectrum,
487000	489000	the infrared.
489000	491000	It would be much more bizarre and interesting
491000	494000	to be able to visualize radio waves in a real-time space
494000	497000	to, like, see all the multi-path that's causing your Wi-Fi
497000	499000	to be weird in specific ways,
499000	501000	why, you know, moving something over here
501000	505000	causes the radiation to change so much at your antenna
505000	508000	to make a difference in your reception strength,
508000	511000	and these are all things that have a bearing to what you do
511000	514000	with light transport, as well as other wave phenomena,
514000	517000	like audio, like really, really high-end audio processing
517000	521000	is the exact same thing as what we treat light processing.
521000	524000	You send out energy, it bounces off of all sorts of things in the world,
524000	527000	and eventually arrives at something that's going to perceive it,
527000	531000	which would be your ears in that case versus your eyes.
531000	534000	So to kind of start with the path of a photon,
534000	536000	of what it would take,
536000	539000	you've got something creates the photon,
539000	542000	and for the longest time in our human existence
542000	544000	about the only thing that we saw creating photons
544000	546000	was a great deal of heat.
546000	548000	You heat things up hot enough,
548000	550000	and photons start coming off of them.
550000	552000	You heat it up enough, it starts glowing a dull red,
552000	555000	you heat it up more, it starts getting more yellowish,
555000	558000	and towards white as more and more of the colors of the spectrum
558000	561000	are emitted from these hot things,
561000	563000	and obviously the sun is a very hot thing
563000	565000	where you've got a fusion reactor going,
565000	569000	and the light that comes off of that is all of these atoms
569000	571000	giving up some energy.
571000	576000	So photons carry energy away from where they came from,
576000	581000	and this is a radiative heat transfer where something gets hot.
581000	584000	If you leave it all by itself there,
584000	587000	it glows and it eventually stops glowing.
587000	589000	It cools down, going down through the spectrum,
589000	592000	getting cooler and cooler until you don't see any visible light
592000	594000	because it's actually lost much of its heat.
594000	599000	On Earth, radiative heat transfer is the least effective form of heat transfer.
599000	601000	You get much more from conduction
601000	604000	where it just kind of goes through the actual physical contact
604000	607000	into other areas as the heat spreads out,
607000	611000	or convection where moving currents of air or water take the heat away.
611000	614000	But in space, radiation is the only way you lose heat,
614000	617000	and in aerospace engineering this is extremely important.
617000	621000	Things like the areas like the International Space Station and Spaceships,
621000	624000	they have to worry a whole lot about thermal management
624000	627000	because the only tool they've really got is radiation.
627000	631000	You see these enormous solar panels where they collect solar energy,
631000	634000	but a lot of space vehicles have to have enormous radiators
634000	638000	where they actually let the energy go out from the vehicle,
638000	640000	otherwise they would get hotter and hotter.
641000	645000	It's important to note that even if it's not glowing so that we can see it,
645000	647000	everything's still radiating,
647000	650000	so you don't see the space station glowing red hot,
650000	652000	it's just glowing at whatever its normal temperature is,
652000	655000	which can be perceived with infrared sensors,
655000	658000	but it slowly loses energy and it eventually reaches a balance.
658000	662000	That's why something stuck out in the sun in space doesn't get hotter and hotter.
662000	666000	Eventually it reaches the point where the light that's coming in and hitting it
666000	668000	is equal by the radiation that's leaving it,
668000	671000	and there are, like you can make,
671000	674000	we've made rocket engines that are radiatively cooled
674000	678000	where they burn 5000 degrees or so inside
678000	682000	and they get so blindingly white hot on the outside
682000	686000	that all of the energy that's not going out the nozzle that's soaking into the walls
686000	689000	is radiated away as a whole lot of light.
689000	692000	And this is essentially what old-style incandescent light bulbs were.
692000	696000	You had a tungsten filament, you made it really hot by pushing electrons through it,
696000	699000	and it got hot enough and it started glowing.
699000	702000	And if you watched closely, if it was a very, like a heavy filament,
702000	704000	you could watch it warm up or especially shut down,
704000	708000	it would go through, kind of ramp through the temperatures, you would see it,
708000	711000	be red and get up to white hot, and then when you shut it down,
711000	714000	it would cool down through yellow and then back through red
714000	719000	before finally settling back to radiating in non-visible regions
719000	721000	at sort of room temperature eventually.
721000	724000	Nowadays we have a lot more efficient ways to create photons
724000	728000	with fluorescence and LEDs, things that are tuned carefully
728000	733000	to just barely nudge the electrons in the atoms out to an excited state,
733000	736000	let them collapse back down and spit a photon out.
736000	741000	For the most part, photon emission is random in terms of which direction it goes.
741000	745000	When you look at radio engineering, there's huge bodies of literature
745000	749000	for intended design that determine how you can make it slightly stronger
749000	753000	or weaker in different directions, but there's still a very fundamental nature of randomness,
753000	756000	which is, again, the quantum mechanics aspect of things.
756000	760000	At a very low level, natural events are completely random
760000	766000	and you can't just say, I only want photons that are going to come out of the left side of this material.
766000	770000	So you get a photon that pops off in some random direction.
770000	774000	It may go straight for, if it's coming from a distant star,
774000	778000	it could go straight for trillions of miles, more or less just traveling through space.
778000	782000	There's little bits of general relativity with warping of light that can happen,
782000	786000	but for the most part, it can continue on indefinitely.
786000	790000	It's a self-propagating wave, so it pops off of some atom somewhere,
790000	794000	maybe flies through space for a billion trillion miles or something,
794000	797000	comes in, finally hits our Earth's atmosphere,
797000	801000	and then starts interacting with the atmosphere in some way.
801000	805000	Every change in density that visible light goes through
805000	808000	will result in it bending its path somewhat.
808000	810000	This is called refraction.
810000	813000	The most obvious case when you look at it is things like prisms and lenses
813000	816000	where you can see the light really strongly warped,
816000	819000	but it happens in any sort of density change,
819000	823000	going from the vacuum of space to the outer reaches of our atmosphere,
823000	827000	and then every change in pressure or temperature changes the density,
827000	833000	and that causes very slight and subtle movements of the changes in the direction of the light.
833000	836000	This is actually why stars twinkle out at night.
836000	841000	You're on a clear night and you see stars coming in from billions or trillions of miles away.
841000	844000	It's going completely straight till it hits the upper atmosphere,
844000	848000	and then it may slightly deviate, just tiny fractions of degrees,
848000	852000	and this can cause the very small number of photons that you're seeing there
852000	856000	to kind of come and go or move around in different ways.
856000	860000	But the most important thing from a computer graphics standpoint
860000	863000	are the effects that happen when it hits more solid matter,
863000	866000	or solid surfaces, or even liquid surfaces,
866000	870000	and that's where it has the opportunity to generally...
870000	875000	Well, even gas, you can wind up having the case of absorbing the photon.
875000	877000	This happens rarely in gas.
877000	880000	You can pass through hundreds of miles of atmosphere
880000	883000	and not have too many of the photons absorbed,
883000	889000	but it happens very rapidly in matter, in solid matter.
889000	894000	A typical photon, when it hits a surface, might penetrate a little bit into it.
894000	898000	A surface like metal will bounce off of just the first several atoms.
898000	903000	It doesn't take many molecules or many atoms of metal before you can reflect light out,
903000	906000	which is why you can make these super enormous space mirrors
906000	910000	that are just a very tiny sputtering of aluminum on some plastic film,
910000	915000	and they can actually make solar sails or giant solar collectors and concentrators.
915000	920000	But for most other materials, the light can penetrate a little bit further into it.
920000	924000	As it interacts with the molecules, it can either be absorbed,
924000	929000	raising the temperature a little bit, going into eventually making it hotter
929000	932000	so that it starts radiating out at some level,
932000	936000	or it can redirect the photon in some way.
936000	939000	You've got the minor redirections from the refraction
939000	944000	and much stronger ones when it interacts and bounces off of a solid surface.
944000	946000	There's a ton of different names.
946000	948000	There's literally a couple dozen different names
948000	951000	for the different ways that light can interact with surfaces.
951000	953000	There's all the different types of scattering.
953000	958000	Of course, reflection, refraction, refraction can be split up into
958000	961000	specular reflection, diffuse reflection,
961000	963000	and there's all sorts of different subcategories.
963000	965000	Optics is a huge topic.
965000	968000	There are societies dedicated to every aspect of it,
968000	971000	and there's huge terminologies for all of it.
971000	973000	But for the most part, you can say,
973000	976000	photon comes in, if it's not absorbed,
976000	978000	it's going to be kicked out some other direction,
978000	981000	and then it can go and interact potentially with the atmosphere
981000	983000	or potentially with another surface.
983000	985000	And eventually, it's either absorbed,
985000	987000	well, eventually it is absorbed somewhere,
987000	990000	but for the most part, they're absorbed into the surfaces around us,
990000	994000	but a tiny, tiny fraction of all the photons that are bouncing around
994000	996000	eventually hits our eyes.
996000	999000	And even when it gets to our eyes, which are mostly transparent,
999000	1001000	there's this chance that the photon hits,
1001000	1003000	and it specularly reflects off of our eye,
1003000	1006000	and it made it all the way out of the billions of possible traces,
1006000	1011000	made it to my eye, and then decides to specularly reflect off some other direction.
1011000	1015000	But most of it that hits the eye and hits the lens gets through,
1015000	1018000	propagates through the vitreous and aqueous humor
1018000	1020000	and all the little biological parts of the eye,
1020000	1023000	and hits receptors in the back of our eyeballs
1023000	1028000	that turn those eventually into neural impulses that our brain works with.
1028000	1031000	Now, our eyes can actually be quite sensitive.
1031000	1036000	The rods, the non-color sensitive part of our eyes,
1036000	1038000	when they're fully dark adapted,
1038000	1042000	if you've been staying outside in a dark area for 20, 30 minutes,
1042000	1049000	single photons can cause chemical reactions to happen inside the rod cells.
1049000	1053000	It takes a handful of them, a couple dozen for it to turn into a neural impulse,
1053000	1055000	but it is possible for people that,
1055000	1058000	especially in the old days, people watching for things on ships
1058000	1063000	in moonless nights that might be out all night with nothing but faint starlight,
1063000	1067000	you can have cases of just handfuls of photons coming off of something,
1067000	1071000	being registered and showing up and people acknowledging their existence,
1071000	1075000	which is pretty amazing when you think about these incredible subatomic particles,
1075000	1082000	not even particles, but incredible, the scope of that being detectable by us as biological entities.
1083000	1087000	There are limits to what you can wind up detecting with light.
1087000	1090000	The visible light that we see has a wavelength,
1090000	1093000	and you can't really deal with things that are smaller than that,
1093000	1097000	which is why you're never going to have a real picture of an atom or a molecule,
1097000	1101000	because those are much, much smaller than the wavelengths of light.
1101000	1106000	You eventually use electron microscopes and then scanning tunneling microscopes
1106000	1110000	and these other things that don't deal with light at all to take those super tiny pictures,
1110000	1113000	like the boy in his atom movie that IBM Research did,
1113000	1116000	which was done with a little raster grid of atoms,
1116000	1120000	which is really in the fundamental sense of the word, deeply awesome,
1120000	1124000	that we are dealing with matter, the very constituents of everything at that level,
1124000	1127000	and we can make a little movie out of it,
1127000	1130000	but those pictures have nothing to do with light, nothing to do with rendering
1130000	1134000	and basically the techniques that I'm talking about here,
1134000	1139000	that's a completely different way of sensing what's going on at that level.
1139000	1143000	So to recap the basic pictures of this,
1143000	1149000	you've got something, a sun up here, spits out some light, travels through space,
1149000	1155000	gets to the atmosphere on the Earth, maybe bends a little bit,
1155000	1158000	maybe just goes straight through, comes down, hits the surface,
1158000	1161000	maybe gets absorbed, maybe hits something else,
1161000	1164000	and you've got walls and rooms and bouncing around in there,
1164000	1168000	and eventually, if we're seeing it, reaches somebody's eyeball inside,
1168000	1171000	and that's the physics of what happens.
1171000	1173000	It's really well understood.
1173000	1177000	It does come down to a lot of data acquisition and characterization.
1177000	1183000	When you talk about how the critical interactions with the surfaces,
1183000	1186000	when you've got your basic theoretical thing,
1186000	1188000	if you talk about a flat surface, you say,
1188000	1191000	light comes in, what happens to it?
1191000	1193000	That's the question of surface response.
1193000	1195000	If you have a perfect mirror,
1195000	1200000	and it's worth noting that you don't have to be perfect on an atomic level
1200000	1203000	to be a perfect mirror, you only have to be perfect at the optical level,
1203000	1205000	which is somewhat larger.
1205000	1210000	So people can make basically perfect mirrors, just highly, highly polished things.
1210000	1215000	A perfect mirror will have the photon reflect off in this exact reflection.
1215000	1219000	If you take the normal to the surface, you wind up with equal angles there.
1219000	1223000	So highly polished surfaces act like this.
1223000	1227000	When you get a reflection off of something like the surface of water,
1227000	1229000	it'll behave like this.
1229000	1233000	But most of the surfaces that we look around us do not behave like this.
1233000	1237000	We have a spread of the energy where it comes in,
1237000	1241000	and it bounces off to some degree in every direction.
1241000	1243000	No matter which way you look at most surfaces,
1243000	1246000	you see, again, zillions of photons coming in.
1246000	1248000	Some of them go in every direction.
1248000	1253000	They just go in a direction that's biased based on the type of surface that it is.
1253000	1255000	A surface that...
1255000	1258000	One of the easy things that a lot of times is approximated,
1258000	1261000	both in the engineering sciences and in computer graphics,
1261000	1264000	is to assume that the surface reflects perfectly diffusely,
1264000	1266000	or it's a Lambertian surface.
1266000	1270000	And what that means is that no matter which way the light comes in,
1270000	1273000	if it hits it completely edge on, completely straight on,
1273000	1277000	it has an equal probability of going in every direction.
1277000	1280000	And there are some materials that are close to this.
1280000	1284000	If you take something like a block of chalk, white chalk,
1284000	1288000	that behaves almost as a perfect diffuse reflector.
1288000	1290000	If you light it from one position,
1290000	1294000	and you look at that like a little scribed out area on it from any different area around it,
1294000	1298000	it will appear to have about the same amount of energy coming out of it.
1298000	1301000	But there are...
1301000	1304000	All surfaces are more complex than that, though.
1304000	1307000	Most of them will say, if you've got light coming in here,
1307000	1310000	there will be more of it coming out around the reflection area,
1310000	1315000	and some general amount coming out in all different directions.
1315000	1318000	But these can actually get quite complicated.
1318000	1322000	And the simplifications that we use in graphics sort of approximate these,
1322000	1325000	but you can measure these with specific tools
1325000	1329000	that go in and take lots of samples from moving the lights around,
1329000	1331000	because it depends...
1331000	1334000	Unfortunately, this is one of the areas where it does get
1334000	1336000	not so great for computer graphics.
1336000	1340000	It depends both on the incoming direction and the upcoming direction.
1340000	1342000	And those are two angles in each one,
1342000	1347000	so it winds up being a four-dimensional equation to say how light comes in here,
1347000	1349000	how does it come out in some other direction.
1349000	1351000	And in fact, it gets worse than that,
1351000	1356000	because very few things do reflect just off of this upper surface.
1356000	1358000	Most of the time, the light will go in,
1358000	1361000	go below the surface, bounce around a little bit,
1361000	1363000	and shoot out some other direction.
1363000	1367000	So if you're saying, well, my photon comes in here,
1367000	1370000	not only do you have to say if you're being really, really accurate,
1370000	1372000	which angle does it come off of,
1372000	1376000	but also how far away from the original point does it come off of?
1376000	1381000	Or if it's a thin surface, how does it come out on the backside?
1381000	1383000	You may have other setups coming there.
1383000	1385000	When you look at, like, a leaf in the sunshine,
1385000	1387000	you've got a lot of the energy,
1387000	1389000	bounces off the shiny top face,
1389000	1392000	but a lot of it diffuses through and comes out on the backside.
1392000	1398000	So these are not pleasantly analytically tractable things.
1398000	1401000	They wind up being big tables of data.
1401000	1404000	And one thing that's important to remember is,
1404000	1407000	when you see, like, tables of data that are collected for things,
1407000	1411000	don't necessarily capture all of the important characteristics of the surface,
1411000	1416000	where if you take one of these sensors that you can capture a table of data here,
1416000	1418000	if you did have your perfect mirror reflector,
1418000	1424000	it's almost certainly not going to have the exact sample exactly where you want.
1424000	1426000	But eventually data does win,
1426000	1428000	just as we increase resolution on things,
1428000	1432000	we'll have higher and higher resolutions for our surface models,
1432000	1437000	and we'll get closer and closer to reality for what we're simulating.
1437000	1443000	So to go as kind of a capsule history of computer graphics rendering then,
1443000	1445000	when computer graphics started off,
1445000	1448000	look in the 60s, 60s and early 70s,
1448000	1452000	computer graphics research focused on the hidden line problem.
1452000	1455000	You know, we had line-oriented displays,
1455000	1462000	either true vector displays where, like the old video game arcade games,
1462000	1465000	like I'm blanking out now,
1465000	1467000	like Asteroids is the best example,
1467000	1471000	that are actually drawn by raster beams moving around
1471000	1473000	where they really are true line displays.
1473000	1475000	There's no raster, there's no edge aliasing,
1475000	1481000	and all the different games like that were what the earliest computer graphics systems
1481000	1484000	were basically like that, where there were vector displays.
1484000	1487000	And once people learned how to draw,
1487000	1490000	figured out all the basic projective math to say,
1490000	1494000	all right, I've got my cube here.
1494000	1496000	You know, I want it to look like that,
1496000	1499000	but when I draw it, I've got that on there.
1499000	1502000	How do we figure out which lines that we're going to erase?
1503000	1506000	And that was, you know, that occupied research for a while
1506000	1508000	to figure out effective ways to do that
1508000	1512000	without spending at the time the scary divide costs for different things,
1512000	1516000	and you'd have lots of interesting work being going on.
1516000	1520000	But when we eventually got raster displays where we could fill them in,
1520000	1523000	of course, at that point people filled in the surfaces of the cube,
1523000	1525000	they're all grayscale at that time,
1525000	1527000	so you can draw a cube and say, well, this will be the light face,
1527000	1529000	this will be the dark face,
1529000	1531000	but that was neat at the time,
1531000	1534000	but that was not sort of what things look like in reality.
1534000	1538000	So people started taking the steps that they could to try and say,
1538000	1542000	what do we need to do to make this more approximate what we see with our eyes?
1542000	1547000	And this has been a path that's been driven probably more than half
1547000	1550000	by sort of ad hoc approaches about just,
1550000	1555000	well, what's reasonably easy for us to do that gets us somewhat closer to it
1555000	1559000	while there's also been sort of a parallel path of saying,
1559000	1561000	well, what's the physics actually doing?
1561000	1565000	How do we make an actual solution for it?
1565000	1571000	So the earliest things that got added to the shading model for computer graphics
1571000	1577000	was if we assumed that there's going to be a light that's at some point,
1577000	1579000	in the beginning it wouldn't even be local,
1579000	1582000	you just say light is coming in from this direction.
1582000	1586000	So we want to be able to say what color or what shade
1586000	1590000	should each individual surface be based on where that light is.
1590000	1593000	So you've got the obvious things that if it's not facing the light,
1593000	1596000	no light hits it and you would draw it black.
1596000	1600000	So the question about things that are directly facing the light,
1600000	1602000	so if you've got light coming in,
1602000	1605000	if you have a surface completely perpendicular to it,
1605000	1607000	you make that your brightest color.
1607000	1610000	If you've got a surface that's completely parallel with it,
1610000	1612000	it gets no light, you make that zero.
1612000	1614000	So you've got some curve that goes between it
1614000	1617000	to say how bright something should be.
1617000	1623000	And it turns out that that's a fairly straightforward bit of math to solve
1623000	1627000	where you have light coming in at a certain angle,
1627000	1630000	you've got the normal to the surface,
1630000	1634000	the amount of light that would strike a little surface there
1634000	1638000	is proportional to the cosine of this angle.
1638000	1640000	And that's actually, that's not an approximation,
1640000	1643000	that's actually a bit of ground truth.
1643000	1645000	If you've got the light coming in
1645000	1649000	and you've got something coming in at this angle,
1649000	1654000	a surface that's, let's see.
1654000	1656000	If you count the number of rays that go in
1656000	1661000	on something catching four of them directly, turning it down,
1661000	1663000	only covering two, two spaces there,
1663000	1665000	all that actually works out correct.
1665000	1668000	And this is the basis for a lot of the,
1668000	1670000	a lot of the real calculations for light transport,
1670000	1674000	not a hack actually part of real proper physics measuring.
1674000	1677000	So once you've got that basic approach,
1677000	1679000	you go back to your cube
1682000	1684000	and you get your light coming in
1684000	1688000	and you've got a brighter face, a brighter face, a darker face,
1688000	1690000	and the faces away from it are completely black
1690000	1691000	and then most people say,
1691000	1693000	well, we don't usually see things like that.
1693000	1696000	So now we get into the fudging and you say,
1696000	1698000	well, let's just brighten everything up a little bit.
1698000	1700000	We'll add an ambient term.
1700000	1702000	So you sort of just add this minimum level
1702000	1704000	to everything on the back side.
1704000	1705000	And that helps a little bit.
1705000	1707000	If you've got a cube, then everything looks pretty much great
1707000	1710000	because it's a constant color just on the side
1710000	1712000	that you might not see over there.
1712000	1714000	But if you've got something more complex,
1714000	1717000	everything that's not facing away from the light
1717000	1719000	winds up being the same color.
1719000	1720000	And it's clearly not correct.
1720000	1721000	It's not what you'd like,
1721000	1726000	but it was all that seemed reasonable to do at the time.
1726000	1729000	The next step was to start looking at surfaces
1729000	1732000	that are more than these perfectly diffuse reflectors.
1732000	1734000	If you model your cube like this,
1734000	1737000	it looks kind of like it was maybe carved out of chalk
1737000	1740000	and it can be a decent representation of that.
1740000	1743000	But very few of the surfaces that we see around us
1743000	1745000	are really that simple.
1745000	1748000	Most things have some kind of a shine or highlight on them.
1748000	1750000	As we look around, you can see reflections
1750000	1752000	and highlights on all sorts of things
1752000	1754000	and the obvious bits of metal and plastic,
1754000	1756000	little things that you might hold in your hand.
1756000	1759000	I can look at all these different shines and reflections
1759000	1761000	on the plastic that I'm holding here.
1761000	1764000	Now, the observation was made
1764000	1766000	that the highlights on most objects
1766000	1768000	that weren't completely mirrors,
1768000	1771000	they tended to be something like a bright hot spot,
1771000	1774000	like if you had your sphere here,
1774000	1775000	you would have a bright hot spot
1775000	1778000	that kind of faded a little bit around there.
1778000	1780000	And just by looking at that and saying,
1780000	1785000	well, what could we do that would be kind of like that?
1785000	1787000	The observation was made that,
1787000	1791000	well, if you take this sort of cosine arrangement here,
1791000	1793000	this makes this nice broad fall off.
1793000	1798000	It makes over the entire surface of the sphere coming from that.
1798000	1801000	It'll fade off to halfway around the light.
1801000	1804000	But if you wanted something that was really tight,
1804000	1807000	the thought was, well, we can just take this value
1807000	1809000	and raise it to a higher power.
1809000	1811000	We can just take this and go, you know,
1811000	1814000	square it, cube it, take it to the 20th power,
1814000	1818000	which can be done effectively, mathematically, quite cheaply.
1818000	1821000	This has no basis in physical reality at all.
1821000	1824000	This is a completely ad hoc approach.
1824000	1825000	But it worked out okay.
1825000	1829000	And this is what the fog lighting model was about,
1829000	1833000	where you separate it into your diffuse lighting,
1833000	1836000	which is more or less what color the surface is,
1836000	1838000	and then your specular lighting,
1838000	1840000	which is what the highlights are going to look like.
1840000	1844000	So you had this other value to play around with,
1844000	1846000	and that was the specular power.
1846000	1850000	And nowadays, I regret using that in my terminology,
1850000	1852000	where we have power maps,
1852000	1855000	and nobody understands what those are.
1855000	1858000	They relate to the specular exponent,
1858000	1861000	what you're going to take something to a power of to tighten it.
1861000	1864000	The better terminology that's used more often now
1864000	1867000	is a roughness map, where you have a mapping,
1867000	1870000	and you also do it in logarithmic space rather than linear,
1870000	1872000	but more or less, that's still today,
1872000	1874000	what a lot of graphics involves,
1874000	1876000	is you've got a roughness parameter,
1876000	1880000	which affects this exponent that you take this extra vector
1880000	1882000	to generate your specular highlights for.
1882000	1886000	And again, it would make so if you're rendering your cube
1886000	1888000	and you get the light at the right angle,
1888000	1891000	like if I'm looking at this here and the light's over here,
1891000	1894000	it hits that, if that's at that right reflection angle,
1894000	1897000	then you'll get a nice bright shade on there.
1897000	1900000	That flat surface will catch the light and it will glint at you,
1900000	1904000	and that would be looked at as a real advance for the rendering.
1904000	1906000	So you've got something that looks diffused,
1906000	1908000	but when it moves into the light,
1908000	1910000	it kind of catches a flash of light and fades out.
1910000	1915000	So the facets on these solid shaded models started looking better.
1915000	1918000	Now, the next thing that people wanted to do is,
1918000	1921000	okay, we've got enough cubes and tetrahedrons
1921000	1924000	and dodecahedrons and whatever.
1924000	1927000	So we want to start making things that look more realistic.
1927000	1929000	We need to have a teapot.
1929000	1932000	We need to have a curved surface in some way.
1932000	1935000	So you make some curved surface like this.
1935000	1937000	There was a lot of work in the early days
1937000	1941000	on directly rasterizing curved surfaces, drawing them directly,
1941000	1945000	but all the real-time graphics, almost all of it,
1945000	1948000	has been a matter of turning your curved surfaces
1948000	1951000	into approximations with flat surfaces.
1951000	1955000	So you've got something that is theoretically a curve,
1955000	1960000	but really it's a bunch of facets.
1960000	1963000	So if you apply the lighting model there to it,
1963000	1965000	you see all of these facets.
1965000	1969000	It stands out as like, okay, you've just carved this out
1969000	1971000	with all these flat planes,
1971000	1973000	and it doesn't fool you into thinking
1973000	1976000	that this is this smooth-curved object.
1976000	1978000	So the next step in graphics that went on
1978000	1984000	was adding the interpolation across the vertexes,
1984000	1987000	where instead of calculating a value for a face,
1987000	1991000	you calculate it for a given vertex, for one corner,
1991000	1993000	and then you just average.
1993000	1995000	You interpolate across there
1995000	1997000	so that a point here is going to be some average
1997000	2001000	between three or four of the points that make it up.
2001000	2004000	And that works surprisingly well.
2004000	2007000	If you're looking again at a diffuse surface,
2007000	2010000	it works out just about as good as you'd like.
2010000	2013000	There are some minor artifacts called mock bands
2013000	2015000	that you get if it changes too much,
2015000	2018000	but if your tessellation's okay, that works out all right.
2018000	2022000	It works out less well with the specular highlights,
2022000	2026000	and the reason is that your specular highlight,
2026000	2028000	if you've got...
2028000	2030000	It might show up like if you were supposed to have
2030000	2033000	some hot spot right here in the middle of a surface.
2033000	2035000	If you calculate it at the outside,
2035000	2039000	this is going to be almost zero for the specular, almost zero.
2039000	2042000	And when you interpolate across it, it's going to have nothing.
2042000	2044000	You're just not going to see it.
2044000	2046000	You'll only see a highlight when the specular comes up
2046000	2048000	at the very edges.
2048000	2049000	And this is what's still to this day
2049000	2052000	sort of the standard open GL shading model is.
2052000	2056000	It's gross shading with calculations at the vertexes,
2056000	2059000	interpolating the colors or parameters across it.
2059000	2062000	So this model is still with us to this day
2062000	2065000	for a lot of sort of quick stuff that's not
2065000	2067000	visual simulation oriented.
2067000	2069000	If you just write something using lighting with open GL,
2069000	2071000	that's the model that you get
2071000	2074000	if you turn on specular highlights.
2074000	2077000	In graphics where they care more about visual quality,
2077000	2080000	what started happening was interpolating
2080000	2082000	not the color across it,
2082000	2084000	but interpolating the normal,
2084000	2087000	sort of the curvature across each point
2087000	2090000	and then applying the lighting model at every pixel.
2090000	2094000	And at the time, this was like a flagrant use of processing power
2094000	2097000	because we're like, okay, these calculations are expensive.
2097000	2100000	We have to do these distance calculations, dot products,
2100000	2102000	exponential power stuff.
2102000	2105000	And when you just do it at each vertex on your cube,
2105000	2108000	okay, so you've got a handful of vertexes
2108000	2110000	that you need to calculate.
2110000	2112000	But even on an old school display,
2112000	2114000	you would have hundreds of thousands of pixels.
2114000	2116000	And so if you're drawing that there,
2116000	2119000	going from doing this maybe a few hundred times
2119000	2122000	or a few thousand times to hundreds of thousands of times
2122000	2125000	for a scene was a large use of additional processing power.
2125000	2128000	But it got you the good looking areas
2128000	2131000	where you could have a highlight that looked about
2131000	2133000	like it should moving across the surface
2133000	2136000	or sitting on a floor looking stable there
2136000	2138000	as you moved around.
2138000	2140000	People that have been in following PC graphics
2140000	2142000	for the last couple of decades,
2142000	2145000	we've seen games that do not have interpolation
2145000	2148000	in the different ways where the lighting would change dramatically.
2148000	2152000	We always had the problem of densely-tesolated characters
2152000	2156000	or objects and then very low-tesolation on the world.
2156000	2158000	And the problem that you'd run into with that
2158000	2162000	is that if you're applying one of these interpolation schemes to it,
2162000	2165000	you would have something that you could never have highlights
2165000	2168000	in the middle of the surface, only at the corners.
2168000	2171000	And there were also issues with perspective math and clipping
2171000	2174000	that would mean that it would change as a really big polygon
2174000	2177000	clipped by the edge of the screen in almost all cases
2177000	2179000	the way people did it.
2179000	2181000	And this was one of the big things that pushed me
2181000	2185000	during the Quake timeframe to use light maps for the first time
2185000	2187000	where instead of I had seen other games
2187000	2189000	that were doing lighting at the vertexes
2189000	2191000	and I didn't think it wasn't good enough,
2191000	2193000	you couldn't get anything resembling a shadow,
2193000	2196000	you had all these swimming artifacts with the lighting
2196000	2199000	and it just didn't give what I wanted to see.
2199000	2202000	And while Quake didn't have any specular highlights,
2202000	2204000	it did have these...
2204000	2206000	You had samples every 16 pixels in the light maps
2206000	2208000	that we interpolated across those,
2208000	2213000	and that gave us the look that was very important for it.
2213000	2215000	And we didn't get to actually...
2215000	2217000	It was only all the way up to Doom 3
2217000	2221000	where we would start doing per-pixel operations like this
2221000	2224000	to get the much better calculations.
2224000	2227000	So even with this level of graphics at that time
2227000	2230000	where you've just got sort of these fog lighting,
2230000	2234000	simple models, hacks like the specular exponent
2234000	2236000	and the ambient term,
2236000	2238000	we started to see some offline things being rendered
2238000	2240000	like some movies, you know, early work,
2240000	2243000	some of the early NASA promotional work that Jim Blinn did
2243000	2246000	were significant in the sort of growth of all of this.
2246000	2249000	And then we finally saw some feature theatrical films
2249000	2252000	with like The Last Star Fighter and especially Tron
2252000	2254000	where you would see...
2254000	2256000	You go back and you look at Tron
2256000	2258000	and you have a lot of these sort of
2258000	2261000	gross-shaded, solid-modeled things on there
2261000	2263000	with your light cycles or recognizers and so on.
2263000	2265000	And they were doing something...
2265000	2267000	They were intelligently picking a battle
2267000	2269000	that could be won at the time.
2269000	2271000	If you said, well, we have to go ahead
2271000	2273000	and render photo-realistic humans,
2273000	2275000	we were nowhere close to up to that task.
2275000	2277000	But we could do geometric solid models
2277000	2279000	that looked good enough to show on the big screen,
2279000	2282000	and that was a pretty big breakthrough.
2282000	2284000	And simultaneously with this,
2284000	2287000	there was an alternate approach to
2287000	2290000	the way graphics were being drawn that...
2290000	2293000	So most of the early graphics were done
2293000	2295000	with rasterization where if you've got
2295000	2299000	your computer screen and you've got
2299000	2302000	your quad on here,
2302000	2304000	you would draw this on a computer
2304000	2306000	by calculating these equations of the lines
2306000	2308000	and then you would usually just kind of
2308000	2312000	walk across building up your rows of pixels.
2314000	2316000	The whole process of hidden surface removal
2316000	2318000	is another step on top of this
2318000	2320000	where if you've got lots of cubes,
2320000	2322000	how do you know which one draws on top of the other one?
2322000	2324000	And this was another thing, if you look back
2324000	2327000	in research from the 70s especially,
2327000	2330000	there was tons of work going on on hidden surface removal
2330000	2332000	of these clever different algorithmic ways.
2332000	2334000	Today we just kill it with a depth buffer.
2334000	2337000	We just throw megabytes and megabytes of memory
2337000	2340000	and the problem gets solved much, much easier.
2340000	2343000	But this path of rasterization is still with us today.
2343000	2347000	GPUs don't rasterize in scanline order like this.
2347000	2350000	They follow crazy winding paths
2350000	2353000	to maximize memory bandwidth to fill up tiles,
2353000	2355000	to rasterize them in different pieces,
2355000	2357000	and they rasterize all quads at a time,
2357000	2360000	but it's still essentially a rasterization method
2360000	2363000	where we have shapes and we figure out how to rasterize them.
2363000	2365000	We figure out which pixels they're going to cover,
2365000	2368000	and then we figure out what we want to do with them.
2368000	2370000	The alternate scheme which was also developed
2370000	2373000	in the later 70s is ray tracing
2373000	2375000	where instead of saying, alright,
2375000	2377000	I'm starting with my object,
2377000	2380000	I'm going to take these four vertexes
2380000	2383000	that are in space, I'm going to take my virtual camera
2383000	2385000	and I'm going to transform them
2385000	2387000	and find out where they are on the screen
2387000	2388000	and then fill them in.
2388000	2390000	Ray tracing goes the other way
2390000	2394000	where you start off with your camera in space somewhere,
2394000	2396000	your virtual viewing screen,
2396000	2400000	and through that you send rays out into your world
2400000	2404000	and you intersect them with your cube over here,
2404000	2406000	and if it hits that cube first,
2406000	2408000	it knows it didn't hit anything behind that,
2408000	2410000	it's got a surface point there,
2410000	2413000	and it can apply whatever shading model it needs to.
2413000	2416000	The thing that ray tracing gave,
2416000	2418000	I mean it's radically slower,
2418000	2420000	thousands of times slower than ray tracing
2420000	2423000	if you're doing just the most straightforward thing.
2423000	2425000	If you just want to draw that cube,
2425000	2428000	you can draw the same thing with ray tracing,
2428000	2431000	it's just going to be a thousand times slower with ray tracing,
2431000	2433000	but it allowed a couple things
2433000	2436000	that were either very difficult or impossible
2436000	2438000	to do properly with ray tracing,
2438000	2440000	and the thing that you would always see
2440000	2443000	in ray tracing demos is your shiny reflective spheres.
2443000	2445000	So you've got a little chrome ball
2445000	2448000	and the fact that you could see the world reflected into it,
2448000	2450000	and then back into your eye
2450000	2452000	was the thing that ray tracing could do
2452000	2455000	that rasterization couldn't do really worth a damn at all.
2455000	2457000	You would approximate it with environment maps
2457000	2459000	and different things,
2459000	2461000	but for reflections and for refraction
2461000	2463000	doing those things properly,
2463000	2466000	ray tracing was really the only good solution,
2466000	2469000	but it wasn't practical even for most offline work.
2469000	2472000	I can remember looking at old research papers
2472000	2475000	of things that are run on deck vax computers,
2475000	2477000	and they talk about the number of hours
2477000	2479000	to render these really trivial scenes,
2479000	2481000	just a few boxes in the eye,
2481000	2483000	maybe a sphere sitting there,
2483000	2486000	and the idea of rendering complete worlds with it
2486000	2489000	was fantasy at the time,
2489000	2491000	but it did address some of those problems
2491000	2494000	for the first time with reflection and refraction,
2494000	2497000	and it also much more elegantly solved shadows,
2497000	2500000	which all of this stuff talking about surface interactions
2500000	2503000	and finding out what you hit with the light,
2503000	2506000	that kind of dodges one of the really hard problems,
2506000	2508000	which is saying that, well,
2508000	2511000	the light obviously doesn't reach through things.
2511000	2513000	If you transform something up here
2513000	2517000	and you transform another surface down here,
2517000	2518000	and the light's up here,
2518000	2521000	this should be in shadow because it's blocked by this,
2521000	2525000	but that turns out to not be a particularly trivial thing to resolve.
2525000	2527000	It's basically the same problem
2527000	2529000	of how you view something from your point of view,
2529000	2531000	but viewed from the light's point of view,
2531000	2533000	and that can mean that,
2533000	2536000	well, if every light in your scene
2536000	2539000	has to do a similar rendering process
2539000	2541000	to what your view does,
2541000	2543000	possibly harder because there are omnidirectional lights
2543000	2545000	in many different cases,
2545000	2547000	and it's just a tough problem,
2547000	2548000	and as with so many things,
2548000	2551000	there's a lot of wonderful research in the 70s and 80s
2551000	2554000	going through about how you do shadows effectively
2554000	2556000	with these different analytic solutions.
2556000	2558000	In the end, we had a brief period
2558000	2562000	where stencil volumes were an effective way to do things,
2562000	2565000	but now it's essentially all shadow buffers,
2565000	2567000	where we really do take every light,
2567000	2569000	render an image from their scene,
2569000	2573000	and use that to back project onto there to figure things out.
2573000	2575000	But that was one thing that ray tracing
2575000	2577000	had an elegant solution for.
2577000	2579000	Again, if you're already a thousand times slower,
2579000	2581000	who cares if you're another factor of two or three slower?
2581000	2583000	For every point you hit, you go ahead and say,
2583000	2585000	I've got my light up here,
2585000	2588000	I'll trace to the light or to however many lights I've got,
2588000	2590000	and if there's something that blocks it,
2590000	2593000	then that's going to be shadowed and I can take it out.
2593000	2598000	So ray tracing always had this much clearer abstraction
2598000	2599000	of what you're doing.
2599000	2602000	It's easy to tell that you're sending out a little array,
2602000	2605000	you hit something, you determine whether you hit all the other lights,
2605000	2608000	or if you bounce or refract into something else.
2608000	2610000	So it's always been easy and clear.
2610000	2615000	It's just had this thousand times slower problem to deal with.
2615000	2619000	So the advances that were being made on graphics,
2619000	2621000	kind of after this early age,
2621000	2625000	focused on the changes in what you can do with the surfaces
2625000	2627000	as the first obvious thing.
2627000	2629000	And a lot of these were driven by
2629000	2632000	sort of artistic and aesthetic concerns,
2632000	2635000	where we got, if you pull up a 3D rendering program
2635000	2636000	and you look at their material stuff,
2636000	2638000	there's a whole page full of options,
2638000	2640000	things that you can tweak, knobs you can turn,
2640000	2642000	checkboxes you can set,
2642000	2646000	and each of these had some use case where somebody wanted this
2646000	2650000	because it made their image generally look a certain way that they wanted.
2650000	2652000	Very rarely were these things driven by
2652000	2655000	sort of physically correct rendering.
2655000	2658000	And there was a huge plethora of these things that came out.
2658000	2661000	Every different program had a different set of options.
2661000	2664000	You always had this fallback of you've got your diffuse colors,
2664000	2666000	your specular color, your roughness,
2666000	2670000	this basic fog shading model persists to this day.
2670000	2674000	But now we have a ton of other things that we can tag on there,
2674000	2676000	things that are subsurface approximate,
2676000	2678000	scattering approximations, Fresnel lighting,
2678000	2682000	different frequency response on surfaces.
2682000	2686000	It's like some of the things do have physical basis to them.
2686000	2688000	Like one obvious thing,
2688000	2693000	the Fresnel effect is the effect that as you get more and more glancing to something,
2693000	2695000	the reflection gets stronger and stronger.
2695000	2699000	And you see this, this is what makes water and glass look like water and glass.
2699000	2701000	If you look straight at them,
2701000	2704000	you pretty much see straight through them without a whole lot of reflection.
2704000	2706000	But as you get more and more edge on,
2706000	2708000	even a surface like this,
2708000	2710000	where when I'm looking at this at this angle here,
2710000	2714000	I've got a very, very strong clear sense of the slightly wavy reflection
2714000	2716000	of that white line there,
2716000	2719000	while if I look at it right here, it's barely visible.
2719000	2722000	So that's a physical effect in reality
2722000	2727000	that you can work through the real physics equations of why this happens.
2727000	2730000	But people, again, sort of called up the trustee,
2730000	2732000	raise a cosine to a power,
2732000	2736000	and it sort of looks like what we want when we're dotting a couple vectors together.
2736000	2739000	So that has, that's something that's based off plausible physics,
2739000	2742000	but generally only roughly approximated.
2742000	2744000	And there are other things like that with,
2744000	2748000	like the change in some metals get their metallic look
2748000	2751000	because they slightly change colors as they get towards grazing angles.
2751000	2754000	So again, you can calculate the real physics for that,
2754000	2755000	or you can just sign it, kind of say,
2755000	2758000	well, this color sort of changes to this color at the edges
2758000	2761000	and start interpolating between them.
2761000	2766000	But lots and lots of good work and lots of high-budget movies and so on
2766000	2770000	were built with these sort of very ad hoc techniques.
2770000	2772000	But sort of in parallel with this,
2772000	2776000	the other big revolution that was happening was global light transport,
2776000	2779000	global illumination.
2779000	2782000	It comes back to that whole hack of the ambient term,
2782000	2786000	this sense that obviously where, okay, if I'm right here,
2786000	2788000	the lights are only directly hitting the outside.
2788000	2791000	The back of my hand has no direct view to any light,
2791000	2794000	but it's still quite bright and clearly illuminated.
2794000	2798000	It's bright because all those lights hit this white board,
2798000	2802000	bounce off of that, and wind up lighting my hand from the back.
2802000	2804000	And you can see, like, color changes,
2804000	2808000	like if I move up here where it's mostly covered by the blue marker on there,
2808000	2810000	the blue tints to it.
2810000	2814000	And this recognition that so much of what we consider important
2814000	2816000	in the visual field is actually indirect.
2816000	2818000	It's not just a matter of, here's the light,
2818000	2820000	here's the surface, what's the reaction.
2820000	2824000	Because we come back to how much of the light gets bounced around.
2824000	2828000	And there's a term called the albedo of a surface,
2828000	2832000	which is what fraction of the light gets reflected versus absorbed.
2832000	2834000	And there's some tricky terminology with this
2834000	2837000	because you can have either the total solar albedo
2837000	2840000	where you talk about how much energy comes off of the sun.
2840000	2842000	And this is used for climate modeling
2842000	2845000	and some remote imaging and things like this where you matter.
2845000	2849000	But you've also then got the visible albedo,
2849000	2851000	which for rendering is what we care about.
2851000	2854000	And the point is that the best reflectors,
2854000	2857000	your chrome sphere that's mirrored or your white piece of chalk
2857000	2859000	or your freshly driven snow,
2859000	2862000	those can reflect 90-ish percent of the light.
2862000	2865000	While your darkest surfaces, your lump of black coal
2865000	2870000	or asphalt in some cases, might only reflect 5%.
2870000	2873000	But when you're reflecting 90% of the light,
2873000	2875000	what that means is that if you're in a room
2875000	2878000	that has mostly white surfaces,
2878000	2882000	a single bit of light coming out of your light emitter
2882000	2886000	might bounce around a dozen times before it finally gets absorbed.
2886000	2889000	So it could take a very complex path
2889000	2891000	before it winds up getting to your eye.
2891000	2896000	And this is why we could have cases like a dark room
2896000	2898000	illuminated only through the crack under the door.
2898000	2901000	But you can still wind up looking even around corners.
2901000	2903000	You can go into the closet in the dark room
2903000	2906000	illuminated under the keyhole and still find things somewhat lit.
2906000	2910000	And that's because of this many bouncing path that light can take
2910000	2912000	from the light emitter coming around
2912000	2914000	until it actually gets to your eye.
2914000	2919000	And this turns out to be a really frighteningly complex
2919000	2922000	and expensive problem to solve properly.
2922000	2927000	The first sets of attempts at this dealt with
2927000	2929000	radiosity approaches.
2937000	2940000	And a lot of this was driven by
2940000	2943000	engineering things beyond just making pictures
2943000	2945000	because you would talk about things like heat management.
2945000	2948000	If you have a certain amount of energy coming in here,
2948000	2950000	how hot is something going to get
2950000	2952000	and what's the hottest part going to be
2952000	2954000	because that matters for a lot of engineering terms.
2954000	2958000	So you can do things like, you know,
2958000	2962000	make a complex surface here
2962000	2966000	and say energy is coming in here.
2966000	2969000	How much of this energy makes its way to here,
2969000	2972000	to here, here, here.
2972000	2974000	And it's not just a matter of what,
2974000	2976000	that's basic geometry calculations to say
2976000	2979000	how much of this is directly impinging on that surface.
2979000	2981000	What gets complicated then is you say,
2981000	2984000	well, this reflects 50% of its light
2984000	2988000	and that 50% goes to all of these different ones here.
2988000	2992000	And this one reflects 50% and that goes to all the ones here.
2992000	2995000	And, you know, in theory, you go,
2995000	2997000	if you're doing everything floating point math,
2997000	2999000	you can keep saying you can bounce it 100 times
2999000	3004000	and say you get, well, 0.0001% winds up coming back to another spot.
3004000	3007000	At some point you just say it's converged well enough,
3007000	3009000	this solution is not going to change much
3009000	3013000	no matter how many more bounces that you do.
3013000	3016000	So the radiosity solutions work by creating
3016000	3021000	this giant linear algebra matrix of coefficients
3021000	3024000	where you say you identify all of your surfaces
3024000	3027000	and you say how much can, what form factor,
3027000	3029000	what fraction of the energy goes
3029000	3031000	to all of the other different surfaces.
3031000	3034000	And then you may be solving this 10,000 by 10,000 matrix
3034000	3037000	and there was a lot of work on the optimizations
3037000	3041000	that go into solving this more effectively.
3041000	3044000	But there are two reasons why radiosity
3044000	3047000	is not a particularly relevant technique
3047000	3049000	for computer graphics anymore.
3049000	3052000	One aspect that it sort of glossed over
3052000	3054000	was the notion of occlusion,
3054000	3057000	where if you've got a surface,
3057000	3059000	if this goes out here
3059000	3062000	and you go around the dark corner,
3062000	3064000	we've got this surface here,
3064000	3067000	it's clear that it can't see this surface at all.
3067000	3070000	It can see this surface, this surface,
3070000	3072000	it can see part of this surface,
3072000	3074000	a fraction of it, and it can see
3074000	3077000	an even smaller part of this surface over here.
3077000	3080000	So you have to calculate these occlusion terms
3080000	3083000	where you're saying each surface,
3083000	3086000	unless you're in your deformed, stretched icosahedron
3086000	3091000	or some solid that has no convex,
3091000	3093000	no concavities inside it,
3093000	3096000	you're going to have these aspects of occlusion.
3096000	3099000	And this becomes a very, very difficult thing
3099000	3101000	to solve completely analytically.
3101000	3104000	If you're trying to stay in just analytic world
3104000	3106000	and you try to solve, well, okay,
3106000	3108000	we have this surface, including this surface,
3108000	3111000	and then another surface here and another surface here,
3111000	3114000	it's the potentially visible set problem
3114000	3118000	on every polygon, and it's an analytic nightmare.
3118000	3121000	So you wind up solving this by approximating.
3121000	3124000	You just say, all right, I've got a surface here,
3124000	3127000	I'll throw a bunch of rays to test out here,
3127000	3129000	and I'll throw 20 rays out,
3129000	3132000	and if 10 of them get through, I'll say I'm 50% occluded.
3132000	3135000	Now, a purist will start blanching and saying,
3135000	3138000	yeah, but that's random, there's this randomness,
3138000	3141000	you might be misestimating, there could be pathological cases,
3142000	3144000	and there's some truth to that.
3144000	3146000	Anytime that you're sampling things,
3146000	3149000	there are sampling cases that can turn out pathological.
3149000	3151000	But the other side of that then goes,
3151000	3154000	it's like, well, we're tracing rays.
3154000	3157000	We have another technique that involves lots of tracing rays
3157000	3159000	and come about it from a different route,
3159000	3162000	which is to say, well, let's start with ray tracing,
3162000	3164000	and let's try and solve the global illumination problem
3164000	3166000	using nothing but ray tracing,
3166000	3168000	which leads to path tracing.
3172000	3175000	So you could make a rendering solution,
3175000	3178000	a rendering program where you start with your light emitter,
3178000	3181000	you throw photons out in all directions,
3181000	3184000	you have your cube here,
3184000	3189000	and somewhere you have your eye.
3191000	3195000	You will get a physically accurate image
3195000	3199000	if you throw random rays, pick a random direction,
3199000	3202000	it goes down, some of them go off here, some of them go up here,
3202000	3206000	but eventually some of them wind up hitting a surface.
3206000	3209000	And then based on what that surface is,
3209000	3212000	you determine which direction the light goes out.
3212000	3214000	It's going to be random.
3214000	3216000	Again, your perfect reflector would not be random,
3216000	3219000	it would go off in exactly the perfect reflection direction.
3219000	3223000	All other materials will throw light in essentially all directions,
3223000	3225000	but with different distributions,
3225000	3228000	there will be more bias towards the reflection direction,
3228000	3230000	there will be a chance that they go everywhere.
3230000	3234000	So one of your billions of light rays goes out, hits there,
3234000	3237000	it decides it's going to reflect up, another one goes out, hits here,
3237000	3239000	it's going to reflect over,
3239000	3243000	but eventually some ray is going to come down, hit a point here,
3243000	3246000	and then reflect at exactly the direction that goes over
3246000	3248000	and hits the surface of your eye,
3248000	3252000	which the lens can then focus into something that you can perceive.
3252000	3255000	And this has an interesting biological side to it.
3255000	3258000	The larger an eye is, the more light it can collect,
3258000	3261000	which is why animals that will generally hunt at night
3261000	3264000	can have larger eyes, larger openings into their eye,
3264000	3267000	and why telescopes get bigger to see more.
3267000	3269000	This is what's happening in reality.
3269000	3273000	Zillions and zillions of photons come off, they bounce around,
3273000	3277000	and eventually some tiny fraction of them hit the lens of your eye
3277000	3279000	or your detector or whatever you're using,
3279000	3282000	and can be resolved into an image.
3282000	3284000	So you can make an image like this.
3284000	3285000	People have done it.
3285000	3288000	It is extraordinarily inefficient,
3288000	3290000	but you can solve everything with it.
3290000	3292000	This is a complete and accurate solution.
3292000	3297000	As accurate as your analysis of what the light's distribution is
3297000	3299000	and what the surface's distributions are,
3299000	3301000	this can be as good as that.
3301000	3304000	You can have your extra surface up here
3304000	3307000	where you hit the ceiling, you bounce back,
3307000	3310000	you hit a wall over here, you bounce back over,
3310000	3313000	and then eventually make your way to the eye.
3313000	3314000	And you start thinking,
3314000	3317000	well, you can have 10 bounces going in a random direction.
3317000	3320000	Your eye is only some handful of millimeters across,
3320000	3322000	but you're projecting an area this size.
3322000	3324000	How many traces do you have to do?
3324000	3327000	Well, you have to do billions and billions,
3327000	3330000	and you wind up with a very noisy image at that.
3330000	3331000	But if you did enough of them,
3331000	3334000	this would come out with the right solution.
3334000	3336000	Trace array, it either gets absorbed
3336000	3339000	or it reflects into a different way or transmits through it.
3339000	3341000	You've got this whole, the model that you use,
3341000	3346000	the bidirectional subsurface scattering distribution function.
3346000	3349000	So as accurate as that is, determines what happens to the lights.
3349000	3351000	You could have models of the lights.
3351000	3354000	There are these standards like IES light tables that have,
3354000	3356000	you know, those particular lights,
3356000	3358000	you could look up what's the distribution of photons
3358000	3359000	that come off of them.
3359000	3361000	You could look it up for all the different ones.
3361000	3365000	And as good as the data is, your simulation can be
3365000	3368000	as good as what you feed it.
3368000	3371000	But it's hopelessly, hopelessly inefficient.
3371000	3374000	What we wind up doing in different ways
3374000	3376000	that can be reasonable approximations
3376000	3381000	are instead of tracing, throwing rays out from the light,
3381000	3384000	which are mostly going to go nowhere near what you want,
3384000	3388000	you can reverse the trace and go from your eyes
3388000	3391000	like in the kind of classic ray tracing.
3391000	3393000	Go to the surface.
3393000	3397000	And then you start getting into the cases where one of the key,
3397000	3399000	one of the sort of buzzwords in high-end rendering
3399000	3403000	is whether a renderer is biased or unbiased.
3403000	3407000	A biased renderer is not necessarily perfect physics,
3407000	3410000	but it's almost, they do it because it's going to be a lot faster.
3410000	3412000	Like the standard thing that you do,
3412000	3414000	if you don't mind being a biased renderer,
3414000	3416000	you say, well, I have all these directions
3416000	3418000	that I could go to the world.
3418000	3419000	I could go up to the ceiling.
3419000	3421000	I could go down to the floor.
3421000	3423000	But I know I've got all of these lights up here,
3423000	3426000	so I'm going to send most of my rays towards the lights
3426000	3429000	because those are almost certainly going to be the things
3429000	3431000	that really make a difference.
3431000	3433000	So you go, you hit your point,
3433000	3436000	and you say trace against every light.
3436000	3438000	You've got three lights going here.
3438000	3440000	Let's run a trace up against them,
3440000	3443000	check for occluders, solid things blocking it off.
3443000	3446000	And then you start throwing random amounts of rays
3446000	3448000	in different directions.
3448000	3450000	You can be smart and base it on what the character
3450000	3452000	of the surface is.
3452000	3456000	It again comes down to these distribution functions
3456000	3458000	where you could have rays where it's more likely
3458000	3460000	that if light comes in this way,
3460000	3463000	it's more likely that it's going to make it out towards your eye,
3463000	3466000	so it makes sense to sample that more often.
3466000	3469000	And there is tons of work going on to this day.
3469000	3472000	This is sort of where the active state of the art
3472000	3474000	of graphics rendering is,
3474000	3477000	where you, how you optimize this path tracing
3477000	3479000	to be more efficient in different cases.
3479000	3483000	But it is always then you're making your approximations
3483000	3485000	on what you want to do.
3485000	3487000	Because you can make, like the problem with this
3487000	3490000	is if you have, if you're biased
3490000	3493000	and you trace specifically to certain lights,
3493000	3496000	there could be combinations of surfaces here,
3496000	3499000	like you might have a surface here which is slightly emissive,
3499000	3502000	and if you wind up hitting that because you were tracing
3502000	3504000	towards the light, that's going to get overrepresented
3504000	3507000	based on, you know, versus something that's over here
3507000	3510000	that wasn't in the direction of one of the lights.
3510000	3513000	But this approach, you know, it pretty much works.
3513000	3517000	We do, like for the baking in idTech 5,
3517000	3520000	we have a very primitive lighting solution
3520000	3522000	because even though we do it offline,
3522000	3525000	we have to, the surface area of one of the maps in Rage
3525000	3528000	is about as much as the pixels that go into a feature film
3528000	3530000	and we have turnaround time.
3530000	3533000	So clearly we can't do these billions of ray traces
3533000	3535000	for every, what would be a frame of that.
3535000	3537000	We, you know, we have to keep these down
3537000	3539000	to some credible amount of time.
3539000	3543000	So what we do is when we're rasterizing a surface,
3543000	3545000	we don't even have the viewer at all.
3545000	3547000	We're doing a view-independent approach
3547000	3549000	for the global illumination.
3549000	3551000	And again, the terminology is problematic
3551000	3553000	because we have radiosity as terminology
3553000	3556000	in a lot of places as a synonym for global illumination
3556000	3558000	and technically it's not, it shouldn't be that way.
3558000	3560000	I mean, we have a visualizer called Rad Preview
3560000	3563000	even though it does not do a matrix calculation
3563000	3565000	for radiosity at all.
3565000	3568000	It's, you know, it is based on this more of a tracing approach.
3568000	3571000	So we get our surfaces, we look at all the lights
3571000	3573000	that we think should be affecting us,
3573000	3575000	we trace to them together,
3575000	3577000	we're affecting us.
3577000	3579000	We trace to them to get our shadows
3579000	3581000	and sample them to make soft shadows.
3581000	3583000	In fact, that's another important thing.
3583000	3585000	The way you get a soft shadow
3585000	3587000	is if you've got a surface
3587000	3590000	and you've got an object that's going to cast a shadow,
3590000	3594000	if you have, if you had a point light source,
3594000	3596000	so it was nothing but a teeny tiny point
3596000	3598000	that all the energy came out of,
3598000	3601000	then you would have a hard shadow edge.
3601000	3603000	It would look like Doom 3
3603000	3605000	where you've got fully illuminated
3605000	3607000	and then fully shadowed.
3607000	3610000	In reality, there's no such thing as a point light source
3610000	3613000	and this is an important thing to realize.
3613000	3616000	Everything, even if you look at a light bulb,
3616000	3618000	a dangling incandescent light bulb,
3618000	3620000	the photons are actually coming out
3620000	3621000	not off of a point,
3621000	3623000	but off of a little zigzaggy filament
3623000	3624000	that's inside that.
3624000	3626000	It has an area and the photons come off
3626000	3628000	distributed from that area.
3628000	3630000	Now, the sharpness of a shadow
3630000	3634000	depends on the ratio of the area of that emitter
3634000	3636000	to the distance that it's going across.
3636000	3640000	When you have a great big, broad fluorescent light assembly
3640000	3643000	and you've got a small occluder here,
3643000	3647000	everything is going to be lit to some degree.
3647000	3649000	You have...
3649000	3651000	Yeah, so in this case,
3651000	3654000	you might have only the very smallest area there
3654000	3656000	that would be solid, completely shadowed,
3656000	3657000	but as you move over,
3657000	3659000	you start to be able to see part of the light.
3659000	3662000	So it gets brighter and brighter
3662000	3665000	until you get to the point over here
3665000	3668000	where you can see the entire light emitter.
3668000	3670000	So we have...
3670000	3672000	To get the soft shadows in rages,
3672000	3673000	I'm...
3673000	3676000	Well, so if you looked at the original, the earlier quakes,
3676000	3678000	there were soft shadows in there,
3678000	3680000	but they weren't a matter of calculating soft shadows.
3680000	3683000	They were because we made a hard shadow calculation
3683000	3685000	and then we interpolated between it,
3685000	3687000	which is why you've got kind of the blurry,
3687000	3689000	stair-steppy edges there.
3689000	3693000	For Tech 5, we actually send a number of shadow samples,
3693000	3694000	and this is one of those things
3694000	3696000	that gets into performance trade-offs
3696000	3701000	where if a designer sets a very large area for a light source,
3701000	3703000	then it will have...
3703000	3706000	You'll have a very broad area of changing shadow resolutions,
3706000	3709000	and if you only put 16 tests to it,
3709000	3711000	that means you only have the possibility
3711000	3713000	of 16 bands of different lighting,
3713000	3715000	and that's in the best case if it comes out
3715000	3718000	exactly for your samples where they do their best good.
3718000	3721000	And it's completely possible to have,
3721000	3723000	if you've got a broad area light source,
3723000	3725000	to need hundreds of samples for every pixel
3725000	3728000	to determine how bright that should be.
3728000	3731000	And it can get worse in a lot of cases.
3731000	3734000	A lot of offline rendering may use thousands of samples
3734000	3737000	per fragment when you get into the global illumination.
3737000	3740000	So what we do from the direct lighting,
3740000	3743000	obviously it's a biased lighting approach there
3743000	3745000	because we sample directly to the lights,
3745000	3749000	but then we send out random rays from the surface
3749000	3751000	to see what else it hits,
3751000	3754000	and when it goes out and hits this surface up here,
3754000	3757000	then we apply a simplified version of the lighting to that.
3757000	3759000	We don't do all the full soft shadows,
3759000	3762000	but we do basic lighting approaches.
3762000	3765000	We've had options to do multiple additional bounces,
3765000	3767000	but this is what we live with
3767000	3770000	is some approach of sampling the global environment,
3770000	3773000	and we don't do it lots for each pixel.
3773000	3775000	What we wind up doing is
3775000	3781000	each point throws one or a few samples into different directions,
3781000	3783000	and then when we average them for this pixel,
3783000	3786000	we average over a broader range of pixels.
3786000	3788000	And these are the types of trade-offs
3788000	3791000	that everybody doing rendering makes different trades like this,
3791000	3794000	where you decide what you think is most important,
3794000	3797000	how much time you can afford to spend on things,
3797000	3802000	and you make your choices and you live with them after that.
3802000	3804000	But we know doing it right
3804000	3809000	is just a matter of throwing billions of rays in an ideal case.
3809000	3812000	You have to throw lots and lots into the environment.
3812000	3814000	We can make decent approximations now,
3814000	3818000	but we're going to soak up all the additional computing power
3818000	3819000	that can be given.
3819000	3821000	One of the saws in the offline rendering world
3821000	3826000	is that the frames will always take a half hour to render in most studios.
3826000	3829000	The more power they get, just the more things that they add to it.
3829000	3832000	There's hope that that's not a law of nature
3832000	3835000	that we are getting to faster turnarounds,
3835000	3839000	kind of like the pace of hard drive size versus usage.
3839000	3844000	But it does seem likely that the path forward is lots and lots of rays,
3844000	3847000	physically accurate material definitions,
3847000	3853000	and approaches that are approximations of the sampling of path tracing.
3853000	3854000	We can do...
3854000	3857000	There are some neat demos going around today,
3857000	3861000	like the Brigade Path Tracing demo, which is real-time,
3861000	3865000	and it's doing simple path tracing from sort of a parallel outdoor light,
3865000	3868000	and it's noisy and fizzly as it comes in,
3868000	3871000	but you can stop and watch it kind of come in more crisply.
3871000	3875000	And eventually, this is going to be the way things go.
3875000	3877000	This is the way we're going to be rendering,
3877000	3882000	but we still have maybe a couple orders of magnitude before it's really competitive.
3882000	3885000	I think one more order of magnitude in performance,
3885000	3888000	and you'll start seeing it used for some real things,
3888000	3892000	but you have to have a good reason to step away from rasterization.
3892000	3895000	But probably when we get two orders of magnitude,
3895000	3898000	then you start seeing it as one of the more general tools.
3898000	3901000	And the reason that it's winning in the offline world,
3901000	3903000	even though it's still slower,
3903000	3905000	people still care about how long their renderings take,
3905000	3908000	even if you're making a feature film or a TV commercial.
3908000	3910000	It matters for your iteration time.
3911000	3916000	The sense is that you get more out of this being understandable
3916000	3919000	with rasterization, environment maps, shadow maps.
3919000	3922000	There are all these knobs that people just...
3922000	3924000	The best people know what they mean,
3924000	3929000	but 90% of the people working in visual and computer graphics,
3929000	3932000	they have these things that they know push this this way,
3932000	3934000	and it kind of does something,
3934000	3936000	but it's a lot of black magic
3936000	3939000	and a lot of things that are just not at all physically plausible.
3939000	3942000	And this is one of the things that I've been working with the artists at IID
3942000	3944000	in the last several months
3944000	3947000	to start moving us towards this more physically-based sense of things,
3947000	3951000	where if you just use your standard diffuse specular roughness,
3951000	3955000	you can have materials just make no sense at all in the real world.
3955000	3958000	You can have things that reflect more energy than come in
3958000	3961000	when you've got a bright diffuse and a bright specular.
3961000	3963000	And there's...
3963000	3966000	The real step that we've had to make education-wise
3966000	3969000	is treating these maps not just as something that you paint in Photoshop,
3969000	3972000	but how you define the materials that are there,
3972000	3974000	where it shouldn't be that...
3974000	3976000	If you're looking at something that's a belt buckle, you say,
3976000	3978000	okay, this is metal, it's going to have a high specular,
3978000	3981000	it's going to have a low diffuse, the specular may have color in it,
3981000	3984000	it's going to have a high power or a low roughness,
3984000	3986000	depending on how you're formulating it,
3986000	3988000	because that's what it is.
3988000	3990000	But far too often in, you know,
3990000	3994000	for the past decade in computer games, especially,
3994000	3997000	the maps that have been fed into these things,
3997000	3999000	the diffuse maps, specular maps,
3999000	4001000	whether they're gloss or roughness or whatever you term it,
4001000	4003000	they're things that are painted in,
4003000	4005000	where a lot of times you'd see a specular map where,
4005000	4008000	yeah, you take your diffuse map and you kind of monochromize
4008000	4012000	and maybe color shift it and you stick it into the specular,
4012000	4014000	and you wind up with things that...
4014000	4017000	Yes, it makes parts of it shiny and parts of it not shiny,
4017000	4019000	but some of these things, like,
4019000	4022000	I don't actually think that there is a physical material that exists
4022000	4024000	in the red specular reflection color.
4024000	4027000	I mean, maybe there is, but it's certainly not common.
4027000	4031000	You know, specular colors are generally white except for metals,
4031000	4034000	which can be the color of the base surface.
4034000	4036000	So there's...
4036000	4039000	The biggest thing that's going to be happening for making games look better
4039000	4042000	is really not advancing the graphics technologies,
4042000	4044000	at least for our studio.
4044000	4048000	It's the matter of getting materials that actually make sense.
4048000	4051000	And once you're there, then you can start improving,
4051000	4055000	the things that you do with adding your better global light transport,
4055000	4057000	all the other cases there.
4057000	4061000	One more thing before I cut out from the time warning here.
4061000	4065000	So the cost of all of this, billions and billions of rays,
4065000	4069000	one technique that's gotten a lot of currency in recent years
4069000	4071000	is ambient occlusion.
4071000	4073000	Now, to explain what ambient occlusion is,
4073000	4075000	it's another one of those great big hacks,
4075000	4077000	but it works, you know, usefully,
4077000	4080000	and it's kind of standard fare and a lot of offline work.
4080000	4086000	So if you have an object that's got some concavity here,
4086000	4089000	and you've got the light shining on it from here,
4089000	4091000	so you light it all up.
4091000	4094000	In an ideal world, you'd be doing all of this path tracing,
4094000	4097000	and you would say that, okay, some of the rays hit here,
4097000	4099000	they bounce here, they bounce around into here,
4099000	4102000	some of them go up here, hit here, and get into that.
4102000	4106000	So the path, the tortuous path that light can take to get into there,
4106000	4108000	that's what you really want to deal with.
4108000	4110000	If you've got your white surface there,
4110000	4114000	you might need to trace 10 bounces from thousands and thousands of things.
4114000	4117000	The observation that ambient occlusion is based on
4117000	4122000	is that when something has other things very close to it,
4122000	4127000	it is very likely to be not as bright as things that...
4127000	4129000	but do not have things next to it.
4129000	4131000	If you've got a flat surface and you're lit,
4131000	4133000	you know, there's nothing that's going to be braided
4133000	4135000	that's taking anything away from it,
4135000	4140000	but if you have a flat surface that, you know, has an occluder here,
4140000	4144000	this area right here, it might be directly seeing the light,
4144000	4148000	and it might be seeing everything in this part of the hemisphere,
4148000	4150000	but part of it's going to be hitting this,
4150000	4152000	and some of that may be going and seeing the light,
4152000	4154000	some of it may be bouncing in different directions.
4154000	4159000	So ambient occlusion, all it does is instead of sampling the whole world,
4159000	4164000	it samples just a small area around the point that you're working with.
4164000	4169000	And, importantly, perhaps even more importantly than the scope of what it's sampling,
4169000	4172000	when it hits things, it doesn't worry about the surface model.
4172000	4176000	It doesn't run, you know, BRDF or BRSSD or whatever.
4176000	4180000	All it does is say, either I hit something close or I didn't hit something,
4180000	4183000	and maybe keep track of how far away it is.
4183000	4189000	And if you get something like this where, okay, there's some light coming in here,
4189000	4191000	I can see this, but I trace out,
4191000	4196000	and 90% of everything around me is hitting something else sort of close.
4196000	4199000	So based on that, I'm going to darken it down,
4199000	4204000	just on the assumption that if I did run a global illumination trace through all of this,
4204000	4209000	that it would come out and say that I'm not as bright as something that's next to me that's open.
4209000	4213000	So something out here, that'll get the full value of whatever it calculates,
4213000	4217000	and as you move towards here, some of it's starting to get darker,
4217000	4220000	until you move all the way in here, we're almost all of it.
4220000	4227000	And it's a very, very crude approximation of just assuming that whatever it hits isn't going to be bright.
4227000	4231000	And you can break that by having cases where, you know, if you had,
4231000	4235000	if the light was coming in right here, where it's directly illuminating all of that,
4235000	4240000	and if that was a white surface, you could have more light coming down onto there rather than less.
4240000	4243000	Ambient occlusion would say, it's got nearby things, it should always be less,
4243000	4248000	but you could actually be getting more light from the global illumination in those cases.
4248000	4251000	It's just one in a long line of all of these approximations that we do.
4251000	4254000	But the takeaway point is, we know what we should do,
4254000	4258000	we know what we would do if we had infinite computing power to go with it.
4258000	4263000	So all of the things now are approximations onto it, ways that we can model our data,
4263000	4269000	ways that we can reduce our number of traces, and optimizations in the code paths to make things go faster.
4269000	4273000	And there's lots of work going on with GPU accelerated ray tracing,
4273000	4277000	again, some of the caustic graphics work for optimizing it in some other ways.
4277000	4282000	And there's lots of active research going on about what corners can you cut.
4282000	4286000	And it's interesting because, again, we know what the right way,
4286000	4290000	zillions of photons coming out, collect them all at the lens of your eye,
4290000	4292000	and sort of make an image from that.
4292000	4295000	But it's going to be research for the coming decade or more,
4295000	4299000	as we kind of work out what the very best approximations for this are.
4299000	4302000	So I ran a little bit over my one hour, but I can start taking questions now.
4302000	4304000	So we've got the microphone there.
4312000	4316000	Up until about maybe five to seven years ago,
4316000	4323000	there was every year an obvious increase in realism in offline rendering for especially movies.
4323000	4329000	And I'm wondering, since a lot of the things that you've mentioned here have been around
4329000	4335000	for as long as I can remember, I mean, Povre and all that decades ago,
4335000	4343000	what is the main driver of that increase in visual fidelity or realism in the more recent years?
4343000	4345000	So a couple of factors.
4345000	4348000	One is actually getting smarter about the materials,
4348000	4352000	where you can throw in all of this light transport stuff,
4352000	4355000	and if you don't have good materials for it, it won't matter.
4355000	4357000	You'll still get non-realistic images.
4357000	4360000	So better data collection, some of the laser scanning,
4360000	4363000	and the different things that let us get really good material qualities,
4363000	4364000	that's been one factor.
4364000	4370000	But probably the biggest factor has just been people being willing to throw that much more processing power at things.
4370000	4375000	I had to go ahead and, instead of letting these early cases where it could take days to render an image,
4375000	4377000	that's never going to get used in production,
4377000	4382000	and all you do is see some of the images in academic research.
4382000	4387000	And the problem with that is while some of the academic research would get the formulas right,
4387000	4389000	they wouldn't have the data right to go with it,
4389000	4392000	where if you've got, it's kind of like programmer art.
4392000	4398000	If you wind up with the programmer or the graphics researcher building the test scene for it,
4398000	4401000	it's probably not going to be a particularly good model of the world.
4401000	4404000	It's going to have too many spherical cow simplifications in it,
4404000	4408000	and it just won't be like what you go to a movie studio,
4408000	4412000	and they'll get all the grime and the nicks and the dings and everything
4412000	4416000	that will make it feel like a real lived-in world.
4416000	4418000	So I think those are really the two things, materials,
4418000	4420000	and then largely getting it into the hands,
4420000	4424000	making it reasonable for the people that are going to put the level of craft and detail
4424000	4426000	that it needs to represent the world,
4426000	4428000	making it feasible for them to use.
4428000	4432000	Is that your motivation for educating the artists at IID?
4432000	4434000	Well, I actually think it's necessary.
4434000	4438000	I think that if you're not getting with physical rendering now,
4438000	4440000	you're going to be left behind as an industry.
4440000	4445000	It's been interesting watching the offline world,
4445000	4448000	where you had the masters of their domain at Pixar.
4448000	4453000	Because they had the very best in process and technology for a long time,
4453000	4456000	they were sort of stragglers to adopt many of the things with ray tracing
4456000	4458000	and physically-based rendering,
4458000	4460000	but they've come around for the most part now,
4460000	4463000	still using the right tool at the right time.
4463000	4468000	But I can't think of many good arguments for not using physically plausible materials.
4468000	4472000	I don't think that there are artistic gains to be had by not doing it,
4472000	4475000	and there's all sorts of minefields where you can mess yourself up.
4475000	4477000	Thank you.
4477000	4483000	The very latest versions of OpenGL support pixel and fragment shaders.
4483000	4487000	And one of the things that I'm curious about is why you don't use procedural graphics
4487000	4490000	and procedural geometry more than you do.
4490000	4497000	Okay, so procedural graphics has been the wave of the future for the last 20 years.
4497000	4502000	And I think that I actually have a fairly strong and sound argument,
4502000	4504000	philosophical stance against this,
4504000	4512000	where in the end procedural data is quirky, hard to deal with data compression.
4512000	4517000	And one of the things that we are continuing to get more and more of is space,
4517000	4519000	the storage that we can get for things.
4519000	4527000	So while you can always pick out some niche market where you are going to be extremely constrained on your space,
4527000	4532000	and you think, well, mobile should have been maybe the space where procedural stuff comes into its own,
4532000	4538000	but that's ramping through all of the storage spaces for everything that it's really not.
4538000	4540000	All the standard methods are going on.
4540000	4545000	So it's a good tool for making programmer hours,
4545000	4549000	but when you want to put it into the hands of the people that are going to...
4549000	4552000	If you're modeling the real world, you laser scan everything.
4552000	4555000	You go in and say, I'm going to scan this room and I'm going to have a terabyte of data,
4555000	4558000	and I'll just render that as an enormous point cloud.
4558000	4560000	And that's credible even.
4560000	4562000	It's not, we can't ship a game like that yet,
4562000	4565000	but that's still within sight of something that we can do.
4565000	4567000	And if you want to give it to an artist to create something,
4567000	4570000	then they're largely going to be compositing together different things.
4570000	4576000	And procedural sources, yeah, you use them for your clouds and your smoke and particle, things like that.
4576000	4581000	But this was Pixar's camp for a long time about doing...
4581000	4586000	They would create with procedures, analytic procedures rather than textures,
4586000	4588000	and that way lost.
4588000	4591000	It was really pretty conclusive that nobody wants to do that.
4591000	4594000	They want to throw 20 layers of effective painting on top of things,
4594000	4597000	and you can still come up with use cases for it,
4597000	4607000	but it adds a lot of complexity for a win that outside of poster child cases really isn't there.
4607000	4613000	So for your offline rendering, have you ever considered using progressive photon mapping techniques?
4613000	4617000	And have you ever had a chance to talk with Henrik Von Jensen about any of that?
4617000	4621000	So I wrote a photon mapping version for our system,
4621000	4626000	and there's a really interesting aspect to this where...
4626000	4633000	So a fundamental aspect of global illumination is that there's no difference between a light emitter and a light reflector,
4633000	4638000	where you have to look at saying the photons that come off of this surface are just as good as the photons that come off of that light.
4638000	4644000	And when you calculate through, when you make a photon map for something,
4644000	4647000	you figure out how many photons you're going to send into the world,
4647000	4655000	you create a map of them, and you use that as an accelerator for determining your global illumination solution for each point.
4655000	4662000	The problem that I ran into was while that works fine for a single sort of character of a scene,
4662000	4666000	for an indoor scene, I found photon mapping to be pretty effective in a lot of ways.
4666000	4672000	I mean, you still have all the problems of where you wind up setting things, bleed-throughs in some cases,
4672000	4674000	but they're manageable problems.
4674000	4680000	But when I ran some numbers and I realized that if you're calculating an outdoor area,
4680000	4685000	the amount of light that falls on like one 8.5 by 11 sheet of paper,
4685000	4690000	just holding it out in the sun, all of a sudden that surface has all of the photons,
4690000	4693000	the same amount of photons that come out of a 100-watt incandescent light bulb,
4693000	4697000	and you start saying, well, we have acres and acres of surfaces out here.
4697000	4701000	And of course, we're scaling everything down, so it still fits with...
4701000	4706000	I completely did not get to any of my output monitors, gamma correction, all that stuff.
4707000	4710000	So, I mean, we have all these hacks to kind of normalize it,
4710000	4716000	but I found it to be in a situation where you had a bright outdoor area and then a dimmer indoor area,
4716000	4722000	you had to have so many photons in the outside to make the dim one come out reasonably
4722000	4724000	that it became pretty prohibitive.
4724000	4730000	The other reason that we don't do photon maps is that it requires a sequencing
4730000	4735000	where the nice thing about distributed ray tracing and the path tracing,
4735000	4739000	in its purest form, it's completely embarrassingly parallel.
4739000	4743000	Any surface can be done at any time because we run on multi-threads,
4743000	4746000	multi-core processors and multiple systems in a cluster,
4746000	4750000	and if you want to do something with an intermediate step like a photon map,
4750000	4754000	you have to build the photon map in some hopefully parallel way
4754000	4756000	and then transfer it to everything else.
4756000	4762000	And my very first global illumination solution in the early days of RAGE was GPU accelerated
4762000	4769000	and I rendered little hemispheres on the GPU and built up a low-resolution mega-texture of the world
4769000	4775000	and used that global illumination, which was reminiscent of a photon map.
4775000	4779000	And it was just one of those things that in practice turned out to really be kind of a pain,
4779000	4785000	and when we went to a completely separable solution, a lot of problems stopped happening.
4785000	4790000	But it was interesting implementing the photon map stuff, going through a few of the cases.
4790000	4793000	It's certainly a valid direction right now,
4793000	4799000	but I think that in a lot of cases that the necessity to generate that ahead of time
4799000	4803000	is a little bit of a hazard for implementation in a lot of parallel cases.
4803000	4807000	For running on a single system, if you know you're going to just plow through it all there,
4807000	4811000	it's got a lot of benefits. It just hurts a little more in a cluster.
4813000	4817000	Hi, so you talked a lot about the geometry and the RAGE tracing, all that sort of stuff.
4817000	4821000	I was just curious if you could talk about how you managed the light representations,
4821000	4825000	specifically things like fluorescence and that sort of stuff.
4825000	4830000	I'm getting another one of my topics that was on my list that I didn't have time to go through.
4830000	4837000	So again, the classical computer graphics light is you wind up with three models of lights.
4837000	4840000	You've got a point light, a spotlight, and a parallel light,
4840000	4843000	and those are our sort of baseline lights in the editor.
4843000	4848000	We augment the point lights by giving them an area radius
4848000	4852000	so we can get the soft shadows and so we can add the distributed RAGE tracing to that.
4852000	4858000	The biggest problem though is that all of our lights are completely physically implausible
4858000	4862000	because they're physically bounded, with the exception of the parallel light.
4862000	4869000	Some of this is history. When we go from Quake 1 all the way up through, especially Doom 3,
4869000	4874000	we built all of our lights out of textures because Doom 3 was all dynamic,
4874000	4879000	so we multiplied two textures together where you would have a projection texture and a fall-off texture,
4879000	4884000	so they occupied this physical space in the world,
4884000	4887000	which is great for culling reasons where you can say,
4887000	4891000	alright, in Doom 3 we tried to say no more than three lights hitting a surface
4891000	4894000	because it was a linear cost, every light cost more on that surface.
4894000	4899000	We wound up with these lights that were very physically implausible.
4899000	4905000	If you're doing this multiplying two textures together, you can make a Gaussian fall-off light,
4905000	4908000	which is a pleasant light to work with that is radially symmetric,
4908000	4911000	but most of the lights in the game wound up being our square light,
4911000	4916000	which is a light that goes almost to the outside edges of this texture,
4916000	4919000	just fading a little bit and then fading a little bit in the other direction,
4919000	4925000	so we could get about as much light as we could into the world for minimal fragment cost.
4925000	4932000	Unfortunately, we kept those through rage as our primary light style.
4932000	4936000	We had some of our very best artists love this because it gave them total control.
4936000	4939000	They would call it painting with light, so they would be able to say,
4939000	4945000	I want this area a little bit brighter here, so I'll use this different texture instead of the standard one.
4945000	4948000	I'll move this or I'll stretch it so it just barely goes below the floor,
4948000	4952000	but it has no fall-off, so it's going to throw all the light into it.
4952000	4958000	That is largely the type of artistic wizardry that we need to evolve past
4958000	4963000	because you will never be able to take light emitters like that and make the world feel real
4963000	4965000	because the light's not real.
4965000	4969000	You can even have completely real materials and you could be doing it with path tracing,
4969000	4974000	but if your light is only coming from these things that do not resemble real lights,
4974000	4977000	then it's never going to be bought off as real.
4977000	4985000	Several years ago, I made a premature evidently push towards physically-based lighting
4985000	4990000	where I was trying to set all of our lights up with using IES light profiles,
4990000	4996000	which are these actual light profiles that the people that make light bulbs go and measure all of these things.
4996000	5000000	You can get the light that's coming at all of these different areas,
5000000	5002000	different sample points coming out of it.
5002000	5007000	That's really useful, although it's important to note that there are simplifications in here.
5007000	5009000	Just because you see an equation doesn't mean it's true.
5009000	5012000	Just because you see a table of data doesn't mean it's true either
5012000	5018000	because you have simplifications like an IES spec for three fluorescent bulbs in a fixture.
5018000	5021000	Yes, you are sampling what the light is at all of these points,
5021000	5027000	but really you should be getting three shadows from it rather than one from an area light source.
5027000	5029000	There's simplifications built into that,
5029000	5032000	but we are not currently using that.
5032000	5038000	The main reason why it fell through when I pushed for it originally was it comes back to the performance.
5038000	5043000	To keep the build times at a certain level that they were familiar with,
5043000	5046000	you wound up with these lights now are extending infinitely.
5046000	5049000	They're proper inverse-square fall-off lights,
5049000	5052000	so if you've got a level with 1,000 lights in it,
5052000	5058000	then in theory you're tracing 1,000 traces out at a minimum to just see whether any light gets there.
5059000	5062000	You cut this down to some rational number of samples,
5062000	5065000	and what that means is there's lots of noise in the images.
5065000	5069000	One of the battles that's been particularly hard for all of the Tech 5 stuff
5069000	5075000	is trying to have a situation where the designers and artists are willing to work with
5075000	5079000	an approximation of what the final output is.
5079000	5082000	It is just very tempting to say,
5082000	5084000	well, I always want to look at what the final output is,
5084000	5087000	which means that everything is always a production quality render,
5087000	5089000	which means it always takes forever.
5089000	5092000	I keep hoping that there will be more of an acceptance of,
5092000	5094000	well, this is roughly what it's like.
5094000	5098000	I can still figure out what my gameplay and rough lighting and everything is,
5098000	5101000	but that's a battle that we fight daily on this.
5104000	5105000	Hi, John.
5105000	5107000	Taking quality materials data for granted,
5107000	5112000	I'm curious what additional visual fidelity you gain by ray tracing box lock trees
5112000	5114000	and then what visual sacrifices you make
5114000	5116000	and what sacrifices you have to make in terms of performance.
5116000	5118000	Or to gain performance.
5118000	5123000	So the question of what you're ray tracing against is sort of orthogonal to the method.
5123000	5127000	I mean, you can rasterize or ray trace lots of different representations,
5127000	5132000	and there was lots of work that went into directly ray tracing against curved surfaces
5132000	5135000	and certainly spheres in some of the easy cases.
5135000	5139000	And for years, I did think that ray tracing into some form of voxel space
5139000	5142000	would be an obvious thing to do,
5142000	5146000	because it seems that there's winds, it's certainly far simpler.
5146000	5148000	You can make a more regular data structure.
5148000	5152000	There's all these things, but it doesn't seem to be panning out that way.
5152000	5155000	It does seem to be that all ray tracing will be against triangle meshes
5155000	5157000	that you will decimate to it.
5157000	5161000	And there's certainly advantages to the comfortable toolpaths, everything there.
5161000	5164000	It seems that's the way that history is flowing,
5164000	5168000	and that's probably the way it's going to work out when we are ray tracing everything.
5169000	5174000	You talked a little bit yesterday on the motion blur that happens
5174000	5178000	on the LCD screens as you're moving your head very quickly.
5178000	5183000	Do you have any more thoughts on if that's a solvable problem for this generation of VRs
5183000	5185000	that's going to take a little longer?
5185000	5188000	So we have an existence proof of something that's good enough.
5188000	5195000	I mean, what Valve put together by packing up the Samsung displays is good enough.
5195000	5200000	If we can get 90 hertz displays that are low persistence, that will do.
5200000	5203000	120 would probably be better,
5203000	5209000	but like my interlace scheme, maybe a good thing to kind of add on top of that if it can be done.
5209000	5211000	But I think there's a good prospect.
5211000	5216000	The fallback plan is LCD backlight flashing.
5216000	5221000	So it's important, and I think that I'm betting that it will be solved
5221000	5225000	for sort of consumer grade VR in the not too distant future,
5225000	5230000	but it's not there right now outside of Valve's prototype.
5235000	5238000	Hi, John. Thanks for the talk.
5238000	5243000	A few years ago I read an MIT paper explaining how to compute saw shadows,
5243000	5247000	and what they did was they interpolated linearly between the parts that were lit
5247000	5249000	and the parts that were not lit.
5249000	5251000	Is that the approach it takes?
5251000	5254000	Is that a linear map or nonlinear map between the umbra and the penumbra?
5254000	5258000	And I was just hoping you could explain in detail how you calculate the intermediate levels.
5258000	5264000	Okay, so that does fall into the category of large body of work of approximations
5264000	5266000	that is pretty much gone and forgotten right now.
5266000	5270000	Our saw shadows are done by sending a certain number of samples,
5270000	5272000	like it's 16 by default.
5272000	5277000	So you send 16 samples to different points on the light that are randomly distributed,
5277000	5281000	and the density of the shadow is just the fraction of them to get through.
5281000	5286000	So you can crank that number up in some cases for some of the really broad area emitters.
5286000	5290000	In theory you'd want it to be 256 samples, so you could get a full range of,
5290000	5294000	or even more on a very bright light, but we get by with 16.
5294000	5297000	There's an approximation that I did on that
5297000	5301000	that instead of randomly sending to all points in the center of the,
5301000	5303000	all points across the area of the light source,
5303000	5306000	by default we send them across the circumference of the light,
5306000	5311000	which gives you, in theory can sometimes make it look a square factor better,
5311000	5313000	but it looks bad at edges.
5313000	5315000	So we're still tracing different things on there,
5315000	5318000	but in the bottom line it's just however many samples you throw.
5318000	5319000	That's the fraction that comes out.
5319000	5324000	Things like that are going back through the history of graphics for 40 years.
5324000	5328000	There's a ton of things that were somewhat complicated analytics solutions
5328000	5331000	that have just over and over fallen to raw brute force,
5331000	5334000	and I think that all of these things will as well.
5334000	5338000	You know, when we are tracing billions of rays per frame,
5338000	5340000	that's when we'll be using ray tracing.
5340000	5343000	I don't think there's going to be too many intermediate steps to that.
5343000	5346000	Thank you.
5346000	5348000	Hello.
5348000	5353000	So I know that in AutoCAD and other engineering programs,
5353000	5358000	there are catalogs of different types of materials
5358000	5366000	that you can test the effects of different things on the structure,
5366000	5370000	so on and so forth, just the different kinds of materials.
5370000	5376000	And my question is for you is that with trying to make your artists use more accurate materials,
5376000	5381000	are you trying to create a catalog of textures?
5381000	5387000	Yeah, so right now we are very much trying to have our master swatch list of,
5387000	5390000	you know, if we need, there's the clear things about,
5390000	5393000	okay, if you're metal, you're in this range, if you're paint, you're in this range,
5393000	5395000	if you're wood, you're in this range, asphalt,
5395000	5400000	having all of this represented as these are the valid ranges
5400000	5405000	of diffuse specular roughness and maps that you're going to have.
5405000	5408000	So we're still working through all of that.
5408000	5412000	And in terms of material libraries, it's a little frustrating when you look at,
5412000	5416000	whether it's 3D Studio or Modo or V-Ray, whatever,
5416000	5419000	the materialists are usually the ad hoc collection that's accreted
5419000	5422000	over a couple decades of company lifespan,
5422000	5426000	and they're usually not a complete, consistent, cohesive,
5426000	5428000	physically-based set of materials.
5428000	5432000	We spent a little bit of time trying to backtrack values
5432000	5436000	from one of the material library sets into the things that we could use,
5436000	5440000	and it wasn't completely clear that they were coming out in the right ranges,
5440000	5444000	so we're building up our own set, and there's lots of studios doing that.
5445000	5450000	Online, there are sets of BRDF measurements for a lot of materials
5450000	5455000	that would be good to start drawing some of the materials from,
5455000	5461000	but we're still looking for, okay, what's the diffuse specular and roughness values going
5461000	5463000	rather than this full table of data,
5463000	5466000	but eventually, I expect that we all will be using,
5466000	5468000	this is data scanned in from the real world,
5468000	5471000	because over and over, that's what eventually wins in the end.
5472000	5473000	Thank you.
5473000	5474000	All right.
5475000	5476000	That looks like it. John, thank you.
5476000	5478000	Thanks. On time.
5501000	5503000	Thank you.
