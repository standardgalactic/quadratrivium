WEBVTT

00:00.000 --> 00:08.360
Good afternoon everybody, I'm Andrew Ross Sorkin and it is a privilege to have with

00:08.360 --> 00:14.640
me Peter Thiel this afternoon, one of the great legendary investors in Silicon Valley.

00:14.640 --> 00:19.720
He has been involved in just about everything that you touch and feel, including being the

00:19.720 --> 00:25.480
co-founder of PayPal, the co-founder of Palantir, he made his first outside investment, made

00:25.480 --> 00:30.240
the first outside investment, I'd say in Facebook, his firm Founders Fund is a big

00:30.240 --> 00:35.280
backer of Stripe and SpaceX, his firm backed numerous other startups through the Founders

00:35.280 --> 00:36.840
Fund into your capital.

00:36.840 --> 00:41.360
He also started the Thiel Fellowship to your program, that's an alternative to a college

00:41.360 --> 00:46.840
degree which I want to get to at one point and more importantly than all of it, he has

00:46.840 --> 00:52.800
touched some of the people and found the people who you read about in the headlines every

00:52.800 --> 00:58.320
day from Mark Zuckerberg to Elon Musk to Sam Altman and so many others and it is great

00:58.320 --> 00:59.320
to have you here.

00:59.320 --> 01:00.320
Thanks for having me.

01:00.320 --> 01:04.960
We're also going to talk a little politics as well, along with maybe some of the issues

01:04.960 --> 01:09.280
and culture conversations that are happening in Silicon Valley, but here's where I want

01:09.280 --> 01:12.640
to start the conversation because I want to start the conversation talking about people

01:12.640 --> 01:16.760
because I think there's something actually extraordinary when you think about your track

01:16.760 --> 01:22.760
record over the years of involving yourself in investing not just in companies but ultimately

01:23.040 --> 01:24.200
in people.

01:24.200 --> 01:28.520
You wrote a book which is coming on a 10-year anniversary and by the way I re-read it and

01:28.520 --> 01:34.440
it stands up in a very big way, it is called Zero to One and you wrote the following about

01:34.440 --> 01:37.280
founders, the idea of founders.

01:37.280 --> 01:40.480
You wrote that the lesson for business is that we need founders.

01:40.480 --> 01:48.200
If anything, we should be more tolerant of founders who seem strange or extreme.

01:48.200 --> 01:56.320
We need unusual individuals to lead companies beyond mere incrementalism and I mention that

01:56.320 --> 02:00.320
because I also just mentioned a number of individuals which we read about all the time

02:00.320 --> 02:05.760
and some of those people would be described as unusual perhaps or even strange.

02:05.760 --> 02:10.640
And I'm curious about how you think over the years you have found these individuals, what

02:10.640 --> 02:15.840
it is that has made these individuals as successful as they have become.

02:16.840 --> 02:22.960
Yeah, it's obviously, if there was some simple magic formula, this is what a founder looks

02:22.960 --> 02:29.760
like and you invest in this category of people who's a founder, it probably gets faked.

02:29.760 --> 02:35.160
It's like, I don't know, it's a 20-year-old with a t-shirt and jeans or something like

02:35.160 --> 02:42.320
this or you end up with all kinds of really fake ideas but yeah, I think a lot of the

02:42.320 --> 02:50.120
great companies that have been built over the last two decades were, they were founded

02:50.120 --> 02:56.520
by people where it was somehow deeply connected to their identity, their life project.

02:56.520 --> 03:03.560
They had some kind of idiosyncratic, somewhat different vision of what they were doing.

03:03.560 --> 03:10.680
They did something new and then they built something extraordinarily big over the years

03:10.680 --> 03:17.200
and of course they have these sort of extreme personalities, often have a lot of blind spots

03:17.200 --> 03:21.520
and there are all these ways in which it's a feature and there are ways in which it can

03:21.520 --> 03:29.120
be a little bit buggy but it's sort of a package deal and I net out to it being massively

03:29.120 --> 03:34.400
advantageous versus let's say a professional CEO being brought in.

03:34.400 --> 03:39.680
The prehistory of this I would say would be in the 1990s, the Silicon Valley formula was

03:39.680 --> 03:45.080
you had various people found the company and then you'd replace them as quickly as possible

03:45.080 --> 03:49.680
with professional CEOs, professional management and there are variations of this that happened

03:49.680 --> 03:56.840
with Netscape and Yahoo and even Google, all these companies and the Gen X people founded

03:56.840 --> 04:00.360
them, the baby boomers came along and sort of took over the companies and stole them

04:00.360 --> 04:03.320
from the Gen X founders in the 90s.

04:03.320 --> 04:08.960
In the 2000s when the millennials founded the companies they were given more of an opportunity

04:09.280 --> 04:10.960
and it made a big difference.

04:10.960 --> 04:18.760
The Facebook story I always tell is it was 2006, two years in, Zuckerberg was like 22

04:18.760 --> 04:27.240
years old and we got a $1 billion offer to sell the company to Yahoo and we had a board

04:27.240 --> 04:31.320
meeting, there were three of us and we thought we should at least talk about it.

04:31.320 --> 04:35.600
It was a lot of money, Zuckerberg would make $250 million and sort of an eight hour long

04:35.720 --> 04:40.160
discussion and he didn't know what he'd do with the money and he'd just start another

04:40.160 --> 04:43.480
social networking company and kind of like the one he had and he didn't know what else

04:43.480 --> 04:50.960
he would do and so he really didn't want to sell and if you had a professional CEO

04:50.960 --> 04:55.280
it would have just been, man I can't believe they're offering us a billion dollars and

04:55.280 --> 05:04.440
I'm going to try not to be too eager and we better take the money and run and that one

05:04.440 --> 05:05.440
thing right makes a big difference.

05:05.440 --> 05:09.080
Let me ask you a different question and all of these individuals had a huge impact on

05:09.080 --> 05:14.760
society and have an enormous individual power and I think one of the things that you've

05:14.760 --> 05:18.120
argued in this book and that you've argued over the years is that we need to give them

05:18.120 --> 05:25.840
that power, we need to offer them a latitude that in many ways we don't offer others.

05:25.840 --> 05:36.040
Well I think one of the frames I always have is that there are many ways in which the United

05:36.040 --> 05:43.040
States, the developed countries have been relatively stagnant for the last 50 years.

05:43.040 --> 05:44.800
Progress has slowed.

05:44.800 --> 05:50.160
We had progress in computers, internet, software and many other domains, things have kind of

05:50.160 --> 05:54.640
stalled out and it sort of manifests in low economic growth in the sense that the younger

05:54.640 --> 05:58.120
generation is going to have a tough time doing as well as their parents and there is

05:58.120 --> 06:06.280
sort of this way that there has been this broad stagnation for 40, 50 years and we need

06:06.280 --> 06:08.520
to find ways to do new things.

06:08.520 --> 06:14.120
I don't think, you know, startup, tech startup companies are the only ways to do them, that

06:14.120 --> 06:22.960
is a vehicle for doing it and if you don't allow these companies to have a certain latitude

06:23.560 --> 06:28.320
and flexibility to try to do new things, we shut it down right away, you know, the stagnation

06:28.320 --> 06:29.680
will be worse than ever.

06:29.680 --> 06:32.840
Okay, but here's a separate almost philosophical question, I'm going to read back something

06:32.840 --> 06:37.400
you said to the New Yorker, there was a piece about Sam Altman, this is right around actually

06:37.400 --> 06:44.280
when open AI began, 2016 and I think it actually might even be representative of how you might

06:44.280 --> 06:48.720
think about Mark Zuckerberg or Elon Musk or some of these other kinds of major players.

06:48.720 --> 06:56.280
This is what you said, you said, Sam's program for the world is anchored by ideas, not people

06:56.280 --> 07:01.440
and that's what makes it powerful because it doesn't immediately get derailed by questions

07:01.440 --> 07:05.720
of popularity and I thought that that was actually very indicative of most of the people

07:05.720 --> 07:10.240
that you have invested in, it's really been about ideas and in some ways you could even

07:10.240 --> 07:13.320
argue is disconnected from people.

07:13.920 --> 07:19.960
I think it is really about a whole wide, people are able to think about a wide spectrum

07:19.960 --> 07:24.640
of things, they're able to think about good founders have theories of how to hire people,

07:24.640 --> 07:28.240
how to manage them, how to build teams, they have theories about where the culture, the

07:28.240 --> 07:34.760
societies were going, they have technical things about the product, the design, they

07:34.760 --> 07:39.400
have ideas about how they should market their company, so they're sort of polymaths are

07:39.480 --> 07:45.720
able to think about a lot of these things, but yeah, I'm biased towards a lot of the

07:45.720 --> 07:52.200
ones where it's more intellectual and maybe, but I think that quote has held up pretty

07:52.200 --> 07:57.080
well with Sam Altman, maybe he needed to pay a little bit more attention to the board

07:57.080 --> 08:01.040
and things like that and there was probably a people dimension that he had ignored a little

08:01.040 --> 08:04.080
bit too much in November 2016.

08:04.080 --> 08:08.800
Since we're on the Sam Altman of it all and since Sam was here yesterday, I'm so curious,

08:08.840 --> 08:14.360
you were a mentor of his, what do you think of open AI and what do you think of AI more

08:14.360 --> 08:15.360
broadly right now?

08:15.360 --> 08:16.920
I mean, are we in a bubble?

08:16.920 --> 08:18.560
Is this the future?

08:18.560 --> 08:19.560
What is this?

08:19.560 --> 08:23.240
Wow, it's a broad question.

08:23.240 --> 08:27.920
I think I'm always hesitant to talk about it because I feel there's so many things I would

08:27.920 --> 08:32.080
have said about AI where I would have been very wrong two, three years ago, so maybe

08:32.080 --> 08:37.080
I'll start by just saying a little bit about the history of what people thought was going

08:37.120 --> 08:42.560
to happen and then the surprising thing that open AI achieved and that did happen and if

08:42.560 --> 08:48.560
you had this debate in the 2010s, there was sort of one, maybe frame in terms of two paradigms,

08:48.560 --> 08:55.560
two books, there was the Boston Book Superintelligence 2014, which is that AI was going to build

08:56.080 --> 09:01.800
this god-like superhuman intelligence and it was heading towards this god-like oracle

09:01.880 --> 09:07.880
and that was what AI was going to be and then there was the Kaifu Li, a rebuttal 2018 AI

09:07.880 --> 09:13.440
superpowers, which was sort of the CCP rebuttal to Silicon Valley, that no, AI is not about

09:13.440 --> 09:18.040
god-like intelligence, that's a science fiction fantasy Silicon Valley has, AI is going to

09:18.040 --> 09:25.040
be about machine learning, data collection, it's not conscious, it's not any of these

09:25.200 --> 09:30.560
weird things, it's surveillance tech and China is going to beat the U.S. in the race for

09:30.600 --> 09:36.080
AI because we have no qualms about sort of this totalitarian, not the word he used, collection

09:36.080 --> 09:42.080
of data in our society and that was sort of the way the AI debate got framed and then

09:42.080 --> 09:45.280
the thing I always said was, man, it's just such a weird word, it means all these different

09:45.280 --> 09:52.280
things, it's annoyingly undefined, but then the sort of surprising and strangely unexpected

09:52.520 --> 09:59.520
thing that happened is that in some sense, what open AI with chat GPT 3.5 for AI was

10:00.760 --> 10:07.760
achieved in late 22, early 23 was you passed the Turing test, which was not super-intelligence,

10:07.760 --> 10:14.760
it's not god-like, it's not low-tech surveillance, but that had been the holy grail of AI for

10:15.000 --> 10:21.680
60 or 70 years and it's a fuzzy line, the Turing test is you have a computer that can convince

10:21.680 --> 10:26.320
you that it's a human being and it's a somewhat fuzzy line because sometimes, but it pretty

10:26.320 --> 10:32.160
clearly hadn't been passed before, it pretty clearly is passed now and that's a really

10:32.160 --> 10:38.000
extraordinary achievement, it's extremely, it raises all sorts of interesting big picture

10:38.000 --> 10:45.000
questions, what does it mean to be a human being in 2024? The sort of placeholder answer

10:46.640 --> 10:50.000
I would have been tempted to give a couple of years ago would be something like the

10:50.000 --> 10:54.560
Noam Chomsky idea that something very important about language, this is what sets humans apart

10:54.600 --> 10:59.080
from all the other animals, we talk to each other and we have these rich semantic syntax

10:59.080 --> 11:06.080
things and so if a computer can replicate that, what does that mean for all of us in

11:06.080 --> 11:11.480
this room? It's an extraordinary development and it was also somehow, even though it had

11:11.480 --> 11:18.080
been the holy grail, somehow in the last decade before, it was not expected at all and so

11:18.080 --> 11:23.320
there's something very significant about it and very underrated and then of course you

11:23.360 --> 11:28.800
get all these questions about, is it going to, is it an econ one question, is it a compliment,

11:28.800 --> 11:32.280
is it going to make people more productive or is it a substitute, good, where it's going

11:32.280 --> 11:36.920
to replace? So what do you think of all of this and how bullish as an investor are you

11:36.920 --> 11:42.000
on this? What do you think our society, when you hear Sam Altman talk about this, you say

11:42.000 --> 11:46.160
he's right, that's what it's going to be, do you think it's going to be something else?

11:46.160 --> 11:50.480
You lived through 1999, there's some people who say this is a hype cycle, other people

11:50.560 --> 11:57.560
say this is the future. Well, I'm very anchored on the 99 history and I somehow always like

11:57.560 --> 12:05.560
to say that 99 was both. The peak of the bubble was also in a sense the peak of clarity, people

12:05.560 --> 12:09.000
who realized the new economy was going to replace the old economy, the internet was

12:09.000 --> 12:16.360
going to be the most important thing in the 21st century and people were right about that

12:16.400 --> 12:22.760
and then the specific investments were incredibly hard to make and even the no-brainer market

12:22.760 --> 12:27.440
leader, so if you said 1999, the no-brainer investment would have been Amazon stock,

12:27.440 --> 12:31.520
it's a leading e-commerce company and they're going to scale and they'll get bigger and

12:31.520 --> 12:41.520
it peaked in December 1999 at $113 a share, it was $5.5 in October 2001, 22 months later,

12:41.520 --> 12:45.680
you then had to wait until the end of 2009 to get back to the 99 highs and then if you'd

12:45.720 --> 12:48.560
waited until today, you would have made 25 times your money from 99, you'd have first

12:48.560 --> 12:55.600
lost, you'd have gone down 95% and then made 500X, so even the no-brainer investment from

12:55.600 --> 13:05.600
99 was wickedly tricky to pull off in retrospect and I sort of think that AI, the LLM form

13:05.600 --> 13:12.520
of AI. These are the large language models. The open AI's of the world. Again, passing

13:12.560 --> 13:19.080
the Turing test, I think it's roughly on the scale of the internet and so it's an incredibly

13:19.080 --> 13:23.880
important thing, it's going to be very important socially, politically, philosophically about

13:23.880 --> 13:30.480
all these questions about meaning and then the financial investment question I find unbelievably

13:30.480 --> 13:38.480
hard and confusing and yeah, it's probably quite tricky. If you had to sort of concretize

13:38.560 --> 13:45.560
one thing that's very strange about the, if you sort of just follow the money, at this

13:45.560 --> 13:51.720
point, 80 to 85% of the money in AI is being made by one company, it's NVIDIA and so it's

13:51.720 --> 13:56.440
all on this sort of very weird hardware layer which Silicon Valley doesn't even know very

13:56.440 --> 14:02.240
much about anymore. We don't really do hardware, we don't do silicon chips in Silicon Valley

14:02.240 --> 14:06.560
anymore. I get pitched on these companies once every three or four years and it's always

14:06.600 --> 14:11.120
I have no clue how to do this. It sounds like a pretty good idea but man, I have no clue

14:11.120 --> 14:17.840
and we never invest. Then there's sort of this theory that the hardware piece makes

14:17.840 --> 14:22.720
the money initially, then gets more commodified over time and it'll shift to software and

14:22.720 --> 14:27.400
the, I don't know, the multi-trillion dollar question, is that going to be true again this

14:27.400 --> 14:34.400
time or will NVIDIA sort of have this incredible monopoly at the moment?

14:36.800 --> 14:43.800
I suspect NVIDIA will, I think it will maintain its position for a while. I think the game

14:50.320 --> 14:55.480
theory on it is something like all the big tech companies are going to start to try to

14:55.480 --> 15:02.080
design their own AI chips so they don't have to do the 10x markup to NVIDIA and then how

15:02.160 --> 15:07.840
hard is it for them to do it, how long will it take? If they all do it, then the chips

15:07.840 --> 15:14.840
become a commodity and nobody makes money in chips. Then do you go into hardware and

15:15.560 --> 15:19.080
you should do it if nobody else is doing it, if everybody does it, you shouldn't do it,

15:19.080 --> 15:23.560
and then maybe, I'm not sure how that nets out, but probably people stay stuck for a

15:23.560 --> 15:27.200
while and NVIDIA goes from strength to strength for a while.

15:27.200 --> 15:30.720
I have a related but maybe personal question for you. You happen to have this very interesting

15:30.720 --> 15:34.840
relationship with Sam Altman and then also a very interesting relationship with Elon

15:34.840 --> 15:41.840
Musk. You both worked at PayPal. You famously were part of a coup effectively to push Elon

15:42.240 --> 15:46.360
Musk out of the company. You're now friends with him all over again and have a stake in

15:46.360 --> 15:49.600
SpaceX. You can maybe walk us through that friendship.

15:49.600 --> 15:56.600
We had some rough moments in 2000, 2001, but it's been beautiful.

15:57.320 --> 16:01.680
We're always going to go with this, actually, is one of the things that's been fascinating

16:01.680 --> 16:05.440
and fascinating to the valley and I think to the country has been the commentary we've

16:05.440 --> 16:09.720
heard from Elon Musk who helped build open AI with Sam and the break actually between

16:09.720 --> 16:16.640
the two of them as creating this not-for-profit and what's happened to it. In fact, Elon

16:16.640 --> 16:21.840
Musk originally sued Sam earlier this year and then dropped the suit recently.

16:21.840 --> 16:26.120
But how do you think about this idea of a company that was started as a not-for-profit

16:26.120 --> 16:30.440
and all of the safety concerns and things that you hear from Elon on one side and Sam

16:30.440 --> 16:32.120
on the other?

16:32.120 --> 16:39.120
Man, whichever person I talk to last, I find the most convincing probably. I talked to

16:40.360 --> 16:46.520
Elon about it and he made this argument. It's just completely illegal for a non-profit

16:46.520 --> 16:51.120
to become a for-profit company because otherwise everyone would set up companies as non-profits

16:51.120 --> 16:55.240
and take advantage of the tax laws and then you turn them into a for-profit and this is

16:56.240 --> 17:00.160
the most obvious arb and they just can't be allowed to do this. It's obviously just

17:00.160 --> 17:05.360
totally illegal with what Sam's trying to do at open AI. And then like half an hour

17:05.360 --> 17:11.680
after the conversation was over, at the moment it's like, oh, that's a really strong argument.

17:11.680 --> 17:17.040
And then half an hour later, it's like, but the whole history of open AI is that the biggest

17:17.040 --> 17:25.040
handicap they had was a non-profit and it led to all these crazy conflicting things culminating

17:25.120 --> 17:31.120
in this non-profit board that thought it was better to shut down the company or the whole

17:31.120 --> 17:36.240
venture, whatever you want to call it, rather than keep going. And nobody is ever going

17:36.240 --> 17:42.080
to take the lesson from open AI to start a non-profit and turn it into a for-profit later,

17:42.080 --> 17:49.080
given what a total disaster that was. But whoever I listen to last, I find the most compelling.

17:49.080 --> 17:53.200
Let me ask you a different question. You've left Silicon Valley. You have now moved to

17:53.200 --> 18:00.200
Los Angeles. That's your home. We left San Francisco specifically. It just felt it was

18:01.000 --> 18:04.600
time to get out. So tell us why it was time to get out, because I think a lot of the issues

18:04.600 --> 18:09.440
that actually we read about around open AI and some of the culture issues add a lot of

18:09.440 --> 18:16.200
these companies are the reason you decided you didn't want to live there anymore. It's

18:16.200 --> 18:23.200
hard to... It's a bunch of things that came together, but there was a sense that it was

18:27.600 --> 18:34.600
sort of the ground zero of the most unhinged place in the country. You had this catastrophic

18:34.960 --> 18:39.480
homeless problem, which maybe is not the most important problem, but it was never getting

18:39.480 --> 18:46.480
better. It was by 2018 when we moved to LA, it felt like it had become extraordinarily

18:47.240 --> 18:53.520
self-hating, where everybody who was not in tech hated the tech industry. This is very

18:53.520 --> 19:00.320
odd. It would be like the people in Houston hating oil or people in Detroit hating cars,

19:00.320 --> 19:07.320
people in New York hating finance. It had this unhinged, self-hating character in the

19:09.520 --> 19:16.360
city itself. There were all these things that seemed extraordinarily unhealthy. If you asked

19:16.360 --> 19:23.360
me in 2021, I would have said, man, they are finally... Yes, they're sitting on the biggest...

19:24.600 --> 19:29.360
They created all this wealth, and yet they are going to succeed in committing suicide.

19:29.360 --> 19:35.560
Three years later, I think the jury is a little bit more out, because maybe the AI revolution

19:35.640 --> 19:42.640
is big enough that it will save even the most, I don't know, the most ridiculously mismanaged

19:43.120 --> 19:44.720
city in the country.

19:44.720 --> 19:45.720
It seemed to me...

19:45.720 --> 19:51.920
Tell me if I'm wrong. I thought that part of the issue that you had with San Francisco

19:51.920 --> 19:57.640
was the politics of it. Not just the politics of it, but how politics had seeped into the

19:57.640 --> 20:04.640
culture of so many of the companies. I think that you thought that it had moved into the

20:05.560 --> 20:07.680
city in a very progressive way.

20:07.680 --> 20:14.680
Yeah, that's always a very clear dimension of it. That's the tip of the iceberg. That's

20:16.320 --> 20:22.120
the part that's above the surface that people always focus on. Then the part that's below

20:22.120 --> 20:29.120
the surface is just the deep corruption, the mismanagement of the schools, the buses, all

20:30.120 --> 20:37.120
the public services, the way things don't work, the way the zoning is the most absurd

20:37.120 --> 20:44.120
in the country. There was a house I was looking to buy where you couldn't build access into

20:44.360 --> 20:51.360
the garage, and Gavin Newsom, who is the Lieutenant Governor of California at the time, said he

20:51.360 --> 20:56.520
would help me get a garage access permit. Again, it's not clear that's what the Lieutenant

20:56.520 --> 21:00.200
Governor of the fifth largest economy in the world should be doing, but he said he knew

21:00.200 --> 21:07.200
how to do this in San Francisco and it was circa 2013. You needed to get it, you needed

21:08.080 --> 21:12.320
to get the neighbors to sign off, which was maybe doable. Then you needed to go to the

21:12.320 --> 21:17.560
Board of Supervisors because you had to build a staircase, and it was a public walkway,

21:17.560 --> 21:21.200
and the whole public had to comment. Nobody knew what happened then. Then even harder,

21:21.200 --> 21:26.480
a tree had grown where the driveway was supposed to be, and you needed a tree removal permit.

21:26.560 --> 21:32.280
This was the sort of thing that you would never get. You can describe all this as crazy

21:32.280 --> 21:39.280
left-wing ideology, but I think it's more like really, really deep corruption. This

21:39.280 --> 21:45.280
is in a way the San Francisco problem, it's the California problem. The analogy I have,

21:45.280 --> 21:50.560
if you want to think about the economy of California, in some ways it's analogous to

21:50.600 --> 21:57.600
Saudi Arabia. You have a very mismanaged state government, there's a lot of insane ideology

21:59.920 --> 22:05.640
that goes with it, but you have these incredible gushers called the big tech companies, and

22:05.640 --> 22:12.640
then there's a way the super insane governance is linked to the gold rush of the place. There's

22:15.960 --> 22:20.240
some point where it'll be too crazy even for California, but California can get away

22:20.320 --> 22:23.480
with a lot of stuff, you wouldn't get away with elsewhere. San Francisco, my judgment,

22:23.480 --> 22:29.480
had gone a little bit too far. Maybe the AI thing is they found one more giant gusher.

22:29.480 --> 22:32.320
You don't have any Saudi money in your fund, I hope.

22:32.320 --> 22:37.320
Virtually none. Just in case. Here's a different question though, because it gets to the politics

22:37.320 --> 22:43.820
of this, which is it seems like a shift inside Silicon Valley, and a shift in terms of even

22:43.820 --> 22:50.820
the way the companies are managed in a political dimension. You were very outspoken, obviously,

22:52.580 --> 22:58.580
you supported President Trump in the last go round. I want to get to that part too,

22:58.580 --> 23:03.220
but I want you to speak first to the shift in the valley, at least what seems like a

23:03.220 --> 23:09.060
shift perception wise from being a very progressive place to maybe less so. Maybe not, maybe it's

23:09.060 --> 23:13.780
just the large summers that I spoke this afternoon, and he said there's 10 people he thinks

23:13.780 --> 23:18.340
are very loud on Twitter, and that's why the world thinks that between David Sachs

23:18.340 --> 23:24.540
and a bunch of other people, and Elon Musk, that's not representative, but I think you

23:24.540 --> 23:26.420
may have a different view.

23:26.420 --> 23:33.420
Well, I don't think you'll get a majority of tech people to support Trump over Biden

23:35.740 --> 23:39.500
or anything like that. I think you'll get way more than you had four or eight years

23:39.540 --> 23:45.540
ago, so I don't know if you're measuring a relative shift or an absolute number. Those

23:45.540 --> 23:50.940
are probably two different measures on that, but I would say that if we ask a very different

23:50.940 --> 23:57.060
question about, let's say, extreme wokeness, or I don't even know what you're supposed

23:57.060 --> 24:04.060
to call it, there is probably a broad consensus among the good tech families in Silicon Valley,

24:09.660 --> 24:16.660
founders, startup CEOs, people across a pretty broad range that it's gone way too far. I

24:16.660 --> 24:22.340
talked to a lot of these people, a lot of them are, I'd say, more centrist Democrats,

24:22.340 --> 24:27.980
but it is just, we need to have a secret plan to fight this, and what they tell me behind

24:27.980 --> 24:34.300
closed doors is way, way tougher than what they dare say in public, and so it is like,

24:34.300 --> 24:38.460
we need to have a plan to hire fewer people from San Francisco, because that's where the

24:38.540 --> 24:42.540
employees are the crazy. So if you want to have a less woke workforce, we need to, we're

24:42.540 --> 24:47.540
going to have targets about how we steadily move our company out of San Francisco specifically,

24:47.540 --> 24:52.540
and yeah, these are the sort of conversations that I've...

24:52.540 --> 24:57.540
And do you agree with this? And by the way, let me just read, you probably know Alex,

24:57.540 --> 25:03.740
Alex Wang, Scale AI CEO, who said that he's put together what he calls a merit-based

25:03.740 --> 25:08.500
hiring program. He said he's getting rid of DEI, says hiring on merit will be a permanent

25:08.500 --> 25:11.820
policy at scale. It's a big deal whenever we invite someone to join our mission, and

25:11.820 --> 25:14.980
those decisions have never been swayed by orthodoxy or virtue signaling or whatever

25:14.980 --> 25:20.820
the current thing is. I think of our guiding principle as MEI, Merit Excellence and Intelligence.

25:20.820 --> 25:24.820
Bill Ackman went on to say that he thinks DEI is actually inherently a racist and illegal

25:24.820 --> 25:25.820
movement.

25:26.820 --> 25:33.820
Yeah, I, again, my feel for, there aren't that many people who are willing to say what

25:33.820 --> 25:38.820
Alex says, but I think there are an awful lot of people who are pretty close to thinking

25:38.820 --> 25:47.820
this, that there were ways they leaned into the DEI thing. It was like an anti-Trump thing.

25:47.820 --> 25:53.820
It was like a, everything was sort of polarized around Trump for the last four years of his

25:53.820 --> 25:58.820
campaign, so you have to demonstrate that you're anti-Trump by being even more pro-DEI.

25:58.820 --> 26:04.820
That's, of course, not necessarily a logical thing, but yes, people somehow ended up in

26:04.820 --> 26:13.820
this place that was very different. There always are questions what drove the DEI movement,

26:13.820 --> 26:22.820
the wokeness in these companies, and it probably is over-determined. There's a bottom-up,

26:22.820 --> 26:26.820
woke millennial people who were brainwashed into DEI in their colleges. That's sort of

26:26.820 --> 26:33.820
the bottom-up theory. There's sort of a, I don't know, there's sort of a cynical corporate

26:33.820 --> 26:38.820
version where this is, you know, the leadership of the company either believed it or used

26:38.820 --> 26:44.820
it as sort of a, as a way to manage and control their companies in certain ways. You know,

26:44.820 --> 26:49.820
the part that I always feel is a little bit underestimated is there was probably also

26:49.820 --> 26:57.820
a top-down level from a government regulatory point of view where, you know, if you don't

26:57.820 --> 27:05.820
do DEI, there is some point where you do get in trouble. You know, I don't know.

27:05.820 --> 27:09.820
This is part of the ESG movement now. I mean, look, we talked about ESG here for a long time.

27:09.820 --> 27:13.820
There was an ESG movement, and then there were probably all these governmental versions.

27:13.820 --> 27:17.820
And so, I don't know, this would be probably, if my candidate for the company in Silicon

27:17.820 --> 27:24.820
Valley is still probably the most woke, would be something like Google. And it's less woke

27:24.820 --> 27:28.820
than it was two, three years ago, but in some ways, you know, they have a total monopoly

27:28.820 --> 27:33.820
in search, and so there's sort of some way in which, you know, if wokeness is a luxury

27:33.820 --> 27:39.820
good, like, you can afford it more if you're a monopoly than if you're not. And then the

27:39.820 --> 27:45.820
problem for Google as a pretty big monopoly is that it's always going to be, you know,

27:45.820 --> 27:49.820
subject to a lot more regulatory pressure from the government. And so if you have something

27:49.820 --> 27:59.820
like the Gemini, the Gemini AI engine, you know, and it's sort of this comical, absurdist

27:59.820 --> 28:04.820
thing where it generates these black women Nazis, you know, and you're supposed to find

28:04.820 --> 28:09.820
famous Nazis, and then the diversity criterion gets applied across the board, and so it just

28:09.820 --> 28:13.820
generates fake black women who are Nazis, which is, you know, a little bit too progressive,

28:13.820 --> 28:20.820
I think. But then if you think of it in terms of this larger political context, Google will

28:20.820 --> 28:26.820
never get in trouble for that. The FDC will never sue them for misinformation or anything

28:26.820 --> 28:33.820
like that. That stuff does not get fact-checked. You don't really get in trouble, and the

28:33.820 --> 28:39.820
FDC will never get in trouble. And you probably even get some protection where, okay, you

28:39.820 --> 28:45.820
know, you are, you're going along with the woke directives from the ESG people or the

28:45.820 --> 28:49.820
government. Maybe you overdid it a little bit, but we trust you to be good at other

28:49.820 --> 28:54.820
things. So there may be a very different calculus if you're sort of a large quasi-regulated

28:54.820 --> 28:57.820
monopoly. Let me ask you about large quasi-regulated monopolies and also concentration, but I

28:57.820 --> 29:01.820
want to read you, this is something you actually wrote in your book 10 years ago about Google,

29:01.820 --> 29:05.820
and it being a monopoly. You said, since it doesn't have to worry about competing with

29:05.820 --> 29:11.820
anyone, it has wider latitude to care about its workers, its products, and its impact on

29:11.820 --> 29:15.820
the wider world. Google's motto, don't be evil, is in part a brand employee, but it's also

29:15.820 --> 29:20.820
a characteristic of a kind of business that's successful enough to take ethics seriously

29:20.820 --> 29:24.820
without jeopardizing its own existence. In business, money is either an important thing

29:24.820 --> 29:28.820
or it's everything. Monopolists can't afford to think about things other than making money.

29:28.820 --> 29:34.820
Non-monopolists can't. In a perfect competition, a business is so focused on today's margin that

29:34.820 --> 29:38.820
it can't possibly plan for a long-term future. Only one thing can allow a business to

29:38.820 --> 29:46.820
transcend the daily brute struggle for survival, monopoly profits. Were you writing in favor

29:46.820 --> 29:51.820
then of the monopoly idea or against?

29:52.820 --> 30:00.820
My book was giving you advice for what to do, and from the inside, you always want to do

30:00.820 --> 30:08.820
something like what Google did. If you're starting a company, competition is for losers.

30:08.820 --> 30:14.820
Capitalism and competition, people always say they're synonyms, I think they're antonyms,

30:14.820 --> 30:19.820
because if you have perfect competition you compete away all the capital. If you want to

30:19.820 --> 30:25.820
have Darwinian competition, beard, red and tooth and claw, you should open a restaurant.

30:25.820 --> 30:29.820
It's like an awful, awful business. You will never make any money. It's perfectly competitive

30:29.820 --> 30:37.820
and completely non-capitalist. From the inside, you want to always go for something like

30:37.820 --> 30:48.820
monopoly. In other parts of my book, I also qualify it that there are dynamic monopolies

30:48.820 --> 30:52.820
that invent something new, that create something new for the world, and we reward them with

30:52.820 --> 30:59.820
patents or things like that that they get. Then at some point, there's always a risk that

30:59.820 --> 31:05.820
these monopolies go bad, that they become like a troll collecting a toll at a bridge,

31:05.820 --> 31:09.820
that they're not dynamic, and that they become that fat and lazy.

31:09.820 --> 31:13.820
Are we there yet? Lena Kahn, if she was sitting here, would say we got there a long time ago.

31:13.820 --> 31:29.820
I think, man, all these ways I would, if I had to defend Google, and I would still say

31:29.820 --> 31:46.820
that it's still better run, even in its silly woke way, even in a slightly troll-like toll

31:46.820 --> 31:53.820
collecting way, than whatever a completely destructive path Lena Kahn would have for the

31:53.820 --> 31:57.820
company. We're still getting more good from Google as it is.

31:57.820 --> 32:01.820
Do you feel the way about all the big tech companies? You have lots of investments in smaller

32:01.820 --> 32:05.820
companies that need to access the app store on Apple's phone. Do you say to yourself that

32:05.820 --> 32:11.820
it should be opened up? Do you say they created the store, therefore they should control the

32:11.820 --> 32:14.820
store? How do you think about that kind of stuff?

32:14.820 --> 32:21.820
There are a lot of complicated questions on all these things. They're much bigger. We're

32:21.820 --> 32:26.820
in a very different place from where you were 10 years ago on these things. I still worry

32:26.820 --> 32:31.820
that in many cases the remedy is worse than the disease. A lot of these businesses are,

32:31.820 --> 32:38.820
if you have a natural monopoly, the remedy is not to break it up. It's like a utility company

32:38.820 --> 32:43.820
and then the remedy is to regulate it or tax it or do various things like that. If you

32:43.820 --> 32:51.820
could convince me that we are a static as a utility company, then maybe the remedy is to do

32:52.820 --> 33:01.820
something like that. To the extent that the real monopoly problems in our society are much

33:01.820 --> 33:09.820
more these old economy, racket-like companies. I spent three months during COVID in Maui and

33:09.820 --> 33:17.820
there's a single hospital in Maui. The Hawaiian Island, there's this line, if you have a pain,

33:17.820 --> 33:24.820
get on a plane because it's a local racket, it's completely mismanaged. That's probably

33:24.820 --> 33:31.820
the really dysfunctional monopolies in our society are these pretty big ones that control

33:31.820 --> 33:40.820
these local markets that are 100% troll collecting. I think even with all my misgivings about

33:41.820 --> 33:48.820
something like Google, it's a vastly morally superior place to your local hospital.

33:48.820 --> 33:53.820
How do you feel about it in the context of AI, which is to say that if you believe AI is this

33:53.820 --> 33:57.820
transformative product and that there's only going to be three or four players who are going to

33:57.820 --> 34:02.820
control all of these models, whether it be Google or Microsoft with open AI or maybe an

34:02.820 --> 34:08.820
Amazon along the way. I don't know where you think Apple is going to land in this conversation.

34:09.820 --> 34:13.820
Is that a good thing or a bad thing? Also, I would argue, even as an investor who looks at

34:13.820 --> 34:19.820
startups, how do you even look at startups down the line that could effectively get competed away

34:19.820 --> 34:24.820
because I'm going to build my app with AI and I'm just going to copy what you've made?

34:24.820 --> 34:31.820
Well, I think it's in a very different place from the consumer internet type businesses.

34:31.820 --> 34:37.820
There's been a history, they've been around for decades. If I had to make the anti-Google

34:37.820 --> 34:44.820
experiment, it would be, they won at Search in 2002 and there's been no serious competition

34:44.820 --> 34:55.820
for 21, 22 years. They beat Microsoft and Yahoo in 2002 and then it's somehow very hard to disrupt

34:55.820 --> 35:04.820
that. Then I think the AI piece is extremely fluid, it's extremely hard to know, it's very hard

35:04.820 --> 35:11.820
to know where the value is. As I said, it's like the obvious monopoly right now is Nvidia

35:11.820 --> 35:22.820
but it doesn't seem that durable. If you thought Nvidia is as durable as Google, the stock's really cheap.

35:22.820 --> 35:30.820
You should just buy it like crazy. The market pricing is telling you they have a temporary

35:30.820 --> 35:37.820
monopoly but it's not very robust and then on the level of the software companies, I worry that

35:37.820 --> 35:46.820
OpenAI has a lead, all sorts of other people are going to be able to catch up pretty quickly

35:46.820 --> 35:52.820
and if you have three or four doing the same thing, that's a lot more than one.

35:52.820 --> 35:55.820
Very, very different set of economics.

35:55.820 --> 35:58.820
I want to pivot the conversation again because another investment that you've made

35:58.820 --> 36:04.820
and been very public about is Bitcoin. You have remained a very big bull.

36:04.820 --> 36:10.820
You have come out publicly and you said that enemy number one to Bitcoin is the sociopathic

36:10.820 --> 36:15.820
grandpa from Omaha that you described as Warren Buffett.

36:15.820 --> 36:19.820
Can you tell me what you were thinking when you said that?

36:20.820 --> 36:37.820
It got a lot of laughs so somehow people, it probably had some kind of a nerve but it was in a 2022

36:37.820 --> 36:44.820
Bitcoin convention talk I gave and there were three separate enemies.

36:44.820 --> 36:49.820
There was Jamie Dimon, Larry Fink who is no longer an enemy by the way.

36:49.820 --> 36:54.820
He sort of shifted but maybe I can say that Larry Fink things too.

36:54.820 --> 37:05.820
Then there was Warren Buffett and the rough context was, my sort of political sociological analysis

37:05.820 --> 37:11.820
was the cryptocurrencies were, it was a revolutionary youth movement but for them to really take over,

37:11.820 --> 37:17.820
you needed, it couldn't just be a student uprising like 1968.

37:17.820 --> 37:24.820
You needed to get the rest of the society on board and as long as the old people were going to sit on their hands

37:24.820 --> 37:30.820
that was the big blocker for cryptocurrencies to go to the next level.

37:30.820 --> 37:32.820
Are you still convinced?

37:32.820 --> 37:48.820
I think it's gotten partially unlocked with the Bitcoin ETF but then probably the part where I'm less convinced of

37:48.820 --> 37:55.820
is this question of the sort of ideological founding vision of Bitcoin or these cryptocurrencies

37:55.820 --> 38:05.820
as sort of a cipherpunk crypto-anarchist libertarian anti-centralized government thing.

38:05.820 --> 38:08.820
Isn't that what got you interested in the first place?

38:08.820 --> 38:15.820
That's what I thought was terrific about it and then the question is does it really work that way

38:15.820 --> 38:18.820
or has that thread somehow gotten lost?

38:18.820 --> 38:25.820
And so when people in the FBI tell me that they'd much rather have criminals use Bitcoin than $100 bills

38:25.820 --> 38:30.820
it suggests that maybe it's not quite working the way it was supposed to.

38:30.820 --> 38:32.820
Have you sold any of your Bitcoin?

38:32.820 --> 38:34.820
I still hold some.

38:35.820 --> 38:49.820
There are all these ways. I didn't buy as much as I should have and I'm not sure it's going to go up that dramatically from here.

38:49.820 --> 38:50.820
From here?

38:50.820 --> 38:56.820
Yeah, I think we got the ETF edition and I don't know who else buys it quickly from here.

38:56.820 --> 38:59.820
It's an interesting investment advice.

39:00.820 --> 39:05.820
That actually surprised me because I thought you were still all in.

39:05.820 --> 39:08.820
I still have a small position.

39:08.820 --> 39:18.820
It probably still can go up some but it's going to be a volatile bumpy ride and I had a dual reason.

39:18.820 --> 39:27.820
One was the sort of ideological decentralized future of computing world that I really do believe and really believe would be better

39:27.820 --> 39:34.820
and it seemed like the perfect vehicle for that for such a long time and I am just much less convinced of that.

39:34.820 --> 39:35.820
Interesting.

39:35.820 --> 39:43.820
So maybe Larry Fink with the BlackRock ETF surrendered to the forces, the anti-ESG forces

39:43.820 --> 39:50.820
or maybe it's more like Bitcoin's been co-opted by them and I worry it was more the latter.

39:50.820 --> 39:54.820
Okay, different question. SpaceX, that's another big investment for you.

39:54.820 --> 39:59.820
After ousting Elon Musk you became friends with him again.

39:59.820 --> 40:02.820
What does that look like to you in the future?

40:02.820 --> 40:10.820
Is that going to be the biggest investment you've ever made when this is all said and done?

40:10.820 --> 40:24.820
Man, I'm always sort of hesitant to sort of pitch these companies too much.

40:24.820 --> 40:34.820
But I think there were sort of a lot of different things that came together.

40:35.820 --> 40:43.820
When Elon was building both Tesla and SpaceX in the 2000s, people thought he was just really, really crazy

40:43.820 --> 40:52.820
and I think even a lot of those of us who worked with him at PayPal, there was this PayPal book that David Sacks and I thought of writing

40:52.820 --> 41:01.820
and the Elon chapter was, I think, entitled something like the man who knew nothing about risk or something like this

41:01.820 --> 41:09.820
and there were all these crazy Elon stories I could tell and then if one of the two companies had succeeded

41:09.820 --> 41:15.820
you would say, well maybe he still got really lucky but when two out of two companies that people thought were completely

41:15.820 --> 41:24.820
hair-brained in the 2000s, when they both succeed, you have to somehow reassess it and somehow the rest of us

41:24.820 --> 41:30.820
somehow are too risk-averse or there's something about risk he knows that we don't or something like this

41:31.820 --> 41:34.820
and so yes, I think there's...

41:34.820 --> 41:36.820
You didn't invest in Tesla?

41:36.820 --> 41:44.820
We did not invest in Tesla. We should have invested in that one. It was public at a much earlier date

41:44.820 --> 41:50.820
and then there's always sort of a self-imposed limitation that we tend not to invest in public companies

41:50.820 --> 41:55.820
there's 20% of the venture fund you could but that was sort of the...

41:55.820 --> 42:01.820
I think they started Tesla in 2002, it went public in 2010

42:01.820 --> 42:10.820
I remember test driving the Model S in October 2012 and it was just, wow this is just a terrific car

42:10.820 --> 42:16.820
and I think the correct thing would have been to wait till they came out with it and then nobody liked it

42:16.820 --> 42:22.820
it was such a hated stock shorted by everybody and you could have just waited 10 years

42:22.820 --> 42:27.820
and just bought the shares in the public market and you would have made 10 times your money in 18 months

42:27.820 --> 42:32.820
and 100 times in the next 6, 7, 8 years

42:32.820 --> 42:42.820
and then there was something also about SpaceX that looked like it was a very crazy, hair-brained idea

42:42.820 --> 42:48.820
and yet it was very straightforward, it was the rocket launch business

42:49.820 --> 42:53.820
the government will pay or the customers pay for the vehicles before you build them

42:53.820 --> 42:58.820
so it's actually cash flow positive, there's some money they needed for expansion

42:58.820 --> 43:03.820
but it was basically a cash flow positive business, it was a weird investment in 2008

43:03.820 --> 43:09.820
they didn't need any of the money but there was some NASA or government rule where they needed outside investors

43:09.820 --> 43:15.820
and so they were forced to take investors and then we were on good enough terms that we did it

43:16.820 --> 43:19.820
if you had been a Tesla shareholder we've all been reading about it

43:19.820 --> 43:23.820
would have you paid him the big compensation package?

43:23.820 --> 43:33.820
I would have, well I think the nuanced answer is I would have voted in favor of the compensation package

43:33.820 --> 43:39.820
because you would know that if it failed the share price would have gone down a lot the next day

43:39.820 --> 43:43.820
because people would wonder whether Elon would quit and that would be bad for the company

43:43.820 --> 43:48.820
so whether you believe in the package or not the rational thing would be that you should vote for it

43:48.820 --> 43:54.820
and then if you think it's a bad idea maybe you sell your shares after you get a pop or something like this

43:54.820 --> 44:00.820
so that's the obvious game theory on why Elon was going to win that vote no matter what

44:00.820 --> 44:07.820
and it was really crazy that we listened to people in the media and I'm sure yourself

44:07.820 --> 44:11.820
but we're all saying it was a hair-brained thing and the shareholders were all going to vote against it

44:11.820 --> 44:16.820
and if you just did the basic analysis it was obvious that Elon was going to win the vote

44:16.820 --> 44:18.820
regardless of what the shareholders actually were

44:18.820 --> 44:20.820
What did you think of him investing in X?

44:20.820 --> 44:25.820
By the way X is what he wanted PayPal to be, did you give him money for that?

44:30.820 --> 44:38.820
We didn't do anything on the Twitter one, we didn't do anything on the current XAI company

44:38.820 --> 44:42.820
I guess there's a lot of different things that have X in the name with Elon

44:50.820 --> 45:02.820
I think it was an incredibly, I do think we need a broader surface area for debate in our society

45:02.820 --> 45:07.820
and so I think obviously there are all these very complicated trade-offs between

45:07.820 --> 45:14.820
how much speech do you suppress, how much good speech are we suppressing, how much bad speech are we allowing

45:14.820 --> 45:17.820
how do you get those trade-offs right, very, very hard to do

45:17.820 --> 45:22.820
My judgment is we should have just a lot more surface area for debate discussion

45:22.820 --> 45:29.820
and I think what Elon did with Twitter was I think extremely important

45:29.820 --> 45:32.820
and I support it as an ideological project

45:32.820 --> 45:40.820
I worry about it as a financial thing, I don't know if that works

45:40.820 --> 45:46.820
We've looked over the years, we've looked over and over again at starting some kind of media company

45:46.820 --> 45:53.820
and there's always sort of this thought, can't you do something else in the sort of right of center media space

45:53.820 --> 45:59.820
and does it have to all be as lame as Fox News, isn't there an opening to do something else

45:59.820 --> 46:06.820
and then the question you always have to ask is it the Murdoch family that keeps it lame

46:06.820 --> 46:10.820
Why do you think it's lame?

46:10.820 --> 46:13.820
I think it's lame because they're controlled by the advertisers

46:13.820 --> 46:19.820
and there's a very narrow limit on what they can do

46:19.820 --> 46:26.820
and then the Elon question with Twitter was are you really allowed to do this and keep the advertisers

46:26.820 --> 46:28.820
and so that's where...

46:28.820 --> 46:30.820
Would you make it harder?

46:30.820 --> 46:36.820
It's super important what Elon did as a non-profit but it's going to be tough as a best...

46:36.820 --> 46:41.820
What about Truth Social?

46:41.820 --> 46:45.820
They have a few other problems they have to solve first

46:45.820 --> 46:47.820
Now it's something you'd invest in

46:47.820 --> 46:50.820
You get your head around the $6 billion valuation

46:50.820 --> 46:57.820
If I wanted to secretly funnel money to the Trump campaign and get around the campaign limitations

46:57.820 --> 47:00.820
so the stock price goes up and you can sell some stock and fund this campaign

47:00.820 --> 47:02.820
that might be a reason to invest

47:02.820 --> 47:07.820
Do you think people are doing that?

47:07.820 --> 47:13.820
They probably don't think of it in quite that literal term but maybe that's what's going on

47:13.820 --> 47:17.820
Have you talked to people in your realm who have said hey?

47:17.820 --> 47:26.820
Nobody's said that but I suspect a lot of the investors are going to vote for Trump

47:26.820 --> 47:31.820
They're thinking about it at least on some subconscious, not articulated level

47:31.820 --> 47:34.820
I want to talk a little more about Trump in just one more second

47:34.820 --> 47:37.820
but I want to ask you one last related social media question

47:37.820 --> 47:41.820
which is the search in general was here in Aspen

47:41.820 --> 47:44.820
and I think you've probably seen in the last couple of weeks that he came out

47:44.820 --> 47:51.820
and genuinely believes that social media and the Facebooks of the world really

47:51.820 --> 47:58.820
have done a real disservice to young people in the country

47:58.820 --> 48:04.820
and I just wonder what you think of that as somebody who invested early in Facebook

48:04.820 --> 48:14.820
I can't say that he's 100% wrong

48:14.820 --> 48:22.820
The place where I always push back on is that I feel it's too easy to turn tech

48:22.820 --> 48:26.820
or the social media companies into the scapegoat for all of our problems

48:27.820 --> 48:34.820
There's some kind of an interesting critique one can make of the tech companies

48:34.820 --> 48:38.820
and if you ask how many of the executives in those companies

48:38.820 --> 48:41.820
how much screen time do they let their kids use

48:41.820 --> 48:44.820
and there's probably sort of an interesting critique one could make

48:44.820 --> 48:45.820
What do you do?

48:45.820 --> 48:47.820
Not very much and I think that's very...

48:47.820 --> 48:49.820
What's not very much?

48:49.820 --> 48:51.820
An hour and a half a week

48:51.820 --> 48:53.820
Something like that

48:53.820 --> 48:54.820
How old are your kids?

48:54.820 --> 48:56.820
Three and a half, five years

48:56.820 --> 48:58.820
Three and a half and five years old

49:02.820 --> 49:10.820
If I were to make the anti-tech argument it's that there are probably a lot of people in tech

49:10.820 --> 49:13.820
who do something quite similar for their own families

49:13.820 --> 49:16.820
and there's some questions that that might lead you to ask

49:16.820 --> 49:18.820
And then on the other hand

49:20.820 --> 49:29.820
I don't think this is the main cause for all the different types of social dysfunction we have

49:29.820 --> 49:33.820
and it's maybe it's a 15%, 20% cause

49:33.820 --> 49:39.820
There's sort of a lot of other things that have gone super haywire in our society

49:39.820 --> 49:46.820
and by putting all the blame onto this, onto tech or onto one company

49:46.820 --> 49:49.820
you are really ignoring a lot of other stuff

49:49.820 --> 49:51.820
We could do a whole panel on this but one related question

49:51.820 --> 49:53.820
because we haven't mentioned it, TikTok

49:53.820 --> 49:56.820
Do you think of TikTok as a national security threat?

49:59.820 --> 50:02.820
Yeah, it's a very...

50:02.820 --> 50:04.820
There's something very strange going on

50:04.820 --> 50:11.820
Obviously the TikTok algorithms for the US are very different from the ByteDance algorithms in China

50:11.820 --> 50:13.820
Would you shut it down in this country?

50:17.820 --> 50:22.820
I probably would lean towards a tougher response

50:22.820 --> 50:24.820
I think just to shift from the normative to the...

50:24.820 --> 50:26.820
I don't think we're going to do anything

50:26.820 --> 50:29.820
I met the TikTok CEO last summer

50:29.820 --> 50:33.820
and I was the Singaporean guy, the TikTok CEO

50:33.820 --> 50:37.820
and I told him he didn't need to worry about it being shut down in the US

50:37.820 --> 50:39.820
and maybe I'm wrong but I think...

50:39.820 --> 50:40.820
Because you know something?

50:40.820 --> 50:45.820
Because we are incompetent and slow and bureaucratic

50:45.820 --> 50:48.820
and we will never get our act together in dealing with the problems of China

50:48.820 --> 50:50.820
until the day they invade Taiwan

50:50.820 --> 50:53.820
and then it will be shut down within 24 hours

50:53.820 --> 50:58.820
and since I think there's a 50-50 chance that China will invade Taiwan in the next five years

50:58.820 --> 51:03.820
my advice to the TikTok CEO was you should take all your people and computers

51:03.820 --> 51:09.820
and get them out of China because once Taiwan gets invaded it'll be too late

51:09.820 --> 51:12.820
so that's my advice but you don't need to worry about us doing anything before then

51:12.820 --> 51:15.820
and then his somewhat...

51:15.820 --> 51:20.820
I'm not sure good or worrisome answer was that they had studied World War I and World War II very carefully

51:20.820 --> 51:25.820
and there were a bunch of companies that were able to trade with all sides in those wars

51:25.820 --> 51:30.820
By the way, that implies that he also thinks that China is going to invade Taiwan

51:30.820 --> 51:31.820
He did not...

51:31.820 --> 51:34.820
You know, again I didn't frame it deterministically

51:34.820 --> 51:37.820
I said 50% chance, five years

51:37.820 --> 51:40.820
We are over time but we're going to keep going just for a little bit

51:40.820 --> 51:43.820
because I promise you we're going to talk a little bit about politics

51:43.820 --> 51:46.820
and I want to talk about your own politics, your own personal politics

51:46.820 --> 51:54.820
You were very vocal and outspoken about supporting who is now the former president the last time

51:54.820 --> 51:59.820
You have been less outspoken this time

51:59.820 --> 52:01.820
We're all going to watch the debate tonight

52:01.820 --> 52:05.820
So before we can get into the lessons and everything that you've learned

52:05.820 --> 52:08.820
and all of your prior experience

52:08.820 --> 52:11.820
are you planning to support the president this time?

52:11.820 --> 52:13.820
You know, I'm...

52:13.820 --> 52:15.820
I'm the former president I should say

52:15.820 --> 52:17.820
You know, you hold a gun to my head

52:17.820 --> 52:21.820
I'll vote for Trump, I'll still...

52:22.820 --> 52:24.820
I'd rather have him vote than Biden

52:24.820 --> 52:27.820
I'm not going to give any money to his super PAC

52:27.820 --> 52:32.820
I'm going to be less involved in all these ways

52:32.820 --> 52:35.820
And man, look, it is...

52:35.820 --> 52:39.820
And then I don't know, I think Trump will win

52:39.820 --> 52:42.820
I think he will win quite solidly

52:42.820 --> 52:45.820
I don't think it's going to even be close

52:45.820 --> 52:49.820
And then my pessimistic look ahead function is

52:49.820 --> 52:53.820
after he wins there will be a lot of buyer's remorse

52:53.820 --> 52:55.820
because the elections are A-B tests

52:55.820 --> 52:58.820
You know, if you asked me to make a pro-Trump argument

52:58.820 --> 53:01.820
I wouldn't, but I can probably come up with anti-Biden arguments

53:01.820 --> 53:03.820
and Biden is not going to make a pro-Biden argument

53:03.820 --> 53:05.820
he's going to make anti-Trump arguments

53:05.820 --> 53:08.820
and it's these two different hate factories

53:08.820 --> 53:10.820
that we have targeted at each other

53:10.820 --> 53:12.820
and that's the way the politics work

53:12.820 --> 53:15.820
and my judgment is Trump will easily win that

53:15.820 --> 53:17.820
but yeah, the election is a relative choice

53:17.820 --> 53:19.820
the post-election is absolute

53:19.820 --> 53:22.820
and then it'll be like, you know, if Biden wins

53:22.820 --> 53:24.820
like, how did we get this senile old man

53:24.820 --> 53:27.820
and if Trump wins, it'll be...

53:27.820 --> 53:29.820
Can I just ask you this?

53:29.820 --> 53:32.820
It's still like this clown show, whatever people will say

53:32.820 --> 53:34.820
I'm not going to ask you to make the pro-Trump argument

53:34.820 --> 53:36.820
That's sort of...

53:36.820 --> 53:39.820
But let me ask you about what I imagine is your anti-Biden argument

53:39.820 --> 53:41.820
I look at the last four years and say to myself

53:41.820 --> 53:44.820
if you were in Silicon Valley and you owned stock

53:44.820 --> 53:46.820
and these tech companies over the last four years

53:46.820 --> 53:48.820
you unfortunately did nothing but go up

53:48.820 --> 53:50.820
and I know...

53:50.820 --> 53:53.820
And I just... I wonder if you can make the argument

53:53.820 --> 53:55.820
because we can talk about Lina Khan

53:55.820 --> 53:58.820
and we can talk about regulations and potential taxes

53:58.820 --> 54:00.820
and all sorts of things

54:00.820 --> 54:02.820
but it's hard for me to look at the last four years and say

54:02.820 --> 54:04.820
especially if I was sitting

54:04.820 --> 54:06.820
I would imagine in your seat and say

54:06.820 --> 54:08.820
this was a terrible travesty

54:08.820 --> 54:10.820
but maybe I don't understand

54:10.820 --> 54:12.820
Well, I mean, I don't know

54:12.820 --> 54:14.820
this may not be believable to you

54:14.820 --> 54:16.820
but I...

54:16.820 --> 54:18.820
I don't think it's...

54:18.820 --> 54:20.820
the only thing I care about

54:20.820 --> 54:23.820
is whether the country is good for the tech billionaires

54:23.820 --> 54:26.820
and I think there are

54:26.820 --> 54:28.820
a lot of people who have not experienced

54:28.820 --> 54:30.820
the last three or four years this way

54:30.820 --> 54:32.820
I think one of the things Carvel said in the earlier

54:32.820 --> 54:34.820
presentation just before

54:34.820 --> 54:36.820
this one that I thought was quite good

54:36.820 --> 54:38.820
was there's been a shocking loss of support

54:38.820 --> 54:41.820
by the Democrats in the 18 to 35 year voters

54:41.820 --> 54:43.820
and it's because you can't get on the housing ladder

54:43.820 --> 54:45.820
you can...

54:45.820 --> 54:47.820
you know, the college debt's overwhelming

54:47.820 --> 54:49.820
you can never get started

54:49.820 --> 54:51.820
and so there's sort of a sense that...

54:51.820 --> 54:53.820
You think he'll be able to fix that?

54:53.820 --> 54:55.820
I don't...

54:55.820 --> 54:57.820
I think it's...

54:57.820 --> 54:59.820
it's just an up-down referendum

54:59.820 --> 55:01.820
on the incumbent at this point

55:01.820 --> 55:03.820
and, you know,

55:03.820 --> 55:05.820
my guess is that the sense is

55:05.820 --> 55:07.820
Biden's definitely not going to fix it

55:07.820 --> 55:09.820
and his time will run out and that's...

55:09.820 --> 55:11.820
and then...

55:11.820 --> 55:13.820
this is where I'm not overly excited

55:13.820 --> 55:15.820
I don't think Trump will

55:15.820 --> 55:17.820
particularly fix it but look

55:17.820 --> 55:19.820
the place where people, you know

55:19.820 --> 55:21.820
at this...

55:21.820 --> 55:23.820
in the audience here I think are just maximally

55:23.820 --> 55:25.820
divergent

55:25.820 --> 55:27.820
yes, the stock market has been great for people here

55:27.820 --> 55:29.820
you're in this wonderful

55:29.820 --> 55:31.820
bubble in Aspen where it's like

55:31.820 --> 55:33.820
I know Clinton is still president

55:33.820 --> 55:35.820
and it's 1995

55:35.820 --> 55:37.820
and everything

55:37.820 --> 55:39.820
is just getting better every day

55:39.820 --> 55:41.820
in every way and it's like some new age

55:41.820 --> 55:43.820
chant if you just say that to yourselves

55:43.820 --> 55:45.820
it's true

55:45.820 --> 55:47.820
and then

55:47.820 --> 55:49.820
the...

55:49.820 --> 55:51.820
the part of the Trump

55:51.820 --> 55:53.820
statement that I think was

55:53.820 --> 55:55.820
the most offensive

55:55.820 --> 55:57.820
thing he said

55:57.820 --> 55:59.820
it was very offensive not just

55:59.820 --> 56:01.820
to Democrats and to Republicans

56:01.820 --> 56:03.820
and especially to Silicon Valley

56:03.820 --> 56:05.820
was make America great again

56:05.820 --> 56:07.820
because that was a pessimistic slogan

56:07.820 --> 56:09.820
it was the most pessimistic slogan

56:09.820 --> 56:11.820
a major presidential candidate

56:11.820 --> 56:13.820
ever had because

56:13.820 --> 56:15.820
what it says implicitly is this is no longer

56:15.820 --> 56:17.820
a great country

56:17.820 --> 56:19.820
and that's what you are never supposed to say

56:19.820 --> 56:21.820
especially if you're a Republican

56:21.820 --> 56:23.820
that's why the Bush people probably hate him

56:23.820 --> 56:25.820
more than anybody in this audience

56:25.820 --> 56:27.820
you know

56:27.820 --> 56:29.820
and then

56:29.820 --> 56:31.820
Silicon Valley was, you know

56:31.820 --> 56:33.820
it's somewhat offensive to people in New York City

56:33.820 --> 56:35.820
but the bankers on Wall Street don't really think

56:35.820 --> 56:37.820
they're making the country a great place

56:37.820 --> 56:39.820
so it's not personally offensive

56:39.820 --> 56:41.820
it was personally offensive to Silicon Valley

56:41.820 --> 56:43.820
and yet

56:43.820 --> 56:45.820
I always think

56:45.820 --> 56:47.820
there is this problem of stagnation

56:47.820 --> 56:49.820
there is this problem we're stuck

56:49.820 --> 56:51.820
there's a sense that

56:51.820 --> 56:53.820
we're not progressing in all these ways

56:53.820 --> 56:55.820
as a society as much as we have

56:55.820 --> 56:57.820
I don't think Trump has all the answers

56:57.820 --> 56:59.820
but I think

56:59.820 --> 57:01.820
what I said in 2016 is

57:01.820 --> 57:03.820
the first step

57:03.820 --> 57:05.820
towards solving problems is to at least talk about them

57:05.820 --> 57:07.820
what about the polarization part

57:07.820 --> 57:09.820
the polarization part the uncertainty part

57:09.820 --> 57:11.820
the questions about democracy

57:11.820 --> 57:13.820
and the rule of law and the future

57:13.820 --> 57:15.820
of a country and I think there's a lot of people

57:15.820 --> 57:17.820
who worry about those things

57:17.820 --> 57:19.820
sure those are all

57:19.820 --> 57:21.820
those are all still

57:21.820 --> 57:23.820
those are things you probably wouldn't worry about

57:23.820 --> 57:25.820
if Biden was the president right

57:25.820 --> 57:27.820
I feel the country is still very polarized

57:27.820 --> 57:29.820
it's been getting more polarized

57:29.820 --> 57:31.820
for decades

57:31.820 --> 57:33.820
it was polarized against

57:33.820 --> 57:35.820
Bork in the 80s

57:35.820 --> 57:37.820
that was sort of a new crescendo in polarization

57:37.820 --> 57:39.820
there was way Fox News was polarized

57:39.820 --> 57:41.820
against the Clintons

57:41.820 --> 57:43.820
and I don't know

57:43.820 --> 57:45.820
it's always what's cause and effect

57:45.820 --> 57:47.820
is the polarization causing the stagnation

57:47.820 --> 57:49.820
or does the stagnation lead to the polarization

57:49.820 --> 57:51.820
I don't think the polarization just happens

57:51.820 --> 57:53.820
in a country where everything is gross

57:53.820 --> 57:55.820
it's a tonal question

57:55.820 --> 57:57.820
you come across a very sensible reasonable person

57:57.820 --> 57:59.820
I think

57:59.820 --> 58:01.820
there are people who hear

58:01.820 --> 58:03.820
I'm sure disagree with you about

58:03.820 --> 58:05.820
lots of different issues but

58:05.820 --> 58:07.820
my question about tone

58:07.820 --> 58:09.820
about the president and the tone of the president

58:09.820 --> 58:11.820
by the way I should say

58:11.820 --> 58:13.820
and I'm not speaking out of school

58:13.820 --> 58:15.820
you also I would say by the way

58:15.820 --> 58:17.820
you've been a Republican

58:17.820 --> 58:19.820
for a long time now

58:19.820 --> 58:21.820
public about that

58:21.820 --> 58:23.820
you're also proudly gay

58:23.820 --> 58:25.820
openly so

58:25.820 --> 58:27.820
and I wonder if you can tie

58:27.820 --> 58:29.820
you know

58:29.820 --> 58:31.820
President Trump when he talks

58:31.820 --> 58:33.820
about some of the issues around LGBT issues

58:33.820 --> 58:35.820
in this country and other people

58:35.820 --> 58:37.820
there are people in those communities

58:37.820 --> 58:39.820
who say they don't feel safe about it

58:39.820 --> 58:41.820
yeah

58:41.820 --> 58:43.820
we can go through all these different

58:43.820 --> 58:45.820
different versions of that

58:45.820 --> 58:47.820
I think

58:47.820 --> 58:49.820
there was never any thought of reversing gay marriage

58:49.820 --> 58:51.820
or any of those things

58:51.820 --> 58:53.820
by Trump

58:53.820 --> 58:55.820
at least

58:55.820 --> 58:57.820
and look

58:57.820 --> 58:59.820
I think the

58:59.820 --> 59:01.820
yeah there are all these ways

59:01.820 --> 59:03.820
they're not the way

59:03.820 --> 59:05.820
I would articulate these things

59:05.820 --> 59:07.820
but

59:07.820 --> 59:09.820
these sort of polite tone

59:09.820 --> 59:11.820
there was

59:13.820 --> 59:15.820
people had attempted to say

59:15.820 --> 59:17.820
something's gone very wrong in our country

59:17.820 --> 59:19.820
the house is on fire, it's burning to the ground

59:19.820 --> 59:21.820
we are a society

59:21.820 --> 59:23.820
in decline, stagnation

59:23.820 --> 59:25.820
maybe

59:25.820 --> 59:27.820
AI will save us

59:27.820 --> 59:29.820
but this is the way people talk about AI

59:29.820 --> 59:31.820
if it doesn't lead to this cornucopian growth

59:31.820 --> 59:33.820
we're just completely going to be

59:33.820 --> 59:35.820
buried by budget deficits

59:35.820 --> 59:37.820
and debt

59:37.820 --> 59:39.820
for decades to come

59:39.820 --> 59:41.820
and I think

59:41.820 --> 59:43.820
AI is a big thing

59:43.820 --> 59:45.820
is it big enough to solve our budget deficit problem

59:45.820 --> 59:47.820
I don't believe it is

59:47.820 --> 59:49.820
we have a lot of these

59:49.820 --> 59:51.820
problems and

59:51.820 --> 59:53.820
at this point

59:53.820 --> 59:55.820
extra politeness

59:55.820 --> 59:57.820
is not quite

59:57.820 --> 59:59.820
the thing

59:59.820 --> 01:00:01.820
it was an inarticulate shriek for help

01:00:01.820 --> 01:00:03.820
and look my sort of fantasy

01:00:03.820 --> 01:00:05.820
in 2016 in supporting Trump

01:00:05.820 --> 01:00:07.820
this was where I was completely delusional

01:00:07.820 --> 01:00:09.820
this would be the way you start to have a conversation

01:00:09.820 --> 01:00:11.820
and

01:00:11.820 --> 01:00:13.820
and that's why

01:00:13.820 --> 01:00:15.820
another reason why I'm

01:00:15.820 --> 01:00:17.820
off-ramping I'd much rather have

01:00:17.820 --> 01:00:19.820
the sort of conversation we had here

01:00:19.820 --> 01:00:21.820
and if I lean in all the way to support Trump

01:00:21.820 --> 01:00:23.820
it'll be all about that

01:00:23.820 --> 01:00:25.820
and we can't talk about all these other things

01:00:25.820 --> 01:00:27.820
which is the way we are going to substantively solve the problems

01:00:27.820 --> 01:00:29.820
I want to thank you for this conversation

01:00:29.820 --> 01:00:31.820
and for addressing all these issues

01:00:31.820 --> 01:00:33.820
it really was a phenomenal discussion

01:00:33.820 --> 01:00:35.820
awesome thank you so so much

01:00:35.820 --> 01:00:37.820
thank you very much

01:00:49.820 --> 01:00:51.820
you

