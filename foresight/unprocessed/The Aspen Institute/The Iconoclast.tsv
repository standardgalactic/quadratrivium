start	end	text
0	8360	Good afternoon everybody, I'm Andrew Ross Sorkin and it is a privilege to have with
8360	14640	me Peter Thiel this afternoon, one of the great legendary investors in Silicon Valley.
14640	19720	He has been involved in just about everything that you touch and feel, including being the
19720	25480	co-founder of PayPal, the co-founder of Palantir, he made his first outside investment, made
25480	30240	the first outside investment, I'd say in Facebook, his firm Founders Fund is a big
30240	35280	backer of Stripe and SpaceX, his firm backed numerous other startups through the Founders
35280	36840	Fund into your capital.
36840	41360	He also started the Thiel Fellowship to your program, that's an alternative to a college
41360	46840	degree which I want to get to at one point and more importantly than all of it, he has
46840	52800	touched some of the people and found the people who you read about in the headlines every
52800	58320	day from Mark Zuckerberg to Elon Musk to Sam Altman and so many others and it is great
58320	59320	to have you here.
59320	60320	Thanks for having me.
60320	64960	We're also going to talk a little politics as well, along with maybe some of the issues
64960	69280	and culture conversations that are happening in Silicon Valley, but here's where I want
69280	72640	to start the conversation because I want to start the conversation talking about people
72640	76760	because I think there's something actually extraordinary when you think about your track
76760	82760	record over the years of involving yourself in investing not just in companies but ultimately
83040	84200	in people.
84200	88520	You wrote a book which is coming on a 10-year anniversary and by the way I re-read it and
88520	94440	it stands up in a very big way, it is called Zero to One and you wrote the following about
94440	97280	founders, the idea of founders.
97280	100480	You wrote that the lesson for business is that we need founders.
100480	108200	If anything, we should be more tolerant of founders who seem strange or extreme.
108200	116320	We need unusual individuals to lead companies beyond mere incrementalism and I mention that
116320	120320	because I also just mentioned a number of individuals which we read about all the time
120320	125760	and some of those people would be described as unusual perhaps or even strange.
125760	130640	And I'm curious about how you think over the years you have found these individuals, what
130640	135840	it is that has made these individuals as successful as they have become.
136840	142960	Yeah, it's obviously, if there was some simple magic formula, this is what a founder looks
142960	149760	like and you invest in this category of people who's a founder, it probably gets faked.
149760	155160	It's like, I don't know, it's a 20-year-old with a t-shirt and jeans or something like
155160	162320	this or you end up with all kinds of really fake ideas but yeah, I think a lot of the
162320	170120	great companies that have been built over the last two decades were, they were founded
170120	176520	by people where it was somehow deeply connected to their identity, their life project.
176520	183560	They had some kind of idiosyncratic, somewhat different vision of what they were doing.
183560	190680	They did something new and then they built something extraordinarily big over the years
190680	197200	and of course they have these sort of extreme personalities, often have a lot of blind spots
197200	201520	and there are all these ways in which it's a feature and there are ways in which it can
201520	209120	be a little bit buggy but it's sort of a package deal and I net out to it being massively
209120	214400	advantageous versus let's say a professional CEO being brought in.
214400	219680	The prehistory of this I would say would be in the 1990s, the Silicon Valley formula was
219680	225080	you had various people found the company and then you'd replace them as quickly as possible
225080	229680	with professional CEOs, professional management and there are variations of this that happened
229680	236840	with Netscape and Yahoo and even Google, all these companies and the Gen X people founded
236840	240360	them, the baby boomers came along and sort of took over the companies and stole them
240360	243320	from the Gen X founders in the 90s.
243320	248960	In the 2000s when the millennials founded the companies they were given more of an opportunity
249280	250960	and it made a big difference.
250960	258760	The Facebook story I always tell is it was 2006, two years in, Zuckerberg was like 22
258760	267240	years old and we got a $1 billion offer to sell the company to Yahoo and we had a board
267240	271320	meeting, there were three of us and we thought we should at least talk about it.
271320	275600	It was a lot of money, Zuckerberg would make $250 million and sort of an eight hour long
275720	280160	discussion and he didn't know what he'd do with the money and he'd just start another
280160	283480	social networking company and kind of like the one he had and he didn't know what else
283480	290960	he would do and so he really didn't want to sell and if you had a professional CEO
290960	295280	it would have just been, man I can't believe they're offering us a billion dollars and
295280	304440	I'm going to try not to be too eager and we better take the money and run and that one
304440	305440	thing right makes a big difference.
305440	309080	Let me ask you a different question and all of these individuals had a huge impact on
309080	314760	society and have an enormous individual power and I think one of the things that you've
314760	318120	argued in this book and that you've argued over the years is that we need to give them
318120	325840	that power, we need to offer them a latitude that in many ways we don't offer others.
325840	336040	Well I think one of the frames I always have is that there are many ways in which the United
336040	343040	States, the developed countries have been relatively stagnant for the last 50 years.
343040	344800	Progress has slowed.
344800	350160	We had progress in computers, internet, software and many other domains, things have kind of
350160	354640	stalled out and it sort of manifests in low economic growth in the sense that the younger
354640	358120	generation is going to have a tough time doing as well as their parents and there is
358120	366280	sort of this way that there has been this broad stagnation for 40, 50 years and we need
366280	368520	to find ways to do new things.
368520	374120	I don't think, you know, startup, tech startup companies are the only ways to do them, that
374120	382960	is a vehicle for doing it and if you don't allow these companies to have a certain latitude
383560	388320	and flexibility to try to do new things, we shut it down right away, you know, the stagnation
388320	389680	will be worse than ever.
389680	392840	Okay, but here's a separate almost philosophical question, I'm going to read back something
392840	397400	you said to the New Yorker, there was a piece about Sam Altman, this is right around actually
397400	404280	when open AI began, 2016 and I think it actually might even be representative of how you might
404280	408720	think about Mark Zuckerberg or Elon Musk or some of these other kinds of major players.
408720	416280	This is what you said, you said, Sam's program for the world is anchored by ideas, not people
416280	421440	and that's what makes it powerful because it doesn't immediately get derailed by questions
421440	425720	of popularity and I thought that that was actually very indicative of most of the people
425720	430240	that you have invested in, it's really been about ideas and in some ways you could even
430240	433320	argue is disconnected from people.
433920	439960	I think it is really about a whole wide, people are able to think about a wide spectrum
439960	444640	of things, they're able to think about good founders have theories of how to hire people,
444640	448240	how to manage them, how to build teams, they have theories about where the culture, the
448240	454760	societies were going, they have technical things about the product, the design, they
454760	459400	have ideas about how they should market their company, so they're sort of polymaths are
459480	465720	able to think about a lot of these things, but yeah, I'm biased towards a lot of the
465720	472200	ones where it's more intellectual and maybe, but I think that quote has held up pretty
472200	477080	well with Sam Altman, maybe he needed to pay a little bit more attention to the board
477080	481040	and things like that and there was probably a people dimension that he had ignored a little
481040	484080	bit too much in November 2016.
484080	488800	Since we're on the Sam Altman of it all and since Sam was here yesterday, I'm so curious,
488840	494360	you were a mentor of his, what do you think of open AI and what do you think of AI more
494360	495360	broadly right now?
495360	496920	I mean, are we in a bubble?
496920	498560	Is this the future?
498560	499560	What is this?
499560	503240	Wow, it's a broad question.
503240	507920	I think I'm always hesitant to talk about it because I feel there's so many things I would
507920	512080	have said about AI where I would have been very wrong two, three years ago, so maybe
512080	517080	I'll start by just saying a little bit about the history of what people thought was going
517120	522560	to happen and then the surprising thing that open AI achieved and that did happen and if
522560	528560	you had this debate in the 2010s, there was sort of one, maybe frame in terms of two paradigms,
528560	535560	two books, there was the Boston Book Superintelligence 2014, which is that AI was going to build
536080	541800	this god-like superhuman intelligence and it was heading towards this god-like oracle
541880	547880	and that was what AI was going to be and then there was the Kaifu Li, a rebuttal 2018 AI
547880	553440	superpowers, which was sort of the CCP rebuttal to Silicon Valley, that no, AI is not about
553440	558040	god-like intelligence, that's a science fiction fantasy Silicon Valley has, AI is going to
558040	565040	be about machine learning, data collection, it's not conscious, it's not any of these
565200	570560	weird things, it's surveillance tech and China is going to beat the U.S. in the race for
570600	576080	AI because we have no qualms about sort of this totalitarian, not the word he used, collection
576080	582080	of data in our society and that was sort of the way the AI debate got framed and then
582080	585280	the thing I always said was, man, it's just such a weird word, it means all these different
585280	592280	things, it's annoyingly undefined, but then the sort of surprising and strangely unexpected
592520	599520	thing that happened is that in some sense, what open AI with chat GPT 3.5 for AI was
600760	607760	achieved in late 22, early 23 was you passed the Turing test, which was not super-intelligence,
607760	614760	it's not god-like, it's not low-tech surveillance, but that had been the holy grail of AI for
615000	621680	60 or 70 years and it's a fuzzy line, the Turing test is you have a computer that can convince
621680	626320	you that it's a human being and it's a somewhat fuzzy line because sometimes, but it pretty
626320	632160	clearly hadn't been passed before, it pretty clearly is passed now and that's a really
632160	638000	extraordinary achievement, it's extremely, it raises all sorts of interesting big picture
638000	645000	questions, what does it mean to be a human being in 2024? The sort of placeholder answer
646640	650000	I would have been tempted to give a couple of years ago would be something like the
650000	654560	Noam Chomsky idea that something very important about language, this is what sets humans apart
654600	659080	from all the other animals, we talk to each other and we have these rich semantic syntax
659080	666080	things and so if a computer can replicate that, what does that mean for all of us in
666080	671480	this room? It's an extraordinary development and it was also somehow, even though it had
671480	678080	been the holy grail, somehow in the last decade before, it was not expected at all and so
678080	683320	there's something very significant about it and very underrated and then of course you
683360	688800	get all these questions about, is it going to, is it an econ one question, is it a compliment,
688800	692280	is it going to make people more productive or is it a substitute, good, where it's going
692280	696920	to replace? So what do you think of all of this and how bullish as an investor are you
696920	702000	on this? What do you think our society, when you hear Sam Altman talk about this, you say
702000	706160	he's right, that's what it's going to be, do you think it's going to be something else?
706160	710480	You lived through 1999, there's some people who say this is a hype cycle, other people
710560	717560	say this is the future. Well, I'm very anchored on the 99 history and I somehow always like
717560	725560	to say that 99 was both. The peak of the bubble was also in a sense the peak of clarity, people
725560	729000	who realized the new economy was going to replace the old economy, the internet was
729000	736360	going to be the most important thing in the 21st century and people were right about that
736400	742760	and then the specific investments were incredibly hard to make and even the no-brainer market
742760	747440	leader, so if you said 1999, the no-brainer investment would have been Amazon stock,
747440	751520	it's a leading e-commerce company and they're going to scale and they'll get bigger and
751520	761520	it peaked in December 1999 at $113 a share, it was $5.5 in October 2001, 22 months later,
761520	765680	you then had to wait until the end of 2009 to get back to the 99 highs and then if you'd
765720	768560	waited until today, you would have made 25 times your money from 99, you'd have first
768560	775600	lost, you'd have gone down 95% and then made 500X, so even the no-brainer investment from
775600	785600	99 was wickedly tricky to pull off in retrospect and I sort of think that AI, the LLM form
785600	792520	of AI. These are the large language models. The open AI's of the world. Again, passing
792560	799080	the Turing test, I think it's roughly on the scale of the internet and so it's an incredibly
799080	803880	important thing, it's going to be very important socially, politically, philosophically about
803880	810480	all these questions about meaning and then the financial investment question I find unbelievably
810480	818480	hard and confusing and yeah, it's probably quite tricky. If you had to sort of concretize
818560	825560	one thing that's very strange about the, if you sort of just follow the money, at this
825560	831720	point, 80 to 85% of the money in AI is being made by one company, it's NVIDIA and so it's
831720	836440	all on this sort of very weird hardware layer which Silicon Valley doesn't even know very
836440	842240	much about anymore. We don't really do hardware, we don't do silicon chips in Silicon Valley
842240	846560	anymore. I get pitched on these companies once every three or four years and it's always
846600	851120	I have no clue how to do this. It sounds like a pretty good idea but man, I have no clue
851120	857840	and we never invest. Then there's sort of this theory that the hardware piece makes
857840	862720	the money initially, then gets more commodified over time and it'll shift to software and
862720	867400	the, I don't know, the multi-trillion dollar question, is that going to be true again this
867400	874400	time or will NVIDIA sort of have this incredible monopoly at the moment?
876800	883800	I suspect NVIDIA will, I think it will maintain its position for a while. I think the game
890320	895480	theory on it is something like all the big tech companies are going to start to try to
895480	902080	design their own AI chips so they don't have to do the 10x markup to NVIDIA and then how
902160	907840	hard is it for them to do it, how long will it take? If they all do it, then the chips
907840	914840	become a commodity and nobody makes money in chips. Then do you go into hardware and
915560	919080	you should do it if nobody else is doing it, if everybody does it, you shouldn't do it,
919080	923560	and then maybe, I'm not sure how that nets out, but probably people stay stuck for a
923560	927200	while and NVIDIA goes from strength to strength for a while.
927200	930720	I have a related but maybe personal question for you. You happen to have this very interesting
930720	934840	relationship with Sam Altman and then also a very interesting relationship with Elon
934840	941840	Musk. You both worked at PayPal. You famously were part of a coup effectively to push Elon
942240	946360	Musk out of the company. You're now friends with him all over again and have a stake in
946360	949600	SpaceX. You can maybe walk us through that friendship.
949600	956600	We had some rough moments in 2000, 2001, but it's been beautiful.
957320	961680	We're always going to go with this, actually, is one of the things that's been fascinating
961680	965440	and fascinating to the valley and I think to the country has been the commentary we've
965440	969720	heard from Elon Musk who helped build open AI with Sam and the break actually between
969720	976640	the two of them as creating this not-for-profit and what's happened to it. In fact, Elon
976640	981840	Musk originally sued Sam earlier this year and then dropped the suit recently.
981840	986120	But how do you think about this idea of a company that was started as a not-for-profit
986120	990440	and all of the safety concerns and things that you hear from Elon on one side and Sam
990440	992120	on the other?
992120	999120	Man, whichever person I talk to last, I find the most convincing probably. I talked to
1000360	1006520	Elon about it and he made this argument. It's just completely illegal for a non-profit
1006520	1011120	to become a for-profit company because otherwise everyone would set up companies as non-profits
1011120	1015240	and take advantage of the tax laws and then you turn them into a for-profit and this is
1016240	1020160	the most obvious arb and they just can't be allowed to do this. It's obviously just
1020160	1025360	totally illegal with what Sam's trying to do at open AI. And then like half an hour
1025360	1031680	after the conversation was over, at the moment it's like, oh, that's a really strong argument.
1031680	1037040	And then half an hour later, it's like, but the whole history of open AI is that the biggest
1037040	1045040	handicap they had was a non-profit and it led to all these crazy conflicting things culminating
1045120	1051120	in this non-profit board that thought it was better to shut down the company or the whole
1051120	1056240	venture, whatever you want to call it, rather than keep going. And nobody is ever going
1056240	1062080	to take the lesson from open AI to start a non-profit and turn it into a for-profit later,
1062080	1069080	given what a total disaster that was. But whoever I listen to last, I find the most compelling.
1069080	1073200	Let me ask you a different question. You've left Silicon Valley. You have now moved to
1073200	1080200	Los Angeles. That's your home. We left San Francisco specifically. It just felt it was
1081000	1084600	time to get out. So tell us why it was time to get out, because I think a lot of the issues
1084600	1089440	that actually we read about around open AI and some of the culture issues add a lot of
1089440	1096200	these companies are the reason you decided you didn't want to live there anymore. It's
1096200	1103200	hard to... It's a bunch of things that came together, but there was a sense that it was
1107600	1114600	sort of the ground zero of the most unhinged place in the country. You had this catastrophic
1114960	1119480	homeless problem, which maybe is not the most important problem, but it was never getting
1119480	1126480	better. It was by 2018 when we moved to LA, it felt like it had become extraordinarily
1127240	1133520	self-hating, where everybody who was not in tech hated the tech industry. This is very
1133520	1140320	odd. It would be like the people in Houston hating oil or people in Detroit hating cars,
1140320	1147320	people in New York hating finance. It had this unhinged, self-hating character in the
1149520	1156360	city itself. There were all these things that seemed extraordinarily unhealthy. If you asked
1156360	1163360	me in 2021, I would have said, man, they are finally... Yes, they're sitting on the biggest...
1164600	1169360	They created all this wealth, and yet they are going to succeed in committing suicide.
1169360	1175560	Three years later, I think the jury is a little bit more out, because maybe the AI revolution
1175640	1182640	is big enough that it will save even the most, I don't know, the most ridiculously mismanaged
1183120	1184720	city in the country.
1184720	1185720	It seemed to me...
1185720	1191920	Tell me if I'm wrong. I thought that part of the issue that you had with San Francisco
1191920	1197640	was the politics of it. Not just the politics of it, but how politics had seeped into the
1197640	1204640	culture of so many of the companies. I think that you thought that it had moved into the
1205560	1207680	city in a very progressive way.
1207680	1214680	Yeah, that's always a very clear dimension of it. That's the tip of the iceberg. That's
1216320	1222120	the part that's above the surface that people always focus on. Then the part that's below
1222120	1229120	the surface is just the deep corruption, the mismanagement of the schools, the buses, all
1230120	1237120	the public services, the way things don't work, the way the zoning is the most absurd
1237120	1244120	in the country. There was a house I was looking to buy where you couldn't build access into
1244360	1251360	the garage, and Gavin Newsom, who is the Lieutenant Governor of California at the time, said he
1251360	1256520	would help me get a garage access permit. Again, it's not clear that's what the Lieutenant
1256520	1260200	Governor of the fifth largest economy in the world should be doing, but he said he knew
1260200	1267200	how to do this in San Francisco and it was circa 2013. You needed to get it, you needed
1268080	1272320	to get the neighbors to sign off, which was maybe doable. Then you needed to go to the
1272320	1277560	Board of Supervisors because you had to build a staircase, and it was a public walkway,
1277560	1281200	and the whole public had to comment. Nobody knew what happened then. Then even harder,
1281200	1286480	a tree had grown where the driveway was supposed to be, and you needed a tree removal permit.
1286560	1292280	This was the sort of thing that you would never get. You can describe all this as crazy
1292280	1299280	left-wing ideology, but I think it's more like really, really deep corruption. This
1299280	1305280	is in a way the San Francisco problem, it's the California problem. The analogy I have,
1305280	1310560	if you want to think about the economy of California, in some ways it's analogous to
1310600	1317600	Saudi Arabia. You have a very mismanaged state government, there's a lot of insane ideology
1319920	1325640	that goes with it, but you have these incredible gushers called the big tech companies, and
1325640	1332640	then there's a way the super insane governance is linked to the gold rush of the place. There's
1335960	1340240	some point where it'll be too crazy even for California, but California can get away
1340320	1343480	with a lot of stuff, you wouldn't get away with elsewhere. San Francisco, my judgment,
1343480	1349480	had gone a little bit too far. Maybe the AI thing is they found one more giant gusher.
1349480	1352320	You don't have any Saudi money in your fund, I hope.
1352320	1357320	Virtually none. Just in case. Here's a different question though, because it gets to the politics
1357320	1363820	of this, which is it seems like a shift inside Silicon Valley, and a shift in terms of even
1363820	1370820	the way the companies are managed in a political dimension. You were very outspoken, obviously,
1372580	1378580	you supported President Trump in the last go round. I want to get to that part too,
1378580	1383220	but I want you to speak first to the shift in the valley, at least what seems like a
1383220	1389060	shift perception wise from being a very progressive place to maybe less so. Maybe not, maybe it's
1389060	1393780	just the large summers that I spoke this afternoon, and he said there's 10 people he thinks
1393780	1398340	are very loud on Twitter, and that's why the world thinks that between David Sachs
1398340	1404540	and a bunch of other people, and Elon Musk, that's not representative, but I think you
1404540	1406420	may have a different view.
1406420	1413420	Well, I don't think you'll get a majority of tech people to support Trump over Biden
1415740	1419500	or anything like that. I think you'll get way more than you had four or eight years
1419540	1425540	ago, so I don't know if you're measuring a relative shift or an absolute number. Those
1425540	1430940	are probably two different measures on that, but I would say that if we ask a very different
1430940	1437060	question about, let's say, extreme wokeness, or I don't even know what you're supposed
1437060	1444060	to call it, there is probably a broad consensus among the good tech families in Silicon Valley,
1449660	1456660	founders, startup CEOs, people across a pretty broad range that it's gone way too far. I
1456660	1462340	talked to a lot of these people, a lot of them are, I'd say, more centrist Democrats,
1462340	1467980	but it is just, we need to have a secret plan to fight this, and what they tell me behind
1467980	1474300	closed doors is way, way tougher than what they dare say in public, and so it is like,
1474300	1478460	we need to have a plan to hire fewer people from San Francisco, because that's where the
1478540	1482540	employees are the crazy. So if you want to have a less woke workforce, we need to, we're
1482540	1487540	going to have targets about how we steadily move our company out of San Francisco specifically,
1487540	1492540	and yeah, these are the sort of conversations that I've...
1492540	1497540	And do you agree with this? And by the way, let me just read, you probably know Alex,
1497540	1503740	Alex Wang, Scale AI CEO, who said that he's put together what he calls a merit-based
1503740	1508500	hiring program. He said he's getting rid of DEI, says hiring on merit will be a permanent
1508500	1511820	policy at scale. It's a big deal whenever we invite someone to join our mission, and
1511820	1514980	those decisions have never been swayed by orthodoxy or virtue signaling or whatever
1514980	1520820	the current thing is. I think of our guiding principle as MEI, Merit Excellence and Intelligence.
1520820	1524820	Bill Ackman went on to say that he thinks DEI is actually inherently a racist and illegal
1524820	1525820	movement.
1526820	1533820	Yeah, I, again, my feel for, there aren't that many people who are willing to say what
1533820	1538820	Alex says, but I think there are an awful lot of people who are pretty close to thinking
1538820	1547820	this, that there were ways they leaned into the DEI thing. It was like an anti-Trump thing.
1547820	1553820	It was like a, everything was sort of polarized around Trump for the last four years of his
1553820	1558820	campaign, so you have to demonstrate that you're anti-Trump by being even more pro-DEI.
1558820	1564820	That's, of course, not necessarily a logical thing, but yes, people somehow ended up in
1564820	1573820	this place that was very different. There always are questions what drove the DEI movement,
1573820	1582820	the wokeness in these companies, and it probably is over-determined. There's a bottom-up,
1582820	1586820	woke millennial people who were brainwashed into DEI in their colleges. That's sort of
1586820	1593820	the bottom-up theory. There's sort of a, I don't know, there's sort of a cynical corporate
1593820	1598820	version where this is, you know, the leadership of the company either believed it or used
1598820	1604820	it as sort of a, as a way to manage and control their companies in certain ways. You know,
1604820	1609820	the part that I always feel is a little bit underestimated is there was probably also
1609820	1617820	a top-down level from a government regulatory point of view where, you know, if you don't
1617820	1625820	do DEI, there is some point where you do get in trouble. You know, I don't know.
1625820	1629820	This is part of the ESG movement now. I mean, look, we talked about ESG here for a long time.
1629820	1633820	There was an ESG movement, and then there were probably all these governmental versions.
1633820	1637820	And so, I don't know, this would be probably, if my candidate for the company in Silicon
1637820	1644820	Valley is still probably the most woke, would be something like Google. And it's less woke
1644820	1648820	than it was two, three years ago, but in some ways, you know, they have a total monopoly
1648820	1653820	in search, and so there's sort of some way in which, you know, if wokeness is a luxury
1653820	1659820	good, like, you can afford it more if you're a monopoly than if you're not. And then the
1659820	1665820	problem for Google as a pretty big monopoly is that it's always going to be, you know,
1665820	1669820	subject to a lot more regulatory pressure from the government. And so if you have something
1669820	1679820	like the Gemini, the Gemini AI engine, you know, and it's sort of this comical, absurdist
1679820	1684820	thing where it generates these black women Nazis, you know, and you're supposed to find
1684820	1689820	famous Nazis, and then the diversity criterion gets applied across the board, and so it just
1689820	1693820	generates fake black women who are Nazis, which is, you know, a little bit too progressive,
1693820	1700820	I think. But then if you think of it in terms of this larger political context, Google will
1700820	1706820	never get in trouble for that. The FDC will never sue them for misinformation or anything
1706820	1713820	like that. That stuff does not get fact-checked. You don't really get in trouble, and the
1713820	1719820	FDC will never get in trouble. And you probably even get some protection where, okay, you
1719820	1725820	know, you are, you're going along with the woke directives from the ESG people or the
1725820	1729820	government. Maybe you overdid it a little bit, but we trust you to be good at other
1729820	1734820	things. So there may be a very different calculus if you're sort of a large quasi-regulated
1734820	1737820	monopoly. Let me ask you about large quasi-regulated monopolies and also concentration, but I
1737820	1741820	want to read you, this is something you actually wrote in your book 10 years ago about Google,
1741820	1745820	and it being a monopoly. You said, since it doesn't have to worry about competing with
1745820	1751820	anyone, it has wider latitude to care about its workers, its products, and its impact on
1751820	1755820	the wider world. Google's motto, don't be evil, is in part a brand employee, but it's also
1755820	1760820	a characteristic of a kind of business that's successful enough to take ethics seriously
1760820	1764820	without jeopardizing its own existence. In business, money is either an important thing
1764820	1768820	or it's everything. Monopolists can't afford to think about things other than making money.
1768820	1774820	Non-monopolists can't. In a perfect competition, a business is so focused on today's margin that
1774820	1778820	it can't possibly plan for a long-term future. Only one thing can allow a business to
1778820	1786820	transcend the daily brute struggle for survival, monopoly profits. Were you writing in favor
1786820	1791820	then of the monopoly idea or against?
1792820	1800820	My book was giving you advice for what to do, and from the inside, you always want to do
1800820	1808820	something like what Google did. If you're starting a company, competition is for losers.
1808820	1814820	Capitalism and competition, people always say they're synonyms, I think they're antonyms,
1814820	1819820	because if you have perfect competition you compete away all the capital. If you want to
1819820	1825820	have Darwinian competition, beard, red and tooth and claw, you should open a restaurant.
1825820	1829820	It's like an awful, awful business. You will never make any money. It's perfectly competitive
1829820	1837820	and completely non-capitalist. From the inside, you want to always go for something like
1837820	1848820	monopoly. In other parts of my book, I also qualify it that there are dynamic monopolies
1848820	1852820	that invent something new, that create something new for the world, and we reward them with
1852820	1859820	patents or things like that that they get. Then at some point, there's always a risk that
1859820	1865820	these monopolies go bad, that they become like a troll collecting a toll at a bridge,
1865820	1869820	that they're not dynamic, and that they become that fat and lazy.
1869820	1873820	Are we there yet? Lena Kahn, if she was sitting here, would say we got there a long time ago.
1873820	1889820	I think, man, all these ways I would, if I had to defend Google, and I would still say
1889820	1906820	that it's still better run, even in its silly woke way, even in a slightly troll-like toll
1906820	1913820	collecting way, than whatever a completely destructive path Lena Kahn would have for the
1913820	1917820	company. We're still getting more good from Google as it is.
1917820	1921820	Do you feel the way about all the big tech companies? You have lots of investments in smaller
1921820	1925820	companies that need to access the app store on Apple's phone. Do you say to yourself that
1925820	1931820	it should be opened up? Do you say they created the store, therefore they should control the
1931820	1934820	store? How do you think about that kind of stuff?
1934820	1941820	There are a lot of complicated questions on all these things. They're much bigger. We're
1941820	1946820	in a very different place from where you were 10 years ago on these things. I still worry
1946820	1951820	that in many cases the remedy is worse than the disease. A lot of these businesses are,
1951820	1958820	if you have a natural monopoly, the remedy is not to break it up. It's like a utility company
1958820	1963820	and then the remedy is to regulate it or tax it or do various things like that. If you
1963820	1971820	could convince me that we are a static as a utility company, then maybe the remedy is to do
1972820	1981820	something like that. To the extent that the real monopoly problems in our society are much
1981820	1989820	more these old economy, racket-like companies. I spent three months during COVID in Maui and
1989820	1997820	there's a single hospital in Maui. The Hawaiian Island, there's this line, if you have a pain,
1997820	2004820	get on a plane because it's a local racket, it's completely mismanaged. That's probably
2004820	2011820	the really dysfunctional monopolies in our society are these pretty big ones that control
2011820	2020820	these local markets that are 100% troll collecting. I think even with all my misgivings about
2021820	2028820	something like Google, it's a vastly morally superior place to your local hospital.
2028820	2033820	How do you feel about it in the context of AI, which is to say that if you believe AI is this
2033820	2037820	transformative product and that there's only going to be three or four players who are going to
2037820	2042820	control all of these models, whether it be Google or Microsoft with open AI or maybe an
2042820	2048820	Amazon along the way. I don't know where you think Apple is going to land in this conversation.
2049820	2053820	Is that a good thing or a bad thing? Also, I would argue, even as an investor who looks at
2053820	2059820	startups, how do you even look at startups down the line that could effectively get competed away
2059820	2064820	because I'm going to build my app with AI and I'm just going to copy what you've made?
2064820	2071820	Well, I think it's in a very different place from the consumer internet type businesses.
2071820	2077820	There's been a history, they've been around for decades. If I had to make the anti-Google
2077820	2084820	experiment, it would be, they won at Search in 2002 and there's been no serious competition
2084820	2095820	for 21, 22 years. They beat Microsoft and Yahoo in 2002 and then it's somehow very hard to disrupt
2095820	2104820	that. Then I think the AI piece is extremely fluid, it's extremely hard to know, it's very hard
2104820	2111820	to know where the value is. As I said, it's like the obvious monopoly right now is Nvidia
2111820	2122820	but it doesn't seem that durable. If you thought Nvidia is as durable as Google, the stock's really cheap.
2122820	2130820	You should just buy it like crazy. The market pricing is telling you they have a temporary
2130820	2137820	monopoly but it's not very robust and then on the level of the software companies, I worry that
2137820	2146820	OpenAI has a lead, all sorts of other people are going to be able to catch up pretty quickly
2146820	2152820	and if you have three or four doing the same thing, that's a lot more than one.
2152820	2155820	Very, very different set of economics.
2155820	2158820	I want to pivot the conversation again because another investment that you've made
2158820	2164820	and been very public about is Bitcoin. You have remained a very big bull.
2164820	2170820	You have come out publicly and you said that enemy number one to Bitcoin is the sociopathic
2170820	2175820	grandpa from Omaha that you described as Warren Buffett.
2175820	2179820	Can you tell me what you were thinking when you said that?
2180820	2197820	It got a lot of laughs so somehow people, it probably had some kind of a nerve but it was in a 2022
2197820	2204820	Bitcoin convention talk I gave and there were three separate enemies.
2204820	2209820	There was Jamie Dimon, Larry Fink who is no longer an enemy by the way.
2209820	2214820	He sort of shifted but maybe I can say that Larry Fink things too.
2214820	2225820	Then there was Warren Buffett and the rough context was, my sort of political sociological analysis
2225820	2231820	was the cryptocurrencies were, it was a revolutionary youth movement but for them to really take over,
2231820	2237820	you needed, it couldn't just be a student uprising like 1968.
2237820	2244820	You needed to get the rest of the society on board and as long as the old people were going to sit on their hands
2244820	2250820	that was the big blocker for cryptocurrencies to go to the next level.
2250820	2252820	Are you still convinced?
2252820	2268820	I think it's gotten partially unlocked with the Bitcoin ETF but then probably the part where I'm less convinced of
2268820	2275820	is this question of the sort of ideological founding vision of Bitcoin or these cryptocurrencies
2275820	2285820	as sort of a cipherpunk crypto-anarchist libertarian anti-centralized government thing.
2285820	2288820	Isn't that what got you interested in the first place?
2288820	2295820	That's what I thought was terrific about it and then the question is does it really work that way
2295820	2298820	or has that thread somehow gotten lost?
2298820	2305820	And so when people in the FBI tell me that they'd much rather have criminals use Bitcoin than $100 bills
2305820	2310820	it suggests that maybe it's not quite working the way it was supposed to.
2310820	2312820	Have you sold any of your Bitcoin?
2312820	2314820	I still hold some.
2315820	2329820	There are all these ways. I didn't buy as much as I should have and I'm not sure it's going to go up that dramatically from here.
2329820	2330820	From here?
2330820	2336820	Yeah, I think we got the ETF edition and I don't know who else buys it quickly from here.
2336820	2339820	It's an interesting investment advice.
2340820	2345820	That actually surprised me because I thought you were still all in.
2345820	2348820	I still have a small position.
2348820	2358820	It probably still can go up some but it's going to be a volatile bumpy ride and I had a dual reason.
2358820	2367820	One was the sort of ideological decentralized future of computing world that I really do believe and really believe would be better
2367820	2374820	and it seemed like the perfect vehicle for that for such a long time and I am just much less convinced of that.
2374820	2375820	Interesting.
2375820	2383820	So maybe Larry Fink with the BlackRock ETF surrendered to the forces, the anti-ESG forces
2383820	2390820	or maybe it's more like Bitcoin's been co-opted by them and I worry it was more the latter.
2390820	2394820	Okay, different question. SpaceX, that's another big investment for you.
2394820	2399820	After ousting Elon Musk you became friends with him again.
2399820	2402820	What does that look like to you in the future?
2402820	2410820	Is that going to be the biggest investment you've ever made when this is all said and done?
2410820	2424820	Man, I'm always sort of hesitant to sort of pitch these companies too much.
2424820	2434820	But I think there were sort of a lot of different things that came together.
2435820	2443820	When Elon was building both Tesla and SpaceX in the 2000s, people thought he was just really, really crazy
2443820	2452820	and I think even a lot of those of us who worked with him at PayPal, there was this PayPal book that David Sacks and I thought of writing
2452820	2461820	and the Elon chapter was, I think, entitled something like the man who knew nothing about risk or something like this
2461820	2469820	and there were all these crazy Elon stories I could tell and then if one of the two companies had succeeded
2469820	2475820	you would say, well maybe he still got really lucky but when two out of two companies that people thought were completely
2475820	2484820	hair-brained in the 2000s, when they both succeed, you have to somehow reassess it and somehow the rest of us
2484820	2490820	somehow are too risk-averse or there's something about risk he knows that we don't or something like this
2491820	2494820	and so yes, I think there's...
2494820	2496820	You didn't invest in Tesla?
2496820	2504820	We did not invest in Tesla. We should have invested in that one. It was public at a much earlier date
2504820	2510820	and then there's always sort of a self-imposed limitation that we tend not to invest in public companies
2510820	2515820	there's 20% of the venture fund you could but that was sort of the...
2515820	2521820	I think they started Tesla in 2002, it went public in 2010
2521820	2530820	I remember test driving the Model S in October 2012 and it was just, wow this is just a terrific car
2530820	2536820	and I think the correct thing would have been to wait till they came out with it and then nobody liked it
2536820	2542820	it was such a hated stock shorted by everybody and you could have just waited 10 years
2542820	2547820	and just bought the shares in the public market and you would have made 10 times your money in 18 months
2547820	2552820	and 100 times in the next 6, 7, 8 years
2552820	2562820	and then there was something also about SpaceX that looked like it was a very crazy, hair-brained idea
2562820	2568820	and yet it was very straightforward, it was the rocket launch business
2569820	2573820	the government will pay or the customers pay for the vehicles before you build them
2573820	2578820	so it's actually cash flow positive, there's some money they needed for expansion
2578820	2583820	but it was basically a cash flow positive business, it was a weird investment in 2008
2583820	2589820	they didn't need any of the money but there was some NASA or government rule where they needed outside investors
2589820	2595820	and so they were forced to take investors and then we were on good enough terms that we did it
2596820	2599820	if you had been a Tesla shareholder we've all been reading about it
2599820	2603820	would have you paid him the big compensation package?
2603820	2613820	I would have, well I think the nuanced answer is I would have voted in favor of the compensation package
2613820	2619820	because you would know that if it failed the share price would have gone down a lot the next day
2619820	2623820	because people would wonder whether Elon would quit and that would be bad for the company
2623820	2628820	so whether you believe in the package or not the rational thing would be that you should vote for it
2628820	2634820	and then if you think it's a bad idea maybe you sell your shares after you get a pop or something like this
2634820	2640820	so that's the obvious game theory on why Elon was going to win that vote no matter what
2640820	2647820	and it was really crazy that we listened to people in the media and I'm sure yourself
2647820	2651820	but we're all saying it was a hair-brained thing and the shareholders were all going to vote against it
2651820	2656820	and if you just did the basic analysis it was obvious that Elon was going to win the vote
2656820	2658820	regardless of what the shareholders actually were
2658820	2660820	What did you think of him investing in X?
2660820	2665820	By the way X is what he wanted PayPal to be, did you give him money for that?
2670820	2678820	We didn't do anything on the Twitter one, we didn't do anything on the current XAI company
2678820	2682820	I guess there's a lot of different things that have X in the name with Elon
2690820	2702820	I think it was an incredibly, I do think we need a broader surface area for debate in our society
2702820	2707820	and so I think obviously there are all these very complicated trade-offs between
2707820	2714820	how much speech do you suppress, how much good speech are we suppressing, how much bad speech are we allowing
2714820	2717820	how do you get those trade-offs right, very, very hard to do
2717820	2722820	My judgment is we should have just a lot more surface area for debate discussion
2722820	2729820	and I think what Elon did with Twitter was I think extremely important
2729820	2732820	and I support it as an ideological project
2732820	2740820	I worry about it as a financial thing, I don't know if that works
2740820	2746820	We've looked over the years, we've looked over and over again at starting some kind of media company
2746820	2753820	and there's always sort of this thought, can't you do something else in the sort of right of center media space
2753820	2759820	and does it have to all be as lame as Fox News, isn't there an opening to do something else
2759820	2766820	and then the question you always have to ask is it the Murdoch family that keeps it lame
2766820	2770820	Why do you think it's lame?
2770820	2773820	I think it's lame because they're controlled by the advertisers
2773820	2779820	and there's a very narrow limit on what they can do
2779820	2786820	and then the Elon question with Twitter was are you really allowed to do this and keep the advertisers
2786820	2788820	and so that's where...
2788820	2790820	Would you make it harder?
2790820	2796820	It's super important what Elon did as a non-profit but it's going to be tough as a best...
2796820	2801820	What about Truth Social?
2801820	2805820	They have a few other problems they have to solve first
2805820	2807820	Now it's something you'd invest in
2807820	2810820	You get your head around the $6 billion valuation
2810820	2817820	If I wanted to secretly funnel money to the Trump campaign and get around the campaign limitations
2817820	2820820	so the stock price goes up and you can sell some stock and fund this campaign
2820820	2822820	that might be a reason to invest
2822820	2827820	Do you think people are doing that?
2827820	2833820	They probably don't think of it in quite that literal term but maybe that's what's going on
2833820	2837820	Have you talked to people in your realm who have said hey?
2837820	2846820	Nobody's said that but I suspect a lot of the investors are going to vote for Trump
2846820	2851820	They're thinking about it at least on some subconscious, not articulated level
2851820	2854820	I want to talk a little more about Trump in just one more second
2854820	2857820	but I want to ask you one last related social media question
2857820	2861820	which is the search in general was here in Aspen
2861820	2864820	and I think you've probably seen in the last couple of weeks that he came out
2864820	2871820	and genuinely believes that social media and the Facebooks of the world really
2871820	2878820	have done a real disservice to young people in the country
2878820	2884820	and I just wonder what you think of that as somebody who invested early in Facebook
2884820	2894820	I can't say that he's 100% wrong
2894820	2902820	The place where I always push back on is that I feel it's too easy to turn tech
2902820	2906820	or the social media companies into the scapegoat for all of our problems
2907820	2914820	There's some kind of an interesting critique one can make of the tech companies
2914820	2918820	and if you ask how many of the executives in those companies
2918820	2921820	how much screen time do they let their kids use
2921820	2924820	and there's probably sort of an interesting critique one could make
2924820	2925820	What do you do?
2925820	2927820	Not very much and I think that's very...
2927820	2929820	What's not very much?
2929820	2931820	An hour and a half a week
2931820	2933820	Something like that
2933820	2934820	How old are your kids?
2934820	2936820	Three and a half, five years
2936820	2938820	Three and a half and five years old
2942820	2950820	If I were to make the anti-tech argument it's that there are probably a lot of people in tech
2950820	2953820	who do something quite similar for their own families
2953820	2956820	and there's some questions that that might lead you to ask
2956820	2958820	And then on the other hand
2960820	2969820	I don't think this is the main cause for all the different types of social dysfunction we have
2969820	2973820	and it's maybe it's a 15%, 20% cause
2973820	2979820	There's sort of a lot of other things that have gone super haywire in our society
2979820	2986820	and by putting all the blame onto this, onto tech or onto one company
2986820	2989820	you are really ignoring a lot of other stuff
2989820	2991820	We could do a whole panel on this but one related question
2991820	2993820	because we haven't mentioned it, TikTok
2993820	2996820	Do you think of TikTok as a national security threat?
2999820	3002820	Yeah, it's a very...
3002820	3004820	There's something very strange going on
3004820	3011820	Obviously the TikTok algorithms for the US are very different from the ByteDance algorithms in China
3011820	3013820	Would you shut it down in this country?
3017820	3022820	I probably would lean towards a tougher response
3022820	3024820	I think just to shift from the normative to the...
3024820	3026820	I don't think we're going to do anything
3026820	3029820	I met the TikTok CEO last summer
3029820	3033820	and I was the Singaporean guy, the TikTok CEO
3033820	3037820	and I told him he didn't need to worry about it being shut down in the US
3037820	3039820	and maybe I'm wrong but I think...
3039820	3040820	Because you know something?
3040820	3045820	Because we are incompetent and slow and bureaucratic
3045820	3048820	and we will never get our act together in dealing with the problems of China
3048820	3050820	until the day they invade Taiwan
3050820	3053820	and then it will be shut down within 24 hours
3053820	3058820	and since I think there's a 50-50 chance that China will invade Taiwan in the next five years
3058820	3063820	my advice to the TikTok CEO was you should take all your people and computers
3063820	3069820	and get them out of China because once Taiwan gets invaded it'll be too late
3069820	3072820	so that's my advice but you don't need to worry about us doing anything before then
3072820	3075820	and then his somewhat...
3075820	3080820	I'm not sure good or worrisome answer was that they had studied World War I and World War II very carefully
3080820	3085820	and there were a bunch of companies that were able to trade with all sides in those wars
3085820	3090820	By the way, that implies that he also thinks that China is going to invade Taiwan
3090820	3091820	He did not...
3091820	3094820	You know, again I didn't frame it deterministically
3094820	3097820	I said 50% chance, five years
3097820	3100820	We are over time but we're going to keep going just for a little bit
3100820	3103820	because I promise you we're going to talk a little bit about politics
3103820	3106820	and I want to talk about your own politics, your own personal politics
3106820	3114820	You were very vocal and outspoken about supporting who is now the former president the last time
3114820	3119820	You have been less outspoken this time
3119820	3121820	We're all going to watch the debate tonight
3121820	3125820	So before we can get into the lessons and everything that you've learned
3125820	3128820	and all of your prior experience
3128820	3131820	are you planning to support the president this time?
3131820	3133820	You know, I'm...
3133820	3135820	I'm the former president I should say
3135820	3137820	You know, you hold a gun to my head
3137820	3141820	I'll vote for Trump, I'll still...
3142820	3144820	I'd rather have him vote than Biden
3144820	3147820	I'm not going to give any money to his super PAC
3147820	3152820	I'm going to be less involved in all these ways
3152820	3155820	And man, look, it is...
3155820	3159820	And then I don't know, I think Trump will win
3159820	3162820	I think he will win quite solidly
3162820	3165820	I don't think it's going to even be close
3165820	3169820	And then my pessimistic look ahead function is
3169820	3173820	after he wins there will be a lot of buyer's remorse
3173820	3175820	because the elections are A-B tests
3175820	3178820	You know, if you asked me to make a pro-Trump argument
3178820	3181820	I wouldn't, but I can probably come up with anti-Biden arguments
3181820	3183820	and Biden is not going to make a pro-Biden argument
3183820	3185820	he's going to make anti-Trump arguments
3185820	3188820	and it's these two different hate factories
3188820	3190820	that we have targeted at each other
3190820	3192820	and that's the way the politics work
3192820	3195820	and my judgment is Trump will easily win that
3195820	3197820	but yeah, the election is a relative choice
3197820	3199820	the post-election is absolute
3199820	3202820	and then it'll be like, you know, if Biden wins
3202820	3204820	like, how did we get this senile old man
3204820	3207820	and if Trump wins, it'll be...
3207820	3209820	Can I just ask you this?
3209820	3212820	It's still like this clown show, whatever people will say
3212820	3214820	I'm not going to ask you to make the pro-Trump argument
3214820	3216820	That's sort of...
3216820	3219820	But let me ask you about what I imagine is your anti-Biden argument
3219820	3221820	I look at the last four years and say to myself
3221820	3224820	if you were in Silicon Valley and you owned stock
3224820	3226820	and these tech companies over the last four years
3226820	3228820	you unfortunately did nothing but go up
3228820	3230820	and I know...
3230820	3233820	And I just... I wonder if you can make the argument
3233820	3235820	because we can talk about Lina Khan
3235820	3238820	and we can talk about regulations and potential taxes
3238820	3240820	and all sorts of things
3240820	3242820	but it's hard for me to look at the last four years and say
3242820	3244820	especially if I was sitting
3244820	3246820	I would imagine in your seat and say
3246820	3248820	this was a terrible travesty
3248820	3250820	but maybe I don't understand
3250820	3252820	Well, I mean, I don't know
3252820	3254820	this may not be believable to you
3254820	3256820	but I...
3256820	3258820	I don't think it's...
3258820	3260820	the only thing I care about
3260820	3263820	is whether the country is good for the tech billionaires
3263820	3266820	and I think there are
3266820	3268820	a lot of people who have not experienced
3268820	3270820	the last three or four years this way
3270820	3272820	I think one of the things Carvel said in the earlier
3272820	3274820	presentation just before
3274820	3276820	this one that I thought was quite good
3276820	3278820	was there's been a shocking loss of support
3278820	3281820	by the Democrats in the 18 to 35 year voters
3281820	3283820	and it's because you can't get on the housing ladder
3283820	3285820	you can...
3285820	3287820	you know, the college debt's overwhelming
3287820	3289820	you can never get started
3289820	3291820	and so there's sort of a sense that...
3291820	3293820	You think he'll be able to fix that?
3293820	3295820	I don't...
3295820	3297820	I think it's...
3297820	3299820	it's just an up-down referendum
3299820	3301820	on the incumbent at this point
3301820	3303820	and, you know,
3303820	3305820	my guess is that the sense is
3305820	3307820	Biden's definitely not going to fix it
3307820	3309820	and his time will run out and that's...
3309820	3311820	and then...
3311820	3313820	this is where I'm not overly excited
3313820	3315820	I don't think Trump will
3315820	3317820	particularly fix it but look
3317820	3319820	the place where people, you know
3319820	3321820	at this...
3321820	3323820	in the audience here I think are just maximally
3323820	3325820	divergent
3325820	3327820	yes, the stock market has been great for people here
3327820	3329820	you're in this wonderful
3329820	3331820	bubble in Aspen where it's like
3331820	3333820	I know Clinton is still president
3333820	3335820	and it's 1995
3335820	3337820	and everything
3337820	3339820	is just getting better every day
3339820	3341820	in every way and it's like some new age
3341820	3343820	chant if you just say that to yourselves
3343820	3345820	it's true
3345820	3347820	and then
3347820	3349820	the...
3349820	3351820	the part of the Trump
3351820	3353820	statement that I think was
3353820	3355820	the most offensive
3355820	3357820	thing he said
3357820	3359820	it was very offensive not just
3359820	3361820	to Democrats and to Republicans
3361820	3363820	and especially to Silicon Valley
3363820	3365820	was make America great again
3365820	3367820	because that was a pessimistic slogan
3367820	3369820	it was the most pessimistic slogan
3369820	3371820	a major presidential candidate
3371820	3373820	ever had because
3373820	3375820	what it says implicitly is this is no longer
3375820	3377820	a great country
3377820	3379820	and that's what you are never supposed to say
3379820	3381820	especially if you're a Republican
3381820	3383820	that's why the Bush people probably hate him
3383820	3385820	more than anybody in this audience
3385820	3387820	you know
3387820	3389820	and then
3389820	3391820	Silicon Valley was, you know
3391820	3393820	it's somewhat offensive to people in New York City
3393820	3395820	but the bankers on Wall Street don't really think
3395820	3397820	they're making the country a great place
3397820	3399820	so it's not personally offensive
3399820	3401820	it was personally offensive to Silicon Valley
3401820	3403820	and yet
3403820	3405820	I always think
3405820	3407820	there is this problem of stagnation
3407820	3409820	there is this problem we're stuck
3409820	3411820	there's a sense that
3411820	3413820	we're not progressing in all these ways
3413820	3415820	as a society as much as we have
3415820	3417820	I don't think Trump has all the answers
3417820	3419820	but I think
3419820	3421820	what I said in 2016 is
3421820	3423820	the first step
3423820	3425820	towards solving problems is to at least talk about them
3425820	3427820	what about the polarization part
3427820	3429820	the polarization part the uncertainty part
3429820	3431820	the questions about democracy
3431820	3433820	and the rule of law and the future
3433820	3435820	of a country and I think there's a lot of people
3435820	3437820	who worry about those things
3437820	3439820	sure those are all
3439820	3441820	those are all still
3441820	3443820	those are things you probably wouldn't worry about
3443820	3445820	if Biden was the president right
3445820	3447820	I feel the country is still very polarized
3447820	3449820	it's been getting more polarized
3449820	3451820	for decades
3451820	3453820	it was polarized against
3453820	3455820	Bork in the 80s
3455820	3457820	that was sort of a new crescendo in polarization
3457820	3459820	there was way Fox News was polarized
3459820	3461820	against the Clintons
3461820	3463820	and I don't know
3463820	3465820	it's always what's cause and effect
3465820	3467820	is the polarization causing the stagnation
3467820	3469820	or does the stagnation lead to the polarization
3469820	3471820	I don't think the polarization just happens
3471820	3473820	in a country where everything is gross
3473820	3475820	it's a tonal question
3475820	3477820	you come across a very sensible reasonable person
3477820	3479820	I think
3479820	3481820	there are people who hear
3481820	3483820	I'm sure disagree with you about
3483820	3485820	lots of different issues but
3485820	3487820	my question about tone
3487820	3489820	about the president and the tone of the president
3489820	3491820	by the way I should say
3491820	3493820	and I'm not speaking out of school
3493820	3495820	you also I would say by the way
3495820	3497820	you've been a Republican
3497820	3499820	for a long time now
3499820	3501820	public about that
3501820	3503820	you're also proudly gay
3503820	3505820	openly so
3505820	3507820	and I wonder if you can tie
3507820	3509820	you know
3509820	3511820	President Trump when he talks
3511820	3513820	about some of the issues around LGBT issues
3513820	3515820	in this country and other people
3515820	3517820	there are people in those communities
3517820	3519820	who say they don't feel safe about it
3519820	3521820	yeah
3521820	3523820	we can go through all these different
3523820	3525820	different versions of that
3525820	3527820	I think
3527820	3529820	there was never any thought of reversing gay marriage
3529820	3531820	or any of those things
3531820	3533820	by Trump
3533820	3535820	at least
3535820	3537820	and look
3537820	3539820	I think the
3539820	3541820	yeah there are all these ways
3541820	3543820	they're not the way
3543820	3545820	I would articulate these things
3545820	3547820	but
3547820	3549820	these sort of polite tone
3549820	3551820	there was
3553820	3555820	people had attempted to say
3555820	3557820	something's gone very wrong in our country
3557820	3559820	the house is on fire, it's burning to the ground
3559820	3561820	we are a society
3561820	3563820	in decline, stagnation
3563820	3565820	maybe
3565820	3567820	AI will save us
3567820	3569820	but this is the way people talk about AI
3569820	3571820	if it doesn't lead to this cornucopian growth
3571820	3573820	we're just completely going to be
3573820	3575820	buried by budget deficits
3575820	3577820	and debt
3577820	3579820	for decades to come
3579820	3581820	and I think
3581820	3583820	AI is a big thing
3583820	3585820	is it big enough to solve our budget deficit problem
3585820	3587820	I don't believe it is
3587820	3589820	we have a lot of these
3589820	3591820	problems and
3591820	3593820	at this point
3593820	3595820	extra politeness
3595820	3597820	is not quite
3597820	3599820	the thing
3599820	3601820	it was an inarticulate shriek for help
3601820	3603820	and look my sort of fantasy
3603820	3605820	in 2016 in supporting Trump
3605820	3607820	this was where I was completely delusional
3607820	3609820	this would be the way you start to have a conversation
3609820	3611820	and
3611820	3613820	and that's why
3613820	3615820	another reason why I'm
3615820	3617820	off-ramping I'd much rather have
3617820	3619820	the sort of conversation we had here
3619820	3621820	and if I lean in all the way to support Trump
3621820	3623820	it'll be all about that
3623820	3625820	and we can't talk about all these other things
3625820	3627820	which is the way we are going to substantively solve the problems
3627820	3629820	I want to thank you for this conversation
3629820	3631820	and for addressing all these issues
3631820	3633820	it really was a phenomenal discussion
3633820	3635820	awesome thank you so so much
3635820	3637820	thank you very much
3649820	3651820	you
