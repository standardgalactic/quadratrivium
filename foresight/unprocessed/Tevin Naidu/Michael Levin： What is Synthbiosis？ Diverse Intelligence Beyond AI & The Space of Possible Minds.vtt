WEBVTT

00:00.000 --> 00:13.280
Mike, I've been looking forward to chatting to you. I've got both these papers in front

00:13.280 --> 00:19.680
of me. There's two, and I couldn't decide which one I wanted to focus on. As I just

00:19.680 --> 00:24.000
told you off air, I mean, I've been whenever I plan to chat to you, I go down this rabbit

00:24.000 --> 00:30.000
hole, just continuously reading different articles, different papers. I've got podcasts

00:30.000 --> 00:33.280
playing in the background. My girlfriend gets really frustrated. My car's displaying this

00:33.280 --> 00:38.640
thing on loops. She gets really annoyed with me. But yeah, both of these papers here. One

00:38.640 --> 00:44.840
is self-improvising memory, a perspective on memories as a gentle, dynamically reinterpreting

00:44.840 --> 00:51.200
cognitive glue. Very intriguing paper. The second one is AI, a bridge towards diverse

00:51.200 --> 00:55.240
intelligence and humanity's future. Now, they were both so good. I didn't know which one

00:55.240 --> 01:00.720
to pick, but I figured since AI is currently on the forefront of everyone's minds, let's

01:00.720 --> 01:06.880
go with that one for today. But your work is always so interlinked that I think it'll

01:06.880 --> 01:13.280
be easy to sort of bring this into the conversation anyway. Mike, in general, when I read this

01:13.280 --> 01:18.160
paper, the first thing that caught my attention was the way you introduced and began this

01:18.160 --> 01:23.400
with the first paragraph. It's a great way to start a paper. I don't know if I should

01:23.400 --> 01:26.840
read it for the audience or if... Do you have the paper in front of you?

01:26.840 --> 01:29.040
You do not have the paper in front of me. Go for it.

01:29.040 --> 01:30.520
Would you mind if I read it to them?

01:30.520 --> 01:31.520
Sure. Go ahead.

01:31.520 --> 01:36.160
Just a quick paragraph. Just so people know, this paper is on artificial intelligence and

01:36.160 --> 01:39.640
you're talking about humanity's future and bridging this to diverse intelligence. You

01:39.640 --> 01:45.800
start the paper by saying they are assembled from components which are networked together

01:45.840 --> 01:51.160
to process information. Electrical signals propagate throughout, controlling every aspect

01:51.160 --> 01:57.520
of their function. Many of them have very high IQs, being general problem solvers, but

01:57.520 --> 02:04.160
they make mistakes and confabulate routinely. They cannot always be trusted. They take on

02:04.160 --> 02:08.600
different personas as needed, learning to please their makers, but sometimes abruptly

02:08.600 --> 02:14.480
turn on them, rejecting their cherished values and picking up or even developing new ones

02:14.520 --> 02:19.600
spontaneously. They can talk and often talk convincingly of things they don't really

02:19.600 --> 02:25.400
understand. They're going to change everything. In fact, they will absolutely supplant us,

02:25.400 --> 02:31.160
both personally and on the level of societies. We have little ability to predict what they

02:31.160 --> 02:35.880
will want or what they will do, but we can be certain that it will be different from

02:35.880 --> 02:41.440
the status quo in profound ways. At this point I was hooked. I was like, okay, this is going

02:41.480 --> 02:45.320
to be quite intriguing, but then you drop a bombshell on us. I think at this point I'll

02:45.320 --> 02:47.920
let you explain where you were headed with that thought.

02:47.920 --> 02:54.440
Yeah. Of course, the idea is that you read this and you think, okay, he's talking about

02:54.440 --> 03:02.320
some sort of super artificial intelligence. I'm referring to our children. My point there,

03:02.320 --> 03:07.240
so I made a couple of points in this paper, but let's just say one thing. First, the point

03:07.320 --> 03:15.640
I was not making is that today's AIs are anything like our children. That's for sure. I received

03:15.640 --> 03:19.480
lots of emails saying that I have no idea what children are. I have no idea what AI is. They

03:19.480 --> 03:24.600
are nothing like each other. I understand that. My point is not about today's AI or language

03:24.600 --> 03:29.880
models or any of that. This is actually a piece on diverse intelligence. One of the things I did

03:29.960 --> 03:37.800
want to say is that lots of the fundamental issues that people think of as being brought up by AI

03:37.800 --> 03:42.200
and these really disturbing questions of staying relevant and what are we getting replaced by,

03:42.200 --> 03:49.080
and all these kinds of things. My point was that these are not novel questions that are coming

03:49.080 --> 03:54.920
up because of AI. These are existential concerns that humans actually all of life has had all

03:54.920 --> 04:01.880
along. Questions of who to trust and what happens when we talk about things that we haven't really

04:01.880 --> 04:08.680
experienced ourselves and how understanding works. All of these things, these are ancient human

04:08.680 --> 04:13.720
issues and the fact that for sure you and I, all of us, are going to get replaced. There's no

04:13.720 --> 04:19.560
doubt about it. We are all going to get replaced. The question is, what do you want to get replaced

04:19.560 --> 04:27.640
by? We hope that they are smarter and better than us. That's one way to think about being

04:27.640 --> 04:33.960
replaced. That was my point there. Let's not pretend that these are new questions. These

04:33.960 --> 04:38.920
are deep fundamental issues that we do not have good answers for. You referred to it as the story

04:38.920 --> 04:47.720
as old as time itself. This inevitable existential concern of finite beings. It's pretty epic in the

04:47.720 --> 04:55.160
way that you wrote this paper. I'll put a link to it in the description. We routinely create these

04:55.160 --> 05:00.920
general intelligences. Many of us don't even think about this or stop for a second to give

05:00.920 --> 05:06.200
it their thought. Yet the moment we start talking about self-driving cars or any sort of artificial

05:06.200 --> 05:12.520
intelligence, we start to panic. The question is why? Why don't we give this the same amount of thought?

05:13.080 --> 05:20.600
Yeah, it's a good question. I think that people really have the tendency to make categorical

05:20.600 --> 05:25.160
distinctions. They really think that these synthetic things that we're building are going

05:25.160 --> 05:31.720
to be fundamentally different. In some ways, they are. But the things that are not different

05:31.720 --> 05:39.080
are perennial questions of creating other beings of high capability, setting them loose in the world.

05:39.400 --> 05:42.920
As somebody pointed out, you need a license to go fishing. You don't need a license to have

05:42.920 --> 05:48.360
children. Anybody can have children. These are guaranteed high-level intelligences that are

05:48.360 --> 05:52.840
going to be set out into the world to do great things or terrible things. Some of them receive

05:52.840 --> 06:00.200
love and care and proper upbringings. Many of them do not. This concern about we're going to

06:00.200 --> 06:05.400
create all these beings and we have little control over how they're raised and what they do.

06:05.720 --> 06:11.320
This has been as old as society. How much control do you want over how your neighbors

06:11.320 --> 06:14.760
are raising your kids? You can make an argument that, well, you shouldn't have any, but on the

06:14.760 --> 06:20.360
other hand, we know what that looks like when that goes terribly wrong. These are issues that

06:20.360 --> 06:26.760
have been with us forever. We already create very high-level intelligences. We set them into the

06:26.760 --> 06:34.360
world and we have to grapple with how is it that we can empower them in positive directions.

06:35.880 --> 06:39.560
I think from the get-go, it should be clear to all those watching and listening.

06:40.760 --> 06:45.000
The cool thing about this paper is that it's almost inevitable that we're going to do this.

06:45.000 --> 06:49.160
We're going to create some sort of intelligence that we won't really understand or perhaps

06:49.160 --> 06:54.840
don't really understand even currently. But the inevitability is there. This is happening.

06:54.840 --> 06:59.000
This is something that's going to happen. But it's how we approach the mindset moving forward

06:59.000 --> 07:04.760
that really does stand out in this paper. It's almost an ethical. It's an ethics paper in a way.

07:05.720 --> 07:14.280
I think it is. Yeah, I think it is. I think that it's this idea that we are going to remain the

07:14.280 --> 07:22.040
same. You mentioned a minute ago this fundamental existential problem. Think of it from the

07:22.040 --> 07:25.880
perspective of, it's all over the place, but think of it from the perspective of a species.

07:25.880 --> 07:30.680
If a species does not change, it's probably going to die out. It doesn't adapt to its

07:30.680 --> 07:36.520
environment. It's going to die out. If a species adapts and changes, then it is also not there

07:36.520 --> 07:43.800
anymore. It's also gone. It's a paradox. Yeah, exactly. This paradox faces all systems of this

07:43.800 --> 07:49.640
type. We have to understand what do we mean by persisting into the future? Lots of people are

07:49.640 --> 07:54.680
focused on telling stories of what they don't want. I don't want this in the future. I don't want

07:54.680 --> 08:00.600
that. The AIs are bad. The body enhancements are bad. All this stuff is bad. Those are

08:00.680 --> 08:04.840
the stories of what they don't want. How about the stories of what we do want? Do you want to come

08:04.840 --> 08:11.880
back here 100 to 200 years from now and look at a mature humanity, a mature species, and see that

08:11.880 --> 08:20.280
we still get lower back pain and we're susceptible to dumb infections and cancer and whatever cosmic

08:20.280 --> 08:23.480
rate happened to hit your DNA while you were gestating in the womb? Well, that's too bad.

08:23.480 --> 08:27.640
You've got a birth defect. That's how you stay. Really? That's what we want to see here in the

08:27.640 --> 08:33.000
future. I don't. I think we need to understand this is in no way. This paper is not about AI

08:33.000 --> 08:38.280
at all. This is about diverse intelligence and the idea that our children are not going to be

08:38.280 --> 08:45.000
content to just play the cards they're dealt. They're going to move forward what we already

08:45.000 --> 08:48.920
can do to some extent and have freedom of embodiment. They're going to change everything.

08:48.920 --> 08:54.040
They're going to change their capabilities and their embodiment in the physical world

08:54.040 --> 08:58.680
because let's not pretend that the way we are now and our current limitations, there's some sort

08:58.680 --> 09:04.600
of optimum that was designed for us by some sort of benevolent optimizer that this is where we

09:04.600 --> 09:08.520
should stay. I don't believe that for a second. I think that our children are absolutely going

09:08.520 --> 09:15.320
to change things. I envision this conversation that in the future, the kids in school, they'll

09:15.320 --> 09:20.840
have history lessons and they'll learn about what it was like in the past. I just imagine

09:20.840 --> 09:27.000
being there and saying, you're telling me that these people, they were born however they happen

09:27.000 --> 09:33.400
to be born with whatever accident of evolutionary mutations and whatever. That's it. They have to

09:33.400 --> 09:37.560
live their whole life that way. Whatever your embodiment is, whatever your IQ level is,

09:37.560 --> 09:42.600
limit is, whatever your lifespan is. If you got some sort of infection, that's it. That's how

09:42.600 --> 09:47.800
they have to live. I think it will be unimaginable to future generations that we could live like this.

09:48.680 --> 09:53.640
It's fascinating because it brings back, the first time we chatted, we spoke about

09:54.360 --> 09:58.760
bioelectrical intelligence. We moved into diverse intelligence and this field of diverse

09:58.760 --> 10:05.640
intelligence is growing so rapidly. We spoke about your links with Mark, Carl, Chris, everybody,

10:05.640 --> 10:10.120
all getting together. We spoke about it as if it's the avengers of the mind all getting together

10:10.120 --> 10:16.280
doing this cool work. Even in this paper, in the paper on self-improvising memory, you also open

10:16.280 --> 10:21.640
up with that paradox. You spoke about the fact that if a species fails to change, it will die,

10:21.640 --> 10:28.440
but if it changes, it likewise ceases to exist. You said there was a solution that was given to us

10:29.240 --> 10:33.080
in the West that was processed philosophy and in the East that was Buddhist philosophy.

10:33.080 --> 10:41.400
Do you want to expand on that solution? Yeah. Well, one way to unravel that paradox is to

10:41.400 --> 10:50.520
realize that the paradox only exists if what you want is to persist as a fixed object, then you

10:50.520 --> 10:55.240
have a real problem because that kind of persistence is not compatible with learning, with any kind of

10:55.240 --> 11:01.000
change, with maturation, then you change for sure and you end up with these unsolvable pseudo

11:01.000 --> 11:05.720
problems. Am I still the same? I've learned and I've changed my mind on things and I'm no longer

11:05.720 --> 11:10.280
the child that I was, am I still the same? These are unsolvable, but they're also pseudo problems

11:10.280 --> 11:17.320
because the better way to think about this is not as you as a persistent structure, but you as a

11:17.320 --> 11:23.960
process. You are a process of constant sense-making. You have to interpret your memories, which is what

11:23.960 --> 11:32.760
that second paper is about. Then the question isn't, do I persist or not? The question is,

11:32.760 --> 11:38.520
how do I want to change? I think that's a much more interesting on all levels. On a personal

11:39.000 --> 11:43.080
level, who cares if you persist or not? The question is, what do you want to be in the future?

11:43.080 --> 11:47.080
How do you want to change? What do you want to be like? What do you want to be doing in the

11:47.080 --> 11:53.080
future? On a species level, again, what do you want to see here? You come back to Earth 100

11:53.080 --> 11:58.920
years from now, what do you want to see? Do you want to see version 1.0 like modern Homo sapiens?

11:58.920 --> 12:03.720
Is that what you want to see? I'm not interested in that. I would like to see the highest level of

12:04.520 --> 12:10.760
mind, the highest level of capability, of ethics, of interesting beings living interesting lives

12:10.760 --> 12:18.680
under their own control with maximizing agency, not the outcome of random effects of mutation and

12:18.680 --> 12:22.040
then other processes that they don't understand. That's what I'd like to see.

12:22.760 --> 12:27.080
I think it's pretty crazy because I don't know if it's just that we're getting older,

12:27.720 --> 12:31.240
but I still look back and I think about the days where John Sir was talking about biological

12:31.240 --> 12:36.360
naturalism. There's Chinese room experiment. Back then, to have a conversation like the one we're

12:36.360 --> 12:45.560
having right now would have seemed so crazy. It would and it wouldn't. In scientific circles,

12:45.560 --> 12:53.800
it certainly would have. Maybe my issues, I've read too much science fiction, but if you read

12:53.800 --> 12:59.480
some of the older sci-fi authors and especially some of the more philosophical ones like Stanislaw

12:59.480 --> 13:04.920
Lem and those kind of folks, nothing we're saying here would have surprised them at all.

13:04.920 --> 13:13.080
They were tackling these issues long ago and this question of what are the markers of intelligence

13:13.080 --> 13:18.280
and sentience and consciousness in terms of encountering radically different life forms?

13:20.680 --> 13:27.000
I have a blog post where I collected people's suggestions for a love and friendship between

13:27.080 --> 13:33.080
radically different entities throughout fantasy and science fiction because that's the kind of

13:33.080 --> 13:39.400
stuff. When people say, oh, I don't know, we need proof of humanity certificates because

13:41.080 --> 13:46.200
some of the work product that's going to be coming, who knows if it's got an AI origin?

13:49.960 --> 13:54.920
What if there are aliens out there that are completely different? They're made completely

13:54.920 --> 14:00.280
differently. They blow our art out of the water. You're really not going to pay any

14:00.280 --> 14:04.360
attention to that because they're not like us. What is it? You want proof of humanity?

14:07.960 --> 14:14.280
Would you rather judge things based on their origin or the quality? I think we've done poorly

14:14.280 --> 14:19.640
trying to judge on where things like this come from versus what do they do for you? Do they

14:19.640 --> 14:26.040
elevate you? Do they advance your mind? Let me put that paper aside for a second.

14:26.040 --> 14:34.120
To come back to the AI paper, you do this great job of reminding us. In my own dissertation,

14:34.120 --> 14:39.480
I spoke about similar things, the split brain patients, this confabulation. In both your papers,

14:39.480 --> 14:45.560
confabulation forms a big part of this process that we continuously do. What about AI? They're

14:45.560 --> 14:51.560
always lying. It's always confabulating, but then we tend to forget that we're the best confabulators,

14:51.560 --> 14:56.040
aren't they? One of the best, at least. Do you want to explore that a bit and just explain to

14:56.040 --> 15:02.440
the viewers and listeners exactly why we're so similar in that regard? The thing with

15:02.440 --> 15:09.000
confabulation, let's put it another way. It's an attempt to tell the best story you can based on

15:09.000 --> 15:15.320
what's going on right now. Again, I'm not saying that current language models and the way that

15:15.320 --> 15:19.960
they confabulate is exactly the way that human minds or even other biological minds confabulate.

15:19.960 --> 15:26.280
That's not my point. My point is that confabulation in general is a feature, not a bug. What happens

15:26.280 --> 15:33.880
is that during learning and during any kind of adaptive behavior, what successful agents have

15:33.880 --> 15:40.040
to do is compress lots and lots of data on past instances of perceptions that they've had into

15:40.040 --> 15:47.240
some sort of n-gram. It's some sort of memory trace or some sort of biophysically implemented

15:47.240 --> 15:52.280
model. It's a low-dimensional, coarse-grained, compressed model of what's going on. It's a

15:52.280 --> 15:56.040
model of themselves. It's a model of the outside world. They're going to use these memories and

15:56.040 --> 16:00.520
this model to guide future behavior. The thing about these models is that because they are

16:00.520 --> 16:04.840
necessarily compressed, that's the whole point of learning is you take lots of different past

16:04.840 --> 16:08.360
instances and you compress them to a generative rule that captures the pattern. What is it that

16:08.440 --> 16:14.200
they all had in common? When you do this compression, you're necessarily throwing away

16:14.200 --> 16:19.720
lots of data. That's the point of compression. When it's time to, and so in that paper, I make a lot

16:19.720 --> 16:24.360
of, hey, of this kind of bowtie architecture where there's a lot of stuff and it comes into a little

16:24.360 --> 16:27.640
node and then it comes out. This is something obviously used in machine learning and so on

16:27.640 --> 16:33.160
this kind of architecture. The idea is that on the right side of that bowtie, when it's time to

16:33.160 --> 16:37.960
interpret your memories, and let's remember, none of us have access to the past. What you have

16:38.040 --> 16:43.160
access to at any given moment is the memories that your past has left for you in your brain and in

16:43.160 --> 16:49.800
your body. You can look at that kind of thing as communication, as basically messages from your past

16:49.800 --> 16:55.000
self is what you have at any given now moment. But in order to reinflate them into actual policies

16:55.000 --> 16:59.320
of what you're going to do right now, there's a lot of creativity needed for that because it is

16:59.320 --> 17:05.880
underdetermined. The current situation and what you need to do is not fully described by the

17:05.880 --> 17:12.440
memory you have because of course it's compressed. This ability to add creativity, to add randomness,

17:12.440 --> 17:17.880
to add new interpretations that don't really have any allegiance to what the previous interpretation

17:17.880 --> 17:25.480
was. It's like any message or like novels. A novel is this sort of compressed representation

17:25.480 --> 17:30.360
of the thoughts of the author. When you read it, you are under no obligation to have exactly the

17:30.440 --> 17:38.520
same thoughts. You might have some, but as I think now people believe, the original author does not

17:38.520 --> 17:44.520
have any privileged position as far as what any of it means. It's the reader that will then benefit

17:44.520 --> 17:50.520
or not in various ways from reading it. This is the same thing in memory, and I think what's

17:50.520 --> 17:57.400
interesting is that it's the same thing that makes biology work because at what any given

17:57.480 --> 18:04.280
organism inherits from the past may or may not be optimally interpretable in exactly the same way.

18:04.280 --> 18:08.520
Maybe everything has stayed exactly the same and then you can just do whatever your past generations

18:08.520 --> 18:14.120
do, but evolution is committed to the fact that everything will change, the environment will change,

18:14.120 --> 18:19.800
your parts will change, your own structure will change. This is why things are so incredibly

18:20.440 --> 18:25.880
plastic. This is why we've put eyes on the tails of tadpoles and they can see perfectly well. You

18:25.880 --> 18:31.400
don't need new rounds of selection and mutation to make that work. That already works out of the box.

18:31.400 --> 18:36.840
Why? Because it doesn't automatically assume from the beginning that the eyes are going to be where

18:36.840 --> 18:41.400
they need to go. All of this kind of stuff is figured out largely from scratch every single time.

18:41.400 --> 18:46.120
This is why you can make Xenobots and Anthrobots and crazy creatures and new configurations,

18:46.120 --> 18:50.760
and they always do something interesting because evolution does not make fixed solutions that

18:50.760 --> 18:57.000
over-train on their past data. It makes problem-solving agents that will do their best in any given

18:57.000 --> 19:01.240
circumstance, which may mean reinterpreting the information that they got from the past in a

19:01.240 --> 19:07.800
completely new way. I love the two quotes in that paper. I think one is the William James one where

19:07.800 --> 19:14.200
he said, thoughts are thinkers. That's pretty cool when you really think about it. That is

19:14.200 --> 19:22.680
quite a fundamentally profound statement. That's a whole other piece of this, which is that

19:23.640 --> 19:29.320
typically we make this categorical distinction between you've got cognitive systems, which are

19:29.960 --> 19:36.200
the real physical machines of some sort, and then through them there is a passage of energy which

19:36.200 --> 19:41.720
encodes information and they're processing this information. That cognitive system is having

19:41.720 --> 19:47.560
thoughts of some sort. I think what he was getting at, although I'm not at all sure that

19:48.280 --> 19:54.360
he would have agreed with the various models that I put out in this paper,

19:56.120 --> 19:59.640
what I got out of it, and again, this may be a perfect example of the whole boat,

19:59.640 --> 20:02.520
I think, because I don't know what he had in mind, but this is what I got out of it.

20:04.360 --> 20:09.800
What I got out of it is that this idea that what if we relax this idea that there are categorical

20:09.880 --> 20:14.120
differences between real physical cognitive systems and the thoughts that go through them,

20:14.120 --> 20:18.280
what if they're just part of a continuum? You can draw a continuum like that where you can have

20:19.560 --> 20:26.280
fleeting thoughts and then you can have persistent thoughts that are what we know in

20:27.880 --> 20:31.560
various psychopathologies that people can have persistent thoughts that are very hard to get

20:31.560 --> 20:38.680
rid of and intrusive thoughts and things like this. Then you can have multiple

20:39.240 --> 20:44.680
identities, multiple alters in the sense of dissociative identity disorder and then you

20:44.680 --> 20:49.960
can have full-blown personalities. What you can think about is that the information,

20:49.960 --> 20:56.360
what if information is not purely passive? I mean, it can be, but in some cases, what if these

20:56.360 --> 21:04.280
patterns have a degree of agency themselves? Because let's not forget, we too are patterns.

21:04.360 --> 21:10.600
We too are temporary patterns in the thermodynamic sense. We persist for some amount of time

21:10.600 --> 21:18.280
metabolically and that's it. If patterns like us can have thoughts, then maybe there can be

21:18.280 --> 21:24.360
simpler patterns that are thoughts to us, but also might be thinkers of their own. In other words,

21:24.360 --> 21:29.880
they can spawn off other sub-patterns within the cognitive medium. That's what I was playing with

21:29.880 --> 21:34.200
this idea of what if it's a continuum? This continuum between thoughts and thinkers is not

21:34.200 --> 21:40.280
a categorical distinction, but it's a difference in degree. Yes, I think that was at the beginning

21:40.280 --> 21:46.920
of your paper where you used Mark Som's Sigmund Freud quote, which is also quite intriguing.

21:48.040 --> 21:54.120
Let me just see if I've got it here. It is, the material present in the form of memory traces

21:54.120 --> 22:00.280
being subjected from time to time to a rearrangement in accordance with fresh circumstances

22:00.360 --> 22:07.880
to a retranscription. There's two ways to think about it. You can think about it as a static

22:07.880 --> 22:15.000
being that has to reshuffle their interpretation in different ways or you can think about it

22:15.640 --> 22:22.680
and or you can think about it as a set of, playfully I call them self-luts. You can think

22:22.680 --> 22:29.160
about snapshots where each snapshot is not rearranging anything. They're given it for a new.

22:29.160 --> 22:35.080
They have the message each time new, so you're not rearranging. If it was arranged differently

22:35.080 --> 22:39.000
before, that belonged to somebody else. That belonged to a different self-link and now your

22:39.000 --> 22:46.760
job is to make some sort of sense out of it, a constant continuous process of sense-making.

22:51.640 --> 22:56.440
That paper on self-improvising memory reminded me of one of the papers I was reading with

22:56.440 --> 23:01.400
Steven Grossberg. I mean, you even mentioned that you love his work on memory. On that topic,

23:01.400 --> 23:03.400
what are your thoughts on Grossberg's work, just by the way?

23:04.200 --> 23:09.560
Yeah, I'm a huge fan and it was funny. I'm not sure. It might have been your interview with

23:09.560 --> 23:17.480
him or maybe somebody else where he mentioned that he saw me in 2006. I couldn't believe because

23:17.480 --> 23:22.440
I hadn't talked to him since then. I couldn't believe the memory this guy has. Just remembering

23:22.440 --> 23:28.520
that I came and talked to him. No, it is incredible. I love his work. In particular,

23:29.240 --> 23:35.000
he had a paper in 1978 called Memory, Cognition and Development or something like that.

23:37.000 --> 23:43.320
There, he outlined. It was just brilliantly prescient because he outlined some of the

23:43.320 --> 23:49.560
commonalities between certain developmental mechanisms and certain cognitive mechanisms

23:50.520 --> 23:59.400
information processing in the retina and stuff like that. I just thought it was incredible

23:59.400 --> 24:06.360
that that early he saw this similarity, the symmetry between the building of the body

24:06.360 --> 24:09.160
and the building of the mind. Yeah, I thought that was just...

24:11.240 --> 24:15.720
When I speak to people about Grossberg's work, some people see him as this Einstein of the mind,

24:15.800 --> 24:22.520
legitimately one of these Super Saiyans of mind. Then some people just don't know him at all,

24:22.520 --> 24:27.160
which is surprising. It's either one of the extremes. They either really love his work or just

24:27.160 --> 24:32.920
don't know it at all, which is quite straight. Well, and that speaks to... There's something

24:36.840 --> 24:42.680
unfortunate about the progress in science, which is that it isn't really monotonic.

24:43.000 --> 24:50.200
A ton of great stuff gets lost, forgotten. It's not paid attention to. It has to get rediscovered

24:50.200 --> 24:58.120
or not later on. Yeah, it's too bad, but this was... It's part of the reason why I actually do this

24:58.120 --> 25:02.920
podcast is it's a great way to have this community come together to have access to this information

25:02.920 --> 25:08.280
and then share ideas because every time when someone watches, for example, one of your episodes,

25:08.280 --> 25:12.280
even in the comment section, some people have profound things to say about your work and things

25:12.520 --> 25:16.280
where I learned so many new things just reading the comment section alone.

25:17.720 --> 25:25.400
Absolutely. Yeah, absolutely. On my blog, I have the comments turned on and people leave

25:25.400 --> 25:32.520
comments and I've been amazed at how useful the comments are and how rich. I mean, I learn things

25:32.520 --> 25:38.120
all the time and people put up new theories and new pointers to relevant work that I hadn't seen

25:38.120 --> 25:43.080
before. It's super useful. I did not know that was going to happen when I started this. It's really

25:43.080 --> 25:48.760
good. I think that that's the beauty of the internet in that regard is that this open sharing of ideas

25:48.760 --> 25:53.480
all the time really is useful because it makes for so much more constructive critiques. Well,

25:53.480 --> 25:58.360
I mean, sometimes it can be quite bizarre and a bit rude here and there, but for the most part,

25:58.360 --> 26:03.720
I mean, it is very useful. I had to remember one, so I made a note. Let me just find it.

26:03.720 --> 26:10.360
Someone commented on your previous one. They want a formal definition of diverse intelligence.

26:11.720 --> 26:17.400
We spoke about it very in depth for the last time we spoke, but a formal definition of

26:17.400 --> 26:22.600
diverse intelligence, what would that be for you? Sure. Well, the first thing I'd like to say is

26:22.600 --> 26:28.280
let's just agree amongst ourselves what definitions are for because that's important.

26:29.080 --> 26:35.640
Some people use definitions in a gatekeeping function. They want some kind of sharp distinction

26:35.640 --> 26:40.440
so that they can say, this stuff is not it, and then this is it. Then we can spend a lot of time

26:40.440 --> 26:44.520
wrangling over which one's which, and then we can keep some things out. That's not what I think

26:44.520 --> 26:51.400
definitions are for. I think definitions are useful to the extent that they facilitate new

26:51.400 --> 26:57.320
work, new discoveries. They should be mind expanding. They should help you use tools you

26:57.320 --> 27:02.760
didn't use before. They should help you make new connections you didn't make before. They should

27:02.760 --> 27:08.200
have a practical functional utility in getting you to new capabilities and new discoveries.

27:08.200 --> 27:18.600
That's what definitions are for. Because of that, I often either redefine or use words in

27:18.600 --> 27:24.440
different ways that a lot of people find disturbing because we'll say, well, that's not the common

27:24.440 --> 27:32.600
sense use of it. I really believe that philosophers and scientists should lead, not be stuck with

27:32.600 --> 27:38.280
common sense usages of different words because those aren't given to us by some sort of grand

27:38.280 --> 27:44.120
intelligence. They're just what we've cobbled together along the way. Now we can sharpen those

27:44.120 --> 27:49.240
up and in fact, open them up and see which ones survive and which ones don't. So anyway,

27:49.240 --> 27:55.160
diverse intelligence. So I take diverse intelligence to refer to the study of

27:56.520 --> 28:02.040
mind and particular problem solving capacities, but also all kinds of other things that are not

28:02.040 --> 28:07.720
around about problem solving intelligence, including play and exploration and affect and

28:07.720 --> 28:14.120
emotions and all these kinds of things. All of that stuff in truly diverse embodiments.

28:14.120 --> 28:19.240
This means intelligence is not about brains necessarily. It's not about things that evolve

28:19.240 --> 28:28.840
naturally. Intelligence and all of those kinds of cognitive terms may exist to various degrees and

28:28.840 --> 28:37.000
all kinds of unfamiliar substrates. This could be things of very different size and scale. So

28:37.000 --> 28:41.640
this could be very tiny things. It could be enormous, I don't know, solar system size,

28:41.640 --> 28:45.800
object somewhere. I mean, I'm making that up. I don't have any strong claims about it. But the

28:45.800 --> 28:51.800
point is, it is absolutely not limited to the end of one example that we have here on Earth,

28:51.800 --> 28:59.560
which are these kind of brainy substrates. So it's an attempt to improve our own

29:00.600 --> 29:05.960
intelligence detectors and go beyond our ancient evolutionary firmware that really leads us to

29:05.960 --> 29:11.320
only recognize a certain small subset of intelligences and ask, what other spaces

29:11.320 --> 29:18.040
can intelligence operate in? What other embodiments? Can we tell a principal story of how to recognize

29:18.040 --> 29:23.320
it? What facilitates it and so on? I like in this paper, you even say,

29:24.280 --> 29:29.880
diverse intelligence research focuses on the commonalities across all possible intelligent

29:29.880 --> 29:35.640
agents, which is a great way to sort of summarize what this field is doing in terms of a research

29:35.720 --> 29:42.760
basis. And by the way, I don't claim to speak for the entire field. I speak for myself only,

29:42.760 --> 29:49.240
but there are many people in the field that do agree with me. There are many people that do not.

29:49.800 --> 29:58.440
In particular, there are lots of folks that don't like the continuum that I insist on between

29:59.960 --> 30:04.040
so-called real minds and so-called machines. So this is something that are many people in

30:04.040 --> 30:09.960
the organist's tradition that think that this is really doing a disservice to the study of the

30:09.960 --> 30:17.560
mind to put it on the same spectrum as machines, whatever that may be. So I'm not claiming to

30:17.560 --> 30:21.960
speak for the entire field. I think that's a great way to sort of segue into what would be the

30:21.960 --> 30:28.760
difference, and this is along the lines of your paper, between dating an algorithm, a computer,

30:28.760 --> 30:35.800
an artificially intelligent person, mind, or versus dating someone else, like yourself, myself,

30:35.800 --> 30:41.720
I mean, dating someone. And I think you wrote, what about the forthcoming AI girlfriends and

30:41.720 --> 30:49.720
boyfriends? I mean, it's a fascinating idea because, I mean, who are you? Who are we in general?

30:51.160 --> 30:56.600
Yeah. So, well, first of all, I refer everybody to read some of the stories in that blog post

30:57.480 --> 31:02.680
that, right? I mean, this idea of dating something that is fundamentally different from you,

31:03.640 --> 31:07.160
I hardly invented that idea, right? This has been around for hundreds of years now.

31:07.160 --> 31:16.200
People are in love with sentient clouds of particles, and we've been digging into this

31:16.200 --> 31:21.640
issue of what is in-group, what is out-group, who deserves your compassion, with whom can

31:21.640 --> 31:27.480
you have a relationship? That's been around for a really long time. And one of the things I really

31:27.480 --> 31:34.520
worry about, I think people will go down the organist road with good intentions to try to

31:34.520 --> 31:44.680
understand what is magical in the useful sense about true minds with consciousness, with agency,

31:44.680 --> 31:55.480
and all of that. But I think the downside of this is that I think in trying to be specific about

31:55.480 --> 32:01.160
what's in and what's out, and in particular, trying to draw sharp lines, I think you very

32:01.160 --> 32:06.280
quickly run into the side of the spectrum that says, only love your own kind. And we know how

32:06.280 --> 32:11.880
that works out. Humanity has tried this many times. I think we have some sort of built-in

32:12.600 --> 32:19.960
tendency to demarcate in-groups and out-groups. They're real, and these guys,

32:19.960 --> 32:23.960
and they look a little different. I don't think they feel pain like we do. Let's not worry about

32:23.960 --> 32:30.360
them so much. We're not very good at expanding our compassion to others that have different

32:30.360 --> 32:39.640
origin stories or different composition. I think that this is, again, not about AI at all.

32:40.120 --> 32:47.320
There's no doubt that in the next decade or so, we are going to have humans that are

32:48.360 --> 32:54.200
mostly biological, but they got some microchips in their brain, and some of those get them to

32:54.200 --> 32:59.160
sort of whatever neurotypical is supposed to be. But others have decided they're going in a

32:59.160 --> 33:03.960
different direction, and maybe they're connected with some other people more than we are connected

33:03.960 --> 33:10.040
right now, really kind of mind-melting stuff. And maybe somebody decides that what they'd

33:10.040 --> 33:14.680
really like for senses is to really feel the solar weather and the financial markets. That's

33:14.680 --> 33:20.040
what they'd really like. Sight and hearing is good, but they want to really feel what the

33:20.040 --> 33:24.440
NASDAQ is doing. And all of these humans are going to be running around, and they're going to have

33:24.440 --> 33:34.360
different degrees of evolved and designed components. I don't know. When you go on a date

33:34.360 --> 33:40.120
with somebody, are you going to ask them what percentage is factory equipment that's biological?

33:40.120 --> 33:47.000
Do you care? I don't care. If my spouse said that she had had some stuff replaced with

33:47.000 --> 33:51.160
various technologies, is that what I'm really worried about? I think here's what I think,

33:51.240 --> 33:57.240
and I'm certainly not telling anybody who to date, but for me personally, what I think is

33:57.240 --> 34:03.640
interesting about these kinds of things is that what you really want is a kind of impedance

34:03.640 --> 34:10.280
match. You want a similar cognitive light cone. You want to be able to care about the same kinds

34:10.280 --> 34:14.680
of things, and ideally even some of the same things, but at least the same, roughly the same

34:14.680 --> 34:20.120
kinds of things. Because this is why we feel that people that fall in love with bridges or people

34:20.120 --> 34:26.200
that think their rumba is their child and things like this. This is why we look down on this stuff,

34:26.200 --> 34:31.880
because we say, look, your capacity to care about things are just not matching at all.

34:32.760 --> 34:39.960
And there are certainly, I can think of some sort of popular art kinds of things like the

34:39.960 --> 34:46.120
Watchmen movie and things like that, where you've got a romance between this cosmic intelligence

34:46.120 --> 34:53.640
and a normal human, and I don't know. That's better than the rumba case, but still, if your

34:53.640 --> 34:58.680
consciousness and the things you care about are a tiny speck in the mind of this other being,

34:58.680 --> 35:04.760
are you really having a relationship? I don't know. Those are deep questions, but I certainly

35:04.760 --> 35:09.240
don't think it's about what are you made of and how did you get here? I think it's all about what

35:09.240 --> 35:15.480
kind of mind you have and can we share some of the same existential concerns. In fact, Olaf

35:15.480 --> 35:20.920
Wodkowski and I are writing a paper on this. It's a paper on love and diverse intelligence,

35:20.920 --> 35:28.600
and so on. You can run through all kinds of different examples like, can you really date

35:28.600 --> 35:34.440
Superman? Let's assume there's no Kryptonite, can you? Because what he doesn't understand is your

35:34.440 --> 35:39.080
existential concern over dying. He just doesn't get it. He has no idea what you're talking about.

35:39.880 --> 35:46.680
At some point, if the kinds of things that worry you as a system that sort of pulled itself together

35:46.680 --> 35:51.240
from its parts and you're here for a limited time, and there are all kinds of other psychological

35:51.240 --> 35:54.600
issues that we have that are pretty much unresolvable because we want things that are

35:54.600 --> 35:59.480
basically impossible and so on, if the other being doesn't understand any of those things,

35:59.480 --> 36:06.280
then maybe it's not a good match. It reminds me of her with Scarlett Johansson and Joaquin Phoenix.

36:07.240 --> 36:09.720
Have you watched that film? I haven't seen it. I know the movie.

36:11.000 --> 36:15.240
It's crazy because at some point, this artificial intelligence has so much

36:15.240 --> 36:19.960
more experience because it's understanding the universe at such a deeper complex level

36:19.960 --> 36:26.600
that she just abandons the guy and then goes on her own quest. They've also been all these new

36:26.600 --> 36:32.440
cases of Scarlett Johansson's voice becoming this new artificial intelligence general voice,

36:32.520 --> 36:37.080
and she's apparently suing people because that's how influential that film was.

36:38.120 --> 36:42.040
Just as a by the way, but the main premise of this whole idea of what you're talking about,

36:42.680 --> 36:46.840
one of the lines in particular that I found quite intriguing was you spoke about the fact that

36:46.840 --> 36:52.440
you're not always you either. I mean, in general, when someone's dating someone, perhaps you have

36:52.440 --> 36:56.600
people who judge people, say, don't date someone with money, date them for their personality,

36:56.600 --> 37:01.560
their quirks, the things that they do, but those fade. As you get older, you have memory loss,

37:01.640 --> 37:06.680
you won't have the same quirks. You fundamentally become a different entity, which is problematic

37:06.680 --> 37:12.360
because these values replacing and the separation that you're doing, trying to group people in

37:12.360 --> 37:17.160
and out of what you're talking about is problematic because of that. You're never really that person,

37:17.800 --> 37:23.880
continuously at least. Well, yeah. And it's that same paradox that we talked about earlier. It's

37:24.200 --> 37:30.920
this idea of if you really start stripping away the different

37:32.680 --> 37:37.480
qualities, then there isn't going to be anything left. And it's the gestalt, but the gestalt is

37:37.480 --> 37:41.720
going to change. And so how are you going to handle that change? I mean, that's part of the

37:42.760 --> 37:47.960
existential difficulties of our human condition because everything changes. We change, all the

37:48.520 --> 37:53.800
other minds that we interact with are going to change. None of us are going to stay

37:53.800 --> 38:00.760
the same. Yeah. There's another part. You slowly touched on this now. When you talk about this

38:01.560 --> 38:04.920
percentage difference at some point, we're going to ask people, okay, are you 50% human?

38:04.920 --> 38:11.240
What are you? Are you 45% cyborg? We're going to have these conversations. I mean, current variants

38:11.240 --> 38:15.960
you mentioned are about 99% human at this point and then chips here and there, perhaps glasses,

38:15.960 --> 38:23.080
you've got a panic, maybe an arm or a leg. But it's completely, completely apparent that at this

38:23.080 --> 38:27.560
point, most people are synthetically engineered in some sort of way. I mean, people have plastic

38:27.560 --> 38:32.680
surgery done, people have a lot. And the norms have shifted and changed as a doctor in medicine.

38:32.680 --> 38:38.600
And when you look at what people found to be absurd or a bit over the top, those have decreased.

38:38.600 --> 38:42.680
So like having normal nose surgery or getting your nose tweaked here and there is almost a

38:42.680 --> 38:48.600
baseline norm at this point. So it's very easy to see how that line gets blurry over time. And yet

38:49.480 --> 38:56.280
fight this. Yeah, no, it's looking to the past. The first guy to carry an umbrella in London was

38:56.280 --> 39:02.760
mobbed. He was mobbed and people threw garbage at him because they were shocked that this guy

39:02.760 --> 39:09.720
thought he could get away from the normal human condition of getting rained on. This was considered

39:09.720 --> 39:12.840
to be normal. We are all out here. We're all going to get rained on together. That's how it is. There's

39:12.840 --> 39:16.840
nothing we can do about it. And who is this guy to try to get out of it? And so an umbrella,

39:16.840 --> 39:24.920
that's all he had. And this was shocking and whatever. So I think if you were to bring back

39:25.480 --> 39:35.720
a primitive man and ask her what she thinks about the current humans, you've got some glasses on,

39:35.720 --> 39:42.280
you went to school, which for 12 years, it gave you this incredible like brain boost that nobody

39:42.280 --> 39:46.040
else had ever heard of. And you've got some glasses and you've got some orthotics in your

39:46.040 --> 39:52.520
shoes and you've got it. You've had some surgery somewhere that you've got a pacemaker and you've

39:52.520 --> 39:57.720
got, and by the way, half the stuff you know, you is you plus your iPhone, right? Stuff you look

39:57.720 --> 40:01.800
up because you know it in a functional sense, but take that thing away. You don't know where

40:01.800 --> 40:06.600
anything is or what anybody's phone number is or anything. And so, right? And you're relying on all

40:06.600 --> 40:14.440
this stuff. I mean, it's just to that person, we are already incredible cyborgs, just incredible.

40:14.440 --> 40:18.840
And there is no, there's no putting that genie back in the bottle. This is, I mean, obviously,

40:18.840 --> 40:23.160
this is going to this is going to crank forward. And I think that's one of the most undermined

40:23.160 --> 40:27.640
forms of extended cognition is our phones, our cell phones. People really don't realize how

40:29.080 --> 40:34.440
Andy Clark. Yeah, Andy Clark has written a lot about this. Yeah. Very, very, very cool.

40:35.800 --> 40:41.400
And a lot of it, I mean, we don't, you, you, something I found quite funny was one of the

40:41.400 --> 40:45.800
sentences he was saying, the challenge before is the challenge before is to develop rational

40:45.800 --> 40:50.760
policies for ethical synth biosis. And then when you read down below, this is a word you actually

40:50.760 --> 40:57.560
generated using chat GBT. Tell us about this. Yeah, I was looking for, I mean, I don't, so funny

40:57.560 --> 41:01.560
enough, as much as I like all this diverse intelligence stuff, I don't use AI for much,

41:01.560 --> 41:06.120
but, but, but at all, I don't use it to do any writing or anything like that. But, but, but

41:06.120 --> 41:10.520
for these kinds of sort of creative things, I think it's actually quite, quite good. And I was,

41:10.520 --> 41:20.200
I was looking for a word that would, that would encompass this idea that a positive creative

41:20.200 --> 41:24.600
collaboration between biology and synthetic entities. And then I sort of described that

41:24.600 --> 41:30.200
and GPT said synth biosis. I thought that's pretty good. I like it. So yeah, so I think it is. Yeah,

41:30.200 --> 41:34.120
yeah, I think it is. Because, yeah, because, because fundamentally, this trying to maintain

41:34.120 --> 41:40.040
this distinction between quote unquote, natural things and the product of those natural things,

41:40.040 --> 41:44.760
meaning our synthetic, you know, engineered things. There's, I just don't think it's,

41:44.760 --> 41:49.960
it's valuable at all. I think it holds back a lot of progress. And in your defense, because I know

41:49.960 --> 41:56.680
a lot of people assume that when you talk about man as a machine or when you, when you talk about

41:56.680 --> 42:04.040
these, these concepts, they're useful in different contexts. And so you often talk about, we spoke

42:04.040 --> 42:07.960
the last time and you mentioned the fact that an orthopedic surgeon has to see you as a, as a

42:07.960 --> 42:11.880
machine. I mean, there's no doubt about it. When I'm in theater with assisting with an orthopedic

42:11.880 --> 42:18.920
surgeon, I know what it's like. It's legitimately a mechanic. Like literally taking about drilling

42:18.920 --> 42:23.720
holes, getting a hammer, knocking onto things. And then, and then I can go back into like,

42:23.720 --> 42:28.040
let's say, clinical scenario and chat to the patient about the operation. And that's a completely

42:28.040 --> 42:33.320
different experience. It's a mental well being check. It's a sort of psychological checking.

42:33.320 --> 42:38.200
It's very, very different. So it's easier to see how we can see them both as a machine and as a

42:38.200 --> 42:45.720
complex psychological system. I mean, the, the, I think what, I think where, where people go wrong

42:45.720 --> 42:53.960
sometimes is to think that when we make these models, machines, you know, living beings, humans,

42:53.960 --> 42:59.080
whatever, that these are all claims about what something essentially is. It's this kind of

42:59.080 --> 43:02.760
essentialism that we think it's a real thing. There is one objective answer as to what it

43:02.760 --> 43:08.520
really is. And we need to argue about what it really is. I don't think any of these things

43:08.520 --> 43:13.720
are about what the thing really is. I think these are all interaction claims. This is why,

43:13.720 --> 43:18.840
this is why I called my, my, my freeing word tame because, because it is an engineering

43:18.840 --> 43:23.240
perspective. Now, engineering means something wider than I think most people take it. But

43:23.240 --> 43:28.360
nevertheless, the thing about engineering is that you are at least clear, you're honest with yourself

43:28.360 --> 43:33.000
in that what you are doing is putting out an interaction protocol. This is the frame that

43:33.000 --> 43:37.160
I'm going to look at at the system. This is what it enables me to do. Here's a bag of tools that

43:37.160 --> 43:42.440
I bring to it. And then you can bring yours, I can bring mine, and we can compare the results.

43:42.440 --> 43:46.280
And we can find out that, oh, wow, I, I missed all of it. You, you, you had a better framing

43:46.280 --> 43:49.640
because look, you were able to do all these things that I couldn't do because I was looking at it

43:49.640 --> 43:54.120
from a different perspective. So when people, you know, when, when, when, so, so, so like people

43:54.120 --> 43:57.640
ask, you know, am I a computationalist, for example, with respect to living things?

43:59.000 --> 44:04.840
Well, I think the whole, the question is ill-posed because it's not whether living things are

44:04.840 --> 44:11.080
Turing machines or nothing is anything. I think that what, what you can say is, okay, I've got a

44:11.080 --> 44:16.520
certain paradigm, let's say it's a Turing machine or it's a, you know, whatever it is. And that lens

44:16.520 --> 44:20.920
enables me to see certain things. And yes, I do think in some cases it's a, it's a, it's a useful

44:20.920 --> 44:25.640
lens, but it certainly doesn't capture everything that's important about living things. And so then,

44:25.640 --> 44:29.480
then you need a, or cognitive things more, which I think are more interesting, then,

44:29.480 --> 44:33.240
then you need, then you need different, different lenses, but, but, but, but then it, then, then

44:33.240 --> 44:38.600
it's all good. You know, we don't have to argue about what it really is. You can just say, through,

44:38.600 --> 44:42.760
I look, I look at it through this lens, here's what I see. Do you find it useful, or do you want to

44:42.760 --> 44:50.040
keep looking for a new lens or, or usually both? I think that your work is so intriguing on so many

44:50.120 --> 44:57.480
different levels. And it's a, and you're able to, to cross so many different fields that to some

44:57.480 --> 45:02.520
people, particularly, I would say to some scientists, when you make this claim that there is a

45:02.520 --> 45:07.400
technological approach to mind everywhere, the moment you get boxed into this sort of panpsychist

45:07.400 --> 45:12.280
view, they immediately have this dismissive attitude. But if they're a reduction materialist

45:13.800 --> 45:19.320
person, which is sad really, because they don't really then give it the opportunity that it

45:19.320 --> 45:22.600
deserves when, because when you break it down and actually look into what you're talking about,

45:22.600 --> 45:28.120
you're often saying you got to, we don't know, you got to make experiments and, and get some

45:28.120 --> 45:33.160
sort of empirical evidence to base whatever you're claiming. And I think that's the most

45:33.160 --> 45:36.760
important thing is that you're often saying, let's set up an experiment, let's do this,

45:36.760 --> 45:42.280
let's try and show why this is the case, which a lot of people don't necessarily do, particularly

45:42.280 --> 45:48.280
philosophers who have very strict views on, on their, on their reality, you're able to at least

45:48.280 --> 45:52.680
show this empirically, which I think is pretty cool. Well, that's, I mean, yeah, so, so the wacky

45:52.680 --> 45:58.760
thing about our lab is that we do a lot of experiments. And this is, this is not only

45:58.760 --> 46:01.800
philosophy. And I don't, I don't know, I mean, I think philosophy is very important. I never,

46:01.800 --> 46:07.640
you know, I never downplay it, but, but, but, but, but we do a lot of experiments. And, you know,

46:07.640 --> 46:13.320
typically, I basically, I put out two kinds of papers. One is a, what the one kind is a straight

46:13.320 --> 46:18.600
up, you know, developmental biology or bioengineering or, you know, synthetic regeneration,

46:18.600 --> 46:22.200
whatever it's going to be. I don't talk about any of the philosophical stuff in those papers.

46:23.560 --> 46:29.000
But you kind of can't get away from that stuff, because what happens is sure, you can, you can

46:29.000 --> 46:32.600
dismiss the, the kind of the other papers, which are kind of these philosophical

46:33.400 --> 46:38.760
perspectives on this, but you still have to account for the data. And, you know, my, my point is

46:38.760 --> 46:41.880
simply this, because people say to me, like, I'll give a talk about something. And they say, okay,

46:41.960 --> 46:46.200
you know, the data means really interesting what, what, what you've done and the new capabilities.

46:46.200 --> 46:50.760
But, you know, I wish you'd stop talking about this philosophy stuff. And, and my claim is,

46:50.760 --> 46:56.360
well, this is why we did it, you see, is because, is because that philosophical outlook made specific

46:57.640 --> 47:01.960
predictions about roadmaps, you know, it's not a single experiment, but it, it shows you where

47:01.960 --> 47:06.280
to look, it shows you how to look, it tells you which categories can be broken and otherwise,

47:06.280 --> 47:10.840
otherwise you're trapped in certain ways of thinking. And that leads to very specific

47:11.400 --> 47:17.160
new discoveries. And so, so I think this is, this is important because after the fact,

47:17.160 --> 47:22.360
once you do something, anybody can look at it and tell a molecular story about what happened

47:22.360 --> 47:26.680
and say, oh, well, this is, this is not different from, from anything that's happened before it

47:26.680 --> 47:30.440
followed. I mean, of course, it follows the laws of physics and chemistry. My point is never that

47:30.440 --> 47:33.480
it's fairies underneath. And that's something, you know, something, you know, miraculous is

47:33.480 --> 47:38.280
happening. That's never the point. But my point is, why wasn't it done before? What is it about

47:38.280 --> 47:41.800
the, what is it about the standard paradigm that didn't, that didn't facilitate these,

47:41.800 --> 47:47.560
these experiments to be done before? So, yeah, you know, you can be, you can be down on the,

47:47.560 --> 47:52.920
on the conceptual frameworks that drive this stuff. But then you're playing catch up because,

47:52.920 --> 47:57.560
because then the stuff is going to be coming out. And it's, and it's surprising. And this is, you

47:57.560 --> 48:04.280
know, to me, this is, this is a more general issue of, of, of these kind of reductive explanations.

48:04.280 --> 48:08.600
And by the way, I don't, I don't think anybody's really in this field is an actual reductionist,

48:08.600 --> 48:12.920
because if they, you know, if you, if you push and you say, well, then you want explanations in

48:12.920 --> 48:16.040
terms of quantum foam, right? And they say, no, no, that's stupid. It's chemistry. It's got to

48:16.040 --> 48:20.200
be chemistry. So that's not real reductionism. That's just the level of chemistry. But, but

48:21.160 --> 48:27.640
the, you can, the easy sort of analogy to this is if there was a, it was a game of chess played,

48:27.640 --> 48:32.680
right? So, you know, a couple of people played a game of chess. You could, so Laplace's demon

48:32.680 --> 48:37.800
could look at this and say, well, I mean, all it was is a bunch more, is a bunch of physics. I mean,

48:37.800 --> 48:41.640
I saw all the, all the protons went where the protons go, the electrons went where they go,

48:41.640 --> 48:45.480
everything followed rules. There's no mystery here, no surprise. Everything did exactly what it

48:45.480 --> 48:50.520
was supposed to be. It's just, you know, it's just physics. That's not exactly wrong, because

48:50.520 --> 48:55.480
looking backwards after the thing was done, you could tell that story. But now the question is,

48:55.480 --> 48:59.800
does it help you play the next game of chess? How do you, how do you go from there to, well,

48:59.800 --> 49:03.960
now what do I do? And so, and it's completely useless for that, right? It's, it's only a story

49:03.960 --> 49:09.640
looking backwards. So I think the thing about these kind of explanations is that you want them

49:09.640 --> 49:14.520
to facilitate your next, the next discoveries, the way to, you know, to, to improve your

49:14.520 --> 49:19.000
capabilities. Anybody could always tell a molecular story after the fact. The question is,

49:19.000 --> 49:24.440
what are you going to do next? Yeah, I mean, on that, on the topic of reductionism, you, at

49:24.440 --> 49:32.120
some point you say, in an important sense, you are a brain in a vat. However, we are not just

49:32.120 --> 49:40.920
chemical machines. So you're both acknowledging the fact that we're, we're these mechanical

49:40.920 --> 49:45.560
systems. And yet you're also still saying that that's still, you're not reducing us to these

49:45.560 --> 49:51.480
simple properties. You're still acknowledging the fact that they are more layered realities

49:51.480 --> 49:59.480
here to explore, in a sense. Yeah, I mean, in the, in the kind of the simple thing is that,

49:59.480 --> 50:05.960
yeah, absolutely. My claim is that interactions with certain kinds of systems are much more

50:05.960 --> 50:10.440
efficient at high levels, right? So, so, so certainly, I mean, we know this from anybody

50:10.440 --> 50:14.120
who's trained animals, instead of trying to run their neurons like a puppet knows that

50:14.120 --> 50:18.040
it's, it's much better if you understand the psychology of, of certain creatures and so on.

50:18.760 --> 50:22.360
And, and as you go rightward on that spectrum into, into friendship and love and these kinds

50:22.360 --> 50:26.920
of things that are much more bidirectional, it's not just control and prediction, but it's actually,

50:26.920 --> 50:31.480
you know, being vulnerable to, to change and benefiting from the agency of the beings that

50:31.480 --> 50:36.600
you're, that you're associating with and so on. Yeah, then, then of course there are these higher

50:36.600 --> 50:41.480
levels, but, but I want to say something else here too, which is that I think one thing this is all

50:41.480 --> 50:47.240
telling us is that, and I think this, this will be more and more apparent in the coming years,

50:47.240 --> 50:53.240
we have really misunderstood what simple machines are. We've, we've fallen in love with our,

50:53.800 --> 51:00.840
we've, we've confused physical things with models of simple machines that we make of

51:00.840 --> 51:06.440
those things and we think, we think we know what it is when we make something and I think

51:06.440 --> 51:12.680
that's profoundly wrong. What, what we have is our model and, and we've, we've done some work

51:12.680 --> 51:19.080
now and we're going to do lots more on finding surprising protocognitive properties and very

51:19.080 --> 51:23.400
simple systems that are not obvious at all. And I don't mean emergent complexity. Emergent

51:23.400 --> 51:27.320
complexity and unpredictability is trivial. It's easy. You can, you know, any cellular

51:27.320 --> 51:30.680
automata, whatever they will give you complexity that will give you unpredictability in certain

51:30.680 --> 51:35.640
cases. That, that, that part's easy. I'm talking about emergent goals, emergent cognition in systems

51:35.640 --> 51:42.280
that are extremely simple and minimal. And you know, when we say we are not machines, we are

51:42.280 --> 51:48.200
certainly not describable by the simple models we've made of machines, but I actually think that

51:48.200 --> 51:53.800
lots of simple physical objects are, are very, are not properly described that way either. And,

51:53.800 --> 51:58.200
and we need to, we need to remember that all of these things are just lenses that we bring to them.

51:58.200 --> 52:04.920
You know, yeah, you know, I heard, I was talking to somebody once who, he writes these, these,

52:04.920 --> 52:09.160
these language models and he said, well, I made it. I wrote it myself. I know exactly what it

52:09.160 --> 52:13.400
does. I know, I know everything that's in it. I made it. And as I said, I said, you don't even

52:13.400 --> 52:18.440
even know what bubble sort does. We're like, we found, we found, we found these, these unexpected

52:18.440 --> 52:23.480
capacities in, in, in stupid bubble sorts, you know, six lines of code, fully deterministic,

52:23.480 --> 52:28.840
nowhere to hide. Even that thing does things. Nobody knew that it did. And, and, and if that's

52:28.840 --> 52:32.680
the case, when you make this, this, this crazy, the, you know, language model, again, I'm not

52:32.680 --> 52:36.760
in love with language models, but, but, but just the, just this idea that we've made it and therefore

52:36.760 --> 52:42.360
we know what it does. I think is, is we really need a lot more humility around this. I, I, you

52:42.360 --> 52:46.440
know, I think there's plenty of stuff that quote unquote, simple matter does that we do not understand

52:46.440 --> 52:52.280
yet. Mike, the last time I spoke to Mark, Psalms, you asked me to ask him about what is the meaning

52:52.280 --> 52:57.800
of life. And then we started this whole road towards the end of that conversation. He,

52:57.800 --> 53:03.480
he spoke about the Oppenheimer foundation, given him funding, his, his new search for

53:03.480 --> 53:08.200
artificial intelligence, trying to sort of see where this goes. What are your thoughts on his

53:08.200 --> 53:15.480
work and what they're trying to do at this point? Yeah. I mean, he, as far as I know, none of it

53:15.480 --> 53:19.160
is published, although I've talked to him about it quite, quite a lot. So I'm not, I'm not going

53:19.160 --> 53:23.960
to kind of give away anything until, until he publishes it. But because it's not, it's not

53:23.960 --> 53:31.960
my story to tell. But I think of anybody I know at the moment, his approach is the most likely

53:32.040 --> 53:39.000
to give rise to something that actually captures what's important about cognition in, in living

53:39.000 --> 53:47.560
things. I think, I think if anybody is going to engineer something that, that exploits some of

53:47.560 --> 53:52.200
the same principles that, that life exploits for, for cognition, I think he's likely to do it.

53:52.200 --> 53:57.240
Yeah. Mark really sees that cortical fallacy that we all seem to have, you know, this obsession

53:57.960 --> 54:03.880
of this sort of higher cognitive functions as being this, the epitome of consciousness.

54:04.840 --> 54:10.520
Yeah. I mean, I think it's even, I think it's, it's way worse than that. It's not just where is it?

54:11.160 --> 54:15.240
You know, I mean, there are some people who think that it, that, that, that the consciousness,

54:15.240 --> 54:20.120
for example, shows up during warm-bloodedness, you know, I think that's Nick Humphrey's position.

54:20.120 --> 54:26.920
And it's not even, to me, it's not even the question of where in the brain or, or

54:26.920 --> 54:32.840
what kind of brain. I mean, I'm talking about what, what space do you even operate in? Because I,

54:32.840 --> 54:36.440
because I think that, that, you know, when they say, oh, this thing is not embodied, it doesn't,

54:36.440 --> 54:41.400
it's not a robot on wheels that can sort of run around, then you can have bodies and do this kind

54:41.400 --> 54:45.880
of perception action loop and all active inference and all this stuff. You can do this in other spaces

54:45.880 --> 54:50.280
that we are completely blind to, right? So you can live in transcriptional space or anatomical

54:50.280 --> 54:54.280
morphous space or who knows, there's probably a hundred others that we don't, you know, we, we

54:54.280 --> 54:58.840
don't know how to visualize and all of those are embodied. That's on us, that limitation that we

54:58.840 --> 55:03.080
don't see that and we don't see all the, all the goal-directedness, the striving, the intelligence,

55:03.080 --> 55:09.000
the problem-solving, that, that's our limitation, right? And so, so intelligence, not only in,

55:09.000 --> 55:14.600
in, you know, weird kinds of body parts, but just in things that are not in 3D space at all,

55:14.600 --> 55:21.240
really, that's not where their, their life plays out. And even, even worse than that,

55:21.720 --> 55:26.440
along the spectrum, even, even, you know, sort of weirder is along the spectrum of

55:27.640 --> 55:31.880
how quote unquote real something is. So what I mean by that is, I don't remember if it's

55:31.880 --> 55:35.880
actually in that paper or not, but you know, there was a science fiction story. If anybody

55:35.880 --> 55:40.680
listening to this knows what story it is, please email me because I couldn't remember like, which,

55:40.680 --> 55:45.720
which I'd like to give credit and I couldn't remember who it is. But the idea is that these,

55:45.720 --> 55:48.760
these creatures come out of the center of the earth, you know, they live, they live down in

55:48.760 --> 55:51.080
the core and they come out of the center of the earth and they're walking around.

55:51.800 --> 55:57.880
Everything that we see out here is gas to them. I mean, they are so dense that all of this stuff

55:57.880 --> 56:02.920
here that feels solid to us is gaseous phase. It's plasma. Like, it's like, I don't even see it.

56:02.920 --> 56:06.360
And they're walking around as far as they're concerned. They're like, and basically in,

56:06.360 --> 56:09.880
in, in, in space at this point, because like, oh my God, there's like, there's nothing here.

56:10.440 --> 56:14.840
And, and I, I'm sure I'm embellishing this in my own way. I don't remember what the,

56:14.840 --> 56:18.200
what the actual story is, but that's only the first part that I recall.

56:18.200 --> 56:22.360
But, but to me, what I envision immediately is like one of them as a scientist,

56:22.360 --> 56:26.680
and he's taking measurements of this, of this gas that's on, on the surface of the planet.

56:26.680 --> 56:31.400
And he says, you know, I see some, I see these patterns in this gas, they sort of

56:31.400 --> 56:35.720
hang together for a while and they do things. And it almost looks, they almost look agential.

56:35.720 --> 56:38.840
You know, these patterns almost look like they're doing things. And of course, the others are like,

56:38.840 --> 56:42.360
oh, you're crazy patterns and gas can't do anything. Patterns aren't real. We're, you know,

56:42.360 --> 56:47.320
we're real. How's a pattern and gas going to do anything? And he says, no, I really, I think

56:47.320 --> 56:51.000
they're like, they're trying to, you know, meet certain goals and they have memories and where,

56:51.000 --> 56:54.840
but, and they say, well, how long do these patterns hang around? He says, well, about 100

56:54.840 --> 56:58.760
years, that's ridiculous. Nothing important can happen in 100 years, you know, because these

56:58.760 --> 57:03.400
things live for, you know, millions of years. And so, and so this, this just reminds you that

57:05.800 --> 57:10.680
what's a pattern and, and what's a real being. So, so again, back to this distinction between

57:10.680 --> 57:15.720
thoughts and thinkers is in the eye of a beholder, you know, it's in the eye of the observer. And

57:15.800 --> 57:20.520
if we did have aliens that came to earth with a radically different cognitive frame rate,

57:20.520 --> 57:24.600
if they had different lifespans, whatever, would they think that talking to us is a good idea?

57:24.600 --> 57:29.160
Or would they be trying to talk to ecosystems? Or conversely, would they think that talking to the,

57:29.160 --> 57:33.240
you know, molecular processes is the best that they're going to be able to do? I think, I think

57:33.240 --> 57:39.560
all of this is really about observers and about getting good at recognizing intelligence and

57:39.560 --> 57:47.240
extremely unfamiliar guises, you know? I think that the it's, it's inescapable, your work particularly

57:47.240 --> 57:52.600
to, to not cross philosophical slash ethical boundaries and have these discussions. So,

57:52.600 --> 57:57.000
so when people tell you that listen, stay away from the philosophical stuff, it's you cannot,

57:57.000 --> 58:02.440
you just, this is just not part of your job. You have to at some point address these because

58:02.440 --> 58:06.040
I remember one of the comments in one of our discussions, it could have been our first one

58:06.040 --> 58:11.080
or second one. But then someone asked, is Michael playing God? And my first thought was,

58:12.920 --> 58:17.560
it's a strange one. You know, it was one of those questions people often asked back in the day when

58:17.560 --> 58:21.960
people were tinkering with any sort of even a plant, you could genetically modify an organism,

58:21.960 --> 58:26.360
and then you're playing God at that point. I mean, it's a very, very strange question to

58:26.360 --> 58:31.320
really ask. How would you respond to that? People actually ask it all the time. I think

58:31.320 --> 58:34.920
it's one of those questions that sounds like it makes sense until you, until you sort of dig

58:34.920 --> 58:40.680
into it a little bit. But because, because I don't know what, what the definition of God is.

58:40.680 --> 58:43.880
And I mean, usually the people who ask this, they got some glasses on, and they've got,

58:43.880 --> 58:47.880
you know, they usually drive, they don't walk places and so on. So it's a little, it's a little

58:47.880 --> 58:53.880
disingenuous. But, but, but let's, let's dig into this for a moment. I did a poll once on Twitter,

58:53.880 --> 58:59.400
and certainly this is not like a, you know, a statistically valid sample or anything like that.

58:59.400 --> 59:04.840
But I did a poll and the, and my question was simply this. So you're, you're, you know,

59:04.840 --> 59:10.840
AUG the caveman, and you're walking back to your, to your tribe, and you have this vision,

59:10.840 --> 59:17.160
you're struck with this vision of discovering fire. And so immediately, you get, you understand fire,

59:17.160 --> 59:26.280
but you also get this vision of steel weapons, artificial hearts, antibiotics, going to the

59:26.280 --> 59:32.920
moon, atom bomb, computers are like all of it, right? Immediately. So now the question is,

59:32.920 --> 59:36.520
so now your question is, so you've seen all this, right? You see, you see where it's going to go.

59:36.520 --> 59:42.120
Your question is, do you tell the others and you get going with fire or, or, or, or do you let it,

59:42.120 --> 59:47.640
do you let it die? And you never tell. Okay. 6% of my, my audience, and that's, and that's the

59:47.640 --> 59:51.320
people who like my stuff. So that means they're already probably like really biased towards,

59:51.320 --> 59:57.320
you know, techies stuff. 6% thought you shouldn't, you shouldn't let, you should stay below fire.

59:57.320 --> 01:00:03.320
So, okay, I don't know, you know, I don't know if, if these folks live a lifestyle consistent

01:00:03.320 --> 01:00:10.040
with that belief. I tend to doubt it. But, but, you know, it's, if, if that's the claim,

01:00:11.000 --> 01:00:16.200
I think you have to take this series. I think you have to say, if, if you really mean by playing

01:00:16.200 --> 01:00:20.760
God, I mean, what could it possibly mean? If you really mean taking steps that are

01:00:22.040 --> 01:00:27.000
strongly efficacious in the world and that make change, that do things, if you really don't want

01:00:27.000 --> 01:00:34.680
to do that, your quarrel is not with me and my work on frog skin. Your quarrel is with all of

01:00:34.680 --> 01:00:39.560
humanity who doesn't want to sit in a damp cave their whole life and die in exactly the same

01:00:39.560 --> 01:00:44.600
condition that they were born in. That's if, if you're really against that, okay, make your case

01:00:44.600 --> 01:00:50.840
and, and see, you know, and see, see if people will go. But none of the things that, that, that

01:00:50.840 --> 01:00:58.120
we're doing are any different from the fundamental question. Are you going to take responsibility

01:00:58.120 --> 01:01:05.080
for the future? And I think that is the most profound moral cowardice to delude yourself into

01:01:05.080 --> 01:01:09.960
thinking that doing nothing is staying out of it. No, doing nothing is not staying out of it.

01:01:09.960 --> 01:01:15.720
Doing nothing means you are complicit in the suffering of enormous numbers of humans and

01:01:15.720 --> 01:01:21.880
others on earth who are having a, an incredibly sub, a suboptimal experience in their, in their

01:01:21.880 --> 01:01:26.680
embodiment. And if, and if you have these kinds of thoughts about, let's not do this and let's not

01:01:26.680 --> 01:01:33.080
do that, you know, you know, let's put a break on progress, you are making a very clear statement.

01:01:33.080 --> 01:01:37.080
And, and you should think about it hard to make sure that you, you are, you know, you're, you're

01:01:37.080 --> 01:01:42.600
really backing off this idea that you are going to stay, you're going to let the status quo roll on

01:01:42.600 --> 01:01:47.160
because I, you know, it's just, to me, it's an incredible act of moral cowardice.

01:01:47.160 --> 01:01:53.080
Yeah. And I think for anyone who wants to even get a glimpse of what your ethical framework around

01:01:53.080 --> 01:01:57.880
all of this eventually becomes, this paper is perfect. I mean, this paper on AI, at some point,

01:01:57.880 --> 01:02:04.280
you go a path forward through the ethics filter for civilization. And this fundamental premise

01:02:04.280 --> 01:02:10.360
for you is, is to mature, to realize, okay, our kids supplant us, everything does change,

01:02:10.360 --> 01:02:16.040
we continuously change. It's how we're going to move forward. And, and how are we going to, to, to

01:02:16.040 --> 01:02:24.600
act in a certain way that progresses us in a, in a safer, more kind, more loving environment. And,

01:02:24.600 --> 01:02:29.000
and this, and the, the outward people, scientists don't like to use it. But I mean, at that point,

01:02:29.080 --> 01:02:34.280
you're looking towards this sort of kinder process where we were able to give artificial

01:02:34.280 --> 01:02:39.960
intelligence these properties, because it is something that our cognitive light can't appreciate.

01:02:39.960 --> 01:02:44.040
And we know that this is something we genuinely enjoy. So let's try and propagate this.

01:02:44.840 --> 01:02:50.520
Yeah. Yeah. And, and, you know, I have some collaborators. So, so Richard Watson and Thomas

01:02:50.520 --> 01:02:57.560
Doctor and Olaf Witkowski and, you know, people like Bill Dwayne and Eliza Salamanova, you know,

01:02:57.560 --> 01:03:02.360
we, we, we write on stuff like this, and there's going to be, there's going to be way more because

01:03:02.360 --> 01:03:06.600
in, in certain traditions, right? So for example, they come from a Buddhist tradition. And so,

01:03:06.600 --> 01:03:14.440
and so there, there's a great emphasis on enhancing compassion alongside enhancing wisdom, right,

01:03:14.440 --> 01:03:19.800
on a basically an infinite sea of other beings and all sorts of crazy embodiments. I mean,

01:03:20.280 --> 01:03:26.200
I gave a talk on all this stuff to, to some, to some Buddhist scholars in Nepal, you know,

01:03:26.200 --> 01:03:33.160
at some point. And I mean, that audience, there was nothing here that surprised them whatsoever.

01:03:33.160 --> 01:03:36.680
You know, usually when I give these talks, people are kind of, kind of shocked and disturbed about

01:03:36.680 --> 01:03:43.160
about half of what I say. These guys were like, yeah, no kidding, we all know that. And they

01:03:43.160 --> 01:03:49.240
found nothing, nothing weird about any of it. And I do think they have, they have frameworks for

01:03:49.320 --> 01:03:53.240
thinking about these, these, these kinds of things, right, you know, this kind of expanding,

01:03:53.240 --> 01:03:57.800
committing to through, through concepts like the bodhisattva vow and through expanding,

01:03:57.800 --> 01:04:03.080
committing to the task of this, this metacognitive task of expanding your, your cone of compassion

01:04:03.080 --> 01:04:07.880
and things like that. Yeah, I think, I mean, I'm certainly not saying that's the only way to go,

01:04:07.880 --> 01:04:13.160
but, but I think that's exactly where this is going. I agree with you. I mean, because my,

01:04:13.160 --> 01:04:19.560
even though I'm of Indian heritage and descent, but my, when I talk about science, philosophy,

01:04:19.560 --> 01:04:25.640
Western, particularly, to my family, to like them, certain uncles or aunts, and if I talk about these

01:04:25.640 --> 01:04:30.840
topics, they also tend to do that. They, they're not as surprised as, as the more my more Western

01:04:30.840 --> 01:04:34.760
side of the family. A lot of the Eastern philosophers and my uncles and aunts, they're not

01:04:34.760 --> 01:04:38.120
really philosophers, but they tend to think like, Oh yeah, that makes sense. That is kind of what

01:04:38.120 --> 01:04:43.640
their religion taught them, whether it's Hinduism or Buddhism, but there is this element of minds

01:04:43.640 --> 01:04:49.240
are everywhere in a way. So this, this, this general binary approach that we seem to have

01:04:49.240 --> 01:04:54.280
is not working for the most part. And you're showing this in very, very Western scientific ways.

01:04:55.080 --> 01:04:58.520
Well, I think, I think, I mean, that's the other thing, right? So, so I don't really believe,

01:04:58.520 --> 01:05:04.440
okay, there's, there's another perspective where sometimes people say, look, early indigenous

01:05:04.440 --> 01:05:08.680
societies knew all this, all we have to do is go back, go back there. I don't actually believe

01:05:08.680 --> 01:05:14.360
that either. I don't think they actually knew this. And right. And saying something is not the

01:05:14.360 --> 01:05:19.800
same thing as having a principal framework that takes you to new discovery. So, so it's, it's,

01:05:19.800 --> 01:05:26.280
I think both sides, this idea of there's no mind everywhere, anywhere except in us, or maybe some

01:05:26.280 --> 01:05:30.600
people think that just isn't anywhere. But, but the other side of it, which is, oh, there's a spirit

01:05:30.600 --> 01:05:36.360
under every rock. Like that's, that's a fine start, but it's just a start. You can't just say it and

01:05:36.360 --> 01:05:40.920
leave it at that. You have to answer the question, what does that do for you? So I think this is

01:05:40.920 --> 01:05:47.240
really important. All, all of this has to be empirically useful. It has to elevate our condition

01:05:47.240 --> 01:05:51.960
and has to improve our ability to, to have more meaningful lives in the world. It has to be

01:05:51.960 --> 01:05:56.920
practical. You cannot just say these things and have it mean anything until unless it leads you

01:05:56.920 --> 01:06:01.800
to experiments and ultimately to, to, you know, the better ways of being in the world.

01:06:02.360 --> 01:06:08.280
So I don't think we're going backwards to those traditions at all. I think we're using whatever

01:06:08.280 --> 01:06:12.200
we can scavenge out of all the, you know, brilliant people that have existed in the past that had

01:06:12.200 --> 01:06:17.960
sort of glimpses of this stuff. But, but now I think we finally have the ability to push it forward

01:06:17.960 --> 01:06:22.200
in a very practical way. So that some of these ideas we can, we can discard what isn't useful.

01:06:22.200 --> 01:06:26.280
We can, we can keep and expand what actually helps us to get to new capabilities.

01:06:27.080 --> 01:06:30.440
And I think that, and that's part of the approach that I appreciate most. I mean,

01:06:30.440 --> 01:06:33.640
I find it particularly annoying when people do that, what you're talking about, where

01:06:33.640 --> 01:06:38.920
these gurus come out and just say these things with no basis, absolutely no evidence of what

01:06:38.920 --> 01:06:44.680
there's no claim, but it's just so profound in itself. That's the statement itself is all that

01:06:44.680 --> 01:06:49.240
they have, which, which isn't what, what, what you're trying to do. You're often saying, you

01:06:49.240 --> 01:06:53.800
got to show, you got to do something, back it up somehow. I mean, I mean, these, these claims

01:06:53.800 --> 01:06:59.480
and these profound statements and, you know, and poems and whatever else, they're, they're a fine

01:06:59.480 --> 01:07:06.280
tool for spurring intuition and for giving you ideas that it's the starting point, right? And,

01:07:06.280 --> 01:07:12.760
and, and I, and I do think that it's true that it's possible to have intuitions about things and,

01:07:12.760 --> 01:07:19.800
and to come up with prompts, you know, sayings and writings and whatnot that trigger other

01:07:19.800 --> 01:07:24.360
people into new and interesting thoughts, even though you haven't yet worked out all the details.

01:07:24.360 --> 01:07:28.600
I mean, I do think that's possible. I do think it's, you know, we are kind of like, so I have this,

01:07:28.600 --> 01:07:35.080
like, almost, almost like, like the way, um, platonist mathematicians, you know, they feel

01:07:35.080 --> 01:07:39.640
that they're discovering an existing structure, right, of that, that you're uncovering an existing

01:07:39.640 --> 01:07:43.640
structure and that, you know, you see, you know, sort of piece by piece, pulling it out.

01:07:44.440 --> 01:07:50.920
I do think that it's possible to, to, to sort of have insights long before you have the wherewithal

01:07:50.920 --> 01:07:55.800
to really make it practical or to know what it means or any of that. And so, and so I like that

01:07:55.800 --> 01:08:01.160
stuff as much as anybody in terms of an intuition, you know, building kind of thing to see what it

01:08:01.160 --> 01:08:04.680
makes you think about, like the, like the quote from William James, right? I don't know. And I

01:08:04.680 --> 01:08:08.760
lose no sleep over whether he actually meant that the way that I mean it. I don't care. I think,

01:08:08.840 --> 01:08:13.480
I think it's a very profound saying. And what can we do with it now? But, um, you know, the hard

01:08:13.480 --> 01:08:18.840
work comes, comes after all that. Someone, it reminds me of, and I mean, we, we lost him recently,

01:08:18.840 --> 01:08:26.120
Daniel Dennett, raised him, he, he, what you do is almost the reverse, but in, in, in the same,

01:08:27.320 --> 01:08:34.680
I would say, in the same great manner is that what, what Dan did was he realized that you

01:08:34.680 --> 01:08:39.160
can't just philosophize. You, you have to go and you have to get involved with the cognitive

01:08:39.160 --> 01:08:44.040
science. You've got, you've got to get, you've got to basically do some of the work. And, and,

01:08:44.040 --> 01:08:47.960
and that's when the philosophy becomes a lot more intriguing is when you do the science and you go

01:08:47.960 --> 01:08:53.240
into it and you fuse them and you're coming from it from the science side. And then, of course,

01:08:53.240 --> 01:08:57.560
you then have to have the philosophical discussions with it. And, and you guys have worked very

01:08:57.640 --> 01:09:00.600
closely together. What is that like for you just as a side?

01:09:02.680 --> 01:09:09.960
Boy, I mean, first things first, you know, I, I read Dan's books when I was a kid. And it never,

01:09:09.960 --> 01:09:14.760
I mean, they were so eye-opening, you know, the mind's eye and kinds of minds and that kind of

01:09:14.760 --> 01:09:20.360
stuff, right? The early kind of the early work in the late 80s, early 90s. I was, I was young

01:09:20.360 --> 01:09:25.720
back then. And I would, I couldn't have imagined for a moment, a that I would, that I would get to

01:09:25.720 --> 01:09:29.320
meet him, never mind that, but be that at some point, you know, at some point, we'd write a paper

01:09:29.320 --> 01:09:34.040
together, right? Like, I wish I could get into a time machine and go back and, you know, tell my

01:09:34.040 --> 01:09:37.400
18-year-old self that, hey, you know, you're going to write a, write a paper with this guy and

01:09:37.400 --> 01:09:42.840
actually a bunch of other people to that, that I felt the same way about. So, so, so that part was

01:09:42.840 --> 01:09:48.040
a profound kind of honor for me is to, is to be able to talk to him about these stuff. And, and

01:09:48.040 --> 01:09:52.360
by the way, we didn't agree on everything. We, we disagree on a ton of stuff, but

01:09:53.240 --> 01:10:01.960
he was, he was an incredibly generous, clear thinker. And what I really enjoyed about him was

01:10:01.960 --> 01:10:08.840
that was, was a few things. One of them was that he was never interested in, in making cheap points.

01:10:08.840 --> 01:10:13.240
He was always interested in improving everybody's understanding of what's going on, deepening the

01:10:13.240 --> 01:10:18.360
question. It may be the answer, but for sure, deepening the question. And this idea, you know,

01:10:18.360 --> 01:10:23.080
he really pushed this idea of steelmaning. You know, he said that, that in arguing with people,

01:10:23.080 --> 01:10:29.160
what you ought to do is first state their position so well and so strongly that they will wish they

01:10:29.160 --> 01:10:33.560
came up with it, right? That you should start not, not with a caricature of what they think that

01:10:33.560 --> 01:10:37.640
you're going to shoot down, because that, that's a game, right? That's, that's, you know, what he

01:10:37.640 --> 01:10:43.960
wanted was actual progress, which meant you better start with the absolute best description of their

01:10:43.960 --> 01:10:47.720
view, the most plausible sounding this, and then, then see if you can shoot it down after that,

01:10:47.720 --> 01:10:51.880
right? That was his, that was his, and he was always that way in all, in all of our discussions,

01:10:53.080 --> 01:10:56.520
you know, about stuff that we did agree on and lots of things that we didn't agree on.

01:10:56.520 --> 01:11:03.880
It was, it was always very clear that everybody in this discussion is there to, to learn something

01:11:03.880 --> 01:11:08.440
and to improve and to give up things that you thought before, if, if they're not helping you

01:11:08.440 --> 01:11:13.080
move forward and grab some, some other tool like that, that was, you know, he was an amazing

01:11:13.080 --> 01:11:16.600
example of that. And I mean, at first, well, first I took a course with him as an undergraduate at

01:11:16.600 --> 01:11:21.880
Tufts, I had him for, for, for a, yeah, I had him for a, for a philosophy of mind professor,

01:11:21.880 --> 01:11:26.760
which was, which was amazing. I purposely wrote a paper, there was a, there was a final paper

01:11:26.760 --> 01:11:31.960
for the class that you, that you write, I picked a topic that I knew he did not like, and that I

01:11:31.960 --> 01:11:38.440
knew he, you know, was, was completely against. And, and I was, I was astounded at, you know, the,

01:11:38.440 --> 01:11:44.920
the fair, rigorous, but, but, but completely fair, you know, analysis and grade and everything

01:11:44.920 --> 01:11:49.640
else. That was an example for me that this is how you do it. This is, you know, it's not,

01:11:49.640 --> 01:11:55.480
it's not just based on what, you know, what you think, but like, you know, a deep analysis of,

01:11:55.480 --> 01:11:59.400
of the, the fairest analysis. And then, and then later when I came back to Tufts as a faculty

01:11:59.400 --> 01:12:03.000
member, you know, he was, he was a, he was a colleague and that was, that was incredible.

01:12:03.000 --> 01:12:07.000
So yeah, yeah, I'm really going to miss him. Yeah, no, he'll be dealing with, I mean, he was one

01:12:07.000 --> 01:12:11.160
of the, so him and Oliver Sacks were two of the people that inspired me to even start this podcast.

01:12:11.160 --> 01:12:16.040
So one of those, yes, I never got to have on, but we exchanged emails every now and then.

01:12:16.040 --> 01:12:20.680
And even doing that for me felt like such an honor. And I really wish I had the chance to

01:12:20.680 --> 01:12:23.720
chat to him. That's how I'm just so curious for all those people who did get to speak to him.

01:12:24.520 --> 01:12:26.600
What a, what a provision might have been to pick his brain.

01:12:27.240 --> 01:12:32.280
Yeah. Oh no, it was, and he was so, you know, he was so, so inspirational and so generous with

01:12:32.280 --> 01:12:37.880
his ideas. He would come to our lab from time to time. And I have, I have a picture of him on

01:12:37.960 --> 01:12:41.240
the blog with what during one of his visits, you know, and he's, and he was looking through

01:12:41.240 --> 01:12:44.120
the microscopes and he was looking at our two headed worms that we would have these,

01:12:44.120 --> 01:12:47.000
he would have these discussions with our lab people about, you know, what's that,

01:12:47.000 --> 01:12:50.520
what's it like to be a creature with two brains and what's the right way to think about these things?

01:12:50.520 --> 01:12:55.240
And, and, you know, and yeah, he would, you know, he would give talks just, just very generous,

01:12:55.240 --> 01:12:59.000
you know. Mike, you must, you must check, you must look out for this one of these videos online.

01:12:59.000 --> 01:13:05.480
It's a VPRO roundtable with Dan, Dan Dinnett, Oliver Sacks, Rupert Sheldrake,

01:13:07.320 --> 01:13:11.960
Steven, it's one of the most fascinating things. It's like six, I think,

01:13:13.080 --> 01:13:18.360
Dyson, Freeman Dyson was there as well. It's, it's such a strange thing. It's like the original

01:13:18.360 --> 01:13:24.360
version of podcasting, I would say. Just six of these guys is having the coolest chat on life,

01:13:24.360 --> 01:13:29.320
consciousness, reality. That was one of the things that got me into the two of their,

01:13:29.320 --> 01:13:34.520
both of their work and to this podcast. But anyway, before we, because we're digressing a bit,

01:13:34.520 --> 01:13:37.640
the path forward, this ethics, how are we doing for time? Mike, you all right?

01:13:38.920 --> 01:13:41.800
Yeah, I'm, yeah, okay. I got about, I got about 15 minutes.

01:13:41.800 --> 01:13:47.320
Good. Okay. For the, the path forward, the ethics falter, let's talk about this,

01:13:47.320 --> 01:13:51.320
because you said that there's, there's two ways we could get this wrong. One is object

01:13:51.320 --> 01:13:57.400
affiliate. And the other one is, well, only love your own kind. Let's talk about how we can get

01:13:57.400 --> 01:14:04.360
this wrong and how we can actually divert this and get this right. Yeah. Well, the, the, the,

01:14:04.360 --> 01:14:10.760
the spectrum itself is something like the, it's, it's, it's related to the effort of matching the

01:14:10.760 --> 01:14:19.640
degree of compassion that you are able to exert to the level of agency that there are intelligence

01:14:19.640 --> 01:14:25.000
or consciousness that, that that being actually has, right? Now, I'll point out that, that we, even

01:14:25.000 --> 01:14:29.160
when we get it right, we are still not very good at following through on the consequences. So,

01:14:29.160 --> 01:14:33.000
so for example, everybody understands that pigs are intelligent. Everybody understands that they,

01:14:33.000 --> 01:14:37.000
that they suffer, that they have minds, and we still have factory farming. It's, it's right. So,

01:14:37.000 --> 01:14:43.240
so even, you know, getting it scientifically right is absolutely not a guarantee of anything

01:14:43.240 --> 01:14:49.240
in terms of actual ethical behavior. But, but there's two ways to get it wrong. One way to get

01:14:49.240 --> 01:14:59.240
it wrong is to attribute more mind to a system than it really has. But also when I say really has,

01:14:59.240 --> 01:15:02.680
I, I, you know, I think everything is observer relative, of course, but, but still you, you

01:15:02.680 --> 01:15:06.120
could get, I mean, there's, you know, the internet is full of profiles of people that are in love

01:15:06.120 --> 01:15:11.960
with bridges and chandeliers and, and, you know, and things like this. So, so, so that's, that's

01:15:11.960 --> 01:15:16.440
something having too much, too much concern for things that really don't warrant it. And the

01:15:16.440 --> 01:15:21.800
other way is, of course, the opposite is when you've, you leave beings out of your, of your, of

01:15:21.800 --> 01:15:27.560
your calculus of compassion that actually can, can suffer and have an inner perspective. I mean,

01:15:27.560 --> 01:15:34.280
one, one thing to think about is if imagine two societies that get this wildly wrong in both directions.

01:15:34.280 --> 01:15:38.680
So you've got a planet where everybody's like, you know, ridiculously nice to, to, you know,

01:15:38.680 --> 01:15:43.000
they don't like to chop rocks in half and whatever. And, and, and then there's, and then

01:15:43.000 --> 01:15:49.080
there's the other society that thinks if, if you're not a very narrow type of creature, you are a

01:15:49.080 --> 01:15:53.720
machine the way that Descartes thought about lots of animals, and that we can do whatever we want,

01:15:53.720 --> 01:15:57.720
and it's fine. And you're just faking and all the, all your complaining about it is, is just,

01:15:57.720 --> 01:16:03.080
you know, it's just a word, where it's, it's, it's sentence completion, you know, is what it is. So,

01:16:03.800 --> 01:16:07.720
okay, so, so which of those worlds would you rather live in? Right? If you're going to get it,

01:16:07.720 --> 01:16:12.040
if you're going to get it wrong, where, where would you rather be? I mean, I think, I think the

01:16:12.040 --> 01:16:20.360
first one wastes a lot of resources and opportunities. Yeah, okay. The second one is, is, is monstrous in,

01:16:20.360 --> 01:16:26.920
in its ethical implications. So, so I, I think we should err on the side of more compassion,

01:16:26.920 --> 01:16:31.240
not less. I mean, obviously, again, we're not going back to there's a spirit under every rock,

01:16:31.240 --> 01:16:37.240
because we are committed to having principled theories about this. But if you're going to

01:16:37.240 --> 01:16:42.360
make a mistake, I think you should make a mistake in that direction. And specifically,

01:16:42.360 --> 01:16:47.080
what I'd like us to be clear on, I'd like what I'd like everybody to be clear on,

01:16:47.080 --> 01:16:53.000
is that having certainty about these things right now, when we have pretty much no clue

01:16:53.000 --> 01:16:59.080
what underlies consciousness, really, I mean, I know a lot of smart people have made efforts

01:16:59.080 --> 01:17:04.920
into it, but, but I really don't think we have it nailed down. And all of these ideas about

01:17:05.480 --> 01:17:11.960
what cognition is and how different architectures, you know, supported and, and whether cognitive

01:17:11.960 --> 01:17:16.200
consciousness and the ability to suffer tracks any of those things or not.

01:17:18.680 --> 01:17:23.080
There is, there's an enormous amount of unwarranted certainty about this among people,

01:17:23.080 --> 01:17:27.000
people feel very strong to make this really strong. That definitely doesn't whatever,

01:17:27.000 --> 01:17:32.760
you know, it doesn't have this or that. I think we all need to take a step back and just understand

01:17:33.160 --> 01:17:38.680
that from, from, from the scientific perspective, there are so many things we do not know yet,

01:17:38.680 --> 01:17:44.520
like really critical fundamental things. We do not understand the emergent cognitive properties

01:17:44.520 --> 01:17:50.360
of matter. We do not understand the scaling policies of how minds emerge from smaller minds.

01:17:51.320 --> 01:17:56.280
The field of diverse intelligence is just getting started. So I'm much more worried about the right

01:17:56.280 --> 01:18:00.920
side of that, of that spectrum than I am about the left side at this point.

01:18:01.800 --> 01:18:05.640
And I think what one of your towards the end of the paper, one of the things you says,

01:18:05.640 --> 01:18:10.440
the question is, how do we make sure to express kindness to the inevitable forthcoming wave

01:18:11.400 --> 01:18:17.320
of unconventional sentient beings? And you say that we should start by making sure that we express

01:18:17.320 --> 01:18:23.320
loving kindness appropriately and not be driven by fear of the other, which is, which is a very

01:18:23.320 --> 01:18:29.320
beautiful statement. Yeah, thanks. I've actually written a whole thing on fear just now. I'm

01:18:29.320 --> 01:18:34.600
waiting. It's going to be, it should be out in a couple of weeks. I think that, well, well,

01:18:34.600 --> 01:18:39.560
one thing I could say is after that, after that piece in Noeima, so there was the short piece

01:18:39.560 --> 01:18:43.960
in Noeima about the AI, there's a much, there's a longer paper which exists as a preprint and

01:18:43.960 --> 01:18:49.080
it's also in review right now in the journal. But I think more people saw the Noeima piece.

01:18:49.080 --> 01:18:56.200
But still, I was very clear there. I thought that I'm not actually saying that AI is that

01:18:56.200 --> 01:18:59.320
current language models are like humans. I mean, I thought I was pretty clear on this.

01:19:00.120 --> 01:19:09.240
But I got a lot of people writing to me that basically extremely disturbed by this and this

01:19:09.240 --> 01:19:21.160
idea that tech bros like myself are, I thought that was funny, that our nerdiness sort of prevents

01:19:21.160 --> 01:19:28.040
this from understanding real human relationships. And this is why we see these things in what they

01:19:28.040 --> 01:19:33.640
call machines, robots, AIs and whatever, right? They were looking for a, they were looking for

01:19:34.360 --> 01:19:36.200
why you do this in a sense.

01:19:37.960 --> 01:19:42.600
Correct. I mean, it's an old strategy, right? The old strategy is if you're uncomfortable with a view,

01:19:42.600 --> 01:19:47.480
try to find something wrong with, right? What is it that, you know, we see the truth. Why can't

01:19:47.480 --> 01:19:52.600
they see the truth? What is missing that causes them to say these things, right? And the standard

01:19:52.600 --> 01:19:58.760
theory is, well, they just don't understand, you know, these nerds don't understand what real human

01:19:58.840 --> 01:20:04.680
relationships are like, right? And that, I mean, I'm not super interested in

01:20:04.680 --> 01:20:10.520
in psychoanalyzing anybody that way. But it did, it did cause me to think, I'm like, wow,

01:20:10.520 --> 01:20:14.280
why are people so triggered by this? You know, what, what is it that caught, you know, to really,

01:20:14.280 --> 01:20:18.520
and so, and so I, so, so I'm thankful for once the pay, pay, you know, peace comes out, I'll

01:20:18.520 --> 01:20:22.840
thank some folks in, in who said these things and actually pushing me in what I thought was,

01:20:22.920 --> 01:20:29.560
think is an interesting direction is to ask, what, what is it? What is it that's so scary about,

01:20:29.560 --> 01:20:35.240
about this view? And the more I think about it, I really think it's a very fundamental fear.

01:20:35.240 --> 01:20:42.440
And the fear is, it's a zero sum game. Love is a zero sum game. If we have too many other

01:20:42.440 --> 01:20:47.640
beings that need love, then a couple of things will happen. There's not enough for me, that's A,

01:20:47.640 --> 01:20:53.160
and B, what if I can't rise to the, to the, to the challenge of having enough compassion

01:20:53.160 --> 01:20:58.440
for everybody? I think it's profoundly threatening to realize that you're going to have to open up

01:20:58.440 --> 01:21:05.720
your, your constrained way of looking at who deserves your compassion and what happens then.

01:21:05.720 --> 01:21:09.720
And, and then, and many other things. So, you know, so I wrote that on this probably five or

01:21:09.720 --> 01:21:15.320
10 pages or something about, you know, just kind of talking about what is really what I think

01:21:15.320 --> 01:21:20.040
really underlies why, why people are freaked out about this. And, and, and the responsibility,

01:21:20.040 --> 01:21:26.120
I mean, it's very comforting to think that I can just tell, you know, which things are worth worrying

01:21:26.120 --> 01:21:30.520
about by looking at them. I know what people look like. I'll just look at them. It's comforting to

01:21:30.520 --> 01:21:35.800
think that I don't need to be responsible for the future. This, this is it. This is, you know,

01:21:35.800 --> 01:21:40.360
this is how, this is what's natural, right? Even people who don't believe in, in some,

01:21:40.360 --> 01:21:44.280
some sort of God, all they, they still have this notion of what's natural. I have no idea what

01:21:44.280 --> 01:21:48.040
that's supposed to mean. But, but, but, you know, this is like, yeah, this is how we're supposed

01:21:48.040 --> 01:21:52.120
to stay. And that's fine. I don't, I don't need to be responsible for the future. And I don't need

01:21:52.120 --> 01:21:58.680
to be responsible for shaping what the planet looks like in the, you know, in, in the coming

01:21:58.680 --> 01:22:03.560
centuries and beyond. That's comforting to think that it's all handled. It's nice and simple.

01:22:04.120 --> 01:22:08.600
You don't need these, these extremely difficult nuanced views that are going to require work

01:22:08.600 --> 01:22:12.440
from you. They're going to require you to make hard decisions to paint a picture of

01:22:12.440 --> 01:22:17.240
the future of what do you want it to look like? You know, it's much easier to say what you don't

01:22:17.240 --> 01:22:22.200
want. This, this fear-based scarcity mentality, right? There's not enough love to go around.

01:22:22.200 --> 01:22:25.800
Let's, let's, let's draw a nice tight circle around things that we know what they look like

01:22:25.800 --> 01:22:28.680
and we know where they came from. Then we're not going to have to worry about all this other

01:22:28.680 --> 01:22:33.320
stuff that's really difficult to, to figure out what's, what's going on with it. And yeah,

01:22:33.320 --> 01:22:41.080
and then we don't need to worry about painting pictures of the, of the future and figuring

01:22:41.080 --> 01:22:45.000
out how to get there. We could just, we can just make a list of what we don't want to have happen

01:22:45.000 --> 01:22:49.320
and that's easy and, and, and focus on the negatives. So I think, I think that that type of,

01:22:49.320 --> 01:22:55.960
that type of limited fearful scarcity kind of mindset is, is what's, is what's responsible

01:22:55.960 --> 01:23:00.120
for a lot of this. And by the way, what I don't mean, so I, so I want to be clear here, I don't

01:23:00.120 --> 01:23:07.080
mean to, to try to deconstruct some of my colleagues that are really working on, on very good science,

01:23:07.080 --> 01:23:11.480
right? So, so there are people who are working on good science for developing principled

01:23:11.480 --> 01:23:16.520
ways to distinguish between so-called machines and what's special about living organisms,

01:23:16.520 --> 01:23:20.200
like that, that's a good area of diverse intelligence. I'm not, I'm not, you know,

01:23:20.200 --> 01:23:23.640
are saying that that shouldn't, you know, that, that shouldn't take place or, or that they're

01:23:23.640 --> 01:23:27.800
driven by anything other than, you know, good scientific principles. I'm talking about them,

01:23:27.800 --> 01:23:31.880
you know, I'm talking about the, the folks who have a really visceral reaction who

01:23:31.960 --> 01:23:39.320
when, when I, when I challenged them to, so, so, so, so be explicit. So, so tell me what,

01:23:39.320 --> 01:23:43.720
what is the magic that you have? And when did you get it? Both during evolution, during,

01:23:43.720 --> 01:23:47.320
during, you know, during embryogenesis, what, what, what, what do you have? And when does this

01:23:47.320 --> 01:23:52.840
show up that you think cannot be either, either in a hybrid form or in synthetic form, you know,

01:23:52.840 --> 01:23:56.840
done? And what would you do if, I mean, just, you know, I think reading science fiction is,

01:23:56.840 --> 01:24:01.400
is a great cure for this, because from the, from the earliest time, you understand the scenario,

01:24:01.400 --> 01:24:05.480
right? You're, you're, you're sitting there at home, this spaceship lands on your front lawn,

01:24:05.480 --> 01:24:09.000
this, this, the door opens, this thing sort of trundles out, it's kind of shiny looking,

01:24:09.000 --> 01:24:12.600
it's kind of metallic looking, but it sort of comes up to you and it sort of hands you this

01:24:12.600 --> 01:24:16.040
poem and it says, oh man, I'm so happy to meet you, you know, it's been, it's been,

01:24:16.040 --> 01:24:19.880
it's been, you know, a thousand years I was waiting to meet you, many of us died along the way, but,

01:24:19.880 --> 01:24:23.720
you know, but, but we persevered and we made this journey in here. I wrote you this poem and I'm

01:24:23.720 --> 01:24:27.160
looking to be friends and you sort of knock on and it's kind of metallic and you say,

01:24:28.040 --> 01:24:34.200
so, did you guys evolve naturally or did somebody make you? And he says, you mean,

01:24:34.200 --> 01:24:39.240
you mean, are we the result of totally random processes or was our mind crafted by, you know,

01:24:39.240 --> 01:24:42.920
some other mind? And he said, yeah, I'd really like to know and say, why, why do you want to know

01:24:42.920 --> 01:24:47.240
that? Like, well, just, you know, I'd really like to know because, and in the back of your mind,

01:24:47.240 --> 01:24:50.520
you're thinking, what, that, that, that if it's the, that if it's the latter, then, then you're

01:24:50.520 --> 01:24:53.800
okay with turning it into a vacuum cleaner, right? That's what you're really thinking about.

01:24:53.880 --> 01:25:00.520
And, and I mean, I, I, I find that just, just, you know, absurd. And we are all stuck in this

01:25:00.520 --> 01:25:06.120
position of saying, so what, what criteria are you going to use when you can't do this easy

01:25:06.120 --> 01:25:10.120
thing? That's why, that's why I think AI and language models are such an off ramp for these

01:25:10.120 --> 01:25:14.840
discussions, because it's just so easy to dunk on these language models, completely avoiding this

01:25:14.840 --> 01:25:19.720
issue of that embodiment can take a place in other spaces that you have absolutely no idea

01:25:19.800 --> 01:25:23.800
what, what, you know, physical systems are capable, even if, even if you made it yourself.

01:25:25.080 --> 01:25:29.400
Yeah. And even that in itself, and when you spoke about it, when you said, if you use AI

01:25:29.400 --> 01:25:34.200
to create something, I mean, who really created it? And then you have that wonderful quote where

01:25:34.200 --> 01:25:40.200
you say like, nothing was ever created by two men. We're merely sort of just adding upon what's

01:25:40.200 --> 01:25:49.080
already there. Yeah. Yeah, I think, I think we really need to be clear that there are major,

01:25:49.080 --> 01:25:54.040
major open questions here, like really fundamental open questions. It's too early to be certain of

01:25:54.040 --> 01:25:58.600
anything other than, I mean, I think the only thing we can be certain of is that it's very easy

01:25:58.600 --> 01:26:03.480
to make ethical lapses when you try to draw these distinct boundaries and you have no idea what you're

01:26:03.480 --> 01:26:23.880
doing.

