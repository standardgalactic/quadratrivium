1
00:00:00,000 --> 00:00:08,080
Hello. Sorry, she said waving the book. Welcome to the latest AQR webinar and welcome to Nick

2
00:00:08,080 --> 00:00:15,760
Salsgate and Nick Chater. I'm very kindly come on board to discuss Nick Cee's latest book.

3
00:00:16,480 --> 00:00:23,440
This one, The Mind is Flat, which he's just told us, has won the US prose award for best book

4
00:00:23,440 --> 00:00:32,240
in clinical psychology. So many congratulations for that. Nick Salsgate, or I can hear a corner,

5
00:00:34,640 --> 00:00:40,560
partook of our last webinar. So he's an old hand at this and he says he's a

6
00:00:40,560 --> 00:00:46,160
philosopher turned advertising planner, turned into some sort of hybrid creature

7
00:00:46,160 --> 00:00:49,600
by work at the School of Life and the Institute of Practition as an advertiser.

8
00:00:50,560 --> 00:00:55,200
Nick Chater is Professor of Behavioural Science and Pathology at the School.

9
00:00:56,080 --> 00:01:02,320
He's on the advisory board of the Nudge Unit. He also broadcasts regularly on BBC Radio 4,

10
00:01:02,320 --> 00:01:11,360
has hundreds of publications on his under his belt and runs a, I meant to ask, what is an M00C?

11
00:01:11,360 --> 00:01:17,520
On the Shocking Shallowness of Human Psychology on Future Learn. Anyway, this is about The Mind

12
00:01:17,520 --> 00:01:25,360
is Flat, the relevance to qualitative research. So I will leave you to it there with me when I

13
00:01:25,360 --> 00:01:37,920
disappear off the screen, hopefully. And Feta Black-Luella. So what a little phase into the background.

14
00:01:38,800 --> 00:01:45,360
So Nick, thanks for joining us. I was reflecting on this. It's about 10 years since we first met

15
00:01:45,440 --> 00:01:52,160
doing work at the IPA. So and it was very exciting to see you publish your now award winning book.

16
00:01:52,960 --> 00:01:56,720
So all those conversations I never got to finish with you because you were rushing somewhere else.

17
00:01:56,720 --> 00:02:04,000
A lot of it was in the book. But what I'm interested in is it strikes me it's quite a personal book in

18
00:02:04,000 --> 00:02:12,240
that it's not just built out of your research, but it's built out of your sort of more profound

19
00:02:12,240 --> 00:02:17,520
beliefs or your deeper beliefs. So I was just interested to start by asking you how you came

20
00:02:17,520 --> 00:02:22,080
to write a book called The Mind is Flat for me. And then we're getting to watching Mead by The

21
00:02:22,080 --> 00:02:28,720
Mind Being Flat. Yes, that's a good question. I think it comes from a couple of sources. One is

22
00:02:28,720 --> 00:02:35,360
that my starting point in the academic world when I did my PhD was the world of cognitive science.

23
00:02:35,360 --> 00:02:40,240
And that's the project of trying to build computer models of the mind. So it's sort of like artificial

24
00:02:40,240 --> 00:02:46,080
intelligence. Your aim is to build models that are like people. And a very natural strategy to do

25
00:02:46,080 --> 00:02:50,240
that is to think, well, what we need to do is to work out what people's beliefs are, what they know

26
00:02:50,240 --> 00:02:54,800
about the world, and also what they like, what they want, what they don't like. So we try and get all

27
00:02:54,800 --> 00:02:59,680
this out of people's heads. And then we put it into a computer program and try and figure out

28
00:02:59,680 --> 00:03:04,640
what the program would like to do. So it seems like a sensible strategy and between before

29
00:03:04,880 --> 00:03:10,800
about from 1980 or so, it was probably the most popular strategy and artificial intelligence.

30
00:03:10,800 --> 00:03:19,120
I came into the field in I suppose about 1986 as a PhD student. So I was in the sort of latter

31
00:03:19,120 --> 00:03:24,240
phases of this project. And it was very influential on me to think that when people tried to do this,

32
00:03:25,760 --> 00:03:30,960
it always seemed to go horribly wrong at the very first stage. So you'd think, I want to know how

33
00:03:30,960 --> 00:03:34,960
to play chess. I want to make a computer that can play chess. So I need to talk to some grand

34
00:03:34,960 --> 00:03:38,720
masters. I mean, they're really good at chess. They must know loads about this. So they'll just

35
00:03:38,720 --> 00:03:42,960
tell me what the strategies they're using are. And I'll put it into my computer and off it will go.

36
00:03:42,960 --> 00:03:47,520
But in fact, it turns out that's a disastrous approach, partly because the grand masters have no

37
00:03:47,520 --> 00:03:52,880
idea what they seem to know. They tell you different things on different days. Most of the time they

38
00:03:52,880 --> 00:03:57,280
just say, well, that's obviously a silly move. You wouldn't want to do that. But they can't really

39
00:03:57,280 --> 00:04:03,680
tell you why. But not only that, they also, the things they can tell you turn out to be rapidly

40
00:04:04,320 --> 00:04:09,200
to lead to inconsistencies. So they'll tell you a few things like, well, a good rule of thumb is x,

41
00:04:09,200 --> 00:04:12,880
good rule of thumb is y. And then you say, yeah, but wait a minute, what about this case where

42
00:04:13,520 --> 00:04:17,040
they seem to give different answers? And that happens immediately, all the time.

43
00:04:17,920 --> 00:04:23,360
And we see this, of course, with ethics. So you think about the general punches we have with

44
00:04:23,360 --> 00:04:28,720
ethics. We're always struggling with things like, well, of course, we want to avoid suffering,

45
00:04:28,720 --> 00:04:35,360
that's terrible, we must reduce suffering. But on the other hand, we want to maintain autonomy.

46
00:04:35,360 --> 00:04:40,000
So we don't want to find ourselves. So that creates ethical dilemmas where people are extremely ill

47
00:04:40,000 --> 00:04:44,480
or suffering terribly. So we don't quite know what to do about that. All of the ethical challenges

48
00:04:44,480 --> 00:04:48,080
that we face now, I've said just illustrations of this fact that the sooner we think about anything

49
00:04:48,080 --> 00:04:53,280
tricky, we realize, oh, no, my beliefs, my preferences, my values, my principles are in

50
00:04:53,280 --> 00:04:59,520
contradiction. To the extent that I can formulate them at all. So just to where that got me to the

51
00:04:59,520 --> 00:05:06,240
thinking about the mind is flat, or the title of the mind is flat, is the old sort of artificial

52
00:05:06,240 --> 00:05:11,360
intelligence perspective would be, you don't quite know what your beliefs are, you don't

53
00:05:11,360 --> 00:05:15,680
quite know what your preferences are, and your principles are. But that sort of whatever's in

54
00:05:15,760 --> 00:05:20,080
your head, it's a bit, it's beliefs and principles and preferences and things like that. There's lots

55
00:05:20,080 --> 00:05:24,080
on. And, you know, the more you think about them, the more you think, oh, I've forgotten about this

56
00:05:24,080 --> 00:05:28,800
one. Oh, I remember that one. And you can tell a longer and longer story about what these preferences

57
00:05:28,800 --> 00:05:35,040
and beliefs are. But I think it's an illusion to think that these stories are actually reflecting

58
00:05:35,040 --> 00:05:39,920
what's in your head. What they are is creative enterprises. They're a creative endeavor. If

59
00:05:39,920 --> 00:05:44,160
you try to understand yourself, in the moment, at the very moment, you're thinking,

60
00:05:44,960 --> 00:05:49,280
well, why did I make that move? Or why is this wrong? But that's not wrong.

61
00:05:49,280 --> 00:05:51,600
Then that's the point at which I'm inventing the story.

62
00:05:52,160 --> 00:05:57,760
So I think what you're saying there is that rather than this, so it's in folks sort of

63
00:05:57,760 --> 00:06:02,560
folk psychological terms, we can say comfortably enough, people do have beliefs and preferences,

64
00:06:02,560 --> 00:06:09,120
and they know things. But the idea that they are somehow stitched together underneath in a coherent

65
00:06:09,200 --> 00:06:15,120
or near coherent whole, that seems to be where your suggestion is they don't lie underneath,

66
00:06:15,120 --> 00:06:19,760
stitched together. We stitch them together as we go. Yes. It's a mention in the moment because

67
00:06:19,760 --> 00:06:27,600
you talk a lot in the book about the improvising mind. Yes. Now, that's exactly right. So I think

68
00:06:27,600 --> 00:06:31,040
we should think of ourselves as rather like fictional characters. So again, one of the things

69
00:06:31,040 --> 00:06:37,120
that comes up a lot in the book is the analogies with fiction. And I think when we're reading a book,

70
00:06:37,120 --> 00:06:41,680
we have a really a real sense of the depth of the characters and our motivations. I'm not quite

71
00:06:41,680 --> 00:06:47,280
sure about all our motivations. We have a sense that they're sort of deep, interesting, rich things.

72
00:06:47,280 --> 00:06:52,800
And indeed, we ourselves are deep, interesting, rich things in a sense. But the sense of depth

73
00:06:52,800 --> 00:06:59,920
can't be that inside the head of the character, say Anna Karenader or Sherlock Holmes, there are

74
00:06:59,920 --> 00:07:04,240
real beliefs and desires and principles. Because of course, this is a fictional character, they

75
00:07:04,240 --> 00:07:10,640
don't have a brain. It's nothing inside. But from the scraps of information we know about that

76
00:07:10,640 --> 00:07:16,160
person, we are able ourselves to weave a complicated story about why they did this and why they thought

77
00:07:16,160 --> 00:07:19,760
that and probably they would have done this in a different situation. And we can do that about

78
00:07:19,760 --> 00:07:25,760
ourselves too. And I think we can do it for the same reason. So we're observing our own lives flow

79
00:07:25,760 --> 00:07:30,320
by, we're observing the people around us. And we understand ourselves in just the way we understand

80
00:07:30,320 --> 00:07:35,680
fictional characters or other people by improvising stories. I think the illusion is thinking, no,

81
00:07:35,680 --> 00:07:40,720
no, when I'm understanding myself, I look inside, you know, I just, there's all this coherent stuff

82
00:07:40,720 --> 00:07:45,600
in my head. And I just have a good, a good nose around in my own brain. And I think that's something

83
00:07:45,600 --> 00:07:49,040
we just simply can't do at all. And it's sort of, sort of, we know this. I mean, if you ask me

84
00:07:49,040 --> 00:07:59,120
something like, I don't know, for example, why, why, why do I, why do I do by one thing rather

85
00:07:59,200 --> 00:08:03,280
than another thing? So I'm say, why do I, you know, why have I got a particular broadband

86
00:08:03,280 --> 00:08:08,080
provider or something really not terribly like that? I think, God, you've got me there. Well,

87
00:08:08,880 --> 00:08:12,800
I can tell you something historical about what I used to have. And I didn't get on very well with

88
00:08:12,800 --> 00:08:17,680
them. And I don't know why I switched to this one, but I can give you a story. And I know it's not,

89
00:08:17,680 --> 00:08:22,480
this is not a thank you a story. It's useful stuff to know. But the idea that it indicates

90
00:08:22,480 --> 00:08:26,400
something like that is an trivial, it's sort of obviously true that we don't have some sort of

91
00:08:26,400 --> 00:08:30,720
deep sense. And yes, I've got a big, all the providers that have strengths and weaknesses.

92
00:08:30,720 --> 00:08:35,280
No, of course I have. I've just got a scrappy understanding. But that scrappy understanding

93
00:08:35,280 --> 00:08:40,720
is sort of always like that. I mean, the sense is, in fact, that we have of being kind of slightly

94
00:08:40,720 --> 00:08:45,440
impostors and skating on thin ice as we flow through life. I think all of us know, really,

95
00:08:45,440 --> 00:08:50,000
that when we're trying to explain and understand our behavior, we're kind of,

96
00:08:50,000 --> 00:08:55,920
we're kind of very unsure. We're bumbling from one situation to another. And we're really quite

97
00:08:55,920 --> 00:09:01,520
good at maintaining the pretence that it's all coherent. Okay, so I want to pick up on here. So

98
00:09:01,520 --> 00:09:06,480
if you're a qualitative researcher, you sit there and conversation with me. And it is a sort of

99
00:09:07,120 --> 00:09:12,640
prevalent belief in the industry that our task, and indeed, this is what clients ask us to do,

100
00:09:12,640 --> 00:09:19,840
they say, I want to know what is behind their thinking. Now, you've just said those, these

101
00:09:19,840 --> 00:09:23,600
comments, if you ask the question, like, why did you switch your broadband provider? And someone

102
00:09:23,600 --> 00:09:28,880
says, well, I became hugely frustrated with the old one. This seems this is true. They've not,

103
00:09:30,480 --> 00:09:35,520
they've not said something that's like profoundly false. But your, your suggestion is what that

104
00:09:35,520 --> 00:09:39,920
they've not revealed, because we're trying to learn these things to predict things. So I suppose

105
00:09:39,920 --> 00:09:46,000
there's two things. So how should we sort of wait what we've discovered there? And what predictive

106
00:09:46,000 --> 00:09:53,120
value should we ascribe to it, if any? Yeah, I think the, the thing I stress really is when

107
00:09:53,120 --> 00:09:58,320
you're asking someone why they did something, they can quite often tell you, not necessarily all

108
00:09:58,320 --> 00:10:03,920
that accurately, but they can tell you something about the history. So what happened? And a little

109
00:10:03,920 --> 00:10:10,800
bit about why? Are there often that, of course, easy in fact, latter interpretation, and I suppose

110
00:10:10,800 --> 00:10:14,720
I must have been fed up with my broadband provider, otherwise why did they change? I may have some

111
00:10:14,720 --> 00:10:19,600
memory of, you know, service outages or something. But this is likely to be pretty partial and,

112
00:10:19,600 --> 00:10:24,800
and mostly much of it will be sort of later interpretation. Having said that, that might be

113
00:10:25,760 --> 00:10:30,480
quite predictive of my future behavior. So the, the sort of superficial sense I have of,

114
00:10:31,520 --> 00:10:36,880
I don't trust company X, Y or Z, even if I'm not quite sure why I do that sense of anything,

115
00:10:38,080 --> 00:10:42,080
that company, or any company with a similar name or any company owned by the same people or

116
00:10:42,080 --> 00:10:46,400
anything that's vaguely associated with it, I just don't like it. And that's useful information to

117
00:10:46,400 --> 00:10:51,680
know. It's not, it's not that there's some sort of deep theory I have, or some really, really

118
00:10:51,680 --> 00:10:58,080
coherent set of things that express my sort of deep true values across all possible situations.

119
00:10:58,080 --> 00:11:03,600
It's just a sort of scatter of local, local experiences and views. So I think there's something

120
00:11:03,600 --> 00:11:07,920
you're touching on there, which I suppose I talked a little bit about this beforehand, that

121
00:11:07,920 --> 00:11:13,760
you're, if we ask a question like that, we put, do we maybe learn very little predictively about

122
00:11:13,760 --> 00:11:19,200
that individual, but maybe learn something predictably about people in general. So we learn

123
00:11:19,200 --> 00:11:24,320
that frustration is a reason for doing something. But broadly, if you reduce frustration in that

124
00:11:24,320 --> 00:11:32,560
market, you will keep more customers. I think this is sort of borrowing from, you know, the idea

125
00:11:32,560 --> 00:11:36,480
of like a Freudian unconscious wherever you come to be, that we'd like to think that preferences

126
00:11:36,480 --> 00:11:42,880
are deeply internal. I think it's the extent to which when we tell these stories about why we

127
00:11:42,880 --> 00:11:47,680
change, they are predictive, not only more of other people's behavior than our own, or they're

128
00:11:47,680 --> 00:11:54,400
kind of collective tropes that we borrow upon. Yeah, I think, I think there is a lot of truth

129
00:11:54,400 --> 00:11:58,720
in that. I think the, sometimes, I mean, I'm first of all, I should stress that I think that

130
00:11:58,720 --> 00:12:03,520
qualitative sort of face-to-face conversational interactions, rich interactions with people

131
00:12:03,520 --> 00:12:08,960
are fantastically important, if you want to understand anything. So I mean, my background

132
00:12:08,960 --> 00:12:14,160
is experimental research and I run a quant or co-run a quant consultancy decision technology,

133
00:12:14,160 --> 00:12:23,520
which does very quanty things. In reality, you can't get very far without rich engagement with

134
00:12:23,520 --> 00:12:26,880
individuals, if you want to understand, you know, or with anything you know, qualitative research

135
00:12:26,880 --> 00:12:32,880
just care about. So I'm not sort of imagining that there's some alternative strategy. But I think

136
00:12:32,880 --> 00:12:38,160
it's probably a mistake to think that what the qualitative research is trying to do is to uncover

137
00:12:38,160 --> 00:12:42,320
some sort of hidden belief structure that the person's not really aware of. It's more that

138
00:12:42,320 --> 00:12:49,120
they're, you're helping, you're allowing them to, as it were, create and give you a story about

139
00:12:49,120 --> 00:12:52,720
their behavior. If you get several people to do this, you'll suddenly find sort of recurrent

140
00:12:52,720 --> 00:12:57,680
patterns and the same things start to come up. And the things that people find persuasive stories

141
00:12:57,680 --> 00:13:02,080
are themselves important. Because if you're introducing a new product or a new option,

142
00:13:02,800 --> 00:13:06,240
a really crucial question is what story are they going to tell about this? And the answer is not

143
00:13:06,240 --> 00:13:12,240
defined. It's not that it's not clear before we start. It's a creative question. And so if I

144
00:13:12,240 --> 00:13:17,600
introduce, you know, the iPhone for the first time or introduce texting or something, before

145
00:13:17,600 --> 00:13:22,240
texting came along, this sounded like a total turkey. It's a, you've already could speak,

146
00:13:22,240 --> 00:13:25,440
now we just can be typing characters in it on a terrible keyboard to each other. That's never

147
00:13:25,440 --> 00:13:30,480
going to work. But in fact, it turns out there are ways of, you know, ways of using the technology

148
00:13:30,480 --> 00:13:35,840
which we love. So I think the idea, we all know that it's not, so whether people are like or

149
00:13:35,840 --> 00:13:40,720
dislike something, it's not, it's not something that's, it's kind of fixed in their head before

150
00:13:40,720 --> 00:13:45,840
the new product or service or offering comes to them. There's a sort of dynamic creative process of

151
00:13:45,840 --> 00:13:49,680
are we all going to get our heads around this? Are we going to decide we love it and this is how

152
00:13:49,680 --> 00:13:53,840
we're using it? Or are we going to just not, and you know, that's just not well, well-determined.

153
00:13:53,840 --> 00:13:57,680
But qualitative interactions with people and exploring that space with them will be really

154
00:13:57,680 --> 00:14:03,920
helpful when giving you a clue. So I suppose, I just wanted to pick up, have you ever in your

155
00:14:03,920 --> 00:14:08,160
long career in psychology, experiment psychology, used qualitative methods? Is that?

156
00:14:08,800 --> 00:14:12,880
Yes, yes, I have actually, yes. So I've been doing, what did you use those for? Because I think one

157
00:14:12,880 --> 00:14:19,520
of the things that people at the AQRR are, they're used to sort of, as we were talking to Luella

158
00:14:19,520 --> 00:14:22,880
before, one of the previous webinars was someone who's written a book called The Focus Group Is

159
00:14:22,880 --> 00:14:27,840
Dead, right? They're used to that kind of wholesale attack on the very credibility of it. So to talk

160
00:14:27,840 --> 00:14:34,480
to someone who holds this apparently sort of a heretical view, yet has used

161
00:14:34,480 --> 00:14:36,800
qualitative methodologies. It'd be interesting to hear about that.

162
00:14:36,800 --> 00:14:42,560
Yeah, yeah. So, I mean, let me, actually, I've used it quite a lot. So in, for example, in

163
00:14:42,560 --> 00:14:50,640
pensions choices, we did a project years ago on what people do, what happens when you're,

164
00:14:51,280 --> 00:14:54,000
when you get to the pensionable age and you can potentially change your annuity.

165
00:14:54,960 --> 00:14:57,920
You can buy a different annuity from the one that's you've got with your current pension

166
00:14:57,920 --> 00:15:02,080
provider. Most of us don't even think about this, we just plow on, we think, well, I'm with,

167
00:15:02,080 --> 00:15:06,560
whoever I'm with, that's just, and often that's really not a good idea. So it's actually relevant

168
00:15:06,560 --> 00:15:12,080
to you at some point in the future, any of you. Watch out, because actually, you can get,

169
00:15:12,640 --> 00:15:16,480
actually, it really makes a big difference which provider you're with. Anyway, the question is,

170
00:15:16,480 --> 00:15:21,440
why don't people do this and how can we get them to do it better? And of course, you might want

171
00:15:22,000 --> 00:15:26,160
to have a big web-based survey of pensions of different ages and so on. There's a quantity

172
00:15:26,160 --> 00:15:31,200
sort of approach and look at different possible ways in which you can persuade people to pay

173
00:15:31,200 --> 00:15:35,120
differently or just get them to explore how they ended up with the pension and ended up with all

174
00:15:35,120 --> 00:15:38,640
that stuff. But you can't really get started with knowing what questions to ask without having

175
00:15:38,640 --> 00:15:43,600
rich interactions with actual people in a situation. And I think that's just the general

176
00:15:43,600 --> 00:15:48,880
story for quantum research, which doesn't start with qual, tends to be pretty hopeless, I think.

177
00:15:48,960 --> 00:15:52,320
Because you just don't know what questions you should be asking, so you just miss out something

178
00:15:52,320 --> 00:15:58,720
absolutely crucial. Yeah, so you wouldn't really want to do a quant, and it used to be the classical

179
00:15:58,720 --> 00:16:04,240
methodology, would never do a quant thing without at least a small, small pie, just to test the

180
00:16:04,240 --> 00:16:10,000
questions, basically. Yeah, yeah. It's probably to test the questions and also to test the breath.

181
00:16:10,000 --> 00:16:15,280
So I think the reality of real interaction, another example would be energy. As it's true,

182
00:16:15,440 --> 00:16:20,160
most of the big quantum projects we do in decision technology do have a qual

183
00:16:20,160 --> 00:16:27,440
front end of some kind, sometimes quite a big one. So things like understanding energy purchasing,

184
00:16:27,440 --> 00:16:34,640
those are all about switching or non-switching for the big six or whatever it is now,

185
00:16:35,600 --> 00:16:41,840
utilities. There are a lot of the factors that people that really are important to people,

186
00:16:41,840 --> 00:16:44,800
are things that will never cross your mind unless you've had those interactions, which

187
00:16:44,800 --> 00:16:49,680
would be obvious to listeners, but it wasn't so obvious to me. So talking to people about

188
00:16:51,280 --> 00:16:56,400
energy, you would find some people who said, no, I think it's basically part of who I am,

189
00:16:56,400 --> 00:17:00,720
that I can keep the house as hot as possible. And I don't want any of this insulation, because I just

190
00:17:00,720 --> 00:17:07,600
want to be able to get much, much energy going through the house as possible. That's comfort.

191
00:17:07,600 --> 00:17:11,600
And you might say, well, that just doesn't make any sense, so surely. It's easy,

192
00:17:11,600 --> 00:17:14,480
more insulation, that's got to be good, but that's not always the way it seems.

193
00:17:14,480 --> 00:17:18,400
There's a nanny state perspective. There are all kinds of perspectives on the problem,

194
00:17:18,400 --> 00:17:24,560
or indeed just a sense that you don't want to think about it. It's upsetting. The whole issue of

195
00:17:24,560 --> 00:17:29,520
energy builds is unpleasant. And not a nice thing to think about, and you just, you're worried about

196
00:17:29,520 --> 00:17:33,760
it. And the last thing you want to be doing is focusing your mind on this and this disturbing

197
00:17:33,760 --> 00:17:37,520
question. So you just don't want to even think about changing your provider or insulating your loft

198
00:17:37,520 --> 00:17:42,800
or anything of that kind. But there's a space of possibilities. It's vast, and people who don't

199
00:17:44,640 --> 00:17:50,480
interact at one to one level with other people who are on this question of interest are going to just

200
00:17:50,480 --> 00:17:54,880
be picking a few things out of the air, which seem like they're a sensible, rational person.

201
00:17:54,880 --> 00:17:58,800
A bit like them seems sensible, but that'll just miss almost everything of interest, I think.

202
00:17:59,680 --> 00:18:04,400
So I think that if people are not getting these, when they express beliefs and preferences,

203
00:18:04,400 --> 00:18:08,960
if they're not getting them from within, where do they get them from?

204
00:18:09,760 --> 00:18:15,200
Yeah, well, I think they get them from basically two places. So one, they're getting them from

205
00:18:15,200 --> 00:18:18,720
their own past experiences. There's a little bit of circularity there, of course, because,

206
00:18:19,840 --> 00:18:25,920
but nonetheless, it's the case that most many of my choices are very much similar to my choices

207
00:18:25,920 --> 00:18:29,920
in the past. And also, I'm using my past choices to work out what sort of person I actually am.

208
00:18:30,640 --> 00:18:35,360
I've quit it. So if I'm thinking tea or coffee in the morning, I often, in fact,

209
00:18:35,360 --> 00:18:39,120
won't think much about it at all. I'll just default to tea in the morning, coffee in the

210
00:18:39,120 --> 00:18:44,480
afternoon, or whatever it is. But indeed, if I try to think carefully about it,

211
00:18:44,480 --> 00:18:49,360
so I find myself in sipping my tea and thinking, is this actually nicer than coffee would be?

212
00:18:50,000 --> 00:18:53,520
It's just really hard to tell, but you have to do a sort of experiment and test both.

213
00:18:54,400 --> 00:18:59,120
We don't, that's not what we're doing. We have the feeling that I must have a desire for tea.

214
00:19:00,400 --> 00:19:05,360
But actually, it's much closer psychologically to the point that I have a habit for tea.

215
00:19:06,240 --> 00:19:08,880
And so that's a lot of our behaviors like that.

216
00:19:09,440 --> 00:19:14,320
So we have habits for which we give reasons, because to have habits with no reasons would seem

217
00:19:15,440 --> 00:19:19,600
embarrassing and incoherent. I've often had the experience of drinking not particularly nice

218
00:19:19,600 --> 00:19:25,600
coffee in places like canteens, where I will have a coffee and I'll think, I've done it again.

219
00:19:26,560 --> 00:19:29,840
I think of myself as a coffee drinker. So when someone says, what would you like, I think,

220
00:19:29,840 --> 00:19:33,520
I'll have some coffee. But then it comes out of some horrendous machine. And I always think,

221
00:19:33,520 --> 00:19:38,560
oh, this bears no relation to the thing I actually like. But there I am drinking it.

222
00:19:38,560 --> 00:19:45,120
And I do it again and again. It's not, it's based on this, in my case, I suppose, a very superficial.

223
00:19:45,120 --> 00:19:49,360
It's what you do in those circumstances. Yeah, your coffee is the thing I tend to respond with.

224
00:19:49,360 --> 00:19:53,360
And I suppose that's sort of your range then. I think there's some, so some of the decisions

225
00:19:53,360 --> 00:19:58,000
are very context driven. So I don't drink at all and I don't like beer. But if I find myself

226
00:19:58,000 --> 00:20:02,160
having to wait for somebody in a pub for a long time, I have a sort of reflexive habit,

227
00:20:02,160 --> 00:20:06,960
while I order a pint of Guinness, because you can sit with a pint of Guinness in a pub forever,

228
00:20:06,960 --> 00:20:10,960
and no one will trouble you. That seems to be, so even though I hate, I'd like,

229
00:20:10,960 --> 00:20:15,200
you have to drink about a third of it. So then people really won't, they just can't work out

230
00:20:15,200 --> 00:20:19,120
how long you've been there and how dangerous you are or whatever. So that's ridiculous,

231
00:20:19,120 --> 00:20:24,080
because I hate the stuff I do. Everything about it is wrong. And yeah, it's a habit.

232
00:20:24,800 --> 00:20:28,240
I just wonder how much, and that seems to be driven by where I am, what I have to do.

233
00:20:29,360 --> 00:20:36,160
There's some work by Steve Sloman called Knowledge Illusion, which is very much about how we,

234
00:20:36,160 --> 00:20:43,200
in a very real sense, store a lot of our apparent beliefs in the outside world. So he used an example,

235
00:20:43,760 --> 00:20:50,320
I think it's a Liverpool University sourced paper, about asking people who can ride a bike

236
00:20:50,320 --> 00:20:54,480
to draw a bicycle. And it turns out, even people who know how to ride a bicycle,

237
00:20:54,480 --> 00:20:58,480
when you ask them to draw one, that it's mechanically, disastrously inaccurate.

238
00:20:59,600 --> 00:21:03,840
And that's because when they, I think when they go to ride a bicycle, the bike reminds them,

239
00:21:03,840 --> 00:21:07,760
as it were, how to ride it. So you don't really need to know, you just need to know enough to

240
00:21:07,760 --> 00:21:13,840
be reminded when a bicycle appears before you. So do you sort of ascribing that what we might be,

241
00:21:13,840 --> 00:21:20,720
when we're questioning people qualitatively, what we're looking for, is to find those

242
00:21:20,720 --> 00:21:24,560
context driven responses, where we then sort of create these?

243
00:21:26,480 --> 00:21:31,760
Yeah, I think that's right. So the thing about habits is they are completely,

244
00:21:32,320 --> 00:21:35,200
they're triggered by the situation we're in, they're triggered by context.

245
00:21:35,920 --> 00:21:40,480
And they often are triggered in a fairly, fairly superficial way. So the bicycle example is a lovely

246
00:21:40,480 --> 00:21:46,000
one. And in riding a bicycle, you don't have to know much, you have to know sort of roughly where

247
00:21:46,000 --> 00:21:50,240
the pedals are, where the seat is, how to get on it. And then you actually have to know some

248
00:21:50,240 --> 00:21:54,160
quite complicated balancing stuff, which you've got no conscious of when it's of any way.

249
00:21:55,280 --> 00:22:00,880
And sort of off you go. But if you don't have to understand the way the gears work and all this

250
00:22:00,960 --> 00:22:05,120
stuff. And so as you say, people can, but people have a sense they must understand what a bicycle

251
00:22:05,120 --> 00:22:10,000
looks like. It seems obvious. And I ride one every day. I must go to the draw one. But the

252
00:22:10,000 --> 00:22:15,200
answer is not at all. Now, that's one of the, going back to the first point about the early

253
00:22:15,200 --> 00:22:20,400
cognitive science and artificial intelligence, the kind, these are sort of similar examples.

254
00:22:20,400 --> 00:22:26,160
So it's a famous example about air conditioners, where you ask people, in America, where everybody

255
00:22:26,160 --> 00:22:30,560
has air conditioners. Well, you know, what's an air conditioner do? How does that work then?

256
00:22:31,680 --> 00:22:36,400
And of course, none of the faintest idea of what the earth is going on. But, but it's,

257
00:22:36,400 --> 00:22:40,160
that's a revelation. And most people have a strong sense, similarly as with the bicycle,

258
00:22:40,160 --> 00:22:43,840
they have a strong sense that they perfectly well understand this, they know all the details,

259
00:22:43,840 --> 00:22:46,720
and they're just going to tell you, but actually now they start to think about it. It's a bit more

260
00:22:46,720 --> 00:22:51,360
complicated than they thought. And I think that's not just true for parts of the physical world.

261
00:22:51,360 --> 00:22:56,080
It's true for our attitudes to the political parties and attitudes of the companies,

262
00:22:56,080 --> 00:23:00,640
our attitudes to deep philosophical questions, but our attitudes for everything are very much

263
00:23:00,640 --> 00:23:06,080
like the bicycle. We have a few snippets, which we get us by in terms of, you know,

264
00:23:06,080 --> 00:23:11,680
struggling, making, engaging with whatever this is enough that we can get by in daily life.

265
00:23:11,680 --> 00:23:15,280
But if you ask us about deep things, then, you know, we're struggling.

266
00:23:16,160 --> 00:23:19,840
Yeah, I decided, I suppose one of the, I mean, I'm a big advocate that the,

267
00:23:19,840 --> 00:23:26,000
the role of a qualitative researcher is one of analysis and interpretation. So it's never just

268
00:23:26,000 --> 00:23:31,040
to report what people said is to think. And I think one of the things that we have to weigh

269
00:23:31,040 --> 00:23:36,800
time and time again is people give you an answer. So you say, do you believe in giving to charity?

270
00:23:36,800 --> 00:23:40,400
This is a very leading question. And they say, yes, of course, I believe in giving to charity.

271
00:23:40,400 --> 00:23:46,000
And we then have to judge whether they really mean that. It's just a socially acceptable answer,

272
00:23:46,000 --> 00:23:51,120
you know, whether that would give any kind of, you're, I mean, you'd ask a slightly more

273
00:23:51,760 --> 00:23:57,440
nuanced series of questions, but the task is to say whether they mean it or whether they just

274
00:23:57,440 --> 00:24:03,920
talk a good game and then never do it. And you get, I do quite a lot of work listening to doctors,

275
00:24:03,920 --> 00:24:12,000
for example. And you do this thing where they can talk about identifying different types of

276
00:24:12,000 --> 00:24:18,720
patient. But if there are only really two kinds of treatment available for mild patients and serious

277
00:24:18,720 --> 00:24:24,400
patients, every patient has to be defined as mild or serious. So even though they can describe what

278
00:24:24,400 --> 00:24:29,040
an in-between moderate patient might be, for example, they will always reclassify them as

279
00:24:29,040 --> 00:24:33,040
mild or serious, because there's nothing to do with a moderate patient. They're no use to them.

280
00:24:33,040 --> 00:24:38,480
So this is, they can talk for hours about the moderate patient, but you know, it's in a sense

281
00:24:38,480 --> 00:24:44,960
empty talk. It's completely sincere, well-meaning to be empty in terms of motivation. And do you

282
00:24:44,960 --> 00:24:51,760
have any sort of tips about how you would detect in the way people talk about things, how to tell

283
00:24:51,760 --> 00:24:55,520
sort of the weak from the chef, or if you think that's possible at all?

284
00:24:57,200 --> 00:25:00,800
Well, I don't think there's any, I don't think there's any simple

285
00:25:00,800 --> 00:25:05,120
way to detect the weak from the chef, but I do completely think it's right that

286
00:25:05,120 --> 00:25:11,360
one should view the task of qualitative researchers as an interpretative task. So you,

287
00:25:11,360 --> 00:25:16,240
as the qualitative researcher, with the knowledge and sophistication and understanding of people

288
00:25:16,240 --> 00:25:22,080
you have, are the best place to have a sense of, well, this is the kind of thing everybody says,

289
00:25:22,080 --> 00:25:27,360
or this doesn't sound quite sincere or whatever. There's no, there's no sort of methodology that

290
00:25:27,360 --> 00:25:33,360
will do better than human judgment on that, I think. I think that's right. So I think, yeah,

291
00:25:33,360 --> 00:25:38,880
so I think sometimes people who are keen on the value of qual from the quantitative end

292
00:25:38,880 --> 00:25:42,080
sort of think that qual is a bit like quant, but it's just less of it.

293
00:25:43,040 --> 00:25:48,880
Complete mistake. It's just totally, it's not that if you could only do lots and lots and lots of

294
00:25:48,880 --> 00:25:53,680
qual and sort of do lots of statistical analysis of the things that people say and so on, that would

295
00:25:53,760 --> 00:25:58,560
be better. I think that's completely, completely mistaken. I think what's very hard in what you

296
00:25:58,560 --> 00:26:06,080
said there is, it is the ability to read other people is a human instinct or something we can do

297
00:26:06,080 --> 00:26:11,280
and we can maybe hone that and get better at it and that is incredibly valuable as a research tool.

298
00:26:12,960 --> 00:26:16,320
Even if we don't believe there is this deep mind, there are so many other things we can

299
00:26:16,320 --> 00:26:22,640
detect in their usefulness and sincerity. Yeah, that's right. And so, I mean, the fact that there's

300
00:26:22,640 --> 00:26:28,880
no, there's no sort of ground truth. There's no ground truth about, you know, am I, am I really

301
00:26:28,880 --> 00:26:32,800
pro or anti charity or do I think giving to charities is good or bad? And the answer is going

302
00:26:32,800 --> 00:26:37,440
to be, well, in some situations, I think it is a good idea and abstract. I think, of course,

303
00:26:37,440 --> 00:26:40,960
charity is very important. People should give to them and perhaps I ought to give to them, but then

304
00:26:41,520 --> 00:26:46,800
in reality, maybe I'm not giving as much as I say I should be. And yet sometimes in particular

305
00:26:46,800 --> 00:26:53,360
context, I will and so I will be a jumble and we're all a jumble. So what the quality, I mean,

306
00:26:53,360 --> 00:26:57,840
I think you qualitative researchers are all very aware of the sort of richness of this.

307
00:26:57,840 --> 00:27:04,480
And I think the task is not to distill it down. I think, well, what's what's really going on with

308
00:27:04,480 --> 00:27:10,560
this person is more to get a sense of what are the various perspectives and experiences and actions

309
00:27:10,560 --> 00:27:15,520
and things that have happened to them that they embody. So what, so it will be a mixture. So I

310
00:27:15,600 --> 00:27:22,160
think one thing that I think is particularly useful is getting people to talk about concrete

311
00:27:22,160 --> 00:27:30,480
examples. So things have actually done. I think people can spin a good yarn in the general context,

312
00:27:30,480 --> 00:27:36,480
which is fairly unconnected to the actual behavior. If you say charity, good or a bad thing,

313
00:27:36,480 --> 00:27:41,120
of course, very good, of course they are. And you can talk at that level of generality forever.

314
00:27:41,200 --> 00:27:46,880
But it gets much more, it's much more specific to me if you say, when did you last give to charity

315
00:27:46,880 --> 00:27:51,760
and why was that? And what happens if you meet someone in the street with a tin or what do you

316
00:27:51,760 --> 00:27:57,280
feel when people come to your door? When did that last happen? The more situation specific, the better.

317
00:27:57,920 --> 00:28:01,520
I think that's because actually one of the questions that's come through on the the chatter

318
00:28:01,520 --> 00:28:07,520
is do you have any sort of question stratagems and that would clearly be one to be as concrete

319
00:28:07,520 --> 00:28:12,640
as possible and specific as possible. And I think one of the things I sort of always that comes up

320
00:28:12,640 --> 00:28:17,920
in coal, I think it's interesting is what is called a FOAF, but a friend of a friend story.

321
00:28:18,560 --> 00:28:22,480
And I think those are interesting because they circulate as folklore, but the person they actually

322
00:28:22,480 --> 00:28:28,960
happen to, nobody has ever actually met. They're that distant. They have a certain quality that you

323
00:28:28,960 --> 00:28:33,600
and you can say, well, does anyone really take them seriously or are they scare stories? So you

324
00:28:33,600 --> 00:28:38,080
tend to hear them for example, say about credit card security, while somebody had their pocket

325
00:28:38,080 --> 00:28:43,280
scanned on the tube and they lost thousands. And the actual occasions of this happening are

326
00:28:43,840 --> 00:28:50,160
non-existent, but the belief is wide. And yeah, so you say, well, when did it actually happen to you?

327
00:28:50,160 --> 00:28:54,240
It would be a very good way of shaking out that. And obviously people then double down,

328
00:28:54,240 --> 00:28:58,240
they say, really did happen to them. And kind of tell when they're doing that.

329
00:28:58,720 --> 00:29:02,800
Another thing to get some of the questions because I'm sort of heading towards the end of our time

330
00:29:02,800 --> 00:29:09,840
is someone's asked, where in the sort of continuum of modern day psychology would you place yourself?

331
00:29:09,840 --> 00:29:13,920
Because the mind of flat does seem, obviously, I realised it's the title of a book and it's

332
00:29:13,920 --> 00:29:17,680
this idea of attention to a book. It seems quite a radical position.

333
00:29:17,680 --> 00:29:24,720
Yeah, I think it is. It is. I was driven to write the book. So this goes back to your very first

334
00:29:24,720 --> 00:29:31,360
question really, because I sort of struggled for all my academic life with two sort of contradictory

335
00:29:32,160 --> 00:29:39,360
feelings. So on the one hand, the large amounts of academic psychology and artificial intelligence

336
00:29:39,360 --> 00:29:44,080
and many other nearby disciplines basically do eschew and economics for that matter.

337
00:29:44,080 --> 00:29:47,600
We have preferences and knowledge and they're pretty stable and they wobble around a bit of

338
00:29:47,600 --> 00:29:53,040
the edges as it were. But that's basically the sort of stuff of the mind, the solid beliefs and

339
00:29:53,040 --> 00:29:57,360
desires and so on. And yeah, every time I ever did an experiment and everybody else, this is

340
00:29:57,360 --> 00:30:02,000
true for everybody else in judgment and decision making or social psychology or any other area of

341
00:30:02,000 --> 00:30:05,360
cognitive psychology, every time you try and pin down one of these beliefs or desires, it shoots

342
00:30:05,360 --> 00:30:09,360
around all over your place and change the context, change the experiment, change the instructions,

343
00:30:09,360 --> 00:30:14,800
you just get totally different answers. So the struggle for me was thinking, well, what do I

344
00:30:14,800 --> 00:30:20,560
make of this? Do I, how do I square this contradiction? And I think ultimately I've broken

345
00:30:20,560 --> 00:30:26,560
one way rather than the other rather. So I've just come to the conclusion that the very idea

346
00:30:26,560 --> 00:30:30,640
that there's any bedrock is a completely, that's just the fundamental mistake.

347
00:30:31,520 --> 00:30:35,280
So this is quite a radical position. So a lot of the experiments I talk about in the book

348
00:30:36,000 --> 00:30:40,320
are quite standard and indeed some of the explanations I give are quite standard. I don't

349
00:30:40,320 --> 00:30:46,320
think there are very many people who are quite taking such a thoroughgoing line as I am and saying,

350
00:30:46,320 --> 00:30:50,160
well, actually, it's sort of improvisation all the way down. But I think the reason one can,

351
00:30:50,160 --> 00:30:55,680
that is a sustainable view and this is a sort of breakthrough in my thinking, hopefully productive

352
00:30:55,680 --> 00:31:00,880
one, was thinking, ah, well, of course, the thing is that when you're improvising, you're always,

353
00:31:00,880 --> 00:31:04,800
you can always improvise based on what all the other thoughts you've had before. And also the

354
00:31:04,800 --> 00:31:07,600
thoughts you've heard from other people and the things they've said and things they've done.

355
00:31:07,600 --> 00:31:12,800
So you're not starting from scratch, you've got this incredibly rich tapestry of previous

356
00:31:12,800 --> 00:31:17,680
improvisational experiences and thoughts and things to draw on. And that's what's allowing you to

357
00:31:17,680 --> 00:31:23,680
create as it were the next thought. It's not, so it's always on the surface, it's always constructed

358
00:31:23,680 --> 00:31:28,320
in the moment, but every moment can refer back to all those other moments. It's not that you're

359
00:31:28,320 --> 00:31:33,360
referring back to a sort of a deeper underlying, this is what I really think and who I really am

360
00:31:33,360 --> 00:31:39,280
level, it's more, I'm more like a tradition, the traditional things that Nick tends to say and do.

361
00:31:40,240 --> 00:31:43,600
Okay, that's it. Someone's just come to the question, it's very interesting,

362
00:31:43,600 --> 00:31:46,640
whether we improvise our emotions as well as our beliefs?

363
00:31:46,640 --> 00:31:51,920
Ah, yes. So there's some lovely examples of this. So I'll mention a couple from the book.

364
00:31:52,880 --> 00:31:58,400
So I think the absolutely answer is yes. There's a lovely experiment where, this is by

365
00:31:59,280 --> 00:32:03,200
Dutton and Aaron in 1974. So it's really an old experiment, but a beautiful experiment,

366
00:32:03,200 --> 00:32:09,600
where they ask female, attractive female experiments as to interview male bridge

367
00:32:09,600 --> 00:32:13,520
crosses. So people are walking across bridges. I should say this is an experiment from 1971,

368
00:32:13,520 --> 00:32:20,880
isn't it? Hence the rather, sort of a pre-me to era nature of the experiment. Yeah, yeah, yeah,

369
00:32:20,880 --> 00:32:24,560
absolutely. Yes, yes, yes, I should stress this. Yes, yes, it would all be done a bit differently

370
00:32:24,560 --> 00:32:31,440
now. Careful. But it was a, so your female experimenters interviewed the male bridge

371
00:32:31,440 --> 00:32:36,480
crosses who are crossing either a high wobbly suspension type bridge on the University of

372
00:32:36,480 --> 00:32:42,000
British Columbia campus, or they have just crossed a low bridge, which is not scary at all.

373
00:32:42,000 --> 00:32:47,920
And the important thing is that the experimenters give the bridge crosser their phone number to

374
00:32:47,920 --> 00:32:51,200
say if there are any issues raised by this experiment, which is very unlikely because

375
00:32:51,200 --> 00:32:54,800
it's not a very interesting experiment. If you want to, if you need to get back to any ethical

376
00:32:54,800 --> 00:32:59,440
concerns, here's my number. And of course, quite a lot of the experimenters who are

377
00:32:59,440 --> 00:33:05,040
undergraduates on campus do in fact call the, call the experimenters because they,

378
00:33:05,040 --> 00:33:10,400
you know, they're interested in seeing more of them. The question, but the exciting prediction

379
00:33:10,400 --> 00:33:16,720
that Dutton and Aaron made was that there would, they were predicted that there would be higher

380
00:33:16,720 --> 00:33:21,840
numbers of phone calls if people had just crossed a high bridge, not a low bridge. And that turns

381
00:33:21,840 --> 00:33:27,360
out to be true. So it's the way the prediction works is you say, well, if you just want to cross

382
00:33:27,360 --> 00:33:30,960
a high bridge, you're full of adrenaline. When you're full of adrenaline, you're thinking,

383
00:33:30,960 --> 00:33:34,720
ah, where's all this adrenaline come from? Ah, I've just met this person who's been running

384
00:33:34,720 --> 00:33:38,640
me through this experiment. I guess I must kind of like them. I mean, you know, I didn't normally

385
00:33:38,640 --> 00:33:42,560
have this much adrenaline. It must be because it's because of them. They've caused it. So you have

386
00:33:42,560 --> 00:33:48,960
that interpretation of your physiological state of it being adrenalized. We interpret that as

387
00:33:48,960 --> 00:33:54,160
attraction. And you get, and you get this absolutely everywhere. So, you know, you get,

388
00:33:54,160 --> 00:33:58,400
so they get this if you go back even earlier in psychology, when you give people adrenaline

389
00:33:58,400 --> 00:34:04,240
shocks, shots, the syringe, but you don't either you do tell them, I'm going to give you some

390
00:34:04,240 --> 00:34:09,200
adrenaline now or you don't. If you don't tell them, then they have to sit and wait for the

391
00:34:09,200 --> 00:34:15,120
experiment to begin. And then they interact with somebody who is a bit strangely and then the

392
00:34:15,120 --> 00:34:21,600
person will either be more annoyed than normal by the person's behavior or more amused by the

393
00:34:21,600 --> 00:34:26,000
behavior, whatever their behavior, the person who's in the waiting room with them, whatever

394
00:34:26,000 --> 00:34:30,000
they do, the person who's got more adrenaline, it got adrenaline in their body, but doesn't

395
00:34:30,000 --> 00:34:34,640
realize it reacts more strongly. But they don't realize that they're reacting more strongly

396
00:34:34,640 --> 00:34:38,080
because of the adrenaline. Of course, they don't know anything about that. They were so annoying.

397
00:34:38,080 --> 00:34:41,200
That person was just, I couldn't believe how annoying they were. And the reason they think

398
00:34:41,200 --> 00:34:45,360
they're so, so annoying is because they're, the person's behaving a bit irritatingly,

399
00:34:45,360 --> 00:34:49,200
but I've got lots of adrenaline. So I must be really annoyed about this because where's the

400
00:34:49,200 --> 00:34:53,360
adrenaline coming from? But if you tell people, are you going to feel a bit weird? Yeah, if there's

401
00:34:53,360 --> 00:34:59,600
adrenaline, there's adrenaline injection. So if you expected to be a bit, feel a bit peculiar,

402
00:34:59,600 --> 00:35:04,320
then those effects don't completely disappear, but they're much reduced because then obviously I

403
00:35:04,320 --> 00:35:10,160
think, oh, I'm feeling a bit strange because they told me I would. So I don't misinterpret my emotion.

404
00:35:10,160 --> 00:35:13,520
So emotionally interpretation is just incredibly rich, incredibly complicated.

405
00:35:13,520 --> 00:35:19,760
But it's the key, I think, to take the key taken message, and I think this is really quite standard

406
00:35:19,760 --> 00:35:24,960
perspective in emotion research, is that you shouldn't think of emotions. We shouldn't think of

407
00:35:24,960 --> 00:35:31,440
emotions as welling up from within that active interpretations. So what you have access to

408
00:35:31,440 --> 00:35:36,960
is your physiological state. I'll know. I've got adrenaline. I haven't got adrenaline. I'm sleepy.

409
00:35:36,960 --> 00:35:42,880
I'm waitful. But I'm then trying to interpret, well, why? Why am I feeling that? And that's

410
00:35:42,880 --> 00:35:48,240
the emotion has been generated. And is that something where we can learn to, in a sense,

411
00:35:48,240 --> 00:35:54,480
create our own emotions? Because I noticed that, despite your clear skepticism for sort of the

412
00:35:54,480 --> 00:36:02,000
psychoanalysis of Freud, you speak favorably, I think, of the effects of CBT or other talking

413
00:36:02,000 --> 00:36:07,040
cures. You believe those are real, that they can change people's lives for the better. So

414
00:36:07,040 --> 00:36:10,880
they're not changing the deep person. What are they changing the patterns of response?

415
00:36:11,440 --> 00:36:17,120
Yeah, I think what they're doing, and I think, actually, the virtues of CBT are quite closely,

416
00:36:17,120 --> 00:36:22,000
closely connected to the virtues of qualitative research, actually. It's all about rich,

417
00:36:22,000 --> 00:36:26,880
rich engagement with other human beings. And one of the things that CBT is doing is what I think

418
00:36:26,880 --> 00:36:33,200
it's doing two key things. One is it's telling you that the experience and thoughts you have

419
00:36:33,200 --> 00:36:37,120
should not be taking the face value. They're interpretations of the moment. So if you have

420
00:36:37,120 --> 00:36:42,640
a feeling of, I'm hopeless, or I can't succeed, or you shouldn't think, oh, that's my inner self

421
00:36:42,640 --> 00:36:47,040
speaking, it's told the real truth. Other people say I'm okay, but I've got the voice from within,

422
00:36:47,040 --> 00:36:50,800
that's the one that's right. That should be treated with great skepticism, because it's

423
00:36:50,800 --> 00:36:54,240
just one or more of those improvisations. And you should be able to step back from and say,

424
00:36:54,240 --> 00:36:57,440
then take yourself, yeah, I improvise that sometimes, sometimes I come up with other stuff.

425
00:36:58,320 --> 00:37:04,480
So that's one point, which is detaching yourself from a sense that there's some sort of gushing

426
00:37:04,480 --> 00:37:09,360
inner truth bursting forth, which you just have to take, which it can be very dangerous if those

427
00:37:09,360 --> 00:37:15,280
thoughts are negative. But the other thing is it's helping you create new habits and new structures

428
00:37:15,280 --> 00:37:22,000
and new stories. I think sometimes therapists think of themselves as creating the true story or

429
00:37:22,000 --> 00:37:26,560
uncovering the true story. And I would say that's not quite right. It's more like co-creation. We

430
00:37:26,560 --> 00:37:32,160
together in this session, as it were, are trying to find a different way of interpreting your life,

431
00:37:32,160 --> 00:37:35,040
maybe a more useful one, and one that will help you go forwards.

432
00:37:36,080 --> 00:37:39,280
Okay, Llewela, you've reappeared. Does this mean we're out of time? Because someone has just asked

433
00:37:39,280 --> 00:37:45,040
to actually what would be a brilliant question. Go ahead. Someone said, what do you think? I think

434
00:37:45,040 --> 00:37:49,440
I remember your answer to this, and I think it was you just burst out laughing, actually. What do

435
00:37:49,440 --> 00:37:57,200
you think of implicit association tests? Ah, right. Well, I think this is a tricky question,

436
00:37:57,200 --> 00:38:04,240
really. I mean, implicit association tests do, you know, they are very powerful. They are powerful

437
00:38:04,240 --> 00:38:15,680
measures of things like of unconscious bias. And I don't think that's right. Well, the implicitness,

438
00:38:15,680 --> 00:38:21,280
I think, is, you might think, ah, they're implicit, these association tests, so they must

439
00:38:21,280 --> 00:38:26,000
actually, these are, therefore, they must be contacting your unconscious. And I think that's

440
00:38:26,000 --> 00:38:36,880
not the right way to look at it. So I think it is true that we do, we do have certain kind of

441
00:38:36,880 --> 00:38:41,920
associative networks between different categories and concepts, which are very fluid and very

442
00:38:41,920 --> 00:38:48,400
variable and jump around, but they nonetheless are there. And we're not aware of them. But, of

443
00:38:48,400 --> 00:38:52,320
course, we're not aware of anything about our minds. We're always improvising in the moment.

444
00:38:53,040 --> 00:38:57,360
So I suppose the thing I want to say, so I'm not a great skeptic of implicit association tests,

445
00:38:57,360 --> 00:39:01,040
and they aren't genuinely interesting and useful. But I don't think that what they're not doing is

446
00:39:01,040 --> 00:39:07,600
revealing your unconscious in any particularly particular way, because from my point of view,

447
00:39:07,600 --> 00:39:13,840
you're never conscious of your inner workings of your brain. Your consciousness just doesn't work

448
00:39:13,840 --> 00:39:19,600
that way. All you ever have is a stream of improvisation. And so if I say, I'll ask you

449
00:39:19,600 --> 00:39:25,280
explicitly, what's your attitude to people in a particular group? I'll generate some stuff. You

450
00:39:25,280 --> 00:39:28,880
might think, well, you must have been conscious of that. But the answer is no, no, you're conscious

451
00:39:28,880 --> 00:39:34,480
of what you've just said. That's true. You weren't conscious of the processes underneath. And you

452
00:39:34,480 --> 00:39:39,360
never are. So you're happy with the association part. It's the implicit part that you know.

453
00:39:41,360 --> 00:39:45,840
That claim that you find troubling. Okay, well, I think, regrettably, because as I think I'm proving

454
00:39:45,840 --> 00:39:51,680
I could talk to all day, there's a time has come to answer Luella has appeared to wrap us up. So

455
00:39:51,680 --> 00:39:58,480
thank you so much for talking about your book, which I can warmly recommend to anyone. So Luella,

456
00:39:58,480 --> 00:40:02,720
to you to wrap us up. Thank you very much, Nick. Well, thank you both very much. I mean,

457
00:40:02,720 --> 00:40:07,040
it was fascinating. And I apologize for hanging around like a bad smell and not turning my video

458
00:40:07,040 --> 00:40:14,400
off. Got there in the end. Just before we say goodbye, hope to see you at the next webinar.

459
00:40:15,840 --> 00:40:21,680
Details will be coming out shortly. And just say or to remind members that there's just over a week

460
00:40:21,680 --> 00:40:29,760
to go before the deadline for paper submissions to a qr's big day out. And through other little

461
00:40:29,760 --> 00:40:35,440
bits and pieces, there are still a few tickets tickets left for a qr's, not the Christmas party

462
00:40:35,440 --> 00:40:43,040
details on the website. There's a new breakfast bites coming up. And a qr spark returns

463
00:40:43,600 --> 00:40:50,720
later on in February with transforming imposter syndrome, which sounds fascinating.

464
00:40:51,440 --> 00:40:57,120
But again, thank you both very much. And I look forward to a rematch actually at some

465
00:40:57,120 --> 00:41:03,920
point, because it seems to be an awful lot that didn't go said. So maybe maybe. Thank you. Thank you.

466
00:41:03,920 --> 00:41:05,840
Bye. Bye.

