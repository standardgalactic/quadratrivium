WEBVTT

00:00.000 --> 00:13.440
Thanks for coming out. It's good to be here. As Eric said, I'm a philosopher, thinking

00:13.440 --> 00:20.160
about consciousness, coming from a background in the sciences and math that always struck

00:20.160 --> 00:28.440
me that the most interesting and hardest unsolved problem in the sciences was the problem

00:28.440 --> 00:34.480
of consciousness. Way back, 25 years ago, when I was in grad school, it seemed to me

00:34.480 --> 00:40.600
the best way to come at this from a big picture perspective was to go into philosophy and

00:40.600 --> 00:44.920
think about the foundational issues that arise and thinking about consciousness from any

00:44.920 --> 00:52.200
number of different angles, including the angles of neuroscience and psychology and AI.

00:52.200 --> 00:55.880
In this talk, I'm going to present a slightly different perspective on the problem after

00:55.880 --> 01:03.800
laying out some background, the perspective of what I call the meta problem of consciousness.

01:03.800 --> 01:08.680
I always like the idea that you approach a problem by stepping one level up, taking the

01:08.680 --> 01:16.760
meta perspective. I love this quote, anything you can do, I can do meta. I have no idea

01:16.760 --> 01:21.040
what the origins was. I like the fact this is attributed to Rudolf Kahnap, one of my

01:21.040 --> 01:25.000
favorite philosophers, but anyone who knows Kahnap's work is completely implausible. He

01:25.000 --> 01:29.120
would ever say anything so frivolous. It's also been attributed to my thesis advisor,

01:29.120 --> 01:34.920
Doug Hofstadter, author of Goethe Lescher Bach and a big fan of the meta perspective,

01:34.920 --> 01:41.000
but he assures me he never said it either. But the meta perspective on anything is stepping

01:41.000 --> 01:48.620
up a level. The meta problem, as I think about it, is called the meta problem because it's

01:48.620 --> 01:54.320
a problem about a problem. A meta theory is a theory about a theory. Meta problem is

01:54.320 --> 01:58.980
a problem about a problem. In particular, it's the problem of explaining why we think

01:58.980 --> 02:04.120
there is a problem about consciousness. So there's a first order problem, the problem

02:04.120 --> 02:09.180
of consciousness. Today I'm going to focus on a problem about it, but I'll start by introducing

02:09.180 --> 02:15.200
the first order problem itself. The first order problem is what we call the hard problem

02:15.200 --> 02:22.000
of consciousness. It's the problem of explaining why and how physical processes should give

02:22.040 --> 02:29.040
rise to conscious experience. You've got all this neurons firing in your brain, bringing

02:31.520 --> 02:37.880
about all kinds of sophisticated behavior. We can get to be done explaining our various

02:37.880 --> 02:41.680
responses, but there's this big question about how it feels from the first person point of

02:41.680 --> 02:46.320
view. That's the subjective experience. I like this illustration of the hard problem

02:46.320 --> 02:51.960
of consciousness. It seems to show someone's hair catching fire, but I guess it's a metaphorical

02:52.400 --> 02:58.400
illustration of the subjective perspective. The hard problem is concerned with what philosophers

02:58.400 --> 03:04.320
call phenomenal consciousness. The word consciousness is ambiguous a thousand ways, but phenomenal

03:04.320 --> 03:10.360
consciousness is what it's like to be a subject from the first person point of view. A system

03:10.360 --> 03:15.880
is phenomenally conscious. If there's something it's like to be it, a mental state is phenomenally

03:15.880 --> 03:20.280
conscious if there's something it's like to be in it. The thought is there are some

03:20.320 --> 03:25.200
systems, so there's something it's like to be that system. There's something it's like

03:25.200 --> 03:30.320
to be me. I presume there's something it's like to be you, but presumably there's nothing

03:30.320 --> 03:35.960
it's like to be this lectern as far as we know. The lectern does not have a first person

03:35.960 --> 03:42.960
perspective. This phrase was made famous by my colleague Tom Nagel at NYU who back in 1974

03:43.040 --> 03:50.040
wrote an article called What is it like to be a bat? The general idea was what's very

03:50.960 --> 03:56.200
hard to know what it's like to be a bat from the third person point of view just looking

03:56.200 --> 04:00.640
at it as a human who has different kinds of experience, but presumably very plausibly

04:00.640 --> 04:05.000
there is something it's like to be a bat. The bat is conscious. It's having subjective

04:05.000 --> 04:12.000
experiences just of a kind very different from ours. In human subjective experience

04:13.920 --> 04:20.400
consciousness divides into any number of different kinds or aspects like different tracks of

04:20.400 --> 04:26.400
the inner movie of consciousness. We have visual experiences like the experience of

04:26.400 --> 04:32.920
say these colors blue and red and green from the first person point of view and of depth.

04:32.920 --> 04:39.920
There are sensory experiences like the experience of my voice, experiences of taste and smell,

04:40.360 --> 04:47.360
their experiences of your body, feeling pain or orgasms or hunger or a tickle or something.

04:47.840 --> 04:53.080
They all have some distinctive first person quality, mental images like recalled visual

04:53.080 --> 05:00.080
images, emotional experiences like experience of happiness or anger and indeed we all seem

05:00.280 --> 05:03.840
to have this stream of a current thought or at the very least we're kind of chattering

05:03.840 --> 05:10.840
away to ourselves and reflecting and deciding. All of these are aspects of subjective experience,

05:11.200 --> 05:17.560
things we experience from the first person point of view and I think these subjective

05:17.560 --> 05:24.560
experiences are at least on the face of it data, data for the science of consciousness

05:24.760 --> 05:29.680
to explain. These are just facts about us that we're having these subjective experiences.

05:29.680 --> 05:34.600
As we ignore them, we're ignoring the data. So if you catalog the data that say the science

05:34.600 --> 05:38.360
of consciousness needs to explain, there are certainly facts about our behavior and how

05:38.360 --> 05:42.480
we respond in situations. There are facts about how our brain, facts about how our brain

05:42.480 --> 05:46.840
is working. There are also facts about how subjective experiences and on the face of

05:46.840 --> 05:53.760
it their data. And it's these data that pose what I call the hard problem of consciousness.

05:53.840 --> 05:59.680
This gets contrasted with the easy problems, the so-called easy problems of consciousness

05:59.680 --> 06:06.680
which are the problems of explaining behavioral and cognitive functions. Objective things

06:07.600 --> 06:12.560
you can measure from the third person point of view typically tied to behavior, perceptual

06:12.560 --> 06:18.440
discrimination say of a stimulus. I can discriminate two different things in my environment. I

06:18.440 --> 06:23.040
can say that's red and that's green. I can integrate the information say about the color

06:23.040 --> 06:27.040
and the shape. I can use it to control my behavior, walk towards the red one rather

06:27.040 --> 06:34.520
than the green one. I can report it, say that's red and so on. Those are all data too for

06:34.520 --> 06:40.040
science to explain. But we've got a bead on how to explain those. They don't seem to

06:40.040 --> 06:47.040
pose as big a problem. Why? We explain those easy problems by finding a mechanism, typically

06:48.040 --> 06:55.040
a neural or computational mechanism that performs the relevant function to explain

06:55.440 --> 07:00.440
how it is that I get to say there's a red thing over there or walk towards it. Will

07:00.440 --> 07:07.440
you find the mechanisms involving perceptual processes and action processes in my brain

07:07.800 --> 07:12.560
that leads to that behavior? Find the right mechanism that performs the function. You've

07:12.560 --> 07:18.680
explained what needs to be explained with the easy problems of consciousness. But for

07:18.680 --> 07:23.800
the hard problem, for subjective experience, it's just not clear that this standard method

07:23.800 --> 07:30.800
works. It looks like explaining all that behavior still leaves open a further question. Why

07:31.040 --> 07:38.040
does all that give you subjective experience? Explain the reacting, the responding, the

07:38.800 --> 07:45.800
controlling, the reporting and so on. It still leaves open the question why is all that accompanied

07:46.040 --> 07:52.680
by subjective experience? Why doesn't it go on in the dark without consciousness, so

07:52.680 --> 07:57.600
to speak? There seems to be what the philosopher Joe Levine has called a gap here, an explanatory

07:57.600 --> 08:02.600
gap between physical processes and subjective experience, at least our standard kinds of

08:02.600 --> 08:07.840
explanation which work really well for the easy problems of behavior and so on. Don't

08:07.880 --> 08:14.880
obviously give you a connection to the subjective aspects of experience. There's been a vast

08:15.880 --> 08:20.760
amount of discussion of these things over, well for centuries really, but it's been particularly

08:20.760 --> 08:27.760
active in recent decades, philosophers, scientists, all kinds of different views. Philosophically

08:28.080 --> 08:34.600
you can divide approaches to the hard problem into at least two classes. One is an approach

08:34.680 --> 08:38.920
on which consciousness is taken to be somehow irreducible and primitive. We can't explain

08:38.920 --> 08:44.240
it in more basic physical terms, so take it as a kind of primitive and that might lead

08:44.240 --> 08:48.080
to dualist theories of consciousness where consciousness is somehow separate from and

08:48.080 --> 08:53.560
interacts with the brain. Recently very popular has been the class of panpsychist theories

08:53.560 --> 08:58.880
of consciousness. I know Galen Strossom is here a while back talking, he very much favors

08:58.880 --> 09:03.000
panpsychist theories where consciousness is something basic in the universe underlying

09:03.040 --> 09:09.040
matter and indeed there are idealist theories where consciousness underlies the whole universe,

09:09.040 --> 09:15.160
so these are all extremely speculative but interesting views that I've explored myself.

09:15.160 --> 09:20.960
There are also reductionist theories of consciousness from functionalist approaches where consciousness

09:20.960 --> 09:27.960
is just basically taken to be a giant algorithm or computation. Biological approaches to consciousness,

09:28.000 --> 09:34.000
my colleague Ned Block was here I know talking about neurobiology based approaches where

09:34.000 --> 09:39.440
it's not the algorithm that matters but the biology is implemented in and indeed the kind

09:39.440 --> 09:44.720
of quantum approaches that people like Roger Penrose and Stuart Hemeroff have made famous.

09:44.720 --> 09:48.960
I mean I think there's interesting things to say about all of these approaches. I think

09:48.960 --> 09:54.400
that right now at least most of the reductionist approaches leave a gap but the non-reductionist

09:54.440 --> 10:01.440
approaches have other problems in seeing how it all works. Today I'm going to take a different

10:01.440 --> 10:08.440
kind of approach, this approach through the meta-problem. One way to motivate this is to

10:08.520 --> 10:14.280
ask, I often get asked, okay you're a philosopher it's fine you get to think about these things

10:14.280 --> 10:20.280
like the hard problem of consciousness, how can I as a scientist or an engineer or an

10:20.280 --> 10:27.280
AI researcher, how can I do something to kind of contribute to help get at this hard problem

10:27.440 --> 10:31.680
of consciousness? Is this just a problem for philosophy? I mean for me to work on it say

10:31.680 --> 10:37.680
as an AI researcher I need something I can operationalize, something I can work with

10:37.680 --> 10:44.180
and try to program and as it stands it's just not clear how to do that with the hard problem.

10:44.180 --> 10:48.320
I mean if you're a neuroscientist there are some things you can do. You can say work with

10:48.320 --> 10:53.520
humans and look at their brains and look for the neural correlates of consciousness, the

10:53.520 --> 10:56.800
bits of the brain that go along with being conscious because at least with humans we

10:56.800 --> 11:01.440
can take as a background assumption, a plausible background assumption that the system is conscious.

11:01.440 --> 11:05.320
For AI we can't even do that, we don't know which AI systems we're working with or conscious,

11:05.320 --> 11:11.320
we need some operational criteria. In AI we mostly work on modeling things like behavior

11:11.320 --> 11:16.240
and objective functioning for consciousness, those are the easy problems. So how does someone

11:16.300 --> 11:22.800
coming from this perspective make a connection to the hard problem of consciousness? Well

11:22.800 --> 11:29.160
one approach is to work on certain problems among the easy problems of behavior that shed

11:29.160 --> 11:36.160
particular light on the hard problem and that's going to be the approach that I look at today.

11:36.920 --> 11:42.400
So the guiding, the key idea here is there are certain behavioral functions that seem

11:42.440 --> 11:49.440
to have a particularly close relation to the hard problem of consciousness. In particular

11:49.440 --> 11:55.080
we say things about consciousness. We make what philosophers call phenomenal reports,

11:55.080 --> 12:02.080
verbal reports of conscious experiences. So I'll say things like I'm conscious, I'm

12:02.160 --> 12:08.280
feeling pain right now and so on. Maybe the consciousness and the pain are subjective

12:08.360 --> 12:14.360
experiences but the reports, the utterances, I am conscious, well that's a bit of behavior.

12:14.360 --> 12:20.640
In principle explaining those is among the easy problems, objectively measurable response,

12:20.640 --> 12:27.640
we can find a mechanism in the brain that produces it. And among our phenomenal reports

12:27.640 --> 12:33.800
there's this special class we can call the problem reports, reports expressing our sense

12:33.800 --> 12:38.720
that consciousness poses a problem. Now admittedly not everyone makes these reports but they

12:38.720 --> 12:43.160
seem to be fairly widespread among, especially among philosophers and scientists thinking

12:43.160 --> 12:47.920
about these things but furthermore it's a sense that it's fairly easy to find and a

12:47.920 --> 12:54.080
very wide class of people who think about consciousness. People say things like there

12:54.080 --> 12:59.920
is a problem of consciousness, a hard problem. On the face of it explaining behavior doesn't

12:59.960 --> 13:05.320
explain consciousness, consciousness seems non-physical, how would you ever explain the

13:05.320 --> 13:10.840
subjective experience of red and so on. It's an objective fact about us, at least about

13:10.840 --> 13:17.840
some of us, that we make those reports and that's the fact about human behavior.

13:19.440 --> 13:25.940
So the matter problem of consciousness then at a second approximation is roughly the problem

13:25.940 --> 13:32.460
of explaining these problem reports, explaining you might say the conviction that we're conscious

13:32.460 --> 13:37.220
and that consciousness is puzzling. And what's nice about this is that although the hard

13:37.220 --> 13:40.820
problem is this, you know, airy-fairy problem about subjective experience that's hard to

13:40.820 --> 13:47.020
pin down, this is a puzzle ultimately about behavior. So this is an easy problem, one

13:47.020 --> 13:51.500
that ought to be open to those standard methods of explanation in the cognitive and brain

13:52.460 --> 13:59.460
sciences. So there's a research program. There's a research program here. So I like

13:59.460 --> 14:02.140
to think of the matter problem as something that can play that role. I talked about earlier

14:02.140 --> 14:06.060
if you say an AI researcher thinking about this. The matter problem is an easy problem,

14:06.060 --> 14:10.540
a problem about behavior that's closely tied to the hard problem. So it's something we

14:10.540 --> 14:14.740
might be able to make some progress on using standard methods of thinking about algorithms

14:14.740 --> 14:19.940
and computations or thinking about brain processes and behavior while still shedding

14:19.940 --> 14:23.980
some light, at least indirectly on the hard problem. It's more tractable than the hard

14:23.980 --> 14:28.220
problem but solving it ought to shed light on the hard problem. And today I'm just going

14:28.220 --> 14:32.500
to kind of lay out the research program and talk about some ways in which it might potentially

14:32.500 --> 14:38.820
shed some light. This is interesting to a philosopher because it looks like an instance

14:38.820 --> 14:42.940
of what people sometimes call genealogical analysis. It goes back to Friedrich Nietzsche

14:42.940 --> 14:47.780
on the genealogy of morals. Instead of thinking about what's good or bad, let's look at where

14:47.780 --> 14:54.660
our sense of good or bad came from, the genealogy of it all in evolution or in culture or in

14:54.660 --> 15:00.340
religion. And people take a genealogical approach to God. Instead of thinking about does God

15:00.340 --> 15:04.860
exist or not, let's look at where our belief in God came from. Maybe there's some evolutionary

15:04.860 --> 15:10.780
reason for why people believe in God. This often leads, not always, but often leads to

15:10.780 --> 15:16.500
a kind of debunking of our beliefs about those domains. Explain why we believe in God in

15:16.500 --> 15:22.500
evolutionary terms. No need for the God hypothesis anymore. Explain our moral beliefs in say

15:22.500 --> 15:28.140
evolutionary terms. Maybe no need to take morality quite so seriously. So some people

15:28.140 --> 15:33.020
at least are inclined to take an approach like this with consciousness too. If you think

15:33.020 --> 15:37.660
about the meta problem, explaining our beliefs about consciousness, that might ultimately

15:37.660 --> 15:45.220
debunk our beliefs about consciousness. This leads to a philosophical view which has recently

15:45.260 --> 15:51.340
attracted a lot of interest, a philosophical view called illusionism, which is the view

15:51.340 --> 15:57.780
that consciousness itself is an illusion or maybe that the problem of consciousness is

15:57.780 --> 16:05.140
an illusion. Explain the illusion and we dissolve the problem. In terms of the meta

16:05.140 --> 16:10.980
problem that view roughly comes to, solve the meta problem, it will dissolve the hard

16:11.020 --> 16:15.420
problem. Explain why it is that we say all these things about consciousness. While we

16:15.420 --> 16:20.940
say I am conscious, while we say consciousness is puzzling, if you can explain all that in

16:20.940 --> 16:27.100
say algorithmic terms, then you'll remove the underlying problem because you'll have

16:27.100 --> 16:31.500
explained why we're puzzled in the first place. Actually, walking over here today, I noticed

16:31.500 --> 16:36.140
that just a couple of blocks away, we have the Museum of Illusions. So I'm going to check

16:36.140 --> 16:40.900
that out later on. But if illusionism is right and added to all those perceptual illusions,

16:41.260 --> 16:46.220
it's going to be the problem of consciousness itself. It's roughly an illusion thrown up

16:46.220 --> 16:51.700
by having a weird self-model with a certain kind of algorithm that attributes to ourselves

16:51.700 --> 16:58.700
special properties that we don't have. So one line on the meta problem is the illusionist

16:58.700 --> 17:03.820
line. Solve the meta problem, you'll get to treat consciousness as an illusion. That's

17:03.820 --> 17:09.540
actually a view that has many antecedents in the history of philosophy one way or another.

17:09.580 --> 17:13.740
Emmanuel Kahn, in his great critique of pure reason, had a section where he talked about

17:13.740 --> 17:21.020
the self or the soul as a transcendental illusion. We seem to have this indivisible soul, but

17:21.020 --> 17:25.740
that's a kind of illusion thrown up by our cognitive processes. The Australian philosophers

17:25.740 --> 17:31.860
are on place, and David Armstrong had versions of this that I might touch on a bit later.

17:31.860 --> 17:38.620
Daniel Dennett, leading reductionist thinker about consciousness, has been pushing for the

17:38.660 --> 17:43.940
last couple of decades the idea that consciousness involves a certain kind of user illusion,

17:43.940 --> 17:50.140
and most recently the British philosopher Keith Frankish has been really pushing illusionism

17:50.140 --> 17:57.140
as a theory of consciousness. Here's a book centering around a paper by Keith Frankish

17:58.100 --> 18:03.580
on illusionism as a theory of consciousness that I recommend to you. So one way to go

18:03.580 --> 18:07.580
with the meta problem is the direction of illusionism, but one nice thing about many

18:07.620 --> 18:12.340
people find illusionism completely unbelievable. They find you, how could it be that consciousness

18:12.340 --> 18:16.900
is an illusion? Look, we just have the subjective experience, it's a datum about our nature,

18:16.900 --> 18:22.460
and I confess I've got some sympathy with that reaction, so I'm not an illusionist myself.

18:22.460 --> 18:26.780
I'm a realist about consciousness in the philosopher's sense where a realist about

18:26.780 --> 18:32.260
something is someone who believes that thing is real. I think consciousness is real, I

18:32.260 --> 18:37.260
think it's not an illusion, I think that solving the meta problem does not dissolve

18:37.260 --> 18:40.540
the hard problem, but the nice thing about the meta problem is you can proceed on it

18:40.540 --> 18:46.740
to some extent at least in initial neutrality on that question, is consciousness real or

18:46.740 --> 18:52.620
is it an illusion? It's a basic problem about our objective functioning of these reports.

18:52.620 --> 18:59.620
What explains those? There's a neutral research program here that both realists, illusionists,

19:00.020 --> 19:03.200
people of all kinds of different views of consciousness can explain, and then we can

19:03.200 --> 19:09.320
come back and look at the philosophical consequences. Well, I'm not an illusionist, I think consciousness

19:09.320 --> 19:14.440
is real. I've got to say, I do feel the temptation of illusionism, I find it really intriguing

19:14.440 --> 19:20.480
and in some ways attractive to you, just fundamentally unbelievable. Nevertheless, I think that the

19:20.480 --> 19:26.960
meta problem should be a tractable problem. Solving it will shed, at the very least, will

19:26.960 --> 19:31.720
shed much light on the hard problem of consciousness, even if it doesn't solve it. If you can explain

19:31.760 --> 19:36.480
our conviction that we're conscious, somehow the source, the roots of our conviction that

19:36.480 --> 19:41.280
we're conscious must have something to do with consciousness, especially if consciousness

19:41.280 --> 19:47.720
is real. I think it's very much a good research program for people to explain. Then I'll move

19:47.720 --> 19:53.880
on now to just outlining the research program a little bit more and then talk a bit about

19:53.880 --> 19:59.120
potential solutions and on impact on theories of consciousness before wrapping up with just

19:59.200 --> 20:06.200
a little bit more about illusionism. This meta problem, which I've been pushing recently,

20:06.920 --> 20:12.920
opens up a tractable empirical research program for everyone, reductionists, non-reductionists,

20:12.920 --> 20:18.420
illusionists, non-illusionists. We can try to solve it and then think about the philosophical

20:18.420 --> 20:25.420
consequences. What is the meta problem? Well, the way I'm going to put it is it's the problem

20:26.420 --> 20:33.420
of topic neutrally explaining problem intuitions or else explaining why that can't be done.

20:34.420 --> 20:41.420
I'll unpack all the pieces of that right now, first starting with problem intuitions. What

20:41.820 --> 20:47.260
are problem intuitions? Well, those are the things we say. There are things we think.

20:47.260 --> 20:51.780
I say consciousness seems irreducible. I might think consciousness is irreducible. People

20:51.780 --> 20:56.700
might be disposed, have a tendency to say or think those things. Problem intuitions all

20:56.700 --> 21:02.820
take to be roughly that tendency. We have dispositions to say and think certain things

21:02.820 --> 21:08.580
about consciousness. What are the core problem intuitions? Well, I think they break down into

21:08.580 --> 21:13.100
a number of different kinds. There's the intuition that consciousness is non-physical. We might

21:13.100 --> 21:17.660
think of that as a metaphysical intuition about the nature of consciousness. There are

21:17.700 --> 21:23.300
intuitions about explanation. Consciousness is hard to explain. Explaining behavior doesn't

21:23.300 --> 21:28.180
explain consciousness. There are intuitions about knowledge of consciousness. Some of

21:28.180 --> 21:32.460
you may know the famous thought experiment of Mary in the black and white room who knows

21:32.460 --> 21:37.380
all about the objective nature of color vision and so on, but still doesn't know what it's

21:37.380 --> 21:41.700
like to see red. She sees red for the first time. She learns something new. That's an

21:41.700 --> 21:46.140
intuition about knowledge of consciousness. There are what philosophers call modal intuitions

21:46.140 --> 21:52.060
about what's possible or imaginable. One famous case is the case of a zombie, a creature

21:52.060 --> 21:57.460
who's physically identical to you and me, but not conscious, or maybe an AI system which

21:57.460 --> 22:02.460
is functionally identical to you and me, but not conscious. That at least seems conceivable

22:02.460 --> 22:08.660
to many people. This is the philosophical zombie, unlike the zombies in movies which

22:08.660 --> 22:13.380
have weird behaviors and go after brains and so on. The philosophical zombie is a creature

22:13.500 --> 22:18.900
that seems, at least behaviorally, maybe physically like a normal human, but doesn't have any

22:18.900 --> 22:23.980
conscious experiences. All the physical states, none of the mental states. It seems to many

22:23.980 --> 22:28.260
people that's at least conceivable. We're not zombies. I don't think anyone here is

22:28.260 --> 22:33.420
a zombie, I hope, but nonetheless, it seems that we can make sense of the idea and one

22:33.420 --> 22:38.300
way to pose the hard problem is why are we not zombies. This imaginability of zombies

22:38.300 --> 22:43.220
is one of the intuitions that gets the problem going. Then you can go on and catalog more

22:43.540 --> 22:48.300
and more intuitions about the distribution of conscious, maybe the intuition that robots

22:48.300 --> 22:53.580
won't be conscious. That's an optional one, I think, or consciousness matters morally

22:53.580 --> 23:00.080
in certain ways and the list goes on. I think there's an interdisciplinary research program

23:00.080 --> 23:06.180
here of working on those intuitions about consciousness and trying to explain them.

23:06.180 --> 23:11.460
Experimental psychology and experimental philosophy and newly active area can study people's intuitions

23:11.500 --> 23:16.540
about consciousness. We can work on models of these things, computational models or neurobiological

23:16.540 --> 23:20.620
models of these intuitions and reports, and indeed, I think there's a lot of room for

23:20.620 --> 23:25.460
philosophical analysis. There's just starting to be a program of people doing these things

23:25.460 --> 23:32.460
in all these fields. It is an empirical question how widely these intuitions are shared. You

23:32.460 --> 23:35.740
might be sitting there thinking, come on, I don't have any of these intuitions. Maybe

23:35.740 --> 23:40.740
this is just you. My sense is from the psychological study to date, it seems that some of these

23:40.740 --> 23:45.940
intuitions about consciousness are at least very widely shared, at least as dispositions

23:45.940 --> 23:51.940
or intuitions, although they're often overridden on reflection. The current data on this is

23:51.940 --> 23:58.940
somewhat limited. There is a lot of empirical work on intuitions about the mind concerning

23:58.980 --> 24:03.020
things like belief, like when do kids get the idea that your belief's about the world,

24:03.020 --> 24:08.340
can be false, concerning the way your self persists through time, could you exist after

24:08.340 --> 24:12.180
the death of your body? Well, consciousness is concerned. There's work on the distribution

24:12.180 --> 24:15.860
of consciousness. Could a robot be conscious? Could a group be conscious? Here's a book

24:15.860 --> 24:19.980
by Paul Bloom, Descartes' Baby. The catalog's a lot of this interesting work, making the

24:19.980 --> 24:26.340
case that many children are intuitive dualists. They're naturally inclined to think there's

24:26.340 --> 24:30.980
something non-physical about the mind. So far, most of this work has not been so much

24:30.980 --> 24:37.220
on these core problem intuitions about consciousness, but there's work developing in this direction.

24:37.260 --> 24:42.060
Sarah Gottlieb and Tanya Lombrozo have a very recent article called Can Science Explain

24:42.060 --> 24:48.340
the Human Mind on People's Judgements about when various mental phenomena are hard to

24:48.340 --> 24:52.540
explain and they seem to find that, yes, subjective experience and things which have, to which

24:52.540 --> 24:58.420
people have privileged first person access seem to pose the problem big time. So there's

24:58.420 --> 25:03.660
the beginning of a research program here. I think there's room for a lot more.

25:03.660 --> 25:08.700
The topic neutrality part, when I say we're looking for a topic neutral explanation of

25:08.700 --> 25:13.740
problem intuitions, that's roughly to say an explanation that doesn't mention consciousness

25:13.740 --> 25:18.700
itself. It's put in neutral terms. It's neutral on the existence of consciousness. The most

25:18.700 --> 25:23.700
obvious one would be something like an algorithmic explanation. I can say, here is the algorithm.

25:23.700 --> 25:29.260
The brain is executing. It generates our conviction that we're conscious and our reports about

25:29.300 --> 25:33.620
consciousness. There may be some time between that algorithm and consciousness, but to specify

25:33.620 --> 25:39.820
the algorithm, you don't need to make claims about consciousness. So the algorithmic version

25:39.820 --> 25:45.340
of the metaproblem is roughly find the algorithm that generates our problem intuition. So that's

25:45.340 --> 25:54.340
I think a principal research program that maybe AI researchers in combination would say psychologists,

25:54.900 --> 26:00.500
the psychologist could help isolate data about the way that the human beings are doing it,

26:00.500 --> 26:04.820
how these things are generated in humans and AI researchers can try and see about implementing

26:04.820 --> 26:09.380
that algorithm in machines and see what results. And I'll talk about a little bit of research

26:09.380 --> 26:15.340
in this direction in just a moment. But okay, now I want to say something about potential

26:15.340 --> 26:20.100
solutions to the problem. Like I say, this is a big research program. I don't claim to

26:20.100 --> 26:24.300
have the solution to the metaproblem. I've got some ideas, but I'm not going to try and

26:24.300 --> 26:30.700
lay out a major solution or just so here are a few things which I think might be parts

26:30.700 --> 26:35.780
of a solution to the problem, many of which have got antecedents here and there in scientific

26:35.780 --> 26:41.220
and philosophical discussion. Some promising ideas include retrospective models, phenomenal

26:41.220 --> 26:46.140
concepts, introspective opacity, the sense of acquaintance. Let me just say something

26:46.140 --> 26:52.300
about a few of these. One starting idea that almost anyone's going to have here is somehow

26:52.300 --> 26:59.100
models of ourselves are playing a central role here. Human beings have models of the

26:59.100 --> 27:06.020
world, naive physics and naive psychology, models of other people and so on. We also

27:06.020 --> 27:10.660
have models of ourselves. It makes sense for us to have models of ourselves and our own

27:10.660 --> 27:15.660
mental processes. This is something that the psychologist Michael Graziano has written

27:15.660 --> 27:21.620
a lot on. We have internal models of our own cognitive processes, including those tied

27:21.660 --> 27:27.660
to consciousness. Somehow, something about our introspective models explains our sense,

27:27.660 --> 27:32.980
A, that we are conscious and B, that this is distinctively problematic. I think anyone

27:32.980 --> 27:38.180
thinking about the metaproblem, this has got to be at least the first step. We have these

27:38.180 --> 27:42.260
introspective models. If you're an illusionist, they'll be false models. If you're a realist,

27:42.260 --> 27:48.340
they needn't be false models, but at the very least, these introspective models are involved,

27:48.380 --> 27:53.860
which is fine, but the devil's in the details. How do they work to generate this problem?

27:53.860 --> 27:58.780
A number of philosophers have argued we have special concepts of consciousness, introspective

27:58.780 --> 28:04.380
concepts of these special subjective states. People call these phenomenal concepts, concepts

28:04.380 --> 28:10.460
of phenomenal consciousness. One thing that's special is these concepts are somehow independent

28:10.460 --> 28:17.460
of our physical concepts. They explain, we've got one set of physical concepts for modeling

28:17.460 --> 28:21.420
the external work world. We've got one set of introspective concepts for modeling our

28:21.420 --> 28:25.220
own mind. These concepts, just by virtue of the way they're designed, are somewhat independent

28:25.220 --> 28:31.340
of each other, and that partly explains why consciousness seems to be independent of

28:31.340 --> 28:36.980
the physical world, intuitively. Maybe that independence of phenomenal concepts could

28:36.980 --> 28:41.660
go some distance to explaining our problem report. I think there's got to be something

28:41.660 --> 28:47.380
to this as well. At the same time, I don't think this goes nearly far enough because

28:47.860 --> 28:52.460
we have concepts of many aspects of the mind, not just of the subjective experiential past,

28:52.460 --> 28:58.180
but things we believe and things we desire. One, I believe that Paris is the capital of

28:58.180 --> 29:04.300
France. That's part of my internal self-model, but that doesn't seem to generate the hard

29:04.300 --> 29:09.060
problem in nearly the same way in which, say, the experience of red does. A lot more needs

29:09.060 --> 29:14.380
to be said about what's going on in cases like having the experience of red and having

29:14.380 --> 29:19.060
the sense that that generates a gap, so it doesn't generalize to everything about the

29:19.060 --> 29:25.260
mind. Some people have thought that what we might call introspective opacity plays a

29:25.260 --> 29:31.020
role, that when we introspect what's going on in our minds, we don't have access to the

29:31.020 --> 29:35.540
underlying physical states. We don't see the neurons in our brains. We don't see that

29:35.540 --> 29:42.300
consciousness as physical, so we see it as non-physical. Most recently, the physicist

29:42.340 --> 29:45.740
Max Tegmark has argued in this direction, saying, somehow, consciousness is substrate

29:45.740 --> 29:50.500
independent. We don't see the substrate, so then we think, ah, maybe it can float free

29:50.500 --> 29:59.020
of the substrate. Armstrong made an analogy with the case of someone in a circus where

29:59.020 --> 30:04.820
the headless person illusion where you don't see someone's there with a veil across their

30:04.820 --> 30:12.140
head. You don't see their head, so you see them as having no head. Here is a 19th century

30:12.180 --> 30:16.180
booth at a circus, a so-called headless woman with a veil over her head. You don't see the

30:16.180 --> 30:20.300
head, so somehow it looks at least for a moment like the person doesn't have a head. Armstrong

30:20.300 --> 30:25.100
says, maybe that's how it is with consciousness. You don't see that it's physical, so you

30:25.100 --> 30:32.820
see it as non-physical. But still, the question comes up, how do we make this inference? There's

30:32.820 --> 30:38.340
something that special goes on in cases like, say, color and taste and so on. Color experience

30:38.340 --> 30:44.300
seems to attribute primitive properties to objects like redness, greenness and so on.

30:44.300 --> 30:48.580
But in fact, in the external world, at the very least, they have complex, reducible

30:48.580 --> 30:55.020
properties. Somehow, internal models of color treat colors like red and green as if they

30:55.020 --> 31:00.580
are primitive things. It turns out to be useful to have these models of things where you treat

31:00.580 --> 31:04.780
certain things as primitive even though they're reducible. And it sure seems that when we

31:04.780 --> 31:10.500
experience colors, we experience greenness as a primitive quality, even though it may

31:10.500 --> 31:15.860
be a very, very complex reducible property. That's something about our model of colors.

31:15.860 --> 31:21.180
The philosopher Wolfgang Schwartz tried to make an analogy with sensor variables in,

31:21.180 --> 31:26.660
say, image processing. You've got some visual sensors and a camera or something. You need

31:26.660 --> 31:32.300
to process the image. Well, you've got some variables, some sensor variables to represent

31:32.300 --> 31:35.620
the sensory inputs that the various sensors are getting. And you might treat them as a

31:35.620 --> 31:39.100
primitive dimension because that's the most useful way to treat them. You don't treat

31:39.100 --> 31:44.420
them as certain amounts of lights or photons firing. You don't need to know about that.

31:44.420 --> 31:49.500
Use these sensor variables and treat them as a primitive dimension. And all that will

31:49.500 --> 31:54.260
play into a model of these things as primitive. Maybe taking that idea and extending it to

31:54.260 --> 32:00.820
introspection, you know, somehow these conscious states are somehow like sensor variables in

32:00.820 --> 32:07.420
our model of the mind. And somehow these internal models give us the sense of being acquainted

32:07.420 --> 32:13.180
with primitive concrete qualities and of our awareness of them. This is still just laying

32:13.180 --> 32:17.140
out. I don't think this is still yet actually explaining a whole lot, but it's laying out.

32:17.140 --> 32:22.220
It's narrowing down what it is that we need to explain to solve the meta problem. But

32:22.220 --> 32:25.820
just to put the pieces together, here's a little summary. One thing I like about this

32:25.820 --> 32:32.960
summary is you can read it in either an illusionist tone of voice as an account of the illusion

32:32.960 --> 32:38.220
of consciousness. All this is how our false introspective models work or in a realist

32:38.220 --> 32:45.540
tone of voice as an account of our true, correct models of consciousness. But we can set it

32:45.540 --> 32:49.140
out in a way which is neutral on the two and then try and figure out later whether these

32:49.140 --> 32:55.220
models are correct as the realist says or incorrect as the illusionist says. We have

32:55.220 --> 33:02.620
introspective models deploying introspective concepts of our internal states that are largely

33:02.620 --> 33:09.180
independent of our physical concepts. These concepts are introspectively opaque, not revealing

33:09.180 --> 33:15.540
any of the underlying mechanisms, our perceptual models perceptually attribute primitive perceptual

33:15.540 --> 33:22.700
qualities to the world, and our introspective models attribute primitive mental relations

33:22.780 --> 33:29.980
to those qualities. These models produce the sense of acquaintance both with those qualities

33:29.980 --> 33:35.700
and with our awareness of those qualities. Like I said, this is not a solution to the

33:35.700 --> 33:40.580
meta problem, but it's trying at least to pin down some parts of the roots of those

33:40.580 --> 33:46.060
intuitions and to narrow down what needs to be explained. To go further, you want, I think,

33:46.060 --> 33:51.580
to test these explanations, both with psychological studies to see if this is plausibly what's

33:51.580 --> 33:56.340
going on in humans. This is the kind of thing which is the basis of our intuitions and computational

33:56.340 --> 34:00.500
models to see if, for example, you could program this kind of thing into an AI system and see

34:00.500 --> 34:07.140
if it can generate somehow qualitatively similar reports and intuitions. You might think that

34:07.140 --> 34:12.500
last thing is a bit far-fetched right now, but I know of at least one instance of this

34:12.500 --> 34:18.660
research program which has been put into play by Luke Milhauser and Bach Schleggeres, two

34:18.700 --> 34:26.860
researchers at Open Philanthropy, very interested in AI and consciousness. They actually built,

34:26.860 --> 34:31.300
they took some ideas about the meta problem from something I'd written about it and from

34:31.300 --> 34:37.900
something that the philosopher Francois Camero had written about it. A couple of basic ideas about

34:37.900 --> 34:43.460
where problem intuitions might come from, and they tried to build them in to a computational

34:44.060 --> 34:52.980
model. They built a little software agent which had certain axioms about colors and how they

34:52.980 --> 34:58.500
work. There's red and there's green, and certain axioms about their own subjective experiences

34:58.500 --> 35:06.180
of colors, and then they combined it with a little theorem prover, and they saw what did

35:06.180 --> 35:10.140
this little software agent come up with, and it came up with claims like, hey, well, my

35:11.100 --> 35:16.620
experiences of color are distinct from any physical state, and so on. They cut a few corners.

35:18.700 --> 35:25.820
This is not yet a truly convincing, sophisticated model of everything going on in the human mind,

35:25.820 --> 35:31.420
but it shows that there's a research program here of trying to find the algorithmic basis

35:32.140 --> 35:37.260
of these states. I think as more sophisticated models develop, we might be able to use these

35:37.340 --> 35:41.900
to provide a way in for AI researchers in thinking about this topic. Of course,

35:41.900 --> 35:46.220
there is the question, if you model all this stuff better and better in a machine,

35:46.220 --> 35:51.020
then is the machine actually going to be conscious, or is it just going to have found

35:51.020 --> 35:58.460
self-models that replicate what's going on in humans? Some people have proposed an artificial

35:58.460 --> 36:06.140
consciousness test. Aaron Sloman, Susan Snyder, and Turner have suggested somehow that if a machine

36:06.220 --> 36:10.380
seems to be puzzled about consciousness in roughly the ways that we are,

36:10.380 --> 36:16.860
maybe that's actually a sign that it's conscious. If a machine actually looks to ask

36:16.860 --> 36:22.140
as if it's puzzled by consciousness, is that a sign of consciousness? These people,

36:22.140 --> 36:26.620
this is suggested as a kind of Turing test for machine consciousness. Find machines which are

36:26.620 --> 36:30.140
conscious like we are. Of course, the opposing point of view is going to be, no, the machine is

36:30.140 --> 36:35.340
not actually conscious. It's just like the machine that studied up for the Turing test by reading

36:35.340 --> 36:41.260
the talk like a human book. It's like, damn, do I really need to convince those humans that I'm

36:41.260 --> 36:47.420
conscious by replicating all those ill-conceived confusions about consciousness? Well, I guess

36:47.420 --> 36:53.340
I can do it if I need to. Anyway, I'm not going to settle this question here, but I do think that

36:53.340 --> 36:59.260
if we somehow find machines being puzzled, it won't surprise me that once we actually have

36:59.260 --> 37:04.300
serious AI systems which engage in natural language and modeling of themselves in the world,

37:05.420 --> 37:09.020
they might well be natural to find themselves saying things like, yeah, I know in principle I'm

37:09.020 --> 37:16.460
just a set of silicon circuits, but I feel like so much more. I think that might tell us something

37:16.460 --> 37:23.580
about consciousness. Let me just say a little bit about theories of consciousness. I do think a

37:23.580 --> 37:29.020
solution to the meta problem and a solution to the hard problem ought to be closely connected.

37:29.020 --> 37:32.860
The illusionist says, solve the meta problem. You'll dissolve the hard problem. But even if

37:32.860 --> 37:39.340
you're not an illusionist about consciousness, there ought to be some link. So here's a thesis.

37:39.340 --> 37:45.660
Whatever explains consciousness should also partly explain our judgments and our reports

37:46.300 --> 37:50.620
about consciousness. The rationale here is it would just be very strange if these things were

37:51.180 --> 37:58.620
independent. If the basis of consciousness played no role in our judgments about consciousness.

37:59.340 --> 38:05.820
So I think you can use this as a way of evaluating or testing theories of consciousness. For theory

38:05.820 --> 38:11.900
of consciousness, there's mechanism M is the basis of consciousness, that M should also partly

38:11.900 --> 38:18.700
explain our judgments about consciousness. Whatever the basis is ought to explain the reports.

38:18.700 --> 38:24.380
And you can use this. You can bring this to bear on various extant theories of consciousness. Here's

38:24.460 --> 38:30.060
one famous current theory of consciousness, integrated information theory developed by

38:30.060 --> 38:38.700
Giulio Tononi and colleagues at the University of Wisconsin. Tononi says the basis of consciousness

38:38.700 --> 38:45.260
is integrated information. A certain kind of integration of information for which Tononi

38:45.260 --> 38:50.860
has a measure that he calls phi. Basically, when your phi is high enough, you get consciousness.

38:50.940 --> 38:56.220
So consciousness is high phi. And there's a mathematical definition, but I won't go into

38:56.220 --> 39:02.540
it here. But such a really interesting theory. So here's a, basically it analyzes a network

39:02.540 --> 39:08.140
property of systems, of units, and it's got an informational measure called phi that's supposed

39:08.140 --> 39:14.700
to go with consciousness. Question. How does, if integrated information is the basis of consciousness,

39:14.700 --> 39:20.060
it ought to explain problem reports, at least in principle. Challenge. How does that work?

39:20.060 --> 39:25.180
And it's at least far from obvious to me how integrated information will explain the problem

39:25.180 --> 39:31.580
reports. It seems pretty dissociated from them. I mean, on Tononi's view, you can have simulations

39:32.220 --> 39:38.460
of systems with high phi that have zero phi. They'll go about making exactly the same reports,

39:38.460 --> 39:43.740
but without consciousness at all. So phi is at least somewhat dissociable. You get systems

39:43.820 --> 39:50.460
very high phi, but no tendency to report. Maybe that's less worrying. Anyway, here's a challenge

39:50.460 --> 39:55.020
for this theory, for other theories. Explain not just how high phi gives you consciousness,

39:55.020 --> 40:01.100
but how it plays a central role in the algorithms that generate problem reports. Something similar

40:01.100 --> 40:07.740
goes for many other theories, biological theories, quantum theories, global workspace, and so on.

40:08.540 --> 40:13.500
But let me just wrap up by saying something about the issue of illusionism that I was

40:13.740 --> 40:19.020
talking about near the start. Again, you might be inclined to think that this approach through

40:19.020 --> 40:23.980
the meta problem tends, at least very naturally, to lead to illusionism. And I think it can be,

40:24.620 --> 40:29.740
it certainly provides, I think, some motivation for illusionism. The view that consciousness

40:29.740 --> 40:36.220
doesn't exist, we just think it does. On this view, again, a solution to the meta problem dissolves

40:36.780 --> 40:43.580
the hard problem. So here's one way of putting the case for illusionism. If there's a solution

40:43.580 --> 40:48.700
to the meta problem, then there's an explanation of our beliefs about consciousness that's

40:48.700 --> 40:52.860
independent of consciousness. There's an algorithm that explains our beliefs about

40:52.860 --> 40:57.260
consciousness, doesn't mention consciousness, arguably could be in place without consciousness.

40:57.820 --> 41:04.300
Arguably, that kind of explanation could debunk our beliefs about consciousness the same way that,

41:04.300 --> 41:10.540
perhaps, explaining beliefs about God in evolutionary terms might debunk belief in God.

41:10.540 --> 41:14.220
It certainly doesn't prove that God doesn't exist. You might think that if you can explain

41:14.220 --> 41:20.300
our beliefs in terms of evolution, it somehow removes the justification or the rational basis

41:20.300 --> 41:24.780
for those beliefs. So something like that, I think, can be applied to consciousness, too. And

41:24.780 --> 41:30.460
there's a lot to be said about analyzing the extent to which this might debunk the beliefs.

41:30.460 --> 41:36.140
On the other hand, the case against illusionism is very, very strong for many people. And the

41:36.140 --> 41:40.620
underlying worry is that some illusionism is completely unbelievable. It's just a manifest

41:40.620 --> 41:47.420
fact about ourselves that we have conscious experience, we experience red, we feel pain,

41:47.420 --> 41:53.740
and so on. To deny those things is to deny the data. Now, the dialectic here is complicated.

41:53.740 --> 41:58.620
The illusionist will come back and say, yes, but I can explain why illusionism is unbelievable.

41:58.620 --> 42:03.180
These models we have, these self-models of consciousness, are so strong that they're

42:03.260 --> 42:08.380
just wired into us by evolution, and they're not models we can get rid of. So my view predicts

42:08.380 --> 42:14.780
that my view is unbelievable. And the question is what, the dialectical situation is complex

42:14.780 --> 42:21.340
and interesting. But maybe I could just wrap up with two expressions of absurdity on either side

42:21.340 --> 42:28.860
of this question, the illusionist and the anti-illusionist, both finding absurdity

42:28.940 --> 42:36.140
in the other person's views. Here's Galen Strawson, who is here. Galen's view is very much that

42:36.140 --> 42:41.180
illusionism is totally absurd. In fact, he thinks it's the most absurd view that anyone has ever

42:41.180 --> 42:47.180
held. There occurred in the 20th century, the most remarkable episode in the whole history of ideas,

42:47.180 --> 42:51.980
the whole history of human thought, a number of thinkers denied the existence of something we

42:51.980 --> 42:57.260
know with certainty to exist, consciousness. He thinks this is just a sign of incredible

42:57.260 --> 43:03.260
philosophical pathology. Here's the rationalist philosopher Eliezer Yudkowski in something he

43:03.260 --> 43:10.620
wrote a few years ago on zombies and consciousness, and the view, the epiphenomenalist view that

43:10.620 --> 43:15.660
consciousness plays no causal role, where he was engaging some stuff I wrote a couple of decades

43:15.660 --> 43:19.900
ago. He said, this is a zombie argument, the idea we can imagine zombies physically like us,

43:19.900 --> 43:25.740
but without consciousness. Maybe a candidate for the most deranged idea in all of philosophy.

43:26.300 --> 43:33.980
The causally closed cognitive system of charmer's internal narrative is malfunctioning in a way that

43:33.980 --> 43:40.620
not by necessity, but just in our own universe miraculously happens to be correct. Here he's

43:40.620 --> 43:45.100
expressing this debunking idea that on this view, there's an algorithm that generates these

43:45.100 --> 43:49.500
intuitions about consciousness, and that's all physical. There's also this further layer of

43:49.500 --> 43:57.260
non-physical stuff, and just by massive coincidence, the physical algorithm is a correct model of the

43:57.260 --> 44:04.220
non-physical stuff. That's a form of debunking here. It would take a miracle for this view to be

44:04.220 --> 44:09.900
correct. So I think both of these views are onto, these objections are onto something, and to make

44:09.900 --> 44:15.260
progress on this, when I decide we need to find a way of getting past these absurdities. I mean,

44:15.260 --> 44:20.780
you might say, well, there's middle ground between very strong illusionism and very strong epiphenomenalism.

44:20.780 --> 44:27.100
It tends to slide back to the same problems. Other forms of illusionism, weaker forms don't

44:27.100 --> 44:32.700
help much with the higher problem. Other forms of realism are still subject to this. It takes a

44:32.700 --> 44:40.380
miracle for this view to be correct. Critique. So I think to get beyond absurdity here, both sides

44:40.380 --> 44:45.100
need to do something more. The illusionist needs to do more to explain how having a mind could

44:45.100 --> 44:51.260
be like this, somehow just like this, even though it's not at all the way that it seems. They need

44:51.260 --> 44:58.300
to find some way to recapture the data. Realists need to explain how it is that these meta-problem

44:58.300 --> 45:03.020
processes are not completely independent of consciousness. Realists need to explain how

45:03.020 --> 45:08.940
meta-problem processes, the ones that generate these intuitions and reports and convictions

45:08.940 --> 45:13.820
about consciousness are essentially grounded in consciousness, even if it's possible somehow for

45:13.820 --> 45:20.540
them to occur or conceivable for them to occur without consciousness. Anyway, so that's just to

45:20.540 --> 45:27.100
lay out a research program. I think a solution to the meta-problem that meets these ambitions

45:27.100 --> 45:32.060
might just possibly solve the hard problem of consciousness or at the very least,

45:32.060 --> 45:37.580
shed significant light on it. In the meantime, the meta-problem is a potentially tractable

45:37.580 --> 45:40.940
research project for everyone, and mine I recommend to all of you. Thanks.

45:48.380 --> 45:54.540
Yes, I just want to say I think it's very interesting this concept of we have these mental models,

45:55.100 --> 46:02.540
collection of mental models, and that this collection of mental models is consciousness,

46:02.620 --> 46:07.420
basically. Consciousness is defined as a collection of these mental models that we have,

46:07.420 --> 46:12.540
and the problem of consciousness is that we don't understand the physical phenomenon that

46:12.540 --> 46:19.740
causes these mental models or that stimulates these mental models. So we just have this belief

46:19.740 --> 46:28.220
that it's ephemeral or not real or something like that. And if you take that view, then what's

46:28.220 --> 46:35.100
interesting is that you could simulate these mental models, like robot could simulate these

46:35.100 --> 46:42.780
mental models, and you could simulate consciousness as well. And even if the underlying physical

46:42.780 --> 46:47.580
phenomenon that fuels these mental models is different, you know, robots have different

46:47.580 --> 46:53.980
sensors, etc., you could still get the same consciousness effect in both cases.

46:54.780 --> 46:58.620
Yeah, I think that's right. Or at the very least, you ought to be able to get,

46:58.620 --> 47:02.380
it looks like you ought to be able to get the same models at least in a robot. If the models

47:02.380 --> 47:07.900
themselves are something algorithmic, and ought to be, you ought to be able to design a robot

47:07.900 --> 47:13.660
that has at the very least, let's say, isomorphic models in some sense that is conscious. Of course,

47:13.660 --> 47:17.980
it's a further question, at least by my lights, but then the robot will be conscious. And that was

47:17.980 --> 47:21.420
the question I alluded to in talking about the artificial consciousness test. But you might think

47:21.420 --> 47:25.580
that would at least be very good evidence that the robot is conscious. If it's got a model of

47:25.580 --> 47:30.140
consciousness just like ours, it seems very plausible there ought to be a very strong link

47:30.140 --> 47:35.660
between having a model like that and being conscious. I mean, I think probably something

47:35.660 --> 47:39.020
like Ned Block, who was here arguing against machine consciousness, would say, no, no,

47:39.020 --> 47:42.700
the model is not enough. The model has to be built of the right stuff. Say it's got to be

47:42.700 --> 47:46.860
built of biology and so on. But at least by my lights, I think if I have found the AI system

47:46.860 --> 47:52.220
that had a very serious version of our model of consciousness, I take that as a very good reason

47:52.220 --> 48:00.940
to believe it's conscious. In the IIT theory, is there a estimate or plausible estimate for what

48:00.940 --> 48:10.780
the value of phi is for people and for other systems? Basically, no. It's extremely hard to measure

48:11.340 --> 48:17.980
in systems of any size at all. I mean, because the way it's defined involves taking a sum over

48:17.980 --> 48:23.340
every possible partition of a system. It turns out, I mean, A, it's hard to measure in the brain

48:23.340 --> 48:27.820
because you've got to involve the causal dependencies set between different units on neurons. But even

48:27.820 --> 48:34.380
for a pure algorithmic system, you've got like a neural network laid out in front of you,

48:34.380 --> 48:38.220
it's computationally intractable to measure the phi of one of those once they get to bigger than

48:38.220 --> 48:43.580
15 units or so. So, you know, today I'd like to say this is an empirical theory and in principle

48:43.580 --> 48:50.140
empirically testable. But notice the in principle, it's extremely difficult to to to measure phi.

48:50.140 --> 48:59.020
Some people, Scott Aronson, the computer scientist has argued, has tried to put forward counter-examples

48:59.020 --> 49:05.180
to the theory, which are basically very, very simple systems like matrix multipliers that

49:05.260 --> 49:09.900
multiply two large matrices turn out to have enormous phi. Phi is as big as you like if the

49:09.900 --> 49:14.620
matrices are big enough. And therefore, by Tononi's theory, we'll not just be conscious, but as

49:14.620 --> 49:19.980
conscious as a human being. And Aronson put this forward as a reductio ad absurdum of the IIT theory.

49:19.980 --> 49:24.620
I think Tononi basically bit the bullet and said, yeah, yeah, those those matrix multipliers are

49:24.620 --> 49:30.620
actually having some high degree of consciousness. So I think IIT is probably missing at least

49:30.620 --> 49:34.540
missing a few pieces of what's going to be developed. But it's a research program too.

49:36.060 --> 49:41.980
You mentioned belief as an example of something where, you know, this is another mental quality,

49:41.980 --> 49:47.900
but people don't seem to have the same sense that it is very hard to explain. In fact,

49:48.940 --> 49:53.900
it almost seems too easy where people like a belief about something sort of feels like just

49:53.900 --> 49:59.580
how things are. You have to kind of reflect on a belief to notice it as a belief. Do you

50:00.220 --> 50:06.700
think there's also or has there been research kind of related to this question into why is that

50:06.700 --> 50:11.500
different? Like, it seems like another angle of attack on this problem is just like, why doesn't

50:11.500 --> 50:16.460
this generate the same hard problem? Yeah, in terms, I'm not sure if there's been sort of

50:17.740 --> 50:20.860
research from the perspective of the meta problem or a theory of mind. Certainly,

50:20.860 --> 50:25.820
people have thought in their own right, what is the difference between belief and experience

50:25.820 --> 50:31.340
that makes them so different? This goes way back to David Hume, a philosopher a few centuries ago,

50:31.340 --> 50:38.220
who said, you know, basically, perception is vivid. Impressions and ideas. Impressions like

50:38.220 --> 50:44.780
experiencing colors are vivid. They have force and vivacity and ideas are merely a faint copy

50:44.780 --> 50:48.540
or something. But that's just the first order. And then there are contemporary versions of this

50:48.540 --> 50:52.940
kind of thing, far more sophisticated ways of saying a similar thing. But yeah, you could,

50:53.020 --> 50:59.500
in principle, explore that through the meta problem. Why does it seem to us that perception is so

50:59.500 --> 51:05.260
much more vivid? What about our models of the mind makes perception seem so much more vivid

51:05.260 --> 51:10.380
than belief? It makes belief seem kind of structural and empty, whereas

51:11.180 --> 51:15.500
perception is so full of light. But no, I don't know of work on that from the meta problem

51:15.500 --> 51:20.220
perspective. Like I said, there's not that much work on these introspective models directly. There

51:20.220 --> 51:23.980
is work on theory of mind about beliefs tends to be about models of other people.

51:25.980 --> 51:29.420
It may be there's something I could dig through a literature on belief that says something about

51:29.420 --> 51:35.340
that. It's a good place to push. Thanks. I wanted to bring up Kurt Girdel. You mentioned your advisor

51:35.340 --> 51:41.500
wrote Girdel Escher Bach. There's something that seems very like Girdel, Girdelian or whatever,

51:41.500 --> 51:48.380
about this whole discussion in that. So Girdel showed that, given like a set of axioms and

51:48.380 --> 51:57.820
mathematics, it would either be consistent or complete, but not both. And it seems like when

51:57.820 --> 52:04.860
Daniel Dennett, Daniel Dennett seems to have like a set of axioms where he cannot construct

52:04.860 --> 52:09.580
consciousness from them. He seems to be very much in this sort of consistent camp. Like he

52:09.580 --> 52:17.020
wants to have a consistent framework, but is okay with the incompleteness. And I wonder if

52:17.100 --> 52:22.860
similar approach could be taken with consciousness where we could in fact prove that consciousness

52:22.860 --> 52:29.020
is independent of Daniel Dennett's set of axioms. The same way they proved after Girdel, they

52:29.020 --> 52:34.220
proved like the continuum hypothesis was independent of ZF set theory. And then they added

52:34.860 --> 52:42.140
the axiom of choice made at ZFC set theory. So I wonder if we could show that like in Daniel

52:42.140 --> 52:47.260
Dennett's world we are essentially zombies or we are kind of either zombies or not. It doesn't

52:47.260 --> 52:53.660
matter. Either statement could be true. And then find what is like the minimum axiom that has to be

52:53.660 --> 52:59.500
added to Dennett's axioms in order to make consciousness true. Interesting. I thought for a

52:59.500 --> 53:03.020
moment this was going to go in a different direction. And you're going to say Dennett is

53:04.460 --> 53:09.100
consistent but incomplete. He doesn't have consciousness in this picture. I'm complete,

53:09.180 --> 53:12.620
I've got consciousness, but inconsistent. That's why I say all these crazy things.

53:14.140 --> 53:18.860
And you're faced with the choice of not having consciousness and being incomplete or having

53:18.860 --> 53:23.180
consciousness and somehow getting this hard problem and being forced into at least puzzles

53:23.180 --> 53:25.980
and paradoxes. But the way you put it was friendlier to me.

53:30.220 --> 53:35.660
Yeah, I mean certainly Dark Hofstetter himself has written a lot on analogies between the

53:35.660 --> 53:41.100
Gordelian paradoxes and the mind-body problem. And he thinks always our models, our self models

53:41.100 --> 53:45.740
are always doomed to be incomplete in the Gordelian way. And he thinks that that might be somehow

53:45.740 --> 53:50.940
part of the explanation of our puzzlement at least about consciousness. Someone like Roger Penrose,

53:50.940 --> 53:57.740
of course, takes this much more seriously, literally. He thinks that the computational

53:57.740 --> 54:04.060
aspects of computational systems are always going to be limited in the Gordel way. He thinks human

54:04.060 --> 54:08.620
beings are not so limited. He thinks we've got mathematical capacities to prove theorems,

54:09.580 --> 54:15.260
to see the truth of certain mathematical claims that no formal system could ever have.

54:15.820 --> 54:20.380
So he thinks that we somehow go beyond that incomplete Gordelian. I don't know if he actually

54:20.380 --> 54:24.860
thinks we're complete, but at least we're not incomplete in the way that finite computational

54:24.860 --> 54:30.220
systems are incomplete. And furthermore, he thinks that extra thing that humans have is tied to

54:30.220 --> 54:35.180
consciousness. I mean, I never quite saw how that last step goes, even if we did have these

54:35.180 --> 54:39.500
special non-algorithmic capacities to see the truth of mathematical theorems. How would that be

54:39.500 --> 54:47.100
tied to consciousness? But at the very least, there are structural analogies to be drawn between

54:47.100 --> 54:51.420
those two cases about incompleteness of certain theories, how literally we should take the analogies

54:51.420 --> 54:58.220
I'd have to think about. Has there been some consideration that the problem of understanding

54:58.220 --> 55:02.860
consciousness sort of inherently must be difficult because we address the problem

55:02.860 --> 55:08.940
using consciousness? I'm reminded of the halting problem in computer science where we say that

55:08.940 --> 55:13.980
in the general case, a program cannot be written to tell whether another program will halt because

55:13.980 --> 55:19.740
what if you ran it on itself? It can't sort of be broad enough to include its own execution. So I

55:19.740 --> 55:24.700
wonder if there's a similar corollary in consciousness where we use consciousness to think about

55:24.700 --> 55:31.500
consciousness. And so therefore, we may not have enough sort of equipment there to be able to unpack

55:32.700 --> 55:38.220
Yeah, I mean, it's tricky. People say it's like a user ruler to measure a ruler. Well, I can use

55:38.220 --> 55:43.580
this ruler to measure many other things, but it can't measure itself. On the other hand,

55:43.580 --> 55:48.380
you can measure one ruler using another ruler. Maybe you can measure one consciousness using

55:48.380 --> 55:53.820
another. The brain can't study the brain, but the brain actually has a pretty good job of studying.

55:54.700 --> 55:59.500
The brain. So there are some self referential paradoxes there. And I think that again is at

55:59.500 --> 56:04.860
the heart of Hofstadter's approach. But I think we'd have to look for very, very specific conditions

56:04.860 --> 56:10.220
under which systems can't study themselves. I did always like the idea that the mind was simple

56:10.220 --> 56:17.500
enough that we could understand it. We would be too simple to understand the mind. So maybe

56:17.500 --> 56:21.180
something like that could be true of consciousness. On the other hand, I actually think that if you

56:21.180 --> 56:25.260
start thinking that consciousness can go along with very simple systems, I think at the very

56:25.260 --> 56:30.140
least we ought to be able to study consciousness in other systems simpler than ourselves. And boy,

56:30.140 --> 56:36.700
if I could solve the hard problem, even in dogs, I'd be I'd be satisfied. Hey, so I have a question

56:36.700 --> 56:42.540
about how the meta problem research program might proceed sort of related to the last question.

56:43.260 --> 56:49.420
So certainly things we believe about our own consciousness, even if we all say them,

56:49.420 --> 56:54.940
probably some of them are false. Our brain has a tendency to hide what reality is like.

56:55.820 --> 56:59.900
If you look at like visual perception, you know, there's what's called lightness constancy, you

56:59.900 --> 57:04.700
know, our brain subtracts out the lighting in the environment. So we actually see more reliably

57:04.700 --> 57:09.980
what the colors of objects are. Like these viral examples of like the black and gold dress is an

57:09.980 --> 57:14.540
example of this. And when you're kind of presented with an explanation of it, it's like, huh, my

57:14.620 --> 57:20.380
brain does that. It's not something we have access to. Yeah. Or like the Yanni Laurel Laurel Yanni.

57:20.380 --> 57:24.300
Yeah, illusion is like another one where like when you hear the explanation, you know, the scientists

57:24.300 --> 57:29.900
that understand it, our own introspection doesn't include that. So how do you kind of proceed with

57:31.260 --> 57:37.020
trying to get at what consciousness really is versus what our sort of whatever simplified or

57:37.020 --> 57:44.300
distorted view might be? Yeah, well, one view here would be that we never have access to the

57:44.300 --> 57:49.500
mechanisms that generate consciousness, but we still have access to the conscious states

57:49.500 --> 57:53.980
themselves. Actually, the Colashley said this decades ago, he said, no process of the brain

57:53.980 --> 57:59.340
is ever conscious. The processes that get you to the states are never conscious. The states they

57:59.340 --> 58:05.340
get you to are conscious. So take your experience of the dress. For me, it was, it was what, white

58:05.420 --> 58:11.100
and gold. So, you know, and I knew that, you know, each of us was certain that I am, I was

58:11.100 --> 58:15.180
experiencing, I was certain that I was experiencing white and gold. Maybe you were certain that you

58:15.180 --> 58:21.340
were experiencing blue and black. Which it was. I remember as I was right. You were sure that, yeah,

58:22.380 --> 58:28.060
those idiots can't be, yeah, can't be looking at this right. But anyway, each of us, I think the

58:28.060 --> 58:31.820
natural way to describe this at least is that each of us was certain what kind of conscious

58:31.820 --> 58:36.700
experience we were having. But what we had no idea about was the mechanisms by which we got

58:36.700 --> 58:42.220
there. So the mechanisms are completely opaque. But the states themselves were at least prima facie

58:42.220 --> 58:45.580
transparent. So I think that would be the standard of view. And even a realist about consciousness

58:46.220 --> 58:50.140
could go with that. They say, well, we know what conscious states, we know what those conscious

58:50.140 --> 58:54.540
states are. We don't know the processes by which they're generated. The illusionist, I think,

58:54.540 --> 58:59.500
wants to go much further and say, well, it seems to you that you know what conscious state you're

58:59.500 --> 59:04.940
having. It seems to you that you're experiencing yellow and gold. Sorry, yellow and white, whatever

59:04.940 --> 59:10.140
it was, golden, gold and white. Black and gold is whatever. Black and blue, I think. And blue.

59:10.140 --> 59:15.900
Gold and white. Yeah. It seems to you that you're experiencing gold and white. But in fact, that

59:15.900 --> 59:21.180
too is just something thrown up by another model. The yellow gold was a perceptual model. And then

59:21.180 --> 59:25.660
there was an introspective model that said you're experiencing gold and white. When maybe, in fact,

59:25.660 --> 59:29.100
you're just a zombie or who knows what's actually going on in your conscious state. So

59:29.100 --> 59:33.340
the illusionist view, I think, has to somehow take this further and say not just the processes

59:33.340 --> 59:37.260
that generate the conscious states, but maybe the conscious states themselves are somehow

59:37.260 --> 59:46.940
opaque to us. All right. Thanks. It feels like some discussion of generality of a problem is

59:46.940 --> 59:53.020
missing from this discussion. The matrix multiplier example of having high phi is still,

59:53.020 --> 59:57.980
it's not a general thing. Is there someone exploring the space, the sort of intersection

59:58.060 --> 01:00:02.300
of generality and complexity that leads to consciousness as an emergent behavior?

01:00:03.100 --> 01:00:07.660
When you say generality, I mean, the idea that a theory should be general, that it should apply

01:00:07.660 --> 01:00:11.900
to every system, you mean mechanisms of... No, generality of the agent, right? If I can write

01:00:11.900 --> 01:00:17.180
an arbitrarily complex program to play tic-tac-toe, and all it will ever be able to do is play tic-tac-toe,

01:00:17.180 --> 01:00:23.340
it has no outputs to express anything else. Yeah. As you said, general in the sense of AGI,

01:00:23.340 --> 01:00:28.460
artificial general intelligence, I mean, some aspects of consciousness seem to be

01:00:28.460 --> 01:00:33.740
domain general, like, for example, maybe as far as belief and reasoning is conscious,

01:00:33.740 --> 01:00:38.140
those are domain general, but much of perception doesn't seem especially domain general, right?

01:00:38.140 --> 01:00:43.900
Color is very domain... Taste is very domain specific, so it's still conscious. If my agent

01:00:43.900 --> 01:00:48.860
can't express problem statements, like, if I don't give it an output by which it can express

01:00:48.860 --> 01:00:52.060
problem statements, you can never come to a conclusion about its consciousness.

01:00:53.260 --> 01:00:57.020
I like to distinguish intelligence and consciousness. I'm even able to... Even natural

01:00:57.020 --> 01:01:01.980
language and, you know, being able to address a problem statement and analyze a problem,

01:01:01.980 --> 01:01:09.740
that's already a very advanced form of intelligence. I think it's very plausible that, say, a mouse has

01:01:09.740 --> 01:01:15.180
got some kind of consciousness, even it's got no ability to address problem statements in many

01:01:15.180 --> 01:01:19.580
of its capacities, maybe very specialized. I mean, it's still much more general than, say,

01:01:19.580 --> 01:01:24.620
a simple neural network that can only do one thing. A mouse can do many things, but I'm not

01:01:24.620 --> 01:01:28.380
sure that I see an essential... I certainly see a connection between intelligence and

01:01:28.380 --> 01:01:33.740
generality. We want to say, you know, somehow a high degree of generality is required for

01:01:33.740 --> 01:01:38.220
high intelligence. I'm not sure there's the same connection for consciousness. I think

01:01:38.220 --> 01:01:44.780
consciousness can be extremely domain specific, has, say, taste and maybe vision or it can be

01:01:44.780 --> 01:01:47.660
domain general. So maybe those two cross cut each other a bit.

01:01:51.340 --> 01:01:58.300
So it seems to me like the meta problem as it's formulated implies some amount of, like,

01:01:58.300 --> 01:02:02.460
separation or epiphenomenalism between, like, consciousness and brain states.

01:02:03.100 --> 01:02:10.060
And one thing that I think underlies a lot of people's motivation to do, say, science is that

01:02:10.620 --> 01:02:17.500
it has causal import. Like, predicting behaviors is clearly a functionally useful thing to do.

01:02:18.140 --> 01:02:22.460
And if you can predict all of behavior without having to explain consciousness,

01:02:23.020 --> 01:02:27.740
their motivation for explaining consciousness sort of evaporates and it sort of feels like,

01:02:27.740 --> 01:02:32.460
yeah, yeah, well, what's the point of even thinking about that because it's just not going

01:02:32.460 --> 01:02:37.100
to do anything for me? What do you say to someone when they say that to you?

01:02:37.820 --> 01:02:39.340
What is the thing that they say to me again?

01:02:39.340 --> 01:02:45.020
That there's no, there's maybe consciousness exists, maybe it doesn't. But if I can explain

01:02:45.020 --> 01:02:48.780
all of human behavior and all of the behavior of the world in general without

01:02:48.780 --> 01:02:54.060
recourse to such concepts, then I've done everything that there is that's useful,

01:02:54.060 --> 01:03:00.140
like explaining consciousness isn't a useful thing to do. And thus, I'm not interested in this and

01:03:00.140 --> 01:03:05.740
it may not be real. I mean, I'm certainly, I'm not, I mean, I think epiphenomenalism could be

01:03:05.740 --> 01:03:09.340
true. I certainly don't have any commitment to it though. It's quite possible that consciousness

01:03:09.340 --> 01:03:14.940
has a role to play in generating behavior that we don't yet understand and maybe thinking hard

01:03:14.940 --> 01:03:20.220
about the meta problem can help us get clearer on those roles. I think if you've got any sympathy

01:03:20.220 --> 01:03:24.700
to panpsychism, maybe consciousness is intimately involved with how physical processes get going

01:03:24.700 --> 01:03:29.660
in the, in the first place. And there are people who want to pursue interactionist ideas where

01:03:29.660 --> 01:03:33.820
consciousness interacts with the brain. Or if you're a reductionist, consciousness may be just

01:03:33.820 --> 01:03:38.860
a matter of the right algorithm. On all those views, consciousness may have some role to play,

01:03:38.860 --> 01:03:44.220
but just say it turns out that you can explain all of behavior, including these problems without,

01:03:45.420 --> 01:03:49.580
without bringing in consciousness. And does that mean that consciousness is not something we

01:03:49.580 --> 01:03:53.020
should care about and not something that matters? I don't think that would follow. I mean, maybe it

01:03:53.020 --> 01:03:58.300
wouldn't matter for certain engineering purposes, say you want to build a useful system. But,

01:03:58.860 --> 01:04:02.860
you know, at least in my view, consciousness is really the only thing that matters. It's a thing

01:04:02.940 --> 01:04:09.100
that makes life worth living. It's what gives our lives meaning and value and so on. So,

01:04:09.100 --> 01:04:13.420
it might turn out that, okay, the point of consciousness is not that useful for explaining

01:04:13.420 --> 01:04:17.980
other stuff. But it's, you know, if it's the source of intrinsic significance in the world,

01:04:17.980 --> 01:04:22.780
then understanding consciousness will still be absolutely essential to understanding ourselves.

01:04:22.780 --> 01:04:28.380
Furthermore, if it comes to developing other systems, like say AI systems or dealing with

01:04:28.380 --> 01:04:33.740
non-human animals and so on, we absolutely want to know, we need to know whether they're conscious,

01:04:33.740 --> 01:04:37.580
because, you know, if they're conscious, they presumably have moral status. If they can suffer,

01:04:38.220 --> 01:04:43.420
then it's very bad to mistreat them. If they're not conscious, then you might, I think it's very

01:04:43.420 --> 01:04:47.980
plausible, treat non-conscious systems. We can treat how we like, and it doesn't really matter

01:04:48.540 --> 01:04:52.700
morally. So, the question of whether, say, an AI system is conscious or not, it's going to be

01:04:52.700 --> 01:04:57.580
absolutely vital for how we interact with it and how we build our society. That's not a question

01:04:57.580 --> 01:05:01.740
of engineering usefulness. That's a question of connecting with our most fundamental values.

01:05:02.380 --> 01:05:08.060
Yeah, I completely agree. I just, I haven't found that formulation to be very convincing to others

01:05:08.060 --> 01:05:15.660
necessarily. Hi, thank you so much for coming and chatting with us today. I'm really interested in

01:05:15.660 --> 01:05:21.500
some of your earlier work, The Extended Mind Distributed Cognition. Yeah. And you're at a company

01:05:21.500 --> 01:05:25.900
speaking with a bunch of people who do an incredibly cognitively demanding task. Yeah.

01:05:25.900 --> 01:05:31.580
Most of the literature that I've read on this topic uses relatively simple examples of telling,

01:05:31.580 --> 01:05:38.540
like, it's difficult to think just inside your head on these relatively simple things. And if

01:05:38.540 --> 01:05:42.140
you take a look at the programs that we build, sort of like on a mundane, day-to-day basis,

01:05:42.140 --> 01:05:46.700
there are millions of lines long. I've read people in the past say something like,

01:05:46.700 --> 01:05:52.140
the Boeing 777 was the most complicated thing that human beings have ever made. And I think

01:05:52.140 --> 01:05:56.540
most of us would look at that and say, we got that beat, you know, like the things that large

01:05:56.540 --> 01:06:01.260
internet companies do, the size, the complexity of that is staggering. And yet if we close our

01:06:01.260 --> 01:06:05.340
eyes, everyone in here is going to say, I'm going to have difficulty writing a 10-line program in

01:06:05.340 --> 01:06:11.340
my head. Okay. So I'm just sort of as an open, like, I'd be very interested in hearing your thoughts

01:06:11.340 --> 01:06:16.860
about how the activity of programming connects to the extended mind ideas.

01:06:17.500 --> 01:06:23.100
Yeah. So this is a reference to something that I got started in about 20 years ago with

01:06:23.740 --> 01:06:29.180
my colleague Andy Clarke. We wrote an article called The Extended Mind about how processes in

01:06:29.180 --> 01:06:34.540
the mind can extend outside the brain when we become coupled to our tools. And actually,

01:06:34.540 --> 01:06:39.820
our central example back then in the mid-90s was a notebook, someone writing stuff in a

01:06:39.820 --> 01:06:44.780
notebook. I mean, even then, we knew about the internet and we had some internet examples.

01:06:44.780 --> 01:06:51.500
I guess this company didn't exist yet in 95. But now, of course, our minds have just become

01:06:51.500 --> 01:06:57.580
more and more extended and, you know, smartphones came along a few years later and everyone is

01:06:57.580 --> 01:07:02.460
coupled very, very closely to their phones and their other devices that coupled them very,

01:07:02.460 --> 01:07:09.820
very closely to the internet. Now, it's certainly the case that a whole lot of my memory is now

01:07:09.820 --> 01:07:15.420
offloaded onto the servers of your company somewhere or other, whether it's in the

01:07:17.820 --> 01:07:24.460
mail systems or navigation mapping systems or other systems. Most of my navigation has been

01:07:25.500 --> 01:07:31.020
offloaded to maps and much of my memory has been offloaded. Well, maybe that's in my phone, but

01:07:32.460 --> 01:07:36.220
other bits of my memory are offloaded into my file system on

01:07:36.620 --> 01:07:46.140
some cloud service. So certainly, vast amounts of my mind are now

01:07:47.020 --> 01:07:51.820
existing in the cloud. And if I was somehow to lose access to those completely, then I'd

01:07:51.820 --> 01:07:58.780
lose an awful lot of my capacities. So I think we are now sort of extending

01:07:58.780 --> 01:08:04.380
into the cloud, thanks to you guys and others. The question specifically about programming

01:08:06.940 --> 01:08:11.420
programming is a kind of active interaction with our devices. I mean, I think of programming

01:08:11.420 --> 01:08:16.460
as something that takes a little bit longer. It's a longer time scale. So the core cases of the

01:08:16.460 --> 01:08:21.980
extended mind involve sort of automatic use of our devices, which are always ready to hand.

01:08:21.980 --> 01:08:28.060
We can use them to get information, to act in the moment, which is the kind of thing that

01:08:28.940 --> 01:08:34.220
the brain does. So insofar as programming is a slower process, you know, and I remember from

01:08:34.860 --> 01:08:43.100
programming days, all the endless hours of debugging and so on. Then it's at least going

01:08:43.100 --> 01:08:47.980
to be a slower time scale for the extended mind. But still, Feynman talked about writing

01:08:48.780 --> 01:08:56.460
this way. Someone looked at Feynman's work and a bunch of notes he had about a physics problem

01:08:56.460 --> 01:09:01.100
he was thinking about. And someone said to him, oh, it's nice you have this record of your work.

01:09:02.060 --> 01:09:07.900
And Feynman said, that's not a record of my work. That's the work. That is the thinking.

01:09:07.900 --> 01:09:12.300
And so I was writing it down and so on. I think, you know, at least my recollection from my programming

01:09:12.300 --> 01:09:16.460
days was that, you know, when you're actually writing a program, that's not like you just

01:09:17.020 --> 01:09:22.780
do a bunch of thinking and then code your thoughts. The programming is to some very

01:09:22.780 --> 01:09:28.700
considerable extent your thinking. So is that the sort of thing you're thinking about here?

01:09:28.700 --> 01:09:35.900
And the, if we, I think as people that program start to reflect on what we do,

01:09:35.900 --> 01:09:42.300
and very few of us actually, like if you're the tech lead of a system, maybe you've got it in your

01:09:42.300 --> 01:09:46.700
head, okay? But you would agree that most of the people on the team who've come more recently only

01:09:46.700 --> 01:09:50.460
have a chunk of it in their head, and yet they're somehow still able to contribute.

01:09:50.460 --> 01:09:56.140
Oh yeah, this is now distributed cognition. I mean, the extended mind that extended cognition

01:09:56.140 --> 01:10:02.060
like starts with an individual and then extends out, extends their capacities out using their

01:10:02.060 --> 01:10:07.100
tools or their devices or even other people. So maybe my partner serves as my memory, but it's

01:10:07.100 --> 01:10:12.300
still centered on an individual. But then there's the closely related case of distributed cognition,

01:10:12.300 --> 01:10:17.580
where you have a team of people who are doing something and are making joint decisions and

01:10:17.580 --> 01:10:21.500
carrying out joint actions in an absolutely seamless way. And I take it as a company like this

01:10:21.500 --> 01:10:25.180
that are going to be any number of instances of distributed cognition. I don't know whether the

01:10:25.180 --> 01:10:32.220
company as a whole has one giant Google mind, or maybe there's just like a near infinite number

01:10:32.220 --> 01:10:39.100
of separate Google minds for all the individual teams and divisions and so on. But I think yeah,

01:10:39.100 --> 01:10:43.500
probably some anthropologist has already done a definitive analysis of distributed cognition

01:10:43.500 --> 01:10:54.220
in this company, but if they haven't, they certainly need to. Thank you.

01:10:55.180 --> 01:10:58.220
Thank you.

