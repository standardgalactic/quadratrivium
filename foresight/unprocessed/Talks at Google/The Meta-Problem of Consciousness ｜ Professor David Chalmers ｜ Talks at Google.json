{"text": " Thanks for coming out. It's good to be here. As Eric said, I'm a philosopher, thinking about consciousness, coming from a background in the sciences and math that always struck me that the most interesting and hardest unsolved problem in the sciences was the problem of consciousness. Way back, 25 years ago, when I was in grad school, it seemed to me the best way to come at this from a big picture perspective was to go into philosophy and think about the foundational issues that arise and thinking about consciousness from any number of different angles, including the angles of neuroscience and psychology and AI. In this talk, I'm going to present a slightly different perspective on the problem after laying out some background, the perspective of what I call the meta problem of consciousness. I always like the idea that you approach a problem by stepping one level up, taking the meta perspective. I love this quote, anything you can do, I can do meta. I have no idea what the origins was. I like the fact this is attributed to Rudolf Kahnap, one of my favorite philosophers, but anyone who knows Kahnap's work is completely implausible. He would ever say anything so frivolous. It's also been attributed to my thesis advisor, Doug Hofstadter, author of Goethe Lescher Bach and a big fan of the meta perspective, but he assures me he never said it either. But the meta perspective on anything is stepping up a level. The meta problem, as I think about it, is called the meta problem because it's a problem about a problem. A meta theory is a theory about a theory. Meta problem is a problem about a problem. In particular, it's the problem of explaining why we think there is a problem about consciousness. So there's a first order problem, the problem of consciousness. Today I'm going to focus on a problem about it, but I'll start by introducing the first order problem itself. The first order problem is what we call the hard problem of consciousness. It's the problem of explaining why and how physical processes should give rise to conscious experience. You've got all this neurons firing in your brain, bringing about all kinds of sophisticated behavior. We can get to be done explaining our various responses, but there's this big question about how it feels from the first person point of view. That's the subjective experience. I like this illustration of the hard problem of consciousness. It seems to show someone's hair catching fire, but I guess it's a metaphorical illustration of the subjective perspective. The hard problem is concerned with what philosophers call phenomenal consciousness. The word consciousness is ambiguous a thousand ways, but phenomenal consciousness is what it's like to be a subject from the first person point of view. A system is phenomenally conscious. If there's something it's like to be it, a mental state is phenomenally conscious if there's something it's like to be in it. The thought is there are some systems, so there's something it's like to be that system. There's something it's like to be me. I presume there's something it's like to be you, but presumably there's nothing it's like to be this lectern as far as we know. The lectern does not have a first person perspective. This phrase was made famous by my colleague Tom Nagel at NYU who back in 1974 wrote an article called What is it like to be a bat? The general idea was what's very hard to know what it's like to be a bat from the third person point of view just looking at it as a human who has different kinds of experience, but presumably very plausibly there is something it's like to be a bat. The bat is conscious. It's having subjective experiences just of a kind very different from ours. In human subjective experience consciousness divides into any number of different kinds or aspects like different tracks of the inner movie of consciousness. We have visual experiences like the experience of say these colors blue and red and green from the first person point of view and of depth. There are sensory experiences like the experience of my voice, experiences of taste and smell, their experiences of your body, feeling pain or orgasms or hunger or a tickle or something. They all have some distinctive first person quality, mental images like recalled visual images, emotional experiences like experience of happiness or anger and indeed we all seem to have this stream of a current thought or at the very least we're kind of chattering away to ourselves and reflecting and deciding. All of these are aspects of subjective experience, things we experience from the first person point of view and I think these subjective experiences are at least on the face of it data, data for the science of consciousness to explain. These are just facts about us that we're having these subjective experiences. As we ignore them, we're ignoring the data. So if you catalog the data that say the science of consciousness needs to explain, there are certainly facts about our behavior and how we respond in situations. There are facts about how our brain, facts about how our brain is working. There are also facts about how subjective experiences and on the face of it their data. And it's these data that pose what I call the hard problem of consciousness. This gets contrasted with the easy problems, the so-called easy problems of consciousness which are the problems of explaining behavioral and cognitive functions. Objective things you can measure from the third person point of view typically tied to behavior, perceptual discrimination say of a stimulus. I can discriminate two different things in my environment. I can say that's red and that's green. I can integrate the information say about the color and the shape. I can use it to control my behavior, walk towards the red one rather than the green one. I can report it, say that's red and so on. Those are all data too for science to explain. But we've got a bead on how to explain those. They don't seem to pose as big a problem. Why? We explain those easy problems by finding a mechanism, typically a neural or computational mechanism that performs the relevant function to explain how it is that I get to say there's a red thing over there or walk towards it. Will you find the mechanisms involving perceptual processes and action processes in my brain that leads to that behavior? Find the right mechanism that performs the function. You've explained what needs to be explained with the easy problems of consciousness. But for the hard problem, for subjective experience, it's just not clear that this standard method works. It looks like explaining all that behavior still leaves open a further question. Why does all that give you subjective experience? Explain the reacting, the responding, the controlling, the reporting and so on. It still leaves open the question why is all that accompanied by subjective experience? Why doesn't it go on in the dark without consciousness, so to speak? There seems to be what the philosopher Joe Levine has called a gap here, an explanatory gap between physical processes and subjective experience, at least our standard kinds of explanation which work really well for the easy problems of behavior and so on. Don't obviously give you a connection to the subjective aspects of experience. There's been a vast amount of discussion of these things over, well for centuries really, but it's been particularly active in recent decades, philosophers, scientists, all kinds of different views. Philosophically you can divide approaches to the hard problem into at least two classes. One is an approach on which consciousness is taken to be somehow irreducible and primitive. We can't explain it in more basic physical terms, so take it as a kind of primitive and that might lead to dualist theories of consciousness where consciousness is somehow separate from and interacts with the brain. Recently very popular has been the class of panpsychist theories of consciousness. I know Galen Strossom is here a while back talking, he very much favors panpsychist theories where consciousness is something basic in the universe underlying matter and indeed there are idealist theories where consciousness underlies the whole universe, so these are all extremely speculative but interesting views that I've explored myself. There are also reductionist theories of consciousness from functionalist approaches where consciousness is just basically taken to be a giant algorithm or computation. Biological approaches to consciousness, my colleague Ned Block was here I know talking about neurobiology based approaches where it's not the algorithm that matters but the biology is implemented in and indeed the kind of quantum approaches that people like Roger Penrose and Stuart Hemeroff have made famous. I mean I think there's interesting things to say about all of these approaches. I think that right now at least most of the reductionist approaches leave a gap but the non-reductionist approaches have other problems in seeing how it all works. Today I'm going to take a different kind of approach, this approach through the meta-problem. One way to motivate this is to ask, I often get asked, okay you're a philosopher it's fine you get to think about these things like the hard problem of consciousness, how can I as a scientist or an engineer or an AI researcher, how can I do something to kind of contribute to help get at this hard problem of consciousness? Is this just a problem for philosophy? I mean for me to work on it say as an AI researcher I need something I can operationalize, something I can work with and try to program and as it stands it's just not clear how to do that with the hard problem. I mean if you're a neuroscientist there are some things you can do. You can say work with humans and look at their brains and look for the neural correlates of consciousness, the bits of the brain that go along with being conscious because at least with humans we can take as a background assumption, a plausible background assumption that the system is conscious. For AI we can't even do that, we don't know which AI systems we're working with or conscious, we need some operational criteria. In AI we mostly work on modeling things like behavior and objective functioning for consciousness, those are the easy problems. So how does someone coming from this perspective make a connection to the hard problem of consciousness? Well one approach is to work on certain problems among the easy problems of behavior that shed particular light on the hard problem and that's going to be the approach that I look at today. So the guiding, the key idea here is there are certain behavioral functions that seem to have a particularly close relation to the hard problem of consciousness. In particular we say things about consciousness. We make what philosophers call phenomenal reports, verbal reports of conscious experiences. So I'll say things like I'm conscious, I'm feeling pain right now and so on. Maybe the consciousness and the pain are subjective experiences but the reports, the utterances, I am conscious, well that's a bit of behavior. In principle explaining those is among the easy problems, objectively measurable response, we can find a mechanism in the brain that produces it. And among our phenomenal reports there's this special class we can call the problem reports, reports expressing our sense that consciousness poses a problem. Now admittedly not everyone makes these reports but they seem to be fairly widespread among, especially among philosophers and scientists thinking about these things but furthermore it's a sense that it's fairly easy to find and a very wide class of people who think about consciousness. People say things like there is a problem of consciousness, a hard problem. On the face of it explaining behavior doesn't explain consciousness, consciousness seems non-physical, how would you ever explain the subjective experience of red and so on. It's an objective fact about us, at least about some of us, that we make those reports and that's the fact about human behavior. So the matter problem of consciousness then at a second approximation is roughly the problem of explaining these problem reports, explaining you might say the conviction that we're conscious and that consciousness is puzzling. And what's nice about this is that although the hard problem is this, you know, airy-fairy problem about subjective experience that's hard to pin down, this is a puzzle ultimately about behavior. So this is an easy problem, one that ought to be open to those standard methods of explanation in the cognitive and brain sciences. So there's a research program. There's a research program here. So I like to think of the matter problem as something that can play that role. I talked about earlier if you say an AI researcher thinking about this. The matter problem is an easy problem, a problem about behavior that's closely tied to the hard problem. So it's something we might be able to make some progress on using standard methods of thinking about algorithms and computations or thinking about brain processes and behavior while still shedding some light, at least indirectly on the hard problem. It's more tractable than the hard problem but solving it ought to shed light on the hard problem. And today I'm just going to kind of lay out the research program and talk about some ways in which it might potentially shed some light. This is interesting to a philosopher because it looks like an instance of what people sometimes call genealogical analysis. It goes back to Friedrich Nietzsche on the genealogy of morals. Instead of thinking about what's good or bad, let's look at where our sense of good or bad came from, the genealogy of it all in evolution or in culture or in religion. And people take a genealogical approach to God. Instead of thinking about does God exist or not, let's look at where our belief in God came from. Maybe there's some evolutionary reason for why people believe in God. This often leads, not always, but often leads to a kind of debunking of our beliefs about those domains. Explain why we believe in God in evolutionary terms. No need for the God hypothesis anymore. Explain our moral beliefs in say evolutionary terms. Maybe no need to take morality quite so seriously. So some people at least are inclined to take an approach like this with consciousness too. If you think about the meta problem, explaining our beliefs about consciousness, that might ultimately debunk our beliefs about consciousness. This leads to a philosophical view which has recently attracted a lot of interest, a philosophical view called illusionism, which is the view that consciousness itself is an illusion or maybe that the problem of consciousness is an illusion. Explain the illusion and we dissolve the problem. In terms of the meta problem that view roughly comes to, solve the meta problem, it will dissolve the hard problem. Explain why it is that we say all these things about consciousness. While we say I am conscious, while we say consciousness is puzzling, if you can explain all that in say algorithmic terms, then you'll remove the underlying problem because you'll have explained why we're puzzled in the first place. Actually, walking over here today, I noticed that just a couple of blocks away, we have the Museum of Illusions. So I'm going to check that out later on. But if illusionism is right and added to all those perceptual illusions, it's going to be the problem of consciousness itself. It's roughly an illusion thrown up by having a weird self-model with a certain kind of algorithm that attributes to ourselves special properties that we don't have. So one line on the meta problem is the illusionist line. Solve the meta problem, you'll get to treat consciousness as an illusion. That's actually a view that has many antecedents in the history of philosophy one way or another. Emmanuel Kahn, in his great critique of pure reason, had a section where he talked about the self or the soul as a transcendental illusion. We seem to have this indivisible soul, but that's a kind of illusion thrown up by our cognitive processes. The Australian philosophers are on place, and David Armstrong had versions of this that I might touch on a bit later. Daniel Dennett, leading reductionist thinker about consciousness, has been pushing for the last couple of decades the idea that consciousness involves a certain kind of user illusion, and most recently the British philosopher Keith Frankish has been really pushing illusionism as a theory of consciousness. Here's a book centering around a paper by Keith Frankish on illusionism as a theory of consciousness that I recommend to you. So one way to go with the meta problem is the direction of illusionism, but one nice thing about many people find illusionism completely unbelievable. They find you, how could it be that consciousness is an illusion? Look, we just have the subjective experience, it's a datum about our nature, and I confess I've got some sympathy with that reaction, so I'm not an illusionist myself. I'm a realist about consciousness in the philosopher's sense where a realist about something is someone who believes that thing is real. I think consciousness is real, I think it's not an illusion, I think that solving the meta problem does not dissolve the hard problem, but the nice thing about the meta problem is you can proceed on it to some extent at least in initial neutrality on that question, is consciousness real or is it an illusion? It's a basic problem about our objective functioning of these reports. What explains those? There's a neutral research program here that both realists, illusionists, people of all kinds of different views of consciousness can explain, and then we can come back and look at the philosophical consequences. Well, I'm not an illusionist, I think consciousness is real. I've got to say, I do feel the temptation of illusionism, I find it really intriguing and in some ways attractive to you, just fundamentally unbelievable. Nevertheless, I think that the meta problem should be a tractable problem. Solving it will shed, at the very least, will shed much light on the hard problem of consciousness, even if it doesn't solve it. If you can explain our conviction that we're conscious, somehow the source, the roots of our conviction that we're conscious must have something to do with consciousness, especially if consciousness is real. I think it's very much a good research program for people to explain. Then I'll move on now to just outlining the research program a little bit more and then talk a bit about potential solutions and on impact on theories of consciousness before wrapping up with just a little bit more about illusionism. This meta problem, which I've been pushing recently, opens up a tractable empirical research program for everyone, reductionists, non-reductionists, illusionists, non-illusionists. We can try to solve it and then think about the philosophical consequences. What is the meta problem? Well, the way I'm going to put it is it's the problem of topic neutrally explaining problem intuitions or else explaining why that can't be done. I'll unpack all the pieces of that right now, first starting with problem intuitions. What are problem intuitions? Well, those are the things we say. There are things we think. I say consciousness seems irreducible. I might think consciousness is irreducible. People might be disposed, have a tendency to say or think those things. Problem intuitions all take to be roughly that tendency. We have dispositions to say and think certain things about consciousness. What are the core problem intuitions? Well, I think they break down into a number of different kinds. There's the intuition that consciousness is non-physical. We might think of that as a metaphysical intuition about the nature of consciousness. There are intuitions about explanation. Consciousness is hard to explain. Explaining behavior doesn't explain consciousness. There are intuitions about knowledge of consciousness. Some of you may know the famous thought experiment of Mary in the black and white room who knows all about the objective nature of color vision and so on, but still doesn't know what it's like to see red. She sees red for the first time. She learns something new. That's an intuition about knowledge of consciousness. There are what philosophers call modal intuitions about what's possible or imaginable. One famous case is the case of a zombie, a creature who's physically identical to you and me, but not conscious, or maybe an AI system which is functionally identical to you and me, but not conscious. That at least seems conceivable to many people. This is the philosophical zombie, unlike the zombies in movies which have weird behaviors and go after brains and so on. The philosophical zombie is a creature that seems, at least behaviorally, maybe physically like a normal human, but doesn't have any conscious experiences. All the physical states, none of the mental states. It seems to many people that's at least conceivable. We're not zombies. I don't think anyone here is a zombie, I hope, but nonetheless, it seems that we can make sense of the idea and one way to pose the hard problem is why are we not zombies. This imaginability of zombies is one of the intuitions that gets the problem going. Then you can go on and catalog more and more intuitions about the distribution of conscious, maybe the intuition that robots won't be conscious. That's an optional one, I think, or consciousness matters morally in certain ways and the list goes on. I think there's an interdisciplinary research program here of working on those intuitions about consciousness and trying to explain them. Experimental psychology and experimental philosophy and newly active area can study people's intuitions about consciousness. We can work on models of these things, computational models or neurobiological models of these intuitions and reports, and indeed, I think there's a lot of room for philosophical analysis. There's just starting to be a program of people doing these things in all these fields. It is an empirical question how widely these intuitions are shared. You might be sitting there thinking, come on, I don't have any of these intuitions. Maybe this is just you. My sense is from the psychological study to date, it seems that some of these intuitions about consciousness are at least very widely shared, at least as dispositions or intuitions, although they're often overridden on reflection. The current data on this is somewhat limited. There is a lot of empirical work on intuitions about the mind concerning things like belief, like when do kids get the idea that your belief's about the world, can be false, concerning the way your self persists through time, could you exist after the death of your body? Well, consciousness is concerned. There's work on the distribution of consciousness. Could a robot be conscious? Could a group be conscious? Here's a book by Paul Bloom, Descartes' Baby. The catalog's a lot of this interesting work, making the case that many children are intuitive dualists. They're naturally inclined to think there's something non-physical about the mind. So far, most of this work has not been so much on these core problem intuitions about consciousness, but there's work developing in this direction. Sarah Gottlieb and Tanya Lombrozo have a very recent article called Can Science Explain the Human Mind on People's Judgements about when various mental phenomena are hard to explain and they seem to find that, yes, subjective experience and things which have, to which people have privileged first person access seem to pose the problem big time. So there's the beginning of a research program here. I think there's room for a lot more. The topic neutrality part, when I say we're looking for a topic neutral explanation of problem intuitions, that's roughly to say an explanation that doesn't mention consciousness itself. It's put in neutral terms. It's neutral on the existence of consciousness. The most obvious one would be something like an algorithmic explanation. I can say, here is the algorithm. The brain is executing. It generates our conviction that we're conscious and our reports about consciousness. There may be some time between that algorithm and consciousness, but to specify the algorithm, you don't need to make claims about consciousness. So the algorithmic version of the metaproblem is roughly find the algorithm that generates our problem intuition. So that's I think a principal research program that maybe AI researchers in combination would say psychologists, the psychologist could help isolate data about the way that the human beings are doing it, how these things are generated in humans and AI researchers can try and see about implementing that algorithm in machines and see what results. And I'll talk about a little bit of research in this direction in just a moment. But okay, now I want to say something about potential solutions to the problem. Like I say, this is a big research program. I don't claim to have the solution to the metaproblem. I've got some ideas, but I'm not going to try and lay out a major solution or just so here are a few things which I think might be parts of a solution to the problem, many of which have got antecedents here and there in scientific and philosophical discussion. Some promising ideas include retrospective models, phenomenal concepts, introspective opacity, the sense of acquaintance. Let me just say something about a few of these. One starting idea that almost anyone's going to have here is somehow models of ourselves are playing a central role here. Human beings have models of the world, naive physics and naive psychology, models of other people and so on. We also have models of ourselves. It makes sense for us to have models of ourselves and our own mental processes. This is something that the psychologist Michael Graziano has written a lot on. We have internal models of our own cognitive processes, including those tied to consciousness. Somehow, something about our introspective models explains our sense, A, that we are conscious and B, that this is distinctively problematic. I think anyone thinking about the metaproblem, this has got to be at least the first step. We have these introspective models. If you're an illusionist, they'll be false models. If you're a realist, they needn't be false models, but at the very least, these introspective models are involved, which is fine, but the devil's in the details. How do they work to generate this problem? A number of philosophers have argued we have special concepts of consciousness, introspective concepts of these special subjective states. People call these phenomenal concepts, concepts of phenomenal consciousness. One thing that's special is these concepts are somehow independent of our physical concepts. They explain, we've got one set of physical concepts for modeling the external work world. We've got one set of introspective concepts for modeling our own mind. These concepts, just by virtue of the way they're designed, are somewhat independent of each other, and that partly explains why consciousness seems to be independent of the physical world, intuitively. Maybe that independence of phenomenal concepts could go some distance to explaining our problem report. I think there's got to be something to this as well. At the same time, I don't think this goes nearly far enough because we have concepts of many aspects of the mind, not just of the subjective experiential past, but things we believe and things we desire. One, I believe that Paris is the capital of France. That's part of my internal self-model, but that doesn't seem to generate the hard problem in nearly the same way in which, say, the experience of red does. A lot more needs to be said about what's going on in cases like having the experience of red and having the sense that that generates a gap, so it doesn't generalize to everything about the mind. Some people have thought that what we might call introspective opacity plays a role, that when we introspect what's going on in our minds, we don't have access to the underlying physical states. We don't see the neurons in our brains. We don't see that consciousness as physical, so we see it as non-physical. Most recently, the physicist Max Tegmark has argued in this direction, saying, somehow, consciousness is substrate independent. We don't see the substrate, so then we think, ah, maybe it can float free of the substrate. Armstrong made an analogy with the case of someone in a circus where the headless person illusion where you don't see someone's there with a veil across their head. You don't see their head, so you see them as having no head. Here is a 19th century booth at a circus, a so-called headless woman with a veil over her head. You don't see the head, so somehow it looks at least for a moment like the person doesn't have a head. Armstrong says, maybe that's how it is with consciousness. You don't see that it's physical, so you see it as non-physical. But still, the question comes up, how do we make this inference? There's something that special goes on in cases like, say, color and taste and so on. Color experience seems to attribute primitive properties to objects like redness, greenness and so on. But in fact, in the external world, at the very least, they have complex, reducible properties. Somehow, internal models of color treat colors like red and green as if they are primitive things. It turns out to be useful to have these models of things where you treat certain things as primitive even though they're reducible. And it sure seems that when we experience colors, we experience greenness as a primitive quality, even though it may be a very, very complex reducible property. That's something about our model of colors. The philosopher Wolfgang Schwartz tried to make an analogy with sensor variables in, say, image processing. You've got some visual sensors and a camera or something. You need to process the image. Well, you've got some variables, some sensor variables to represent the sensory inputs that the various sensors are getting. And you might treat them as a primitive dimension because that's the most useful way to treat them. You don't treat them as certain amounts of lights or photons firing. You don't need to know about that. Use these sensor variables and treat them as a primitive dimension. And all that will play into a model of these things as primitive. Maybe taking that idea and extending it to introspection, you know, somehow these conscious states are somehow like sensor variables in our model of the mind. And somehow these internal models give us the sense of being acquainted with primitive concrete qualities and of our awareness of them. This is still just laying out. I don't think this is still yet actually explaining a whole lot, but it's laying out. It's narrowing down what it is that we need to explain to solve the meta problem. But just to put the pieces together, here's a little summary. One thing I like about this summary is you can read it in either an illusionist tone of voice as an account of the illusion of consciousness. All this is how our false introspective models work or in a realist tone of voice as an account of our true, correct models of consciousness. But we can set it out in a way which is neutral on the two and then try and figure out later whether these models are correct as the realist says or incorrect as the illusionist says. We have introspective models deploying introspective concepts of our internal states that are largely independent of our physical concepts. These concepts are introspectively opaque, not revealing any of the underlying mechanisms, our perceptual models perceptually attribute primitive perceptual qualities to the world, and our introspective models attribute primitive mental relations to those qualities. These models produce the sense of acquaintance both with those qualities and with our awareness of those qualities. Like I said, this is not a solution to the meta problem, but it's trying at least to pin down some parts of the roots of those intuitions and to narrow down what needs to be explained. To go further, you want, I think, to test these explanations, both with psychological studies to see if this is plausibly what's going on in humans. This is the kind of thing which is the basis of our intuitions and computational models to see if, for example, you could program this kind of thing into an AI system and see if it can generate somehow qualitatively similar reports and intuitions. You might think that last thing is a bit far-fetched right now, but I know of at least one instance of this research program which has been put into play by Luke Milhauser and Bach Schleggeres, two researchers at Open Philanthropy, very interested in AI and consciousness. They actually built, they took some ideas about the meta problem from something I'd written about it and from something that the philosopher Francois Camero had written about it. A couple of basic ideas about where problem intuitions might come from, and they tried to build them in to a computational model. They built a little software agent which had certain axioms about colors and how they work. There's red and there's green, and certain axioms about their own subjective experiences of colors, and then they combined it with a little theorem prover, and they saw what did this little software agent come up with, and it came up with claims like, hey, well, my experiences of color are distinct from any physical state, and so on. They cut a few corners. This is not yet a truly convincing, sophisticated model of everything going on in the human mind, but it shows that there's a research program here of trying to find the algorithmic basis of these states. I think as more sophisticated models develop, we might be able to use these to provide a way in for AI researchers in thinking about this topic. Of course, there is the question, if you model all this stuff better and better in a machine, then is the machine actually going to be conscious, or is it just going to have found self-models that replicate what's going on in humans? Some people have proposed an artificial consciousness test. Aaron Sloman, Susan Snyder, and Turner have suggested somehow that if a machine seems to be puzzled about consciousness in roughly the ways that we are, maybe that's actually a sign that it's conscious. If a machine actually looks to ask as if it's puzzled by consciousness, is that a sign of consciousness? These people, this is suggested as a kind of Turing test for machine consciousness. Find machines which are conscious like we are. Of course, the opposing point of view is going to be, no, the machine is not actually conscious. It's just like the machine that studied up for the Turing test by reading the talk like a human book. It's like, damn, do I really need to convince those humans that I'm conscious by replicating all those ill-conceived confusions about consciousness? Well, I guess I can do it if I need to. Anyway, I'm not going to settle this question here, but I do think that if we somehow find machines being puzzled, it won't surprise me that once we actually have serious AI systems which engage in natural language and modeling of themselves in the world, they might well be natural to find themselves saying things like, yeah, I know in principle I'm just a set of silicon circuits, but I feel like so much more. I think that might tell us something about consciousness. Let me just say a little bit about theories of consciousness. I do think a solution to the meta problem and a solution to the hard problem ought to be closely connected. The illusionist says, solve the meta problem. You'll dissolve the hard problem. But even if you're not an illusionist about consciousness, there ought to be some link. So here's a thesis. Whatever explains consciousness should also partly explain our judgments and our reports about consciousness. The rationale here is it would just be very strange if these things were independent. If the basis of consciousness played no role in our judgments about consciousness. So I think you can use this as a way of evaluating or testing theories of consciousness. For theory of consciousness, there's mechanism M is the basis of consciousness, that M should also partly explain our judgments about consciousness. Whatever the basis is ought to explain the reports. And you can use this. You can bring this to bear on various extant theories of consciousness. Here's one famous current theory of consciousness, integrated information theory developed by Giulio Tononi and colleagues at the University of Wisconsin. Tononi says the basis of consciousness is integrated information. A certain kind of integration of information for which Tononi has a measure that he calls phi. Basically, when your phi is high enough, you get consciousness. So consciousness is high phi. And there's a mathematical definition, but I won't go into it here. But such a really interesting theory. So here's a, basically it analyzes a network property of systems, of units, and it's got an informational measure called phi that's supposed to go with consciousness. Question. How does, if integrated information is the basis of consciousness, it ought to explain problem reports, at least in principle. Challenge. How does that work? And it's at least far from obvious to me how integrated information will explain the problem reports. It seems pretty dissociated from them. I mean, on Tononi's view, you can have simulations of systems with high phi that have zero phi. They'll go about making exactly the same reports, but without consciousness at all. So phi is at least somewhat dissociable. You get systems very high phi, but no tendency to report. Maybe that's less worrying. Anyway, here's a challenge for this theory, for other theories. Explain not just how high phi gives you consciousness, but how it plays a central role in the algorithms that generate problem reports. Something similar goes for many other theories, biological theories, quantum theories, global workspace, and so on. But let me just wrap up by saying something about the issue of illusionism that I was talking about near the start. Again, you might be inclined to think that this approach through the meta problem tends, at least very naturally, to lead to illusionism. And I think it can be, it certainly provides, I think, some motivation for illusionism. The view that consciousness doesn't exist, we just think it does. On this view, again, a solution to the meta problem dissolves the hard problem. So here's one way of putting the case for illusionism. If there's a solution to the meta problem, then there's an explanation of our beliefs about consciousness that's independent of consciousness. There's an algorithm that explains our beliefs about consciousness, doesn't mention consciousness, arguably could be in place without consciousness. Arguably, that kind of explanation could debunk our beliefs about consciousness the same way that, perhaps, explaining beliefs about God in evolutionary terms might debunk belief in God. It certainly doesn't prove that God doesn't exist. You might think that if you can explain our beliefs in terms of evolution, it somehow removes the justification or the rational basis for those beliefs. So something like that, I think, can be applied to consciousness, too. And there's a lot to be said about analyzing the extent to which this might debunk the beliefs. On the other hand, the case against illusionism is very, very strong for many people. And the underlying worry is that some illusionism is completely unbelievable. It's just a manifest fact about ourselves that we have conscious experience, we experience red, we feel pain, and so on. To deny those things is to deny the data. Now, the dialectic here is complicated. The illusionist will come back and say, yes, but I can explain why illusionism is unbelievable. These models we have, these self-models of consciousness, are so strong that they're just wired into us by evolution, and they're not models we can get rid of. So my view predicts that my view is unbelievable. And the question is what, the dialectical situation is complex and interesting. But maybe I could just wrap up with two expressions of absurdity on either side of this question, the illusionist and the anti-illusionist, both finding absurdity in the other person's views. Here's Galen Strawson, who is here. Galen's view is very much that illusionism is totally absurd. In fact, he thinks it's the most absurd view that anyone has ever held. There occurred in the 20th century, the most remarkable episode in the whole history of ideas, the whole history of human thought, a number of thinkers denied the existence of something we know with certainty to exist, consciousness. He thinks this is just a sign of incredible philosophical pathology. Here's the rationalist philosopher Eliezer Yudkowski in something he wrote a few years ago on zombies and consciousness, and the view, the epiphenomenalist view that consciousness plays no causal role, where he was engaging some stuff I wrote a couple of decades ago. He said, this is a zombie argument, the idea we can imagine zombies physically like us, but without consciousness. Maybe a candidate for the most deranged idea in all of philosophy. The causally closed cognitive system of charmer's internal narrative is malfunctioning in a way that not by necessity, but just in our own universe miraculously happens to be correct. Here he's expressing this debunking idea that on this view, there's an algorithm that generates these intuitions about consciousness, and that's all physical. There's also this further layer of non-physical stuff, and just by massive coincidence, the physical algorithm is a correct model of the non-physical stuff. That's a form of debunking here. It would take a miracle for this view to be correct. So I think both of these views are onto, these objections are onto something, and to make progress on this, when I decide we need to find a way of getting past these absurdities. I mean, you might say, well, there's middle ground between very strong illusionism and very strong epiphenomenalism. It tends to slide back to the same problems. Other forms of illusionism, weaker forms don't help much with the higher problem. Other forms of realism are still subject to this. It takes a miracle for this view to be correct. Critique. So I think to get beyond absurdity here, both sides need to do something more. The illusionist needs to do more to explain how having a mind could be like this, somehow just like this, even though it's not at all the way that it seems. They need to find some way to recapture the data. Realists need to explain how it is that these meta-problem processes are not completely independent of consciousness. Realists need to explain how meta-problem processes, the ones that generate these intuitions and reports and convictions about consciousness are essentially grounded in consciousness, even if it's possible somehow for them to occur or conceivable for them to occur without consciousness. Anyway, so that's just to lay out a research program. I think a solution to the meta-problem that meets these ambitions might just possibly solve the hard problem of consciousness or at the very least, shed significant light on it. In the meantime, the meta-problem is a potentially tractable research project for everyone, and mine I recommend to all of you. Thanks. Yes, I just want to say I think it's very interesting this concept of we have these mental models, collection of mental models, and that this collection of mental models is consciousness, basically. Consciousness is defined as a collection of these mental models that we have, and the problem of consciousness is that we don't understand the physical phenomenon that causes these mental models or that stimulates these mental models. So we just have this belief that it's ephemeral or not real or something like that. And if you take that view, then what's interesting is that you could simulate these mental models, like robot could simulate these mental models, and you could simulate consciousness as well. And even if the underlying physical phenomenon that fuels these mental models is different, you know, robots have different sensors, etc., you could still get the same consciousness effect in both cases. Yeah, I think that's right. Or at the very least, you ought to be able to get, it looks like you ought to be able to get the same models at least in a robot. If the models themselves are something algorithmic, and ought to be, you ought to be able to design a robot that has at the very least, let's say, isomorphic models in some sense that is conscious. Of course, it's a further question, at least by my lights, but then the robot will be conscious. And that was the question I alluded to in talking about the artificial consciousness test. But you might think that would at least be very good evidence that the robot is conscious. If it's got a model of consciousness just like ours, it seems very plausible there ought to be a very strong link between having a model like that and being conscious. I mean, I think probably something like Ned Block, who was here arguing against machine consciousness, would say, no, no, the model is not enough. The model has to be built of the right stuff. Say it's got to be built of biology and so on. But at least by my lights, I think if I have found the AI system that had a very serious version of our model of consciousness, I take that as a very good reason to believe it's conscious. In the IIT theory, is there a estimate or plausible estimate for what the value of phi is for people and for other systems? Basically, no. It's extremely hard to measure in systems of any size at all. I mean, because the way it's defined involves taking a sum over every possible partition of a system. It turns out, I mean, A, it's hard to measure in the brain because you've got to involve the causal dependencies set between different units on neurons. But even for a pure algorithmic system, you've got like a neural network laid out in front of you, it's computationally intractable to measure the phi of one of those once they get to bigger than 15 units or so. So, you know, today I'd like to say this is an empirical theory and in principle empirically testable. But notice the in principle, it's extremely difficult to to to measure phi. Some people, Scott Aronson, the computer scientist has argued, has tried to put forward counter-examples to the theory, which are basically very, very simple systems like matrix multipliers that multiply two large matrices turn out to have enormous phi. Phi is as big as you like if the matrices are big enough. And therefore, by Tononi's theory, we'll not just be conscious, but as conscious as a human being. And Aronson put this forward as a reductio ad absurdum of the IIT theory. I think Tononi basically bit the bullet and said, yeah, yeah, those those matrix multipliers are actually having some high degree of consciousness. So I think IIT is probably missing at least missing a few pieces of what's going to be developed. But it's a research program too. You mentioned belief as an example of something where, you know, this is another mental quality, but people don't seem to have the same sense that it is very hard to explain. In fact, it almost seems too easy where people like a belief about something sort of feels like just how things are. You have to kind of reflect on a belief to notice it as a belief. Do you think there's also or has there been research kind of related to this question into why is that different? Like, it seems like another angle of attack on this problem is just like, why doesn't this generate the same hard problem? Yeah, in terms, I'm not sure if there's been sort of research from the perspective of the meta problem or a theory of mind. Certainly, people have thought in their own right, what is the difference between belief and experience that makes them so different? This goes way back to David Hume, a philosopher a few centuries ago, who said, you know, basically, perception is vivid. Impressions and ideas. Impressions like experiencing colors are vivid. They have force and vivacity and ideas are merely a faint copy or something. But that's just the first order. And then there are contemporary versions of this kind of thing, far more sophisticated ways of saying a similar thing. But yeah, you could, in principle, explore that through the meta problem. Why does it seem to us that perception is so much more vivid? What about our models of the mind makes perception seem so much more vivid than belief? It makes belief seem kind of structural and empty, whereas perception is so full of light. But no, I don't know of work on that from the meta problem perspective. Like I said, there's not that much work on these introspective models directly. There is work on theory of mind about beliefs tends to be about models of other people. It may be there's something I could dig through a literature on belief that says something about that. It's a good place to push. Thanks. I wanted to bring up Kurt Girdel. You mentioned your advisor wrote Girdel Escher Bach. There's something that seems very like Girdel, Girdelian or whatever, about this whole discussion in that. So Girdel showed that, given like a set of axioms and mathematics, it would either be consistent or complete, but not both. And it seems like when Daniel Dennett, Daniel Dennett seems to have like a set of axioms where he cannot construct consciousness from them. He seems to be very much in this sort of consistent camp. Like he wants to have a consistent framework, but is okay with the incompleteness. And I wonder if similar approach could be taken with consciousness where we could in fact prove that consciousness is independent of Daniel Dennett's set of axioms. The same way they proved after Girdel, they proved like the continuum hypothesis was independent of ZF set theory. And then they added the axiom of choice made at ZFC set theory. So I wonder if we could show that like in Daniel Dennett's world we are essentially zombies or we are kind of either zombies or not. It doesn't matter. Either statement could be true. And then find what is like the minimum axiom that has to be added to Dennett's axioms in order to make consciousness true. Interesting. I thought for a moment this was going to go in a different direction. And you're going to say Dennett is consistent but incomplete. He doesn't have consciousness in this picture. I'm complete, I've got consciousness, but inconsistent. That's why I say all these crazy things. And you're faced with the choice of not having consciousness and being incomplete or having consciousness and somehow getting this hard problem and being forced into at least puzzles and paradoxes. But the way you put it was friendlier to me. Yeah, I mean certainly Dark Hofstetter himself has written a lot on analogies between the Gordelian paradoxes and the mind-body problem. And he thinks always our models, our self models are always doomed to be incomplete in the Gordelian way. And he thinks that that might be somehow part of the explanation of our puzzlement at least about consciousness. Someone like Roger Penrose, of course, takes this much more seriously, literally. He thinks that the computational aspects of computational systems are always going to be limited in the Gordel way. He thinks human beings are not so limited. He thinks we've got mathematical capacities to prove theorems, to see the truth of certain mathematical claims that no formal system could ever have. So he thinks that we somehow go beyond that incomplete Gordelian. I don't know if he actually thinks we're complete, but at least we're not incomplete in the way that finite computational systems are incomplete. And furthermore, he thinks that extra thing that humans have is tied to consciousness. I mean, I never quite saw how that last step goes, even if we did have these special non-algorithmic capacities to see the truth of mathematical theorems. How would that be tied to consciousness? But at the very least, there are structural analogies to be drawn between those two cases about incompleteness of certain theories, how literally we should take the analogies I'd have to think about. Has there been some consideration that the problem of understanding consciousness sort of inherently must be difficult because we address the problem using consciousness? I'm reminded of the halting problem in computer science where we say that in the general case, a program cannot be written to tell whether another program will halt because what if you ran it on itself? It can't sort of be broad enough to include its own execution. So I wonder if there's a similar corollary in consciousness where we use consciousness to think about consciousness. And so therefore, we may not have enough sort of equipment there to be able to unpack Yeah, I mean, it's tricky. People say it's like a user ruler to measure a ruler. Well, I can use this ruler to measure many other things, but it can't measure itself. On the other hand, you can measure one ruler using another ruler. Maybe you can measure one consciousness using another. The brain can't study the brain, but the brain actually has a pretty good job of studying. The brain. So there are some self referential paradoxes there. And I think that again is at the heart of Hofstadter's approach. But I think we'd have to look for very, very specific conditions under which systems can't study themselves. I did always like the idea that the mind was simple enough that we could understand it. We would be too simple to understand the mind. So maybe something like that could be true of consciousness. On the other hand, I actually think that if you start thinking that consciousness can go along with very simple systems, I think at the very least we ought to be able to study consciousness in other systems simpler than ourselves. And boy, if I could solve the hard problem, even in dogs, I'd be I'd be satisfied. Hey, so I have a question about how the meta problem research program might proceed sort of related to the last question. So certainly things we believe about our own consciousness, even if we all say them, probably some of them are false. Our brain has a tendency to hide what reality is like. If you look at like visual perception, you know, there's what's called lightness constancy, you know, our brain subtracts out the lighting in the environment. So we actually see more reliably what the colors of objects are. Like these viral examples of like the black and gold dress is an example of this. And when you're kind of presented with an explanation of it, it's like, huh, my brain does that. It's not something we have access to. Yeah. Or like the Yanni Laurel Laurel Yanni. Yeah, illusion is like another one where like when you hear the explanation, you know, the scientists that understand it, our own introspection doesn't include that. So how do you kind of proceed with trying to get at what consciousness really is versus what our sort of whatever simplified or distorted view might be? Yeah, well, one view here would be that we never have access to the mechanisms that generate consciousness, but we still have access to the conscious states themselves. Actually, the Colashley said this decades ago, he said, no process of the brain is ever conscious. The processes that get you to the states are never conscious. The states they get you to are conscious. So take your experience of the dress. For me, it was, it was what, white and gold. So, you know, and I knew that, you know, each of us was certain that I am, I was experiencing, I was certain that I was experiencing white and gold. Maybe you were certain that you were experiencing blue and black. Which it was. I remember as I was right. You were sure that, yeah, those idiots can't be, yeah, can't be looking at this right. But anyway, each of us, I think the natural way to describe this at least is that each of us was certain what kind of conscious experience we were having. But what we had no idea about was the mechanisms by which we got there. So the mechanisms are completely opaque. But the states themselves were at least prima facie transparent. So I think that would be the standard of view. And even a realist about consciousness could go with that. They say, well, we know what conscious states, we know what those conscious states are. We don't know the processes by which they're generated. The illusionist, I think, wants to go much further and say, well, it seems to you that you know what conscious state you're having. It seems to you that you're experiencing yellow and gold. Sorry, yellow and white, whatever it was, golden, gold and white. Black and gold is whatever. Black and blue, I think. And blue. Gold and white. Yeah. It seems to you that you're experiencing gold and white. But in fact, that too is just something thrown up by another model. The yellow gold was a perceptual model. And then there was an introspective model that said you're experiencing gold and white. When maybe, in fact, you're just a zombie or who knows what's actually going on in your conscious state. So the illusionist view, I think, has to somehow take this further and say not just the processes that generate the conscious states, but maybe the conscious states themselves are somehow opaque to us. All right. Thanks. It feels like some discussion of generality of a problem is missing from this discussion. The matrix multiplier example of having high phi is still, it's not a general thing. Is there someone exploring the space, the sort of intersection of generality and complexity that leads to consciousness as an emergent behavior? When you say generality, I mean, the idea that a theory should be general, that it should apply to every system, you mean mechanisms of... No, generality of the agent, right? If I can write an arbitrarily complex program to play tic-tac-toe, and all it will ever be able to do is play tic-tac-toe, it has no outputs to express anything else. Yeah. As you said, general in the sense of AGI, artificial general intelligence, I mean, some aspects of consciousness seem to be domain general, like, for example, maybe as far as belief and reasoning is conscious, those are domain general, but much of perception doesn't seem especially domain general, right? Color is very domain... Taste is very domain specific, so it's still conscious. If my agent can't express problem statements, like, if I don't give it an output by which it can express problem statements, you can never come to a conclusion about its consciousness. I like to distinguish intelligence and consciousness. I'm even able to... Even natural language and, you know, being able to address a problem statement and analyze a problem, that's already a very advanced form of intelligence. I think it's very plausible that, say, a mouse has got some kind of consciousness, even it's got no ability to address problem statements in many of its capacities, maybe very specialized. I mean, it's still much more general than, say, a simple neural network that can only do one thing. A mouse can do many things, but I'm not sure that I see an essential... I certainly see a connection between intelligence and generality. We want to say, you know, somehow a high degree of generality is required for high intelligence. I'm not sure there's the same connection for consciousness. I think consciousness can be extremely domain specific, has, say, taste and maybe vision or it can be domain general. So maybe those two cross cut each other a bit. So it seems to me like the meta problem as it's formulated implies some amount of, like, separation or epiphenomenalism between, like, consciousness and brain states. And one thing that I think underlies a lot of people's motivation to do, say, science is that it has causal import. Like, predicting behaviors is clearly a functionally useful thing to do. And if you can predict all of behavior without having to explain consciousness, their motivation for explaining consciousness sort of evaporates and it sort of feels like, yeah, yeah, well, what's the point of even thinking about that because it's just not going to do anything for me? What do you say to someone when they say that to you? What is the thing that they say to me again? That there's no, there's maybe consciousness exists, maybe it doesn't. But if I can explain all of human behavior and all of the behavior of the world in general without recourse to such concepts, then I've done everything that there is that's useful, like explaining consciousness isn't a useful thing to do. And thus, I'm not interested in this and it may not be real. I mean, I'm certainly, I'm not, I mean, I think epiphenomenalism could be true. I certainly don't have any commitment to it though. It's quite possible that consciousness has a role to play in generating behavior that we don't yet understand and maybe thinking hard about the meta problem can help us get clearer on those roles. I think if you've got any sympathy to panpsychism, maybe consciousness is intimately involved with how physical processes get going in the, in the first place. And there are people who want to pursue interactionist ideas where consciousness interacts with the brain. Or if you're a reductionist, consciousness may be just a matter of the right algorithm. On all those views, consciousness may have some role to play, but just say it turns out that you can explain all of behavior, including these problems without, without bringing in consciousness. And does that mean that consciousness is not something we should care about and not something that matters? I don't think that would follow. I mean, maybe it wouldn't matter for certain engineering purposes, say you want to build a useful system. But, you know, at least in my view, consciousness is really the only thing that matters. It's a thing that makes life worth living. It's what gives our lives meaning and value and so on. So, it might turn out that, okay, the point of consciousness is not that useful for explaining other stuff. But it's, you know, if it's the source of intrinsic significance in the world, then understanding consciousness will still be absolutely essential to understanding ourselves. Furthermore, if it comes to developing other systems, like say AI systems or dealing with non-human animals and so on, we absolutely want to know, we need to know whether they're conscious, because, you know, if they're conscious, they presumably have moral status. If they can suffer, then it's very bad to mistreat them. If they're not conscious, then you might, I think it's very plausible, treat non-conscious systems. We can treat how we like, and it doesn't really matter morally. So, the question of whether, say, an AI system is conscious or not, it's going to be absolutely vital for how we interact with it and how we build our society. That's not a question of engineering usefulness. That's a question of connecting with our most fundamental values. Yeah, I completely agree. I just, I haven't found that formulation to be very convincing to others necessarily. Hi, thank you so much for coming and chatting with us today. I'm really interested in some of your earlier work, The Extended Mind Distributed Cognition. Yeah. And you're at a company speaking with a bunch of people who do an incredibly cognitively demanding task. Yeah. Most of the literature that I've read on this topic uses relatively simple examples of telling, like, it's difficult to think just inside your head on these relatively simple things. And if you take a look at the programs that we build, sort of like on a mundane, day-to-day basis, there are millions of lines long. I've read people in the past say something like, the Boeing 777 was the most complicated thing that human beings have ever made. And I think most of us would look at that and say, we got that beat, you know, like the things that large internet companies do, the size, the complexity of that is staggering. And yet if we close our eyes, everyone in here is going to say, I'm going to have difficulty writing a 10-line program in my head. Okay. So I'm just sort of as an open, like, I'd be very interested in hearing your thoughts about how the activity of programming connects to the extended mind ideas. Yeah. So this is a reference to something that I got started in about 20 years ago with my colleague Andy Clarke. We wrote an article called The Extended Mind about how processes in the mind can extend outside the brain when we become coupled to our tools. And actually, our central example back then in the mid-90s was a notebook, someone writing stuff in a notebook. I mean, even then, we knew about the internet and we had some internet examples. I guess this company didn't exist yet in 95. But now, of course, our minds have just become more and more extended and, you know, smartphones came along a few years later and everyone is coupled very, very closely to their phones and their other devices that coupled them very, very closely to the internet. Now, it's certainly the case that a whole lot of my memory is now offloaded onto the servers of your company somewhere or other, whether it's in the mail systems or navigation mapping systems or other systems. Most of my navigation has been offloaded to maps and much of my memory has been offloaded. Well, maybe that's in my phone, but other bits of my memory are offloaded into my file system on some cloud service. So certainly, vast amounts of my mind are now existing in the cloud. And if I was somehow to lose access to those completely, then I'd lose an awful lot of my capacities. So I think we are now sort of extending into the cloud, thanks to you guys and others. The question specifically about programming programming is a kind of active interaction with our devices. I mean, I think of programming as something that takes a little bit longer. It's a longer time scale. So the core cases of the extended mind involve sort of automatic use of our devices, which are always ready to hand. We can use them to get information, to act in the moment, which is the kind of thing that the brain does. So insofar as programming is a slower process, you know, and I remember from programming days, all the endless hours of debugging and so on. Then it's at least going to be a slower time scale for the extended mind. But still, Feynman talked about writing this way. Someone looked at Feynman's work and a bunch of notes he had about a physics problem he was thinking about. And someone said to him, oh, it's nice you have this record of your work. And Feynman said, that's not a record of my work. That's the work. That is the thinking. And so I was writing it down and so on. I think, you know, at least my recollection from my programming days was that, you know, when you're actually writing a program, that's not like you just do a bunch of thinking and then code your thoughts. The programming is to some very considerable extent your thinking. So is that the sort of thing you're thinking about here? And the, if we, I think as people that program start to reflect on what we do, and very few of us actually, like if you're the tech lead of a system, maybe you've got it in your head, okay? But you would agree that most of the people on the team who've come more recently only have a chunk of it in their head, and yet they're somehow still able to contribute. Oh yeah, this is now distributed cognition. I mean, the extended mind that extended cognition like starts with an individual and then extends out, extends their capacities out using their tools or their devices or even other people. So maybe my partner serves as my memory, but it's still centered on an individual. But then there's the closely related case of distributed cognition, where you have a team of people who are doing something and are making joint decisions and carrying out joint actions in an absolutely seamless way. And I take it as a company like this that are going to be any number of instances of distributed cognition. I don't know whether the company as a whole has one giant Google mind, or maybe there's just like a near infinite number of separate Google minds for all the individual teams and divisions and so on. But I think yeah, probably some anthropologist has already done a definitive analysis of distributed cognition in this company, but if they haven't, they certainly need to. Thank you. Thank you.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 13.44, "text": " Thanks for coming out. It's good to be here. As Eric said, I'm a philosopher, thinking", "tokens": [50364, 2561, 337, 1348, 484, 13, 467, 311, 665, 281, 312, 510, 13, 1018, 9336, 848, 11, 286, 478, 257, 29805, 11, 1953, 51036], "temperature": 0.0, "avg_logprob": -0.18385305561003137, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.023935580626130104}, {"id": 1, "seek": 0, "start": 13.44, "end": 20.16, "text": " about consciousness, coming from a background in the sciences and math that always struck", "tokens": [51036, 466, 10081, 11, 1348, 490, 257, 3678, 294, 264, 17677, 293, 5221, 300, 1009, 13159, 51372], "temperature": 0.0, "avg_logprob": -0.18385305561003137, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.023935580626130104}, {"id": 2, "seek": 0, "start": 20.16, "end": 28.44, "text": " me that the most interesting and hardest unsolved problem in the sciences was the problem", "tokens": [51372, 385, 300, 264, 881, 1880, 293, 13158, 2693, 29110, 1154, 294, 264, 17677, 390, 264, 1154, 51786], "temperature": 0.0, "avg_logprob": -0.18385305561003137, "compression_ratio": 1.5113636363636365, "no_speech_prob": 0.023935580626130104}, {"id": 3, "seek": 2844, "start": 28.44, "end": 34.480000000000004, "text": " of consciousness. Way back, 25 years ago, when I was in grad school, it seemed to me", "tokens": [50364, 295, 10081, 13, 9558, 646, 11, 3552, 924, 2057, 11, 562, 286, 390, 294, 2771, 1395, 11, 309, 6576, 281, 385, 50666], "temperature": 0.0, "avg_logprob": -0.139574666817983, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0012624673545360565}, {"id": 4, "seek": 2844, "start": 34.480000000000004, "end": 40.6, "text": " the best way to come at this from a big picture perspective was to go into philosophy and", "tokens": [50666, 264, 1151, 636, 281, 808, 412, 341, 490, 257, 955, 3036, 4585, 390, 281, 352, 666, 10675, 293, 50972], "temperature": 0.0, "avg_logprob": -0.139574666817983, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0012624673545360565}, {"id": 5, "seek": 2844, "start": 40.6, "end": 44.92, "text": " think about the foundational issues that arise and thinking about consciousness from any", "tokens": [50972, 519, 466, 264, 32195, 2663, 300, 20288, 293, 1953, 466, 10081, 490, 604, 51188], "temperature": 0.0, "avg_logprob": -0.139574666817983, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0012624673545360565}, {"id": 6, "seek": 2844, "start": 44.92, "end": 52.2, "text": " number of different angles, including the angles of neuroscience and psychology and AI.", "tokens": [51188, 1230, 295, 819, 14708, 11, 3009, 264, 14708, 295, 42762, 293, 15105, 293, 7318, 13, 51552], "temperature": 0.0, "avg_logprob": -0.139574666817983, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0012624673545360565}, {"id": 7, "seek": 2844, "start": 52.2, "end": 55.88, "text": " In this talk, I'm going to present a slightly different perspective on the problem after", "tokens": [51552, 682, 341, 751, 11, 286, 478, 516, 281, 1974, 257, 4748, 819, 4585, 322, 264, 1154, 934, 51736], "temperature": 0.0, "avg_logprob": -0.139574666817983, "compression_ratio": 1.673003802281369, "no_speech_prob": 0.0012624673545360565}, {"id": 8, "seek": 5588, "start": 55.88, "end": 63.800000000000004, "text": " laying out some background, the perspective of what I call the meta problem of consciousness.", "tokens": [50364, 14903, 484, 512, 3678, 11, 264, 4585, 295, 437, 286, 818, 264, 19616, 1154, 295, 10081, 13, 50760], "temperature": 0.0, "avg_logprob": -0.16270032362504439, "compression_ratio": 1.6806083650190113, "no_speech_prob": 0.006480510346591473}, {"id": 9, "seek": 5588, "start": 63.800000000000004, "end": 68.68, "text": " I always like the idea that you approach a problem by stepping one level up, taking the", "tokens": [50760, 286, 1009, 411, 264, 1558, 300, 291, 3109, 257, 1154, 538, 16821, 472, 1496, 493, 11, 1940, 264, 51004], "temperature": 0.0, "avg_logprob": -0.16270032362504439, "compression_ratio": 1.6806083650190113, "no_speech_prob": 0.006480510346591473}, {"id": 10, "seek": 5588, "start": 68.68, "end": 76.76, "text": " meta perspective. I love this quote, anything you can do, I can do meta. I have no idea", "tokens": [51004, 19616, 4585, 13, 286, 959, 341, 6513, 11, 1340, 291, 393, 360, 11, 286, 393, 360, 19616, 13, 286, 362, 572, 1558, 51408], "temperature": 0.0, "avg_logprob": -0.16270032362504439, "compression_ratio": 1.6806083650190113, "no_speech_prob": 0.006480510346591473}, {"id": 11, "seek": 5588, "start": 76.76, "end": 81.04, "text": " what the origins was. I like the fact this is attributed to Rudolf Kahnap, one of my", "tokens": [51408, 437, 264, 22721, 390, 13, 286, 411, 264, 1186, 341, 307, 30976, 281, 18636, 7491, 591, 12140, 569, 11, 472, 295, 452, 51622], "temperature": 0.0, "avg_logprob": -0.16270032362504439, "compression_ratio": 1.6806083650190113, "no_speech_prob": 0.006480510346591473}, {"id": 12, "seek": 5588, "start": 81.04, "end": 85.0, "text": " favorite philosophers, but anyone who knows Kahnap's work is completely implausible. He", "tokens": [51622, 2954, 36839, 11, 457, 2878, 567, 3255, 591, 12140, 569, 311, 589, 307, 2584, 8484, 8463, 964, 13, 634, 51820], "temperature": 0.0, "avg_logprob": -0.16270032362504439, "compression_ratio": 1.6806083650190113, "no_speech_prob": 0.006480510346591473}, {"id": 13, "seek": 8500, "start": 85.0, "end": 89.12, "text": " would ever say anything so frivolous. It's also been attributed to my thesis advisor,", "tokens": [50364, 576, 1562, 584, 1340, 370, 431, 21356, 563, 13, 467, 311, 611, 668, 30976, 281, 452, 22288, 19161, 11, 50570], "temperature": 0.0, "avg_logprob": -0.1753783811602676, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.014055105857551098}, {"id": 14, "seek": 8500, "start": 89.12, "end": 94.92, "text": " Doug Hofstadter, author of Goethe Lescher Bach and a big fan of the meta perspective,", "tokens": [50570, 12742, 37379, 48299, 391, 11, 3793, 295, 1037, 302, 675, 6965, 6759, 30920, 293, 257, 955, 3429, 295, 264, 19616, 4585, 11, 50860], "temperature": 0.0, "avg_logprob": -0.1753783811602676, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.014055105857551098}, {"id": 15, "seek": 8500, "start": 94.92, "end": 101.0, "text": " but he assures me he never said it either. But the meta perspective on anything is stepping", "tokens": [50860, 457, 415, 1256, 1303, 385, 415, 1128, 848, 309, 2139, 13, 583, 264, 19616, 4585, 322, 1340, 307, 16821, 51164], "temperature": 0.0, "avg_logprob": -0.1753783811602676, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.014055105857551098}, {"id": 16, "seek": 8500, "start": 101.0, "end": 108.62, "text": " up a level. The meta problem, as I think about it, is called the meta problem because it's", "tokens": [51164, 493, 257, 1496, 13, 440, 19616, 1154, 11, 382, 286, 519, 466, 309, 11, 307, 1219, 264, 19616, 1154, 570, 309, 311, 51545], "temperature": 0.0, "avg_logprob": -0.1753783811602676, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.014055105857551098}, {"id": 17, "seek": 8500, "start": 108.62, "end": 114.32, "text": " a problem about a problem. A meta theory is a theory about a theory. Meta problem is", "tokens": [51545, 257, 1154, 466, 257, 1154, 13, 316, 19616, 5261, 307, 257, 5261, 466, 257, 5261, 13, 6377, 64, 1154, 307, 51830], "temperature": 0.0, "avg_logprob": -0.1753783811602676, "compression_ratio": 1.7845528455284554, "no_speech_prob": 0.014055105857551098}, {"id": 18, "seek": 11432, "start": 114.32, "end": 118.97999999999999, "text": " a problem about a problem. In particular, it's the problem of explaining why we think", "tokens": [50364, 257, 1154, 466, 257, 1154, 13, 682, 1729, 11, 309, 311, 264, 1154, 295, 13468, 983, 321, 519, 50597], "temperature": 0.0, "avg_logprob": -0.10269059285078899, "compression_ratio": 2.1132075471698113, "no_speech_prob": 0.0021141751203686}, {"id": 19, "seek": 11432, "start": 118.97999999999999, "end": 124.11999999999999, "text": " there is a problem about consciousness. So there's a first order problem, the problem", "tokens": [50597, 456, 307, 257, 1154, 466, 10081, 13, 407, 456, 311, 257, 700, 1668, 1154, 11, 264, 1154, 50854], "temperature": 0.0, "avg_logprob": -0.10269059285078899, "compression_ratio": 2.1132075471698113, "no_speech_prob": 0.0021141751203686}, {"id": 20, "seek": 11432, "start": 124.11999999999999, "end": 129.18, "text": " of consciousness. Today I'm going to focus on a problem about it, but I'll start by introducing", "tokens": [50854, 295, 10081, 13, 2692, 286, 478, 516, 281, 1879, 322, 257, 1154, 466, 309, 11, 457, 286, 603, 722, 538, 15424, 51107], "temperature": 0.0, "avg_logprob": -0.10269059285078899, "compression_ratio": 2.1132075471698113, "no_speech_prob": 0.0021141751203686}, {"id": 21, "seek": 11432, "start": 129.18, "end": 135.2, "text": " the first order problem itself. The first order problem is what we call the hard problem", "tokens": [51107, 264, 700, 1668, 1154, 2564, 13, 440, 700, 1668, 1154, 307, 437, 321, 818, 264, 1152, 1154, 51408], "temperature": 0.0, "avg_logprob": -0.10269059285078899, "compression_ratio": 2.1132075471698113, "no_speech_prob": 0.0021141751203686}, {"id": 22, "seek": 11432, "start": 135.2, "end": 142.0, "text": " of consciousness. It's the problem of explaining why and how physical processes should give", "tokens": [51408, 295, 10081, 13, 467, 311, 264, 1154, 295, 13468, 983, 293, 577, 4001, 7555, 820, 976, 51748], "temperature": 0.0, "avg_logprob": -0.10269059285078899, "compression_ratio": 2.1132075471698113, "no_speech_prob": 0.0021141751203686}, {"id": 23, "seek": 14200, "start": 142.04, "end": 149.04, "text": " rise to conscious experience. You've got all this neurons firing in your brain, bringing", "tokens": [50366, 6272, 281, 6648, 1752, 13, 509, 600, 658, 439, 341, 22027, 16045, 294, 428, 3567, 11, 5062, 50716], "temperature": 0.0, "avg_logprob": -0.195279541015625, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00394241651520133}, {"id": 24, "seek": 14200, "start": 151.52, "end": 157.88, "text": " about all kinds of sophisticated behavior. We can get to be done explaining our various", "tokens": [50840, 466, 439, 3685, 295, 16950, 5223, 13, 492, 393, 483, 281, 312, 1096, 13468, 527, 3683, 51158], "temperature": 0.0, "avg_logprob": -0.195279541015625, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00394241651520133}, {"id": 25, "seek": 14200, "start": 157.88, "end": 161.68, "text": " responses, but there's this big question about how it feels from the first person point of", "tokens": [51158, 13019, 11, 457, 456, 311, 341, 955, 1168, 466, 577, 309, 3417, 490, 264, 700, 954, 935, 295, 51348], "temperature": 0.0, "avg_logprob": -0.195279541015625, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00394241651520133}, {"id": 26, "seek": 14200, "start": 161.68, "end": 166.32, "text": " view. That's the subjective experience. I like this illustration of the hard problem", "tokens": [51348, 1910, 13, 663, 311, 264, 25972, 1752, 13, 286, 411, 341, 22645, 295, 264, 1152, 1154, 51580], "temperature": 0.0, "avg_logprob": -0.195279541015625, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00394241651520133}, {"id": 27, "seek": 14200, "start": 166.32, "end": 171.96, "text": " of consciousness. It seems to show someone's hair catching fire, but I guess it's a metaphorical", "tokens": [51580, 295, 10081, 13, 467, 2544, 281, 855, 1580, 311, 2578, 16124, 2610, 11, 457, 286, 2041, 309, 311, 257, 19157, 804, 51862], "temperature": 0.0, "avg_logprob": -0.195279541015625, "compression_ratio": 1.650735294117647, "no_speech_prob": 0.00394241651520133}, {"id": 28, "seek": 17196, "start": 172.4, "end": 178.4, "text": " illustration of the subjective perspective. The hard problem is concerned with what philosophers", "tokens": [50386, 22645, 295, 264, 25972, 4585, 13, 440, 1152, 1154, 307, 5922, 365, 437, 36839, 50686], "temperature": 0.0, "avg_logprob": -0.10996022878908644, "compression_ratio": 2.008510638297872, "no_speech_prob": 0.00024509921786375344}, {"id": 29, "seek": 17196, "start": 178.4, "end": 184.32, "text": " call phenomenal consciousness. The word consciousness is ambiguous a thousand ways, but phenomenal", "tokens": [50686, 818, 17778, 10081, 13, 440, 1349, 10081, 307, 39465, 257, 4714, 2098, 11, 457, 17778, 50982], "temperature": 0.0, "avg_logprob": -0.10996022878908644, "compression_ratio": 2.008510638297872, "no_speech_prob": 0.00024509921786375344}, {"id": 30, "seek": 17196, "start": 184.32, "end": 190.36, "text": " consciousness is what it's like to be a subject from the first person point of view. A system", "tokens": [50982, 10081, 307, 437, 309, 311, 411, 281, 312, 257, 3983, 490, 264, 700, 954, 935, 295, 1910, 13, 316, 1185, 51284], "temperature": 0.0, "avg_logprob": -0.10996022878908644, "compression_ratio": 2.008510638297872, "no_speech_prob": 0.00024509921786375344}, {"id": 31, "seek": 17196, "start": 190.36, "end": 195.88, "text": " is phenomenally conscious. If there's something it's like to be it, a mental state is phenomenally", "tokens": [51284, 307, 9388, 379, 6648, 13, 759, 456, 311, 746, 309, 311, 411, 281, 312, 309, 11, 257, 4973, 1785, 307, 9388, 379, 51560], "temperature": 0.0, "avg_logprob": -0.10996022878908644, "compression_ratio": 2.008510638297872, "no_speech_prob": 0.00024509921786375344}, {"id": 32, "seek": 17196, "start": 195.88, "end": 200.28, "text": " conscious if there's something it's like to be in it. The thought is there are some", "tokens": [51560, 6648, 498, 456, 311, 746, 309, 311, 411, 281, 312, 294, 309, 13, 440, 1194, 307, 456, 366, 512, 51780], "temperature": 0.0, "avg_logprob": -0.10996022878908644, "compression_ratio": 2.008510638297872, "no_speech_prob": 0.00024509921786375344}, {"id": 33, "seek": 20028, "start": 200.32, "end": 205.2, "text": " systems, so there's something it's like to be that system. There's something it's like", "tokens": [50366, 3652, 11, 370, 456, 311, 746, 309, 311, 411, 281, 312, 300, 1185, 13, 821, 311, 746, 309, 311, 411, 50610], "temperature": 0.0, "avg_logprob": -0.13500293608634703, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.0002692370326258242}, {"id": 34, "seek": 20028, "start": 205.2, "end": 210.32, "text": " to be me. I presume there's something it's like to be you, but presumably there's nothing", "tokens": [50610, 281, 312, 385, 13, 286, 43283, 456, 311, 746, 309, 311, 411, 281, 312, 291, 11, 457, 26742, 456, 311, 1825, 50866], "temperature": 0.0, "avg_logprob": -0.13500293608634703, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.0002692370326258242}, {"id": 35, "seek": 20028, "start": 210.32, "end": 215.96, "text": " it's like to be this lectern as far as we know. The lectern does not have a first person", "tokens": [50866, 309, 311, 411, 281, 312, 341, 5899, 1248, 382, 1400, 382, 321, 458, 13, 440, 5899, 1248, 775, 406, 362, 257, 700, 954, 51148], "temperature": 0.0, "avg_logprob": -0.13500293608634703, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.0002692370326258242}, {"id": 36, "seek": 20028, "start": 215.96, "end": 222.96, "text": " perspective. This phrase was made famous by my colleague Tom Nagel at NYU who back in 1974", "tokens": [51148, 4585, 13, 639, 9535, 390, 1027, 4618, 538, 452, 13532, 5041, 18913, 338, 412, 42682, 567, 646, 294, 33422, 51498], "temperature": 0.0, "avg_logprob": -0.13500293608634703, "compression_ratio": 1.816326530612245, "no_speech_prob": 0.0002692370326258242}, {"id": 37, "seek": 22296, "start": 223.04000000000002, "end": 230.04000000000002, "text": " wrote an article called What is it like to be a bat? The general idea was what's very", "tokens": [50368, 4114, 364, 7222, 1219, 708, 307, 309, 411, 281, 312, 257, 7362, 30, 440, 2674, 1558, 390, 437, 311, 588, 50718], "temperature": 0.0, "avg_logprob": -0.16643765393425436, "compression_ratio": 1.7958333333333334, "no_speech_prob": 0.0003918860456906259}, {"id": 38, "seek": 22296, "start": 230.96, "end": 236.20000000000002, "text": " hard to know what it's like to be a bat from the third person point of view just looking", "tokens": [50764, 1152, 281, 458, 437, 309, 311, 411, 281, 312, 257, 7362, 490, 264, 2636, 954, 935, 295, 1910, 445, 1237, 51026], "temperature": 0.0, "avg_logprob": -0.16643765393425436, "compression_ratio": 1.7958333333333334, "no_speech_prob": 0.0003918860456906259}, {"id": 39, "seek": 22296, "start": 236.20000000000002, "end": 240.64000000000001, "text": " at it as a human who has different kinds of experience, but presumably very plausibly", "tokens": [51026, 412, 309, 382, 257, 1952, 567, 575, 819, 3685, 295, 1752, 11, 457, 26742, 588, 34946, 3545, 51248], "temperature": 0.0, "avg_logprob": -0.16643765393425436, "compression_ratio": 1.7958333333333334, "no_speech_prob": 0.0003918860456906259}, {"id": 40, "seek": 22296, "start": 240.64000000000001, "end": 245.0, "text": " there is something it's like to be a bat. The bat is conscious. It's having subjective", "tokens": [51248, 456, 307, 746, 309, 311, 411, 281, 312, 257, 7362, 13, 440, 7362, 307, 6648, 13, 467, 311, 1419, 25972, 51466], "temperature": 0.0, "avg_logprob": -0.16643765393425436, "compression_ratio": 1.7958333333333334, "no_speech_prob": 0.0003918860456906259}, {"id": 41, "seek": 22296, "start": 245.0, "end": 252.0, "text": " experiences just of a kind very different from ours. In human subjective experience", "tokens": [51466, 5235, 445, 295, 257, 733, 588, 819, 490, 11896, 13, 682, 1952, 25972, 1752, 51816], "temperature": 0.0, "avg_logprob": -0.16643765393425436, "compression_ratio": 1.7958333333333334, "no_speech_prob": 0.0003918860456906259}, {"id": 42, "seek": 25296, "start": 253.92000000000002, "end": 260.40000000000003, "text": " consciousness divides into any number of different kinds or aspects like different tracks of", "tokens": [50412, 10081, 41347, 666, 604, 1230, 295, 819, 3685, 420, 7270, 411, 819, 10218, 295, 50736], "temperature": 0.0, "avg_logprob": -0.191792191685857, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.00017939334793481976}, {"id": 43, "seek": 25296, "start": 260.40000000000003, "end": 266.40000000000003, "text": " the inner movie of consciousness. We have visual experiences like the experience of", "tokens": [50736, 264, 7284, 3169, 295, 10081, 13, 492, 362, 5056, 5235, 411, 264, 1752, 295, 51036], "temperature": 0.0, "avg_logprob": -0.191792191685857, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.00017939334793481976}, {"id": 44, "seek": 25296, "start": 266.40000000000003, "end": 272.92, "text": " say these colors blue and red and green from the first person point of view and of depth.", "tokens": [51036, 584, 613, 4577, 3344, 293, 2182, 293, 3092, 490, 264, 700, 954, 935, 295, 1910, 293, 295, 7161, 13, 51362], "temperature": 0.0, "avg_logprob": -0.191792191685857, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.00017939334793481976}, {"id": 45, "seek": 25296, "start": 272.92, "end": 279.92, "text": " There are sensory experiences like the experience of my voice, experiences of taste and smell,", "tokens": [51362, 821, 366, 27233, 5235, 411, 264, 1752, 295, 452, 3177, 11, 5235, 295, 3939, 293, 4316, 11, 51712], "temperature": 0.0, "avg_logprob": -0.191792191685857, "compression_ratio": 1.814070351758794, "no_speech_prob": 0.00017939334793481976}, {"id": 46, "seek": 27992, "start": 280.36, "end": 287.36, "text": " their experiences of your body, feeling pain or orgasms or hunger or a tickle or something.", "tokens": [50386, 641, 5235, 295, 428, 1772, 11, 2633, 1822, 420, 44834, 2592, 420, 19229, 420, 257, 5204, 306, 420, 746, 13, 50736], "temperature": 0.0, "avg_logprob": -0.19794855489359273, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.0006665110704489052}, {"id": 47, "seek": 27992, "start": 287.84000000000003, "end": 293.08000000000004, "text": " They all have some distinctive first person quality, mental images like recalled visual", "tokens": [50760, 814, 439, 362, 512, 27766, 700, 954, 3125, 11, 4973, 5267, 411, 39301, 5056, 51022], "temperature": 0.0, "avg_logprob": -0.19794855489359273, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.0006665110704489052}, {"id": 48, "seek": 27992, "start": 293.08000000000004, "end": 300.08000000000004, "text": " images, emotional experiences like experience of happiness or anger and indeed we all seem", "tokens": [51022, 5267, 11, 6863, 5235, 411, 1752, 295, 8324, 420, 10240, 293, 6451, 321, 439, 1643, 51372], "temperature": 0.0, "avg_logprob": -0.19794855489359273, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.0006665110704489052}, {"id": 49, "seek": 27992, "start": 300.28000000000003, "end": 303.84000000000003, "text": " to have this stream of a current thought or at the very least we're kind of chattering", "tokens": [51382, 281, 362, 341, 4309, 295, 257, 2190, 1194, 420, 412, 264, 588, 1935, 321, 434, 733, 295, 37432, 51560], "temperature": 0.0, "avg_logprob": -0.19794855489359273, "compression_ratio": 1.6376146788990826, "no_speech_prob": 0.0006665110704489052}, {"id": 50, "seek": 30384, "start": 303.84, "end": 310.84, "text": " away to ourselves and reflecting and deciding. All of these are aspects of subjective experience,", "tokens": [50364, 1314, 281, 4175, 293, 23543, 293, 17990, 13, 1057, 295, 613, 366, 7270, 295, 25972, 1752, 11, 50714], "temperature": 0.0, "avg_logprob": -0.11826299366198088, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0017000840744003654}, {"id": 51, "seek": 30384, "start": 311.2, "end": 317.56, "text": " things we experience from the first person point of view and I think these subjective", "tokens": [50732, 721, 321, 1752, 490, 264, 700, 954, 935, 295, 1910, 293, 286, 519, 613, 25972, 51050], "temperature": 0.0, "avg_logprob": -0.11826299366198088, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0017000840744003654}, {"id": 52, "seek": 30384, "start": 317.56, "end": 324.55999999999995, "text": " experiences are at least on the face of it data, data for the science of consciousness", "tokens": [51050, 5235, 366, 412, 1935, 322, 264, 1851, 295, 309, 1412, 11, 1412, 337, 264, 3497, 295, 10081, 51400], "temperature": 0.0, "avg_logprob": -0.11826299366198088, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0017000840744003654}, {"id": 53, "seek": 30384, "start": 324.76, "end": 329.67999999999995, "text": " to explain. These are just facts about us that we're having these subjective experiences.", "tokens": [51410, 281, 2903, 13, 1981, 366, 445, 9130, 466, 505, 300, 321, 434, 1419, 613, 25972, 5235, 13, 51656], "temperature": 0.0, "avg_logprob": -0.11826299366198088, "compression_ratio": 1.7647058823529411, "no_speech_prob": 0.0017000840744003654}, {"id": 54, "seek": 32968, "start": 329.68, "end": 334.6, "text": " As we ignore them, we're ignoring the data. So if you catalog the data that say the science", "tokens": [50364, 1018, 321, 11200, 552, 11, 321, 434, 26258, 264, 1412, 13, 407, 498, 291, 19746, 264, 1412, 300, 584, 264, 3497, 50610], "temperature": 0.0, "avg_logprob": -0.20084141749961704, "compression_ratio": 1.909871244635193, "no_speech_prob": 8.749176777200773e-05}, {"id": 55, "seek": 32968, "start": 334.6, "end": 338.36, "text": " of consciousness needs to explain, there are certainly facts about our behavior and how", "tokens": [50610, 295, 10081, 2203, 281, 2903, 11, 456, 366, 3297, 9130, 466, 527, 5223, 293, 577, 50798], "temperature": 0.0, "avg_logprob": -0.20084141749961704, "compression_ratio": 1.909871244635193, "no_speech_prob": 8.749176777200773e-05}, {"id": 56, "seek": 32968, "start": 338.36, "end": 342.48, "text": " we respond in situations. There are facts about how our brain, facts about how our brain", "tokens": [50798, 321, 4196, 294, 6851, 13, 821, 366, 9130, 466, 577, 527, 3567, 11, 9130, 466, 577, 527, 3567, 51004], "temperature": 0.0, "avg_logprob": -0.20084141749961704, "compression_ratio": 1.909871244635193, "no_speech_prob": 8.749176777200773e-05}, {"id": 57, "seek": 32968, "start": 342.48, "end": 346.84000000000003, "text": " is working. There are also facts about how subjective experiences and on the face of", "tokens": [51004, 307, 1364, 13, 821, 366, 611, 9130, 466, 577, 25972, 5235, 293, 322, 264, 1851, 295, 51222], "temperature": 0.0, "avg_logprob": -0.20084141749961704, "compression_ratio": 1.909871244635193, "no_speech_prob": 8.749176777200773e-05}, {"id": 58, "seek": 32968, "start": 346.84000000000003, "end": 353.76, "text": " it their data. And it's these data that pose what I call the hard problem of consciousness.", "tokens": [51222, 309, 641, 1412, 13, 400, 309, 311, 613, 1412, 300, 10774, 437, 286, 818, 264, 1152, 1154, 295, 10081, 13, 51568], "temperature": 0.0, "avg_logprob": -0.20084141749961704, "compression_ratio": 1.909871244635193, "no_speech_prob": 8.749176777200773e-05}, {"id": 59, "seek": 35376, "start": 353.84, "end": 359.68, "text": " This gets contrasted with the easy problems, the so-called easy problems of consciousness", "tokens": [50368, 639, 2170, 8712, 292, 365, 264, 1858, 2740, 11, 264, 370, 12, 11880, 1858, 2740, 295, 10081, 50660], "temperature": 0.0, "avg_logprob": -0.14261366923650107, "compression_ratio": 1.7596899224806202, "no_speech_prob": 0.0009392719948664308}, {"id": 60, "seek": 35376, "start": 359.68, "end": 366.68, "text": " which are the problems of explaining behavioral and cognitive functions. Objective things", "tokens": [50660, 597, 366, 264, 2740, 295, 13468, 19124, 293, 15605, 6828, 13, 24753, 488, 721, 51010], "temperature": 0.0, "avg_logprob": -0.14261366923650107, "compression_ratio": 1.7596899224806202, "no_speech_prob": 0.0009392719948664308}, {"id": 61, "seek": 35376, "start": 367.59999999999997, "end": 372.56, "text": " you can measure from the third person point of view typically tied to behavior, perceptual", "tokens": [51056, 291, 393, 3481, 490, 264, 2636, 954, 935, 295, 1910, 5850, 9601, 281, 5223, 11, 43276, 901, 51304], "temperature": 0.0, "avg_logprob": -0.14261366923650107, "compression_ratio": 1.7596899224806202, "no_speech_prob": 0.0009392719948664308}, {"id": 62, "seek": 35376, "start": 372.56, "end": 378.44, "text": " discrimination say of a stimulus. I can discriminate two different things in my environment. I", "tokens": [51304, 15973, 584, 295, 257, 21366, 13, 286, 393, 47833, 732, 819, 721, 294, 452, 2823, 13, 286, 51598], "temperature": 0.0, "avg_logprob": -0.14261366923650107, "compression_ratio": 1.7596899224806202, "no_speech_prob": 0.0009392719948664308}, {"id": 63, "seek": 35376, "start": 378.44, "end": 383.03999999999996, "text": " can say that's red and that's green. I can integrate the information say about the color", "tokens": [51598, 393, 584, 300, 311, 2182, 293, 300, 311, 3092, 13, 286, 393, 13365, 264, 1589, 584, 466, 264, 2017, 51828], "temperature": 0.0, "avg_logprob": -0.14261366923650107, "compression_ratio": 1.7596899224806202, "no_speech_prob": 0.0009392719948664308}, {"id": 64, "seek": 38304, "start": 383.04, "end": 387.04, "text": " and the shape. I can use it to control my behavior, walk towards the red one rather", "tokens": [50364, 293, 264, 3909, 13, 286, 393, 764, 309, 281, 1969, 452, 5223, 11, 1792, 3030, 264, 2182, 472, 2831, 50564], "temperature": 0.0, "avg_logprob": -0.16351218890118344, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0002304580993950367}, {"id": 65, "seek": 38304, "start": 387.04, "end": 394.52000000000004, "text": " than the green one. I can report it, say that's red and so on. Those are all data too for", "tokens": [50564, 813, 264, 3092, 472, 13, 286, 393, 2275, 309, 11, 584, 300, 311, 2182, 293, 370, 322, 13, 3950, 366, 439, 1412, 886, 337, 50938], "temperature": 0.0, "avg_logprob": -0.16351218890118344, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0002304580993950367}, {"id": 66, "seek": 38304, "start": 394.52000000000004, "end": 400.04, "text": " science to explain. But we've got a bead on how to explain those. They don't seem to", "tokens": [50938, 3497, 281, 2903, 13, 583, 321, 600, 658, 257, 24117, 322, 577, 281, 2903, 729, 13, 814, 500, 380, 1643, 281, 51214], "temperature": 0.0, "avg_logprob": -0.16351218890118344, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0002304580993950367}, {"id": 67, "seek": 38304, "start": 400.04, "end": 407.04, "text": " pose as big a problem. Why? We explain those easy problems by finding a mechanism, typically", "tokens": [51214, 10774, 382, 955, 257, 1154, 13, 1545, 30, 492, 2903, 729, 1858, 2740, 538, 5006, 257, 7513, 11, 5850, 51564], "temperature": 0.0, "avg_logprob": -0.16351218890118344, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.0002304580993950367}, {"id": 68, "seek": 40704, "start": 408.04, "end": 415.04, "text": " a neural or computational mechanism that performs the relevant function to explain", "tokens": [50414, 257, 18161, 420, 28270, 7513, 300, 26213, 264, 7340, 2445, 281, 2903, 50764], "temperature": 0.0, "avg_logprob": -0.17815952043275576, "compression_ratio": 1.6813725490196079, "no_speech_prob": 0.0001739576255204156}, {"id": 69, "seek": 40704, "start": 415.44, "end": 420.44, "text": " how it is that I get to say there's a red thing over there or walk towards it. Will", "tokens": [50784, 577, 309, 307, 300, 286, 483, 281, 584, 456, 311, 257, 2182, 551, 670, 456, 420, 1792, 3030, 309, 13, 3099, 51034], "temperature": 0.0, "avg_logprob": -0.17815952043275576, "compression_ratio": 1.6813725490196079, "no_speech_prob": 0.0001739576255204156}, {"id": 70, "seek": 40704, "start": 420.44, "end": 427.44, "text": " you find the mechanisms involving perceptual processes and action processes in my brain", "tokens": [51034, 291, 915, 264, 15902, 17030, 43276, 901, 7555, 293, 3069, 7555, 294, 452, 3567, 51384], "temperature": 0.0, "avg_logprob": -0.17815952043275576, "compression_ratio": 1.6813725490196079, "no_speech_prob": 0.0001739576255204156}, {"id": 71, "seek": 40704, "start": 427.8, "end": 432.56, "text": " that leads to that behavior? Find the right mechanism that performs the function. You've", "tokens": [51402, 300, 6689, 281, 300, 5223, 30, 11809, 264, 558, 7513, 300, 26213, 264, 2445, 13, 509, 600, 51640], "temperature": 0.0, "avg_logprob": -0.17815952043275576, "compression_ratio": 1.6813725490196079, "no_speech_prob": 0.0001739576255204156}, {"id": 72, "seek": 43256, "start": 432.56, "end": 438.68, "text": " explained what needs to be explained with the easy problems of consciousness. But for", "tokens": [50364, 8825, 437, 2203, 281, 312, 8825, 365, 264, 1858, 2740, 295, 10081, 13, 583, 337, 50670], "temperature": 0.0, "avg_logprob": -0.1786514409383138, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.006484369747340679}, {"id": 73, "seek": 43256, "start": 438.68, "end": 443.8, "text": " the hard problem, for subjective experience, it's just not clear that this standard method", "tokens": [50670, 264, 1152, 1154, 11, 337, 25972, 1752, 11, 309, 311, 445, 406, 1850, 300, 341, 3832, 3170, 50926], "temperature": 0.0, "avg_logprob": -0.1786514409383138, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.006484369747340679}, {"id": 74, "seek": 43256, "start": 443.8, "end": 450.8, "text": " works. It looks like explaining all that behavior still leaves open a further question. Why", "tokens": [50926, 1985, 13, 467, 1542, 411, 13468, 439, 300, 5223, 920, 5510, 1269, 257, 3052, 1168, 13, 1545, 51276], "temperature": 0.0, "avg_logprob": -0.1786514409383138, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.006484369747340679}, {"id": 75, "seek": 43256, "start": 451.04, "end": 458.04, "text": " does all that give you subjective experience? Explain the reacting, the responding, the", "tokens": [51288, 775, 439, 300, 976, 291, 25972, 1752, 30, 39574, 264, 25817, 11, 264, 16670, 11, 264, 51638], "temperature": 0.0, "avg_logprob": -0.1786514409383138, "compression_ratio": 1.6635514018691588, "no_speech_prob": 0.006484369747340679}, {"id": 76, "seek": 45804, "start": 458.8, "end": 465.8, "text": " controlling, the reporting and so on. It still leaves open the question why is all that accompanied", "tokens": [50402, 14905, 11, 264, 10031, 293, 370, 322, 13, 467, 920, 5510, 1269, 264, 1168, 983, 307, 439, 300, 24202, 50752], "temperature": 0.0, "avg_logprob": -0.1751936921978941, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.00022334106324706227}, {"id": 77, "seek": 45804, "start": 466.04, "end": 472.68, "text": " by subjective experience? Why doesn't it go on in the dark without consciousness, so", "tokens": [50764, 538, 25972, 1752, 30, 1545, 1177, 380, 309, 352, 322, 294, 264, 2877, 1553, 10081, 11, 370, 51096], "temperature": 0.0, "avg_logprob": -0.1751936921978941, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.00022334106324706227}, {"id": 78, "seek": 45804, "start": 472.68, "end": 477.6, "text": " to speak? There seems to be what the philosopher Joe Levine has called a gap here, an explanatory", "tokens": [51096, 281, 1710, 30, 821, 2544, 281, 312, 437, 264, 29805, 6807, 28471, 533, 575, 1219, 257, 7417, 510, 11, 364, 9045, 4745, 51342], "temperature": 0.0, "avg_logprob": -0.1751936921978941, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.00022334106324706227}, {"id": 79, "seek": 45804, "start": 477.6, "end": 482.6, "text": " gap between physical processes and subjective experience, at least our standard kinds of", "tokens": [51342, 7417, 1296, 4001, 7555, 293, 25972, 1752, 11, 412, 1935, 527, 3832, 3685, 295, 51592], "temperature": 0.0, "avg_logprob": -0.1751936921978941, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.00022334106324706227}, {"id": 80, "seek": 45804, "start": 482.6, "end": 487.84000000000003, "text": " explanation which work really well for the easy problems of behavior and so on. Don't", "tokens": [51592, 10835, 597, 589, 534, 731, 337, 264, 1858, 2740, 295, 5223, 293, 370, 322, 13, 1468, 380, 51854], "temperature": 0.0, "avg_logprob": -0.1751936921978941, "compression_ratio": 1.6205673758865249, "no_speech_prob": 0.00022334106324706227}, {"id": 81, "seek": 48784, "start": 487.88, "end": 494.88, "text": " obviously give you a connection to the subjective aspects of experience. There's been a vast", "tokens": [50366, 2745, 976, 291, 257, 4984, 281, 264, 25972, 7270, 295, 1752, 13, 821, 311, 668, 257, 8369, 50716], "temperature": 0.0, "avg_logprob": -0.14423871923376014, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00024528210633434355}, {"id": 82, "seek": 48784, "start": 495.88, "end": 500.76, "text": " amount of discussion of these things over, well for centuries really, but it's been particularly", "tokens": [50766, 2372, 295, 5017, 295, 613, 721, 670, 11, 731, 337, 13926, 534, 11, 457, 309, 311, 668, 4098, 51010], "temperature": 0.0, "avg_logprob": -0.14423871923376014, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00024528210633434355}, {"id": 83, "seek": 48784, "start": 500.76, "end": 507.76, "text": " active in recent decades, philosophers, scientists, all kinds of different views. Philosophically", "tokens": [51010, 4967, 294, 5162, 7878, 11, 36839, 11, 7708, 11, 439, 3685, 295, 819, 6809, 13, 31182, 5317, 984, 51360], "temperature": 0.0, "avg_logprob": -0.14423871923376014, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00024528210633434355}, {"id": 84, "seek": 48784, "start": 508.08, "end": 514.6, "text": " you can divide approaches to the hard problem into at least two classes. One is an approach", "tokens": [51376, 291, 393, 9845, 11587, 281, 264, 1152, 1154, 666, 412, 1935, 732, 5359, 13, 1485, 307, 364, 3109, 51702], "temperature": 0.0, "avg_logprob": -0.14423871923376014, "compression_ratio": 1.6059322033898304, "no_speech_prob": 0.00024528210633434355}, {"id": 85, "seek": 51460, "start": 514.6800000000001, "end": 518.9200000000001, "text": " on which consciousness is taken to be somehow irreducible and primitive. We can't explain", "tokens": [50368, 322, 597, 10081, 307, 2726, 281, 312, 6063, 16014, 769, 32128, 293, 28540, 13, 492, 393, 380, 2903, 50580], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 86, "seek": 51460, "start": 518.9200000000001, "end": 524.24, "text": " it in more basic physical terms, so take it as a kind of primitive and that might lead", "tokens": [50580, 309, 294, 544, 3875, 4001, 2115, 11, 370, 747, 309, 382, 257, 733, 295, 28540, 293, 300, 1062, 1477, 50846], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 87, "seek": 51460, "start": 524.24, "end": 528.08, "text": " to dualist theories of consciousness where consciousness is somehow separate from and", "tokens": [50846, 281, 11848, 468, 13667, 295, 10081, 689, 10081, 307, 6063, 4994, 490, 293, 51038], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 88, "seek": 51460, "start": 528.08, "end": 533.5600000000001, "text": " interacts with the brain. Recently very popular has been the class of panpsychist theories", "tokens": [51038, 43582, 365, 264, 3567, 13, 20072, 588, 3743, 575, 668, 264, 1508, 295, 2462, 1878, 16384, 468, 13667, 51312], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 89, "seek": 51460, "start": 533.5600000000001, "end": 538.88, "text": " of consciousness. I know Galen Strossom is here a while back talking, he very much favors", "tokens": [51312, 295, 10081, 13, 286, 458, 7336, 268, 8251, 772, 298, 307, 510, 257, 1339, 646, 1417, 11, 415, 588, 709, 40554, 51578], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 90, "seek": 51460, "start": 538.88, "end": 543.0, "text": " panpsychist theories where consciousness is something basic in the universe underlying", "tokens": [51578, 2462, 1878, 16384, 468, 13667, 689, 10081, 307, 746, 3875, 294, 264, 6445, 14217, 51784], "temperature": 0.0, "avg_logprob": -0.17060395591279381, "compression_ratio": 1.886120996441281, "no_speech_prob": 0.00490058958530426}, {"id": 91, "seek": 54300, "start": 543.04, "end": 549.04, "text": " matter and indeed there are idealist theories where consciousness underlies the whole universe,", "tokens": [50366, 1871, 293, 6451, 456, 366, 7157, 468, 13667, 689, 10081, 833, 24119, 264, 1379, 6445, 11, 50666], "temperature": 0.0, "avg_logprob": -0.19142417385153573, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.00039195784484036267}, {"id": 92, "seek": 54300, "start": 549.04, "end": 555.16, "text": " so these are all extremely speculative but interesting views that I've explored myself.", "tokens": [50666, 370, 613, 366, 439, 4664, 49415, 457, 1880, 6809, 300, 286, 600, 24016, 2059, 13, 50972], "temperature": 0.0, "avg_logprob": -0.19142417385153573, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.00039195784484036267}, {"id": 93, "seek": 54300, "start": 555.16, "end": 560.96, "text": " There are also reductionist theories of consciousness from functionalist approaches where consciousness", "tokens": [50972, 821, 366, 611, 11004, 468, 13667, 295, 10081, 490, 11745, 468, 11587, 689, 10081, 51262], "temperature": 0.0, "avg_logprob": -0.19142417385153573, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.00039195784484036267}, {"id": 94, "seek": 54300, "start": 560.96, "end": 567.96, "text": " is just basically taken to be a giant algorithm or computation. Biological approaches to consciousness,", "tokens": [51262, 307, 445, 1936, 2726, 281, 312, 257, 7410, 9284, 420, 24903, 13, 13007, 4383, 11587, 281, 10081, 11, 51612], "temperature": 0.0, "avg_logprob": -0.19142417385153573, "compression_ratio": 1.7612612612612613, "no_speech_prob": 0.00039195784484036267}, {"id": 95, "seek": 56796, "start": 568.0, "end": 574.0, "text": " my colleague Ned Block was here I know talking about neurobiology based approaches where", "tokens": [50366, 452, 13532, 31355, 17500, 390, 510, 286, 458, 1417, 466, 16499, 5614, 1793, 2361, 11587, 689, 50666], "temperature": 0.0, "avg_logprob": -0.16336607465557024, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0010147255379706621}, {"id": 96, "seek": 56796, "start": 574.0, "end": 579.44, "text": " it's not the algorithm that matters but the biology is implemented in and indeed the kind", "tokens": [50666, 309, 311, 406, 264, 9284, 300, 7001, 457, 264, 14956, 307, 12270, 294, 293, 6451, 264, 733, 50938], "temperature": 0.0, "avg_logprob": -0.16336607465557024, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0010147255379706621}, {"id": 97, "seek": 56796, "start": 579.44, "end": 584.72, "text": " of quantum approaches that people like Roger Penrose and Stuart Hemeroff have made famous.", "tokens": [50938, 295, 13018, 11587, 300, 561, 411, 17666, 10571, 37841, 293, 36236, 18568, 2032, 602, 362, 1027, 4618, 13, 51202], "temperature": 0.0, "avg_logprob": -0.16336607465557024, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0010147255379706621}, {"id": 98, "seek": 56796, "start": 584.72, "end": 588.96, "text": " I mean I think there's interesting things to say about all of these approaches. I think", "tokens": [51202, 286, 914, 286, 519, 456, 311, 1880, 721, 281, 584, 466, 439, 295, 613, 11587, 13, 286, 519, 51414], "temperature": 0.0, "avg_logprob": -0.16336607465557024, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0010147255379706621}, {"id": 99, "seek": 56796, "start": 588.96, "end": 594.4000000000001, "text": " that right now at least most of the reductionist approaches leave a gap but the non-reductionist", "tokens": [51414, 300, 558, 586, 412, 1935, 881, 295, 264, 11004, 468, 11587, 1856, 257, 7417, 457, 264, 2107, 12, 265, 40335, 468, 51686], "temperature": 0.0, "avg_logprob": -0.16336607465557024, "compression_ratio": 1.7132075471698114, "no_speech_prob": 0.0010147255379706621}, {"id": 100, "seek": 59440, "start": 594.4399999999999, "end": 601.4399999999999, "text": " approaches have other problems in seeing how it all works. Today I'm going to take a different", "tokens": [50366, 11587, 362, 661, 2740, 294, 2577, 577, 309, 439, 1985, 13, 2692, 286, 478, 516, 281, 747, 257, 819, 50716], "temperature": 0.0, "avg_logprob": -0.2258542450991544, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00109763047657907}, {"id": 101, "seek": 59440, "start": 601.4399999999999, "end": 608.4399999999999, "text": " kind of approach, this approach through the meta-problem. One way to motivate this is to", "tokens": [50716, 733, 295, 3109, 11, 341, 3109, 807, 264, 19616, 12, 47419, 13, 1485, 636, 281, 28497, 341, 307, 281, 51066], "temperature": 0.0, "avg_logprob": -0.2258542450991544, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00109763047657907}, {"id": 102, "seek": 59440, "start": 608.52, "end": 614.28, "text": " ask, I often get asked, okay you're a philosopher it's fine you get to think about these things", "tokens": [51070, 1029, 11, 286, 2049, 483, 2351, 11, 1392, 291, 434, 257, 29805, 309, 311, 2489, 291, 483, 281, 519, 466, 613, 721, 51358], "temperature": 0.0, "avg_logprob": -0.2258542450991544, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00109763047657907}, {"id": 103, "seek": 59440, "start": 614.28, "end": 620.28, "text": " like the hard problem of consciousness, how can I as a scientist or an engineer or an", "tokens": [51358, 411, 264, 1152, 1154, 295, 10081, 11, 577, 393, 286, 382, 257, 12662, 420, 364, 11403, 420, 364, 51658], "temperature": 0.0, "avg_logprob": -0.2258542450991544, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00109763047657907}, {"id": 104, "seek": 62028, "start": 620.28, "end": 627.28, "text": " AI researcher, how can I do something to kind of contribute to help get at this hard problem", "tokens": [50364, 7318, 21751, 11, 577, 393, 286, 360, 746, 281, 733, 295, 10586, 281, 854, 483, 412, 341, 1152, 1154, 50714], "temperature": 0.0, "avg_logprob": -0.15987954820905412, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0007531462470069528}, {"id": 105, "seek": 62028, "start": 627.4399999999999, "end": 631.68, "text": " of consciousness? Is this just a problem for philosophy? I mean for me to work on it say", "tokens": [50722, 295, 10081, 30, 1119, 341, 445, 257, 1154, 337, 10675, 30, 286, 914, 337, 385, 281, 589, 322, 309, 584, 50934], "temperature": 0.0, "avg_logprob": -0.15987954820905412, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0007531462470069528}, {"id": 106, "seek": 62028, "start": 631.68, "end": 637.68, "text": " as an AI researcher I need something I can operationalize, something I can work with", "tokens": [50934, 382, 364, 7318, 21751, 286, 643, 746, 286, 393, 16607, 1125, 11, 746, 286, 393, 589, 365, 51234], "temperature": 0.0, "avg_logprob": -0.15987954820905412, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0007531462470069528}, {"id": 107, "seek": 62028, "start": 637.68, "end": 644.18, "text": " and try to program and as it stands it's just not clear how to do that with the hard problem.", "tokens": [51234, 293, 853, 281, 1461, 293, 382, 309, 7382, 309, 311, 445, 406, 1850, 577, 281, 360, 300, 365, 264, 1152, 1154, 13, 51559], "temperature": 0.0, "avg_logprob": -0.15987954820905412, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0007531462470069528}, {"id": 108, "seek": 62028, "start": 644.18, "end": 648.3199999999999, "text": " I mean if you're a neuroscientist there are some things you can do. You can say work with", "tokens": [51559, 286, 914, 498, 291, 434, 257, 28813, 5412, 468, 456, 366, 512, 721, 291, 393, 360, 13, 509, 393, 584, 589, 365, 51766], "temperature": 0.0, "avg_logprob": -0.15987954820905412, "compression_ratio": 1.7857142857142858, "no_speech_prob": 0.0007531462470069528}, {"id": 109, "seek": 64832, "start": 648.32, "end": 653.5200000000001, "text": " humans and look at their brains and look for the neural correlates of consciousness, the", "tokens": [50364, 6255, 293, 574, 412, 641, 15442, 293, 574, 337, 264, 18161, 13983, 1024, 295, 10081, 11, 264, 50624], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 110, "seek": 64832, "start": 653.5200000000001, "end": 656.8000000000001, "text": " bits of the brain that go along with being conscious because at least with humans we", "tokens": [50624, 9239, 295, 264, 3567, 300, 352, 2051, 365, 885, 6648, 570, 412, 1935, 365, 6255, 321, 50788], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 111, "seek": 64832, "start": 656.8000000000001, "end": 661.44, "text": " can take as a background assumption, a plausible background assumption that the system is conscious.", "tokens": [50788, 393, 747, 382, 257, 3678, 15302, 11, 257, 39925, 3678, 15302, 300, 264, 1185, 307, 6648, 13, 51020], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 112, "seek": 64832, "start": 661.44, "end": 665.32, "text": " For AI we can't even do that, we don't know which AI systems we're working with or conscious,", "tokens": [51020, 1171, 7318, 321, 393, 380, 754, 360, 300, 11, 321, 500, 380, 458, 597, 7318, 3652, 321, 434, 1364, 365, 420, 6648, 11, 51214], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 113, "seek": 64832, "start": 665.32, "end": 671.32, "text": " we need some operational criteria. In AI we mostly work on modeling things like behavior", "tokens": [51214, 321, 643, 512, 16607, 11101, 13, 682, 7318, 321, 5240, 589, 322, 15983, 721, 411, 5223, 51514], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 114, "seek": 64832, "start": 671.32, "end": 676.24, "text": " and objective functioning for consciousness, those are the easy problems. So how does someone", "tokens": [51514, 293, 10024, 18483, 337, 10081, 11, 729, 366, 264, 1858, 2740, 13, 407, 577, 775, 1580, 51760], "temperature": 0.0, "avg_logprob": -0.1191468118619518, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.000587955117225647}, {"id": 115, "seek": 67624, "start": 676.3, "end": 682.8, "text": " coming from this perspective make a connection to the hard problem of consciousness? Well", "tokens": [50367, 1348, 490, 341, 4585, 652, 257, 4984, 281, 264, 1152, 1154, 295, 10081, 30, 1042, 50692], "temperature": 0.0, "avg_logprob": -0.12366720917937044, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0004043832595925778}, {"id": 116, "seek": 67624, "start": 682.8, "end": 689.16, "text": " one approach is to work on certain problems among the easy problems of behavior that shed", "tokens": [50692, 472, 3109, 307, 281, 589, 322, 1629, 2740, 3654, 264, 1858, 2740, 295, 5223, 300, 14951, 51010], "temperature": 0.0, "avg_logprob": -0.12366720917937044, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0004043832595925778}, {"id": 117, "seek": 67624, "start": 689.16, "end": 696.16, "text": " particular light on the hard problem and that's going to be the approach that I look at today.", "tokens": [51010, 1729, 1442, 322, 264, 1152, 1154, 293, 300, 311, 516, 281, 312, 264, 3109, 300, 286, 574, 412, 965, 13, 51360], "temperature": 0.0, "avg_logprob": -0.12366720917937044, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0004043832595925778}, {"id": 118, "seek": 67624, "start": 696.92, "end": 702.4, "text": " So the guiding, the key idea here is there are certain behavioral functions that seem", "tokens": [51398, 407, 264, 25061, 11, 264, 2141, 1558, 510, 307, 456, 366, 1629, 19124, 6828, 300, 1643, 51672], "temperature": 0.0, "avg_logprob": -0.12366720917937044, "compression_ratio": 1.6981132075471699, "no_speech_prob": 0.0004043832595925778}, {"id": 119, "seek": 70240, "start": 702.4399999999999, "end": 709.4399999999999, "text": " to have a particularly close relation to the hard problem of consciousness. In particular", "tokens": [50366, 281, 362, 257, 4098, 1998, 9721, 281, 264, 1152, 1154, 295, 10081, 13, 682, 1729, 50716], "temperature": 0.0, "avg_logprob": -0.17195520009080026, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.00040424414328299463}, {"id": 120, "seek": 70240, "start": 709.4399999999999, "end": 715.0799999999999, "text": " we say things about consciousness. We make what philosophers call phenomenal reports,", "tokens": [50716, 321, 584, 721, 466, 10081, 13, 492, 652, 437, 36839, 818, 17778, 7122, 11, 50998], "temperature": 0.0, "avg_logprob": -0.17195520009080026, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.00040424414328299463}, {"id": 121, "seek": 70240, "start": 715.0799999999999, "end": 722.0799999999999, "text": " verbal reports of conscious experiences. So I'll say things like I'm conscious, I'm", "tokens": [50998, 24781, 7122, 295, 6648, 5235, 13, 407, 286, 603, 584, 721, 411, 286, 478, 6648, 11, 286, 478, 51348], "temperature": 0.0, "avg_logprob": -0.17195520009080026, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.00040424414328299463}, {"id": 122, "seek": 70240, "start": 722.16, "end": 728.28, "text": " feeling pain right now and so on. Maybe the consciousness and the pain are subjective", "tokens": [51352, 2633, 1822, 558, 586, 293, 370, 322, 13, 2704, 264, 10081, 293, 264, 1822, 366, 25972, 51658], "temperature": 0.0, "avg_logprob": -0.17195520009080026, "compression_ratio": 1.7164179104477613, "no_speech_prob": 0.00040424414328299463}, {"id": 123, "seek": 72828, "start": 728.36, "end": 734.36, "text": " experiences but the reports, the utterances, I am conscious, well that's a bit of behavior.", "tokens": [50368, 5235, 457, 264, 7122, 11, 264, 17567, 2676, 11, 286, 669, 6648, 11, 731, 300, 311, 257, 857, 295, 5223, 13, 50668], "temperature": 0.0, "avg_logprob": -0.16549411186805138, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0011332141002640128}, {"id": 124, "seek": 72828, "start": 734.36, "end": 740.64, "text": " In principle explaining those is among the easy problems, objectively measurable response,", "tokens": [50668, 682, 8665, 13468, 729, 307, 3654, 264, 1858, 2740, 11, 46067, 43615, 4134, 11, 50982], "temperature": 0.0, "avg_logprob": -0.16549411186805138, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0011332141002640128}, {"id": 125, "seek": 72828, "start": 740.64, "end": 747.64, "text": " we can find a mechanism in the brain that produces it. And among our phenomenal reports", "tokens": [50982, 321, 393, 915, 257, 7513, 294, 264, 3567, 300, 14725, 309, 13, 400, 3654, 527, 17778, 7122, 51332], "temperature": 0.0, "avg_logprob": -0.16549411186805138, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0011332141002640128}, {"id": 126, "seek": 72828, "start": 747.64, "end": 753.8, "text": " there's this special class we can call the problem reports, reports expressing our sense", "tokens": [51332, 456, 311, 341, 2121, 1508, 321, 393, 818, 264, 1154, 7122, 11, 7122, 22171, 527, 2020, 51640], "temperature": 0.0, "avg_logprob": -0.16549411186805138, "compression_ratio": 1.669767441860465, "no_speech_prob": 0.0011332141002640128}, {"id": 127, "seek": 75380, "start": 753.8, "end": 758.7199999999999, "text": " that consciousness poses a problem. Now admittedly not everyone makes these reports but they", "tokens": [50364, 300, 10081, 26059, 257, 1154, 13, 823, 14920, 356, 406, 1518, 1669, 613, 7122, 457, 436, 50610], "temperature": 0.0, "avg_logprob": -0.11299356501153175, "compression_ratio": 1.7658730158730158, "no_speech_prob": 0.0006864743772894144}, {"id": 128, "seek": 75380, "start": 758.7199999999999, "end": 763.16, "text": " seem to be fairly widespread among, especially among philosophers and scientists thinking", "tokens": [50610, 1643, 281, 312, 6457, 22679, 3654, 11, 2318, 3654, 36839, 293, 7708, 1953, 50832], "temperature": 0.0, "avg_logprob": -0.11299356501153175, "compression_ratio": 1.7658730158730158, "no_speech_prob": 0.0006864743772894144}, {"id": 129, "seek": 75380, "start": 763.16, "end": 767.92, "text": " about these things but furthermore it's a sense that it's fairly easy to find and a", "tokens": [50832, 466, 613, 721, 457, 3052, 3138, 309, 311, 257, 2020, 300, 309, 311, 6457, 1858, 281, 915, 293, 257, 51070], "temperature": 0.0, "avg_logprob": -0.11299356501153175, "compression_ratio": 1.7658730158730158, "no_speech_prob": 0.0006864743772894144}, {"id": 130, "seek": 75380, "start": 767.92, "end": 774.0799999999999, "text": " very wide class of people who think about consciousness. People say things like there", "tokens": [51070, 588, 4874, 1508, 295, 561, 567, 519, 466, 10081, 13, 3432, 584, 721, 411, 456, 51378], "temperature": 0.0, "avg_logprob": -0.11299356501153175, "compression_ratio": 1.7658730158730158, "no_speech_prob": 0.0006864743772894144}, {"id": 131, "seek": 75380, "start": 774.0799999999999, "end": 779.92, "text": " is a problem of consciousness, a hard problem. On the face of it explaining behavior doesn't", "tokens": [51378, 307, 257, 1154, 295, 10081, 11, 257, 1152, 1154, 13, 1282, 264, 1851, 295, 309, 13468, 5223, 1177, 380, 51670], "temperature": 0.0, "avg_logprob": -0.11299356501153175, "compression_ratio": 1.7658730158730158, "no_speech_prob": 0.0006864743772894144}, {"id": 132, "seek": 77992, "start": 779.9599999999999, "end": 785.3199999999999, "text": " explain consciousness, consciousness seems non-physical, how would you ever explain the", "tokens": [50366, 2903, 10081, 11, 10081, 2544, 2107, 12, 950, 36280, 11, 577, 576, 291, 1562, 2903, 264, 50634], "temperature": 0.0, "avg_logprob": -0.15026557139861277, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.0001971136371139437}, {"id": 133, "seek": 77992, "start": 785.3199999999999, "end": 790.8399999999999, "text": " subjective experience of red and so on. It's an objective fact about us, at least about", "tokens": [50634, 25972, 1752, 295, 2182, 293, 370, 322, 13, 467, 311, 364, 10024, 1186, 466, 505, 11, 412, 1935, 466, 50910], "temperature": 0.0, "avg_logprob": -0.15026557139861277, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.0001971136371139437}, {"id": 134, "seek": 77992, "start": 790.8399999999999, "end": 797.8399999999999, "text": " some of us, that we make those reports and that's the fact about human behavior.", "tokens": [50910, 512, 295, 505, 11, 300, 321, 652, 729, 7122, 293, 300, 311, 264, 1186, 466, 1952, 5223, 13, 51260], "temperature": 0.0, "avg_logprob": -0.15026557139861277, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.0001971136371139437}, {"id": 135, "seek": 77992, "start": 799.4399999999999, "end": 805.9399999999999, "text": " So the matter problem of consciousness then at a second approximation is roughly the problem", "tokens": [51340, 407, 264, 1871, 1154, 295, 10081, 550, 412, 257, 1150, 28023, 307, 9810, 264, 1154, 51665], "temperature": 0.0, "avg_logprob": -0.15026557139861277, "compression_ratio": 1.6859903381642511, "no_speech_prob": 0.0001971136371139437}, {"id": 136, "seek": 80594, "start": 805.94, "end": 812.46, "text": " of explaining these problem reports, explaining you might say the conviction that we're conscious", "tokens": [50364, 295, 13468, 613, 1154, 7122, 11, 13468, 291, 1062, 584, 264, 24837, 300, 321, 434, 6648, 50690], "temperature": 0.0, "avg_logprob": -0.16297391381594215, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.00011588366032810882}, {"id": 137, "seek": 80594, "start": 812.46, "end": 817.22, "text": " and that consciousness is puzzling. And what's nice about this is that although the hard", "tokens": [50690, 293, 300, 10081, 307, 18741, 1688, 13, 400, 437, 311, 1481, 466, 341, 307, 300, 4878, 264, 1152, 50928], "temperature": 0.0, "avg_logprob": -0.16297391381594215, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.00011588366032810882}, {"id": 138, "seek": 80594, "start": 817.22, "end": 820.82, "text": " problem is this, you know, airy-fairy problem about subjective experience that's hard to", "tokens": [50928, 1154, 307, 341, 11, 291, 458, 11, 1988, 88, 12, 69, 47413, 1154, 466, 25972, 1752, 300, 311, 1152, 281, 51108], "temperature": 0.0, "avg_logprob": -0.16297391381594215, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.00011588366032810882}, {"id": 139, "seek": 80594, "start": 820.82, "end": 827.0200000000001, "text": " pin down, this is a puzzle ultimately about behavior. So this is an easy problem, one", "tokens": [51108, 5447, 760, 11, 341, 307, 257, 12805, 6284, 466, 5223, 13, 407, 341, 307, 364, 1858, 1154, 11, 472, 51418], "temperature": 0.0, "avg_logprob": -0.16297391381594215, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.00011588366032810882}, {"id": 140, "seek": 80594, "start": 827.0200000000001, "end": 831.5, "text": " that ought to be open to those standard methods of explanation in the cognitive and brain", "tokens": [51418, 300, 13416, 281, 312, 1269, 281, 729, 3832, 7150, 295, 10835, 294, 264, 15605, 293, 3567, 51642], "temperature": 0.0, "avg_logprob": -0.16297391381594215, "compression_ratio": 1.796812749003984, "no_speech_prob": 0.00011588366032810882}, {"id": 141, "seek": 83150, "start": 832.46, "end": 839.46, "text": " sciences. So there's a research program. There's a research program here. So I like", "tokens": [50412, 17677, 13, 407, 456, 311, 257, 2132, 1461, 13, 821, 311, 257, 2132, 1461, 510, 13, 407, 286, 411, 50762], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 142, "seek": 83150, "start": 839.46, "end": 842.14, "text": " to think of the matter problem as something that can play that role. I talked about earlier", "tokens": [50762, 281, 519, 295, 264, 1871, 1154, 382, 746, 300, 393, 862, 300, 3090, 13, 286, 2825, 466, 3071, 50896], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 143, "seek": 83150, "start": 842.14, "end": 846.06, "text": " if you say an AI researcher thinking about this. The matter problem is an easy problem,", "tokens": [50896, 498, 291, 584, 364, 7318, 21751, 1953, 466, 341, 13, 440, 1871, 1154, 307, 364, 1858, 1154, 11, 51092], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 144, "seek": 83150, "start": 846.06, "end": 850.54, "text": " a problem about behavior that's closely tied to the hard problem. So it's something we", "tokens": [51092, 257, 1154, 466, 5223, 300, 311, 8185, 9601, 281, 264, 1152, 1154, 13, 407, 309, 311, 746, 321, 51316], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 145, "seek": 83150, "start": 850.54, "end": 854.74, "text": " might be able to make some progress on using standard methods of thinking about algorithms", "tokens": [51316, 1062, 312, 1075, 281, 652, 512, 4205, 322, 1228, 3832, 7150, 295, 1953, 466, 14642, 51526], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 146, "seek": 83150, "start": 854.74, "end": 859.94, "text": " and computations or thinking about brain processes and behavior while still shedding", "tokens": [51526, 293, 2807, 763, 420, 1953, 466, 3567, 7555, 293, 5223, 1339, 920, 49934, 51786], "temperature": 0.0, "avg_logprob": -0.15788950712784477, "compression_ratio": 1.962686567164179, "no_speech_prob": 0.00031488711829297245}, {"id": 147, "seek": 85994, "start": 859.94, "end": 863.98, "text": " some light, at least indirectly on the hard problem. It's more tractable than the hard", "tokens": [50364, 512, 1442, 11, 412, 1935, 37779, 322, 264, 1152, 1154, 13, 467, 311, 544, 24207, 712, 813, 264, 1152, 50566], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 148, "seek": 85994, "start": 863.98, "end": 868.22, "text": " problem but solving it ought to shed light on the hard problem. And today I'm just going", "tokens": [50566, 1154, 457, 12606, 309, 13416, 281, 14951, 1442, 322, 264, 1152, 1154, 13, 400, 965, 286, 478, 445, 516, 50778], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 149, "seek": 85994, "start": 868.22, "end": 872.5, "text": " to kind of lay out the research program and talk about some ways in which it might potentially", "tokens": [50778, 281, 733, 295, 2360, 484, 264, 2132, 1461, 293, 751, 466, 512, 2098, 294, 597, 309, 1062, 7263, 50992], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 150, "seek": 85994, "start": 872.5, "end": 878.82, "text": " shed some light. This is interesting to a philosopher because it looks like an instance", "tokens": [50992, 14951, 512, 1442, 13, 639, 307, 1880, 281, 257, 29805, 570, 309, 1542, 411, 364, 5197, 51308], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 151, "seek": 85994, "start": 878.82, "end": 882.94, "text": " of what people sometimes call genealogical analysis. It goes back to Friedrich Nietzsche", "tokens": [51308, 295, 437, 561, 2171, 818, 12186, 44434, 804, 5215, 13, 467, 1709, 646, 281, 17605, 10794, 36583, 89, 12287, 51514], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 152, "seek": 85994, "start": 882.94, "end": 887.7800000000001, "text": " on the genealogy of morals. Instead of thinking about what's good or bad, let's look at where", "tokens": [51514, 322, 264, 12186, 304, 7794, 295, 46849, 13, 7156, 295, 1953, 466, 437, 311, 665, 420, 1578, 11, 718, 311, 574, 412, 689, 51756], "temperature": 0.0, "avg_logprob": -0.11436353623867035, "compression_ratio": 1.7395498392282958, "no_speech_prob": 0.0014999255072325468}, {"id": 153, "seek": 88778, "start": 887.78, "end": 894.66, "text": " our sense of good or bad came from, the genealogy of it all in evolution or in culture or in", "tokens": [50364, 527, 2020, 295, 665, 420, 1578, 1361, 490, 11, 264, 12186, 304, 7794, 295, 309, 439, 294, 9303, 420, 294, 3713, 420, 294, 50708], "temperature": 0.0, "avg_logprob": -0.11954482396443684, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.007571192923933268}, {"id": 154, "seek": 88778, "start": 894.66, "end": 900.3399999999999, "text": " religion. And people take a genealogical approach to God. Instead of thinking about does God", "tokens": [50708, 7561, 13, 400, 561, 747, 257, 12186, 44434, 804, 3109, 281, 1265, 13, 7156, 295, 1953, 466, 775, 1265, 50992], "temperature": 0.0, "avg_logprob": -0.11954482396443684, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.007571192923933268}, {"id": 155, "seek": 88778, "start": 900.3399999999999, "end": 904.86, "text": " exist or not, let's look at where our belief in God came from. Maybe there's some evolutionary", "tokens": [50992, 2514, 420, 406, 11, 718, 311, 574, 412, 689, 527, 7107, 294, 1265, 1361, 490, 13, 2704, 456, 311, 512, 27567, 51218], "temperature": 0.0, "avg_logprob": -0.11954482396443684, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.007571192923933268}, {"id": 156, "seek": 88778, "start": 904.86, "end": 910.78, "text": " reason for why people believe in God. This often leads, not always, but often leads to", "tokens": [51218, 1778, 337, 983, 561, 1697, 294, 1265, 13, 639, 2049, 6689, 11, 406, 1009, 11, 457, 2049, 6689, 281, 51514], "temperature": 0.0, "avg_logprob": -0.11954482396443684, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.007571192923933268}, {"id": 157, "seek": 88778, "start": 910.78, "end": 916.5, "text": " a kind of debunking of our beliefs about those domains. Explain why we believe in God in", "tokens": [51514, 257, 733, 295, 3001, 3197, 278, 295, 527, 13585, 466, 729, 25514, 13, 39574, 983, 321, 1697, 294, 1265, 294, 51800], "temperature": 0.0, "avg_logprob": -0.11954482396443684, "compression_ratio": 1.7207547169811321, "no_speech_prob": 0.007571192923933268}, {"id": 158, "seek": 91650, "start": 916.5, "end": 922.5, "text": " evolutionary terms. No need for the God hypothesis anymore. Explain our moral beliefs in say", "tokens": [50364, 27567, 2115, 13, 883, 643, 337, 264, 1265, 17291, 3602, 13, 39574, 527, 9723, 13585, 294, 584, 50664], "temperature": 0.0, "avg_logprob": -0.12634863024172577, "compression_ratio": 1.76171875, "no_speech_prob": 0.00023770307598169893}, {"id": 159, "seek": 91650, "start": 922.5, "end": 928.14, "text": " evolutionary terms. Maybe no need to take morality quite so seriously. So some people", "tokens": [50664, 27567, 2115, 13, 2704, 572, 643, 281, 747, 29106, 1596, 370, 6638, 13, 407, 512, 561, 50946], "temperature": 0.0, "avg_logprob": -0.12634863024172577, "compression_ratio": 1.76171875, "no_speech_prob": 0.00023770307598169893}, {"id": 160, "seek": 91650, "start": 928.14, "end": 933.02, "text": " at least are inclined to take an approach like this with consciousness too. If you think", "tokens": [50946, 412, 1935, 366, 28173, 281, 747, 364, 3109, 411, 341, 365, 10081, 886, 13, 759, 291, 519, 51190], "temperature": 0.0, "avg_logprob": -0.12634863024172577, "compression_ratio": 1.76171875, "no_speech_prob": 0.00023770307598169893}, {"id": 161, "seek": 91650, "start": 933.02, "end": 937.66, "text": " about the meta problem, explaining our beliefs about consciousness, that might ultimately", "tokens": [51190, 466, 264, 19616, 1154, 11, 13468, 527, 13585, 466, 10081, 11, 300, 1062, 6284, 51422], "temperature": 0.0, "avg_logprob": -0.12634863024172577, "compression_ratio": 1.76171875, "no_speech_prob": 0.00023770307598169893}, {"id": 162, "seek": 91650, "start": 937.66, "end": 945.22, "text": " debunk our beliefs about consciousness. This leads to a philosophical view which has recently", "tokens": [51422, 3001, 3197, 527, 13585, 466, 10081, 13, 639, 6689, 281, 257, 25066, 1910, 597, 575, 3938, 51800], "temperature": 0.0, "avg_logprob": -0.12634863024172577, "compression_ratio": 1.76171875, "no_speech_prob": 0.00023770307598169893}, {"id": 163, "seek": 94522, "start": 945.26, "end": 951.34, "text": " attracted a lot of interest, a philosophical view called illusionism, which is the view", "tokens": [50366, 15912, 257, 688, 295, 1179, 11, 257, 25066, 1910, 1219, 18854, 1434, 11, 597, 307, 264, 1910, 50670], "temperature": 0.0, "avg_logprob": -0.17942164103190103, "compression_ratio": 1.839572192513369, "no_speech_prob": 0.0007785680936649442}, {"id": 164, "seek": 94522, "start": 951.34, "end": 957.78, "text": " that consciousness itself is an illusion or maybe that the problem of consciousness is", "tokens": [50670, 300, 10081, 2564, 307, 364, 18854, 420, 1310, 300, 264, 1154, 295, 10081, 307, 50992], "temperature": 0.0, "avg_logprob": -0.17942164103190103, "compression_ratio": 1.839572192513369, "no_speech_prob": 0.0007785680936649442}, {"id": 165, "seek": 94522, "start": 957.78, "end": 965.14, "text": " an illusion. Explain the illusion and we dissolve the problem. In terms of the meta", "tokens": [50992, 364, 18854, 13, 39574, 264, 18854, 293, 321, 30150, 264, 1154, 13, 682, 2115, 295, 264, 19616, 51360], "temperature": 0.0, "avg_logprob": -0.17942164103190103, "compression_ratio": 1.839572192513369, "no_speech_prob": 0.0007785680936649442}, {"id": 166, "seek": 94522, "start": 965.14, "end": 970.98, "text": " problem that view roughly comes to, solve the meta problem, it will dissolve the hard", "tokens": [51360, 1154, 300, 1910, 9810, 1487, 281, 11, 5039, 264, 19616, 1154, 11, 309, 486, 30150, 264, 1152, 51652], "temperature": 0.0, "avg_logprob": -0.17942164103190103, "compression_ratio": 1.839572192513369, "no_speech_prob": 0.0007785680936649442}, {"id": 167, "seek": 97098, "start": 971.02, "end": 975.4200000000001, "text": " problem. Explain why it is that we say all these things about consciousness. While we", "tokens": [50366, 1154, 13, 39574, 983, 309, 307, 300, 321, 584, 439, 613, 721, 466, 10081, 13, 3987, 321, 50586], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 168, "seek": 97098, "start": 975.4200000000001, "end": 980.94, "text": " say I am conscious, while we say consciousness is puzzling, if you can explain all that in", "tokens": [50586, 584, 286, 669, 6648, 11, 1339, 321, 584, 10081, 307, 18741, 1688, 11, 498, 291, 393, 2903, 439, 300, 294, 50862], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 169, "seek": 97098, "start": 980.94, "end": 987.1, "text": " say algorithmic terms, then you'll remove the underlying problem because you'll have", "tokens": [50862, 584, 9284, 299, 2115, 11, 550, 291, 603, 4159, 264, 14217, 1154, 570, 291, 603, 362, 51170], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 170, "seek": 97098, "start": 987.1, "end": 991.5, "text": " explained why we're puzzled in the first place. Actually, walking over here today, I noticed", "tokens": [51170, 8825, 983, 321, 434, 18741, 1493, 294, 264, 700, 1081, 13, 5135, 11, 4494, 670, 510, 965, 11, 286, 5694, 51390], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 171, "seek": 97098, "start": 991.5, "end": 996.14, "text": " that just a couple of blocks away, we have the Museum of Illusions. So I'm going to check", "tokens": [51390, 300, 445, 257, 1916, 295, 8474, 1314, 11, 321, 362, 264, 10967, 295, 10597, 27255, 13, 407, 286, 478, 516, 281, 1520, 51622], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 172, "seek": 97098, "start": 996.14, "end": 1000.9, "text": " that out later on. But if illusionism is right and added to all those perceptual illusions,", "tokens": [51622, 300, 484, 1780, 322, 13, 583, 498, 18854, 1434, 307, 558, 293, 3869, 281, 439, 729, 43276, 901, 49836, 11, 51860], "temperature": 0.0, "avg_logprob": -0.1645069122314453, "compression_ratio": 1.7402597402597402, "no_speech_prob": 0.003270447952672839}, {"id": 173, "seek": 100090, "start": 1001.26, "end": 1006.22, "text": " it's going to be the problem of consciousness itself. It's roughly an illusion thrown up", "tokens": [50382, 309, 311, 516, 281, 312, 264, 1154, 295, 10081, 2564, 13, 467, 311, 9810, 364, 18854, 11732, 493, 50630], "temperature": 0.0, "avg_logprob": -0.14969033115314986, "compression_ratio": 1.7126436781609196, "no_speech_prob": 0.00026087352307513356}, {"id": 174, "seek": 100090, "start": 1006.22, "end": 1011.6999999999999, "text": " by having a weird self-model with a certain kind of algorithm that attributes to ourselves", "tokens": [50630, 538, 1419, 257, 3657, 2698, 12, 8014, 338, 365, 257, 1629, 733, 295, 9284, 300, 17212, 281, 4175, 50904], "temperature": 0.0, "avg_logprob": -0.14969033115314986, "compression_ratio": 1.7126436781609196, "no_speech_prob": 0.00026087352307513356}, {"id": 175, "seek": 100090, "start": 1011.6999999999999, "end": 1018.6999999999999, "text": " special properties that we don't have. So one line on the meta problem is the illusionist", "tokens": [50904, 2121, 7221, 300, 321, 500, 380, 362, 13, 407, 472, 1622, 322, 264, 19616, 1154, 307, 264, 18854, 468, 51254], "temperature": 0.0, "avg_logprob": -0.14969033115314986, "compression_ratio": 1.7126436781609196, "no_speech_prob": 0.00026087352307513356}, {"id": 176, "seek": 100090, "start": 1018.6999999999999, "end": 1023.8199999999999, "text": " line. Solve the meta problem, you'll get to treat consciousness as an illusion. That's", "tokens": [51254, 1622, 13, 7026, 303, 264, 19616, 1154, 11, 291, 603, 483, 281, 2387, 10081, 382, 364, 18854, 13, 663, 311, 51510], "temperature": 0.0, "avg_logprob": -0.14969033115314986, "compression_ratio": 1.7126436781609196, "no_speech_prob": 0.00026087352307513356}, {"id": 177, "seek": 100090, "start": 1023.8199999999999, "end": 1029.54, "text": " actually a view that has many antecedents in the history of philosophy one way or another.", "tokens": [51510, 767, 257, 1910, 300, 575, 867, 23411, 1232, 791, 294, 264, 2503, 295, 10675, 472, 636, 420, 1071, 13, 51796], "temperature": 0.0, "avg_logprob": -0.14969033115314986, "compression_ratio": 1.7126436781609196, "no_speech_prob": 0.00026087352307513356}, {"id": 178, "seek": 102954, "start": 1029.58, "end": 1033.74, "text": " Emmanuel Kahn, in his great critique of pure reason, had a section where he talked about", "tokens": [50366, 44421, 591, 12140, 11, 294, 702, 869, 25673, 295, 6075, 1778, 11, 632, 257, 3541, 689, 415, 2825, 466, 50574], "temperature": 0.0, "avg_logprob": -0.2139932507666472, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.0012049461947754025}, {"id": 179, "seek": 102954, "start": 1033.74, "end": 1041.02, "text": " the self or the soul as a transcendental illusion. We seem to have this indivisible soul, but", "tokens": [50574, 264, 2698, 420, 264, 5133, 382, 257, 28535, 14533, 18854, 13, 492, 1643, 281, 362, 341, 1016, 592, 271, 964, 5133, 11, 457, 50938], "temperature": 0.0, "avg_logprob": -0.2139932507666472, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.0012049461947754025}, {"id": 180, "seek": 102954, "start": 1041.02, "end": 1045.74, "text": " that's a kind of illusion thrown up by our cognitive processes. The Australian philosophers", "tokens": [50938, 300, 311, 257, 733, 295, 18854, 11732, 493, 538, 527, 15605, 7555, 13, 440, 13337, 36839, 51174], "temperature": 0.0, "avg_logprob": -0.2139932507666472, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.0012049461947754025}, {"id": 181, "seek": 102954, "start": 1045.74, "end": 1051.86, "text": " are on place, and David Armstrong had versions of this that I might touch on a bit later.", "tokens": [51174, 366, 322, 1081, 11, 293, 4389, 36100, 632, 9606, 295, 341, 300, 286, 1062, 2557, 322, 257, 857, 1780, 13, 51480], "temperature": 0.0, "avg_logprob": -0.2139932507666472, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.0012049461947754025}, {"id": 182, "seek": 102954, "start": 1051.86, "end": 1058.62, "text": " Daniel Dennett, leading reductionist thinker about consciousness, has been pushing for the", "tokens": [51480, 8033, 19027, 3093, 11, 5775, 11004, 468, 519, 260, 466, 10081, 11, 575, 668, 7380, 337, 264, 51818], "temperature": 0.0, "avg_logprob": -0.2139932507666472, "compression_ratio": 1.5964912280701755, "no_speech_prob": 0.0012049461947754025}, {"id": 183, "seek": 105862, "start": 1058.6599999999999, "end": 1063.9399999999998, "text": " last couple of decades the idea that consciousness involves a certain kind of user illusion,", "tokens": [50366, 1036, 1916, 295, 7878, 264, 1558, 300, 10081, 11626, 257, 1629, 733, 295, 4195, 18854, 11, 50630], "temperature": 0.0, "avg_logprob": -0.14557338247493823, "compression_ratio": 1.8155737704918034, "no_speech_prob": 0.00027777598006650805}, {"id": 184, "seek": 105862, "start": 1063.9399999999998, "end": 1070.1399999999999, "text": " and most recently the British philosopher Keith Frankish has been really pushing illusionism", "tokens": [50630, 293, 881, 3938, 264, 6221, 29805, 20613, 6823, 742, 575, 668, 534, 7380, 18854, 1434, 50940], "temperature": 0.0, "avg_logprob": -0.14557338247493823, "compression_ratio": 1.8155737704918034, "no_speech_prob": 0.00027777598006650805}, {"id": 185, "seek": 105862, "start": 1070.1399999999999, "end": 1077.1399999999999, "text": " as a theory of consciousness. Here's a book centering around a paper by Keith Frankish", "tokens": [50940, 382, 257, 5261, 295, 10081, 13, 1692, 311, 257, 1446, 1489, 1794, 926, 257, 3035, 538, 20613, 6823, 742, 51290], "temperature": 0.0, "avg_logprob": -0.14557338247493823, "compression_ratio": 1.8155737704918034, "no_speech_prob": 0.00027777598006650805}, {"id": 186, "seek": 105862, "start": 1078.1, "end": 1083.58, "text": " on illusionism as a theory of consciousness that I recommend to you. So one way to go", "tokens": [51338, 322, 18854, 1434, 382, 257, 5261, 295, 10081, 300, 286, 2748, 281, 291, 13, 407, 472, 636, 281, 352, 51612], "temperature": 0.0, "avg_logprob": -0.14557338247493823, "compression_ratio": 1.8155737704918034, "no_speech_prob": 0.00027777598006650805}, {"id": 187, "seek": 105862, "start": 1083.58, "end": 1087.58, "text": " with the meta problem is the direction of illusionism, but one nice thing about many", "tokens": [51612, 365, 264, 19616, 1154, 307, 264, 3513, 295, 18854, 1434, 11, 457, 472, 1481, 551, 466, 867, 51812], "temperature": 0.0, "avg_logprob": -0.14557338247493823, "compression_ratio": 1.8155737704918034, "no_speech_prob": 0.00027777598006650805}, {"id": 188, "seek": 108758, "start": 1087.62, "end": 1092.34, "text": " people find illusionism completely unbelievable. They find you, how could it be that consciousness", "tokens": [50366, 561, 915, 18854, 1434, 2584, 16605, 13, 814, 915, 291, 11, 577, 727, 309, 312, 300, 10081, 50602], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 189, "seek": 108758, "start": 1092.34, "end": 1096.8999999999999, "text": " is an illusion? Look, we just have the subjective experience, it's a datum about our nature,", "tokens": [50602, 307, 364, 18854, 30, 2053, 11, 321, 445, 362, 264, 25972, 1752, 11, 309, 311, 257, 1137, 449, 466, 527, 3687, 11, 50830], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 190, "seek": 108758, "start": 1096.8999999999999, "end": 1102.46, "text": " and I confess I've got some sympathy with that reaction, so I'm not an illusionist myself.", "tokens": [50830, 293, 286, 19367, 286, 600, 658, 512, 33240, 365, 300, 5480, 11, 370, 286, 478, 406, 364, 18854, 468, 2059, 13, 51108], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 191, "seek": 108758, "start": 1102.46, "end": 1106.78, "text": " I'm a realist about consciousness in the philosopher's sense where a realist about", "tokens": [51108, 286, 478, 257, 957, 468, 466, 10081, 294, 264, 29805, 311, 2020, 689, 257, 957, 468, 466, 51324], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 192, "seek": 108758, "start": 1106.78, "end": 1112.26, "text": " something is someone who believes that thing is real. I think consciousness is real, I", "tokens": [51324, 746, 307, 1580, 567, 12307, 300, 551, 307, 957, 13, 286, 519, 10081, 307, 957, 11, 286, 51598], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 193, "seek": 108758, "start": 1112.26, "end": 1117.26, "text": " think it's not an illusion, I think that solving the meta problem does not dissolve", "tokens": [51598, 519, 309, 311, 406, 364, 18854, 11, 286, 519, 300, 12606, 264, 19616, 1154, 775, 406, 30150, 51848], "temperature": 0.0, "avg_logprob": -0.15718695068359376, "compression_ratio": 1.8939929328621907, "no_speech_prob": 0.00044334158883430064}, {"id": 194, "seek": 111726, "start": 1117.26, "end": 1120.54, "text": " the hard problem, but the nice thing about the meta problem is you can proceed on it", "tokens": [50364, 264, 1152, 1154, 11, 457, 264, 1481, 551, 466, 264, 19616, 1154, 307, 291, 393, 8991, 322, 309, 50528], "temperature": 0.0, "avg_logprob": -0.15226118087768556, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.00010883576760534197}, {"id": 195, "seek": 111726, "start": 1120.54, "end": 1126.74, "text": " to some extent at least in initial neutrality on that question, is consciousness real or", "tokens": [50528, 281, 512, 8396, 412, 1935, 294, 5883, 39913, 1860, 322, 300, 1168, 11, 307, 10081, 957, 420, 50838], "temperature": 0.0, "avg_logprob": -0.15226118087768556, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.00010883576760534197}, {"id": 196, "seek": 111726, "start": 1126.74, "end": 1132.62, "text": " is it an illusion? It's a basic problem about our objective functioning of these reports.", "tokens": [50838, 307, 309, 364, 18854, 30, 467, 311, 257, 3875, 1154, 466, 527, 10024, 18483, 295, 613, 7122, 13, 51132], "temperature": 0.0, "avg_logprob": -0.15226118087768556, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.00010883576760534197}, {"id": 197, "seek": 111726, "start": 1132.62, "end": 1139.62, "text": " What explains those? There's a neutral research program here that both realists, illusionists,", "tokens": [51132, 708, 13948, 729, 30, 821, 311, 257, 10598, 2132, 1461, 510, 300, 1293, 957, 1751, 11, 18854, 1751, 11, 51482], "temperature": 0.0, "avg_logprob": -0.15226118087768556, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.00010883576760534197}, {"id": 198, "seek": 111726, "start": 1140.02, "end": 1143.2, "text": " people of all kinds of different views of consciousness can explain, and then we can", "tokens": [51502, 561, 295, 439, 3685, 295, 819, 6809, 295, 10081, 393, 2903, 11, 293, 550, 321, 393, 51661], "temperature": 0.0, "avg_logprob": -0.15226118087768556, "compression_ratio": 1.7170542635658914, "no_speech_prob": 0.00010883576760534197}, {"id": 199, "seek": 114320, "start": 1143.2, "end": 1149.32, "text": " come back and look at the philosophical consequences. Well, I'm not an illusionist, I think consciousness", "tokens": [50364, 808, 646, 293, 574, 412, 264, 25066, 10098, 13, 1042, 11, 286, 478, 406, 364, 18854, 468, 11, 286, 519, 10081, 50670], "temperature": 0.0, "avg_logprob": -0.17265601850982404, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0006870063953101635}, {"id": 200, "seek": 114320, "start": 1149.32, "end": 1154.44, "text": " is real. I've got to say, I do feel the temptation of illusionism, I find it really intriguing", "tokens": [50670, 307, 957, 13, 286, 600, 658, 281, 584, 11, 286, 360, 841, 264, 30423, 295, 18854, 1434, 11, 286, 915, 309, 534, 32503, 50926], "temperature": 0.0, "avg_logprob": -0.17265601850982404, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0006870063953101635}, {"id": 201, "seek": 114320, "start": 1154.44, "end": 1160.48, "text": " and in some ways attractive to you, just fundamentally unbelievable. Nevertheless, I think that the", "tokens": [50926, 293, 294, 512, 2098, 12609, 281, 291, 11, 445, 17879, 16605, 13, 26554, 11, 286, 519, 300, 264, 51228], "temperature": 0.0, "avg_logprob": -0.17265601850982404, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0006870063953101635}, {"id": 202, "seek": 114320, "start": 1160.48, "end": 1166.96, "text": " meta problem should be a tractable problem. Solving it will shed, at the very least, will", "tokens": [51228, 19616, 1154, 820, 312, 257, 24207, 712, 1154, 13, 7026, 798, 309, 486, 14951, 11, 412, 264, 588, 1935, 11, 486, 51552], "temperature": 0.0, "avg_logprob": -0.17265601850982404, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0006870063953101635}, {"id": 203, "seek": 114320, "start": 1166.96, "end": 1171.72, "text": " shed much light on the hard problem of consciousness, even if it doesn't solve it. If you can explain", "tokens": [51552, 14951, 709, 1442, 322, 264, 1152, 1154, 295, 10081, 11, 754, 498, 309, 1177, 380, 5039, 309, 13, 759, 291, 393, 2903, 51790], "temperature": 0.0, "avg_logprob": -0.17265601850982404, "compression_ratio": 1.7083333333333333, "no_speech_prob": 0.0006870063953101635}, {"id": 204, "seek": 117172, "start": 1171.76, "end": 1176.48, "text": " our conviction that we're conscious, somehow the source, the roots of our conviction that", "tokens": [50366, 527, 24837, 300, 321, 434, 6648, 11, 6063, 264, 4009, 11, 264, 10669, 295, 527, 24837, 300, 50602], "temperature": 0.0, "avg_logprob": -0.15182291731542472, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00020333382417447865}, {"id": 205, "seek": 117172, "start": 1176.48, "end": 1181.28, "text": " we're conscious must have something to do with consciousness, especially if consciousness", "tokens": [50602, 321, 434, 6648, 1633, 362, 746, 281, 360, 365, 10081, 11, 2318, 498, 10081, 50842], "temperature": 0.0, "avg_logprob": -0.15182291731542472, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00020333382417447865}, {"id": 206, "seek": 117172, "start": 1181.28, "end": 1187.72, "text": " is real. I think it's very much a good research program for people to explain. Then I'll move", "tokens": [50842, 307, 957, 13, 286, 519, 309, 311, 588, 709, 257, 665, 2132, 1461, 337, 561, 281, 2903, 13, 1396, 286, 603, 1286, 51164], "temperature": 0.0, "avg_logprob": -0.15182291731542472, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00020333382417447865}, {"id": 207, "seek": 117172, "start": 1187.72, "end": 1193.88, "text": " on now to just outlining the research program a little bit more and then talk a bit about", "tokens": [51164, 322, 586, 281, 445, 484, 31079, 264, 2132, 1461, 257, 707, 857, 544, 293, 550, 751, 257, 857, 466, 51472], "temperature": 0.0, "avg_logprob": -0.15182291731542472, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00020333382417447865}, {"id": 208, "seek": 117172, "start": 1193.88, "end": 1199.1200000000001, "text": " potential solutions and on impact on theories of consciousness before wrapping up with just", "tokens": [51472, 3995, 6547, 293, 322, 2712, 322, 13667, 295, 10081, 949, 21993, 493, 365, 445, 51734], "temperature": 0.0, "avg_logprob": -0.15182291731542472, "compression_ratio": 1.8421052631578947, "no_speech_prob": 0.00020333382417447865}, {"id": 209, "seek": 119912, "start": 1199.1999999999998, "end": 1206.1999999999998, "text": " a little bit more about illusionism. This meta problem, which I've been pushing recently,", "tokens": [50368, 257, 707, 857, 544, 466, 18854, 1434, 13, 639, 19616, 1154, 11, 597, 286, 600, 668, 7380, 3938, 11, 50718], "temperature": 0.0, "avg_logprob": -0.17241266722320228, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00034577507176436484}, {"id": 210, "seek": 119912, "start": 1206.9199999999998, "end": 1212.9199999999998, "text": " opens up a tractable empirical research program for everyone, reductionists, non-reductionists,", "tokens": [50754, 9870, 493, 257, 24207, 712, 31886, 2132, 1461, 337, 1518, 11, 11004, 1751, 11, 2107, 12, 265, 40335, 1751, 11, 51054], "temperature": 0.0, "avg_logprob": -0.17241266722320228, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00034577507176436484}, {"id": 211, "seek": 119912, "start": 1212.9199999999998, "end": 1218.4199999999998, "text": " illusionists, non-illusionists. We can try to solve it and then think about the philosophical", "tokens": [51054, 18854, 1751, 11, 2107, 12, 373, 5704, 1751, 13, 492, 393, 853, 281, 5039, 309, 293, 550, 519, 466, 264, 25066, 51329], "temperature": 0.0, "avg_logprob": -0.17241266722320228, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00034577507176436484}, {"id": 212, "seek": 119912, "start": 1218.4199999999998, "end": 1225.4199999999998, "text": " consequences. What is the meta problem? Well, the way I'm going to put it is it's the problem", "tokens": [51329, 10098, 13, 708, 307, 264, 19616, 1154, 30, 1042, 11, 264, 636, 286, 478, 516, 281, 829, 309, 307, 309, 311, 264, 1154, 51679], "temperature": 0.0, "avg_logprob": -0.17241266722320228, "compression_ratio": 1.6726457399103138, "no_speech_prob": 0.00034577507176436484}, {"id": 213, "seek": 122542, "start": 1226.42, "end": 1233.42, "text": " of topic neutrally explaining problem intuitions or else explaining why that can't be done.", "tokens": [50414, 295, 4829, 39913, 379, 13468, 1154, 16224, 626, 420, 1646, 13468, 983, 300, 393, 380, 312, 1096, 13, 50764], "temperature": 0.0, "avg_logprob": -0.20316337136661305, "compression_ratio": 1.7810945273631842, "no_speech_prob": 0.0004951736773364246}, {"id": 214, "seek": 122542, "start": 1234.42, "end": 1241.42, "text": " I'll unpack all the pieces of that right now, first starting with problem intuitions. What", "tokens": [50814, 286, 603, 26699, 439, 264, 3755, 295, 300, 558, 586, 11, 700, 2891, 365, 1154, 16224, 626, 13, 708, 51164], "temperature": 0.0, "avg_logprob": -0.20316337136661305, "compression_ratio": 1.7810945273631842, "no_speech_prob": 0.0004951736773364246}, {"id": 215, "seek": 122542, "start": 1241.8200000000002, "end": 1247.26, "text": " are problem intuitions? Well, those are the things we say. There are things we think.", "tokens": [51184, 366, 1154, 16224, 626, 30, 1042, 11, 729, 366, 264, 721, 321, 584, 13, 821, 366, 721, 321, 519, 13, 51456], "temperature": 0.0, "avg_logprob": -0.20316337136661305, "compression_ratio": 1.7810945273631842, "no_speech_prob": 0.0004951736773364246}, {"id": 216, "seek": 122542, "start": 1247.26, "end": 1251.78, "text": " I say consciousness seems irreducible. I might think consciousness is irreducible. People", "tokens": [51456, 286, 584, 10081, 2544, 16014, 769, 32128, 13, 286, 1062, 519, 10081, 307, 16014, 769, 32128, 13, 3432, 51682], "temperature": 0.0, "avg_logprob": -0.20316337136661305, "compression_ratio": 1.7810945273631842, "no_speech_prob": 0.0004951736773364246}, {"id": 217, "seek": 125178, "start": 1251.78, "end": 1256.7, "text": " might be disposed, have a tendency to say or think those things. Problem intuitions all", "tokens": [50364, 1062, 312, 4920, 1744, 11, 362, 257, 18187, 281, 584, 420, 519, 729, 721, 13, 11676, 16224, 626, 439, 50610], "temperature": 0.0, "avg_logprob": -0.10753664924103079, "compression_ratio": 1.848360655737705, "no_speech_prob": 0.0003051663807127625}, {"id": 218, "seek": 125178, "start": 1256.7, "end": 1262.82, "text": " take to be roughly that tendency. We have dispositions to say and think certain things", "tokens": [50610, 747, 281, 312, 9810, 300, 18187, 13, 492, 362, 15885, 2451, 281, 584, 293, 519, 1629, 721, 50916], "temperature": 0.0, "avg_logprob": -0.10753664924103079, "compression_ratio": 1.848360655737705, "no_speech_prob": 0.0003051663807127625}, {"id": 219, "seek": 125178, "start": 1262.82, "end": 1268.58, "text": " about consciousness. What are the core problem intuitions? Well, I think they break down into", "tokens": [50916, 466, 10081, 13, 708, 366, 264, 4965, 1154, 16224, 626, 30, 1042, 11, 286, 519, 436, 1821, 760, 666, 51204], "temperature": 0.0, "avg_logprob": -0.10753664924103079, "compression_ratio": 1.848360655737705, "no_speech_prob": 0.0003051663807127625}, {"id": 220, "seek": 125178, "start": 1268.58, "end": 1273.1, "text": " a number of different kinds. There's the intuition that consciousness is non-physical. We might", "tokens": [51204, 257, 1230, 295, 819, 3685, 13, 821, 311, 264, 24002, 300, 10081, 307, 2107, 12, 950, 36280, 13, 492, 1062, 51430], "temperature": 0.0, "avg_logprob": -0.10753664924103079, "compression_ratio": 1.848360655737705, "no_speech_prob": 0.0003051663807127625}, {"id": 221, "seek": 125178, "start": 1273.1, "end": 1277.66, "text": " think of that as a metaphysical intuition about the nature of consciousness. There are", "tokens": [51430, 519, 295, 300, 382, 257, 30946, 36280, 24002, 466, 264, 3687, 295, 10081, 13, 821, 366, 51658], "temperature": 0.0, "avg_logprob": -0.10753664924103079, "compression_ratio": 1.848360655737705, "no_speech_prob": 0.0003051663807127625}, {"id": 222, "seek": 127766, "start": 1277.7, "end": 1283.3000000000002, "text": " intuitions about explanation. Consciousness is hard to explain. Explaining behavior doesn't", "tokens": [50366, 16224, 626, 466, 10835, 13, 6923, 4139, 1287, 307, 1152, 281, 2903, 13, 12514, 3686, 5223, 1177, 380, 50646], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 223, "seek": 127766, "start": 1283.3000000000002, "end": 1288.18, "text": " explain consciousness. There are intuitions about knowledge of consciousness. Some of", "tokens": [50646, 2903, 10081, 13, 821, 366, 16224, 626, 466, 3601, 295, 10081, 13, 2188, 295, 50890], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 224, "seek": 127766, "start": 1288.18, "end": 1292.46, "text": " you may know the famous thought experiment of Mary in the black and white room who knows", "tokens": [50890, 291, 815, 458, 264, 4618, 1194, 5120, 295, 6059, 294, 264, 2211, 293, 2418, 1808, 567, 3255, 51104], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 225, "seek": 127766, "start": 1292.46, "end": 1297.38, "text": " all about the objective nature of color vision and so on, but still doesn't know what it's", "tokens": [51104, 439, 466, 264, 10024, 3687, 295, 2017, 5201, 293, 370, 322, 11, 457, 920, 1177, 380, 458, 437, 309, 311, 51350], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 226, "seek": 127766, "start": 1297.38, "end": 1301.7, "text": " like to see red. She sees red for the first time. She learns something new. That's an", "tokens": [51350, 411, 281, 536, 2182, 13, 1240, 8194, 2182, 337, 264, 700, 565, 13, 1240, 27152, 746, 777, 13, 663, 311, 364, 51566], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 227, "seek": 127766, "start": 1301.7, "end": 1306.14, "text": " intuition about knowledge of consciousness. There are what philosophers call modal intuitions", "tokens": [51566, 24002, 466, 3601, 295, 10081, 13, 821, 366, 437, 36839, 818, 39745, 16224, 626, 51788], "temperature": 0.0, "avg_logprob": -0.10158746525392694, "compression_ratio": 1.9316546762589928, "no_speech_prob": 0.0021811260376125574}, {"id": 228, "seek": 130614, "start": 1306.14, "end": 1312.0600000000002, "text": " about what's possible or imaginable. One famous case is the case of a zombie, a creature", "tokens": [50364, 466, 437, 311, 1944, 420, 23427, 712, 13, 1485, 4618, 1389, 307, 264, 1389, 295, 257, 20310, 11, 257, 12797, 50660], "temperature": 0.0, "avg_logprob": -0.1350026362150618, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.0024711359292268753}, {"id": 229, "seek": 130614, "start": 1312.0600000000002, "end": 1317.46, "text": " who's physically identical to you and me, but not conscious, or maybe an AI system which", "tokens": [50660, 567, 311, 9762, 14800, 281, 291, 293, 385, 11, 457, 406, 6648, 11, 420, 1310, 364, 7318, 1185, 597, 50930], "temperature": 0.0, "avg_logprob": -0.1350026362150618, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.0024711359292268753}, {"id": 230, "seek": 130614, "start": 1317.46, "end": 1322.46, "text": " is functionally identical to you and me, but not conscious. That at least seems conceivable", "tokens": [50930, 307, 2445, 379, 14800, 281, 291, 293, 385, 11, 457, 406, 6648, 13, 663, 412, 1935, 2544, 10413, 34376, 51180], "temperature": 0.0, "avg_logprob": -0.1350026362150618, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.0024711359292268753}, {"id": 231, "seek": 130614, "start": 1322.46, "end": 1328.66, "text": " to many people. This is the philosophical zombie, unlike the zombies in movies which", "tokens": [51180, 281, 867, 561, 13, 639, 307, 264, 25066, 20310, 11, 8343, 264, 24230, 294, 6233, 597, 51490], "temperature": 0.0, "avg_logprob": -0.1350026362150618, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.0024711359292268753}, {"id": 232, "seek": 130614, "start": 1328.66, "end": 1333.38, "text": " have weird behaviors and go after brains and so on. The philosophical zombie is a creature", "tokens": [51490, 362, 3657, 15501, 293, 352, 934, 15442, 293, 370, 322, 13, 440, 25066, 20310, 307, 257, 12797, 51726], "temperature": 0.0, "avg_logprob": -0.1350026362150618, "compression_ratio": 1.8464730290456433, "no_speech_prob": 0.0024711359292268753}, {"id": 233, "seek": 133338, "start": 1333.5, "end": 1338.9, "text": " that seems, at least behaviorally, maybe physically like a normal human, but doesn't have any", "tokens": [50370, 300, 2544, 11, 412, 1935, 5223, 379, 11, 1310, 9762, 411, 257, 2710, 1952, 11, 457, 1177, 380, 362, 604, 50640], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 234, "seek": 133338, "start": 1338.9, "end": 1343.98, "text": " conscious experiences. All the physical states, none of the mental states. It seems to many", "tokens": [50640, 6648, 5235, 13, 1057, 264, 4001, 4368, 11, 6022, 295, 264, 4973, 4368, 13, 467, 2544, 281, 867, 50894], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 235, "seek": 133338, "start": 1343.98, "end": 1348.2600000000002, "text": " people that's at least conceivable. We're not zombies. I don't think anyone here is", "tokens": [50894, 561, 300, 311, 412, 1935, 10413, 34376, 13, 492, 434, 406, 24230, 13, 286, 500, 380, 519, 2878, 510, 307, 51108], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 236, "seek": 133338, "start": 1348.2600000000002, "end": 1353.42, "text": " a zombie, I hope, but nonetheless, it seems that we can make sense of the idea and one", "tokens": [51108, 257, 20310, 11, 286, 1454, 11, 457, 26756, 11, 309, 2544, 300, 321, 393, 652, 2020, 295, 264, 1558, 293, 472, 51366], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 237, "seek": 133338, "start": 1353.42, "end": 1358.3000000000002, "text": " way to pose the hard problem is why are we not zombies. This imaginability of zombies", "tokens": [51366, 636, 281, 10774, 264, 1152, 1154, 307, 983, 366, 321, 406, 24230, 13, 639, 23427, 2310, 295, 24230, 51610], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 238, "seek": 133338, "start": 1358.3000000000002, "end": 1363.22, "text": " is one of the intuitions that gets the problem going. Then you can go on and catalog more", "tokens": [51610, 307, 472, 295, 264, 16224, 626, 300, 2170, 264, 1154, 516, 13, 1396, 291, 393, 352, 322, 293, 19746, 544, 51856], "temperature": 0.0, "avg_logprob": -0.12456259108681715, "compression_ratio": 1.7972972972972974, "no_speech_prob": 0.0033741341903805733}, {"id": 239, "seek": 136322, "start": 1363.54, "end": 1368.3, "text": " and more intuitions about the distribution of conscious, maybe the intuition that robots", "tokens": [50380, 293, 544, 16224, 626, 466, 264, 7316, 295, 6648, 11, 1310, 264, 24002, 300, 14733, 50618], "temperature": 0.0, "avg_logprob": -0.14033597515475366, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.00014872448809910566}, {"id": 240, "seek": 136322, "start": 1368.3, "end": 1373.58, "text": " won't be conscious. That's an optional one, I think, or consciousness matters morally", "tokens": [50618, 1582, 380, 312, 6648, 13, 663, 311, 364, 17312, 472, 11, 286, 519, 11, 420, 10081, 7001, 38622, 50882], "temperature": 0.0, "avg_logprob": -0.14033597515475366, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.00014872448809910566}, {"id": 241, "seek": 136322, "start": 1373.58, "end": 1380.08, "text": " in certain ways and the list goes on. I think there's an interdisciplinary research program", "tokens": [50882, 294, 1629, 2098, 293, 264, 1329, 1709, 322, 13, 286, 519, 456, 311, 364, 38280, 2132, 1461, 51207], "temperature": 0.0, "avg_logprob": -0.14033597515475366, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.00014872448809910566}, {"id": 242, "seek": 136322, "start": 1380.08, "end": 1386.18, "text": " here of working on those intuitions about consciousness and trying to explain them.", "tokens": [51207, 510, 295, 1364, 322, 729, 16224, 626, 466, 10081, 293, 1382, 281, 2903, 552, 13, 51512], "temperature": 0.0, "avg_logprob": -0.14033597515475366, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.00014872448809910566}, {"id": 243, "seek": 136322, "start": 1386.18, "end": 1391.46, "text": " Experimental psychology and experimental philosophy and newly active area can study people's intuitions", "tokens": [51512, 37933, 304, 15105, 293, 17069, 10675, 293, 15109, 4967, 1859, 393, 2979, 561, 311, 16224, 626, 51776], "temperature": 0.0, "avg_logprob": -0.14033597515475366, "compression_ratio": 1.8087649402390438, "no_speech_prob": 0.00014872448809910566}, {"id": 244, "seek": 139146, "start": 1391.5, "end": 1396.54, "text": " about consciousness. We can work on models of these things, computational models or neurobiological", "tokens": [50366, 466, 10081, 13, 492, 393, 589, 322, 5245, 295, 613, 721, 11, 28270, 5245, 420, 16499, 5614, 4383, 50618], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 245, "seek": 139146, "start": 1396.54, "end": 1400.6200000000001, "text": " models of these intuitions and reports, and indeed, I think there's a lot of room for", "tokens": [50618, 5245, 295, 613, 16224, 626, 293, 7122, 11, 293, 6451, 11, 286, 519, 456, 311, 257, 688, 295, 1808, 337, 50822], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 246, "seek": 139146, "start": 1400.6200000000001, "end": 1405.46, "text": " philosophical analysis. There's just starting to be a program of people doing these things", "tokens": [50822, 25066, 5215, 13, 821, 311, 445, 2891, 281, 312, 257, 1461, 295, 561, 884, 613, 721, 51064], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 247, "seek": 139146, "start": 1405.46, "end": 1412.46, "text": " in all these fields. It is an empirical question how widely these intuitions are shared. You", "tokens": [51064, 294, 439, 613, 7909, 13, 467, 307, 364, 31886, 1168, 577, 13371, 613, 16224, 626, 366, 5507, 13, 509, 51414], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 248, "seek": 139146, "start": 1412.46, "end": 1415.74, "text": " might be sitting there thinking, come on, I don't have any of these intuitions. Maybe", "tokens": [51414, 1062, 312, 3798, 456, 1953, 11, 808, 322, 11, 286, 500, 380, 362, 604, 295, 613, 16224, 626, 13, 2704, 51578], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 249, "seek": 139146, "start": 1415.74, "end": 1420.74, "text": " this is just you. My sense is from the psychological study to date, it seems that some of these", "tokens": [51578, 341, 307, 445, 291, 13, 1222, 2020, 307, 490, 264, 14346, 2979, 281, 4002, 11, 309, 2544, 300, 512, 295, 613, 51828], "temperature": 0.0, "avg_logprob": -0.1346167027950287, "compression_ratio": 1.8245033112582782, "no_speech_prob": 0.00028646094142459333}, {"id": 250, "seek": 142074, "start": 1420.74, "end": 1425.94, "text": " intuitions about consciousness are at least very widely shared, at least as dispositions", "tokens": [50364, 16224, 626, 466, 10081, 366, 412, 1935, 588, 13371, 5507, 11, 412, 1935, 382, 15885, 2451, 50624], "temperature": 0.0, "avg_logprob": -0.15907880371692135, "compression_ratio": 1.784, "no_speech_prob": 0.00016858380695339292}, {"id": 251, "seek": 142074, "start": 1425.94, "end": 1431.94, "text": " or intuitions, although they're often overridden on reflection. The current data on this is", "tokens": [50624, 420, 16224, 626, 11, 4878, 436, 434, 2049, 670, 81, 6171, 322, 12914, 13, 440, 2190, 1412, 322, 341, 307, 50924], "temperature": 0.0, "avg_logprob": -0.15907880371692135, "compression_ratio": 1.784, "no_speech_prob": 0.00016858380695339292}, {"id": 252, "seek": 142074, "start": 1431.94, "end": 1438.94, "text": " somewhat limited. There is a lot of empirical work on intuitions about the mind concerning", "tokens": [50924, 8344, 5567, 13, 821, 307, 257, 688, 295, 31886, 589, 322, 16224, 626, 466, 264, 1575, 18087, 51274], "temperature": 0.0, "avg_logprob": -0.15907880371692135, "compression_ratio": 1.784, "no_speech_prob": 0.00016858380695339292}, {"id": 253, "seek": 142074, "start": 1438.98, "end": 1443.02, "text": " things like belief, like when do kids get the idea that your belief's about the world,", "tokens": [51276, 721, 411, 7107, 11, 411, 562, 360, 2301, 483, 264, 1558, 300, 428, 7107, 311, 466, 264, 1002, 11, 51478], "temperature": 0.0, "avg_logprob": -0.15907880371692135, "compression_ratio": 1.784, "no_speech_prob": 0.00016858380695339292}, {"id": 254, "seek": 142074, "start": 1443.02, "end": 1448.34, "text": " can be false, concerning the way your self persists through time, could you exist after", "tokens": [51478, 393, 312, 7908, 11, 18087, 264, 636, 428, 2698, 868, 1751, 807, 565, 11, 727, 291, 2514, 934, 51744], "temperature": 0.0, "avg_logprob": -0.15907880371692135, "compression_ratio": 1.784, "no_speech_prob": 0.00016858380695339292}, {"id": 255, "seek": 144834, "start": 1448.34, "end": 1452.1799999999998, "text": " the death of your body? Well, consciousness is concerned. There's work on the distribution", "tokens": [50364, 264, 2966, 295, 428, 1772, 30, 1042, 11, 10081, 307, 5922, 13, 821, 311, 589, 322, 264, 7316, 50556], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 256, "seek": 144834, "start": 1452.1799999999998, "end": 1455.86, "text": " of consciousness. Could a robot be conscious? Could a group be conscious? Here's a book", "tokens": [50556, 295, 10081, 13, 7497, 257, 7881, 312, 6648, 30, 7497, 257, 1594, 312, 6648, 30, 1692, 311, 257, 1446, 50740], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 257, "seek": 144834, "start": 1455.86, "end": 1459.98, "text": " by Paul Bloom, Descartes' Baby. The catalog's a lot of this interesting work, making the", "tokens": [50740, 538, 4552, 25927, 11, 3885, 44672, 279, 6, 9425, 13, 440, 19746, 311, 257, 688, 295, 341, 1880, 589, 11, 1455, 264, 50946], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 258, "seek": 144834, "start": 1459.98, "end": 1466.34, "text": " case that many children are intuitive dualists. They're naturally inclined to think there's", "tokens": [50946, 1389, 300, 867, 2227, 366, 21769, 11848, 1751, 13, 814, 434, 8195, 28173, 281, 519, 456, 311, 51264], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 259, "seek": 144834, "start": 1466.34, "end": 1470.98, "text": " something non-physical about the mind. So far, most of this work has not been so much", "tokens": [51264, 746, 2107, 12, 950, 36280, 466, 264, 1575, 13, 407, 1400, 11, 881, 295, 341, 589, 575, 406, 668, 370, 709, 51496], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 260, "seek": 144834, "start": 1470.98, "end": 1477.22, "text": " on these core problem intuitions about consciousness, but there's work developing in this direction.", "tokens": [51496, 322, 613, 4965, 1154, 16224, 626, 466, 10081, 11, 457, 456, 311, 589, 6416, 294, 341, 3513, 13, 51808], "temperature": 0.0, "avg_logprob": -0.15244600754375606, "compression_ratio": 1.761290322580645, "no_speech_prob": 0.003939700312912464}, {"id": 261, "seek": 147722, "start": 1477.26, "end": 1482.06, "text": " Sarah Gottlieb and Tanya Lombrozo have a very recent article called Can Science Explain", "tokens": [50366, 9519, 19133, 6302, 65, 293, 314, 8791, 441, 3548, 340, 4765, 362, 257, 588, 5162, 7222, 1219, 1664, 8976, 39574, 50606], "temperature": 0.0, "avg_logprob": -0.20308171066583372, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.030514342710375786}, {"id": 262, "seek": 147722, "start": 1482.06, "end": 1488.34, "text": " the Human Mind on People's Judgements about when various mental phenomena are hard to", "tokens": [50606, 264, 10294, 13719, 322, 3432, 311, 19476, 1117, 466, 562, 3683, 4973, 22004, 366, 1152, 281, 50920], "temperature": 0.0, "avg_logprob": -0.20308171066583372, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.030514342710375786}, {"id": 263, "seek": 147722, "start": 1488.34, "end": 1492.54, "text": " explain and they seem to find that, yes, subjective experience and things which have, to which", "tokens": [50920, 2903, 293, 436, 1643, 281, 915, 300, 11, 2086, 11, 25972, 1752, 293, 721, 597, 362, 11, 281, 597, 51130], "temperature": 0.0, "avg_logprob": -0.20308171066583372, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.030514342710375786}, {"id": 264, "seek": 147722, "start": 1492.54, "end": 1498.42, "text": " people have privileged first person access seem to pose the problem big time. So there's", "tokens": [51130, 561, 362, 25293, 700, 954, 2105, 1643, 281, 10774, 264, 1154, 955, 565, 13, 407, 456, 311, 51424], "temperature": 0.0, "avg_logprob": -0.20308171066583372, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.030514342710375786}, {"id": 265, "seek": 147722, "start": 1498.42, "end": 1503.66, "text": " the beginning of a research program here. I think there's room for a lot more.", "tokens": [51424, 264, 2863, 295, 257, 2132, 1461, 510, 13, 286, 519, 456, 311, 1808, 337, 257, 688, 544, 13, 51686], "temperature": 0.0, "avg_logprob": -0.20308171066583372, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.030514342710375786}, {"id": 266, "seek": 150366, "start": 1503.66, "end": 1508.7, "text": " The topic neutrality part, when I say we're looking for a topic neutral explanation of", "tokens": [50364, 440, 4829, 39913, 1860, 644, 11, 562, 286, 584, 321, 434, 1237, 337, 257, 4829, 10598, 10835, 295, 50616], "temperature": 0.0, "avg_logprob": -0.17236054059371209, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.0003566489613149315}, {"id": 267, "seek": 150366, "start": 1508.7, "end": 1513.74, "text": " problem intuitions, that's roughly to say an explanation that doesn't mention consciousness", "tokens": [50616, 1154, 16224, 626, 11, 300, 311, 9810, 281, 584, 364, 10835, 300, 1177, 380, 2152, 10081, 50868], "temperature": 0.0, "avg_logprob": -0.17236054059371209, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.0003566489613149315}, {"id": 268, "seek": 150366, "start": 1513.74, "end": 1518.7, "text": " itself. It's put in neutral terms. It's neutral on the existence of consciousness. The most", "tokens": [50868, 2564, 13, 467, 311, 829, 294, 10598, 2115, 13, 467, 311, 10598, 322, 264, 9123, 295, 10081, 13, 440, 881, 51116], "temperature": 0.0, "avg_logprob": -0.17236054059371209, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.0003566489613149315}, {"id": 269, "seek": 150366, "start": 1518.7, "end": 1523.7, "text": " obvious one would be something like an algorithmic explanation. I can say, here is the algorithm.", "tokens": [51116, 6322, 472, 576, 312, 746, 411, 364, 9284, 299, 10835, 13, 286, 393, 584, 11, 510, 307, 264, 9284, 13, 51366], "temperature": 0.0, "avg_logprob": -0.17236054059371209, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.0003566489613149315}, {"id": 270, "seek": 150366, "start": 1523.7, "end": 1529.26, "text": " The brain is executing. It generates our conviction that we're conscious and our reports about", "tokens": [51366, 440, 3567, 307, 32368, 13, 467, 23815, 527, 24837, 300, 321, 434, 6648, 293, 527, 7122, 466, 51644], "temperature": 0.0, "avg_logprob": -0.17236054059371209, "compression_ratio": 1.815686274509804, "no_speech_prob": 0.0003566489613149315}, {"id": 271, "seek": 152926, "start": 1529.3, "end": 1533.62, "text": " consciousness. There may be some time between that algorithm and consciousness, but to specify", "tokens": [50366, 10081, 13, 821, 815, 312, 512, 565, 1296, 300, 9284, 293, 10081, 11, 457, 281, 16500, 50582], "temperature": 0.0, "avg_logprob": -0.25136752128601075, "compression_ratio": 1.72, "no_speech_prob": 0.00021639169426634908}, {"id": 272, "seek": 152926, "start": 1533.62, "end": 1539.82, "text": " the algorithm, you don't need to make claims about consciousness. So the algorithmic version", "tokens": [50582, 264, 9284, 11, 291, 500, 380, 643, 281, 652, 9441, 466, 10081, 13, 407, 264, 9284, 299, 3037, 50892], "temperature": 0.0, "avg_logprob": -0.25136752128601075, "compression_ratio": 1.72, "no_speech_prob": 0.00021639169426634908}, {"id": 273, "seek": 152926, "start": 1539.82, "end": 1545.34, "text": " of the metaproblem is roughly find the algorithm that generates our problem intuition. So that's", "tokens": [50892, 295, 264, 1131, 569, 340, 1113, 307, 9810, 915, 264, 9284, 300, 23815, 527, 1154, 24002, 13, 407, 300, 311, 51168], "temperature": 0.0, "avg_logprob": -0.25136752128601075, "compression_ratio": 1.72, "no_speech_prob": 0.00021639169426634908}, {"id": 274, "seek": 152926, "start": 1545.34, "end": 1554.34, "text": " I think a principal research program that maybe AI researchers in combination would say psychologists,", "tokens": [51168, 286, 519, 257, 9716, 2132, 1461, 300, 1310, 7318, 10309, 294, 6562, 576, 584, 41562, 11, 51618], "temperature": 0.0, "avg_logprob": -0.25136752128601075, "compression_ratio": 1.72, "no_speech_prob": 0.00021639169426634908}, {"id": 275, "seek": 155434, "start": 1554.8999999999999, "end": 1560.5, "text": " the psychologist could help isolate data about the way that the human beings are doing it,", "tokens": [50392, 264, 29514, 727, 854, 25660, 1412, 466, 264, 636, 300, 264, 1952, 8958, 366, 884, 309, 11, 50672], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 276, "seek": 155434, "start": 1560.5, "end": 1564.82, "text": " how these things are generated in humans and AI researchers can try and see about implementing", "tokens": [50672, 577, 613, 721, 366, 10833, 294, 6255, 293, 7318, 10309, 393, 853, 293, 536, 466, 18114, 50888], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 277, "seek": 155434, "start": 1564.82, "end": 1569.3799999999999, "text": " that algorithm in machines and see what results. And I'll talk about a little bit of research", "tokens": [50888, 300, 9284, 294, 8379, 293, 536, 437, 3542, 13, 400, 286, 603, 751, 466, 257, 707, 857, 295, 2132, 51116], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 278, "seek": 155434, "start": 1569.3799999999999, "end": 1575.34, "text": " in this direction in just a moment. But okay, now I want to say something about potential", "tokens": [51116, 294, 341, 3513, 294, 445, 257, 1623, 13, 583, 1392, 11, 586, 286, 528, 281, 584, 746, 466, 3995, 51414], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 279, "seek": 155434, "start": 1575.34, "end": 1580.1, "text": " solutions to the problem. Like I say, this is a big research program. I don't claim to", "tokens": [51414, 6547, 281, 264, 1154, 13, 1743, 286, 584, 11, 341, 307, 257, 955, 2132, 1461, 13, 286, 500, 380, 3932, 281, 51652], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 280, "seek": 155434, "start": 1580.1, "end": 1584.3, "text": " have the solution to the metaproblem. I've got some ideas, but I'm not going to try and", "tokens": [51652, 362, 264, 3827, 281, 264, 1131, 569, 340, 1113, 13, 286, 600, 658, 512, 3487, 11, 457, 286, 478, 406, 516, 281, 853, 293, 51862], "temperature": 0.0, "avg_logprob": -0.14328965407151442, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0007095225155353546}, {"id": 281, "seek": 158430, "start": 1584.3, "end": 1590.7, "text": " lay out a major solution or just so here are a few things which I think might be parts", "tokens": [50364, 2360, 484, 257, 2563, 3827, 420, 445, 370, 510, 366, 257, 1326, 721, 597, 286, 519, 1062, 312, 3166, 50684], "temperature": 0.0, "avg_logprob": -0.13683480555468266, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.00010887799726333469}, {"id": 282, "seek": 158430, "start": 1590.7, "end": 1595.78, "text": " of a solution to the problem, many of which have got antecedents here and there in scientific", "tokens": [50684, 295, 257, 3827, 281, 264, 1154, 11, 867, 295, 597, 362, 658, 23411, 1232, 791, 510, 293, 456, 294, 8134, 50938], "temperature": 0.0, "avg_logprob": -0.13683480555468266, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.00010887799726333469}, {"id": 283, "seek": 158430, "start": 1595.78, "end": 1601.22, "text": " and philosophical discussion. Some promising ideas include retrospective models, phenomenal", "tokens": [50938, 293, 25066, 5017, 13, 2188, 20257, 3487, 4090, 34997, 488, 5245, 11, 17778, 51210], "temperature": 0.0, "avg_logprob": -0.13683480555468266, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.00010887799726333469}, {"id": 284, "seek": 158430, "start": 1601.22, "end": 1606.1399999999999, "text": " concepts, introspective opacity, the sense of acquaintance. Let me just say something", "tokens": [51210, 10392, 11, 560, 28713, 488, 41693, 11, 264, 2020, 295, 36954, 719, 13, 961, 385, 445, 584, 746, 51456], "temperature": 0.0, "avg_logprob": -0.13683480555468266, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.00010887799726333469}, {"id": 285, "seek": 158430, "start": 1606.1399999999999, "end": 1612.3, "text": " about a few of these. One starting idea that almost anyone's going to have here is somehow", "tokens": [51456, 466, 257, 1326, 295, 613, 13, 1485, 2891, 1558, 300, 1920, 2878, 311, 516, 281, 362, 510, 307, 6063, 51764], "temperature": 0.0, "avg_logprob": -0.13683480555468266, "compression_ratio": 1.6753731343283582, "no_speech_prob": 0.00010887799726333469}, {"id": 286, "seek": 161230, "start": 1612.3, "end": 1619.1, "text": " models of ourselves are playing a central role here. Human beings have models of the", "tokens": [50364, 5245, 295, 4175, 366, 2433, 257, 5777, 3090, 510, 13, 10294, 8958, 362, 5245, 295, 264, 50704], "temperature": 0.0, "avg_logprob": -0.11809812982877095, "compression_ratio": 1.8033472803347281, "no_speech_prob": 0.008307771757245064}, {"id": 287, "seek": 161230, "start": 1619.1, "end": 1626.02, "text": " world, naive physics and naive psychology, models of other people and so on. We also", "tokens": [50704, 1002, 11, 29052, 10649, 293, 29052, 15105, 11, 5245, 295, 661, 561, 293, 370, 322, 13, 492, 611, 51050], "temperature": 0.0, "avg_logprob": -0.11809812982877095, "compression_ratio": 1.8033472803347281, "no_speech_prob": 0.008307771757245064}, {"id": 288, "seek": 161230, "start": 1626.02, "end": 1630.6599999999999, "text": " have models of ourselves. It makes sense for us to have models of ourselves and our own", "tokens": [51050, 362, 5245, 295, 4175, 13, 467, 1669, 2020, 337, 505, 281, 362, 5245, 295, 4175, 293, 527, 1065, 51282], "temperature": 0.0, "avg_logprob": -0.11809812982877095, "compression_ratio": 1.8033472803347281, "no_speech_prob": 0.008307771757245064}, {"id": 289, "seek": 161230, "start": 1630.6599999999999, "end": 1635.6599999999999, "text": " mental processes. This is something that the psychologist Michael Graziano has written", "tokens": [51282, 4973, 7555, 13, 639, 307, 746, 300, 264, 29514, 5116, 8985, 89, 6254, 575, 3720, 51532], "temperature": 0.0, "avg_logprob": -0.11809812982877095, "compression_ratio": 1.8033472803347281, "no_speech_prob": 0.008307771757245064}, {"id": 290, "seek": 161230, "start": 1635.6599999999999, "end": 1641.62, "text": " a lot on. We have internal models of our own cognitive processes, including those tied", "tokens": [51532, 257, 688, 322, 13, 492, 362, 6920, 5245, 295, 527, 1065, 15605, 7555, 11, 3009, 729, 9601, 51830], "temperature": 0.0, "avg_logprob": -0.11809812982877095, "compression_ratio": 1.8033472803347281, "no_speech_prob": 0.008307771757245064}, {"id": 291, "seek": 164162, "start": 1641.6599999999999, "end": 1647.6599999999999, "text": " to consciousness. Somehow, something about our introspective models explains our sense,", "tokens": [50366, 281, 10081, 13, 28357, 11, 746, 466, 527, 560, 28713, 488, 5245, 13948, 527, 2020, 11, 50666], "temperature": 0.0, "avg_logprob": -0.14852915139033876, "compression_ratio": 1.9071729957805907, "no_speech_prob": 0.00039192900294438004}, {"id": 292, "seek": 164162, "start": 1647.6599999999999, "end": 1652.9799999999998, "text": " A, that we are conscious and B, that this is distinctively problematic. I think anyone", "tokens": [50666, 316, 11, 300, 321, 366, 6648, 293, 363, 11, 300, 341, 307, 10644, 3413, 19011, 13, 286, 519, 2878, 50932], "temperature": 0.0, "avg_logprob": -0.14852915139033876, "compression_ratio": 1.9071729957805907, "no_speech_prob": 0.00039192900294438004}, {"id": 293, "seek": 164162, "start": 1652.9799999999998, "end": 1658.1799999999998, "text": " thinking about the metaproblem, this has got to be at least the first step. We have these", "tokens": [50932, 1953, 466, 264, 1131, 569, 340, 1113, 11, 341, 575, 658, 281, 312, 412, 1935, 264, 700, 1823, 13, 492, 362, 613, 51192], "temperature": 0.0, "avg_logprob": -0.14852915139033876, "compression_ratio": 1.9071729957805907, "no_speech_prob": 0.00039192900294438004}, {"id": 294, "seek": 164162, "start": 1658.1799999999998, "end": 1662.26, "text": " introspective models. If you're an illusionist, they'll be false models. If you're a realist,", "tokens": [51192, 560, 28713, 488, 5245, 13, 759, 291, 434, 364, 18854, 468, 11, 436, 603, 312, 7908, 5245, 13, 759, 291, 434, 257, 957, 468, 11, 51396], "temperature": 0.0, "avg_logprob": -0.14852915139033876, "compression_ratio": 1.9071729957805907, "no_speech_prob": 0.00039192900294438004}, {"id": 295, "seek": 164162, "start": 1662.26, "end": 1668.34, "text": " they needn't be false models, but at the very least, these introspective models are involved,", "tokens": [51396, 436, 643, 77, 380, 312, 7908, 5245, 11, 457, 412, 264, 588, 1935, 11, 613, 560, 28713, 488, 5245, 366, 3288, 11, 51700], "temperature": 0.0, "avg_logprob": -0.14852915139033876, "compression_ratio": 1.9071729957805907, "no_speech_prob": 0.00039192900294438004}, {"id": 296, "seek": 166834, "start": 1668.3799999999999, "end": 1673.86, "text": " which is fine, but the devil's in the details. How do they work to generate this problem?", "tokens": [50366, 597, 307, 2489, 11, 457, 264, 13297, 311, 294, 264, 4365, 13, 1012, 360, 436, 589, 281, 8460, 341, 1154, 30, 50640], "temperature": 0.0, "avg_logprob": -0.17149929205576578, "compression_ratio": 1.8196078431372549, "no_speech_prob": 0.0015483051538467407}, {"id": 297, "seek": 166834, "start": 1673.86, "end": 1678.78, "text": " A number of philosophers have argued we have special concepts of consciousness, introspective", "tokens": [50640, 316, 1230, 295, 36839, 362, 20219, 321, 362, 2121, 10392, 295, 10081, 11, 560, 28713, 488, 50886], "temperature": 0.0, "avg_logprob": -0.17149929205576578, "compression_ratio": 1.8196078431372549, "no_speech_prob": 0.0015483051538467407}, {"id": 298, "seek": 166834, "start": 1678.78, "end": 1684.3799999999999, "text": " concepts of these special subjective states. People call these phenomenal concepts, concepts", "tokens": [50886, 10392, 295, 613, 2121, 25972, 4368, 13, 3432, 818, 613, 17778, 10392, 11, 10392, 51166], "temperature": 0.0, "avg_logprob": -0.17149929205576578, "compression_ratio": 1.8196078431372549, "no_speech_prob": 0.0015483051538467407}, {"id": 299, "seek": 166834, "start": 1684.3799999999999, "end": 1690.4599999999998, "text": " of phenomenal consciousness. One thing that's special is these concepts are somehow independent", "tokens": [51166, 295, 17778, 10081, 13, 1485, 551, 300, 311, 2121, 307, 613, 10392, 366, 6063, 6695, 51470], "temperature": 0.0, "avg_logprob": -0.17149929205576578, "compression_ratio": 1.8196078431372549, "no_speech_prob": 0.0015483051538467407}, {"id": 300, "seek": 166834, "start": 1690.4599999999998, "end": 1697.4599999999998, "text": " of our physical concepts. They explain, we've got one set of physical concepts for modeling", "tokens": [51470, 295, 527, 4001, 10392, 13, 814, 2903, 11, 321, 600, 658, 472, 992, 295, 4001, 10392, 337, 15983, 51820], "temperature": 0.0, "avg_logprob": -0.17149929205576578, "compression_ratio": 1.8196078431372549, "no_speech_prob": 0.0015483051538467407}, {"id": 301, "seek": 169746, "start": 1697.46, "end": 1701.42, "text": " the external work world. We've got one set of introspective concepts for modeling our", "tokens": [50364, 264, 8320, 589, 1002, 13, 492, 600, 658, 472, 992, 295, 560, 28713, 488, 10392, 337, 15983, 527, 50562], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 302, "seek": 169746, "start": 1701.42, "end": 1705.22, "text": " own mind. These concepts, just by virtue of the way they're designed, are somewhat independent", "tokens": [50562, 1065, 1575, 13, 1981, 10392, 11, 445, 538, 20816, 295, 264, 636, 436, 434, 4761, 11, 366, 8344, 6695, 50752], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 303, "seek": 169746, "start": 1705.22, "end": 1711.3400000000001, "text": " of each other, and that partly explains why consciousness seems to be independent of", "tokens": [50752, 295, 1184, 661, 11, 293, 300, 17031, 13948, 983, 10081, 2544, 281, 312, 6695, 295, 51058], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 304, "seek": 169746, "start": 1711.3400000000001, "end": 1716.98, "text": " the physical world, intuitively. Maybe that independence of phenomenal concepts could", "tokens": [51058, 264, 4001, 1002, 11, 46506, 13, 2704, 300, 14640, 295, 17778, 10392, 727, 51340], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 305, "seek": 169746, "start": 1716.98, "end": 1721.66, "text": " go some distance to explaining our problem report. I think there's got to be something", "tokens": [51340, 352, 512, 4560, 281, 13468, 527, 1154, 2275, 13, 286, 519, 456, 311, 658, 281, 312, 746, 51574], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 306, "seek": 169746, "start": 1721.66, "end": 1727.38, "text": " to this as well. At the same time, I don't think this goes nearly far enough because", "tokens": [51574, 281, 341, 382, 731, 13, 1711, 264, 912, 565, 11, 286, 500, 380, 519, 341, 1709, 6217, 1400, 1547, 570, 51860], "temperature": 0.0, "avg_logprob": -0.15307543195527176, "compression_ratio": 1.7091503267973855, "no_speech_prob": 0.0001969946752069518}, {"id": 307, "seek": 172738, "start": 1727.8600000000001, "end": 1732.46, "text": " we have concepts of many aspects of the mind, not just of the subjective experiential past,", "tokens": [50388, 321, 362, 10392, 295, 867, 7270, 295, 264, 1575, 11, 406, 445, 295, 264, 25972, 49611, 831, 1791, 11, 50618], "temperature": 0.0, "avg_logprob": -0.13205634795867646, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.00011225238267797977}, {"id": 308, "seek": 172738, "start": 1732.46, "end": 1738.18, "text": " but things we believe and things we desire. One, I believe that Paris is the capital of", "tokens": [50618, 457, 721, 321, 1697, 293, 721, 321, 7516, 13, 1485, 11, 286, 1697, 300, 8380, 307, 264, 4238, 295, 50904], "temperature": 0.0, "avg_logprob": -0.13205634795867646, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.00011225238267797977}, {"id": 309, "seek": 172738, "start": 1738.18, "end": 1744.3000000000002, "text": " France. That's part of my internal self-model, but that doesn't seem to generate the hard", "tokens": [50904, 6190, 13, 663, 311, 644, 295, 452, 6920, 2698, 12, 8014, 338, 11, 457, 300, 1177, 380, 1643, 281, 8460, 264, 1152, 51210], "temperature": 0.0, "avg_logprob": -0.13205634795867646, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.00011225238267797977}, {"id": 310, "seek": 172738, "start": 1744.3000000000002, "end": 1749.0600000000002, "text": " problem in nearly the same way in which, say, the experience of red does. A lot more needs", "tokens": [51210, 1154, 294, 6217, 264, 912, 636, 294, 597, 11, 584, 11, 264, 1752, 295, 2182, 775, 13, 316, 688, 544, 2203, 51448], "temperature": 0.0, "avg_logprob": -0.13205634795867646, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.00011225238267797977}, {"id": 311, "seek": 172738, "start": 1749.0600000000002, "end": 1754.38, "text": " to be said about what's going on in cases like having the experience of red and having", "tokens": [51448, 281, 312, 848, 466, 437, 311, 516, 322, 294, 3331, 411, 1419, 264, 1752, 295, 2182, 293, 1419, 51714], "temperature": 0.0, "avg_logprob": -0.13205634795867646, "compression_ratio": 1.6931818181818181, "no_speech_prob": 0.00011225238267797977}, {"id": 312, "seek": 175438, "start": 1754.38, "end": 1759.0600000000002, "text": " the sense that that generates a gap, so it doesn't generalize to everything about the", "tokens": [50364, 264, 2020, 300, 300, 23815, 257, 7417, 11, 370, 309, 1177, 380, 2674, 1125, 281, 1203, 466, 264, 50598], "temperature": 0.0, "avg_logprob": -0.11324460038514896, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0003242906532250345}, {"id": 313, "seek": 175438, "start": 1759.0600000000002, "end": 1765.2600000000002, "text": " mind. Some people have thought that what we might call introspective opacity plays a", "tokens": [50598, 1575, 13, 2188, 561, 362, 1194, 300, 437, 321, 1062, 818, 560, 28713, 488, 41693, 5749, 257, 50908], "temperature": 0.0, "avg_logprob": -0.11324460038514896, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0003242906532250345}, {"id": 314, "seek": 175438, "start": 1765.2600000000002, "end": 1771.0200000000002, "text": " role, that when we introspect what's going on in our minds, we don't have access to the", "tokens": [50908, 3090, 11, 300, 562, 321, 560, 28713, 437, 311, 516, 322, 294, 527, 9634, 11, 321, 500, 380, 362, 2105, 281, 264, 51196], "temperature": 0.0, "avg_logprob": -0.11324460038514896, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0003242906532250345}, {"id": 315, "seek": 175438, "start": 1771.0200000000002, "end": 1775.5400000000002, "text": " underlying physical states. We don't see the neurons in our brains. We don't see that", "tokens": [51196, 14217, 4001, 4368, 13, 492, 500, 380, 536, 264, 22027, 294, 527, 15442, 13, 492, 500, 380, 536, 300, 51422], "temperature": 0.0, "avg_logprob": -0.11324460038514896, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0003242906532250345}, {"id": 316, "seek": 175438, "start": 1775.5400000000002, "end": 1782.3000000000002, "text": " consciousness as physical, so we see it as non-physical. Most recently, the physicist", "tokens": [51422, 10081, 382, 4001, 11, 370, 321, 536, 309, 382, 2107, 12, 950, 36280, 13, 4534, 3938, 11, 264, 42466, 51760], "temperature": 0.0, "avg_logprob": -0.11324460038514896, "compression_ratio": 1.8220338983050848, "no_speech_prob": 0.0003242906532250345}, {"id": 317, "seek": 178230, "start": 1782.34, "end": 1785.74, "text": " Max Tegmark has argued in this direction, saying, somehow, consciousness is substrate", "tokens": [50366, 7402, 314, 1146, 5638, 575, 20219, 294, 341, 3513, 11, 1566, 11, 6063, 11, 10081, 307, 27585, 50536], "temperature": 0.0, "avg_logprob": -0.18983085002374211, "compression_ratio": 1.71484375, "no_speech_prob": 0.00017945772560779005}, {"id": 318, "seek": 178230, "start": 1785.74, "end": 1790.5, "text": " independent. We don't see the substrate, so then we think, ah, maybe it can float free", "tokens": [50536, 6695, 13, 492, 500, 380, 536, 264, 27585, 11, 370, 550, 321, 519, 11, 3716, 11, 1310, 309, 393, 15706, 1737, 50774], "temperature": 0.0, "avg_logprob": -0.18983085002374211, "compression_ratio": 1.71484375, "no_speech_prob": 0.00017945772560779005}, {"id": 319, "seek": 178230, "start": 1790.5, "end": 1799.02, "text": " of the substrate. Armstrong made an analogy with the case of someone in a circus where", "tokens": [50774, 295, 264, 27585, 13, 36100, 1027, 364, 21663, 365, 264, 1389, 295, 1580, 294, 257, 32155, 689, 51200], "temperature": 0.0, "avg_logprob": -0.18983085002374211, "compression_ratio": 1.71484375, "no_speech_prob": 0.00017945772560779005}, {"id": 320, "seek": 178230, "start": 1799.02, "end": 1804.82, "text": " the headless person illusion where you don't see someone's there with a veil across their", "tokens": [51200, 264, 1378, 1832, 954, 18854, 689, 291, 500, 380, 536, 1580, 311, 456, 365, 257, 30705, 2108, 641, 51490], "temperature": 0.0, "avg_logprob": -0.18983085002374211, "compression_ratio": 1.71484375, "no_speech_prob": 0.00017945772560779005}, {"id": 321, "seek": 178230, "start": 1804.82, "end": 1812.1399999999999, "text": " head. You don't see their head, so you see them as having no head. Here is a 19th century", "tokens": [51490, 1378, 13, 509, 500, 380, 536, 641, 1378, 11, 370, 291, 536, 552, 382, 1419, 572, 1378, 13, 1692, 307, 257, 1294, 392, 4901, 51856], "temperature": 0.0, "avg_logprob": -0.18983085002374211, "compression_ratio": 1.71484375, "no_speech_prob": 0.00017945772560779005}, {"id": 322, "seek": 181214, "start": 1812.18, "end": 1816.18, "text": " booth at a circus, a so-called headless woman with a veil over her head. You don't see the", "tokens": [50366, 20912, 412, 257, 32155, 11, 257, 370, 12, 11880, 1378, 1832, 3059, 365, 257, 30705, 670, 720, 1378, 13, 509, 500, 380, 536, 264, 50566], "temperature": 0.0, "avg_logprob": -0.18229941398866714, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0001535251794848591}, {"id": 323, "seek": 181214, "start": 1816.18, "end": 1820.3000000000002, "text": " head, so somehow it looks at least for a moment like the person doesn't have a head. Armstrong", "tokens": [50566, 1378, 11, 370, 6063, 309, 1542, 412, 1935, 337, 257, 1623, 411, 264, 954, 1177, 380, 362, 257, 1378, 13, 36100, 50772], "temperature": 0.0, "avg_logprob": -0.18229941398866714, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0001535251794848591}, {"id": 324, "seek": 181214, "start": 1820.3000000000002, "end": 1825.1000000000001, "text": " says, maybe that's how it is with consciousness. You don't see that it's physical, so you", "tokens": [50772, 1619, 11, 1310, 300, 311, 577, 309, 307, 365, 10081, 13, 509, 500, 380, 536, 300, 309, 311, 4001, 11, 370, 291, 51012], "temperature": 0.0, "avg_logprob": -0.18229941398866714, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0001535251794848591}, {"id": 325, "seek": 181214, "start": 1825.1000000000001, "end": 1832.8200000000002, "text": " see it as non-physical. But still, the question comes up, how do we make this inference? There's", "tokens": [51012, 536, 309, 382, 2107, 12, 950, 36280, 13, 583, 920, 11, 264, 1168, 1487, 493, 11, 577, 360, 321, 652, 341, 38253, 30, 821, 311, 51398], "temperature": 0.0, "avg_logprob": -0.18229941398866714, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0001535251794848591}, {"id": 326, "seek": 181214, "start": 1832.8200000000002, "end": 1838.3400000000001, "text": " something that special goes on in cases like, say, color and taste and so on. Color experience", "tokens": [51398, 746, 300, 2121, 1709, 322, 294, 3331, 411, 11, 584, 11, 2017, 293, 3939, 293, 370, 322, 13, 10458, 1752, 51674], "temperature": 0.0, "avg_logprob": -0.18229941398866714, "compression_ratio": 1.6798561151079137, "no_speech_prob": 0.0001535251794848591}, {"id": 327, "seek": 183834, "start": 1838.34, "end": 1844.3, "text": " seems to attribute primitive properties to objects like redness, greenness and so on.", "tokens": [50364, 2544, 281, 19667, 28540, 7221, 281, 6565, 411, 2182, 1287, 11, 3092, 1287, 293, 370, 322, 13, 50662], "temperature": 0.0, "avg_logprob": -0.16580961282970835, "compression_ratio": 1.7862903225806452, "no_speech_prob": 0.007684591691941023}, {"id": 328, "seek": 183834, "start": 1844.3, "end": 1848.58, "text": " But in fact, in the external world, at the very least, they have complex, reducible", "tokens": [50662, 583, 294, 1186, 11, 294, 264, 8320, 1002, 11, 412, 264, 588, 1935, 11, 436, 362, 3997, 11, 2783, 32128, 50876], "temperature": 0.0, "avg_logprob": -0.16580961282970835, "compression_ratio": 1.7862903225806452, "no_speech_prob": 0.007684591691941023}, {"id": 329, "seek": 183834, "start": 1848.58, "end": 1855.02, "text": " properties. Somehow, internal models of color treat colors like red and green as if they", "tokens": [50876, 7221, 13, 28357, 11, 6920, 5245, 295, 2017, 2387, 4577, 411, 2182, 293, 3092, 382, 498, 436, 51198], "temperature": 0.0, "avg_logprob": -0.16580961282970835, "compression_ratio": 1.7862903225806452, "no_speech_prob": 0.007684591691941023}, {"id": 330, "seek": 183834, "start": 1855.02, "end": 1860.58, "text": " are primitive things. It turns out to be useful to have these models of things where you treat", "tokens": [51198, 366, 28540, 721, 13, 467, 4523, 484, 281, 312, 4420, 281, 362, 613, 5245, 295, 721, 689, 291, 2387, 51476], "temperature": 0.0, "avg_logprob": -0.16580961282970835, "compression_ratio": 1.7862903225806452, "no_speech_prob": 0.007684591691941023}, {"id": 331, "seek": 183834, "start": 1860.58, "end": 1864.78, "text": " certain things as primitive even though they're reducible. And it sure seems that when we", "tokens": [51476, 1629, 721, 382, 28540, 754, 1673, 436, 434, 2783, 32128, 13, 400, 309, 988, 2544, 300, 562, 321, 51686], "temperature": 0.0, "avg_logprob": -0.16580961282970835, "compression_ratio": 1.7862903225806452, "no_speech_prob": 0.007684591691941023}, {"id": 332, "seek": 186478, "start": 1864.78, "end": 1870.5, "text": " experience colors, we experience greenness as a primitive quality, even though it may", "tokens": [50364, 1752, 4577, 11, 321, 1752, 3092, 1287, 382, 257, 28540, 3125, 11, 754, 1673, 309, 815, 50650], "temperature": 0.0, "avg_logprob": -0.16208805084228517, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.0006664471002295613}, {"id": 333, "seek": 186478, "start": 1870.5, "end": 1875.86, "text": " be a very, very complex reducible property. That's something about our model of colors.", "tokens": [50650, 312, 257, 588, 11, 588, 3997, 2783, 32128, 4707, 13, 663, 311, 746, 466, 527, 2316, 295, 4577, 13, 50918], "temperature": 0.0, "avg_logprob": -0.16208805084228517, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.0006664471002295613}, {"id": 334, "seek": 186478, "start": 1875.86, "end": 1881.18, "text": " The philosopher Wolfgang Schwartz tried to make an analogy with sensor variables in,", "tokens": [50918, 440, 29805, 16634, 19619, 17576, 45929, 3031, 281, 652, 364, 21663, 365, 10200, 9102, 294, 11, 51184], "temperature": 0.0, "avg_logprob": -0.16208805084228517, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.0006664471002295613}, {"id": 335, "seek": 186478, "start": 1881.18, "end": 1886.66, "text": " say, image processing. You've got some visual sensors and a camera or something. You need", "tokens": [51184, 584, 11, 3256, 9007, 13, 509, 600, 658, 512, 5056, 14840, 293, 257, 2799, 420, 746, 13, 509, 643, 51458], "temperature": 0.0, "avg_logprob": -0.16208805084228517, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.0006664471002295613}, {"id": 336, "seek": 186478, "start": 1886.66, "end": 1892.3, "text": " to process the image. Well, you've got some variables, some sensor variables to represent", "tokens": [51458, 281, 1399, 264, 3256, 13, 1042, 11, 291, 600, 658, 512, 9102, 11, 512, 10200, 9102, 281, 2906, 51740], "temperature": 0.0, "avg_logprob": -0.16208805084228517, "compression_ratio": 1.7042801556420233, "no_speech_prob": 0.0006664471002295613}, {"id": 337, "seek": 189230, "start": 1892.3, "end": 1895.62, "text": " the sensory inputs that the various sensors are getting. And you might treat them as a", "tokens": [50364, 264, 27233, 15743, 300, 264, 3683, 14840, 366, 1242, 13, 400, 291, 1062, 2387, 552, 382, 257, 50530], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 338, "seek": 189230, "start": 1895.62, "end": 1899.1, "text": " primitive dimension because that's the most useful way to treat them. You don't treat", "tokens": [50530, 28540, 10139, 570, 300, 311, 264, 881, 4420, 636, 281, 2387, 552, 13, 509, 500, 380, 2387, 50704], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 339, "seek": 189230, "start": 1899.1, "end": 1904.4199999999998, "text": " them as certain amounts of lights or photons firing. You don't need to know about that.", "tokens": [50704, 552, 382, 1629, 11663, 295, 5811, 420, 40209, 16045, 13, 509, 500, 380, 643, 281, 458, 466, 300, 13, 50970], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 340, "seek": 189230, "start": 1904.4199999999998, "end": 1909.5, "text": " Use these sensor variables and treat them as a primitive dimension. And all that will", "tokens": [50970, 8278, 613, 10200, 9102, 293, 2387, 552, 382, 257, 28540, 10139, 13, 400, 439, 300, 486, 51224], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 341, "seek": 189230, "start": 1909.5, "end": 1914.26, "text": " play into a model of these things as primitive. Maybe taking that idea and extending it to", "tokens": [51224, 862, 666, 257, 2316, 295, 613, 721, 382, 28540, 13, 2704, 1940, 300, 1558, 293, 24360, 309, 281, 51462], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 342, "seek": 189230, "start": 1914.26, "end": 1920.82, "text": " introspection, you know, somehow these conscious states are somehow like sensor variables in", "tokens": [51462, 560, 2635, 19997, 11, 291, 458, 11, 6063, 613, 6648, 4368, 366, 6063, 411, 10200, 9102, 294, 51790], "temperature": 0.0, "avg_logprob": -0.13567492921473617, "compression_ratio": 1.9272727272727272, "no_speech_prob": 0.024404063820838928}, {"id": 343, "seek": 192082, "start": 1920.82, "end": 1927.4199999999998, "text": " our model of the mind. And somehow these internal models give us the sense of being acquainted", "tokens": [50364, 527, 2316, 295, 264, 1575, 13, 400, 6063, 613, 6920, 5245, 976, 505, 264, 2020, 295, 885, 50224, 50694], "temperature": 0.0, "avg_logprob": -0.13633321601653767, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0034819734282791615}, {"id": 344, "seek": 192082, "start": 1927.4199999999998, "end": 1933.1799999999998, "text": " with primitive concrete qualities and of our awareness of them. This is still just laying", "tokens": [50694, 365, 28540, 9859, 16477, 293, 295, 527, 8888, 295, 552, 13, 639, 307, 920, 445, 14903, 50982], "temperature": 0.0, "avg_logprob": -0.13633321601653767, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0034819734282791615}, {"id": 345, "seek": 192082, "start": 1933.1799999999998, "end": 1937.1399999999999, "text": " out. I don't think this is still yet actually explaining a whole lot, but it's laying out.", "tokens": [50982, 484, 13, 286, 500, 380, 519, 341, 307, 920, 1939, 767, 13468, 257, 1379, 688, 11, 457, 309, 311, 14903, 484, 13, 51180], "temperature": 0.0, "avg_logprob": -0.13633321601653767, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0034819734282791615}, {"id": 346, "seek": 192082, "start": 1937.1399999999999, "end": 1942.22, "text": " It's narrowing down what it is that we need to explain to solve the meta problem. But", "tokens": [51180, 467, 311, 9432, 278, 760, 437, 309, 307, 300, 321, 643, 281, 2903, 281, 5039, 264, 19616, 1154, 13, 583, 51434], "temperature": 0.0, "avg_logprob": -0.13633321601653767, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0034819734282791615}, {"id": 347, "seek": 192082, "start": 1942.22, "end": 1945.82, "text": " just to put the pieces together, here's a little summary. One thing I like about this", "tokens": [51434, 445, 281, 829, 264, 3755, 1214, 11, 510, 311, 257, 707, 12691, 13, 1485, 551, 286, 411, 466, 341, 51614], "temperature": 0.0, "avg_logprob": -0.13633321601653767, "compression_ratio": 1.6679104477611941, "no_speech_prob": 0.0034819734282791615}, {"id": 348, "seek": 194582, "start": 1945.82, "end": 1952.96, "text": " summary is you can read it in either an illusionist tone of voice as an account of the illusion", "tokens": [50364, 12691, 307, 291, 393, 1401, 309, 294, 2139, 364, 18854, 468, 8027, 295, 3177, 382, 364, 2696, 295, 264, 18854, 50721], "temperature": 0.0, "avg_logprob": -0.1106684649432147, "compression_ratio": 1.9350649350649352, "no_speech_prob": 0.03840406984090805}, {"id": 349, "seek": 194582, "start": 1952.96, "end": 1958.22, "text": " of consciousness. All this is how our false introspective models work or in a realist", "tokens": [50721, 295, 10081, 13, 1057, 341, 307, 577, 527, 7908, 560, 28713, 488, 5245, 589, 420, 294, 257, 957, 468, 50984], "temperature": 0.0, "avg_logprob": -0.1106684649432147, "compression_ratio": 1.9350649350649352, "no_speech_prob": 0.03840406984090805}, {"id": 350, "seek": 194582, "start": 1958.22, "end": 1965.54, "text": " tone of voice as an account of our true, correct models of consciousness. But we can set it", "tokens": [50984, 8027, 295, 3177, 382, 364, 2696, 295, 527, 2074, 11, 3006, 5245, 295, 10081, 13, 583, 321, 393, 992, 309, 51350], "temperature": 0.0, "avg_logprob": -0.1106684649432147, "compression_ratio": 1.9350649350649352, "no_speech_prob": 0.03840406984090805}, {"id": 351, "seek": 194582, "start": 1965.54, "end": 1969.1399999999999, "text": " out in a way which is neutral on the two and then try and figure out later whether these", "tokens": [51350, 484, 294, 257, 636, 597, 307, 10598, 322, 264, 732, 293, 550, 853, 293, 2573, 484, 1780, 1968, 613, 51530], "temperature": 0.0, "avg_logprob": -0.1106684649432147, "compression_ratio": 1.9350649350649352, "no_speech_prob": 0.03840406984090805}, {"id": 352, "seek": 194582, "start": 1969.1399999999999, "end": 1975.22, "text": " models are correct as the realist says or incorrect as the illusionist says. We have", "tokens": [51530, 5245, 366, 3006, 382, 264, 957, 468, 1619, 420, 18424, 382, 264, 18854, 468, 1619, 13, 492, 362, 51834], "temperature": 0.0, "avg_logprob": -0.1106684649432147, "compression_ratio": 1.9350649350649352, "no_speech_prob": 0.03840406984090805}, {"id": 353, "seek": 197522, "start": 1975.22, "end": 1982.6200000000001, "text": " introspective models deploying introspective concepts of our internal states that are largely", "tokens": [50364, 560, 28713, 488, 5245, 34198, 560, 28713, 488, 10392, 295, 527, 6920, 4368, 300, 366, 11611, 50734], "temperature": 0.0, "avg_logprob": -0.13671377260391027, "compression_ratio": 1.9187817258883249, "no_speech_prob": 0.00015345313295256346}, {"id": 354, "seek": 197522, "start": 1982.6200000000001, "end": 1989.18, "text": " independent of our physical concepts. These concepts are introspectively opaque, not revealing", "tokens": [50734, 6695, 295, 527, 4001, 10392, 13, 1981, 10392, 366, 560, 28713, 3413, 42687, 11, 406, 23983, 51062], "temperature": 0.0, "avg_logprob": -0.13671377260391027, "compression_ratio": 1.9187817258883249, "no_speech_prob": 0.00015345313295256346}, {"id": 355, "seek": 197522, "start": 1989.18, "end": 1995.54, "text": " any of the underlying mechanisms, our perceptual models perceptually attribute primitive perceptual", "tokens": [51062, 604, 295, 264, 14217, 15902, 11, 527, 43276, 901, 5245, 43276, 671, 19667, 28540, 43276, 901, 51380], "temperature": 0.0, "avg_logprob": -0.13671377260391027, "compression_ratio": 1.9187817258883249, "no_speech_prob": 0.00015345313295256346}, {"id": 356, "seek": 197522, "start": 1995.54, "end": 2002.7, "text": " qualities to the world, and our introspective models attribute primitive mental relations", "tokens": [51380, 16477, 281, 264, 1002, 11, 293, 527, 560, 28713, 488, 5245, 19667, 28540, 4973, 2299, 51738], "temperature": 0.0, "avg_logprob": -0.13671377260391027, "compression_ratio": 1.9187817258883249, "no_speech_prob": 0.00015345313295256346}, {"id": 357, "seek": 200270, "start": 2002.78, "end": 2009.98, "text": " to those qualities. These models produce the sense of acquaintance both with those qualities", "tokens": [50368, 281, 729, 16477, 13, 1981, 5245, 5258, 264, 2020, 295, 36954, 719, 1293, 365, 729, 16477, 50728], "temperature": 0.0, "avg_logprob": -0.13608452059187978, "compression_ratio": 1.75390625, "no_speech_prob": 0.01688024215400219}, {"id": 358, "seek": 200270, "start": 2009.98, "end": 2015.7, "text": " and with our awareness of those qualities. Like I said, this is not a solution to the", "tokens": [50728, 293, 365, 527, 8888, 295, 729, 16477, 13, 1743, 286, 848, 11, 341, 307, 406, 257, 3827, 281, 264, 51014], "temperature": 0.0, "avg_logprob": -0.13608452059187978, "compression_ratio": 1.75390625, "no_speech_prob": 0.01688024215400219}, {"id": 359, "seek": 200270, "start": 2015.7, "end": 2020.5800000000002, "text": " meta problem, but it's trying at least to pin down some parts of the roots of those", "tokens": [51014, 19616, 1154, 11, 457, 309, 311, 1382, 412, 1935, 281, 5447, 760, 512, 3166, 295, 264, 10669, 295, 729, 51258], "temperature": 0.0, "avg_logprob": -0.13608452059187978, "compression_ratio": 1.75390625, "no_speech_prob": 0.01688024215400219}, {"id": 360, "seek": 200270, "start": 2020.5800000000002, "end": 2026.06, "text": " intuitions and to narrow down what needs to be explained. To go further, you want, I think,", "tokens": [51258, 16224, 626, 293, 281, 9432, 760, 437, 2203, 281, 312, 8825, 13, 1407, 352, 3052, 11, 291, 528, 11, 286, 519, 11, 51532], "temperature": 0.0, "avg_logprob": -0.13608452059187978, "compression_ratio": 1.75390625, "no_speech_prob": 0.01688024215400219}, {"id": 361, "seek": 200270, "start": 2026.06, "end": 2031.5800000000002, "text": " to test these explanations, both with psychological studies to see if this is plausibly what's", "tokens": [51532, 281, 1500, 613, 28708, 11, 1293, 365, 14346, 5313, 281, 536, 498, 341, 307, 34946, 3545, 437, 311, 51808], "temperature": 0.0, "avg_logprob": -0.13608452059187978, "compression_ratio": 1.75390625, "no_speech_prob": 0.01688024215400219}, {"id": 362, "seek": 203158, "start": 2031.58, "end": 2036.34, "text": " going on in humans. This is the kind of thing which is the basis of our intuitions and computational", "tokens": [50364, 516, 322, 294, 6255, 13, 639, 307, 264, 733, 295, 551, 597, 307, 264, 5143, 295, 527, 16224, 626, 293, 28270, 50602], "temperature": 0.0, "avg_logprob": -0.14789720618206523, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0002867481380235404}, {"id": 363, "seek": 203158, "start": 2036.34, "end": 2040.5, "text": " models to see if, for example, you could program this kind of thing into an AI system and see", "tokens": [50602, 5245, 281, 536, 498, 11, 337, 1365, 11, 291, 727, 1461, 341, 733, 295, 551, 666, 364, 7318, 1185, 293, 536, 50810], "temperature": 0.0, "avg_logprob": -0.14789720618206523, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0002867481380235404}, {"id": 364, "seek": 203158, "start": 2040.5, "end": 2047.1399999999999, "text": " if it can generate somehow qualitatively similar reports and intuitions. You might think that", "tokens": [50810, 498, 309, 393, 8460, 6063, 31312, 356, 2531, 7122, 293, 16224, 626, 13, 509, 1062, 519, 300, 51142], "temperature": 0.0, "avg_logprob": -0.14789720618206523, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0002867481380235404}, {"id": 365, "seek": 203158, "start": 2047.1399999999999, "end": 2052.5, "text": " last thing is a bit far-fetched right now, but I know of at least one instance of this", "tokens": [51142, 1036, 551, 307, 257, 857, 1400, 12, 69, 7858, 292, 558, 586, 11, 457, 286, 458, 295, 412, 1935, 472, 5197, 295, 341, 51410], "temperature": 0.0, "avg_logprob": -0.14789720618206523, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0002867481380235404}, {"id": 366, "seek": 203158, "start": 2052.5, "end": 2058.66, "text": " research program which has been put into play by Luke Milhauser and Bach Schleggeres, two", "tokens": [51410, 2132, 1461, 597, 575, 668, 829, 666, 862, 538, 13044, 7036, 1641, 18088, 293, 30920, 2065, 6363, 1321, 279, 11, 732, 51718], "temperature": 0.0, "avg_logprob": -0.14789720618206523, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0002867481380235404}, {"id": 367, "seek": 205866, "start": 2058.7, "end": 2066.8599999999997, "text": " researchers at Open Philanthropy, very interested in AI and consciousness. They actually built,", "tokens": [50366, 10309, 412, 7238, 7777, 282, 14222, 88, 11, 588, 3102, 294, 7318, 293, 10081, 13, 814, 767, 3094, 11, 50774], "temperature": 0.0, "avg_logprob": -0.17334981711514025, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0009996377630159259}, {"id": 368, "seek": 205866, "start": 2066.8599999999997, "end": 2071.2999999999997, "text": " they took some ideas about the meta problem from something I'd written about it and from", "tokens": [50774, 436, 1890, 512, 3487, 466, 264, 19616, 1154, 490, 746, 286, 1116, 3720, 466, 309, 293, 490, 50996], "temperature": 0.0, "avg_logprob": -0.17334981711514025, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0009996377630159259}, {"id": 369, "seek": 205866, "start": 2071.2999999999997, "end": 2077.8999999999996, "text": " something that the philosopher Francois Camero had written about it. A couple of basic ideas about", "tokens": [50996, 746, 300, 264, 29805, 34695, 271, 6886, 2032, 632, 3720, 466, 309, 13, 316, 1916, 295, 3875, 3487, 466, 51326], "temperature": 0.0, "avg_logprob": -0.17334981711514025, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0009996377630159259}, {"id": 370, "seek": 205866, "start": 2077.8999999999996, "end": 2083.46, "text": " where problem intuitions might come from, and they tried to build them in to a computational", "tokens": [51326, 689, 1154, 16224, 626, 1062, 808, 490, 11, 293, 436, 3031, 281, 1322, 552, 294, 281, 257, 28270, 51604], "temperature": 0.0, "avg_logprob": -0.17334981711514025, "compression_ratio": 1.6491228070175439, "no_speech_prob": 0.0009996377630159259}, {"id": 371, "seek": 208346, "start": 2084.06, "end": 2092.98, "text": " model. They built a little software agent which had certain axioms about colors and how they", "tokens": [50394, 2316, 13, 814, 3094, 257, 707, 4722, 9461, 597, 632, 1629, 6360, 72, 4785, 466, 4577, 293, 577, 436, 50840], "temperature": 0.0, "avg_logprob": -0.1713239034016927, "compression_ratio": 1.8109452736318408, "no_speech_prob": 0.0027997882571071386}, {"id": 372, "seek": 208346, "start": 2092.98, "end": 2098.5, "text": " work. There's red and there's green, and certain axioms about their own subjective experiences", "tokens": [50840, 589, 13, 821, 311, 2182, 293, 456, 311, 3092, 11, 293, 1629, 6360, 72, 4785, 466, 641, 1065, 25972, 5235, 51116], "temperature": 0.0, "avg_logprob": -0.1713239034016927, "compression_ratio": 1.8109452736318408, "no_speech_prob": 0.0027997882571071386}, {"id": 373, "seek": 208346, "start": 2098.5, "end": 2106.18, "text": " of colors, and then they combined it with a little theorem prover, and they saw what did", "tokens": [51116, 295, 4577, 11, 293, 550, 436, 9354, 309, 365, 257, 707, 20904, 447, 331, 11, 293, 436, 1866, 437, 630, 51500], "temperature": 0.0, "avg_logprob": -0.1713239034016927, "compression_ratio": 1.8109452736318408, "no_speech_prob": 0.0027997882571071386}, {"id": 374, "seek": 208346, "start": 2106.18, "end": 2110.14, "text": " this little software agent come up with, and it came up with claims like, hey, well, my", "tokens": [51500, 341, 707, 4722, 9461, 808, 493, 365, 11, 293, 309, 1361, 493, 365, 9441, 411, 11, 4177, 11, 731, 11, 452, 51698], "temperature": 0.0, "avg_logprob": -0.1713239034016927, "compression_ratio": 1.8109452736318408, "no_speech_prob": 0.0027997882571071386}, {"id": 375, "seek": 211014, "start": 2111.1, "end": 2116.62, "text": " experiences of color are distinct from any physical state, and so on. They cut a few corners.", "tokens": [50412, 5235, 295, 2017, 366, 10644, 490, 604, 4001, 1785, 11, 293, 370, 322, 13, 814, 1723, 257, 1326, 12413, 13, 50688], "temperature": 0.0, "avg_logprob": -0.14082062521646188, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.00044394456199370325}, {"id": 376, "seek": 211014, "start": 2118.7, "end": 2125.8199999999997, "text": " This is not yet a truly convincing, sophisticated model of everything going on in the human mind,", "tokens": [50792, 639, 307, 406, 1939, 257, 4908, 24823, 11, 16950, 2316, 295, 1203, 516, 322, 294, 264, 1952, 1575, 11, 51148], "temperature": 0.0, "avg_logprob": -0.14082062521646188, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.00044394456199370325}, {"id": 377, "seek": 211014, "start": 2125.8199999999997, "end": 2131.42, "text": " but it shows that there's a research program here of trying to find the algorithmic basis", "tokens": [51148, 457, 309, 3110, 300, 456, 311, 257, 2132, 1461, 510, 295, 1382, 281, 915, 264, 9284, 299, 5143, 51428], "temperature": 0.0, "avg_logprob": -0.14082062521646188, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.00044394456199370325}, {"id": 378, "seek": 211014, "start": 2132.14, "end": 2137.2599999999998, "text": " of these states. I think as more sophisticated models develop, we might be able to use these", "tokens": [51464, 295, 613, 4368, 13, 286, 519, 382, 544, 16950, 5245, 1499, 11, 321, 1062, 312, 1075, 281, 764, 613, 51720], "temperature": 0.0, "avg_logprob": -0.14082062521646188, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.00044394456199370325}, {"id": 379, "seek": 213726, "start": 2137.34, "end": 2141.9, "text": " to provide a way in for AI researchers in thinking about this topic. Of course,", "tokens": [50368, 281, 2893, 257, 636, 294, 337, 7318, 10309, 294, 1953, 466, 341, 4829, 13, 2720, 1164, 11, 50596], "temperature": 0.0, "avg_logprob": -0.10456234675187331, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0006068971706554294}, {"id": 380, "seek": 213726, "start": 2141.9, "end": 2146.2200000000003, "text": " there is the question, if you model all this stuff better and better in a machine,", "tokens": [50596, 456, 307, 264, 1168, 11, 498, 291, 2316, 439, 341, 1507, 1101, 293, 1101, 294, 257, 3479, 11, 50812], "temperature": 0.0, "avg_logprob": -0.10456234675187331, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0006068971706554294}, {"id": 381, "seek": 213726, "start": 2146.2200000000003, "end": 2151.0200000000004, "text": " then is the machine actually going to be conscious, or is it just going to have found", "tokens": [50812, 550, 307, 264, 3479, 767, 516, 281, 312, 6648, 11, 420, 307, 309, 445, 516, 281, 362, 1352, 51052], "temperature": 0.0, "avg_logprob": -0.10456234675187331, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0006068971706554294}, {"id": 382, "seek": 213726, "start": 2151.0200000000004, "end": 2158.46, "text": " self-models that replicate what's going on in humans? Some people have proposed an artificial", "tokens": [51052, 2698, 12, 8014, 1625, 300, 25356, 437, 311, 516, 322, 294, 6255, 30, 2188, 561, 362, 10348, 364, 11677, 51424], "temperature": 0.0, "avg_logprob": -0.10456234675187331, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0006068971706554294}, {"id": 383, "seek": 213726, "start": 2158.46, "end": 2166.1400000000003, "text": " consciousness test. Aaron Sloman, Susan Snyder, and Turner have suggested somehow that if a machine", "tokens": [51424, 10081, 1500, 13, 14018, 6187, 4277, 11, 15160, 49464, 1068, 11, 293, 28950, 362, 10945, 6063, 300, 498, 257, 3479, 51808], "temperature": 0.0, "avg_logprob": -0.10456234675187331, "compression_ratio": 1.655430711610487, "no_speech_prob": 0.0006068971706554294}, {"id": 384, "seek": 216614, "start": 2166.22, "end": 2170.3799999999997, "text": " seems to be puzzled about consciousness in roughly the ways that we are,", "tokens": [50368, 2544, 281, 312, 18741, 1493, 466, 10081, 294, 9810, 264, 2098, 300, 321, 366, 11, 50576], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 385, "seek": 216614, "start": 2170.3799999999997, "end": 2176.8599999999997, "text": " maybe that's actually a sign that it's conscious. If a machine actually looks to ask", "tokens": [50576, 1310, 300, 311, 767, 257, 1465, 300, 309, 311, 6648, 13, 759, 257, 3479, 767, 1542, 281, 1029, 50900], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 386, "seek": 216614, "start": 2176.8599999999997, "end": 2182.14, "text": " as if it's puzzled by consciousness, is that a sign of consciousness? These people,", "tokens": [50900, 382, 498, 309, 311, 18741, 1493, 538, 10081, 11, 307, 300, 257, 1465, 295, 10081, 30, 1981, 561, 11, 51164], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 387, "seek": 216614, "start": 2182.14, "end": 2186.62, "text": " this is suggested as a kind of Turing test for machine consciousness. Find machines which are", "tokens": [51164, 341, 307, 10945, 382, 257, 733, 295, 314, 1345, 1500, 337, 3479, 10081, 13, 11809, 8379, 597, 366, 51388], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 388, "seek": 216614, "start": 2186.62, "end": 2190.14, "text": " conscious like we are. Of course, the opposing point of view is going to be, no, the machine is", "tokens": [51388, 6648, 411, 321, 366, 13, 2720, 1164, 11, 264, 27890, 935, 295, 1910, 307, 516, 281, 312, 11, 572, 11, 264, 3479, 307, 51564], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 389, "seek": 216614, "start": 2190.14, "end": 2195.3399999999997, "text": " not actually conscious. It's just like the machine that studied up for the Turing test by reading", "tokens": [51564, 406, 767, 6648, 13, 467, 311, 445, 411, 264, 3479, 300, 9454, 493, 337, 264, 314, 1345, 1500, 538, 3760, 51824], "temperature": 0.0, "avg_logprob": -0.08533318587175505, "compression_ratio": 1.9448529411764706, "no_speech_prob": 0.0005032367771491408}, {"id": 390, "seek": 219534, "start": 2195.34, "end": 2201.26, "text": " the talk like a human book. It's like, damn, do I really need to convince those humans that I'm", "tokens": [50364, 264, 751, 411, 257, 1952, 1446, 13, 467, 311, 411, 11, 8151, 11, 360, 286, 534, 643, 281, 13447, 729, 6255, 300, 286, 478, 50660], "temperature": 0.0, "avg_logprob": -0.0668696247298142, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.0009532392141409218}, {"id": 391, "seek": 219534, "start": 2201.26, "end": 2207.42, "text": " conscious by replicating all those ill-conceived confusions about consciousness? Well, I guess", "tokens": [50660, 6648, 538, 3248, 30541, 439, 729, 3171, 12, 1671, 384, 3194, 1497, 27255, 466, 10081, 30, 1042, 11, 286, 2041, 50968], "temperature": 0.0, "avg_logprob": -0.0668696247298142, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.0009532392141409218}, {"id": 392, "seek": 219534, "start": 2207.42, "end": 2213.34, "text": " I can do it if I need to. Anyway, I'm not going to settle this question here, but I do think that", "tokens": [50968, 286, 393, 360, 309, 498, 286, 643, 281, 13, 5684, 11, 286, 478, 406, 516, 281, 11852, 341, 1168, 510, 11, 457, 286, 360, 519, 300, 51264], "temperature": 0.0, "avg_logprob": -0.0668696247298142, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.0009532392141409218}, {"id": 393, "seek": 219534, "start": 2213.34, "end": 2219.26, "text": " if we somehow find machines being puzzled, it won't surprise me that once we actually have", "tokens": [51264, 498, 321, 6063, 915, 8379, 885, 18741, 1493, 11, 309, 1582, 380, 6365, 385, 300, 1564, 321, 767, 362, 51560], "temperature": 0.0, "avg_logprob": -0.0668696247298142, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.0009532392141409218}, {"id": 394, "seek": 219534, "start": 2219.26, "end": 2224.3, "text": " serious AI systems which engage in natural language and modeling of themselves in the world,", "tokens": [51560, 3156, 7318, 3652, 597, 4683, 294, 3303, 2856, 293, 15983, 295, 2969, 294, 264, 1002, 11, 51812], "temperature": 0.0, "avg_logprob": -0.0668696247298142, "compression_ratio": 1.6109215017064846, "no_speech_prob": 0.0009532392141409218}, {"id": 395, "seek": 222534, "start": 2225.42, "end": 2229.02, "text": " they might well be natural to find themselves saying things like, yeah, I know in principle I'm", "tokens": [50368, 436, 1062, 731, 312, 3303, 281, 915, 2969, 1566, 721, 411, 11, 1338, 11, 286, 458, 294, 8665, 286, 478, 50548], "temperature": 0.0, "avg_logprob": -0.08864370122686163, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.00016340507136192173}, {"id": 396, "seek": 222534, "start": 2229.02, "end": 2236.46, "text": " just a set of silicon circuits, but I feel like so much more. I think that might tell us something", "tokens": [50548, 445, 257, 992, 295, 22848, 26354, 11, 457, 286, 841, 411, 370, 709, 544, 13, 286, 519, 300, 1062, 980, 505, 746, 50920], "temperature": 0.0, "avg_logprob": -0.08864370122686163, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.00016340507136192173}, {"id": 397, "seek": 222534, "start": 2236.46, "end": 2243.58, "text": " about consciousness. Let me just say a little bit about theories of consciousness. I do think a", "tokens": [50920, 466, 10081, 13, 961, 385, 445, 584, 257, 707, 857, 466, 13667, 295, 10081, 13, 286, 360, 519, 257, 51276], "temperature": 0.0, "avg_logprob": -0.08864370122686163, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.00016340507136192173}, {"id": 398, "seek": 222534, "start": 2243.58, "end": 2249.02, "text": " solution to the meta problem and a solution to the hard problem ought to be closely connected.", "tokens": [51276, 3827, 281, 264, 19616, 1154, 293, 257, 3827, 281, 264, 1152, 1154, 13416, 281, 312, 8185, 4582, 13, 51548], "temperature": 0.0, "avg_logprob": -0.08864370122686163, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.00016340507136192173}, {"id": 399, "seek": 222534, "start": 2249.02, "end": 2252.86, "text": " The illusionist says, solve the meta problem. You'll dissolve the hard problem. But even if", "tokens": [51548, 440, 18854, 468, 1619, 11, 5039, 264, 19616, 1154, 13, 509, 603, 30150, 264, 1152, 1154, 13, 583, 754, 498, 51740], "temperature": 0.0, "avg_logprob": -0.08864370122686163, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.00016340507136192173}, {"id": 400, "seek": 225286, "start": 2252.86, "end": 2259.34, "text": " you're not an illusionist about consciousness, there ought to be some link. So here's a thesis.", "tokens": [50364, 291, 434, 406, 364, 18854, 468, 466, 10081, 11, 456, 13416, 281, 312, 512, 2113, 13, 407, 510, 311, 257, 22288, 13, 50688], "temperature": 0.0, "avg_logprob": -0.08694339727426505, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00024146460054907948}, {"id": 401, "seek": 225286, "start": 2259.34, "end": 2265.6600000000003, "text": " Whatever explains consciousness should also partly explain our judgments and our reports", "tokens": [50688, 8541, 13948, 10081, 820, 611, 17031, 2903, 527, 40337, 293, 527, 7122, 51004], "temperature": 0.0, "avg_logprob": -0.08694339727426505, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00024146460054907948}, {"id": 402, "seek": 225286, "start": 2266.3, "end": 2270.6200000000003, "text": " about consciousness. The rationale here is it would just be very strange if these things were", "tokens": [51036, 466, 10081, 13, 440, 41989, 510, 307, 309, 576, 445, 312, 588, 5861, 498, 613, 721, 645, 51252], "temperature": 0.0, "avg_logprob": -0.08694339727426505, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00024146460054907948}, {"id": 403, "seek": 225286, "start": 2271.1800000000003, "end": 2278.6200000000003, "text": " independent. If the basis of consciousness played no role in our judgments about consciousness.", "tokens": [51280, 6695, 13, 759, 264, 5143, 295, 10081, 3737, 572, 3090, 294, 527, 40337, 466, 10081, 13, 51652], "temperature": 0.0, "avg_logprob": -0.08694339727426505, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00024146460054907948}, {"id": 404, "seek": 227862, "start": 2279.3399999999997, "end": 2285.8199999999997, "text": " So I think you can use this as a way of evaluating or testing theories of consciousness. For theory", "tokens": [50400, 407, 286, 519, 291, 393, 764, 341, 382, 257, 636, 295, 27479, 420, 4997, 13667, 295, 10081, 13, 1171, 5261, 50724], "temperature": 0.0, "avg_logprob": -0.1186912226122479, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.00021649972768500447}, {"id": 405, "seek": 227862, "start": 2285.8199999999997, "end": 2291.9, "text": " of consciousness, there's mechanism M is the basis of consciousness, that M should also partly", "tokens": [50724, 295, 10081, 11, 456, 311, 7513, 376, 307, 264, 5143, 295, 10081, 11, 300, 376, 820, 611, 17031, 51028], "temperature": 0.0, "avg_logprob": -0.1186912226122479, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.00021649972768500447}, {"id": 406, "seek": 227862, "start": 2291.9, "end": 2298.7, "text": " explain our judgments about consciousness. Whatever the basis is ought to explain the reports.", "tokens": [51028, 2903, 527, 40337, 466, 10081, 13, 8541, 264, 5143, 307, 13416, 281, 2903, 264, 7122, 13, 51368], "temperature": 0.0, "avg_logprob": -0.1186912226122479, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.00021649972768500447}, {"id": 407, "seek": 227862, "start": 2298.7, "end": 2304.38, "text": " And you can use this. You can bring this to bear on various extant theories of consciousness. Here's", "tokens": [51368, 400, 291, 393, 764, 341, 13, 509, 393, 1565, 341, 281, 6155, 322, 3683, 1279, 394, 13667, 295, 10081, 13, 1692, 311, 51652], "temperature": 0.0, "avg_logprob": -0.1186912226122479, "compression_ratio": 1.8660287081339713, "no_speech_prob": 0.00021649972768500447}, {"id": 408, "seek": 230438, "start": 2304.46, "end": 2310.06, "text": " one famous current theory of consciousness, integrated information theory developed by", "tokens": [50368, 472, 4618, 2190, 5261, 295, 10081, 11, 10919, 1589, 5261, 4743, 538, 50648], "temperature": 0.0, "avg_logprob": -0.11570248046478668, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0007309268112294376}, {"id": 409, "seek": 230438, "start": 2310.06, "end": 2318.7000000000003, "text": " Giulio Tononi and colleagues at the University of Wisconsin. Tononi says the basis of consciousness", "tokens": [50648, 38679, 1004, 11385, 17049, 293, 7734, 412, 264, 3535, 295, 17977, 13, 11385, 17049, 1619, 264, 5143, 295, 10081, 51080], "temperature": 0.0, "avg_logprob": -0.11570248046478668, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0007309268112294376}, {"id": 410, "seek": 230438, "start": 2318.7000000000003, "end": 2325.26, "text": " is integrated information. A certain kind of integration of information for which Tononi", "tokens": [51080, 307, 10919, 1589, 13, 316, 1629, 733, 295, 10980, 295, 1589, 337, 597, 11385, 17049, 51408], "temperature": 0.0, "avg_logprob": -0.11570248046478668, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0007309268112294376}, {"id": 411, "seek": 230438, "start": 2325.26, "end": 2330.86, "text": " has a measure that he calls phi. Basically, when your phi is high enough, you get consciousness.", "tokens": [51408, 575, 257, 3481, 300, 415, 5498, 13107, 13, 8537, 11, 562, 428, 13107, 307, 1090, 1547, 11, 291, 483, 10081, 13, 51688], "temperature": 0.0, "avg_logprob": -0.11570248046478668, "compression_ratio": 1.7799043062200957, "no_speech_prob": 0.0007309268112294376}, {"id": 412, "seek": 233086, "start": 2330.94, "end": 2336.2200000000003, "text": " So consciousness is high phi. And there's a mathematical definition, but I won't go into", "tokens": [50368, 407, 10081, 307, 1090, 13107, 13, 400, 456, 311, 257, 18894, 7123, 11, 457, 286, 1582, 380, 352, 666, 50632], "temperature": 0.0, "avg_logprob": -0.14416363917359518, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.0005702182534150779}, {"id": 413, "seek": 233086, "start": 2336.2200000000003, "end": 2342.54, "text": " it here. But such a really interesting theory. So here's a, basically it analyzes a network", "tokens": [50632, 309, 510, 13, 583, 1270, 257, 534, 1880, 5261, 13, 407, 510, 311, 257, 11, 1936, 309, 6459, 12214, 257, 3209, 50948], "temperature": 0.0, "avg_logprob": -0.14416363917359518, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.0005702182534150779}, {"id": 414, "seek": 233086, "start": 2342.54, "end": 2348.1400000000003, "text": " property of systems, of units, and it's got an informational measure called phi that's supposed", "tokens": [50948, 4707, 295, 3652, 11, 295, 6815, 11, 293, 309, 311, 658, 364, 49391, 3481, 1219, 13107, 300, 311, 3442, 51228], "temperature": 0.0, "avg_logprob": -0.14416363917359518, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.0005702182534150779}, {"id": 415, "seek": 233086, "start": 2348.1400000000003, "end": 2354.7000000000003, "text": " to go with consciousness. Question. How does, if integrated information is the basis of consciousness,", "tokens": [51228, 281, 352, 365, 10081, 13, 14464, 13, 1012, 775, 11, 498, 10919, 1589, 307, 264, 5143, 295, 10081, 11, 51556], "temperature": 0.0, "avg_logprob": -0.14416363917359518, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.0005702182534150779}, {"id": 416, "seek": 233086, "start": 2354.7000000000003, "end": 2360.06, "text": " it ought to explain problem reports, at least in principle. Challenge. How does that work?", "tokens": [51556, 309, 13416, 281, 2903, 1154, 7122, 11, 412, 1935, 294, 8665, 13, 17517, 13, 1012, 775, 300, 589, 30, 51824], "temperature": 0.0, "avg_logprob": -0.14416363917359518, "compression_ratio": 1.6906474820143884, "no_speech_prob": 0.0005702182534150779}, {"id": 417, "seek": 236006, "start": 2360.06, "end": 2365.18, "text": " And it's at least far from obvious to me how integrated information will explain the problem", "tokens": [50364, 400, 309, 311, 412, 1935, 1400, 490, 6322, 281, 385, 577, 10919, 1589, 486, 2903, 264, 1154, 50620], "temperature": 0.0, "avg_logprob": -0.08045553077350963, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.00023409783898387104}, {"id": 418, "seek": 236006, "start": 2365.18, "end": 2371.58, "text": " reports. It seems pretty dissociated from them. I mean, on Tononi's view, you can have simulations", "tokens": [50620, 7122, 13, 467, 2544, 1238, 44446, 770, 490, 552, 13, 286, 914, 11, 322, 11385, 17049, 311, 1910, 11, 291, 393, 362, 35138, 50940], "temperature": 0.0, "avg_logprob": -0.08045553077350963, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.00023409783898387104}, {"id": 419, "seek": 236006, "start": 2372.22, "end": 2378.46, "text": " of systems with high phi that have zero phi. They'll go about making exactly the same reports,", "tokens": [50972, 295, 3652, 365, 1090, 13107, 300, 362, 4018, 13107, 13, 814, 603, 352, 466, 1455, 2293, 264, 912, 7122, 11, 51284], "temperature": 0.0, "avg_logprob": -0.08045553077350963, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.00023409783898387104}, {"id": 420, "seek": 236006, "start": 2378.46, "end": 2383.74, "text": " but without consciousness at all. So phi is at least somewhat dissociable. You get systems", "tokens": [51284, 457, 1553, 10081, 412, 439, 13, 407, 13107, 307, 412, 1935, 8344, 44446, 712, 13, 509, 483, 3652, 51548], "temperature": 0.0, "avg_logprob": -0.08045553077350963, "compression_ratio": 1.5774058577405858, "no_speech_prob": 0.00023409783898387104}, {"id": 421, "seek": 238374, "start": 2383.8199999999997, "end": 2390.4599999999996, "text": " very high phi, but no tendency to report. Maybe that's less worrying. Anyway, here's a challenge", "tokens": [50368, 588, 1090, 13107, 11, 457, 572, 18187, 281, 2275, 13, 2704, 300, 311, 1570, 18788, 13, 5684, 11, 510, 311, 257, 3430, 50700], "temperature": 0.0, "avg_logprob": -0.090915770757766, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.0026721160393208265}, {"id": 422, "seek": 238374, "start": 2390.4599999999996, "end": 2395.02, "text": " for this theory, for other theories. Explain not just how high phi gives you consciousness,", "tokens": [50700, 337, 341, 5261, 11, 337, 661, 13667, 13, 39574, 406, 445, 577, 1090, 13107, 2709, 291, 10081, 11, 50928], "temperature": 0.0, "avg_logprob": -0.090915770757766, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.0026721160393208265}, {"id": 423, "seek": 238374, "start": 2395.02, "end": 2401.1, "text": " but how it plays a central role in the algorithms that generate problem reports. Something similar", "tokens": [50928, 457, 577, 309, 5749, 257, 5777, 3090, 294, 264, 14642, 300, 8460, 1154, 7122, 13, 6595, 2531, 51232], "temperature": 0.0, "avg_logprob": -0.090915770757766, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.0026721160393208265}, {"id": 424, "seek": 238374, "start": 2401.1, "end": 2407.74, "text": " goes for many other theories, biological theories, quantum theories, global workspace, and so on.", "tokens": [51232, 1709, 337, 867, 661, 13667, 11, 13910, 13667, 11, 13018, 13667, 11, 4338, 32706, 11, 293, 370, 322, 13, 51564], "temperature": 0.0, "avg_logprob": -0.090915770757766, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.0026721160393208265}, {"id": 425, "seek": 238374, "start": 2408.54, "end": 2413.5, "text": " But let me just wrap up by saying something about the issue of illusionism that I was", "tokens": [51604, 583, 718, 385, 445, 7019, 493, 538, 1566, 746, 466, 264, 2734, 295, 18854, 1434, 300, 286, 390, 51852], "temperature": 0.0, "avg_logprob": -0.090915770757766, "compression_ratio": 1.6643109540636043, "no_speech_prob": 0.0026721160393208265}, {"id": 426, "seek": 241374, "start": 2413.74, "end": 2419.02, "text": " talking about near the start. Again, you might be inclined to think that this approach through", "tokens": [50364, 1417, 466, 2651, 264, 722, 13, 3764, 11, 291, 1062, 312, 28173, 281, 519, 300, 341, 3109, 807, 50628], "temperature": 0.0, "avg_logprob": -0.0861653706123089, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0005269779358059168}, {"id": 427, "seek": 241374, "start": 2419.02, "end": 2423.9799999999996, "text": " the meta problem tends, at least very naturally, to lead to illusionism. And I think it can be,", "tokens": [50628, 264, 19616, 1154, 12258, 11, 412, 1935, 588, 8195, 11, 281, 1477, 281, 18854, 1434, 13, 400, 286, 519, 309, 393, 312, 11, 50876], "temperature": 0.0, "avg_logprob": -0.0861653706123089, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0005269779358059168}, {"id": 428, "seek": 241374, "start": 2424.62, "end": 2429.74, "text": " it certainly provides, I think, some motivation for illusionism. The view that consciousness", "tokens": [50908, 309, 3297, 6417, 11, 286, 519, 11, 512, 12335, 337, 18854, 1434, 13, 440, 1910, 300, 10081, 51164], "temperature": 0.0, "avg_logprob": -0.0861653706123089, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0005269779358059168}, {"id": 429, "seek": 241374, "start": 2429.74, "end": 2436.22, "text": " doesn't exist, we just think it does. On this view, again, a solution to the meta problem dissolves", "tokens": [51164, 1177, 380, 2514, 11, 321, 445, 519, 309, 775, 13, 1282, 341, 1910, 11, 797, 11, 257, 3827, 281, 264, 19616, 1154, 15840, 977, 51488], "temperature": 0.0, "avg_logprob": -0.0861653706123089, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0005269779358059168}, {"id": 430, "seek": 241374, "start": 2436.7799999999997, "end": 2443.58, "text": " the hard problem. So here's one way of putting the case for illusionism. If there's a solution", "tokens": [51516, 264, 1152, 1154, 13, 407, 510, 311, 472, 636, 295, 3372, 264, 1389, 337, 18854, 1434, 13, 759, 456, 311, 257, 3827, 51856], "temperature": 0.0, "avg_logprob": -0.0861653706123089, "compression_ratio": 1.7638376383763839, "no_speech_prob": 0.0005269779358059168}, {"id": 431, "seek": 244358, "start": 2443.58, "end": 2448.7, "text": " to the meta problem, then there's an explanation of our beliefs about consciousness that's", "tokens": [50364, 281, 264, 19616, 1154, 11, 550, 456, 311, 364, 10835, 295, 527, 13585, 466, 10081, 300, 311, 50620], "temperature": 0.0, "avg_logprob": -0.07922829234081766, "compression_ratio": 2.0727272727272728, "no_speech_prob": 0.0002957460528705269}, {"id": 432, "seek": 244358, "start": 2448.7, "end": 2452.86, "text": " independent of consciousness. There's an algorithm that explains our beliefs about", "tokens": [50620, 6695, 295, 10081, 13, 821, 311, 364, 9284, 300, 13948, 527, 13585, 466, 50828], "temperature": 0.0, "avg_logprob": -0.07922829234081766, "compression_ratio": 2.0727272727272728, "no_speech_prob": 0.0002957460528705269}, {"id": 433, "seek": 244358, "start": 2452.86, "end": 2457.2599999999998, "text": " consciousness, doesn't mention consciousness, arguably could be in place without consciousness.", "tokens": [50828, 10081, 11, 1177, 380, 2152, 10081, 11, 26771, 727, 312, 294, 1081, 1553, 10081, 13, 51048], "temperature": 0.0, "avg_logprob": -0.07922829234081766, "compression_ratio": 2.0727272727272728, "no_speech_prob": 0.0002957460528705269}, {"id": 434, "seek": 244358, "start": 2457.8199999999997, "end": 2464.2999999999997, "text": " Arguably, that kind of explanation could debunk our beliefs about consciousness the same way that,", "tokens": [51076, 48560, 1188, 11, 300, 733, 295, 10835, 727, 3001, 3197, 527, 13585, 466, 10081, 264, 912, 636, 300, 11, 51400], "temperature": 0.0, "avg_logprob": -0.07922829234081766, "compression_ratio": 2.0727272727272728, "no_speech_prob": 0.0002957460528705269}, {"id": 435, "seek": 244358, "start": 2464.2999999999997, "end": 2470.54, "text": " perhaps, explaining beliefs about God in evolutionary terms might debunk belief in God.", "tokens": [51400, 4317, 11, 13468, 13585, 466, 1265, 294, 27567, 2115, 1062, 3001, 3197, 7107, 294, 1265, 13, 51712], "temperature": 0.0, "avg_logprob": -0.07922829234081766, "compression_ratio": 2.0727272727272728, "no_speech_prob": 0.0002957460528705269}, {"id": 436, "seek": 247054, "start": 2470.54, "end": 2474.22, "text": " It certainly doesn't prove that God doesn't exist. You might think that if you can explain", "tokens": [50364, 467, 3297, 1177, 380, 7081, 300, 1265, 1177, 380, 2514, 13, 509, 1062, 519, 300, 498, 291, 393, 2903, 50548], "temperature": 0.0, "avg_logprob": -0.06751498388587882, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0002611071686260402}, {"id": 437, "seek": 247054, "start": 2474.22, "end": 2480.3, "text": " our beliefs in terms of evolution, it somehow removes the justification or the rational basis", "tokens": [50548, 527, 13585, 294, 2115, 295, 9303, 11, 309, 6063, 30445, 264, 31591, 420, 264, 15090, 5143, 50852], "temperature": 0.0, "avg_logprob": -0.06751498388587882, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0002611071686260402}, {"id": 438, "seek": 247054, "start": 2480.3, "end": 2484.7799999999997, "text": " for those beliefs. So something like that, I think, can be applied to consciousness, too. And", "tokens": [50852, 337, 729, 13585, 13, 407, 746, 411, 300, 11, 286, 519, 11, 393, 312, 6456, 281, 10081, 11, 886, 13, 400, 51076], "temperature": 0.0, "avg_logprob": -0.06751498388587882, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0002611071686260402}, {"id": 439, "seek": 247054, "start": 2484.7799999999997, "end": 2490.46, "text": " there's a lot to be said about analyzing the extent to which this might debunk the beliefs.", "tokens": [51076, 456, 311, 257, 688, 281, 312, 848, 466, 23663, 264, 8396, 281, 597, 341, 1062, 3001, 3197, 264, 13585, 13, 51360], "temperature": 0.0, "avg_logprob": -0.06751498388587882, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0002611071686260402}, {"id": 440, "seek": 247054, "start": 2490.46, "end": 2496.14, "text": " On the other hand, the case against illusionism is very, very strong for many people. And the", "tokens": [51360, 1282, 264, 661, 1011, 11, 264, 1389, 1970, 18854, 1434, 307, 588, 11, 588, 2068, 337, 867, 561, 13, 400, 264, 51644], "temperature": 0.0, "avg_logprob": -0.06751498388587882, "compression_ratio": 1.669064748201439, "no_speech_prob": 0.0002611071686260402}, {"id": 441, "seek": 249614, "start": 2496.14, "end": 2500.62, "text": " underlying worry is that some illusionism is completely unbelievable. It's just a manifest", "tokens": [50364, 14217, 3292, 307, 300, 512, 18854, 1434, 307, 2584, 16605, 13, 467, 311, 445, 257, 10067, 50588], "temperature": 0.0, "avg_logprob": -0.09512556923760308, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0031708001624792814}, {"id": 442, "seek": 249614, "start": 2500.62, "end": 2507.42, "text": " fact about ourselves that we have conscious experience, we experience red, we feel pain,", "tokens": [50588, 1186, 466, 4175, 300, 321, 362, 6648, 1752, 11, 321, 1752, 2182, 11, 321, 841, 1822, 11, 50928], "temperature": 0.0, "avg_logprob": -0.09512556923760308, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0031708001624792814}, {"id": 443, "seek": 249614, "start": 2507.42, "end": 2513.74, "text": " and so on. To deny those things is to deny the data. Now, the dialectic here is complicated.", "tokens": [50928, 293, 370, 322, 13, 1407, 15744, 729, 721, 307, 281, 15744, 264, 1412, 13, 823, 11, 264, 24652, 299, 510, 307, 6179, 13, 51244], "temperature": 0.0, "avg_logprob": -0.09512556923760308, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0031708001624792814}, {"id": 444, "seek": 249614, "start": 2513.74, "end": 2518.62, "text": " The illusionist will come back and say, yes, but I can explain why illusionism is unbelievable.", "tokens": [51244, 440, 18854, 468, 486, 808, 646, 293, 584, 11, 2086, 11, 457, 286, 393, 2903, 983, 18854, 1434, 307, 16605, 13, 51488], "temperature": 0.0, "avg_logprob": -0.09512556923760308, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0031708001624792814}, {"id": 445, "seek": 249614, "start": 2518.62, "end": 2523.18, "text": " These models we have, these self-models of consciousness, are so strong that they're", "tokens": [51488, 1981, 5245, 321, 362, 11, 613, 2698, 12, 8014, 1625, 295, 10081, 11, 366, 370, 2068, 300, 436, 434, 51716], "temperature": 0.0, "avg_logprob": -0.09512556923760308, "compression_ratio": 1.7626459143968871, "no_speech_prob": 0.0031708001624792814}, {"id": 446, "seek": 252318, "start": 2523.2599999999998, "end": 2528.3799999999997, "text": " just wired into us by evolution, and they're not models we can get rid of. So my view predicts", "tokens": [50368, 445, 27415, 666, 505, 538, 9303, 11, 293, 436, 434, 406, 5245, 321, 393, 483, 3973, 295, 13, 407, 452, 1910, 6069, 82, 50624], "temperature": 0.0, "avg_logprob": -0.0973367691040039, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00040354186785407364}, {"id": 447, "seek": 252318, "start": 2528.3799999999997, "end": 2534.7799999999997, "text": " that my view is unbelievable. And the question is what, the dialectical situation is complex", "tokens": [50624, 300, 452, 1910, 307, 16605, 13, 400, 264, 1168, 307, 437, 11, 264, 24652, 804, 2590, 307, 3997, 50944], "temperature": 0.0, "avg_logprob": -0.0973367691040039, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00040354186785407364}, {"id": 448, "seek": 252318, "start": 2534.7799999999997, "end": 2541.3399999999997, "text": " and interesting. But maybe I could just wrap up with two expressions of absurdity on either side", "tokens": [50944, 293, 1880, 13, 583, 1310, 286, 727, 445, 7019, 493, 365, 732, 15277, 295, 19774, 507, 322, 2139, 1252, 51272], "temperature": 0.0, "avg_logprob": -0.0973367691040039, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00040354186785407364}, {"id": 449, "seek": 252318, "start": 2541.3399999999997, "end": 2548.8599999999997, "text": " of this question, the illusionist and the anti-illusionist, both finding absurdity", "tokens": [51272, 295, 341, 1168, 11, 264, 18854, 468, 293, 264, 6061, 12, 373, 5704, 468, 11, 1293, 5006, 19774, 507, 51648], "temperature": 0.0, "avg_logprob": -0.0973367691040039, "compression_ratio": 1.6238938053097345, "no_speech_prob": 0.00040354186785407364}, {"id": 450, "seek": 254886, "start": 2548.94, "end": 2556.1400000000003, "text": " in the other person's views. Here's Galen Strawson, who is here. Galen's view is very much that", "tokens": [50368, 294, 264, 661, 954, 311, 6809, 13, 1692, 311, 7336, 268, 35104, 3015, 11, 567, 307, 510, 13, 7336, 268, 311, 1910, 307, 588, 709, 300, 50728], "temperature": 0.0, "avg_logprob": -0.09130702938949853, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.03159833326935768}, {"id": 451, "seek": 254886, "start": 2556.1400000000003, "end": 2561.1800000000003, "text": " illusionism is totally absurd. In fact, he thinks it's the most absurd view that anyone has ever", "tokens": [50728, 18854, 1434, 307, 3879, 19774, 13, 682, 1186, 11, 415, 7309, 309, 311, 264, 881, 19774, 1910, 300, 2878, 575, 1562, 50980], "temperature": 0.0, "avg_logprob": -0.09130702938949853, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.03159833326935768}, {"id": 452, "seek": 254886, "start": 2561.1800000000003, "end": 2567.1800000000003, "text": " held. There occurred in the 20th century, the most remarkable episode in the whole history of ideas,", "tokens": [50980, 5167, 13, 821, 11068, 294, 264, 945, 392, 4901, 11, 264, 881, 12802, 3500, 294, 264, 1379, 2503, 295, 3487, 11, 51280], "temperature": 0.0, "avg_logprob": -0.09130702938949853, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.03159833326935768}, {"id": 453, "seek": 254886, "start": 2567.1800000000003, "end": 2571.98, "text": " the whole history of human thought, a number of thinkers denied the existence of something we", "tokens": [51280, 264, 1379, 2503, 295, 1952, 1194, 11, 257, 1230, 295, 37895, 17774, 264, 9123, 295, 746, 321, 51520], "temperature": 0.0, "avg_logprob": -0.09130702938949853, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.03159833326935768}, {"id": 454, "seek": 254886, "start": 2571.98, "end": 2577.26, "text": " know with certainty to exist, consciousness. He thinks this is just a sign of incredible", "tokens": [51520, 458, 365, 27022, 281, 2514, 11, 10081, 13, 634, 7309, 341, 307, 445, 257, 1465, 295, 4651, 51784], "temperature": 0.0, "avg_logprob": -0.09130702938949853, "compression_ratio": 1.7122302158273381, "no_speech_prob": 0.03159833326935768}, {"id": 455, "seek": 257726, "start": 2577.26, "end": 2583.26, "text": " philosophical pathology. Here's the rationalist philosopher Eliezer Yudkowski in something he", "tokens": [50364, 25066, 3100, 1793, 13, 1692, 311, 264, 15090, 468, 29805, 2699, 414, 4527, 398, 532, 74, 21866, 294, 746, 415, 50664], "temperature": 0.0, "avg_logprob": -0.1148952671459743, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0011868190485984087}, {"id": 456, "seek": 257726, "start": 2583.26, "end": 2590.6200000000003, "text": " wrote a few years ago on zombies and consciousness, and the view, the epiphenomenalist view that", "tokens": [50664, 4114, 257, 1326, 924, 2057, 322, 24230, 293, 10081, 11, 293, 264, 1910, 11, 264, 2388, 647, 2932, 4726, 304, 468, 1910, 300, 51032], "temperature": 0.0, "avg_logprob": -0.1148952671459743, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0011868190485984087}, {"id": 457, "seek": 257726, "start": 2590.6200000000003, "end": 2595.6600000000003, "text": " consciousness plays no causal role, where he was engaging some stuff I wrote a couple of decades", "tokens": [51032, 10081, 5749, 572, 38755, 3090, 11, 689, 415, 390, 11268, 512, 1507, 286, 4114, 257, 1916, 295, 7878, 51284], "temperature": 0.0, "avg_logprob": -0.1148952671459743, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0011868190485984087}, {"id": 458, "seek": 257726, "start": 2595.6600000000003, "end": 2599.9, "text": " ago. He said, this is a zombie argument, the idea we can imagine zombies physically like us,", "tokens": [51284, 2057, 13, 634, 848, 11, 341, 307, 257, 20310, 6770, 11, 264, 1558, 321, 393, 3811, 24230, 9762, 411, 505, 11, 51496], "temperature": 0.0, "avg_logprob": -0.1148952671459743, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0011868190485984087}, {"id": 459, "seek": 257726, "start": 2599.9, "end": 2605.7400000000002, "text": " but without consciousness. Maybe a candidate for the most deranged idea in all of philosophy.", "tokens": [51496, 457, 1553, 10081, 13, 2704, 257, 11532, 337, 264, 881, 1163, 10296, 1558, 294, 439, 295, 10675, 13, 51788], "temperature": 0.0, "avg_logprob": -0.1148952671459743, "compression_ratio": 1.7050359712230216, "no_speech_prob": 0.0011868190485984087}, {"id": 460, "seek": 260574, "start": 2606.2999999999997, "end": 2613.9799999999996, "text": " The causally closed cognitive system of charmer's internal narrative is malfunctioning in a way that", "tokens": [50392, 440, 3302, 379, 5395, 15605, 1185, 295, 1290, 936, 311, 6920, 9977, 307, 50229, 278, 294, 257, 636, 300, 50776], "temperature": 0.0, "avg_logprob": -0.12447718452004826, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006560714682564139}, {"id": 461, "seek": 260574, "start": 2613.9799999999996, "end": 2620.62, "text": " not by necessity, but just in our own universe miraculously happens to be correct. Here he's", "tokens": [50776, 406, 538, 24217, 11, 457, 445, 294, 527, 1065, 6445, 30686, 25038, 2314, 281, 312, 3006, 13, 1692, 415, 311, 51108], "temperature": 0.0, "avg_logprob": -0.12447718452004826, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006560714682564139}, {"id": 462, "seek": 260574, "start": 2620.62, "end": 2625.1, "text": " expressing this debunking idea that on this view, there's an algorithm that generates these", "tokens": [51108, 22171, 341, 3001, 3197, 278, 1558, 300, 322, 341, 1910, 11, 456, 311, 364, 9284, 300, 23815, 613, 51332], "temperature": 0.0, "avg_logprob": -0.12447718452004826, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006560714682564139}, {"id": 463, "seek": 260574, "start": 2625.1, "end": 2629.5, "text": " intuitions about consciousness, and that's all physical. There's also this further layer of", "tokens": [51332, 16224, 626, 466, 10081, 11, 293, 300, 311, 439, 4001, 13, 821, 311, 611, 341, 3052, 4583, 295, 51552], "temperature": 0.0, "avg_logprob": -0.12447718452004826, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.0006560714682564139}, {"id": 464, "seek": 262950, "start": 2629.5, "end": 2637.26, "text": " non-physical stuff, and just by massive coincidence, the physical algorithm is a correct model of the", "tokens": [50364, 2107, 12, 950, 36280, 1507, 11, 293, 445, 538, 5994, 22137, 11, 264, 4001, 9284, 307, 257, 3006, 2316, 295, 264, 50752], "temperature": 0.0, "avg_logprob": -0.1050061046487034, "compression_ratio": 1.6694915254237288, "no_speech_prob": 0.001365050789900124}, {"id": 465, "seek": 262950, "start": 2637.26, "end": 2644.22, "text": " non-physical stuff. That's a form of debunking here. It would take a miracle for this view to be", "tokens": [50752, 2107, 12, 950, 36280, 1507, 13, 663, 311, 257, 1254, 295, 3001, 3197, 278, 510, 13, 467, 576, 747, 257, 14660, 337, 341, 1910, 281, 312, 51100], "temperature": 0.0, "avg_logprob": -0.1050061046487034, "compression_ratio": 1.6694915254237288, "no_speech_prob": 0.001365050789900124}, {"id": 466, "seek": 262950, "start": 2644.22, "end": 2649.9, "text": " correct. So I think both of these views are onto, these objections are onto something, and to make", "tokens": [51100, 3006, 13, 407, 286, 519, 1293, 295, 613, 6809, 366, 3911, 11, 613, 44649, 366, 3911, 746, 11, 293, 281, 652, 51384], "temperature": 0.0, "avg_logprob": -0.1050061046487034, "compression_ratio": 1.6694915254237288, "no_speech_prob": 0.001365050789900124}, {"id": 467, "seek": 262950, "start": 2649.9, "end": 2655.26, "text": " progress on this, when I decide we need to find a way of getting past these absurdities. I mean,", "tokens": [51384, 4205, 322, 341, 11, 562, 286, 4536, 321, 643, 281, 915, 257, 636, 295, 1242, 1791, 613, 19774, 1088, 13, 286, 914, 11, 51652], "temperature": 0.0, "avg_logprob": -0.1050061046487034, "compression_ratio": 1.6694915254237288, "no_speech_prob": 0.001365050789900124}, {"id": 468, "seek": 265526, "start": 2655.26, "end": 2660.78, "text": " you might say, well, there's middle ground between very strong illusionism and very strong epiphenomenalism.", "tokens": [50364, 291, 1062, 584, 11, 731, 11, 456, 311, 2808, 2727, 1296, 588, 2068, 18854, 1434, 293, 588, 2068, 2388, 647, 2932, 4726, 304, 1434, 13, 50640], "temperature": 0.0, "avg_logprob": -0.08086885611216227, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.0011331194546073675}, {"id": 469, "seek": 265526, "start": 2660.78, "end": 2667.1000000000004, "text": " It tends to slide back to the same problems. Other forms of illusionism, weaker forms don't", "tokens": [50640, 467, 12258, 281, 4137, 646, 281, 264, 912, 2740, 13, 5358, 6422, 295, 18854, 1434, 11, 24286, 6422, 500, 380, 50956], "temperature": 0.0, "avg_logprob": -0.08086885611216227, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.0011331194546073675}, {"id": 470, "seek": 265526, "start": 2667.1000000000004, "end": 2672.7000000000003, "text": " help much with the higher problem. Other forms of realism are still subject to this. It takes a", "tokens": [50956, 854, 709, 365, 264, 2946, 1154, 13, 5358, 6422, 295, 38484, 366, 920, 3983, 281, 341, 13, 467, 2516, 257, 51236], "temperature": 0.0, "avg_logprob": -0.08086885611216227, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.0011331194546073675}, {"id": 471, "seek": 265526, "start": 2672.7000000000003, "end": 2680.38, "text": " miracle for this view to be correct. Critique. So I think to get beyond absurdity here, both sides", "tokens": [51236, 14660, 337, 341, 1910, 281, 312, 3006, 13, 23202, 1925, 13, 407, 286, 519, 281, 483, 4399, 19774, 507, 510, 11, 1293, 4881, 51620], "temperature": 0.0, "avg_logprob": -0.08086885611216227, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.0011331194546073675}, {"id": 472, "seek": 265526, "start": 2680.38, "end": 2685.1000000000004, "text": " need to do something more. The illusionist needs to do more to explain how having a mind could", "tokens": [51620, 643, 281, 360, 746, 544, 13, 440, 18854, 468, 2203, 281, 360, 544, 281, 2903, 577, 1419, 257, 1575, 727, 51856], "temperature": 0.0, "avg_logprob": -0.08086885611216227, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.0011331194546073675}, {"id": 473, "seek": 268510, "start": 2685.1, "end": 2691.2599999999998, "text": " be like this, somehow just like this, even though it's not at all the way that it seems. They need", "tokens": [50364, 312, 411, 341, 11, 6063, 445, 411, 341, 11, 754, 1673, 309, 311, 406, 412, 439, 264, 636, 300, 309, 2544, 13, 814, 643, 50672], "temperature": 0.0, "avg_logprob": -0.08403556163494404, "compression_ratio": 1.9346938775510205, "no_speech_prob": 0.0005690123070962727}, {"id": 474, "seek": 268510, "start": 2691.2599999999998, "end": 2698.2999999999997, "text": " to find some way to recapture the data. Realists need to explain how it is that these meta-problem", "tokens": [50672, 281, 915, 512, 636, 281, 43086, 35603, 264, 1412, 13, 8467, 1751, 643, 281, 2903, 577, 309, 307, 300, 613, 19616, 12, 47419, 51024], "temperature": 0.0, "avg_logprob": -0.08403556163494404, "compression_ratio": 1.9346938775510205, "no_speech_prob": 0.0005690123070962727}, {"id": 475, "seek": 268510, "start": 2698.2999999999997, "end": 2703.02, "text": " processes are not completely independent of consciousness. Realists need to explain how", "tokens": [51024, 7555, 366, 406, 2584, 6695, 295, 10081, 13, 8467, 1751, 643, 281, 2903, 577, 51260], "temperature": 0.0, "avg_logprob": -0.08403556163494404, "compression_ratio": 1.9346938775510205, "no_speech_prob": 0.0005690123070962727}, {"id": 476, "seek": 268510, "start": 2703.02, "end": 2708.94, "text": " meta-problem processes, the ones that generate these intuitions and reports and convictions", "tokens": [51260, 19616, 12, 47419, 7555, 11, 264, 2306, 300, 8460, 613, 16224, 626, 293, 7122, 293, 44757, 51556], "temperature": 0.0, "avg_logprob": -0.08403556163494404, "compression_ratio": 1.9346938775510205, "no_speech_prob": 0.0005690123070962727}, {"id": 477, "seek": 268510, "start": 2708.94, "end": 2713.8199999999997, "text": " about consciousness are essentially grounded in consciousness, even if it's possible somehow for", "tokens": [51556, 466, 10081, 366, 4476, 23535, 294, 10081, 11, 754, 498, 309, 311, 1944, 6063, 337, 51800], "temperature": 0.0, "avg_logprob": -0.08403556163494404, "compression_ratio": 1.9346938775510205, "no_speech_prob": 0.0005690123070962727}, {"id": 478, "seek": 271382, "start": 2713.82, "end": 2720.54, "text": " them to occur or conceivable for them to occur without consciousness. Anyway, so that's just to", "tokens": [50364, 552, 281, 5160, 420, 10413, 34376, 337, 552, 281, 5160, 1553, 10081, 13, 5684, 11, 370, 300, 311, 445, 281, 50700], "temperature": 0.0, "avg_logprob": -0.08919488952820559, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.00010548930004006252}, {"id": 479, "seek": 271382, "start": 2720.54, "end": 2727.1000000000004, "text": " lay out a research program. I think a solution to the meta-problem that meets these ambitions", "tokens": [50700, 2360, 484, 257, 2132, 1461, 13, 286, 519, 257, 3827, 281, 264, 19616, 12, 47419, 300, 13961, 613, 34475, 51028], "temperature": 0.0, "avg_logprob": -0.08919488952820559, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.00010548930004006252}, {"id": 480, "seek": 271382, "start": 2727.1000000000004, "end": 2732.06, "text": " might just possibly solve the hard problem of consciousness or at the very least,", "tokens": [51028, 1062, 445, 6264, 5039, 264, 1152, 1154, 295, 10081, 420, 412, 264, 588, 1935, 11, 51276], "temperature": 0.0, "avg_logprob": -0.08919488952820559, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.00010548930004006252}, {"id": 481, "seek": 271382, "start": 2732.06, "end": 2737.5800000000004, "text": " shed significant light on it. In the meantime, the meta-problem is a potentially tractable", "tokens": [51276, 14951, 4776, 1442, 322, 309, 13, 682, 264, 14991, 11, 264, 19616, 12, 47419, 307, 257, 7263, 24207, 712, 51552], "temperature": 0.0, "avg_logprob": -0.08919488952820559, "compression_ratio": 1.7075471698113207, "no_speech_prob": 0.00010548930004006252}, {"id": 482, "seek": 273758, "start": 2737.58, "end": 2740.94, "text": " research project for everyone, and mine I recommend to all of you. Thanks.", "tokens": [50364, 2132, 1716, 337, 1518, 11, 293, 3892, 286, 2748, 281, 439, 295, 291, 13, 2561, 13, 50532], "temperature": 0.0, "avg_logprob": -0.18546706340352043, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0005026414291933179}, {"id": 483, "seek": 273758, "start": 2748.38, "end": 2754.54, "text": " Yes, I just want to say I think it's very interesting this concept of we have these mental models,", "tokens": [50904, 1079, 11, 286, 445, 528, 281, 584, 286, 519, 309, 311, 588, 1880, 341, 3410, 295, 321, 362, 613, 4973, 5245, 11, 51212], "temperature": 0.0, "avg_logprob": -0.18546706340352043, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0005026414291933179}, {"id": 484, "seek": 273758, "start": 2755.1, "end": 2762.54, "text": " collection of mental models, and that this collection of mental models is consciousness,", "tokens": [51240, 5765, 295, 4973, 5245, 11, 293, 300, 341, 5765, 295, 4973, 5245, 307, 10081, 11, 51612], "temperature": 0.0, "avg_logprob": -0.18546706340352043, "compression_ratio": 1.617283950617284, "no_speech_prob": 0.0005026414291933179}, {"id": 485, "seek": 276254, "start": 2762.62, "end": 2767.42, "text": " basically. Consciousness is defined as a collection of these mental models that we have,", "tokens": [50368, 1936, 13, 6923, 4139, 1287, 307, 7642, 382, 257, 5765, 295, 613, 4973, 5245, 300, 321, 362, 11, 50608], "temperature": 0.0, "avg_logprob": -0.09405801997465246, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0023172765504568815}, {"id": 486, "seek": 276254, "start": 2767.42, "end": 2772.54, "text": " and the problem of consciousness is that we don't understand the physical phenomenon that", "tokens": [50608, 293, 264, 1154, 295, 10081, 307, 300, 321, 500, 380, 1223, 264, 4001, 14029, 300, 50864], "temperature": 0.0, "avg_logprob": -0.09405801997465246, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0023172765504568815}, {"id": 487, "seek": 276254, "start": 2772.54, "end": 2779.74, "text": " causes these mental models or that stimulates these mental models. So we just have this belief", "tokens": [50864, 7700, 613, 4973, 5245, 420, 300, 14572, 1024, 613, 4973, 5245, 13, 407, 321, 445, 362, 341, 7107, 51224], "temperature": 0.0, "avg_logprob": -0.09405801997465246, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0023172765504568815}, {"id": 488, "seek": 276254, "start": 2779.74, "end": 2788.22, "text": " that it's ephemeral or not real or something like that. And if you take that view, then what's", "tokens": [51224, 300, 309, 311, 308, 41245, 2790, 420, 406, 957, 420, 746, 411, 300, 13, 400, 498, 291, 747, 300, 1910, 11, 550, 437, 311, 51648], "temperature": 0.0, "avg_logprob": -0.09405801997465246, "compression_ratio": 1.803921568627451, "no_speech_prob": 0.0023172765504568815}, {"id": 489, "seek": 278822, "start": 2788.22, "end": 2795.1, "text": " interesting is that you could simulate these mental models, like robot could simulate these", "tokens": [50364, 1880, 307, 300, 291, 727, 27817, 613, 4973, 5245, 11, 411, 7881, 727, 27817, 613, 50708], "temperature": 0.0, "avg_logprob": -0.09655424666731324, "compression_ratio": 1.934782608695652, "no_speech_prob": 0.004127374850213528}, {"id": 490, "seek": 278822, "start": 2795.1, "end": 2802.7799999999997, "text": " mental models, and you could simulate consciousness as well. And even if the underlying physical", "tokens": [50708, 4973, 5245, 11, 293, 291, 727, 27817, 10081, 382, 731, 13, 400, 754, 498, 264, 14217, 4001, 51092], "temperature": 0.0, "avg_logprob": -0.09655424666731324, "compression_ratio": 1.934782608695652, "no_speech_prob": 0.004127374850213528}, {"id": 491, "seek": 278822, "start": 2802.7799999999997, "end": 2807.58, "text": " phenomenon that fuels these mental models is different, you know, robots have different", "tokens": [51092, 14029, 300, 24616, 613, 4973, 5245, 307, 819, 11, 291, 458, 11, 14733, 362, 819, 51332], "temperature": 0.0, "avg_logprob": -0.09655424666731324, "compression_ratio": 1.934782608695652, "no_speech_prob": 0.004127374850213528}, {"id": 492, "seek": 278822, "start": 2807.58, "end": 2813.98, "text": " sensors, etc., you could still get the same consciousness effect in both cases.", "tokens": [51332, 14840, 11, 5183, 7933, 291, 727, 920, 483, 264, 912, 10081, 1802, 294, 1293, 3331, 13, 51652], "temperature": 0.0, "avg_logprob": -0.09655424666731324, "compression_ratio": 1.934782608695652, "no_speech_prob": 0.004127374850213528}, {"id": 493, "seek": 281398, "start": 2814.78, "end": 2818.62, "text": " Yeah, I think that's right. Or at the very least, you ought to be able to get,", "tokens": [50404, 865, 11, 286, 519, 300, 311, 558, 13, 1610, 412, 264, 588, 1935, 11, 291, 13416, 281, 312, 1075, 281, 483, 11, 50596], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 494, "seek": 281398, "start": 2818.62, "end": 2822.38, "text": " it looks like you ought to be able to get the same models at least in a robot. If the models", "tokens": [50596, 309, 1542, 411, 291, 13416, 281, 312, 1075, 281, 483, 264, 912, 5245, 412, 1935, 294, 257, 7881, 13, 759, 264, 5245, 50784], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 495, "seek": 281398, "start": 2822.38, "end": 2827.9, "text": " themselves are something algorithmic, and ought to be, you ought to be able to design a robot", "tokens": [50784, 2969, 366, 746, 9284, 299, 11, 293, 13416, 281, 312, 11, 291, 13416, 281, 312, 1075, 281, 1715, 257, 7881, 51060], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 496, "seek": 281398, "start": 2827.9, "end": 2833.66, "text": " that has at the very least, let's say, isomorphic models in some sense that is conscious. Of course,", "tokens": [51060, 300, 575, 412, 264, 588, 1935, 11, 718, 311, 584, 11, 307, 32702, 299, 5245, 294, 512, 2020, 300, 307, 6648, 13, 2720, 1164, 11, 51348], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 497, "seek": 281398, "start": 2833.66, "end": 2837.98, "text": " it's a further question, at least by my lights, but then the robot will be conscious. And that was", "tokens": [51348, 309, 311, 257, 3052, 1168, 11, 412, 1935, 538, 452, 5811, 11, 457, 550, 264, 7881, 486, 312, 6648, 13, 400, 300, 390, 51564], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 498, "seek": 281398, "start": 2837.98, "end": 2841.42, "text": " the question I alluded to in talking about the artificial consciousness test. But you might think", "tokens": [51564, 264, 1168, 286, 33919, 281, 294, 1417, 466, 264, 11677, 10081, 1500, 13, 583, 291, 1062, 519, 51736], "temperature": 0.0, "avg_logprob": -0.11453375116094842, "compression_ratio": 1.9685314685314685, "no_speech_prob": 0.0017807773547247052}, {"id": 499, "seek": 284142, "start": 2841.42, "end": 2845.58, "text": " that would at least be very good evidence that the robot is conscious. If it's got a model of", "tokens": [50364, 300, 576, 412, 1935, 312, 588, 665, 4467, 300, 264, 7881, 307, 6648, 13, 759, 309, 311, 658, 257, 2316, 295, 50572], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 500, "seek": 284142, "start": 2845.58, "end": 2850.14, "text": " consciousness just like ours, it seems very plausible there ought to be a very strong link", "tokens": [50572, 10081, 445, 411, 11896, 11, 309, 2544, 588, 39925, 456, 13416, 281, 312, 257, 588, 2068, 2113, 50800], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 501, "seek": 284142, "start": 2850.14, "end": 2855.66, "text": " between having a model like that and being conscious. I mean, I think probably something", "tokens": [50800, 1296, 1419, 257, 2316, 411, 300, 293, 885, 6648, 13, 286, 914, 11, 286, 519, 1391, 746, 51076], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 502, "seek": 284142, "start": 2855.66, "end": 2859.02, "text": " like Ned Block, who was here arguing against machine consciousness, would say, no, no,", "tokens": [51076, 411, 31355, 17500, 11, 567, 390, 510, 19697, 1970, 3479, 10081, 11, 576, 584, 11, 572, 11, 572, 11, 51244], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 503, "seek": 284142, "start": 2859.02, "end": 2862.7000000000003, "text": " the model is not enough. The model has to be built of the right stuff. Say it's got to be", "tokens": [51244, 264, 2316, 307, 406, 1547, 13, 440, 2316, 575, 281, 312, 3094, 295, 264, 558, 1507, 13, 6463, 309, 311, 658, 281, 312, 51428], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 504, "seek": 284142, "start": 2862.7000000000003, "end": 2866.86, "text": " built of biology and so on. But at least by my lights, I think if I have found the AI system", "tokens": [51428, 3094, 295, 14956, 293, 370, 322, 13, 583, 412, 1935, 538, 452, 5811, 11, 286, 519, 498, 286, 362, 1352, 264, 7318, 1185, 51636], "temperature": 0.0, "avg_logprob": -0.11228577770403962, "compression_ratio": 1.8221476510067114, "no_speech_prob": 0.0010642405832186341}, {"id": 505, "seek": 286686, "start": 2866.86, "end": 2872.2200000000003, "text": " that had a very serious version of our model of consciousness, I take that as a very good reason", "tokens": [50364, 300, 632, 257, 588, 3156, 3037, 295, 527, 2316, 295, 10081, 11, 286, 747, 300, 382, 257, 588, 665, 1778, 50632], "temperature": 0.0, "avg_logprob": -0.10114672486211213, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0009086579084396362}, {"id": 506, "seek": 286686, "start": 2872.2200000000003, "end": 2880.94, "text": " to believe it's conscious. In the IIT theory, is there a estimate or plausible estimate for what", "tokens": [50632, 281, 1697, 309, 311, 6648, 13, 682, 264, 286, 3927, 5261, 11, 307, 456, 257, 12539, 420, 39925, 12539, 337, 437, 51068], "temperature": 0.0, "avg_logprob": -0.10114672486211213, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0009086579084396362}, {"id": 507, "seek": 286686, "start": 2880.94, "end": 2890.78, "text": " the value of phi is for people and for other systems? Basically, no. It's extremely hard to measure", "tokens": [51068, 264, 2158, 295, 13107, 307, 337, 561, 293, 337, 661, 3652, 30, 8537, 11, 572, 13, 467, 311, 4664, 1152, 281, 3481, 51560], "temperature": 0.0, "avg_logprob": -0.10114672486211213, "compression_ratio": 1.5421052631578946, "no_speech_prob": 0.0009086579084396362}, {"id": 508, "seek": 289078, "start": 2891.34, "end": 2897.98, "text": " in systems of any size at all. I mean, because the way it's defined involves taking a sum over", "tokens": [50392, 294, 3652, 295, 604, 2744, 412, 439, 13, 286, 914, 11, 570, 264, 636, 309, 311, 7642, 11626, 1940, 257, 2408, 670, 50724], "temperature": 0.0, "avg_logprob": -0.11416200864112984, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.001895484747365117}, {"id": 509, "seek": 289078, "start": 2897.98, "end": 2903.34, "text": " every possible partition of a system. It turns out, I mean, A, it's hard to measure in the brain", "tokens": [50724, 633, 1944, 24808, 295, 257, 1185, 13, 467, 4523, 484, 11, 286, 914, 11, 316, 11, 309, 311, 1152, 281, 3481, 294, 264, 3567, 50992], "temperature": 0.0, "avg_logprob": -0.11416200864112984, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.001895484747365117}, {"id": 510, "seek": 289078, "start": 2903.34, "end": 2907.82, "text": " because you've got to involve the causal dependencies set between different units on neurons. But even", "tokens": [50992, 570, 291, 600, 658, 281, 9494, 264, 38755, 36606, 992, 1296, 819, 6815, 322, 22027, 13, 583, 754, 51216], "temperature": 0.0, "avg_logprob": -0.11416200864112984, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.001895484747365117}, {"id": 511, "seek": 289078, "start": 2907.82, "end": 2914.38, "text": " for a pure algorithmic system, you've got like a neural network laid out in front of you,", "tokens": [51216, 337, 257, 6075, 9284, 299, 1185, 11, 291, 600, 658, 411, 257, 18161, 3209, 9897, 484, 294, 1868, 295, 291, 11, 51544], "temperature": 0.0, "avg_logprob": -0.11416200864112984, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.001895484747365117}, {"id": 512, "seek": 289078, "start": 2914.38, "end": 2918.2200000000003, "text": " it's computationally intractable to measure the phi of one of those once they get to bigger than", "tokens": [51544, 309, 311, 24903, 379, 560, 1897, 712, 281, 3481, 264, 13107, 295, 472, 295, 729, 1564, 436, 483, 281, 3801, 813, 51736], "temperature": 0.0, "avg_logprob": -0.11416200864112984, "compression_ratio": 1.7240143369175627, "no_speech_prob": 0.001895484747365117}, {"id": 513, "seek": 291822, "start": 2918.22, "end": 2923.58, "text": " 15 units or so. So, you know, today I'd like to say this is an empirical theory and in principle", "tokens": [50364, 2119, 6815, 420, 370, 13, 407, 11, 291, 458, 11, 965, 286, 1116, 411, 281, 584, 341, 307, 364, 31886, 5261, 293, 294, 8665, 50632], "temperature": 0.0, "avg_logprob": -0.21423216660817465, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005108526675030589}, {"id": 514, "seek": 291822, "start": 2923.58, "end": 2930.14, "text": " empirically testable. But notice the in principle, it's extremely difficult to to to measure phi.", "tokens": [50632, 25790, 984, 1500, 712, 13, 583, 3449, 264, 294, 8665, 11, 309, 311, 4664, 2252, 281, 281, 281, 3481, 13107, 13, 50960], "temperature": 0.0, "avg_logprob": -0.21423216660817465, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005108526675030589}, {"id": 515, "seek": 291822, "start": 2930.14, "end": 2939.02, "text": " Some people, Scott Aronson, the computer scientist has argued, has tried to put forward counter-examples", "tokens": [50960, 2188, 561, 11, 6659, 1587, 892, 266, 11, 264, 3820, 12662, 575, 20219, 11, 575, 3031, 281, 829, 2128, 5682, 12, 3121, 335, 2622, 51404], "temperature": 0.0, "avg_logprob": -0.21423216660817465, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005108526675030589}, {"id": 516, "seek": 291822, "start": 2939.02, "end": 2945.18, "text": " to the theory, which are basically very, very simple systems like matrix multipliers that", "tokens": [51404, 281, 264, 5261, 11, 597, 366, 1936, 588, 11, 588, 2199, 3652, 411, 8141, 12788, 4890, 300, 51712], "temperature": 0.0, "avg_logprob": -0.21423216660817465, "compression_ratio": 1.5877551020408163, "no_speech_prob": 0.0005108526675030589}, {"id": 517, "seek": 294518, "start": 2945.2599999999998, "end": 2949.8999999999996, "text": " multiply two large matrices turn out to have enormous phi. Phi is as big as you like if the", "tokens": [50368, 12972, 732, 2416, 32284, 1261, 484, 281, 362, 11322, 13107, 13, 41435, 307, 382, 955, 382, 291, 411, 498, 264, 50600], "temperature": 0.0, "avg_logprob": -0.1344034809711551, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.00047262420412153006}, {"id": 518, "seek": 294518, "start": 2949.8999999999996, "end": 2954.62, "text": " matrices are big enough. And therefore, by Tononi's theory, we'll not just be conscious, but as", "tokens": [50600, 32284, 366, 955, 1547, 13, 400, 4412, 11, 538, 11385, 17049, 311, 5261, 11, 321, 603, 406, 445, 312, 6648, 11, 457, 382, 50836], "temperature": 0.0, "avg_logprob": -0.1344034809711551, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.00047262420412153006}, {"id": 519, "seek": 294518, "start": 2954.62, "end": 2959.98, "text": " conscious as a human being. And Aronson put this forward as a reductio ad absurdum of the IIT theory.", "tokens": [50836, 6648, 382, 257, 1952, 885, 13, 400, 1587, 892, 266, 829, 341, 2128, 382, 257, 2783, 349, 1004, 614, 19774, 449, 295, 264, 286, 3927, 5261, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1344034809711551, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.00047262420412153006}, {"id": 520, "seek": 294518, "start": 2959.98, "end": 2964.62, "text": " I think Tononi basically bit the bullet and said, yeah, yeah, those those matrix multipliers are", "tokens": [51104, 286, 519, 11385, 17049, 1936, 857, 264, 11632, 293, 848, 11, 1338, 11, 1338, 11, 729, 729, 8141, 12788, 4890, 366, 51336], "temperature": 0.0, "avg_logprob": -0.1344034809711551, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.00047262420412153006}, {"id": 521, "seek": 294518, "start": 2964.62, "end": 2970.62, "text": " actually having some high degree of consciousness. So I think IIT is probably missing at least", "tokens": [51336, 767, 1419, 512, 1090, 4314, 295, 10081, 13, 407, 286, 519, 286, 3927, 307, 1391, 5361, 412, 1935, 51636], "temperature": 0.0, "avg_logprob": -0.1344034809711551, "compression_ratio": 1.693661971830986, "no_speech_prob": 0.00047262420412153006}, {"id": 522, "seek": 297062, "start": 2970.62, "end": 2974.54, "text": " missing a few pieces of what's going to be developed. But it's a research program too.", "tokens": [50364, 5361, 257, 1326, 3755, 295, 437, 311, 516, 281, 312, 4743, 13, 583, 309, 311, 257, 2132, 1461, 886, 13, 50560], "temperature": 0.0, "avg_logprob": -0.08891210470113668, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0005518908146768808}, {"id": 523, "seek": 297062, "start": 2976.06, "end": 2981.98, "text": " You mentioned belief as an example of something where, you know, this is another mental quality,", "tokens": [50636, 509, 2835, 7107, 382, 364, 1365, 295, 746, 689, 11, 291, 458, 11, 341, 307, 1071, 4973, 3125, 11, 50932], "temperature": 0.0, "avg_logprob": -0.08891210470113668, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0005518908146768808}, {"id": 524, "seek": 297062, "start": 2981.98, "end": 2987.9, "text": " but people don't seem to have the same sense that it is very hard to explain. In fact,", "tokens": [50932, 457, 561, 500, 380, 1643, 281, 362, 264, 912, 2020, 300, 309, 307, 588, 1152, 281, 2903, 13, 682, 1186, 11, 51228], "temperature": 0.0, "avg_logprob": -0.08891210470113668, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0005518908146768808}, {"id": 525, "seek": 297062, "start": 2988.94, "end": 2993.9, "text": " it almost seems too easy where people like a belief about something sort of feels like just", "tokens": [51280, 309, 1920, 2544, 886, 1858, 689, 561, 411, 257, 7107, 466, 746, 1333, 295, 3417, 411, 445, 51528], "temperature": 0.0, "avg_logprob": -0.08891210470113668, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0005518908146768808}, {"id": 526, "seek": 297062, "start": 2993.9, "end": 2999.58, "text": " how things are. You have to kind of reflect on a belief to notice it as a belief. Do you", "tokens": [51528, 577, 721, 366, 13, 509, 362, 281, 733, 295, 5031, 322, 257, 7107, 281, 3449, 309, 382, 257, 7107, 13, 1144, 291, 51812], "temperature": 0.0, "avg_logprob": -0.08891210470113668, "compression_ratio": 1.714828897338403, "no_speech_prob": 0.0005518908146768808}, {"id": 527, "seek": 299958, "start": 3000.22, "end": 3006.7, "text": " think there's also or has there been research kind of related to this question into why is that", "tokens": [50396, 519, 456, 311, 611, 420, 575, 456, 668, 2132, 733, 295, 4077, 281, 341, 1168, 666, 983, 307, 300, 50720], "temperature": 0.0, "avg_logprob": -0.11504138190791292, "compression_ratio": 1.667883211678832, "no_speech_prob": 0.00048704404616728425}, {"id": 528, "seek": 299958, "start": 3006.7, "end": 3011.5, "text": " different? Like, it seems like another angle of attack on this problem is just like, why doesn't", "tokens": [50720, 819, 30, 1743, 11, 309, 2544, 411, 1071, 5802, 295, 2690, 322, 341, 1154, 307, 445, 411, 11, 983, 1177, 380, 50960], "temperature": 0.0, "avg_logprob": -0.11504138190791292, "compression_ratio": 1.667883211678832, "no_speech_prob": 0.00048704404616728425}, {"id": 529, "seek": 299958, "start": 3011.5, "end": 3016.46, "text": " this generate the same hard problem? Yeah, in terms, I'm not sure if there's been sort of", "tokens": [50960, 341, 8460, 264, 912, 1152, 1154, 30, 865, 11, 294, 2115, 11, 286, 478, 406, 988, 498, 456, 311, 668, 1333, 295, 51208], "temperature": 0.0, "avg_logprob": -0.11504138190791292, "compression_ratio": 1.667883211678832, "no_speech_prob": 0.00048704404616728425}, {"id": 530, "seek": 299958, "start": 3017.74, "end": 3020.86, "text": " research from the perspective of the meta problem or a theory of mind. Certainly,", "tokens": [51272, 2132, 490, 264, 4585, 295, 264, 19616, 1154, 420, 257, 5261, 295, 1575, 13, 16628, 11, 51428], "temperature": 0.0, "avg_logprob": -0.11504138190791292, "compression_ratio": 1.667883211678832, "no_speech_prob": 0.00048704404616728425}, {"id": 531, "seek": 299958, "start": 3020.86, "end": 3025.8199999999997, "text": " people have thought in their own right, what is the difference between belief and experience", "tokens": [51428, 561, 362, 1194, 294, 641, 1065, 558, 11, 437, 307, 264, 2649, 1296, 7107, 293, 1752, 51676], "temperature": 0.0, "avg_logprob": -0.11504138190791292, "compression_ratio": 1.667883211678832, "no_speech_prob": 0.00048704404616728425}, {"id": 532, "seek": 302582, "start": 3025.82, "end": 3031.34, "text": " that makes them so different? This goes way back to David Hume, a philosopher a few centuries ago,", "tokens": [50364, 300, 1669, 552, 370, 819, 30, 639, 1709, 636, 646, 281, 4389, 389, 2540, 11, 257, 29805, 257, 1326, 13926, 2057, 11, 50640], "temperature": 0.0, "avg_logprob": -0.16362904236379977, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0023215305991470814}, {"id": 533, "seek": 302582, "start": 3031.34, "end": 3038.2200000000003, "text": " who said, you know, basically, perception is vivid. Impressions and ideas. Impressions like", "tokens": [50640, 567, 848, 11, 291, 458, 11, 1936, 11, 12860, 307, 23603, 13, 8270, 735, 626, 293, 3487, 13, 8270, 735, 626, 411, 50984], "temperature": 0.0, "avg_logprob": -0.16362904236379977, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0023215305991470814}, {"id": 534, "seek": 302582, "start": 3038.2200000000003, "end": 3044.78, "text": " experiencing colors are vivid. They have force and vivacity and ideas are merely a faint copy", "tokens": [50984, 11139, 4577, 366, 23603, 13, 814, 362, 3464, 293, 11005, 19008, 293, 3487, 366, 17003, 257, 21104, 5055, 51312], "temperature": 0.0, "avg_logprob": -0.16362904236379977, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0023215305991470814}, {"id": 535, "seek": 302582, "start": 3044.78, "end": 3048.54, "text": " or something. But that's just the first order. And then there are contemporary versions of this", "tokens": [51312, 420, 746, 13, 583, 300, 311, 445, 264, 700, 1668, 13, 400, 550, 456, 366, 14878, 9606, 295, 341, 51500], "temperature": 0.0, "avg_logprob": -0.16362904236379977, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0023215305991470814}, {"id": 536, "seek": 302582, "start": 3048.54, "end": 3052.94, "text": " kind of thing, far more sophisticated ways of saying a similar thing. But yeah, you could,", "tokens": [51500, 733, 295, 551, 11, 1400, 544, 16950, 2098, 295, 1566, 257, 2531, 551, 13, 583, 1338, 11, 291, 727, 11, 51720], "temperature": 0.0, "avg_logprob": -0.16362904236379977, "compression_ratio": 1.6297577854671281, "no_speech_prob": 0.0023215305991470814}, {"id": 537, "seek": 305294, "start": 3053.02, "end": 3059.5, "text": " in principle, explore that through the meta problem. Why does it seem to us that perception is so", "tokens": [50368, 294, 8665, 11, 6839, 300, 807, 264, 19616, 1154, 13, 1545, 775, 309, 1643, 281, 505, 300, 12860, 307, 370, 50692], "temperature": 0.0, "avg_logprob": -0.1060651351358289, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00023031947785057127}, {"id": 538, "seek": 305294, "start": 3059.5, "end": 3065.26, "text": " much more vivid? What about our models of the mind makes perception seem so much more vivid", "tokens": [50692, 709, 544, 23603, 30, 708, 466, 527, 5245, 295, 264, 1575, 1669, 12860, 1643, 370, 709, 544, 23603, 50980], "temperature": 0.0, "avg_logprob": -0.1060651351358289, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00023031947785057127}, {"id": 539, "seek": 305294, "start": 3065.26, "end": 3070.38, "text": " than belief? It makes belief seem kind of structural and empty, whereas", "tokens": [50980, 813, 7107, 30, 467, 1669, 7107, 1643, 733, 295, 15067, 293, 6707, 11, 9735, 51236], "temperature": 0.0, "avg_logprob": -0.1060651351358289, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00023031947785057127}, {"id": 540, "seek": 305294, "start": 3071.18, "end": 3075.5, "text": " perception is so full of light. But no, I don't know of work on that from the meta problem", "tokens": [51276, 12860, 307, 370, 1577, 295, 1442, 13, 583, 572, 11, 286, 500, 380, 458, 295, 589, 322, 300, 490, 264, 19616, 1154, 51492], "temperature": 0.0, "avg_logprob": -0.1060651351358289, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00023031947785057127}, {"id": 541, "seek": 305294, "start": 3075.5, "end": 3080.2200000000003, "text": " perspective. Like I said, there's not that much work on these introspective models directly. There", "tokens": [51492, 4585, 13, 1743, 286, 848, 11, 456, 311, 406, 300, 709, 589, 322, 613, 560, 28713, 488, 5245, 3838, 13, 821, 51728], "temperature": 0.0, "avg_logprob": -0.1060651351358289, "compression_ratio": 1.7826086956521738, "no_speech_prob": 0.00023031947785057127}, {"id": 542, "seek": 308022, "start": 3080.22, "end": 3083.98, "text": " is work on theory of mind about beliefs tends to be about models of other people.", "tokens": [50364, 307, 589, 322, 5261, 295, 1575, 466, 13585, 12258, 281, 312, 466, 5245, 295, 661, 561, 13, 50552], "temperature": 0.0, "avg_logprob": -0.13514113817058626, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0001194539072457701}, {"id": 543, "seek": 308022, "start": 3085.98, "end": 3089.4199999999996, "text": " It may be there's something I could dig through a literature on belief that says something about", "tokens": [50652, 467, 815, 312, 456, 311, 746, 286, 727, 2528, 807, 257, 10394, 322, 7107, 300, 1619, 746, 466, 50824], "temperature": 0.0, "avg_logprob": -0.13514113817058626, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0001194539072457701}, {"id": 544, "seek": 308022, "start": 3089.4199999999996, "end": 3095.3399999999997, "text": " that. It's a good place to push. Thanks. I wanted to bring up Kurt Girdel. You mentioned your advisor", "tokens": [50824, 300, 13, 467, 311, 257, 665, 1081, 281, 2944, 13, 2561, 13, 286, 1415, 281, 1565, 493, 26168, 460, 1271, 338, 13, 509, 2835, 428, 19161, 51120], "temperature": 0.0, "avg_logprob": -0.13514113817058626, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0001194539072457701}, {"id": 545, "seek": 308022, "start": 3095.3399999999997, "end": 3101.5, "text": " wrote Girdel Escher Bach. There's something that seems very like Girdel, Girdelian or whatever,", "tokens": [51120, 4114, 460, 1271, 338, 2313, 6759, 30920, 13, 821, 311, 746, 300, 2544, 588, 411, 460, 1271, 338, 11, 460, 1271, 338, 952, 420, 2035, 11, 51428], "temperature": 0.0, "avg_logprob": -0.13514113817058626, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0001194539072457701}, {"id": 546, "seek": 308022, "start": 3101.5, "end": 3108.3799999999997, "text": " about this whole discussion in that. So Girdel showed that, given like a set of axioms and", "tokens": [51428, 466, 341, 1379, 5017, 294, 300, 13, 407, 460, 1271, 338, 4712, 300, 11, 2212, 411, 257, 992, 295, 6360, 72, 4785, 293, 51772], "temperature": 0.0, "avg_logprob": -0.13514113817058626, "compression_ratio": 1.7106227106227105, "no_speech_prob": 0.0001194539072457701}, {"id": 547, "seek": 310838, "start": 3108.38, "end": 3117.82, "text": " mathematics, it would either be consistent or complete, but not both. And it seems like when", "tokens": [50364, 18666, 11, 309, 576, 2139, 312, 8398, 420, 3566, 11, 457, 406, 1293, 13, 400, 309, 2544, 411, 562, 50836], "temperature": 0.0, "avg_logprob": -0.0959869341903858, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.0008481238037347794}, {"id": 548, "seek": 310838, "start": 3117.82, "end": 3124.86, "text": " Daniel Dennett, Daniel Dennett seems to have like a set of axioms where he cannot construct", "tokens": [50836, 8033, 19027, 3093, 11, 8033, 19027, 3093, 2544, 281, 362, 411, 257, 992, 295, 6360, 72, 4785, 689, 415, 2644, 7690, 51188], "temperature": 0.0, "avg_logprob": -0.0959869341903858, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.0008481238037347794}, {"id": 549, "seek": 310838, "start": 3124.86, "end": 3129.58, "text": " consciousness from them. He seems to be very much in this sort of consistent camp. Like he", "tokens": [51188, 10081, 490, 552, 13, 634, 2544, 281, 312, 588, 709, 294, 341, 1333, 295, 8398, 2255, 13, 1743, 415, 51424], "temperature": 0.0, "avg_logprob": -0.0959869341903858, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.0008481238037347794}, {"id": 550, "seek": 310838, "start": 3129.58, "end": 3137.02, "text": " wants to have a consistent framework, but is okay with the incompleteness. And I wonder if", "tokens": [51424, 2738, 281, 362, 257, 8398, 8388, 11, 457, 307, 1392, 365, 264, 14036, 14657, 15264, 13, 400, 286, 2441, 498, 51796], "temperature": 0.0, "avg_logprob": -0.0959869341903858, "compression_ratio": 1.7102803738317758, "no_speech_prob": 0.0008481238037347794}, {"id": 551, "seek": 313702, "start": 3137.1, "end": 3142.86, "text": " similar approach could be taken with consciousness where we could in fact prove that consciousness", "tokens": [50368, 2531, 3109, 727, 312, 2726, 365, 10081, 689, 321, 727, 294, 1186, 7081, 300, 10081, 50656], "temperature": 0.0, "avg_logprob": -0.09799075656467014, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.001147086382843554}, {"id": 552, "seek": 313702, "start": 3142.86, "end": 3149.02, "text": " is independent of Daniel Dennett's set of axioms. The same way they proved after Girdel, they", "tokens": [50656, 307, 6695, 295, 8033, 19027, 3093, 311, 992, 295, 6360, 72, 4785, 13, 440, 912, 636, 436, 14617, 934, 460, 1271, 338, 11, 436, 50964], "temperature": 0.0, "avg_logprob": -0.09799075656467014, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.001147086382843554}, {"id": 553, "seek": 313702, "start": 3149.02, "end": 3154.22, "text": " proved like the continuum hypothesis was independent of ZF set theory. And then they added", "tokens": [50964, 14617, 411, 264, 36120, 17291, 390, 6695, 295, 1176, 37, 992, 5261, 13, 400, 550, 436, 3869, 51224], "temperature": 0.0, "avg_logprob": -0.09799075656467014, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.001147086382843554}, {"id": 554, "seek": 313702, "start": 3154.86, "end": 3162.14, "text": " the axiom of choice made at ZFC set theory. So I wonder if we could show that like in Daniel", "tokens": [51256, 264, 6360, 72, 298, 295, 3922, 1027, 412, 1176, 18671, 992, 5261, 13, 407, 286, 2441, 498, 321, 727, 855, 300, 411, 294, 8033, 51620], "temperature": 0.0, "avg_logprob": -0.09799075656467014, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.001147086382843554}, {"id": 555, "seek": 316214, "start": 3162.14, "end": 3167.2599999999998, "text": " Dennett's world we are essentially zombies or we are kind of either zombies or not. It doesn't", "tokens": [50364, 19027, 3093, 311, 1002, 321, 366, 4476, 24230, 420, 321, 366, 733, 295, 2139, 24230, 420, 406, 13, 467, 1177, 380, 50620], "temperature": 0.0, "avg_logprob": -0.13646359192697624, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.002971504582092166}, {"id": 556, "seek": 316214, "start": 3167.2599999999998, "end": 3173.66, "text": " matter. Either statement could be true. And then find what is like the minimum axiom that has to be", "tokens": [50620, 1871, 13, 13746, 5629, 727, 312, 2074, 13, 400, 550, 915, 437, 307, 411, 264, 7285, 6360, 72, 298, 300, 575, 281, 312, 50940], "temperature": 0.0, "avg_logprob": -0.13646359192697624, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.002971504582092166}, {"id": 557, "seek": 316214, "start": 3173.66, "end": 3179.5, "text": " added to Dennett's axioms in order to make consciousness true. Interesting. I thought for a", "tokens": [50940, 3869, 281, 19027, 3093, 311, 6360, 72, 4785, 294, 1668, 281, 652, 10081, 2074, 13, 14711, 13, 286, 1194, 337, 257, 51232], "temperature": 0.0, "avg_logprob": -0.13646359192697624, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.002971504582092166}, {"id": 558, "seek": 316214, "start": 3179.5, "end": 3183.02, "text": " moment this was going to go in a different direction. And you're going to say Dennett is", "tokens": [51232, 1623, 341, 390, 516, 281, 352, 294, 257, 819, 3513, 13, 400, 291, 434, 516, 281, 584, 19027, 3093, 307, 51408], "temperature": 0.0, "avg_logprob": -0.13646359192697624, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.002971504582092166}, {"id": 559, "seek": 316214, "start": 3184.46, "end": 3189.1, "text": " consistent but incomplete. He doesn't have consciousness in this picture. I'm complete,", "tokens": [51480, 8398, 457, 31709, 13, 634, 1177, 380, 362, 10081, 294, 341, 3036, 13, 286, 478, 3566, 11, 51712], "temperature": 0.0, "avg_logprob": -0.13646359192697624, "compression_ratio": 1.7340823970037453, "no_speech_prob": 0.002971504582092166}, {"id": 560, "seek": 318910, "start": 3189.18, "end": 3192.62, "text": " I've got consciousness, but inconsistent. That's why I say all these crazy things.", "tokens": [50368, 286, 600, 658, 10081, 11, 457, 36891, 13, 663, 311, 983, 286, 584, 439, 613, 3219, 721, 13, 50540], "temperature": 0.0, "avg_logprob": -0.18115694146407277, "compression_ratio": 1.62109375, "no_speech_prob": 0.0011471905745565891}, {"id": 561, "seek": 318910, "start": 3194.14, "end": 3198.86, "text": " And you're faced with the choice of not having consciousness and being incomplete or having", "tokens": [50616, 400, 291, 434, 11446, 365, 264, 3922, 295, 406, 1419, 10081, 293, 885, 31709, 420, 1419, 50852], "temperature": 0.0, "avg_logprob": -0.18115694146407277, "compression_ratio": 1.62109375, "no_speech_prob": 0.0011471905745565891}, {"id": 562, "seek": 318910, "start": 3198.86, "end": 3203.18, "text": " consciousness and somehow getting this hard problem and being forced into at least puzzles", "tokens": [50852, 10081, 293, 6063, 1242, 341, 1152, 1154, 293, 885, 7579, 666, 412, 1935, 24138, 51068], "temperature": 0.0, "avg_logprob": -0.18115694146407277, "compression_ratio": 1.62109375, "no_speech_prob": 0.0011471905745565891}, {"id": 563, "seek": 318910, "start": 3203.18, "end": 3205.98, "text": " and paradoxes. But the way you put it was friendlier to me.", "tokens": [51068, 293, 26221, 279, 13, 583, 264, 636, 291, 829, 309, 390, 1277, 2753, 281, 385, 13, 51208], "temperature": 0.0, "avg_logprob": -0.18115694146407277, "compression_ratio": 1.62109375, "no_speech_prob": 0.0011471905745565891}, {"id": 564, "seek": 318910, "start": 3210.22, "end": 3215.66, "text": " Yeah, I mean certainly Dark Hofstetter himself has written a lot on analogies between the", "tokens": [51420, 865, 11, 286, 914, 3297, 9563, 37379, 372, 27296, 3647, 575, 3720, 257, 688, 322, 16660, 530, 1296, 264, 51692], "temperature": 0.0, "avg_logprob": -0.18115694146407277, "compression_ratio": 1.62109375, "no_speech_prob": 0.0011471905745565891}, {"id": 565, "seek": 321566, "start": 3215.66, "end": 3221.1, "text": " Gordelian paradoxes and the mind-body problem. And he thinks always our models, our self models", "tokens": [50364, 460, 765, 338, 952, 26221, 279, 293, 264, 1575, 12, 1067, 1154, 13, 400, 415, 7309, 1009, 527, 5245, 11, 527, 2698, 5245, 50636], "temperature": 0.0, "avg_logprob": -0.13457701887403214, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0004720319411717355}, {"id": 566, "seek": 321566, "start": 3221.1, "end": 3225.74, "text": " are always doomed to be incomplete in the Gordelian way. And he thinks that that might be somehow", "tokens": [50636, 366, 1009, 33847, 281, 312, 31709, 294, 264, 460, 765, 338, 952, 636, 13, 400, 415, 7309, 300, 300, 1062, 312, 6063, 50868], "temperature": 0.0, "avg_logprob": -0.13457701887403214, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0004720319411717355}, {"id": 567, "seek": 321566, "start": 3225.74, "end": 3230.94, "text": " part of the explanation of our puzzlement at least about consciousness. Someone like Roger Penrose,", "tokens": [50868, 644, 295, 264, 10835, 295, 527, 18741, 3054, 412, 1935, 466, 10081, 13, 8734, 411, 17666, 10571, 37841, 11, 51128], "temperature": 0.0, "avg_logprob": -0.13457701887403214, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0004720319411717355}, {"id": 568, "seek": 321566, "start": 3230.94, "end": 3237.74, "text": " of course, takes this much more seriously, literally. He thinks that the computational", "tokens": [51128, 295, 1164, 11, 2516, 341, 709, 544, 6638, 11, 3736, 13, 634, 7309, 300, 264, 28270, 51468], "temperature": 0.0, "avg_logprob": -0.13457701887403214, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0004720319411717355}, {"id": 569, "seek": 321566, "start": 3237.74, "end": 3244.06, "text": " aspects of computational systems are always going to be limited in the Gordel way. He thinks human", "tokens": [51468, 7270, 295, 28270, 3652, 366, 1009, 516, 281, 312, 5567, 294, 264, 460, 765, 338, 636, 13, 634, 7309, 1952, 51784], "temperature": 0.0, "avg_logprob": -0.13457701887403214, "compression_ratio": 1.8075471698113208, "no_speech_prob": 0.0004720319411717355}, {"id": 570, "seek": 324406, "start": 3244.06, "end": 3248.62, "text": " beings are not so limited. He thinks we've got mathematical capacities to prove theorems,", "tokens": [50364, 8958, 366, 406, 370, 5567, 13, 634, 7309, 321, 600, 658, 18894, 39396, 281, 7081, 10299, 2592, 11, 50592], "temperature": 0.0, "avg_logprob": -0.080785033816383, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0005181321175768971}, {"id": 571, "seek": 324406, "start": 3249.58, "end": 3255.2599999999998, "text": " to see the truth of certain mathematical claims that no formal system could ever have.", "tokens": [50640, 281, 536, 264, 3494, 295, 1629, 18894, 9441, 300, 572, 9860, 1185, 727, 1562, 362, 13, 50924], "temperature": 0.0, "avg_logprob": -0.080785033816383, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0005181321175768971}, {"id": 572, "seek": 324406, "start": 3255.82, "end": 3260.38, "text": " So he thinks that we somehow go beyond that incomplete Gordelian. I don't know if he actually", "tokens": [50952, 407, 415, 7309, 300, 321, 6063, 352, 4399, 300, 31709, 460, 765, 338, 952, 13, 286, 500, 380, 458, 498, 415, 767, 51180], "temperature": 0.0, "avg_logprob": -0.080785033816383, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0005181321175768971}, {"id": 573, "seek": 324406, "start": 3260.38, "end": 3264.86, "text": " thinks we're complete, but at least we're not incomplete in the way that finite computational", "tokens": [51180, 7309, 321, 434, 3566, 11, 457, 412, 1935, 321, 434, 406, 31709, 294, 264, 636, 300, 19362, 28270, 51404], "temperature": 0.0, "avg_logprob": -0.080785033816383, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0005181321175768971}, {"id": 574, "seek": 324406, "start": 3264.86, "end": 3270.22, "text": " systems are incomplete. And furthermore, he thinks that extra thing that humans have is tied to", "tokens": [51404, 3652, 366, 31709, 13, 400, 3052, 3138, 11, 415, 7309, 300, 2857, 551, 300, 6255, 362, 307, 9601, 281, 51672], "temperature": 0.0, "avg_logprob": -0.080785033816383, "compression_ratio": 1.776061776061776, "no_speech_prob": 0.0005181321175768971}, {"id": 575, "seek": 327022, "start": 3270.22, "end": 3275.18, "text": " consciousness. I mean, I never quite saw how that last step goes, even if we did have these", "tokens": [50364, 10081, 13, 286, 914, 11, 286, 1128, 1596, 1866, 577, 300, 1036, 1823, 1709, 11, 754, 498, 321, 630, 362, 613, 50612], "temperature": 0.0, "avg_logprob": -0.07551593250698513, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.0006967830704525113}, {"id": 576, "seek": 327022, "start": 3275.18, "end": 3279.5, "text": " special non-algorithmic capacities to see the truth of mathematical theorems. How would that be", "tokens": [50612, 2121, 2107, 12, 20422, 6819, 13195, 39396, 281, 536, 264, 3494, 295, 18894, 10299, 2592, 13, 1012, 576, 300, 312, 50828], "temperature": 0.0, "avg_logprob": -0.07551593250698513, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.0006967830704525113}, {"id": 577, "seek": 327022, "start": 3279.5, "end": 3287.1, "text": " tied to consciousness? But at the very least, there are structural analogies to be drawn between", "tokens": [50828, 9601, 281, 10081, 30, 583, 412, 264, 588, 1935, 11, 456, 366, 15067, 16660, 530, 281, 312, 10117, 1296, 51208], "temperature": 0.0, "avg_logprob": -0.07551593250698513, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.0006967830704525113}, {"id": 578, "seek": 327022, "start": 3287.1, "end": 3291.4199999999996, "text": " those two cases about incompleteness of certain theories, how literally we should take the analogies", "tokens": [51208, 729, 732, 3331, 466, 14036, 14657, 15264, 295, 1629, 13667, 11, 577, 3736, 321, 820, 747, 264, 16660, 530, 51424], "temperature": 0.0, "avg_logprob": -0.07551593250698513, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.0006967830704525113}, {"id": 579, "seek": 327022, "start": 3291.4199999999996, "end": 3298.22, "text": " I'd have to think about. Has there been some consideration that the problem of understanding", "tokens": [51424, 286, 1116, 362, 281, 519, 466, 13, 8646, 456, 668, 512, 12381, 300, 264, 1154, 295, 3701, 51764], "temperature": 0.0, "avg_logprob": -0.07551593250698513, "compression_ratio": 1.6830985915492958, "no_speech_prob": 0.0006967830704525113}, {"id": 580, "seek": 329822, "start": 3298.22, "end": 3302.8599999999997, "text": " consciousness sort of inherently must be difficult because we address the problem", "tokens": [50364, 10081, 1333, 295, 27993, 1633, 312, 2252, 570, 321, 2985, 264, 1154, 50596], "temperature": 0.0, "avg_logprob": -0.07868418039060106, "compression_ratio": 1.7803030303030303, "no_speech_prob": 0.0021271214354783297}, {"id": 581, "seek": 329822, "start": 3302.8599999999997, "end": 3308.9399999999996, "text": " using consciousness? I'm reminded of the halting problem in computer science where we say that", "tokens": [50596, 1228, 10081, 30, 286, 478, 15920, 295, 264, 7523, 783, 1154, 294, 3820, 3497, 689, 321, 584, 300, 50900], "temperature": 0.0, "avg_logprob": -0.07868418039060106, "compression_ratio": 1.7803030303030303, "no_speech_prob": 0.0021271214354783297}, {"id": 582, "seek": 329822, "start": 3308.9399999999996, "end": 3313.98, "text": " in the general case, a program cannot be written to tell whether another program will halt because", "tokens": [50900, 294, 264, 2674, 1389, 11, 257, 1461, 2644, 312, 3720, 281, 980, 1968, 1071, 1461, 486, 12479, 570, 51152], "temperature": 0.0, "avg_logprob": -0.07868418039060106, "compression_ratio": 1.7803030303030303, "no_speech_prob": 0.0021271214354783297}, {"id": 583, "seek": 329822, "start": 3313.98, "end": 3319.74, "text": " what if you ran it on itself? It can't sort of be broad enough to include its own execution. So I", "tokens": [51152, 437, 498, 291, 5872, 309, 322, 2564, 30, 467, 393, 380, 1333, 295, 312, 4152, 1547, 281, 4090, 1080, 1065, 15058, 13, 407, 286, 51440], "temperature": 0.0, "avg_logprob": -0.07868418039060106, "compression_ratio": 1.7803030303030303, "no_speech_prob": 0.0021271214354783297}, {"id": 584, "seek": 329822, "start": 3319.74, "end": 3324.7, "text": " wonder if there's a similar corollary in consciousness where we use consciousness to think about", "tokens": [51440, 2441, 498, 456, 311, 257, 2531, 1181, 1833, 822, 294, 10081, 689, 321, 764, 10081, 281, 519, 466, 51688], "temperature": 0.0, "avg_logprob": -0.07868418039060106, "compression_ratio": 1.7803030303030303, "no_speech_prob": 0.0021271214354783297}, {"id": 585, "seek": 332470, "start": 3324.7, "end": 3331.5, "text": " consciousness. And so therefore, we may not have enough sort of equipment there to be able to unpack", "tokens": [50364, 10081, 13, 400, 370, 4412, 11, 321, 815, 406, 362, 1547, 1333, 295, 5927, 456, 281, 312, 1075, 281, 26699, 50704], "temperature": 0.0, "avg_logprob": -0.12619977161802096, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0007311988738365471}, {"id": 586, "seek": 332470, "start": 3332.7, "end": 3338.22, "text": " Yeah, I mean, it's tricky. People say it's like a user ruler to measure a ruler. Well, I can use", "tokens": [50764, 865, 11, 286, 914, 11, 309, 311, 12414, 13, 3432, 584, 309, 311, 411, 257, 4195, 19661, 281, 3481, 257, 19661, 13, 1042, 11, 286, 393, 764, 51040], "temperature": 0.0, "avg_logprob": -0.12619977161802096, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0007311988738365471}, {"id": 587, "seek": 332470, "start": 3338.22, "end": 3343.58, "text": " this ruler to measure many other things, but it can't measure itself. On the other hand,", "tokens": [51040, 341, 19661, 281, 3481, 867, 661, 721, 11, 457, 309, 393, 380, 3481, 2564, 13, 1282, 264, 661, 1011, 11, 51308], "temperature": 0.0, "avg_logprob": -0.12619977161802096, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0007311988738365471}, {"id": 588, "seek": 332470, "start": 3343.58, "end": 3348.3799999999997, "text": " you can measure one ruler using another ruler. Maybe you can measure one consciousness using", "tokens": [51308, 291, 393, 3481, 472, 19661, 1228, 1071, 19661, 13, 2704, 291, 393, 3481, 472, 10081, 1228, 51548], "temperature": 0.0, "avg_logprob": -0.12619977161802096, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0007311988738365471}, {"id": 589, "seek": 332470, "start": 3348.3799999999997, "end": 3353.8199999999997, "text": " another. The brain can't study the brain, but the brain actually has a pretty good job of studying.", "tokens": [51548, 1071, 13, 440, 3567, 393, 380, 2979, 264, 3567, 11, 457, 264, 3567, 767, 575, 257, 1238, 665, 1691, 295, 7601, 13, 51820], "temperature": 0.0, "avg_logprob": -0.12619977161802096, "compression_ratio": 1.8282442748091603, "no_speech_prob": 0.0007311988738365471}, {"id": 590, "seek": 335470, "start": 3354.7, "end": 3359.5, "text": " The brain. So there are some self referential paradoxes there. And I think that again is at", "tokens": [50364, 440, 3567, 13, 407, 456, 366, 512, 2698, 2864, 2549, 26221, 279, 456, 13, 400, 286, 519, 300, 797, 307, 412, 50604], "temperature": 0.0, "avg_logprob": -0.09117057867217482, "compression_ratio": 1.6783216783216783, "no_speech_prob": 0.0004437877214513719}, {"id": 591, "seek": 335470, "start": 3359.5, "end": 3364.8599999999997, "text": " the heart of Hofstadter's approach. But I think we'd have to look for very, very specific conditions", "tokens": [50604, 264, 1917, 295, 37379, 48299, 391, 311, 3109, 13, 583, 286, 519, 321, 1116, 362, 281, 574, 337, 588, 11, 588, 2685, 4487, 50872], "temperature": 0.0, "avg_logprob": -0.09117057867217482, "compression_ratio": 1.6783216783216783, "no_speech_prob": 0.0004437877214513719}, {"id": 592, "seek": 335470, "start": 3364.8599999999997, "end": 3370.22, "text": " under which systems can't study themselves. I did always like the idea that the mind was simple", "tokens": [50872, 833, 597, 3652, 393, 380, 2979, 2969, 13, 286, 630, 1009, 411, 264, 1558, 300, 264, 1575, 390, 2199, 51140], "temperature": 0.0, "avg_logprob": -0.09117057867217482, "compression_ratio": 1.6783216783216783, "no_speech_prob": 0.0004437877214513719}, {"id": 593, "seek": 335470, "start": 3370.22, "end": 3377.5, "text": " enough that we could understand it. We would be too simple to understand the mind. So maybe", "tokens": [51140, 1547, 300, 321, 727, 1223, 309, 13, 492, 576, 312, 886, 2199, 281, 1223, 264, 1575, 13, 407, 1310, 51504], "temperature": 0.0, "avg_logprob": -0.09117057867217482, "compression_ratio": 1.6783216783216783, "no_speech_prob": 0.0004437877214513719}, {"id": 594, "seek": 335470, "start": 3377.5, "end": 3381.18, "text": " something like that could be true of consciousness. On the other hand, I actually think that if you", "tokens": [51504, 746, 411, 300, 727, 312, 2074, 295, 10081, 13, 1282, 264, 661, 1011, 11, 286, 767, 519, 300, 498, 291, 51688], "temperature": 0.0, "avg_logprob": -0.09117057867217482, "compression_ratio": 1.6783216783216783, "no_speech_prob": 0.0004437877214513719}, {"id": 595, "seek": 338118, "start": 3381.18, "end": 3385.2599999999998, "text": " start thinking that consciousness can go along with very simple systems, I think at the very", "tokens": [50364, 722, 1953, 300, 10081, 393, 352, 2051, 365, 588, 2199, 3652, 11, 286, 519, 412, 264, 588, 50568], "temperature": 0.0, "avg_logprob": -0.08643149454659278, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.00026427165721543133}, {"id": 596, "seek": 338118, "start": 3385.2599999999998, "end": 3390.14, "text": " least we ought to be able to study consciousness in other systems simpler than ourselves. And boy,", "tokens": [50568, 1935, 321, 13416, 281, 312, 1075, 281, 2979, 10081, 294, 661, 3652, 18587, 813, 4175, 13, 400, 3237, 11, 50812], "temperature": 0.0, "avg_logprob": -0.08643149454659278, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.00026427165721543133}, {"id": 597, "seek": 338118, "start": 3390.14, "end": 3396.7, "text": " if I could solve the hard problem, even in dogs, I'd be I'd be satisfied. Hey, so I have a question", "tokens": [50812, 498, 286, 727, 5039, 264, 1152, 1154, 11, 754, 294, 7197, 11, 286, 1116, 312, 286, 1116, 312, 11239, 13, 1911, 11, 370, 286, 362, 257, 1168, 51140], "temperature": 0.0, "avg_logprob": -0.08643149454659278, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.00026427165721543133}, {"id": 598, "seek": 338118, "start": 3396.7, "end": 3402.54, "text": " about how the meta problem research program might proceed sort of related to the last question.", "tokens": [51140, 466, 577, 264, 19616, 1154, 2132, 1461, 1062, 8991, 1333, 295, 4077, 281, 264, 1036, 1168, 13, 51432], "temperature": 0.0, "avg_logprob": -0.08643149454659278, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.00026427165721543133}, {"id": 599, "seek": 338118, "start": 3403.2599999999998, "end": 3409.4199999999996, "text": " So certainly things we believe about our own consciousness, even if we all say them,", "tokens": [51468, 407, 3297, 721, 321, 1697, 466, 527, 1065, 10081, 11, 754, 498, 321, 439, 584, 552, 11, 51776], "temperature": 0.0, "avg_logprob": -0.08643149454659278, "compression_ratio": 1.7416974169741697, "no_speech_prob": 0.00026427165721543133}, {"id": 600, "seek": 340942, "start": 3409.42, "end": 3414.94, "text": " probably some of them are false. Our brain has a tendency to hide what reality is like.", "tokens": [50364, 1391, 512, 295, 552, 366, 7908, 13, 2621, 3567, 575, 257, 18187, 281, 6479, 437, 4103, 307, 411, 13, 50640], "temperature": 0.0, "avg_logprob": -0.08583183946280644, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.0009387456811964512}, {"id": 601, "seek": 340942, "start": 3415.82, "end": 3419.9, "text": " If you look at like visual perception, you know, there's what's called lightness constancy, you", "tokens": [50684, 759, 291, 574, 412, 411, 5056, 12860, 11, 291, 458, 11, 456, 311, 437, 311, 1219, 1442, 1287, 1817, 6717, 11, 291, 50888], "temperature": 0.0, "avg_logprob": -0.08583183946280644, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.0009387456811964512}, {"id": 602, "seek": 340942, "start": 3419.9, "end": 3424.7000000000003, "text": " know, our brain subtracts out the lighting in the environment. So we actually see more reliably", "tokens": [50888, 458, 11, 527, 3567, 16390, 82, 484, 264, 9577, 294, 264, 2823, 13, 407, 321, 767, 536, 544, 49927, 51128], "temperature": 0.0, "avg_logprob": -0.08583183946280644, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.0009387456811964512}, {"id": 603, "seek": 340942, "start": 3424.7000000000003, "end": 3429.98, "text": " what the colors of objects are. Like these viral examples of like the black and gold dress is an", "tokens": [51128, 437, 264, 4577, 295, 6565, 366, 13, 1743, 613, 16132, 5110, 295, 411, 264, 2211, 293, 3821, 5231, 307, 364, 51392], "temperature": 0.0, "avg_logprob": -0.08583183946280644, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.0009387456811964512}, {"id": 604, "seek": 340942, "start": 3429.98, "end": 3434.54, "text": " example of this. And when you're kind of presented with an explanation of it, it's like, huh, my", "tokens": [51392, 1365, 295, 341, 13, 400, 562, 291, 434, 733, 295, 8212, 365, 364, 10835, 295, 309, 11, 309, 311, 411, 11, 7020, 11, 452, 51620], "temperature": 0.0, "avg_logprob": -0.08583183946280644, "compression_ratio": 1.6596491228070176, "no_speech_prob": 0.0009387456811964512}, {"id": 605, "seek": 343454, "start": 3434.62, "end": 3440.38, "text": " brain does that. It's not something we have access to. Yeah. Or like the Yanni Laurel Laurel Yanni.", "tokens": [50368, 3567, 775, 300, 13, 467, 311, 406, 746, 321, 362, 2105, 281, 13, 865, 13, 1610, 411, 264, 398, 35832, 27270, 75, 27270, 75, 398, 35832, 13, 50656], "temperature": 0.0, "avg_logprob": -0.1451573321693822, "compression_ratio": 1.6239669421487604, "no_speech_prob": 0.00026930743479169905}, {"id": 606, "seek": 343454, "start": 3440.38, "end": 3444.3, "text": " Yeah, illusion is like another one where like when you hear the explanation, you know, the scientists", "tokens": [50656, 865, 11, 18854, 307, 411, 1071, 472, 689, 411, 562, 291, 1568, 264, 10835, 11, 291, 458, 11, 264, 7708, 50852], "temperature": 0.0, "avg_logprob": -0.1451573321693822, "compression_ratio": 1.6239669421487604, "no_speech_prob": 0.00026930743479169905}, {"id": 607, "seek": 343454, "start": 3444.3, "end": 3449.9, "text": " that understand it, our own introspection doesn't include that. So how do you kind of proceed with", "tokens": [50852, 300, 1223, 309, 11, 527, 1065, 560, 2635, 19997, 1177, 380, 4090, 300, 13, 407, 577, 360, 291, 733, 295, 8991, 365, 51132], "temperature": 0.0, "avg_logprob": -0.1451573321693822, "compression_ratio": 1.6239669421487604, "no_speech_prob": 0.00026930743479169905}, {"id": 608, "seek": 343454, "start": 3451.2599999999998, "end": 3457.02, "text": " trying to get at what consciousness really is versus what our sort of whatever simplified or", "tokens": [51200, 1382, 281, 483, 412, 437, 10081, 534, 307, 5717, 437, 527, 1333, 295, 2035, 26335, 420, 51488], "temperature": 0.0, "avg_logprob": -0.1451573321693822, "compression_ratio": 1.6239669421487604, "no_speech_prob": 0.00026930743479169905}, {"id": 609, "seek": 345702, "start": 3457.02, "end": 3464.3, "text": " distorted view might be? Yeah, well, one view here would be that we never have access to the", "tokens": [50364, 33431, 1910, 1062, 312, 30, 865, 11, 731, 11, 472, 1910, 510, 576, 312, 300, 321, 1128, 362, 2105, 281, 264, 50728], "temperature": 0.0, "avg_logprob": -0.14150687626429967, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.002016864949837327}, {"id": 610, "seek": 345702, "start": 3464.3, "end": 3469.5, "text": " mechanisms that generate consciousness, but we still have access to the conscious states", "tokens": [50728, 15902, 300, 8460, 10081, 11, 457, 321, 920, 362, 2105, 281, 264, 6648, 4368, 50988], "temperature": 0.0, "avg_logprob": -0.14150687626429967, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.002016864949837327}, {"id": 611, "seek": 345702, "start": 3469.5, "end": 3473.98, "text": " themselves. Actually, the Colashley said this decades ago, he said, no process of the brain", "tokens": [50988, 2969, 13, 5135, 11, 264, 4004, 1299, 3420, 848, 341, 7878, 2057, 11, 415, 848, 11, 572, 1399, 295, 264, 3567, 51212], "temperature": 0.0, "avg_logprob": -0.14150687626429967, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.002016864949837327}, {"id": 612, "seek": 345702, "start": 3473.98, "end": 3479.34, "text": " is ever conscious. The processes that get you to the states are never conscious. The states they", "tokens": [51212, 307, 1562, 6648, 13, 440, 7555, 300, 483, 291, 281, 264, 4368, 366, 1128, 6648, 13, 440, 4368, 436, 51480], "temperature": 0.0, "avg_logprob": -0.14150687626429967, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.002016864949837327}, {"id": 613, "seek": 345702, "start": 3479.34, "end": 3485.34, "text": " get you to are conscious. So take your experience of the dress. For me, it was, it was what, white", "tokens": [51480, 483, 291, 281, 366, 6648, 13, 407, 747, 428, 1752, 295, 264, 5231, 13, 1171, 385, 11, 309, 390, 11, 309, 390, 437, 11, 2418, 51780], "temperature": 0.0, "avg_logprob": -0.14150687626429967, "compression_ratio": 1.8611111111111112, "no_speech_prob": 0.002016864949837327}, {"id": 614, "seek": 348534, "start": 3485.42, "end": 3491.1000000000004, "text": " and gold. So, you know, and I knew that, you know, each of us was certain that I am, I was", "tokens": [50368, 293, 3821, 13, 407, 11, 291, 458, 11, 293, 286, 2586, 300, 11, 291, 458, 11, 1184, 295, 505, 390, 1629, 300, 286, 669, 11, 286, 390, 50652], "temperature": 0.0, "avg_logprob": -0.1548247110275995, "compression_ratio": 1.9672131147540983, "no_speech_prob": 0.003696442348882556}, {"id": 615, "seek": 348534, "start": 3491.1000000000004, "end": 3495.1800000000003, "text": " experiencing, I was certain that I was experiencing white and gold. Maybe you were certain that you", "tokens": [50652, 11139, 11, 286, 390, 1629, 300, 286, 390, 11139, 2418, 293, 3821, 13, 2704, 291, 645, 1629, 300, 291, 50856], "temperature": 0.0, "avg_logprob": -0.1548247110275995, "compression_ratio": 1.9672131147540983, "no_speech_prob": 0.003696442348882556}, {"id": 616, "seek": 348534, "start": 3495.1800000000003, "end": 3501.34, "text": " were experiencing blue and black. Which it was. I remember as I was right. You were sure that, yeah,", "tokens": [50856, 645, 11139, 3344, 293, 2211, 13, 3013, 309, 390, 13, 286, 1604, 382, 286, 390, 558, 13, 509, 645, 988, 300, 11, 1338, 11, 51164], "temperature": 0.0, "avg_logprob": -0.1548247110275995, "compression_ratio": 1.9672131147540983, "no_speech_prob": 0.003696442348882556}, {"id": 617, "seek": 348534, "start": 3502.38, "end": 3508.06, "text": " those idiots can't be, yeah, can't be looking at this right. But anyway, each of us, I think the", "tokens": [51216, 729, 36454, 393, 380, 312, 11, 1338, 11, 393, 380, 312, 1237, 412, 341, 558, 13, 583, 4033, 11, 1184, 295, 505, 11, 286, 519, 264, 51500], "temperature": 0.0, "avg_logprob": -0.1548247110275995, "compression_ratio": 1.9672131147540983, "no_speech_prob": 0.003696442348882556}, {"id": 618, "seek": 348534, "start": 3508.06, "end": 3511.82, "text": " natural way to describe this at least is that each of us was certain what kind of conscious", "tokens": [51500, 3303, 636, 281, 6786, 341, 412, 1935, 307, 300, 1184, 295, 505, 390, 1629, 437, 733, 295, 6648, 51688], "temperature": 0.0, "avg_logprob": -0.1548247110275995, "compression_ratio": 1.9672131147540983, "no_speech_prob": 0.003696442348882556}, {"id": 619, "seek": 351182, "start": 3511.82, "end": 3516.7000000000003, "text": " experience we were having. But what we had no idea about was the mechanisms by which we got", "tokens": [50364, 1752, 321, 645, 1419, 13, 583, 437, 321, 632, 572, 1558, 466, 390, 264, 15902, 538, 597, 321, 658, 50608], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 620, "seek": 351182, "start": 3516.7000000000003, "end": 3522.2200000000003, "text": " there. So the mechanisms are completely opaque. But the states themselves were at least prima facie", "tokens": [50608, 456, 13, 407, 264, 15902, 366, 2584, 42687, 13, 583, 264, 4368, 2969, 645, 412, 1935, 19507, 1915, 414, 50884], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 621, "seek": 351182, "start": 3522.2200000000003, "end": 3525.5800000000004, "text": " transparent. So I think that would be the standard of view. And even a realist about consciousness", "tokens": [50884, 12737, 13, 407, 286, 519, 300, 576, 312, 264, 3832, 295, 1910, 13, 400, 754, 257, 957, 468, 466, 10081, 51052], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 622, "seek": 351182, "start": 3526.2200000000003, "end": 3530.1400000000003, "text": " could go with that. They say, well, we know what conscious states, we know what those conscious", "tokens": [51084, 727, 352, 365, 300, 13, 814, 584, 11, 731, 11, 321, 458, 437, 6648, 4368, 11, 321, 458, 437, 729, 6648, 51280], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 623, "seek": 351182, "start": 3530.1400000000003, "end": 3534.54, "text": " states are. We don't know the processes by which they're generated. The illusionist, I think,", "tokens": [51280, 4368, 366, 13, 492, 500, 380, 458, 264, 7555, 538, 597, 436, 434, 10833, 13, 440, 18854, 468, 11, 286, 519, 11, 51500], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 624, "seek": 351182, "start": 3534.54, "end": 3539.5, "text": " wants to go much further and say, well, it seems to you that you know what conscious state you're", "tokens": [51500, 2738, 281, 352, 709, 3052, 293, 584, 11, 731, 11, 309, 2544, 281, 291, 300, 291, 458, 437, 6648, 1785, 291, 434, 51748], "temperature": 0.0, "avg_logprob": -0.09601343809253107, "compression_ratio": 1.8827361563517915, "no_speech_prob": 0.000778311921749264}, {"id": 625, "seek": 353950, "start": 3539.5, "end": 3544.94, "text": " having. It seems to you that you're experiencing yellow and gold. Sorry, yellow and white, whatever", "tokens": [50364, 1419, 13, 467, 2544, 281, 291, 300, 291, 434, 11139, 5566, 293, 3821, 13, 4919, 11, 5566, 293, 2418, 11, 2035, 50636], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 626, "seek": 353950, "start": 3544.94, "end": 3550.14, "text": " it was, golden, gold and white. Black and gold is whatever. Black and blue, I think. And blue.", "tokens": [50636, 309, 390, 11, 9729, 11, 3821, 293, 2418, 13, 4076, 293, 3821, 307, 2035, 13, 4076, 293, 3344, 11, 286, 519, 13, 400, 3344, 13, 50896], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 627, "seek": 353950, "start": 3550.14, "end": 3555.9, "text": " Gold and white. Yeah. It seems to you that you're experiencing gold and white. But in fact, that", "tokens": [50896, 6731, 293, 2418, 13, 865, 13, 467, 2544, 281, 291, 300, 291, 434, 11139, 3821, 293, 2418, 13, 583, 294, 1186, 11, 300, 51184], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 628, "seek": 353950, "start": 3555.9, "end": 3561.18, "text": " too is just something thrown up by another model. The yellow gold was a perceptual model. And then", "tokens": [51184, 886, 307, 445, 746, 11732, 493, 538, 1071, 2316, 13, 440, 5566, 3821, 390, 257, 43276, 901, 2316, 13, 400, 550, 51448], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 629, "seek": 353950, "start": 3561.18, "end": 3565.66, "text": " there was an introspective model that said you're experiencing gold and white. When maybe, in fact,", "tokens": [51448, 456, 390, 364, 560, 28713, 488, 2316, 300, 848, 291, 434, 11139, 3821, 293, 2418, 13, 1133, 1310, 11, 294, 1186, 11, 51672], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 630, "seek": 353950, "start": 3565.66, "end": 3569.1, "text": " you're just a zombie or who knows what's actually going on in your conscious state. So", "tokens": [51672, 291, 434, 445, 257, 20310, 420, 567, 3255, 437, 311, 767, 516, 322, 294, 428, 6648, 1785, 13, 407, 51844], "temperature": 0.0, "avg_logprob": -0.15262156519396552, "compression_ratio": 2.0533807829181496, "no_speech_prob": 0.0006663050735369325}, {"id": 631, "seek": 356910, "start": 3569.1, "end": 3573.3399999999997, "text": " the illusionist view, I think, has to somehow take this further and say not just the processes", "tokens": [50364, 264, 18854, 468, 1910, 11, 286, 519, 11, 575, 281, 6063, 747, 341, 3052, 293, 584, 406, 445, 264, 7555, 50576], "temperature": 0.0, "avg_logprob": -0.12158748891093943, "compression_ratio": 1.7234848484848484, "no_speech_prob": 4.3184718379052356e-05}, {"id": 632, "seek": 356910, "start": 3573.3399999999997, "end": 3577.2599999999998, "text": " that generate the conscious states, but maybe the conscious states themselves are somehow", "tokens": [50576, 300, 8460, 264, 6648, 4368, 11, 457, 1310, 264, 6648, 4368, 2969, 366, 6063, 50772], "temperature": 0.0, "avg_logprob": -0.12158748891093943, "compression_ratio": 1.7234848484848484, "no_speech_prob": 4.3184718379052356e-05}, {"id": 633, "seek": 356910, "start": 3577.2599999999998, "end": 3586.94, "text": " opaque to us. All right. Thanks. It feels like some discussion of generality of a problem is", "tokens": [50772, 42687, 281, 505, 13, 1057, 558, 13, 2561, 13, 467, 3417, 411, 512, 5017, 295, 1337, 1860, 295, 257, 1154, 307, 51256], "temperature": 0.0, "avg_logprob": -0.12158748891093943, "compression_ratio": 1.7234848484848484, "no_speech_prob": 4.3184718379052356e-05}, {"id": 634, "seek": 356910, "start": 3586.94, "end": 3593.02, "text": " missing from this discussion. The matrix multiplier example of having high phi is still,", "tokens": [51256, 5361, 490, 341, 5017, 13, 440, 8141, 44106, 1365, 295, 1419, 1090, 13107, 307, 920, 11, 51560], "temperature": 0.0, "avg_logprob": -0.12158748891093943, "compression_ratio": 1.7234848484848484, "no_speech_prob": 4.3184718379052356e-05}, {"id": 635, "seek": 356910, "start": 3593.02, "end": 3597.98, "text": " it's not a general thing. Is there someone exploring the space, the sort of intersection", "tokens": [51560, 309, 311, 406, 257, 2674, 551, 13, 1119, 456, 1580, 12736, 264, 1901, 11, 264, 1333, 295, 15236, 51808], "temperature": 0.0, "avg_logprob": -0.12158748891093943, "compression_ratio": 1.7234848484848484, "no_speech_prob": 4.3184718379052356e-05}, {"id": 636, "seek": 359798, "start": 3598.06, "end": 3602.3, "text": " of generality and complexity that leads to consciousness as an emergent behavior?", "tokens": [50368, 295, 1337, 1860, 293, 14024, 300, 6689, 281, 10081, 382, 364, 4345, 6930, 5223, 30, 50580], "temperature": 0.0, "avg_logprob": -0.11502241906318955, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0014229919761419296}, {"id": 637, "seek": 359798, "start": 3603.1, "end": 3607.66, "text": " When you say generality, I mean, the idea that a theory should be general, that it should apply", "tokens": [50620, 1133, 291, 584, 1337, 1860, 11, 286, 914, 11, 264, 1558, 300, 257, 5261, 820, 312, 2674, 11, 300, 309, 820, 3079, 50848], "temperature": 0.0, "avg_logprob": -0.11502241906318955, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0014229919761419296}, {"id": 638, "seek": 359798, "start": 3607.66, "end": 3611.9, "text": " to every system, you mean mechanisms of... No, generality of the agent, right? If I can write", "tokens": [50848, 281, 633, 1185, 11, 291, 914, 15902, 295, 485, 883, 11, 1337, 1860, 295, 264, 9461, 11, 558, 30, 759, 286, 393, 2464, 51060], "temperature": 0.0, "avg_logprob": -0.11502241906318955, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0014229919761419296}, {"id": 639, "seek": 359798, "start": 3611.9, "end": 3617.18, "text": " an arbitrarily complex program to play tic-tac-toe, and all it will ever be able to do is play tic-tac-toe,", "tokens": [51060, 364, 19071, 3289, 3997, 1461, 281, 862, 256, 299, 12, 83, 326, 12, 1353, 68, 11, 293, 439, 309, 486, 1562, 312, 1075, 281, 360, 307, 862, 256, 299, 12, 83, 326, 12, 1353, 68, 11, 51324], "temperature": 0.0, "avg_logprob": -0.11502241906318955, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0014229919761419296}, {"id": 640, "seek": 359798, "start": 3617.18, "end": 3623.34, "text": " it has no outputs to express anything else. Yeah. As you said, general in the sense of AGI,", "tokens": [51324, 309, 575, 572, 23930, 281, 5109, 1340, 1646, 13, 865, 13, 1018, 291, 848, 11, 2674, 294, 264, 2020, 295, 316, 26252, 11, 51632], "temperature": 0.0, "avg_logprob": -0.11502241906318955, "compression_ratio": 1.7127272727272727, "no_speech_prob": 0.0014229919761419296}, {"id": 641, "seek": 362334, "start": 3623.34, "end": 3628.46, "text": " artificial general intelligence, I mean, some aspects of consciousness seem to be", "tokens": [50364, 11677, 2674, 7599, 11, 286, 914, 11, 512, 7270, 295, 10081, 1643, 281, 312, 50620], "temperature": 0.0, "avg_logprob": -0.13830762696497648, "compression_ratio": 1.7707509881422925, "no_speech_prob": 0.003021773649379611}, {"id": 642, "seek": 362334, "start": 3628.46, "end": 3633.7400000000002, "text": " domain general, like, for example, maybe as far as belief and reasoning is conscious,", "tokens": [50620, 9274, 2674, 11, 411, 11, 337, 1365, 11, 1310, 382, 1400, 382, 7107, 293, 21577, 307, 6648, 11, 50884], "temperature": 0.0, "avg_logprob": -0.13830762696497648, "compression_ratio": 1.7707509881422925, "no_speech_prob": 0.003021773649379611}, {"id": 643, "seek": 362334, "start": 3633.7400000000002, "end": 3638.1400000000003, "text": " those are domain general, but much of perception doesn't seem especially domain general, right?", "tokens": [50884, 729, 366, 9274, 2674, 11, 457, 709, 295, 12860, 1177, 380, 1643, 2318, 9274, 2674, 11, 558, 30, 51104], "temperature": 0.0, "avg_logprob": -0.13830762696497648, "compression_ratio": 1.7707509881422925, "no_speech_prob": 0.003021773649379611}, {"id": 644, "seek": 362334, "start": 3638.1400000000003, "end": 3643.9, "text": " Color is very domain... Taste is very domain specific, so it's still conscious. If my agent", "tokens": [51104, 10458, 307, 588, 9274, 485, 33770, 307, 588, 9274, 2685, 11, 370, 309, 311, 920, 6648, 13, 759, 452, 9461, 51392], "temperature": 0.0, "avg_logprob": -0.13830762696497648, "compression_ratio": 1.7707509881422925, "no_speech_prob": 0.003021773649379611}, {"id": 645, "seek": 362334, "start": 3643.9, "end": 3648.86, "text": " can't express problem statements, like, if I don't give it an output by which it can express", "tokens": [51392, 393, 380, 5109, 1154, 12363, 11, 411, 11, 498, 286, 500, 380, 976, 309, 364, 5598, 538, 597, 309, 393, 5109, 51640], "temperature": 0.0, "avg_logprob": -0.13830762696497648, "compression_ratio": 1.7707509881422925, "no_speech_prob": 0.003021773649379611}, {"id": 646, "seek": 364886, "start": 3648.86, "end": 3652.06, "text": " problem statements, you can never come to a conclusion about its consciousness.", "tokens": [50364, 1154, 12363, 11, 291, 393, 1128, 808, 281, 257, 10063, 466, 1080, 10081, 13, 50524], "temperature": 0.0, "avg_logprob": -0.12437860092314162, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.0007546137785539031}, {"id": 647, "seek": 364886, "start": 3653.26, "end": 3657.02, "text": " I like to distinguish intelligence and consciousness. I'm even able to... Even natural", "tokens": [50584, 286, 411, 281, 20206, 7599, 293, 10081, 13, 286, 478, 754, 1075, 281, 485, 2754, 3303, 50772], "temperature": 0.0, "avg_logprob": -0.12437860092314162, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.0007546137785539031}, {"id": 648, "seek": 364886, "start": 3657.02, "end": 3661.98, "text": " language and, you know, being able to address a problem statement and analyze a problem,", "tokens": [50772, 2856, 293, 11, 291, 458, 11, 885, 1075, 281, 2985, 257, 1154, 5629, 293, 12477, 257, 1154, 11, 51020], "temperature": 0.0, "avg_logprob": -0.12437860092314162, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.0007546137785539031}, {"id": 649, "seek": 364886, "start": 3661.98, "end": 3669.7400000000002, "text": " that's already a very advanced form of intelligence. I think it's very plausible that, say, a mouse has", "tokens": [51020, 300, 311, 1217, 257, 588, 7339, 1254, 295, 7599, 13, 286, 519, 309, 311, 588, 39925, 300, 11, 584, 11, 257, 9719, 575, 51408], "temperature": 0.0, "avg_logprob": -0.12437860092314162, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.0007546137785539031}, {"id": 650, "seek": 364886, "start": 3669.7400000000002, "end": 3675.1800000000003, "text": " got some kind of consciousness, even it's got no ability to address problem statements in many", "tokens": [51408, 658, 512, 733, 295, 10081, 11, 754, 309, 311, 658, 572, 3485, 281, 2985, 1154, 12363, 294, 867, 51680], "temperature": 0.0, "avg_logprob": -0.12437860092314162, "compression_ratio": 1.8455284552845528, "no_speech_prob": 0.0007546137785539031}, {"id": 651, "seek": 367518, "start": 3675.18, "end": 3679.58, "text": " of its capacities, maybe very specialized. I mean, it's still much more general than, say,", "tokens": [50364, 295, 1080, 39396, 11, 1310, 588, 19813, 13, 286, 914, 11, 309, 311, 920, 709, 544, 2674, 813, 11, 584, 11, 50584], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 652, "seek": 367518, "start": 3679.58, "end": 3684.62, "text": " a simple neural network that can only do one thing. A mouse can do many things, but I'm not", "tokens": [50584, 257, 2199, 18161, 3209, 300, 393, 787, 360, 472, 551, 13, 316, 9719, 393, 360, 867, 721, 11, 457, 286, 478, 406, 50836], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 653, "seek": 367518, "start": 3684.62, "end": 3688.3799999999997, "text": " sure that I see an essential... I certainly see a connection between intelligence and", "tokens": [50836, 988, 300, 286, 536, 364, 7115, 485, 286, 3297, 536, 257, 4984, 1296, 7599, 293, 51024], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 654, "seek": 367518, "start": 3688.3799999999997, "end": 3693.74, "text": " generality. We want to say, you know, somehow a high degree of generality is required for", "tokens": [51024, 1337, 1860, 13, 492, 528, 281, 584, 11, 291, 458, 11, 6063, 257, 1090, 4314, 295, 1337, 1860, 307, 4739, 337, 51292], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 655, "seek": 367518, "start": 3693.74, "end": 3698.22, "text": " high intelligence. I'm not sure there's the same connection for consciousness. I think", "tokens": [51292, 1090, 7599, 13, 286, 478, 406, 988, 456, 311, 264, 912, 4984, 337, 10081, 13, 286, 519, 51516], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 656, "seek": 367518, "start": 3698.22, "end": 3704.7799999999997, "text": " consciousness can be extremely domain specific, has, say, taste and maybe vision or it can be", "tokens": [51516, 10081, 393, 312, 4664, 9274, 2685, 11, 575, 11, 584, 11, 3939, 293, 1310, 5201, 420, 309, 393, 312, 51844], "temperature": 0.0, "avg_logprob": -0.08825220802957698, "compression_ratio": 1.8026755852842808, "no_speech_prob": 0.0020769156981259584}, {"id": 657, "seek": 370478, "start": 3704.78, "end": 3707.6600000000003, "text": " domain general. So maybe those two cross cut each other a bit.", "tokens": [50364, 9274, 2674, 13, 407, 1310, 729, 732, 3278, 1723, 1184, 661, 257, 857, 13, 50508], "temperature": 0.0, "avg_logprob": -0.12536043144134154, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0003352438216097653}, {"id": 658, "seek": 370478, "start": 3711.34, "end": 3718.3, "text": " So it seems to me like the meta problem as it's formulated implies some amount of, like,", "tokens": [50692, 407, 309, 2544, 281, 385, 411, 264, 19616, 1154, 382, 309, 311, 48936, 18779, 512, 2372, 295, 11, 411, 11, 51040], "temperature": 0.0, "avg_logprob": -0.12536043144134154, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0003352438216097653}, {"id": 659, "seek": 370478, "start": 3718.3, "end": 3722.46, "text": " separation or epiphenomenalism between, like, consciousness and brain states.", "tokens": [51040, 14634, 420, 2388, 647, 2932, 4726, 304, 1434, 1296, 11, 411, 11, 10081, 293, 3567, 4368, 13, 51248], "temperature": 0.0, "avg_logprob": -0.12536043144134154, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0003352438216097653}, {"id": 660, "seek": 370478, "start": 3723.1000000000004, "end": 3730.0600000000004, "text": " And one thing that I think underlies a lot of people's motivation to do, say, science is that", "tokens": [51280, 400, 472, 551, 300, 286, 519, 833, 24119, 257, 688, 295, 561, 311, 12335, 281, 360, 11, 584, 11, 3497, 307, 300, 51628], "temperature": 0.0, "avg_logprob": -0.12536043144134154, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0003352438216097653}, {"id": 661, "seek": 373006, "start": 3730.62, "end": 3737.5, "text": " it has causal import. Like, predicting behaviors is clearly a functionally useful thing to do.", "tokens": [50392, 309, 575, 38755, 974, 13, 1743, 11, 32884, 15501, 307, 4448, 257, 2445, 379, 4420, 551, 281, 360, 13, 50736], "temperature": 0.0, "avg_logprob": -0.09580852017544284, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.0024895297829061747}, {"id": 662, "seek": 373006, "start": 3738.14, "end": 3742.46, "text": " And if you can predict all of behavior without having to explain consciousness,", "tokens": [50768, 400, 498, 291, 393, 6069, 439, 295, 5223, 1553, 1419, 281, 2903, 10081, 11, 50984], "temperature": 0.0, "avg_logprob": -0.09580852017544284, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.0024895297829061747}, {"id": 663, "seek": 373006, "start": 3743.02, "end": 3747.74, "text": " their motivation for explaining consciousness sort of evaporates and it sort of feels like,", "tokens": [51012, 641, 12335, 337, 13468, 10081, 1333, 295, 26315, 1024, 293, 309, 1333, 295, 3417, 411, 11, 51248], "temperature": 0.0, "avg_logprob": -0.09580852017544284, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.0024895297829061747}, {"id": 664, "seek": 373006, "start": 3747.74, "end": 3752.46, "text": " yeah, yeah, well, what's the point of even thinking about that because it's just not going", "tokens": [51248, 1338, 11, 1338, 11, 731, 11, 437, 311, 264, 935, 295, 754, 1953, 466, 300, 570, 309, 311, 445, 406, 516, 51484], "temperature": 0.0, "avg_logprob": -0.09580852017544284, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.0024895297829061747}, {"id": 665, "seek": 373006, "start": 3752.46, "end": 3757.1, "text": " to do anything for me? What do you say to someone when they say that to you?", "tokens": [51484, 281, 360, 1340, 337, 385, 30, 708, 360, 291, 584, 281, 1580, 562, 436, 584, 300, 281, 291, 30, 51716], "temperature": 0.0, "avg_logprob": -0.09580852017544284, "compression_ratio": 1.7642276422764227, "no_speech_prob": 0.0024895297829061747}, {"id": 666, "seek": 375710, "start": 3757.8199999999997, "end": 3759.3399999999997, "text": " What is the thing that they say to me again?", "tokens": [50400, 708, 307, 264, 551, 300, 436, 584, 281, 385, 797, 30, 50476], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 667, "seek": 375710, "start": 3759.3399999999997, "end": 3765.02, "text": " That there's no, there's maybe consciousness exists, maybe it doesn't. But if I can explain", "tokens": [50476, 663, 456, 311, 572, 11, 456, 311, 1310, 10081, 8198, 11, 1310, 309, 1177, 380, 13, 583, 498, 286, 393, 2903, 50760], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 668, "seek": 375710, "start": 3765.02, "end": 3768.7799999999997, "text": " all of human behavior and all of the behavior of the world in general without", "tokens": [50760, 439, 295, 1952, 5223, 293, 439, 295, 264, 5223, 295, 264, 1002, 294, 2674, 1553, 50948], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 669, "seek": 375710, "start": 3768.7799999999997, "end": 3774.06, "text": " recourse to such concepts, then I've done everything that there is that's useful,", "tokens": [50948, 850, 13656, 281, 1270, 10392, 11, 550, 286, 600, 1096, 1203, 300, 456, 307, 300, 311, 4420, 11, 51212], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 670, "seek": 375710, "start": 3774.06, "end": 3780.14, "text": " like explaining consciousness isn't a useful thing to do. And thus, I'm not interested in this and", "tokens": [51212, 411, 13468, 10081, 1943, 380, 257, 4420, 551, 281, 360, 13, 400, 8807, 11, 286, 478, 406, 3102, 294, 341, 293, 51516], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 671, "seek": 375710, "start": 3780.14, "end": 3785.74, "text": " it may not be real. I mean, I'm certainly, I'm not, I mean, I think epiphenomenalism could be", "tokens": [51516, 309, 815, 406, 312, 957, 13, 286, 914, 11, 286, 478, 3297, 11, 286, 478, 406, 11, 286, 914, 11, 286, 519, 2388, 647, 2932, 4726, 304, 1434, 727, 312, 51796], "temperature": 0.0, "avg_logprob": -0.1282717778132512, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0012742463732138276}, {"id": 672, "seek": 378574, "start": 3785.74, "end": 3789.3399999999997, "text": " true. I certainly don't have any commitment to it though. It's quite possible that consciousness", "tokens": [50364, 2074, 13, 286, 3297, 500, 380, 362, 604, 8371, 281, 309, 1673, 13, 467, 311, 1596, 1944, 300, 10081, 50544], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 673, "seek": 378574, "start": 3789.3399999999997, "end": 3794.9399999999996, "text": " has a role to play in generating behavior that we don't yet understand and maybe thinking hard", "tokens": [50544, 575, 257, 3090, 281, 862, 294, 17746, 5223, 300, 321, 500, 380, 1939, 1223, 293, 1310, 1953, 1152, 50824], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 674, "seek": 378574, "start": 3794.9399999999996, "end": 3800.22, "text": " about the meta problem can help us get clearer on those roles. I think if you've got any sympathy", "tokens": [50824, 466, 264, 19616, 1154, 393, 854, 505, 483, 26131, 322, 729, 9604, 13, 286, 519, 498, 291, 600, 658, 604, 33240, 51088], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 675, "seek": 378574, "start": 3800.22, "end": 3804.7, "text": " to panpsychism, maybe consciousness is intimately involved with how physical processes get going", "tokens": [51088, 281, 2462, 1878, 16384, 1434, 11, 1310, 10081, 307, 560, 5401, 3288, 365, 577, 4001, 7555, 483, 516, 51312], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 676, "seek": 378574, "start": 3804.7, "end": 3809.66, "text": " in the, in the first place. And there are people who want to pursue interactionist ideas where", "tokens": [51312, 294, 264, 11, 294, 264, 700, 1081, 13, 400, 456, 366, 561, 567, 528, 281, 12392, 9285, 468, 3487, 689, 51560], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 677, "seek": 378574, "start": 3809.66, "end": 3813.8199999999997, "text": " consciousness interacts with the brain. Or if you're a reductionist, consciousness may be just", "tokens": [51560, 10081, 43582, 365, 264, 3567, 13, 1610, 498, 291, 434, 257, 11004, 468, 11, 10081, 815, 312, 445, 51768], "temperature": 0.0, "avg_logprob": -0.08159136027097702, "compression_ratio": 1.7777777777777777, "no_speech_prob": 0.0006060057785362005}, {"id": 678, "seek": 381382, "start": 3813.82, "end": 3818.86, "text": " a matter of the right algorithm. On all those views, consciousness may have some role to play,", "tokens": [50364, 257, 1871, 295, 264, 558, 9284, 13, 1282, 439, 729, 6809, 11, 10081, 815, 362, 512, 3090, 281, 862, 11, 50616], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 679, "seek": 381382, "start": 3818.86, "end": 3824.2200000000003, "text": " but just say it turns out that you can explain all of behavior, including these problems without,", "tokens": [50616, 457, 445, 584, 309, 4523, 484, 300, 291, 393, 2903, 439, 295, 5223, 11, 3009, 613, 2740, 1553, 11, 50884], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 680, "seek": 381382, "start": 3825.42, "end": 3829.5800000000004, "text": " without bringing in consciousness. And does that mean that consciousness is not something we", "tokens": [50944, 1553, 5062, 294, 10081, 13, 400, 775, 300, 914, 300, 10081, 307, 406, 746, 321, 51152], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 681, "seek": 381382, "start": 3829.5800000000004, "end": 3833.02, "text": " should care about and not something that matters? I don't think that would follow. I mean, maybe it", "tokens": [51152, 820, 1127, 466, 293, 406, 746, 300, 7001, 30, 286, 500, 380, 519, 300, 576, 1524, 13, 286, 914, 11, 1310, 309, 51324], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 682, "seek": 381382, "start": 3833.02, "end": 3838.3, "text": " wouldn't matter for certain engineering purposes, say you want to build a useful system. But,", "tokens": [51324, 2759, 380, 1871, 337, 1629, 7043, 9932, 11, 584, 291, 528, 281, 1322, 257, 4420, 1185, 13, 583, 11, 51588], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 683, "seek": 381382, "start": 3838.86, "end": 3842.86, "text": " you know, at least in my view, consciousness is really the only thing that matters. It's a thing", "tokens": [51616, 291, 458, 11, 412, 1935, 294, 452, 1910, 11, 10081, 307, 534, 264, 787, 551, 300, 7001, 13, 467, 311, 257, 551, 51816], "temperature": 0.0, "avg_logprob": -0.09053133462221567, "compression_ratio": 1.8343949044585988, "no_speech_prob": 0.00045779760694131255}, {"id": 684, "seek": 384286, "start": 3842.94, "end": 3849.1, "text": " that makes life worth living. It's what gives our lives meaning and value and so on. So,", "tokens": [50368, 300, 1669, 993, 3163, 2647, 13, 467, 311, 437, 2709, 527, 2909, 3620, 293, 2158, 293, 370, 322, 13, 407, 11, 50676], "temperature": 0.0, "avg_logprob": -0.10895640242333506, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.001273952191695571}, {"id": 685, "seek": 384286, "start": 3849.1, "end": 3853.42, "text": " it might turn out that, okay, the point of consciousness is not that useful for explaining", "tokens": [50676, 309, 1062, 1261, 484, 300, 11, 1392, 11, 264, 935, 295, 10081, 307, 406, 300, 4420, 337, 13468, 50892], "temperature": 0.0, "avg_logprob": -0.10895640242333506, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.001273952191695571}, {"id": 686, "seek": 384286, "start": 3853.42, "end": 3857.98, "text": " other stuff. But it's, you know, if it's the source of intrinsic significance in the world,", "tokens": [50892, 661, 1507, 13, 583, 309, 311, 11, 291, 458, 11, 498, 309, 311, 264, 4009, 295, 35698, 17687, 294, 264, 1002, 11, 51120], "temperature": 0.0, "avg_logprob": -0.10895640242333506, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.001273952191695571}, {"id": 687, "seek": 384286, "start": 3857.98, "end": 3862.78, "text": " then understanding consciousness will still be absolutely essential to understanding ourselves.", "tokens": [51120, 550, 3701, 10081, 486, 920, 312, 3122, 7115, 281, 3701, 4175, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10895640242333506, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.001273952191695571}, {"id": 688, "seek": 384286, "start": 3862.78, "end": 3868.38, "text": " Furthermore, if it comes to developing other systems, like say AI systems or dealing with", "tokens": [51360, 23999, 11, 498, 309, 1487, 281, 6416, 661, 3652, 11, 411, 584, 7318, 3652, 420, 6260, 365, 51640], "temperature": 0.0, "avg_logprob": -0.10895640242333506, "compression_ratio": 1.6801470588235294, "no_speech_prob": 0.001273952191695571}, {"id": 689, "seek": 386838, "start": 3868.38, "end": 3873.7400000000002, "text": " non-human animals and so on, we absolutely want to know, we need to know whether they're conscious,", "tokens": [50364, 2107, 12, 18796, 4882, 293, 370, 322, 11, 321, 3122, 528, 281, 458, 11, 321, 643, 281, 458, 1968, 436, 434, 6648, 11, 50632], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 690, "seek": 386838, "start": 3873.7400000000002, "end": 3877.58, "text": " because, you know, if they're conscious, they presumably have moral status. If they can suffer,", "tokens": [50632, 570, 11, 291, 458, 11, 498, 436, 434, 6648, 11, 436, 26742, 362, 9723, 6558, 13, 759, 436, 393, 9753, 11, 50824], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 691, "seek": 386838, "start": 3878.2200000000003, "end": 3883.42, "text": " then it's very bad to mistreat them. If they're not conscious, then you might, I think it's very", "tokens": [50856, 550, 309, 311, 588, 1578, 281, 3544, 620, 552, 13, 759, 436, 434, 406, 6648, 11, 550, 291, 1062, 11, 286, 519, 309, 311, 588, 51116], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 692, "seek": 386838, "start": 3883.42, "end": 3887.98, "text": " plausible, treat non-conscious systems. We can treat how we like, and it doesn't really matter", "tokens": [51116, 39925, 11, 2387, 2107, 12, 19877, 3652, 13, 492, 393, 2387, 577, 321, 411, 11, 293, 309, 1177, 380, 534, 1871, 51344], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 693, "seek": 386838, "start": 3888.54, "end": 3892.7000000000003, "text": " morally. So, the question of whether, say, an AI system is conscious or not, it's going to be", "tokens": [51372, 38622, 13, 407, 11, 264, 1168, 295, 1968, 11, 584, 11, 364, 7318, 1185, 307, 6648, 420, 406, 11, 309, 311, 516, 281, 312, 51580], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 694, "seek": 386838, "start": 3892.7000000000003, "end": 3897.58, "text": " absolutely vital for how we interact with it and how we build our society. That's not a question", "tokens": [51580, 3122, 11707, 337, 577, 321, 4648, 365, 309, 293, 577, 321, 1322, 527, 4086, 13, 663, 311, 406, 257, 1168, 51824], "temperature": 0.0, "avg_logprob": -0.0900881677060514, "compression_ratio": 1.8585209003215435, "no_speech_prob": 0.0008825806435197592}, {"id": 695, "seek": 389758, "start": 3897.58, "end": 3901.74, "text": " of engineering usefulness. That's a question of connecting with our most fundamental values.", "tokens": [50364, 295, 7043, 4420, 1287, 13, 663, 311, 257, 1168, 295, 11015, 365, 527, 881, 8088, 4190, 13, 50572], "temperature": 0.0, "avg_logprob": -0.11679600403372166, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0010203843703493476}, {"id": 696, "seek": 389758, "start": 3902.38, "end": 3908.06, "text": " Yeah, I completely agree. I just, I haven't found that formulation to be very convincing to others", "tokens": [50604, 865, 11, 286, 2584, 3986, 13, 286, 445, 11, 286, 2378, 380, 1352, 300, 37642, 281, 312, 588, 24823, 281, 2357, 50888], "temperature": 0.0, "avg_logprob": -0.11679600403372166, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0010203843703493476}, {"id": 697, "seek": 389758, "start": 3908.06, "end": 3915.66, "text": " necessarily. Hi, thank you so much for coming and chatting with us today. I'm really interested in", "tokens": [50888, 4725, 13, 2421, 11, 1309, 291, 370, 709, 337, 1348, 293, 24654, 365, 505, 965, 13, 286, 478, 534, 3102, 294, 51268], "temperature": 0.0, "avg_logprob": -0.11679600403372166, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0010203843703493476}, {"id": 698, "seek": 389758, "start": 3915.66, "end": 3921.5, "text": " some of your earlier work, The Extended Mind Distributed Cognition. Yeah. And you're at a company", "tokens": [51268, 512, 295, 428, 3071, 589, 11, 440, 9881, 3502, 13719, 9840, 2024, 4866, 383, 2912, 849, 13, 865, 13, 400, 291, 434, 412, 257, 2237, 51560], "temperature": 0.0, "avg_logprob": -0.11679600403372166, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0010203843703493476}, {"id": 699, "seek": 389758, "start": 3921.5, "end": 3925.9, "text": " speaking with a bunch of people who do an incredibly cognitively demanding task. Yeah.", "tokens": [51560, 4124, 365, 257, 3840, 295, 561, 567, 360, 364, 6252, 15605, 356, 19960, 5633, 13, 865, 13, 51780], "temperature": 0.0, "avg_logprob": -0.11679600403372166, "compression_ratio": 1.5780730897009967, "no_speech_prob": 0.0010203843703493476}, {"id": 700, "seek": 392590, "start": 3925.9, "end": 3931.58, "text": " Most of the literature that I've read on this topic uses relatively simple examples of telling,", "tokens": [50364, 4534, 295, 264, 10394, 300, 286, 600, 1401, 322, 341, 4829, 4960, 7226, 2199, 5110, 295, 3585, 11, 50648], "temperature": 0.0, "avg_logprob": -0.09928924972946579, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.004357529804110527}, {"id": 701, "seek": 392590, "start": 3931.58, "end": 3938.54, "text": " like, it's difficult to think just inside your head on these relatively simple things. And if", "tokens": [50648, 411, 11, 309, 311, 2252, 281, 519, 445, 1854, 428, 1378, 322, 613, 7226, 2199, 721, 13, 400, 498, 50996], "temperature": 0.0, "avg_logprob": -0.09928924972946579, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.004357529804110527}, {"id": 702, "seek": 392590, "start": 3938.54, "end": 3942.14, "text": " you take a look at the programs that we build, sort of like on a mundane, day-to-day basis,", "tokens": [50996, 291, 747, 257, 574, 412, 264, 4268, 300, 321, 1322, 11, 1333, 295, 411, 322, 257, 43497, 11, 786, 12, 1353, 12, 810, 5143, 11, 51176], "temperature": 0.0, "avg_logprob": -0.09928924972946579, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.004357529804110527}, {"id": 703, "seek": 392590, "start": 3942.14, "end": 3946.7000000000003, "text": " there are millions of lines long. I've read people in the past say something like,", "tokens": [51176, 456, 366, 6803, 295, 3876, 938, 13, 286, 600, 1401, 561, 294, 264, 1791, 584, 746, 411, 11, 51404], "temperature": 0.0, "avg_logprob": -0.09928924972946579, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.004357529804110527}, {"id": 704, "seek": 392590, "start": 3946.7000000000003, "end": 3952.14, "text": " the Boeing 777 was the most complicated thing that human beings have ever made. And I think", "tokens": [51404, 264, 30831, 1614, 17512, 390, 264, 881, 6179, 551, 300, 1952, 8958, 362, 1562, 1027, 13, 400, 286, 519, 51676], "temperature": 0.0, "avg_logprob": -0.09928924972946579, "compression_ratio": 1.7014925373134329, "no_speech_prob": 0.004357529804110527}, {"id": 705, "seek": 395214, "start": 3952.14, "end": 3956.54, "text": " most of us would look at that and say, we got that beat, you know, like the things that large", "tokens": [50364, 881, 295, 505, 576, 574, 412, 300, 293, 584, 11, 321, 658, 300, 4224, 11, 291, 458, 11, 411, 264, 721, 300, 2416, 50584], "temperature": 0.0, "avg_logprob": -0.11519163897913745, "compression_ratio": 1.6325088339222615, "no_speech_prob": 0.0015136369038373232}, {"id": 706, "seek": 395214, "start": 3956.54, "end": 3961.2599999999998, "text": " internet companies do, the size, the complexity of that is staggering. And yet if we close our", "tokens": [50584, 4705, 3431, 360, 11, 264, 2744, 11, 264, 14024, 295, 300, 307, 42974, 13, 400, 1939, 498, 321, 1998, 527, 50820], "temperature": 0.0, "avg_logprob": -0.11519163897913745, "compression_ratio": 1.6325088339222615, "no_speech_prob": 0.0015136369038373232}, {"id": 707, "seek": 395214, "start": 3961.2599999999998, "end": 3965.3399999999997, "text": " eyes, everyone in here is going to say, I'm going to have difficulty writing a 10-line program in", "tokens": [50820, 2575, 11, 1518, 294, 510, 307, 516, 281, 584, 11, 286, 478, 516, 281, 362, 10360, 3579, 257, 1266, 12, 1889, 1461, 294, 51024], "temperature": 0.0, "avg_logprob": -0.11519163897913745, "compression_ratio": 1.6325088339222615, "no_speech_prob": 0.0015136369038373232}, {"id": 708, "seek": 395214, "start": 3965.3399999999997, "end": 3971.3399999999997, "text": " my head. Okay. So I'm just sort of as an open, like, I'd be very interested in hearing your thoughts", "tokens": [51024, 452, 1378, 13, 1033, 13, 407, 286, 478, 445, 1333, 295, 382, 364, 1269, 11, 411, 11, 286, 1116, 312, 588, 3102, 294, 4763, 428, 4598, 51324], "temperature": 0.0, "avg_logprob": -0.11519163897913745, "compression_ratio": 1.6325088339222615, "no_speech_prob": 0.0015136369038373232}, {"id": 709, "seek": 395214, "start": 3971.3399999999997, "end": 3976.8599999999997, "text": " about how the activity of programming connects to the extended mind ideas.", "tokens": [51324, 466, 577, 264, 5191, 295, 9410, 16967, 281, 264, 10913, 1575, 3487, 13, 51600], "temperature": 0.0, "avg_logprob": -0.11519163897913745, "compression_ratio": 1.6325088339222615, "no_speech_prob": 0.0015136369038373232}, {"id": 710, "seek": 397686, "start": 3977.5, "end": 3983.1, "text": " Yeah. So this is a reference to something that I got started in about 20 years ago with", "tokens": [50396, 865, 13, 407, 341, 307, 257, 6408, 281, 746, 300, 286, 658, 1409, 294, 466, 945, 924, 2057, 365, 50676], "temperature": 0.0, "avg_logprob": -0.14120092215361418, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0021102323662489653}, {"id": 711, "seek": 397686, "start": 3983.7400000000002, "end": 3989.1800000000003, "text": " my colleague Andy Clarke. We wrote an article called The Extended Mind about how processes in", "tokens": [50708, 452, 13532, 13285, 28410, 330, 13, 492, 4114, 364, 7222, 1219, 440, 9881, 3502, 13719, 466, 577, 7555, 294, 50980], "temperature": 0.0, "avg_logprob": -0.14120092215361418, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0021102323662489653}, {"id": 712, "seek": 397686, "start": 3989.1800000000003, "end": 3994.54, "text": " the mind can extend outside the brain when we become coupled to our tools. And actually,", "tokens": [50980, 264, 1575, 393, 10101, 2380, 264, 3567, 562, 321, 1813, 29482, 281, 527, 3873, 13, 400, 767, 11, 51248], "temperature": 0.0, "avg_logprob": -0.14120092215361418, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0021102323662489653}, {"id": 713, "seek": 397686, "start": 3994.54, "end": 3999.82, "text": " our central example back then in the mid-90s was a notebook, someone writing stuff in a", "tokens": [51248, 527, 5777, 1365, 646, 550, 294, 264, 2062, 12, 7771, 82, 390, 257, 21060, 11, 1580, 3579, 1507, 294, 257, 51512], "temperature": 0.0, "avg_logprob": -0.14120092215361418, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0021102323662489653}, {"id": 714, "seek": 397686, "start": 3999.82, "end": 4004.78, "text": " notebook. I mean, even then, we knew about the internet and we had some internet examples.", "tokens": [51512, 21060, 13, 286, 914, 11, 754, 550, 11, 321, 2586, 466, 264, 4705, 293, 321, 632, 512, 4705, 5110, 13, 51760], "temperature": 0.0, "avg_logprob": -0.14120092215361418, "compression_ratio": 1.6209386281588447, "no_speech_prob": 0.0021102323662489653}, {"id": 715, "seek": 400478, "start": 4004.78, "end": 4011.5, "text": " I guess this company didn't exist yet in 95. But now, of course, our minds have just become", "tokens": [50364, 286, 2041, 341, 2237, 994, 380, 2514, 1939, 294, 13420, 13, 583, 586, 11, 295, 1164, 11, 527, 9634, 362, 445, 1813, 50700], "temperature": 0.0, "avg_logprob": -0.0875820106930203, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.000645239488221705}, {"id": 716, "seek": 400478, "start": 4011.5, "end": 4017.5800000000004, "text": " more and more extended and, you know, smartphones came along a few years later and everyone is", "tokens": [50700, 544, 293, 544, 10913, 293, 11, 291, 458, 11, 26782, 1361, 2051, 257, 1326, 924, 1780, 293, 1518, 307, 51004], "temperature": 0.0, "avg_logprob": -0.0875820106930203, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.000645239488221705}, {"id": 717, "seek": 400478, "start": 4017.5800000000004, "end": 4022.46, "text": " coupled very, very closely to their phones and their other devices that coupled them very,", "tokens": [51004, 29482, 588, 11, 588, 8185, 281, 641, 10216, 293, 641, 661, 5759, 300, 29482, 552, 588, 11, 51248], "temperature": 0.0, "avg_logprob": -0.0875820106930203, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.000645239488221705}, {"id": 718, "seek": 400478, "start": 4022.46, "end": 4029.82, "text": " very closely to the internet. Now, it's certainly the case that a whole lot of my memory is now", "tokens": [51248, 588, 8185, 281, 264, 4705, 13, 823, 11, 309, 311, 3297, 264, 1389, 300, 257, 1379, 688, 295, 452, 4675, 307, 586, 51616], "temperature": 0.0, "avg_logprob": -0.0875820106930203, "compression_ratio": 1.6504424778761062, "no_speech_prob": 0.000645239488221705}, {"id": 719, "seek": 402982, "start": 4029.82, "end": 4035.42, "text": " offloaded onto the servers of your company somewhere or other, whether it's in the", "tokens": [50364, 766, 2907, 292, 3911, 264, 15909, 295, 428, 2237, 4079, 420, 661, 11, 1968, 309, 311, 294, 264, 50644], "temperature": 0.0, "avg_logprob": -0.13879799842834473, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.0018357302760705352}, {"id": 720, "seek": 402982, "start": 4037.82, "end": 4044.46, "text": " mail systems or navigation mapping systems or other systems. Most of my navigation has been", "tokens": [50764, 10071, 3652, 420, 17346, 18350, 3652, 420, 661, 3652, 13, 4534, 295, 452, 17346, 575, 668, 51096], "temperature": 0.0, "avg_logprob": -0.13879799842834473, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.0018357302760705352}, {"id": 721, "seek": 402982, "start": 4045.5, "end": 4051.02, "text": " offloaded to maps and much of my memory has been offloaded. Well, maybe that's in my phone, but", "tokens": [51148, 766, 2907, 292, 281, 11317, 293, 709, 295, 452, 4675, 575, 668, 766, 2907, 292, 13, 1042, 11, 1310, 300, 311, 294, 452, 2593, 11, 457, 51424], "temperature": 0.0, "avg_logprob": -0.13879799842834473, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.0018357302760705352}, {"id": 722, "seek": 402982, "start": 4052.46, "end": 4056.2200000000003, "text": " other bits of my memory are offloaded into my file system on", "tokens": [51496, 661, 9239, 295, 452, 4675, 366, 766, 2907, 292, 666, 452, 3991, 1185, 322, 51684], "temperature": 0.0, "avg_logprob": -0.13879799842834473, "compression_ratio": 1.7891891891891891, "no_speech_prob": 0.0018357302760705352}, {"id": 723, "seek": 405622, "start": 4056.62, "end": 4066.14, "text": " some cloud service. So certainly, vast amounts of my mind are now", "tokens": [50384, 512, 4588, 2643, 13, 407, 3297, 11, 8369, 11663, 295, 452, 1575, 366, 586, 50860], "temperature": 0.0, "avg_logprob": -0.14458573491949783, "compression_ratio": 1.558252427184466, "no_speech_prob": 0.00035672582453116775}, {"id": 724, "seek": 405622, "start": 4067.02, "end": 4071.8199999999997, "text": " existing in the cloud. And if I was somehow to lose access to those completely, then I'd", "tokens": [50904, 6741, 294, 264, 4588, 13, 400, 498, 286, 390, 6063, 281, 3624, 2105, 281, 729, 2584, 11, 550, 286, 1116, 51144], "temperature": 0.0, "avg_logprob": -0.14458573491949783, "compression_ratio": 1.558252427184466, "no_speech_prob": 0.00035672582453116775}, {"id": 725, "seek": 405622, "start": 4071.8199999999997, "end": 4078.7799999999997, "text": " lose an awful lot of my capacities. So I think we are now sort of extending", "tokens": [51144, 3624, 364, 11232, 688, 295, 452, 39396, 13, 407, 286, 519, 321, 366, 586, 1333, 295, 24360, 51492], "temperature": 0.0, "avg_logprob": -0.14458573491949783, "compression_ratio": 1.558252427184466, "no_speech_prob": 0.00035672582453116775}, {"id": 726, "seek": 405622, "start": 4078.7799999999997, "end": 4084.3799999999997, "text": " into the cloud, thanks to you guys and others. The question specifically about programming", "tokens": [51492, 666, 264, 4588, 11, 3231, 281, 291, 1074, 293, 2357, 13, 440, 1168, 4682, 466, 9410, 51772], "temperature": 0.0, "avg_logprob": -0.14458573491949783, "compression_ratio": 1.558252427184466, "no_speech_prob": 0.00035672582453116775}, {"id": 727, "seek": 408622, "start": 4086.9399999999996, "end": 4091.4199999999996, "text": " programming is a kind of active interaction with our devices. I mean, I think of programming", "tokens": [50400, 9410, 307, 257, 733, 295, 4967, 9285, 365, 527, 5759, 13, 286, 914, 11, 286, 519, 295, 9410, 50624], "temperature": 0.0, "avg_logprob": -0.10608137181374878, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.00020968663739040494}, {"id": 728, "seek": 408622, "start": 4091.4199999999996, "end": 4096.46, "text": " as something that takes a little bit longer. It's a longer time scale. So the core cases of the", "tokens": [50624, 382, 746, 300, 2516, 257, 707, 857, 2854, 13, 467, 311, 257, 2854, 565, 4373, 13, 407, 264, 4965, 3331, 295, 264, 50876], "temperature": 0.0, "avg_logprob": -0.10608137181374878, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.00020968663739040494}, {"id": 729, "seek": 408622, "start": 4096.46, "end": 4101.98, "text": " extended mind involve sort of automatic use of our devices, which are always ready to hand.", "tokens": [50876, 10913, 1575, 9494, 1333, 295, 12509, 764, 295, 527, 5759, 11, 597, 366, 1009, 1919, 281, 1011, 13, 51152], "temperature": 0.0, "avg_logprob": -0.10608137181374878, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.00020968663739040494}, {"id": 730, "seek": 408622, "start": 4101.98, "end": 4108.0599999999995, "text": " We can use them to get information, to act in the moment, which is the kind of thing that", "tokens": [51152, 492, 393, 764, 552, 281, 483, 1589, 11, 281, 605, 294, 264, 1623, 11, 597, 307, 264, 733, 295, 551, 300, 51456], "temperature": 0.0, "avg_logprob": -0.10608137181374878, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.00020968663739040494}, {"id": 731, "seek": 408622, "start": 4108.94, "end": 4114.219999999999, "text": " the brain does. So insofar as programming is a slower process, you know, and I remember from", "tokens": [51500, 264, 3567, 775, 13, 407, 294, 539, 21196, 382, 9410, 307, 257, 14009, 1399, 11, 291, 458, 11, 293, 286, 1604, 490, 51764], "temperature": 0.0, "avg_logprob": -0.10608137181374878, "compression_ratio": 1.7276119402985075, "no_speech_prob": 0.00020968663739040494}, {"id": 732, "seek": 411422, "start": 4114.860000000001, "end": 4123.1, "text": " programming days, all the endless hours of debugging and so on. Then it's at least going", "tokens": [50396, 9410, 1708, 11, 439, 264, 16144, 2496, 295, 45592, 293, 370, 322, 13, 1396, 309, 311, 412, 1935, 516, 50808], "temperature": 0.0, "avg_logprob": -0.11942647632799651, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.00033458383404649794}, {"id": 733, "seek": 411422, "start": 4123.1, "end": 4127.9800000000005, "text": " to be a slower time scale for the extended mind. But still, Feynman talked about writing", "tokens": [50808, 281, 312, 257, 14009, 565, 4373, 337, 264, 10913, 1575, 13, 583, 920, 11, 46530, 77, 1601, 2825, 466, 3579, 51052], "temperature": 0.0, "avg_logprob": -0.11942647632799651, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.00033458383404649794}, {"id": 734, "seek": 411422, "start": 4128.780000000001, "end": 4136.46, "text": " this way. Someone looked at Feynman's work and a bunch of notes he had about a physics problem", "tokens": [51092, 341, 636, 13, 8734, 2956, 412, 46530, 77, 1601, 311, 589, 293, 257, 3840, 295, 5570, 415, 632, 466, 257, 10649, 1154, 51476], "temperature": 0.0, "avg_logprob": -0.11942647632799651, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.00033458383404649794}, {"id": 735, "seek": 411422, "start": 4136.46, "end": 4141.1, "text": " he was thinking about. And someone said to him, oh, it's nice you have this record of your work.", "tokens": [51476, 415, 390, 1953, 466, 13, 400, 1580, 848, 281, 796, 11, 1954, 11, 309, 311, 1481, 291, 362, 341, 2136, 295, 428, 589, 13, 51708], "temperature": 0.0, "avg_logprob": -0.11942647632799651, "compression_ratio": 1.5974025974025974, "no_speech_prob": 0.00033458383404649794}, {"id": 736, "seek": 414110, "start": 4142.06, "end": 4147.900000000001, "text": " And Feynman said, that's not a record of my work. That's the work. That is the thinking.", "tokens": [50412, 400, 46530, 77, 1601, 848, 11, 300, 311, 406, 257, 2136, 295, 452, 589, 13, 663, 311, 264, 589, 13, 663, 307, 264, 1953, 13, 50704], "temperature": 0.0, "avg_logprob": -0.12441999629392463, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.0012815502705052495}, {"id": 737, "seek": 414110, "start": 4147.900000000001, "end": 4152.3, "text": " And so I was writing it down and so on. I think, you know, at least my recollection from my programming", "tokens": [50704, 400, 370, 286, 390, 3579, 309, 760, 293, 370, 322, 13, 286, 519, 11, 291, 458, 11, 412, 1935, 452, 39495, 10183, 490, 452, 9410, 50924], "temperature": 0.0, "avg_logprob": -0.12441999629392463, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.0012815502705052495}, {"id": 738, "seek": 414110, "start": 4152.3, "end": 4156.46, "text": " days was that, you know, when you're actually writing a program, that's not like you just", "tokens": [50924, 1708, 390, 300, 11, 291, 458, 11, 562, 291, 434, 767, 3579, 257, 1461, 11, 300, 311, 406, 411, 291, 445, 51132], "temperature": 0.0, "avg_logprob": -0.12441999629392463, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.0012815502705052495}, {"id": 739, "seek": 414110, "start": 4157.02, "end": 4162.780000000001, "text": " do a bunch of thinking and then code your thoughts. The programming is to some very", "tokens": [51160, 360, 257, 3840, 295, 1953, 293, 550, 3089, 428, 4598, 13, 440, 9410, 307, 281, 512, 588, 51448], "temperature": 0.0, "avg_logprob": -0.12441999629392463, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.0012815502705052495}, {"id": 740, "seek": 414110, "start": 4162.780000000001, "end": 4168.700000000001, "text": " considerable extent your thinking. So is that the sort of thing you're thinking about here?", "tokens": [51448, 24167, 8396, 428, 1953, 13, 407, 307, 300, 264, 1333, 295, 551, 291, 434, 1953, 466, 510, 30, 51744], "temperature": 0.0, "avg_logprob": -0.12441999629392463, "compression_ratio": 1.8247011952191234, "no_speech_prob": 0.0012815502705052495}, {"id": 741, "seek": 416870, "start": 4168.7, "end": 4175.9, "text": " And the, if we, I think as people that program start to reflect on what we do,", "tokens": [50364, 400, 264, 11, 498, 321, 11, 286, 519, 382, 561, 300, 1461, 722, 281, 5031, 322, 437, 321, 360, 11, 50724], "temperature": 0.0, "avg_logprob": -0.15958920840559335, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.0009743248810991645}, {"id": 742, "seek": 416870, "start": 4175.9, "end": 4182.3, "text": " and very few of us actually, like if you're the tech lead of a system, maybe you've got it in your", "tokens": [50724, 293, 588, 1326, 295, 505, 767, 11, 411, 498, 291, 434, 264, 7553, 1477, 295, 257, 1185, 11, 1310, 291, 600, 658, 309, 294, 428, 51044], "temperature": 0.0, "avg_logprob": -0.15958920840559335, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.0009743248810991645}, {"id": 743, "seek": 416870, "start": 4182.3, "end": 4186.7, "text": " head, okay? But you would agree that most of the people on the team who've come more recently only", "tokens": [51044, 1378, 11, 1392, 30, 583, 291, 576, 3986, 300, 881, 295, 264, 561, 322, 264, 1469, 567, 600, 808, 544, 3938, 787, 51264], "temperature": 0.0, "avg_logprob": -0.15958920840559335, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.0009743248810991645}, {"id": 744, "seek": 416870, "start": 4186.7, "end": 4190.46, "text": " have a chunk of it in their head, and yet they're somehow still able to contribute.", "tokens": [51264, 362, 257, 16635, 295, 309, 294, 641, 1378, 11, 293, 1939, 436, 434, 6063, 920, 1075, 281, 10586, 13, 51452], "temperature": 0.0, "avg_logprob": -0.15958920840559335, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.0009743248810991645}, {"id": 745, "seek": 416870, "start": 4190.46, "end": 4196.139999999999, "text": " Oh yeah, this is now distributed cognition. I mean, the extended mind that extended cognition", "tokens": [51452, 876, 1338, 11, 341, 307, 586, 12631, 46905, 13, 286, 914, 11, 264, 10913, 1575, 300, 10913, 46905, 51736], "temperature": 0.0, "avg_logprob": -0.15958920840559335, "compression_ratio": 1.663003663003663, "no_speech_prob": 0.0009743248810991645}, {"id": 746, "seek": 419614, "start": 4196.14, "end": 4202.06, "text": " like starts with an individual and then extends out, extends their capacities out using their", "tokens": [50364, 411, 3719, 365, 364, 2609, 293, 550, 26448, 484, 11, 26448, 641, 39396, 484, 1228, 641, 50660], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 747, "seek": 419614, "start": 4202.06, "end": 4207.1, "text": " tools or their devices or even other people. So maybe my partner serves as my memory, but it's", "tokens": [50660, 3873, 420, 641, 5759, 420, 754, 661, 561, 13, 407, 1310, 452, 4975, 13451, 382, 452, 4675, 11, 457, 309, 311, 50912], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 748, "seek": 419614, "start": 4207.1, "end": 4212.3, "text": " still centered on an individual. But then there's the closely related case of distributed cognition,", "tokens": [50912, 920, 18988, 322, 364, 2609, 13, 583, 550, 456, 311, 264, 8185, 4077, 1389, 295, 12631, 46905, 11, 51172], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 749, "seek": 419614, "start": 4212.3, "end": 4217.58, "text": " where you have a team of people who are doing something and are making joint decisions and", "tokens": [51172, 689, 291, 362, 257, 1469, 295, 561, 567, 366, 884, 746, 293, 366, 1455, 7225, 5327, 293, 51436], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 750, "seek": 419614, "start": 4217.58, "end": 4221.5, "text": " carrying out joint actions in an absolutely seamless way. And I take it as a company like this", "tokens": [51436, 9792, 484, 7225, 5909, 294, 364, 3122, 28677, 636, 13, 400, 286, 747, 309, 382, 257, 2237, 411, 341, 51632], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 751, "seek": 419614, "start": 4221.5, "end": 4225.18, "text": " that are going to be any number of instances of distributed cognition. I don't know whether the", "tokens": [51632, 300, 366, 516, 281, 312, 604, 1230, 295, 14519, 295, 12631, 46905, 13, 286, 500, 380, 458, 1968, 264, 51816], "temperature": 0.0, "avg_logprob": -0.08577372950892295, "compression_ratio": 1.7788161993769471, "no_speech_prob": 0.00113296031486243}, {"id": 752, "seek": 422518, "start": 4225.18, "end": 4232.22, "text": " company as a whole has one giant Google mind, or maybe there's just like a near infinite number", "tokens": [50364, 2237, 382, 257, 1379, 575, 472, 7410, 3329, 1575, 11, 420, 1310, 456, 311, 445, 411, 257, 2651, 13785, 1230, 50716], "temperature": 0.0, "avg_logprob": -0.16718738079071044, "compression_ratio": 1.5565217391304347, "no_speech_prob": 0.00021878324332647026}, {"id": 753, "seek": 422518, "start": 4232.22, "end": 4239.1, "text": " of separate Google minds for all the individual teams and divisions and so on. But I think yeah,", "tokens": [50716, 295, 4994, 3329, 9634, 337, 439, 264, 2609, 5491, 293, 24328, 293, 370, 322, 13, 583, 286, 519, 1338, 11, 51060], "temperature": 0.0, "avg_logprob": -0.16718738079071044, "compression_ratio": 1.5565217391304347, "no_speech_prob": 0.00021878324332647026}, {"id": 754, "seek": 422518, "start": 4239.1, "end": 4243.5, "text": " probably some anthropologist has already done a definitive analysis of distributed cognition", "tokens": [51060, 1391, 512, 22727, 9201, 575, 1217, 1096, 257, 28152, 5215, 295, 12631, 46905, 51280], "temperature": 0.0, "avg_logprob": -0.16718738079071044, "compression_ratio": 1.5565217391304347, "no_speech_prob": 0.00021878324332647026}, {"id": 755, "seek": 422518, "start": 4243.5, "end": 4254.22, "text": " in this company, but if they haven't, they certainly need to. Thank you.", "tokens": [51280, 294, 341, 2237, 11, 457, 498, 436, 2378, 380, 11, 436, 3297, 643, 281, 13, 1044, 291, 13, 51816], "temperature": 0.0, "avg_logprob": -0.16718738079071044, "compression_ratio": 1.5565217391304347, "no_speech_prob": 0.00021878324332647026}, {"id": 756, "seek": 425518, "start": 4255.18, "end": 4258.22, "text": " Thank you.", "tokens": [50364, 1044, 291, 13, 50516], "temperature": 0.0, "avg_logprob": -0.814461867014567, "compression_ratio": 0.5555555555555556, "no_speech_prob": 0.8290488123893738}], "language": "en"}