start	end	text
0	8820	This is a compliant machine called a mechanical neural network.
8820	13880	It's the first of its kind to successfully demonstrate the mysterious ability to learn
13880	16300	similar to biological brains.
16300	22040	Inspired by the mathematics of artificial neural networks, which enable most artificial intelligent
22040	27440	machine learning technologies today, this mechanical neural network paves the way for
27440	33880	a new kind of material that can physically learn its mechanical behaviors and properties.
33880	38860	Whereas the properties of most materials remain largely fixed and are a function of their
38860	44080	composition and microstructure, this new kind of learning material could get better and
44080	49740	better at exhibiting desired mechanical properties and behaviors, such as this shape morphing
49740	55520	behavior, when exposed to ever increasing amounts of loading experiences.
55760	60920	If such materials are ever damaged or cut to form new shapes or sizes, they could not
60920	67080	only relearn their original behaviors, but they could also learn new behaviors as desired.
67080	70720	The applications of such learning materials are endless.
70720	75640	Imagine training the wings of an aircraft so that they learn to optimally warp their
75640	81480	airfoil shape when subjected to unanticipated and changing wind loading conditions so that
81480	86880	the aircraft improves its fuel efficiency and maneuverability with every flight.
86880	91440	Or imagine training the structural members of a building by shaking them in different
91440	96480	ways so that the building learns to remain stationary regardless of the kind of seismic
96480	100040	waves induced by an actual earthquake when it strikes.
100040	105360	Or imagine training body armor by repeatedly shooting it at different locations and from
105360	110880	different orientations so that the armor gets better and better at redirecting any projectiles
110920	114360	impacting shock waves away from vital organs.
114360	118920	Instead of expending the immense amount of time and cost it currently takes to develop
118920	123800	a new material that achieves specific combinations of desired properties which are currently
123800	129400	not possible, such learning materials could simply be deployed without human understanding
129400	134680	and the material would autonomously learn to achieve those properties while also acquiring
134680	138880	that understanding for future designers to learn from.
138880	141880	So how would this kind of learning material work?
141880	146200	Well, it's important to first understand the source of its inspiration.
146200	152360	The idea for a mechanical neural network was inspired by a physical version of an artificial
152360	153560	neural network.
153560	158840	The mathematics underlying artificial neural networks are diagrammed using interconnected
158840	164280	lines that represent scalar weight values which are multiplied by input numbers that
164280	166880	are fed into multiple layers of neurons.
166880	172400	These neurons consist of activation functions that ultimately produce output numbers.
172400	177360	If the artificial neural network is provided with a set of known input and output numbers,
177360	183480	the network can be trained by tuning its weights over time so that it accurately predicts previously
183480	187360	unknown output numbers that result for any input numbers.
187360	191560	Here, different shades of blue represent different scalar weight values.
191560	197280	In this way, artificial neural networks can mathematically learn to model complex systems
197280	200160	that map many inputs to many outputs.
200160	205640	Similarly, mechanical neural networks possess physical interconnected tunable beams, shown
205640	210680	here as blue lines, which are mechanical analogues to the weight lines within artificial neural
210680	212040	network diagrams.
212040	216640	The beams connected nodes, shown as white circles outline black, which are analogous
216720	219800	to the neurons within artificial neural networks.
219800	224920	Whereas artificial neural networks tune their weights to match input numbers to output numbers,
224920	230280	the mechanical neural network proposed here tunes the axial stiffness values of its beams
230280	234720	to match input loads to desired output behaviors.
234720	239240	To demonstrate how the envisioned mechanical learning would work, suppose a shape morphing
239240	245080	behavior is desired for the following eight-layer deep triangular lattice consisting of eight
245080	248120	input nodes and eight output nodes.
248120	253360	Note that the black bars along the top and bottom edges of this lattice represent a grounded
253360	256880	body on which the nodes that touch it are pinned.
256880	261520	Suppose that when the input nodes along the left side are loaded by equivalent horizontal
261520	267160	forces, it is desired that the output nodes along the right side respond by displacing
267160	272720	to target locations along the contour of an undulating sinusoidal shape, shown as the
272720	273800	red curve.
273800	278160	To learn the shape morphing behavior, each tunable beam in the lattice would start the
278160	284760	learning process by setting their axial stiffness to a random value depicted here as a specific
284760	287800	shade of blue according to this color scale.
287800	292120	When the input nodes on the left side of the lattice are loaded with the horizontal input
292120	297560	forces of the desired behavior, the resulting displacements of the output nodes would then
297560	304520	be measured and a mean-squared error, i.e. MSE, would be calculated by finding the average
304520	309600	of the scalar difference between the target output node displacements and these measured
309600	316080	output node displacements, i.e. their final location error, EI, for all n nodes on the
316080	322040	right side of the lattice squared, for this lattice, n equals eight output nodes.
322040	327120	The tunable beam elements would then change their axial stiffness values according to
327160	333640	an optimization algorithm such that when the process of loading, measuring, and calculating
333640	339360	the mean-squared error is repeated, the mean-squared error would be minimized until a working
339360	345120	combination of beam stiffness values is identified that achieves the desired behavior.
345120	349960	One possible combination of beam stiffness values that enabled this mechanical neural
349960	355120	network to achieve the desired sinusoidal shape morphing behavior is shown here.
355120	360520	Suppose it is desired that the neural network then learns another new behavior in addition
360520	361880	to the first behavior.
361880	366880	Specifically, suppose it is desired that in addition to the lattice's output nodes displacing
366880	371960	to this sinusoidal shape in response to its input nodes being loaded with equivalent horizontal
371960	377720	forces, the same lattice's output nodes also displace to an inverted sinusoidal shape in
377720	383480	response to its input nodes being loaded by equivalent vertical input forces instead.
383480	388800	To learn the new behavior, shown green, while maintaining the ability to simultaneously achieve
388800	393640	the first behavior, shown red, the lattice of tunable beam elements could either start
393640	399160	with another random combination of stiffness values as shown here, or they could start
399160	403840	with the same combination of stiffness values that were found to successfully achieve the
403840	405480	first behavior only.
405480	410280	Parenthetically, the latter choice becomes increasingly favorable as the mechanical neural
410280	414920	network acquires more and more behaviors because the working combination of beam stiffness
414920	419720	values acts as a sort of muscle memory for previously learned behaviors.
419720	424280	Regardless of what starting combination of beam stiffness values are selected, however,
424280	429120	the input nodes would then be loaded with both the horizontal and then vertical forces
429120	435160	of the first and second behaviors respectively, and a single mean squared error would be calculated
435160	441800	that simultaneously considers the square of the output node final location errors of both
441800	444400	loading scenarios averaged together.
444400	449080	The tunable beam elements would then change their axial stiffness values according to
449080	456920	the same optimization algorithm such that when the process of loading, measuring, and calculating
456920	462400	the cumulative mean squared error of both behaviors is repeated, this new mean squared
462400	468360	error would be minimized until a working combination of beam stiffness values is identified
468360	473400	that successfully achieves the first and second behaviors simultaneously.
473400	478200	Note that the tunable beams all remain the same shade of blue regardless of whether the
478200	482680	lattice is actuated with the loads of the first or the second behaviors because the
482680	487600	same combination of beam stiffness values successfully achieves both behaviors.
487600	492520	It's also important to recognize that mechanical neural networks can achieve the same desired
492520	497640	set of behaviors using many different combinations of beam stiffness values.
497640	502680	Note for instance that although this second solution exhibits the same desired behaviors
502680	507680	as our first solution, it does so with an entirely different combination of beam stiffness
507680	508680	values.
508680	512560	The fact that many different combinations of beam stiffness values can achieve the same
512560	517360	behaviors allows mechanical neural networks to learn more and more new behaviors while
517360	520520	retaining memory of previously learned behaviors.
520520	525200	Finally, it's also worth noting that mechanical neural networks are not limited to learning
525200	531120	shape morphing behaviors only but can learn almost any combination of quasi-static, thermal,
531120	536560	and even dynamic mechanical behaviors including the control of wave propagation within their
536560	539620	lattice.
539620	544640	To experimentally demonstrate the concept of a mechanical neural network, it was important
544640	549600	to first design a tunable beam that could achieve adjustable stiffness along its axis.
549600	554080	After comparing multiple concepts, we settled on this compliant design.
554080	558720	It consists of two parallel blade flexors that deform to guide the translational extension
558720	563920	and contraction of the beam along its axis while rigidly constraining all other directions.
563920	569040	A bracket is attached to the beam's housing in part to provide a hard stop so that the
569040	573240	parallel blade flexors are not allowed to deform to a point where they would yield,
573240	576520	i.e. be permanently damaged beyond their elastic limit.
576520	582120	The bracket is also attached to the magnet end of a voice coil actuator which is aligned
582120	584040	with the beam's central axis.
584040	588720	The actuator's other mating end, which consists of a coil of copper wire wrapped around a
588720	593560	drum, is attached to another bracket that is attached to the other side of the beam's
593560	594560	housing.
594560	598520	Depending on the direction and magnitude of the current flowing through the wrapped wire,
598520	603280	the magnetic field can be induced by the coil that pushes or pulls on the voice coil's
603280	608800	magnet end, thus actuating the beam along its axis in either direction.
608800	613280	Two strain gauge sensors are mounted on either side of one of the parallel blade flexors
613280	618660	at its base to accurately measure the resulting displacement of the beam along its axis by
618660	623560	transforming the flexor's deformation strain into a proportional voltage signal.
623560	629080	In this way, closed loop control can be applied to actively tune the beam's axial stiffness
629080	632320	to achieve any value between an upper and a lower limit.
632320	637320	You could imagine that the highest axial stiffness would be achieved if when the beam is loaded,
637320	642880	the voice coil responds by resisting the load with the largest actuated force possible in
642880	645480	the opposite direction as the applied load.
645480	649920	Likewise, the lowest axial stiffness would be achieved if when the beam is loaded, the
649920	655160	voice coil responds by assisting the load with the largest actuated force possible along
655160	657760	the same direction as the applied load.
657760	663760	In this way, the tunable beams could be made to achieve zero or even negative stiffness.
663760	668880	The beam's housing inflectures were cut from an aluminum sheet using wire EDM and its brackets
668880	671760	were machined from aluminum L brackets.
671760	676760	We applied proportional and derivative closed loop control as detailed by this diagram to
676760	680240	achieve the desired stiffness control of the tunable beams.
680240	685760	An instant testing machine was used to individually calibrate each beam by generating these four
685760	688800	plots to inform the controller as shown.
688800	694640	If this function is set to EK in the control loop and the proportional gain Kp is set to
694640	700000	a desired value, the resulting forced displacement response of the actively controlled beam will
700000	705120	be linear and will possess an unchanging slope, i.e. stiffness, that is equal to the
705120	708280	proportional gain Kp value set.
708280	712960	This plot, measured using an instant testing machine, shows the linear forced displacement
712960	718480	responses of a tunable beam being controlled with different Kp values to achieve corresponding
718480	721520	positive and negative axial stiffness values.
721520	725840	The maximum and minimum stiffness values that the beam could be controlled to achieve without
725840	733280	becoming unstable was measured to be 2.3 Nm and negative 2 Nm respectively.
733280	738280	With a working tunable beam that could be controlled to achieve any desired axial stiffness
738280	744000	between its maximum and minimum stiffness values, 21 such tunable beams were fabricated
744000	749320	and assembled within a triangular configuration as shown by these blue lines to demonstrate
749320	752000	learning within a mechanical neural network.
752000	756720	Four additional voice coil actuators were used in conjunction with decoupling flexures
756720	760720	to drive the two input nodes on the left side of the lattice with forces that can be made
760720	763800	to point in any in-plane direction desired.
763800	769800	Two cameras mounted on a frame directly measure the displacement of pins inserted at the center
769800	775360	of both output nodes and black felt is used to contrast the white color of the pin heads
775360	777080	so that they stand out.
777080	781760	This colored computer generated image helps clarify other important features within the
781760	783440	mechanical neural network.
783440	788400	Note the purple colored rotational flexures centered around each of the network's nodes.
788400	793760	These flexures passively deform to accommodate the expansions and contractions of the tunable
793760	796840	beams as the network is loaded during learning.
796840	802120	Also note the green colored flexures that decouple the input actuators due to their cleverly
802120	803640	stacked arrangement.
803640	808480	Hard stops are built around all the flexures in the system to prevent them from yielding.
808480	813000	Although the machine's two mounted cameras can directly measure the lattice's output
813000	818560	node displacements, note that the strain gauge sensors on each beam can directly measure
818560	823360	the beam's extension and contraction and that information can be used to indirectly
823360	827600	calculate the displacements of all the nodes in the mechanical neural network including
827600	829880	the displacements of its output nodes.
829880	834560	This strain gauge approach to indirectly sensing the output node displacements can predict
834560	839680	the displacements with a much higher sampling rate compared to the frame rate of the cameras.
839680	844440	These plots show how accurately the strain gauge approach tracked the cameras measured
844440	849000	output node displacements when the lattice was loaded with a random combination of axial
849000	852720	stiffness values uploaded to each tunable beam in the lattice.
852720	856680	The strain gauge approach is also important to the functionality of mechanical neural
856680	861400	networks because without the approach such networks cannot learn without being placed
861400	866680	in a testing rig which is not practical for most applications that require in-field learning.
866680	871360	Moreover, the ability to accurately measure the displacements of all the nodes in the
871360	876560	network when it is subjected to unanticipated and changing ambient loading scenarios is
876560	881800	necessary for mechanical neural networks to be able to identify when those loads correspond
881800	886480	to the input forces of their desired behaviors being learned so that the network can then
886480	891080	calculate its mean squared error and minimize it as described previously.
891080	896480	Note that the input node forces can be indirectly calculated at any given time using the current
896480	901800	combination of beam stiffness values uploaded to the network at that time and the corresponding
901800	906240	strain gauge measured displacements of all the network's nodes that resulted from these
906240	908400	loading forces.
908400	913600	Our 21 beam mechanical neural network first demonstrated its ability to learn by learning
913600	918160	two behaviors simultaneously using the approach described previously.
918160	923640	For the first behavior shown exaggerated in red here, output node 1 should displace outward
923640	929080	0.5 millimeters while output node 2 should displace inward 0.5 millimeters when the input
929080	932000	nodes are loaded with 1 Newton horizontal forces.
932000	937200	For the second behavior shown exaggerated in green here, the output node 1 should displace
937200	942720	inward 0.5 millimeters while output node 2 should displace outward 0.5 millimeters when
942720	946360	the input nodes are loaded with 1 Newton vertical forces.
946360	950920	The first optimization algorithm that we use to determine what combination of axial stiffness
950920	955720	values should be uploaded to each tunable beam in lattice during each step of the learning
955720	958560	approach was a genetic algorithm.
958560	963280	The algorithm samples 1000 random beam stiffness combinations.
963280	968280	It then identifies and plots the combination that achieved the lowest resulting output
968280	970520	node displacement mean squared error.
970520	976320	A new, more promising group of 1000 beam stiffness combinations is then generated by crossing
976320	980240	the most successful combinations attempted in the previous group.
980240	985640	The process is repeated until the mean squared error calculated stops changing from one group
985640	986640	to the next.
986640	991840	A plot showing how the algorithm reduced the mean squared error over time is shown here,
991840	997160	along with a video showing the mechanical neural network learning in real time.
997160	1002280	This animation shows how both output nodes displaced progressively closer to their target
1002280	1008320	locations as improved beam stiffness combinations were identified from one group to the next.
1008320	1013280	The initial starting and ending locations of those output nodes are shown here without
1013280	1015720	the visual clutter of the path taken.
1015720	1021520	You can see that their final locations are almost directly on top of the target locations.
1021520	1026720	Once learning was successfully demonstrated in this way, using the genetic algorithm described
1026720	1032640	previously, we then conducted a study to compare the performance of five other optimization
1032640	1037440	algorithms to determine which algorithm is best suited for mechanical neural network
1037440	1039040	learning in general.
1039040	1044400	The five additional algorithms studied were full pattern search, partial pattern search,
1044400	1048880	interior point, sequential quadratic programming, and Nelder mean.
1048880	1053200	We compared how low the final mean squared error could be made using each algorithm,
1053200	1058160	i.e. how accurately the mechanical neural network could successfully learn its behaviors,
1058160	1063480	and how many iterations the algorithm required to achieve that final mean squared error, i.e.
1063480	1067160	how fast the mechanical neural network could learn its behaviors.
1067160	1071400	It was determined that Nelder mean was the best suited algorithm for mechanical neural
1071400	1076840	networks due to the algorithm's practical learning speed, impressive learning accuracy,
1076840	1079280	and its insensitivity to system noise.
1079280	1083520	The details of that study were published in the Journal of Mechanical Design and a link
1083520	1086480	to the paper is provided in the description below.
1086480	1091280	We were also interested to use the mechanical neural network to determine whether beams
1091280	1096040	that are tuned to exhibit non-linear stiffness, i.e. stiffness that changes as the beams
1096040	1100800	deform, are favorable for learning compared to beams that are tuned to exhibit linear
1100800	1101800	stiffness.
1101800	1105440	Our closed loop controller was designed to test this hypothesis.
1105440	1111600	If this f of ek function is changed from ek to a different function, like tangent ek,
1111600	1116120	then the resulting force displacement plot exhibited by the actively controlled beam
1116120	1118680	would be a non-linear tangent function.
1118680	1123600	This plot shows the tunable beam's force displacement response measured using an instrument
1123600	1130200	testing machine with f of ek equaling ek and tangent ek for different proportional gain
1130200	1134240	values, i.e. a kp of 1, 0, and negative 1.
1134240	1139280	We then trained the mechanical neural network to learn random shape morphing behaviors using
1139280	1145240	both linear and non-linear tangent force displacement responses and compared their mean squared error
1145240	1147960	versus time plots as shown here.
1147960	1153400	Much to our surprise, the plots suggest that tunable beams that achieve linear stiffness
1153400	1158360	can learn behaviors with greater accuracy, i.e. lower mean squared error, than tunable
1158360	1161360	beams that achieve non-linear stiffness.
1161360	1166640	We then created a computational tool to simulate the behavior of our mechanical neural network
1166640	1172200	design so that we could use the tool to predict how well larger versions of the same design
1172200	1177320	would learn if we had the time and resources to build and incorporate many more tunable
1177320	1182960	beams within its lattice as depicted by this photoshopped image of a much larger lattice.
1182960	1188240	Our computational tool models the tunable beams as linear beams, which are depicted
1188240	1193160	as blue lines, and their lengths are set to be the length of the beams in our fabricated
1193160	1197360	mechanical neural network, i.e. 6 inches from node to node.
1197360	1202240	We restricted each beam in our simulation to only achieve axial stiffness values between
1202240	1207920	the maximum and minimum stiffness values measured from our fabricated beam, i.e. 2.3 Newtons
1207920	1212440	per millimeter and negative 2 Newtons per millimeter respectively, and we set their passive
1212440	1218280	non-axial stiffness values equal to the values calculated using finite element analysis as
1218280	1219280	shown here.
1219280	1224400	We also restricted the simulated beams from extending or contracting more than plus and
1224400	1229280	minus 2.5 millimeters, which is the limit of our fabricated beams as governed by their
1229280	1230640	hard stops.
1230640	1235760	Finite element analysis was used to validate the computational tool's accuracy by loading
1235760	1241080	a 21-beam version of the design in its passive state, i.e. without any closed loop stiffness
1241080	1247120	control activated, with 25 random force combinations imparted on its two input nodes.
1247120	1252560	The X and Y components of the lattice's resulting output node displacements, calculated using
1252560	1259000	both finite element analysis and our computational tool, are plotted here showing good correspondence
1259000	1265240	between each of the 25 force combinations, once configured to mimic our fabricated mechanical
1265240	1266240	neural network.
1266240	1271260	The computational tool was then used to simulate the effect that the number of layers would
1271260	1276920	have on the ability for a triangularly configured mechanical neural network consisting of eight
1276920	1282440	input and output nodes to learn different numbers of random shape morphing behaviors.
1282440	1287360	The results of the study indicate, one, that mechanical learning improves with more layers,
1287360	1291920	likely because there are more tunable beams with which to learn, and two, the more random
1291920	1296420	behaviors that are required to be learned, the less accurately all the behaviors can
1296420	1298440	be learned simultaneously.
1298440	1303280	This plot was similarly generated, but for only two, four, and eight layers, and for
1303280	1308360	both triangular and square lattice configurations, shown green and red respectively.
1308360	1313680	It is clear from these results that triangular lattice configurations can, in general, learn
1313680	1319120	different numbers of shape morphing behaviors more effectively than square lattice configurations.
1319120	1324240	The reason is likely because triangular lattices have more beams for the same number of layers,
1324240	1329200	and they can propagate displacements in all directions, rather than just along orthogonal
1329200	1332240	directions, as is the case with square lattices.
1332240	1337200	To learn the effect that the number of layers and output nodes have on mechanical learning,
1337200	1342680	we used our computational tool to generate the following plot for triangular lattices
1342680	1346280	that learn the two sinusoidal behaviors described previously.
1346280	1351480	The plot indicates that once the lattice possesses two or more layers, the number of output nodes
1351480	1353120	does not seem to matter.
1353120	1358040	It's true that the more output nodes a lattice has, the more output node displacement requirements
1358040	1362880	the output nodes must satisfy, but it's also true that the more output nodes a lattice has,
1362880	1367760	the more beams the lattice can employ to satisfy those requirements during learning, so both
1367760	1369760	effects seem to negate each other.
1369760	1374040	If you'd like to learn more about the details presented in this video, I encourage you to
1374040	1378320	read our first published journal article on the topic of mechanical neural networks
1378320	1382760	in Science Robotics, where our work was featured on the journal's front cover.
1382760	1387680	A link to the paper is provided in the description below, along with a link to my Thingiverse
1387680	1392360	account where you can download the part files necessary to fabricate our mechanical neural
1392360	1393360	network.
1393360	1398000	Finally, I want to thank my students Ryan Lee, who built and tested the mechanical neural
1398000	1404160	network, Erwin Mulder, who developed our computational tool, P. H. R. Sainaghi, who helped perform
1404160	1408960	the optimization algorithm comparison study, and all the other students who contributed
1408960	1411960	in smaller ways to the success of this project.
1411960	1417680	I am especially grateful to my AFOSR program manager, Les Lee, for making this research
1417680	1422160	possible through his continued funding and generous support of my group.
1422160	1426240	If you'd like to support my channel, I've provided instructions in the description
1426240	1427240	below.
1427240	1430000	Thanks for watching the Facts of Mechanical Design.
