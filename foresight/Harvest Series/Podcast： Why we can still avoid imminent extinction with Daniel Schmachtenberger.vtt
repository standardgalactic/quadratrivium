WEBVTT

00:00.000 --> 00:10.480
Daniel Schmartenberger, thank you for being with us.

00:10.480 --> 00:11.480
Thanks for having me.

00:11.480 --> 00:15.440
So, you're a philosopher, a founding member of the Consilience Project.

00:15.440 --> 00:21.200
The goal of this conversation today is to analyze the direction our civilization is

00:21.200 --> 00:28.160
taking in half an hour, because you've been doing like so many great podcasts about the

00:28.160 --> 00:34.120
metacrisis during lasting three to four hours, and I suggest that people go and watch them

00:34.120 --> 00:35.120
on the Internet.

00:35.120 --> 00:36.120
They're very good.

00:36.120 --> 00:37.960
We'll start with the harvest of the day.

00:37.960 --> 00:44.280
The question I'm asking to all the guests here for Harvard Podcasts, if something easy

00:44.280 --> 00:49.760
or simple could be done and would make the world a better place, what would it be for

00:49.760 --> 00:51.000
you, Daniel?

00:51.000 --> 00:54.800
When I saw the note that you sent me, that that would be a last question.

00:54.800 --> 00:58.080
Is there a simple or easy thing that everyone could do that make the world a better place?

00:58.080 --> 00:59.080
That kind of cringed?

00:59.080 --> 01:05.120
Because I usually really am not a fan of that question, because the world needs so many

01:05.120 --> 01:10.120
different kinds of things done that require different skills and capacities and orientations

01:10.120 --> 01:14.920
and to try to reduce it to some thing that would be true for everybody.

01:14.920 --> 01:18.880
You get a platitude like be kind or loving or something like that, or you get something

01:18.880 --> 01:24.480
like recycle or pick up trash or try to use less carbon or something that doesn't map

01:24.480 --> 01:26.680
to the whole set of things that the world needs.

01:26.680 --> 01:35.440
I think there's a process where movements have been associated with political processes

01:35.440 --> 01:40.680
and markets in a way that it's like, here's this great catastrophe that'll happen if the

01:40.680 --> 01:45.360
other side gets elected, so everybody needs to get out and vote for so and so.

01:45.360 --> 01:50.480
That's like everybody can do a simple thing because we're relating to everybody as voters

01:50.480 --> 01:56.120
or everybody donate to this cause or boycott this thing, but the complexity of the world's

01:56.120 --> 02:02.600
issues from climate issues to AI risk to supply chain issues to electrical grid issues, like

02:02.600 --> 02:05.040
there's no action like that.

02:05.040 --> 02:09.360
There's no somebody to vote for or not to vote for thing to donate to that addresses

02:09.360 --> 02:10.360
it.

02:10.360 --> 02:16.240
One thing that is not necessarily easy, but is relatively simple, that would be great

02:16.240 --> 02:22.440
if everybody in the world could do more, is to seek to try to understand other people's

02:22.440 --> 02:27.680
perspectives much more deeply, particularly those that are most different than their own.

02:27.680 --> 02:38.400
If you can try to take the opposite perspective on abortion, on gun control, on climate change,

02:38.400 --> 02:44.320
on the Ukraine-Russia war, on the Chinese versus Western system, on any of those things,

02:44.320 --> 02:46.000
on the Israel-Palestine issue.

02:46.000 --> 02:51.960
If you can try to earnestly be able to make the argument that the person on the other

02:51.960 --> 02:56.640
side would make as well enough that they don't have anything to add to it, and not

02:56.640 --> 03:02.120
just as a rhetorical process, but connect to the values that they care about and what

03:02.120 --> 03:05.840
it feels like to be them and see the world through their eyes, realizing that there might

03:05.840 --> 03:06.840
be distortion.

03:06.840 --> 03:10.920
There might be a lot of things missing, but there's not zero truth or zero value to it.

03:10.920 --> 03:20.160
That process, if everyone did that, would actually result in addressing the metacrisis

03:20.320 --> 03:26.080
in all of its complexity, the issues in synthetic biology risk, and pandemics, and escalation

03:26.080 --> 03:30.560
pathways to warfare, and economic issues, and geopolitical issues, and all of them.

03:30.560 --> 03:37.320
You can say that they either come down to conflict or externalities, like we cause harm

03:37.320 --> 03:43.320
directly, intentionally, which a war is a great example of, or harm gets caused that

03:43.320 --> 03:46.160
we didn't intend to cause.

03:46.160 --> 03:48.040
No one intended to cause climate change.

03:48.040 --> 03:53.720
We just wanted to have transportation and energy, and the secondary byproduct of that

03:53.720 --> 03:55.800
was climate change.

03:55.800 --> 03:59.760
All of the environmental issues, no one intentionally had a conflict with the environment that was

03:59.760 --> 04:00.760
causing it.

04:00.760 --> 04:05.880
It was the externality of optimizing something and causing harm somewhere else.

04:05.880 --> 04:09.240
There are problems that we intentionally cause, and there are problems that we accidentally

04:09.240 --> 04:10.240
cause.

04:10.240 --> 04:13.640
Both of them would be corrected by seeking to understand all the perspectives more,

04:13.640 --> 04:19.440
because if you sought to understand the perspectives well enough, conflict theory would evaporate.

04:19.440 --> 04:23.560
Most of the mistakes, when you're trying to optimize for one thing and you end up causing

04:23.560 --> 04:27.560
externalities to something else, somebody else saw that and knew that, and if you were

04:27.560 --> 04:33.040
in wide enough conversations, then the thing that you're trying to optimize for that's

04:33.040 --> 04:36.400
going to cause harm somewhere else someone else would have mentioned and said, actually,

04:36.400 --> 04:40.040
let's improve your design or your strategy by factoring this.

04:40.040 --> 04:45.240
Both the unintentional externalities and the intentional conflict would be resolved through

04:45.240 --> 04:51.960
active perspective seeking and then perspectives and this is wonderful.

04:51.960 --> 04:56.880
When you look at the history, as you said, humans seem to have a talent for innovation

04:56.880 --> 05:03.200
and progress, but also a natural tendency for war and chaos.

05:03.200 --> 05:08.760
These two tendencies fit each other and make things bigger and bigger, so greatest but

05:08.760 --> 05:12.720
out of control technologies can cause a huge damage.

05:12.720 --> 05:21.800
What do you think should be done about technologies and do they represent innovation or danger

05:21.800 --> 05:23.560
for you?

05:23.560 --> 05:27.560
First thing about technology is that even if we're not talking about a military technology,

05:27.560 --> 05:31.560
we're talking about a technology for some other purpose, even if we develop a technology

05:31.560 --> 05:35.540
for some non-military purpose, it will have a military application or some kind of conflict

05:35.540 --> 05:40.900
oriented application, basically saying all technologies dual use.

05:40.900 --> 05:46.220
Maybe we're doing the synthetic biology gene editing for trying to cure cancer, but as

05:46.220 --> 05:50.660
we get better at making tools to do gene editing, can that be used for bio weapons?

05:50.660 --> 05:51.660
Totally.

05:51.660 --> 05:56.560
Maybe we're making the AI to try to do drug discovery, but can that same AI do autonomous

05:56.560 --> 05:58.060
drones?

05:58.060 --> 05:59.180
Of course it can.

05:59.180 --> 06:04.940
Whatever purpose we're developing technology for, we're also making that technology cheaper

06:04.940 --> 06:11.660
and easier for all other types of purposes simultaneously, and that's a huge thing we

06:11.660 --> 06:13.220
have to factor.

06:13.220 --> 06:19.500
From a conflict point of view, obviously people with stone age technology can't cause a war

06:19.500 --> 06:23.740
that blows the world up, and people with bronze age technology can't cause a war that blows

06:23.740 --> 06:24.740
the world up.

06:24.740 --> 06:28.820
The harm is proportional to the amount of tech, so as we move into exponentially more

06:28.820 --> 06:36.260
powerful tech, we can't continue to use it with the types of conflict orientation and

06:36.260 --> 06:38.420
irresponsibility we used previous tech.

06:38.420 --> 06:43.180
The other thing is that even when we're not using tech for intentionally conflict oriented

06:43.180 --> 06:49.220
purposes, all of the tech we use does externalize harm in different ways.

06:49.220 --> 06:54.580
So whether we're talking about agricultural technology where the nitrogen fertilizer fed

06:54.580 --> 06:59.420
a lot of people but also causes all the dead zones in the ocean and soil erosion and biodiversity

06:59.420 --> 07:05.340
loss, exponentially more technology also means exponentially more externalities.

07:05.340 --> 07:09.660
And so we can't handle exponential war and we can't handle exponential externalities.

07:09.660 --> 07:15.220
So we have to change our relationship with technology really fundamentally and say no

07:15.220 --> 07:20.500
other animal have the ability to destroy the biosphere that it depends upon.

07:20.500 --> 07:21.500
We now do.

07:21.500 --> 07:25.840
We did not for all of human history, so we didn't have to really wrestle with that power.

07:25.840 --> 07:31.820
We did kill and enslave and genocide and every previous civilization doesn't still exist

07:31.820 --> 07:37.160
because they all ended up collapsing mostly for reasons that were largely self-induced.

07:37.160 --> 07:41.660
Even when wars happened, oftentimes a war that overtook a civilization was from an enemy

07:41.660 --> 07:46.700
that was less powerful than ones that they had vanquished in their prime.

07:46.700 --> 07:50.260
They had already went through some internal institutional decay from infighting and things

07:50.260 --> 07:51.420
like that.

07:51.420 --> 07:54.540
Many early civilizations died from environmentally induced causes.

07:54.540 --> 07:56.220
They cut down all the trees.

07:56.220 --> 07:59.200
They over stripped the soil of nutrients.

07:59.200 --> 08:03.540
So civilizational breakdown is actually the norm.

08:03.540 --> 08:05.260
It's just never been at a global level.

08:05.260 --> 08:07.980
Now we don't live in the United States or China.

08:07.980 --> 08:13.740
We live in a place where the cell phone that we're watching this on or the computer we're

08:13.740 --> 08:19.780
watching it on took six continent supply chains to make communicating via satellites

08:20.300 --> 08:24.580
so we live in a kind of global civilization where none of the countries are actually

08:24.580 --> 08:27.180
autonomous for fundamental things that they need.

08:27.180 --> 08:34.860
Now that we do have the ability to destroy the biosphere either very rapidly through

08:34.860 --> 08:41.300
exponential technology like synthetic biology or AI or warfare or kind of slowly through

08:41.300 --> 08:45.100
the limits of growth and environmental issues but that's not all that slow.

08:45.100 --> 08:51.180
If you have the power to destroy the nature that you depend upon you have to consciously

08:51.180 --> 08:53.900
steward it or you'll self-terminate.

08:53.900 --> 09:01.300
So the gist is we don't have evolutionary capacities.

09:01.300 --> 09:04.020
We have trans evolutionary capacities meaning-

09:04.020 --> 09:05.900
What's the difference here?

09:05.900 --> 09:06.900
Yeah.

09:06.900 --> 09:10.100
So and I'm meaning evolution in a biologic evolution sense.

09:10.100 --> 09:17.460
So another animal has the capacities that it has corporeally built into its body based

09:17.460 --> 09:18.460
on its genes.

09:18.460 --> 09:22.580
So a predator can't become radically more predatory quickly.

09:22.580 --> 09:27.700
It is only through genetic mutation that maybe it becomes slightly faster or has slightly

09:27.700 --> 09:32.420
bigger teeth and then it's going to be a relatively small change and then there will be co-selection.

09:32.420 --> 09:36.340
The slightly more effective predator will eat the slightly slower preys which means

09:36.340 --> 09:41.780
that the faster prey genes and breed and you get this kind of co-selective process.

09:41.780 --> 09:47.360
We threw our ability to build tools and then tools on tools, recursive abstraction.

09:47.360 --> 09:53.860
If you look at a true apex predator, you look at an orca in the ocean, an orca maybe can

09:53.860 --> 09:59.500
catch one fish at a time, one tuna at a time, then you look at a trawling boat that has

09:59.500 --> 10:03.340
a mile long drift net that can pull up 100,000 fish at once.

10:03.340 --> 10:05.340
They're not apex predators, right?

10:05.340 --> 10:07.620
Like it's wrong to think of us as apex predators.

10:07.620 --> 10:14.580
We have power that is not encoded in our bodies, extra corporeal technological capacity.

10:14.580 --> 10:17.980
You look at a nuclear bomb explosion versus a pissed off polar bear.

10:17.980 --> 10:21.580
They're not similar levels of destructive capacity.

10:21.580 --> 10:26.860
So since we have beyond evolutionary capacity, we actually have to have beyond evolutionary

10:26.860 --> 10:30.140
motive to guide that capacity.

10:30.140 --> 10:35.220
And if you want to say that mythopoetically, it's if you have the power of gods and by

10:35.220 --> 10:37.660
gods here, like I mean little G, right?

10:37.660 --> 10:42.580
I mean it mythopoetically meaning you can make species extinct.

10:42.580 --> 10:44.100
You can destroy ecosystems.

10:44.100 --> 10:48.940
You can create an Anthropocene where the largest effect on the geology of the planet is human

10:48.940 --> 10:49.940
activity.

10:49.940 --> 10:51.980
You can genetically engineer new species, right?

10:51.980 --> 10:55.940
That's much closer to the power of gods than it is the power of an apex predator.

10:55.940 --> 10:59.740
If you don't also have the love and wisdom of gods and prudence of gods to guide it,

10:59.740 --> 11:01.300
it doesn't go well.

11:01.300 --> 11:09.580
And so, you know, that is just another way of saying if you have recursive abstraction

11:09.580 --> 11:17.420
on tools that gives us and tools and coordination that give us the radically more than evolutionary

11:17.420 --> 11:22.860
capacity to affect the world, we have to move into trans evolutionary motive, which means

11:22.860 --> 11:26.180
the same recursive abstraction that we're doing right now saying, oh yeah, I guess it

11:26.180 --> 11:33.020
makes sense that we can't run an exponential financial system that's attached to a linear

11:33.020 --> 11:37.220
materials economy that takes stuff out of nature faster than it can be replenished and

11:37.220 --> 11:40.740
turns it into trash and pollution in nature faster than it can be processed.

11:40.740 --> 11:44.500
You can't do that exponentially forever on a finite planet, so we have to do something

11:44.500 --> 11:48.740
fundamentally different, which means you can't orient towards continued, maximized growth

11:48.740 --> 11:52.020
and maximized conflict orientation forever.

11:52.020 --> 11:54.460
So that's what I mean by a trans evolutionary motive.

11:54.860 --> 12:02.020
Is it naive to think that we need a global government and we can make a global governance?

12:02.020 --> 12:09.820
When you look at the problem of countries having competitive dynamics with each other

12:09.820 --> 12:16.620
where nobody wants to price carbon properly, because if they do, their own economy will

12:16.620 --> 12:20.900
be so damaged relative to whoever doesn't that the radically decreased geopolitical

12:20.900 --> 12:25.500
power will express itself as less military power, less trade power, and particularly

12:25.500 --> 12:29.020
with whoever is at the leading edge of guiding the world system.

12:29.020 --> 12:36.660
This classic, the US isn't going to if China doesn't and vice versa, so then everyone is

12:36.660 --> 12:47.020
mostly actually just in an economics race that is also bound to an actual arms race.

12:47.020 --> 12:49.500
And that's true for pricing carbon and climate change.

12:49.500 --> 12:54.780
It's also true for fishing of the oceans and aerosols and on and on and on.

12:54.780 --> 13:00.460
So if you have an issue like the atmosphere, aerosols and the atmosphere and ozone layer,

13:00.460 --> 13:05.540
or you have an issue like the oceans or climate change, no country can solve that problem.

13:05.540 --> 13:09.700
And any country that does the thing that is doing its share that is economically disadvantaged

13:09.700 --> 13:13.940
in the short term by doing it, it just isn't going to do that if everyone else doesn't

13:13.940 --> 13:16.020
because they are caught in the competitive dynamics.

13:17.020 --> 13:21.460
So when you look at that, you're like, all right, well, we need global government because

13:21.460 --> 13:22.500
we have global issues.

13:22.500 --> 13:25.700
We don't just have national issues and you have to have governance at the level that

13:25.700 --> 13:27.980
you have issues.

13:27.980 --> 13:32.260
But then of course, most thinking people aren't really a big fan of the idea of global government

13:32.260 --> 13:37.380
because it's not a great idea to have unchecked power, though we don't have a good history

13:37.380 --> 13:40.780
of being good stewards of unchecked power.

13:40.780 --> 13:46.900
And so in many modern governments in the United States, it was kind of like the foundation

13:46.900 --> 13:51.820
of the whole idea was let's separate church and state, let's separate the judicial branch

13:51.820 --> 13:55.020
and the legislative branch and the executive branch.

13:55.020 --> 13:59.020
Let's even separate the legislative branches in the separate houses.

13:59.020 --> 14:02.340
Let's try to create as much check and balance on power as possible.

14:02.340 --> 14:07.580
So if you had a one world government that had enough power to be able to price carbon

14:07.580 --> 14:12.740
properly and enforce fishing laws and et cetera, how do you prevent it from becoming

14:12.740 --> 14:14.980
corrupted or captured?

14:14.980 --> 14:20.500
And so we need global government and we don't want global government and so that this is

14:20.500 --> 14:24.980
this like you have catastrophes on one hand that need to be avoided and that typically

14:24.980 --> 14:29.860
looks like more control mechanisms of things that if you don't control will lead to catastrophe

14:29.860 --> 14:34.620
and the control mechanisms typically lead to dystopias.

14:35.060 --> 14:37.340
So we want something that is not catastrophes or dystopias.

14:37.340 --> 14:41.460
We kind of call this the third attractor and that means you have to have control mechanisms

14:41.460 --> 14:44.860
that prevent catastrophes, but you have to have checks and balances on the power within

14:44.860 --> 14:45.860
those.

14:45.860 --> 14:46.860
How do you do that?

14:46.860 --> 14:50.620
So global governance and global government are not the same thing, right?

14:50.620 --> 14:54.300
Global government, the idea that there's some centralized global monopoly of violence,

14:54.300 --> 14:55.700
the bad idea.

14:55.700 --> 15:00.100
The idea that there is some more effective process of global coordination, even whether

15:00.140 --> 15:06.660
it's a more effective process of nations engaging in multilateral agreements that can

15:06.660 --> 15:12.300
be facilitated by technology that can make the participation or violation of those agreements

15:12.300 --> 15:20.300
more transparent or there is some process of global governance that has to occur where

15:20.300 --> 15:24.460
there's both effective power for enforcement.

15:24.460 --> 15:29.100
This is why we can solve those types of coordination problems to some degree, those race to the

15:29.100 --> 15:35.060
bottom within a country where you have a monopoly of violence because the law on monopoly

15:35.060 --> 15:38.260
of violence just basically says, no, you're not allowed to cut down any of those trees.

15:38.260 --> 15:42.220
That's a national park and if you try, the police will stop you and they have more capacity

15:42.220 --> 15:43.940
for violence than you do.

15:43.940 --> 15:47.660
With international issues where you don't actually have international enforcement, it's

15:47.660 --> 15:48.660
really, really tricky.

15:48.660 --> 15:54.140
So for all of the really global issues, and that looks like it's in each nation's interests

15:54.140 --> 15:58.340
to burn the coal as fast as it can and the oil, it's in each nation's interests to win

15:58.460 --> 16:01.900
the AI arms race, even though that increases the likelihood that we all die from it in

16:01.900 --> 16:03.220
the long term.

16:03.220 --> 16:10.340
So global governance that has appropriate checks and balances is a tricky topic, but

16:10.340 --> 16:12.300
it's a necessary topic.

16:12.300 --> 16:13.780
What gives you hope today?

16:13.780 --> 16:16.780
A lot of things can be hoped.

16:16.780 --> 16:27.900
I have noticed in my own work, people in top positions of power and major institutions

16:27.980 --> 16:37.820
that affect the world being radically more aware of things that are fundamentally unviable

16:37.820 --> 16:45.020
about this world system and interested in deeper changes and actually starting to try

16:45.020 --> 16:48.860
to implement some things just even in the last couple of years than I had ever experienced

16:48.860 --> 16:50.300
previously.

16:50.300 --> 16:57.380
So the idea that, you know, the kind of behavior that individuals can do on their own matters

16:57.460 --> 17:01.820
and the kind of stuff we can do locally like, you know, prototyping new types of communities

17:01.820 --> 17:09.140
and new types of cities, you don't solve climate change in time and you don't solve planetary

17:09.140 --> 17:12.460
boundaries in time and you don't solve AI risk that way, right?

17:12.460 --> 17:16.300
That requires kind of agreement from existing top-down organizations.

17:16.300 --> 17:18.420
They can't actually innovate a new world.

17:18.420 --> 17:22.380
They can just stop bad things from happening with the right kinds of agreements to innovate

17:22.380 --> 17:29.660
a new world actually does require local and more participatory activity.

17:29.660 --> 17:39.940
But the fact that after COVID and after the extreme political polarization that has happened

17:39.940 --> 17:47.540
and after how much of Australia burned and then flooded and, you know, now with the war

17:47.540 --> 17:54.380
on Ukraine and I think there was a situation where previously people who were thinking

17:54.380 --> 18:00.740
about it and who were prescient realized this world system is destabilizing and is fundamentally

18:00.740 --> 18:02.180
not sustainable.

18:02.180 --> 18:04.580
Most of the people who were administrating it didn't think that.

18:04.580 --> 18:09.460
Now almost everybody thinks that and that's actually something that gives me hope.

18:09.460 --> 18:10.700
Great.

18:10.700 --> 18:15.220
How much time do we have to react to avoid extinction?

18:15.980 --> 18:19.780
Some species go extinct every day as a result of human activity.

18:19.780 --> 18:26.700
So for them, we're already past existential risk, you know, Kiev was an incredibly progressive

18:26.700 --> 18:28.420
place not very long ago.

18:28.420 --> 18:33.940
It wouldn't have seemed like a place where eminent catastrophic risk was coming for many

18:33.940 --> 18:43.820
people and, you know, that's even true of Syria not that long ago and you see the pictures

18:43.820 --> 18:47.740
of what culture was like in 1968 in Iran.

18:47.740 --> 18:50.900
So it's not like how long do we have before catastrophe hits.

18:50.900 --> 18:55.180
We're already in a rolling global catastrophe.

18:55.180 --> 19:00.940
Like how long does Australia have before it burns that already happened, you know, and

19:00.940 --> 19:04.580
from extreme weather events that are a result of human induced activity poor environmental

19:04.580 --> 19:11.340
management and problems with utility companies and overuse of groundwater and climate change.

19:11.340 --> 19:16.940
And how quickly does war escalate as a result of what's happening in Ukraine at larger scale

19:16.940 --> 19:23.700
and already what we see in regarding Taiwan and Azerbaijan and Armenia and Iran and so

19:23.700 --> 19:25.940
many places.

19:25.940 --> 19:32.140
These things could move very fast or more slowly in ways that are chaotic and totally

19:32.140 --> 19:34.780
unpredictable.

19:34.780 --> 19:40.020
When you look at things like the planetary boundaries, how long until we pass certain

19:40.100 --> 19:47.140
planetary boundaries, you'll hear people talk about this thing happens in 2050 and this

19:47.140 --> 19:50.780
thing happens and by the end of the century or whatever with climate change.

19:50.780 --> 19:55.780
But we've already passed some of the planetary boundaries, you know, there's a study just

19:55.780 --> 20:01.900
published in the American Chemical Society Journal saying that certain toxic chemicals

20:01.900 --> 20:06.140
in rainwater kind of ubiquitous around the world are past the EPA thresholds for human

20:06.140 --> 20:07.700
health.

20:07.700 --> 20:12.980
And this was particularly the the fluorinated surfactants which don't break down, right?

20:12.980 --> 20:14.900
So they come forever chemicals.

20:14.900 --> 20:19.980
But the idea that things that are carcinogens and cause birth defects and are endocrine

20:19.980 --> 20:25.580
disruptors in rainwater all around the world are past the levels of human health tolerability

20:25.580 --> 20:26.580
is a huge deal.

20:26.580 --> 20:33.180
It means even if you go get off grid as can be and try to live off the land, you can't.

20:33.180 --> 20:37.540
And how quickly we're producing those chemicals, not only is there a cumulative effect of them

20:37.540 --> 20:43.220
because they're persistent, but we're also increasing our production of them exponentially.

20:43.220 --> 20:44.860
And so how long do we have?

20:44.860 --> 20:51.780
We're already in a situation of a breakdown of a world system.

20:51.780 --> 20:54.300
It's already existential for many species.

20:54.300 --> 20:58.140
It's already catastrophic for people in many areas of the world.

20:58.140 --> 21:06.820
And so I would reorient the question to be more like, is there anything that we can do

21:06.820 --> 21:09.860
to have it not be totalizing?

21:09.860 --> 21:11.620
And the answer is yes.

21:11.620 --> 21:19.260
And the answer time wise on that is the full life attention of everyone as best as possible

21:19.260 --> 21:23.100
directed at better understanding the issues and participating in the solutions is what's

21:23.100 --> 21:24.100
required.

21:24.100 --> 21:30.420
In individual level, we've become a bit lazy maybe because we think like there is always

21:30.420 --> 21:33.900
a solution and we don't really need to act.

21:33.900 --> 21:38.780
How to wake up and also how do you get the news because you have like so many news in

21:38.780 --> 21:39.780
different directions.

21:39.780 --> 21:44.180
Like we don't know who to believe and we don't know like we're not sure we need to act because

21:44.180 --> 21:47.140
things always have a solution by themselves.

21:47.140 --> 21:53.460
There's a really interesting book called The Politics of the Invisible written after Chernobyl

21:53.460 --> 22:00.380
because after the Chernobyl explosion, the uranium is invisible, right?

22:00.380 --> 22:02.540
We can't see it with the human eye.

22:02.540 --> 22:06.620
Obviously now COVID that's invisible and yet totally lethal.

22:06.620 --> 22:15.220
And what he was exploring in Politics of the Invisible is because of modern technology and

22:15.220 --> 22:20.300
chemistry, we can make things that are totally lethal that we can't see that require people

22:20.300 --> 22:26.420
with Geiger counters and the ability to do physics that not everyone can do to be able

22:26.420 --> 22:27.820
to determine safety levels.

22:27.820 --> 22:31.420
How does that work with democracy when most people don't have the capacity to do that?

22:31.420 --> 22:36.740
So you'll see currently a lot of people doubting climate change science, but nobody can actually,

22:36.740 --> 22:42.540
the average citizen can't run the IPCC's mathematical models to say they work or they don't work

22:42.540 --> 22:44.140
or they...

22:44.140 --> 22:53.140
And so people are largely kind of left to faith and you then end up getting politics driving

22:53.140 --> 22:57.740
people to either be kind of pro-institutional or anti-institutional.

22:57.740 --> 23:01.860
And the institutions get things wrong, so it's easy to be anti-institutional and neither

23:01.860 --> 23:06.420
of the positions are actually viable and there is something other than truth, which is the

23:06.420 --> 23:08.820
movement to power motivated in both of them.

23:08.820 --> 23:13.140
I see that when people think someone else will come up with a solution, they feel kind

23:13.140 --> 23:18.980
of unmotivated, but also when people think there is no solution, they feel unmotivated.

23:18.980 --> 23:26.060
And this is also something I find really interesting is when I talk to someone who has a really

23:26.060 --> 23:34.540
fervent adamant view about whatever it is, that whether it's vaccines or masks or what

23:34.540 --> 23:40.340
should happen in Russia, Ukraine or abortion law, whatever, they go from complete certainty

23:40.340 --> 23:43.540
without understanding the position of the other side or all the complexity or nuance

23:43.540 --> 23:45.140
well.

23:45.140 --> 23:49.460
And if I challenge it and not, regardless of which side it is, and show them the increased

23:49.460 --> 23:53.580
complexity, okay, well if we price carbon that way and China doesn't, then autocracy

23:53.620 --> 24:00.260
ends up running the world, so you're voting democracy out and whatever it is, then for

24:00.260 --> 24:04.780
so many people, the first response when you increase, show them the way they're thinking

24:04.780 --> 24:08.980
about it doesn't actually map to the complexity of the problem, they go from utter certainty

24:08.980 --> 24:10.580
to nihilism in one step.

24:10.580 --> 24:13.700
They're like, oh fuck it, it's too hard, it's too complex, I give up.

24:13.700 --> 24:20.540
And to move from certainty to nihilism in one step is so damn lazy, like cognitively,

24:20.540 --> 24:22.820
emotionally, epistemically lazy.

24:22.820 --> 24:27.260
And so I want people to go from certainty to like, actually I don't understand this

24:27.260 --> 24:28.260
all that well.

24:28.260 --> 24:33.660
Actually, climate change or global science or policy on this thing is pretty complex.

24:33.660 --> 24:36.780
There are experts who spend their whole life working on it who disagree.

24:36.780 --> 24:41.860
That doesn't mean there aren't solutions, but the one that was fed to me that everybody

24:41.860 --> 24:45.700
on my political side agrees with and everyone on the other side disagrees with is probably

24:45.700 --> 24:49.100
not a fair version of the whole truth.

24:49.100 --> 24:52.140
So I'm not going to give up because I don't know.

24:52.140 --> 24:54.220
I'm not going to hold the certainty that I know because I don't.

24:54.220 --> 24:58.980
I'm going to work to try to understand competently while recognizing I don't yet.

24:58.980 --> 25:04.420
And then even once I get to much deeper understanding, I'll still recognize how much stuff I don't

25:04.420 --> 25:07.180
know that's relevant and new information that might come in.

25:07.180 --> 25:13.980
So I want people to be much more epistemically rigorous and epistemically humble at the same

25:13.980 --> 25:17.980
time, epistemology meaning how we go about knowing things.

25:17.980 --> 25:24.020
So I want them to work much harder at trying to come to understand while having much less

25:24.020 --> 25:26.340
certainty about their current level of understanding.

25:26.340 --> 25:31.140
So when you ask what sources should people go to for news or whatever, the ones they don't

25:31.140 --> 25:34.740
currently go to is the first answer.

25:34.740 --> 25:36.900
And then, of course, progressively better sources.

25:36.900 --> 25:41.140
Not all the sources independent of political spinner are equally good.

25:41.140 --> 25:47.740
But when you can see where do the various earnest experts on the topic disagree and

25:47.740 --> 25:52.780
you at least understand those positions pretty well, then you start to have a sense of the

25:52.780 --> 25:53.780
topic.

25:53.780 --> 25:59.300
As a philosopher and because you spoke about politics, do you want to stay away from politics

25:59.300 --> 26:02.500
or are you into politics?

26:02.500 --> 26:08.700
Politics meaning how people organize and how they coordinate and how they make sense of

26:08.700 --> 26:10.980
the world together so they can make choices together.

26:10.980 --> 26:14.500
No, I'm totally focused on that.

26:14.500 --> 26:23.260
The current political system and the United States does not do a very good job of helping

26:23.260 --> 26:27.900
people collectively make sense of issues well, collectively identify all the values that

26:27.900 --> 26:33.420
matter that are shared values and then collectively make good choices in the presence of the shared

26:33.420 --> 26:36.260
sense making and shared values generation.

26:36.260 --> 26:42.820
So it's not that I think there is never a time to engage in voting for a particular

26:42.820 --> 26:47.860
candidate or on a particular proposition, but how to engage in metapolitics, meaning

26:47.860 --> 26:53.500
how to evolve this political system and economic system, how to evolve the political economy

26:53.500 --> 26:58.060
along with evolving the infrastructure and tech stack and the culture and value system

26:58.060 --> 27:01.700
simultaneously because all three of those inter-effect each other.

27:01.700 --> 27:07.020
The culture, the political economy and the infrastructure and technology, they all inter-effect

27:07.020 --> 27:08.020
each other.

27:08.020 --> 27:12.580
So you can't change any of them without changing all of them to think through what has to happen

27:12.580 --> 27:17.020
in all of those for a viable world to come about.

27:17.020 --> 27:19.540
I'm very interested in that.

27:19.540 --> 27:20.540
Okay.

27:20.540 --> 27:24.780
Let's speak a bit about you, something very interesting I found.

27:24.780 --> 27:28.620
You mentioned you were homeschooled by your parents.

27:28.620 --> 27:36.420
Which qualities did your parents manage to let flourish in you that might not have been

27:36.420 --> 27:42.380
so important also in the traditional education when you're changing teachers every year?

27:42.380 --> 27:49.260
I was homeschooled, I did go to school, both private and public schools for little bits

27:49.260 --> 27:50.260
throughout my life.

27:50.260 --> 27:53.900
So I have some experience of it, but most of my childhood was homeschooled, but it was

27:53.900 --> 27:59.820
not traditional homeschooling, meaning I didn't have the state curriculum and just do it at

27:59.820 --> 28:00.820
home.

28:00.820 --> 28:06.900
My parents were kind of interested in running an educational experiment that is a little

28:06.900 --> 28:10.780
bit closer to what people call unschooling today, but there was just no curriculum.

28:11.340 --> 28:12.340
Okay.

28:12.340 --> 28:15.020
What they felt you need to learn.

28:15.020 --> 28:16.500
It's not what they felt.

28:16.500 --> 28:25.420
Their hypothesis was expose the kids to all the different topics, see which ones they're

28:25.420 --> 28:29.620
interested in, facilitate their interest, and kind of trust them.

28:29.620 --> 28:35.980
So it's aligned with some of the ideas of Montessori and Dewey and Constructivism.

28:35.980 --> 28:39.780
But you know, radical had no curriculum at all.

28:39.780 --> 28:47.020
But and I'm not saying that is what I would advise, but there's a lot good in that.

28:47.020 --> 28:57.820
And what qualities that facilitated in me that most educational systems don't is all

28:57.820 --> 29:00.540
of my studies were things I was interested in.

29:00.540 --> 29:05.260
And so my interest in learning was actually growing all the time, right?

29:05.260 --> 29:08.860
There was never a place where I wanted to get out of school and go play or do something

29:08.860 --> 29:15.540
else where learning felt like a burden or where I ended up not having any negative association

29:15.540 --> 29:16.540
with study.

29:16.540 --> 29:20.020
And I had only positive association because I was studying things I wanted to study.

29:20.020 --> 29:26.620
So I find that people tend to become good at things they really enjoy.

29:26.620 --> 29:33.020
And so facilitating, like even if you have a curriculum, really paying attention to where

29:33.020 --> 29:36.500
a student's interests are and where their passions are.

29:36.500 --> 29:41.260
And if there's a topic that isn't appealing to them, trying to find a way that actually

29:41.260 --> 29:44.980
has it really appeal as opposed to just forcing them to do the thing makes a huge difference

29:44.980 --> 29:48.700
not to their learning of that topic, but to their relationship to learning itself.

29:48.700 --> 29:56.100
What a special event that put you on this path of trying to see the truth, what's happening

29:56.100 --> 29:59.700
and observe the complexity of the world.

29:59.700 --> 30:00.700
Lots of events.

30:00.700 --> 30:11.460
I mean, some people have a near death experience turning point that is really kind of singular.

30:11.460 --> 30:15.820
I think most people's life path unfolds from lots of things.

30:15.820 --> 30:21.300
So as I'm mentioning being homeschooled by parents who are obviously kind of interested

30:21.300 --> 30:26.540
in childhood development and the books my parents read to me as bedtime stories were

30:26.540 --> 30:32.620
Buckminster Fuller's Design Science and Fritschof Capra Systems Theory and Eastern

30:32.620 --> 30:34.380
Vedic Philosophy and things like that.

30:34.380 --> 30:40.140
So there were people who were thinking about what is the world?

30:40.140 --> 30:41.260
How does the world work?

30:41.260 --> 30:46.140
How do we integrate across the various philosophic and scientific traditions?

30:46.140 --> 30:47.540
How do we improve civilization?

30:47.540 --> 30:50.500
Those were kind of like just the core thoughts.

30:50.500 --> 30:54.780
And so I didn't really have to get on that path.

30:54.780 --> 31:02.420
And then a big part of my study as a kid was not just studying various areas of philosophy

31:02.420 --> 31:06.020
or science or whatever, but also being actively engaged in activism.

31:06.020 --> 31:13.420
My mom was particularly into kind of hands-on activism with whether it was helping the local

31:13.420 --> 31:19.780
animal shelter or larger kind of factory farm animal rights issues or environmental issues.

31:19.780 --> 31:26.060
So being engaged in activism and then seeing what the problems in the world were and then

31:26.060 --> 31:30.380
similarly having a system science and kind of design science background to look at it

31:30.380 --> 31:32.700
and say, how are these problems interconnected?

31:32.700 --> 31:34.860
What do they have in common as generative dynamics?

31:34.860 --> 31:41.260
What would it take to address them more comprehensively because it's not that hard to see that whether

31:41.260 --> 31:45.020
we're talking about issues in healthcare or issues in war, issues in politics or issues

31:45.020 --> 31:49.740
in the environment, things like perverse economic incentive or one of the drivers of all of

31:49.740 --> 31:50.740
them.

31:50.740 --> 31:53.500
So it's like, well, how do we think through an economic system that doesn't have perverse

31:53.500 --> 31:54.500
incentive?

31:54.500 --> 31:58.860
Yeah, I would say it was working across many different areas of activism, seeing how they

31:58.860 --> 32:03.700
related to seeing why the solutions that we were working on weren't adequate because they

32:03.700 --> 32:07.820
didn't address the deeper dynamics.

32:07.820 --> 32:10.780
Those were kind of key early things for me.

32:10.780 --> 32:11.780
Thank you very much, Daniel.

32:11.780 --> 32:12.780
Yeah.

32:12.780 --> 32:13.780
Thank you.

32:13.780 --> 32:14.780
Thank you.

32:14.780 --> 32:15.780
Bye.

32:15.780 --> 32:16.780
Bye.

32:16.780 --> 32:17.780
Bye.

32:17.780 --> 32:18.780
Bye.

32:18.780 --> 32:19.780
Bye.

32:19.780 --> 32:20.780
Bye.

32:20.780 --> 32:21.780
Bye.

32:21.780 --> 32:22.780
Bye.

