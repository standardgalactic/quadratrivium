start	end	text
0	7740	Today we return to the wonderful desert landscape of Kwa. And we're gonna be
7740	15000	talking about an issue that is, well, in a way dominates the next several decades
15000	18840	in philosophy. Now at first glance you might think it's a very surprising thing.
18840	22160	What is this issue? It's often referred to as the problem of
22160	26800	quantifying it and dealing with the issues that arise from a quantified
26800	31920	load a lot from combining ideas about possibility and necessity or for that
31920	36760	matter various attitudes on belief and knowledge with quantifiable apparatus
36760	42320	that allows you to use terms like some and all. Now at first glance you might
42320	46840	think why is this significant? Why does this pose serious philosophical problems?
46840	53720	The answer is roughly this. There is a traditional way of looking at
53720	60080	metaphysics where you think about objects. As in Aristotle, for example,
60080	64600	there are substances, they have properties, they stand in relation, and some of the
64600	69400	properties of these substances are essential to them. They couldn't lose
69400	74840	them without altering what they are. Okay? Other properties are accidental. They
74840	80280	can change without affecting the identity of the object at all. So for example, what
80320	85200	are some accidental properties of me? They could change, I would still be me. Yeah.
85200	89840	Where you're standing? Where I'm standing, exactly. I'm standing here right now, but I
89840	95320	can move around, I'm still me. Okay? If I do this, you can't suddenly say, well, we
95320	100760	just keep getting a new professor in this class. Right? I'm still me. Other properties
100760	104880	that are accidental. What are you wearing? What I'm wearing, exactly. I could wear
104880	109320	different things, I'm still me. That I'm wearing this kind of sort of cream colored
109360	114280	shirt. That is an accidental property of mine. What are some other accidental
114280	123200	properties of mine? The color of your hair. Color of my hair? Yeah. I guess I could
123200	130240	do something about that. It used to be different, but I was the same person. In
130240	133960	fact, somebody recently saw me. I guess they hadn't seen me in a while. They said,
134520	140720	when did your hair turn like this? I don't know. Actually, I sort of do know. It all
140720	145720	happened rather suddenly. But anyway, that's something that is an accidental
145720	149920	property of mine. What about essential properties? These are properties that are
149920	153760	necessary to a thing. And in fact, Aristotle gives us three ways of thinking
153760	158600	about these properties that are necessary to a thing. One is just that. The
158600	164720	thing cannot lose them without stopping to be what it is. A second is that they
164720	170280	are the things by virtue of which the thing is what it is. We might say that
170280	174760	they are the nature of the thing. That's the way he sometimes refers to it. And
174760	178960	Aquinas later calls it the nature of the thing. It's what makes it what it is. And
178960	183080	then finally, we could think of it as something like the definition of the
183080	186880	thing or what corresponds in the thing to what would be a definition of it. Now,
186960	190480	could there be a definition of me? Aristotle talks about the question of
190480	193960	whether there could be a definition of Socrates, for example. But there could
193960	199600	certainly be a definition of a general kind. So we might think we could have a
199600	204400	definition of bachelor or a definition of human being even. And that these things
204400	208960	would express what is necessary to being a bachelor or a human being, what makes
208960	213520	somebody a bachelor or a human being, what would correspond in the thing, the
213520	217120	properties in the thing that would match the definition of those terms
217160	224360	bachelor and human being. So are there such essential properties? Well, from one
224360	228400	point of view, yes, in the Aristotelian tradition, in fact, not only are there
228400	231360	such properties, but they're crucial to understanding the nature of the world.
231560	235160	After all, the accidental properties aren't really very important in detailing
235160	240960	what a thing is, but the essential properties are. And so Aristotelian
240960	245160	essentialism is this doctrine that some of the properties of a thing are really
245160	250360	substantively identical to it, right? Not identical to it, essential to it. And
250440	255000	constitutive of its identity in some way. Now, there has been throughout the history
255000	259720	of philosophy some resistance to this idea. And so there are people, I think
259720	266120	John Walk would be a good example, at least in, well, in a certain respect, in
266160	271720	another respect, not at all. Maybe Hume is a good example of someone who is
271760	279160	doubtful about this idea of essentialism. Why do I say, well, Locke distinguishes
279160	283080	the real from the nominal essence of the thing. He does think things have a real
283080	289440	essence connected to the real internal constitution of the thing. But most of
289440	292920	the essences he thinks that are talked about in the Aristotelian tradition are
292920	297200	actually just nominal essences. They do correspond to something like the
297200	301000	definition. But the definition, you might say, is something that depends on our
301000	305200	categories, our way of understanding the thing. So understand me as a human
305200	309600	being and certain things will look essential to me. But we could also ask,
309600	313680	well, am I essentially a human being? Maybe, maybe not. And if I'm not
313720	317160	essentially a human being, then those properties that are essential to me
317160	322000	qua human being might not be essential to me, qua soul, let's say, or qua
322040	326200	something else. And so it depends how a thing is described, what is essential to
326200	331400	me. From this perspective, you might say, essence depends on the description of
331400	335080	the thing. It's something that we use to understand the thing, but it's not in
335080	340400	the thing itself. And so one way of framing this issue is, if we grant that
340400	344520	some properties have this status of being essential, either to a thing or to a
344520	349480	kind of thing, then is that something that really is about that object? Is it
349520	355000	really about that kind? Or is it something that we are supplying as part of our
355000	359120	conceptual framework for understanding that thing, that kind? It's really a
359120	365360	question of realism versus a kind of anti-realism about those essences. So
365520	369200	almost nobody is going to say, oh, just nothing's essential to anything, in the
369200	373040	sense that we never can talk about something being necessarily this or
373040	377120	that, or we can't really talk about definitions. It's a question of whether
377400	381160	that distinction is something that we find in the world among the properties of
381160	385040	the thing or the kind, or whether it's something that really is just our
385040	390320	creation. Now suppose you're a logical empiricist and you think, well, first of
390320	393240	all, you're going to be uncomfortable with this talk of necessity in the first
393240	398600	place, right? And we'll get some more of that in a moment. But whether or not
398600	402360	you're willing to talk about necessity at all, you're going to think, well, what
403080	408280	is necessity from a logical empiricist point of view? It's basically analytic
408280	412840	truth. It is coming from our verbal conventions. And so you're going to
412840	417280	think that, of course, to the extent that we can talk about essences at all,
417680	421080	they're things that are coming from our conceptual capacities. They're coming
421080	424680	from our linguistic framework. And so sure, we can have definitions of
424680	429000	terms, but that's not expressing some fundamental distinction between
429000	433600	properties in the thing. It's simply a function of the definitions of the
433600	438200	terms we're using. So it's all coming from us. From a more traditional
438200	441920	perspective, though, you might think, no, there really are things that are
441920	446280	essential to me and I couldn't lose without ceasing to be me. There are other
446280	451200	things that may be, well, certainly I can lose and still be me, like the color
451200	456640	of my hair or the color of my shirt or where I'm standing. Now, if we start
456640	460880	asking, well, what are the kinds of things that are essential to me? It's
460880	464440	much harder, right? Easy to list accidental properties. But if I say
464440	468920	suddenly, well, one is essential to me, then that's a really hard question to
468920	470280	answer. Yeah.
470520	472760	Do these essential properties actually need to you?
473920	479240	Well, not all of them certainly, right? There could be some things that are
479240	484920	essential to me. For example, you might say, I've got an idea. Self-identity is
484920	490280	essential. You are necessarily you. Okay? So Dan Bonovac is necessarily Dan
490280	495720	Bonovac. Now, that seems pretty safe. And also a good example of something that
495720	499480	seems analytic, right? It's not something that really expresses something you might
499480	504240	think about the nature of me, but about the way we use identity. And certainly,
504240	507480	it's not unique. Every object would have that property and have that property
507480	512440	essentially. So not all of these are going to really be unique to me. On the
512440	516880	other hand, you might have the idea that what makes me differ from anyone else is
516880	520840	that if you take the collection of these essential properties, there's something
520840	525080	that's unique to me about that collection. So individually, they might not be
525080	530040	unique, but that combination might be. On the other hand, maybe not. So have you
530040	536240	ever seen a movie multiplicity? The guy gets cloned and then the clones start
536240	541440	cloning themselves and it all gets sort of outrageously outhand. But anyway,
541440	549360	suppose we did have a cloning mechanism so that there were just a bunch of
549360	554080	duplicates of me. Would those be me? Would we not say, oh, Dan Bonovac used to be a
554080	557720	particular, but now he's a general kind and there are a bunch of them. He's
557720	562320	multiply instantiated. Or would there be something that distinguishes me from them?
562360	566400	Something about my origin, maybe, the way in which I came to be. They came to be
566400	570240	in a very different way by means of the cloning machine. Or maybe it's a
570240	574120	transporter malfunction in Star Trek. You know, you get in the transporter and
574120	578560	actually we don't send your particles down. We just rebuild you on the other
578560	582640	side and kill you here. It's a really disturbing view of the transporter system,
582640	585880	but suppose you have that view. And then suppose it malfunctions so that we don't
585880	588920	kill you here. So you're still on the ship. But also now there's a clone of you
588960	592640	running around on the planet. And then the clone comes back and what that means is
592640	595600	now there's a second one of you on the ship and that guy's still stuck down
595600	600840	there and they all claim to be you. Well, I don't know what to say about such cases.
600840	605920	So it's not clear to me now whether we have three of you or whether, no, you're
605920	609200	still you. There's something essential to you about the way in which you were
609200	614600	created. These are copies of you, but they're not you. Just as if you produce a
614600	618320	copy of a file on a computer. You've got a copy of the file. You don't have that
618360	626040	same file. In any event, however that may be, does this whole idea of an essence of
626040	632240	the thing make any sense? Well, I've already mentioned one reason why is a
632240	636960	logical empiricist. You might think it doesn't. But there are other reasons you
636960	642640	might think it doesn't. And they are more general. After all, Klein is not a logical
642640	646320	empiricist. He's attacked the analytic synthetic distinction. He's attacked the
646320	649640	identity of truth by convention. So you might think he's the kind of guy that's
649640	653200	actually going to be very friendly toward this idea of essential problems,
653200	660440	really beating the world. But not true. And why not? Well, really, let's go back and
660440	672280	think about the essential major of empiricism. What is an empiricist? An
672280	680240	empiricist thinks that, oh, knowledge comes from what? Well, well, analytic
680240	683800	and synthetic truth, but fundamentally experience, right? And then, yeah, there
683800	687800	are these things that are really, well, knowledge of a sort, but really, in the
687800	690840	end, knowledge of linguistic conventions or something like that, you might
690840	696000	think. But all of our knowledge of the world comes from experience. Now, if
696000	699680	you're quite, you're not actually going to single out some of these analytic
699920	703760	judgments or conventional judgments or something like that as an exception. In
703760	707200	the end, it's all really about the world. And so it's all coming from
707200	713520	experience. It's all judged by the tribunal of experience. So in the end, it
713520	718640	all comes down to experience. But now, there are going to be things that are
718640	723000	hard to explain in connection with experience. So think about the kinds of
723000	727200	things that you as trouble accounting for, for example. Okay, we can talk about
727240	731760	the color of my shirt. But now, there are going to be other properties of me,
731760	737800	dispositional properties of me that you might think are not so evident. What do
737800	746000	we say about dispositional properties? What are some examples of dispositional
746000	749880	properties? You can't directly observe them. They have to do with the way I
749880	755040	would behave in certain circumstances. But those circumstances might actually
755040	762000	never come about. Like the match, let's say. We say it's not soluble, even though
762000	765280	it's never placed in water. It's a we never really have the experience of
765280	770080	finding out. Similarly, the salt in my salt shake. I say it is soluble, but
770080	773320	actually, it might never encounter water. And so we might never find out.
773320	777120	Look at your temper. Sorry. Would your temper be one?
777120	781200	Okay, good. My temper. Am I somebody who is a rassable, easy to anger? Or am I
781200	788400	somebody who's gentle, mellow, difficult to anger? Well, I think I don't know. Not
788400	793440	much happens in the average analytic tradition course to really upset me. And
793440	796880	so you might think this is like the match that's never been placed in water,
796880	801440	right? I mean, nothing's ever happened in your in your experience to really test
801440	807080	whether I'm easy to anger or not. And the same thing is true with respect to you
807080	811000	given my experience, right? Are you easy to anger or not? I don't have any
811000	814640	experience that's relevant to that. I mean, you might be the sort of person who
814640	821240	flies off the handle. What, analytic judgments? No. And you know, analytic
821240	823760	philosophy does that to some people. There's the famous story about
823760	828040	Wittgenstein threatening copper with the poker. But wordarily, you might think,
828040	832440	yeah, it doesn't really come up in the context of this sort of course. So we
832480	836160	don't find out. And maybe I never find out that about them. Yeah.
836160	842640	We're saying that these dispositional probabilities are like essential things.
842640	845840	Oh, no, no, no. I'm not saying anything about them being essential. I'm just
845840	849240	thinking, yeah, well, I should make it clear what I'm saying here. What are
849240	856880	potential trouble for an empiricist? Things where we say, gosh, what
856880	862320	experience could that be based on? Right? Now, maybe I do have experience.
862320	865280	There might be some people who see you get angry and they have a sense you're
865280	870080	either easy to anger or hard to anger. But maybe we never encounter that,
870080	873680	right? You just go through life and it's all pretty good. Go through life. It's
873680	880880	like, you know, all right, there's this story about a kid who, you know, never
880880	886320	spoke. Parents took him to all sorts of specialists, had him examined. He seemed
886320	891440	normal in all other ways, but just never said a word. Well, finally they gave up,
891440	895120	right? They take him to this specialist, that specialist, do all sorts of brain
895120	899040	scans and so on. He seems absolutely normal, seems to be intelligent. Nobody
899040	903280	can figure out why this child does not speak. So eventually they just kind of
903280	908200	give up. And then one morning, the kid's sitting down before going to school for
908200	913760	breakfast. Mom gives him this piece of toast. Kid suddenly looks at it and says,
913760	918720	this toast is burnt. Well, suddenly she and her husband, they're all like, you
918720	922960	spoke, you spoke, they're so happy, right? And the kid said, well, of course I
922960	928480	can speak. Why haven't you said anything up to now? It's been 12 years. Kid said,
928480	934320	well, it's all been okay up to now. Okay, so it might be that the kid goes through
934320	937600	life the whole way, right? I mean, we never find out whether this person is
937600	941760	easy to anger because just nothing ever happens to upset them. Yeah, why would
941920	945680	that really be a problem? Because we don't have the knowledge then. So, I mean, you
945680	950000	don't have to justify it with empiricism if you don't know it. Okay, good. You might just say,
950000	954720	well, then we don't know, right? Whether this person is erasable or gentle or what
954720	959520	have you. And so that's fine. It's fine to have things we do not know. But now you
959520	963600	might think, well, here's the problem. Remember, we were talking about this in
963600	968640	Karnap, where Karnap was trying to define terms like soluble in terms that were
968640	972400	strictly observational. And he probably couldn't do it with a regular conditional.
972400	977280	He needed something like a counterfactual conditional. So it had to be something like
978080	988000	if blah, blah, blah were to happen, right? Then blah, blah, blah would happen.
992320	997440	And now the problem is that were to and that would. It seems to refer to things that
997440	1004240	actually, well, aren't part of this world. The way philosophers now, following Leibniz,
1004240	1009360	said to think about this, it's talking about other possible worlds. If you were to be placed
1009360	1014080	in this kind of situation, right, but maybe you never are, then this would happen. And so it's
1014080	1018560	not just that we don't happen to know. It feels like the kind of thing that actually
1018560	1023360	it would be hard to explain our possession of such a property. What could it even mean
1023360	1029520	to attribute such a property on empiricist grounds? Because you might think, gosh, it's not
1029520	1033920	just that to notice I'd have to somehow have contact with these other possible worlds. The
1033920	1038240	very definition of what it is that such a property seems to refer to these other worlds.
1038800	1047840	And so there's something strange about that. Yeah. I mean, you could just arrive at that knowledge
1047840	1056000	inductively and say salt dissolves when placed in water, right? I don't really, I remember
1056000	1059520	talking about this before, but not that we'll be visiting it like this. I don't really see why
1059520	1064320	you need counterfactuals. Good, good. Well, you might think, look, I don't really need
1066080	1071200	any mysterious knowledge here. Here's how I do it. I have inductive evidence about this rule,
1071200	1078560	right? And on the basis of that inductive evidence, I conclude certain generalizations.
1078560	1084400	And some of those I actually consider laws. Now, some of these generalizations I consider
1084400	1092880	accidental. It just so happens that this takes place. I can't infer it to have any really
1092880	1097680	lawline character. It's just been a matter of chance that it's worked out that way. However,
1097680	1101520	some of these other things might seem to me to reflect some deeper pattern.
1101520	1107440	And so I think that's a law. Now, what's involved in my going from the generalization
1107440	1114480	that G puts salt in water and it dissolves to the law, put it in water, it must dissolve?
1114480	1119680	Where does the must come from? Where does the necessity come from? And you might say,
1120240	1126080	look, it's just if we have enough inductive evidence, right? We do this in the United States.
1126080	1130480	We do it in Europe. We do it in Africa. We do it in India. We do it in China. We do it in Russia.
1130480	1134320	And gee, no matter where we go, no matter when it is, it seems to all be the same.
1134320	1138640	And we start thinking, this isn't just an accident. This is really lawlike.
1138640	1144000	And so one way of looking at this is to say, we start attributing something like necessity,
1144000	1149760	like the must, like calling that a law, when the inductive evidence is just very broad,
1149760	1157120	very powerful, seems very, what, have a huge scope in space and time and so on.
1160640	1165600	Which is, by the way, why it would be so hard to come up with equivalent laws in the social sciences,
1165600	1169760	because you might think it's very hard to have that kind of fraud, inductive evidence.
1169760	1173840	Maybe in psychology, you can do it because you can observe lots of people in lots of cultures
1173840	1178000	and so forth. But if you're thinking about political science, you might think, gosh,
1178000	1185120	where's the science? Because here we call that a department of government, right?
1185120	1188560	We don't claim it to be a science. But you might think, the problem is really,
1188560	1193440	we can't get enough inductive evidence. I mean, how many countries are there in the world now?
1193440	1199760	That's quite few, but not in comparison to grains of salt, for example. And what kinds of experience
1199760	1206720	have we had, let's say, with revolutions? Well, some, but not equivalent to putting salt in water
1206720	1210960	and finding out what happens. And so, you might think there, the inductive evidence is just
1210960	1215600	sparse enough, very hard to make that move. Anyway, I don't have any real objection to that.
1217600	1223920	In fact, I think that's the way Locke thinks all of this goes. It's Hume, who after all says,
1223920	1228080	wait a minute, look at what's happening in these cases. We observe this happening,
1228080	1233120	we observe that happening, we never see the causal connection. We never actually observe the link.
1234080	1239280	Yeah. I don't really see how this inductive evidence would work. Like, if someone were to
1239280	1243760	tell me that salt doesn't dissolve in oil, I wouldn't necessarily have to do the experiment over and
1243760	1249440	over again to understand that for certain, but I could still believe it conceptually. So, I feel
1249440	1253120	like inductive evidence isn't necessarily the only way to get some kind of dispositional property or
1253120	1268240	something. Right. Well, here's the problem. Sometimes you're right. We do take one counter
1268240	1275120	instances enough to establish either a connection or the lack of a connection. But I'm thinking of
1275120	1282880	cases like the cold fusion experiments. People claim to have discovered cold fusion. And then,
1283200	1288880	for at least a decade, there was a huge attempt to try to replicate those experiments to figure
1288880	1294320	out whether there really was a principle underlying this and there was really a technology that would
1294320	1299920	enable cold fusion or whether this was due to some, the results they got were due to some kind of weird
1300720	1306400	phenomenon in their lab. And for a long time, it was unsettled what it was. I think now most
1306400	1311120	people dismiss the possibility, though I think there are still some authors who think that
1311920	1319280	there may still be something there that one could do. But many of them, from one experiment,
1319280	1323360	people thought, oh, that's intriguing. It made them want to do more experiments. But people
1323360	1328000	didn't immediately say, we've got the technology in the future. Let's start building cold fusion,
1328000	1334320	power plants, and so forth. They felt the need to do more experimentation. So, I think in some
1334400	1341760	contexts, especially when something refutes along, then it's very powerful. We say, wait a minute,
1341760	1348480	this is going to happen. We put the salt in the oil and then what happens when we put the salt in
1348480	1353680	the oil? We've never done it before. We're doing it for the first time. And we might say, aha,
1353680	1359120	this is what happened. It did dissolve, so salt does dissolve oil or it didn't dissolve. But
1359120	1365600	the evidence for that is rather thin until we repeat it. And if it's the kind of thing that we
1365600	1372960	can't repeat, then it's hard to know what to do, which is, again, part of the reason why it's a
1372960	1377200	political science. It would be so difficult to come up with something law-like. You can't start
1377200	1382800	saying, whoa, what if that would happen again? Let's hold the last presidential race over again
1382800	1387360	and see if Trump still wins under these conditions or something. Yeah, can't do that.
1388240	1398400	And so, in short, it's the kind of thing that, well, yeah, it's going to depend a lot on how
1398400	1402880	this fits in with the rest of our knowledge. And so, quiet at least will say, yeah, you're right,
1402880	1408800	this is how it goes. But a lot of that is driven by where this is in the web, how close we are to
1408800	1413680	experience, how much other theoretical support there is and so forth. Anyway, we're getting sort
1413680	1417680	of off track because I don't want to spend a huge amount of time thinking about how we can
1417680	1423920	account for dispositional properties, except to say that there's a sense in which essential
1423920	1432000	properties raise the same kinds of questions. I was hoping here to be referring to something we all
1432000	1441200	agree about, but oh well. Anyway, essential properties are kind of the same. Why? Because we
1441200	1452480	think, well, yeah, I'm saying here, gosh, if the object were right to lack the property,
1452560	1468400	it wouldn't be what it is. And that's similarly modal, right? It's similarly talking about what
1468400	1475680	would be the case. And maybe I never, in fact, lack the property. And so, you know, for example,
1475680	1481760	would I still be me if I were bald? Well, let's suppose I just never go bald. And then you might
1481760	1487600	say, well, gosh, we never find out. Now, in fact, we think, oh, come on, it's still me himself
1487600	1494240	to be bald. And so, we think we know something about that. And yet, it looks like, in a sense,
1495440	1500880	what we're knowing here goes similarly beyond experience directly. So, if you're in the school
1500880	1505360	of lock as an empiricist, you're going to say, well, we reach inductive conclusions about this,
1505360	1511040	just as we do about these scientific laws, just as we do dispositional properties. If you're more
1511040	1515760	humian, you're going to see a deeper problem here. And think that the very idea takes you
1515760	1524640	beyond the bounds of experience in a way that makes you uncomfortable. So, why did I stand on that?
1526160	1530000	I don't know. It was really just to make the point that there is kind of this distinction
1530000	1534560	between the lockians and the humians here, and that there's a sort of parallel problem here.
1534560	1538960	So, just as Karnab worried a lot about this, and a lot of people start writing about
1538960	1542720	counterfactual conditionals, and how to understand them, and what the nature of laws is, and so
1542720	1550160	forth. So, similarly, we have an analogous problem with essential properties. Now, we can characterize
1550160	1556640	certain contexts in language and in thought as referentially transparent, and others as
1556640	1561840	referentially opaque. And that's an important distinction for Karnab. So, here's the general
1561840	1571200	idea. We've got this notion of identity. Okay? And there, or just expressed by is in English.
1572080	1579280	And ordinarily, it allows us to substitute. So, typically, we can substitute identicals
1579840	1597280	for identities. So, here's an example. Two plus two is four. Four plus four is eight.
1598400	1602880	Well, I should be able to substitute two plus two for four in that equation to get two plus two
1603440	1612640	plus two plus two is eight. And that, that seems right, right? That works out just fine.
1612640	1619280	And so ordinarily, this is a legitimate rule. Leibniz's law in general says that things are
1619280	1623440	identical. If they have exactly the same properties, and if they have exactly the same properties,
1623440	1628080	you should be able to substitute one for the other. And typically, we can do that. If Dan
1628080	1632400	Bonobak is talking, and Dan Bonobak is the professor, then the professor is talking, etc.
1633520	1640960	But now, there are some contexts where that prevails. So, we'll say that a context is transparent.
1645120	1651040	If that works, that is to say, if substituting identicals for identicals always preserves
1651040	1661360	truth value. So, it turns true sentences into true sentences, and false sentences and false
1661360	1675440	sentences. And opaque, if it sometimes fails, which means it doesn't always preserve truth value.
1675440	1683920	So, Quine is worried about these opaque contexts, where we've got some situations where substitution
1683920	1690400	doesn't always work. Here's one of his examples. Basically, well, yeah, we can say things that
1690400	1703600	involve quotation, either directly or indirectly. So, yeah, here's one of these examples. Cicero,
1704320	1715920	a name, right, contains six letters. This fall, by the way, there's going to be a
1715920	1721840	course on Cicero and Catullus in the classics. So, you should all take it. It would help with your new lab.
1725440	1731920	Yeah, well, I'm very fond of both of them. So, now, Cicero, what is his actual name?
1732640	1740400	Well, it's Marcus Tullius Cicero. And so, he's sometimes called Tully as a nickname. So, Cicero
1740400	1748240	is Tully. But then we might think, ah, so we can substitute. Tully contains six letters.
1751120	1757840	Well, that obviously fails, right? We don't preserve truth by that kind of substitution. We
1757840	1762400	can substitute in direct notation. And that's sort of a surprise, really, because after all,
1762400	1768080	this is about the name, Cicero, and not about the person. And so, the identity of the person here
1768080	1773840	doesn't mean that the names are going to share the properties. So, it's easy to explain why that fails.
1773840	1781040	Now, this can also be indirect. So, for example, he gives us this case. Georgione is called Barbarelli.
1781040	1786800	Sorry, Georgione is Barbarelli. Georgione Barbarelli was the first of the great painters of the
1786800	1791360	Italian Renaissance. And in particular, he's thought to have painted a painting called The Three
1791360	1797680	Philosophers, which is perhaps why Klein knows about it. Sort of a mysterious character. He died
1797680	1804480	when he was around 30 of the play, and only painted a few paintings. So, little is known about him.
1805120	1810800	But anyway, here's a quite example. Georgione was so-called because of his size. Big guy.
1811360	1817360	Okay? Barbarelli was so-called because of his size. Well, that's not right.
1818320	1823840	Okay? So, so-called here is something that sort of sneaks in a reference to the name. And so,
1823840	1828000	it's kind of an indirect, well, not literally, an indirect quotation. But nevertheless,
1828000	1833840	it's something like a quotation context. It sneaks it in. So, there are those kinds of cases.
1834560	1840080	But there are much more interesting kinds of cases. So, in particular, necessity
1842080	1846560	is one of these. One way of thinking about an essential property is that it's necessary to the
1846560	1851520	thing, or to the kind of thing. But now we can think, well, wait a minute, necessity is weird
1851520	1856240	because it's opaque in this way. So, here's an example that might show that.
1857200	1860720	The number of planets
1865440	1866000	is 9.
1869280	1870160	Necessarily,
1874000	1883520	9 is greater than 7. Therefore, necessarily, the number of planets
1886400	1891360	is greater than 7. Now, does that work?
1895680	1896960	No. What's gone wrong?
1906160	1908880	There's no necessity that there'd be more than 7 planets.
1908880	1911920	Exactly. There's no necessity that there'd be more than 7 planets.
1912640	1916880	I think there could have been 6 planets. I mean, a little while ago,
1916880	1920800	they demoted Pluto for being a planet. Now, again, they promoted Pluto back up again.
1920800	1925280	So, there are 9 planets again. Yay! Go ahead, because it makes it easier to teach quine here.
1926880	1931600	But, actually, somebody said, well, wait a minute, I'm not sure. The Earth is a planet.
1932320	1935200	And you might think, oh, wait, we're going to change the definition of planets. So,
1935200	1938720	even the Earth isn't a planet. Maybe it will turn out that only, I don't know,
1939280	1942720	would satisfy their new definition of planets. Those people got their way.
1943280	1947520	But there might be way fewer than 7 planets by that criterion. In any case, you might think,
1947520	1952400	yeah, look, it's highly contingent whether or not there are more than 7 planets. That's not a
1952400	1958720	necessary truth. But this surely is a necessary truth. 9 is greater than 7. That seems necessary.
1958720	1963760	Something that follows from the laws of arithmetic. And the number of planets is 9.
1963760	1968560	So, why can't we do this substitution? Well, here's what quine ends up concluding.
1970960	1977920	Is this property, so you can frame it this way, is the property of being
1980000	1993440	necessarily greater than 7? Well, maybe I don't want to. We could just say, is that true?
1994080	2004880	Let's say, is the property of being greater than 7 necessary to 9, the object 9?
2006960	2010800	Now, one way of looking at it, if you're a realist, you think you can answer the question. If you're
2010800	2015200	a realist, the amount is essences, right? Because then you think, yes, the essence is in the object.
2015760	2018960	And so, what is the realist going to say about this question?
2019920	2023200	Is the property of being greater than 7 necessary to 9?
2026560	2034480	Yeah, sure it is. Because 9 is necessarily greater than 7. You couldn't make it less than 7,
2034480	2042240	for example, or equal to 7 without changing what 9 is. But suppose we're one of these anti-realists.
2044880	2046480	Then how are you going to answer that question?
2049920	2058960	It depends how you designate it, right? If you call it, if you're thinking of 9 as 9,
2058960	2062800	then yes, it's necessarily greater than 7. It has that property unnecessarily.
2063520	2066960	But suppose you're thinking of it as the number of planets, then it doesn't.
2067600	2076480	9 quad, 9, you might think, necessarily has that property. But the number of planets,
2076480	2084720	9 quad, the number of planets does not. And so, it sort of depends on how it's described.
2092240	2097200	And that's in the end client's position. It depends how it's described. So we can talk
2097200	2105360	about things having essences, but only as, when described as such and such. 9 described as that
2105360	2110080	number. We're already sort of describing it in terms of its position in the number sequence.
2110080	2115040	And so, yes, it's necessarily greater than 7, but 9 described as the number of planets. No,
2115040	2120240	that's not necessarily greater than 7. 9, just without any description, he says,
2121120	2124480	I don't think I could make any sense of the idea. Yeah.
2124480	2128640	Well, why is 9 described as the number of planets not necessarily greater than 7?
2129440	2131360	Because there could have been fewer than 7 planets.
2131360	2131920	But there aren't.
2132560	2135520	There aren't. Yeah, there aren't.
2136400	2140880	That's why I'm confused. Like, there could have been, but if there would have been,
2140880	2144960	then it just wouldn't have been 9 in the first place. It would be different. So it wouldn't
2144960	2145760	necessarily, you know.
2145760	2149920	Yeah, yeah, yeah. Okay, good. You might think the number of planets, wait a minute,
2151280	2155680	I'm not sure what to do with that when I start thinking about other possible circumstances.
2155680	2160400	After all, you say that could have been fewer than 9 planets. Well, we're now talking about some
2160400	2168000	other possible world, right? And so, what about one of these worlds where there are now fewer
2168000	2178080	than, here's the sun, and here's Mercury, let's say, and here's Venus, and the big bang worked
2178080	2182240	out a little differently in this world. So all the other planets flew off in this space,
2182240	2186560	and there are only those two remaining. Okay. So in this world, there are two planets.
2187280	2191040	Now, what does the number of planets refer to in that world?
2192240	2199040	Two. Okay. One wavelength. Yeah, look, the number of planets here is just two.
2200240	2206320	But then it looks like the number of planets is 9 in this world, 2 in that world, so it's not
2206320	2211120	necessarily greater than 7. On the other hand, you might think, wait a minute, no, when I said the
2211120	2215520	number of planets is 9, I mean the number of planets in this world. And so I don't mean the
2215520	2222960	number of planets, let's call the actual world here w, in this world, w prime, let's say, then
2222960	2230000	really I have to distinguish the number of planets in w prime from the number of planets
2232240	2238560	in w. And the number of planets in w is still 9, right? Because it is what it is. It doesn't
2238560	2242880	matter what world you're viewing it from, in that world, in our world, the number of planets is
2242880	2248080	9. And so you might think, wait a minute, when I say the number of planets, do I mean that to
2248080	2252000	vary with world? So, ooh, now the number of planets is this. Or do I mean the number of
2252000	2258080	planets there actually are? And that actually would be something that ties this to this world.
2258080	2264080	The actual number of planets? That sort of means that's not going to vary from world to world.
2264880	2269760	But if I don't sort of pin it down with actually, then it looks like it could vary.
2270720	2275200	On the other hand, people don't ordinarily go around, unless they're teaching seminars on
2275200	2281600	motor logic, they don't go around using the term actually much in that way. And so often,
2281600	2286880	if we just say the number of planets, the number of students in the class, etc., etc., we mean the
2286880	2291520	actual number. We're not talking about something that might vary. You know, I say the number of
2291520	2298560	students in the class is, what is it in this class? Like 25. And somebody says, well, what if a
2298560	2308400	bunch of people dropped? Well, yeah, then the number of planets would change. The number of
2308400	2313440	students that are in the class then would be different. On the other hand, the number of
2313440	2319920	students who were in the class now would remain the same. And so you might think that actually
2319920	2325920	there's a sort of hidden ambiguity here, which I think is part of this. You might think, look,
2326000	2330160	it depends on how it's described. And here's an additional way in which it depends.
2330160	2334480	Do I mean the number of planets that happen to be in a given world? Or do I mean the number
2334480	2338560	of planets that actually are in this world? And those would be, as it were, two different
2338560	2343520	descriptions. And that too would affect what we end up saying about this question.
2346400	2352560	Okay, well, that's one sort of problem. It's connected to a problem about quantification.
2352560	2358960	Because now if I say, so there is something
2362960	2364960	that is necessarily
2368560	2372160	greater than seven. How do I evaluate that?
2372400	2382400	Now, Quine doesn't have any problem with necessity applied to a sentence.
2382960	2388240	He doesn't have any problem with necessity on the outside of this, you might say. It's a necessary
2388240	2395680	truth that blah, blah, blah, blah, blah, blah. He worries about the necessity being inside.
2395680	2401040	Okay, there is something that is necessarily greater than seven, that has been greater than seven
2401040	2407440	as an essential property of it. And why does he worry about that? Because this something
2408880	2414800	isn't described as being of any particular kind. And if it really does depend on how it's described,
2414800	2419760	then it doesn't make any sense to talk about whether the object itself is necessarily greater
2419760	2426400	than seven or not. What makes sense is to say the number of planets is not necessarily greater
2426400	2431520	than seven, but nine is necessarily greater than seven. And yet we're talking about the same object,
2431520	2437760	so it depends on the description. And so he's worried that things like this don't fully make sense.
2439440	2445040	Now, the same sort of thing can happen with respect to attitudes. And that's what the paper
2445040	2451600	quantifiers in propositional attitudes is about. This begins, by the way, with one of my favorite
2451600	2458960	passages of analytic philosophy. The incorrectness of rendering Tessius is hunting unicorns. In the
2458960	2464960	fashion that there is an X, such that X is a unicorn and Tessius is hunting X, is conveniently
2464960	2470080	attested by the non-existence of unicorns. But it's not due simply to that zoological Kunah.
2470720	2474880	It would be equally incorrect to render Ernest's hunting lions as there is an X such that X is
2474880	2480720	a lion. And Ernest is hunting X, where Ernest is a sportsman in Africa. The force of one is
2480720	2484640	rather that there is some individual lion or several, which Ernest is hunting, stray circus
2484640	2491680	property, for example. The contrast recurs in I want a sloop. The version, there is an X such
2491680	2497120	that X is a sloop, and I want X. It's suitable insofar only as there may be said to be a certain
2497120	2503600	sloop that I want. If what I seek is mere relief from slooplessness, then do guess the wrong idea.
2504560	2508560	Okay, now this is something that actually linguists have worried a lot about. What do you do about
2508560	2513040	cases like hunting a unicorn or hunting a lion or wanting a sloop and so forth?
2514720	2518480	And then he kind of leaves that problem behind, but it's an interesting problem.
2518480	2525920	Anyway, that's one difficulty where we want to say, wait, hunting, actually, yeah, I should
2525920	2533040	sort of put in here. We've got this additional thing now of attitudes. Hunting is something
2533040	2544240	that does involve some kind of attitude. Hunting, searching for wanting.
2547600	2555520	But there are others. So here is a wonderful story. Consider the difference between there is an X
2555520	2561200	such that Ralph believes that X is a spy and Ralph believes that there is an X such that X is a spy.
2561920	2566800	They're two very different states, right? They may be ambiguously phrased as Ralph believes that
2566800	2571760	someone's a spy, but they may be unambiguously phrased respectively as there's someone who Ralph
2571760	2577040	believes to be a spy, and Ralph believes there are spies. The difference is vast. If Ralph is like
2577040	2581840	most of us, aid is true, that is to say, he does believe there are spies, but there's no particular
2581840	2590160	person of whom he believes that that person is a spy. Well, here is the marvelous story.
2591200	2595280	There's a certain man in a brown hat whom Ralph has glimpsed several times under questionable
2595280	2600560	circumstances on which we need not enter here. Suffice it to say that Ralph suspects he's a spy.
2600560	2605360	Also, there's a gray-haired man vaguely known as Ralph as rather a pillar of the community whom
2605360	2610000	Ralph is not aware of having seen except once at the beach. Now, Ralph does not know it, but the
2610000	2615440	men are one and the same. Can we say of this man, Bernard J. Orcutt, to give him a name,
2616000	2622880	that Ralph believes him to be a spy? If so, we find ourselves accepting a conjunction of this type.
2622880	2629120	W sincerely denies blah-blah-blah and yet believes that blah-blah-blah. With one and the same sentence
2629120	2633920	in both of these planks, for Ralph is ready enough to say in all sincerity Bernard J. Orcutt
2633920	2638160	is no spy. He's that upstanding member of the community, right? If on the other hand, with a
2638160	2643840	view to disallowing these situations, we say Ralph believes the man in the brown hat is a spy,
2643840	2648320	Ralph doesn't believe the man seen at the beach is a spy. But wait a minute, the man in the brown
2648320	2654400	hat is the man at the beach. Now, what do we say about Ralph's beliefs? So here the problem is,
2654400	2662080	well, in general about belief, but also specifically about this. Does Ralph have a belief for Ralph
2662080	2684480	Bernard J? Well, here's Ralph. He believes the man in the brown hat is a spy, but Ralph doesn't believe
2685280	2702880	that the man at the beach is a spy. In fact, he would outright deny it, but those two are identical,
2703680	2709680	right? They're both Bernard J. Orcutt. So does Ralph believe that Orcutt is a spy or not?
2710400	2715360	Well, under one description, the man in the brown hat, yes. Under the other description,
2715360	2721680	the man at the beach, no. And so it's very tempting here to say that actually belief
2721680	2726560	is not something you have about an object, it's something you have about an object under a certain
2726560	2736560	description.
