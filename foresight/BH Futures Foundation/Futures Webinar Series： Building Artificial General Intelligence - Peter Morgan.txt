Okay, good evening everyone and welcome to Future's webinar series by BH Future's Foundation.
I am Ivana Yevtovich, webinar coordinator.
Tonight we will hear about artificial intelligence, the development of artificial general intelligence
is going to require algorithms that can do things like inductive reasoning, planning and optimal
learning from limited amounts of data. Several efforts are underway to develop these technologies
for deployment in future systems. We are currently witnessing these new approaches being given more
and more attention as we enter the new and perhaps golden age of artificial general intelligence.
In this talk we will present some of the newer more general approaches to solving intelligence
that are really currently under development with the view to deployment in the intelligence system
of the future. Tonight's speaker is our guest Peter Morgan. Peter is author of the popular report
Machine Learning is changing the rules, ways businesses can utilize artificial intelligence
to innovate. Published by O'Reilly, he's passionate about artificial intelligence and the positive
changes in this technology can and is bringing to society. Peter founded the artificial intelligence
consult company, Deep Learning Partnership to carry out his mission of helping to bring artificial
intelligence to the world. He advises and mentors technology startups and is a speaker at artificial
intelligence conferences and meetups. Peter founded the popular London Deep Learning Lab
Meetup. Links for the mentioned companies are listed down below so you can check it out.
Peter, it's an honor to have you here tonight and thank you so much for being with us.
Thanks Havana. Okay, so let's get started. So Havana just introduced me and there is a data
science conference on the 2nd of July at Croatia that I'll just put a little shout out now for.
So if you want to look out for that, tune in for that as well. Okay, so there's a little
book I wrote that Havana mentioned on a practical book on implementing machine learning in real
deployment for companies. That's what I do for living. I'm a consultant, machine learning consultant.
Today's talk is going to be a little more futuristic in that there are no actual deployments yet
but it's a look towards the future where we are now, where we want to get to and how we will get there.
So here's an outline of my talk. What is intelligence? Let's start off with the basic
question we're trying to solve and then look at how the world produces intelligent systems,
either biological or non-biological. We're trying to non-biological route here.
We are the biological, humans are the most intelligent thing that we know of in the
universe so far, although at times it doesn't seem like it, right? And I'll do a very quick recap
of deep learning and just to see if that's part of the journey or not, if it's a dead end or if
that's a step along the way to artificial general intelligence. And hopefully everybody's at that
kind of level, you've heard of deep learning, machine learning, that will probably help understand
the talk but even if you don't it, it doesn't really matter. This is a fairly general talk high
level. And then we'll look at AGI or artificial general intelligence and we'll see maybe how we
might build such a system or if it's possible and then if it is how we might build it and we'll
wrap up. So my talk will be about 40 minutes long and so let's get into it. So I mean why do we even
want to build general intelligence? Well the idea is, and you may have heard DeepMind say that,
it's a company based here in London under the Google umbrella these days, because then we'll
build intelligence and use it to solve everything else, right? That's the big goal, that's the vision.
So at the moment, like I say, we're the most intelligent things around so we're solving
all scientific problems, medicine, climate change, just every problem right now, humans are tackling it
as we have been doing from the beginning of time. So it's a big vision, right, is to build systems
that can basically supersede us and accelerate science. Isn't that an amazing goal, right?
Isn't that an amazing achievement if we could do that? Clearly, it's worth a lot of money so
everyone's working on it, Microsoft, Google, a lot of bunch of startups. So let's see where we are on
that journey. Okay, now first thing I'll mention is that people do get a little bit worried, oh my
god, what happens when, you know, we're no longer the most intelligent things. That's a rather
philosophical question and there's a lot of debate and books been written about that. It's a very hot
topic at the moment. It comes under the umbrella of AI safety and so if you want to look into that,
you know, I encourage you to do that, but we'll focus on the engineering and this talk and the
science. Okay, we'll leave the philosophical problems to the philosophers, I'm afraid,
or that that's a topic for another talk, which I could give too, but I won't on this one. So
again, you know, what is intelligence? Is it, you know, beating go? Is it, you know, winning
at Starcraft, you know, beating the best, go play at the best players in all of these games,
basically, go Starcraft, chess, Jeopardy. Well, as amazing achievements as all of those were,
like breathtaking, you know, when it happened at the moment, I remember, you know, watching
all of them actually and just, you know, put my breath away. But no, it's not actually general
intelligence. Those are examples of very narrow intelligence and pressure as they may be,
because the system, the clever system that beat Gary Gatt, Casper Robert, chess, it can't,
you know, beat Lisa Doll that go, it's essentially dumb outside of its very narrow domain,
in which it's superhuman intelligence. Okay, so they're not generally intelligent machine systems.
Okay, so they're all examples of narrow AI. So what is intelligence? Well,
Howard Gardner at Harvard, a couple of decades ago, you know, it seems so obvious now,
but at the time, you know, no one had kind of thought about this or written it down,
which I, you know, it's one of those things. But he did, and I like it because it sort of says
there's about nine different components to intelligence, right? So, you know, the go,
the chess, that's a logical mathematical component that's superhuman at the moment.
I mean, a calculator that we can buy for five bucks or whatever, you know, can do long multiplication,
you know, far faster than we can. Okay, so there's clearly superhuman in that domain.
But what about the others? Musical, nature, spatial, you know, robots maneuvering, navigating
through space, time, self-driving cars, that kind of thing. Intrapersonal, now these are the harder
ones, aren't they? The personal intelligence, social intelligence, and intro knowing ourselves,
and then enter knowing about others. Okay, so that those are probably, you know, the most
challenging thing. And the was that, you know, people say, you know, a lot of skeptics know,
will never have, you know, be able to build systems like that. Well, I'm going to argue,
there's nothing in physics, laws of physics that says we can't. And clearly, biology has done it,
right? And so that's, we're a physical system. There are people, and, you know, it's fine,
80% of the world believes in some religion, that's fine too. But I would argue that,
you know, once you get the right physical systems that, you know, they will be capable,
have the capacity of, you know, believing in higher powers and stuff like that too. So, you know,
there's all these philosophical questions come up as well. But they can be, you know, I will try to
reason to scientific questions, engineering questions. There's linguistic language,
natural language processing, translation, you know, Siri, Google translate, you know, these are
amazing systems, but they're not quite there yet. They're not quite superhuman. Go is, you know,
calculators are, but, you know, all of these are the types of intelligence we are working on. Okay,
we're not there yet. We're not human level intelligence, but we're certainly working on them.
You know, the bodily kinesthetic, you know, you watch, is it Atlas, the Boston Robotics,
Boston Dynamics, whatever they're called company, you know, doing flips now, you know,
like a gymnast. So we're making a lot of progress on many of the, on most, on all of them, actually.
And it's essentially, why are we here? You can imagine a robot sitting there going, hmm,
why am I here? You know, that's how we'll know we've got to learn intelligence, probably.
And there's a nice beautiful picture of one right there. And so how far have we come?
I've covered all these, you know, we've got the calculation, but they're not creative. We have
to tell them what to do. These systems, they're not self aware. They don't have subjective
experience. So the existential down the bottom is zero. They don't ponder, you know, as far as I
know, my laptop's not wondering, you know, why it's here. Maybe, maybe it is. And just not telling
me, but I don't think so. Okay, so, um, so how will we get to AGI then? Well, it will take a village
to create, you know, it takes a village to create a child. The well known saying in psychology will
the same thing. It's going to take a village to create artificial general intelligence. And in that
village will basically comprise of computer scientists, physicists, neuroscientists, of course,
because we are the example and colleges, sociologists. So general intelligence is general,
right? We're trying to, you know, basically build human liberal intelligence and then suppress it.
So it's going to take, not just computer scientists set in sight of Google anymore, it's
going to take physicists and neuroscientists and psychologists. No doubt, you know, Microsoft,
Google, they have teams like this in place. Okay, so it's a little early, they don't talk about it,
but yeah, but people are working on this stuff right now. So we'll have a look at some of the
efforts and some of the history and some of the future of that, which is what this talks about.
Okay, so physical systems, what have we got? So we've got biological, you know, I can argue that
plants, bacteria, insects, mammals, us, we're all natures full of, you know, intelligent systems.
How many species are there? You know, absolutely millions. And, you know, locus is intelligent,
it's adapted to its environment. You know, it can overcome and reproduce. It doesn't really
make goals and accomplish them, though. It doesn't consciously do that. You know, mammals are the
only things that do that. And so there are various levels of intelligence, too. So we're trying to
build the human level intelligence, the mammalian intelligence. And, you know, perhaps we'll start
off with an ape intelligence and then, you know, progress to human level and then superhuman. So
that's where we are. And so what are we, what, physically, what do we have? We have CPUs,
processors, we have GPUs, FPGA, ASICs. And we also, those are all digital, examples of digital
processing systems, okay. And those of you who have done a computer science degree or
electrical engineering degree, you'll be familiar with all of those. And then we have
something called neuromorphic, which is, which processes based on biology, okay. And those are
very interesting. Those exist today. And they're quite large as well. We're up to about a billion
neurons, okay, artificial neurons. And that's like a mouse. So we could argue we have mouse level
intelligence today. And we'll see a little bit of that later on. And so that's exciting. Digital,
it's always going to be an emulation neuromorphic, it's going to be more of a direct simulation,
okay. So there's the difference between an emulation, which is something that you run on
a digital processor and an emulation, which is an actual physical or simulation rather,
which is an actual simulation of the actual physical system, which is the brain. So neuromorphic,
we can do simulations, we can run it on real time, just like the brain or artificial neurons,
all the rest, emulations on digital processors, which actually takes a lot more energy and time.
It's, it's not, you know, we can get there, but it's, it's just, it's not a direct way of getting
there, whereas neuromorphic is. And then we have quantum. Is there any, is quantum
processors, you've all, we've all heard of quantum computing nowadays is catching the news.
Is that a part of the journey or not? We don't know, maybe the brain uses quantum physics
at the level of microtubules. Roger Penrose would argue it does,
who's to argue with him, he's very clever physicist there in Oxford. But, you know,
the fact is, you know, we don't know. Okay, so we'll look at it, we'll look a little bit
deeper into all of those and then we'll wrap up at the end and I'll tell you where we are today.
So biology is what I mentioned from the lowest little, you know, single celled amoeba to the,
you know, C. elegans, that little worm there with 137 neurons. We can count them. We built
that system actually. So we can actually, we built that little guy there. B, we haven't built.
That's got about a million neurons and that tiny little brain there. It's a little nervous
system, central nervous system. And then the human brain, that's a hundred billion neurons that,
you know, that's clearly a tough one to crack. That's what we're trying to go.
So a little bit of the big picture, you know, the brain is a system at what level do we attack this
on? Do we attack it at the level of atoms and molecules like, you know, Roger Penrose is doing,
that's where the quantum physics is after all. Or do we start at synapses? Or do we start,
you know, at a collection of neurons and synapses like the Kinectome? Is that a better level to
start? Or do we have to start right down at the molecular level? So these are very fundamental
questions that need to be sort of asked and experimented with some pro. This is a science. So,
you know, there's theory, but there's also experiment and test ideas out.
If we just start at the neuron, this is what we have to build. Now that's a very complex system,
right? But this is quite wonderful because this is how nature does intelligence. Like who were
the guests, right? We needed such a complex thing to come up with conscious creatures,
you know, like ourselves. I mean, this is very fundamental, you know, it's a neuron
of intelligence, one could argue. Now, do we have to actually recreate that? Or can we do it some
other way? Okay, that's, that's a very good question. Clearly, if we could just reproduce,
we would just be recreating nature, right? So a lot of this is these artificial neurons are not
this complex, the simplified versions. Can they, you know, can that give rise to consciousness?
Yeah, we don't know yet. Okay, so clearly, it's a tough problem. So it'd be a tough engineering
problem to build something like that. Okay, so the next level up really is, you know, we have
about 2 million cortical columns made up of these neurons in the brain, there's 100 billion neurons,
so you do the math, and you see, you know, there's 10,000 neurons per cortical column or something
like that, maybe 50,000. So, but there's basically 2 million, maybe these are the fundamental units,
maybe this is, if we build 2 million of these, this, this is all we'd need to do to build consciousness
and human level intelligence. So, I mean, neuroscience, as a science has been around
150 years, I mean, a lot of progress has been made in understanding the brain, right, with the
hippocampus, all those different parts. And so, you know, we know a heck of a lot actually about
intelligence, biological intelligence. So, you know, the question we've got to ask ourselves is,
you know, what level do we start at, what level is needed, and then how do we build,
is a lot of this comes down to an engineering problem. So, there's a connectome, there's a
next level up. So, we started with neuron, next level up, these cortical columns in the slightly
high level, we mentioned earlier, the connectome. And so, that's, you know, from one side of the
brain to the other, you know, our emotions, you know, creativity, poetry, painting, you know,
sculpture, engineering structures, you know, is this, you know, is this the level it's kind of
happening at, you know, or does it happen at cortical column or the neuron, you know, or can
we just start here, the kind of bigger conceptual. So, these are good questions. These are all good
engineering questions. And then, of course, you know, if we want to embody this stuff, not just
have it running in our laptop or data, we need to, you know, we'll need a central nervous system,
basically. So, if we're going to build robots like Atlas, you know, we're going to have to connect,
you know, CPU, but it also reaches out in a very complex central nervous system as well.
The beautiful thing, nature, you know, we've been, the Earth's been here 4.5 billion years,
first life was about a billion years ago, that single cell protozoa, you know, so we've had about
a billion years to develop this, you know, evolution, dead end, branching, 99% of species
are extinct. You know, evolution just tries everything, okay, the laws of physical try
everything, intelligent, you know, survivor, the fittest, the things that are well adapted to the
environment, they get to survive. And, you know, over time, you know, what was it a million years
ago, the Neanderthal, and then they developed a bigger neocortex, which enabled them to think a
bit better than the next type of ape. And all the rest kind of basically went extinct, right? So,
we want homo sapiens, and we don't, you know, trying to build ourselves, okay, replicate nature.
So, and then the last level up is social systems. So, you know, if we build a, you know, a few robots,
they've got to get on. You know, we have our social systems, you know, we're a lot more peaceful,
maybe than we used to be. We still have the capacity to go to war, but maybe there's less war.
So, you know, we want to build these higher level structure, hierarchy, societal structures, okay.
And two side people say utopia, dystopia, what's it going to be? Are we going to all get along
these super intelligent machines? Are they going to show us how to live in harmony and,
you know, solve science and cancer and everything? Or are they going to be like the terminator and
come and just get it, wipe us out? Because they see us as kind of destructive and kind of stupid
in a way, okay. Good philosophical questions, right? So, we're not there yet. So, but one day
we will be, and the people give kind of serious attention. So, biological hardware, okay, so
there's the CPUs, GPUs and something called the IP intelligent processing, you know, there's a
company called Graphcore based of the UK. It just got 200 million or 500 million dollars
funding every day, it seems to go up to build this new type of processor. Basically, it's not
really intelligent, it just does matrix multiplication much farther than the GPU. So, it's kind of,
I probably shouldn't know, it's specialized to do deep learning, it's very good at artificial,
you know, deep learning calculation. I'm going to argue deep learning won't get us a general
intelligence, but they're very good at classifying and, you know, drawing graphs, that kind of stuff.
They're not intelligent though, they'll never become conscious. But this is just basically
showing you the CPU, GPU, IP, digital processors, and there they are, that's what they look like.
They build them, they ship them, they get paid money for them. So, maybe some of you didn't
know that, you know, where we are with the ASICs. It's kind of a very, they're calling it like the
Cambrian Explosion and processors. There's a hundred different companies building these ASIC
processors, but they're all designed to optimize the deep learning calculations.
Okay, so we had the CPU there, the Intel, we had the Nvidia GPU, AMD make them too,
but now there's the Google make the GPU, Graphcore make the bottom two ASICs.
They're really good at deep learning, but they're not going to get us to general intelligence.
Again, they're narrow, what I would call narrow AI. And, but yeah, there's a lot of money going
into building these things right now. A lot of these startups are raising a lot of money
to build these for the deep learning. So basically we're solving deep learning, okay,
which is not general intelligence, but we're well on the way to optimizing the hell out of that.
Okay, but it will not get us to general intelligence. So that's what a cloud TPU looks like.
So today we can log into these things. They're a little bit more expensive than a GPUs,
which we can also log into. So say I want to do a deep learning calculation,
I go to Google Cloud, you know, I just say, you know, you go to Amazon, Google, Microsoft,
Azure, the three main cloud providers, only Google have the TPU. That's what they look like.
That's a hundred petaflops. Okay, so that's incredible. I mean, the biggest supercomputer in
the world is about a hundred, is a thousand petaflops. And they take up more than 10 times
the space. These are very powerful things, but they're very domain specific. They narrow AI,
but they're, they're hugely powerful thing and super impressive. And if you're, if you're into
hardware, these things, you know, Google hired 10 years ago, some guys to the best in the world,
to build these things for them. And they kept them secret for a while. That's how DeepMind
AlphaGo, by the way, they, they use these. Okay, so those are TPUs. Again, this is a
larger supercomputer, but it's as dumb as a brick, okay? It can multiply to very large numbers or
factor something very quickly in the, you know, flash of an eye, but they don't, they're no
consciousness, there's no creativity, there's nothing, okay? So these things, they, they're
good at number crunching, but that's about it. But they're hugely impressive and they
cost a lot of money. They also use a lot of power. This thing, the summit supercomputer by IBM.
So it's not just a matter of raw compute, right? This thing uses 13 million watts of power. The,
the brain uses 30 watts. So it's almost a factor of a million more efficient, okay? The brain,
and then we do a heck of a lot more biology is very clever, isn't it? So, you know, what these,
that just gives me more and more respect for biology when I see things like this.
So yeah, there it is. There is the creation. 1.1 million, or you could say 4.5 billion years of
evolution is optimized to this, to us here today. You know, Einstein, Picasso, Van Gogh, you know,
Leonardo da Vinci, who's the smartest guy on the planet today, maybe Ed Whitton at Princeton,
he's a physicist. We can do a lot, which computers cannot. So how the heck do we do it, right?
It's 30 watts. It's, it's just, you know, fits in the skull. It's, it's 1.5 kilo. So what's going
on? What are we missing? Okay, this is where neuromorphic computing comes in. And there's a
project called Spinnaker. So this guy called Steve Furber up in Manchester, he helped build the arm
processor, which is a CPU, and recently sold to SoftBank, I think for 20 billion.
Now he, out of that 20 years ago, he started to build neuromorphic computing. And so Spinnaker is
his effort. It's now part of the human brain project. So these things are, my point is that,
you know, these things are real. You may not have heard of them, but, you know, they've been
going 20 years now. IBM have an effort called True North. So these things are based, these
processes are based on how the brain works. Okay, they're not like the summit, they're not, not
emulation. They're actually direct simulation of how the brain, so they're basically building
artificial neurons and silicon. Okay, artificial neurons and silicon. And we're up to about a billion,
which is about a mouse. Okay, today, 20 years ago, we had one right now. Everything's on a
Moore's Law. So yeah, we're up to about a billion. Maybe we need just to scale it another 100 times
and have a human brain. That's quite possible, actually, it's in the human brain project. It has
a billion euro funding. So that's that's that's moving as fast as it can move. Okay, it's a big
European project now. So yeah, and it's available today in the cloud. IBM have theirs. Intel also
have something called the Ohi, the Hawaiian word. There are many startups as well. So again,
there are, you know, maybe 50 startups, neuromorphic, just Google it, neuromorphic computing.
There are bigger efforts, brain scales is another human brain project one study started in Germany.
It's been a Chrissy UK one true north is IBM and Intel have one. And then there's all the startups
as well. Exciting times, we live in exciting times. So, so basically, you know, we have the
digital processing, which I showed you, including the ASICs, TPUs, the Graphcore, we have neuromorphic,
which is biologically inspired computing, and we have quantum computing. Okay, so, you know,
20 years ago, we just really had the digital. Today, we have three different types of computing.
And so things are going to get interesting. And we live in interesting times the next 20 years
are going to be very interesting in terms of computation. Because we now have this neuromorphic,
which is like biology, and we also have quantum computing. So things are going to get very,
very interesting. So that's what it looks like. There's five cabinets, we're up to 10 now.
And this is how it scales, you start off with 1000 neurons in the core, you put 18 cores on
a chip, then you put 48, this is all engineering at this point, it goes to a fab and it gets built.
You have 48 chips on the board, 24 boards in a rack, and then you put five racks per cabinet and 10
cabinets. That's the intelligence of a mouse right there. That's a billion artificial neurons,
much bigger than a biological neuron. But again, all of this is on Moore's law when they first
we had 1000 remember in 1970, I think we had 1024, the first processor that ever built. And it was
the size of a one inch by one inch 1000. Now we can fit 10 billion neurons on a one inch by one
inch. Okay, it's Moore's law. So these things are shrinking. You know, so, you know, it's on a
trajectory. So that will scale down nicely in 10, 20 years, that will be the size of the mouse brain.
Okay, so that's what they look like. That's on brain scales on the left, that's a
human brain project from Germany. And then there's Google GTPs on the right. So analog versus digital,
I'm arguing that we need the newer, we need the neuromorphic on the left to get us to general
intelligence. The one on the right will do it, we can simulate it, but it's like a thousand
time classification is impressive as an engineering fee is that is, but it's very good at deep learning.
Okay, what about quantum? Maybe we're making progress there, we're up to about 100 qubits,
quantum bits, that's on its own Moore's law. So, you know, within 10 years, we're on 1000,
then we'll start doing interesting calculations. And does the brain use quantum? Roger Penrose
would argue yes. Yeah, we don't know if we have to go to that level. Roger Penrose actually argues
that, you know, consciousness comes, is the only way to get a conscious thing is system is to go
down to the quantum level. Interesting, huh? Okay, so there we have it. Those are the four
types of compute, we have digital, we have neuromorphic, we have quantum, and we have biology.
Okay, and that's what they look like at the microscopic level. So in some sense, you know,
their computation, you know, the physics of computation is called information processing,
okay. And in some sense, you know, when you get down to it, you know, the equations are the same
for the three classical systems. For the quantum computing, they're different, they obey the laws
of quantum mechanics. But theoretically, if you're interested, you could just Google information
processing. Eventually, you wind up here. But the trick is to build them, right? Okay, so that's
what the data center of the future is going to look like. Right now, that's just almost, you know,
99% classical digital computing. You know, there's a few spinnaker machines, you can buy that spinnaker
processor, you know, you can actually buy them. So, but not many data centers have them. But the
point is you can buy them. Quantum computing, you can also buy or you can buy that you can log
into the cloud today and log into an IBM machine, they have 20 quantum computers on the cloud as
of today, and also log into a regati machine. Amazon and Azure, Microsoft and their cloud
are also going to offer quantum computing as a service soon. You can log into spinnaker at the
human brain project, but I think you have to be an academic to do that. It won't be long before
they commercialize that too. But you can see the road ahead. I'm arguing that probably neuromorphic
is the way to get us a different intelligence. Quantum is going to be very useful for
simulating molecules, molecular dynamics, drug discovery, in classical will be good for, you
know, the internet, our iPhones, etc. So, each type of computing has its own specific use. I'm
going to argue neuromorphic is probably the one for AGI. Okay, so deep learning, what about deep
learning? I'll end the time here, 30 minutes. Okay, probably be another 15 minutes. Okay,
probably two thirds through the talk. So, we keep on this call, everyone's heard of deep learning.
You know, I make a living out of it. I've been doing it for six years, seven years now.
That's, you know, it's not going to get us a general intelligence. So, I basically put that in
here to just point that out. It's good at classifying images. It does some sort of language
translation and text to speech, etc. There's neural network, deep learning optimized chip
in all phones now, or you see all laptops, okay. Yeah, they're called system on a chip. You have
your CPU, you have your GPU, but you also have a neural networking deep learning
processor as well these days, okay. So, they're used to some things, mostly, you know, to do
with image recognition, classification and language. Okay, so it just swaps over to whatever
processor is best for the time. So, if you have an application on your phone that requires
deep learning, it will swap over to the deep learning processor. And these are known as
co-processors. So, the CPU is always the main core processor. But if it has something that
needs to offload on the GPU or the neural deep learning processor, it will do. And then the
back and forth between CPU, GPU, they call it co-processors. So, you know, these neural network
are on all devices these days, okay. Probably in the last five years, they've started putting
them on all devices, because deep learning is a thing now, right. There's no neuromorphic
processors yet. Maybe that's to come. Okay, they're too big, right. They won't fit in the phone yet.
You have to use them on the cloud. And so, you know, we've all heard of the different
framework. TensorFlow is the most popular. PyTorch has become quite popular as well. The two main
deep learning frameworks are TensorFlow and PyTorch, which are interesting. And that's it.
This isn't a talk about deep learning, or TensorFlow or PyTorch. But I just put it in there
to see whether, you know, deep learning is getting all the press, you know, is it part of the journey?
No. It doesn't give you what a neuron does. No. It can do, like I say, image classification language,
but it will not do the other types of intelligence. Remember, the creativity of moving around
navigations through space, interpersonal, interpersonal won't give you that at all.
Zilch zero. Okay. So we're going to need something else. I mentioned neuromorphic. But what about
the theory? Okay, so let's have a quick look at that now. Okay, so general reason of intelligence.
So, you know, what do we need? What are the different approaches? I'll cover them.
There's called active inference, which I'm going to really focus on. And then what do we need to
build an AGI processor? Okay, so what do we need? So what we do is we turn to physics, right? We're
a physical system, the human brain of a fly, a snake, a monkey, you know, these are all physical
systems. And so what do we need to understand in physics? There's no easy way out. There's no magic.
We've got to go down. We've got to do the math, right? So, you know, are we missing anything in
physics? Well, there's everything we know about the universe right there. And all of that can be
described as a very fundamental principle called the principle of least action. Now, about two or
three years ago, this book published two years ago, in fact, became a university press called the
principle of least action. All the physics can be actually reframed as, you know, this principle,
which basically says, now it gets mathematical for the next couple of slides, switch off if you
want to. But conceptually, what we do is we write down something called the action, which we denote
as s. And we write down that equation, it basically goes back to Hamilton Lagrange, about 150 years
ago. And, you know, it's quite common if you're a physicist to formulate things in terms of Lagrangians,
Hamiltonians, the action is a function of these Lagrangians. And, you know, you do some scary math
and basic point, I can formulate any system in the world, whether it's a brain, or a car going down
the road, a couple of billiard balls on a billiard table, anything like atomic quantum physics,
classical physics, the universe cosmology, turns out there's this very unifying principle called
the principle of least action. Okay. So maybe we could start there. Okay. So what we have to do,
what's different about the brain compared to say, you know, a black hole, or, or, you know,
a system of galaxies, or, you know, a chemical interaction, okay, what's different here? So
we got to understand the system we're trying to model, right? So we need to, we need to build a
system that can model the world. Hmm. Okay. Just like a mouse makes a little model of the maze, or
we make a model of how we're going to make money, or get up and go to work, or, you know,
get in the car and go on a holiday, you know, we're always modeling the world crossing the road
without getting one over, et cetera, et cetera. You know, finding a mate, getting married, having
kids, you know, we're modeling all the time, you know, solving, you know, problem in chemistry,
we're modeling, modeling, modeling, we're always trying to model the world. So
we need to build a system that can do that using the principle of least action. That to me is
general. That would be a generally intelligent system. Okay. So how do we go about doing that?
Just so happens that a lot of very smart people in the world have been working on this for the last
30 years or so and doing the math. Okay. They've been writing papers, publishing them, writing
the equations down, building prototype systems. Okay. But it's got to, these systems have to be
able to explain and understand what they see, play all these board games, go chess, Sudoku,
but also, you know, cross the street without getting run over. They have to be able to model
their world. Okay. If you build a robot, no use having it just walk in front of a car, right?
It has to be modeling its environment. I mean, that Atlas robot doing flips. I mean, that's
mind boggling. So that's a robot modeling its world that it can do that.
But also it has, that's physical and it also has to be smart, right? That
Atlas is dumb as a brick, you can't play chess. We have to have the whole thing,
like we have, you know, 1.5 kilos, 30 watts, we have to make the whole thing,
which is where the neuromorphic process would come in. So it can plan problem solve,
build new models as they learn more about the world, update their prior knowledge,
you know, just like we do imagining things, have imagination into personal skills. Okay. So here's
some approaches. I mentioned some very clever people who work on this. There's a guy called
Karl Friston here at the UCL in London. There's a guy, Tishby in Israel, Bialek at Princeton,
Hooter is in Australia at the moment. He started in Germany, I think, Schmidt-Huber is in India,
in Switzerland. He's, he's set up a company called Golden Machine with lots of patents.
He's very smart guy. So, and there's many more. So these are very clever people being,
you know, trying to solve intelligence for their life. I mean, you know, as children,
they were going, you know, how do I solve intelligence? You know, some of us say, well,
yeah, how do I get up at nine and come home at five? I mean, these guys, you know,
just like Einstein, natural born with this thing, right? I want to solve intelligence.
So these are the guys. Okay, so let's focus in on Karl Friston.
So basically, he's using the principle of least action. It's, I call it the free energy principle,
but it's the same thing, basically, it uses physics. Okay, so basically, his stance is that
systems, you know, operate in a world to minimize your free energy, something called free energy.
And, you know, that will cause them to explore, you know, you get the explore exploit tradeoff,
they will explore their environment. How else do we learn? Remember, as little kids,
baby, watch a baby, they just roam around, crawl around exploring their environment,
putting things in their mouth. Yeah, this is how we learn. Okay, so the principle of free energy,
you know, this is what basically our brains are doing. They're just minimizing the free
energy the whole time. If there's uncertainty, we want to minimize it, right? That maybe that's
what the best definition of intelligence is, minimizing uncertainty as quickly as possible
and effectively as possible. Okay, how do we, you know, solve chemistry or physics or figure
out the universe? Well, these are uncertainties, we're just trying to minimize them as quickly as
possible. And it turns out the brain, we're not separate from the universe, okay, we're a physical
system within the universe, which, you know, our environment. So, you know, they're interacting
the whole time. So it's just physics, okay, basically, I say just in quotation marks. So
you can write down equations for these interactions and how our system might minimize
this free energy in the areas that's called first and I mean,
we could listen to him for two seconds.
So I guess technical quite quickly, a lot to do with probability, Bayesian influence,
he mentioned the word influence. Yeah, so the brain, it's always, there's always sensory input,
right? Even when we're sleeping, you know, we have dreams, there's subconscious, there's conscious,
I mean, you know, there's internal sensory perception that is perception from our environment.
You know, there's mental illness, schizophrenia, where the information processing goes awry.
You know, it's a complex system, there's 100 billion neurons all different parts, layers upon
layers, it's true evolution. The neocortex is what enables us to come up with things like
a theory of relativity and build cars and, you know, solve physics and chemistry problems and
mathematics. So yeah, it's a complex system, but it's basically a system that's based on the
free energy principle, which you heard Professor Friston explaining a little bit there. That's
what it looks like in a diagram. These other guys like Schmidt-Huber, they have their own systems,
but I think they will all basically boil down to, you know, the free energy principle,
the equations, you know, they look kind of similar. They may use different terminology
vocabulary, but physics is physics, right? Okay, so they're all trying to model a physical system
called the brain. Right, so we have external states, internal states, and there's only a few
more slides now. And something called Markov-Lanker, which kind of delineates the two, the internal
from the external environment, but there's no real, you know, there's no fixed thing, right? I mean,
things enter and we take action, enter our brain and we take action, right, all the time. We're
always interacting with our environment throughout pores and our skin. There is no fixed line,
but it's a theoretical construct to help us through the max. Okay, and it's completely
general. It works for cells. Cells are intelligent. They reproduce, you know, they survive in their
environment right up to brains. Okay, and this is the math, pretty ugly. Okay, so last few slides.
Can we build general intelligence? Okay, very clever math. These guys might end up getting
Nobel Prizes and whatnot, because, you know, one could argue it is maybe the defining problem about
time, right? Build intelligence, you know, solve climate change, solve cancer, build intelligence,
you know, these are the big problems. If someone solves it and builds the system, you know,
they're going to get a lot of money and a lot of prizes. So, I mean, a lot of these guys have a
super lot of recognition already if you're in the field. So, and, you know, it's a combination of,
like I showed before, computer science, so a lot of them are computer science, physics,
and neuroscience. So, a lot of them are neuroscientists, but some are more computer science, but
with a little neuroscience, some are neuroscientists with a little computer science, you know,
a little physics. But yeah, the one thing is they're all really, really good at math. Okay,
so can we build? The answer is yes. We have candidate theories. We have some algorithm
software, some math. We have the hardware now, and we have masses of data sets. So,
when, right, basically, the question is, how about if it's when? It's going to be like a
TensorFlow for general intelligence, just to kind of touch base with something we're familiar with.
And we're going to need a lot of software engineers to actually build these systems
and hardware engineers to build the neural network processors. It's a big project. I mean,
the human brain project, you know, is an Apollo project of our time.
You know, it's going to require funding. There's a lot of funding going into this stuff at the
moment. And you've got the human brain project, DeepMind, you've got the US brain project, China's
working on this, everyone's working on it. Should we build AGI? Again, that comes back to the
philosophy, philosophical question, you know, safety, ethics, singularity. But that's for another
time. Okay, so here are some AGI projects I mentioned from countries all over the world,
all very, very viable projects, in my opinion, all of them. No clear winner. All good stuff.
Okay, so in conclusion, it's obvious that deep learning is lacking the foundations to build
general intelligence. It's based on statistics, not physics. It's a statistical hack. It's very
clever. But it takes a million times as much energy as the brain to do, you know, about one
percent of what the brain does. So clearly, that's a no. Research groups are looking into
bio plausible models. That's the way to get there. That's, you know, in terms of theory and hardware.
So the real question is when, right? So we've got prototypes now, Schmidt-Huber,
you know, he's building stuff, commercializing it. Oh, Friston, you know, has a huge code base,
you know, hundreds of papers. So we were on our way. We're at the beginning of an
exponential curve, I'd say, right? So yeah, it's not a when, it's not a defining moment. It's a
continuum. We're at the beginning. We've got a, we've got a billion neurons,
artificial neurons in a human brain project. We've got the brain of a mouse that could do
Sudoku puzzles that can solve stuff that humans can solve that deep learning would never be able
to solve at a thousand times less energy. So we've got the hardware that's on its own Moore's law.
And what else? So finally, even Jeff Hinton, he's a godfather of deep learning, right? Won
a Turing Award with Jan Lacoon and Yoshua Benjo last year for deep learning. He's saying, assuming,
you know, he knows as much about anybody about deep learning. He's one of the founders. Assuming
that the computer industry can keep producing better hardware, I think business issues are
going to take us a long way. He's talking about the TPUs, the Graphcore, all of that. Obviously,
if we get the big conceptual breakthroughs, probably from neuroscience, it'll take us further. I think
one of the big breakthroughs that's going to come is we're going to understand the brain.
Yeah, it's all about understanding how nature has done it. And nature is used to laws of physics.
And Carl Friston, this act of inference, formulates that beautifully in some beautiful mathematics.
Okay, so was this your final word? Can we move on to questions?
Yeah, so any questions? Thank you. Okay, we have a few questions. It was a really enthusiastic
speech of yours. And so these are the questions. If we managed to create artificial general
intelligence, what would be the odds of the AGI being sentient? Yeah, so that will fall out naturally.
So sentience is part of intelligence. Remember the types of intelligence? So that's the existential
part. That's what that meant. So yeah, they have to be sentient. Okay, they have to be sentient.
I mean, first of all, we'll build ape-like intelligence. Apes are sentient, right? They
know what's going on in that level. Okay, so they will be sentient. And as we get more and more
intelligent, they'll become more and more sentient. Yeah, we haven't seen that movie here. That's a
beautiful movie with Joachim Phoenix. Have you seen it here? The thing on the iPhone gets smarter
and smarter, more and more sentient until it goes off into its hyper universe somewhere. I mean,
that's the kind of thing. It will start kind of like human level, ape level, then get the human
level, but then go into, you know, they'll be more sentient than us. Okay, and together with this
question, if it grasps the concept of the humor, it controls us by giving us false predictions.
Can you trust it and secure it? Is that slavery? Yeah, so that's a good question too.
No, they'll have rights like us, right? Just like, you know, there's animal rights,
animal cruelty is a no-no, right? You go to prison if you harm an animal, right? It's not right.
So yeah, that comes down to ethics and law. Yeah, they'll have their own rights.
They will have rights.
Okay, and okay, what do you think about artificial intelligence in drug design?
Yeah, so it's going to help a lot. So right now we took a question because we're using deep learning
to help us discover drugs to explore the chemically molecular dynamic space
much quicker than we can if, you know, we do it ourselves. Okay, so deep learning is actually
accelerating drug discovery right now. Okay, the idea is to accelerate it even further by
using an artificially journal intelligence system. So yes, right now deep learning is
absolutely accelerating drug discovery and has witnessed in the deep mind-winning,
particular in competition recently, which is, you know, molecular dynamics, which is
similar to drug discovery. Okay, so there's just one comment. A lot of science fiction's work have
gave rise and inspiration to many great technologies and research. So they want to know
which science fiction or any other general books have gave you inspiration and helped
you shape yourself towards the professional that you are today?
Yeah, so science fiction is, you know, when I was younger, I always read science fiction and
watched Star Trek, you know, huge science fiction fan, really. So yeah, I mean, as the most foundation
series, Robert Heinlein, Isaac Asimov, Arthur C. Clarke, those are kind of the, but yeah, there's
new guys around right now with, you know, different science fiction series. Always good
for the imagination to read science fiction. There's nothing wrong with the fact that it's
encouraged, right, to, science fiction is a great thing. That's, you know, it's the start of all
sciences in science fiction. So yeah, you can encourage it. Okay. And if we ever reach artificial
general intelligence, do you think laws would be implemented on time, or we would firstly see
abuse of artificial general intelligence in daily life? You partially gave the answer on this.
Yeah, so, you know, there's always going to be good actors and bad actors, right? So yeah, we're
going to have to come up with laws and try to find ways of enforcing it. There's going to be some
silly things happen, of course, you know, decide with nuclear energy, right? Very, all very powerful
technologies can get misused by bad actors. And so we are, we're going to have to keep an eye out
for that. We have to enforce it. We have to have police at that point, right? Yeah, of course.
And the last final question, as far as I can see, how, oh, okay, one more. Okay, how artificial
general intelligence could affect religions? What's that? Okay, how the artificial general
intelligence could affect religions? Oh, yeah, so I did mention that, I think
sentient being will have the capacity for religion and religious and spirituality and all that good
stuff. You know, so yeah, it just comes along with a religion. It's a type of intelligence,
intelligence is a type of intelligence. Yeah, of course. Okay, as far as I can see,
that those are all questions, but we'll wait a few minutes more. Thank you so much for answers and
for this presentation and being with us tonight. It was really enthusiastic and inspiring to watch
this and to understand it a bit more. So we really thank you. Thank you so much, me and all the people
from Foundation. Sure, I look forward to watching it on YouTube. Yeah, and we hope to collaborate
again with you, of course. So thank you so much. There are no more questions, so I would call it.
And okay, thank you everyone for watching. See you on the next webinar.
