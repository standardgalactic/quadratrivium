1
00:00:00,000 --> 00:00:16,000
Okay, good evening everyone and welcome to Future's webinar series by BH Future's Foundation.

2
00:00:16,000 --> 00:00:18,800
I am Ivana Yevtovich, webinar coordinator.

3
00:00:18,800 --> 00:00:25,200
Tonight we will hear about artificial intelligence, the development of artificial general intelligence

4
00:00:25,200 --> 00:00:31,280
is going to require algorithms that can do things like inductive reasoning, planning and optimal

5
00:00:31,280 --> 00:00:37,760
learning from limited amounts of data. Several efforts are underway to develop these technologies

6
00:00:38,560 --> 00:00:44,640
for deployment in future systems. We are currently witnessing these new approaches being given more

7
00:00:44,640 --> 00:00:50,400
and more attention as we enter the new and perhaps golden age of artificial general intelligence.

8
00:00:51,040 --> 00:00:57,440
In this talk we will present some of the newer more general approaches to solving intelligence

9
00:00:57,440 --> 00:01:04,320
that are really currently under development with the view to deployment in the intelligence system

10
00:01:04,320 --> 00:01:11,360
of the future. Tonight's speaker is our guest Peter Morgan. Peter is author of the popular report

11
00:01:11,360 --> 00:01:18,320
Machine Learning is changing the rules, ways businesses can utilize artificial intelligence

12
00:01:18,400 --> 00:01:24,400
to innovate. Published by O'Reilly, he's passionate about artificial intelligence and the positive

13
00:01:24,400 --> 00:01:32,480
changes in this technology can and is bringing to society. Peter founded the artificial intelligence

14
00:01:32,480 --> 00:01:38,480
consult company, Deep Learning Partnership to carry out his mission of helping to bring artificial

15
00:01:38,480 --> 00:01:45,200
intelligence to the world. He advises and mentors technology startups and is a speaker at artificial

16
00:01:45,200 --> 00:01:50,960
intelligence conferences and meetups. Peter founded the popular London Deep Learning Lab

17
00:01:50,960 --> 00:01:55,920
Meetup. Links for the mentioned companies are listed down below so you can check it out.

18
00:01:56,720 --> 00:02:00,800
Peter, it's an honor to have you here tonight and thank you so much for being with us.

19
00:02:01,840 --> 00:02:10,800
Thanks Havana. Okay, so let's get started. So Havana just introduced me and there is a data

20
00:02:10,800 --> 00:02:19,600
science conference on the 2nd of July at Croatia that I'll just put a little shout out now for.

21
00:02:19,600 --> 00:02:26,080
So if you want to look out for that, tune in for that as well. Okay, so there's a little

22
00:02:26,080 --> 00:02:35,680
book I wrote that Havana mentioned on a practical book on implementing machine learning in real

23
00:02:36,240 --> 00:02:43,680
deployment for companies. That's what I do for living. I'm a consultant, machine learning consultant.

24
00:02:43,680 --> 00:02:49,040
Today's talk is going to be a little more futuristic in that there are no actual deployments yet

25
00:02:50,480 --> 00:02:58,960
but it's a look towards the future where we are now, where we want to get to and how we will get there.

26
00:02:59,200 --> 00:03:06,720
So here's an outline of my talk. What is intelligence? Let's start off with the basic

27
00:03:06,720 --> 00:03:15,120
question we're trying to solve and then look at how the world produces intelligent systems,

28
00:03:15,120 --> 00:03:19,520
either biological or non-biological. We're trying to non-biological route here.

29
00:03:20,880 --> 00:03:25,280
We are the biological, humans are the most intelligent thing that we know of in the

30
00:03:25,280 --> 00:03:32,560
universe so far, although at times it doesn't seem like it, right? And I'll do a very quick recap

31
00:03:32,560 --> 00:03:42,080
of deep learning and just to see if that's part of the journey or not, if it's a dead end or if

32
00:03:42,080 --> 00:03:47,680
that's a step along the way to artificial general intelligence. And hopefully everybody's at that

33
00:03:47,680 --> 00:03:52,000
kind of level, you've heard of deep learning, machine learning, that will probably help understand

34
00:03:52,000 --> 00:03:56,400
the talk but even if you don't it, it doesn't really matter. This is a fairly general talk high

35
00:03:56,400 --> 00:04:04,800
level. And then we'll look at AGI or artificial general intelligence and we'll see maybe how we

36
00:04:04,800 --> 00:04:09,920
might build such a system or if it's possible and then if it is how we might build it and we'll

37
00:04:09,920 --> 00:04:19,600
wrap up. So my talk will be about 40 minutes long and so let's get into it. So I mean why do we even

38
00:04:19,600 --> 00:04:25,840
want to build general intelligence? Well the idea is, and you may have heard DeepMind say that,

39
00:04:25,840 --> 00:04:31,760
it's a company based here in London under the Google umbrella these days, because then we'll

40
00:04:31,760 --> 00:04:36,960
build intelligence and use it to solve everything else, right? That's the big goal, that's the vision.

41
00:04:38,400 --> 00:04:43,520
So at the moment, like I say, we're the most intelligent things around so we're solving

42
00:04:43,520 --> 00:04:52,720
all scientific problems, medicine, climate change, just every problem right now, humans are tackling it

43
00:04:53,280 --> 00:04:59,280
as we have been doing from the beginning of time. So it's a big vision, right, is to build systems

44
00:04:59,280 --> 00:05:05,360
that can basically supersede us and accelerate science. Isn't that an amazing goal, right?

45
00:05:05,360 --> 00:05:10,400
Isn't that an amazing achievement if we could do that? Clearly, it's worth a lot of money so

46
00:05:10,400 --> 00:05:16,480
everyone's working on it, Microsoft, Google, a lot of bunch of startups. So let's see where we are on

47
00:05:16,480 --> 00:05:22,480
that journey. Okay, now first thing I'll mention is that people do get a little bit worried, oh my

48
00:05:22,480 --> 00:05:26,880
god, what happens when, you know, we're no longer the most intelligent things. That's a rather

49
00:05:26,880 --> 00:05:31,040
philosophical question and there's a lot of debate and books been written about that. It's a very hot

50
00:05:31,040 --> 00:05:36,000
topic at the moment. It comes under the umbrella of AI safety and so if you want to look into that,

51
00:05:36,800 --> 00:05:40,640
you know, I encourage you to do that, but we'll focus on the engineering and this talk and the

52
00:05:40,640 --> 00:05:46,720
science. Okay, we'll leave the philosophical problems to the philosophers, I'm afraid,

53
00:05:46,720 --> 00:05:52,480
or that that's a topic for another talk, which I could give too, but I won't on this one. So

54
00:05:53,440 --> 00:05:58,960
again, you know, what is intelligence? Is it, you know, beating go? Is it, you know, winning

55
00:05:58,960 --> 00:06:04,640
at Starcraft, you know, beating the best, go play at the best players in all of these games,

56
00:06:04,640 --> 00:06:11,360
basically, go Starcraft, chess, Jeopardy. Well, as amazing achievements as all of those were,

57
00:06:11,360 --> 00:06:16,640
like breathtaking, you know, when it happened at the moment, I remember, you know, watching

58
00:06:16,640 --> 00:06:21,280
all of them actually and just, you know, put my breath away. But no, it's not actually general

59
00:06:21,280 --> 00:06:25,680
intelligence. Those are examples of very narrow intelligence and pressure as they may be,

60
00:06:26,640 --> 00:06:35,600
because the system, the clever system that beat Gary Gatt, Casper Robert, chess, it can't,

61
00:06:36,720 --> 00:06:41,360
you know, beat Lisa Doll that go, it's essentially dumb outside of its very narrow domain,

62
00:06:42,080 --> 00:06:46,560
in which it's superhuman intelligence. Okay, so they're not generally intelligent machine systems.

63
00:06:48,000 --> 00:06:52,880
Okay, so they're all examples of narrow AI. So what is intelligence? Well,

64
00:06:53,840 --> 00:06:59,680
Howard Gardner at Harvard, a couple of decades ago, you know, it seems so obvious now,

65
00:06:59,680 --> 00:07:03,520
but at the time, you know, no one had kind of thought about this or written it down,

66
00:07:03,520 --> 00:07:10,800
which I, you know, it's one of those things. But he did, and I like it because it sort of says

67
00:07:10,800 --> 00:07:15,120
there's about nine different components to intelligence, right? So, you know, the go,

68
00:07:15,120 --> 00:07:20,560
the chess, that's a logical mathematical component that's superhuman at the moment.

69
00:07:20,560 --> 00:07:27,200
I mean, a calculator that we can buy for five bucks or whatever, you know, can do long multiplication,

70
00:07:27,760 --> 00:07:33,360
you know, far faster than we can. Okay, so there's clearly superhuman in that domain.

71
00:07:33,360 --> 00:07:39,360
But what about the others? Musical, nature, spatial, you know, robots maneuvering, navigating

72
00:07:39,360 --> 00:07:44,480
through space, time, self-driving cars, that kind of thing. Intrapersonal, now these are the harder

73
00:07:44,480 --> 00:07:50,480
ones, aren't they? The personal intelligence, social intelligence, and intro knowing ourselves,

74
00:07:50,480 --> 00:07:55,760
and then enter knowing about others. Okay, so that those are probably, you know, the most

75
00:07:55,760 --> 00:08:02,080
challenging thing. And the was that, you know, people say, you know, a lot of skeptics know,

76
00:08:02,080 --> 00:08:05,760
will never have, you know, be able to build systems like that. Well, I'm going to argue,

77
00:08:05,760 --> 00:08:11,280
there's nothing in physics, laws of physics that says we can't. And clearly, biology has done it,

78
00:08:11,280 --> 00:08:16,720
right? And so that's, we're a physical system. There are people, and, you know, it's fine,

79
00:08:16,720 --> 00:08:22,160
80% of the world believes in some religion, that's fine too. But I would argue that,

80
00:08:22,880 --> 00:08:27,360
you know, once you get the right physical systems that, you know, they will be capable,

81
00:08:27,360 --> 00:08:32,560
have the capacity of, you know, believing in higher powers and stuff like that too. So, you know,

82
00:08:32,560 --> 00:08:37,120
there's all these philosophical questions come up as well. But they can be, you know, I will try to

83
00:08:37,120 --> 00:08:41,520
reason to scientific questions, engineering questions. There's linguistic language,

84
00:08:42,240 --> 00:08:49,120
natural language processing, translation, you know, Siri, Google translate, you know, these are

85
00:08:49,120 --> 00:08:54,960
amazing systems, but they're not quite there yet. They're not quite superhuman. Go is, you know,

86
00:08:54,960 --> 00:09:01,200
calculators are, but, you know, all of these are the types of intelligence we are working on. Okay,

87
00:09:01,200 --> 00:09:05,680
we're not there yet. We're not human level intelligence, but we're certainly working on them.

88
00:09:05,680 --> 00:09:14,400
You know, the bodily kinesthetic, you know, you watch, is it Atlas, the Boston Robotics,

89
00:09:14,400 --> 00:09:18,960
Boston Dynamics, whatever they're called company, you know, doing flips now, you know,

90
00:09:18,960 --> 00:09:23,920
like a gymnast. So we're making a lot of progress on many of the, on most, on all of them, actually.

91
00:09:24,560 --> 00:09:29,040
And it's essentially, why are we here? You can imagine a robot sitting there going, hmm,

92
00:09:29,040 --> 00:09:33,520
why am I here? You know, that's how we'll know we've got to learn intelligence, probably.

93
00:09:34,480 --> 00:09:39,760
And there's a nice beautiful picture of one right there. And so how far have we come?

94
00:09:40,480 --> 00:09:45,520
I've covered all these, you know, we've got the calculation, but they're not creative. We have

95
00:09:45,520 --> 00:09:51,360
to tell them what to do. These systems, they're not self aware. They don't have subjective

96
00:09:51,360 --> 00:09:58,560
experience. So the existential down the bottom is zero. They don't ponder, you know, as far as I

97
00:09:58,560 --> 00:10:04,240
know, my laptop's not wondering, you know, why it's here. Maybe, maybe it is. And just not telling

98
00:10:04,240 --> 00:10:12,320
me, but I don't think so. Okay, so, um, so how will we get to AGI then? Well, it will take a village

99
00:10:12,320 --> 00:10:19,120
to create, you know, it takes a village to create a child. The well known saying in psychology will

100
00:10:19,120 --> 00:10:24,080
the same thing. It's going to take a village to create artificial general intelligence. And in that

101
00:10:24,080 --> 00:10:29,680
village will basically comprise of computer scientists, physicists, neuroscientists, of course,

102
00:10:29,680 --> 00:10:35,680
because we are the example and colleges, sociologists. So general intelligence is general,

103
00:10:35,680 --> 00:10:40,960
right? We're trying to, you know, basically build human liberal intelligence and then suppress it.

104
00:10:40,960 --> 00:10:45,680
So it's going to take, not just computer scientists set in sight of Google anymore, it's

105
00:10:45,680 --> 00:10:52,480
going to take physicists and neuroscientists and psychologists. No doubt, you know, Microsoft,

106
00:10:52,480 --> 00:11:00,400
Google, they have teams like this in place. Okay, so it's a little early, they don't talk about it,

107
00:11:00,400 --> 00:11:06,560
but yeah, but people are working on this stuff right now. So we'll have a look at some of the

108
00:11:06,560 --> 00:11:13,040
efforts and some of the history and some of the future of that, which is what this talks about.

109
00:11:13,040 --> 00:11:20,560
Okay, so physical systems, what have we got? So we've got biological, you know, I can argue that

110
00:11:20,640 --> 00:11:27,600
plants, bacteria, insects, mammals, us, we're all natures full of, you know, intelligent systems.

111
00:11:27,600 --> 00:11:33,680
How many species are there? You know, absolutely millions. And, you know, locus is intelligent,

112
00:11:33,680 --> 00:11:41,600
it's adapted to its environment. You know, it can overcome and reproduce. It doesn't really

113
00:11:41,600 --> 00:11:47,360
make goals and accomplish them, though. It doesn't consciously do that. You know, mammals are the

114
00:11:47,360 --> 00:11:53,440
only things that do that. And so there are various levels of intelligence, too. So we're trying to

115
00:11:53,440 --> 00:12:00,640
build the human level intelligence, the mammalian intelligence. And, you know, perhaps we'll start

116
00:12:00,640 --> 00:12:06,960
off with an ape intelligence and then, you know, progress to human level and then superhuman. So

117
00:12:06,960 --> 00:12:13,120
that's where we are. And so what are we, what, physically, what do we have? We have CPUs,

118
00:12:13,120 --> 00:12:20,320
processors, we have GPUs, FPGA, ASICs. And we also, those are all digital, examples of digital

119
00:12:20,960 --> 00:12:27,760
processing systems, okay. And those of you who have done a computer science degree or

120
00:12:27,760 --> 00:12:31,680
electrical engineering degree, you'll be familiar with all of those. And then we have

121
00:12:31,680 --> 00:12:38,640
something called neuromorphic, which is, which processes based on biology, okay. And those are

122
00:12:38,640 --> 00:12:44,880
very interesting. Those exist today. And they're quite large as well. We're up to about a billion

123
00:12:45,680 --> 00:12:52,560
neurons, okay, artificial neurons. And that's like a mouse. So we could argue we have mouse level

124
00:12:52,560 --> 00:12:59,840
intelligence today. And we'll see a little bit of that later on. And so that's exciting. Digital,

125
00:12:59,840 --> 00:13:04,960
it's always going to be an emulation neuromorphic, it's going to be more of a direct simulation,

126
00:13:04,960 --> 00:13:08,560
okay. So there's the difference between an emulation, which is something that you run on

127
00:13:08,560 --> 00:13:15,360
a digital processor and an emulation, which is an actual physical or simulation rather,

128
00:13:15,360 --> 00:13:21,120
which is an actual simulation of the actual physical system, which is the brain. So neuromorphic,

129
00:13:21,120 --> 00:13:25,600
we can do simulations, we can run it on real time, just like the brain or artificial neurons,

130
00:13:26,160 --> 00:13:33,120
all the rest, emulations on digital processors, which actually takes a lot more energy and time.

131
00:13:33,120 --> 00:13:40,240
It's, it's not, you know, we can get there, but it's, it's just, it's not a direct way of getting

132
00:13:40,240 --> 00:13:44,720
there, whereas neuromorphic is. And then we have quantum. Is there any, is quantum

133
00:13:45,680 --> 00:13:49,680
processors, you've all, we've all heard of quantum computing nowadays is catching the news.

134
00:13:49,680 --> 00:13:56,640
Is that a part of the journey or not? We don't know, maybe the brain uses quantum physics

135
00:13:56,640 --> 00:14:01,200
at the level of microtubules. Roger Penrose would argue it does,

136
00:14:02,320 --> 00:14:08,240
who's to argue with him, he's very clever physicist there in Oxford. But, you know,

137
00:14:09,920 --> 00:14:15,520
the fact is, you know, we don't know. Okay, so we'll look at it, we'll look a little bit

138
00:14:15,520 --> 00:14:19,520
deeper into all of those and then we'll wrap up at the end and I'll tell you where we are today.

139
00:14:20,160 --> 00:14:27,520
So biology is what I mentioned from the lowest little, you know, single celled amoeba to the,

140
00:14:28,320 --> 00:14:35,120
you know, C. elegans, that little worm there with 137 neurons. We can count them. We built

141
00:14:35,120 --> 00:14:40,640
that system actually. So we can actually, we built that little guy there. B, we haven't built.

142
00:14:40,640 --> 00:14:45,840
That's got about a million neurons and that tiny little brain there. It's a little nervous

143
00:14:45,840 --> 00:14:50,080
system, central nervous system. And then the human brain, that's a hundred billion neurons that,

144
00:14:50,080 --> 00:14:54,240
you know, that's clearly a tough one to crack. That's what we're trying to go.

145
00:14:55,520 --> 00:15:02,640
So a little bit of the big picture, you know, the brain is a system at what level do we attack this

146
00:15:02,640 --> 00:15:08,000
on? Do we attack it at the level of atoms and molecules like, you know, Roger Penrose is doing,

147
00:15:08,000 --> 00:15:14,240
that's where the quantum physics is after all. Or do we start at synapses? Or do we start,

148
00:15:14,240 --> 00:15:21,120
you know, at a collection of neurons and synapses like the Kinectome? Is that a better level to

149
00:15:21,120 --> 00:15:25,600
start? Or do we have to start right down at the molecular level? So these are very fundamental

150
00:15:25,600 --> 00:15:30,560
questions that need to be sort of asked and experimented with some pro. This is a science. So,

151
00:15:30,560 --> 00:15:34,480
you know, there's theory, but there's also experiment and test ideas out.

152
00:15:37,120 --> 00:15:42,160
If we just start at the neuron, this is what we have to build. Now that's a very complex system,

153
00:15:42,160 --> 00:15:46,800
right? But this is quite wonderful because this is how nature does intelligence. Like who were

154
00:15:46,800 --> 00:15:53,440
the guests, right? We needed such a complex thing to come up with conscious creatures,

155
00:15:53,440 --> 00:15:57,920
you know, like ourselves. I mean, this is very fundamental, you know, it's a neuron

156
00:15:57,920 --> 00:16:05,440
of intelligence, one could argue. Now, do we have to actually recreate that? Or can we do it some

157
00:16:05,440 --> 00:16:12,320
other way? Okay, that's, that's a very good question. Clearly, if we could just reproduce,

158
00:16:12,320 --> 00:16:17,920
we would just be recreating nature, right? So a lot of this is these artificial neurons are not

159
00:16:17,920 --> 00:16:24,960
this complex, the simplified versions. Can they, you know, can that give rise to consciousness?

160
00:16:24,960 --> 00:16:31,520
Yeah, we don't know yet. Okay, so clearly, it's a tough problem. So it'd be a tough engineering

161
00:16:31,520 --> 00:16:38,400
problem to build something like that. Okay, so the next level up really is, you know, we have

162
00:16:38,400 --> 00:16:43,200
about 2 million cortical columns made up of these neurons in the brain, there's 100 billion neurons,

163
00:16:43,200 --> 00:16:50,240
so you do the math, and you see, you know, there's 10,000 neurons per cortical column or something

164
00:16:50,240 --> 00:16:56,080
like that, maybe 50,000. So, but there's basically 2 million, maybe these are the fundamental units,

165
00:16:56,080 --> 00:17:02,640
maybe this is, if we build 2 million of these, this, this is all we'd need to do to build consciousness

166
00:17:02,640 --> 00:17:08,000
and human level intelligence. So, I mean, neuroscience, as a science has been around

167
00:17:08,000 --> 00:17:12,880
150 years, I mean, a lot of progress has been made in understanding the brain, right, with the

168
00:17:12,880 --> 00:17:18,960
hippocampus, all those different parts. And so, you know, we know a heck of a lot actually about

169
00:17:18,960 --> 00:17:23,840
intelligence, biological intelligence. So, you know, the question we've got to ask ourselves is,

170
00:17:23,840 --> 00:17:27,280
you know, what level do we start at, what level is needed, and then how do we build,

171
00:17:27,280 --> 00:17:32,800
is a lot of this comes down to an engineering problem. So, there's a connectome, there's a

172
00:17:32,800 --> 00:17:39,520
next level up. So, we started with neuron, next level up, these cortical columns in the slightly

173
00:17:39,520 --> 00:17:44,480
high level, we mentioned earlier, the connectome. And so, that's, you know, from one side of the

174
00:17:44,480 --> 00:17:52,880
brain to the other, you know, our emotions, you know, creativity, poetry, painting, you know,

175
00:17:53,600 --> 00:18:00,560
sculpture, engineering structures, you know, is this, you know, is this the level it's kind of

176
00:18:00,560 --> 00:18:05,680
happening at, you know, or does it happen at cortical column or the neuron, you know, or can

177
00:18:05,680 --> 00:18:11,040
we just start here, the kind of bigger conceptual. So, these are good questions. These are all good

178
00:18:11,040 --> 00:18:17,840
engineering questions. And then, of course, you know, if we want to embody this stuff, not just

179
00:18:17,840 --> 00:18:21,920
have it running in our laptop or data, we need to, you know, we'll need a central nervous system,

180
00:18:21,920 --> 00:18:26,400
basically. So, if we're going to build robots like Atlas, you know, we're going to have to connect,

181
00:18:26,400 --> 00:18:35,040
you know, CPU, but it also reaches out in a very complex central nervous system as well.

182
00:18:35,840 --> 00:18:41,440
The beautiful thing, nature, you know, we've been, the Earth's been here 4.5 billion years,

183
00:18:41,440 --> 00:18:46,880
first life was about a billion years ago, that single cell protozoa, you know, so we've had about

184
00:18:46,960 --> 00:18:53,600
a billion years to develop this, you know, evolution, dead end, branching, 99% of species

185
00:18:53,600 --> 00:19:00,160
are extinct. You know, evolution just tries everything, okay, the laws of physical try

186
00:19:00,160 --> 00:19:05,600
everything, intelligent, you know, survivor, the fittest, the things that are well adapted to the

187
00:19:05,600 --> 00:19:14,160
environment, they get to survive. And, you know, over time, you know, what was it a million years

188
00:19:14,160 --> 00:19:19,440
ago, the Neanderthal, and then they developed a bigger neocortex, which enabled them to think a

189
00:19:19,440 --> 00:19:25,440
bit better than the next type of ape. And all the rest kind of basically went extinct, right? So,

190
00:19:25,440 --> 00:19:34,880
we want homo sapiens, and we don't, you know, trying to build ourselves, okay, replicate nature.

191
00:19:34,880 --> 00:19:42,800
So, and then the last level up is social systems. So, you know, if we build a, you know, a few robots,

192
00:19:42,800 --> 00:19:48,320
they've got to get on. You know, we have our social systems, you know, we're a lot more peaceful,

193
00:19:48,320 --> 00:19:53,520
maybe than we used to be. We still have the capacity to go to war, but maybe there's less war.

194
00:19:54,320 --> 00:20:00,400
So, you know, we want to build these higher level structure, hierarchy, societal structures, okay.

195
00:20:01,360 --> 00:20:06,800
And two side people say utopia, dystopia, what's it going to be? Are we going to all get along

196
00:20:06,800 --> 00:20:10,800
these super intelligent machines? Are they going to show us how to live in harmony and,

197
00:20:10,800 --> 00:20:15,040
you know, solve science and cancer and everything? Or are they going to be like the terminator and

198
00:20:15,040 --> 00:20:19,840
come and just get it, wipe us out? Because they see us as kind of destructive and kind of stupid

199
00:20:19,840 --> 00:20:28,800
in a way, okay. Good philosophical questions, right? So, we're not there yet. So, but one day

200
00:20:28,800 --> 00:20:37,920
we will be, and the people give kind of serious attention. So, biological hardware, okay, so

201
00:20:37,920 --> 00:20:42,880
there's the CPUs, GPUs and something called the IP intelligent processing, you know, there's a

202
00:20:42,880 --> 00:20:50,480
company called Graphcore based of the UK. It just got 200 million or 500 million dollars

203
00:20:50,480 --> 00:20:57,200
funding every day, it seems to go up to build this new type of processor. Basically, it's not

204
00:20:57,200 --> 00:21:02,800
really intelligent, it just does matrix multiplication much farther than the GPU. So, it's kind of,

205
00:21:03,600 --> 00:21:10,400
I probably shouldn't know, it's specialized to do deep learning, it's very good at artificial,

206
00:21:10,400 --> 00:21:14,800
you know, deep learning calculation. I'm going to argue deep learning won't get us a general

207
00:21:14,800 --> 00:21:20,960
intelligence, but they're very good at classifying and, you know, drawing graphs, that kind of stuff.

208
00:21:22,080 --> 00:21:27,200
They're not intelligent though, they'll never become conscious. But this is just basically

209
00:21:27,200 --> 00:21:33,760
showing you the CPU, GPU, IP, digital processors, and there they are, that's what they look like.

210
00:21:33,760 --> 00:21:39,840
They build them, they ship them, they get paid money for them. So, maybe some of you didn't

211
00:21:39,840 --> 00:21:44,320
know that, you know, where we are with the ASICs. It's kind of a very, they're calling it like the

212
00:21:44,320 --> 00:21:49,520
Cambrian Explosion and processors. There's a hundred different companies building these ASIC

213
00:21:49,520 --> 00:21:57,280
processors, but they're all designed to optimize the deep learning calculations.

214
00:21:57,280 --> 00:22:03,600
Okay, so we had the CPU there, the Intel, we had the Nvidia GPU, AMD make them too,

215
00:22:03,600 --> 00:22:08,960
but now there's the Google make the GPU, Graphcore make the bottom two ASICs.

216
00:22:09,920 --> 00:22:14,240
They're really good at deep learning, but they're not going to get us to general intelligence.

217
00:22:14,240 --> 00:22:22,560
Again, they're narrow, what I would call narrow AI. And, but yeah, there's a lot of money going

218
00:22:22,560 --> 00:22:26,800
into building these things right now. A lot of these startups are raising a lot of money

219
00:22:26,800 --> 00:22:30,720
to build these for the deep learning. So basically we're solving deep learning, okay,

220
00:22:30,720 --> 00:22:35,840
which is not general intelligence, but we're well on the way to optimizing the hell out of that.

221
00:22:35,840 --> 00:22:40,560
Okay, but it will not get us to general intelligence. So that's what a cloud TPU looks like.

222
00:22:40,560 --> 00:22:46,000
So today we can log into these things. They're a little bit more expensive than a GPUs,

223
00:22:46,000 --> 00:22:49,680
which we can also log into. So say I want to do a deep learning calculation,

224
00:22:49,680 --> 00:22:55,520
I go to Google Cloud, you know, I just say, you know, you go to Amazon, Google, Microsoft,

225
00:22:55,520 --> 00:23:00,240
Azure, the three main cloud providers, only Google have the TPU. That's what they look like.

226
00:23:00,240 --> 00:23:06,800
That's a hundred petaflops. Okay, so that's incredible. I mean, the biggest supercomputer in

227
00:23:06,800 --> 00:23:12,320
the world is about a hundred, is a thousand petaflops. And they take up more than 10 times

228
00:23:12,320 --> 00:23:18,000
the space. These are very powerful things, but they're very domain specific. They narrow AI,

229
00:23:18,000 --> 00:23:23,200
but they're, they're hugely powerful thing and super impressive. And if you're, if you're into

230
00:23:23,200 --> 00:23:28,800
hardware, these things, you know, Google hired 10 years ago, some guys to the best in the world,

231
00:23:28,800 --> 00:23:34,000
to build these things for them. And they kept them secret for a while. That's how DeepMind

232
00:23:34,560 --> 00:23:41,360
AlphaGo, by the way, they, they use these. Okay, so those are TPUs. Again, this is a

233
00:23:41,360 --> 00:23:46,560
larger supercomputer, but it's as dumb as a brick, okay? It can multiply to very large numbers or

234
00:23:46,560 --> 00:23:54,240
factor something very quickly in the, you know, flash of an eye, but they don't, they're no

235
00:23:54,240 --> 00:24:00,720
consciousness, there's no creativity, there's nothing, okay? So these things, they, they're

236
00:24:00,720 --> 00:24:04,880
good at number crunching, but that's about it. But they're hugely impressive and they

237
00:24:04,880 --> 00:24:10,240
cost a lot of money. They also use a lot of power. This thing, the summit supercomputer by IBM.

238
00:24:10,880 --> 00:24:16,640
So it's not just a matter of raw compute, right? This thing uses 13 million watts of power. The,

239
00:24:16,640 --> 00:24:25,760
the brain uses 30 watts. So it's almost a factor of a million more efficient, okay? The brain,

240
00:24:25,760 --> 00:24:31,280
and then we do a heck of a lot more biology is very clever, isn't it? So, you know, what these,

241
00:24:31,280 --> 00:24:34,480
that just gives me more and more respect for biology when I see things like this.

242
00:24:35,920 --> 00:24:42,800
So yeah, there it is. There is the creation. 1.1 million, or you could say 4.5 billion years of

243
00:24:42,800 --> 00:24:51,120
evolution is optimized to this, to us here today. You know, Einstein, Picasso, Van Gogh, you know,

244
00:24:52,080 --> 00:24:57,600
Leonardo da Vinci, who's the smartest guy on the planet today, maybe Ed Whitton at Princeton,

245
00:24:57,600 --> 00:25:03,360
he's a physicist. We can do a lot, which computers cannot. So how the heck do we do it, right?

246
00:25:03,360 --> 00:25:09,840
It's 30 watts. It's, it's just, you know, fits in the skull. It's, it's 1.5 kilo. So what's going

247
00:25:09,840 --> 00:25:18,800
on? What are we missing? Okay, this is where neuromorphic computing comes in. And there's a

248
00:25:18,800 --> 00:25:25,360
project called Spinnaker. So this guy called Steve Furber up in Manchester, he helped build the arm

249
00:25:26,000 --> 00:25:34,160
processor, which is a CPU, and recently sold to SoftBank, I think for 20 billion.

250
00:25:37,040 --> 00:25:42,880
Now he, out of that 20 years ago, he started to build neuromorphic computing. And so Spinnaker is

251
00:25:42,880 --> 00:25:47,920
his effort. It's now part of the human brain project. So these things are, my point is that,

252
00:25:47,920 --> 00:25:51,920
you know, these things are real. You may not have heard of them, but, you know, they've been

253
00:25:51,920 --> 00:25:57,920
going 20 years now. IBM have an effort called True North. So these things are based, these

254
00:25:57,920 --> 00:26:03,920
processes are based on how the brain works. Okay, they're not like the summit, they're not, not

255
00:26:04,560 --> 00:26:09,040
emulation. They're actually direct simulation of how the brain, so they're basically building

256
00:26:09,040 --> 00:26:16,240
artificial neurons and silicon. Okay, artificial neurons and silicon. And we're up to about a billion,

257
00:26:16,240 --> 00:26:22,480
which is about a mouse. Okay, today, 20 years ago, we had one right now. Everything's on a

258
00:26:22,480 --> 00:26:28,560
Moore's Law. So yeah, we're up to about a billion. Maybe we need just to scale it another 100 times

259
00:26:28,560 --> 00:26:33,600
and have a human brain. That's quite possible, actually, it's in the human brain project. It has

260
00:26:33,600 --> 00:26:40,000
a billion euro funding. So that's that's that's moving as fast as it can move. Okay, it's a big

261
00:26:40,000 --> 00:26:48,160
European project now. So yeah, and it's available today in the cloud. IBM have theirs. Intel also

262
00:26:48,160 --> 00:26:56,560
have something called the Ohi, the Hawaiian word. There are many startups as well. So again,

263
00:26:56,560 --> 00:27:00,560
there are, you know, maybe 50 startups, neuromorphic, just Google it, neuromorphic computing.

264
00:27:01,600 --> 00:27:07,440
There are bigger efforts, brain scales is another human brain project one study started in Germany.

265
00:27:07,520 --> 00:27:14,320
It's been a Chrissy UK one true north is IBM and Intel have one. And then there's all the startups

266
00:27:14,320 --> 00:27:22,800
as well. Exciting times, we live in exciting times. So, so basically, you know, we have the

267
00:27:22,800 --> 00:27:28,880
digital processing, which I showed you, including the ASICs, TPUs, the Graphcore, we have neuromorphic,

268
00:27:28,880 --> 00:27:34,560
which is biologically inspired computing, and we have quantum computing. Okay, so, you know,

269
00:27:34,560 --> 00:27:40,000
20 years ago, we just really had the digital. Today, we have three different types of computing.

270
00:27:40,000 --> 00:27:44,320
And so things are going to get interesting. And we live in interesting times the next 20 years

271
00:27:44,320 --> 00:27:49,680
are going to be very interesting in terms of computation. Because we now have this neuromorphic,

272
00:27:49,680 --> 00:27:54,240
which is like biology, and we also have quantum computing. So things are going to get very,

273
00:27:54,240 --> 00:27:59,040
very interesting. So that's what it looks like. There's five cabinets, we're up to 10 now.

274
00:27:59,840 --> 00:28:07,200
And this is how it scales, you start off with 1000 neurons in the core, you put 18 cores on

275
00:28:07,200 --> 00:28:12,160
a chip, then you put 48, this is all engineering at this point, it goes to a fab and it gets built.

276
00:28:12,160 --> 00:28:18,320
You have 48 chips on the board, 24 boards in a rack, and then you put five racks per cabinet and 10

277
00:28:18,320 --> 00:28:24,880
cabinets. That's the intelligence of a mouse right there. That's a billion artificial neurons,

278
00:28:24,880 --> 00:28:31,120
much bigger than a biological neuron. But again, all of this is on Moore's law when they first

279
00:28:31,120 --> 00:28:38,320
we had 1000 remember in 1970, I think we had 1024, the first processor that ever built. And it was

280
00:28:38,320 --> 00:28:47,280
the size of a one inch by one inch 1000. Now we can fit 10 billion neurons on a one inch by one

281
00:28:47,280 --> 00:28:54,000
inch. Okay, it's Moore's law. So these things are shrinking. You know, so, you know, it's on a

282
00:28:54,000 --> 00:28:59,200
trajectory. So that will scale down nicely in 10, 20 years, that will be the size of the mouse brain.

283
00:29:00,080 --> 00:29:04,240
Okay, so that's what they look like. That's on brain scales on the left, that's a

284
00:29:06,080 --> 00:29:13,120
human brain project from Germany. And then there's Google GTPs on the right. So analog versus digital,

285
00:29:13,120 --> 00:29:18,320
I'm arguing that we need the newer, we need the neuromorphic on the left to get us to general

286
00:29:18,320 --> 00:29:23,920
intelligence. The one on the right will do it, we can simulate it, but it's like a thousand

287
00:29:23,920 --> 00:29:29,760
time classification is impressive as an engineering fee is that is, but it's very good at deep learning.

288
00:29:31,040 --> 00:29:38,800
Okay, what about quantum? Maybe we're making progress there, we're up to about 100 qubits,

289
00:29:38,800 --> 00:29:43,600
quantum bits, that's on its own Moore's law. So, you know, within 10 years, we're on 1000,

290
00:29:43,600 --> 00:29:50,160
then we'll start doing interesting calculations. And does the brain use quantum? Roger Penrose

291
00:29:50,160 --> 00:29:57,280
would argue yes. Yeah, we don't know if we have to go to that level. Roger Penrose actually argues

292
00:29:57,280 --> 00:30:06,160
that, you know, consciousness comes, is the only way to get a conscious thing is system is to go

293
00:30:06,160 --> 00:30:12,080
down to the quantum level. Interesting, huh? Okay, so there we have it. Those are the four

294
00:30:12,080 --> 00:30:16,480
types of compute, we have digital, we have neuromorphic, we have quantum, and we have biology.

295
00:30:19,280 --> 00:30:27,520
Okay, and that's what they look like at the microscopic level. So in some sense, you know,

296
00:30:28,080 --> 00:30:33,360
their computation, you know, the physics of computation is called information processing,

297
00:30:33,360 --> 00:30:40,320
okay. And in some sense, you know, when you get down to it, you know, the equations are the same

298
00:30:41,040 --> 00:30:45,440
for the three classical systems. For the quantum computing, they're different, they obey the laws

299
00:30:45,440 --> 00:30:51,280
of quantum mechanics. But theoretically, if you're interested, you could just Google information

300
00:30:51,280 --> 00:30:57,520
processing. Eventually, you wind up here. But the trick is to build them, right? Okay, so that's

301
00:30:57,520 --> 00:31:02,320
what the data center of the future is going to look like. Right now, that's just almost, you know,

302
00:31:02,320 --> 00:31:09,760
99% classical digital computing. You know, there's a few spinnaker machines, you can buy that spinnaker

303
00:31:09,760 --> 00:31:17,600
processor, you know, you can actually buy them. So, but not many data centers have them. But the

304
00:31:17,600 --> 00:31:22,400
point is you can buy them. Quantum computing, you can also buy or you can buy that you can log

305
00:31:22,400 --> 00:31:27,040
into the cloud today and log into an IBM machine, they have 20 quantum computers on the cloud as

306
00:31:27,040 --> 00:31:35,840
of today, and also log into a regati machine. Amazon and Azure, Microsoft and their cloud

307
00:31:35,840 --> 00:31:41,280
are also going to offer quantum computing as a service soon. You can log into spinnaker at the

308
00:31:41,280 --> 00:31:46,000
human brain project, but I think you have to be an academic to do that. It won't be long before

309
00:31:46,000 --> 00:31:51,680
they commercialize that too. But you can see the road ahead. I'm arguing that probably neuromorphic

310
00:31:51,680 --> 00:31:55,840
is the way to get us a different intelligence. Quantum is going to be very useful for

311
00:31:56,480 --> 00:32:03,200
simulating molecules, molecular dynamics, drug discovery, in classical will be good for, you

312
00:32:03,440 --> 00:32:09,760
know, the internet, our iPhones, etc. So, each type of computing has its own specific use. I'm

313
00:32:09,760 --> 00:32:15,520
going to argue neuromorphic is probably the one for AGI. Okay, so deep learning, what about deep

314
00:32:15,520 --> 00:32:22,880
learning? I'll end the time here, 30 minutes. Okay, probably be another 15 minutes. Okay,

315
00:32:22,880 --> 00:32:31,200
probably two thirds through the talk. So, we keep on this call, everyone's heard of deep learning.

316
00:32:31,520 --> 00:32:36,080
You know, I make a living out of it. I've been doing it for six years, seven years now.

317
00:32:37,760 --> 00:32:42,320
That's, you know, it's not going to get us a general intelligence. So, I basically put that in

318
00:32:42,320 --> 00:32:47,920
here to just point that out. It's good at classifying images. It does some sort of language

319
00:32:47,920 --> 00:32:54,320
translation and text to speech, etc. There's neural network, deep learning optimized chip

320
00:32:54,320 --> 00:33:01,760
in all phones now, or you see all laptops, okay. Yeah, they're called system on a chip. You have

321
00:33:01,760 --> 00:33:05,680
your CPU, you have your GPU, but you also have a neural networking deep learning

322
00:33:05,680 --> 00:33:11,440
processor as well these days, okay. So, they're used to some things, mostly, you know, to do

323
00:33:11,440 --> 00:33:17,920
with image recognition, classification and language. Okay, so it just swaps over to whatever

324
00:33:17,920 --> 00:33:24,000
processor is best for the time. So, if you have an application on your phone that requires

325
00:33:24,000 --> 00:33:29,040
deep learning, it will swap over to the deep learning processor. And these are known as

326
00:33:29,040 --> 00:33:34,560
co-processors. So, the CPU is always the main core processor. But if it has something that

327
00:33:34,560 --> 00:33:39,840
needs to offload on the GPU or the neural deep learning processor, it will do. And then the

328
00:33:39,840 --> 00:33:47,200
back and forth between CPU, GPU, they call it co-processors. So, you know, these neural network

329
00:33:47,920 --> 00:33:52,640
are on all devices these days, okay. Probably in the last five years, they've started putting

330
00:33:52,640 --> 00:33:57,200
them on all devices, because deep learning is a thing now, right. There's no neuromorphic

331
00:33:57,200 --> 00:34:02,640
processors yet. Maybe that's to come. Okay, they're too big, right. They won't fit in the phone yet.

332
00:34:03,360 --> 00:34:07,760
You have to use them on the cloud. And so, you know, we've all heard of the different

333
00:34:07,760 --> 00:34:13,120
framework. TensorFlow is the most popular. PyTorch has become quite popular as well. The two main

334
00:34:13,120 --> 00:34:17,520
deep learning frameworks are TensorFlow and PyTorch, which are interesting. And that's it.

335
00:34:17,520 --> 00:34:22,960
This isn't a talk about deep learning, or TensorFlow or PyTorch. But I just put it in there

336
00:34:22,960 --> 00:34:28,160
to see whether, you know, deep learning is getting all the press, you know, is it part of the journey?

337
00:34:28,160 --> 00:34:41,200
No. It doesn't give you what a neuron does. No. It can do, like I say, image classification language,

338
00:34:41,200 --> 00:34:45,520
but it will not do the other types of intelligence. Remember, the creativity of moving around

339
00:34:45,520 --> 00:34:50,160
navigations through space, interpersonal, interpersonal won't give you that at all.

340
00:34:51,760 --> 00:34:57,440
Zilch zero. Okay. So we're going to need something else. I mentioned neuromorphic. But what about

341
00:34:57,440 --> 00:35:03,200
the theory? Okay, so let's have a quick look at that now. Okay, so general reason of intelligence.

342
00:35:03,200 --> 00:35:07,280
So, you know, what do we need? What are the different approaches? I'll cover them.

343
00:35:08,480 --> 00:35:13,360
There's called active inference, which I'm going to really focus on. And then what do we need to

344
00:35:13,360 --> 00:35:22,240
build an AGI processor? Okay, so what do we need? So what we do is we turn to physics, right? We're

345
00:35:22,240 --> 00:35:31,680
a physical system, the human brain of a fly, a snake, a monkey, you know, these are all physical

346
00:35:31,680 --> 00:35:38,560
systems. And so what do we need to understand in physics? There's no easy way out. There's no magic.

347
00:35:38,560 --> 00:35:44,240
We've got to go down. We've got to do the math, right? So, you know, are we missing anything in

348
00:35:44,240 --> 00:35:49,760
physics? Well, there's everything we know about the universe right there. And all of that can be

349
00:35:49,760 --> 00:35:56,000
described as a very fundamental principle called the principle of least action. Now, about two or

350
00:35:56,000 --> 00:36:01,520
three years ago, this book published two years ago, in fact, became a university press called the

351
00:36:01,520 --> 00:36:07,440
principle of least action. All the physics can be actually reframed as, you know, this principle,

352
00:36:07,440 --> 00:36:11,920
which basically says, now it gets mathematical for the next couple of slides, switch off if you

353
00:36:11,920 --> 00:36:17,120
want to. But conceptually, what we do is we write down something called the action, which we denote

354
00:36:17,120 --> 00:36:24,720
as s. And we write down that equation, it basically goes back to Hamilton Lagrange, about 150 years

355
00:36:24,720 --> 00:36:30,720
ago. And, you know, it's quite common if you're a physicist to formulate things in terms of Lagrangians,

356
00:36:30,720 --> 00:36:37,600
Hamiltonians, the action is a function of these Lagrangians. And, you know, you do some scary math

357
00:36:37,600 --> 00:36:45,520
and basic point, I can formulate any system in the world, whether it's a brain, or a car going down

358
00:36:45,520 --> 00:36:51,600
the road, a couple of billiard balls on a billiard table, anything like atomic quantum physics,

359
00:36:52,640 --> 00:36:58,880
classical physics, the universe cosmology, turns out there's this very unifying principle called

360
00:36:58,880 --> 00:37:06,480
the principle of least action. Okay. So maybe we could start there. Okay. So what we have to do,

361
00:37:06,480 --> 00:37:11,280
what's different about the brain compared to say, you know, a black hole, or, or, you know,

362
00:37:11,280 --> 00:37:18,640
a system of galaxies, or, you know, a chemical interaction, okay, what's different here? So

363
00:37:18,640 --> 00:37:24,880
we got to understand the system we're trying to model, right? So we need to, we need to build a

364
00:37:24,880 --> 00:37:31,280
system that can model the world. Hmm. Okay. Just like a mouse makes a little model of the maze, or

365
00:37:31,280 --> 00:37:35,920
we make a model of how we're going to make money, or get up and go to work, or, you know,

366
00:37:35,920 --> 00:37:39,760
get in the car and go on a holiday, you know, we're always modeling the world crossing the road

367
00:37:39,760 --> 00:37:45,280
without getting one over, et cetera, et cetera. You know, finding a mate, getting married, having

368
00:37:45,280 --> 00:37:51,920
kids, you know, we're modeling all the time, you know, solving, you know, problem in chemistry,

369
00:37:51,920 --> 00:37:54,960
we're modeling, modeling, modeling, we're always trying to model the world. So

370
00:37:54,960 --> 00:37:59,440
we need to build a system that can do that using the principle of least action. That to me is

371
00:37:59,440 --> 00:38:03,200
general. That would be a generally intelligent system. Okay. So how do we go about doing that?

372
00:38:03,760 --> 00:38:09,280
Just so happens that a lot of very smart people in the world have been working on this for the last

373
00:38:09,280 --> 00:38:15,200
30 years or so and doing the math. Okay. They've been writing papers, publishing them, writing

374
00:38:15,200 --> 00:38:20,480
the equations down, building prototype systems. Okay. But it's got to, these systems have to be

375
00:38:20,560 --> 00:38:27,360
able to explain and understand what they see, play all these board games, go chess, Sudoku,

376
00:38:27,360 --> 00:38:31,120
but also, you know, cross the street without getting run over. They have to be able to model

377
00:38:31,120 --> 00:38:36,080
their world. Okay. If you build a robot, no use having it just walk in front of a car, right?

378
00:38:36,080 --> 00:38:41,600
It has to be modeling its environment. I mean, that Atlas robot doing flips. I mean, that's

379
00:38:41,600 --> 00:38:46,160
mind boggling. So that's a robot modeling its world that it can do that.

380
00:38:47,040 --> 00:38:51,520
But also it has, that's physical and it also has to be smart, right? That

381
00:38:52,160 --> 00:38:55,680
Atlas is dumb as a brick, you can't play chess. We have to have the whole thing,

382
00:38:55,680 --> 00:39:00,480
like we have, you know, 1.5 kilos, 30 watts, we have to make the whole thing,

383
00:39:00,480 --> 00:39:05,440
which is where the neuromorphic process would come in. So it can plan problem solve,

384
00:39:05,440 --> 00:39:10,080
build new models as they learn more about the world, update their prior knowledge,

385
00:39:10,080 --> 00:39:15,600
you know, just like we do imagining things, have imagination into personal skills. Okay. So here's

386
00:39:15,600 --> 00:39:20,000
some approaches. I mentioned some very clever people who work on this. There's a guy called

387
00:39:20,000 --> 00:39:25,840
Karl Friston here at the UCL in London. There's a guy, Tishby in Israel, Bialek at Princeton,

388
00:39:25,840 --> 00:39:34,000
Hooter is in Australia at the moment. He started in Germany, I think, Schmidt-Huber is in India,

389
00:39:34,000 --> 00:39:39,600
in Switzerland. He's, he's set up a company called Golden Machine with lots of patents.

390
00:39:39,600 --> 00:39:44,480
He's very smart guy. So, and there's many more. So these are very clever people being,

391
00:39:45,200 --> 00:39:50,160
you know, trying to solve intelligence for their life. I mean, you know, as children,

392
00:39:50,160 --> 00:39:53,920
they were going, you know, how do I solve intelligence? You know, some of us say, well,

393
00:39:53,920 --> 00:39:58,320
yeah, how do I get up at nine and come home at five? I mean, these guys, you know,

394
00:39:58,320 --> 00:40:03,280
just like Einstein, natural born with this thing, right? I want to solve intelligence.

395
00:40:04,160 --> 00:40:08,960
So these are the guys. Okay, so let's focus in on Karl Friston.

396
00:40:09,280 --> 00:40:18,400
So basically, he's using the principle of least action. It's, I call it the free energy principle,

397
00:40:18,400 --> 00:40:23,200
but it's the same thing, basically, it uses physics. Okay, so basically, his stance is that

398
00:40:23,200 --> 00:40:28,240
systems, you know, operate in a world to minimize your free energy, something called free energy.

399
00:40:28,800 --> 00:40:34,880
And, you know, that will cause them to explore, you know, you get the explore exploit tradeoff,

400
00:40:34,880 --> 00:40:38,640
they will explore their environment. How else do we learn? Remember, as little kids,

401
00:40:38,640 --> 00:40:43,280
baby, watch a baby, they just roam around, crawl around exploring their environment,

402
00:40:43,280 --> 00:40:48,720
putting things in their mouth. Yeah, this is how we learn. Okay, so the principle of free energy,

403
00:40:49,920 --> 00:40:54,960
you know, this is what basically our brains are doing. They're just minimizing the free

404
00:40:54,960 --> 00:40:59,840
energy the whole time. If there's uncertainty, we want to minimize it, right? That maybe that's

405
00:40:59,840 --> 00:41:03,760
what the best definition of intelligence is, minimizing uncertainty as quickly as possible

406
00:41:03,760 --> 00:41:09,760
and effectively as possible. Okay, how do we, you know, solve chemistry or physics or figure

407
00:41:09,760 --> 00:41:13,600
out the universe? Well, these are uncertainties, we're just trying to minimize them as quickly as

408
00:41:13,600 --> 00:41:18,560
possible. And it turns out the brain, we're not separate from the universe, okay, we're a physical

409
00:41:18,560 --> 00:41:24,080
system within the universe, which, you know, our environment. So, you know, they're interacting

410
00:41:24,080 --> 00:41:29,680
the whole time. So it's just physics, okay, basically, I say just in quotation marks. So

411
00:41:29,680 --> 00:41:34,240
you can write down equations for these interactions and how our system might minimize

412
00:41:34,240 --> 00:41:40,080
this free energy in the areas that's called first and I mean,

413
00:41:44,320 --> 00:41:50,560
we could listen to him for two seconds.

414
00:42:30,080 --> 00:42:56,320
So I guess technical quite quickly, a lot to do with probability, Bayesian influence,

415
00:42:56,320 --> 00:43:03,040
he mentioned the word influence. Yeah, so the brain, it's always, there's always sensory input,

416
00:43:03,040 --> 00:43:07,920
right? Even when we're sleeping, you know, we have dreams, there's subconscious, there's conscious,

417
00:43:07,920 --> 00:43:14,640
I mean, you know, there's internal sensory perception that is perception from our environment.

418
00:43:15,600 --> 00:43:20,400
You know, there's mental illness, schizophrenia, where the information processing goes awry.

419
00:43:21,360 --> 00:43:25,520
You know, it's a complex system, there's 100 billion neurons all different parts, layers upon

420
00:43:25,520 --> 00:43:30,960
layers, it's true evolution. The neocortex is what enables us to come up with things like

421
00:43:30,960 --> 00:43:35,920
a theory of relativity and build cars and, you know, solve physics and chemistry problems and

422
00:43:35,920 --> 00:43:41,280
mathematics. So yeah, it's a complex system, but it's basically a system that's based on the

423
00:43:41,280 --> 00:43:46,080
free energy principle, which you heard Professor Friston explaining a little bit there. That's

424
00:43:46,080 --> 00:43:50,880
what it looks like in a diagram. These other guys like Schmidt-Huber, they have their own systems,

425
00:43:50,880 --> 00:43:55,280
but I think they will all basically boil down to, you know, the free energy principle,

426
00:43:56,000 --> 00:44:00,640
the equations, you know, they look kind of similar. They may use different terminology

427
00:44:00,640 --> 00:44:05,440
vocabulary, but physics is physics, right? Okay, so they're all trying to model a physical system

428
00:44:05,440 --> 00:44:11,760
called the brain. Right, so we have external states, internal states, and there's only a few

429
00:44:11,760 --> 00:44:17,680
more slides now. And something called Markov-Lanker, which kind of delineates the two, the internal

430
00:44:17,680 --> 00:44:24,480
from the external environment, but there's no real, you know, there's no fixed thing, right? I mean,

431
00:44:24,480 --> 00:44:29,920
things enter and we take action, enter our brain and we take action, right, all the time. We're

432
00:44:29,920 --> 00:44:36,320
always interacting with our environment throughout pores and our skin. There is no fixed line,

433
00:44:36,320 --> 00:44:43,120
but it's a theoretical construct to help us through the max. Okay, and it's completely

434
00:44:43,120 --> 00:44:49,440
general. It works for cells. Cells are intelligent. They reproduce, you know, they survive in their

435
00:44:49,440 --> 00:44:57,840
environment right up to brains. Okay, and this is the math, pretty ugly. Okay, so last few slides.

436
00:44:57,840 --> 00:45:03,200
Can we build general intelligence? Okay, very clever math. These guys might end up getting

437
00:45:03,200 --> 00:45:08,080
Nobel Prizes and whatnot, because, you know, one could argue it is maybe the defining problem about

438
00:45:08,240 --> 00:45:13,600
time, right? Build intelligence, you know, solve climate change, solve cancer, build intelligence,

439
00:45:13,600 --> 00:45:19,120
you know, these are the big problems. If someone solves it and builds the system, you know,

440
00:45:19,120 --> 00:45:23,920
they're going to get a lot of money and a lot of prizes. So, I mean, a lot of these guys have a

441
00:45:23,920 --> 00:45:30,640
super lot of recognition already if you're in the field. So, and, you know, it's a combination of,

442
00:45:30,640 --> 00:45:34,880
like I showed before, computer science, so a lot of them are computer science, physics,

443
00:45:34,880 --> 00:45:40,560
and neuroscience. So, a lot of them are neuroscientists, but some are more computer science, but

444
00:45:40,560 --> 00:45:44,960
with a little neuroscience, some are neuroscientists with a little computer science, you know,

445
00:45:44,960 --> 00:45:49,520
a little physics. But yeah, the one thing is they're all really, really good at math. Okay,

446
00:45:49,520 --> 00:45:56,800
so can we build? The answer is yes. We have candidate theories. We have some algorithm

447
00:45:56,800 --> 00:46:02,320
software, some math. We have the hardware now, and we have masses of data sets. So,

448
00:46:03,280 --> 00:46:09,280
when, right, basically, the question is, how about if it's when? It's going to be like a

449
00:46:09,280 --> 00:46:13,600
TensorFlow for general intelligence, just to kind of touch base with something we're familiar with.

450
00:46:14,160 --> 00:46:18,720
And we're going to need a lot of software engineers to actually build these systems

451
00:46:18,720 --> 00:46:23,920
and hardware engineers to build the neural network processors. It's a big project. I mean,

452
00:46:23,920 --> 00:46:27,280
the human brain project, you know, is an Apollo project of our time.

453
00:46:27,280 --> 00:46:33,760
You know, it's going to require funding. There's a lot of funding going into this stuff at the

454
00:46:33,760 --> 00:46:39,680
moment. And you've got the human brain project, DeepMind, you've got the US brain project, China's

455
00:46:39,680 --> 00:46:44,960
working on this, everyone's working on it. Should we build AGI? Again, that comes back to the

456
00:46:44,960 --> 00:46:52,320
philosophy, philosophical question, you know, safety, ethics, singularity. But that's for another

457
00:46:52,320 --> 00:47:00,000
time. Okay, so here are some AGI projects I mentioned from countries all over the world,

458
00:47:00,000 --> 00:47:07,680
all very, very viable projects, in my opinion, all of them. No clear winner. All good stuff.

459
00:47:09,040 --> 00:47:16,160
Okay, so in conclusion, it's obvious that deep learning is lacking the foundations to build

460
00:47:16,160 --> 00:47:21,600
general intelligence. It's based on statistics, not physics. It's a statistical hack. It's very

461
00:47:21,600 --> 00:47:27,120
clever. But it takes a million times as much energy as the brain to do, you know, about one

462
00:47:27,120 --> 00:47:32,160
percent of what the brain does. So clearly, that's a no. Research groups are looking into

463
00:47:32,160 --> 00:47:39,120
bio plausible models. That's the way to get there. That's, you know, in terms of theory and hardware.

464
00:47:39,680 --> 00:47:45,840
So the real question is when, right? So we've got prototypes now, Schmidt-Huber,

465
00:47:45,840 --> 00:47:51,760
you know, he's building stuff, commercializing it. Oh, Friston, you know, has a huge code base,

466
00:47:52,400 --> 00:47:57,200
you know, hundreds of papers. So we were on our way. We're at the beginning of an

467
00:47:57,200 --> 00:48:04,560
exponential curve, I'd say, right? So yeah, it's not a when, it's not a defining moment. It's a

468
00:48:04,560 --> 00:48:08,640
continuum. We're at the beginning. We've got a, we've got a billion neurons,

469
00:48:09,280 --> 00:48:13,680
artificial neurons in a human brain project. We've got the brain of a mouse that could do

470
00:48:13,680 --> 00:48:18,320
Sudoku puzzles that can solve stuff that humans can solve that deep learning would never be able

471
00:48:18,320 --> 00:48:24,560
to solve at a thousand times less energy. So we've got the hardware that's on its own Moore's law.

472
00:48:25,760 --> 00:48:31,680
And what else? So finally, even Jeff Hinton, he's a godfather of deep learning, right? Won

473
00:48:31,680 --> 00:48:39,360
a Turing Award with Jan Lacoon and Yoshua Benjo last year for deep learning. He's saying, assuming,

474
00:48:39,360 --> 00:48:44,880
you know, he knows as much about anybody about deep learning. He's one of the founders. Assuming

475
00:48:44,880 --> 00:48:48,800
that the computer industry can keep producing better hardware, I think business issues are

476
00:48:48,800 --> 00:48:53,600
going to take us a long way. He's talking about the TPUs, the Graphcore, all of that. Obviously,

477
00:48:53,600 --> 00:49:00,160
if we get the big conceptual breakthroughs, probably from neuroscience, it'll take us further. I think

478
00:49:00,240 --> 00:49:03,840
one of the big breakthroughs that's going to come is we're going to understand the brain.

479
00:49:04,880 --> 00:49:10,720
Yeah, it's all about understanding how nature has done it. And nature is used to laws of physics.

480
00:49:10,720 --> 00:49:20,640
And Carl Friston, this act of inference, formulates that beautifully in some beautiful mathematics.

481
00:49:30,160 --> 00:49:55,280
Okay, so was this your final word? Can we move on to questions?

482
00:49:56,160 --> 00:50:07,360
Yeah, so any questions? Thank you. Okay, we have a few questions. It was a really enthusiastic

483
00:50:07,360 --> 00:50:14,080
speech of yours. And so these are the questions. If we managed to create artificial general

484
00:50:14,080 --> 00:50:23,760
intelligence, what would be the odds of the AGI being sentient? Yeah, so that will fall out naturally.

485
00:50:24,160 --> 00:50:30,400
So sentience is part of intelligence. Remember the types of intelligence? So that's the existential

486
00:50:30,400 --> 00:50:38,320
part. That's what that meant. So yeah, they have to be sentient. Okay, they have to be sentient.

487
00:50:39,040 --> 00:50:43,040
I mean, first of all, we'll build ape-like intelligence. Apes are sentient, right? They

488
00:50:43,040 --> 00:50:48,160
know what's going on in that level. Okay, so they will be sentient. And as we get more and more

489
00:50:48,160 --> 00:50:53,600
intelligent, they'll become more and more sentient. Yeah, we haven't seen that movie here. That's a

490
00:50:53,600 --> 00:51:00,400
beautiful movie with Joachim Phoenix. Have you seen it here? The thing on the iPhone gets smarter

491
00:51:00,400 --> 00:51:06,640
and smarter, more and more sentient until it goes off into its hyper universe somewhere. I mean,

492
00:51:06,640 --> 00:51:11,200
that's the kind of thing. It will start kind of like human level, ape level, then get the human

493
00:51:11,200 --> 00:51:18,480
level, but then go into, you know, they'll be more sentient than us. Okay, and together with this

494
00:51:18,480 --> 00:51:25,120
question, if it grasps the concept of the humor, it controls us by giving us false predictions.

495
00:51:25,680 --> 00:51:31,440
Can you trust it and secure it? Is that slavery? Yeah, so that's a good question too.

496
00:51:31,440 --> 00:51:35,920
No, they'll have rights like us, right? Just like, you know, there's animal rights,

497
00:51:35,920 --> 00:51:43,040
animal cruelty is a no-no, right? You go to prison if you harm an animal, right? It's not right.

498
00:51:44,080 --> 00:51:48,800
So yeah, that comes down to ethics and law. Yeah, they'll have their own rights.

499
00:51:52,240 --> 00:51:53,040
They will have rights.

500
00:51:53,040 --> 00:52:08,000
Okay, and okay, what do you think about artificial intelligence in drug design?

501
00:52:10,080 --> 00:52:15,600
Yeah, so it's going to help a lot. So right now we took a question because we're using deep learning

502
00:52:15,600 --> 00:52:22,960
to help us discover drugs to explore the chemically molecular dynamic space

503
00:52:23,920 --> 00:52:27,840
much quicker than we can if, you know, we do it ourselves. Okay, so deep learning is actually

504
00:52:27,840 --> 00:52:32,800
accelerating drug discovery right now. Okay, the idea is to accelerate it even further by

505
00:52:32,800 --> 00:52:38,080
using an artificially journal intelligence system. So yes, right now deep learning is

506
00:52:38,080 --> 00:52:42,480
absolutely accelerating drug discovery and has witnessed in the deep mind-winning,

507
00:52:42,960 --> 00:52:46,960
particular in competition recently, which is, you know, molecular dynamics, which is

508
00:52:46,960 --> 00:52:54,560
similar to drug discovery. Okay, so there's just one comment. A lot of science fiction's work have

509
00:52:55,360 --> 00:53:01,680
gave rise and inspiration to many great technologies and research. So they want to know

510
00:53:02,480 --> 00:53:08,640
which science fiction or any other general books have gave you inspiration and helped

511
00:53:08,640 --> 00:53:11,680
you shape yourself towards the professional that you are today?

512
00:53:13,680 --> 00:53:18,720
Yeah, so science fiction is, you know, when I was younger, I always read science fiction and

513
00:53:18,720 --> 00:53:25,680
watched Star Trek, you know, huge science fiction fan, really. So yeah, I mean, as the most foundation

514
00:53:25,680 --> 00:53:32,800
series, Robert Heinlein, Isaac Asimov, Arthur C. Clarke, those are kind of the, but yeah, there's

515
00:53:33,120 --> 00:53:38,720
new guys around right now with, you know, different science fiction series. Always good

516
00:53:38,720 --> 00:53:45,840
for the imagination to read science fiction. There's nothing wrong with the fact that it's

517
00:53:45,840 --> 00:53:51,120
encouraged, right, to, science fiction is a great thing. That's, you know, it's the start of all

518
00:53:51,120 --> 00:53:59,200
sciences in science fiction. So yeah, you can encourage it. Okay. And if we ever reach artificial

519
00:53:59,200 --> 00:54:05,680
general intelligence, do you think laws would be implemented on time, or we would firstly see

520
00:54:05,680 --> 00:54:12,080
abuse of artificial general intelligence in daily life? You partially gave the answer on this.

521
00:54:13,360 --> 00:54:17,280
Yeah, so, you know, there's always going to be good actors and bad actors, right? So yeah, we're

522
00:54:17,280 --> 00:54:21,920
going to have to come up with laws and try to find ways of enforcing it. There's going to be some

523
00:54:21,920 --> 00:54:27,120
silly things happen, of course, you know, decide with nuclear energy, right? Very, all very powerful

524
00:54:27,120 --> 00:54:32,960
technologies can get misused by bad actors. And so we are, we're going to have to keep an eye out

525
00:54:32,960 --> 00:54:38,560
for that. We have to enforce it. We have to have police at that point, right? Yeah, of course.

526
00:54:39,200 --> 00:54:48,400
And the last final question, as far as I can see, how, oh, okay, one more. Okay, how artificial

527
00:54:48,400 --> 00:54:56,960
general intelligence could affect religions? What's that? Okay, how the artificial general

528
00:54:57,200 --> 00:55:03,440
intelligence could affect religions? Oh, yeah, so I did mention that, I think

529
00:55:04,480 --> 00:55:11,200
sentient being will have the capacity for religion and religious and spirituality and all that good

530
00:55:11,200 --> 00:55:19,520
stuff. You know, so yeah, it just comes along with a religion. It's a type of intelligence,

531
00:55:19,840 --> 00:55:25,120
intelligence is a type of intelligence. Yeah, of course. Okay, as far as I can see,

532
00:55:25,120 --> 00:55:33,040
that those are all questions, but we'll wait a few minutes more. Thank you so much for answers and

533
00:55:33,040 --> 00:55:39,600
for this presentation and being with us tonight. It was really enthusiastic and inspiring to watch

534
00:55:39,600 --> 00:55:49,040
this and to understand it a bit more. So we really thank you. Thank you so much, me and all the people

535
00:55:49,120 --> 00:56:00,080
from Foundation. Sure, I look forward to watching it on YouTube. Yeah, and we hope to collaborate

536
00:56:00,080 --> 00:56:07,440
again with you, of course. So thank you so much. There are no more questions, so I would call it.

537
00:56:08,960 --> 00:56:16,240
And okay, thank you everyone for watching. See you on the next webinar.

