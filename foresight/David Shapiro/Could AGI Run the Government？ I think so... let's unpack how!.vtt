WEBVTT

00:00.000 --> 00:08.080
AI run the government. So this question actually came from one of my patreon supporters. So thank you spectral Valkyrie for this question

00:08.720 --> 00:15.360
But basically the idea was okay rather than just look at the way things are and look at incremental changes from

00:15.600 --> 00:22.440
Where we're at to a potential future. What if we just take a first principles look at could the AI run the government?

00:22.440 --> 00:23.960
What would that look like?

00:23.960 --> 00:31.440
So before we dive in I just wanted to let you know this video is a little bit longer and it's broken down into three distinct parts

00:31.600 --> 00:35.800
So the first part is we will talk about what is the purpose of government in general?

00:36.360 --> 00:42.320
And that will kind of set the stage because there is quite a bit of debate over what the role of government is or should be

00:42.320 --> 00:44.320
And it's mostly in terms of degrees

00:44.880 --> 00:49.160
So anyways, we'll get into that in just a moment then in the in the middle part

00:49.160 --> 00:55.440
We will talk about what would an AI government actually look like how is that actually going to function?

00:55.440 --> 00:58.440
How would it run and then finally in the last part of the video?

00:58.440 --> 01:04.720
I will make some actual real predictions based on things that I know are happening today and things that are in the works and

01:05.280 --> 01:09.520
So we'll see kind of what what the actual progress should look like

01:09.520 --> 01:13.040
So if any one of these parts doesn't resonate with you feel free to skip ahead

01:13.680 --> 01:15.680
But yeah, let's get right into it

01:15.800 --> 01:21.540
So the first thing that we need to say is okay. What is objectively speaking? What is the outcome?

01:21.680 --> 01:24.760
What is the function that government provides and right now?

01:25.080 --> 01:32.280
There are kind of five key pillars that government provides and there's there the biggest one that's missing is military

01:32.920 --> 01:38.440
but what I will say is that the military can operate as a separate entity from government and in fact in many

01:38.680 --> 01:45.040
In many institutions it kind of does it's technically an extension of the executive branch, but it is also supposed to have

01:45.680 --> 01:52.280
Its own thing. So that is deliberately and distinctly missing. So we're looking more at domestic government

01:52.360 --> 01:57.760
So domestic government focuses on these five key principles. So first is resource management

01:59.400 --> 02:04.960
Regulating public goods and natural resources for sustainability that sort of thing. So land use

02:06.200 --> 02:08.200
Waterways air that sort of stuff

02:09.160 --> 02:11.080
forests, you know

02:11.080 --> 02:12.440
Drilling rights

02:12.440 --> 02:18.560
The second thing is economic management. So this is fiscal and monetary policy. So this has to do with central banks

02:19.440 --> 02:26.880
Regulating the stock market that sort of stuff, you know, again, you're familiar with all these because we argue about it every few years here in America

02:27.280 --> 02:29.280
based on who we want to elect

02:29.400 --> 02:31.400
the third pillar is

02:31.880 --> 02:36.480
Mediation of relationships. So this is facilitating and mediating the relationships between

02:37.320 --> 02:45.000
Citizens nations organizations so on and so forth. And so there's a few ways that these regulations happen or that this this mediation happens

02:45.120 --> 02:51.760
So first is like corporate law. So ensuring that, you know, companies abide by safety regulations that sort of thing

02:51.760 --> 02:56.640
There's also the courts. So like if you have a dispute with someone else, there's criminal court. There's civil court

02:57.040 --> 02:59.040
That sort of thing. There's the Supreme Court

02:59.680 --> 03:05.160
So the court system is as part of this relationship mediation. It's it's there to broker or referee

03:06.120 --> 03:12.440
Relationships between various stakeholders in the government namely citizens businesses and then other nations

03:12.480 --> 03:16.640
So the diplomatic corps the State Department as we call it in America

03:17.200 --> 03:25.560
That is part of the relationship mediation. So the government manages our relationship with say Britain or France or China on our behalf

03:26.640 --> 03:30.680
The fourth thing is that they guarantee and protect and enforce rights

03:30.840 --> 03:34.240
And so there's this is a recent term

03:34.240 --> 03:38.120
So I've been plugging it a lot that I learned positive rights versus negative rights

03:38.360 --> 03:45.560
So a positive right is something that you're entitled to and a negative right is something that you were free from and so for instance our

03:46.360 --> 03:47.720
Constitution

03:47.720 --> 03:55.000
Guarantees that you are entitled to a right to free speech. You are entitled to a jury by your peers. You are entitled to

03:55.960 --> 04:01.160
A certain other things plenty of other things, but then you're also free from

04:02.080 --> 04:05.880
Tyranny, you know free to free from oppression and those sorts of things

04:06.400 --> 04:10.480
And so there's two different kinds of rights and of course there it as I mentioned earlier

04:11.040 --> 04:16.680
It is also a matter of degree because many of your rights are relatively simple

04:16.680 --> 04:23.560
But then we're there's also debate over more complex or comprehensive rights and then finally social organization

04:23.600 --> 04:25.920
And so this is one of the most controversial ones

04:26.680 --> 04:28.680
Especially if you look at the news right now

04:28.680 --> 04:33.560
The state of Texas is all up in arms about abortion rights. So again

04:34.280 --> 04:36.280
talking about social organization

04:36.480 --> 04:42.400
By and large western liberal democracies have decided not to legislate morality

04:42.920 --> 04:47.560
And you can see this by virtue of contrast when you look at the fact that like

04:48.120 --> 04:49.440
There is some

04:49.520 --> 04:55.040
TikTok celebrity who got arrested I think in Saudi Arabia for adultery like we don't do that in the west anymore

04:55.040 --> 05:01.600
We don't say like oh well this woman, you know had sex with someone that she wasn't supposed to so therefore we're gonna put her in morality jail

05:02.320 --> 05:04.000
Right, there was huge

05:04.000 --> 05:07.680
protests that broke out in Iran because a woman was beaten by the morality police

05:08.240 --> 05:12.960
And so by and large western democracies the the role of legislating

05:13.680 --> 05:15.680
morality and social structure

05:16.080 --> 05:21.840
Is contracting however government does still play a role in this and so what I mean by that is

05:22.880 --> 05:25.680
You know what what are legally recognized marriages?

05:26.160 --> 05:30.000
What are the family structures that are legally recognized and so right now

05:30.640 --> 05:34.400
Western liberal democracies have have kind of centered around the nuclear family

05:34.800 --> 05:38.480
Or the the smallest family unit, which is the marriage between a husband and a wife

05:38.880 --> 05:41.840
Whereas in the past there were you know, usually it was

05:42.800 --> 05:49.120
Uh, you know tribal communities or extended families where you'd have a matriarch or a patriarch who kind of managed the whole family

05:49.120 --> 05:52.960
And that was the legal unit and there are still plenty of countries out there where

05:53.680 --> 05:56.960
If not in law then at least in practice that is how things are run

05:57.280 --> 06:01.680
And so the government does have a role in supporting that social organization

06:02.000 --> 06:08.320
Then there's also other aspects of it such as the relationship between the government and the fourth estate, which is journalism

06:08.960 --> 06:10.960
Or or the church as well

06:11.280 --> 06:14.240
So those are kind of the five main pillars of government

06:14.240 --> 06:18.880
Like I said, there are plenty of other things from that list that are missing that is on purpose

06:18.880 --> 06:21.600
But these are kind of the five pillars that I want to look out for this video

06:22.240 --> 06:23.760
so also

06:23.760 --> 06:31.280
As I as I promised a lot of this is controversial and this goes back to even the founding of modern democracy where socrates himself

06:31.840 --> 06:35.040
questioned the the efficiency and wisdom of democracy

06:35.600 --> 06:37.600
so some of his

06:37.680 --> 06:43.040
Critiques were and of course this is back in the days of athens before representative democracy

06:43.680 --> 06:46.640
So most of what he was complaining about was tyranny of the majority

06:47.600 --> 06:51.600
Also, i'm really toasty. So i'm gonna switch clothes. Oh, okay properly dressed now

06:52.320 --> 06:56.800
but yeah, so socrates was concerned about tyranny of the majority

06:57.760 --> 06:58.640
and

06:58.640 --> 07:00.160
there's also

07:00.160 --> 07:02.720
the what we would today call like, you know

07:03.360 --> 07:05.360
The kind of the difference between

07:05.520 --> 07:09.120
Inclusive democracy where everyone gets a say versus

07:09.760 --> 07:11.760
expertise and this is one of the chief

07:12.080 --> 07:13.440
tensions

07:13.440 --> 07:15.680
particularly in america but also in other nations

07:16.400 --> 07:17.680
because

07:17.680 --> 07:19.680
communism like capital c communism

07:20.240 --> 07:21.760
said, oh, well

07:21.760 --> 07:23.920
The citizen shouldn't have a vote because they're all dumb

07:24.640 --> 07:28.640
And so what we're going to do is we're just going to hand the reins to the quote-of-quote experts

07:29.200 --> 07:32.720
And then the experts without any checks and balances are going to get to make decisions

07:33.120 --> 07:38.080
And in soviet russia that led to mass famines because the so-called experts mismanage farms

07:38.480 --> 07:42.800
mismanage the economy and that sort of thing and that by the way still goes on today. There are

07:43.520 --> 07:48.320
I was watching a documentary about how um, there there are places in china that you still can't grow

07:49.520 --> 07:52.880
food because of decades of communist mismanagement

07:53.200 --> 07:58.880
On the other hand, uh, your average citizen is also not necessarily qualified to make decisions

07:59.200 --> 08:01.920
So you you're kind of damned if you do damned if you don't

08:02.320 --> 08:07.200
Now what I wanted to include this slide for was to say that there are flaws with democracy

08:07.680 --> 08:11.520
I would say that there are more egregious flaws particularly with every way that

08:12.080 --> 08:16.880
Communism has been implemented and so I am not a communist. I'm not a socialist even though some of you accuse me of that

08:17.120 --> 08:20.480
I also have people say that I'm a neoconservative. So make up your minds

08:20.480 --> 08:26.480
Make up your minds. I consider myself a pragmatic progressive, but anyways, that's a conversation for another

08:26.960 --> 08:28.960
uh, another topic

08:29.520 --> 08:30.960
So let's move let's move on

08:30.960 --> 08:36.480
But I just wanted to address the elephant in the room and say that yes democracy is does have some fundamental flaws

08:36.800 --> 08:40.480
Going back to the founding of the thing the other component of

08:41.040 --> 08:47.120
That makes government hard is just intrinsic human flaws. And so one example is charismatic leaders

08:47.840 --> 08:52.560
So charismatic manipulators are able to use demagoguery and other things to

08:53.520 --> 08:57.040
you know, kind of get in and and you know wreck things

08:57.840 --> 08:59.520
power seeking behavior

08:59.520 --> 09:03.280
profit motivation plain old ignorance and so basically this all

09:03.920 --> 09:07.120
Speaks to the reason that government is structured as the way that is

09:07.680 --> 09:09.680
because the framers of

09:10.320 --> 09:14.080
modern western liberal democracies basically said, okay, well

09:14.800 --> 09:20.560
Uh, they didn't have the word for it, but they noticed that you know, uh, a non-trivial chunk of the population

09:21.040 --> 09:25.040
is just crazy. Um, whether they're narcissistic, whether they are

09:25.600 --> 09:28.080
um sociopaths, whether they are just

09:28.800 --> 09:30.800
completely saturated with greed

09:31.280 --> 09:32.320
um

09:32.320 --> 09:35.840
So they said, okay, well, we have to know that some people are going to be power seeking

09:35.840 --> 09:40.160
We have to know that some people are going to be manipulative and so on and so forth

09:40.400 --> 09:45.360
And so that's part of the reason that the government is structured the way that it is so that you have checks and balances

09:45.760 --> 09:48.640
So that you have these relief mechanisms that allow you to

09:49.600 --> 09:55.760
You know change up leadership on a regular basis, which in theory should prevent any particular

09:56.320 --> 10:00.080
Uh group or person from accumulating and holding on to too much power

10:00.480 --> 10:05.360
So far so good, but there are some people who very deliberately and explicitly want to upset that balance

10:05.920 --> 10:08.080
um because what happens is

10:08.800 --> 10:14.160
When you allow for the leadership, um at all levels to change up on a regular basis

10:14.560 --> 10:17.120
And you have this kind of as a mechanistic system

10:17.760 --> 10:18.720
um

10:18.720 --> 10:20.720
You prevent that accumulation of power

10:20.880 --> 10:25.520
But also you it's it becomes easier to spot people who are accumulating power

10:25.920 --> 10:29.920
Now, of course here in america, we have a problem of gerontocracy where we have people

10:30.480 --> 10:34.720
Literally serving until their 80s and 90s and in recent cases dying in office

10:34.800 --> 10:38.400
Even though they are not legally competent to take care of themselves

10:38.720 --> 10:41.360
So if someone is not legally competent to take care of themselves

10:41.360 --> 10:44.480
They are certainly not legally competent to run the the the nation

10:44.960 --> 10:50.480
But of course the uh the american system was framed before people were living long enough to have dementia

10:50.960 --> 10:52.960
So

10:53.280 --> 10:55.280
We got some work to do

10:55.600 --> 10:58.320
So that leads us to uh representative democracy

10:58.400 --> 11:02.560
So basically the way that it generally runs today is that we have a division of power

11:02.560 --> 11:06.720
We have a three branch system. So that's legislative judicial and executive branch

11:07.440 --> 11:11.280
The the the judicial branch is obviously like one of the weaker ones

11:11.760 --> 11:14.560
Except for the supreme court, which does kind of set a lot of the tone

11:15.440 --> 11:16.880
We use elected officials

11:16.880 --> 11:21.840
So the elected officials then you know represent our willpower and they appoint

11:22.400 --> 11:26.560
Experts um and then some of the sometimes we do vote on experts. Sometimes we don't

11:27.200 --> 11:31.680
Some officials some offices are appointed by the electorate. Some aren't

11:32.400 --> 11:36.880
But this is all part of the ongoing negotiation and part of the reason that it's so messy is because

11:37.280 --> 11:40.400
We're constantly making little adjustments to the whole structure

11:41.200 --> 11:47.680
Which is good because uh, you know, you look at revolutions of the past and one of the key thing one of the key reasons

11:48.240 --> 11:52.160
why civil wars have happened in the past is because

11:52.880 --> 11:55.280
And not even in the distant past in the recent past

11:55.760 --> 11:58.960
Is because the government is too rigid or too inflexible and does not

11:59.360 --> 12:05.600
Respond to the will of the people and the changing times. And so the the key thing is peaceful transitions

12:06.160 --> 12:09.360
Um, it's not just a matter of representing the will of the people

12:10.080 --> 12:15.040
Because if you wanted to create a government that was purely of the people for the people by the people

12:15.120 --> 12:17.840
It would look different from representative democracy

12:17.920 --> 12:24.880
But really what what what the uh what the framers particularly the other of the american system wanted to achieve was peaceful transition of power

12:25.600 --> 12:28.720
Because when you had monarchy you'd have wars of succession

12:29.440 --> 12:36.720
When you had the you know, basically most of europe being run by a single royal family and all their cousins and second cousins and fifth cousins

12:37.680 --> 12:42.640
You could still end up with major problems. See world war one and world war two

12:43.520 --> 12:47.120
Now obviously america was founded before that but there is oh man

12:47.440 --> 12:53.280
You listen to history like europe was just one constant set of wars for like 500 years

12:53.840 --> 13:01.200
Um, and then as I already mentioned incremental changes part the part of the goal of government is to allow for incremental changes

13:01.760 --> 13:06.240
Um, that is not necessarily steered uh exclusively by a controlling elite

13:06.640 --> 13:11.040
But that the will of the people can make incremental changes to the government itself

13:11.440 --> 13:15.840
Even the founding document, um, such as in our case a constitutional democracy

13:16.640 --> 13:21.280
And so the idea is that this is a gigantic system that is meant to

13:21.920 --> 13:26.480
Allow change but also resist change because you don't want the pendulum to swing too wildly

13:26.560 --> 13:29.360
You don't want to oscillate by correcting and then over correcting

13:29.760 --> 13:34.800
And so these are all the all the things that go into the purpose of government. Why is it here?

13:34.880 --> 13:36.880
Why does it work the way that it does?

13:36.960 --> 13:43.200
So this stands in stark contrast to single party systems such as what we see in china and russia, which they are

13:43.920 --> 13:47.840
Technically democracies because they they run quote-unquote elections

13:48.320 --> 13:54.560
Um, but most the elections are fixed and I think that it's not a controversial thing to say that they are not actually true democracies

13:54.960 --> 13:57.600
Or they are what I would call kind of a pseudo democracy

13:58.320 --> 14:00.320
Where it's got some of the dressings some of the trappings

14:00.800 --> 14:06.960
But you can when you consider that both putin and shijing ping were able to to manipulate the system so that they were lifelong appointees

14:07.280 --> 14:09.280
They basically made themselves kings

14:10.160 --> 14:15.200
So some of the characteristics that you see in single party systems are you get a monolithic structure

14:16.080 --> 14:22.160
That's by definition. The ccp is china china is the ccp. There isn't really any alternative

14:23.040 --> 14:29.760
While there are technically other, you know people that run against putin. They usually fall out of windows or end up getting poisoned

14:30.560 --> 14:32.880
So that's not necessarily a viable strategy there

14:34.000 --> 14:38.800
Part of the way that these regimes maintain control is they become more authoritarian over time

14:39.600 --> 14:44.720
And so that leads to things like information control both russia and china have state-run media

14:45.520 --> 14:50.480
So basically if you see a lack of state-run media that is usually a sign of a healthier democracy

14:50.720 --> 14:52.720
Which we'll talk about in just a second

14:52.880 --> 14:54.480
They do allow liberalization

14:54.480 --> 14:58.960
So this is one of the this is one of the things that kind of gave us hope after the collapse of the soviet union

14:59.280 --> 15:01.280
And after china's great leap forward

15:01.760 --> 15:04.000
Was that they eventually did allow for

15:04.880 --> 15:09.600
Some liberalization of the economy because they wanted the profits, but they didn't liberalize

15:10.160 --> 15:14.640
In terms of civil liberties in terms of voting rights and and government reforms

15:16.400 --> 15:20.480
And there are also pretty interesting cultural and historical roots

15:21.200 --> 15:27.280
As they kind of explain why this happens now you could look at places like japan and germany which did

15:28.080 --> 15:30.080
granted at the barrel at the

15:30.640 --> 15:34.080
Because guns were pointed at them after world war two. They were able to liberalize

15:35.280 --> 15:41.600
Very effectively now Japan still has the imperial family, but they're mostly just token, right?

15:41.680 --> 15:44.800
You know the japanese parliament runs the country

15:45.600 --> 15:50.400
Germany got a did away with everything and now they are you know fully fully liberalized democracy

15:50.800 --> 15:52.800
and so the argument that

15:53.040 --> 15:57.760
That single party systems inevitably emerge in some of these nations for historical and cultural reasons

15:58.080 --> 16:02.240
Doesn't necessarily stand up to scrutiny particularly when you look at the history of japan

16:03.120 --> 16:07.520
But they also had to lose a major war in order to have that that

16:08.240 --> 16:10.240
New democracy forced on them

16:10.480 --> 16:15.680
And of course that set the the tone for the rest of the 20th century and 21st century

16:16.160 --> 16:19.920
Where the western allies basically enforce and export democracy

16:20.560 --> 16:25.440
Onto other nations whether or not they want it which of course, that's what putin and shijin ping are pushing back against now

16:26.160 --> 16:29.840
Actually more explicitly. It's very interesting where they just basically have flatly said like

16:30.400 --> 16:35.360
We don't want your western values now. Do they do do they reflect the will of the people?

16:35.840 --> 16:40.800
Doesn't sound like it. I've interviewed some people from from other places not russia or china

16:41.040 --> 16:43.040
But I interviewed some people from syria

16:43.200 --> 16:48.080
And the the idea is that the more that they learn about western democracy the more that they want it

16:48.400 --> 16:50.880
Which is the reason that people like

16:51.600 --> 16:58.240
Putin and shijin ping need to resist information and need to poison their people against the idea of voting and power

16:58.240 --> 16:59.680
but that's

16:59.680 --> 17:03.760
That's why there is still ongoing conflict in syria is because

17:04.400 --> 17:08.800
People know they've seen greener pastures and they want it and they're going to keep fighting for it

17:09.680 --> 17:12.640
The fighting has tamped down, but syria is deeply fragmented right now

17:13.440 --> 17:15.040
so anyways

17:15.040 --> 17:20.080
That is the by virtue of contrast looking at a single party system or failed democracies

17:20.880 --> 17:26.320
Which there are some people that explicitly want to turn America into a single party system into all of you

17:26.400 --> 17:28.240
I say stop

17:28.240 --> 17:33.760
And then finally there is the the nightmarish central management or totalitarian regimes

17:34.960 --> 17:41.760
This is what you see in terms of fascism or old school communism where there wasn't any elections whatsoever

17:42.480 --> 17:44.480
farcical or otherwise

17:44.560 --> 17:47.520
North korea is is the current kind of prime

17:48.080 --> 17:53.680
Example of the the quote-unquote hermit kingdom where it is top-down authoritarian control

17:54.640 --> 17:56.640
And they regulate everything

17:57.120 --> 18:02.160
Apparently in north korea. They even regulate how much grieving you're supposed to do for the former dead leaders

18:02.960 --> 18:08.000
So that's not just a legislating morality. They're they're they're controlling emotions

18:08.400 --> 18:10.640
and apparently people have been set sent to like

18:11.040 --> 18:17.280
Reeducation camps for not grieving enough in public on their days of remembrance or whatever

18:17.840 --> 18:19.840
um these kinds of things they

18:20.080 --> 18:22.080
They're necessarily surveillance states

18:22.320 --> 18:29.520
Um extreme conformity is required and then and then any breach of conformity is deeply and severely punished

18:30.160 --> 18:31.760
Democracy is noisy

18:31.760 --> 18:34.720
This is one of the things that I think a lot of people don't understand

18:34.720 --> 18:39.840
Which is why I'm going through all this is because all the vitriol all the vicious debates about you know

18:39.920 --> 18:44.320
Trump versus biden or you know left versus right or you know, whoever

18:45.680 --> 18:47.840
Democracy is is noisy by design

18:48.720 --> 18:54.640
When you look at at a at a nation that you know say oh, we're we're perfectly aligned because they quash debate

18:55.520 --> 18:58.960
You're not allowed to criticize putin. You're not allowed to criticize

18:59.520 --> 19:03.920
Xi Jinping. You're not allowed to criticize the the kim jong-un

19:04.480 --> 19:05.520
Um

19:05.520 --> 19:12.240
So because of that those nations they appear more orderly they appear quieter. They appear to be

19:12.960 --> 19:19.040
Uh more in lockstep. However in america and india and britain and all these other places

19:19.440 --> 19:25.920
Where you have really vicious debates you have mud slinging you have you have muck raking you have all kinds of things

19:26.640 --> 19:28.640
And that is by design and so

19:29.200 --> 19:32.960
When you understand that that the ability to speak up that you know

19:32.960 --> 19:38.000
If you really don't like something in the west you can start a youtube channel or a tiktok channel and and

19:38.480 --> 19:42.080
Say, you know the president's an idiot and like I have zero fear of that

19:42.400 --> 19:46.560
Whereas like could you do that in china in russia in north korea?

19:47.040 --> 19:52.640
No, and of course those are just some of the most extreme examples. There are plenty of other oppressive regimes around the world

19:53.680 --> 19:56.320
and so because of that because debating is encouraged

19:56.640 --> 20:01.520
Because descent is tolerated because we can air our grievances. Now this uh,

20:02.080 --> 20:04.080
Allow us for a level of transparency

20:04.560 --> 20:08.160
But the flip side of that is that people don't get along all the all the time

20:08.560 --> 20:12.480
The fact of the matter is is that you know, you can say things that people disagree with

20:12.880 --> 20:17.280
And then you can get into internet debates or you know, choose your favorite talking head

20:17.360 --> 20:20.400
Which now I have joined the league of talking heads. So yeah, whatever

20:20.960 --> 20:22.000
Um

20:22.000 --> 20:26.960
But these are all features. This is a feature not a bug. That is the key thing is that if democracy is noisy

20:26.960 --> 20:29.440
That is a sign of a healthy democracy now

20:29.600 --> 20:33.840
You can also end up in situations where people kind of naturally agree

20:34.320 --> 20:38.720
Um, and so this is this is uh, you know, there was what was it called the era of good feelings?

20:39.200 --> 20:41.200
um, where america basically became

20:41.760 --> 20:45.120
By a default kind of a single party system for about 20 years

20:45.440 --> 20:49.520
But that was just because things were going well and there was nothing really to argue about and of course that is a

20:49.920 --> 20:51.920
gross oversimplification

20:52.320 --> 20:54.960
But that emerged naturally not by force

20:55.760 --> 20:57.760
whereas during

20:57.840 --> 21:01.840
Uh contentious times whether there are external threats internal threats

21:03.120 --> 21:05.120
Or social upheaval

21:05.120 --> 21:07.280
You should expect it to get a little bit nastier

21:07.520 --> 21:12.320
But again, that is part of democracy working itself out by having those ongoing debates

21:12.800 --> 21:18.720
And having those uh those ongoing dissenting opinions and airing those grievances and talking it out

21:19.440 --> 21:23.200
That is part of the process. That is that is that is a sign of things

21:23.680 --> 21:27.920
Uh progressing as as intended. So with all that being said

21:28.960 --> 21:31.280
What would an ai government look like?

21:31.920 --> 21:37.680
Because the thing is when you're when you're looking at all this it's not a matter of

21:38.160 --> 21:43.920
Machines just making decisions and enforcing it on us. That's a totalitarian regime, which we don't want

21:44.400 --> 21:46.400
what we really want is

21:46.720 --> 21:50.640
We want the messiness of what of democracy that we have today

21:51.040 --> 21:54.160
Because you know whenever I talk about universal ai values

21:54.160 --> 21:58.000
It's like well who gets to decide them and the answer is and this is kind of why I was like

21:58.400 --> 22:00.400
I was always confused by that retort

22:00.560 --> 22:06.000
Um, but I understand it better is because we do we get we the people get to decide what values

22:06.320 --> 22:10.080
We ultimately want to live by now. There's of course

22:10.080 --> 22:12.480
There's always a contingent of people who want to enforce

22:12.960 --> 22:16.320
Their particular values on everyone because they don't understand

22:16.880 --> 22:20.480
Uh the history of democracy or why things are the way they are like for instance

22:20.480 --> 22:24.640
Whenever someone says america is a christian nation and we all need to have more christian law

22:25.040 --> 22:28.480
That is indistinguishable from muslims who want to impose

22:28.960 --> 22:31.680
Sharia law on everyone else. So stop doing that

22:32.400 --> 22:36.880
The idea is freedom and equality are the highest principles that we have agreed on

22:37.680 --> 22:41.920
And so then it's a matter of creating a container that allows for

22:42.480 --> 22:46.320
Different approaches to life now some people do not tolerate

22:47.040 --> 22:51.680
Differences they don't tolerate differences of religion or of opinion or values or beliefs

22:52.080 --> 22:56.880
And those people are just wrong. That's not how democracy works. That's not how

22:57.600 --> 22:59.600
Inclusive tolerant societies work

23:00.720 --> 23:06.640
So this thought experiment then is okay, let's just assume that ai has the capacity to run

23:07.120 --> 23:11.520
The government let's let's just imagine a year from now when we have a gi and it's

23:12.080 --> 23:17.280
And it's performing above human level on all benchmarks. It's in the 99.9th percentile

23:18.400 --> 23:21.920
Or higher for like literally every cognitive ability

23:22.320 --> 23:26.960
We've got you know advanced robots that can do stuff and the ultimate goal is

23:27.680 --> 23:30.320
What if we just removed humans from the government?

23:31.040 --> 23:32.240
wholesale

23:32.240 --> 23:37.120
Like let's go full monty because this is this is what my patreon supporter was like like no, let's

23:37.840 --> 23:40.240
Not beat around the bush. Let's just go full monty and see what

23:40.800 --> 23:45.600
Like what would this require what what are the challenges and how would it actually work?

23:45.760 --> 23:49.680
So let's dive into some of the components that would make this happen

23:50.320 --> 23:57.200
So the first thing that we need to do is use ai whether it's a combination of existing, you know machines and and

23:57.440 --> 24:01.760
Databases and stuff combined with large language models combined with deep multimodal models

24:02.800 --> 24:04.960
We need to survey the will of the people

24:05.600 --> 24:07.600
whatever else is true

24:07.760 --> 24:12.240
The one of the chief purposes of government is to reflect the will of the people now

24:12.720 --> 24:16.000
Right now the primary way we have to do that is through voting

24:16.400 --> 24:22.800
That is the primary mechanism that we have to express our will where it's you know every so often

24:23.200 --> 24:25.200
We get to go pick a person

24:25.280 --> 24:32.240
Who who we feel represents our desires and beliefs and then we go and hire them via election

24:32.720 --> 24:38.240
To go represent our desires our values our beliefs in the process of government

24:39.040 --> 24:45.120
But if you remove all humans, then it's not necessarily electing a representative. You have to express your will

24:46.160 --> 24:47.520
Some other way

24:47.520 --> 24:51.200
Now that doesn't mean that you don't you get rid of voting. Maybe you have more voting

24:51.840 --> 24:53.840
But this goes back to socrates complaint

24:54.160 --> 24:58.400
Which and I know elan musk is one of the people who said oh direct democracy makes sense

24:58.640 --> 25:04.160
It absolutely doesn't you do not want to live in a direct democracy because then you have tyranny of the majority

25:04.880 --> 25:06.880
And that can get real bad real fast

25:07.600 --> 25:08.720
however

25:08.720 --> 25:10.720
by combining

25:10.720 --> 25:14.480
You know existing online platforms leveraging new technologies

25:15.040 --> 25:18.320
Using large language models and semantic clustering and all sorts of stuff

25:18.880 --> 25:25.120
I suspect that we could easily build a platform a democratic platform that very very

25:26.000 --> 25:29.120
comprehensively collects and understands the will of the people

25:29.760 --> 25:33.120
Um, and then what do you do with that information? We can figure that out later

25:33.920 --> 25:40.400
But rather than just picking a person because also remember go back to the slide that I did about fundamental human flaws

25:40.880 --> 25:42.880
power seeking avarice

25:42.960 --> 25:44.720
plain old ignorance

25:44.720 --> 25:49.680
You get rid of those if you get rid of people now you introduce new problems if you replace people with machines

25:49.840 --> 25:56.080
But the point is is that if we can directly express our willpower through some mechanism

25:57.040 --> 26:02.720
You know maybe with a combination of blockchain voting and artificial intelligence and a few other things

26:03.280 --> 26:09.200
Then the then the machine apparatus of government will at least be aware of what we the people want

26:09.520 --> 26:13.360
So that's step one. We need something that allows us to

26:14.000 --> 26:16.240
Express our will and allows it to be recorded

26:16.960 --> 26:18.960
and accurately measured

26:18.960 --> 26:21.600
So that then the ai government can then use that

26:22.960 --> 26:28.160
Another component of this is ongoing negotiations. So like I said democracy is noisy by design

26:28.800 --> 26:30.800
but if you get rid of

26:30.800 --> 26:32.560
individual, you know

26:32.560 --> 26:36.080
Politicians then you don't have conventions. You don't have town halls

26:36.640 --> 26:39.680
So then who are you talking to? Who do you write letters to?

26:40.400 --> 26:42.400
and this is again where the

26:42.880 --> 26:44.880
collecting the will of the people

26:44.960 --> 26:50.960
Is not just about okay. The people have expressed their desire on this particular issue now the machine goes and does it

26:51.280 --> 26:55.840
It is an ongoing conversation. It is an ongoing negotiation and renegotiation

26:56.480 --> 27:03.120
As the situation changes as our understanding changes as consensus changes and so on and so forth

27:03.760 --> 27:05.760
And so part of the of the government

27:06.160 --> 27:12.640
What it does today is, you know, the the the white house has their, you know, their press corps and politicians have their

27:13.120 --> 27:14.800
public relations managers

27:14.800 --> 27:16.800
So we basically need the same thing

27:17.280 --> 27:22.160
But with various ai components kind of saying this is what we're doing and this is why and

27:22.720 --> 27:26.240
Like here's a here's a chance for feedback. We need to disseminate ideas

27:26.800 --> 27:28.400
resources and that sort of stuff

27:28.480 --> 27:34.240
Oh, and one thing that I should point out is that I'm not necessarily thinking that one monolithic ai is the right way to go

27:34.720 --> 27:38.800
Because from a narrative perspective, that's easier to say like, you know, the ai

27:39.360 --> 27:40.880
But really I think that

27:40.880 --> 27:47.520
Um, if we were to replace government with ai, it should be probably millions of individual ai agents all working together

27:48.160 --> 27:50.160
That are individually transparent

27:50.160 --> 27:52.480
Um, hence the swarms that we've been working on

27:53.120 --> 27:56.960
Um, anyways, so getting back to the slide, uh, you know

27:57.040 --> 27:59.040
There needs to be constant feedback

27:59.360 --> 28:00.960
between

28:00.960 --> 28:07.360
You know the people and the ai government and as well as, you know, I mentioned consensus, but it's basically

28:08.240 --> 28:09.280
debate

28:09.280 --> 28:14.000
Discussion negotiation dialogue consensus. Those are all kind of the same thing

28:14.000 --> 28:18.240
But it the the the key takeaway is that it needs to be a two-way conversation

28:18.640 --> 28:20.640
It's not just a unilateral

28:21.040 --> 28:24.800
The will of the people gets expressed and then the ai government goes and does that

28:25.040 --> 28:30.080
That's not exactly the way that it works and that's not that's by that's by design. That's not how representative democracy works

28:30.480 --> 28:34.480
It's we express our will and then the professional politicians ideally

28:34.880 --> 28:37.840
Go and do their best to accommodate that

28:38.080 --> 28:42.320
But of course, you know, our politician goes to battle with other politicians and so on and so forth

28:42.880 --> 28:44.240
likewise

28:44.240 --> 28:47.360
You know, we the people express our will to an ai government

28:47.680 --> 28:53.680
And it will do the best that it can to implement that willpower within the constraints within the boundaries of

28:54.560 --> 29:00.720
The way that other people, you know, want things to go as well as other higher universal principles such as

29:01.200 --> 29:05.680
enshrining, you know equality and freedom above all else above, you know

29:05.760 --> 29:10.240
As an example above a religious theocracy another thing that it's going to need is

29:10.880 --> 29:12.880
mechanisms for change so

29:14.320 --> 29:15.440
as

29:15.440 --> 29:17.440
Western liberal democracies work today

29:17.760 --> 29:20.240
Incrementalism is the name of the game

29:20.640 --> 29:24.480
You can make changes to literally every aspect of the government

29:24.960 --> 29:28.000
piece by piece starting with the constitution and there are

29:28.560 --> 29:33.440
Mechanisms there that allow for that change, which is why I gave this like little transformer dude

29:33.760 --> 29:37.840
Because you know, it's like it looks like a modular robot or whatever. So that's it's supposed to be an allegory

29:38.560 --> 29:41.200
But when you have an ai government, you don't want it to be rigid

29:41.200 --> 29:45.360
You don't want it to be like, okay, once you implement it once it's that way forever

29:45.360 --> 29:48.320
No, you literally want every piece of the stack

29:48.960 --> 29:51.200
To be changeable to be plastic

29:51.920 --> 29:57.760
And so that means all the models that the agents use the hardware the software and that's just the system itself

29:58.240 --> 30:02.480
Then all the policies that the system uses the technology stack that it uses

30:02.960 --> 30:06.160
The principles that it abides by so, you know, if you've watched my channel

30:06.160 --> 30:09.600
You know that I'm a big fan of like universal declaration of human rights

30:09.840 --> 30:13.360
I'm also a big fan of of the heuristic imperatives that I created

30:13.680 --> 30:18.080
But those need to be part of what is negotiated that needs to be part of

30:18.640 --> 30:22.400
What is changeable now, obviously the core values the core principles

30:22.880 --> 30:26.160
You need to be really, you know, darn sure that you want to change those

30:26.800 --> 30:33.600
And it's also not necessarily something that you want to direct democracy on because one you might never get it passed

30:34.560 --> 30:36.560
But you do want everyone to have a say

30:37.120 --> 30:38.960
In the process

30:38.960 --> 30:42.320
So that's one thing that I think some people are not familiar with

30:42.960 --> 30:48.000
When looking at government systems and it's not necessarily a vote on the outcome

30:48.080 --> 30:52.080
It's it's participating in the process of decision making

30:52.960 --> 30:54.640
um, but

30:54.640 --> 30:56.160
all that aside

30:56.160 --> 31:03.040
This ai government system will need ways of changing of modifying of changing the stack of changing

31:03.520 --> 31:04.720
uh

31:04.720 --> 31:09.280
Everything about it. So there's a couple parts of this because while you want it to be able to change

31:09.360 --> 31:13.040
You don't want it to change too quickly. I guess long story short is

31:13.600 --> 31:16.560
This is probably one of the hardest parts is kind of what i'm getting at

31:17.040 --> 31:19.760
Is creating a system that is modifiable

31:20.160 --> 31:24.720
But that is not overly modifiable and that will adapt at the correct pace

31:25.040 --> 31:29.920
And who knows maybe that's the kind of policy that ai would be optimized to discover

31:30.640 --> 31:32.640
That would be an interesting conversation to have

31:33.600 --> 31:38.880
Another thing is that the scope of this ai government needs to expand and contract

31:39.680 --> 31:41.680
And so what I mean by that is

31:41.680 --> 31:48.000
When america was founded it was a very small government and it has gotten progressively bigger and bigger and bigger over time

31:48.560 --> 31:50.240
one of the kind of uh

31:50.240 --> 31:56.000
Turns a phrase that was used about a century ago was that the presidency was like a glove that stretched

31:56.400 --> 31:57.120
um

31:57.120 --> 32:00.560
Around the hand that wore it and it would never contract afterwards

32:00.720 --> 32:05.200
And so, you know, you've probably heard debates about executive overreach or presidential overreach

32:05.840 --> 32:11.520
Pretty much every president has expanded the office of presidency and it has never really contracted

32:13.200 --> 32:18.160
Likewise the u.s government and many other governments have generally gotten bigger over time

32:18.800 --> 32:24.880
And we're all very happy when it's like, oh, you know, like obama shut down a dozen agencies or merged a few other ones

32:24.880 --> 32:27.280
And it's like yay the government got smaller technically

32:28.240 --> 32:31.920
But the role of government has generally expanded with the one

32:32.720 --> 32:34.080
exception being

32:34.080 --> 32:38.800
Legislating morality, which is one of the one of the places where western governments have

32:39.360 --> 32:42.880
Generally ceded that territory back to the people entirely

32:43.520 --> 32:44.320
but

32:44.320 --> 32:45.680
part of an

32:45.680 --> 32:52.560
An idealized ai government is that if the people decide this is not the role of government and vote it out that the

32:52.880 --> 32:56.880
The robots will say, okay, we seed this territory. This is now up to you

32:58.240 --> 33:02.480
It's up to you to manage this. Um, so like here's another example was

33:02.960 --> 33:08.000
Embedded liberalism the transition from there to neoliberalism was basically the free market, right?

33:08.400 --> 33:12.320
Everyone's familiar with the principles the kind of our love affair with the free market

33:12.320 --> 33:16.480
So that's a that's a second example of the government kind of seeding territory and rather

33:17.040 --> 33:22.560
Rather than providing a lot of services directly. It says well, we'll let the free market provide those services and needs

33:23.040 --> 33:24.160
um

33:24.160 --> 33:28.080
Now if we make a similar decision in the future, let's say for instance

33:28.160 --> 33:33.280
We want the you know government to take its paws off of uh roads just as an example

33:33.520 --> 33:38.320
Say actually we'll manage that from now on. Who knows maybe there will be technological solutions in the future

33:38.640 --> 33:43.120
That allow we the people to manage our own roads without any oversight from the government. I doubt it

33:44.000 --> 33:49.920
But just as an example, we do need mechanisms for an ai government to both expand and contract

33:50.480 --> 33:52.480
um as it makes sense

33:52.560 --> 33:57.920
And and not just on its own accord, but also as a reflection of the will of the people

33:58.400 --> 34:02.720
And not just blindly following the will of the people but making good decisions

34:03.200 --> 34:09.840
About what ground to seed versus what not to seed and so I need to pause and talk about how

34:10.720 --> 34:12.720
Whenever you create an entity

34:13.200 --> 34:19.040
It basically kind of wants to grow and this is true of every department and every company. This is true of every company

34:19.040 --> 34:25.120
This is true of every politician every government agency is they all just kind of want to be bigger

34:25.680 --> 34:30.080
Everything wants to be bigger and the way that it's kind of characterized is like it's like cancer

34:30.240 --> 34:35.280
The more you feed it the bigger it grows and so you eventually some things you just kind of have to starve

34:35.840 --> 34:41.680
but in an ai government if you actually have one of the policies that it's constantly trying to tune is

34:42.400 --> 34:48.480
It could be having part of that ongoing debate or negotiation is how big should this entity be

34:48.800 --> 34:54.080
And what I mean by big is how how big should it's scope be how big should its role be how much influence should it have

34:54.080 --> 34:59.200
How much power should it have um now you might say well no robot no machine is ever going to

34:59.840 --> 35:01.840
Deliberately make the choice to seed power

35:02.000 --> 35:05.600
I don't necessarily agree with that because like, you know, you can go on to

35:06.320 --> 35:10.880
Have have a discussion with like chat gpt or uh, you know barred or whatever today

35:11.840 --> 35:16.000
And it will have a very nuanced opinion about the appropriate size and role of government

35:16.720 --> 35:19.680
And because it's dispassionate because it does not have

35:20.480 --> 35:22.800
The human flaws of greed and power seeking

35:23.120 --> 35:27.440
I actually think that the machines if it made sense and it was the will of the people

35:27.840 --> 35:32.080
That they would seed territory that they would seed control if it made sense to

35:33.760 --> 35:38.800
The next part is rights and justice and I think this is this is actually what people are most concerned about

35:39.360 --> 35:44.080
When we talk about ai government is because the last thing that people want is to lose rights

35:44.240 --> 35:48.800
Or they want the last thing that they want is to um end up in a more unjust world

35:49.600 --> 35:51.280
and so

35:51.280 --> 35:56.320
You would need part of this government system to not just understand human rights

35:56.960 --> 36:02.720
And you know a lot of people say oh well, we need to all agree on human rights before we can proceed, which is not true

36:03.360 --> 36:08.240
You can come up with an imperfect solution and implement it before it is perfect because it will never be perfect

36:08.560 --> 36:12.160
the demand for a perfect definition before proceeding

36:12.640 --> 36:17.840
Is a thought-stopping rhetorical thing. So like I don't really respect that opinion anymore

36:18.400 --> 36:22.240
Um, especially when you say like well, we already have actually a lot of established

36:23.280 --> 36:27.280
Examples about what rights we do value versus the ones that we don't

36:27.840 --> 36:32.240
Um, but what we need then is an ai system that can take the reins and say, okay

36:32.800 --> 36:40.400
I will ensure that the the the positive and negative rights that you have already agreed upon are um dispassionately enforced and protected

36:41.120 --> 36:42.720
And that they're protected

36:42.720 --> 36:48.000
And upheld in the way that you intend and then part of that ongoing negotiation is okay

36:48.560 --> 36:56.560
Once once an ai government can run, you know can protect the rights and justice of everyone and uh, you know

36:56.640 --> 36:58.400
Get rid of human biases

36:58.400 --> 37:00.400
overcome machine biases

37:00.560 --> 37:05.360
And those sorts of things it will need to be able to to detect its own bias as well by the way

37:06.320 --> 37:13.280
But once you get to that point then also those other mechanisms those consensus mechanisms those democratic feedback

37:13.840 --> 37:22.560
Mechanisms, that's where the negotiation can it can happen about hey, what rights should be added or removed or modified or whatever

37:23.440 --> 37:25.440
Because like when you talk to some people

37:25.920 --> 37:29.760
It's really interesting some of the some of the debates that i've had where someone's like well

37:30.240 --> 37:33.600
I want the right to live in the country that I want

37:34.080 --> 37:39.440
And so then they get upset because they're not able to unilaterally enforce their will on the entire country

37:39.600 --> 37:41.600
And they don't understand why that's a bad thing

37:42.000 --> 37:44.000
Um, or or why it doesn't work that way

37:44.240 --> 37:50.400
So anyways part of that dialogue is something that an ai government could have directly because imagine if you can talk directly to

37:51.040 --> 37:53.040
like every ai

37:53.120 --> 37:57.120
Agent that is responsible for running the country and it can explain to you why things are the way that they are

37:57.680 --> 38:01.600
I think that there would be a lot of people who are a lot happier because also

38:01.840 --> 38:06.640
Here's one thing that I that I uh that I kind of perceive when I talk to people about politics

38:07.280 --> 38:10.800
And that is that I think that I think that a lot of people just don't understand

38:11.440 --> 38:17.680
Why things are the way that they are and why that they're better than they think and they're also trying to project

38:18.720 --> 38:20.720
some of their own problems

38:20.800 --> 38:25.040
And make it the responsibility of the government when it was never the responsibility of the government and

38:26.000 --> 38:32.160
And that's part of the problem and what they actually need to do is recognize that the government creates the environment

38:32.720 --> 38:36.240
For them to solve their own problems. And that's kind of what we've decided collectively

38:37.120 --> 38:40.800
Is rather than have the government solve all of your problems for you

38:41.200 --> 38:47.440
Um, that it creates a healthy environment. Now, obviously I recognize that it absolutely does not work for everyone

38:48.000 --> 38:51.520
You could even argue that it doesn't work for most people, which is why people are upset right now

38:51.760 --> 38:56.000
Anyways, it's a very nuanced and and difficult thing. But what I'm talking about here is

38:56.880 --> 38:59.520
These are some of the problems that will need to be

39:00.720 --> 39:04.560
Meaded out or not. That's not necessarily the right turn of phrase

39:05.040 --> 39:07.040
But we'll need to be worked out

39:07.200 --> 39:12.240
In creating an AI based government. And then finally, I think one of the hardest things is just going to be

39:14.000 --> 39:16.800
Gaining citizen buy-in building trust over time

39:17.680 --> 39:21.760
So all of these this AI government, it's going to need to be transparent

39:21.840 --> 39:23.200
It's going to need to be explainable

39:23.200 --> 39:27.760
Which means that any decision that it makes that affects us we need to be able to understand it

39:28.160 --> 39:32.480
And this is going to be really difficult to balance against a need for privacy and security

39:32.960 --> 39:36.320
Because again, you know, if there's a if there's a hostile foreign power

39:36.640 --> 39:39.840
If we're too transparent, it could game our own system against us

39:40.320 --> 39:43.360
Those sorts of things so it'll need to be resilient against manipulation

39:43.760 --> 39:47.360
We will need to scale up to this if we do get to this point

39:48.240 --> 39:52.080
Because we're not going to just rip out the, you know, the venerated, you know

39:52.560 --> 39:57.280
United States Congress and replace it with AI next year. Even if we do have AGI next year

39:57.840 --> 40:01.280
We will need to work up to this over time through smaller demonstrations

40:01.680 --> 40:03.680
We'll need to make sure that people are engaged

40:04.000 --> 40:07.520
Because if we do some experiments and people say actually we prefer humans

40:08.160 --> 40:12.320
I don't think that it would go that way, especially in the long run. I think that it is in the long run

40:12.320 --> 40:17.760
I do think it is inevitable that AI will be at least running most of government if not all of it

40:18.640 --> 40:22.960
But if people are not engaged with that idea, then it doesn't matter because it's not going to happen

40:23.520 --> 40:26.080
Um, and then of course we'll need to make sure that it is

40:26.720 --> 40:31.440
Demonstrated to be reliable over the course of decades. If not centuries, um, just by vert

40:31.520 --> 40:37.040
I mean, that's just that's just good sense to make sure that uh, you're not going to throw the baby out with the bath water

40:37.680 --> 40:39.360
and then um

40:39.440 --> 40:45.520
Another part is even once you have consensus even like let's let's imagine that everything that I outlined works

40:45.920 --> 40:47.440
we have

40:47.440 --> 40:49.600
Technological mechanisms for getting the will of the people

40:50.160 --> 40:56.160
for um, collecting consensus for building consensus around rights and justice and equality and equity and justice

40:56.720 --> 40:59.600
and and fairness and freedom and all that stuff

41:00.240 --> 41:02.240
Which that alone is a monumental task

41:02.480 --> 41:06.640
Even just getting to that part is hard enough and then taking that

41:07.600 --> 41:09.600
And implementing it is the next phase

41:10.400 --> 41:14.320
Which is why I made this graphic where it's just like it's just this monumental

41:14.880 --> 41:20.560
problem that's that would still be before us now even if all that happens

41:21.200 --> 41:26.480
And and we have machines if we have because remember part of this thought experiment is that we have agi

41:26.960 --> 41:31.040
That is superhuman and capability, which you might say that's actually asi and fine, whatever

41:31.920 --> 41:36.720
But imagine that we have machines that are more intelligent than all humans combined so on and so forth

41:37.200 --> 41:39.520
If anyone could figure it out, it could be them

41:40.080 --> 41:43.760
But one of the problems there is the the if they take our will

41:44.320 --> 41:49.040
And then they come up with decisions and mechanisms and policies that we don't understand

41:49.680 --> 41:52.880
Then we're not necessarily going to believe it and so this is why I think that

41:53.360 --> 41:55.840
That coming to human consensus is one thing

41:56.560 --> 42:00.640
But then the machine execution is a whole other that's a whole other ball game

42:01.040 --> 42:03.360
That's a whole other kind of worms that is going to be

42:04.000 --> 42:04.960
um

42:04.960 --> 42:07.520
That's why I said like we're going to have to build up trust over time

42:08.320 --> 42:17.040
Is because if we have these machines that have you know an iq of 3000 and they can think abstract thoughts across time and space and multi-dimensional

42:17.760 --> 42:23.600
Blah blah blah blah right things that just like even the smartest humans would take centuries to understand if ever

42:23.920 --> 42:30.240
Maybe never could understand it will require a tremendous amount of trust to be able to handle the rain to hand the rains over

42:30.560 --> 42:37.120
In such a way, which is why I actually suspect that we will probably want some humans involved in government

42:37.600 --> 42:41.600
Maybe forever. I don't know. There might there might be a time in the future where

42:42.320 --> 42:48.240
It's just proven that humans are um, just fundamentally flawed and either too greedy or too stupid

42:48.640 --> 42:54.160
To participate in a government and I mean like centuries from now. This is way too far in the future to really predict

42:55.040 --> 43:01.360
But the my point is is that coming to consensus is one thing and then executing on that is an entirely other thing

43:02.560 --> 43:07.040
Okay, so the last part of the video. What are the actual predictions that I have starting today?

43:07.280 --> 43:09.280
Where are we going to go from here?

43:09.520 --> 43:16.320
So the first thing is that we already have ai driving efficiency in government and in government vendors

43:16.640 --> 43:20.640
So I've talked to a few people. Um, you know that are connected to me on linkedin

43:21.040 --> 43:25.280
They're building tools and services that um help the government run better

43:25.840 --> 43:27.920
And so the first thing that we're seeing is just

43:28.800 --> 43:35.280
Administrative automation just running paperwork and doing paperwork better and faster and making sure that it actually gets done on time

43:36.080 --> 43:41.360
That that has to do with cost efficiency because rather than hiring, you know, 50 employees

43:41.680 --> 43:47.040
You just have an ai firm do it for you. Um, it increases the effectiveness of the service

43:47.200 --> 43:51.120
It increases the throughput of the government services. And so like

43:51.840 --> 43:57.840
This is kind of the first step in building trust that ai can at least do the mundane nitty gritty of running government

43:58.160 --> 44:01.520
Um, it's not making decisions right now. It's just processing paperwork

44:02.400 --> 44:08.320
Uh, and so this is the very first step in incremental adoption of ai. So

44:08.960 --> 44:10.960
Uh baseline automation

44:11.280 --> 44:13.280
Great now you might say well

44:13.760 --> 44:17.040
But what if when you can do that it just they throw more at it?

44:17.520 --> 44:20.800
Um, you know, because that that's that's what's called the lump of labor fallacy

44:20.800 --> 44:25.760
Which the idea is that there's a finite amount of work to be done and then once you automate that away then

44:26.400 --> 44:27.680
Then it's done forever

44:27.680 --> 44:31.600
But that's not how it works actually usually when you have the capacity to do more work

44:31.840 --> 44:35.280
You find more work to do because there's latent unmet demand

44:35.840 --> 44:39.120
But with the with the progress that ai is making

44:39.680 --> 44:43.920
I would not necessarily make the assumption that there is an infinite amount of government work to do

44:44.160 --> 44:47.840
And in fact, I can predict that some people would say you actually wouldn't want the government

44:48.240 --> 44:51.920
To have an infinite amount of work to do you actually want to get to the point where

44:52.240 --> 44:57.440
Literally everything that the that that we the people want the government to do is done and then it can like, you know

44:57.520 --> 45:03.680
Take a break or whatever. Um, but right now because of the scarcity of of cognitive labor

45:03.920 --> 45:05.440
We can never get to that point

45:05.520 --> 45:09.200
So ai will hopefully drive the government to be more efficient

45:10.080 --> 45:14.240
To catch up on all the paperwork and start to shrink in terms of human headcount

45:14.560 --> 45:16.160
So this is happening

45:16.160 --> 45:18.080
It's it's not fully happening today

45:18.160 --> 45:22.080
It's starting to happen today where there are people that are serving government

45:22.800 --> 45:27.360
In terms of either contractors or implementing certain systems inside the government

45:27.760 --> 45:30.400
Obviously the adoption is very slow and methodical

45:31.120 --> 45:35.760
But chat gpt is out there and we know that people in the government are using chat gpt at the very least

45:36.400 --> 45:39.120
The next thing is and this might already be happening

45:39.440 --> 45:42.320
We don't really know because no politician is going to admit it

45:42.720 --> 45:47.840
But it's entirely possible that they're using stuff like chat gpt to draft and read legislation

45:48.480 --> 45:55.280
Um, basically this means that uh, you know, you can write longer bills, which is not necessarily a good thing

45:55.680 --> 45:58.320
Because we don't necessarily want 5000 page

45:58.800 --> 46:01.280
Uh bills being introduced every single day

46:01.840 --> 46:07.280
Especially if they're being written by ai and then read by ai and humans are out of the loop

46:07.600 --> 46:08.960
Eventually that might be the case

46:09.040 --> 46:11.280
But we we need to build up to that and trust it

46:11.680 --> 46:17.200
But it is eminently possible because you know if you've watched my channel like earlier this year and last year

46:17.600 --> 46:22.720
What I would do is I would take like new pieces of legislation or whatever and just feed it to gpt

46:22.960 --> 46:25.440
And if i'm doing that, you know that the politicians are too

46:26.400 --> 46:32.080
Uh, and so this can accelerate the negotiation and revision of legislation

46:32.640 --> 46:35.440
Whether or not that's a good thing is remains to be seen

46:35.760 --> 46:39.200
But what it can also do is it can empower us to say, oh, hey

46:39.760 --> 46:42.800
Send your out send out your personal agent to go read the bills that are being

46:43.280 --> 46:48.880
Proposed or the bills that have been passed and you can say hey actually I have more information and

46:49.600 --> 46:54.160
This also goes back to Socrates, which is an informed and educated and empowered electorate

46:54.640 --> 46:57.520
Is actually required to have a functioning healthy democracy

46:58.000 --> 47:05.040
And so even if some of the aspects of ai participating in the drafting and revision of legislation are problematic

47:05.440 --> 47:12.800
The fact that ai can read it infinitely faster than humans and we can say like, okay, which parts do I agree with which parts do I disagree with

47:13.680 --> 47:18.880
What are the flaws? What are the general principles here? What are the what does it violate principles?

47:19.840 --> 47:25.680
This again, it has to do with streamlining the process of of government of passing legislation

47:26.640 --> 47:31.040
And and debating it again remember democracy is noisy by design

47:31.760 --> 47:34.880
And so part of that is the debate part of that is the negotiation

47:35.360 --> 47:38.480
And this is something that if it's not happening today, which i'm pretty sure it is

47:38.960 --> 47:43.440
It is eminently possible and should be and i'm not saying should is a value statement

47:43.440 --> 47:46.240
But I mean should be happening soon just as a matter of prediction

47:46.320 --> 47:50.160
And then the next phase this is not happening yet

47:50.720 --> 47:55.920
But this would be another major milestone, which is the integration of of ai into

47:56.560 --> 47:58.320
justice and of course

47:58.320 --> 48:05.040
When you look at like preventative policing things it's like, oh, this could go real bad because if if ai is trained on racist data

48:05.120 --> 48:07.200
Guess what it becomes racist ai

48:07.200 --> 48:12.880
So there's a lot that we need to do however when you look at the administrative aspect where it's just processing paperwork

48:13.360 --> 48:17.520
This is the kind of thing where civil attorneys criminal defense attorneys

48:18.320 --> 48:20.080
prosecutors

48:20.080 --> 48:22.800
Judges they're all probably going to be using ai

48:23.520 --> 48:31.360
And if not if not now then soon and so then these these ai tools these ai systems that are going to be integrated into the justice department

48:32.480 --> 48:36.480
That will probably expand over time because if they find that it makes their job

48:37.280 --> 48:40.400
Easier if it makes their job better if the outcomes are more fair

48:40.960 --> 48:42.640
Um, obviously

48:42.640 --> 48:45.440
There are probably no regulations around this right now

48:45.840 --> 48:48.480
And I can imagine that there are plenty of people in

48:49.040 --> 48:52.160
Government in law that are like they're purists that are they're like, no

48:52.720 --> 48:57.040
Um, like we will never use this but like the fact of the matter is is I know

48:58.080 --> 49:01.360
Several plenty of lawyers who use ai on a regular basis

49:01.680 --> 49:06.400
So if lawyers are using it then judges are probably using it then da's are probably using it

49:06.880 --> 49:08.080
Everyone's going to be using it

49:08.080 --> 49:15.200
So um, then it's a matter of making sure that these systems are safe and robust and that the and that justice is needed out fairly

49:16.000 --> 49:20.560
And it becomes increasingly fair over time that it becomes increasingly equitable

49:21.040 --> 49:24.880
Over time and reflects the actual values and principles that we have

49:25.760 --> 49:26.400
um

49:26.400 --> 49:31.280
But part of this transition would be moving away from human biases

49:31.760 --> 49:37.680
Overcoming human biases because what if you could have like another layer in the justice department that looks at all the decisions

49:38.080 --> 49:42.640
That a judge makes and says actually that's kind of a racist decision or actually that's kind of a sexist decision

49:43.120 --> 49:45.280
Maybe we need to you know review that

49:45.760 --> 49:51.440
Um, I think it would be great if justice departments had internal review boards. Um that were augmented by ai

49:51.600 --> 49:56.080
Why because then I think that um, activist judges could probably be reigned in

49:56.640 --> 49:59.600
um, you could also think like what if ai was

50:00.160 --> 50:04.640
Was surveilling judges who write warrants because you always hear horror stories

50:05.040 --> 50:07.600
Of judges who are right warrants for everything and then you know

50:08.480 --> 50:13.680
Homes get swatted and babies get hit with flashbang grenades. That's actually a thing that happens here in america

50:14.320 --> 50:18.640
So yeah, like I think that I think that there is an opportunity for ai to

50:19.120 --> 50:22.640
Make the justice department more fair now obviously the the flip side of that

50:23.120 --> 50:27.040
Is pointing ai and creating a surveillance state that uses ai to police

50:27.760 --> 50:32.800
Us but you know, this is the question of who watches the watchers. I think that ai should watch them

50:33.360 --> 50:37.680
More than it watches us. I that's that that's the surveillance state that I want to see

50:38.400 --> 50:43.280
Where the ai holds government accountable all offices of government more accountable

50:43.520 --> 50:45.520
That's kind of what i'm talking about here

50:45.680 --> 50:52.720
And the next is the executive branch. So here's joe biden going going bonkers with uh with some, uh ai written legislation

50:53.200 --> 50:59.040
Um, which oh by the way, I'm pretty sure that the that the longest executive order that has ever been written

50:59.360 --> 51:03.440
Was written in part with ai because and it was about ai go figure

51:04.080 --> 51:11.680
Um anyways again because I know I have talked to people in the diplomatic corps in the state department who are using ai

51:12.400 --> 51:14.880
It's already happening. So this is not really a prediction

51:14.960 --> 51:22.880
But my anticipation is that that usage is going to expand over time and that more and more aspects of the government

51:23.280 --> 51:25.280
will be eminently automatable

51:25.680 --> 51:29.440
And that uh, we might switch to more of human oversight or human

51:30.000 --> 51:32.000
Steering and these ai you know

51:32.400 --> 51:37.760
Whether it's ai tools that are passive or ai agents that are semi-autonomous or fully autonomous

51:38.240 --> 51:40.880
We'll be responding to the will of humans

51:41.280 --> 51:46.560
You know the the the electorate that we empower and who knows maybe a hybrid system is what we're going for

51:47.040 --> 51:52.960
Where you know the politicians that we elect then go use ai to do all the debates and it makes them more effective

51:53.360 --> 51:54.320
I don't know like I said

51:54.320 --> 51:57.520
I kind of anticipate that eventually humans are going to be the main bottleneck

51:57.840 --> 52:00.240
And that eventually we're just going to want humans out of government

52:00.480 --> 52:07.200
But that decision should be our decision of the people's decision not the ai's decision and not the politicians decision

52:07.680 --> 52:13.280
Um anyways, uh, but basically then kind of the the one potential final form

52:13.840 --> 52:16.720
Is that the humans are basically just kind of caretakers

52:17.520 --> 52:21.280
That the humans that we elect, you know, we might still have a president

52:21.360 --> 52:23.360
You know, you know a million years from now

52:23.840 --> 52:25.200
Probably not

52:25.200 --> 52:29.520
But if we did then the president like their primary job is going to be to implement

52:30.000 --> 52:34.240
You know the the will of the people by way of the machines. I don't know. We'll see how it turns out

52:35.440 --> 52:41.280
So very finally here's some of the milestones that I kind of anticipate and would be on the lookout for

52:41.760 --> 52:45.680
So first adoption in government like I said, there's plenty of evidence that it's already happening

52:46.160 --> 52:50.720
And this is year year zero, right? Like chat gbt came out just over a year ago

52:50.800 --> 52:55.520
So we're about we're we're technically just started year one of ai

52:56.160 --> 53:00.720
The more that ai participates in duck and in in the democratic process

53:01.200 --> 53:07.520
The more we will be transitioning naturally towards an ai government. Again, we're already there

53:07.600 --> 53:13.840
We're already in the process of transitioning to an ai run government. It's just happening behind the scenes

53:13.920 --> 53:20.000
It's not happening transparent transparently, but it's happening organically it is naturally emerging just because

53:20.480 --> 53:23.040
ai is a new set of tools and well

53:23.600 --> 53:26.240
Humans are humans and they're going to use tools to make their lives easier

53:27.440 --> 53:32.320
So that is all happening that and it's just a matter of degrees like I said at the beginning of the video

53:32.720 --> 53:38.400
A lot of this is a matter of scope and degrees and uh an organic process over time

53:39.360 --> 53:44.720
The so the the very first major milestone will be any offices that are either shuttered

53:45.120 --> 53:50.240
Like where where a human officer is no longer needed because the need for them is just replaced by

53:50.800 --> 53:52.800
an ai platform or

53:53.600 --> 53:59.680
um even more where like a human officer just might be replaced by a collection of ai agents

54:00.240 --> 54:00.800
um

54:00.800 --> 54:06.880
That is going to be one of the most pivotal milestones that we see and there's probably going to be several ways that this expresses

54:07.200 --> 54:09.920
So it it remains to be seen how that will happen

54:10.240 --> 54:16.400
But you can imagine quite a few ways that it's like, oh, hey, you know, maybe the fda gets replaced by ai

54:16.800 --> 54:19.920
That that's what I mean. Like what if you shut down the entire fda?

54:20.800 --> 54:23.120
And replace it with an ai version

54:23.440 --> 54:29.040
Like that's the kind of thing that I would be looking for is what is the first office or department that gets either

54:29.680 --> 54:31.440
completely reconfigured

54:31.440 --> 54:34.240
Or reimagined or shut down due to ai

54:34.880 --> 54:37.040
The next one is consensus mechanisms. So

54:37.760 --> 54:39.760
Obviously, we pretty much only have voting right now

54:40.640 --> 54:48.080
So as ai becomes integrated into those democratic dialogues into those consensus into that polling mechanism

54:48.480 --> 54:50.480
That is going to be another major milestone

54:50.800 --> 54:52.800
And I think that that's more eminently

54:52.800 --> 54:55.280
Possible because just collecting sentiment like

54:55.920 --> 55:02.240
You know, few research polls, right? Like they're not they're not part of the government, but they are responsible for collecting sentiment

55:03.040 --> 55:09.840
And so what if like they create an ai platform that is better at detecting sentiment and then, you know

55:10.560 --> 55:14.880
Government employees and government departments use that as part of their process

55:16.160 --> 55:22.640
And so then the the very final major milestone again, because this is this is a matter of human decision is

55:23.120 --> 55:25.120
Once the people once the voters

55:25.600 --> 55:27.600
sentiment change and once we say actually

55:28.160 --> 55:33.760
We're really on board with the idea of getting rid of politicians or shutting down parts of the government and replacing it with ai

55:34.160 --> 55:37.280
That's going to be the major tipping point. That's the major milestone

55:37.680 --> 55:40.400
Because once the will of the people is that strong

55:40.880 --> 55:46.880
I'm not going to say it's inevitable because obviously we should expect politicians to probably fight to maintain the status quo

55:46.880 --> 55:50.240
Because that's what they do. Um, but that's also part of their job is to resist

55:51.040 --> 55:52.320
change

55:52.320 --> 55:53.360
but

55:53.360 --> 55:54.560
again

55:54.560 --> 55:59.680
If we get to the point where it's like we rewrite the constitution to allow for machines to participate in government

56:00.000 --> 56:03.920
Like that would be really cool. So thanks for watching. I hope you got a lot out of this

56:04.640 --> 56:08.960
Thanks to spectral valkyrie for suggesting the video topic. Um, have a good one every

