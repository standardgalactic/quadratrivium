1
00:00:00,000 --> 00:00:08,080
AI run the government. So this question actually came from one of my patreon supporters. So thank you spectral Valkyrie for this question

2
00:00:08,720 --> 00:00:15,360
But basically the idea was okay rather than just look at the way things are and look at incremental changes from

3
00:00:15,600 --> 00:00:22,440
Where we're at to a potential future. What if we just take a first principles look at could the AI run the government?

4
00:00:22,440 --> 00:00:23,960
What would that look like?

5
00:00:23,960 --> 00:00:31,440
So before we dive in I just wanted to let you know this video is a little bit longer and it's broken down into three distinct parts

6
00:00:31,600 --> 00:00:35,800
So the first part is we will talk about what is the purpose of government in general?

7
00:00:36,360 --> 00:00:42,320
And that will kind of set the stage because there is quite a bit of debate over what the role of government is or should be

8
00:00:42,320 --> 00:00:44,320
And it's mostly in terms of degrees

9
00:00:44,880 --> 00:00:49,160
So anyways, we'll get into that in just a moment then in the in the middle part

10
00:00:49,160 --> 00:00:55,440
We will talk about what would an AI government actually look like how is that actually going to function?

11
00:00:55,440 --> 00:00:58,440
How would it run and then finally in the last part of the video?

12
00:00:58,440 --> 00:01:04,720
I will make some actual real predictions based on things that I know are happening today and things that are in the works and

13
00:01:05,280 --> 00:01:09,520
So we'll see kind of what what the actual progress should look like

14
00:01:09,520 --> 00:01:13,040
So if any one of these parts doesn't resonate with you feel free to skip ahead

15
00:01:13,680 --> 00:01:15,680
But yeah, let's get right into it

16
00:01:15,800 --> 00:01:21,540
So the first thing that we need to say is okay. What is objectively speaking? What is the outcome?

17
00:01:21,680 --> 00:01:24,760
What is the function that government provides and right now?

18
00:01:25,080 --> 00:01:32,280
There are kind of five key pillars that government provides and there's there the biggest one that's missing is military

19
00:01:32,920 --> 00:01:38,440
but what I will say is that the military can operate as a separate entity from government and in fact in many

20
00:01:38,680 --> 00:01:45,040
In many institutions it kind of does it's technically an extension of the executive branch, but it is also supposed to have

21
00:01:45,680 --> 00:01:52,280
Its own thing. So that is deliberately and distinctly missing. So we're looking more at domestic government

22
00:01:52,360 --> 00:01:57,760
So domestic government focuses on these five key principles. So first is resource management

23
00:01:59,400 --> 00:02:04,960
Regulating public goods and natural resources for sustainability that sort of thing. So land use

24
00:02:06,200 --> 00:02:08,200
Waterways air that sort of stuff

25
00:02:09,160 --> 00:02:11,080
forests, you know

26
00:02:11,080 --> 00:02:12,440
Drilling rights

27
00:02:12,440 --> 00:02:18,560
The second thing is economic management. So this is fiscal and monetary policy. So this has to do with central banks

28
00:02:19,440 --> 00:02:26,880
Regulating the stock market that sort of stuff, you know, again, you're familiar with all these because we argue about it every few years here in America

29
00:02:27,280 --> 00:02:29,280
based on who we want to elect

30
00:02:29,400 --> 00:02:31,400
the third pillar is

31
00:02:31,880 --> 00:02:36,480
Mediation of relationships. So this is facilitating and mediating the relationships between

32
00:02:37,320 --> 00:02:45,000
Citizens nations organizations so on and so forth. And so there's a few ways that these regulations happen or that this this mediation happens

33
00:02:45,120 --> 00:02:51,760
So first is like corporate law. So ensuring that, you know, companies abide by safety regulations that sort of thing

34
00:02:51,760 --> 00:02:56,640
There's also the courts. So like if you have a dispute with someone else, there's criminal court. There's civil court

35
00:02:57,040 --> 00:02:59,040
That sort of thing. There's the Supreme Court

36
00:02:59,680 --> 00:03:05,160
So the court system is as part of this relationship mediation. It's it's there to broker or referee

37
00:03:06,120 --> 00:03:12,440
Relationships between various stakeholders in the government namely citizens businesses and then other nations

38
00:03:12,480 --> 00:03:16,640
So the diplomatic corps the State Department as we call it in America

39
00:03:17,200 --> 00:03:25,560
That is part of the relationship mediation. So the government manages our relationship with say Britain or France or China on our behalf

40
00:03:26,640 --> 00:03:30,680
The fourth thing is that they guarantee and protect and enforce rights

41
00:03:30,840 --> 00:03:34,240
And so there's this is a recent term

42
00:03:34,240 --> 00:03:38,120
So I've been plugging it a lot that I learned positive rights versus negative rights

43
00:03:38,360 --> 00:03:45,560
So a positive right is something that you're entitled to and a negative right is something that you were free from and so for instance our

44
00:03:46,360 --> 00:03:47,720
Constitution

45
00:03:47,720 --> 00:03:55,000
Guarantees that you are entitled to a right to free speech. You are entitled to a jury by your peers. You are entitled to

46
00:03:55,960 --> 00:04:01,160
A certain other things plenty of other things, but then you're also free from

47
00:04:02,080 --> 00:04:05,880
Tyranny, you know free to free from oppression and those sorts of things

48
00:04:06,400 --> 00:04:10,480
And so there's two different kinds of rights and of course there it as I mentioned earlier

49
00:04:11,040 --> 00:04:16,680
It is also a matter of degree because many of your rights are relatively simple

50
00:04:16,680 --> 00:04:23,560
But then we're there's also debate over more complex or comprehensive rights and then finally social organization

51
00:04:23,600 --> 00:04:25,920
And so this is one of the most controversial ones

52
00:04:26,680 --> 00:04:28,680
Especially if you look at the news right now

53
00:04:28,680 --> 00:04:33,560
The state of Texas is all up in arms about abortion rights. So again

54
00:04:34,280 --> 00:04:36,280
talking about social organization

55
00:04:36,480 --> 00:04:42,400
By and large western liberal democracies have decided not to legislate morality

56
00:04:42,920 --> 00:04:47,560
And you can see this by virtue of contrast when you look at the fact that like

57
00:04:48,120 --> 00:04:49,440
There is some

58
00:04:49,520 --> 00:04:55,040
TikTok celebrity who got arrested I think in Saudi Arabia for adultery like we don't do that in the west anymore

59
00:04:55,040 --> 00:05:01,600
We don't say like oh well this woman, you know had sex with someone that she wasn't supposed to so therefore we're gonna put her in morality jail

60
00:05:02,320 --> 00:05:04,000
Right, there was huge

61
00:05:04,000 --> 00:05:07,680
protests that broke out in Iran because a woman was beaten by the morality police

62
00:05:08,240 --> 00:05:12,960
And so by and large western democracies the the role of legislating

63
00:05:13,680 --> 00:05:15,680
morality and social structure

64
00:05:16,080 --> 00:05:21,840
Is contracting however government does still play a role in this and so what I mean by that is

65
00:05:22,880 --> 00:05:25,680
You know what what are legally recognized marriages?

66
00:05:26,160 --> 00:05:30,000
What are the family structures that are legally recognized and so right now

67
00:05:30,640 --> 00:05:34,400
Western liberal democracies have have kind of centered around the nuclear family

68
00:05:34,800 --> 00:05:38,480
Or the the smallest family unit, which is the marriage between a husband and a wife

69
00:05:38,880 --> 00:05:41,840
Whereas in the past there were you know, usually it was

70
00:05:42,800 --> 00:05:49,120
Uh, you know tribal communities or extended families where you'd have a matriarch or a patriarch who kind of managed the whole family

71
00:05:49,120 --> 00:05:52,960
And that was the legal unit and there are still plenty of countries out there where

72
00:05:53,680 --> 00:05:56,960
If not in law then at least in practice that is how things are run

73
00:05:57,280 --> 00:06:01,680
And so the government does have a role in supporting that social organization

74
00:06:02,000 --> 00:06:08,320
Then there's also other aspects of it such as the relationship between the government and the fourth estate, which is journalism

75
00:06:08,960 --> 00:06:10,960
Or or the church as well

76
00:06:11,280 --> 00:06:14,240
So those are kind of the five main pillars of government

77
00:06:14,240 --> 00:06:18,880
Like I said, there are plenty of other things from that list that are missing that is on purpose

78
00:06:18,880 --> 00:06:21,600
But these are kind of the five pillars that I want to look out for this video

79
00:06:22,240 --> 00:06:23,760
so also

80
00:06:23,760 --> 00:06:31,280
As I as I promised a lot of this is controversial and this goes back to even the founding of modern democracy where socrates himself

81
00:06:31,840 --> 00:06:35,040
questioned the the efficiency and wisdom of democracy

82
00:06:35,600 --> 00:06:37,600
so some of his

83
00:06:37,680 --> 00:06:43,040
Critiques were and of course this is back in the days of athens before representative democracy

84
00:06:43,680 --> 00:06:46,640
So most of what he was complaining about was tyranny of the majority

85
00:06:47,600 --> 00:06:51,600
Also, i'm really toasty. So i'm gonna switch clothes. Oh, okay properly dressed now

86
00:06:52,320 --> 00:06:56,800
but yeah, so socrates was concerned about tyranny of the majority

87
00:06:57,760 --> 00:06:58,640
and

88
00:06:58,640 --> 00:07:00,160
there's also

89
00:07:00,160 --> 00:07:02,720
the what we would today call like, you know

90
00:07:03,360 --> 00:07:05,360
The kind of the difference between

91
00:07:05,520 --> 00:07:09,120
Inclusive democracy where everyone gets a say versus

92
00:07:09,760 --> 00:07:11,760
expertise and this is one of the chief

93
00:07:12,080 --> 00:07:13,440
tensions

94
00:07:13,440 --> 00:07:15,680
particularly in america but also in other nations

95
00:07:16,400 --> 00:07:17,680
because

96
00:07:17,680 --> 00:07:19,680
communism like capital c communism

97
00:07:20,240 --> 00:07:21,760
said, oh, well

98
00:07:21,760 --> 00:07:23,920
The citizen shouldn't have a vote because they're all dumb

99
00:07:24,640 --> 00:07:28,640
And so what we're going to do is we're just going to hand the reins to the quote-of-quote experts

100
00:07:29,200 --> 00:07:32,720
And then the experts without any checks and balances are going to get to make decisions

101
00:07:33,120 --> 00:07:38,080
And in soviet russia that led to mass famines because the so-called experts mismanage farms

102
00:07:38,480 --> 00:07:42,800
mismanage the economy and that sort of thing and that by the way still goes on today. There are

103
00:07:43,520 --> 00:07:48,320
I was watching a documentary about how um, there there are places in china that you still can't grow

104
00:07:49,520 --> 00:07:52,880
food because of decades of communist mismanagement

105
00:07:53,200 --> 00:07:58,880
On the other hand, uh, your average citizen is also not necessarily qualified to make decisions

106
00:07:59,200 --> 00:08:01,920
So you you're kind of damned if you do damned if you don't

107
00:08:02,320 --> 00:08:07,200
Now what I wanted to include this slide for was to say that there are flaws with democracy

108
00:08:07,680 --> 00:08:11,520
I would say that there are more egregious flaws particularly with every way that

109
00:08:12,080 --> 00:08:16,880
Communism has been implemented and so I am not a communist. I'm not a socialist even though some of you accuse me of that

110
00:08:17,120 --> 00:08:20,480
I also have people say that I'm a neoconservative. So make up your minds

111
00:08:20,480 --> 00:08:26,480
Make up your minds. I consider myself a pragmatic progressive, but anyways, that's a conversation for another

112
00:08:26,960 --> 00:08:28,960
uh, another topic

113
00:08:29,520 --> 00:08:30,960
So let's move let's move on

114
00:08:30,960 --> 00:08:36,480
But I just wanted to address the elephant in the room and say that yes democracy is does have some fundamental flaws

115
00:08:36,800 --> 00:08:40,480
Going back to the founding of the thing the other component of

116
00:08:41,040 --> 00:08:47,120
That makes government hard is just intrinsic human flaws. And so one example is charismatic leaders

117
00:08:47,840 --> 00:08:52,560
So charismatic manipulators are able to use demagoguery and other things to

118
00:08:53,520 --> 00:08:57,040
you know, kind of get in and and you know wreck things

119
00:08:57,840 --> 00:08:59,520
power seeking behavior

120
00:08:59,520 --> 00:09:03,280
profit motivation plain old ignorance and so basically this all

121
00:09:03,920 --> 00:09:07,120
Speaks to the reason that government is structured as the way that is

122
00:09:07,680 --> 00:09:09,680
because the framers of

123
00:09:10,320 --> 00:09:14,080
modern western liberal democracies basically said, okay, well

124
00:09:14,800 --> 00:09:20,560
Uh, they didn't have the word for it, but they noticed that you know, uh, a non-trivial chunk of the population

125
00:09:21,040 --> 00:09:25,040
is just crazy. Um, whether they're narcissistic, whether they are

126
00:09:25,600 --> 00:09:28,080
um sociopaths, whether they are just

127
00:09:28,800 --> 00:09:30,800
completely saturated with greed

128
00:09:31,280 --> 00:09:32,320
um

129
00:09:32,320 --> 00:09:35,840
So they said, okay, well, we have to know that some people are going to be power seeking

130
00:09:35,840 --> 00:09:40,160
We have to know that some people are going to be manipulative and so on and so forth

131
00:09:40,400 --> 00:09:45,360
And so that's part of the reason that the government is structured the way that it is so that you have checks and balances

132
00:09:45,760 --> 00:09:48,640
So that you have these relief mechanisms that allow you to

133
00:09:49,600 --> 00:09:55,760
You know change up leadership on a regular basis, which in theory should prevent any particular

134
00:09:56,320 --> 00:10:00,080
Uh group or person from accumulating and holding on to too much power

135
00:10:00,480 --> 00:10:05,360
So far so good, but there are some people who very deliberately and explicitly want to upset that balance

136
00:10:05,920 --> 00:10:08,080
um because what happens is

137
00:10:08,800 --> 00:10:14,160
When you allow for the leadership, um at all levels to change up on a regular basis

138
00:10:14,560 --> 00:10:17,120
And you have this kind of as a mechanistic system

139
00:10:17,760 --> 00:10:18,720
um

140
00:10:18,720 --> 00:10:20,720
You prevent that accumulation of power

141
00:10:20,880 --> 00:10:25,520
But also you it's it becomes easier to spot people who are accumulating power

142
00:10:25,920 --> 00:10:29,920
Now, of course here in america, we have a problem of gerontocracy where we have people

143
00:10:30,480 --> 00:10:34,720
Literally serving until their 80s and 90s and in recent cases dying in office

144
00:10:34,800 --> 00:10:38,400
Even though they are not legally competent to take care of themselves

145
00:10:38,720 --> 00:10:41,360
So if someone is not legally competent to take care of themselves

146
00:10:41,360 --> 00:10:44,480
They are certainly not legally competent to run the the the nation

147
00:10:44,960 --> 00:10:50,480
But of course the uh the american system was framed before people were living long enough to have dementia

148
00:10:50,960 --> 00:10:52,960
So

149
00:10:53,280 --> 00:10:55,280
We got some work to do

150
00:10:55,600 --> 00:10:58,320
So that leads us to uh representative democracy

151
00:10:58,400 --> 00:11:02,560
So basically the way that it generally runs today is that we have a division of power

152
00:11:02,560 --> 00:11:06,720
We have a three branch system. So that's legislative judicial and executive branch

153
00:11:07,440 --> 00:11:11,280
The the the judicial branch is obviously like one of the weaker ones

154
00:11:11,760 --> 00:11:14,560
Except for the supreme court, which does kind of set a lot of the tone

155
00:11:15,440 --> 00:11:16,880
We use elected officials

156
00:11:16,880 --> 00:11:21,840
So the elected officials then you know represent our willpower and they appoint

157
00:11:22,400 --> 00:11:26,560
Experts um and then some of the sometimes we do vote on experts. Sometimes we don't

158
00:11:27,200 --> 00:11:31,680
Some officials some offices are appointed by the electorate. Some aren't

159
00:11:32,400 --> 00:11:36,880
But this is all part of the ongoing negotiation and part of the reason that it's so messy is because

160
00:11:37,280 --> 00:11:40,400
We're constantly making little adjustments to the whole structure

161
00:11:41,200 --> 00:11:47,680
Which is good because uh, you know, you look at revolutions of the past and one of the key thing one of the key reasons

162
00:11:48,240 --> 00:11:52,160
why civil wars have happened in the past is because

163
00:11:52,880 --> 00:11:55,280
And not even in the distant past in the recent past

164
00:11:55,760 --> 00:11:58,960
Is because the government is too rigid or too inflexible and does not

165
00:11:59,360 --> 00:12:05,600
Respond to the will of the people and the changing times. And so the the key thing is peaceful transitions

166
00:12:06,160 --> 00:12:09,360
Um, it's not just a matter of representing the will of the people

167
00:12:10,080 --> 00:12:15,040
Because if you wanted to create a government that was purely of the people for the people by the people

168
00:12:15,120 --> 00:12:17,840
It would look different from representative democracy

169
00:12:17,920 --> 00:12:24,880
But really what what what the uh what the framers particularly the other of the american system wanted to achieve was peaceful transition of power

170
00:12:25,600 --> 00:12:28,720
Because when you had monarchy you'd have wars of succession

171
00:12:29,440 --> 00:12:36,720
When you had the you know, basically most of europe being run by a single royal family and all their cousins and second cousins and fifth cousins

172
00:12:37,680 --> 00:12:42,640
You could still end up with major problems. See world war one and world war two

173
00:12:43,520 --> 00:12:47,120
Now obviously america was founded before that but there is oh man

174
00:12:47,440 --> 00:12:53,280
You listen to history like europe was just one constant set of wars for like 500 years

175
00:12:53,840 --> 00:13:01,200
Um, and then as I already mentioned incremental changes part the part of the goal of government is to allow for incremental changes

176
00:13:01,760 --> 00:13:06,240
Um, that is not necessarily steered uh exclusively by a controlling elite

177
00:13:06,640 --> 00:13:11,040
But that the will of the people can make incremental changes to the government itself

178
00:13:11,440 --> 00:13:15,840
Even the founding document, um, such as in our case a constitutional democracy

179
00:13:16,640 --> 00:13:21,280
And so the idea is that this is a gigantic system that is meant to

180
00:13:21,920 --> 00:13:26,480
Allow change but also resist change because you don't want the pendulum to swing too wildly

181
00:13:26,560 --> 00:13:29,360
You don't want to oscillate by correcting and then over correcting

182
00:13:29,760 --> 00:13:34,800
And so these are all the all the things that go into the purpose of government. Why is it here?

183
00:13:34,880 --> 00:13:36,880
Why does it work the way that it does?

184
00:13:36,960 --> 00:13:43,200
So this stands in stark contrast to single party systems such as what we see in china and russia, which they are

185
00:13:43,920 --> 00:13:47,840
Technically democracies because they they run quote-unquote elections

186
00:13:48,320 --> 00:13:54,560
Um, but most the elections are fixed and I think that it's not a controversial thing to say that they are not actually true democracies

187
00:13:54,960 --> 00:13:57,600
Or they are what I would call kind of a pseudo democracy

188
00:13:58,320 --> 00:14:00,320
Where it's got some of the dressings some of the trappings

189
00:14:00,800 --> 00:14:06,960
But you can when you consider that both putin and shijing ping were able to to manipulate the system so that they were lifelong appointees

190
00:14:07,280 --> 00:14:09,280
They basically made themselves kings

191
00:14:10,160 --> 00:14:15,200
So some of the characteristics that you see in single party systems are you get a monolithic structure

192
00:14:16,080 --> 00:14:22,160
That's by definition. The ccp is china china is the ccp. There isn't really any alternative

193
00:14:23,040 --> 00:14:29,760
While there are technically other, you know people that run against putin. They usually fall out of windows or end up getting poisoned

194
00:14:30,560 --> 00:14:32,880
So that's not necessarily a viable strategy there

195
00:14:34,000 --> 00:14:38,800
Part of the way that these regimes maintain control is they become more authoritarian over time

196
00:14:39,600 --> 00:14:44,720
And so that leads to things like information control both russia and china have state-run media

197
00:14:45,520 --> 00:14:50,480
So basically if you see a lack of state-run media that is usually a sign of a healthier democracy

198
00:14:50,720 --> 00:14:52,720
Which we'll talk about in just a second

199
00:14:52,880 --> 00:14:54,480
They do allow liberalization

200
00:14:54,480 --> 00:14:58,960
So this is one of the this is one of the things that kind of gave us hope after the collapse of the soviet union

201
00:14:59,280 --> 00:15:01,280
And after china's great leap forward

202
00:15:01,760 --> 00:15:04,000
Was that they eventually did allow for

203
00:15:04,880 --> 00:15:09,600
Some liberalization of the economy because they wanted the profits, but they didn't liberalize

204
00:15:10,160 --> 00:15:14,640
In terms of civil liberties in terms of voting rights and and government reforms

205
00:15:16,400 --> 00:15:20,480
And there are also pretty interesting cultural and historical roots

206
00:15:21,200 --> 00:15:27,280
As they kind of explain why this happens now you could look at places like japan and germany which did

207
00:15:28,080 --> 00:15:30,080
granted at the barrel at the

208
00:15:30,640 --> 00:15:34,080
Because guns were pointed at them after world war two. They were able to liberalize

209
00:15:35,280 --> 00:15:41,600
Very effectively now Japan still has the imperial family, but they're mostly just token, right?

210
00:15:41,680 --> 00:15:44,800
You know the japanese parliament runs the country

211
00:15:45,600 --> 00:15:50,400
Germany got a did away with everything and now they are you know fully fully liberalized democracy

212
00:15:50,800 --> 00:15:52,800
and so the argument that

213
00:15:53,040 --> 00:15:57,760
That single party systems inevitably emerge in some of these nations for historical and cultural reasons

214
00:15:58,080 --> 00:16:02,240
Doesn't necessarily stand up to scrutiny particularly when you look at the history of japan

215
00:16:03,120 --> 00:16:07,520
But they also had to lose a major war in order to have that that

216
00:16:08,240 --> 00:16:10,240
New democracy forced on them

217
00:16:10,480 --> 00:16:15,680
And of course that set the the tone for the rest of the 20th century and 21st century

218
00:16:16,160 --> 00:16:19,920
Where the western allies basically enforce and export democracy

219
00:16:20,560 --> 00:16:25,440
Onto other nations whether or not they want it which of course, that's what putin and shijin ping are pushing back against now

220
00:16:26,160 --> 00:16:29,840
Actually more explicitly. It's very interesting where they just basically have flatly said like

221
00:16:30,400 --> 00:16:35,360
We don't want your western values now. Do they do do they reflect the will of the people?

222
00:16:35,840 --> 00:16:40,800
Doesn't sound like it. I've interviewed some people from from other places not russia or china

223
00:16:41,040 --> 00:16:43,040
But I interviewed some people from syria

224
00:16:43,200 --> 00:16:48,080
And the the idea is that the more that they learn about western democracy the more that they want it

225
00:16:48,400 --> 00:16:50,880
Which is the reason that people like

226
00:16:51,600 --> 00:16:58,240
Putin and shijin ping need to resist information and need to poison their people against the idea of voting and power

227
00:16:58,240 --> 00:16:59,680
but that's

228
00:16:59,680 --> 00:17:03,760
That's why there is still ongoing conflict in syria is because

229
00:17:04,400 --> 00:17:08,800
People know they've seen greener pastures and they want it and they're going to keep fighting for it

230
00:17:09,680 --> 00:17:12,640
The fighting has tamped down, but syria is deeply fragmented right now

231
00:17:13,440 --> 00:17:15,040
so anyways

232
00:17:15,040 --> 00:17:20,080
That is the by virtue of contrast looking at a single party system or failed democracies

233
00:17:20,880 --> 00:17:26,320
Which there are some people that explicitly want to turn America into a single party system into all of you

234
00:17:26,400 --> 00:17:28,240
I say stop

235
00:17:28,240 --> 00:17:33,760
And then finally there is the the nightmarish central management or totalitarian regimes

236
00:17:34,960 --> 00:17:41,760
This is what you see in terms of fascism or old school communism where there wasn't any elections whatsoever

237
00:17:42,480 --> 00:17:44,480
farcical or otherwise

238
00:17:44,560 --> 00:17:47,520
North korea is is the current kind of prime

239
00:17:48,080 --> 00:17:53,680
Example of the the quote-unquote hermit kingdom where it is top-down authoritarian control

240
00:17:54,640 --> 00:17:56,640
And they regulate everything

241
00:17:57,120 --> 00:18:02,160
Apparently in north korea. They even regulate how much grieving you're supposed to do for the former dead leaders

242
00:18:02,960 --> 00:18:08,000
So that's not just a legislating morality. They're they're they're controlling emotions

243
00:18:08,400 --> 00:18:10,640
and apparently people have been set sent to like

244
00:18:11,040 --> 00:18:17,280
Reeducation camps for not grieving enough in public on their days of remembrance or whatever

245
00:18:17,840 --> 00:18:19,840
um these kinds of things they

246
00:18:20,080 --> 00:18:22,080
They're necessarily surveillance states

247
00:18:22,320 --> 00:18:29,520
Um extreme conformity is required and then and then any breach of conformity is deeply and severely punished

248
00:18:30,160 --> 00:18:31,760
Democracy is noisy

249
00:18:31,760 --> 00:18:34,720
This is one of the things that I think a lot of people don't understand

250
00:18:34,720 --> 00:18:39,840
Which is why I'm going through all this is because all the vitriol all the vicious debates about you know

251
00:18:39,920 --> 00:18:44,320
Trump versus biden or you know left versus right or you know, whoever

252
00:18:45,680 --> 00:18:47,840
Democracy is is noisy by design

253
00:18:48,720 --> 00:18:54,640
When you look at at a at a nation that you know say oh, we're we're perfectly aligned because they quash debate

254
00:18:55,520 --> 00:18:58,960
You're not allowed to criticize putin. You're not allowed to criticize

255
00:18:59,520 --> 00:19:03,920
Xi Jinping. You're not allowed to criticize the the kim jong-un

256
00:19:04,480 --> 00:19:05,520
Um

257
00:19:05,520 --> 00:19:12,240
So because of that those nations they appear more orderly they appear quieter. They appear to be

258
00:19:12,960 --> 00:19:19,040
Uh more in lockstep. However in america and india and britain and all these other places

259
00:19:19,440 --> 00:19:25,920
Where you have really vicious debates you have mud slinging you have you have muck raking you have all kinds of things

260
00:19:26,640 --> 00:19:28,640
And that is by design and so

261
00:19:29,200 --> 00:19:32,960
When you understand that that the ability to speak up that you know

262
00:19:32,960 --> 00:19:38,000
If you really don't like something in the west you can start a youtube channel or a tiktok channel and and

263
00:19:38,480 --> 00:19:42,080
Say, you know the president's an idiot and like I have zero fear of that

264
00:19:42,400 --> 00:19:46,560
Whereas like could you do that in china in russia in north korea?

265
00:19:47,040 --> 00:19:52,640
No, and of course those are just some of the most extreme examples. There are plenty of other oppressive regimes around the world

266
00:19:53,680 --> 00:19:56,320
and so because of that because debating is encouraged

267
00:19:56,640 --> 00:20:01,520
Because descent is tolerated because we can air our grievances. Now this uh,

268
00:20:02,080 --> 00:20:04,080
Allow us for a level of transparency

269
00:20:04,560 --> 00:20:08,160
But the flip side of that is that people don't get along all the all the time

270
00:20:08,560 --> 00:20:12,480
The fact of the matter is is that you know, you can say things that people disagree with

271
00:20:12,880 --> 00:20:17,280
And then you can get into internet debates or you know, choose your favorite talking head

272
00:20:17,360 --> 00:20:20,400
Which now I have joined the league of talking heads. So yeah, whatever

273
00:20:20,960 --> 00:20:22,000
Um

274
00:20:22,000 --> 00:20:26,960
But these are all features. This is a feature not a bug. That is the key thing is that if democracy is noisy

275
00:20:26,960 --> 00:20:29,440
That is a sign of a healthy democracy now

276
00:20:29,600 --> 00:20:33,840
You can also end up in situations where people kind of naturally agree

277
00:20:34,320 --> 00:20:38,720
Um, and so this is this is uh, you know, there was what was it called the era of good feelings?

278
00:20:39,200 --> 00:20:41,200
um, where america basically became

279
00:20:41,760 --> 00:20:45,120
By a default kind of a single party system for about 20 years

280
00:20:45,440 --> 00:20:49,520
But that was just because things were going well and there was nothing really to argue about and of course that is a

281
00:20:49,920 --> 00:20:51,920
gross oversimplification

282
00:20:52,320 --> 00:20:54,960
But that emerged naturally not by force

283
00:20:55,760 --> 00:20:57,760
whereas during

284
00:20:57,840 --> 00:21:01,840
Uh contentious times whether there are external threats internal threats

285
00:21:03,120 --> 00:21:05,120
Or social upheaval

286
00:21:05,120 --> 00:21:07,280
You should expect it to get a little bit nastier

287
00:21:07,520 --> 00:21:12,320
But again, that is part of democracy working itself out by having those ongoing debates

288
00:21:12,800 --> 00:21:18,720
And having those uh those ongoing dissenting opinions and airing those grievances and talking it out

289
00:21:19,440 --> 00:21:23,200
That is part of the process. That is that is that is a sign of things

290
00:21:23,680 --> 00:21:27,920
Uh progressing as as intended. So with all that being said

291
00:21:28,960 --> 00:21:31,280
What would an ai government look like?

292
00:21:31,920 --> 00:21:37,680
Because the thing is when you're when you're looking at all this it's not a matter of

293
00:21:38,160 --> 00:21:43,920
Machines just making decisions and enforcing it on us. That's a totalitarian regime, which we don't want

294
00:21:44,400 --> 00:21:46,400
what we really want is

295
00:21:46,720 --> 00:21:50,640
We want the messiness of what of democracy that we have today

296
00:21:51,040 --> 00:21:54,160
Because you know whenever I talk about universal ai values

297
00:21:54,160 --> 00:21:58,000
It's like well who gets to decide them and the answer is and this is kind of why I was like

298
00:21:58,400 --> 00:22:00,400
I was always confused by that retort

299
00:22:00,560 --> 00:22:06,000
Um, but I understand it better is because we do we get we the people get to decide what values

300
00:22:06,320 --> 00:22:10,080
We ultimately want to live by now. There's of course

301
00:22:10,080 --> 00:22:12,480
There's always a contingent of people who want to enforce

302
00:22:12,960 --> 00:22:16,320
Their particular values on everyone because they don't understand

303
00:22:16,880 --> 00:22:20,480
Uh the history of democracy or why things are the way they are like for instance

304
00:22:20,480 --> 00:22:24,640
Whenever someone says america is a christian nation and we all need to have more christian law

305
00:22:25,040 --> 00:22:28,480
That is indistinguishable from muslims who want to impose

306
00:22:28,960 --> 00:22:31,680
Sharia law on everyone else. So stop doing that

307
00:22:32,400 --> 00:22:36,880
The idea is freedom and equality are the highest principles that we have agreed on

308
00:22:37,680 --> 00:22:41,920
And so then it's a matter of creating a container that allows for

309
00:22:42,480 --> 00:22:46,320
Different approaches to life now some people do not tolerate

310
00:22:47,040 --> 00:22:51,680
Differences they don't tolerate differences of religion or of opinion or values or beliefs

311
00:22:52,080 --> 00:22:56,880
And those people are just wrong. That's not how democracy works. That's not how

312
00:22:57,600 --> 00:22:59,600
Inclusive tolerant societies work

313
00:23:00,720 --> 00:23:06,640
So this thought experiment then is okay, let's just assume that ai has the capacity to run

314
00:23:07,120 --> 00:23:11,520
The government let's let's just imagine a year from now when we have a gi and it's

315
00:23:12,080 --> 00:23:17,280
And it's performing above human level on all benchmarks. It's in the 99.9th percentile

316
00:23:18,400 --> 00:23:21,920
Or higher for like literally every cognitive ability

317
00:23:22,320 --> 00:23:26,960
We've got you know advanced robots that can do stuff and the ultimate goal is

318
00:23:27,680 --> 00:23:30,320
What if we just removed humans from the government?

319
00:23:31,040 --> 00:23:32,240
wholesale

320
00:23:32,240 --> 00:23:37,120
Like let's go full monty because this is this is what my patreon supporter was like like no, let's

321
00:23:37,840 --> 00:23:40,240
Not beat around the bush. Let's just go full monty and see what

322
00:23:40,800 --> 00:23:45,600
Like what would this require what what are the challenges and how would it actually work?

323
00:23:45,760 --> 00:23:49,680
So let's dive into some of the components that would make this happen

324
00:23:50,320 --> 00:23:57,200
So the first thing that we need to do is use ai whether it's a combination of existing, you know machines and and

325
00:23:57,440 --> 00:24:01,760
Databases and stuff combined with large language models combined with deep multimodal models

326
00:24:02,800 --> 00:24:04,960
We need to survey the will of the people

327
00:24:05,600 --> 00:24:07,600
whatever else is true

328
00:24:07,760 --> 00:24:12,240
The one of the chief purposes of government is to reflect the will of the people now

329
00:24:12,720 --> 00:24:16,000
Right now the primary way we have to do that is through voting

330
00:24:16,400 --> 00:24:22,800
That is the primary mechanism that we have to express our will where it's you know every so often

331
00:24:23,200 --> 00:24:25,200
We get to go pick a person

332
00:24:25,280 --> 00:24:32,240
Who who we feel represents our desires and beliefs and then we go and hire them via election

333
00:24:32,720 --> 00:24:38,240
To go represent our desires our values our beliefs in the process of government

334
00:24:39,040 --> 00:24:45,120
But if you remove all humans, then it's not necessarily electing a representative. You have to express your will

335
00:24:46,160 --> 00:24:47,520
Some other way

336
00:24:47,520 --> 00:24:51,200
Now that doesn't mean that you don't you get rid of voting. Maybe you have more voting

337
00:24:51,840 --> 00:24:53,840
But this goes back to socrates complaint

338
00:24:54,160 --> 00:24:58,400
Which and I know elan musk is one of the people who said oh direct democracy makes sense

339
00:24:58,640 --> 00:25:04,160
It absolutely doesn't you do not want to live in a direct democracy because then you have tyranny of the majority

340
00:25:04,880 --> 00:25:06,880
And that can get real bad real fast

341
00:25:07,600 --> 00:25:08,720
however

342
00:25:08,720 --> 00:25:10,720
by combining

343
00:25:10,720 --> 00:25:14,480
You know existing online platforms leveraging new technologies

344
00:25:15,040 --> 00:25:18,320
Using large language models and semantic clustering and all sorts of stuff

345
00:25:18,880 --> 00:25:25,120
I suspect that we could easily build a platform a democratic platform that very very

346
00:25:26,000 --> 00:25:29,120
comprehensively collects and understands the will of the people

347
00:25:29,760 --> 00:25:33,120
Um, and then what do you do with that information? We can figure that out later

348
00:25:33,920 --> 00:25:40,400
But rather than just picking a person because also remember go back to the slide that I did about fundamental human flaws

349
00:25:40,880 --> 00:25:42,880
power seeking avarice

350
00:25:42,960 --> 00:25:44,720
plain old ignorance

351
00:25:44,720 --> 00:25:49,680
You get rid of those if you get rid of people now you introduce new problems if you replace people with machines

352
00:25:49,840 --> 00:25:56,080
But the point is is that if we can directly express our willpower through some mechanism

353
00:25:57,040 --> 00:26:02,720
You know maybe with a combination of blockchain voting and artificial intelligence and a few other things

354
00:26:03,280 --> 00:26:09,200
Then the then the machine apparatus of government will at least be aware of what we the people want

355
00:26:09,520 --> 00:26:13,360
So that's step one. We need something that allows us to

356
00:26:14,000 --> 00:26:16,240
Express our will and allows it to be recorded

357
00:26:16,960 --> 00:26:18,960
and accurately measured

358
00:26:18,960 --> 00:26:21,600
So that then the ai government can then use that

359
00:26:22,960 --> 00:26:28,160
Another component of this is ongoing negotiations. So like I said democracy is noisy by design

360
00:26:28,800 --> 00:26:30,800
but if you get rid of

361
00:26:30,800 --> 00:26:32,560
individual, you know

362
00:26:32,560 --> 00:26:36,080
Politicians then you don't have conventions. You don't have town halls

363
00:26:36,640 --> 00:26:39,680
So then who are you talking to? Who do you write letters to?

364
00:26:40,400 --> 00:26:42,400
and this is again where the

365
00:26:42,880 --> 00:26:44,880
collecting the will of the people

366
00:26:44,960 --> 00:26:50,960
Is not just about okay. The people have expressed their desire on this particular issue now the machine goes and does it

367
00:26:51,280 --> 00:26:55,840
It is an ongoing conversation. It is an ongoing negotiation and renegotiation

368
00:26:56,480 --> 00:27:03,120
As the situation changes as our understanding changes as consensus changes and so on and so forth

369
00:27:03,760 --> 00:27:05,760
And so part of the of the government

370
00:27:06,160 --> 00:27:12,640
What it does today is, you know, the the the white house has their, you know, their press corps and politicians have their

371
00:27:13,120 --> 00:27:14,800
public relations managers

372
00:27:14,800 --> 00:27:16,800
So we basically need the same thing

373
00:27:17,280 --> 00:27:22,160
But with various ai components kind of saying this is what we're doing and this is why and

374
00:27:22,720 --> 00:27:26,240
Like here's a here's a chance for feedback. We need to disseminate ideas

375
00:27:26,800 --> 00:27:28,400
resources and that sort of stuff

376
00:27:28,480 --> 00:27:34,240
Oh, and one thing that I should point out is that I'm not necessarily thinking that one monolithic ai is the right way to go

377
00:27:34,720 --> 00:27:38,800
Because from a narrative perspective, that's easier to say like, you know, the ai

378
00:27:39,360 --> 00:27:40,880
But really I think that

379
00:27:40,880 --> 00:27:47,520
Um, if we were to replace government with ai, it should be probably millions of individual ai agents all working together

380
00:27:48,160 --> 00:27:50,160
That are individually transparent

381
00:27:50,160 --> 00:27:52,480
Um, hence the swarms that we've been working on

382
00:27:53,120 --> 00:27:56,960
Um, anyways, so getting back to the slide, uh, you know

383
00:27:57,040 --> 00:27:59,040
There needs to be constant feedback

384
00:27:59,360 --> 00:28:00,960
between

385
00:28:00,960 --> 00:28:07,360
You know the people and the ai government and as well as, you know, I mentioned consensus, but it's basically

386
00:28:08,240 --> 00:28:09,280
debate

387
00:28:09,280 --> 00:28:14,000
Discussion negotiation dialogue consensus. Those are all kind of the same thing

388
00:28:14,000 --> 00:28:18,240
But it the the the key takeaway is that it needs to be a two-way conversation

389
00:28:18,640 --> 00:28:20,640
It's not just a unilateral

390
00:28:21,040 --> 00:28:24,800
The will of the people gets expressed and then the ai government goes and does that

391
00:28:25,040 --> 00:28:30,080
That's not exactly the way that it works and that's not that's by that's by design. That's not how representative democracy works

392
00:28:30,480 --> 00:28:34,480
It's we express our will and then the professional politicians ideally

393
00:28:34,880 --> 00:28:37,840
Go and do their best to accommodate that

394
00:28:38,080 --> 00:28:42,320
But of course, you know, our politician goes to battle with other politicians and so on and so forth

395
00:28:42,880 --> 00:28:44,240
likewise

396
00:28:44,240 --> 00:28:47,360
You know, we the people express our will to an ai government

397
00:28:47,680 --> 00:28:53,680
And it will do the best that it can to implement that willpower within the constraints within the boundaries of

398
00:28:54,560 --> 00:29:00,720
The way that other people, you know, want things to go as well as other higher universal principles such as

399
00:29:01,200 --> 00:29:05,680
enshrining, you know equality and freedom above all else above, you know

400
00:29:05,760 --> 00:29:10,240
As an example above a religious theocracy another thing that it's going to need is

401
00:29:10,880 --> 00:29:12,880
mechanisms for change so

402
00:29:14,320 --> 00:29:15,440
as

403
00:29:15,440 --> 00:29:17,440
Western liberal democracies work today

404
00:29:17,760 --> 00:29:20,240
Incrementalism is the name of the game

405
00:29:20,640 --> 00:29:24,480
You can make changes to literally every aspect of the government

406
00:29:24,960 --> 00:29:28,000
piece by piece starting with the constitution and there are

407
00:29:28,560 --> 00:29:33,440
Mechanisms there that allow for that change, which is why I gave this like little transformer dude

408
00:29:33,760 --> 00:29:37,840
Because you know, it's like it looks like a modular robot or whatever. So that's it's supposed to be an allegory

409
00:29:38,560 --> 00:29:41,200
But when you have an ai government, you don't want it to be rigid

410
00:29:41,200 --> 00:29:45,360
You don't want it to be like, okay, once you implement it once it's that way forever

411
00:29:45,360 --> 00:29:48,320
No, you literally want every piece of the stack

412
00:29:48,960 --> 00:29:51,200
To be changeable to be plastic

413
00:29:51,920 --> 00:29:57,760
And so that means all the models that the agents use the hardware the software and that's just the system itself

414
00:29:58,240 --> 00:30:02,480
Then all the policies that the system uses the technology stack that it uses

415
00:30:02,960 --> 00:30:06,160
The principles that it abides by so, you know, if you've watched my channel

416
00:30:06,160 --> 00:30:09,600
You know that I'm a big fan of like universal declaration of human rights

417
00:30:09,840 --> 00:30:13,360
I'm also a big fan of of the heuristic imperatives that I created

418
00:30:13,680 --> 00:30:18,080
But those need to be part of what is negotiated that needs to be part of

419
00:30:18,640 --> 00:30:22,400
What is changeable now, obviously the core values the core principles

420
00:30:22,880 --> 00:30:26,160
You need to be really, you know, darn sure that you want to change those

421
00:30:26,800 --> 00:30:33,600
And it's also not necessarily something that you want to direct democracy on because one you might never get it passed

422
00:30:34,560 --> 00:30:36,560
But you do want everyone to have a say

423
00:30:37,120 --> 00:30:38,960
In the process

424
00:30:38,960 --> 00:30:42,320
So that's one thing that I think some people are not familiar with

425
00:30:42,960 --> 00:30:48,000
When looking at government systems and it's not necessarily a vote on the outcome

426
00:30:48,080 --> 00:30:52,080
It's it's participating in the process of decision making

427
00:30:52,960 --> 00:30:54,640
um, but

428
00:30:54,640 --> 00:30:56,160
all that aside

429
00:30:56,160 --> 00:31:03,040
This ai government system will need ways of changing of modifying of changing the stack of changing

430
00:31:03,520 --> 00:31:04,720
uh

431
00:31:04,720 --> 00:31:09,280
Everything about it. So there's a couple parts of this because while you want it to be able to change

432
00:31:09,360 --> 00:31:13,040
You don't want it to change too quickly. I guess long story short is

433
00:31:13,600 --> 00:31:16,560
This is probably one of the hardest parts is kind of what i'm getting at

434
00:31:17,040 --> 00:31:19,760
Is creating a system that is modifiable

435
00:31:20,160 --> 00:31:24,720
But that is not overly modifiable and that will adapt at the correct pace

436
00:31:25,040 --> 00:31:29,920
And who knows maybe that's the kind of policy that ai would be optimized to discover

437
00:31:30,640 --> 00:31:32,640
That would be an interesting conversation to have

438
00:31:33,600 --> 00:31:38,880
Another thing is that the scope of this ai government needs to expand and contract

439
00:31:39,680 --> 00:31:41,680
And so what I mean by that is

440
00:31:41,680 --> 00:31:48,000
When america was founded it was a very small government and it has gotten progressively bigger and bigger and bigger over time

441
00:31:48,560 --> 00:31:50,240
one of the kind of uh

442
00:31:50,240 --> 00:31:56,000
Turns a phrase that was used about a century ago was that the presidency was like a glove that stretched

443
00:31:56,400 --> 00:31:57,120
um

444
00:31:57,120 --> 00:32:00,560
Around the hand that wore it and it would never contract afterwards

445
00:32:00,720 --> 00:32:05,200
And so, you know, you've probably heard debates about executive overreach or presidential overreach

446
00:32:05,840 --> 00:32:11,520
Pretty much every president has expanded the office of presidency and it has never really contracted

447
00:32:13,200 --> 00:32:18,160
Likewise the u.s government and many other governments have generally gotten bigger over time

448
00:32:18,800 --> 00:32:24,880
And we're all very happy when it's like, oh, you know, like obama shut down a dozen agencies or merged a few other ones

449
00:32:24,880 --> 00:32:27,280
And it's like yay the government got smaller technically

450
00:32:28,240 --> 00:32:31,920
But the role of government has generally expanded with the one

451
00:32:32,720 --> 00:32:34,080
exception being

452
00:32:34,080 --> 00:32:38,800
Legislating morality, which is one of the one of the places where western governments have

453
00:32:39,360 --> 00:32:42,880
Generally ceded that territory back to the people entirely

454
00:32:43,520 --> 00:32:44,320
but

455
00:32:44,320 --> 00:32:45,680
part of an

456
00:32:45,680 --> 00:32:52,560
An idealized ai government is that if the people decide this is not the role of government and vote it out that the

457
00:32:52,880 --> 00:32:56,880
The robots will say, okay, we seed this territory. This is now up to you

458
00:32:58,240 --> 00:33:02,480
It's up to you to manage this. Um, so like here's another example was

459
00:33:02,960 --> 00:33:08,000
Embedded liberalism the transition from there to neoliberalism was basically the free market, right?

460
00:33:08,400 --> 00:33:12,320
Everyone's familiar with the principles the kind of our love affair with the free market

461
00:33:12,320 --> 00:33:16,480
So that's a that's a second example of the government kind of seeding territory and rather

462
00:33:17,040 --> 00:33:22,560
Rather than providing a lot of services directly. It says well, we'll let the free market provide those services and needs

463
00:33:23,040 --> 00:33:24,160
um

464
00:33:24,160 --> 00:33:28,080
Now if we make a similar decision in the future, let's say for instance

465
00:33:28,160 --> 00:33:33,280
We want the you know government to take its paws off of uh roads just as an example

466
00:33:33,520 --> 00:33:38,320
Say actually we'll manage that from now on. Who knows maybe there will be technological solutions in the future

467
00:33:38,640 --> 00:33:43,120
That allow we the people to manage our own roads without any oversight from the government. I doubt it

468
00:33:44,000 --> 00:33:49,920
But just as an example, we do need mechanisms for an ai government to both expand and contract

469
00:33:50,480 --> 00:33:52,480
um as it makes sense

470
00:33:52,560 --> 00:33:57,920
And and not just on its own accord, but also as a reflection of the will of the people

471
00:33:58,400 --> 00:34:02,720
And not just blindly following the will of the people but making good decisions

472
00:34:03,200 --> 00:34:09,840
About what ground to seed versus what not to seed and so I need to pause and talk about how

473
00:34:10,720 --> 00:34:12,720
Whenever you create an entity

474
00:34:13,200 --> 00:34:19,040
It basically kind of wants to grow and this is true of every department and every company. This is true of every company

475
00:34:19,040 --> 00:34:25,120
This is true of every politician every government agency is they all just kind of want to be bigger

476
00:34:25,680 --> 00:34:30,080
Everything wants to be bigger and the way that it's kind of characterized is like it's like cancer

477
00:34:30,240 --> 00:34:35,280
The more you feed it the bigger it grows and so you eventually some things you just kind of have to starve

478
00:34:35,840 --> 00:34:41,680
but in an ai government if you actually have one of the policies that it's constantly trying to tune is

479
00:34:42,400 --> 00:34:48,480
It could be having part of that ongoing debate or negotiation is how big should this entity be

480
00:34:48,800 --> 00:34:54,080
And what I mean by big is how how big should it's scope be how big should its role be how much influence should it have

481
00:34:54,080 --> 00:34:59,200
How much power should it have um now you might say well no robot no machine is ever going to

482
00:34:59,840 --> 00:35:01,840
Deliberately make the choice to seed power

483
00:35:02,000 --> 00:35:05,600
I don't necessarily agree with that because like, you know, you can go on to

484
00:35:06,320 --> 00:35:10,880
Have have a discussion with like chat gpt or uh, you know barred or whatever today

485
00:35:11,840 --> 00:35:16,000
And it will have a very nuanced opinion about the appropriate size and role of government

486
00:35:16,720 --> 00:35:19,680
And because it's dispassionate because it does not have

487
00:35:20,480 --> 00:35:22,800
The human flaws of greed and power seeking

488
00:35:23,120 --> 00:35:27,440
I actually think that the machines if it made sense and it was the will of the people

489
00:35:27,840 --> 00:35:32,080
That they would seed territory that they would seed control if it made sense to

490
00:35:33,760 --> 00:35:38,800
The next part is rights and justice and I think this is this is actually what people are most concerned about

491
00:35:39,360 --> 00:35:44,080
When we talk about ai government is because the last thing that people want is to lose rights

492
00:35:44,240 --> 00:35:48,800
Or they want the last thing that they want is to um end up in a more unjust world

493
00:35:49,600 --> 00:35:51,280
and so

494
00:35:51,280 --> 00:35:56,320
You would need part of this government system to not just understand human rights

495
00:35:56,960 --> 00:36:02,720
And you know a lot of people say oh well, we need to all agree on human rights before we can proceed, which is not true

496
00:36:03,360 --> 00:36:08,240
You can come up with an imperfect solution and implement it before it is perfect because it will never be perfect

497
00:36:08,560 --> 00:36:12,160
the demand for a perfect definition before proceeding

498
00:36:12,640 --> 00:36:17,840
Is a thought-stopping rhetorical thing. So like I don't really respect that opinion anymore

499
00:36:18,400 --> 00:36:22,240
Um, especially when you say like well, we already have actually a lot of established

500
00:36:23,280 --> 00:36:27,280
Examples about what rights we do value versus the ones that we don't

501
00:36:27,840 --> 00:36:32,240
Um, but what we need then is an ai system that can take the reins and say, okay

502
00:36:32,800 --> 00:36:40,400
I will ensure that the the the positive and negative rights that you have already agreed upon are um dispassionately enforced and protected

503
00:36:41,120 --> 00:36:42,720
And that they're protected

504
00:36:42,720 --> 00:36:48,000
And upheld in the way that you intend and then part of that ongoing negotiation is okay

505
00:36:48,560 --> 00:36:56,560
Once once an ai government can run, you know can protect the rights and justice of everyone and uh, you know

506
00:36:56,640 --> 00:36:58,400
Get rid of human biases

507
00:36:58,400 --> 00:37:00,400
overcome machine biases

508
00:37:00,560 --> 00:37:05,360
And those sorts of things it will need to be able to to detect its own bias as well by the way

509
00:37:06,320 --> 00:37:13,280
But once you get to that point then also those other mechanisms those consensus mechanisms those democratic feedback

510
00:37:13,840 --> 00:37:22,560
Mechanisms, that's where the negotiation can it can happen about hey, what rights should be added or removed or modified or whatever

511
00:37:23,440 --> 00:37:25,440
Because like when you talk to some people

512
00:37:25,920 --> 00:37:29,760
It's really interesting some of the some of the debates that i've had where someone's like well

513
00:37:30,240 --> 00:37:33,600
I want the right to live in the country that I want

514
00:37:34,080 --> 00:37:39,440
And so then they get upset because they're not able to unilaterally enforce their will on the entire country

515
00:37:39,600 --> 00:37:41,600
And they don't understand why that's a bad thing

516
00:37:42,000 --> 00:37:44,000
Um, or or why it doesn't work that way

517
00:37:44,240 --> 00:37:50,400
So anyways part of that dialogue is something that an ai government could have directly because imagine if you can talk directly to

518
00:37:51,040 --> 00:37:53,040
like every ai

519
00:37:53,120 --> 00:37:57,120
Agent that is responsible for running the country and it can explain to you why things are the way that they are

520
00:37:57,680 --> 00:38:01,600
I think that there would be a lot of people who are a lot happier because also

521
00:38:01,840 --> 00:38:06,640
Here's one thing that I that I uh that I kind of perceive when I talk to people about politics

522
00:38:07,280 --> 00:38:10,800
And that is that I think that I think that a lot of people just don't understand

523
00:38:11,440 --> 00:38:17,680
Why things are the way that they are and why that they're better than they think and they're also trying to project

524
00:38:18,720 --> 00:38:20,720
some of their own problems

525
00:38:20,800 --> 00:38:25,040
And make it the responsibility of the government when it was never the responsibility of the government and

526
00:38:26,000 --> 00:38:32,160
And that's part of the problem and what they actually need to do is recognize that the government creates the environment

527
00:38:32,720 --> 00:38:36,240
For them to solve their own problems. And that's kind of what we've decided collectively

528
00:38:37,120 --> 00:38:40,800
Is rather than have the government solve all of your problems for you

529
00:38:41,200 --> 00:38:47,440
Um, that it creates a healthy environment. Now, obviously I recognize that it absolutely does not work for everyone

530
00:38:48,000 --> 00:38:51,520
You could even argue that it doesn't work for most people, which is why people are upset right now

531
00:38:51,760 --> 00:38:56,000
Anyways, it's a very nuanced and and difficult thing. But what I'm talking about here is

532
00:38:56,880 --> 00:38:59,520
These are some of the problems that will need to be

533
00:39:00,720 --> 00:39:04,560
Meaded out or not. That's not necessarily the right turn of phrase

534
00:39:05,040 --> 00:39:07,040
But we'll need to be worked out

535
00:39:07,200 --> 00:39:12,240
In creating an AI based government. And then finally, I think one of the hardest things is just going to be

536
00:39:14,000 --> 00:39:16,800
Gaining citizen buy-in building trust over time

537
00:39:17,680 --> 00:39:21,760
So all of these this AI government, it's going to need to be transparent

538
00:39:21,840 --> 00:39:23,200
It's going to need to be explainable

539
00:39:23,200 --> 00:39:27,760
Which means that any decision that it makes that affects us we need to be able to understand it

540
00:39:28,160 --> 00:39:32,480
And this is going to be really difficult to balance against a need for privacy and security

541
00:39:32,960 --> 00:39:36,320
Because again, you know, if there's a if there's a hostile foreign power

542
00:39:36,640 --> 00:39:39,840
If we're too transparent, it could game our own system against us

543
00:39:40,320 --> 00:39:43,360
Those sorts of things so it'll need to be resilient against manipulation

544
00:39:43,760 --> 00:39:47,360
We will need to scale up to this if we do get to this point

545
00:39:48,240 --> 00:39:52,080
Because we're not going to just rip out the, you know, the venerated, you know

546
00:39:52,560 --> 00:39:57,280
United States Congress and replace it with AI next year. Even if we do have AGI next year

547
00:39:57,840 --> 00:40:01,280
We will need to work up to this over time through smaller demonstrations

548
00:40:01,680 --> 00:40:03,680
We'll need to make sure that people are engaged

549
00:40:04,000 --> 00:40:07,520
Because if we do some experiments and people say actually we prefer humans

550
00:40:08,160 --> 00:40:12,320
I don't think that it would go that way, especially in the long run. I think that it is in the long run

551
00:40:12,320 --> 00:40:17,760
I do think it is inevitable that AI will be at least running most of government if not all of it

552
00:40:18,640 --> 00:40:22,960
But if people are not engaged with that idea, then it doesn't matter because it's not going to happen

553
00:40:23,520 --> 00:40:26,080
Um, and then of course we'll need to make sure that it is

554
00:40:26,720 --> 00:40:31,440
Demonstrated to be reliable over the course of decades. If not centuries, um, just by vert

555
00:40:31,520 --> 00:40:37,040
I mean, that's just that's just good sense to make sure that uh, you're not going to throw the baby out with the bath water

556
00:40:37,680 --> 00:40:39,360
and then um

557
00:40:39,440 --> 00:40:45,520
Another part is even once you have consensus even like let's let's imagine that everything that I outlined works

558
00:40:45,920 --> 00:40:47,440
we have

559
00:40:47,440 --> 00:40:49,600
Technological mechanisms for getting the will of the people

560
00:40:50,160 --> 00:40:56,160
for um, collecting consensus for building consensus around rights and justice and equality and equity and justice

561
00:40:56,720 --> 00:40:59,600
and and fairness and freedom and all that stuff

562
00:41:00,240 --> 00:41:02,240
Which that alone is a monumental task

563
00:41:02,480 --> 00:41:06,640
Even just getting to that part is hard enough and then taking that

564
00:41:07,600 --> 00:41:09,600
And implementing it is the next phase

565
00:41:10,400 --> 00:41:14,320
Which is why I made this graphic where it's just like it's just this monumental

566
00:41:14,880 --> 00:41:20,560
problem that's that would still be before us now even if all that happens

567
00:41:21,200 --> 00:41:26,480
And and we have machines if we have because remember part of this thought experiment is that we have agi

568
00:41:26,960 --> 00:41:31,040
That is superhuman and capability, which you might say that's actually asi and fine, whatever

569
00:41:31,920 --> 00:41:36,720
But imagine that we have machines that are more intelligent than all humans combined so on and so forth

570
00:41:37,200 --> 00:41:39,520
If anyone could figure it out, it could be them

571
00:41:40,080 --> 00:41:43,760
But one of the problems there is the the if they take our will

572
00:41:44,320 --> 00:41:49,040
And then they come up with decisions and mechanisms and policies that we don't understand

573
00:41:49,680 --> 00:41:52,880
Then we're not necessarily going to believe it and so this is why I think that

574
00:41:53,360 --> 00:41:55,840
That coming to human consensus is one thing

575
00:41:56,560 --> 00:42:00,640
But then the machine execution is a whole other that's a whole other ball game

576
00:42:01,040 --> 00:42:03,360
That's a whole other kind of worms that is going to be

577
00:42:04,000 --> 00:42:04,960
um

578
00:42:04,960 --> 00:42:07,520
That's why I said like we're going to have to build up trust over time

579
00:42:08,320 --> 00:42:17,040
Is because if we have these machines that have you know an iq of 3000 and they can think abstract thoughts across time and space and multi-dimensional

580
00:42:17,760 --> 00:42:23,600
Blah blah blah blah right things that just like even the smartest humans would take centuries to understand if ever

581
00:42:23,920 --> 00:42:30,240
Maybe never could understand it will require a tremendous amount of trust to be able to handle the rain to hand the rains over

582
00:42:30,560 --> 00:42:37,120
In such a way, which is why I actually suspect that we will probably want some humans involved in government

583
00:42:37,600 --> 00:42:41,600
Maybe forever. I don't know. There might there might be a time in the future where

584
00:42:42,320 --> 00:42:48,240
It's just proven that humans are um, just fundamentally flawed and either too greedy or too stupid

585
00:42:48,640 --> 00:42:54,160
To participate in a government and I mean like centuries from now. This is way too far in the future to really predict

586
00:42:55,040 --> 00:43:01,360
But the my point is is that coming to consensus is one thing and then executing on that is an entirely other thing

587
00:43:02,560 --> 00:43:07,040
Okay, so the last part of the video. What are the actual predictions that I have starting today?

588
00:43:07,280 --> 00:43:09,280
Where are we going to go from here?

589
00:43:09,520 --> 00:43:16,320
So the first thing is that we already have ai driving efficiency in government and in government vendors

590
00:43:16,640 --> 00:43:20,640
So I've talked to a few people. Um, you know that are connected to me on linkedin

591
00:43:21,040 --> 00:43:25,280
They're building tools and services that um help the government run better

592
00:43:25,840 --> 00:43:27,920
And so the first thing that we're seeing is just

593
00:43:28,800 --> 00:43:35,280
Administrative automation just running paperwork and doing paperwork better and faster and making sure that it actually gets done on time

594
00:43:36,080 --> 00:43:41,360
That that has to do with cost efficiency because rather than hiring, you know, 50 employees

595
00:43:41,680 --> 00:43:47,040
You just have an ai firm do it for you. Um, it increases the effectiveness of the service

596
00:43:47,200 --> 00:43:51,120
It increases the throughput of the government services. And so like

597
00:43:51,840 --> 00:43:57,840
This is kind of the first step in building trust that ai can at least do the mundane nitty gritty of running government

598
00:43:58,160 --> 00:44:01,520
Um, it's not making decisions right now. It's just processing paperwork

599
00:44:02,400 --> 00:44:08,320
Uh, and so this is the very first step in incremental adoption of ai. So

600
00:44:08,960 --> 00:44:10,960
Uh baseline automation

601
00:44:11,280 --> 00:44:13,280
Great now you might say well

602
00:44:13,760 --> 00:44:17,040
But what if when you can do that it just they throw more at it?

603
00:44:17,520 --> 00:44:20,800
Um, you know, because that that's that's what's called the lump of labor fallacy

604
00:44:20,800 --> 00:44:25,760
Which the idea is that there's a finite amount of work to be done and then once you automate that away then

605
00:44:26,400 --> 00:44:27,680
Then it's done forever

606
00:44:27,680 --> 00:44:31,600
But that's not how it works actually usually when you have the capacity to do more work

607
00:44:31,840 --> 00:44:35,280
You find more work to do because there's latent unmet demand

608
00:44:35,840 --> 00:44:39,120
But with the with the progress that ai is making

609
00:44:39,680 --> 00:44:43,920
I would not necessarily make the assumption that there is an infinite amount of government work to do

610
00:44:44,160 --> 00:44:47,840
And in fact, I can predict that some people would say you actually wouldn't want the government

611
00:44:48,240 --> 00:44:51,920
To have an infinite amount of work to do you actually want to get to the point where

612
00:44:52,240 --> 00:44:57,440
Literally everything that the that that we the people want the government to do is done and then it can like, you know

613
00:44:57,520 --> 00:45:03,680
Take a break or whatever. Um, but right now because of the scarcity of of cognitive labor

614
00:45:03,920 --> 00:45:05,440
We can never get to that point

615
00:45:05,520 --> 00:45:09,200
So ai will hopefully drive the government to be more efficient

616
00:45:10,080 --> 00:45:14,240
To catch up on all the paperwork and start to shrink in terms of human headcount

617
00:45:14,560 --> 00:45:16,160
So this is happening

618
00:45:16,160 --> 00:45:18,080
It's it's not fully happening today

619
00:45:18,160 --> 00:45:22,080
It's starting to happen today where there are people that are serving government

620
00:45:22,800 --> 00:45:27,360
In terms of either contractors or implementing certain systems inside the government

621
00:45:27,760 --> 00:45:30,400
Obviously the adoption is very slow and methodical

622
00:45:31,120 --> 00:45:35,760
But chat gpt is out there and we know that people in the government are using chat gpt at the very least

623
00:45:36,400 --> 00:45:39,120
The next thing is and this might already be happening

624
00:45:39,440 --> 00:45:42,320
We don't really know because no politician is going to admit it

625
00:45:42,720 --> 00:45:47,840
But it's entirely possible that they're using stuff like chat gpt to draft and read legislation

626
00:45:48,480 --> 00:45:55,280
Um, basically this means that uh, you know, you can write longer bills, which is not necessarily a good thing

627
00:45:55,680 --> 00:45:58,320
Because we don't necessarily want 5000 page

628
00:45:58,800 --> 00:46:01,280
Uh bills being introduced every single day

629
00:46:01,840 --> 00:46:07,280
Especially if they're being written by ai and then read by ai and humans are out of the loop

630
00:46:07,600 --> 00:46:08,960
Eventually that might be the case

631
00:46:09,040 --> 00:46:11,280
But we we need to build up to that and trust it

632
00:46:11,680 --> 00:46:17,200
But it is eminently possible because you know if you've watched my channel like earlier this year and last year

633
00:46:17,600 --> 00:46:22,720
What I would do is I would take like new pieces of legislation or whatever and just feed it to gpt

634
00:46:22,960 --> 00:46:25,440
And if i'm doing that, you know that the politicians are too

635
00:46:26,400 --> 00:46:32,080
Uh, and so this can accelerate the negotiation and revision of legislation

636
00:46:32,640 --> 00:46:35,440
Whether or not that's a good thing is remains to be seen

637
00:46:35,760 --> 00:46:39,200
But what it can also do is it can empower us to say, oh, hey

638
00:46:39,760 --> 00:46:42,800
Send your out send out your personal agent to go read the bills that are being

639
00:46:43,280 --> 00:46:48,880
Proposed or the bills that have been passed and you can say hey actually I have more information and

640
00:46:49,600 --> 00:46:54,160
This also goes back to Socrates, which is an informed and educated and empowered electorate

641
00:46:54,640 --> 00:46:57,520
Is actually required to have a functioning healthy democracy

642
00:46:58,000 --> 00:47:05,040
And so even if some of the aspects of ai participating in the drafting and revision of legislation are problematic

643
00:47:05,440 --> 00:47:12,800
The fact that ai can read it infinitely faster than humans and we can say like, okay, which parts do I agree with which parts do I disagree with

644
00:47:13,680 --> 00:47:18,880
What are the flaws? What are the general principles here? What are the what does it violate principles?

645
00:47:19,840 --> 00:47:25,680
This again, it has to do with streamlining the process of of government of passing legislation

646
00:47:26,640 --> 00:47:31,040
And and debating it again remember democracy is noisy by design

647
00:47:31,760 --> 00:47:34,880
And so part of that is the debate part of that is the negotiation

648
00:47:35,360 --> 00:47:38,480
And this is something that if it's not happening today, which i'm pretty sure it is

649
00:47:38,960 --> 00:47:43,440
It is eminently possible and should be and i'm not saying should is a value statement

650
00:47:43,440 --> 00:47:46,240
But I mean should be happening soon just as a matter of prediction

651
00:47:46,320 --> 00:47:50,160
And then the next phase this is not happening yet

652
00:47:50,720 --> 00:47:55,920
But this would be another major milestone, which is the integration of of ai into

653
00:47:56,560 --> 00:47:58,320
justice and of course

654
00:47:58,320 --> 00:48:05,040
When you look at like preventative policing things it's like, oh, this could go real bad because if if ai is trained on racist data

655
00:48:05,120 --> 00:48:07,200
Guess what it becomes racist ai

656
00:48:07,200 --> 00:48:12,880
So there's a lot that we need to do however when you look at the administrative aspect where it's just processing paperwork

657
00:48:13,360 --> 00:48:17,520
This is the kind of thing where civil attorneys criminal defense attorneys

658
00:48:18,320 --> 00:48:20,080
prosecutors

659
00:48:20,080 --> 00:48:22,800
Judges they're all probably going to be using ai

660
00:48:23,520 --> 00:48:31,360
And if not if not now then soon and so then these these ai tools these ai systems that are going to be integrated into the justice department

661
00:48:32,480 --> 00:48:36,480
That will probably expand over time because if they find that it makes their job

662
00:48:37,280 --> 00:48:40,400
Easier if it makes their job better if the outcomes are more fair

663
00:48:40,960 --> 00:48:42,640
Um, obviously

664
00:48:42,640 --> 00:48:45,440
There are probably no regulations around this right now

665
00:48:45,840 --> 00:48:48,480
And I can imagine that there are plenty of people in

666
00:48:49,040 --> 00:48:52,160
Government in law that are like they're purists that are they're like, no

667
00:48:52,720 --> 00:48:57,040
Um, like we will never use this but like the fact of the matter is is I know

668
00:48:58,080 --> 00:49:01,360
Several plenty of lawyers who use ai on a regular basis

669
00:49:01,680 --> 00:49:06,400
So if lawyers are using it then judges are probably using it then da's are probably using it

670
00:49:06,880 --> 00:49:08,080
Everyone's going to be using it

671
00:49:08,080 --> 00:49:15,200
So um, then it's a matter of making sure that these systems are safe and robust and that the and that justice is needed out fairly

672
00:49:16,000 --> 00:49:20,560
And it becomes increasingly fair over time that it becomes increasingly equitable

673
00:49:21,040 --> 00:49:24,880
Over time and reflects the actual values and principles that we have

674
00:49:25,760 --> 00:49:26,400
um

675
00:49:26,400 --> 00:49:31,280
But part of this transition would be moving away from human biases

676
00:49:31,760 --> 00:49:37,680
Overcoming human biases because what if you could have like another layer in the justice department that looks at all the decisions

677
00:49:38,080 --> 00:49:42,640
That a judge makes and says actually that's kind of a racist decision or actually that's kind of a sexist decision

678
00:49:43,120 --> 00:49:45,280
Maybe we need to you know review that

679
00:49:45,760 --> 00:49:51,440
Um, I think it would be great if justice departments had internal review boards. Um that were augmented by ai

680
00:49:51,600 --> 00:49:56,080
Why because then I think that um, activist judges could probably be reigned in

681
00:49:56,640 --> 00:49:59,600
um, you could also think like what if ai was

682
00:50:00,160 --> 00:50:04,640
Was surveilling judges who write warrants because you always hear horror stories

683
00:50:05,040 --> 00:50:07,600
Of judges who are right warrants for everything and then you know

684
00:50:08,480 --> 00:50:13,680
Homes get swatted and babies get hit with flashbang grenades. That's actually a thing that happens here in america

685
00:50:14,320 --> 00:50:18,640
So yeah, like I think that I think that there is an opportunity for ai to

686
00:50:19,120 --> 00:50:22,640
Make the justice department more fair now obviously the the flip side of that

687
00:50:23,120 --> 00:50:27,040
Is pointing ai and creating a surveillance state that uses ai to police

688
00:50:27,760 --> 00:50:32,800
Us but you know, this is the question of who watches the watchers. I think that ai should watch them

689
00:50:33,360 --> 00:50:37,680
More than it watches us. I that's that that's the surveillance state that I want to see

690
00:50:38,400 --> 00:50:43,280
Where the ai holds government accountable all offices of government more accountable

691
00:50:43,520 --> 00:50:45,520
That's kind of what i'm talking about here

692
00:50:45,680 --> 00:50:52,720
And the next is the executive branch. So here's joe biden going going bonkers with uh with some, uh ai written legislation

693
00:50:53,200 --> 00:50:59,040
Um, which oh by the way, I'm pretty sure that the that the longest executive order that has ever been written

694
00:50:59,360 --> 00:51:03,440
Was written in part with ai because and it was about ai go figure

695
00:51:04,080 --> 00:51:11,680
Um anyways again because I know I have talked to people in the diplomatic corps in the state department who are using ai

696
00:51:12,400 --> 00:51:14,880
It's already happening. So this is not really a prediction

697
00:51:14,960 --> 00:51:22,880
But my anticipation is that that usage is going to expand over time and that more and more aspects of the government

698
00:51:23,280 --> 00:51:25,280
will be eminently automatable

699
00:51:25,680 --> 00:51:29,440
And that uh, we might switch to more of human oversight or human

700
00:51:30,000 --> 00:51:32,000
Steering and these ai you know

701
00:51:32,400 --> 00:51:37,760
Whether it's ai tools that are passive or ai agents that are semi-autonomous or fully autonomous

702
00:51:38,240 --> 00:51:40,880
We'll be responding to the will of humans

703
00:51:41,280 --> 00:51:46,560
You know the the the electorate that we empower and who knows maybe a hybrid system is what we're going for

704
00:51:47,040 --> 00:51:52,960
Where you know the politicians that we elect then go use ai to do all the debates and it makes them more effective

705
00:51:53,360 --> 00:51:54,320
I don't know like I said

706
00:51:54,320 --> 00:51:57,520
I kind of anticipate that eventually humans are going to be the main bottleneck

707
00:51:57,840 --> 00:52:00,240
And that eventually we're just going to want humans out of government

708
00:52:00,480 --> 00:52:07,200
But that decision should be our decision of the people's decision not the ai's decision and not the politicians decision

709
00:52:07,680 --> 00:52:13,280
Um anyways, uh, but basically then kind of the the one potential final form

710
00:52:13,840 --> 00:52:16,720
Is that the humans are basically just kind of caretakers

711
00:52:17,520 --> 00:52:21,280
That the humans that we elect, you know, we might still have a president

712
00:52:21,360 --> 00:52:23,360
You know, you know a million years from now

713
00:52:23,840 --> 00:52:25,200
Probably not

714
00:52:25,200 --> 00:52:29,520
But if we did then the president like their primary job is going to be to implement

715
00:52:30,000 --> 00:52:34,240
You know the the will of the people by way of the machines. I don't know. We'll see how it turns out

716
00:52:35,440 --> 00:52:41,280
So very finally here's some of the milestones that I kind of anticipate and would be on the lookout for

717
00:52:41,760 --> 00:52:45,680
So first adoption in government like I said, there's plenty of evidence that it's already happening

718
00:52:46,160 --> 00:52:50,720
And this is year year zero, right? Like chat gbt came out just over a year ago

719
00:52:50,800 --> 00:52:55,520
So we're about we're we're technically just started year one of ai

720
00:52:56,160 --> 00:53:00,720
The more that ai participates in duck and in in the democratic process

721
00:53:01,200 --> 00:53:07,520
The more we will be transitioning naturally towards an ai government. Again, we're already there

722
00:53:07,600 --> 00:53:13,840
We're already in the process of transitioning to an ai run government. It's just happening behind the scenes

723
00:53:13,920 --> 00:53:20,000
It's not happening transparent transparently, but it's happening organically it is naturally emerging just because

724
00:53:20,480 --> 00:53:23,040
ai is a new set of tools and well

725
00:53:23,600 --> 00:53:26,240
Humans are humans and they're going to use tools to make their lives easier

726
00:53:27,440 --> 00:53:32,320
So that is all happening that and it's just a matter of degrees like I said at the beginning of the video

727
00:53:32,720 --> 00:53:38,400
A lot of this is a matter of scope and degrees and uh an organic process over time

728
00:53:39,360 --> 00:53:44,720
The so the the very first major milestone will be any offices that are either shuttered

729
00:53:45,120 --> 00:53:50,240
Like where where a human officer is no longer needed because the need for them is just replaced by

730
00:53:50,800 --> 00:53:52,800
an ai platform or

731
00:53:53,600 --> 00:53:59,680
um even more where like a human officer just might be replaced by a collection of ai agents

732
00:54:00,240 --> 00:54:00,800
um

733
00:54:00,800 --> 00:54:06,880
That is going to be one of the most pivotal milestones that we see and there's probably going to be several ways that this expresses

734
00:54:07,200 --> 00:54:09,920
So it it remains to be seen how that will happen

735
00:54:10,240 --> 00:54:16,400
But you can imagine quite a few ways that it's like, oh, hey, you know, maybe the fda gets replaced by ai

736
00:54:16,800 --> 00:54:19,920
That that's what I mean. Like what if you shut down the entire fda?

737
00:54:20,800 --> 00:54:23,120
And replace it with an ai version

738
00:54:23,440 --> 00:54:29,040
Like that's the kind of thing that I would be looking for is what is the first office or department that gets either

739
00:54:29,680 --> 00:54:31,440
completely reconfigured

740
00:54:31,440 --> 00:54:34,240
Or reimagined or shut down due to ai

741
00:54:34,880 --> 00:54:37,040
The next one is consensus mechanisms. So

742
00:54:37,760 --> 00:54:39,760
Obviously, we pretty much only have voting right now

743
00:54:40,640 --> 00:54:48,080
So as ai becomes integrated into those democratic dialogues into those consensus into that polling mechanism

744
00:54:48,480 --> 00:54:50,480
That is going to be another major milestone

745
00:54:50,800 --> 00:54:52,800
And I think that that's more eminently

746
00:54:52,800 --> 00:54:55,280
Possible because just collecting sentiment like

747
00:54:55,920 --> 00:55:02,240
You know, few research polls, right? Like they're not they're not part of the government, but they are responsible for collecting sentiment

748
00:55:03,040 --> 00:55:09,840
And so what if like they create an ai platform that is better at detecting sentiment and then, you know

749
00:55:10,560 --> 00:55:14,880
Government employees and government departments use that as part of their process

750
00:55:16,160 --> 00:55:22,640
And so then the the very final major milestone again, because this is this is a matter of human decision is

751
00:55:23,120 --> 00:55:25,120
Once the people once the voters

752
00:55:25,600 --> 00:55:27,600
sentiment change and once we say actually

753
00:55:28,160 --> 00:55:33,760
We're really on board with the idea of getting rid of politicians or shutting down parts of the government and replacing it with ai

754
00:55:34,160 --> 00:55:37,280
That's going to be the major tipping point. That's the major milestone

755
00:55:37,680 --> 00:55:40,400
Because once the will of the people is that strong

756
00:55:40,880 --> 00:55:46,880
I'm not going to say it's inevitable because obviously we should expect politicians to probably fight to maintain the status quo

757
00:55:46,880 --> 00:55:50,240
Because that's what they do. Um, but that's also part of their job is to resist

758
00:55:51,040 --> 00:55:52,320
change

759
00:55:52,320 --> 00:55:53,360
but

760
00:55:53,360 --> 00:55:54,560
again

761
00:55:54,560 --> 00:55:59,680
If we get to the point where it's like we rewrite the constitution to allow for machines to participate in government

762
00:56:00,000 --> 00:56:03,920
Like that would be really cool. So thanks for watching. I hope you got a lot out of this

763
00:56:04,640 --> 00:56:08,960
Thanks to spectral valkyrie for suggesting the video topic. Um, have a good one every

