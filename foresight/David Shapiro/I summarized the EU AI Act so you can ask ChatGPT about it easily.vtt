WEBVTT

00:00.000 --> 00:05.120
I think we're ready to begin um you saw me look at the camera used to be over

00:05.120 --> 00:11.240
there now you're over here okay so I ran a poll 17 hours ago I asked if y'all

00:11.240 --> 00:17.600
wanted me to do a video on the EU AI Act man god names gotta get better with

00:17.600 --> 00:23.320
names I'm good with acronyms come to me for acronyms Gato Gaia ages okay anyways

00:23.320 --> 00:27.520
so y'all were confused about what I meant by Haas which is something from

00:27.520 --> 00:32.440
here in the south basically Haas means just something big right it's short it's

00:32.440 --> 00:40.120
a southern dialect for horse or in particular a big horse so this document

00:40.120 --> 00:46.760
is a Haas because look how freaking long it is it just keeps going so I plugged

00:46.760 --> 00:55.720
it in over here and it is 70,000 tokens long so even if I had access to GPT-432

00:55.720 --> 00:59.400
K which I did briefly and then they revoked it I think they got overwhelmed

00:59.400 --> 01:05.320
because I used it I tried to use GPT-432 K on a couple things and it was just

01:05.320 --> 01:09.880
like server is overloaded servers over anyways so hopefully I get that back but

01:09.880 --> 01:13.520
the idea what there would be I could read it and you know chop it up into maybe

01:13.520 --> 01:17.920
four sections three or four sections and read the whole thing but we don't have

01:17.920 --> 01:25.040
that and I do have GPT-3.5 turbo 16k 0613 so this model is actually super

01:25.320 --> 01:33.080
steerable it is actually better than original GPT-4 add a lot of things it's

01:33.080 --> 01:36.800
still kind of dumb especially if the instructions are too complex but as long

01:36.800 --> 01:46.600
as you give it just one task GPT-3.3.5 turbo 0613 the June 13th model is more

01:46.600 --> 01:50.720
than adequate for most things now that being said because I'm interpreting

01:51.040 --> 01:58.400
and I'm doing summarization I'm gonna use 04613 so the instructions that I gave

01:58.400 --> 02:03.600
it just now and I know that I'm ready to start the video primary purpose zoom in

02:03.600 --> 02:08.640
a little bit the primary purpose or the following is a chunk of legislation your

02:08.640 --> 02:14.720
job is to summarize this legislation with two primary goals one drastically

02:14.720 --> 02:17.920
reduce the word count and two retain enough context that it will still make

02:18.000 --> 02:21.600
sense the reason for this is the current AI technology can only read chunks that

02:21.600 --> 02:25.600
are so big method the user will give you a chunk of legislation via chat your

02:25.600 --> 02:28.960
response must only be the summarized version do not chat with the user engage

02:28.960 --> 02:33.480
with them or offer any other commentary summarize only so I copied the first

02:33.480 --> 02:41.320
hundred lines of the legislation in you here and this is what it spit out so it

02:41.320 --> 02:45.800
took all that and just said okay this is what it means so the first hundred

02:45.800 --> 02:54.760
lines which you can see here so we've got 344,000 characters 3665 lines of

02:54.760 --> 02:58.720
stuff to go through I'm not going to read the whole thing I'm not AI explained

02:59.720 --> 03:03.760
that dude just like you all are impressed with how much work I can do I'm

03:03.760 --> 03:07.760
impressed with how much that dude can read just honestly I'm maybe he uses

03:07.760 --> 03:15.280
chat GPT I don't know anyways if you're watching it's just a joke okay so

03:15.280 --> 03:23.480
anyways so ultimately basically that that first hundred lines was summarized

03:23.480 --> 03:27.240
and condensed down to the European Commission proposes a regulation for

03:27.240 --> 03:30.760
harmonized rules on artificial intelligence aiming to balance the

03:30.760 --> 03:35.600
socioeconomic benefits of AI with potential risks the proposal seeks to

03:35.600 --> 03:39.520
ensure AI systems are safe respect fundamental rights provide legal

03:39.520 --> 03:43.680
certainty for investment and innovation enhance governance and prevent market

03:43.680 --> 03:48.640
fragmentation so it has says nothing about existential risks or prevent AI

03:48.640 --> 03:52.360
from killing everyone it's sort of implicit because like if AI kills

03:52.360 --> 03:55.840
everyone you can't have investment in innovation but I would rather see

03:55.840 --> 04:00.560
legislation that is explicit it proposes a risk-based approach prohibiting

04:00.560 --> 04:04.800
certain harmful AI practices and setting requirements for high-risk AI systems

04:04.800 --> 04:09.960
okay cool we'll see how they define that later the proposal also establishes a

04:09.960 --> 04:13.520
governance system at member state level and a European artificial intelligence

04:13.520 --> 04:16.760
board at union level okay cool so this is this is going to be an

04:16.760 --> 04:21.080
international regulator great it is consistent with existing union

04:21.080 --> 04:24.680
legislation and policies including data protection consumer protection

04:24.680 --> 04:28.760
non-discrimination and gender equality so these are all very low-level risks

04:28.760 --> 04:33.080
none of this is actually talking like when they say high risk they're probably

04:33.080 --> 04:38.080
meaning like the social credit system that is used in China which that is a

04:38.080 --> 04:43.080
high risk but it is not the highest risk the proposal is based on article 114 of

04:43.120 --> 04:48.040
the Treaty of the Functioning of the European Union Union the TFEU which

04:48.040 --> 04:51.880
ensures the establishment and functioning of the internal market okay so this is

04:51.880 --> 04:56.000
mostly a market-oriented piece of legislation great so we know that this

04:56.000 --> 04:59.480
works so let's go ahead and save this out I'm gonna walk you through the whole

04:59.480 --> 05:04.680
process and then I'll yeah so this is this is how this is how we're gonna

05:04.680 --> 05:08.240
proceed for those of you that are newer to my channel this is actually the

05:08.240 --> 05:11.440
original format that I used where I would where I would walk you through the

05:11.440 --> 05:17.080
entire process so just watch that on 2x and you'll see the whole process of how

05:17.080 --> 05:24.600
I approach these things so we'll call this system summarize yes dot text and so

05:24.600 --> 05:28.360
basically I give it a system a system message up with very very clear

05:28.360 --> 05:33.240
instructions and and what I expect and and what it should expect and then it

05:33.240 --> 05:39.920
gives you very clear consistent results so then we come over to do to do to do

05:39.920 --> 05:45.320
to do step one simplify so this is I'm just re I'm borrowing code which I

05:45.320 --> 05:53.920
always do so we've got this so this is what we're gonna use to do that this is

05:53.920 --> 05:57.400
this is this is a KB service that I'm working on so I'll show you that in an

05:57.400 --> 06:06.240
upcoming video but you don't get to see that yet we don't need KB functions so

06:06.240 --> 06:11.120
delete that flask routes we're not gonna do a flask app so that's also fine

06:11.120 --> 06:15.680
actually I guess I just delete most of it okay cool so we get rid of flask

06:15.680 --> 06:19.040
cuz we're not gonna do that we're not gonna do threading we're not gonna we

06:19.040 --> 06:27.800
don't need flask or logging or JSON or YAML okay clean it up I probably should

06:27.800 --> 06:31.320
have done that before I started the video but it's good to it's good for you

06:31.320 --> 06:35.600
to see how messy my process is I am the first person to tell you I am not a

06:35.640 --> 06:40.120
professional developer I never was my professional background was I was in

06:40.120 --> 06:44.000
virtualization and automation so I'm an automation engineer which is why I

06:44.000 --> 06:48.960
approach things the way that I do which is creating discrete steps so you notice

06:48.960 --> 06:54.400
the thought the title of this is step one simplify okay cool so basically what

06:54.400 --> 07:01.760
we're gonna do is we're going to ask this handy dandy coding chatbot that I

07:01.800 --> 07:11.440
built which you can use this it is available over here I had a bunch of

07:11.440 --> 07:18.840
people submitting pull requests and they kept trying to like change the way that

07:18.840 --> 07:22.880
this thing works so I just said it to public archive so here's the thing is I

07:22.880 --> 07:29.320
welcome pull requests that are like simple fixes or small improvements don't

07:29.320 --> 07:33.440
refactor my code just fork it right like there's 19 forks if you want to if you

07:33.440 --> 07:37.600
want to fundamentally change how it works fine but I got tired of people

07:37.600 --> 07:41.480
messing up my code so I just said it to public archive and guess what like

07:41.480 --> 07:44.880
people you can still do whatever you want with it anyways so we're gonna use

07:44.880 --> 07:50.320
this as a co-pilot tool because I got frustrated with GitHub because they're

07:50.320 --> 07:57.440
co-pilot customer service whatever documentation is garbage okay let's see

07:57.440 --> 08:05.680
I have here let's just write a function that accepts a gigantic string and

08:05.680 --> 08:16.280
returns now let's see and let's see splits it by lines and then chunks 100

08:16.280 --> 08:32.000
lines together and returns those chunks as strings so the final result will be a

08:32.000 --> 08:43.880
list of strings each string represents 100 lines of the original okay so this

08:43.880 --> 08:50.960
is this is my coding chatbot assistant that it uses it also uses GPT for you I

08:50.960 --> 08:58.120
tried it you can actually switch it to oh it's using the old one hold on now I

08:58.120 --> 09:04.560
need to update that hold on hold on that's the wrong model coding chatbot

09:04.560 --> 09:07.880
assistant see this is what I mean is someone someone updated it oh no my

09:07.880 --> 09:12.040
local one uses the right one so someone updated it with the wrong model and made

09:12.040 --> 09:15.640
a bunch of other assumptions and I was just like no this is not this is not

09:15.640 --> 09:22.760
what I wanted okay so here we go here's the function Python chunk strings line

09:22.760 --> 09:31.320
lines equals split oh wow I did it in two lines cool this functions first splits

09:31.320 --> 09:40.520
the string into lines using the delimiter then it uses a list comprehension

09:40.520 --> 09:45.320
to create chunks of 100 lines each the range yep the result is a list of strings

09:45.320 --> 09:51.280
cool excellent excellent excellent so I'm gonna go ahead and copy this out oh and

09:51.280 --> 09:56.680
another good thing is that uh like well yeah you see how it works all right so

09:56.680 --> 10:05.600
we'll go ahead and do that so chunk strings so first we want to just act

10:05.680 --> 10:16.760
equals open file and I've got it named as act text just right here yep oh and

10:16.760 --> 10:23.320
also this excuse me this this uses a scratch pad so what I can do is I can

10:23.320 --> 10:30.840
actually populate the code that I'm working on over here so now it's aware

10:30.840 --> 10:35.520
of what I'm working on so this scratch pad is a holdout so rather than giving it

10:35.520 --> 10:43.600
the code in sequence the the coding chatbot actually has a it has here let me

10:43.600 --> 10:46.840
show you the system message so here's the instructions your Python coding

10:46.840 --> 10:51.000
assistant you know me turn on word wrap your Python coding assistant etc etc

10:51.000 --> 10:56.040
scratch pad so basically tells you the scratch pad is usable you know so that

10:56.040 --> 10:59.560
you know what the user is working on so that you can talk about this and this is

10:59.560 --> 11:05.360
passed to the chatbot every time so whatever the conversation is like that

11:05.360 --> 11:10.240
that is in the past I don't know if I'm explaining that well anyways point being

11:10.240 --> 11:14.000
is that it see it can see the code that you're working on as long as you keep

11:14.000 --> 11:23.560
this updated okay so that's the first hundred lines let's go ahead and see

11:23.560 --> 11:29.120
where did it go step one simplify cool so act equals that and then we'll say

11:29.160 --> 11:37.400
chunks equals see chunk string chunk string act all right so that this

11:37.400 --> 11:44.600
basically creates the chunks that we're gonna be working on and that is that

11:44.600 --> 11:50.680
let's see I'm gonna need to watch this because mmm well here let me just show

11:50.680 --> 11:57.560
you something real quick so the first hundred lines if we take that over to

11:57.840 --> 12:03.720
playground and paste it in here you see that a hundred lines is about 4,000

12:03.720 --> 12:09.920
tokens so that would obviously be too big for text of inchio 3 but with with

12:09.920 --> 12:17.320
GPT-4 we have 8,000 tokens and then with 3.5 16k we have 16,000 tokens so we

12:17.320 --> 12:23.360
could actually probably do more but the thing is is that again 3.5 turbo is

12:23.360 --> 12:28.440
actually you know it let's try it real quick heck with it heck with it while

12:28.440 --> 12:36.080
we're here let's go back over to chat let's give it this chunk because if it

12:36.080 --> 12:42.360
can if I can do it faster and cheaper why not why not and then we need this is

12:42.360 --> 12:49.600
our system message we need to make sure that we're gonna use 3.5 turbo 16k so

12:49.600 --> 12:53.920
that it's got enough space okay turn the temperature down we do not want you to

12:53.920 --> 12:59.000
be creative thank you very much all right and then let's see how well it

12:59.000 --> 13:06.160
summarizes it yeah so it's not this summarization is not nearly as elegant

13:06.160 --> 13:15.520
or as concise but just glancing at it it's okay I think I'm gonna stick with

13:15.800 --> 13:21.280
four but I'm glad I did this side-by-side so the the the GPT-4 it's a much more

13:21.280 --> 13:25.880
elegant summary and it's also less worthy even though so it's not quite as

13:25.880 --> 13:30.080
fast and it's not quite as cheap because we need to capture the essence of

13:30.080 --> 13:34.640
something that's really important let's use the smarter model now that being

13:34.640 --> 13:41.400
said again 3.5 turbo the the June 13th one plenty plenty good for a lot of

13:41.400 --> 13:48.320
things okay cool so I'm glad I ran that test where are we what am I doing I don't

13:48.320 --> 13:54.480
know I'm lost I'm always lost there's this meme it's like a pug in a field

13:54.480 --> 13:59.720
with a wizard hat and it says that the meme is like not all who wander are

13:59.720 --> 14:05.160
lost except Dave Dave is lost as fuck and that's me I'm the pug with a wizard

14:05.160 --> 14:10.000
hat does that make any sense I need more coffee

14:11.440 --> 14:14.640
okay all right I hope you find this entertaining because I just woke up and

14:14.640 --> 14:19.540
I was like my brain's like hey we should work on this all right now we're back

14:19.540 --> 14:23.400
here all right we've got our chunks so now what we need to do so this is this

14:23.400 --> 14:30.760
is where it gets fun so four chunk in chunks this is super straightforward

14:30.800 --> 14:43.920
let's see messages equals this is gonna be a list and then the role will be

14:43.920 --> 14:54.200
user and the content wow I know how to type I promise it's just getting it from

14:54.200 --> 14:58.640
my head to the to the hands on the keyboard to the screen that's too many

14:58.680 --> 15:05.120
steps right now content equals chunk okay cool so basically what we're doing

15:05.120 --> 15:10.640
right here is we're setting it up to look exactly like this so I'm putting

15:10.640 --> 15:14.480
the chunk in here and then we also need to load the system message so what we're

15:14.480 --> 15:20.840
gonna do is we're gonna do system equals open file system underscore

15:20.840 --> 15:27.320
summarize so this is this is the instructions dot text so system message

15:27.360 --> 15:38.360
is the new prompt engineering all right cool so then we'll do role system and

15:38.360 --> 15:46.600
content is system all right so now we're ready to pass it up to our model right

15:46.600 --> 15:53.880
here so then we'll just do response equals chatbot messages ta-da is that

15:53.880 --> 16:00.360
simple so it's ready and so this response is going to be the summary and so

16:00.360 --> 16:04.360
now I need to figure out how I want to save this save these summaries out in a

16:04.360 --> 16:17.640
way that makes sense let's see let me ask my chatbot assistant okay cool great

16:17.640 --> 16:26.800
now I want to pass a list of strings to a function and have that function save

16:26.800 --> 16:36.440
them to a specified folder as a parameter and I want it to serialize

16:36.800 --> 16:51.080
those files like so so it'll be like file 001 dot text file 0002 dot text and so

16:51.080 --> 17:02.760
on let's see you should see the script I'm working on all right cool so then

17:02.800 --> 17:09.840
we're gonna we're gonna have summaries equals list and then summaries dot

17:09.840 --> 17:15.720
append response so now basically we're gonna have the summaries all in order

17:15.720 --> 17:20.120
and what I'm gonna do is I'm gonna copy and paste this into my scratch pad so

17:20.120 --> 17:24.040
that the chatbot knows what I'm working on and I'll show you how that it says oh

17:24.040 --> 17:28.800
okay cool I probably should have told it that I'm gonna do that with the summaries

17:28.960 --> 17:33.760
it's usually pretty good at making the inference okay cool let's see def save

17:33.760 --> 17:40.240
strings if os path exists or if it doesn't exist make it otherwise enumerate

17:40.240 --> 17:44.720
strings so as long as I've been using Python I'm not entirely sure how

17:44.720 --> 17:52.520
enumerate works maybe I should ask all right but let's go over here let's go

17:52.520 --> 18:07.520
back to my script save strings cool file I05 interesting yes see I'm not even

18:07.520 --> 18:14.120
sure how that works fantastic let's see if it let's see if it works though the

18:14.120 --> 18:18.400
function first checks that the specified folder exists excellent then it uses it

18:18.400 --> 18:22.480
to make it then then iterates over the list of strings using enumerate which

18:22.480 --> 18:26.920
provides both the index and the value okay so that's what enumerate does the

18:26.920 --> 18:32.480
index is used to generate the file name with I colon O5 in the f string

18:32.480 --> 18:39.520
ensuring that the index is zero padded to five digits well that was easy cool

18:39.520 --> 18:48.480
right and then it uses the right method yeah so instead I want I was hoping it

18:48.480 --> 18:56.360
would use my save file but that's fine so let's go to here and we're gonna do

18:56.360 --> 19:05.280
summaries and so instead we're going to assume that that is already there and

19:05.280 --> 19:24.640
then we are going to do file path equals I was path join folder yeah that works

19:24.640 --> 19:41.320
and then we are going to do save file because this so my save file function

19:41.320 --> 19:46.800
encodes it in UTF-8 so just reuse something rather than do it here because

19:46.800 --> 19:50.240
you see this doesn't do it in UTF-8 you want to make sure that you have a nice

19:50.280 --> 19:56.000
standardized thing that's what I'm doing here file path and s so that should be

19:56.000 --> 20:04.760
good fine all right so save strings so then we do save strings we'll do

20:04.760 --> 20:15.360
summaries no I need to do yes summaries and then summaries that should work now

20:15.360 --> 20:23.640
that being said I want to print the response as I get them there we go and

20:23.640 --> 20:34.920
then response all right let's give this a whirl and see if it works CD what is this

20:34.920 --> 20:47.000
EU AI act zoom in a little bit Python step 01 this will probably take a while

20:47.000 --> 20:57.200
because we've got 3,000 line 3300 lines there we go cool hmm hold on oh right

20:57.200 --> 21:03.480
right right I forgot about this okay so this is an important thing what I started

21:03.480 --> 21:08.720
doing and I forgot to integrate this so what I started doing is I when I whenever

21:08.720 --> 21:13.240
I call the chatbot I return the text and the token use so because this is

21:13.240 --> 21:16.760
actually really helpful if you just go ahead and return the tokens so that you

21:16.760 --> 21:22.400
know when to summarize it so instead what I need to do is response tokens

21:22.400 --> 21:28.880
because I don't need to save I don't need to save a tuple out here but this

21:28.880 --> 21:37.040
otherwise looks good and then what I'm gonna do is I'm gonna go grab something

21:37.040 --> 21:40.160
to make the the printout look a little bit better

21:40.160 --> 21:46.360
to do to do to do to do reflective journaling tool this one has this one

21:46.360 --> 22:00.200
has good pretty output so we're gonna do formatted lines yep so take the formatted

22:00.200 --> 22:15.620
lines here and then we'll do print new line new line new line and formatted

22:15.620 --> 22:23.080
lines all right so that will that'll make it that'll make it prettier and then

22:23.080 --> 22:30.840
we'll also use so this this is this is why I appreciate when people add feedback

22:30.840 --> 22:36.080
is we added someone added the halo which is a little like thing that shows that

22:36.080 --> 22:44.080
it's thinking so I'm gonna add that real quick as well and the way that you use

22:44.080 --> 22:47.920
that is down here

22:54.040 --> 22:57.480
and so once once this is running I'll pause the video so you don't have to

22:57.480 --> 23:00.960
watch the whole thing so you're actually probably closer to the end if I had to

23:00.960 --> 23:03.280
guess

23:05.760 --> 23:21.200
oops spinner start so we'll say summarizing next chunk and then spinner stop

23:24.080 --> 23:29.320
okay so let's try this make sure it works

23:32.200 --> 23:36.560
summarizing next chunk hey look now it gives us some output better user

23:36.560 --> 23:44.160
experience it tells me what it's doing text wrap is not defined whoops what do

23:44.160 --> 23:49.360
you mean I need to import everything that you use import text wrap try that

23:49.360 --> 23:54.120
again third time's a charm all right and if this works then I'll go ahead and

23:54.120 --> 23:57.480
pause it and then we'll come back once the whole video is or once the whole

23:57.480 --> 24:05.640
thing is done why is it in hold on hold on that's not right why are you giving

24:05.640 --> 24:14.880
me this garbage that's not correct oh right I need to print out formatted

24:14.880 --> 24:18.320
text my bad

24:20.880 --> 24:27.000
don't give me this nonsense because basically what you want to do is you

24:27.000 --> 24:30.400
want to have it formatted in such a way there we go see so now we have this nice

24:30.400 --> 24:34.560
little block it's easier to read all right cool so this is working we'll watch

24:34.560 --> 24:39.240
it just a couple times you see how fast it is the the June 13th update is much

24:39.280 --> 24:47.720
much faster let's see excellent excellent excellent so we will I'm gonna pause the

24:47.720 --> 24:56.320
video and we'll come back and and take a look at the final result cheers okay and

24:56.320 --> 25:01.520
we're back so after running it all here let me just show you what the results

25:01.520 --> 25:09.840
were we've got 37 files each with a summary and I wrote a really quick I

25:09.840 --> 25:14.320
hacked together a really quick script that merged them all and so the merged

25:14.320 --> 25:21.560
result is 34,000 characters long so we reduced it by a factor of 10 to 1 just

25:21.560 --> 25:27.640
just shy of 10 to 1 which when you plug that in over here that's 6,000 tokens so

25:27.680 --> 25:32.440
we went from from 60,000 or 70,000 tokens I don't remember exactly to 6,000

25:32.440 --> 25:36.400
tokens one of the reasons that we had a more drastic reduction reduction of

25:36.400 --> 25:40.920
token count is because we removed all the serial numbers and stuff because

25:40.920 --> 25:45.400
that's kind of superfluous if you if you remove symbols and stuff like this

25:45.400 --> 25:50.240
these are high token things if it's ordinary words like AI and each system

25:50.240 --> 25:56.560
these are easy for the model to tokenize so that means what we can do now is we

25:56.560 --> 26:05.200
can just take this whole thing and come over to chat and say let's see main

26:05.200 --> 26:18.400
purpose here turn it believe that you are a chatbot tasked with discussing the

26:18.400 --> 26:27.240
following legislation with the user make sure to well hell but I mean that

26:27.240 --> 26:37.320
that's all it is use the legislation summary below to conduct the conversation

26:37.320 --> 26:44.920
and that's it and so then we say a legislation summary and we'll copy paste

26:44.960 --> 26:50.440
it here and so then we move over to we could do 16k because that'll be that'll

26:50.440 --> 26:54.720
be faster actually here let's try that real quick let's try that temperature

26:54.720 --> 27:08.040
there okay give me a high level overview of this legislation blah blah blah

27:08.160 --> 27:17.480
okay cool we're new after five years how is it funded let's see the funding and

27:17.480 --> 27:20.640
implementation of this legislation comes from the multi-annual financial

27:20.640 --> 27:25.040
framework blah blah blah the financial impact includes allocation of resources

27:25.040 --> 27:36.800
and having watched it go through how many employees will it cost there we go

27:36.800 --> 27:44.840
ten full-time equivalent employees all right so we can clear that out just

27:44.840 --> 27:50.360
because it ultimately is superfluous so some of the questions let's see will

27:50.360 --> 28:00.280
this legislation hamper research and innovation let's see the legislation

28:00.280 --> 28:02.920
aims to balance the benefits of AI research and innovation with the need

28:02.920 --> 28:06.200
for safety and respect for fundamental rights it includes measures to support

28:06.240 --> 28:10.640
innovation such as AI regulatory sandboxes and reducing the regulatory burden

28:10.640 --> 28:14.920
on SMEs and startups so the SMEs are going to be subject matter experts like

28:14.920 --> 28:19.520
UNI as well as startups the goal is to provide legal certainty and prevent

28:19.520 --> 28:24.000
market fragmentation which can actually foster innovation by creating a level

28:24.000 --> 28:27.680
playing field for AI developers however it imposes certain requirements and

28:27.680 --> 28:37.840
obligations on high-risk AI how does this legislation define high-risk AI

28:39.560 --> 28:45.120
let's see this legislation categorizes AI systems into three risk levels

28:45.120 --> 28:49.840
unacceptable high and low or minimal high-risk AI is based on their intended

28:49.840 --> 28:54.040
purpose and usage while the specific criteria may vary high-risk AI generally

28:54.040 --> 28:57.360
include those use the safety components of products covered by union

28:57.360 --> 29:01.080
harmonization legislation as well as AI used in critical infrastructure

29:01.080 --> 29:04.360
management education vocational training employment and workers

29:04.360 --> 29:10.160
management these high-risk AI systems are subject to requirements what are

29:10.160 --> 29:17.880
unacceptable types the legislation prohibits certain AI practices that are

29:17.880 --> 29:21.480
considered unacceptable due to their potential to violate fundamental rights

29:21.480 --> 29:26.800
while the specific types may vary some examples include manipulate human

29:26.800 --> 29:29.960
behavior exploit vulnerabilities or enable social scoring by public

29:29.960 --> 29:34.880
authorities right so as I mentioned social credit system these practices are

29:34.880 --> 29:40.200
deemed harmful freedom dignity democracy equality and fundamental rights okay

29:40.200 --> 29:50.680
cool does this legislation address existential risk at all does it address

29:50.880 --> 29:58.600
autonomous AI the legislation does not explicitly address existential risk or

29:58.600 --> 30:05.320
autonomous AI systems wow okay now one thing that I will say is that if you look

30:05.320 --> 30:11.640
at the legislation it does talk about like basically human supervision yeah

30:11.640 --> 30:20.000
so like AI regulatory sandbox by one or more member stages no like here where

30:20.000 --> 30:24.480
was it and talked about not supervision of the sandboxes but like AI systems

30:24.480 --> 30:31.640
basically need to be steerable it's in there somewhere okay but let's see it

30:31.640 --> 30:34.280
does not specifically address the potential risk associated with highly

30:34.280 --> 30:37.440
autonomous or super intelligent AI systems that could pose existential

30:37.440 --> 30:40.800
threats however the legislation's emphasis on risk management human

30:40.800 --> 30:43.880
oversight oh that's what it was oversight not supervision and robustness

30:43.880 --> 30:48.000
requirements for high-risk AI systems indirectly contributes to addressing the

30:48.000 --> 30:51.960
safety concerns associated with AI technologies it is important to note

30:51.960 --> 30:55.200
that addressing existential risk related to AI may require further research

30:55.200 --> 30:59.800
discussions and potentially additional regular to regulations in the future okay

30:59.800 --> 31:10.440
cool so there you have it this file is saved on as merged dot text let me go

31:10.440 --> 31:17.000
ahead and send that up to get so you can all use it let's see get status I get

31:17.240 --> 31:24.400
add get commit AM all done get push all right so there you have it you have a

31:24.400 --> 31:31.520
much condensed version of the EU act here and merged you can plug it

31:31.520 --> 31:37.080
into the playground and ask questions to your heart's content if you have access

31:37.080 --> 31:41.240
to it but otherwise you can at least just read it here yeah I think we're all

31:41.240 --> 31:44.000
done thanks for watching

