1
00:00:00,000 --> 00:00:05,120
I think we're ready to begin um you saw me look at the camera used to be over

2
00:00:05,120 --> 00:00:11,240
there now you're over here okay so I ran a poll 17 hours ago I asked if y'all

3
00:00:11,240 --> 00:00:17,600
wanted me to do a video on the EU AI Act man god names gotta get better with

4
00:00:17,600 --> 00:00:23,320
names I'm good with acronyms come to me for acronyms Gato Gaia ages okay anyways

5
00:00:23,320 --> 00:00:27,520
so y'all were confused about what I meant by Haas which is something from

6
00:00:27,520 --> 00:00:32,440
here in the south basically Haas means just something big right it's short it's

7
00:00:32,440 --> 00:00:40,120
a southern dialect for horse or in particular a big horse so this document

8
00:00:40,120 --> 00:00:46,760
is a Haas because look how freaking long it is it just keeps going so I plugged

9
00:00:46,760 --> 00:00:55,720
it in over here and it is 70,000 tokens long so even if I had access to GPT-432

10
00:00:55,720 --> 00:00:59,400
K which I did briefly and then they revoked it I think they got overwhelmed

11
00:00:59,400 --> 00:01:05,320
because I used it I tried to use GPT-432 K on a couple things and it was just

12
00:01:05,320 --> 00:01:09,880
like server is overloaded servers over anyways so hopefully I get that back but

13
00:01:09,880 --> 00:01:13,520
the idea what there would be I could read it and you know chop it up into maybe

14
00:01:13,520 --> 00:01:17,920
four sections three or four sections and read the whole thing but we don't have

15
00:01:17,920 --> 00:01:25,040
that and I do have GPT-3.5 turbo 16k 0613 so this model is actually super

16
00:01:25,320 --> 00:01:33,080
steerable it is actually better than original GPT-4 add a lot of things it's

17
00:01:33,080 --> 00:01:36,800
still kind of dumb especially if the instructions are too complex but as long

18
00:01:36,800 --> 00:01:46,600
as you give it just one task GPT-3.3.5 turbo 0613 the June 13th model is more

19
00:01:46,600 --> 00:01:50,720
than adequate for most things now that being said because I'm interpreting

20
00:01:51,040 --> 00:01:58,400
and I'm doing summarization I'm gonna use 04613 so the instructions that I gave

21
00:01:58,400 --> 00:02:03,600
it just now and I know that I'm ready to start the video primary purpose zoom in

22
00:02:03,600 --> 00:02:08,640
a little bit the primary purpose or the following is a chunk of legislation your

23
00:02:08,640 --> 00:02:14,720
job is to summarize this legislation with two primary goals one drastically

24
00:02:14,720 --> 00:02:17,920
reduce the word count and two retain enough context that it will still make

25
00:02:18,000 --> 00:02:21,600
sense the reason for this is the current AI technology can only read chunks that

26
00:02:21,600 --> 00:02:25,600
are so big method the user will give you a chunk of legislation via chat your

27
00:02:25,600 --> 00:02:28,960
response must only be the summarized version do not chat with the user engage

28
00:02:28,960 --> 00:02:33,480
with them or offer any other commentary summarize only so I copied the first

29
00:02:33,480 --> 00:02:41,320
hundred lines of the legislation in you here and this is what it spit out so it

30
00:02:41,320 --> 00:02:45,800
took all that and just said okay this is what it means so the first hundred

31
00:02:45,800 --> 00:02:54,760
lines which you can see here so we've got 344,000 characters 3665 lines of

32
00:02:54,760 --> 00:02:58,720
stuff to go through I'm not going to read the whole thing I'm not AI explained

33
00:02:59,720 --> 00:03:03,760
that dude just like you all are impressed with how much work I can do I'm

34
00:03:03,760 --> 00:03:07,760
impressed with how much that dude can read just honestly I'm maybe he uses

35
00:03:07,760 --> 00:03:15,280
chat GPT I don't know anyways if you're watching it's just a joke okay so

36
00:03:15,280 --> 00:03:23,480
anyways so ultimately basically that that first hundred lines was summarized

37
00:03:23,480 --> 00:03:27,240
and condensed down to the European Commission proposes a regulation for

38
00:03:27,240 --> 00:03:30,760
harmonized rules on artificial intelligence aiming to balance the

39
00:03:30,760 --> 00:03:35,600
socioeconomic benefits of AI with potential risks the proposal seeks to

40
00:03:35,600 --> 00:03:39,520
ensure AI systems are safe respect fundamental rights provide legal

41
00:03:39,520 --> 00:03:43,680
certainty for investment and innovation enhance governance and prevent market

42
00:03:43,680 --> 00:03:48,640
fragmentation so it has says nothing about existential risks or prevent AI

43
00:03:48,640 --> 00:03:52,360
from killing everyone it's sort of implicit because like if AI kills

44
00:03:52,360 --> 00:03:55,840
everyone you can't have investment in innovation but I would rather see

45
00:03:55,840 --> 00:04:00,560
legislation that is explicit it proposes a risk-based approach prohibiting

46
00:04:00,560 --> 00:04:04,800
certain harmful AI practices and setting requirements for high-risk AI systems

47
00:04:04,800 --> 00:04:09,960
okay cool we'll see how they define that later the proposal also establishes a

48
00:04:09,960 --> 00:04:13,520
governance system at member state level and a European artificial intelligence

49
00:04:13,520 --> 00:04:16,760
board at union level okay cool so this is this is going to be an

50
00:04:16,760 --> 00:04:21,080
international regulator great it is consistent with existing union

51
00:04:21,080 --> 00:04:24,680
legislation and policies including data protection consumer protection

52
00:04:24,680 --> 00:04:28,760
non-discrimination and gender equality so these are all very low-level risks

53
00:04:28,760 --> 00:04:33,080
none of this is actually talking like when they say high risk they're probably

54
00:04:33,080 --> 00:04:38,080
meaning like the social credit system that is used in China which that is a

55
00:04:38,080 --> 00:04:43,080
high risk but it is not the highest risk the proposal is based on article 114 of

56
00:04:43,120 --> 00:04:48,040
the Treaty of the Functioning of the European Union Union the TFEU which

57
00:04:48,040 --> 00:04:51,880
ensures the establishment and functioning of the internal market okay so this is

58
00:04:51,880 --> 00:04:56,000
mostly a market-oriented piece of legislation great so we know that this

59
00:04:56,000 --> 00:04:59,480
works so let's go ahead and save this out I'm gonna walk you through the whole

60
00:04:59,480 --> 00:05:04,680
process and then I'll yeah so this is this is how this is how we're gonna

61
00:05:04,680 --> 00:05:08,240
proceed for those of you that are newer to my channel this is actually the

62
00:05:08,240 --> 00:05:11,440
original format that I used where I would where I would walk you through the

63
00:05:11,440 --> 00:05:17,080
entire process so just watch that on 2x and you'll see the whole process of how

64
00:05:17,080 --> 00:05:24,600
I approach these things so we'll call this system summarize yes dot text and so

65
00:05:24,600 --> 00:05:28,360
basically I give it a system a system message up with very very clear

66
00:05:28,360 --> 00:05:33,240
instructions and and what I expect and and what it should expect and then it

67
00:05:33,240 --> 00:05:39,920
gives you very clear consistent results so then we come over to do to do to do

68
00:05:39,920 --> 00:05:45,320
to do step one simplify so this is I'm just re I'm borrowing code which I

69
00:05:45,320 --> 00:05:53,920
always do so we've got this so this is what we're gonna use to do that this is

70
00:05:53,920 --> 00:05:57,400
this is this is a KB service that I'm working on so I'll show you that in an

71
00:05:57,400 --> 00:06:06,240
upcoming video but you don't get to see that yet we don't need KB functions so

72
00:06:06,240 --> 00:06:11,120
delete that flask routes we're not gonna do a flask app so that's also fine

73
00:06:11,120 --> 00:06:15,680
actually I guess I just delete most of it okay cool so we get rid of flask

74
00:06:15,680 --> 00:06:19,040
cuz we're not gonna do that we're not gonna do threading we're not gonna we

75
00:06:19,040 --> 00:06:27,800
don't need flask or logging or JSON or YAML okay clean it up I probably should

76
00:06:27,800 --> 00:06:31,320
have done that before I started the video but it's good to it's good for you

77
00:06:31,320 --> 00:06:35,600
to see how messy my process is I am the first person to tell you I am not a

78
00:06:35,640 --> 00:06:40,120
professional developer I never was my professional background was I was in

79
00:06:40,120 --> 00:06:44,000
virtualization and automation so I'm an automation engineer which is why I

80
00:06:44,000 --> 00:06:48,960
approach things the way that I do which is creating discrete steps so you notice

81
00:06:48,960 --> 00:06:54,400
the thought the title of this is step one simplify okay cool so basically what

82
00:06:54,400 --> 00:07:01,760
we're gonna do is we're going to ask this handy dandy coding chatbot that I

83
00:07:01,800 --> 00:07:11,440
built which you can use this it is available over here I had a bunch of

84
00:07:11,440 --> 00:07:18,840
people submitting pull requests and they kept trying to like change the way that

85
00:07:18,840 --> 00:07:22,880
this thing works so I just said it to public archive so here's the thing is I

86
00:07:22,880 --> 00:07:29,320
welcome pull requests that are like simple fixes or small improvements don't

87
00:07:29,320 --> 00:07:33,440
refactor my code just fork it right like there's 19 forks if you want to if you

88
00:07:33,440 --> 00:07:37,600
want to fundamentally change how it works fine but I got tired of people

89
00:07:37,600 --> 00:07:41,480
messing up my code so I just said it to public archive and guess what like

90
00:07:41,480 --> 00:07:44,880
people you can still do whatever you want with it anyways so we're gonna use

91
00:07:44,880 --> 00:07:50,320
this as a co-pilot tool because I got frustrated with GitHub because they're

92
00:07:50,320 --> 00:07:57,440
co-pilot customer service whatever documentation is garbage okay let's see

93
00:07:57,440 --> 00:08:05,680
I have here let's just write a function that accepts a gigantic string and

94
00:08:05,680 --> 00:08:16,280
returns now let's see and let's see splits it by lines and then chunks 100

95
00:08:16,280 --> 00:08:32,000
lines together and returns those chunks as strings so the final result will be a

96
00:08:32,000 --> 00:08:43,880
list of strings each string represents 100 lines of the original okay so this

97
00:08:43,880 --> 00:08:50,960
is this is my coding chatbot assistant that it uses it also uses GPT for you I

98
00:08:50,960 --> 00:08:58,120
tried it you can actually switch it to oh it's using the old one hold on now I

99
00:08:58,120 --> 00:09:04,560
need to update that hold on hold on that's the wrong model coding chatbot

100
00:09:04,560 --> 00:09:07,880
assistant see this is what I mean is someone someone updated it oh no my

101
00:09:07,880 --> 00:09:12,040
local one uses the right one so someone updated it with the wrong model and made

102
00:09:12,040 --> 00:09:15,640
a bunch of other assumptions and I was just like no this is not this is not

103
00:09:15,640 --> 00:09:22,760
what I wanted okay so here we go here's the function Python chunk strings line

104
00:09:22,760 --> 00:09:31,320
lines equals split oh wow I did it in two lines cool this functions first splits

105
00:09:31,320 --> 00:09:40,520
the string into lines using the delimiter then it uses a list comprehension

106
00:09:40,520 --> 00:09:45,320
to create chunks of 100 lines each the range yep the result is a list of strings

107
00:09:45,320 --> 00:09:51,280
cool excellent excellent excellent so I'm gonna go ahead and copy this out oh and

108
00:09:51,280 --> 00:09:56,680
another good thing is that uh like well yeah you see how it works all right so

109
00:09:56,680 --> 00:10:05,600
we'll go ahead and do that so chunk strings so first we want to just act

110
00:10:05,680 --> 00:10:16,760
equals open file and I've got it named as act text just right here yep oh and

111
00:10:16,760 --> 00:10:23,320
also this excuse me this this uses a scratch pad so what I can do is I can

112
00:10:23,320 --> 00:10:30,840
actually populate the code that I'm working on over here so now it's aware

113
00:10:30,840 --> 00:10:35,520
of what I'm working on so this scratch pad is a holdout so rather than giving it

114
00:10:35,520 --> 00:10:43,600
the code in sequence the the coding chatbot actually has a it has here let me

115
00:10:43,600 --> 00:10:46,840
show you the system message so here's the instructions your Python coding

116
00:10:46,840 --> 00:10:51,000
assistant you know me turn on word wrap your Python coding assistant etc etc

117
00:10:51,000 --> 00:10:56,040
scratch pad so basically tells you the scratch pad is usable you know so that

118
00:10:56,040 --> 00:10:59,560
you know what the user is working on so that you can talk about this and this is

119
00:10:59,560 --> 00:11:05,360
passed to the chatbot every time so whatever the conversation is like that

120
00:11:05,360 --> 00:11:10,240
that is in the past I don't know if I'm explaining that well anyways point being

121
00:11:10,240 --> 00:11:14,000
is that it see it can see the code that you're working on as long as you keep

122
00:11:14,000 --> 00:11:23,560
this updated okay so that's the first hundred lines let's go ahead and see

123
00:11:23,560 --> 00:11:29,120
where did it go step one simplify cool so act equals that and then we'll say

124
00:11:29,160 --> 00:11:37,400
chunks equals see chunk string chunk string act all right so that this

125
00:11:37,400 --> 00:11:44,600
basically creates the chunks that we're gonna be working on and that is that

126
00:11:44,600 --> 00:11:50,680
let's see I'm gonna need to watch this because mmm well here let me just show

127
00:11:50,680 --> 00:11:57,560
you something real quick so the first hundred lines if we take that over to

128
00:11:57,840 --> 00:12:03,720
playground and paste it in here you see that a hundred lines is about 4,000

129
00:12:03,720 --> 00:12:09,920
tokens so that would obviously be too big for text of inchio 3 but with with

130
00:12:09,920 --> 00:12:17,320
GPT-4 we have 8,000 tokens and then with 3.5 16k we have 16,000 tokens so we

131
00:12:17,320 --> 00:12:23,360
could actually probably do more but the thing is is that again 3.5 turbo is

132
00:12:23,360 --> 00:12:28,440
actually you know it let's try it real quick heck with it heck with it while

133
00:12:28,440 --> 00:12:36,080
we're here let's go back over to chat let's give it this chunk because if it

134
00:12:36,080 --> 00:12:42,360
can if I can do it faster and cheaper why not why not and then we need this is

135
00:12:42,360 --> 00:12:49,600
our system message we need to make sure that we're gonna use 3.5 turbo 16k so

136
00:12:49,600 --> 00:12:53,920
that it's got enough space okay turn the temperature down we do not want you to

137
00:12:53,920 --> 00:12:59,000
be creative thank you very much all right and then let's see how well it

138
00:12:59,000 --> 00:13:06,160
summarizes it yeah so it's not this summarization is not nearly as elegant

139
00:13:06,160 --> 00:13:15,520
or as concise but just glancing at it it's okay I think I'm gonna stick with

140
00:13:15,800 --> 00:13:21,280
four but I'm glad I did this side-by-side so the the the GPT-4 it's a much more

141
00:13:21,280 --> 00:13:25,880
elegant summary and it's also less worthy even though so it's not quite as

142
00:13:25,880 --> 00:13:30,080
fast and it's not quite as cheap because we need to capture the essence of

143
00:13:30,080 --> 00:13:34,640
something that's really important let's use the smarter model now that being

144
00:13:34,640 --> 00:13:41,400
said again 3.5 turbo the the June 13th one plenty plenty good for a lot of

145
00:13:41,400 --> 00:13:48,320
things okay cool so I'm glad I ran that test where are we what am I doing I don't

146
00:13:48,320 --> 00:13:54,480
know I'm lost I'm always lost there's this meme it's like a pug in a field

147
00:13:54,480 --> 00:13:59,720
with a wizard hat and it says that the meme is like not all who wander are

148
00:13:59,720 --> 00:14:05,160
lost except Dave Dave is lost as fuck and that's me I'm the pug with a wizard

149
00:14:05,160 --> 00:14:10,000
hat does that make any sense I need more coffee

150
00:14:11,440 --> 00:14:14,640
okay all right I hope you find this entertaining because I just woke up and

151
00:14:14,640 --> 00:14:19,540
I was like my brain's like hey we should work on this all right now we're back

152
00:14:19,540 --> 00:14:23,400
here all right we've got our chunks so now what we need to do so this is this

153
00:14:23,400 --> 00:14:30,760
is where it gets fun so four chunk in chunks this is super straightforward

154
00:14:30,800 --> 00:14:43,920
let's see messages equals this is gonna be a list and then the role will be

155
00:14:43,920 --> 00:14:54,200
user and the content wow I know how to type I promise it's just getting it from

156
00:14:54,200 --> 00:14:58,640
my head to the to the hands on the keyboard to the screen that's too many

157
00:14:58,680 --> 00:15:05,120
steps right now content equals chunk okay cool so basically what we're doing

158
00:15:05,120 --> 00:15:10,640
right here is we're setting it up to look exactly like this so I'm putting

159
00:15:10,640 --> 00:15:14,480
the chunk in here and then we also need to load the system message so what we're

160
00:15:14,480 --> 00:15:20,840
gonna do is we're gonna do system equals open file system underscore

161
00:15:20,840 --> 00:15:27,320
summarize so this is this is the instructions dot text so system message

162
00:15:27,360 --> 00:15:38,360
is the new prompt engineering all right cool so then we'll do role system and

163
00:15:38,360 --> 00:15:46,600
content is system all right so now we're ready to pass it up to our model right

164
00:15:46,600 --> 00:15:53,880
here so then we'll just do response equals chatbot messages ta-da is that

165
00:15:53,880 --> 00:16:00,360
simple so it's ready and so this response is going to be the summary and so

166
00:16:00,360 --> 00:16:04,360
now I need to figure out how I want to save this save these summaries out in a

167
00:16:04,360 --> 00:16:17,640
way that makes sense let's see let me ask my chatbot assistant okay cool great

168
00:16:17,640 --> 00:16:26,800
now I want to pass a list of strings to a function and have that function save

169
00:16:26,800 --> 00:16:36,440
them to a specified folder as a parameter and I want it to serialize

170
00:16:36,800 --> 00:16:51,080
those files like so so it'll be like file 001 dot text file 0002 dot text and so

171
00:16:51,080 --> 00:17:02,760
on let's see you should see the script I'm working on all right cool so then

172
00:17:02,800 --> 00:17:09,840
we're gonna we're gonna have summaries equals list and then summaries dot

173
00:17:09,840 --> 00:17:15,720
append response so now basically we're gonna have the summaries all in order

174
00:17:15,720 --> 00:17:20,120
and what I'm gonna do is I'm gonna copy and paste this into my scratch pad so

175
00:17:20,120 --> 00:17:24,040
that the chatbot knows what I'm working on and I'll show you how that it says oh

176
00:17:24,040 --> 00:17:28,800
okay cool I probably should have told it that I'm gonna do that with the summaries

177
00:17:28,960 --> 00:17:33,760
it's usually pretty good at making the inference okay cool let's see def save

178
00:17:33,760 --> 00:17:40,240
strings if os path exists or if it doesn't exist make it otherwise enumerate

179
00:17:40,240 --> 00:17:44,720
strings so as long as I've been using Python I'm not entirely sure how

180
00:17:44,720 --> 00:17:52,520
enumerate works maybe I should ask all right but let's go over here let's go

181
00:17:52,520 --> 00:18:07,520
back to my script save strings cool file I05 interesting yes see I'm not even

182
00:18:07,520 --> 00:18:14,120
sure how that works fantastic let's see if it let's see if it works though the

183
00:18:14,120 --> 00:18:18,400
function first checks that the specified folder exists excellent then it uses it

184
00:18:18,400 --> 00:18:22,480
to make it then then iterates over the list of strings using enumerate which

185
00:18:22,480 --> 00:18:26,920
provides both the index and the value okay so that's what enumerate does the

186
00:18:26,920 --> 00:18:32,480
index is used to generate the file name with I colon O5 in the f string

187
00:18:32,480 --> 00:18:39,520
ensuring that the index is zero padded to five digits well that was easy cool

188
00:18:39,520 --> 00:18:48,480
right and then it uses the right method yeah so instead I want I was hoping it

189
00:18:48,480 --> 00:18:56,360
would use my save file but that's fine so let's go to here and we're gonna do

190
00:18:56,360 --> 00:19:05,280
summaries and so instead we're going to assume that that is already there and

191
00:19:05,280 --> 00:19:24,640
then we are going to do file path equals I was path join folder yeah that works

192
00:19:24,640 --> 00:19:41,320
and then we are going to do save file because this so my save file function

193
00:19:41,320 --> 00:19:46,800
encodes it in UTF-8 so just reuse something rather than do it here because

194
00:19:46,800 --> 00:19:50,240
you see this doesn't do it in UTF-8 you want to make sure that you have a nice

195
00:19:50,280 --> 00:19:56,000
standardized thing that's what I'm doing here file path and s so that should be

196
00:19:56,000 --> 00:20:04,760
good fine all right so save strings so then we do save strings we'll do

197
00:20:04,760 --> 00:20:15,360
summaries no I need to do yes summaries and then summaries that should work now

198
00:20:15,360 --> 00:20:23,640
that being said I want to print the response as I get them there we go and

199
00:20:23,640 --> 00:20:34,920
then response all right let's give this a whirl and see if it works CD what is this

200
00:20:34,920 --> 00:20:47,000
EU AI act zoom in a little bit Python step 01 this will probably take a while

201
00:20:47,000 --> 00:20:57,200
because we've got 3,000 line 3300 lines there we go cool hmm hold on oh right

202
00:20:57,200 --> 00:21:03,480
right right I forgot about this okay so this is an important thing what I started

203
00:21:03,480 --> 00:21:08,720
doing and I forgot to integrate this so what I started doing is I when I whenever

204
00:21:08,720 --> 00:21:13,240
I call the chatbot I return the text and the token use so because this is

205
00:21:13,240 --> 00:21:16,760
actually really helpful if you just go ahead and return the tokens so that you

206
00:21:16,760 --> 00:21:22,400
know when to summarize it so instead what I need to do is response tokens

207
00:21:22,400 --> 00:21:28,880
because I don't need to save I don't need to save a tuple out here but this

208
00:21:28,880 --> 00:21:37,040
otherwise looks good and then what I'm gonna do is I'm gonna go grab something

209
00:21:37,040 --> 00:21:40,160
to make the the printout look a little bit better

210
00:21:40,160 --> 00:21:46,360
to do to do to do to do reflective journaling tool this one has this one

211
00:21:46,360 --> 00:22:00,200
has good pretty output so we're gonna do formatted lines yep so take the formatted

212
00:22:00,200 --> 00:22:15,620
lines here and then we'll do print new line new line new line and formatted

213
00:22:15,620 --> 00:22:23,080
lines all right so that will that'll make it that'll make it prettier and then

214
00:22:23,080 --> 00:22:30,840
we'll also use so this this is this is why I appreciate when people add feedback

215
00:22:30,840 --> 00:22:36,080
is we added someone added the halo which is a little like thing that shows that

216
00:22:36,080 --> 00:22:44,080
it's thinking so I'm gonna add that real quick as well and the way that you use

217
00:22:44,080 --> 00:22:47,920
that is down here

218
00:22:54,040 --> 00:22:57,480
and so once once this is running I'll pause the video so you don't have to

219
00:22:57,480 --> 00:23:00,960
watch the whole thing so you're actually probably closer to the end if I had to

220
00:23:00,960 --> 00:23:03,280
guess

221
00:23:05,760 --> 00:23:21,200
oops spinner start so we'll say summarizing next chunk and then spinner stop

222
00:23:24,080 --> 00:23:29,320
okay so let's try this make sure it works

223
00:23:32,200 --> 00:23:36,560
summarizing next chunk hey look now it gives us some output better user

224
00:23:36,560 --> 00:23:44,160
experience it tells me what it's doing text wrap is not defined whoops what do

225
00:23:44,160 --> 00:23:49,360
you mean I need to import everything that you use import text wrap try that

226
00:23:49,360 --> 00:23:54,120
again third time's a charm all right and if this works then I'll go ahead and

227
00:23:54,120 --> 00:23:57,480
pause it and then we'll come back once the whole video is or once the whole

228
00:23:57,480 --> 00:24:05,640
thing is done why is it in hold on hold on that's not right why are you giving

229
00:24:05,640 --> 00:24:14,880
me this garbage that's not correct oh right I need to print out formatted

230
00:24:14,880 --> 00:24:18,320
text my bad

231
00:24:20,880 --> 00:24:27,000
don't give me this nonsense because basically what you want to do is you

232
00:24:27,000 --> 00:24:30,400
want to have it formatted in such a way there we go see so now we have this nice

233
00:24:30,400 --> 00:24:34,560
little block it's easier to read all right cool so this is working we'll watch

234
00:24:34,560 --> 00:24:39,240
it just a couple times you see how fast it is the the June 13th update is much

235
00:24:39,280 --> 00:24:47,720
much faster let's see excellent excellent excellent so we will I'm gonna pause the

236
00:24:47,720 --> 00:24:56,320
video and we'll come back and and take a look at the final result cheers okay and

237
00:24:56,320 --> 00:25:01,520
we're back so after running it all here let me just show you what the results

238
00:25:01,520 --> 00:25:09,840
were we've got 37 files each with a summary and I wrote a really quick I

239
00:25:09,840 --> 00:25:14,320
hacked together a really quick script that merged them all and so the merged

240
00:25:14,320 --> 00:25:21,560
result is 34,000 characters long so we reduced it by a factor of 10 to 1 just

241
00:25:21,560 --> 00:25:27,640
just shy of 10 to 1 which when you plug that in over here that's 6,000 tokens so

242
00:25:27,680 --> 00:25:32,440
we went from from 60,000 or 70,000 tokens I don't remember exactly to 6,000

243
00:25:32,440 --> 00:25:36,400
tokens one of the reasons that we had a more drastic reduction reduction of

244
00:25:36,400 --> 00:25:40,920
token count is because we removed all the serial numbers and stuff because

245
00:25:40,920 --> 00:25:45,400
that's kind of superfluous if you if you remove symbols and stuff like this

246
00:25:45,400 --> 00:25:50,240
these are high token things if it's ordinary words like AI and each system

247
00:25:50,240 --> 00:25:56,560
these are easy for the model to tokenize so that means what we can do now is we

248
00:25:56,560 --> 00:26:05,200
can just take this whole thing and come over to chat and say let's see main

249
00:26:05,200 --> 00:26:18,400
purpose here turn it believe that you are a chatbot tasked with discussing the

250
00:26:18,400 --> 00:26:27,240
following legislation with the user make sure to well hell but I mean that

251
00:26:27,240 --> 00:26:37,320
that's all it is use the legislation summary below to conduct the conversation

252
00:26:37,320 --> 00:26:44,920
and that's it and so then we say a legislation summary and we'll copy paste

253
00:26:44,960 --> 00:26:50,440
it here and so then we move over to we could do 16k because that'll be that'll

254
00:26:50,440 --> 00:26:54,720
be faster actually here let's try that real quick let's try that temperature

255
00:26:54,720 --> 00:27:08,040
there okay give me a high level overview of this legislation blah blah blah

256
00:27:08,160 --> 00:27:17,480
okay cool we're new after five years how is it funded let's see the funding and

257
00:27:17,480 --> 00:27:20,640
implementation of this legislation comes from the multi-annual financial

258
00:27:20,640 --> 00:27:25,040
framework blah blah blah the financial impact includes allocation of resources

259
00:27:25,040 --> 00:27:36,800
and having watched it go through how many employees will it cost there we go

260
00:27:36,800 --> 00:27:44,840
ten full-time equivalent employees all right so we can clear that out just

261
00:27:44,840 --> 00:27:50,360
because it ultimately is superfluous so some of the questions let's see will

262
00:27:50,360 --> 00:28:00,280
this legislation hamper research and innovation let's see the legislation

263
00:28:00,280 --> 00:28:02,920
aims to balance the benefits of AI research and innovation with the need

264
00:28:02,920 --> 00:28:06,200
for safety and respect for fundamental rights it includes measures to support

265
00:28:06,240 --> 00:28:10,640
innovation such as AI regulatory sandboxes and reducing the regulatory burden

266
00:28:10,640 --> 00:28:14,920
on SMEs and startups so the SMEs are going to be subject matter experts like

267
00:28:14,920 --> 00:28:19,520
UNI as well as startups the goal is to provide legal certainty and prevent

268
00:28:19,520 --> 00:28:24,000
market fragmentation which can actually foster innovation by creating a level

269
00:28:24,000 --> 00:28:27,680
playing field for AI developers however it imposes certain requirements and

270
00:28:27,680 --> 00:28:37,840
obligations on high-risk AI how does this legislation define high-risk AI

271
00:28:39,560 --> 00:28:45,120
let's see this legislation categorizes AI systems into three risk levels

272
00:28:45,120 --> 00:28:49,840
unacceptable high and low or minimal high-risk AI is based on their intended

273
00:28:49,840 --> 00:28:54,040
purpose and usage while the specific criteria may vary high-risk AI generally

274
00:28:54,040 --> 00:28:57,360
include those use the safety components of products covered by union

275
00:28:57,360 --> 00:29:01,080
harmonization legislation as well as AI used in critical infrastructure

276
00:29:01,080 --> 00:29:04,360
management education vocational training employment and workers

277
00:29:04,360 --> 00:29:10,160
management these high-risk AI systems are subject to requirements what are

278
00:29:10,160 --> 00:29:17,880
unacceptable types the legislation prohibits certain AI practices that are

279
00:29:17,880 --> 00:29:21,480
considered unacceptable due to their potential to violate fundamental rights

280
00:29:21,480 --> 00:29:26,800
while the specific types may vary some examples include manipulate human

281
00:29:26,800 --> 00:29:29,960
behavior exploit vulnerabilities or enable social scoring by public

282
00:29:29,960 --> 00:29:34,880
authorities right so as I mentioned social credit system these practices are

283
00:29:34,880 --> 00:29:40,200
deemed harmful freedom dignity democracy equality and fundamental rights okay

284
00:29:40,200 --> 00:29:50,680
cool does this legislation address existential risk at all does it address

285
00:29:50,880 --> 00:29:58,600
autonomous AI the legislation does not explicitly address existential risk or

286
00:29:58,600 --> 00:30:05,320
autonomous AI systems wow okay now one thing that I will say is that if you look

287
00:30:05,320 --> 00:30:11,640
at the legislation it does talk about like basically human supervision yeah

288
00:30:11,640 --> 00:30:20,000
so like AI regulatory sandbox by one or more member stages no like here where

289
00:30:20,000 --> 00:30:24,480
was it and talked about not supervision of the sandboxes but like AI systems

290
00:30:24,480 --> 00:30:31,640
basically need to be steerable it's in there somewhere okay but let's see it

291
00:30:31,640 --> 00:30:34,280
does not specifically address the potential risk associated with highly

292
00:30:34,280 --> 00:30:37,440
autonomous or super intelligent AI systems that could pose existential

293
00:30:37,440 --> 00:30:40,800
threats however the legislation's emphasis on risk management human

294
00:30:40,800 --> 00:30:43,880
oversight oh that's what it was oversight not supervision and robustness

295
00:30:43,880 --> 00:30:48,000
requirements for high-risk AI systems indirectly contributes to addressing the

296
00:30:48,000 --> 00:30:51,960
safety concerns associated with AI technologies it is important to note

297
00:30:51,960 --> 00:30:55,200
that addressing existential risk related to AI may require further research

298
00:30:55,200 --> 00:30:59,800
discussions and potentially additional regular to regulations in the future okay

299
00:30:59,800 --> 00:31:10,440
cool so there you have it this file is saved on as merged dot text let me go

300
00:31:10,440 --> 00:31:17,000
ahead and send that up to get so you can all use it let's see get status I get

301
00:31:17,240 --> 00:31:24,400
add get commit AM all done get push all right so there you have it you have a

302
00:31:24,400 --> 00:31:31,520
much condensed version of the EU act here and merged you can plug it

303
00:31:31,520 --> 00:31:37,080
into the playground and ask questions to your heart's content if you have access

304
00:31:37,080 --> 00:31:41,240
to it but otherwise you can at least just read it here yeah I think we're all

305
00:31:41,240 --> 00:31:44,000
done thanks for watching

