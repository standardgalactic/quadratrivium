start	end	text
0	5720	Hello everybody, David Shapiro here with a update.
5720	9120	So we're going to cover two things today real quick.
9120	15720	The big thing is, I mentioned in a previous video, we need GAIA, Global AI Agency.
15720	17160	And we're working towards that.
17160	24080	And so I created a public repository of news and summaries, basically where I'm collecting
24080	29360	evidence and news that is very encouraging because it's all moving in the right direction.
29360	35520	We've got everything from the Future of Life Institute open letter to pause giant models,
35520	40880	news out of the UK, the EU, which yes, I know the UK left the EU.
40880	47000	I made a mistake of forgetting about Brexit in a previous video.
47000	53000	The UN Secretary General talking about yes, he's amenable to the idea of an international
53000	60960	AI watchdog, the United States Senate, their hearing on AI, the EU AI Act, the US House
60960	68600	of Representatives and Senate having now basically matched actions with words.
68600	75440	So after the hearing, both the US House of Representatives and the Senate have introduced
75440	80040	legislation or commissions or policies.
80040	83480	So we'll go over all those in much greater detail in just a moment.
83480	87240	But before we dive into that, I've been working on this thing.
87240	92680	I had this idea for a long time, and it's basically we can use large language models
92680	98840	like GPT because they are trained on so much text data, they're trained on data from around
98840	99840	the globe.
99840	106480	Granted, it is primarily English, so there is definitely some bias, cultural bias in there.
106480	112440	However, that being said, it has read so much about the world that it knows more about religion,
112440	117760	politics, psychology, culture, history than any one person.
117760	124440	So as far as having the ability to take perspectives, it's actually pretty good.
124440	128360	And so rather than walk you through the code, I'll just show you what I've got working so
128360	129360	far.
129360	134360	So basically what I have it do is actually first I need to make sure, well, no, that's
134360	135640	fine.
135640	146000	So basically what I have it do, what it does, anyways, is I have it synthesize a persona.
146000	155880	And so this persona is a whole bunch of random stuff like variables that it can pick to basically
155880	158240	create a synthetic person.
158240	166480	And I don't mean that in the manipulation way, but it has geographic origins, ethnicities,
166480	173800	cultures, languages, political dispositions, different factors about the person, such as
173800	179440	their physical health, their mental health, other habits, preferences, that sort of thing.
179440	185920	And so basically what it does is to create a persona is it'll grab one of these variables
185920	193120	or one option from each set of variables and then create a profile or a dossier in
193120	197440	order to take the perspective of that person.
197440	200520	And then it will talk through on a particular issue.
200520	206600	And I picked UBI because I've been on a economics and UBI kick lately.
206600	215160	And so I wanted to basically come up with a way of automatically understanding what the
215160	222120	concerns that everyone is going to have could be, but not just elucidate or articulate the
222120	229120	problems that they will have or the concerns that they'll have over a policy like UBI,
229120	232960	but how do we actually arrive at consensus?
232960	238880	And consensus is not necessarily, so a lot of people have misconception about consensus.
238880	241480	Consensus doesn't mean unanimous agreement.
241480	246160	Consensus means that it gets to a point that is good enough that people will kind of stop
246160	247160	fighting it.
247160	248720	It's about compromise.
248720	255200	And so anytime that there's been any kind of contentious policy or legislation, even
255200	259400	including the United States Constitution, nobody was happy with it because they had to
259400	264920	come to consensus in order to get something that everyone would tolerate, everyone would
264920	265920	accept.
265920	270280	So it wasn't perfect to anyone's mind, but it was something that they would all accept.
270280	275800	And so the idea is, okay, let's take this random profile of a person so that we can
275800	282040	get a global representation of all perspectives, regardless of how small they are, because
282040	287040	the thing is, when you look at some of these things like atheist, Islam, Christianity,
287040	294200	Buddhist, some of these are overrepresented in some areas and some of them are underrepresented.
294200	295800	Same thing for political leanings.
295800	301760	I even include libertarians and anarchists and statists and communists and reactionaries
301760	303800	and populists and nationalists and fascists.
303800	307440	I don't know if fascism isn't in here.
307440	308920	Fascism isn't in here.
308920	311960	So fascist perspectives don't get represented, but nationalists do.
311960	314800	So close enough, authoritarians get represented.
314800	320560	So the idea is that we can get a very well-rounded representation of all human perspectives more
320560	321560	or less.
321560	327040	There are going to be some flaws with this because it is the first edition, first example.
327040	334080	But the idea is that you can get a very, very diverse set of perspectives on a particular
334080	335080	issue.
335080	339720	And then once you get those perspectives, you can then work through and figure out, okay,
339720	345080	what kind of policy is this person most likely to accept?
345080	350240	And so by then generating a whole bunch of potential policies, you can say, okay, well,
350320	354600	let's look at the commonality between all of these and let's get really creative.
354600	356720	So let me just go ahead and show you how this works.
356720	357720	All right.
357720	362280	So the first thing it does is it grabs a random persona, so you see where it's like heavy
362280	367680	social media user, they're West Asian, cultural background is West Asian, their geographic
367680	369920	origin is from North Africa.
369920	375400	So imagine a West Asian family in North Africa, they're a wealthy family, they're heavy social
375400	377280	media user, so on and so forth.
377280	382520	Okay, so I ask, what would this person think about UBI?
382520	387920	And because ChatGPT is so heavily trained to be a helpful assistant, I couldn't get
387920	393320	ChatGPT to take that perspective, but what I could do is say advocate zealously on behalf
393320	396640	of this person, and that got really good results.
396640	400800	So let's see, as an advocate for this persona, I would say that they might have mixed feelings
400800	402160	about UBI.
402160	409560	On one hand, they are wealthy and underemployed, which might lead them to see UBI as, let's
409560	410560	see, where did it go?
410560	411560	Hang on.
411560	412560	Okay, it's saved.
412560	413560	Sorry.
413560	417160	Let's see, unnecessary for themselves and potentially harmful to their financial status
417160	419120	if it results in higher taxes.
419120	423080	They also might be concerned about the potential for UBI to discourage work and productivity
423080	426560	given their own success in wealth oriented aspirations.
426560	429760	On the other hand, their experience with financial stress and their social concerns might make
429760	435400	them sympathetic to the idea of UBI as a means of reducing poverty and inequality.
435400	440160	However, their nationalist political affiliation might make them more inclined to support policies
440160	444200	that prioritize the needs and interests of their own country and its citizens, which
444200	448160	could include skepticism towards UBI if they perceive it as benefiting outsiders as a form
448160	449800	of globalist policy.
449800	455120	So you see it has a very nuanced way of saying, okay, this person has lots of different beliefs
455120	458760	and it's pretty complex.
458760	459760	Let's see.
459760	463480	Okay, so given their wealth oriented aspirations, nationalist political affiliation and their
463480	468200	experience with financial stress, they might resonate with a fiscal policy or UBI implementation
468200	472640	that is designed to stimulate economic growth and productivity while also addressing social
472640	474720	inequality within their own country.
474720	478380	For instance, they might support a UBI program that is funded through progressive taxation
478380	481320	where the wealthy pay a higher percentage of their income taxes.
481320	484200	This would align with their social concerns and their belief in the importance of addressing
484200	485200	inequality.
485200	488420	However, they would likely want assurances that this would not unduly burden them or
488420	490820	negatively impact their own financial status.
490820	495420	They might also resonate with a UBI program that includes work incentives or requirements
495420	498640	to address their concerns about discouraging work and productivity.
498640	502540	For instance, they might support a UBI that is conditional on recipients engaging in
502540	506300	some kind of work, education or community service.
506300	511260	So this is a theme that keeps emerging because I've run this experiment a few times.
511260	515820	I don't know if that's the underlying training of chat GPT or if it's just this is the most
515820	522180	logical way forward where basically either you have a requirement or an incentive or
522180	523180	reward.
523180	528940	So basically like you get, everyone gets a baseline UBI, but if you volunteer, you get
528940	530540	more UBI, right?
530540	534220	It's like kind of adjusting your tax returns here in America.
534220	535220	Okay.
535220	540220	So finally, given their nationalist policy, they want to UBI that prioritizes the needs
540220	543140	and interests of their own country's citizens.
543140	549840	So this could be something like a tax break if you buy local or any number of ways.
549840	557820	So then I ask it to say, all right, come up with a policy that this person might like.
557820	563260	And so in this case, it said the national prosperity dividend, which that sounds rather
563260	565820	authoritarian, but okay, we'll go with it.
565820	573180	So the NPD, which that's also the acronym for narcissistic personality disorder.
573180	575380	Oh boy.
575380	578700	Maybe let's workshop that before we go live with it.
578700	583620	Anyways, so the NPD is a form of universal basic income that is designed to stimulate
583620	587380	economic growth, reduce social inequality and prioritize the needs and interest.
587380	588380	Okay.
588380	589380	So you get that.
589380	594180	So it's predicated on their engaging in some form of work, education or community service,
594180	597940	more time work, vocational training, higher ed, so on and so forth.
597940	602860	You know, actually like that particular thing, because this is a recurring theme, I'm not
602860	606940	certain that that's actually a bad idea where like you incentivize people to continue to
606940	613980	better themselves, even if it's a small carrot, like, you know, hey, if you're in, if you're
613980	618380	going to higher education, even if, you know, you're at the college degree you're getting
618380	622980	might not ever do anything, you get an extra $500 a month, you will at least be a better
622980	626900	informed citizen and a better civic participant.
626900	627900	Who knows?
627900	628900	I don't know.
628900	630380	Incentivize the behavior you want to see.
630380	631380	Oh, here we go.
631380	634500	The NPD would also include a patriotic bonus.
634500	635500	Yikes.
635500	640700	An additional payment for those who contribute significantly to the country's economy, culture
640700	641940	or society.
641940	642940	Okay.
642940	645740	I wouldn't call it a patriotic bonus.
645740	649860	That's a little, that's a little totalitarian, but I get the, I get the idea.
649860	653300	So this would include entrepreneurs, artists, scientists and community leaders.
653300	658780	So actually I think Ireland already has something like this where basically if you are a professional
658780	663620	artist or author or whatever a creative type, you get a stipend.
663620	667500	I don't know what they call it in Ireland, but there is precedent for this being a thing.
667500	672940	So like if you're, if you're a content creator or a cultural commentator or whatever, you
672940	676940	could get a little bit, an additional stipend.
676940	677940	So all right.
678220	680060	There you have it.
680060	682780	And then if we run it again, so let me do a clear screen.
682780	688500	If we run it again, let's say we get a young adult who's wealthy from Eastern Europe, whose
688500	692340	culture is indigenous South American, interesting.
692340	693900	They like gaming.
693900	694900	They speak Spanish.
694900	698420	That makes sense if they're from South America.
698420	703580	They do not care about the community and they are a very fragile person.
703620	711660	They're an angry, fragile person who's, who is educated, they've been very experienced.
711660	715660	They had a good childhood, sorry, they've had a good, good life experience.
715660	716740	They're presently single.
716740	718740	They're a progressive atheist.
718740	719740	Yeah.
719740	723820	This actually sounds, oh, and they're worried about their career.
723820	724820	Interesting.
724820	725820	Okay.
725820	727580	So let's see.
727580	729740	I'm not going to read the whole thing to you.
729740	733060	Like I did the first one, you get the idea.
733260	737460	So you see how it takes into account, like the last one, they were nationalist and blah,
737460	738460	blah, blah.
738460	739460	And this one is progressive.
739460	743260	Given their moderate intolerance, they might prefer UBI that includes some form of means
743260	744260	testing.
744260	747260	Means testing keeps coming up, keeps coming up as well.
747260	748260	Let's see.
748260	750780	Skeptical about whether everyone deserves UBI.
750780	751780	Ouch.
751780	756140	I, there's some people on Reddit that this sounds like.
756140	757420	And that's not to trash people on Reddit.
757420	761100	I actually learned a lot from some people on Reddit.
761100	762100	But yeah.
762100	765940	So UBI to reduce overconsumption and promote more sustainable lifestyles.
765940	766940	Yeah.
766940	773420	So this actually keeps coming up as well where for some people means testing sustainability.
773420	780460	So basically like you might get an additional UBI bonus if you live sustainably or whatever.
780460	784460	So basically like discourage overconsumption, that's a, that's a trend that keeps coming
784460	785460	up.
785460	786460	So okay.
786460	793700	What environmental U, U, UBI, the puibi, the PB would be funded primary through a progressive
793700	798340	tax system where the wealthiest individuals and okay, yeah, blah, blah, blah.
798340	801820	I haven't seen too much in terms of funding.
801820	807020	One of them did say fund it through carbon taxes, which I thought was, was an interesting
807020	811580	way as you partially fund it through, through that to align with their environmentalist values
811580	813460	would also, oh, here it is.
813460	814460	Carbon tax.
814460	815460	Okay.
815580	817460	So these are some ideas that keep coming up.
817460	822100	Again, I think that the underlying model has a little bit of bias here.
822100	828420	It would be interesting to see if there is a future version of GPT that is not already
828420	832580	pre-trained to be kind of on board with some of these ideas.
832580	837180	Because one thing that doesn't, that has come up is like, if you have someone who is just
837180	842220	adamantly opposed to it, it doesn't say like, this person will never agree to this under
842220	843340	any circumstances.
843340	847420	It works really hard to try and find something that they might agree with.
847420	855380	So anyways, this is all saved out to, it's saved out into the UBI folder as a YAML document.
855380	860220	So it just, it basically just saves the conversation as, as a whole.
860220	865780	I think, yeah, it even includes the system message because the system message includes
865780	869260	the, includes the, the persona.
869260	870500	And the first one, it was hilarious.
870500	876740	It was a radically intolerant feminist who is a Scientologist, which is just like, wow,
876740	880500	this was, this was really interesting as it tried to figure out how to appease a very
880500	882820	dogmatic person.
882820	886620	So anyways, this is a work in progress.
886620	892460	I, I don't know where it's going exactly, but the idea is that maybe you could use it
892460	898500	for policy research, maybe you could use it for, it actually came, it was, I've been thinking
898500	904500	about it for a long time, but I had some inspiration after talking to the Gato community about the
904500	910820	Democratic inputs to AI because the idea of using a chatbot to extract information from
910820	913700	a person, from a real person is one thing.
913700	916980	But then I was like, you know, the model already has a tremendous amount of information.
916980	921860	So why don't we just bootstrap it and ask the model to kind of think through this.
921860	926820	So this is essentially a tree of thought, but each branch of the tree is a different
926820	927940	persona.
927940	932780	And then each of those branches has three sub branches where I ask at those three questions
932780	936820	like, you know, what do you think this person will think about UBI?
936820	939220	What kind of fiscal policy do you think would resonate?
939220	942620	And then finally, given the persona and their disposition, can you creatively conjure up
942620	946640	a policy that has a high chance of reaching consensus with this person?
946640	949980	So it's, you know, basically you can create an arbitrary number of branches.
949980	954220	And then as you, as those branches span out and you get all the leaves, you gather the
954220	956180	leaves together and see what fits.
956180	957180	Okay.
957180	960020	Anyways, so you're up to date on that project.
960020	965140	So let's dive back into the GAIA initiative, the global AI agencies.
965140	971140	So I've been watching the news and I realized that the number of things that are piling
971140	973100	up that make me feel good.
973100	977780	And I know that there's a lot of people out there that are skeptical of, of anything to
977780	980980	do with government or corporations.
980980	983940	And for those people, I empathize with you.
983940	992420	Growing up, I was more like that where I was super skeptical of all trappings of power.
992420	998820	And certainly my friends were very like disestablishment, Tarianism and anarcho libertarian, whatever.
998820	1001660	But none of them ever did anything with it.
1001660	1003020	So this is the world we live in.
1003020	1006540	We live in a world with corporations and governments and stuff.
1006540	1010380	And yes, all power needs to be scrutinized.
1010380	1013500	Seescepticism is absolutely fine.
1013500	1015660	That is part of the democratic process.
1015660	1020280	That being said, if you're dogmatically against all forms of power, well, I mean, wish in
1020280	1023180	one hand and you know, you know what to do with the other one.
1023180	1024500	See which one fills up first.
1024500	1030500	So anyways, I have been keeping track of all this stuff because I see the currents and
1030500	1034160	the trends and it is actually very, very encouraging to me.
1034160	1037020	So I've got it all in chronological order.
1037020	1043020	So first was the Future of Life Institute published their open letter, you know, signed
1043020	1046980	by everyone, including Elon Musk and yada, yada, yada.
1046980	1050820	What I didn't realize was that it actually came with a policy paper.
1050820	1058020	And so this policy paper, it's only 14 pages and it has seven policy recommendations.
1058020	1063900	So this came out in, let's see, April 12th.
1063900	1070420	I think I might have that wrong, the pause, the big pause.
1070420	1072780	So the paper was published March 22nd.
1072780	1078100	The policy recommendations came out a few days later, a couple weeks later.
1078100	1083700	So what I did was I took all that and then I made a very brief summary of the whole thing
1083700	1084700	right here.
1084700	1089860	So you can click on the link and see it, but it's a few basic things, mandate, robust
1089860	1095980	third party auditing, regulate organizations access to computational power, establish capable
1095980	1101980	AI agencies at the national level, establish liability for AI caused harm, introduce measures
1101980	1107860	to prevent and track AI model leaks, expand AI technical safety research, and develop
1107860	1110660	standards for identifying and managing AI generated content.
1110660	1111660	Okay, sure, whatever.
1111660	1115140	It's all pretty boilerplate in the grand scheme of things.
1115140	1119580	But so that came out March, April, March 29th.
1119580	1125620	The UK did this, this jobby, which I haven't had a chance to summarize yet.
1125620	1133420	But basically the idea is a pro innovation, AI regulatory framework, et cetera, et cetera.
1133420	1135340	Again, you see how long this thing is.
1135340	1141340	That's why it takes a little, takes a little bit of doing to summarize with a, with a GPT
1141340	1142860	API calls.
1142860	1151940	So anyways, they call for a regulatory sandbox, which so does the EA, the EU, good grief,
1151940	1156140	EU AI Act also calls for regulatory sandboxes.
1156140	1160700	So if you, if you don't know a regulatory sandbox is basically you create a safe space
1160700	1168980	where you can experiment with AI, you know, that is a little bit more permissive.
1168980	1171180	So and this is this is very often the case.
1171180	1176100	So for instance, one of the most familiar ones is if you're doing medical research,
1176100	1181580	for instance, you're allowed to use substances that are otherwise illegal.
1181580	1184340	You just have to go through approval processes.
1184340	1185340	It's not quite the same.
1185340	1191140	But the idea is that like people have been able to experiment with THC and LSD and psilocybin,
1191140	1195940	even though it's still a schedule to drug or whatever in the United States.
1195940	1199060	You just have to, you have to be approved to do so.
1199060	1204980	Likewise, if you are an approved entity, the idea of a regulatory sandbox is that you can
1204980	1208580	still do whatever science you need to do as long as you do so safely.
1208580	1212860	But also one thing about these pro innovation things is, and this is a common theme that
1212860	1216180	I actually noticed, which is why I was inspired to do this.
1216180	1224060	So the UK and the United States have all focused on protecting innovation and accelerating
1224060	1225060	innovation.
1226060	1234980	So then in early May, the UN Secretary General Antonio Guterres said that he's amenable to
1234980	1241980	the idea of the IAEA for AI, which also open AI, I forgot to add that, but open AI basically
1241980	1245100	published a blog calling for the same thing.
1245100	1249780	Then a few days later, the United States Senate hearing on AI.
1249780	1256180	This was the one with Sam Ullman and Christina Montgomery and Gary Marcus.
1256180	1258740	This was almost a three hour talk.
1258740	1262220	And I took the transcript of that and I summarized it here.
1262220	1268140	So the high level summary basically just says, here's the key points that they discussed.
1268140	1271260	And then I break each one of those down further.
1271260	1276260	So it takes you 20 minutes to read this instead of three hours.
1276260	1280260	It's pretty straightforward.
1280260	1281940	There was a lot of back and forth, a lot of questions.
1281940	1284780	I watched pretty much the entire hearing.
1284780	1288540	But clearly, the United States government was listening.
1288540	1295500	And I wonder if this whole thing was just an orchestrated series of events or not.
1295500	1300100	But anyways, a month later, the EU AI Act was proposed.
1300100	1302860	I don't think it's been adopted or ratified or anything.
1302860	1307620	I want to explain in the comments that there's still quite a process to go through.
1307620	1309820	They've got to get feedback.
1309820	1316140	But then more recently, in just the last couple of days, the United States House of Representatives
1316140	1324460	by Representative Ted Liu and a few others introduced a bipartisan commission.
1324460	1325460	Basically it's an AI commission.
1325460	1326460	I summarized it here.
1326460	1328860	I didn't summarize it here.
1328860	1333060	I copied the text here because their PDF was garbage.
1333060	1335740	Seriously, this is the United States.
1335740	1338340	You can pay someone who knows how to make a PDF.
1338340	1339340	Good Lord.
1339340	1342980	So anyways, it's relatively straightforward.
1342980	1348540	Mostly this is just saying let's appoint a panel to come up with policy recommendations.
1348540	1351740	It's not really, they're not going to do anything.
1351740	1355100	Basically it's going to produce three reports.
1355100	1361540	And so this is going to recommend what the United States Congress does for AI.
1361540	1363620	Okay, great.
1363620	1368380	Congressional commission, they're interested in getting more information, which means that
1368380	1369780	they're going to solicit experts.
1369780	1377140	So one thing that I thought was most interesting was the panel is that they want to have members
1377140	1381700	of the commission shall have a demonstrated background in at least one of the following.
1381700	1385020	Computer science or AI specifically.
1385020	1391340	Social society including constitutional rights, civil liberties, ethics and the creative community.
1391340	1394820	Industry and workforce and then government including national security.
1394820	1399320	So when you get these kinds of people in a room together, it's not just engineers and
1399320	1401020	not just data scientists.
1401020	1406940	This is going to be people that are in political science, civil rights, civil liberties, industry
1406940	1410460	insiders and then finally national security experts.
1410460	1414060	So this is going to be a pretty comprehensive set of recommendations and I'm actually pretty
1414060	1417740	happy to see that Ted Lu is leading that.
1417740	1421980	And Ted Lu is, or is he the Los Angeles County?
1421980	1427420	So it's not surprising that California Bro is going to be figuring that out.
1427420	1433300	And then finally most recently was just a couple days ago, Senator Chuck Schumer announced
1433300	1439740	the safe framework at the CSIS, which is really interesting.
1439740	1442220	And I don't know if this has been ratified yet or anything.
1442220	1448380	I haven't been able to find the actual text of the idea, but there is a one pager out
1448380	1452540	there somewhere that summarizes it very succinctly.
1452540	1457540	But I took the transcript from this and I summarized the talk here.
1457540	1467300	So basically it comes down to four major components, security, which basically talks about national
1467300	1475700	security above all else, but also corporate security and privacy of citizens, accountability,
1475700	1481580	which talks about how do you, how do you, it's actually pretty similar to the EU thing
1481580	1484980	where, oh, I forgot to mention this for the EU AI Act.
1484980	1490980	The primary thing that the EU AI Act does is it bans outright social credit systems and
1490980	1497820	surveillance like high, basically big brother bans big brother stuff.
1497820	1501020	And so this is what the security and accountability does.
1501020	1505600	An interesting part of this was the foundations aspect of the framework.
1505600	1512280	So basically one of the key things of Chuck Schumer's framework is to protect the foundations
1512280	1513900	of democracy.
1513900	1518740	So I was talking with my wife about this and she suspects that this is a direct reaction
1518740	1525140	to the January 6th attempted insurrection at the US Capitol when people are breaking
1525140	1530860	into and keep in mind that many members of Congress were directly in danger.
1530860	1537700	And so we suspect, we being my wife and I, we suspect that this is actually basically
1537700	1545060	the Congress, House of Representatives and senators, they didn't take social media seriously
1545580	1549420	and then, you know, Facebook happened with Cambridge Analytica.
1549420	1555460	I don't think it's controversial to say that, that Facebook and other social media companies
1555460	1562140	directly contributed to the widespread abuses of misinformation, but also just coordination
1562140	1563180	of violence.
1563180	1564620	It's that simple.
1564620	1569300	And so they, they learned their lesson by not taking social media seriously and now they're
1569300	1572020	taking artificial intelligence very seriously.
1572020	1577300	So on a cynical note, this is basically the establishment wanting to protect the establishment
1577300	1579820	and the status quo.
1579820	1581500	That is a pretty cynical take.
1581500	1584700	That doesn't mean that it's the only thing because I actually listened to all of Chuck
1584700	1588860	Schumer's talk and he had a very clear, like words matter.
1588860	1591260	He had a very clear-eyed understanding of what's coming.
1591260	1595940	He even talked about the possibility of jobs dislocation.
1595940	1601020	He likened it to globalization and offshoring because he said like, yes, globalization and
1601020	1607340	offshoring did actually help the economy because it, you know, allowed us to lower the prices
1607340	1612260	of goods and services, but at the same time, millions of Americans lost their job.
1612260	1616180	And so the implication there was that the United States government did not do a good
1616180	1624540	enough job to protect Americans while we were rabidly offshoring in the 90s and 2000s.
1624540	1626700	And then finally, explainability.
1626700	1630900	Some people commented that Chuck Schumer doesn't really seem to understand how AI works because
1631780	1636060	it's not a database that you can like say, oh, this is where it got the data from.
1636060	1641500	That being said, I think that these commissions will figure out, you know, that while you
1641500	1647660	can't look at the model and infer what was in it, you can look at the training data.
1647660	1652580	So what I suspect is that there's going to be very soon open source standards on training
1652580	1653580	data.
1653580	1657860	So basically, in order to be a licensed and approved and publicly available model, the
1657860	1662980	underpinning training data will have to be publicly available, or at least inspected.
1662980	1666220	He did talk about innovation first as well.
1666220	1670300	So this is a common theme that's emerging at least in Britain and America.
1670300	1673140	The EU is less concerned about innovation.
1673140	1678700	They're more concerned about fundamental civil rights and foundational human rights,
1678700	1679700	which is good.
1679700	1682260	Like I would I would actually like that.
1682260	1690020	But as an individual nation, they are highly, highly focused on focusing on innovation first
1690020	1692660	and then safety rights, accountability and stuff.
1692660	1698180	So it's basically here's the roadmap of how to innovate safely and fat and quickly.
1698180	1702380	And the idea is there are geopolitical competitions happening.
1702380	1707540	Vladimir Putin said what I think it was 2021, the nation that solves artificial intelligence
1707540	1711780	will own, you know, the next century, and it's probably going to be a lot longer than
1711780	1712780	that.
1712780	1717820	Russia, unfortunately, for them does not have the economy or the they have brain drain,
1717820	1721460	so they're not going to be a participant in artificial intelligence.
1721460	1726780	It's basically going to come down to America versus China versus the EU.
1726780	1732300	But the EU is more ideologically aligned with America and vice versa.
1732300	1737420	So it'll basically come down to East versus West, which is basically, you know, the same
1737420	1743220	idea of World War Two and the Cold War, which was Western ideology versus Eastern ideology.
1743220	1748060	So this is what the geopolitical conflict is shaping up to be for the next century.
1748060	1750300	Yay, repeat of the 20th century.
1750300	1752420	Let's hope that it's not as bloody.
1752420	1758300	And I say that flippantly, but I am dead serious because the stakes are very, very high here,
1758300	1763260	which is why I call this the Gaia Initiative, because Gaia is Greek for Earth or Mother Earth.
1763260	1765500	And also Gaia was the goddess of monsters, too.
1765500	1770300	So on the topic of Malik and Shogoth and all those other things, I think that Gaia is a
1770300	1772020	really appropriate name.
1772020	1773580	So anyways, this is out here.
1773580	1779260	It's just under github.com slash daveshop slash Gaia initiative.
1779260	1782500	I will update this as interesting news comes out.
1782500	1783940	I might forget about it for a while.
1783940	1789620	I tend to do that, but it's up there and I find all this news very encouraging.
1789620	1790620	So thanks for watching.
1790620	1791620	I hope you got a lot out of it.
1791620	1791640	Cheers.
