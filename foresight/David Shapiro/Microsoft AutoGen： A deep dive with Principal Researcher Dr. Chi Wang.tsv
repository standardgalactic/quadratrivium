start	end	text
0	1880	Chi, thanks for jumping on.
1880	3680	It's a pleasure to meet you.
3680	5400	I was really excited.
5400	7720	Yeah, you're quite welcome.
7720	11280	Obviously, Autogen is all the rage right now.
11280	12280	It's very popular.
12280	14920	There's lots and lots of videos being made about Autogen.
14920	16640	But before we dive into that,
16640	18800	I was wondering if you could just tell me a little bit more
18800	21760	about your time at Microsoft as a principal researcher,
21760	23440	like how did you get into that position?
23440	24680	What's it been like?
24680	27120	Yes, just give me the story.
27120	29760	Thank you. Yeah, my name is Chi.
30720	33680	Principal researcher at Microsoft Research.
33680	35560	I joined long time ago.
35560	39120	I joined about nine years ago in Microsoft.
39120	41840	And I've been working on many different projects.
41840	44120	Apparently now I'm focusing on Autogen.
44120	47640	And before that, I worked on automated machine learning,
47640	50120	machine learning for systems,
50120	53200	data science, data analytics, data mining.
53200	56560	So quite a lot of different things.
56560	59640	And some of the work is more like on a theoretical set
60000	63160	side and some of them is more to the system side.
64320	69320	And yeah, I've been focusing on Autogen recently.
69560	72160	So very happy to be here.
72160	73000	Excellent.
73000	76080	Yeah, with all the progress that's been made
76080	78880	on large language models and working on assistance
78880	82440	and agents, and then of course, working on agents,
82440	84080	working with other agents,
84080	85880	let me ask kind of a big question.
85880	89080	Like what was the genesis behind Autogen?
90000	92360	How was that project proposed?
92360	94680	Like how did it come together?
94680	96560	Like what was the theoretical work behind it?
96560	101120	And how did you get from zero to where you are today?
101120	104640	Yeah, so that's a very interesting question.
104640	106520	And to fully answer that question,
106520	108520	I need to tell a long story.
109440	110920	But let me first tell you a short one.
110920	115920	Short answer is like with this big kind of opportunities
115960	119360	with larger models, so powerful techniques.
119360	121200	At MSR, we want to ask the question,
121200	123160	like what is the future, right?
123160	127160	We want to be forward-looking, we want to be futuristic,
127160	129240	kind of take the solid leadership.
129240	131760	And because one of the famous quotes
131760	134520	from the founder of Macro Research,
134520	137680	we can say that the best science
137680	140960	will be indistinguishable from magic.
140960	144920	So that's the level of ambition we have.
144920	146200	So we asked the question,
146200	149640	what is the future of AI applications?
149640	152280	And how do we empower every developer to build them?
153360	156040	Yeah, so that's a fundamental driving question.
156040	160200	And now a longer version of the answer is that,
160200	162560	I started from, I thought as a tutorial,
162560	163600	before I worked on Autogen,
163600	166240	I worked on automated machine learning,
166240	168720	which is another open source project called FLAML.
169840	174360	FLAML is a solution for automating model selection,
174360	175880	hyperparameter tuning, essentially,
175880	180240	black box optimization to navigate a larger space
180240	181720	without knowing the gradient.
182960	185800	So it's a very powerful technique,
185800	190800	but that was started before the larger model takes the storm.
191720	194520	And when chatGVT released, right?
194520	199520	And that's a big, big kind of upgrade of the model capabilities.
199520	204520	And so I started working on a similar problem
204680	206000	as automated machine learning.
206000	208400	I started working on inference hyperparameter tuning
208400	210600	for these chatGVT models.
210600	213000	For example, how do you select the best model?
213000	216120	How do you select the right prompt temperature
216120	217960	and all the other inference parameters
217960	221440	so that you can maximize the utility from the models
221440	223040	while minimizing your cost?
224080	228560	So that's the initial work on this direction.
228640	231520	And when GT4 is released,
231520	235360	that's another big upgrade of the level capabilities.
235360	239000	So then I started really to ask the question,
239000	244000	okay, if we kind of want to bring the best power
244680	247480	of the model and really solve really difficult problems,
247480	249720	what should be the right way to do it?
249720	254200	And agent is apparently a very powerful notion.
254200	257240	It's another kind of level of the automation
257240	259440	as opposed to the previous automation
259440	262680	in the 20 machine learning work I did.
262680	265000	So yeah, so that's where they started.
266040	270440	And of course, it's a whole new area.
270440	271720	No, the shop agent is not new.
271720	275560	It's has been there for a long time.
275560	277240	And I remember back in college,
277240	279680	I worked on some like game competition,
279680	283080	like building agents that can play games
283080	284840	with each other and compete.
284960	288240	At that time, we were using many of the rule-based methods
288240	291720	where a lot of deal with a lot of corner cases and so on.
291720	293040	So it's not viable.
293040	295640	It's a good notion, but not viable.
295640	298800	And these larger models,
298800	300960	especially the chat-operated models,
300960	305760	really make it viable and a reality
305760	309040	that we can build new software based on.
309040	311240	And to study this new area,
311240	315960	we kind of need to think many things from scratch
315960	320400	and try to take some of the first principles
320400	321880	and what is the right approach.
321880	325880	And basically leverage every lesson
325880	329240	we learned from the previous projects, previous experience,
329240	334240	but try to build this one multi-agent framework
336040	338720	that is really generic,
338720	340720	and can support diverse applications.
341720	344680	Yeah, so there are many different examples
344680	348960	of sources of inspirations I can give you,
348960	352800	but why not show it's like using everything I learned
352800	357560	and also take every feedback I received from everyone
357560	359280	and iterate on that.
359280	361960	And so that's how we come here today.
361960	362880	Excellent.
362880	365440	Yeah, no, I mean, there's a lot to unpack there.
365440	368320	It's fascinating to me that it started
368320	371120	as sort of like auto ML,
371120	374200	like automating the optimization.
374200	378040	And I can see how going to like optimizing prompts
378040	380960	and optimizing hyperparameters and parameter tuning
380960	383640	could then lead to the agents, especially, like you said,
383640	386000	if the idea is thinking to the future,
386000	387960	like what is the sci-fi version
387960	391560	of enabling application development in the future?
391560	395800	So I wanted to follow up with a kind of a two-part question.
395800	399920	So in the most basic level, what is AutoGen?
399920	402080	But more specifically, what is the vision?
402080	404720	Like what is it that you're trying to solve
404720	406440	with AutoGen right now?
406440	410080	Yeah, so yeah, in one word,
410080	414600	AutoGen is the multi-agent AI framework,
414600	417840	and especially focusing on multi-agent conversations
417840	421520	so that we can connect large-level models, tools,
421520	426520	and human inputs together to solve complex asks.
426600	429480	There can be multiple ways to understand this.
429480	434120	So in one way is to understand it as a programming framework
435000	437760	for developers to build applications easily
437760	440480	with some simple and unified abstraction
440480	442280	so that they don't need to worry too much
442280	443480	about the lower details,
443480	446600	but can focus on how to define agents,
446600	450160	how to get them to work with each other,
450160	453080	and eventually reach the goal.
453080	456000	It can also be understood as a tool
456000	459000	to kind of scale up,
459000	461880	scale up the power of our models
461880	464440	and makes them even more useful
464440	466680	by connecting with other tools,
466680	471680	non-narrative model tools, or human collaborators,
472640	476680	and kind of scale up both the complexity of the problem
476680	480760	they can solve, the degree of automation, to some extent.
480760	484080	Yeah, this is kind of a relatively abstract instruction,
484080	486920	but if we think about it,
486920	490480	about how people use it, it's quite simple.
490480	493040	So when developers build applications with AutoGen,
493040	495240	it basically boils down to two steps.
495240	497080	Step one is to define agents,
497080	499120	and step two is to get them to talk.
499120	501280	So as simple as that.
501840	506840	Yeah, so we try to make it very useful and generic,
506840	507800	but on the other hand,
507800	512160	we want to have a very simple interface for people to use.
512160	515240	Yeah, I mean, that's exactly the vision
515240	517200	that I kind of settled on
517200	520920	for my hierarchical autonomous agent swarm idea,
520920	524640	but I don't want to make it about that.
524640	526120	Right now, it's just fascinating
526120	529600	that we kind of converge on a very similar principle,
529600	533040	like let's make the deployment of software
533040	534840	as easy as possible.
534840	536720	And so there's two things that you mentioned,
536720	538280	like layers of abstraction,
538280	540440	because I think that's a really good intuitive way
540440	541280	of thinking about it,
541280	545040	like in the same way that a Python interpreter
545040	548160	was a layer of abstraction from compiled code,
548160	550320	and then maybe language models
550320	551760	are another layer of abstraction
551760	554000	where it's natural language interface.
554000	556280	This could be seen as, again,
556280	557960	another layer of abstraction,
557960	559840	where instead of looking at interacting
559840	561400	with the language model directly,
561400	563720	it is now a type of interpreter,
563720	565520	but this is the agents
565520	569160	and the multi-agent framework on top of it.
569160	570480	So that's my intuition.
570480	572760	Do you agree with that or disagree?
572760	576160	Or like, how do you think of those layers of abstraction?
576160	578960	Yeah, that's a fantastic question.
578960	581760	The abstraction is indeed at a higher level
581760	583600	of the agent abstraction.
584600	588040	It unifies a number of different things.
588040	590200	One is larger models.
590200	593040	So when we use a single instance of a larger model,
593040	595200	we usually do prompt engineering
595200	597960	and try to give some input text
597960	599880	and get some output text out of it.
600920	605080	This agent abstraction can encapsulate that underneath
605080	607760	and provide a more intuitive way
607760	612160	to think of it as an agent that can converse with you.
612160	617160	So not just as one single text completion inference anymore.
617640	621400	It can do tasks, can persist some states
621400	624240	and continue to take your feedback
624240	628480	and produce more refined result and so on.
628480	632320	So that's a larger model-based agent.
633400	637040	There are two other kinds of backhands
637040	638120	that can be encapsulated.
638120	642200	One is, you can think of it as programming language
642200	646600	or tool-based agent, which doesn't use a larger model,
646600	650320	but they can still perform very useful actions.
650320	652440	They can do code execution, for example,
652440	655040	or it can execute predefined functions
655040	658880	or it can basically execute any programming logic
658880	662280	you've defined there.
662280	666880	And third one is the human kind of backed agents.
666880	670840	So these agents can be considered as some kind of user proxy.
672120	676720	So when they need human input, the human can take over
676720	681720	and just participate the multi-agent workflow
681760	683360	as one of the agents.
683360	685520	So you can see about several agents.
685520	688520	Some of them are larger model-based, some are tool-based,
688520	691880	others are human-based.
691880	695400	So then they can just cooperate together
695440	696880	through a very natural interface,
696880	700720	which is a conversational interface.
700720	704240	So that's kind of layer of abstraction we provide.
705360	708040	Yeah, I appreciate that.
708040	709560	And I'm reminded of during,
709560	712480	I think it was the Ignite keynote speech Satya Nadella said,
712480	713920	think of it as a reasoning engine
713920	715680	and a natural language interface.
715680	717320	And that was like the two simplest ways
717320	721160	to think of generative AI, at least the language side.
722160	725760	So the other topic that I wanted to ask about
725760	728000	to kind of dig into was thinking about it
728000	730200	as a kind of automation.
730200	733920	So there's the agent-based, there's the tools-based,
733920	735960	but then overall kind of,
735960	738840	and this is a messaging kind of a framing
738840	741640	that I've adopted when talking to people is,
741640	743560	and of course it's an oversimplification,
743560	748280	but AI is, one, AI is not new,
748280	749960	like machine learning has been around for a while,
749960	752600	this is just a step function in terms of capabilities
752600	755040	that models have.
755040	758080	But it's also just the simplest way to think about it
758080	760960	from a production standpoint or from a software standpoint,
760960	763880	is it's a new suite of automation tools, right?
763880	765120	That's kind of how I think of it.
765120	767400	Is that a fair characterization
767400	769360	or is there something that I'm missing from that?
769360	772480	Cause I do feel like there might be something missing
772480	774880	or something that that characterization
774880	776200	doesn't fully convey,
776200	779120	but it is still fundamentally new automation, right?
780080	784160	So if I try to understand it from an automation point of view,
784160	789160	I think agent is fundamentally a automation concept.
790880	794040	The automation is more like about,
794040	798360	instead of giving every detailed instructions using code,
798360	801320	I say step one, do this, step two, do that,
801320	806320	using from precisely defined program language specification.
806320	811320	And now we can make some more vague specification
812520	815240	using like natural language specification,
815240	817880	say I want to accomplish such a task
817880	820240	and could the agent do it for me?
820240	825240	So, and then underneath the agent needs to kind of break it down
825240	830240	a big complex task into maybe smaller, solvable tasks.
830760	835560	And until each task can be conveniently solved
835560	840560	by a simple inference and produce a corresponding code
841640	842720	to solve that task.
842720	846440	And then eventually we need to recompose them,
846440	848000	all of these intermediate steps
848000	850480	and get to the final output back.
850480	853240	So that is one part of the automation story.
854240	857000	And another part of it is,
857000	859400	think about this automating some tasks
859400	861880	that human had to do.
862080	867080	AutoGen really started with some very simple kind of automation.
868560	870840	Just think about how you use chatGBT.
872000	875600	You as a human need to ask questions
875600	877880	and chatGBT gave you some answer.
877880	879680	Sometimes it gave you the code
879680	882320	and then human need to take that code
882320	886960	and run it by yourself and get some result.
886960	889080	If it's not correct, you send it back
889080	892920	and chatGBT gave you some results for the game.
892920	895160	And here in this kind of interaction,
895160	897240	human students do a lot of work,
897240	902240	but many of the work can be automated if we use agent.
903120	906760	And even some kind of human feedback,
906760	911760	like non-code, if I don't like the results,
912960	916040	but I know my preferences, I will tell it,
916040	921040	such as change the chart from using a dollar to percentage
921400	923240	that kind of requirement,
923240	927400	or teach me this lesson,
927400	928800	teach me about math,
928800	931720	but using a concrete money example, right?
931720	933640	So those kind of requirements
933640	937400	can be somewhat automated using all different ways.
937400	939880	Sometimes we can use larger models.
940680	945000	Sometimes we can use some retrieval augmented approach
945000	950000	to inform retrieval to get the knowledge from somewhere.
951120	955480	That's another kind of interesting automation
955480	957160	that we can make.
957160	960400	Yeah, and within that, those automation stories,
960400	964000	because some of the examples,
964000	967680	what was it, how did you say like a vague specification,
967680	969200	right, a natural language specification
969200	972320	that is not quite as rigorous as software development
972320	974120	might have required in the past?
974120	976040	And then of course, with these models,
976040	979360	they have the ability to kind of think through it,
979360	981920	or break it down into steps.
981920	985880	So with all that, and some of the work that I have found is,
985880	988120	or some of the problems that I've confronted,
988120	989960	because it can think in general principles,
989960	991960	it does know a lot about software development,
991960	994040	and I mean, the language models know a lot
994040	995200	about a lot of things.
995200	998480	So with respect to autogen,
998480	1001640	and kind of getting to where you're at today,
1001640	1003840	what are some of the biggest challenges
1003840	1006000	that you've overcome so far, or that you haven't overcome?
1006000	1008560	Maybe that would be a more interesting story.
1008560	1011840	Yeah, sure, I could talk about both.
1011840	1014560	For what we have overcome,
1015640	1020640	I think we have kind of figured out the abstraction
1020720	1025240	to the earlier about how to unify these different types
1025240	1030240	of capabilities, different ways of making them work together.
1031080	1034960	We'll have found one very simple interface
1034960	1039120	that kind of accommodate a variety of different communication
1039120	1039960	patterns.
1039960	1042800	So one example is the, so there are several examples.
1042800	1045880	One is the simple like one-to-one conversation.
1047080	1052080	Another is hierarchical chat, like suppose one agent
1052080	1056280	is more sit on top and talk to several sub-agents,
1057280	1061240	it manages, and they can be nested structure,
1061240	1062360	hierarchical structure.
1063360	1068120	And another example is multiple one-on-one joint chat.
1068120	1072880	So there's no one that is strictly sit on top.
1072880	1075360	Everyone talks to the other else,
1075360	1079440	but it's multiple one-on-one which are connected.
1079440	1081320	So I talk to you, you talk to Katie,
1081320	1084320	you can talk to me in this kind of triangle
1084360	1086360	or multiple joint chat.
1086360	1091280	And there's also a group chat, meaning it's not a one-on-one
1091280	1092240	trend anymore.
1092240	1095160	So everybody send messages to everyone else.
1095160	1099560	So we see each other's message and there's a hidden
1099560	1102280	group chat manager which does this kind of work.
1102280	1106240	So architectural wise, it's still like one-on-one chat,
1106240	1111240	but on the surface we can create an experience
1112120	1114880	that simulates the group chat.
1114880	1117400	And they can nest it the chat in some way,
1117400	1120400	like for example, we can start with one-on-one conversation
1120400	1124760	now, but at some time I decide to consult Katie.
1124760	1126840	So I will hold on my current conversation
1126840	1128960	and have some conversation with her.
1128960	1132160	And then after I finish the conversation with her,
1132160	1134600	I get back and continue the conversation with you.
1134600	1137720	So that is a kind of nested chat.
1137720	1140080	I believe that essentially you have the building blocks
1140080	1141240	right now, right?
1141240	1143440	These are some very common building blocks
1143440	1146440	and we compose them together in different ways.
1146440	1150120	We can build really complex workflows in general.
1150120	1154640	So any arbitrarily complex communication patterns
1154640	1157280	can be essentially built up within these building blocks.
1157280	1159720	But I think that is what we have achieved.
1159720	1163080	And we have also many examples for different applications
1163080	1167600	of using these different types of patterns.
1167600	1169680	This is another second thing we figured out.
1169680	1172160	And the third thing I think is the ability
1172160	1178600	to take human input and human control in a very natural way.
1178600	1181640	And I thought earlier it's like every agent
1181640	1186760	can be configured to enable the human input or disable that,
1186760	1189360	depending on what you need.
1189360	1195360	And also you can decide the type of environment from human.
1195360	1199320	You can take over every time or you can only selectively
1199320	1201800	chime in at a certain time.
1201800	1203840	So that's a very useful feature because when
1203840	1207480	you develop this automation, initially you
1207480	1210680	don't know which step is easy to automate
1210680	1215240	and which step is necessary for human to get in.
1215240	1219760	So you can start from the more human loop way.
1219760	1221960	And when you figure out that one step is
1221960	1225720	you can confidently automate, then you can gradually reduce
1225720	1227040	your human integration.
1227080	1232800	So this convenience is very useful for doing all the experiments
1232800	1235320	and figure out the right way.
1235320	1238480	And make sure or still make sure human has a control
1238480	1240120	when they need to.
1240120	1241640	This is the third thing I think.
1241640	1245840	So one more thing is the modularity and the reusability
1245840	1247040	of the agents.
1247040	1251880	That is a very important design part of it.
1251880	1255600	So make sure that if you develop one useful agent
1255640	1258600	in a different application, you could either directly reuse
1258600	1262680	or start to modify it or extend from different ways.
1262680	1266120	And make sure the barrier to hard work is not lost.
1266120	1268520	I think that's also very important,
1268520	1272360	seeing when we work together to build more and more
1272360	1274360	complex applications.
1274360	1279240	These are a number of things I think we're kind of figure out.
1279240	1282760	And there are indeed a lot of challenges we haven't.
1282760	1286440	And yeah, shall we get to that part?
1286440	1291160	Yeah, no, I just want to reflect on some of the processes
1291160	1294320	that you outlined, like removing humans from the loop
1294320	1295640	step by step.
1295640	1297480	Back in my time as an automation engineer,
1297480	1301480	that's exactly what I would do is like, OK, I can write a script
1301480	1302560	that does one part easily.
1302560	1303320	Cool.
1303320	1305160	Now, what's the next part?
1305160	1307800	And then where do I have to jump in?
1307800	1310640	And some of the other problems that you solved, like knowing.
1310680	1312480	So this I think is really important,
1312480	1315280	because some of the members of my team and my projects
1315280	1319120	have found the same thing, is that knowing when to be quiet,
1319120	1322480	knowing when not to jump in is, in many respects,
1322480	1324440	more important because you don't want to end up
1324440	1327080	with too much noise or wasted tokens.
1327080	1328720	So that's really fascinating.
1328720	1332400	Before we talk about problems you haven't overcome,
1332400	1334240	can you talk about some insights from that,
1334240	1338840	like that inhibition signal or keeping the noise lower?
1338840	1340360	What were the key insights there?
1340360	1342480	Like how did you test that and figure it out?
1342480	1345760	And do you have any general principles for anyone else
1345760	1347840	building agents?
1347840	1349680	Yeah, this is a very good question.
1349680	1355120	This is also related to another question about when
1355120	1359880	do you add agents to provide the feedback and when
1359880	1362640	that is not helpful, right?
1362640	1366720	Because I assume the noise you're talking about
1366720	1373080	is when you add more agents to service for democratics
1373080	1380080	or agents that try to refine what the other agent is doing,
1380080	1380960	right?
1380960	1383480	They serve as a channel to provide feedback,
1383480	1387360	but sometimes not feedback can be misleading and actually
1387360	1392600	prevent the original agent doing the right thing.
1392600	1393920	Yeah, we do observe that.
1393920	1397760	And also, it's not like the more agents, the better.
1397760	1399720	It's not necessarily that.
1399720	1403400	For example, if you use GPD4 as the back end
1403400	1408240	for an assistant agent, for a large number of problems,
1408240	1411480	you'll need a simple two-agent workflow.
1411480	1414840	One assistant agent, another user proxy agent.
1414840	1416240	Yeah, probably I need to explain what
1416240	1417840	the user proxy agent is.
1417840	1420440	Basically, it refers to what I meant earlier
1420440	1423920	about automating some of the work that human does.
1423920	1426000	For example, using tools to execute
1426000	1428720	Python code or run some predefined functions.
1428720	1434080	So if you use one GPD assistant agent to suggest a solution
1434080	1436720	such as code or function and use another user proxy
1436720	1440520	to execute them and just provide feedback back and forth,
1440520	1444080	you can solve a large number of problems very well.
1444080	1446760	And some of them are also complicated
1446760	1448680	and can involve multiple steps.
1448760	1453960	But if you use GPD3.5 turbo, then it's much less
1453960	1455760	to work in this way.
1455760	1458920	So adding more agents will be much more helpful.
1458920	1462120	And even for GPD4, when the problem complexity
1462120	1466280	goes above a certain level, it stops
1466280	1469120	to follow the main instructions.
1469120	1471720	But because of the trick for one single agent to work,
1471720	1475680	it actually puts a lot of careful instructions
1475680	1478360	in the system message and make it
1478360	1482800	know how to deal with some complex situations.
1482800	1487120	But we noted that if you put too many of them, even for GPD4,
1487120	1491160	and for complex tasks, start to forget these instructions
1491160	1495000	and not do things as you want.
1495000	1498880	Otherwise, you can just give it a simple instruction
1498880	1502000	to say, try your best to solve the hardest problem
1502000	1504960	and then it will be done.
1505000	1505880	We're not there yet.
1505880	1507520	I mean, in the future, we may.
1507520	1511280	This makes me want to bring up one interesting kind of law.
1511280	1515760	We, a few of us, came up called Kabuchi's law.
1515760	1518960	The law has some similarity with,
1518960	1521920	it's an analogy of the Conway's law in software engineering.
1521920	1523920	I'm not sure if you familiar with that notion.
1523920	1524920	No.
1524920	1527760	So Conway's law basically saying the complexity
1527760	1531920	of the software or the architecture of the software
1531920	1535000	is a reflection of the organization
1535000	1538040	that makes the software, that builds the software.
1538040	1538440	OK.
1538440	1538840	Makes sense.
1538840	1539200	Yeah.
1539200	1543480	So our Kabuchi's law says the model complexity
1543480	1547200	will affect the model capacity or capability.
1547200	1550720	We change the topology of the ideal multi-agent solution.
1550720	1553400	It's a summarization of what I mentioned earlier.
1553400	1556040	If you use a more powerful model,
1556040	1561000	then likely you can use simpler topology of multi-agents
1561040	1564120	to solve a common task and vice versa.
1564120	1566840	And also, I think we need more and more research
1566840	1569040	to understand this better as it's not soft.
1569040	1573680	I'm seeing people trying all different kind of topologies
1573680	1575600	or communication patterns for different applications.
1575600	1577760	They're very creative.
1577760	1582320	And what we had to figure out is what is the best topology
1582320	1585520	and for a particular model and for a particular application
1585520	1588440	in a kind of a very clear way to answer that question.
1588440	1589600	We were not here.
1589640	1593360	And this is one of actually a big challenge
1593360	1595800	or a big important problem we want to solve.
1595800	1596880	Yeah, next.
1596880	1597680	Yeah.
1597680	1600000	No, I mean, well, first, thanks for sharing
1600000	1602320	some of those critical insights.
1602320	1604920	And so I guess the general principle
1604920	1609200	is the smarter the underpinning model,
1609200	1612160	the simpler the topology can be because the more complex
1612160	1613280	the instructions can be.
1613280	1615680	And the more complex the tasks that an individual agent
1615680	1618040	can carry out.
1618080	1619760	Saying it out loud, it seems kind of obvious,
1619760	1622280	but that's a good rule to generalize.
1622280	1626120	So yeah, I guess let's pivot into what are some of the remaining
1626120	1626600	problems?
1626600	1630520	What are your biggest challenges that you either are working on
1630520	1632920	or are going to be down the road?
1632920	1634920	You mentioned topologies, like figuring out
1634920	1636680	what is the correct topology.
1636680	1639440	And of course, I can imagine that it's a moving target
1639440	1642440	because as the underlying models change, almost
1642440	1645760	on a monthly basis, you get new and different capabilities
1645760	1648640	that kind of maybe send you back to the drawing board
1648640	1650280	sometimes.
1650280	1653520	Yeah, this is why having a framework that
1653520	1658240	is versatile and that is flexible to do the experiments
1658240	1664200	is so crucial to kind of do the fast adaptation
1664200	1669280	as model moves as prominent techniques advances
1669280	1673040	and as more and more small model specialized models are
1673040	1675160	available, they will probably also
1675160	1679480	change a lot about what was the best way to build
1679480	1681040	the applications.
1681040	1685440	Yeah, so this is, I think, the big value of autogen.
1685440	1688320	And for unsolved research questions,
1688320	1692800	there are some concrete ones I can give you a few examples.
1692800	1696640	One is about this decomposition problem.
1696640	1700560	As we mentioned earlier, we want to be
1700560	1704360	able to achieve a state where the human can only
1704360	1710480	need to specify rapidly big ambitious goal
1710480	1712720	and underneath, we want the agent
1712720	1718120	to be able to decompose that into solvable problems, probably
1718120	1721640	multiple layers, and eventually recompose it
1721640	1725720	and solve each of them and recompose it.
1725720	1727880	And during this process, there are situations
1727880	1730840	where the human need to provide the correct specifications
1730840	1734440	because the initial one can be ambiguous.
1734440	1737160	And we want the human to only provide
1737160	1740040	the necessary and make a minimal kind of necessary
1740040	1743200	qualifications and instructions and that agent
1743200	1746080	to figure out the rest of them.
1746080	1749520	That is a big challenge because if we want to solve
1749520	1752680	more complex problems, we have to have a principal way
1752680	1755200	to do this.
1755200	1758320	And the second question also ready to do this
1758320	1761920	is as we solve bigger and bigger problems,
1761920	1768240	how do we do proper validation of the intermediate results?
1768240	1770320	Because we don't do that.
1770320	1774560	If possible, the agent will stick to some wrong intermediate
1774560	1780040	results and just keep doing, keep wasting their work.
1780040	1784600	And at certain time, if we need to provide validation
1784600	1787560	or use agent to do self-validation, that's hard.
1787680	1792440	But I do a way to do it.
1792440	1796160	So we need probably into some formal language
1796160	1802400	or formal way to do this proper validation
1802400	1805920	so that the automation can indeed happen in a way
1805920	1809920	that human desires.
1809920	1814120	Yeah, so these are some just two kind of concrete pieces
1814120	1815720	like problems.
1815720	1818880	Yeah, in my project, we almost started in the reverse
1818880	1823280	where we started with oversight of steering and oversight
1823280	1825000	and supervision.
1825000	1830760	So I'm curious, what's your perception or research
1830760	1833200	or findings with respect to?
1833200	1836960	Because you already mentioned having an assistant agent
1836960	1841160	and then also having kind of a top-down hierarchical agent
1841160	1843120	where you've got subordinates.
1843120	1845000	What do you think about my intuition
1845000	1851320	that working towards having supervisors steering QA quality
1851320	1855520	assurance agents throughout the network of agents
1855520	1857880	that are capable of providing some of that feedback
1857880	1860160	that you mentioned earlier, is that kind of the direction
1860160	1860880	that you're going?
1860880	1863280	Or have you tried that and it didn't work?
1863280	1865960	Or what are your thoughts in terms
1865960	1870280	of having some of those specialized roles or personas
1870280	1873040	as a way to help along?
1873040	1877760	Yeah, there are some examples that work pretty well.
1877760	1879800	I can show some of them.
1879800	1884640	One is a three-agent setup to solve a multi-agent coding
1884640	1885800	scenario.
1885800	1888600	The application is for a supply chain optimization.
1888600	1891440	It's done by another MSR team.
1891440	1894560	But that solution, in my view, is quite generic.
1894560	1897400	It's not restricted to that particular application.
1897400	1901480	And the setup is like, it's a hierarchical setup.
1901520	1903200	There's the commander on top.
1903200	1907120	There's a writer who is responsible in writing Python
1907120	1907920	code.
1907920	1911360	The agent can also have access to some proper tools,
1911360	1913040	like organization tools.
1913040	1917200	And the other subagent is actually Safeguard.
1917200	1920720	Safeguard is in charge of reviewing code safety.
1920720	1923080	So the way it works is that the commander receives
1923080	1924280	some user's question.
1924280	1928400	It will first ask the writer to write the code.
1928400	1930680	And after receiving the code, it will ask the Safeguard
1930680	1932880	to review the code for safety.
1932880	1935680	And only if the safety criteria is met,
1935680	1939880	it will round the code and send the result back.
1939880	1943840	Otherwise, it will just ask the writer to rewrite the code.
1943840	1947120	And this can go back and forth because there can be errors.
1947120	1951080	So when you debug, the writer can do that.
1951080	1954080	Until the result is correct, the writer
1954080	1956520	comes back with a final natural language answer
1956520	1957400	to some result.
1957400	1959800	And the current return that to user.
1959800	1965280	So this is almost a quite simple multi-agent setup,
1965280	1969400	but very effective in our application, almost 100%
1969400	1971920	correct every time.
1971920	1977040	One kind of lesson is if we merge the capability of the writer
1977040	1979600	and the Safeguard into one agent,
1979600	1982840	it doesn't work that well, especially in the code safety
1982840	1984560	part.
1984600	1988640	So we have the experiments in our paper.
1988640	1993680	We found that if you merge them, then the accuracy
1993680	1998240	for detecting code safety issue will drop significantly,
1998240	2001000	both for GP4 and GP3.5 Turbo, but more
2001000	2003840	significantly for GP3.5.
2003840	2008720	So this kind of hints that one agent,
2008720	2011880	if you ask to both suggest a solution
2011880	2016240	and check the solution suggested by itself,
2016240	2018840	have a bias.
2018840	2022360	But we separate them and also prevent them
2022360	2025160	to talk to each other, kind of make
2025160	2027640	them work in an adversarial setting.
2027640	2029400	It does it better.
2029400	2031640	So that is one observation.
2031640	2034360	But we also have other kind of scenarios
2034360	2037840	where we do involve every agent in one group chat.
2037880	2039920	So everyone also sees other's message
2039920	2042200	and can reply back.
2042200	2046040	It also works sometimes for other tasks.
2046040	2051120	For example, a critique to suggest a visualization
2051120	2053600	criteria for a visualization task.
2053600	2058880	You can have one agent write code and another to criticize.
2058880	2059720	It sort of works.
2059720	2064520	But my intuition is still that if we put every agent work
2064560	2068480	together always in a group chat, it may not always work
2068480	2070640	because they may have the tendency
2070640	2077160	to agree with each other and try hard to challenge.
2077160	2082200	I would say it's case by case for different applications.
2082200	2085760	There's also some benefit of doing it in this group chat
2085760	2087760	because it's relatively simple.
2087760	2090600	You don't need to do very hard about handling
2090600	2093440	the message separation.
2093440	2095480	You can simply define your agents
2095480	2098920	and put them in a group chat and get them running quickly.
2098920	2100200	So that's one benefit of group chat
2100200	2102600	and seeing many people are using that approach.
2102600	2107080	But just to be careful that it may not always
2107080	2111160	work because of the limitations of the models.
2111160	2113360	So that's really fascinating to me.
2113360	2115920	And my intuition was the same.
2115920	2118280	But it's interesting to have that validation
2118280	2119520	from another perspective.
2119520	2123120	So it's almost like even though the underlying model
2123120	2127160	is GPT-4 running all of the agents or 3.5 turbo,
2127160	2133080	there's still a positive effect from using division of labor,
2133080	2134720	which the division of labor comes
2134720	2138320	from the history of human work.
2138320	2142000	And so just taking a moment, obviously these models
2142000	2143320	do not work like human brains.
2143320	2147720	But when you have an agent with a very specific task and mission
2147720	2151360	and set of success criteria, that effectiveness
2151400	2154120	of the division of labor still helps,
2154120	2157160	even though it's just activating the latent capabilities
2157160	2159480	within the same underpinning model.
2159480	2162320	And then another intuition or a principle
2162320	2167440	that I want to reiterate is the idea that, in some cases,
2167440	2170960	group work makes sense, but in some cases, it doesn't.
2170960	2173680	It's almost like the same difference in humans
2173680	2178800	where the power of introverts, doing solo work on your own
2178800	2180920	versus doing collaborative group work.
2180960	2183840	So again, not saying that they're operating like humans,
2183840	2186680	but it's really interesting to see some of these parallels
2186680	2192800	emerge between multi-agent work and the nature of human labor.
2192800	2195680	So yeah, very fascinating.
2195680	2199560	And it's interesting because in some of the conversations
2199560	2202400	that I've had and some of the observations that I've made,
2202400	2204640	it's almost like what we're doing with these agents,
2204640	2209040	these groups of agents, is recreating a corporation.
2209040	2211680	You might have a CEO or a boss or a supervisor,
2211680	2214160	and then you have the coder and then the QA.
2214160	2216480	So it's a very similar structure.
2216480	2220280	So do you have any other major insights or lessons
2220280	2224200	that you think are either recently or super valuable
2224200	2225960	that you want to share with other researchers
2225960	2227960	or that you would recommend?
2227960	2228720	Sure, sure.
2228720	2230520	There are so many of them.
2230520	2235120	I can give you a few examples.
2235120	2240400	One thing is the chat, the conversation perspective.
2240400	2245840	I mentioned earlier that chat GPD is a big inspiration.
2245840	2247560	Certainly for many people.
2247560	2250680	But for me, there's a personal story
2250680	2254120	about what specific user I felt from it.
2254120	2258240	It's a reminder of something I learned back in my college
2258240	2264000	from a professor who told me that conversation is a provable
2264000	2269840	way of making a good progress of learning.
2269840	2275240	I don't remember the exact quote of that, but it's roughly that.
2275240	2279120	So basically, he's trying to say, conversation
2279120	2283640	is a very powerful form of either learning or making
2283640	2289120	progress, or et cetera, that many people didn't realize
2289120	2291680	it's how important it is.
2291680	2295640	And there are some theoretical roots there.
2295640	2301080	So that's one reason I'm so kind of so sure,
2301080	2305920	or so I have so much belief in using conversation
2305920	2312360	as the central medium of the command multi-agent interface.
2312360	2317040	Again, I know there's a science, although I didn't have time
2317040	2319680	to find out which reference it was.
2319680	2325600	But I know that, so it gave me the confidence or the belief
2325600	2327560	that this is the right thing to do.
2327560	2330240	I think one of my favorite courses,
2330240	2332320	Jimmy actually found me some reference
2332320	2335000	from a social scientist.
2335000	2337440	He mentioned something similar to that.
2337440	2342880	Yeah, so this is one lesson, one kind of unique thing
2342880	2346320	that I don't think many people have really.
2346320	2350640	They kind of understand chatGVT is very powerful,
2350640	2353840	and also get a lot of useful experience from that.
2353840	2357960	But maybe this science part of it is less known.
2357960	2360040	So that's one thing I would share.
2360040	2363200	Another inspiration source, as I told you,
2363200	2366280	so auto-gen is really inspired by many different things,
2366280	2369200	many projects I've worked on before,
2369200	2370680	and all the lessons I've learned.
2370680	2374400	So another one, for example, is the operating system.
2374400	2376440	So this is also not so obvious.
2376440	2380120	When we talk about AI, why do we talk about operating systems?
2380120	2383840	I think the several things, several inspiration
2383840	2386520	I take from the success of operating systems.
2386520	2392560	One is the idea of maximizing the utility of the most valuable
2392560	2395120	resource you have.
2395120	2399520	So in old days, it's like the CPU, the GPU.
2399520	2402360	But I think in the new era of AI,
2402440	2406840	these powerful, not even models is so valuable resource
2406840	2413120	and building an operating system around them, right?
2413120	2415960	And maximizing their utility, but to give them
2415960	2421200	the necessary peripherals and do the right coordination.
2421200	2426240	And it's super critical from the system point of view.
2426240	2428840	And also, so that operating system is really
2428840	2431240	you can build a platform that can support
2431240	2434080	many diverse applications on top of that.
2434080	2438200	So we need to design a very generic robust kind of system
2438200	2439320	to do that, right?
2439320	2442480	So these are all the design principles
2442480	2445360	we try to use when we design AutoGen.
2445360	2449880	And similarly, the idea of object-oriented programming
2449880	2452440	is very useful.
2452440	2454840	So many developers have very interesting ideas
2454840	2457840	they want to try and develop.
2457840	2460440	And now with this framework that hides a lot of complexity
2460440	2464560	inside the framework, they're able to kind of do the things
2464560	2466400	they want more easily.
2466400	2468920	That's a part of abstraction.
2468920	2475160	I already mentioned the agent, notion, automation,
2475160	2476280	inspiration.
2476280	2479160	The one thing I want to mention is open source, right?
2479160	2482440	The concept of open source is that it
2482440	2486040	can solve the common problems that community needs
2486040	2488160	and make it really easy to use.
2488160	2493160	So those are probably most modern kind of things
2493160	2497200	that can get good open source adoption
2497200	2500960	and build something that the community loves, right?
2500960	2503440	Yeah, so I think that is my valuable lesson
2503440	2505400	I want to share with all researchers, right?
2505400	2508960	If you want to get their research adopted
2508960	2512640	and get more and more impact and influence
2512640	2514840	and through this open source channel,
2514840	2520480	then spend a lot of effort about usability
2520480	2524200	and solving the common problem that many people want
2524200	2528680	to solve is what's going to be considered.
2528680	2531120	I have personally found success in giving away
2531120	2534400	as much valuable information and ideas as I can.
2534400	2538080	That's what my whole YouTube career and computer science
2538080	2539720	career is based on now.
2539720	2542760	So thank you for sharing those critical insights.
2542760	2545120	So on the topic of operating systems,
2545120	2547040	because I'm really glad you brought that up,
2547040	2550320	because I started thinking about language models
2550320	2553360	as a component, like a new component of an operating
2553360	2554040	system.
2554040	2556600	So I'm glad to know that there's some convergence there.
2556600	2558960	Is that kind of the future of Autogen?
2558960	2560920	Is that what you're looking to move towards
2560920	2566040	is kind of being the operating system or a major component
2566040	2570680	of a future operating system that uses language models
2570680	2575160	as like kind of the new CPU and maybe retrieval augmented,
2575160	2578680	some kind of storage as like the new memory?
2578680	2581680	Is that kind of the direction that it's going?
2581680	2582400	Yeah, exactly.
2582400	2585200	So it's my ambition.
2585200	2587440	When I started working with Autogen,
2587440	2592640	I discussed with some systems friends working on the systems.
2592640	2594480	I told them this idea.
2594480	2598080	And yeah, it sounds very ambitious idea to them.
2598080	2603240	But I can see that some people really liked this idea.
2603240	2606040	And even some 13-year people will give me
2606040	2608640	stronger, strong support of this.
2608640	2612520	He kind of had that idea independently.
2612520	2616360	I kind of see that some of the most visionary people also
2616360	2617160	realized this.
2617160	2622400	And definitely, we want to pursue for that.
2622400	2623280	Excellent.
2623280	2627640	So taking a big step back, just in terms of the direction
2627640	2630280	of research, I think, I don't know if it's official,
2630280	2634680	but the rumor is right now OpenAI is working on GPT-5.
2634680	2637160	And then, of course, Google with Gemini and Meta,
2637160	2640240	like everyone is working on bigger and bigger models now.
2640240	2644480	And so we're going to get more capabilities at the same time.
2644480	2646480	Smaller models are becoming more efficient.
2646480	2650200	So Satya Nadella announced small language models coming.
2650200	2653840	So that way, you can probably perform very small cognitive
2653840	2656480	functions, but very quickly and efficiently.
2656480	2659240	So what are some of the trends that you
2659240	2663680	see intersecting with your work around auto-gen and agents
2663680	2665200	and agent swarms?
2665200	2667040	And what I mean, I guess, to be specific,
2667040	2672720	is maybe cost changing or new capabilities coming.
2672720	2674880	Are there any capabilities that you're really looking for
2674880	2678160	that would make your job easier?
2678160	2680800	What are your thoughts on some of these new capabilities
2680800	2685640	and making these multi-agent platforms more autonomous?
2685680	2687400	Or is that a good idea, a bad idea?
2687400	2689360	So very kind of open-ended question,
2689360	2693080	like what do you see coming this time next year?
2693080	2697720	Yeah, I think the idea of having specialized models
2697720	2701560	to perform certain tasks in an excellent way
2701560	2705560	and in a cheap way is fascinating.
2705560	2709440	It's indeed worth a lot of investigation.
2709440	2713400	For example, some of the hard problems I mentioned earlier
2713400	2717280	about the decomposition, recombination, validation,
2717280	2720160	it's possible that some specialized model
2720160	2722480	can do these kind of tasks really well.
2722480	2723760	Or we haven't seen that yet.
2723760	2728160	But conceptually, that sounds like a possibility.
2728160	2733440	Actually, I'm pretty surprised that we haven't found
2733440	2735120	a special model that can solve this.
2735120	2739840	So it makes me kind of wonder why.
2739840	2742880	Because it's such a natural idea that if you're
2742880	2745920	finding a model that can do certain things,
2745920	2748240	you should be able to do certain tasks very well
2748240	2752320	and you can just replace one specific agent with that.
2752320	2754920	And I don't know many people are trying that.
2754920	2758240	Either there's some fundamental reason
2758240	2763960	we haven't figured out why we can't do that,
2763960	2767920	or we should be able to see that pretty soon.
2767920	2770440	I think it's only one of these two possibilities.
2770440	2772360	Because the former possibility is still there
2772400	2776000	because the small model, it's possible that the small model
2776000	2778280	lacks some very important capability
2778280	2781920	of being functioned to perform these hard tasks.
2781920	2783480	Because these tasks are not easy.
2783480	2788400	The composition problem, I think, even the GPD4 model,
2788400	2791440	it's known to not to be too good at planning.
2791440	2795200	It can do some kind of planning, but not perfectly.
2795200	2797800	So if you want to get better capability than GPD4
2797800	2803240	in some specialized tasks, it's to be seeing
2803240	2804760	whether we can accomplish that.
2804760	2808360	But if we lower the target, if we say,
2808360	2810240	let's train some small models that
2810240	2812840	can do something that GPD4 is already good at,
2812840	2816120	that is much more amenable.
2816120	2819400	I think I already see evidence of that.
2819400	2823640	So then it's more like a cost reduction story.
2823640	2827960	So that is, I'm pretty sure, that's feasible.
2827960	2831760	And the other part about getting better capability
2831760	2835520	than the big model, in some aspect,
2835520	2842240	is to be kind of, yeah, we have to hold our scientific curiosity
2842240	2845440	and see what happens.
2845440	2846360	That makes sense.
2846360	2850840	We are almost out of time, so I want to respect everyone's time.
2850840	2853120	And so I'll just say, thank you so much
2853120	2856200	for jumping on and sharing some of your thoughts.
2856200	2860480	I'm super excited to be along for the ride.
2860480	2863480	But yeah, before we close, I'll give the floor to you.
2863480	2867680	Is there anything that you'd like to put out in the world,
2867680	2871720	any personal requests or personal hopes
2871720	2875200	that you want to want to share with a broader audience?
2875200	2878000	Thanks for giving me the opportunity to do that.
2878000	2881280	Yeah, I want to say that we are still
2881280	2884520	early at the new age.
2884520	2887560	Agents become mature software that
2887560	2890400	can do a lot of things for us.
2890400	2892840	We want to build the future together
2892840	2895960	with everyone from the community.
2895960	2898560	So give Autogeno a try.
2898560	2900680	Try to use it for applications.
2900680	2903520	Let us know what's working and what's not.
2903520	2908200	We are very happy to work together to improve it
2908200	2910840	and answer some of the big, important problems
2910920	2912080	as we mentioned.
2912080	2916800	And I really want to acknowledge that all the contributors,
2916800	2921600	starting from the original paper to the recent,
2921600	2925080	more open source resources, joined together,
2925080	2928960	and the huge developer community that's supporting us,
2928960	2933880	I really learned a lot from everyone who has used
2933880	2938480	and provided feedback that people are super, super creative.
2938480	2942720	I think this is the right way to solve the hard problems
2942720	2946760	and hope to continue to do that and support the community,
2946760	2947840	support everyone.
2947840	2951120	And for example, the effort you're doing
2951120	2954680	with the hierarchical agent swarm,
2954680	2958200	it's a very good example that you're
2958200	2963560	making certain bats on certain ways of making money and work.
2963560	2966200	I'm very curious to see how that experiment goes.
2966200	2970440	And if altering can be of any help in this or other consumer
2970440	2975600	efforts, we'll be very happy to support you
2975600	2981560	if you need any feature and useful infrastructure support
2981560	2983320	that kind of thing.
2983320	2985880	Yes, let us know.
2985880	2987760	Yeah, absolutely.
2987760	2990440	No, we'll be definitely looking forward
2990440	2993560	to continuing the collaboration.
2993560	2996120	I think that, as you said, there is a lot of work to do.
2996160	2997680	And there are some limitations.
2997680	3000600	The model's limitations today are the model's limitations.
3000600	3003200	There's not a lot we can do to work around that.
3003200	3005240	But it is just the beginning.
3005240	3008640	And that's one thing that I'll use the closing to say
3008640	3013040	is remember where we were a year ago today.
3013040	3017600	Chat GPT was probably published just about a year ago.
3017600	3021760	But before that, it was GPT-3, GPT-3.5.
3021760	3026100	And the distance that we've covered in just the last year
3026100	3031460	is it is a privilege to be part of one of the greatest shifts
3031460	3033260	that humanity has ever seen.
3033260	3034780	And some days, it doesn't feel real.
3034780	3036780	And some days, it feels a little too real
3036780	3038100	and a little too overwhelming.
3038100	3042300	So thank you, Xi, for helping make this a reality
3042300	3044540	and spending some time talking with me.
3044540	3047620	And thank you to Katie for helping put this together.
3047620	3049940	And yeah, so thanks everyone.
3049940	3053740	And yeah, see you all next time.
3053740	3054540	Thank you so much.
