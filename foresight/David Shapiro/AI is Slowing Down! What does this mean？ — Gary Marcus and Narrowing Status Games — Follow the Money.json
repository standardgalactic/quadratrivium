{"text": " David Shapiro here, your personal chief AI officer. So what I wanted to do today was unpack some of the recent patterns and trends that we've been seeing. Now I made a video recently where I talked about all the reasons that I think that AI is slowing down and of course I'm not the only one. Now there are plenty of people who disagree with this story and I'll address that in a minute with respect to the potential emergence of echo chambers. But first I want to address, okay, what does it mean? Now that AI is slowing down, or at least there are initial signs that AI might be slowing down in terms of progress, and that's not to say that it's stalling, it's just the rate of acceleration is deteriorating. So when I say slowing down, that's like we're still at the very early stages if this trend is reversing. So the first thing is safety. This is really great news for people in the safety crowd because it means that the singularity is not gonna happen in 2027. We can kick the can down the road a little bit further before we get an intelligence explosion if an intelligence explosion is even possible. Personally, I've started to have doubts that we're gonna get those accelerating returns, particularly as I've seen some new news about the way that the human brain might work. There is increasing evidence that the human brain is not just a matter of computation based on neural synaptic connections, but that it could be a combination of that, the electromagnetic waves that propagate across the brain as well as quantum effects. There is increasing evidence that human consciousness and human intelligence is actually the combination of several energies and several parts of physics that are all working together to create that. So I'm just like, hmm, maybe there's a lot more to intelligence than we thought, and of course there's gonna be a lot of people out there saying, see, I told you so, but it is what it is. And these are also just possibilities. But according to this possibility, it might be that there are gonna be continuing diminishing returns with respect to neural networks or even silicon-based computing that means that it will just be increasingly difficult to either reconstruct or to capture human-level intelligence. And another thing that's emerging to me is that we are going to see a very distinct bifurcation between human intelligence and machine intelligence, meaning that it's gonna be kind of like comparing apples to oranges, and it really already is, because we look at large language models which are very clearly processing information. I remember I had a conversation with some philosophers a year ago or so, and they made the somewhat asinine claim that, oh, they don't know anything, there's no information. I'm like, that's literally all that they're doing is just processing information, but it depends on definitions. And so to these philosophers, the idea that this is a machine that only processes information because their definition of information was stuff in human brains. I'm like, okay, well, that's just a bad definition of information. Anyways, going down a rabbit hole. My point is that it really depends on how you look at intelligence and how you define intelligence. And I really don't like those gotcha questions because it's like, how do you define intelligence? And it's like, I mean, it depends on who you ask. There's a million definitions of intelligence. And the fact that we don't have a good definition of intelligence means that also, by extension, we don't have a good definition of artificial general intelligence. And when you ask a mathematician what intelligence is, they're gonna give you one answer. When you ask a neuroscientist what intelligence is, they're gonna give you a different answer. If you ask a psychologist and a philosopher what intelligence is, again, they're going to give you fundamentally different answers. So moving on, another thing that this is good for, and this is gonna be really good news, really reassuring news to many of you out there, is that if AI is indeed slowing down, that means that the threat to jobs and the rate of change for jobs is going to be slower, which means the status quo that we have is going to persist a little bit longer than perhaps some of us would like. Now, what I do wanna address is that there's gonna be mixed reactions to this. So some people are like, let's just get it done, like replace my job, I'm ready to get out of the workforce, give me UBI and get me out of the workforce for good. I don't care. And other people are gonna be like, well, this will give us time to create new jobs, I don't wanna lose my job yet, and so on and so forth. Now, if I had to guess, now keep in mind that I'm speculating here, and that's a lot of what I do on this channel, my gut check now is that it's gonna be five to 10 years. And I've talked about this before where you look at the adoption curve, and it's like seven years. So maybe 2030, and 2030 seems to be a pretty sticky date. So anywhere between 2027 to 2030 is when we might start seeing some really drastic change out there. Now, I could be wrong, we could have a confluence of multiple technologies, like again, I'm really waiting to see how GPT-5 and robotics mix, because you see the number of bipedal, like humanoid robotic chassis being built around the world. And like, remember, this is only gen one. So GPT-5 and Claude Four and whatever else, you combine that level of intelligence with robots, that really could change a lot for a lot of things. And I think there's, I don't know if it's proven out or to what extent, but I've heard that Tesla is already using their robots in the Tesla factories. And the economic carrot for that is really high. So don't underestimate the power of that economic incentive to get things really going. But overall, if the advancement of AI intelligence is indeed slowing down, it just gives us all more time to adapt on a cybersecurity level, on an economic level, on a military level. So it means that, you know, your life is not gonna get upended soon, hopefully. So this leads me to want to address another thing. About what, 12 months ago, a little bit more, I predicted that we would have AGI by September 2024. So that's just a few months from now. Now, what I was looking at at the time, and, you know, if you go back and watch my videos, there's a whole bunch of charts and data that I was looking at. And this is right along the curve of what Ray Kurzweil originally proposed, is to when we would have a human level, you know, intelligence in a single computer is actually 2023. So that was one piece of data. I was also looking at parameter counts going up, logarithmically, which they have been, but they've slowed down. And the one thing that I was not looking at, so this is the piece of data that I did not include in all of those calculations, was the exponentially rising costs of training subsequent generations of models. So, you know, as, I think it was Dimitris Abbas was talking about on a podcast recently, every subsequent generation from GPT-2 to 3 to 4 costs 10 times as much to train, if not more. So while all these other things are going up exponentially, so is cost. And that did not figure into my calculus. And so because of that, it's like, oh, well, if I had thing, you know, recognize that, I might have said, well, we're probably gonna get diminishing returns sooner rather than later. Now I have been talking about diminishing returns pretty much for the life of this channel. And I've been wondering, when is the jig gonna be up? When are we gonna run out of steam here? And it looks like we're starting to run out of steam. Now again, you know, the train is still running, we're still burning pretty hot, but we're not accelerating anymore. We are probably on a more geometric trajectory right now if I had to guess. And it all comes down to economics. It really is just with exponentially rising costs with a, we're entering into what's called a red ocean market, which means it's not just, you know, a blue ocean out there with its just open AI with their frontier model. Lots of other models have caught up to GPT-4O, Claude 3.5 Sonnet has clearly surpassed it as far as I can tell. Obviously people like looking at a, whatever that benchmark is called, I don't really give that much weight because it's, that seems like it's mostly a popularity contest and open AI still has a lot of fanboys, but doing a side-by-side comparison of capability between chat GPT-4O and Claude 3.5, it is hands down Claude 3.5 is in another league as far as I can tell. Now obviously a lot of you out there use it for different things. So, you know, it is gonna, it's gonna depend on your use case. Another thing that I've noticed is that there's been fewer breakthroughs. So like, yes, chat GPT-4O has the voice mode, which is really, you know, okay, cool, like it can do a sultry voice and sound effects, which is great. But that was a predictable addition with multimodality, where it's like, okay, text and audio, great. This is still leaving a huge swath of economic interests and intellectual interests completely untouched. Take math for instance, they still haven't figured out math and physics and those sorts of things. And also after playing around with the ARC AGI test, yes, I have not been a fan of the ARC AGI test, but at the same time, like it does prove a point. It does prove a point that the kind of reasoning that these things do is still very different from human reasoning, which is another reason that I'm talking about a bifurcation of intelligence. That we might be, and this is again, as pure speculation on my point, we might be getting to a point where we're starting to recognize, okay, this machine is kind of an alien intelligence. It clearly has its own consistent way of approaching the world, but it is also very different from us. Now, Bill Gates was on a podcast recently saying that metacognition is gonna be the next step. Okay, sure, I mean, I've been working on cognitive architectures for a while, and there are some really sharp people out there that figured out how to give models metacognition a while ago, it's really just down to prompting. You can give, for instance, especially with these gigantic context windows, you can give one sec, one model say, hey, you're a metacognitive agent that's viewing these other thoughts. Tell us what you think about it. Help steer it on moral course. This was entirely all of my work on the ACE framework, the autonomous cognitive entity framework, which I did abandon because Microsoft Autogen and other platforms far surpassed what I could do on my own, even with help from people on the internet, because why it's Microsoft, and they have a lot more money than I do. Now, that leads me to another point that I wanna address, and that is echo chambers. So most of you in the audience, based on the polls that I've run, most of you in the audience, statistically speaking, are kind of in the middle of the bell curve where you're reasonable and you want the truth, and you want some honest, genuine thoughts. There are, however, many people out there that are on more of the tail, like left to right tail of the bell curve, where you wanna see doom or you wanna see acceleration, and you're not really interested in other narratives. And the reason that I'm using the word echo chamber, which is often pathologized, is because there have actually been a few people that did directly express to me they did not want an alternative narrative. They only wanted to double down on their personal narrative, the one that they want to be true, which, believe me, I want to have all kinds of advancements happening next year. That was not hype when I said that I was predicting AGI this year. That was a genuine prediction on my part, and I was like, man, things are happening, they're accelerating, but I don't believe that anymore because of the data that I'm seeing, because of the trends that I'm seeing. And I know that that sucks, like if someone is banking on a certain outcome, like expectations and reality, there's always a gap between expectations and reality, and when that gap gets bigger, it sucks. Now, some people are gonna take this news and interpret it in completely unexpected ways to me, and that's fine. But what I do wanna caution is for the five or less percent of you out there in the audience that are on the tails of the bell curve in terms of expectations and your disposition, your valence towards this, is if you broaden your narratives just a little bit, then you might be surprised at some of the other advantages that are happening, and also just realizing that there is a silver lining, is that the disruption that is coming is gonna take a little bit longer, which means that society will be a little bit more stable, which means that the risk of catastrophic outcomes or unintended outcomes goes down significantly. And on the topic of those narratives and those echo chambers, a lot of people have asked me to comment on Gary Marcus, and I've resisted until now, but having gotten back on Twitter, I will say that I've watched some really interesting and highly vitriolic debates between namely Gary Marcus, Yasha Bach, and Jan Lacoon. Now, these are supposed to be the adults in the room, and having watched Yasha on some interviews, like he's a very sharp guy, but even he got into the like, let's just beat up on, let's like, what is the term that kids use these days, like let's clown on Gary Marcus train, and that was honestly really disappointing because this is someone who's supposed to be like a high brow like academic researcher, and he's sharing like caricature memes of Gary, which, I mean, I would never do that. I don't particularly agree with Gary anymore, but that was incredibly immature. And then Jan Lacoon has often had this like, old man yells at cloud energy, which is weird because it's like, half of what he says I agree with, like Ferventland, the other half, I'm like, where did that come from? So, all right, so what happens? And this is not, to be fair, taking a step back, this is not a unique phenomenon in AI. Some of, one of my good friends as a physicist, this kind of thing happens in the physics community all the time, apparently, where it's like disagreements and arguments over interpretations will actually like, come to shouting matches and sometimes fist fights. Physicists are actually pretty hardcore, it turns out. So, from my reading of, you know, human nature, what I, the way that I interpret this is that we have a tightening status game. So, Gary, Yasha, Yan, all of these people, they suddenly saw themselves having much, much higher social status because of artificial intelligence. And so, one way to compare this is, imagine you're back in high school and something changes and suddenly, the nerds are all the most popular kids in school. Well, then something changes again, and it's like, oh, well, actually, instead of the top eight nerds, now it's the top five. And so, three have to get kicked off the island. That's what's happening. And so, they're scrabbling over diminishing social status because, again, with AI slowing down, it's no longer as hot and sexy as it was a year ago. It's no longer, you know, you can't just say, hey, I was gonna kill everyone and get an invitation to the TED stage anymore. And so, because of that, because the status game is narrowing, because the number of people that can be high status is going down, the rules are becoming more arbitrary and people are becoming a little bit more snippy, a little bit more vitriolic, as I said. The stakes go up because the risk of losing status, especially, this is what we saw with Ilya. I talked about this extensively. The reason that Ilya was socially canceled with an open AI is because he made the cardinal sin of attacking Sam Altman, even though he was doing it for what he believed was the right reasons, that was a violation of the social norm, which is Sam Altman is king. And of course, Sam Altman, as a power seeking person, was not going to tolerate that. Consciously or unconsciously, that was just never going to, he was never going to tolerate it. So what happens is, other AI commentators out there, namely Gary, Yasha, and Yan, are doubling down on their narratives, because basically they're gonna be doubling down on the narratives that got them that social status in the first place. And that is my read on the situation. And also, I take that as evidence that AI is slowing down, because again, if AI is running out of steam, then the amount of space that the public square needs of AI commentators is going down. It's also been a year and a half since Gary Marcus was in front of the Senate. And have you seen him or heard him any other place? No, like his 15 minutes of fame might be over, and that sucks, like that doesn't feel good. It does not feel good to feel like you're being left behind by the conversation or by society, which is to me, an explanation as to why Gary has been so incredibly salty lately. And then of course, other people that are not as aware of these status games will jump in on bullying, because if you show weakness in a high-stakes status game, people will unconsciously, it's tall poppy syndrome and a number of other phenomenon, people will unconsciously jump in on that and say, ah, time to bully that person, because they're signaling that their status is vulnerable. So that's my read on the whole situation. And yeah, it's not ideal, it's not what I hoped, it's not what I predicted, but I ignored the numbers, I ignored the money, right? Like, and hindsight, that was pretty dumb. So am I still predicting September 2024? Again, this is where I'm gonna double down on my narrative. I think that GPT-5 plus robots will surprise a lot of people with what it's capable of. Is it gonna replace all of us? No, it's gonna be like the Nestor class four from iRobot, where it's like, it's capable of running your mail for you automatically, but not much else. That's kind of what I predict. So it's like, you know, you can get rid of like, maybe some warehouse workers, some factory workers, some mail carriers, but it's not gonna like, upend the whole economy. So, all right. This has been your first episode of David Shapiro, your personal chief AI officer. Let me know how you think this went in the comments and I'll see you next time. Cheers.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 3.84, "text": " David Shapiro here, your personal chief AI officer.", "tokens": [50364, 4389, 44160, 5182, 510, 11, 428, 2973, 9588, 7318, 8456, 13, 50556], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 1, "seek": 0, "start": 3.84, "end": 6.8, "text": " So what I wanted to do today was unpack", "tokens": [50556, 407, 437, 286, 1415, 281, 360, 965, 390, 26699, 50704], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 2, "seek": 0, "start": 6.8, "end": 9.92, "text": " some of the recent patterns and trends", "tokens": [50704, 512, 295, 264, 5162, 8294, 293, 13892, 50860], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 3, "seek": 0, "start": 9.92, "end": 11.36, "text": " that we've been seeing.", "tokens": [50860, 300, 321, 600, 668, 2577, 13, 50932], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 4, "seek": 0, "start": 11.36, "end": 13.66, "text": " Now I made a video recently where I talked about", "tokens": [50932, 823, 286, 1027, 257, 960, 3938, 689, 286, 2825, 466, 51047], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 5, "seek": 0, "start": 13.66, "end": 16.84, "text": " all the reasons that I think that AI is slowing down", "tokens": [51047, 439, 264, 4112, 300, 286, 519, 300, 7318, 307, 26958, 760, 51206], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 6, "seek": 0, "start": 16.84, "end": 18.84, "text": " and of course I'm not the only one.", "tokens": [51206, 293, 295, 1164, 286, 478, 406, 264, 787, 472, 13, 51306], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 7, "seek": 0, "start": 18.84, "end": 22.240000000000002, "text": " Now there are plenty of people who disagree with this story", "tokens": [51306, 823, 456, 366, 7140, 295, 561, 567, 14091, 365, 341, 1657, 51476], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 8, "seek": 0, "start": 22.240000000000002, "end": 24.84, "text": " and I'll address that in a minute with respect", "tokens": [51476, 293, 286, 603, 2985, 300, 294, 257, 3456, 365, 3104, 51606], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 9, "seek": 0, "start": 24.84, "end": 28.6, "text": " to the potential emergence of echo chambers.", "tokens": [51606, 281, 264, 3995, 36211, 295, 14300, 34513, 13, 51794], "temperature": 0.0, "avg_logprob": -0.1075952032338018, "compression_ratio": 1.6204379562043796, "no_speech_prob": 0.01770438812673092}, {"id": 10, "seek": 2860, "start": 28.6, "end": 31.8, "text": " But first I want to address, okay, what does it mean?", "tokens": [50364, 583, 700, 286, 528, 281, 2985, 11, 1392, 11, 437, 775, 309, 914, 30, 50524], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 11, "seek": 2860, "start": 31.8, "end": 33.56, "text": " Now that AI is slowing down,", "tokens": [50524, 823, 300, 7318, 307, 26958, 760, 11, 50612], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 12, "seek": 2860, "start": 33.56, "end": 35.28, "text": " or at least there are initial signs", "tokens": [50612, 420, 412, 1935, 456, 366, 5883, 7880, 50698], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 13, "seek": 2860, "start": 35.28, "end": 37.28, "text": " that AI might be slowing down in terms of progress,", "tokens": [50698, 300, 7318, 1062, 312, 26958, 760, 294, 2115, 295, 4205, 11, 50798], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 14, "seek": 2860, "start": 37.28, "end": 39.120000000000005, "text": " and that's not to say that it's stalling,", "tokens": [50798, 293, 300, 311, 406, 281, 584, 300, 309, 311, 19633, 278, 11, 50890], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 15, "seek": 2860, "start": 39.120000000000005, "end": 42.54, "text": " it's just the rate of acceleration is deteriorating.", "tokens": [50890, 309, 311, 445, 264, 3314, 295, 17162, 307, 26431, 990, 13, 51061], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 16, "seek": 2860, "start": 42.54, "end": 43.800000000000004, "text": " So when I say slowing down,", "tokens": [51061, 407, 562, 286, 584, 26958, 760, 11, 51124], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 17, "seek": 2860, "start": 43.800000000000004, "end": 46.56, "text": " that's like we're still at the very early stages", "tokens": [51124, 300, 311, 411, 321, 434, 920, 412, 264, 588, 2440, 10232, 51262], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 18, "seek": 2860, "start": 46.56, "end": 49.760000000000005, "text": " if this trend is reversing.", "tokens": [51262, 498, 341, 6028, 307, 14582, 278, 13, 51422], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 19, "seek": 2860, "start": 49.760000000000005, "end": 51.96, "text": " So the first thing is safety.", "tokens": [51422, 407, 264, 700, 551, 307, 4514, 13, 51532], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 20, "seek": 2860, "start": 51.96, "end": 54.88, "text": " This is really great news for people in the safety crowd", "tokens": [51532, 639, 307, 534, 869, 2583, 337, 561, 294, 264, 4514, 6919, 51678], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 21, "seek": 2860, "start": 54.88, "end": 57.08, "text": " because it means that the singularity", "tokens": [51678, 570, 309, 1355, 300, 264, 20010, 507, 51788], "temperature": 0.0, "avg_logprob": -0.099569673123567, "compression_ratio": 1.7491166077738516, "no_speech_prob": 0.000732128624804318}, {"id": 22, "seek": 5708, "start": 57.08, "end": 59.48, "text": " is not gonna happen in 2027.", "tokens": [50364, 307, 406, 799, 1051, 294, 945, 10076, 13, 50484], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 23, "seek": 5708, "start": 59.48, "end": 62.56, "text": " We can kick the can down the road a little bit further", "tokens": [50484, 492, 393, 4437, 264, 393, 760, 264, 3060, 257, 707, 857, 3052, 50638], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 24, "seek": 5708, "start": 62.56, "end": 64.88, "text": " before we get an intelligence explosion", "tokens": [50638, 949, 321, 483, 364, 7599, 15673, 50754], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 25, "seek": 5708, "start": 64.88, "end": 68.16, "text": " if an intelligence explosion is even possible.", "tokens": [50754, 498, 364, 7599, 15673, 307, 754, 1944, 13, 50918], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 26, "seek": 5708, "start": 68.16, "end": 70.06, "text": " Personally, I've started to have doubts", "tokens": [50918, 21079, 11, 286, 600, 1409, 281, 362, 22618, 51013], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 27, "seek": 5708, "start": 70.06, "end": 72.6, "text": " that we're gonna get those accelerating returns,", "tokens": [51013, 300, 321, 434, 799, 483, 729, 34391, 11247, 11, 51140], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 28, "seek": 5708, "start": 72.6, "end": 75.74, "text": " particularly as I've seen some new news", "tokens": [51140, 4098, 382, 286, 600, 1612, 512, 777, 2583, 51297], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 29, "seek": 5708, "start": 75.74, "end": 78.92, "text": " about the way that the human brain might work.", "tokens": [51297, 466, 264, 636, 300, 264, 1952, 3567, 1062, 589, 13, 51456], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 30, "seek": 5708, "start": 78.92, "end": 81.44, "text": " There is increasing evidence that the human brain", "tokens": [51456, 821, 307, 5662, 4467, 300, 264, 1952, 3567, 51582], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 31, "seek": 5708, "start": 81.44, "end": 83.64, "text": " is not just a matter of computation", "tokens": [51582, 307, 406, 445, 257, 1871, 295, 24903, 51692], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 32, "seek": 5708, "start": 83.64, "end": 86.08, "text": " based on neural synaptic connections,", "tokens": [51692, 2361, 322, 18161, 5451, 2796, 299, 9271, 11, 51814], "temperature": 0.0, "avg_logprob": -0.09865001974434688, "compression_ratio": 1.6785714285714286, "no_speech_prob": 0.004754457622766495}, {"id": 33, "seek": 8608, "start": 86.08, "end": 88.16, "text": " but that it could be a combination of that,", "tokens": [50364, 457, 300, 309, 727, 312, 257, 6562, 295, 300, 11, 50468], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 34, "seek": 8608, "start": 88.16, "end": 90.64, "text": " the electromagnetic waves that propagate across the brain", "tokens": [50468, 264, 32214, 9417, 300, 48256, 2108, 264, 3567, 50592], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 35, "seek": 8608, "start": 90.64, "end": 92.16, "text": " as well as quantum effects.", "tokens": [50592, 382, 731, 382, 13018, 5065, 13, 50668], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 36, "seek": 8608, "start": 92.16, "end": 95.8, "text": " There is increasing evidence that human consciousness", "tokens": [50668, 821, 307, 5662, 4467, 300, 1952, 10081, 50850], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 37, "seek": 8608, "start": 95.8, "end": 98.6, "text": " and human intelligence is actually the combination", "tokens": [50850, 293, 1952, 7599, 307, 767, 264, 6562, 50990], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 38, "seek": 8608, "start": 98.6, "end": 101.36, "text": " of several energies and several parts of physics", "tokens": [50990, 295, 2940, 25737, 293, 2940, 3166, 295, 10649, 51128], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 39, "seek": 8608, "start": 101.36, "end": 103.64, "text": " that are all working together to create that.", "tokens": [51128, 300, 366, 439, 1364, 1214, 281, 1884, 300, 13, 51242], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 40, "seek": 8608, "start": 103.64, "end": 106.68, "text": " So I'm just like, hmm, maybe there's a lot more", "tokens": [51242, 407, 286, 478, 445, 411, 11, 16478, 11, 1310, 456, 311, 257, 688, 544, 51394], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 41, "seek": 8608, "start": 106.68, "end": 107.96, "text": " to intelligence than we thought,", "tokens": [51394, 281, 7599, 813, 321, 1194, 11, 51458], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 42, "seek": 8608, "start": 107.96, "end": 109.56, "text": " and of course there's gonna be a lot of people out there", "tokens": [51458, 293, 295, 1164, 456, 311, 799, 312, 257, 688, 295, 561, 484, 456, 51538], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 43, "seek": 8608, "start": 109.56, "end": 113.0, "text": " saying, see, I told you so, but it is what it is.", "tokens": [51538, 1566, 11, 536, 11, 286, 1907, 291, 370, 11, 457, 309, 307, 437, 309, 307, 13, 51710], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 44, "seek": 8608, "start": 113.0, "end": 115.96, "text": " And these are also just possibilities.", "tokens": [51710, 400, 613, 366, 611, 445, 12178, 13, 51858], "temperature": 0.0, "avg_logprob": -0.11950723968283103, "compression_ratio": 1.7320872274143302, "no_speech_prob": 7.254063530126587e-05}, {"id": 45, "seek": 11596, "start": 115.96, "end": 119.47999999999999, "text": " But according to this possibility,", "tokens": [50364, 583, 4650, 281, 341, 7959, 11, 50540], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 46, "seek": 11596, "start": 119.47999999999999, "end": 121.97999999999999, "text": " it might be that there are gonna be continuing", "tokens": [50540, 309, 1062, 312, 300, 456, 366, 799, 312, 9289, 50665], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 47, "seek": 11596, "start": 121.97999999999999, "end": 125.88, "text": " diminishing returns with respect to neural networks", "tokens": [50665, 15739, 3807, 11247, 365, 3104, 281, 18161, 9590, 50860], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 48, "seek": 11596, "start": 125.88, "end": 128.16, "text": " or even silicon-based computing", "tokens": [50860, 420, 754, 22848, 12, 6032, 15866, 50974], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 49, "seek": 11596, "start": 128.16, "end": 130.92, "text": " that means that it will just be increasingly difficult", "tokens": [50974, 300, 1355, 300, 309, 486, 445, 312, 12980, 2252, 51112], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 50, "seek": 11596, "start": 130.92, "end": 135.72, "text": " to either reconstruct or to capture human-level intelligence.", "tokens": [51112, 281, 2139, 31499, 420, 281, 7983, 1952, 12, 12418, 7599, 13, 51352], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 51, "seek": 11596, "start": 135.72, "end": 137.32, "text": " And another thing that's emerging to me", "tokens": [51352, 400, 1071, 551, 300, 311, 14989, 281, 385, 51432], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 52, "seek": 11596, "start": 137.32, "end": 141.07999999999998, "text": " is that we are going to see a very distinct bifurcation", "tokens": [51432, 307, 300, 321, 366, 516, 281, 536, 257, 588, 10644, 272, 351, 374, 46252, 51620], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 53, "seek": 11596, "start": 141.07999999999998, "end": 143.85999999999999, "text": " between human intelligence and machine intelligence,", "tokens": [51620, 1296, 1952, 7599, 293, 3479, 7599, 11, 51759], "temperature": 0.0, "avg_logprob": -0.10191702356143874, "compression_ratio": 1.724, "no_speech_prob": 3.321300391689874e-05}, {"id": 54, "seek": 14386, "start": 143.86, "end": 147.14000000000001, "text": " meaning that it's gonna be kind of like comparing apples", "tokens": [50364, 3620, 300, 309, 311, 799, 312, 733, 295, 411, 15763, 16814, 50528], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 55, "seek": 14386, "start": 147.14000000000001, "end": 149.26000000000002, "text": " to oranges, and it really already is,", "tokens": [50528, 281, 35474, 11, 293, 309, 534, 1217, 307, 11, 50634], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 56, "seek": 14386, "start": 149.26000000000002, "end": 150.82000000000002, "text": " because we look at large language models", "tokens": [50634, 570, 321, 574, 412, 2416, 2856, 5245, 50712], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 57, "seek": 14386, "start": 150.82000000000002, "end": 153.5, "text": " which are very clearly processing information.", "tokens": [50712, 597, 366, 588, 4448, 9007, 1589, 13, 50846], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 58, "seek": 14386, "start": 153.5, "end": 154.82000000000002, "text": " I remember I had a conversation", "tokens": [50846, 286, 1604, 286, 632, 257, 3761, 50912], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 59, "seek": 14386, "start": 154.82000000000002, "end": 157.38000000000002, "text": " with some philosophers a year ago or so,", "tokens": [50912, 365, 512, 36839, 257, 1064, 2057, 420, 370, 11, 51040], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 60, "seek": 14386, "start": 157.38000000000002, "end": 161.06, "text": " and they made the somewhat asinine claim that,", "tokens": [51040, 293, 436, 1027, 264, 8344, 382, 259, 533, 3932, 300, 11, 51224], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 61, "seek": 14386, "start": 161.06, "end": 164.70000000000002, "text": " oh, they don't know anything, there's no information.", "tokens": [51224, 1954, 11, 436, 500, 380, 458, 1340, 11, 456, 311, 572, 1589, 13, 51406], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 62, "seek": 14386, "start": 164.70000000000002, "end": 167.16000000000003, "text": " I'm like, that's literally all that they're doing", "tokens": [51406, 286, 478, 411, 11, 300, 311, 3736, 439, 300, 436, 434, 884, 51529], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 63, "seek": 14386, "start": 167.16000000000003, "end": 169.38000000000002, "text": " is just processing information,", "tokens": [51529, 307, 445, 9007, 1589, 11, 51640], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 64, "seek": 14386, "start": 169.38000000000002, "end": 170.78000000000003, "text": " but it depends on definitions.", "tokens": [51640, 457, 309, 5946, 322, 21988, 13, 51710], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 65, "seek": 14386, "start": 170.78000000000003, "end": 172.44000000000003, "text": " And so to these philosophers,", "tokens": [51710, 400, 370, 281, 613, 36839, 11, 51793], "temperature": 0.0, "avg_logprob": -0.12602165341377258, "compression_ratio": 1.7570422535211268, "no_speech_prob": 0.0033760492224246264}, {"id": 66, "seek": 17244, "start": 172.44, "end": 173.76, "text": " the idea that this is a machine", "tokens": [50364, 264, 1558, 300, 341, 307, 257, 3479, 50430], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 67, "seek": 17244, "start": 173.76, "end": 175.32, "text": " that only processes information", "tokens": [50430, 300, 787, 7555, 1589, 50508], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 68, "seek": 17244, "start": 175.32, "end": 177.84, "text": " because their definition of information", "tokens": [50508, 570, 641, 7123, 295, 1589, 50634], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 69, "seek": 17244, "start": 177.84, "end": 179.44, "text": " was stuff in human brains.", "tokens": [50634, 390, 1507, 294, 1952, 15442, 13, 50714], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 70, "seek": 17244, "start": 179.44, "end": 180.56, "text": " I'm like, okay, well,", "tokens": [50714, 286, 478, 411, 11, 1392, 11, 731, 11, 50770], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 71, "seek": 17244, "start": 180.56, "end": 182.85999999999999, "text": " that's just a bad definition of information.", "tokens": [50770, 300, 311, 445, 257, 1578, 7123, 295, 1589, 13, 50885], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 72, "seek": 17244, "start": 182.85999999999999, "end": 184.68, "text": " Anyways, going down a rabbit hole.", "tokens": [50885, 15585, 11, 516, 760, 257, 19509, 5458, 13, 50976], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 73, "seek": 17244, "start": 184.68, "end": 186.84, "text": " My point is that it really depends", "tokens": [50976, 1222, 935, 307, 300, 309, 534, 5946, 51084], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 74, "seek": 17244, "start": 186.84, "end": 188.16, "text": " on how you look at intelligence", "tokens": [51084, 322, 577, 291, 574, 412, 7599, 51150], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 75, "seek": 17244, "start": 188.16, "end": 189.96, "text": " and how you define intelligence.", "tokens": [51150, 293, 577, 291, 6964, 7599, 13, 51240], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 76, "seek": 17244, "start": 189.96, "end": 192.04, "text": " And I really don't like those gotcha questions", "tokens": [51240, 400, 286, 534, 500, 380, 411, 729, 658, 4413, 1651, 51344], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 77, "seek": 17244, "start": 192.04, "end": 193.68, "text": " because it's like, how do you define intelligence?", "tokens": [51344, 570, 309, 311, 411, 11, 577, 360, 291, 6964, 7599, 30, 51426], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 78, "seek": 17244, "start": 193.68, "end": 196.96, "text": " And it's like, I mean, it depends on who you ask.", "tokens": [51426, 400, 309, 311, 411, 11, 286, 914, 11, 309, 5946, 322, 567, 291, 1029, 13, 51590], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 79, "seek": 17244, "start": 196.96, "end": 199.12, "text": " There's a million definitions of intelligence.", "tokens": [51590, 821, 311, 257, 2459, 21988, 295, 7599, 13, 51698], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 80, "seek": 17244, "start": 199.12, "end": 201.12, "text": " And the fact that we don't have a good definition", "tokens": [51698, 400, 264, 1186, 300, 321, 500, 380, 362, 257, 665, 7123, 51798], "temperature": 0.0, "avg_logprob": -0.10005584417604933, "compression_ratio": 1.9625850340136055, "no_speech_prob": 0.00043051724787801504}, {"id": 81, "seek": 20112, "start": 201.12, "end": 204.08, "text": " of intelligence means that also, by extension,", "tokens": [50364, 295, 7599, 1355, 300, 611, 11, 538, 10320, 11, 50512], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 82, "seek": 20112, "start": 204.08, "end": 205.24, "text": " we don't have a good definition", "tokens": [50512, 321, 500, 380, 362, 257, 665, 7123, 50570], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 83, "seek": 20112, "start": 205.24, "end": 207.12, "text": " of artificial general intelligence.", "tokens": [50570, 295, 11677, 2674, 7599, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 84, "seek": 20112, "start": 207.12, "end": 210.08, "text": " And when you ask a mathematician what intelligence is,", "tokens": [50664, 400, 562, 291, 1029, 257, 48281, 437, 7599, 307, 11, 50812], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 85, "seek": 20112, "start": 210.08, "end": 211.12, "text": " they're gonna give you one answer.", "tokens": [50812, 436, 434, 799, 976, 291, 472, 1867, 13, 50864], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 86, "seek": 20112, "start": 211.12, "end": 213.44, "text": " When you ask a neuroscientist what intelligence is,", "tokens": [50864, 1133, 291, 1029, 257, 28813, 5412, 468, 437, 7599, 307, 11, 50980], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 87, "seek": 20112, "start": 213.44, "end": 215.0, "text": " they're gonna give you a different answer.", "tokens": [50980, 436, 434, 799, 976, 291, 257, 819, 1867, 13, 51058], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 88, "seek": 20112, "start": 215.0, "end": 216.84, "text": " If you ask a psychologist and a philosopher", "tokens": [51058, 759, 291, 1029, 257, 29514, 293, 257, 29805, 51150], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 89, "seek": 20112, "start": 216.84, "end": 218.28, "text": " what intelligence is, again,", "tokens": [51150, 437, 7599, 307, 11, 797, 11, 51222], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 90, "seek": 20112, "start": 218.28, "end": 221.16, "text": " they're going to give you fundamentally different answers.", "tokens": [51222, 436, 434, 516, 281, 976, 291, 17879, 819, 6338, 13, 51366], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 91, "seek": 20112, "start": 221.16, "end": 225.24, "text": " So moving on, another thing that this is good for,", "tokens": [51366, 407, 2684, 322, 11, 1071, 551, 300, 341, 307, 665, 337, 11, 51570], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 92, "seek": 20112, "start": 225.24, "end": 226.8, "text": " and this is gonna be really good news,", "tokens": [51570, 293, 341, 307, 799, 312, 534, 665, 2583, 11, 51648], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 93, "seek": 20112, "start": 226.8, "end": 229.70000000000002, "text": " really reassuring news to many of you out there,", "tokens": [51648, 534, 19486, 1345, 2583, 281, 867, 295, 291, 484, 456, 11, 51793], "temperature": 0.0, "avg_logprob": -0.09393443927898273, "compression_ratio": 2.050359712230216, "no_speech_prob": 0.0011334633454680443}, {"id": 94, "seek": 22970, "start": 229.7, "end": 232.22, "text": " is that if AI is indeed slowing down,", "tokens": [50364, 307, 300, 498, 7318, 307, 6451, 26958, 760, 11, 50490], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 95, "seek": 22970, "start": 232.22, "end": 233.98, "text": " that means that the threat to jobs", "tokens": [50490, 300, 1355, 300, 264, 4734, 281, 4782, 50578], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 96, "seek": 22970, "start": 233.98, "end": 236.94, "text": " and the rate of change for jobs is going to be slower,", "tokens": [50578, 293, 264, 3314, 295, 1319, 337, 4782, 307, 516, 281, 312, 14009, 11, 50726], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 97, "seek": 22970, "start": 236.94, "end": 239.14, "text": " which means the status quo that we have", "tokens": [50726, 597, 1355, 264, 6558, 28425, 300, 321, 362, 50836], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 98, "seek": 22970, "start": 239.14, "end": 241.17999999999998, "text": " is going to persist a little bit longer", "tokens": [50836, 307, 516, 281, 13233, 257, 707, 857, 2854, 50938], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 99, "seek": 22970, "start": 241.17999999999998, "end": 243.11999999999998, "text": " than perhaps some of us would like.", "tokens": [50938, 813, 4317, 512, 295, 505, 576, 411, 13, 51035], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 100, "seek": 22970, "start": 243.11999999999998, "end": 244.61999999999998, "text": " Now, what I do wanna address", "tokens": [51035, 823, 11, 437, 286, 360, 1948, 2985, 51110], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 101, "seek": 22970, "start": 244.61999999999998, "end": 248.22, "text": " is that there's gonna be mixed reactions to this.", "tokens": [51110, 307, 300, 456, 311, 799, 312, 7467, 12215, 281, 341, 13, 51290], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 102, "seek": 22970, "start": 248.22, "end": 251.14, "text": " So some people are like, let's just get it done,", "tokens": [51290, 407, 512, 561, 366, 411, 11, 718, 311, 445, 483, 309, 1096, 11, 51436], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 103, "seek": 22970, "start": 251.14, "end": 254.01999999999998, "text": " like replace my job, I'm ready to get out of the workforce,", "tokens": [51436, 411, 7406, 452, 1691, 11, 286, 478, 1919, 281, 483, 484, 295, 264, 14201, 11, 51580], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 104, "seek": 22970, "start": 254.01999999999998, "end": 258.15999999999997, "text": " give me UBI and get me out of the workforce for good.", "tokens": [51580, 976, 385, 624, 11291, 293, 483, 385, 484, 295, 264, 14201, 337, 665, 13, 51787], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 105, "seek": 22970, "start": 258.15999999999997, "end": 259.09999999999997, "text": " I don't care.", "tokens": [51787, 286, 500, 380, 1127, 13, 51834], "temperature": 0.0, "avg_logprob": -0.09174648258421156, "compression_ratio": 1.7206896551724138, "no_speech_prob": 0.006691389251500368}, {"id": 106, "seek": 25910, "start": 259.14000000000004, "end": 260.42, "text": " And other people are gonna be like,", "tokens": [50366, 400, 661, 561, 366, 799, 312, 411, 11, 50430], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 107, "seek": 25910, "start": 260.42, "end": 264.18, "text": " well, this will give us time to create new jobs,", "tokens": [50430, 731, 11, 341, 486, 976, 505, 565, 281, 1884, 777, 4782, 11, 50618], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 108, "seek": 25910, "start": 264.18, "end": 266.94, "text": " I don't wanna lose my job yet, and so on and so forth.", "tokens": [50618, 286, 500, 380, 1948, 3624, 452, 1691, 1939, 11, 293, 370, 322, 293, 370, 5220, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 109, "seek": 25910, "start": 266.94, "end": 268.22, "text": " Now, if I had to guess,", "tokens": [50756, 823, 11, 498, 286, 632, 281, 2041, 11, 50820], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 110, "seek": 25910, "start": 268.22, "end": 270.58000000000004, "text": " now keep in mind that I'm speculating here,", "tokens": [50820, 586, 1066, 294, 1575, 300, 286, 478, 1608, 12162, 510, 11, 50938], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 111, "seek": 25910, "start": 270.58000000000004, "end": 273.14000000000004, "text": " and that's a lot of what I do on this channel,", "tokens": [50938, 293, 300, 311, 257, 688, 295, 437, 286, 360, 322, 341, 2269, 11, 51066], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 112, "seek": 25910, "start": 273.14000000000004, "end": 276.14000000000004, "text": " my gut check now is that it's gonna be five to 10 years.", "tokens": [51066, 452, 5228, 1520, 586, 307, 300, 309, 311, 799, 312, 1732, 281, 1266, 924, 13, 51216], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 113, "seek": 25910, "start": 276.14000000000004, "end": 277.38, "text": " And I've talked about this before", "tokens": [51216, 400, 286, 600, 2825, 466, 341, 949, 51278], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 114, "seek": 25910, "start": 277.38, "end": 279.62, "text": " where you look at the adoption curve,", "tokens": [51278, 689, 291, 574, 412, 264, 19215, 7605, 11, 51390], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 115, "seek": 25910, "start": 279.62, "end": 281.56, "text": " and it's like seven years.", "tokens": [51390, 293, 309, 311, 411, 3407, 924, 13, 51487], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 116, "seek": 25910, "start": 281.56, "end": 285.94, "text": " So maybe 2030, and 2030 seems to be a pretty sticky date.", "tokens": [51487, 407, 1310, 28638, 11, 293, 28638, 2544, 281, 312, 257, 1238, 14470, 4002, 13, 51706], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 117, "seek": 25910, "start": 285.94, "end": 289.02000000000004, "text": " So anywhere between 2027 to 2030", "tokens": [51706, 407, 4992, 1296, 945, 10076, 281, 28638, 51860], "temperature": 0.0, "avg_logprob": -0.11574732629876387, "compression_ratio": 1.6372549019607843, "no_speech_prob": 0.0006878040730953217}, {"id": 118, "seek": 28902, "start": 289.02, "end": 290.18, "text": " is when we might start seeing", "tokens": [50364, 307, 562, 321, 1062, 722, 2577, 50422], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 119, "seek": 28902, "start": 290.18, "end": 292.14, "text": " some really drastic change out there.", "tokens": [50422, 512, 534, 36821, 1319, 484, 456, 13, 50520], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 120, "seek": 28902, "start": 292.14, "end": 293.5, "text": " Now, I could be wrong,", "tokens": [50520, 823, 11, 286, 727, 312, 2085, 11, 50588], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 121, "seek": 28902, "start": 293.5, "end": 296.34, "text": " we could have a confluence of multiple technologies,", "tokens": [50588, 321, 727, 362, 257, 1497, 40432, 295, 3866, 7943, 11, 50730], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 122, "seek": 28902, "start": 296.34, "end": 299.02, "text": " like again, I'm really waiting to see", "tokens": [50730, 411, 797, 11, 286, 478, 534, 3806, 281, 536, 50864], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 123, "seek": 28902, "start": 299.02, "end": 301.7, "text": " how GPT-5 and robotics mix,", "tokens": [50864, 577, 26039, 51, 12, 20, 293, 34145, 2890, 11, 50998], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 124, "seek": 28902, "start": 301.7, "end": 304.62, "text": " because you see the number of bipedal,", "tokens": [50998, 570, 291, 536, 264, 1230, 295, 19016, 292, 304, 11, 51144], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 125, "seek": 28902, "start": 304.62, "end": 307.7, "text": " like humanoid robotic chassis being built around the world.", "tokens": [51144, 411, 1952, 17079, 30468, 28262, 885, 3094, 926, 264, 1002, 13, 51298], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 126, "seek": 28902, "start": 307.7, "end": 311.02, "text": " And like, remember, this is only gen one.", "tokens": [51298, 400, 411, 11, 1604, 11, 341, 307, 787, 1049, 472, 13, 51464], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 127, "seek": 28902, "start": 311.02, "end": 315.46, "text": " So GPT-5 and Claude Four and whatever else,", "tokens": [51464, 407, 26039, 51, 12, 20, 293, 12947, 2303, 7451, 293, 2035, 1646, 11, 51686], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 128, "seek": 28902, "start": 315.46, "end": 318.21999999999997, "text": " you combine that level of intelligence with robots,", "tokens": [51686, 291, 10432, 300, 1496, 295, 7599, 365, 14733, 11, 51824], "temperature": 0.0, "avg_logprob": -0.13051461416577537, "compression_ratio": 1.5871886120996441, "no_speech_prob": 0.001500951126217842}, {"id": 129, "seek": 31822, "start": 318.22, "end": 321.58000000000004, "text": " that really could change a lot for a lot of things.", "tokens": [50364, 300, 534, 727, 1319, 257, 688, 337, 257, 688, 295, 721, 13, 50532], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 130, "seek": 31822, "start": 321.58000000000004, "end": 322.5, "text": " And I think there's,", "tokens": [50532, 400, 286, 519, 456, 311, 11, 50578], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 131, "seek": 31822, "start": 322.5, "end": 325.34000000000003, "text": " I don't know if it's proven out or to what extent,", "tokens": [50578, 286, 500, 380, 458, 498, 309, 311, 12785, 484, 420, 281, 437, 8396, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 132, "seek": 31822, "start": 325.34000000000003, "end": 328.3, "text": " but I've heard that Tesla is already using their robots", "tokens": [50720, 457, 286, 600, 2198, 300, 13666, 307, 1217, 1228, 641, 14733, 50868], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 133, "seek": 31822, "start": 328.3, "end": 330.06, "text": " in the Tesla factories.", "tokens": [50868, 294, 264, 13666, 24813, 13, 50956], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 134, "seek": 31822, "start": 330.06, "end": 333.58000000000004, "text": " And the economic carrot for that is really high.", "tokens": [50956, 400, 264, 4836, 22767, 337, 300, 307, 534, 1090, 13, 51132], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 135, "seek": 31822, "start": 333.58000000000004, "end": 338.42, "text": " So don't underestimate the power of that economic incentive", "tokens": [51132, 407, 500, 380, 35826, 264, 1347, 295, 300, 4836, 22346, 51374], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 136, "seek": 31822, "start": 338.42, "end": 341.28000000000003, "text": " to get things really going.", "tokens": [51374, 281, 483, 721, 534, 516, 13, 51517], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 137, "seek": 31822, "start": 341.28000000000003, "end": 345.1, "text": " But overall, if the advancement of AI intelligence", "tokens": [51517, 583, 4787, 11, 498, 264, 35764, 295, 7318, 7599, 51708], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 138, "seek": 31822, "start": 345.1, "end": 346.5, "text": " is indeed slowing down,", "tokens": [51708, 307, 6451, 26958, 760, 11, 51778], "temperature": 0.0, "avg_logprob": -0.1053128329190341, "compression_ratio": 1.66, "no_speech_prob": 0.0002868305891752243}, {"id": 139, "seek": 34650, "start": 346.54, "end": 348.78, "text": " it just gives us all more time to adapt", "tokens": [50366, 309, 445, 2709, 505, 439, 544, 565, 281, 6231, 50478], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 140, "seek": 34650, "start": 348.78, "end": 352.06, "text": " on a cybersecurity level, on an economic level,", "tokens": [50478, 322, 257, 38765, 1496, 11, 322, 364, 4836, 1496, 11, 50642], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 141, "seek": 34650, "start": 352.06, "end": 353.58, "text": " on a military level.", "tokens": [50642, 322, 257, 4632, 1496, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 142, "seek": 34650, "start": 353.58, "end": 354.68, "text": " So it means that, you know,", "tokens": [50718, 407, 309, 1355, 300, 11, 291, 458, 11, 50773], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 143, "seek": 34650, "start": 354.68, "end": 359.68, "text": " your life is not gonna get upended soon, hopefully.", "tokens": [50773, 428, 993, 307, 406, 799, 483, 493, 3502, 2321, 11, 4696, 13, 51023], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 144, "seek": 34650, "start": 360.46, "end": 363.34, "text": " So this leads me to want to address another thing.", "tokens": [51062, 407, 341, 6689, 385, 281, 528, 281, 2985, 1071, 551, 13, 51206], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 145, "seek": 34650, "start": 364.74, "end": 367.1, "text": " About what, 12 months ago, a little bit more,", "tokens": [51276, 7769, 437, 11, 2272, 2493, 2057, 11, 257, 707, 857, 544, 11, 51394], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 146, "seek": 34650, "start": 367.1, "end": 370.7, "text": " I predicted that we would have AGI by September 2024.", "tokens": [51394, 286, 19147, 300, 321, 576, 362, 316, 26252, 538, 7216, 45237, 13, 51574], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 147, "seek": 34650, "start": 370.7, "end": 372.82, "text": " So that's just a few months from now.", "tokens": [51574, 407, 300, 311, 445, 257, 1326, 2493, 490, 586, 13, 51680], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 148, "seek": 34650, "start": 372.82, "end": 375.06, "text": " Now, what I was looking at at the time,", "tokens": [51680, 823, 11, 437, 286, 390, 1237, 412, 412, 264, 565, 11, 51792], "temperature": 0.0, "avg_logprob": -0.1181843788897405, "compression_ratio": 1.5559701492537314, "no_speech_prob": 0.0008558121626265347}, {"id": 149, "seek": 37506, "start": 375.06, "end": 377.06, "text": " and, you know, if you go back and watch my videos,", "tokens": [50364, 293, 11, 291, 458, 11, 498, 291, 352, 646, 293, 1159, 452, 2145, 11, 50464], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 150, "seek": 37506, "start": 377.06, "end": 378.58, "text": " there's a whole bunch of charts and data", "tokens": [50464, 456, 311, 257, 1379, 3840, 295, 17767, 293, 1412, 50540], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 151, "seek": 37506, "start": 378.58, "end": 380.02, "text": " that I was looking at.", "tokens": [50540, 300, 286, 390, 1237, 412, 13, 50612], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 152, "seek": 37506, "start": 380.02, "end": 383.54, "text": " And this is right along the curve", "tokens": [50612, 400, 341, 307, 558, 2051, 264, 7605, 50788], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 153, "seek": 37506, "start": 383.54, "end": 386.7, "text": " of what Ray Kurzweil originally proposed,", "tokens": [50788, 295, 437, 10883, 45307, 826, 388, 7993, 10348, 11, 50946], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 154, "seek": 37506, "start": 386.7, "end": 389.86, "text": " is to when we would have a human level, you know,", "tokens": [50946, 307, 281, 562, 321, 576, 362, 257, 1952, 1496, 11, 291, 458, 11, 51104], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 155, "seek": 37506, "start": 389.86, "end": 393.04, "text": " intelligence in a single computer is actually 2023.", "tokens": [51104, 7599, 294, 257, 2167, 3820, 307, 767, 44377, 13, 51263], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 156, "seek": 37506, "start": 393.04, "end": 394.82, "text": " So that was one piece of data.", "tokens": [51263, 407, 300, 390, 472, 2522, 295, 1412, 13, 51352], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 157, "seek": 37506, "start": 394.82, "end": 397.38, "text": " I was also looking at parameter counts going up,", "tokens": [51352, 286, 390, 611, 1237, 412, 13075, 14893, 516, 493, 11, 51480], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 158, "seek": 37506, "start": 397.38, "end": 401.14, "text": " logarithmically, which they have been,", "tokens": [51480, 41473, 32674, 984, 11, 597, 436, 362, 668, 11, 51668], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 159, "seek": 37506, "start": 401.14, "end": 402.18, "text": " but they've slowed down.", "tokens": [51668, 457, 436, 600, 32057, 760, 13, 51720], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 160, "seek": 37506, "start": 402.18, "end": 404.3, "text": " And the one thing that I was not looking at,", "tokens": [51720, 400, 264, 472, 551, 300, 286, 390, 406, 1237, 412, 11, 51826], "temperature": 0.0, "avg_logprob": -0.12468187652365134, "compression_ratio": 1.6529209621993126, "no_speech_prob": 0.0010004002833738923}, {"id": 161, "seek": 40430, "start": 404.3, "end": 406.62, "text": " so this is the piece of data that I did not include", "tokens": [50364, 370, 341, 307, 264, 2522, 295, 1412, 300, 286, 630, 406, 4090, 50480], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 162, "seek": 40430, "start": 406.62, "end": 408.34000000000003, "text": " in all of those calculations,", "tokens": [50480, 294, 439, 295, 729, 20448, 11, 50566], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 163, "seek": 40430, "start": 408.34000000000003, "end": 410.86, "text": " was the exponentially rising costs", "tokens": [50566, 390, 264, 37330, 11636, 5497, 50692], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 164, "seek": 40430, "start": 410.86, "end": 413.66, "text": " of training subsequent generations of models.", "tokens": [50692, 295, 3097, 19962, 10593, 295, 5245, 13, 50832], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 165, "seek": 40430, "start": 413.66, "end": 417.1, "text": " So, you know, as, I think it was Dimitris Abbas", "tokens": [50832, 407, 11, 291, 458, 11, 382, 11, 286, 519, 309, 390, 20975, 270, 5714, 2847, 16342, 51004], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 166, "seek": 40430, "start": 417.1, "end": 419.46000000000004, "text": " was talking about on a podcast recently,", "tokens": [51004, 390, 1417, 466, 322, 257, 7367, 3938, 11, 51122], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 167, "seek": 40430, "start": 419.46000000000004, "end": 423.18, "text": " every subsequent generation from GPT-2 to 3 to 4", "tokens": [51122, 633, 19962, 5125, 490, 26039, 51, 12, 17, 281, 805, 281, 1017, 51308], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 168, "seek": 40430, "start": 423.18, "end": 427.54, "text": " costs 10 times as much to train, if not more.", "tokens": [51308, 5497, 1266, 1413, 382, 709, 281, 3847, 11, 498, 406, 544, 13, 51526], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 169, "seek": 40430, "start": 427.54, "end": 429.54, "text": " So while all these other things", "tokens": [51526, 407, 1339, 439, 613, 661, 721, 51626], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 170, "seek": 40430, "start": 429.54, "end": 432.02, "text": " are going up exponentially, so is cost.", "tokens": [51626, 366, 516, 493, 37330, 11, 370, 307, 2063, 13, 51750], "temperature": 0.0, "avg_logprob": -0.149725806194803, "compression_ratio": 1.6076923076923078, "no_speech_prob": 0.00011959240509895608}, {"id": 171, "seek": 43202, "start": 432.02, "end": 434.78, "text": " And that did not figure into my calculus.", "tokens": [50364, 400, 300, 630, 406, 2573, 666, 452, 33400, 13, 50502], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 172, "seek": 43202, "start": 434.78, "end": 437.14, "text": " And so because of that, it's like, oh, well,", "tokens": [50502, 400, 370, 570, 295, 300, 11, 309, 311, 411, 11, 1954, 11, 731, 11, 50620], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 173, "seek": 43202, "start": 437.14, "end": 440.29999999999995, "text": " if I had thing, you know, recognize that,", "tokens": [50620, 498, 286, 632, 551, 11, 291, 458, 11, 5521, 300, 11, 50778], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 174, "seek": 43202, "start": 440.29999999999995, "end": 442.18, "text": " I might have said, well, we're probably gonna get", "tokens": [50778, 286, 1062, 362, 848, 11, 731, 11, 321, 434, 1391, 799, 483, 50872], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 175, "seek": 43202, "start": 442.18, "end": 444.5, "text": " diminishing returns sooner rather than later.", "tokens": [50872, 15739, 3807, 11247, 15324, 2831, 813, 1780, 13, 50988], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 176, "seek": 43202, "start": 444.5, "end": 447.5, "text": " Now I have been talking about diminishing returns", "tokens": [50988, 823, 286, 362, 668, 1417, 466, 15739, 3807, 11247, 51138], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 177, "seek": 43202, "start": 447.5, "end": 449.34, "text": " pretty much for the life of this channel.", "tokens": [51138, 1238, 709, 337, 264, 993, 295, 341, 2269, 13, 51230], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 178, "seek": 43202, "start": 449.34, "end": 452.65999999999997, "text": " And I've been wondering, when is the jig gonna be up?", "tokens": [51230, 400, 286, 600, 668, 6359, 11, 562, 307, 264, 43716, 799, 312, 493, 30, 51396], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 179, "seek": 43202, "start": 452.65999999999997, "end": 454.53999999999996, "text": " When are we gonna run out of steam here?", "tokens": [51396, 1133, 366, 321, 799, 1190, 484, 295, 11952, 510, 30, 51490], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 180, "seek": 43202, "start": 454.53999999999996, "end": 457.09999999999997, "text": " And it looks like we're starting to run out of steam.", "tokens": [51490, 400, 309, 1542, 411, 321, 434, 2891, 281, 1190, 484, 295, 11952, 13, 51618], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 181, "seek": 43202, "start": 457.09999999999997, "end": 459.7, "text": " Now again, you know, the train is still running,", "tokens": [51618, 823, 797, 11, 291, 458, 11, 264, 3847, 307, 920, 2614, 11, 51748], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 182, "seek": 43202, "start": 459.7, "end": 461.9, "text": " we're still burning pretty hot,", "tokens": [51748, 321, 434, 920, 9488, 1238, 2368, 11, 51858], "temperature": 0.0, "avg_logprob": -0.12548201424734934, "compression_ratio": 1.801980198019802, "no_speech_prob": 0.010985742323100567}, {"id": 183, "seek": 46190, "start": 462.78, "end": 464.26, "text": " but we're not accelerating anymore.", "tokens": [50408, 457, 321, 434, 406, 34391, 3602, 13, 50482], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 184, "seek": 46190, "start": 464.26, "end": 468.94, "text": " We are probably on a more geometric trajectory right now", "tokens": [50482, 492, 366, 1391, 322, 257, 544, 33246, 21512, 558, 586, 50716], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 185, "seek": 46190, "start": 468.94, "end": 470.17999999999995, "text": " if I had to guess.", "tokens": [50716, 498, 286, 632, 281, 2041, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 186, "seek": 46190, "start": 471.17999999999995, "end": 473.09999999999997, "text": " And it all comes down to economics.", "tokens": [50828, 400, 309, 439, 1487, 760, 281, 14564, 13, 50924], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 187, "seek": 46190, "start": 473.09999999999997, "end": 476.82, "text": " It really is just with exponentially rising costs", "tokens": [50924, 467, 534, 307, 445, 365, 37330, 11636, 5497, 51110], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 188, "seek": 46190, "start": 476.82, "end": 480.41999999999996, "text": " with a, we're entering into what's called a red ocean market,", "tokens": [51110, 365, 257, 11, 321, 434, 11104, 666, 437, 311, 1219, 257, 2182, 7810, 2142, 11, 51290], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 189, "seek": 46190, "start": 480.41999999999996, "end": 482.78, "text": " which means it's not just, you know, a blue ocean", "tokens": [51290, 597, 1355, 309, 311, 406, 445, 11, 291, 458, 11, 257, 3344, 7810, 51408], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 190, "seek": 46190, "start": 482.78, "end": 487.06, "text": " out there with its just open AI with their frontier model.", "tokens": [51408, 484, 456, 365, 1080, 445, 1269, 7318, 365, 641, 35853, 2316, 13, 51622], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 191, "seek": 46190, "start": 487.06, "end": 490.9, "text": " Lots of other models have caught up to GPT-4O,", "tokens": [51622, 15908, 295, 661, 5245, 362, 5415, 493, 281, 26039, 51, 12, 19, 46, 11, 51814], "temperature": 0.0, "avg_logprob": -0.1648308576735775, "compression_ratio": 1.554307116104869, "no_speech_prob": 0.0006666210247203708}, {"id": 192, "seek": 49090, "start": 490.94, "end": 493.7, "text": " Claude 3.5 Sonnet has clearly surpassed it", "tokens": [50366, 12947, 2303, 805, 13, 20, 5185, 7129, 575, 4448, 27650, 292, 309, 50504], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 193, "seek": 49090, "start": 493.7, "end": 494.97999999999996, "text": " as far as I can tell.", "tokens": [50504, 382, 1400, 382, 286, 393, 980, 13, 50568], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 194, "seek": 49090, "start": 494.97999999999996, "end": 497.14, "text": " Obviously people like looking at a,", "tokens": [50568, 7580, 561, 411, 1237, 412, 257, 11, 50676], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 195, "seek": 49090, "start": 497.14, "end": 499.26, "text": " whatever that benchmark is called,", "tokens": [50676, 2035, 300, 18927, 307, 1219, 11, 50782], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 196, "seek": 49090, "start": 499.26, "end": 501.14, "text": " I don't really give that much weight because it's,", "tokens": [50782, 286, 500, 380, 534, 976, 300, 709, 3364, 570, 309, 311, 11, 50876], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 197, "seek": 49090, "start": 501.14, "end": 503.62, "text": " that seems like it's mostly a popularity contest", "tokens": [50876, 300, 2544, 411, 309, 311, 5240, 257, 19301, 10287, 51000], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 198, "seek": 49090, "start": 503.62, "end": 506.85999999999996, "text": " and open AI still has a lot of fanboys,", "tokens": [51000, 293, 1269, 7318, 920, 575, 257, 688, 295, 3429, 31638, 11, 51162], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 199, "seek": 49090, "start": 506.85999999999996, "end": 509.64, "text": " but doing a side-by-side comparison of capability", "tokens": [51162, 457, 884, 257, 1252, 12, 2322, 12, 1812, 9660, 295, 13759, 51301], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 200, "seek": 49090, "start": 509.64, "end": 512.9, "text": " between chat GPT-4O and Claude 3.5,", "tokens": [51301, 1296, 5081, 26039, 51, 12, 19, 46, 293, 12947, 2303, 805, 13, 20, 11, 51464], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 201, "seek": 49090, "start": 512.9, "end": 517.1, "text": " it is hands down Claude 3.5 is in another league", "tokens": [51464, 309, 307, 2377, 760, 12947, 2303, 805, 13, 20, 307, 294, 1071, 14957, 51674], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 202, "seek": 49090, "start": 517.1, "end": 518.14, "text": " as far as I can tell.", "tokens": [51674, 382, 1400, 382, 286, 393, 980, 13, 51726], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 203, "seek": 49090, "start": 518.14, "end": 519.5799999999999, "text": " Now obviously a lot of you out there", "tokens": [51726, 823, 2745, 257, 688, 295, 291, 484, 456, 51798], "temperature": 0.0, "avg_logprob": -0.12750085417207305, "compression_ratio": 1.6284722222222223, "no_speech_prob": 0.002550593577325344}, {"id": 204, "seek": 51958, "start": 519.58, "end": 521.0600000000001, "text": " use it for different things.", "tokens": [50364, 764, 309, 337, 819, 721, 13, 50438], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 205, "seek": 51958, "start": 521.0600000000001, "end": 523.4200000000001, "text": " So, you know, it is gonna,", "tokens": [50438, 407, 11, 291, 458, 11, 309, 307, 799, 11, 50556], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 206, "seek": 51958, "start": 523.4200000000001, "end": 525.98, "text": " it's gonna depend on your use case.", "tokens": [50556, 309, 311, 799, 5672, 322, 428, 764, 1389, 13, 50684], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 207, "seek": 51958, "start": 525.98, "end": 527.46, "text": " Another thing that I've noticed is that", "tokens": [50684, 3996, 551, 300, 286, 600, 5694, 307, 300, 50758], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 208, "seek": 51958, "start": 527.46, "end": 529.1800000000001, "text": " there's been fewer breakthroughs.", "tokens": [50758, 456, 311, 668, 13366, 22397, 82, 13, 50844], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 209, "seek": 51958, "start": 529.1800000000001, "end": 533.26, "text": " So like, yes, chat GPT-4O has the voice mode,", "tokens": [50844, 407, 411, 11, 2086, 11, 5081, 26039, 51, 12, 19, 46, 575, 264, 3177, 4391, 11, 51048], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 210, "seek": 51958, "start": 533.26, "end": 535.38, "text": " which is really, you know, okay, cool,", "tokens": [51048, 597, 307, 534, 11, 291, 458, 11, 1392, 11, 1627, 11, 51154], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 211, "seek": 51958, "start": 535.38, "end": 537.86, "text": " like it can do a sultry voice and sound effects,", "tokens": [51154, 411, 309, 393, 360, 257, 262, 723, 627, 3177, 293, 1626, 5065, 11, 51278], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 212, "seek": 51958, "start": 537.86, "end": 539.1, "text": " which is great.", "tokens": [51278, 597, 307, 869, 13, 51340], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 213, "seek": 51958, "start": 539.1, "end": 543.26, "text": " But that was a predictable addition with multimodality,", "tokens": [51340, 583, 300, 390, 257, 27737, 4500, 365, 32972, 378, 1860, 11, 51548], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 214, "seek": 51958, "start": 543.26, "end": 546.46, "text": " where it's like, okay, text and audio, great.", "tokens": [51548, 689, 309, 311, 411, 11, 1392, 11, 2487, 293, 6278, 11, 869, 13, 51708], "temperature": 0.0, "avg_logprob": -0.12723172893960968, "compression_ratio": 1.622568093385214, "no_speech_prob": 0.00572909926995635}, {"id": 215, "seek": 54646, "start": 546.46, "end": 550.58, "text": " This is still leaving a huge swath of economic interests", "tokens": [50364, 639, 307, 920, 5012, 257, 2603, 1693, 998, 295, 4836, 8847, 50570], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 216, "seek": 54646, "start": 550.58, "end": 553.38, "text": " and intellectual interests completely untouched.", "tokens": [50570, 293, 12576, 8847, 2584, 1701, 36740, 13, 50710], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 217, "seek": 54646, "start": 554.5, "end": 555.58, "text": " Take math for instance,", "tokens": [50766, 3664, 5221, 337, 5197, 11, 50820], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 218, "seek": 54646, "start": 555.58, "end": 557.5, "text": " they still haven't figured out math and physics", "tokens": [50820, 436, 920, 2378, 380, 8932, 484, 5221, 293, 10649, 50916], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 219, "seek": 54646, "start": 557.5, "end": 558.88, "text": " and those sorts of things.", "tokens": [50916, 293, 729, 7527, 295, 721, 13, 50985], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 220, "seek": 54646, "start": 558.88, "end": 563.88, "text": " And also after playing around with the ARC AGI test,", "tokens": [50985, 400, 611, 934, 2433, 926, 365, 264, 8943, 34, 316, 26252, 1500, 11, 51235], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 221, "seek": 54646, "start": 564.5400000000001, "end": 568.0600000000001, "text": " yes, I have not been a fan of the ARC AGI test,", "tokens": [51268, 2086, 11, 286, 362, 406, 668, 257, 3429, 295, 264, 8943, 34, 316, 26252, 1500, 11, 51444], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 222, "seek": 54646, "start": 568.0600000000001, "end": 570.9000000000001, "text": " but at the same time, like it does prove a point.", "tokens": [51444, 457, 412, 264, 912, 565, 11, 411, 309, 775, 7081, 257, 935, 13, 51586], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 223, "seek": 54646, "start": 570.9000000000001, "end": 573.2800000000001, "text": " It does prove a point that the kind of reasoning", "tokens": [51586, 467, 775, 7081, 257, 935, 300, 264, 733, 295, 21577, 51705], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 224, "seek": 54646, "start": 573.2800000000001, "end": 575.44, "text": " that these things do is still very different", "tokens": [51705, 300, 613, 721, 360, 307, 920, 588, 819, 51813], "temperature": 0.0, "avg_logprob": -0.13190433979034424, "compression_ratio": 1.7007575757575757, "no_speech_prob": 0.0010321601293981075}, {"id": 225, "seek": 57544, "start": 575.44, "end": 576.6600000000001, "text": " from human reasoning,", "tokens": [50364, 490, 1952, 21577, 11, 50425], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 226, "seek": 57544, "start": 576.6600000000001, "end": 578.2, "text": " which is another reason that I'm talking about", "tokens": [50425, 597, 307, 1071, 1778, 300, 286, 478, 1417, 466, 50502], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 227, "seek": 57544, "start": 578.2, "end": 580.2, "text": " a bifurcation of intelligence.", "tokens": [50502, 257, 272, 351, 374, 46252, 295, 7599, 13, 50602], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 228, "seek": 57544, "start": 580.2, "end": 581.96, "text": " That we might be, and this is again,", "tokens": [50602, 663, 321, 1062, 312, 11, 293, 341, 307, 797, 11, 50690], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 229, "seek": 57544, "start": 581.96, "end": 583.9000000000001, "text": " as pure speculation on my point,", "tokens": [50690, 382, 6075, 27696, 322, 452, 935, 11, 50787], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 230, "seek": 57544, "start": 583.9000000000001, "end": 586.84, "text": " we might be getting to a point where", "tokens": [50787, 321, 1062, 312, 1242, 281, 257, 935, 689, 50934], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 231, "seek": 57544, "start": 586.84, "end": 589.24, "text": " we're starting to recognize, okay,", "tokens": [50934, 321, 434, 2891, 281, 5521, 11, 1392, 11, 51054], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 232, "seek": 57544, "start": 589.24, "end": 591.72, "text": " this machine is kind of an alien intelligence.", "tokens": [51054, 341, 3479, 307, 733, 295, 364, 12319, 7599, 13, 51178], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 233, "seek": 57544, "start": 591.72, "end": 594.32, "text": " It clearly has its own consistent way", "tokens": [51178, 467, 4448, 575, 1080, 1065, 8398, 636, 51308], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 234, "seek": 57544, "start": 594.32, "end": 595.86, "text": " of approaching the world,", "tokens": [51308, 295, 14908, 264, 1002, 11, 51385], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 235, "seek": 57544, "start": 595.86, "end": 597.98, "text": " but it is also very different from us.", "tokens": [51385, 457, 309, 307, 611, 588, 819, 490, 505, 13, 51491], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 236, "seek": 57544, "start": 597.98, "end": 600.22, "text": " Now, Bill Gates was on a podcast recently saying", "tokens": [51491, 823, 11, 5477, 26494, 390, 322, 257, 7367, 3938, 1566, 51603], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 237, "seek": 57544, "start": 600.22, "end": 602.8000000000001, "text": " that metacognition is gonna be the next step.", "tokens": [51603, 300, 1131, 326, 2912, 849, 307, 799, 312, 264, 958, 1823, 13, 51732], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 238, "seek": 57544, "start": 602.8000000000001, "end": 604.84, "text": " Okay, sure, I mean, I've been working on cognitive", "tokens": [51732, 1033, 11, 988, 11, 286, 914, 11, 286, 600, 668, 1364, 322, 15605, 51834], "temperature": 0.0, "avg_logprob": -0.15771061942081324, "compression_ratio": 1.678125, "no_speech_prob": 0.005727831274271011}, {"id": 239, "seek": 60484, "start": 604.88, "end": 606.4, "text": " architectures for a while,", "tokens": [50366, 6331, 1303, 337, 257, 1339, 11, 50442], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 240, "seek": 60484, "start": 606.4, "end": 608.0, "text": " and there are some really sharp people out there", "tokens": [50442, 293, 456, 366, 512, 534, 8199, 561, 484, 456, 50522], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 241, "seek": 60484, "start": 608.0, "end": 610.84, "text": " that figured out how to give models metacognition", "tokens": [50522, 300, 8932, 484, 577, 281, 976, 5245, 1131, 326, 2912, 849, 50664], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 242, "seek": 60484, "start": 610.84, "end": 613.12, "text": " a while ago, it's really just down to prompting.", "tokens": [50664, 257, 1339, 2057, 11, 309, 311, 534, 445, 760, 281, 12391, 278, 13, 50778], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 243, "seek": 60484, "start": 614.48, "end": 616.24, "text": " You can give, for instance,", "tokens": [50846, 509, 393, 976, 11, 337, 5197, 11, 50934], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 244, "seek": 60484, "start": 616.24, "end": 618.52, "text": " especially with these gigantic context windows,", "tokens": [50934, 2318, 365, 613, 26800, 4319, 9309, 11, 51048], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 245, "seek": 60484, "start": 618.52, "end": 621.32, "text": " you can give one sec, one model say,", "tokens": [51048, 291, 393, 976, 472, 907, 11, 472, 2316, 584, 11, 51188], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 246, "seek": 60484, "start": 621.32, "end": 623.72, "text": " hey, you're a metacognitive agent", "tokens": [51188, 4177, 11, 291, 434, 257, 1131, 326, 2912, 2187, 9461, 51308], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 247, "seek": 60484, "start": 623.72, "end": 625.36, "text": " that's viewing these other thoughts.", "tokens": [51308, 300, 311, 17480, 613, 661, 4598, 13, 51390], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 248, "seek": 60484, "start": 625.36, "end": 626.76, "text": " Tell us what you think about it.", "tokens": [51390, 5115, 505, 437, 291, 519, 466, 309, 13, 51460], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 249, "seek": 60484, "start": 626.76, "end": 628.36, "text": " Help steer it on moral course.", "tokens": [51460, 10773, 30814, 309, 322, 9723, 1164, 13, 51540], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 250, "seek": 60484, "start": 628.36, "end": 631.0400000000001, "text": " This was entirely all of my work on the ACE framework,", "tokens": [51540, 639, 390, 7696, 439, 295, 452, 589, 322, 264, 44606, 8388, 11, 51674], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 251, "seek": 60484, "start": 631.0400000000001, "end": 633.6, "text": " the autonomous cognitive entity framework,", "tokens": [51674, 264, 23797, 15605, 13977, 8388, 11, 51802], "temperature": 0.0, "avg_logprob": -0.1414618120125845, "compression_ratio": 1.7105263157894737, "no_speech_prob": 0.008844356052577496}, {"id": 252, "seek": 63360, "start": 633.6, "end": 636.2, "text": " which I did abandon because Microsoft Autogen", "tokens": [50364, 597, 286, 630, 9072, 570, 8116, 6049, 8799, 50494], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 253, "seek": 63360, "start": 636.2, "end": 640.2, "text": " and other platforms far surpassed what I could do", "tokens": [50494, 293, 661, 9473, 1400, 27650, 292, 437, 286, 727, 360, 50694], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 254, "seek": 63360, "start": 640.2, "end": 643.44, "text": " on my own, even with help from people on the internet,", "tokens": [50694, 322, 452, 1065, 11, 754, 365, 854, 490, 561, 322, 264, 4705, 11, 50856], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 255, "seek": 63360, "start": 643.44, "end": 644.4, "text": " because why it's Microsoft,", "tokens": [50856, 570, 983, 309, 311, 8116, 11, 50904], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 256, "seek": 63360, "start": 644.4, "end": 646.6, "text": " and they have a lot more money than I do.", "tokens": [50904, 293, 436, 362, 257, 688, 544, 1460, 813, 286, 360, 13, 51014], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 257, "seek": 63360, "start": 647.5600000000001, "end": 649.9200000000001, "text": " Now, that leads me to another point that I wanna address,", "tokens": [51062, 823, 11, 300, 6689, 385, 281, 1071, 935, 300, 286, 1948, 2985, 11, 51180], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 258, "seek": 63360, "start": 649.9200000000001, "end": 651.4, "text": " and that is echo chambers.", "tokens": [51180, 293, 300, 307, 14300, 34513, 13, 51254], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 259, "seek": 63360, "start": 651.4, "end": 653.72, "text": " So most of you in the audience,", "tokens": [51254, 407, 881, 295, 291, 294, 264, 4034, 11, 51370], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 260, "seek": 63360, "start": 653.72, "end": 655.72, "text": " based on the polls that I've run,", "tokens": [51370, 2361, 322, 264, 24264, 300, 286, 600, 1190, 11, 51470], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 261, "seek": 63360, "start": 655.72, "end": 657.72, "text": " most of you in the audience, statistically speaking,", "tokens": [51470, 881, 295, 291, 294, 264, 4034, 11, 36478, 4124, 11, 51570], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 262, "seek": 63360, "start": 657.72, "end": 659.12, "text": " are kind of in the middle of the bell curve", "tokens": [51570, 366, 733, 295, 294, 264, 2808, 295, 264, 4549, 7605, 51640], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 263, "seek": 63360, "start": 659.12, "end": 661.28, "text": " where you're reasonable and you want the truth,", "tokens": [51640, 689, 291, 434, 10585, 293, 291, 528, 264, 3494, 11, 51748], "temperature": 0.0, "avg_logprob": -0.14316181455339705, "compression_ratio": 1.7432432432432432, "no_speech_prob": 0.0004305294423829764}, {"id": 264, "seek": 66128, "start": 661.28, "end": 664.04, "text": " and you want some honest, genuine thoughts.", "tokens": [50364, 293, 291, 528, 512, 3245, 11, 16699, 4598, 13, 50502], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 265, "seek": 66128, "start": 664.04, "end": 666.1999999999999, "text": " There are, however, many people out there", "tokens": [50502, 821, 366, 11, 4461, 11, 867, 561, 484, 456, 50610], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 266, "seek": 66128, "start": 666.1999999999999, "end": 668.4399999999999, "text": " that are on more of the tail,", "tokens": [50610, 300, 366, 322, 544, 295, 264, 6838, 11, 50722], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 267, "seek": 66128, "start": 668.4399999999999, "end": 670.48, "text": " like left to right tail of the bell curve,", "tokens": [50722, 411, 1411, 281, 558, 6838, 295, 264, 4549, 7605, 11, 50824], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 268, "seek": 66128, "start": 670.48, "end": 674.76, "text": " where you wanna see doom or you wanna see acceleration,", "tokens": [50824, 689, 291, 1948, 536, 37131, 420, 291, 1948, 536, 17162, 11, 51038], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 269, "seek": 66128, "start": 674.76, "end": 678.48, "text": " and you're not really interested in other narratives.", "tokens": [51038, 293, 291, 434, 406, 534, 3102, 294, 661, 28016, 13, 51224], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 270, "seek": 66128, "start": 678.48, "end": 680.9599999999999, "text": " And the reason that I'm using the word echo chamber,", "tokens": [51224, 400, 264, 1778, 300, 286, 478, 1228, 264, 1349, 14300, 13610, 11, 51348], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 271, "seek": 66128, "start": 680.9599999999999, "end": 683.92, "text": " which is often pathologized,", "tokens": [51348, 597, 307, 2049, 3100, 1132, 1602, 11, 51496], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 272, "seek": 66128, "start": 683.92, "end": 686.76, "text": " is because there have actually been a few people", "tokens": [51496, 307, 570, 456, 362, 767, 668, 257, 1326, 561, 51638], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 273, "seek": 66128, "start": 686.76, "end": 689.16, "text": " that did directly express to me", "tokens": [51638, 300, 630, 3838, 5109, 281, 385, 51758], "temperature": 0.0, "avg_logprob": -0.13669738938323164, "compression_ratio": 1.6576923076923078, "no_speech_prob": 0.0012841306161135435}, {"id": 274, "seek": 68916, "start": 689.16, "end": 691.36, "text": " they did not want an alternative narrative.", "tokens": [50364, 436, 630, 406, 528, 364, 8535, 9977, 13, 50474], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 275, "seek": 68916, "start": 691.36, "end": 695.4, "text": " They only wanted to double down on their personal narrative,", "tokens": [50474, 814, 787, 1415, 281, 3834, 760, 322, 641, 2973, 9977, 11, 50676], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 276, "seek": 68916, "start": 695.4, "end": 697.4399999999999, "text": " the one that they want to be true,", "tokens": [50676, 264, 472, 300, 436, 528, 281, 312, 2074, 11, 50778], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 277, "seek": 68916, "start": 697.4399999999999, "end": 698.92, "text": " which, believe me,", "tokens": [50778, 597, 11, 1697, 385, 11, 50852], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 278, "seek": 68916, "start": 698.92, "end": 701.88, "text": " I want to have all kinds of advancements", "tokens": [50852, 286, 528, 281, 362, 439, 3685, 295, 7295, 1117, 51000], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 279, "seek": 68916, "start": 701.88, "end": 703.3199999999999, "text": " happening next year.", "tokens": [51000, 2737, 958, 1064, 13, 51072], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 280, "seek": 68916, "start": 704.1999999999999, "end": 706.3199999999999, "text": " That was not hype when I said", "tokens": [51116, 663, 390, 406, 24144, 562, 286, 848, 51222], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 281, "seek": 68916, "start": 706.3199999999999, "end": 708.8399999999999, "text": " that I was predicting AGI this year.", "tokens": [51222, 300, 286, 390, 32884, 316, 26252, 341, 1064, 13, 51348], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 282, "seek": 68916, "start": 708.8399999999999, "end": 711.24, "text": " That was a genuine prediction on my part,", "tokens": [51348, 663, 390, 257, 16699, 17630, 322, 452, 644, 11, 51468], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 283, "seek": 68916, "start": 711.24, "end": 713.0799999999999, "text": " and I was like, man, things are happening,", "tokens": [51468, 293, 286, 390, 411, 11, 587, 11, 721, 366, 2737, 11, 51560], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 284, "seek": 68916, "start": 713.0799999999999, "end": 714.16, "text": " they're accelerating,", "tokens": [51560, 436, 434, 34391, 11, 51614], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 285, "seek": 68916, "start": 714.16, "end": 715.3199999999999, "text": " but I don't believe that anymore", "tokens": [51614, 457, 286, 500, 380, 1697, 300, 3602, 51672], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 286, "seek": 68916, "start": 715.3199999999999, "end": 716.8399999999999, "text": " because of the data that I'm seeing,", "tokens": [51672, 570, 295, 264, 1412, 300, 286, 478, 2577, 11, 51748], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 287, "seek": 68916, "start": 716.8399999999999, "end": 718.8, "text": " because of the trends that I'm seeing.", "tokens": [51748, 570, 295, 264, 13892, 300, 286, 478, 2577, 13, 51846], "temperature": 0.0, "avg_logprob": -0.09035106415444231, "compression_ratio": 1.8560885608856088, "no_speech_prob": 0.0016482715727761388}, {"id": 288, "seek": 71880, "start": 718.8, "end": 719.9599999999999, "text": " And I know that that sucks,", "tokens": [50364, 400, 286, 458, 300, 300, 15846, 11, 50422], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 289, "seek": 71880, "start": 719.9599999999999, "end": 724.9599999999999, "text": " like if someone is banking on a certain outcome,", "tokens": [50422, 411, 498, 1580, 307, 18261, 322, 257, 1629, 9700, 11, 50672], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 290, "seek": 71880, "start": 725.28, "end": 726.92, "text": " like expectations and reality,", "tokens": [50688, 411, 9843, 293, 4103, 11, 50770], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 291, "seek": 71880, "start": 726.92, "end": 729.4799999999999, "text": " there's always a gap between expectations and reality,", "tokens": [50770, 456, 311, 1009, 257, 7417, 1296, 9843, 293, 4103, 11, 50898], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 292, "seek": 71880, "start": 729.4799999999999, "end": 732.8, "text": " and when that gap gets bigger, it sucks.", "tokens": [50898, 293, 562, 300, 7417, 2170, 3801, 11, 309, 15846, 13, 51064], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 293, "seek": 71880, "start": 732.8, "end": 735.1999999999999, "text": " Now, some people are gonna take this news", "tokens": [51064, 823, 11, 512, 561, 366, 799, 747, 341, 2583, 51184], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 294, "seek": 71880, "start": 735.1999999999999, "end": 738.3599999999999, "text": " and interpret it in completely unexpected ways to me,", "tokens": [51184, 293, 7302, 309, 294, 2584, 13106, 2098, 281, 385, 11, 51342], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 295, "seek": 71880, "start": 738.3599999999999, "end": 739.5999999999999, "text": " and that's fine.", "tokens": [51342, 293, 300, 311, 2489, 13, 51404], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 296, "seek": 71880, "start": 739.5999999999999, "end": 742.8399999999999, "text": " But what I do wanna caution is for the five", "tokens": [51404, 583, 437, 286, 360, 1948, 23585, 307, 337, 264, 1732, 51566], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 297, "seek": 71880, "start": 742.8399999999999, "end": 745.24, "text": " or less percent of you out there in the audience", "tokens": [51566, 420, 1570, 3043, 295, 291, 484, 456, 294, 264, 4034, 51686], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 298, "seek": 71880, "start": 745.24, "end": 747.4799999999999, "text": " that are on the tails of the bell curve", "tokens": [51686, 300, 366, 322, 264, 28537, 295, 264, 4549, 7605, 51798], "temperature": 0.0, "avg_logprob": -0.12689371669993682, "compression_ratio": 1.7335907335907337, "no_speech_prob": 0.0002868219744414091}, {"id": 299, "seek": 74748, "start": 747.48, "end": 750.32, "text": " in terms of expectations and your disposition,", "tokens": [50364, 294, 2115, 295, 9843, 293, 428, 40293, 11, 50506], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 300, "seek": 74748, "start": 750.32, "end": 752.44, "text": " your valence towards this,", "tokens": [50506, 428, 1323, 655, 3030, 341, 11, 50612], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 301, "seek": 74748, "start": 752.44, "end": 757.44, "text": " is if you broaden your narratives just a little bit,", "tokens": [50612, 307, 498, 291, 47045, 428, 28016, 445, 257, 707, 857, 11, 50862], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 302, "seek": 74748, "start": 758.28, "end": 759.88, "text": " then you might be surprised", "tokens": [50904, 550, 291, 1062, 312, 6100, 50984], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 303, "seek": 74748, "start": 759.88, "end": 762.16, "text": " at some of the other advantages that are happening,", "tokens": [50984, 412, 512, 295, 264, 661, 14906, 300, 366, 2737, 11, 51098], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 304, "seek": 74748, "start": 762.16, "end": 764.48, "text": " and also just realizing that there is a silver lining,", "tokens": [51098, 293, 611, 445, 16734, 300, 456, 307, 257, 8753, 19628, 11, 51214], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 305, "seek": 74748, "start": 764.48, "end": 767.44, "text": " is that the disruption that is coming", "tokens": [51214, 307, 300, 264, 28751, 300, 307, 1348, 51362], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 306, "seek": 74748, "start": 767.44, "end": 768.88, "text": " is gonna take a little bit longer,", "tokens": [51362, 307, 799, 747, 257, 707, 857, 2854, 11, 51434], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 307, "seek": 74748, "start": 768.88, "end": 771.76, "text": " which means that society will be a little bit more stable,", "tokens": [51434, 597, 1355, 300, 4086, 486, 312, 257, 707, 857, 544, 8351, 11, 51578], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 308, "seek": 74748, "start": 771.76, "end": 774.96, "text": " which means that the risk of catastrophic outcomes", "tokens": [51578, 597, 1355, 300, 264, 3148, 295, 34915, 10070, 51738], "temperature": 0.0, "avg_logprob": -0.09636279388710305, "compression_ratio": 1.8122448979591836, "no_speech_prob": 0.0005702489870600402}, {"id": 309, "seek": 77496, "start": 774.96, "end": 778.1600000000001, "text": " or unintended outcomes goes down significantly.", "tokens": [50364, 420, 49902, 10070, 1709, 760, 10591, 13, 50524], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 310, "seek": 77496, "start": 778.1600000000001, "end": 780.6, "text": " And on the topic of those narratives", "tokens": [50524, 400, 322, 264, 4829, 295, 729, 28016, 50646], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 311, "seek": 77496, "start": 780.6, "end": 782.2800000000001, "text": " and those echo chambers,", "tokens": [50646, 293, 729, 14300, 34513, 11, 50730], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 312, "seek": 77496, "start": 782.2800000000001, "end": 785.1600000000001, "text": " a lot of people have asked me to comment on Gary Marcus,", "tokens": [50730, 257, 688, 295, 561, 362, 2351, 385, 281, 2871, 322, 13788, 26574, 11, 50874], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 313, "seek": 77496, "start": 785.1600000000001, "end": 786.72, "text": " and I've resisted until now,", "tokens": [50874, 293, 286, 600, 4597, 292, 1826, 586, 11, 50952], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 314, "seek": 77496, "start": 787.6, "end": 790.5600000000001, "text": " but having gotten back on Twitter,", "tokens": [50996, 457, 1419, 5768, 646, 322, 5794, 11, 51144], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 315, "seek": 77496, "start": 790.5600000000001, "end": 793.24, "text": " I will say that I've watched some really interesting", "tokens": [51144, 286, 486, 584, 300, 286, 600, 6337, 512, 534, 1880, 51278], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 316, "seek": 77496, "start": 793.24, "end": 795.36, "text": " and highly vitriolic debates", "tokens": [51278, 293, 5405, 9467, 470, 7940, 24203, 51384], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 317, "seek": 77496, "start": 795.36, "end": 800.36, "text": " between namely Gary Marcus, Yasha Bach, and Jan Lacoon.", "tokens": [51384, 1296, 20926, 13788, 26574, 11, 398, 12137, 30920, 11, 293, 4956, 40113, 4106, 13, 51634], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 318, "seek": 77496, "start": 801.12, "end": 803.2, "text": " Now, these are supposed to be the adults in the room,", "tokens": [51672, 823, 11, 613, 366, 3442, 281, 312, 264, 8865, 294, 264, 1808, 11, 51776], "temperature": 0.0, "avg_logprob": -0.13803903545652116, "compression_ratio": 1.5629629629629629, "no_speech_prob": 0.0071192411705851555}, {"id": 319, "seek": 80320, "start": 803.2, "end": 806.0400000000001, "text": " and having watched Yasha on some interviews,", "tokens": [50364, 293, 1419, 6337, 398, 12137, 322, 512, 12318, 11, 50506], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 320, "seek": 80320, "start": 806.0400000000001, "end": 808.32, "text": " like he's a very sharp guy,", "tokens": [50506, 411, 415, 311, 257, 588, 8199, 2146, 11, 50620], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 321, "seek": 80320, "start": 808.32, "end": 811.2, "text": " but even he got into the like, let's just beat up on,", "tokens": [50620, 457, 754, 415, 658, 666, 264, 411, 11, 718, 311, 445, 4224, 493, 322, 11, 50764], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 322, "seek": 80320, "start": 811.2, "end": 813.2, "text": " let's like, what is the term that kids use these days,", "tokens": [50764, 718, 311, 411, 11, 437, 307, 264, 1433, 300, 2301, 764, 613, 1708, 11, 50864], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 323, "seek": 80320, "start": 813.2, "end": 816.0400000000001, "text": " like let's clown on Gary Marcus train,", "tokens": [50864, 411, 718, 311, 22209, 322, 13788, 26574, 3847, 11, 51006], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 324, "seek": 80320, "start": 816.0400000000001, "end": 817.8000000000001, "text": " and that was honestly really disappointing", "tokens": [51006, 293, 300, 390, 6095, 534, 25054, 51094], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 325, "seek": 80320, "start": 817.8000000000001, "end": 819.36, "text": " because this is someone who's supposed to be like", "tokens": [51094, 570, 341, 307, 1580, 567, 311, 3442, 281, 312, 411, 51172], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 326, "seek": 80320, "start": 819.36, "end": 822.0400000000001, "text": " a high brow like academic researcher,", "tokens": [51172, 257, 1090, 19299, 411, 7778, 21751, 11, 51306], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 327, "seek": 80320, "start": 822.0400000000001, "end": 824.9200000000001, "text": " and he's sharing like caricature memes of Gary,", "tokens": [51306, 293, 415, 311, 5414, 411, 45732, 1503, 29730, 295, 13788, 11, 51450], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 328, "seek": 80320, "start": 824.9200000000001, "end": 827.0400000000001, "text": " which, I mean, I would never do that.", "tokens": [51450, 597, 11, 286, 914, 11, 286, 576, 1128, 360, 300, 13, 51556], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 329, "seek": 80320, "start": 827.0400000000001, "end": 829.08, "text": " I don't particularly agree with Gary anymore,", "tokens": [51556, 286, 500, 380, 4098, 3986, 365, 13788, 3602, 11, 51658], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 330, "seek": 80320, "start": 829.08, "end": 831.24, "text": " but that was incredibly immature.", "tokens": [51658, 457, 300, 390, 6252, 49539, 13, 51766], "temperature": 0.0, "avg_logprob": -0.135792982493732, "compression_ratio": 1.7062706270627064, "no_speech_prob": 0.003172097960487008}, {"id": 331, "seek": 83124, "start": 831.24, "end": 833.24, "text": " And then Jan Lacoon has often had this like,", "tokens": [50364, 400, 550, 4956, 40113, 4106, 575, 2049, 632, 341, 411, 11, 50464], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 332, "seek": 83124, "start": 833.24, "end": 835.8, "text": " old man yells at cloud energy,", "tokens": [50464, 1331, 587, 48543, 412, 4588, 2281, 11, 50592], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 333, "seek": 83124, "start": 835.8, "end": 838.04, "text": " which is weird because it's like,", "tokens": [50592, 597, 307, 3657, 570, 309, 311, 411, 11, 50704], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 334, "seek": 83124, "start": 838.04, "end": 839.72, "text": " half of what he says I agree with,", "tokens": [50704, 1922, 295, 437, 415, 1619, 286, 3986, 365, 11, 50788], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 335, "seek": 83124, "start": 839.72, "end": 840.88, "text": " like Ferventland, the other half,", "tokens": [50788, 411, 479, 1978, 317, 1661, 11, 264, 661, 1922, 11, 50846], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 336, "seek": 83124, "start": 840.88, "end": 842.88, "text": " I'm like, where did that come from?", "tokens": [50846, 286, 478, 411, 11, 689, 630, 300, 808, 490, 30, 50946], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 337, "seek": 83124, "start": 842.88, "end": 845.32, "text": " So, all right, so what happens?", "tokens": [50946, 407, 11, 439, 558, 11, 370, 437, 2314, 30, 51068], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 338, "seek": 83124, "start": 845.32, "end": 848.48, "text": " And this is not, to be fair, taking a step back,", "tokens": [51068, 400, 341, 307, 406, 11, 281, 312, 3143, 11, 1940, 257, 1823, 646, 11, 51226], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 339, "seek": 83124, "start": 848.48, "end": 851.6, "text": " this is not a unique phenomenon in AI.", "tokens": [51226, 341, 307, 406, 257, 3845, 14029, 294, 7318, 13, 51382], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 340, "seek": 83124, "start": 851.6, "end": 854.36, "text": " Some of, one of my good friends as a physicist,", "tokens": [51382, 2188, 295, 11, 472, 295, 452, 665, 1855, 382, 257, 42466, 11, 51520], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 341, "seek": 83124, "start": 854.36, "end": 856.64, "text": " this kind of thing happens in the physics community", "tokens": [51520, 341, 733, 295, 551, 2314, 294, 264, 10649, 1768, 51634], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 342, "seek": 83124, "start": 856.64, "end": 858.2, "text": " all the time, apparently,", "tokens": [51634, 439, 264, 565, 11, 7970, 11, 51712], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 343, "seek": 83124, "start": 858.2, "end": 861.04, "text": " where it's like disagreements and arguments", "tokens": [51712, 689, 309, 311, 411, 23926, 6400, 293, 12869, 51854], "temperature": 0.0, "avg_logprob": -0.1364858881632487, "compression_ratio": 1.691275167785235, "no_speech_prob": 0.000519283174071461}, {"id": 344, "seek": 86104, "start": 861.04, "end": 863.48, "text": " over interpretations will actually like,", "tokens": [50364, 670, 37547, 486, 767, 411, 11, 50486], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 345, "seek": 86104, "start": 863.48, "end": 866.16, "text": " come to shouting matches and sometimes fist fights.", "tokens": [50486, 808, 281, 20382, 10676, 293, 2171, 21849, 14512, 13, 50620], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 346, "seek": 86104, "start": 866.16, "end": 869.7199999999999, "text": " Physicists are actually pretty hardcore, it turns out.", "tokens": [50620, 15542, 299, 1751, 366, 767, 1238, 28196, 11, 309, 4523, 484, 13, 50798], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 347, "seek": 86104, "start": 869.7199999999999, "end": 874.7199999999999, "text": " So, from my reading of, you know, human nature,", "tokens": [50798, 407, 11, 490, 452, 3760, 295, 11, 291, 458, 11, 1952, 3687, 11, 51048], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 348, "seek": 86104, "start": 874.92, "end": 877.4, "text": " what I, the way that I interpret this is that", "tokens": [51058, 437, 286, 11, 264, 636, 300, 286, 7302, 341, 307, 300, 51182], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 349, "seek": 86104, "start": 877.4, "end": 880.04, "text": " we have a tightening status game.", "tokens": [51182, 321, 362, 257, 42217, 6558, 1216, 13, 51314], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 350, "seek": 86104, "start": 880.04, "end": 883.36, "text": " So, Gary, Yasha, Yan, all of these people,", "tokens": [51314, 407, 11, 13788, 11, 398, 12137, 11, 13633, 11, 439, 295, 613, 561, 11, 51480], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 351, "seek": 86104, "start": 883.36, "end": 885.7199999999999, "text": " they suddenly saw themselves having much,", "tokens": [51480, 436, 5800, 1866, 2969, 1419, 709, 11, 51598], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 352, "seek": 86104, "start": 885.7199999999999, "end": 889.7199999999999, "text": " much higher social status because of artificial intelligence.", "tokens": [51598, 709, 2946, 2093, 6558, 570, 295, 11677, 7599, 13, 51798], "temperature": 0.0, "avg_logprob": -0.17893280806364836, "compression_ratio": 1.6168582375478928, "no_speech_prob": 0.0010321130976080894}, {"id": 353, "seek": 88972, "start": 889.72, "end": 891.72, "text": " And so, one way to compare this is,", "tokens": [50364, 400, 370, 11, 472, 636, 281, 6794, 341, 307, 11, 50464], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 354, "seek": 88972, "start": 891.72, "end": 894.36, "text": " imagine you're back in high school", "tokens": [50464, 3811, 291, 434, 646, 294, 1090, 1395, 50596], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 355, "seek": 88972, "start": 894.36, "end": 896.52, "text": " and something changes and suddenly,", "tokens": [50596, 293, 746, 2962, 293, 5800, 11, 50704], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 356, "seek": 88972, "start": 896.52, "end": 899.36, "text": " the nerds are all the most popular kids in school.", "tokens": [50704, 264, 23229, 82, 366, 439, 264, 881, 3743, 2301, 294, 1395, 13, 50846], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 357, "seek": 88972, "start": 899.36, "end": 901.5600000000001, "text": " Well, then something changes again,", "tokens": [50846, 1042, 11, 550, 746, 2962, 797, 11, 50956], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 358, "seek": 88972, "start": 901.5600000000001, "end": 903.0400000000001, "text": " and it's like, oh, well, actually,", "tokens": [50956, 293, 309, 311, 411, 11, 1954, 11, 731, 11, 767, 11, 51030], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 359, "seek": 88972, "start": 903.0400000000001, "end": 905.96, "text": " instead of the top eight nerds, now it's the top five.", "tokens": [51030, 2602, 295, 264, 1192, 3180, 23229, 82, 11, 586, 309, 311, 264, 1192, 1732, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 360, "seek": 88972, "start": 905.96, "end": 908.6, "text": " And so, three have to get kicked off the island.", "tokens": [51176, 400, 370, 11, 1045, 362, 281, 483, 14609, 766, 264, 6077, 13, 51308], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 361, "seek": 88972, "start": 908.6, "end": 909.8000000000001, "text": " That's what's happening.", "tokens": [51308, 663, 311, 437, 311, 2737, 13, 51368], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 362, "seek": 88972, "start": 909.8000000000001, "end": 913.44, "text": " And so, they're scrabbling over diminishing social status", "tokens": [51368, 400, 370, 11, 436, 434, 795, 5305, 18262, 670, 15739, 3807, 2093, 6558, 51550], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 363, "seek": 88972, "start": 913.44, "end": 916.88, "text": " because, again, with AI slowing down,", "tokens": [51550, 570, 11, 797, 11, 365, 7318, 26958, 760, 11, 51722], "temperature": 0.0, "avg_logprob": -0.10140842379945697, "compression_ratio": 1.709433962264151, "no_speech_prob": 0.0006666424451395869}, {"id": 364, "seek": 91688, "start": 916.92, "end": 920.04, "text": " it's no longer as hot and sexy as it was a year ago.", "tokens": [50366, 309, 311, 572, 2854, 382, 2368, 293, 13701, 382, 309, 390, 257, 1064, 2057, 13, 50522], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 365, "seek": 91688, "start": 920.04, "end": 922.0, "text": " It's no longer, you know, you can't just say,", "tokens": [50522, 467, 311, 572, 2854, 11, 291, 458, 11, 291, 393, 380, 445, 584, 11, 50620], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 366, "seek": 91688, "start": 922.0, "end": 923.16, "text": " hey, I was gonna kill everyone", "tokens": [50620, 4177, 11, 286, 390, 799, 1961, 1518, 50678], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 367, "seek": 91688, "start": 923.16, "end": 926.32, "text": " and get an invitation to the TED stage anymore.", "tokens": [50678, 293, 483, 364, 17890, 281, 264, 43036, 3233, 3602, 13, 50836], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 368, "seek": 91688, "start": 926.32, "end": 927.76, "text": " And so, because of that,", "tokens": [50836, 400, 370, 11, 570, 295, 300, 11, 50908], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 369, "seek": 91688, "start": 927.76, "end": 929.64, "text": " because the status game is narrowing,", "tokens": [50908, 570, 264, 6558, 1216, 307, 9432, 278, 11, 51002], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 370, "seek": 91688, "start": 929.64, "end": 930.68, "text": " because the number of people", "tokens": [51002, 570, 264, 1230, 295, 561, 51054], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 371, "seek": 91688, "start": 930.68, "end": 932.76, "text": " that can be high status is going down,", "tokens": [51054, 300, 393, 312, 1090, 6558, 307, 516, 760, 11, 51158], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 372, "seek": 91688, "start": 932.76, "end": 934.68, "text": " the rules are becoming more arbitrary", "tokens": [51158, 264, 4474, 366, 5617, 544, 23211, 51254], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 373, "seek": 91688, "start": 934.68, "end": 936.88, "text": " and people are becoming a little bit more snippy,", "tokens": [51254, 293, 561, 366, 5617, 257, 707, 857, 544, 35623, 88, 11, 51364], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 374, "seek": 91688, "start": 936.88, "end": 940.08, "text": " a little bit more vitriolic, as I said.", "tokens": [51364, 257, 707, 857, 544, 9467, 470, 7940, 11, 382, 286, 848, 13, 51524], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 375, "seek": 91688, "start": 940.08, "end": 942.76, "text": " The stakes go up because the risk of losing status,", "tokens": [51524, 440, 28429, 352, 493, 570, 264, 3148, 295, 7027, 6558, 11, 51658], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 376, "seek": 91688, "start": 942.76, "end": 944.76, "text": " especially, this is what we saw with Ilya.", "tokens": [51658, 2318, 11, 341, 307, 437, 321, 1866, 365, 286, 45106, 13, 51758], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 377, "seek": 91688, "start": 944.76, "end": 946.08, "text": " I talked about this extensively.", "tokens": [51758, 286, 2825, 466, 341, 32636, 13, 51824], "temperature": 0.0, "avg_logprob": -0.08106810369609314, "compression_ratio": 1.8193548387096774, "no_speech_prob": 0.010650407522916794}, {"id": 378, "seek": 94608, "start": 946.08, "end": 949.48, "text": " The reason that Ilya was socially canceled with an open AI", "tokens": [50364, 440, 1778, 300, 286, 45106, 390, 21397, 24839, 365, 364, 1269, 7318, 50534], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 379, "seek": 94608, "start": 949.48, "end": 952.44, "text": " is because he made the cardinal sin", "tokens": [50534, 307, 570, 415, 1027, 264, 2920, 2071, 3343, 50682], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 380, "seek": 94608, "start": 952.44, "end": 953.96, "text": " of attacking Sam Altman,", "tokens": [50682, 295, 15010, 4832, 15992, 1601, 11, 50758], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 381, "seek": 94608, "start": 953.96, "end": 956.76, "text": " even though he was doing it for what he believed", "tokens": [50758, 754, 1673, 415, 390, 884, 309, 337, 437, 415, 7847, 50898], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 382, "seek": 94608, "start": 956.76, "end": 958.88, "text": " was the right reasons,", "tokens": [50898, 390, 264, 558, 4112, 11, 51004], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 383, "seek": 94608, "start": 958.88, "end": 961.12, "text": " that was a violation of the social norm,", "tokens": [51004, 300, 390, 257, 22840, 295, 264, 2093, 2026, 11, 51116], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 384, "seek": 94608, "start": 961.12, "end": 963.3000000000001, "text": " which is Sam Altman is king.", "tokens": [51116, 597, 307, 4832, 15992, 1601, 307, 4867, 13, 51225], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 385, "seek": 94608, "start": 963.3000000000001, "end": 966.0, "text": " And of course, Sam Altman, as a power seeking person,", "tokens": [51225, 400, 295, 1164, 11, 4832, 15992, 1601, 11, 382, 257, 1347, 11670, 954, 11, 51360], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 386, "seek": 94608, "start": 966.0, "end": 968.44, "text": " was not going to tolerate that.", "tokens": [51360, 390, 406, 516, 281, 25773, 300, 13, 51482], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 387, "seek": 94608, "start": 968.44, "end": 970.0400000000001, "text": " Consciously or unconsciously,", "tokens": [51482, 6923, 4139, 356, 420, 18900, 356, 11, 51562], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 388, "seek": 94608, "start": 970.0400000000001, "end": 971.36, "text": " that was just never going to,", "tokens": [51562, 300, 390, 445, 1128, 516, 281, 11, 51628], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 389, "seek": 94608, "start": 971.36, "end": 972.9200000000001, "text": " he was never going to tolerate it.", "tokens": [51628, 415, 390, 1128, 516, 281, 25773, 309, 13, 51706], "temperature": 0.0, "avg_logprob": -0.1392776459220826, "compression_ratio": 1.7894736842105263, "no_speech_prob": 0.00044416237506084144}, {"id": 390, "seek": 97292, "start": 972.92, "end": 974.88, "text": " So what happens is,", "tokens": [50364, 407, 437, 2314, 307, 11, 50462], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 391, "seek": 97292, "start": 974.88, "end": 976.68, "text": " other AI commentators out there,", "tokens": [50462, 661, 7318, 2871, 3391, 484, 456, 11, 50552], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 392, "seek": 97292, "start": 976.68, "end": 978.9599999999999, "text": " namely Gary, Yasha, and Yan,", "tokens": [50552, 20926, 13788, 11, 398, 12137, 11, 293, 13633, 11, 50666], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 393, "seek": 97292, "start": 978.9599999999999, "end": 980.52, "text": " are doubling down on their narratives,", "tokens": [50666, 366, 33651, 760, 322, 641, 28016, 11, 50744], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 394, "seek": 97292, "start": 980.52, "end": 983.4799999999999, "text": " because basically they're gonna be doubling down", "tokens": [50744, 570, 1936, 436, 434, 799, 312, 33651, 760, 50892], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 395, "seek": 97292, "start": 983.4799999999999, "end": 985.4799999999999, "text": " on the narratives that got them that social status", "tokens": [50892, 322, 264, 28016, 300, 658, 552, 300, 2093, 6558, 50992], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 396, "seek": 97292, "start": 985.4799999999999, "end": 987.18, "text": " in the first place.", "tokens": [50992, 294, 264, 700, 1081, 13, 51077], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 397, "seek": 97292, "start": 987.18, "end": 990.3199999999999, "text": " And that is my read on the situation.", "tokens": [51077, 400, 300, 307, 452, 1401, 322, 264, 2590, 13, 51234], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 398, "seek": 97292, "start": 990.3199999999999, "end": 992.4399999999999, "text": " And also, I take that as evidence", "tokens": [51234, 400, 611, 11, 286, 747, 300, 382, 4467, 51340], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 399, "seek": 97292, "start": 992.4399999999999, "end": 994.24, "text": " that AI is slowing down,", "tokens": [51340, 300, 7318, 307, 26958, 760, 11, 51430], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 400, "seek": 97292, "start": 994.24, "end": 997.36, "text": " because again, if AI is running out of steam,", "tokens": [51430, 570, 797, 11, 498, 7318, 307, 2614, 484, 295, 11952, 11, 51586], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 401, "seek": 97292, "start": 997.36, "end": 999.76, "text": " then the amount of space", "tokens": [51586, 550, 264, 2372, 295, 1901, 51706], "temperature": 0.0, "avg_logprob": -0.13630630659020465, "compression_ratio": 1.728813559322034, "no_speech_prob": 0.0015008862828835845}, {"id": 402, "seek": 99976, "start": 999.8, "end": 1003.12, "text": " that the public square needs of AI commentators", "tokens": [50366, 300, 264, 1908, 3732, 2203, 295, 7318, 2871, 3391, 50532], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 403, "seek": 99976, "start": 1003.12, "end": 1004.08, "text": " is going down.", "tokens": [50532, 307, 516, 760, 13, 50580], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 404, "seek": 99976, "start": 1004.08, "end": 1005.36, "text": " It's also been a year and a half", "tokens": [50580, 467, 311, 611, 668, 257, 1064, 293, 257, 1922, 50644], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 405, "seek": 99976, "start": 1005.36, "end": 1007.4399999999999, "text": " since Gary Marcus was in front of the Senate.", "tokens": [50644, 1670, 13788, 26574, 390, 294, 1868, 295, 264, 9867, 13, 50748], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 406, "seek": 99976, "start": 1007.4399999999999, "end": 1010.4, "text": " And have you seen him or heard him any other place?", "tokens": [50748, 400, 362, 291, 1612, 796, 420, 2198, 796, 604, 661, 1081, 30, 50896], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 407, "seek": 99976, "start": 1010.4, "end": 1014.0, "text": " No, like his 15 minutes of fame might be over,", "tokens": [50896, 883, 11, 411, 702, 2119, 2077, 295, 16874, 1062, 312, 670, 11, 51076], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 408, "seek": 99976, "start": 1014.0, "end": 1016.88, "text": " and that sucks, like that doesn't feel good.", "tokens": [51076, 293, 300, 15846, 11, 411, 300, 1177, 380, 841, 665, 13, 51220], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 409, "seek": 99976, "start": 1016.88, "end": 1020.3199999999999, "text": " It does not feel good to feel like you're being left behind", "tokens": [51220, 467, 775, 406, 841, 665, 281, 841, 411, 291, 434, 885, 1411, 2261, 51392], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 410, "seek": 99976, "start": 1020.3199999999999, "end": 1022.48, "text": " by the conversation or by society,", "tokens": [51392, 538, 264, 3761, 420, 538, 4086, 11, 51500], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 411, "seek": 99976, "start": 1022.48, "end": 1025.6, "text": " which is to me, an explanation as to why Gary", "tokens": [51500, 597, 307, 281, 385, 11, 364, 10835, 382, 281, 983, 13788, 51656], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 412, "seek": 99976, "start": 1025.6, "end": 1029.12, "text": " has been so incredibly salty lately.", "tokens": [51656, 575, 668, 370, 6252, 18443, 12881, 13, 51832], "temperature": 0.0, "avg_logprob": -0.09766432296398074, "compression_ratio": 1.6076388888888888, "no_speech_prob": 0.011685328558087349}, {"id": 413, "seek": 102912, "start": 1029.1599999999999, "end": 1031.4399999999998, "text": " And then of course, other people", "tokens": [50366, 400, 550, 295, 1164, 11, 661, 561, 50480], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 414, "seek": 102912, "start": 1031.4399999999998, "end": 1033.8, "text": " that are not as aware of these status games", "tokens": [50480, 300, 366, 406, 382, 3650, 295, 613, 6558, 2813, 50598], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 415, "seek": 102912, "start": 1033.8, "end": 1035.1399999999999, "text": " will jump in on bullying,", "tokens": [50598, 486, 3012, 294, 322, 25633, 11, 50665], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 416, "seek": 102912, "start": 1035.1399999999999, "end": 1038.84, "text": " because if you show weakness in a high-stakes status game,", "tokens": [50665, 570, 498, 291, 855, 12772, 294, 257, 1090, 12, 372, 3419, 6558, 1216, 11, 50850], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 417, "seek": 102912, "start": 1038.84, "end": 1040.8, "text": " people will unconsciously,", "tokens": [50850, 561, 486, 18900, 356, 11, 50948], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 418, "seek": 102912, "start": 1040.8, "end": 1043.76, "text": " it's tall poppy syndrome and a number of other phenomenon,", "tokens": [50948, 309, 311, 6764, 1665, 8200, 19371, 293, 257, 1230, 295, 661, 14029, 11, 51096], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 419, "seek": 102912, "start": 1043.76, "end": 1045.76, "text": " people will unconsciously jump in on that", "tokens": [51096, 561, 486, 18900, 356, 3012, 294, 322, 300, 51196], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 420, "seek": 102912, "start": 1045.76, "end": 1047.8, "text": " and say, ah, time to bully that person,", "tokens": [51196, 293, 584, 11, 3716, 11, 565, 281, 29123, 300, 954, 11, 51298], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 421, "seek": 102912, "start": 1047.8, "end": 1051.6399999999999, "text": " because they're signaling that their status is vulnerable.", "tokens": [51298, 570, 436, 434, 38639, 300, 641, 6558, 307, 10955, 13, 51490], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 422, "seek": 102912, "start": 1051.6399999999999, "end": 1053.8, "text": " So that's my read on the whole situation.", "tokens": [51490, 407, 300, 311, 452, 1401, 322, 264, 1379, 2590, 13, 51598], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 423, "seek": 102912, "start": 1053.8, "end": 1055.9199999999998, "text": " And yeah, it's not ideal, it's not what I hoped,", "tokens": [51598, 400, 1338, 11, 309, 311, 406, 7157, 11, 309, 311, 406, 437, 286, 19737, 11, 51704], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 424, "seek": 102912, "start": 1055.9199999999998, "end": 1057.32, "text": " it's not what I predicted,", "tokens": [51704, 309, 311, 406, 437, 286, 19147, 11, 51774], "temperature": 0.0, "avg_logprob": -0.10430139176389004, "compression_ratio": 1.84, "no_speech_prob": 0.00040445380727760494}, {"id": 425, "seek": 105732, "start": 1057.32, "end": 1061.6799999999998, "text": " but I ignored the numbers, I ignored the money, right?", "tokens": [50364, 457, 286, 19735, 264, 3547, 11, 286, 19735, 264, 1460, 11, 558, 30, 50582], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 426, "seek": 105732, "start": 1061.6799999999998, "end": 1065.8799999999999, "text": " Like, and hindsight, that was pretty dumb.", "tokens": [50582, 1743, 11, 293, 44357, 11, 300, 390, 1238, 10316, 13, 50792], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 427, "seek": 105732, "start": 1065.8799999999999, "end": 1069.0, "text": " So am I still predicting September 2024?", "tokens": [50792, 407, 669, 286, 920, 32884, 7216, 45237, 30, 50948], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 428, "seek": 105732, "start": 1069.0, "end": 1072.36, "text": " Again, this is where I'm gonna double down on my narrative.", "tokens": [50948, 3764, 11, 341, 307, 689, 286, 478, 799, 3834, 760, 322, 452, 9977, 13, 51116], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 429, "seek": 105732, "start": 1072.36, "end": 1074.28, "text": " I think that GPT-5 plus robots", "tokens": [51116, 286, 519, 300, 26039, 51, 12, 20, 1804, 14733, 51212], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 430, "seek": 105732, "start": 1074.28, "end": 1077.1399999999999, "text": " will surprise a lot of people with what it's capable of.", "tokens": [51212, 486, 6365, 257, 688, 295, 561, 365, 437, 309, 311, 8189, 295, 13, 51355], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 431, "seek": 105732, "start": 1077.1399999999999, "end": 1078.8799999999999, "text": " Is it gonna replace all of us?", "tokens": [51355, 1119, 309, 799, 7406, 439, 295, 505, 30, 51442], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 432, "seek": 105732, "start": 1078.8799999999999, "end": 1081.24, "text": " No, it's gonna be like the Nestor class four", "tokens": [51442, 883, 11, 309, 311, 799, 312, 411, 264, 31581, 284, 1508, 1451, 51560], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 433, "seek": 105732, "start": 1081.24, "end": 1083.08, "text": " from iRobot, where it's like,", "tokens": [51560, 490, 741, 26332, 310, 11, 689, 309, 311, 411, 11, 51652], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 434, "seek": 105732, "start": 1083.08, "end": 1086.32, "text": " it's capable of running your mail for you automatically,", "tokens": [51652, 309, 311, 8189, 295, 2614, 428, 10071, 337, 291, 6772, 11, 51814], "temperature": 0.0, "avg_logprob": -0.1591019997229943, "compression_ratio": 1.5809859154929577, "no_speech_prob": 0.0006666441331617534}, {"id": 435, "seek": 108632, "start": 1086.32, "end": 1088.2, "text": " but not much else.", "tokens": [50364, 457, 406, 709, 1646, 13, 50458], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 436, "seek": 108632, "start": 1088.2, "end": 1089.26, "text": " That's kind of what I predict.", "tokens": [50458, 663, 311, 733, 295, 437, 286, 6069, 13, 50511], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 437, "seek": 108632, "start": 1089.26, "end": 1090.96, "text": " So it's like, you know, you can get rid of like,", "tokens": [50511, 407, 309, 311, 411, 11, 291, 458, 11, 291, 393, 483, 3973, 295, 411, 11, 50596], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 438, "seek": 108632, "start": 1090.96, "end": 1094.24, "text": " maybe some warehouse workers, some factory workers,", "tokens": [50596, 1310, 512, 22244, 5600, 11, 512, 9265, 5600, 11, 50760], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 439, "seek": 108632, "start": 1094.24, "end": 1096.82, "text": " some mail carriers, but it's not gonna like,", "tokens": [50760, 512, 10071, 28541, 11, 457, 309, 311, 406, 799, 411, 11, 50889], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 440, "seek": 108632, "start": 1096.82, "end": 1098.08, "text": " upend the whole economy.", "tokens": [50889, 493, 521, 264, 1379, 5010, 13, 50952], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 441, "seek": 108632, "start": 1098.08, "end": 1099.6799999999998, "text": " So, all right.", "tokens": [50952, 407, 11, 439, 558, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 442, "seek": 108632, "start": 1099.6799999999998, "end": 1102.8799999999999, "text": " This has been your first episode of David Shapiro,", "tokens": [51032, 639, 575, 668, 428, 700, 3500, 295, 4389, 44160, 5182, 11, 51192], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 443, "seek": 108632, "start": 1102.8799999999999, "end": 1105.6, "text": " your personal chief AI officer.", "tokens": [51192, 428, 2973, 9588, 7318, 8456, 13, 51328], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 444, "seek": 108632, "start": 1105.6, "end": 1107.56, "text": " Let me know how you think this went in the comments", "tokens": [51328, 961, 385, 458, 577, 291, 519, 341, 1437, 294, 264, 3053, 51426], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 445, "seek": 108632, "start": 1107.56, "end": 1108.56, "text": " and I'll see you next time.", "tokens": [51426, 293, 286, 603, 536, 291, 958, 565, 13, 51476], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}, {"id": 446, "seek": 108632, "start": 1108.56, "end": 1109.3999999999999, "text": " Cheers.", "tokens": [51476, 13006, 13, 51518], "temperature": 0.0, "avg_logprob": -0.1406171986314117, "compression_ratio": 1.592156862745098, "no_speech_prob": 0.003172102151438594}], "language": "en"}