WEBVTT

00:00.000 --> 00:01.880
Chi, thanks for jumping on.

00:01.880 --> 00:03.680
It's a pleasure to meet you.

00:03.680 --> 00:05.400
I was really excited.

00:05.400 --> 00:07.720
Yeah, you're quite welcome.

00:07.720 --> 00:11.280
Obviously, Autogen is all the rage right now.

00:11.280 --> 00:12.280
It's very popular.

00:12.280 --> 00:14.920
There's lots and lots of videos being made about Autogen.

00:14.920 --> 00:16.640
But before we dive into that,

00:16.640 --> 00:18.800
I was wondering if you could just tell me a little bit more

00:18.800 --> 00:21.760
about your time at Microsoft as a principal researcher,

00:21.760 --> 00:23.440
like how did you get into that position?

00:23.440 --> 00:24.680
What's it been like?

00:24.680 --> 00:27.120
Yes, just give me the story.

00:27.120 --> 00:29.760
Thank you. Yeah, my name is Chi.

00:30.720 --> 00:33.680
Principal researcher at Microsoft Research.

00:33.680 --> 00:35.560
I joined long time ago.

00:35.560 --> 00:39.120
I joined about nine years ago in Microsoft.

00:39.120 --> 00:41.840
And I've been working on many different projects.

00:41.840 --> 00:44.120
Apparently now I'm focusing on Autogen.

00:44.120 --> 00:47.640
And before that, I worked on automated machine learning,

00:47.640 --> 00:50.120
machine learning for systems,

00:50.120 --> 00:53.200
data science, data analytics, data mining.

00:53.200 --> 00:56.560
So quite a lot of different things.

00:56.560 --> 00:59.640
And some of the work is more like on a theoretical set

01:00.000 --> 01:03.160
side and some of them is more to the system side.

01:04.320 --> 01:09.320
And yeah, I've been focusing on Autogen recently.

01:09.560 --> 01:12.160
So very happy to be here.

01:12.160 --> 01:13.000
Excellent.

01:13.000 --> 01:16.080
Yeah, with all the progress that's been made

01:16.080 --> 01:18.880
on large language models and working on assistance

01:18.880 --> 01:22.440
and agents, and then of course, working on agents,

01:22.440 --> 01:24.080
working with other agents,

01:24.080 --> 01:25.880
let me ask kind of a big question.

01:25.880 --> 01:29.080
Like what was the genesis behind Autogen?

01:30.000 --> 01:32.360
How was that project proposed?

01:32.360 --> 01:34.680
Like how did it come together?

01:34.680 --> 01:36.560
Like what was the theoretical work behind it?

01:36.560 --> 01:41.120
And how did you get from zero to where you are today?

01:41.120 --> 01:44.640
Yeah, so that's a very interesting question.

01:44.640 --> 01:46.520
And to fully answer that question,

01:46.520 --> 01:48.520
I need to tell a long story.

01:49.440 --> 01:50.920
But let me first tell you a short one.

01:50.920 --> 01:55.920
Short answer is like with this big kind of opportunities

01:55.960 --> 01:59.360
with larger models, so powerful techniques.

01:59.360 --> 02:01.200
At MSR, we want to ask the question,

02:01.200 --> 02:03.160
like what is the future, right?

02:03.160 --> 02:07.160
We want to be forward-looking, we want to be futuristic,

02:07.160 --> 02:09.240
kind of take the solid leadership.

02:09.240 --> 02:11.760
And because one of the famous quotes

02:11.760 --> 02:14.520
from the founder of Macro Research,

02:14.520 --> 02:17.680
we can say that the best science

02:17.680 --> 02:20.960
will be indistinguishable from magic.

02:20.960 --> 02:24.920
So that's the level of ambition we have.

02:24.920 --> 02:26.200
So we asked the question,

02:26.200 --> 02:29.640
what is the future of AI applications?

02:29.640 --> 02:32.280
And how do we empower every developer to build them?

02:33.360 --> 02:36.040
Yeah, so that's a fundamental driving question.

02:36.040 --> 02:40.200
And now a longer version of the answer is that,

02:40.200 --> 02:42.560
I started from, I thought as a tutorial,

02:42.560 --> 02:43.600
before I worked on Autogen,

02:43.600 --> 02:46.240
I worked on automated machine learning,

02:46.240 --> 02:48.720
which is another open source project called FLAML.

02:49.840 --> 02:54.360
FLAML is a solution for automating model selection,

02:54.360 --> 02:55.880
hyperparameter tuning, essentially,

02:55.880 --> 03:00.240
black box optimization to navigate a larger space

03:00.240 --> 03:01.720
without knowing the gradient.

03:02.960 --> 03:05.800
So it's a very powerful technique,

03:05.800 --> 03:10.800
but that was started before the larger model takes the storm.

03:11.720 --> 03:14.520
And when chatGVT released, right?

03:14.520 --> 03:19.520
And that's a big, big kind of upgrade of the model capabilities.

03:19.520 --> 03:24.520
And so I started working on a similar problem

03:24.680 --> 03:26.000
as automated machine learning.

03:26.000 --> 03:28.400
I started working on inference hyperparameter tuning

03:28.400 --> 03:30.600
for these chatGVT models.

03:30.600 --> 03:33.000
For example, how do you select the best model?

03:33.000 --> 03:36.120
How do you select the right prompt temperature

03:36.120 --> 03:37.960
and all the other inference parameters

03:37.960 --> 03:41.440
so that you can maximize the utility from the models

03:41.440 --> 03:43.040
while minimizing your cost?

03:44.080 --> 03:48.560
So that's the initial work on this direction.

03:48.640 --> 03:51.520
And when GT4 is released,

03:51.520 --> 03:55.360
that's another big upgrade of the level capabilities.

03:55.360 --> 03:59.000
So then I started really to ask the question,

03:59.000 --> 04:04.000
okay, if we kind of want to bring the best power

04:04.680 --> 04:07.480
of the model and really solve really difficult problems,

04:07.480 --> 04:09.720
what should be the right way to do it?

04:09.720 --> 04:14.200
And agent is apparently a very powerful notion.

04:14.200 --> 04:17.240
It's another kind of level of the automation

04:17.240 --> 04:19.440
as opposed to the previous automation

04:19.440 --> 04:22.680
in the 20 machine learning work I did.

04:22.680 --> 04:25.000
So yeah, so that's where they started.

04:26.040 --> 04:30.440
And of course, it's a whole new area.

04:30.440 --> 04:31.720
No, the shop agent is not new.

04:31.720 --> 04:35.560
It's has been there for a long time.

04:35.560 --> 04:37.240
And I remember back in college,

04:37.240 --> 04:39.680
I worked on some like game competition,

04:39.680 --> 04:43.080
like building agents that can play games

04:43.080 --> 04:44.840
with each other and compete.

04:44.960 --> 04:48.240
At that time, we were using many of the rule-based methods

04:48.240 --> 04:51.720
where a lot of deal with a lot of corner cases and so on.

04:51.720 --> 04:53.040
So it's not viable.

04:53.040 --> 04:55.640
It's a good notion, but not viable.

04:55.640 --> 04:58.800
And these larger models,

04:58.800 --> 05:00.960
especially the chat-operated models,

05:00.960 --> 05:05.760
really make it viable and a reality

05:05.760 --> 05:09.040
that we can build new software based on.

05:09.040 --> 05:11.240
And to study this new area,

05:11.240 --> 05:15.960
we kind of need to think many things from scratch

05:15.960 --> 05:20.400
and try to take some of the first principles

05:20.400 --> 05:21.880
and what is the right approach.

05:21.880 --> 05:25.880
And basically leverage every lesson

05:25.880 --> 05:29.240
we learned from the previous projects, previous experience,

05:29.240 --> 05:34.240
but try to build this one multi-agent framework

05:36.040 --> 05:38.720
that is really generic,

05:38.720 --> 05:40.720
and can support diverse applications.

05:41.720 --> 05:44.680
Yeah, so there are many different examples

05:44.680 --> 05:48.960
of sources of inspirations I can give you,

05:48.960 --> 05:52.800
but why not show it's like using everything I learned

05:52.800 --> 05:57.560
and also take every feedback I received from everyone

05:57.560 --> 05:59.280
and iterate on that.

05:59.280 --> 06:01.960
And so that's how we come here today.

06:01.960 --> 06:02.880
Excellent.

06:02.880 --> 06:05.440
Yeah, no, I mean, there's a lot to unpack there.

06:05.440 --> 06:08.320
It's fascinating to me that it started

06:08.320 --> 06:11.120
as sort of like auto ML,

06:11.120 --> 06:14.200
like automating the optimization.

06:14.200 --> 06:18.040
And I can see how going to like optimizing prompts

06:18.040 --> 06:20.960
and optimizing hyperparameters and parameter tuning

06:20.960 --> 06:23.640
could then lead to the agents, especially, like you said,

06:23.640 --> 06:26.000
if the idea is thinking to the future,

06:26.000 --> 06:27.960
like what is the sci-fi version

06:27.960 --> 06:31.560
of enabling application development in the future?

06:31.560 --> 06:35.800
So I wanted to follow up with a kind of a two-part question.

06:35.800 --> 06:39.920
So in the most basic level, what is AutoGen?

06:39.920 --> 06:42.080
But more specifically, what is the vision?

06:42.080 --> 06:44.720
Like what is it that you're trying to solve

06:44.720 --> 06:46.440
with AutoGen right now?

06:46.440 --> 06:50.080
Yeah, so yeah, in one word,

06:50.080 --> 06:54.600
AutoGen is the multi-agent AI framework,

06:54.600 --> 06:57.840
and especially focusing on multi-agent conversations

06:57.840 --> 07:01.520
so that we can connect large-level models, tools,

07:01.520 --> 07:06.520
and human inputs together to solve complex asks.

07:06.600 --> 07:09.480
There can be multiple ways to understand this.

07:09.480 --> 07:14.120
So in one way is to understand it as a programming framework

07:15.000 --> 07:17.760
for developers to build applications easily

07:17.760 --> 07:20.480
with some simple and unified abstraction

07:20.480 --> 07:22.280
so that they don't need to worry too much

07:22.280 --> 07:23.480
about the lower details,

07:23.480 --> 07:26.600
but can focus on how to define agents,

07:26.600 --> 07:30.160
how to get them to work with each other,

07:30.160 --> 07:33.080
and eventually reach the goal.

07:33.080 --> 07:36.000
It can also be understood as a tool

07:36.000 --> 07:39.000
to kind of scale up,

07:39.000 --> 07:41.880
scale up the power of our models

07:41.880 --> 07:44.440
and makes them even more useful

07:44.440 --> 07:46.680
by connecting with other tools,

07:46.680 --> 07:51.680
non-narrative model tools, or human collaborators,

07:52.640 --> 07:56.680
and kind of scale up both the complexity of the problem

07:56.680 --> 08:00.760
they can solve, the degree of automation, to some extent.

08:00.760 --> 08:04.080
Yeah, this is kind of a relatively abstract instruction,

08:04.080 --> 08:06.920
but if we think about it,

08:06.920 --> 08:10.480
about how people use it, it's quite simple.

08:10.480 --> 08:13.040
So when developers build applications with AutoGen,

08:13.040 --> 08:15.240
it basically boils down to two steps.

08:15.240 --> 08:17.080
Step one is to define agents,

08:17.080 --> 08:19.120
and step two is to get them to talk.

08:19.120 --> 08:21.280
So as simple as that.

08:21.840 --> 08:26.840
Yeah, so we try to make it very useful and generic,

08:26.840 --> 08:27.800
but on the other hand,

08:27.800 --> 08:32.160
we want to have a very simple interface for people to use.

08:32.160 --> 08:35.240
Yeah, I mean, that's exactly the vision

08:35.240 --> 08:37.200
that I kind of settled on

08:37.200 --> 08:40.920
for my hierarchical autonomous agent swarm idea,

08:40.920 --> 08:44.640
but I don't want to make it about that.

08:44.640 --> 08:46.120
Right now, it's just fascinating

08:46.120 --> 08:49.600
that we kind of converge on a very similar principle,

08:49.600 --> 08:53.040
like let's make the deployment of software

08:53.040 --> 08:54.840
as easy as possible.

08:54.840 --> 08:56.720
And so there's two things that you mentioned,

08:56.720 --> 08:58.280
like layers of abstraction,

08:58.280 --> 09:00.440
because I think that's a really good intuitive way

09:00.440 --> 09:01.280
of thinking about it,

09:01.280 --> 09:05.040
like in the same way that a Python interpreter

09:05.040 --> 09:08.160
was a layer of abstraction from compiled code,

09:08.160 --> 09:10.320
and then maybe language models

09:10.320 --> 09:11.760
are another layer of abstraction

09:11.760 --> 09:14.000
where it's natural language interface.

09:14.000 --> 09:16.280
This could be seen as, again,

09:16.280 --> 09:17.960
another layer of abstraction,

09:17.960 --> 09:19.840
where instead of looking at interacting

09:19.840 --> 09:21.400
with the language model directly,

09:21.400 --> 09:23.720
it is now a type of interpreter,

09:23.720 --> 09:25.520
but this is the agents

09:25.520 --> 09:29.160
and the multi-agent framework on top of it.

09:29.160 --> 09:30.480
So that's my intuition.

09:30.480 --> 09:32.760
Do you agree with that or disagree?

09:32.760 --> 09:36.160
Or like, how do you think of those layers of abstraction?

09:36.160 --> 09:38.960
Yeah, that's a fantastic question.

09:38.960 --> 09:41.760
The abstraction is indeed at a higher level

09:41.760 --> 09:43.600
of the agent abstraction.

09:44.600 --> 09:48.040
It unifies a number of different things.

09:48.040 --> 09:50.200
One is larger models.

09:50.200 --> 09:53.040
So when we use a single instance of a larger model,

09:53.040 --> 09:55.200
we usually do prompt engineering

09:55.200 --> 09:57.960
and try to give some input text

09:57.960 --> 09:59.880
and get some output text out of it.

10:00.920 --> 10:05.080
This agent abstraction can encapsulate that underneath

10:05.080 --> 10:07.760
and provide a more intuitive way

10:07.760 --> 10:12.160
to think of it as an agent that can converse with you.

10:12.160 --> 10:17.160
So not just as one single text completion inference anymore.

10:17.640 --> 10:21.400
It can do tasks, can persist some states

10:21.400 --> 10:24.240
and continue to take your feedback

10:24.240 --> 10:28.480
and produce more refined result and so on.

10:28.480 --> 10:32.320
So that's a larger model-based agent.

10:33.400 --> 10:37.040
There are two other kinds of backhands

10:37.040 --> 10:38.120
that can be encapsulated.

10:38.120 --> 10:42.200
One is, you can think of it as programming language

10:42.200 --> 10:46.600
or tool-based agent, which doesn't use a larger model,

10:46.600 --> 10:50.320
but they can still perform very useful actions.

10:50.320 --> 10:52.440
They can do code execution, for example,

10:52.440 --> 10:55.040
or it can execute predefined functions

10:55.040 --> 10:58.880
or it can basically execute any programming logic

10:58.880 --> 11:02.280
you've defined there.

11:02.280 --> 11:06.880
And third one is the human kind of backed agents.

11:06.880 --> 11:10.840
So these agents can be considered as some kind of user proxy.

11:12.120 --> 11:16.720
So when they need human input, the human can take over

11:16.720 --> 11:21.720
and just participate the multi-agent workflow

11:21.760 --> 11:23.360
as one of the agents.

11:23.360 --> 11:25.520
So you can see about several agents.

11:25.520 --> 11:28.520
Some of them are larger model-based, some are tool-based,

11:28.520 --> 11:31.880
others are human-based.

11:31.880 --> 11:35.400
So then they can just cooperate together

11:35.440 --> 11:36.880
through a very natural interface,

11:36.880 --> 11:40.720
which is a conversational interface.

11:40.720 --> 11:44.240
So that's kind of layer of abstraction we provide.

11:45.360 --> 11:48.040
Yeah, I appreciate that.

11:48.040 --> 11:49.560
And I'm reminded of during,

11:49.560 --> 11:52.480
I think it was the Ignite keynote speech Satya Nadella said,

11:52.480 --> 11:53.920
think of it as a reasoning engine

11:53.920 --> 11:55.680
and a natural language interface.

11:55.680 --> 11:57.320
And that was like the two simplest ways

11:57.320 --> 12:01.160
to think of generative AI, at least the language side.

12:02.160 --> 12:05.760
So the other topic that I wanted to ask about

12:05.760 --> 12:08.000
to kind of dig into was thinking about it

12:08.000 --> 12:10.200
as a kind of automation.

12:10.200 --> 12:13.920
So there's the agent-based, there's the tools-based,

12:13.920 --> 12:15.960
but then overall kind of,

12:15.960 --> 12:18.840
and this is a messaging kind of a framing

12:18.840 --> 12:21.640
that I've adopted when talking to people is,

12:21.640 --> 12:23.560
and of course it's an oversimplification,

12:23.560 --> 12:28.280
but AI is, one, AI is not new,

12:28.280 --> 12:29.960
like machine learning has been around for a while,

12:29.960 --> 12:32.600
this is just a step function in terms of capabilities

12:32.600 --> 12:35.040
that models have.

12:35.040 --> 12:38.080
But it's also just the simplest way to think about it

12:38.080 --> 12:40.960
from a production standpoint or from a software standpoint,

12:40.960 --> 12:43.880
is it's a new suite of automation tools, right?

12:43.880 --> 12:45.120
That's kind of how I think of it.

12:45.120 --> 12:47.400
Is that a fair characterization

12:47.400 --> 12:49.360
or is there something that I'm missing from that?

12:49.360 --> 12:52.480
Cause I do feel like there might be something missing

12:52.480 --> 12:54.880
or something that that characterization

12:54.880 --> 12:56.200
doesn't fully convey,

12:56.200 --> 12:59.120
but it is still fundamentally new automation, right?

13:00.080 --> 13:04.160
So if I try to understand it from an automation point of view,

13:04.160 --> 13:09.160
I think agent is fundamentally a automation concept.

13:10.880 --> 13:14.040
The automation is more like about,

13:14.040 --> 13:18.360
instead of giving every detailed instructions using code,

13:18.360 --> 13:21.320
I say step one, do this, step two, do that,

13:21.320 --> 13:26.320
using from precisely defined program language specification.

13:26.320 --> 13:31.320
And now we can make some more vague specification

13:32.520 --> 13:35.240
using like natural language specification,

13:35.240 --> 13:37.880
say I want to accomplish such a task

13:37.880 --> 13:40.240
and could the agent do it for me?

13:40.240 --> 13:45.240
So, and then underneath the agent needs to kind of break it down

13:45.240 --> 13:50.240
a big complex task into maybe smaller, solvable tasks.

13:50.760 --> 13:55.560
And until each task can be conveniently solved

13:55.560 --> 14:00.560
by a simple inference and produce a corresponding code

14:01.640 --> 14:02.720
to solve that task.

14:02.720 --> 14:06.440
And then eventually we need to recompose them,

14:06.440 --> 14:08.000
all of these intermediate steps

14:08.000 --> 14:10.480
and get to the final output back.

14:10.480 --> 14:13.240
So that is one part of the automation story.

14:14.240 --> 14:17.000
And another part of it is,

14:17.000 --> 14:19.400
think about this automating some tasks

14:19.400 --> 14:21.880
that human had to do.

14:22.080 --> 14:27.080
AutoGen really started with some very simple kind of automation.

14:28.560 --> 14:30.840
Just think about how you use chatGBT.

14:32.000 --> 14:35.600
You as a human need to ask questions

14:35.600 --> 14:37.880
and chatGBT gave you some answer.

14:37.880 --> 14:39.680
Sometimes it gave you the code

14:39.680 --> 14:42.320
and then human need to take that code

14:42.320 --> 14:46.960
and run it by yourself and get some result.

14:46.960 --> 14:49.080
If it's not correct, you send it back

14:49.080 --> 14:52.920
and chatGBT gave you some results for the game.

14:52.920 --> 14:55.160
And here in this kind of interaction,

14:55.160 --> 14:57.240
human students do a lot of work,

14:57.240 --> 15:02.240
but many of the work can be automated if we use agent.

15:03.120 --> 15:06.760
And even some kind of human feedback,

15:06.760 --> 15:11.760
like non-code, if I don't like the results,

15:12.960 --> 15:16.040
but I know my preferences, I will tell it,

15:16.040 --> 15:21.040
such as change the chart from using a dollar to percentage

15:21.400 --> 15:23.240
that kind of requirement,

15:23.240 --> 15:27.400
or teach me this lesson,

15:27.400 --> 15:28.800
teach me about math,

15:28.800 --> 15:31.720
but using a concrete money example, right?

15:31.720 --> 15:33.640
So those kind of requirements

15:33.640 --> 15:37.400
can be somewhat automated using all different ways.

15:37.400 --> 15:39.880
Sometimes we can use larger models.

15:40.680 --> 15:45.000
Sometimes we can use some retrieval augmented approach

15:45.000 --> 15:50.000
to inform retrieval to get the knowledge from somewhere.

15:51.120 --> 15:55.480
That's another kind of interesting automation

15:55.480 --> 15:57.160
that we can make.

15:57.160 --> 16:00.400
Yeah, and within that, those automation stories,

16:00.400 --> 16:04.000
because some of the examples,

16:04.000 --> 16:07.680
what was it, how did you say like a vague specification,

16:07.680 --> 16:09.200
right, a natural language specification

16:09.200 --> 16:12.320
that is not quite as rigorous as software development

16:12.320 --> 16:14.120
might have required in the past?

16:14.120 --> 16:16.040
And then of course, with these models,

16:16.040 --> 16:19.360
they have the ability to kind of think through it,

16:19.360 --> 16:21.920
or break it down into steps.

16:21.920 --> 16:25.880
So with all that, and some of the work that I have found is,

16:25.880 --> 16:28.120
or some of the problems that I've confronted,

16:28.120 --> 16:29.960
because it can think in general principles,

16:29.960 --> 16:31.960
it does know a lot about software development,

16:31.960 --> 16:34.040
and I mean, the language models know a lot

16:34.040 --> 16:35.200
about a lot of things.

16:35.200 --> 16:38.480
So with respect to autogen,

16:38.480 --> 16:41.640
and kind of getting to where you're at today,

16:41.640 --> 16:43.840
what are some of the biggest challenges

16:43.840 --> 16:46.000
that you've overcome so far, or that you haven't overcome?

16:46.000 --> 16:48.560
Maybe that would be a more interesting story.

16:48.560 --> 16:51.840
Yeah, sure, I could talk about both.

16:51.840 --> 16:54.560
For what we have overcome,

16:55.640 --> 17:00.640
I think we have kind of figured out the abstraction

17:00.720 --> 17:05.240
to the earlier about how to unify these different types

17:05.240 --> 17:10.240
of capabilities, different ways of making them work together.

17:11.080 --> 17:14.960
We'll have found one very simple interface

17:14.960 --> 17:19.120
that kind of accommodate a variety of different communication

17:19.120 --> 17:19.960
patterns.

17:19.960 --> 17:22.800
So one example is the, so there are several examples.

17:22.800 --> 17:25.880
One is the simple like one-to-one conversation.

17:27.080 --> 17:32.080
Another is hierarchical chat, like suppose one agent

17:32.080 --> 17:36.280
is more sit on top and talk to several sub-agents,

17:37.280 --> 17:41.240
it manages, and they can be nested structure,

17:41.240 --> 17:42.360
hierarchical structure.

17:43.360 --> 17:48.120
And another example is multiple one-on-one joint chat.

17:48.120 --> 17:52.880
So there's no one that is strictly sit on top.

17:52.880 --> 17:55.360
Everyone talks to the other else,

17:55.360 --> 17:59.440
but it's multiple one-on-one which are connected.

17:59.440 --> 18:01.320
So I talk to you, you talk to Katie,

18:01.320 --> 18:04.320
you can talk to me in this kind of triangle

18:04.360 --> 18:06.360
or multiple joint chat.

18:06.360 --> 18:11.280
And there's also a group chat, meaning it's not a one-on-one

18:11.280 --> 18:12.240
trend anymore.

18:12.240 --> 18:15.160
So everybody send messages to everyone else.

18:15.160 --> 18:19.560
So we see each other's message and there's a hidden

18:19.560 --> 18:22.280
group chat manager which does this kind of work.

18:22.280 --> 18:26.240
So architectural wise, it's still like one-on-one chat,

18:26.240 --> 18:31.240
but on the surface we can create an experience

18:32.120 --> 18:34.880
that simulates the group chat.

18:34.880 --> 18:37.400
And they can nest it the chat in some way,

18:37.400 --> 18:40.400
like for example, we can start with one-on-one conversation

18:40.400 --> 18:44.760
now, but at some time I decide to consult Katie.

18:44.760 --> 18:46.840
So I will hold on my current conversation

18:46.840 --> 18:48.960
and have some conversation with her.

18:48.960 --> 18:52.160
And then after I finish the conversation with her,

18:52.160 --> 18:54.600
I get back and continue the conversation with you.

18:54.600 --> 18:57.720
So that is a kind of nested chat.

18:57.720 --> 19:00.080
I believe that essentially you have the building blocks

19:00.080 --> 19:01.240
right now, right?

19:01.240 --> 19:03.440
These are some very common building blocks

19:03.440 --> 19:06.440
and we compose them together in different ways.

19:06.440 --> 19:10.120
We can build really complex workflows in general.

19:10.120 --> 19:14.640
So any arbitrarily complex communication patterns

19:14.640 --> 19:17.280
can be essentially built up within these building blocks.

19:17.280 --> 19:19.720
But I think that is what we have achieved.

19:19.720 --> 19:23.080
And we have also many examples for different applications

19:23.080 --> 19:27.600
of using these different types of patterns.

19:27.600 --> 19:29.680
This is another second thing we figured out.

19:29.680 --> 19:32.160
And the third thing I think is the ability

19:32.160 --> 19:38.600
to take human input and human control in a very natural way.

19:38.600 --> 19:41.640
And I thought earlier it's like every agent

19:41.640 --> 19:46.760
can be configured to enable the human input or disable that,

19:46.760 --> 19:49.360
depending on what you need.

19:49.360 --> 19:55.360
And also you can decide the type of environment from human.

19:55.360 --> 19:59.320
You can take over every time or you can only selectively

19:59.320 --> 20:01.800
chime in at a certain time.

20:01.800 --> 20:03.840
So that's a very useful feature because when

20:03.840 --> 20:07.480
you develop this automation, initially you

20:07.480 --> 20:10.680
don't know which step is easy to automate

20:10.680 --> 20:15.240
and which step is necessary for human to get in.

20:15.240 --> 20:19.760
So you can start from the more human loop way.

20:19.760 --> 20:21.960
And when you figure out that one step is

20:21.960 --> 20:25.720
you can confidently automate, then you can gradually reduce

20:25.720 --> 20:27.040
your human integration.

20:27.080 --> 20:32.800
So this convenience is very useful for doing all the experiments

20:32.800 --> 20:35.320
and figure out the right way.

20:35.320 --> 20:38.480
And make sure or still make sure human has a control

20:38.480 --> 20:40.120
when they need to.

20:40.120 --> 20:41.640
This is the third thing I think.

20:41.640 --> 20:45.840
So one more thing is the modularity and the reusability

20:45.840 --> 20:47.040
of the agents.

20:47.040 --> 20:51.880
That is a very important design part of it.

20:51.880 --> 20:55.600
So make sure that if you develop one useful agent

20:55.640 --> 20:58.600
in a different application, you could either directly reuse

20:58.600 --> 21:02.680
or start to modify it or extend from different ways.

21:02.680 --> 21:06.120
And make sure the barrier to hard work is not lost.

21:06.120 --> 21:08.520
I think that's also very important,

21:08.520 --> 21:12.360
seeing when we work together to build more and more

21:12.360 --> 21:14.360
complex applications.

21:14.360 --> 21:19.240
These are a number of things I think we're kind of figure out.

21:19.240 --> 21:22.760
And there are indeed a lot of challenges we haven't.

21:22.760 --> 21:26.440
And yeah, shall we get to that part?

21:26.440 --> 21:31.160
Yeah, no, I just want to reflect on some of the processes

21:31.160 --> 21:34.320
that you outlined, like removing humans from the loop

21:34.320 --> 21:35.640
step by step.

21:35.640 --> 21:37.480
Back in my time as an automation engineer,

21:37.480 --> 21:41.480
that's exactly what I would do is like, OK, I can write a script

21:41.480 --> 21:42.560
that does one part easily.

21:42.560 --> 21:43.320
Cool.

21:43.320 --> 21:45.160
Now, what's the next part?

21:45.160 --> 21:47.800
And then where do I have to jump in?

21:47.800 --> 21:50.640
And some of the other problems that you solved, like knowing.

21:50.680 --> 21:52.480
So this I think is really important,

21:52.480 --> 21:55.280
because some of the members of my team and my projects

21:55.280 --> 21:59.120
have found the same thing, is that knowing when to be quiet,

21:59.120 --> 22:02.480
knowing when not to jump in is, in many respects,

22:02.480 --> 22:04.440
more important because you don't want to end up

22:04.440 --> 22:07.080
with too much noise or wasted tokens.

22:07.080 --> 22:08.720
So that's really fascinating.

22:08.720 --> 22:12.400
Before we talk about problems you haven't overcome,

22:12.400 --> 22:14.240
can you talk about some insights from that,

22:14.240 --> 22:18.840
like that inhibition signal or keeping the noise lower?

22:18.840 --> 22:20.360
What were the key insights there?

22:20.360 --> 22:22.480
Like how did you test that and figure it out?

22:22.480 --> 22:25.760
And do you have any general principles for anyone else

22:25.760 --> 22:27.840
building agents?

22:27.840 --> 22:29.680
Yeah, this is a very good question.

22:29.680 --> 22:35.120
This is also related to another question about when

22:35.120 --> 22:39.880
do you add agents to provide the feedback and when

22:39.880 --> 22:42.640
that is not helpful, right?

22:42.640 --> 22:46.720
Because I assume the noise you're talking about

22:46.720 --> 22:53.080
is when you add more agents to service for democratics

22:53.080 --> 23:00.080
or agents that try to refine what the other agent is doing,

23:00.080 --> 23:00.960
right?

23:00.960 --> 23:03.480
They serve as a channel to provide feedback,

23:03.480 --> 23:07.360
but sometimes not feedback can be misleading and actually

23:07.360 --> 23:12.600
prevent the original agent doing the right thing.

23:12.600 --> 23:13.920
Yeah, we do observe that.

23:13.920 --> 23:17.760
And also, it's not like the more agents, the better.

23:17.760 --> 23:19.720
It's not necessarily that.

23:19.720 --> 23:23.400
For example, if you use GPD4 as the back end

23:23.400 --> 23:28.240
for an assistant agent, for a large number of problems,

23:28.240 --> 23:31.480
you'll need a simple two-agent workflow.

23:31.480 --> 23:34.840
One assistant agent, another user proxy agent.

23:34.840 --> 23:36.240
Yeah, probably I need to explain what

23:36.240 --> 23:37.840
the user proxy agent is.

23:37.840 --> 23:40.440
Basically, it refers to what I meant earlier

23:40.440 --> 23:43.920
about automating some of the work that human does.

23:43.920 --> 23:46.000
For example, using tools to execute

23:46.000 --> 23:48.720
Python code or run some predefined functions.

23:48.720 --> 23:54.080
So if you use one GPD assistant agent to suggest a solution

23:54.080 --> 23:56.720
such as code or function and use another user proxy

23:56.720 --> 24:00.520
to execute them and just provide feedback back and forth,

24:00.520 --> 24:04.080
you can solve a large number of problems very well.

24:04.080 --> 24:06.760
And some of them are also complicated

24:06.760 --> 24:08.680
and can involve multiple steps.

24:08.760 --> 24:13.960
But if you use GPD3.5 turbo, then it's much less

24:13.960 --> 24:15.760
to work in this way.

24:15.760 --> 24:18.920
So adding more agents will be much more helpful.

24:18.920 --> 24:22.120
And even for GPD4, when the problem complexity

24:22.120 --> 24:26.280
goes above a certain level, it stops

24:26.280 --> 24:29.120
to follow the main instructions.

24:29.120 --> 24:31.720
But because of the trick for one single agent to work,

24:31.720 --> 24:35.680
it actually puts a lot of careful instructions

24:35.680 --> 24:38.360
in the system message and make it

24:38.360 --> 24:42.800
know how to deal with some complex situations.

24:42.800 --> 24:47.120
But we noted that if you put too many of them, even for GPD4,

24:47.120 --> 24:51.160
and for complex tasks, start to forget these instructions

24:51.160 --> 24:55.000
and not do things as you want.

24:55.000 --> 24:58.880
Otherwise, you can just give it a simple instruction

24:58.880 --> 25:02.000
to say, try your best to solve the hardest problem

25:02.000 --> 25:04.960
and then it will be done.

25:05.000 --> 25:05.880
We're not there yet.

25:05.880 --> 25:07.520
I mean, in the future, we may.

25:07.520 --> 25:11.280
This makes me want to bring up one interesting kind of law.

25:11.280 --> 25:15.760
We, a few of us, came up called Kabuchi's law.

25:15.760 --> 25:18.960
The law has some similarity with,

25:18.960 --> 25:21.920
it's an analogy of the Conway's law in software engineering.

25:21.920 --> 25:23.920
I'm not sure if you familiar with that notion.

25:23.920 --> 25:24.920
No.

25:24.920 --> 25:27.760
So Conway's law basically saying the complexity

25:27.760 --> 25:31.920
of the software or the architecture of the software

25:31.920 --> 25:35.000
is a reflection of the organization

25:35.000 --> 25:38.040
that makes the software, that builds the software.

25:38.040 --> 25:38.440
OK.

25:38.440 --> 25:38.840
Makes sense.

25:38.840 --> 25:39.200
Yeah.

25:39.200 --> 25:43.480
So our Kabuchi's law says the model complexity

25:43.480 --> 25:47.200
will affect the model capacity or capability.

25:47.200 --> 25:50.720
We change the topology of the ideal multi-agent solution.

25:50.720 --> 25:53.400
It's a summarization of what I mentioned earlier.

25:53.400 --> 25:56.040
If you use a more powerful model,

25:56.040 --> 26:01.000
then likely you can use simpler topology of multi-agents

26:01.040 --> 26:04.120
to solve a common task and vice versa.

26:04.120 --> 26:06.840
And also, I think we need more and more research

26:06.840 --> 26:09.040
to understand this better as it's not soft.

26:09.040 --> 26:13.680
I'm seeing people trying all different kind of topologies

26:13.680 --> 26:15.600
or communication patterns for different applications.

26:15.600 --> 26:17.760
They're very creative.

26:17.760 --> 26:22.320
And what we had to figure out is what is the best topology

26:22.320 --> 26:25.520
and for a particular model and for a particular application

26:25.520 --> 26:28.440
in a kind of a very clear way to answer that question.

26:28.440 --> 26:29.600
We were not here.

26:29.640 --> 26:33.360
And this is one of actually a big challenge

26:33.360 --> 26:35.800
or a big important problem we want to solve.

26:35.800 --> 26:36.880
Yeah, next.

26:36.880 --> 26:37.680
Yeah.

26:37.680 --> 26:40.000
No, I mean, well, first, thanks for sharing

26:40.000 --> 26:42.320
some of those critical insights.

26:42.320 --> 26:44.920
And so I guess the general principle

26:44.920 --> 26:49.200
is the smarter the underpinning model,

26:49.200 --> 26:52.160
the simpler the topology can be because the more complex

26:52.160 --> 26:53.280
the instructions can be.

26:53.280 --> 26:55.680
And the more complex the tasks that an individual agent

26:55.680 --> 26:58.040
can carry out.

26:58.080 --> 26:59.760
Saying it out loud, it seems kind of obvious,

26:59.760 --> 27:02.280
but that's a good rule to generalize.

27:02.280 --> 27:06.120
So yeah, I guess let's pivot into what are some of the remaining

27:06.120 --> 27:06.600
problems?

27:06.600 --> 27:10.520
What are your biggest challenges that you either are working on

27:10.520 --> 27:12.920
or are going to be down the road?

27:12.920 --> 27:14.920
You mentioned topologies, like figuring out

27:14.920 --> 27:16.680
what is the correct topology.

27:16.680 --> 27:19.440
And of course, I can imagine that it's a moving target

27:19.440 --> 27:22.440
because as the underlying models change, almost

27:22.440 --> 27:25.760
on a monthly basis, you get new and different capabilities

27:25.760 --> 27:28.640
that kind of maybe send you back to the drawing board

27:28.640 --> 27:30.280
sometimes.

27:30.280 --> 27:33.520
Yeah, this is why having a framework that

27:33.520 --> 27:38.240
is versatile and that is flexible to do the experiments

27:38.240 --> 27:44.200
is so crucial to kind of do the fast adaptation

27:44.200 --> 27:49.280
as model moves as prominent techniques advances

27:49.280 --> 27:53.040
and as more and more small model specialized models are

27:53.040 --> 27:55.160
available, they will probably also

27:55.160 --> 27:59.480
change a lot about what was the best way to build

27:59.480 --> 28:01.040
the applications.

28:01.040 --> 28:05.440
Yeah, so this is, I think, the big value of autogen.

28:05.440 --> 28:08.320
And for unsolved research questions,

28:08.320 --> 28:12.800
there are some concrete ones I can give you a few examples.

28:12.800 --> 28:16.640
One is about this decomposition problem.

28:16.640 --> 28:20.560
As we mentioned earlier, we want to be

28:20.560 --> 28:24.360
able to achieve a state where the human can only

28:24.360 --> 28:30.480
need to specify rapidly big ambitious goal

28:30.480 --> 28:32.720
and underneath, we want the agent

28:32.720 --> 28:38.120
to be able to decompose that into solvable problems, probably

28:38.120 --> 28:41.640
multiple layers, and eventually recompose it

28:41.640 --> 28:45.720
and solve each of them and recompose it.

28:45.720 --> 28:47.880
And during this process, there are situations

28:47.880 --> 28:50.840
where the human need to provide the correct specifications

28:50.840 --> 28:54.440
because the initial one can be ambiguous.

28:54.440 --> 28:57.160
And we want the human to only provide

28:57.160 --> 29:00.040
the necessary and make a minimal kind of necessary

29:00.040 --> 29:03.200
qualifications and instructions and that agent

29:03.200 --> 29:06.080
to figure out the rest of them.

29:06.080 --> 29:09.520
That is a big challenge because if we want to solve

29:09.520 --> 29:12.680
more complex problems, we have to have a principal way

29:12.680 --> 29:15.200
to do this.

29:15.200 --> 29:18.320
And the second question also ready to do this

29:18.320 --> 29:21.920
is as we solve bigger and bigger problems,

29:21.920 --> 29:28.240
how do we do proper validation of the intermediate results?

29:28.240 --> 29:30.320
Because we don't do that.

29:30.320 --> 29:34.560
If possible, the agent will stick to some wrong intermediate

29:34.560 --> 29:40.040
results and just keep doing, keep wasting their work.

29:40.040 --> 29:44.600
And at certain time, if we need to provide validation

29:44.600 --> 29:47.560
or use agent to do self-validation, that's hard.

29:47.680 --> 29:52.440
But I do a way to do it.

29:52.440 --> 29:56.160
So we need probably into some formal language

29:56.160 --> 30:02.400
or formal way to do this proper validation

30:02.400 --> 30:05.920
so that the automation can indeed happen in a way

30:05.920 --> 30:09.920
that human desires.

30:09.920 --> 30:14.120
Yeah, so these are some just two kind of concrete pieces

30:14.120 --> 30:15.720
like problems.

30:15.720 --> 30:18.880
Yeah, in my project, we almost started in the reverse

30:18.880 --> 30:23.280
where we started with oversight of steering and oversight

30:23.280 --> 30:25.000
and supervision.

30:25.000 --> 30:30.760
So I'm curious, what's your perception or research

30:30.760 --> 30:33.200
or findings with respect to?

30:33.200 --> 30:36.960
Because you already mentioned having an assistant agent

30:36.960 --> 30:41.160
and then also having kind of a top-down hierarchical agent

30:41.160 --> 30:43.120
where you've got subordinates.

30:43.120 --> 30:45.000
What do you think about my intuition

30:45.000 --> 30:51.320
that working towards having supervisors steering QA quality

30:51.320 --> 30:55.520
assurance agents throughout the network of agents

30:55.520 --> 30:57.880
that are capable of providing some of that feedback

30:57.880 --> 31:00.160
that you mentioned earlier, is that kind of the direction

31:00.160 --> 31:00.880
that you're going?

31:00.880 --> 31:03.280
Or have you tried that and it didn't work?

31:03.280 --> 31:05.960
Or what are your thoughts in terms

31:05.960 --> 31:10.280
of having some of those specialized roles or personas

31:10.280 --> 31:13.040
as a way to help along?

31:13.040 --> 31:17.760
Yeah, there are some examples that work pretty well.

31:17.760 --> 31:19.800
I can show some of them.

31:19.800 --> 31:24.640
One is a three-agent setup to solve a multi-agent coding

31:24.640 --> 31:25.800
scenario.

31:25.800 --> 31:28.600
The application is for a supply chain optimization.

31:28.600 --> 31:31.440
It's done by another MSR team.

31:31.440 --> 31:34.560
But that solution, in my view, is quite generic.

31:34.560 --> 31:37.400
It's not restricted to that particular application.

31:37.400 --> 31:41.480
And the setup is like, it's a hierarchical setup.

31:41.520 --> 31:43.200
There's the commander on top.

31:43.200 --> 31:47.120
There's a writer who is responsible in writing Python

31:47.120 --> 31:47.920
code.

31:47.920 --> 31:51.360
The agent can also have access to some proper tools,

31:51.360 --> 31:53.040
like organization tools.

31:53.040 --> 31:57.200
And the other subagent is actually Safeguard.

31:57.200 --> 32:00.720
Safeguard is in charge of reviewing code safety.

32:00.720 --> 32:03.080
So the way it works is that the commander receives

32:03.080 --> 32:04.280
some user's question.

32:04.280 --> 32:08.400
It will first ask the writer to write the code.

32:08.400 --> 32:10.680
And after receiving the code, it will ask the Safeguard

32:10.680 --> 32:12.880
to review the code for safety.

32:12.880 --> 32:15.680
And only if the safety criteria is met,

32:15.680 --> 32:19.880
it will round the code and send the result back.

32:19.880 --> 32:23.840
Otherwise, it will just ask the writer to rewrite the code.

32:23.840 --> 32:27.120
And this can go back and forth because there can be errors.

32:27.120 --> 32:31.080
So when you debug, the writer can do that.

32:31.080 --> 32:34.080
Until the result is correct, the writer

32:34.080 --> 32:36.520
comes back with a final natural language answer

32:36.520 --> 32:37.400
to some result.

32:37.400 --> 32:39.800
And the current return that to user.

32:39.800 --> 32:45.280
So this is almost a quite simple multi-agent setup,

32:45.280 --> 32:49.400
but very effective in our application, almost 100%

32:49.400 --> 32:51.920
correct every time.

32:51.920 --> 32:57.040
One kind of lesson is if we merge the capability of the writer

32:57.040 --> 32:59.600
and the Safeguard into one agent,

32:59.600 --> 33:02.840
it doesn't work that well, especially in the code safety

33:02.840 --> 33:04.560
part.

33:04.600 --> 33:08.640
So we have the experiments in our paper.

33:08.640 --> 33:13.680
We found that if you merge them, then the accuracy

33:13.680 --> 33:18.240
for detecting code safety issue will drop significantly,

33:18.240 --> 33:21.000
both for GP4 and GP3.5 Turbo, but more

33:21.000 --> 33:23.840
significantly for GP3.5.

33:23.840 --> 33:28.720
So this kind of hints that one agent,

33:28.720 --> 33:31.880
if you ask to both suggest a solution

33:31.880 --> 33:36.240
and check the solution suggested by itself,

33:36.240 --> 33:38.840
have a bias.

33:38.840 --> 33:42.360
But we separate them and also prevent them

33:42.360 --> 33:45.160
to talk to each other, kind of make

33:45.160 --> 33:47.640
them work in an adversarial setting.

33:47.640 --> 33:49.400
It does it better.

33:49.400 --> 33:51.640
So that is one observation.

33:51.640 --> 33:54.360
But we also have other kind of scenarios

33:54.360 --> 33:57.840
where we do involve every agent in one group chat.

33:57.880 --> 33:59.920
So everyone also sees other's message

33:59.920 --> 34:02.200
and can reply back.

34:02.200 --> 34:06.040
It also works sometimes for other tasks.

34:06.040 --> 34:11.120
For example, a critique to suggest a visualization

34:11.120 --> 34:13.600
criteria for a visualization task.

34:13.600 --> 34:18.880
You can have one agent write code and another to criticize.

34:18.880 --> 34:19.720
It sort of works.

34:19.720 --> 34:24.520
But my intuition is still that if we put every agent work

34:24.560 --> 34:28.480
together always in a group chat, it may not always work

34:28.480 --> 34:30.640
because they may have the tendency

34:30.640 --> 34:37.160
to agree with each other and try hard to challenge.

34:37.160 --> 34:42.200
I would say it's case by case for different applications.

34:42.200 --> 34:45.760
There's also some benefit of doing it in this group chat

34:45.760 --> 34:47.760
because it's relatively simple.

34:47.760 --> 34:50.600
You don't need to do very hard about handling

34:50.600 --> 34:53.440
the message separation.

34:53.440 --> 34:55.480
You can simply define your agents

34:55.480 --> 34:58.920
and put them in a group chat and get them running quickly.

34:58.920 --> 35:00.200
So that's one benefit of group chat

35:00.200 --> 35:02.600
and seeing many people are using that approach.

35:02.600 --> 35:07.080
But just to be careful that it may not always

35:07.080 --> 35:11.160
work because of the limitations of the models.

35:11.160 --> 35:13.360
So that's really fascinating to me.

35:13.360 --> 35:15.920
And my intuition was the same.

35:15.920 --> 35:18.280
But it's interesting to have that validation

35:18.280 --> 35:19.520
from another perspective.

35:19.520 --> 35:23.120
So it's almost like even though the underlying model

35:23.120 --> 35:27.160
is GPT-4 running all of the agents or 3.5 turbo,

35:27.160 --> 35:33.080
there's still a positive effect from using division of labor,

35:33.080 --> 35:34.720
which the division of labor comes

35:34.720 --> 35:38.320
from the history of human work.

35:38.320 --> 35:42.000
And so just taking a moment, obviously these models

35:42.000 --> 35:43.320
do not work like human brains.

35:43.320 --> 35:47.720
But when you have an agent with a very specific task and mission

35:47.720 --> 35:51.360
and set of success criteria, that effectiveness

35:51.400 --> 35:54.120
of the division of labor still helps,

35:54.120 --> 35:57.160
even though it's just activating the latent capabilities

35:57.160 --> 35:59.480
within the same underpinning model.

35:59.480 --> 36:02.320
And then another intuition or a principle

36:02.320 --> 36:07.440
that I want to reiterate is the idea that, in some cases,

36:07.440 --> 36:10.960
group work makes sense, but in some cases, it doesn't.

36:10.960 --> 36:13.680
It's almost like the same difference in humans

36:13.680 --> 36:18.800
where the power of introverts, doing solo work on your own

36:18.800 --> 36:20.920
versus doing collaborative group work.

36:20.960 --> 36:23.840
So again, not saying that they're operating like humans,

36:23.840 --> 36:26.680
but it's really interesting to see some of these parallels

36:26.680 --> 36:32.800
emerge between multi-agent work and the nature of human labor.

36:32.800 --> 36:35.680
So yeah, very fascinating.

36:35.680 --> 36:39.560
And it's interesting because in some of the conversations

36:39.560 --> 36:42.400
that I've had and some of the observations that I've made,

36:42.400 --> 36:44.640
it's almost like what we're doing with these agents,

36:44.640 --> 36:49.040
these groups of agents, is recreating a corporation.

36:49.040 --> 36:51.680
You might have a CEO or a boss or a supervisor,

36:51.680 --> 36:54.160
and then you have the coder and then the QA.

36:54.160 --> 36:56.480
So it's a very similar structure.

36:56.480 --> 37:00.280
So do you have any other major insights or lessons

37:00.280 --> 37:04.200
that you think are either recently or super valuable

37:04.200 --> 37:05.960
that you want to share with other researchers

37:05.960 --> 37:07.960
or that you would recommend?

37:07.960 --> 37:08.720
Sure, sure.

37:08.720 --> 37:10.520
There are so many of them.

37:10.520 --> 37:15.120
I can give you a few examples.

37:15.120 --> 37:20.400
One thing is the chat, the conversation perspective.

37:20.400 --> 37:25.840
I mentioned earlier that chat GPD is a big inspiration.

37:25.840 --> 37:27.560
Certainly for many people.

37:27.560 --> 37:30.680
But for me, there's a personal story

37:30.680 --> 37:34.120
about what specific user I felt from it.

37:34.120 --> 37:38.240
It's a reminder of something I learned back in my college

37:38.240 --> 37:44.000
from a professor who told me that conversation is a provable

37:44.000 --> 37:49.840
way of making a good progress of learning.

37:49.840 --> 37:55.240
I don't remember the exact quote of that, but it's roughly that.

37:55.240 --> 37:59.120
So basically, he's trying to say, conversation

37:59.120 --> 38:03.640
is a very powerful form of either learning or making

38:03.640 --> 38:09.120
progress, or et cetera, that many people didn't realize

38:09.120 --> 38:11.680
it's how important it is.

38:11.680 --> 38:15.640
And there are some theoretical roots there.

38:15.640 --> 38:21.080
So that's one reason I'm so kind of so sure,

38:21.080 --> 38:25.920
or so I have so much belief in using conversation

38:25.920 --> 38:32.360
as the central medium of the command multi-agent interface.

38:32.360 --> 38:37.040
Again, I know there's a science, although I didn't have time

38:37.040 --> 38:39.680
to find out which reference it was.

38:39.680 --> 38:45.600
But I know that, so it gave me the confidence or the belief

38:45.600 --> 38:47.560
that this is the right thing to do.

38:47.560 --> 38:50.240
I think one of my favorite courses,

38:50.240 --> 38:52.320
Jimmy actually found me some reference

38:52.320 --> 38:55.000
from a social scientist.

38:55.000 --> 38:57.440
He mentioned something similar to that.

38:57.440 --> 39:02.880
Yeah, so this is one lesson, one kind of unique thing

39:02.880 --> 39:06.320
that I don't think many people have really.

39:06.320 --> 39:10.640
They kind of understand chatGVT is very powerful,

39:10.640 --> 39:13.840
and also get a lot of useful experience from that.

39:13.840 --> 39:17.960
But maybe this science part of it is less known.

39:17.960 --> 39:20.040
So that's one thing I would share.

39:20.040 --> 39:23.200
Another inspiration source, as I told you,

39:23.200 --> 39:26.280
so auto-gen is really inspired by many different things,

39:26.280 --> 39:29.200
many projects I've worked on before,

39:29.200 --> 39:30.680
and all the lessons I've learned.

39:30.680 --> 39:34.400
So another one, for example, is the operating system.

39:34.400 --> 39:36.440
So this is also not so obvious.

39:36.440 --> 39:40.120
When we talk about AI, why do we talk about operating systems?

39:40.120 --> 39:43.840
I think the several things, several inspiration

39:43.840 --> 39:46.520
I take from the success of operating systems.

39:46.520 --> 39:52.560
One is the idea of maximizing the utility of the most valuable

39:52.560 --> 39:55.120
resource you have.

39:55.120 --> 39:59.520
So in old days, it's like the CPU, the GPU.

39:59.520 --> 40:02.360
But I think in the new era of AI,

40:02.440 --> 40:06.840
these powerful, not even models is so valuable resource

40:06.840 --> 40:13.120
and building an operating system around them, right?

40:13.120 --> 40:15.960
And maximizing their utility, but to give them

40:15.960 --> 40:21.200
the necessary peripherals and do the right coordination.

40:21.200 --> 40:26.240
And it's super critical from the system point of view.

40:26.240 --> 40:28.840
And also, so that operating system is really

40:28.840 --> 40:31.240
you can build a platform that can support

40:31.240 --> 40:34.080
many diverse applications on top of that.

40:34.080 --> 40:38.200
So we need to design a very generic robust kind of system

40:38.200 --> 40:39.320
to do that, right?

40:39.320 --> 40:42.480
So these are all the design principles

40:42.480 --> 40:45.360
we try to use when we design AutoGen.

40:45.360 --> 40:49.880
And similarly, the idea of object-oriented programming

40:49.880 --> 40:52.440
is very useful.

40:52.440 --> 40:54.840
So many developers have very interesting ideas

40:54.840 --> 40:57.840
they want to try and develop.

40:57.840 --> 41:00.440
And now with this framework that hides a lot of complexity

41:00.440 --> 41:04.560
inside the framework, they're able to kind of do the things

41:04.560 --> 41:06.400
they want more easily.

41:06.400 --> 41:08.920
That's a part of abstraction.

41:08.920 --> 41:15.160
I already mentioned the agent, notion, automation,

41:15.160 --> 41:16.280
inspiration.

41:16.280 --> 41:19.160
The one thing I want to mention is open source, right?

41:19.160 --> 41:22.440
The concept of open source is that it

41:22.440 --> 41:26.040
can solve the common problems that community needs

41:26.040 --> 41:28.160
and make it really easy to use.

41:28.160 --> 41:33.160
So those are probably most modern kind of things

41:33.160 --> 41:37.200
that can get good open source adoption

41:37.200 --> 41:40.960
and build something that the community loves, right?

41:40.960 --> 41:43.440
Yeah, so I think that is my valuable lesson

41:43.440 --> 41:45.400
I want to share with all researchers, right?

41:45.400 --> 41:48.960
If you want to get their research adopted

41:48.960 --> 41:52.640
and get more and more impact and influence

41:52.640 --> 41:54.840
and through this open source channel,

41:54.840 --> 42:00.480
then spend a lot of effort about usability

42:00.480 --> 42:04.200
and solving the common problem that many people want

42:04.200 --> 42:08.680
to solve is what's going to be considered.

42:08.680 --> 42:11.120
I have personally found success in giving away

42:11.120 --> 42:14.400
as much valuable information and ideas as I can.

42:14.400 --> 42:18.080
That's what my whole YouTube career and computer science

42:18.080 --> 42:19.720
career is based on now.

42:19.720 --> 42:22.760
So thank you for sharing those critical insights.

42:22.760 --> 42:25.120
So on the topic of operating systems,

42:25.120 --> 42:27.040
because I'm really glad you brought that up,

42:27.040 --> 42:30.320
because I started thinking about language models

42:30.320 --> 42:33.360
as a component, like a new component of an operating

42:33.360 --> 42:34.040
system.

42:34.040 --> 42:36.600
So I'm glad to know that there's some convergence there.

42:36.600 --> 42:38.960
Is that kind of the future of Autogen?

42:38.960 --> 42:40.920
Is that what you're looking to move towards

42:40.920 --> 42:46.040
is kind of being the operating system or a major component

42:46.040 --> 42:50.680
of a future operating system that uses language models

42:50.680 --> 42:55.160
as like kind of the new CPU and maybe retrieval augmented,

42:55.160 --> 42:58.680
some kind of storage as like the new memory?

42:58.680 --> 43:01.680
Is that kind of the direction that it's going?

43:01.680 --> 43:02.400
Yeah, exactly.

43:02.400 --> 43:05.200
So it's my ambition.

43:05.200 --> 43:07.440
When I started working with Autogen,

43:07.440 --> 43:12.640
I discussed with some systems friends working on the systems.

43:12.640 --> 43:14.480
I told them this idea.

43:14.480 --> 43:18.080
And yeah, it sounds very ambitious idea to them.

43:18.080 --> 43:23.240
But I can see that some people really liked this idea.

43:23.240 --> 43:26.040
And even some 13-year people will give me

43:26.040 --> 43:28.640
stronger, strong support of this.

43:28.640 --> 43:32.520
He kind of had that idea independently.

43:32.520 --> 43:36.360
I kind of see that some of the most visionary people also

43:36.360 --> 43:37.160
realized this.

43:37.160 --> 43:42.400
And definitely, we want to pursue for that.

43:42.400 --> 43:43.280
Excellent.

43:43.280 --> 43:47.640
So taking a big step back, just in terms of the direction

43:47.640 --> 43:50.280
of research, I think, I don't know if it's official,

43:50.280 --> 43:54.680
but the rumor is right now OpenAI is working on GPT-5.

43:54.680 --> 43:57.160
And then, of course, Google with Gemini and Meta,

43:57.160 --> 44:00.240
like everyone is working on bigger and bigger models now.

44:00.240 --> 44:04.480
And so we're going to get more capabilities at the same time.

44:04.480 --> 44:06.480
Smaller models are becoming more efficient.

44:06.480 --> 44:10.200
So Satya Nadella announced small language models coming.

44:10.200 --> 44:13.840
So that way, you can probably perform very small cognitive

44:13.840 --> 44:16.480
functions, but very quickly and efficiently.

44:16.480 --> 44:19.240
So what are some of the trends that you

44:19.240 --> 44:23.680
see intersecting with your work around auto-gen and agents

44:23.680 --> 44:25.200
and agent swarms?

44:25.200 --> 44:27.040
And what I mean, I guess, to be specific,

44:27.040 --> 44:32.720
is maybe cost changing or new capabilities coming.

44:32.720 --> 44:34.880
Are there any capabilities that you're really looking for

44:34.880 --> 44:38.160
that would make your job easier?

44:38.160 --> 44:40.800
What are your thoughts on some of these new capabilities

44:40.800 --> 44:45.640
and making these multi-agent platforms more autonomous?

44:45.680 --> 44:47.400
Or is that a good idea, a bad idea?

44:47.400 --> 44:49.360
So very kind of open-ended question,

44:49.360 --> 44:53.080
like what do you see coming this time next year?

44:53.080 --> 44:57.720
Yeah, I think the idea of having specialized models

44:57.720 --> 45:01.560
to perform certain tasks in an excellent way

45:01.560 --> 45:05.560
and in a cheap way is fascinating.

45:05.560 --> 45:09.440
It's indeed worth a lot of investigation.

45:09.440 --> 45:13.400
For example, some of the hard problems I mentioned earlier

45:13.400 --> 45:17.280
about the decomposition, recombination, validation,

45:17.280 --> 45:20.160
it's possible that some specialized model

45:20.160 --> 45:22.480
can do these kind of tasks really well.

45:22.480 --> 45:23.760
Or we haven't seen that yet.

45:23.760 --> 45:28.160
But conceptually, that sounds like a possibility.

45:28.160 --> 45:33.440
Actually, I'm pretty surprised that we haven't found

45:33.440 --> 45:35.120
a special model that can solve this.

45:35.120 --> 45:39.840
So it makes me kind of wonder why.

45:39.840 --> 45:42.880
Because it's such a natural idea that if you're

45:42.880 --> 45:45.920
finding a model that can do certain things,

45:45.920 --> 45:48.240
you should be able to do certain tasks very well

45:48.240 --> 45:52.320
and you can just replace one specific agent with that.

45:52.320 --> 45:54.920
And I don't know many people are trying that.

45:54.920 --> 45:58.240
Either there's some fundamental reason

45:58.240 --> 46:03.960
we haven't figured out why we can't do that,

46:03.960 --> 46:07.920
or we should be able to see that pretty soon.

46:07.920 --> 46:10.440
I think it's only one of these two possibilities.

46:10.440 --> 46:12.360
Because the former possibility is still there

46:12.400 --> 46:16.000
because the small model, it's possible that the small model

46:16.000 --> 46:18.280
lacks some very important capability

46:18.280 --> 46:21.920
of being functioned to perform these hard tasks.

46:21.920 --> 46:23.480
Because these tasks are not easy.

46:23.480 --> 46:28.400
The composition problem, I think, even the GPD4 model,

46:28.400 --> 46:31.440
it's known to not to be too good at planning.

46:31.440 --> 46:35.200
It can do some kind of planning, but not perfectly.

46:35.200 --> 46:37.800
So if you want to get better capability than GPD4

46:37.800 --> 46:43.240
in some specialized tasks, it's to be seeing

46:43.240 --> 46:44.760
whether we can accomplish that.

46:44.760 --> 46:48.360
But if we lower the target, if we say,

46:48.360 --> 46:50.240
let's train some small models that

46:50.240 --> 46:52.840
can do something that GPD4 is already good at,

46:52.840 --> 46:56.120
that is much more amenable.

46:56.120 --> 46:59.400
I think I already see evidence of that.

46:59.400 --> 47:03.640
So then it's more like a cost reduction story.

47:03.640 --> 47:07.960
So that is, I'm pretty sure, that's feasible.

47:07.960 --> 47:11.760
And the other part about getting better capability

47:11.760 --> 47:15.520
than the big model, in some aspect,

47:15.520 --> 47:22.240
is to be kind of, yeah, we have to hold our scientific curiosity

47:22.240 --> 47:25.440
and see what happens.

47:25.440 --> 47:26.360
That makes sense.

47:26.360 --> 47:30.840
We are almost out of time, so I want to respect everyone's time.

47:30.840 --> 47:33.120
And so I'll just say, thank you so much

47:33.120 --> 47:36.200
for jumping on and sharing some of your thoughts.

47:36.200 --> 47:40.480
I'm super excited to be along for the ride.

47:40.480 --> 47:43.480
But yeah, before we close, I'll give the floor to you.

47:43.480 --> 47:47.680
Is there anything that you'd like to put out in the world,

47:47.680 --> 47:51.720
any personal requests or personal hopes

47:51.720 --> 47:55.200
that you want to want to share with a broader audience?

47:55.200 --> 47:58.000
Thanks for giving me the opportunity to do that.

47:58.000 --> 48:01.280
Yeah, I want to say that we are still

48:01.280 --> 48:04.520
early at the new age.

48:04.520 --> 48:07.560
Agents become mature software that

48:07.560 --> 48:10.400
can do a lot of things for us.

48:10.400 --> 48:12.840
We want to build the future together

48:12.840 --> 48:15.960
with everyone from the community.

48:15.960 --> 48:18.560
So give Autogeno a try.

48:18.560 --> 48:20.680
Try to use it for applications.

48:20.680 --> 48:23.520
Let us know what's working and what's not.

48:23.520 --> 48:28.200
We are very happy to work together to improve it

48:28.200 --> 48:30.840
and answer some of the big, important problems

48:30.920 --> 48:32.080
as we mentioned.

48:32.080 --> 48:36.800
And I really want to acknowledge that all the contributors,

48:36.800 --> 48:41.600
starting from the original paper to the recent,

48:41.600 --> 48:45.080
more open source resources, joined together,

48:45.080 --> 48:48.960
and the huge developer community that's supporting us,

48:48.960 --> 48:53.880
I really learned a lot from everyone who has used

48:53.880 --> 48:58.480
and provided feedback that people are super, super creative.

48:58.480 --> 49:02.720
I think this is the right way to solve the hard problems

49:02.720 --> 49:06.760
and hope to continue to do that and support the community,

49:06.760 --> 49:07.840
support everyone.

49:07.840 --> 49:11.120
And for example, the effort you're doing

49:11.120 --> 49:14.680
with the hierarchical agent swarm,

49:14.680 --> 49:18.200
it's a very good example that you're

49:18.200 --> 49:23.560
making certain bats on certain ways of making money and work.

49:23.560 --> 49:26.200
I'm very curious to see how that experiment goes.

49:26.200 --> 49:30.440
And if altering can be of any help in this or other consumer

49:30.440 --> 49:35.600
efforts, we'll be very happy to support you

49:35.600 --> 49:41.560
if you need any feature and useful infrastructure support

49:41.560 --> 49:43.320
that kind of thing.

49:43.320 --> 49:45.880
Yes, let us know.

49:45.880 --> 49:47.760
Yeah, absolutely.

49:47.760 --> 49:50.440
No, we'll be definitely looking forward

49:50.440 --> 49:53.560
to continuing the collaboration.

49:53.560 --> 49:56.120
I think that, as you said, there is a lot of work to do.

49:56.160 --> 49:57.680
And there are some limitations.

49:57.680 --> 50:00.600
The model's limitations today are the model's limitations.

50:00.600 --> 50:03.200
There's not a lot we can do to work around that.

50:03.200 --> 50:05.240
But it is just the beginning.

50:05.240 --> 50:08.640
And that's one thing that I'll use the closing to say

50:08.640 --> 50:13.040
is remember where we were a year ago today.

50:13.040 --> 50:17.600
Chat GPT was probably published just about a year ago.

50:17.600 --> 50:21.760
But before that, it was GPT-3, GPT-3.5.

50:21.760 --> 50:26.100
And the distance that we've covered in just the last year

50:26.100 --> 50:31.460
is it is a privilege to be part of one of the greatest shifts

50:31.460 --> 50:33.260
that humanity has ever seen.

50:33.260 --> 50:34.780
And some days, it doesn't feel real.

50:34.780 --> 50:36.780
And some days, it feels a little too real

50:36.780 --> 50:38.100
and a little too overwhelming.

50:38.100 --> 50:42.300
So thank you, Xi, for helping make this a reality

50:42.300 --> 50:44.540
and spending some time talking with me.

50:44.540 --> 50:47.620
And thank you to Katie for helping put this together.

50:47.620 --> 50:49.940
And yeah, so thanks everyone.

50:49.940 --> 50:53.740
And yeah, see you all next time.

50:53.740 --> 50:54.540
Thank you so much.

