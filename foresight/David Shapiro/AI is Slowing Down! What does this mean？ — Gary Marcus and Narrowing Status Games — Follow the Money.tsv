start	end	text
0	3840	David Shapiro here, your personal chief AI officer.
3840	6800	So what I wanted to do today was unpack
6800	9920	some of the recent patterns and trends
9920	11360	that we've been seeing.
11360	13660	Now I made a video recently where I talked about
13660	16840	all the reasons that I think that AI is slowing down
16840	18840	and of course I'm not the only one.
18840	22240	Now there are plenty of people who disagree with this story
22240	24840	and I'll address that in a minute with respect
24840	28600	to the potential emergence of echo chambers.
28600	31800	But first I want to address, okay, what does it mean?
31800	33560	Now that AI is slowing down,
33560	35280	or at least there are initial signs
35280	37280	that AI might be slowing down in terms of progress,
37280	39120	and that's not to say that it's stalling,
39120	42540	it's just the rate of acceleration is deteriorating.
42540	43800	So when I say slowing down,
43800	46560	that's like we're still at the very early stages
46560	49760	if this trend is reversing.
49760	51960	So the first thing is safety.
51960	54880	This is really great news for people in the safety crowd
54880	57080	because it means that the singularity
57080	59480	is not gonna happen in 2027.
59480	62560	We can kick the can down the road a little bit further
62560	64880	before we get an intelligence explosion
64880	68160	if an intelligence explosion is even possible.
68160	70060	Personally, I've started to have doubts
70060	72600	that we're gonna get those accelerating returns,
72600	75740	particularly as I've seen some new news
75740	78920	about the way that the human brain might work.
78920	81440	There is increasing evidence that the human brain
81440	83640	is not just a matter of computation
83640	86080	based on neural synaptic connections,
86080	88160	but that it could be a combination of that,
88160	90640	the electromagnetic waves that propagate across the brain
90640	92160	as well as quantum effects.
92160	95800	There is increasing evidence that human consciousness
95800	98600	and human intelligence is actually the combination
98600	101360	of several energies and several parts of physics
101360	103640	that are all working together to create that.
103640	106680	So I'm just like, hmm, maybe there's a lot more
106680	107960	to intelligence than we thought,
107960	109560	and of course there's gonna be a lot of people out there
109560	113000	saying, see, I told you so, but it is what it is.
113000	115960	And these are also just possibilities.
115960	119480	But according to this possibility,
119480	121980	it might be that there are gonna be continuing
121980	125880	diminishing returns with respect to neural networks
125880	128160	or even silicon-based computing
128160	130920	that means that it will just be increasingly difficult
130920	135720	to either reconstruct or to capture human-level intelligence.
135720	137320	And another thing that's emerging to me
137320	141080	is that we are going to see a very distinct bifurcation
141080	143860	between human intelligence and machine intelligence,
143860	147140	meaning that it's gonna be kind of like comparing apples
147140	149260	to oranges, and it really already is,
149260	150820	because we look at large language models
150820	153500	which are very clearly processing information.
153500	154820	I remember I had a conversation
154820	157380	with some philosophers a year ago or so,
157380	161060	and they made the somewhat asinine claim that,
161060	164700	oh, they don't know anything, there's no information.
164700	167160	I'm like, that's literally all that they're doing
167160	169380	is just processing information,
169380	170780	but it depends on definitions.
170780	172440	And so to these philosophers,
172440	173760	the idea that this is a machine
173760	175320	that only processes information
175320	177840	because their definition of information
177840	179440	was stuff in human brains.
179440	180560	I'm like, okay, well,
180560	182860	that's just a bad definition of information.
182860	184680	Anyways, going down a rabbit hole.
184680	186840	My point is that it really depends
186840	188160	on how you look at intelligence
188160	189960	and how you define intelligence.
189960	192040	And I really don't like those gotcha questions
192040	193680	because it's like, how do you define intelligence?
193680	196960	And it's like, I mean, it depends on who you ask.
196960	199120	There's a million definitions of intelligence.
199120	201120	And the fact that we don't have a good definition
201120	204080	of intelligence means that also, by extension,
204080	205240	we don't have a good definition
205240	207120	of artificial general intelligence.
207120	210080	And when you ask a mathematician what intelligence is,
210080	211120	they're gonna give you one answer.
211120	213440	When you ask a neuroscientist what intelligence is,
213440	215000	they're gonna give you a different answer.
215000	216840	If you ask a psychologist and a philosopher
216840	218280	what intelligence is, again,
218280	221160	they're going to give you fundamentally different answers.
221160	225240	So moving on, another thing that this is good for,
225240	226800	and this is gonna be really good news,
226800	229700	really reassuring news to many of you out there,
229700	232220	is that if AI is indeed slowing down,
232220	233980	that means that the threat to jobs
233980	236940	and the rate of change for jobs is going to be slower,
236940	239140	which means the status quo that we have
239140	241180	is going to persist a little bit longer
241180	243120	than perhaps some of us would like.
243120	244620	Now, what I do wanna address
244620	248220	is that there's gonna be mixed reactions to this.
248220	251140	So some people are like, let's just get it done,
251140	254020	like replace my job, I'm ready to get out of the workforce,
254020	258160	give me UBI and get me out of the workforce for good.
258160	259100	I don't care.
259140	260420	And other people are gonna be like,
260420	264180	well, this will give us time to create new jobs,
264180	266940	I don't wanna lose my job yet, and so on and so forth.
266940	268220	Now, if I had to guess,
268220	270580	now keep in mind that I'm speculating here,
270580	273140	and that's a lot of what I do on this channel,
273140	276140	my gut check now is that it's gonna be five to 10 years.
276140	277380	And I've talked about this before
277380	279620	where you look at the adoption curve,
279620	281560	and it's like seven years.
281560	285940	So maybe 2030, and 2030 seems to be a pretty sticky date.
285940	289020	So anywhere between 2027 to 2030
289020	290180	is when we might start seeing
290180	292140	some really drastic change out there.
292140	293500	Now, I could be wrong,
293500	296340	we could have a confluence of multiple technologies,
296340	299020	like again, I'm really waiting to see
299020	301700	how GPT-5 and robotics mix,
301700	304620	because you see the number of bipedal,
304620	307700	like humanoid robotic chassis being built around the world.
307700	311020	And like, remember, this is only gen one.
311020	315460	So GPT-5 and Claude Four and whatever else,
315460	318220	you combine that level of intelligence with robots,
318220	321580	that really could change a lot for a lot of things.
321580	322500	And I think there's,
322500	325340	I don't know if it's proven out or to what extent,
325340	328300	but I've heard that Tesla is already using their robots
328300	330060	in the Tesla factories.
330060	333580	And the economic carrot for that is really high.
333580	338420	So don't underestimate the power of that economic incentive
338420	341280	to get things really going.
341280	345100	But overall, if the advancement of AI intelligence
345100	346500	is indeed slowing down,
346540	348780	it just gives us all more time to adapt
348780	352060	on a cybersecurity level, on an economic level,
352060	353580	on a military level.
353580	354680	So it means that, you know,
354680	359680	your life is not gonna get upended soon, hopefully.
360460	363340	So this leads me to want to address another thing.
364740	367100	About what, 12 months ago, a little bit more,
367100	370700	I predicted that we would have AGI by September 2024.
370700	372820	So that's just a few months from now.
372820	375060	Now, what I was looking at at the time,
375060	377060	and, you know, if you go back and watch my videos,
377060	378580	there's a whole bunch of charts and data
378580	380020	that I was looking at.
380020	383540	And this is right along the curve
383540	386700	of what Ray Kurzweil originally proposed,
386700	389860	is to when we would have a human level, you know,
389860	393040	intelligence in a single computer is actually 2023.
393040	394820	So that was one piece of data.
394820	397380	I was also looking at parameter counts going up,
397380	401140	logarithmically, which they have been,
401140	402180	but they've slowed down.
402180	404300	And the one thing that I was not looking at,
404300	406620	so this is the piece of data that I did not include
406620	408340	in all of those calculations,
408340	410860	was the exponentially rising costs
410860	413660	of training subsequent generations of models.
413660	417100	So, you know, as, I think it was Dimitris Abbas
417100	419460	was talking about on a podcast recently,
419460	423180	every subsequent generation from GPT-2 to 3 to 4
423180	427540	costs 10 times as much to train, if not more.
427540	429540	So while all these other things
429540	432020	are going up exponentially, so is cost.
432020	434780	And that did not figure into my calculus.
434780	437140	And so because of that, it's like, oh, well,
437140	440300	if I had thing, you know, recognize that,
440300	442180	I might have said, well, we're probably gonna get
442180	444500	diminishing returns sooner rather than later.
444500	447500	Now I have been talking about diminishing returns
447500	449340	pretty much for the life of this channel.
449340	452660	And I've been wondering, when is the jig gonna be up?
452660	454540	When are we gonna run out of steam here?
454540	457100	And it looks like we're starting to run out of steam.
457100	459700	Now again, you know, the train is still running,
459700	461900	we're still burning pretty hot,
462780	464260	but we're not accelerating anymore.
464260	468940	We are probably on a more geometric trajectory right now
468940	470180	if I had to guess.
471180	473100	And it all comes down to economics.
473100	476820	It really is just with exponentially rising costs
476820	480420	with a, we're entering into what's called a red ocean market,
480420	482780	which means it's not just, you know, a blue ocean
482780	487060	out there with its just open AI with their frontier model.
487060	490900	Lots of other models have caught up to GPT-4O,
490940	493700	Claude 3.5 Sonnet has clearly surpassed it
493700	494980	as far as I can tell.
494980	497140	Obviously people like looking at a,
497140	499260	whatever that benchmark is called,
499260	501140	I don't really give that much weight because it's,
501140	503620	that seems like it's mostly a popularity contest
503620	506860	and open AI still has a lot of fanboys,
506860	509640	but doing a side-by-side comparison of capability
509640	512900	between chat GPT-4O and Claude 3.5,
512900	517100	it is hands down Claude 3.5 is in another league
517100	518140	as far as I can tell.
518140	519580	Now obviously a lot of you out there
519580	521060	use it for different things.
521060	523420	So, you know, it is gonna,
523420	525980	it's gonna depend on your use case.
525980	527460	Another thing that I've noticed is that
527460	529180	there's been fewer breakthroughs.
529180	533260	So like, yes, chat GPT-4O has the voice mode,
533260	535380	which is really, you know, okay, cool,
535380	537860	like it can do a sultry voice and sound effects,
537860	539100	which is great.
539100	543260	But that was a predictable addition with multimodality,
543260	546460	where it's like, okay, text and audio, great.
546460	550580	This is still leaving a huge swath of economic interests
550580	553380	and intellectual interests completely untouched.
554500	555580	Take math for instance,
555580	557500	they still haven't figured out math and physics
557500	558880	and those sorts of things.
558880	563880	And also after playing around with the ARC AGI test,
564540	568060	yes, I have not been a fan of the ARC AGI test,
568060	570900	but at the same time, like it does prove a point.
570900	573280	It does prove a point that the kind of reasoning
573280	575440	that these things do is still very different
575440	576660	from human reasoning,
576660	578200	which is another reason that I'm talking about
578200	580200	a bifurcation of intelligence.
580200	581960	That we might be, and this is again,
581960	583900	as pure speculation on my point,
583900	586840	we might be getting to a point where
586840	589240	we're starting to recognize, okay,
589240	591720	this machine is kind of an alien intelligence.
591720	594320	It clearly has its own consistent way
594320	595860	of approaching the world,
595860	597980	but it is also very different from us.
597980	600220	Now, Bill Gates was on a podcast recently saying
600220	602800	that metacognition is gonna be the next step.
602800	604840	Okay, sure, I mean, I've been working on cognitive
604880	606400	architectures for a while,
606400	608000	and there are some really sharp people out there
608000	610840	that figured out how to give models metacognition
610840	613120	a while ago, it's really just down to prompting.
614480	616240	You can give, for instance,
616240	618520	especially with these gigantic context windows,
618520	621320	you can give one sec, one model say,
621320	623720	hey, you're a metacognitive agent
623720	625360	that's viewing these other thoughts.
625360	626760	Tell us what you think about it.
626760	628360	Help steer it on moral course.
628360	631040	This was entirely all of my work on the ACE framework,
631040	633600	the autonomous cognitive entity framework,
633600	636200	which I did abandon because Microsoft Autogen
636200	640200	and other platforms far surpassed what I could do
640200	643440	on my own, even with help from people on the internet,
643440	644400	because why it's Microsoft,
644400	646600	and they have a lot more money than I do.
647560	649920	Now, that leads me to another point that I wanna address,
649920	651400	and that is echo chambers.
651400	653720	So most of you in the audience,
653720	655720	based on the polls that I've run,
655720	657720	most of you in the audience, statistically speaking,
657720	659120	are kind of in the middle of the bell curve
659120	661280	where you're reasonable and you want the truth,
661280	664040	and you want some honest, genuine thoughts.
664040	666200	There are, however, many people out there
666200	668440	that are on more of the tail,
668440	670480	like left to right tail of the bell curve,
670480	674760	where you wanna see doom or you wanna see acceleration,
674760	678480	and you're not really interested in other narratives.
678480	680960	And the reason that I'm using the word echo chamber,
680960	683920	which is often pathologized,
683920	686760	is because there have actually been a few people
686760	689160	that did directly express to me
689160	691360	they did not want an alternative narrative.
691360	695400	They only wanted to double down on their personal narrative,
695400	697440	the one that they want to be true,
697440	698920	which, believe me,
698920	701880	I want to have all kinds of advancements
701880	703320	happening next year.
704200	706320	That was not hype when I said
706320	708840	that I was predicting AGI this year.
708840	711240	That was a genuine prediction on my part,
711240	713080	and I was like, man, things are happening,
713080	714160	they're accelerating,
714160	715320	but I don't believe that anymore
715320	716840	because of the data that I'm seeing,
716840	718800	because of the trends that I'm seeing.
718800	719960	And I know that that sucks,
719960	724960	like if someone is banking on a certain outcome,
725280	726920	like expectations and reality,
726920	729480	there's always a gap between expectations and reality,
729480	732800	and when that gap gets bigger, it sucks.
732800	735200	Now, some people are gonna take this news
735200	738360	and interpret it in completely unexpected ways to me,
738360	739600	and that's fine.
739600	742840	But what I do wanna caution is for the five
742840	745240	or less percent of you out there in the audience
745240	747480	that are on the tails of the bell curve
747480	750320	in terms of expectations and your disposition,
750320	752440	your valence towards this,
752440	757440	is if you broaden your narratives just a little bit,
758280	759880	then you might be surprised
759880	762160	at some of the other advantages that are happening,
762160	764480	and also just realizing that there is a silver lining,
764480	767440	is that the disruption that is coming
767440	768880	is gonna take a little bit longer,
768880	771760	which means that society will be a little bit more stable,
771760	774960	which means that the risk of catastrophic outcomes
774960	778160	or unintended outcomes goes down significantly.
778160	780600	And on the topic of those narratives
780600	782280	and those echo chambers,
782280	785160	a lot of people have asked me to comment on Gary Marcus,
785160	786720	and I've resisted until now,
787600	790560	but having gotten back on Twitter,
790560	793240	I will say that I've watched some really interesting
793240	795360	and highly vitriolic debates
795360	800360	between namely Gary Marcus, Yasha Bach, and Jan Lacoon.
801120	803200	Now, these are supposed to be the adults in the room,
803200	806040	and having watched Yasha on some interviews,
806040	808320	like he's a very sharp guy,
808320	811200	but even he got into the like, let's just beat up on,
811200	813200	let's like, what is the term that kids use these days,
813200	816040	like let's clown on Gary Marcus train,
816040	817800	and that was honestly really disappointing
817800	819360	because this is someone who's supposed to be like
819360	822040	a high brow like academic researcher,
822040	824920	and he's sharing like caricature memes of Gary,
824920	827040	which, I mean, I would never do that.
827040	829080	I don't particularly agree with Gary anymore,
829080	831240	but that was incredibly immature.
831240	833240	And then Jan Lacoon has often had this like,
833240	835800	old man yells at cloud energy,
835800	838040	which is weird because it's like,
838040	839720	half of what he says I agree with,
839720	840880	like Ferventland, the other half,
840880	842880	I'm like, where did that come from?
842880	845320	So, all right, so what happens?
845320	848480	And this is not, to be fair, taking a step back,
848480	851600	this is not a unique phenomenon in AI.
851600	854360	Some of, one of my good friends as a physicist,
854360	856640	this kind of thing happens in the physics community
856640	858200	all the time, apparently,
858200	861040	where it's like disagreements and arguments
861040	863480	over interpretations will actually like,
863480	866160	come to shouting matches and sometimes fist fights.
866160	869720	Physicists are actually pretty hardcore, it turns out.
869720	874720	So, from my reading of, you know, human nature,
874920	877400	what I, the way that I interpret this is that
877400	880040	we have a tightening status game.
880040	883360	So, Gary, Yasha, Yan, all of these people,
883360	885720	they suddenly saw themselves having much,
885720	889720	much higher social status because of artificial intelligence.
889720	891720	And so, one way to compare this is,
891720	894360	imagine you're back in high school
894360	896520	and something changes and suddenly,
896520	899360	the nerds are all the most popular kids in school.
899360	901560	Well, then something changes again,
901560	903040	and it's like, oh, well, actually,
903040	905960	instead of the top eight nerds, now it's the top five.
905960	908600	And so, three have to get kicked off the island.
908600	909800	That's what's happening.
909800	913440	And so, they're scrabbling over diminishing social status
913440	916880	because, again, with AI slowing down,
916920	920040	it's no longer as hot and sexy as it was a year ago.
920040	922000	It's no longer, you know, you can't just say,
922000	923160	hey, I was gonna kill everyone
923160	926320	and get an invitation to the TED stage anymore.
926320	927760	And so, because of that,
927760	929640	because the status game is narrowing,
929640	930680	because the number of people
930680	932760	that can be high status is going down,
932760	934680	the rules are becoming more arbitrary
934680	936880	and people are becoming a little bit more snippy,
936880	940080	a little bit more vitriolic, as I said.
940080	942760	The stakes go up because the risk of losing status,
942760	944760	especially, this is what we saw with Ilya.
944760	946080	I talked about this extensively.
946080	949480	The reason that Ilya was socially canceled with an open AI
949480	952440	is because he made the cardinal sin
952440	953960	of attacking Sam Altman,
953960	956760	even though he was doing it for what he believed
956760	958880	was the right reasons,
958880	961120	that was a violation of the social norm,
961120	963300	which is Sam Altman is king.
963300	966000	And of course, Sam Altman, as a power seeking person,
966000	968440	was not going to tolerate that.
968440	970040	Consciously or unconsciously,
970040	971360	that was just never going to,
971360	972920	he was never going to tolerate it.
972920	974880	So what happens is,
974880	976680	other AI commentators out there,
976680	978960	namely Gary, Yasha, and Yan,
978960	980520	are doubling down on their narratives,
980520	983480	because basically they're gonna be doubling down
983480	985480	on the narratives that got them that social status
985480	987180	in the first place.
987180	990320	And that is my read on the situation.
990320	992440	And also, I take that as evidence
992440	994240	that AI is slowing down,
994240	997360	because again, if AI is running out of steam,
997360	999760	then the amount of space
999800	1003120	that the public square needs of AI commentators
1003120	1004080	is going down.
1004080	1005360	It's also been a year and a half
1005360	1007440	since Gary Marcus was in front of the Senate.
1007440	1010400	And have you seen him or heard him any other place?
1010400	1014000	No, like his 15 minutes of fame might be over,
1014000	1016880	and that sucks, like that doesn't feel good.
1016880	1020320	It does not feel good to feel like you're being left behind
1020320	1022480	by the conversation or by society,
1022480	1025600	which is to me, an explanation as to why Gary
1025600	1029120	has been so incredibly salty lately.
1029160	1031440	And then of course, other people
1031440	1033800	that are not as aware of these status games
1033800	1035140	will jump in on bullying,
1035140	1038840	because if you show weakness in a high-stakes status game,
1038840	1040800	people will unconsciously,
1040800	1043760	it's tall poppy syndrome and a number of other phenomenon,
1043760	1045760	people will unconsciously jump in on that
1045760	1047800	and say, ah, time to bully that person,
1047800	1051640	because they're signaling that their status is vulnerable.
1051640	1053800	So that's my read on the whole situation.
1053800	1055920	And yeah, it's not ideal, it's not what I hoped,
1055920	1057320	it's not what I predicted,
1057320	1061680	but I ignored the numbers, I ignored the money, right?
1061680	1065880	Like, and hindsight, that was pretty dumb.
1065880	1069000	So am I still predicting September 2024?
1069000	1072360	Again, this is where I'm gonna double down on my narrative.
1072360	1074280	I think that GPT-5 plus robots
1074280	1077140	will surprise a lot of people with what it's capable of.
1077140	1078880	Is it gonna replace all of us?
1078880	1081240	No, it's gonna be like the Nestor class four
1081240	1083080	from iRobot, where it's like,
1083080	1086320	it's capable of running your mail for you automatically,
1086320	1088200	but not much else.
1088200	1089260	That's kind of what I predict.
1089260	1090960	So it's like, you know, you can get rid of like,
1090960	1094240	maybe some warehouse workers, some factory workers,
1094240	1096820	some mail carriers, but it's not gonna like,
1096820	1098080	upend the whole economy.
1098080	1099680	So, all right.
1099680	1102880	This has been your first episode of David Shapiro,
1102880	1105600	your personal chief AI officer.
1105600	1107560	Let me know how you think this went in the comments
1107560	1108560	and I'll see you next time.
1108560	1109400	Cheers.
