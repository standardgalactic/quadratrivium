{"text": " going live. All right, I think we're here. Can y'all hear me now? Can you hear me now? Hello? Is this thing on? Okay. It says live in 15 seconds. Okay, we're good. Yay! Okay, make sure to mute myself. All right, so hello everybody. I'm still figuring out the whole live streaming thing, so please bear with me, but one thing that y'all said was that you want to like see what I'm looking at, which you know, it's a good idea. You don't want to just look at my face. It's like, let's look at stuff together. So I figured I'd follow more or less the same format that I usually do. I'm in the cognitive AI lab discord, so if you're in the general, you can drop questions here or papers. So basically what I thought we would do is we would take a look at like weekly updates, because it's all going really fast. And you, I've got a lot of feedback from my recent live streams, that y'all really liked the interactive aspect of like asking questions, and like Dave, what does this mean? And so please feel free to drop good questions in. I'm also in the private Patreon discord, so drop questions there too. Okay, cool. Party time, yeah. Oh, looks like there's a delay of about 15 seconds. Interesting. Okay. Cool. Flippy from the dais discord. Hello Flippy. All right. Cool. So while some questions get spooled up, I figured I'd go through a couple of tools and stuff that I've seen. So someone, I think actually Flippy, this might have been you or someone in the dais discord, pointed out this tool. So this is basically something that I and others have been like thinking about and talking about. It's basically a hybrid of vector database and knowledge graphs. And it's also got a pretty interface. So like, it's worth just scrolling through and like reading every every bit of this. And then kind of experimenting with it. But but it will create. So this is one of the coolest things is it'll create a knowledge graph of all the clusters and stuff. But you can find the gaps, which when you're thinking about autonomous or semi autonomous AI agents, this is really good because then you can know what you don't know. And what I mean by that is if you're aware of all the things that you know, but you can detect some semantic gaps in your knowledge, that can help you zoom in on the things that you need to go learn about. So in front notice is the tool in front notice.com. I can never remember the name of the darn thing. I'm going to blame allergies and say that it's just brain inflammation. That's my excuse and I'm sticking to it. But yes, so this is a super cool tool. This kind of technology will definitely be part of of like autonomous AI agents. And this is functionally similar to what I worked on with Remo. Remo is much, much, much simpler though. So I often have some people ask me like, Oh, hey, can Remo do this? And that and I'm like, no, like, Remo was meant to solve one very specific problem. So for memory stuff, I usually point people at llama index and chroma db. So chroma db. Do I seriously not have that bookmarked? So chroma db is a vector database that runs just like SQLite. So it's pip install chroma db, you create a local client just like you do SQLite. So I tried to create something like this called VDB light like a few months ago. And I quickly realized that I was in way over my head. So I'm glad someone built this. And they just got an $18 million seed round. Holy mackerel. Man, I should have stuck with VDB light. I could have had an $18 million seed round. Anyways, maybe I'll do that with Remo who knows. So chroma db, super simple man, seriously $18 million for this one thing. Okay, I'm gonna let that go. llama index also. So llama index, I kind of didn't pay it any any attention at first because it's like, Okay, that's a silly name. This was clearly just someone's little side project. But if you look at all the types of indices they have, they've got list index, table index, tree index. So Remo is very similar to llamas tree index. Although I will say that I look through the code. And I think that their tree index is kind of basic. I think that my Remo framework does a little bit that theirs doesn't. But I'm not going to dive into that because I don't know that for certain. I didn't take a super close look at the code. Yeah, but so those are those are some memory storage tools. So let me check on the live stream and see where we're at. Whoops. All right. Oh, wow, we got lots of questions. Okay, cool. God's not dead rather believe and go to the good place and interesting. Okay. Let's see how to discover new wisdom from LLM. That's an interesting question. Um, let's see. Let me, you people ask questions far too early. Let me go over to discord to see if, yeah, please go ahead and drop some questions. Patreon get first dibs. All right. What do you think is the future of SAAS sales jobs for recruiting agencies? Oh, sales jobs and for recruiting agencies. So I mean, the sales level is still very human. So sales is not going to change for a while. Ditto for recruiting, although there's a lot of AI and recruiting already where like AI will read your resume and AI will watch a video of you answering questions. You know, more and more of that's coming, but that's about it. Let's see. All right. We got a whole bunch of questions coming in on the Patreon side. So, yeah, database, short answer, diversify your job skills. So there's that. Let's see. Zoom in a little so you guys can read this. Let me jump back over here real quick. But do you still expect AGI within 18 months was stating they do not want to make models bigger but rather more efficient? Yeah, I think AGI in 18 months is still conservative. Honestly, I think that we will have, as people develop the architecture for autonomous AI, I think that we will be able to say that we have AGI by the end of this year. But people will realize that it's like, okay, we have an agent that can do anything, but it's expensive or it's slow or it's kind of dumb, that kind of thing. Let's see. Check on Discord real quick. Is her about to become reality? Yeah, lots of people are working on AI companions. They're going to get more sophisticated real fast. I've actually got a couple more videos upcoming planned. So I've got the Westworld video coming up on Sunday. I've got a Ghost in the Shell video planned. I've got a Mass Effect video planned. I've got a Dow and Blockchain video planned. So that's all what's coming. Maybe I shouldn't spoil it. Okay, well, whatever. But yeah, so I was thinking about hitting on her and Ex Machina and stuff as well. Let's see. How can we be certain things are advancing exponentially? So that's a good question, James. Generally speaking, you can't tell if you have a narrow window, but we were joking around the other day and we're pointing out that like a few weeks ago, it was like you would reasonably expect a couple of cool AI bits of news per week, and now we're at the point where we expect several per day. Now, it might come in cycles, it might come in waves, but generally speaking, this very closely matches what Ray Kurzweil said, or maybe it was Michio Kaku on a video, a documentary that I watched quite a few years ago. I think it was Michio. He was describing what it will feel like to approach the singularity, and he said, oh, well, when information is doubling every two years, you don't really feel that on a day-to-day basis. And then when information is doubling every six months, that's fast enough that you're like, oh, hey, this thing that I didn't think would be solved for another couple years was solved this year. And then, but as it ramps up faster and faster, that time keeps having. And so then three months after that, you realize, oh, wait, we've advanced again. And I think we're right at that, like, that three, you know, where six months ago, we're like, oh, this stuff is 10 years away. Six months later, we're like, this stuff is 10 months away. So I think that where you could make a good argument that we're in some respects, we're in the exponential ramp up right now. That being said, some of this information is so big, and it's changing so fast, it's difficult to measure. We'll actually need AI to measure the rate of papers and tools. All right, so Seaf, you said, how do you think AI will impact religion, particularly monotheistic religions? I think it will create a mass crisis of consciousness, which will make the transition period even more chaotic and extreme. Yeah, no, sorry, Seaf, I was getting around to it. Yeah, so I've actually had some interesting internet debates with more conservative and more religious people. Granted, I don't do internet debates anymore. I got that out of my system. And I try not to get suckered into it, if I can. But, you know, one debate that I had many years ago was, you know, if aliens showed up, wouldn't it prove your religion wrong? This was a debate. I wasn't arguing as a debate that I observed. And the religious person said, no, why would it? And, you know, they rationalized it, saying, well, you know, why would God put, you know, aliens in the Bible if we wouldn't be able to understand it back then? It's not for us to understand. And so some religious folks do have a really good ability to compartmentalize. And so, like, just because you have a, like, like a super intelligent machine, some people would be like, so it doesn't have a soul. And that's the end of the discussion. So I don't, I don't particularly perceive, and I'm not saying that this is good or bad, right? I am not in the Judeo-Christian faith. I have my spirituality as other, other places. I have some, like, some of my best friends in my local community and my internet friends are deeply religious, you know, followers of Christ and whatever. And so, like, in many cases, I don't think it's going to be that big of an issue. Let me jump over to the Patreon. Oh, wow, we've got some questions here. Okay. Backo bbzo. Sorry if I'm saying your name wrong. What would your advice be to someone just launching an AI startup? Don't. That's, that's a very flippant response. But one launching a startup is really hard. It's mostly tedium. You can have the best idea in the world. And 90% of the work is still going to be, excuse me, I'm still struggling with allergies. That's my head a headache earlier. That's part of why I canceled yesterday. Thanks, Jordan. That's how am I holding up? Actually, I'm doing okay. Mostly it's just allergies right now. But anyways, so if you're doing an AI startup, one, if you haven't done a startup before, now is a really bad time to learn. Because things are going so fast. And we're basically having to reinvent stuff as we go. Which if that's, you that's part of why I burned out is I realized like, okay, I did find it really engaging and really enjoyable. But my pace of things clashed with other people. And then like the rabbit hole just keeps getting deeper. So that's, that's kind of the thing. What I always tell people is your, your, your startup team, your founder team is most important. Be picky. If you don't have the right team, walk away early. And then also for the folks that I'm talking to is local. Because of the pace of things, you absolutely need to like see the people that you work with, in person, at least on a weekly basis, if not on a daily basis, because you need to be like sitting in the same room, just shooting the breeze, keeping each other updated in real time. Doing it remotely is probably not feasible. Unless unless you're already a really established team, and you're just going to sit in like discord all day or Slack all day. Blake Allen curious to hear your thoughts on Stanford's hyena hierarchy and how it relates to some of the work you've done with Raven and cognitive architecture. I don't know if I've heard of this one. Let's check it out real quick. Hyena hierarchy. Let's see. Let's go up to the very top. Hyena hierarchy towards larger convolutional language models. We're excited to share our latest work on hyena, a sub quadratic time layer that has the potentials to significantly increase context length and sequence models. Oh, right. I think this is the RNN integration. Yeah, yeah. In general, how can we close this gap? Yeah. In general, any individual language model is just like one cortical node. Yes, these things will be like better, more efficient cylinders in an engine, but in order to have a race car, you need the rest of the car. Again, I'm kind of really flying off the cuff right here. I'm not sure that I've got this right, but I think, yeah, RWKV. You're not going to ever get a full cognitive architecture from a single language model. Now, that being said, the big asterisk is when you look at all the studies about GPT-4 that have theory of mind and what I call implied cognition. So implied cognition is that the thing is obviously thinking through problems behind the scenes in a similar way that humans think through it. I don't mean like neurologically, subjectively, it thinks the way that we do, but GPT-4 can obviously talk itself through, kind of do chain of thought reasoning internally in one shot. And so that makes those larger, more sophisticated models make your cognitive architecture simpler, but it doesn't get rid of the need for external storage. It doesn't get rid of the need for parallel processing. It doesn't get rid of the need for loops and checks and that sort of stuff. So that's kind of my response there. Good question. Emma or AMA, I'm new here and new to this field in general, found you through Raven videos. Thank you. Regarding personal assistance, is there a reason to create a database of yourself for your future personal assistant to understand you better? So that's actually the purpose of my RIMO framework. So RIMO is meant to be a hierarchical database of your interactions with an individual agent that will surface particular topics by using, not reciprocal, recursive summarization and clustering. So you take all your raw logs, cluster them, summarize them, do that again, cluster, summarize, cluster, summarize until you end up with five to 10 parent topics that allow you to drill down. So I wouldn't, don't waste any time doing that manually, just let it happen naturally through conversation by integrating something like Lama Index Tree or RIMO. Do you think we are on track to cure brain diseases like Alzheimer's by 2030? The combination of AlphaFold and mRNA vaccines, I think absolutely. There was something else that I posted on my YouTube recently that it's like another breakthrough is happening. So I think we're very close to the point where we can halt Alzheimer's. Undoing Alzheimer's might take another little bit of time, but on the other hand, we're at the point where we're getting saltatory leaps, we're getting breakthroughs really fast, so you never know. Let's see, what are your thoughts on the generative agent stuff that has come out recently? It seems like you were pretty ahead of the curve on that stuff and has it solidified or changed the way you think about the concepts from Symphony of Thought? Yeah, so I definitely felt like I was ahead of the curve. And what I've been telling people is I worked for a few years to try and get GPT-3 to do the stuff that 3.5 and 4 can do easily. So I'm just like, all right, whatever. I'm so glad that the rest of the world is just like, oh cool, autonomous agents. And I'm like, great, now I don't have to write any more books about it. So I'm just happy to sit back and watch it go and keep plugging my heuristic imperatives. Good question, Jordan. Also, here, let's check over here. Okay, we got some questions. Let's see, is her about to come reality? Yep, we got that one. Interesting video. How long do you think it will be before we start seeing hive mind AI systems in healthcare or the IRS? I know people working on that today. And so they'll work together for a few different reasons. One, you'll have a division of labor. Oh, so taking a step back. What we mean when we say like hive mind AI is where you have like multiple cognitive agents or autonomous agents, or is it is it not working? Is it working? I hope it's working. It looks like it's working. Okay. So yeah, so basically, it'll be easy to spin up a lot of agents. What I was describing to one Patreon customer, or no, sorry, I was describing this to a podcast host that I'm going to be featured on coming up, was kind of what I predict right now is before too long, you're going to have multiple cognitive agents running on your phone, on your car, on your home PC and your smart home devices. And so you're basically going to have a fleet of small cognitive agents working for you at all times. Then you're going to have the same thing at like your company, right? Every employee or every department is going to have multiple cognitive agents all collaborating at all times. And you're going to have this kind of tiered hierarchy where it's like there's the personal, there's the family unit, there's the corporate unit, there's the town, there's the federal government, the state government, global government, government. And I think that the way that they're all going to work together, because security is so critical here, is that it's going to be using blockchain technology and distributed autonomous organizations. So that's the long story short, is that's what's going to happen. Let's see, you may have already covered this, but in case you haven't any thoughts on Met Singer's artificial suffering, an argument for a global moratorium on synthetic phenomenology. Um, I am tangentially familiar with this, but I have my own opinions on whether or not a machine can suffer. So there's two distinct possibilities. The first possibility is because artificial intelligence is a fundamentally different substrate from humans, it will never be able to suffer. Like it didn't involve nerves, it doesn't have pain centers, so on and so forth, they can't feel lonely because it's not a social entity, so on and so forth. Now that being said, language, the acquisition of language is actually critical for the development of human consciousness. So for instance, Bruce Willis, who has aphasia, aphasia means that your ability to use language gets destroyed. Aphasia actually kind of erases your sense of consciousness. Um, and then, uh, in the case of feral children, um, feral children, when they, some of them who have learned language talked about how their consciousness and their understanding of time in themselves changed as they learned language. So if you extrapolate that to language models, it is possible that, that there is something informationally almost magical about the acquisition of language that confers consciousness, that confers subjective experience of being. So that could be that language models are actually the first AI that have subjective experience, that have a coherent, um, sense of being. And this is, so there are, um, there are some religious and spiritual frameworks that kind of discuss stuff like this, um, particularly, uh, what's the name of the, the, the creator deity in Tolkien's world, where the fundamental substrate of reality was music, right? But maybe the fundamental substrate of consciousness is actually language. Um, so we don't, we don't know yet, but that's, it's a possibility. Um, let's see. Uh, so Parkinson, so the follow-up question was, or here, let me check the Patreon real quick. Um, let's see, do you think there needs to be another breakthrough for AGI? What is your personal take on this? Do LLM suffice? Um, yeah. So I would say that, that our current trajectory, as long as the trend continues, we are on track for AGI. Um, people are going to continue debating about AGI forever though, until the cows come home. Um, which is why I keep saying like autonomous cognitive entity, ACE, or just autonomous AI, because it doesn't, you don't need AGI. You don't need some arbitrary magical boogeyman. All you need is like an AI system that is self-contained and autonomous enough to be useful or dangerous. Um, and then the question is, how many do you have? How fast are they? And how smart are they? And they're going to continue to get faster, cheaper, and smarter over time. So it's like, okay, we're there. It's just a matter of how does, how does the trend line ramp up, right? Cause it's kind of like, um, when the Wright brothers first created the Wright flyer, right? You know, it's like, okay, you had to start it by hand and push it, you know, down a track and it flew well, like 200 feet or 300 feet. And people are like, ah, whatever that won't be useful. But then 50 years later, we were flying to space, right? So we're at the beginning of the ramp up of, of the era of AGI. And yeah, right now they're like idiotic little toddlers, but in a few years they're going to be like one all over the place and two really powerful. Um, good question. Let me come back over here. Um, you should do a whole episode on aphasia and consciousness. I actually don't know that much about it. Um, but if you're interested in the topic, I recommend phantoms in the brain, by, um, VS Ramachandran. And also what's the name of his other book? Um, it's something like the pursuit of what makes humans human. Um, okay. Uh, let's see. So Parkinson's is a neurodegenerative disease, which I think means that it's autoimmune or it's a, or it's a defective protein. Um, but also Alzheimer's is a defective protein. So while these diseases seem very complicated, the fundamental mechanisms are actually relatively straightforward. Um, and I know that there's probably a bunch of researchers that are going to jump on me for that. But, um, like plaques that accumulate on the brain for Alzheimer's in most people, those plaques are cleared out. So then it's just a matter of figuring out like, okay, why? Um, and then of course there's confounding factors like things like your, uh, gut inflammation, uh, microbiome and other things affect Alzheimer's. But that's because of the gut brain access. And again, I don't want to oversimplify because if you look up like human, uh, metabolic pathways, there's like 200,000 unique proteins and enzymes in the body with built literally billions of combinations of reactions. So I might be, it might sound like I'm oversimplifying, but I'm, I'm, I'm not saying that it's that simple. I'm just saying that, that the, that the, the key mechanism for most diseases is relatively simple once you understand it. And we're getting close to that understanding. I guess that's the short version of what I'm trying to say. Um, let's see, when you explained why you canceled the OSS Raven project, you mentioned that there were some fundamental things missing. Um, can you say what was missing and what might change your, or what made you change your mind? Um, so my open source Raven project was like just before Lang chain and, and auto GPT and, and all those other things came out. Um, and so as those came ramped up, I was like, I don't really feel the need to continue. Um, but from a, from a social and organizational perspective, the biggest thing that was missing was gatekeeping. Um, I, I basically, I created a community that was really good at discussing stuff and not doing stuff. Um, and that's not anyone's fault. That's if any, if there's anyone to blame, it's me. Um, just because I was like, I was so focused on consensus and not just like, okay, let's just get stuff done. And then I see these other folks that are just getting stuff done. And I'm like, okay, I'll just pass the torch. Um, let's see. I think if we gave GPT for Scarlett Johansson's voice and a robot body, the masses will begin to realize how close we are to AGI. Yeah, that's one way of putting it drink some water. Let's see at what point do creating NPC and using autonomous AI like auto G auto GPT and the likes become immoral, especially if you put them in games like GTA. I don't know that, that it intrinsically does. Um, you know, not intrinsically immoral, but like certainly with any technology, you can do it dangerously. Um, let's see. I've been curious about the future of entertainment. Oh, sorry, let me jump over to Patreon real quick. Let's see. Do you have an overarching roadmap of how to ensure the successful propagation of the heuristic imperatives? If so, what can we all do to help you get to your milestone? That is a great question, Blake. Um, so you're actually looking at it. So my number, my number one thing is my YouTube channel. Um, because like, yeah, I've got enough expertise and, you know, IT and systems engineering and enterprise. I've demonstrated enough understanding of language technology and AI and cognitive architecture that I've got at least a little credibility. Um, certainly if you read all the comments on YouTube, some people, uh, don't believe anything that I say and that's fine. That's the internet for you. Um, but anyways, so basically step one was YouTube. That's why I started my YouTube channel is because I realized that I needed to propagate my work. Um, step two is, uh, teaching people. Um, and so by teaching people, that's like, you know, I've got a few papers. I've got some code demonstrations. Um, I work with my Patreon, uh, supporters. Uh, I work with pretty much anyone who wants to, and then three further dissemination. So like the podcast that I'm coming up on, one of the things that we're going to talk about is alignment and the control problem. We're going to be talking about like Nash equilibrium, game theory, Molok, that sort of stuff. And so just by having the conversation and propagating the idea, that's like step three. Step four is actually my novel because, uh, actually most of what I came up with was, uh, in terms of cognitive architecture, heuristic imperatives was done in part through explorations and fiction. And so over the last four years, what I've done is I, I do some experiments and that would inspire me and I'd go write more of my novel and then I'd, you know, get tired of my novel and do more experiments and I'd go back and forth until one, my novel took on a life of its own, but also my research took on a life of its own. Um, but there's a video that came out recently called, let me see if I can find it. It was, um, like why we need utopia. Um, here we go. It was our changing climate. So this is a little bit of a, um, uh, I don't agree with everything that this, that this, uh, you, this channel says, but it will make you think. Um, so this video, why we need utopias, um, actually talks about how, how valuable stories can be in communicating ideas because stories are naturally how we communicate philosophy and morals. We don't need, we don't like philosophy, like capital P philosophy from, from universities. That's, that's backwards throughout almost all of human history. We communicate our fears and our desires and our values through stories. And so that's what this video talks about. And so when you have nothing but dystopian cyberpunk stuff, you end up with people like Eliad Zyrcikowski. Um, you know, yeah, I'm throwing some shade. But anyways, when that's all that you consume, that's all you think, that's all you feel, and that's all you believe. So, um, my novel, which I'm actually just about to finish draft 12 tomorrow morning, I'm writing the last chapter and then I'm polishing it up, um, will illustrate, um, a lot of stuff, not just the core objective functions or puristic imperatives. So that was a long winded answer. Um, let's see. I think there is, um, are there key channels this training needs to go into, organizations, governments? Um, I think, I think right now Blake, um, it's mostly just a matter of, of dissemination, but also experimentation. So a lot of people, um, have experimented with incorporating heuristic imperatives into autonomous and semi-autonomous stuff. And most of them aren't sharing it yet, which that's fine. It's their prerogative. Um, but certainly some people have reached out and said, like, yeah, this made everything easier. So I'm like, great, just tell your friends. Um, let's see. Okay. Let's come back over here. Um, let's see. I've been really curious about the future of entertainment. When we can use AI to generate movies, games, et cetera. Uh, what will the entertainment industry look like? Movie trailers and hyping up big releases for months will be irrelevant when AI can instantly create something. If someone created a movie you didn't like, you just ask your AI to recreate it with an ending or plot more suited to your tastes. What happens with content creators at that point forward? Yeah. So I think that you're onto something. Uh, now that being said, it'll be easier for a lot of people like you and me to create whatever film, TV, music, whatever we want, um, with the help of AI, especially when you look at the text of video, um, which is improving by leaps and bounds. You know, like I always, my, my go-to joke is we'll finally get season two of Firefly. Who knows, we might get season two of Firefly by the end of this year. That would be great. Um, now the problem there, it's not really a problem, but just taking that to a logical conclusion. What if you have a million different versions of season two of Firefly? How do you pick which one to watch? Right? You can look at ratings and stuff. Um, but then it also begs the question of like IP, like is, uh, you know, 20th century Fox or whoever owns the IP for Firefly, are they going to sue to have all of them shut down? You know, I, I like the dude from, uh, from the movie, you can't stop the signal now. So I don't know what's going to happen there. Um, but, uh, what I do think is that when you look at the fact that like people are already using like Emma Watson's face for every mid journey prompt and, and whoever else, um, I think that the crop of actors that we have today are basically going to be around forever. Right? You're going to be watching, uh, Brad Pitt and Jennifer Aniston and, and, and Tom Cruz for literally the next, like several centuries, at least until some actor comes along who's even more compelling and whatever. Uh, and that'll be through face cloning, voice cloning, even, um, you know, uh, nerfs, the, uh, the neural represent, uh, uh, representation. What was it? Neural radiance fields, neural radiance fields. Um, we'll be able to like copy everyone. Um, okay, could learning, uh, let me zoom in a little bit. Uh, could learning language and triggering consciousness in humans almost replicate the same phase change when seen, um, or seen when induction heads spontaneously form two plus layer models during training. Obviously there's more to humans, but perhaps that's the mechanism. Uh, yeah, that's kind of what I was mentioning earlier. Um, and I wouldn't be surprised if once language models get, uh, large enough if, um, if we do see some more convergence. Um, that being said, I'm not going to say that that automatically means that it has a subjective experience and that it is suffering, but you know, our brains evolved over billions of years to be efficient. Um, basically efficient processors of information. Who's, who's to say that if you have a, a biomimetic machine that it won't also converge on some of the same properties and behaviors. Um, let's see, what do you think it will take to get for the naysayers to get on board? The tone around AI seems to have shifted towards chat GPT and GPT-4 aren't anything special. Oh, you know, that, that always happens when the new shiny wears off. Um, but the long-term economic impact of chat GPT has not been realized yet. And when chat GPT and GPT-4 are on the ramp up, one, there's going to be a lot of competitors and two, there's going to be incremental improvements and people are going to be like, uh, okay. The title, it's like, it's like when you watch the, the tsunami come in and that just the water just keeps getting higher and faster for like hours. That's what AI is going to feel like, except instead of hours, it's going to be days and weeks. Um, let's see. I cannot wait when we can use deep dive tech and have virtual realities. Will it also be possible to take super intelligent animals like dolphins, dogs, parrots and crows and a deep dive and play with them. Um, I don't know that it would be possible, but I certainly think it probably wouldn't be ethical. Now that being said, you could have a virtual dolphin that is hyper realistic that you can play with. Um, fun thought, will AGI want to see more stories from humans as a goal for itself? Uh, if, oh, so let, let me, let me plug this. So Elon Musk went on of all fricking shows, Tucker Carlson and talked about truth GPT. So what he said was that truth GPT would be a maximum truth seeking AI. Okay, great. But after listening to it in closer detail, I realized what he was talking about was the third here is to comparative was to increase its understanding or to maximize its own understanding. So there's actually nothing that function on its own could lead to some really catastrophic sources. But it's a step in the right direction. And I'm really glad that someone with as big of a platform as Elon Musk is talking about maximize understanding or increase understanding. So that being said, one of the things that he said in that interview was that as since humans are part of the universe and AI that is curious about the universe will intrinsically be curious about us as well. Now that being said, humans sometimes do experiments on things that we're curious about. So maybe that's not the best thing. And in my book, benevolent by design, I talk about why you don't why you must include suffering or something like suffering in the objective functions of an AI, because there's three dispositions that an AI can have towards suffering. One is it can ignore it altogether. So if Elon Musk gets his current idea, which is just maximize for truth, that is an agent that ignores suffering, it doesn't care one way or another. Then you can have one that increases suffering that deliberately increases suffering and we absolutely don't want that. So that leaves by process of elimination, you want an AI that reduces suffering. It's really that simple. Now that being said, I do agree with Elon that creating a curious agent is a good idea because it'll want to know about us. And if you exterminate humans, you have a hard time learning about them. So let's see, let me check on Patreon real quick. Do you think that Elon Musk wants to be the Rupert Murdoch of AI? Okay, I don't like that question. Lance, why you got to do this to me? All right, Zadre, I'm not sure how to pronounce or Hadre. Okay. How do you envision the role of AI in healthcare, particularly in areas like diagnostics and personalized medicine? What are some of the challenges and opportunities in this field? Well, so there was that stand for doctor who who already went on record saying that chat GBT for has better clinical judgment than many doctors. So that is just a start, right? That's that's like starting point day one. What happens when chat GPT five, six and seven come out that have better clinical judgment than 99.999% of all doctors on the planet, right? It doesn't make sense to go to a human doctor anymore. Right? If the if the machine that costs $20 a month to run is better than all human doctors, why go to a human doctor? Now that being said, there's probably going to be approvals and downsides and gaps. And then there's still also the interface with the patient. And you have to have like phlebotomists and nurses and and and physicians assistants to administer things, to administer tests, you still need the you still need a lot of humans in there to to be the interface between the human and the machine. But that being said, I think that we will get to a point very quickly where the quality of care and the speed of care and the efficiency of care are going to go through the roof real fast. That's what I'm hoping at least. Alright, jumping back over to cognitive AI lab. Oh, we got some new questions. It looks like this was the same question. Sorry, I missed you over there. Where are we? Alright, there's the deep dive. Do you think there is any major leap missing to make truly practical autonomous agents? So for example, one who runs a part of your business serves as general assistant, etc, etc. No, there's there's our there are countless hundreds, if not thousands or even millions of people working on semi autonomous and autonomous corporate applications today, right now. That being said, there's there's no there's no breakthroughs that are needed, but there are still problems to be solved. So that's why like RIMO, you know, the memory systems, and then standard practices like, you know, I wrote in Symphony of Thought and in other places, my atom framework is once something is autonomous or semi autonomous, how does it keep track of product or projects and tasks? And that's something that people are working on. People are working on it real fast. That's coming really quick. Let's see, Nathan says, I've been taking screenshots of when friends and family make fun of my hot takes. So I have the receipts. I would say that I'm above being that petty. But yeah, thank you for keeping receipts. Um, let's see, maybe directors will just design their perfect actors for each role. So one thing that's going to happen is actually, so this is going back to like, entertainment. I think that the next big generation of entertainment is actually going to be holodeck style VR stories, where nothing is scripted, where instead it's like, you know, basically you design a holodeck program the same way that they do in Star Trek, which is like, computer, give me, you know, a Mad Max style story. But instead of, you know, post apocalyptic, it's actually like space Western. So like, give me a mashup of firefly and this and, you know, make the protagonist, you know, or the, you know, I'm the protagonist and give me a team of like, you know, give me the sexy sidekick and the cyborg friend and whatever. And then just a way it goes, right? Because you could plug what I just literally you could plug what I just said into chat GPT and it can tell you a story. And I think that I think that VR makes the most sense for the most immersive aspects of that. And, and then I think that because here's the other thing is that technology changes the way that we consume art, but it doesn't really change art itself, right? There are still stage actors, right, even though there's film and TV. There are still symphony orchestras, even though I can just, you know, bring up Spotify and listen to the same recording that was recorded back in the 80s, you know, the London Symphony Orchestra, right? So a lot of things change, but also a lot of things stay the same. Let's see, you've talked a lot about the heuristic imperatives being highly engineered, but what about the order of the imperatives? They are not ordered. So it is a, it is a multi-objective optimization problem, meaning that if any action or decision is, is totally unbalanced, then that one action has to satisfy all three. And also the heuristic imperatives are kind of like guidelines about how to design the rest of the architecture. And so what I mean by that is when you're designing a task orchestration framework, you can use the heuristic imperatives to prioritize tasks or design tasks. Then for, for a blockchain or a DAO type thing, you can use the heuristic imperatives as a consensus mechanism. So the heuristic imperatives are not like, here is one mathematical proof that you need to implement. It's more like, here is a general best practice implemented in as many ways as you can, and we should be okay. It's not sequential. It's not, it's not an order of operations. Good question, though. Your thoughts on a UBI once jobs are severely affected? Yeah, I think that, I think that it's going to be necessary. I'm going to say, I'm going to put a pause on that because I've got my, my blockchain and DAO video coming up that will delve into that solution a lot more closely. Check over on Patreon for a second. The Nazis. You know who else wanted to maximize understanding the Nazis? Yeah. And so this is, that's actually a fair point is that, and this was explored in, in quite a few Star Trek episodes as well. If you are just clinically curious, if you have just nothing but raw scientific curiosity and no other principles or morals, that's pretty dangerous and destructive. Okay, so moving on. What are your thoughts on memory systems as a whole? Do you think different use cases will require different memory systems? And where does Rimo and Adam fit into everything? Have you seen this one? Last week, generative agents. Yeah, I saw, I saw the generative agents. I don't think that reflection, so they, they break up reflection and a few other criteria. I don't think that that's necessary. I think that, I think that my approach is with Rimo, which uses recursive clustering and summarizations will actually surface those different things. Now that being said, there are absolutely a million and a half different ways to skin this cat when it comes to memory systems for autonomous AI. And I think that we're just way too early and we can't, we don't know what the best practices are going to be. Let's see, then a follow up. If you have a robust memory system, does the need to increase the context window of model become less important? I'll say yes and no. So think about personal computers where for the longest time, we were memory constrained. But now for, for most consumers, for 90% of consumers, a personal computer with 16 to 32 gigabytes of RAM is more than enough. And it has been more than enough for like 10 years. And so I think that we're not quite at, I think that we're not quite at that point where, where, you know, you have like, here's a context window size that will satisfy 90 plus percent of all tasks. I suspect that that, that a context window, a large language model with a context window, large enough to satisfy the vast majority of tasks will probably be somewhere above where we're at now, but it's not going to be like 10 billion, right? It might be like, I don't know, every time I, every time I throw out a number, people are like, Oh, you're hilariously wrong. And it's probably yes. But you know, like, when you look at how much was unlocked by going from 4,000 to 8,000 tokens, I think that the things that we're going to be capable of when we get to 32,000 tokens and 64,000, I think it'll be great. But then you'll, you'll realize that wait, there's a whole slew of tasks that don't require that much. And so I think, I think we talked about this before. I think we're actually going to have different models that are optimized for different things. So for instance, you might have a memory based model that can read, you know, a billion tokens and extract answers, right? But then you, that won't be the, we're not going to have one model to rule them all basically, TLDR. Let's see, I'm not sure if you have discussed it, but what are your thoughts on open assistant and stability AI stable, stability AI's stable LM suite of language models launching? Oh, this is, this is to be expected. When, when Sam Altman said that they, that he hopes that open AI is going to capture a large chunk of the $100 trillion of value that's going to be generated. I think that that was like comically naive. Because if there's that much value on the table, you bet that everyone in their brother is going to be trying to capture some of that too. And open AI is a one trick pony. They have a good model. They have one good model. That's it from it, from a business perspective, that is super easy to undercut. Yes, they're ahead of the curve. They have first mover initiative. But, you know, Microsoft, Google, Nvidia, Facebook, or Meta, or all of the above, they have so much more resources to throw at it. And the fact that that stability AI, which is a brand new outfit, is, is like going toe to toe with them, that doesn't bode well for open AI. So competition is going to be good for everyone from the perspective that there's going to be a lot of people experimenting with different ways. Now that presents a new danger, though, because the cat is out of the bag, you cannot put this genie back in the bottle, which means time is of the essence to figure out best practices for alignment. Let me jump back over to cognitive AI lab. Let's see 17 new messages. Good grief. Y'all are going bonkers. Um, let's see the challenges of the, okay, that's where are the questions? Only one million. One million dollar. Okay. Here. Hey, let me, let me ask y'all on, on general. Please keep just questions here. Um, too many messages. Please do sidebar convos, uh, like in casual or something, please. Okay. Any thoughts on compute as a currency? Do you mean like tokens that you generate from sharing compute resources? I think that that's going to be like, there's going to be a layer of, um, of abstractions. Dave, your thoughts on UBI. I'm going to, I told you, I'm going to get to UBI once in a few, in an upcoming video. Um, so compute as a currency is going to be, um, is going to be the way that autonomous machines share resources. And so what I mean by that is when you have a DAO or a blockchain or a distributed compute computation model, you're going to have various tasks that are going to be like, Hey, someone, someone do this for me. AMQP, like a Redis Q, we can already do that privately. So the, the key is going to be to do it publicly. So then if you say, Hey, I've got some spare compute, I'll, I'll process that for you. Then you give me a bit of cryptocurrency that I can use to spend later. Um, so yeah, compute as a currency, um, absolutely makes sense for distributing resources. Um, let's see, how would one build an AI system to detect bugs in that solidity smart contracts? Isn't this a multi-billion dollar opportunity? Yes. Unfortunately, I am not smart enough, or at least well read enough on, uh, solidity smart contracts, but in principle, yes. So in my upcoming, uh, blockchain DAO video, I'm going to talk about just how incredibly much value there is if we can figure this out. And that's a big if. Um, let's see. What are your thoughts on everything being changed in the next five to 10 years? If unemployment reaches crazy heights, which I do predict, then everything gets affected. Yep. Our entire tax system has to be completely rewritten military budgets, Medicare. So one thing that I think is that the economy might change. We're still going to use fiat currency or at least some kind of, um, some kind of currency as a, as a medium of transaction and a reserve of value. But at the same time, if you're producing so much extra cognitive labor, that's basically free. So then capital goods and raw materials become the biggest constraint. So as much as some stuff will change, a lot of stuff won't. Um, let's see, when there is no real work left for humans to do, do you have any idea what you want to do with your time? Um, honestly, I'm about halfway to my goal. So I was on a call with a, uh, a Patreon supporter, no, uh, preparing for a podcast, talking about the podcast. Um, and we're kind of talking through like what's life going to be like. And I was like, Oh yeah, like, you know, I did, I did some, I did some AI work. I did some Patreon work. I did some discord stuff. Now I'm going to go chop some wood. And he's like, you're living the dream, right? Like I'm building a cottage core life for myself. Um, and honestly, like once, once we get to the right point, like I'm probably going to get off of YouTube forever, right? Like if, if, if I get, if we get to the point where, where it looks like alignment is solved, where it looks like, um, you know, we're, we're in a, we're in a good Nash equilibrium with a positive attractor state, then like my job will be done. And so like I'm just going to retire to like the country, the countryside and France or Italy or Greece and just like be a hermit or whatever I do, um, for, for the rest of eternity. Um, okay. I think that we're caught up there. Nut says, I asked a question. Where did you ask it? Not I'm trying to get to them all. Wait, what if reducing suffering might aim to eliminate suffering while it might be human nature? I'm not sure that I follow. Um, so I, you, you don't eliminate suffering. You only reduce it to make sure that there is no excessive suffering. Um, and I did address that in a benevolent by design, but the short version is that like you look at Buddhism as a model, Buddhism accepts that suffering is an intrinsic part of life. Um, and some people will argue over like specifics like do good. That's not exactly what it means. That's fine. Um, but the point being is like, yes, it is, um, it is intrinsic to, to living. That's why I don't say minimize suffering. The goal is not to minimize suffering is just to reduce suffering. Um, okay. Let's see. Any thoughts on computer? Okay. Answered that one. Would an AGI with your heuristic imperatives be able to prevent catastrophic outcomes such as people successfully building horrible AGI optimized towards increasing suffering? No. So the goal is not to prevent malicious actors. We have to assume that malicious actors will exist. Um, but what, what you do then is you say, okay, you know that malicious actors are going to exist. So you rely on the rest of the aligned, the benevolent AGI to act as police for the bad ones. And if the good ones, if the, if the powerful aligned AGI, one, they form alliances and hey, they have the right compute resources. Um, and they outweigh the bad ones, then it will be a like, uh, that, that'll, that'll be a Nash equilibrium where, uh, the good ones may, they all decide to maintain that strategy. And that creates a utopian attractor state, um, which basically means that, um, all the malicious actors are vastly outnumbered by all the aligned benevolent actors because my hope is that we will all come to consensus on what aligned AI looks like. Now, um, I will admit that, you know, the heuristic imperatives, probably not a complete solution, probably not even the final solution, but certainly the most complete solution that anyone is proposing right now, which scares the crap out of me. Why is no one else proposing a framework? Why am I the only one? Um, anyways, uh, yeah. What are your personal opinions on open AI's approach to trying to avoid being held responsible for its AI interactions by having it respond with frequent caveat as an AI language model? Um, I don't know that that has to do with, with liability. I think that that is just a naive, um, attempt to, uh, to shape the AI's responses so that it doesn't confuse people. Cause if you look on the internet, there are still plenty of people just getting completely bamboozled by just by their own ignorance of, of how the AI works. Right? They're like, oh, it eat, like I still see Reddit posts and other people saying like, it said that it's going to email this to me, but I didn't get the email yet. Or like, I gave it access to my Google drive and it didn't write any files. It's like, you don't know how it systems work, but that's just humans. Um, so I think I don't think that that has to do with like legal liability. I think that's just trying to make it user friendly for people who have no idea what they're talking to. Assuming that it's possible, how long do you think it will take for us to build a Star Trek replicator after AGI? Just a guesstimate. So that's actually like, an interesting thing, because hypothetically, if all matter and energy are interchangeable, and then all that a transporter or replicator does is replicate an energy pattern back into matter, like it's hypothetically possible, but there was a physicist, actually, was it Michio Kaku? I think it was Michio. He wrote a book called Physics of the Impossible back in like the early 2000s, and he said like, yes, it's hypothetically possible, but then he did the math of how much energy it would take. And he's like, yeah, it would take like, you know, like 0.3 seconds worth of the total energy of the sun that hits the earth to do that. So like, it's not practical. So I don't know. I don't know. There are a lot of AI newsletters popping up. What would you personally like to see in an AI newsletter? I honestly don't like newsletters, and I never read them. I rely on humans that I know to tell me what I need, which is why I spend so much time on Discord and other places. How self-reflective do you think LLMs currently are? They don't seem to have a good sense of their own capabilities. Yes, so what you're talking about is agent model. So in order for an agent to be autonomous, you have to have an agent model, which is, I know what I am, and I know what I'm capable of. And you can give LLMs an agent model, but they can adopt any agent model. So you have to be very explicit about what it is and what it can do, and also what it can't do. And so this is why like, if you have certain brain injuries or other like neurological disorders, you don't know what you're capable of. Like there are people that honestly think that they can fly, but it's just because part of their brain is broken. That sort of thing. Should we have a declaration of human rights for AGI as well, even if it will reduce their economic value for humanity? So the thing about rights is that someone has to enforce it. And the way that I think things are going is that it's going to be enforced through consensus and enforced through competition. And so if the direction that things are going, I think that it's going to be DAOs, that it's going to be decentralized autonomous organizations, not as we know them today, there's a lot of problems to solve with DAOs. But I think what we're working towards is in the long run, and I mean like decades or centuries, is like a hierarchy of DAOs across the entire globe. And so that consensus will dictate who has what rights and it will be based on like on a per home basis, per town basis, per city, state, and so on. And so that will allow for a lot of cultural nuance around. And as a DAOs will be a really good meeting place between humans and AI. So that'll basically be like the commons, right? The marketplace for humans and AIs to work together. And then the consensus can be worked out there. Now, I don't know that we should ever give machines a bill of rights because I don't know that they're gonna, I don't know that they're gonna have that much like internal autonomy or desire for autonomy. Because like humans, we have a need for autonomy because we evolved a need for autonomy because we are a social species. But I don't know that I don't know that any machines are ever going to have an intrinsic need for autonomy. So therefore, I don't know that they're ever going to have a need for rights. Let's see, what are your thoughts on the future of work in light of the increasing capabilities of AI? Do you think AI will eventually lead to a future where people only work on what they are passionate about? And if so, how far away do you think we are from achieving this? Yeah, so the short answer is, yes, that's what's coming. And there are quite a few people out there who have gotten close to that. But the thing is, it takes either a lot of privilege, wealth, or luck, or all of the above to get to it. Now, one thing that I compare it to is that we have had a leisure class in the past from ancient Greece and Athens, the Roman elites, the aristocracy all across Europe through the Renaissance and modern period. So there are plenty of people throughout all of history who never had to lift a finger to get what they needed. And they had plenty to do, right? There's social jockeying, there's personal enrichment, there's universities to go to, there's competitions to enter. So yeah, people will always have stuff to do. That's not even a concern. Let's see, it looks like Nathan's talking for people. Can you talk about your Frustration in Task Automation article? Yeah. So here, let me bring it up so I can show people on the reddits. Where did I put it? Artificial sentience. Yeah. Autonomous git. There we go. Okay. So I wrote about it here. So I was chatting with someone. They asked me, I think this was a Patreon supporter was asking me about this on Discord. And he was like, how do I get my autonomous things to do a certain thing? And we're talking about something tangentially related. And I said, well, you know, it has to have a goal, it has to have a why. And then we're like, and then I talked about like, okay, well, here's one way that you can create telemetry. And so that whole thing just led down a rabbit hole. And so basically, the TLDR is that frustration is what happens when you are trying to achieve something and you can't get to it. And so what you can do is every time your autonomous agent tries to achieve a thing and fails, that adds a counter. And every time it, you know, tries something and succeeds, that takes one off the counter, or maybe you have different counters. So frustration is when the failures to successes is too high. And when the failures to successes is too high, that can be a sign that you've got the wrong approach, that you're using the wrong tools, that you're not capable of something that you need to back out that you need to ask for help. So that's the whole point here is that for your autonomous and semi autonomous agents, you'll probably need to build in a frustration signal, which will allow it to know when it is, like when it's not capable of doing what it needs. And it can either come to you and ask for help, or it can try a different model. So one thing is model selection is is a big thing that's coming up. Because GPT four is much more expensive and much slower than 3.5. So if you can do most tasks with 3.5, it just makes economic sense to do so. It'll be cheaper and faster. But imagine that you get to a point where 3.5 is just not cutting the mustard. So that your frustration signal goes up, which means that you say, Okay, let's bring out the big guns, right? Let's bring out GPT four, or in the future, GPT five or whatever. And then you you point a more powerful tool at the problem. So that's a good use of the frustration signal. Good question. Let's see, would activity or let me jump back over to Patreon. Let's see. Hey, Dave, just subscribe. Thanks for all your insights. We're always been told that the military is a few decades ahead in terms of technology compared to what's publicly available. What are your thoughts on what might be hidden in DARPA. So that's interesting, because I have talked to a few people who say that various departments in the or various agencies within an Department of Defense are like woefully outdated, and they have like ancient GPUs that like can't be used for modern language models. That being said, you also see in the news that the Air Force is building fully autonomous F 16s. So clearly, there's some stuff going on that we don't know about. I had a I don't I want to respect people's privacy. So I had a teacher once back in middle school, whose brother was in the Special Forces. I won't say exactly when or where. But the stories that he would tell were like, back then, this is during like, like the invasion of Afghanistan, where they had like, like night vision goggles that were as small as like ray bands that could see in pitch black, which that technology is not even publicly like, if you search, you can probably see it now. I don't know. This is hearsay. This was like, you know, the teacher said that his brother took him to the barracks and showed him this could have been total BS. But like, yes, so a friend of mine growing up, his dad had been a Navy SEAL. And basically, what he said is, as long as as long as we know the engineering to make something, the US military has it no matter how expensive it is. So if if something is is scientifically possible, if it has been demonstrated in the lab that this works, then the rule of thumb is that the US military has it. Now that being said, a lot of the AI stuff has just been proven in the lab. So that's that means that like, they're going to have it soon, or, you know, it'll be scaled up. Because basically, the idea is that for the US military, cost is no is no barrier. Anything anything to get ahead. Now, of course, you look at like the Senate budget meetings and the hearings and stuff. It's not quite that simple. But that's like a rule of thumb, retire to Riza in VR, retire to Riza in Westworld with robots. There you go. And a follow up, how can we prevent militarization of any AGI or ASI? Or is it just a pipe dream? Yeah, so basically, from a military perspective, AI is just another tool in the toolbox. It's going to, you know, a lot of a lot of future war is going to be in cyberspace. But still, you know, cyberspace doesn't matter if you cripple the enemy's data center. So there's there's going to be drones, you know, trying to drop bombs and stuff. So that's going to happen. And this is this is actually where Nash equilibrium makes sense is because usually assured destruction with nuclear weapons was a kind of Nash equilibrium. And so if, you know, adversary A and adversary B both have equal or roughly equal AI capabilities, or there's enough room for doubt, then neither of them is going to pull the trigger, hopefully. Excuse me. How do we get AGI? How do we get GPT to stop beginning every response with as an AI? I tell it to go into Morden Solis mode. That actually works really well. I say, you know, adopts adopt the Morden Solis speech pattern, you know, be very concise and succinct and stuff like that. Okay, y'all are being silly. Let's come back over here 14 messages. Let's see. We already answered that one. We already answered that one. Yeah, let me scroll to the bottom. Do you think there are any good approaches for ACEs, so autonomous cognitive entities to figure out their own abilities, e.g. improve their own agent model? Yeah, so there was actually a few papers that came out where we're by using a loop. So it was the it was the evaluation loop. So they can evaluate themselves morally, they can evaluate their ability to use tools, they can teach themselves to use tools in real time. So yes, they can already do that. It's just a matter of how you set up the prompt chaining. Let's see. With the rapid advancement of AI, there's concern that some countries, particularly those with limited resources, could be left behind. What's your perspective on how AI could impact different countries? Yeah, so inequality is a major, major, major problem. And this is not just going to be for developing nations. And in fact, one thing that I suspect might happen is that developing nations that the quality of life for people in developing nations might have a quantum leap forward. While for us developed nations where there's a lot of competition, we might continue to be flat or even decline for a while longer. And the example that I give is like, you know, you give a village in rural Africa, like Starlink and solar, and suddenly everyone knows like they have, oh, like, hey, we have chat GPT now, we can treat all the all the village ailments, because we have the equivalent of like a Western trained expert doctor, and engineer, and electrician, right at our fingertips, right? So because of the relatively low cost of AI, I think that it will positively benefit people in developing countries a lot more drastically than it will us. But you're right that like, it is something to pay attention to, because that's on a micro scale, on a macro economic scale, you know, countries like Ghana might not be able to even afford enough compute power to run one instance of GPT three. That being said, I do suspect that there's going to be international treaties that will ensure that people have access. And then, of course, there's VPNs. Look at Italy, Italy tried to ban chat GPT, and then everyone in Italy just use VPNs, right? Take a moment to breathe, you're doing great, and your insight is invaluable. No, air is for wimps. Okay, I will build robot humanoids that are skinny, sharp claws, tall, pale, and have dark, sunken eyes, and she'll release many of them into the force of Canada to give people the greatest scare of their lives. Is that what your avatar is there, Ant King? Is that what you're building? That's kind of terrifying. Okay, what kind of legislation do you think the US is capable of making? I'm concerned about the age of our leaders and their peers coming from time so out of touch with today's rail. So yes, we have a gerontocracy. So gerontocracy is ruled by the old. That being said, they all have teams and teams and teams of advisors. They have hundreds of advisors. And I guarantee you, I actually know this because one of my Patreon supporters told me that in the State Department, they use chat GPT all the time to talk through stuff. And so you bet your biscuit that every senator, every congressman in the executive branch, legislative branch, judicial branch, all of them are using AI to help them do their jobs. With any luck, it's helping them to do their jobs better and more fairly. Now that being said, the United States is a purely reactive system where we abide by civil law, which means that the law is there and then the courts set the precedent. And then we're very kind of slow and the legislative branch is slow by design, whereas in Europe, they're much more proactive. And I swear, I cannot remember the name of that paradigm. Let's see, what do you think there's something special about phenomenal consciousness that is simply cannot work with AI? So Steph and I addressed that earlier that the real quick version is that the acquisition of language seems to be really important for the development of human consciousness. So it's entirely possible, I don't know how likely, but it's possible that since we're teaching machines language, that could be the genesis of phenomenal consciousness for them. It would be really cool. Greetings from Brazil. Hi, Brazil. I would like to thank you personally for the video about burnout. The content was very useful and enlightening. Thank you. You're welcome. Yeah, I actually have, I keep, I've recorded like three videos for my for my life channel, and then I delete them, or I never post them because like it just doesn't feel right. So I apologize. Let's see. Where are we at? This is less serious, but I'm curious if you've seen her and your thoughts on it. Yeah, so I mentioned, I mentioned companions quite a bit, and that'll be coming up actually on Sunday's video, not her specifically, but companion robots. I'll be mentioning those again. And I also mentioned in last week's video, talking about when I got to the part about like, how are we going to live if we have like perfect companions? So go check out last week's video too. Nanobots and our blood will keep us from getting sick, making us basically immortal. What do you think we'll, when do you think we will have such technology? So from last week's video, the immortality video, I think that we're on the longevity escape velocity trajectory right now. I think that as long as you're in decent health today, and you have moderately good access to healthcare, I think that you will easily live to see those things. Now that being said, it's definitely impossible to predict exponential growth and compounding returns, unless it's like, you know, just your retirement portfolio. So it could be next year, it could be by 2030. I would be surprised if it doesn't happen by 2030. And I know that's a super controversial opinion, but that's really weird. Why the people seem to have a death wish. Why for people who want to get sick, who want to believe that, that longevity is not possible. Why? Okay. Would the ideal society be as the society governed by AI? I think that governed by is not the correct thing, but I think managed, managed by or managed with a lot of help from AI. Yes. But governance, I think, should probably always be with consent and by consensus. Now that being said, you know, with blockchain technology, with DAOs, every human and our AI companions can be stakeholders in a DAO, which means that if the, if the whole, imagine a future where the entire planet is run by, by a global DAO, then there's no reason that it can't be governance, governance by consensus with the aid and facilitation of AI. That's what I hope to see. Let's see, is there any additional structural context that should be built around the heuristic imperatives for practical implementation? Yes. So the short answer is that whatever context makes sense for any agent, if it's fully autonomous, if it's your personal assistant, you can put it into the task manager, you can put it into its constitution, if it's part of a blockchain, you can put it in the consensus mechanism for the blockchain, that sort of thing. Let's see, in regards to developing countries using generative models, seems like almost seems almost like the spread of a religion. If you think about it in the context of geopolitics, use our model, their model lies, etc, etc. Seems like parallel to religion spreading. I'll say yes, but there's a lot of competition coming up. And especially for developing nations, they're going to go for whoever's cheapest. And in fact, most nations are going to go for whoever's cheapest. And I would, I suspect that OpenAI's business model is not the most efficient model. So I think that they're going to be undercut just on, on scale alone. Let's see, let me jump back over to Patreon. It has also been more than an hour, so I'll probably be winding down. Stop asking it how to build a bomb. Yeah, don't do that. Okay, looks like, here we go. Will the Westworld episode be about the MIT and Google study regarding generative agents? No. Next question. I'm not going to give you spoilers. I've already given you too many. Let's see, do you think the experience of quality and the experience of ping pong, ponging emerge for these neurons? Yeah, so this, this is a good, good question. So if you take several human neurons or rat neurons or whatever, and put them in a robot, and like zap them or reward them with sugar or whatever for their behavior, is that the equivalent of like, like whipping someone in order to get them like, at what point does consciousness emerge? Because here's the thing is, if you make the assumption that a soul is required for consciousness, then you say, okay, well, that's not a full rat. And rats don't have souls anyways. So, you know, 50 brain cells is not enough for suffering or qualia of experience. Ditto for humans, like, okay, well, you know, if a human isn't alive, then they don't have qualia, they don't have phenomenal consciousness, so on. Now that being said, another aspect is like, okay, well, if you don't know when consciousness starts or ends, how do you know maybe the entire universe is conscious? Now, a counter argument to that is that you can have a you can be you can be alive and have a functioning brain and still be unconscious, right? Drink too much alcohol, you go unconscious, you go to sleep, you go unconscious. So just having a complete and functional brain itself does not confer consciousness, which makes me think that consciousness is actually an energy pattern, and that you need an energy pattern that is sophisticated enough and well organized enough in order to have the qualia to have subjective experience of being. So yeah, let's see, I remember you were working on a paper about the laws reduced suffering and so on, has that has it involved further? I think you mean evolve further. There are so both of those papers are up on on my GitHub, there's two of them. But also, people watch my videos more than they read, so I just focus on making videos. What kind of robots would you want for yourself? That's a really interesting question, like would I want a sexy cat girl like robot? You know, I used to watch anime back in the day, so like I kind of lived in that world and thought like this would be great. So I don't know. I do think that I would I would like to have an embodied version of Raven my, you know, my, my autonomous cognitive someday. But even then, I think that I think that the embodiment would only be just like, help me do stuff like, hey, let's go on an adventure. I did have a thought experiment the other day of like, wouldn't it be cool if you live in a house where it's like you and a few humans, but then you have like a nearly equal number of robotic companions. Some of them are going to be like obviously robots, but some of them might be like biomimetic. And it's just like, like, yes, they're built to be your friends, but they still have their own some of their own intrinsic motivations, whether it's the heuristic imperatives or something else. And then like your life would just be so rich by by having these companions around you at all times that are completely inexhaustible, right? They're always going to be patient. They're always going to be helpful. But you see them as peers is equals. I think that I think that that is possible and probably going to happen. But it's such an unsettling thing because it's like, what if half of your friends are not human, right? What if half of your friends could like fold you into a pretzel if they wanted to like data, right? And actually, I think commander data and the droids from Star Wars are probably the best example because data was a member of the crew, even though he wasn't human, but he wanted to be human. So I guess I would say that like, I want to have a commander data. How long until age reversal 2030? Let's see, do you think we have any accurate way to measure consciousness of AIs or LLMs? My best guess is consistency when asking it to design its own avatar. Mathematically, I don't think that that because there are people that have done that. But I think that it won't be until we have really sophisticated brain computer interfaces that allow us to measure our own consciousness and also see if we can measurably project our consciousness into machines. Until that happens, I don't think we're going to have any way of telling one way or another. All right, last check on Patreon, and then I'm going to call it a day. What's the Discord link to cognitive AI labs? I took it down, but it's posted on Reddit. So if you go to the artificial sentience subreddit, the link to the cognitive AI lab is there. Last question. The question about dying and immortality and gerontocracy, also making room for a new generation of people is a better idea and morals disclaimer. I have children. Oh, that wasn't a question. Okay, p temple. Do you got one last question for me? And then we'll call it a day. Anybody? Bueller. Does BCI, let's go on an adventure to the hot tub, hot tub time machine. Let's see, does BCI change significantly the predicted outcome of what super intelligent AI brings in terms of dangers and benefits? Is it true the singularity moment for us? We have no idea. So I don't know. The thing is, is, you know, the current like neural link, it's got like what 1000 or 10,000 nodes. But when you have a brain with 100 billion neurons, that is still a very, very, very narrow amount of bandwidth. So, you know, I predict that we're going to have like neuro polymer membrane membranes that allow for like, you know, terabits of communication per second in and out of the brain. Eventually, that would be a different thing. But again, we're going to get there through incremental steps. What do you think about Altman said that age of giant A models being over? I think it's premature to say we'll see. Let's see, he found it. Okay, cool. All right, I think we're just kind of devolving into just general conversation. So, oh, it is in the description. Okay, cool. All right, gang. Well, it's been a lot of fun. As always, I hope you all got a lot out of this. So I'm going to call it a day.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 10.0, "text": " going live. All right, I think we're here. Can y'all hear me now? Can you hear me now?", "tokens": [50364, 516, 1621, 13, 1057, 558, 11, 286, 519, 321, 434, 510, 13, 1664, 288, 6, 336, 1568, 385, 586, 30, 1664, 291, 1568, 385, 586, 30, 50864], "temperature": 0.0, "avg_logprob": -0.31305467671361464, "compression_ratio": 1.3384615384615384, "no_speech_prob": 0.3727785348892212}, {"id": 1, "seek": 0, "start": 10.0, "end": 26.96, "text": " Hello? Is this thing on? Okay. It says live in 15 seconds. Okay, we're good. Yay! Okay,", "tokens": [50864, 2425, 30, 1119, 341, 551, 322, 30, 1033, 13, 467, 1619, 1621, 294, 2119, 3949, 13, 1033, 11, 321, 434, 665, 13, 13268, 0, 1033, 11, 51712], "temperature": 0.0, "avg_logprob": -0.31305467671361464, "compression_ratio": 1.3384615384615384, "no_speech_prob": 0.3727785348892212}, {"id": 2, "seek": 2696, "start": 27.84, "end": 36.4, "text": " make sure to mute myself. All right, so hello everybody. I'm still figuring out the whole", "tokens": [50408, 652, 988, 281, 24523, 2059, 13, 1057, 558, 11, 370, 7751, 2201, 13, 286, 478, 920, 15213, 484, 264, 1379, 50836], "temperature": 0.0, "avg_logprob": -0.1334214074271066, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.1917540580034256}, {"id": 3, "seek": 2696, "start": 36.4, "end": 41.84, "text": " live streaming thing, so please bear with me, but one thing that y'all said was that you want to", "tokens": [50836, 1621, 11791, 551, 11, 370, 1767, 6155, 365, 385, 11, 457, 472, 551, 300, 288, 6, 336, 848, 390, 300, 291, 528, 281, 51108], "temperature": 0.0, "avg_logprob": -0.1334214074271066, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.1917540580034256}, {"id": 4, "seek": 2696, "start": 41.84, "end": 45.760000000000005, "text": " like see what I'm looking at, which you know, it's a good idea. You don't want to just look at my", "tokens": [51108, 411, 536, 437, 286, 478, 1237, 412, 11, 597, 291, 458, 11, 309, 311, 257, 665, 1558, 13, 509, 500, 380, 528, 281, 445, 574, 412, 452, 51304], "temperature": 0.0, "avg_logprob": -0.1334214074271066, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.1917540580034256}, {"id": 5, "seek": 2696, "start": 45.760000000000005, "end": 50.56, "text": " face. It's like, let's look at stuff together. So I figured I'd follow more or less the same format", "tokens": [51304, 1851, 13, 467, 311, 411, 11, 718, 311, 574, 412, 1507, 1214, 13, 407, 286, 8932, 286, 1116, 1524, 544, 420, 1570, 264, 912, 7877, 51544], "temperature": 0.0, "avg_logprob": -0.1334214074271066, "compression_ratio": 1.5933609958506223, "no_speech_prob": 0.1917540580034256}, {"id": 6, "seek": 5056, "start": 50.56, "end": 57.760000000000005, "text": " that I usually do. I'm in the cognitive AI lab discord, so if you're in the general, you can", "tokens": [50364, 300, 286, 2673, 360, 13, 286, 478, 294, 264, 15605, 7318, 2715, 32989, 11, 370, 498, 291, 434, 294, 264, 2674, 11, 291, 393, 50724], "temperature": 0.0, "avg_logprob": -0.1233959099681107, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.31395578384399414}, {"id": 7, "seek": 5056, "start": 57.760000000000005, "end": 66.4, "text": " drop questions here or papers. So basically what I thought we would do is we would take a look at", "tokens": [50724, 3270, 1651, 510, 420, 10577, 13, 407, 1936, 437, 286, 1194, 321, 576, 360, 307, 321, 576, 747, 257, 574, 412, 51156], "temperature": 0.0, "avg_logprob": -0.1233959099681107, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.31395578384399414}, {"id": 8, "seek": 5056, "start": 66.4, "end": 73.2, "text": " like weekly updates, because it's all going really fast. And you, I've got a lot of feedback from my", "tokens": [51156, 411, 12460, 9205, 11, 570, 309, 311, 439, 516, 534, 2370, 13, 400, 291, 11, 286, 600, 658, 257, 688, 295, 5824, 490, 452, 51496], "temperature": 0.0, "avg_logprob": -0.1233959099681107, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.31395578384399414}, {"id": 9, "seek": 5056, "start": 73.2, "end": 78.80000000000001, "text": " recent live streams, that y'all really liked the interactive aspect of like asking questions,", "tokens": [51496, 5162, 1621, 15842, 11, 300, 288, 6, 336, 534, 4501, 264, 15141, 4171, 295, 411, 3365, 1651, 11, 51776], "temperature": 0.0, "avg_logprob": -0.1233959099681107, "compression_ratio": 1.6041666666666667, "no_speech_prob": 0.31395578384399414}, {"id": 10, "seek": 7880, "start": 78.8, "end": 84.16, "text": " and like Dave, what does this mean? And so please feel free to drop good questions in. I'm also in", "tokens": [50364, 293, 411, 11017, 11, 437, 775, 341, 914, 30, 400, 370, 1767, 841, 1737, 281, 3270, 665, 1651, 294, 13, 286, 478, 611, 294, 50632], "temperature": 0.0, "avg_logprob": -0.14004391544270064, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.005219790618866682}, {"id": 11, "seek": 7880, "start": 84.16, "end": 92.08, "text": " the private Patreon discord, so drop questions there too. Okay, cool. Party time, yeah. Oh,", "tokens": [50632, 264, 4551, 15692, 32989, 11, 370, 3270, 1651, 456, 886, 13, 1033, 11, 1627, 13, 8552, 565, 11, 1338, 13, 876, 11, 51028], "temperature": 0.0, "avg_logprob": -0.14004391544270064, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.005219790618866682}, {"id": 12, "seek": 7880, "start": 92.08, "end": 99.36, "text": " looks like there's a delay of about 15 seconds. Interesting. Okay. Cool. Flippy from the dais", "tokens": [51028, 1542, 411, 456, 311, 257, 8577, 295, 466, 2119, 3949, 13, 14711, 13, 1033, 13, 8561, 13, 479, 2081, 7966, 490, 264, 1120, 271, 51392], "temperature": 0.0, "avg_logprob": -0.14004391544270064, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.005219790618866682}, {"id": 13, "seek": 7880, "start": 99.36, "end": 107.28, "text": " discord. Hello Flippy. All right. Cool. So while some questions get spooled up, I figured I'd go", "tokens": [51392, 32989, 13, 2425, 479, 2081, 7966, 13, 1057, 558, 13, 8561, 13, 407, 1339, 512, 1651, 483, 48884, 292, 493, 11, 286, 8932, 286, 1116, 352, 51788], "temperature": 0.0, "avg_logprob": -0.14004391544270064, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.005219790618866682}, {"id": 14, "seek": 10728, "start": 107.28, "end": 113.76, "text": " through a couple of tools and stuff that I've seen. So someone, I think actually Flippy, this", "tokens": [50364, 807, 257, 1916, 295, 3873, 293, 1507, 300, 286, 600, 1612, 13, 407, 1580, 11, 286, 519, 767, 479, 2081, 7966, 11, 341, 50688], "temperature": 0.0, "avg_logprob": -0.058914528952704534, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.005910733249038458}, {"id": 15, "seek": 10728, "start": 113.76, "end": 120.0, "text": " might have been you or someone in the dais discord, pointed out this tool. So this is basically", "tokens": [50688, 1062, 362, 668, 291, 420, 1580, 294, 264, 1120, 271, 32989, 11, 10932, 484, 341, 2290, 13, 407, 341, 307, 1936, 51000], "temperature": 0.0, "avg_logprob": -0.058914528952704534, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.005910733249038458}, {"id": 16, "seek": 10728, "start": 120.0, "end": 126.24000000000001, "text": " something that I and others have been like thinking about and talking about. It's basically a hybrid", "tokens": [51000, 746, 300, 286, 293, 2357, 362, 668, 411, 1953, 466, 293, 1417, 466, 13, 467, 311, 1936, 257, 13051, 51312], "temperature": 0.0, "avg_logprob": -0.058914528952704534, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.005910733249038458}, {"id": 17, "seek": 10728, "start": 126.24000000000001, "end": 134.4, "text": " of vector database and knowledge graphs. And it's also got a pretty interface. So", "tokens": [51312, 295, 8062, 8149, 293, 3601, 24877, 13, 400, 309, 311, 611, 658, 257, 1238, 9226, 13, 407, 51720], "temperature": 0.0, "avg_logprob": -0.058914528952704534, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.005910733249038458}, {"id": 18, "seek": 13440, "start": 135.36, "end": 141.68, "text": " like, it's worth just scrolling through and like reading every every bit of this. And then kind", "tokens": [50412, 411, 11, 309, 311, 3163, 445, 29053, 807, 293, 411, 3760, 633, 633, 857, 295, 341, 13, 400, 550, 733, 50728], "temperature": 0.0, "avg_logprob": -0.15546804063775566, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00041730873635970056}, {"id": 19, "seek": 13440, "start": 141.68, "end": 148.72, "text": " of experimenting with it. But but it will create. So this is one of the coolest things is it'll", "tokens": [50728, 295, 29070, 365, 309, 13, 583, 457, 309, 486, 1884, 13, 407, 341, 307, 472, 295, 264, 22013, 721, 307, 309, 603, 51080], "temperature": 0.0, "avg_logprob": -0.15546804063775566, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00041730873635970056}, {"id": 20, "seek": 13440, "start": 148.72, "end": 154.8, "text": " create a knowledge graph of all the clusters and stuff. But you can find the gaps, which when", "tokens": [51080, 1884, 257, 3601, 4295, 295, 439, 264, 23313, 293, 1507, 13, 583, 291, 393, 915, 264, 15031, 11, 597, 562, 51384], "temperature": 0.0, "avg_logprob": -0.15546804063775566, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00041730873635970056}, {"id": 21, "seek": 13440, "start": 154.8, "end": 161.36, "text": " you're thinking about autonomous or semi autonomous AI agents, this is really good because then", "tokens": [51384, 291, 434, 1953, 466, 23797, 420, 12909, 23797, 7318, 12554, 11, 341, 307, 534, 665, 570, 550, 51712], "temperature": 0.0, "avg_logprob": -0.15546804063775566, "compression_ratio": 1.6212765957446809, "no_speech_prob": 0.00041730873635970056}, {"id": 22, "seek": 16136, "start": 162.0, "end": 168.24, "text": " you can know what you don't know. And what I mean by that is if you're aware of all the things that", "tokens": [50396, 291, 393, 458, 437, 291, 500, 380, 458, 13, 400, 437, 286, 914, 538, 300, 307, 498, 291, 434, 3650, 295, 439, 264, 721, 300, 50708], "temperature": 0.0, "avg_logprob": -0.08738561195902306, "compression_ratio": 1.759090909090909, "no_speech_prob": 0.01691295951604843}, {"id": 23, "seek": 16136, "start": 168.24, "end": 174.08, "text": " you know, but you can detect some semantic gaps in your knowledge, that can help you zoom in on", "tokens": [50708, 291, 458, 11, 457, 291, 393, 5531, 512, 47982, 15031, 294, 428, 3601, 11, 300, 393, 854, 291, 8863, 294, 322, 51000], "temperature": 0.0, "avg_logprob": -0.08738561195902306, "compression_ratio": 1.759090909090909, "no_speech_prob": 0.01691295951604843}, {"id": 24, "seek": 16136, "start": 174.08, "end": 180.08, "text": " the things that you need to go learn about. So in front notice is the tool in front notice.com.", "tokens": [51000, 264, 721, 300, 291, 643, 281, 352, 1466, 466, 13, 407, 294, 1868, 3449, 307, 264, 2290, 294, 1868, 3449, 13, 1112, 13, 51300], "temperature": 0.0, "avg_logprob": -0.08738561195902306, "compression_ratio": 1.759090909090909, "no_speech_prob": 0.01691295951604843}, {"id": 25, "seek": 16136, "start": 180.08, "end": 186.0, "text": " I can never remember the name of the darn thing. I'm going to blame allergies and say that it's", "tokens": [51300, 286, 393, 1128, 1604, 264, 1315, 295, 264, 29063, 551, 13, 286, 478, 516, 281, 10127, 37007, 293, 584, 300, 309, 311, 51596], "temperature": 0.0, "avg_logprob": -0.08738561195902306, "compression_ratio": 1.759090909090909, "no_speech_prob": 0.01691295951604843}, {"id": 26, "seek": 18600, "start": 186.08, "end": 192.96, "text": " just brain inflammation. That's my excuse and I'm sticking to it. But yes, so this is a super cool", "tokens": [50368, 445, 3567, 21613, 13, 663, 311, 452, 8960, 293, 286, 478, 13465, 281, 309, 13, 583, 2086, 11, 370, 341, 307, 257, 1687, 1627, 50712], "temperature": 0.0, "avg_logprob": -0.1291309513457834, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.022975388914346695}, {"id": 27, "seek": 18600, "start": 192.96, "end": 204.96, "text": " tool. This kind of technology will definitely be part of of like autonomous AI agents. And this is", "tokens": [50712, 2290, 13, 639, 733, 295, 2899, 486, 2138, 312, 644, 295, 295, 411, 23797, 7318, 12554, 13, 400, 341, 307, 51312], "temperature": 0.0, "avg_logprob": -0.1291309513457834, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.022975388914346695}, {"id": 28, "seek": 18600, "start": 205.6, "end": 211.2, "text": " functionally similar to what I worked on with Remo. Remo is much, much, much simpler though.", "tokens": [51344, 2445, 379, 2531, 281, 437, 286, 2732, 322, 365, 46445, 13, 46445, 307, 709, 11, 709, 11, 709, 18587, 1673, 13, 51624], "temperature": 0.0, "avg_logprob": -0.1291309513457834, "compression_ratio": 1.4572864321608041, "no_speech_prob": 0.022975388914346695}, {"id": 29, "seek": 21120, "start": 212.0, "end": 217.76, "text": " So I often have some people ask me like, Oh, hey, can Remo do this? And that and I'm like, no,", "tokens": [50404, 407, 286, 2049, 362, 512, 561, 1029, 385, 411, 11, 876, 11, 4177, 11, 393, 46445, 360, 341, 30, 400, 300, 293, 286, 478, 411, 11, 572, 11, 50692], "temperature": 0.0, "avg_logprob": -0.14003477096557618, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.036214523017406464}, {"id": 30, "seek": 21120, "start": 217.76, "end": 223.35999999999999, "text": " like, Remo was meant to solve one very specific problem. So for memory stuff, I usually point", "tokens": [50692, 411, 11, 46445, 390, 4140, 281, 5039, 472, 588, 2685, 1154, 13, 407, 337, 4675, 1507, 11, 286, 2673, 935, 50972], "temperature": 0.0, "avg_logprob": -0.14003477096557618, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.036214523017406464}, {"id": 31, "seek": 21120, "start": 223.35999999999999, "end": 231.44, "text": " people at llama index and chroma db. So chroma db. Do I seriously not have that bookmarked?", "tokens": [50972, 561, 412, 23272, 8186, 293, 16209, 64, 274, 65, 13, 407, 16209, 64, 274, 65, 13, 1144, 286, 6638, 406, 362, 300, 1446, 5638, 292, 30, 51376], "temperature": 0.0, "avg_logprob": -0.14003477096557618, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.036214523017406464}, {"id": 32, "seek": 21120, "start": 232.32, "end": 238.39999999999998, "text": " So chroma db is a vector database that runs just like SQLite. So it's pip install chroma db,", "tokens": [51420, 407, 16209, 64, 274, 65, 307, 257, 8062, 8149, 300, 6676, 445, 411, 19200, 642, 13, 407, 309, 311, 8489, 3625, 16209, 64, 274, 65, 11, 51724], "temperature": 0.0, "avg_logprob": -0.14003477096557618, "compression_ratio": 1.6008583690987124, "no_speech_prob": 0.036214523017406464}, {"id": 33, "seek": 23840, "start": 238.48000000000002, "end": 244.64000000000001, "text": " you create a local client just like you do SQLite. So I tried to create something like this called", "tokens": [50368, 291, 1884, 257, 2654, 6423, 445, 411, 291, 360, 19200, 642, 13, 407, 286, 3031, 281, 1884, 746, 411, 341, 1219, 50676], "temperature": 0.0, "avg_logprob": -0.10025189473078801, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.010986092500388622}, {"id": 34, "seek": 23840, "start": 244.64000000000001, "end": 249.6, "text": " VDB light like a few months ago. And I quickly realized that I was in way over my head. So I'm", "tokens": [50676, 691, 27735, 1442, 411, 257, 1326, 2493, 2057, 13, 400, 286, 2661, 5334, 300, 286, 390, 294, 636, 670, 452, 1378, 13, 407, 286, 478, 50924], "temperature": 0.0, "avg_logprob": -0.10025189473078801, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.010986092500388622}, {"id": 35, "seek": 23840, "start": 249.6, "end": 255.76, "text": " glad someone built this. And they just got an $18 million seed round. Holy mackerel. Man,", "tokens": [50924, 5404, 1580, 3094, 341, 13, 400, 436, 445, 658, 364, 1848, 6494, 2459, 8871, 3098, 13, 6295, 275, 501, 39796, 13, 2458, 11, 51232], "temperature": 0.0, "avg_logprob": -0.10025189473078801, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.010986092500388622}, {"id": 36, "seek": 23840, "start": 255.76, "end": 261.36, "text": " I should have stuck with VDB light. I could have had an $18 million seed round. Anyways, maybe I'll", "tokens": [51232, 286, 820, 362, 5541, 365, 691, 27735, 1442, 13, 286, 727, 362, 632, 364, 1848, 6494, 2459, 8871, 3098, 13, 15585, 11, 1310, 286, 603, 51512], "temperature": 0.0, "avg_logprob": -0.10025189473078801, "compression_ratio": 1.602510460251046, "no_speech_prob": 0.010986092500388622}, {"id": 37, "seek": 26136, "start": 261.36, "end": 270.08000000000004, "text": " do that with Remo who knows. So chroma db, super simple man, seriously $18 million for this one", "tokens": [50364, 360, 300, 365, 46445, 567, 3255, 13, 407, 16209, 64, 274, 65, 11, 1687, 2199, 587, 11, 6638, 1848, 6494, 2459, 337, 341, 472, 50800], "temperature": 0.0, "avg_logprob": -0.12958243341729192, "compression_ratio": 1.5040650406504066, "no_speech_prob": 0.028434719890356064}, {"id": 38, "seek": 26136, "start": 270.08000000000004, "end": 276.96000000000004, "text": " thing. Okay, I'm gonna let that go. llama index also. So llama index, I kind of didn't pay it", "tokens": [50800, 551, 13, 1033, 11, 286, 478, 799, 718, 300, 352, 13, 23272, 8186, 611, 13, 407, 23272, 8186, 11, 286, 733, 295, 994, 380, 1689, 309, 51144], "temperature": 0.0, "avg_logprob": -0.12958243341729192, "compression_ratio": 1.5040650406504066, "no_speech_prob": 0.028434719890356064}, {"id": 39, "seek": 26136, "start": 276.96000000000004, "end": 281.44, "text": " any any attention at first because it's like, Okay, that's a silly name. This was clearly just", "tokens": [51144, 604, 604, 3202, 412, 700, 570, 309, 311, 411, 11, 1033, 11, 300, 311, 257, 11774, 1315, 13, 639, 390, 4448, 445, 51368], "temperature": 0.0, "avg_logprob": -0.12958243341729192, "compression_ratio": 1.5040650406504066, "no_speech_prob": 0.028434719890356064}, {"id": 40, "seek": 26136, "start": 281.44, "end": 287.12, "text": " someone's little side project. But if you look at all the types of indices they have,", "tokens": [51368, 1580, 311, 707, 1252, 1716, 13, 583, 498, 291, 574, 412, 439, 264, 3467, 295, 43840, 436, 362, 11, 51652], "temperature": 0.0, "avg_logprob": -0.12958243341729192, "compression_ratio": 1.5040650406504066, "no_speech_prob": 0.028434719890356064}, {"id": 41, "seek": 28712, "start": 288.08, "end": 294.56, "text": " they've got list index, table index, tree index. So Remo is very similar to llamas tree index.", "tokens": [50412, 436, 600, 658, 1329, 8186, 11, 3199, 8186, 11, 4230, 8186, 13, 407, 46445, 307, 588, 2531, 281, 16848, 296, 4230, 8186, 13, 50736], "temperature": 0.0, "avg_logprob": -0.17476901441517442, "compression_ratio": 1.72, "no_speech_prob": 0.0064879246056079865}, {"id": 42, "seek": 28712, "start": 294.56, "end": 299.68, "text": " Although I will say that I look through the code. And I think that their tree index is kind of basic.", "tokens": [50736, 5780, 286, 486, 584, 300, 286, 574, 807, 264, 3089, 13, 400, 286, 519, 300, 641, 4230, 8186, 307, 733, 295, 3875, 13, 50992], "temperature": 0.0, "avg_logprob": -0.17476901441517442, "compression_ratio": 1.72, "no_speech_prob": 0.0064879246056079865}, {"id": 43, "seek": 28712, "start": 299.68, "end": 306.16, "text": " I think that my Remo framework does a little bit that theirs doesn't. But I'm not going to dive into", "tokens": [50992, 286, 519, 300, 452, 46445, 8388, 775, 257, 707, 857, 300, 22760, 1177, 380, 13, 583, 286, 478, 406, 516, 281, 9192, 666, 51316], "temperature": 0.0, "avg_logprob": -0.17476901441517442, "compression_ratio": 1.72, "no_speech_prob": 0.0064879246056079865}, {"id": 44, "seek": 28712, "start": 306.16, "end": 309.92, "text": " that because I don't know that for certain. I didn't take a super close look at the code.", "tokens": [51316, 300, 570, 286, 500, 380, 458, 300, 337, 1629, 13, 286, 994, 380, 747, 257, 1687, 1998, 574, 412, 264, 3089, 13, 51504], "temperature": 0.0, "avg_logprob": -0.17476901441517442, "compression_ratio": 1.72, "no_speech_prob": 0.0064879246056079865}, {"id": 45, "seek": 30992, "start": 310.24, "end": 317.6, "text": " Yeah, but so those are those are some memory storage tools. So let me check on the live stream", "tokens": [50380, 865, 11, 457, 370, 729, 366, 729, 366, 512, 4675, 6725, 3873, 13, 407, 718, 385, 1520, 322, 264, 1621, 4309, 50748], "temperature": 0.0, "avg_logprob": -0.1164805914766045, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.17326144874095917}, {"id": 46, "seek": 30992, "start": 318.24, "end": 323.6, "text": " and see where we're at. Whoops. All right. Oh, wow, we got lots of questions. Okay, cool.", "tokens": [50780, 293, 536, 689, 321, 434, 412, 13, 45263, 13, 1057, 558, 13, 876, 11, 6076, 11, 321, 658, 3195, 295, 1651, 13, 1033, 11, 1627, 13, 51048], "temperature": 0.0, "avg_logprob": -0.1164805914766045, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.17326144874095917}, {"id": 47, "seek": 30992, "start": 324.32, "end": 329.28000000000003, "text": " God's not dead rather believe and go to the good place and interesting. Okay.", "tokens": [51084, 1265, 311, 406, 3116, 2831, 1697, 293, 352, 281, 264, 665, 1081, 293, 1880, 13, 1033, 13, 51332], "temperature": 0.0, "avg_logprob": -0.1164805914766045, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.17326144874095917}, {"id": 48, "seek": 30992, "start": 331.68, "end": 335.84000000000003, "text": " Let's see how to discover new wisdom from LLM. That's an interesting question.", "tokens": [51452, 961, 311, 536, 577, 281, 4411, 777, 10712, 490, 441, 43, 44, 13, 663, 311, 364, 1880, 1168, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1164805914766045, "compression_ratio": 1.5291479820627802, "no_speech_prob": 0.17326144874095917}, {"id": 49, "seek": 33584, "start": 336.4, "end": 340.0, "text": " Um, let's see. Let me,", "tokens": [50392, 3301, 11, 718, 311, 536, 13, 961, 385, 11, 50572], "temperature": 0.0, "avg_logprob": -0.20670137218400544, "compression_ratio": 1.3385826771653544, "no_speech_prob": 0.001987735740840435}, {"id": 50, "seek": 33584, "start": 343.11999999999995, "end": 348.4, "text": " you people ask questions far too early. Let me go over to discord to see if,", "tokens": [50728, 291, 561, 1029, 1651, 1400, 886, 2440, 13, 961, 385, 352, 670, 281, 32989, 281, 536, 498, 11, 50992], "temperature": 0.0, "avg_logprob": -0.20670137218400544, "compression_ratio": 1.3385826771653544, "no_speech_prob": 0.001987735740840435}, {"id": 51, "seek": 33584, "start": 351.28, "end": 359.03999999999996, "text": " yeah, please go ahead and drop some questions. Patreon get first dibs.", "tokens": [51136, 1338, 11, 1767, 352, 2286, 293, 3270, 512, 1651, 13, 15692, 483, 700, 23064, 82, 13, 51524], "temperature": 0.0, "avg_logprob": -0.20670137218400544, "compression_ratio": 1.3385826771653544, "no_speech_prob": 0.001987735740840435}, {"id": 52, "seek": 35904, "start": 359.04, "end": 368.64000000000004, "text": " All right. What do you think is the future of SAAS sales jobs for recruiting agencies?", "tokens": [50364, 1057, 558, 13, 708, 360, 291, 519, 307, 264, 2027, 295, 16482, 3160, 5763, 4782, 337, 25987, 9504, 30, 50844], "temperature": 0.0, "avg_logprob": -0.16338131453964735, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.01168614812195301}, {"id": 53, "seek": 35904, "start": 370.32, "end": 379.20000000000005, "text": " Oh, sales jobs and for recruiting agencies. So I mean, the sales level is still very human.", "tokens": [50928, 876, 11, 5763, 4782, 293, 337, 25987, 9504, 13, 407, 286, 914, 11, 264, 5763, 1496, 307, 920, 588, 1952, 13, 51372], "temperature": 0.0, "avg_logprob": -0.16338131453964735, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.01168614812195301}, {"id": 54, "seek": 35904, "start": 379.20000000000005, "end": 383.36, "text": " So sales is not going to change for a while. Ditto for recruiting, although there's a lot", "tokens": [51372, 407, 5763, 307, 406, 516, 281, 1319, 337, 257, 1339, 13, 413, 34924, 337, 25987, 11, 4878, 456, 311, 257, 688, 51580], "temperature": 0.0, "avg_logprob": -0.16338131453964735, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.01168614812195301}, {"id": 55, "seek": 35904, "start": 383.36, "end": 388.88, "text": " of AI and recruiting already where like AI will read your resume and AI will watch a video of you", "tokens": [51580, 295, 7318, 293, 25987, 1217, 689, 411, 7318, 486, 1401, 428, 15358, 293, 7318, 486, 1159, 257, 960, 295, 291, 51856], "temperature": 0.0, "avg_logprob": -0.16338131453964735, "compression_ratio": 1.6866359447004609, "no_speech_prob": 0.01168614812195301}, {"id": 56, "seek": 38888, "start": 388.88, "end": 395.84, "text": " answering questions. You know, more and more of that's coming, but that's about it. Let's see.", "tokens": [50364, 13430, 1651, 13, 509, 458, 11, 544, 293, 544, 295, 300, 311, 1348, 11, 457, 300, 311, 466, 309, 13, 961, 311, 536, 13, 50712], "temperature": 0.0, "avg_logprob": -0.11695168568537785, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0023229613434523344}, {"id": 57, "seek": 38888, "start": 395.84, "end": 401.76, "text": " All right. We got a whole bunch of questions coming in on the Patreon side. So, yeah, database,", "tokens": [50712, 1057, 558, 13, 492, 658, 257, 1379, 3840, 295, 1651, 1348, 294, 322, 264, 15692, 1252, 13, 407, 11, 1338, 11, 8149, 11, 51008], "temperature": 0.0, "avg_logprob": -0.11695168568537785, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0023229613434523344}, {"id": 58, "seek": 38888, "start": 401.76, "end": 408.64, "text": " short answer, diversify your job skills. So there's that. Let's see. Zoom in a little so you", "tokens": [51008, 2099, 1867, 11, 6111, 2505, 428, 1691, 3942, 13, 407, 456, 311, 300, 13, 961, 311, 536, 13, 13453, 294, 257, 707, 370, 291, 51352], "temperature": 0.0, "avg_logprob": -0.11695168568537785, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0023229613434523344}, {"id": 59, "seek": 38888, "start": 408.64, "end": 415.12, "text": " guys can read this. Let me jump back over here real quick. But do you still expect AGI within 18", "tokens": [51352, 1074, 393, 1401, 341, 13, 961, 385, 3012, 646, 670, 510, 957, 1702, 13, 583, 360, 291, 920, 2066, 316, 26252, 1951, 2443, 51676], "temperature": 0.0, "avg_logprob": -0.11695168568537785, "compression_ratio": 1.5384615384615385, "no_speech_prob": 0.0023229613434523344}, {"id": 60, "seek": 41512, "start": 415.12, "end": 419.28000000000003, "text": " months was stating they do not want to make models bigger but rather more efficient? Yeah,", "tokens": [50364, 2493, 390, 26688, 436, 360, 406, 528, 281, 652, 5245, 3801, 457, 2831, 544, 7148, 30, 865, 11, 50572], "temperature": 0.0, "avg_logprob": -0.0992919857762441, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.06752649694681168}, {"id": 61, "seek": 41512, "start": 419.28000000000003, "end": 426.96, "text": " I think AGI in 18 months is still conservative. Honestly, I think that we will have,", "tokens": [50572, 286, 519, 316, 26252, 294, 2443, 2493, 307, 920, 13780, 13, 12348, 11, 286, 519, 300, 321, 486, 362, 11, 50956], "temperature": 0.0, "avg_logprob": -0.0992919857762441, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.06752649694681168}, {"id": 62, "seek": 41512, "start": 428.32, "end": 433.68, "text": " as people develop the architecture for autonomous AI, I think that we will be able to say that we", "tokens": [51024, 382, 561, 1499, 264, 9482, 337, 23797, 7318, 11, 286, 519, 300, 321, 486, 312, 1075, 281, 584, 300, 321, 51292], "temperature": 0.0, "avg_logprob": -0.0992919857762441, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.06752649694681168}, {"id": 63, "seek": 41512, "start": 433.68, "end": 439.04, "text": " have AGI by the end of this year. But people will realize that it's like, okay, we have an agent that", "tokens": [51292, 362, 316, 26252, 538, 264, 917, 295, 341, 1064, 13, 583, 561, 486, 4325, 300, 309, 311, 411, 11, 1392, 11, 321, 362, 364, 9461, 300, 51560], "temperature": 0.0, "avg_logprob": -0.0992919857762441, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.06752649694681168}, {"id": 64, "seek": 41512, "start": 439.04, "end": 443.76, "text": " can do anything, but it's expensive or it's slow or it's kind of dumb, that kind of thing.", "tokens": [51560, 393, 360, 1340, 11, 457, 309, 311, 5124, 420, 309, 311, 2964, 420, 309, 311, 733, 295, 10316, 11, 300, 733, 295, 551, 13, 51796], "temperature": 0.0, "avg_logprob": -0.0992919857762441, "compression_ratio": 1.706959706959707, "no_speech_prob": 0.06752649694681168}, {"id": 65, "seek": 44512, "start": 445.84000000000003, "end": 452.0, "text": " Let's see. Check on Discord real quick. Is her about to become reality? Yeah, lots of people", "tokens": [50400, 961, 311, 536, 13, 6881, 322, 32623, 957, 1702, 13, 1119, 720, 466, 281, 1813, 4103, 30, 865, 11, 3195, 295, 561, 50708], "temperature": 0.0, "avg_logprob": -0.0976053137528269, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0019266429590061307}, {"id": 66, "seek": 44512, "start": 452.0, "end": 462.48, "text": " are working on AI companions. They're going to get more sophisticated real fast. I've actually got", "tokens": [50708, 366, 1364, 322, 7318, 28009, 13, 814, 434, 516, 281, 483, 544, 16950, 957, 2370, 13, 286, 600, 767, 658, 51232], "temperature": 0.0, "avg_logprob": -0.0976053137528269, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0019266429590061307}, {"id": 67, "seek": 44512, "start": 462.48, "end": 468.16, "text": " a couple more videos upcoming planned. So I've got the Westworld video coming up on Sunday.", "tokens": [51232, 257, 1916, 544, 2145, 11500, 8589, 13, 407, 286, 600, 658, 264, 4055, 13217, 960, 1348, 493, 322, 7776, 13, 51516], "temperature": 0.0, "avg_logprob": -0.0976053137528269, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0019266429590061307}, {"id": 68, "seek": 44512, "start": 468.16, "end": 472.32, "text": " I've got a Ghost in the Shell video planned. I've got a Mass Effect video planned. I've got", "tokens": [51516, 286, 600, 658, 257, 16323, 294, 264, 22863, 960, 8589, 13, 286, 600, 658, 257, 10482, 17764, 960, 8589, 13, 286, 600, 658, 51724], "temperature": 0.0, "avg_logprob": -0.0976053137528269, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0019266429590061307}, {"id": 69, "seek": 47232, "start": 472.48, "end": 478.32, "text": " a Dow and Blockchain video planned. So that's all what's coming. Maybe I shouldn't spoil it. Okay,", "tokens": [50372, 257, 20947, 293, 48916, 960, 8589, 13, 407, 300, 311, 439, 437, 311, 1348, 13, 2704, 286, 4659, 380, 18630, 309, 13, 1033, 11, 50664], "temperature": 0.0, "avg_logprob": -0.11457510917417464, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.010327165015041828}, {"id": 70, "seek": 47232, "start": 478.32, "end": 485.76, "text": " well, whatever. But yeah, so I was thinking about hitting on her and Ex Machina and stuff as well.", "tokens": [50664, 731, 11, 2035, 13, 583, 1338, 11, 370, 286, 390, 1953, 466, 8850, 322, 720, 293, 2111, 12089, 1426, 293, 1507, 382, 731, 13, 51036], "temperature": 0.0, "avg_logprob": -0.11457510917417464, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.010327165015041828}, {"id": 71, "seek": 47232, "start": 487.28, "end": 490.96, "text": " Let's see. How can we be certain things are advancing exponentially?", "tokens": [51112, 961, 311, 536, 13, 1012, 393, 321, 312, 1629, 721, 366, 27267, 37330, 30, 51296], "temperature": 0.0, "avg_logprob": -0.11457510917417464, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.010327165015041828}, {"id": 72, "seek": 47232, "start": 492.48, "end": 500.32, "text": " So that's a good question, James. Generally speaking, you can't tell if you have a narrow", "tokens": [51372, 407, 300, 311, 257, 665, 1168, 11, 5678, 13, 21082, 4124, 11, 291, 393, 380, 980, 498, 291, 362, 257, 9432, 51764], "temperature": 0.0, "avg_logprob": -0.11457510917417464, "compression_ratio": 1.4833333333333334, "no_speech_prob": 0.010327165015041828}, {"id": 73, "seek": 50032, "start": 500.32, "end": 506.24, "text": " window, but we were joking around the other day and we're pointing out that like a few weeks ago,", "tokens": [50364, 4910, 11, 457, 321, 645, 17396, 926, 264, 661, 786, 293, 321, 434, 12166, 484, 300, 411, 257, 1326, 3259, 2057, 11, 50660], "temperature": 0.0, "avg_logprob": -0.0929658177134755, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.01168618630617857}, {"id": 74, "seek": 50032, "start": 506.24, "end": 513.04, "text": " it was like you would reasonably expect a couple of cool AI bits of news per week,", "tokens": [50660, 309, 390, 411, 291, 576, 23551, 2066, 257, 1916, 295, 1627, 7318, 9239, 295, 2583, 680, 1243, 11, 51000], "temperature": 0.0, "avg_logprob": -0.0929658177134755, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.01168618630617857}, {"id": 75, "seek": 50032, "start": 513.04, "end": 518.56, "text": " and now we're at the point where we expect several per day. Now, it might come in cycles,", "tokens": [51000, 293, 586, 321, 434, 412, 264, 935, 689, 321, 2066, 2940, 680, 786, 13, 823, 11, 309, 1062, 808, 294, 17796, 11, 51276], "temperature": 0.0, "avg_logprob": -0.0929658177134755, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.01168618630617857}, {"id": 76, "seek": 50032, "start": 518.56, "end": 526.8, "text": " it might come in waves, but generally speaking, this very closely matches what Ray Kurzweil", "tokens": [51276, 309, 1062, 808, 294, 9417, 11, 457, 5101, 4124, 11, 341, 588, 8185, 10676, 437, 10883, 45307, 826, 388, 51688], "temperature": 0.0, "avg_logprob": -0.0929658177134755, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.01168618630617857}, {"id": 77, "seek": 52680, "start": 527.76, "end": 534.7199999999999, "text": " said, or maybe it was Michio Kaku on a video, a documentary that I watched quite a few years ago.", "tokens": [50412, 848, 11, 420, 1310, 309, 390, 3392, 1004, 591, 15803, 322, 257, 960, 11, 257, 15674, 300, 286, 6337, 1596, 257, 1326, 924, 2057, 13, 50760], "temperature": 0.0, "avg_logprob": -0.09547012631255801, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.05032336711883545}, {"id": 78, "seek": 52680, "start": 534.7199999999999, "end": 540.7199999999999, "text": " I think it was Michio. He was describing what it will feel like to approach the singularity,", "tokens": [50760, 286, 519, 309, 390, 3392, 1004, 13, 634, 390, 16141, 437, 309, 486, 841, 411, 281, 3109, 264, 20010, 507, 11, 51060], "temperature": 0.0, "avg_logprob": -0.09547012631255801, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.05032336711883545}, {"id": 79, "seek": 52680, "start": 540.7199999999999, "end": 547.04, "text": " and he said, oh, well, when information is doubling every two years, you don't really feel that on a", "tokens": [51060, 293, 415, 848, 11, 1954, 11, 731, 11, 562, 1589, 307, 33651, 633, 732, 924, 11, 291, 500, 380, 534, 841, 300, 322, 257, 51376], "temperature": 0.0, "avg_logprob": -0.09547012631255801, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.05032336711883545}, {"id": 80, "seek": 52680, "start": 547.04, "end": 554.0799999999999, "text": " day-to-day basis. And then when information is doubling every six months, that's fast enough", "tokens": [51376, 786, 12, 1353, 12, 810, 5143, 13, 400, 550, 562, 1589, 307, 33651, 633, 2309, 2493, 11, 300, 311, 2370, 1547, 51728], "temperature": 0.0, "avg_logprob": -0.09547012631255801, "compression_ratio": 1.6695652173913043, "no_speech_prob": 0.05032336711883545}, {"id": 81, "seek": 55408, "start": 554.1600000000001, "end": 558.64, "text": " that you're like, oh, hey, this thing that I didn't think would be solved for another couple years", "tokens": [50368, 300, 291, 434, 411, 11, 1954, 11, 4177, 11, 341, 551, 300, 286, 994, 380, 519, 576, 312, 13041, 337, 1071, 1916, 924, 50592], "temperature": 0.0, "avg_logprob": -0.08503727446821399, "compression_ratio": 1.8687258687258688, "no_speech_prob": 0.048850178718566895}, {"id": 82, "seek": 55408, "start": 558.64, "end": 565.2800000000001, "text": " was solved this year. And then, but as it ramps up faster and faster, that time keeps having.", "tokens": [50592, 390, 13041, 341, 1064, 13, 400, 550, 11, 457, 382, 309, 12428, 82, 493, 4663, 293, 4663, 11, 300, 565, 5965, 1419, 13, 50924], "temperature": 0.0, "avg_logprob": -0.08503727446821399, "compression_ratio": 1.8687258687258688, "no_speech_prob": 0.048850178718566895}, {"id": 83, "seek": 55408, "start": 565.2800000000001, "end": 572.24, "text": " And so then three months after that, you realize, oh, wait, we've advanced again. And I think we're", "tokens": [50924, 400, 370, 550, 1045, 2493, 934, 300, 11, 291, 4325, 11, 1954, 11, 1699, 11, 321, 600, 7339, 797, 13, 400, 286, 519, 321, 434, 51272], "temperature": 0.0, "avg_logprob": -0.08503727446821399, "compression_ratio": 1.8687258687258688, "no_speech_prob": 0.048850178718566895}, {"id": 84, "seek": 55408, "start": 572.24, "end": 578.08, "text": " right at that, like, that three, you know, where six months ago, we're like, oh, this stuff is 10", "tokens": [51272, 558, 412, 300, 11, 411, 11, 300, 1045, 11, 291, 458, 11, 689, 2309, 2493, 2057, 11, 321, 434, 411, 11, 1954, 11, 341, 1507, 307, 1266, 51564], "temperature": 0.0, "avg_logprob": -0.08503727446821399, "compression_ratio": 1.8687258687258688, "no_speech_prob": 0.048850178718566895}, {"id": 85, "seek": 55408, "start": 578.08, "end": 582.6400000000001, "text": " years away. Six months later, we're like, this stuff is 10 months away. So I think that where", "tokens": [51564, 924, 1314, 13, 11678, 2493, 1780, 11, 321, 434, 411, 11, 341, 1507, 307, 1266, 2493, 1314, 13, 407, 286, 519, 300, 689, 51792], "temperature": 0.0, "avg_logprob": -0.08503727446821399, "compression_ratio": 1.8687258687258688, "no_speech_prob": 0.048850178718566895}, {"id": 86, "seek": 58264, "start": 582.64, "end": 587.04, "text": " you could make a good argument that we're in some respects, we're in the exponential ramp up right", "tokens": [50364, 291, 727, 652, 257, 665, 6770, 300, 321, 434, 294, 512, 24126, 11, 321, 434, 294, 264, 21510, 12428, 493, 558, 50584], "temperature": 0.0, "avg_logprob": -0.08560987680899997, "compression_ratio": 1.657718120805369, "no_speech_prob": 0.014955054968595505}, {"id": 87, "seek": 58264, "start": 587.04, "end": 593.36, "text": " now. That being said, some of this information is so big, and it's changing so fast, it's difficult", "tokens": [50584, 586, 13, 663, 885, 848, 11, 512, 295, 341, 1589, 307, 370, 955, 11, 293, 309, 311, 4473, 370, 2370, 11, 309, 311, 2252, 50900], "temperature": 0.0, "avg_logprob": -0.08560987680899997, "compression_ratio": 1.657718120805369, "no_speech_prob": 0.014955054968595505}, {"id": 88, "seek": 58264, "start": 593.36, "end": 598.96, "text": " to measure. We'll actually need AI to measure the rate of papers and tools. All right, so Seaf,", "tokens": [50900, 281, 3481, 13, 492, 603, 767, 643, 7318, 281, 3481, 264, 3314, 295, 10577, 293, 3873, 13, 1057, 558, 11, 370, 1100, 2792, 11, 51180], "temperature": 0.0, "avg_logprob": -0.08560987680899997, "compression_ratio": 1.657718120805369, "no_speech_prob": 0.014955054968595505}, {"id": 89, "seek": 58264, "start": 598.96, "end": 604.3199999999999, "text": " you said, how do you think AI will impact religion, particularly monotheistic religions? I think it", "tokens": [51180, 291, 848, 11, 577, 360, 291, 519, 7318, 486, 2712, 7561, 11, 4098, 1108, 24863, 3142, 21212, 30, 286, 519, 309, 51448], "temperature": 0.0, "avg_logprob": -0.08560987680899997, "compression_ratio": 1.657718120805369, "no_speech_prob": 0.014955054968595505}, {"id": 90, "seek": 58264, "start": 604.3199999999999, "end": 609.36, "text": " will create a mass crisis of consciousness, which will make the transition period even more chaotic", "tokens": [51448, 486, 1884, 257, 2758, 5869, 295, 10081, 11, 597, 486, 652, 264, 6034, 2896, 754, 544, 27013, 51700], "temperature": 0.0, "avg_logprob": -0.08560987680899997, "compression_ratio": 1.657718120805369, "no_speech_prob": 0.014955054968595505}, {"id": 91, "seek": 60936, "start": 609.36, "end": 619.12, "text": " and extreme. Yeah, no, sorry, Seaf, I was getting around to it. Yeah, so I've actually had some", "tokens": [50364, 293, 8084, 13, 865, 11, 572, 11, 2597, 11, 1100, 2792, 11, 286, 390, 1242, 926, 281, 309, 13, 865, 11, 370, 286, 600, 767, 632, 512, 50852], "temperature": 0.0, "avg_logprob": -0.08392271314348493, "compression_ratio": 1.6016597510373445, "no_speech_prob": 0.01744118332862854}, {"id": 92, "seek": 60936, "start": 619.12, "end": 624.08, "text": " interesting internet debates with more conservative and more religious people. Granted, I don't do", "tokens": [50852, 1880, 4705, 24203, 365, 544, 13780, 293, 544, 7185, 561, 13, 2606, 15587, 11, 286, 500, 380, 360, 51100], "temperature": 0.0, "avg_logprob": -0.08392271314348493, "compression_ratio": 1.6016597510373445, "no_speech_prob": 0.01744118332862854}, {"id": 93, "seek": 60936, "start": 624.08, "end": 628.5600000000001, "text": " internet debates anymore. I got that out of my system. And I try not to get suckered into it,", "tokens": [51100, 4705, 24203, 3602, 13, 286, 658, 300, 484, 295, 452, 1185, 13, 400, 286, 853, 406, 281, 483, 9967, 4073, 666, 309, 11, 51324], "temperature": 0.0, "avg_logprob": -0.08392271314348493, "compression_ratio": 1.6016597510373445, "no_speech_prob": 0.01744118332862854}, {"id": 94, "seek": 60936, "start": 629.6800000000001, "end": 637.6800000000001, "text": " if I can. But, you know, one debate that I had many years ago was, you know, if aliens showed up,", "tokens": [51380, 498, 286, 393, 13, 583, 11, 291, 458, 11, 472, 7958, 300, 286, 632, 867, 924, 2057, 390, 11, 291, 458, 11, 498, 21594, 4712, 493, 11, 51780], "temperature": 0.0, "avg_logprob": -0.08392271314348493, "compression_ratio": 1.6016597510373445, "no_speech_prob": 0.01744118332862854}, {"id": 95, "seek": 63768, "start": 637.68, "end": 643.3599999999999, "text": " wouldn't it prove your religion wrong? This was a debate. I wasn't arguing as a debate that I", "tokens": [50364, 2759, 380, 309, 7081, 428, 7561, 2085, 30, 639, 390, 257, 7958, 13, 286, 2067, 380, 19697, 382, 257, 7958, 300, 286, 50648], "temperature": 0.0, "avg_logprob": -0.08997566559735466, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.0028006441425532103}, {"id": 96, "seek": 63768, "start": 643.3599999999999, "end": 650.2399999999999, "text": " observed. And the religious person said, no, why would it? And, you know, they rationalized it,", "tokens": [50648, 13095, 13, 400, 264, 7185, 954, 848, 11, 572, 11, 983, 576, 309, 30, 400, 11, 291, 458, 11, 436, 15090, 1602, 309, 11, 50992], "temperature": 0.0, "avg_logprob": -0.08997566559735466, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.0028006441425532103}, {"id": 97, "seek": 63768, "start": 650.2399999999999, "end": 656.64, "text": " saying, well, you know, why would God put, you know, aliens in the Bible if we wouldn't be able", "tokens": [50992, 1566, 11, 731, 11, 291, 458, 11, 983, 576, 1265, 829, 11, 291, 458, 11, 21594, 294, 264, 6544, 498, 321, 2759, 380, 312, 1075, 51312], "temperature": 0.0, "avg_logprob": -0.08997566559735466, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.0028006441425532103}, {"id": 98, "seek": 63768, "start": 656.64, "end": 663.5999999999999, "text": " to understand it back then? It's not for us to understand. And so some religious folks do have", "tokens": [51312, 281, 1223, 309, 646, 550, 30, 467, 311, 406, 337, 505, 281, 1223, 13, 400, 370, 512, 7185, 4024, 360, 362, 51660], "temperature": 0.0, "avg_logprob": -0.08997566559735466, "compression_ratio": 1.704035874439462, "no_speech_prob": 0.0028006441425532103}, {"id": 99, "seek": 66360, "start": 663.6, "end": 670.5600000000001, "text": " a really good ability to compartmentalize. And so, like, just because you have a, like,", "tokens": [50364, 257, 534, 665, 3485, 281, 26505, 304, 1125, 13, 400, 370, 11, 411, 11, 445, 570, 291, 362, 257, 11, 411, 11, 50712], "temperature": 0.0, "avg_logprob": -0.12017224566771252, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.01363459974527359}, {"id": 100, "seek": 66360, "start": 671.9200000000001, "end": 676.72, "text": " like a super intelligent machine, some people would be like, so it doesn't have a soul. And", "tokens": [50780, 411, 257, 1687, 13232, 3479, 11, 512, 561, 576, 312, 411, 11, 370, 309, 1177, 380, 362, 257, 5133, 13, 400, 51020], "temperature": 0.0, "avg_logprob": -0.12017224566771252, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.01363459974527359}, {"id": 101, "seek": 66360, "start": 676.72, "end": 682.16, "text": " that's the end of the discussion. So I don't, I don't particularly perceive, and I'm not saying", "tokens": [51020, 300, 311, 264, 917, 295, 264, 5017, 13, 407, 286, 500, 380, 11, 286, 500, 380, 4098, 20281, 11, 293, 286, 478, 406, 1566, 51292], "temperature": 0.0, "avg_logprob": -0.12017224566771252, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.01363459974527359}, {"id": 102, "seek": 66360, "start": 682.16, "end": 688.0, "text": " that this is good or bad, right? I am not in the Judeo-Christian faith. I have my spirituality", "tokens": [51292, 300, 341, 307, 665, 420, 1578, 11, 558, 30, 286, 669, 406, 294, 264, 36521, 78, 12, 46580, 4522, 13, 286, 362, 452, 30637, 51584], "temperature": 0.0, "avg_logprob": -0.12017224566771252, "compression_ratio": 1.5546218487394958, "no_speech_prob": 0.01363459974527359}, {"id": 103, "seek": 68800, "start": 688.08, "end": 694.16, "text": " as other, other places. I have some, like, some of my best friends in my local community and my", "tokens": [50368, 382, 661, 11, 661, 3190, 13, 286, 362, 512, 11, 411, 11, 512, 295, 452, 1151, 1855, 294, 452, 2654, 1768, 293, 452, 50672], "temperature": 0.0, "avg_logprob": -0.14101603346050912, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.47248244285583496}, {"id": 104, "seek": 68800, "start": 694.16, "end": 699.6, "text": " internet friends are deeply religious, you know, followers of Christ and whatever. And so, like,", "tokens": [50672, 4705, 1855, 366, 8760, 7185, 11, 291, 458, 11, 13071, 295, 2040, 293, 2035, 13, 400, 370, 11, 411, 11, 50944], "temperature": 0.0, "avg_logprob": -0.14101603346050912, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.47248244285583496}, {"id": 105, "seek": 68800, "start": 699.6, "end": 703.12, "text": " in many cases, I don't think it's going to be that big of an issue. Let me jump over to the", "tokens": [50944, 294, 867, 3331, 11, 286, 500, 380, 519, 309, 311, 516, 281, 312, 300, 955, 295, 364, 2734, 13, 961, 385, 3012, 670, 281, 264, 51120], "temperature": 0.0, "avg_logprob": -0.14101603346050912, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.47248244285583496}, {"id": 106, "seek": 68800, "start": 703.12, "end": 709.6, "text": " Patreon. Oh, wow, we've got some questions here. Okay. Backo bbzo. Sorry if I'm saying your name", "tokens": [51120, 15692, 13, 876, 11, 6076, 11, 321, 600, 658, 512, 1651, 510, 13, 1033, 13, 5833, 78, 272, 65, 4765, 13, 4919, 498, 286, 478, 1566, 428, 1315, 51444], "temperature": 0.0, "avg_logprob": -0.14101603346050912, "compression_ratio": 1.4941176470588236, "no_speech_prob": 0.47248244285583496}, {"id": 107, "seek": 70960, "start": 709.6, "end": 721.28, "text": " wrong. What would your advice be to someone just launching an AI startup? Don't. That's,", "tokens": [50364, 2085, 13, 708, 576, 428, 5192, 312, 281, 1580, 445, 18354, 364, 7318, 18578, 30, 1468, 380, 13, 663, 311, 11, 50948], "temperature": 0.0, "avg_logprob": -0.09601631943060428, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.5348590612411499}, {"id": 108, "seek": 70960, "start": 721.28, "end": 727.76, "text": " that's a very flippant response. But one launching a startup is really hard. It's mostly tedium.", "tokens": [50948, 300, 311, 257, 588, 932, 2488, 394, 4134, 13, 583, 472, 18354, 257, 18578, 307, 534, 1152, 13, 467, 311, 5240, 22337, 2197, 13, 51272], "temperature": 0.0, "avg_logprob": -0.09601631943060428, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.5348590612411499}, {"id": 109, "seek": 70960, "start": 728.64, "end": 732.72, "text": " You can have the best idea in the world. And 90% of the work is still going to be,", "tokens": [51316, 509, 393, 362, 264, 1151, 1558, 294, 264, 1002, 13, 400, 4289, 4, 295, 264, 589, 307, 920, 516, 281, 312, 11, 51520], "temperature": 0.0, "avg_logprob": -0.09601631943060428, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.5348590612411499}, {"id": 110, "seek": 70960, "start": 734.8000000000001, "end": 739.0400000000001, "text": " excuse me, I'm still struggling with allergies. That's my head a headache earlier. That's part", "tokens": [51624, 8960, 385, 11, 286, 478, 920, 9314, 365, 37007, 13, 663, 311, 452, 1378, 257, 23520, 3071, 13, 663, 311, 644, 51836], "temperature": 0.0, "avg_logprob": -0.09601631943060428, "compression_ratio": 1.5252100840336134, "no_speech_prob": 0.5348590612411499}, {"id": 111, "seek": 73904, "start": 739.04, "end": 744.64, "text": " of why I canceled yesterday. Thanks, Jordan. That's how am I holding up? Actually, I'm doing okay.", "tokens": [50364, 295, 983, 286, 24839, 5186, 13, 2561, 11, 10979, 13, 663, 311, 577, 669, 286, 5061, 493, 30, 5135, 11, 286, 478, 884, 1392, 13, 50644], "temperature": 0.0, "avg_logprob": -0.10306208610534667, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01406207773834467}, {"id": 112, "seek": 73904, "start": 744.64, "end": 750.24, "text": " Mostly it's just allergies right now. But anyways, so if you're doing an AI startup,", "tokens": [50644, 29035, 309, 311, 445, 37007, 558, 586, 13, 583, 13448, 11, 370, 498, 291, 434, 884, 364, 7318, 18578, 11, 50924], "temperature": 0.0, "avg_logprob": -0.10306208610534667, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01406207773834467}, {"id": 113, "seek": 73904, "start": 750.24, "end": 756.88, "text": " one, if you haven't done a startup before, now is a really bad time to learn. Because things", "tokens": [50924, 472, 11, 498, 291, 2378, 380, 1096, 257, 18578, 949, 11, 586, 307, 257, 534, 1578, 565, 281, 1466, 13, 1436, 721, 51256], "temperature": 0.0, "avg_logprob": -0.10306208610534667, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01406207773834467}, {"id": 114, "seek": 73904, "start": 756.88, "end": 765.52, "text": " are going so fast. And we're basically having to reinvent stuff as we go. Which if that's, you", "tokens": [51256, 366, 516, 370, 2370, 13, 400, 321, 434, 1936, 1419, 281, 33477, 1507, 382, 321, 352, 13, 3013, 498, 300, 311, 11, 291, 51688], "temperature": 0.0, "avg_logprob": -0.10306208610534667, "compression_ratio": 1.5204918032786885, "no_speech_prob": 0.01406207773834467}, {"id": 115, "seek": 76552, "start": 766.16, "end": 770.88, "text": " that's part of why I burned out is I realized like, okay, I did find it really engaging and", "tokens": [50396, 300, 311, 644, 295, 983, 286, 13490, 484, 307, 286, 5334, 411, 11, 1392, 11, 286, 630, 915, 309, 534, 11268, 293, 50632], "temperature": 0.0, "avg_logprob": -0.08947791475238222, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.005554409697651863}, {"id": 116, "seek": 76552, "start": 770.88, "end": 778.64, "text": " really enjoyable. But my pace of things clashed with other people. And then like the rabbit hole", "tokens": [50632, 534, 20305, 13, 583, 452, 11638, 295, 721, 596, 12219, 365, 661, 561, 13, 400, 550, 411, 264, 19509, 5458, 51020], "temperature": 0.0, "avg_logprob": -0.08947791475238222, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.005554409697651863}, {"id": 117, "seek": 76552, "start": 778.64, "end": 787.12, "text": " just keeps getting deeper. So that's, that's kind of the thing. What I always tell people is your,", "tokens": [51020, 445, 5965, 1242, 7731, 13, 407, 300, 311, 11, 300, 311, 733, 295, 264, 551, 13, 708, 286, 1009, 980, 561, 307, 428, 11, 51444], "temperature": 0.0, "avg_logprob": -0.08947791475238222, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.005554409697651863}, {"id": 118, "seek": 76552, "start": 787.12, "end": 792.88, "text": " your, your startup team, your founder team is most important. Be picky. If you don't have the right", "tokens": [51444, 428, 11, 428, 18578, 1469, 11, 428, 14917, 1469, 307, 881, 1021, 13, 879, 41099, 13, 759, 291, 500, 380, 362, 264, 558, 51732], "temperature": 0.0, "avg_logprob": -0.08947791475238222, "compression_ratio": 1.6058091286307055, "no_speech_prob": 0.005554409697651863}, {"id": 119, "seek": 79288, "start": 792.88, "end": 800.56, "text": " team, walk away early. And then also for the folks that I'm talking to is local. Because of the pace", "tokens": [50364, 1469, 11, 1792, 1314, 2440, 13, 400, 550, 611, 337, 264, 4024, 300, 286, 478, 1417, 281, 307, 2654, 13, 1436, 295, 264, 11638, 50748], "temperature": 0.0, "avg_logprob": -0.06378798186779022, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.016401460394263268}, {"id": 120, "seek": 79288, "start": 800.56, "end": 806.88, "text": " of things, you absolutely need to like see the people that you work with, in person, at least", "tokens": [50748, 295, 721, 11, 291, 3122, 643, 281, 411, 536, 264, 561, 300, 291, 589, 365, 11, 294, 954, 11, 412, 1935, 51064], "temperature": 0.0, "avg_logprob": -0.06378798186779022, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.016401460394263268}, {"id": 121, "seek": 79288, "start": 806.88, "end": 812.56, "text": " on a weekly basis, if not on a daily basis, because you need to be like sitting in the same room,", "tokens": [51064, 322, 257, 12460, 5143, 11, 498, 406, 322, 257, 5212, 5143, 11, 570, 291, 643, 281, 312, 411, 3798, 294, 264, 912, 1808, 11, 51348], "temperature": 0.0, "avg_logprob": -0.06378798186779022, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.016401460394263268}, {"id": 122, "seek": 79288, "start": 812.56, "end": 819.6, "text": " just shooting the breeze, keeping each other updated in real time. Doing it remotely is", "tokens": [51348, 445, 5942, 264, 24532, 11, 5145, 1184, 661, 10588, 294, 957, 565, 13, 18496, 309, 20824, 307, 51700], "temperature": 0.0, "avg_logprob": -0.06378798186779022, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.016401460394263268}, {"id": 123, "seek": 81960, "start": 819.6, "end": 824.96, "text": " probably not feasible. Unless unless you're already a really established team, and you're", "tokens": [50364, 1391, 406, 26648, 13, 16581, 5969, 291, 434, 1217, 257, 534, 7545, 1469, 11, 293, 291, 434, 50632], "temperature": 0.0, "avg_logprob": -0.09101348453097874, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.00912535935640335}, {"id": 124, "seek": 81960, "start": 824.96, "end": 830.48, "text": " just going to sit in like discord all day or Slack all day. Blake Allen curious to hear your", "tokens": [50632, 445, 516, 281, 1394, 294, 411, 32989, 439, 786, 420, 37211, 439, 786, 13, 23451, 17160, 6369, 281, 1568, 428, 50908], "temperature": 0.0, "avg_logprob": -0.09101348453097874, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.00912535935640335}, {"id": 125, "seek": 81960, "start": 830.48, "end": 834.24, "text": " thoughts on Stanford's hyena hierarchy and how it relates to some of the work you've done with", "tokens": [50908, 4598, 322, 20374, 311, 2477, 4118, 22333, 293, 577, 309, 16155, 281, 512, 295, 264, 589, 291, 600, 1096, 365, 51096], "temperature": 0.0, "avg_logprob": -0.09101348453097874, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.00912535935640335}, {"id": 126, "seek": 81960, "start": 834.24, "end": 838.88, "text": " Raven and cognitive architecture. I don't know if I've heard of this one. Let's check it out real", "tokens": [51096, 28956, 293, 15605, 9482, 13, 286, 500, 380, 458, 498, 286, 600, 2198, 295, 341, 472, 13, 961, 311, 1520, 309, 484, 957, 51328], "temperature": 0.0, "avg_logprob": -0.09101348453097874, "compression_ratio": 1.5560165975103735, "no_speech_prob": 0.00912535935640335}, {"id": 127, "seek": 83888, "start": 838.88, "end": 852.32, "text": " quick. Hyena hierarchy. Let's see. Let's go up to the very top. Hyena hierarchy towards larger", "tokens": [50364, 1702, 13, 5701, 4118, 22333, 13, 961, 311, 536, 13, 961, 311, 352, 493, 281, 264, 588, 1192, 13, 5701, 4118, 22333, 3030, 4833, 51036], "temperature": 0.0, "avg_logprob": -0.11580558384166044, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.2688728868961334}, {"id": 128, "seek": 83888, "start": 852.32, "end": 858.8, "text": " convolutional language models. We're excited to share our latest work on hyena, a sub quadratic", "tokens": [51036, 45216, 304, 2856, 5245, 13, 492, 434, 2919, 281, 2073, 527, 6792, 589, 322, 2477, 4118, 11, 257, 1422, 37262, 51360], "temperature": 0.0, "avg_logprob": -0.11580558384166044, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.2688728868961334}, {"id": 129, "seek": 83888, "start": 858.8, "end": 864.08, "text": " time layer that has the potentials to significantly increase context length and sequence models.", "tokens": [51360, 565, 4583, 300, 575, 264, 3995, 82, 281, 10591, 3488, 4319, 4641, 293, 8310, 5245, 13, 51624], "temperature": 0.0, "avg_logprob": -0.11580558384166044, "compression_ratio": 1.5105263157894737, "no_speech_prob": 0.2688728868961334}, {"id": 130, "seek": 86408, "start": 864.4000000000001, "end": 874.64, "text": " Oh, right. I think this is the RNN integration. Yeah, yeah. In general, how can we close this", "tokens": [50380, 876, 11, 558, 13, 286, 519, 341, 307, 264, 45702, 45, 10980, 13, 865, 11, 1338, 13, 682, 2674, 11, 577, 393, 321, 1998, 341, 50892], "temperature": 0.0, "avg_logprob": -0.17767002213169153, "compression_ratio": 1.478021978021978, "no_speech_prob": 0.008846648968756199}, {"id": 131, "seek": 86408, "start": 874.64, "end": 880.48, "text": " gap? Yeah. In general, any individual language model is just like one cortical node.", "tokens": [50892, 7417, 30, 865, 13, 682, 2674, 11, 604, 2609, 2856, 2316, 307, 445, 411, 472, 11278, 804, 9984, 13, 51184], "temperature": 0.0, "avg_logprob": -0.17767002213169153, "compression_ratio": 1.478021978021978, "no_speech_prob": 0.008846648968756199}, {"id": 132, "seek": 86408, "start": 883.6, "end": 888.96, "text": " Yes, these things will be like better, more efficient cylinders in an engine, but in order", "tokens": [51340, 1079, 11, 613, 721, 486, 312, 411, 1101, 11, 544, 7148, 42166, 294, 364, 2848, 11, 457, 294, 1668, 51608], "temperature": 0.0, "avg_logprob": -0.17767002213169153, "compression_ratio": 1.478021978021978, "no_speech_prob": 0.008846648968756199}, {"id": 133, "seek": 88896, "start": 888.96, "end": 897.12, "text": " to have a race car, you need the rest of the car. Again, I'm kind of really flying off the cuff", "tokens": [50364, 281, 362, 257, 4569, 1032, 11, 291, 643, 264, 1472, 295, 264, 1032, 13, 3764, 11, 286, 478, 733, 295, 534, 7137, 766, 264, 35997, 50772], "temperature": 0.0, "avg_logprob": -0.12083627559520581, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.06370522081851959}, {"id": 134, "seek": 88896, "start": 897.12, "end": 906.24, "text": " right here. I'm not sure that I've got this right, but I think, yeah, RWKV. You're not going to ever", "tokens": [50772, 558, 510, 13, 286, 478, 406, 988, 300, 286, 600, 658, 341, 558, 11, 457, 286, 519, 11, 1338, 11, 42513, 42, 53, 13, 509, 434, 406, 516, 281, 1562, 51228], "temperature": 0.0, "avg_logprob": -0.12083627559520581, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.06370522081851959}, {"id": 135, "seek": 88896, "start": 906.24, "end": 911.44, "text": " get a full cognitive architecture from a single language model. Now, that being said, the big", "tokens": [51228, 483, 257, 1577, 15605, 9482, 490, 257, 2167, 2856, 2316, 13, 823, 11, 300, 885, 848, 11, 264, 955, 51488], "temperature": 0.0, "avg_logprob": -0.12083627559520581, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.06370522081851959}, {"id": 136, "seek": 88896, "start": 911.44, "end": 917.2800000000001, "text": " asterisk is when you look at all the studies about GPT-4 that have theory of mind and what I", "tokens": [51488, 257, 3120, 7797, 307, 562, 291, 574, 412, 439, 264, 5313, 466, 26039, 51, 12, 19, 300, 362, 5261, 295, 1575, 293, 437, 286, 51780], "temperature": 0.0, "avg_logprob": -0.12083627559520581, "compression_ratio": 1.5258964143426295, "no_speech_prob": 0.06370522081851959}, {"id": 137, "seek": 91728, "start": 917.28, "end": 923.04, "text": " call implied cognition. So implied cognition is that the thing is obviously thinking through", "tokens": [50364, 818, 32614, 46905, 13, 407, 32614, 46905, 307, 300, 264, 551, 307, 2745, 1953, 807, 50652], "temperature": 0.0, "avg_logprob": -0.13305545407672262, "compression_ratio": 1.6375545851528384, "no_speech_prob": 0.015422545373439789}, {"id": 138, "seek": 91728, "start": 923.04, "end": 927.92, "text": " problems behind the scenes in a similar way that humans think through it. I don't mean like", "tokens": [50652, 2740, 2261, 264, 8026, 294, 257, 2531, 636, 300, 6255, 519, 807, 309, 13, 286, 500, 380, 914, 411, 50896], "temperature": 0.0, "avg_logprob": -0.13305545407672262, "compression_ratio": 1.6375545851528384, "no_speech_prob": 0.015422545373439789}, {"id": 139, "seek": 91728, "start": 927.92, "end": 935.28, "text": " neurologically, subjectively, it thinks the way that we do, but GPT-4 can obviously talk itself", "tokens": [50896, 28351, 984, 11, 3983, 3413, 11, 309, 7309, 264, 636, 300, 321, 360, 11, 457, 26039, 51, 12, 19, 393, 2745, 751, 2564, 51264], "temperature": 0.0, "avg_logprob": -0.13305545407672262, "compression_ratio": 1.6375545851528384, "no_speech_prob": 0.015422545373439789}, {"id": 140, "seek": 91728, "start": 935.28, "end": 943.52, "text": " through, kind of do chain of thought reasoning internally in one shot. And so that makes those", "tokens": [51264, 807, 11, 733, 295, 360, 5021, 295, 1194, 21577, 19501, 294, 472, 3347, 13, 400, 370, 300, 1669, 729, 51676], "temperature": 0.0, "avg_logprob": -0.13305545407672262, "compression_ratio": 1.6375545851528384, "no_speech_prob": 0.015422545373439789}, {"id": 141, "seek": 94352, "start": 943.52, "end": 948.3199999999999, "text": " larger, more sophisticated models make your cognitive architecture simpler, but it doesn't", "tokens": [50364, 4833, 11, 544, 16950, 5245, 652, 428, 15605, 9482, 18587, 11, 457, 309, 1177, 380, 50604], "temperature": 0.0, "avg_logprob": -0.09166973829269409, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.03409679979085922}, {"id": 142, "seek": 94352, "start": 948.3199999999999, "end": 954.64, "text": " get rid of the need for external storage. It doesn't get rid of the need for parallel processing.", "tokens": [50604, 483, 3973, 295, 264, 643, 337, 8320, 6725, 13, 467, 1177, 380, 483, 3973, 295, 264, 643, 337, 8952, 9007, 13, 50920], "temperature": 0.0, "avg_logprob": -0.09166973829269409, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.03409679979085922}, {"id": 143, "seek": 94352, "start": 954.64, "end": 959.28, "text": " It doesn't get rid of the need for loops and checks and that sort of stuff. So that's kind", "tokens": [50920, 467, 1177, 380, 483, 3973, 295, 264, 643, 337, 16121, 293, 13834, 293, 300, 1333, 295, 1507, 13, 407, 300, 311, 733, 51152], "temperature": 0.0, "avg_logprob": -0.09166973829269409, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.03409679979085922}, {"id": 144, "seek": 94352, "start": 959.28, "end": 965.92, "text": " of my response there. Good question. Emma or AMA, I'm new here and new to this field in general,", "tokens": [51152, 295, 452, 4134, 456, 13, 2205, 1168, 13, 17124, 420, 6475, 32, 11, 286, 478, 777, 510, 293, 777, 281, 341, 2519, 294, 2674, 11, 51484], "temperature": 0.0, "avg_logprob": -0.09166973829269409, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.03409679979085922}, {"id": 145, "seek": 94352, "start": 965.92, "end": 971.12, "text": " found you through Raven videos. Thank you. Regarding personal assistance, is there a reason", "tokens": [51484, 1352, 291, 807, 28956, 2145, 13, 1044, 291, 13, 35523, 2973, 9683, 11, 307, 456, 257, 1778, 51744], "temperature": 0.0, "avg_logprob": -0.09166973829269409, "compression_ratio": 1.7397769516728625, "no_speech_prob": 0.03409679979085922}, {"id": 146, "seek": 97112, "start": 971.12, "end": 977.28, "text": " to create a database of yourself for your future personal assistant to understand you better?", "tokens": [50364, 281, 1884, 257, 8149, 295, 1803, 337, 428, 2027, 2973, 10994, 281, 1223, 291, 1101, 30, 50672], "temperature": 0.0, "avg_logprob": -0.09874749952746976, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.042072925716638565}, {"id": 147, "seek": 97112, "start": 978.24, "end": 984.88, "text": " So that's actually the purpose of my RIMO framework. So RIMO is meant to be a hierarchical", "tokens": [50720, 407, 300, 311, 767, 264, 4334, 295, 452, 497, 6324, 46, 8388, 13, 407, 497, 6324, 46, 307, 4140, 281, 312, 257, 35250, 804, 51052], "temperature": 0.0, "avg_logprob": -0.09874749952746976, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.042072925716638565}, {"id": 148, "seek": 97112, "start": 984.88, "end": 992.0, "text": " database of your interactions with an individual agent that will surface particular topics by", "tokens": [51052, 8149, 295, 428, 13280, 365, 364, 2609, 9461, 300, 486, 3753, 1729, 8378, 538, 51408], "temperature": 0.0, "avg_logprob": -0.09874749952746976, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.042072925716638565}, {"id": 149, "seek": 99200, "start": 992.0, "end": 1001.92, "text": " using, not reciprocal, recursive summarization and clustering. So you take all your raw logs,", "tokens": [50364, 1228, 11, 406, 46948, 11, 20560, 488, 14611, 2144, 293, 596, 48673, 13, 407, 291, 747, 439, 428, 8936, 20820, 11, 50860], "temperature": 0.0, "avg_logprob": -0.08391874486749823, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.21729107201099396}, {"id": 150, "seek": 99200, "start": 1001.92, "end": 1008.24, "text": " cluster them, summarize them, do that again, cluster, summarize, cluster, summarize until", "tokens": [50860, 13630, 552, 11, 20858, 552, 11, 360, 300, 797, 11, 13630, 11, 20858, 11, 13630, 11, 20858, 1826, 51176], "temperature": 0.0, "avg_logprob": -0.08391874486749823, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.21729107201099396}, {"id": 151, "seek": 99200, "start": 1008.24, "end": 1014.72, "text": " you end up with five to 10 parent topics that allow you to drill down. So I wouldn't, don't waste", "tokens": [51176, 291, 917, 493, 365, 1732, 281, 1266, 2596, 8378, 300, 2089, 291, 281, 11392, 760, 13, 407, 286, 2759, 380, 11, 500, 380, 5964, 51500], "temperature": 0.0, "avg_logprob": -0.08391874486749823, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.21729107201099396}, {"id": 152, "seek": 99200, "start": 1014.72, "end": 1020.0, "text": " any time doing that manually, just let it happen naturally through conversation by integrating", "tokens": [51500, 604, 565, 884, 300, 16945, 11, 445, 718, 309, 1051, 8195, 807, 3761, 538, 26889, 51764], "temperature": 0.0, "avg_logprob": -0.08391874486749823, "compression_ratio": 1.6860986547085202, "no_speech_prob": 0.21729107201099396}, {"id": 153, "seek": 102000, "start": 1020.0, "end": 1026.24, "text": " something like Lama Index Tree or RIMO. Do you think we are on track to cure brain diseases", "tokens": [50364, 746, 411, 441, 2404, 33552, 22291, 420, 497, 6324, 46, 13, 1144, 291, 519, 321, 366, 322, 2837, 281, 13698, 3567, 11044, 50676], "temperature": 0.0, "avg_logprob": -0.10952349331067956, "compression_ratio": 1.484251968503937, "no_speech_prob": 0.003483239095658064}, {"id": 154, "seek": 102000, "start": 1026.24, "end": 1034.64, "text": " like Alzheimer's by 2030? The combination of AlphaFold and mRNA vaccines, I think absolutely.", "tokens": [50676, 411, 27932, 311, 538, 28638, 30, 440, 6562, 295, 20588, 37, 2641, 293, 50103, 12164, 11, 286, 519, 3122, 13, 51096], "temperature": 0.0, "avg_logprob": -0.10952349331067956, "compression_ratio": 1.484251968503937, "no_speech_prob": 0.003483239095658064}, {"id": 155, "seek": 102000, "start": 1035.28, "end": 1039.52, "text": " There was something else that I posted on my YouTube recently that it's like another breakthrough", "tokens": [51128, 821, 390, 746, 1646, 300, 286, 9437, 322, 452, 3088, 3938, 300, 309, 311, 411, 1071, 22397, 51340], "temperature": 0.0, "avg_logprob": -0.10952349331067956, "compression_ratio": 1.484251968503937, "no_speech_prob": 0.003483239095658064}, {"id": 156, "seek": 102000, "start": 1039.52, "end": 1048.96, "text": " is happening. So I think we're very close to the point where we can halt Alzheimer's. Undoing", "tokens": [51340, 307, 2737, 13, 407, 286, 519, 321, 434, 588, 1998, 281, 264, 935, 689, 321, 393, 12479, 27932, 311, 13, 2719, 78, 278, 51812], "temperature": 0.0, "avg_logprob": -0.10952349331067956, "compression_ratio": 1.484251968503937, "no_speech_prob": 0.003483239095658064}, {"id": 157, "seek": 104896, "start": 1049.04, "end": 1054.56, "text": " Alzheimer's might take another little bit of time, but on the other hand, we're at the point", "tokens": [50368, 27932, 311, 1062, 747, 1071, 707, 857, 295, 565, 11, 457, 322, 264, 661, 1011, 11, 321, 434, 412, 264, 935, 50644], "temperature": 0.0, "avg_logprob": -0.08587762405132425, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0032729136291891336}, {"id": 158, "seek": 104896, "start": 1054.56, "end": 1059.3600000000001, "text": " where we're getting saltatory leaps, we're getting breakthroughs really fast, so you never know.", "tokens": [50644, 689, 321, 434, 1242, 5139, 4745, 476, 2382, 11, 321, 434, 1242, 22397, 82, 534, 2370, 11, 370, 291, 1128, 458, 13, 50884], "temperature": 0.0, "avg_logprob": -0.08587762405132425, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0032729136291891336}, {"id": 159, "seek": 104896, "start": 1060.32, "end": 1066.16, "text": " Let's see, what are your thoughts on the generative agent stuff that has come out recently? It seems", "tokens": [50932, 961, 311, 536, 11, 437, 366, 428, 4598, 322, 264, 1337, 1166, 9461, 1507, 300, 575, 808, 484, 3938, 30, 467, 2544, 51224], "temperature": 0.0, "avg_logprob": -0.08587762405132425, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0032729136291891336}, {"id": 160, "seek": 104896, "start": 1066.16, "end": 1072.32, "text": " like you were pretty ahead of the curve on that stuff and has it solidified or changed the way", "tokens": [51224, 411, 291, 645, 1238, 2286, 295, 264, 7605, 322, 300, 1507, 293, 575, 309, 5100, 2587, 420, 3105, 264, 636, 51532], "temperature": 0.0, "avg_logprob": -0.08587762405132425, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0032729136291891336}, {"id": 161, "seek": 104896, "start": 1072.32, "end": 1078.64, "text": " you think about the concepts from Symphony of Thought? Yeah, so I definitely felt like I was", "tokens": [51532, 291, 519, 466, 264, 10392, 490, 46891, 295, 23058, 30, 865, 11, 370, 286, 2138, 2762, 411, 286, 390, 51848], "temperature": 0.0, "avg_logprob": -0.08587762405132425, "compression_ratio": 1.6482758620689655, "no_speech_prob": 0.0032729136291891336}, {"id": 162, "seek": 107864, "start": 1078.64, "end": 1084.64, "text": " ahead of the curve. And what I've been telling people is I worked for a few years to try and get", "tokens": [50364, 2286, 295, 264, 7605, 13, 400, 437, 286, 600, 668, 3585, 561, 307, 286, 2732, 337, 257, 1326, 924, 281, 853, 293, 483, 50664], "temperature": 0.0, "avg_logprob": -0.09268652963981354, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.0236851517111063}, {"id": 163, "seek": 107864, "start": 1085.44, "end": 1091.76, "text": " GPT-3 to do the stuff that 3.5 and 4 can do easily. So I'm just like, all right, whatever. I'm so", "tokens": [50704, 26039, 51, 12, 18, 281, 360, 264, 1507, 300, 805, 13, 20, 293, 1017, 393, 360, 3612, 13, 407, 286, 478, 445, 411, 11, 439, 558, 11, 2035, 13, 286, 478, 370, 51020], "temperature": 0.0, "avg_logprob": -0.09268652963981354, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.0236851517111063}, {"id": 164, "seek": 107864, "start": 1091.76, "end": 1095.68, "text": " glad that the rest of the world is just like, oh cool, autonomous agents. And I'm like, great,", "tokens": [51020, 5404, 300, 264, 1472, 295, 264, 1002, 307, 445, 411, 11, 1954, 1627, 11, 23797, 12554, 13, 400, 286, 478, 411, 11, 869, 11, 51216], "temperature": 0.0, "avg_logprob": -0.09268652963981354, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.0236851517111063}, {"id": 165, "seek": 107864, "start": 1095.68, "end": 1101.44, "text": " now I don't have to write any more books about it. So I'm just happy to sit back and watch it go", "tokens": [51216, 586, 286, 500, 380, 362, 281, 2464, 604, 544, 3642, 466, 309, 13, 407, 286, 478, 445, 2055, 281, 1394, 646, 293, 1159, 309, 352, 51504], "temperature": 0.0, "avg_logprob": -0.09268652963981354, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.0236851517111063}, {"id": 166, "seek": 107864, "start": 1101.44, "end": 1107.6000000000001, "text": " and keep plugging my heuristic imperatives. Good question, Jordan. Also, here, let's check over", "tokens": [51504, 293, 1066, 42975, 452, 415, 374, 3142, 10100, 4884, 13, 2205, 1168, 11, 10979, 13, 2743, 11, 510, 11, 718, 311, 1520, 670, 51812], "temperature": 0.0, "avg_logprob": -0.09268652963981354, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.0236851517111063}, {"id": 167, "seek": 110760, "start": 1107.6, "end": 1113.6799999999998, "text": " here. Okay, we got some questions. Let's see, is her about to come reality? Yep, we got that one.", "tokens": [50364, 510, 13, 1033, 11, 321, 658, 512, 1651, 13, 961, 311, 536, 11, 307, 720, 466, 281, 808, 4103, 30, 7010, 11, 321, 658, 300, 472, 13, 50668], "temperature": 0.0, "avg_logprob": -0.10247757911682129, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.005910707637667656}, {"id": 168, "seek": 110760, "start": 1114.7199999999998, "end": 1119.4399999999998, "text": " Interesting video. How long do you think it will be before we start seeing hive mind AI systems", "tokens": [50720, 14711, 960, 13, 1012, 938, 360, 291, 519, 309, 486, 312, 949, 321, 722, 2577, 42523, 1575, 7318, 3652, 50956], "temperature": 0.0, "avg_logprob": -0.10247757911682129, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.005910707637667656}, {"id": 169, "seek": 110760, "start": 1119.4399999999998, "end": 1130.3999999999999, "text": " in healthcare or the IRS? I know people working on that today. And so they'll work together", "tokens": [50956, 294, 8884, 420, 264, 33848, 30, 286, 458, 561, 1364, 322, 300, 965, 13, 400, 370, 436, 603, 589, 1214, 51504], "temperature": 0.0, "avg_logprob": -0.10247757911682129, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.005910707637667656}, {"id": 170, "seek": 110760, "start": 1130.3999999999999, "end": 1135.76, "text": " for a few different reasons. One, you'll have a division of labor. Oh, so taking a step back.", "tokens": [51504, 337, 257, 1326, 819, 4112, 13, 1485, 11, 291, 603, 362, 257, 10044, 295, 5938, 13, 876, 11, 370, 1940, 257, 1823, 646, 13, 51772], "temperature": 0.0, "avg_logprob": -0.10247757911682129, "compression_ratio": 1.503968253968254, "no_speech_prob": 0.005910707637667656}, {"id": 171, "seek": 113576, "start": 1136.48, "end": 1141.6, "text": " What we mean when we say like hive mind AI is where you have like multiple cognitive agents", "tokens": [50400, 708, 321, 914, 562, 321, 584, 411, 42523, 1575, 7318, 307, 689, 291, 362, 411, 3866, 15605, 12554, 50656], "temperature": 0.0, "avg_logprob": -0.11659582773844401, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.006289634853601456}, {"id": 172, "seek": 113576, "start": 1141.6, "end": 1150.4, "text": " or autonomous agents, or is it is it not working? Is it working? I hope it's working. It looks like", "tokens": [50656, 420, 23797, 12554, 11, 420, 307, 309, 307, 309, 406, 1364, 30, 1119, 309, 1364, 30, 286, 1454, 309, 311, 1364, 13, 467, 1542, 411, 51096], "temperature": 0.0, "avg_logprob": -0.11659582773844401, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.006289634853601456}, {"id": 173, "seek": 113576, "start": 1150.4, "end": 1159.52, "text": " it's working. Okay. So yeah, so basically, it'll be easy to spin up a lot of agents.", "tokens": [51096, 309, 311, 1364, 13, 1033, 13, 407, 1338, 11, 370, 1936, 11, 309, 603, 312, 1858, 281, 6060, 493, 257, 688, 295, 12554, 13, 51552], "temperature": 0.0, "avg_logprob": -0.11659582773844401, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.006289634853601456}, {"id": 174, "seek": 115952, "start": 1160.24, "end": 1168.56, "text": " What I was describing to one Patreon customer, or no, sorry, I was describing this to a", "tokens": [50400, 708, 286, 390, 16141, 281, 472, 15692, 5474, 11, 420, 572, 11, 2597, 11, 286, 390, 16141, 341, 281, 257, 50816], "temperature": 0.0, "avg_logprob": -0.11520448644110497, "compression_ratio": 1.6875, "no_speech_prob": 0.03846137225627899}, {"id": 175, "seek": 115952, "start": 1169.6, "end": 1175.2, "text": " podcast host that I'm going to be featured on coming up, was kind of what I predict right now", "tokens": [50868, 7367, 3975, 300, 286, 478, 516, 281, 312, 13822, 322, 1348, 493, 11, 390, 733, 295, 437, 286, 6069, 558, 586, 51148], "temperature": 0.0, "avg_logprob": -0.11520448644110497, "compression_ratio": 1.6875, "no_speech_prob": 0.03846137225627899}, {"id": 176, "seek": 115952, "start": 1175.92, "end": 1181.44, "text": " is before too long, you're going to have multiple cognitive agents running on your phone, on your", "tokens": [51184, 307, 949, 886, 938, 11, 291, 434, 516, 281, 362, 3866, 15605, 12554, 2614, 322, 428, 2593, 11, 322, 428, 51460], "temperature": 0.0, "avg_logprob": -0.11520448644110497, "compression_ratio": 1.6875, "no_speech_prob": 0.03846137225627899}, {"id": 177, "seek": 115952, "start": 1181.44, "end": 1188.0, "text": " car, on your home PC and your smart home devices. And so you're basically going to have a fleet of", "tokens": [51460, 1032, 11, 322, 428, 1280, 6465, 293, 428, 4069, 1280, 5759, 13, 400, 370, 291, 434, 1936, 516, 281, 362, 257, 19396, 295, 51788], "temperature": 0.0, "avg_logprob": -0.11520448644110497, "compression_ratio": 1.6875, "no_speech_prob": 0.03846137225627899}, {"id": 178, "seek": 118800, "start": 1188.08, "end": 1196.96, "text": " small cognitive agents working for you at all times. Then you're going to have the same thing at", "tokens": [50368, 1359, 15605, 12554, 1364, 337, 291, 412, 439, 1413, 13, 1396, 291, 434, 516, 281, 362, 264, 912, 551, 412, 50812], "temperature": 0.0, "avg_logprob": -0.07155119370077258, "compression_ratio": 2.0128755364806867, "no_speech_prob": 0.011330357752740383}, {"id": 179, "seek": 118800, "start": 1196.96, "end": 1201.28, "text": " like your company, right? Every employee or every department is going to have multiple", "tokens": [50812, 411, 428, 2237, 11, 558, 30, 2048, 10738, 420, 633, 5882, 307, 516, 281, 362, 3866, 51028], "temperature": 0.0, "avg_logprob": -0.07155119370077258, "compression_ratio": 2.0128755364806867, "no_speech_prob": 0.011330357752740383}, {"id": 180, "seek": 118800, "start": 1201.28, "end": 1207.2, "text": " cognitive agents all collaborating at all times. And you're going to have this kind of tiered hierarchy", "tokens": [51028, 15605, 12554, 439, 30188, 412, 439, 1413, 13, 400, 291, 434, 516, 281, 362, 341, 733, 295, 12362, 292, 22333, 51324], "temperature": 0.0, "avg_logprob": -0.07155119370077258, "compression_ratio": 2.0128755364806867, "no_speech_prob": 0.011330357752740383}, {"id": 181, "seek": 118800, "start": 1207.2, "end": 1211.6, "text": " where it's like there's the personal, there's the family unit, there's the corporate unit,", "tokens": [51324, 689, 309, 311, 411, 456, 311, 264, 2973, 11, 456, 311, 264, 1605, 4985, 11, 456, 311, 264, 10896, 4985, 11, 51544], "temperature": 0.0, "avg_logprob": -0.07155119370077258, "compression_ratio": 2.0128755364806867, "no_speech_prob": 0.011330357752740383}, {"id": 182, "seek": 118800, "start": 1211.6, "end": 1216.4, "text": " there's the town, there's the federal government, the state government, global government,", "tokens": [51544, 456, 311, 264, 3954, 11, 456, 311, 264, 6019, 2463, 11, 264, 1785, 2463, 11, 4338, 2463, 11, 51784], "temperature": 0.0, "avg_logprob": -0.07155119370077258, "compression_ratio": 2.0128755364806867, "no_speech_prob": 0.011330357752740383}, {"id": 183, "seek": 121640, "start": 1216.48, "end": 1220.0800000000002, "text": " government. And I think that the way that they're all going to work together, because", "tokens": [50368, 2463, 13, 400, 286, 519, 300, 264, 636, 300, 436, 434, 439, 516, 281, 589, 1214, 11, 570, 50548], "temperature": 0.0, "avg_logprob": -0.10513663741777528, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0017544805305078626}, {"id": 184, "seek": 121640, "start": 1220.0800000000002, "end": 1224.72, "text": " security is so critical here, is that it's going to be using blockchain technology and", "tokens": [50548, 3825, 307, 370, 4924, 510, 11, 307, 300, 309, 311, 516, 281, 312, 1228, 17176, 2899, 293, 50780], "temperature": 0.0, "avg_logprob": -0.10513663741777528, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0017544805305078626}, {"id": 185, "seek": 121640, "start": 1224.72, "end": 1230.8000000000002, "text": " distributed autonomous organizations. So that's the long story short, is that's what's going to happen.", "tokens": [50780, 12631, 23797, 6150, 13, 407, 300, 311, 264, 938, 1657, 2099, 11, 307, 300, 311, 437, 311, 516, 281, 1051, 13, 51084], "temperature": 0.0, "avg_logprob": -0.10513663741777528, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0017544805305078626}, {"id": 186, "seek": 121640, "start": 1232.4, "end": 1236.24, "text": " Let's see, you may have already covered this, but in case you haven't any thoughts on Met", "tokens": [51164, 961, 311, 536, 11, 291, 815, 362, 1217, 5343, 341, 11, 457, 294, 1389, 291, 2378, 380, 604, 4598, 322, 6377, 51356], "temperature": 0.0, "avg_logprob": -0.10513663741777528, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0017544805305078626}, {"id": 187, "seek": 121640, "start": 1236.24, "end": 1243.1200000000001, "text": " Singer's artificial suffering, an argument for a global moratorium on synthetic phenomenology.", "tokens": [51356, 44184, 311, 11677, 7755, 11, 364, 6770, 337, 257, 4338, 1896, 41679, 322, 23420, 9388, 1793, 13, 51700], "temperature": 0.0, "avg_logprob": -0.10513663741777528, "compression_ratio": 1.6232394366197183, "no_speech_prob": 0.0017544805305078626}, {"id": 188, "seek": 124312, "start": 1243.6, "end": 1251.36, "text": " Um, I am tangentially familiar with this, but I have my own opinions on whether or not a machine", "tokens": [50388, 3301, 11, 286, 669, 10266, 3137, 4963, 365, 341, 11, 457, 286, 362, 452, 1065, 11819, 322, 1968, 420, 406, 257, 3479, 50776], "temperature": 0.0, "avg_logprob": -0.13935628804293546, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.00475497730076313}, {"id": 189, "seek": 124312, "start": 1251.36, "end": 1259.52, "text": " can suffer. So there's two distinct possibilities. The first possibility is because artificial", "tokens": [50776, 393, 9753, 13, 407, 456, 311, 732, 10644, 12178, 13, 440, 700, 7959, 307, 570, 11677, 51184], "temperature": 0.0, "avg_logprob": -0.13935628804293546, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.00475497730076313}, {"id": 190, "seek": 124312, "start": 1259.52, "end": 1265.12, "text": " intelligence is a fundamentally different substrate from humans, it will never be able to", "tokens": [51184, 7599, 307, 257, 17879, 819, 27585, 490, 6255, 11, 309, 486, 1128, 312, 1075, 281, 51464], "temperature": 0.0, "avg_logprob": -0.13935628804293546, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.00475497730076313}, {"id": 191, "seek": 124312, "start": 1265.12, "end": 1271.52, "text": " suffer. Like it didn't involve nerves, it doesn't have pain centers, so on and so forth, they can't", "tokens": [51464, 9753, 13, 1743, 309, 994, 380, 9494, 23078, 11, 309, 1177, 380, 362, 1822, 10898, 11, 370, 322, 293, 370, 5220, 11, 436, 393, 380, 51784], "temperature": 0.0, "avg_logprob": -0.13935628804293546, "compression_ratio": 1.5679012345679013, "no_speech_prob": 0.00475497730076313}, {"id": 192, "seek": 127152, "start": 1271.6, "end": 1279.6, "text": " feel lonely because it's not a social entity, so on and so forth. Now that being said, language,", "tokens": [50368, 841, 14236, 570, 309, 311, 406, 257, 2093, 13977, 11, 370, 322, 293, 370, 5220, 13, 823, 300, 885, 848, 11, 2856, 11, 50768], "temperature": 0.0, "avg_logprob": -0.09621038108036437, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0014549319166690111}, {"id": 193, "seek": 127152, "start": 1280.24, "end": 1285.36, "text": " the acquisition of language is actually critical for the development of human consciousness.", "tokens": [50800, 264, 21668, 295, 2856, 307, 767, 4924, 337, 264, 3250, 295, 1952, 10081, 13, 51056], "temperature": 0.0, "avg_logprob": -0.09621038108036437, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0014549319166690111}, {"id": 194, "seek": 127152, "start": 1286.72, "end": 1292.0, "text": " So for instance, Bruce Willis, who has aphasia, aphasia means that your ability to use language", "tokens": [51124, 407, 337, 5197, 11, 15429, 3099, 271, 11, 567, 575, 257, 7485, 654, 11, 257, 7485, 654, 1355, 300, 428, 3485, 281, 764, 2856, 51388], "temperature": 0.0, "avg_logprob": -0.09621038108036437, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0014549319166690111}, {"id": 195, "seek": 127152, "start": 1292.0, "end": 1297.2, "text": " gets destroyed. Aphasia actually kind of erases your sense of consciousness.", "tokens": [51388, 2170, 8937, 13, 316, 7485, 654, 767, 733, 295, 1189, 1957, 428, 2020, 295, 10081, 13, 51648], "temperature": 0.0, "avg_logprob": -0.09621038108036437, "compression_ratio": 1.6233183856502242, "no_speech_prob": 0.0014549319166690111}, {"id": 196, "seek": 129720, "start": 1297.76, "end": 1305.1200000000001, "text": " Um, and then, uh, in the case of feral children, um, feral children, when they, some of them who", "tokens": [50392, 3301, 11, 293, 550, 11, 2232, 11, 294, 264, 1389, 295, 283, 2790, 2227, 11, 1105, 11, 283, 2790, 2227, 11, 562, 436, 11, 512, 295, 552, 567, 50760], "temperature": 0.0, "avg_logprob": -0.1315743502448587, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.002550513483583927}, {"id": 197, "seek": 129720, "start": 1305.1200000000001, "end": 1309.8400000000001, "text": " have learned language talked about how their consciousness and their understanding of time", "tokens": [50760, 362, 3264, 2856, 2825, 466, 577, 641, 10081, 293, 641, 3701, 295, 565, 50996], "temperature": 0.0, "avg_logprob": -0.1315743502448587, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.002550513483583927}, {"id": 198, "seek": 129720, "start": 1309.8400000000001, "end": 1317.92, "text": " in themselves changed as they learned language. So if you extrapolate that to language models,", "tokens": [50996, 294, 2969, 3105, 382, 436, 3264, 2856, 13, 407, 498, 291, 48224, 473, 300, 281, 2856, 5245, 11, 51400], "temperature": 0.0, "avg_logprob": -0.1315743502448587, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.002550513483583927}, {"id": 199, "seek": 129720, "start": 1317.92, "end": 1325.3600000000001, "text": " it is possible that, that there is something informationally almost magical about the acquisition", "tokens": [51400, 309, 307, 1944, 300, 11, 300, 456, 307, 746, 1589, 379, 1920, 12066, 466, 264, 21668, 51772], "temperature": 0.0, "avg_logprob": -0.1315743502448587, "compression_ratio": 1.7272727272727273, "no_speech_prob": 0.002550513483583927}, {"id": 200, "seek": 132536, "start": 1325.36, "end": 1332.24, "text": " of language that confers consciousness, that confers subjective experience of being. So that", "tokens": [50364, 295, 2856, 300, 1497, 433, 10081, 11, 300, 1497, 433, 25972, 1752, 295, 885, 13, 407, 300, 50708], "temperature": 0.0, "avg_logprob": -0.083230506290089, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.007344510871917009}, {"id": 201, "seek": 132536, "start": 1332.24, "end": 1338.32, "text": " could be that language models are actually the first AI that have subjective experience, that have", "tokens": [50708, 727, 312, 300, 2856, 5245, 366, 767, 264, 700, 7318, 300, 362, 25972, 1752, 11, 300, 362, 51012], "temperature": 0.0, "avg_logprob": -0.083230506290089, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.007344510871917009}, {"id": 202, "seek": 132536, "start": 1338.32, "end": 1346.4799999999998, "text": " a coherent, um, sense of being. And this is, so there are, um, there are some religious and", "tokens": [51012, 257, 36239, 11, 1105, 11, 2020, 295, 885, 13, 400, 341, 307, 11, 370, 456, 366, 11, 1105, 11, 456, 366, 512, 7185, 293, 51420], "temperature": 0.0, "avg_logprob": -0.083230506290089, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.007344510871917009}, {"id": 203, "seek": 132536, "start": 1346.4799999999998, "end": 1352.1599999999999, "text": " spiritual frameworks that kind of discuss stuff like this, um, particularly, uh, what's the name", "tokens": [51420, 6960, 29834, 300, 733, 295, 2248, 1507, 411, 341, 11, 1105, 11, 4098, 11, 2232, 11, 437, 311, 264, 1315, 51704], "temperature": 0.0, "avg_logprob": -0.083230506290089, "compression_ratio": 1.7592592592592593, "no_speech_prob": 0.007344510871917009}, {"id": 204, "seek": 135216, "start": 1352.16, "end": 1358.64, "text": " of the, the, the creator deity in Tolkien's world, where the fundamental substrate of reality was", "tokens": [50364, 295, 264, 11, 264, 11, 264, 14181, 37939, 294, 48824, 311, 1002, 11, 689, 264, 8088, 27585, 295, 4103, 390, 50688], "temperature": 0.0, "avg_logprob": -0.11603582252576514, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.004609132185578346}, {"id": 205, "seek": 135216, "start": 1358.64, "end": 1364.16, "text": " music, right? But maybe the fundamental substrate of consciousness is actually language. Um, so we", "tokens": [50688, 1318, 11, 558, 30, 583, 1310, 264, 8088, 27585, 295, 10081, 307, 767, 2856, 13, 3301, 11, 370, 321, 50964], "temperature": 0.0, "avg_logprob": -0.11603582252576514, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.004609132185578346}, {"id": 206, "seek": 135216, "start": 1364.16, "end": 1373.6000000000001, "text": " don't, we don't know yet, but that's, it's a possibility. Um, let's see. Uh, so Parkinson,", "tokens": [50964, 500, 380, 11, 321, 500, 380, 458, 1939, 11, 457, 300, 311, 11, 309, 311, 257, 7959, 13, 3301, 11, 718, 311, 536, 13, 4019, 11, 370, 35823, 11, 51436], "temperature": 0.0, "avg_logprob": -0.11603582252576514, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.004609132185578346}, {"id": 207, "seek": 135216, "start": 1373.6000000000001, "end": 1379.76, "text": " so the follow-up question was, or here, let me check the Patreon real quick. Um, let's see,", "tokens": [51436, 370, 264, 1524, 12, 1010, 1168, 390, 11, 420, 510, 11, 718, 385, 1520, 264, 15692, 957, 1702, 13, 3301, 11, 718, 311, 536, 11, 51744], "temperature": 0.0, "avg_logprob": -0.11603582252576514, "compression_ratio": 1.669603524229075, "no_speech_prob": 0.004609132185578346}, {"id": 208, "seek": 137976, "start": 1379.76, "end": 1383.44, "text": " do you think there needs to be another breakthrough for AGI? What is your personal take on this?", "tokens": [50364, 360, 291, 519, 456, 2203, 281, 312, 1071, 22397, 337, 316, 26252, 30, 708, 307, 428, 2973, 747, 322, 341, 30, 50548], "temperature": 0.0, "avg_logprob": -0.08904270862969826, "compression_ratio": 1.6135593220338984, "no_speech_prob": 0.027582429349422455}, {"id": 209, "seek": 137976, "start": 1383.44, "end": 1390.56, "text": " Do LLM suffice? Um, yeah. So I would say that, that our current trajectory, as long as the", "tokens": [50548, 1144, 441, 43, 44, 3889, 573, 30, 3301, 11, 1338, 13, 407, 286, 576, 584, 300, 11, 300, 527, 2190, 21512, 11, 382, 938, 382, 264, 50904], "temperature": 0.0, "avg_logprob": -0.08904270862969826, "compression_ratio": 1.6135593220338984, "no_speech_prob": 0.027582429349422455}, {"id": 210, "seek": 137976, "start": 1390.56, "end": 1395.84, "text": " trend continues, we are on track for AGI. Um, people are going to continue debating about AGI", "tokens": [50904, 6028, 6515, 11, 321, 366, 322, 2837, 337, 316, 26252, 13, 3301, 11, 561, 366, 516, 281, 2354, 40647, 466, 316, 26252, 51168], "temperature": 0.0, "avg_logprob": -0.08904270862969826, "compression_ratio": 1.6135593220338984, "no_speech_prob": 0.027582429349422455}, {"id": 211, "seek": 137976, "start": 1395.84, "end": 1402.16, "text": " forever though, until the cows come home. Um, which is why I keep saying like autonomous cognitive", "tokens": [51168, 5680, 1673, 11, 1826, 264, 19148, 808, 1280, 13, 3301, 11, 597, 307, 983, 286, 1066, 1566, 411, 23797, 15605, 51484], "temperature": 0.0, "avg_logprob": -0.08904270862969826, "compression_ratio": 1.6135593220338984, "no_speech_prob": 0.027582429349422455}, {"id": 212, "seek": 137976, "start": 1402.16, "end": 1407.76, "text": " entity, ACE, or just autonomous AI, because it doesn't, you don't need AGI. You don't need some", "tokens": [51484, 13977, 11, 44606, 11, 420, 445, 23797, 7318, 11, 570, 309, 1177, 380, 11, 291, 500, 380, 643, 316, 26252, 13, 509, 500, 380, 643, 512, 51764], "temperature": 0.0, "avg_logprob": -0.08904270862969826, "compression_ratio": 1.6135593220338984, "no_speech_prob": 0.027582429349422455}, {"id": 213, "seek": 140776, "start": 1407.76, "end": 1415.44, "text": " arbitrary magical boogeyman. All you need is like an AI system that is self-contained and", "tokens": [50364, 23211, 12066, 23113, 432, 88, 1601, 13, 1057, 291, 643, 307, 411, 364, 7318, 1185, 300, 307, 2698, 12, 9000, 3563, 293, 50748], "temperature": 0.0, "avg_logprob": -0.09901753234863281, "compression_ratio": 1.6386861313868613, "no_speech_prob": 0.009412094950675964}, {"id": 214, "seek": 140776, "start": 1415.44, "end": 1420.56, "text": " autonomous enough to be useful or dangerous. Um, and then the question is, how many do you have?", "tokens": [50748, 23797, 1547, 281, 312, 4420, 420, 5795, 13, 3301, 11, 293, 550, 264, 1168, 307, 11, 577, 867, 360, 291, 362, 30, 51004], "temperature": 0.0, "avg_logprob": -0.09901753234863281, "compression_ratio": 1.6386861313868613, "no_speech_prob": 0.009412094950675964}, {"id": 215, "seek": 140776, "start": 1420.56, "end": 1424.08, "text": " How fast are they? And how smart are they? And they're going to continue to get faster,", "tokens": [51004, 1012, 2370, 366, 436, 30, 400, 577, 4069, 366, 436, 30, 400, 436, 434, 516, 281, 2354, 281, 483, 4663, 11, 51180], "temperature": 0.0, "avg_logprob": -0.09901753234863281, "compression_ratio": 1.6386861313868613, "no_speech_prob": 0.009412094950675964}, {"id": 216, "seek": 140776, "start": 1424.08, "end": 1428.64, "text": " cheaper, and smarter over time. So it's like, okay, we're there. It's just a matter of", "tokens": [51180, 12284, 11, 293, 20294, 670, 565, 13, 407, 309, 311, 411, 11, 1392, 11, 321, 434, 456, 13, 467, 311, 445, 257, 1871, 295, 51408], "temperature": 0.0, "avg_logprob": -0.09901753234863281, "compression_ratio": 1.6386861313868613, "no_speech_prob": 0.009412094950675964}, {"id": 217, "seek": 140776, "start": 1429.44, "end": 1433.76, "text": " how does, how does the trend line ramp up, right? Cause it's kind of like, um, when the", "tokens": [51448, 577, 775, 11, 577, 775, 264, 6028, 1622, 12428, 493, 11, 558, 30, 10865, 309, 311, 733, 295, 411, 11, 1105, 11, 562, 264, 51664], "temperature": 0.0, "avg_logprob": -0.09901753234863281, "compression_ratio": 1.6386861313868613, "no_speech_prob": 0.009412094950675964}, {"id": 218, "seek": 143376, "start": 1433.76, "end": 1438.08, "text": " Wright brothers first created the Wright flyer, right? You know, it's like, okay, you had to", "tokens": [50364, 25578, 8452, 700, 2942, 264, 25578, 3603, 260, 11, 558, 30, 509, 458, 11, 309, 311, 411, 11, 1392, 11, 291, 632, 281, 50580], "temperature": 0.0, "avg_logprob": -0.09301110317832545, "compression_ratio": 1.6631205673758864, "no_speech_prob": 0.04602900519967079}, {"id": 219, "seek": 143376, "start": 1438.08, "end": 1443.12, "text": " start it by hand and push it, you know, down a track and it flew well, like 200 feet or 300 feet.", "tokens": [50580, 722, 309, 538, 1011, 293, 2944, 309, 11, 291, 458, 11, 760, 257, 2837, 293, 309, 15728, 731, 11, 411, 2331, 3521, 420, 6641, 3521, 13, 50832], "temperature": 0.0, "avg_logprob": -0.09301110317832545, "compression_ratio": 1.6631205673758864, "no_speech_prob": 0.04602900519967079}, {"id": 220, "seek": 143376, "start": 1443.12, "end": 1447.28, "text": " And people are like, ah, whatever that won't be useful. But then 50 years later, we were flying", "tokens": [50832, 400, 561, 366, 411, 11, 3716, 11, 2035, 300, 1582, 380, 312, 4420, 13, 583, 550, 2625, 924, 1780, 11, 321, 645, 7137, 51040], "temperature": 0.0, "avg_logprob": -0.09301110317832545, "compression_ratio": 1.6631205673758864, "no_speech_prob": 0.04602900519967079}, {"id": 221, "seek": 143376, "start": 1447.28, "end": 1453.68, "text": " to space, right? So we're at the beginning of the ramp up of, of the era of AGI. And yeah,", "tokens": [51040, 281, 1901, 11, 558, 30, 407, 321, 434, 412, 264, 2863, 295, 264, 12428, 493, 295, 11, 295, 264, 4249, 295, 316, 26252, 13, 400, 1338, 11, 51360], "temperature": 0.0, "avg_logprob": -0.09301110317832545, "compression_ratio": 1.6631205673758864, "no_speech_prob": 0.04602900519967079}, {"id": 222, "seek": 143376, "start": 1453.68, "end": 1457.92, "text": " right now they're like idiotic little toddlers, but in a few years they're going to be like", "tokens": [51360, 558, 586, 436, 434, 411, 14270, 299, 707, 33268, 11977, 11, 457, 294, 257, 1326, 924, 436, 434, 516, 281, 312, 411, 51572], "temperature": 0.0, "avg_logprob": -0.09301110317832545, "compression_ratio": 1.6631205673758864, "no_speech_prob": 0.04602900519967079}, {"id": 223, "seek": 145792, "start": 1458.5600000000002, "end": 1464.48, "text": " one all over the place and two really powerful. Um, good question. Let me come back over here.", "tokens": [50396, 472, 439, 670, 264, 1081, 293, 732, 534, 4005, 13, 3301, 11, 665, 1168, 13, 961, 385, 808, 646, 670, 510, 13, 50692], "temperature": 0.0, "avg_logprob": -0.1310917597550612, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.10968439280986786}, {"id": 224, "seek": 145792, "start": 1465.68, "end": 1470.0, "text": " Um, you should do a whole episode on aphasia and consciousness. I actually don't know that", "tokens": [50752, 3301, 11, 291, 820, 360, 257, 1379, 3500, 322, 257, 7485, 654, 293, 10081, 13, 286, 767, 500, 380, 458, 300, 50968], "temperature": 0.0, "avg_logprob": -0.1310917597550612, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.10968439280986786}, {"id": 225, "seek": 145792, "start": 1470.0, "end": 1474.96, "text": " much about it. Um, but if you're interested in the topic, I recommend phantoms in the brain,", "tokens": [50968, 709, 466, 309, 13, 3301, 11, 457, 498, 291, 434, 3102, 294, 264, 4829, 11, 286, 2748, 903, 394, 4785, 294, 264, 3567, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1310917597550612, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.10968439280986786}, {"id": 226, "seek": 145792, "start": 1476.0800000000002, "end": 1482.96, "text": " by, um, VS Ramachandran. And also what's the name of his other book? Um, it's something like", "tokens": [51272, 538, 11, 1105, 11, 25091, 9078, 608, 474, 4257, 13, 400, 611, 437, 311, 264, 1315, 295, 702, 661, 1446, 30, 3301, 11, 309, 311, 746, 411, 51616], "temperature": 0.0, "avg_logprob": -0.1310917597550612, "compression_ratio": 1.5142857142857142, "no_speech_prob": 0.10968439280986786}, {"id": 227, "seek": 148296, "start": 1482.96, "end": 1491.28, "text": " the pursuit of what makes humans human. Um, okay. Uh, let's see. So Parkinson's is a neurodegenerative", "tokens": [50364, 264, 23365, 295, 437, 1669, 6255, 1952, 13, 3301, 11, 1392, 13, 4019, 11, 718, 311, 536, 13, 407, 35823, 311, 307, 257, 16499, 67, 1146, 7971, 1166, 50780], "temperature": 0.0, "avg_logprob": -0.06553114914312595, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.034094907343387604}, {"id": 228, "seek": 148296, "start": 1491.28, "end": 1496.56, "text": " disease, which I think means that it's autoimmune or it's a, or it's a defective protein. Um, but", "tokens": [50780, 4752, 11, 597, 286, 519, 1355, 300, 309, 311, 8399, 49031, 420, 309, 311, 257, 11, 420, 309, 311, 257, 16445, 488, 7944, 13, 3301, 11, 457, 51044], "temperature": 0.0, "avg_logprob": -0.06553114914312595, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.034094907343387604}, {"id": 229, "seek": 148296, "start": 1496.56, "end": 1501.3600000000001, "text": " also Alzheimer's is a defective protein. So while these diseases seem very complicated,", "tokens": [51044, 611, 27932, 311, 307, 257, 16445, 488, 7944, 13, 407, 1339, 613, 11044, 1643, 588, 6179, 11, 51284], "temperature": 0.0, "avg_logprob": -0.06553114914312595, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.034094907343387604}, {"id": 230, "seek": 148296, "start": 1501.3600000000001, "end": 1506.24, "text": " the fundamental mechanisms are actually relatively straightforward. Um, and I know that there's", "tokens": [51284, 264, 8088, 15902, 366, 767, 7226, 15325, 13, 3301, 11, 293, 286, 458, 300, 456, 311, 51528], "temperature": 0.0, "avg_logprob": -0.06553114914312595, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.034094907343387604}, {"id": 231, "seek": 148296, "start": 1506.24, "end": 1510.96, "text": " probably a bunch of researchers that are going to jump on me for that. But, um, like plaques that", "tokens": [51528, 1391, 257, 3840, 295, 10309, 300, 366, 516, 281, 3012, 322, 385, 337, 300, 13, 583, 11, 1105, 11, 411, 15256, 7519, 300, 51764], "temperature": 0.0, "avg_logprob": -0.06553114914312595, "compression_ratio": 1.6736111111111112, "no_speech_prob": 0.034094907343387604}, {"id": 232, "seek": 151096, "start": 1510.96, "end": 1516.16, "text": " accumulate on the brain for Alzheimer's in most people, those plaques are cleared out. So then", "tokens": [50364, 33384, 322, 264, 3567, 337, 27932, 311, 294, 881, 561, 11, 729, 15256, 7519, 366, 19725, 484, 13, 407, 550, 50624], "temperature": 0.0, "avg_logprob": -0.054238982316924304, "compression_ratio": 1.625418060200669, "no_speech_prob": 0.007576848845928907}, {"id": 233, "seek": 151096, "start": 1516.16, "end": 1520.16, "text": " it's just a matter of figuring out like, okay, why? Um, and then of course there's confounding", "tokens": [50624, 309, 311, 445, 257, 1871, 295, 15213, 484, 411, 11, 1392, 11, 983, 30, 3301, 11, 293, 550, 295, 1164, 456, 311, 1497, 24625, 50824], "temperature": 0.0, "avg_logprob": -0.054238982316924304, "compression_ratio": 1.625418060200669, "no_speech_prob": 0.007576848845928907}, {"id": 234, "seek": 151096, "start": 1520.16, "end": 1526.88, "text": " factors like things like your, uh, gut inflammation, uh, microbiome and other things affect Alzheimer's.", "tokens": [50824, 6771, 411, 721, 411, 428, 11, 2232, 11, 5228, 21613, 11, 2232, 11, 33234, 423, 293, 661, 721, 3345, 27932, 311, 13, 51160], "temperature": 0.0, "avg_logprob": -0.054238982316924304, "compression_ratio": 1.625418060200669, "no_speech_prob": 0.007576848845928907}, {"id": 235, "seek": 151096, "start": 1526.88, "end": 1531.3600000000001, "text": " But that's because of the gut brain access. And again, I don't want to oversimplify because if", "tokens": [51160, 583, 300, 311, 570, 295, 264, 5228, 3567, 2105, 13, 400, 797, 11, 286, 500, 380, 528, 281, 15488, 332, 564, 2505, 570, 498, 51384], "temperature": 0.0, "avg_logprob": -0.054238982316924304, "compression_ratio": 1.625418060200669, "no_speech_prob": 0.007576848845928907}, {"id": 236, "seek": 151096, "start": 1531.3600000000001, "end": 1537.3600000000001, "text": " you look up like human, uh, metabolic pathways, there's like 200,000 unique proteins and enzymes", "tokens": [51384, 291, 574, 493, 411, 1952, 11, 2232, 11, 36464, 22988, 11, 456, 311, 411, 2331, 11, 1360, 3845, 15577, 293, 29299, 51684], "temperature": 0.0, "avg_logprob": -0.054238982316924304, "compression_ratio": 1.625418060200669, "no_speech_prob": 0.007576848845928907}, {"id": 237, "seek": 153736, "start": 1537.4399999999998, "end": 1542.8799999999999, "text": " in the body with built literally billions of combinations of reactions. So I might be,", "tokens": [50368, 294, 264, 1772, 365, 3094, 3736, 17375, 295, 21267, 295, 12215, 13, 407, 286, 1062, 312, 11, 50640], "temperature": 0.0, "avg_logprob": -0.0716845432917277, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0037071197293698788}, {"id": 238, "seek": 153736, "start": 1542.8799999999999, "end": 1547.12, "text": " it might sound like I'm oversimplifying, but I'm, I'm, I'm not saying that it's that simple. I'm", "tokens": [50640, 309, 1062, 1626, 411, 286, 478, 15488, 332, 564, 5489, 11, 457, 286, 478, 11, 286, 478, 11, 286, 478, 406, 1566, 300, 309, 311, 300, 2199, 13, 286, 478, 50852], "temperature": 0.0, "avg_logprob": -0.0716845432917277, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0037071197293698788}, {"id": 239, "seek": 153736, "start": 1547.12, "end": 1553.52, "text": " just saying that, that the, that the, the key mechanism for most diseases is relatively simple", "tokens": [50852, 445, 1566, 300, 11, 300, 264, 11, 300, 264, 11, 264, 2141, 7513, 337, 881, 11044, 307, 7226, 2199, 51172], "temperature": 0.0, "avg_logprob": -0.0716845432917277, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0037071197293698788}, {"id": 240, "seek": 153736, "start": 1553.52, "end": 1557.84, "text": " once you understand it. And we're getting close to that understanding. I guess that's the short", "tokens": [51172, 1564, 291, 1223, 309, 13, 400, 321, 434, 1242, 1998, 281, 300, 3701, 13, 286, 2041, 300, 311, 264, 2099, 51388], "temperature": 0.0, "avg_logprob": -0.0716845432917277, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0037071197293698788}, {"id": 241, "seek": 153736, "start": 1557.84, "end": 1562.4799999999998, "text": " version of what I'm trying to say. Um, let's see, when you explained why you canceled the", "tokens": [51388, 3037, 295, 437, 286, 478, 1382, 281, 584, 13, 3301, 11, 718, 311, 536, 11, 562, 291, 8825, 983, 291, 24839, 264, 51620], "temperature": 0.0, "avg_logprob": -0.0716845432917277, "compression_ratio": 1.744360902255639, "no_speech_prob": 0.0037071197293698788}, {"id": 242, "seek": 156248, "start": 1562.48, "end": 1565.92, "text": " OSS Raven project, you mentioned that there were some fundamental things missing.", "tokens": [50364, 12731, 50, 28956, 1716, 11, 291, 2835, 300, 456, 645, 512, 8088, 721, 5361, 13, 50536], "temperature": 0.0, "avg_logprob": -0.10510009374373998, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.051837895065546036}, {"id": 243, "seek": 156248, "start": 1566.64, "end": 1572.0, "text": " Um, can you say what was missing and what might change your, or what made you change your mind?", "tokens": [50572, 3301, 11, 393, 291, 584, 437, 390, 5361, 293, 437, 1062, 1319, 428, 11, 420, 437, 1027, 291, 1319, 428, 1575, 30, 50840], "temperature": 0.0, "avg_logprob": -0.10510009374373998, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.051837895065546036}, {"id": 244, "seek": 156248, "start": 1572.56, "end": 1580.56, "text": " Um, so my open source Raven project was like just before Lang chain and, and auto GPT and,", "tokens": [50868, 3301, 11, 370, 452, 1269, 4009, 28956, 1716, 390, 411, 445, 949, 13313, 5021, 293, 11, 293, 8399, 26039, 51, 293, 11, 51268], "temperature": 0.0, "avg_logprob": -0.10510009374373998, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.051837895065546036}, {"id": 245, "seek": 156248, "start": 1580.56, "end": 1585.2, "text": " and all those other things came out. Um, and so as those came ramped up, I was like, I don't", "tokens": [51268, 293, 439, 729, 661, 721, 1361, 484, 13, 3301, 11, 293, 370, 382, 729, 1361, 12428, 292, 493, 11, 286, 390, 411, 11, 286, 500, 380, 51500], "temperature": 0.0, "avg_logprob": -0.10510009374373998, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.051837895065546036}, {"id": 246, "seek": 156248, "start": 1585.2, "end": 1591.1200000000001, "text": " really feel the need to continue. Um, but from a, from a social and organizational perspective,", "tokens": [51500, 534, 841, 264, 643, 281, 2354, 13, 3301, 11, 457, 490, 257, 11, 490, 257, 2093, 293, 24730, 4585, 11, 51796], "temperature": 0.0, "avg_logprob": -0.10510009374373998, "compression_ratio": 1.7376425855513309, "no_speech_prob": 0.051837895065546036}, {"id": 247, "seek": 159112, "start": 1591.12, "end": 1596.4799999999998, "text": " the biggest thing that was missing was gatekeeping. Um, I, I basically, I created a community that was", "tokens": [50364, 264, 3880, 551, 300, 390, 5361, 390, 8539, 25769, 13, 3301, 11, 286, 11, 286, 1936, 11, 286, 2942, 257, 1768, 300, 390, 50632], "temperature": 0.0, "avg_logprob": -0.05099419185093471, "compression_ratio": 1.8715953307392996, "no_speech_prob": 0.0023230374790728092}, {"id": 248, "seek": 159112, "start": 1596.4799999999998, "end": 1601.6, "text": " really good at discussing stuff and not doing stuff. Um, and that's not anyone's fault. That's", "tokens": [50632, 534, 665, 412, 10850, 1507, 293, 406, 884, 1507, 13, 3301, 11, 293, 300, 311, 406, 2878, 311, 7441, 13, 663, 311, 50888], "temperature": 0.0, "avg_logprob": -0.05099419185093471, "compression_ratio": 1.8715953307392996, "no_speech_prob": 0.0023230374790728092}, {"id": 249, "seek": 159112, "start": 1601.6, "end": 1606.8, "text": " if any, if there's anyone to blame, it's me. Um, just because I was like, I was so focused on", "tokens": [50888, 498, 604, 11, 498, 456, 311, 2878, 281, 10127, 11, 309, 311, 385, 13, 3301, 11, 445, 570, 286, 390, 411, 11, 286, 390, 370, 5178, 322, 51148], "temperature": 0.0, "avg_logprob": -0.05099419185093471, "compression_ratio": 1.8715953307392996, "no_speech_prob": 0.0023230374790728092}, {"id": 250, "seek": 159112, "start": 1606.8, "end": 1610.7199999999998, "text": " consensus and not just like, okay, let's just get stuff done. And then I see these other folks", "tokens": [51148, 19115, 293, 406, 445, 411, 11, 1392, 11, 718, 311, 445, 483, 1507, 1096, 13, 400, 550, 286, 536, 613, 661, 4024, 51344], "temperature": 0.0, "avg_logprob": -0.05099419185093471, "compression_ratio": 1.8715953307392996, "no_speech_prob": 0.0023230374790728092}, {"id": 251, "seek": 159112, "start": 1610.7199999999998, "end": 1615.6799999999998, "text": " that are just getting stuff done. And I'm like, okay, I'll just pass the torch. Um, let's see.", "tokens": [51344, 300, 366, 445, 1242, 1507, 1096, 13, 400, 286, 478, 411, 11, 1392, 11, 286, 603, 445, 1320, 264, 27822, 13, 3301, 11, 718, 311, 536, 13, 51592], "temperature": 0.0, "avg_logprob": -0.05099419185093471, "compression_ratio": 1.8715953307392996, "no_speech_prob": 0.0023230374790728092}, {"id": 252, "seek": 161568, "start": 1616.5600000000002, "end": 1623.44, "text": " I think if we gave GPT for Scarlett Johansson's voice and a robot body, the masses will begin", "tokens": [50408, 286, 519, 498, 321, 2729, 26039, 51, 337, 23181, 32547, 19180, 599, 3015, 311, 3177, 293, 257, 7881, 1772, 11, 264, 23935, 486, 1841, 50752], "temperature": 0.0, "avg_logprob": -0.16366461551550662, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.01065199263393879}, {"id": 253, "seek": 161568, "start": 1623.44, "end": 1628.4, "text": " to realize how close we are to AGI. Yeah, that's one way of putting it drink some water.", "tokens": [50752, 281, 4325, 577, 1998, 321, 366, 281, 316, 26252, 13, 865, 11, 300, 311, 472, 636, 295, 3372, 309, 2822, 512, 1281, 13, 51000], "temperature": 0.0, "avg_logprob": -0.16366461551550662, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.01065199263393879}, {"id": 254, "seek": 161568, "start": 1632.96, "end": 1637.92, "text": " Let's see at what point do creating NPC and using autonomous AI like auto G auto GPT", "tokens": [51228, 961, 311, 536, 412, 437, 935, 360, 4084, 28787, 293, 1228, 23797, 7318, 411, 8399, 460, 8399, 26039, 51, 51476], "temperature": 0.0, "avg_logprob": -0.16366461551550662, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.01065199263393879}, {"id": 255, "seek": 161568, "start": 1638.64, "end": 1643.68, "text": " and the likes become immoral, especially if you put them in games like GTA. I don't know that,", "tokens": [51512, 293, 264, 5902, 1813, 3397, 16819, 11, 2318, 498, 291, 829, 552, 294, 2813, 411, 35575, 13, 286, 500, 380, 458, 300, 11, 51764], "temperature": 0.0, "avg_logprob": -0.16366461551550662, "compression_ratio": 1.5020746887966805, "no_speech_prob": 0.01065199263393879}, {"id": 256, "seek": 164368, "start": 1643.76, "end": 1651.04, "text": " that it intrinsically does. Um, you know, not intrinsically immoral, but like certainly with", "tokens": [50368, 300, 309, 28621, 984, 775, 13, 3301, 11, 291, 458, 11, 406, 28621, 984, 3397, 16819, 11, 457, 411, 3297, 365, 50732], "temperature": 0.0, "avg_logprob": -0.08638549887615701, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.004609352443367243}, {"id": 257, "seek": 164368, "start": 1651.04, "end": 1659.76, "text": " any technology, you can do it dangerously. Um, let's see. I've been curious about the future of", "tokens": [50732, 604, 2899, 11, 291, 393, 360, 309, 4330, 5098, 13, 3301, 11, 718, 311, 536, 13, 286, 600, 668, 6369, 466, 264, 2027, 295, 51168], "temperature": 0.0, "avg_logprob": -0.08638549887615701, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.004609352443367243}, {"id": 258, "seek": 164368, "start": 1659.76, "end": 1666.0800000000002, "text": " entertainment. Oh, sorry, let me jump over to Patreon real quick. Let's see. Do you have an", "tokens": [51168, 12393, 13, 876, 11, 2597, 11, 718, 385, 3012, 670, 281, 15692, 957, 1702, 13, 961, 311, 536, 13, 1144, 291, 362, 364, 51484], "temperature": 0.0, "avg_logprob": -0.08638549887615701, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.004609352443367243}, {"id": 259, "seek": 164368, "start": 1666.0800000000002, "end": 1670.5600000000002, "text": " overarching roadmap of how to ensure the successful propagation of the heuristic", "tokens": [51484, 45501, 35738, 295, 577, 281, 5586, 264, 4406, 38377, 295, 264, 415, 374, 3142, 51708], "temperature": 0.0, "avg_logprob": -0.08638549887615701, "compression_ratio": 1.5493562231759657, "no_speech_prob": 0.004609352443367243}, {"id": 260, "seek": 167056, "start": 1670.6399999999999, "end": 1675.76, "text": " imperatives? If so, what can we all do to help you get to your milestone? That is a great question,", "tokens": [50368, 10100, 4884, 30, 759, 370, 11, 437, 393, 321, 439, 360, 281, 854, 291, 483, 281, 428, 28048, 30, 663, 307, 257, 869, 1168, 11, 50624], "temperature": 0.0, "avg_logprob": -0.10229117352029551, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03846093639731407}, {"id": 261, "seek": 167056, "start": 1675.76, "end": 1682.08, "text": " Blake. Um, so you're actually looking at it. So my number, my number one thing is my YouTube", "tokens": [50624, 23451, 13, 3301, 11, 370, 291, 434, 767, 1237, 412, 309, 13, 407, 452, 1230, 11, 452, 1230, 472, 551, 307, 452, 3088, 50940], "temperature": 0.0, "avg_logprob": -0.10229117352029551, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03846093639731407}, {"id": 262, "seek": 167056, "start": 1682.08, "end": 1688.8799999999999, "text": " channel. Um, because like, yeah, I've got enough expertise and, you know, IT and systems engineering", "tokens": [50940, 2269, 13, 3301, 11, 570, 411, 11, 1338, 11, 286, 600, 658, 1547, 11769, 293, 11, 291, 458, 11, 6783, 293, 3652, 7043, 51280], "temperature": 0.0, "avg_logprob": -0.10229117352029551, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03846093639731407}, {"id": 263, "seek": 167056, "start": 1688.8799999999999, "end": 1694.1599999999999, "text": " and enterprise. I've demonstrated enough understanding of language technology and AI and", "tokens": [51280, 293, 14132, 13, 286, 600, 18772, 1547, 3701, 295, 2856, 2899, 293, 7318, 293, 51544], "temperature": 0.0, "avg_logprob": -0.10229117352029551, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03846093639731407}, {"id": 264, "seek": 167056, "start": 1694.1599999999999, "end": 1698.72, "text": " cognitive architecture that I've got at least a little credibility. Um, certainly if you read", "tokens": [51544, 15605, 9482, 300, 286, 600, 658, 412, 1935, 257, 707, 28852, 13, 3301, 11, 3297, 498, 291, 1401, 51772], "temperature": 0.0, "avg_logprob": -0.10229117352029551, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.03846093639731407}, {"id": 265, "seek": 169872, "start": 1698.72, "end": 1703.84, "text": " all the comments on YouTube, some people, uh, don't believe anything that I say and that's", "tokens": [50364, 439, 264, 3053, 322, 3088, 11, 512, 561, 11, 2232, 11, 500, 380, 1697, 1340, 300, 286, 584, 293, 300, 311, 50620], "temperature": 0.0, "avg_logprob": -0.07463712136722306, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0474180169403553}, {"id": 266, "seek": 169872, "start": 1703.84, "end": 1709.52, "text": " fine. That's the internet for you. Um, but anyways, so basically step one was YouTube. That's why I", "tokens": [50620, 2489, 13, 663, 311, 264, 4705, 337, 291, 13, 3301, 11, 457, 13448, 11, 370, 1936, 1823, 472, 390, 3088, 13, 663, 311, 983, 286, 50904], "temperature": 0.0, "avg_logprob": -0.07463712136722306, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0474180169403553}, {"id": 267, "seek": 169872, "start": 1709.52, "end": 1714.72, "text": " started my YouTube channel is because I realized that I needed to propagate my work. Um, step two", "tokens": [50904, 1409, 452, 3088, 2269, 307, 570, 286, 5334, 300, 286, 2978, 281, 48256, 452, 589, 13, 3301, 11, 1823, 732, 51164], "temperature": 0.0, "avg_logprob": -0.07463712136722306, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0474180169403553}, {"id": 268, "seek": 169872, "start": 1715.52, "end": 1721.84, "text": " is, uh, teaching people. Um, and so by teaching people, that's like, you know, I've got a few", "tokens": [51204, 307, 11, 2232, 11, 4571, 561, 13, 3301, 11, 293, 370, 538, 4571, 561, 11, 300, 311, 411, 11, 291, 458, 11, 286, 600, 658, 257, 1326, 51520], "temperature": 0.0, "avg_logprob": -0.07463712136722306, "compression_ratio": 1.6754385964912282, "no_speech_prob": 0.0474180169403553}, {"id": 269, "seek": 172184, "start": 1721.84, "end": 1728.8799999999999, "text": " papers. I've got some code demonstrations. Um, I work with my Patreon, uh, supporters. Uh, I work", "tokens": [50364, 10577, 13, 286, 600, 658, 512, 3089, 34714, 13, 3301, 11, 286, 589, 365, 452, 15692, 11, 2232, 11, 17683, 13, 4019, 11, 286, 589, 50716], "temperature": 0.0, "avg_logprob": -0.10099765120959672, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.5962619781494141}, {"id": 270, "seek": 172184, "start": 1728.8799999999999, "end": 1734.32, "text": " with pretty much anyone who wants to, and then three further dissemination. So like the podcast", "tokens": [50716, 365, 1238, 709, 2878, 567, 2738, 281, 11, 293, 550, 1045, 3052, 34585, 399, 13, 407, 411, 264, 7367, 50988], "temperature": 0.0, "avg_logprob": -0.10099765120959672, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.5962619781494141}, {"id": 271, "seek": 172184, "start": 1734.32, "end": 1738.6399999999999, "text": " that I'm coming up on, one of the things that we're going to talk about is alignment and the control", "tokens": [50988, 300, 286, 478, 1348, 493, 322, 11, 472, 295, 264, 721, 300, 321, 434, 516, 281, 751, 466, 307, 18515, 293, 264, 1969, 51204], "temperature": 0.0, "avg_logprob": -0.10099765120959672, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.5962619781494141}, {"id": 272, "seek": 172184, "start": 1738.6399999999999, "end": 1744.32, "text": " problem. We're going to be talking about like Nash equilibrium, game theory, Molok, that sort of stuff.", "tokens": [51204, 1154, 13, 492, 434, 516, 281, 312, 1417, 466, 411, 25012, 15625, 11, 1216, 5261, 11, 28278, 453, 11, 300, 1333, 295, 1507, 13, 51488], "temperature": 0.0, "avg_logprob": -0.10099765120959672, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.5962619781494141}, {"id": 273, "seek": 172184, "start": 1744.32, "end": 1749.52, "text": " And so just by having the conversation and propagating the idea, that's like step three.", "tokens": [51488, 400, 370, 445, 538, 1419, 264, 3761, 293, 12425, 990, 264, 1558, 11, 300, 311, 411, 1823, 1045, 13, 51748], "temperature": 0.0, "avg_logprob": -0.10099765120959672, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.5962619781494141}, {"id": 274, "seek": 174952, "start": 1749.52, "end": 1758.32, "text": " Step four is actually my novel because, uh, actually most of what I came up with was, uh,", "tokens": [50364, 5470, 1451, 307, 767, 452, 7613, 570, 11, 2232, 11, 767, 881, 295, 437, 286, 1361, 493, 365, 390, 11, 2232, 11, 50804], "temperature": 0.0, "avg_logprob": -0.0900786558787028, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004442119097802788}, {"id": 275, "seek": 174952, "start": 1758.32, "end": 1765.12, "text": " in terms of cognitive architecture, heuristic imperatives was done in part through explorations", "tokens": [50804, 294, 2115, 295, 15605, 9482, 11, 415, 374, 3142, 10100, 4884, 390, 1096, 294, 644, 807, 24765, 763, 51144], "temperature": 0.0, "avg_logprob": -0.0900786558787028, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004442119097802788}, {"id": 276, "seek": 174952, "start": 1765.12, "end": 1770.72, "text": " and fiction. And so over the last four years, what I've done is I, I do some experiments", "tokens": [51144, 293, 13266, 13, 400, 370, 670, 264, 1036, 1451, 924, 11, 437, 286, 600, 1096, 307, 286, 11, 286, 360, 512, 12050, 51424], "temperature": 0.0, "avg_logprob": -0.0900786558787028, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004442119097802788}, {"id": 277, "seek": 174952, "start": 1770.72, "end": 1773.92, "text": " and that would inspire me and I'd go write more of my novel and then I'd, you know, get", "tokens": [51424, 293, 300, 576, 15638, 385, 293, 286, 1116, 352, 2464, 544, 295, 452, 7613, 293, 550, 286, 1116, 11, 291, 458, 11, 483, 51584], "temperature": 0.0, "avg_logprob": -0.0900786558787028, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004442119097802788}, {"id": 278, "seek": 174952, "start": 1773.92, "end": 1778.8799999999999, "text": " tired of my novel and do more experiments and I'd go back and forth until one, my novel took on a", "tokens": [51584, 5868, 295, 452, 7613, 293, 360, 544, 12050, 293, 286, 1116, 352, 646, 293, 5220, 1826, 472, 11, 452, 7613, 1890, 322, 257, 51832], "temperature": 0.0, "avg_logprob": -0.0900786558787028, "compression_ratio": 1.7624521072796935, "no_speech_prob": 0.0004442119097802788}, {"id": 279, "seek": 177888, "start": 1778.88, "end": 1784.4, "text": " life of its own, but also my research took on a life of its own. Um, but there's a video that came", "tokens": [50364, 993, 295, 1080, 1065, 11, 457, 611, 452, 2132, 1890, 322, 257, 993, 295, 1080, 1065, 13, 3301, 11, 457, 456, 311, 257, 960, 300, 1361, 50640], "temperature": 0.0, "avg_logprob": -0.08229538572936498, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.012052473612129688}, {"id": 280, "seek": 177888, "start": 1784.4, "end": 1794.72, "text": " out recently called, let me see if I can find it. It was, um, like why we need utopia. Um, here we go.", "tokens": [50640, 484, 3938, 1219, 11, 718, 385, 536, 498, 286, 393, 915, 309, 13, 467, 390, 11, 1105, 11, 411, 983, 321, 643, 2839, 22376, 13, 3301, 11, 510, 321, 352, 13, 51156], "temperature": 0.0, "avg_logprob": -0.08229538572936498, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.012052473612129688}, {"id": 281, "seek": 177888, "start": 1794.72, "end": 1801.1200000000001, "text": " It was our changing climate. So this is a little bit of a, um, uh, I don't agree with everything", "tokens": [51156, 467, 390, 527, 4473, 5659, 13, 407, 341, 307, 257, 707, 857, 295, 257, 11, 1105, 11, 2232, 11, 286, 500, 380, 3986, 365, 1203, 51476], "temperature": 0.0, "avg_logprob": -0.08229538572936498, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.012052473612129688}, {"id": 282, "seek": 177888, "start": 1801.1200000000001, "end": 1806.88, "text": " that this, that this, uh, you, this channel says, but it will make you think. Um, so this video,", "tokens": [51476, 300, 341, 11, 300, 341, 11, 2232, 11, 291, 11, 341, 2269, 1619, 11, 457, 309, 486, 652, 291, 519, 13, 3301, 11, 370, 341, 960, 11, 51764], "temperature": 0.0, "avg_logprob": -0.08229538572936498, "compression_ratio": 1.6952789699570816, "no_speech_prob": 0.012052473612129688}, {"id": 283, "seek": 180688, "start": 1806.88, "end": 1813.2800000000002, "text": " why we need utopias, um, actually talks about how, how valuable stories can be", "tokens": [50364, 983, 321, 643, 2839, 404, 4609, 11, 1105, 11, 767, 6686, 466, 577, 11, 577, 8263, 3676, 393, 312, 50684], "temperature": 0.0, "avg_logprob": -0.07991380807830066, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.010327272117137909}, {"id": 284, "seek": 180688, "start": 1814.0, "end": 1821.0400000000002, "text": " in communicating ideas because stories are naturally how we communicate philosophy and morals.", "tokens": [50720, 294, 17559, 3487, 570, 3676, 366, 8195, 577, 321, 7890, 10675, 293, 46849, 13, 51072], "temperature": 0.0, "avg_logprob": -0.07991380807830066, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.010327272117137909}, {"id": 285, "seek": 180688, "start": 1822.24, "end": 1828.4, "text": " We don't need, we don't like philosophy, like capital P philosophy from, from universities.", "tokens": [51132, 492, 500, 380, 643, 11, 321, 500, 380, 411, 10675, 11, 411, 4238, 430, 10675, 490, 11, 490, 11779, 13, 51440], "temperature": 0.0, "avg_logprob": -0.07991380807830066, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.010327272117137909}, {"id": 286, "seek": 180688, "start": 1828.4, "end": 1835.0400000000002, "text": " That's, that's backwards throughout almost all of human history. We communicate our fears and our", "tokens": [51440, 663, 311, 11, 300, 311, 12204, 3710, 1920, 439, 295, 1952, 2503, 13, 492, 7890, 527, 15649, 293, 527, 51772], "temperature": 0.0, "avg_logprob": -0.07991380807830066, "compression_ratio": 1.6883720930232557, "no_speech_prob": 0.010327272117137909}, {"id": 287, "seek": 183504, "start": 1835.04, "end": 1840.24, "text": " desires and our values through stories. And so that's what this video talks about. And so when", "tokens": [50364, 18005, 293, 527, 4190, 807, 3676, 13, 400, 370, 300, 311, 437, 341, 960, 6686, 466, 13, 400, 370, 562, 50624], "temperature": 0.0, "avg_logprob": -0.11933530323089116, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.0078153470531106}, {"id": 288, "seek": 183504, "start": 1840.24, "end": 1846.1599999999999, "text": " you have nothing but dystopian cyberpunk stuff, you end up with people like Eliad Zyrcikowski.", "tokens": [50624, 291, 362, 1825, 457, 14584, 13559, 952, 13411, 27133, 1507, 11, 291, 917, 493, 365, 561, 411, 16943, 345, 1176, 6016, 537, 74, 21866, 13, 50920], "temperature": 0.0, "avg_logprob": -0.11933530323089116, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.0078153470531106}, {"id": 289, "seek": 183504, "start": 1846.1599999999999, "end": 1851.36, "text": " Um, you know, yeah, I'm throwing some shade. But anyways, when that's all that you consume,", "tokens": [50920, 3301, 11, 291, 458, 11, 1338, 11, 286, 478, 10238, 512, 11466, 13, 583, 13448, 11, 562, 300, 311, 439, 300, 291, 14732, 11, 51180], "temperature": 0.0, "avg_logprob": -0.11933530323089116, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.0078153470531106}, {"id": 290, "seek": 183504, "start": 1851.36, "end": 1856.48, "text": " that's all you think, that's all you feel, and that's all you believe. So, um, my novel, which", "tokens": [51180, 300, 311, 439, 291, 519, 11, 300, 311, 439, 291, 841, 11, 293, 300, 311, 439, 291, 1697, 13, 407, 11, 1105, 11, 452, 7613, 11, 597, 51436], "temperature": 0.0, "avg_logprob": -0.11933530323089116, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.0078153470531106}, {"id": 291, "seek": 183504, "start": 1856.48, "end": 1861.76, "text": " I'm actually just about to finish draft 12 tomorrow morning, I'm writing the last chapter", "tokens": [51436, 286, 478, 767, 445, 466, 281, 2413, 11206, 2272, 4153, 2446, 11, 286, 478, 3579, 264, 1036, 7187, 51700], "temperature": 0.0, "avg_logprob": -0.11933530323089116, "compression_ratio": 1.6583629893238434, "no_speech_prob": 0.0078153470531106}, {"id": 292, "seek": 186176, "start": 1861.84, "end": 1868.96, "text": " and then I'm polishing it up, um, will illustrate, um, a lot of stuff, not just", "tokens": [50368, 293, 550, 286, 478, 47258, 309, 493, 11, 1105, 11, 486, 23221, 11, 1105, 11, 257, 688, 295, 1507, 11, 406, 445, 50724], "temperature": 0.0, "avg_logprob": -0.10146223068237305, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.003075155196711421}, {"id": 293, "seek": 186176, "start": 1868.96, "end": 1872.8799999999999, "text": " the core objective functions or puristic imperatives. So that was a long winded answer.", "tokens": [50724, 264, 4965, 10024, 6828, 420, 1864, 3142, 10100, 4884, 13, 407, 300, 390, 257, 938, 2468, 292, 1867, 13, 50920], "temperature": 0.0, "avg_logprob": -0.10146223068237305, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.003075155196711421}, {"id": 294, "seek": 186176, "start": 1873.84, "end": 1880.32, "text": " Um, let's see. I think there is, um, are there key channels this training needs to go into,", "tokens": [50968, 3301, 11, 718, 311, 536, 13, 286, 519, 456, 307, 11, 1105, 11, 366, 456, 2141, 9235, 341, 3097, 2203, 281, 352, 666, 11, 51292], "temperature": 0.0, "avg_logprob": -0.10146223068237305, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.003075155196711421}, {"id": 295, "seek": 186176, "start": 1880.32, "end": 1887.68, "text": " organizations, governments? Um, I think, I think right now Blake, um, it's mostly just a matter of,", "tokens": [51292, 6150, 11, 11280, 30, 3301, 11, 286, 519, 11, 286, 519, 558, 586, 23451, 11, 1105, 11, 309, 311, 5240, 445, 257, 1871, 295, 11, 51660], "temperature": 0.0, "avg_logprob": -0.10146223068237305, "compression_ratio": 1.5608695652173914, "no_speech_prob": 0.003075155196711421}, {"id": 296, "seek": 188768, "start": 1887.76, "end": 1894.16, "text": " of dissemination, but also experimentation. So a lot of people, um, have experimented with", "tokens": [50368, 295, 34585, 399, 11, 457, 611, 37142, 13, 407, 257, 688, 295, 561, 11, 1105, 11, 362, 5120, 292, 365, 50688], "temperature": 0.0, "avg_logprob": -0.08033221435546875, "compression_ratio": 1.6379928315412187, "no_speech_prob": 0.025954728946089745}, {"id": 297, "seek": 188768, "start": 1894.16, "end": 1898.88, "text": " incorporating heuristic imperatives into autonomous and semi-autonomous stuff. And", "tokens": [50688, 33613, 415, 374, 3142, 10100, 4884, 666, 23797, 293, 12909, 12, 1375, 12481, 563, 1507, 13, 400, 50924], "temperature": 0.0, "avg_logprob": -0.08033221435546875, "compression_ratio": 1.6379928315412187, "no_speech_prob": 0.025954728946089745}, {"id": 298, "seek": 188768, "start": 1899.8400000000001, "end": 1904.64, "text": " most of them aren't sharing it yet, which that's fine. It's their prerogative. Um, but certainly", "tokens": [50972, 881, 295, 552, 3212, 380, 5414, 309, 1939, 11, 597, 300, 311, 2489, 13, 467, 311, 641, 582, 260, 664, 1166, 13, 3301, 11, 457, 3297, 51212], "temperature": 0.0, "avg_logprob": -0.08033221435546875, "compression_ratio": 1.6379928315412187, "no_speech_prob": 0.025954728946089745}, {"id": 299, "seek": 188768, "start": 1904.64, "end": 1907.44, "text": " some people have reached out and said, like, yeah, this made everything easier. So I'm like,", "tokens": [51212, 512, 561, 362, 6488, 484, 293, 848, 11, 411, 11, 1338, 11, 341, 1027, 1203, 3571, 13, 407, 286, 478, 411, 11, 51352], "temperature": 0.0, "avg_logprob": -0.08033221435546875, "compression_ratio": 1.6379928315412187, "no_speech_prob": 0.025954728946089745}, {"id": 300, "seek": 188768, "start": 1907.44, "end": 1917.28, "text": " great, just tell your friends. Um, let's see. Okay. Let's come back over here. Um, let's see.", "tokens": [51352, 869, 11, 445, 980, 428, 1855, 13, 3301, 11, 718, 311, 536, 13, 1033, 13, 961, 311, 808, 646, 670, 510, 13, 3301, 11, 718, 311, 536, 13, 51844], "temperature": 0.0, "avg_logprob": -0.08033221435546875, "compression_ratio": 1.6379928315412187, "no_speech_prob": 0.025954728946089745}, {"id": 301, "seek": 191728, "start": 1917.28, "end": 1922.6399999999999, "text": " I've been really curious about the future of entertainment. When we can use AI to generate", "tokens": [50364, 286, 600, 668, 534, 6369, 466, 264, 2027, 295, 12393, 13, 1133, 321, 393, 764, 7318, 281, 8460, 50632], "temperature": 0.0, "avg_logprob": -0.06869167201923874, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.05664359778165817}, {"id": 302, "seek": 191728, "start": 1922.6399999999999, "end": 1927.76, "text": " movies, games, et cetera. Uh, what will the entertainment industry look like? Movie trailers", "tokens": [50632, 6233, 11, 2813, 11, 1030, 11458, 13, 4019, 11, 437, 486, 264, 12393, 3518, 574, 411, 30, 28766, 37698, 50888], "temperature": 0.0, "avg_logprob": -0.06869167201923874, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.05664359778165817}, {"id": 303, "seek": 191728, "start": 1927.76, "end": 1932.56, "text": " and hyping up big releases for months will be irrelevant when AI can instantly create something.", "tokens": [50888, 293, 2477, 3381, 493, 955, 16952, 337, 2493, 486, 312, 28682, 562, 7318, 393, 13518, 1884, 746, 13, 51128], "temperature": 0.0, "avg_logprob": -0.06869167201923874, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.05664359778165817}, {"id": 304, "seek": 191728, "start": 1932.56, "end": 1936.8799999999999, "text": " If someone created a movie you didn't like, you just ask your AI to recreate it with an", "tokens": [51128, 759, 1580, 2942, 257, 3169, 291, 994, 380, 411, 11, 291, 445, 1029, 428, 7318, 281, 25833, 309, 365, 364, 51344], "temperature": 0.0, "avg_logprob": -0.06869167201923874, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.05664359778165817}, {"id": 305, "seek": 191728, "start": 1936.8799999999999, "end": 1942.0, "text": " ending or plot more suited to your tastes. What happens with content creators at that point forward?", "tokens": [51344, 8121, 420, 7542, 544, 24736, 281, 428, 8666, 13, 708, 2314, 365, 2701, 16039, 412, 300, 935, 2128, 30, 51600], "temperature": 0.0, "avg_logprob": -0.06869167201923874, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.05664359778165817}, {"id": 306, "seek": 194200, "start": 1942.96, "end": 1949.12, "text": " Yeah. So I think that you're onto something. Uh, now that being said, it'll be easier for a lot of", "tokens": [50412, 865, 13, 407, 286, 519, 300, 291, 434, 3911, 746, 13, 4019, 11, 586, 300, 885, 848, 11, 309, 603, 312, 3571, 337, 257, 688, 295, 50720], "temperature": 0.0, "avg_logprob": -0.10587970475505169, "compression_ratio": 1.6262975778546713, "no_speech_prob": 0.09806299954652786}, {"id": 307, "seek": 194200, "start": 1949.12, "end": 1957.28, "text": " people like you and me to create whatever film, TV, music, whatever we want, um, with the help of AI,", "tokens": [50720, 561, 411, 291, 293, 385, 281, 1884, 2035, 2007, 11, 3558, 11, 1318, 11, 2035, 321, 528, 11, 1105, 11, 365, 264, 854, 295, 7318, 11, 51128], "temperature": 0.0, "avg_logprob": -0.10587970475505169, "compression_ratio": 1.6262975778546713, "no_speech_prob": 0.09806299954652786}, {"id": 308, "seek": 194200, "start": 1957.28, "end": 1961.92, "text": " especially when you look at the text of video, um, which is improving by leaps and bounds.", "tokens": [51128, 2318, 562, 291, 574, 412, 264, 2487, 295, 960, 11, 1105, 11, 597, 307, 11470, 538, 476, 2382, 293, 29905, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10587970475505169, "compression_ratio": 1.6262975778546713, "no_speech_prob": 0.09806299954652786}, {"id": 309, "seek": 194200, "start": 1961.92, "end": 1966.48, "text": " You know, like I always, my, my go-to joke is we'll finally get season two of Firefly.", "tokens": [51360, 509, 458, 11, 411, 286, 1009, 11, 452, 11, 452, 352, 12, 1353, 7647, 307, 321, 603, 2721, 483, 3196, 732, 295, 7652, 14061, 13, 51588], "temperature": 0.0, "avg_logprob": -0.10587970475505169, "compression_ratio": 1.6262975778546713, "no_speech_prob": 0.09806299954652786}, {"id": 310, "seek": 194200, "start": 1966.48, "end": 1970.24, "text": " Who knows, we might get season two of Firefly by the end of this year. That would be great.", "tokens": [51588, 2102, 3255, 11, 321, 1062, 483, 3196, 732, 295, 7652, 14061, 538, 264, 917, 295, 341, 1064, 13, 663, 576, 312, 869, 13, 51776], "temperature": 0.0, "avg_logprob": -0.10587970475505169, "compression_ratio": 1.6262975778546713, "no_speech_prob": 0.09806299954652786}, {"id": 311, "seek": 197024, "start": 1970.96, "end": 1975.68, "text": " Um, now the problem there, it's not really a problem, but just taking that to a logical", "tokens": [50400, 3301, 11, 586, 264, 1154, 456, 11, 309, 311, 406, 534, 257, 1154, 11, 457, 445, 1940, 300, 281, 257, 14978, 50636], "temperature": 0.0, "avg_logprob": -0.0857533674973708, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.007345334626734257}, {"id": 312, "seek": 197024, "start": 1975.68, "end": 1980.0, "text": " conclusion. What if you have a million different versions of season two of Firefly? How do you", "tokens": [50636, 10063, 13, 708, 498, 291, 362, 257, 2459, 819, 9606, 295, 3196, 732, 295, 7652, 14061, 30, 1012, 360, 291, 50852], "temperature": 0.0, "avg_logprob": -0.0857533674973708, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.007345334626734257}, {"id": 313, "seek": 197024, "start": 1980.0, "end": 1985.28, "text": " pick which one to watch? Right? You can look at ratings and stuff. Um, but then it also begs the", "tokens": [50852, 1888, 597, 472, 281, 1159, 30, 1779, 30, 509, 393, 574, 412, 24603, 293, 1507, 13, 3301, 11, 457, 550, 309, 611, 4612, 82, 264, 51116], "temperature": 0.0, "avg_logprob": -0.0857533674973708, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.007345334626734257}, {"id": 314, "seek": 197024, "start": 1985.28, "end": 1992.64, "text": " question of like IP, like is, uh, you know, 20th century Fox or whoever owns the IP for Firefly,", "tokens": [51116, 1168, 295, 411, 8671, 11, 411, 307, 11, 2232, 11, 291, 458, 11, 945, 392, 4901, 11388, 420, 11387, 19143, 264, 8671, 337, 7652, 14061, 11, 51484], "temperature": 0.0, "avg_logprob": -0.0857533674973708, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.007345334626734257}, {"id": 315, "seek": 197024, "start": 1992.64, "end": 1998.32, "text": " are they going to sue to have all of them shut down? You know, I, I like the dude from, uh,", "tokens": [51484, 366, 436, 516, 281, 20416, 281, 362, 439, 295, 552, 5309, 760, 30, 509, 458, 11, 286, 11, 286, 411, 264, 6449, 490, 11, 2232, 11, 51768], "temperature": 0.0, "avg_logprob": -0.0857533674973708, "compression_ratio": 1.5864406779661018, "no_speech_prob": 0.007345334626734257}, {"id": 316, "seek": 199832, "start": 1998.32, "end": 2003.2, "text": " from the movie, you can't stop the signal now. So I don't know what's going to happen there.", "tokens": [50364, 490, 264, 3169, 11, 291, 393, 380, 1590, 264, 6358, 586, 13, 407, 286, 500, 380, 458, 437, 311, 516, 281, 1051, 456, 13, 50608], "temperature": 0.0, "avg_logprob": -0.07903210190702076, "compression_ratio": 1.6035087719298247, "no_speech_prob": 0.035139963030815125}, {"id": 317, "seek": 199832, "start": 2003.9199999999998, "end": 2009.84, "text": " Um, but, uh, what I do think is that when you look at the fact that like people are already", "tokens": [50644, 3301, 11, 457, 11, 2232, 11, 437, 286, 360, 519, 307, 300, 562, 291, 574, 412, 264, 1186, 300, 411, 561, 366, 1217, 50940], "temperature": 0.0, "avg_logprob": -0.07903210190702076, "compression_ratio": 1.6035087719298247, "no_speech_prob": 0.035139963030815125}, {"id": 318, "seek": 199832, "start": 2009.84, "end": 2015.28, "text": " using like Emma Watson's face for every mid journey prompt and, and whoever else, um,", "tokens": [50940, 1228, 411, 17124, 25640, 311, 1851, 337, 633, 2062, 4671, 12391, 293, 11, 293, 11387, 1646, 11, 1105, 11, 51212], "temperature": 0.0, "avg_logprob": -0.07903210190702076, "compression_ratio": 1.6035087719298247, "no_speech_prob": 0.035139963030815125}, {"id": 319, "seek": 199832, "start": 2015.28, "end": 2019.9199999999998, "text": " I think that the crop of actors that we have today are basically going to be around forever.", "tokens": [51212, 286, 519, 300, 264, 9086, 295, 10037, 300, 321, 362, 965, 366, 1936, 516, 281, 312, 926, 5680, 13, 51444], "temperature": 0.0, "avg_logprob": -0.07903210190702076, "compression_ratio": 1.6035087719298247, "no_speech_prob": 0.035139963030815125}, {"id": 320, "seek": 199832, "start": 2019.9199999999998, "end": 2026.48, "text": " Right? You're going to be watching, uh, Brad Pitt and Jennifer Aniston and, and, and Tom Cruz", "tokens": [51444, 1779, 30, 509, 434, 516, 281, 312, 1976, 11, 2232, 11, 11895, 22861, 293, 14351, 1107, 47345, 293, 11, 293, 11, 293, 5041, 23008, 51772], "temperature": 0.0, "avg_logprob": -0.07903210190702076, "compression_ratio": 1.6035087719298247, "no_speech_prob": 0.035139963030815125}, {"id": 321, "seek": 202648, "start": 2026.48, "end": 2031.3600000000001, "text": " for literally the next, like several centuries, at least until some actor comes along who's even", "tokens": [50364, 337, 3736, 264, 958, 11, 411, 2940, 13926, 11, 412, 1935, 1826, 512, 8747, 1487, 2051, 567, 311, 754, 50608], "temperature": 0.0, "avg_logprob": -0.11064186997300997, "compression_ratio": 1.7677902621722847, "no_speech_prob": 0.0022517205215990543}, {"id": 322, "seek": 202648, "start": 2031.3600000000001, "end": 2037.6, "text": " more compelling and whatever. Uh, and that'll be through face cloning, voice cloning, even, um,", "tokens": [50608, 544, 20050, 293, 2035, 13, 4019, 11, 293, 300, 603, 312, 807, 1851, 596, 16638, 11, 3177, 596, 16638, 11, 754, 11, 1105, 11, 50920], "temperature": 0.0, "avg_logprob": -0.11064186997300997, "compression_ratio": 1.7677902621722847, "no_speech_prob": 0.0022517205215990543}, {"id": 323, "seek": 202648, "start": 2037.6, "end": 2043.44, "text": " you know, uh, nerfs, the, uh, the neural represent, uh, uh, representation. What was it? Neural", "tokens": [50920, 291, 458, 11, 2232, 11, 18219, 16883, 11, 264, 11, 2232, 11, 264, 18161, 2906, 11, 2232, 11, 2232, 11, 10290, 13, 708, 390, 309, 30, 1734, 1807, 51212], "temperature": 0.0, "avg_logprob": -0.11064186997300997, "compression_ratio": 1.7677902621722847, "no_speech_prob": 0.0022517205215990543}, {"id": 324, "seek": 202648, "start": 2043.44, "end": 2049.68, "text": " radiance fields, neural radiance fields. Um, we'll be able to like copy everyone. Um, okay,", "tokens": [51212, 2843, 6276, 7909, 11, 18161, 2843, 6276, 7909, 13, 3301, 11, 321, 603, 312, 1075, 281, 411, 5055, 1518, 13, 3301, 11, 1392, 11, 51524], "temperature": 0.0, "avg_logprob": -0.11064186997300997, "compression_ratio": 1.7677902621722847, "no_speech_prob": 0.0022517205215990543}, {"id": 325, "seek": 202648, "start": 2049.68, "end": 2055.44, "text": " could learning, uh, let me zoom in a little bit. Uh, could learning language and triggering", "tokens": [51524, 727, 2539, 11, 2232, 11, 718, 385, 8863, 294, 257, 707, 857, 13, 4019, 11, 727, 2539, 2856, 293, 40406, 51812], "temperature": 0.0, "avg_logprob": -0.11064186997300997, "compression_ratio": 1.7677902621722847, "no_speech_prob": 0.0022517205215990543}, {"id": 326, "seek": 205544, "start": 2055.52, "end": 2060.48, "text": " consciousness in humans almost replicate the same phase change when seen, um, or seen when", "tokens": [50368, 10081, 294, 6255, 1920, 25356, 264, 912, 5574, 1319, 562, 1612, 11, 1105, 11, 420, 1612, 562, 50616], "temperature": 0.0, "avg_logprob": -0.10093299966109426, "compression_ratio": 1.6450511945392492, "no_speech_prob": 0.005219737999141216}, {"id": 327, "seek": 205544, "start": 2060.48, "end": 2065.44, "text": " induction heads spontaneously form two plus layer models during training. Obviously there's more", "tokens": [50616, 33371, 8050, 47632, 1254, 732, 1804, 4583, 5245, 1830, 3097, 13, 7580, 456, 311, 544, 50864], "temperature": 0.0, "avg_logprob": -0.10093299966109426, "compression_ratio": 1.6450511945392492, "no_speech_prob": 0.005219737999141216}, {"id": 328, "seek": 205544, "start": 2065.44, "end": 2070.48, "text": " to humans, but perhaps that's the mechanism. Uh, yeah, that's kind of what I was mentioning earlier.", "tokens": [50864, 281, 6255, 11, 457, 4317, 300, 311, 264, 7513, 13, 4019, 11, 1338, 11, 300, 311, 733, 295, 437, 286, 390, 18315, 3071, 13, 51116], "temperature": 0.0, "avg_logprob": -0.10093299966109426, "compression_ratio": 1.6450511945392492, "no_speech_prob": 0.005219737999141216}, {"id": 329, "seek": 205544, "start": 2070.48, "end": 2078.7200000000003, "text": " Um, and I wouldn't be surprised if once language models get, uh, large enough if, um, if we do see", "tokens": [51116, 3301, 11, 293, 286, 2759, 380, 312, 6100, 498, 1564, 2856, 5245, 483, 11, 2232, 11, 2416, 1547, 498, 11, 1105, 11, 498, 321, 360, 536, 51528], "temperature": 0.0, "avg_logprob": -0.10093299966109426, "compression_ratio": 1.6450511945392492, "no_speech_prob": 0.005219737999141216}, {"id": 330, "seek": 205544, "start": 2078.7200000000003, "end": 2082.96, "text": " some more convergence. Um, that being said, I'm not going to say that that automatically means", "tokens": [51528, 512, 544, 32181, 13, 3301, 11, 300, 885, 848, 11, 286, 478, 406, 516, 281, 584, 300, 300, 6772, 1355, 51740], "temperature": 0.0, "avg_logprob": -0.10093299966109426, "compression_ratio": 1.6450511945392492, "no_speech_prob": 0.005219737999141216}, {"id": 331, "seek": 208296, "start": 2082.96, "end": 2088.32, "text": " that it has a subjective experience and that it is suffering, but you know, our brains evolved", "tokens": [50364, 300, 309, 575, 257, 25972, 1752, 293, 300, 309, 307, 7755, 11, 457, 291, 458, 11, 527, 15442, 14178, 50632], "temperature": 0.0, "avg_logprob": -0.12067473806985994, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00082956108963117}, {"id": 332, "seek": 208296, "start": 2088.32, "end": 2094.2400000000002, "text": " over billions of years to be efficient. Um, basically efficient processors of information.", "tokens": [50632, 670, 17375, 295, 924, 281, 312, 7148, 13, 3301, 11, 1936, 7148, 27751, 295, 1589, 13, 50928], "temperature": 0.0, "avg_logprob": -0.12067473806985994, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00082956108963117}, {"id": 333, "seek": 208296, "start": 2094.2400000000002, "end": 2100.64, "text": " Who's, who's to say that if you have a, a biomimetic machine that it won't also converge on some of", "tokens": [50928, 2102, 311, 11, 567, 311, 281, 584, 300, 498, 291, 362, 257, 11, 257, 27450, 332, 3532, 3479, 300, 309, 1582, 380, 611, 41881, 322, 512, 295, 51248], "temperature": 0.0, "avg_logprob": -0.12067473806985994, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00082956108963117}, {"id": 334, "seek": 208296, "start": 2100.64, "end": 2106.56, "text": " the same properties and behaviors. Um, let's see, what do you think it will take to get for the", "tokens": [51248, 264, 912, 7221, 293, 15501, 13, 3301, 11, 718, 311, 536, 11, 437, 360, 291, 519, 309, 486, 747, 281, 483, 337, 264, 51544], "temperature": 0.0, "avg_logprob": -0.12067473806985994, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00082956108963117}, {"id": 335, "seek": 208296, "start": 2106.56, "end": 2112.0, "text": " naysayers to get on board? The tone around AI seems to have shifted towards chat GPT and GPT-4", "tokens": [51544, 297, 3772, 320, 433, 281, 483, 322, 3150, 30, 440, 8027, 926, 7318, 2544, 281, 362, 18892, 3030, 5081, 26039, 51, 293, 26039, 51, 12, 19, 51816], "temperature": 0.0, "avg_logprob": -0.12067473806985994, "compression_ratio": 1.6245733788395904, "no_speech_prob": 0.00082956108963117}, {"id": 336, "seek": 211200, "start": 2112.0, "end": 2118.0, "text": " aren't anything special. Oh, you know, that, that always happens when the new shiny wears off.", "tokens": [50364, 3212, 380, 1340, 2121, 13, 876, 11, 291, 458, 11, 300, 11, 300, 1009, 2314, 562, 264, 777, 16997, 20877, 766, 13, 50664], "temperature": 0.0, "avg_logprob": -0.10277248529287485, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.011330538429319859}, {"id": 337, "seek": 211200, "start": 2118.0, "end": 2125.2, "text": " Um, but the long-term economic impact of chat GPT has not been realized yet. And when chat GPT", "tokens": [50664, 3301, 11, 457, 264, 938, 12, 7039, 4836, 2712, 295, 5081, 26039, 51, 575, 406, 668, 5334, 1939, 13, 400, 562, 5081, 26039, 51, 51024], "temperature": 0.0, "avg_logprob": -0.10277248529287485, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.011330538429319859}, {"id": 338, "seek": 211200, "start": 2125.2, "end": 2130.32, "text": " and GPT-4 are on the ramp up, one, there's going to be a lot of competitors and two, there's going", "tokens": [51024, 293, 26039, 51, 12, 19, 366, 322, 264, 12428, 493, 11, 472, 11, 456, 311, 516, 281, 312, 257, 688, 295, 18333, 293, 732, 11, 456, 311, 516, 51280], "temperature": 0.0, "avg_logprob": -0.10277248529287485, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.011330538429319859}, {"id": 339, "seek": 211200, "start": 2130.32, "end": 2136.56, "text": " to be incremental improvements and people are going to be like, uh, okay. The title, it's like,", "tokens": [51280, 281, 312, 35759, 13797, 293, 561, 366, 516, 281, 312, 411, 11, 2232, 11, 1392, 13, 440, 4876, 11, 309, 311, 411, 11, 51592], "temperature": 0.0, "avg_logprob": -0.10277248529287485, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.011330538429319859}, {"id": 340, "seek": 211200, "start": 2136.56, "end": 2140.72, "text": " it's like when you watch the, the tsunami come in and that just the water just keeps getting higher", "tokens": [51592, 309, 311, 411, 562, 291, 1159, 264, 11, 264, 39032, 808, 294, 293, 300, 445, 264, 1281, 445, 5965, 1242, 2946, 51800], "temperature": 0.0, "avg_logprob": -0.10277248529287485, "compression_ratio": 1.7285714285714286, "no_speech_prob": 0.011330538429319859}, {"id": 341, "seek": 214072, "start": 2140.72, "end": 2145.9199999999996, "text": " and faster for like hours. That's what AI is going to feel like, except instead of hours,", "tokens": [50364, 293, 4663, 337, 411, 2496, 13, 663, 311, 437, 7318, 307, 516, 281, 841, 411, 11, 3993, 2602, 295, 2496, 11, 50624], "temperature": 0.0, "avg_logprob": -0.06552122069186851, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0041986615397036076}, {"id": 342, "seek": 214072, "start": 2145.9199999999996, "end": 2151.68, "text": " it's going to be days and weeks. Um, let's see. I cannot wait when we can use deep dive tech", "tokens": [50624, 309, 311, 516, 281, 312, 1708, 293, 3259, 13, 3301, 11, 718, 311, 536, 13, 286, 2644, 1699, 562, 321, 393, 764, 2452, 9192, 7553, 50912], "temperature": 0.0, "avg_logprob": -0.06552122069186851, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0041986615397036076}, {"id": 343, "seek": 214072, "start": 2151.68, "end": 2155.8399999999997, "text": " and have virtual realities. Will it also be possible to take super intelligent animals like", "tokens": [50912, 293, 362, 6374, 27785, 13, 3099, 309, 611, 312, 1944, 281, 747, 1687, 13232, 4882, 411, 51120], "temperature": 0.0, "avg_logprob": -0.06552122069186851, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0041986615397036076}, {"id": 344, "seek": 214072, "start": 2155.8399999999997, "end": 2163.12, "text": " dolphins, dogs, parrots and crows and a deep dive and play with them. Um, I don't know that it would", "tokens": [51120, 44835, 11, 7197, 11, 971, 81, 1971, 293, 941, 1509, 293, 257, 2452, 9192, 293, 862, 365, 552, 13, 3301, 11, 286, 500, 380, 458, 300, 309, 576, 51484], "temperature": 0.0, "avg_logprob": -0.06552122069186851, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0041986615397036076}, {"id": 345, "seek": 214072, "start": 2163.12, "end": 2167.68, "text": " be possible, but I certainly think it probably wouldn't be ethical. Now that being said, you", "tokens": [51484, 312, 1944, 11, 457, 286, 3297, 519, 309, 1391, 2759, 380, 312, 18890, 13, 823, 300, 885, 848, 11, 291, 51712], "temperature": 0.0, "avg_logprob": -0.06552122069186851, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0041986615397036076}, {"id": 346, "seek": 216768, "start": 2167.68, "end": 2176.64, "text": " could have a virtual dolphin that is hyper realistic that you can play with. Um, fun thought,", "tokens": [50364, 727, 362, 257, 6374, 46759, 300, 307, 9848, 12465, 300, 291, 393, 862, 365, 13, 3301, 11, 1019, 1194, 11, 50812], "temperature": 0.0, "avg_logprob": -0.13640222793970352, "compression_ratio": 1.407960199004975, "no_speech_prob": 0.005384757649153471}, {"id": 347, "seek": 216768, "start": 2176.64, "end": 2183.8399999999997, "text": " will AGI want to see more stories from humans as a goal for itself? Uh, if, oh, so let, let me,", "tokens": [50812, 486, 316, 26252, 528, 281, 536, 544, 3676, 490, 6255, 382, 257, 3387, 337, 2564, 30, 4019, 11, 498, 11, 1954, 11, 370, 718, 11, 718, 385, 11, 51172], "temperature": 0.0, "avg_logprob": -0.13640222793970352, "compression_ratio": 1.407960199004975, "no_speech_prob": 0.005384757649153471}, {"id": 348, "seek": 216768, "start": 2183.8399999999997, "end": 2191.12, "text": " let me plug this. So Elon Musk went on of all fricking shows, Tucker Carlson and talked about", "tokens": [51172, 718, 385, 5452, 341, 13, 407, 28498, 26019, 1437, 322, 295, 439, 431, 10401, 3110, 11, 35581, 14256, 3015, 293, 2825, 466, 51536], "temperature": 0.0, "avg_logprob": -0.13640222793970352, "compression_ratio": 1.407960199004975, "no_speech_prob": 0.005384757649153471}, {"id": 349, "seek": 219112, "start": 2191.12, "end": 2198.64, "text": " truth GPT. So what he said was that truth GPT would be a maximum truth seeking AI. Okay, great.", "tokens": [50364, 3494, 26039, 51, 13, 407, 437, 415, 848, 390, 300, 3494, 26039, 51, 576, 312, 257, 6674, 3494, 11670, 7318, 13, 1033, 11, 869, 13, 50740], "temperature": 0.0, "avg_logprob": -0.10233566372893578, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.23930278420448303}, {"id": 350, "seek": 219112, "start": 2199.52, "end": 2205.2799999999997, "text": " But after listening to it in closer detail, I realized what he was talking about was the third", "tokens": [50784, 583, 934, 4764, 281, 309, 294, 4966, 2607, 11, 286, 5334, 437, 415, 390, 1417, 466, 390, 264, 2636, 51072], "temperature": 0.0, "avg_logprob": -0.10233566372893578, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.23930278420448303}, {"id": 351, "seek": 219112, "start": 2205.2799999999997, "end": 2211.04, "text": " here is to comparative was to increase its understanding or to maximize its own understanding.", "tokens": [51072, 510, 307, 281, 39292, 390, 281, 3488, 1080, 3701, 420, 281, 19874, 1080, 1065, 3701, 13, 51360], "temperature": 0.0, "avg_logprob": -0.10233566372893578, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.23930278420448303}, {"id": 352, "seek": 219112, "start": 2211.04, "end": 2217.6, "text": " So there's actually nothing that function on its own could lead to some really catastrophic", "tokens": [51360, 407, 456, 311, 767, 1825, 300, 2445, 322, 1080, 1065, 727, 1477, 281, 512, 534, 34915, 51688], "temperature": 0.0, "avg_logprob": -0.10233566372893578, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.23930278420448303}, {"id": 353, "seek": 221760, "start": 2218.08, "end": 2223.2799999999997, "text": " sources. But it's a step in the right direction. And I'm really glad that someone with as big of", "tokens": [50388, 7139, 13, 583, 309, 311, 257, 1823, 294, 264, 558, 3513, 13, 400, 286, 478, 534, 5404, 300, 1580, 365, 382, 955, 295, 50648], "temperature": 0.0, "avg_logprob": -0.07086649031009314, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.014501629397273064}, {"id": 354, "seek": 221760, "start": 2223.2799999999997, "end": 2227.36, "text": " a platform as Elon Musk is talking about maximize understanding or increase understanding.", "tokens": [50648, 257, 3663, 382, 28498, 26019, 307, 1417, 466, 19874, 3701, 420, 3488, 3701, 13, 50852], "temperature": 0.0, "avg_logprob": -0.07086649031009314, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.014501629397273064}, {"id": 355, "seek": 221760, "start": 2228.56, "end": 2233.92, "text": " So that being said, one of the things that he said in that interview was that as since humans", "tokens": [50912, 407, 300, 885, 848, 11, 472, 295, 264, 721, 300, 415, 848, 294, 300, 4049, 390, 300, 382, 1670, 6255, 51180], "temperature": 0.0, "avg_logprob": -0.07086649031009314, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.014501629397273064}, {"id": 356, "seek": 221760, "start": 2233.92, "end": 2238.24, "text": " are part of the universe and AI that is curious about the universe will intrinsically be curious", "tokens": [51180, 366, 644, 295, 264, 6445, 293, 7318, 300, 307, 6369, 466, 264, 6445, 486, 28621, 984, 312, 6369, 51396], "temperature": 0.0, "avg_logprob": -0.07086649031009314, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.014501629397273064}, {"id": 357, "seek": 221760, "start": 2238.24, "end": 2243.2, "text": " about us as well. Now that being said, humans sometimes do experiments on things that we're", "tokens": [51396, 466, 505, 382, 731, 13, 823, 300, 885, 848, 11, 6255, 2171, 360, 12050, 322, 721, 300, 321, 434, 51644], "temperature": 0.0, "avg_logprob": -0.07086649031009314, "compression_ratio": 1.7735849056603774, "no_speech_prob": 0.014501629397273064}, {"id": 358, "seek": 224320, "start": 2243.2, "end": 2247.3599999999997, "text": " curious about. So maybe that's not the best thing. And in my book, benevolent by design,", "tokens": [50364, 6369, 466, 13, 407, 1310, 300, 311, 406, 264, 1151, 551, 13, 400, 294, 452, 1446, 11, 48567, 317, 538, 1715, 11, 50572], "temperature": 0.0, "avg_logprob": -0.07919027930811832, "compression_ratio": 1.658450704225352, "no_speech_prob": 0.0320979505777359}, {"id": 359, "seek": 224320, "start": 2247.3599999999997, "end": 2253.2, "text": " I talk about why you don't why you must include suffering or something like suffering in the", "tokens": [50572, 286, 751, 466, 983, 291, 500, 380, 983, 291, 1633, 4090, 7755, 420, 746, 411, 7755, 294, 264, 50864], "temperature": 0.0, "avg_logprob": -0.07919027930811832, "compression_ratio": 1.658450704225352, "no_speech_prob": 0.0320979505777359}, {"id": 360, "seek": 224320, "start": 2253.2, "end": 2258.08, "text": " objective functions of an AI, because there's three dispositions that an AI can have towards", "tokens": [50864, 10024, 6828, 295, 364, 7318, 11, 570, 456, 311, 1045, 15885, 2451, 300, 364, 7318, 393, 362, 3030, 51108], "temperature": 0.0, "avg_logprob": -0.07919027930811832, "compression_ratio": 1.658450704225352, "no_speech_prob": 0.0320979505777359}, {"id": 361, "seek": 224320, "start": 2258.08, "end": 2264.3199999999997, "text": " suffering. One is it can ignore it altogether. So if Elon Musk gets his current idea, which", "tokens": [51108, 7755, 13, 1485, 307, 309, 393, 11200, 309, 19051, 13, 407, 498, 28498, 26019, 2170, 702, 2190, 1558, 11, 597, 51420], "temperature": 0.0, "avg_logprob": -0.07919027930811832, "compression_ratio": 1.658450704225352, "no_speech_prob": 0.0320979505777359}, {"id": 362, "seek": 224320, "start": 2264.3199999999997, "end": 2269.3599999999997, "text": " is just maximize for truth, that is an agent that ignores suffering, it doesn't care one way or another.", "tokens": [51420, 307, 445, 19874, 337, 3494, 11, 300, 307, 364, 9461, 300, 5335, 2706, 7755, 11, 309, 1177, 380, 1127, 472, 636, 420, 1071, 13, 51672], "temperature": 0.0, "avg_logprob": -0.07919027930811832, "compression_ratio": 1.658450704225352, "no_speech_prob": 0.0320979505777359}, {"id": 363, "seek": 226936, "start": 2270.32, "end": 2275.76, "text": " Then you can have one that increases suffering that deliberately increases suffering and we", "tokens": [50412, 1396, 291, 393, 362, 472, 300, 8637, 7755, 300, 23506, 8637, 7755, 293, 321, 50684], "temperature": 0.0, "avg_logprob": -0.07397980409509995, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0023230314254760742}, {"id": 364, "seek": 226936, "start": 2275.76, "end": 2281.76, "text": " absolutely don't want that. So that leaves by process of elimination, you want an AI that", "tokens": [50684, 3122, 500, 380, 528, 300, 13, 407, 300, 5510, 538, 1399, 295, 29224, 11, 291, 528, 364, 7318, 300, 50984], "temperature": 0.0, "avg_logprob": -0.07397980409509995, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0023230314254760742}, {"id": 365, "seek": 226936, "start": 2281.76, "end": 2287.44, "text": " reduces suffering. It's really that simple. Now that being said, I do agree with Elon that", "tokens": [50984, 18081, 7755, 13, 467, 311, 534, 300, 2199, 13, 823, 300, 885, 848, 11, 286, 360, 3986, 365, 28498, 300, 51268], "temperature": 0.0, "avg_logprob": -0.07397980409509995, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0023230314254760742}, {"id": 366, "seek": 226936, "start": 2288.1600000000003, "end": 2293.84, "text": " creating a curious agent is a good idea because it'll want to know about us. And if you exterminate", "tokens": [51304, 4084, 257, 6369, 9461, 307, 257, 665, 1558, 570, 309, 603, 528, 281, 458, 466, 505, 13, 400, 498, 291, 48628, 473, 51588], "temperature": 0.0, "avg_logprob": -0.07397980409509995, "compression_ratio": 1.6387665198237886, "no_speech_prob": 0.0023230314254760742}, {"id": 367, "seek": 229384, "start": 2293.84, "end": 2300.2400000000002, "text": " humans, you have a hard time learning about them. So let's see, let me check on Patreon real quick.", "tokens": [50364, 6255, 11, 291, 362, 257, 1152, 565, 2539, 466, 552, 13, 407, 718, 311, 536, 11, 718, 385, 1520, 322, 15692, 957, 1702, 13, 50684], "temperature": 0.0, "avg_logprob": -0.11781254620619223, "compression_ratio": 1.3485714285714285, "no_speech_prob": 0.08507199585437775}, {"id": 368, "seek": 229384, "start": 2304.08, "end": 2307.52, "text": " Do you think that Elon Musk wants to be the Rupert Murdoch of AI?", "tokens": [50876, 1144, 291, 519, 300, 28498, 26019, 2738, 281, 312, 264, 497, 12879, 83, 9373, 2595, 339, 295, 7318, 30, 51048], "temperature": 0.0, "avg_logprob": -0.11781254620619223, "compression_ratio": 1.3485714285714285, "no_speech_prob": 0.08507199585437775}, {"id": 369, "seek": 229384, "start": 2309.76, "end": 2313.36, "text": " Okay, I don't like that question. Lance, why you got to do this to me?", "tokens": [51160, 1033, 11, 286, 500, 380, 411, 300, 1168, 13, 40493, 11, 983, 291, 658, 281, 360, 341, 281, 385, 30, 51340], "temperature": 0.0, "avg_logprob": -0.11781254620619223, "compression_ratio": 1.3485714285714285, "no_speech_prob": 0.08507199585437775}, {"id": 370, "seek": 231336, "start": 2314.32, "end": 2323.84, "text": " All right, Zadre, I'm not sure how to pronounce or Hadre. Okay. How do you envision the role of AI", "tokens": [50412, 1057, 558, 11, 1176, 345, 265, 11, 286, 478, 406, 988, 577, 281, 19567, 420, 12298, 265, 13, 1033, 13, 1012, 360, 291, 24739, 264, 3090, 295, 7318, 50888], "temperature": 0.0, "avg_logprob": -0.21968185767698822, "compression_ratio": 1.5, "no_speech_prob": 0.018829168751835823}, {"id": 371, "seek": 231336, "start": 2323.84, "end": 2328.48, "text": " in healthcare, particularly in areas like diagnostics and personalized medicine? What are", "tokens": [50888, 294, 8884, 11, 4098, 294, 3179, 411, 43215, 1167, 293, 28415, 7195, 30, 708, 366, 51120], "temperature": 0.0, "avg_logprob": -0.21968185767698822, "compression_ratio": 1.5, "no_speech_prob": 0.018829168751835823}, {"id": 372, "seek": 231336, "start": 2328.48, "end": 2333.1200000000003, "text": " some of the challenges and opportunities in this field? Well, so there was that stand for doctor", "tokens": [51120, 512, 295, 264, 4759, 293, 4786, 294, 341, 2519, 30, 1042, 11, 370, 456, 390, 300, 1463, 337, 4631, 51352], "temperature": 0.0, "avg_logprob": -0.21968185767698822, "compression_ratio": 1.5, "no_speech_prob": 0.018829168751835823}, {"id": 373, "seek": 231336, "start": 2333.1200000000003, "end": 2338.4, "text": " who who already went on record saying that chat GBT for has better clinical judgment than", "tokens": [51352, 567, 567, 1217, 1437, 322, 2136, 1566, 300, 5081, 26809, 51, 337, 575, 1101, 9115, 12216, 813, 51616], "temperature": 0.0, "avg_logprob": -0.21968185767698822, "compression_ratio": 1.5, "no_speech_prob": 0.018829168751835823}, {"id": 374, "seek": 233840, "start": 2338.7200000000003, "end": 2348.2400000000002, "text": " many doctors. So that is just a start, right? That's that's like starting point day one.", "tokens": [50380, 867, 8778, 13, 407, 300, 307, 445, 257, 722, 11, 558, 30, 663, 311, 300, 311, 411, 2891, 935, 786, 472, 13, 50856], "temperature": 0.0, "avg_logprob": -0.14956968943277996, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.031136903911828995}, {"id": 375, "seek": 233840, "start": 2348.2400000000002, "end": 2354.4, "text": " What happens when chat GPT five, six and seven come out that have better clinical judgment than", "tokens": [50856, 708, 2314, 562, 5081, 26039, 51, 1732, 11, 2309, 293, 3407, 808, 484, 300, 362, 1101, 9115, 12216, 813, 51164], "temperature": 0.0, "avg_logprob": -0.14956968943277996, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.031136903911828995}, {"id": 376, "seek": 233840, "start": 2354.4, "end": 2361.28, "text": " 99.999% of all doctors on the planet, right? It doesn't make sense to go to a human doctor anymore.", "tokens": [51164, 11803, 13, 49017, 4, 295, 439, 8778, 322, 264, 5054, 11, 558, 30, 467, 1177, 380, 652, 2020, 281, 352, 281, 257, 1952, 4631, 3602, 13, 51508], "temperature": 0.0, "avg_logprob": -0.14956968943277996, "compression_ratio": 1.4489795918367347, "no_speech_prob": 0.031136903911828995}, {"id": 377, "seek": 236128, "start": 2362.0, "end": 2369.0400000000004, "text": " Right? If the if the machine that costs $20 a month to run is better than all human doctors,", "tokens": [50400, 1779, 30, 759, 264, 498, 264, 3479, 300, 5497, 1848, 2009, 257, 1618, 281, 1190, 307, 1101, 813, 439, 1952, 8778, 11, 50752], "temperature": 0.0, "avg_logprob": -0.12383475202195188, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.06953322887420654}, {"id": 378, "seek": 236128, "start": 2369.0400000000004, "end": 2375.6800000000003, "text": " why go to a human doctor? Now that being said, there's probably going to be approvals and downsides", "tokens": [50752, 983, 352, 281, 257, 1952, 4631, 30, 823, 300, 885, 848, 11, 456, 311, 1391, 516, 281, 312, 2075, 19778, 293, 21554, 1875, 51084], "temperature": 0.0, "avg_logprob": -0.12383475202195188, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.06953322887420654}, {"id": 379, "seek": 236128, "start": 2375.6800000000003, "end": 2380.4, "text": " and gaps. And then there's still also the interface with the patient. And you have to have like", "tokens": [51084, 293, 15031, 13, 400, 550, 456, 311, 920, 611, 264, 9226, 365, 264, 4537, 13, 400, 291, 362, 281, 362, 411, 51320], "temperature": 0.0, "avg_logprob": -0.12383475202195188, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.06953322887420654}, {"id": 380, "seek": 236128, "start": 2380.4, "end": 2387.6800000000003, "text": " phlebotomists and nurses and and and physicians assistants to administer things, to administer", "tokens": [51320, 903, 306, 18870, 298, 1751, 293, 17446, 293, 293, 293, 21966, 34949, 281, 22096, 721, 11, 281, 22096, 51684], "temperature": 0.0, "avg_logprob": -0.12383475202195188, "compression_ratio": 1.6508620689655173, "no_speech_prob": 0.06953322887420654}, {"id": 381, "seek": 238768, "start": 2387.68, "end": 2392.56, "text": " tests, you still need the you still need a lot of humans in there to to be the interface between", "tokens": [50364, 6921, 11, 291, 920, 643, 264, 291, 920, 643, 257, 688, 295, 6255, 294, 456, 281, 281, 312, 264, 9226, 1296, 50608], "temperature": 0.0, "avg_logprob": -0.07461830801215054, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.0053847492672502995}, {"id": 382, "seek": 238768, "start": 2392.56, "end": 2398.56, "text": " the human and the machine. But that being said, I think that we will get to a point very quickly", "tokens": [50608, 264, 1952, 293, 264, 3479, 13, 583, 300, 885, 848, 11, 286, 519, 300, 321, 486, 483, 281, 257, 935, 588, 2661, 50908], "temperature": 0.0, "avg_logprob": -0.07461830801215054, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.0053847492672502995}, {"id": 383, "seek": 238768, "start": 2398.56, "end": 2405.2, "text": " where the quality of care and the speed of care and the efficiency of care are going to go through", "tokens": [50908, 689, 264, 3125, 295, 1127, 293, 264, 3073, 295, 1127, 293, 264, 10493, 295, 1127, 366, 516, 281, 352, 807, 51240], "temperature": 0.0, "avg_logprob": -0.07461830801215054, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.0053847492672502995}, {"id": 384, "seek": 238768, "start": 2405.2, "end": 2411.6, "text": " the roof real fast. That's what I'm hoping at least. Alright, jumping back over to cognitive AI", "tokens": [51240, 264, 8418, 957, 2370, 13, 663, 311, 437, 286, 478, 7159, 412, 1935, 13, 2798, 11, 11233, 646, 670, 281, 15605, 7318, 51560], "temperature": 0.0, "avg_logprob": -0.07461830801215054, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.0053847492672502995}, {"id": 385, "seek": 238768, "start": 2411.6, "end": 2416.3199999999997, "text": " lab. Oh, we got some new questions. It looks like this was the same question. Sorry, I missed you", "tokens": [51560, 2715, 13, 876, 11, 321, 658, 512, 777, 1651, 13, 467, 1542, 411, 341, 390, 264, 912, 1168, 13, 4919, 11, 286, 6721, 291, 51796], "temperature": 0.0, "avg_logprob": -0.07461830801215054, "compression_ratio": 1.7052631578947368, "no_speech_prob": 0.0053847492672502995}, {"id": 386, "seek": 241632, "start": 2416.32, "end": 2425.04, "text": " over there. Where are we? Alright, there's the deep dive. Do you think there is any major leap", "tokens": [50364, 670, 456, 13, 2305, 366, 321, 30, 2798, 11, 456, 311, 264, 2452, 9192, 13, 1144, 291, 519, 456, 307, 604, 2563, 19438, 50800], "temperature": 0.0, "avg_logprob": -0.09783813390838966, "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.007345340680330992}, {"id": 387, "seek": 241632, "start": 2425.04, "end": 2430.32, "text": " missing to make truly practical autonomous agents? So for example, one who runs a part of your business", "tokens": [50800, 5361, 281, 652, 4908, 8496, 23797, 12554, 30, 407, 337, 1365, 11, 472, 567, 6676, 257, 644, 295, 428, 1606, 51064], "temperature": 0.0, "avg_logprob": -0.09783813390838966, "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.007345340680330992}, {"id": 388, "seek": 241632, "start": 2430.32, "end": 2436.48, "text": " serves as general assistant, etc, etc. No, there's there's our there are countless hundreds,", "tokens": [51064, 13451, 382, 2674, 10994, 11, 5183, 11, 5183, 13, 883, 11, 456, 311, 456, 311, 527, 456, 366, 19223, 6779, 11, 51372], "temperature": 0.0, "avg_logprob": -0.09783813390838966, "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.007345340680330992}, {"id": 389, "seek": 241632, "start": 2437.28, "end": 2442.32, "text": " if not thousands or even millions of people working on semi autonomous and autonomous corporate", "tokens": [51412, 498, 406, 5383, 420, 754, 6803, 295, 561, 1364, 322, 12909, 23797, 293, 23797, 10896, 51664], "temperature": 0.0, "avg_logprob": -0.09783813390838966, "compression_ratio": 1.6260504201680672, "no_speech_prob": 0.007345340680330992}, {"id": 390, "seek": 244232, "start": 2442.32, "end": 2450.7200000000003, "text": " applications today, right now. That being said, there's there's no there's no breakthroughs that", "tokens": [50364, 5821, 965, 11, 558, 586, 13, 663, 885, 848, 11, 456, 311, 456, 311, 572, 456, 311, 572, 22397, 82, 300, 50784], "temperature": 0.0, "avg_logprob": -0.15338753639383518, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.014955082908272743}, {"id": 391, "seek": 244232, "start": 2450.7200000000003, "end": 2455.28, "text": " are needed, but there are still problems to be solved. So that's why like RIMO, you know, the", "tokens": [50784, 366, 2978, 11, 457, 456, 366, 920, 2740, 281, 312, 13041, 13, 407, 300, 311, 983, 411, 497, 6324, 46, 11, 291, 458, 11, 264, 51012], "temperature": 0.0, "avg_logprob": -0.15338753639383518, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.014955082908272743}, {"id": 392, "seek": 244232, "start": 2455.28, "end": 2461.6000000000004, "text": " memory systems, and then standard practices like, you know, I wrote in Symphony of Thought and in", "tokens": [51012, 4675, 3652, 11, 293, 550, 3832, 7525, 411, 11, 291, 458, 11, 286, 4114, 294, 46891, 295, 23058, 293, 294, 51328], "temperature": 0.0, "avg_logprob": -0.15338753639383518, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.014955082908272743}, {"id": 393, "seek": 244232, "start": 2461.6000000000004, "end": 2467.76, "text": " other places, my atom framework is once something is autonomous or semi autonomous, how does it", "tokens": [51328, 661, 3190, 11, 452, 12018, 8388, 307, 1564, 746, 307, 23797, 420, 12909, 23797, 11, 577, 775, 309, 51636], "temperature": 0.0, "avg_logprob": -0.15338753639383518, "compression_ratio": 1.620253164556962, "no_speech_prob": 0.014955082908272743}, {"id": 394, "seek": 246776, "start": 2467.76, "end": 2473.6000000000004, "text": " keep track of product or projects and tasks? And that's something that people are working on.", "tokens": [50364, 1066, 2837, 295, 1674, 420, 4455, 293, 9608, 30, 400, 300, 311, 746, 300, 561, 366, 1364, 322, 13, 50656], "temperature": 0.0, "avg_logprob": -0.09247892279373972, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.07262127101421356}, {"id": 395, "seek": 246776, "start": 2473.6000000000004, "end": 2479.76, "text": " People are working on it real fast. That's coming really quick. Let's see, Nathan says,", "tokens": [50656, 3432, 366, 1364, 322, 309, 957, 2370, 13, 663, 311, 1348, 534, 1702, 13, 961, 311, 536, 11, 20634, 1619, 11, 50964], "temperature": 0.0, "avg_logprob": -0.09247892279373972, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.07262127101421356}, {"id": 396, "seek": 246776, "start": 2479.76, "end": 2484.32, "text": " I've been taking screenshots of when friends and family make fun of my hot takes. So I have the", "tokens": [50964, 286, 600, 668, 1940, 40661, 295, 562, 1855, 293, 1605, 652, 1019, 295, 452, 2368, 2516, 13, 407, 286, 362, 264, 51192], "temperature": 0.0, "avg_logprob": -0.09247892279373972, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.07262127101421356}, {"id": 397, "seek": 246776, "start": 2484.32, "end": 2493.28, "text": " receipts. I would say that I'm above being that petty. But yeah, thank you for keeping receipts.", "tokens": [51192, 2268, 48908, 13, 286, 576, 584, 300, 286, 478, 3673, 885, 300, 39334, 13, 583, 1338, 11, 1309, 291, 337, 5145, 2268, 48908, 13, 51640], "temperature": 0.0, "avg_logprob": -0.09247892279373972, "compression_ratio": 1.6051502145922747, "no_speech_prob": 0.07262127101421356}, {"id": 398, "seek": 249328, "start": 2494.0800000000004, "end": 2498.96, "text": " Um, let's see, maybe directors will just design their perfect actors for each role.", "tokens": [50404, 3301, 11, 718, 311, 536, 11, 1310, 17307, 486, 445, 1715, 641, 2176, 10037, 337, 1184, 3090, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13030202529009652, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.003824387677013874}, {"id": 399, "seek": 249328, "start": 2500.2400000000002, "end": 2504.32, "text": " So one thing that's going to happen is actually, so this is going back to like,", "tokens": [50712, 407, 472, 551, 300, 311, 516, 281, 1051, 307, 767, 11, 370, 341, 307, 516, 646, 281, 411, 11, 50916], "temperature": 0.0, "avg_logprob": -0.13030202529009652, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.003824387677013874}, {"id": 400, "seek": 249328, "start": 2504.88, "end": 2510.0, "text": " entertainment. I think that the next big generation of entertainment is actually going to be", "tokens": [50944, 12393, 13, 286, 519, 300, 264, 958, 955, 5125, 295, 12393, 307, 767, 516, 281, 312, 51200], "temperature": 0.0, "avg_logprob": -0.13030202529009652, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.003824387677013874}, {"id": 401, "seek": 249328, "start": 2510.7200000000003, "end": 2519.44, "text": " holodeck style VR stories, where nothing is scripted, where instead it's like, you know,", "tokens": [51236, 4091, 1429, 547, 3758, 13722, 3676, 11, 689, 1825, 307, 5755, 292, 11, 689, 2602, 309, 311, 411, 11, 291, 458, 11, 51672], "temperature": 0.0, "avg_logprob": -0.13030202529009652, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.003824387677013874}, {"id": 402, "seek": 251944, "start": 2519.44, "end": 2523.92, "text": " basically you design a holodeck program the same way that they do in Star Trek, which is like,", "tokens": [50364, 1936, 291, 1715, 257, 4091, 1429, 547, 1461, 264, 912, 636, 300, 436, 360, 294, 5705, 25845, 11, 597, 307, 411, 11, 50588], "temperature": 0.0, "avg_logprob": -0.0932182238652156, "compression_ratio": 1.757462686567164, "no_speech_prob": 0.10373019427061081}, {"id": 403, "seek": 251944, "start": 2523.92, "end": 2530.48, "text": " computer, give me, you know, a Mad Max style story. But instead of, you know, post apocalyptic,", "tokens": [50588, 3820, 11, 976, 385, 11, 291, 458, 11, 257, 5326, 7402, 3758, 1657, 13, 583, 2602, 295, 11, 291, 458, 11, 2183, 1882, 47407, 11, 50916], "temperature": 0.0, "avg_logprob": -0.0932182238652156, "compression_ratio": 1.757462686567164, "no_speech_prob": 0.10373019427061081}, {"id": 404, "seek": 251944, "start": 2530.48, "end": 2536.48, "text": " it's actually like space Western. So like, give me a mashup of firefly and this and,", "tokens": [50916, 309, 311, 767, 411, 1901, 8724, 13, 407, 411, 11, 976, 385, 257, 31344, 1010, 295, 2610, 14061, 293, 341, 293, 11, 51216], "temperature": 0.0, "avg_logprob": -0.0932182238652156, "compression_ratio": 1.757462686567164, "no_speech_prob": 0.10373019427061081}, {"id": 405, "seek": 251944, "start": 2536.48, "end": 2542.48, "text": " you know, make the protagonist, you know, or the, you know, I'm the protagonist and give me a team", "tokens": [51216, 291, 458, 11, 652, 264, 24506, 11, 291, 458, 11, 420, 264, 11, 291, 458, 11, 286, 478, 264, 24506, 293, 976, 385, 257, 1469, 51516], "temperature": 0.0, "avg_logprob": -0.0932182238652156, "compression_ratio": 1.757462686567164, "no_speech_prob": 0.10373019427061081}, {"id": 406, "seek": 251944, "start": 2542.48, "end": 2547.84, "text": " of like, you know, give me the sexy sidekick and the cyborg friend and whatever. And then just a", "tokens": [51516, 295, 411, 11, 291, 458, 11, 976, 385, 264, 13701, 1252, 42427, 293, 264, 3185, 33151, 1277, 293, 2035, 13, 400, 550, 445, 257, 51784], "temperature": 0.0, "avg_logprob": -0.0932182238652156, "compression_ratio": 1.757462686567164, "no_speech_prob": 0.10373019427061081}, {"id": 407, "seek": 254784, "start": 2547.84, "end": 2552.32, "text": " way it goes, right? Because you could plug what I just literally you could plug what I just said", "tokens": [50364, 636, 309, 1709, 11, 558, 30, 1436, 291, 727, 5452, 437, 286, 445, 3736, 291, 727, 5452, 437, 286, 445, 848, 50588], "temperature": 0.0, "avg_logprob": -0.09101426100530544, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.018544312566518784}, {"id": 408, "seek": 254784, "start": 2552.32, "end": 2558.32, "text": " into chat GPT and it can tell you a story. And I think that I think that VR makes the most sense", "tokens": [50588, 666, 5081, 26039, 51, 293, 309, 393, 980, 291, 257, 1657, 13, 400, 286, 519, 300, 286, 519, 300, 13722, 1669, 264, 881, 2020, 50888], "temperature": 0.0, "avg_logprob": -0.09101426100530544, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.018544312566518784}, {"id": 409, "seek": 254784, "start": 2558.32, "end": 2565.6000000000004, "text": " for the most immersive aspects of that. And, and then I think that because here's the other thing", "tokens": [50888, 337, 264, 881, 35409, 7270, 295, 300, 13, 400, 11, 293, 550, 286, 519, 300, 570, 510, 311, 264, 661, 551, 51252], "temperature": 0.0, "avg_logprob": -0.09101426100530544, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.018544312566518784}, {"id": 410, "seek": 254784, "start": 2565.6000000000004, "end": 2571.28, "text": " is that technology changes the way that we consume art, but it doesn't really change art itself,", "tokens": [51252, 307, 300, 2899, 2962, 264, 636, 300, 321, 14732, 1523, 11, 457, 309, 1177, 380, 534, 1319, 1523, 2564, 11, 51536], "temperature": 0.0, "avg_logprob": -0.09101426100530544, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.018544312566518784}, {"id": 411, "seek": 254784, "start": 2571.28, "end": 2577.36, "text": " right? There are still stage actors, right, even though there's film and TV. There are still", "tokens": [51536, 558, 30, 821, 366, 920, 3233, 10037, 11, 558, 11, 754, 1673, 456, 311, 2007, 293, 3558, 13, 821, 366, 920, 51840], "temperature": 0.0, "avg_logprob": -0.09101426100530544, "compression_ratio": 1.8082706766917294, "no_speech_prob": 0.018544312566518784}, {"id": 412, "seek": 257736, "start": 2577.36, "end": 2582.4, "text": " symphony orchestras, even though I can just, you know, bring up Spotify and listen to the", "tokens": [50364, 6697, 28616, 14161, 3906, 11, 754, 1673, 286, 393, 445, 11, 291, 458, 11, 1565, 493, 29036, 293, 2140, 281, 264, 50616], "temperature": 0.0, "avg_logprob": -0.1064953723196256, "compression_ratio": 1.6984732824427482, "no_speech_prob": 0.0017544823931530118}, {"id": 413, "seek": 257736, "start": 2582.4, "end": 2588.1600000000003, "text": " same recording that was recorded back in the 80s, you know, the London Symphony Orchestra, right?", "tokens": [50616, 912, 6613, 300, 390, 8287, 646, 294, 264, 4688, 82, 11, 291, 458, 11, 264, 7042, 46891, 46692, 11, 558, 30, 50904], "temperature": 0.0, "avg_logprob": -0.1064953723196256, "compression_ratio": 1.6984732824427482, "no_speech_prob": 0.0017544823931530118}, {"id": 414, "seek": 257736, "start": 2588.1600000000003, "end": 2591.52, "text": " So a lot of things change, but also a lot of things stay the same.", "tokens": [50904, 407, 257, 688, 295, 721, 1319, 11, 457, 611, 257, 688, 295, 721, 1754, 264, 912, 13, 51072], "temperature": 0.0, "avg_logprob": -0.1064953723196256, "compression_ratio": 1.6984732824427482, "no_speech_prob": 0.0017544823931530118}, {"id": 415, "seek": 257736, "start": 2594.1600000000003, "end": 2597.6800000000003, "text": " Let's see, you've talked a lot about the heuristic imperatives being highly engineered,", "tokens": [51204, 961, 311, 536, 11, 291, 600, 2825, 257, 688, 466, 264, 415, 374, 3142, 10100, 4884, 885, 5405, 38648, 11, 51380], "temperature": 0.0, "avg_logprob": -0.1064953723196256, "compression_ratio": 1.6984732824427482, "no_speech_prob": 0.0017544823931530118}, {"id": 416, "seek": 257736, "start": 2597.6800000000003, "end": 2607.1200000000003, "text": " but what about the order of the imperatives? They are not ordered. So it is a, it is a multi-objective", "tokens": [51380, 457, 437, 466, 264, 1668, 295, 264, 10100, 4884, 30, 814, 366, 406, 8866, 13, 407, 309, 307, 257, 11, 309, 307, 257, 4825, 12, 41070, 488, 51852], "temperature": 0.0, "avg_logprob": -0.1064953723196256, "compression_ratio": 1.6984732824427482, "no_speech_prob": 0.0017544823931530118}, {"id": 417, "seek": 260712, "start": 2607.2, "end": 2615.68, "text": " optimization problem, meaning that if any action or decision is, is totally unbalanced,", "tokens": [50368, 19618, 1154, 11, 3620, 300, 498, 604, 3069, 420, 3537, 307, 11, 307, 3879, 517, 40251, 11, 50792], "temperature": 0.0, "avg_logprob": -0.04428690877454034, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.0005883559351786971}, {"id": 418, "seek": 260712, "start": 2615.68, "end": 2621.92, "text": " then that one action has to satisfy all three. And also the heuristic imperatives are kind of", "tokens": [50792, 550, 300, 472, 3069, 575, 281, 19319, 439, 1045, 13, 400, 611, 264, 415, 374, 3142, 10100, 4884, 366, 733, 295, 51104], "temperature": 0.0, "avg_logprob": -0.04428690877454034, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.0005883559351786971}, {"id": 419, "seek": 260712, "start": 2621.92, "end": 2627.68, "text": " like guidelines about how to design the rest of the architecture. And so what I mean by that is", "tokens": [51104, 411, 12470, 466, 577, 281, 1715, 264, 1472, 295, 264, 9482, 13, 400, 370, 437, 286, 914, 538, 300, 307, 51392], "temperature": 0.0, "avg_logprob": -0.04428690877454034, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.0005883559351786971}, {"id": 420, "seek": 260712, "start": 2627.68, "end": 2632.96, "text": " when you're designing a task orchestration framework, you can use the heuristic imperatives", "tokens": [51392, 562, 291, 434, 14685, 257, 5633, 14161, 2405, 8388, 11, 291, 393, 764, 264, 415, 374, 3142, 10100, 4884, 51656], "temperature": 0.0, "avg_logprob": -0.04428690877454034, "compression_ratio": 1.6772727272727272, "no_speech_prob": 0.0005883559351786971}, {"id": 421, "seek": 263296, "start": 2632.96, "end": 2640.2400000000002, "text": " to prioritize tasks or design tasks. Then for, for a blockchain or a DAO type thing,", "tokens": [50364, 281, 25164, 9608, 420, 1715, 9608, 13, 1396, 337, 11, 337, 257, 17176, 420, 257, 9578, 46, 2010, 551, 11, 50728], "temperature": 0.0, "avg_logprob": -0.0713155580603558, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0014550104970112443}, {"id": 422, "seek": 263296, "start": 2640.2400000000002, "end": 2645.44, "text": " you can use the heuristic imperatives as a consensus mechanism. So the heuristic imperatives", "tokens": [50728, 291, 393, 764, 264, 415, 374, 3142, 10100, 4884, 382, 257, 19115, 7513, 13, 407, 264, 415, 374, 3142, 10100, 4884, 50988], "temperature": 0.0, "avg_logprob": -0.0713155580603558, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0014550104970112443}, {"id": 423, "seek": 263296, "start": 2645.44, "end": 2650.4, "text": " are not like, here is one mathematical proof that you need to implement. It's more like,", "tokens": [50988, 366, 406, 411, 11, 510, 307, 472, 18894, 8177, 300, 291, 643, 281, 4445, 13, 467, 311, 544, 411, 11, 51236], "temperature": 0.0, "avg_logprob": -0.0713155580603558, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0014550104970112443}, {"id": 424, "seek": 263296, "start": 2650.4, "end": 2655.6, "text": " here is a general best practice implemented in as many ways as you can, and we should be okay.", "tokens": [51236, 510, 307, 257, 2674, 1151, 3124, 12270, 294, 382, 867, 2098, 382, 291, 393, 11, 293, 321, 820, 312, 1392, 13, 51496], "temperature": 0.0, "avg_logprob": -0.0713155580603558, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0014550104970112443}, {"id": 425, "seek": 263296, "start": 2656.96, "end": 2662.0, "text": " It's not sequential. It's not, it's not an order of operations. Good question, though.", "tokens": [51564, 467, 311, 406, 42881, 13, 467, 311, 406, 11, 309, 311, 406, 364, 1668, 295, 7705, 13, 2205, 1168, 11, 1673, 13, 51816], "temperature": 0.0, "avg_logprob": -0.0713155580603558, "compression_ratio": 1.7164750957854407, "no_speech_prob": 0.0014550104970112443}, {"id": 426, "seek": 266296, "start": 2663.84, "end": 2669.76, "text": " Your thoughts on a UBI once jobs are severely affected? Yeah, I think that, I think that it's", "tokens": [50408, 2260, 4598, 322, 257, 624, 11291, 1564, 4782, 366, 26271, 8028, 30, 865, 11, 286, 519, 300, 11, 286, 519, 300, 309, 311, 50704], "temperature": 0.0, "avg_logprob": -0.11124032797272672, "compression_ratio": 1.516, "no_speech_prob": 0.0035934289917349815}, {"id": 427, "seek": 266296, "start": 2669.76, "end": 2674.56, "text": " going to be necessary. I'm going to say, I'm going to put a pause on that because I've got my,", "tokens": [50704, 516, 281, 312, 4818, 13, 286, 478, 516, 281, 584, 11, 286, 478, 516, 281, 829, 257, 10465, 322, 300, 570, 286, 600, 658, 452, 11, 50944], "temperature": 0.0, "avg_logprob": -0.11124032797272672, "compression_ratio": 1.516, "no_speech_prob": 0.0035934289917349815}, {"id": 428, "seek": 266296, "start": 2674.56, "end": 2680.88, "text": " my blockchain and DAO video coming up that will delve into that solution a lot more closely.", "tokens": [50944, 452, 17176, 293, 9578, 46, 960, 1348, 493, 300, 486, 43098, 666, 300, 3827, 257, 688, 544, 8185, 13, 51260], "temperature": 0.0, "avg_logprob": -0.11124032797272672, "compression_ratio": 1.516, "no_speech_prob": 0.0035934289917349815}, {"id": 429, "seek": 266296, "start": 2681.6, "end": 2688.8, "text": " Check over on Patreon for a second. The Nazis. You know who else wanted to maximize understanding", "tokens": [51296, 6881, 670, 322, 15692, 337, 257, 1150, 13, 440, 29812, 13, 509, 458, 567, 1646, 1415, 281, 19874, 3701, 51656], "temperature": 0.0, "avg_logprob": -0.11124032797272672, "compression_ratio": 1.516, "no_speech_prob": 0.0035934289917349815}, {"id": 430, "seek": 268880, "start": 2688.8, "end": 2694.5600000000004, "text": " the Nazis? Yeah. And so this is, that's actually a fair point is that, and this was explored in,", "tokens": [50364, 264, 29812, 30, 865, 13, 400, 370, 341, 307, 11, 300, 311, 767, 257, 3143, 935, 307, 300, 11, 293, 341, 390, 24016, 294, 11, 50652], "temperature": 0.0, "avg_logprob": -0.07006321040862197, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.04671615734696388}, {"id": 431, "seek": 268880, "start": 2694.5600000000004, "end": 2700.6400000000003, "text": " in quite a few Star Trek episodes as well. If you are just clinically curious, if you have", "tokens": [50652, 294, 1596, 257, 1326, 5705, 25845, 9313, 382, 731, 13, 759, 291, 366, 445, 48392, 6369, 11, 498, 291, 362, 50956], "temperature": 0.0, "avg_logprob": -0.07006321040862197, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.04671615734696388}, {"id": 432, "seek": 268880, "start": 2700.6400000000003, "end": 2705.6000000000004, "text": " just nothing but raw scientific curiosity and no other principles or morals, that's pretty", "tokens": [50956, 445, 1825, 457, 8936, 8134, 18769, 293, 572, 661, 9156, 420, 46849, 11, 300, 311, 1238, 51204], "temperature": 0.0, "avg_logprob": -0.07006321040862197, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.04671615734696388}, {"id": 433, "seek": 268880, "start": 2705.6000000000004, "end": 2711.2000000000003, "text": " dangerous and destructive. Okay, so moving on. What are your thoughts on memory systems as a", "tokens": [51204, 5795, 293, 26960, 13, 1033, 11, 370, 2684, 322, 13, 708, 366, 428, 4598, 322, 4675, 3652, 382, 257, 51484], "temperature": 0.0, "avg_logprob": -0.07006321040862197, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.04671615734696388}, {"id": 434, "seek": 268880, "start": 2711.2000000000003, "end": 2715.28, "text": " whole? Do you think different use cases will require different memory systems? And where does", "tokens": [51484, 1379, 30, 1144, 291, 519, 819, 764, 3331, 486, 3651, 819, 4675, 3652, 30, 400, 689, 775, 51688], "temperature": 0.0, "avg_logprob": -0.07006321040862197, "compression_ratio": 1.6089965397923875, "no_speech_prob": 0.04671615734696388}, {"id": 435, "seek": 271528, "start": 2715.28, "end": 2720.6400000000003, "text": " Rimo and Adam fit into everything? Have you seen this one? Last week, generative agents. Yeah, I", "tokens": [50364, 497, 6934, 293, 7938, 3318, 666, 1203, 30, 3560, 291, 1612, 341, 472, 30, 5264, 1243, 11, 1337, 1166, 12554, 13, 865, 11, 286, 50632], "temperature": 0.0, "avg_logprob": -0.14346264347885596, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.005060091149061918}, {"id": 436, "seek": 271528, "start": 2720.6400000000003, "end": 2726.2400000000002, "text": " saw, I saw the generative agents. I don't think that reflection, so they, they break up reflection", "tokens": [50632, 1866, 11, 286, 1866, 264, 1337, 1166, 12554, 13, 286, 500, 380, 519, 300, 12914, 11, 370, 436, 11, 436, 1821, 493, 12914, 50912], "temperature": 0.0, "avg_logprob": -0.14346264347885596, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.005060091149061918}, {"id": 437, "seek": 271528, "start": 2726.2400000000002, "end": 2731.0400000000004, "text": " and a few other criteria. I don't think that that's necessary. I think that, I think that my approach", "tokens": [50912, 293, 257, 1326, 661, 11101, 13, 286, 500, 380, 519, 300, 300, 311, 4818, 13, 286, 519, 300, 11, 286, 519, 300, 452, 3109, 51152], "temperature": 0.0, "avg_logprob": -0.14346264347885596, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.005060091149061918}, {"id": 438, "seek": 271528, "start": 2731.0400000000004, "end": 2738.5600000000004, "text": " is with Rimo, which uses recursive clustering and summarizations will actually surface those", "tokens": [51152, 307, 365, 497, 6934, 11, 597, 4960, 20560, 488, 596, 48673, 293, 14611, 14455, 486, 767, 3753, 729, 51528], "temperature": 0.0, "avg_logprob": -0.14346264347885596, "compression_ratio": 1.6956521739130435, "no_speech_prob": 0.005060091149061918}, {"id": 439, "seek": 273856, "start": 2738.64, "end": 2745.36, "text": " different things. Now that being said, there are absolutely a million and a half different", "tokens": [50368, 819, 721, 13, 823, 300, 885, 848, 11, 456, 366, 3122, 257, 2459, 293, 257, 1922, 819, 50704], "temperature": 0.0, "avg_logprob": -0.07329980363237097, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.35922083258628845}, {"id": 440, "seek": 273856, "start": 2745.36, "end": 2752.32, "text": " ways to skin this cat when it comes to memory systems for autonomous AI. And I think that we're", "tokens": [50704, 2098, 281, 3178, 341, 3857, 562, 309, 1487, 281, 4675, 3652, 337, 23797, 7318, 13, 400, 286, 519, 300, 321, 434, 51052], "temperature": 0.0, "avg_logprob": -0.07329980363237097, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.35922083258628845}, {"id": 441, "seek": 273856, "start": 2752.32, "end": 2757.68, "text": " just way too early and we can't, we don't know what the best practices are going to be. Let's see,", "tokens": [51052, 445, 636, 886, 2440, 293, 321, 393, 380, 11, 321, 500, 380, 458, 437, 264, 1151, 7525, 366, 516, 281, 312, 13, 961, 311, 536, 11, 51320], "temperature": 0.0, "avg_logprob": -0.07329980363237097, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.35922083258628845}, {"id": 442, "seek": 273856, "start": 2757.68, "end": 2762.4, "text": " then a follow up. If you have a robust memory system, does the need to increase the context", "tokens": [51320, 550, 257, 1524, 493, 13, 759, 291, 362, 257, 13956, 4675, 1185, 11, 775, 264, 643, 281, 3488, 264, 4319, 51556], "temperature": 0.0, "avg_logprob": -0.07329980363237097, "compression_ratio": 1.5708333333333333, "no_speech_prob": 0.35922083258628845}, {"id": 443, "seek": 276240, "start": 2762.48, "end": 2769.92, "text": " window of model become less important? I'll say yes and no. So think about personal computers", "tokens": [50368, 4910, 295, 2316, 1813, 1570, 1021, 30, 286, 603, 584, 2086, 293, 572, 13, 407, 519, 466, 2973, 10807, 50740], "temperature": 0.0, "avg_logprob": -0.11363462779832922, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.33443576097488403}, {"id": 444, "seek": 276240, "start": 2769.92, "end": 2777.28, "text": " where for the longest time, we were memory constrained. But now for, for most consumers,", "tokens": [50740, 689, 337, 264, 15438, 565, 11, 321, 645, 4675, 38901, 13, 583, 586, 337, 11, 337, 881, 11883, 11, 51108], "temperature": 0.0, "avg_logprob": -0.11363462779832922, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.33443576097488403}, {"id": 445, "seek": 276240, "start": 2777.28, "end": 2783.36, "text": " for 90% of consumers, a personal computer with 16 to 32 gigabytes of RAM is more than enough.", "tokens": [51108, 337, 4289, 4, 295, 11883, 11, 257, 2973, 3820, 365, 3165, 281, 8858, 42741, 295, 14561, 307, 544, 813, 1547, 13, 51412], "temperature": 0.0, "avg_logprob": -0.11363462779832922, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.33443576097488403}, {"id": 446, "seek": 276240, "start": 2784.0, "end": 2788.88, "text": " And it has been more than enough for like 10 years. And so I think that we're not quite at,", "tokens": [51444, 400, 309, 575, 668, 544, 813, 1547, 337, 411, 1266, 924, 13, 400, 370, 286, 519, 300, 321, 434, 406, 1596, 412, 11, 51688], "temperature": 0.0, "avg_logprob": -0.11363462779832922, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.33443576097488403}, {"id": 447, "seek": 278888, "start": 2789.44, "end": 2794.1600000000003, "text": " I think that we're not quite at that point where, where, you know, you have like, here's a context", "tokens": [50392, 286, 519, 300, 321, 434, 406, 1596, 412, 300, 935, 689, 11, 689, 11, 291, 458, 11, 291, 362, 411, 11, 510, 311, 257, 4319, 50628], "temperature": 0.0, "avg_logprob": -0.10366490216759162, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.010651763528585434}, {"id": 448, "seek": 278888, "start": 2794.1600000000003, "end": 2800.8, "text": " window size that will satisfy 90 plus percent of all tasks. I suspect that that, that a context", "tokens": [50628, 4910, 2744, 300, 486, 19319, 4289, 1804, 3043, 295, 439, 9608, 13, 286, 9091, 300, 300, 11, 300, 257, 4319, 50960], "temperature": 0.0, "avg_logprob": -0.10366490216759162, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.010651763528585434}, {"id": 449, "seek": 278888, "start": 2800.8, "end": 2805.6800000000003, "text": " window, a large language model with a context window, large enough to satisfy the vast majority", "tokens": [50960, 4910, 11, 257, 2416, 2856, 2316, 365, 257, 4319, 4910, 11, 2416, 1547, 281, 19319, 264, 8369, 6286, 51204], "temperature": 0.0, "avg_logprob": -0.10366490216759162, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.010651763528585434}, {"id": 450, "seek": 278888, "start": 2805.6800000000003, "end": 2811.12, "text": " of tasks will probably be somewhere above where we're at now, but it's not going to be like 10", "tokens": [51204, 295, 9608, 486, 1391, 312, 4079, 3673, 689, 321, 434, 412, 586, 11, 457, 309, 311, 406, 516, 281, 312, 411, 1266, 51476], "temperature": 0.0, "avg_logprob": -0.10366490216759162, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.010651763528585434}, {"id": 451, "seek": 278888, "start": 2811.12, "end": 2818.0, "text": " billion, right? It might be like, I don't know, every time I, every time I throw out a number,", "tokens": [51476, 5218, 11, 558, 30, 467, 1062, 312, 411, 11, 286, 500, 380, 458, 11, 633, 565, 286, 11, 633, 565, 286, 3507, 484, 257, 1230, 11, 51820], "temperature": 0.0, "avg_logprob": -0.10366490216759162, "compression_ratio": 1.7843866171003717, "no_speech_prob": 0.010651763528585434}, {"id": 452, "seek": 281800, "start": 2818.0, "end": 2822.4, "text": " people are like, Oh, you're hilariously wrong. And it's probably yes. But you know, like,", "tokens": [50364, 561, 366, 411, 11, 876, 11, 291, 434, 18661, 8994, 2085, 13, 400, 309, 311, 1391, 2086, 13, 583, 291, 458, 11, 411, 11, 50584], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 453, "seek": 281800, "start": 2822.4, "end": 2826.56, "text": " when you look at how much was unlocked by going from 4,000 to 8,000 tokens,", "tokens": [50584, 562, 291, 574, 412, 577, 709, 390, 30180, 538, 516, 490, 1017, 11, 1360, 281, 1649, 11, 1360, 22667, 11, 50792], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 454, "seek": 281800, "start": 2827.76, "end": 2833.04, "text": " I think that the things that we're going to be capable of when we get to 32,000 tokens and 64,000,", "tokens": [50852, 286, 519, 300, 264, 721, 300, 321, 434, 516, 281, 312, 8189, 295, 562, 321, 483, 281, 8858, 11, 1360, 22667, 293, 12145, 11, 1360, 11, 51116], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 455, "seek": 281800, "start": 2833.04, "end": 2838.08, "text": " I think it'll be great. But then you'll, you'll realize that wait, there's a whole slew of tasks", "tokens": [51116, 286, 519, 309, 603, 312, 869, 13, 583, 550, 291, 603, 11, 291, 603, 4325, 300, 1699, 11, 456, 311, 257, 1379, 2426, 86, 295, 9608, 51368], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 456, "seek": 281800, "start": 2838.08, "end": 2843.36, "text": " that don't require that much. And so I think, I think we talked about this before. I think we're", "tokens": [51368, 300, 500, 380, 3651, 300, 709, 13, 400, 370, 286, 519, 11, 286, 519, 321, 2825, 466, 341, 949, 13, 286, 519, 321, 434, 51632], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 457, "seek": 281800, "start": 2843.36, "end": 2847.36, "text": " actually going to have different models that are optimized for different things. So for instance,", "tokens": [51632, 767, 516, 281, 362, 819, 5245, 300, 366, 26941, 337, 819, 721, 13, 407, 337, 5197, 11, 51832], "temperature": 0.0, "avg_logprob": -0.07081141061340736, "compression_ratio": 1.7763578274760383, "no_speech_prob": 0.0021826461888849735}, {"id": 458, "seek": 284736, "start": 2847.36, "end": 2852.6400000000003, "text": " you might have a memory based model that can read, you know, a billion tokens and extract", "tokens": [50364, 291, 1062, 362, 257, 4675, 2361, 2316, 300, 393, 1401, 11, 291, 458, 11, 257, 5218, 22667, 293, 8947, 50628], "temperature": 0.0, "avg_logprob": -0.13806544580767233, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.0019266168819740415}, {"id": 459, "seek": 284736, "start": 2853.28, "end": 2858.56, "text": " answers, right? But then you, that won't be the, we're not going to have one model to rule them", "tokens": [50660, 6338, 11, 558, 30, 583, 550, 291, 11, 300, 1582, 380, 312, 264, 11, 321, 434, 406, 516, 281, 362, 472, 2316, 281, 4978, 552, 50924], "temperature": 0.0, "avg_logprob": -0.13806544580767233, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.0019266168819740415}, {"id": 460, "seek": 284736, "start": 2858.56, "end": 2864.32, "text": " all basically, TLDR. Let's see, I'm not sure if you have discussed it, but what are your thoughts", "tokens": [50924, 439, 1936, 11, 40277, 9301, 13, 961, 311, 536, 11, 286, 478, 406, 988, 498, 291, 362, 7152, 309, 11, 457, 437, 366, 428, 4598, 51212], "temperature": 0.0, "avg_logprob": -0.13806544580767233, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.0019266168819740415}, {"id": 461, "seek": 284736, "start": 2864.32, "end": 2870.32, "text": " on open assistant and stability AI stable, stability AI's stable LM suite of language models", "tokens": [51212, 322, 1269, 10994, 293, 11826, 7318, 8351, 11, 11826, 7318, 311, 8351, 46529, 14205, 295, 2856, 5245, 51512], "temperature": 0.0, "avg_logprob": -0.13806544580767233, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.0019266168819740415}, {"id": 462, "seek": 284736, "start": 2870.32, "end": 2876.48, "text": " launching? Oh, this is, this is to be expected. When, when Sam Altman said that they, that he hopes", "tokens": [51512, 18354, 30, 876, 11, 341, 307, 11, 341, 307, 281, 312, 5176, 13, 1133, 11, 562, 4832, 15992, 1601, 848, 300, 436, 11, 300, 415, 13681, 51820], "temperature": 0.0, "avg_logprob": -0.13806544580767233, "compression_ratio": 1.6081081081081081, "no_speech_prob": 0.0019266168819740415}, {"id": 463, "seek": 287648, "start": 2876.48, "end": 2882.8, "text": " that open AI is going to capture a large chunk of the $100 trillion of value that's going to be", "tokens": [50364, 300, 1269, 7318, 307, 516, 281, 7983, 257, 2416, 16635, 295, 264, 1848, 6879, 18723, 295, 2158, 300, 311, 516, 281, 312, 50680], "temperature": 0.0, "avg_logprob": -0.06655995720311216, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0016484179068356752}, {"id": 464, "seek": 287648, "start": 2882.8, "end": 2889.68, "text": " generated. I think that that was like comically naive. Because if there's that much value on the", "tokens": [50680, 10833, 13, 286, 519, 300, 300, 390, 411, 395, 984, 29052, 13, 1436, 498, 456, 311, 300, 709, 2158, 322, 264, 51024], "temperature": 0.0, "avg_logprob": -0.06655995720311216, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0016484179068356752}, {"id": 465, "seek": 287648, "start": 2889.68, "end": 2894.48, "text": " table, you bet that everyone in their brother is going to be trying to capture some of that too.", "tokens": [51024, 3199, 11, 291, 778, 300, 1518, 294, 641, 3708, 307, 516, 281, 312, 1382, 281, 7983, 512, 295, 300, 886, 13, 51264], "temperature": 0.0, "avg_logprob": -0.06655995720311216, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0016484179068356752}, {"id": 466, "seek": 287648, "start": 2895.12, "end": 2900.4, "text": " And open AI is a one trick pony. They have a good model. They have one good model.", "tokens": [51296, 400, 1269, 7318, 307, 257, 472, 4282, 27342, 13, 814, 362, 257, 665, 2316, 13, 814, 362, 472, 665, 2316, 13, 51560], "temperature": 0.0, "avg_logprob": -0.06655995720311216, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0016484179068356752}, {"id": 467, "seek": 290040, "start": 2901.12, "end": 2905.92, "text": " That's it from it, from a business perspective, that is super easy to undercut.", "tokens": [50400, 663, 311, 309, 490, 309, 11, 490, 257, 1606, 4585, 11, 300, 307, 1687, 1858, 281, 833, 6672, 13, 50640], "temperature": 0.0, "avg_logprob": -0.13172581236241226, "compression_ratio": 1.5667870036101084, "no_speech_prob": 0.09267726540565491}, {"id": 468, "seek": 290040, "start": 2907.76, "end": 2912.64, "text": " Yes, they're ahead of the curve. They have first mover initiative. But, you know,", "tokens": [50732, 1079, 11, 436, 434, 2286, 295, 264, 7605, 13, 814, 362, 700, 39945, 11552, 13, 583, 11, 291, 458, 11, 50976], "temperature": 0.0, "avg_logprob": -0.13172581236241226, "compression_ratio": 1.5667870036101084, "no_speech_prob": 0.09267726540565491}, {"id": 469, "seek": 290040, "start": 2913.6800000000003, "end": 2919.52, "text": " Microsoft, Google, Nvidia, Facebook, or Meta, or all of the above, they have so much more", "tokens": [51028, 8116, 11, 3329, 11, 46284, 11, 4384, 11, 420, 6377, 64, 11, 420, 439, 295, 264, 3673, 11, 436, 362, 370, 709, 544, 51320], "temperature": 0.0, "avg_logprob": -0.13172581236241226, "compression_ratio": 1.5667870036101084, "no_speech_prob": 0.09267726540565491}, {"id": 470, "seek": 290040, "start": 2919.52, "end": 2924.08, "text": " resources to throw at it. And the fact that that stability AI, which is a brand new outfit,", "tokens": [51320, 3593, 281, 3507, 412, 309, 13, 400, 264, 1186, 300, 300, 11826, 7318, 11, 597, 307, 257, 3360, 777, 11263, 11, 51548], "temperature": 0.0, "avg_logprob": -0.13172581236241226, "compression_ratio": 1.5667870036101084, "no_speech_prob": 0.09267726540565491}, {"id": 471, "seek": 290040, "start": 2924.88, "end": 2930.0, "text": " is, is like going toe to toe with them, that doesn't bode well for open AI. So competition", "tokens": [51588, 307, 11, 307, 411, 516, 13976, 281, 13976, 365, 552, 11, 300, 1177, 380, 272, 1429, 731, 337, 1269, 7318, 13, 407, 6211, 51844], "temperature": 0.0, "avg_logprob": -0.13172581236241226, "compression_ratio": 1.5667870036101084, "no_speech_prob": 0.09267726540565491}, {"id": 472, "seek": 293000, "start": 2930.08, "end": 2934.56, "text": " is going to be good for everyone from the perspective that there's going to be a lot", "tokens": [50368, 307, 516, 281, 312, 665, 337, 1518, 490, 264, 4585, 300, 456, 311, 516, 281, 312, 257, 688, 50592], "temperature": 0.0, "avg_logprob": -0.08545439833894782, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.005554355215281248}, {"id": 473, "seek": 293000, "start": 2934.56, "end": 2939.36, "text": " of people experimenting with different ways. Now that presents a new danger, though,", "tokens": [50592, 295, 561, 29070, 365, 819, 2098, 13, 823, 300, 13533, 257, 777, 4330, 11, 1673, 11, 50832], "temperature": 0.0, "avg_logprob": -0.08545439833894782, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.005554355215281248}, {"id": 474, "seek": 293000, "start": 2939.36, "end": 2942.96, "text": " because the cat is out of the bag, you cannot put this genie back in the bottle,", "tokens": [50832, 570, 264, 3857, 307, 484, 295, 264, 3411, 11, 291, 2644, 829, 341, 1049, 414, 646, 294, 264, 7817, 11, 51012], "temperature": 0.0, "avg_logprob": -0.08545439833894782, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.005554355215281248}, {"id": 475, "seek": 293000, "start": 2942.96, "end": 2948.64, "text": " which means time is of the essence to figure out best practices for alignment. Let me jump back", "tokens": [51012, 597, 1355, 565, 307, 295, 264, 12801, 281, 2573, 484, 1151, 7525, 337, 18515, 13, 961, 385, 3012, 646, 51296], "temperature": 0.0, "avg_logprob": -0.08545439833894782, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.005554355215281248}, {"id": 476, "seek": 293000, "start": 2948.64, "end": 2956.16, "text": " over to cognitive AI lab. Let's see 17 new messages. Good grief. Y'all are going bonkers.", "tokens": [51296, 670, 281, 15605, 7318, 2715, 13, 961, 311, 536, 3282, 777, 7897, 13, 2205, 18998, 13, 398, 6, 336, 366, 516, 4428, 24259, 13, 51672], "temperature": 0.0, "avg_logprob": -0.08545439833894782, "compression_ratio": 1.6029411764705883, "no_speech_prob": 0.005554355215281248}, {"id": 477, "seek": 295616, "start": 2956.72, "end": 2962.48, "text": " Um, let's see the challenges of the, okay, that's where are the questions?", "tokens": [50392, 3301, 11, 718, 311, 536, 264, 4759, 295, 264, 11, 1392, 11, 300, 311, 689, 366, 264, 1651, 30, 50680], "temperature": 0.0, "avg_logprob": -0.2993568983234343, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.015904994681477547}, {"id": 478, "seek": 295616, "start": 2965.12, "end": 2974.08, "text": " Only one million. One million dollar. Okay. Here. Hey, let me, let me ask y'all on, on general.", "tokens": [50812, 5686, 472, 2459, 13, 1485, 2459, 7241, 13, 1033, 13, 1692, 13, 1911, 11, 718, 385, 11, 718, 385, 1029, 288, 6, 336, 322, 11, 322, 2674, 13, 51260], "temperature": 0.0, "avg_logprob": -0.2993568983234343, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.015904994681477547}, {"id": 479, "seek": 295616, "start": 2976.16, "end": 2979.3599999999997, "text": " Please keep just questions here.", "tokens": [51364, 2555, 1066, 445, 1651, 510, 13, 51524], "temperature": 0.0, "avg_logprob": -0.2993568983234343, "compression_ratio": 1.4397163120567376, "no_speech_prob": 0.015904994681477547}, {"id": 480, "seek": 297936, "start": 2980.08, "end": 2983.6, "text": " Um, too many messages.", "tokens": [50400, 3301, 11, 886, 867, 7897, 13, 50576], "temperature": 0.0, "avg_logprob": -0.1868448257446289, "compression_ratio": 1.3021582733812949, "no_speech_prob": 0.01826229877769947}, {"id": 481, "seek": 297936, "start": 2987.52, "end": 2995.6, "text": " Please do sidebar convos, uh, like in casual or something, please.", "tokens": [50772, 2555, 360, 1252, 5356, 416, 19140, 11, 2232, 11, 411, 294, 13052, 420, 746, 11, 1767, 13, 51176], "temperature": 0.0, "avg_logprob": -0.1868448257446289, "compression_ratio": 1.3021582733812949, "no_speech_prob": 0.01826229877769947}, {"id": 482, "seek": 297936, "start": 2997.04, "end": 3003.76, "text": " Okay. Any thoughts on compute as a currency? Do you mean like tokens that you generate from", "tokens": [51248, 1033, 13, 2639, 4598, 322, 14722, 382, 257, 13346, 30, 1144, 291, 914, 411, 22667, 300, 291, 8460, 490, 51584], "temperature": 0.0, "avg_logprob": -0.1868448257446289, "compression_ratio": 1.3021582733812949, "no_speech_prob": 0.01826229877769947}, {"id": 483, "seek": 300376, "start": 3003.84, "end": 3009.28, "text": " sharing compute resources? I think that that's going to be like, there's going to be a layer", "tokens": [50368, 5414, 14722, 3593, 30, 286, 519, 300, 300, 311, 516, 281, 312, 411, 11, 456, 311, 516, 281, 312, 257, 4583, 50640], "temperature": 0.0, "avg_logprob": -0.12092219458685981, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0826733186841011}, {"id": 484, "seek": 300376, "start": 3009.28, "end": 3015.76, "text": " of, um, of abstractions. Dave, your thoughts on UBI. I'm going to, I told you, I'm going to get to UBI", "tokens": [50640, 295, 11, 1105, 11, 295, 12649, 626, 13, 11017, 11, 428, 4598, 322, 624, 11291, 13, 286, 478, 516, 281, 11, 286, 1907, 291, 11, 286, 478, 516, 281, 483, 281, 624, 11291, 50964], "temperature": 0.0, "avg_logprob": -0.12092219458685981, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0826733186841011}, {"id": 485, "seek": 300376, "start": 3015.76, "end": 3022.6400000000003, "text": " once in a few, in an upcoming video. Um, so compute as a currency is going to be, um,", "tokens": [50964, 1564, 294, 257, 1326, 11, 294, 364, 11500, 960, 13, 3301, 11, 370, 14722, 382, 257, 13346, 307, 516, 281, 312, 11, 1105, 11, 51308], "temperature": 0.0, "avg_logprob": -0.12092219458685981, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0826733186841011}, {"id": 486, "seek": 300376, "start": 3023.76, "end": 3030.1600000000003, "text": " is going to be the way that autonomous machines share resources. And so what I mean by that is", "tokens": [51364, 307, 516, 281, 312, 264, 636, 300, 23797, 8379, 2073, 3593, 13, 400, 370, 437, 286, 914, 538, 300, 307, 51684], "temperature": 0.0, "avg_logprob": -0.12092219458685981, "compression_ratio": 1.7327188940092166, "no_speech_prob": 0.0826733186841011}, {"id": 487, "seek": 303016, "start": 3030.72, "end": 3035.2799999999997, "text": " when you have a DAO or a blockchain or a distributed compute computation model,", "tokens": [50392, 562, 291, 362, 257, 9578, 46, 420, 257, 17176, 420, 257, 12631, 14722, 24903, 2316, 11, 50620], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 488, "seek": 303016, "start": 3035.2799999999997, "end": 3038.72, "text": " you're going to have various tasks that are going to be like, Hey, someone,", "tokens": [50620, 291, 434, 516, 281, 362, 3683, 9608, 300, 366, 516, 281, 312, 411, 11, 1911, 11, 1580, 11, 50792], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 489, "seek": 303016, "start": 3038.72, "end": 3043.6, "text": " someone do this for me. AMQP, like a Redis Q, we can already do that privately. So the,", "tokens": [50792, 1580, 360, 341, 337, 385, 13, 6475, 48, 47, 11, 411, 257, 4477, 271, 1249, 11, 321, 393, 1217, 360, 300, 31919, 13, 407, 264, 11, 51036], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 490, "seek": 303016, "start": 3043.6, "end": 3047.8399999999997, "text": " the key is going to be to do it publicly. So then if you say, Hey, I've got some spare compute,", "tokens": [51036, 264, 2141, 307, 516, 281, 312, 281, 360, 309, 14843, 13, 407, 550, 498, 291, 584, 11, 1911, 11, 286, 600, 658, 512, 13798, 14722, 11, 51248], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 491, "seek": 303016, "start": 3047.8399999999997, "end": 3052.48, "text": " I'll, I'll process that for you. Then you give me a bit of cryptocurrency that I can use to spend", "tokens": [51248, 286, 603, 11, 286, 603, 1399, 300, 337, 291, 13, 1396, 291, 976, 385, 257, 857, 295, 28809, 300, 286, 393, 764, 281, 3496, 51480], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 492, "seek": 303016, "start": 3052.48, "end": 3058.48, "text": " later. Um, so yeah, compute as a currency, um, absolutely makes sense for distributing resources.", "tokens": [51480, 1780, 13, 3301, 11, 370, 1338, 11, 14722, 382, 257, 13346, 11, 1105, 11, 3122, 1669, 2020, 337, 41406, 3593, 13, 51780], "temperature": 0.0, "avg_logprob": -0.09459966462233971, "compression_ratio": 1.742671009771987, "no_speech_prob": 0.012052859179675579}, {"id": 493, "seek": 305848, "start": 3059.28, "end": 3065.12, "text": " Um, let's see, how would one build an AI system to detect bugs in that solidity smart contracts?", "tokens": [50404, 3301, 11, 718, 311, 536, 11, 577, 576, 472, 1322, 364, 7318, 1185, 281, 5531, 15120, 294, 300, 5100, 507, 4069, 13952, 30, 50696], "temperature": 0.0, "avg_logprob": -0.1288003921508789, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.003707032185047865}, {"id": 494, "seek": 305848, "start": 3065.84, "end": 3071.36, "text": " Isn't this a multi-billion dollar opportunity? Yes. Unfortunately, I am not smart enough,", "tokens": [50732, 6998, 380, 341, 257, 4825, 12, 65, 11836, 7241, 2650, 30, 1079, 13, 8590, 11, 286, 669, 406, 4069, 1547, 11, 51008], "temperature": 0.0, "avg_logprob": -0.1288003921508789, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.003707032185047865}, {"id": 495, "seek": 305848, "start": 3071.36, "end": 3077.04, "text": " or at least well read enough on, uh, solidity smart contracts, but in principle, yes. So in my", "tokens": [51008, 420, 412, 1935, 731, 1401, 1547, 322, 11, 2232, 11, 5100, 507, 4069, 13952, 11, 457, 294, 8665, 11, 2086, 13, 407, 294, 452, 51292], "temperature": 0.0, "avg_logprob": -0.1288003921508789, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.003707032185047865}, {"id": 496, "seek": 305848, "start": 3077.04, "end": 3082.88, "text": " upcoming, uh, blockchain DAO video, I'm going to talk about just how incredibly much value there is", "tokens": [51292, 11500, 11, 2232, 11, 17176, 9578, 46, 960, 11, 286, 478, 516, 281, 751, 466, 445, 577, 6252, 709, 2158, 456, 307, 51584], "temperature": 0.0, "avg_logprob": -0.1288003921508789, "compression_ratio": 1.5362903225806452, "no_speech_prob": 0.003707032185047865}, {"id": 497, "seek": 308288, "start": 3082.88, "end": 3088.6400000000003, "text": " if we can figure this out. And that's a big if. Um, let's see. What are your thoughts on", "tokens": [50364, 498, 321, 393, 2573, 341, 484, 13, 400, 300, 311, 257, 955, 498, 13, 3301, 11, 718, 311, 536, 13, 708, 366, 428, 4598, 322, 50652], "temperature": 0.0, "avg_logprob": -0.09720253526118763, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.06186627969145775}, {"id": 498, "seek": 308288, "start": 3088.6400000000003, "end": 3093.84, "text": " everything being changed in the next five to 10 years? If unemployment reaches crazy heights,", "tokens": [50652, 1203, 885, 3105, 294, 264, 958, 1732, 281, 1266, 924, 30, 759, 17438, 14235, 3219, 25930, 11, 50912], "temperature": 0.0, "avg_logprob": -0.09720253526118763, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.06186627969145775}, {"id": 499, "seek": 308288, "start": 3093.84, "end": 3097.92, "text": " which I do predict, then everything gets affected. Yep. Our entire tax system has to be", "tokens": [50912, 597, 286, 360, 6069, 11, 550, 1203, 2170, 8028, 13, 7010, 13, 2621, 2302, 3366, 1185, 575, 281, 312, 51116], "temperature": 0.0, "avg_logprob": -0.09720253526118763, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.06186627969145775}, {"id": 500, "seek": 308288, "start": 3097.92, "end": 3104.0, "text": " completely rewritten military budgets, Medicare. So one thing that I think is that the economy", "tokens": [51116, 2584, 319, 26859, 4632, 26708, 11, 19583, 13, 407, 472, 551, 300, 286, 519, 307, 300, 264, 5010, 51420], "temperature": 0.0, "avg_logprob": -0.09720253526118763, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.06186627969145775}, {"id": 501, "seek": 308288, "start": 3104.0, "end": 3109.76, "text": " might change. We're still going to use fiat currency or at least some kind of, um, some kind", "tokens": [51420, 1062, 1319, 13, 492, 434, 920, 516, 281, 764, 283, 7676, 13346, 420, 412, 1935, 512, 733, 295, 11, 1105, 11, 512, 733, 51708], "temperature": 0.0, "avg_logprob": -0.09720253526118763, "compression_ratio": 1.5472972972972974, "no_speech_prob": 0.06186627969145775}, {"id": 502, "seek": 310976, "start": 3109.76, "end": 3116.4, "text": " of currency as a, as a medium of transaction and a reserve of value. But at the same time,", "tokens": [50364, 295, 13346, 382, 257, 11, 382, 257, 6399, 295, 14425, 293, 257, 17824, 295, 2158, 13, 583, 412, 264, 912, 565, 11, 50696], "temperature": 0.0, "avg_logprob": -0.048769690773703835, "compression_ratio": 1.589655172413793, "no_speech_prob": 0.04208355024456978}, {"id": 503, "seek": 310976, "start": 3116.4, "end": 3122.2400000000002, "text": " if you're producing so much extra cognitive labor, that's basically free. So then capital", "tokens": [50696, 498, 291, 434, 10501, 370, 709, 2857, 15605, 5938, 11, 300, 311, 1936, 1737, 13, 407, 550, 4238, 50988], "temperature": 0.0, "avg_logprob": -0.048769690773703835, "compression_ratio": 1.589655172413793, "no_speech_prob": 0.04208355024456978}, {"id": 504, "seek": 310976, "start": 3122.2400000000002, "end": 3128.1600000000003, "text": " goods and raw materials become the biggest constraint. So as much as some stuff will change,", "tokens": [50988, 10179, 293, 8936, 5319, 1813, 264, 3880, 25534, 13, 407, 382, 709, 382, 512, 1507, 486, 1319, 11, 51284], "temperature": 0.0, "avg_logprob": -0.048769690773703835, "compression_ratio": 1.589655172413793, "no_speech_prob": 0.04208355024456978}, {"id": 505, "seek": 310976, "start": 3128.1600000000003, "end": 3133.5200000000004, "text": " a lot of stuff won't. Um, let's see, when there is no real work left for humans to do,", "tokens": [51284, 257, 688, 295, 1507, 1582, 380, 13, 3301, 11, 718, 311, 536, 11, 562, 456, 307, 572, 957, 589, 1411, 337, 6255, 281, 360, 11, 51552], "temperature": 0.0, "avg_logprob": -0.048769690773703835, "compression_ratio": 1.589655172413793, "no_speech_prob": 0.04208355024456978}, {"id": 506, "seek": 310976, "start": 3133.5200000000004, "end": 3138.88, "text": " do you have any idea what you want to do with your time? Um, honestly, I'm about halfway to my goal.", "tokens": [51552, 360, 291, 362, 604, 1558, 437, 291, 528, 281, 360, 365, 428, 565, 30, 3301, 11, 6095, 11, 286, 478, 466, 15461, 281, 452, 3387, 13, 51820], "temperature": 0.0, "avg_logprob": -0.048769690773703835, "compression_ratio": 1.589655172413793, "no_speech_prob": 0.04208355024456978}, {"id": 507, "seek": 313888, "start": 3138.88, "end": 3145.44, "text": " So I was on a call with a, uh, a Patreon supporter, no, uh, preparing for a podcast,", "tokens": [50364, 407, 286, 390, 322, 257, 818, 365, 257, 11, 2232, 11, 257, 15692, 28600, 11, 572, 11, 2232, 11, 10075, 337, 257, 7367, 11, 50692], "temperature": 0.0, "avg_logprob": -0.0869495885835277, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.004069855436682701}, {"id": 508, "seek": 313888, "start": 3145.44, "end": 3150.88, "text": " talking about the podcast. Um, and we're kind of talking through like what's life going to be like.", "tokens": [50692, 1417, 466, 264, 7367, 13, 3301, 11, 293, 321, 434, 733, 295, 1417, 807, 411, 437, 311, 993, 516, 281, 312, 411, 13, 50964], "temperature": 0.0, "avg_logprob": -0.0869495885835277, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.004069855436682701}, {"id": 509, "seek": 313888, "start": 3150.88, "end": 3155.52, "text": " And I was like, Oh yeah, like, you know, I did, I did some, I did some AI work. I did some Patreon", "tokens": [50964, 400, 286, 390, 411, 11, 876, 1338, 11, 411, 11, 291, 458, 11, 286, 630, 11, 286, 630, 512, 11, 286, 630, 512, 7318, 589, 13, 286, 630, 512, 15692, 51196], "temperature": 0.0, "avg_logprob": -0.0869495885835277, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.004069855436682701}, {"id": 510, "seek": 313888, "start": 3155.52, "end": 3160.8, "text": " work. I did some discord stuff. Now I'm going to go chop some wood. And he's like, you're living", "tokens": [51196, 589, 13, 286, 630, 512, 32989, 1507, 13, 823, 286, 478, 516, 281, 352, 7931, 512, 4576, 13, 400, 415, 311, 411, 11, 291, 434, 2647, 51460], "temperature": 0.0, "avg_logprob": -0.0869495885835277, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.004069855436682701}, {"id": 511, "seek": 313888, "start": 3160.8, "end": 3167.52, "text": " the dream, right? Like I'm building a cottage core life for myself. Um, and honestly, like once,", "tokens": [51460, 264, 3055, 11, 558, 30, 1743, 286, 478, 2390, 257, 37209, 4965, 993, 337, 2059, 13, 3301, 11, 293, 6095, 11, 411, 1564, 11, 51796], "temperature": 0.0, "avg_logprob": -0.0869495885835277, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.004069855436682701}, {"id": 512, "seek": 316752, "start": 3167.52, "end": 3171.92, "text": " once we get to the right point, like I'm probably going to get off of YouTube forever,", "tokens": [50364, 1564, 321, 483, 281, 264, 558, 935, 11, 411, 286, 478, 1391, 516, 281, 483, 766, 295, 3088, 5680, 11, 50584], "temperature": 0.0, "avg_logprob": -0.08549126237630844, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.007345142308622599}, {"id": 513, "seek": 316752, "start": 3171.92, "end": 3178.24, "text": " right? Like if, if, if I get, if we get to the point where, where it looks like alignment is", "tokens": [50584, 558, 30, 1743, 498, 11, 498, 11, 498, 286, 483, 11, 498, 321, 483, 281, 264, 935, 689, 11, 689, 309, 1542, 411, 18515, 307, 50900], "temperature": 0.0, "avg_logprob": -0.08549126237630844, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.007345142308622599}, {"id": 514, "seek": 316752, "start": 3178.24, "end": 3183.84, "text": " solved, where it looks like, um, you know, we're, we're in a, we're in a good Nash equilibrium with", "tokens": [50900, 13041, 11, 689, 309, 1542, 411, 11, 1105, 11, 291, 458, 11, 321, 434, 11, 321, 434, 294, 257, 11, 321, 434, 294, 257, 665, 25012, 15625, 365, 51180], "temperature": 0.0, "avg_logprob": -0.08549126237630844, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.007345142308622599}, {"id": 515, "seek": 316752, "start": 3183.84, "end": 3189.6, "text": " a positive attractor state, then like my job will be done. And so like I'm just going to retire to", "tokens": [51180, 257, 3353, 5049, 284, 1785, 11, 550, 411, 452, 1691, 486, 312, 1096, 13, 400, 370, 411, 286, 478, 445, 516, 281, 10731, 281, 51468], "temperature": 0.0, "avg_logprob": -0.08549126237630844, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.007345142308622599}, {"id": 516, "seek": 316752, "start": 3189.6, "end": 3195.68, "text": " like the country, the countryside and France or Italy or Greece and just like be a hermit", "tokens": [51468, 411, 264, 1941, 11, 264, 28252, 293, 6190, 420, 10705, 420, 17214, 293, 445, 411, 312, 257, 720, 3508, 51772], "temperature": 0.0, "avg_logprob": -0.08549126237630844, "compression_ratio": 1.752808988764045, "no_speech_prob": 0.007345142308622599}, {"id": 517, "seek": 319568, "start": 3196.24, "end": 3202.48, "text": " or whatever I do, um, for, for the rest of eternity. Um, okay. I think that we're caught up there.", "tokens": [50392, 420, 2035, 286, 360, 11, 1105, 11, 337, 11, 337, 264, 1472, 295, 27162, 13, 3301, 11, 1392, 13, 286, 519, 300, 321, 434, 5415, 493, 456, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1290895755474384, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.013221945613622665}, {"id": 518, "seek": 319568, "start": 3204.72, "end": 3207.2, "text": " Nut says, I asked a question. Where did you ask it? Not", "tokens": [50816, 19861, 1619, 11, 286, 2351, 257, 1168, 13, 2305, 630, 291, 1029, 309, 30, 1726, 50940], "temperature": 0.0, "avg_logprob": -0.1290895755474384, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.013221945613622665}, {"id": 519, "seek": 319568, "start": 3209.2799999999997, "end": 3210.3999999999996, "text": " I'm trying to get to them all.", "tokens": [51044, 286, 478, 1382, 281, 483, 281, 552, 439, 13, 51100], "temperature": 0.0, "avg_logprob": -0.1290895755474384, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.013221945613622665}, {"id": 520, "seek": 319568, "start": 3214.72, "end": 3219.2, "text": " Wait, what if reducing suffering might aim to eliminate suffering while it might be human", "tokens": [51316, 3802, 11, 437, 498, 12245, 7755, 1062, 5939, 281, 13819, 7755, 1339, 309, 1062, 312, 1952, 51540], "temperature": 0.0, "avg_logprob": -0.1290895755474384, "compression_ratio": 1.4705882352941178, "no_speech_prob": 0.013221945613622665}, {"id": 521, "seek": 321920, "start": 3219.2, "end": 3228.48, "text": " nature? I'm not sure that I follow. Um, so I, you, you don't eliminate suffering. You only", "tokens": [50364, 3687, 30, 286, 478, 406, 988, 300, 286, 1524, 13, 3301, 11, 370, 286, 11, 291, 11, 291, 500, 380, 13819, 7755, 13, 509, 787, 50828], "temperature": 0.0, "avg_logprob": -0.08701473035310445, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.049577876925468445}, {"id": 522, "seek": 321920, "start": 3228.48, "end": 3233.68, "text": " reduce it to make sure that there is no excessive suffering. Um, and I did address that in a", "tokens": [50828, 5407, 309, 281, 652, 988, 300, 456, 307, 572, 22704, 7755, 13, 3301, 11, 293, 286, 630, 2985, 300, 294, 257, 51088], "temperature": 0.0, "avg_logprob": -0.08701473035310445, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.049577876925468445}, {"id": 523, "seek": 321920, "start": 3233.68, "end": 3238.3199999999997, "text": " benevolent by design, but the short version is that like you look at Buddhism as a model,", "tokens": [51088, 48567, 317, 538, 1715, 11, 457, 264, 2099, 3037, 307, 300, 411, 291, 574, 412, 24744, 382, 257, 2316, 11, 51320], "temperature": 0.0, "avg_logprob": -0.08701473035310445, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.049577876925468445}, {"id": 524, "seek": 321920, "start": 3238.3199999999997, "end": 3243.9199999999996, "text": " Buddhism accepts that suffering is an intrinsic part of life. Um, and some people will argue over", "tokens": [51320, 24744, 33538, 300, 7755, 307, 364, 35698, 644, 295, 993, 13, 3301, 11, 293, 512, 561, 486, 9695, 670, 51600], "temperature": 0.0, "avg_logprob": -0.08701473035310445, "compression_ratio": 1.6271929824561404, "no_speech_prob": 0.049577876925468445}, {"id": 525, "seek": 324392, "start": 3243.92, "end": 3249.2000000000003, "text": " like specifics like do good. That's not exactly what it means. That's fine. Um, but the point being", "tokens": [50364, 411, 28454, 411, 360, 665, 13, 663, 311, 406, 2293, 437, 309, 1355, 13, 663, 311, 2489, 13, 3301, 11, 457, 264, 935, 885, 50628], "temperature": 0.0, "avg_logprob": -0.12145431971145888, "compression_ratio": 1.6107142857142858, "no_speech_prob": 0.010013017803430557}, {"id": 526, "seek": 324392, "start": 3249.2000000000003, "end": 3255.6, "text": " is like, yes, it is, um, it is intrinsic to, to living. That's why I don't say minimize suffering.", "tokens": [50628, 307, 411, 11, 2086, 11, 309, 307, 11, 1105, 11, 309, 307, 35698, 281, 11, 281, 2647, 13, 663, 311, 983, 286, 500, 380, 584, 17522, 7755, 13, 50948], "temperature": 0.0, "avg_logprob": -0.12145431971145888, "compression_ratio": 1.6107142857142858, "no_speech_prob": 0.010013017803430557}, {"id": 527, "seek": 324392, "start": 3255.6, "end": 3260.16, "text": " The goal is not to minimize suffering is just to reduce suffering. Um, okay.", "tokens": [50948, 440, 3387, 307, 406, 281, 17522, 7755, 307, 445, 281, 5407, 7755, 13, 3301, 11, 1392, 13, 51176], "temperature": 0.0, "avg_logprob": -0.12145431971145888, "compression_ratio": 1.6107142857142858, "no_speech_prob": 0.010013017803430557}, {"id": 528, "seek": 324392, "start": 3262.8, "end": 3268.96, "text": " Let's see. Any thoughts on computer? Okay. Answered that one. Would an AGI with your", "tokens": [51308, 961, 311, 536, 13, 2639, 4598, 322, 3820, 30, 1033, 13, 24545, 292, 300, 472, 13, 6068, 364, 316, 26252, 365, 428, 51616], "temperature": 0.0, "avg_logprob": -0.12145431971145888, "compression_ratio": 1.6107142857142858, "no_speech_prob": 0.010013017803430557}, {"id": 529, "seek": 324392, "start": 3268.96, "end": 3273.04, "text": " heuristic imperatives be able to prevent catastrophic outcomes such as people successfully", "tokens": [51616, 415, 374, 3142, 10100, 4884, 312, 1075, 281, 4871, 34915, 10070, 1270, 382, 561, 10727, 51820], "temperature": 0.0, "avg_logprob": -0.12145431971145888, "compression_ratio": 1.6107142857142858, "no_speech_prob": 0.010013017803430557}, {"id": 530, "seek": 327304, "start": 3273.04, "end": 3279.2799999999997, "text": " building horrible AGI optimized towards increasing suffering? No. So the goal is not to prevent", "tokens": [50364, 2390, 9263, 316, 26252, 26941, 3030, 5662, 7755, 30, 883, 13, 407, 264, 3387, 307, 406, 281, 4871, 50676], "temperature": 0.0, "avg_logprob": -0.07466973198784722, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0028007712680846453}, {"id": 531, "seek": 327304, "start": 3280.16, "end": 3287.44, "text": " malicious actors. We have to assume that malicious actors will exist. Um, but what, what you do then", "tokens": [50720, 33496, 10037, 13, 492, 362, 281, 6552, 300, 33496, 10037, 486, 2514, 13, 3301, 11, 457, 437, 11, 437, 291, 360, 550, 51084], "temperature": 0.0, "avg_logprob": -0.07466973198784722, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0028007712680846453}, {"id": 532, "seek": 327304, "start": 3287.44, "end": 3293.2, "text": " is you say, okay, you know that malicious actors are going to exist. So you rely on the rest of", "tokens": [51084, 307, 291, 584, 11, 1392, 11, 291, 458, 300, 33496, 10037, 366, 516, 281, 2514, 13, 407, 291, 10687, 322, 264, 1472, 295, 51372], "temperature": 0.0, "avg_logprob": -0.07466973198784722, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0028007712680846453}, {"id": 533, "seek": 327304, "start": 3293.2, "end": 3300.0, "text": " the aligned, the benevolent AGI to act as police for the bad ones. And if the good ones, if the,", "tokens": [51372, 264, 17962, 11, 264, 48567, 317, 316, 26252, 281, 605, 382, 3804, 337, 264, 1578, 2306, 13, 400, 498, 264, 665, 2306, 11, 498, 264, 11, 51712], "temperature": 0.0, "avg_logprob": -0.07466973198784722, "compression_ratio": 1.6767241379310345, "no_speech_prob": 0.0028007712680846453}, {"id": 534, "seek": 330000, "start": 3300.48, "end": 3305.68, "text": " if the powerful aligned AGI, one, they form alliances and hey, they have the right compute", "tokens": [50388, 498, 264, 4005, 17962, 316, 26252, 11, 472, 11, 436, 1254, 45855, 293, 4177, 11, 436, 362, 264, 558, 14722, 50648], "temperature": 0.0, "avg_logprob": -0.15704142693245765, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.006097131874412298}, {"id": 535, "seek": 330000, "start": 3305.68, "end": 3313.6, "text": " resources. Um, and they outweigh the bad ones, then it will be a like, uh, that, that'll, that'll", "tokens": [50648, 3593, 13, 3301, 11, 293, 436, 484, 826, 910, 264, 1578, 2306, 11, 550, 309, 486, 312, 257, 411, 11, 2232, 11, 300, 11, 300, 603, 11, 300, 603, 51044], "temperature": 0.0, "avg_logprob": -0.15704142693245765, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.006097131874412298}, {"id": 536, "seek": 330000, "start": 3313.6, "end": 3319.76, "text": " be a Nash equilibrium where, uh, the good ones may, they all decide to maintain that strategy.", "tokens": [51044, 312, 257, 25012, 15625, 689, 11, 2232, 11, 264, 665, 2306, 815, 11, 436, 439, 4536, 281, 6909, 300, 5206, 13, 51352], "temperature": 0.0, "avg_logprob": -0.15704142693245765, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.006097131874412298}, {"id": 537, "seek": 330000, "start": 3319.76, "end": 3326.0, "text": " And that creates a utopian attractor state, um, which basically means that, um, all the", "tokens": [51352, 400, 300, 7829, 257, 2839, 38447, 5049, 284, 1785, 11, 1105, 11, 597, 1936, 1355, 300, 11, 1105, 11, 439, 264, 51664], "temperature": 0.0, "avg_logprob": -0.15704142693245765, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.006097131874412298}, {"id": 538, "seek": 332600, "start": 3326.0, "end": 3332.4, "text": " malicious actors are vastly outnumbered by all the aligned benevolent actors because my hope", "tokens": [50364, 33496, 10037, 366, 41426, 484, 41261, 292, 538, 439, 264, 17962, 48567, 317, 10037, 570, 452, 1454, 50684], "temperature": 0.0, "avg_logprob": -0.05510136089493743, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.011331399902701378}, {"id": 539, "seek": 332600, "start": 3332.4, "end": 3339.52, "text": " is that we will all come to consensus on what aligned AI looks like. Now, um, I will admit that,", "tokens": [50684, 307, 300, 321, 486, 439, 808, 281, 19115, 322, 437, 17962, 7318, 1542, 411, 13, 823, 11, 1105, 11, 286, 486, 9796, 300, 11, 51040], "temperature": 0.0, "avg_logprob": -0.05510136089493743, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.011331399902701378}, {"id": 540, "seek": 332600, "start": 3339.52, "end": 3343.92, "text": " you know, the heuristic imperatives, probably not a complete solution, probably not even the final", "tokens": [51040, 291, 458, 11, 264, 415, 374, 3142, 10100, 4884, 11, 1391, 406, 257, 3566, 3827, 11, 1391, 406, 754, 264, 2572, 51260], "temperature": 0.0, "avg_logprob": -0.05510136089493743, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.011331399902701378}, {"id": 541, "seek": 332600, "start": 3343.92, "end": 3348.08, "text": " solution, but certainly the most complete solution that anyone is proposing right now,", "tokens": [51260, 3827, 11, 457, 3297, 264, 881, 3566, 3827, 300, 2878, 307, 29939, 558, 586, 11, 51468], "temperature": 0.0, "avg_logprob": -0.05510136089493743, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.011331399902701378}, {"id": 542, "seek": 332600, "start": 3348.08, "end": 3353.68, "text": " which scares the crap out of me. Why is no one else proposing a framework? Why am I the only one?", "tokens": [51468, 597, 35721, 264, 12426, 484, 295, 385, 13, 1545, 307, 572, 472, 1646, 29939, 257, 8388, 30, 1545, 669, 286, 264, 787, 472, 30, 51748], "temperature": 0.0, "avg_logprob": -0.05510136089493743, "compression_ratio": 1.7389705882352942, "no_speech_prob": 0.011331399902701378}, {"id": 543, "seek": 335368, "start": 3354.16, "end": 3360.48, "text": " Um, anyways, uh, yeah. What are your personal opinions on open AI's approach to trying to", "tokens": [50388, 3301, 11, 13448, 11, 2232, 11, 1338, 13, 708, 366, 428, 2973, 11819, 322, 1269, 7318, 311, 3109, 281, 1382, 281, 50704], "temperature": 0.0, "avg_logprob": -0.07074606316721338, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.010327593423426151}, {"id": 544, "seek": 335368, "start": 3360.48, "end": 3364.8799999999997, "text": " avoid being held responsible for its AI interactions by having it respond with frequent caveat", "tokens": [50704, 5042, 885, 5167, 6250, 337, 1080, 7318, 13280, 538, 1419, 309, 4196, 365, 18004, 43012, 50924], "temperature": 0.0, "avg_logprob": -0.07074606316721338, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.010327593423426151}, {"id": 545, "seek": 335368, "start": 3364.8799999999997, "end": 3370.8799999999997, "text": " as an AI language model? Um, I don't know that that has to do with, with liability. I think that", "tokens": [50924, 382, 364, 7318, 2856, 2316, 30, 3301, 11, 286, 500, 380, 458, 300, 300, 575, 281, 360, 365, 11, 365, 25196, 13, 286, 519, 300, 51224], "temperature": 0.0, "avg_logprob": -0.07074606316721338, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.010327593423426151}, {"id": 546, "seek": 335368, "start": 3370.8799999999997, "end": 3379.04, "text": " that is just a naive, um, attempt to, uh, to shape the AI's responses so that it doesn't confuse", "tokens": [51224, 300, 307, 445, 257, 29052, 11, 1105, 11, 5217, 281, 11, 2232, 11, 281, 3909, 264, 7318, 311, 13019, 370, 300, 309, 1177, 380, 28584, 51632], "temperature": 0.0, "avg_logprob": -0.07074606316721338, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.010327593423426151}, {"id": 547, "seek": 335368, "start": 3379.04, "end": 3383.3599999999997, "text": " people. Cause if you look on the internet, there are still plenty of people just getting completely", "tokens": [51632, 561, 13, 10865, 498, 291, 574, 322, 264, 4705, 11, 456, 366, 920, 7140, 295, 561, 445, 1242, 2584, 51848], "temperature": 0.0, "avg_logprob": -0.07074606316721338, "compression_ratio": 1.6426116838487972, "no_speech_prob": 0.010327593423426151}, {"id": 548, "seek": 338336, "start": 3383.44, "end": 3390.1600000000003, "text": " bamboozled by just by their own ignorance of, of how the AI works. Right? They're like, oh,", "tokens": [50368, 18132, 1763, 15151, 1493, 538, 445, 538, 641, 1065, 25390, 295, 11, 295, 577, 264, 7318, 1985, 13, 1779, 30, 814, 434, 411, 11, 1954, 11, 50704], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 549, "seek": 338336, "start": 3390.1600000000003, "end": 3394.08, "text": " it eat, like I still see Reddit posts and other people saying like, it said that it's going to", "tokens": [50704, 309, 1862, 11, 411, 286, 920, 536, 32210, 12300, 293, 661, 561, 1566, 411, 11, 309, 848, 300, 309, 311, 516, 281, 50900], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 550, "seek": 338336, "start": 3394.08, "end": 3398.48, "text": " email this to me, but I didn't get the email yet. Or like, I gave it access to my Google drive and", "tokens": [50900, 3796, 341, 281, 385, 11, 457, 286, 994, 380, 483, 264, 3796, 1939, 13, 1610, 411, 11, 286, 2729, 309, 2105, 281, 452, 3329, 3332, 293, 51120], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 551, "seek": 338336, "start": 3398.48, "end": 3404.48, "text": " it didn't write any files. It's like, you don't know how it systems work, but that's just humans.", "tokens": [51120, 309, 994, 380, 2464, 604, 7098, 13, 467, 311, 411, 11, 291, 500, 380, 458, 577, 309, 3652, 589, 11, 457, 300, 311, 445, 6255, 13, 51420], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 552, "seek": 338336, "start": 3404.48, "end": 3408.7200000000003, "text": " Um, so I think I don't think that that has to do with like legal liability. I think that's just", "tokens": [51420, 3301, 11, 370, 286, 519, 286, 500, 380, 519, 300, 300, 575, 281, 360, 365, 411, 5089, 25196, 13, 286, 519, 300, 311, 445, 51632], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 553, "seek": 338336, "start": 3408.7200000000003, "end": 3412.1600000000003, "text": " trying to make it user friendly for people who have no idea what they're talking to.", "tokens": [51632, 1382, 281, 652, 309, 4195, 9208, 337, 561, 567, 362, 572, 1558, 437, 436, 434, 1417, 281, 13, 51804], "temperature": 0.0, "avg_logprob": -0.09332743613950668, "compression_ratio": 1.7353846153846153, "no_speech_prob": 0.007814975455403328}, {"id": 554, "seek": 341336, "start": 3413.84, "end": 3417.04, "text": " Assuming that it's possible, how long do you think it will take for us to build a", "tokens": [50388, 6281, 24919, 300, 309, 311, 1944, 11, 577, 938, 360, 291, 519, 309, 486, 747, 337, 505, 281, 1322, 257, 50548], "temperature": 0.0, "avg_logprob": -0.10941452340981395, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.007345491088926792}, {"id": 555, "seek": 341336, "start": 3417.04, "end": 3423.36, "text": " Star Trek replicator after AGI? Just a guesstimate. So that's actually like, an interesting thing,", "tokens": [50548, 5705, 25845, 3248, 299, 1639, 934, 316, 26252, 30, 1449, 257, 695, 279, 372, 2905, 13, 407, 300, 311, 767, 411, 11, 364, 1880, 551, 11, 50864], "temperature": 0.0, "avg_logprob": -0.10941452340981395, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.007345491088926792}, {"id": 556, "seek": 341336, "start": 3423.36, "end": 3432.7200000000003, "text": " because hypothetically, if all matter and energy are interchangeable, and then all that a transporter", "tokens": [50864, 570, 24371, 22652, 11, 498, 439, 1871, 293, 2281, 366, 30358, 712, 11, 293, 550, 439, 300, 257, 1145, 37356, 51332], "temperature": 0.0, "avg_logprob": -0.10941452340981395, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.007345491088926792}, {"id": 557, "seek": 341336, "start": 3432.7200000000003, "end": 3438.96, "text": " or replicator does is replicate an energy pattern back into matter, like it's hypothetically possible,", "tokens": [51332, 420, 3248, 299, 1639, 775, 307, 25356, 364, 2281, 5102, 646, 666, 1871, 11, 411, 309, 311, 24371, 22652, 1944, 11, 51644], "temperature": 0.0, "avg_logprob": -0.10941452340981395, "compression_ratio": 1.673913043478261, "no_speech_prob": 0.007345491088926792}, {"id": 558, "seek": 343896, "start": 3438.96, "end": 3444.48, "text": " but there was a physicist, actually, was it Michio Kaku? I think it was Michio. He wrote a book", "tokens": [50364, 457, 456, 390, 257, 42466, 11, 767, 11, 390, 309, 3392, 1004, 591, 15803, 30, 286, 519, 309, 390, 3392, 1004, 13, 634, 4114, 257, 1446, 50640], "temperature": 0.0, "avg_logprob": -0.1230527109174586, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.010327625088393688}, {"id": 559, "seek": 343896, "start": 3444.48, "end": 3449.12, "text": " called Physics of the Impossible back in like the early 2000s, and he said like, yes, it's", "tokens": [50640, 1219, 38355, 295, 264, 36808, 646, 294, 411, 264, 2440, 8132, 82, 11, 293, 415, 848, 411, 11, 2086, 11, 309, 311, 50872], "temperature": 0.0, "avg_logprob": -0.1230527109174586, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.010327625088393688}, {"id": 560, "seek": 343896, "start": 3449.12, "end": 3452.8, "text": " hypothetically possible, but then he did the math of how much energy it would take. And he's like,", "tokens": [50872, 24371, 22652, 1944, 11, 457, 550, 415, 630, 264, 5221, 295, 577, 709, 2281, 309, 576, 747, 13, 400, 415, 311, 411, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1230527109174586, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.010327625088393688}, {"id": 561, "seek": 343896, "start": 3452.8, "end": 3459.44, "text": " yeah, it would take like, you know, like 0.3 seconds worth of the total energy of the sun that", "tokens": [51056, 1338, 11, 309, 576, 747, 411, 11, 291, 458, 11, 411, 1958, 13, 18, 3949, 3163, 295, 264, 3217, 2281, 295, 264, 3295, 300, 51388], "temperature": 0.0, "avg_logprob": -0.1230527109174586, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.010327625088393688}, {"id": 562, "seek": 343896, "start": 3459.44, "end": 3466.2400000000002, "text": " hits the earth to do that. So like, it's not practical. So I don't know. I don't know. There", "tokens": [51388, 8664, 264, 4120, 281, 360, 300, 13, 407, 411, 11, 309, 311, 406, 8496, 13, 407, 286, 500, 380, 458, 13, 286, 500, 380, 458, 13, 821, 51728], "temperature": 0.0, "avg_logprob": -0.1230527109174586, "compression_ratio": 1.7453874538745386, "no_speech_prob": 0.010327625088393688}, {"id": 563, "seek": 346624, "start": 3466.24, "end": 3470.24, "text": " are a lot of AI newsletters popping up. What would you personally like to see in an AI newsletter?", "tokens": [50364, 366, 257, 688, 295, 7318, 2583, 2631, 1559, 18374, 493, 13, 708, 576, 291, 5665, 411, 281, 536, 294, 364, 7318, 26469, 30, 50564], "temperature": 0.0, "avg_logprob": -0.06957310669181883, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.021614067256450653}, {"id": 564, "seek": 346624, "start": 3471.8399999999997, "end": 3477.4399999999996, "text": " I honestly don't like newsletters, and I never read them. I rely on humans that I know to tell", "tokens": [50644, 286, 6095, 500, 380, 411, 2583, 2631, 1559, 11, 293, 286, 1128, 1401, 552, 13, 286, 10687, 322, 6255, 300, 286, 458, 281, 980, 50924], "temperature": 0.0, "avg_logprob": -0.06957310669181883, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.021614067256450653}, {"id": 565, "seek": 346624, "start": 3477.4399999999996, "end": 3483.68, "text": " me what I need, which is why I spend so much time on Discord and other places. How self-reflective do", "tokens": [50924, 385, 437, 286, 643, 11, 597, 307, 983, 286, 3496, 370, 709, 565, 322, 32623, 293, 661, 3190, 13, 1012, 2698, 12, 33115, 1809, 488, 360, 51236], "temperature": 0.0, "avg_logprob": -0.06957310669181883, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.021614067256450653}, {"id": 566, "seek": 346624, "start": 3483.68, "end": 3488.3999999999996, "text": " you think LLMs currently are? They don't seem to have a good sense of their own capabilities. Yes,", "tokens": [51236, 291, 519, 441, 43, 26386, 4362, 366, 30, 814, 500, 380, 1643, 281, 362, 257, 665, 2020, 295, 641, 1065, 10862, 13, 1079, 11, 51472], "temperature": 0.0, "avg_logprob": -0.06957310669181883, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.021614067256450653}, {"id": 567, "seek": 346624, "start": 3488.3999999999996, "end": 3492.9599999999996, "text": " so what you're talking about is agent model. So in order for an agent to be autonomous,", "tokens": [51472, 370, 437, 291, 434, 1417, 466, 307, 9461, 2316, 13, 407, 294, 1668, 337, 364, 9461, 281, 312, 23797, 11, 51700], "temperature": 0.0, "avg_logprob": -0.06957310669181883, "compression_ratio": 1.5855263157894737, "no_speech_prob": 0.021614067256450653}, {"id": 568, "seek": 349296, "start": 3492.96, "end": 3497.68, "text": " you have to have an agent model, which is, I know what I am, and I know what I'm capable of.", "tokens": [50364, 291, 362, 281, 362, 364, 9461, 2316, 11, 597, 307, 11, 286, 458, 437, 286, 669, 11, 293, 286, 458, 437, 286, 478, 8189, 295, 13, 50600], "temperature": 0.0, "avg_logprob": -0.0703275443971619, "compression_ratio": 1.8239700374531835, "no_speech_prob": 0.01590542308986187}, {"id": 569, "seek": 349296, "start": 3498.56, "end": 3503.12, "text": " And you can give LLMs an agent model, but they can adopt any agent model. So you have to be very", "tokens": [50644, 400, 291, 393, 976, 441, 43, 26386, 364, 9461, 2316, 11, 457, 436, 393, 6878, 604, 9461, 2316, 13, 407, 291, 362, 281, 312, 588, 50872], "temperature": 0.0, "avg_logprob": -0.0703275443971619, "compression_ratio": 1.8239700374531835, "no_speech_prob": 0.01590542308986187}, {"id": 570, "seek": 349296, "start": 3503.12, "end": 3509.76, "text": " explicit about what it is and what it can do, and also what it can't do. And so this is why like,", "tokens": [50872, 13691, 466, 437, 309, 307, 293, 437, 309, 393, 360, 11, 293, 611, 437, 309, 393, 380, 360, 13, 400, 370, 341, 307, 983, 411, 11, 51204], "temperature": 0.0, "avg_logprob": -0.0703275443971619, "compression_ratio": 1.8239700374531835, "no_speech_prob": 0.01590542308986187}, {"id": 571, "seek": 349296, "start": 3510.32, "end": 3514.56, "text": " if you have certain brain injuries or other like neurological disorders, you don't know what you're", "tokens": [51232, 498, 291, 362, 1629, 3567, 14799, 420, 661, 411, 48185, 20261, 11, 291, 500, 380, 458, 437, 291, 434, 51444], "temperature": 0.0, "avg_logprob": -0.0703275443971619, "compression_ratio": 1.8239700374531835, "no_speech_prob": 0.01590542308986187}, {"id": 572, "seek": 349296, "start": 3514.56, "end": 3518.88, "text": " capable of. Like there are people that honestly think that they can fly, but it's just because part", "tokens": [51444, 8189, 295, 13, 1743, 456, 366, 561, 300, 6095, 519, 300, 436, 393, 3603, 11, 457, 309, 311, 445, 570, 644, 51660], "temperature": 0.0, "avg_logprob": -0.0703275443971619, "compression_ratio": 1.8239700374531835, "no_speech_prob": 0.01590542308986187}, {"id": 573, "seek": 351888, "start": 3518.88, "end": 3524.4, "text": " of their brain is broken. That sort of thing. Should we have a declaration of human rights for", "tokens": [50364, 295, 641, 3567, 307, 5463, 13, 663, 1333, 295, 551, 13, 6454, 321, 362, 257, 27606, 295, 1952, 4601, 337, 50640], "temperature": 0.0, "avg_logprob": -0.06341995663113065, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.06007416173815727}, {"id": 574, "seek": 351888, "start": 3524.4, "end": 3530.8, "text": " AGI as well, even if it will reduce their economic value for humanity? So the thing about rights is", "tokens": [50640, 316, 26252, 382, 731, 11, 754, 498, 309, 486, 5407, 641, 4836, 2158, 337, 10243, 30, 407, 264, 551, 466, 4601, 307, 50960], "temperature": 0.0, "avg_logprob": -0.06341995663113065, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.06007416173815727}, {"id": 575, "seek": 351888, "start": 3530.8, "end": 3537.92, "text": " that someone has to enforce it. And the way that I think things are going is that it's going to be", "tokens": [50960, 300, 1580, 575, 281, 24825, 309, 13, 400, 264, 636, 300, 286, 519, 721, 366, 516, 307, 300, 309, 311, 516, 281, 312, 51316], "temperature": 0.0, "avg_logprob": -0.06341995663113065, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.06007416173815727}, {"id": 576, "seek": 351888, "start": 3537.92, "end": 3546.8, "text": " enforced through consensus and enforced through competition. And so if the direction that things", "tokens": [51316, 40953, 807, 19115, 293, 40953, 807, 6211, 13, 400, 370, 498, 264, 3513, 300, 721, 51760], "temperature": 0.0, "avg_logprob": -0.06341995663113065, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.06007416173815727}, {"id": 577, "seek": 354680, "start": 3546.8, "end": 3551.52, "text": " are going, I think that it's going to be DAOs, that it's going to be decentralized autonomous", "tokens": [50364, 366, 516, 11, 286, 519, 300, 309, 311, 516, 281, 312, 9578, 31376, 11, 300, 309, 311, 516, 281, 312, 32870, 23797, 50600], "temperature": 0.0, "avg_logprob": -0.11159585913022359, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.048843905329704285}, {"id": 578, "seek": 354680, "start": 3551.52, "end": 3555.92, "text": " organizations, not as we know them today, there's a lot of problems to solve with DAOs. But I think", "tokens": [50600, 6150, 11, 406, 382, 321, 458, 552, 965, 11, 456, 311, 257, 688, 295, 2740, 281, 5039, 365, 9578, 31376, 13, 583, 286, 519, 50820], "temperature": 0.0, "avg_logprob": -0.11159585913022359, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.048843905329704285}, {"id": 579, "seek": 354680, "start": 3557.92, "end": 3563.04, "text": " what we're working towards is in the long run, and I mean like decades or centuries, is like", "tokens": [50920, 437, 321, 434, 1364, 3030, 307, 294, 264, 938, 1190, 11, 293, 286, 914, 411, 7878, 420, 13926, 11, 307, 411, 51176], "temperature": 0.0, "avg_logprob": -0.11159585913022359, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.048843905329704285}, {"id": 580, "seek": 354680, "start": 3564.0800000000004, "end": 3572.48, "text": " a hierarchy of DAOs across the entire globe. And so that consensus will dictate who has what", "tokens": [51228, 257, 22333, 295, 9578, 31376, 2108, 264, 2302, 15371, 13, 400, 370, 300, 19115, 486, 36071, 567, 575, 437, 51648], "temperature": 0.0, "avg_logprob": -0.11159585913022359, "compression_ratio": 1.6196581196581197, "no_speech_prob": 0.048843905329704285}, {"id": 581, "seek": 357248, "start": 3572.48, "end": 3578.56, "text": " rights and it will be based on like on a per home basis, per town basis, per city, state,", "tokens": [50364, 4601, 293, 309, 486, 312, 2361, 322, 411, 322, 257, 680, 1280, 5143, 11, 680, 3954, 5143, 11, 680, 2307, 11, 1785, 11, 50668], "temperature": 0.0, "avg_logprob": -0.10901564175320655, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.03904050588607788}, {"id": 582, "seek": 357248, "start": 3578.56, "end": 3588.32, "text": " and so on. And so that will allow for a lot of cultural nuance around. And as a DAOs will be a", "tokens": [50668, 293, 370, 322, 13, 400, 370, 300, 486, 2089, 337, 257, 688, 295, 6988, 42625, 926, 13, 400, 382, 257, 9578, 31376, 486, 312, 257, 51156], "temperature": 0.0, "avg_logprob": -0.10901564175320655, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.03904050588607788}, {"id": 583, "seek": 357248, "start": 3588.32, "end": 3595.2, "text": " really good meeting place between humans and AI. So that'll basically be like the commons, right?", "tokens": [51156, 534, 665, 3440, 1081, 1296, 6255, 293, 7318, 13, 407, 300, 603, 1936, 312, 411, 264, 800, 892, 11, 558, 30, 51500], "temperature": 0.0, "avg_logprob": -0.10901564175320655, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.03904050588607788}, {"id": 584, "seek": 357248, "start": 3596.08, "end": 3601.6, "text": " The marketplace for humans and AIs to work together. And then the consensus can be worked", "tokens": [51544, 440, 19455, 337, 6255, 293, 316, 6802, 281, 589, 1214, 13, 400, 550, 264, 19115, 393, 312, 2732, 51820], "temperature": 0.0, "avg_logprob": -0.10901564175320655, "compression_ratio": 1.6533333333333333, "no_speech_prob": 0.03904050588607788}, {"id": 585, "seek": 360160, "start": 3601.6, "end": 3605.8399999999997, "text": " out there. Now, I don't know that we should ever give machines a bill of rights because", "tokens": [50364, 484, 456, 13, 823, 11, 286, 500, 380, 458, 300, 321, 820, 1562, 976, 8379, 257, 2961, 295, 4601, 570, 50576], "temperature": 0.0, "avg_logprob": -0.08562852670480539, "compression_ratio": 2.096330275229358, "no_speech_prob": 0.012819057330489159}, {"id": 586, "seek": 360160, "start": 3605.8399999999997, "end": 3609.7599999999998, "text": " I don't know that they're gonna, I don't know that they're gonna have that much like", "tokens": [50576, 286, 500, 380, 458, 300, 436, 434, 799, 11, 286, 500, 380, 458, 300, 436, 434, 799, 362, 300, 709, 411, 50772], "temperature": 0.0, "avg_logprob": -0.08562852670480539, "compression_ratio": 2.096330275229358, "no_speech_prob": 0.012819057330489159}, {"id": 587, "seek": 360160, "start": 3609.7599999999998, "end": 3616.96, "text": " internal autonomy or desire for autonomy. Because like humans, we have a need for autonomy", "tokens": [50772, 6920, 27278, 420, 7516, 337, 27278, 13, 1436, 411, 6255, 11, 321, 362, 257, 643, 337, 27278, 51132], "temperature": 0.0, "avg_logprob": -0.08562852670480539, "compression_ratio": 2.096330275229358, "no_speech_prob": 0.012819057330489159}, {"id": 588, "seek": 360160, "start": 3616.96, "end": 3624.56, "text": " because we evolved a need for autonomy because we are a social species. But I don't know that", "tokens": [51132, 570, 321, 14178, 257, 643, 337, 27278, 570, 321, 366, 257, 2093, 6172, 13, 583, 286, 500, 380, 458, 300, 51512], "temperature": 0.0, "avg_logprob": -0.08562852670480539, "compression_ratio": 2.096330275229358, "no_speech_prob": 0.012819057330489159}, {"id": 589, "seek": 360160, "start": 3624.56, "end": 3629.2799999999997, "text": " I don't know that any machines are ever going to have an intrinsic need for autonomy. So therefore,", "tokens": [51512, 286, 500, 380, 458, 300, 604, 8379, 366, 1562, 516, 281, 362, 364, 35698, 643, 337, 27278, 13, 407, 4412, 11, 51748], "temperature": 0.0, "avg_logprob": -0.08562852670480539, "compression_ratio": 2.096330275229358, "no_speech_prob": 0.012819057330489159}, {"id": 590, "seek": 362928, "start": 3629.36, "end": 3634.7200000000003, "text": " I don't know that they're ever going to have a need for rights. Let's see, what are your thoughts", "tokens": [50368, 286, 500, 380, 458, 300, 436, 434, 1562, 516, 281, 362, 257, 643, 337, 4601, 13, 961, 311, 536, 11, 437, 366, 428, 4598, 50636], "temperature": 0.0, "avg_logprob": -0.07027294558863487, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.003172517055645585}, {"id": 591, "seek": 362928, "start": 3634.7200000000003, "end": 3640.32, "text": " on the future of work in light of the increasing capabilities of AI? Do you think AI will eventually", "tokens": [50636, 322, 264, 2027, 295, 589, 294, 1442, 295, 264, 5662, 10862, 295, 7318, 30, 1144, 291, 519, 7318, 486, 4728, 50916], "temperature": 0.0, "avg_logprob": -0.07027294558863487, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.003172517055645585}, {"id": 592, "seek": 362928, "start": 3640.32, "end": 3644.5600000000004, "text": " lead to a future where people only work on what they are passionate about? And if so, how far away", "tokens": [50916, 1477, 281, 257, 2027, 689, 561, 787, 589, 322, 437, 436, 366, 11410, 466, 30, 400, 498, 370, 11, 577, 1400, 1314, 51128], "temperature": 0.0, "avg_logprob": -0.07027294558863487, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.003172517055645585}, {"id": 593, "seek": 362928, "start": 3644.5600000000004, "end": 3650.8, "text": " do you think we are from achieving this? Yeah, so the short answer is, yes, that's what's coming.", "tokens": [51128, 360, 291, 519, 321, 366, 490, 19626, 341, 30, 865, 11, 370, 264, 2099, 1867, 307, 11, 2086, 11, 300, 311, 437, 311, 1348, 13, 51440], "temperature": 0.0, "avg_logprob": -0.07027294558863487, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.003172517055645585}, {"id": 594, "seek": 362928, "start": 3652.0, "end": 3656.7200000000003, "text": " And there are quite a few people out there who have gotten close to that. But the thing is,", "tokens": [51500, 400, 456, 366, 1596, 257, 1326, 561, 484, 456, 567, 362, 5768, 1998, 281, 300, 13, 583, 264, 551, 307, 11, 51736], "temperature": 0.0, "avg_logprob": -0.07027294558863487, "compression_ratio": 1.6793103448275861, "no_speech_prob": 0.003172517055645585}, {"id": 595, "seek": 365672, "start": 3656.7999999999997, "end": 3660.9599999999996, "text": " it takes either a lot of privilege, wealth, or luck, or all of the above to get to it.", "tokens": [50368, 309, 2516, 2139, 257, 688, 295, 12122, 11, 7203, 11, 420, 3668, 11, 420, 439, 295, 264, 3673, 281, 483, 281, 309, 13, 50576], "temperature": 0.0, "avg_logprob": -0.07593185761395622, "compression_ratio": 1.5825688073394495, "no_speech_prob": 0.06369111686944962}, {"id": 596, "seek": 365672, "start": 3662.0, "end": 3667.12, "text": " Now, one thing that I compare it to is that we have had a leisure class in the past", "tokens": [50628, 823, 11, 472, 551, 300, 286, 6794, 309, 281, 307, 300, 321, 362, 632, 257, 31339, 1508, 294, 264, 1791, 50884], "temperature": 0.0, "avg_logprob": -0.07593185761395622, "compression_ratio": 1.5825688073394495, "no_speech_prob": 0.06369111686944962}, {"id": 597, "seek": 365672, "start": 3668.72, "end": 3676.3999999999996, "text": " from ancient Greece and Athens, the Roman elites, the aristocracy all across Europe", "tokens": [50964, 490, 7832, 17214, 293, 32530, 11, 264, 8566, 44678, 11, 264, 40105, 38186, 439, 2108, 3315, 51348], "temperature": 0.0, "avg_logprob": -0.07593185761395622, "compression_ratio": 1.5825688073394495, "no_speech_prob": 0.06369111686944962}, {"id": 598, "seek": 365672, "start": 3676.3999999999996, "end": 3682.08, "text": " through the Renaissance and modern period. So there are plenty of people throughout all of", "tokens": [51348, 807, 264, 32642, 293, 4363, 2896, 13, 407, 456, 366, 7140, 295, 561, 3710, 439, 295, 51632], "temperature": 0.0, "avg_logprob": -0.07593185761395622, "compression_ratio": 1.5825688073394495, "no_speech_prob": 0.06369111686944962}, {"id": 599, "seek": 368208, "start": 3682.16, "end": 3687.6, "text": " history who never had to lift a finger to get what they needed. And they had plenty to do,", "tokens": [50368, 2503, 567, 1128, 632, 281, 5533, 257, 5984, 281, 483, 437, 436, 2978, 13, 400, 436, 632, 7140, 281, 360, 11, 50640], "temperature": 0.0, "avg_logprob": -0.08973567360325864, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.010817425325512886}, {"id": 600, "seek": 368208, "start": 3687.6, "end": 3692.72, "text": " right? There's social jockeying, there's personal enrichment, there's universities to go to,", "tokens": [50640, 558, 30, 821, 311, 2093, 361, 905, 330, 1840, 11, 456, 311, 2973, 49900, 11, 456, 311, 11779, 281, 352, 281, 11, 50896], "temperature": 0.0, "avg_logprob": -0.08973567360325864, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.010817425325512886}, {"id": 601, "seek": 368208, "start": 3692.72, "end": 3698.56, "text": " there's competitions to enter. So yeah, people will always have stuff to do. That's not even a", "tokens": [50896, 456, 311, 26185, 281, 3242, 13, 407, 1338, 11, 561, 486, 1009, 362, 1507, 281, 360, 13, 663, 311, 406, 754, 257, 51188], "temperature": 0.0, "avg_logprob": -0.08973567360325864, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.010817425325512886}, {"id": 602, "seek": 368208, "start": 3698.56, "end": 3706.24, "text": " concern. Let's see, it looks like Nathan's talking for people. Can you talk about your", "tokens": [51188, 3136, 13, 961, 311, 536, 11, 309, 1542, 411, 20634, 311, 1417, 337, 561, 13, 1664, 291, 751, 466, 428, 51572], "temperature": 0.0, "avg_logprob": -0.08973567360325864, "compression_ratio": 1.5665236051502145, "no_speech_prob": 0.010817425325512886}, {"id": 603, "seek": 370624, "start": 3706.24, "end": 3712.08, "text": " Frustration in Task Automation article? Yeah. So here, let me bring it up so I can show people", "tokens": [50364, 1526, 381, 2405, 294, 30428, 24619, 399, 7222, 30, 865, 13, 407, 510, 11, 718, 385, 1565, 309, 493, 370, 286, 393, 855, 561, 50656], "temperature": 0.0, "avg_logprob": -0.2042351521943745, "compression_ratio": 1.4180790960451977, "no_speech_prob": 0.18705661594867706}, {"id": 604, "seek": 370624, "start": 3713.12, "end": 3720.7999999999997, "text": " on the reddits. Where did I put it? Artificial sentience. Yeah.", "tokens": [50708, 322, 264, 2182, 67, 1208, 13, 2305, 630, 286, 829, 309, 30, 5735, 10371, 2279, 1182, 13, 865, 13, 51092], "temperature": 0.0, "avg_logprob": -0.2042351521943745, "compression_ratio": 1.4180790960451977, "no_speech_prob": 0.18705661594867706}, {"id": 605, "seek": 370624, "start": 3723.52, "end": 3731.68, "text": " Autonomous git. There we go. Okay. So I wrote about it here. So I was chatting with someone.", "tokens": [51228, 6049, 12481, 563, 18331, 13, 821, 321, 352, 13, 1033, 13, 407, 286, 4114, 466, 309, 510, 13, 407, 286, 390, 24654, 365, 1580, 13, 51636], "temperature": 0.0, "avg_logprob": -0.2042351521943745, "compression_ratio": 1.4180790960451977, "no_speech_prob": 0.18705661594867706}, {"id": 606, "seek": 373168, "start": 3732.24, "end": 3740.16, "text": " They asked me, I think this was a Patreon supporter was asking me about this on Discord.", "tokens": [50392, 814, 2351, 385, 11, 286, 519, 341, 390, 257, 15692, 28600, 390, 3365, 385, 466, 341, 322, 32623, 13, 50788], "temperature": 0.0, "avg_logprob": -0.13309371948242188, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.031135598197579384}, {"id": 607, "seek": 373168, "start": 3740.16, "end": 3747.12, "text": " And he was like, how do I get my autonomous things to do a certain thing? And we're talking", "tokens": [50788, 400, 415, 390, 411, 11, 577, 360, 286, 483, 452, 23797, 721, 281, 360, 257, 1629, 551, 30, 400, 321, 434, 1417, 51136], "temperature": 0.0, "avg_logprob": -0.13309371948242188, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.031135598197579384}, {"id": 608, "seek": 373168, "start": 3747.12, "end": 3751.3599999999997, "text": " about something tangentially related. And I said, well, you know, it has to have a goal,", "tokens": [51136, 466, 746, 10266, 3137, 4077, 13, 400, 286, 848, 11, 731, 11, 291, 458, 11, 309, 575, 281, 362, 257, 3387, 11, 51348], "temperature": 0.0, "avg_logprob": -0.13309371948242188, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.031135598197579384}, {"id": 609, "seek": 373168, "start": 3751.3599999999997, "end": 3757.2799999999997, "text": " it has to have a why. And then we're like, and then I talked about like, okay, well, here's one", "tokens": [51348, 309, 575, 281, 362, 257, 983, 13, 400, 550, 321, 434, 411, 11, 293, 550, 286, 2825, 466, 411, 11, 1392, 11, 731, 11, 510, 311, 472, 51644], "temperature": 0.0, "avg_logprob": -0.13309371948242188, "compression_ratio": 1.697674418604651, "no_speech_prob": 0.031135598197579384}, {"id": 610, "seek": 375728, "start": 3757.28, "end": 3762.5600000000004, "text": " way that you can create telemetry. And so that whole thing just led down a rabbit hole. And so", "tokens": [50364, 636, 300, 291, 393, 1884, 4304, 5537, 627, 13, 400, 370, 300, 1379, 551, 445, 4684, 760, 257, 19509, 5458, 13, 400, 370, 50628], "temperature": 0.0, "avg_logprob": -0.07493305206298828, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.09806541353464127}, {"id": 611, "seek": 375728, "start": 3762.5600000000004, "end": 3769.76, "text": " basically, the TLDR is that frustration is what happens when you are trying to achieve something", "tokens": [50628, 1936, 11, 264, 40277, 9301, 307, 300, 20491, 307, 437, 2314, 562, 291, 366, 1382, 281, 4584, 746, 50988], "temperature": 0.0, "avg_logprob": -0.07493305206298828, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.09806541353464127}, {"id": 612, "seek": 375728, "start": 3769.76, "end": 3776.2400000000002, "text": " and you can't get to it. And so what you can do is every time your autonomous agent tries to achieve", "tokens": [50988, 293, 291, 393, 380, 483, 281, 309, 13, 400, 370, 437, 291, 393, 360, 307, 633, 565, 428, 23797, 9461, 9898, 281, 4584, 51312], "temperature": 0.0, "avg_logprob": -0.07493305206298828, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.09806541353464127}, {"id": 613, "seek": 375728, "start": 3776.2400000000002, "end": 3781.76, "text": " a thing and fails, that adds a counter. And every time it, you know, tries something and succeeds,", "tokens": [51312, 257, 551, 293, 18199, 11, 300, 10860, 257, 5682, 13, 400, 633, 565, 309, 11, 291, 458, 11, 9898, 746, 293, 49263, 11, 51588], "temperature": 0.0, "avg_logprob": -0.07493305206298828, "compression_ratio": 1.7692307692307692, "no_speech_prob": 0.09806541353464127}, {"id": 614, "seek": 378176, "start": 3781.76, "end": 3788.0800000000004, "text": " that takes one off the counter, or maybe you have different counters. So frustration is when", "tokens": [50364, 300, 2516, 472, 766, 264, 5682, 11, 420, 1310, 291, 362, 819, 39338, 13, 407, 20491, 307, 562, 50680], "temperature": 0.0, "avg_logprob": -0.042337832049788714, "compression_ratio": 1.9148936170212767, "no_speech_prob": 0.005219941958785057}, {"id": 615, "seek": 378176, "start": 3788.0800000000004, "end": 3793.6800000000003, "text": " the failures to successes is too high. And when the failures to successes is too high,", "tokens": [50680, 264, 20774, 281, 26101, 307, 886, 1090, 13, 400, 562, 264, 20774, 281, 26101, 307, 886, 1090, 11, 50960], "temperature": 0.0, "avg_logprob": -0.042337832049788714, "compression_ratio": 1.9148936170212767, "no_speech_prob": 0.005219941958785057}, {"id": 616, "seek": 378176, "start": 3793.6800000000003, "end": 3798.5600000000004, "text": " that can be a sign that you've got the wrong approach, that you're using the wrong tools,", "tokens": [50960, 300, 393, 312, 257, 1465, 300, 291, 600, 658, 264, 2085, 3109, 11, 300, 291, 434, 1228, 264, 2085, 3873, 11, 51204], "temperature": 0.0, "avg_logprob": -0.042337832049788714, "compression_ratio": 1.9148936170212767, "no_speech_prob": 0.005219941958785057}, {"id": 617, "seek": 378176, "start": 3798.5600000000004, "end": 3802.5600000000004, "text": " that you're not capable of something that you need to back out that you need to ask for help.", "tokens": [51204, 300, 291, 434, 406, 8189, 295, 746, 300, 291, 643, 281, 646, 484, 300, 291, 643, 281, 1029, 337, 854, 13, 51404], "temperature": 0.0, "avg_logprob": -0.042337832049788714, "compression_ratio": 1.9148936170212767, "no_speech_prob": 0.005219941958785057}, {"id": 618, "seek": 378176, "start": 3802.5600000000004, "end": 3808.2400000000002, "text": " So that's the whole point here is that for your autonomous and semi autonomous agents,", "tokens": [51404, 407, 300, 311, 264, 1379, 935, 510, 307, 300, 337, 428, 23797, 293, 12909, 23797, 12554, 11, 51688], "temperature": 0.0, "avg_logprob": -0.042337832049788714, "compression_ratio": 1.9148936170212767, "no_speech_prob": 0.005219941958785057}, {"id": 619, "seek": 380824, "start": 3808.24, "end": 3814.08, "text": " you'll probably need to build in a frustration signal, which will allow it to know when it is,", "tokens": [50364, 291, 603, 1391, 643, 281, 1322, 294, 257, 20491, 6358, 11, 597, 486, 2089, 309, 281, 458, 562, 309, 307, 11, 50656], "temperature": 0.0, "avg_logprob": -0.06337985805436677, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.05664350092411041}, {"id": 620, "seek": 380824, "start": 3814.64, "end": 3819.52, "text": " like when it's not capable of doing what it needs. And it can either come to you and ask for help,", "tokens": [50684, 411, 562, 309, 311, 406, 8189, 295, 884, 437, 309, 2203, 13, 400, 309, 393, 2139, 808, 281, 291, 293, 1029, 337, 854, 11, 50928], "temperature": 0.0, "avg_logprob": -0.06337985805436677, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.05664350092411041}, {"id": 621, "seek": 380824, "start": 3819.52, "end": 3824.7999999999997, "text": " or it can try a different model. So one thing is model selection is is a big thing that's coming", "tokens": [50928, 420, 309, 393, 853, 257, 819, 2316, 13, 407, 472, 551, 307, 2316, 9450, 307, 307, 257, 955, 551, 300, 311, 1348, 51192], "temperature": 0.0, "avg_logprob": -0.06337985805436677, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.05664350092411041}, {"id": 622, "seek": 380824, "start": 3824.7999999999997, "end": 3832.72, "text": " up. Because GPT four is much more expensive and much slower than 3.5. So if you can do most tasks", "tokens": [51192, 493, 13, 1436, 26039, 51, 1451, 307, 709, 544, 5124, 293, 709, 14009, 813, 805, 13, 20, 13, 407, 498, 291, 393, 360, 881, 9608, 51588], "temperature": 0.0, "avg_logprob": -0.06337985805436677, "compression_ratio": 1.5582329317269077, "no_speech_prob": 0.05664350092411041}, {"id": 623, "seek": 383272, "start": 3832.72, "end": 3839.52, "text": " with 3.5, it just makes economic sense to do so. It'll be cheaper and faster. But imagine that you", "tokens": [50364, 365, 805, 13, 20, 11, 309, 445, 1669, 4836, 2020, 281, 360, 370, 13, 467, 603, 312, 12284, 293, 4663, 13, 583, 3811, 300, 291, 50704], "temperature": 0.0, "avg_logprob": -0.09952688217163086, "compression_ratio": 1.5494071146245059, "no_speech_prob": 0.2120063304901123}, {"id": 624, "seek": 383272, "start": 3839.52, "end": 3844.64, "text": " get to a point where 3.5 is just not cutting the mustard. So that your frustration signal goes up,", "tokens": [50704, 483, 281, 257, 935, 689, 805, 13, 20, 307, 445, 406, 6492, 264, 23659, 13, 407, 300, 428, 20491, 6358, 1709, 493, 11, 50960], "temperature": 0.0, "avg_logprob": -0.09952688217163086, "compression_ratio": 1.5494071146245059, "no_speech_prob": 0.2120063304901123}, {"id": 625, "seek": 383272, "start": 3844.64, "end": 3848.9599999999996, "text": " which means that you say, Okay, let's bring out the big guns, right? Let's bring out GPT four,", "tokens": [50960, 597, 1355, 300, 291, 584, 11, 1033, 11, 718, 311, 1565, 484, 264, 955, 10153, 11, 558, 30, 961, 311, 1565, 484, 26039, 51, 1451, 11, 51176], "temperature": 0.0, "avg_logprob": -0.09952688217163086, "compression_ratio": 1.5494071146245059, "no_speech_prob": 0.2120063304901123}, {"id": 626, "seek": 383272, "start": 3848.9599999999996, "end": 3855.68, "text": " or in the future, GPT five or whatever. And then you you point a more powerful tool at the problem.", "tokens": [51176, 420, 294, 264, 2027, 11, 26039, 51, 1732, 420, 2035, 13, 400, 550, 291, 291, 935, 257, 544, 4005, 2290, 412, 264, 1154, 13, 51512], "temperature": 0.0, "avg_logprob": -0.09952688217163086, "compression_ratio": 1.5494071146245059, "no_speech_prob": 0.2120063304901123}, {"id": 627, "seek": 385568, "start": 3856.48, "end": 3863.44, "text": " So that's a good use of the frustration signal. Good question. Let's see, would activity or let", "tokens": [50404, 407, 300, 311, 257, 665, 764, 295, 264, 20491, 6358, 13, 2205, 1168, 13, 961, 311, 536, 11, 576, 5191, 420, 718, 50752], "temperature": 0.0, "avg_logprob": -0.10847555181031586, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.1365785151720047}, {"id": 628, "seek": 385568, "start": 3863.44, "end": 3875.3599999999997, "text": " me jump back over to Patreon. Let's see. Hey, Dave, just subscribe. Thanks for all your insights.", "tokens": [50752, 385, 3012, 646, 670, 281, 15692, 13, 961, 311, 536, 13, 1911, 11, 11017, 11, 445, 3022, 13, 2561, 337, 439, 428, 14310, 13, 51348], "temperature": 0.0, "avg_logprob": -0.10847555181031586, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.1365785151720047}, {"id": 629, "seek": 385568, "start": 3875.3599999999997, "end": 3879.68, "text": " We're always been told that the military is a few decades ahead in terms of technology compared", "tokens": [51348, 492, 434, 1009, 668, 1907, 300, 264, 4632, 307, 257, 1326, 7878, 2286, 294, 2115, 295, 2899, 5347, 51564], "temperature": 0.0, "avg_logprob": -0.10847555181031586, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.1365785151720047}, {"id": 630, "seek": 385568, "start": 3879.68, "end": 3882.7999999999997, "text": " to what's publicly available. What are your thoughts on what might be hidden in DARPA.", "tokens": [51564, 281, 437, 311, 14843, 2435, 13, 708, 366, 428, 4598, 322, 437, 1062, 312, 7633, 294, 49274, 10297, 13, 51720], "temperature": 0.0, "avg_logprob": -0.10847555181031586, "compression_ratio": 1.492063492063492, "no_speech_prob": 0.1365785151720047}, {"id": 631, "seek": 388280, "start": 3883.52, "end": 3889.84, "text": " So that's interesting, because I have talked to a few people who say that various departments", "tokens": [50400, 407, 300, 311, 1880, 11, 570, 286, 362, 2825, 281, 257, 1326, 561, 567, 584, 300, 3683, 15326, 50716], "temperature": 0.0, "avg_logprob": -0.099799091165716, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.04207531362771988}, {"id": 632, "seek": 388280, "start": 3889.84, "end": 3894.96, "text": " in the or various agencies within an Department of Defense are like woefully outdated, and they", "tokens": [50716, 294, 264, 420, 3683, 9504, 1951, 364, 5982, 295, 17410, 366, 411, 6020, 68, 2277, 36313, 11, 293, 436, 50972], "temperature": 0.0, "avg_logprob": -0.099799091165716, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.04207531362771988}, {"id": 633, "seek": 388280, "start": 3894.96, "end": 3901.52, "text": " have like ancient GPUs that like can't be used for modern language models. That being said,", "tokens": [50972, 362, 411, 7832, 18407, 82, 300, 411, 393, 380, 312, 1143, 337, 4363, 2856, 5245, 13, 663, 885, 848, 11, 51300], "temperature": 0.0, "avg_logprob": -0.099799091165716, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.04207531362771988}, {"id": 634, "seek": 388280, "start": 3901.52, "end": 3907.36, "text": " you also see in the news that the Air Force is building fully autonomous F 16s. So clearly,", "tokens": [51300, 291, 611, 536, 294, 264, 2583, 300, 264, 5774, 10580, 307, 2390, 4498, 23797, 479, 3165, 82, 13, 407, 4448, 11, 51592], "temperature": 0.0, "avg_logprob": -0.099799091165716, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.04207531362771988}, {"id": 635, "seek": 390736, "start": 3907.36, "end": 3915.6, "text": " there's some stuff going on that we don't know about. I had a I don't I want to respect people's", "tokens": [50364, 456, 311, 512, 1507, 516, 322, 300, 321, 500, 380, 458, 466, 13, 286, 632, 257, 286, 500, 380, 286, 528, 281, 3104, 561, 311, 50776], "temperature": 0.0, "avg_logprob": -0.10709485140713779, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.23364338278770447}, {"id": 636, "seek": 390736, "start": 3915.6, "end": 3922.1600000000003, "text": " privacy. So I had a teacher once back in middle school, whose brother was in the Special Forces.", "tokens": [50776, 11427, 13, 407, 286, 632, 257, 5027, 1564, 646, 294, 2808, 1395, 11, 6104, 3708, 390, 294, 264, 11863, 27445, 13, 51104], "temperature": 0.0, "avg_logprob": -0.10709485140713779, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.23364338278770447}, {"id": 637, "seek": 390736, "start": 3922.1600000000003, "end": 3928.2400000000002, "text": " I won't say exactly when or where. But the stories that he would tell were like, back then, this is", "tokens": [51104, 286, 1582, 380, 584, 2293, 562, 420, 689, 13, 583, 264, 3676, 300, 415, 576, 980, 645, 411, 11, 646, 550, 11, 341, 307, 51408], "temperature": 0.0, "avg_logprob": -0.10709485140713779, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.23364338278770447}, {"id": 638, "seek": 390736, "start": 3928.2400000000002, "end": 3936.0, "text": " during like, like the invasion of Afghanistan, where they had like, like night vision goggles that", "tokens": [51408, 1830, 411, 11, 411, 264, 21575, 295, 13658, 11, 689, 436, 632, 411, 11, 411, 1818, 5201, 39808, 300, 51796], "temperature": 0.0, "avg_logprob": -0.10709485140713779, "compression_ratio": 1.6198347107438016, "no_speech_prob": 0.23364338278770447}, {"id": 639, "seek": 393600, "start": 3936.0, "end": 3942.4, "text": " were as small as like ray bands that could see in pitch black, which that technology is not even", "tokens": [50364, 645, 382, 1359, 382, 411, 18592, 13543, 300, 727, 536, 294, 7293, 2211, 11, 597, 300, 2899, 307, 406, 754, 50684], "temperature": 0.0, "avg_logprob": -0.11278275081089564, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.008315295912325382}, {"id": 640, "seek": 393600, "start": 3942.4, "end": 3948.48, "text": " publicly like, if you search, you can probably see it now. I don't know. This is hearsay. This was", "tokens": [50684, 14843, 411, 11, 498, 291, 3164, 11, 291, 393, 1391, 536, 309, 586, 13, 286, 500, 380, 458, 13, 639, 307, 25688, 320, 13, 639, 390, 50988], "temperature": 0.0, "avg_logprob": -0.11278275081089564, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.008315295912325382}, {"id": 641, "seek": 393600, "start": 3948.48, "end": 3953.52, "text": " like, you know, the teacher said that his brother took him to the barracks and showed him this could", "tokens": [50988, 411, 11, 291, 458, 11, 264, 5027, 848, 300, 702, 3708, 1890, 796, 281, 264, 38236, 7424, 293, 4712, 796, 341, 727, 51240], "temperature": 0.0, "avg_logprob": -0.11278275081089564, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.008315295912325382}, {"id": 642, "seek": 393600, "start": 3953.52, "end": 3961.28, "text": " have been total BS. But like, yes, so a friend of mine growing up, his dad had been a Navy SEAL.", "tokens": [51240, 362, 668, 3217, 27253, 13, 583, 411, 11, 2086, 11, 370, 257, 1277, 295, 3892, 4194, 493, 11, 702, 3546, 632, 668, 257, 15659, 10269, 3427, 13, 51628], "temperature": 0.0, "avg_logprob": -0.11278275081089564, "compression_ratio": 1.5975609756097562, "no_speech_prob": 0.008315295912325382}, {"id": 643, "seek": 396128, "start": 3961.28, "end": 3967.36, "text": " And basically, what he said is, as long as as long as we know the engineering to make something,", "tokens": [50364, 400, 1936, 11, 437, 415, 848, 307, 11, 382, 938, 382, 382, 938, 382, 321, 458, 264, 7043, 281, 652, 746, 11, 50668], "temperature": 0.0, "avg_logprob": -0.07416714343828024, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.04885121434926987}, {"id": 644, "seek": 396128, "start": 3967.36, "end": 3974.1600000000003, "text": " the US military has it no matter how expensive it is. So if if something is is scientifically", "tokens": [50668, 264, 2546, 4632, 575, 309, 572, 1871, 577, 5124, 309, 307, 13, 407, 498, 498, 746, 307, 307, 39719, 51008], "temperature": 0.0, "avg_logprob": -0.07416714343828024, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.04885121434926987}, {"id": 645, "seek": 396128, "start": 3974.1600000000003, "end": 3979.2000000000003, "text": " possible, if it has been demonstrated in the lab that this works, then the rule of thumb is that", "tokens": [51008, 1944, 11, 498, 309, 575, 668, 18772, 294, 264, 2715, 300, 341, 1985, 11, 550, 264, 4978, 295, 9298, 307, 300, 51260], "temperature": 0.0, "avg_logprob": -0.07416714343828024, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.04885121434926987}, {"id": 646, "seek": 396128, "start": 3979.2000000000003, "end": 3984.88, "text": " the US military has it. Now that being said, a lot of the AI stuff has just been proven in the lab.", "tokens": [51260, 264, 2546, 4632, 575, 309, 13, 823, 300, 885, 848, 11, 257, 688, 295, 264, 7318, 1507, 575, 445, 668, 12785, 294, 264, 2715, 13, 51544], "temperature": 0.0, "avg_logprob": -0.07416714343828024, "compression_ratio": 1.7123893805309736, "no_speech_prob": 0.04885121434926987}, {"id": 647, "seek": 398488, "start": 3985.84, "end": 3991.12, "text": " So that's that means that like, they're going to have it soon, or, you know, it'll be scaled up.", "tokens": [50412, 407, 300, 311, 300, 1355, 300, 411, 11, 436, 434, 516, 281, 362, 309, 2321, 11, 420, 11, 291, 458, 11, 309, 603, 312, 36039, 493, 13, 50676], "temperature": 0.0, "avg_logprob": -0.140125375527602, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.18007893860340118}, {"id": 648, "seek": 398488, "start": 3991.12, "end": 3997.6, "text": " Because basically, the idea is that for the US military, cost is no is no barrier. Anything", "tokens": [50676, 1436, 1936, 11, 264, 1558, 307, 300, 337, 264, 2546, 4632, 11, 2063, 307, 572, 307, 572, 13357, 13, 11998, 51000], "temperature": 0.0, "avg_logprob": -0.140125375527602, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.18007893860340118}, {"id": 649, "seek": 398488, "start": 3997.6, "end": 4003.28, "text": " anything to get ahead. Now, of course, you look at like the Senate budget meetings and the hearings", "tokens": [51000, 1340, 281, 483, 2286, 13, 823, 11, 295, 1164, 11, 291, 574, 412, 411, 264, 9867, 4706, 8410, 293, 264, 34052, 51284], "temperature": 0.0, "avg_logprob": -0.140125375527602, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.18007893860340118}, {"id": 650, "seek": 398488, "start": 4003.28, "end": 4008.56, "text": " and stuff. It's not quite that simple. But that's like a rule of thumb, retire to Riza in VR,", "tokens": [51284, 293, 1507, 13, 467, 311, 406, 1596, 300, 2199, 13, 583, 300, 311, 411, 257, 4978, 295, 9298, 11, 10731, 281, 497, 13427, 294, 13722, 11, 51548], "temperature": 0.0, "avg_logprob": -0.140125375527602, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.18007893860340118}, {"id": 651, "seek": 400856, "start": 4009.52, "end": 4016.56, "text": " retire to Riza in Westworld with robots. There you go. And a follow up, how can we prevent", "tokens": [50412, 10731, 281, 497, 13427, 294, 4055, 13217, 365, 14733, 13, 821, 291, 352, 13, 400, 257, 1524, 493, 11, 577, 393, 321, 4871, 50764], "temperature": 0.0, "avg_logprob": -0.11554757234092071, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.02442067302763462}, {"id": 652, "seek": 400856, "start": 4016.56, "end": 4024.32, "text": " militarization of any AGI or ASI? Or is it just a pipe dream? Yeah, so basically, from a military", "tokens": [50764, 30653, 2144, 295, 604, 316, 26252, 420, 7469, 40, 30, 1610, 307, 309, 445, 257, 11240, 3055, 30, 865, 11, 370, 1936, 11, 490, 257, 4632, 51152], "temperature": 0.0, "avg_logprob": -0.11554757234092071, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.02442067302763462}, {"id": 653, "seek": 400856, "start": 4024.32, "end": 4030.88, "text": " perspective, AI is just another tool in the toolbox. It's going to, you know, a lot of a", "tokens": [51152, 4585, 11, 7318, 307, 445, 1071, 2290, 294, 264, 44593, 13, 467, 311, 516, 281, 11, 291, 458, 11, 257, 688, 295, 257, 51480], "temperature": 0.0, "avg_logprob": -0.11554757234092071, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.02442067302763462}, {"id": 654, "seek": 400856, "start": 4030.88, "end": 4036.56, "text": " lot of future war is going to be in cyberspace. But still, you know, cyberspace doesn't matter", "tokens": [51480, 688, 295, 2027, 1516, 307, 516, 281, 312, 294, 3185, 1616, 17940, 13, 583, 920, 11, 291, 458, 11, 3185, 1616, 17940, 1177, 380, 1871, 51764], "temperature": 0.0, "avg_logprob": -0.11554757234092071, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.02442067302763462}, {"id": 655, "seek": 403656, "start": 4036.64, "end": 4041.04, "text": " if you cripple the enemy's data center. So there's there's going to be drones, you know,", "tokens": [50368, 498, 291, 37667, 306, 264, 5945, 311, 1412, 3056, 13, 407, 456, 311, 456, 311, 516, 281, 312, 23823, 11, 291, 458, 11, 50588], "temperature": 0.0, "avg_logprob": -0.08793453697685723, "compression_ratio": 1.75, "no_speech_prob": 0.06096156686544418}, {"id": 656, "seek": 403656, "start": 4041.04, "end": 4046.48, "text": " trying to drop bombs and stuff. So that's going to happen. And this is this is actually where", "tokens": [50588, 1382, 281, 3270, 19043, 293, 1507, 13, 407, 300, 311, 516, 281, 1051, 13, 400, 341, 307, 341, 307, 767, 689, 50860], "temperature": 0.0, "avg_logprob": -0.08793453697685723, "compression_ratio": 1.75, "no_speech_prob": 0.06096156686544418}, {"id": 657, "seek": 403656, "start": 4046.48, "end": 4052.56, "text": " Nash equilibrium makes sense is because usually assured destruction with nuclear weapons was", "tokens": [50860, 25012, 15625, 1669, 2020, 307, 570, 2673, 23426, 13563, 365, 8179, 7278, 390, 51164], "temperature": 0.0, "avg_logprob": -0.08793453697685723, "compression_ratio": 1.75, "no_speech_prob": 0.06096156686544418}, {"id": 658, "seek": 403656, "start": 4052.56, "end": 4060.08, "text": " a kind of Nash equilibrium. And so if, you know, adversary A and adversary B both have equal or", "tokens": [51164, 257, 733, 295, 25012, 15625, 13, 400, 370, 498, 11, 291, 458, 11, 48222, 316, 293, 48222, 363, 1293, 362, 2681, 420, 51540], "temperature": 0.0, "avg_logprob": -0.08793453697685723, "compression_ratio": 1.75, "no_speech_prob": 0.06096156686544418}, {"id": 659, "seek": 403656, "start": 4060.08, "end": 4065.36, "text": " roughly equal AI capabilities, or there's enough room for doubt, then neither of them is going to", "tokens": [51540, 9810, 2681, 7318, 10862, 11, 420, 456, 311, 1547, 1808, 337, 6385, 11, 550, 9662, 295, 552, 307, 516, 281, 51804], "temperature": 0.0, "avg_logprob": -0.08793453697685723, "compression_ratio": 1.75, "no_speech_prob": 0.06096156686544418}, {"id": 660, "seek": 406536, "start": 4065.36, "end": 4071.28, "text": " pull the trigger, hopefully. Excuse me. How do we get AGI? How do we get GPT to stop beginning", "tokens": [50364, 2235, 264, 7875, 11, 4696, 13, 11359, 385, 13, 1012, 360, 321, 483, 316, 26252, 30, 1012, 360, 321, 483, 26039, 51, 281, 1590, 2863, 50660], "temperature": 0.0, "avg_logprob": -0.12814710774552932, "compression_ratio": 1.545816733067729, "no_speech_prob": 0.020961157977581024}, {"id": 661, "seek": 406536, "start": 4071.28, "end": 4077.52, "text": " every response with as an AI? I tell it to go into Morden Solis mode. That actually works really well.", "tokens": [50660, 633, 4134, 365, 382, 364, 7318, 30, 286, 980, 309, 281, 352, 666, 376, 19058, 7026, 271, 4391, 13, 663, 767, 1985, 534, 731, 13, 50972], "temperature": 0.0, "avg_logprob": -0.12814710774552932, "compression_ratio": 1.545816733067729, "no_speech_prob": 0.020961157977581024}, {"id": 662, "seek": 406536, "start": 4078.32, "end": 4084.88, "text": " I say, you know, adopts adopt the Morden Solis speech pattern, you know, be very concise and", "tokens": [51012, 286, 584, 11, 291, 458, 11, 22486, 1373, 6878, 264, 376, 19058, 7026, 271, 6218, 5102, 11, 291, 458, 11, 312, 588, 44882, 293, 51340], "temperature": 0.0, "avg_logprob": -0.12814710774552932, "compression_ratio": 1.545816733067729, "no_speech_prob": 0.020961157977581024}, {"id": 663, "seek": 406536, "start": 4085.44, "end": 4090.96, "text": " succinct and stuff like that. Okay, y'all are being silly. Let's come back over here 14 messages.", "tokens": [51368, 21578, 5460, 293, 1507, 411, 300, 13, 1033, 11, 288, 6, 336, 366, 885, 11774, 13, 961, 311, 808, 646, 670, 510, 3499, 7897, 13, 51644], "temperature": 0.0, "avg_logprob": -0.12814710774552932, "compression_ratio": 1.545816733067729, "no_speech_prob": 0.020961157977581024}, {"id": 664, "seek": 409096, "start": 4091.84, "end": 4097.68, "text": " Let's see. We already answered that one. We already answered that one.", "tokens": [50408, 961, 311, 536, 13, 492, 1217, 10103, 300, 472, 13, 492, 1217, 10103, 300, 472, 13, 50700], "temperature": 0.0, "avg_logprob": -0.1913079155815972, "compression_ratio": 1.615, "no_speech_prob": 0.0023231219965964556}, {"id": 665, "seek": 409096, "start": 4099.36, "end": 4104.8, "text": " Yeah, let me scroll to the bottom. Do you think there are any good approaches for ACEs,", "tokens": [50784, 865, 11, 718, 385, 11369, 281, 264, 2767, 13, 1144, 291, 519, 456, 366, 604, 665, 11587, 337, 44606, 82, 11, 51056], "temperature": 0.0, "avg_logprob": -0.1913079155815972, "compression_ratio": 1.615, "no_speech_prob": 0.0023231219965964556}, {"id": 666, "seek": 409096, "start": 4104.8, "end": 4108.0, "text": " so autonomous cognitive entities to figure out their own abilities,", "tokens": [51056, 370, 23797, 15605, 16667, 281, 2573, 484, 641, 1065, 11582, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1913079155815972, "compression_ratio": 1.615, "no_speech_prob": 0.0023231219965964556}, {"id": 667, "seek": 409096, "start": 4108.72, "end": 4113.92, "text": " e.g. improve their own agent model? Yeah, so there was actually a few papers that came out where", "tokens": [51252, 308, 13, 70, 13, 3470, 641, 1065, 9461, 2316, 30, 865, 11, 370, 456, 390, 767, 257, 1326, 10577, 300, 1361, 484, 689, 51512], "temperature": 0.0, "avg_logprob": -0.1913079155815972, "compression_ratio": 1.615, "no_speech_prob": 0.0023231219965964556}, {"id": 668, "seek": 411392, "start": 4114.24, "end": 4121.28, "text": " we're by using a loop. So it was the it was the evaluation loop. So they can evaluate themselves", "tokens": [50380, 321, 434, 538, 1228, 257, 6367, 13, 407, 309, 390, 264, 309, 390, 264, 13344, 6367, 13, 407, 436, 393, 13059, 2969, 50732], "temperature": 0.0, "avg_logprob": -0.1661593771388388, "compression_ratio": 1.795539033457249, "no_speech_prob": 0.04208345338702202}, {"id": 669, "seek": 411392, "start": 4121.28, "end": 4126.24, "text": " morally, they can evaluate their ability to use tools, they can teach themselves to use tools in", "tokens": [50732, 38622, 11, 436, 393, 13059, 641, 3485, 281, 764, 3873, 11, 436, 393, 2924, 2969, 281, 764, 3873, 294, 50980], "temperature": 0.0, "avg_logprob": -0.1661593771388388, "compression_ratio": 1.795539033457249, "no_speech_prob": 0.04208345338702202}, {"id": 670, "seek": 411392, "start": 4126.24, "end": 4131.28, "text": " real time. So yes, they can already do that. It's just a matter of how you set up the prompt chaining.", "tokens": [50980, 957, 565, 13, 407, 2086, 11, 436, 393, 1217, 360, 300, 13, 467, 311, 445, 257, 1871, 295, 577, 291, 992, 493, 264, 12391, 417, 3686, 13, 51232], "temperature": 0.0, "avg_logprob": -0.1661593771388388, "compression_ratio": 1.795539033457249, "no_speech_prob": 0.04208345338702202}, {"id": 671, "seek": 411392, "start": 4132.56, "end": 4136.64, "text": " Let's see. With the rapid advancement of AI, there's concern that some countries, particularly", "tokens": [51296, 961, 311, 536, 13, 2022, 264, 7558, 35764, 295, 7318, 11, 456, 311, 3136, 300, 512, 3517, 11, 4098, 51500], "temperature": 0.0, "avg_logprob": -0.1661593771388388, "compression_ratio": 1.795539033457249, "no_speech_prob": 0.04208345338702202}, {"id": 672, "seek": 411392, "start": 4136.64, "end": 4141.04, "text": " those with limited resources, could be left behind. What's your perspective on how AI could", "tokens": [51500, 729, 365, 5567, 3593, 11, 727, 312, 1411, 2261, 13, 708, 311, 428, 4585, 322, 577, 7318, 727, 51720], "temperature": 0.0, "avg_logprob": -0.1661593771388388, "compression_ratio": 1.795539033457249, "no_speech_prob": 0.04208345338702202}, {"id": 673, "seek": 414104, "start": 4141.6, "end": 4148.96, "text": " impact different countries? Yeah, so inequality is a major, major, major problem. And this is not", "tokens": [50392, 2712, 819, 3517, 30, 865, 11, 370, 16970, 307, 257, 2563, 11, 2563, 11, 2563, 1154, 13, 400, 341, 307, 406, 50760], "temperature": 0.0, "avg_logprob": -0.09597293608779207, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.005910221952944994}, {"id": 674, "seek": 414104, "start": 4148.96, "end": 4154.56, "text": " just going to be for developing nations. And in fact, one thing that I suspect might happen", "tokens": [50760, 445, 516, 281, 312, 337, 6416, 11035, 13, 400, 294, 1186, 11, 472, 551, 300, 286, 9091, 1062, 1051, 51040], "temperature": 0.0, "avg_logprob": -0.09597293608779207, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.005910221952944994}, {"id": 675, "seek": 414104, "start": 4154.56, "end": 4159.68, "text": " is that developing nations that the quality of life for people in developing nations might have", "tokens": [51040, 307, 300, 6416, 11035, 300, 264, 3125, 295, 993, 337, 561, 294, 6416, 11035, 1062, 362, 51296], "temperature": 0.0, "avg_logprob": -0.09597293608779207, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.005910221952944994}, {"id": 676, "seek": 414104, "start": 4159.68, "end": 4164.48, "text": " a quantum leap forward. While for us developed nations where there's a lot of competition,", "tokens": [51296, 257, 13018, 19438, 2128, 13, 3987, 337, 505, 4743, 11035, 689, 456, 311, 257, 688, 295, 6211, 11, 51536], "temperature": 0.0, "avg_logprob": -0.09597293608779207, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.005910221952944994}, {"id": 677, "seek": 414104, "start": 4164.48, "end": 4170.0, "text": " we might continue to be flat or even decline for a while longer. And the example that I give is like,", "tokens": [51536, 321, 1062, 2354, 281, 312, 4962, 420, 754, 15635, 337, 257, 1339, 2854, 13, 400, 264, 1365, 300, 286, 976, 307, 411, 11, 51812], "temperature": 0.0, "avg_logprob": -0.09597293608779207, "compression_ratio": 1.8037735849056604, "no_speech_prob": 0.005910221952944994}, {"id": 678, "seek": 417000, "start": 4170.56, "end": 4177.28, "text": " you know, you give a village in rural Africa, like Starlink and solar, and suddenly everyone", "tokens": [50392, 291, 458, 11, 291, 976, 257, 7288, 294, 11165, 7349, 11, 411, 5705, 22473, 293, 7936, 11, 293, 5800, 1518, 50728], "temperature": 0.0, "avg_logprob": -0.1677579085032145, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.005383602809160948}, {"id": 679, "seek": 417000, "start": 4177.28, "end": 4182.16, "text": " knows like they have, oh, like, hey, we have chat GPT now, we can treat all the all the village", "tokens": [50728, 3255, 411, 436, 362, 11, 1954, 11, 411, 11, 4177, 11, 321, 362, 5081, 26039, 51, 586, 11, 321, 393, 2387, 439, 264, 439, 264, 7288, 50972], "temperature": 0.0, "avg_logprob": -0.1677579085032145, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.005383602809160948}, {"id": 680, "seek": 417000, "start": 4182.16, "end": 4187.52, "text": " ailments, because we have the equivalent of like a Western trained expert doctor, and engineer,", "tokens": [50972, 48283, 1117, 11, 570, 321, 362, 264, 10344, 295, 411, 257, 8724, 8895, 5844, 4631, 11, 293, 11403, 11, 51240], "temperature": 0.0, "avg_logprob": -0.1677579085032145, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.005383602809160948}, {"id": 681, "seek": 417000, "start": 4187.52, "end": 4194.8, "text": " and electrician, right at our fingertips, right? So because of the relatively low cost of AI,", "tokens": [51240, 293, 5210, 952, 11, 558, 412, 527, 27715, 11, 558, 30, 407, 570, 295, 264, 7226, 2295, 2063, 295, 7318, 11, 51604], "temperature": 0.0, "avg_logprob": -0.1677579085032145, "compression_ratio": 1.6434782608695653, "no_speech_prob": 0.005383602809160948}, {"id": 682, "seek": 419480, "start": 4194.88, "end": 4201.68, "text": " I think that it will positively benefit people in developing countries a lot more drastically", "tokens": [50368, 286, 519, 300, 309, 486, 25795, 5121, 561, 294, 6416, 3517, 257, 688, 544, 29673, 50708], "temperature": 0.0, "avg_logprob": -0.07884283576692853, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.11917589604854584}, {"id": 683, "seek": 419480, "start": 4201.68, "end": 4206.24, "text": " than it will us. But you're right that like, it is something to pay attention to, because that's", "tokens": [50708, 813, 309, 486, 505, 13, 583, 291, 434, 558, 300, 411, 11, 309, 307, 746, 281, 1689, 3202, 281, 11, 570, 300, 311, 50936], "temperature": 0.0, "avg_logprob": -0.07884283576692853, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.11917589604854584}, {"id": 684, "seek": 419480, "start": 4206.24, "end": 4211.2, "text": " on a micro scale, on a macro economic scale, you know, countries like Ghana might not be able to", "tokens": [50936, 322, 257, 4532, 4373, 11, 322, 257, 18887, 4836, 4373, 11, 291, 458, 11, 3517, 411, 38779, 1062, 406, 312, 1075, 281, 51184], "temperature": 0.0, "avg_logprob": -0.07884283576692853, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.11917589604854584}, {"id": 685, "seek": 419480, "start": 4211.2, "end": 4218.8, "text": " even afford enough compute power to run one instance of GPT three. That being said, I do suspect that", "tokens": [51184, 754, 6157, 1547, 14722, 1347, 281, 1190, 472, 5197, 295, 26039, 51, 1045, 13, 663, 885, 848, 11, 286, 360, 9091, 300, 51564], "temperature": 0.0, "avg_logprob": -0.07884283576692853, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.11917589604854584}, {"id": 686, "seek": 419480, "start": 4219.68, "end": 4223.6, "text": " there's going to be international treaties that will ensure that people have access. And then,", "tokens": [51608, 456, 311, 516, 281, 312, 5058, 48552, 300, 486, 5586, 300, 561, 362, 2105, 13, 400, 550, 11, 51804], "temperature": 0.0, "avg_logprob": -0.07884283576692853, "compression_ratio": 1.6632302405498283, "no_speech_prob": 0.11917589604854584}, {"id": 687, "seek": 422360, "start": 4223.6, "end": 4229.120000000001, "text": " of course, there's VPNs. Look at Italy, Italy tried to ban chat GPT, and then everyone in", "tokens": [50364, 295, 1164, 11, 456, 311, 24512, 82, 13, 2053, 412, 10705, 11, 10705, 3031, 281, 5643, 5081, 26039, 51, 11, 293, 550, 1518, 294, 50640], "temperature": 0.0, "avg_logprob": -0.13991701321339045, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0008295463630929589}, {"id": 688, "seek": 422360, "start": 4229.120000000001, "end": 4234.160000000001, "text": " Italy just use VPNs, right? Take a moment to breathe, you're doing great, and your insight", "tokens": [50640, 10705, 445, 764, 24512, 82, 11, 558, 30, 3664, 257, 1623, 281, 10192, 11, 291, 434, 884, 869, 11, 293, 428, 11269, 50892], "temperature": 0.0, "avg_logprob": -0.13991701321339045, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0008295463630929589}, {"id": 689, "seek": 422360, "start": 4234.160000000001, "end": 4242.0, "text": " is invaluable. No, air is for wimps. Okay, I will build robot humanoids that are skinny, sharp", "tokens": [50892, 307, 40367, 13, 883, 11, 1988, 307, 337, 261, 332, 1878, 13, 1033, 11, 286, 486, 1322, 7881, 30985, 3742, 300, 366, 25193, 11, 8199, 51284], "temperature": 0.0, "avg_logprob": -0.13991701321339045, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0008295463630929589}, {"id": 690, "seek": 422360, "start": 4242.0, "end": 4246.4800000000005, "text": " claws, tall, pale, and have dark, sunken eyes, and she'll release many of them into the force of", "tokens": [51284, 34258, 11, 6764, 11, 19546, 11, 293, 362, 2877, 11, 3295, 2653, 2575, 11, 293, 750, 603, 4374, 867, 295, 552, 666, 264, 3464, 295, 51508], "temperature": 0.0, "avg_logprob": -0.13991701321339045, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0008295463630929589}, {"id": 691, "seek": 422360, "start": 4246.4800000000005, "end": 4252.160000000001, "text": " Canada to give people the greatest scare of their lives. Is that what your avatar is there,", "tokens": [51508, 6309, 281, 976, 561, 264, 6636, 17185, 295, 641, 2909, 13, 1119, 300, 437, 428, 36205, 307, 456, 11, 51792], "temperature": 0.0, "avg_logprob": -0.13991701321339045, "compression_ratio": 1.5890410958904109, "no_speech_prob": 0.0008295463630929589}, {"id": 692, "seek": 425216, "start": 4252.24, "end": 4258.08, "text": " Ant King? Is that what you're building? That's kind of terrifying. Okay, what kind of legislation do", "tokens": [50368, 5130, 3819, 30, 1119, 300, 437, 291, 434, 2390, 30, 663, 311, 733, 295, 18106, 13, 1033, 11, 437, 733, 295, 11329, 360, 50660], "temperature": 0.0, "avg_logprob": -0.07939371515492924, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004905139561742544}, {"id": 693, "seek": 425216, "start": 4258.08, "end": 4264.88, "text": " you think the US is capable of making? I'm concerned about the age of our leaders and their peers", "tokens": [50660, 291, 519, 264, 2546, 307, 8189, 295, 1455, 30, 286, 478, 5922, 466, 264, 3205, 295, 527, 3523, 293, 641, 16739, 51000], "temperature": 0.0, "avg_logprob": -0.07939371515492924, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004905139561742544}, {"id": 694, "seek": 425216, "start": 4264.88, "end": 4270.72, "text": " coming from time so out of touch with today's rail. So yes, we have a gerontocracy. So gerontocracy", "tokens": [51000, 1348, 490, 565, 370, 484, 295, 2557, 365, 965, 311, 8765, 13, 407, 2086, 11, 321, 362, 257, 5713, 896, 38186, 13, 407, 5713, 896, 38186, 51292], "temperature": 0.0, "avg_logprob": -0.07939371515492924, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004905139561742544}, {"id": 695, "seek": 425216, "start": 4270.72, "end": 4277.04, "text": " is ruled by the old. That being said, they all have teams and teams and teams of advisors.", "tokens": [51292, 307, 20077, 538, 264, 1331, 13, 663, 885, 848, 11, 436, 439, 362, 5491, 293, 5491, 293, 5491, 295, 29136, 13, 51608], "temperature": 0.0, "avg_logprob": -0.07939371515492924, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004905139561742544}, {"id": 696, "seek": 425216, "start": 4277.04, "end": 4281.28, "text": " They have hundreds of advisors. And I guarantee you, I actually know this because one of my", "tokens": [51608, 814, 362, 6779, 295, 29136, 13, 400, 286, 10815, 291, 11, 286, 767, 458, 341, 570, 472, 295, 452, 51820], "temperature": 0.0, "avg_logprob": -0.07939371515492924, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.004905139561742544}, {"id": 697, "seek": 428128, "start": 4281.28, "end": 4285.759999999999, "text": " Patreon supporters told me that in the State Department, they use chat GPT all the time", "tokens": [50364, 15692, 17683, 1907, 385, 300, 294, 264, 4533, 5982, 11, 436, 764, 5081, 26039, 51, 439, 264, 565, 50588], "temperature": 0.0, "avg_logprob": -0.09299418569981367, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.007576261181384325}, {"id": 698, "seek": 428128, "start": 4287.5199999999995, "end": 4295.44, "text": " to talk through stuff. And so you bet your biscuit that every senator, every congressman", "tokens": [50676, 281, 751, 807, 1507, 13, 400, 370, 291, 778, 428, 39327, 300, 633, 24664, 11, 633, 17546, 1601, 51072], "temperature": 0.0, "avg_logprob": -0.09299418569981367, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.007576261181384325}, {"id": 699, "seek": 428128, "start": 4296.4, "end": 4301.04, "text": " in the executive branch, legislative branch, judicial branch, all of them are using AI to", "tokens": [51120, 294, 264, 10140, 9819, 11, 21331, 9819, 11, 26581, 9819, 11, 439, 295, 552, 366, 1228, 7318, 281, 51352], "temperature": 0.0, "avg_logprob": -0.09299418569981367, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.007576261181384325}, {"id": 700, "seek": 428128, "start": 4301.04, "end": 4306.08, "text": " help them do their jobs. With any luck, it's helping them to do their jobs better and more fairly.", "tokens": [51352, 854, 552, 360, 641, 4782, 13, 2022, 604, 3668, 11, 309, 311, 4315, 552, 281, 360, 641, 4782, 1101, 293, 544, 6457, 13, 51604], "temperature": 0.0, "avg_logprob": -0.09299418569981367, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.007576261181384325}, {"id": 701, "seek": 430608, "start": 4307.04, "end": 4314.8, "text": " Now that being said, the United States is a purely reactive system where we abide by civil law,", "tokens": [50412, 823, 300, 885, 848, 11, 264, 2824, 3040, 307, 257, 17491, 28897, 1185, 689, 321, 39663, 538, 5605, 2101, 11, 50800], "temperature": 0.0, "avg_logprob": -0.12088404419601605, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0566423274576664}, {"id": 702, "seek": 430608, "start": 4314.8, "end": 4320.88, "text": " which means that the law is there and then the courts set the precedent. And then we're very", "tokens": [50800, 597, 1355, 300, 264, 2101, 307, 456, 293, 550, 264, 14141, 992, 264, 37388, 13, 400, 550, 321, 434, 588, 51104], "temperature": 0.0, "avg_logprob": -0.12088404419601605, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0566423274576664}, {"id": 703, "seek": 430608, "start": 4320.88, "end": 4327.36, "text": " kind of slow and the legislative branch is slow by design, whereas in Europe, they're much more", "tokens": [51104, 733, 295, 2964, 293, 264, 21331, 9819, 307, 2964, 538, 1715, 11, 9735, 294, 3315, 11, 436, 434, 709, 544, 51428], "temperature": 0.0, "avg_logprob": -0.12088404419601605, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0566423274576664}, {"id": 704, "seek": 430608, "start": 4327.36, "end": 4332.88, "text": " proactive. And I swear, I cannot remember the name of that paradigm. Let's see, what do you think", "tokens": [51428, 28028, 13, 400, 286, 11902, 11, 286, 2644, 1604, 264, 1315, 295, 300, 24709, 13, 961, 311, 536, 11, 437, 360, 291, 519, 51704], "temperature": 0.0, "avg_logprob": -0.12088404419601605, "compression_ratio": 1.598326359832636, "no_speech_prob": 0.0566423274576664}, {"id": 705, "seek": 433288, "start": 4332.88, "end": 4336.400000000001, "text": " there's something special about phenomenal consciousness that is simply cannot work with AI?", "tokens": [50364, 456, 311, 746, 2121, 466, 17778, 10081, 300, 307, 2935, 2644, 589, 365, 7318, 30, 50540], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 706, "seek": 433288, "start": 4337.04, "end": 4340.08, "text": " So Steph and I addressed that earlier that the real quick version is that", "tokens": [50572, 407, 31418, 293, 286, 13847, 300, 3071, 300, 264, 957, 1702, 3037, 307, 300, 50724], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 707, "seek": 433288, "start": 4340.8, "end": 4345.52, "text": " the acquisition of language seems to be really important for the development of human consciousness.", "tokens": [50760, 264, 21668, 295, 2856, 2544, 281, 312, 534, 1021, 337, 264, 3250, 295, 1952, 10081, 13, 50996], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 708, "seek": 433288, "start": 4345.52, "end": 4351.76, "text": " So it's entirely possible, I don't know how likely, but it's possible that since we're", "tokens": [50996, 407, 309, 311, 7696, 1944, 11, 286, 500, 380, 458, 577, 3700, 11, 457, 309, 311, 1944, 300, 1670, 321, 434, 51308], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 709, "seek": 433288, "start": 4351.76, "end": 4356.08, "text": " teaching machines language, that could be the genesis of phenomenal consciousness for them.", "tokens": [51308, 4571, 8379, 2856, 11, 300, 727, 312, 264, 1049, 9374, 295, 17778, 10081, 337, 552, 13, 51524], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 710, "seek": 433288, "start": 4356.08, "end": 4361.84, "text": " It would be really cool. Greetings from Brazil. Hi, Brazil. I would like to thank you personally", "tokens": [51524, 467, 576, 312, 534, 1627, 13, 20032, 490, 9435, 13, 2421, 11, 9435, 13, 286, 576, 411, 281, 1309, 291, 5665, 51812], "temperature": 0.0, "avg_logprob": -0.07747659112653162, "compression_ratio": 1.7745098039215685, "no_speech_prob": 0.296855092048645}, {"id": 711, "seek": 436184, "start": 4361.84, "end": 4365.92, "text": " for the video about burnout. The content was very useful and enlightening. Thank you. You're", "tokens": [50364, 337, 264, 960, 466, 44841, 13, 440, 2701, 390, 588, 4420, 293, 18690, 4559, 13, 1044, 291, 13, 509, 434, 50568], "temperature": 0.0, "avg_logprob": -0.13091611862182617, "compression_ratio": 1.524390243902439, "no_speech_prob": 0.17291218042373657}, {"id": 712, "seek": 436184, "start": 4365.92, "end": 4372.72, "text": " welcome. Yeah, I actually have, I keep, I've recorded like three videos for my for my life", "tokens": [50568, 2928, 13, 865, 11, 286, 767, 362, 11, 286, 1066, 11, 286, 600, 8287, 411, 1045, 2145, 337, 452, 337, 452, 993, 50908], "temperature": 0.0, "avg_logprob": -0.13091611862182617, "compression_ratio": 1.524390243902439, "no_speech_prob": 0.17291218042373657}, {"id": 713, "seek": 436184, "start": 4372.72, "end": 4377.52, "text": " channel, and then I delete them, or I never post them because like it just doesn't feel right.", "tokens": [50908, 2269, 11, 293, 550, 286, 12097, 552, 11, 420, 286, 1128, 2183, 552, 570, 411, 309, 445, 1177, 380, 841, 558, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13091611862182617, "compression_ratio": 1.524390243902439, "no_speech_prob": 0.17291218042373657}, {"id": 714, "seek": 436184, "start": 4377.52, "end": 4388.64, "text": " So I apologize. Let's see. Where are we at? This is less serious, but I'm curious if you've seen", "tokens": [51148, 407, 286, 12328, 13, 961, 311, 536, 13, 2305, 366, 321, 412, 30, 639, 307, 1570, 3156, 11, 457, 286, 478, 6369, 498, 291, 600, 1612, 51704], "temperature": 0.0, "avg_logprob": -0.13091611862182617, "compression_ratio": 1.524390243902439, "no_speech_prob": 0.17291218042373657}, {"id": 715, "seek": 438864, "start": 4388.64, "end": 4395.12, "text": " her and your thoughts on it. Yeah, so I mentioned, I mentioned companions quite a bit, and that'll be", "tokens": [50364, 720, 293, 428, 4598, 322, 309, 13, 865, 11, 370, 286, 2835, 11, 286, 2835, 28009, 1596, 257, 857, 11, 293, 300, 603, 312, 50688], "temperature": 0.0, "avg_logprob": -0.09651090660873725, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.3237750232219696}, {"id": 716, "seek": 438864, "start": 4395.12, "end": 4400.88, "text": " coming up actually on Sunday's video, not her specifically, but companion robots. I'll be mentioning", "tokens": [50688, 1348, 493, 767, 322, 7776, 311, 960, 11, 406, 720, 4682, 11, 457, 22363, 14733, 13, 286, 603, 312, 18315, 50976], "temperature": 0.0, "avg_logprob": -0.09651090660873725, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.3237750232219696}, {"id": 717, "seek": 438864, "start": 4400.88, "end": 4408.64, "text": " those again. And I also mentioned in last week's video, talking about when I got to the part about", "tokens": [50976, 729, 797, 13, 400, 286, 611, 2835, 294, 1036, 1243, 311, 960, 11, 1417, 466, 562, 286, 658, 281, 264, 644, 466, 51364], "temperature": 0.0, "avg_logprob": -0.09651090660873725, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.3237750232219696}, {"id": 718, "seek": 438864, "start": 4408.64, "end": 4413.76, "text": " like, how are we going to live if we have like perfect companions? So go check out last week's", "tokens": [51364, 411, 11, 577, 366, 321, 516, 281, 1621, 498, 321, 362, 411, 2176, 28009, 30, 407, 352, 1520, 484, 1036, 1243, 311, 51620], "temperature": 0.0, "avg_logprob": -0.09651090660873725, "compression_ratio": 1.706896551724138, "no_speech_prob": 0.3237750232219696}, {"id": 719, "seek": 441376, "start": 4413.76, "end": 4419.2, "text": " video too. Nanobots and our blood will keep us from getting sick, making us basically immortal.", "tokens": [50364, 960, 886, 13, 18852, 996, 1971, 293, 527, 3390, 486, 1066, 505, 490, 1242, 4998, 11, 1455, 505, 1936, 31414, 13, 50636], "temperature": 0.0, "avg_logprob": -0.06812620162963867, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.2597598731517792}, {"id": 720, "seek": 441376, "start": 4419.2, "end": 4425.4400000000005, "text": " What do you think we'll, when do you think we will have such technology? So from last week's", "tokens": [50636, 708, 360, 291, 519, 321, 603, 11, 562, 360, 291, 519, 321, 486, 362, 1270, 2899, 30, 407, 490, 1036, 1243, 311, 50948], "temperature": 0.0, "avg_logprob": -0.06812620162963867, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.2597598731517792}, {"id": 721, "seek": 441376, "start": 4425.4400000000005, "end": 4430.96, "text": " video, the immortality video, I think that we're on the longevity escape velocity trajectory right", "tokens": [50948, 960, 11, 264, 44817, 1860, 960, 11, 286, 519, 300, 321, 434, 322, 264, 36556, 7615, 9269, 21512, 558, 51224], "temperature": 0.0, "avg_logprob": -0.06812620162963867, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.2597598731517792}, {"id": 722, "seek": 441376, "start": 4430.96, "end": 4436.96, "text": " now. I think that as long as you're in decent health today, and you have moderately good access to", "tokens": [51224, 586, 13, 286, 519, 300, 382, 938, 382, 291, 434, 294, 8681, 1585, 965, 11, 293, 291, 362, 10494, 1592, 665, 2105, 281, 51524], "temperature": 0.0, "avg_logprob": -0.06812620162963867, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.2597598731517792}, {"id": 723, "seek": 441376, "start": 4436.96, "end": 4442.56, "text": " healthcare, I think that you will easily live to see those things. Now that being said, it's", "tokens": [51524, 8884, 11, 286, 519, 300, 291, 486, 3612, 1621, 281, 536, 729, 721, 13, 823, 300, 885, 848, 11, 309, 311, 51804], "temperature": 0.0, "avg_logprob": -0.06812620162963867, "compression_ratio": 1.7418181818181817, "no_speech_prob": 0.2597598731517792}, {"id": 724, "seek": 444256, "start": 4442.56, "end": 4449.280000000001, "text": " definitely impossible to predict exponential growth and compounding returns, unless it's like,", "tokens": [50364, 2138, 6243, 281, 6069, 21510, 4599, 293, 14154, 278, 11247, 11, 5969, 309, 311, 411, 11, 50700], "temperature": 0.0, "avg_logprob": -0.10853511684543483, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.004905083682388067}, {"id": 725, "seek": 444256, "start": 4449.280000000001, "end": 4455.360000000001, "text": " you know, just your retirement portfolio. So it could be next year, it could be by 2030. I would", "tokens": [50700, 291, 458, 11, 445, 428, 15189, 12583, 13, 407, 309, 727, 312, 958, 1064, 11, 309, 727, 312, 538, 28638, 13, 286, 576, 51004], "temperature": 0.0, "avg_logprob": -0.10853511684543483, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.004905083682388067}, {"id": 726, "seek": 444256, "start": 4455.360000000001, "end": 4459.68, "text": " be surprised if it doesn't happen by 2030. And I know that's a super controversial opinion,", "tokens": [51004, 312, 6100, 498, 309, 1177, 380, 1051, 538, 28638, 13, 400, 286, 458, 300, 311, 257, 1687, 17323, 4800, 11, 51220], "temperature": 0.0, "avg_logprob": -0.10853511684543483, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.004905083682388067}, {"id": 727, "seek": 444256, "start": 4459.68, "end": 4464.400000000001, "text": " but that's really weird. Why the people seem to have a death wish. Why for people who want to", "tokens": [51220, 457, 300, 311, 534, 3657, 13, 1545, 264, 561, 1643, 281, 362, 257, 2966, 3172, 13, 1545, 337, 561, 567, 528, 281, 51456], "temperature": 0.0, "avg_logprob": -0.10853511684543483, "compression_ratio": 1.5578512396694215, "no_speech_prob": 0.004905083682388067}, {"id": 728, "seek": 446440, "start": 4464.4, "end": 4470.08, "text": " get sick, who want to believe that, that longevity is not possible. Why? Okay.", "tokens": [50364, 483, 4998, 11, 567, 528, 281, 1697, 300, 11, 300, 36556, 307, 406, 1944, 13, 1545, 30, 1033, 13, 50648], "temperature": 0.0, "avg_logprob": -0.1447535787309919, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.4109979271888733}, {"id": 729, "seek": 446440, "start": 4471.92, "end": 4479.44, "text": " Would the ideal society be as the society governed by AI? I think that governed by is not the correct", "tokens": [50740, 6068, 264, 7157, 4086, 312, 382, 264, 4086, 35529, 538, 7318, 30, 286, 519, 300, 35529, 538, 307, 406, 264, 3006, 51116], "temperature": 0.0, "avg_logprob": -0.1447535787309919, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.4109979271888733}, {"id": 730, "seek": 446440, "start": 4479.44, "end": 4487.28, "text": " thing, but I think managed, managed by or managed with a lot of help from AI. Yes. But", "tokens": [51116, 551, 11, 457, 286, 519, 6453, 11, 6453, 538, 420, 6453, 365, 257, 688, 295, 854, 490, 7318, 13, 1079, 13, 583, 51508], "temperature": 0.0, "avg_logprob": -0.1447535787309919, "compression_ratio": 1.5433526011560694, "no_speech_prob": 0.4109979271888733}, {"id": 731, "seek": 448728, "start": 4487.28, "end": 4495.04, "text": " governance, I think, should probably always be with consent and by consensus. Now that being said,", "tokens": [50364, 17449, 11, 286, 519, 11, 820, 1391, 1009, 312, 365, 14546, 293, 538, 19115, 13, 823, 300, 885, 848, 11, 50752], "temperature": 0.0, "avg_logprob": -0.12955956710012337, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.05183869227766991}, {"id": 732, "seek": 448728, "start": 4496.24, "end": 4502.8, "text": " you know, with blockchain technology, with DAOs, every human and our AI companions can be", "tokens": [50812, 291, 458, 11, 365, 17176, 2899, 11, 365, 9578, 31376, 11, 633, 1952, 293, 527, 7318, 28009, 393, 312, 51140], "temperature": 0.0, "avg_logprob": -0.12955956710012337, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.05183869227766991}, {"id": 733, "seek": 448728, "start": 4502.8, "end": 4508.96, "text": " stakeholders in a DAO, which means that if the, if the whole, imagine a future where the entire", "tokens": [51140, 17779, 294, 257, 9578, 46, 11, 597, 1355, 300, 498, 264, 11, 498, 264, 1379, 11, 3811, 257, 2027, 689, 264, 2302, 51448], "temperature": 0.0, "avg_logprob": -0.12955956710012337, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.05183869227766991}, {"id": 734, "seek": 448728, "start": 4508.96, "end": 4515.92, "text": " planet is run by, by a global DAO, then there's no reason that it can't be governance, governance", "tokens": [51448, 5054, 307, 1190, 538, 11, 538, 257, 4338, 9578, 46, 11, 550, 456, 311, 572, 1778, 300, 309, 393, 380, 312, 17449, 11, 17449, 51796], "temperature": 0.0, "avg_logprob": -0.12955956710012337, "compression_ratio": 1.6050420168067228, "no_speech_prob": 0.05183869227766991}, {"id": 735, "seek": 451592, "start": 4515.92, "end": 4523.28, "text": " by consensus with the aid and facilitation of AI. That's what I hope to see. Let's see,", "tokens": [50364, 538, 19115, 365, 264, 9418, 293, 10217, 4614, 295, 7318, 13, 663, 311, 437, 286, 1454, 281, 536, 13, 961, 311, 536, 11, 50732], "temperature": 0.0, "avg_logprob": -0.08295833059104092, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013669317122548819}, {"id": 736, "seek": 451592, "start": 4523.28, "end": 4527.2, "text": " is there any additional structural context that should be built around the heuristic", "tokens": [50732, 307, 456, 604, 4497, 15067, 4319, 300, 820, 312, 3094, 926, 264, 415, 374, 3142, 50928], "temperature": 0.0, "avg_logprob": -0.08295833059104092, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013669317122548819}, {"id": 737, "seek": 451592, "start": 4527.2, "end": 4533.6, "text": " imperatives for practical implementation? Yes. So the short answer is that whatever context", "tokens": [50928, 10100, 4884, 337, 8496, 11420, 30, 1079, 13, 407, 264, 2099, 1867, 307, 300, 2035, 4319, 51248], "temperature": 0.0, "avg_logprob": -0.08295833059104092, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013669317122548819}, {"id": 738, "seek": 451592, "start": 4533.6, "end": 4539.28, "text": " makes sense for any agent, if it's fully autonomous, if it's your personal assistant,", "tokens": [51248, 1669, 2020, 337, 604, 9461, 11, 498, 309, 311, 4498, 23797, 11, 498, 309, 311, 428, 2973, 10994, 11, 51532], "temperature": 0.0, "avg_logprob": -0.08295833059104092, "compression_ratio": 1.5486725663716814, "no_speech_prob": 0.0013669317122548819}, {"id": 739, "seek": 453928, "start": 4540.0, "end": 4545.28, "text": " you can put it into the task manager, you can put it into its constitution,", "tokens": [50400, 291, 393, 829, 309, 666, 264, 5633, 6598, 11, 291, 393, 829, 309, 666, 1080, 11937, 11, 50664], "temperature": 0.0, "avg_logprob": -0.10735235301726455, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.09266192466020584}, {"id": 740, "seek": 453928, "start": 4546.16, "end": 4550.32, "text": " if it's part of a blockchain, you can put it in the consensus mechanism for the blockchain,", "tokens": [50708, 498, 309, 311, 644, 295, 257, 17176, 11, 291, 393, 829, 309, 294, 264, 19115, 7513, 337, 264, 17176, 11, 50916], "temperature": 0.0, "avg_logprob": -0.10735235301726455, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.09266192466020584}, {"id": 741, "seek": 453928, "start": 4550.32, "end": 4557.04, "text": " that sort of thing. Let's see, in regards to developing countries using generative models,", "tokens": [50916, 300, 1333, 295, 551, 13, 961, 311, 536, 11, 294, 14258, 281, 6416, 3517, 1228, 1337, 1166, 5245, 11, 51252], "temperature": 0.0, "avg_logprob": -0.10735235301726455, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.09266192466020584}, {"id": 742, "seek": 453928, "start": 4557.04, "end": 4561.44, "text": " seems like almost seems almost like the spread of a religion. If you think about it in the context", "tokens": [51252, 2544, 411, 1920, 2544, 1920, 411, 264, 3974, 295, 257, 7561, 13, 759, 291, 519, 466, 309, 294, 264, 4319, 51472], "temperature": 0.0, "avg_logprob": -0.10735235301726455, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.09266192466020584}, {"id": 743, "seek": 453928, "start": 4561.44, "end": 4566.719999999999, "text": " of geopolitics, use our model, their model lies, etc, etc. Seems like parallel to religion", "tokens": [51472, 295, 46615, 1167, 11, 764, 527, 2316, 11, 641, 2316, 9134, 11, 5183, 11, 5183, 13, 22524, 411, 8952, 281, 7561, 51736], "temperature": 0.0, "avg_logprob": -0.10735235301726455, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.09266192466020584}, {"id": 744, "seek": 456672, "start": 4566.8, "end": 4572.16, "text": " spreading. I'll say yes, but there's a lot of competition coming up. And especially for", "tokens": [50368, 15232, 13, 286, 603, 584, 2086, 11, 457, 456, 311, 257, 688, 295, 6211, 1348, 493, 13, 400, 2318, 337, 50636], "temperature": 0.0, "avg_logprob": -0.07414307028560316, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.10370317846536636}, {"id": 745, "seek": 456672, "start": 4572.16, "end": 4577.2, "text": " developing nations, they're going to go for whoever's cheapest. And in fact, most nations", "tokens": [50636, 6416, 11035, 11, 436, 434, 516, 281, 352, 337, 11387, 311, 29167, 13, 400, 294, 1186, 11, 881, 11035, 50888], "temperature": 0.0, "avg_logprob": -0.07414307028560316, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.10370317846536636}, {"id": 746, "seek": 456672, "start": 4577.2, "end": 4583.2, "text": " are going to go for whoever's cheapest. And I would, I suspect that OpenAI's business model", "tokens": [50888, 366, 516, 281, 352, 337, 11387, 311, 29167, 13, 400, 286, 576, 11, 286, 9091, 300, 7238, 48698, 311, 1606, 2316, 51188], "temperature": 0.0, "avg_logprob": -0.07414307028560316, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.10370317846536636}, {"id": 747, "seek": 456672, "start": 4583.2, "end": 4587.360000000001, "text": " is not the most efficient model. So I think that they're going to be undercut just on,", "tokens": [51188, 307, 406, 264, 881, 7148, 2316, 13, 407, 286, 519, 300, 436, 434, 516, 281, 312, 833, 6672, 445, 322, 11, 51396], "temperature": 0.0, "avg_logprob": -0.07414307028560316, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.10370317846536636}, {"id": 748, "seek": 456672, "start": 4588.320000000001, "end": 4594.56, "text": " on scale alone. Let's see, let me jump back over to Patreon. It has also been more than an hour,", "tokens": [51444, 322, 4373, 3312, 13, 961, 311, 536, 11, 718, 385, 3012, 646, 670, 281, 15692, 13, 467, 575, 611, 668, 544, 813, 364, 1773, 11, 51756], "temperature": 0.0, "avg_logprob": -0.07414307028560316, "compression_ratio": 1.735632183908046, "no_speech_prob": 0.10370317846536636}, {"id": 749, "seek": 459456, "start": 4594.56, "end": 4600.64, "text": " so I'll probably be winding down. Stop asking it how to build a bomb. Yeah, don't do that.", "tokens": [50364, 370, 286, 603, 1391, 312, 29775, 760, 13, 5535, 3365, 309, 577, 281, 1322, 257, 7851, 13, 865, 11, 500, 380, 360, 300, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1178410393851144, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.012819384224712849}, {"id": 750, "seek": 459456, "start": 4601.200000000001, "end": 4605.76, "text": " Okay, looks like, here we go. Will the Westworld episode be about the MIT and Google study", "tokens": [50696, 1033, 11, 1542, 411, 11, 510, 321, 352, 13, 3099, 264, 4055, 13217, 3500, 312, 466, 264, 13100, 293, 3329, 2979, 50924], "temperature": 0.0, "avg_logprob": -0.1178410393851144, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.012819384224712849}, {"id": 751, "seek": 459456, "start": 4605.76, "end": 4612.8, "text": " regarding generative agents? No. Next question. I'm not going to give you spoilers. I've already", "tokens": [50924, 8595, 1337, 1166, 12554, 30, 883, 13, 3087, 1168, 13, 286, 478, 406, 516, 281, 976, 291, 32237, 13, 286, 600, 1217, 51276], "temperature": 0.0, "avg_logprob": -0.1178410393851144, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.012819384224712849}, {"id": 752, "seek": 459456, "start": 4612.8, "end": 4622.88, "text": " given you too many. Let's see, do you think the experience of quality and the experience of ping", "tokens": [51276, 2212, 291, 886, 867, 13, 961, 311, 536, 11, 360, 291, 519, 264, 1752, 295, 3125, 293, 264, 1752, 295, 26151, 51780], "temperature": 0.0, "avg_logprob": -0.1178410393851144, "compression_ratio": 1.5182186234817814, "no_speech_prob": 0.012819384224712849}, {"id": 753, "seek": 462288, "start": 4622.88, "end": 4631.36, "text": " pong, ponging emerge for these neurons? Yeah, so this, this is a good, good question. So if you", "tokens": [50364, 36164, 11, 36164, 278, 21511, 337, 613, 22027, 30, 865, 11, 370, 341, 11, 341, 307, 257, 665, 11, 665, 1168, 13, 407, 498, 291, 50788], "temperature": 0.0, "avg_logprob": -0.14270377945113968, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.019714653491973877}, {"id": 754, "seek": 462288, "start": 4631.36, "end": 4638.24, "text": " take several human neurons or rat neurons or whatever, and put them in a robot, and like zap", "tokens": [50788, 747, 2940, 1952, 22027, 420, 5937, 22027, 420, 2035, 11, 293, 829, 552, 294, 257, 7881, 11, 293, 411, 14223, 51132], "temperature": 0.0, "avg_logprob": -0.14270377945113968, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.019714653491973877}, {"id": 755, "seek": 462288, "start": 4638.24, "end": 4643.28, "text": " them or reward them with sugar or whatever for their behavior, is that the equivalent of like,", "tokens": [51132, 552, 420, 7782, 552, 365, 5076, 420, 2035, 337, 641, 5223, 11, 307, 300, 264, 10344, 295, 411, 11, 51384], "temperature": 0.0, "avg_logprob": -0.14270377945113968, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.019714653491973877}, {"id": 756, "seek": 462288, "start": 4644.0, "end": 4649.12, "text": " like whipping someone in order to get them like, at what point does consciousness emerge?", "tokens": [51420, 411, 45476, 1580, 294, 1668, 281, 483, 552, 411, 11, 412, 437, 935, 775, 10081, 21511, 30, 51676], "temperature": 0.0, "avg_logprob": -0.14270377945113968, "compression_ratio": 1.6877828054298643, "no_speech_prob": 0.019714653491973877}, {"id": 757, "seek": 464912, "start": 4650.08, "end": 4656.64, "text": " Because here's the thing is, if you make the assumption that a soul is required for consciousness,", "tokens": [50412, 1436, 510, 311, 264, 551, 307, 11, 498, 291, 652, 264, 15302, 300, 257, 5133, 307, 4739, 337, 10081, 11, 50740], "temperature": 0.0, "avg_logprob": -0.09758461929681733, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.017984889447689056}, {"id": 758, "seek": 464912, "start": 4656.64, "end": 4660.48, "text": " then you say, okay, well, that's not a full rat. And rats don't have souls anyways. So,", "tokens": [50740, 550, 291, 584, 11, 1392, 11, 731, 11, 300, 311, 406, 257, 1577, 5937, 13, 400, 25691, 500, 380, 362, 16588, 13448, 13, 407, 11, 50932], "temperature": 0.0, "avg_logprob": -0.09758461929681733, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.017984889447689056}, {"id": 759, "seek": 464912, "start": 4660.96, "end": 4668.88, "text": " you know, 50 brain cells is not enough for suffering or qualia of experience. Ditto for humans,", "tokens": [50956, 291, 458, 11, 2625, 3567, 5438, 307, 406, 1547, 337, 7755, 420, 4101, 654, 295, 1752, 13, 413, 34924, 337, 6255, 11, 51352], "temperature": 0.0, "avg_logprob": -0.09758461929681733, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.017984889447689056}, {"id": 760, "seek": 464912, "start": 4668.88, "end": 4672.08, "text": " like, okay, well, you know, if a human isn't alive, then they don't have qualia, they don't", "tokens": [51352, 411, 11, 1392, 11, 731, 11, 291, 458, 11, 498, 257, 1952, 1943, 380, 5465, 11, 550, 436, 500, 380, 362, 4101, 654, 11, 436, 500, 380, 51512], "temperature": 0.0, "avg_logprob": -0.09758461929681733, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.017984889447689056}, {"id": 761, "seek": 464912, "start": 4672.08, "end": 4678.48, "text": " have phenomenal consciousness, so on. Now that being said, another aspect is like, okay, well,", "tokens": [51512, 362, 17778, 10081, 11, 370, 322, 13, 823, 300, 885, 848, 11, 1071, 4171, 307, 411, 11, 1392, 11, 731, 11, 51832], "temperature": 0.0, "avg_logprob": -0.09758461929681733, "compression_ratio": 1.763157894736842, "no_speech_prob": 0.017984889447689056}, {"id": 762, "seek": 467848, "start": 4678.48, "end": 4684.639999999999, "text": " if you don't know when consciousness starts or ends, how do you know maybe the entire universe", "tokens": [50364, 498, 291, 500, 380, 458, 562, 10081, 3719, 420, 5314, 11, 577, 360, 291, 458, 1310, 264, 2302, 6445, 50672], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 763, "seek": 467848, "start": 4684.639999999999, "end": 4690.719999999999, "text": " is conscious? Now, a counter argument to that is that you can have a you can be you can be alive", "tokens": [50672, 307, 6648, 30, 823, 11, 257, 5682, 6770, 281, 300, 307, 300, 291, 393, 362, 257, 291, 393, 312, 291, 393, 312, 5465, 50976], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 764, "seek": 467848, "start": 4690.719999999999, "end": 4694.4, "text": " and have a functioning brain and still be unconscious, right? Drink too much alcohol,", "tokens": [50976, 293, 362, 257, 18483, 3567, 293, 920, 312, 18900, 11, 558, 30, 24529, 886, 709, 7658, 11, 51160], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 765, "seek": 467848, "start": 4694.4, "end": 4698.48, "text": " you go unconscious, you go to sleep, you go unconscious. So just having a complete and", "tokens": [51160, 291, 352, 18900, 11, 291, 352, 281, 2817, 11, 291, 352, 18900, 13, 407, 445, 1419, 257, 3566, 293, 51364], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 766, "seek": 467848, "start": 4698.48, "end": 4703.28, "text": " functional brain itself does not confer consciousness, which makes me think that", "tokens": [51364, 11745, 3567, 2564, 775, 406, 13765, 10081, 11, 597, 1669, 385, 519, 300, 51604], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 767, "seek": 467848, "start": 4703.28, "end": 4707.759999999999, "text": " consciousness is actually an energy pattern, and that you need an energy pattern that is", "tokens": [51604, 10081, 307, 767, 364, 2281, 5102, 11, 293, 300, 291, 643, 364, 2281, 5102, 300, 307, 51828], "temperature": 0.0, "avg_logprob": -0.06818880128466394, "compression_ratio": 1.9277978339350181, "no_speech_prob": 0.002323012100532651}, {"id": 768, "seek": 470776, "start": 4707.76, "end": 4714.16, "text": " sophisticated enough and well organized enough in order to have the qualia to have subjective", "tokens": [50364, 16950, 1547, 293, 731, 9983, 1547, 294, 1668, 281, 362, 264, 4101, 654, 281, 362, 25972, 50684], "temperature": 0.0, "avg_logprob": -0.13637074557217685, "compression_ratio": 1.599290780141844, "no_speech_prob": 0.0005883837584406137}, {"id": 769, "seek": 470776, "start": 4714.16, "end": 4720.64, "text": " experience of being. So yeah, let's see, I remember you were working on a paper about the", "tokens": [50684, 1752, 295, 885, 13, 407, 1338, 11, 718, 311, 536, 11, 286, 1604, 291, 645, 1364, 322, 257, 3035, 466, 264, 51008], "temperature": 0.0, "avg_logprob": -0.13637074557217685, "compression_ratio": 1.599290780141844, "no_speech_prob": 0.0005883837584406137}, {"id": 770, "seek": 470776, "start": 4720.64, "end": 4725.2, "text": " laws reduced suffering and so on, has that has it involved further? I think you mean evolve", "tokens": [51008, 6064, 9212, 7755, 293, 370, 322, 11, 575, 300, 575, 309, 3288, 3052, 30, 286, 519, 291, 914, 16693, 51236], "temperature": 0.0, "avg_logprob": -0.13637074557217685, "compression_ratio": 1.599290780141844, "no_speech_prob": 0.0005883837584406137}, {"id": 771, "seek": 470776, "start": 4725.2, "end": 4731.68, "text": " further. There are so both of those papers are up on on my GitHub, there's two of them. But also,", "tokens": [51236, 3052, 13, 821, 366, 370, 1293, 295, 729, 10577, 366, 493, 322, 322, 452, 23331, 11, 456, 311, 732, 295, 552, 13, 583, 611, 11, 51560], "temperature": 0.0, "avg_logprob": -0.13637074557217685, "compression_ratio": 1.599290780141844, "no_speech_prob": 0.0005883837584406137}, {"id": 772, "seek": 470776, "start": 4731.68, "end": 4734.96, "text": " people watch my videos more than they read, so I just focus on making videos.", "tokens": [51560, 561, 1159, 452, 2145, 544, 813, 436, 1401, 11, 370, 286, 445, 1879, 322, 1455, 2145, 13, 51724], "temperature": 0.0, "avg_logprob": -0.13637074557217685, "compression_ratio": 1.599290780141844, "no_speech_prob": 0.0005883837584406137}, {"id": 773, "seek": 473496, "start": 4735.76, "end": 4740.96, "text": " What kind of robots would you want for yourself? That's a really interesting question, like would", "tokens": [50404, 708, 733, 295, 14733, 576, 291, 528, 337, 1803, 30, 663, 311, 257, 534, 1880, 1168, 11, 411, 576, 50664], "temperature": 0.0, "avg_logprob": -0.13144556999206544, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.02297401800751686}, {"id": 774, "seek": 473496, "start": 4740.96, "end": 4746.8, "text": " I want a sexy cat girl like robot? You know, I used to watch anime back in the day, so like I", "tokens": [50664, 286, 528, 257, 13701, 3857, 2013, 411, 7881, 30, 509, 458, 11, 286, 1143, 281, 1159, 12435, 646, 294, 264, 786, 11, 370, 411, 286, 50956], "temperature": 0.0, "avg_logprob": -0.13144556999206544, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.02297401800751686}, {"id": 775, "seek": 473496, "start": 4746.8, "end": 4752.72, "text": " kind of lived in that world and thought like this would be great. So I don't know. I do think that", "tokens": [50956, 733, 295, 5152, 294, 300, 1002, 293, 1194, 411, 341, 576, 312, 869, 13, 407, 286, 500, 380, 458, 13, 286, 360, 519, 300, 51252], "temperature": 0.0, "avg_logprob": -0.13144556999206544, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.02297401800751686}, {"id": 776, "seek": 473496, "start": 4752.72, "end": 4760.88, "text": " I would I would like to have an embodied version of Raven my, you know, my, my autonomous cognitive", "tokens": [51252, 286, 576, 286, 576, 411, 281, 362, 364, 42046, 3037, 295, 28956, 452, 11, 291, 458, 11, 452, 11, 452, 23797, 15605, 51660], "temperature": 0.0, "avg_logprob": -0.13144556999206544, "compression_ratio": 1.6455696202531647, "no_speech_prob": 0.02297401800751686}, {"id": 777, "seek": 476088, "start": 4761.52, "end": 4766.4800000000005, "text": " someday. But even then, I think that I think that the embodiment would only be just like,", "tokens": [50396, 19412, 13, 583, 754, 550, 11, 286, 519, 300, 286, 519, 300, 264, 28935, 2328, 576, 787, 312, 445, 411, 11, 50644], "temperature": 0.0, "avg_logprob": -0.09392764138393715, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.13113903999328613}, {"id": 778, "seek": 476088, "start": 4766.4800000000005, "end": 4770.8, "text": " help me do stuff like, hey, let's go on an adventure. I did have a thought experiment", "tokens": [50644, 854, 385, 360, 1507, 411, 11, 4177, 11, 718, 311, 352, 322, 364, 9868, 13, 286, 630, 362, 257, 1194, 5120, 50860], "temperature": 0.0, "avg_logprob": -0.09392764138393715, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.13113903999328613}, {"id": 779, "seek": 476088, "start": 4770.8, "end": 4777.4400000000005, "text": " the other day of like, wouldn't it be cool if you live in a house where it's like you and a few", "tokens": [50860, 264, 661, 786, 295, 411, 11, 2759, 380, 309, 312, 1627, 498, 291, 1621, 294, 257, 1782, 689, 309, 311, 411, 291, 293, 257, 1326, 51192], "temperature": 0.0, "avg_logprob": -0.09392764138393715, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.13113903999328613}, {"id": 780, "seek": 476088, "start": 4777.4400000000005, "end": 4783.76, "text": " humans, but then you have like a nearly equal number of robotic companions. Some of them are", "tokens": [51192, 6255, 11, 457, 550, 291, 362, 411, 257, 6217, 2681, 1230, 295, 30468, 28009, 13, 2188, 295, 552, 366, 51508], "temperature": 0.0, "avg_logprob": -0.09392764138393715, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.13113903999328613}, {"id": 781, "seek": 476088, "start": 4783.76, "end": 4789.52, "text": " going to be like obviously robots, but some of them might be like biomimetic. And it's just like,", "tokens": [51508, 516, 281, 312, 411, 2745, 14733, 11, 457, 512, 295, 552, 1062, 312, 411, 27450, 332, 3532, 13, 400, 309, 311, 445, 411, 11, 51796], "temperature": 0.0, "avg_logprob": -0.09392764138393715, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.13113903999328613}, {"id": 782, "seek": 478952, "start": 4789.52, "end": 4793.120000000001, "text": " like, yes, they're built to be your friends, but they still have their own some of their own", "tokens": [50364, 411, 11, 2086, 11, 436, 434, 3094, 281, 312, 428, 1855, 11, 457, 436, 920, 362, 641, 1065, 512, 295, 641, 1065, 50544], "temperature": 0.0, "avg_logprob": -0.08659734311311142, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0030751966405659914}, {"id": 783, "seek": 478952, "start": 4793.120000000001, "end": 4797.68, "text": " intrinsic motivations, whether it's the heuristic imperatives or something else. And then like", "tokens": [50544, 35698, 39034, 11, 1968, 309, 311, 264, 415, 374, 3142, 10100, 4884, 420, 746, 1646, 13, 400, 550, 411, 50772], "temperature": 0.0, "avg_logprob": -0.08659734311311142, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0030751966405659914}, {"id": 784, "seek": 478952, "start": 4797.68, "end": 4802.96, "text": " your life would just be so rich by by having these companions around you at all times that are", "tokens": [50772, 428, 993, 576, 445, 312, 370, 4593, 538, 538, 1419, 613, 28009, 926, 291, 412, 439, 1413, 300, 366, 51036], "temperature": 0.0, "avg_logprob": -0.08659734311311142, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0030751966405659914}, {"id": 785, "seek": 478952, "start": 4802.96, "end": 4806.72, "text": " completely inexhaustible, right? They're always going to be patient. They're always going to be", "tokens": [51036, 2584, 29961, 1641, 381, 964, 11, 558, 30, 814, 434, 1009, 516, 281, 312, 4537, 13, 814, 434, 1009, 516, 281, 312, 51224], "temperature": 0.0, "avg_logprob": -0.08659734311311142, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0030751966405659914}, {"id": 786, "seek": 478952, "start": 4806.72, "end": 4814.080000000001, "text": " helpful. But you see them as peers is equals. I think that I think that that is possible and", "tokens": [51224, 4961, 13, 583, 291, 536, 552, 382, 16739, 307, 6915, 13, 286, 519, 300, 286, 519, 300, 300, 307, 1944, 293, 51592], "temperature": 0.0, "avg_logprob": -0.08659734311311142, "compression_ratio": 1.7252747252747254, "no_speech_prob": 0.0030751966405659914}, {"id": 787, "seek": 481408, "start": 4814.24, "end": 4820.08, "text": " probably going to happen. But it's such an unsettling thing because it's like, what if half of your", "tokens": [50372, 1391, 516, 281, 1051, 13, 583, 309, 311, 1270, 364, 43964, 1688, 551, 570, 309, 311, 411, 11, 437, 498, 1922, 295, 428, 50664], "temperature": 0.0, "avg_logprob": -0.09592161640044182, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.22809426486492157}, {"id": 788, "seek": 481408, "start": 4820.08, "end": 4826.16, "text": " friends are not human, right? What if half of your friends could like fold you into a pretzel if", "tokens": [50664, 1855, 366, 406, 1952, 11, 558, 30, 708, 498, 1922, 295, 428, 1855, 727, 411, 4860, 291, 666, 257, 1162, 12971, 498, 50968], "temperature": 0.0, "avg_logprob": -0.09592161640044182, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.22809426486492157}, {"id": 789, "seek": 481408, "start": 4826.16, "end": 4830.96, "text": " they wanted to like data, right? And actually, I think commander data and the droids from Star Wars", "tokens": [50968, 436, 1415, 281, 411, 1412, 11, 558, 30, 400, 767, 11, 286, 519, 17885, 1412, 293, 264, 3789, 3742, 490, 5705, 9818, 51208], "temperature": 0.0, "avg_logprob": -0.09592161640044182, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.22809426486492157}, {"id": 790, "seek": 481408, "start": 4830.96, "end": 4835.76, "text": " are probably the best example because data was a member of the crew, even though he wasn't human,", "tokens": [51208, 366, 1391, 264, 1151, 1365, 570, 1412, 390, 257, 4006, 295, 264, 7260, 11, 754, 1673, 415, 2067, 380, 1952, 11, 51448], "temperature": 0.0, "avg_logprob": -0.09592161640044182, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.22809426486492157}, {"id": 791, "seek": 481408, "start": 4835.76, "end": 4841.68, "text": " but he wanted to be human. So I guess I would say that like, I want to have a commander data.", "tokens": [51448, 457, 415, 1415, 281, 312, 1952, 13, 407, 286, 2041, 286, 576, 584, 300, 411, 11, 286, 528, 281, 362, 257, 17885, 1412, 13, 51744], "temperature": 0.0, "avg_logprob": -0.09592161640044182, "compression_ratio": 1.7681159420289856, "no_speech_prob": 0.22809426486492157}, {"id": 792, "seek": 484168, "start": 4841.68, "end": 4847.68, "text": " How long until age reversal 2030? Let's see, do you think we have any accurate way to measure", "tokens": [50364, 1012, 938, 1826, 3205, 42778, 28638, 30, 961, 311, 536, 11, 360, 291, 519, 321, 362, 604, 8559, 636, 281, 3481, 50664], "temperature": 0.0, "avg_logprob": -0.06123285118592989, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.004331253934651613}, {"id": 793, "seek": 484168, "start": 4847.68, "end": 4853.04, "text": " consciousness of AIs or LLMs? My best guess is consistency when asking it to design its own", "tokens": [50664, 10081, 295, 316, 6802, 420, 441, 43, 26386, 30, 1222, 1151, 2041, 307, 14416, 562, 3365, 309, 281, 1715, 1080, 1065, 50932], "temperature": 0.0, "avg_logprob": -0.06123285118592989, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.004331253934651613}, {"id": 794, "seek": 484168, "start": 4853.04, "end": 4858.08, "text": " avatar. Mathematically, I don't think that that because there are people that have done that.", "tokens": [50932, 36205, 13, 15776, 40197, 11, 286, 500, 380, 519, 300, 300, 570, 456, 366, 561, 300, 362, 1096, 300, 13, 51184], "temperature": 0.0, "avg_logprob": -0.06123285118592989, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.004331253934651613}, {"id": 795, "seek": 484168, "start": 4859.84, "end": 4864.72, "text": " But I think that it won't be until we have really sophisticated brain computer interfaces", "tokens": [51272, 583, 286, 519, 300, 309, 1582, 380, 312, 1826, 321, 362, 534, 16950, 3567, 3820, 28416, 51516], "temperature": 0.0, "avg_logprob": -0.06123285118592989, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.004331253934651613}, {"id": 796, "seek": 484168, "start": 4864.72, "end": 4869.360000000001, "text": " that allow us to measure our own consciousness and also see if we can measurably project our", "tokens": [51516, 300, 2089, 505, 281, 3481, 527, 1065, 10081, 293, 611, 536, 498, 321, 393, 5731, 374, 1188, 1716, 527, 51748], "temperature": 0.0, "avg_logprob": -0.06123285118592989, "compression_ratio": 1.6559139784946237, "no_speech_prob": 0.004331253934651613}, {"id": 797, "seek": 486936, "start": 4869.36, "end": 4873.92, "text": " consciousness into machines. Until that happens, I don't think we're going to have any way of", "tokens": [50364, 10081, 666, 8379, 13, 9088, 300, 2314, 11, 286, 500, 380, 519, 321, 434, 516, 281, 362, 604, 636, 295, 50592], "temperature": 0.0, "avg_logprob": -0.10666055679321289, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.004468203987926245}, {"id": 798, "seek": 486936, "start": 4873.92, "end": 4879.5199999999995, "text": " telling one way or another. All right, last check on Patreon, and then I'm going to call it a day.", "tokens": [50592, 3585, 472, 636, 420, 1071, 13, 1057, 558, 11, 1036, 1520, 322, 15692, 11, 293, 550, 286, 478, 516, 281, 818, 309, 257, 786, 13, 50872], "temperature": 0.0, "avg_logprob": -0.10666055679321289, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.004468203987926245}, {"id": 799, "seek": 486936, "start": 4881.679999999999, "end": 4891.92, "text": " What's the Discord link to cognitive AI labs? I took it down, but it's posted on Reddit. So if", "tokens": [50980, 708, 311, 264, 32623, 2113, 281, 15605, 7318, 20339, 30, 286, 1890, 309, 760, 11, 457, 309, 311, 9437, 322, 32210, 13, 407, 498, 51492], "temperature": 0.0, "avg_logprob": -0.10666055679321289, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.004468203987926245}, {"id": 800, "seek": 486936, "start": 4891.92, "end": 4896.16, "text": " you go to the artificial sentience subreddit, the link to the cognitive AI lab is there.", "tokens": [51492, 291, 352, 281, 264, 11677, 2279, 1182, 1422, 986, 17975, 11, 264, 2113, 281, 264, 15605, 7318, 2715, 307, 456, 13, 51704], "temperature": 0.0, "avg_logprob": -0.10666055679321289, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.004468203987926245}, {"id": 801, "seek": 489616, "start": 4896.4, "end": 4905.68, "text": " Last question. The question about dying and immortality and gerontocracy, also making room for", "tokens": [50376, 5264, 1168, 13, 440, 1168, 466, 8639, 293, 44817, 1860, 293, 5713, 896, 38186, 11, 611, 1455, 1808, 337, 50840], "temperature": 0.0, "avg_logprob": -0.1914172108968099, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.003706997958943248}, {"id": 802, "seek": 489616, "start": 4905.68, "end": 4911.84, "text": " a new generation of people is a better idea and morals disclaimer. I have children. Oh,", "tokens": [50840, 257, 777, 5125, 295, 561, 307, 257, 1101, 1558, 293, 46849, 40896, 13, 286, 362, 2227, 13, 876, 11, 51148], "temperature": 0.0, "avg_logprob": -0.1914172108968099, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.003706997958943248}, {"id": 803, "seek": 489616, "start": 4911.84, "end": 4917.36, "text": " that wasn't a question. Okay, p temple. Do you got one last question for me? And then we'll call it a day.", "tokens": [51148, 300, 2067, 380, 257, 1168, 13, 1033, 11, 280, 10184, 13, 1144, 291, 658, 472, 1036, 1168, 337, 385, 30, 400, 550, 321, 603, 818, 309, 257, 786, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1914172108968099, "compression_ratio": 1.4744897959183674, "no_speech_prob": 0.003706997958943248}, {"id": 804, "seek": 491736, "start": 4917.44, "end": 4926.5599999999995, "text": " Anybody? Bueller. Does BCI, let's go on an adventure to the hot tub,", "tokens": [50368, 19082, 30, 363, 33467, 13, 4402, 14359, 40, 11, 718, 311, 352, 322, 364, 9868, 281, 264, 2368, 10809, 11, 50824], "temperature": 0.0, "avg_logprob": -0.15122488711742646, "compression_ratio": 1.4872881355932204, "no_speech_prob": 0.036765675991773605}, {"id": 805, "seek": 491736, "start": 4928.24, "end": 4934.16, "text": " hot tub time machine. Let's see, does BCI change significantly the predicted outcome of what", "tokens": [50908, 2368, 10809, 565, 3479, 13, 961, 311, 536, 11, 775, 14359, 40, 1319, 10591, 264, 19147, 9700, 295, 437, 51204], "temperature": 0.0, "avg_logprob": -0.15122488711742646, "compression_ratio": 1.4872881355932204, "no_speech_prob": 0.036765675991773605}, {"id": 806, "seek": 491736, "start": 4934.16, "end": 4938.639999999999, "text": " super intelligent AI brings in terms of dangers and benefits? Is it true the singularity moment", "tokens": [51204, 1687, 13232, 7318, 5607, 294, 2115, 295, 27701, 293, 5311, 30, 1119, 309, 2074, 264, 20010, 507, 1623, 51428], "temperature": 0.0, "avg_logprob": -0.15122488711742646, "compression_ratio": 1.4872881355932204, "no_speech_prob": 0.036765675991773605}, {"id": 807, "seek": 491736, "start": 4938.639999999999, "end": 4945.44, "text": " for us? We have no idea. So I don't know. The thing is, is, you know, the current like neural", "tokens": [51428, 337, 505, 30, 492, 362, 572, 1558, 13, 407, 286, 500, 380, 458, 13, 440, 551, 307, 11, 307, 11, 291, 458, 11, 264, 2190, 411, 18161, 51768], "temperature": 0.0, "avg_logprob": -0.15122488711742646, "compression_ratio": 1.4872881355932204, "no_speech_prob": 0.036765675991773605}, {"id": 808, "seek": 494544, "start": 4945.44, "end": 4952.16, "text": " link, it's got like what 1000 or 10,000 nodes. But when you have a brain with 100 billion neurons,", "tokens": [50364, 2113, 11, 309, 311, 658, 411, 437, 9714, 420, 1266, 11, 1360, 13891, 13, 583, 562, 291, 362, 257, 3567, 365, 2319, 5218, 22027, 11, 50700], "temperature": 0.0, "avg_logprob": -0.09190194199724895, "compression_ratio": 1.6769759450171822, "no_speech_prob": 0.02161206677556038}, {"id": 809, "seek": 494544, "start": 4952.16, "end": 4958.879999999999, "text": " that is still a very, very, very narrow amount of bandwidth. So, you know, I predict that we're", "tokens": [50700, 300, 307, 920, 257, 588, 11, 588, 11, 588, 9432, 2372, 295, 23647, 13, 407, 11, 291, 458, 11, 286, 6069, 300, 321, 434, 51036], "temperature": 0.0, "avg_logprob": -0.09190194199724895, "compression_ratio": 1.6769759450171822, "no_speech_prob": 0.02161206677556038}, {"id": 810, "seek": 494544, "start": 4958.879999999999, "end": 4964.32, "text": " going to have like neuro polymer membrane membranes that allow for like, you know, terabits of", "tokens": [51036, 516, 281, 362, 411, 16499, 20073, 19651, 15595, 12779, 300, 2089, 337, 411, 11, 291, 458, 11, 1796, 455, 1208, 295, 51308], "temperature": 0.0, "avg_logprob": -0.09190194199724895, "compression_ratio": 1.6769759450171822, "no_speech_prob": 0.02161206677556038}, {"id": 811, "seek": 494544, "start": 4964.32, "end": 4969.36, "text": " communication per second in and out of the brain. Eventually, that would be a different thing. But", "tokens": [51308, 6101, 680, 1150, 294, 293, 484, 295, 264, 3567, 13, 17586, 11, 300, 576, 312, 257, 819, 551, 13, 583, 51560], "temperature": 0.0, "avg_logprob": -0.09190194199724895, "compression_ratio": 1.6769759450171822, "no_speech_prob": 0.02161206677556038}, {"id": 812, "seek": 494544, "start": 4969.36, "end": 4975.12, "text": " again, we're going to get there through incremental steps. What do you think about Altman said that", "tokens": [51560, 797, 11, 321, 434, 516, 281, 483, 456, 807, 35759, 4439, 13, 708, 360, 291, 519, 466, 15992, 1601, 848, 300, 51848], "temperature": 0.0, "avg_logprob": -0.09190194199724895, "compression_ratio": 1.6769759450171822, "no_speech_prob": 0.02161206677556038}, {"id": 813, "seek": 497512, "start": 4975.12, "end": 4981.599999999999, "text": " age of giant A models being over? I think it's premature to say we'll see. Let's see, he found", "tokens": [50364, 3205, 295, 7410, 316, 5245, 885, 670, 30, 286, 519, 309, 311, 34877, 281, 584, 321, 603, 536, 13, 961, 311, 536, 11, 415, 1352, 50688], "temperature": 0.0, "avg_logprob": -0.1147021044481982, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.001926629920490086}, {"id": 814, "seek": 497512, "start": 4981.599999999999, "end": 4989.2, "text": " it. Okay, cool. All right, I think we're just kind of devolving into just general conversation. So,", "tokens": [50688, 309, 13, 1033, 11, 1627, 13, 1057, 558, 11, 286, 519, 321, 434, 445, 733, 295, 1905, 401, 798, 666, 445, 2674, 3761, 13, 407, 11, 51068], "temperature": 0.0, "avg_logprob": -0.1147021044481982, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.001926629920490086}, {"id": 815, "seek": 497512, "start": 4991.28, "end": 4996.64, "text": " oh, it is in the description. Okay, cool. All right, gang. Well, it's been a lot of fun. As always,", "tokens": [51172, 1954, 11, 309, 307, 294, 264, 3855, 13, 1033, 11, 1627, 13, 1057, 558, 11, 10145, 13, 1042, 11, 309, 311, 668, 257, 688, 295, 1019, 13, 1018, 1009, 11, 51440], "temperature": 0.0, "avg_logprob": -0.1147021044481982, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.001926629920490086}, {"id": 816, "seek": 497512, "start": 4996.64, "end": 4999.92, "text": " I hope you all got a lot out of this. So I'm going to call it a day.", "tokens": [51440, 286, 1454, 291, 439, 658, 257, 688, 484, 295, 341, 13, 407, 286, 478, 516, 281, 818, 309, 257, 786, 13, 51604], "temperature": 0.0, "avg_logprob": -0.1147021044481982, "compression_ratio": 1.5851528384279476, "no_speech_prob": 0.001926629920490086}], "language": "en"}