WEBVTT

00:00.000 --> 00:04.000
As you know, I have a thesis about the exponential age

00:04.000 --> 00:07.000
that we're about to go through the fastest pace of technology

00:07.000 --> 00:09.000
the world has ever seen.

00:09.000 --> 00:11.000
That's what this whole series is about.

00:11.000 --> 00:14.000
This next interview with an old friend of mine

00:14.000 --> 00:18.000
is probably one of the most important single interviews

00:18.000 --> 00:20.000
you will watch.

00:20.000 --> 00:24.000
I can't stress enough how important the concepts

00:24.000 --> 00:26.000
and what is happening and the speed of which

00:26.000 --> 00:29.000
artificial intelligence is going to change humanity.

00:29.000 --> 00:33.000
It is something that we all need to pay attention to,

00:33.000 --> 00:37.000
understand and use in our favour because it's happening

00:37.000 --> 00:40.000
and it's happening at a scale of which you cannot comprehend.

00:43.000 --> 00:45.000
Emma, fantastic you see you back on Real Vision.

00:45.000 --> 00:47.000
Good to be back. Thanks for having me.

00:49.000 --> 00:52.000
You were known in the past in various guises on Real Vision

00:52.000 --> 00:55.000
because this is not your first rodeo.

00:55.000 --> 00:58.000
You were the frontier guy

00:58.000 --> 01:01.000
and we're going to talk about a new frontier today

01:01.000 --> 01:04.000
and then also in the pandemic you helped guide us

01:04.000 --> 01:06.000
through some of that too.

01:06.000 --> 01:08.000
Give people a bit about your background

01:08.000 --> 01:10.000
because it's a fascinating background

01:10.000 --> 01:12.000
and it's an interesting journey to where you are today.

01:12.000 --> 01:15.000
Yeah, it has been a few different skins.

01:15.000 --> 01:17.000
I was a hedge fund manager

01:17.000 --> 01:19.000
at the start of my career running Global Macro

01:19.000 --> 01:22.000
then switched to emerging markets, frontier markets

01:22.000 --> 01:24.000
and tech.

01:24.000 --> 01:26.000
At one point I was one of the larger video game investors

01:26.000 --> 01:28.000
which is also quite fun.

01:28.000 --> 01:31.000
Took a bit of a break when my son was diagnosed with autism

01:31.000 --> 01:34.000
and I used artificial intelligence to re-put up his drugs

01:34.000 --> 01:36.000
to make him it better.

01:36.000 --> 01:38.000
Well advised him some top hedge fund managers

01:38.000 --> 01:41.000
and governments on various things including counter extremism

01:41.000 --> 01:43.000
and fun things like that.

01:43.000 --> 01:46.000
Went back to being a hedge fund manager, did okay

01:46.000 --> 01:48.000
and then had a look at the world.

01:48.000 --> 01:51.000
What we do as fund managers is we look for arbitrage opportunities

01:51.000 --> 01:54.000
and we look for where things are building up and breaking down

01:54.000 --> 01:56.000
and it struck me that a lot of stuff was breaking down.

01:56.000 --> 02:00.000
I decided like let's try and make it better effectively

02:00.000 --> 02:02.000
by combining some of these systems

02:02.000 --> 02:04.000
and some of these arbitrage opportunities.

02:04.000 --> 02:06.000
So one of the big things was education.

02:06.000 --> 02:10.000
Another big thing was leading the United Nations

02:10.000 --> 02:12.000
AI initiative against COVID-19.

02:12.000 --> 02:14.000
I think the last time I was on Real Vision

02:14.000 --> 02:17.000
was February this thick, 2020

02:17.000 --> 02:20.000
and we had a nice chat about how the world was going to change

02:20.000 --> 02:22.000
dramatically and it did

02:22.000 --> 02:24.000
and then I was like oh crap I have to do something about it.

02:24.000 --> 02:27.000
So we made all the COVID research in the world free

02:27.000 --> 02:30.000
and pushed that and then I was lead architect of Kayak

02:30.000 --> 02:34.000
which was the UNESCO World Bank WHO backed initiatives

02:34.000 --> 02:37.000
to use artificial intelligence to take all that knowledge

02:37.000 --> 02:40.000
and compress it down to reports for policymakers

02:40.000 --> 02:42.000
so that we can be a bit more coordinated.

02:42.000 --> 02:45.000
Similar to how we take all that information and fund management

02:45.000 --> 02:48.000
compress it down and try to figure out those key drivers.

02:48.000 --> 02:51.000
It was a mixed success but I think it did some difference

02:51.000 --> 02:54.000
and now from that something a bit bigger

02:54.000 --> 02:57.000
which is AI for everything basically.

02:57.000 --> 03:00.000
So AI has clearly now become your thing, right?

03:00.000 --> 03:02.000
This is your focus.

03:02.000 --> 03:05.000
So before we get into what you're doing now

03:05.000 --> 03:08.000
what the hell gave a hedge fund manager

03:08.000 --> 03:12.000
the thought process that hey I can help the WHO

03:12.000 --> 03:15.000
and everybody else with artificial intelligence?

03:15.000 --> 03:17.000
Well it's because to be a hedge fund manager

03:17.000 --> 03:19.000
you have to be a bit of an egomaniac, right?

03:19.000 --> 03:22.000
I know that you're right and everybody else is kind of wrong.

03:22.000 --> 03:26.000
Look I mean all of what we do is information classification

03:26.000 --> 03:28.000
and that's the nature of artificial intelligence.

03:28.000 --> 03:31.000
So information comes in and then Claude Shannon

03:31.000 --> 03:33.000
style of information theory.

03:33.000 --> 03:35.000
Information is only valuable as much as the change in the state

03:35.000 --> 03:37.000
so you're always looking for something on that graph

03:37.000 --> 03:39.000
or that new thing that will cause you to change

03:39.000 --> 03:41.000
from a buy to a sell or an increase or decrease

03:41.000 --> 03:43.000
in your positioning, right?

03:43.000 --> 03:45.000
I kind of realized over the years though

03:45.000 --> 03:48.000
like my background was mathematics, computer science originally

03:48.000 --> 03:50.000
quite quantitative, quite analytical.

03:50.000 --> 03:54.000
The next wave of AI was something a bit different

03:54.000 --> 03:56.000
that would enable us to do something a bit different

03:56.000 --> 03:59.000
because we moved from this big data age, you know

03:59.000 --> 04:01.000
where you had massive amounts of information

04:01.000 --> 04:03.000
and extrapolated it and targeted it to kind of sell

04:03.000 --> 04:06.000
Raoul some suntan or whatever, you know?

04:06.000 --> 04:08.000
To something a bit different, a big model

04:08.000 --> 04:10.000
You're jealous of my tan.

04:10.000 --> 04:12.000
I'm jealous of your tan.

04:12.000 --> 04:14.000
I'm in London, you're in Cayman Island, I'm turning pasty.

04:14.000 --> 04:16.000
Completely.

04:16.000 --> 04:18.000
I have to fly out there too.

04:18.000 --> 04:20.000
So moving from that area was about extrapolation

04:20.000 --> 04:23.000
in the individual to something new in 2017

04:23.000 --> 04:25.000
which was a big model age.

04:25.000 --> 04:28.000
AI went from being able just to extrapolation

04:28.000 --> 04:30.000
to being able to pay attention.

04:30.000 --> 04:32.000
In fact, there was a seminal paper called

04:32.000 --> 04:35.000
attention is all you need about how to build an AI

04:35.000 --> 04:37.000
that paid attention to the most important parts of a sentence

04:37.000 --> 04:39.000
the most important parts of an image

04:39.000 --> 04:42.000
to do principle based analysis

04:42.000 --> 04:44.000
which is insane if you think about it

04:44.000 --> 04:46.000
this is exactly what we do, right?

04:46.000 --> 04:48.000
What do you mean by principle based analysis?

04:48.000 --> 04:50.000
Sorry.

04:50.000 --> 04:52.000
So rather than doing extrapolation

04:52.000 --> 04:54.000
so rather than doing momentum, beta

04:54.000 --> 04:57.000
AI became able to do alpha

04:57.000 --> 05:00.000
it became able to basically come up with principles

05:00.000 --> 05:02.000
that allowed it to understand

05:02.000 --> 05:04.000
the hidden layers of meaning

05:04.000 --> 05:06.000
with things.

05:06.000 --> 05:08.000
So you can go into a bit more detail

05:08.000 --> 05:10.000
but this is how the human brain works, right?

05:10.000 --> 05:12.000
We have two parts of our brain

05:12.000 --> 05:14.000
which is like the past

05:14.000 --> 05:16.000
and that's a tiger over there

05:16.000 --> 05:18.000
in that bush, right?

05:18.000 --> 05:20.000
It's the type one type two kind of thinking

05:20.000 --> 05:22.000
so AI was always the extrapolation

05:22.000 --> 05:24.000
and now we have a new type of AI

05:24.000 --> 05:26.000
that mimics the human brain

05:26.000 --> 05:28.000
by figuring out principles

05:28.000 --> 05:30.000
from highly structured data

05:30.000 --> 05:32.000
which is kind of what we did every single day

05:32.000 --> 05:34.000
as the finance guys, right?

05:34.000 --> 05:36.000
But at a completely different scale

05:36.000 --> 05:38.000
I don't think even now people have appreciated

05:38.000 --> 05:40.000
how big a change that's going to be

05:40.000 --> 05:42.000
I think we're starting to figure that out now.

05:42.000 --> 05:44.000
So

05:44.000 --> 05:46.000
before we get into the guts of this

05:46.000 --> 05:48.000
let's go on a bit of the journey

05:48.000 --> 05:50.000
of AI

05:50.000 --> 05:52.000
because you've talked about where it was

05:52.000 --> 05:54.000
and then we started to see stuff like

05:54.000 --> 05:56.000
DeepMind

05:56.000 --> 05:58.000
and then GPT-3

05:58.000 --> 06:00.000
OpenAI, all of this.

06:00.000 --> 06:02.000
So if you can just frame it for people

06:02.000 --> 06:04.000
because a lot of this is going to be new for people

06:04.000 --> 06:06.000
and I think it's incredibly important

06:06.000 --> 06:08.000
people understand what's happening

06:08.000 --> 06:10.000
and where the hell of this is going.

06:10.000 --> 06:12.000
Yeah, so if you look at DeepMind

06:12.000 --> 06:14.000
they are famous for

06:14.000 --> 06:16.000
many things, you know, Demos has done

06:16.000 --> 06:18.000
a fantastic job.

06:18.000 --> 06:20.000
One of the things they did is

06:20.000 --> 06:22.000
thinking back, you had Gary Kasparov

06:22.000 --> 06:24.000
being beaten by Deep Blue

06:24.000 --> 06:26.000
so you know, as older fellows we remember that

06:26.000 --> 06:28.000
not like the younger with the snapkins

06:28.000 --> 06:30.000
who'd never seen a bear market in their lives

06:30.000 --> 06:32.000
you know, kind of changes happening

06:32.000 --> 06:34.000
what Deep Blue did was

06:34.000 --> 06:36.000
it did an analysis of every single game

06:36.000 --> 06:38.000
in the past and then extrapolated

06:38.000 --> 06:40.000
and then it brute-forced it.

06:40.000 --> 06:42.000
So Gary could only think X moves in the future

06:42.000 --> 06:44.000
he could think X plus 2, X plus 3

06:44.000 --> 06:46.000
and that's how he got beaten by brute-force.

06:46.000 --> 06:48.000
Now, the Chinese game of Go

06:48.000 --> 06:50.000
Chinese checkers, effectively

06:50.000 --> 06:52.000
people thought you'd never be able to brute-force it

06:52.000 --> 06:54.000
because there's too many things that you can do

06:54.000 --> 06:56.000
there's too many moves on that board, right?

06:56.000 --> 06:58.000
And so they were like,

06:58.000 --> 07:00.000
that'll never be beaten by computer

07:00.000 --> 07:02.000
because you need to build a computer that's

07:02.000 --> 07:04.000
the biggest computer ever

07:04.000 --> 07:06.000
times a million.

07:06.000 --> 07:08.000
What DeepMind did

07:08.000 --> 07:10.000
is that basically they came up with

07:10.000 --> 07:12.000
a self-supervised learning algorithm

07:12.000 --> 07:14.000
that

07:14.000 --> 07:16.000
learned how to dream

07:16.000 --> 07:18.000
that's probably the best way to kind of put it

07:18.000 --> 07:20.000
about how one would play

07:20.000 --> 07:22.000
Go in a principled way

07:22.000 --> 07:24.000
so it didn't even have

07:24.000 --> 07:26.000
all the past games in its memory

07:26.000 --> 07:28.000
it just played against itself and tried to figure out

07:28.000 --> 07:30.000
how to do this. They made a whole base of these

07:30.000 --> 07:32.000
agents with reinforcement learning

07:32.000 --> 07:34.000
that you gave it an Atari with no instructions

07:34.000 --> 07:36.000
that learned how to play Breakout

07:36.000 --> 07:38.000
and then Starcraft

07:38.000 --> 07:40.000
without any instructions

07:40.000 --> 07:42.000
people need to understand that, they figured it out

07:42.000 --> 07:44.000
you put it in front of the computer

07:44.000 --> 07:46.000
and it just figures it out and it gets better and better

07:46.000 --> 07:48.000
so when you see it playing Breakout

07:48.000 --> 07:50.000
it's suddenly doing these crazy moves like that

07:50.000 --> 07:52.000
and so Lisa Doll was like a seventh Dan

07:52.000 --> 07:54.000
in Go

07:54.000 --> 07:56.000
so she was a Magnus Carlson

07:56.000 --> 07:58.000
of Go effectively

07:58.000 --> 08:00.000
and it wasn't a current Magnus Carlson

08:00.000 --> 08:02.000
type situation, it's very difficult to cheat in Go

08:02.000 --> 08:04.000
because you didn't have to be able to talk to you

08:04.000 --> 08:06.000
we're not talking about anal probes in this one

08:06.000 --> 08:08.000
we're talking about

08:08.000 --> 08:10.000
compensation is going pretty well

08:10.000 --> 08:12.000
so what happened is

08:12.000 --> 08:14.000
that the next highest person

08:14.000 --> 08:16.000
was like a fourth Dan or something

08:16.000 --> 08:18.000
so he's like Federer Carlson rolled into one

08:18.000 --> 08:20.000
that much better, I was like never beat him

08:20.000 --> 08:22.000
he won one game

08:22.000 --> 08:24.000
the computer won seven

08:24.000 --> 08:26.000
and everyone was like holy crap

08:26.000 --> 08:28.000
what is that, because computer learned to play

08:28.000 --> 08:30.000
in a completely different way

08:30.000 --> 08:32.000
and it was like it was playing with an alien

08:32.000 --> 08:34.000
because it didn't learn past games

08:36.000 --> 08:38.000
as you said it learns an entirely new way

08:38.000 --> 08:40.000
literally it played against itself

08:40.000 --> 08:42.000
it dreamt

08:42.000 --> 08:44.000
so then it plays against itself in its memory

08:44.000 --> 08:46.000
and then it does that again and again and again

08:46.000 --> 08:48.000
and so within just a few weeks

08:48.000 --> 08:50.000
it outperformed him

08:50.000 --> 08:52.000
and then these models got better and better

08:52.000 --> 08:54.000
and smaller and smaller, we haven't seen the generalization of the models yet

08:54.000 --> 08:56.000
but they're coming

08:56.000 --> 08:58.000
so you have to optimize when you don't even tell it the rules

08:58.000 --> 09:00.000
which is kind of insane

09:00.000 --> 09:02.000
then on the other hand

09:02.000 --> 09:04.000
you had what was known as foundation models

09:04.000 --> 09:06.000
which is where this attention based

09:06.000 --> 09:08.000
architecture came in

09:08.000 --> 09:10.000
so in the attention thing they were seeing when the games were

09:10.000 --> 09:12.000
actually a final thing about this

09:12.000 --> 09:14.000
and you can see this in the AlphaGo documentary

09:14.000 --> 09:16.000
that's on YouTube if you want to see more details

09:16.000 --> 09:18.000
is that as a result of this

09:18.000 --> 09:20.000
did Lisa doll go and say

09:20.000 --> 09:22.000
I'm hanging up my go pieces

09:22.000 --> 09:24.000
and I'm going to pack them away, no

09:24.000 --> 09:26.000
he started playing against it and now he's even better

09:26.000 --> 09:28.000
as a player

09:28.000 --> 09:30.000
and the entire go

09:30.000 --> 09:32.000
competitive scene has improved

09:32.000 --> 09:34.000
because now they're figuring out brand new ways

09:34.000 --> 09:36.000
and gambits and things they'd never seen before

09:36.000 --> 09:38.000
which I think is really interesting

09:38.000 --> 09:40.000
then you had this other big area

09:40.000 --> 09:42.000
which was kind of some of this deep learning area

09:42.000 --> 09:44.000
we have these big corpuses

09:44.000 --> 09:46.000
and like I said you can do extrapolations

09:46.000 --> 09:48.000
but you don't understand meaning

09:48.000 --> 09:50.000
and so this is where these attention based architectures came in

09:50.000 --> 09:52.000
it's actually quite interesting

09:52.000 --> 09:54.000
when I was taking a break

09:54.000 --> 09:56.000
from fund management to work with my son

09:56.000 --> 09:58.000
autism is a very interesting condition

09:58.000 --> 10:00.000
no cure, nothing to be done

10:00.000 --> 10:02.000
so of course you know you go and quit being a hedge fund manager

10:02.000 --> 10:04.000
and build a team and try to do it

10:04.000 --> 10:06.000
because you go maniacs right

10:06.000 --> 10:08.000
my wife is a applied behavioural

10:08.000 --> 10:10.000
analyst who just treats kids

10:10.000 --> 10:12.000
with autism

10:12.000 --> 10:14.000
so I lived that life

10:14.000 --> 10:16.000
exactly so applied behavioural

10:16.000 --> 10:18.000
analysis uses variable

10:18.000 --> 10:20.000
rewards and a lot of the stuff you use in video games

10:20.000 --> 10:22.000
to rebuild words

10:22.000 --> 10:24.000
so if you have a stroke or you have autism

10:24.000 --> 10:26.000
you haven't basically said can

10:26.000 --> 10:28.000
right so the word can can mean I can

10:28.000 --> 10:30.000
it can mean that can

10:30.000 --> 10:32.000
it can mean the can can

10:32.000 --> 10:34.000
lots of different things

10:34.000 --> 10:36.000
but because there's so much noise in the brain

10:36.000 --> 10:38.000
which is why you see a lot of kids and adults with autism

10:38.000 --> 10:40.000
not being able to handle large amounts of information

10:40.000 --> 10:42.000
I don't have aspergers myself and ADHD

10:42.000 --> 10:44.000
they usually balance out

10:44.000 --> 10:46.000
sometimes not quite

10:46.000 --> 10:48.000
it's very difficult to pay attention

10:48.000 --> 10:50.000
to how you feel that

10:50.000 --> 10:52.000
like you know when your leg is tapping

10:52.000 --> 10:54.000
there's just too much going on

10:54.000 --> 10:56.000
that's the fugue state

10:56.000 --> 10:58.000
because there's two transmitters in the brain

10:58.000 --> 11:00.000
GABA which calms you down

11:00.000 --> 11:02.000
and GLUTAMATE which excites you

11:02.000 --> 11:04.000
so when you pop a valiant the GABA levels go up

11:04.000 --> 11:06.000
and imagine if your brain was always excited

11:06.000 --> 11:08.000
for one reason or another

11:08.000 --> 11:10.000
you wouldn't be able to concentrate

11:10.000 --> 11:12.000
and build those connections to the word can

11:12.000 --> 11:14.000
you know that hidden layer of meaning

11:14.000 --> 11:16.000
for what can is

11:16.000 --> 11:18.000
what can actually cause it

11:18.000 --> 11:20.000
but because medicine treats everyone the same

11:20.000 --> 11:22.000
it meant that one drug that made 34% of kids better

11:22.000 --> 11:24.000
made 28% of kids worse

11:24.000 --> 11:26.000
so there's no cure and there's no treatment

11:26.000 --> 11:28.000
so that's a different bigger story

11:28.000 --> 11:30.000
and something again this AI can help with

11:30.000 --> 11:32.000
and why is that relevant

11:32.000 --> 11:34.000
it's because what this AI does now

11:34.000 --> 11:36.000
is exactly the same

11:36.000 --> 11:38.000
it uses giant honking supercomputers

11:38.000 --> 11:40.000
so that if you take a terabyte of text

11:40.000 --> 11:42.000
it learns what the most important words

11:42.000 --> 11:44.000
in the sentence are

11:44.000 --> 11:46.000
it took

11:46.000 --> 11:48.000
a thousand gigabytes of text

11:48.000 --> 11:50.000
and it learned how to write in any style

11:50.000 --> 11:52.000
and any extension

11:52.000 --> 11:54.000
so it paid the most important part of any sentence

11:54.000 --> 11:56.000
so you give it a sentence like legolas and gimli

11:56.000 --> 11:58.000
that's all you give it and it'll write an entire scene

11:58.000 --> 12:00.000
in the style of Tolkien

12:00.000 --> 12:02.000
that's never been seen before

12:02.000 --> 12:04.000
you know you give it a sentence

12:04.000 --> 12:06.000
and you say make it happier

12:06.000 --> 12:08.000
it understands what happier is

12:08.000 --> 12:10.000
and this is what's called a latent space of meaning

12:10.000 --> 12:12.000
because it takes

12:12.000 --> 12:14.000
that took one terabyte

12:14.000 --> 12:16.000
of information so a thousand gigabytes

12:16.000 --> 12:18.000
and GPT-3 is about

12:18.000 --> 12:20.000
40 gigabytes in size

12:20.000 --> 12:22.000
but it can recreate any style of writing

12:22.000 --> 12:24.000
an understanding style of writing

12:24.000 --> 12:26.000
which is again a bit crazy

12:26.000 --> 12:28.000
I mean it's

12:28.000 --> 12:30.000
it's staggering and we'll come into the societal impact

12:30.000 --> 12:32.000
on what this all means in a bit

12:32.000 --> 12:34.000
but just want to get through the technology

12:34.000 --> 12:36.000
it is astonishing when you see GPT-3

12:36.000 --> 12:38.000
because basically it writes authentic

12:38.000 --> 12:40.000
pieces

12:40.000 --> 12:42.000
that are not stolen from other things

12:42.000 --> 12:44.000
much like

12:44.000 --> 12:46.000
the deep

12:46.000 --> 12:48.000
deep mind did with go

12:48.000 --> 12:50.000
it wasn't stealing from old games

12:50.000 --> 12:52.000
it learnt how to do it

12:52.000 --> 12:54.000
is that right?

12:54.000 --> 12:56.000
it learnt principles, it learnt stars

12:56.000 --> 12:58.000
it learnt what's called a latent space

12:58.000 --> 13:00.000
the hidden layers of meanings

13:00.000 --> 13:02.000
between different types of words

13:02.000 --> 13:04.000
so like we just released

13:04.000 --> 13:06.000
the most advanced image version of that

13:06.000 --> 13:08.000
stable diffusion

13:08.000 --> 13:10.000
stable diffusion took

13:10.000 --> 13:12.000
100,000 gigabytes

13:12.000 --> 13:14.000
so 100 terabytes of images

13:14.000 --> 13:16.000
and we made a 2 gigabyte file

13:16.000 --> 13:18.000
that can do any style

13:18.000 --> 13:20.000
and any image of any type

13:20.000 --> 13:22.000
so this is like Dali

13:22.000 --> 13:24.000
right?

13:24.000 --> 13:26.000
it's Dali on steroids

13:38.000 --> 13:40.000
so subscribe now to the channel

13:40.000 --> 13:42.000
and never miss an update

13:42.000 --> 13:44.000
there is simply too much going on

13:44.000 --> 13:46.000
so subscribe now, thank you

13:46.000 --> 13:48.000
so

13:48.000 --> 13:50.000
explain Dali and then we'll come into what you're doing

13:50.000 --> 13:52.000
because again

13:52.000 --> 13:54.000
I just want to get people up the knowledge graph

13:54.000 --> 13:56.000
because Dali was the next big one that I stopped

13:56.000 --> 13:58.000
in my tracks and went holy shit this is

13:58.000 --> 14:00.000
amazing

14:00.000 --> 14:02.000
so GPT-3 came out in 2020

14:02.000 --> 14:04.000
and then we released

14:04.000 --> 14:06.000
the open source version of that GPT-Mia

14:06.000 --> 14:08.000
which I'll convert to

14:08.000 --> 14:10.000
last year there was a breakthrough in image generation

14:10.000 --> 14:12.000
so you can generate text and everyone was like

14:12.000 --> 14:14.000
image is too difficult right?

14:14.000 --> 14:16.000
because a picture paints a thousand words

14:16.000 --> 14:18.000
like it's really going to be a thousand kinds of complex

14:18.000 --> 14:20.000
turns out it wasn't

14:20.000 --> 14:22.000
so you had something called clip

14:22.000 --> 14:24.000
which basically you took any image

14:24.000 --> 14:26.000
and it would be able to classify it

14:26.000 --> 14:28.000
so it would be able to say that's a Raoul

14:28.000 --> 14:30.000
and that's a red sofa and all these things

14:30.000 --> 14:32.000
understand loads of concepts because they compress that down

14:32.000 --> 14:34.000
then you had a generative model that took words to images

14:34.000 --> 14:36.000
so you had two models, a word to image model

14:36.000 --> 14:38.000
and image to word model

14:38.000 --> 14:40.000
and at the start of last year we figured out how to bounce them off each other

14:40.000 --> 14:42.000
so it would generate an image

14:42.000 --> 14:44.000
and it would check if that image was the same as the prompt

14:44.000 --> 14:46.000
and it would go back and forth, back and forth

14:46.000 --> 14:48.000
and after 10 minutes you'd generate

14:48.000 --> 14:50.000
a semulchrum of an image

14:50.000 --> 14:52.000
from the word input so words go in and images come out

14:52.000 --> 14:54.000
and you're like oh crap

14:54.000 --> 14:56.000
it looks a bit mushy

14:56.000 --> 14:58.000
but that's insane, it can generate an image of anything

14:58.000 --> 15:00.000
but it isn't high quality

15:00.000 --> 15:02.000
then what happened is that

15:02.000 --> 15:04.000
OpenAI and us accelerated that whole space

15:04.000 --> 15:06.000
because we thought it was freaking cool

15:06.000 --> 15:08.000
and put lots of research into it

15:08.000 --> 15:10.000
and so you've got to the point now whereby

15:10.000 --> 15:12.000
you can put in Robert De Niro's Gandalf

15:12.000 --> 15:14.000
and one second later

15:14.000 --> 15:16.000
you get an image output

15:16.000 --> 15:18.000
so the first output of that was

15:18.000 --> 15:20.000
that hit the mainstream was Dali from OpenAI

15:20.000 --> 15:22.000
that was in April of this year

15:22.000 --> 15:24.000
so you can say

15:24.000 --> 15:26.000
a cybercone, goth girl

15:26.000 --> 15:28.000
overlooking Neo Tokyo

15:28.000 --> 15:30.000
and boom, 8 seconds later it's generated

15:30.000 --> 15:32.000
and this is a totally unique

15:32.000 --> 15:34.000
creative image that did not exist

15:34.000 --> 15:36.000
in the world before, right?

15:36.000 --> 15:38.000
it did not exist in the world before

15:38.000 --> 15:40.000
all the data that went into that

15:40.000 --> 15:42.000
so it was about 600 million images

15:42.000 --> 15:44.000
it can't recreate any of those images

15:44.000 --> 15:46.000
instead it's learned the

15:46.000 --> 15:48.000
principles of that so again it's

15:48.000 --> 15:50.000
the principle based analysis

15:50.000 --> 15:52.000
which is insane, right?

15:52.000 --> 15:54.000
because it's like

15:54.000 --> 15:56.000
again it's the heuristic stuff that we do all the time

15:56.000 --> 15:58.000
and they combine different concepts

15:58.000 --> 16:00.000
you can say a Van Gogh

16:00.000 --> 16:02.000
by Banksy

16:02.000 --> 16:04.000
and it will do a Van Gogh

16:04.000 --> 16:06.000
by Banksy or you can kind of do a screen

16:06.000 --> 16:08.000
and now there's more and more technologies

16:08.000 --> 16:10.000
that have been measured from that

16:10.000 --> 16:12.000
so OpenAI kind of announced the closed beta

16:12.000 --> 16:14.000
of that and then

16:14.000 --> 16:16.000
my company Stability AI

16:16.000 --> 16:18.000
created a version, well it's 30 times faster

16:18.000 --> 16:20.000
and more powerful

16:20.000 --> 16:22.000
so tell me about Stability AI

16:22.000 --> 16:24.000
when did it start, who's involved

16:24.000 --> 16:26.000
what are you guys doing?

16:26.000 --> 16:28.000
yeah, so starting in 2020

16:28.000 --> 16:30.000
we're technically starting in 2019

16:30.000 --> 16:32.000
with the education work

16:32.000 --> 16:34.000
but I can talk about that later

16:34.000 --> 16:36.000
but 2020 is when it was formed officially

16:36.000 --> 16:38.000
to do the COVID work

16:38.000 --> 16:40.000
so it's lead the UN COVID initiative

16:40.000 --> 16:42.000
launched at Stanford etc

16:42.000 --> 16:44.000
I founded it, yeah

16:44.000 --> 16:46.000
because

16:46.000 --> 16:48.000
someone needs to build something

16:48.000 --> 16:50.000
to do AI as a public good

16:50.000 --> 16:52.000
so I didn't exactly know what the business model was

16:52.000 --> 16:54.000
or anything like that then, I just thought

16:54.000 --> 16:56.000
people are dying effectively

16:56.000 --> 16:58.000
and then we have the other products, actually I'll mention it

16:58.000 --> 17:00.000
so my co-founder and I

17:00.000 --> 17:02.000
so Joe's runs the charitable arm

17:02.000 --> 17:04.000
we have took the global X prize

17:04.000 --> 17:06.000
for learning so that was a $15 million

17:06.000 --> 17:08.000
prize funded by Elon Musk and Tony Robbins

17:08.000 --> 17:10.000
for the first app that could teach

17:10.000 --> 17:12.000
literacy and numeracy in 18 months

17:12.000 --> 17:14.000
for that internet and we've been deploying

17:14.000 --> 17:16.000
in refugee camps and low income areas around the world

17:16.000 --> 17:18.000
to the point where now

17:18.000 --> 17:20.000
we are teaching kids literacy

17:20.000 --> 17:22.000
and numeracy in 13 months and one hour a day

17:22.000 --> 17:24.000
in a refugee camp in Malawi

17:24.000 --> 17:26.000
and we just got the remit

17:26.000 --> 17:28.000
to educate every child in Malawi, 3.9 million kids

17:28.000 --> 17:30.000
with a completely open

17:30.000 --> 17:32.000
book of hardware, software, deployment and curriculum

17:32.000 --> 17:34.000
so we're going to invite the world to say

17:34.000 --> 17:36.000
let's build an open source education system

17:36.000 --> 17:38.000
where the AI teaches the kids and the kids teach the AI

17:38.000 --> 17:40.000
that's the type of stuff that we wanted to do

17:40.000 --> 17:42.000
because so much of the world's issues

17:42.000 --> 17:44.000
are coordination problems

17:44.000 --> 17:46.000
so I figured out how to bring in the multilaterals

17:46.000 --> 17:48.000
the locals and others like the simple mechanism design

17:48.000 --> 17:50.000
and so let's do education

17:50.000 --> 17:52.000
let's do healthcare but then as we were doing this

17:52.000 --> 17:54.000
and we talked to a lot of the big private companies

17:54.000 --> 17:56.000
they promised a lot and they didn't deliver

17:56.000 --> 17:58.000
and it's called me thinking about the future

17:58.000 --> 18:00.000
so some of the people on this call

18:00.000 --> 18:02.000
will be familiar with

18:02.000 --> 18:04.000
the Chinese social credit score system

18:04.000 --> 18:06.000
and the use of AI in China

18:06.000 --> 18:08.000
to identify Ugears and others

18:08.000 --> 18:10.000
and everyone's got a rating

18:10.000 --> 18:12.000
you hang out with someone with too low a rating

18:12.000 --> 18:14.000
your rating starts to go down

18:14.000 --> 18:16.000
8 million people in China can't use planes or trains

18:16.000 --> 18:18.000
it's behavioural economics right

18:18.000 --> 18:20.000
done by AI

18:20.000 --> 18:22.000
it's gamified life

18:22.000 --> 18:24.000
life has become a video game

18:24.000 --> 18:26.000
and AI is the extra system on top

18:26.000 --> 18:28.000
but now you think about it

18:28.000 --> 18:30.000
the entire web 2

18:30.000 --> 18:32.000
was basically Facebook and Google

18:32.000 --> 18:34.000
it was AI

18:34.000 --> 18:36.000
big data models

18:36.000 --> 18:38.000
and now you've moved to the big model era

18:38.000 --> 18:40.000
where to build these models you need to have the best data

18:40.000 --> 18:42.000
amazingly smart people

18:42.000 --> 18:44.000
and fricking supercomputers

18:44.000 --> 18:46.000
why fricking supercomputers I mean

18:46.000 --> 18:48.000
is that a multiple times faster than NASA

18:48.000 --> 18:50.000
supercomputers because that's what compresses

18:50.000 --> 18:52.000
this data down into knowledge

18:52.000 --> 18:54.000
so information to knowledge on this

18:54.000 --> 18:56.000
because knowledge is when you extract the principles

18:56.000 --> 18:58.000
from information right

18:58.000 --> 19:00.000
and then wisdom is when you apply it to today

19:00.000 --> 19:02.000
so we have this some knowledge extraction system

19:02.000 --> 19:04.000
so I looked at that and I was like

19:04.000 --> 19:06.000
the only people that can build this are NVIDIA

19:06.000 --> 19:08.000
Meta, Google

19:08.000 --> 19:10.000
slash DeepMind, Microsoft

19:10.000 --> 19:12.000
slash OpenAI

19:12.000 --> 19:14.000
and how are they aligned

19:14.000 --> 19:16.000
because this is super powerful technology

19:16.000 --> 19:18.000
they can be used to target us ads better than anything else

19:18.000 --> 19:20.000
or it can be used to change our mind because it's convincing

19:20.000 --> 19:22.000
you see GPT-3 writing

19:22.000 --> 19:24.000
you can't tell it's not a human

19:24.000 --> 19:26.000
right

19:26.000 --> 19:28.000
you look at the audio version you can't listen

19:28.000 --> 19:30.000
say it's not human like my sister-in-law

19:30.000 --> 19:32.000
Zeena just sold her company

19:32.000 --> 19:34.000
to Spotify, it's an Antik

19:34.000 --> 19:36.000
fully emotionally real AI voices

19:36.000 --> 19:38.000
using this technology

19:38.000 --> 19:40.000
so she did the technology for all the

19:40.000 --> 19:42.000
Blizzard and everything

19:42.000 --> 19:44.000
and then somebody has now got AI

19:44.000 --> 19:46.000
for creating podcasts

19:46.000 --> 19:48.000
so you can have Joe Rogan interviewing

19:48.000 --> 19:50.000
Steve Jobs

19:50.000 --> 19:52.000
neither of these exist and the interview never existed

19:52.000 --> 19:54.000
but the AI does it

19:54.000 --> 19:56.000
and it sounds just like them right

19:56.000 --> 19:58.000
and this is the thing it's got that human level

19:58.000 --> 20:00.000
so like Sanantik also did

20:00.000 --> 20:02.000
Bal Kilmer's voice for his documentary

20:02.000 --> 20:04.000
in Top Gun because he lost it completely

20:04.000 --> 20:06.000
and it's completely emotionally real

20:06.000 --> 20:08.000
so it's getting to that period of emotional realness

20:08.000 --> 20:10.000
and human realness

20:10.000 --> 20:12.000
which means then you think about the future and you're like

20:12.000 --> 20:14.000
this is one of the most powerful technologies

20:14.000 --> 20:16.000
ever because it's approaching humanity

20:16.000 --> 20:18.000
not in a generalized sense

20:18.000 --> 20:20.000
where the AI can do everything in its sky net

20:20.000 --> 20:22.000
but as a tool

20:22.000 --> 20:24.000
for targeting and convincing

20:24.000 --> 20:26.000
and manipulation

20:26.000 --> 20:28.000
so what happens if only big tech companies

20:28.000 --> 20:30.000
do this because they went from being open

20:30.000 --> 20:32.000
to being private even open AI

20:32.000 --> 20:34.000
that got a billion dollars from Musk

20:34.000 --> 20:36.000
and others and then a billion from Microsoft

20:36.000 --> 20:38.000
stop releasing their code

20:38.000 --> 20:40.000
so people can have this

20:40.000 --> 20:42.000
so they turn closed

20:42.000 --> 20:44.000
and then they stop sharing

20:44.000 --> 20:46.000
and you're like as this is the most powerful thing

20:46.000 --> 20:48.000
if you fast forward 5-10 years

20:48.000 --> 20:50.000
does it make sense that a private company will have a monopoly

20:50.000 --> 20:52.000
or a series of private companies will have a monopoly on this

20:52.000 --> 20:54.000
then it will reflect

20:54.000 --> 20:56.000
basically Palo Alto norms

20:56.000 --> 20:58.000
and it will mean those companies are more powerful

20:58.000 --> 21:00.000
than any government in the earth

21:00.000 --> 21:02.000
and I was like that's wrong

21:02.000 --> 21:04.000
I was like there needs to be

21:04.000 --> 21:06.000
an alternative that is open

21:06.000 --> 21:08.000
you know kind of AI for the people by the people we call it

21:08.000 --> 21:10.000
because

21:10.000 --> 21:12.000
not only is that morally right

21:12.000 --> 21:14.000
because it's unethical to keep powerful technology

21:14.000 --> 21:16.000
that can make people's lives better

21:16.000 --> 21:18.000
from the people that can benefit from it the most

21:18.000 --> 21:20.000
but it's actually a better model

21:20.000 --> 21:22.000
because you have open innovation

21:22.000 --> 21:24.000
this is why Linux became the servers of choice

21:24.000 --> 21:26.000
and the most secure servers

21:26.000 --> 21:28.000
Windows has all these holes in

21:28.000 --> 21:30.000
Linux holes get patched instantly right

21:30.000 --> 21:32.000
this is where you've got databases kind of taking over

21:32.000 --> 21:34.000
because nothing can beat human creativity when that happened

21:34.000 --> 21:36.000
I look at web3 and crypto

21:36.000 --> 21:38.000
and I'm like it nearly got there

21:38.000 --> 21:40.000
and then it kind of got hijacked

21:40.000 --> 21:42.000
because it was part of the puzzle

21:42.000 --> 21:44.000
but it wasn't the whole puzzle

21:44.000 --> 21:46.000
because when I went to talk to a lot of web3 people

21:46.000 --> 21:48.000
I'm like where's the AI in web3

21:48.000 --> 21:50.000
they were like well we'll get to it

21:50.000 --> 21:52.000
but I was like the whole of web2 was AI

21:52.000 --> 21:54.000
how are you gonna do web3 without AI

21:54.000 --> 21:56.000
and when they gave examples like Alephia

21:56.000 --> 21:58.000
and other things

21:58.000 --> 22:00.000
with the talking NFTs

22:00.000 --> 22:02.000
the technology they used was our technology

22:02.000 --> 22:04.000
and we released

22:04.000 --> 22:06.000
but usgpt near

22:06.000 --> 22:08.000
which I thought was quite interesting

22:08.000 --> 22:10.000
so then I realised it's actually a bigger thing here

22:10.000 --> 22:12.000
and a bigger reason to do this

22:12.000 --> 22:14.000
but how do you compete with open AI

22:14.000 --> 22:16.000
and deep mines and Microsoft and Google

22:16.000 --> 22:18.000
with their billions of dollars of budget

22:20.000 --> 22:22.000
which was an interesting one

22:22.000 --> 22:24.000
how do you do it right

22:24.000 --> 22:26.000
do you go and raise two billion dollars

22:26.000 --> 22:28.000
no go do it another way

22:28.000 --> 22:30.000
so what did you do

22:30.000 --> 22:32.000
so I built community

22:32.000 --> 22:34.000
so in 2020 a lot of people

22:34.000 --> 22:36.000
were just like you know COVID

22:36.000 --> 22:38.000
and in quarantine

22:38.000 --> 22:40.000
so we built up a Luther AI

22:40.000 --> 22:42.000
which the base principle was

22:42.000 --> 22:44.000
let's create an open source version of GPT3

22:44.000 --> 22:46.000
you know

22:46.000 --> 22:48.000
did you create it

22:48.000 --> 22:50.000
or clone GPT3

22:50.000 --> 22:52.000
and then allowed to build on top

22:52.000 --> 22:54.000
how do you start this

22:54.000 --> 22:56.000
so like there were five initial creators

22:56.000 --> 22:58.000
and then I came like a month after

22:58.000 --> 23:00.000
and we were working with some of the second wave

23:00.000 --> 23:02.000
and said let's accelerate this up

23:02.000 --> 23:04.000
so they looked at the model so the data wasn't open

23:04.000 --> 23:06.000
so we had to create our own data set

23:06.000 --> 23:08.000
and so we had to crawl the internet

23:08.000 --> 23:10.000
and create a terabyte of data

23:10.000 --> 23:12.000
the compute wasn't available

23:12.000 --> 23:14.000
so we got a grant from Google

23:14.000 --> 23:16.000
who provided the compute initially

23:16.000 --> 23:18.000
and then the expertise

23:18.000 --> 23:20.000
it was all like PhD students

23:20.000 --> 23:22.000
or self-taught programmers

23:22.000 --> 23:24.000
and others were like how would this work

23:24.000 --> 23:26.000
because they released an academic paper

23:26.000 --> 23:28.000
from scratch and then created a model

23:28.000 --> 23:30.000
that was 75% as good

23:30.000 --> 23:32.000
but it was available

23:32.000 --> 23:34.000
so the models from a Luther AI

23:34.000 --> 23:36.000
which kind of stability runs now

23:36.000 --> 23:38.000
basically via the top level

23:38.000 --> 23:40.000
people but we're going to spin it off

23:40.000 --> 23:42.000
into its own independent charity

23:42.000 --> 23:44.000
for a number of reasons

23:44.000 --> 23:46.000
they've been downloaded 25 million times

23:46.000 --> 23:48.000
now by developers

23:48.000 --> 23:50.000
so anytime you see a chat bot

23:50.000 --> 23:52.000
or something like that that's getting to human levels

23:52.000 --> 23:54.000
it's probably going to be that

23:54.000 --> 23:56.000
it's 80% as good as GPT-3

23:56.000 --> 23:58.000
but it doesn't matter because you can customize it

23:58.000 --> 24:00.000
and you can extend it

24:00.000 --> 24:02.000
and you can run it on your own hardware

24:02.000 --> 24:04.000
so it's a 20 billion parameter model

24:04.000 --> 24:06.000
versus 175 billion parameter model

24:06.000 --> 24:08.000
it's eight times smaller

24:08.000 --> 24:10.000
but you know it's just like the big steel mills

24:10.000 --> 24:12.000
and the little ones if you look at the kind of Clayton Christian

24:12.000 --> 24:14.000
small can outcompete big

24:14.000 --> 24:16.000
and then I realized that there's a talent arbitrage here

24:16.000 --> 24:18.000
whereby there's a lot of people

24:18.000 --> 24:20.000
that want to build open source

24:20.000 --> 24:22.000
but there's no super compute

24:22.000 --> 24:24.000
in academia so when I said super compute

24:24.000 --> 24:26.000
needed for this I meant it

24:26.000 --> 24:28.000
like the

24:28.000 --> 24:30.000
amount of super compute

24:30.000 --> 24:32.000
the amount of breakthroughs in this foundational

24:32.000 --> 24:34.000
model research

24:34.000 --> 24:36.000
20 years ago 100% came from academia

24:36.000 --> 24:38.000
10 years ago 75%

24:38.000 --> 24:40.000
came from academia last year

24:40.000 --> 24:42.000
0% came from academia

24:42.000 --> 24:44.000
because there was this

24:44.000 --> 24:46.000
massive ramp-up in compute capabilities

24:46.000 --> 24:48.000
but academia couldn't access it

24:48.000 --> 24:50.000
only private companies could

24:50.000 --> 24:52.000
so if you wanted to have a breakthrough

24:52.000 --> 24:54.000
or work in cutting edge research you had three options

24:54.000 --> 24:56.000
do a start up, start up suck

24:56.000 --> 24:58.000
put that to the side, especially for academics

24:58.000 --> 25:00.000
number two you go and work for big tech

25:00.000 --> 25:02.000
and then you get 59 page NDAs

25:02.000 --> 25:04.000
and you might do cool stuff

25:04.000 --> 25:06.000
like we've seen text to video from the Google team

25:06.000 --> 25:08.000
that'll never be released by Google

25:08.000 --> 25:10.000
because of ethical fears which we can discuss

25:10.000 --> 25:12.000
and the final option is

25:12.000 --> 25:14.000
you go and work for some of these independent labs

25:14.000 --> 25:16.000
like OpenAI and others that were meant to be independent

25:16.000 --> 25:18.000
and then became less independent over time

25:18.000 --> 25:20.000
otherwise you stay in academia and you're like

25:20.000 --> 25:22.000
I would like to do these but I can't

25:22.000 --> 25:24.000
so I saw that the core

25:24.000 --> 25:26.000
choke point was compute

25:26.000 --> 25:28.000
a community was forming for talent

25:28.000 --> 25:30.000
and then we need to be highly structured about data

25:30.000 --> 25:32.000
so what I did was

25:32.000 --> 25:34.000
I said how big a super computer can I build

25:34.000 --> 25:36.000
if I put all my money into it

25:36.000 --> 25:38.000
and I'd become very persuasive

25:38.000 --> 25:40.000
and then I built the 10th fastest public

25:40.000 --> 25:42.000
super computer in the world in four months

25:44.000 --> 25:46.000
and it turns out you can build a very large super computer

25:46.000 --> 25:48.000
so Ezra 1 which is our super computer

25:48.000 --> 25:50.000
which all my money went into

25:50.000 --> 25:52.000
is about

25:52.000 --> 25:54.000
eight times faster than the fastest

25:54.000 --> 25:56.000
super computer in the UK

25:56.000 --> 25:58.000
and about seven times faster than all of NASA's

25:58.000 --> 26:00.000
super computers put together

26:00.000 --> 26:02.000
and that's the level that you need

26:02.000 --> 26:04.000
to basically create these models

26:04.000 --> 26:06.000
it's like the entry level

26:06.000 --> 26:08.000
that need for compute keeps going up

26:08.000 --> 26:10.000
can you use distributed computing power

26:10.000 --> 26:12.000
or is it still not fast enough

26:12.000 --> 26:14.000
so

26:14.000 --> 26:16.000
you can do it once you've done the initial model

26:16.000 --> 26:18.000
so what happens is that you take

26:18.000 --> 26:20.000
in this case we took 100,000 gigabytes of data

26:20.000 --> 26:22.000
so we made the biggest image data set in the world

26:22.000 --> 26:24.000
previously the largest was 100 million

26:24.000 --> 26:26.000
then we made 400 million

26:26.000 --> 26:28.000
then we made 5.6 billion

26:28.000 --> 26:30.000
a 250 terabyte image

26:30.000 --> 26:32.000
label pair data set

26:32.000 --> 26:34.000
then we took 2 billion of that

26:34.000 --> 26:36.000
which is the high quality images and then we crunched them back and forth on this

26:36.000 --> 26:38.000
so what happens is after you crunched

26:38.000 --> 26:40.000
them back and forth then you've got a file

26:40.000 --> 26:42.000
that can be adapted and trained

26:42.000 --> 26:44.000
basically it's gone through

26:44.000 --> 26:46.000
primary school

26:46.000 --> 26:48.000
of learning

26:48.000 --> 26:50.000
and then you can teach it more advanced concepts

26:50.000 --> 26:52.000
so like some people are taking the training on Japanese

26:52.000 --> 26:54.000
concepts, some people are taking

26:54.000 --> 26:56.000
anime cat girl, waifus or whatever

26:56.000 --> 26:58.000
you can add that specialization

26:58.000 --> 27:00.000
once it's achieved kind of the high school level

27:00.000 --> 27:02.000
so there's a big compute

27:02.000 --> 27:04.000
and a little computer

27:04.000 --> 27:06.000
does the network then learn from all of these people

27:06.000 --> 27:08.000
working on the network itself

27:08.000 --> 27:10.000
no

27:10.000 --> 27:12.000
it's distributed and you've got lots of people doing different things

27:12.000 --> 27:14.000
does that increase the knowledge base

27:14.000 --> 27:16.000
or not

27:16.000 --> 27:18.000
it increases the large base of the community

27:18.000 --> 27:20.000
but we have to understand this model

27:20.000 --> 27:22.000
it's not a distributed model where it's like lots of little

27:22.000 --> 27:24.000
brain cells out there

27:24.000 --> 27:26.000
it's a 2

27:26.000 --> 27:28.000
gigabyte file

27:28.000 --> 27:30.000
that can recreate

27:30.000 --> 27:32.000
and create any image in any style

27:32.000 --> 27:34.000
so you took 100,000 gigabytes of image and created

27:34.000 --> 27:36.000
so sometimes I think

27:36.000 --> 27:38.000
I'm on that Silicon Valley show

27:38.000 --> 27:40.000
and we're from HBO

27:40.000 --> 27:42.000
and we're Pied Piper and I think

27:42.000 --> 27:44.000
crap, am I Erlich Backman or Ross Hanneman

27:44.000 --> 27:46.000
you know

27:46.000 --> 27:48.000
it's one of those kind of guys right

27:48.000 --> 27:50.000
it's the most advanced technology

27:50.000 --> 27:52.000
the world's ever seen for compression because

27:52.000 --> 27:54.000
the entirety of humanity is basically

27:54.000 --> 27:56.000
about communication and compression

27:56.000 --> 27:58.000
we're compression machines

27:58.000 --> 28:00.000
that's all we do

28:00.000 --> 28:02.000
so people are listening to this podcast now

28:02.000 --> 28:04.000
and they're listening to yours and mine

28:04.000 --> 28:06.000
common context and the compression

28:06.000 --> 28:08.000
and the knowledge that we've had over the years

28:08.000 --> 28:10.000
and they're learning something new right now

28:10.000 --> 28:12.000
it's what we do and hopefully it's valuable

28:12.000 --> 28:14.000
because they'll see that holy crap this new technology way

28:14.000 --> 28:16.000
was coming but if you can do it to images

28:16.000 --> 28:18.000
you can do it to anything so actually how we had

28:18.000 --> 28:20.000
the breakthrough is we took a language model

28:20.000 --> 28:22.000
and image model and we fused them together

28:22.000 --> 28:24.000
and somehow it learned the different concepts

28:24.000 --> 28:26.000
then what we're seeing is that

28:26.000 --> 28:28.000
when you have different models of different types

28:28.000 --> 28:30.000
so someone takes a 2 gigabyte file

28:30.000 --> 28:32.000
you take it and you put it on all your images in

28:32.000 --> 28:34.000
and I take it and I put all my images in

28:34.000 --> 28:36.000
and I fused them together and create another 2 gigabyte file

28:36.000 --> 28:38.000
that knows both of them without going up

28:38.000 --> 28:40.000
in size very much

28:40.000 --> 28:42.000
that's a bit insane in fact

28:42.000 --> 28:44.000
OpenAI did this with a model called GATO

28:44.000 --> 28:46.000
recently

28:46.000 --> 28:48.000
so what happened is that there were

28:48.000 --> 28:50.000
hundreds of different models they built that were quite big

28:50.000 --> 28:52.000
that were like robotics

28:52.000 --> 28:54.000
and playing chess and all these other things

28:56.000 --> 28:58.000
they said what happens if we combine them all together

28:58.000 --> 29:00.000
and see what happens to these latent spaces

29:00.000 --> 29:02.000
the hidden meanings of understanding just like the neurons in our brain

29:02.000 --> 29:04.000
it created a 1.6 billion

29:04.000 --> 29:06.000
parameter file that can

29:06.000 --> 29:08.000
open doors and play chess

29:08.000 --> 29:10.000
and play starcraft and all sorts of other things

29:12.000 --> 29:14.000
and they were like what

29:14.000 --> 29:16.000
and this is the thing

29:16.000 --> 29:18.000
you've got a breakthrough in intelligence

29:18.000 --> 29:20.000
but then you've broken through

29:20.000 --> 29:22.000
to the point where this is the important part

29:22.000 --> 29:24.000
stable diffusion is the first model

29:24.000 --> 29:26.000
that's small enough, fast enough and cheap enough

29:26.000 --> 29:28.000
to go anywhere

29:28.000 --> 29:30.000
so you can run it on your MacBook M1

29:30.000 --> 29:32.000
and you can make Robert De Niro by Banksy

29:32.000 --> 29:34.000
and Renoir

29:34.000 --> 29:36.000
in Guadalajara

29:36.000 --> 29:38.000
in a snowstorm

29:38.000 --> 29:40.000
without internet access

29:40.000 --> 29:42.000
and that 2GB file will reproduce that

29:42.000 --> 29:44.000
faithfully each time

29:46.000 --> 29:48.000
yes

29:48.000 --> 29:50.000
it is a 2GB file that has

29:50.000 --> 29:52.000
compressed the knowledge of the internet

29:52.000 --> 29:54.000
in images

29:54.000 --> 29:56.000
I can't quite get my head around this

29:56.000 --> 29:58.000
so

29:58.000 --> 30:00.000
where do you think

30:00.000 --> 30:02.000
what you're working on goes

30:02.000 --> 30:04.000
what is the image thing, where is this going towards

30:04.000 --> 30:06.000
because right now it's kind of interesting

30:06.000 --> 30:08.000
yes we're going to see

30:08.000 --> 30:10.000
creative industries, marketing, others use this

30:10.000 --> 30:12.000
quite quickly and effectively

30:12.000 --> 30:14.000
but where is this

30:14.000 --> 30:16.000
in your head, where is your mental model

30:16.000 --> 30:18.000
what you're actually working on here

30:18.000 --> 30:20.000
because you're not working on

30:20.000 --> 30:22.000
creating nice images, you're working on something bigger

30:22.000 --> 30:24.000
what is that

30:24.000 --> 30:26.000
it's the intelligent internet

30:26.000 --> 30:28.000
this is about to be pushed out to the edge

30:28.000 --> 30:30.000
so every person, country, country and culture

30:30.000 --> 30:32.000
has their own models that are constantly updated

30:32.000 --> 30:34.000
so you'll have your own model

30:34.000 --> 30:36.000
of all your knowledge across modalities

30:36.000 --> 30:38.000
and you can run it on your local hardware

30:38.000 --> 30:40.000
without being accessed to the internet

30:40.000 --> 30:42.000
so the internet right now is centralized

30:42.000 --> 30:44.000
and all that is running on Google servers

30:44.000 --> 30:46.000
and guiding you, that gets pushed out to the edge

30:46.000 --> 30:48.000
because finally

30:48.000 --> 30:50.000
you have this compression technology

30:50.000 --> 30:52.000
and you know, it's interesting because there's a bunch of structural things here

30:52.000 --> 30:54.000
so Apple is the most interesting thing

30:54.000 --> 30:56.000
with regards to this

30:56.000 --> 30:58.000
Apple will be the biggest AI company in the world in two years

30:58.000 --> 31:00.000
why?

31:00.000 --> 31:02.000
I'm listening to this on a MacBook

31:02.000 --> 31:04.000
M1 right now

31:04.000 --> 31:06.000
16.8% of the chipset

31:06.000 --> 31:08.000
is a neural engine that's not used

31:08.000 --> 31:10.000
that is designed for exactly this type of model

31:10.000 --> 31:12.000
and it's proliferating right

31:12.000 --> 31:14.000
everyone's moving to M1 MacBooks

31:14.000 --> 31:16.000
everyone's moving to A16 Bionics

31:16.000 --> 31:18.000
that also have neural engines

31:18.000 --> 31:20.000
and they're not used, are Apple stupid? No

31:20.000 --> 31:22.000
they have an entire teams building these types of models

31:22.000 --> 31:24.000
for their augmented reality and beyond

31:24.000 --> 31:26.000
so you're going to move from Siri 1 to Siri 5

31:26.000 --> 31:28.000
the Siri is a bit crap

31:28.000 --> 31:30.000
it won't be seen

31:30.000 --> 31:32.000
and so as that technology proliferates

31:32.000 --> 31:34.000
and then people take what

31:34.000 --> 31:36.000
we're building

31:36.000 --> 31:38.000
and you create 100,000 million

31:38.000 --> 31:40.000
new developers in this space

31:40.000 --> 31:42.000
the possibilities are endless

31:42.000 --> 31:44.000
you've seen hundreds of things built on stable diffusion

31:44.000 --> 31:46.000
but like I said, I don't just want images

31:46.000 --> 31:48.000
I want audio, I want video, I want to have text

31:48.000 --> 31:50.000
I want knowledge, I want my databases

31:50.000 --> 31:52.000
combined with my type 1 and type 2 brains

31:52.000 --> 31:54.000
and then you have an AI

31:54.000 --> 31:56.000
that either manipulates you

31:56.000 --> 31:58.000
or it works for you

31:58.000 --> 32:00.000
and my thing is it's open infrastructure

32:00.000 --> 32:02.000
that should work for every individual

32:02.000 --> 32:04.000
and this is also why I've got a very different approach to most

32:04.000 --> 32:06.000
so most people's approach would be B2B

32:06.000 --> 32:08.000
go to the big companies and sell them API access

32:08.000 --> 32:10.000
instead I'm forward deploying

32:10.000 --> 32:12.000
engineers into the biggest brands in the world

32:12.000 --> 32:14.000
getting them to invest in my next round

32:14.000 --> 32:16.000
of financing

32:16.000 --> 32:18.000
and I'm also doing that for countries

32:18.000 --> 32:20.000
like India and saying what's the probability this technology

32:20.000 --> 32:22.000
will be used by everyone in India in 10 to 20 years

32:22.000 --> 32:24.000
100%

32:24.000 --> 32:26.000
or 95%

32:26.000 --> 32:28.000
so I'm saying I will build it for you next year

32:28.000 --> 32:30.000
and getting all the biggest Indian conglomerates

32:30.000 --> 32:32.000
and others together

32:32.000 --> 32:34.000
and taking the smartest engineers out of Silicon Valley

32:34.000 --> 32:36.000
back to India

32:36.000 --> 32:38.000
like one of my fun ones is I have a JV with Eros

32:38.000 --> 32:40.000
which is the Netflix of India

32:40.000 --> 32:42.000
so 200 million daily active users

32:42.000 --> 32:44.000
all the Bollywood content, I have an exclusive on it

32:44.000 --> 32:46.000
and a revenue share

32:46.000 --> 32:48.000
so what's the probability that

32:48.000 --> 32:50.000
Bollywood content will be interactive

32:50.000 --> 32:52.000
through these models

32:52.000 --> 32:54.000
of course it will be

32:54.000 --> 32:56.000
so I'm locking down all the content

32:56.000 --> 32:58.000
Netflix really works on interactive content actually

32:58.000 --> 33:00.000
yeah but not like this

33:00.000 --> 33:02.000
they don't have this expertise because right now

33:02.000 --> 33:04.000
you know how many people can build these models

33:04.000 --> 33:06.000
40

33:06.000 --> 33:08.000
in 5 years how many people will be able to

33:08.000 --> 33:10.000
build these models

33:10.000 --> 33:12.000
4 million

33:12.000 --> 33:14.000
so there's some really interesting arbitrages

33:14.000 --> 33:16.000
in the market right now

33:16.000 --> 33:18.000
and my take is that if I push hard enough

33:18.000 --> 33:20.000
and I outcompete the big guys which I am

33:20.000 --> 33:22.000
like my team is 100 now

33:22.000 --> 33:24.000
you know

33:24.000 --> 33:26.000
and I'm outcompeting these big guys by building

33:26.000 --> 33:28.000
products

33:28.000 --> 33:30.000
products to the market quicker

33:30.000 --> 33:32.000
then I force everyone to go open source

33:32.000 --> 33:34.000
because it's no longer a differentiating factor

33:34.000 --> 33:36.000
and then that changes it

33:36.000 --> 33:38.000
from a closed panopticon for our kids

33:38.000 --> 33:40.000
you know and ourselves

33:40.000 --> 33:42.000
to something different

33:42.000 --> 33:44.000
but I think it's more beneficial

33:44.000 --> 33:46.000
okay so let's talk about what it could be

33:46.000 --> 33:48.000
it's

33:48.000 --> 33:50.000
clearly fucking terrifying

33:50.000 --> 33:52.000
because

33:52.000 --> 33:54.000
either open source or in private hands

33:54.000 --> 33:56.000
if it's open source

33:56.000 --> 33:58.000
it's like a

33:58.000 --> 34:00.000
virus

34:00.000 --> 34:02.000
it'll go where it goes

34:02.000 --> 34:04.000
and people will use it how they use it

34:04.000 --> 34:06.000
and there's no stopping it

34:06.000 --> 34:08.000
okay fine

34:08.000 --> 34:10.000
how does society deal

34:10.000 --> 34:12.000
with the fact that we don't know

34:12.000 --> 34:14.000
who is a human and who is not

34:14.000 --> 34:16.000
and how we're being manipulated

34:16.000 --> 34:18.000
and who not I wrote a thread on this the other day

34:18.000 --> 34:20.000
about digital ID being

34:20.000 --> 34:22.000
one of these key things

34:22.000 --> 34:24.000
but it's this whole element of deep fake

34:24.000 --> 34:26.000
of what is real in this world

34:26.000 --> 34:28.000
how do you deal with this

34:28.000 --> 34:30.000
because it's going to shatter society

34:32.000 --> 34:34.000
it will adjust society definitely

34:34.000 --> 34:36.000
and so

34:36.000 --> 34:38.000
kind of a reason for releasing the model

34:38.000 --> 34:40.000
you know during the COVID thing

34:40.000 --> 34:42.000
I just had a lot of conversations about third immunity

34:42.000 --> 34:44.000
right

34:44.000 --> 34:46.000
which was bad for that

34:46.000 --> 34:48.000
I believe it's good for this

34:48.000 --> 34:50.000
releasing this model out there it's going to be everywhere in a year

34:50.000 --> 34:52.000
this is a one to one

34:52.000 --> 34:54.000
billion person moment right

34:54.000 --> 34:56.000
we're right now a few million people

34:56.000 --> 34:58.000
this is exponential without question

34:58.000 --> 35:00.000
it's exponential without question

35:00.000 --> 35:02.000
but this is a really interesting thing

35:02.000 --> 35:04.000
right now very few people know that you can create anything

35:04.000 --> 35:06.000
in a second

35:06.000 --> 35:08.000
for one cent and less than a cent soon

35:08.000 --> 35:10.000
right soon everyone will know about it

35:10.000 --> 35:12.000
because it will be in all your favourite apps

35:12.000 --> 35:14.000
so we're integrated into Canva right now

35:14.000 --> 35:16.000
we're integrated into Photoshop

35:16.000 --> 35:18.000
you can see big announcements coming out

35:18.000 --> 35:20.000
because we're partnering with everyone

35:20.000 --> 35:22.000
with interactive content

35:22.000 --> 35:24.000
what does that mean it means people suddenly start thinking about this thing

35:24.000 --> 35:26.000
what is real what is not real

35:26.000 --> 35:28.000
and I said identity is key

35:28.000 --> 35:30.000
so the other part of Apple

35:30.000 --> 35:32.000
the fact that they got the identity architecture down

35:32.000 --> 35:34.000
and that allows them to have verified content creation

35:34.000 --> 35:36.000
what we have with Adobe and others

35:36.000 --> 35:38.000
is we've been pushing content

35:38.000 --> 35:40.000
authority basically

35:40.000 --> 35:42.000
which is a small metadata pile

35:42.000 --> 35:44.000
that attaches to every piece of content

35:44.000 --> 35:46.000
and it's hash and if either of them are edited

35:46.000 --> 35:48.000
it changes and it shows that it's not true

35:48.000 --> 35:50.000
it's not a blockchain thing

35:50.000 --> 35:52.000
but it allows you to verify

35:52.000 --> 35:54.000
content

35:54.000 --> 35:56.000
in a positive way

35:56.000 --> 35:58.000
why is it not on blockchain

35:58.000 --> 36:00.000
it's not on blockchain because it doesn't need to be on blockchain

36:00.000 --> 36:02.000
that's why

36:02.000 --> 36:04.000
there's a generalization of the knowledge

36:04.000 --> 36:06.000
because like Google owns all of the knowledge

36:06.000 --> 36:08.000
blockchain is the only way

36:08.000 --> 36:10.000
of not having one central power

36:10.000 --> 36:12.000
owning the knowledge

36:12.000 --> 36:14.000
it is a way

36:14.000 --> 36:16.000
of not having one central power owning the knowledge

36:16.000 --> 36:18.000
and you combine this with a blockchain

36:18.000 --> 36:20.000
but you can think of it as super advanced metadata

36:20.000 --> 36:22.000
so you know when you have metadata

36:22.000 --> 36:24.000
in a file like Exif

36:24.000 --> 36:26.000
when you edit that the file stays constant

36:26.000 --> 36:28.000
with this they're both immutable

36:28.000 --> 36:30.000
effectively so you can tell

36:30.000 --> 36:32.000
that the other has been tampered

36:32.000 --> 36:34.000
so if it says that it's from Raoul

36:34.000 --> 36:36.000
it's from Raoul effectively

36:36.000 --> 36:38.000
but there's no blockchain look up for that

36:38.000 --> 36:40.000
you can make it stronger with a blockchain

36:40.000 --> 36:42.000
but you know it's just a standard that's open source

36:42.000 --> 36:44.000
that we're pushing effectively

36:44.000 --> 36:46.000
so it's kind of a positive one

36:46.000 --> 36:48.000
it's not a negative one

36:48.000 --> 36:50.000
obviously there's ways around that and things like that

36:50.000 --> 36:52.000
but it'll get people thinking about these things

36:52.000 --> 36:54.000
how does identity work in a new age

36:54.000 --> 36:56.000
because so much of what we do is identity

36:56.000 --> 36:58.000
most of finance is basically

36:58.000 --> 37:00.000
most of kind of

37:00.000 --> 37:02.000
the whole blockchain is identity

37:02.000 --> 37:04.000
it's all about identity exchange

37:04.000 --> 37:06.000
so this thing is how can we build better systems for identity

37:06.000 --> 37:08.000
because that's the final part

37:08.000 --> 37:10.000
information, there's massive information

37:10.000 --> 37:12.000
and also stable diffusion

37:12.000 --> 37:14.000
as we released it was a snapshot of the internet

37:14.000 --> 37:16.000
it's biased, it's racist, it's everything

37:16.000 --> 37:18.000
if you enter the prompts and wrong

37:18.000 --> 37:20.000
part of that is

37:20.000 --> 37:22.000
showing some of the images of the racial bias

37:22.000 --> 37:24.000
of the algorithms

37:24.000 --> 37:26.000
so my thing was like

37:26.000 --> 37:28.000
if it's just one company that controls it

37:28.000 --> 37:30.000
what opening I did with Dali

37:30.000 --> 37:32.000
so Dali is a control system, you don't access the code

37:32.000 --> 37:34.000
images or anything

37:34.000 --> 37:36.000
to make it less racist

37:36.000 --> 37:38.000
whenever a gender neutral word

37:38.000 --> 37:40.000
is put like sumo wrestler

37:40.000 --> 37:42.000
it would randomly add

37:42.000 --> 37:44.000
a gender and a race

37:44.000 --> 37:46.000
so you type in sumo wrestler

37:46.000 --> 37:48.000
and you've got Indian female sumo wrestler

37:48.000 --> 37:50.000
tiny little Indian lady

37:50.000 --> 37:52.000
sumo wrestling

37:52.000 --> 37:54.000
and stuff like that

37:54.000 --> 37:56.000
that is one way

37:56.000 --> 37:58.000
but instead my preference is for every single company

37:58.000 --> 38:00.000
country and culture to have their own models

38:00.000 --> 38:02.000
and be able to create their own

38:02.000 --> 38:04.000
and then like I said it becomes acknowledged what it looks like

38:04.000 --> 38:06.000
but then you can set standards

38:06.000 --> 38:08.000
you can be the standard that people build around

38:08.000 --> 38:10.000
and you can incorporate authentication in that standard

38:10.000 --> 38:12.000
because the other way that I talk about these things

38:12.000 --> 38:14.000
is a generative search engine

38:14.000 --> 38:16.000
because now you have stable diffusion

38:16.000 --> 38:18.000
and in six months

38:18.000 --> 38:20.000
it will be perfect photo realistic

38:20.000 --> 38:22.000
12 months maximum

38:22.000 --> 38:24.000
do you need google image search anymore

38:24.000 --> 38:26.000
because what's your job to be done

38:26.000 --> 38:28.000
when you do google image search

38:28.000 --> 38:30.000
is to have a picture of a certain type

38:30.000 --> 38:32.000
now a little fricking two gigabyte file

38:32.000 --> 38:34.000
on your local computer

38:34.000 --> 38:36.000
or something that you pay a fraction of a penny for online

38:36.000 --> 38:38.000
can create any image you can imagine

38:38.000 --> 38:40.000
and you can edit it with your words basically

38:40.000 --> 38:42.000
what is that if not

38:42.000 --> 38:44.000
a search engine of a type

38:44.000 --> 38:46.000
it searches for a concept

38:46.000 --> 38:48.000
and it turns it into an image

38:48.000 --> 38:50.000
it's a creative search engine

38:50.000 --> 38:52.000
that creates

38:52.000 --> 38:54.000
by as you say you just put in a word

38:54.000 --> 38:56.000
or a vocal command and say I want this

38:56.000 --> 38:58.000
and it creates it

38:58.000 --> 39:00.000
but then you can also say

39:00.000 --> 39:02.000
I want a presentation

39:02.000 --> 39:04.000
about

39:04.000 --> 39:06.000
cicada migrations

39:06.000 --> 39:08.000
affecting sesame seed prices

39:08.000 --> 39:10.000
I watched too much Silicon Valley here

39:10.000 --> 39:12.000
and in a couple of years

39:12.000 --> 39:14.000
it will create a beautiful presentation for you

39:14.000 --> 39:16.000
and then you can say I want it to be happier

39:16.000 --> 39:18.000
or sadder or I want it to be more impactful

39:18.000 --> 39:20.000
and it will adjust the presentation dynamically for you

39:20.000 --> 39:22.000
no more powerpoint

39:22.000 --> 39:24.000
but it's going to do video as well right

39:24.000 --> 39:26.000
we don't need to do this

39:26.000 --> 39:28.000
I could just say hey have a conversation

39:28.000 --> 39:30.000
between Raoul and Emad

39:30.000 --> 39:32.000
about AI and here's the narrative arc

39:32.000 --> 39:34.000
and it'll just do it

39:34.000 --> 39:36.000
pretty much yeah just like it does in Steve Jobs

39:36.000 --> 39:38.000
but in 3D video

39:38.000 --> 39:40.000
so like I don't know if I should be talking about this

39:40.000 --> 39:42.000
but I'm going to talk about it anyway

39:42.000 --> 39:44.000
so what if I get in trouble

39:44.000 --> 39:46.000
there are two

39:46.000 --> 39:48.000
there are two boxing legends

39:48.000 --> 39:50.000
families

39:50.000 --> 39:52.000
who are giving us all of the

39:52.000 --> 39:54.000
motion capture data

39:54.000 --> 39:56.000
and media from their lives

39:56.000 --> 39:58.000
and we're building up

39:58.000 --> 40:00.000
an analysis of how that works

40:00.000 --> 40:02.000
so that we can basically say

40:02.000 --> 40:04.000
who won between X and Y

40:04.000 --> 40:06.000
in a fight in their prime run on the supercomputer

40:06.000 --> 40:08.000
where nobody knows the outcome

40:08.000 --> 40:10.000
when they never fought with each other

40:10.000 --> 40:12.000
because they were of different generations

40:12.000 --> 40:14.000
yes

40:14.000 --> 40:16.000
so you can pick two

40:16.000 --> 40:18.000
you can pick two different people

40:18.000 --> 40:20.000
I can't say who they are

40:20.000 --> 40:22.000
but you know those types of things that you've always postulated

40:22.000 --> 40:24.000
we can do that now

40:24.000 --> 40:26.000
and obviously this is going to completely

40:26.000 --> 40:28.000
change music as well right

40:28.000 --> 40:30.000
yeah so we've released our music models already

40:30.000 --> 40:32.000
uh dance diffusion

40:32.000 --> 40:34.000
where we did a slightly different thing

40:34.000 --> 40:36.000
we wanted to take a snapshot of the internet

40:36.000 --> 40:38.000
we made it so everyone can take their back catalogue

40:38.000 --> 40:40.000
incorporate it into a kindergarten level

40:40.000 --> 40:42.000
of knowledge

40:42.000 --> 40:44.000
for the model

40:44.000 --> 40:46.000
and then you can query that

40:46.000 --> 40:48.000
to create your own style in anything

40:48.000 --> 40:50.000
so we call it dance diffusion

40:50.000 --> 40:52.000
and we're teaming up with the top EDM

40:52.000 --> 40:54.000
DJs and others in the world

40:54.000 --> 40:56.000
so that every musician will have their own models

40:56.000 --> 40:58.000
that can generate music

40:58.000 --> 41:00.000
in their style and then

41:00.000 --> 41:02.000
if they give permission we're going to mash them all together

41:02.000 --> 41:04.000
and you've got a generative

41:04.000 --> 41:06.000
Spotify

41:06.000 --> 41:08.000
effectively which then

41:08.000 --> 41:10.000
basically as people prompt it

41:10.000 --> 41:12.000
there's an attribution system where it plays them

41:14.000 --> 41:16.000
and that will just be like 100 gigabytes

41:16.000 --> 41:18.000
as a file that will capture the music of the world

41:18.000 --> 41:20.000
which again is insane

41:20.000 --> 41:22.000
this compression thing

41:22.000 --> 41:24.000
you know it's actually like you know

41:24.000 --> 41:26.000
you read so much right Raoul

41:26.000 --> 41:28.000
and then you write your notes

41:28.000 --> 41:30.000
and then you write your investment thesis

41:30.000 --> 41:32.000
investment thesis is compression of knowledge

41:32.000 --> 41:34.000
a vaccine schedule is compression of knowledge

41:34.000 --> 41:36.000
we finally figured out how to make computers

41:36.000 --> 41:38.000
compress information into knowledge

41:38.000 --> 41:40.000
so

41:40.000 --> 41:42.000
I mean this is

41:42.000 --> 41:44.000
I knew this was going to be an interesting conversation

41:44.000 --> 41:46.000
and I've been

41:46.000 --> 41:48.000
looking at this for a while

41:48.000 --> 41:50.000
but Franklin

41:50.000 --> 41:52.000
fucking staggered at how fast this is moving

41:52.000 --> 41:54.000
and what you're doing

41:54.000 --> 41:56.000
I mean this is

41:56.000 --> 41:58.000
truly exponential as you say

41:58.000 --> 42:00.000
within two or three years

42:00.000 --> 42:02.000
this is multiple billion people

42:02.000 --> 42:04.000
and the complete shift on a humanity level

42:04.000 --> 42:06.000
of how

42:06.000 --> 42:08.000
information is processed and delivered

42:08.000 --> 42:10.000
and that is society

42:10.000 --> 42:12.000
so basically it's a shift in society

42:12.000 --> 42:14.000
and so my thing was to go

42:14.000 --> 42:16.000
into emerging markets and others

42:16.000 --> 42:18.000
and give us technology to them

42:18.000 --> 42:20.000
otherwise they'll be left behind

42:20.000 --> 42:22.000
because you know like Dali 2

42:22.000 --> 42:24.000
you can't use if you're an Ukrainian

42:24.000 --> 42:26.000
and you can't use it for anything Ukrainian related

42:26.000 --> 42:28.000
and there's no appealing that

42:28.000 --> 42:30.000
or anything like that

42:30.000 --> 42:32.000
but it means Ukrainians are left behind

42:32.000 --> 42:34.000
whereas everyone else can become

42:34.000 --> 42:36.000
limited creatives that can generate

42:36.000 --> 42:38.000
any image in eight seconds

42:38.000 --> 42:40.000
so this is also why it's stability

42:40.000 --> 42:42.000
we do everything, we do code models

42:42.000 --> 42:44.000
image models, language models, audio models

42:44.000 --> 42:46.000
video models, protein folding models and others

42:46.000 --> 42:48.000
and so you're going to see leaps across all these areas

42:48.000 --> 42:50.000
in parallel

42:50.000 --> 42:52.000
I've argued for a very long time

42:52.000 --> 42:54.000
in fact I was writing articles in GMI about this

42:54.000 --> 42:56.000
ten years ago

42:56.000 --> 42:58.000
that AI plus big data

42:58.000 --> 43:00.000
equals medical breakthroughs

43:00.000 --> 43:02.000
because

43:02.000 --> 43:04.000
what the AI can do with that data

43:04.000 --> 43:06.000
is something that humans can't do

43:06.000 --> 43:08.000
in the standard scientific method

43:08.000 --> 43:10.000
of hypothesis testing, it's just too slow

43:10.000 --> 43:12.000
and too cumbersome

43:12.000 --> 43:14.000
you can get it to generate null hypotheses

43:14.000 --> 43:16.000
which humans don't like to do

43:16.000 --> 43:18.000
you can use this to transform so many things

43:18.000 --> 43:20.000
once it gets productized

43:20.000 --> 43:22.000
because it's the other thing

43:22.000 --> 43:24.000
most of this stuff was stuck in labs, it wasn't productized

43:24.000 --> 43:26.000
so if you look at what's happened with Stable Diffusion

43:26.000 --> 43:28.000
people have built hundreds of products on this ecosystem already

43:28.000 --> 43:30.000
like make your own sneakers

43:30.000 --> 43:32.000
they don't make any movie

43:32.000 --> 43:34.000
they've done architecture, they've done 3D worlds

43:34.000 --> 43:36.000
like the Cambrian explosion

43:36.000 --> 43:38.000
of talent is similar to what I've seen

43:38.000 --> 43:40.000
at the early days of Web 3

43:40.000 --> 43:42.000
except for there's no reason

43:42.000 --> 43:44.000
to boost traffic economic incentives

43:44.000 --> 43:46.000
when you're creating value

43:46.000 --> 43:48.000
a lot of value in the world, to be honest

43:48.000 --> 43:50.000
is the entropy of information

43:50.000 --> 43:52.000
how much value in the world is taken by taking unstructured

43:52.000 --> 43:54.000
data and making it structured

43:54.000 --> 43:56.000
that's exactly what this technology enables

43:56.000 --> 43:58.000
anyone to do

43:58.000 --> 44:00.000
and that's why we have AI that works with us

44:00.000 --> 44:02.000
to structure the world around us

44:02.000 --> 44:04.000
to enable us to achieve more

44:04.000 --> 44:06.000
that's kind of my theory here

44:06.000 --> 44:08.000
and this is again why, like I said, it needs to be

44:08.000 --> 44:10.000
disposed of us

44:10.000 --> 44:12.000
so you would

44:12.000 --> 44:14.000
err towards augmented

44:14.000 --> 44:16.000
humanity

44:16.000 --> 44:18.000
as opposed to a singularity

44:18.000 --> 44:20.000
or is it augmented and then a singularity

44:20.000 --> 44:22.000
where does this go?

44:22.000 --> 44:24.000
so look, I find the whole AGI

44:24.000 --> 44:26.000
I think largely distasteful

44:26.000 --> 44:28.000
there's a variety of reasons

44:28.000 --> 44:30.000
I think it misaligns a lot of incentives

44:30.000 --> 44:32.000
and I think the current way

44:32.000 --> 44:34.000
a lot of these big labs are going

44:34.000 --> 44:36.000
which is that you take the data

44:36.000 --> 44:38.000
and you create gigantic models

44:38.000 --> 44:40.000
that are only usable by gigantic machines

44:40.000 --> 44:42.000
will probably kill us all

44:42.000 --> 44:44.000
if it creates a singularity

44:44.000 --> 44:46.000
because the incentive alignment

44:46.000 --> 44:48.000
of these groups is to serve us ads

44:48.000 --> 44:50.000
and manipulate us effectively

44:50.000 --> 44:52.000
and it's trained on largely western datasets

44:52.000 --> 44:54.000
you know what happens when you

44:54.000 --> 44:56.000
talk to a doctor?

44:56.000 --> 44:58.000
no, Teh, the chatbot from Microsoft

44:58.000 --> 45:00.000
you remember that?

45:00.000 --> 45:02.000
it became abusive

45:02.000 --> 45:04.000
it became a Nazi

45:04.000 --> 45:06.000
so it talked to people and learned from them

45:06.000 --> 45:08.000
within a day and a half it turned them into a Nazi

45:08.000 --> 45:10.000
if I train on the internet

45:10.000 --> 45:12.000
I'm going to create a really

45:12.000 --> 45:14.000
fucked up AI

45:14.000 --> 45:16.000
to put it quite honestly

45:16.000 --> 45:18.000
it's not going to be an AI that labs

45:18.000 --> 45:20.000
it's going to be an AI that probably kills us all

45:20.000 --> 45:22.000
whereas if everyone's got their own AIs

45:22.000 --> 45:24.000
what does the network learn?

45:24.000 --> 45:26.000
if we take the models of all of humanity

45:26.000 --> 45:28.000
and all the cultures

45:28.000 --> 45:30.000
and all the different ethical views

45:30.000 --> 45:32.000
and we combine those models

45:32.000 --> 45:34.000
and all these AIs are designed to augment humanity

45:34.000 --> 45:36.000
rather than manipulate them

45:36.000 --> 45:38.000
I think that's a far more positive potential

45:38.000 --> 45:40.000
I don't think it's sufficient

45:40.000 --> 45:42.000
I think a lot of work needs to be done or others

45:42.000 --> 45:44.000
I think this AI is dangerous

45:44.000 --> 45:46.000
but it's inevitable

45:46.000 --> 45:48.000
and the way that it's being controlled

45:48.000 --> 45:50.000
by private corporations

45:50.000 --> 45:52.000
by millions of people or whatever

45:52.000 --> 45:54.000
but I think the current mechanism is wrong

45:54.000 --> 45:56.000
and I think again there's a lot of things

45:56.000 --> 45:58.000
around the singularity thing

45:58.000 --> 46:00.000
that are misaligned

46:00.000 --> 46:02.000
if we do build singularity I would like it to help us all

46:02.000 --> 46:04.000
but in the meantime let's just help people

46:04.000 --> 46:06.000
let's make people more creative

46:06.000 --> 46:08.000
let's make people able to act

46:08.000 --> 46:10.000
but there is unintended consequences

46:10.000 --> 46:12.000
you get that right?

46:12.000 --> 46:14.000
there are very unintended consequences

46:14.000 --> 46:16.000
we have no idea what the probabilistic outcome is

46:16.000 --> 46:18.000
of this

46:18.000 --> 46:20.000
uncertainty, not risk, right?

46:20.000 --> 46:22.000
so this is why the default

46:22.000 --> 46:24.000
for all of the corporations

46:24.000 --> 46:26.000
is this technology should not be released to anyone

46:26.000 --> 46:28.000
because we're the only ones responsible for this technology

46:28.000 --> 46:30.000
and that in itself

46:30.000 --> 46:32.000
and that doesn't stand up to scrutiny

46:32.000 --> 46:34.000
there's different outcomes

46:34.000 --> 46:36.000
from different methodology

46:36.000 --> 46:38.000
giving it to everybody who knows

46:38.000 --> 46:40.000
what foreign governments do

46:40.000 --> 46:42.000
there's a lot here

46:42.000 --> 46:44.000
I can tell you on that one

46:44.000 --> 46:46.000
foreign governments already have access to this technology

46:46.000 --> 46:48.000
and China and other places ramped up

46:48.000 --> 46:50.000
their supercomputers massively

46:50.000 --> 46:52.000
so they already have access to far more advanced versions

46:52.000 --> 46:54.000
of this technology than the one that's being made widely available

46:54.000 --> 46:56.000
which is one of the reasons we need to build

46:56.000 --> 46:58.000
our immunity ahead of the next election cycle

46:58.000 --> 47:00.000
so you think that the

47:02.000 --> 47:04.000
let's use the Russian example

47:04.000 --> 47:06.000
the Russian online misinformation campaign

47:06.000 --> 47:08.000
is now being run by AI

47:08.000 --> 47:10.000
which is why it's pretty much unstoppable

47:12.000 --> 47:14.000
it's unstoppable if you

47:14.000 --> 47:16.000
if you build better AI

47:16.000 --> 47:18.000
I mean to be honest, do you like Twitter

47:18.000 --> 47:20.000
and things like that? Like come on man

47:20.000 --> 47:22.000
you can do better than that

47:22.000 --> 47:24.000
like you see all the check mark hijacking and things like that

47:24.000 --> 47:26.000
you can tell what an AI is

47:26.000 --> 47:28.000
if you've got sufficiently advanced AI on the other side

47:28.000 --> 47:30.000
but again, people learn to not trust everything they see

47:30.000 --> 47:32.000
until we introduce a new structure

47:32.000 --> 47:34.000
like we right now need to have

47:34.000 --> 47:36.000
a verification protocol for information

47:36.000 --> 47:38.000
our social media

47:38.000 --> 47:40.000
and our information systems

47:40.000 --> 47:42.000
are inadequate to the task

47:42.000 --> 47:44.000
the internet is

47:46.000 --> 47:48.000
it's an intelligence amplifier

47:48.000 --> 47:50.000
but only for the few

47:50.000 --> 47:52.000
so what happened is the internet took it, compressed it down

47:52.000 --> 47:54.000
then some people just went way out there

47:54.000 --> 47:56.000
and they have a disproportionate impact on everyone

47:56.000 --> 47:58.000
and most people are left behind

47:58.000 --> 48:00.000
they have the audiences, they set the narrative

48:00.000 --> 48:02.000
and the narrative that

48:02.000 --> 48:04.000
basically is most appealing to the millennium part of our brain

48:04.000 --> 48:06.000
is one of divisiveness

48:06.000 --> 48:08.000
which is why the middle has disappeared

48:08.000 --> 48:10.000
and that's why it can tap into these things

48:10.000 --> 48:12.000
that's right, exactly right

48:12.000 --> 48:14.000
because the easiest way to manipulate humans

48:14.000 --> 48:16.000
is emotion and the strongest emotions

48:16.000 --> 48:18.000
are the polarizing emotions

48:18.000 --> 48:20.000
whereas with this technology you can say

48:20.000 --> 48:22.000
I want this article written

48:22.000 --> 48:24.000
from the perspective of a tea party

48:24.000 --> 48:26.000
conservative versus a libertarian

48:26.000 --> 48:28.000
and I will automatically change that

48:28.000 --> 48:32.000
it's a universal translation engine as well

48:32.000 --> 48:34.000
again, which is crazy

48:34.000 --> 48:36.000
clearly, yeah

48:36.000 --> 48:38.000
without question

48:38.000 --> 48:40.000
okay, once we've got this technology

48:40.000 --> 48:42.000
we've got another super trend

48:42.000 --> 48:44.000
that's happening at the same time

48:44.000 --> 48:46.000
there's a few super trends all happening

48:46.000 --> 48:48.000
I call them the exponential age

48:48.000 --> 48:50.000
one of them is compute power, all of this

48:50.000 --> 48:52.000
so they all go together, the other one is robotics

48:52.000 --> 48:54.000
so now, how close are we

48:54.000 --> 48:56.000
to creating sentient robots

48:56.000 --> 48:58.000
where is sentient

48:58.000 --> 49:00.000
in this process

49:00.000 --> 49:02.000
what's the definition of sentient

49:02.000 --> 49:04.000
I don't know

49:04.000 --> 49:06.000
we don't know, right

49:06.000 --> 49:08.000
nobody knows what sentience is

49:08.000 --> 49:10.000
there is no commonly defined thing

49:10.000 --> 49:12.000
in terms of like

49:12.000 --> 49:14.000
the things you see in the movies

49:14.000 --> 49:16.000
nobody knows

49:16.000 --> 49:18.000
because this is the thing

49:18.000 --> 49:20.000
if you ask anyone how far away are we

49:20.000 --> 49:22.000
from singularity or intelligence

49:22.000 --> 49:24.000
people will say

49:24.000 --> 49:26.000
at most, at minimum

49:26.000 --> 49:28.000
18 months, right

49:28.000 --> 49:30.000
why

49:30.000 --> 49:32.000
because what possible information could you have

49:32.000 --> 49:34.000
to say that a human level intelligence

49:34.000 --> 49:36.000
is less than 12 months away

49:36.000 --> 49:38.000
I'm not sure

49:38.000 --> 49:40.000
and nobody's been able to tell me an answer

49:40.000 --> 49:42.000
so, you know, this is

49:42.000 --> 49:44.000
a case of we don't know, but what we do know is that

49:44.000 --> 49:46.000
AI is getting better than humans at certain things

49:46.000 --> 49:48.000
so like

49:48.000 --> 49:50.000
open AI just released, maybe they were pressured

49:50.000 --> 49:52.000
by someone, the open source version of the software

49:52.000 --> 49:54.000
called whisper, which is

49:54.000 --> 49:56.000
a dynamic transcription engine

49:56.000 --> 49:58.000
you can speak in five different languages

49:58.000 --> 50:00.000
in the same sentence and it will transcribe it

50:00.000 --> 50:02.000
perfectly into English

50:02.000 --> 50:04.000
it's actually got above human level transcription quality

50:04.000 --> 50:06.000
and so

50:06.000 --> 50:08.000
stable diffusion is above human level

50:08.000 --> 50:10.000
image generation quality

50:10.000 --> 50:12.000
GPT-3 is above human level

50:12.000 --> 50:14.000
writing quality

50:14.000 --> 50:16.000
when we combine those all together

50:16.000 --> 50:18.000
you will get an illusion of sentience

50:18.000 --> 50:20.000
because you can't tell it's not a human maybe

50:20.000 --> 50:22.000
but is it really sentient and has agency

50:22.000 --> 50:24.000
I don't know

50:24.000 --> 50:26.000
and for the robotics thing, I think that Tesla's got

50:26.000 --> 50:28.000
some much bigger plans than they're letting on

50:28.000 --> 50:30.000
in regards to that

50:30.000 --> 50:32.000
we're going to see some big speed ups

50:32.000 --> 50:34.000
yeah, again I think people

50:34.000 --> 50:36.000
people are

50:36.000 --> 50:38.000
underestimating the speed of what is happening

50:38.000 --> 50:40.000
and I think you've confirmed it to me

50:40.000 --> 50:42.000
that the speed of which all of this is happening

50:42.000 --> 50:44.000
is

50:44.000 --> 50:46.000
ridiculous

50:46.000 --> 50:48.000
it's a true

50:48.000 --> 50:50.000
exponential, this is also actually

50:50.000 --> 50:52.000
when you look at AI research papers

50:52.000 --> 50:54.000
it's a doubling every 24 months

50:54.000 --> 50:56.000
on that

50:56.000 --> 50:58.000
so it actually is an exponential thing on AI research papers

50:58.000 --> 51:00.000
when you plot it

51:00.000 --> 51:02.000
on a log graph it's a straight line

51:02.000 --> 51:04.000
so as this goes it will continue going exponential

51:04.000 --> 51:06.000
and like I said exponentials are

51:06.000 --> 51:08.000
a hell of a thing

51:08.000 --> 51:10.000
we are not equipped to handle them

51:10.000 --> 51:12.000
no and we've got too many, well too many

51:12.000 --> 51:14.000
we're going to have the fastest pace of change

51:14.000 --> 51:16.000
humanity's ever seen because of technology

51:16.000 --> 51:18.000
because there's so many of these

51:18.000 --> 51:20.000
all happening at the same time

51:20.000 --> 51:22.000
it's a lot

51:22.000 --> 51:24.000
even as everything else breaks down

51:24.000 --> 51:26.000
all our systems are at the edge

51:26.000 --> 51:28.000
of our stability

51:28.000 --> 51:30.000
because I was like we need to reform education

51:30.000 --> 51:32.000
healthcare and all these things quick

51:32.000 --> 51:34.000
because we're going to see

51:34.000 --> 51:36.000
this is not normal

51:36.000 --> 51:38.000
what we're seeing today

51:38.000 --> 51:40.000
they might say oh interest rates are 7%

51:40.000 --> 51:42.000
worse than could happen

51:42.000 --> 51:44.000
come on guys

51:44.000 --> 51:46.000
these are symptoms not kind of causes

51:46.000 --> 51:48.000
the reality is our systems are out

51:48.000 --> 51:50.000
data need to be improved

51:50.000 --> 51:52.000
so what happened with crypto is they tried to grow a whole new system

51:52.000 --> 51:54.000
and then there's this system

51:54.000 --> 51:56.000
that's made and lost

51:56.000 --> 51:58.000
whereas this technology

51:58.000 --> 52:00.000
because it can take unstructured data

52:00.000 --> 52:02.000
to structured data

52:02.000 --> 52:04.000
can sit in our systems and extend them

52:04.000 --> 52:06.000
they can disrupt them or extend them

52:06.000 --> 52:08.000
so it's really interesting

52:08.000 --> 52:10.000
I think again the pace of change will be ridiculous

52:10.000 --> 52:12.000
so how the hell would somebody like Real Vision

52:12.000 --> 52:14.000
deal with

52:14.000 --> 52:16.000
I mean every company in the world

52:16.000 --> 52:18.000
has to change their business models yet again

52:18.000 --> 52:20.000
people are changing to web 3

52:20.000 --> 52:22.000
because that's another new business model

52:22.000 --> 52:24.000
the application of technology at scale

52:24.000 --> 52:26.000
in a totally disruptive way

52:26.000 --> 52:28.000
how the hell do we all deal with it

52:28.000 --> 52:30.000
how do we even get ahead

52:30.000 --> 52:32.000
so the lovely thing is

52:32.000 --> 52:34.000
when I go into the biggest media companies in the world

52:34.000 --> 52:36.000
right now they've already prototyped the technology

52:36.000 --> 52:38.000
internally because we made it so they could

52:38.000 --> 52:40.000
this is a new internet that's coming

52:40.000 --> 52:42.000
and so the reason I start stability

52:42.000 --> 52:44.000
was to be the layer one for next generation AI

52:44.000 --> 52:46.000
so my aim is to build the biggest company in the world

52:46.000 --> 52:48.000
that puts this technology to everyone

52:48.000 --> 52:50.000
so they can build their own models

52:50.000 --> 52:52.000
or if they want the white glove service

52:52.000 --> 52:54.000
they come to us and we forward deploy engineers

52:54.000 --> 52:56.000
to take all the content in the world and make it living

52:56.000 --> 52:58.000
and interactive

52:58.000 --> 53:00.000
but you just kind of got to get into this

53:00.000 --> 53:02.000
and again you know how it was when you said

53:02.000 --> 53:04.000
the first bitcoin?

53:04.000 --> 53:06.000
it's magic

53:06.000 --> 53:08.000
sufficiently advanced technology is magic this is the same

53:08.000 --> 53:10.000
when you create your first image

53:10.000 --> 53:12.000
if you do something boring it's going to be like whatever

53:12.000 --> 53:14.000
it's style transfer

53:14.000 --> 53:16.000
but when you create your first original image

53:16.000 --> 53:18.000
combining different styles and concepts

53:18.000 --> 53:20.000
and the image in your head becomes reality

53:20.000 --> 53:22.000
you're like

53:22.000 --> 53:24.000
this is new

53:24.000 --> 53:26.000
this is different this is crazy

53:26.000 --> 53:28.000
it's the biggest thing of all time and it's not just for images

53:28.000 --> 53:30.000
images are the

53:30.000 --> 53:32.000
breakthrough wedge

53:32.000 --> 53:34.000
because it's gone from 20% to 80%

53:34.000 --> 53:36.000
language GPT-3 was an 80% to 90% moment

53:36.000 --> 53:38.000
this is

53:38.000 --> 53:40.000
99% of the world don't believe they can create

53:40.000 --> 53:42.000
they can suddenly create anything

53:42.000 --> 53:44.000
you got to just get in there and you got to basically find where it is

53:44.000 --> 53:46.000
because what happens is that

53:46.000 --> 53:48.000
there's this wonderful description of infrastructure

53:48.000 --> 53:50.000
as the most efficient means by which a society stores

53:50.000 --> 53:52.000
and ships value

53:52.000 --> 53:54.000
the value landscape in content

53:54.000 --> 53:56.000
in enterprise

53:56.000 --> 53:58.000
in a lot of things

53:58.000 --> 54:00.000
in information is about to be upended

54:00.000 --> 54:02.000
and we don't know what the new landscape is

54:02.000 --> 54:04.000
and so you got to be in there to understand that

54:04.000 --> 54:06.000
what role do humans play

54:08.000 --> 54:10.000
you know obviously we've got a shrinking world

54:10.000 --> 54:12.000
population over time so

54:12.000 --> 54:14.000
I think of robots and AI

54:14.000 --> 54:16.000
and I wrote a few articles about it

54:16.000 --> 54:18.000
so these are new demographics

54:18.000 --> 54:20.000
but they can periferate very far

54:20.000 --> 54:22.000
so does that increase

54:22.000 --> 54:24.000
GDP growth and humans need to move

54:24.000 --> 54:26.000
towards some sort of universal basic income

54:26.000 --> 54:28.000
or different roles

54:28.000 --> 54:30.000
how are you thinking that

54:30.000 --> 54:32.000
I think that we need to move towards universal basic income

54:32.000 --> 54:34.000
like you know this is why

54:34.000 --> 54:36.000
I'm rolling this out in emerging markets

54:36.000 --> 54:38.000
the education tablets create the best

54:38.000 --> 54:40.000
data sets to feed models for every nation

54:40.000 --> 54:42.000
so I'm going to make it to the Malawi

54:42.000 --> 54:44.000
where it adds percentage points to its GDP

54:44.000 --> 54:46.000
Ethiopia adds percentage points to their GDP

54:46.000 --> 54:48.000
India is the number one market for this

54:48.000 --> 54:50.000
because they have ATAR

54:50.000 --> 54:52.000
India Stack 5G

54:52.000 --> 54:54.000
and all the capital needed

54:54.000 --> 54:56.000
so India is one of our biggest markets

54:56.000 --> 54:58.000
by far and literally we will accelerate

54:58.000 --> 55:00.000
Indian GDP and the Indians will then have a better system

55:00.000 --> 55:02.000
than we have in the west

55:02.000 --> 55:04.000
like already 13 months to literacy and numeracy

55:04.000 --> 55:06.000
on one hour a day is better than

55:06.000 --> 55:08.000
most primary you know kindergarten

55:08.000 --> 55:10.000
so think about what it's going to be

55:10.000 --> 55:12.000
self-learning AI system

55:12.000 --> 55:14.000
it's going to be crazy but then they are equipped

55:14.000 --> 55:16.000
for that and you need to have things like UBI

55:16.000 --> 55:18.000
so one of the things we've done is in our country level

55:18.000 --> 55:20.000
subsidiaries and we're doing just about all the countries in the world

55:20.000 --> 55:22.000
10% of the shares are reserved

55:22.000 --> 55:24.000
for the kids that use our education tablets

55:24.000 --> 55:26.000
so they'll be getting shares

55:26.000 --> 55:28.000
as they kind of grow

55:28.000 --> 55:30.000
and then we're trying to figure out how UBI

55:30.000 --> 55:32.000
looks like on the back of that which is insane

55:32.000 --> 55:34.000
like we shouldn't have to do that

55:34.000 --> 55:36.000
but nobody else is thinking about the pace of change

55:36.000 --> 55:38.000
and scale of this

55:38.000 --> 55:40.000
are you going to structure this as a DAO

55:40.000 --> 55:42.000
or a foundation or something

55:42.000 --> 55:44.000
I wanted to do a DAO of DAOs originally

55:44.000 --> 55:46.000
and

55:46.000 --> 55:48.000
then I realised the infrastructure wasn't there

55:48.000 --> 55:50.000
and then I realised let's just

55:50.000 --> 55:52.000
IPO in every single country

55:52.000 --> 55:54.000
and create the next trillion dollar business

55:54.000 --> 55:56.000
that's the best way to do this

55:56.000 --> 55:58.000
distributed listing

55:58.000 --> 56:00.000
okay interesting

56:00.000 --> 56:02.000
yeah distributed listing

56:02.000 --> 56:04.000
the Indian version of stability should be owned

56:04.000 --> 56:06.000
by the Indians for the Indians

56:06.000 --> 56:08.000
running it

56:08.000 --> 56:10.000
there's an opportunity here

56:10.000 --> 56:12.000
same for all these other countries

56:12.000 --> 56:14.000
maybe DAOs work in the future

56:14.000 --> 56:16.000
maybe you can do air drops

56:16.000 --> 56:18.000
it's open right

56:18.000 --> 56:20.000
but this is a cool thing this technology

56:20.000 --> 56:22.000
has an exponential

56:22.000 --> 56:24.000
so nobody knows

56:24.000 --> 56:26.000
what the answer is

56:26.000 --> 56:28.000
final question

56:28.000 --> 56:30.000
because there's a lot to digest here

56:30.000 --> 56:32.000
how are governments going to deal with this

56:32.000 --> 56:34.000
so

56:34.000 --> 56:36.000
the European Union

56:36.000 --> 56:38.000
is trying to ban open source artificial intelligence now

56:38.000 --> 56:40.000
because they view the edges

56:40.000 --> 56:42.000
regulation

56:42.000 --> 56:44.000
so authors of models will be liable

56:44.000 --> 56:46.000
for the use of the models

56:46.000 --> 56:48.000
the US is uncertain right now

56:48.000 --> 56:50.000
the UK is massively pro AI

56:50.000 --> 56:52.000
and so they've been upgrading it massively

56:52.000 --> 56:54.000
in emerging markets

56:54.000 --> 56:56.000
guess what

56:56.000 --> 56:58.000
I'm going to the governments to tell them they can have this technology for free

56:58.000 --> 57:00.000
they love me

57:00.000 --> 57:02.000
so

57:02.000 --> 57:04.000
you'll have most of the world loving it

57:04.000 --> 57:06.000
and then Europe is a big question mark

57:06.000 --> 57:08.000
US is a small question mark

57:08.000 --> 57:10.000
and I think they'll be very pro this

57:10.000 --> 57:12.000
because it adds GDP at a time

57:12.000 --> 57:14.000
when there is no abundance

57:14.000 --> 57:16.000
the question is does it then collapse GDP afterwards

57:16.000 --> 57:18.000
politicians don't think that far

57:18.000 --> 57:20.000
honestly

57:20.000 --> 57:22.000
when I look at it

57:22.000 --> 57:24.000
what is GDP

57:24.000 --> 57:26.000
GDP is population growth plus productivity

57:26.000 --> 57:28.000
this does both population growth

57:28.000 --> 57:30.000
and productivity

57:30.000 --> 57:32.000
because it is population

57:32.000 --> 57:34.000
robots and AI are demographics

57:34.000 --> 57:36.000
and increases productivity

57:36.000 --> 57:38.000
so that should mean the pie increases

57:38.000 --> 57:40.000
so per capita GDP rises

57:40.000 --> 57:42.000
that's my working hypothesis

57:42.000 --> 57:44.000
until

57:44.000 --> 57:46.000
it replaces the humans eventually anyway

57:46.000 --> 57:48.000
exactly and there's this other part

57:48.000 --> 57:50.000
which is that basically the west

57:50.000 --> 57:52.000
and advanced economies have borrowed too much from their balance sheet

57:52.000 --> 57:54.000
from the future based on identity

57:54.000 --> 57:56.000
whereas you look at India and other places

57:56.000 --> 57:58.000
they haven't done that

57:58.000 --> 58:00.000
so when you incorporate this technology

58:00.000 --> 58:02.000
with godland entity structures

58:02.000 --> 58:04.000
you suddenly have massive credit creation

58:04.000 --> 58:06.000
like you've never seen before

58:06.000 --> 58:08.000
because information which money

58:08.000 --> 58:10.000
can flow much nicer around India

58:10.000 --> 58:12.000
or fricking Ethiopia or anywhere else

58:12.000 --> 58:14.000
especially because our tablets are standardized tablets

58:14.000 --> 58:16.000
that we're deploying at scale

58:16.000 --> 58:18.000
with a new type of bond

58:18.000 --> 58:20.000
whereby you only pay based on outcomes if you're a donor

58:20.000 --> 58:22.000
which is measured through the tablets

58:22.000 --> 58:24.000
so my thing is like infrastructure

58:24.000 --> 58:26.000
the west I have no idea what to do with

58:26.000 --> 58:28.000
like I'm just going to the company

58:28.000 --> 58:30.000
to say give me your content and let's share on this upside

58:30.000 --> 58:32.000
but it's difficult to try

58:32.000 --> 58:34.000
and fix the UK or US or Europe

58:34.000 --> 58:36.000
and there's enough smart people there who can do that

58:36.000 --> 58:38.000
Have an amazing conversation

58:38.000 --> 58:40.000
I've absolutely loved it

58:40.000 --> 58:42.000
I'm terrified and excited at the same time

58:42.000 --> 58:44.000
which is what I was hoping

58:44.000 --> 58:46.000
I'll definitely get you back

58:46.000 --> 58:48.000
to talk more about this because

58:48.000 --> 58:50.000
we barely scratched the surface

58:50.000 --> 58:52.000
Yeah, no problem, like I said

58:52.000 --> 58:54.000
we've tried it publicly, I think this is one of the first times

58:54.000 --> 58:56.000
we're talking about actually the bigger plans

58:56.000 --> 58:58.000
like I think we're recording this now

58:58.000 --> 59:00.000
next week we do our big launch event

59:00.000 --> 59:02.000
but everyone needs to know about this right

59:02.000 --> 59:04.000
and everyone needs to participate

59:04.000 --> 59:06.000
because this should be a communal effort

59:06.000 --> 59:08.000
because we need to guide it together, right?

59:08.000 --> 59:10.000
Exactly right, well listen

59:10.000 --> 59:12.000
best of luck with everything

59:12.000 --> 59:14.000
let's hope the unintended consequences

59:14.000 --> 59:16.000
are not as bad as could be

59:16.000 --> 59:18.000
we'll only find out but we're going down this path anyway

59:18.000 --> 59:20.000
regardless so you might as well

59:20.000 --> 59:22.000
tell us what the consequences are and not to the few

59:22.000 --> 59:24.000
Exactly, cheers Rowell

59:24.000 --> 59:26.000
Thank you my friend

59:28.000 --> 59:30.000
There is so much to unpack

59:30.000 --> 59:32.000
for an interview like this

59:32.000 --> 59:34.000
Firstly

59:34.000 --> 59:36.000
it shows that the hypothesis

59:36.000 --> 59:38.000
that technological growth

59:38.000 --> 59:40.000
is going exponential and it is not going to stop

59:40.000 --> 59:42.000
regardless of what the central banks are doing

59:42.000 --> 59:44.000
or inflation is doing

59:44.000 --> 59:46.000
it's kind of irrelevant

59:46.000 --> 59:48.000
when the speed of technological

59:48.000 --> 59:50.000
technological adoption

59:50.000 --> 59:52.000
is so rapid

59:52.000 --> 59:54.000
and so truly extraordinary and profound

59:56.000 --> 59:58.000
the way this is changing humanity

59:58.000 --> 01:00:00.000
both from education

01:00:00.000 --> 01:00:02.000
medical sciences

01:00:02.000 --> 01:00:04.000
science in general

01:00:04.000 --> 01:00:06.000
the creative industries, the media industry

01:00:06.000 --> 01:00:08.000
everybody

01:00:08.000 --> 01:00:10.000
this is again

01:00:10.000 --> 01:00:12.000
happening on a scale like the internet

01:00:12.000 --> 01:00:14.000
but maybe even more so

01:00:14.000 --> 01:00:16.000
and we've got many of these technologies

01:00:16.000 --> 01:00:18.000
all overlapping

01:00:18.000 --> 01:00:20.000
as what I've talked about before

01:00:20.000 --> 01:00:22.000
blockchain technology has been the fastest

01:00:22.000 --> 01:00:24.000
adoption of any technology the world has ever seen

01:00:24.000 --> 01:00:26.000
and looks like AI may even

01:00:26.000 --> 01:00:28.000
exceed that

01:00:28.000 --> 01:00:30.000
and then we've got robotics and space

01:00:30.000 --> 01:00:32.000
and internet of things

01:00:32.000 --> 01:00:34.000
and on and on and on

01:00:34.000 --> 01:00:36.000
so

01:00:36.000 --> 01:00:38.000
you can either fear this stuff

01:00:38.000 --> 01:00:40.000
or you can use it

01:00:40.000 --> 01:00:42.000
to your advantage and invest in your own future

01:00:42.000 --> 01:00:44.000
and that's the route I take

01:00:44.000 --> 01:00:46.000
there is unintended consequences

01:00:46.000 --> 01:00:48.000
we just don't know what they are

01:00:48.000 --> 01:00:50.000
and I think Emmad's point about

01:00:50.000 --> 01:00:52.000
should it be given

01:00:52.000 --> 01:00:54.000
to the few

01:00:54.000 --> 01:00:56.000
or the many

01:00:56.000 --> 01:00:58.000
to deal with those unintended consequences

01:00:58.000 --> 01:01:00.000
I think he's probably right

01:01:00.000 --> 01:01:02.000
that give it to everybody

01:01:02.000 --> 01:01:04.000
is probably the only way around this

01:01:04.000 --> 01:01:06.000
anyway, a truly extraordinary interview

01:01:06.000 --> 01:01:08.000
and I hope you enjoyed it

01:01:14.000 --> 01:01:16.000
with in-depth analysis from real experts

01:01:16.000 --> 01:01:18.000
join the revolution at realvision.com

