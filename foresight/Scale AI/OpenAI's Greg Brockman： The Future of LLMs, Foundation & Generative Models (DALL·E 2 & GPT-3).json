{"text": " We're joined next by Greg Brockman, President, Chairman and Founder of Open AI and Alexander Wang, CEO and Founder of Scale AI. Open AI is a research and deployment company whose mission is to ensure general-purpose artificial intelligence benefits all of humanity. For Open AI, Greg was the CTO of Stripe, which he helped build from 4 to 250 employees. Please join me in welcoming to the stage Greg Brockman and Alexander Wang. Hey Greg. Hey. Thanks for making it. Absolutely. I'd be happy to be here. I want to start actually, I don't know if you remember this, but we first met at this summer camp called Spark where you gave a presentation about, at the time you were the CTO of Stripe and you gave this presentation about sort of like everything you had accomplished and I was a member of that camp and it was extremely memorable. You had a lot of good sound bites. I'm glad that it landed. Kind of a full circle moment. Well I think to start out with, I mean you've been CTO and now you're President of Open AI, but CTO of two incredibly iconic companies, Stripe and Open AI, in some ways probably two of the most iconic startups of the past decade. I wanted to start out just by asking in what ways are the two organizations the same and being CTO the same and in what ways are they different? Thank you for the kind of words. I think that one thing that's very interesting to me about kind of having been part of both of these organizations is seeing how much groups of people are kind of the same regardless of what the problem in front of you is. So I think that a lot of how we approached Stripe was thinking from first principles. I remember when we were pre-launch and we had some buzz going because we had some early customers and one of my friends took me out to launch, he was like all right, I've been hearing about this Stripe thing, what's your secret sauce? I was like, I mean we just make payments really good and he's like no, no, no, come on, you can tell me, what's the secret sauce? And really that was the secret sauce, right, is that we had just rethought every single piece of what we were doing from the ground up from first principles, not sort of locked into the way that people had been doing it and we asked how should it be, like where's all the pain and does it need to be there? I think that in AI we did much the same, we really thought about okay, there's this field that we're entering and that we hire a lot of people who had been in the field, but a lot of us also hadn't been in the field and we came to it with beginner's eyes and I think that that approach of just not being beholden to all the ways people were doing it, but also becoming expert in the way that things have been done because if you just throw everything out, like you're also just going to be starting from scratch in a not helpful way. So I think that that maybe is the deepest commonality between them. But obviously very different organizations, for Stripe I think that we ran the traditional startup playbook. You basically come up with the innovation and you just build, build, build. You get in front of customers from day one, the story is that we gave the first API to a customer who charged a credit card and he was like, I would like my money now please and we were like, huh, I guess we should build that. Open AI, we had research to do, like where's the customer? And it really took us I guess five years, starting late 2015 and it's really not until 2020 that we had our very first product. And so I think that that sort of figuring out like what you're even supposed to work on, like did you do a good job, should you feel good on a day-to-day basis? I think that all of that had to come from within rather than from without. Yeah. Well, actually I want to go back to this point that you mentioned around first principles thinking. It's very interesting because even I remember like maybe 2020 or 2021, you know, you would sort of post-GPD3, you would talk to other researchers in the field and even they would still, you know, there's still like some degree of skepticism over the sort of like core concept of scaling up these models and if there were still gains to be had, et cetera. And I think, you know, I don't know the story but it seems like the sort of research sort of intuition that led to GPD3, Dolly 2 that have really ushered in kind of a new era of AI were probably, you know, somewhat against the grain or somewhat unintuitive at the time. You know, one question I have for you is, you know, I think now looking back it's obviously very obvious to point out GPD3, Dolly 2 basically have fundamentally accelerated AI progress and its relevance to the world and its relevance to every industry and sort of have created the sort of most recent AI wave. How is that matched up against your expectations when you were building these technologies? You know? Yeah. Well, I think the thing that's most interesting to me is that those models you mentioned are kind of overnight successes that took many, many years to create. And so, you know, from the outside it looks like, wow, you just like produce this model and that model and really on the inside, the GPT arc, that's a five-year arc, right? It really started with sentiment neuron paper which is back in 2017. Do you remember that paper? I remember the paper. It was very cool. Yeah. But it felt very novel. It felt very novel. Yeah. Very few people remember it. It's, you know, it was this very early result where we basically had been training a LSTM at the time to predict the next character in text. So, we basically showed a bunch of Amazon reviews. We said, what's the next character and of course it's going to learn where the commas go. Where the periods go. But of course it's not going to understand anything. But we found a single neuron in that model that had learned a state-of-the-art sentiment analysis classifier. I can tell you this is a positive review or negative review. That's understanding. You know, I don't know what understanding means but it's semantics for sure. And that for us was like, okay, this is going to work. The transformer came out late 2017 and my co-founder Ilya immediately was like, that's the thing. That's what we've been waiting for. So, you take this sort of very early nascent result, put in a transformer and then that's GPT-1. GPT-2 is you just keep pushing it. And you know, I think that the algorithm we kind of run internally is that we do these little sort of get signs of life and you have to be very, very careful to distinguish signs of life from like kind of just pushing too hard on a specific data set that isn't really going to keep going. But if you kind of build those right intuitions then you know, okay, now is the time to put in more compute. Now is the time to put in more researchers. Now is the time to like really scale it up. And so GPT-2 obviously was exciting and that we were all like, well, we look at the curves. You know, the bigger we made this model, the more compute we put in, the more data we put in, the more we just sort of got all the engineering details right, those curves just got better. And so actually, you know, our goal was just to break the paradigm. It was just push it until the curve stopped looking good and we still haven't managed to accomplish it. Yeah. Well, I think one of the things, at least for me and probably for many people who initially played with GPT-3, the like shocking thing was not, I mean, it wasn't necessarily that even the model got better and better performance on, you know, established tasks is that it sort of had all these qualitatively new behaviors that were felt very magical. And even now, you know, there's prompts that, you know, you'll see on Twitter or whatnot that are sort of really shocking. I mean, did you have these sort of like early moments when like you had the early model results were like, holy crap, this is like, this is magic. Yeah. Well, I think that the earliest one that I remember was around code. I mean, just, you know, at the time, totally mind blowing that you could just write a function name and a doc string kind of describing what the function should do and actually write it. Not super complicated functions, right? But just that it was able to, you know, you ask for, you know, something to take a couple lines and they would be able to really do it. You modify things a little bit to make sure it hadn't just memorized it. Make sure enough that it would write out the modified code. And I think, you know, the overall thing that's really interesting about the paradigm of a GPT-3 is that where it really comes from is that I, you know, we kind of had this picture that, look, the problem with these models is that they're great within their data distribution. But as soon as you're outside of that distribution, like all bets are off. And so what if you just make the whole world, the whole universe, be the data distribution? You put the whole internet in there. And I think that what we've really seen is that these models, that they really are able to generalize extremely well within the kinds of things that they've seen. You know, again, different question if it's never seen anything like it. I mean, humans are also not very good at things you've never seen before. But I think that that picture of just, like, all of the different things that it's seen in all these different configurations is almost unimaginable. There's no human who's been able to consume, you know, 40 terabytes worth of text. And so I think that we just keep seeing surprises where you just ask for, one of my favorite ones actually was this teacher-student interaction where I was the teacher model as the student and I managed to teach it how to sort numbers. And you just kind of have these experiences where, like, that's what it should be like to interact with an AI. Yeah. I mean, it's incredibly shocking. You know, one of the things I'm curious to get your thoughts on is, I think, in the path of developing GP3, you know, required, I think probably the jump from GP2 to GP3 required a lot of conviction because, you know, you all were spending probably a fair amount on a compute at the time to be able to train these models and there were probably a lot of experiments that didn't work and so you had to be willing to keep going after it. Did that phase of the journey, sort of this, like, GP2 to GP3 jump, was it scary? Did you have doubts? Or were you very confident that, hey, you know, we're going to scale this up and even though we're going to not get it right the first few times, it's going to be amazing? Yeah. And to your point that scale was not an obvious thing, not the company, but the scaling things up, at the time, the funny thing is actually our very first scale result that just sort of convinced us that this is the right way to approach things. You push it until it breaks. Not necessarily that more compute is just magically always going to solve your problem. It was Dota. That was, you know, playing competitive video games and there we kind of went through this whole, that was a three-year arc where we started out with something that didn't do anything, finally beat, like, you know, the in-house team, then we managed to go beat the pros and at each step it was just kind of pushing in all dimensions, right, is make the model bigger, it's to, you know, sort of, again, fix all the bugs and you just kind of keep iterating on every single dimension and every single dimension yields returns. And so I think that we did very much the same thing where for GP2, you know, it's not as simple as saying, okay, like, clearly you just need to, like, you know, crank up this one variable and you just do it in one shot. It's this, like, sort of iterative, like, stepping through the space on each axis at every single time. And so I think that on the one hand it does require conviction because you do need to say we're going to, like, carve out a big compute budget so that you're not constantly not kind of fighting other people for the big supercomputers, but on the other hand, I think it's also very iterative and you don't have to make scary irreversible decisions because in each step you get feedback from reality. And I think that that key of, like, both the big picture, thinking of what if this works and make sure that you're really set up for success, but also don't blindly spend a year of your organization on just, like, pursuing a thing that might not pan out. I think that balancing those two is what was really key. Yeah, I mean, one of the cool things is you sort of walk through this and talk through the insights is that the sort of organizational learnings were really critical in this entire sort of path-dependent sort of path to GP3. It sort of, you know, it makes sense when you say it that sort of insights from Dota 2 and insights from the sentiment neuron were sort of like the key, these were like the key nuggets that led to the sort of, like, crystallized idea of, you know, scaling up and building GP3, but it's very unintuitive from the outside and sort of, I think it's almost a statement of innovation in some sense is that, you know, you're going to piece together this sort of, like, disparate collection of insights that you gather from a wide variety of experiments and eventually you sort of, like, get the ingredients together and you build something. Yeah, that's the first principle is thinking in action. Yeah. You know, I think that the story of AI, I don't know if you think about this at all, but I think about this a little bit, I think the story of AI to date and especially the past few years and the story of open AI is probably going to be something that historians are going to study for, you know, decades and decades to come. Are there any fun stories from the journey of creating some of these foundation models that you think deserve to be in the history books? Well, I'll tell you my actual favorite story from the Dota days. So, you know, we've been working on this system and, you know, actually the funny thing is at the very beginning we wrote down our list of milestones. On this date we're going to be Jonas, our best open AI employee who also had many thousands of hours of Dota 2 gameplay. This date we're going to beat the semi-pros, you know, this date we're going to beat the pros and so it's supposed to be like June 6th or something, June 6th rolls around, we don't have anything. Like, you know, he just crushes us and two weeks go by, three weeks go by, we keep pushing back that deadline by a week every week and then one day we actually do beat him. And you know, I think my conclusion was that like it wasn't actually actionable to sort of set those goals of outputs, you can only control your inputs, you can control the experiments you run. And so we just managed the project very differently after that and the thing that was so crazy to me still is that, you know, so a week before the international, which is the like world championships we're going to show up, we're going to play 1v1 against the best players in the world, we finally started beating our semi-protester and we're like, okay, maybe this is actually going to happen. But then we learned that he actually was on like vacation, he didn't have his like real setup and so we're like, oh no, like this is not going to go well. So we show up, you know, we continue to train, we like kind of do like a Hail Mary of like scaling things up, biggest scale we've ever done and we show up at the international and we play against, you know, like sort of low lowest, you know, low ranked pro, like a previous pro and we go 3-0-3-0-2-1. So we basically win-win and then we did have one loss and we take a look at it and it's like this item that we've never trained with, we've never seen before, oh wow, okay, we need to add that and, you know, do it fast. And so the team stays up all night putting this thing into the training, getting the whole thing launched and, you know, again, like we did double the scale where we're basically maxing out our CPU cores at this point and start training and, you know, we're supposed to play against the top pros in the world, fortunately they can't do the next day so we get an additional day of training and the number two person comes in, he plays against us and we win-win-win-win-win and he's like, okay, but I beat this but the top player is never going to lose to this thing or sorry, yeah, the top player is going to crash this thing and fortunately because he had spent so long playing that that guy couldn't come that day so we got one more day of training and that one more day of training was enough and so I think it's just the story of like you can really see the improvement and at each step we could see new behaviors that the system have learned and I think that that experience of just sort of watching a girl up in front of you is just something that was really amazing. I'm actually surprised because you would, I sensibly you'd probably train the sort of like agents for a long, long, long time going into the international and surprised at each incremental day. Yeah, so this is something I think has changed over time so at the time we basically had two weeks worth of training was like the whole model run and so you'd start from scratch each time and the thing that was really funny in the middle was that, you know, we put in this new item, we were training it and when we took out of training it was the best spot we ever saw except that our semi-protester was looking at it and was like this bot is doing something really dumb, it's just sitting there in the first wave and taking all this damage it doesn't have to, I'm going to go beat it, he ran it and go fight it and he lost. It's like that was weird and he did it like five more times and he lost each time but then he figured out a strategy that actually does work which is you, you realize what was going on was it was baiting him, it had learned to deceive, you know it actually learned that what you do is that like you pretend oh I'm just a weak little bot, I don't know what I'm doing and then you know a person comes in and you're just like smack. And so the way you defeat that is that you actually, you don't fall for the bait, right, you let the bot take all this damage and sit there and get weaker and then you finally go in for the kill and so there we actually stitched together our good bot for the first wave with the deceived bot thereafter and so there was a lot of this sort of like really examining what was going on in the systems because it's such a limited domain, you know it's a complicated domain but it's very, very interpretable. It meant that we could observe behaviors like this and figure out how to engineer around them but once we graduated from the 1v1 version of the game to the full 5v5 you know much more like you know like competitive basketball or something rather than heads up, suddenly all of our analysis of the behavior stopped working, right, that we used to have someone who just literally would watch the bot play and be like oh we have this bug in the training we got to go fix that, for 5v5 we just could not do that and I think that's kind of where we've graduated as a field is that too when you look at GPT-3 and the mistakes it makes sometimes people ask well why didn't it make that mistake and sometimes you can interpret it but sometimes it's also a little bit like asking well you know why did you make a mistake on some tests it's like well you think you know but like your explanation isn't always very good and I think that to do complicated behaviors sometimes there's a very complicated explanation. Yeah. Have you read this short story I think it's like the Lifecycle of Software Objects by Ted Chang? I think I have but I don't recall the details. It's like it's about how they're these AI pets and they sort of like keep learning new and new behaviors it's very reminiscent of describing these Dota agents. Yeah yeah I think we'll see that kind of thing in our future somewhere. I want to kind of go back you know one of the things we've known each other for many years long before you know these foundation models and even before this competition Dota 2 and one thing I vividly remember is how sort of optimistic and confident you were in sort of this sort of path of increasing and increasing AI capability you know sort of I remember the time as maybe 2016, 2017 it felt very striking because it was sort of like you know with these algorithms they're still pretty weak and you were always very confident like oh yeah they're just going to keep getting better and better and better and you know you're very a lot of confidence in that. What were the things that back then gave you sort of the resolve or confidence in the and the optimism in the technology? Yeah I mean at some level you know to have that kind of belief and conviction and something that hasn't happened yet it's a very intuitive thing. I mean I remember when I was in school and showed up excited about doing NLP research I went and tracked down an NLP professor and I was like please can I do some research for you and he's like okay he shows me these like parsed trees and stuff and I look at that and I was like this is never going to work right and you know to explain like why does it feel like it's not going to work it just doesn't have the right properties right it just felt like you're going to pour all this human like engineering and intuition and effort into the system and I know I can't even describe how language works. Yep. Right it just feels like there's just something inherently missing but I think neural nets have the opposite property. Neural nets is very clear this is a system that absorbs data it absorbs compute it's like a sponge that just like slurps everything up and so it has the right form factor but the thing that's always been missing as well can you train it right? Do you have enough data do you have enough compute do you have enough ability to like have a learning algorithm that can shovel the stuff in efficiently in a way that it comes out in some way that generalizes like that's the thing that's been missing and I think what became kind of clear you know the field really I think got its most recent resurgence in 2012 with the Alex in that paper and I think that there that was the first time where you had a neural net that really just crushed a task right that it was like people had spent decades on computer vision and suddenly it's like well I'm so sorry but this approach has just supplanted you by this this massive gap and I think that you just started to see it spread right that it was almost like you had these these all these disparate departments and there was this wall that was being knocked down day after day and I think that when you see a trend like that were things that have been long-standing and very deeply established in these ways of thinking these great debates that have gone on for a long time and suddenly you're seeing a repeated result that is consistent with the history I think that that for me is maybe the most clear sign that it's like something is going to work and there's a real sort of exponential that is waiting to unfold. And then you know were there what were the what were the moments if any of of doubt and you know let's let's chart the path I think open I start in 2016 yeah yeah I'd say December 2015 you know 2016 okay great December 2015 till now were there any moments of of doubt in the technology or was it sort of always hey this is you know this is clearly the way of the future yeah I mean I think that doubt is a strong word there's definitely moments like I think to build something you you're always doubting right that you're always like you've got to be questioning every single bit of your implementation like anytime you see like a graph that's wiggling in a weird way you've got to go figure it out you can't just be like I'm sure that the AI's will sort it out. And so I think there was like lots of sort of tactical doubt lots of like sort of worries that were not quite doing it right lots of like redoing the calculations to figure out like hey how big of a model do you think you're going to need lots of mistakes for sure like a good example of this is the scaling laws so we did this study to actually start to really scientifically understand how do models improve as you push on various axes so as you pour more computing as you pour more data in and one conclusion that we had at one point was that basically that there's you know sort of a limited amount of data that you want to pour into these models and that there's kind of this very this very clear curve and that one thing that we realized only years later was actually that we'd read the curves a little bit wrong and you actually want to be trained for way more tokens way more data than anyone had expected and that did I you know that there's definitely these moments where these things that just didn't quite click where it's like just didn't add up that we were training for so little and that you know something conclusions that you drew downstream but then you realize there was a foundational assumption that was wrong and suddenly things make way more sense so I think it's a little bit like you know physics in some sense for like do you do doubt physics it's like I kind of do I think all physics is wrong right but like only so wrong right it's like we clearly haven't reconciled like quantum and relativity is that there's like something wrong there but that that wrongness is actually an opportunity it's actually a sign of you have this things are useful right really like it's affected our lives and it's actually like pretty great I'm very happy with what physics has done but also there's fruit and so I think that that for me that's always been the feeling that there's something here and that you know if we do keep pushing and somehow the scaling laws all peter out right and they suddenly drop off a cliff and we can't make any further progress like that would be the most exciting time in this field because we would finally reach the limit of technology we would finally learn something and then we would finally have a picture of what the next thing to do is yeah that's super it actually reminds me of this one of the stripe operating principles which is I think micro pessimists macro optimists yep yep yes and it's very I mean it's very resonant but obviously like very related to what you're talking about which is these you know you have to be extremely pessimistic we're extremely questioning in the moments of the technology but then obviously on a long enough time horizon incredible stuff pops out yep you got to be excited like I think that this is just an exciting field and it's a scary field as well you got to have some amount of just like awe at the fact that you have these these models that they started as just random numbers right and then you have build these massive supercomputers these massive data sets and you do a ton of the engineering work you do a ton of these algorithmic developments you put them all into a package right and we don't really have other technologies that work like this like I think the fact to me the most fundamental picture this like sponge that you just kind of pour stuff into and you get this model it's reusable and works across all these different areas like you can't do that for traditional software right traditional software is it's just you know human effort writing down all the rules and that's where the return comes from but you can't you know maybe you have like a spark cluster that does some stuff but that's not that's not the cake and in in neural networks it really is yeah you know I want to kind of switch gears to thinking about the the sort of future and and and looking forward at what kind of what's next what do you think I mean I'll ask this sort of as broadly as possible to start with what do you think the future of AI holds yeah I think that the future of AI is going to again be both exciting and a source of a lot of change and I think that that is something that you know part of our mission is to try to help facilitate that as positive way as possible I think that kind of you know the super high level I kind of feel like AI was like you know something that for the you know 2020 10s was like kind of cool you know it's the game of like publishing papers and you play some video games and like you know it's just like it's just like fun good science I think it's really interesting that 2020 kicked off with GPT 3 which is really the first model that was commercially useful just as the model like literally put an API on top of it people just talk to it and people build products on top of it and you know that you know one of our early customers just you know just raised it at 1.5 billion valuation which to me is is a really wonderful thing to realize that you build this model and it creates so much value for so many different people and I think that we're still in such early days for what these models can do and so I think that what I'm most excited about from just seeing GPT 3 seeing Dolly is thinking about the the sort of economic value that it can create for people and I think that there's a lot of other pieces to it in terms of like you know that everyone's going to be more creative if you want to like I can't draw but now I can create images now I could take a picture of this in my head and I can actually see it on on a page and one of my favorite applications of Dolly is actually people who are 3D physical artists you know something's like a sculptor and now they can actually get a great rendering of the thing that they have in mind by kind of just like iterating with this machine and they go build it right I think that this sort of amplification of what humans can do is what these systems are for and so I think that for this decade I think what we're really going to see is these tools just sort of proliferating they're going to be everywhere they're going to be baked into every company I think it's kind of like the internet transition that you know that it was kind of like if you're a company like what's your internet strategy and you know 1990 it's like what even is this thing you know and in 2000 it's like huh maybe it's interesting and there there's a little you know boom and bust and here we are today even talk about an internet strategy is like it's just so integral to every business it's not even like it's not even a separate thing right it's just like it's just part of like your it's like your payroll strategy right it's like it's not like a separate part of your business that you can pick or choose whether you're going to have it and I think that AI is going to be much the same I think there will be a transition point right I think that it's it's interesting like our mission is really about building artificial general intelligence right really trying to build machines that are able to perform whole tasks right that are you know push this technology to its limit and build machines that are able to you know our charter definition is outperform humans at most economically valuable work and there's a question of the timeline but I think that that picture of you know you have these tools that are creative that help everyone amplify and what happens when they do become so capable that they're able to perform these tasks even autonomously and I think that actually the implications of that are different from what people expect I think that it's much more like you know that I think there's still going to be this amplification but I think that there the change is going to be just very hard to predict and unexpected and I think that really thinking about how all of that sort of value gets distributed how to make sure that it's sort of pointed at solving these like hard challenges that humans you know maybe are unable to solve ourselves you know the climate change and you know universal education and things like that and really transitioning to this like AI powered world I think is going to be just like a real sort of challenge for the whole you know all of humanity to work together on. Yeah I mean I totally agree one thing that I think is almost funny with how the timing of all these technologies have worked out is that you know last year everyone was talking about Web 3 as crypto and now it feels very obvious that AI is the actual Web 3 you know. We'll take Web 4. Yeah Web 4 we'll skip we'll skip over one but sort of like Web 1 was just reading Web 2 was reading and writing and now Web 3 or 4 depending on what we want to say is ads, computer reading, computer write and it's sort of this incredible new phase. You know one so I think I think you mentioned two two directions here that I think are really interesting one is the sort of advancement and sort of proliferation of GP3 and Dolly and sort of the existing tools becoming more and more economically useful and there's sort of this continued improvement of the algorithms themselves towards sort of towards sort of AGI. What do you think and obviously don't reveal any opening secrets but what do you think this sort of like roadmap to AGI looks like from where we are now? I mean I think that humanity to a large extent has been on the AGI roadmap for a very very long time. I think even looking at just the history of neural networks in particular you know on the one hand we say hey 2012 like that was the moment like everything changed you know that like you look at these we have all these curves of how much compute people put into the landmark results it was going like 10x year over year still continuing by the way that's that's a decade of 10x year over year that's insane and the thing is we actually did a study to then look back at previous results all the way back to you know say the perceptron in 1959 and you actually find that there's basically a very smooth curve back there as well. The amount of compute going into all the landmark results was exactly Moore's law and it kind of makes sense right it's like that people were not willing to spend more money they wanted to spend a constant amount of money on these experiments because you're starving grad students like you know you can only get so much computer time and that the results got better and better the more compute was available to them and I think that that is so interesting that yeah basically what changed in 2012 was that we said okay we're just gonna like you know we are gonna spend more money we're gonna build massive supercomputers now because the ROI is there but that fundamentally the curve if you control for that that cost factor it looks exactly the same and so I think that basically this picture of building more capable models by pouring more compute into them by getting better at harnessing this technology of neural networks back propagation I think that has been very invariant and the details you know maybe change a little bit you know do you want to work on GPT-3 do you want to work on whisper like do you pour in your your you know speech data do you pour in text data from the internet and to me those details I think you know they matter in the like in the like sense of like what are you gonna work on today and you know what are you gonna download but if you zoom out you look at the scale of like these this technology I think it actually sort of doesn't matter so much I think kind of what we're building it's almost like building computers like you think about the Haiti and Moore's law right where it's just like there's a new chip that comes out and there's a new chip that comes out and it's kind of like what's the you know what's the path to building the best computer the answer is well you just keep building the next best chip and you keep building the next best chip and you keep getting better peripherals and all these you know keep working every single piece of the technology and so I think this full stack of better GPUs great software for utilizing them neural networks that we learned to harness more and more the scaling laws doing all the science alignment extremely important making sure these models not just are smart but actually are aligned with what humans intend all of that I think is the stack and so I think that you know what our goal is is just to keep doing something that was previously impossible every single year so you know that I guess well you should check back in a year but hopefully 2023 we'll all forget about Dolly 2 and GPT 3 and we'll be talking about something new and I think as long as we continue that like you cannot continue that path without ending up somewhere amazing yeah I mean I think I actually remember this in I think probably 2017 you were sort of very still quite you were very excited about sort of the sort of Moore's law continuing and that that sort of creating a lot more opportunity for you know neural networks and AI and that's that's sort of played out are you worried about the sort of proverbial end of Moore's law kind of causing a stall out in in progress so I'm not worried about it per se like I think the way to think about this right because I think we you know we often get caught in this debate of like is it all about scale or is it all about algorithms is all about data and the answer is that's a wrong question right it's really like you multiply together these factors and the best thing to do when you're multiplying together multiple terms is that you actually kind of want them all to be equal and I think that the answer is like it's been great for the past you know seven years that we've been able to just pour more dollars to build bigger computers that's one way to get ahead of Moore's law at some point they're just aren't more dollars right there aren't more grains of sand to you know that have been turned into into these these wonderful computers that we use so there is a limit there that we have not yet hit but when you do that does not stall all progress right you still have algorithmic progress and there we've again done studies and we've shown that actually if you take like an example is if you look at the amount of compute it takes to hit the same performance so to train you know a state of the art that you know 2012 or 2014 vision model that that computes also falling exponentially we're basically making exponential progress in algorithms not at the same rate as we are able to you know sort of build bigger computers but that is an amazing force too you know it's like I've got this exponential I've got that exponential like let's not even talk about the data exponential so I think that that the truth is that we will find a way I think that the history of this field is just so consistent and I think that that you know humanity is just so innovative that I think that that we're not going to hit a wall for the foreseeable future and do you think that you know one of the one of the interesting juxtapositions of of today just from a scientific perspective is a relative slowing in nearly every other science and there's you know there's a lot of research that sort of demonstrated that science on the whole slowing and then comparatively the sort of acceleration of artificial intelligence and sort of this this you know in many ways this renaissance that we're entering right now do you do you fear that at some point AI will similarly sort of reach these points of admission mark returns and slow relative like in much in the same way that other sciences have or do you think that's so far away that you know well I think two things I mean I think that there's there's always s-curves although I think that something is also interesting about s-curves is that there tends to be paradigm shifts like have you ever read Singularity is Near no I haven't yeah so this is the Ray Kurzweil book from like 2004 something and I always thought just based on the reputation it's going to be kind of a crazy book but if you actually read it it's the most dry boring reading you'll ever do and it's basically just curve after curve of different industries within computing showing how the performance has changed over time and it's you know basically the conclusion he comes to is that there's this repeated pattern that seems to happen across you know memory across number of transistors on the chip you know etc etc where you kind of have an s-curve of the current paradigm and then you have paradigm shift and that example he talks about is you know thinking about let's talk about CDs right so you talk about great you know CD adoption it's like you know it's great s-curve it's suddenly everywhere it's like everyone's got a CD player like it's just the technology of the day and people get really excited about doing more of the same thing it's like Blu-ray that's the thing you know and so then everyone starts investing in Blu-rays and somehow it just doesn't take off and it's because it's just more of the same and it's like you know it's not backwards compatible and so it's just not really worth it but the real paradigm shift was streaming right suddenly you have this new adoption curve this new s-curve that just is this like totally different way and the way we got to fast computers was basically five different paradigm shifts across a hundred years and so I think that that's maybe a story here too which is like there's gonna be an s-curve in what we're doing right now and that there will be a paradigm shift when you hit it and I think that that again speaks to the ingenuity of humans but I think there's also a second thing where my other answer is to some extent it doesn't matter because the thing about this field is that it's useful now right that kind of the goal that I think we've always had for AI was to actually make us so computers are just way more helpful like you think about what computers have done for humanity right like how many problems they've helped us solve they've created new problems as well but I think that on net that they've helped us solve way more problems than they've created and I think they've kind of just changed the nature of how we interact with each other about how you know like it's just like hard to get lost anymore right you just pull out google maps I think there's really amazing problems that are now within our reach that just would not have been otherwise and I think that AI like we're starting to crack that nut we're starting to be able to you know like it's I think it's kind of interesting you could get a co-pilot you know which which we we power we have the models that power it and that the way that that is useful to people is that provides very low latency suggestions right it's basically an autocomplete for code and that you know there's a very strict latency budget you know if you're more than you know 1500 milliseconds to get a autocomplete suggestion it's worthless like no one wants that you've already moved on but I think that what we really want to build the next phase is machines that help you produce that are able to produce artifacts that are materially interesting on their own so not just interesting because it's like a fast suggestion to you but because it's actually a quality answer and you're starting to see if you talk to our current gbt iteration you can ask it to write some poems and it writes way better poetry than I can it actually wrote a poem for my wife that made us both cry like you know yeah I I cannot do that myself but now I can you know by partnering with this with this machine and I think that that's the real story right is really trying to get these tools out and everywhere and yeah you know if what we're doing right now stalls out I don't think that removes the value from what we're able to create yeah by the way it's depressing that the the attention span of most engineers is only 1500 seconds but you know it is what it is I what uh what if anything you know I think one of the things that if I recall spurred you to to work on opening I was was sort of also being concerned about the sort of potential negative consequences of of the technology um what at this point looking forward what are your sort of biggest concerns or what are you afraid of with with artificial intelligence that you sort of urge everyone in the field to sort of help avoid yeah so I think that one thing that's very interesting about AI is that you know if you talked to certainly you know 10 years ago if you looked at every article about it you talked to someone on the street terminator is the main thing that comes up right so I think there's always been this feeling around AI that is sort of you know that there's an element of fear mixed with the you know sometimes people don't see any potential or sometimes you know they realize that there is the potential but like really trying to figure out and navigate it and I think that that picture the specifics you know I think that that we're starting to see a little bit more but I think the high level picture of this is technology that's very powerful and it can be powerful in positive ways and negative ways um I think is extremely correct and I think it's very important not just to be you know starry eyed optimist everything's just going to work itself out but also not to be you know sort of doomsday like everything is terrible and you know humanity is over because I don't think that's at all true I think this technology can be the the best thing that is the way we've ever created and help us be the best versions of ourselves but I think that it requires very careful navigating of the space and it's not something that just is for you know companies of Silicon Valley to figure out I think it's it's really all of humanity kind of challenge um so I think that we're going to go through different phases I think that that right now I you know we're kind of starting to build systems where that I you know you think about misuse is the most clear problem and the systems themselves are still not very powerful right that the kinds of things you worry about for GPT-3 are you know important problems you think about bias and representation you think about the system sort of you know sort of saying the wrong thing you know but but its action is really in your mind right it's it's sort of words on a page that then you know words on a page are very powerful but that they don't themselves have direct action in the world but you think about something like codex our code writing system which is a little bit more like a robot because it has it emits code and if you were to just execute that code directly it can actually directly have actuators into the world and making sure that that's aligned and doing the right kinds of things not having buggy code and not writing viruses and that kind of thing like that's really important and so I think that that figuring out what values go into this these machines and that they're operating according to those values that's going to be very very critical figure out how to avoid misuse and sort of regulate that both at a sort of societal level at a you know technical level all of that is very important and I and I do think that there is also a point where the technology itself you have to think about that it's going to be extremely powerful and you think about a system that's you know sort of talking to lots of humans and is operating unchecked that's the kind of thing that you should worry about you know we already worry about that think about the companies right that lots of people are using this you know social media platform or you know any of the technologies that we use and how much influence those can have in the world and those aren't systems that have you know sort of deep sort of behaviors that are emergent from from from what they've learned and so I think that that figuring out the technical controls to make sure that these systems remain in service of humanity and sort of to actually empower and accelerate all of us that I think is is also a very critical thing so it's kind of this like a ramping set of stakes and making sure that we're building systems that are aligned with with our values and figuring out what that even means like what what is the values of humanity that should be in the system and that I think is not going to be an easy problem you know one question and this this may be the last question that I have for you is sort of one of the thing one of the conclusions of if the technology such that scale continues to be the the sort of one of the more important things you know scale whether it's data or better algorithms or scale compute then it it the technology itself will tend towards sort of this game theoretical proliferation mode where it's sort of like people are going to compete and you see some of this today even with the large tech companies and you guys obviously people are going to compete to sort of build the bigger supercomputers that have the better performance and you have the bigger supercomputer you have sort of supremacy over the other supercomputers and sort of there's like this you know laddering the stakes and sort of and proliferation is really the sort of the right word do you think that that is a version of the future or do you think that there's sort of some path in which this becomes a much more sort of like open and useful not this sort of like tool for nation states or large companies to compete with one another I think that the future that seems to be unfolding is kind of a you know replay of how say computing technology has played out more broadly I think that that it is still going to be the case that you're going to have these increasingly massive supercomputers that are in the hands of only a few that are able to just create models that can just do crazy things that no one else can do but I don't think that that removes the value from the massive set of things that people are going to do with these models and so you know I think that balancing the like super powerful very dual use extremely you know think of these like almost like you know these massive like you know sort of systems that are you know we think about like a nuclear reactor and it's like you know it's like these like giant like sort of you know systems that you should approach with great care um and you think about like you know by contrast think about wind turbines and like there's lots of wind turbines everywhere and actually that if you add up the amount of value from wind turbines versus nuclear reactors like I think actually that the balance is probably in favor of wind turbines and so I think that that's kind of the future we're going to is that the AI technology is going to be everywhere and there's going to be lots of value that's delivered by having open source models that are integrated to every business and that people are building all sorts of crazy applications on top of and that's something that we really want to support and promote and you also have to have this dual answer for what you do with the with the new extremely capable stuff that's just a mile ahead of everything else and that's something you have to treat with kid gloves with with more care and I think that that balance is tricky it's not easy um that's something that we as an organization have been trying to straddle and I think that you know we've had real existential struggles internally trying to figure out you know like our goal is to empower everyone it's really to uh to to bring everyone along to this AI transition and the best way to do that I think that our picture of it has changed as the technology has unfolded and I think that we're starting to get a sense of of you know where this can go it's really exciting to see all the the energy of all these builders coming in because I think that like you said people are starting to realize like AI is really going to work and it's time to build yeah well um this was an incredible conversation thank you so much Greg next time we speak I'll make you uh read the poem that all right there we go cool thank you so much thank you so much", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.72, "text": " We're joined next by Greg Brockman, President, Chairman and Founder of Open AI and Alexander", "tokens": [50364, 492, 434, 6869, 958, 538, 11490, 32093, 1601, 11, 3117, 11, 17866, 293, 8207, 260, 295, 7238, 7318, 293, 14845, 51100], "temperature": 0.0, "avg_logprob": -0.20204978519015843, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.34935563802719116}, {"id": 1, "seek": 0, "start": 14.72, "end": 18.36, "text": " Wang, CEO and Founder of Scale AI.", "tokens": [51100, 14499, 11, 9282, 293, 8207, 260, 295, 42999, 7318, 13, 51282], "temperature": 0.0, "avg_logprob": -0.20204978519015843, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.34935563802719116}, {"id": 2, "seek": 0, "start": 18.36, "end": 23.52, "text": " Open AI is a research and deployment company whose mission is to ensure general-purpose", "tokens": [51282, 7238, 7318, 307, 257, 2132, 293, 19317, 2237, 6104, 4447, 307, 281, 5586, 2674, 12, 42601, 51540], "temperature": 0.0, "avg_logprob": -0.20204978519015843, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.34935563802719116}, {"id": 3, "seek": 0, "start": 23.52, "end": 27.28, "text": " artificial intelligence benefits all of humanity.", "tokens": [51540, 11677, 7599, 5311, 439, 295, 10243, 13, 51728], "temperature": 0.0, "avg_logprob": -0.20204978519015843, "compression_ratio": 1.4171122994652405, "no_speech_prob": 0.34935563802719116}, {"id": 4, "seek": 2728, "start": 27.28, "end": 34.52, "text": " For Open AI, Greg was the CTO of Stripe, which he helped build from 4 to 250 employees.", "tokens": [50364, 1171, 7238, 7318, 11, 11490, 390, 264, 383, 15427, 295, 20390, 494, 11, 597, 415, 4254, 1322, 490, 1017, 281, 11650, 6619, 13, 50726], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 5, "seek": 2728, "start": 34.52, "end": 40.52, "text": " Please join me in welcoming to the stage Greg Brockman and Alexander Wang.", "tokens": [50726, 2555, 3917, 385, 294, 17378, 281, 264, 3233, 11490, 32093, 1601, 293, 14845, 14499, 13, 51026], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 6, "seek": 2728, "start": 40.52, "end": 42.52, "text": " Hey Greg.", "tokens": [51026, 1911, 11490, 13, 51126], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 7, "seek": 2728, "start": 42.52, "end": 44.52, "text": " Hey.", "tokens": [51126, 1911, 13, 51226], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 8, "seek": 2728, "start": 44.52, "end": 47.0, "text": " Thanks for making it.", "tokens": [51226, 2561, 337, 1455, 309, 13, 51350], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 9, "seek": 2728, "start": 47.0, "end": 48.0, "text": " Absolutely.", "tokens": [51350, 7021, 13, 51400], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 10, "seek": 2728, "start": 48.0, "end": 55.84, "text": " I'd be happy to be here.", "tokens": [51400, 286, 1116, 312, 2055, 281, 312, 510, 13, 51792], "temperature": 0.0, "avg_logprob": -0.40127432024156723, "compression_ratio": 1.289617486338798, "no_speech_prob": 0.044642023742198944}, {"id": 11, "seek": 5584, "start": 55.84, "end": 60.88, "text": " I want to start actually, I don't know if you remember this, but we first met at this", "tokens": [50364, 286, 528, 281, 722, 767, 11, 286, 500, 380, 458, 498, 291, 1604, 341, 11, 457, 321, 700, 1131, 412, 341, 50616], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 12, "seek": 5584, "start": 60.88, "end": 67.0, "text": " summer camp called Spark where you gave a presentation about, at the time you were the", "tokens": [50616, 4266, 2255, 1219, 23424, 689, 291, 2729, 257, 5860, 466, 11, 412, 264, 565, 291, 645, 264, 50922], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 13, "seek": 5584, "start": 67.0, "end": 70.56, "text": " CTO of Stripe and you gave this presentation about sort of like everything you had accomplished", "tokens": [50922, 383, 15427, 295, 20390, 494, 293, 291, 2729, 341, 5860, 466, 1333, 295, 411, 1203, 291, 632, 15419, 51100], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 14, "seek": 5584, "start": 70.56, "end": 73.88, "text": " and I was a member of that camp and it was extremely memorable.", "tokens": [51100, 293, 286, 390, 257, 4006, 295, 300, 2255, 293, 309, 390, 4664, 20723, 13, 51266], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 15, "seek": 5584, "start": 73.88, "end": 75.88, "text": " You had a lot of good sound bites.", "tokens": [51266, 509, 632, 257, 688, 295, 665, 1626, 26030, 13, 51366], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 16, "seek": 5584, "start": 75.88, "end": 78.52000000000001, "text": " I'm glad that it landed.", "tokens": [51366, 286, 478, 5404, 300, 309, 15336, 13, 51498], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 17, "seek": 5584, "start": 78.52000000000001, "end": 80.96000000000001, "text": " Kind of a full circle moment.", "tokens": [51498, 9242, 295, 257, 1577, 6329, 1623, 13, 51620], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 18, "seek": 5584, "start": 80.96000000000001, "end": 85.4, "text": " Well I think to start out with, I mean you've been CTO and now you're President of Open", "tokens": [51620, 1042, 286, 519, 281, 722, 484, 365, 11, 286, 914, 291, 600, 668, 383, 15427, 293, 586, 291, 434, 3117, 295, 7238, 51842], "temperature": 0.0, "avg_logprob": -0.22924361551614633, "compression_ratio": 1.6776315789473684, "no_speech_prob": 0.6281927824020386}, {"id": 19, "seek": 8540, "start": 85.44000000000001, "end": 92.84, "text": " AI, but CTO of two incredibly iconic companies, Stripe and Open AI, in some ways probably two", "tokens": [50366, 7318, 11, 457, 383, 15427, 295, 732, 6252, 15762, 3431, 11, 20390, 494, 293, 7238, 7318, 11, 294, 512, 2098, 1391, 732, 50736], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 20, "seek": 8540, "start": 92.84, "end": 96.96000000000001, "text": " of the most iconic startups of the past decade.", "tokens": [50736, 295, 264, 881, 15762, 28041, 295, 264, 1791, 10378, 13, 50942], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 21, "seek": 8540, "start": 96.96000000000001, "end": 103.32000000000001, "text": " I wanted to start out just by asking in what ways are the two organizations the same and", "tokens": [50942, 286, 1415, 281, 722, 484, 445, 538, 3365, 294, 437, 2098, 366, 264, 732, 6150, 264, 912, 293, 51260], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 22, "seek": 8540, "start": 103.32000000000001, "end": 106.28, "text": " being CTO the same and in what ways are they different?", "tokens": [51260, 885, 383, 15427, 264, 912, 293, 294, 437, 2098, 366, 436, 819, 30, 51408], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 23, "seek": 8540, "start": 106.28, "end": 108.52000000000001, "text": " Thank you for the kind of words.", "tokens": [51408, 1044, 291, 337, 264, 733, 295, 2283, 13, 51520], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 24, "seek": 8540, "start": 108.52000000000001, "end": 113.36000000000001, "text": " I think that one thing that's very interesting to me about kind of having been part of both", "tokens": [51520, 286, 519, 300, 472, 551, 300, 311, 588, 1880, 281, 385, 466, 733, 295, 1419, 668, 644, 295, 1293, 51762], "temperature": 0.0, "avg_logprob": -0.16853084931006798, "compression_ratio": 1.6844262295081966, "no_speech_prob": 0.009695758111774921}, {"id": 25, "seek": 11336, "start": 113.36, "end": 119.28, "text": " of these organizations is seeing how much groups of people are kind of the same regardless", "tokens": [50364, 295, 613, 6150, 307, 2577, 577, 709, 3935, 295, 561, 366, 733, 295, 264, 912, 10060, 50660], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 26, "seek": 11336, "start": 119.28, "end": 122.16, "text": " of what the problem in front of you is.", "tokens": [50660, 295, 437, 264, 1154, 294, 1868, 295, 291, 307, 13, 50804], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 27, "seek": 11336, "start": 122.16, "end": 127.32, "text": " So I think that a lot of how we approached Stripe was thinking from first principles.", "tokens": [50804, 407, 286, 519, 300, 257, 688, 295, 577, 321, 17247, 20390, 494, 390, 1953, 490, 700, 9156, 13, 51062], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 28, "seek": 11336, "start": 127.32, "end": 132.0, "text": " I remember when we were pre-launch and we had some buzz going because we had some early", "tokens": [51062, 286, 1604, 562, 321, 645, 659, 12, 875, 1680, 293, 321, 632, 512, 13036, 516, 570, 321, 632, 512, 2440, 51296], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 29, "seek": 11336, "start": 132.0, "end": 136.48, "text": " customers and one of my friends took me out to launch, he was like all right, I've been", "tokens": [51296, 4581, 293, 472, 295, 452, 1855, 1890, 385, 484, 281, 4025, 11, 415, 390, 411, 439, 558, 11, 286, 600, 668, 51520], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 30, "seek": 11336, "start": 136.48, "end": 139.72, "text": " hearing about this Stripe thing, what's your secret sauce?", "tokens": [51520, 4763, 466, 341, 20390, 494, 551, 11, 437, 311, 428, 4054, 4880, 30, 51682], "temperature": 0.0, "avg_logprob": -0.1880603006907872, "compression_ratio": 1.6164874551971327, "no_speech_prob": 0.0009395182132720947}, {"id": 31, "seek": 13972, "start": 139.8, "end": 144.48, "text": " I was like, I mean we just make payments really good and he's like no, no, no, come on, you", "tokens": [50368, 286, 390, 411, 11, 286, 914, 321, 445, 652, 14348, 534, 665, 293, 415, 311, 411, 572, 11, 572, 11, 572, 11, 808, 322, 11, 291, 50602], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 32, "seek": 13972, "start": 144.48, "end": 147.04, "text": " can tell me, what's the secret sauce?", "tokens": [50602, 393, 980, 385, 11, 437, 311, 264, 4054, 4880, 30, 50730], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 33, "seek": 13972, "start": 147.04, "end": 150.8, "text": " And really that was the secret sauce, right, is that we had just rethought every single", "tokens": [50730, 400, 534, 300, 390, 264, 4054, 4880, 11, 558, 11, 307, 300, 321, 632, 445, 319, 43135, 633, 2167, 50918], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 34, "seek": 13972, "start": 150.8, "end": 154.48, "text": " piece of what we were doing from the ground up from first principles, not sort of locked", "tokens": [50918, 2522, 295, 437, 321, 645, 884, 490, 264, 2727, 493, 490, 700, 9156, 11, 406, 1333, 295, 9376, 51102], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 35, "seek": 13972, "start": 154.48, "end": 157.88, "text": " into the way that people had been doing it and we asked how should it be, like where's", "tokens": [51102, 666, 264, 636, 300, 561, 632, 668, 884, 309, 293, 321, 2351, 577, 820, 309, 312, 11, 411, 689, 311, 51272], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 36, "seek": 13972, "start": 157.88, "end": 160.96, "text": " all the pain and does it need to be there?", "tokens": [51272, 439, 264, 1822, 293, 775, 309, 643, 281, 312, 456, 30, 51426], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 37, "seek": 13972, "start": 160.96, "end": 164.84, "text": " I think that in AI we did much the same, we really thought about okay, there's this field", "tokens": [51426, 286, 519, 300, 294, 7318, 321, 630, 709, 264, 912, 11, 321, 534, 1194, 466, 1392, 11, 456, 311, 341, 2519, 51620], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 38, "seek": 13972, "start": 164.84, "end": 168.0, "text": " that we're entering and that we hire a lot of people who had been in the field, but a", "tokens": [51620, 300, 321, 434, 11104, 293, 300, 321, 11158, 257, 688, 295, 561, 567, 632, 668, 294, 264, 2519, 11, 457, 257, 51778], "temperature": 0.0, "avg_logprob": -0.20824960382973276, "compression_ratio": 1.8545454545454545, "no_speech_prob": 0.006486865226179361}, {"id": 39, "seek": 16800, "start": 168.0, "end": 171.44, "text": " lot of us also hadn't been in the field and we came to it with beginner's eyes and I think", "tokens": [50364, 688, 295, 505, 611, 8782, 380, 668, 294, 264, 2519, 293, 321, 1361, 281, 309, 365, 22080, 311, 2575, 293, 286, 519, 50536], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 40, "seek": 16800, "start": 171.44, "end": 175.36, "text": " that that approach of just not being beholden to all the ways people were doing it, but", "tokens": [50536, 300, 300, 3109, 295, 445, 406, 885, 27234, 268, 281, 439, 264, 2098, 561, 645, 884, 309, 11, 457, 50732], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 41, "seek": 16800, "start": 175.36, "end": 179.84, "text": " also becoming expert in the way that things have been done because if you just throw everything", "tokens": [50732, 611, 5617, 5844, 294, 264, 636, 300, 721, 362, 668, 1096, 570, 498, 291, 445, 3507, 1203, 50956], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 42, "seek": 16800, "start": 179.84, "end": 184.6, "text": " out, like you're also just going to be starting from scratch in a not helpful way.", "tokens": [50956, 484, 11, 411, 291, 434, 611, 445, 516, 281, 312, 2891, 490, 8459, 294, 257, 406, 4961, 636, 13, 51194], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 43, "seek": 16800, "start": 184.6, "end": 188.36, "text": " So I think that that maybe is the deepest commonality between them.", "tokens": [51194, 407, 286, 519, 300, 300, 1310, 307, 264, 28288, 2689, 1860, 1296, 552, 13, 51382], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 44, "seek": 16800, "start": 188.36, "end": 193.64, "text": " But obviously very different organizations, for Stripe I think that we ran the traditional", "tokens": [51382, 583, 2745, 588, 819, 6150, 11, 337, 20390, 494, 286, 519, 300, 321, 5872, 264, 5164, 51646], "temperature": 0.0, "avg_logprob": -0.17712336138260265, "compression_ratio": 1.725752508361204, "no_speech_prob": 0.0012061676243320107}, {"id": 45, "seek": 19364, "start": 193.64, "end": 194.79999999999998, "text": " startup playbook.", "tokens": [50364, 18578, 862, 2939, 13, 50422], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 46, "seek": 19364, "start": 194.79999999999998, "end": 198.23999999999998, "text": " You basically come up with the innovation and you just build, build, build.", "tokens": [50422, 509, 1936, 808, 493, 365, 264, 8504, 293, 291, 445, 1322, 11, 1322, 11, 1322, 13, 50594], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 47, "seek": 19364, "start": 198.23999999999998, "end": 206.44, "text": " You get in front of customers from day one, the story is that we gave the first API to", "tokens": [50594, 509, 483, 294, 1868, 295, 4581, 490, 786, 472, 11, 264, 1657, 307, 300, 321, 2729, 264, 700, 9362, 281, 51004], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 48, "seek": 19364, "start": 206.44, "end": 210.07999999999998, "text": " a customer who charged a credit card and he was like, I would like my money now please", "tokens": [51004, 257, 5474, 567, 11109, 257, 5397, 2920, 293, 415, 390, 411, 11, 286, 576, 411, 452, 1460, 586, 1767, 51186], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 49, "seek": 19364, "start": 210.07999999999998, "end": 214.83999999999997, "text": " and we were like, huh, I guess we should build that.", "tokens": [51186, 293, 321, 645, 411, 11, 7020, 11, 286, 2041, 321, 820, 1322, 300, 13, 51424], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 50, "seek": 19364, "start": 214.83999999999997, "end": 219.79999999999998, "text": " Open AI, we had research to do, like where's the customer?", "tokens": [51424, 7238, 7318, 11, 321, 632, 2132, 281, 360, 11, 411, 689, 311, 264, 5474, 30, 51672], "temperature": 0.0, "avg_logprob": -0.21376366708792893, "compression_ratio": 1.6336206896551724, "no_speech_prob": 0.07362505048513412}, {"id": 51, "seek": 21980, "start": 219.8, "end": 225.08, "text": " And it really took us I guess five years, starting late 2015 and it's really not until", "tokens": [50364, 400, 309, 534, 1890, 505, 286, 2041, 1732, 924, 11, 2891, 3469, 7546, 293, 309, 311, 534, 406, 1826, 50628], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 52, "seek": 21980, "start": 225.08, "end": 228.24, "text": " 2020 that we had our very first product.", "tokens": [50628, 4808, 300, 321, 632, 527, 588, 700, 1674, 13, 50786], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 53, "seek": 21980, "start": 228.24, "end": 232.4, "text": " And so I think that that sort of figuring out like what you're even supposed to work", "tokens": [50786, 400, 370, 286, 519, 300, 300, 1333, 295, 15213, 484, 411, 437, 291, 434, 754, 3442, 281, 589, 50994], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 54, "seek": 21980, "start": 232.4, "end": 237.52, "text": " on, like did you do a good job, should you feel good on a day-to-day basis?", "tokens": [50994, 322, 11, 411, 630, 291, 360, 257, 665, 1691, 11, 820, 291, 841, 665, 322, 257, 786, 12, 1353, 12, 810, 5143, 30, 51250], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 55, "seek": 21980, "start": 237.52, "end": 240.72000000000003, "text": " I think that all of that had to come from within rather than from without.", "tokens": [51250, 286, 519, 300, 439, 295, 300, 632, 281, 808, 490, 1951, 2831, 813, 490, 1553, 13, 51410], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 56, "seek": 21980, "start": 240.72000000000003, "end": 241.72000000000003, "text": " Yeah.", "tokens": [51410, 865, 13, 51460], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 57, "seek": 21980, "start": 241.72000000000003, "end": 244.76000000000002, "text": " Well, actually I want to go back to this point that you mentioned around first principles", "tokens": [51460, 1042, 11, 767, 286, 528, 281, 352, 646, 281, 341, 935, 300, 291, 2835, 926, 700, 9156, 51612], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 58, "seek": 21980, "start": 244.76000000000002, "end": 245.76000000000002, "text": " thinking.", "tokens": [51612, 1953, 13, 51662], "temperature": 0.0, "avg_logprob": -0.220592898707236, "compression_ratio": 1.6398601398601398, "no_speech_prob": 0.04206688702106476}, {"id": 59, "seek": 24576, "start": 245.76, "end": 251.56, "text": " It's very interesting because even I remember like maybe 2020 or 2021, you know, you would", "tokens": [50364, 467, 311, 588, 1880, 570, 754, 286, 1604, 411, 1310, 4808, 420, 7201, 11, 291, 458, 11, 291, 576, 50654], "temperature": 0.0, "avg_logprob": -0.20347134412917417, "compression_ratio": 1.734375, "no_speech_prob": 0.0038225583266466856}, {"id": 60, "seek": 24576, "start": 251.56, "end": 256.88, "text": " sort of post-GPD3, you would talk to other researchers in the field and even they would", "tokens": [50654, 1333, 295, 2183, 12, 38, 17349, 18, 11, 291, 576, 751, 281, 661, 10309, 294, 264, 2519, 293, 754, 436, 576, 50920], "temperature": 0.0, "avg_logprob": -0.20347134412917417, "compression_ratio": 1.734375, "no_speech_prob": 0.0038225583266466856}, {"id": 61, "seek": 24576, "start": 256.88, "end": 262.08, "text": " still, you know, there's still like some degree of skepticism over the sort of like core concept", "tokens": [50920, 920, 11, 291, 458, 11, 456, 311, 920, 411, 512, 4314, 295, 19128, 26356, 670, 264, 1333, 295, 411, 4965, 3410, 51180], "temperature": 0.0, "avg_logprob": -0.20347134412917417, "compression_ratio": 1.734375, "no_speech_prob": 0.0038225583266466856}, {"id": 62, "seek": 24576, "start": 262.08, "end": 266.0, "text": " of scaling up these models and if there were still gains to be had, et cetera.", "tokens": [51180, 295, 21589, 493, 613, 5245, 293, 498, 456, 645, 920, 16823, 281, 312, 632, 11, 1030, 11458, 13, 51376], "temperature": 0.0, "avg_logprob": -0.20347134412917417, "compression_ratio": 1.734375, "no_speech_prob": 0.0038225583266466856}, {"id": 63, "seek": 24576, "start": 266.0, "end": 271.59999999999997, "text": " And I think, you know, I don't know the story but it seems like the sort of research sort", "tokens": [51376, 400, 286, 519, 11, 291, 458, 11, 286, 500, 380, 458, 264, 1657, 457, 309, 2544, 411, 264, 1333, 295, 2132, 1333, 51656], "temperature": 0.0, "avg_logprob": -0.20347134412917417, "compression_ratio": 1.734375, "no_speech_prob": 0.0038225583266466856}, {"id": 64, "seek": 27160, "start": 271.6, "end": 278.36, "text": " of intuition that led to GPD3, Dolly 2 that have really ushered in kind of a new era of", "tokens": [50364, 295, 24002, 300, 4684, 281, 460, 17349, 18, 11, 1144, 13020, 568, 300, 362, 534, 505, 511, 292, 294, 733, 295, 257, 777, 4249, 295, 50702], "temperature": 0.0, "avg_logprob": -0.19559763858192844, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.026743672788143158}, {"id": 65, "seek": 27160, "start": 278.36, "end": 284.76000000000005, "text": " AI were probably, you know, somewhat against the grain or somewhat unintuitive at the time.", "tokens": [50702, 7318, 645, 1391, 11, 291, 458, 11, 8344, 1970, 264, 12837, 420, 8344, 517, 686, 48314, 412, 264, 565, 13, 51022], "temperature": 0.0, "avg_logprob": -0.19559763858192844, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.026743672788143158}, {"id": 66, "seek": 27160, "start": 284.76000000000005, "end": 290.8, "text": " You know, one question I have for you is, you know, I think now looking back it's obviously", "tokens": [51022, 509, 458, 11, 472, 1168, 286, 362, 337, 291, 307, 11, 291, 458, 11, 286, 519, 586, 1237, 646, 309, 311, 2745, 51324], "temperature": 0.0, "avg_logprob": -0.19559763858192844, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.026743672788143158}, {"id": 67, "seek": 27160, "start": 290.8, "end": 297.84000000000003, "text": " very obvious to point out GPD3, Dolly 2 basically have fundamentally accelerated AI progress", "tokens": [51324, 588, 6322, 281, 935, 484, 460, 17349, 18, 11, 1144, 13020, 568, 1936, 362, 17879, 29763, 7318, 4205, 51676], "temperature": 0.0, "avg_logprob": -0.19559763858192844, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.026743672788143158}, {"id": 68, "seek": 29784, "start": 297.84, "end": 302.52, "text": " and its relevance to the world and its relevance to every industry and sort of have created", "tokens": [50364, 293, 1080, 32684, 281, 264, 1002, 293, 1080, 32684, 281, 633, 3518, 293, 1333, 295, 362, 2942, 50598], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 69, "seek": 29784, "start": 302.52, "end": 307.03999999999996, "text": " the sort of most recent AI wave.", "tokens": [50598, 264, 1333, 295, 881, 5162, 7318, 5772, 13, 50824], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 70, "seek": 29784, "start": 307.03999999999996, "end": 311.67999999999995, "text": " How is that matched up against your expectations when you were building these technologies?", "tokens": [50824, 1012, 307, 300, 21447, 493, 1970, 428, 9843, 562, 291, 645, 2390, 613, 7943, 30, 51056], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 71, "seek": 29784, "start": 311.67999999999995, "end": 312.67999999999995, "text": " You know?", "tokens": [51056, 509, 458, 30, 51106], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 72, "seek": 29784, "start": 312.67999999999995, "end": 313.67999999999995, "text": " Yeah.", "tokens": [51106, 865, 13, 51156], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 73, "seek": 29784, "start": 313.67999999999995, "end": 317.71999999999997, "text": " Well, I think the thing that's most interesting to me is that those models you mentioned are", "tokens": [51156, 1042, 11, 286, 519, 264, 551, 300, 311, 881, 1880, 281, 385, 307, 300, 729, 5245, 291, 2835, 366, 51358], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 74, "seek": 29784, "start": 317.71999999999997, "end": 321.64, "text": " kind of overnight successes that took many, many years to create.", "tokens": [51358, 733, 295, 13935, 26101, 300, 1890, 867, 11, 867, 924, 281, 1884, 13, 51554], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 75, "seek": 29784, "start": 321.64, "end": 324.76, "text": " And so, you know, from the outside it looks like, wow, you just like produce this model", "tokens": [51554, 400, 370, 11, 291, 458, 11, 490, 264, 2380, 309, 1542, 411, 11, 6076, 11, 291, 445, 411, 5258, 341, 2316, 51710], "temperature": 0.0, "avg_logprob": -0.16425211676235857, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0007316255941987038}, {"id": 76, "seek": 32476, "start": 324.76, "end": 329.52, "text": " and that model and really on the inside, the GPT arc, that's a five-year arc, right?", "tokens": [50364, 293, 300, 2316, 293, 534, 322, 264, 1854, 11, 264, 26039, 51, 10346, 11, 300, 311, 257, 1732, 12, 5294, 10346, 11, 558, 30, 50602], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 77, "seek": 32476, "start": 329.52, "end": 333.64, "text": " It really started with sentiment neuron paper which is back in 2017.", "tokens": [50602, 467, 534, 1409, 365, 16149, 34090, 3035, 597, 307, 646, 294, 6591, 13, 50808], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 78, "seek": 32476, "start": 333.64, "end": 334.64, "text": " Do you remember that paper?", "tokens": [50808, 1144, 291, 1604, 300, 3035, 30, 50858], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 79, "seek": 32476, "start": 334.64, "end": 335.64, "text": " I remember the paper.", "tokens": [50858, 286, 1604, 264, 3035, 13, 50908], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 80, "seek": 32476, "start": 335.64, "end": 336.64, "text": " It was very cool.", "tokens": [50908, 467, 390, 588, 1627, 13, 50958], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 81, "seek": 32476, "start": 336.64, "end": 337.64, "text": " Yeah.", "tokens": [50958, 865, 13, 51008], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 82, "seek": 32476, "start": 337.64, "end": 338.64, "text": " But it felt very novel.", "tokens": [51008, 583, 309, 2762, 588, 7613, 13, 51058], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 83, "seek": 32476, "start": 338.64, "end": 339.64, "text": " It felt very novel.", "tokens": [51058, 467, 2762, 588, 7613, 13, 51108], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 84, "seek": 32476, "start": 339.64, "end": 340.64, "text": " Yeah.", "tokens": [51108, 865, 13, 51158], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 85, "seek": 32476, "start": 340.64, "end": 341.64, "text": " Very few people remember it.", "tokens": [51158, 4372, 1326, 561, 1604, 309, 13, 51208], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 86, "seek": 32476, "start": 341.64, "end": 345.4, "text": " It's, you know, it was this very early result where we basically had been training a LSTM", "tokens": [51208, 467, 311, 11, 291, 458, 11, 309, 390, 341, 588, 2440, 1874, 689, 321, 1936, 632, 668, 3097, 257, 441, 6840, 44, 51396], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 87, "seek": 32476, "start": 345.4, "end": 348.03999999999996, "text": " at the time to predict the next character in text.", "tokens": [51396, 412, 264, 565, 281, 6069, 264, 958, 2517, 294, 2487, 13, 51528], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 88, "seek": 32476, "start": 348.03999999999996, "end": 349.8, "text": " So, we basically showed a bunch of Amazon reviews.", "tokens": [51528, 407, 11, 321, 1936, 4712, 257, 3840, 295, 6795, 10229, 13, 51616], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 89, "seek": 32476, "start": 349.8, "end": 352.88, "text": " We said, what's the next character and of course it's going to learn where the commas", "tokens": [51616, 492, 848, 11, 437, 311, 264, 958, 2517, 293, 295, 1164, 309, 311, 516, 281, 1466, 689, 264, 800, 296, 51770], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 90, "seek": 32476, "start": 352.88, "end": 353.88, "text": " go.", "tokens": [51770, 352, 13, 51820], "temperature": 0.0, "avg_logprob": -0.20082296327103016, "compression_ratio": 1.719298245614035, "no_speech_prob": 0.07363332062959671}, {"id": 91, "seek": 35388, "start": 353.88, "end": 354.88, "text": " Where the periods go.", "tokens": [50364, 2305, 264, 13804, 352, 13, 50414], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 92, "seek": 35388, "start": 354.88, "end": 357.8, "text": " But of course it's not going to understand anything.", "tokens": [50414, 583, 295, 1164, 309, 311, 406, 516, 281, 1223, 1340, 13, 50560], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 93, "seek": 35388, "start": 357.8, "end": 362.36, "text": " But we found a single neuron in that model that had learned a state-of-the-art sentiment", "tokens": [50560, 583, 321, 1352, 257, 2167, 34090, 294, 300, 2316, 300, 632, 3264, 257, 1785, 12, 2670, 12, 3322, 12, 446, 16149, 50788], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 94, "seek": 35388, "start": 362.36, "end": 363.36, "text": " analysis classifier.", "tokens": [50788, 5215, 1508, 9902, 13, 50838], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 95, "seek": 35388, "start": 363.36, "end": 366.08, "text": " I can tell you this is a positive review or negative review.", "tokens": [50838, 286, 393, 980, 291, 341, 307, 257, 3353, 3131, 420, 3671, 3131, 13, 50974], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 96, "seek": 35388, "start": 366.08, "end": 367.08, "text": " That's understanding.", "tokens": [50974, 663, 311, 3701, 13, 51024], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 97, "seek": 35388, "start": 367.08, "end": 370.56, "text": " You know, I don't know what understanding means but it's semantics for sure.", "tokens": [51024, 509, 458, 11, 286, 500, 380, 458, 437, 3701, 1355, 457, 309, 311, 4361, 45298, 337, 988, 13, 51198], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 98, "seek": 35388, "start": 370.56, "end": 374.04, "text": " And that for us was like, okay, this is going to work.", "tokens": [51198, 400, 300, 337, 505, 390, 411, 11, 1392, 11, 341, 307, 516, 281, 589, 13, 51372], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 99, "seek": 35388, "start": 374.04, "end": 380.12, "text": " The transformer came out late 2017 and my co-founder Ilya immediately was like, that's", "tokens": [51372, 440, 31782, 1361, 484, 3469, 6591, 293, 452, 598, 12, 33348, 286, 45106, 4258, 390, 411, 11, 300, 311, 51676], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 100, "seek": 35388, "start": 380.12, "end": 381.12, "text": " the thing.", "tokens": [51676, 264, 551, 13, 51726], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 101, "seek": 35388, "start": 381.12, "end": 382.12, "text": " That's what we've been waiting for.", "tokens": [51726, 663, 311, 437, 321, 600, 668, 3806, 337, 13, 51776], "temperature": 0.0, "avg_logprob": -0.16549615990625668, "compression_ratio": 1.697452229299363, "no_speech_prob": 0.00022337021073326468}, {"id": 102, "seek": 38212, "start": 382.12, "end": 386.56, "text": " So, you take this sort of very early nascent result, put in a transformer and then that's", "tokens": [50364, 407, 11, 291, 747, 341, 1333, 295, 588, 2440, 5382, 2207, 1874, 11, 829, 294, 257, 31782, 293, 550, 300, 311, 50586], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 103, "seek": 38212, "start": 386.56, "end": 387.56, "text": " GPT-1.", "tokens": [50586, 26039, 51, 12, 16, 13, 50636], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 104, "seek": 38212, "start": 387.56, "end": 390.04, "text": " GPT-2 is you just keep pushing it.", "tokens": [50636, 26039, 51, 12, 17, 307, 291, 445, 1066, 7380, 309, 13, 50760], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 105, "seek": 38212, "start": 390.04, "end": 393.84000000000003, "text": " And you know, I think that the algorithm we kind of run internally is that we do these", "tokens": [50760, 400, 291, 458, 11, 286, 519, 300, 264, 9284, 321, 733, 295, 1190, 19501, 307, 300, 321, 360, 613, 50950], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 106, "seek": 38212, "start": 393.84000000000003, "end": 398.24, "text": " little sort of get signs of life and you have to be very, very careful to distinguish signs", "tokens": [50950, 707, 1333, 295, 483, 7880, 295, 993, 293, 291, 362, 281, 312, 588, 11, 588, 5026, 281, 20206, 7880, 51170], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 107, "seek": 38212, "start": 398.24, "end": 401.84000000000003, "text": " of life from like kind of just pushing too hard on a specific data set that isn't really", "tokens": [51170, 295, 993, 490, 411, 733, 295, 445, 7380, 886, 1152, 322, 257, 2685, 1412, 992, 300, 1943, 380, 534, 51350], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 108, "seek": 38212, "start": 401.84000000000003, "end": 402.84000000000003, "text": " going to keep going.", "tokens": [51350, 516, 281, 1066, 516, 13, 51400], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 109, "seek": 38212, "start": 402.84000000000003, "end": 406.28000000000003, "text": " But if you kind of build those right intuitions then you know, okay, now is the time to put", "tokens": [51400, 583, 498, 291, 733, 295, 1322, 729, 558, 16224, 626, 550, 291, 458, 11, 1392, 11, 586, 307, 264, 565, 281, 829, 51572], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 110, "seek": 38212, "start": 406.28000000000003, "end": 407.28000000000003, "text": " in more compute.", "tokens": [51572, 294, 544, 14722, 13, 51622], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 111, "seek": 38212, "start": 407.28000000000003, "end": 408.28000000000003, "text": " Now is the time to put in more researchers.", "tokens": [51622, 823, 307, 264, 565, 281, 829, 294, 544, 10309, 13, 51672], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 112, "seek": 38212, "start": 408.28000000000003, "end": 410.64, "text": " Now is the time to like really scale it up.", "tokens": [51672, 823, 307, 264, 565, 281, 411, 534, 4373, 309, 493, 13, 51790], "temperature": 0.0, "avg_logprob": -0.1601224562701057, "compression_ratio": 1.852852852852853, "no_speech_prob": 0.0003149832191411406}, {"id": 113, "seek": 41064, "start": 410.64, "end": 416.03999999999996, "text": " And so GPT-2 obviously was exciting and that we were all like, well, we look at the curves.", "tokens": [50364, 400, 370, 26039, 51, 12, 17, 2745, 390, 4670, 293, 300, 321, 645, 439, 411, 11, 731, 11, 321, 574, 412, 264, 19490, 13, 50634], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 114, "seek": 41064, "start": 416.03999999999996, "end": 418.88, "text": " You know, the bigger we made this model, the more compute we put in, the more data we put", "tokens": [50634, 509, 458, 11, 264, 3801, 321, 1027, 341, 2316, 11, 264, 544, 14722, 321, 829, 294, 11, 264, 544, 1412, 321, 829, 50776], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 115, "seek": 41064, "start": 418.88, "end": 423.8, "text": " in, the more we just sort of got all the engineering details right, those curves just got better.", "tokens": [50776, 294, 11, 264, 544, 321, 445, 1333, 295, 658, 439, 264, 7043, 4365, 558, 11, 729, 19490, 445, 658, 1101, 13, 51022], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 116, "seek": 41064, "start": 423.8, "end": 426.88, "text": " And so actually, you know, our goal was just to break the paradigm.", "tokens": [51022, 400, 370, 767, 11, 291, 458, 11, 527, 3387, 390, 445, 281, 1821, 264, 24709, 13, 51176], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 117, "seek": 41064, "start": 426.88, "end": 430.59999999999997, "text": " It was just push it until the curve stopped looking good and we still haven't managed", "tokens": [51176, 467, 390, 445, 2944, 309, 1826, 264, 7605, 5936, 1237, 665, 293, 321, 920, 2378, 380, 6453, 51362], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 118, "seek": 41064, "start": 430.59999999999997, "end": 431.59999999999997, "text": " to accomplish it.", "tokens": [51362, 281, 9021, 309, 13, 51412], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 119, "seek": 41064, "start": 431.59999999999997, "end": 432.59999999999997, "text": " Yeah.", "tokens": [51412, 865, 13, 51462], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 120, "seek": 41064, "start": 432.59999999999997, "end": 438.12, "text": " Well, I think one of the things, at least for me and probably for many people who initially", "tokens": [51462, 1042, 11, 286, 519, 472, 295, 264, 721, 11, 412, 1935, 337, 385, 293, 1391, 337, 867, 561, 567, 9105, 51738], "temperature": 0.0, "avg_logprob": -0.15318608283996582, "compression_ratio": 1.7264150943396226, "no_speech_prob": 0.00023048059665597975}, {"id": 121, "seek": 43812, "start": 438.12, "end": 442.44, "text": " played with GPT-3, the like shocking thing was not, I mean, it wasn't necessarily that", "tokens": [50364, 3737, 365, 26039, 51, 12, 18, 11, 264, 411, 18776, 551, 390, 406, 11, 286, 914, 11, 309, 2067, 380, 4725, 300, 50580], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 122, "seek": 43812, "start": 442.44, "end": 447.8, "text": " even the model got better and better performance on, you know, established tasks is that it", "tokens": [50580, 754, 264, 2316, 658, 1101, 293, 1101, 3389, 322, 11, 291, 458, 11, 7545, 9608, 307, 300, 309, 50848], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 123, "seek": 43812, "start": 447.8, "end": 452.28000000000003, "text": " sort of had all these qualitatively new behaviors that were felt very magical.", "tokens": [50848, 1333, 295, 632, 439, 613, 31312, 356, 777, 15501, 300, 645, 2762, 588, 12066, 13, 51072], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 124, "seek": 43812, "start": 452.28000000000003, "end": 455.92, "text": " And even now, you know, there's prompts that, you know, you'll see on Twitter or whatnot", "tokens": [51072, 400, 754, 586, 11, 291, 458, 11, 456, 311, 41095, 300, 11, 291, 458, 11, 291, 603, 536, 322, 5794, 420, 25882, 51254], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 125, "seek": 43812, "start": 455.92, "end": 458.16, "text": " that are sort of really shocking.", "tokens": [51254, 300, 366, 1333, 295, 534, 18776, 13, 51366], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 126, "seek": 43812, "start": 458.16, "end": 464.28000000000003, "text": " I mean, did you have these sort of like early moments when like you had the early model", "tokens": [51366, 286, 914, 11, 630, 291, 362, 613, 1333, 295, 411, 2440, 6065, 562, 411, 291, 632, 264, 2440, 2316, 51672], "temperature": 0.0, "avg_logprob": -0.16831792521680522, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.007574265822768211}, {"id": 127, "seek": 46428, "start": 464.28, "end": 468.15999999999997, "text": " results were like, holy crap, this is like, this is magic.", "tokens": [50364, 3542, 645, 411, 11, 10622, 12426, 11, 341, 307, 411, 11, 341, 307, 5585, 13, 50558], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 128, "seek": 46428, "start": 468.15999999999997, "end": 469.15999999999997, "text": " Yeah.", "tokens": [50558, 865, 13, 50608], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 129, "seek": 46428, "start": 469.15999999999997, "end": 472.84, "text": " Well, I think that the earliest one that I remember was around code.", "tokens": [50608, 1042, 11, 286, 519, 300, 264, 20573, 472, 300, 286, 1604, 390, 926, 3089, 13, 50792], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 130, "seek": 46428, "start": 472.84, "end": 477.67999999999995, "text": " I mean, just, you know, at the time, totally mind blowing that you could just write a function", "tokens": [50792, 286, 914, 11, 445, 11, 291, 458, 11, 412, 264, 565, 11, 3879, 1575, 15068, 300, 291, 727, 445, 2464, 257, 2445, 51034], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 131, "seek": 46428, "start": 477.67999999999995, "end": 481.4, "text": " name and a doc string kind of describing what the function should do and actually write", "tokens": [51034, 1315, 293, 257, 3211, 6798, 733, 295, 16141, 437, 264, 2445, 820, 360, 293, 767, 2464, 51220], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 132, "seek": 46428, "start": 481.4, "end": 482.4, "text": " it.", "tokens": [51220, 309, 13, 51270], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 133, "seek": 46428, "start": 482.4, "end": 483.71999999999997, "text": " Not super complicated functions, right?", "tokens": [51270, 1726, 1687, 6179, 6828, 11, 558, 30, 51336], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 134, "seek": 46428, "start": 483.71999999999997, "end": 487.4, "text": " But just that it was able to, you know, you ask for, you know, something to take a couple", "tokens": [51336, 583, 445, 300, 309, 390, 1075, 281, 11, 291, 458, 11, 291, 1029, 337, 11, 291, 458, 11, 746, 281, 747, 257, 1916, 51520], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 135, "seek": 46428, "start": 487.4, "end": 489.59999999999997, "text": " lines and they would be able to really do it.", "tokens": [51520, 3876, 293, 436, 576, 312, 1075, 281, 534, 360, 309, 13, 51630], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 136, "seek": 46428, "start": 489.59999999999997, "end": 492.15999999999997, "text": " You modify things a little bit to make sure it hadn't just memorized it.", "tokens": [51630, 509, 16927, 721, 257, 707, 857, 281, 652, 988, 309, 8782, 380, 445, 46677, 309, 13, 51758], "temperature": 0.0, "avg_logprob": -0.19523352818773282, "compression_ratio": 1.7670807453416149, "no_speech_prob": 0.06184728071093559}, {"id": 137, "seek": 49216, "start": 492.16, "end": 495.0, "text": " Make sure enough that it would write out the modified code.", "tokens": [50364, 4387, 988, 1547, 300, 309, 576, 2464, 484, 264, 15873, 3089, 13, 50506], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 138, "seek": 49216, "start": 495.0, "end": 498.48, "text": " And I think, you know, the overall thing that's really interesting about the paradigm of a", "tokens": [50506, 400, 286, 519, 11, 291, 458, 11, 264, 4787, 551, 300, 311, 534, 1880, 466, 264, 24709, 295, 257, 50680], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 139, "seek": 49216, "start": 498.48, "end": 504.28000000000003, "text": " GPT-3 is that where it really comes from is that I, you know, we kind of had this picture", "tokens": [50680, 26039, 51, 12, 18, 307, 300, 689, 309, 534, 1487, 490, 307, 300, 286, 11, 291, 458, 11, 321, 733, 295, 632, 341, 3036, 50970], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 140, "seek": 49216, "start": 504.28000000000003, "end": 509.16, "text": " that, look, the problem with these models is that they're great within their data distribution.", "tokens": [50970, 300, 11, 574, 11, 264, 1154, 365, 613, 5245, 307, 300, 436, 434, 869, 1951, 641, 1412, 7316, 13, 51214], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 141, "seek": 49216, "start": 509.16, "end": 512.6800000000001, "text": " But as soon as you're outside of that distribution, like all bets are off.", "tokens": [51214, 583, 382, 2321, 382, 291, 434, 2380, 295, 300, 7316, 11, 411, 439, 39922, 366, 766, 13, 51390], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 142, "seek": 49216, "start": 512.6800000000001, "end": 516.6, "text": " And so what if you just make the whole world, the whole universe, be the data distribution?", "tokens": [51390, 400, 370, 437, 498, 291, 445, 652, 264, 1379, 1002, 11, 264, 1379, 6445, 11, 312, 264, 1412, 7316, 30, 51586], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 143, "seek": 49216, "start": 516.6, "end": 518.6800000000001, "text": " You put the whole internet in there.", "tokens": [51586, 509, 829, 264, 1379, 4705, 294, 456, 13, 51690], "temperature": 0.0, "avg_logprob": -0.20415608441388167, "compression_ratio": 1.758957654723127, "no_speech_prob": 0.0010003597708418965}, {"id": 144, "seek": 51868, "start": 518.68, "end": 525.4, "text": " And I think that what we've really seen is that these models, that they really are able", "tokens": [50364, 400, 286, 519, 300, 437, 321, 600, 534, 1612, 307, 300, 613, 5245, 11, 300, 436, 534, 366, 1075, 50700], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 145, "seek": 51868, "start": 525.4, "end": 528.8399999999999, "text": " to generalize extremely well within the kinds of things that they've seen.", "tokens": [50700, 281, 2674, 1125, 4664, 731, 1951, 264, 3685, 295, 721, 300, 436, 600, 1612, 13, 50872], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 146, "seek": 51868, "start": 528.8399999999999, "end": 531.12, "text": " You know, again, different question if it's never seen anything like it.", "tokens": [50872, 509, 458, 11, 797, 11, 819, 1168, 498, 309, 311, 1128, 1612, 1340, 411, 309, 13, 50986], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 147, "seek": 51868, "start": 531.12, "end": 534.64, "text": " I mean, humans are also not very good at things you've never seen before.", "tokens": [50986, 286, 914, 11, 6255, 366, 611, 406, 588, 665, 412, 721, 291, 600, 1128, 1612, 949, 13, 51162], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 148, "seek": 51868, "start": 534.64, "end": 539.8399999999999, "text": " But I think that that picture of just, like, all of the different things that it's seen", "tokens": [51162, 583, 286, 519, 300, 300, 3036, 295, 445, 11, 411, 11, 439, 295, 264, 819, 721, 300, 309, 311, 1612, 51422], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 149, "seek": 51868, "start": 539.8399999999999, "end": 542.16, "text": " in all these different configurations is almost unimaginable.", "tokens": [51422, 294, 439, 613, 819, 31493, 307, 1920, 517, 44976, 712, 13, 51538], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 150, "seek": 51868, "start": 542.16, "end": 546.5999999999999, "text": " There's no human who's been able to consume, you know, 40 terabytes worth of text.", "tokens": [51538, 821, 311, 572, 1952, 567, 311, 668, 1075, 281, 14732, 11, 291, 458, 11, 3356, 1796, 24538, 3163, 295, 2487, 13, 51760], "temperature": 0.0, "avg_logprob": -0.1405130174424913, "compression_ratio": 1.8066666666666666, "no_speech_prob": 0.0004581805260386318}, {"id": 151, "seek": 54660, "start": 546.6, "end": 551.52, "text": " And so I think that we just keep seeing surprises where you just ask for, one of my favorite", "tokens": [50364, 400, 370, 286, 519, 300, 321, 445, 1066, 2577, 22655, 689, 291, 445, 1029, 337, 11, 472, 295, 452, 2954, 50610], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 152, "seek": 54660, "start": 551.52, "end": 556.12, "text": " ones actually was this teacher-student interaction where I was the teacher model as the student", "tokens": [50610, 2306, 767, 390, 341, 5027, 12, 372, 24064, 9285, 689, 286, 390, 264, 5027, 2316, 382, 264, 3107, 50840], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 153, "seek": 54660, "start": 556.12, "end": 558.32, "text": " and I managed to teach it how to sort numbers.", "tokens": [50840, 293, 286, 6453, 281, 2924, 309, 577, 281, 1333, 3547, 13, 50950], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 154, "seek": 54660, "start": 558.32, "end": 561.24, "text": " And you just kind of have these experiences where, like, that's what it should be like", "tokens": [50950, 400, 291, 445, 733, 295, 362, 613, 5235, 689, 11, 411, 11, 300, 311, 437, 309, 820, 312, 411, 51096], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 155, "seek": 54660, "start": 561.24, "end": 562.72, "text": " to interact with an AI.", "tokens": [51096, 281, 4648, 365, 364, 7318, 13, 51170], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 156, "seek": 54660, "start": 562.72, "end": 563.72, "text": " Yeah.", "tokens": [51170, 865, 13, 51220], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 157, "seek": 54660, "start": 563.72, "end": 565.6, "text": " I mean, it's incredibly shocking.", "tokens": [51220, 286, 914, 11, 309, 311, 6252, 18776, 13, 51314], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 158, "seek": 54660, "start": 565.6, "end": 571.08, "text": " You know, one of the things I'm curious to get your thoughts on is, I think, in the path", "tokens": [51314, 509, 458, 11, 472, 295, 264, 721, 286, 478, 6369, 281, 483, 428, 4598, 322, 307, 11, 286, 519, 11, 294, 264, 3100, 51588], "temperature": 0.0, "avg_logprob": -0.1916217041015625, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.00021651167480740696}, {"id": 159, "seek": 57108, "start": 571.08, "end": 577.2, "text": " of developing GP3, you know, required, I think probably the jump from GP2 to GP3 required", "tokens": [50364, 295, 6416, 26039, 18, 11, 291, 458, 11, 4739, 11, 286, 519, 1391, 264, 3012, 490, 26039, 17, 281, 26039, 18, 4739, 50670], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 160, "seek": 57108, "start": 577.2, "end": 582.0, "text": " a lot of conviction because, you know, you all were spending probably a fair amount on", "tokens": [50670, 257, 688, 295, 24837, 570, 11, 291, 458, 11, 291, 439, 645, 6434, 1391, 257, 3143, 2372, 322, 50910], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 161, "seek": 57108, "start": 582.0, "end": 584.96, "text": " a compute at the time to be able to train these models and there were probably a lot", "tokens": [50910, 257, 14722, 412, 264, 565, 281, 312, 1075, 281, 3847, 613, 5245, 293, 456, 645, 1391, 257, 688, 51058], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 162, "seek": 57108, "start": 584.96, "end": 589.36, "text": " of experiments that didn't work and so you had to be willing to keep going after it.", "tokens": [51058, 295, 12050, 300, 994, 380, 589, 293, 370, 291, 632, 281, 312, 4950, 281, 1066, 516, 934, 309, 13, 51278], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 163, "seek": 57108, "start": 589.36, "end": 595.0, "text": " Did that phase of the journey, sort of this, like, GP2 to GP3 jump, was it scary?", "tokens": [51278, 2589, 300, 5574, 295, 264, 4671, 11, 1333, 295, 341, 11, 411, 11, 26039, 17, 281, 26039, 18, 3012, 11, 390, 309, 6958, 30, 51560], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 164, "seek": 57108, "start": 595.0, "end": 596.2, "text": " Did you have doubts?", "tokens": [51560, 2589, 291, 362, 22618, 30, 51620], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 165, "seek": 57108, "start": 596.2, "end": 599.84, "text": " Or were you very confident that, hey, you know, we're going to scale this up and even", "tokens": [51620, 1610, 645, 291, 588, 6679, 300, 11, 4177, 11, 291, 458, 11, 321, 434, 516, 281, 4373, 341, 493, 293, 754, 51802], "temperature": 0.0, "avg_logprob": -0.18633392974213286, "compression_ratio": 1.7370129870129871, "no_speech_prob": 0.061840493232011795}, {"id": 166, "seek": 59984, "start": 599.84, "end": 604.0400000000001, "text": " though we're going to not get it right the first few times, it's going to be amazing?", "tokens": [50364, 1673, 321, 434, 516, 281, 406, 483, 309, 558, 264, 700, 1326, 1413, 11, 309, 311, 516, 281, 312, 2243, 30, 50574], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 167, "seek": 59984, "start": 604.0400000000001, "end": 605.0400000000001, "text": " Yeah.", "tokens": [50574, 865, 13, 50624], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 168, "seek": 59984, "start": 605.0400000000001, "end": 610.36, "text": " And to your point that scale was not an obvious thing, not the company, but the scaling things", "tokens": [50624, 400, 281, 428, 935, 300, 4373, 390, 406, 364, 6322, 551, 11, 406, 264, 2237, 11, 457, 264, 21589, 721, 50890], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 169, "seek": 59984, "start": 610.36, "end": 616.0, "text": " up, at the time, the funny thing is actually our very first scale result that just sort", "tokens": [50890, 493, 11, 412, 264, 565, 11, 264, 4074, 551, 307, 767, 527, 588, 700, 4373, 1874, 300, 445, 1333, 51172], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 170, "seek": 59984, "start": 616.0, "end": 619.32, "text": " of convinced us that this is the right way to approach things.", "tokens": [51172, 295, 12561, 505, 300, 341, 307, 264, 558, 636, 281, 3109, 721, 13, 51338], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 171, "seek": 59984, "start": 619.32, "end": 620.64, "text": " You push it until it breaks.", "tokens": [51338, 509, 2944, 309, 1826, 309, 9857, 13, 51404], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 172, "seek": 59984, "start": 620.64, "end": 624.24, "text": " Not necessarily that more compute is just magically always going to solve your problem.", "tokens": [51404, 1726, 4725, 300, 544, 14722, 307, 445, 39763, 1009, 516, 281, 5039, 428, 1154, 13, 51584], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 173, "seek": 59984, "start": 624.24, "end": 625.24, "text": " It was Dota.", "tokens": [51584, 467, 390, 413, 5377, 13, 51634], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 174, "seek": 59984, "start": 625.24, "end": 628.08, "text": " That was, you know, playing competitive video games and there we kind of went through this", "tokens": [51634, 663, 390, 11, 291, 458, 11, 2433, 10043, 960, 2813, 293, 456, 321, 733, 295, 1437, 807, 341, 51776], "temperature": 0.0, "avg_logprob": -0.17151618685041156, "compression_ratio": 1.7275541795665634, "no_speech_prob": 0.0006262135575525463}, {"id": 175, "seek": 62808, "start": 628.08, "end": 632.12, "text": " whole, that was a three-year arc where we started out with something that didn't do", "tokens": [50364, 1379, 11, 300, 390, 257, 1045, 12, 5294, 10346, 689, 321, 1409, 484, 365, 746, 300, 994, 380, 360, 50566], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 176, "seek": 62808, "start": 632.12, "end": 636.0, "text": " anything, finally beat, like, you know, the in-house team, then we managed to go beat", "tokens": [50566, 1340, 11, 2721, 4224, 11, 411, 11, 291, 458, 11, 264, 294, 12, 6410, 1469, 11, 550, 321, 6453, 281, 352, 4224, 50760], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 177, "seek": 62808, "start": 636.0, "end": 641.08, "text": " the pros and at each step it was just kind of pushing in all dimensions, right, is make", "tokens": [50760, 264, 6267, 293, 412, 1184, 1823, 309, 390, 445, 733, 295, 7380, 294, 439, 12819, 11, 558, 11, 307, 652, 51014], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 178, "seek": 62808, "start": 641.08, "end": 646.24, "text": " the model bigger, it's to, you know, sort of, again, fix all the bugs and you just kind", "tokens": [51014, 264, 2316, 3801, 11, 309, 311, 281, 11, 291, 458, 11, 1333, 295, 11, 797, 11, 3191, 439, 264, 15120, 293, 291, 445, 733, 51272], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 179, "seek": 62808, "start": 646.24, "end": 650.9200000000001, "text": " of keep iterating on every single dimension and every single dimension yields returns.", "tokens": [51272, 295, 1066, 17138, 990, 322, 633, 2167, 10139, 293, 633, 2167, 10139, 32168, 11247, 13, 51506], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 180, "seek": 62808, "start": 650.9200000000001, "end": 655.5600000000001, "text": " And so I think that we did very much the same thing where for GP2, you know, it's not as", "tokens": [51506, 400, 370, 286, 519, 300, 321, 630, 588, 709, 264, 912, 551, 689, 337, 26039, 17, 11, 291, 458, 11, 309, 311, 406, 382, 51738], "temperature": 0.0, "avg_logprob": -0.1584367199220519, "compression_ratio": 1.796551724137931, "no_speech_prob": 0.0017003904795274138}, {"id": 181, "seek": 65556, "start": 655.5999999999999, "end": 660.2399999999999, "text": " simple as saying, okay, like, clearly you just need to, like, you know, crank up this", "tokens": [50366, 2199, 382, 1566, 11, 1392, 11, 411, 11, 4448, 291, 445, 643, 281, 11, 411, 11, 291, 458, 11, 21263, 493, 341, 50598], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 182, "seek": 65556, "start": 660.2399999999999, "end": 662.4399999999999, "text": " one variable and you just do it in one shot.", "tokens": [50598, 472, 7006, 293, 291, 445, 360, 309, 294, 472, 3347, 13, 50708], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 183, "seek": 65556, "start": 662.4399999999999, "end": 667.0799999999999, "text": " It's this, like, sort of iterative, like, stepping through the space on each axis at", "tokens": [50708, 467, 311, 341, 11, 411, 11, 1333, 295, 17138, 1166, 11, 411, 11, 16821, 807, 264, 1901, 322, 1184, 10298, 412, 50940], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 184, "seek": 65556, "start": 667.0799999999999, "end": 668.52, "text": " every single time.", "tokens": [50940, 633, 2167, 565, 13, 51012], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 185, "seek": 65556, "start": 668.52, "end": 671.7199999999999, "text": " And so I think that on the one hand it does require conviction because you do need to", "tokens": [51012, 400, 370, 286, 519, 300, 322, 264, 472, 1011, 309, 775, 3651, 24837, 570, 291, 360, 643, 281, 51172], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 186, "seek": 65556, "start": 671.7199999999999, "end": 675.3599999999999, "text": " say we're going to, like, carve out a big compute budget so that you're not constantly", "tokens": [51172, 584, 321, 434, 516, 281, 11, 411, 11, 33832, 484, 257, 955, 14722, 4706, 370, 300, 291, 434, 406, 6460, 51354], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 187, "seek": 65556, "start": 675.3599999999999, "end": 679.88, "text": " not kind of fighting other people for the big supercomputers, but on the other hand,", "tokens": [51354, 406, 733, 295, 5237, 661, 561, 337, 264, 955, 27839, 2582, 433, 11, 457, 322, 264, 661, 1011, 11, 51580], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 188, "seek": 65556, "start": 679.88, "end": 683.56, "text": " I think it's also very iterative and you don't have to make scary irreversible decisions", "tokens": [51580, 286, 519, 309, 311, 611, 588, 17138, 1166, 293, 291, 500, 380, 362, 281, 652, 6958, 16014, 840, 964, 5327, 51764], "temperature": 0.0, "avg_logprob": -0.1323922724505655, "compression_ratio": 1.8043478260869565, "no_speech_prob": 0.001169247436337173}, {"id": 189, "seek": 68356, "start": 683.5999999999999, "end": 686.4, "text": " because in each step you get feedback from reality.", "tokens": [50366, 570, 294, 1184, 1823, 291, 483, 5824, 490, 4103, 13, 50506], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 190, "seek": 68356, "start": 686.4, "end": 691.8, "text": " And I think that that key of, like, both the big picture, thinking of what if this works", "tokens": [50506, 400, 286, 519, 300, 300, 2141, 295, 11, 411, 11, 1293, 264, 955, 3036, 11, 1953, 295, 437, 498, 341, 1985, 50776], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 191, "seek": 68356, "start": 691.8, "end": 696.8399999999999, "text": " and make sure that you're really set up for success, but also don't blindly spend a year", "tokens": [50776, 293, 652, 988, 300, 291, 434, 534, 992, 493, 337, 2245, 11, 457, 611, 500, 380, 47744, 3496, 257, 1064, 51028], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 192, "seek": 68356, "start": 696.8399999999999, "end": 700.3199999999999, "text": " of your organization on just, like, pursuing a thing that might not pan out.", "tokens": [51028, 295, 428, 4475, 322, 445, 11, 411, 11, 20222, 257, 551, 300, 1062, 406, 2462, 484, 13, 51202], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 193, "seek": 68356, "start": 700.3199999999999, "end": 703.0, "text": " I think that balancing those two is what was really key.", "tokens": [51202, 286, 519, 300, 22495, 729, 732, 307, 437, 390, 534, 2141, 13, 51336], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 194, "seek": 68356, "start": 703.0, "end": 708.2399999999999, "text": " Yeah, I mean, one of the cool things is you sort of walk through this and talk through", "tokens": [51336, 865, 11, 286, 914, 11, 472, 295, 264, 1627, 721, 307, 291, 1333, 295, 1792, 807, 341, 293, 751, 807, 51598], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 195, "seek": 68356, "start": 708.2399999999999, "end": 713.52, "text": " the insights is that the sort of organizational learnings were really critical in this entire", "tokens": [51598, 264, 14310, 307, 300, 264, 1333, 295, 24730, 2539, 82, 645, 534, 4924, 294, 341, 2302, 51862], "temperature": 0.0, "avg_logprob": -0.1700261000430945, "compression_ratio": 1.8013245033112584, "no_speech_prob": 9.311826579505578e-05}, {"id": 196, "seek": 71352, "start": 713.88, "end": 719.3199999999999, "text": " sort of path-dependent sort of path to GP3.", "tokens": [50382, 1333, 295, 3100, 12, 36763, 317, 1333, 295, 3100, 281, 26039, 18, 13, 50654], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 197, "seek": 71352, "start": 719.3199999999999, "end": 725.0799999999999, "text": " It sort of, you know, it makes sense when you say it that sort of insights from Dota 2", "tokens": [50654, 467, 1333, 295, 11, 291, 458, 11, 309, 1669, 2020, 562, 291, 584, 309, 300, 1333, 295, 14310, 490, 413, 5377, 568, 50942], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 198, "seek": 71352, "start": 725.0799999999999, "end": 729.04, "text": " and insights from the sentiment neuron were sort of like the key, these were like the", "tokens": [50942, 293, 14310, 490, 264, 16149, 34090, 645, 1333, 295, 411, 264, 2141, 11, 613, 645, 411, 264, 51140], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 199, "seek": 71352, "start": 729.04, "end": 733.04, "text": " key nuggets that led to the sort of, like, crystallized idea of, you know, scaling up", "tokens": [51140, 2141, 42663, 300, 4684, 281, 264, 1333, 295, 11, 411, 11, 31924, 1602, 1558, 295, 11, 291, 458, 11, 21589, 493, 51340], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 200, "seek": 71352, "start": 733.04, "end": 737.52, "text": " and building GP3, but it's very unintuitive from the outside and sort of, I think it's", "tokens": [51340, 293, 2390, 26039, 18, 11, 457, 309, 311, 588, 29466, 48314, 490, 264, 2380, 293, 1333, 295, 11, 286, 519, 309, 311, 51564], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 201, "seek": 71352, "start": 737.52, "end": 742.68, "text": " almost a statement of innovation in some sense is that, you know, you're going to piece together", "tokens": [51564, 1920, 257, 5629, 295, 8504, 294, 512, 2020, 307, 300, 11, 291, 458, 11, 291, 434, 516, 281, 2522, 1214, 51822], "temperature": 0.0, "avg_logprob": -0.19738104177075763, "compression_ratio": 1.8549618320610688, "no_speech_prob": 0.0001354948471998796}, {"id": 202, "seek": 74268, "start": 742.7199999999999, "end": 746.7199999999999, "text": " this sort of, like, disparate collection of insights that you gather from a wide variety", "tokens": [50366, 341, 1333, 295, 11, 411, 11, 14548, 473, 5765, 295, 14310, 300, 291, 5448, 490, 257, 4874, 5673, 50566], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 203, "seek": 74268, "start": 746.7199999999999, "end": 751.28, "text": " of experiments and eventually you sort of, like, get the ingredients together and you", "tokens": [50566, 295, 12050, 293, 4728, 291, 1333, 295, 11, 411, 11, 483, 264, 6952, 1214, 293, 291, 50794], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 204, "seek": 74268, "start": 751.28, "end": 752.28, "text": " build something.", "tokens": [50794, 1322, 746, 13, 50844], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 205, "seek": 74268, "start": 752.28, "end": 754.88, "text": " Yeah, that's the first principle is thinking in action.", "tokens": [50844, 865, 11, 300, 311, 264, 700, 8665, 307, 1953, 294, 3069, 13, 50974], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 206, "seek": 74268, "start": 754.88, "end": 755.88, "text": " Yeah.", "tokens": [50974, 865, 13, 51024], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 207, "seek": 74268, "start": 755.88, "end": 760.0, "text": " You know, I think that the story of AI, I don't know if you think about this at all, but I", "tokens": [51024, 509, 458, 11, 286, 519, 300, 264, 1657, 295, 7318, 11, 286, 500, 380, 458, 498, 291, 519, 466, 341, 412, 439, 11, 457, 286, 51230], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 208, "seek": 74268, "start": 760.0, "end": 764.3199999999999, "text": " think about this a little bit, I think the story of AI to date and especially the past", "tokens": [51230, 519, 466, 341, 257, 707, 857, 11, 286, 519, 264, 1657, 295, 7318, 281, 4002, 293, 2318, 264, 1791, 51446], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 209, "seek": 74268, "start": 764.3199999999999, "end": 768.52, "text": " few years and the story of open AI is probably going to be something that historians are", "tokens": [51446, 1326, 924, 293, 264, 1657, 295, 1269, 7318, 307, 1391, 516, 281, 312, 746, 300, 26442, 366, 51656], "temperature": 0.0, "avg_logprob": -0.16478479825533354, "compression_ratio": 1.870503597122302, "no_speech_prob": 0.00010226283484371379}, {"id": 210, "seek": 76852, "start": 768.52, "end": 772.84, "text": " going to study for, you know, decades and decades to come.", "tokens": [50364, 516, 281, 2979, 337, 11, 291, 458, 11, 7878, 293, 7878, 281, 808, 13, 50580], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 211, "seek": 76852, "start": 772.84, "end": 777.84, "text": " Are there any fun stories from the journey of creating some of these foundation models", "tokens": [50580, 2014, 456, 604, 1019, 3676, 490, 264, 4671, 295, 4084, 512, 295, 613, 7030, 5245, 50830], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 212, "seek": 76852, "start": 777.84, "end": 780.92, "text": " that you think deserve to be in the history books?", "tokens": [50830, 300, 291, 519, 9948, 281, 312, 294, 264, 2503, 3642, 30, 50984], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 213, "seek": 76852, "start": 780.92, "end": 786.6, "text": " Well, I'll tell you my actual favorite story from the Dota days.", "tokens": [50984, 1042, 11, 286, 603, 980, 291, 452, 3539, 2954, 1657, 490, 264, 413, 5377, 1708, 13, 51268], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 214, "seek": 76852, "start": 786.6, "end": 791.4, "text": " So, you know, we've been working on this system and, you know, actually the funny thing is", "tokens": [51268, 407, 11, 291, 458, 11, 321, 600, 668, 1364, 322, 341, 1185, 293, 11, 291, 458, 11, 767, 264, 4074, 551, 307, 51508], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 215, "seek": 76852, "start": 791.4, "end": 794.36, "text": " at the very beginning we wrote down our list of milestones.", "tokens": [51508, 412, 264, 588, 2863, 321, 4114, 760, 527, 1329, 295, 42038, 13, 51656], "temperature": 0.0, "avg_logprob": -0.15277849710904634, "compression_ratio": 1.6546184738955823, "no_speech_prob": 0.0004876377934124321}, {"id": 216, "seek": 79436, "start": 794.36, "end": 800.2, "text": " On this date we're going to be Jonas, our best open AI employee who also had many thousands", "tokens": [50364, 1282, 341, 4002, 321, 434, 516, 281, 312, 34630, 11, 527, 1151, 1269, 7318, 10738, 567, 611, 632, 867, 5383, 50656], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 217, "seek": 79436, "start": 800.2, "end": 802.72, "text": " of hours of Dota 2 gameplay.", "tokens": [50656, 295, 2496, 295, 413, 5377, 568, 11421, 13, 50782], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 218, "seek": 79436, "start": 802.72, "end": 805.24, "text": " This date we're going to beat the semi-pros, you know, this date we're going to beat the", "tokens": [50782, 639, 4002, 321, 434, 516, 281, 4224, 264, 12909, 12, 1424, 329, 11, 291, 458, 11, 341, 4002, 321, 434, 516, 281, 4224, 264, 50908], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 219, "seek": 79436, "start": 805.24, "end": 809.72, "text": " pros and so it's supposed to be like June 6th or something, June 6th rolls around, we", "tokens": [50908, 6267, 293, 370, 309, 311, 3442, 281, 312, 411, 6928, 1386, 392, 420, 746, 11, 6928, 1386, 392, 15767, 926, 11, 321, 51132], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 220, "seek": 79436, "start": 809.72, "end": 810.72, "text": " don't have anything.", "tokens": [51132, 500, 380, 362, 1340, 13, 51182], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 221, "seek": 79436, "start": 810.72, "end": 814.48, "text": " Like, you know, he just crushes us and two weeks go by, three weeks go by, we keep pushing", "tokens": [51182, 1743, 11, 291, 458, 11, 415, 445, 10321, 279, 505, 293, 732, 3259, 352, 538, 11, 1045, 3259, 352, 538, 11, 321, 1066, 7380, 51370], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 222, "seek": 79436, "start": 814.48, "end": 819.08, "text": " back that deadline by a week every week and then one day we actually do beat him.", "tokens": [51370, 646, 300, 20615, 538, 257, 1243, 633, 1243, 293, 550, 472, 786, 321, 767, 360, 4224, 796, 13, 51600], "temperature": 0.0, "avg_logprob": -0.19996175278712364, "compression_ratio": 1.778181818181818, "no_speech_prob": 0.0420556515455246}, {"id": 223, "seek": 81908, "start": 819.08, "end": 824.0400000000001, "text": " And you know, I think my conclusion was that like it wasn't actually actionable to sort", "tokens": [50364, 400, 291, 458, 11, 286, 519, 452, 10063, 390, 300, 411, 309, 2067, 380, 767, 45098, 281, 1333, 50612], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 224, "seek": 81908, "start": 824.0400000000001, "end": 828.72, "text": " of set those goals of outputs, you can only control your inputs, you can control the experiments", "tokens": [50612, 295, 992, 729, 5493, 295, 23930, 11, 291, 393, 787, 1969, 428, 15743, 11, 291, 393, 1969, 264, 12050, 50846], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 225, "seek": 81908, "start": 828.72, "end": 829.72, "text": " you run.", "tokens": [50846, 291, 1190, 13, 50896], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 226, "seek": 81908, "start": 829.72, "end": 833.6800000000001, "text": " And so we just managed the project very differently after that and the thing that was so crazy", "tokens": [50896, 400, 370, 321, 445, 6453, 264, 1716, 588, 7614, 934, 300, 293, 264, 551, 300, 390, 370, 3219, 51094], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 227, "seek": 81908, "start": 833.6800000000001, "end": 838.1600000000001, "text": " to me still is that, you know, so a week before the international, which is the like world", "tokens": [51094, 281, 385, 920, 307, 300, 11, 291, 458, 11, 370, 257, 1243, 949, 264, 5058, 11, 597, 307, 264, 411, 1002, 51318], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 228, "seek": 81908, "start": 838.1600000000001, "end": 841.0, "text": " championships we're going to show up, we're going to play 1v1 against the best players", "tokens": [51318, 41433, 321, 434, 516, 281, 855, 493, 11, 321, 434, 516, 281, 862, 502, 85, 16, 1970, 264, 1151, 4150, 51460], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 229, "seek": 81908, "start": 841.0, "end": 845.12, "text": " in the world, we finally started beating our semi-protester and we're like, okay, maybe", "tokens": [51460, 294, 264, 1002, 11, 321, 2721, 1409, 13497, 527, 12909, 12, 33629, 3011, 293, 321, 434, 411, 11, 1392, 11, 1310, 51666], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 230, "seek": 81908, "start": 845.12, "end": 847.24, "text": " this is actually going to happen.", "tokens": [51666, 341, 307, 767, 516, 281, 1051, 13, 51772], "temperature": 0.0, "avg_logprob": -0.17905665430529363, "compression_ratio": 1.798165137614679, "no_speech_prob": 0.030180633068084717}, {"id": 231, "seek": 84724, "start": 847.24, "end": 850.36, "text": " But then we learned that he actually was on like vacation, he didn't have his like real", "tokens": [50364, 583, 550, 321, 3264, 300, 415, 767, 390, 322, 411, 12830, 11, 415, 994, 380, 362, 702, 411, 957, 50520], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 232, "seek": 84724, "start": 850.36, "end": 854.36, "text": " setup and so we're like, oh no, like this is not going to go well.", "tokens": [50520, 8657, 293, 370, 321, 434, 411, 11, 1954, 572, 11, 411, 341, 307, 406, 516, 281, 352, 731, 13, 50720], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 233, "seek": 84724, "start": 854.36, "end": 857.96, "text": " So we show up, you know, we continue to train, we like kind of do like a Hail Mary of like", "tokens": [50720, 407, 321, 855, 493, 11, 291, 458, 11, 321, 2354, 281, 3847, 11, 321, 411, 733, 295, 360, 411, 257, 32495, 6059, 295, 411, 50900], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 234, "seek": 84724, "start": 857.96, "end": 863.24, "text": " scaling things up, biggest scale we've ever done and we show up at the international and", "tokens": [50900, 21589, 721, 493, 11, 3880, 4373, 321, 600, 1562, 1096, 293, 321, 855, 493, 412, 264, 5058, 293, 51164], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 235, "seek": 84724, "start": 863.24, "end": 868.64, "text": " we play against, you know, like sort of low lowest, you know, low ranked pro, like a previous", "tokens": [51164, 321, 862, 1970, 11, 291, 458, 11, 411, 1333, 295, 2295, 12437, 11, 291, 458, 11, 2295, 20197, 447, 11, 411, 257, 3894, 51434], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 236, "seek": 84724, "start": 868.64, "end": 873.6, "text": " pro and we go 3-0-3-0-2-1.", "tokens": [51434, 447, 293, 321, 352, 805, 12, 15, 12, 18, 12, 15, 12, 17, 12, 16, 13, 51682], "temperature": 0.0, "avg_logprob": -0.18141950162729822, "compression_ratio": 1.7366412213740459, "no_speech_prob": 0.004466385114938021}, {"id": 237, "seek": 87360, "start": 873.6, "end": 877.96, "text": " So we basically win-win and then we did have one loss and we take a look at it and it's", "tokens": [50364, 407, 321, 1936, 1942, 12, 9136, 293, 550, 321, 630, 362, 472, 4470, 293, 321, 747, 257, 574, 412, 309, 293, 309, 311, 50582], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 238, "seek": 87360, "start": 877.96, "end": 881.36, "text": " like this item that we've never trained with, we've never seen before, oh wow, okay, we", "tokens": [50582, 411, 341, 3174, 300, 321, 600, 1128, 8895, 365, 11, 321, 600, 1128, 1612, 949, 11, 1954, 6076, 11, 1392, 11, 321, 50752], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 239, "seek": 87360, "start": 881.36, "end": 884.2, "text": " need to add that and, you know, do it fast.", "tokens": [50752, 643, 281, 909, 300, 293, 11, 291, 458, 11, 360, 309, 2370, 13, 50894], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 240, "seek": 87360, "start": 884.2, "end": 887.48, "text": " And so the team stays up all night putting this thing into the training, getting the", "tokens": [50894, 400, 370, 264, 1469, 10834, 493, 439, 1818, 3372, 341, 551, 666, 264, 3097, 11, 1242, 264, 51058], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 241, "seek": 87360, "start": 887.48, "end": 891.52, "text": " whole thing launched and, you know, again, like we did double the scale where we're basically", "tokens": [51058, 1379, 551, 8730, 293, 11, 291, 458, 11, 797, 11, 411, 321, 630, 3834, 264, 4373, 689, 321, 434, 1936, 51260], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 242, "seek": 87360, "start": 891.52, "end": 897.88, "text": " maxing out our CPU cores at this point and start training and, you know, we're supposed", "tokens": [51260, 11469, 278, 484, 527, 13199, 24826, 412, 341, 935, 293, 722, 3097, 293, 11, 291, 458, 11, 321, 434, 3442, 51578], "temperature": 0.0, "avg_logprob": -0.1748141651005708, "compression_ratio": 1.7933579335793357, "no_speech_prob": 0.06367814540863037}, {"id": 243, "seek": 89788, "start": 897.88, "end": 903.64, "text": " to play against the top pros in the world, fortunately they can't do the next day so", "tokens": [50364, 281, 862, 1970, 264, 1192, 6267, 294, 264, 1002, 11, 25511, 436, 393, 380, 360, 264, 958, 786, 370, 50652], "temperature": 0.0, "avg_logprob": -0.20671914753160978, "compression_ratio": 1.763819095477387, "no_speech_prob": 0.4297987222671509}, {"id": 244, "seek": 89788, "start": 903.64, "end": 909.32, "text": " we get an additional day of training and the number two person comes in, he plays against", "tokens": [50652, 321, 483, 364, 4497, 786, 295, 3097, 293, 264, 1230, 732, 954, 1487, 294, 11, 415, 5749, 1970, 50936], "temperature": 0.0, "avg_logprob": -0.20671914753160978, "compression_ratio": 1.763819095477387, "no_speech_prob": 0.4297987222671509}, {"id": 245, "seek": 89788, "start": 909.32, "end": 917.04, "text": " us and we win-win-win-win-win and he's like, okay, but I beat this but the top player is", "tokens": [50936, 505, 293, 321, 1942, 12, 9136, 12, 9136, 12, 9136, 12, 9136, 293, 415, 311, 411, 11, 1392, 11, 457, 286, 4224, 341, 457, 264, 1192, 4256, 307, 51322], "temperature": 0.0, "avg_logprob": -0.20671914753160978, "compression_ratio": 1.763819095477387, "no_speech_prob": 0.4297987222671509}, {"id": 246, "seek": 89788, "start": 917.04, "end": 921.2, "text": " never going to lose to this thing or sorry, yeah, the top player is going to crash this", "tokens": [51322, 1128, 516, 281, 3624, 281, 341, 551, 420, 2597, 11, 1338, 11, 264, 1192, 4256, 307, 516, 281, 8252, 341, 51530], "temperature": 0.0, "avg_logprob": -0.20671914753160978, "compression_ratio": 1.763819095477387, "no_speech_prob": 0.4297987222671509}, {"id": 247, "seek": 92120, "start": 921.2800000000001, "end": 927.8000000000001, "text": " thing and fortunately because he had spent so long playing that that guy couldn't come", "tokens": [50368, 551, 293, 25511, 570, 415, 632, 4418, 370, 938, 2433, 300, 300, 2146, 2809, 380, 808, 50694], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 248, "seek": 92120, "start": 927.8000000000001, "end": 931.72, "text": " that day so we got one more day of training and that one more day of training was enough", "tokens": [50694, 300, 786, 370, 321, 658, 472, 544, 786, 295, 3097, 293, 300, 472, 544, 786, 295, 3097, 390, 1547, 50890], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 249, "seek": 92120, "start": 931.72, "end": 935.44, "text": " and so I think it's just the story of like you can really see the improvement and at", "tokens": [50890, 293, 370, 286, 519, 309, 311, 445, 264, 1657, 295, 411, 291, 393, 534, 536, 264, 10444, 293, 412, 51076], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 250, "seek": 92120, "start": 935.44, "end": 940.36, "text": " each step we could see new behaviors that the system have learned and I think that that", "tokens": [51076, 1184, 1823, 321, 727, 536, 777, 15501, 300, 264, 1185, 362, 3264, 293, 286, 519, 300, 300, 51322], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 251, "seek": 92120, "start": 940.36, "end": 943.6400000000001, "text": " experience of just sort of watching a girl up in front of you is just something that", "tokens": [51322, 1752, 295, 445, 1333, 295, 1976, 257, 2013, 493, 294, 1868, 295, 291, 307, 445, 746, 300, 51486], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 252, "seek": 92120, "start": 943.6400000000001, "end": 945.1400000000001, "text": " was really amazing.", "tokens": [51486, 390, 534, 2243, 13, 51561], "temperature": 0.0, "avg_logprob": -0.17485332489013672, "compression_ratio": 1.834008097165992, "no_speech_prob": 0.5384463667869568}, {"id": 253, "seek": 94514, "start": 945.14, "end": 950.74, "text": " I'm actually surprised because you would, I sensibly you'd probably train the sort", "tokens": [50364, 286, 478, 767, 6100, 570, 291, 576, 11, 286, 2923, 3545, 291, 1116, 1391, 3847, 264, 1333, 50644], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 254, "seek": 94514, "start": 950.74, "end": 954.66, "text": " of like agents for a long, long, long time going into the international and surprised", "tokens": [50644, 295, 411, 12554, 337, 257, 938, 11, 938, 11, 938, 565, 516, 666, 264, 5058, 293, 6100, 50840], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 255, "seek": 94514, "start": 954.66, "end": 955.9, "text": " at each incremental day.", "tokens": [50840, 412, 1184, 35759, 786, 13, 50902], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 256, "seek": 94514, "start": 955.9, "end": 959.3, "text": " Yeah, so this is something I think has changed over time so at the time we basically had", "tokens": [50902, 865, 11, 370, 341, 307, 746, 286, 519, 575, 3105, 670, 565, 370, 412, 264, 565, 321, 1936, 632, 51072], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 257, "seek": 94514, "start": 959.3, "end": 962.6999999999999, "text": " two weeks worth of training was like the whole model run and so you'd start from scratch", "tokens": [51072, 732, 3259, 3163, 295, 3097, 390, 411, 264, 1379, 2316, 1190, 293, 370, 291, 1116, 722, 490, 8459, 51242], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 258, "seek": 94514, "start": 962.6999999999999, "end": 967.86, "text": " each time and the thing that was really funny in the middle was that, you know, we put in", "tokens": [51242, 1184, 565, 293, 264, 551, 300, 390, 534, 4074, 294, 264, 2808, 390, 300, 11, 291, 458, 11, 321, 829, 294, 51500], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 259, "seek": 94514, "start": 967.86, "end": 971.42, "text": " this new item, we were training it and when we took out of training it was the best spot", "tokens": [51500, 341, 777, 3174, 11, 321, 645, 3097, 309, 293, 562, 321, 1890, 484, 295, 3097, 309, 390, 264, 1151, 4008, 51678], "temperature": 0.0, "avg_logprob": -0.19977401790762306, "compression_ratio": 1.7973856209150327, "no_speech_prob": 0.002799159148707986}, {"id": 260, "seek": 97142, "start": 971.42, "end": 976.66, "text": " we ever saw except that our semi-protester was looking at it and was like this bot is", "tokens": [50364, 321, 1562, 1866, 3993, 300, 527, 12909, 12, 33629, 3011, 390, 1237, 412, 309, 293, 390, 411, 341, 10592, 307, 50626], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 261, "seek": 97142, "start": 976.66, "end": 979.6999999999999, "text": " doing something really dumb, it's just sitting there in the first wave and taking all this", "tokens": [50626, 884, 746, 534, 10316, 11, 309, 311, 445, 3798, 456, 294, 264, 700, 5772, 293, 1940, 439, 341, 50778], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 262, "seek": 97142, "start": 979.6999999999999, "end": 983.06, "text": " damage it doesn't have to, I'm going to go beat it, he ran it and go fight it and he", "tokens": [50778, 4344, 309, 1177, 380, 362, 281, 11, 286, 478, 516, 281, 352, 4224, 309, 11, 415, 5872, 309, 293, 352, 2092, 309, 293, 415, 50946], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 263, "seek": 97142, "start": 983.06, "end": 984.06, "text": " lost.", "tokens": [50946, 2731, 13, 50996], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 264, "seek": 97142, "start": 984.06, "end": 987.66, "text": " It's like that was weird and he did it like five more times and he lost each time but", "tokens": [50996, 467, 311, 411, 300, 390, 3657, 293, 415, 630, 309, 411, 1732, 544, 1413, 293, 415, 2731, 1184, 565, 457, 51176], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 265, "seek": 97142, "start": 987.66, "end": 990.66, "text": " then he figured out a strategy that actually does work which is you, you realize what was", "tokens": [51176, 550, 415, 8932, 484, 257, 5206, 300, 767, 775, 589, 597, 307, 291, 11, 291, 4325, 437, 390, 51326], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 266, "seek": 97142, "start": 990.66, "end": 994.4599999999999, "text": " going on was it was baiting him, it had learned to deceive, you know it actually learned that", "tokens": [51326, 516, 322, 390, 309, 390, 16865, 278, 796, 11, 309, 632, 3264, 281, 43440, 11, 291, 458, 309, 767, 3264, 300, 51516], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 267, "seek": 97142, "start": 994.4599999999999, "end": 997.5799999999999, "text": " what you do is that like you pretend oh I'm just a weak little bot, I don't know what", "tokens": [51516, 437, 291, 360, 307, 300, 411, 291, 11865, 1954, 286, 478, 445, 257, 5336, 707, 10592, 11, 286, 500, 380, 458, 437, 51672], "temperature": 0.0, "avg_logprob": -0.211692224982326, "compression_ratio": 1.8765060240963856, "no_speech_prob": 0.11271467804908752}, {"id": 268, "seek": 99758, "start": 997.58, "end": 1002.26, "text": " I'm doing and then you know a person comes in and you're just like smack.", "tokens": [50364, 286, 478, 884, 293, 550, 291, 458, 257, 954, 1487, 294, 293, 291, 434, 445, 411, 36348, 13, 50598], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 269, "seek": 99758, "start": 1002.26, "end": 1006.6600000000001, "text": " And so the way you defeat that is that you actually, you don't fall for the bait, right,", "tokens": [50598, 400, 370, 264, 636, 291, 11785, 300, 307, 300, 291, 767, 11, 291, 500, 380, 2100, 337, 264, 16865, 11, 558, 11, 50818], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 270, "seek": 99758, "start": 1006.6600000000001, "end": 1010.38, "text": " you let the bot take all this damage and sit there and get weaker and then you finally", "tokens": [50818, 291, 718, 264, 10592, 747, 439, 341, 4344, 293, 1394, 456, 293, 483, 24286, 293, 550, 291, 2721, 51004], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 271, "seek": 99758, "start": 1010.38, "end": 1015.58, "text": " go in for the kill and so there we actually stitched together our good bot for the first", "tokens": [51004, 352, 294, 337, 264, 1961, 293, 370, 456, 321, 767, 48992, 1214, 527, 665, 10592, 337, 264, 700, 51264], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 272, "seek": 99758, "start": 1015.58, "end": 1019.6600000000001, "text": " wave with the deceived bot thereafter and so there was a lot of this sort of like really", "tokens": [51264, 5772, 365, 264, 41304, 10592, 38729, 293, 370, 456, 390, 257, 688, 295, 341, 1333, 295, 411, 534, 51468], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 273, "seek": 99758, "start": 1019.6600000000001, "end": 1024.46, "text": " examining what was going on in the systems because it's such a limited domain, you know", "tokens": [51468, 34662, 437, 390, 516, 322, 294, 264, 3652, 570, 309, 311, 1270, 257, 5567, 9274, 11, 291, 458, 51708], "temperature": 0.0, "avg_logprob": -0.14185870639861575, "compression_ratio": 1.8392857142857142, "no_speech_prob": 0.020956270396709442}, {"id": 274, "seek": 102446, "start": 1024.46, "end": 1027.8600000000001, "text": " it's a complicated domain but it's very, very interpretable.", "tokens": [50364, 309, 311, 257, 6179, 9274, 457, 309, 311, 588, 11, 588, 7302, 712, 13, 50534], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 275, "seek": 102446, "start": 1027.8600000000001, "end": 1031.18, "text": " It meant that we could observe behaviors like this and figure out how to engineer around", "tokens": [50534, 467, 4140, 300, 321, 727, 11441, 15501, 411, 341, 293, 2573, 484, 577, 281, 11403, 926, 50700], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 276, "seek": 102446, "start": 1031.18, "end": 1036.38, "text": " them but once we graduated from the 1v1 version of the game to the full 5v5 you know much", "tokens": [50700, 552, 457, 1564, 321, 13693, 490, 264, 502, 85, 16, 3037, 295, 264, 1216, 281, 264, 1577, 1025, 85, 20, 291, 458, 709, 50960], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 277, "seek": 102446, "start": 1036.38, "end": 1041.66, "text": " more like you know like competitive basketball or something rather than heads up, suddenly", "tokens": [50960, 544, 411, 291, 458, 411, 10043, 11767, 420, 746, 2831, 813, 8050, 493, 11, 5800, 51224], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 278, "seek": 102446, "start": 1041.66, "end": 1046.26, "text": " all of our analysis of the behavior stopped working, right, that we used to have someone", "tokens": [51224, 439, 295, 527, 5215, 295, 264, 5223, 5936, 1364, 11, 558, 11, 300, 321, 1143, 281, 362, 1580, 51454], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 279, "seek": 102446, "start": 1046.26, "end": 1049.5, "text": " who just literally would watch the bot play and be like oh we have this bug in the training", "tokens": [51454, 567, 445, 3736, 576, 1159, 264, 10592, 862, 293, 312, 411, 1954, 321, 362, 341, 7426, 294, 264, 3097, 51616], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 280, "seek": 102446, "start": 1049.5, "end": 1053.26, "text": " we got to go fix that, for 5v5 we just could not do that and I think that's kind of where", "tokens": [51616, 321, 658, 281, 352, 3191, 300, 11, 337, 1025, 85, 20, 321, 445, 727, 406, 360, 300, 293, 286, 519, 300, 311, 733, 295, 689, 51804], "temperature": 0.0, "avg_logprob": -0.18134387551921688, "compression_ratio": 1.7319884726224783, "no_speech_prob": 0.004069450777024031}, {"id": 281, "seek": 105326, "start": 1053.26, "end": 1057.82, "text": " we've graduated as a field is that too when you look at GPT-3 and the mistakes it makes", "tokens": [50364, 321, 600, 13693, 382, 257, 2519, 307, 300, 886, 562, 291, 574, 412, 26039, 51, 12, 18, 293, 264, 8038, 309, 1669, 50592], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 282, "seek": 105326, "start": 1057.82, "end": 1062.06, "text": " sometimes people ask well why didn't it make that mistake and sometimes you can interpret", "tokens": [50592, 2171, 561, 1029, 731, 983, 994, 380, 309, 652, 300, 6146, 293, 2171, 291, 393, 7302, 50804], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 283, "seek": 105326, "start": 1062.06, "end": 1065.94, "text": " it but sometimes it's also a little bit like asking well you know why did you make a mistake", "tokens": [50804, 309, 457, 2171, 309, 311, 611, 257, 707, 857, 411, 3365, 731, 291, 458, 983, 630, 291, 652, 257, 6146, 50998], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 284, "seek": 105326, "start": 1065.94, "end": 1069.54, "text": " on some tests it's like well you think you know but like your explanation isn't always", "tokens": [50998, 322, 512, 6921, 309, 311, 411, 731, 291, 519, 291, 458, 457, 411, 428, 10835, 1943, 380, 1009, 51178], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 285, "seek": 105326, "start": 1069.54, "end": 1073.58, "text": " very good and I think that to do complicated behaviors sometimes there's a very complicated", "tokens": [51178, 588, 665, 293, 286, 519, 300, 281, 360, 6179, 15501, 2171, 456, 311, 257, 588, 6179, 51380], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 286, "seek": 105326, "start": 1073.58, "end": 1074.58, "text": " explanation.", "tokens": [51380, 10835, 13, 51430], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 287, "seek": 105326, "start": 1074.58, "end": 1075.58, "text": " Yeah.", "tokens": [51430, 865, 13, 51480], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 288, "seek": 105326, "start": 1075.58, "end": 1080.26, "text": " Have you read this short story I think it's like the Lifecycle of Software Objects by", "tokens": [51480, 3560, 291, 1401, 341, 2099, 1657, 286, 519, 309, 311, 411, 264, 7720, 14796, 295, 27428, 24753, 82, 538, 51714], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 289, "seek": 105326, "start": 1080.26, "end": 1081.26, "text": " Ted Chang?", "tokens": [51714, 14985, 17179, 30, 51764], "temperature": 0.0, "avg_logprob": -0.18792256065036939, "compression_ratio": 1.8403908794788273, "no_speech_prob": 0.006487320642918348}, {"id": 290, "seek": 108126, "start": 1081.26, "end": 1083.26, "text": " I think I have but I don't recall the details.", "tokens": [50364, 286, 519, 286, 362, 457, 286, 500, 380, 9901, 264, 4365, 13, 50464], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 291, "seek": 108126, "start": 1083.26, "end": 1086.42, "text": " It's like it's about how they're these AI pets and they sort of like keep learning new", "tokens": [50464, 467, 311, 411, 309, 311, 466, 577, 436, 434, 613, 7318, 19897, 293, 436, 1333, 295, 411, 1066, 2539, 777, 50622], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 292, "seek": 108126, "start": 1086.42, "end": 1090.62, "text": " and new behaviors it's very reminiscent of describing these Dota agents.", "tokens": [50622, 293, 777, 15501, 309, 311, 588, 44304, 295, 16141, 613, 413, 5377, 12554, 13, 50832], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 293, "seek": 108126, "start": 1090.62, "end": 1095.18, "text": " Yeah yeah I think we'll see that kind of thing in our future somewhere.", "tokens": [50832, 865, 1338, 286, 519, 321, 603, 536, 300, 733, 295, 551, 294, 527, 2027, 4079, 13, 51060], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 294, "seek": 108126, "start": 1095.18, "end": 1099.26, "text": " I want to kind of go back you know one of the things we've known each other for many", "tokens": [51060, 286, 528, 281, 733, 295, 352, 646, 291, 458, 472, 295, 264, 721, 321, 600, 2570, 1184, 661, 337, 867, 51264], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 295, "seek": 108126, "start": 1099.26, "end": 1106.3799999999999, "text": " years long before you know these foundation models and even before this competition Dota", "tokens": [51264, 924, 938, 949, 291, 458, 613, 7030, 5245, 293, 754, 949, 341, 6211, 413, 5377, 51620], "temperature": 0.0, "avg_logprob": -0.3024496473707594, "compression_ratio": 1.7186311787072244, "no_speech_prob": 0.003706142771989107}, {"id": 296, "seek": 110638, "start": 1106.38, "end": 1113.94, "text": " 2 and one thing I vividly remember is how sort of optimistic and confident you were", "tokens": [50364, 568, 293, 472, 551, 286, 23603, 356, 1604, 307, 577, 1333, 295, 19397, 293, 6679, 291, 645, 50742], "temperature": 0.0, "avg_logprob": -0.15683179100354513, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.10075468569993973}, {"id": 297, "seek": 110638, "start": 1113.94, "end": 1119.3000000000002, "text": " in sort of this sort of path of increasing and increasing AI capability you know sort", "tokens": [50742, 294, 1333, 295, 341, 1333, 295, 3100, 295, 5662, 293, 5662, 7318, 13759, 291, 458, 1333, 51010], "temperature": 0.0, "avg_logprob": -0.15683179100354513, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.10075468569993973}, {"id": 298, "seek": 110638, "start": 1119.3000000000002, "end": 1124.5, "text": " of I remember the time as maybe 2016, 2017 it felt very striking because it was sort", "tokens": [51010, 295, 286, 1604, 264, 565, 382, 1310, 6549, 11, 6591, 309, 2762, 588, 18559, 570, 309, 390, 1333, 51270], "temperature": 0.0, "avg_logprob": -0.15683179100354513, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.10075468569993973}, {"id": 299, "seek": 110638, "start": 1124.5, "end": 1131.46, "text": " of like you know with these algorithms they're still pretty weak and you were always very", "tokens": [51270, 295, 411, 291, 458, 365, 613, 14642, 436, 434, 920, 1238, 5336, 293, 291, 645, 1009, 588, 51618], "temperature": 0.0, "avg_logprob": -0.15683179100354513, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.10075468569993973}, {"id": 300, "seek": 110638, "start": 1131.46, "end": 1134.94, "text": " confident like oh yeah they're just going to keep getting better and better and better", "tokens": [51618, 6679, 411, 1954, 1338, 436, 434, 445, 516, 281, 1066, 1242, 1101, 293, 1101, 293, 1101, 51792], "temperature": 0.0, "avg_logprob": -0.15683179100354513, "compression_ratio": 1.8109243697478992, "no_speech_prob": 0.10075468569993973}, {"id": 301, "seek": 113494, "start": 1134.94, "end": 1137.14, "text": " and you know you're very a lot of confidence in that.", "tokens": [50364, 293, 291, 458, 291, 434, 588, 257, 688, 295, 6687, 294, 300, 13, 50474], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 302, "seek": 113494, "start": 1137.14, "end": 1143.8600000000001, "text": " What were the things that back then gave you sort of the resolve or confidence in the", "tokens": [50474, 708, 645, 264, 721, 300, 646, 550, 2729, 291, 1333, 295, 264, 14151, 420, 6687, 294, 264, 50810], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 303, "seek": 113494, "start": 1143.8600000000001, "end": 1146.06, "text": " and the optimism in the technology?", "tokens": [50810, 293, 264, 31074, 294, 264, 2899, 30, 50920], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 304, "seek": 113494, "start": 1146.06, "end": 1153.54, "text": " Yeah I mean at some level you know to have that kind of belief and conviction and something", "tokens": [50920, 865, 286, 914, 412, 512, 1496, 291, 458, 281, 362, 300, 733, 295, 7107, 293, 24837, 293, 746, 51294], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 305, "seek": 113494, "start": 1153.54, "end": 1155.8600000000001, "text": " that hasn't happened yet it's a very intuitive thing.", "tokens": [51294, 300, 6132, 380, 2011, 1939, 309, 311, 257, 588, 21769, 551, 13, 51410], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 306, "seek": 113494, "start": 1155.8600000000001, "end": 1161.1000000000001, "text": " I mean I remember when I was in school and showed up excited about doing NLP research", "tokens": [51410, 286, 914, 286, 1604, 562, 286, 390, 294, 1395, 293, 4712, 493, 2919, 466, 884, 426, 45196, 2132, 51672], "temperature": 0.0, "avg_logprob": -0.17508013561518507, "compression_ratio": 1.6680327868852458, "no_speech_prob": 0.014493757858872414}, {"id": 307, "seek": 116110, "start": 1161.1, "end": 1164.62, "text": " I went and tracked down an NLP professor and I was like please can I do some research for", "tokens": [50364, 286, 1437, 293, 31703, 760, 364, 426, 45196, 8304, 293, 286, 390, 411, 1767, 393, 286, 360, 512, 2132, 337, 50540], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 308, "seek": 116110, "start": 1164.62, "end": 1169.3799999999999, "text": " you and he's like okay he shows me these like parsed trees and stuff and I look at that", "tokens": [50540, 291, 293, 415, 311, 411, 1392, 415, 3110, 385, 613, 411, 21156, 292, 5852, 293, 1507, 293, 286, 574, 412, 300, 50778], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 309, "seek": 116110, "start": 1169.3799999999999, "end": 1173.9399999999998, "text": " and I was like this is never going to work right and you know to explain like why does", "tokens": [50778, 293, 286, 390, 411, 341, 307, 1128, 516, 281, 589, 558, 293, 291, 458, 281, 2903, 411, 983, 775, 51006], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 310, "seek": 116110, "start": 1173.9399999999998, "end": 1176.6599999999999, "text": " it feel like it's not going to work it just doesn't have the right properties right it", "tokens": [51006, 309, 841, 411, 309, 311, 406, 516, 281, 589, 309, 445, 1177, 380, 362, 264, 558, 7221, 558, 309, 51142], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 311, "seek": 116110, "start": 1176.6599999999999, "end": 1181.4599999999998, "text": " just felt like you're going to pour all this human like engineering and intuition and effort", "tokens": [51142, 445, 2762, 411, 291, 434, 516, 281, 2016, 439, 341, 1952, 411, 7043, 293, 24002, 293, 4630, 51382], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 312, "seek": 116110, "start": 1181.4599999999998, "end": 1185.3, "text": " into the system and I know I can't even describe how language works.", "tokens": [51382, 666, 264, 1185, 293, 286, 458, 286, 393, 380, 754, 6786, 577, 2856, 1985, 13, 51574], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 313, "seek": 116110, "start": 1185.3, "end": 1186.3, "text": " Yep.", "tokens": [51574, 7010, 13, 51624], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 314, "seek": 116110, "start": 1186.3, "end": 1189.62, "text": " Right it just feels like there's just something inherently missing but I think neural nets", "tokens": [51624, 1779, 309, 445, 3417, 411, 456, 311, 445, 746, 27993, 5361, 457, 286, 519, 18161, 36170, 51790], "temperature": 0.0, "avg_logprob": -0.19144268425143496, "compression_ratio": 1.8680981595092025, "no_speech_prob": 0.10655438154935837}, {"id": 315, "seek": 118962, "start": 1189.62, "end": 1191.4199999999998, "text": " have the opposite property.", "tokens": [50364, 362, 264, 6182, 4707, 13, 50454], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 316, "seek": 118962, "start": 1191.4199999999998, "end": 1195.58, "text": " Neural nets is very clear this is a system that absorbs data it absorbs compute it's", "tokens": [50454, 1734, 1807, 36170, 307, 588, 1850, 341, 307, 257, 1185, 300, 40745, 1412, 309, 40745, 14722, 309, 311, 50662], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 317, "seek": 118962, "start": 1195.58, "end": 1200.06, "text": " like a sponge that just like slurps everything up and so it has the right form factor but", "tokens": [50662, 411, 257, 23134, 300, 445, 411, 1061, 374, 1878, 1203, 493, 293, 370, 309, 575, 264, 558, 1254, 5952, 457, 50886], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 318, "seek": 118962, "start": 1200.06, "end": 1203.3799999999999, "text": " the thing that's always been missing as well can you train it right?", "tokens": [50886, 264, 551, 300, 311, 1009, 668, 5361, 382, 731, 393, 291, 3847, 309, 558, 30, 51052], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 319, "seek": 118962, "start": 1203.3799999999999, "end": 1207.3, "text": " Do you have enough data do you have enough compute do you have enough ability to like", "tokens": [51052, 1144, 291, 362, 1547, 1412, 360, 291, 362, 1547, 14722, 360, 291, 362, 1547, 3485, 281, 411, 51248], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 320, "seek": 118962, "start": 1207.3, "end": 1210.4199999999998, "text": " have a learning algorithm that can shovel the stuff in efficiently in a way that it comes", "tokens": [51248, 362, 257, 2539, 9284, 300, 393, 29789, 264, 1507, 294, 19621, 294, 257, 636, 300, 309, 1487, 51404], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 321, "seek": 118962, "start": 1210.4199999999998, "end": 1214.3799999999999, "text": " out in some way that generalizes like that's the thing that's been missing and I think", "tokens": [51404, 484, 294, 512, 636, 300, 2674, 5660, 411, 300, 311, 264, 551, 300, 311, 668, 5361, 293, 286, 519, 51602], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 322, "seek": 118962, "start": 1214.3799999999999, "end": 1219.5, "text": " what became kind of clear you know the field really I think got its most recent resurgence", "tokens": [51602, 437, 3062, 733, 295, 1850, 291, 458, 264, 2519, 534, 286, 519, 658, 1080, 881, 5162, 725, 44607, 51858], "temperature": 0.0, "avg_logprob": -0.1608017382978582, "compression_ratio": 1.9290123456790123, "no_speech_prob": 0.001324408920481801}, {"id": 323, "seek": 121950, "start": 1219.58, "end": 1227.66, "text": " in 2012 with the Alex in that paper and I think that there that was the first time where", "tokens": [50368, 294, 9125, 365, 264, 5202, 294, 300, 3035, 293, 286, 519, 300, 456, 300, 390, 264, 700, 565, 689, 50772], "temperature": 0.0, "avg_logprob": -0.14304874938668558, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.00034592917654663324}, {"id": 324, "seek": 121950, "start": 1227.66, "end": 1231.82, "text": " you had a neural net that really just crushed a task right that it was like people had spent", "tokens": [50772, 291, 632, 257, 18161, 2533, 300, 534, 445, 19889, 257, 5633, 558, 300, 309, 390, 411, 561, 632, 4418, 50980], "temperature": 0.0, "avg_logprob": -0.14304874938668558, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.00034592917654663324}, {"id": 325, "seek": 121950, "start": 1231.82, "end": 1236.94, "text": " decades on computer vision and suddenly it's like well I'm so sorry but this approach has", "tokens": [50980, 7878, 322, 3820, 5201, 293, 5800, 309, 311, 411, 731, 286, 478, 370, 2597, 457, 341, 3109, 575, 51236], "temperature": 0.0, "avg_logprob": -0.14304874938668558, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.00034592917654663324}, {"id": 326, "seek": 121950, "start": 1236.94, "end": 1241.38, "text": " just supplanted you by this this massive gap and I think that you just started to see it", "tokens": [51236, 445, 9386, 15587, 291, 538, 341, 341, 5994, 7417, 293, 286, 519, 300, 291, 445, 1409, 281, 536, 309, 51458], "temperature": 0.0, "avg_logprob": -0.14304874938668558, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.00034592917654663324}, {"id": 327, "seek": 121950, "start": 1241.38, "end": 1246.14, "text": " spread right that it was almost like you had these these all these disparate departments", "tokens": [51458, 3974, 558, 300, 309, 390, 1920, 411, 291, 632, 613, 613, 439, 613, 14548, 473, 15326, 51696], "temperature": 0.0, "avg_logprob": -0.14304874938668558, "compression_ratio": 1.8032128514056225, "no_speech_prob": 0.00034592917654663324}, {"id": 328, "seek": 124614, "start": 1246.14, "end": 1251.46, "text": " and there was this wall that was being knocked down day after day and I think that when you", "tokens": [50364, 293, 456, 390, 341, 2929, 300, 390, 885, 16914, 760, 786, 934, 786, 293, 286, 519, 300, 562, 291, 50630], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 329, "seek": 124614, "start": 1251.46, "end": 1255.6200000000001, "text": " see a trend like that were things that have been long-standing and very deeply established", "tokens": [50630, 536, 257, 6028, 411, 300, 645, 721, 300, 362, 668, 938, 12, 8618, 293, 588, 8760, 7545, 50838], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 330, "seek": 124614, "start": 1255.6200000000001, "end": 1259.8200000000002, "text": " in these ways of thinking these great debates that have gone on for a long time and suddenly", "tokens": [50838, 294, 613, 2098, 295, 1953, 613, 869, 24203, 300, 362, 2780, 322, 337, 257, 938, 565, 293, 5800, 51048], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 331, "seek": 124614, "start": 1259.8200000000002, "end": 1265.38, "text": " you're seeing a repeated result that is consistent with the history I think that that for me", "tokens": [51048, 291, 434, 2577, 257, 10477, 1874, 300, 307, 8398, 365, 264, 2503, 286, 519, 300, 300, 337, 385, 51326], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 332, "seek": 124614, "start": 1265.38, "end": 1268.94, "text": " is maybe the most clear sign that it's like something is going to work and there's a real", "tokens": [51326, 307, 1310, 264, 881, 1850, 1465, 300, 309, 311, 411, 746, 307, 516, 281, 589, 293, 456, 311, 257, 957, 51504], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 333, "seek": 124614, "start": 1268.94, "end": 1272.0600000000002, "text": " sort of exponential that is waiting to unfold.", "tokens": [51504, 1333, 295, 21510, 300, 307, 3806, 281, 17980, 13, 51660], "temperature": 0.0, "avg_logprob": -0.12897285793138588, "compression_ratio": 1.8231046931407942, "no_speech_prob": 0.001700292807072401}, {"id": 334, "seek": 127206, "start": 1272.06, "end": 1277.94, "text": " And then you know were there what were the what were the moments if any of of doubt and", "tokens": [50364, 400, 550, 291, 458, 645, 456, 437, 645, 264, 437, 645, 264, 6065, 498, 604, 295, 295, 6385, 293, 50658], "temperature": 0.0, "avg_logprob": -0.22577984533577322, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.0021149131935089827}, {"id": 335, "seek": 127206, "start": 1277.94, "end": 1282.62, "text": " you know let's let's chart the path I think open I start in 2016 yeah yeah I'd say December", "tokens": [50658, 291, 458, 718, 311, 718, 311, 6927, 264, 3100, 286, 519, 1269, 286, 722, 294, 6549, 1338, 1338, 286, 1116, 584, 7687, 50892], "temperature": 0.0, "avg_logprob": -0.22577984533577322, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.0021149131935089827}, {"id": 336, "seek": 127206, "start": 1282.62, "end": 1288.62, "text": " 2015 you know 2016 okay great December 2015 till now were there any moments of of doubt", "tokens": [50892, 7546, 291, 458, 6549, 1392, 869, 7687, 7546, 4288, 586, 645, 456, 604, 6065, 295, 295, 6385, 51192], "temperature": 0.0, "avg_logprob": -0.22577984533577322, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.0021149131935089827}, {"id": 337, "seek": 127206, "start": 1288.62, "end": 1293.82, "text": " in the technology or was it sort of always hey this is you know this is clearly the way", "tokens": [51192, 294, 264, 2899, 420, 390, 309, 1333, 295, 1009, 4177, 341, 307, 291, 458, 341, 307, 4448, 264, 636, 51452], "temperature": 0.0, "avg_logprob": -0.22577984533577322, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.0021149131935089827}, {"id": 338, "seek": 127206, "start": 1293.82, "end": 1299.5, "text": " of the future yeah I mean I think that doubt is a strong word there's definitely moments", "tokens": [51452, 295, 264, 2027, 1338, 286, 914, 286, 519, 300, 6385, 307, 257, 2068, 1349, 456, 311, 2138, 6065, 51736], "temperature": 0.0, "avg_logprob": -0.22577984533577322, "compression_ratio": 1.905579399141631, "no_speech_prob": 0.0021149131935089827}, {"id": 339, "seek": 129950, "start": 1299.5, "end": 1304.1, "text": " like I think to build something you you're always doubting right that you're always like", "tokens": [50364, 411, 286, 519, 281, 1322, 746, 291, 291, 434, 1009, 10831, 783, 558, 300, 291, 434, 1009, 411, 50594], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 340, "seek": 129950, "start": 1304.1, "end": 1307.66, "text": " you've got to be questioning every single bit of your implementation like anytime you", "tokens": [50594, 291, 600, 658, 281, 312, 21257, 633, 2167, 857, 295, 428, 11420, 411, 13038, 291, 50772], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 341, "seek": 129950, "start": 1307.66, "end": 1311.14, "text": " see like a graph that's wiggling in a weird way you've got to go figure it out you can't", "tokens": [50772, 536, 411, 257, 4295, 300, 311, 261, 24542, 294, 257, 3657, 636, 291, 600, 658, 281, 352, 2573, 309, 484, 291, 393, 380, 50946], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 342, "seek": 129950, "start": 1311.14, "end": 1315.94, "text": " just be like I'm sure that the AI's will sort it out.", "tokens": [50946, 445, 312, 411, 286, 478, 988, 300, 264, 7318, 311, 486, 1333, 309, 484, 13, 51186], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 343, "seek": 129950, "start": 1315.94, "end": 1320.46, "text": " And so I think there was like lots of sort of tactical doubt lots of like sort of worries", "tokens": [51186, 400, 370, 286, 519, 456, 390, 411, 3195, 295, 1333, 295, 26323, 6385, 3195, 295, 411, 1333, 295, 16340, 51412], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 344, "seek": 129950, "start": 1320.46, "end": 1324.5, "text": " that were not quite doing it right lots of like redoing the calculations to figure out", "tokens": [51412, 300, 645, 406, 1596, 884, 309, 558, 3195, 295, 411, 29956, 278, 264, 20448, 281, 2573, 484, 51614], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 345, "seek": 129950, "start": 1324.5, "end": 1328.82, "text": " like hey how big of a model do you think you're going to need lots of mistakes for sure like", "tokens": [51614, 411, 4177, 577, 955, 295, 257, 2316, 360, 291, 519, 291, 434, 516, 281, 643, 3195, 295, 8038, 337, 988, 411, 51830], "temperature": 0.0, "avg_logprob": -0.14654372798071968, "compression_ratio": 1.9764309764309764, "no_speech_prob": 0.0007551820599474013}, {"id": 346, "seek": 132882, "start": 1328.82, "end": 1333.7, "text": " a good example of this is the scaling laws so we did this study to actually start to", "tokens": [50364, 257, 665, 1365, 295, 341, 307, 264, 21589, 6064, 370, 321, 630, 341, 2979, 281, 767, 722, 281, 50608], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 347, "seek": 132882, "start": 1333.7, "end": 1338.7, "text": " really scientifically understand how do models improve as you push on various axes so as", "tokens": [50608, 534, 39719, 1223, 577, 360, 5245, 3470, 382, 291, 2944, 322, 3683, 35387, 370, 382, 50858], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 348, "seek": 132882, "start": 1338.7, "end": 1342.9399999999998, "text": " you pour more computing as you pour more data in and one conclusion that we had at one point", "tokens": [50858, 291, 2016, 544, 15866, 382, 291, 2016, 544, 1412, 294, 293, 472, 10063, 300, 321, 632, 412, 472, 935, 51070], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 349, "seek": 132882, "start": 1342.9399999999998, "end": 1348.62, "text": " was that basically that there's you know sort of a limited amount of data that you want", "tokens": [51070, 390, 300, 1936, 300, 456, 311, 291, 458, 1333, 295, 257, 5567, 2372, 295, 1412, 300, 291, 528, 51354], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 350, "seek": 132882, "start": 1348.62, "end": 1352.5, "text": " to pour into these models and that there's kind of this very this very clear curve and", "tokens": [51354, 281, 2016, 666, 613, 5245, 293, 300, 456, 311, 733, 295, 341, 588, 341, 588, 1850, 7605, 293, 51548], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 351, "seek": 132882, "start": 1352.5, "end": 1356.7, "text": " that one thing that we realized only years later was actually that we'd read the curves", "tokens": [51548, 300, 472, 551, 300, 321, 5334, 787, 924, 1780, 390, 767, 300, 321, 1116, 1401, 264, 19490, 51758], "temperature": 0.0, "avg_logprob": -0.1500478952872653, "compression_ratio": 1.9236363636363636, "no_speech_prob": 0.00019711998174898326}, {"id": 352, "seek": 135670, "start": 1356.7, "end": 1361.1200000000001, "text": " a little bit wrong and you actually want to be trained for way more tokens way more data", "tokens": [50364, 257, 707, 857, 2085, 293, 291, 767, 528, 281, 312, 8895, 337, 636, 544, 22667, 636, 544, 1412, 50585], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 353, "seek": 135670, "start": 1361.1200000000001, "end": 1365.22, "text": " than anyone had expected and that did I you know that there's definitely these moments", "tokens": [50585, 813, 2878, 632, 5176, 293, 300, 630, 286, 291, 458, 300, 456, 311, 2138, 613, 6065, 50790], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 354, "seek": 135670, "start": 1365.22, "end": 1368.78, "text": " where these things that just didn't quite click where it's like just didn't add up that", "tokens": [50790, 689, 613, 721, 300, 445, 994, 380, 1596, 2052, 689, 309, 311, 411, 445, 994, 380, 909, 493, 300, 50968], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 355, "seek": 135670, "start": 1368.78, "end": 1372.74, "text": " we were training for so little and that you know something conclusions that you drew downstream", "tokens": [50968, 321, 645, 3097, 337, 370, 707, 293, 300, 291, 458, 746, 22865, 300, 291, 12804, 30621, 51166], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 356, "seek": 135670, "start": 1372.74, "end": 1377.06, "text": " but then you realize there was a foundational assumption that was wrong and suddenly things", "tokens": [51166, 457, 550, 291, 4325, 456, 390, 257, 32195, 15302, 300, 390, 2085, 293, 5800, 721, 51382], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 357, "seek": 135670, "start": 1377.06, "end": 1380.78, "text": " make way more sense so I think it's a little bit like you know physics in some sense for", "tokens": [51382, 652, 636, 544, 2020, 370, 286, 519, 309, 311, 257, 707, 857, 411, 291, 458, 10649, 294, 512, 2020, 337, 51568], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 358, "seek": 135670, "start": 1380.78, "end": 1384.6200000000001, "text": " like do you do doubt physics it's like I kind of do I think all physics is wrong right", "tokens": [51568, 411, 360, 291, 360, 6385, 10649, 309, 311, 411, 286, 733, 295, 360, 286, 519, 439, 10649, 307, 2085, 558, 51760], "temperature": 0.0, "avg_logprob": -0.18231438228062222, "compression_ratio": 2.042345276872964, "no_speech_prob": 0.0013246985618025064}, {"id": 359, "seek": 138462, "start": 1384.62, "end": 1388.7399999999998, "text": " but like only so wrong right it's like we clearly haven't reconciled like quantum and", "tokens": [50364, 457, 411, 787, 370, 2085, 558, 309, 311, 411, 321, 4448, 2378, 380, 9993, 3208, 292, 411, 13018, 293, 50570], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 360, "seek": 138462, "start": 1388.7399999999998, "end": 1392.62, "text": " relativity is that there's like something wrong there but that that wrongness is actually", "tokens": [50570, 45675, 307, 300, 456, 311, 411, 746, 2085, 456, 457, 300, 300, 2085, 1287, 307, 767, 50764], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 361, "seek": 138462, "start": 1392.62, "end": 1396.8999999999999, "text": " an opportunity it's actually a sign of you have this things are useful right really like", "tokens": [50764, 364, 2650, 309, 311, 767, 257, 1465, 295, 291, 362, 341, 721, 366, 4420, 558, 534, 411, 50978], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 362, "seek": 138462, "start": 1396.8999999999999, "end": 1400.06, "text": " it's affected our lives and it's actually like pretty great I'm very happy with what", "tokens": [50978, 309, 311, 8028, 527, 2909, 293, 309, 311, 767, 411, 1238, 869, 286, 478, 588, 2055, 365, 437, 51136], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 363, "seek": 138462, "start": 1400.06, "end": 1404.58, "text": " physics has done but also there's fruit and so I think that that for me that's always been", "tokens": [51136, 10649, 575, 1096, 457, 611, 456, 311, 6773, 293, 370, 286, 519, 300, 300, 337, 385, 300, 311, 1009, 668, 51362], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 364, "seek": 138462, "start": 1404.58, "end": 1409.62, "text": " the feeling that there's something here and that you know if we do keep pushing and somehow", "tokens": [51362, 264, 2633, 300, 456, 311, 746, 510, 293, 300, 291, 458, 498, 321, 360, 1066, 7380, 293, 6063, 51614], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 365, "seek": 138462, "start": 1409.62, "end": 1412.86, "text": " the scaling laws all peter out right and they suddenly drop off a cliff and we can't make", "tokens": [51614, 264, 21589, 6064, 439, 280, 2398, 484, 558, 293, 436, 5800, 3270, 766, 257, 22316, 293, 321, 393, 380, 652, 51776], "temperature": 0.0, "avg_logprob": -0.14803233411577013, "compression_ratio": 1.9138461538461538, "no_speech_prob": 0.00013133497850503772}, {"id": 366, "seek": 141286, "start": 1412.9399999999998, "end": 1417.1399999999999, "text": " any further progress like that would be the most exciting time in this field because we", "tokens": [50368, 604, 3052, 4205, 411, 300, 576, 312, 264, 881, 4670, 565, 294, 341, 2519, 570, 321, 50578], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 367, "seek": 141286, "start": 1417.1399999999999, "end": 1421.1799999999998, "text": " would finally reach the limit of technology we would finally learn something and then", "tokens": [50578, 576, 2721, 2524, 264, 4948, 295, 2899, 321, 576, 2721, 1466, 746, 293, 550, 50780], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 368, "seek": 141286, "start": 1421.1799999999998, "end": 1424.86, "text": " we would finally have a picture of what the next thing to do is yeah that's super it actually", "tokens": [50780, 321, 576, 2721, 362, 257, 3036, 295, 437, 264, 958, 551, 281, 360, 307, 1338, 300, 311, 1687, 309, 767, 50964], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 369, "seek": 141286, "start": 1424.86, "end": 1431.1, "text": " reminds me of this one of the stripe operating principles which is I think micro pessimists", "tokens": [50964, 12025, 385, 295, 341, 472, 295, 264, 42957, 7447, 9156, 597, 307, 286, 519, 4532, 37399, 1751, 51276], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 370, "seek": 141286, "start": 1431.1, "end": 1436.3799999999999, "text": " macro optimists yep yep yes and it's very I mean it's very resonant but obviously like", "tokens": [51276, 18887, 5028, 1751, 18633, 18633, 2086, 293, 309, 311, 588, 286, 914, 309, 311, 588, 12544, 394, 457, 2745, 411, 51540], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 371, "seek": 141286, "start": 1436.3799999999999, "end": 1441.9799999999998, "text": " very related to what you're talking about which is these you know you have to be extremely", "tokens": [51540, 588, 4077, 281, 437, 291, 434, 1417, 466, 597, 307, 613, 291, 458, 291, 362, 281, 312, 4664, 51820], "temperature": 0.0, "avg_logprob": -0.13772417917972854, "compression_ratio": 1.8645833333333333, "no_speech_prob": 0.002049211645498872}, {"id": 372, "seek": 144198, "start": 1441.98, "end": 1446.22, "text": " pessimistic we're extremely questioning in the moments of the technology but then obviously", "tokens": [50364, 37399, 3142, 321, 434, 4664, 21257, 294, 264, 6065, 295, 264, 2899, 457, 550, 2745, 50576], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 373, "seek": 144198, "start": 1446.22, "end": 1451.14, "text": " on a long enough time horizon incredible stuff pops out yep you got to be excited like I", "tokens": [50576, 322, 257, 938, 1547, 565, 18046, 4651, 1507, 16795, 484, 18633, 291, 658, 281, 312, 2919, 411, 286, 50822], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 374, "seek": 144198, "start": 1451.14, "end": 1455.82, "text": " think that this is just an exciting field and it's a scary field as well you got to have", "tokens": [50822, 519, 300, 341, 307, 445, 364, 4670, 2519, 293, 309, 311, 257, 6958, 2519, 382, 731, 291, 658, 281, 362, 51056], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 375, "seek": 144198, "start": 1455.82, "end": 1460.98, "text": " some amount of just like awe at the fact that you have these these models that they started", "tokens": [51056, 512, 2372, 295, 445, 411, 30912, 412, 264, 1186, 300, 291, 362, 613, 613, 5245, 300, 436, 1409, 51314], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 376, "seek": 144198, "start": 1460.98, "end": 1465.46, "text": " as just random numbers right and then you have build these massive supercomputers these massive", "tokens": [51314, 382, 445, 4974, 3547, 558, 293, 550, 291, 362, 1322, 613, 5994, 27839, 2582, 433, 613, 5994, 51538], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 377, "seek": 144198, "start": 1465.46, "end": 1470.5, "text": " data sets and you do a ton of the engineering work you do a ton of these algorithmic developments", "tokens": [51538, 1412, 6352, 293, 291, 360, 257, 2952, 295, 264, 7043, 589, 291, 360, 257, 2952, 295, 613, 9284, 299, 20862, 51790], "temperature": 0.0, "avg_logprob": -0.16464508556928792, "compression_ratio": 1.825657894736842, "no_speech_prob": 0.0002304241934325546}, {"id": 378, "seek": 147050, "start": 1470.58, "end": 1474.34, "text": " you put them all into a package right and we don't really have other technologies that", "tokens": [50368, 291, 829, 552, 439, 666, 257, 7372, 558, 293, 321, 500, 380, 534, 362, 661, 7943, 300, 50556], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 379, "seek": 147050, "start": 1474.34, "end": 1479.22, "text": " work like this like I think the fact to me the most fundamental picture this like sponge", "tokens": [50556, 589, 411, 341, 411, 286, 519, 264, 1186, 281, 385, 264, 881, 8088, 3036, 341, 411, 23134, 50800], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 380, "seek": 147050, "start": 1479.22, "end": 1483.26, "text": " that you just kind of pour stuff into and you get this model it's reusable and works", "tokens": [50800, 300, 291, 445, 733, 295, 2016, 1507, 666, 293, 291, 483, 341, 2316, 309, 311, 41807, 293, 1985, 51002], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 381, "seek": 147050, "start": 1483.26, "end": 1487.42, "text": " across all these different areas like you can't do that for traditional software right", "tokens": [51002, 2108, 439, 613, 819, 3179, 411, 291, 393, 380, 360, 300, 337, 5164, 4722, 558, 51210], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 382, "seek": 147050, "start": 1487.42, "end": 1491.38, "text": " traditional software is it's just you know human effort writing down all the rules and", "tokens": [51210, 5164, 4722, 307, 309, 311, 445, 291, 458, 1952, 4630, 3579, 760, 439, 264, 4474, 293, 51408], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 383, "seek": 147050, "start": 1491.38, "end": 1494.78, "text": " that's where the return comes from but you can't you know maybe you have like a spark", "tokens": [51408, 300, 311, 689, 264, 2736, 1487, 490, 457, 291, 393, 380, 291, 458, 1310, 291, 362, 411, 257, 9908, 51578], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 384, "seek": 147050, "start": 1494.78, "end": 1499.94, "text": " cluster that does some stuff but that's not that's not the cake and in in neural networks", "tokens": [51578, 13630, 300, 775, 512, 1507, 457, 300, 311, 406, 300, 311, 406, 264, 5908, 293, 294, 294, 18161, 9590, 51836], "temperature": 0.0, "avg_logprob": -0.09812258977959626, "compression_ratio": 1.9003115264797508, "no_speech_prob": 0.013216651976108551}, {"id": 385, "seek": 149994, "start": 1499.94, "end": 1504.9, "text": " it really is yeah you know I want to kind of switch gears to thinking about the the", "tokens": [50364, 309, 534, 307, 1338, 291, 458, 286, 528, 281, 733, 295, 3679, 20915, 281, 1953, 466, 264, 264, 50612], "temperature": 0.0, "avg_logprob": -0.13159793888756988, "compression_ratio": 1.9301310043668123, "no_speech_prob": 0.0001851671695476398}, {"id": 386, "seek": 149994, "start": 1504.9, "end": 1510.46, "text": " sort of future and and and looking forward at what kind of what's next what do you think", "tokens": [50612, 1333, 295, 2027, 293, 293, 293, 1237, 2128, 412, 437, 733, 295, 437, 311, 958, 437, 360, 291, 519, 50890], "temperature": 0.0, "avg_logprob": -0.13159793888756988, "compression_ratio": 1.9301310043668123, "no_speech_prob": 0.0001851671695476398}, {"id": 387, "seek": 149994, "start": 1510.46, "end": 1513.8, "text": " I mean I'll ask this sort of as broadly as possible to start with what do you think the", "tokens": [50890, 286, 914, 286, 603, 1029, 341, 1333, 295, 382, 19511, 382, 1944, 281, 722, 365, 437, 360, 291, 519, 264, 51057], "temperature": 0.0, "avg_logprob": -0.13159793888756988, "compression_ratio": 1.9301310043668123, "no_speech_prob": 0.0001851671695476398}, {"id": 388, "seek": 149994, "start": 1513.8, "end": 1522.3, "text": " future of AI holds yeah I think that the future of AI is going to again be both exciting and", "tokens": [51057, 2027, 295, 7318, 9190, 1338, 286, 519, 300, 264, 2027, 295, 7318, 307, 516, 281, 797, 312, 1293, 4670, 293, 51482], "temperature": 0.0, "avg_logprob": -0.13159793888756988, "compression_ratio": 1.9301310043668123, "no_speech_prob": 0.0001851671695476398}, {"id": 389, "seek": 149994, "start": 1522.3, "end": 1525.6200000000001, "text": " a source of a lot of change and I think that that is something that you know part of our", "tokens": [51482, 257, 4009, 295, 257, 688, 295, 1319, 293, 286, 519, 300, 300, 307, 746, 300, 291, 458, 644, 295, 527, 51648], "temperature": 0.0, "avg_logprob": -0.13159793888756988, "compression_ratio": 1.9301310043668123, "no_speech_prob": 0.0001851671695476398}, {"id": 390, "seek": 152562, "start": 1525.6399999999999, "end": 1531.1799999999998, "text": " mission is to try to help facilitate that as positive way as possible I think that kind", "tokens": [50365, 4447, 307, 281, 853, 281, 854, 20207, 300, 382, 3353, 636, 382, 1944, 286, 519, 300, 733, 50642], "temperature": 0.0, "avg_logprob": -0.1533111642908167, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.035117704421281815}, {"id": 391, "seek": 152562, "start": 1531.1799999999998, "end": 1536.6999999999998, "text": " of you know the super high level I kind of feel like AI was like you know something that", "tokens": [50642, 295, 291, 458, 264, 1687, 1090, 1496, 286, 733, 295, 841, 411, 7318, 390, 411, 291, 458, 746, 300, 50918], "temperature": 0.0, "avg_logprob": -0.1533111642908167, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.035117704421281815}, {"id": 392, "seek": 152562, "start": 1536.6999999999998, "end": 1540.62, "text": " for the you know 2020 10s was like kind of cool you know it's the game of like publishing", "tokens": [50918, 337, 264, 291, 458, 4808, 1266, 82, 390, 411, 733, 295, 1627, 291, 458, 309, 311, 264, 1216, 295, 411, 17832, 51114], "temperature": 0.0, "avg_logprob": -0.1533111642908167, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.035117704421281815}, {"id": 393, "seek": 152562, "start": 1540.62, "end": 1544.34, "text": " papers and you play some video games and like you know it's just like it's just like fun", "tokens": [51114, 10577, 293, 291, 862, 512, 960, 2813, 293, 411, 291, 458, 309, 311, 445, 411, 309, 311, 445, 411, 1019, 51300], "temperature": 0.0, "avg_logprob": -0.1533111642908167, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.035117704421281815}, {"id": 394, "seek": 152562, "start": 1544.34, "end": 1551.82, "text": " good science I think it's really interesting that 2020 kicked off with GPT 3 which is really", "tokens": [51300, 665, 3497, 286, 519, 309, 311, 534, 1880, 300, 4808, 14609, 766, 365, 26039, 51, 805, 597, 307, 534, 51674], "temperature": 0.0, "avg_logprob": -0.1533111642908167, "compression_ratio": 1.8512396694214877, "no_speech_prob": 0.035117704421281815}, {"id": 395, "seek": 155182, "start": 1551.8999999999999, "end": 1556.62, "text": " the first model that was commercially useful just as the model like literally put an API", "tokens": [50368, 264, 700, 2316, 300, 390, 41751, 4420, 445, 382, 264, 2316, 411, 3736, 829, 364, 9362, 50604], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 396, "seek": 155182, "start": 1556.62, "end": 1561.78, "text": " on top of it people just talk to it and people build products on top of it and you know that", "tokens": [50604, 322, 1192, 295, 309, 561, 445, 751, 281, 309, 293, 561, 1322, 3383, 322, 1192, 295, 309, 293, 291, 458, 300, 50862], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 397, "seek": 155182, "start": 1561.78, "end": 1566.26, "text": " you know one of our early customers just you know just raised it at 1.5 billion valuation", "tokens": [50862, 291, 458, 472, 295, 527, 2440, 4581, 445, 291, 458, 445, 6005, 309, 412, 502, 13, 20, 5218, 38546, 51086], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 398, "seek": 155182, "start": 1566.26, "end": 1570.54, "text": " which to me is is a really wonderful thing to realize that you build this model and it", "tokens": [51086, 597, 281, 385, 307, 307, 257, 534, 3715, 551, 281, 4325, 300, 291, 1322, 341, 2316, 293, 309, 51300], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 399, "seek": 155182, "start": 1570.54, "end": 1575.8999999999999, "text": " creates so much value for so many different people and I think that we're still in such", "tokens": [51300, 7829, 370, 709, 2158, 337, 370, 867, 819, 561, 293, 286, 519, 300, 321, 434, 920, 294, 1270, 51568], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 400, "seek": 155182, "start": 1575.8999999999999, "end": 1580.3, "text": " early days for what these models can do and so I think that what I'm most excited about", "tokens": [51568, 2440, 1708, 337, 437, 613, 5245, 393, 360, 293, 370, 286, 519, 300, 437, 286, 478, 881, 2919, 466, 51788], "temperature": 0.0, "avg_logprob": -0.14223966979980468, "compression_ratio": 1.8350515463917525, "no_speech_prob": 0.0018666937248781323}, {"id": 401, "seek": 158030, "start": 1580.34, "end": 1586.62, "text": " from just seeing GPT 3 seeing Dolly is thinking about the the sort of economic value that", "tokens": [50366, 490, 445, 2577, 26039, 51, 805, 2577, 1144, 13020, 307, 1953, 466, 264, 264, 1333, 295, 4836, 2158, 300, 50680], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 402, "seek": 158030, "start": 1586.62, "end": 1590.62, "text": " it can create for people and I think that there's a lot of other pieces to it in terms", "tokens": [50680, 309, 393, 1884, 337, 561, 293, 286, 519, 300, 456, 311, 257, 688, 295, 661, 3755, 281, 309, 294, 2115, 50880], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 403, "seek": 158030, "start": 1590.62, "end": 1595.26, "text": " of like you know that everyone's going to be more creative if you want to like I can't", "tokens": [50880, 295, 411, 291, 458, 300, 1518, 311, 516, 281, 312, 544, 5880, 498, 291, 528, 281, 411, 286, 393, 380, 51112], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 404, "seek": 158030, "start": 1595.26, "end": 1598.78, "text": " draw but now I can create images now I could take a picture of this in my head and I can", "tokens": [51112, 2642, 457, 586, 286, 393, 1884, 5267, 586, 286, 727, 747, 257, 3036, 295, 341, 294, 452, 1378, 293, 286, 393, 51288], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 405, "seek": 158030, "start": 1598.78, "end": 1602.94, "text": " actually see it on on a page and one of my favorite applications of Dolly is actually", "tokens": [51288, 767, 536, 309, 322, 322, 257, 3028, 293, 472, 295, 452, 2954, 5821, 295, 1144, 13020, 307, 767, 51496], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 406, "seek": 158030, "start": 1602.94, "end": 1608.02, "text": " people who are 3D physical artists you know something's like a sculptor and now they", "tokens": [51496, 561, 567, 366, 805, 35, 4001, 6910, 291, 458, 746, 311, 411, 257, 12613, 284, 293, 586, 436, 51750], "temperature": 0.0, "avg_logprob": -0.15882481795090894, "compression_ratio": 1.7668918918918919, "no_speech_prob": 0.003943858202546835}, {"id": 407, "seek": 160802, "start": 1608.06, "end": 1611.5, "text": " can actually get a great rendering of the thing that they have in mind by kind of just", "tokens": [50366, 393, 767, 483, 257, 869, 22407, 295, 264, 551, 300, 436, 362, 294, 1575, 538, 733, 295, 445, 50538], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 408, "seek": 160802, "start": 1611.5, "end": 1615.46, "text": " like iterating with this machine and they go build it right I think that this sort of", "tokens": [50538, 411, 17138, 990, 365, 341, 3479, 293, 436, 352, 1322, 309, 558, 286, 519, 300, 341, 1333, 295, 50736], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 409, "seek": 160802, "start": 1615.46, "end": 1620.58, "text": " amplification of what humans can do is what these systems are for and so I think that", "tokens": [50736, 9731, 3774, 295, 437, 6255, 393, 360, 307, 437, 613, 3652, 366, 337, 293, 370, 286, 519, 300, 50992], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 410, "seek": 160802, "start": 1620.58, "end": 1623.74, "text": " for this decade I think what we're really going to see is these tools just sort of", "tokens": [50992, 337, 341, 10378, 286, 519, 437, 321, 434, 534, 516, 281, 536, 307, 613, 3873, 445, 1333, 295, 51150], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 411, "seek": 160802, "start": 1623.74, "end": 1627.1, "text": " proliferating they're going to be everywhere they're going to be baked into every company", "tokens": [51150, 24398, 9361, 990, 436, 434, 516, 281, 312, 5315, 436, 434, 516, 281, 312, 19453, 666, 633, 2237, 51318], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 412, "seek": 160802, "start": 1627.1, "end": 1631.62, "text": " I think it's kind of like the internet transition that you know that it was kind of like if", "tokens": [51318, 286, 519, 309, 311, 733, 295, 411, 264, 4705, 6034, 300, 291, 458, 300, 309, 390, 733, 295, 411, 498, 51544], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 413, "seek": 160802, "start": 1631.62, "end": 1635.5, "text": " you're a company like what's your internet strategy and you know 1990 it's like what", "tokens": [51544, 291, 434, 257, 2237, 411, 437, 311, 428, 4705, 5206, 293, 291, 458, 13384, 309, 311, 411, 437, 51738], "temperature": 0.0, "avg_logprob": -0.09922624296612209, "compression_ratio": 2.0066006600660065, "no_speech_prob": 0.0005702512571588159}, {"id": 414, "seek": 163550, "start": 1635.54, "end": 1639.54, "text": " even is this thing you know and in 2000 it's like huh maybe it's interesting and there", "tokens": [50366, 754, 307, 341, 551, 291, 458, 293, 294, 8132, 309, 311, 411, 7020, 1310, 309, 311, 1880, 293, 456, 50566], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 415, "seek": 163550, "start": 1639.54, "end": 1644.34, "text": " there's a little you know boom and bust and here we are today even talk about an internet", "tokens": [50566, 456, 311, 257, 707, 291, 458, 9351, 293, 19432, 293, 510, 321, 366, 965, 754, 751, 466, 364, 4705, 50806], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 416, "seek": 163550, "start": 1644.34, "end": 1648.06, "text": " strategy is like it's just so integral to every business it's not even like it's not", "tokens": [50806, 5206, 307, 411, 309, 311, 445, 370, 11573, 281, 633, 1606, 309, 311, 406, 754, 411, 309, 311, 406, 50992], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 417, "seek": 163550, "start": 1648.06, "end": 1651.38, "text": " even a separate thing right it's just like it's just part of like your it's like your", "tokens": [50992, 754, 257, 4994, 551, 558, 309, 311, 445, 411, 309, 311, 445, 644, 295, 411, 428, 309, 311, 411, 428, 51158], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 418, "seek": 163550, "start": 1651.38, "end": 1654.38, "text": " payroll strategy right it's like it's not like a separate part of your business that", "tokens": [51158, 36873, 5206, 558, 309, 311, 411, 309, 311, 406, 411, 257, 4994, 644, 295, 428, 1606, 300, 51308], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 419, "seek": 163550, "start": 1654.38, "end": 1657.74, "text": " you can pick or choose whether you're going to have it and I think that AI is going to", "tokens": [51308, 291, 393, 1888, 420, 2826, 1968, 291, 434, 516, 281, 362, 309, 293, 286, 519, 300, 7318, 307, 516, 281, 51476], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 420, "seek": 163550, "start": 1657.74, "end": 1661.82, "text": " be much the same I think there will be a transition point right I think that it's it's", "tokens": [51476, 312, 709, 264, 912, 286, 519, 456, 486, 312, 257, 6034, 935, 558, 286, 519, 300, 309, 311, 309, 311, 51680], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 421, "seek": 163550, "start": 1661.82, "end": 1665.06, "text": " interesting like our mission is really about building artificial general intelligence right", "tokens": [51680, 1880, 411, 527, 4447, 307, 534, 466, 2390, 11677, 2674, 7599, 558, 51842], "temperature": 0.0, "avg_logprob": -0.10781694040065859, "compression_ratio": 2.147692307692308, "no_speech_prob": 0.0018670253921300173}, {"id": 422, "seek": 166506, "start": 1665.1, "end": 1669.62, "text": " really trying to build machines that are able to perform whole tasks right that are you know", "tokens": [50366, 534, 1382, 281, 1322, 8379, 300, 366, 1075, 281, 2042, 1379, 9608, 558, 300, 366, 291, 458, 50592], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 423, "seek": 166506, "start": 1669.62, "end": 1674.6599999999999, "text": " push this technology to its limit and build machines that are able to you know our charter", "tokens": [50592, 2944, 341, 2899, 281, 1080, 4948, 293, 1322, 8379, 300, 366, 1075, 281, 291, 458, 527, 27472, 50844], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 424, "seek": 166506, "start": 1674.6599999999999, "end": 1678.54, "text": " definition is outperform humans at most economically valuable work and there's a question of the", "tokens": [50844, 7123, 307, 484, 26765, 6255, 412, 881, 26811, 8263, 589, 293, 456, 311, 257, 1168, 295, 264, 51038], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 425, "seek": 166506, "start": 1678.54, "end": 1682.98, "text": " timeline but I think that that picture of you know you have these tools that are creative", "tokens": [51038, 12933, 457, 286, 519, 300, 300, 3036, 295, 291, 458, 291, 362, 613, 3873, 300, 366, 5880, 51260], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 426, "seek": 166506, "start": 1682.98, "end": 1687.7, "text": " that help everyone amplify and what happens when they do become so capable that they're", "tokens": [51260, 300, 854, 1518, 41174, 293, 437, 2314, 562, 436, 360, 1813, 370, 8189, 300, 436, 434, 51496], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 427, "seek": 166506, "start": 1687.7, "end": 1692.3799999999999, "text": " able to perform these tasks even autonomously and I think that actually the implications", "tokens": [51496, 1075, 281, 2042, 613, 9608, 754, 18203, 5098, 293, 286, 519, 300, 767, 264, 16602, 51730], "temperature": 0.0, "avg_logprob": -0.12133777247065991, "compression_ratio": 1.9328621908127208, "no_speech_prob": 0.0005697396118193865}, {"id": 428, "seek": 169238, "start": 1692.38, "end": 1696.46, "text": " of that are different from what people expect I think that it's much more like you know that", "tokens": [50364, 295, 300, 366, 819, 490, 437, 561, 2066, 286, 519, 300, 309, 311, 709, 544, 411, 291, 458, 300, 50568], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 429, "seek": 169238, "start": 1696.46, "end": 1700.8600000000001, "text": " I think there's still going to be this amplification but I think that there the change is going", "tokens": [50568, 286, 519, 456, 311, 920, 516, 281, 312, 341, 9731, 3774, 457, 286, 519, 300, 456, 264, 1319, 307, 516, 50788], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 430, "seek": 169238, "start": 1700.8600000000001, "end": 1706.3000000000002, "text": " to be just very hard to predict and unexpected and I think that really thinking about how", "tokens": [50788, 281, 312, 445, 588, 1152, 281, 6069, 293, 13106, 293, 286, 519, 300, 534, 1953, 466, 577, 51060], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 431, "seek": 169238, "start": 1706.3000000000002, "end": 1710.8200000000002, "text": " all of that sort of value gets distributed how to make sure that it's sort of pointed", "tokens": [51060, 439, 295, 300, 1333, 295, 2158, 2170, 12631, 577, 281, 652, 988, 300, 309, 311, 1333, 295, 10932, 51286], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 432, "seek": 169238, "start": 1710.8200000000002, "end": 1715.0200000000002, "text": " at solving these like hard challenges that humans you know maybe are unable to solve", "tokens": [51286, 412, 12606, 613, 411, 1152, 4759, 300, 6255, 291, 458, 1310, 366, 11299, 281, 5039, 51496], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 433, "seek": 169238, "start": 1715.0200000000002, "end": 1718.7800000000002, "text": " ourselves you know the climate change and you know universal education and things like", "tokens": [51496, 4175, 291, 458, 264, 5659, 1319, 293, 291, 458, 11455, 3309, 293, 721, 411, 51684], "temperature": 0.0, "avg_logprob": -0.10987382057385567, "compression_ratio": 1.9420289855072463, "no_speech_prob": 0.002887628972530365}, {"id": 434, "seek": 171878, "start": 1718.86, "end": 1724.22, "text": " that and really transitioning to this like AI powered world I think is going to be just", "tokens": [50368, 300, 293, 534, 33777, 281, 341, 411, 7318, 17786, 1002, 286, 519, 307, 516, 281, 312, 445, 50636], "temperature": 0.0, "avg_logprob": -0.18138909571379133, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.0031707556918263435}, {"id": 435, "seek": 171878, "start": 1724.22, "end": 1728.1399999999999, "text": " like a real sort of challenge for the whole you know all of humanity to work together", "tokens": [50636, 411, 257, 957, 1333, 295, 3430, 337, 264, 1379, 291, 458, 439, 295, 10243, 281, 589, 1214, 50832], "temperature": 0.0, "avg_logprob": -0.18138909571379133, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.0031707556918263435}, {"id": 436, "seek": 171878, "start": 1728.1399999999999, "end": 1733.3799999999999, "text": " on. Yeah I mean I totally agree one thing that I think is almost funny with how the timing", "tokens": [50832, 322, 13, 865, 286, 914, 286, 3879, 3986, 472, 551, 300, 286, 519, 307, 1920, 4074, 365, 577, 264, 10822, 51094], "temperature": 0.0, "avg_logprob": -0.18138909571379133, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.0031707556918263435}, {"id": 437, "seek": 171878, "start": 1733.3799999999999, "end": 1736.82, "text": " of all these technologies have worked out is that you know last year everyone was talking", "tokens": [51094, 295, 439, 613, 7943, 362, 2732, 484, 307, 300, 291, 458, 1036, 1064, 1518, 390, 1417, 51266], "temperature": 0.0, "avg_logprob": -0.18138909571379133, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.0031707556918263435}, {"id": 438, "seek": 171878, "start": 1736.82, "end": 1744.1, "text": " about Web 3 as crypto and now it feels very obvious that AI is the actual Web 3 you know.", "tokens": [51266, 466, 9573, 805, 382, 17240, 293, 586, 309, 3417, 588, 6322, 300, 7318, 307, 264, 3539, 9573, 805, 291, 458, 13, 51630], "temperature": 0.0, "avg_logprob": -0.18138909571379133, "compression_ratio": 1.688212927756654, "no_speech_prob": 0.0031707556918263435}, {"id": 439, "seek": 174410, "start": 1744.1799999999998, "end": 1748.54, "text": " We'll take Web 4. Yeah Web 4 we'll skip we'll skip over one but sort of like Web 1 was just", "tokens": [50368, 492, 603, 747, 9573, 1017, 13, 865, 9573, 1017, 321, 603, 10023, 321, 603, 10023, 670, 472, 457, 1333, 295, 411, 9573, 502, 390, 445, 50586], "temperature": 0.0, "avg_logprob": -0.23246378558022635, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.015168078243732452}, {"id": 440, "seek": 174410, "start": 1748.54, "end": 1754.1399999999999, "text": " reading Web 2 was reading and writing and now Web 3 or 4 depending on what we want to", "tokens": [50586, 3760, 9573, 568, 390, 3760, 293, 3579, 293, 586, 9573, 805, 420, 1017, 5413, 322, 437, 321, 528, 281, 50866], "temperature": 0.0, "avg_logprob": -0.23246378558022635, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.015168078243732452}, {"id": 441, "seek": 174410, "start": 1754.1399999999999, "end": 1760.54, "text": " say is ads, computer reading, computer write and it's sort of this incredible new phase.", "tokens": [50866, 584, 307, 10342, 11, 3820, 3760, 11, 3820, 2464, 293, 309, 311, 1333, 295, 341, 4651, 777, 5574, 13, 51186], "temperature": 0.0, "avg_logprob": -0.23246378558022635, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.015168078243732452}, {"id": 442, "seek": 174410, "start": 1760.54, "end": 1764.4199999999998, "text": " You know one so I think I think you mentioned two two directions here that I think are really", "tokens": [51186, 509, 458, 472, 370, 286, 519, 286, 519, 291, 2835, 732, 732, 11095, 510, 300, 286, 519, 366, 534, 51380], "temperature": 0.0, "avg_logprob": -0.23246378558022635, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.015168078243732452}, {"id": 443, "seek": 174410, "start": 1764.4199999999998, "end": 1771.78, "text": " interesting one is the sort of advancement and sort of proliferation of GP3 and Dolly", "tokens": [51380, 1880, 472, 307, 264, 1333, 295, 35764, 293, 1333, 295, 24398, 44987, 295, 26039, 18, 293, 1144, 13020, 51748], "temperature": 0.0, "avg_logprob": -0.23246378558022635, "compression_ratio": 1.7768924302788844, "no_speech_prob": 0.015168078243732452}, {"id": 444, "seek": 177178, "start": 1771.86, "end": 1775.66, "text": " and sort of the existing tools becoming more and more economically useful and there's", "tokens": [50368, 293, 1333, 295, 264, 6741, 3873, 5617, 544, 293, 544, 26811, 4420, 293, 456, 311, 50558], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 445, "seek": 177178, "start": 1775.66, "end": 1780.46, "text": " sort of this continued improvement of the algorithms themselves towards sort of towards", "tokens": [50558, 1333, 295, 341, 7014, 10444, 295, 264, 14642, 2969, 3030, 1333, 295, 3030, 50798], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 446, "seek": 177178, "start": 1780.46, "end": 1784.86, "text": " sort of AGI. What do you think and obviously don't reveal any opening secrets but what", "tokens": [50798, 1333, 295, 316, 26252, 13, 708, 360, 291, 519, 293, 2745, 500, 380, 10658, 604, 5193, 14093, 457, 437, 51018], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 447, "seek": 177178, "start": 1784.86, "end": 1789.1399999999999, "text": " do you think this sort of like roadmap to AGI looks like from where we are now? I mean", "tokens": [51018, 360, 291, 519, 341, 1333, 295, 411, 35738, 281, 316, 26252, 1542, 411, 490, 689, 321, 366, 586, 30, 286, 914, 51232], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 448, "seek": 177178, "start": 1789.1399999999999, "end": 1794.7, "text": " I think that humanity to a large extent has been on the AGI roadmap for a very very long", "tokens": [51232, 286, 519, 300, 10243, 281, 257, 2416, 8396, 575, 668, 322, 264, 316, 26252, 35738, 337, 257, 588, 588, 938, 51510], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 449, "seek": 177178, "start": 1794.7, "end": 1800.8999999999999, "text": " time. I think even looking at just the history of neural networks in particular you know", "tokens": [51510, 565, 13, 286, 519, 754, 1237, 412, 445, 264, 2503, 295, 18161, 9590, 294, 1729, 291, 458, 51820], "temperature": 0.0, "avg_logprob": -0.1491955348423549, "compression_ratio": 1.797945205479452, "no_speech_prob": 0.0022505363449454308}, {"id": 450, "seek": 180090, "start": 1800.94, "end": 1804.8200000000002, "text": " on the one hand we say hey 2012 like that was the moment like everything changed you", "tokens": [50366, 322, 264, 472, 1011, 321, 584, 4177, 9125, 411, 300, 390, 264, 1623, 411, 1203, 3105, 291, 50560], "temperature": 0.0, "avg_logprob": -0.18340212504069012, "compression_ratio": 1.8215767634854771, "no_speech_prob": 0.0001910672872327268}, {"id": 451, "seek": 180090, "start": 1804.8200000000002, "end": 1808.5, "text": " know that like you look at these we have all these curves of how much compute people put", "tokens": [50560, 458, 300, 411, 291, 574, 412, 613, 321, 362, 439, 613, 19490, 295, 577, 709, 14722, 561, 829, 50744], "temperature": 0.0, "avg_logprob": -0.18340212504069012, "compression_ratio": 1.8215767634854771, "no_speech_prob": 0.0001910672872327268}, {"id": 452, "seek": 180090, "start": 1808.5, "end": 1812.0600000000002, "text": " into the landmark results it was going like 10x year over year still continuing by the", "tokens": [50744, 666, 264, 26962, 3542, 309, 390, 516, 411, 1266, 87, 1064, 670, 1064, 920, 9289, 538, 264, 50922], "temperature": 0.0, "avg_logprob": -0.18340212504069012, "compression_ratio": 1.8215767634854771, "no_speech_prob": 0.0001910672872327268}, {"id": 453, "seek": 180090, "start": 1812.0600000000002, "end": 1819.22, "text": " way that's that's a decade of 10x year over year that's insane and the thing is we actually", "tokens": [50922, 636, 300, 311, 300, 311, 257, 10378, 295, 1266, 87, 1064, 670, 1064, 300, 311, 10838, 293, 264, 551, 307, 321, 767, 51280], "temperature": 0.0, "avg_logprob": -0.18340212504069012, "compression_ratio": 1.8215767634854771, "no_speech_prob": 0.0001910672872327268}, {"id": 454, "seek": 180090, "start": 1819.22, "end": 1825.7800000000002, "text": " did a study to then look back at previous results all the way back to you know say the", "tokens": [51280, 630, 257, 2979, 281, 550, 574, 646, 412, 3894, 3542, 439, 264, 636, 646, 281, 291, 458, 584, 264, 51608], "temperature": 0.0, "avg_logprob": -0.18340212504069012, "compression_ratio": 1.8215767634854771, "no_speech_prob": 0.0001910672872327268}, {"id": 455, "seek": 182578, "start": 1825.82, "end": 1832.34, "text": " perceptron in 1959 and you actually find that there's basically a very smooth curve back", "tokens": [50366, 43276, 2044, 294, 45608, 293, 291, 767, 915, 300, 456, 311, 1936, 257, 588, 5508, 7605, 646, 50692], "temperature": 0.0, "avg_logprob": -0.13515840117464362, "compression_ratio": 1.6394052044609666, "no_speech_prob": 0.0018097403226420283}, {"id": 456, "seek": 182578, "start": 1832.34, "end": 1836.22, "text": " there as well. The amount of compute going into all the landmark results was exactly", "tokens": [50692, 456, 382, 731, 13, 440, 2372, 295, 14722, 516, 666, 439, 264, 26962, 3542, 390, 2293, 50886], "temperature": 0.0, "avg_logprob": -0.13515840117464362, "compression_ratio": 1.6394052044609666, "no_speech_prob": 0.0018097403226420283}, {"id": 457, "seek": 182578, "start": 1836.22, "end": 1841.02, "text": " Moore's law and it kind of makes sense right it's like that people were not willing to", "tokens": [50886, 21644, 311, 2101, 293, 309, 733, 295, 1669, 2020, 558, 309, 311, 411, 300, 561, 645, 406, 4950, 281, 51126], "temperature": 0.0, "avg_logprob": -0.13515840117464362, "compression_ratio": 1.6394052044609666, "no_speech_prob": 0.0018097403226420283}, {"id": 458, "seek": 182578, "start": 1841.02, "end": 1845.58, "text": " spend more money they wanted to spend a constant amount of money on these experiments because", "tokens": [51126, 3496, 544, 1460, 436, 1415, 281, 3496, 257, 5754, 2372, 295, 1460, 322, 613, 12050, 570, 51354], "temperature": 0.0, "avg_logprob": -0.13515840117464362, "compression_ratio": 1.6394052044609666, "no_speech_prob": 0.0018097403226420283}, {"id": 459, "seek": 182578, "start": 1845.58, "end": 1850.06, "text": " you're starving grad students like you know you can only get so much computer time and", "tokens": [51354, 291, 434, 28420, 2771, 1731, 411, 291, 458, 291, 393, 787, 483, 370, 709, 3820, 565, 293, 51578], "temperature": 0.0, "avg_logprob": -0.13515840117464362, "compression_ratio": 1.6394052044609666, "no_speech_prob": 0.0018097403226420283}, {"id": 460, "seek": 185006, "start": 1850.1, "end": 1856.3799999999999, "text": " that the results got better and better the more compute was available to them and I think", "tokens": [50366, 300, 264, 3542, 658, 1101, 293, 1101, 264, 544, 14722, 390, 2435, 281, 552, 293, 286, 519, 50680], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 461, "seek": 185006, "start": 1856.3799999999999, "end": 1859.74, "text": " that that is so interesting that yeah basically what changed in 2012 was that we said okay", "tokens": [50680, 300, 300, 307, 370, 1880, 300, 1338, 1936, 437, 3105, 294, 9125, 390, 300, 321, 848, 1392, 50848], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 462, "seek": 185006, "start": 1859.74, "end": 1862.6599999999999, "text": " we're just gonna like you know we are gonna spend more money we're gonna build massive", "tokens": [50848, 321, 434, 445, 799, 411, 291, 458, 321, 366, 799, 3496, 544, 1460, 321, 434, 799, 1322, 5994, 50994], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 463, "seek": 185006, "start": 1862.6599999999999, "end": 1868.5, "text": " supercomputers now because the ROI is there but that fundamentally the curve if you control", "tokens": [50994, 27839, 2582, 433, 586, 570, 264, 49808, 307, 456, 457, 300, 17879, 264, 7605, 498, 291, 1969, 51286], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 464, "seek": 185006, "start": 1868.5, "end": 1872.1, "text": " for that that cost factor it looks exactly the same and so I think that basically this", "tokens": [51286, 337, 300, 300, 2063, 5952, 309, 1542, 2293, 264, 912, 293, 370, 286, 519, 300, 1936, 341, 51466], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 465, "seek": 185006, "start": 1872.1, "end": 1876.5, "text": " picture of building more capable models by pouring more compute into them by getting", "tokens": [51466, 3036, 295, 2390, 544, 8189, 5245, 538, 20450, 544, 14722, 666, 552, 538, 1242, 51686], "temperature": 0.0, "avg_logprob": -0.10987398080658495, "compression_ratio": 1.8122866894197953, "no_speech_prob": 0.00017951830523088574}, {"id": 466, "seek": 187650, "start": 1876.58, "end": 1881.26, "text": " better at harnessing this technology of neural networks back propagation I think that has", "tokens": [50368, 1101, 412, 19700, 278, 341, 2899, 295, 18161, 9590, 646, 38377, 286, 519, 300, 575, 50602], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 467, "seek": 187650, "start": 1881.26, "end": 1884.94, "text": " been very invariant and the details you know maybe change a little bit you know do you want to", "tokens": [50602, 668, 588, 33270, 394, 293, 264, 4365, 291, 458, 1310, 1319, 257, 707, 857, 291, 458, 360, 291, 528, 281, 50786], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 468, "seek": 187650, "start": 1884.94, "end": 1890.14, "text": " work on GPT-3 do you want to work on whisper like do you pour in your your you know speech", "tokens": [50786, 589, 322, 26039, 51, 12, 18, 360, 291, 528, 281, 589, 322, 26018, 411, 360, 291, 2016, 294, 428, 428, 291, 458, 6218, 51046], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 469, "seek": 187650, "start": 1890.14, "end": 1894.7, "text": " data do you pour in text data from the internet and to me those details I think you know they", "tokens": [51046, 1412, 360, 291, 2016, 294, 2487, 1412, 490, 264, 4705, 293, 281, 385, 729, 4365, 286, 519, 291, 458, 436, 51274], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 470, "seek": 187650, "start": 1894.7, "end": 1898.46, "text": " matter in the like in the like sense of like what are you gonna work on today and you know", "tokens": [51274, 1871, 294, 264, 411, 294, 264, 411, 2020, 295, 411, 437, 366, 291, 799, 589, 322, 965, 293, 291, 458, 51462], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 471, "seek": 187650, "start": 1898.46, "end": 1902.02, "text": " what are you gonna download but if you zoom out you look at the scale of like these this", "tokens": [51462, 437, 366, 291, 799, 5484, 457, 498, 291, 8863, 484, 291, 574, 412, 264, 4373, 295, 411, 613, 341, 51640], "temperature": 0.0, "avg_logprob": -0.10609698841590008, "compression_ratio": 1.974820143884892, "no_speech_prob": 0.0038229848723858595}, {"id": 472, "seek": 190202, "start": 1902.06, "end": 1907.3, "text": " technology I think it actually sort of doesn't matter so much I think kind of what we're", "tokens": [50366, 2899, 286, 519, 309, 767, 1333, 295, 1177, 380, 1871, 370, 709, 286, 519, 733, 295, 437, 321, 434, 50628], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 473, "seek": 190202, "start": 1907.3, "end": 1909.94, "text": " building it's almost like building computers like you think about the Haiti and Moore's", "tokens": [50628, 2390, 309, 311, 1920, 411, 2390, 10807, 411, 291, 519, 466, 264, 35231, 293, 21644, 311, 50760], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 474, "seek": 190202, "start": 1909.94, "end": 1912.9, "text": " law right where it's just like there's a new chip that comes out and there's a new chip that", "tokens": [50760, 2101, 558, 689, 309, 311, 445, 411, 456, 311, 257, 777, 11409, 300, 1487, 484, 293, 456, 311, 257, 777, 11409, 300, 50908], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 475, "seek": 190202, "start": 1912.9, "end": 1916.3799999999999, "text": " comes out and it's kind of like what's the you know what's the path to building the best", "tokens": [50908, 1487, 484, 293, 309, 311, 733, 295, 411, 437, 311, 264, 291, 458, 437, 311, 264, 3100, 281, 2390, 264, 1151, 51082], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 476, "seek": 190202, "start": 1916.3799999999999, "end": 1919.86, "text": " computer the answer is well you just keep building the next best chip and you keep building", "tokens": [51082, 3820, 264, 1867, 307, 731, 291, 445, 1066, 2390, 264, 958, 1151, 11409, 293, 291, 1066, 2390, 51256], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 477, "seek": 190202, "start": 1919.86, "end": 1923.62, "text": " the next best chip and you keep getting better peripherals and all these you know keep working", "tokens": [51256, 264, 958, 1151, 11409, 293, 291, 1066, 1242, 1101, 26807, 1124, 293, 439, 613, 291, 458, 1066, 1364, 51444], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 478, "seek": 190202, "start": 1923.62, "end": 1929.22, "text": " every single piece of the technology and so I think this full stack of better GPUs great", "tokens": [51444, 633, 2167, 2522, 295, 264, 2899, 293, 370, 286, 519, 341, 1577, 8630, 295, 1101, 18407, 82, 869, 51724], "temperature": 0.0, "avg_logprob": -0.11689454682019292, "compression_ratio": 2.141891891891892, "no_speech_prob": 0.010649190284311771}, {"id": 479, "seek": 192922, "start": 1929.26, "end": 1933.06, "text": " software for utilizing them neural networks that we learned to harness more and more the", "tokens": [50366, 4722, 337, 26775, 552, 18161, 9590, 300, 321, 3264, 281, 19700, 544, 293, 544, 264, 50556], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 480, "seek": 192922, "start": 1933.06, "end": 1937.34, "text": " scaling laws doing all the science alignment extremely important making sure these models", "tokens": [50556, 21589, 6064, 884, 439, 264, 3497, 18515, 4664, 1021, 1455, 988, 613, 5245, 50770], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 481, "seek": 192922, "start": 1937.34, "end": 1942.94, "text": " not just are smart but actually are aligned with what humans intend all of that I think is the", "tokens": [50770, 406, 445, 366, 4069, 457, 767, 366, 17962, 365, 437, 6255, 19759, 439, 295, 300, 286, 519, 307, 264, 51050], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 482, "seek": 192922, "start": 1942.94, "end": 1947.3, "text": " stack and so I think that you know what our goal is is just to keep doing something that was", "tokens": [51050, 8630, 293, 370, 286, 519, 300, 291, 458, 437, 527, 3387, 307, 307, 445, 281, 1066, 884, 746, 300, 390, 51268], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 483, "seek": 192922, "start": 1947.3, "end": 1951.54, "text": " previously impossible every single year so you know that I guess well you should check back", "tokens": [51268, 8046, 6243, 633, 2167, 1064, 370, 291, 458, 300, 286, 2041, 731, 291, 820, 1520, 646, 51480], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 484, "seek": 192922, "start": 1951.54, "end": 1957.42, "text": " in a year but hopefully 2023 we'll all forget about Dolly 2 and GPT 3 and we'll be talking", "tokens": [51480, 294, 257, 1064, 457, 4696, 44377, 321, 603, 439, 2870, 466, 1144, 13020, 568, 293, 26039, 51, 805, 293, 321, 603, 312, 1417, 51774], "temperature": 0.0, "avg_logprob": -0.15236845016479492, "compression_ratio": 1.7373417721518987, "no_speech_prob": 0.0019262388814240694}, {"id": 485, "seek": 195742, "start": 1957.42, "end": 1962.8200000000002, "text": " about something new and I think as long as we continue that like you cannot continue that", "tokens": [50364, 466, 746, 777, 293, 286, 519, 382, 938, 382, 321, 2354, 300, 411, 291, 2644, 2354, 300, 50634], "temperature": 0.0, "avg_logprob": -0.13792914152145386, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0010983663378283381}, {"id": 486, "seek": 195742, "start": 1962.8200000000002, "end": 1969.02, "text": " path without ending up somewhere amazing yeah I mean I think I actually remember this in I", "tokens": [50634, 3100, 1553, 8121, 493, 4079, 2243, 1338, 286, 914, 286, 519, 286, 767, 1604, 341, 294, 286, 50944], "temperature": 0.0, "avg_logprob": -0.13792914152145386, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0010983663378283381}, {"id": 487, "seek": 195742, "start": 1969.02, "end": 1975.98, "text": " think probably 2017 you were sort of very still quite you were very excited about sort of the", "tokens": [50944, 519, 1391, 6591, 291, 645, 1333, 295, 588, 920, 1596, 291, 645, 588, 2919, 466, 1333, 295, 264, 51292], "temperature": 0.0, "avg_logprob": -0.13792914152145386, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0010983663378283381}, {"id": 488, "seek": 195742, "start": 1975.98, "end": 1982.98, "text": " sort of Moore's law continuing and that that sort of creating a lot more opportunity for you", "tokens": [51292, 1333, 295, 21644, 311, 2101, 9289, 293, 300, 300, 1333, 295, 4084, 257, 688, 544, 2650, 337, 291, 51642], "temperature": 0.0, "avg_logprob": -0.13792914152145386, "compression_ratio": 1.7311320754716981, "no_speech_prob": 0.0010983663378283381}, {"id": 489, "seek": 198298, "start": 1982.98, "end": 1988.42, "text": " know neural networks and AI and that's that's sort of played out are you worried about the sort", "tokens": [50364, 458, 18161, 9590, 293, 7318, 293, 300, 311, 300, 311, 1333, 295, 3737, 484, 366, 291, 5804, 466, 264, 1333, 50636], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 490, "seek": 198298, "start": 1988.42, "end": 1996.38, "text": " of proverbial end of Moore's law kind of causing a stall out in in progress so I'm not worried", "tokens": [50636, 295, 49923, 831, 917, 295, 21644, 311, 2101, 733, 295, 9853, 257, 19633, 484, 294, 294, 4205, 370, 286, 478, 406, 5804, 51034], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 491, "seek": 198298, "start": 1996.38, "end": 1999.82, "text": " about it per se like I think the way to think about this right because I think we you know we", "tokens": [51034, 466, 309, 680, 369, 411, 286, 519, 264, 636, 281, 519, 466, 341, 558, 570, 286, 519, 321, 291, 458, 321, 51206], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 492, "seek": 198298, "start": 1999.82, "end": 2003.66, "text": " often get caught in this debate of like is it all about scale or is it all about algorithms is", "tokens": [51206, 2049, 483, 5415, 294, 341, 7958, 295, 411, 307, 309, 439, 466, 4373, 420, 307, 309, 439, 466, 14642, 307, 51398], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 493, "seek": 198298, "start": 2003.66, "end": 2008.54, "text": " all about data and the answer is that's a wrong question right it's really like you multiply", "tokens": [51398, 439, 466, 1412, 293, 264, 1867, 307, 300, 311, 257, 2085, 1168, 558, 309, 311, 534, 411, 291, 12972, 51642], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 494, "seek": 198298, "start": 2008.54, "end": 2011.66, "text": " together these factors and the best thing to do when you're multiplying together multiple terms", "tokens": [51642, 1214, 613, 6771, 293, 264, 1151, 551, 281, 360, 562, 291, 434, 30955, 1214, 3866, 2115, 51798], "temperature": 0.0, "avg_logprob": -0.13070326140432648, "compression_ratio": 1.9586206896551723, "no_speech_prob": 0.0021149886306375265}, {"id": 495, "seek": 201166, "start": 2011.74, "end": 2016.0600000000002, "text": " is that you actually kind of want them all to be equal and I think that the answer is like it's", "tokens": [50368, 307, 300, 291, 767, 733, 295, 528, 552, 439, 281, 312, 2681, 293, 286, 519, 300, 264, 1867, 307, 411, 309, 311, 50584], "temperature": 0.0, "avg_logprob": -0.113616943359375, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.0014545037411153316}, {"id": 496, "seek": 201166, "start": 2016.0600000000002, "end": 2021.98, "text": " been great for the past you know seven years that we've been able to just pour more dollars to", "tokens": [50584, 668, 869, 337, 264, 1791, 291, 458, 3407, 924, 300, 321, 600, 668, 1075, 281, 445, 2016, 544, 3808, 281, 50880], "temperature": 0.0, "avg_logprob": -0.113616943359375, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.0014545037411153316}, {"id": 497, "seek": 201166, "start": 2021.98, "end": 2025.74, "text": " build bigger computers that's one way to get ahead of Moore's law at some point they're just", "tokens": [50880, 1322, 3801, 10807, 300, 311, 472, 636, 281, 483, 2286, 295, 21644, 311, 2101, 412, 512, 935, 436, 434, 445, 51068], "temperature": 0.0, "avg_logprob": -0.113616943359375, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.0014545037411153316}, {"id": 498, "seek": 201166, "start": 2025.74, "end": 2029.9, "text": " aren't more dollars right there aren't more grains of sand to you know that have been turned into", "tokens": [51068, 3212, 380, 544, 3808, 558, 456, 3212, 380, 544, 22908, 295, 4932, 281, 291, 458, 300, 362, 668, 3574, 666, 51276], "temperature": 0.0, "avg_logprob": -0.113616943359375, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.0014545037411153316}, {"id": 499, "seek": 201166, "start": 2029.9, "end": 2036.8600000000001, "text": " into these these wonderful computers that we use so there is a limit there that we have not yet", "tokens": [51276, 666, 613, 613, 3715, 10807, 300, 321, 764, 370, 456, 307, 257, 4948, 456, 300, 321, 362, 406, 1939, 51624], "temperature": 0.0, "avg_logprob": -0.113616943359375, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.0014545037411153316}, {"id": 500, "seek": 203686, "start": 2036.9399999999998, "end": 2042.62, "text": " hit but when you do that does not stall all progress right you still have algorithmic progress", "tokens": [50368, 2045, 457, 562, 291, 360, 300, 775, 406, 19633, 439, 4205, 558, 291, 920, 362, 9284, 299, 4205, 50652], "temperature": 0.0, "avg_logprob": -0.10993265882830754, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.002472170628607273}, {"id": 501, "seek": 203686, "start": 2042.62, "end": 2047.1, "text": " and there we've again done studies and we've shown that actually if you take like an example is if", "tokens": [50652, 293, 456, 321, 600, 797, 1096, 5313, 293, 321, 600, 4898, 300, 767, 498, 291, 747, 411, 364, 1365, 307, 498, 50876], "temperature": 0.0, "avg_logprob": -0.10993265882830754, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.002472170628607273}, {"id": 502, "seek": 203686, "start": 2047.1, "end": 2052.22, "text": " you look at the amount of compute it takes to hit the same performance so to train you know a state", "tokens": [50876, 291, 574, 412, 264, 2372, 295, 14722, 309, 2516, 281, 2045, 264, 912, 3389, 370, 281, 3847, 291, 458, 257, 1785, 51132], "temperature": 0.0, "avg_logprob": -0.10993265882830754, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.002472170628607273}, {"id": 503, "seek": 203686, "start": 2052.22, "end": 2059.74, "text": " of the art that you know 2012 or 2014 vision model that that computes also falling exponentially", "tokens": [51132, 295, 264, 1523, 300, 291, 458, 9125, 420, 8227, 5201, 2316, 300, 300, 715, 1819, 611, 7440, 37330, 51508], "temperature": 0.0, "avg_logprob": -0.10993265882830754, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.002472170628607273}, {"id": 504, "seek": 203686, "start": 2059.74, "end": 2064.46, "text": " we're basically making exponential progress in algorithms not at the same rate as we are able", "tokens": [51508, 321, 434, 1936, 1455, 21510, 4205, 294, 14642, 406, 412, 264, 912, 3314, 382, 321, 366, 1075, 51744], "temperature": 0.0, "avg_logprob": -0.10993265882830754, "compression_ratio": 1.8473282442748091, "no_speech_prob": 0.002472170628607273}, {"id": 505, "seek": 206446, "start": 2064.46, "end": 2069.18, "text": " to you know sort of build bigger computers but that is an amazing force too you know it's like", "tokens": [50364, 281, 291, 458, 1333, 295, 1322, 3801, 10807, 457, 300, 307, 364, 2243, 3464, 886, 291, 458, 309, 311, 411, 50600], "temperature": 0.0, "avg_logprob": -0.07941858042841372, "compression_ratio": 2.0081967213114753, "no_speech_prob": 0.0006259772344492376}, {"id": 506, "seek": 206446, "start": 2069.18, "end": 2073.02, "text": " I've got this exponential I've got that exponential like let's not even talk about the data exponential", "tokens": [50600, 286, 600, 658, 341, 21510, 286, 600, 658, 300, 21510, 411, 718, 311, 406, 754, 751, 466, 264, 1412, 21510, 50792], "temperature": 0.0, "avg_logprob": -0.07941858042841372, "compression_ratio": 2.0081967213114753, "no_speech_prob": 0.0006259772344492376}, {"id": 507, "seek": 206446, "start": 2073.02, "end": 2077.9, "text": " so I think that that the truth is that we will find a way I think that the history of this field", "tokens": [50792, 370, 286, 519, 300, 300, 264, 3494, 307, 300, 321, 486, 915, 257, 636, 286, 519, 300, 264, 2503, 295, 341, 2519, 51036], "temperature": 0.0, "avg_logprob": -0.07941858042841372, "compression_ratio": 2.0081967213114753, "no_speech_prob": 0.0006259772344492376}, {"id": 508, "seek": 206446, "start": 2077.9, "end": 2083.02, "text": " is just so consistent and I think that that you know humanity is just so innovative that I think", "tokens": [51036, 307, 445, 370, 8398, 293, 286, 519, 300, 300, 291, 458, 10243, 307, 445, 370, 12999, 300, 286, 519, 51292], "temperature": 0.0, "avg_logprob": -0.07941858042841372, "compression_ratio": 2.0081967213114753, "no_speech_prob": 0.0006259772344492376}, {"id": 509, "seek": 206446, "start": 2083.02, "end": 2089.66, "text": " that that we're not going to hit a wall for the foreseeable future and do you think that you know", "tokens": [51292, 300, 300, 321, 434, 406, 516, 281, 2045, 257, 2929, 337, 264, 38736, 712, 2027, 293, 360, 291, 519, 300, 291, 458, 51624], "temperature": 0.0, "avg_logprob": -0.07941858042841372, "compression_ratio": 2.0081967213114753, "no_speech_prob": 0.0006259772344492376}, {"id": 510, "seek": 208966, "start": 2089.66, "end": 2096.3799999999997, "text": " one of the one of the interesting juxtapositions of of today just from a scientific perspective is", "tokens": [50364, 472, 295, 264, 472, 295, 264, 1880, 3649, 734, 569, 329, 2451, 295, 295, 965, 445, 490, 257, 8134, 4585, 307, 50700], "temperature": 0.0, "avg_logprob": -0.06955882935296921, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0019228134769946337}, {"id": 511, "seek": 208966, "start": 2096.3799999999997, "end": 2101.74, "text": " a relative slowing in nearly every other science and there's you know there's a lot of research", "tokens": [50700, 257, 4972, 26958, 294, 6217, 633, 661, 3497, 293, 456, 311, 291, 458, 456, 311, 257, 688, 295, 2132, 50968], "temperature": 0.0, "avg_logprob": -0.06955882935296921, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0019228134769946337}, {"id": 512, "seek": 208966, "start": 2101.74, "end": 2105.74, "text": " that sort of demonstrated that science on the whole slowing and then comparatively the sort of", "tokens": [50968, 300, 1333, 295, 18772, 300, 3497, 322, 264, 1379, 26958, 293, 550, 6311, 19020, 264, 1333, 295, 51168], "temperature": 0.0, "avg_logprob": -0.06955882935296921, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0019228134769946337}, {"id": 513, "seek": 208966, "start": 2105.74, "end": 2109.98, "text": " acceleration of artificial intelligence and sort of this this you know in many ways this", "tokens": [51168, 17162, 295, 11677, 7599, 293, 1333, 295, 341, 341, 291, 458, 294, 867, 2098, 341, 51380], "temperature": 0.0, "avg_logprob": -0.06955882935296921, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0019228134769946337}, {"id": 514, "seek": 208966, "start": 2109.98, "end": 2116.22, "text": " renaissance that we're entering right now do you do you fear that at some point AI will similarly", "tokens": [51380, 319, 629, 14431, 300, 321, 434, 11104, 558, 586, 360, 291, 360, 291, 4240, 300, 412, 512, 935, 7318, 486, 14138, 51692], "temperature": 0.0, "avg_logprob": -0.06955882935296921, "compression_ratio": 1.8888888888888888, "no_speech_prob": 0.0019228134769946337}, {"id": 515, "seek": 211622, "start": 2116.22, "end": 2120.8599999999997, "text": " sort of reach these points of admission mark returns and slow relative like in much in the", "tokens": [50364, 1333, 295, 2524, 613, 2793, 295, 24668, 1491, 11247, 293, 2964, 4972, 411, 294, 709, 294, 264, 50596], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 516, "seek": 211622, "start": 2120.8599999999997, "end": 2125.58, "text": " same way that other sciences have or do you think that's so far away that you know well I think", "tokens": [50596, 912, 636, 300, 661, 17677, 362, 420, 360, 291, 519, 300, 311, 370, 1400, 1314, 300, 291, 458, 731, 286, 519, 50832], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 517, "seek": 211622, "start": 2125.58, "end": 2129.8199999999997, "text": " two things I mean I think that there's there's always s-curves although I think that something", "tokens": [50832, 732, 721, 286, 914, 286, 519, 300, 456, 311, 456, 311, 1009, 262, 12, 14112, 977, 4878, 286, 519, 300, 746, 51044], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 518, "seek": 211622, "start": 2129.8199999999997, "end": 2133.98, "text": " is also interesting about s-curves is that there tends to be paradigm shifts like have you ever", "tokens": [51044, 307, 611, 1880, 466, 262, 12, 14112, 977, 307, 300, 456, 12258, 281, 312, 24709, 19201, 411, 362, 291, 1562, 51252], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 519, "seek": 211622, "start": 2133.98, "end": 2140.06, "text": " read Singularity is Near no I haven't yeah so this is the Ray Kurzweil book from like 2004", "tokens": [51252, 1401, 7474, 1040, 507, 307, 22200, 572, 286, 2378, 380, 1338, 370, 341, 307, 264, 10883, 45307, 826, 388, 1446, 490, 411, 15817, 51556], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 520, "seek": 211622, "start": 2140.06, "end": 2145.4199999999996, "text": " something and I always thought just based on the reputation it's going to be kind of a crazy book", "tokens": [51556, 746, 293, 286, 1009, 1194, 445, 2361, 322, 264, 13061, 309, 311, 516, 281, 312, 733, 295, 257, 3219, 1446, 51824], "temperature": 0.0, "avg_logprob": -0.11123815003563375, "compression_ratio": 1.7854889589905363, "no_speech_prob": 0.0016478225588798523}, {"id": 521, "seek": 214542, "start": 2145.42, "end": 2150.14, "text": " but if you actually read it it's the most dry boring reading you'll ever do and it's basically", "tokens": [50364, 457, 498, 291, 767, 1401, 309, 309, 311, 264, 881, 4016, 9989, 3760, 291, 603, 1562, 360, 293, 309, 311, 1936, 50600], "temperature": 0.0, "avg_logprob": -0.06244995459070746, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0001634167565498501}, {"id": 522, "seek": 214542, "start": 2150.14, "end": 2156.54, "text": " just curve after curve of different industries within computing showing how the performance has", "tokens": [50600, 445, 7605, 934, 7605, 295, 819, 13284, 1951, 15866, 4099, 577, 264, 3389, 575, 50920], "temperature": 0.0, "avg_logprob": -0.06244995459070746, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0001634167565498501}, {"id": 523, "seek": 214542, "start": 2156.54, "end": 2162.06, "text": " changed over time and it's you know basically the conclusion he comes to is that there's this", "tokens": [50920, 3105, 670, 565, 293, 309, 311, 291, 458, 1936, 264, 10063, 415, 1487, 281, 307, 300, 456, 311, 341, 51196], "temperature": 0.0, "avg_logprob": -0.06244995459070746, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0001634167565498501}, {"id": 524, "seek": 214542, "start": 2162.06, "end": 2167.02, "text": " repeated pattern that seems to happen across you know memory across number of transistors on the", "tokens": [51196, 10477, 5102, 300, 2544, 281, 1051, 2108, 291, 458, 4675, 2108, 1230, 295, 1145, 46976, 322, 264, 51444], "temperature": 0.0, "avg_logprob": -0.06244995459070746, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0001634167565498501}, {"id": 525, "seek": 214542, "start": 2167.02, "end": 2172.2200000000003, "text": " chip you know etc etc where you kind of have an s-curve of the current paradigm and then you have", "tokens": [51444, 11409, 291, 458, 5183, 5183, 689, 291, 733, 295, 362, 364, 262, 12, 14112, 303, 295, 264, 2190, 24709, 293, 550, 291, 362, 51704], "temperature": 0.0, "avg_logprob": -0.06244995459070746, "compression_ratio": 1.8352490421455938, "no_speech_prob": 0.0001634167565498501}, {"id": 526, "seek": 217222, "start": 2172.2999999999997, "end": 2179.58, "text": " paradigm shift and that example he talks about is you know thinking about let's talk about CDs", "tokens": [50368, 24709, 5513, 293, 300, 1365, 415, 6686, 466, 307, 291, 458, 1953, 466, 718, 311, 751, 466, 45257, 50732], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 527, "seek": 217222, "start": 2179.58, "end": 2183.5, "text": " right so you talk about great you know CD adoption it's like you know it's great s-curve it's", "tokens": [50732, 558, 370, 291, 751, 466, 869, 291, 458, 6743, 19215, 309, 311, 411, 291, 458, 309, 311, 869, 262, 12, 14112, 303, 309, 311, 50928], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 528, "seek": 217222, "start": 2183.5, "end": 2187.3399999999997, "text": " suddenly everywhere it's like everyone's got a CD player like it's just the technology of the day", "tokens": [50928, 5800, 5315, 309, 311, 411, 1518, 311, 658, 257, 6743, 4256, 411, 309, 311, 445, 264, 2899, 295, 264, 786, 51120], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 529, "seek": 217222, "start": 2187.8999999999996, "end": 2191.5, "text": " and people get really excited about doing more of the same thing it's like Blu-ray that's the thing", "tokens": [51148, 293, 561, 483, 534, 2919, 466, 884, 544, 295, 264, 912, 551, 309, 311, 411, 2177, 84, 12, 3458, 300, 311, 264, 551, 51328], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 530, "seek": 217222, "start": 2191.5, "end": 2196.4599999999996, "text": " you know and so then everyone starts investing in Blu-rays and somehow it just doesn't take off", "tokens": [51328, 291, 458, 293, 370, 550, 1518, 3719, 10978, 294, 2177, 84, 12, 36212, 293, 6063, 309, 445, 1177, 380, 747, 766, 51576], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 531, "seek": 217222, "start": 2196.4599999999996, "end": 2199.74, "text": " and it's because it's just more of the same and it's like you know it's not backwards compatible", "tokens": [51576, 293, 309, 311, 570, 309, 311, 445, 544, 295, 264, 912, 293, 309, 311, 411, 291, 458, 309, 311, 406, 12204, 18218, 51740], "temperature": 0.0, "avg_logprob": -0.07787864980563311, "compression_ratio": 2.0244755244755246, "no_speech_prob": 0.001501000253483653}, {"id": 532, "seek": 219974, "start": 2199.74, "end": 2203.58, "text": " and so it's just not really worth it but the real paradigm shift was streaming right suddenly", "tokens": [50364, 293, 370, 309, 311, 445, 406, 534, 3163, 309, 457, 264, 957, 24709, 5513, 390, 11791, 558, 5800, 50556], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 533, "seek": 219974, "start": 2203.58, "end": 2207.4199999999996, "text": " you have this new adoption curve this new s-curve that just is this like totally different way", "tokens": [50556, 291, 362, 341, 777, 19215, 7605, 341, 777, 262, 12, 14112, 303, 300, 445, 307, 341, 411, 3879, 819, 636, 50748], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 534, "seek": 219974, "start": 2207.4199999999996, "end": 2210.54, "text": " and the way we got to fast computers was basically five different paradigm shifts", "tokens": [50748, 293, 264, 636, 321, 658, 281, 2370, 10807, 390, 1936, 1732, 819, 24709, 19201, 50904], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 535, "seek": 219974, "start": 2210.54, "end": 2214.3799999999997, "text": " across a hundred years and so I think that that's maybe a story here too which is like", "tokens": [50904, 2108, 257, 3262, 924, 293, 370, 286, 519, 300, 300, 311, 1310, 257, 1657, 510, 886, 597, 307, 411, 51096], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 536, "seek": 219974, "start": 2214.3799999999997, "end": 2218.14, "text": " there's gonna be an s-curve in what we're doing right now and that there will be a paradigm shift", "tokens": [51096, 456, 311, 799, 312, 364, 262, 12, 14112, 303, 294, 437, 321, 434, 884, 558, 586, 293, 300, 456, 486, 312, 257, 24709, 5513, 51284], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 537, "seek": 219974, "start": 2218.14, "end": 2222.14, "text": " when you hit it and I think that that again speaks to the ingenuity of humans but I think there's", "tokens": [51284, 562, 291, 2045, 309, 293, 286, 519, 300, 300, 797, 10789, 281, 264, 21600, 21757, 295, 6255, 457, 286, 519, 456, 311, 51484], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 538, "seek": 219974, "start": 2222.14, "end": 2229.2599999999998, "text": " also a second thing where my other answer is to some extent it doesn't matter because the thing", "tokens": [51484, 611, 257, 1150, 551, 689, 452, 661, 1867, 307, 281, 512, 8396, 309, 1177, 380, 1871, 570, 264, 551, 51840], "temperature": 0.0, "avg_logprob": -0.05909353808352822, "compression_ratio": 1.9373134328358208, "no_speech_prob": 0.0008294491562992334}, {"id": 539, "seek": 222926, "start": 2229.26, "end": 2234.2200000000003, "text": " about this field is that it's useful now right that kind of the goal that I think we've always", "tokens": [50364, 466, 341, 2519, 307, 300, 309, 311, 4420, 586, 558, 300, 733, 295, 264, 3387, 300, 286, 519, 321, 600, 1009, 50612], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 540, "seek": 222926, "start": 2234.2200000000003, "end": 2239.1000000000004, "text": " had for AI was to actually make us so computers are just way more helpful like you think about what", "tokens": [50612, 632, 337, 7318, 390, 281, 767, 652, 505, 370, 10807, 366, 445, 636, 544, 4961, 411, 291, 519, 466, 437, 50856], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 541, "seek": 222926, "start": 2239.1000000000004, "end": 2242.78, "text": " computers have done for humanity right like how many problems they've helped us solve they've", "tokens": [50856, 10807, 362, 1096, 337, 10243, 558, 411, 577, 867, 2740, 436, 600, 4254, 505, 5039, 436, 600, 51040], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 542, "seek": 222926, "start": 2242.78, "end": 2246.5400000000004, "text": " created new problems as well but I think that on net that they've helped us solve way more problems", "tokens": [51040, 2942, 777, 2740, 382, 731, 457, 286, 519, 300, 322, 2533, 300, 436, 600, 4254, 505, 5039, 636, 544, 2740, 51228], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 543, "seek": 222926, "start": 2246.5400000000004, "end": 2250.5400000000004, "text": " than they've created and I think they've kind of just changed the nature of how we interact with", "tokens": [51228, 813, 436, 600, 2942, 293, 286, 519, 436, 600, 733, 295, 445, 3105, 264, 3687, 295, 577, 321, 4648, 365, 51428], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 544, "seek": 222926, "start": 2250.5400000000004, "end": 2254.78, "text": " each other about how you know like it's just like hard to get lost anymore right you just", "tokens": [51428, 1184, 661, 466, 577, 291, 458, 411, 309, 311, 445, 411, 1152, 281, 483, 2731, 3602, 558, 291, 445, 51640], "temperature": 0.0, "avg_logprob": -0.06254558708831554, "compression_ratio": 2.0034843205574915, "no_speech_prob": 0.0016479117330163717}, {"id": 545, "seek": 225478, "start": 2254.78, "end": 2259.02, "text": " pull out google maps I think there's really amazing problems that are now within our reach", "tokens": [50364, 2235, 484, 20742, 11317, 286, 519, 456, 311, 534, 2243, 2740, 300, 366, 586, 1951, 527, 2524, 50576], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 546, "seek": 225478, "start": 2259.02, "end": 2263.7400000000002, "text": " that just would not have been otherwise and I think that AI like we're starting to crack that", "tokens": [50576, 300, 445, 576, 406, 362, 668, 5911, 293, 286, 519, 300, 7318, 411, 321, 434, 2891, 281, 6226, 300, 50812], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 547, "seek": 225478, "start": 2263.7400000000002, "end": 2267.9, "text": " nut we're starting to be able to you know like it's I think it's kind of interesting you could", "tokens": [50812, 5393, 321, 434, 2891, 281, 312, 1075, 281, 291, 458, 411, 309, 311, 286, 519, 309, 311, 733, 295, 1880, 291, 727, 51020], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 548, "seek": 225478, "start": 2267.9, "end": 2274.2200000000003, "text": " get a co-pilot you know which which we we power we have the models that power it and that the way", "tokens": [51020, 483, 257, 598, 12, 79, 31516, 291, 458, 597, 597, 321, 321, 1347, 321, 362, 264, 5245, 300, 1347, 309, 293, 300, 264, 636, 51336], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 549, "seek": 225478, "start": 2274.2200000000003, "end": 2278.3, "text": " that that is useful to people is that provides very low latency suggestions right it's basically", "tokens": [51336, 300, 300, 307, 4420, 281, 561, 307, 300, 6417, 588, 2295, 27043, 13396, 558, 309, 311, 1936, 51540], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 550, "seek": 225478, "start": 2278.3, "end": 2283.02, "text": " an autocomplete for code and that you know there's a very strict latency budget you know if you're", "tokens": [51540, 364, 45833, 298, 17220, 337, 3089, 293, 300, 291, 458, 456, 311, 257, 588, 10910, 27043, 4706, 291, 458, 498, 291, 434, 51776], "temperature": 0.0, "avg_logprob": -0.08244753943549263, "compression_ratio": 1.91, "no_speech_prob": 0.008058054372668266}, {"id": 551, "seek": 228302, "start": 2283.02, "end": 2287.74, "text": " more than you know 1500 milliseconds to get a autocomplete suggestion it's worthless like no", "tokens": [50364, 544, 813, 291, 458, 22671, 34184, 281, 483, 257, 45833, 298, 17220, 16541, 309, 311, 34857, 411, 572, 50600], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 552, "seek": 228302, "start": 2287.74, "end": 2293.66, "text": " one wants that you've already moved on but I think that what we really want to build the next", "tokens": [50600, 472, 2738, 300, 291, 600, 1217, 4259, 322, 457, 286, 519, 300, 437, 321, 534, 528, 281, 1322, 264, 958, 50896], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 553, "seek": 228302, "start": 2293.66, "end": 2299.1, "text": " phase is machines that help you produce that are able to produce artifacts that are materially", "tokens": [50896, 5574, 307, 8379, 300, 854, 291, 5258, 300, 366, 1075, 281, 5258, 24617, 300, 366, 2389, 2270, 51168], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 554, "seek": 228302, "start": 2299.1, "end": 2303.1, "text": " interesting on their own so not just interesting because it's like a fast suggestion to you but", "tokens": [51168, 1880, 322, 641, 1065, 370, 406, 445, 1880, 570, 309, 311, 411, 257, 2370, 16541, 281, 291, 457, 51368], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 555, "seek": 228302, "start": 2303.1, "end": 2307.2599999999998, "text": " because it's actually a quality answer and you're starting to see if you talk to our current gbt", "tokens": [51368, 570, 309, 311, 767, 257, 3125, 1867, 293, 291, 434, 2891, 281, 536, 498, 291, 751, 281, 527, 2190, 290, 4517, 51576], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 556, "seek": 228302, "start": 2307.2599999999998, "end": 2311.1, "text": " iteration you can ask it to write some poems and it writes way better poetry than I can", "tokens": [51576, 24784, 291, 393, 1029, 309, 281, 2464, 512, 24014, 293, 309, 13657, 636, 1101, 15155, 813, 286, 393, 51768], "temperature": 0.0, "avg_logprob": -0.06513819618830605, "compression_ratio": 1.7955271565495208, "no_speech_prob": 0.0003053051477763802}, {"id": 557, "seek": 231110, "start": 2311.8199999999997, "end": 2319.8199999999997, "text": " it actually wrote a poem for my wife that made us both cry like you know yeah I I cannot do that", "tokens": [50400, 309, 767, 4114, 257, 13065, 337, 452, 3836, 300, 1027, 505, 1293, 3305, 411, 291, 458, 1338, 286, 286, 2644, 360, 300, 50800], "temperature": 0.0, "avg_logprob": -0.06512221137245933, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.00017950266192201525}, {"id": 558, "seek": 231110, "start": 2319.8199999999997, "end": 2325.66, "text": " myself but now I can you know by partnering with this with this machine and I think that", "tokens": [50800, 2059, 457, 586, 286, 393, 291, 458, 538, 31290, 365, 341, 365, 341, 3479, 293, 286, 519, 300, 51092], "temperature": 0.0, "avg_logprob": -0.06512221137245933, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.00017950266192201525}, {"id": 559, "seek": 231110, "start": 2325.66, "end": 2330.14, "text": " that's the real story right is really trying to get these tools out and everywhere and yeah you", "tokens": [51092, 300, 311, 264, 957, 1657, 558, 307, 534, 1382, 281, 483, 613, 3873, 484, 293, 5315, 293, 1338, 291, 51316], "temperature": 0.0, "avg_logprob": -0.06512221137245933, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.00017950266192201525}, {"id": 560, "seek": 231110, "start": 2330.14, "end": 2335.02, "text": " know if what we're doing right now stalls out I don't think that removes the value from what we're", "tokens": [51316, 458, 498, 437, 321, 434, 884, 558, 586, 50248, 484, 286, 500, 380, 519, 300, 30445, 264, 2158, 490, 437, 321, 434, 51560], "temperature": 0.0, "avg_logprob": -0.06512221137245933, "compression_ratio": 1.7757009345794392, "no_speech_prob": 0.00017950266192201525}, {"id": 561, "seek": 233502, "start": 2335.02, "end": 2341.02, "text": " able to create yeah by the way it's depressing that the the attention span of most engineers is", "tokens": [50364, 1075, 281, 1884, 1338, 538, 264, 636, 309, 311, 36355, 300, 264, 264, 3202, 16174, 295, 881, 11955, 307, 50664], "temperature": 0.0, "avg_logprob": -0.11073458054486443, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.004259907174855471}, {"id": 562, "seek": 233502, "start": 2341.02, "end": 2349.34, "text": " only 1500 seconds but you know it is what it is I what uh what if anything you know I think", "tokens": [50664, 787, 22671, 3949, 457, 291, 458, 309, 307, 437, 309, 307, 286, 437, 2232, 437, 498, 1340, 291, 458, 286, 519, 51080], "temperature": 0.0, "avg_logprob": -0.11073458054486443, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.004259907174855471}, {"id": 563, "seek": 233502, "start": 2350.06, "end": 2355.2599999999998, "text": " one of the things that if I recall spurred you to to work on opening I was was sort of", "tokens": [51116, 472, 295, 264, 721, 300, 498, 286, 9901, 35657, 986, 291, 281, 281, 589, 322, 5193, 286, 390, 390, 1333, 295, 51376], "temperature": 0.0, "avg_logprob": -0.11073458054486443, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.004259907174855471}, {"id": 564, "seek": 233502, "start": 2356.14, "end": 2360.78, "text": " also being concerned about the sort of potential negative consequences of of the technology", "tokens": [51420, 611, 885, 5922, 466, 264, 1333, 295, 3995, 3671, 10098, 295, 295, 264, 2899, 51652], "temperature": 0.0, "avg_logprob": -0.11073458054486443, "compression_ratio": 1.6944444444444444, "no_speech_prob": 0.004259907174855471}, {"id": 565, "seek": 236078, "start": 2360.78, "end": 2365.9, "text": " um what at this point looking forward what are your sort of biggest concerns or what are you", "tokens": [50364, 1105, 437, 412, 341, 935, 1237, 2128, 437, 366, 428, 1333, 295, 3880, 7389, 420, 437, 366, 291, 50620], "temperature": 0.0, "avg_logprob": -0.08001090408465185, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0012063359608873725}, {"id": 566, "seek": 236078, "start": 2365.9, "end": 2370.3, "text": " afraid of with with artificial intelligence that you sort of urge everyone in the field to sort of", "tokens": [50620, 4638, 295, 365, 365, 11677, 7599, 300, 291, 1333, 295, 19029, 1518, 294, 264, 2519, 281, 1333, 295, 50840], "temperature": 0.0, "avg_logprob": -0.08001090408465185, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0012063359608873725}, {"id": 567, "seek": 236078, "start": 2370.3, "end": 2376.5400000000004, "text": " help avoid yeah so I think that one thing that's very interesting about AI is that you know if you", "tokens": [50840, 854, 5042, 1338, 370, 286, 519, 300, 472, 551, 300, 311, 588, 1880, 466, 7318, 307, 300, 291, 458, 498, 291, 51152], "temperature": 0.0, "avg_logprob": -0.08001090408465185, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0012063359608873725}, {"id": 568, "seek": 236078, "start": 2376.5400000000004, "end": 2381.1800000000003, "text": " talked to certainly you know 10 years ago if you looked at every article about it you talked to", "tokens": [51152, 2825, 281, 3297, 291, 458, 1266, 924, 2057, 498, 291, 2956, 412, 633, 7222, 466, 309, 291, 2825, 281, 51384], "temperature": 0.0, "avg_logprob": -0.08001090408465185, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0012063359608873725}, {"id": 569, "seek": 236078, "start": 2381.1800000000003, "end": 2385.1000000000004, "text": " someone on the street terminator is the main thing that comes up right so I think there's always been", "tokens": [51384, 1580, 322, 264, 4838, 10761, 1639, 307, 264, 2135, 551, 300, 1487, 493, 558, 370, 286, 519, 456, 311, 1009, 668, 51580], "temperature": 0.0, "avg_logprob": -0.08001090408465185, "compression_ratio": 1.876923076923077, "no_speech_prob": 0.0012063359608873725}, {"id": 570, "seek": 238510, "start": 2385.18, "end": 2391.8199999999997, "text": " this feeling around AI that is sort of you know that there's an element of fear mixed with the", "tokens": [50368, 341, 2633, 926, 7318, 300, 307, 1333, 295, 291, 458, 300, 456, 311, 364, 4478, 295, 4240, 7467, 365, 264, 50700], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 571, "seek": 238510, "start": 2391.8199999999997, "end": 2394.94, "text": " you know sometimes people don't see any potential or sometimes you know they realize that there is", "tokens": [50700, 291, 458, 2171, 561, 500, 380, 536, 604, 3995, 420, 2171, 291, 458, 436, 4325, 300, 456, 307, 50856], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 572, "seek": 238510, "start": 2394.94, "end": 2400.38, "text": " the potential but like really trying to figure out and navigate it and I think that that picture", "tokens": [50856, 264, 3995, 457, 411, 534, 1382, 281, 2573, 484, 293, 12350, 309, 293, 286, 519, 300, 300, 3036, 51128], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 573, "seek": 238510, "start": 2400.38, "end": 2404.06, "text": " the specifics you know I think that that we're starting to see a little bit more but I think", "tokens": [51128, 264, 28454, 291, 458, 286, 519, 300, 300, 321, 434, 2891, 281, 536, 257, 707, 857, 544, 457, 286, 519, 51312], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 574, "seek": 238510, "start": 2404.06, "end": 2407.9, "text": " the high level picture of this is technology that's very powerful and it can be powerful in", "tokens": [51312, 264, 1090, 1496, 3036, 295, 341, 307, 2899, 300, 311, 588, 4005, 293, 309, 393, 312, 4005, 294, 51504], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 575, "seek": 238510, "start": 2407.9, "end": 2412.38, "text": " positive ways and negative ways um I think is extremely correct and I think it's very important", "tokens": [51504, 3353, 2098, 293, 3671, 2098, 1105, 286, 519, 307, 4664, 3006, 293, 286, 519, 309, 311, 588, 1021, 51728], "temperature": 0.0, "avg_logprob": -0.04778833994789729, "compression_ratio": 1.9895470383275262, "no_speech_prob": 0.006093950010836124}, {"id": 576, "seek": 241238, "start": 2412.38, "end": 2416.2200000000003, "text": " not just to be you know starry eyed optimist everything's just going to work itself out", "tokens": [50364, 406, 445, 281, 312, 291, 458, 3543, 627, 9817, 292, 5028, 468, 1203, 311, 445, 516, 281, 589, 2564, 484, 50556], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 577, "seek": 241238, "start": 2416.2200000000003, "end": 2421.9, "text": " but also not to be you know sort of doomsday like everything is terrible and you know humanity is", "tokens": [50556, 457, 611, 406, 281, 312, 291, 458, 1333, 295, 360, 4785, 810, 411, 1203, 307, 6237, 293, 291, 458, 10243, 307, 50840], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 578, "seek": 241238, "start": 2421.9, "end": 2425.98, "text": " over because I don't think that's at all true I think this technology can be the the best thing", "tokens": [50840, 670, 570, 286, 500, 380, 519, 300, 311, 412, 439, 2074, 286, 519, 341, 2899, 393, 312, 264, 264, 1151, 551, 51044], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 579, "seek": 241238, "start": 2425.98, "end": 2429.98, "text": " that is the way we've ever created and help us be the best versions of ourselves but I think", "tokens": [51044, 300, 307, 264, 636, 321, 600, 1562, 2942, 293, 854, 505, 312, 264, 1151, 9606, 295, 4175, 457, 286, 519, 51244], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 580, "seek": 241238, "start": 2429.98, "end": 2435.02, "text": " that it requires very careful navigating of the space and it's not something that just is for you", "tokens": [51244, 300, 309, 7029, 588, 5026, 32054, 295, 264, 1901, 293, 309, 311, 406, 746, 300, 445, 307, 337, 291, 51496], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 581, "seek": 241238, "start": 2435.02, "end": 2438.38, "text": " know companies of Silicon Valley to figure out I think it's it's really all of humanity kind of", "tokens": [51496, 458, 3431, 295, 25351, 10666, 281, 2573, 484, 286, 519, 309, 311, 309, 311, 534, 439, 295, 10243, 733, 295, 51664], "temperature": 0.0, "avg_logprob": -0.0897658383404767, "compression_ratio": 1.880794701986755, "no_speech_prob": 0.002049570670351386}, {"id": 582, "seek": 243838, "start": 2438.38, "end": 2443.6600000000003, "text": " challenge um so I think that we're going to go through different phases I think that that right", "tokens": [50364, 3430, 1105, 370, 286, 519, 300, 321, 434, 516, 281, 352, 807, 819, 18764, 286, 519, 300, 300, 558, 50628], "temperature": 0.0, "avg_logprob": -0.09803962707519531, "compression_ratio": 1.8735177865612649, "no_speech_prob": 0.0005525780725292861}, {"id": 583, "seek": 243838, "start": 2443.6600000000003, "end": 2448.54, "text": " now I you know we're kind of starting to build systems where that I you know you think about", "tokens": [50628, 586, 286, 291, 458, 321, 434, 733, 295, 2891, 281, 1322, 3652, 689, 300, 286, 291, 458, 291, 519, 466, 50872], "temperature": 0.0, "avg_logprob": -0.09803962707519531, "compression_ratio": 1.8735177865612649, "no_speech_prob": 0.0005525780725292861}, {"id": 584, "seek": 243838, "start": 2449.26, "end": 2455.02, "text": " misuse is the most clear problem and the systems themselves are still not very powerful right", "tokens": [50908, 3346, 438, 307, 264, 881, 1850, 1154, 293, 264, 3652, 2969, 366, 920, 406, 588, 4005, 558, 51196], "temperature": 0.0, "avg_logprob": -0.09803962707519531, "compression_ratio": 1.8735177865612649, "no_speech_prob": 0.0005525780725292861}, {"id": 585, "seek": 243838, "start": 2455.02, "end": 2459.5, "text": " that the kinds of things you worry about for GPT-3 are you know important problems you think", "tokens": [51196, 300, 264, 3685, 295, 721, 291, 3292, 466, 337, 26039, 51, 12, 18, 366, 291, 458, 1021, 2740, 291, 519, 51420], "temperature": 0.0, "avg_logprob": -0.09803962707519531, "compression_ratio": 1.8735177865612649, "no_speech_prob": 0.0005525780725292861}, {"id": 586, "seek": 243838, "start": 2459.5, "end": 2464.1400000000003, "text": " about bias and representation you think about the system sort of you know sort of saying the wrong", "tokens": [51420, 466, 12577, 293, 10290, 291, 519, 466, 264, 1185, 1333, 295, 291, 458, 1333, 295, 1566, 264, 2085, 51652], "temperature": 0.0, "avg_logprob": -0.09803962707519531, "compression_ratio": 1.8735177865612649, "no_speech_prob": 0.0005525780725292861}, {"id": 587, "seek": 246414, "start": 2464.14, "end": 2468.2999999999997, "text": " thing you know but but its action is really in your mind right it's it's sort of words on a page", "tokens": [50364, 551, 291, 458, 457, 457, 1080, 3069, 307, 534, 294, 428, 1575, 558, 309, 311, 309, 311, 1333, 295, 2283, 322, 257, 3028, 50572], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 588, "seek": 246414, "start": 2468.2999999999997, "end": 2472.3799999999997, "text": " that then you know words on a page are very powerful but that they don't themselves have", "tokens": [50572, 300, 550, 291, 458, 2283, 322, 257, 3028, 366, 588, 4005, 457, 300, 436, 500, 380, 2969, 362, 50776], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 589, "seek": 246414, "start": 2472.3799999999997, "end": 2476.46, "text": " direct action in the world but you think about something like codex our code writing system", "tokens": [50776, 2047, 3069, 294, 264, 1002, 457, 291, 519, 466, 746, 411, 3089, 87, 527, 3089, 3579, 1185, 50980], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 590, "seek": 246414, "start": 2476.46, "end": 2481.5, "text": " which is a little bit more like a robot because it has it emits code and if you were to just execute", "tokens": [50980, 597, 307, 257, 707, 857, 544, 411, 257, 7881, 570, 309, 575, 309, 846, 1208, 3089, 293, 498, 291, 645, 281, 445, 14483, 51232], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 591, "seek": 246414, "start": 2481.5, "end": 2486.7, "text": " that code directly it can actually directly have actuators into the world and making sure that that's", "tokens": [51232, 300, 3089, 3838, 309, 393, 767, 3838, 362, 34964, 3391, 666, 264, 1002, 293, 1455, 988, 300, 300, 311, 51492], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 592, "seek": 246414, "start": 2486.7, "end": 2491.5, "text": " aligned and doing the right kinds of things not having buggy code and not writing viruses and that", "tokens": [51492, 17962, 293, 884, 264, 558, 3685, 295, 721, 406, 1419, 7426, 1480, 3089, 293, 406, 3579, 21785, 293, 300, 51732], "temperature": 0.0, "avg_logprob": -0.07446010847737018, "compression_ratio": 1.9429530201342282, "no_speech_prob": 0.002550276694819331}, {"id": 593, "seek": 249150, "start": 2491.5, "end": 2495.26, "text": " kind of thing like that's really important and so I think that that figuring out what values go", "tokens": [50364, 733, 295, 551, 411, 300, 311, 534, 1021, 293, 370, 286, 519, 300, 300, 15213, 484, 437, 4190, 352, 50552], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 594, "seek": 249150, "start": 2495.26, "end": 2499.02, "text": " into this these machines and that they're operating according to those values that's going to be very", "tokens": [50552, 666, 341, 613, 8379, 293, 300, 436, 434, 7447, 4650, 281, 729, 4190, 300, 311, 516, 281, 312, 588, 50740], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 595, "seek": 249150, "start": 2499.02, "end": 2505.02, "text": " very critical figure out how to avoid misuse and sort of regulate that both at a sort of societal", "tokens": [50740, 588, 4924, 2573, 484, 577, 281, 5042, 3346, 438, 293, 1333, 295, 24475, 300, 1293, 412, 257, 1333, 295, 33472, 51040], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 596, "seek": 249150, "start": 2505.02, "end": 2510.7, "text": " level at a you know technical level all of that is very important and I and I do think that there", "tokens": [51040, 1496, 412, 257, 291, 458, 6191, 1496, 439, 295, 300, 307, 588, 1021, 293, 286, 293, 286, 360, 519, 300, 456, 51324], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 597, "seek": 249150, "start": 2510.7, "end": 2515.26, "text": " is also a point where the technology itself you have to think about that it's going to be extremely", "tokens": [51324, 307, 611, 257, 935, 689, 264, 2899, 2564, 291, 362, 281, 519, 466, 300, 309, 311, 516, 281, 312, 4664, 51552], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 598, "seek": 249150, "start": 2515.26, "end": 2520.54, "text": " powerful and you think about a system that's you know sort of talking to lots of humans and", "tokens": [51552, 4005, 293, 291, 519, 466, 257, 1185, 300, 311, 291, 458, 1333, 295, 1417, 281, 3195, 295, 6255, 293, 51816], "temperature": 0.0, "avg_logprob": -0.08204052665016869, "compression_ratio": 2.0454545454545454, "no_speech_prob": 0.0006460053264163435}, {"id": 599, "seek": 252054, "start": 2520.62, "end": 2523.74, "text": " is operating unchecked that's the kind of thing that you should worry about you know we already", "tokens": [50368, 307, 7447, 46672, 292, 300, 311, 264, 733, 295, 551, 300, 291, 820, 3292, 466, 291, 458, 321, 1217, 50524], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 600, "seek": 252054, "start": 2523.74, "end": 2528.46, "text": " worry about that think about the companies right that lots of people are using this you know social", "tokens": [50524, 3292, 466, 300, 519, 466, 264, 3431, 558, 300, 3195, 295, 561, 366, 1228, 341, 291, 458, 2093, 50760], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 601, "seek": 252054, "start": 2528.46, "end": 2532.86, "text": " media platform or you know any of the technologies that we use and how much influence those can have", "tokens": [50760, 3021, 3663, 420, 291, 458, 604, 295, 264, 7943, 300, 321, 764, 293, 577, 709, 6503, 729, 393, 362, 50980], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 602, "seek": 252054, "start": 2532.86, "end": 2539.74, "text": " in the world and those aren't systems that have you know sort of deep sort of behaviors that are", "tokens": [50980, 294, 264, 1002, 293, 729, 3212, 380, 3652, 300, 362, 291, 458, 1333, 295, 2452, 1333, 295, 15501, 300, 366, 51324], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 603, "seek": 252054, "start": 2539.74, "end": 2544.3, "text": " emergent from from from what they've learned and so I think that that figuring out the technical", "tokens": [51324, 4345, 6930, 490, 490, 490, 437, 436, 600, 3264, 293, 370, 286, 519, 300, 300, 15213, 484, 264, 6191, 51552], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 604, "seek": 252054, "start": 2544.3, "end": 2549.5, "text": " controls to make sure that these systems remain in service of humanity and sort of to", "tokens": [51552, 9003, 281, 652, 988, 300, 613, 3652, 6222, 294, 2643, 295, 10243, 293, 1333, 295, 281, 51812], "temperature": 0.0, "avg_logprob": -0.06939827728271485, "compression_ratio": 1.952542372881356, "no_speech_prob": 0.000487613637233153}, {"id": 605, "seek": 254950, "start": 2549.58, "end": 2555.34, "text": " actually empower and accelerate all of us that I think is is also a very critical thing so it's", "tokens": [50368, 767, 11071, 293, 21341, 439, 295, 505, 300, 286, 519, 307, 307, 611, 257, 588, 4924, 551, 370, 309, 311, 50656], "temperature": 0.0, "avg_logprob": -0.06626131298305753, "compression_ratio": 1.8700787401574803, "no_speech_prob": 4.329935836722143e-05}, {"id": 606, "seek": 254950, "start": 2555.34, "end": 2559.34, "text": " kind of this like a ramping set of stakes and making sure that we're building systems that are", "tokens": [50656, 733, 295, 341, 411, 257, 12428, 278, 992, 295, 28429, 293, 1455, 988, 300, 321, 434, 2390, 3652, 300, 366, 50856], "temperature": 0.0, "avg_logprob": -0.06626131298305753, "compression_ratio": 1.8700787401574803, "no_speech_prob": 4.329935836722143e-05}, {"id": 607, "seek": 254950, "start": 2559.34, "end": 2564.22, "text": " aligned with with our values and figuring out what that even means like what what is the values", "tokens": [50856, 17962, 365, 365, 527, 4190, 293, 15213, 484, 437, 300, 754, 1355, 411, 437, 437, 307, 264, 4190, 51100], "temperature": 0.0, "avg_logprob": -0.06626131298305753, "compression_ratio": 1.8700787401574803, "no_speech_prob": 4.329935836722143e-05}, {"id": 608, "seek": 254950, "start": 2564.22, "end": 2567.9, "text": " of humanity that should be in the system and that I think is not going to be an easy problem", "tokens": [51100, 295, 10243, 300, 820, 312, 294, 264, 1185, 293, 300, 286, 519, 307, 406, 516, 281, 312, 364, 1858, 1154, 51284], "temperature": 0.0, "avg_logprob": -0.06626131298305753, "compression_ratio": 1.8700787401574803, "no_speech_prob": 4.329935836722143e-05}, {"id": 609, "seek": 254950, "start": 2568.78, "end": 2574.62, "text": " you know one question and this this may be the last question that I have for you is sort of one", "tokens": [51328, 291, 458, 472, 1168, 293, 341, 341, 815, 312, 264, 1036, 1168, 300, 286, 362, 337, 291, 307, 1333, 295, 472, 51620], "temperature": 0.0, "avg_logprob": -0.06626131298305753, "compression_ratio": 1.8700787401574803, "no_speech_prob": 4.329935836722143e-05}, {"id": 610, "seek": 257462, "start": 2574.62, "end": 2581.9, "text": " of the thing one of the conclusions of if the technology such that scale continues to be the", "tokens": [50364, 295, 264, 551, 472, 295, 264, 22865, 295, 498, 264, 2899, 1270, 300, 4373, 6515, 281, 312, 264, 50728], "temperature": 0.0, "avg_logprob": -0.06527703148978097, "compression_ratio": 1.952, "no_speech_prob": 0.00169751129578799}, {"id": 611, "seek": 257462, "start": 2581.9, "end": 2586.2999999999997, "text": " the sort of one of the more important things you know scale whether it's data or better algorithms", "tokens": [50728, 264, 1333, 295, 472, 295, 264, 544, 1021, 721, 291, 458, 4373, 1968, 309, 311, 1412, 420, 1101, 14642, 50948], "temperature": 0.0, "avg_logprob": -0.06527703148978097, "compression_ratio": 1.952, "no_speech_prob": 0.00169751129578799}, {"id": 612, "seek": 257462, "start": 2586.2999999999997, "end": 2593.66, "text": " or scale compute then it it the technology itself will tend towards sort of this game theoretical", "tokens": [50948, 420, 4373, 14722, 550, 309, 309, 264, 2899, 2564, 486, 3928, 3030, 1333, 295, 341, 1216, 20864, 51316], "temperature": 0.0, "avg_logprob": -0.06527703148978097, "compression_ratio": 1.952, "no_speech_prob": 0.00169751129578799}, {"id": 613, "seek": 257462, "start": 2593.66, "end": 2598.7799999999997, "text": " proliferation mode where it's sort of like people are going to compete and you see some of this today", "tokens": [51316, 24398, 44987, 4391, 689, 309, 311, 1333, 295, 411, 561, 366, 516, 281, 11831, 293, 291, 536, 512, 295, 341, 965, 51572], "temperature": 0.0, "avg_logprob": -0.06527703148978097, "compression_ratio": 1.952, "no_speech_prob": 0.00169751129578799}, {"id": 614, "seek": 257462, "start": 2598.7799999999997, "end": 2602.06, "text": " even with the large tech companies and you guys obviously people are going to compete to sort of", "tokens": [51572, 754, 365, 264, 2416, 7553, 3431, 293, 291, 1074, 2745, 561, 366, 516, 281, 11831, 281, 1333, 295, 51736], "temperature": 0.0, "avg_logprob": -0.06527703148978097, "compression_ratio": 1.952, "no_speech_prob": 0.00169751129578799}, {"id": 615, "seek": 260206, "start": 2602.06, "end": 2606.62, "text": " build the bigger supercomputers that have the better performance and you have the bigger supercomputer", "tokens": [50364, 1322, 264, 3801, 27839, 2582, 433, 300, 362, 264, 1101, 3389, 293, 291, 362, 264, 3801, 36708, 50592], "temperature": 0.0, "avg_logprob": -0.07021912904543297, "compression_ratio": 2.108108108108108, "no_speech_prob": 0.002468827646225691}, {"id": 616, "seek": 260206, "start": 2606.62, "end": 2610.2999999999997, "text": " you have sort of supremacy over the other supercomputers and sort of there's like this", "tokens": [50592, 291, 362, 1333, 295, 35572, 670, 264, 661, 27839, 2582, 433, 293, 1333, 295, 456, 311, 411, 341, 50776], "temperature": 0.0, "avg_logprob": -0.07021912904543297, "compression_ratio": 2.108108108108108, "no_speech_prob": 0.002468827646225691}, {"id": 617, "seek": 260206, "start": 2611.18, "end": 2616.38, "text": " you know laddering the stakes and sort of and proliferation is really the sort of the right", "tokens": [50820, 291, 458, 18325, 278, 264, 28429, 293, 1333, 295, 293, 24398, 44987, 307, 534, 264, 1333, 295, 264, 558, 51080], "temperature": 0.0, "avg_logprob": -0.07021912904543297, "compression_ratio": 2.108108108108108, "no_speech_prob": 0.002468827646225691}, {"id": 618, "seek": 260206, "start": 2616.38, "end": 2621.5, "text": " word do you think that that is a version of the future or do you think that there's sort of", "tokens": [51080, 1349, 360, 291, 519, 300, 300, 307, 257, 3037, 295, 264, 2027, 420, 360, 291, 519, 300, 456, 311, 1333, 295, 51336], "temperature": 0.0, "avg_logprob": -0.07021912904543297, "compression_ratio": 2.108108108108108, "no_speech_prob": 0.002468827646225691}, {"id": 619, "seek": 260206, "start": 2621.5, "end": 2627.1, "text": " some path in which this becomes a much more sort of like open and useful not this sort of like", "tokens": [51336, 512, 3100, 294, 597, 341, 3643, 257, 709, 544, 1333, 295, 411, 1269, 293, 4420, 406, 341, 1333, 295, 411, 51616], "temperature": 0.0, "avg_logprob": -0.07021912904543297, "compression_ratio": 2.108108108108108, "no_speech_prob": 0.002468827646225691}, {"id": 620, "seek": 262710, "start": 2627.18, "end": 2633.5, "text": " tool for nation states or large companies to compete with one another I think that the future", "tokens": [50368, 2290, 337, 4790, 4368, 420, 2416, 3431, 281, 11831, 365, 472, 1071, 286, 519, 300, 264, 2027, 50684], "temperature": 0.0, "avg_logprob": -0.06233772738226529, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0007094976608641446}, {"id": 621, "seek": 262710, "start": 2633.5, "end": 2642.2999999999997, "text": " that seems to be unfolding is kind of a you know replay of how say computing technology has played", "tokens": [50684, 300, 2544, 281, 312, 44586, 307, 733, 295, 257, 291, 458, 23836, 295, 577, 584, 15866, 2899, 575, 3737, 51124], "temperature": 0.0, "avg_logprob": -0.06233772738226529, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0007094976608641446}, {"id": 622, "seek": 262710, "start": 2642.2999999999997, "end": 2648.06, "text": " out more broadly I think that that it is still going to be the case that you're going to have", "tokens": [51124, 484, 544, 19511, 286, 519, 300, 300, 309, 307, 920, 516, 281, 312, 264, 1389, 300, 291, 434, 516, 281, 362, 51412], "temperature": 0.0, "avg_logprob": -0.06233772738226529, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0007094976608641446}, {"id": 623, "seek": 262710, "start": 2648.06, "end": 2653.18, "text": " these increasingly massive supercomputers that are in the hands of only a few that are able to just", "tokens": [51412, 613, 12980, 5994, 27839, 2582, 433, 300, 366, 294, 264, 2377, 295, 787, 257, 1326, 300, 366, 1075, 281, 445, 51668], "temperature": 0.0, "avg_logprob": -0.06233772738226529, "compression_ratio": 1.7625570776255708, "no_speech_prob": 0.0007094976608641446}, {"id": 624, "seek": 265318, "start": 2653.18, "end": 2657.98, "text": " create models that can just do crazy things that no one else can do but I don't think that that", "tokens": [50364, 1884, 5245, 300, 393, 445, 360, 3219, 721, 300, 572, 472, 1646, 393, 360, 457, 286, 500, 380, 519, 300, 300, 50604], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 625, "seek": 265318, "start": 2657.98, "end": 2662.8599999999997, "text": " removes the value from the massive set of things that people are going to do with these models", "tokens": [50604, 30445, 264, 2158, 490, 264, 5994, 992, 295, 721, 300, 561, 366, 516, 281, 360, 365, 613, 5245, 50848], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 626, "seek": 265318, "start": 2662.8599999999997, "end": 2668.7799999999997, "text": " and so you know I think that balancing the like super powerful very dual use extremely you know", "tokens": [50848, 293, 370, 291, 458, 286, 519, 300, 22495, 264, 411, 1687, 4005, 588, 11848, 764, 4664, 291, 458, 51144], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 627, "seek": 265318, "start": 2668.7799999999997, "end": 2673.66, "text": " think of these like almost like you know these massive like you know sort of systems that are", "tokens": [51144, 519, 295, 613, 411, 1920, 411, 291, 458, 613, 5994, 411, 291, 458, 1333, 295, 3652, 300, 366, 51388], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 628, "seek": 265318, "start": 2673.66, "end": 2676.62, "text": " you know we think about like a nuclear reactor and it's like you know it's like these like giant", "tokens": [51388, 291, 458, 321, 519, 466, 411, 257, 8179, 20628, 293, 309, 311, 411, 291, 458, 309, 311, 411, 613, 411, 7410, 51536], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 629, "seek": 265318, "start": 2676.62, "end": 2681.1, "text": " like sort of you know systems that you should approach with great care um and you think about", "tokens": [51536, 411, 1333, 295, 291, 458, 3652, 300, 291, 820, 3109, 365, 869, 1127, 1105, 293, 291, 519, 466, 51760], "temperature": 0.0, "avg_logprob": -0.0574115589261055, "compression_ratio": 2.0915750915750917, "no_speech_prob": 0.0011332966387271881}, {"id": 630, "seek": 268110, "start": 2681.1, "end": 2685.18, "text": " like you know by contrast think about wind turbines and like there's lots of wind turbines", "tokens": [50364, 411, 291, 458, 538, 8712, 519, 466, 2468, 44947, 293, 411, 456, 311, 3195, 295, 2468, 44947, 50568], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 631, "seek": 268110, "start": 2685.18, "end": 2688.22, "text": " everywhere and actually that if you add up the amount of value from wind turbines versus nuclear", "tokens": [50568, 5315, 293, 767, 300, 498, 291, 909, 493, 264, 2372, 295, 2158, 490, 2468, 44947, 5717, 8179, 50720], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 632, "seek": 268110, "start": 2688.22, "end": 2691.9, "text": " reactors like I think actually that the balance is probably in favor of wind turbines and so I", "tokens": [50720, 41649, 411, 286, 519, 767, 300, 264, 4772, 307, 1391, 294, 2294, 295, 2468, 44947, 293, 370, 286, 50904], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 633, "seek": 268110, "start": 2691.9, "end": 2696.22, "text": " think that that's kind of the future we're going to is that the AI technology is going to be everywhere", "tokens": [50904, 519, 300, 300, 311, 733, 295, 264, 2027, 321, 434, 516, 281, 307, 300, 264, 7318, 2899, 307, 516, 281, 312, 5315, 51120], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 634, "seek": 268110, "start": 2696.22, "end": 2701.42, "text": " and there's going to be lots of value that's delivered by having open source models that are", "tokens": [51120, 293, 456, 311, 516, 281, 312, 3195, 295, 2158, 300, 311, 10144, 538, 1419, 1269, 4009, 5245, 300, 366, 51380], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 635, "seek": 268110, "start": 2701.42, "end": 2705.1, "text": " integrated to every business and that people are building all sorts of crazy applications on top of", "tokens": [51380, 10919, 281, 633, 1606, 293, 300, 561, 366, 2390, 439, 7527, 295, 3219, 5821, 322, 1192, 295, 51564], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 636, "seek": 268110, "start": 2705.1, "end": 2709.1, "text": " and that's something that we really want to support and promote and you also have to have this", "tokens": [51564, 293, 300, 311, 746, 300, 321, 534, 528, 281, 1406, 293, 9773, 293, 291, 611, 362, 281, 362, 341, 51764], "temperature": 0.0, "avg_logprob": -0.05293955638490874, "compression_ratio": 2.011940298507463, "no_speech_prob": 0.0002779740607365966}, {"id": 637, "seek": 270910, "start": 2709.1, "end": 2713.42, "text": " dual answer for what you do with the with the new extremely capable stuff that's just a mile ahead", "tokens": [50364, 11848, 1867, 337, 437, 291, 360, 365, 264, 365, 264, 777, 4664, 8189, 1507, 300, 311, 445, 257, 12620, 2286, 50580], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 638, "seek": 270910, "start": 2713.42, "end": 2718.14, "text": " of everything else and that's something you have to treat with kid gloves with with more care", "tokens": [50580, 295, 1203, 1646, 293, 300, 311, 746, 291, 362, 281, 2387, 365, 1636, 14976, 365, 365, 544, 1127, 50816], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 639, "seek": 270910, "start": 2718.14, "end": 2722.54, "text": " and I think that that balance is tricky it's not easy um that's something that we as an organization", "tokens": [50816, 293, 286, 519, 300, 300, 4772, 307, 12414, 309, 311, 406, 1858, 1105, 300, 311, 746, 300, 321, 382, 364, 4475, 51036], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 640, "seek": 270910, "start": 2722.54, "end": 2725.74, "text": " have been trying to straddle and I think that you know we've had real existential struggles", "tokens": [51036, 362, 668, 1382, 281, 1056, 345, 2285, 293, 286, 519, 300, 291, 458, 321, 600, 632, 957, 37133, 17592, 51196], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 641, "seek": 270910, "start": 2725.74, "end": 2729.98, "text": " internally trying to figure out you know like our goal is to empower everyone it's really to uh", "tokens": [51196, 19501, 1382, 281, 2573, 484, 291, 458, 411, 527, 3387, 307, 281, 11071, 1518, 309, 311, 534, 281, 2232, 51408], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 642, "seek": 270910, "start": 2729.98, "end": 2735.66, "text": " to to bring everyone along to this AI transition and the best way to do that I think that our", "tokens": [51408, 281, 281, 1565, 1518, 2051, 281, 341, 7318, 6034, 293, 264, 1151, 636, 281, 360, 300, 286, 519, 300, 527, 51692], "temperature": 0.0, "avg_logprob": -0.06523924383498331, "compression_ratio": 1.8976897689768977, "no_speech_prob": 0.0031717196106910706}, {"id": 643, "seek": 273566, "start": 2735.66, "end": 2739.74, "text": " picture of it has changed as the technology has unfolded and I think that we're starting to get a", "tokens": [50364, 3036, 295, 309, 575, 3105, 382, 264, 2899, 575, 17980, 292, 293, 286, 519, 300, 321, 434, 2891, 281, 483, 257, 50568], "temperature": 0.0, "avg_logprob": -0.0786756297998261, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0006770324544049799}, {"id": 644, "seek": 273566, "start": 2739.74, "end": 2744.94, "text": " sense of of you know where this can go it's really exciting to see all the the energy of all these", "tokens": [50568, 2020, 295, 295, 291, 458, 689, 341, 393, 352, 309, 311, 534, 4670, 281, 536, 439, 264, 264, 2281, 295, 439, 613, 50828], "temperature": 0.0, "avg_logprob": -0.0786756297998261, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0006770324544049799}, {"id": 645, "seek": 273566, "start": 2744.94, "end": 2748.46, "text": " builders coming in because I think that like you said people are starting to realize like AI is", "tokens": [50828, 36281, 1348, 294, 570, 286, 519, 300, 411, 291, 848, 561, 366, 2891, 281, 4325, 411, 7318, 307, 51004], "temperature": 0.0, "avg_logprob": -0.0786756297998261, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0006770324544049799}, {"id": 646, "seek": 273566, "start": 2748.46, "end": 2753.58, "text": " really going to work and it's time to build yeah well um this was an incredible conversation thank", "tokens": [51004, 534, 516, 281, 589, 293, 309, 311, 565, 281, 1322, 1338, 731, 1105, 341, 390, 364, 4651, 3761, 1309, 51260], "temperature": 0.0, "avg_logprob": -0.0786756297998261, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0006770324544049799}, {"id": 647, "seek": 273566, "start": 2753.58, "end": 2758.8599999999997, "text": " you so much Greg next time we speak I'll make you uh read the poem that all right there we go", "tokens": [51260, 291, 370, 709, 11490, 958, 565, 321, 1710, 286, 603, 652, 291, 2232, 1401, 264, 13065, 300, 439, 558, 456, 321, 352, 51524], "temperature": 0.0, "avg_logprob": -0.0786756297998261, "compression_ratio": 1.7765567765567765, "no_speech_prob": 0.0006770324544049799}, {"id": 648, "seek": 275886, "start": 2758.86, "end": 2762.06, "text": " cool thank you so much thank you so much", "tokens": [50364, 1627, 1309, 291, 370, 709, 1309, 291, 370, 709, 50524], "temperature": 0.0, "avg_logprob": -0.3770827849706014, "compression_ratio": 1.25, "no_speech_prob": 0.008113840594887733}], "language": "en"}