start	end	text
0	14000	Today we're going to talk about PageRank and a lot you're going to see a lot of stuff on
14000	15500	PageRank.
15500	24000	This was a key invention that led to the founding of Google in the early 90s and I'm going to
24000	26000	give you some mathematical foundations.
27000	35000	I'm also going to talk about extensions like what's called Topic Specific PageRank
35000	44000	or SIPRANKs for finding similar pages, TrustRank and I will explain how web spamming works,
44000	51000	how that search engine optimized companies can try to increase the rank so there's a
51000	55000	huge gap between search engines and these guys.
57000	59000	Let me first start.
61000	69000	Let me give several definitions of PageRank.
69000	71000	I'm going to start with Fluid.
71000	76000	So there's going to be in this course both intuition and mathematics.
76000	79000	A lot of intuition, a lot of mathematics too.
79000	88000	So I'll give multiple ways of Fluid algorithm, random walk and matrix representation all for
88000	90000	the same algorithm.
90000	97000	And then I'll give you some intuition on matrices and eigenvectors, eigenvalues, which maybe
97000	100000	you see hopefully you get good intuition here.
101000	107000	So in a PageRank there's only one value for each web page.
107000	115000	So it's a big directed graph on the web pages and each page has a value that is computed
115000	124000	and the intuition is a page that is important, is pointed to by important pages and an important
124000	127000	page points to important pages.
127000	129000	So that's recursive.
129000	133000	That means there's a recursive iterative algorithm.
133000	139000	First intuition is that it's kind of like a liquid, fluid.
139000	148000	Each web page or node is a container and the links are hives and you start by putting
148000	154000	a little bit of fluid in each of the web pages and then the fluid will circulate according
154000	156000	to some rules.
156000	163000	So if you have one liter, then one of our n liters is put in every page and then you
163000	164000	repeat.
164000	168000	So there's a link from P to P prime.
168000	175000	So each page P has links going out and if there's n links going out, maybe there's only
175000	181000	three links going out, each page, each link will get one third of the fluid.
181000	188000	The fluid is divided between that of links and then the next step, you look at the links
188000	192000	coming in and for each incoming link you take the fluid.
192000	200000	So you see the fluid circulates like that and eventually it converges.
200000	203000	So here's an example of web pages.
203000	206000	So there's eight pages here.
206000	209000	A, B, C, D, E, F, G, H.
209000	212000	There's each page has one eighth.
212000	214000	So now the fluid circulates.
214000	216000	How does it work?
216000	218000	Well look at page A.
218000	230000	So page A has D going in, E going in, H going in, F going in, and G going in.
230000	238000	And so what happens is after one iteration, A has one eighth of a liter which leaves and
238000	241000	all the n links, the fluid comes in.
241000	245000	So D has one eighth of a liter but has two outgoing links.
245000	247000	So it's divided by two.
247000	250000	So you have one 16 coming from D.
250000	253000	E has also two outgoing links.
253000	258000	So there's one 16 coming from E.
258000	260000	H has no outgoing links.
260000	262000	So everything goes there.
262000	264000	So this is one eighth.
264000	267000	That's H.
267000	270000	F has no outgoing links.
270000	271000	And G neither.
271000	276000	So there's both one eighth there.
276000	279000	That's F and G.
279000	282000	So the total is three eighths, four eighths.
282000	284000	This is one half.
284000	286000	That's after one iteration.
286000	288000	It's the same for all of them.
288000	291000	And you keep going until it converges.
291000	295000	And you can prove it converges, which we will do in a little bit.
295000	301000	And after you keep doing that, you get these numbers.
301000	308000	So A has four thirteenths, B has two thirteenths, D has one thirteenth, and so on.
308000	311000	So this is the result of the page rank.
311000	313000	It's just this fixed point.
313000	316000	A is the most important page here.
316000	321000	And D, H, E, F, and G are less important.
321000	323000	That's the basic idea.
323000	325000	Of course there's a problem.
325000	329000	It's not going to work if you do like that.
329000	334000	So this basic algorithm is nice, but it doesn't always work.
334000	337000	So we have to fix it.
337000	340000	So let's say we change the graph.
340000	342000	F points to G and G points to F.
342000	345000	They don't point to A, they point to each other.
345000	348000	So what happens now?
348000	350000	The thing keeps circulating.
350000	355000	But look, all the fluid that comes in here never goes out.
355000	357000	You see that?
357000	359000	It just will accumulate here.
359000	363000	All the fluid will eventually, this part will empty, zero.
363000	366000	Everything will eventually come here.
366000	369000	F and G will each get half.
369000	371000	F and G has to get zero.
371000	373000	That's not good enough.
373000	377000	So you think, well, this is a stupid algorithm.
377000	379000	It's very bad.
379000	384000	Well, the insight from the smart guys who made Google is,
384000	386000	we can actually fix this problem.
386000	389000	So you see the problem now.
389000	393000	We can still use the fluid intuition to fix it.
393000	395000	Look at the Earth.
395000	398000	Water flows down, right?
398000	400000	First, everything goes into the ocean.
400000	404000	But why does not everything stay in the ocean?
404000	406000	Still, there's water on the mountains.
406000	409000	Because there's water also going up.
409000	412000	This is called up by evaporation.
412000	414000	So it's kind of circulating.
414000	417000	So you have lakes in the mountains.
417000	422000	And that's what they do now for the pay track algorithm.
422000	425000	You can, the update rule.
425000	429000	So it's not just what fluid goes in.
429000	432000	There's also fluid going out.
432000	438000	So you take the fluid, OK?
438000	441000	So you make a scale at the end of the day.
441000	448000	You reduce the fluid in each page by some factor s,
448000	450000	like 0.9 or something.
450000	457000	And you add a little bit of fluid, 1 minus s over n, everywhere.
457000	461000	So even the pages very low, very low,
461000	464000	pay track will get some.
464000	468000	So it's like a random jump, OK?
468000	472000	So basically the pay track evaporates from each node.
472000	476000	And it rains uniformly on all nodes.
476000	480000	So that means we have now a cycle between all nodes.
480000	487000	And this fixes the problem, OK?
487000	493000	So you have the basic update rule extended with scaling.
493000	495000	So this is the evaporation.
495000	499000	You can show it with converges, which we will show in a while.
499000	502000	It's matrix computation, which we'll show later.
502000	509000	And the real scaling factor is some number very close to 1, 0.8, 0.9.
509000	513000	So that means most of the time the fluid stays on the page,
513000	520000	like a small percentage of the time it jumps when it evaporates, OK?
520000	526000	And this definition, the fluid definition, is equivalent.
526000	532000	You can say it's also kind of, you can formulate it as a random walk definition.
532000	536000	This is maybe more intuitive for humans.
536000	541000	Let's say you have somebody who is browsing the web randomly.
541000	545000	I'm looking at a web page, and then I click on the web page.
545000	548000	So I jump from one page to the other.
548000	553000	And I keep clicking, and I'm surfing for K steps.
553000	556000	And then I get bored, and I don't get another page.
556000	562000	So it's like I'm walking randomly on the network, OK?
562000	565000	And you walk K steps.
565000	568000	And then you jump to some random page, you walk K steps.
568000	572000	Then you walk, jump, and you walk K steps.
572000	578000	So this is the walking is exactly the page after K iterations.
578000	587000	And the jump is the rain with the jumping to random page with probability 1 minus s, OK?
587000	593000	So it turns out they're equivalent, which we'll see in a minute.
593000	595000	OK?
595000	599000	So this is the basic algorithm.
599000	603000	It was modified a lot, OK?
603000	610000	So I won't say so much here, because we're going to go into the other slides.
610000	613000	Search companies will cheat.
613000	616000	They don't call it cheating.
616000	622000	They call it search engine optimization, please, SEO.
622000	629000	And if I want to be very high at the Google ranking, I pay SEO companies the money.
629000	634000	And they will do some magic, and all of a sudden I get very high scores.
634000	639000	And it works using something called link farms, which we'll explain.
639000	640000	OK?
640000	645000	And also something we mentioned before is advertising.
645000	647000	So it's the links.
647000	649000	You also have pay links.
649000	652000	And Google makes huge money with that.
652000	653000	OK?
653000	655000	So that's an extension.
655000	657000	OK?
657000	668000	So let me now go to the more in-detailed discussion of PageRank.
668000	675000	So these slides are actually by a colleague of mine called Sarunas Gerzioskas,
675000	680000	who is, I think, from Lithuania, but he's now in Sweden, KTH.
680000	684000	So he was very nice to get to these slides, which I modified a little.
684000	686000	So this goes into a lot of detail.
686000	687000	OK?
687000	693000	On different kind of things for PageRank.
693000	696000	So first I want to give you intuition.
696000	701000	We will go a little bit into the math, matrix representation for random walks,
701000	703000	the notion of eigenvalues.
703000	709000	Then I will show the PageRank algorithm, how it works exactly, formally.
709000	712000	And then we go beyond PageRank.
712000	718000	How can you search in a more focused way, topic specific,
718000	722000	or how you can find similar pages, using variation,
722000	727000	that say I'm looking for movies that are like this movie.
727000	728000	OK?
728000	731000	So, for example, I like a lot the movie Doom,
731000	734000	and I want to find movies that are like this movie.
734000	736000	So with SimRank lets me do that.
736000	737000	So it's similar.
737000	742000	And the final thing is that I want to talk, I want to explain how the cheaters work.
742000	745000	This is called web spamming.
745000	750000	So very quickly after Google invented the PageRank,
750000	753000	the companies invented the ways to cheat.
753000	754000	OK?
754000	756000	And this is called link farming.
756000	758000	So I'll show you exactly how it works.
758000	763000	And we'll figure out how can you increase the PageRank artificially.
763000	771000	And then I'll show you some algorithm called TrustRank to go bypass the cheaters.
771000	772000	OK?
772000	779000	So the first part of the talk is more general talk about random walks and matrices.
779000	782000	So this gives you kind of intuition on the mathematics.
782000	787000	So I'm going to give you mathematics, but also intuition.
787000	791000	So the first thing I want to talk about is random walks.
791000	798000	So here's a graph with vertices, 1, 2, 3, 4, 5, and edges connected to them.
798000	800000	And I want to do a random walk.
800000	802000	That means I start somewhere.
802000	804000	I've got node 1.
804000	809000	I move to a neighboring node with some probability.
809000	811000	1 over d of v.
811000	815000	So d is the degree of the vertex.
815000	817000	It's how many links there are.
817000	820000	So the node 1 has a degree of 2.
820000	824000	So there's one half probability of going on each of those links.
824000	828000	And then I keep making walk steps.
828000	834000	And the sequence of this technically is something called a Markov chain.
834000	843000	I'm not going to give you so much theory, but it's basically a sequence where each step is chosen according to some probability.
843000	844000	And there's no memory.
844000	846000	I mean, it doesn't remember where it comes from.
846000	848000	You just each step, it's there.
848000	852000	It makes another jump, but it actually has no memory where it came from.
852000	854000	So that's called Markov chain.
854000	856000	Okay?
856000	859000	So let's say we start at node 1.
859000	861000	So here I make a table.
861000	864000	So node 1 here.
864000	871000	So in the beginning at time 0, I have one probability of being at node 1 and 0 for being everywhere else.
871000	875000	And then I do one step, but a two-step, three-step.
875000	883000	And each step, I will walk randomly according to the links.
883000	884000	Okay?
884000	893000	So after one step, see how it works out, I will be either at node 2 or 3 with probability 50%.
893000	894000	Okay?
894000	895000	And then I keep going.
895000	902000	So the 2 can go either to 1 or 4, and the 3 can go to 1, 4, or 5.
902000	907000	So the 2, the 0.5, will be split between 1 and 4.
907000	913000	And the node 3, the 50%, will be split between 1, 4, and 5.
913000	918000	So 16% or 17% for each of them.
918000	919000	So that gives me this.
919000	925000	That means there's 42% chance of being at node 1.
925000	927000	So where does this number come from?
927000	937000	Well, it means I have a 25% chance coming from node 2 and a 17% chance of coming from node 3.
937000	941000	And 25 plus 17 is 42.
941000	943000	That's very quick to pick up.
943000	947000	Also being in node 4, I have a 42%.
947000	951000	And node 5 is only one way to get there.
951000	954000	It's from 3 because I'm not getting 4.
954000	960000	So there's a 1 over 6, so 17%, rounded into 2 decimals.
960000	965000	And the sum of all these is normally going to be 1.
965000	969000	Might be slightly different because of round off error, but it's supposed to be 1.
969000	970000	Okay?
970000	971000	So I keep going.
971000	974000	You can see now the numbers change.
974000	980000	After 3 steps, I will be in these places with these probabilities.
980000	982000	And I keep going and I can keep going.
982000	984000	4, 5, 6.
984000	990000	You see, eventually, it's like they're kind of converging, okay?
990000	993000	To some value.
993000	995000	Okay?
995000	997000	And it will converge.
997000	1003000	So the initial node, I started with node 1, but of course you can start with more nodes.
1003000	1006000	So here's a longer table.
1006000	1011000	So you start from 0 up to the top and you keep going.
1011000	1015000	And it kind of looks like it's converging, right?
1015000	1019000	17, 17, 25, 25, 17.
1019000	1021000	How would you think?
1021000	1025000	It seems to be, it smells like it's converging over.
1025000	1028000	And it does actually converge.
1028000	1037000	And you can prove for any connected, non-by-part, bi-directional graph at any starting point,
1037000	1041000	the random one converges.
1041000	1045000	And now I want you to have intuition on this.
1045000	1048000	The graph has to be connected, of course.
1048000	1054000	If it's not connected, if it looks like this.
1054000	1056000	So let's say the graph looks like this.
1056000	1058000	There's two pieces.
1058000	1065000	Well, if I start here, I will never get there, okay?
1065000	1066000	For example.
1066000	1073000	Or if I have a bi-part type graph.
1073000	1078000	See, depending on if I start here or if I start here, I will converge differently.
1078000	1082000	So it's not really converging for any random starting point.
1082000	1087000	See, here I say any starting point, okay?
1087000	1096000	So if the graph is not connected, then the convergence would be different depending on the starting point, right?
1096000	1098000	So it has to be connected.
1098000	1100000	So you have to understand, intuition is important.
1100000	1102000	It has to be connected.
1102000	1104000	It has to be non-by-part type.
1104000	1108000	Because if it's bi-part type, then you can divide the graph into two pieces.
1108000	1114000	If I start here, then I will go here and it will be oscillating forever.
1114000	1117000	All the probability will be here and this will be zero.
1117000	1120000	And then it will all be here and all this will be zero.
1120000	1123000	So it's oscillating and not converging.
1123000	1127000	So that's why it has to be non-by-part type.
1127000	1128000	See that?
1128000	1131000	So you have to understand this intuition, huh?
1131000	1134000	So it's not just random words there, okay?
1134000	1136000	So make sure you understand.
1136000	1138000	Okay?
1138000	1144000	And the unique is only one result.
1144000	1151000	Unique stationary means that once you converge it never changes anymore, okay?
1151000	1157000	So this is a kind of iteration, which we call power iteration.
1157000	1160000	Okay?
1160000	1164000	So this is the final value.
1164000	1167000	17, 17, 25, 25, 17.
1167000	1170000	What are those numbers mean, actually?
1170000	1174000	Actually, we can figure it out what they have to mean.
1174000	1179000	We can actually give a formula for this.
1179000	1180000	The random walk.
1180000	1185000	So pi is the final set of probabilities.
1185000	1189000	And it's stationary, so it's staying the same.
1189000	1196000	D of V is the degree and M is the number of edges, okay, in the graph.
1196000	1200000	So in this graph, 1, 2, 3, 4, 5, 6, edges.
1200000	1204000	So 2M is 12.
1204000	1208000	So 3 is the degree 3.
1208000	1209000	1, 2, 3.
1209000	1215000	And 3 divided by 12 is 1, 4, 25%.
1215000	1217000	That's the coincidence, huh?
1217000	1219000	So 2 has two outcome edges.
1219000	1225000	2 divided by 12 is 1, 6, which is 0.17.
1225000	1226000	Amazing, huh?
1226000	1227000	Isn't it?
1227000	1230000	So we can prove that this has to be the right value.
1230000	1235000	It's actually very easy to prove, okay?
1235000	1239000	We can prove that this value is a fixed point.
1239000	1245000	That means if you do one more iteration on this value, you get the same value.
1245000	1250000	We start with pi, and we will do one iteration giving pi prime.
1250000	1251000	Okay?
1251000	1253000	And so how do you do that?
1253000	1259000	Well, the new value is all the in-going links, okay?
1259000	1264000	So for node V, we take all the links going from U to V.
1264000	1273000	And from each one of those, we have the probability on U divided by the degree.
1273000	1275000	1 over D, okay?
1275000	1287000	This one is du over 2m, and the du's cancel, so we get the sum of 1 over 2m, the links
1287000	1289000	coming from U to V.
1289000	1293000	But how many links are there going from U to V?
1293000	1296000	Well, it's exactly the degree of V.
1296000	1299000	How many links are going to this node?
1299000	1301000	1, 2, 3, okay?
1301000	1305000	That means it's the degree of V divided by 2m.
1305000	1308000	Pi prime is equal to pi.
1308000	1313000	So you could show that it's the degree divided by 2m, right?
1313000	1315000	We need that.
1315000	1318000	Now, there's another thing.
1318000	1321000	If the graph is deregular.
1321000	1327000	So deregular means that all the nodes have the same degree, D, everywhere.
1327000	1334000	If it's like that, of course, then the probability is going to be the same everywhere, right?
1334000	1337000	So uniform means it's the same.
1337000	1342000	So if I have three links on every node, it's going to be the same, uniform.
1342000	1344000	Okay, that's intuitive, right?
1344000	1347000	So you have to get the intuition, okay?
1347000	1355000	So this is just some numbers showing how it works.
1355000	1362000	So the stationary distribution is proportional to the degree of V.
1362000	1366000	The degree is how many links, okay?
1366000	1367000	So what does that mean?
1367000	1369000	There's intuition.
1369000	1371000	Well, it's pretty clear.
1371000	1378000	The more neighbors you have, the more chance that people are going to come visit you.
1378000	1379000	So the probability is higher.
1379000	1382000	See, that's kind of the intuition, okay?
1382000	1391000	So you can see how the matrix, the random walk is going to work.
1391000	1401000	Now, let's look at a more numerical form of representation, a matrix representation.
1401000	1406000	We're going to do the same thing now with matrices.
1406000	1408000	So here's my graph.
1408000	1410000	So I'm going to keep using the same example.
1410000	1417000	And that matrix called A is the adjacency matrix for this graph.
1417000	1418000	What does it mean?
1418000	1425000	Well, if you look at the rows, there's five rows and five columns.
1425000	1433000	So if there's a link from one to two, that means there's a one in element one, two.
1433000	1436000	So the first row, second column.
1436000	1440000	So let me show you.
1440000	1449000	So this link, one, two, means that there's from row one, there's a link to two here.
1449000	1451000	There's also a link from one to three.
1451000	1456000	So row one, column three, there's a link here.
1456000	1467000	And each row corresponds to one node, the origin, and the column corresponds to the destination, okay?
1467000	1471000	So how many ones are there in that graph?
1471000	1473000	In this matrix, how many ones?
1473000	1480000	You have one, two, three, four, five, six, six edges, huh?
1480000	1483000	So how many ones are going to be in there?
1483000	1484000	Two times.
1484000	1486000	Because, of course, they go both directions.
1486000	1488000	That's one to two, two to one.
1488000	1489000	So you have twelve.
1489000	1490000	They're out.
1490000	1492000	See, it's very two to go.
1492000	1497000	So that's the first matrix called adjacency matrix.
1497000	1503000	But now we want another matrix because we're going with probabilities.
1503000	1504000	We have a probability.
1504000	1507000	So we want that to be in the matrix too.
1507000	1516000	So first I want to do my special matrix called the diagonal matrix D.
1516000	1524000	And each value on the diagonal is one over one over the degree.
1524000	1530000	So for the first element, it's one over two, then one over two.
1530000	1534000	Note three has three legs, so it's one over three.
1534000	1538000	Note four has three legs, so it's one over three.
1538000	1541000	And note five has two legs, so it's one over two.
1541000	1544000	So why am I introducing this matrix?
1544000	1552000	Because it lets me define another matrix, which is called the transition matrix.
1552000	1556000	So this one is actually D times A.
1556000	1557000	So what does it mean?
1557000	1562000	Instead of ones, I now have probabilities.
1562000	1568000	So if I have a row one, if I have a node one, it is one half probability I go to two,
1568000	1571000	and one half probability I go to three.
1571000	1572000	See that?
1572000	1579000	So in each row, all the elements tell me the probability they go to the other one.
1579000	1580000	Question?
1580000	1581000	Yes.
1581000	1584000	In PageRank, we have a directed graph, correct?
1584000	1586000	Yes, we will get to that.
1586000	1591000	So yes, I'm talking now, I'm directing graph, but we will get to directed graph,
1591000	1593000	and you'll see what happens when we get there.
1593000	1599000	It's very interesting stuff, but you have to understand first this piece, this one, huh?
1599000	1600000	Yeah, yeah.
1600000	1601000	No problem, no problem.
1601000	1607000	We get there, and you will see all the neat intuition that comes when the graph becomes directed.
1607000	1610000	So here, I'm just giving you intuitions, okay?
1610000	1618000	Because eventually, we're going to be talking to PageRank, and then I want you to understand that stuff, okay?
1618000	1627000	So if you're in row two, you can go to row one, with probability half and a four with probability half.
1627000	1630000	If you're in two, you go to one or four.
1630000	1632000	See how it works, huh?
1632000	1636000	So all the ones in a row are turned into probabilities.
1636000	1641000	So the sum of the probabilities for each row is equal to one, huh?
1641000	1644000	And this matrix is actually D times A.
1644000	1647000	So there's two matrices that are really important here.
1647000	1656000	The adjacency, which gives you the graph, and the transition matrix, which gives you the probabilities, okay?
1656000	1663000	So formally, A is n by n adjacency matrix of the graph.
1663000	1674000	A, i, j is one if there's a link between nodes i and j, and otherwise it's zero, okay?
1674000	1681000	Actually, you can say it gives me all the paths that you can do in one half, huh?
1681000	1685000	Because you're making one connection, okay?
1685000	1687000	The adjacency matrix.
1687000	1695000	Now let's go do a little bit more intuition, and I'll show you and you'll see how neat the matrix representation is.
1695000	1699000	Let's say I want to count two hop paths.
1699000	1702000	I want to go one, two.
1702000	1704000	How many are there?
1704000	1708000	From a node, I want to go two hops instead of one.
1708000	1710000	You know it's so neat.
1710000	1715000	It's just A squared when you do matrix multiplication.
1715000	1726000	The A times A, the matrix multiplication, gives me the number of two hop paths, okay?
1726000	1729000	And A cubed, what does A cubed mean less?
1729000	1734000	Well, the number of three hop paths, okay?
1734000	1735000	So how does that work?
1735000	1737000	Well, I'll give you some intuition.
1737000	1740000	Okay, a small technical thing.
1740000	1745000	It's actually giving you walks.
1745000	1748000	Sorry, I have to be technical about graphs.
1748000	1755000	A path is when you don't repeat any vertices, so it's like the marking on the street.
1755000	1764000	Whereas a walk is like a person walking back and forth, so you can actually repeat vertices, okay?
1764000	1770000	So actually, we're counting walks, okay, to be very technical.
1770000	1773000	We're counting walks, okay?
1773000	1775000	So how does it work?
1775000	1786000	Actually, you have to make a diagram and a fingerprint and understand why the matrix multiplication gives you that.
1786000	1788000	Okay?
1788000	1794000	So let's say I want to do A times A.
1794000	1797000	Okay, A times A.
1797000	1806000	And here I have a row, row I, and here I have a column.
1806000	1808000	Okay?
1808000	1810000	Okay?
1810000	1818000	So, and here I have 1's and 0's up.
1818000	1826000	For example, some way, and this will give me element i, j, a, l.
1826000	1828000	So how does it work?
1828000	1837000	So these are, the one means you have one hoppa from i to 1 to center hoppa.
1837000	1839000	So how does the multiplication work?
1839000	1844000	1 times 0 plus 0 times 1 plus 1 times 0 plus 1 times 1.
1844000	1847000	Well, how does it, what does it mean in terms of hops?
1847000	1851000	Here I'm going from i to 1.
1851000	1857000	And here I'm going from 1 to j.
1857000	1859000	You see that?
1859000	1863000	So I go from i to 1 and then from 1 to j.
1863000	1867000	Then I go from i to 2 and from 2 to j.
1867000	1871000	From i to n and to j.
1871000	1879000	So each one of these combinations is going from i to j, but the node in the middle is different.
1879000	1881000	You see that?
1881000	1886000	And it's only going to be 1 if there's both 1's.
1886000	1892000	That means if I have a path from i to 2 and 2 to j, it's going to multiply 1 times 1.
1892000	1900000	So it's only 1 if the number, if there's actually a path there or a walkup.
1900000	1912000	So if you sum them all, it gives me all the possible walks from i to j with 2 hops.
1912000	1919000	And if here, and it keeps going like that, if you put the matrix here which gives you n hops,
1919000	1923000	then you hear you will add one more and you get n plus 1.
1923000	1925000	Do you see how it works?
1925000	1932000	So the matrix multiplication gives you the total number of walks.
1932000	1935000	Okay?
1935000	1945000	So what if you take the vector now, 1, 0, 0, 0, 0 and you multiply by a?
1945000	1953000	Well, it's like you start, okay?
1953000	1961000	You're starting from 1, or 0, or 0, or 0, or 0.
1961000	1966000	So the number of walks, the one where you start from is 1, 0, 0, 0, 0.
1966000	1971000	It's given by that.
1971000	1981000	So basically it tells you how many walks of length 1 that start from node 1, ending in node i.
1981000	1983000	Okay?
1983000	1986000	And you could do multiplication for that.
1986000	1989000	See how matrix multiplication is really neat, huh?
1989000	1995000	So v a squared, it gives you 2, 0, 0, 2, 1.
1995000	2003000	So now we have 2 walks going from node 1 ending up in node 1, or 2 walks from node 1 ending up in node 4.
2003000	2005000	Okay?
2005000	2009000	See what's neat, huh?
2009000	2011000	And 3 gives you how many walks of length?
2011000	2013000	3.
2013000	2017000	And it's all the same, I'm always talking about this one, huh?
2017000	2027000	And you see how the matrix really corresponds very nicely to graphs and doing things on graphs, okay?
2027000	2029000	Okay?
2029000	2032000	So far we did the adjacency matrix.
2032000	2036000	What about the random walk matrix, the transition matrix?
2036000	2038000	That's this one.
2038000	2043000	And with the probabilities, okay?
2043000	2048000	So this gives you the probability of ending up somewhere.
2048000	2050000	Okay?
2050000	2057000	If you start in node 1, the probability of ending in here is one-half.
2057000	2061000	The probability of ending in node 4 is zero.
2061000	2064000	And you could do squares.
2064000	2069000	So for example, if you keep going,
2069000	2074000	if you take this vector here and multiply again by m,
2074000	2080000	the number you get here is actually the probability that you end up in those nodes when you start with node 1.
2080000	2082000	It's neat, huh?
2082000	2087000	Question? No? It's okay?
2087000	2091000	So you can see how matrices and graphs are very close.
2091000	2096000	So this is going to help us understand page rank, yeah?
2096000	2098000	Okay?
2098000	2102000	So we have a random walk on a graph G.
2102000	2105000	Now we start doing random walks on that page rank.
2105000	2111000	We start at node v0, and after t steps, we end up in node vt.
2111000	2115000	We move to a neighbor with probability one over the degree.
2115000	2122000	Each time we go to a node, if there's multiple paths, we divide evenly, yeah?
2122000	2127000	And the chain of random nodes, it's what's called a Markov chain.
2127000	2131000	So a Markov chain is a sequence where whenever you make one step,
2131000	2135000	you make kind of random choice, some probabilities,
2135000	2137000	but you forget everything you did before.
2137000	2143000	It only depends where you are now, so there's no memory, okay?
2143000	2150000	So the initial state would be here, so you have probability one being node 1, okay?
2150000	2156000	Now you can do multiple steps.
2156000	2167000	So after t steps, the probabilities is given by this vector, pt, p0 times m power t.
2167000	2173000	So this is matrix exponential, matrix multiplications, huh?
2173000	2176000	See how it works, huh?
2176000	2184000	If you're a stickler for doing the m on the left, you have to do transpose, of course.
2184000	2192000	That means you have row mixes here, but that's a detail, okay?
2192000	2199000	So here we have pt is p0 times m to the t, and we start again with our matrix,
2199000	2204000	and we start with the 1, 0, 0, 0, 0, and we do one step.
2204000	2210000	So we have probabilities a half and a half for getting there, okay?
2210000	2214000	And then keep it doing again, and we keep going.
2214000	2220000	And eventually, I mean, it's going to converge.
2220000	2224000	Remember, I showed you the table, but we're doing the same thing here, huh?
2224000	2232000	So when pt plus 1 is equal to pt, we have reached a stationary distribution.
2232000	2236000	So let me call this vector pi, okay?
2236000	2242000	It's not 3.4, and I have not chosen this notation,
2242000	2245000	but this is what Sylvonez has chosen.
2245000	2249000	So pi times m is equal to pi.
2249000	2253000	Stationary, when we start with these probabilities, we make a step,
2253000	2257000	we end up with the same probabilities, okay?
2257000	2261000	See that?
2261000	2265000	You remember the notion of eigenvectors, have you seen that?
2265000	2268000	Well, this is an eigenvector, either young.
2268000	2275000	Remember, every matrices have special vectors called eigenvectors
2275000	2277000	that give some property in the matrix.
2277000	2283000	So v is an eigenvector of m, and lambda is the eigenvalue
2283000	2289000	if v times m is equal to lambda, which is a scalar number times v.
2289000	2293000	It's just scaling the v.
2293000	2297000	So this one is clearly an eigenvector, right?
2297000	2299000	Interesting, huh?
2299000	2304000	So pt is connected to eigenvectors.
2304000	2313000	Pi is an eigenvector of m with eigenvalue lambda equal to 1, okay?
2313000	2315000	Okay, so that's the first part.
2315000	2317000	Let me go on now.
2317000	2320000	Let me go on now by giving you some more intuition
2320000	2325000	on eigenvectors and eigenvalues in terms of graphs.
2325000	2329000	So eigenvectors and eigenvalues are very useful things,
2329000	2333000	but with graphs they have some really neat properties.
2333000	2336000	So remember this, okay?
2336000	2338000	This is what we just saw.
2338000	2345000	We have pi as an eigenvector with eigenvalue 1.
2345000	2349000	But we can actually say more things, okay?
2349000	2354000	There's something called the spectrum of a matrix.
2354000	2356000	I'm not sure if you saw that.
2356000	2358000	Have you seen that?
2358000	2360000	Have you seen that spectrum?
2360000	2362000	Yes? Good.
2362000	2364000	That means this will be very easy, right?
2364000	2367000	No?
2367000	2370000	So assume now, now I'm going to give you some intuition.
2370000	2373000	Assume you have a D regular graph.
2373000	2378000	So that's a graph where all the nodes have a degree of D.
2378000	2384000	So there are all three things coming out, for example.
2384000	2386000	Okay?
2386000	2392000	And now we have a, which is the adjacency matrix for this.
2392000	2395000	So a times x, okay?
2395000	2401000	So this is just a matrix multiplication of a times vector x
2401000	2406000	equal vector y, okay?
2406000	2411000	And an eigenvector, this is refresher.
2411000	2420000	An eigenvector is a vector x such that this is equal to some number times that, okay?
2420000	2427000	So what happens with degree D?
2427000	2434000	Now we're going to connect the eigenvalues, eigenvectors with graphs, okay?
2434000	2439000	Graphs, which are these visual topological things, like on the web.
2439000	2442000	And matrices, which is just a bunch of numbers.
2442000	2444000	How does it connect?
2444000	2448000	Suppose all the nodes have degree D and G is connected.
2448000	2452000	So it's a D regular graph, huh?
2452000	2454000	Okay.
2454000	2458000	What are some eigenvalues?
2458000	2460000	Well, let's try.
2460000	2467000	Let's say we try to vector y, y, y, y only once, this graph, okay?
2467000	2474000	Then a times x will be D, D into all the D's.
2474000	2480000	Because each node has three outgoing things, but also three incoming things.
2480000	2485000	So the number of ways of going into a node is D.
2485000	2489000	So that means D is an eigenvalue.
2489000	2495000	So if you have a graph with only degree D, well D is an eigenvalue.
2495000	2500000	So eigenvalue is somehow connected with the degree of the graph.
2500000	2501000	It's funny, huh?
2501000	2504000	Interesting, huh?
2504000	2506000	Okay.
2506000	2514000	So the vector of all the nodes has an eigenvalue of D, okay?
2514000	2518000	This is actually what's called the principal eigenvector.
2518000	2520000	But let's look at some other graphs.
2520000	2525000	So the D regular graph is a very simple uniform graph.
2525000	2527000	Let's look at some other ones.
2527000	2530000	Very interesting, okay?
2530000	2531000	In general.
2531000	2537000	Now, there's a concept called spectrograph of a graph.
2537000	2543000	So if we have now a matrix A, a JCC represents a graph.
2543000	2546000	V times A is equal to lambda times V.
2546000	2550000	Well, if it's a column vector, you can say A V is lambda V.
2550000	2553000	Here we have row vectors.
2553000	2558000	So if A is a real symmetric matrix, so for non-directed graphs it's symmetric,
2558000	2564000	real numbers, then it has n eigenvectors and n eigenvalues.
2564000	2567000	And all the eigenvalues are real numbers.
2567000	2568000	And you could order them.
2568000	2571000	Lambda 1 and lambda 2 up to lambda n.
2571000	2573000	That's something you can show.
2573000	2575000	And the eigenvectors are orthogonal.
2575000	2579000	So they're orthogonal to each other.
2579000	2584000	And if G is a D regular graph, then lambda 1 is equal to D.
2584000	2592000	Somehow, degree of the graph is connected to the eigenvalue.
2592000	2594000	Okay?
2594000	2598000	For a random walk matrix, which is not the degree of D,
2598000	2604000	which is a random walk matrix, you have normalized.
2604000	2607000	This is the one where you have probabilities.
2607000	2610000	The principal eigenvalue is 1.
2610000	2611000	Here you have probabilities.
2611000	2613000	It's not that JCC, yeah?
2613000	2616000	It's the probabilities that eigenvalue is 1.
2616000	2620000	Okay?
2620000	2622000	This I will skip.
2622000	2625000	There is another concept called graph laplation,
2625000	2626000	but I would not use it.
2626000	2629000	But Saruna wants to tell you about it,
2629000	2633000	but I'm not going to tell you about it.
2633000	2640000	And the set of all the eigenvalues is called the spectra of the graph.
2640000	2642000	Okay?
2642000	2646000	And this could be for the A, JCC,
2646000	2649000	or the transition probability matrix M,
2649000	2652000	or the L matrix, which I'm not talking about.
2652000	2655000	And there's a very interesting number called
2655000	2659000	the difference between lambda 1 and lambda 2.
2659000	2662000	So lambda 1 is the principal eigenvalue,
2662000	2665000	but lambda 2 is also interesting.
2665000	2669000	And there's a number where lambda 1 minus lambda 2,
2669000	2672000	which has a name, which is called the eigengap,
2672000	2674000	or the spectral gap.
2674000	2676000	Okay?
2676000	2679000	And for N, it's 1 minus lambda 2,
2679000	2682000	because lambda 1 is equal to 1.
2682000	2684000	Okay?
2684000	2686000	Fine.
2686000	2689000	What if the graph is disconnected?
2689000	2693000	Okay, now we're going to show some examples
2693000	2695000	to make more pure intuition,
2695000	2698000	and that will all help for later
2698000	2700000	when we start thinking of the paint track.
2700000	2702000	Okay?
2702000	2705000	What happens if the graph is disconnected?
2705000	2710000	Well, lambda 1 is equal to lambda 2.
2710000	2712000	That's weird enough.
2712000	2714000	If the graph is disconnected,
2714000	2720000	you could actually say something about these two highest eigenvalues.
2720000	2722000	Okay?
2722000	2725000	So let's see how it works.
2725000	2728000	So now I'm going to give you some intuition.
2728000	2731000	So let's say we have a graph that's not connected.
2731000	2733000	Two components.
2733000	2736000	Each one is deregular, just for simplicity.
2736000	2739000	So each one has the same number of names.
2739000	2741000	So we can have two little triangles.
2741000	2745000	So what are some eigenvalues for this?
2745000	2749000	Well, for example,
2749000	2752000	if you put 1's on the A,
2752000	2754000	and 0's on the B,
2754000	2756000	then you get a vector, right?
2756000	2758000	1, 1, 1, 0, 0, 0.
2758000	2761000	Or you can put 1's on the B,
2761000	2764000	and 0's on the A, right?
2764000	2768000	So if you put 1's on the A,
2768000	2771000	and 0's on the B,
2771000	2773000	and you multiply by A,
2773000	2776000	A times x prime here,
2776000	2778000	you add up all the degrees.
2778000	2782000	So you get d, d, d, d with 0's.
2782000	2786000	That means d is an eigenvalue.
2786000	2789000	But you also have another vector,
2789000	2792000	orthogonal, 0's and 1's on the B,
2792000	2795000	and it also gives d, d, d, d, d, d.
2795000	2800000	So you have two separate eigenvalues
2800000	2802000	that are the same.
2802000	2803000	Okay?
2803000	2806000	Notice if the degree would be different for me,
2806000	2808000	we would have different values.
2808000	2810000	We would have d1 and d2.
2810000	2812000	We would have d for both.
2812000	2814000	So they're the same.
2814000	2820000	And you can kind of do approximation now.
2820000	2823000	So we saw that if you have this,
2823000	2826000	the eigenvalues are the same.
2826000	2828000	You have two eigenvalues that are the same.
2828000	2832000	Now assume that it's almost,
2832000	2834000	almost disconnected.
2834000	2837000	We only have a small number of links here.
2837000	2839000	Well, it turns out,
2839000	2844000	lambda 1 and lambda 2 will be very close to each other.
2844000	2846000	It will be approximately 0.
2846000	2849000	So you can see that the connectedness
2849000	2852000	are somehow related to the eigenvalues.
2852000	2856000	Okay?
2856000	2857000	Okay.
2857000	2860000	For every connected,
2860000	2864000	normal bipartite, undirected graph,
2864000	2867000	the distribution converges to a limit.
2867000	2869000	Okay?
2869000	2872000	A unique stationary distribution, pi,
2872000	2875000	and it's regular, it's uniform.
2875000	2876000	Okay?
2876000	2878000	Why connected?
2878000	2880000	I mentioned already, yeah?
2880000	2882000	The graph has to be connected.
2882000	2887000	What happens if it's not connected?
2887000	2891000	What happens if it's not connected?
2891000	2893000	You see, I explained it already.
2893000	2895000	In case that you don't have one,
2895000	2897000	you need stationary distribution then.
2897000	2900000	You can have one or another one.
2900000	2901000	Okay?
2901000	2905000	What if it's bipartite?
2905000	2908000	Then you will have all the probabilities on one side,
2908000	2910000	so you can divide the graph into two sides.
2910000	2913000	All the probabilities on one side are not 0.
2913000	2915000	The other side is 0s,
2915000	2918000	and if you do one step, it all shifts to the other side,
2918000	2920000	and you have oscillation.
2920000	2922000	There's no convergence.
2923000	2925000	And what about directed graphs?
2925000	2928000	And now we've got to start going to directed graphs.
2928000	2930000	So now your body needs to be tuition.
2930000	2933000	What about directed graphs?
2933000	2935000	Okay?
2935000	2937000	So here's a directed graph.
2937000	2941000	It turns out the directed graph
2941000	2946000	has to be strongly connected.
2946000	2948000	Remember, we said what it means, huh?
2948000	2950000	That means there is a directed path
2950000	2952000	and it knows another.
2952000	2955000	What happens if it's not strongly connected?
2955000	2957000	Oh, you have to have intuition there.
2957000	2960000	So an example of that in the beginning.
2960000	2963000	If it's not strongly connected,
2963000	2969000	then they say walks will leak.
2969000	2975000	It means that if it's not strongly connected,
2975000	2977000	what happens?
2977000	2978000	Okay?
2978000	2980000	There's one thing.
2980000	2982000	Here's another one.
2982000	2986000	Notice this graph here.
2986000	2988000	So this one on the left is strongly connected.
2988000	2989000	So we're good.
2989000	2993000	The right one is also strongly connected.
2993000	2995000	No, this one is not strongly connected.
2995000	2997000	But this one has another problem.
2997000	2999000	It's not...
2999000	3003000	You have actually two cycles going like this.
3003000	3005000	Okay?
3005000	3011000	And this is a property called periodicity.
3011000	3013000	Huh?
3013000	3016000	A, the graph has to be A periodic.
3016000	3019000	So this is kind of generalizing by part-time.
3019000	3020000	Done.
3020000	3025000	Visits to some of should never be a multiple of some number.
3025000	3029000	So here, visits will be multiple of three steps.
3029000	3030000	Always.
3030000	3033000	Well, if you do that, the whole thing's going to oscillate.
3033000	3034000	Done.
3034000	3036000	Okay?
3036000	3039000	So if you do that, the whole thing will oscillate.
3039000	3043000	And so it's not going to be convergent.
3043000	3046000	So it has to be A periodic.
3046000	3049000	If you don't, you're not allowed to have that.
3049000	3052000	Okay?
3052000	3057000	So the greatest common divisor of the lengths of all the cycles is one.
3057000	3063000	So you can see some intuition here about the graph.
3063000	3064000	Okay.
3064000	3071000	So all of that was kind of preliminary stuff to get your neurons moving.
3071000	3074000	And now that we can start talking about page rank.
3074000	3075000	Okay?
3075000	3080000	So now I'm going to talk about mobile page rank.
3080000	3085000	So first, I'll give you a little history of what search.
3085000	3092000	So this all started a long time ago in prehistory.
3092000	3094000	Another millennium.
3094000	3098000	1989, okay, which is a long time ago.
3098000	3100000	It's really super long ago.
3100000	3105000	It's like, before the prince was born or something.
3105000	3109000	So here you have the first generation of search.
3109000	3113000	So you have people who are making web pages.
3113000	3115000	And people want to search them.
3115000	3118000	The first generation was manual curation.
3118000	3122000	So Yahoo!, which started back in those days.
3122000	3132000	There was little gnomes or monks sat in an office looking at all the web pages and kind of making directories.
3132000	3134000	And I went science.
3134000	3135000	I click on science.
3135000	3136000	It's trun.
3136000	3137000	Okay?
3137000	3140000	Yeah, but that's kind of not scalable.
3140000	3141000	Okay?
3141000	3144000	So then now we have second generation.
3145000	3151000	And there was a very nice one called Alfa Vista, which you have probably never used, which I used.
3151000	3155000	And this was classical information retrieval.
3155000	3158000	So basically they look at the text in the pages.
3158000	3163000	If there's lots of words on astronomy, then it's based on, then it's astronomy.
3163000	3164000	Okay?
3164000	3165000	And then the indices.
3165000	3168000	But this didn't work very well.
3168000	3172000	And it was, and it was spammed.
3172000	3174000	People did something called term spam.
3174000	3177000	It was very easy to cheat from this.
3177000	3180000	And then the third generation came.
3180000	3182000	And it basically took over.
3182000	3184000	This was Google Page Drive.
3184000	3185000	Okay?
3185000	3188000	So this is the short history of web search.
3188000	3190000	Okay?
3190000	3197000	So what I'm going to do now is I'm going to explain Google Page Drive.
3197000	3204000	And we're going to use all our intuition on graphs and matrices and all that stuff
3204000	3208000	to really see how to design it and not to make it work.
3208000	3209000	Okay?
3209000	3214000	But as noticed, it's three o'clock, so we're going to make a break first.
3214000	3215000	Okay?
3215000	3217000	Design Page Drive.
3217000	3223000	And we're going to use some of the intuition we saw before the break.
3223000	3226000	Okay?
3227000	3231000	So we have a bunch of pages.
3231000	3234000	And here we're talking about votes.
3234000	3237000	So it's like the fluid that you have above.
3237000	3240000	And you distribute the votes to outgoing links.
3240000	3242000	Okay?
3242000	3250000	So if a page J has some quotes, rj, and n outlink, each link gets rj over n.
3250000	3251000	Okay?
3251000	3253000	So that's here.
3253000	3256000	And so pages will vote.
3256000	3261000	So the idea is that the more votes you get, the more important you are.
3261000	3263000	It's like in an election.
3263000	3268000	And if your page is important, then you have more votes, rj is more.
3268000	3270000	So a vote from an important page is more.
3270000	3272000	So that's like what we saw before.
3272000	3274000	Okay?
3275000	3281000	And the importance of a page is the sum of the votes, the inlinks.
3281000	3284000	So the other pages then vote for it.
3284000	3285000	Okay?
3285000	3288000	So this is something we saw, kind of.
3288000	3289000	Okay?
3289000	3292000	This is actually very similar to random one.
3292000	3305000	So we can actually say that a Google Page Drive is the principal driving vector of the transition matrix of the web graph.
3305000	3306000	Okay?
3307000	3315000	So you have the web graph, which is huge, billions of links.
3315000	3317000	So the matrices are very big.
3317000	3318000	Okay?
3318000	3320000	So we're going to compute this.
3320000	3331000	We're going to compute the eigenvector of a matrix, which is 10 billion by 10 billion on the side.
3331000	3335000	That makes how many elements inside that matrix?
3335000	3340000	Well, 10 to the 20th elements in there.
3340000	3342000	So that's a lot, right?
3342000	3348000	So can you see any issues with that?
3348000	3355000	Well, I mean, not so many computers can store 10 to the 20.
3355000	3356000	Okay?
3357000	3359000	That's one issue.
3361000	3362000	But there's more issues.
3362000	3365000	So we're trying to make it practical now, aren't we?
3365000	3369000	So one issue is the matrix is huge.
3369000	3373000	The other issue is, well, remember this diagram?
3373000	3378000	This is the structure of the web.
3378000	3386000	Well, in order for there to be a unique stationary distribution, it has to be a strongly connected component.
3386000	3389000	So is this thing a strongly connected component?
3389000	3390000	No.
3390000	3393000	I mean, there's one inside, but it's not.
3393000	3395000	So that's a problem, okay?
3395000	3396000	That's another problem.
3396000	3399000	It's not strongly connected.
3399000	3403000	So it's a directional graph.
3403000	3408000	So here, for example, so there's two problems.
3408000	3412000	So the Google people have some very nice terminology for this.
3412000	3420000	So here we have a node which only has inlinks and no outlinks.
3420000	3424000	So this one is called a dead end.
3424000	3429000	We set dead end, and we saw it already before the break.
3429000	3432000	So you can say the votes leak out.
3432000	3436000	Everything collects there, and there's no, they're not circulating anymore.
3436000	3438000	That's one problem.
3438000	3440000	Or another issue.
3440000	3442000	So here's another graph.
3442000	3444000	So this graph has a problem too.
3444000	3447000	Can you see what the problem is here?
3447000	3451000	So here you have three nodes.
3451000	3456000	So the Google people call this a spider trap.
3456000	3458000	Something that traps spiders.
3458000	3463000	I'm not sure why they call it a spider trap, but it's called a spider trap.
3463000	3465000	That's another problem.
3465000	3467000	So the votes disappear.
3467000	3469000	They all collect there.
3469000	3471000	They're no longer circulating.
3471000	3473000	And of course it's not strongly connected.
3473000	3477000	So again, these are all problems we have to fix.
3477000	3479000	Okay?
3479000	3481000	So how do we fix it?
3481000	3484000	Well, we have to fix the graph.
3484000	3488000	We have to make it strongly connected and empiric.
3488000	3491000	Those were the two positions.
3491000	3494000	Strongly connected and empiric.
3494000	3496000	The solution of Google.
3496000	3498000	Okay?
3498000	3502000	This is very similar to the evaporation idea.
3502000	3510000	If you make very, very small leaks from every node to every other node.
3510000	3512000	So this is the evaporation.
3512000	3519000	It means there's a small probability of jumping from any node to any other node.
3519000	3522000	But the main graph is still the same.
3522000	3525000	So here's your main graph.
3525000	3530000	Then you have another graph with very tiny, tiny probabilities.
3530000	3533000	But between every node and every node is very tiny.
3533000	3536000	And you basically sum them together.
3536000	3538000	Okay?
3538000	3541000	So it's got very nice innovation and it turns into that.
3541000	3543000	Okay?
3543000	3547000	So the idea is that you have a random walk.
3547000	3554000	And when you're at a node, you will either follow the link or you will jump.
3554000	3557000	So it's basically the evaporation idea.
3557000	3562000	Some probability here, if you call it beta, you follow the real link.
3562000	3567000	And with one minus beta, you just jump to some random page.
3567000	3569000	Okay?
3569000	3572000	And usually it's very close to one.
3572000	3577000	Now, that means close to the time, you keep following links.
3577000	3582000	But at one step to five or ten links, you jump.
3582000	3586000	So it's like you walk for five steps and you jump.
3586000	3591000	So if you're in a spider trap going in a circle,
3591000	3596000	after five to ten steps, you will jump out from the spider trap.
3596000	3598000	Okay?
3598000	3603000	So if you go to a dead end, once you're in the dead end, there's no way of getting out.
3603000	3605000	So you will immediately jump out.
3605000	3611000	So dead end is a little bit special because there's no link going out.
3611000	3614000	So the only way to get out is to teleport.
3614000	3616000	Okay?
3616000	3619000	So if you're a dead end, you're always going to teleport.
3619000	3622000	So here's my graph.
3622000	3626000	So here's my transition matrix for this graph.
3626000	3630000	But this graph has maybe problems.
3630000	3633000	We don't know. Maybe you have spider traps dead ends.
3633000	3638000	So we have another graph with very small values.
3638000	3640000	Okay?
3640000	3643000	Here they're not so small because you only have five nodes.
3643000	3649000	But if I have ten billion nodes, the value of each one of these numbers will be less than one over ten billion.
3649000	3650000	Okay?
3650000	3653000	So this is what we call the teleportation matrix.
3653000	3660000	So you will combine these two matrices to get a new transition matrix.
3660000	3662000	Okay?
3662000	3665000	Combine them so you make the sum of them.
3665000	3669000	So this one is the matrix as you will do with the probability beta.
3669000	3671000	So this is the step.
3671000	3675000	And the teleportation, you will do with one minus beta.
3675000	3679000	Okay? And then you combine them.
3679000	3683000	Notice you combine them.
3683000	3686000	So this one is beta times this one.
3686000	3689000	Plus one minus beta times this.
3689000	3692000	Except here you have one.
3692000	3695000	And not one minus beta.
3695000	3698000	Well that's because it's a dead end.
3698000	3701000	You can't get out here.
3701000	3703000	Here there's nothing here.
3703000	3708000	So that means for the dead ends, you have to have an immediate teleport.
3708000	3710000	Okay?
3710000	3712000	There you have to have an immediate teleport.
3712000	3716000	So you have one minus beta if these are not all zeros.
3716000	3721000	But if it's zero you have to get out from node one.
3721000	3722000	Okay?
3722000	3727000	So that gives me this matrix here.
3727000	3731000	Notice this one, second row.
3731000	3734000	Here it's zeros.
3734000	3736000	That means you don't get out.
3736000	3738000	Here there you're stuck.
3738000	3742000	But you have to give it probabilities that add to one.
3742000	3743000	Okay?
3743000	3750000	So that means you have to multiply this teleportation matrix by one.
3750000	3754000	So that gives you one fourth probability to go into any other node.
3754000	3756000	Okay?
3756000	3759000	Okay, fine.
3759000	3761000	Is it fixed?
3761000	3763000	Well if beta is zero it doesn't work.
3763000	3767000	But we assume beta is never going to be zero.
3767000	3771000	But there's still other problems to make it really work.
3771000	3772000	Okay?
3772000	3774000	So you have this huge matrix.
3774000	3782000	How does the matrix, the paycheck matrix look if you have ten billion pages?
3782000	3784000	Pretty big, huh?
3784000	3786000	Dense matrix.
3786000	3789000	All the elements are basically non-zero.
3789000	3792000	Most of them are non-zero.
3792000	3795000	N squared, non-zero elements.
3795000	3797000	That's a lot.
3797000	3799000	It's not N.
3799000	3801000	It's not the number of nodes times the degree.
3801000	3804000	It's N squared.
3804000	3809000	So okay, the Google people were scratching their head and saying,
3809000	3815000	how do we implement this ten billion by ten billion matrix?
3815000	3818000	Can you even store it in memory?
3818000	3821000	How much memory would you need for that matrix?
3821000	3824000	What about the, can you store it in memory?
3824000	3826000	What do you think?
3826000	3831000	Is there a system in today that could store a matrix like that?
3831000	3834000	No one.
3834000	3840000	I mean ten billion by ten billion, that's ten to the twentieth elements.
3840000	3844000	Even Google today doesn't have like that kind of storage, okay?
3844000	3847000	So the fix is you have to be smart as usual.
3847000	3849000	Question?
3849000	3856000	If the universe doesn't contain enough atoms to store the geometry?
3856000	3858000	I might, sure.
3858000	3864000	Probably if you had a computer the size of the earth you could store it though.
3864000	3870000	Because sometimes we say there's ten to the seventy-six particles in the universe.
3870000	3874000	So yeah, you're fine. If you have the universe you can store it though.
3874000	3877000	I don't have the universe in my pocket.
3877000	3880000	So I can't store it.
3880000	3883000	So the idea is to be a little bit smart.
3883000	3889000	The idea is not to add the teleportation to every single number,
3889000	3895000	but to kind of keep it separate, okay?
3895000	3898000	So here you have, this is the computation you're doing.
3898000	3900000	You have some vector.
3900000	3902000	You multiply by a paint rank.
3902000	3908000	And you're basically looking for eigenvalue convergence of this thing, huh?
3908000	3912000	But you don't want to store this matrix. It's to big.
3912000	3916000	So what you do is you keep this one, the original one,
3916000	3921000	which does not have all, which has lots of zeros, does not have the teleportation.
3921000	3925000	And the teleportation is added only after that.
3925000	3928000	So this is like a tax, okay?
3928000	3932000	It's basically because it's always the same for every node.
3932000	3934000	It doesn't depend on the node.
3934000	3937000	That means you could add it in separately, okay?
3937000	3941000	So this is like one minus theta over n.
3941000	3947000	And so in that way you don't actually have to store ten to the twenty elements.
3947000	3950000	The matrix is sparse, okay?
3950000	3957000	This matrix, the number of elements, is basically similar to the number of edges, okay?
3957000	3960000	So it's much, much less, okay?
3960000	3963000	M is what's called a sparse matrix.
3963000	3966000	So most of the entries in the M are zeros.
3966000	3971000	You can implement it much more efficiently, okay?
3971000	3973000	Okay?
3973000	3976000	Of course you have to handle the dead ends, okay?
3976000	3980000	Be careful with the dead ends because you have to jump out.
3980000	3984000	For the dead ends, it's not one minus theta.
3984000	3989000	You have to be careful because you need to jump out one over n for the dead ends, huh?
3989000	3991000	Okay?
3991000	3993000	And then you get something nice.
3993000	3995000	So you get this nice figure.
3995000	3998000	Each of the nodes here is proportional to the page rank.
3998000	4000000	So B and C are very important.
4000000	4003000	And E is not important.
4003000	4005000	So what?
4005000	4007000	Okay.
4007000	4010000	Okay, so that's the basic page rank.
4010000	4018000	But once people invent page rank, there's actually lots of extras that people want to do.
4018000	4022000	So there's still kind of problems and we'll talk about some of them.
4022000	4030000	The first thing is that page rank measures the popularity in general of the page.
4030000	4032000	How popular is the page?
4032000	4036000	But maybe I'm only interested in stamp collecting
4036000	4040000	and I want to know what is the best page for stamp collecting
4040000	4044000	and I'm not interested in, in general, popularity.
4044000	4047000	Maybe there's not so many people doing stamp collecting
4047000	4054000	and there's many more people interested in Kalashnikov machine guns than stamps.
4054000	4059000	So there would be no stamp pages who had much less popularity.
4059000	4064000	So you want maybe a page rank that knows about topics.
4064000	4067000	Okay, so we'll explain that a little bit.
4067000	4074000	And another thing is you can take this, you can also have used page rank to find similarities.
4074000	4079000	That's important if I, for example, if I'm looking for pictures,
4079000	4084000	I'm looking for pictures of trees, for example, and I have this very nice palm tree
4084000	4090000	and I want similar pictures, you can use a similar algorithm than this
4090000	4094000	to find similarity, similar pages.
4094000	4098000	That's nice, okay, that's one thing.
4098000	4101000	That's, that's making it very specific.
4101000	4112000	Another problem is spam, okay, it's possible to spam or to cheat on the page rank
4112000	4116000	and this is called web spanning and you can do things like live farms
4116000	4118000	and there's a way around that.
4118000	4122000	You have to somehow know what are trusted pages.
4122000	4125000	So there's an algorithm called trust rank.
4125000	4131000	And finally, the Hudson authorities, we, there's two kinds of importance.
4131000	4136000	There's the pages that are important, but also the pages that lead to important pages.
4136000	4139000	So page rank only has one measure.
4139000	4142000	Okay, so that we saw last time.
4142000	4148000	But I'm going to talk about these two, topic specific and web spamming.
4148000	4154000	So beyond page rank, first it's topic specific.
4154000	4161000	So I have some graph here with the heavy notes and the heavy links and the light links.
4161000	4164000	But I'm interested in some kind of topic.
4164000	4170000	So I want only to look at the good pages in a particular topic.
4170000	4171000	So how do I do that?
4171000	4176000	I have to give more influence to pages that are close to some topic.
4176000	4181000	And the way to fix that is you change how you teleport.
4181000	4190000	Instead of teleporting to any random page, you teleport to pages that are kind of rubbed,
4190000	4195000	okay, that have something to do with sports or spam collecting.
4196000	4203000	But once you know that you have the teleport set, you change the teleport set,
4203000	4206000	you can still use the regular page rank.
4206000	4210000	So that works really well for the topic specific element.
4218000	4222000	Okay, how do we get this teleport set?
4222000	4224000	Well, there's different ways.
4224000	4227000	You can use classic techniques from older search engines.
4227000	4233000	You can look at the contents of the pages for that, okay?
4233000	4238000	You could also look at who is making the query, okay?
4238000	4242000	You could look at browsing history, okay?
4242000	4245000	Find type Manchester, what do I mean?
4245000	4250000	Do I mean football team or do I mean the city Manchester?
4250000	4253000	Well, it depends on my browsing history, maybe, okay?
4253000	4258000	So there's many ways to do that kind of stuff, okay?
4258000	4261000	And that's how topics specific works.
4261000	4267000	Another way you can extend the page rank is measuring similarity or proximity.
4267000	4269000	So here's an example.
4269000	4272000	Let's say we have this graph here.
4272000	4275000	Look at these two notes, one and four.
4275000	4278000	How close are they?
4278000	4282000	Some sets, or seven and one.
4282000	4284000	How close is it?
4284000	4287000	Because the shortest path is the same.
4287000	4289000	One, two.
4289000	4293000	But maybe four is closer because there's more paths.
4293000	4296000	Maybe four is closer to one than seven.
4296000	4300000	Because seven is only one path, okay?
4300000	4302000	Multiple two-out paths.
4302000	4306000	Only one path from one to seven, okay?
4306000	4309000	So that's one way of extending it.
4309000	4313000	So this is called sim rank.
4313000	4315000	So here's another example.
4315000	4320000	I have four pictures and I want to show how similar are these pictures.
4320000	4324000	So picture one has a house and a tree.
4324000	4327000	Picture two has a house and a mountain.
4327000	4329000	Picture three has a house and a tree.
4329000	4332000	And four has a tree and a mountain.
4332000	4337000	So which pictures are similar to picture one?
4337000	4341000	How similar is picture one to four, okay?
4341000	4344000	Or maybe there's ones that are closer.
4344000	4349000	One to three might be closer because they're both having a house and a tree.
4349000	4355000	So we can use something like patron to figure that out, okay?
4355000	4359000	So this is kind of like topic-specific.
4359000	4365000	Again, we want to bias the telechord sets.
4365000	4367000	And recapitulate the page rank.
4367000	4371000	So it's a kind of variation on the page rank.
4371000	4376000	So the idea is that the telechord set is the node itself.
4376000	4380000	So the node is closest to itself, okay?
4380000	4384000	Usually the telechord set is all relevant nodes.
4384000	4388000	But here the node is the one closest to itself, okay?
4388000	4393000	So that's one way that you modify the page rank.
4393000	4398000	You make random walks from a fixed node, okay?
4398000	4402000	And then you can do things like, here's an example with authors,
4402000	4405000	conferences, and tags.
4405000	4411000	So articles, authors, people writing articles on this.
4411000	4414000	So this you do it for all nodes.
4414000	4418000	This is actually used in the website called pinterest.
4418000	4421000	You may be using it for recognition.
4421000	4425000	They use something like this, okay?
4425000	4431000	So this is also known as page rank with restarts.
4431000	4434000	So here's the example with the pictures.
4434000	4438000	So what is the most related picture to picture one?
4438000	4439000	Okay?
4439000	4442000	You have your telechord set which is picture one.
4442000	4446000	And you do your random walks with the restart.
4446000	4452000	And the result of this is going to be picture three, okay?
4452000	4457000	So if you look here, here you have your graph with seven nodes.
4457000	4461000	Here you have your transition matrix, okay?
4461000	4466000	And now you do the convergence of this, okay?
4466000	4468000	And you can see, notice you have two groups.
4468000	4472000	You have the pics, the four, the four pics on the top
4472000	4477000	and the three attributes on the bottom, okay?
4477000	4484000	So you compute the page rank matrix.
4484000	4489000	And you can see that here you can do the restart, okay?
4489000	4491000	On pic one.
4491000	4495000	So from pic one, you go one, two, three, four,
4495000	4497000	attack the telechords.
4497000	4506000	And here you have the three things on the bottom, okay?
4506000	4511000	And the result is that pic one and pic three are going to be the closest
4511000	4514000	when you converge this, okay?
4514000	4518000	That's one way of extending page rank.
4518000	4522000	And in this other example, when I note one,
4522000	4527000	you can see that one and four are pretty close, 0.24,
4527000	4531000	but no seven is farther away, 0.07, okay?
4531000	4537000	So basically doing the page rank with the restart, okay?
4537000	4541000	So that gives us three kind of variations of page rank.
4541000	4546000	It's a normal page rank, which teleports randomly.
4546000	4550000	We have the topic-specific page rank,
4550000	4554000	which teleports to pages that are relevant,
4554000	4560000	and we have the same rank, which always teleports to the same node
4560000	4562000	for finding similar notes.
4562000	4568000	So these are three different ways of using page rank, okay?
4568000	4572000	So now the final thing I want to say is web spamming.
4572000	4577000	How do you, you can cheat on page rank, okay?
4577000	4580000	What is web spamming?
4580000	4587000	So web spamming is a deliberate action to boost a web page in ranking.
4587000	4593000	And there's lots of these web, there's lots of spam pages, okay,
4593000	4599000	which are created only to appear your rank results that should not be there.
4599000	4604000	So this thing, like I mentioned before, has a very dignified name
4604000	4609000	called search engine optimization, but it's basically cheating.
4609000	4613000	So Google has spent a lot of effort combating this.
4613000	4617000	So let me talk a little bit about cheating.
4617000	4619000	How do you cheat on the web?
4619000	4621000	In the early search engines, how did they work?
4621000	4625000	So they crawl the web, they look at all the pages, they index the pages,
4625000	4630000	and they respond to queries with your pages containing words.
4630000	4633000	That's the old names that go for page rank, yeah.
4633000	4638000	That's very easy to cheat there.
4638000	4641000	How do you measure the importance?
4641000	4647000	Well, in the early search engines, you look how many times the words are there,
4647000	4652000	or what is the header, if the header words, okay?
4652000	4656000	So of course it's very easy to cheat, you do that.
4656000	4661000	So as people began to use search engines, there were companies
4661000	4664000	that tried to exploit it to cheat.
4664000	4666000	So here's an example.
4666000	4673000	So I'm selling shirts, and I want lots of people to come to my website.
4673000	4676000	So I want to pretend that my website is about movies.
4676000	4678000	So how do I do that?
4678000	4680000	Well, I use a technique.
4680000	4684000	For the early search engines, it was pretty easy, okay?
4684000	4688000	How do I make my page appear to be about movies?
4688000	4689000	It's very easy.
4689000	4693000	I add the word movies a thousand times to my page,
4693000	4697000	but I make it so it's white so nobody sees it,
4697000	4701000	and search engines will see it, yeah.
4701000	4708000	And can you also spam on the importance of your page?
4708000	4710000	Yeah, this is before page rank, yeah.
4710000	4714000	So this doesn't work anymore now, giving it for history.
4714000	4716000	But there's also a way to spam page rank,
4716000	4718000	which I explained in a few minutes.
4718000	4722000	It's just called link farms, okay?
4722000	4725000	In other ways, you run the query movie,
4725000	4728000	you see what is the page that came first.
4728000	4731000	So that's the important page, and you take the text of that page,
4731000	4735000	you just copy it into your cheat.
4735000	4742000	This is called term spam, okay?
4742000	4746000	So Google made a solution to that.
4746000	4750000	Instead of using the words in the page,
4750000	4754000	use the words in the link to the page,
4754000	4758000	which is called the anchor text and the surrounding text,
4758000	4760000	so what people say about the new.
4760000	4764000	And of course, use page rank to measure the importance.
4764000	4768000	So with page rank, the short seller doesn't work.
4768000	4771000	His technique doesn't work anymore.
4772000	4777000	It doesn't matter if the short seller puts the word movies in his pages,
4777000	4782000	because no movie pages are going to link to this page, okay?
4782000	4789000	So he's not going to be ranked high for movies, or even for shirts.
4789000	4791000	But you can cheat on this.
4791000	4797000	And this is called link farms, okay?
4798000	4804000	Okay, so let's say the short seller, he creates 1,000 pages.
4804000	4809000	Each of those pages links to the movie page, okay?
4809000	4812000	Yeah.
4812000	4815000	But those pages are no in-links.
4815000	4817000	That doesn't really work, God.
4817000	4822000	Even if he makes a million pages pointing to the shirt page,
4822000	4825000	real important movie pages like IMDB,
4825000	4829000	there's no way you can beat them, okay?
4829000	4839000	But, but there is a way to beat page rank.
4839000	4843000	We span farming, kind of coordinated with that.
4843000	4847000	This has been used, and it's sometimes called Google bombing.
4847000	4851000	A few years ago, now it works too.
4851000	4855000	But if when George Bush was president,
4855000	4858000	you type miserable failure in Google,
4858000	4861000	it's a choice to the biography of George Bush.
4861000	4864000	It's nice, isn't it?
4864000	4867000	Miserable failure links to Bush,
4867000	4869000	and it still does, it's called Google bombing.
4869000	4871000	So how does that work?
4871000	4874000	It's possible to do that, to cheat.
4874000	4877000	This is called spam farming.
4877000	4882000	It's possible to create a structure in the graph
4882000	4887000	that concentrates the page rank of a particular page.
4887000	4890000	Okay? How does that work?
4890000	4894000	So, I'll show you the technique.
4894000	4898000	So, basically it works like this.
4898000	4903000	There's three, there's three kinds of pages.
4903000	4905000	So let's say I'm a spammer.
4905000	4907000	I want to cheat, okay?
4907000	4910000	I want to increase the page rank of some page.
4910000	4912000	So I look at the web,
4912000	4915000	and there's three kinds of pages for my interview.
4915000	4918000	There's inaccessible pages.
4918000	4920000	That's pages owned by other people.
4920000	4922000	Most of them are inaccessible.
4922000	4924000	Then there's accessible pages.
4924000	4926000	These are pages owned by other people,
4926000	4930000	but I can add something to the blogs, for example,
4930000	4932000	or comments, reviews.
4932000	4934000	I can post there.
4934000	4937000	I can put something there, even though I'm not the owner.
4937000	4939000	It's called accessible pages.
4939000	4941000	And finally, there's a small number of pages
4941000	4944000	that are owned by me, spammer.
4944000	4946000	These are called owned pages.
4946000	4948000	So I have these three kinds of pages.
4948000	4950000	So how can I use this?
4950000	4953000	So that's the structure.
4953000	4956000	So here's the web.
4956000	4958000	This is the whole web.
4958000	4960000	And here is the page,
4960000	4963000	and I want to increase the page rank of this one.
4963000	4966000	So how do I do it?
4966000	4969000	I want to maximize the page rank of the team.
4969000	4971000	The web has two kinds of pages.
4971000	4973000	So the green ones,
4973000	4976000	those are the ones that I can add something to,
4976000	4978000	even though I'm not the owner,
4978000	4982000	like their blogs, or I can put a comment, or something.
4982000	4985000	Then the others are inaccessible.
4985000	4987000	I have no control over them.
4987000	4989000	Most of them are inaccessible.
4989000	4992000	You might have a few pages where you can add,
4992000	4994000	but most of them are owned by other people.
4994000	4996000	So I can't do anything to her.
4996000	4998000	Fine.
4998000	5000000	So what do I do?
5000000	5002000	Well, the first thing I do
5002000	5006000	is I post on as many places as I can,
5006000	5008000	links to team.
5008000	5012000	I link to team from as many accessible pages as possible.
5012000	5014000	That's the first step.
5014000	5016000	It's not enough, but it's the first step.
5016000	5018000	That will already increase a little bit
5018000	5021000	the page rank of the team.
5021000	5023000	But that's not enough.
5023000	5025000	What I really have to do then,
5025000	5027000	is I do another step
5027000	5031000	where I construct what's called a link farm
5031000	5036000	to multiply the page rank of team.
5036000	5039000	So these red pages are my pages.
5039000	5041000	So I buy a bunch of machines,
5041000	5043000	or I rent machines,
5043000	5046000	and I can write anything I want on them.
5046000	5050000	This is my link farm, the obvious red pages.
5050000	5052000	And the link farm pages
5052000	5054000	will all point to team,
5054000	5056000	and team points back to them.
5056000	5058000	So it seems kind of weird,
5058000	5060000	all these pages are going to point to team,
5060000	5064000	and on team I make the link back.
5064000	5067000	And that's called the link farm.
5067000	5070000	And these red pages are owned by me.
5070000	5072000	So how does this work?
5072000	5077000	So this will actually improve my page rank.
5077000	5079000	Notice there can be many here,
5079000	5082000	not billions, but not billions.
5082000	5084000	But there could be millions.
5084000	5086000	So how can this work?
5086000	5088000	So let's make some computations.
5088000	5091000	Let's compute the page rank now.
5091000	5095000	So let's say there's N pages
5095000	5097000	that are getting accessible.
5097000	5099000	N is huge numbers.
5099000	5102000	And there's N pages that are owned by me.
5102000	5104000	Which is also being numbered
5104000	5107000	much smaller than N.
5107000	5112000	Let's say that little x in green
5112000	5116000	is the page rank that comes from the accessible pages.
5116000	5120000	It's not so big, but there's some numbers.
5120000	5124000	And Y is the page rank of page T.
5124000	5127000	Now we can compute according to page rank
5127000	5129000	what it's going to be.
5129000	5131000	So first of all, what is the rank
5131000	5133000	with one of these pages?
5133000	5135000	What is the rank?
5135000	5137000	Several sources of rank.
5137000	5141000	One rank, one source comes from the outlet of T.
5141000	5147000	But another one comes from the teleportation.
5147000	5149000	So it's like this.
5149000	5153000	So each form page has this rank.
5153000	5155000	So Y is the rank of T.
5155000	5159000	So it's beta Y over M
5159000	5163000	plus 1 minus beta over N.
5163000	5164000	See that?
5164000	5167000	So it's the page rank coming from T
5167000	5170000	and the teleportation rank.
5170000	5173000	Okay?
5173000	5175000	Okay, let's go on.
5175000	5178000	So what is the rank of page T?
5178000	5184000	Well, it's the page rank coming from the green pages
5184000	5186000	plus all the page rank.
5186000	5189000	These only have one update.
5189000	5191000	And they're all going to T.
5191000	5194000	So it's M times beta
5194000	5198000	and this is the page rank coming from the red pages.
5198000	5201000	Beta Y over M plus 1 minus beta over N.
5201000	5205000	You also have teleportation to page T.
5205000	5207000	So this is a very small one.
5207000	5208000	Okay?
5208000	5210000	So here we have a nice formula.
5210000	5212000	So let's simplify this
5212000	5215000	and see what we can learn from it.
5215000	5217000	Okay?
5217000	5219000	So we can simplify this a little bit.
5219000	5224000	So this Y is equal to X plus beta squared Y
5224000	5227000	plus this beta times 1 minus beta
5227000	5229000	times M over N
5229000	5233000	plus this very small number.
5233000	5235000	Okay?
5235000	5239000	This number we should remove is too small.
5239000	5241000	And then we simplify.
5241000	5245000	We have Y on both sides here.
5245000	5247000	So it's 1 minus beta squared.
5247000	5252000	So Y is equal to X divided by 1 minus beta squared
5252000	5256000	plus this number
5256000	5262000	divided by 1 minus beta squared.
5262000	5265000	So it's some constant times M over N.
5265000	5268000	So what does that mean?
5268000	5269000	Okay?
5269000	5273000	So the value of the constant is beta over 1 plus beta.
5273000	5275000	Okay?
5275000	5283000	What can we learn from this?
5283000	5285000	What can we learn from this?
5285000	5289000	How can we increase now the page rank of Y?
5289000	5293000	Notice there is this M factor here.
5293000	5296000	By making M large,
5296000	5299000	we can make Y as large as we want.
5299000	5302000	So independent of everybody else.
5302000	5305000	If we put a million pages here,
5305000	5307000	we make it large.
5307000	5310000	If we put 10 billion, it's much bigger.
5310000	5313000	You add a number proportional to M.
5313000	5317000	So that means the more pages you put in the farm,
5317000	5320000	the higher the page rank it gets.
5320000	5322000	Okay?
5322000	5326000	And that's how these big farms work.
5326000	5327000	So how can that work?
5327000	5329000	What is really the idea here?
5329000	5330000	How is this working?
5330000	5333000	Well, it's because these farm pages,
5333000	5337000	they all get teleportation is going to them.
5337000	5340000	And the more you have them,
5340000	5344000	the bigger fraction of teleportations will go there.
5344000	5348000	So the teleportation here,
5348000	5353000	1 minus beta over N times M.
5353000	5357000	So it depends on the fraction of M over N.
5357000	5360000	The bigger that M is,
5360000	5363000	the more the teleportation will go there,
5363000	5366000	and the more you can increase the page rank.
5366000	5369000	And it doesn't matter what anybody else does.
5369000	5371000	They do whatever they want.
5371000	5375000	If I'm rich enough, I just have to create a lot of pages,
5375000	5377000	and the teleportation will go there,
5377000	5379000	and I can increase that.
5379000	5382000	So the search engine optimizers,
5382000	5385000	this is what they do.
5385000	5386000	Okay?
5386000	5391000	The random teleportation from all the web to the farm nodes
5391000	5397000	gets concentrated and pushed into page T.
5397000	5399000	Okay?
5399000	5404000	And this is how the big farms work.
5404000	5405000	Okay?
5405000	5408000	Actually, you might say,
5408000	5413000	yeah, M is still going to be very small compared to M.
5413000	5414000	This is true.
5414000	5420000	But you don't have to have M be large compared to M.
5420000	5424000	It just has to be larger than your competitors.
5424000	5426000	So if you're a shirt seller,
5426000	5429000	as long as you get higher up than other shirt sellers,
5429000	5430000	you're good.
5430000	5434000	You're not competing with really popular pages,
5434000	5435000	like Amazon or someone.
5435000	5439000	You're only competing with other shirt sellers.
5439000	5443000	So M doesn't even have to be that large.
5443000	5448000	But of course, the shirt sellers will all be paying these companies
5448000	5454000	the search engine optimizers for increasing their rank.
5454000	5459000	And the one who pays the most will increase the rank the most.
5459000	5460000	Okay?
5460000	5465000	So this was a big problem for people in the early days.
5465000	5469000	They have now fixed sort of that problem.
5469000	5472000	So a lot of the problem, you see how it works up.
5472000	5476000	So a lot of the problem of this has been fixed now.
5476000	5482000	This was a big problem in the first decade of the 2000s.
5482000	5484000	Really big problem.
5484000	5488000	But so Google spent a lot of effort to try to fix this.
5488000	5492000	So the algorithm they use now is a secret.
5492000	5494000	Nobody knows what it is.
5494000	5495000	Okay?
5495000	5499000	And does it fix the problem?
5499000	5500000	I don't know.
5500000	5501000	What do you think?
5501000	5505000	Is there still doing people doing search engine optimization?
5505000	5506000	Yes.
5506000	5507000	They still do it?
5507000	5508000	Yeah.
5508000	5511000	That means Google is not that successful, right?
5511000	5514000	But here's an idea how to fix it.
5514000	5516000	This is called trust rank.
5516000	5520000	And it's based on concept of what's called spam mass.
5520000	5522000	So we want to combat this.
5522000	5524000	So this is called linked spam.
5524000	5525000	Okay?
5525000	5528000	How do you combat this?
5528000	5532000	Well, one way is that you know where the spam farms are.
5532000	5534000	You blacklist them.
5534000	5539000	But of course they're not going to announce themselves publicly.
5539000	5540000	Okay?
5540000	5543000	So that doesn't always work.
5543000	5549000	But the other way would be teleporting only to trusted pages.
5549000	5553000	This one here you're teleporting to all these pages.
5553000	5555000	Even the farm pages.
5555000	5558000	But maybe they're not trusted.
5558000	5564000	So somehow you have to find out what are trusted pages.
5564000	5567000	And you teleport mostly to them.
5567000	5570000	Okay?
5570000	5576000	And the idea is it's very rare for a good page, a non-cheating page,
5576000	5578000	to point to a spam page.
5578000	5582000	These spam pages tend to be hidden inside linked farms.
5582000	5583000	Okay?
5583000	5588000	So you change your teleport set, again, to be not everybody,
5588000	5590000	but trusted pages.
5590000	5595000	So it's a variation of topic to specific patron.
5595000	5597000	Okay?
5597000	5601000	So you do a trust computation.
5601000	5605000	You start from trusted pages and you compute trust.
5605000	5609000	And you split trust across the outline of the names.
5609000	5613000	And the degree of trust, so you have some pages trusted at.
5613000	5616000	What a New York Times trusted page.
5616000	5619000	The degree of trust decreases with the distance.
5619000	5622000	So there's some way of distributing trust.
5622000	5625000	Okay?
5625000	5627000	So this is not that easy.
5627000	5632000	Because you can't actually inspect all the pages manually.
5632000	5635000	You want to have a lot of pages that are trusted.
5635000	5637000	The more the better.
5637000	5639000	But you have to make sure they're trusted.
5639000	5642000	So how do you do that?
5642000	5645000	Well, one way is just page rank itself.
5645000	5652000	Usually the top pages produced by page rank are okay.
5652000	5658000	Because the linked farms, they can't actually push the page up so high.
5658000	5664000	Or you have certain domains where you know that it's trusted.
5664000	5668000	The dot edu domain is universities, for example.
5668000	5673000	Or government pages, Hart-Milston, for example.
5673000	5675000	Okay?
5675000	5681000	And all pages below the threshold are marked as spam.
5681000	5686000	But that's still not really good enough.
5686000	5692000	So the way that it's done in the trust rank model
5692000	5696000	is you have this concept called spam mass.
5696000	5699000	So you start with this green trusted set of pages.
5699000	5703000	And you want to say, and this is the page you're looking at.
5703000	5706000	And then you're looking at the page rank of this page.
5706000	5711000	And you want to say, how much of this page rank is coming from spam?
5711000	5715000	How much is coming from trusted pages?
5715000	5717000	Okay?
5717000	5718000	So there's some kind of estimate.
5718000	5720000	We don't really know.
5720000	5724000	RP is the page rank of page P.
5724000	5732000	RP plus is the page rank of P when you teleport into trusted pages only.
5732000	5737000	And then RP minus is the difference between the two.
5737000	5739000	And this is called the spam mass.
5739000	5746000	How much of the page rank comes from spam pages?
5746000	5748000	Okay?
5748000	5755000	So a fraction of the page rank is coming from spam pages.
5755000	5757000	So pages with high spam mass are spam.
5757000	5759000	You throw them out.
5759000	5760000	Okay?
5760000	5763000	So even pages that are not in the trusted set,
5763000	5767000	you can keep them if they have low spam mass.
5767000	5769000	Okay?
5769000	5774000	So this kind of idea, you have to do this
5774000	5778000	to not be killed by big farms.
5778000	5780000	Okay?
5780000	5782000	So this is one approach.
5782000	5785000	The question, what does Google do today?
5785000	5789000	It's not really known except for some people working at Google.
5789000	5791000	It's kind of a secret.
5791000	5793000	And that helps them, of course,
5793000	5798000	because it's hard to cheat if you don't know the algorithm.
5798000	5799000	Okay?
5799000	5803000	So let me now just summarize the page rank.
5803000	5806000	Page rank is one of many powerful techniques.
5806000	5808000	It's a kind of random block.
5808000	5810000	So we looked how that works.
5810000	5813000	We represented it with matrices.
5813000	5818000	So it's the constant eigenvalue eigenvectors can help us,
5818000	5821000	okay, for understanding it.
5821000	5825000	I showed a little bit of the history.
5825000	5827000	That is the problems.
5827000	5829000	The matrices are very big.
5829000	5831000	So how do you handle huge matrices?
5831000	5834000	How do you handle topics specific?
5834000	5840000	So there's a narrowing to topics specific, teleports specific topics.
5840000	5843000	You can also use it for finding similar nodes.
5843000	5845000	And you can spam it.
5845000	5849000	So I showed you how linked farms work.
5849000	5851000	They can increase the page rank.
5851000	5855000	But you can combat that using algorithms such as trust rank
5855000	5858000	to estimate spam mass.
5858000	5863000	And so the linked farms won't kill you.
5863000	5864000	Okay.
5864000	5866000	So let me end there.
5866000	5872000	So that gives you some idea of all of the stuff going on around the page rank.
5872000	5875000	So, of course, the page rank is very important.
5875000	5877000	It was a key invention.
5877000	5881000	It's what made Google rich at base.
5881000	5886000	And the step after that was the advertising.
5886000	5890000	It was targeted advertising with the generalized second price.
5890000	5895000	So that and page rank is what Google made their empire out of.
5895000	5896000	Okay.
