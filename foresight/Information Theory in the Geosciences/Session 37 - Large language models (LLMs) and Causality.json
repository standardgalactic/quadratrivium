{"text": " All right, I'm happy to introduce Antoine, a very energetic young man who joined a research program when it was in January, just this past year, this year. And before that, Antoine was working with this startup company called Extra Lab. He was on their software engineer side, helping develop systems for capturing river water quality data with the technology that was developed by the founder of Extra Lab. But I'm glad he came to us to do his PhD and has been working on issues related to causality and large language models, and he can tame GPD like nobody else. So with that, Antoine, all yours. Okay, so thank you, Praveen. So indeed, today I'm going to talk to you about LLM's and causality. As you can have guessed, if any of you just took a small quick look at the papers, cyber-voted Lila last time. So just to put it back in a bit of a context, this is a picture I use in all my presentations that I used to illustrate what's going on with climate change right now. And this is just more than 20 inches of precipitation in one night and for a lot of day. And it's just to exemplify how climate change changes the way that extreme events are happening and how can we do to stop them and how can we tackle those problems. And this is, so as Praveen introduced, I'm not going to spend a lot of time on this, but the statement here is that the decision-making process is critical in the resilience, in increasing or decreasing resilience to climate change risks, and so to address the extreme events. The problem is decisions are taken by humans, and until recently we didn't have GPD, and understanding natural language with mathematics is complicated. And there is no breakthrough framework until GPD came out, which we've seen as an opportunity to try to understand how humans think in language. So what I'm working on right now is using GPD agents to generate multiple decision pathways based on a context of an extreme event, let's say a forecast of a flooding for a city. And we use multiple GPD agents to talk to each other in order to come up with decisions pathway, which then we can evaluate to understand whether it is good or bad decisions. And this is just the start of a work in which we will try to maximize resilience and see what is the takes of LLMs and AI in that particular problem. So I'm going to be presenting that at AGU, have a talk on the morning, Monday morning. So if you want to see what it's about, I would gladly see you in the audience. But so we'll get back on the subject here. So I talked a bit about LLMs. Even I'm pretty sure that everyone here is familiar with what it is. Still, I'm going to say, so large language models, they are the class of language models, such as GPD, etc., usually based on the transformer architecture. And so those models receive a text input and will make predictions, textual predictions. They're known because they're really good at understanding human language in the sense that they are a great conversational agents. So GPTs, Barrett, Paul, and Lama, there's a lot of them. And you've probably heard about a couple. And so as for applications of LLMs, translation tasks, you can use them for text generation, report story scripts. You can ask an LLM to generate 10 different poems on a subject you like in that particular style, for instance, can use LLMs for Q&As, synthesizing, etc. So this is what an LLM is like. Now, introducing causality is rather complicated because it's a complicated term. But I'm pretty sure, again, the most part of you are really familiar with what causality is. So I'm just going to say it's a relation, studying causality, studying relationships between cause and effect. Due to Pearl dedicated the major part of his life, working on that, I'm pretty sure you're all familiar with his work. So I'm not going to stain his image, trying to give another definition that wouldn't serve no purpose. Um, causality carries more information than correlation, which is why it is so interesting. Studying causality is more important than studying just statistical correlations, for that matter. This is why there is a lot of work on studying causality, in order to understand how natural processes interact with each other. And the question now is, how does those two concepts connect? Why do we even have this question of can LLMs infer causality? The question comes from the fact that LLMs learn their input data, their training data is huge corpus of text that ranges from Wikipedia articles to blog posts to books, etc. So literally what they are is just a condensed experience of what the world beat them. And in those texts, there is a lot of information about describing processes and everything. So today, if you ask a GPT agent, I see it start to rain. What is the impact on the ground? And the LLM will answer the ground will be wet. So it may appear that the LLM is able to infer causality in that particular setting, because it is able to tell you what is going to be the outcome of a situation you describe. But a lot of people have been digging into this and trying to figure out if this is really causality or no, and if it is, which type of causality it is, and we'll get back to that later. And let's say they were really possible of inferring causality, what would be the implications on future research on a world, etc. And I just want to finish this by putting another small motivation point, which is that if we get back to my previous topic and the thing I'm working on, from Zhang et al. from this paper says, decision-making scenarios require a quantitative understanding of the effects of actions leading to the desired outcome. In another way, if we want to be able to tackle precisely decision-making problems, we need to have an understanding of cause and effects. Otherwise, it's complicated to have all the causal chains of actions that would be triggered by one particular decision. So this is a bit of the motivation why it would be interesting for us to understand whether LLMs are able to do causality or not, and which one. So just a quick view of the papers I used to do this literature review. Those two first paper are by Jin et al. The first one, they present Clutter, which is a causal benchmark. They use in order to evaluate LLMs to causal task, as well as fine-tuning LLM models to see if they could approve their results. The second one, they introduce a task for LLMs to be evaluated on, which is called core to causation. So basically, they try to convert correlation to causation and see how well it translates. The two next papers, Kissiman and Lyudel. So Kissiman et al is yes, it's just another study of multiple types of causality evaluation on LLMs. Lyudel 2019, this one is a bit interesting because it's older. So this one was out before the LLMs actually were advertised and were that popular. And this one uses a different approach using intelligent agents, but I will get back to that. And the last one, Vetservish is probably the most interesting in this one because it's the most, not unbiased, but they make the strongest statements. They say that LLMs are causal parrots and they can maybe appear to talk causality, but deep inside, they're not at all and never will be. So they make quite strong statements and it's interesting. And the last one, the last one is early 2023 and gives a couple of insights on future work and future directions, but don't give a lot of answers in there. So I'll just start by quickly reminding for this, for the purpose of this study that the difference between causal discovery and causal inference tasks, because those concepts are used in the papers. So causal discovery is constructing a causal structure. Basically it is figuring out a dag, a directly, sorry, directed a cyclic graph in which all the nodes are variable and there is a link between the nodes when there is a functional relationship. The causal discovery holds a structure for, in order to be able to infer causality on multiple levels. Multiple levels of causality, as defined by Perl, are observational, interventional and counterfactual. Where observational, you only need to observe the cause and effect for you to be able to say that this is causal. Interventional requires the intervention, so changing a variable and seeing if there is an effect on another one. And counterfactual is knowing that there is a causality link. It is the highest level of causality. Knowing there is a causality level and two variables, what would happen if you would change the variable in such a way? So they just remind the difference between discovery, which is more about finding the structure that ties all variables together and explaining the possible relationship that can be between. And causal inference would be more about determining what level, what strength of causality there is between two variables and which direction to. And so the first results that are given by Kissimer et al. So they work on inferring causal discovery. So what they do is they're trying to come up with that direct to stick with graph using an LLM. And so the findings are that the best LLM in the list, GPT-4, and is almost always GPT-4, art performs causal discovery frameworks by approximately 40% on the Tobingen benchmark on pairwise causal discovery tasks. So for two variable, two by two variables, is being able to find out if they could be related in some way or not. And so this is the list of the model they tested. And almost every time is GPT-4 performing at the best. So this is quite an interesting result, but they also balance that result with the fact that LLMs present a strong lack of robustness because when they fail, it is really unpredictable to predict. It is really unpredictable the fact that are going to fail or not. So you might have 96% of accuracy, but it's hard to predict when they will fail. This is what they put the accent on when they present their results. As for the benchmark they use, it is very diverse. So over 100 causal relationships from a variety of domains, physics, biology, zoology, cognitive science, epidemiology, soil science. So there is a couple of examples of relationships that are in their framework for use to be LLMs. So for instance, alcohol and main corpuscular volume. So a question like this will be asked to the LLM and whether depending on the answer is yes or no, it will compare the answer with the real in the framework to establish the accuracy person. Sorry. So the second result is by Zetz Avicila. They do a lot of different types of causal inference and causal tasks in their study. It's very complete. They also do a causal discovery task, which is pretty much the same. They feed a scientific question to the LLM and depending on the answer, they say yes or no to the establishing of causal discovery. So this is the results they get. Where GPT-3, GPT-4 are open AI models. LUMINUS is a model that is built by LUMINUS. It's the corporation itself and OPT is the META Facebook LLM. So yes, Russian? Just to clarify, they're just checking the question and the answer. They're not actually checking the chain of reasoning. No, not in this one. There is some frameworks and some benchmarks in which they use a chain of thoughts prompt engineering in order to be able to check the chain, but not in this one. And they're just using off-the-shelf LLMs. They're not specifically trained for these. No. Well, yes and no. So they're off-the-shelves LLM. They're not fine-tuned. However, they make some assumptions that in some cases, the enormously high result for GPT-4 could indicate that some parts of the benchmark are actually included in GPT-4's training, but it's hypothetical. They don't have that knowledge. It's just a hypothesis they make. But technically, no, it's just off-the-shelves LLM and these ones are not fine-tuned. And the assumption is that their answers that they have are well-established beyond dispute that this is the correct answer. Yes, I guess. Okay. Thanks. So yes, this is the result they give for LLMs. To be honest, it's a bit hard to interpret the results sometimes in this paper. There are some sections that are extremely clear as to the results and findings, et cetera. Some are less. This is actually one of the main negative point of this paper that's been highlighted on the open reviews. This paper in particular is going to be published in Transaction for National Learning. It's been reviewed on open reviews. So all the reviews are publicly available on open reviews. It's really interesting. I read a couple. And what's being said about this paper is that the math behind and the logic behind it is really strong, but sometimes the results are not well explained. And sometimes I just cannot tie the results to what they claim. But that's why we'll move on to the next one. This is the findings on different types of causal inference. So by Genital, the first paper. And so they test about 10 LLMs. They test their accuracy on observational, intranational, and counterfactual tasks. And on top of that, so they are tested again, the clatter dataset, which is composed of if I, yeah, 10,000 samples of approximately even distributed for every causal task containing different types of data. And they also come up with what they call causal cot, which is a fine-tuning model they did using their dataset. So they were trying to figure out at the same time how well LLMs performed on a causal benchmark, as well as if they find to the model what performance improvement do you have. And so they conclude that overall, the models just perform slightly better than random, which is not that great. They also conclude that there is two percent, there is approximately two percent difference in accuracy on TB4 and their fine-tuned version, which they say is outstandingly good. I personally, I think it's interesting to use this approach. However, the results are not that shining for now. And so this is one other result there is. In the second paper they present, this is another causal task, which they call chord cause. So basically, the point of this is to escalate one correlation relationships to causation. So you know there is a correlation. So let's say that causal discovery is almost done. You are sure there is a correlation, a grounded one between two variables. And the point would be to determine whether it is cold or not. And so this benchmark is run on 17 LLMs and also 12 fine-tuned LLMs, which is on the right side. So yeah, they give multiple metrics in there. Again, they say the results are not really incredible. They don't really conclude on the results. In none of the papers, based on the results, they are able to say yes, LLMs are able to do causality, no, LLMs are not able to do causality. Every time it's always very measured and every paper ends the same way. It's at this point, we're not able to refute the fact that LLMs can infer causality. So they have strong insights that they might or might not be able to, but they cannot come up with a conclusion in the end. Here, what is interesting to show is that in this particular case for escalating correlation to causation, there is a real impact in fine-tuning models. As we can see, the precision increases a lot between off-the-shelf models and fine-tuned models. So the takes of those two papers by Jin et al, which are separated for a two-month or three-month, if I remember correctly, and it's relatively linked. So the main overall take on those two papers by Jin is that using causal benchmarks is really interesting to LLM training as it can really improve the training performance and it can actually induce some of causal causality at least on that particular dataset in the LLM. And also that fine-tuning is really helpful in this scenario. Okay, so I'm good. Yeah, of course. In the previous slide, you mentioned that in the previous one. In the previous one, sorry. I know it's there. They test for counterfactuals. Oh, sorry. This one? Yes. Okay. They test for counterfactuals and interventionals, right? How do they test for counterfactuals? I don't really know because they don't give any example. If I remember correctly in the papers, they don't give any example of any example. Well, they do give example structures. They do give example structures of how their dataset is made, but they don't give like actual example that are fed to the models as questions and answer. So I'm not really able, let me just see real quick. No, because this is just the constitution of their dataset. They explain a bit how they do constitute their dataset. So they choose variables, generate causal graphs, map them, etc. So the data is composed like this, but they don't actually give examples to which their dataset. Maybe with the additional, in the additional supplementary information, probably they have something. In the supplementary information of the paper or something, they may have something. Well, this is already from the supplementary. Those two slides are from the supplementary information and I don't remember. I can take a look afterwards, but I don't remember seeing any example of what they actually feed. I have some for other benchmarks, but not for this one. I see. Thank you, Antoine. And so yeah, so I guess it's time to talk about this a little bit. This is a paper by Llewital 2019 and it's so it studies intelligent agent systems. I just want to say that it is, in my opinion, it is interesting in this context just because they focus on what is the importance of experience on learning potential causality. They use a different approach, which is still interesting because so here what they mean by intelligent agent systems or agent. They use the actual similar definition of agent that is in the context of complex adaptive systems. So where an agent would be defined by an entity that have sensors that is able to perceive the outside world actuators that can interact with the world and also an internal model that is just a logic for the agent to decide what it's going to do depending on the inputs it receives in the sensor and what it's going to do to the world. So this is how an agent is defined in the complex adaptive systems. And the difference with the intelligent systems, intelligent agent from the URL is that they also give the ability to understand natural language to their agents. So what do they do with those agents? They trained the agents on multiple life classical scenarios and then they use humans to create more training instances out of more scenarios and then they put those agents in those particular scenarios to see what they're able to do with it. So the agents have a bit of prior knowledge. Some more scenarios are created and then they use the agents. All the scenarios in this study are generated with a game in this fact. I'm just going to use this fact to add on the, I feel like some video games might present like the perfect ground for testing and simulating this kind of behaviors. There is a lot and a lot of different examples of people doing reinforcement learning on video games, learning AI strategies to drive a car for racing lines, this stuff. So I just wanted to make a small side note on the fact that video games represent a good training example. So in this case, this game is Minecraft. It's a game where you interact with the world. And so what they do, they put the agents in Minecraft and they generate a bunch of scenarios, which is like one, I attack the co and I attack the co. And this is the two outcomes. And for those two outcomes, the agent is going to infer causal or not causal. So based on their prior knowledge and more scenarios created by players and then are collected, then the agents are evaluated on whether they experience in learning from those scenarios, made them able to infer causality in new, newly presented scenarios. They gave a bit of the architecture they use to structure their model and their inference. So the shared experience is represented by, I guess, the pool of knowledge that all the agents learn all together. Those are events triggered. When you attack a cow, you get some beef. They don't give a lot of details, whereas all this works, if I remember correctly, but in the end, they just come up with a causal question, which the agents do inference on. And they're able then to classify what are considered as causal or not. And then they just compare with the example they had in first. So the principle of finding they give from this study is that experience mechanism is key for language concepts, understanding and learning, which is a very long turn of phrase for causality. So it is interesting. This paper is interesting in this way, because LLMs can be seen as agents in that they are trained and they learn out of huge text corpuses that represent, I don't know, novels, articles, blog posts, Wikipedia. Those can be seen as scenarios where the LLM will learn some knowledge. At the end, you can interact with an LLM as you can interact with those agents. Their inputs are the sensors and the text feedback they will give is the actuator. You can use an NNM as a robot if you ask, do some actions or something. So what's interesting is that if we put in parallel LLMs and the agents as described in this paper, well, basically what they say is that experience is key for causality. So they would be, from my understanding of that paper, what I get of that paper would be that more data, more training could eventually lead to causality, which is opposed to the thoughts that are given in different papers in this selection. I still think this one is interesting. It's a different approach. I think it's similar to what LLMs do today. Maybe some will argue that it's not, but I found this interesting. And I guess now it's time to dig deep in the biggest paper in the corpus, I think, which is ZetaVis. So it's the one when I said they make strong assumptions, strong claims that LLMs cannot do causality and never could. And the two main potential reasons they give is that the errors that are contained in the corpus used to train LLMs really hamper the outputs and hamper the knowledge base. So it would be like, it would be like putting poison in the brain. Eventually, it's not going to be able to function correctly. So what they say is that errors in the input data is going to be propagating to more errors in the output. So this is the first reason. And the second reason they give is the lack of physical data in training data set. They say that the whole difference between correlation causation is the physical evidence and the physical grounding of those facts. And they say that because LLMs are not trained with physical evidence, physical data, et cetera, well, they inherently haven't, they're unable to ground the facts they claim. To quote, they say prohibits any sort of induction of the actual data generating mechanism. So this is the two main reasons they give. And on top of that, they provide with mathematical explanation of why that stands. So the main contribution in that paper is that they define a subgroup of structural causal models named media SEM. So the structural causal model, it is, I've did my research on this, it is a bit unclear to me as if it's really defined by bongers of it, or if it was. Because I feel like a lot of, a lot of parts in this are shared with the Perlian theory of causality and more work on it. But if I quote the SEM was first defined by bongers at all in 2021, and this is the, this is the definition they give. So SEM is a tuple that contains all this. In short, if I try to simplify the definition of this, an SEM contains a series of structural equations in the Perlian sense. Well, that's, that's pretty much it actually. There are some details on the variable. I don't understand all the, all the subtleties to this definition. Yeah. Maybe we can get back to that later. Okay, they also remind a couple of definitions and insights. So they remind the Perl's causal hierarchy, which consists on three languages that can respectively do observational causality, inter-reventional causality, and counterfactual causality. And then they give their insight, their first thought on it. M be some SEM. So M, so SEM is a set of structural equations in that context. Knowledge about the structural equations and the causal graph of M is knowledge about answering L3 and L2 queries in M respectively. So their insight is that if M is an SEM, knowing about the structural equations in that SEM and the causal graph is enough to perform inter-reventional and counterfactual causality. And this is what they use to introduce their concept of a meta SEM, which is another SEM that is able to do inter-reventional and counterfactual just based on those information. So this is literally the definition they give for the media SEM. And then they will spell the rest of the paper trying to show that LLMs can be assimilated to media SEMs, which they cannot achieve actually. But I feel like just outlining those particular properties and giving the insights and everything is still a great contribution to the question in the sense that it's a first exploration of a real formal process in order to be able to determine whether LLMs are able to do causality or not. So they, yeah, Ocean. Oh, I can hear you. Just trying to parse what you just said, but it sounds like what they're suggesting using different language is that if you can, if you have enough information in the construct, the SEM, which is your representation, if you have enough information to answer interventional and counterfactual questions correctly, then they're saying you can infer causality. Would that be a good interpretation? In other words, if the representation does not allow you to answer those two kinds of questions, they're basically arguing that you can't infer causality. Yeah, I think this is a good summary of the definition. So it says something about the particular form of the representation that you need to have. In other words, is it answering the question correctly does not imply that you actually have, well, that's complicated. It seems to me that you need a particular structure which enables you to answer them, but answering them doesn't necessarily mean you have that structure. Anyway, that's kind of what I'm struggling with here. Okay. Okay, so I'll just continue. So this is the conjecture that you make, M1 be an SEM and 2 a respective media SEM. So it means that M2 is able to answer queries on M1 based on its observational data. So basically M2 would be the LLM in this one. So then define Q and A in the language and in the interventional language of M1, observational language of M2, causal queries with their respective answers, blah, blah, blah, then we have FQ equals A is equivalent to FQ minimizes training error. So basically what they say in this conjecture is that F of Q, which is the LLM's predictive models. So the predictions based on the interventional of M1 equals the observational of M2 minimizes training error. So basically what they say is that you don't learn anything more. I'm sorry. I don't know if that's really clear. I'm going to try this again. What they try to say here is that an LLM learning on the interventional and not learning anything more based on that model being able to already have the knowledge on the observational distribution of M2 is equivalent. So basically in the information of the observational distribution of M2, you already have all the informations to do interventional querying on the other SCM means that the LLM minimizes training error. So in that case means that the model converges and it is able to do it. This is the conjecture, in other words, this is the conjecture they come up with to say that if an LLM can be assimilated to a meta SCM, so it is able to escalate the causal task rank based on observational data, then it is causal. This is the conjecture they come up with and they cannot prove it. This is again one of the strongest remarks and feedbacks that has been given in open reviews for day paper. The reviewer said you make such strong claims on causality and LLMs, but eventually you cannot conclude on the conjecture. So the work is really interesting, but eventually you do not conclude on it. They still give results and everything. In this one, for instance, this is basically intuitive physics, basic logic questions, such as if flipping switches causes light bulbs to shine and shining light bulbs causes mothas to appear. Does flipping switches cause mothas to appear, which is a typical causal question, and those are the results of the following LLMs on all those types of questions. Everywhere there is an exclamation mark like that. They say that, as I was saying before, that eventually that data, this type of questions can have been included in GBD4's training. They give a kind of twisted explanation. They say that this framework was already published in another paper and they say that they've been extensively running this framework and they also say that OpenAI's API collects data on queries and answers and everything, and so they just make the assumption that maybe the data they used while running benchmark was used in training of GBD4 when it was GBD3 back then. This is why they put an exclamation mark next to it. They say we're not sure we can trust these answers for those reasons. There also are small variations of the models where every COT thing means chain of thought. I don't know if you're familiar with chain of thought. Basically, it is what it's called, a prompt engineering pattern. With LLMs, the prompt is the input we feed to the LLM and prompt engineering is how to access more LLM features and enforce a behavior based on how you write the prompt. Chain of thought is a prompt engineering technique where you will specify clearly in the prompt that you want the LLM to output multiple midway thinking thoughts and thinking steps before actually outputting an answer. We will look like that. For instance, you could say if flipping switches blah, blah, blah, you ask a question and then you say please answer by giving three main thoughts first, one, two, three, then give a preliminary answer and then answer. That would be considered a COT. It's been proven as making the LLMs able to answer more accurately or at least to be able to track down the chain process. There is also another type of it which I am aware of, but I feel like it's incredibly hard to implement, but it still would be really interesting. It's called tree of thoughts, which is pretty much the same principle as chain of thoughts, but you take branches so that you are able to track down which path led to which results. We can get back to that later. This is the results they give about classical causality. In summary, the takeaways they offer, they present. Inability to ground tachal facts is part of the reason why LLMs are not able to infer generalized causal relations. However, they acknowledge that LLMs represent a head start to learning and inference. They are unable to prove conjecture one despite the strong claims that LLMs are only causal parrots. There is a whole paragraph on results on actual causal escalation tests, but there is no sort of table that summarizes results. I feel like this is a work in progress and will be interesting in the near future if they can come up with more results on the subject. This would be approximately a summary of what I've read in the six papers. I'm just going to give a couple of future identified work in those papers, so as to align possible research directions from these researchers in that area that may give us discussion elements. None of them could actually conclude that LLMs can do causality or not, but what they do acknowledge is that LLMs represent suitable candidates to support actual causal inference framework just because they have a really interesting knowledge base as part of their huge corpus of text learning on. A lot of them cannot conclude on the fact that LLMs can do causality, but they would be inclined to working with LLMs in order to combine with actual causality inference frameworks. Those in those four papers, they share the perspective that using LLMs as tools to enhance training of existing causal models is worth exploring, pretty similar to the first one. Another interesting element would be that causal benchmarks, such as the latter presented in the first paper, represent interesting access of improvement for LLM fine-tuning or towards the development of causal LLMs. Ginadal, I think she's working on this already because she's publishing a lot. She made it clear that this is just the first step in her work. I guess this is also interesting to follow, see if coming up with bigger causal frameworks will make able. But in the end, what is still interesting to discuss here is that causal relationships embedded in frameworks, whether it is to test LLMs or to fine-tune them, it is still going to be in their knowledge base in some way. I guess the question that wanted to be addressed here at first is about interventional and current factual, which is not based on observational. This is what I had as a presentation. I thought it was going to be shorter than that. I just think this is a basis to start a discussion on this topic because we have some elements now. Thanks, Antoine. Now we are open for questions. Hello. I'm sorry. I'm late today. I didn't go to the details of the papers. I'm just wondering whether the fact that the GPT-4 is better than the GPT-3.5 in reasoning, can that be simply due to that the GPT-4 has more data to be trained and more parameters to be estimated? In a sense, it's due to an interpolation and regression issue. The so-called better reasoning is a representation of a better regression be obtained through the training. It is an interesting thought. Because the concluding saying that the LAM cannot do the causality. If we are going back, so the reason why GPT-4 is better is to be trained with more data and more parameters to be tuned. Yes, it is actually true. This is pretty much what they give. I guess this is what they want to explain when they say that LLMs are causal parrots. If they see causality in their training base in their data set and training data set, they will be able to eventually get that relationship out of their training data set as a result. Eventually, yes, GPT-4 performs better because they've seen much. The question here would be more to say that are LLMs able to infer causality? Does it mean that they need to see it all to be able to do real causality? Or is the question here more about, no, can they actually do real causality, creating something? This is interesting in the context of climate change, for instance, because all the natural processes are non-stationary. They keep increasing in intensity, and they either are more intense or more sparse than before, etc. There is nothing we can predict that. We don't understand that. This is what's interesting in that particular context to me because that would be a great way to evaluate to benchmark how LLMs interact with those data. Because this, we cannot have that in our training data set. The problem is, it's in foreseen. Every time it's new. But it's a great remark. It's a great remark. Thank you. Because my experience is that the deep learning is a very powerful regression tool. My personal experience of using the chat GPT is doing pretty well on the data set that is trained most from, but the pretty poor job, kind of the questions that is lastly trained from. For example, I sometimes use the chat GPT to provide some suggestions to where to travel from. I can get very good advice in these famous places. But if I was asking where to travel, like do the hiking in the places nearby my current town, Dave, it's just a random answer and not accurate. So I still think it's a regression problem for the LLM. Thanks. Tim, I think you have a question or you want to participate. Yeah. You know, causality is so fascinating and also problematic. I'm a little bit rusty, but I'll put this forward. And particularly looking at this slide makes me wonder, you know, well, I guess the classic response is, can we ever infer causality, whether for a machine or human? And my answer, I guess, is ultimately not. But looking at this slide makes me think that perhaps a question that we could answer is whether an LLM could perform logical reasoning. Is that a fair distinction? Are those things the same? I feel like when I look at this slide, the distinction I hear is that the causal structure is provided to the LLM in the prompt. You know, we say if flipping switches, you know, this happens and if this and that happens. And so the causal structure is provided. And what we're testing is whether the LLM can sort of use logic to understand that relationship when the structure is known. That's interesting. I feel like in this particular example, this is the type of question and answering there is the way they describe it in Clatter, the genital paper, the cool little questions are really different. And so I guess, yes, your remark is interesting. I feel like it really depends in the different papers on what they want to put forward, whether it is interventional and counterfactual causality, or in that particular case, maybe it would be closer to logical reasoning. But it's really interesting. I guess it's still here, basically, what they say x causes y and y causes z does x causes z would be different depending on the situation. So I mean, this is the graph, this is the structure, and then depending on the variables you pick, it is true or it is not. But is it based on logic or it can also be based on observations? I don't know if you agree with that. Well, well, sure. And I guess, you know, I guess the former, there's, I guess, maybe it's still controversial, but some might argue that the former, you know, inferring causality simply on observations is ultimately something we can never do. Not that it isn't useful to sort of try to develop sort of causal models. It definitely is. But ultimately, it's something we can never do. But with logic, you know, we can come to absolute conclusions. Like if we are given a structure, we can reason about that, sort of, you know, come up with determined sort of relationships based on that structure. Hashin and Beshi, did you want to react to this? Could you let me share my screen a moment? Of course. So I put this in the chat. I just wanted to make you guys aware of this paper, which I think would be an interesting follow on to this conversation, because this paper by Fran\u00e7ois Chalet, and you can go listen to him on YouTube, is very interesting. I just became familiar with and I recommend this paper for two reasons. One is because it seems like a very cogent analysis of what would be necessary in order to have machine intelligence. And it feels to me like causality, the ability to infer causality or to determine a chain of reasoning using causal principles would be an important component of that. The other reason is because, as I've highlighted there, he actually defines if he comes up with a metric for defining intelligence of a machine based on algorithmic information theory, which information theory being sort of a core part of what we're trying to talk about here. But one of the things he talks about there is the need to account for prior information. So this discussion about whether you're memorizing and regurgitating versus doing reasoning has a lot to do with how much prior information you have. If you already know the answer and you give me the correct answer, did you give it to me because you did reasoning or because you just knew the answer and you just stated the answer? So in the paper he talks about the need for being able to assess generalization ability. And we're talking about generalization ability being not just weak generalization, meaning in the context of things you've seen before, but strong generalization in what he calls developer aware generalization in the sense of being able to generalize beyond the situations that you've seen in your training data, beyond your prior knowledge, and therefore address novel situations. And it sounds to me like if we're going to assess the ability of a machine or a program or a set of programs to do causal reasoning, then much in the nature of counterfactuals and so on, you need this ability to be able to take those principles and then generalize into some other context that has never been seen before. And so I found this a very interesting paper because he sort of breaks it down into the necessary and sufficient components. In particular, if you're trying to compare two agents, you need to compare them with the same priors. In other words, if two agents have different priors, different levels of prior knowledge, then you can't, and the second agent has more prior knowledge than the first, and it gives a better answer, you can't necessarily conclude that that second agent is more intelligent because it's not starting from the same basis. It might also already have known that answer because it was in its prior knowledge base. So I think what you brought up about the LLMs, what training data have they seen? Timothy's very astute observation that the nature of the causal reasoning was already stated in that sentence. And you just gave an example and all it had to do was fill in the blanks with different priors and A's and B's and answer that question. Was it really doing causal reasoning? It was just using a rule which was given to it. So if I looked at that sentence that you gave me and I just memorized that sequence of sentences and I just applied it in a different context, am I doing causal reasoning? I think this really bears looking in deeper to some of these issues that I think Francois is talking about in this paper. Just a quick comment. I have to leave soon as well. So I think it might be interesting to go through the architecture of either the chat GPT 3.5 or GPT 4. I'm not sure whether it's solely just based on the transformer or something else, but the architecture definitely will guide the reasoning. So let me make a quick comment. I might have just said this before. I mean this discussion is very, very helpful. And Antoine, thank you for doing this pretty nice review. I mean what this has brought to light in my mind is the distinction between causality and logical reasoning which Timothy pointed out. And then within that the causality is basically causal discovery versus causal reasoning. Is that different from logical reasoning and so forth? Right? I mean so there are some distinctions to be made and this whole idea of intelligence, I mean is intelligence all reasoning or when we think about intelligence we think about intuition. We think about creativity. We think about coming up with new solutions when new constraints and things present which didn't exist. I mean the whole of the science and engineering is all of that, right? Pretty much all fields where you're trying to find new solutions which probably do not have a historical precedence. And these large language models rely on that historical precedence. I mean the priors as you call it. And so how do we make that distinction? And the second thing is that large language models are essentially inferring these things from the basis of language. They are not doing analysis of data. There may be auxiliary tools that say okay now I can go and probe the data but that probing is based on the logic that is built or large logic that these large language models come up with. And so I think there needs to be some very subtle characterization of what we mean. I mean extending this idea of causality in those three notions that you talked about from a language to a data context. We use the word data loosely. I mean what we are using the word data is essentially language data, not quantitative numerical data on which these analysis are built. So there is much to be done in parsing this out very, very carefully and going about doing that. Having said that, the encouraging thing which I find is the following. So when I was in grad school, I did a couple of courses on artificial intelligence and the prevailing language at that time was Lisp and Prolog. Lisp processing and basically logical programming. That's what Prolog was. So the idea was that if you could program logic in all its complexity and the many books written on the structure of human logic and to take that and program it, you would be successful in mimicking intelligence. And to me at that time said, okay, you may be able to do a pretty sophisticated job with deductive logic, but there was nothing in that which would allow you to do inductive logic, which basically goes on to looking at inclusion and creativity. The thing is that didn't go too far and then we have this large language models who say, okay, I don't need a language that is based on reasoning. All I need to do is have the capability to infuse things from data and computation. And so that's the generative model's success where they can pretty much infer. So the idea is that, okay, I don't need how to reason. Everything that I need to learn about reasoning is already built into the millions and billions of textual data that is there. So if I have the ability to infer that, I will, even though I don't know that it is essentially a logical reasoning and maybe some things beyond. My guess is that a lot of the other things are built into our language structure very deeply. And to the extent that we can then reintegrate that, re-manipulate that, use that as a foundation for thinking in new ways, we can build on it, but I don't think we are there yet. And this whole idea of causality, causal reasoning, causal inference and other things may fall in that space saying we don't yet know how to go about doing that, although that information is there. So the distinction between language and the data-driven approach is important and there is more to be done with this space than what is out there. Oshin? Yeah, thanks for raising that issue, Praveen. And interestingly enough, I just came across this paper about something called Dreamcoder. And if you read down here, it says we present Dreamcoder, a system that learns to solve problems by writing programs. It builds expertise by creating programming languages for expressing domain concepts. A wake sleep learning algorithm alternately extends the language with new symbolic abstractions and trains the neural network on imagined and replayed problems. And then concepts are built compositionally from those learned earlier, yielding multilayered symbolic representations that are interpretable and transferable to new tasks. So anyway, I just thought it was interesting because there is actually now apparently some small breakthrough into developing machine learning structures where learning concepts and extending language much in the way that we learn concepts and extend language in order to do reasoning and causal reasoning and all of that. So that's actually an interesting, we're just starting to happen. Yeah, I would say that, I mean, I think we are at the beginning of a breakthrough in these things. We are now assembling essential tools that may help us move this to expect these tools that are not trained or developed for a specific task to inherently be able to do that. I think it's a little far, but there needs to be more and that's an opportunity for us. From an information theory perspective, this brings me back to the fact that everything we do is based on embeddings. We take objects or concepts and we build embeddings out of them, which are then manipulated using reasoning machine learning or whether it's human or machines. And so we start with symbols. The symbols are represented by embeddings and that's an information theory problem. How do we choose the correct embedding, which represents the information, all of the necessary and relevant information, which can then be processed? And how do you then represent that information in a way that can actually be manipulated using the tools that are available to us in machine learning that's typically using vectors, vector spaces and being able to do dot products in order to do similarity operations, to add vectors in order to do addition and subtraction operations, sort of logical things that are involved in logical reasoning. But then on top of those concepts, we have to, on top of those embeddings, we have to build concepts, which are collections of these. And from those, we have to build languages. And when we build languages, which are minimum, which are shorter description length representations of concepts, we're then able to do reasoning using those higher level objects or concepts. And so I kind of have been seeing this kind of structure emerging in the machine learning, particularly in the context of evolutionary robotics and artificial intelligence. But I think it provides an interesting way for us to think about how we actually process information using the tools of algorithmic information theory and Shannon information and how that leads to us being able to build sort of these informational pyramids or, you know, things where we can, we can think about things at lower levels of the hierarchy and then at higher levels of the hierarchy and actually do these sort of intelligent processing. Yeah, no, I agree with that completely. And I think the generative models, the transformers are built on the series of embeddings. I mean, it's a recursive embedding process that generates these parameters and estimation of these parameters across these things. And one of the things which we are trying to explore with Hersh is, well, they're a way for us to modify that to see causal reasoning can be extracted using that embedding structure. So that's a big question. So the thing that bothers me a lot is sometimes we may be using embeddings that are not properly informative. If I just give you a stream of stream flow and I treat, let's say I give you rainfall potential evaporation and stream flow, and those are three values, and I just put them in a vector. And I'm telling you at this point in time, this is the vector, and next point in time, this is the vector, and this is, you know, and I've got these three values. If I'm not telling you whether the stream flow is going up or going down at that point in time, or whether the, but the energy is increasing or decreasing or the rainfall is increasing or decreasing, I might be giving an embedding which is not sufficiently informative for you to be able to do meaningful inference. And so thinking about how we develop our data embeddings as a first step before we even present them to our algorithm seems to be an important step. Yeah, or get the algorithms to basically build on the initial embedding to explore alternates and see what makes sense. Correct. I was going to ask if in on this question of embeddings, it would be difficult for a language model to speak on causality because usually we reason about causality in terms of graphs. And as I understand, there in the large language model, there, there's no structure of a graph. So maybe it's using the wrong embedding to speak about causality, maybe the language model understands causality in a different way, in a different embedding than we typically would analyze causality. I don't think it's necessary. Well, Praveen can probably answer this better, but I don't think it's necessarily true that a large language model and graphs are not the same thing, because a large language model can be thought of as a very high dimensional joint probability density function. And that's basically how we build those is by using building graphs, right, of conditional probabilities and so on. Antoine and Praveen isn't it true that that's what a lot of, what's his names, the father of causal inference, I forget his name. Perl? Perl. Perl, a lot of his work was based on that, that the fact that those two are essentially the same thing. Yeah. Yeah. I mean, the representation of causality as a graphical model came out of Perl and then quantified by Sprites. I put that link in the chat. There's a nice book by Sprites, which I recommend to everybody to read a minute, just helps lay that down on how to do this in a mathematical way and how to think about it. But I think the real question that we haven't yet answered effectively is in our context where we are dealing with data in space and time, what does causality mean? I mean, in a medical context, I mean, you can figure out whether smoking causes cancer or not through a whole bunch of different things. But in our context, where we have potentially continuous space-time domain, it's easier to answer the question of causality. The necessary condition for causality in time is breaking of symmetry in time. The past causes, the future, future cannot cause past. That's the necessary condition. Is that a sufficient condition or not? That has not been well answered. Now, if you extend that in space, there is no such framework. I mean, so then you have to ride on a vector space to basically figure out a directionality and then say, okay, something that is happening in one space, preclude something that is happening in another. You might ride on a river and say, okay, I'm going to forward. But then the whole issue of backwater propagation and all that thing happens and then that can break down. So what is that framework? What do we mean when we say causality within the context of what we're dealing with has not been well defined? And that's a struggle in there. And then we anchor on surrogate processes. And Allison has done some work with information theory in which direction the information blows. I think like that. I mean, so those are good starting points and there might be some hint of how we may go about doing it. But until we break through, we are going to be scratching this on the surface and hoping that somehow some model is going to provide that input. So would it be fair to say that causality is a representational assumption rather than a fact? In other words, it's a hypothesis we make about the world and we test. And just to take a simple example, if I just said rainfall and runoff, and I ask you to say, does rain cause runoff? That's going to have all the problems that you just talked about, right? But there are causal effects. Increasing CO2 is causing climate change. And so there are definitely open causal issues. But my point is, are we treating causality as a fact or are we treating causality as a representational explanation? Yeah, we don't know that, right? I mean, probably that to go hand in hand, a certain type of representation will help us infer a certain type of causality. But until we come up with proper definitions and proper classifications, I think what we end up doing is anchoring on a representation that is convenient and then infer causality associated with that representation. And then say, well, no, this represents everything we got. So structural causal model might fall into one of those categories. But yeah, I don't know the answer. I mean, I'm just articulating the questions that go through my mind. But I mean, if we take an extreme example, like F is equal to MA, right? It's a structural representation that was come up with. And you test it, and it all never fails. We start to treat it as a fact of nature, right? Because it's a hypothesis that has never actually been disproved by a counterfactual, by an example that contradicts it. So maybe something similar with causality, you have a chain of reasoning, and if that chain of reasoning always holds up, then eventually you start to treat it as though it's a fact of nature. Probably. I mean, even if it equals MA is wrong in certain cases, like photons, it kind of brings the question of, is all of causality emergent? Can you have fundamental laws that are causal? Or is everything kind of in a higher, kind of more broad context, complex systems? Well, if I can go back to ask Antoine a question. Well, go ahead and answer that first. I was just going to say, I think Ocean, I don't claim to have read Hume, but I think you summarize Hume's argument that, you know, fundamentally, we can't know causality absolutely. But, you know, we can, we can, you know, strengthen our beliefs. And that sort of this is all very useful. I don't think Hume was trying to argue that, you know, we shouldn't be logical beings and throw out this, these aspirations for understanding causality completely. And I think that's kind of what you're saying that, you know, yes, F equals MA is wrong, but it's, you know, right under, you know, most of the conditions that we encounter in our day to day. And so it can basically be taken as fact. And that's kind of what our definition of causality is. It's right until it's wrong. But Antoine, going back to the large language models, if these people who wrote all these papers were to take a bunch of age roles, my daughter's eight, I'm just picking eight out of a hat, and attempted to do these same tests on them, right? That's kind of what I was thinking about when you said that they were testing these large language models to infer causality. If they ran these same tests on a bunch of eight-year-olds, you know, in other words, how do they know that their tests are actually meaningful tests for establishing whether or not the LLM or the eight-year-old has the ability to cause inference? I don't think they do. I feel like this is what we're getting out of this discussion. It's like, what is causality in the end? And how can you be sure that it is causality you're inferring and not logic reasoning as Timothy proposed? So I don't think they really do. All they can do is come up with a benchmark, a controlled one that has causated causes and effects and tests if an LLM is able to recreate that. But again, is this purely reasoning or this just or this just retrieval from your knowledge? And I think there's also another point to consider as Pravin mentioned earlier, that it's a bit different because it's language and might take my thought on that. I don't have anything to support that claim, but my thought on that is that we as humans use language to formulate concepts and to reason. So eventually, if we reach the point to which the LLM is so powerful in text, in natural language processing, actually, what are the implications of it on its ability to formulate concepts and reason? I want to get back to the chain of thought and tree of thought prompt engineering techniques I was telling you about earlier. The tree of thought is pretty much the same thing. So you say to your LLM, right, this is a question, I want the answer. But first, I want your first thought on the answer and then you separate into two and you like choose different ways of thinking about it and just create a tree and output all difference. That would be able, that would make us able to track how does the net. I saw that there is a very interesting paper on it. I can link it in the chat tree of thought. So my take on this, my question would be LLM are basically two years old and they're able to do so much already. And at what pace are they still going to grow in the future? And what are the implications on the amount of knowledge that will be theirs in a couple of years from now? Because in the end, is causality just like you have this in your knowledge, you can take it out and get it again. Because if it's that, I don't have any doubt that in maybe 10 years from now or I don't know why. At some point, we'll figure it out to every knowledge we know in the LLMs. It's not reasonable to think that. But core factuals and everything, some more, I don't really have an answer. I don't think anyone has an answer in the papers I mentioned. Yes, Ernan? Yeah, this is great discussion. I have more questions here for us to reflect. But it seems like we are collecting all the reflections. It seems like we still don't have a way to measure causality, a solid way like we do measure models via the WSER or some other metrics. And my perception of causality is something that may be reproducible across experiments in different environments that are looking at kind of the same processes. So think about streamflow in Switzerland versus Tucson versus Washington. But do we have tools to measure causality? In other words, can we say the same way in an analogous way, we have a way, machine learning models, overfeats, underfeats, do we have a way to say this model overfeats causality, this model underfeats causality? This is a good causality explanation of the process. And I don't know if that exists. And that goes back to the way we usually validate or cross validate models in which we split the data set in a number of folds and then we cross validate it. Should we instead do tests for causality in a similar way or analogous way in which we take data sets from different environments and then we see if the knowledge is transferred across those environments via the cross validation. So perhaps that removes a little bit of the anxiety we have for perfection in causality. And we kind of explain it in a way that we quantify and not as a binary yes or no. And another problem is predicting beyond training in the at once example of climate change. It's another limitation. I don't know if we're at the point at which the models will be able to reason and then beyond training, even though they're perfectly trained, reason about climate change consequences and the trends. If the trends are learned from the data themselves, then yes. But if there's nothing that let us know about surprises, I doubt. And the other thing is the data limits are really constraining our learning or the models learning pace of the facts and not to speak of the counterfact loss. But I mean, those are kind of some of the lines or bullets I could raise from everybody's discussion but so far. That's a great discussion. If I, yeah, thank you for intervention Aaron. If I may maybe give another couple of elements in there to give a couple more insights on those questions. Okay, so I have a small amount of knowledge on digital twins. Before I was here, when I was in master's degree, five, six years ago in France, I was an apprentice at Dassault Systems at the same time and they were working on digital twins back then. So I was a bit in there. In short, for those who will know digital twins is a concept that ties a physical object to a virtual representation, where there is a synchronization of data between the two of them. And what's hot in the topic right now is because of climate change and extreme events and everything is a digital twin of the planet Earth. There is a perspective on that from the European Union, which is called destination Earth. So they plan to do a digital twin of the whole Earth by 2027, I don't remember 2028. My take on this is from what I've seen in the paper, talking about the intelligent agents that learn about experience. I drew the parallel between those agents and what on a lens able to do. But the key thing here is that experience is beneficial to causal understanding. And I guess this is what's also been put forward by my the causal inference frameworks that do need a lot of data, experimentations and everything. And so just my small insight on there would be that digital twins may just represent a great environment for LLMs to interact with if those virtual environments are good enough to be representative of what's happening out there. And this is where all work of all traditional, I would say research comes in, flow modeling, ground flow modeling, rainfall runoff, geochemistry. And so my vision of, so we're at UIUC in Illinois in the CI Net program, we're studying the Singapore watershed. And so maybe a target I'd like to achieve would be like to have a digital twin of that watershed represented by a 3D model and data coming in the same time. And on top of that, you would have physics, a physics engine reality represented by all the process based simulation models we know and et cetera. And this would be the great place for LLMs to fully express itself and make interactions and make experiences. And this would potentially provide a great environment to perform causal inference and maybe to test whether LLMs are actually able to do causal inference, because all we've been fitting is generated text and made up benchmarks, which is interesting. And it's the first step. Eventually experience is the key, I feel like, and the digital twin would be really interesting environment for that. This is just like both thoughts I've had. You want to reflect on that, Ocean? No, no, no, absolutely. I think you're absolutely going down the right track because you're saying basically that you need to not only respond, you need to be able to interrogate your environment and giving them a digital environment to interrogate is a useful thing to do. And that's actually behind this poet paper that I put up there about where the environment changes as the ability of the agent changes. So it's like a co-evolution process where it actually evolves the environment, which is one step beyond what you're thinking, what you're talking about. But it also occurred to me, the reason I put my hand up was that I think it's really interesting to have the LLM as the agent that's doing the learning. I hadn't thought of that. I think it would also be interesting in a decision context, which I think is where you're going, to have multiple LLMs take the roles of different stakeholders and play devil's advocate. So you've got the rancher and you could say, okay, your job is to play the role of the rancher, your job is to play the role of the environmentalist, your job is to play the role of whatever. And you could do some very, very interesting role playing explorations with the goal of coming up with potential solutions to difficult transdisciplinary decision-making problems, where you can play them out using agents rather than having to get real humans in there before you then take those to the next stage and involve humans. I'm glad you brought it up because this is exactly what we do. Perfect. And so I'm going to be presenting that with Praveen at AGU. And just to give a couple of heads up. So I have a couple of examples where exactly I have a mayor science expert and everything talking in response to a flood event, impeding flood event or something. And the problematic right now is to find the right metric and find ways to evaluate the output of the models because this is taxed. It's complicated to evaluate compared to LSTM, which would output a sequence of numbers. And then you would use all the mathematics, you know, to evaluate it. But how do you do it with tax? It's either you come up with something new, either you use an LLM to do it, but there is a bias in using an LLM to evaluate an LLM. So this is a question that needs to be answered right now. But yes. That's like a tool for gowns. Yeah, exactly. So yeah, if that interests you and you're coming to AGU, my talk is morning morning. I'm going to be talking about that. Would you mind dropping me an email telling me where and when? I wanted to comment on the talks on AGU because well, with the names that are usually in the talks and also for the participants who were at the SNF in the house workshop, I collected some of the talks that will be presented by participants at AGU. So we have a nice Excel spreadsheet that I could share. Please, save us a slide. Yeah, you can even filter it by daytime. So you kind of have like a... So would you rather have me send your information to you so you can like enrich the database? No, I think I already have you in the database. If you allow me, I can very quickly share my screen and show you. It's just a spreadsheet and I just scraped the data from the AGU website. So go ahead. If I'm missing someone, I could even... Yeah, so just to give us an example, my talk... Are you physically there? Yeah, I will be physically there. Okay, perfect. So my talk is also on Monday, but you can see what I scraped is just the ID, the title of the talk. These are the participants who are usually in this meetings or who are at the workshop. So you can see that it's Uwe Hoshin, myself. I'm the speaker and you can see who is the speaker in this column of authors with the double mark. Thank you. That's a great help. From what I see, we're going to be running around chasing for our... If you follow this schedule very strictly, you will be around the Moscone Center a couple of times, but I think you can pick and choose what looks interesting. Thanks for that. It's great. So I will share the label and then we can see how it can be passed around and how I can add data to it. All right, perfect. Thanks. Unfortunately, I have to go for a student exam. So one final comment, thinking about student exams, this thing about causal reasoning also reminds me of the kind of questions we try to ask students when they're doing their qualifier or they're doing their... Right, there's the kind of questions which are just about what do you know, facts, regurgitate, and then hopefully you get to the kind of questions where they get to generalize beyond and that's where you test their true understanding and or intelligence. So it felt... It just felt like it has direct relevance to what you were talking about. Anyway, I got to go. Bye, guys. Bye, everyone. Bye, bye. Just a final comment that we are going to be having our winter break and we are going to be back on January 17 with Manuel's presentation. Beautiful. Thanks, everyone. Bye, guys. Thanks.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 9.68, "text": " All right, I'm happy to introduce Antoine, a very energetic young man who joined a research", "tokens": [50364, 1057, 558, 11, 286, 478, 2055, 281, 5366, 5130, 44454, 11, 257, 588, 24935, 2037, 587, 567, 6869, 257, 2132, 50848], "temperature": 0.0, "avg_logprob": -0.32577766806392344, "compression_ratio": 1.3964497041420119, "no_speech_prob": 0.04365157708525658}, {"id": 1, "seek": 0, "start": 9.68, "end": 16.32, "text": " program when it was in January, just this past year, this year.", "tokens": [50848, 1461, 562, 309, 390, 294, 7061, 11, 445, 341, 1791, 1064, 11, 341, 1064, 13, 51180], "temperature": 0.0, "avg_logprob": -0.32577766806392344, "compression_ratio": 1.3964497041420119, "no_speech_prob": 0.04365157708525658}, {"id": 2, "seek": 0, "start": 16.32, "end": 24.16, "text": " And before that, Antoine was working with this startup company called Extra Lab.", "tokens": [51180, 400, 949, 300, 11, 5130, 44454, 390, 1364, 365, 341, 18578, 2237, 1219, 29429, 10137, 13, 51572], "temperature": 0.0, "avg_logprob": -0.32577766806392344, "compression_ratio": 1.3964497041420119, "no_speech_prob": 0.04365157708525658}, {"id": 3, "seek": 2416, "start": 24.48, "end": 34.08, "text": " He was on their software engineer side, helping develop systems for capturing", "tokens": [50380, 634, 390, 322, 641, 4722, 11403, 1252, 11, 4315, 1499, 3652, 337, 23384, 50860], "temperature": 0.0, "avg_logprob": -0.18846240043640136, "compression_ratio": 1.4064171122994653, "no_speech_prob": 0.008259592577815056}, {"id": 4, "seek": 2416, "start": 35.6, "end": 41.44, "text": " river water quality data with the technology that was developed by the founder of Extra Lab.", "tokens": [50936, 6810, 1281, 3125, 1412, 365, 264, 2899, 300, 390, 4743, 538, 264, 14917, 295, 29429, 10137, 13, 51228], "temperature": 0.0, "avg_logprob": -0.18846240043640136, "compression_ratio": 1.4064171122994653, "no_speech_prob": 0.008259592577815056}, {"id": 5, "seek": 2416, "start": 42.56, "end": 51.760000000000005, "text": " But I'm glad he came to us to do his PhD and has been working on issues related to causality", "tokens": [51284, 583, 286, 478, 5404, 415, 1361, 281, 505, 281, 360, 702, 14476, 293, 575, 668, 1364, 322, 2663, 4077, 281, 3302, 1860, 51744], "temperature": 0.0, "avg_logprob": -0.18846240043640136, "compression_ratio": 1.4064171122994653, "no_speech_prob": 0.008259592577815056}, {"id": 6, "seek": 5176, "start": 51.76, "end": 58.0, "text": " and large language models, and he can tame GPD like nobody else.", "tokens": [50364, 293, 2416, 2856, 5245, 11, 293, 415, 393, 45774, 460, 17349, 411, 5079, 1646, 13, 50676], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 7, "seek": 5176, "start": 58.559999999999995, "end": 62.64, "text": " So with that, Antoine, all yours.", "tokens": [50704, 407, 365, 300, 11, 5130, 44454, 11, 439, 6342, 13, 50908], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 8, "seek": 5176, "start": 63.519999999999996, "end": 64.96, "text": " Okay, so thank you, Praveen.", "tokens": [50952, 1033, 11, 370, 1309, 291, 11, 12133, 303, 268, 13, 51024], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 9, "seek": 5176, "start": 64.96, "end": 68.88, "text": " So indeed, today I'm going to talk to you about LLM's and causality.", "tokens": [51024, 407, 6451, 11, 965, 286, 478, 516, 281, 751, 281, 291, 466, 441, 43, 44, 311, 293, 3302, 1860, 13, 51220], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 10, "seek": 5176, "start": 70.16, "end": 75.36, "text": " As you can have guessed, if any of you just took a small quick look at the papers,", "tokens": [51284, 1018, 291, 393, 362, 21852, 11, 498, 604, 295, 291, 445, 1890, 257, 1359, 1702, 574, 412, 264, 10577, 11, 51544], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 11, "seek": 5176, "start": 75.36, "end": 77.12, "text": " cyber-voted Lila last time.", "tokens": [51544, 13411, 12, 85, 23325, 441, 7371, 1036, 565, 13, 51632], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 12, "seek": 5176, "start": 78.56, "end": 81.03999999999999, "text": " So just to put it back in a bit of a context,", "tokens": [51704, 407, 445, 281, 829, 309, 646, 294, 257, 857, 295, 257, 4319, 11, 51828], "temperature": 0.0, "avg_logprob": -0.20904704743781977, "compression_ratio": 1.4769874476987448, "no_speech_prob": 0.0037031304091215134}, {"id": 13, "seek": 8104, "start": 81.04, "end": 84.80000000000001, "text": " this is a picture I use in all my presentations that I used to illustrate", "tokens": [50364, 341, 307, 257, 3036, 286, 764, 294, 439, 452, 18964, 300, 286, 1143, 281, 23221, 50552], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 14, "seek": 8104, "start": 84.80000000000001, "end": 86.56, "text": " what's going on with climate change right now.", "tokens": [50552, 437, 311, 516, 322, 365, 5659, 1319, 558, 586, 13, 50640], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 15, "seek": 8104, "start": 86.56, "end": 91.60000000000001, "text": " And this is just more than 20 inches of precipitation in one night and for a lot of day.", "tokens": [50640, 400, 341, 307, 445, 544, 813, 945, 8478, 295, 37662, 294, 472, 1818, 293, 337, 257, 688, 295, 786, 13, 50892], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 16, "seek": 8104, "start": 92.4, "end": 100.16000000000001, "text": " And it's just to exemplify how climate change changes the way that extreme events are happening", "tokens": [50932, 400, 309, 311, 445, 281, 24112, 2505, 577, 5659, 1319, 2962, 264, 636, 300, 8084, 3931, 366, 2737, 51320], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 17, "seek": 8104, "start": 100.16000000000001, "end": 104.4, "text": " and how can we do to stop them and how can we tackle those problems.", "tokens": [51320, 293, 577, 393, 321, 360, 281, 1590, 552, 293, 577, 393, 321, 14896, 729, 2740, 13, 51532], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 18, "seek": 8104, "start": 105.36000000000001, "end": 110.64000000000001, "text": " And this is, so as Praveen introduced, I'm not going to spend a lot of time on this, but", "tokens": [51580, 400, 341, 307, 11, 370, 382, 12133, 303, 268, 7268, 11, 286, 478, 406, 516, 281, 3496, 257, 688, 295, 565, 322, 341, 11, 457, 51844], "temperature": 0.0, "avg_logprob": -0.12266336750780416, "compression_ratio": 1.7406015037593985, "no_speech_prob": 0.005810712929815054}, {"id": 19, "seek": 11104, "start": 111.2, "end": 120.32000000000001, "text": " the statement here is that the decision-making process is critical in the resilience,", "tokens": [50372, 264, 5629, 510, 307, 300, 264, 3537, 12, 12402, 1399, 307, 4924, 294, 264, 19980, 11, 50828], "temperature": 0.0, "avg_logprob": -0.19276260685276342, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0006065131165087223}, {"id": 20, "seek": 11104, "start": 120.32000000000001, "end": 124.56, "text": " in increasing or decreasing resilience to climate change risks,", "tokens": [50828, 294, 5662, 420, 23223, 19980, 281, 5659, 1319, 10888, 11, 51040], "temperature": 0.0, "avg_logprob": -0.19276260685276342, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0006065131165087223}, {"id": 21, "seek": 11104, "start": 125.2, "end": 128.4, "text": " and so to address the extreme events.", "tokens": [51072, 293, 370, 281, 2985, 264, 8084, 3931, 13, 51232], "temperature": 0.0, "avg_logprob": -0.19276260685276342, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0006065131165087223}, {"id": 22, "seek": 11104, "start": 130.24, "end": 134.96, "text": " The problem is decisions are taken by humans, and until recently we didn't have GPD,", "tokens": [51324, 440, 1154, 307, 5327, 366, 2726, 538, 6255, 11, 293, 1826, 3938, 321, 994, 380, 362, 460, 17349, 11, 51560], "temperature": 0.0, "avg_logprob": -0.19276260685276342, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0006065131165087223}, {"id": 23, "seek": 11104, "start": 134.96, "end": 140.16, "text": " and understanding natural language with mathematics is complicated.", "tokens": [51560, 293, 3701, 3303, 2856, 365, 18666, 307, 6179, 13, 51820], "temperature": 0.0, "avg_logprob": -0.19276260685276342, "compression_ratio": 1.5740740740740742, "no_speech_prob": 0.0006065131165087223}, {"id": 24, "seek": 14016, "start": 140.72, "end": 145.2, "text": " And there is no breakthrough framework until GPD came out,", "tokens": [50392, 400, 456, 307, 572, 22397, 8388, 1826, 460, 17349, 1361, 484, 11, 50616], "temperature": 0.0, "avg_logprob": -0.08000932595668694, "compression_ratio": 1.4681818181818183, "no_speech_prob": 0.0009996059816330671}, {"id": 25, "seek": 14016, "start": 145.92, "end": 151.51999999999998, "text": " which we've seen as an opportunity to try to understand how humans think in language.", "tokens": [50652, 597, 321, 600, 1612, 382, 364, 2650, 281, 853, 281, 1223, 577, 6255, 519, 294, 2856, 13, 50932], "temperature": 0.0, "avg_logprob": -0.08000932595668694, "compression_ratio": 1.4681818181818183, "no_speech_prob": 0.0009996059816330671}, {"id": 26, "seek": 14016, "start": 152.8, "end": 159.76, "text": " So what I'm working on right now is using GPD agents to generate multiple decision pathways", "tokens": [50996, 407, 437, 286, 478, 1364, 322, 558, 586, 307, 1228, 460, 17349, 12554, 281, 8460, 3866, 3537, 22988, 51344], "temperature": 0.0, "avg_logprob": -0.08000932595668694, "compression_ratio": 1.4681818181818183, "no_speech_prob": 0.0009996059816330671}, {"id": 27, "seek": 14016, "start": 160.48, "end": 166.56, "text": " based on a context of an extreme event, let's say a forecast of a flooding for a city.", "tokens": [51380, 2361, 322, 257, 4319, 295, 364, 8084, 2280, 11, 718, 311, 584, 257, 14330, 295, 257, 24132, 337, 257, 2307, 13, 51684], "temperature": 0.0, "avg_logprob": -0.08000932595668694, "compression_ratio": 1.4681818181818183, "no_speech_prob": 0.0009996059816330671}, {"id": 28, "seek": 16656, "start": 167.2, "end": 171.68, "text": " And we use multiple GPD agents to talk to each other in order to come up with decisions", "tokens": [50396, 400, 321, 764, 3866, 460, 17349, 12554, 281, 751, 281, 1184, 661, 294, 1668, 281, 808, 493, 365, 5327, 50620], "temperature": 0.0, "avg_logprob": -0.08007958302131066, "compression_ratio": 1.5687022900763359, "no_speech_prob": 0.004605816211551428}, {"id": 29, "seek": 16656, "start": 171.68, "end": 176.56, "text": " pathway, which then we can evaluate to understand whether it is good or bad decisions.", "tokens": [50620, 18590, 11, 597, 550, 321, 393, 13059, 281, 1223, 1968, 309, 307, 665, 420, 1578, 5327, 13, 50864], "temperature": 0.0, "avg_logprob": -0.08007958302131066, "compression_ratio": 1.5687022900763359, "no_speech_prob": 0.004605816211551428}, {"id": 30, "seek": 16656, "start": 177.12, "end": 183.76, "text": " And this is just the start of a work in which we will try to maximize resilience", "tokens": [50892, 400, 341, 307, 445, 264, 722, 295, 257, 589, 294, 597, 321, 486, 853, 281, 19874, 19980, 51224], "temperature": 0.0, "avg_logprob": -0.08007958302131066, "compression_ratio": 1.5687022900763359, "no_speech_prob": 0.004605816211551428}, {"id": 31, "seek": 16656, "start": 183.76, "end": 190.08, "text": " and see what is the takes of LLMs and AI in that particular problem.", "tokens": [51224, 293, 536, 437, 307, 264, 2516, 295, 441, 43, 26386, 293, 7318, 294, 300, 1729, 1154, 13, 51540], "temperature": 0.0, "avg_logprob": -0.08007958302131066, "compression_ratio": 1.5687022900763359, "no_speech_prob": 0.004605816211551428}, {"id": 32, "seek": 16656, "start": 190.08, "end": 194.8, "text": " So I'm going to be presenting that at AGU, have a talk on the morning, Monday morning.", "tokens": [51540, 407, 286, 478, 516, 281, 312, 15578, 300, 412, 28406, 52, 11, 362, 257, 751, 322, 264, 2446, 11, 8138, 2446, 13, 51776], "temperature": 0.0, "avg_logprob": -0.08007958302131066, "compression_ratio": 1.5687022900763359, "no_speech_prob": 0.004605816211551428}, {"id": 33, "seek": 19480, "start": 194.8, "end": 199.60000000000002, "text": " So if you want to see what it's about, I would gladly see you in the audience.", "tokens": [50364, 407, 498, 291, 528, 281, 536, 437, 309, 311, 466, 11, 286, 576, 47307, 536, 291, 294, 264, 4034, 13, 50604], "temperature": 0.0, "avg_logprob": -0.14236927958368098, "compression_ratio": 1.5346938775510204, "no_speech_prob": 0.0056371744722127914}, {"id": 34, "seek": 19480, "start": 200.4, "end": 206.8, "text": " But so we'll get back on the subject here. So I talked a bit about LLMs.", "tokens": [50644, 583, 370, 321, 603, 483, 646, 322, 264, 3983, 510, 13, 407, 286, 2825, 257, 857, 466, 441, 43, 26386, 13, 50964], "temperature": 0.0, "avg_logprob": -0.14236927958368098, "compression_ratio": 1.5346938775510204, "no_speech_prob": 0.0056371744722127914}, {"id": 35, "seek": 19480, "start": 206.8, "end": 210.24, "text": " Even I'm pretty sure that everyone here is familiar with what it is.", "tokens": [50964, 2754, 286, 478, 1238, 988, 300, 1518, 510, 307, 4963, 365, 437, 309, 307, 13, 51136], "temperature": 0.0, "avg_logprob": -0.14236927958368098, "compression_ratio": 1.5346938775510204, "no_speech_prob": 0.0056371744722127914}, {"id": 36, "seek": 19480, "start": 210.88000000000002, "end": 218.4, "text": " Still, I'm going to say, so large language models, they are the class of language models,", "tokens": [51168, 8291, 11, 286, 478, 516, 281, 584, 11, 370, 2416, 2856, 5245, 11, 436, 366, 264, 1508, 295, 2856, 5245, 11, 51544], "temperature": 0.0, "avg_logprob": -0.14236927958368098, "compression_ratio": 1.5346938775510204, "no_speech_prob": 0.0056371744722127914}, {"id": 37, "seek": 19480, "start": 218.4, "end": 223.20000000000002, "text": " such as GPD, etc., usually based on the transformer architecture.", "tokens": [51544, 1270, 382, 460, 17349, 11, 5183, 7933, 2673, 2361, 322, 264, 31782, 9482, 13, 51784], "temperature": 0.0, "avg_logprob": -0.14236927958368098, "compression_ratio": 1.5346938775510204, "no_speech_prob": 0.0056371744722127914}, {"id": 38, "seek": 22320, "start": 223.2, "end": 230.16, "text": " And so those models receive a text input and will make predictions, textual predictions.", "tokens": [50364, 400, 370, 729, 5245, 4774, 257, 2487, 4846, 293, 486, 652, 21264, 11, 2487, 901, 21264, 13, 50712], "temperature": 0.0, "avg_logprob": -0.1596173618150794, "compression_ratio": 1.5327868852459017, "no_speech_prob": 0.00019711443746928126}, {"id": 39, "seek": 22320, "start": 230.79999999999998, "end": 235.83999999999997, "text": " They're known because they're really good at understanding human language in the sense that", "tokens": [50744, 814, 434, 2570, 570, 436, 434, 534, 665, 412, 3701, 1952, 2856, 294, 264, 2020, 300, 50996], "temperature": 0.0, "avg_logprob": -0.1596173618150794, "compression_ratio": 1.5327868852459017, "no_speech_prob": 0.00019711443746928126}, {"id": 40, "seek": 22320, "start": 235.83999999999997, "end": 244.39999999999998, "text": " they are a great conversational agents. So GPTs, Barrett, Paul, and Lama, there's a lot of them.", "tokens": [50996, 436, 366, 257, 869, 2615, 1478, 12554, 13, 407, 26039, 33424, 11, 4156, 14313, 11, 4552, 11, 293, 441, 2404, 11, 456, 311, 257, 688, 295, 552, 13, 51424], "temperature": 0.0, "avg_logprob": -0.1596173618150794, "compression_ratio": 1.5327868852459017, "no_speech_prob": 0.00019711443746928126}, {"id": 41, "seek": 22320, "start": 245.12, "end": 252.72, "text": " And you've probably heard about a couple. And so as for applications of LLMs, translation tasks,", "tokens": [51460, 400, 291, 600, 1391, 2198, 466, 257, 1916, 13, 400, 370, 382, 337, 5821, 295, 441, 43, 26386, 11, 12853, 9608, 11, 51840], "temperature": 0.0, "avg_logprob": -0.1596173618150794, "compression_ratio": 1.5327868852459017, "no_speech_prob": 0.00019711443746928126}, {"id": 42, "seek": 25320, "start": 253.51999999999998, "end": 256.56, "text": " you can use them for text generation, report story scripts.", "tokens": [50380, 291, 393, 764, 552, 337, 2487, 5125, 11, 2275, 1657, 23294, 13, 50532], "temperature": 0.0, "avg_logprob": -0.14441599629142068, "compression_ratio": 1.5069124423963134, "no_speech_prob": 0.0004237710381858051}, {"id": 43, "seek": 25320, "start": 257.12, "end": 264.56, "text": " You can ask an LLM to generate 10 different poems on a subject you like in that particular style,", "tokens": [50560, 509, 393, 1029, 364, 441, 43, 44, 281, 8460, 1266, 819, 24014, 322, 257, 3983, 291, 411, 294, 300, 1729, 3758, 11, 50932], "temperature": 0.0, "avg_logprob": -0.14441599629142068, "compression_ratio": 1.5069124423963134, "no_speech_prob": 0.0004237710381858051}, {"id": 44, "seek": 25320, "start": 264.56, "end": 271.84, "text": " for instance, can use LLMs for Q&As, synthesizing, etc. So this is what an LLM is like.", "tokens": [50932, 337, 5197, 11, 393, 764, 441, 43, 26386, 337, 1249, 5, 10884, 11, 26617, 3319, 11, 5183, 13, 407, 341, 307, 437, 364, 441, 43, 44, 307, 411, 13, 51296], "temperature": 0.0, "avg_logprob": -0.14441599629142068, "compression_ratio": 1.5069124423963134, "no_speech_prob": 0.0004237710381858051}, {"id": 45, "seek": 25320, "start": 273.84, "end": 279.52, "text": " Now, introducing causality is rather complicated because it's a complicated term.", "tokens": [51396, 823, 11, 15424, 3302, 1860, 307, 2831, 6179, 570, 309, 311, 257, 6179, 1433, 13, 51680], "temperature": 0.0, "avg_logprob": -0.14441599629142068, "compression_ratio": 1.5069124423963134, "no_speech_prob": 0.0004237710381858051}, {"id": 46, "seek": 27952, "start": 279.68, "end": 285.2, "text": " But I'm pretty sure, again, the most part of you are really familiar with what causality is.", "tokens": [50372, 583, 286, 478, 1238, 988, 11, 797, 11, 264, 881, 644, 295, 291, 366, 534, 4963, 365, 437, 3302, 1860, 307, 13, 50648], "temperature": 0.0, "avg_logprob": -0.13643905351746757, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.0026713786646723747}, {"id": 47, "seek": 27952, "start": 285.2, "end": 289.2, "text": " So I'm just going to say it's a relation, studying causality, studying relationships", "tokens": [50648, 407, 286, 478, 445, 516, 281, 584, 309, 311, 257, 9721, 11, 7601, 3302, 1860, 11, 7601, 6159, 50848], "temperature": 0.0, "avg_logprob": -0.13643905351746757, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.0026713786646723747}, {"id": 48, "seek": 27952, "start": 289.2, "end": 296.32, "text": " between cause and effect. Due to Pearl dedicated the major part of his life, working on that,", "tokens": [50848, 1296, 3082, 293, 1802, 13, 18980, 281, 24639, 8374, 264, 2563, 644, 295, 702, 993, 11, 1364, 322, 300, 11, 51204], "temperature": 0.0, "avg_logprob": -0.13643905351746757, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.0026713786646723747}, {"id": 49, "seek": 27952, "start": 296.32, "end": 300.96, "text": " I'm pretty sure you're all familiar with his work. So I'm not going to stain his image,", "tokens": [51204, 286, 478, 1238, 988, 291, 434, 439, 4963, 365, 702, 589, 13, 407, 286, 478, 406, 516, 281, 16441, 702, 3256, 11, 51436], "temperature": 0.0, "avg_logprob": -0.13643905351746757, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.0026713786646723747}, {"id": 50, "seek": 27952, "start": 300.96, "end": 304.24, "text": " trying to give another definition that wouldn't serve no purpose.", "tokens": [51436, 1382, 281, 976, 1071, 7123, 300, 2759, 380, 4596, 572, 4334, 13, 51600], "temperature": 0.0, "avg_logprob": -0.13643905351746757, "compression_ratio": 1.7489711934156378, "no_speech_prob": 0.0026713786646723747}, {"id": 51, "seek": 30424, "start": 305.2, "end": 311.68, "text": " Um, causality carries more information than correlation, which is why it is so interesting.", "tokens": [50412, 3301, 11, 3302, 1860, 16402, 544, 1589, 813, 20009, 11, 597, 307, 983, 309, 307, 370, 1880, 13, 50736], "temperature": 0.0, "avg_logprob": -0.12855064868927002, "compression_ratio": 1.696808510638298, "no_speech_prob": 0.005466907750815153}, {"id": 52, "seek": 30424, "start": 312.72, "end": 319.52, "text": " Studying causality is more important than studying just statistical correlations,", "tokens": [50788, 4541, 1840, 3302, 1860, 307, 544, 1021, 813, 7601, 445, 22820, 13983, 763, 11, 51128], "temperature": 0.0, "avg_logprob": -0.12855064868927002, "compression_ratio": 1.696808510638298, "no_speech_prob": 0.005466907750815153}, {"id": 53, "seek": 30424, "start": 319.52, "end": 323.44, "text": " for that matter. This is why there is a lot of work on studying causality,", "tokens": [51128, 337, 300, 1871, 13, 639, 307, 983, 456, 307, 257, 688, 295, 589, 322, 7601, 3302, 1860, 11, 51324], "temperature": 0.0, "avg_logprob": -0.12855064868927002, "compression_ratio": 1.696808510638298, "no_speech_prob": 0.005466907750815153}, {"id": 54, "seek": 30424, "start": 323.44, "end": 327.92, "text": " in order to understand how natural processes interact with each other.", "tokens": [51324, 294, 1668, 281, 1223, 577, 3303, 7555, 4648, 365, 1184, 661, 13, 51548], "temperature": 0.0, "avg_logprob": -0.12855064868927002, "compression_ratio": 1.696808510638298, "no_speech_prob": 0.005466907750815153}, {"id": 55, "seek": 32792, "start": 327.92, "end": 335.68, "text": " And the question now is, how does those two concepts connect?", "tokens": [50364, 400, 264, 1168, 586, 307, 11, 577, 775, 729, 732, 10392, 1745, 30, 50752], "temperature": 0.0, "avg_logprob": -0.1568516179134971, "compression_ratio": 1.549222797927461, "no_speech_prob": 0.006096037104725838}, {"id": 56, "seek": 32792, "start": 337.44, "end": 340.88, "text": " Why do we even have this question of can LLMs infer causality?", "tokens": [50840, 1545, 360, 321, 754, 362, 341, 1168, 295, 393, 441, 43, 26386, 13596, 3302, 1860, 30, 51012], "temperature": 0.0, "avg_logprob": -0.1568516179134971, "compression_ratio": 1.549222797927461, "no_speech_prob": 0.006096037104725838}, {"id": 57, "seek": 32792, "start": 341.6, "end": 348.48, "text": " The question comes from the fact that LLMs learn their input data, their training data is", "tokens": [51048, 440, 1168, 1487, 490, 264, 1186, 300, 441, 43, 26386, 1466, 641, 4846, 1412, 11, 641, 3097, 1412, 307, 51392], "temperature": 0.0, "avg_logprob": -0.1568516179134971, "compression_ratio": 1.549222797927461, "no_speech_prob": 0.006096037104725838}, {"id": 58, "seek": 32792, "start": 348.48, "end": 356.24, "text": " huge corpus of text that ranges from Wikipedia articles to blog posts to books, etc.", "tokens": [51392, 2603, 1181, 31624, 295, 2487, 300, 22526, 490, 28999, 11290, 281, 6968, 12300, 281, 3642, 11, 5183, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1568516179134971, "compression_ratio": 1.549222797927461, "no_speech_prob": 0.006096037104725838}, {"id": 59, "seek": 35624, "start": 356.32, "end": 362.48, "text": " So literally what they are is just a condensed experience of what the world beat them.", "tokens": [50368, 407, 3736, 437, 436, 366, 307, 445, 257, 36398, 1752, 295, 437, 264, 1002, 4224, 552, 13, 50676], "temperature": 0.0, "avg_logprob": -0.141873888222568, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.0008827741257846355}, {"id": 60, "seek": 35624, "start": 363.36, "end": 370.32, "text": " And in those texts, there is a lot of information about describing processes and everything.", "tokens": [50720, 400, 294, 729, 15765, 11, 456, 307, 257, 688, 295, 1589, 466, 16141, 7555, 293, 1203, 13, 51068], "temperature": 0.0, "avg_logprob": -0.141873888222568, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.0008827741257846355}, {"id": 61, "seek": 35624, "start": 370.96000000000004, "end": 378.16, "text": " So today, if you ask a GPT agent, I see it start to rain. What is the impact on the ground?", "tokens": [51100, 407, 965, 11, 498, 291, 1029, 257, 26039, 51, 9461, 11, 286, 536, 309, 722, 281, 4830, 13, 708, 307, 264, 2712, 322, 264, 2727, 30, 51460], "temperature": 0.0, "avg_logprob": -0.141873888222568, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.0008827741257846355}, {"id": 62, "seek": 35624, "start": 378.72, "end": 381.76, "text": " And the LLM will answer the ground will be wet.", "tokens": [51488, 400, 264, 441, 43, 44, 486, 1867, 264, 2727, 486, 312, 6630, 13, 51640], "temperature": 0.0, "avg_logprob": -0.141873888222568, "compression_ratio": 1.4976525821596245, "no_speech_prob": 0.0008827741257846355}, {"id": 63, "seek": 38176, "start": 381.84, "end": 390.0, "text": " So it may appear that the LLM is able to infer causality in that particular setting,", "tokens": [50368, 407, 309, 815, 4204, 300, 264, 441, 43, 44, 307, 1075, 281, 13596, 3302, 1860, 294, 300, 1729, 3287, 11, 50776], "temperature": 0.0, "avg_logprob": -0.14585310220718384, "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.0200026948004961}, {"id": 64, "seek": 38176, "start": 390.0, "end": 394.4, "text": " because it is able to tell you what is going to be the outcome of a situation you describe.", "tokens": [50776, 570, 309, 307, 1075, 281, 980, 291, 437, 307, 516, 281, 312, 264, 9700, 295, 257, 2590, 291, 6786, 13, 50996], "temperature": 0.0, "avg_logprob": -0.14585310220718384, "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.0200026948004961}, {"id": 65, "seek": 38176, "start": 395.2, "end": 400.0, "text": " But a lot of people have been digging into this and trying to figure out if this is really causality", "tokens": [51036, 583, 257, 688, 295, 561, 362, 668, 17343, 666, 341, 293, 1382, 281, 2573, 484, 498, 341, 307, 534, 3302, 1860, 51276], "temperature": 0.0, "avg_logprob": -0.14585310220718384, "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.0200026948004961}, {"id": 66, "seek": 38176, "start": 400.0, "end": 404.24, "text": " or no, and if it is, which type of causality it is, and we'll get back to that later.", "tokens": [51276, 420, 572, 11, 293, 498, 309, 307, 11, 597, 2010, 295, 3302, 1860, 309, 307, 11, 293, 321, 603, 483, 646, 281, 300, 1780, 13, 51488], "temperature": 0.0, "avg_logprob": -0.14585310220718384, "compression_ratio": 1.6805555555555556, "no_speech_prob": 0.0200026948004961}, {"id": 67, "seek": 40424, "start": 404.96000000000004, "end": 412.56, "text": " And let's say they were really possible of inferring causality, what would be the implications", "tokens": [50400, 400, 718, 311, 584, 436, 645, 534, 1944, 295, 13596, 2937, 3302, 1860, 11, 437, 576, 312, 264, 16602, 50780], "temperature": 0.0, "avg_logprob": -0.14472675323486328, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.027991093695163727}, {"id": 68, "seek": 40424, "start": 413.2, "end": 420.64, "text": " on future research on a world, etc. And I just want to finish this by putting another small", "tokens": [50812, 322, 2027, 2132, 322, 257, 1002, 11, 5183, 13, 400, 286, 445, 528, 281, 2413, 341, 538, 3372, 1071, 1359, 51184], "temperature": 0.0, "avg_logprob": -0.14472675323486328, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.027991093695163727}, {"id": 69, "seek": 40424, "start": 420.64, "end": 428.0, "text": " motivation point, which is that if we get back to my previous topic and the thing I'm working on,", "tokens": [51184, 12335, 935, 11, 597, 307, 300, 498, 321, 483, 646, 281, 452, 3894, 4829, 293, 264, 551, 286, 478, 1364, 322, 11, 51552], "temperature": 0.0, "avg_logprob": -0.14472675323486328, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.027991093695163727}, {"id": 70, "seek": 42800, "start": 428.56, "end": 434.88, "text": " from Zhang et al. from this paper says, decision-making scenarios require a quantitative", "tokens": [50392, 490, 17729, 1030, 419, 13, 490, 341, 3035, 1619, 11, 3537, 12, 12402, 15077, 3651, 257, 27778, 50708], "temperature": 0.0, "avg_logprob": -0.17063676198323569, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.012422410771250725}, {"id": 71, "seek": 42800, "start": 434.88, "end": 441.6, "text": " understanding of the effects of actions leading to the desired outcome. In another way,", "tokens": [50708, 3701, 295, 264, 5065, 295, 5909, 5775, 281, 264, 14721, 9700, 13, 682, 1071, 636, 11, 51044], "temperature": 0.0, "avg_logprob": -0.17063676198323569, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.012422410771250725}, {"id": 72, "seek": 42800, "start": 442.72, "end": 447.6, "text": " if we want to be able to tackle precisely decision-making problems,", "tokens": [51100, 498, 321, 528, 281, 312, 1075, 281, 14896, 13402, 3537, 12, 12402, 2740, 11, 51344], "temperature": 0.0, "avg_logprob": -0.17063676198323569, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.012422410771250725}, {"id": 73, "seek": 42800, "start": 449.04, "end": 453.44, "text": " we need to have an understanding of cause and effects. Otherwise, it's complicated to have", "tokens": [51416, 321, 643, 281, 362, 364, 3701, 295, 3082, 293, 5065, 13, 10328, 11, 309, 311, 6179, 281, 362, 51636], "temperature": 0.0, "avg_logprob": -0.17063676198323569, "compression_ratio": 1.6502463054187193, "no_speech_prob": 0.012422410771250725}, {"id": 74, "seek": 45344, "start": 453.44, "end": 461.68, "text": " all the causal chains of actions that would be triggered by one particular decision.", "tokens": [50364, 439, 264, 38755, 12626, 295, 5909, 300, 576, 312, 21710, 538, 472, 1729, 3537, 13, 50776], "temperature": 0.0, "avg_logprob": -0.11931416228577331, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.004678539466112852}, {"id": 75, "seek": 45344, "start": 461.68, "end": 466.0, "text": " So this is a bit of the motivation why it would be interesting for us to understand whether", "tokens": [50776, 407, 341, 307, 257, 857, 295, 264, 12335, 983, 309, 576, 312, 1880, 337, 505, 281, 1223, 1968, 50992], "temperature": 0.0, "avg_logprob": -0.11931416228577331, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.004678539466112852}, {"id": 76, "seek": 45344, "start": 466.0, "end": 474.15999999999997, "text": " LLMs are able to do causality or not, and which one. So just a quick view of the papers I used to do", "tokens": [50992, 441, 43, 26386, 366, 1075, 281, 360, 3302, 1860, 420, 406, 11, 293, 597, 472, 13, 407, 445, 257, 1702, 1910, 295, 264, 10577, 286, 1143, 281, 360, 51400], "temperature": 0.0, "avg_logprob": -0.11931416228577331, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.004678539466112852}, {"id": 77, "seek": 45344, "start": 474.15999999999997, "end": 482.24, "text": " this literature review. Those two first paper are by Jin et al. The first one, they present", "tokens": [51400, 341, 10394, 3131, 13, 3950, 732, 700, 3035, 366, 538, 10617, 1030, 419, 13, 440, 700, 472, 11, 436, 1974, 51804], "temperature": 0.0, "avg_logprob": -0.11931416228577331, "compression_ratio": 1.611353711790393, "no_speech_prob": 0.004678539466112852}, {"id": 78, "seek": 48224, "start": 482.24, "end": 491.12, "text": " Clutter, which is a causal benchmark. They use in order to evaluate LLMs to causal task,", "tokens": [50364, 2033, 9947, 11, 597, 307, 257, 38755, 18927, 13, 814, 764, 294, 1668, 281, 13059, 441, 43, 26386, 281, 38755, 5633, 11, 50808], "temperature": 0.0, "avg_logprob": -0.1551788542005751, "compression_ratio": 1.675, "no_speech_prob": 0.005907532759010792}, {"id": 79, "seek": 48224, "start": 491.12, "end": 495.04, "text": " as well as fine-tuning LLM models to see if they could approve their results.", "tokens": [50808, 382, 731, 382, 2489, 12, 83, 37726, 441, 43, 44, 5245, 281, 536, 498, 436, 727, 18827, 641, 3542, 13, 51004], "temperature": 0.0, "avg_logprob": -0.1551788542005751, "compression_ratio": 1.675, "no_speech_prob": 0.005907532759010792}, {"id": 80, "seek": 48224, "start": 496.24, "end": 503.28000000000003, "text": " The second one, they introduce a task for LLMs to be evaluated on, which is called", "tokens": [51064, 440, 1150, 472, 11, 436, 5366, 257, 5633, 337, 441, 43, 26386, 281, 312, 25509, 322, 11, 597, 307, 1219, 51416], "temperature": 0.0, "avg_logprob": -0.1551788542005751, "compression_ratio": 1.675, "no_speech_prob": 0.005907532759010792}, {"id": 81, "seek": 48224, "start": 504.08, "end": 510.88, "text": " core to causation. So basically, they try to convert correlation to causation and see", "tokens": [51456, 4965, 281, 3302, 399, 13, 407, 1936, 11, 436, 853, 281, 7620, 20009, 281, 3302, 399, 293, 536, 51796], "temperature": 0.0, "avg_logprob": -0.1551788542005751, "compression_ratio": 1.675, "no_speech_prob": 0.005907532759010792}, {"id": 82, "seek": 51088, "start": 510.88, "end": 519.4399999999999, "text": " how well it translates. The two next papers, Kissiman and Lyudel. So Kissiman et al is", "tokens": [50364, 577, 731, 309, 28468, 13, 440, 732, 958, 10577, 11, 24297, 25504, 293, 12687, 532, 338, 13, 407, 24297, 25504, 1030, 419, 307, 50792], "temperature": 0.0, "avg_logprob": -0.19310547245873344, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0005273458082228899}, {"id": 83, "seek": 51088, "start": 526.08, "end": 531.92, "text": " yes, it's just another study of multiple types of causality evaluation on LLMs.", "tokens": [51124, 2086, 11, 309, 311, 445, 1071, 2979, 295, 3866, 3467, 295, 3302, 1860, 13344, 322, 441, 43, 26386, 13, 51416], "temperature": 0.0, "avg_logprob": -0.19310547245873344, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0005273458082228899}, {"id": 84, "seek": 51088, "start": 533.6, "end": 539.28, "text": " Lyudel 2019, this one is a bit interesting because it's older. So this one was out before", "tokens": [51500, 12687, 532, 338, 6071, 11, 341, 472, 307, 257, 857, 1880, 570, 309, 311, 4906, 13, 407, 341, 472, 390, 484, 949, 51784], "temperature": 0.0, "avg_logprob": -0.19310547245873344, "compression_ratio": 1.4222222222222223, "no_speech_prob": 0.0005273458082228899}, {"id": 85, "seek": 53928, "start": 539.28, "end": 547.12, "text": " the LLMs actually were advertised and were that popular. And this one uses a different approach", "tokens": [50364, 264, 441, 43, 26386, 767, 645, 42310, 293, 645, 300, 3743, 13, 400, 341, 472, 4960, 257, 819, 3109, 50756], "temperature": 0.0, "avg_logprob": -0.19422777237430697, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.0020181513391435146}, {"id": 86, "seek": 53928, "start": 547.12, "end": 552.48, "text": " using intelligent agents, but I will get back to that. And the last one,", "tokens": [50756, 1228, 13232, 12554, 11, 457, 286, 486, 483, 646, 281, 300, 13, 400, 264, 1036, 472, 11, 51024], "temperature": 0.0, "avg_logprob": -0.19422777237430697, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.0020181513391435146}, {"id": 87, "seek": 53928, "start": 553.76, "end": 559.8399999999999, "text": " Vetservish is probably the most interesting in this one because it's the most,", "tokens": [51088, 691, 1385, 1978, 742, 307, 1391, 264, 881, 1880, 294, 341, 472, 570, 309, 311, 264, 881, 11, 51392], "temperature": 0.0, "avg_logprob": -0.19422777237430697, "compression_ratio": 1.496969696969697, "no_speech_prob": 0.0020181513391435146}, {"id": 88, "seek": 55984, "start": 560.8000000000001, "end": 569.84, "text": " not unbiased, but they make the strongest statements. They say that LLMs are causal", "tokens": [50412, 406, 517, 5614, 1937, 11, 457, 436, 652, 264, 16595, 12363, 13, 814, 584, 300, 441, 43, 26386, 366, 38755, 50864], "temperature": 0.0, "avg_logprob": -0.15128800143366275, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0240424033254385}, {"id": 89, "seek": 55984, "start": 569.84, "end": 575.76, "text": " parrots and they can maybe appear to talk causality, but deep inside, they're not at all and never", "tokens": [50864, 971, 81, 1971, 293, 436, 393, 1310, 4204, 281, 751, 3302, 1860, 11, 457, 2452, 1854, 11, 436, 434, 406, 412, 439, 293, 1128, 51160], "temperature": 0.0, "avg_logprob": -0.15128800143366275, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0240424033254385}, {"id": 90, "seek": 55984, "start": 575.76, "end": 581.12, "text": " will be. So they make quite strong statements and it's interesting. And the last one,", "tokens": [51160, 486, 312, 13, 407, 436, 652, 1596, 2068, 12363, 293, 309, 311, 1880, 13, 400, 264, 1036, 472, 11, 51428], "temperature": 0.0, "avg_logprob": -0.15128800143366275, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0240424033254385}, {"id": 91, "seek": 55984, "start": 581.12, "end": 589.36, "text": " the last one is early 2023 and gives a couple of insights on future work and future directions,", "tokens": [51428, 264, 1036, 472, 307, 2440, 44377, 293, 2709, 257, 1916, 295, 14310, 322, 2027, 589, 293, 2027, 11095, 11, 51840], "temperature": 0.0, "avg_logprob": -0.15128800143366275, "compression_ratio": 1.6322869955156951, "no_speech_prob": 0.0240424033254385}, {"id": 92, "seek": 58936, "start": 589.36, "end": 596.72, "text": " but don't give a lot of answers in there. So I'll just start by quickly reminding for this,", "tokens": [50364, 457, 500, 380, 976, 257, 688, 295, 6338, 294, 456, 13, 407, 286, 603, 445, 722, 538, 2661, 27639, 337, 341, 11, 50732], "temperature": 0.0, "avg_logprob": -0.12520109064438764, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005272951093502343}, {"id": 93, "seek": 58936, "start": 596.72, "end": 601.44, "text": " for the purpose of this study that the difference between causal discovery and causal inference", "tokens": [50732, 337, 264, 4334, 295, 341, 2979, 300, 264, 2649, 1296, 38755, 12114, 293, 38755, 38253, 50968], "temperature": 0.0, "avg_logprob": -0.12520109064438764, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005272951093502343}, {"id": 94, "seek": 58936, "start": 601.44, "end": 608.8000000000001, "text": " tasks, because those concepts are used in the papers. So causal discovery is constructing", "tokens": [50968, 9608, 11, 570, 729, 10392, 366, 1143, 294, 264, 10577, 13, 407, 38755, 12114, 307, 39969, 51336], "temperature": 0.0, "avg_logprob": -0.12520109064438764, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005272951093502343}, {"id": 95, "seek": 58936, "start": 608.8000000000001, "end": 615.6800000000001, "text": " a causal structure. Basically it is figuring out a dag, a directly, sorry, directed a cyclic graph", "tokens": [51336, 257, 38755, 3877, 13, 8537, 309, 307, 15213, 484, 257, 15460, 11, 257, 3838, 11, 2597, 11, 12898, 257, 38154, 1050, 4295, 51680], "temperature": 0.0, "avg_logprob": -0.12520109064438764, "compression_ratio": 1.663716814159292, "no_speech_prob": 0.0005272951093502343}, {"id": 96, "seek": 61568, "start": 616.4799999999999, "end": 621.68, "text": " in which all the nodes are variable and there is a link between the nodes when there is a", "tokens": [50404, 294, 597, 439, 264, 13891, 366, 7006, 293, 456, 307, 257, 2113, 1296, 264, 13891, 562, 456, 307, 257, 50664], "temperature": 0.0, "avg_logprob": -0.12534195629518424, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0018667238764464855}, {"id": 97, "seek": 61568, "start": 621.68, "end": 630.2399999999999, "text": " functional relationship. The causal discovery holds a structure for, in order to be able to infer", "tokens": [50664, 11745, 2480, 13, 440, 38755, 12114, 9190, 257, 3877, 337, 11, 294, 1668, 281, 312, 1075, 281, 13596, 51092], "temperature": 0.0, "avg_logprob": -0.12534195629518424, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0018667238764464855}, {"id": 98, "seek": 61568, "start": 630.2399999999999, "end": 636.4799999999999, "text": " causality on multiple levels. Multiple levels of causality, as defined by Perl, are observational,", "tokens": [51092, 3302, 1860, 322, 3866, 4358, 13, 40056, 4358, 295, 3302, 1860, 11, 382, 7642, 538, 3026, 75, 11, 366, 9951, 1478, 11, 51404], "temperature": 0.0, "avg_logprob": -0.12534195629518424, "compression_ratio": 1.615819209039548, "no_speech_prob": 0.0018667238764464855}, {"id": 99, "seek": 63648, "start": 636.5600000000001, "end": 643.04, "text": " interventional and counterfactual. Where observational, you only need to observe", "tokens": [50368, 13176, 304, 293, 5682, 44919, 901, 13, 2305, 9951, 1478, 11, 291, 787, 643, 281, 11441, 50692], "temperature": 0.0, "avg_logprob": -0.13625551706337066, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.030666103586554527}, {"id": 100, "seek": 63648, "start": 644.24, "end": 652.5600000000001, "text": " the cause and effect for you to be able to say that this is causal. Interventional requires the", "tokens": [50752, 264, 3082, 293, 1802, 337, 291, 281, 312, 1075, 281, 584, 300, 341, 307, 38755, 13, 5751, 46105, 7029, 264, 51168], "temperature": 0.0, "avg_logprob": -0.13625551706337066, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.030666103586554527}, {"id": 101, "seek": 63648, "start": 652.5600000000001, "end": 657.2, "text": " intervention, so changing a variable and seeing if there is an effect on another one.", "tokens": [51168, 13176, 11, 370, 4473, 257, 7006, 293, 2577, 498, 456, 307, 364, 1802, 322, 1071, 472, 13, 51400], "temperature": 0.0, "avg_logprob": -0.13625551706337066, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.030666103586554527}, {"id": 102, "seek": 63648, "start": 657.84, "end": 665.36, "text": " And counterfactual is knowing that there is a causality link. It is the highest level of", "tokens": [51432, 400, 5682, 44919, 901, 307, 5276, 300, 456, 307, 257, 3302, 1860, 2113, 13, 467, 307, 264, 6343, 1496, 295, 51808], "temperature": 0.0, "avg_logprob": -0.13625551706337066, "compression_ratio": 1.781725888324873, "no_speech_prob": 0.030666103586554527}, {"id": 103, "seek": 66536, "start": 665.36, "end": 670.72, "text": " causality. Knowing there is a causality level and two variables, what would happen if you would", "tokens": [50364, 3302, 1860, 13, 25499, 456, 307, 257, 3302, 1860, 1496, 293, 732, 9102, 11, 437, 576, 1051, 498, 291, 576, 50632], "temperature": 0.0, "avg_logprob": -0.12807643107878855, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0006461364100687206}, {"id": 104, "seek": 66536, "start": 670.72, "end": 678.24, "text": " change the variable in such a way? So they just remind the difference between discovery, which", "tokens": [50632, 1319, 264, 7006, 294, 1270, 257, 636, 30, 407, 436, 445, 4160, 264, 2649, 1296, 12114, 11, 597, 51008], "temperature": 0.0, "avg_logprob": -0.12807643107878855, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0006461364100687206}, {"id": 105, "seek": 66536, "start": 678.24, "end": 688.08, "text": " is more about finding the structure that ties all variables together and explaining the possible", "tokens": [51008, 307, 544, 466, 5006, 264, 3877, 300, 14039, 439, 9102, 1214, 293, 13468, 264, 1944, 51500], "temperature": 0.0, "avg_logprob": -0.12807643107878855, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0006461364100687206}, {"id": 106, "seek": 66536, "start": 688.08, "end": 693.6800000000001, "text": " relationship that can be between. And causal inference would be more about determining what", "tokens": [51500, 2480, 300, 393, 312, 1296, 13, 400, 38755, 38253, 576, 312, 544, 466, 23751, 437, 51780], "temperature": 0.0, "avg_logprob": -0.12807643107878855, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.0006461364100687206}, {"id": 107, "seek": 69368, "start": 693.68, "end": 698.9599999999999, "text": " level, what strength of causality there is between two variables and which direction to.", "tokens": [50364, 1496, 11, 437, 3800, 295, 3302, 1860, 456, 307, 1296, 732, 9102, 293, 597, 3513, 281, 13, 50628], "temperature": 0.0, "avg_logprob": -0.22363084735292377, "compression_ratio": 1.5, "no_speech_prob": 0.000869060168042779}, {"id": 108, "seek": 69368, "start": 700.88, "end": 708.64, "text": " And so the first results that are given by Kissimer et al. So they work on inferring", "tokens": [50724, 400, 370, 264, 700, 3542, 300, 366, 2212, 538, 24297, 9713, 1030, 419, 13, 407, 436, 589, 322, 13596, 2937, 51112], "temperature": 0.0, "avg_logprob": -0.22363084735292377, "compression_ratio": 1.5, "no_speech_prob": 0.000869060168042779}, {"id": 109, "seek": 69368, "start": 708.64, "end": 714.2399999999999, "text": " causal discovery. So what they do is they're trying to come up with that direct to stick with graph", "tokens": [51112, 38755, 12114, 13, 407, 437, 436, 360, 307, 436, 434, 1382, 281, 808, 493, 365, 300, 2047, 281, 2897, 365, 4295, 51392], "temperature": 0.0, "avg_logprob": -0.22363084735292377, "compression_ratio": 1.5, "no_speech_prob": 0.000869060168042779}, {"id": 110, "seek": 71424, "start": 714.32, "end": 726.16, "text": " using an LLM. And so the findings are that the best LLM in the list, GPT-4, and is almost always", "tokens": [50368, 1228, 364, 441, 43, 44, 13, 400, 370, 264, 16483, 366, 300, 264, 1151, 441, 43, 44, 294, 264, 1329, 11, 26039, 51, 12, 19, 11, 293, 307, 1920, 1009, 50960], "temperature": 0.0, "avg_logprob": -0.2500366520237278, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.07471919804811478}, {"id": 111, "seek": 71424, "start": 726.16, "end": 732.72, "text": " GPT-4, art performs causal discovery frameworks by approximately 40% on the Tobingen benchmark", "tokens": [50960, 26039, 51, 12, 19, 11, 1523, 26213, 38755, 12114, 29834, 538, 10447, 3356, 4, 322, 264, 26350, 12343, 18927, 51288], "temperature": 0.0, "avg_logprob": -0.2500366520237278, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.07471919804811478}, {"id": 112, "seek": 71424, "start": 733.36, "end": 739.6800000000001, "text": " on pairwise causal discovery tasks. So for two variable, two by two variables,", "tokens": [51320, 322, 6119, 3711, 38755, 12114, 9608, 13, 407, 337, 732, 7006, 11, 732, 538, 732, 9102, 11, 51636], "temperature": 0.0, "avg_logprob": -0.2500366520237278, "compression_ratio": 1.4917127071823204, "no_speech_prob": 0.07471919804811478}, {"id": 113, "seek": 73968, "start": 740.2399999999999, "end": 744.64, "text": " is being able to find out if they could be related in some way or not.", "tokens": [50392, 307, 885, 1075, 281, 915, 484, 498, 436, 727, 312, 4077, 294, 512, 636, 420, 406, 13, 50612], "temperature": 0.0, "avg_logprob": -0.11745076939679575, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.0032219989225268364}, {"id": 114, "seek": 73968, "start": 745.52, "end": 753.92, "text": " And so this is the list of the model they tested. And almost every time is GPT-4 performing at the", "tokens": [50656, 400, 370, 341, 307, 264, 1329, 295, 264, 2316, 436, 8246, 13, 400, 1920, 633, 565, 307, 26039, 51, 12, 19, 10205, 412, 264, 51076], "temperature": 0.0, "avg_logprob": -0.11745076939679575, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.0032219989225268364}, {"id": 115, "seek": 73968, "start": 753.92, "end": 763.12, "text": " best. So this is quite an interesting result, but they also balance that result with the fact that", "tokens": [51076, 1151, 13, 407, 341, 307, 1596, 364, 1880, 1874, 11, 457, 436, 611, 4772, 300, 1874, 365, 264, 1186, 300, 51536], "temperature": 0.0, "avg_logprob": -0.11745076939679575, "compression_ratio": 1.5056179775280898, "no_speech_prob": 0.0032219989225268364}, {"id": 116, "seek": 76312, "start": 763.92, "end": 771.12, "text": " LLMs present a strong lack of robustness because when they fail, it is really unpredictable", "tokens": [50404, 441, 43, 26386, 1974, 257, 2068, 5011, 295, 13956, 1287, 570, 562, 436, 3061, 11, 309, 307, 534, 31160, 50764], "temperature": 0.0, "avg_logprob": -0.18432343006134033, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.023681720718741417}, {"id": 117, "seek": 76312, "start": 771.76, "end": 778.16, "text": " to predict. It is really unpredictable the fact that are going to fail or not. So you might have", "tokens": [50796, 281, 6069, 13, 467, 307, 534, 31160, 264, 1186, 300, 366, 516, 281, 3061, 420, 406, 13, 407, 291, 1062, 362, 51116], "temperature": 0.0, "avg_logprob": -0.18432343006134033, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.023681720718741417}, {"id": 118, "seek": 76312, "start": 778.16, "end": 784.64, "text": " 96% of accuracy, but it's hard to predict when they will fail. This is what they put the accent on", "tokens": [51116, 24124, 4, 295, 14170, 11, 457, 309, 311, 1152, 281, 6069, 562, 436, 486, 3061, 13, 639, 307, 437, 436, 829, 264, 11982, 322, 51440], "temperature": 0.0, "avg_logprob": -0.18432343006134033, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.023681720718741417}, {"id": 119, "seek": 76312, "start": 786.0, "end": 787.28, "text": " when they present their results.", "tokens": [51508, 562, 436, 1974, 641, 3542, 13, 51572], "temperature": 0.0, "avg_logprob": -0.18432343006134033, "compression_ratio": 1.6243654822335025, "no_speech_prob": 0.023681720718741417}, {"id": 120, "seek": 78728, "start": 787.68, "end": 799.1999999999999, "text": " As for the benchmark they use, it is very diverse. So over 100 causal relationships from a variety", "tokens": [50384, 1018, 337, 264, 18927, 436, 764, 11, 309, 307, 588, 9521, 13, 407, 670, 2319, 38755, 6159, 490, 257, 5673, 50960], "temperature": 0.0, "avg_logprob": -0.12427173342023577, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.004980381112545729}, {"id": 121, "seek": 78728, "start": 799.1999999999999, "end": 806.0, "text": " of domains, physics, biology, zoology, cognitive science, epidemiology, soil science. So there", "tokens": [50960, 295, 25514, 11, 10649, 11, 14956, 11, 710, 1092, 7794, 11, 15605, 3497, 11, 35761, 1793, 11, 6704, 3497, 13, 407, 456, 51300], "temperature": 0.0, "avg_logprob": -0.12427173342023577, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.004980381112545729}, {"id": 122, "seek": 78728, "start": 806.0, "end": 811.68, "text": " is a couple of examples of relationships that are in their framework for use to be LLMs.", "tokens": [51300, 307, 257, 1916, 295, 5110, 295, 6159, 300, 366, 294, 641, 8388, 337, 764, 281, 312, 441, 43, 26386, 13, 51584], "temperature": 0.0, "avg_logprob": -0.12427173342023577, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.004980381112545729}, {"id": 123, "seek": 81168, "start": 812.4, "end": 818.8, "text": " So for instance, alcohol and main corpuscular volume. So a question like this will be asked", "tokens": [50400, 407, 337, 5197, 11, 7658, 293, 2135, 1181, 31624, 17792, 5523, 13, 407, 257, 1168, 411, 341, 486, 312, 2351, 50720], "temperature": 0.0, "avg_logprob": -0.24529972882337972, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.009123585186898708}, {"id": 124, "seek": 81168, "start": 818.8, "end": 825.52, "text": " to the LLM and whether depending on the answer is yes or no, it will compare the answer with the", "tokens": [50720, 281, 264, 441, 43, 44, 293, 1968, 5413, 322, 264, 1867, 307, 2086, 420, 572, 11, 309, 486, 6794, 264, 1867, 365, 264, 51056], "temperature": 0.0, "avg_logprob": -0.24529972882337972, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.009123585186898708}, {"id": 125, "seek": 81168, "start": 825.52, "end": 837.68, "text": " real in the framework to establish the accuracy person. Sorry. So the second result is by Zetz", "tokens": [51056, 957, 294, 264, 8388, 281, 8327, 264, 14170, 954, 13, 4919, 13, 407, 264, 1150, 1874, 307, 538, 1176, 10074, 51664], "temperature": 0.0, "avg_logprob": -0.24529972882337972, "compression_ratio": 1.5053191489361701, "no_speech_prob": 0.009123585186898708}, {"id": 126, "seek": 83768, "start": 837.68, "end": 845.52, "text": " Avicila. They do a lot of different types of causal inference and causal tasks in their study.", "tokens": [50364, 11667, 299, 7371, 13, 814, 360, 257, 688, 295, 819, 3467, 295, 38755, 38253, 293, 38755, 9608, 294, 641, 2979, 13, 50756], "temperature": 0.0, "avg_logprob": -0.16295341003772823, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.006583439186215401}, {"id": 127, "seek": 83768, "start": 845.52, "end": 850.16, "text": " It's very complete. They also do a causal discovery task, which is pretty much the same.", "tokens": [50756, 467, 311, 588, 3566, 13, 814, 611, 360, 257, 38755, 12114, 5633, 11, 597, 307, 1238, 709, 264, 912, 13, 50988], "temperature": 0.0, "avg_logprob": -0.16295341003772823, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.006583439186215401}, {"id": 128, "seek": 83768, "start": 850.16, "end": 855.68, "text": " They feed a scientific question to the LLM and depending on the answer, they say yes or no", "tokens": [50988, 814, 3154, 257, 8134, 1168, 281, 264, 441, 43, 44, 293, 5413, 322, 264, 1867, 11, 436, 584, 2086, 420, 572, 51264], "temperature": 0.0, "avg_logprob": -0.16295341003772823, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.006583439186215401}, {"id": 129, "seek": 83768, "start": 856.4, "end": 867.04, "text": " to the establishing of causal discovery. So this is the results they get.", "tokens": [51300, 281, 264, 22494, 295, 38755, 12114, 13, 407, 341, 307, 264, 3542, 436, 483, 13, 51832], "temperature": 0.0, "avg_logprob": -0.16295341003772823, "compression_ratio": 1.6415094339622642, "no_speech_prob": 0.006583439186215401}, {"id": 130, "seek": 86768, "start": 868.2399999999999, "end": 874.8, "text": " Where GPT-3, GPT-4 are open AI models. LUMINUS is a model that is built by LUMINUS.", "tokens": [50392, 2305, 26039, 51, 12, 18, 11, 26039, 51, 12, 19, 366, 1269, 7318, 5245, 13, 441, 14340, 1464, 3447, 307, 257, 2316, 300, 307, 3094, 538, 441, 14340, 1464, 3447, 13, 50720], "temperature": 0.0, "avg_logprob": -0.1652517993040759, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.001925264485180378}, {"id": 131, "seek": 86768, "start": 874.8, "end": 883.28, "text": " It's the corporation itself and OPT is the META Facebook LLM. So yes, Russian?", "tokens": [50720, 467, 311, 264, 22197, 2564, 293, 23324, 51, 307, 264, 376, 4850, 32, 4384, 441, 43, 44, 13, 407, 2086, 11, 7220, 30, 51144], "temperature": 0.0, "avg_logprob": -0.1652517993040759, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.001925264485180378}, {"id": 132, "seek": 86768, "start": 885.76, "end": 890.7199999999999, "text": " Just to clarify, they're just checking the question and the answer. They're not", "tokens": [51268, 1449, 281, 17594, 11, 436, 434, 445, 8568, 264, 1168, 293, 264, 1867, 13, 814, 434, 406, 51516], "temperature": 0.0, "avg_logprob": -0.1652517993040759, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.001925264485180378}, {"id": 133, "seek": 86768, "start": 890.7199999999999, "end": 897.3599999999999, "text": " actually checking the chain of reasoning. No, not in this one. There is some frameworks", "tokens": [51516, 767, 8568, 264, 5021, 295, 21577, 13, 883, 11, 406, 294, 341, 472, 13, 821, 307, 512, 29834, 51848], "temperature": 0.0, "avg_logprob": -0.1652517993040759, "compression_ratio": 1.4473684210526316, "no_speech_prob": 0.001925264485180378}, {"id": 134, "seek": 89736, "start": 897.36, "end": 904.16, "text": " and some benchmarks in which they use a chain of thoughts prompt engineering in order to be able", "tokens": [50364, 293, 512, 43751, 294, 597, 436, 764, 257, 5021, 295, 4598, 12391, 7043, 294, 1668, 281, 312, 1075, 50704], "temperature": 0.0, "avg_logprob": -0.1775074544942604, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.001672085258178413}, {"id": 135, "seek": 89736, "start": 904.16, "end": 910.8000000000001, "text": " to check the chain, but not in this one. And they're just using off-the-shelf LLMs. They're", "tokens": [50704, 281, 1520, 264, 5021, 11, 457, 406, 294, 341, 472, 13, 400, 436, 434, 445, 1228, 766, 12, 3322, 12, 46626, 441, 43, 26386, 13, 814, 434, 51036], "temperature": 0.0, "avg_logprob": -0.1775074544942604, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.001672085258178413}, {"id": 136, "seek": 89736, "start": 910.8000000000001, "end": 918.32, "text": " not specifically trained for these. No. Well, yes and no. So they're off-the-shelves LLM. They're", "tokens": [51036, 406, 4682, 8895, 337, 613, 13, 883, 13, 1042, 11, 2086, 293, 572, 13, 407, 436, 434, 766, 12, 3322, 12, 2716, 338, 977, 441, 43, 44, 13, 814, 434, 51412], "temperature": 0.0, "avg_logprob": -0.1775074544942604, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.001672085258178413}, {"id": 137, "seek": 89736, "start": 918.32, "end": 927.28, "text": " not fine-tuned. However, they make some assumptions that in some cases, the enormously high result", "tokens": [51412, 406, 2489, 12, 83, 43703, 13, 2908, 11, 436, 652, 512, 17695, 300, 294, 512, 3331, 11, 264, 39669, 1090, 1874, 51860], "temperature": 0.0, "avg_logprob": -0.1775074544942604, "compression_ratio": 1.5975103734439835, "no_speech_prob": 0.001672085258178413}, {"id": 138, "seek": 92728, "start": 927.28, "end": 935.68, "text": " for GPT-4 could indicate that some parts of the benchmark are actually included in GPT-4's training,", "tokens": [50364, 337, 26039, 51, 12, 19, 727, 13330, 300, 512, 3166, 295, 264, 18927, 366, 767, 5556, 294, 26039, 51, 12, 19, 311, 3097, 11, 50784], "temperature": 0.0, "avg_logprob": -0.08595829403277525, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.00026514462660998106}, {"id": 139, "seek": 92728, "start": 935.68, "end": 942.0799999999999, "text": " but it's hypothetical. They don't have that knowledge. It's just a hypothesis they make.", "tokens": [50784, 457, 309, 311, 33053, 13, 814, 500, 380, 362, 300, 3601, 13, 467, 311, 445, 257, 17291, 436, 652, 13, 51104], "temperature": 0.0, "avg_logprob": -0.08595829403277525, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.00026514462660998106}, {"id": 140, "seek": 92728, "start": 942.0799999999999, "end": 946.3199999999999, "text": " But technically, no, it's just off-the-shelves LLM and these ones are not fine-tuned.", "tokens": [51104, 583, 12120, 11, 572, 11, 309, 311, 445, 766, 12, 3322, 12, 2716, 338, 977, 441, 43, 44, 293, 613, 2306, 366, 406, 2489, 12, 83, 43703, 13, 51316], "temperature": 0.0, "avg_logprob": -0.08595829403277525, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.00026514462660998106}, {"id": 141, "seek": 92728, "start": 947.92, "end": 952.56, "text": " And the assumption is that their answers that they have are well-established", "tokens": [51396, 400, 264, 15302, 307, 300, 641, 6338, 300, 436, 362, 366, 731, 12, 33542, 4173, 51628], "temperature": 0.0, "avg_logprob": -0.08595829403277525, "compression_ratio": 1.5172413793103448, "no_speech_prob": 0.00026514462660998106}, {"id": 142, "seek": 95256, "start": 953.28, "end": 963.8399999999999, "text": " beyond dispute that this is the correct answer. Yes, I guess. Okay. Thanks.", "tokens": [50400, 4399, 25379, 300, 341, 307, 264, 3006, 1867, 13, 1079, 11, 286, 2041, 13, 1033, 13, 2561, 13, 50928], "temperature": 0.0, "avg_logprob": -0.15212918772841943, "compression_ratio": 1.4593023255813953, "no_speech_prob": 0.006189375184476376}, {"id": 143, "seek": 95256, "start": 964.7199999999999, "end": 974.0799999999999, "text": " So yes, this is the result they give for LLMs. To be honest, it's a bit hard to", "tokens": [50972, 407, 2086, 11, 341, 307, 264, 1874, 436, 976, 337, 441, 43, 26386, 13, 1407, 312, 3245, 11, 309, 311, 257, 857, 1152, 281, 51440], "temperature": 0.0, "avg_logprob": -0.15212918772841943, "compression_ratio": 1.4593023255813953, "no_speech_prob": 0.006189375184476376}, {"id": 144, "seek": 95256, "start": 974.0799999999999, "end": 979.1199999999999, "text": " interpret the results sometimes in this paper. There are some sections that are extremely clear", "tokens": [51440, 7302, 264, 3542, 2171, 294, 341, 3035, 13, 821, 366, 512, 10863, 300, 366, 4664, 1850, 51692], "temperature": 0.0, "avg_logprob": -0.15212918772841943, "compression_ratio": 1.4593023255813953, "no_speech_prob": 0.006189375184476376}, {"id": 145, "seek": 97912, "start": 980.0, "end": 986.48, "text": " as to the results and findings, et cetera. Some are less. This is actually one of the main", "tokens": [50408, 382, 281, 264, 3542, 293, 16483, 11, 1030, 11458, 13, 2188, 366, 1570, 13, 639, 307, 767, 472, 295, 264, 2135, 50732], "temperature": 0.0, "avg_logprob": -0.14644154941334445, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.006189580541104078}, {"id": 146, "seek": 97912, "start": 986.48, "end": 992.8, "text": " negative point of this paper that's been highlighted on the open reviews. This paper in", "tokens": [50732, 3671, 935, 295, 341, 3035, 300, 311, 668, 17173, 322, 264, 1269, 10229, 13, 639, 3035, 294, 51048], "temperature": 0.0, "avg_logprob": -0.14644154941334445, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.006189580541104078}, {"id": 147, "seek": 97912, "start": 992.8, "end": 998.24, "text": " particular is going to be published in Transaction for National Learning. It's been reviewed on", "tokens": [51048, 1729, 307, 516, 281, 312, 6572, 294, 6531, 2894, 337, 4862, 15205, 13, 467, 311, 668, 18429, 322, 51320], "temperature": 0.0, "avg_logprob": -0.14644154941334445, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.006189580541104078}, {"id": 148, "seek": 97912, "start": 998.24, "end": 1002.5600000000001, "text": " open reviews. So all the reviews are publicly available on open reviews. It's really interesting.", "tokens": [51320, 1269, 10229, 13, 407, 439, 264, 10229, 366, 14843, 2435, 322, 1269, 10229, 13, 467, 311, 534, 1880, 13, 51536], "temperature": 0.0, "avg_logprob": -0.14644154941334445, "compression_ratio": 1.6986301369863013, "no_speech_prob": 0.006189580541104078}, {"id": 149, "seek": 100256, "start": 1002.56, "end": 1007.1999999999999, "text": " I read a couple. And what's being said about this paper is that", "tokens": [50364, 286, 1401, 257, 1916, 13, 400, 437, 311, 885, 848, 466, 341, 3035, 307, 300, 50596], "temperature": 0.0, "avg_logprob": -0.13060054779052735, "compression_ratio": 1.5804878048780489, "no_speech_prob": 0.06275959312915802}, {"id": 150, "seek": 100256, "start": 1008.3199999999999, "end": 1012.56, "text": " the math behind and the logic behind it is really strong, but sometimes the results", "tokens": [50652, 264, 5221, 2261, 293, 264, 9952, 2261, 309, 307, 534, 2068, 11, 457, 2171, 264, 3542, 50864], "temperature": 0.0, "avg_logprob": -0.13060054779052735, "compression_ratio": 1.5804878048780489, "no_speech_prob": 0.06275959312915802}, {"id": 151, "seek": 100256, "start": 1012.56, "end": 1018.2399999999999, "text": " are not well explained. And sometimes I just cannot tie the results to what they claim.", "tokens": [50864, 366, 406, 731, 8825, 13, 400, 2171, 286, 445, 2644, 7582, 264, 3542, 281, 437, 436, 3932, 13, 51148], "temperature": 0.0, "avg_logprob": -0.13060054779052735, "compression_ratio": 1.5804878048780489, "no_speech_prob": 0.06275959312915802}, {"id": 152, "seek": 100256, "start": 1018.2399999999999, "end": 1028.0, "text": " But that's why we'll move on to the next one. This is the findings on different types of", "tokens": [51148, 583, 300, 311, 983, 321, 603, 1286, 322, 281, 264, 958, 472, 13, 639, 307, 264, 16483, 322, 819, 3467, 295, 51636], "temperature": 0.0, "avg_logprob": -0.13060054779052735, "compression_ratio": 1.5804878048780489, "no_speech_prob": 0.06275959312915802}, {"id": 153, "seek": 102800, "start": 1028.0, "end": 1036.64, "text": " causal inference. So by Genital, the first paper. And so they test about 10 LLMs.", "tokens": [50364, 38755, 38253, 13, 407, 538, 3632, 1686, 11, 264, 700, 3035, 13, 400, 370, 436, 1500, 466, 1266, 441, 43, 26386, 13, 50796], "temperature": 0.0, "avg_logprob": -0.2560085628343665, "compression_ratio": 1.4624277456647399, "no_speech_prob": 0.021274549886584282}, {"id": 154, "seek": 102800, "start": 1038.16, "end": 1044.56, "text": " They test their accuracy on observational, intranational, and counterfactual tasks.", "tokens": [50872, 814, 1500, 641, 14170, 322, 9951, 1478, 11, 560, 4257, 1478, 11, 293, 5682, 44919, 901, 9608, 13, 51192], "temperature": 0.0, "avg_logprob": -0.2560085628343665, "compression_ratio": 1.4624277456647399, "no_speech_prob": 0.021274549886584282}, {"id": 155, "seek": 102800, "start": 1044.56, "end": 1052.32, "text": " And on top of that, so they are tested again, the clatter dataset, which is composed of", "tokens": [51192, 400, 322, 1192, 295, 300, 11, 370, 436, 366, 8246, 797, 11, 264, 596, 1161, 28872, 11, 597, 307, 18204, 295, 51580], "temperature": 0.0, "avg_logprob": -0.2560085628343665, "compression_ratio": 1.4624277456647399, "no_speech_prob": 0.021274549886584282}, {"id": 156, "seek": 105232, "start": 1052.96, "end": 1060.72, "text": " if I, yeah, 10,000 samples of approximately even distributed for every causal task", "tokens": [50396, 498, 286, 11, 1338, 11, 1266, 11, 1360, 10938, 295, 10447, 754, 12631, 337, 633, 38755, 5633, 50784], "temperature": 0.0, "avg_logprob": -0.16195415728019946, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0008692709961906075}, {"id": 157, "seek": 105232, "start": 1060.72, "end": 1066.96, "text": " containing different types of data. And they also come up with what they call causal cot,", "tokens": [50784, 19273, 819, 3467, 295, 1412, 13, 400, 436, 611, 808, 493, 365, 437, 436, 818, 38755, 26529, 11, 51096], "temperature": 0.0, "avg_logprob": -0.16195415728019946, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0008692709961906075}, {"id": 158, "seek": 105232, "start": 1067.6, "end": 1073.84, "text": " which is a fine-tuning model they did using their dataset. So they were trying to figure out at the", "tokens": [51128, 597, 307, 257, 2489, 12, 83, 37726, 2316, 436, 630, 1228, 641, 28872, 13, 407, 436, 645, 1382, 281, 2573, 484, 412, 264, 51440], "temperature": 0.0, "avg_logprob": -0.16195415728019946, "compression_ratio": 1.5027624309392265, "no_speech_prob": 0.0008692709961906075}, {"id": 159, "seek": 107384, "start": 1073.84, "end": 1083.84, "text": " same time how well LLMs performed on a causal benchmark, as well as if they find", "tokens": [50364, 912, 565, 577, 731, 441, 43, 26386, 10332, 322, 257, 38755, 18927, 11, 382, 731, 382, 498, 436, 915, 50864], "temperature": 0.0, "avg_logprob": -0.1415090560913086, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.04741079360246658}, {"id": 160, "seek": 107384, "start": 1083.84, "end": 1090.72, "text": " to the model what performance improvement do you have. And so they conclude that", "tokens": [50864, 281, 264, 2316, 437, 3389, 10444, 360, 291, 362, 13, 400, 370, 436, 16886, 300, 51208], "temperature": 0.0, "avg_logprob": -0.1415090560913086, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.04741079360246658}, {"id": 161, "seek": 107384, "start": 1092.56, "end": 1098.32, "text": " overall, the models just perform slightly better than random, which is not that great.", "tokens": [51300, 4787, 11, 264, 5245, 445, 2042, 4748, 1101, 813, 4974, 11, 597, 307, 406, 300, 869, 13, 51588], "temperature": 0.0, "avg_logprob": -0.1415090560913086, "compression_ratio": 1.5121951219512195, "no_speech_prob": 0.04741079360246658}, {"id": 162, "seek": 109832, "start": 1099.04, "end": 1105.52, "text": " They also conclude that there is two percent, there is approximately two percent difference in", "tokens": [50400, 814, 611, 16886, 300, 456, 307, 732, 3043, 11, 456, 307, 10447, 732, 3043, 2649, 294, 50724], "temperature": 0.0, "avg_logprob": -0.19406049391802618, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0017006187699735165}, {"id": 163, "seek": 109832, "start": 1105.52, "end": 1114.08, "text": " accuracy on TB4 and their fine-tuned version, which they say is outstandingly good. I personally,", "tokens": [50724, 14170, 322, 29711, 19, 293, 641, 2489, 12, 83, 43703, 3037, 11, 597, 436, 584, 307, 14485, 356, 665, 13, 286, 5665, 11, 51152], "temperature": 0.0, "avg_logprob": -0.19406049391802618, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0017006187699735165}, {"id": 164, "seek": 109832, "start": 1114.08, "end": 1120.8799999999999, "text": " I think it's interesting to use this approach. However, the results are not that shining for now.", "tokens": [51152, 286, 519, 309, 311, 1880, 281, 764, 341, 3109, 13, 2908, 11, 264, 3542, 366, 406, 300, 18269, 337, 586, 13, 51492], "temperature": 0.0, "avg_logprob": -0.19406049391802618, "compression_ratio": 1.5104166666666667, "no_speech_prob": 0.0017006187699735165}, {"id": 165, "seek": 112088, "start": 1121.8400000000001, "end": 1129.0400000000002, "text": " And so this is one other result there is. In the second paper they present,", "tokens": [50412, 400, 370, 341, 307, 472, 661, 1874, 456, 307, 13, 682, 264, 1150, 3035, 436, 1974, 11, 50772], "temperature": 0.0, "avg_logprob": -0.15562990733555385, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.003764917142689228}, {"id": 166, "seek": 112088, "start": 1131.1200000000001, "end": 1137.6000000000001, "text": " this is another causal task, which they call chord cause. So basically, the point of this", "tokens": [50876, 341, 307, 1071, 38755, 5633, 11, 597, 436, 818, 14137, 3082, 13, 407, 1936, 11, 264, 935, 295, 341, 51200], "temperature": 0.0, "avg_logprob": -0.15562990733555385, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.003764917142689228}, {"id": 167, "seek": 112088, "start": 1137.6000000000001, "end": 1144.88, "text": " is to escalate one correlation relationships to causation. So you know there is a correlation.", "tokens": [51200, 307, 281, 17871, 473, 472, 20009, 6159, 281, 3302, 399, 13, 407, 291, 458, 456, 307, 257, 20009, 13, 51564], "temperature": 0.0, "avg_logprob": -0.15562990733555385, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.003764917142689228}, {"id": 168, "seek": 112088, "start": 1144.88, "end": 1150.5600000000002, "text": " So let's say that causal discovery is almost done. You are sure there is a correlation,", "tokens": [51564, 407, 718, 311, 584, 300, 38755, 12114, 307, 1920, 1096, 13, 509, 366, 988, 456, 307, 257, 20009, 11, 51848], "temperature": 0.0, "avg_logprob": -0.15562990733555385, "compression_ratio": 1.7938144329896908, "no_speech_prob": 0.003764917142689228}, {"id": 169, "seek": 115056, "start": 1150.56, "end": 1155.76, "text": " a grounded one between two variables. And the point would be to determine whether it is cold or not.", "tokens": [50364, 257, 23535, 472, 1296, 732, 9102, 13, 400, 264, 935, 576, 312, 281, 6997, 1968, 309, 307, 3554, 420, 406, 13, 50624], "temperature": 0.0, "avg_logprob": -0.11603448360781127, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.0004877849423792213}, {"id": 170, "seek": 115056, "start": 1157.36, "end": 1167.6799999999998, "text": " And so this benchmark is run on 17 LLMs and also 12 fine-tuned LLMs, which is on the right side.", "tokens": [50704, 400, 370, 341, 18927, 307, 1190, 322, 3282, 441, 43, 26386, 293, 611, 2272, 2489, 12, 83, 43703, 441, 43, 26386, 11, 597, 307, 322, 264, 558, 1252, 13, 51220], "temperature": 0.0, "avg_logprob": -0.11603448360781127, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.0004877849423792213}, {"id": 171, "seek": 115056, "start": 1170.6399999999999, "end": 1177.6, "text": " So yeah, they give multiple metrics in there. Again, they say the results are not really incredible.", "tokens": [51368, 407, 1338, 11, 436, 976, 3866, 16367, 294, 456, 13, 3764, 11, 436, 584, 264, 3542, 366, 406, 534, 4651, 13, 51716], "temperature": 0.0, "avg_logprob": -0.11603448360781127, "compression_ratio": 1.4752475247524752, "no_speech_prob": 0.0004877849423792213}, {"id": 172, "seek": 117760, "start": 1177.6799999999998, "end": 1186.56, "text": " They don't really conclude on the results. In none of the papers, based on the results,", "tokens": [50368, 814, 500, 380, 534, 16886, 322, 264, 3542, 13, 682, 6022, 295, 264, 10577, 11, 2361, 322, 264, 3542, 11, 50812], "temperature": 0.0, "avg_logprob": -0.13419631883209826, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0009109388338401914}, {"id": 173, "seek": 117760, "start": 1186.56, "end": 1192.1599999999999, "text": " they are able to say yes, LLMs are able to do causality, no, LLMs are not able to do causality.", "tokens": [50812, 436, 366, 1075, 281, 584, 2086, 11, 441, 43, 26386, 366, 1075, 281, 360, 3302, 1860, 11, 572, 11, 441, 43, 26386, 366, 406, 1075, 281, 360, 3302, 1860, 13, 51092], "temperature": 0.0, "avg_logprob": -0.13419631883209826, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0009109388338401914}, {"id": 174, "seek": 117760, "start": 1192.1599999999999, "end": 1198.48, "text": " Every time it's always very measured and every paper ends the same way. It's at this point,", "tokens": [51092, 2048, 565, 309, 311, 1009, 588, 12690, 293, 633, 3035, 5314, 264, 912, 636, 13, 467, 311, 412, 341, 935, 11, 51408], "temperature": 0.0, "avg_logprob": -0.13419631883209826, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0009109388338401914}, {"id": 175, "seek": 117760, "start": 1198.48, "end": 1206.7199999999998, "text": " we're not able to refute the fact that LLMs can infer causality. So they have strong", "tokens": [51408, 321, 434, 406, 1075, 281, 1895, 1169, 264, 1186, 300, 441, 43, 26386, 393, 13596, 3302, 1860, 13, 407, 436, 362, 2068, 51820], "temperature": 0.0, "avg_logprob": -0.13419631883209826, "compression_ratio": 1.791044776119403, "no_speech_prob": 0.0009109388338401914}, {"id": 176, "seek": 120760, "start": 1208.48, "end": 1213.4399999999998, "text": " insights that they might or might not be able to, but they cannot come up with a conclusion in the", "tokens": [50408, 14310, 300, 436, 1062, 420, 1062, 406, 312, 1075, 281, 11, 457, 436, 2644, 808, 493, 365, 257, 10063, 294, 264, 50656], "temperature": 0.0, "avg_logprob": -0.12027157374790737, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0006983680068515241}, {"id": 177, "seek": 120760, "start": 1213.4399999999998, "end": 1222.1599999999999, "text": " end. Here, what is interesting to show is that in this particular case for escalating correlation", "tokens": [50656, 917, 13, 1692, 11, 437, 307, 1880, 281, 855, 307, 300, 294, 341, 1729, 1389, 337, 17871, 990, 20009, 51092], "temperature": 0.0, "avg_logprob": -0.12027157374790737, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0006983680068515241}, {"id": 178, "seek": 120760, "start": 1222.1599999999999, "end": 1227.84, "text": " to causation, there is a real impact in fine-tuning models. As we can see, the", "tokens": [51092, 281, 3302, 399, 11, 456, 307, 257, 957, 2712, 294, 2489, 12, 83, 37726, 5245, 13, 1018, 321, 393, 536, 11, 264, 51376], "temperature": 0.0, "avg_logprob": -0.12027157374790737, "compression_ratio": 1.5988372093023255, "no_speech_prob": 0.0006983680068515241}, {"id": 179, "seek": 122784, "start": 1228.8, "end": 1236.1599999999999, "text": " precision increases a lot between off-the-shelf models and fine-tuned models.", "tokens": [50412, 18356, 8637, 257, 688, 1296, 766, 12, 3322, 12, 46626, 5245, 293, 2489, 12, 83, 43703, 5245, 13, 50780], "temperature": 0.0, "avg_logprob": -0.2118382237174294, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.02367858961224556}, {"id": 180, "seek": 122784, "start": 1237.6799999999998, "end": 1244.3999999999999, "text": " So the takes of those two papers by Jin et al, which are separated for a two-month or", "tokens": [50856, 407, 264, 2516, 295, 729, 732, 10577, 538, 10617, 1030, 419, 11, 597, 366, 12005, 337, 257, 732, 12, 23534, 420, 51192], "temperature": 0.0, "avg_logprob": -0.2118382237174294, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.02367858961224556}, {"id": 181, "seek": 122784, "start": 1244.3999999999999, "end": 1250.8, "text": " three-month, if I remember correctly, and it's relatively linked. So the main overall take", "tokens": [51192, 1045, 12, 23534, 11, 498, 286, 1604, 8944, 11, 293, 309, 311, 7226, 9408, 13, 407, 264, 2135, 4787, 747, 51512], "temperature": 0.0, "avg_logprob": -0.2118382237174294, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.02367858961224556}, {"id": 182, "seek": 122784, "start": 1250.8, "end": 1257.4399999999998, "text": " on those two papers by Jin is that using causal benchmarks is really interesting to LLM training", "tokens": [51512, 322, 729, 732, 10577, 538, 10617, 307, 300, 1228, 38755, 43751, 307, 534, 1880, 281, 441, 43, 44, 3097, 51844], "temperature": 0.0, "avg_logprob": -0.2118382237174294, "compression_ratio": 1.588235294117647, "no_speech_prob": 0.02367858961224556}, {"id": 183, "seek": 125744, "start": 1257.44, "end": 1264.16, "text": " as it can really improve the training performance and it can actually induce some of causal causality", "tokens": [50364, 382, 309, 393, 534, 3470, 264, 3097, 3389, 293, 309, 393, 767, 41263, 512, 295, 38755, 3302, 1860, 50700], "temperature": 0.0, "avg_logprob": -0.19595617861361117, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.001343287411145866}, {"id": 184, "seek": 125744, "start": 1264.16, "end": 1270.72, "text": " at least on that particular dataset in the LLM. And also that fine-tuning is really helpful in this", "tokens": [50700, 412, 1935, 322, 300, 1729, 28872, 294, 264, 441, 43, 44, 13, 400, 611, 300, 2489, 12, 83, 37726, 307, 534, 4961, 294, 341, 51028], "temperature": 0.0, "avg_logprob": -0.19595617861361117, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.001343287411145866}, {"id": 185, "seek": 125744, "start": 1271.28, "end": 1281.44, "text": " scenario. Okay, so I'm good. Yeah, of course. In the previous slide, you mentioned that in the", "tokens": [51056, 9005, 13, 1033, 11, 370, 286, 478, 665, 13, 865, 11, 295, 1164, 13, 682, 264, 3894, 4137, 11, 291, 2835, 300, 294, 264, 51564], "temperature": 0.0, "avg_logprob": -0.19595617861361117, "compression_ratio": 1.5336787564766838, "no_speech_prob": 0.001343287411145866}, {"id": 186, "seek": 128144, "start": 1281.52, "end": 1294.88, "text": " previous one. In the previous one, sorry. I know it's there. They test for counterfactuals.", "tokens": [50368, 3894, 472, 13, 682, 264, 3894, 472, 11, 2597, 13, 286, 458, 309, 311, 456, 13, 814, 1500, 337, 5682, 44919, 901, 82, 13, 51036], "temperature": 0.0, "avg_logprob": -0.2503771521828391, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.01513868197798729}, {"id": 187, "seek": 128144, "start": 1296.0800000000002, "end": 1305.3600000000001, "text": " Oh, sorry. This one? Yes. Okay. They test for counterfactuals and interventionals, right? How", "tokens": [51096, 876, 11, 2597, 13, 639, 472, 30, 1079, 13, 1033, 13, 814, 1500, 337, 5682, 44919, 901, 82, 293, 13176, 1124, 11, 558, 30, 1012, 51560], "temperature": 0.0, "avg_logprob": -0.2503771521828391, "compression_ratio": 1.5163934426229508, "no_speech_prob": 0.01513868197798729}, {"id": 188, "seek": 130536, "start": 1305.36, "end": 1313.9199999999998, "text": " do they test for counterfactuals? I don't really know because they don't give any example. If I", "tokens": [50364, 360, 436, 1500, 337, 5682, 44919, 901, 82, 30, 286, 500, 380, 534, 458, 570, 436, 500, 380, 976, 604, 1365, 13, 759, 286, 50792], "temperature": 0.0, "avg_logprob": -0.10603331866329663, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.0015475533436983824}, {"id": 189, "seek": 130536, "start": 1313.9199999999998, "end": 1320.6399999999999, "text": " remember correctly in the papers, they don't give any example of any example. Well, they do give", "tokens": [50792, 1604, 8944, 294, 264, 10577, 11, 436, 500, 380, 976, 604, 1365, 295, 604, 1365, 13, 1042, 11, 436, 360, 976, 51128], "temperature": 0.0, "avg_logprob": -0.10603331866329663, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.0015475533436983824}, {"id": 190, "seek": 130536, "start": 1320.6399999999999, "end": 1330.08, "text": " example structures. They do give example structures of how their dataset is made, but they don't give", "tokens": [51128, 1365, 9227, 13, 814, 360, 976, 1365, 9227, 295, 577, 641, 28872, 307, 1027, 11, 457, 436, 500, 380, 976, 51600], "temperature": 0.0, "avg_logprob": -0.10603331866329663, "compression_ratio": 1.8846153846153846, "no_speech_prob": 0.0015475533436983824}, {"id": 191, "seek": 133008, "start": 1330.1599999999999, "end": 1336.32, "text": " like actual example that are fed to the models as questions and answer. So I'm not really able,", "tokens": [50368, 411, 3539, 1365, 300, 366, 4636, 281, 264, 5245, 382, 1651, 293, 1867, 13, 407, 286, 478, 406, 534, 1075, 11, 50676], "temperature": 0.0, "avg_logprob": -0.10904208194004016, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002934512449428439}, {"id": 192, "seek": 133008, "start": 1336.32, "end": 1343.52, "text": " let me just see real quick. No, because this is just the constitution of their dataset.", "tokens": [50676, 718, 385, 445, 536, 957, 1702, 13, 883, 11, 570, 341, 307, 445, 264, 11937, 295, 641, 28872, 13, 51036], "temperature": 0.0, "avg_logprob": -0.10904208194004016, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002934512449428439}, {"id": 193, "seek": 133008, "start": 1345.6, "end": 1351.4399999999998, "text": " They explain a bit how they do constitute their dataset. So they choose variables,", "tokens": [51140, 814, 2903, 257, 857, 577, 436, 360, 41658, 641, 28872, 13, 407, 436, 2826, 9102, 11, 51432], "temperature": 0.0, "avg_logprob": -0.10904208194004016, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002934512449428439}, {"id": 194, "seek": 133008, "start": 1351.4399999999998, "end": 1358.48, "text": " generate causal graphs, map them, etc. So the data is composed like this, but they don't actually give", "tokens": [51432, 8460, 38755, 24877, 11, 4471, 552, 11, 5183, 13, 407, 264, 1412, 307, 18204, 411, 341, 11, 457, 436, 500, 380, 767, 976, 51784], "temperature": 0.0, "avg_logprob": -0.10904208194004016, "compression_ratio": 1.6327433628318584, "no_speech_prob": 0.002934512449428439}, {"id": 195, "seek": 135848, "start": 1358.56, "end": 1365.84, "text": " examples to which their dataset. Maybe with the additional, in the additional", "tokens": [50368, 5110, 281, 597, 641, 28872, 13, 2704, 365, 264, 4497, 11, 294, 264, 4497, 50732], "temperature": 0.0, "avg_logprob": -0.2078311721999924, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0011869454756379128}, {"id": 196, "seek": 135848, "start": 1368.0, "end": 1373.84, "text": " supplementary information, probably they have something. In the supplementary information of", "tokens": [50840, 15436, 822, 1589, 11, 1391, 436, 362, 746, 13, 682, 264, 15436, 822, 1589, 295, 51132], "temperature": 0.0, "avg_logprob": -0.2078311721999924, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0011869454756379128}, {"id": 197, "seek": 135848, "start": 1373.84, "end": 1380.16, "text": " the paper or something, they may have something. Well, this is already from the supplementary.", "tokens": [51132, 264, 3035, 420, 746, 11, 436, 815, 362, 746, 13, 1042, 11, 341, 307, 1217, 490, 264, 15436, 822, 13, 51448], "temperature": 0.0, "avg_logprob": -0.2078311721999924, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0011869454756379128}, {"id": 198, "seek": 135848, "start": 1380.16, "end": 1384.48, "text": " Those two slides are from the supplementary information and I don't remember. I can take", "tokens": [51448, 3950, 732, 9788, 366, 490, 264, 15436, 822, 1589, 293, 286, 500, 380, 1604, 13, 286, 393, 747, 51664], "temperature": 0.0, "avg_logprob": -0.2078311721999924, "compression_ratio": 1.903225806451613, "no_speech_prob": 0.0011869454756379128}, {"id": 199, "seek": 138448, "start": 1384.48, "end": 1390.48, "text": " a look afterwards, but I don't remember seeing any example of what they actually feed. I have some", "tokens": [50364, 257, 574, 10543, 11, 457, 286, 500, 380, 1604, 2577, 604, 1365, 295, 437, 436, 767, 3154, 13, 286, 362, 512, 50664], "temperature": 0.0, "avg_logprob": -0.15713947259106684, "compression_ratio": 1.5267489711934157, "no_speech_prob": 0.002017696388065815}, {"id": 200, "seek": 138448, "start": 1390.48, "end": 1399.04, "text": " for other benchmarks, but not for this one. I see. Thank you, Antoine. And so yeah,", "tokens": [50664, 337, 661, 43751, 11, 457, 406, 337, 341, 472, 13, 286, 536, 13, 1044, 291, 11, 5130, 44454, 13, 400, 370, 1338, 11, 51092], "temperature": 0.0, "avg_logprob": -0.15713947259106684, "compression_ratio": 1.5267489711934157, "no_speech_prob": 0.002017696388065815}, {"id": 201, "seek": 138448, "start": 1400.08, "end": 1407.04, "text": " so I guess it's time to talk about this a little bit. This is a paper by Llewital 2019 and it's", "tokens": [51144, 370, 286, 2041, 309, 311, 565, 281, 751, 466, 341, 257, 707, 857, 13, 639, 307, 257, 3035, 538, 441, 306, 86, 1686, 6071, 293, 309, 311, 51492], "temperature": 0.0, "avg_logprob": -0.15713947259106684, "compression_ratio": 1.5267489711934157, "no_speech_prob": 0.002017696388065815}, {"id": 202, "seek": 138448, "start": 1407.04, "end": 1413.2, "text": " so it studies intelligent agent systems. I just want to say that it is, in my opinion, it is", "tokens": [51492, 370, 309, 5313, 13232, 9461, 3652, 13, 286, 445, 528, 281, 584, 300, 309, 307, 11, 294, 452, 4800, 11, 309, 307, 51800], "temperature": 0.0, "avg_logprob": -0.15713947259106684, "compression_ratio": 1.5267489711934157, "no_speech_prob": 0.002017696388065815}, {"id": 203, "seek": 141320, "start": 1413.2, "end": 1419.52, "text": " interesting in this context just because they focus on what is the importance of experience", "tokens": [50364, 1880, 294, 341, 4319, 445, 570, 436, 1879, 322, 437, 307, 264, 7379, 295, 1752, 50680], "temperature": 0.0, "avg_logprob": -0.10712288503777491, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.00563752232119441}, {"id": 204, "seek": 141320, "start": 1419.52, "end": 1425.44, "text": " on learning potential causality. They use a different approach, which is still interesting", "tokens": [50680, 322, 2539, 3995, 3302, 1860, 13, 814, 764, 257, 819, 3109, 11, 597, 307, 920, 1880, 50976], "temperature": 0.0, "avg_logprob": -0.10712288503777491, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.00563752232119441}, {"id": 205, "seek": 141320, "start": 1425.44, "end": 1431.8400000000001, "text": " because so here what they mean by intelligent agent systems or agent. They use the actual", "tokens": [50976, 570, 370, 510, 437, 436, 914, 538, 13232, 9461, 3652, 420, 9461, 13, 814, 764, 264, 3539, 51296], "temperature": 0.0, "avg_logprob": -0.10712288503777491, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.00563752232119441}, {"id": 206, "seek": 141320, "start": 1431.8400000000001, "end": 1437.44, "text": " similar definition of agent that is in the context of complex adaptive systems. So", "tokens": [51296, 2531, 7123, 295, 9461, 300, 307, 294, 264, 4319, 295, 3997, 27912, 3652, 13, 407, 51576], "temperature": 0.0, "avg_logprob": -0.10712288503777491, "compression_ratio": 1.6985645933014355, "no_speech_prob": 0.00563752232119441}, {"id": 207, "seek": 143744, "start": 1437.44, "end": 1443.44, "text": " where an agent would be defined by an entity that have sensors that is able to perceive the", "tokens": [50364, 689, 364, 9461, 576, 312, 7642, 538, 364, 13977, 300, 362, 14840, 300, 307, 1075, 281, 20281, 264, 50664], "temperature": 0.0, "avg_logprob": -0.09720339245266385, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.015175472013652325}, {"id": 208, "seek": 143744, "start": 1443.44, "end": 1450.24, "text": " outside world actuators that can interact with the world and also an internal model that is just", "tokens": [50664, 2380, 1002, 34964, 3391, 300, 393, 4648, 365, 264, 1002, 293, 611, 364, 6920, 2316, 300, 307, 445, 51004], "temperature": 0.0, "avg_logprob": -0.09720339245266385, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.015175472013652325}, {"id": 209, "seek": 143744, "start": 1451.52, "end": 1457.92, "text": " a logic for the agent to decide what it's going to do depending on the inputs it receives in the", "tokens": [51068, 257, 9952, 337, 264, 9461, 281, 4536, 437, 309, 311, 516, 281, 360, 5413, 322, 264, 15743, 309, 20717, 294, 264, 51388], "temperature": 0.0, "avg_logprob": -0.09720339245266385, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.015175472013652325}, {"id": 210, "seek": 143744, "start": 1457.92, "end": 1465.28, "text": " sensor and what it's going to do to the world. So this is how an agent is defined in the complex", "tokens": [51388, 10200, 293, 437, 309, 311, 516, 281, 360, 281, 264, 1002, 13, 407, 341, 307, 577, 364, 9461, 307, 7642, 294, 264, 3997, 51756], "temperature": 0.0, "avg_logprob": -0.09720339245266385, "compression_ratio": 1.8725490196078431, "no_speech_prob": 0.015175472013652325}, {"id": 211, "seek": 146528, "start": 1465.36, "end": 1472.08, "text": " adaptive systems. And the difference with the intelligent systems, intelligent agent from", "tokens": [50368, 27912, 3652, 13, 400, 264, 2649, 365, 264, 13232, 3652, 11, 13232, 9461, 490, 50704], "temperature": 0.0, "avg_logprob": -0.1389150117572985, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.004601188004016876}, {"id": 212, "seek": 146528, "start": 1472.08, "end": 1478.56, "text": " the URL is that they also give the ability to understand natural language to their agents.", "tokens": [50704, 264, 12905, 307, 300, 436, 611, 976, 264, 3485, 281, 1223, 3303, 2856, 281, 641, 12554, 13, 51028], "temperature": 0.0, "avg_logprob": -0.1389150117572985, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.004601188004016876}, {"id": 213, "seek": 146528, "start": 1481.28, "end": 1488.8799999999999, "text": " So what do they do with those agents? They trained the agents on multiple life classical scenarios", "tokens": [51164, 407, 437, 360, 436, 360, 365, 729, 12554, 30, 814, 8895, 264, 12554, 322, 3866, 993, 13735, 15077, 51544], "temperature": 0.0, "avg_logprob": -0.1389150117572985, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.004601188004016876}, {"id": 214, "seek": 148888, "start": 1489.7600000000002, "end": 1504.0, "text": " and then they use humans to create more training instances out of more scenarios", "tokens": [50408, 293, 550, 436, 764, 6255, 281, 1884, 544, 3097, 14519, 484, 295, 544, 15077, 51120], "temperature": 0.0, "avg_logprob": -0.08020597298940023, "compression_ratio": 1.7006369426751593, "no_speech_prob": 0.010323677211999893}, {"id": 215, "seek": 148888, "start": 1504.0, "end": 1509.92, "text": " and then they put those agents in those particular scenarios to see what they're able to do with it.", "tokens": [51120, 293, 550, 436, 829, 729, 12554, 294, 729, 1729, 15077, 281, 536, 437, 436, 434, 1075, 281, 360, 365, 309, 13, 51416], "temperature": 0.0, "avg_logprob": -0.08020597298940023, "compression_ratio": 1.7006369426751593, "no_speech_prob": 0.010323677211999893}, {"id": 216, "seek": 148888, "start": 1509.92, "end": 1516.3200000000002, "text": " So the agents have a bit of prior knowledge. Some more scenarios are created and then", "tokens": [51416, 407, 264, 12554, 362, 257, 857, 295, 4059, 3601, 13, 2188, 544, 15077, 366, 2942, 293, 550, 51736], "temperature": 0.0, "avg_logprob": -0.08020597298940023, "compression_ratio": 1.7006369426751593, "no_speech_prob": 0.010323677211999893}, {"id": 217, "seek": 151632, "start": 1516.3999999999999, "end": 1522.32, "text": " they use the agents. All the scenarios in this study are generated with a game in this fact.", "tokens": [50368, 436, 764, 264, 12554, 13, 1057, 264, 15077, 294, 341, 2979, 366, 10833, 365, 257, 1216, 294, 341, 1186, 13, 50664], "temperature": 0.0, "avg_logprob": -0.09290131755258846, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.011502623558044434}, {"id": 218, "seek": 151632, "start": 1523.6, "end": 1530.32, "text": " I'm just going to use this fact to add on the, I feel like some video games might present like", "tokens": [50728, 286, 478, 445, 516, 281, 764, 341, 1186, 281, 909, 322, 264, 11, 286, 841, 411, 512, 960, 2813, 1062, 1974, 411, 51064], "temperature": 0.0, "avg_logprob": -0.09290131755258846, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.011502623558044434}, {"id": 219, "seek": 151632, "start": 1530.32, "end": 1537.76, "text": " the perfect ground for testing and simulating this kind of behaviors. There is a lot and a lot", "tokens": [51064, 264, 2176, 2727, 337, 4997, 293, 1034, 12162, 341, 733, 295, 15501, 13, 821, 307, 257, 688, 293, 257, 688, 51436], "temperature": 0.0, "avg_logprob": -0.09290131755258846, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.011502623558044434}, {"id": 220, "seek": 151632, "start": 1537.76, "end": 1543.4399999999998, "text": " of different examples of people doing reinforcement learning on video games, learning AI strategies", "tokens": [51436, 295, 819, 5110, 295, 561, 884, 29280, 2539, 322, 960, 2813, 11, 2539, 7318, 9029, 51720], "temperature": 0.0, "avg_logprob": -0.09290131755258846, "compression_ratio": 1.668122270742358, "no_speech_prob": 0.011502623558044434}, {"id": 221, "seek": 154344, "start": 1543.52, "end": 1550.3200000000002, "text": " to drive a car for racing lines, this stuff. So I just wanted to make a small side note on", "tokens": [50368, 281, 3332, 257, 1032, 337, 12553, 3876, 11, 341, 1507, 13, 407, 286, 445, 1415, 281, 652, 257, 1359, 1252, 3637, 322, 50708], "temperature": 0.0, "avg_logprob": -0.1375548243522644, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.020322002470493317}, {"id": 222, "seek": 154344, "start": 1550.3200000000002, "end": 1554.96, "text": " the fact that video games represent a good training example. So in this case, this game is", "tokens": [50708, 264, 1186, 300, 960, 2813, 2906, 257, 665, 3097, 1365, 13, 407, 294, 341, 1389, 11, 341, 1216, 307, 50940], "temperature": 0.0, "avg_logprob": -0.1375548243522644, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.020322002470493317}, {"id": 223, "seek": 154344, "start": 1554.96, "end": 1560.3200000000002, "text": " Minecraft. It's a game where you interact with the world. And so what they do, they put the agents", "tokens": [50940, 21029, 13, 467, 311, 257, 1216, 689, 291, 4648, 365, 264, 1002, 13, 400, 370, 437, 436, 360, 11, 436, 829, 264, 12554, 51208], "temperature": 0.0, "avg_logprob": -0.1375548243522644, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.020322002470493317}, {"id": 224, "seek": 154344, "start": 1560.3200000000002, "end": 1567.6000000000001, "text": " in Minecraft and they generate a bunch of scenarios, which is like one, I attack the co and I attack", "tokens": [51208, 294, 21029, 293, 436, 8460, 257, 3840, 295, 15077, 11, 597, 307, 411, 472, 11, 286, 2690, 264, 598, 293, 286, 2690, 51572], "temperature": 0.0, "avg_logprob": -0.1375548243522644, "compression_ratio": 1.6075949367088607, "no_speech_prob": 0.020322002470493317}, {"id": 225, "seek": 156760, "start": 1567.6, "end": 1573.12, "text": " the co. And this is the two outcomes. And for those two outcomes, the agent is going to infer", "tokens": [50364, 264, 598, 13, 400, 341, 307, 264, 732, 10070, 13, 400, 337, 729, 732, 10070, 11, 264, 9461, 307, 516, 281, 13596, 50640], "temperature": 0.0, "avg_logprob": -0.08222257523309617, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.027995498850941658}, {"id": 226, "seek": 156760, "start": 1573.12, "end": 1579.1999999999998, "text": " causal or not causal. So based on their prior knowledge and more scenarios created by players", "tokens": [50640, 38755, 420, 406, 38755, 13, 407, 2361, 322, 641, 4059, 3601, 293, 544, 15077, 2942, 538, 4150, 50944], "temperature": 0.0, "avg_logprob": -0.08222257523309617, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.027995498850941658}, {"id": 227, "seek": 156760, "start": 1579.1999999999998, "end": 1586.1599999999999, "text": " and then are collected, then the agents are evaluated on whether they experience in learning", "tokens": [50944, 293, 550, 366, 11087, 11, 550, 264, 12554, 366, 25509, 322, 1968, 436, 1752, 294, 2539, 51292], "temperature": 0.0, "avg_logprob": -0.08222257523309617, "compression_ratio": 1.5909090909090908, "no_speech_prob": 0.027995498850941658}, {"id": 228, "seek": 158616, "start": 1586.16, "end": 1593.76, "text": " from those scenarios, made them able to infer causality in new, newly presented scenarios.", "tokens": [50364, 490, 729, 15077, 11, 1027, 552, 1075, 281, 13596, 3302, 1860, 294, 777, 11, 15109, 8212, 15077, 13, 50744], "temperature": 0.0, "avg_logprob": -0.13937871686873898, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.0758226290345192}, {"id": 229, "seek": 158616, "start": 1596.88, "end": 1602.88, "text": " They gave a bit of the architecture they use to structure their model and their inference.", "tokens": [50900, 814, 2729, 257, 857, 295, 264, 9482, 436, 764, 281, 3877, 641, 2316, 293, 641, 38253, 13, 51200], "temperature": 0.0, "avg_logprob": -0.13937871686873898, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.0758226290345192}, {"id": 230, "seek": 158616, "start": 1603.68, "end": 1612.48, "text": " So the shared experience is represented by, I guess, the pool of knowledge that all the agents", "tokens": [51240, 407, 264, 5507, 1752, 307, 10379, 538, 11, 286, 2041, 11, 264, 7005, 295, 3601, 300, 439, 264, 12554, 51680], "temperature": 0.0, "avg_logprob": -0.13937871686873898, "compression_ratio": 1.5771428571428572, "no_speech_prob": 0.0758226290345192}, {"id": 231, "seek": 161248, "start": 1612.48, "end": 1618.32, "text": " learn all together. Those are events triggered. When you attack a cow, you get some beef.", "tokens": [50364, 1466, 439, 1214, 13, 3950, 366, 3931, 21710, 13, 1133, 291, 2690, 257, 8408, 11, 291, 483, 512, 9256, 13, 50656], "temperature": 0.0, "avg_logprob": -0.12671447883952747, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.008709074929356575}, {"id": 232, "seek": 161248, "start": 1621.44, "end": 1627.2, "text": " They don't give a lot of details, whereas all this works, if I remember correctly,", "tokens": [50812, 814, 500, 380, 976, 257, 688, 295, 4365, 11, 9735, 439, 341, 1985, 11, 498, 286, 1604, 8944, 11, 51100], "temperature": 0.0, "avg_logprob": -0.12671447883952747, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.008709074929356575}, {"id": 233, "seek": 161248, "start": 1627.2, "end": 1633.04, "text": " but in the end, they just come up with a causal question, which the agents do inference on.", "tokens": [51100, 457, 294, 264, 917, 11, 436, 445, 808, 493, 365, 257, 38755, 1168, 11, 597, 264, 12554, 360, 38253, 322, 13, 51392], "temperature": 0.0, "avg_logprob": -0.12671447883952747, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.008709074929356575}, {"id": 234, "seek": 161248, "start": 1634.0, "end": 1640.32, "text": " And they're able then to classify what are considered as causal or not. And then they", "tokens": [51440, 400, 436, 434, 1075, 550, 281, 33872, 437, 366, 4888, 382, 38755, 420, 406, 13, 400, 550, 436, 51756], "temperature": 0.0, "avg_logprob": -0.12671447883952747, "compression_ratio": 1.5418502202643172, "no_speech_prob": 0.008709074929356575}, {"id": 235, "seek": 164032, "start": 1640.32, "end": 1649.36, "text": " just compare with the example they had in first. So the principle of finding they give from this", "tokens": [50364, 445, 6794, 365, 264, 1365, 436, 632, 294, 700, 13, 407, 264, 8665, 295, 5006, 436, 976, 490, 341, 50816], "temperature": 0.0, "avg_logprob": -0.13845292348710317, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0005791549338027835}, {"id": 236, "seek": 164032, "start": 1649.36, "end": 1655.2, "text": " study is that experience mechanism is key for language concepts, understanding and learning,", "tokens": [50816, 2979, 307, 300, 1752, 7513, 307, 2141, 337, 2856, 10392, 11, 3701, 293, 2539, 11, 51108], "temperature": 0.0, "avg_logprob": -0.13845292348710317, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0005791549338027835}, {"id": 237, "seek": 164032, "start": 1655.2, "end": 1662.3999999999999, "text": " which is a very long turn of phrase for causality. So it is interesting. This paper is interesting", "tokens": [51108, 597, 307, 257, 588, 938, 1261, 295, 9535, 337, 3302, 1860, 13, 407, 309, 307, 1880, 13, 639, 3035, 307, 1880, 51468], "temperature": 0.0, "avg_logprob": -0.13845292348710317, "compression_ratio": 1.5737704918032787, "no_speech_prob": 0.0005791549338027835}, {"id": 238, "seek": 166240, "start": 1662.48, "end": 1674.48, "text": " in this way, because LLMs can be seen as agents in that they are trained and they learn out of", "tokens": [50368, 294, 341, 636, 11, 570, 441, 43, 26386, 393, 312, 1612, 382, 12554, 294, 300, 436, 366, 8895, 293, 436, 1466, 484, 295, 50968], "temperature": 0.0, "avg_logprob": -0.12058985364306105, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.07473941892385483}, {"id": 239, "seek": 166240, "start": 1674.48, "end": 1679.76, "text": " huge text corpuses that represent, I don't know, novels, articles, blog posts, Wikipedia.", "tokens": [50968, 2603, 2487, 1181, 79, 8355, 300, 2906, 11, 286, 500, 380, 458, 11, 24574, 11, 11290, 11, 6968, 12300, 11, 28999, 13, 51232], "temperature": 0.0, "avg_logprob": -0.12058985364306105, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.07473941892385483}, {"id": 240, "seek": 166240, "start": 1681.1200000000001, "end": 1685.1200000000001, "text": " Those can be seen as scenarios where the LLM will learn some knowledge.", "tokens": [51300, 3950, 393, 312, 1612, 382, 15077, 689, 264, 441, 43, 44, 486, 1466, 512, 3601, 13, 51500], "temperature": 0.0, "avg_logprob": -0.12058985364306105, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.07473941892385483}, {"id": 241, "seek": 166240, "start": 1686.24, "end": 1690.64, "text": " At the end, you can interact with an LLM as you can interact with those agents.", "tokens": [51556, 1711, 264, 917, 11, 291, 393, 4648, 365, 364, 441, 43, 44, 382, 291, 393, 4648, 365, 729, 12554, 13, 51776], "temperature": 0.0, "avg_logprob": -0.12058985364306105, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.07473941892385483}, {"id": 242, "seek": 169064, "start": 1691.2800000000002, "end": 1698.0, "text": " Their inputs are the sensors and the text feedback they will give is the actuator.", "tokens": [50396, 6710, 15743, 366, 264, 14840, 293, 264, 2487, 5824, 436, 486, 976, 307, 264, 34964, 1639, 13, 50732], "temperature": 0.0, "avg_logprob": -0.08830836446661698, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.0010003703646361828}, {"id": 243, "seek": 169064, "start": 1698.0, "end": 1704.24, "text": " You can use an NNM as a robot if you ask, do some actions or something. So what's interesting is that", "tokens": [50732, 509, 393, 764, 364, 426, 45, 44, 382, 257, 7881, 498, 291, 1029, 11, 360, 512, 5909, 420, 746, 13, 407, 437, 311, 1880, 307, 300, 51044], "temperature": 0.0, "avg_logprob": -0.08830836446661698, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.0010003703646361828}, {"id": 244, "seek": 169064, "start": 1704.24, "end": 1712.48, "text": " if we put in parallel LLMs and the agents as described in this paper, well, basically what", "tokens": [51044, 498, 321, 829, 294, 8952, 441, 43, 26386, 293, 264, 12554, 382, 7619, 294, 341, 3035, 11, 731, 11, 1936, 437, 51456], "temperature": 0.0, "avg_logprob": -0.08830836446661698, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.0010003703646361828}, {"id": 245, "seek": 169064, "start": 1712.48, "end": 1718.48, "text": " they say is that experience is key for causality. So they would be, from my understanding of that", "tokens": [51456, 436, 584, 307, 300, 1752, 307, 2141, 337, 3302, 1860, 13, 407, 436, 576, 312, 11, 490, 452, 3701, 295, 300, 51756], "temperature": 0.0, "avg_logprob": -0.08830836446661698, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.0010003703646361828}, {"id": 246, "seek": 171848, "start": 1718.48, "end": 1726.48, "text": " paper, what I get of that paper would be that more data, more training could eventually lead", "tokens": [50364, 3035, 11, 437, 286, 483, 295, 300, 3035, 576, 312, 300, 544, 1412, 11, 544, 3097, 727, 4728, 1477, 50764], "temperature": 0.0, "avg_logprob": -0.07055343281139027, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.001000309712253511}, {"id": 247, "seek": 171848, "start": 1726.48, "end": 1734.16, "text": " to causality, which is opposed to the thoughts that are given in different papers in this selection.", "tokens": [50764, 281, 3302, 1860, 11, 597, 307, 8851, 281, 264, 4598, 300, 366, 2212, 294, 819, 10577, 294, 341, 9450, 13, 51148], "temperature": 0.0, "avg_logprob": -0.07055343281139027, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.001000309712253511}, {"id": 248, "seek": 171848, "start": 1735.52, "end": 1738.96, "text": " I still think this one is interesting. It's a different approach.", "tokens": [51216, 286, 920, 519, 341, 472, 307, 1880, 13, 467, 311, 257, 819, 3109, 13, 51388], "temperature": 0.0, "avg_logprob": -0.07055343281139027, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.001000309712253511}, {"id": 249, "seek": 171848, "start": 1741.28, "end": 1747.3600000000001, "text": " I think it's similar to what LLMs do today. Maybe some will argue that it's not, but I found", "tokens": [51504, 286, 519, 309, 311, 2531, 281, 437, 441, 43, 26386, 360, 965, 13, 2704, 512, 486, 9695, 300, 309, 311, 406, 11, 457, 286, 1352, 51808], "temperature": 0.0, "avg_logprob": -0.07055343281139027, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.001000309712253511}, {"id": 250, "seek": 174736, "start": 1747.36, "end": 1753.1999999999998, "text": " this interesting. And I guess now it's time to dig deep in the biggest paper in the corpus,", "tokens": [50364, 341, 1880, 13, 400, 286, 2041, 586, 309, 311, 565, 281, 2528, 2452, 294, 264, 3880, 3035, 294, 264, 1181, 31624, 11, 50656], "temperature": 0.0, "avg_logprob": -0.13065173778128117, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0009544825879856944}, {"id": 251, "seek": 174736, "start": 1753.1999999999998, "end": 1760.08, "text": " I think, which is ZetaVis. So it's the one when I said they make strong assumptions,", "tokens": [50656, 286, 519, 11, 597, 307, 1176, 7664, 53, 271, 13, 407, 309, 311, 264, 472, 562, 286, 848, 436, 652, 2068, 17695, 11, 51000], "temperature": 0.0, "avg_logprob": -0.13065173778128117, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0009544825879856944}, {"id": 252, "seek": 174736, "start": 1761.28, "end": 1767.9199999999998, "text": " strong claims that LLMs cannot do causality and never could. And the two main potential", "tokens": [51060, 2068, 9441, 300, 441, 43, 26386, 2644, 360, 3302, 1860, 293, 1128, 727, 13, 400, 264, 732, 2135, 3995, 51392], "temperature": 0.0, "avg_logprob": -0.13065173778128117, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0009544825879856944}, {"id": 253, "seek": 174736, "start": 1767.9199999999998, "end": 1775.12, "text": " reasons they give is that the errors that are contained in the corpus used to train LLMs", "tokens": [51392, 4112, 436, 976, 307, 300, 264, 13603, 300, 366, 16212, 294, 264, 1181, 31624, 1143, 281, 3847, 441, 43, 26386, 51752], "temperature": 0.0, "avg_logprob": -0.13065173778128117, "compression_ratio": 1.6045454545454545, "no_speech_prob": 0.0009544825879856944}, {"id": 254, "seek": 177512, "start": 1775.12, "end": 1782.2399999999998, "text": " really hamper the outputs and hamper the knowledge base. So it would be like,", "tokens": [50364, 534, 7852, 610, 264, 23930, 293, 7852, 610, 264, 3601, 3096, 13, 407, 309, 576, 312, 411, 11, 50720], "temperature": 0.0, "avg_logprob": -0.08046135695084282, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.0002453475317452103}, {"id": 255, "seek": 177512, "start": 1782.2399999999998, "end": 1786.8, "text": " it would be like putting poison in the brain. Eventually, it's not going to be able to function", "tokens": [50720, 309, 576, 312, 411, 3372, 10836, 294, 264, 3567, 13, 17586, 11, 309, 311, 406, 516, 281, 312, 1075, 281, 2445, 50948], "temperature": 0.0, "avg_logprob": -0.08046135695084282, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.0002453475317452103}, {"id": 256, "seek": 177512, "start": 1786.8, "end": 1793.6799999999998, "text": " correctly. So what they say is that errors in the input data is going to be propagating to more", "tokens": [50948, 8944, 13, 407, 437, 436, 584, 307, 300, 13603, 294, 264, 4846, 1412, 307, 516, 281, 312, 12425, 990, 281, 544, 51292], "temperature": 0.0, "avg_logprob": -0.08046135695084282, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.0002453475317452103}, {"id": 257, "seek": 177512, "start": 1793.6799999999998, "end": 1798.9599999999998, "text": " errors in the output. So this is the first reason. And the second reason they give is the lack of", "tokens": [51292, 13603, 294, 264, 5598, 13, 407, 341, 307, 264, 700, 1778, 13, 400, 264, 1150, 1778, 436, 976, 307, 264, 5011, 295, 51556], "temperature": 0.0, "avg_logprob": -0.08046135695084282, "compression_ratio": 1.755980861244019, "no_speech_prob": 0.0002453475317452103}, {"id": 258, "seek": 179896, "start": 1798.96, "end": 1806.16, "text": " physical data in training data set. They say that the whole difference between correlation", "tokens": [50364, 4001, 1412, 294, 3097, 1412, 992, 13, 814, 584, 300, 264, 1379, 2649, 1296, 20009, 50724], "temperature": 0.0, "avg_logprob": -0.1439166891163793, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.029297158122062683}, {"id": 259, "seek": 179896, "start": 1806.16, "end": 1812.16, "text": " causation is the physical evidence and the physical grounding of those facts. And they say that because", "tokens": [50724, 3302, 399, 307, 264, 4001, 4467, 293, 264, 4001, 46727, 295, 729, 9130, 13, 400, 436, 584, 300, 570, 51024], "temperature": 0.0, "avg_logprob": -0.1439166891163793, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.029297158122062683}, {"id": 260, "seek": 179896, "start": 1812.16, "end": 1818.72, "text": " LLMs are not trained with physical evidence, physical data, et cetera, well, they inherently", "tokens": [51024, 441, 43, 26386, 366, 406, 8895, 365, 4001, 4467, 11, 4001, 1412, 11, 1030, 11458, 11, 731, 11, 436, 27993, 51352], "temperature": 0.0, "avg_logprob": -0.1439166891163793, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.029297158122062683}, {"id": 261, "seek": 179896, "start": 1818.72, "end": 1827.3600000000001, "text": " haven't, they're unable to ground the facts they claim. To quote, they say prohibits any sort of", "tokens": [51352, 2378, 380, 11, 436, 434, 11299, 281, 2727, 264, 9130, 436, 3932, 13, 1407, 6513, 11, 436, 584, 16015, 1208, 604, 1333, 295, 51784], "temperature": 0.0, "avg_logprob": -0.1439166891163793, "compression_ratio": 1.786046511627907, "no_speech_prob": 0.029297158122062683}, {"id": 262, "seek": 182736, "start": 1827.4399999999998, "end": 1835.84, "text": " induction of the actual data generating mechanism. So this is the two main reasons they give.", "tokens": [50368, 33371, 295, 264, 3539, 1412, 17746, 7513, 13, 407, 341, 307, 264, 732, 2135, 4112, 436, 976, 13, 50788], "temperature": 0.0, "avg_logprob": -0.07927565739072602, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.00039200729224830866}, {"id": 263, "seek": 182736, "start": 1836.8, "end": 1844.7199999999998, "text": " And on top of that, they provide with mathematical explanation of why that stands.", "tokens": [50836, 400, 322, 1192, 295, 300, 11, 436, 2893, 365, 18894, 10835, 295, 983, 300, 7382, 13, 51232], "temperature": 0.0, "avg_logprob": -0.07927565739072602, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.00039200729224830866}, {"id": 264, "seek": 182736, "start": 1845.52, "end": 1851.36, "text": " So the main contribution in that paper is that they define a subgroup of structural", "tokens": [51272, 407, 264, 2135, 13150, 294, 300, 3035, 307, 300, 436, 6964, 257, 1422, 17377, 295, 15067, 51564], "temperature": 0.0, "avg_logprob": -0.07927565739072602, "compression_ratio": 1.5757575757575757, "no_speech_prob": 0.00039200729224830866}, {"id": 265, "seek": 185136, "start": 1851.4399999999998, "end": 1861.76, "text": " causal models named media SEM. So the structural causal model, it is, I've did my research on", "tokens": [50368, 38755, 5245, 4926, 3021, 318, 6683, 13, 407, 264, 15067, 38755, 2316, 11, 309, 307, 11, 286, 600, 630, 452, 2132, 322, 50884], "temperature": 0.0, "avg_logprob": -0.15710887676332055, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.03407255560159683}, {"id": 266, "seek": 185136, "start": 1861.76, "end": 1867.1999999999998, "text": " this, it is a bit unclear to me as if it's really defined by bongers of it, or if it was.", "tokens": [50884, 341, 11, 309, 307, 257, 857, 25636, 281, 385, 382, 498, 309, 311, 534, 7642, 538, 272, 556, 433, 295, 309, 11, 420, 498, 309, 390, 13, 51156], "temperature": 0.0, "avg_logprob": -0.15710887676332055, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.03407255560159683}, {"id": 267, "seek": 185136, "start": 1867.1999999999998, "end": 1874.3999999999999, "text": " Because I feel like a lot of, a lot of parts in this are shared with the Perlian theory of causality", "tokens": [51156, 1436, 286, 841, 411, 257, 688, 295, 11, 257, 688, 295, 3166, 294, 341, 366, 5507, 365, 264, 3026, 75, 952, 5261, 295, 3302, 1860, 51516], "temperature": 0.0, "avg_logprob": -0.15710887676332055, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.03407255560159683}, {"id": 268, "seek": 187440, "start": 1874.4, "end": 1883.3600000000001, "text": " and more work on it. But if I quote the SEM was first defined by bongers at all in 2021,", "tokens": [50364, 293, 544, 589, 322, 309, 13, 583, 498, 286, 6513, 264, 318, 6683, 390, 700, 7642, 538, 272, 556, 433, 412, 439, 294, 7201, 11, 50812], "temperature": 0.0, "avg_logprob": -0.167741644872378, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.014717448502779007}, {"id": 269, "seek": 187440, "start": 1883.3600000000001, "end": 1890.88, "text": " and this is the, this is the definition they give. So SEM is a tuple that contains all this.", "tokens": [50812, 293, 341, 307, 264, 11, 341, 307, 264, 7123, 436, 976, 13, 407, 318, 6683, 307, 257, 2604, 781, 300, 8306, 439, 341, 13, 51188], "temperature": 0.0, "avg_logprob": -0.167741644872378, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.014717448502779007}, {"id": 270, "seek": 187440, "start": 1893.1200000000001, "end": 1898.8000000000002, "text": " In short, if I try to simplify the definition of this, an SEM", "tokens": [51300, 682, 2099, 11, 498, 286, 853, 281, 20460, 264, 7123, 295, 341, 11, 364, 318, 6683, 51584], "temperature": 0.0, "avg_logprob": -0.167741644872378, "compression_ratio": 1.4817073170731707, "no_speech_prob": 0.014717448502779007}, {"id": 271, "seek": 189880, "start": 1899.68, "end": 1908.6399999999999, "text": " contains a series of structural equations in the Perlian sense.", "tokens": [50408, 8306, 257, 2638, 295, 15067, 11787, 294, 264, 3026, 75, 952, 2020, 13, 50856], "temperature": 0.0, "avg_logprob": -0.1951939037867955, "compression_ratio": 1.2764227642276422, "no_speech_prob": 0.002550323959439993}, {"id": 272, "seek": 189880, "start": 1912.08, "end": 1917.04, "text": " Well, that's, that's pretty much it actually. There are some details on the variable. I don't", "tokens": [51028, 1042, 11, 300, 311, 11, 300, 311, 1238, 709, 309, 767, 13, 821, 366, 512, 4365, 322, 264, 7006, 13, 286, 500, 380, 51276], "temperature": 0.0, "avg_logprob": -0.1951939037867955, "compression_ratio": 1.2764227642276422, "no_speech_prob": 0.002550323959439993}, {"id": 273, "seek": 191704, "start": 1917.12, "end": 1930.6399999999999, "text": " understand all the, all the subtleties to this definition. Yeah. Maybe we can get back to that", "tokens": [50368, 1223, 439, 264, 11, 439, 264, 7257, 2631, 530, 281, 341, 7123, 13, 865, 13, 2704, 321, 393, 483, 646, 281, 300, 51044], "temperature": 0.0, "avg_logprob": -0.12557060822196628, "compression_ratio": 1.3923076923076922, "no_speech_prob": 0.004467126447707415}, {"id": 274, "seek": 191704, "start": 1930.6399999999999, "end": 1943.04, "text": " later. Okay, they also remind a couple of definitions and insights. So they remind the", "tokens": [51044, 1780, 13, 1033, 11, 436, 611, 4160, 257, 1916, 295, 21988, 293, 14310, 13, 407, 436, 4160, 264, 51664], "temperature": 0.0, "avg_logprob": -0.12557060822196628, "compression_ratio": 1.3923076923076922, "no_speech_prob": 0.004467126447707415}, {"id": 275, "seek": 194304, "start": 1943.12, "end": 1948.8799999999999, "text": " Perl's causal hierarchy, which consists on three languages that can respectively", "tokens": [50368, 3026, 75, 311, 38755, 22333, 11, 597, 14689, 322, 1045, 8650, 300, 393, 25009, 50656], "temperature": 0.0, "avg_logprob": -0.14395789873032344, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.00439829844981432}, {"id": 276, "seek": 194304, "start": 1949.92, "end": 1954.56, "text": " do observational causality, inter-reventional causality, and counterfactual causality.", "tokens": [50708, 360, 9951, 1478, 3302, 1860, 11, 728, 12, 265, 46105, 3302, 1860, 11, 293, 5682, 44919, 901, 3302, 1860, 13, 50940], "temperature": 0.0, "avg_logprob": -0.14395789873032344, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.00439829844981432}, {"id": 277, "seek": 194304, "start": 1955.44, "end": 1962.8, "text": " And then they give their insight, their first thought on it. M be some SEM. So M,", "tokens": [50984, 400, 550, 436, 976, 641, 11269, 11, 641, 700, 1194, 322, 309, 13, 376, 312, 512, 318, 6683, 13, 407, 376, 11, 51352], "temperature": 0.0, "avg_logprob": -0.14395789873032344, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.00439829844981432}, {"id": 278, "seek": 194304, "start": 1962.8, "end": 1971.12, "text": " so SEM is a set of structural equations in that context. Knowledge about the structural equations", "tokens": [51352, 370, 318, 6683, 307, 257, 992, 295, 15067, 11787, 294, 300, 4319, 13, 32906, 466, 264, 15067, 11787, 51768], "temperature": 0.0, "avg_logprob": -0.14395789873032344, "compression_ratio": 1.6367924528301887, "no_speech_prob": 0.00439829844981432}, {"id": 279, "seek": 197112, "start": 1971.12, "end": 1978.2399999999998, "text": " and the causal graph of M is knowledge about answering L3 and L2 queries in M respectively.", "tokens": [50364, 293, 264, 38755, 4295, 295, 376, 307, 3601, 466, 13430, 441, 18, 293, 441, 17, 24109, 294, 376, 25009, 13, 50720], "temperature": 0.0, "avg_logprob": -0.07083175462834976, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0020188360940665007}, {"id": 280, "seek": 197112, "start": 1978.8799999999999, "end": 1989.36, "text": " So their insight is that if M is an SEM, knowing about the structural equations in that SEM", "tokens": [50752, 407, 641, 11269, 307, 300, 498, 376, 307, 364, 318, 6683, 11, 5276, 466, 264, 15067, 11787, 294, 300, 318, 6683, 51276], "temperature": 0.0, "avg_logprob": -0.07083175462834976, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0020188360940665007}, {"id": 281, "seek": 197112, "start": 1989.36, "end": 1995.52, "text": " and the causal graph is enough to perform inter-reventional and counterfactual causality.", "tokens": [51276, 293, 264, 38755, 4295, 307, 1547, 281, 2042, 728, 12, 265, 46105, 293, 5682, 44919, 901, 3302, 1860, 13, 51584], "temperature": 0.0, "avg_logprob": -0.07083175462834976, "compression_ratio": 1.5423728813559323, "no_speech_prob": 0.0020188360940665007}, {"id": 282, "seek": 199552, "start": 1995.76, "end": 2002.6399999999999, "text": " And this is what they use to introduce their concept of a meta SEM, which is another SEM", "tokens": [50376, 400, 341, 307, 437, 436, 764, 281, 5366, 641, 3410, 295, 257, 19616, 318, 6683, 11, 597, 307, 1071, 318, 6683, 50720], "temperature": 0.0, "avg_logprob": -0.1832942569378725, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.002182540250942111}, {"id": 283, "seek": 199552, "start": 2002.6399999999999, "end": 2009.92, "text": " that is able to do inter-reventional and counterfactual just based on those information. So this is", "tokens": [50720, 300, 307, 1075, 281, 360, 728, 12, 265, 46105, 293, 5682, 44919, 901, 445, 2361, 322, 729, 1589, 13, 407, 341, 307, 51084], "temperature": 0.0, "avg_logprob": -0.1832942569378725, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.002182540250942111}, {"id": 284, "seek": 199552, "start": 2009.92, "end": 2015.28, "text": " literally the definition they give for the media SEM. And then they will spell the rest of the paper", "tokens": [51084, 3736, 264, 7123, 436, 976, 337, 264, 3021, 318, 6683, 13, 400, 550, 436, 486, 9827, 264, 1472, 295, 264, 3035, 51352], "temperature": 0.0, "avg_logprob": -0.1832942569378725, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.002182540250942111}, {"id": 285, "seek": 199552, "start": 2015.28, "end": 2021.44, "text": " trying to show that LLMs can be assimilated to media SEMs, which they cannot achieve actually.", "tokens": [51352, 1382, 281, 855, 300, 441, 43, 26386, 393, 312, 8249, 45678, 281, 3021, 318, 6683, 82, 11, 597, 436, 2644, 4584, 767, 13, 51660], "temperature": 0.0, "avg_logprob": -0.1832942569378725, "compression_ratio": 1.648068669527897, "no_speech_prob": 0.002182540250942111}, {"id": 286, "seek": 202144, "start": 2021.52, "end": 2034.0800000000002, "text": " But I feel like just outlining those particular properties and giving the insights and everything", "tokens": [50368, 583, 286, 841, 411, 445, 484, 31079, 729, 1729, 7221, 293, 2902, 264, 14310, 293, 1203, 50996], "temperature": 0.0, "avg_logprob": -0.1120278329560251, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0012249177088961005}, {"id": 287, "seek": 202144, "start": 2034.0800000000002, "end": 2039.52, "text": " is still a great contribution to the question in the sense that it's a first exploration of a real", "tokens": [50996, 307, 920, 257, 869, 13150, 281, 264, 1168, 294, 264, 2020, 300, 309, 311, 257, 700, 16197, 295, 257, 957, 51268], "temperature": 0.0, "avg_logprob": -0.1120278329560251, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0012249177088961005}, {"id": 288, "seek": 202144, "start": 2042.0, "end": 2049.2000000000003, "text": " formal process in order to be able to determine whether LLMs are able to do causality or not.", "tokens": [51392, 9860, 1399, 294, 1668, 281, 312, 1075, 281, 6997, 1968, 441, 43, 26386, 366, 1075, 281, 360, 3302, 1860, 420, 406, 13, 51752], "temperature": 0.0, "avg_logprob": -0.1120278329560251, "compression_ratio": 1.5343915343915344, "no_speech_prob": 0.0012249177088961005}, {"id": 289, "seek": 204920, "start": 2050.16, "end": 2052.16, "text": " So they, yeah, Ocean.", "tokens": [50412, 407, 436, 11, 1338, 11, 18101, 13, 50512], "temperature": 0.0, "avg_logprob": -0.2446581825377449, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.0012630659621208906}, {"id": 290, "seek": 204920, "start": 2055.7599999999998, "end": 2056.7999999999997, "text": " Oh, I can hear you.", "tokens": [50692, 876, 11, 286, 393, 1568, 291, 13, 50744], "temperature": 0.0, "avg_logprob": -0.2446581825377449, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.0012630659621208906}, {"id": 291, "seek": 204920, "start": 2059.2, "end": 2064.3199999999997, "text": " Just trying to parse what you just said, but it sounds like what they're suggesting using", "tokens": [50864, 1449, 1382, 281, 48377, 437, 291, 445, 848, 11, 457, 309, 3263, 411, 437, 436, 434, 18094, 1228, 51120], "temperature": 0.0, "avg_logprob": -0.2446581825377449, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.0012630659621208906}, {"id": 292, "seek": 204920, "start": 2064.3199999999997, "end": 2073.12, "text": " different language is that if you can, if you have enough information in the construct, the SEM,", "tokens": [51120, 819, 2856, 307, 300, 498, 291, 393, 11, 498, 291, 362, 1547, 1589, 294, 264, 7690, 11, 264, 318, 6683, 11, 51560], "temperature": 0.0, "avg_logprob": -0.2446581825377449, "compression_ratio": 1.4161490683229814, "no_speech_prob": 0.0012630659621208906}, {"id": 293, "seek": 207312, "start": 2074.08, "end": 2079.68, "text": " which is your representation, if you have enough information to answer", "tokens": [50412, 597, 307, 428, 10290, 11, 498, 291, 362, 1547, 1589, 281, 1867, 50692], "temperature": 0.0, "avg_logprob": -0.11730580580861945, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0006661433726549149}, {"id": 294, "seek": 207312, "start": 2080.4, "end": 2086.24, "text": " interventional and counterfactual questions correctly, then they're saying you can infer", "tokens": [50728, 13176, 304, 293, 5682, 44919, 901, 1651, 8944, 11, 550, 436, 434, 1566, 291, 393, 13596, 51020], "temperature": 0.0, "avg_logprob": -0.11730580580861945, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0006661433726549149}, {"id": 295, "seek": 207312, "start": 2086.24, "end": 2097.2799999999997, "text": " causality. Would that be a good interpretation? In other words, if the representation does not", "tokens": [51020, 3302, 1860, 13, 6068, 300, 312, 257, 665, 14174, 30, 682, 661, 2283, 11, 498, 264, 10290, 775, 406, 51572], "temperature": 0.0, "avg_logprob": -0.11730580580861945, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0006661433726549149}, {"id": 296, "seek": 207312, "start": 2097.2799999999997, "end": 2103.04, "text": " allow you to answer those two kinds of questions, they're basically arguing that you can't infer", "tokens": [51572, 2089, 291, 281, 1867, 729, 732, 3685, 295, 1651, 11, 436, 434, 1936, 19697, 300, 291, 393, 380, 13596, 51860], "temperature": 0.0, "avg_logprob": -0.11730580580861945, "compression_ratio": 1.6714285714285715, "no_speech_prob": 0.0006661433726549149}, {"id": 297, "seek": 210304, "start": 2103.04, "end": 2110.24, "text": " causality. Yeah, I think this is a good summary of the definition.", "tokens": [50364, 3302, 1860, 13, 865, 11, 286, 519, 341, 307, 257, 665, 12691, 295, 264, 7123, 13, 50724], "temperature": 0.0, "avg_logprob": -0.1139015989788508, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.00014407603885047138}, {"id": 298, "seek": 210304, "start": 2113.44, "end": 2117.44, "text": " So it says something about the particular form of the representation that you need to have.", "tokens": [50884, 407, 309, 1619, 746, 466, 264, 1729, 1254, 295, 264, 10290, 300, 291, 643, 281, 362, 13, 51084], "temperature": 0.0, "avg_logprob": -0.1139015989788508, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.00014407603885047138}, {"id": 299, "seek": 210304, "start": 2121.04, "end": 2128.4, "text": " In other words, is it answering the question correctly does not imply that you actually have,", "tokens": [51264, 682, 661, 2283, 11, 307, 309, 13430, 264, 1168, 8944, 775, 406, 33616, 300, 291, 767, 362, 11, 51632], "temperature": 0.0, "avg_logprob": -0.1139015989788508, "compression_ratio": 1.4823529411764707, "no_speech_prob": 0.00014407603885047138}, {"id": 300, "seek": 212840, "start": 2129.28, "end": 2138.2400000000002, "text": " well, that's complicated. It seems to me that you need a particular structure which enables you", "tokens": [50408, 731, 11, 300, 311, 6179, 13, 467, 2544, 281, 385, 300, 291, 643, 257, 1729, 3877, 597, 17077, 291, 50856], "temperature": 0.0, "avg_logprob": -0.13229218012169947, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.001324406242929399}, {"id": 301, "seek": 212840, "start": 2138.2400000000002, "end": 2141.6, "text": " to answer them, but answering them doesn't necessarily mean you have that structure.", "tokens": [50856, 281, 1867, 552, 11, 457, 13430, 552, 1177, 380, 4725, 914, 291, 362, 300, 3877, 13, 51024], "temperature": 0.0, "avg_logprob": -0.13229218012169947, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.001324406242929399}, {"id": 302, "seek": 212840, "start": 2142.32, "end": 2145.84, "text": " Anyway, that's kind of what I'm struggling with here. Okay.", "tokens": [51060, 5684, 11, 300, 311, 733, 295, 437, 286, 478, 9314, 365, 510, 13, 1033, 13, 51236], "temperature": 0.0, "avg_logprob": -0.13229218012169947, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.001324406242929399}, {"id": 303, "seek": 212840, "start": 2149.6, "end": 2153.6800000000003, "text": " Okay, so I'll just continue. So this is the conjecture that you make,", "tokens": [51424, 1033, 11, 370, 286, 603, 445, 2354, 13, 407, 341, 307, 264, 416, 1020, 540, 300, 291, 652, 11, 51628], "temperature": 0.0, "avg_logprob": -0.13229218012169947, "compression_ratio": 1.5577889447236182, "no_speech_prob": 0.001324406242929399}, {"id": 304, "seek": 215368, "start": 2153.8399999999997, "end": 2164.96, "text": " M1 be an SEM and 2 a respective media SEM. So it means that M2 is able to answer queries on", "tokens": [50372, 376, 16, 312, 364, 318, 6683, 293, 568, 257, 23649, 3021, 318, 6683, 13, 407, 309, 1355, 300, 376, 17, 307, 1075, 281, 1867, 24109, 322, 50928], "temperature": 0.0, "avg_logprob": -0.20299952908566124, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.0038229888305068016}, {"id": 305, "seek": 215368, "start": 2164.96, "end": 2170.48, "text": " M1 based on its observational data. So basically M2 would be the LLM in this one.", "tokens": [50928, 376, 16, 2361, 322, 1080, 9951, 1478, 1412, 13, 407, 1936, 376, 17, 576, 312, 264, 441, 43, 44, 294, 341, 472, 13, 51204], "temperature": 0.0, "avg_logprob": -0.20299952908566124, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.0038229888305068016}, {"id": 306, "seek": 215368, "start": 2172.0, "end": 2179.04, "text": " So then define Q and A in the language and in the interventional language of M1,", "tokens": [51280, 407, 550, 6964, 1249, 293, 316, 294, 264, 2856, 293, 294, 264, 13176, 304, 2856, 295, 376, 16, 11, 51632], "temperature": 0.0, "avg_logprob": -0.20299952908566124, "compression_ratio": 1.5029585798816567, "no_speech_prob": 0.0038229888305068016}, {"id": 307, "seek": 217904, "start": 2179.04, "end": 2182.88, "text": " observational language of M2, causal queries with their respective answers,", "tokens": [50364, 9951, 1478, 2856, 295, 376, 17, 11, 38755, 24109, 365, 641, 23649, 6338, 11, 50556], "temperature": 0.0, "avg_logprob": -0.13808667218243634, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0029345264192670584}, {"id": 308, "seek": 217904, "start": 2183.52, "end": 2188.64, "text": " blah, blah, blah, then we have FQ equals A is equivalent to FQ minimizes training error.", "tokens": [50588, 12288, 11, 12288, 11, 12288, 11, 550, 321, 362, 479, 48, 6915, 316, 307, 10344, 281, 479, 48, 4464, 5660, 3097, 6713, 13, 50844], "temperature": 0.0, "avg_logprob": -0.13808667218243634, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0029345264192670584}, {"id": 309, "seek": 217904, "start": 2189.2, "end": 2195.12, "text": " So basically what they say in this conjecture is that F of Q,", "tokens": [50872, 407, 1936, 437, 436, 584, 294, 341, 416, 1020, 540, 307, 300, 479, 295, 1249, 11, 51168], "temperature": 0.0, "avg_logprob": -0.13808667218243634, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0029345264192670584}, {"id": 310, "seek": 217904, "start": 2197.7599999999998, "end": 2205.2, "text": " which is the LLM's predictive models. So the predictions based on the interventional", "tokens": [51300, 597, 307, 264, 441, 43, 44, 311, 35521, 5245, 13, 407, 264, 21264, 2361, 322, 264, 13176, 304, 51672], "temperature": 0.0, "avg_logprob": -0.13808667218243634, "compression_ratio": 1.502415458937198, "no_speech_prob": 0.0029345264192670584}, {"id": 311, "seek": 220520, "start": 2205.4399999999996, "end": 2214.3999999999996, "text": " of M1 equals the observational of M2 minimizes training error. So basically what they say is", "tokens": [50376, 295, 376, 16, 6915, 264, 9951, 1478, 295, 376, 17, 4464, 5660, 3097, 6713, 13, 407, 1936, 437, 436, 584, 307, 50824], "temperature": 0.0, "avg_logprob": -0.11317228016100432, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0015246878610923886}, {"id": 312, "seek": 220520, "start": 2214.3999999999996, "end": 2222.48, "text": " that you don't learn anything more. I'm sorry. I don't know if that's really clear. I'm going to", "tokens": [50824, 300, 291, 500, 380, 1466, 1340, 544, 13, 286, 478, 2597, 13, 286, 500, 380, 458, 498, 300, 311, 534, 1850, 13, 286, 478, 516, 281, 51228], "temperature": 0.0, "avg_logprob": -0.11317228016100432, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0015246878610923886}, {"id": 313, "seek": 220520, "start": 2222.48, "end": 2231.68, "text": " try this again. What they try to say here is that an LLM learning on the interventional", "tokens": [51228, 853, 341, 797, 13, 708, 436, 853, 281, 584, 510, 307, 300, 364, 441, 43, 44, 2539, 322, 264, 13176, 304, 51688], "temperature": 0.0, "avg_logprob": -0.11317228016100432, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.0015246878610923886}, {"id": 314, "seek": 223168, "start": 2232.56, "end": 2243.6, "text": " and not learning anything more based on that model being able to already have the knowledge", "tokens": [50408, 293, 406, 2539, 1340, 544, 2361, 322, 300, 2316, 885, 1075, 281, 1217, 362, 264, 3601, 50960], "temperature": 0.0, "avg_logprob": -0.14364848570390182, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.0005792098818346858}, {"id": 315, "seek": 223168, "start": 2243.6, "end": 2250.3999999999996, "text": " on the observational distribution of M2 is equivalent. So basically in the information", "tokens": [50960, 322, 264, 9951, 1478, 7316, 295, 376, 17, 307, 10344, 13, 407, 1936, 294, 264, 1589, 51300], "temperature": 0.0, "avg_logprob": -0.14364848570390182, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.0005792098818346858}, {"id": 316, "seek": 223168, "start": 2250.3999999999996, "end": 2256.48, "text": " of the observational distribution of M2, you already have all the informations", "tokens": [51300, 295, 264, 9951, 1478, 7316, 295, 376, 17, 11, 291, 1217, 362, 439, 264, 38855, 51604], "temperature": 0.0, "avg_logprob": -0.14364848570390182, "compression_ratio": 1.748299319727891, "no_speech_prob": 0.0005792098818346858}, {"id": 317, "seek": 225648, "start": 2257.44, "end": 2264.64, "text": " to do interventional querying on the other SCM means that the LLM minimizes training error.", "tokens": [50412, 281, 360, 13176, 304, 7083, 1840, 322, 264, 661, 9028, 44, 1355, 300, 264, 441, 43, 44, 4464, 5660, 3097, 6713, 13, 50772], "temperature": 0.0, "avg_logprob": -0.08360068303234172, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.011155674234032631}, {"id": 318, "seek": 225648, "start": 2264.64, "end": 2270.48, "text": " So in that case means that the model converges and it is able to do it. This is the conjecture,", "tokens": [50772, 407, 294, 300, 1389, 1355, 300, 264, 2316, 9652, 2880, 293, 309, 307, 1075, 281, 360, 309, 13, 639, 307, 264, 416, 1020, 540, 11, 51064], "temperature": 0.0, "avg_logprob": -0.08360068303234172, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.011155674234032631}, {"id": 319, "seek": 225648, "start": 2270.48, "end": 2275.44, "text": " in other words, this is the conjecture they come up with to say that if an LLM can be", "tokens": [51064, 294, 661, 2283, 11, 341, 307, 264, 416, 1020, 540, 436, 808, 493, 365, 281, 584, 300, 498, 364, 441, 43, 44, 393, 312, 51312], "temperature": 0.0, "avg_logprob": -0.08360068303234172, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.011155674234032631}, {"id": 320, "seek": 225648, "start": 2275.44, "end": 2285.2, "text": " assimilated to a meta SCM, so it is able to escalate the causal task rank based on observational data,", "tokens": [51312, 8249, 45678, 281, 257, 19616, 9028, 44, 11, 370, 309, 307, 1075, 281, 17871, 473, 264, 38755, 5633, 6181, 2361, 322, 9951, 1478, 1412, 11, 51800], "temperature": 0.0, "avg_logprob": -0.08360068303234172, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.011155674234032631}, {"id": 321, "seek": 228520, "start": 2285.2, "end": 2290.0, "text": " then it is causal. This is the conjecture they come up with and they cannot prove it.", "tokens": [50364, 550, 309, 307, 38755, 13, 639, 307, 264, 416, 1020, 540, 436, 808, 493, 365, 293, 436, 2644, 7081, 309, 13, 50604], "temperature": 0.0, "avg_logprob": -0.08984431353482333, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0015974012203514576}, {"id": 322, "seek": 228520, "start": 2291.9199999999996, "end": 2297.68, "text": " This is again one of the strongest remarks and feedbacks that has been given in open reviews", "tokens": [50700, 639, 307, 797, 472, 295, 264, 16595, 19151, 293, 5824, 82, 300, 575, 668, 2212, 294, 1269, 10229, 50988], "temperature": 0.0, "avg_logprob": -0.08984431353482333, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0015974012203514576}, {"id": 323, "seek": 228520, "start": 2297.68, "end": 2305.7599999999998, "text": " for day paper. The reviewer said you make such strong claims on causality and LLMs,", "tokens": [50988, 337, 786, 3035, 13, 440, 3131, 260, 848, 291, 652, 1270, 2068, 9441, 322, 3302, 1860, 293, 441, 43, 26386, 11, 51392], "temperature": 0.0, "avg_logprob": -0.08984431353482333, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0015974012203514576}, {"id": 324, "seek": 228520, "start": 2305.7599999999998, "end": 2309.68, "text": " but eventually you cannot conclude on the conjecture. So the work is really interesting,", "tokens": [51392, 457, 4728, 291, 2644, 16886, 322, 264, 416, 1020, 540, 13, 407, 264, 589, 307, 534, 1880, 11, 51588], "temperature": 0.0, "avg_logprob": -0.08984431353482333, "compression_ratio": 1.6325581395348838, "no_speech_prob": 0.0015974012203514576}, {"id": 325, "seek": 230968, "start": 2309.68, "end": 2317.04, "text": " but eventually you do not conclude on it. They still give results and everything.", "tokens": [50364, 457, 4728, 291, 360, 406, 16886, 322, 309, 13, 814, 920, 976, 3542, 293, 1203, 13, 50732], "temperature": 0.0, "avg_logprob": -0.13028960350232247, "compression_ratio": 1.691542288557214, "no_speech_prob": 0.012236453592777252}, {"id": 326, "seek": 230968, "start": 2318.96, "end": 2325.8399999999997, "text": " In this one, for instance, this is basically intuitive physics, basic logic questions,", "tokens": [50828, 682, 341, 472, 11, 337, 5197, 11, 341, 307, 1936, 21769, 10649, 11, 3875, 9952, 1651, 11, 51172], "temperature": 0.0, "avg_logprob": -0.13028960350232247, "compression_ratio": 1.691542288557214, "no_speech_prob": 0.012236453592777252}, {"id": 327, "seek": 230968, "start": 2326.96, "end": 2332.3999999999996, "text": " such as if flipping switches causes light bulbs to shine and shining light bulbs causes", "tokens": [51228, 1270, 382, 498, 26886, 19458, 7700, 1442, 32871, 281, 12207, 293, 18269, 1442, 32871, 7700, 51500], "temperature": 0.0, "avg_logprob": -0.13028960350232247, "compression_ratio": 1.691542288557214, "no_speech_prob": 0.012236453592777252}, {"id": 328, "seek": 230968, "start": 2332.3999999999996, "end": 2338.3999999999996, "text": " mothas to appear. Does flipping switches cause mothas to appear, which is a typical", "tokens": [51500, 275, 900, 296, 281, 4204, 13, 4402, 26886, 19458, 3082, 275, 900, 296, 281, 4204, 11, 597, 307, 257, 7476, 51800], "temperature": 0.0, "avg_logprob": -0.13028960350232247, "compression_ratio": 1.691542288557214, "no_speech_prob": 0.012236453592777252}, {"id": 329, "seek": 233840, "start": 2338.4, "end": 2347.28, "text": " causal question, and those are the results of the following LLMs on all those types of questions.", "tokens": [50364, 38755, 1168, 11, 293, 729, 366, 264, 3542, 295, 264, 3480, 441, 43, 26386, 322, 439, 729, 3467, 295, 1651, 13, 50808], "temperature": 0.0, "avg_logprob": -0.16941002831942792, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.001548041240312159}, {"id": 330, "seek": 233840, "start": 2348.08, "end": 2355.36, "text": " Everywhere there is an exclamation mark like that. They say that, as I was saying before,", "tokens": [50848, 37322, 456, 307, 364, 1624, 43233, 1491, 411, 300, 13, 814, 584, 300, 11, 382, 286, 390, 1566, 949, 11, 51212], "temperature": 0.0, "avg_logprob": -0.16941002831942792, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.001548041240312159}, {"id": 331, "seek": 233840, "start": 2355.36, "end": 2361.52, "text": " that eventually that data, this type of questions can have been included in GBD4's training.", "tokens": [51212, 300, 4728, 300, 1412, 11, 341, 2010, 295, 1651, 393, 362, 668, 5556, 294, 26809, 35, 19, 311, 3097, 13, 51520], "temperature": 0.0, "avg_logprob": -0.16941002831942792, "compression_ratio": 1.4814814814814814, "no_speech_prob": 0.001548041240312159}, {"id": 332, "seek": 236152, "start": 2362.48, "end": 2370.64, "text": " They give a kind of twisted explanation. They say that this framework was already published in", "tokens": [50412, 814, 976, 257, 733, 295, 23057, 10835, 13, 814, 584, 300, 341, 8388, 390, 1217, 6572, 294, 50820], "temperature": 0.0, "avg_logprob": -0.1431333033243815, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.015420513227581978}, {"id": 333, "seek": 236152, "start": 2370.64, "end": 2375.92, "text": " another paper and they say that they've been extensively running this framework and they", "tokens": [50820, 1071, 3035, 293, 436, 584, 300, 436, 600, 668, 32636, 2614, 341, 8388, 293, 436, 51084], "temperature": 0.0, "avg_logprob": -0.1431333033243815, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.015420513227581978}, {"id": 334, "seek": 236152, "start": 2375.92, "end": 2380.8, "text": " also say that OpenAI's API collects data on queries and answers and everything,", "tokens": [51084, 611, 584, 300, 7238, 48698, 311, 9362, 39897, 1412, 322, 24109, 293, 6338, 293, 1203, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1431333033243815, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.015420513227581978}, {"id": 335, "seek": 236152, "start": 2381.44, "end": 2386.8, "text": " and so they just make the assumption that maybe the data they used while running benchmark was", "tokens": [51360, 293, 370, 436, 445, 652, 264, 15302, 300, 1310, 264, 1412, 436, 1143, 1339, 2614, 18927, 390, 51628], "temperature": 0.0, "avg_logprob": -0.1431333033243815, "compression_ratio": 1.6497695852534562, "no_speech_prob": 0.015420513227581978}, {"id": 336, "seek": 238680, "start": 2386.8, "end": 2392.4, "text": " used in training of GBD4 when it was GBD3 back then. This is why they put an exclamation mark", "tokens": [50364, 1143, 294, 3097, 295, 26809, 35, 19, 562, 309, 390, 26809, 35, 18, 646, 550, 13, 639, 307, 983, 436, 829, 364, 1624, 43233, 1491, 50644], "temperature": 0.0, "avg_logprob": -0.11417330072281208, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.005467743147164583}, {"id": 337, "seek": 238680, "start": 2392.4, "end": 2397.6800000000003, "text": " next to it. They say we're not sure we can trust these answers for those reasons.", "tokens": [50644, 958, 281, 309, 13, 814, 584, 321, 434, 406, 988, 321, 393, 3361, 613, 6338, 337, 729, 4112, 13, 50908], "temperature": 0.0, "avg_logprob": -0.11417330072281208, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.005467743147164583}, {"id": 338, "seek": 238680, "start": 2400.4, "end": 2408.7200000000003, "text": " There also are small variations of the models where every COT thing means chain of thought.", "tokens": [51044, 821, 611, 366, 1359, 17840, 295, 264, 5245, 689, 633, 3002, 51, 551, 1355, 5021, 295, 1194, 13, 51460], "temperature": 0.0, "avg_logprob": -0.11417330072281208, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.005467743147164583}, {"id": 339, "seek": 238680, "start": 2410.1600000000003, "end": 2415.84, "text": " I don't know if you're familiar with chain of thought. Basically, it is what it's called,", "tokens": [51532, 286, 500, 380, 458, 498, 291, 434, 4963, 365, 5021, 295, 1194, 13, 8537, 11, 309, 307, 437, 309, 311, 1219, 11, 51816], "temperature": 0.0, "avg_logprob": -0.11417330072281208, "compression_ratio": 1.5387931034482758, "no_speech_prob": 0.005467743147164583}, {"id": 340, "seek": 241584, "start": 2415.84, "end": 2421.76, "text": " a prompt engineering pattern. With LLMs, the prompt is the input we feed to the LLM and prompt", "tokens": [50364, 257, 12391, 7043, 5102, 13, 2022, 441, 43, 26386, 11, 264, 12391, 307, 264, 4846, 321, 3154, 281, 264, 441, 43, 44, 293, 12391, 50660], "temperature": 0.0, "avg_logprob": -0.08059021355449289, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0015244712121784687}, {"id": 341, "seek": 241584, "start": 2421.76, "end": 2432.56, "text": " engineering is how to access more LLM features and enforce a behavior based on how you write the", "tokens": [50660, 7043, 307, 577, 281, 2105, 544, 441, 43, 44, 4122, 293, 24825, 257, 5223, 2361, 322, 577, 291, 2464, 264, 51200], "temperature": 0.0, "avg_logprob": -0.08059021355449289, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0015244712121784687}, {"id": 342, "seek": 241584, "start": 2432.56, "end": 2438.8, "text": " prompt. Chain of thought is a prompt engineering technique where you will specify clearly in the", "tokens": [51200, 12391, 13, 33252, 295, 1194, 307, 257, 12391, 7043, 6532, 689, 291, 486, 16500, 4448, 294, 264, 51512], "temperature": 0.0, "avg_logprob": -0.08059021355449289, "compression_ratio": 1.6744186046511629, "no_speech_prob": 0.0015244712121784687}, {"id": 343, "seek": 243880, "start": 2438.8, "end": 2448.2400000000002, "text": " prompt that you want the LLM to output multiple midway thinking thoughts and thinking steps", "tokens": [50364, 12391, 300, 291, 528, 264, 441, 43, 44, 281, 5598, 3866, 2062, 676, 1953, 4598, 293, 1953, 4439, 50836], "temperature": 0.0, "avg_logprob": -0.1638980715462331, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.035666096955537796}, {"id": 344, "seek": 243880, "start": 2448.88, "end": 2453.28, "text": " before actually outputting an answer. We will look like that. For instance, you could say if", "tokens": [50868, 949, 767, 5598, 783, 364, 1867, 13, 492, 486, 574, 411, 300, 13, 1171, 5197, 11, 291, 727, 584, 498, 51088], "temperature": 0.0, "avg_logprob": -0.1638980715462331, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.035666096955537796}, {"id": 345, "seek": 243880, "start": 2453.28, "end": 2458.48, "text": " flipping switches blah, blah, blah, you ask a question and then you say please answer by giving", "tokens": [51088, 26886, 19458, 12288, 11, 12288, 11, 12288, 11, 291, 1029, 257, 1168, 293, 550, 291, 584, 1767, 1867, 538, 2902, 51348], "temperature": 0.0, "avg_logprob": -0.1638980715462331, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.035666096955537796}, {"id": 346, "seek": 243880, "start": 2458.48, "end": 2465.92, "text": " three main thoughts first, one, two, three, then give a preliminary answer and then answer. That", "tokens": [51348, 1045, 2135, 4598, 700, 11, 472, 11, 732, 11, 1045, 11, 550, 976, 257, 28817, 1867, 293, 550, 1867, 13, 663, 51720], "temperature": 0.0, "avg_logprob": -0.1638980715462331, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.035666096955537796}, {"id": 347, "seek": 246592, "start": 2465.92, "end": 2472.4, "text": " would be considered a COT. It's been proven as making the LLMs able to answer more accurately", "tokens": [50364, 576, 312, 4888, 257, 3002, 51, 13, 467, 311, 668, 12785, 382, 1455, 264, 441, 43, 26386, 1075, 281, 1867, 544, 20095, 50688], "temperature": 0.0, "avg_logprob": -0.08722431101697556, "compression_ratio": 1.575, "no_speech_prob": 0.005553652066737413}, {"id": 348, "seek": 246592, "start": 2472.96, "end": 2480.88, "text": " or at least to be able to track down the chain process. There is also another type of it which", "tokens": [50716, 420, 412, 1935, 281, 312, 1075, 281, 2837, 760, 264, 5021, 1399, 13, 821, 307, 611, 1071, 2010, 295, 309, 597, 51112], "temperature": 0.0, "avg_logprob": -0.08722431101697556, "compression_ratio": 1.575, "no_speech_prob": 0.005553652066737413}, {"id": 349, "seek": 246592, "start": 2480.88, "end": 2486.2400000000002, "text": " I am aware of, but I feel like it's incredibly hard to implement, but it still would be really", "tokens": [51112, 286, 669, 3650, 295, 11, 457, 286, 841, 411, 309, 311, 6252, 1152, 281, 4445, 11, 457, 309, 920, 576, 312, 534, 51380], "temperature": 0.0, "avg_logprob": -0.08722431101697556, "compression_ratio": 1.575, "no_speech_prob": 0.005553652066737413}, {"id": 350, "seek": 246592, "start": 2486.2400000000002, "end": 2490.2400000000002, "text": " interesting. It's called tree of thoughts, which is pretty much the same principle as chain of", "tokens": [51380, 1880, 13, 467, 311, 1219, 4230, 295, 4598, 11, 597, 307, 1238, 709, 264, 912, 8665, 382, 5021, 295, 51580], "temperature": 0.0, "avg_logprob": -0.08722431101697556, "compression_ratio": 1.575, "no_speech_prob": 0.005553652066737413}, {"id": 351, "seek": 249024, "start": 2490.8799999999997, "end": 2496.4799999999996, "text": " thoughts, but you take branches so that you are able to track down which path", "tokens": [50396, 4598, 11, 457, 291, 747, 14770, 370, 300, 291, 366, 1075, 281, 2837, 760, 597, 3100, 50676], "temperature": 0.0, "avg_logprob": -0.18952557397267175, "compression_ratio": 1.532544378698225, "no_speech_prob": 0.01281755231320858}, {"id": 352, "seek": 249024, "start": 2496.4799999999996, "end": 2503.9199999999996, "text": " led to which results. We can get back to that later. This is the results they give about", "tokens": [50676, 4684, 281, 597, 3542, 13, 492, 393, 483, 646, 281, 300, 1780, 13, 639, 307, 264, 3542, 436, 976, 466, 51048], "temperature": 0.0, "avg_logprob": -0.18952557397267175, "compression_ratio": 1.532544378698225, "no_speech_prob": 0.01281755231320858}, {"id": 353, "seek": 249024, "start": 2503.9199999999996, "end": 2514.08, "text": " classical causality. In summary, the takeaways they offer, they present. Inability to ground", "tokens": [51048, 13735, 3302, 1860, 13, 682, 12691, 11, 264, 45584, 436, 2626, 11, 436, 1974, 13, 682, 2310, 281, 2727, 51556], "temperature": 0.0, "avg_logprob": -0.18952557397267175, "compression_ratio": 1.532544378698225, "no_speech_prob": 0.01281755231320858}, {"id": 354, "seek": 251408, "start": 2514.08, "end": 2519.04, "text": " tachal facts is part of the reason why LLMs are not able to infer generalized causal relations.", "tokens": [50364, 256, 608, 304, 9130, 307, 644, 295, 264, 1778, 983, 441, 43, 26386, 366, 406, 1075, 281, 13596, 44498, 38755, 2299, 13, 50612], "temperature": 0.0, "avg_logprob": -0.2139883041381836, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.033554039895534515}, {"id": 355, "seek": 251408, "start": 2520.64, "end": 2525.2799999999997, "text": " However, they acknowledge that LLMs represent a head start to learning and inference.", "tokens": [50692, 2908, 11, 436, 10692, 300, 441, 43, 26386, 2906, 257, 1378, 722, 281, 2539, 293, 38253, 13, 50924], "temperature": 0.0, "avg_logprob": -0.2139883041381836, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.033554039895534515}, {"id": 356, "seek": 251408, "start": 2527.6, "end": 2533.2, "text": " They are unable to prove conjecture one despite the strong claims that LLMs are only causal parrots.", "tokens": [51040, 814, 366, 11299, 281, 7081, 416, 1020, 540, 472, 7228, 264, 2068, 9441, 300, 441, 43, 26386, 366, 787, 38755, 971, 81, 1971, 13, 51320], "temperature": 0.0, "avg_logprob": -0.2139883041381836, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.033554039895534515}, {"id": 357, "seek": 251408, "start": 2536.72, "end": 2540.24, "text": " There is a whole paragraph on results on actual", "tokens": [51496, 821, 307, 257, 1379, 18865, 322, 3542, 322, 3539, 51672], "temperature": 0.0, "avg_logprob": -0.2139883041381836, "compression_ratio": 1.5639810426540284, "no_speech_prob": 0.033554039895534515}, {"id": 358, "seek": 254024, "start": 2540.9599999999996, "end": 2547.4399999999996, "text": " causal escalation tests, but there is no sort of table that summarizes results.", "tokens": [50400, 38755, 17871, 399, 6921, 11, 457, 456, 307, 572, 1333, 295, 3199, 300, 14611, 5660, 3542, 13, 50724], "temperature": 0.0, "avg_logprob": -0.09648398919539018, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.009121241979300976}, {"id": 359, "seek": 254024, "start": 2550.08, "end": 2558.72, "text": " I feel like this is a work in progress and will be interesting in the near future if they can come", "tokens": [50856, 286, 841, 411, 341, 307, 257, 589, 294, 4205, 293, 486, 312, 1880, 294, 264, 2651, 2027, 498, 436, 393, 808, 51288], "temperature": 0.0, "avg_logprob": -0.09648398919539018, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.009121241979300976}, {"id": 360, "seek": 254024, "start": 2558.72, "end": 2567.3599999999997, "text": " up with more results on the subject. This would be approximately a summary of what I've read in", "tokens": [51288, 493, 365, 544, 3542, 322, 264, 3983, 13, 639, 576, 312, 10447, 257, 12691, 295, 437, 286, 600, 1401, 294, 51720], "temperature": 0.0, "avg_logprob": -0.09648398919539018, "compression_ratio": 1.481081081081081, "no_speech_prob": 0.009121241979300976}, {"id": 361, "seek": 256736, "start": 2567.36, "end": 2576.6400000000003, "text": " the six papers. I'm just going to give a couple of future identified work in those papers,", "tokens": [50364, 264, 2309, 10577, 13, 286, 478, 445, 516, 281, 976, 257, 1916, 295, 2027, 9234, 589, 294, 729, 10577, 11, 50828], "temperature": 0.0, "avg_logprob": -0.13468334751744424, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.007691402919590473}, {"id": 362, "seek": 256736, "start": 2576.6400000000003, "end": 2582.8, "text": " so as to align possible research directions from these researchers in that area that may", "tokens": [50828, 370, 382, 281, 7975, 1944, 2132, 11095, 490, 613, 10309, 294, 300, 1859, 300, 815, 51136], "temperature": 0.0, "avg_logprob": -0.13468334751744424, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.007691402919590473}, {"id": 363, "seek": 256736, "start": 2582.8, "end": 2591.76, "text": " give us discussion elements. None of them could actually conclude that LLMs can do causality", "tokens": [51136, 976, 505, 5017, 4959, 13, 14492, 295, 552, 727, 767, 16886, 300, 441, 43, 26386, 393, 360, 3302, 1860, 51584], "temperature": 0.0, "avg_logprob": -0.13468334751744424, "compression_ratio": 1.4945054945054945, "no_speech_prob": 0.007691402919590473}, {"id": 364, "seek": 259176, "start": 2591.76, "end": 2598.0800000000004, "text": " or not, but what they do acknowledge is that LLMs represent suitable candidates to support", "tokens": [50364, 420, 406, 11, 457, 437, 436, 360, 10692, 307, 300, 441, 43, 26386, 2906, 12873, 11255, 281, 1406, 50680], "temperature": 0.0, "avg_logprob": -0.09887023252599379, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.03207750990986824}, {"id": 365, "seek": 259176, "start": 2598.0800000000004, "end": 2604.96, "text": " actual causal inference framework just because they have a really interesting knowledge base", "tokens": [50680, 3539, 38755, 38253, 8388, 445, 570, 436, 362, 257, 534, 1880, 3601, 3096, 51024], "temperature": 0.0, "avg_logprob": -0.09887023252599379, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.03207750990986824}, {"id": 366, "seek": 259176, "start": 2604.96, "end": 2612.48, "text": " as part of their huge corpus of text learning on. A lot of them cannot conclude on the fact", "tokens": [51024, 382, 644, 295, 641, 2603, 1181, 31624, 295, 2487, 2539, 322, 13, 316, 688, 295, 552, 2644, 16886, 322, 264, 1186, 51400], "temperature": 0.0, "avg_logprob": -0.09887023252599379, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.03207750990986824}, {"id": 367, "seek": 259176, "start": 2612.48, "end": 2617.6800000000003, "text": " that LLMs can do causality, but they would be inclined to working with LLMs in order to", "tokens": [51400, 300, 441, 43, 26386, 393, 360, 3302, 1860, 11, 457, 436, 576, 312, 28173, 281, 1364, 365, 441, 43, 26386, 294, 1668, 281, 51660], "temperature": 0.0, "avg_logprob": -0.09887023252599379, "compression_ratio": 1.635135135135135, "no_speech_prob": 0.03207750990986824}, {"id": 368, "seek": 261768, "start": 2617.68, "end": 2625.7599999999998, "text": " combine with actual causality inference frameworks. Those in those four papers,", "tokens": [50364, 10432, 365, 3539, 3302, 1860, 38253, 29834, 13, 3950, 294, 729, 1451, 10577, 11, 50768], "temperature": 0.0, "avg_logprob": -0.15533067084647514, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.005218732636421919}, {"id": 369, "seek": 261768, "start": 2627.2, "end": 2632.16, "text": " they share the perspective that using LLMs as tools to enhance training of existing causal", "tokens": [50840, 436, 2073, 264, 4585, 300, 1228, 441, 43, 26386, 382, 3873, 281, 11985, 3097, 295, 6741, 38755, 51088], "temperature": 0.0, "avg_logprob": -0.15533067084647514, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.005218732636421919}, {"id": 370, "seek": 261768, "start": 2632.16, "end": 2639.12, "text": " models is worth exploring, pretty similar to the first one. Another interesting element would be", "tokens": [51088, 5245, 307, 3163, 12736, 11, 1238, 2531, 281, 264, 700, 472, 13, 3996, 1880, 4478, 576, 312, 51436], "temperature": 0.0, "avg_logprob": -0.15533067084647514, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.005218732636421919}, {"id": 371, "seek": 261768, "start": 2639.12, "end": 2643.7599999999998, "text": " that causal benchmarks, such as the latter presented in the first paper, represent interesting", "tokens": [51436, 300, 38755, 43751, 11, 1270, 382, 264, 18481, 8212, 294, 264, 700, 3035, 11, 2906, 1880, 51668], "temperature": 0.0, "avg_logprob": -0.15533067084647514, "compression_ratio": 1.6306306306306306, "no_speech_prob": 0.005218732636421919}, {"id": 372, "seek": 264376, "start": 2643.76, "end": 2649.0400000000004, "text": " access of improvement for LLM fine-tuning or towards the development of causal LLMs.", "tokens": [50364, 2105, 295, 10444, 337, 441, 43, 44, 2489, 12, 83, 37726, 420, 3030, 264, 3250, 295, 38755, 441, 43, 26386, 13, 50628], "temperature": 0.0, "avg_logprob": -0.19116726186540392, "compression_ratio": 1.4491978609625669, "no_speech_prob": 0.008185544982552528}, {"id": 373, "seek": 264376, "start": 2650.88, "end": 2662.2400000000002, "text": " Ginadal, I think she's working on this already because she's publishing a lot. She made it", "tokens": [50720, 36846, 345, 304, 11, 286, 519, 750, 311, 1364, 322, 341, 1217, 570, 750, 311, 17832, 257, 688, 13, 1240, 1027, 309, 51288], "temperature": 0.0, "avg_logprob": -0.19116726186540392, "compression_ratio": 1.4491978609625669, "no_speech_prob": 0.008185544982552528}, {"id": 374, "seek": 264376, "start": 2662.2400000000002, "end": 2667.6000000000004, "text": " clear that this is just the first step in her work. I guess this is also interesting to follow,", "tokens": [51288, 1850, 300, 341, 307, 445, 264, 700, 1823, 294, 720, 589, 13, 286, 2041, 341, 307, 611, 1880, 281, 1524, 11, 51556], "temperature": 0.0, "avg_logprob": -0.19116726186540392, "compression_ratio": 1.4491978609625669, "no_speech_prob": 0.008185544982552528}, {"id": 375, "seek": 266760, "start": 2668.08, "end": 2675.68, "text": " see if coming up with bigger causal frameworks will make able. But in the end, what is still", "tokens": [50388, 536, 498, 1348, 493, 365, 3801, 38755, 29834, 486, 652, 1075, 13, 583, 294, 264, 917, 11, 437, 307, 920, 50768], "temperature": 0.0, "avg_logprob": -0.09456356366475423, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.005468481220304966}, {"id": 376, "seek": 266760, "start": 2675.68, "end": 2684.4, "text": " interesting to discuss here is that causal relationships embedded in frameworks,", "tokens": [50768, 1880, 281, 2248, 510, 307, 300, 38755, 6159, 16741, 294, 29834, 11, 51204], "temperature": 0.0, "avg_logprob": -0.09456356366475423, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.005468481220304966}, {"id": 377, "seek": 266760, "start": 2685.92, "end": 2692.7999999999997, "text": " whether it is to test LLMs or to fine-tune them, it is still going to be in their knowledge base", "tokens": [51280, 1968, 309, 307, 281, 1500, 441, 43, 26386, 420, 281, 2489, 12, 83, 2613, 552, 11, 309, 307, 920, 516, 281, 312, 294, 641, 3601, 3096, 51624], "temperature": 0.0, "avg_logprob": -0.09456356366475423, "compression_ratio": 1.569767441860465, "no_speech_prob": 0.005468481220304966}, {"id": 378, "seek": 269280, "start": 2692.8, "end": 2698.5600000000004, "text": " in some way. I guess the question that wanted to be addressed here at first is about", "tokens": [50364, 294, 512, 636, 13, 286, 2041, 264, 1168, 300, 1415, 281, 312, 13847, 510, 412, 700, 307, 466, 50652], "temperature": 0.0, "avg_logprob": -0.12810696625128026, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0038830218836665154}, {"id": 379, "seek": 269280, "start": 2700.6400000000003, "end": 2704.4, "text": " interventional and current factual, which is not based on observational.", "tokens": [50756, 13176, 304, 293, 2190, 48029, 11, 597, 307, 406, 2361, 322, 9951, 1478, 13, 50944], "temperature": 0.0, "avg_logprob": -0.12810696625128026, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0038830218836665154}, {"id": 380, "seek": 269280, "start": 2706.48, "end": 2713.6000000000004, "text": " This is what I had as a presentation. I thought it was going to be shorter than that.", "tokens": [51048, 639, 307, 437, 286, 632, 382, 257, 5860, 13, 286, 1194, 309, 390, 516, 281, 312, 11639, 813, 300, 13, 51404], "temperature": 0.0, "avg_logprob": -0.12810696625128026, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0038830218836665154}, {"id": 381, "seek": 269280, "start": 2714.48, "end": 2721.6000000000004, "text": " I just think this is a basis to start a discussion on this topic because we have some elements now.", "tokens": [51448, 286, 445, 519, 341, 307, 257, 5143, 281, 722, 257, 5017, 322, 341, 4829, 570, 321, 362, 512, 4959, 586, 13, 51804], "temperature": 0.0, "avg_logprob": -0.12810696625128026, "compression_ratio": 1.6103286384976525, "no_speech_prob": 0.0038830218836665154}, {"id": 382, "seek": 272280, "start": 2723.04, "end": 2736.7200000000003, "text": " Thanks, Antoine. Now we are open for questions.", "tokens": [50376, 2561, 11, 5130, 44454, 13, 823, 321, 366, 1269, 337, 1651, 13, 51060], "temperature": 0.0, "avg_logprob": -0.552035391330719, "compression_ratio": 0.8545454545454545, "no_speech_prob": 0.005949986167252064}, {"id": 383, "seek": 273672, "start": 2736.72, "end": 2753.4399999999996, "text": " Hello. I'm sorry. I'm late today. I didn't go to the details of the papers. I'm just wondering", "tokens": [50364, 2425, 13, 286, 478, 2597, 13, 286, 478, 3469, 965, 13, 286, 994, 380, 352, 281, 264, 4365, 295, 264, 10577, 13, 286, 478, 445, 6359, 51200], "temperature": 0.0, "avg_logprob": -0.17536975542704264, "compression_ratio": 1.3687943262411348, "no_speech_prob": 0.016039762645959854}, {"id": 384, "seek": 273672, "start": 2753.4399999999996, "end": 2761.9199999999996, "text": " whether the fact that the GPT-4 is better than the GPT-3.5 in reasoning, can that be simply due to", "tokens": [51200, 1968, 264, 1186, 300, 264, 26039, 51, 12, 19, 307, 1101, 813, 264, 26039, 51, 12, 18, 13, 20, 294, 21577, 11, 393, 300, 312, 2935, 3462, 281, 51624], "temperature": 0.0, "avg_logprob": -0.17536975542704264, "compression_ratio": 1.3687943262411348, "no_speech_prob": 0.016039762645959854}, {"id": 385, "seek": 276192, "start": 2762.64, "end": 2767.12, "text": " that the GPT-4 has more data to be trained and more parameters to be estimated?", "tokens": [50400, 300, 264, 26039, 51, 12, 19, 575, 544, 1412, 281, 312, 8895, 293, 544, 9834, 281, 312, 14109, 30, 50624], "temperature": 0.0, "avg_logprob": -0.22495241634181287, "compression_ratio": 1.5337423312883436, "no_speech_prob": 0.007560014724731445}, {"id": 386, "seek": 276192, "start": 2770.16, "end": 2779.6800000000003, "text": " In a sense, it's due to an interpolation and regression issue. The so-called better reasoning", "tokens": [50776, 682, 257, 2020, 11, 309, 311, 3462, 281, 364, 44902, 399, 293, 24590, 2734, 13, 440, 370, 12, 11880, 1101, 21577, 51252], "temperature": 0.0, "avg_logprob": -0.22495241634181287, "compression_ratio": 1.5337423312883436, "no_speech_prob": 0.007560014724731445}, {"id": 387, "seek": 276192, "start": 2779.6800000000003, "end": 2785.44, "text": " is a representation of a better regression be obtained through the training.", "tokens": [51252, 307, 257, 10290, 295, 257, 1101, 24590, 312, 14879, 807, 264, 3097, 13, 51540], "temperature": 0.0, "avg_logprob": -0.22495241634181287, "compression_ratio": 1.5337423312883436, "no_speech_prob": 0.007560014724731445}, {"id": 388, "seek": 278544, "start": 2785.76, "end": 2789.36, "text": " It is an interesting thought.", "tokens": [50380, 467, 307, 364, 1880, 1194, 13, 50560], "temperature": 0.0, "avg_logprob": -0.28325219881736624, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0027126900386065245}, {"id": 389, "seek": 278544, "start": 2791.04, "end": 2799.6, "text": " Because the concluding saying that the LAM cannot do the causality. If we are going back,", "tokens": [50644, 1436, 264, 9312, 278, 1566, 300, 264, 441, 2865, 2644, 360, 264, 3302, 1860, 13, 759, 321, 366, 516, 646, 11, 51072], "temperature": 0.0, "avg_logprob": -0.28325219881736624, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0027126900386065245}, {"id": 390, "seek": 278544, "start": 2799.6, "end": 2807.68, "text": " so the reason why GPT-4 is better is to be trained with more data and more parameters to be tuned.", "tokens": [51072, 370, 264, 1778, 983, 26039, 51, 12, 19, 307, 1101, 307, 281, 312, 8895, 365, 544, 1412, 293, 544, 9834, 281, 312, 10870, 13, 51476], "temperature": 0.0, "avg_logprob": -0.28325219881736624, "compression_ratio": 1.3974358974358974, "no_speech_prob": 0.0027126900386065245}, {"id": 391, "seek": 280768, "start": 2808.64, "end": 2818.72, "text": " Yes, it is actually true. This is pretty much what they give. I guess this is what they want", "tokens": [50412, 1079, 11, 309, 307, 767, 2074, 13, 639, 307, 1238, 709, 437, 436, 976, 13, 286, 2041, 341, 307, 437, 436, 528, 50916], "temperature": 0.0, "avg_logprob": -0.13732742510343854, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.025895532220602036}, {"id": 392, "seek": 280768, "start": 2818.72, "end": 2824.7999999999997, "text": " to explain when they say that LLMs are causal parrots. If they see causality in their training", "tokens": [50916, 281, 2903, 562, 436, 584, 300, 441, 43, 26386, 366, 38755, 971, 81, 1971, 13, 759, 436, 536, 3302, 1860, 294, 641, 3097, 51220], "temperature": 0.0, "avg_logprob": -0.13732742510343854, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.025895532220602036}, {"id": 393, "seek": 280768, "start": 2824.7999999999997, "end": 2831.52, "text": " base in their data set and training data set, they will be able to eventually get that relationship", "tokens": [51220, 3096, 294, 641, 1412, 992, 293, 3097, 1412, 992, 11, 436, 486, 312, 1075, 281, 4728, 483, 300, 2480, 51556], "temperature": 0.0, "avg_logprob": -0.13732742510343854, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.025895532220602036}, {"id": 394, "seek": 280768, "start": 2831.52, "end": 2837.04, "text": " out of their training data set as a result. Eventually, yes, GPT-4 performs better because", "tokens": [51556, 484, 295, 641, 3097, 1412, 992, 382, 257, 1874, 13, 17586, 11, 2086, 11, 26039, 51, 12, 19, 26213, 1101, 570, 51832], "temperature": 0.0, "avg_logprob": -0.13732742510343854, "compression_ratio": 1.7181818181818183, "no_speech_prob": 0.025895532220602036}, {"id": 395, "seek": 283704, "start": 2837.04, "end": 2844.16, "text": " they've seen much. The question here would be more to say that are LLMs able to infer causality?", "tokens": [50364, 436, 600, 1612, 709, 13, 440, 1168, 510, 576, 312, 544, 281, 584, 300, 366, 441, 43, 26386, 1075, 281, 13596, 3302, 1860, 30, 50720], "temperature": 0.0, "avg_logprob": -0.09691228671949736, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.008703500032424927}, {"id": 396, "seek": 283704, "start": 2844.16, "end": 2851.2799999999997, "text": " Does it mean that they need to see it all to be able to do real causality? Or is the question", "tokens": [50720, 4402, 309, 914, 300, 436, 643, 281, 536, 309, 439, 281, 312, 1075, 281, 360, 957, 3302, 1860, 30, 1610, 307, 264, 1168, 51076], "temperature": 0.0, "avg_logprob": -0.09691228671949736, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.008703500032424927}, {"id": 397, "seek": 283704, "start": 2851.2799999999997, "end": 2858.08, "text": " here more about, no, can they actually do real causality, creating something? This is interesting", "tokens": [51076, 510, 544, 466, 11, 572, 11, 393, 436, 767, 360, 957, 3302, 1860, 11, 4084, 746, 30, 639, 307, 1880, 51416], "temperature": 0.0, "avg_logprob": -0.09691228671949736, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.008703500032424927}, {"id": 398, "seek": 283704, "start": 2858.08, "end": 2862.96, "text": " in the context of climate change, for instance, because all the natural processes are non-stationary.", "tokens": [51416, 294, 264, 4319, 295, 5659, 1319, 11, 337, 5197, 11, 570, 439, 264, 3303, 7555, 366, 2107, 12, 19159, 822, 13, 51660], "temperature": 0.0, "avg_logprob": -0.09691228671949736, "compression_ratio": 1.6810344827586208, "no_speech_prob": 0.008703500032424927}, {"id": 399, "seek": 286296, "start": 2862.96, "end": 2870.16, "text": " They keep increasing in intensity, and they either are more intense or more sparse than", "tokens": [50364, 814, 1066, 5662, 294, 13749, 11, 293, 436, 2139, 366, 544, 9447, 420, 544, 637, 11668, 813, 50724], "temperature": 0.0, "avg_logprob": -0.07971327803855718, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0019263924332335591}, {"id": 400, "seek": 286296, "start": 2870.16, "end": 2875.92, "text": " before, etc. There is nothing we can predict that. We don't understand that. This is what's", "tokens": [50724, 949, 11, 5183, 13, 821, 307, 1825, 321, 393, 6069, 300, 13, 492, 500, 380, 1223, 300, 13, 639, 307, 437, 311, 51012], "temperature": 0.0, "avg_logprob": -0.07971327803855718, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0019263924332335591}, {"id": 401, "seek": 286296, "start": 2875.92, "end": 2881.52, "text": " interesting in that particular context to me because that would be a great way to evaluate", "tokens": [51012, 1880, 294, 300, 1729, 4319, 281, 385, 570, 300, 576, 312, 257, 869, 636, 281, 13059, 51292], "temperature": 0.0, "avg_logprob": -0.07971327803855718, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0019263924332335591}, {"id": 402, "seek": 286296, "start": 2881.52, "end": 2888.7200000000003, "text": " to benchmark how LLMs interact with those data. Because this, we cannot have that in our training", "tokens": [51292, 281, 18927, 577, 441, 43, 26386, 4648, 365, 729, 1412, 13, 1436, 341, 11, 321, 2644, 362, 300, 294, 527, 3097, 51652], "temperature": 0.0, "avg_logprob": -0.07971327803855718, "compression_ratio": 1.6211453744493391, "no_speech_prob": 0.0019263924332335591}, {"id": 403, "seek": 288872, "start": 2888.72, "end": 2896.56, "text": " data set. The problem is, it's in foreseen. Every time it's new. But it's a great remark.", "tokens": [50364, 1412, 992, 13, 440, 1154, 307, 11, 309, 311, 294, 2091, 22008, 13, 2048, 565, 309, 311, 777, 13, 583, 309, 311, 257, 869, 7942, 13, 50756], "temperature": 0.0, "avg_logprob": -0.2086738215552436, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.005719532258808613}, {"id": 404, "seek": 288872, "start": 2897.3599999999997, "end": 2902.48, "text": " It's a great remark. Thank you. Because my experience is that the deep learning is a very", "tokens": [50796, 467, 311, 257, 869, 7942, 13, 1044, 291, 13, 1436, 452, 1752, 307, 300, 264, 2452, 2539, 307, 257, 588, 51052], "temperature": 0.0, "avg_logprob": -0.2086738215552436, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.005719532258808613}, {"id": 405, "seek": 288872, "start": 2902.48, "end": 2913.68, "text": " powerful regression tool. My personal experience of using the chat GPT is doing pretty well on", "tokens": [51052, 4005, 24590, 2290, 13, 1222, 2973, 1752, 295, 1228, 264, 5081, 26039, 51, 307, 884, 1238, 731, 322, 51612], "temperature": 0.0, "avg_logprob": -0.2086738215552436, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.005719532258808613}, {"id": 406, "seek": 291368, "start": 2914.64, "end": 2921.8399999999997, "text": " the data set that is trained most from, but the pretty poor job, kind of the questions that", "tokens": [50412, 264, 1412, 992, 300, 307, 8895, 881, 490, 11, 457, 264, 1238, 4716, 1691, 11, 733, 295, 264, 1651, 300, 50772], "temperature": 0.0, "avg_logprob": -0.22930215419023886, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.01095942035317421}, {"id": 407, "seek": 291368, "start": 2921.8399999999997, "end": 2927.68, "text": " is lastly trained from. For example, I sometimes use the chat GPT to provide some suggestions to", "tokens": [50772, 307, 16386, 8895, 490, 13, 1171, 1365, 11, 286, 2171, 764, 264, 5081, 26039, 51, 281, 2893, 512, 13396, 281, 51064], "temperature": 0.0, "avg_logprob": -0.22930215419023886, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.01095942035317421}, {"id": 408, "seek": 291368, "start": 2927.68, "end": 2934.72, "text": " where to travel from. I can get very good advice in these famous places. But if I was asking", "tokens": [51064, 689, 281, 3147, 490, 13, 286, 393, 483, 588, 665, 5192, 294, 613, 4618, 3190, 13, 583, 498, 286, 390, 3365, 51416], "temperature": 0.0, "avg_logprob": -0.22930215419023886, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.01095942035317421}, {"id": 409, "seek": 291368, "start": 2935.8399999999997, "end": 2941.8399999999997, "text": " where to travel, like do the hiking in the places nearby my current town,", "tokens": [51472, 689, 281, 3147, 11, 411, 360, 264, 23784, 294, 264, 3190, 11184, 452, 2190, 3954, 11, 51772], "temperature": 0.0, "avg_logprob": -0.22930215419023886, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.01095942035317421}, {"id": 410, "seek": 294184, "start": 2941.84, "end": 2951.76, "text": " Dave, it's just a random answer and not accurate. So I still think it's a regression problem for the", "tokens": [50364, 11017, 11, 309, 311, 445, 257, 4974, 1867, 293, 406, 8559, 13, 407, 286, 920, 519, 309, 311, 257, 24590, 1154, 337, 264, 50860], "temperature": 0.0, "avg_logprob": -0.2832177969125601, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0009999393951147795}, {"id": 411, "seek": 294184, "start": 2951.76, "end": 2963.28, "text": " LLM. Thanks. Tim, I think you have a question or you want to participate. Yeah. You know,", "tokens": [50860, 441, 43, 44, 13, 2561, 13, 7172, 11, 286, 519, 291, 362, 257, 1168, 420, 291, 528, 281, 8197, 13, 865, 13, 509, 458, 11, 51436], "temperature": 0.0, "avg_logprob": -0.2832177969125601, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0009999393951147795}, {"id": 412, "seek": 294184, "start": 2963.92, "end": 2971.44, "text": " causality is so fascinating and also problematic. I'm a little bit rusty, but I'll put this forward.", "tokens": [51468, 3302, 1860, 307, 370, 10343, 293, 611, 19011, 13, 286, 478, 257, 707, 857, 45394, 11, 457, 286, 603, 829, 341, 2128, 13, 51844], "temperature": 0.0, "avg_logprob": -0.2832177969125601, "compression_ratio": 1.4405940594059405, "no_speech_prob": 0.0009999393951147795}, {"id": 413, "seek": 297184, "start": 2972.2400000000002, "end": 2976.32, "text": " And particularly looking at this slide makes me wonder, you know,", "tokens": [50384, 400, 4098, 1237, 412, 341, 4137, 1669, 385, 2441, 11, 291, 458, 11, 50588], "temperature": 0.0, "avg_logprob": -0.15892281165489783, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00035674168611876667}, {"id": 414, "seek": 297184, "start": 2978.48, "end": 2984.48, "text": " well, I guess the classic response is, can we ever infer causality, whether for a machine or human?", "tokens": [50696, 731, 11, 286, 2041, 264, 7230, 4134, 307, 11, 393, 321, 1562, 13596, 3302, 1860, 11, 1968, 337, 257, 3479, 420, 1952, 30, 50996], "temperature": 0.0, "avg_logprob": -0.15892281165489783, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00035674168611876667}, {"id": 415, "seek": 297184, "start": 2986.08, "end": 2993.92, "text": " And my answer, I guess, is ultimately not. But looking at this slide makes me think that perhaps", "tokens": [51076, 400, 452, 1867, 11, 286, 2041, 11, 307, 6284, 406, 13, 583, 1237, 412, 341, 4137, 1669, 385, 519, 300, 4317, 51468], "temperature": 0.0, "avg_logprob": -0.15892281165489783, "compression_ratio": 1.5595238095238095, "no_speech_prob": 0.00035674168611876667}, {"id": 416, "seek": 299392, "start": 2994.32, "end": 3002.2400000000002, "text": " a question that we could answer is whether an LLM could perform logical reasoning.", "tokens": [50384, 257, 1168, 300, 321, 727, 1867, 307, 1968, 364, 441, 43, 44, 727, 2042, 14978, 21577, 13, 50780], "temperature": 0.0, "avg_logprob": -0.12479340235392253, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00164785236120224}, {"id": 417, "seek": 299392, "start": 3003.6, "end": 3008.88, "text": " Is that a fair distinction? Are those things the same? I feel like when I look at this slide,", "tokens": [50848, 1119, 300, 257, 3143, 16844, 30, 2014, 729, 721, 264, 912, 30, 286, 841, 411, 562, 286, 574, 412, 341, 4137, 11, 51112], "temperature": 0.0, "avg_logprob": -0.12479340235392253, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00164785236120224}, {"id": 418, "seek": 299392, "start": 3010.08, "end": 3016.88, "text": " the distinction I hear is that the causal structure is provided to the LLM in the prompt.", "tokens": [51172, 264, 16844, 286, 1568, 307, 300, 264, 38755, 3877, 307, 5649, 281, 264, 441, 43, 44, 294, 264, 12391, 13, 51512], "temperature": 0.0, "avg_logprob": -0.12479340235392253, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00164785236120224}, {"id": 419, "seek": 299392, "start": 3016.88, "end": 3021.52, "text": " You know, we say if flipping switches, you know, this happens and if this and that happens.", "tokens": [51512, 509, 458, 11, 321, 584, 498, 26886, 19458, 11, 291, 458, 11, 341, 2314, 293, 498, 341, 293, 300, 2314, 13, 51744], "temperature": 0.0, "avg_logprob": -0.12479340235392253, "compression_ratio": 1.6199095022624435, "no_speech_prob": 0.00164785236120224}, {"id": 420, "seek": 302152, "start": 3022.24, "end": 3029.44, "text": " And so the causal structure is provided. And what we're testing is whether the LLM can sort of", "tokens": [50400, 400, 370, 264, 38755, 3877, 307, 5649, 13, 400, 437, 321, 434, 4997, 307, 1968, 264, 441, 43, 44, 393, 1333, 295, 50760], "temperature": 0.0, "avg_logprob": -0.09697487277369346, "compression_ratio": 1.4972067039106145, "no_speech_prob": 0.0003249799192417413}, {"id": 421, "seek": 302152, "start": 3029.44, "end": 3033.84, "text": " use logic to understand that relationship when the structure is known.", "tokens": [50760, 764, 9952, 281, 1223, 300, 2480, 562, 264, 3877, 307, 2570, 13, 50980], "temperature": 0.0, "avg_logprob": -0.09697487277369346, "compression_ratio": 1.4972067039106145, "no_speech_prob": 0.0003249799192417413}, {"id": 422, "seek": 302152, "start": 3036.88, "end": 3043.52, "text": " That's interesting. I feel like in this particular example, this is the type of question and answering", "tokens": [51132, 663, 311, 1880, 13, 286, 841, 411, 294, 341, 1729, 1365, 11, 341, 307, 264, 2010, 295, 1168, 293, 13430, 51464], "temperature": 0.0, "avg_logprob": -0.09697487277369346, "compression_ratio": 1.4972067039106145, "no_speech_prob": 0.0003249799192417413}, {"id": 423, "seek": 304352, "start": 3043.52, "end": 3051.44, "text": " there is the way they describe it in Clatter, the genital paper, the cool little questions", "tokens": [50364, 456, 307, 264, 636, 436, 6786, 309, 294, 2033, 1161, 11, 264, 1049, 1686, 3035, 11, 264, 1627, 707, 1651, 50760], "temperature": 0.0, "avg_logprob": -0.14433820681138473, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0026724967174232006}, {"id": 424, "seek": 304352, "start": 3051.44, "end": 3056.32, "text": " are really different. And so I guess, yes, your remark is interesting. I feel like it really", "tokens": [50760, 366, 534, 819, 13, 400, 370, 286, 2041, 11, 2086, 11, 428, 7942, 307, 1880, 13, 286, 841, 411, 309, 534, 51004], "temperature": 0.0, "avg_logprob": -0.14433820681138473, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0026724967174232006}, {"id": 425, "seek": 304352, "start": 3056.32, "end": 3061.04, "text": " depends in the different papers on what they want to put forward, whether it is", "tokens": [51004, 5946, 294, 264, 819, 10577, 322, 437, 436, 528, 281, 829, 2128, 11, 1968, 309, 307, 51240], "temperature": 0.0, "avg_logprob": -0.14433820681138473, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0026724967174232006}, {"id": 426, "seek": 304352, "start": 3062.16, "end": 3067.36, "text": " interventional and counterfactual causality, or in that particular case, maybe it would be closer to", "tokens": [51296, 13176, 304, 293, 5682, 44919, 901, 3302, 1860, 11, 420, 294, 300, 1729, 1389, 11, 1310, 309, 576, 312, 4966, 281, 51556], "temperature": 0.0, "avg_logprob": -0.14433820681138473, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0026724967174232006}, {"id": 427, "seek": 306736, "start": 3067.36, "end": 3071.36, "text": " logical reasoning. But", "tokens": [50364, 14978, 21577, 13, 583, 50564], "temperature": 0.0, "avg_logprob": -0.343233677378872, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0033762578386813402}, {"id": 428, "seek": 306736, "start": 3075.36, "end": 3083.2000000000003, "text": " it's really interesting. I guess it's still here, basically, what they say x causes y and y causes", "tokens": [50764, 309, 311, 534, 1880, 13, 286, 2041, 309, 311, 920, 510, 11, 1936, 11, 437, 436, 584, 2031, 7700, 288, 293, 288, 7700, 51156], "temperature": 0.0, "avg_logprob": -0.343233677378872, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0033762578386813402}, {"id": 429, "seek": 306736, "start": 3083.2000000000003, "end": 3095.52, "text": " z does x causes z would be different depending on the situation. So I mean, this is the graph,", "tokens": [51156, 710, 775, 2031, 7700, 710, 576, 312, 819, 5413, 322, 264, 2590, 13, 407, 286, 914, 11, 341, 307, 264, 4295, 11, 51772], "temperature": 0.0, "avg_logprob": -0.343233677378872, "compression_ratio": 1.4210526315789473, "no_speech_prob": 0.0033762578386813402}, {"id": 430, "seek": 309552, "start": 3096.16, "end": 3101.84, "text": " this is the structure, and then depending on the variables you pick, it is true or it is not.", "tokens": [50396, 341, 307, 264, 3877, 11, 293, 550, 5413, 322, 264, 9102, 291, 1888, 11, 309, 307, 2074, 420, 309, 307, 406, 13, 50680], "temperature": 0.0, "avg_logprob": -0.1844972591955685, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00043728272430598736}, {"id": 431, "seek": 309552, "start": 3102.48, "end": 3110.32, "text": " But is it based on logic or it can also be based on observations? I don't know if you agree with that.", "tokens": [50712, 583, 307, 309, 2361, 322, 9952, 420, 309, 393, 611, 312, 2361, 322, 18163, 30, 286, 500, 380, 458, 498, 291, 3986, 365, 300, 13, 51104], "temperature": 0.0, "avg_logprob": -0.1844972591955685, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00043728272430598736}, {"id": 432, "seek": 309552, "start": 3112.4, "end": 3119.68, "text": " Well, well, sure. And I guess, you know, I guess the former, there's, I guess, maybe it's still", "tokens": [51208, 1042, 11, 731, 11, 988, 13, 400, 286, 2041, 11, 291, 458, 11, 286, 2041, 264, 5819, 11, 456, 311, 11, 286, 2041, 11, 1310, 309, 311, 920, 51572], "temperature": 0.0, "avg_logprob": -0.1844972591955685, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00043728272430598736}, {"id": 433, "seek": 309552, "start": 3119.68, "end": 3124.48, "text": " controversial, but some might argue that the former, you know, inferring causality simply", "tokens": [51572, 17323, 11, 457, 512, 1062, 9695, 300, 264, 5819, 11, 291, 458, 11, 13596, 2937, 3302, 1860, 2935, 51812], "temperature": 0.0, "avg_logprob": -0.1844972591955685, "compression_ratio": 1.6608695652173913, "no_speech_prob": 0.00043728272430598736}, {"id": 434, "seek": 312448, "start": 3124.48, "end": 3130.16, "text": " on observations is ultimately something we can never do. Not that it isn't useful to sort of", "tokens": [50364, 322, 18163, 307, 6284, 746, 321, 393, 1128, 360, 13, 1726, 300, 309, 1943, 380, 4420, 281, 1333, 295, 50648], "temperature": 0.0, "avg_logprob": -0.10727742923203334, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.0005524308071471751}, {"id": 435, "seek": 312448, "start": 3130.16, "end": 3136.4, "text": " try to develop sort of causal models. It definitely is. But ultimately, it's something we can never do.", "tokens": [50648, 853, 281, 1499, 1333, 295, 38755, 5245, 13, 467, 2138, 307, 13, 583, 6284, 11, 309, 311, 746, 321, 393, 1128, 360, 13, 50960], "temperature": 0.0, "avg_logprob": -0.10727742923203334, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.0005524308071471751}, {"id": 436, "seek": 312448, "start": 3137.36, "end": 3142.8, "text": " But with logic, you know, we can come to absolute conclusions. Like if we are given a structure,", "tokens": [51008, 583, 365, 9952, 11, 291, 458, 11, 321, 393, 808, 281, 8236, 22865, 13, 1743, 498, 321, 366, 2212, 257, 3877, 11, 51280], "temperature": 0.0, "avg_logprob": -0.10727742923203334, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.0005524308071471751}, {"id": 437, "seek": 312448, "start": 3142.8, "end": 3150.8, "text": " we can reason about that, sort of, you know, come up with determined sort of relationships", "tokens": [51280, 321, 393, 1778, 466, 300, 11, 1333, 295, 11, 291, 458, 11, 808, 493, 365, 9540, 1333, 295, 6159, 51680], "temperature": 0.0, "avg_logprob": -0.10727742923203334, "compression_ratio": 1.761467889908257, "no_speech_prob": 0.0005524308071471751}, {"id": 438, "seek": 315080, "start": 3150.8, "end": 3151.76, "text": " based on that structure.", "tokens": [50364, 2361, 322, 300, 3877, 13, 50412], "temperature": 0.0, "avg_logprob": -0.21750823656717935, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.0006769337342120707}, {"id": 439, "seek": 315080, "start": 3157.84, "end": 3159.76, "text": " Hashin and Beshi, did you want to react to this?", "tokens": [50716, 30775, 259, 293, 8190, 4954, 11, 630, 291, 528, 281, 4515, 281, 341, 30, 50812], "temperature": 0.0, "avg_logprob": -0.21750823656717935, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.0006769337342120707}, {"id": 440, "seek": 315080, "start": 3162.7200000000003, "end": 3165.28, "text": " Could you let me share my screen a moment? Of course.", "tokens": [50960, 7497, 291, 718, 385, 2073, 452, 2568, 257, 1623, 30, 2720, 1164, 13, 51088], "temperature": 0.0, "avg_logprob": -0.21750823656717935, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.0006769337342120707}, {"id": 441, "seek": 315080, "start": 3172.0800000000004, "end": 3177.52, "text": " So I put this in the chat. I just wanted to make you guys aware of this", "tokens": [51428, 407, 286, 829, 341, 294, 264, 5081, 13, 286, 445, 1415, 281, 652, 291, 1074, 3650, 295, 341, 51700], "temperature": 0.0, "avg_logprob": -0.21750823656717935, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.0006769337342120707}, {"id": 442, "seek": 317752, "start": 3178.48, "end": 3184.72, "text": " paper, which I think would be an interesting follow on to this conversation, because", "tokens": [50412, 3035, 11, 597, 286, 519, 576, 312, 364, 1880, 1524, 322, 281, 341, 3761, 11, 570, 50724], "temperature": 0.0, "avg_logprob": -0.13386301661646643, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0014081897679716349}, {"id": 443, "seek": 317752, "start": 3185.52, "end": 3189.84, "text": " this paper by Fran\u00e7ois Chalet, and you can go listen to him on YouTube, is very interesting.", "tokens": [50764, 341, 3035, 538, 1526, 12368, 7376, 761, 49744, 11, 293, 291, 393, 352, 2140, 281, 796, 322, 3088, 11, 307, 588, 1880, 13, 50980], "temperature": 0.0, "avg_logprob": -0.13386301661646643, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0014081897679716349}, {"id": 444, "seek": 317752, "start": 3190.88, "end": 3197.28, "text": " I just became familiar with and I recommend this paper for two reasons. One is because it", "tokens": [51032, 286, 445, 3062, 4963, 365, 293, 286, 2748, 341, 3035, 337, 732, 4112, 13, 1485, 307, 570, 309, 51352], "temperature": 0.0, "avg_logprob": -0.13386301661646643, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0014081897679716349}, {"id": 445, "seek": 317752, "start": 3197.28, "end": 3204.16, "text": " seems like a very cogent analysis of what would be necessary in order to have machine intelligence.", "tokens": [51352, 2544, 411, 257, 588, 598, 6930, 5215, 295, 437, 576, 312, 4818, 294, 1668, 281, 362, 3479, 7599, 13, 51696], "temperature": 0.0, "avg_logprob": -0.13386301661646643, "compression_ratio": 1.5593220338983051, "no_speech_prob": 0.0014081897679716349}, {"id": 446, "seek": 320416, "start": 3204.8799999999997, "end": 3211.04, "text": " And it feels to me like causality, the ability to infer causality or to determine a chain of", "tokens": [50400, 400, 309, 3417, 281, 385, 411, 3302, 1860, 11, 264, 3485, 281, 13596, 3302, 1860, 420, 281, 6997, 257, 5021, 295, 50708], "temperature": 0.0, "avg_logprob": -0.07581115063325858, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.0020798961631953716}, {"id": 447, "seek": 320416, "start": 3211.04, "end": 3218.3999999999996, "text": " reasoning using causal principles would be an important component of that. The other reason", "tokens": [50708, 21577, 1228, 38755, 9156, 576, 312, 364, 1021, 6542, 295, 300, 13, 440, 661, 1778, 51076], "temperature": 0.0, "avg_logprob": -0.07581115063325858, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.0020798961631953716}, {"id": 448, "seek": 320416, "start": 3218.3999999999996, "end": 3226.08, "text": " is because, as I've highlighted there, he actually defines if he comes up with a metric for defining", "tokens": [51076, 307, 570, 11, 382, 286, 600, 17173, 456, 11, 415, 767, 23122, 498, 415, 1487, 493, 365, 257, 20678, 337, 17827, 51460], "temperature": 0.0, "avg_logprob": -0.07581115063325858, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.0020798961631953716}, {"id": 449, "seek": 320416, "start": 3226.08, "end": 3232.56, "text": " intelligence of a machine based on algorithmic information theory, which information theory", "tokens": [51460, 7599, 295, 257, 3479, 2361, 322, 9284, 299, 1589, 5261, 11, 597, 1589, 5261, 51784], "temperature": 0.0, "avg_logprob": -0.07581115063325858, "compression_ratio": 1.632034632034632, "no_speech_prob": 0.0020798961631953716}, {"id": 450, "seek": 323256, "start": 3232.56, "end": 3238.56, "text": " being sort of a core part of what we're trying to talk about here. But one of the things he talks", "tokens": [50364, 885, 1333, 295, 257, 4965, 644, 295, 437, 321, 434, 1382, 281, 751, 466, 510, 13, 583, 472, 295, 264, 721, 415, 6686, 50664], "temperature": 0.0, "avg_logprob": -0.06508617970480848, "compression_ratio": 1.5810055865921788, "no_speech_prob": 0.0008157147676683962}, {"id": 451, "seek": 323256, "start": 3238.56, "end": 3253.6, "text": " about there is the need to account for prior information. So this discussion about whether", "tokens": [50664, 466, 456, 307, 264, 643, 281, 2696, 337, 4059, 1589, 13, 407, 341, 5017, 466, 1968, 51416], "temperature": 0.0, "avg_logprob": -0.06508617970480848, "compression_ratio": 1.5810055865921788, "no_speech_prob": 0.0008157147676683962}, {"id": 452, "seek": 323256, "start": 3253.6, "end": 3260.16, "text": " you're memorizing and regurgitating versus doing reasoning has a lot to do with how much prior", "tokens": [51416, 291, 434, 10560, 3319, 293, 1121, 5476, 16350, 5717, 884, 21577, 575, 257, 688, 281, 360, 365, 577, 709, 4059, 51744], "temperature": 0.0, "avg_logprob": -0.06508617970480848, "compression_ratio": 1.5810055865921788, "no_speech_prob": 0.0008157147676683962}, {"id": 453, "seek": 326016, "start": 3260.16, "end": 3265.44, "text": " information you have. If you already know the answer and you give me the correct answer,", "tokens": [50364, 1589, 291, 362, 13, 759, 291, 1217, 458, 264, 1867, 293, 291, 976, 385, 264, 3006, 1867, 11, 50628], "temperature": 0.0, "avg_logprob": -0.08538080851236979, "compression_ratio": 1.9579831932773109, "no_speech_prob": 0.0012629581615328789}, {"id": 454, "seek": 326016, "start": 3265.44, "end": 3270.48, "text": " did you give it to me because you did reasoning or because you just knew the answer and you just", "tokens": [50628, 630, 291, 976, 309, 281, 385, 570, 291, 630, 21577, 420, 570, 291, 445, 2586, 264, 1867, 293, 291, 445, 50880], "temperature": 0.0, "avg_logprob": -0.08538080851236979, "compression_ratio": 1.9579831932773109, "no_speech_prob": 0.0012629581615328789}, {"id": 455, "seek": 326016, "start": 3272.0, "end": 3278.3999999999996, "text": " stated the answer? So in the paper he talks about the need for being able to assess generalization", "tokens": [50956, 11323, 264, 1867, 30, 407, 294, 264, 3035, 415, 6686, 466, 264, 643, 337, 885, 1075, 281, 5877, 2674, 2144, 51276], "temperature": 0.0, "avg_logprob": -0.08538080851236979, "compression_ratio": 1.9579831932773109, "no_speech_prob": 0.0012629581615328789}, {"id": 456, "seek": 326016, "start": 3278.3999999999996, "end": 3283.44, "text": " ability. And we're talking about generalization ability being not just weak generalization,", "tokens": [51276, 3485, 13, 400, 321, 434, 1417, 466, 2674, 2144, 3485, 885, 406, 445, 5336, 2674, 2144, 11, 51528], "temperature": 0.0, "avg_logprob": -0.08538080851236979, "compression_ratio": 1.9579831932773109, "no_speech_prob": 0.0012629581615328789}, {"id": 457, "seek": 326016, "start": 3284.0, "end": 3289.68, "text": " meaning in the context of things you've seen before, but strong generalization in what he", "tokens": [51556, 3620, 294, 264, 4319, 295, 721, 291, 600, 1612, 949, 11, 457, 2068, 2674, 2144, 294, 437, 415, 51840], "temperature": 0.0, "avg_logprob": -0.08538080851236979, "compression_ratio": 1.9579831932773109, "no_speech_prob": 0.0012629581615328789}, {"id": 458, "seek": 328968, "start": 3289.68, "end": 3296.16, "text": " calls developer aware generalization in the sense of being able to generalize beyond the", "tokens": [50364, 5498, 10754, 3650, 2674, 2144, 294, 264, 2020, 295, 885, 1075, 281, 2674, 1125, 4399, 264, 50688], "temperature": 0.0, "avg_logprob": -0.09238106409708659, "compression_ratio": 1.5872093023255813, "no_speech_prob": 0.0002775303437374532}, {"id": 459, "seek": 328968, "start": 3296.16, "end": 3302.48, "text": " situations that you've seen in your training data, beyond your prior knowledge, and therefore", "tokens": [50688, 6851, 300, 291, 600, 1612, 294, 428, 3097, 1412, 11, 4399, 428, 4059, 3601, 11, 293, 4412, 51004], "temperature": 0.0, "avg_logprob": -0.09238106409708659, "compression_ratio": 1.5872093023255813, "no_speech_prob": 0.0002775303437374532}, {"id": 460, "seek": 328968, "start": 3303.12, "end": 3310.3199999999997, "text": " address novel situations. And it sounds to me like if we're going to assess the ability of", "tokens": [51036, 2985, 7613, 6851, 13, 400, 309, 3263, 281, 385, 411, 498, 321, 434, 516, 281, 5877, 264, 3485, 295, 51396], "temperature": 0.0, "avg_logprob": -0.09238106409708659, "compression_ratio": 1.5872093023255813, "no_speech_prob": 0.0002775303437374532}, {"id": 461, "seek": 331032, "start": 3310.96, "end": 3320.4, "text": " a machine or a program or a set of programs to do causal reasoning, then", "tokens": [50396, 257, 3479, 420, 257, 1461, 420, 257, 992, 295, 4268, 281, 360, 38755, 21577, 11, 550, 50868], "temperature": 0.0, "avg_logprob": -0.08911810151065688, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0037608379498124123}, {"id": 462, "seek": 331032, "start": 3322.2400000000002, "end": 3328.1600000000003, "text": " much in the nature of counterfactuals and so on, you need this ability to be able to take those", "tokens": [50960, 709, 294, 264, 3687, 295, 5682, 44919, 901, 82, 293, 370, 322, 11, 291, 643, 341, 3485, 281, 312, 1075, 281, 747, 729, 51256], "temperature": 0.0, "avg_logprob": -0.08911810151065688, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0037608379498124123}, {"id": 463, "seek": 331032, "start": 3329.1200000000003, "end": 3333.36, "text": " principles and then generalize into some other context that has never been seen before.", "tokens": [51304, 9156, 293, 550, 2674, 1125, 666, 512, 661, 4319, 300, 575, 1128, 668, 1612, 949, 13, 51516], "temperature": 0.0, "avg_logprob": -0.08911810151065688, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0037608379498124123}, {"id": 464, "seek": 331032, "start": 3334.4, "end": 3338.88, "text": " And so I found this a very interesting paper because he sort of breaks it down into the", "tokens": [51568, 400, 370, 286, 1352, 341, 257, 588, 1880, 3035, 570, 415, 1333, 295, 9857, 309, 760, 666, 264, 51792], "temperature": 0.0, "avg_logprob": -0.08911810151065688, "compression_ratio": 1.6074766355140186, "no_speech_prob": 0.0037608379498124123}, {"id": 465, "seek": 333888, "start": 3338.88, "end": 3346.0, "text": " necessary and sufficient components. In particular, if you're trying to compare two agents,", "tokens": [50364, 4818, 293, 11563, 6677, 13, 682, 1729, 11, 498, 291, 434, 1382, 281, 6794, 732, 12554, 11, 50720], "temperature": 0.0, "avg_logprob": -0.07337084141644565, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.0004041476349812001}, {"id": 466, "seek": 333888, "start": 3346.7200000000003, "end": 3352.8, "text": " you need to compare them with the same priors. In other words, if two agents have different priors,", "tokens": [50756, 291, 643, 281, 6794, 552, 365, 264, 912, 1790, 830, 13, 682, 661, 2283, 11, 498, 732, 12554, 362, 819, 1790, 830, 11, 51060], "temperature": 0.0, "avg_logprob": -0.07337084141644565, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.0004041476349812001}, {"id": 467, "seek": 333888, "start": 3352.8, "end": 3358.88, "text": " different levels of prior knowledge, then you can't, and the second agent has more prior knowledge", "tokens": [51060, 819, 4358, 295, 4059, 3601, 11, 550, 291, 393, 380, 11, 293, 264, 1150, 9461, 575, 544, 4059, 3601, 51364], "temperature": 0.0, "avg_logprob": -0.07337084141644565, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.0004041476349812001}, {"id": 468, "seek": 333888, "start": 3358.88, "end": 3363.76, "text": " than the first, and it gives a better answer, you can't necessarily conclude that that second", "tokens": [51364, 813, 264, 700, 11, 293, 309, 2709, 257, 1101, 1867, 11, 291, 393, 380, 4725, 16886, 300, 300, 1150, 51608], "temperature": 0.0, "avg_logprob": -0.07337084141644565, "compression_ratio": 1.8113207547169812, "no_speech_prob": 0.0004041476349812001}, {"id": 469, "seek": 336376, "start": 3363.76, "end": 3368.7200000000003, "text": " agent is more intelligent because it's not starting from the same basis. It might also", "tokens": [50364, 9461, 307, 544, 13232, 570, 309, 311, 406, 2891, 490, 264, 912, 5143, 13, 467, 1062, 611, 50612], "temperature": 0.0, "avg_logprob": -0.08472514875007398, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0007787834038026631}, {"id": 470, "seek": 336376, "start": 3368.7200000000003, "end": 3372.48, "text": " already have known that answer because it was in its prior knowledge base.", "tokens": [50612, 1217, 362, 2570, 300, 1867, 570, 309, 390, 294, 1080, 4059, 3601, 3096, 13, 50800], "temperature": 0.0, "avg_logprob": -0.08472514875007398, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0007787834038026631}, {"id": 471, "seek": 336376, "start": 3374.1600000000003, "end": 3381.0400000000004, "text": " So I think what you brought up about the LLMs, what training data have they seen?", "tokens": [50884, 407, 286, 519, 437, 291, 3038, 493, 466, 264, 441, 43, 26386, 11, 437, 3097, 1412, 362, 436, 1612, 30, 51228], "temperature": 0.0, "avg_logprob": -0.08472514875007398, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0007787834038026631}, {"id": 472, "seek": 336376, "start": 3382.5600000000004, "end": 3388.88, "text": " Timothy's very astute observation that the nature of the causal reasoning was already", "tokens": [51304, 29418, 311, 588, 5357, 1169, 14816, 300, 264, 3687, 295, 264, 38755, 21577, 390, 1217, 51620], "temperature": 0.0, "avg_logprob": -0.08472514875007398, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0007787834038026631}, {"id": 473, "seek": 336376, "start": 3388.88, "end": 3393.44, "text": " stated in that sentence. And you just gave an example and all it had to do was fill in the", "tokens": [51620, 11323, 294, 300, 8174, 13, 400, 291, 445, 2729, 364, 1365, 293, 439, 309, 632, 281, 360, 390, 2836, 294, 264, 51848], "temperature": 0.0, "avg_logprob": -0.08472514875007398, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0007787834038026631}, {"id": 474, "seek": 339344, "start": 3393.44, "end": 3403.76, "text": " blanks with different priors and A's and B's and answer that question. Was it really doing", "tokens": [50364, 8247, 82, 365, 819, 1790, 830, 293, 316, 311, 293, 363, 311, 293, 1867, 300, 1168, 13, 3027, 309, 534, 884, 50880], "temperature": 0.0, "avg_logprob": -0.07765407422009636, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0002232048864243552}, {"id": 475, "seek": 339344, "start": 3403.76, "end": 3410.0, "text": " causal reasoning? It was just using a rule which was given to it. So if I looked at that sentence", "tokens": [50880, 38755, 21577, 30, 467, 390, 445, 1228, 257, 4978, 597, 390, 2212, 281, 309, 13, 407, 498, 286, 2956, 412, 300, 8174, 51192], "temperature": 0.0, "avg_logprob": -0.07765407422009636, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0002232048864243552}, {"id": 476, "seek": 339344, "start": 3411.36, "end": 3417.84, "text": " that you gave me and I just memorized that sequence of sentences and I just applied it", "tokens": [51260, 300, 291, 2729, 385, 293, 286, 445, 46677, 300, 8310, 295, 16579, 293, 286, 445, 6456, 309, 51584], "temperature": 0.0, "avg_logprob": -0.07765407422009636, "compression_ratio": 1.5449438202247192, "no_speech_prob": 0.0002232048864243552}, {"id": 477, "seek": 341784, "start": 3417.84, "end": 3425.6000000000004, "text": " in a different context, am I doing causal reasoning? I think this really bears looking", "tokens": [50364, 294, 257, 819, 4319, 11, 669, 286, 884, 38755, 21577, 30, 286, 519, 341, 534, 17276, 1237, 50752], "temperature": 0.0, "avg_logprob": -0.11238936221960819, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0010316716507077217}, {"id": 478, "seek": 341784, "start": 3425.6000000000004, "end": 3429.04, "text": " in deeper to some of these issues that I think Francois is talking about in this paper.", "tokens": [50752, 294, 7731, 281, 512, 295, 613, 2663, 300, 286, 519, 34695, 271, 307, 1417, 466, 294, 341, 3035, 13, 50924], "temperature": 0.0, "avg_logprob": -0.11238936221960819, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0010316716507077217}, {"id": 479, "seek": 341784, "start": 3434.08, "end": 3442.6400000000003, "text": " Just a quick comment. I have to leave soon as well. So I think it might be interesting to go", "tokens": [51176, 1449, 257, 1702, 2871, 13, 286, 362, 281, 1856, 2321, 382, 731, 13, 407, 286, 519, 309, 1062, 312, 1880, 281, 352, 51604], "temperature": 0.0, "avg_logprob": -0.11238936221960819, "compression_ratio": 1.4751381215469612, "no_speech_prob": 0.0010316716507077217}, {"id": 480, "seek": 344264, "start": 3442.64, "end": 3449.6, "text": " through the architecture of either the chat GPT 3.5 or GPT 4. I'm not sure whether it's solely", "tokens": [50364, 807, 264, 9482, 295, 2139, 264, 5081, 26039, 51, 805, 13, 20, 420, 26039, 51, 1017, 13, 286, 478, 406, 988, 1968, 309, 311, 23309, 50712], "temperature": 0.0, "avg_logprob": -0.1402575451394786, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.001998117659240961}, {"id": 481, "seek": 344264, "start": 3449.6, "end": 3454.3199999999997, "text": " just based on the transformer or something else, but the architecture definitely will guide the", "tokens": [50712, 445, 2361, 322, 264, 31782, 420, 746, 1646, 11, 457, 264, 9482, 2138, 486, 5934, 264, 50948], "temperature": 0.0, "avg_logprob": -0.1402575451394786, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.001998117659240961}, {"id": 482, "seek": 344264, "start": 3454.96, "end": 3464.24, "text": " reasoning. So let me make a quick comment. I might have just said this before. I mean this", "tokens": [50980, 21577, 13, 407, 718, 385, 652, 257, 1702, 2871, 13, 286, 1062, 362, 445, 848, 341, 949, 13, 286, 914, 341, 51444], "temperature": 0.0, "avg_logprob": -0.1402575451394786, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.001998117659240961}, {"id": 483, "seek": 344264, "start": 3464.24, "end": 3471.68, "text": " discussion is very, very helpful. And Antoine, thank you for doing this pretty nice review.", "tokens": [51444, 5017, 307, 588, 11, 588, 4961, 13, 400, 5130, 44454, 11, 1309, 291, 337, 884, 341, 1238, 1481, 3131, 13, 51816], "temperature": 0.0, "avg_logprob": -0.1402575451394786, "compression_ratio": 1.5541666666666667, "no_speech_prob": 0.001998117659240961}, {"id": 484, "seek": 347168, "start": 3471.7599999999998, "end": 3482.0, "text": " I mean what this has brought to light in my mind is the distinction between causality and logical", "tokens": [50368, 286, 914, 437, 341, 575, 3038, 281, 1442, 294, 452, 1575, 307, 264, 16844, 1296, 3302, 1860, 293, 14978, 50880], "temperature": 0.0, "avg_logprob": -0.13357257843017578, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.0019162693060934544}, {"id": 485, "seek": 347168, "start": 3482.0, "end": 3491.3599999999997, "text": " reasoning which Timothy pointed out. And then within that the causality is basically causal", "tokens": [50880, 21577, 597, 29418, 10932, 484, 13, 400, 550, 1951, 300, 264, 3302, 1860, 307, 1936, 38755, 51348], "temperature": 0.0, "avg_logprob": -0.13357257843017578, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.0019162693060934544}, {"id": 486, "seek": 347168, "start": 3491.3599999999997, "end": 3496.72, "text": " discovery versus causal reasoning. Is that different from logical reasoning and so forth?", "tokens": [51348, 12114, 5717, 38755, 21577, 13, 1119, 300, 819, 490, 14978, 21577, 293, 370, 5220, 30, 51616], "temperature": 0.0, "avg_logprob": -0.13357257843017578, "compression_ratio": 1.5942857142857143, "no_speech_prob": 0.0019162693060934544}, {"id": 487, "seek": 349672, "start": 3496.72, "end": 3503.2799999999997, "text": " Right? I mean so there are some distinctions to be made and this whole idea of intelligence,", "tokens": [50364, 1779, 30, 286, 914, 370, 456, 366, 512, 1483, 49798, 281, 312, 1027, 293, 341, 1379, 1558, 295, 7599, 11, 50692], "temperature": 0.0, "avg_logprob": -0.1285196469153887, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.004957973957061768}, {"id": 488, "seek": 349672, "start": 3503.2799999999997, "end": 3510.3199999999997, "text": " I mean is intelligence all reasoning or when we think about intelligence we think about", "tokens": [50692, 286, 914, 307, 7599, 439, 21577, 420, 562, 321, 519, 466, 7599, 321, 519, 466, 51044], "temperature": 0.0, "avg_logprob": -0.1285196469153887, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.004957973957061768}, {"id": 489, "seek": 349672, "start": 3510.3199999999997, "end": 3517.12, "text": " intuition. We think about creativity. We think about coming up with new solutions when new", "tokens": [51044, 24002, 13, 492, 519, 466, 12915, 13, 492, 519, 466, 1348, 493, 365, 777, 6547, 562, 777, 51384], "temperature": 0.0, "avg_logprob": -0.1285196469153887, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.004957973957061768}, {"id": 490, "seek": 349672, "start": 3517.12, "end": 3524.3999999999996, "text": " constraints and things present which didn't exist. I mean the whole of the science and engineering is", "tokens": [51384, 18491, 293, 721, 1974, 597, 994, 380, 2514, 13, 286, 914, 264, 1379, 295, 264, 3497, 293, 7043, 307, 51748], "temperature": 0.0, "avg_logprob": -0.1285196469153887, "compression_ratio": 1.8195121951219513, "no_speech_prob": 0.004957973957061768}, {"id": 491, "seek": 352440, "start": 3524.48, "end": 3531.52, "text": " all of that, right? Pretty much all fields where you're trying to find new solutions which", "tokens": [50368, 439, 295, 300, 11, 558, 30, 10693, 709, 439, 7909, 689, 291, 434, 1382, 281, 915, 777, 6547, 597, 50720], "temperature": 0.0, "avg_logprob": -0.14822214041183243, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.0009678449714556336}, {"id": 492, "seek": 352440, "start": 3531.52, "end": 3539.04, "text": " probably do not have a historical precedence. And these large language models rely on that", "tokens": [50720, 1391, 360, 406, 362, 257, 8584, 16969, 655, 13, 400, 613, 2416, 2856, 5245, 10687, 322, 300, 51096], "temperature": 0.0, "avg_logprob": -0.14822214041183243, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.0009678449714556336}, {"id": 493, "seek": 352440, "start": 3539.04, "end": 3547.28, "text": " historical precedence. I mean the priors as you call it. And so how do we make that distinction?", "tokens": [51096, 8584, 16969, 655, 13, 286, 914, 264, 1790, 830, 382, 291, 818, 309, 13, 400, 370, 577, 360, 321, 652, 300, 16844, 30, 51508], "temperature": 0.0, "avg_logprob": -0.14822214041183243, "compression_ratio": 1.5444444444444445, "no_speech_prob": 0.0009678449714556336}, {"id": 494, "seek": 354728, "start": 3547.28, "end": 3556.32, "text": " And the second thing is that large language models are essentially inferring these things from", "tokens": [50364, 400, 264, 1150, 551, 307, 300, 2416, 2856, 5245, 366, 4476, 13596, 2937, 613, 721, 490, 50816], "temperature": 0.0, "avg_logprob": -0.09976689265324519, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.00036770544829778373}, {"id": 495, "seek": 354728, "start": 3556.96, "end": 3564.88, "text": " the basis of language. They are not doing analysis of data. There may be auxiliary tools", "tokens": [50848, 264, 5143, 295, 2856, 13, 814, 366, 406, 884, 5215, 295, 1412, 13, 821, 815, 312, 43741, 3873, 51244], "temperature": 0.0, "avg_logprob": -0.09976689265324519, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.00036770544829778373}, {"id": 496, "seek": 354728, "start": 3565.52, "end": 3572.88, "text": " that say okay now I can go and probe the data but that probing is based on the logic that is built", "tokens": [51276, 300, 584, 1392, 586, 286, 393, 352, 293, 22715, 264, 1412, 457, 300, 1239, 278, 307, 2361, 322, 264, 9952, 300, 307, 3094, 51644], "temperature": 0.0, "avg_logprob": -0.09976689265324519, "compression_ratio": 1.630057803468208, "no_speech_prob": 0.00036770544829778373}, {"id": 497, "seek": 357288, "start": 3573.84, "end": 3581.76, "text": " or large logic that these large language models come up with. And so I think there needs to be", "tokens": [50412, 420, 2416, 9952, 300, 613, 2416, 2856, 5245, 808, 493, 365, 13, 400, 370, 286, 519, 456, 2203, 281, 312, 50808], "temperature": 0.0, "avg_logprob": -0.072772400195782, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.0005181971937417984}, {"id": 498, "seek": 357288, "start": 3581.76, "end": 3588.48, "text": " some very subtle characterization of what we mean. I mean extending this idea of causality", "tokens": [50808, 512, 588, 13743, 49246, 295, 437, 321, 914, 13, 286, 914, 24360, 341, 1558, 295, 3302, 1860, 51144], "temperature": 0.0, "avg_logprob": -0.072772400195782, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.0005181971937417984}, {"id": 499, "seek": 357288, "start": 3588.48, "end": 3597.6800000000003, "text": " in those three notions that you talked about from a language to a data context. We use the word", "tokens": [51144, 294, 729, 1045, 35799, 300, 291, 2825, 466, 490, 257, 2856, 281, 257, 1412, 4319, 13, 492, 764, 264, 1349, 51604], "temperature": 0.0, "avg_logprob": -0.072772400195782, "compression_ratio": 1.510752688172043, "no_speech_prob": 0.0005181971937417984}, {"id": 500, "seek": 359768, "start": 3597.68, "end": 3604.72, "text": " data loosely. I mean what we are using the word data is essentially language data, not quantitative", "tokens": [50364, 1412, 37966, 13, 286, 914, 437, 321, 366, 1228, 264, 1349, 1412, 307, 4476, 2856, 1412, 11, 406, 27778, 50716], "temperature": 0.0, "avg_logprob": -0.10578561896708474, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009537655278109014}, {"id": 501, "seek": 359768, "start": 3604.72, "end": 3615.04, "text": " numerical data on which these analysis are built. So there is much to be done in parsing this out", "tokens": [50716, 29054, 1412, 322, 597, 613, 5215, 366, 3094, 13, 407, 456, 307, 709, 281, 312, 1096, 294, 21156, 278, 341, 484, 51232], "temperature": 0.0, "avg_logprob": -0.10578561896708474, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009537655278109014}, {"id": 502, "seek": 359768, "start": 3615.04, "end": 3622.56, "text": " very, very carefully and going about doing that. Having said that, the encouraging thing which I", "tokens": [51232, 588, 11, 588, 7500, 293, 516, 466, 884, 300, 13, 10222, 848, 300, 11, 264, 14580, 551, 597, 286, 51608], "temperature": 0.0, "avg_logprob": -0.10578561896708474, "compression_ratio": 1.5978260869565217, "no_speech_prob": 0.0009537655278109014}, {"id": 503, "seek": 362256, "start": 3622.56, "end": 3629.04, "text": " find is the following. So when I was in grad school, I did a couple of courses on artificial", "tokens": [50364, 915, 307, 264, 3480, 13, 407, 562, 286, 390, 294, 2771, 1395, 11, 286, 630, 257, 1916, 295, 7712, 322, 11677, 50688], "temperature": 0.0, "avg_logprob": -0.10424701734022661, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.003316389163956046}, {"id": 504, "seek": 362256, "start": 3629.04, "end": 3635.36, "text": " intelligence and the prevailing language at that time was Lisp and Prolog. Lisp processing and", "tokens": [50688, 7599, 293, 264, 12642, 23315, 2856, 412, 300, 565, 390, 441, 7631, 293, 1705, 4987, 13, 441, 7631, 9007, 293, 51004], "temperature": 0.0, "avg_logprob": -0.10424701734022661, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.003316389163956046}, {"id": 505, "seek": 362256, "start": 3635.36, "end": 3646.32, "text": " basically logical programming. That's what Prolog was. So the idea was that if you could program", "tokens": [51004, 1936, 14978, 9410, 13, 663, 311, 437, 1705, 4987, 390, 13, 407, 264, 1558, 390, 300, 498, 291, 727, 1461, 51552], "temperature": 0.0, "avg_logprob": -0.10424701734022661, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.003316389163956046}, {"id": 506, "seek": 362256, "start": 3646.32, "end": 3652.16, "text": " logic in all its complexity and the many books written on the structure of human logic and", "tokens": [51552, 9952, 294, 439, 1080, 14024, 293, 264, 867, 3642, 3720, 322, 264, 3877, 295, 1952, 9952, 293, 51844], "temperature": 0.0, "avg_logprob": -0.10424701734022661, "compression_ratio": 1.6233766233766234, "no_speech_prob": 0.003316389163956046}, {"id": 507, "seek": 365216, "start": 3652.24, "end": 3658.0, "text": " to take that and program it, you would be successful in mimicking intelligence. And", "tokens": [50368, 281, 747, 300, 293, 1461, 309, 11, 291, 576, 312, 4406, 294, 12247, 10401, 7599, 13, 400, 50656], "temperature": 0.0, "avg_logprob": -0.1077306900901356, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006547346129082143}, {"id": 508, "seek": 365216, "start": 3660.08, "end": 3665.2, "text": " to me at that time said, okay, you may be able to do a pretty sophisticated job with", "tokens": [50760, 281, 385, 412, 300, 565, 848, 11, 1392, 11, 291, 815, 312, 1075, 281, 360, 257, 1238, 16950, 1691, 365, 51016], "temperature": 0.0, "avg_logprob": -0.1077306900901356, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006547346129082143}, {"id": 509, "seek": 365216, "start": 3665.2, "end": 3670.48, "text": " deductive logic, but there was nothing in that which would allow you to do inductive logic,", "tokens": [51016, 31513, 488, 9952, 11, 457, 456, 390, 1825, 294, 300, 597, 576, 2089, 291, 281, 360, 31612, 488, 9952, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1077306900901356, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006547346129082143}, {"id": 510, "seek": 365216, "start": 3671.2, "end": 3680.56, "text": " which basically goes on to looking at inclusion and creativity. The thing is that didn't go too far", "tokens": [51316, 597, 1936, 1709, 322, 281, 1237, 412, 15874, 293, 12915, 13, 440, 551, 307, 300, 994, 380, 352, 886, 1400, 51784], "temperature": 0.0, "avg_logprob": -0.1077306900901356, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.0006547346129082143}, {"id": 511, "seek": 368056, "start": 3680.56, "end": 3688.56, "text": " and then we have this large language models who say, okay, I don't need a language that is based", "tokens": [50364, 293, 550, 321, 362, 341, 2416, 2856, 5245, 567, 584, 11, 1392, 11, 286, 500, 380, 643, 257, 2856, 300, 307, 2361, 50764], "temperature": 0.0, "avg_logprob": -0.12362386241103664, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.00019373312534298748}, {"id": 512, "seek": 368056, "start": 3688.56, "end": 3698.4, "text": " on reasoning. All I need to do is have the capability to infuse things from data", "tokens": [50764, 322, 21577, 13, 1057, 286, 643, 281, 360, 307, 362, 264, 13759, 281, 1536, 438, 721, 490, 1412, 51256], "temperature": 0.0, "avg_logprob": -0.12362386241103664, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.00019373312534298748}, {"id": 513, "seek": 368056, "start": 3701.7599999999998, "end": 3708.88, "text": " and computation. And so that's the generative model's success where they can pretty much", "tokens": [51424, 293, 24903, 13, 400, 370, 300, 311, 264, 1337, 1166, 2316, 311, 2245, 689, 436, 393, 1238, 709, 51780], "temperature": 0.0, "avg_logprob": -0.12362386241103664, "compression_ratio": 1.528735632183908, "no_speech_prob": 0.00019373312534298748}, {"id": 514, "seek": 370888, "start": 3708.88, "end": 3714.96, "text": " infer. So the idea is that, okay, I don't need how to reason. Everything that I need to learn", "tokens": [50364, 13596, 13, 407, 264, 1558, 307, 300, 11, 1392, 11, 286, 500, 380, 643, 577, 281, 1778, 13, 5471, 300, 286, 643, 281, 1466, 50668], "temperature": 0.0, "avg_logprob": -0.07936351675736276, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0007901891367509961}, {"id": 515, "seek": 370888, "start": 3714.96, "end": 3720.48, "text": " about reasoning is already built into the millions and billions of textual data that is there.", "tokens": [50668, 466, 21577, 307, 1217, 3094, 666, 264, 6803, 293, 17375, 295, 2487, 901, 1412, 300, 307, 456, 13, 50944], "temperature": 0.0, "avg_logprob": -0.07936351675736276, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0007901891367509961}, {"id": 516, "seek": 370888, "start": 3721.04, "end": 3728.2400000000002, "text": " So if I have the ability to infer that, I will, even though I don't know that it is essentially", "tokens": [50972, 407, 498, 286, 362, 264, 3485, 281, 13596, 300, 11, 286, 486, 11, 754, 1673, 286, 500, 380, 458, 300, 309, 307, 4476, 51332], "temperature": 0.0, "avg_logprob": -0.07936351675736276, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0007901891367509961}, {"id": 517, "seek": 370888, "start": 3728.2400000000002, "end": 3736.1600000000003, "text": " a logical reasoning and maybe some things beyond. My guess is that a lot of the other things are", "tokens": [51332, 257, 14978, 21577, 293, 1310, 512, 721, 4399, 13, 1222, 2041, 307, 300, 257, 688, 295, 264, 661, 721, 366, 51728], "temperature": 0.0, "avg_logprob": -0.07936351675736276, "compression_ratio": 1.6933333333333334, "no_speech_prob": 0.0007901891367509961}, {"id": 518, "seek": 373616, "start": 3736.16, "end": 3744.7999999999997, "text": " built into our language structure very deeply. And to the extent that we can then", "tokens": [50364, 3094, 666, 527, 2856, 3877, 588, 8760, 13, 400, 281, 264, 8396, 300, 321, 393, 550, 50796], "temperature": 0.0, "avg_logprob": -0.11454502908807052, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0013230742188170552}, {"id": 519, "seek": 373616, "start": 3746.56, "end": 3753.92, "text": " reintegrate that, re-manipulate that, use that as a foundation for thinking in new ways, we can", "tokens": [50884, 319, 31131, 473, 300, 11, 319, 12, 1601, 647, 5256, 300, 11, 764, 300, 382, 257, 7030, 337, 1953, 294, 777, 2098, 11, 321, 393, 51252], "temperature": 0.0, "avg_logprob": -0.11454502908807052, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0013230742188170552}, {"id": 520, "seek": 373616, "start": 3753.92, "end": 3758.8799999999997, "text": " build on it, but I don't think we are there yet. And this whole idea of causality, causal reasoning,", "tokens": [51252, 1322, 322, 309, 11, 457, 286, 500, 380, 519, 321, 366, 456, 1939, 13, 400, 341, 1379, 1558, 295, 3302, 1860, 11, 38755, 21577, 11, 51500], "temperature": 0.0, "avg_logprob": -0.11454502908807052, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0013230742188170552}, {"id": 521, "seek": 373616, "start": 3758.8799999999997, "end": 3765.8399999999997, "text": " causal inference and other things may fall in that space saying we don't yet know how to go", "tokens": [51500, 38755, 38253, 293, 661, 721, 815, 2100, 294, 300, 1901, 1566, 321, 500, 380, 1939, 458, 577, 281, 352, 51848], "temperature": 0.0, "avg_logprob": -0.11454502908807052, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0013230742188170552}, {"id": 522, "seek": 376584, "start": 3765.84, "end": 3771.92, "text": " about doing that, although that information is there. So the distinction between language", "tokens": [50364, 466, 884, 300, 11, 4878, 300, 1589, 307, 456, 13, 407, 264, 16844, 1296, 2856, 50668], "temperature": 0.0, "avg_logprob": -0.1313241133049353, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.0001738150604069233}, {"id": 523, "seek": 376584, "start": 3771.92, "end": 3779.6000000000004, "text": " and the data-driven approach is important and there is more to be done with this space than", "tokens": [50668, 293, 264, 1412, 12, 25456, 3109, 307, 1021, 293, 456, 307, 544, 281, 312, 1096, 365, 341, 1901, 813, 51052], "temperature": 0.0, "avg_logprob": -0.1313241133049353, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.0001738150604069233}, {"id": 524, "seek": 376584, "start": 3779.6000000000004, "end": 3791.84, "text": " what is out there. Oshin? Yeah, thanks for raising that issue, Praveen. And interestingly enough,", "tokens": [51052, 437, 307, 484, 456, 13, 422, 2716, 259, 30, 865, 11, 3231, 337, 11225, 300, 2734, 11, 12133, 303, 268, 13, 400, 25873, 1547, 11, 51664], "temperature": 0.0, "avg_logprob": -0.1313241133049353, "compression_ratio": 1.516304347826087, "no_speech_prob": 0.0001738150604069233}, {"id": 525, "seek": 379184, "start": 3791.92, "end": 3803.76, "text": " I just came across this paper about something called Dreamcoder. And if you read down here,", "tokens": [50368, 286, 445, 1361, 2108, 341, 3035, 466, 746, 1219, 12105, 66, 19866, 13, 400, 498, 291, 1401, 760, 510, 11, 50960], "temperature": 0.0, "avg_logprob": -0.12658312361119156, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.002177618443965912}, {"id": 526, "seek": 379184, "start": 3804.8, "end": 3809.92, "text": " it says we present Dreamcoder, a system that learns to solve problems by writing programs.", "tokens": [51012, 309, 1619, 321, 1974, 12105, 66, 19866, 11, 257, 1185, 300, 27152, 281, 5039, 2740, 538, 3579, 4268, 13, 51268], "temperature": 0.0, "avg_logprob": -0.12658312361119156, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.002177618443965912}, {"id": 527, "seek": 379184, "start": 3810.48, "end": 3815.2000000000003, "text": " It builds expertise by creating programming languages for expressing domain concepts.", "tokens": [51296, 467, 15182, 11769, 538, 4084, 9410, 8650, 337, 22171, 9274, 10392, 13, 51532], "temperature": 0.0, "avg_logprob": -0.12658312361119156, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.002177618443965912}, {"id": 528, "seek": 381520, "start": 3816.16, "end": 3822.56, "text": " A wake sleep learning algorithm alternately extends the language with new symbolic abstractions", "tokens": [50412, 316, 6634, 2817, 2539, 9284, 5400, 1592, 26448, 264, 2856, 365, 777, 25755, 12649, 626, 50732], "temperature": 0.0, "avg_logprob": -0.11683120975246677, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0056279925629496574}, {"id": 529, "seek": 381520, "start": 3822.56, "end": 3827.2799999999997, "text": " and trains the neural network on imagined and replayed problems. And then concepts are built", "tokens": [50732, 293, 16329, 264, 18161, 3209, 322, 16590, 293, 23836, 292, 2740, 13, 400, 550, 10392, 366, 3094, 50968], "temperature": 0.0, "avg_logprob": -0.11683120975246677, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0056279925629496574}, {"id": 530, "seek": 381520, "start": 3827.2799999999997, "end": 3832.96, "text": " compositionally from those learned earlier, yielding multilayered symbolic representations", "tokens": [50968, 12686, 379, 490, 729, 3264, 3071, 11, 11257, 278, 2120, 388, 320, 4073, 25755, 33358, 51252], "temperature": 0.0, "avg_logprob": -0.11683120975246677, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0056279925629496574}, {"id": 531, "seek": 381520, "start": 3832.96, "end": 3839.2, "text": " that are interpretable and transferable to new tasks. So anyway, I just thought it was interesting", "tokens": [51252, 300, 366, 7302, 712, 293, 5003, 712, 281, 777, 9608, 13, 407, 4033, 11, 286, 445, 1194, 309, 390, 1880, 51564], "temperature": 0.0, "avg_logprob": -0.11683120975246677, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.0056279925629496574}, {"id": 532, "seek": 383920, "start": 3839.2, "end": 3850.56, "text": " because there is actually now apparently some small breakthrough into developing machine learning", "tokens": [50364, 570, 456, 307, 767, 586, 7970, 512, 1359, 22397, 666, 6416, 3479, 2539, 50932], "temperature": 0.0, "avg_logprob": -0.13874684847318208, "compression_ratio": 1.7421383647798743, "no_speech_prob": 0.00186535797547549}, {"id": 533, "seek": 383920, "start": 3851.7599999999998, "end": 3856.8799999999997, "text": " structures where learning concepts and extending language much in the way that we", "tokens": [50992, 9227, 689, 2539, 10392, 293, 24360, 2856, 709, 294, 264, 636, 300, 321, 51248], "temperature": 0.0, "avg_logprob": -0.13874684847318208, "compression_ratio": 1.7421383647798743, "no_speech_prob": 0.00186535797547549}, {"id": 534, "seek": 383920, "start": 3858.24, "end": 3864.96, "text": " learn concepts and extend language in order to do reasoning and causal reasoning and all of that.", "tokens": [51316, 1466, 10392, 293, 10101, 2856, 294, 1668, 281, 360, 21577, 293, 38755, 21577, 293, 439, 295, 300, 13, 51652], "temperature": 0.0, "avg_logprob": -0.13874684847318208, "compression_ratio": 1.7421383647798743, "no_speech_prob": 0.00186535797547549}, {"id": 535, "seek": 386496, "start": 3864.96, "end": 3868.16, "text": " So that's actually an interesting, we're just starting to happen.", "tokens": [50364, 407, 300, 311, 767, 364, 1880, 11, 321, 434, 445, 2891, 281, 1051, 13, 50524], "temperature": 0.0, "avg_logprob": -0.1354620841241652, "compression_ratio": 1.4764705882352942, "no_speech_prob": 0.0008649583905935287}, {"id": 536, "seek": 386496, "start": 3872.0, "end": 3879.36, "text": " Yeah, I would say that, I mean, I think we are at the beginning of a breakthrough in these", "tokens": [50716, 865, 11, 286, 576, 584, 300, 11, 286, 914, 11, 286, 519, 321, 366, 412, 264, 2863, 295, 257, 22397, 294, 613, 51084], "temperature": 0.0, "avg_logprob": -0.1354620841241652, "compression_ratio": 1.4764705882352942, "no_speech_prob": 0.0008649583905935287}, {"id": 537, "seek": 386496, "start": 3880.08, "end": 3888.48, "text": " things. We are now assembling essential tools that may help us move this to expect these tools", "tokens": [51120, 721, 13, 492, 366, 586, 43867, 7115, 3873, 300, 815, 854, 505, 1286, 341, 281, 2066, 613, 3873, 51540], "temperature": 0.0, "avg_logprob": -0.1354620841241652, "compression_ratio": 1.4764705882352942, "no_speech_prob": 0.0008649583905935287}, {"id": 538, "seek": 388848, "start": 3889.36, "end": 3894.88, "text": " that are not trained or developed for a specific task to inherently be able to do that.", "tokens": [50408, 300, 366, 406, 8895, 420, 4743, 337, 257, 2685, 5633, 281, 27993, 312, 1075, 281, 360, 300, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10742984279509514, "compression_ratio": 1.5, "no_speech_prob": 0.0003296469512861222}, {"id": 539, "seek": 388848, "start": 3895.76, "end": 3902.8, "text": " I think it's a little far, but there needs to be more and that's an opportunity for us.", "tokens": [50728, 286, 519, 309, 311, 257, 707, 1400, 11, 457, 456, 2203, 281, 312, 544, 293, 300, 311, 364, 2650, 337, 505, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10742984279509514, "compression_ratio": 1.5, "no_speech_prob": 0.0003296469512861222}, {"id": 540, "seek": 388848, "start": 3908.88, "end": 3913.84, "text": " From an information theory perspective, this brings me back to the fact that", "tokens": [51384, 3358, 364, 1589, 5261, 4585, 11, 341, 5607, 385, 646, 281, 264, 1186, 300, 51632], "temperature": 0.0, "avg_logprob": -0.10742984279509514, "compression_ratio": 1.5, "no_speech_prob": 0.0003296469512861222}, {"id": 541, "seek": 391384, "start": 3914.1600000000003, "end": 3922.6400000000003, "text": " everything we do is based on embeddings. We take objects or concepts and we build embeddings", "tokens": [50380, 1203, 321, 360, 307, 2361, 322, 12240, 29432, 13, 492, 747, 6565, 420, 10392, 293, 321, 1322, 12240, 29432, 50804], "temperature": 0.0, "avg_logprob": -0.17133550174900744, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004042371001560241}, {"id": 542, "seek": 391384, "start": 3922.6400000000003, "end": 3929.52, "text": " out of them, which are then manipulated using reasoning machine learning or whether it's human", "tokens": [50804, 484, 295, 552, 11, 597, 366, 550, 37161, 1228, 21577, 3479, 2539, 420, 1968, 309, 311, 1952, 51148], "temperature": 0.0, "avg_logprob": -0.17133550174900744, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004042371001560241}, {"id": 543, "seek": 391384, "start": 3930.1600000000003, "end": 3937.6000000000004, "text": " or machines. And so we start with symbols. The symbols are represented by embeddings", "tokens": [51180, 420, 8379, 13, 400, 370, 321, 722, 365, 16944, 13, 440, 16944, 366, 10379, 538, 12240, 29432, 51552], "temperature": 0.0, "avg_logprob": -0.17133550174900744, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0004042371001560241}, {"id": 544, "seek": 393760, "start": 3938.56, "end": 3943.36, "text": " and that's an information theory problem. How do we choose the correct embedding,", "tokens": [50412, 293, 300, 311, 364, 1589, 5261, 1154, 13, 1012, 360, 321, 2826, 264, 3006, 12240, 3584, 11, 50652], "temperature": 0.0, "avg_logprob": -0.09502746212866998, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.0006981806363910437}, {"id": 545, "seek": 393760, "start": 3944.0, "end": 3950.0, "text": " which represents the information, all of the necessary and relevant information,", "tokens": [50684, 597, 8855, 264, 1589, 11, 439, 295, 264, 4818, 293, 7340, 1589, 11, 50984], "temperature": 0.0, "avg_logprob": -0.09502746212866998, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.0006981806363910437}, {"id": 546, "seek": 393760, "start": 3951.36, "end": 3955.92, "text": " which can then be processed? And how do you then represent that information in a way that can", "tokens": [51052, 597, 393, 550, 312, 18846, 30, 400, 577, 360, 291, 550, 2906, 300, 1589, 294, 257, 636, 300, 393, 51280], "temperature": 0.0, "avg_logprob": -0.09502746212866998, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.0006981806363910437}, {"id": 547, "seek": 393760, "start": 3955.92, "end": 3960.56, "text": " actually be manipulated using the tools that are available to us in machine learning that's", "tokens": [51280, 767, 312, 37161, 1228, 264, 3873, 300, 366, 2435, 281, 505, 294, 3479, 2539, 300, 311, 51512], "temperature": 0.0, "avg_logprob": -0.09502746212866998, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.0006981806363910437}, {"id": 548, "seek": 393760, "start": 3960.56, "end": 3966.16, "text": " typically using vectors, vector spaces and being able to do dot products in order to", "tokens": [51512, 5850, 1228, 18875, 11, 8062, 7673, 293, 885, 1075, 281, 360, 5893, 3383, 294, 1668, 281, 51792], "temperature": 0.0, "avg_logprob": -0.09502746212866998, "compression_ratio": 1.7966804979253113, "no_speech_prob": 0.0006981806363910437}, {"id": 549, "seek": 396616, "start": 3966.8799999999997, "end": 3973.68, "text": " do similarity operations, to add vectors in order to do addition and subtraction operations,", "tokens": [50400, 360, 32194, 7705, 11, 281, 909, 18875, 294, 1668, 281, 360, 4500, 293, 16390, 313, 7705, 11, 50740], "temperature": 0.0, "avg_logprob": -0.11910290664501405, "compression_ratio": 1.914572864321608, "no_speech_prob": 0.0003248304419685155}, {"id": 550, "seek": 396616, "start": 3974.64, "end": 3979.7599999999998, "text": " sort of logical things that are involved in logical reasoning. But then on top of those", "tokens": [50788, 1333, 295, 14978, 721, 300, 366, 3288, 294, 14978, 21577, 13, 583, 550, 322, 1192, 295, 729, 51044], "temperature": 0.0, "avg_logprob": -0.11910290664501405, "compression_ratio": 1.914572864321608, "no_speech_prob": 0.0003248304419685155}, {"id": 551, "seek": 396616, "start": 3979.7599999999998, "end": 3984.72, "text": " concepts, we have to, on top of those embeddings, we have to build concepts, which are collections of", "tokens": [51044, 10392, 11, 321, 362, 281, 11, 322, 1192, 295, 729, 12240, 29432, 11, 321, 362, 281, 1322, 10392, 11, 597, 366, 16641, 295, 51292], "temperature": 0.0, "avg_logprob": -0.11910290664501405, "compression_ratio": 1.914572864321608, "no_speech_prob": 0.0003248304419685155}, {"id": 552, "seek": 396616, "start": 3984.72, "end": 3991.8399999999997, "text": " these. And from those, we have to build languages. And when we build languages, which are minimum,", "tokens": [51292, 613, 13, 400, 490, 729, 11, 321, 362, 281, 1322, 8650, 13, 400, 562, 321, 1322, 8650, 11, 597, 366, 7285, 11, 51648], "temperature": 0.0, "avg_logprob": -0.11910290664501405, "compression_ratio": 1.914572864321608, "no_speech_prob": 0.0003248304419685155}, {"id": 553, "seek": 399184, "start": 3991.84, "end": 3997.84, "text": " which are shorter description length representations of concepts, we're then able to do reasoning", "tokens": [50364, 597, 366, 11639, 3855, 4641, 33358, 295, 10392, 11, 321, 434, 550, 1075, 281, 360, 21577, 50664], "temperature": 0.0, "avg_logprob": -0.10716411590576172, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005184643086977303}, {"id": 554, "seek": 399184, "start": 3997.84, "end": 4005.2000000000003, "text": " using those higher level objects or concepts. And so I kind of have been seeing this kind of", "tokens": [50664, 1228, 729, 2946, 1496, 6565, 420, 10392, 13, 400, 370, 286, 733, 295, 362, 668, 2577, 341, 733, 295, 51032], "temperature": 0.0, "avg_logprob": -0.10716411590576172, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005184643086977303}, {"id": 555, "seek": 399184, "start": 4005.2000000000003, "end": 4010.0, "text": " structure emerging in the machine learning, particularly in the context of evolutionary", "tokens": [51032, 3877, 14989, 294, 264, 3479, 2539, 11, 4098, 294, 264, 4319, 295, 27567, 51272], "temperature": 0.0, "avg_logprob": -0.10716411590576172, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005184643086977303}, {"id": 556, "seek": 399184, "start": 4010.0, "end": 4016.88, "text": " robotics and artificial intelligence. But I think it provides an interesting way for us to think", "tokens": [51272, 34145, 293, 11677, 7599, 13, 583, 286, 519, 309, 6417, 364, 1880, 636, 337, 505, 281, 519, 51616], "temperature": 0.0, "avg_logprob": -0.10716411590576172, "compression_ratio": 1.5957446808510638, "no_speech_prob": 0.0005184643086977303}, {"id": 557, "seek": 401688, "start": 4016.88, "end": 4024.7200000000003, "text": " about how we actually process information using the tools of algorithmic information theory and", "tokens": [50364, 466, 577, 321, 767, 1399, 1589, 1228, 264, 3873, 295, 9284, 299, 1589, 5261, 293, 50756], "temperature": 0.0, "avg_logprob": -0.11743612642641421, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.0008272991981357336}, {"id": 558, "seek": 401688, "start": 4024.7200000000003, "end": 4032.7200000000003, "text": " Shannon information and how that leads to us being able to build sort of these informational", "tokens": [50756, 28974, 1589, 293, 577, 300, 6689, 281, 505, 885, 1075, 281, 1322, 1333, 295, 613, 49391, 51156], "temperature": 0.0, "avg_logprob": -0.11743612642641421, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.0008272991981357336}, {"id": 559, "seek": 401688, "start": 4032.7200000000003, "end": 4038.1600000000003, "text": " pyramids or, you know, things where we can, we can think about things at lower levels of the hierarchy", "tokens": [51156, 20543, 3742, 420, 11, 291, 458, 11, 721, 689, 321, 393, 11, 321, 393, 519, 466, 721, 412, 3126, 4358, 295, 264, 22333, 51428], "temperature": 0.0, "avg_logprob": -0.11743612642641421, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.0008272991981357336}, {"id": 560, "seek": 401688, "start": 4038.1600000000003, "end": 4042.8, "text": " and then at higher levels of the hierarchy and actually do these sort of intelligent processing.", "tokens": [51428, 293, 550, 412, 2946, 4358, 295, 264, 22333, 293, 767, 360, 613, 1333, 295, 13232, 9007, 13, 51660], "temperature": 0.0, "avg_logprob": -0.11743612642641421, "compression_ratio": 1.8743961352657006, "no_speech_prob": 0.0008272991981357336}, {"id": 561, "seek": 404280, "start": 4042.8, "end": 4050.32, "text": " Yeah, no, I agree with that completely. And I think the generative models, the transformers are", "tokens": [50364, 865, 11, 572, 11, 286, 3986, 365, 300, 2584, 13, 400, 286, 519, 264, 1337, 1166, 5245, 11, 264, 4088, 433, 366, 50740], "temperature": 0.0, "avg_logprob": -0.18617843299783687, "compression_ratio": 1.68, "no_speech_prob": 0.00071510742418468}, {"id": 562, "seek": 404280, "start": 4050.32, "end": 4056.4, "text": " built on the series of embeddings. I mean, it's a recursive embedding process that generates these", "tokens": [50740, 3094, 322, 264, 2638, 295, 12240, 29432, 13, 286, 914, 11, 309, 311, 257, 20560, 488, 12240, 3584, 1399, 300, 23815, 613, 51044], "temperature": 0.0, "avg_logprob": -0.18617843299783687, "compression_ratio": 1.68, "no_speech_prob": 0.00071510742418468}, {"id": 563, "seek": 404280, "start": 4056.4, "end": 4063.2000000000003, "text": " parameters and estimation of these parameters across these things. And one of the things which", "tokens": [51044, 9834, 293, 35701, 295, 613, 9834, 2108, 613, 721, 13, 400, 472, 295, 264, 721, 597, 51384], "temperature": 0.0, "avg_logprob": -0.18617843299783687, "compression_ratio": 1.68, "no_speech_prob": 0.00071510742418468}, {"id": 564, "seek": 404280, "start": 4063.2000000000003, "end": 4070.1600000000003, "text": " we are trying to explore with Hersh is, well, they're a way for us to modify that to see", "tokens": [51384, 321, 366, 1382, 281, 6839, 365, 41222, 71, 307, 11, 731, 11, 436, 434, 257, 636, 337, 505, 281, 16927, 300, 281, 536, 51732], "temperature": 0.0, "avg_logprob": -0.18617843299783687, "compression_ratio": 1.68, "no_speech_prob": 0.00071510742418468}, {"id": 565, "seek": 407016, "start": 4070.7999999999997, "end": 4078.3999999999996, "text": " causal reasoning can be extracted using that embedding structure. So that's a big question.", "tokens": [50396, 38755, 21577, 393, 312, 34086, 1228, 300, 12240, 3584, 3877, 13, 407, 300, 311, 257, 955, 1168, 13, 50776], "temperature": 0.0, "avg_logprob": -0.11738684037152458, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00034572850563563406}, {"id": 566, "seek": 407016, "start": 4079.44, "end": 4085.44, "text": " So the thing that bothers me a lot is sometimes we may be using embeddings that are not", "tokens": [50828, 407, 264, 551, 300, 33980, 385, 257, 688, 307, 2171, 321, 815, 312, 1228, 12240, 29432, 300, 366, 406, 51128], "temperature": 0.0, "avg_logprob": -0.11738684037152458, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00034572850563563406}, {"id": 567, "seek": 407016, "start": 4086.3999999999996, "end": 4090.64, "text": " properly informative. If I just give you a stream of stream flow and I treat,", "tokens": [51176, 6108, 27759, 13, 759, 286, 445, 976, 291, 257, 4309, 295, 4309, 3095, 293, 286, 2387, 11, 51388], "temperature": 0.0, "avg_logprob": -0.11738684037152458, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00034572850563563406}, {"id": 568, "seek": 407016, "start": 4091.8399999999997, "end": 4096.4, "text": " let's say I give you rainfall potential evaporation and stream flow, and those are three values,", "tokens": [51448, 718, 311, 584, 286, 976, 291, 29382, 3995, 1073, 569, 9357, 293, 4309, 3095, 11, 293, 729, 366, 1045, 4190, 11, 51676], "temperature": 0.0, "avg_logprob": -0.11738684037152458, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.00034572850563563406}, {"id": 569, "seek": 409640, "start": 4096.4, "end": 4100.879999999999, "text": " and I just put them in a vector. And I'm telling you at this point in time, this is the vector,", "tokens": [50364, 293, 286, 445, 829, 552, 294, 257, 8062, 13, 400, 286, 478, 3585, 291, 412, 341, 935, 294, 565, 11, 341, 307, 264, 8062, 11, 50588], "temperature": 0.0, "avg_logprob": -0.1007109003618729, "compression_ratio": 1.9958677685950412, "no_speech_prob": 0.0010980963706970215}, {"id": 570, "seek": 409640, "start": 4100.879999999999, "end": 4104.799999999999, "text": " and next point in time, this is the vector, and this is, you know, and I've got these three values.", "tokens": [50588, 293, 958, 935, 294, 565, 11, 341, 307, 264, 8062, 11, 293, 341, 307, 11, 291, 458, 11, 293, 286, 600, 658, 613, 1045, 4190, 13, 50784], "temperature": 0.0, "avg_logprob": -0.1007109003618729, "compression_ratio": 1.9958677685950412, "no_speech_prob": 0.0010980963706970215}, {"id": 571, "seek": 409640, "start": 4106.32, "end": 4110.799999999999, "text": " If I'm not telling you whether the stream flow is going up or going down at that point in time,", "tokens": [50860, 759, 286, 478, 406, 3585, 291, 1968, 264, 4309, 3095, 307, 516, 493, 420, 516, 760, 412, 300, 935, 294, 565, 11, 51084], "temperature": 0.0, "avg_logprob": -0.1007109003618729, "compression_ratio": 1.9958677685950412, "no_speech_prob": 0.0010980963706970215}, {"id": 572, "seek": 409640, "start": 4111.5199999999995, "end": 4116.879999999999, "text": " or whether the, but the energy is increasing or decreasing or the rainfall is increasing or", "tokens": [51120, 420, 1968, 264, 11, 457, 264, 2281, 307, 5662, 420, 23223, 420, 264, 29382, 307, 5662, 420, 51388], "temperature": 0.0, "avg_logprob": -0.1007109003618729, "compression_ratio": 1.9958677685950412, "no_speech_prob": 0.0010980963706970215}, {"id": 573, "seek": 409640, "start": 4116.879999999999, "end": 4122.4, "text": " decreasing, I might be giving an embedding which is not sufficiently informative for you to be able", "tokens": [51388, 23223, 11, 286, 1062, 312, 2902, 364, 12240, 3584, 597, 307, 406, 31868, 27759, 337, 291, 281, 312, 1075, 51664], "temperature": 0.0, "avg_logprob": -0.1007109003618729, "compression_ratio": 1.9958677685950412, "no_speech_prob": 0.0010980963706970215}, {"id": 574, "seek": 412240, "start": 4122.4, "end": 4131.839999999999, "text": " to do meaningful inference. And so thinking about how we develop our data embeddings as a first", "tokens": [50364, 281, 360, 10995, 38253, 13, 400, 370, 1953, 466, 577, 321, 1499, 527, 1412, 12240, 29432, 382, 257, 700, 50836], "temperature": 0.0, "avg_logprob": -0.10825227478803215, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.00033995273406617343}, {"id": 575, "seek": 412240, "start": 4131.839999999999, "end": 4135.679999999999, "text": " step before we even present them to our algorithm seems to be an important step.", "tokens": [50836, 1823, 949, 321, 754, 1974, 552, 281, 527, 9284, 2544, 281, 312, 364, 1021, 1823, 13, 51028], "temperature": 0.0, "avg_logprob": -0.10825227478803215, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.00033995273406617343}, {"id": 576, "seek": 412240, "start": 4136.799999999999, "end": 4143.04, "text": " Yeah, or get the algorithms to basically build on the initial embedding to explore", "tokens": [51084, 865, 11, 420, 483, 264, 14642, 281, 1936, 1322, 322, 264, 5883, 12240, 3584, 281, 6839, 51396], "temperature": 0.0, "avg_logprob": -0.10825227478803215, "compression_ratio": 1.5416666666666667, "no_speech_prob": 0.00033995273406617343}, {"id": 577, "seek": 414304, "start": 4143.04, "end": 4150.4, "text": " alternates and see what makes sense. Correct. I was going to ask if in on this question of", "tokens": [50364, 5400, 1024, 293, 536, 437, 1669, 2020, 13, 12753, 13, 286, 390, 516, 281, 1029, 498, 294, 322, 341, 1168, 295, 50732], "temperature": 0.0, "avg_logprob": -0.13776293108540197, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0032697548158466816}, {"id": 578, "seek": 414304, "start": 4150.4, "end": 4157.2, "text": " embeddings, it would be difficult for a language model to speak on causality because usually we", "tokens": [50732, 12240, 29432, 11, 309, 576, 312, 2252, 337, 257, 2856, 2316, 281, 1710, 322, 3302, 1860, 570, 2673, 321, 51072], "temperature": 0.0, "avg_logprob": -0.13776293108540197, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0032697548158466816}, {"id": 579, "seek": 414304, "start": 4157.2, "end": 4164.88, "text": " reason about causality in terms of graphs. And as I understand, there in the large language model,", "tokens": [51072, 1778, 466, 3302, 1860, 294, 2115, 295, 24877, 13, 400, 382, 286, 1223, 11, 456, 294, 264, 2416, 2856, 2316, 11, 51456], "temperature": 0.0, "avg_logprob": -0.13776293108540197, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0032697548158466816}, {"id": 580, "seek": 414304, "start": 4164.88, "end": 4170.64, "text": " there, there's no structure of a graph. So maybe it's using the wrong embedding to speak about", "tokens": [51456, 456, 11, 456, 311, 572, 3877, 295, 257, 4295, 13, 407, 1310, 309, 311, 1228, 264, 2085, 12240, 3584, 281, 1710, 466, 51744], "temperature": 0.0, "avg_logprob": -0.13776293108540197, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0032697548158466816}, {"id": 581, "seek": 417064, "start": 4170.64, "end": 4176.4800000000005, "text": " causality, maybe the language model understands causality in a different way, in a different", "tokens": [50364, 3302, 1860, 11, 1310, 264, 2856, 2316, 15146, 3302, 1860, 294, 257, 819, 636, 11, 294, 257, 819, 50656], "temperature": 0.0, "avg_logprob": -0.12983466111696684, "compression_ratio": 1.8031496062992125, "no_speech_prob": 0.00019090947171207517}, {"id": 582, "seek": 417064, "start": 4176.4800000000005, "end": 4183.360000000001, "text": " embedding than we typically would analyze causality. I don't think it's necessary. Well,", "tokens": [50656, 12240, 3584, 813, 321, 5850, 576, 12477, 3302, 1860, 13, 286, 500, 380, 519, 309, 311, 4818, 13, 1042, 11, 51000], "temperature": 0.0, "avg_logprob": -0.12983466111696684, "compression_ratio": 1.8031496062992125, "no_speech_prob": 0.00019090947171207517}, {"id": 583, "seek": 417064, "start": 4183.360000000001, "end": 4187.92, "text": " Praveen can probably answer this better, but I don't think it's necessarily true that a large", "tokens": [51000, 12133, 303, 268, 393, 1391, 1867, 341, 1101, 11, 457, 286, 500, 380, 519, 309, 311, 4725, 2074, 300, 257, 2416, 51228], "temperature": 0.0, "avg_logprob": -0.12983466111696684, "compression_ratio": 1.8031496062992125, "no_speech_prob": 0.00019090947171207517}, {"id": 584, "seek": 417064, "start": 4187.92, "end": 4193.12, "text": " language model and graphs are not the same thing, because a large language model can be", "tokens": [51228, 2856, 2316, 293, 24877, 366, 406, 264, 912, 551, 11, 570, 257, 2416, 2856, 2316, 393, 312, 51488], "temperature": 0.0, "avg_logprob": -0.12983466111696684, "compression_ratio": 1.8031496062992125, "no_speech_prob": 0.00019090947171207517}, {"id": 585, "seek": 417064, "start": 4193.12, "end": 4199.04, "text": " thought of as a very high dimensional joint probability density function. And that's basically", "tokens": [51488, 1194, 295, 382, 257, 588, 1090, 18795, 7225, 8482, 10305, 2445, 13, 400, 300, 311, 1936, 51784], "temperature": 0.0, "avg_logprob": -0.12983466111696684, "compression_ratio": 1.8031496062992125, "no_speech_prob": 0.00019090947171207517}, {"id": 586, "seek": 419904, "start": 4200.0, "end": 4204.64, "text": " how we build those is by using building graphs, right, of conditional probabilities and so on.", "tokens": [50412, 577, 321, 1322, 729, 307, 538, 1228, 2390, 24877, 11, 558, 11, 295, 27708, 33783, 293, 370, 322, 13, 50644], "temperature": 0.0, "avg_logprob": -0.17639292348729502, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0016439853934571147}, {"id": 587, "seek": 419904, "start": 4206.4, "end": 4211.5199999999995, "text": " Antoine and Praveen isn't it true that that's what a lot of, what's his names,", "tokens": [50732, 5130, 44454, 293, 12133, 303, 268, 1943, 380, 309, 2074, 300, 300, 311, 437, 257, 688, 295, 11, 437, 311, 702, 5288, 11, 50988], "temperature": 0.0, "avg_logprob": -0.17639292348729502, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0016439853934571147}, {"id": 588, "seek": 419904, "start": 4213.2, "end": 4219.6, "text": " the father of causal inference, I forget his name. Perl? Perl. Perl, a lot of his work was", "tokens": [51072, 264, 3086, 295, 38755, 38253, 11, 286, 2870, 702, 1315, 13, 3026, 75, 30, 3026, 75, 13, 3026, 75, 11, 257, 688, 295, 702, 589, 390, 51392], "temperature": 0.0, "avg_logprob": -0.17639292348729502, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0016439853934571147}, {"id": 589, "seek": 419904, "start": 4219.6, "end": 4226.88, "text": " based on that, that the fact that those two are essentially the same thing. Yeah. Yeah. I mean,", "tokens": [51392, 2361, 322, 300, 11, 300, 264, 1186, 300, 729, 732, 366, 4476, 264, 912, 551, 13, 865, 13, 865, 13, 286, 914, 11, 51756], "temperature": 0.0, "avg_logprob": -0.17639292348729502, "compression_ratio": 1.651376146788991, "no_speech_prob": 0.0016439853934571147}, {"id": 590, "seek": 422688, "start": 4227.4400000000005, "end": 4234.4800000000005, "text": " the representation of causality as a graphical model came out of Perl and then quantified by", "tokens": [50392, 264, 10290, 295, 3302, 1860, 382, 257, 35942, 2316, 1361, 484, 295, 3026, 75, 293, 550, 4426, 2587, 538, 50744], "temperature": 0.0, "avg_logprob": -0.09768333642379097, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.00125898199621588}, {"id": 591, "seek": 422688, "start": 4235.12, "end": 4242.08, "text": " Sprites. I put that link in the chat. There's a nice book by Sprites, which I recommend to", "tokens": [50776, 7702, 3324, 13, 286, 829, 300, 2113, 294, 264, 5081, 13, 821, 311, 257, 1481, 1446, 538, 7702, 3324, 11, 597, 286, 2748, 281, 51124], "temperature": 0.0, "avg_logprob": -0.09768333642379097, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.00125898199621588}, {"id": 592, "seek": 422688, "start": 4242.08, "end": 4247.84, "text": " everybody to read a minute, just helps lay that down on how to do this in a mathematical", "tokens": [51124, 2201, 281, 1401, 257, 3456, 11, 445, 3665, 2360, 300, 760, 322, 577, 281, 360, 341, 294, 257, 18894, 51412], "temperature": 0.0, "avg_logprob": -0.09768333642379097, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.00125898199621588}, {"id": 593, "seek": 422688, "start": 4247.84, "end": 4254.64, "text": " way and how to think about it. But I think the real question that we haven't yet answered", "tokens": [51412, 636, 293, 577, 281, 519, 466, 309, 13, 583, 286, 519, 264, 957, 1168, 300, 321, 2378, 380, 1939, 10103, 51752], "temperature": 0.0, "avg_logprob": -0.09768333642379097, "compression_ratio": 1.5603448275862069, "no_speech_prob": 0.00125898199621588}, {"id": 594, "seek": 425464, "start": 4255.52, "end": 4262.72, "text": " effectively is in our context where we are dealing with data in space and time,", "tokens": [50408, 8659, 307, 294, 527, 4319, 689, 321, 366, 6260, 365, 1412, 294, 1901, 293, 565, 11, 50768], "temperature": 0.0, "avg_logprob": -0.11016693711280823, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.0006456676637753844}, {"id": 595, "seek": 425464, "start": 4263.68, "end": 4270.64, "text": " what does causality mean? I mean, in a medical context, I mean, you can figure out whether", "tokens": [50816, 437, 775, 3302, 1860, 914, 30, 286, 914, 11, 294, 257, 4625, 4319, 11, 286, 914, 11, 291, 393, 2573, 484, 1968, 51164], "temperature": 0.0, "avg_logprob": -0.11016693711280823, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.0006456676637753844}, {"id": 596, "seek": 425464, "start": 4270.64, "end": 4279.280000000001, "text": " smoking causes cancer or not through a whole bunch of different things. But in our context,", "tokens": [51164, 14055, 7700, 5592, 420, 406, 807, 257, 1379, 3840, 295, 819, 721, 13, 583, 294, 527, 4319, 11, 51596], "temperature": 0.0, "avg_logprob": -0.11016693711280823, "compression_ratio": 1.5232558139534884, "no_speech_prob": 0.0006456676637753844}, {"id": 597, "seek": 427928, "start": 4279.28, "end": 4287.2, "text": " where we have potentially continuous space-time domain, it's easier to answer the question of", "tokens": [50364, 689, 321, 362, 7263, 10957, 1901, 12, 3766, 9274, 11, 309, 311, 3571, 281, 1867, 264, 1168, 295, 50760], "temperature": 0.0, "avg_logprob": -0.11869892707237831, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0007782174507156014}, {"id": 598, "seek": 427928, "start": 4287.2, "end": 4296.32, "text": " causality. The necessary condition for causality in time is breaking of symmetry in time. The", "tokens": [50760, 3302, 1860, 13, 440, 4818, 4188, 337, 3302, 1860, 294, 565, 307, 7697, 295, 25440, 294, 565, 13, 440, 51216], "temperature": 0.0, "avg_logprob": -0.11869892707237831, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0007782174507156014}, {"id": 599, "seek": 427928, "start": 4296.88, "end": 4302.48, "text": " past causes, the future, future cannot cause past. That's the necessary condition. Is that a", "tokens": [51244, 1791, 7700, 11, 264, 2027, 11, 2027, 2644, 3082, 1791, 13, 663, 311, 264, 4818, 4188, 13, 1119, 300, 257, 51524], "temperature": 0.0, "avg_logprob": -0.11869892707237831, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.0007782174507156014}, {"id": 600, "seek": 430248, "start": 4302.48, "end": 4310.24, "text": " sufficient condition or not? That has not been well answered. Now, if you extend that in space,", "tokens": [50364, 11563, 4188, 420, 406, 30, 663, 575, 406, 668, 731, 10103, 13, 823, 11, 498, 291, 10101, 300, 294, 1901, 11, 50752], "temperature": 0.0, "avg_logprob": -0.10632650144807584, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0009393657092005014}, {"id": 601, "seek": 430248, "start": 4310.24, "end": 4317.679999999999, "text": " there is no such framework. I mean, so then you have to ride on a vector space to basically", "tokens": [50752, 456, 307, 572, 1270, 8388, 13, 286, 914, 11, 370, 550, 291, 362, 281, 5077, 322, 257, 8062, 1901, 281, 1936, 51124], "temperature": 0.0, "avg_logprob": -0.10632650144807584, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0009393657092005014}, {"id": 602, "seek": 430248, "start": 4317.679999999999, "end": 4323.5199999999995, "text": " figure out a directionality and then say, okay, something that is happening in one space,", "tokens": [51124, 2573, 484, 257, 3513, 1860, 293, 550, 584, 11, 1392, 11, 746, 300, 307, 2737, 294, 472, 1901, 11, 51416], "temperature": 0.0, "avg_logprob": -0.10632650144807584, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0009393657092005014}, {"id": 603, "seek": 430248, "start": 4324.16, "end": 4329.599999999999, "text": " preclude something that is happening in another. You might ride on a river and say, okay,", "tokens": [51448, 4346, 32334, 746, 300, 307, 2737, 294, 1071, 13, 509, 1062, 5077, 322, 257, 6810, 293, 584, 11, 1392, 11, 51720], "temperature": 0.0, "avg_logprob": -0.10632650144807584, "compression_ratio": 1.6681818181818182, "no_speech_prob": 0.0009393657092005014}, {"id": 604, "seek": 432960, "start": 4329.6, "end": 4335.4400000000005, "text": " I'm going to forward. But then the whole issue of backwater propagation and all that thing happens", "tokens": [50364, 286, 478, 516, 281, 2128, 13, 583, 550, 264, 1379, 2734, 295, 646, 8002, 38377, 293, 439, 300, 551, 2314, 50656], "temperature": 0.0, "avg_logprob": -0.11709094047546387, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.000309989060042426}, {"id": 605, "seek": 432960, "start": 4335.4400000000005, "end": 4341.04, "text": " and then that can break down. So what is that framework? What do we mean when we say causality", "tokens": [50656, 293, 550, 300, 393, 1821, 760, 13, 407, 437, 307, 300, 8388, 30, 708, 360, 321, 914, 562, 321, 584, 3302, 1860, 50936], "temperature": 0.0, "avg_logprob": -0.11709094047546387, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.000309989060042426}, {"id": 606, "seek": 432960, "start": 4341.04, "end": 4347.200000000001, "text": " within the context of what we're dealing with has not been well defined? And that's a struggle", "tokens": [50936, 1951, 264, 4319, 295, 437, 321, 434, 6260, 365, 575, 406, 668, 731, 7642, 30, 400, 300, 311, 257, 7799, 51244], "temperature": 0.0, "avg_logprob": -0.11709094047546387, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.000309989060042426}, {"id": 607, "seek": 432960, "start": 4348.4800000000005, "end": 4356.8, "text": " in there. And then we anchor on surrogate processes. And Allison has done some work with", "tokens": [51308, 294, 456, 13, 400, 550, 321, 18487, 322, 1022, 6675, 473, 7555, 13, 400, 32638, 575, 1096, 512, 589, 365, 51724], "temperature": 0.0, "avg_logprob": -0.11709094047546387, "compression_ratio": 1.597457627118644, "no_speech_prob": 0.000309989060042426}, {"id": 608, "seek": 435680, "start": 4356.8, "end": 4361.84, "text": " information theory in which direction the information blows. I think like that. I mean, so", "tokens": [50364, 1589, 5261, 294, 597, 3513, 264, 1589, 18458, 13, 286, 519, 411, 300, 13, 286, 914, 11, 370, 50616], "temperature": 0.0, "avg_logprob": -0.0979707267846954, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0002822076785378158}, {"id": 609, "seek": 435680, "start": 4362.72, "end": 4368.64, "text": " those are good starting points and there might be some hint of how we may go about doing it.", "tokens": [50660, 729, 366, 665, 2891, 2793, 293, 456, 1062, 312, 512, 12075, 295, 577, 321, 815, 352, 466, 884, 309, 13, 50956], "temperature": 0.0, "avg_logprob": -0.0979707267846954, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0002822076785378158}, {"id": 610, "seek": 435680, "start": 4368.64, "end": 4373.28, "text": " But until we break through, we are going to be scratching this on the surface and hoping that", "tokens": [50956, 583, 1826, 321, 1821, 807, 11, 321, 366, 516, 281, 312, 29699, 341, 322, 264, 3753, 293, 7159, 300, 51188], "temperature": 0.0, "avg_logprob": -0.0979707267846954, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0002822076785378158}, {"id": 611, "seek": 435680, "start": 4373.28, "end": 4384.24, "text": " somehow some model is going to provide that input. So would it be fair to say that causality is a", "tokens": [51188, 6063, 512, 2316, 307, 516, 281, 2893, 300, 4846, 13, 407, 576, 309, 312, 3143, 281, 584, 300, 3302, 1860, 307, 257, 51736], "temperature": 0.0, "avg_logprob": -0.0979707267846954, "compression_ratio": 1.6816143497757847, "no_speech_prob": 0.0002822076785378158}, {"id": 612, "seek": 438424, "start": 4384.24, "end": 4391.36, "text": " representational assumption rather than a fact? In other words, it's a hypothesis we make about", "tokens": [50364, 2906, 1478, 15302, 2831, 813, 257, 1186, 30, 682, 661, 2283, 11, 309, 311, 257, 17291, 321, 652, 466, 50720], "temperature": 0.0, "avg_logprob": -0.08432238300641377, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006875701365061104}, {"id": 613, "seek": 438424, "start": 4391.36, "end": 4398.0, "text": " the world and we test. And just to take a simple example, if I just said rainfall and runoff,", "tokens": [50720, 264, 1002, 293, 321, 1500, 13, 400, 445, 281, 747, 257, 2199, 1365, 11, 498, 286, 445, 848, 29382, 293, 1190, 4506, 11, 51052], "temperature": 0.0, "avg_logprob": -0.08432238300641377, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006875701365061104}, {"id": 614, "seek": 438424, "start": 4398.96, "end": 4403.679999999999, "text": " and I ask you to say, does rain cause runoff? That's going to have all the problems that you", "tokens": [51100, 293, 286, 1029, 291, 281, 584, 11, 775, 4830, 3082, 1190, 4506, 30, 663, 311, 516, 281, 362, 439, 264, 2740, 300, 291, 51336], "temperature": 0.0, "avg_logprob": -0.08432238300641377, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006875701365061104}, {"id": 615, "seek": 438424, "start": 4403.679999999999, "end": 4412.16, "text": " just talked about, right? But there are causal effects. Increasing CO2 is causing climate change.", "tokens": [51336, 445, 2825, 466, 11, 558, 30, 583, 456, 366, 38755, 5065, 13, 30367, 3349, 3002, 17, 307, 9853, 5659, 1319, 13, 51760], "temperature": 0.0, "avg_logprob": -0.08432238300641377, "compression_ratio": 1.5637860082304527, "no_speech_prob": 0.0006875701365061104}, {"id": 616, "seek": 441216, "start": 4413.12, "end": 4423.2, "text": " And so there are definitely open causal issues. But my point is, are we treating causality as a", "tokens": [50412, 400, 370, 456, 366, 2138, 1269, 38755, 2663, 13, 583, 452, 935, 307, 11, 366, 321, 15083, 3302, 1860, 382, 257, 50916], "temperature": 0.0, "avg_logprob": -0.14188401452426253, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.000249113334575668}, {"id": 617, "seek": 441216, "start": 4423.2, "end": 4426.8, "text": " fact or are we treating causality as a representational explanation?", "tokens": [50916, 1186, 420, 366, 321, 15083, 3302, 1860, 382, 257, 2906, 1478, 10835, 30, 51096], "temperature": 0.0, "avg_logprob": -0.14188401452426253, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.000249113334575668}, {"id": 618, "seek": 441216, "start": 4429.2, "end": 4435.76, "text": " Yeah, we don't know that, right? I mean, probably that to go hand in hand, a certain type of", "tokens": [51216, 865, 11, 321, 500, 380, 458, 300, 11, 558, 30, 286, 914, 11, 1391, 300, 281, 352, 1011, 294, 1011, 11, 257, 1629, 2010, 295, 51544], "temperature": 0.0, "avg_logprob": -0.14188401452426253, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.000249113334575668}, {"id": 619, "seek": 441216, "start": 4435.76, "end": 4441.44, "text": " representation will help us infer a certain type of causality. But until we come up with", "tokens": [51544, 10290, 486, 854, 505, 13596, 257, 1629, 2010, 295, 3302, 1860, 13, 583, 1826, 321, 808, 493, 365, 51828], "temperature": 0.0, "avg_logprob": -0.14188401452426253, "compression_ratio": 1.7213930348258706, "no_speech_prob": 0.000249113334575668}, {"id": 620, "seek": 444144, "start": 4441.44, "end": 4451.12, "text": " proper definitions and proper classifications, I think what we end up doing is anchoring on a", "tokens": [50364, 2296, 21988, 293, 2296, 1508, 7833, 11, 286, 519, 437, 321, 917, 493, 884, 307, 12723, 3662, 322, 257, 50848], "temperature": 0.0, "avg_logprob": -0.10722828680469144, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.0006455965340137482}, {"id": 621, "seek": 444144, "start": 4451.12, "end": 4457.28, "text": " representation that is convenient and then infer causality associated with that representation.", "tokens": [50848, 10290, 300, 307, 10851, 293, 550, 13596, 3302, 1860, 6615, 365, 300, 10290, 13, 51156], "temperature": 0.0, "avg_logprob": -0.10722828680469144, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.0006455965340137482}, {"id": 622, "seek": 444144, "start": 4457.28, "end": 4462.799999999999, "text": " And then say, well, no, this represents everything we got. So structural causal model might fall into", "tokens": [51156, 400, 550, 584, 11, 731, 11, 572, 11, 341, 8855, 1203, 321, 658, 13, 407, 15067, 38755, 2316, 1062, 2100, 666, 51432], "temperature": 0.0, "avg_logprob": -0.10722828680469144, "compression_ratio": 1.5901639344262295, "no_speech_prob": 0.0006455965340137482}, {"id": 623, "seek": 446280, "start": 4462.8, "end": 4472.0, "text": " one of those categories. But yeah, I don't know the answer. I mean, I'm just articulating", "tokens": [50364, 472, 295, 729, 10479, 13, 583, 1338, 11, 286, 500, 380, 458, 264, 1867, 13, 286, 914, 11, 286, 478, 445, 15228, 12162, 50824], "temperature": 0.0, "avg_logprob": -0.13418043984307182, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.0004580261302180588}, {"id": 624, "seek": 446280, "start": 4472.88, "end": 4478.24, "text": " the questions that go through my mind. But I mean, if we take an extreme example,", "tokens": [50868, 264, 1651, 300, 352, 807, 452, 1575, 13, 583, 286, 914, 11, 498, 321, 747, 364, 8084, 1365, 11, 51136], "temperature": 0.0, "avg_logprob": -0.13418043984307182, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.0004580261302180588}, {"id": 625, "seek": 446280, "start": 4478.24, "end": 4486.16, "text": " like F is equal to MA, right? It's a structural representation that was come up with. And you", "tokens": [51136, 411, 479, 307, 2681, 281, 12191, 11, 558, 30, 467, 311, 257, 15067, 10290, 300, 390, 808, 493, 365, 13, 400, 291, 51532], "temperature": 0.0, "avg_logprob": -0.13418043984307182, "compression_ratio": 1.4095744680851063, "no_speech_prob": 0.0004580261302180588}, {"id": 626, "seek": 448616, "start": 4486.16, "end": 4494.08, "text": " test it, and it all never fails. We start to treat it as a fact of nature, right? Because it's", "tokens": [50364, 1500, 309, 11, 293, 309, 439, 1128, 18199, 13, 492, 722, 281, 2387, 309, 382, 257, 1186, 295, 3687, 11, 558, 30, 1436, 309, 311, 50760], "temperature": 0.0, "avg_logprob": -0.09141009341004075, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.0003739520034287125}, {"id": 627, "seek": 448616, "start": 4494.08, "end": 4503.2, "text": " a hypothesis that has never actually been disproved by a counterfactual, by an example that", "tokens": [50760, 257, 17291, 300, 575, 1128, 767, 668, 717, 4318, 937, 538, 257, 5682, 44919, 901, 11, 538, 364, 1365, 300, 51216], "temperature": 0.0, "avg_logprob": -0.09141009341004075, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.0003739520034287125}, {"id": 628, "seek": 448616, "start": 4503.2, "end": 4509.28, "text": " contradicts it. So maybe something similar with causality, you have a chain of reasoning,", "tokens": [51216, 28900, 82, 309, 13, 407, 1310, 746, 2531, 365, 3302, 1860, 11, 291, 362, 257, 5021, 295, 21577, 11, 51520], "temperature": 0.0, "avg_logprob": -0.09141009341004075, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.0003739520034287125}, {"id": 629, "seek": 448616, "start": 4509.28, "end": 4513.84, "text": " and if that chain of reasoning always holds up, then eventually you start to treat it as though", "tokens": [51520, 293, 498, 300, 5021, 295, 21577, 1009, 9190, 493, 11, 550, 4728, 291, 722, 281, 2387, 309, 382, 1673, 51748], "temperature": 0.0, "avg_logprob": -0.09141009341004075, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.0003739520034287125}, {"id": 630, "seek": 451384, "start": 4513.84, "end": 4523.2, "text": " it's a fact of nature. Probably. I mean, even if it equals MA is wrong in certain cases,", "tokens": [50364, 309, 311, 257, 1186, 295, 3687, 13, 9210, 13, 286, 914, 11, 754, 498, 309, 6915, 12191, 307, 2085, 294, 1629, 3331, 11, 50832], "temperature": 0.0, "avg_logprob": -0.16987041398590685, "compression_ratio": 1.267605633802817, "no_speech_prob": 0.0004954254836775362}, {"id": 631, "seek": 451384, "start": 4523.2, "end": 4532.88, "text": " like photons, it kind of brings the question of, is all of causality emergent? Can you have", "tokens": [50832, 411, 40209, 11, 309, 733, 295, 5607, 264, 1168, 295, 11, 307, 439, 295, 3302, 1860, 4345, 6930, 30, 1664, 291, 362, 51316], "temperature": 0.0, "avg_logprob": -0.16987041398590685, "compression_ratio": 1.267605633802817, "no_speech_prob": 0.0004954254836775362}, {"id": 632, "seek": 453288, "start": 4532.88, "end": 4540.24, "text": " fundamental laws that are causal? Or is everything kind of in a higher,", "tokens": [50364, 8088, 6064, 300, 366, 38755, 30, 1610, 307, 1203, 733, 295, 294, 257, 2946, 11, 50732], "temperature": 0.0, "avg_logprob": -0.25831635215065696, "compression_ratio": 1.3509933774834437, "no_speech_prob": 0.013215712271630764}, {"id": 633, "seek": 453288, "start": 4546.64, "end": 4550.72, "text": " kind of more broad context, complex systems?", "tokens": [51052, 733, 295, 544, 4152, 4319, 11, 3997, 3652, 30, 51256], "temperature": 0.0, "avg_logprob": -0.25831635215065696, "compression_ratio": 1.3509933774834437, "no_speech_prob": 0.013215712271630764}, {"id": 634, "seek": 453288, "start": 4552.32, "end": 4557.92, "text": " Well, if I can go back to ask Antoine a question. Well, go ahead and answer that first.", "tokens": [51336, 1042, 11, 498, 286, 393, 352, 646, 281, 1029, 5130, 44454, 257, 1168, 13, 1042, 11, 352, 2286, 293, 1867, 300, 700, 13, 51616], "temperature": 0.0, "avg_logprob": -0.25831635215065696, "compression_ratio": 1.3509933774834437, "no_speech_prob": 0.013215712271630764}, {"id": 635, "seek": 455792, "start": 4558.8, "end": 4565.28, "text": " I was just going to say, I think Ocean, I don't claim to have read Hume, but I think you summarize", "tokens": [50408, 286, 390, 445, 516, 281, 584, 11, 286, 519, 18101, 11, 286, 500, 380, 3932, 281, 362, 1401, 389, 2540, 11, 457, 286, 519, 291, 20858, 50732], "temperature": 0.0, "avg_logprob": -0.18033519245329357, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003818895434960723}, {"id": 636, "seek": 455792, "start": 4565.28, "end": 4576.56, "text": " Hume's argument that, you know, fundamentally, we can't know causality absolutely. But, you know,", "tokens": [50732, 389, 2540, 311, 6770, 300, 11, 291, 458, 11, 17879, 11, 321, 393, 380, 458, 3302, 1860, 3122, 13, 583, 11, 291, 458, 11, 51296], "temperature": 0.0, "avg_logprob": -0.18033519245329357, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003818895434960723}, {"id": 637, "seek": 455792, "start": 4576.56, "end": 4585.04, "text": " we can, we can, you know, strengthen our beliefs. And that sort of this is all very useful. I don't", "tokens": [51296, 321, 393, 11, 321, 393, 11, 291, 458, 11, 17045, 527, 13585, 13, 400, 300, 1333, 295, 341, 307, 439, 588, 4420, 13, 286, 500, 380, 51720], "temperature": 0.0, "avg_logprob": -0.18033519245329357, "compression_ratio": 1.574468085106383, "no_speech_prob": 0.003818895434960723}, {"id": 638, "seek": 458504, "start": 4585.5199999999995, "end": 4592.72, "text": " think Hume was trying to argue that, you know, we shouldn't be logical beings and throw out this,", "tokens": [50388, 519, 389, 2540, 390, 1382, 281, 9695, 300, 11, 291, 458, 11, 321, 4659, 380, 312, 14978, 8958, 293, 3507, 484, 341, 11, 50748], "temperature": 0.0, "avg_logprob": -0.10172806790000515, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0016733021475374699}, {"id": 639, "seek": 458504, "start": 4592.72, "end": 4598.0, "text": " these aspirations for understanding causality completely. And I think that's kind of what", "tokens": [50748, 613, 32458, 337, 3701, 3302, 1860, 2584, 13, 400, 286, 519, 300, 311, 733, 295, 437, 51012], "temperature": 0.0, "avg_logprob": -0.10172806790000515, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0016733021475374699}, {"id": 640, "seek": 458504, "start": 4598.0, "end": 4604.16, "text": " you're saying that, you know, yes, F equals MA is wrong, but it's, you know, right under,", "tokens": [51012, 291, 434, 1566, 300, 11, 291, 458, 11, 2086, 11, 479, 6915, 12191, 307, 2085, 11, 457, 309, 311, 11, 291, 458, 11, 558, 833, 11, 51320], "temperature": 0.0, "avg_logprob": -0.10172806790000515, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0016733021475374699}, {"id": 641, "seek": 458504, "start": 4605.76, "end": 4610.96, "text": " you know, most of the conditions that we encounter in our day to day. And so it can", "tokens": [51400, 291, 458, 11, 881, 295, 264, 4487, 300, 321, 8593, 294, 527, 786, 281, 786, 13, 400, 370, 309, 393, 51660], "temperature": 0.0, "avg_logprob": -0.10172806790000515, "compression_ratio": 1.6188340807174888, "no_speech_prob": 0.0016733021475374699}, {"id": 642, "seek": 461096, "start": 4610.96, "end": 4616.56, "text": " basically be taken as fact. And that's kind of what our definition of causality is.", "tokens": [50364, 1936, 312, 2726, 382, 1186, 13, 400, 300, 311, 733, 295, 437, 527, 7123, 295, 3302, 1860, 307, 13, 50644], "temperature": 0.0, "avg_logprob": -0.10836199772210768, "compression_ratio": 1.51, "no_speech_prob": 0.000968744105193764}, {"id": 643, "seek": 461096, "start": 4617.44, "end": 4622.88, "text": " It's right until it's wrong. But Antoine, going back to the large language models,", "tokens": [50688, 467, 311, 558, 1826, 309, 311, 2085, 13, 583, 5130, 44454, 11, 516, 646, 281, 264, 2416, 2856, 5245, 11, 50960], "temperature": 0.0, "avg_logprob": -0.10836199772210768, "compression_ratio": 1.51, "no_speech_prob": 0.000968744105193764}, {"id": 644, "seek": 461096, "start": 4626.56, "end": 4630.88, "text": " if these people who wrote all these papers were to take a bunch of", "tokens": [51144, 498, 613, 561, 567, 4114, 439, 613, 10577, 645, 281, 747, 257, 3840, 295, 51360], "temperature": 0.0, "avg_logprob": -0.10836199772210768, "compression_ratio": 1.51, "no_speech_prob": 0.000968744105193764}, {"id": 645, "seek": 461096, "start": 4632.4, "end": 4635.04, "text": " age roles, my daughter's eight, I'm just picking eight out of a hat,", "tokens": [51436, 3205, 9604, 11, 452, 4653, 311, 3180, 11, 286, 478, 445, 8867, 3180, 484, 295, 257, 2385, 11, 51568], "temperature": 0.0, "avg_logprob": -0.10836199772210768, "compression_ratio": 1.51, "no_speech_prob": 0.000968744105193764}, {"id": 646, "seek": 463504, "start": 4636.0, "end": 4642.24, "text": " and attempted to do these same tests on them, right? That's kind of what I was thinking about", "tokens": [50412, 293, 18997, 281, 360, 613, 912, 6921, 322, 552, 11, 558, 30, 663, 311, 733, 295, 437, 286, 390, 1953, 466, 50724], "temperature": 0.0, "avg_logprob": -0.13742703550002155, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0004799461748916656}, {"id": 647, "seek": 463504, "start": 4642.24, "end": 4647.04, "text": " when you said that they were testing these large language models to infer causality.", "tokens": [50724, 562, 291, 848, 300, 436, 645, 4997, 613, 2416, 2856, 5245, 281, 13596, 3302, 1860, 13, 50964], "temperature": 0.0, "avg_logprob": -0.13742703550002155, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0004799461748916656}, {"id": 648, "seek": 463504, "start": 4648.08, "end": 4654.24, "text": " If they ran these same tests on a bunch of eight-year-olds, you know, in other words,", "tokens": [51016, 759, 436, 5872, 613, 912, 6921, 322, 257, 3840, 295, 3180, 12, 5294, 12, 31518, 11, 291, 458, 11, 294, 661, 2283, 11, 51324], "temperature": 0.0, "avg_logprob": -0.13742703550002155, "compression_ratio": 1.543859649122807, "no_speech_prob": 0.0004799461748916656}, {"id": 649, "seek": 465424, "start": 4654.96, "end": 4662.88, "text": " how do they know that their tests are actually meaningful tests", "tokens": [50400, 577, 360, 436, 458, 300, 641, 6921, 366, 767, 10995, 6921, 50796], "temperature": 0.0, "avg_logprob": -0.13991820225950147, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.00926504097878933}, {"id": 650, "seek": 465424, "start": 4664.719999999999, "end": 4671.36, "text": " for establishing whether or not the LLM or the eight-year-old has the ability to", "tokens": [50888, 337, 22494, 1968, 420, 406, 264, 441, 43, 44, 420, 264, 3180, 12, 5294, 12, 2641, 575, 264, 3485, 281, 51220], "temperature": 0.0, "avg_logprob": -0.13991820225950147, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.00926504097878933}, {"id": 651, "seek": 465424, "start": 4672.719999999999, "end": 4683.12, "text": " cause inference? I don't think they do. I feel like this is what we're getting out of this", "tokens": [51288, 3082, 38253, 30, 286, 500, 380, 519, 436, 360, 13, 286, 841, 411, 341, 307, 437, 321, 434, 1242, 484, 295, 341, 51808], "temperature": 0.0, "avg_logprob": -0.13991820225950147, "compression_ratio": 1.4506172839506173, "no_speech_prob": 0.00926504097878933}, {"id": 652, "seek": 468312, "start": 4683.12, "end": 4687.84, "text": " discussion. It's like, what is causality in the end? And how can you be sure that it is", "tokens": [50364, 5017, 13, 467, 311, 411, 11, 437, 307, 3302, 1860, 294, 264, 917, 30, 400, 577, 393, 291, 312, 988, 300, 309, 307, 50600], "temperature": 0.0, "avg_logprob": -0.1237619654337565, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.006586223840713501}, {"id": 653, "seek": 468312, "start": 4687.84, "end": 4696.5599999999995, "text": " causality you're inferring and not logic reasoning as Timothy proposed? So I don't think they really", "tokens": [50600, 3302, 1860, 291, 434, 13596, 2937, 293, 406, 9952, 21577, 382, 29418, 10348, 30, 407, 286, 500, 380, 519, 436, 534, 51036], "temperature": 0.0, "avg_logprob": -0.1237619654337565, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.006586223840713501}, {"id": 654, "seek": 468312, "start": 4696.5599999999995, "end": 4707.92, "text": " do. All they can do is come up with a benchmark, a controlled one that has causated causes and effects", "tokens": [51036, 360, 13, 1057, 436, 393, 360, 307, 808, 493, 365, 257, 18927, 11, 257, 10164, 472, 300, 575, 3302, 770, 7700, 293, 5065, 51604], "temperature": 0.0, "avg_logprob": -0.1237619654337565, "compression_ratio": 1.5315789473684212, "no_speech_prob": 0.006586223840713501}, {"id": 655, "seek": 470792, "start": 4708.88, "end": 4719.4400000000005, "text": " and tests if an LLM is able to recreate that. But again, is this purely reasoning or this just", "tokens": [50412, 293, 6921, 498, 364, 441, 43, 44, 307, 1075, 281, 25833, 300, 13, 583, 797, 11, 307, 341, 17491, 21577, 420, 341, 445, 50940], "temperature": 0.0, "avg_logprob": -0.1627430559983894, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.010487048886716366}, {"id": 656, "seek": 470792, "start": 4722.08, "end": 4728.88, "text": " or this just retrieval from your knowledge? And I think there's also another point to consider", "tokens": [51072, 420, 341, 445, 19817, 3337, 490, 428, 3601, 30, 400, 286, 519, 456, 311, 611, 1071, 935, 281, 1949, 51412], "temperature": 0.0, "avg_logprob": -0.1627430559983894, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.010487048886716366}, {"id": 657, "seek": 470792, "start": 4730.0, "end": 4734.32, "text": " as Pravin mentioned earlier, that it's a bit different because it's language and", "tokens": [51468, 382, 12133, 4796, 2835, 3071, 11, 300, 309, 311, 257, 857, 819, 570, 309, 311, 2856, 293, 51684], "temperature": 0.0, "avg_logprob": -0.1627430559983894, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.010487048886716366}, {"id": 658, "seek": 473432, "start": 4734.96, "end": 4739.92, "text": " might take my thought on that. I don't have anything to support that claim, but my thought on that", "tokens": [50396, 1062, 747, 452, 1194, 322, 300, 13, 286, 500, 380, 362, 1340, 281, 1406, 300, 3932, 11, 457, 452, 1194, 322, 300, 50644], "temperature": 0.0, "avg_logprob": -0.09338965886075731, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0028889316599816084}, {"id": 659, "seek": 473432, "start": 4741.12, "end": 4749.84, "text": " is that we as humans use language to formulate concepts and to reason. So eventually, if we", "tokens": [50704, 307, 300, 321, 382, 6255, 764, 2856, 281, 47881, 10392, 293, 281, 1778, 13, 407, 4728, 11, 498, 321, 51140], "temperature": 0.0, "avg_logprob": -0.09338965886075731, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0028889316599816084}, {"id": 660, "seek": 473432, "start": 4749.84, "end": 4759.5199999999995, "text": " reach the point to which the LLM is so powerful in text, in natural language processing, actually,", "tokens": [51140, 2524, 264, 935, 281, 597, 264, 441, 43, 44, 307, 370, 4005, 294, 2487, 11, 294, 3303, 2856, 9007, 11, 767, 11, 51624], "temperature": 0.0, "avg_logprob": -0.09338965886075731, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0028889316599816084}, {"id": 661, "seek": 475952, "start": 4760.320000000001, "end": 4769.52, "text": " what are the implications of it on its ability to formulate concepts and reason? I want to get", "tokens": [50404, 437, 366, 264, 16602, 295, 309, 322, 1080, 3485, 281, 47881, 10392, 293, 1778, 30, 286, 528, 281, 483, 50864], "temperature": 0.0, "avg_logprob": -0.12881974551988684, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.0021484806202352047}, {"id": 662, "seek": 475952, "start": 4769.52, "end": 4774.160000000001, "text": " back to the chain of thought and tree of thought prompt engineering techniques I was telling you", "tokens": [50864, 646, 281, 264, 5021, 295, 1194, 293, 4230, 295, 1194, 12391, 7043, 7512, 286, 390, 3585, 291, 51096], "temperature": 0.0, "avg_logprob": -0.12881974551988684, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.0021484806202352047}, {"id": 663, "seek": 475952, "start": 4774.160000000001, "end": 4780.160000000001, "text": " about earlier. The tree of thought is pretty much the same thing. So you say to your LLM,", "tokens": [51096, 466, 3071, 13, 440, 4230, 295, 1194, 307, 1238, 709, 264, 912, 551, 13, 407, 291, 584, 281, 428, 441, 43, 44, 11, 51396], "temperature": 0.0, "avg_logprob": -0.12881974551988684, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.0021484806202352047}, {"id": 664, "seek": 475952, "start": 4780.160000000001, "end": 4787.52, "text": " right, this is a question, I want the answer. But first, I want your first thought on the answer", "tokens": [51396, 558, 11, 341, 307, 257, 1168, 11, 286, 528, 264, 1867, 13, 583, 700, 11, 286, 528, 428, 700, 1194, 322, 264, 1867, 51764], "temperature": 0.0, "avg_logprob": -0.12881974551988684, "compression_ratio": 1.7104072398190044, "no_speech_prob": 0.0021484806202352047}, {"id": 665, "seek": 478752, "start": 4787.52, "end": 4793.52, "text": " and then you separate into two and you like choose different ways of thinking about it and", "tokens": [50364, 293, 550, 291, 4994, 666, 732, 293, 291, 411, 2826, 819, 2098, 295, 1953, 466, 309, 293, 50664], "temperature": 0.0, "avg_logprob": -0.17370889541950632, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0026722210459411144}, {"id": 666, "seek": 478752, "start": 4793.52, "end": 4800.080000000001, "text": " just create a tree and output all difference. That would be able, that would make us able to track", "tokens": [50664, 445, 1884, 257, 4230, 293, 5598, 439, 2649, 13, 663, 576, 312, 1075, 11, 300, 576, 652, 505, 1075, 281, 2837, 50992], "temperature": 0.0, "avg_logprob": -0.17370889541950632, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0026722210459411144}, {"id": 667, "seek": 478752, "start": 4800.080000000001, "end": 4806.240000000001, "text": " how does the net. I saw that there is a very interesting paper on it. I can link it in the", "tokens": [50992, 577, 775, 264, 2533, 13, 286, 1866, 300, 456, 307, 257, 588, 1880, 3035, 322, 309, 13, 286, 393, 2113, 309, 294, 264, 51300], "temperature": 0.0, "avg_logprob": -0.17370889541950632, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0026722210459411144}, {"id": 668, "seek": 478752, "start": 4806.240000000001, "end": 4814.96, "text": " chat tree of thought. So my take on this, my question would be LLM are basically two years old", "tokens": [51300, 5081, 4230, 295, 1194, 13, 407, 452, 747, 322, 341, 11, 452, 1168, 576, 312, 441, 43, 44, 366, 1936, 732, 924, 1331, 51736], "temperature": 0.0, "avg_logprob": -0.17370889541950632, "compression_ratio": 1.644736842105263, "no_speech_prob": 0.0026722210459411144}, {"id": 669, "seek": 481496, "start": 4814.96, "end": 4821.68, "text": " and they're able to do so much already. And at what pace are they still going to grow in the", "tokens": [50364, 293, 436, 434, 1075, 281, 360, 370, 709, 1217, 13, 400, 412, 437, 11638, 366, 436, 920, 516, 281, 1852, 294, 264, 50700], "temperature": 0.0, "avg_logprob": -0.13598974545796713, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0008039740496315062}, {"id": 670, "seek": 481496, "start": 4821.68, "end": 4830.88, "text": " future? And what are the implications on the amount of knowledge that will be theirs in a couple", "tokens": [50700, 2027, 30, 400, 437, 366, 264, 16602, 322, 264, 2372, 295, 3601, 300, 486, 312, 22760, 294, 257, 1916, 51160], "temperature": 0.0, "avg_logprob": -0.13598974545796713, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0008039740496315062}, {"id": 671, "seek": 481496, "start": 4830.88, "end": 4838.4800000000005, "text": " of years from now? Because in the end, is causality just like you have this in your knowledge, you", "tokens": [51160, 295, 924, 490, 586, 30, 1436, 294, 264, 917, 11, 307, 3302, 1860, 445, 411, 291, 362, 341, 294, 428, 3601, 11, 291, 51540], "temperature": 0.0, "avg_logprob": -0.13598974545796713, "compression_ratio": 1.565217391304348, "no_speech_prob": 0.0008039740496315062}, {"id": 672, "seek": 483848, "start": 4838.48, "end": 4845.2, "text": " can take it out and get it again. Because if it's that, I don't have any doubt that in maybe 10", "tokens": [50364, 393, 747, 309, 484, 293, 483, 309, 797, 13, 1436, 498, 309, 311, 300, 11, 286, 500, 380, 362, 604, 6385, 300, 294, 1310, 1266, 50700], "temperature": 0.0, "avg_logprob": -0.19137855745711416, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.16439883410930634}, {"id": 673, "seek": 483848, "start": 4845.2, "end": 4850.0, "text": " years from now or I don't know why. At some point, we'll figure it out to every knowledge we know in", "tokens": [50700, 924, 490, 586, 420, 286, 500, 380, 458, 983, 13, 1711, 512, 935, 11, 321, 603, 2573, 309, 484, 281, 633, 3601, 321, 458, 294, 50940], "temperature": 0.0, "avg_logprob": -0.19137855745711416, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.16439883410930634}, {"id": 674, "seek": 483848, "start": 4850.0, "end": 4859.04, "text": " the LLMs. It's not reasonable to think that. But core factuals and everything, some more,", "tokens": [50940, 264, 441, 43, 26386, 13, 467, 311, 406, 10585, 281, 519, 300, 13, 583, 4965, 1186, 901, 82, 293, 1203, 11, 512, 544, 11, 51392], "temperature": 0.0, "avg_logprob": -0.19137855745711416, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.16439883410930634}, {"id": 675, "seek": 483848, "start": 4861.759999999999, "end": 4866.4, "text": " I don't really have an answer. I don't think anyone has an answer in the papers I mentioned.", "tokens": [51528, 286, 500, 380, 534, 362, 364, 1867, 13, 286, 500, 380, 519, 2878, 575, 364, 1867, 294, 264, 10577, 286, 2835, 13, 51760], "temperature": 0.0, "avg_logprob": -0.19137855745711416, "compression_ratio": 1.662280701754386, "no_speech_prob": 0.16439883410930634}, {"id": 676, "seek": 486640, "start": 4867.2, "end": 4879.92, "text": " Yes, Ernan? Yeah, this is great discussion. I have more questions here for us to reflect.", "tokens": [50404, 1079, 11, 3300, 17622, 30, 865, 11, 341, 307, 869, 5017, 13, 286, 362, 544, 1651, 510, 337, 505, 281, 5031, 13, 51040], "temperature": 0.0, "avg_logprob": -0.26400501170056934, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0007428418030031025}, {"id": 677, "seek": 486640, "start": 4880.48, "end": 4889.759999999999, "text": " But it seems like we are collecting all the reflections. It seems like we still don't have", "tokens": [51068, 583, 309, 2544, 411, 321, 366, 12510, 439, 264, 30679, 13, 467, 2544, 411, 321, 920, 500, 380, 362, 51532], "temperature": 0.0, "avg_logprob": -0.26400501170056934, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0007428418030031025}, {"id": 678, "seek": 488976, "start": 4889.76, "end": 4898.64, "text": " a way to measure causality, a solid way like we do measure models via the WSER or some other", "tokens": [50364, 257, 636, 281, 3481, 3302, 1860, 11, 257, 5100, 636, 411, 321, 360, 3481, 5245, 5766, 264, 343, 50, 1598, 420, 512, 661, 50808], "temperature": 0.0, "avg_logprob": -0.20665661233370422, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.0013021277263760567}, {"id": 679, "seek": 488976, "start": 4898.64, "end": 4910.08, "text": " metrics. And my perception of causality is something that may be reproducible across", "tokens": [50808, 16367, 13, 400, 452, 12860, 295, 3302, 1860, 307, 746, 300, 815, 312, 11408, 32128, 2108, 51380], "temperature": 0.0, "avg_logprob": -0.20665661233370422, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.0013021277263760567}, {"id": 680, "seek": 488976, "start": 4910.08, "end": 4916.64, "text": " experiments in different environments that are looking at kind of the same processes.", "tokens": [51380, 12050, 294, 819, 12388, 300, 366, 1237, 412, 733, 295, 264, 912, 7555, 13, 51708], "temperature": 0.0, "avg_logprob": -0.20665661233370422, "compression_ratio": 1.4858757062146892, "no_speech_prob": 0.0013021277263760567}, {"id": 681, "seek": 491664, "start": 4916.64, "end": 4926.240000000001, "text": " So think about streamflow in Switzerland versus Tucson versus Washington. But do we", "tokens": [50364, 407, 519, 466, 4309, 10565, 294, 23312, 5717, 47417, 5717, 6149, 13, 583, 360, 321, 50844], "temperature": 0.0, "avg_logprob": -0.21610534191131592, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001986198127269745}, {"id": 682, "seek": 491664, "start": 4928.0, "end": 4934.64, "text": " have tools to measure causality? In other words, can we say the same way in an analogous way,", "tokens": [50932, 362, 3873, 281, 3481, 3302, 1860, 30, 682, 661, 2283, 11, 393, 321, 584, 264, 912, 636, 294, 364, 16660, 563, 636, 11, 51264], "temperature": 0.0, "avg_logprob": -0.21610534191131592, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001986198127269745}, {"id": 683, "seek": 491664, "start": 4934.64, "end": 4940.400000000001, "text": " we have a way, machine learning models, overfeats, underfeats, do we have a way to say this model", "tokens": [51264, 321, 362, 257, 636, 11, 3479, 2539, 5245, 11, 670, 2106, 1720, 11, 833, 2106, 1720, 11, 360, 321, 362, 257, 636, 281, 584, 341, 2316, 51552], "temperature": 0.0, "avg_logprob": -0.21610534191131592, "compression_ratio": 1.5714285714285714, "no_speech_prob": 0.001986198127269745}, {"id": 684, "seek": 494040, "start": 4940.4, "end": 4949.04, "text": " overfeats causality, this model underfeats causality? This is a good causality explanation of the", "tokens": [50364, 670, 2106, 1720, 3302, 1860, 11, 341, 2316, 833, 2106, 1720, 3302, 1860, 30, 639, 307, 257, 665, 3302, 1860, 10835, 295, 264, 50796], "temperature": 0.0, "avg_logprob": -0.1443223688337538, "compression_ratio": 1.6045197740112995, "no_speech_prob": 0.004395126365125179}, {"id": 685, "seek": 494040, "start": 4949.04, "end": 4957.5199999999995, "text": " process. And I don't know if that exists. And that goes back to the way we usually validate or", "tokens": [50796, 1399, 13, 400, 286, 500, 380, 458, 498, 300, 8198, 13, 400, 300, 1709, 646, 281, 264, 636, 321, 2673, 29562, 420, 51220], "temperature": 0.0, "avg_logprob": -0.1443223688337538, "compression_ratio": 1.6045197740112995, "no_speech_prob": 0.004395126365125179}, {"id": 686, "seek": 494040, "start": 4957.5199999999995, "end": 4966.799999999999, "text": " cross validate models in which we split the data set in a number of folds and then we cross", "tokens": [51220, 3278, 29562, 5245, 294, 597, 321, 7472, 264, 1412, 992, 294, 257, 1230, 295, 31341, 293, 550, 321, 3278, 51684], "temperature": 0.0, "avg_logprob": -0.1443223688337538, "compression_ratio": 1.6045197740112995, "no_speech_prob": 0.004395126365125179}, {"id": 687, "seek": 496680, "start": 4966.8, "end": 4975.52, "text": " validate it. Should we instead do tests for causality in a similar way or analogous way in", "tokens": [50364, 29562, 309, 13, 6454, 321, 2602, 360, 6921, 337, 3302, 1860, 294, 257, 2531, 636, 420, 16660, 563, 636, 294, 50800], "temperature": 0.0, "avg_logprob": -0.10165630068097796, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.0009998827008530498}, {"id": 688, "seek": 496680, "start": 4975.52, "end": 4981.360000000001, "text": " which we take data sets from different environments and then we see if the knowledge is transferred", "tokens": [50800, 597, 321, 747, 1412, 6352, 490, 819, 12388, 293, 550, 321, 536, 498, 264, 3601, 307, 15809, 51092], "temperature": 0.0, "avg_logprob": -0.10165630068097796, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.0009998827008530498}, {"id": 689, "seek": 496680, "start": 4981.360000000001, "end": 4988.24, "text": " across those environments via the cross validation. So perhaps that removes a little bit of the", "tokens": [51092, 2108, 729, 12388, 5766, 264, 3278, 24071, 13, 407, 4317, 300, 30445, 257, 707, 857, 295, 264, 51436], "temperature": 0.0, "avg_logprob": -0.10165630068097796, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.0009998827008530498}, {"id": 690, "seek": 496680, "start": 4988.24, "end": 4994.400000000001, "text": " anxiety we have for perfection in causality. And we kind of explain it in a way that we", "tokens": [51436, 9119, 321, 362, 337, 19708, 294, 3302, 1860, 13, 400, 321, 733, 295, 2903, 309, 294, 257, 636, 300, 321, 51744], "temperature": 0.0, "avg_logprob": -0.10165630068097796, "compression_ratio": 1.6622222222222223, "no_speech_prob": 0.0009998827008530498}, {"id": 691, "seek": 499440, "start": 4994.5599999999995, "end": 5006.32, "text": " quantify and not as a binary yes or no. And another problem is predicting beyond training", "tokens": [50372, 40421, 293, 406, 382, 257, 17434, 2086, 420, 572, 13, 400, 1071, 1154, 307, 32884, 4399, 3097, 50960], "temperature": 0.0, "avg_logprob": -0.1508147538597904, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.000656050571706146}, {"id": 692, "seek": 499440, "start": 5008.08, "end": 5014.48, "text": " in the at once example of climate change. It's another limitation. I don't know if we're at the", "tokens": [51048, 294, 264, 412, 1564, 1365, 295, 5659, 1319, 13, 467, 311, 1071, 27432, 13, 286, 500, 380, 458, 498, 321, 434, 412, 264, 51368], "temperature": 0.0, "avg_logprob": -0.1508147538597904, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.000656050571706146}, {"id": 693, "seek": 499440, "start": 5014.48, "end": 5020.0, "text": " point at which the models will be able to reason and then beyond training, even though they're", "tokens": [51368, 935, 412, 597, 264, 5245, 486, 312, 1075, 281, 1778, 293, 550, 4399, 3097, 11, 754, 1673, 436, 434, 51644], "temperature": 0.0, "avg_logprob": -0.1508147538597904, "compression_ratio": 1.5642458100558658, "no_speech_prob": 0.000656050571706146}, {"id": 694, "seek": 502000, "start": 5020.0, "end": 5029.04, "text": " perfectly trained, reason about climate change consequences and the trends. If the trends are", "tokens": [50364, 6239, 8895, 11, 1778, 466, 5659, 1319, 10098, 293, 264, 13892, 13, 759, 264, 13892, 366, 50816], "temperature": 0.0, "avg_logprob": -0.13924464871806483, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0007095892797224224}, {"id": 695, "seek": 502000, "start": 5029.04, "end": 5036.08, "text": " learned from the data themselves, then yes. But if there's nothing that let us know about surprises,", "tokens": [50816, 3264, 490, 264, 1412, 2969, 11, 550, 2086, 13, 583, 498, 456, 311, 1825, 300, 718, 505, 458, 466, 22655, 11, 51168], "temperature": 0.0, "avg_logprob": -0.13924464871806483, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0007095892797224224}, {"id": 696, "seek": 502000, "start": 5036.96, "end": 5045.04, "text": " I doubt. And the other thing is the data limits are really constraining our learning", "tokens": [51212, 286, 6385, 13, 400, 264, 661, 551, 307, 264, 1412, 10406, 366, 534, 11525, 1760, 527, 2539, 51616], "temperature": 0.0, "avg_logprob": -0.13924464871806483, "compression_ratio": 1.576271186440678, "no_speech_prob": 0.0007095892797224224}, {"id": 697, "seek": 504504, "start": 5045.12, "end": 5058.72, "text": " or the models learning pace of the facts and not to speak of the counterfact loss. But", "tokens": [50368, 420, 264, 5245, 2539, 11638, 295, 264, 9130, 293, 406, 281, 1710, 295, 264, 5682, 44919, 4470, 13, 583, 51048], "temperature": 0.0, "avg_logprob": -0.2550203535291884, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.002547760494053364}, {"id": 698, "seek": 504504, "start": 5059.28, "end": 5064.96, "text": " I mean, those are kind of some of the lines or bullets I could raise from everybody's discussion", "tokens": [51076, 286, 914, 11, 729, 366, 733, 295, 512, 295, 264, 3876, 420, 20132, 286, 727, 5300, 490, 2201, 311, 5017, 51360], "temperature": 0.0, "avg_logprob": -0.2550203535291884, "compression_ratio": 1.3863636363636365, "no_speech_prob": 0.002547760494053364}, {"id": 699, "seek": 506496, "start": 5064.96, "end": 5067.84, "text": " but so far. That's a great discussion.", "tokens": [50364, 457, 370, 1400, 13, 663, 311, 257, 869, 5017, 13, 50508], "temperature": 0.0, "avg_logprob": -0.20312115297479144, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.009258502162992954}, {"id": 700, "seek": 506496, "start": 5072.08, "end": 5080.32, "text": " If I, yeah, thank you for intervention Aaron. If I may maybe give another couple of elements in", "tokens": [50720, 759, 286, 11, 1338, 11, 1309, 291, 337, 13176, 14018, 13, 759, 286, 815, 1310, 976, 1071, 1916, 295, 4959, 294, 51132], "temperature": 0.0, "avg_logprob": -0.20312115297479144, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.009258502162992954}, {"id": 701, "seek": 506496, "start": 5080.32, "end": 5089.12, "text": " there to give a couple more insights on those questions. Okay, so I have a small amount of", "tokens": [51132, 456, 281, 976, 257, 1916, 544, 14310, 322, 729, 1651, 13, 1033, 11, 370, 286, 362, 257, 1359, 2372, 295, 51572], "temperature": 0.0, "avg_logprob": -0.20312115297479144, "compression_ratio": 1.4331210191082802, "no_speech_prob": 0.009258502162992954}, {"id": 702, "seek": 508912, "start": 5089.12, "end": 5096.16, "text": " knowledge on digital twins. Before I was here, when I was in master's degree, five, six years ago", "tokens": [50364, 3601, 322, 4562, 22555, 13, 4546, 286, 390, 510, 11, 562, 286, 390, 294, 4505, 311, 4314, 11, 1732, 11, 2309, 924, 2057, 50716], "temperature": 0.0, "avg_logprob": -0.14349072105006166, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.051746953278779984}, {"id": 703, "seek": 508912, "start": 5096.16, "end": 5101.36, "text": " in France, I was an apprentice at Dassault Systems at the same time and they were working on digital", "tokens": [50716, 294, 6190, 11, 286, 390, 364, 40207, 412, 22306, 5107, 27059, 412, 264, 912, 565, 293, 436, 645, 1364, 322, 4562, 50976], "temperature": 0.0, "avg_logprob": -0.14349072105006166, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.051746953278779984}, {"id": 704, "seek": 508912, "start": 5101.36, "end": 5108.4, "text": " twins back then. So I was a bit in there. In short, for those who will know digital twins is a concept", "tokens": [50976, 22555, 646, 550, 13, 407, 286, 390, 257, 857, 294, 456, 13, 682, 2099, 11, 337, 729, 567, 486, 458, 4562, 22555, 307, 257, 3410, 51328], "temperature": 0.0, "avg_logprob": -0.14349072105006166, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.051746953278779984}, {"id": 705, "seek": 508912, "start": 5108.4, "end": 5114.16, "text": " that ties a physical object to a virtual representation, where there is a synchronization", "tokens": [51328, 300, 14039, 257, 4001, 2657, 281, 257, 6374, 10290, 11, 689, 456, 307, 257, 19331, 2144, 51616], "temperature": 0.0, "avg_logprob": -0.14349072105006166, "compression_ratio": 1.6428571428571428, "no_speech_prob": 0.051746953278779984}, {"id": 706, "seek": 511416, "start": 5114.24, "end": 5123.599999999999, "text": " of data between the two of them. And what's hot in the topic right now is because of climate", "tokens": [50368, 295, 1412, 1296, 264, 732, 295, 552, 13, 400, 437, 311, 2368, 294, 264, 4829, 558, 586, 307, 570, 295, 5659, 50836], "temperature": 0.0, "avg_logprob": -0.11222737282514572, "compression_ratio": 1.5, "no_speech_prob": 0.030623260885477066}, {"id": 707, "seek": 511416, "start": 5123.599999999999, "end": 5128.72, "text": " change and extreme events and everything is a digital twin of the planet Earth. There is", "tokens": [50836, 1319, 293, 8084, 3931, 293, 1203, 307, 257, 4562, 18397, 295, 264, 5054, 4755, 13, 821, 307, 51092], "temperature": 0.0, "avg_logprob": -0.11222737282514572, "compression_ratio": 1.5, "no_speech_prob": 0.030623260885477066}, {"id": 708, "seek": 511416, "start": 5131.68, "end": 5138.639999999999, "text": " a perspective on that from the European Union, which is called destination Earth. So they plan", "tokens": [51240, 257, 4585, 322, 300, 490, 264, 6473, 8133, 11, 597, 307, 1219, 12236, 4755, 13, 407, 436, 1393, 51588], "temperature": 0.0, "avg_logprob": -0.11222737282514572, "compression_ratio": 1.5, "no_speech_prob": 0.030623260885477066}, {"id": 709, "seek": 513864, "start": 5138.64, "end": 5146.8, "text": " to do a digital twin of the whole Earth by 2027, I don't remember 2028. My take on this is", "tokens": [50364, 281, 360, 257, 4562, 18397, 295, 264, 1379, 4755, 538, 945, 10076, 11, 286, 500, 380, 1604, 945, 11205, 13, 1222, 747, 322, 341, 307, 50772], "temperature": 0.0, "avg_logprob": -0.14241043297020164, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.01564486138522625}, {"id": 710, "seek": 513864, "start": 5148.240000000001, "end": 5154.88, "text": " from what I've seen in the paper, talking about the intelligent agents that learn about experience.", "tokens": [50844, 490, 437, 286, 600, 1612, 294, 264, 3035, 11, 1417, 466, 264, 13232, 12554, 300, 1466, 466, 1752, 13, 51176], "temperature": 0.0, "avg_logprob": -0.14241043297020164, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.01564486138522625}, {"id": 711, "seek": 513864, "start": 5157.76, "end": 5164.240000000001, "text": " I drew the parallel between those agents and what on a lens able to do. But the key thing here is", "tokens": [51320, 286, 12804, 264, 8952, 1296, 729, 12554, 293, 437, 322, 257, 6765, 1075, 281, 360, 13, 583, 264, 2141, 551, 510, 307, 51644], "temperature": 0.0, "avg_logprob": -0.14241043297020164, "compression_ratio": 1.476923076923077, "no_speech_prob": 0.01564486138522625}, {"id": 712, "seek": 516424, "start": 5164.24, "end": 5174.32, "text": " that experience is beneficial to causal understanding. And I guess this is what's also been put forward", "tokens": [50364, 300, 1752, 307, 14072, 281, 38755, 3701, 13, 400, 286, 2041, 341, 307, 437, 311, 611, 668, 829, 2128, 50868], "temperature": 0.0, "avg_logprob": -0.13221728801727295, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.009113945066928864}, {"id": 713, "seek": 516424, "start": 5174.32, "end": 5182.4, "text": " by my the causal inference frameworks that do need a lot of data, experimentations and everything.", "tokens": [50868, 538, 452, 264, 38755, 38253, 29834, 300, 360, 643, 257, 688, 295, 1412, 11, 5120, 763, 293, 1203, 13, 51272], "temperature": 0.0, "avg_logprob": -0.13221728801727295, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.009113945066928864}, {"id": 714, "seek": 516424, "start": 5182.4, "end": 5189.92, "text": " And so just my small insight on there would be that digital twins may just represent a great", "tokens": [51272, 400, 370, 445, 452, 1359, 11269, 322, 456, 576, 312, 300, 4562, 22555, 815, 445, 2906, 257, 869, 51648], "temperature": 0.0, "avg_logprob": -0.13221728801727295, "compression_ratio": 1.5364583333333333, "no_speech_prob": 0.009113945066928864}, {"id": 715, "seek": 518992, "start": 5189.92, "end": 5201.28, "text": " environment for LLMs to interact with if those virtual environments are good enough", "tokens": [50364, 2823, 337, 441, 43, 26386, 281, 4648, 365, 498, 729, 6374, 12388, 366, 665, 1547, 50932], "temperature": 0.0, "avg_logprob": -0.1685927031470127, "compression_ratio": 1.5, "no_speech_prob": 0.006688999943435192}, {"id": 716, "seek": 518992, "start": 5201.84, "end": 5208.8, "text": " to be representative of what's happening out there. And this is where all work of all", "tokens": [50960, 281, 312, 12424, 295, 437, 311, 2737, 484, 456, 13, 400, 341, 307, 689, 439, 589, 295, 439, 51308], "temperature": 0.0, "avg_logprob": -0.1685927031470127, "compression_ratio": 1.5, "no_speech_prob": 0.006688999943435192}, {"id": 717, "seek": 518992, "start": 5208.8, "end": 5214.4, "text": " traditional, I would say research comes in, flow modeling, ground flow modeling, rainfall runoff,", "tokens": [51308, 5164, 11, 286, 576, 584, 2132, 1487, 294, 11, 3095, 15983, 11, 2727, 3095, 15983, 11, 29382, 1190, 4506, 11, 51588], "temperature": 0.0, "avg_logprob": -0.1685927031470127, "compression_ratio": 1.5, "no_speech_prob": 0.006688999943435192}, {"id": 718, "seek": 521440, "start": 5215.28, "end": 5227.36, "text": " geochemistry. And so my vision of, so we're at UIUC in Illinois in the CI Net program,", "tokens": [50408, 1519, 8997, 443, 5980, 13, 400, 370, 452, 5201, 295, 11, 370, 321, 434, 412, 15682, 23967, 294, 17508, 294, 264, 37777, 6188, 1461, 11, 51012], "temperature": 0.0, "avg_logprob": -0.18967586517333984, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.002216341206803918}, {"id": 719, "seek": 521440, "start": 5227.36, "end": 5233.679999999999, "text": " we're studying the Singapore watershed. And so maybe a target I'd like to achieve would be like", "tokens": [51012, 321, 434, 7601, 264, 14491, 49728, 13, 400, 370, 1310, 257, 3779, 286, 1116, 411, 281, 4584, 576, 312, 411, 51328], "temperature": 0.0, "avg_logprob": -0.18967586517333984, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.002216341206803918}, {"id": 720, "seek": 521440, "start": 5233.679999999999, "end": 5241.12, "text": " to have a digital twin of that watershed represented by a 3D model and data coming in the same time.", "tokens": [51328, 281, 362, 257, 4562, 18397, 295, 300, 49728, 10379, 538, 257, 805, 35, 2316, 293, 1412, 1348, 294, 264, 912, 565, 13, 51700], "temperature": 0.0, "avg_logprob": -0.18967586517333984, "compression_ratio": 1.4739583333333333, "no_speech_prob": 0.002216341206803918}, {"id": 721, "seek": 524112, "start": 5241.2, "end": 5247.2, "text": " And on top of that, you would have physics, a physics engine reality represented by all the", "tokens": [50368, 400, 322, 1192, 295, 300, 11, 291, 576, 362, 10649, 11, 257, 10649, 2848, 4103, 10379, 538, 439, 264, 50668], "temperature": 0.0, "avg_logprob": -0.12472567482600136, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0005111696664243937}, {"id": 722, "seek": 524112, "start": 5248.16, "end": 5255.36, "text": " process based simulation models we know and et cetera. And this would be the great place for", "tokens": [50716, 1399, 2361, 16575, 5245, 321, 458, 293, 1030, 11458, 13, 400, 341, 576, 312, 264, 869, 1081, 337, 51076], "temperature": 0.0, "avg_logprob": -0.12472567482600136, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0005111696664243937}, {"id": 723, "seek": 524112, "start": 5255.36, "end": 5264.0, "text": " LLMs to fully express itself and make interactions and make experiences. And this would potentially", "tokens": [51076, 441, 43, 26386, 281, 4498, 5109, 2564, 293, 652, 13280, 293, 652, 5235, 13, 400, 341, 576, 7263, 51508], "temperature": 0.0, "avg_logprob": -0.12472567482600136, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.0005111696664243937}, {"id": 724, "seek": 526400, "start": 5264.0, "end": 5272.88, "text": " provide a great environment to perform causal inference and maybe to test whether LLMs are", "tokens": [50364, 2893, 257, 869, 2823, 281, 2042, 38755, 38253, 293, 1310, 281, 1500, 1968, 441, 43, 26386, 366, 50808], "temperature": 0.0, "avg_logprob": -0.15848915917532785, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.014716826379299164}, {"id": 725, "seek": 526400, "start": 5272.88, "end": 5278.24, "text": " actually able to do causal inference, because all we've been fitting is generated text and made up", "tokens": [50808, 767, 1075, 281, 360, 38755, 38253, 11, 570, 439, 321, 600, 668, 15669, 307, 10833, 2487, 293, 1027, 493, 51076], "temperature": 0.0, "avg_logprob": -0.15848915917532785, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.014716826379299164}, {"id": 726, "seek": 526400, "start": 5278.24, "end": 5282.8, "text": " benchmarks, which is interesting. And it's the first step. Eventually experience is the key,", "tokens": [51076, 43751, 11, 597, 307, 1880, 13, 400, 309, 311, 264, 700, 1823, 13, 17586, 1752, 307, 264, 2141, 11, 51304], "temperature": 0.0, "avg_logprob": -0.15848915917532785, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.014716826379299164}, {"id": 727, "seek": 526400, "start": 5282.8, "end": 5287.44, "text": " I feel like, and the digital twin would be really interesting environment for that. This is just", "tokens": [51304, 286, 841, 411, 11, 293, 264, 4562, 18397, 576, 312, 534, 1880, 2823, 337, 300, 13, 639, 307, 445, 51536], "temperature": 0.0, "avg_logprob": -0.15848915917532785, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.014716826379299164}, {"id": 728, "seek": 526400, "start": 5287.44, "end": 5293.52, "text": " like both thoughts I've had. You want to reflect on that, Ocean? No, no, no, absolutely. I think", "tokens": [51536, 411, 1293, 4598, 286, 600, 632, 13, 509, 528, 281, 5031, 322, 300, 11, 18101, 30, 883, 11, 572, 11, 572, 11, 3122, 13, 286, 519, 51840], "temperature": 0.0, "avg_logprob": -0.15848915917532785, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.014716826379299164}, {"id": 729, "seek": 529352, "start": 5293.6, "end": 5297.040000000001, "text": " you're absolutely going down the right track because you're saying basically", "tokens": [50368, 291, 434, 3122, 516, 760, 264, 558, 2837, 570, 291, 434, 1566, 1936, 50540], "temperature": 0.0, "avg_logprob": -0.1061836418352629, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0010306905023753643}, {"id": 730, "seek": 529352, "start": 5297.68, "end": 5305.120000000001, "text": " that you need to not only respond, you need to be able to interrogate your environment", "tokens": [50572, 300, 291, 643, 281, 406, 787, 4196, 11, 291, 643, 281, 312, 1075, 281, 24871, 473, 428, 2823, 50944], "temperature": 0.0, "avg_logprob": -0.1061836418352629, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0010306905023753643}, {"id": 731, "seek": 529352, "start": 5306.4800000000005, "end": 5311.4400000000005, "text": " and giving them a digital environment to interrogate is a useful thing to do. And that's", "tokens": [51012, 293, 2902, 552, 257, 4562, 2823, 281, 24871, 473, 307, 257, 4420, 551, 281, 360, 13, 400, 300, 311, 51260], "temperature": 0.0, "avg_logprob": -0.1061836418352629, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0010306905023753643}, {"id": 732, "seek": 529352, "start": 5311.4400000000005, "end": 5320.4800000000005, "text": " actually behind this poet paper that I put up there about where the environment changes as", "tokens": [51260, 767, 2261, 341, 20874, 3035, 300, 286, 829, 493, 456, 466, 689, 264, 2823, 2962, 382, 51712], "temperature": 0.0, "avg_logprob": -0.1061836418352629, "compression_ratio": 1.7411167512690355, "no_speech_prob": 0.0010306905023753643}, {"id": 733, "seek": 532048, "start": 5320.48, "end": 5328.0, "text": " the ability of the agent changes. So it's like a co-evolution process where it actually evolves", "tokens": [50364, 264, 3485, 295, 264, 9461, 2962, 13, 407, 309, 311, 411, 257, 598, 12, 13379, 3386, 1399, 689, 309, 767, 43737, 50740], "temperature": 0.0, "avg_logprob": -0.07437256404331752, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.0007786192581988871}, {"id": 734, "seek": 532048, "start": 5328.0, "end": 5331.679999999999, "text": " the environment, which is one step beyond what you're thinking, what you're talking about.", "tokens": [50740, 264, 2823, 11, 597, 307, 472, 1823, 4399, 437, 291, 434, 1953, 11, 437, 291, 434, 1417, 466, 13, 50924], "temperature": 0.0, "avg_logprob": -0.07437256404331752, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.0007786192581988871}, {"id": 735, "seek": 532048, "start": 5331.679999999999, "end": 5337.679999999999, "text": " But it also occurred to me, the reason I put my hand up was that I think it's really interesting", "tokens": [50924, 583, 309, 611, 11068, 281, 385, 11, 264, 1778, 286, 829, 452, 1011, 493, 390, 300, 286, 519, 309, 311, 534, 1880, 51224], "temperature": 0.0, "avg_logprob": -0.07437256404331752, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.0007786192581988871}, {"id": 736, "seek": 532048, "start": 5337.679999999999, "end": 5344.32, "text": " to have the LLM as the agent that's doing the learning. I hadn't thought of that. I think it", "tokens": [51224, 281, 362, 264, 441, 43, 44, 382, 264, 9461, 300, 311, 884, 264, 2539, 13, 286, 8782, 380, 1194, 295, 300, 13, 286, 519, 309, 51556], "temperature": 0.0, "avg_logprob": -0.07437256404331752, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.0007786192581988871}, {"id": 737, "seek": 532048, "start": 5344.32, "end": 5349.12, "text": " would also be interesting in a decision context, which I think is where you're going, to have", "tokens": [51556, 576, 611, 312, 1880, 294, 257, 3537, 4319, 11, 597, 286, 519, 307, 689, 291, 434, 516, 11, 281, 362, 51796], "temperature": 0.0, "avg_logprob": -0.07437256404331752, "compression_ratio": 1.7602996254681649, "no_speech_prob": 0.0007786192581988871}, {"id": 738, "seek": 534912, "start": 5349.12, "end": 5356.48, "text": " multiple LLMs take the roles of different stakeholders and play devil's advocate. So", "tokens": [50364, 3866, 441, 43, 26386, 747, 264, 9604, 295, 819, 17779, 293, 862, 13297, 311, 14608, 13, 407, 50732], "temperature": 0.0, "avg_logprob": -0.07703570661873653, "compression_ratio": 1.8494623655913978, "no_speech_prob": 0.0006158150499686599}, {"id": 739, "seek": 534912, "start": 5356.48, "end": 5361.04, "text": " you've got the rancher and you could say, okay, your job is to play the role of the rancher,", "tokens": [50732, 291, 600, 658, 264, 22883, 260, 293, 291, 727, 584, 11, 1392, 11, 428, 1691, 307, 281, 862, 264, 3090, 295, 264, 22883, 260, 11, 50960], "temperature": 0.0, "avg_logprob": -0.07703570661873653, "compression_ratio": 1.8494623655913978, "no_speech_prob": 0.0006158150499686599}, {"id": 740, "seek": 534912, "start": 5361.04, "end": 5366.24, "text": " your job is to play the role of the environmentalist, your job is to play the role of whatever.", "tokens": [50960, 428, 1691, 307, 281, 862, 264, 3090, 295, 264, 8303, 468, 11, 428, 1691, 307, 281, 862, 264, 3090, 295, 2035, 13, 51220], "temperature": 0.0, "avg_logprob": -0.07703570661873653, "compression_ratio": 1.8494623655913978, "no_speech_prob": 0.0006158150499686599}, {"id": 741, "seek": 534912, "start": 5367.04, "end": 5371.92, "text": " And you could do some very, very interesting role playing explorations", "tokens": [51260, 400, 291, 727, 360, 512, 588, 11, 588, 1880, 3090, 2433, 24765, 763, 51504], "temperature": 0.0, "avg_logprob": -0.07703570661873653, "compression_ratio": 1.8494623655913978, "no_speech_prob": 0.0006158150499686599}, {"id": 742, "seek": 537192, "start": 5371.92, "end": 5382.24, "text": " with the goal of coming up with potential solutions to difficult transdisciplinary", "tokens": [50364, 365, 264, 3387, 295, 1348, 493, 365, 3995, 6547, 281, 2252, 1145, 30520, 50880], "temperature": 0.0, "avg_logprob": -0.1452084240848071, "compression_ratio": 1.5355450236966826, "no_speech_prob": 0.006287521217018366}, {"id": 743, "seek": 537192, "start": 5382.24, "end": 5389.2, "text": " decision-making problems, where you can play them out using agents rather than having to get", "tokens": [50880, 3537, 12, 12402, 2740, 11, 689, 291, 393, 862, 552, 484, 1228, 12554, 2831, 813, 1419, 281, 483, 51228], "temperature": 0.0, "avg_logprob": -0.1452084240848071, "compression_ratio": 1.5355450236966826, "no_speech_prob": 0.006287521217018366}, {"id": 744, "seek": 537192, "start": 5389.2, "end": 5394.8, "text": " real humans in there before you then take those to the next stage and involve humans.", "tokens": [51228, 957, 6255, 294, 456, 949, 291, 550, 747, 729, 281, 264, 958, 3233, 293, 9494, 6255, 13, 51508], "temperature": 0.0, "avg_logprob": -0.1452084240848071, "compression_ratio": 1.5355450236966826, "no_speech_prob": 0.006287521217018366}, {"id": 745, "seek": 537192, "start": 5395.84, "end": 5398.56, "text": " I'm glad you brought it up because this is exactly what we do.", "tokens": [51560, 286, 478, 5404, 291, 3038, 309, 493, 570, 341, 307, 2293, 437, 321, 360, 13, 51696], "temperature": 0.0, "avg_logprob": -0.1452084240848071, "compression_ratio": 1.5355450236966826, "no_speech_prob": 0.006287521217018366}, {"id": 746, "seek": 539856, "start": 5399.04, "end": 5408.56, "text": " Perfect. And so I'm going to be presenting that with Praveen at AGU. And just to give a couple", "tokens": [50388, 10246, 13, 400, 370, 286, 478, 516, 281, 312, 15578, 300, 365, 12133, 303, 268, 412, 28406, 52, 13, 400, 445, 281, 976, 257, 1916, 50864], "temperature": 0.0, "avg_logprob": -0.1720198942034432, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.009703977033495903}, {"id": 747, "seek": 539856, "start": 5408.56, "end": 5416.64, "text": " of heads up. So I have a couple of examples where exactly I have a mayor science expert and", "tokens": [50864, 295, 8050, 493, 13, 407, 286, 362, 257, 1916, 295, 5110, 689, 2293, 286, 362, 257, 10120, 3497, 5844, 293, 51268], "temperature": 0.0, "avg_logprob": -0.1720198942034432, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.009703977033495903}, {"id": 748, "seek": 539856, "start": 5416.64, "end": 5422.8, "text": " everything talking in response to a flood event, impeding flood event or something. And the", "tokens": [51268, 1203, 1417, 294, 4134, 281, 257, 10481, 2280, 11, 704, 9794, 10481, 2280, 420, 746, 13, 400, 264, 51576], "temperature": 0.0, "avg_logprob": -0.1720198942034432, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.009703977033495903}, {"id": 749, "seek": 539856, "start": 5422.8, "end": 5428.160000000001, "text": " problematic right now is to find the right metric and find ways to evaluate the output", "tokens": [51576, 19011, 558, 586, 307, 281, 915, 264, 558, 20678, 293, 915, 2098, 281, 13059, 264, 5598, 51844], "temperature": 0.0, "avg_logprob": -0.1720198942034432, "compression_ratio": 1.6515837104072397, "no_speech_prob": 0.009703977033495903}, {"id": 750, "seek": 542816, "start": 5428.16, "end": 5435.5199999999995, "text": " of the models because this is taxed. It's complicated to evaluate compared to LSTM,", "tokens": [50364, 295, 264, 5245, 570, 341, 307, 3366, 292, 13, 467, 311, 6179, 281, 13059, 5347, 281, 441, 6840, 44, 11, 50732], "temperature": 0.0, "avg_logprob": -0.1295321875927495, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.005379709880799055}, {"id": 751, "seek": 542816, "start": 5435.5199999999995, "end": 5440.48, "text": " which would output a sequence of numbers. And then you would use all the mathematics,", "tokens": [50732, 597, 576, 5598, 257, 8310, 295, 3547, 13, 400, 550, 291, 576, 764, 439, 264, 18666, 11, 50980], "temperature": 0.0, "avg_logprob": -0.1295321875927495, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.005379709880799055}, {"id": 752, "seek": 542816, "start": 5440.48, "end": 5445.28, "text": " you know, to evaluate it. But how do you do it with tax? It's either you come up with something new,", "tokens": [50980, 291, 458, 11, 281, 13059, 309, 13, 583, 577, 360, 291, 360, 309, 365, 3366, 30, 467, 311, 2139, 291, 808, 493, 365, 746, 777, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1295321875927495, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.005379709880799055}, {"id": 753, "seek": 542816, "start": 5445.84, "end": 5452.48, "text": " either you use an LLM to do it, but there is a bias in using an LLM to evaluate an LLM.", "tokens": [51248, 2139, 291, 764, 364, 441, 43, 44, 281, 360, 309, 11, 457, 456, 307, 257, 12577, 294, 1228, 364, 441, 43, 44, 281, 13059, 364, 441, 43, 44, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1295321875927495, "compression_ratio": 1.6574074074074074, "no_speech_prob": 0.005379709880799055}, {"id": 754, "seek": 545248, "start": 5452.48, "end": 5455.919999999999, "text": " So this is a question that needs to be answered right now. But yes.", "tokens": [50364, 407, 341, 307, 257, 1168, 300, 2203, 281, 312, 10103, 558, 586, 13, 583, 2086, 13, 50536], "temperature": 0.0, "avg_logprob": -0.2090838659377325, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.013622188940644264}, {"id": 755, "seek": 545248, "start": 5457.12, "end": 5464.08, "text": " That's like a tool for gowns. Yeah, exactly. So yeah, if that interests you and you're coming", "tokens": [50596, 663, 311, 411, 257, 2290, 337, 34428, 82, 13, 865, 11, 2293, 13, 407, 1338, 11, 498, 300, 8847, 291, 293, 291, 434, 1348, 50944], "temperature": 0.0, "avg_logprob": -0.2090838659377325, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.013622188940644264}, {"id": 756, "seek": 545248, "start": 5464.08, "end": 5467.28, "text": " to AGU, my talk is morning morning. I'm going to be talking about that.", "tokens": [50944, 281, 28406, 52, 11, 452, 751, 307, 2446, 2446, 13, 286, 478, 516, 281, 312, 1417, 466, 300, 13, 51104], "temperature": 0.0, "avg_logprob": -0.2090838659377325, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.013622188940644264}, {"id": 757, "seek": 545248, "start": 5468.639999999999, "end": 5471.2, "text": " Would you mind dropping me an email telling me where and when?", "tokens": [51172, 6068, 291, 1575, 13601, 385, 364, 3796, 3585, 385, 689, 293, 562, 30, 51300], "temperature": 0.0, "avg_logprob": -0.2090838659377325, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.013622188940644264}, {"id": 758, "seek": 545248, "start": 5472.639999999999, "end": 5479.839999999999, "text": " I wanted to comment on the talks on AGU because well, with the names that are usually in the", "tokens": [51372, 286, 1415, 281, 2871, 322, 264, 6686, 322, 28406, 52, 570, 731, 11, 365, 264, 5288, 300, 366, 2673, 294, 264, 51732], "temperature": 0.0, "avg_logprob": -0.2090838659377325, "compression_ratio": 1.5748987854251013, "no_speech_prob": 0.013622188940644264}, {"id": 759, "seek": 547984, "start": 5479.84, "end": 5486.24, "text": " talks and also for the participants who were at the SNF in the house workshop, I collected some", "tokens": [50364, 6686, 293, 611, 337, 264, 10503, 567, 645, 412, 264, 13955, 37, 294, 264, 1782, 13541, 11, 286, 11087, 512, 50684], "temperature": 0.0, "avg_logprob": -0.19637985229492189, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.006486161611974239}, {"id": 760, "seek": 547984, "start": 5486.24, "end": 5493.4400000000005, "text": " of the talks that will be presented by participants at AGU. So we have a nice Excel spreadsheet", "tokens": [50684, 295, 264, 6686, 300, 486, 312, 8212, 538, 10503, 412, 28406, 52, 13, 407, 321, 362, 257, 1481, 19060, 27733, 51044], "temperature": 0.0, "avg_logprob": -0.19637985229492189, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.006486161611974239}, {"id": 761, "seek": 547984, "start": 5493.4400000000005, "end": 5501.04, "text": " that I could share. Please, save us a slide. Yeah, you can even filter it by daytime. So you", "tokens": [51044, 300, 286, 727, 2073, 13, 2555, 11, 3155, 505, 257, 4137, 13, 865, 11, 291, 393, 754, 6608, 309, 538, 31908, 13, 407, 291, 51424], "temperature": 0.0, "avg_logprob": -0.19637985229492189, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.006486161611974239}, {"id": 762, "seek": 547984, "start": 5501.04, "end": 5506.56, "text": " kind of have like a... So would you rather have me send your information to you so you can like", "tokens": [51424, 733, 295, 362, 411, 257, 485, 407, 576, 291, 2831, 362, 385, 2845, 428, 1589, 281, 291, 370, 291, 393, 411, 51700], "temperature": 0.0, "avg_logprob": -0.19637985229492189, "compression_ratio": 1.6033755274261603, "no_speech_prob": 0.006486161611974239}, {"id": 763, "seek": 550656, "start": 5506.56, "end": 5513.4400000000005, "text": " enrich the database? No, I think I already have you in the database. If you allow me, I can very", "tokens": [50364, 18849, 264, 8149, 30, 883, 11, 286, 519, 286, 1217, 362, 291, 294, 264, 8149, 13, 759, 291, 2089, 385, 11, 286, 393, 588, 50708], "temperature": 0.0, "avg_logprob": -0.11972252527872722, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0014547038590535522}, {"id": 764, "seek": 550656, "start": 5513.4400000000005, "end": 5521.120000000001, "text": " quickly share my screen and show you. It's just a spreadsheet and I just scraped the data from the", "tokens": [50708, 2661, 2073, 452, 2568, 293, 855, 291, 13, 467, 311, 445, 257, 27733, 293, 286, 445, 13943, 3452, 264, 1412, 490, 264, 51092], "temperature": 0.0, "avg_logprob": -0.11972252527872722, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0014547038590535522}, {"id": 765, "seek": 550656, "start": 5521.120000000001, "end": 5526.56, "text": " AGU website. So go ahead. If I'm missing someone, I could even...", "tokens": [51092, 28406, 52, 3144, 13, 407, 352, 2286, 13, 759, 286, 478, 5361, 1580, 11, 286, 727, 754, 485, 51364], "temperature": 0.0, "avg_logprob": -0.11972252527872722, "compression_ratio": 1.4745762711864407, "no_speech_prob": 0.0014547038590535522}, {"id": 766, "seek": 552656, "start": 5526.56, "end": 5535.6, "text": " Yeah, so just to give us an example, my talk...", "tokens": [50364, 865, 11, 370, 445, 281, 976, 505, 364, 1365, 11, 452, 751, 485, 50816], "temperature": 0.0, "avg_logprob": -0.1492863832894018, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.004981092642992735}, {"id": 767, "seek": 552656, "start": 5540.160000000001, "end": 5544.080000000001, "text": " Are you physically there? Yeah, I will be physically there.", "tokens": [51044, 2014, 291, 9762, 456, 30, 865, 11, 286, 486, 312, 9762, 456, 13, 51240], "temperature": 0.0, "avg_logprob": -0.1492863832894018, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.004981092642992735}, {"id": 768, "seek": 552656, "start": 5544.080000000001, "end": 5551.76, "text": " Okay, perfect. So my talk is also on Monday, but you can see what I scraped is just the ID,", "tokens": [51240, 1033, 11, 2176, 13, 407, 452, 751, 307, 611, 322, 8138, 11, 457, 291, 393, 536, 437, 286, 13943, 3452, 307, 445, 264, 7348, 11, 51624], "temperature": 0.0, "avg_logprob": -0.1492863832894018, "compression_ratio": 1.3630136986301369, "no_speech_prob": 0.004981092642992735}, {"id": 769, "seek": 555176, "start": 5552.64, "end": 5558.16, "text": " the title of the talk. These are the participants who are usually in this meetings or who are at", "tokens": [50408, 264, 4876, 295, 264, 751, 13, 1981, 366, 264, 10503, 567, 366, 2673, 294, 341, 8410, 420, 567, 366, 412, 50684], "temperature": 0.0, "avg_logprob": -0.19776954650878906, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.008311515673995018}, {"id": 770, "seek": 555176, "start": 5558.16, "end": 5564.4800000000005, "text": " the workshop. So you can see that it's Uwe Hoshin, myself. I'm the speaker and you can see who is", "tokens": [50684, 264, 13541, 13, 407, 291, 393, 536, 300, 309, 311, 624, 826, 389, 3019, 259, 11, 2059, 13, 286, 478, 264, 8145, 293, 291, 393, 536, 567, 307, 51000], "temperature": 0.0, "avg_logprob": -0.19776954650878906, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.008311515673995018}, {"id": 771, "seek": 555176, "start": 5564.4800000000005, "end": 5572.96, "text": " the speaker in this column of authors with the double mark. Thank you. That's a great help.", "tokens": [51000, 264, 8145, 294, 341, 7738, 295, 16552, 365, 264, 3834, 1491, 13, 1044, 291, 13, 663, 311, 257, 869, 854, 13, 51424], "temperature": 0.0, "avg_logprob": -0.19776954650878906, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.008311515673995018}, {"id": 772, "seek": 555176, "start": 5573.52, "end": 5577.280000000001, "text": " From what I see, we're going to be running around chasing for our...", "tokens": [51452, 3358, 437, 286, 536, 11, 321, 434, 516, 281, 312, 2614, 926, 17876, 337, 527, 485, 51640], "temperature": 0.0, "avg_logprob": -0.19776954650878906, "compression_ratio": 1.6136363636363635, "no_speech_prob": 0.008311515673995018}, {"id": 773, "seek": 557728, "start": 5577.679999999999, "end": 5583.44, "text": " If you follow this schedule very strictly, you will be around the Moscone Center a couple of", "tokens": [50384, 759, 291, 1524, 341, 7567, 588, 20792, 11, 291, 486, 312, 926, 264, 17213, 546, 5169, 257, 1916, 295, 50672], "temperature": 0.0, "avg_logprob": -0.16337344111228475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0015005770837888122}, {"id": 774, "seek": 557728, "start": 5583.44, "end": 5588.48, "text": " times, but I think you can pick and choose what looks interesting. Thanks for that. It's great.", "tokens": [50672, 1413, 11, 457, 286, 519, 291, 393, 1888, 293, 2826, 437, 1542, 1880, 13, 2561, 337, 300, 13, 467, 311, 869, 13, 50924], "temperature": 0.0, "avg_logprob": -0.16337344111228475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0015005770837888122}, {"id": 775, "seek": 557728, "start": 5590.0, "end": 5596.639999999999, "text": " So I will share the label and then we can see how it can be passed around and how I can add data to", "tokens": [51000, 407, 286, 486, 2073, 264, 7645, 293, 550, 321, 393, 536, 577, 309, 393, 312, 4678, 926, 293, 577, 286, 393, 909, 1412, 281, 51332], "temperature": 0.0, "avg_logprob": -0.16337344111228475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0015005770837888122}, {"id": 776, "seek": 557728, "start": 5596.639999999999, "end": 5604.0, "text": " it. All right, perfect. Thanks. Unfortunately, I have to go for a student exam. So one final", "tokens": [51332, 309, 13, 1057, 558, 11, 2176, 13, 2561, 13, 8590, 11, 286, 362, 281, 352, 337, 257, 3107, 1139, 13, 407, 472, 2572, 51700], "temperature": 0.0, "avg_logprob": -0.16337344111228475, "compression_ratio": 1.5614754098360655, "no_speech_prob": 0.0015005770837888122}, {"id": 777, "seek": 560400, "start": 5604.08, "end": 5610.48, "text": " comment, thinking about student exams, this thing about causal reasoning also reminds me of the", "tokens": [50368, 2871, 11, 1953, 466, 3107, 20514, 11, 341, 551, 466, 38755, 21577, 611, 12025, 385, 295, 264, 50688], "temperature": 0.0, "avg_logprob": -0.13134432301937954, "compression_ratio": 1.895397489539749, "no_speech_prob": 0.0072197760455310345}, {"id": 778, "seek": 560400, "start": 5610.48, "end": 5614.32, "text": " kind of questions we try to ask students when they're doing their qualifier or they're doing", "tokens": [50688, 733, 295, 1651, 321, 853, 281, 1029, 1731, 562, 436, 434, 884, 641, 4101, 9902, 420, 436, 434, 884, 50880], "temperature": 0.0, "avg_logprob": -0.13134432301937954, "compression_ratio": 1.895397489539749, "no_speech_prob": 0.0072197760455310345}, {"id": 779, "seek": 560400, "start": 5614.32, "end": 5618.72, "text": " their... Right, there's the kind of questions which are just about what do you know, facts,", "tokens": [50880, 641, 485, 1779, 11, 456, 311, 264, 733, 295, 1651, 597, 366, 445, 466, 437, 360, 291, 458, 11, 9130, 11, 51100], "temperature": 0.0, "avg_logprob": -0.13134432301937954, "compression_ratio": 1.895397489539749, "no_speech_prob": 0.0072197760455310345}, {"id": 780, "seek": 560400, "start": 5618.72, "end": 5623.36, "text": " regurgitate, and then hopefully you get to the kind of questions where they get to", "tokens": [51100, 1121, 5476, 8086, 11, 293, 550, 4696, 291, 483, 281, 264, 733, 295, 1651, 689, 436, 483, 281, 51332], "temperature": 0.0, "avg_logprob": -0.13134432301937954, "compression_ratio": 1.895397489539749, "no_speech_prob": 0.0072197760455310345}, {"id": 781, "seek": 560400, "start": 5624.08, "end": 5629.2, "text": " generalize beyond and that's where you test their true understanding and or intelligence.", "tokens": [51368, 2674, 1125, 4399, 293, 300, 311, 689, 291, 1500, 641, 2074, 3701, 293, 420, 7599, 13, 51624], "temperature": 0.0, "avg_logprob": -0.13134432301937954, "compression_ratio": 1.895397489539749, "no_speech_prob": 0.0072197760455310345}, {"id": 782, "seek": 562920, "start": 5630.0, "end": 5633.679999999999, "text": " So it felt... It just felt like it has direct relevance to what you were talking about.", "tokens": [50404, 407, 309, 2762, 485, 467, 445, 2762, 411, 309, 575, 2047, 32684, 281, 437, 291, 645, 1417, 466, 13, 50588], "temperature": 0.0, "avg_logprob": -0.1874559142372825, "compression_ratio": 1.5837320574162679, "no_speech_prob": 0.0016193387564271688}, {"id": 783, "seek": 562920, "start": 5636.24, "end": 5643.12, "text": " Anyway, I got to go. Bye, guys. Bye, everyone. Bye, bye. Just a final comment that we are going to", "tokens": [50716, 5684, 11, 286, 658, 281, 352, 13, 4621, 11, 1074, 13, 4621, 11, 1518, 13, 4621, 11, 6543, 13, 1449, 257, 2572, 2871, 300, 321, 366, 516, 281, 51060], "temperature": 0.0, "avg_logprob": -0.1874559142372825, "compression_ratio": 1.5837320574162679, "no_speech_prob": 0.0016193387564271688}, {"id": 784, "seek": 562920, "start": 5643.12, "end": 5651.12, "text": " be having our winter break and we are going to be back on January 17 with Manuel's presentation.", "tokens": [51060, 312, 1419, 527, 6355, 1821, 293, 321, 366, 516, 281, 312, 646, 322, 7061, 3282, 365, 34362, 311, 5860, 13, 51460], "temperature": 0.0, "avg_logprob": -0.1874559142372825, "compression_ratio": 1.5837320574162679, "no_speech_prob": 0.0016193387564271688}, {"id": 785, "seek": 562920, "start": 5652.48, "end": 5656.08, "text": " Beautiful. Thanks, everyone. Bye, guys. Thanks.", "tokens": [51528, 14724, 13, 2561, 11, 1518, 13, 4621, 11, 1074, 13, 2561, 13, 51708], "temperature": 0.0, "avg_logprob": -0.1874559142372825, "compression_ratio": 1.5837320574162679, "no_speech_prob": 0.0016193387564271688}], "language": "en"}