start	end	text
0	10800	We start diving into the greedy methods by presenting an algorithm called the orthogonal
10800	13000	matching pursuit.
13000	14000	The idea is the following.
14000	20960	We are looking at the system ax equals b and we are searching for a spar solution to it.
20960	25880	We will find the support of x by operating sequentially and gradually.
25880	30800	We start by searching the best possible solution with the support of only one atom.
30800	36160	This is done by sweeping through all the m possibilities and finding the column in a
36160	39840	that leads to the best match between ax and b.
39840	44680	Once found, this column will stay with us and we will search for the second atom to
44680	45680	join it.
45680	50920	Again, sweeping through all the a minus one possibilities, we choose the second atom such
50920	55360	that the match between ax and b is the best possible.
55360	59320	This way, the support grows by one non-zero at a time.
59320	65200	The algorithm stops when ax and b are close enough to each other.
65200	70720	Put in terms of the tree we have seen before, we start with an empty support and then check
70720	75880	m options for the first atom thus getting to the best chosen solution with cardinality
75880	76880	one.
76880	82000	Other than checking all the possibilities of cardinality two, we check only the options
82000	85640	that rely on the already found solution.
85640	92040	This process proceeds this way again and again until we get to a good enough approximation.
92040	97640	This way, instead of a combinatorial number of tests, we apply order of m tests to complete
97640	99360	the algorithm.
99360	107840	The highlighted path describes how the support has grown by one non-zero in each step.
107840	112480	While the above description may seem clear enough, it is actually a bit vague and various
112480	116920	greedy algorithms could be proposed while being based on this rationale.
116920	122600	We shall introduce several such methods and start by focusing on the OMP, orthogonal matching
122600	124960	pursuit.
124960	130160	Like all other greedy methods, the OMP generates series of solutions with gradually growing
130160	131480	support.
131480	136220	We denote these solutions as x0, x1, etc.
136220	140680	These proposed solutions do not obey the equation ax equals b.
140680	148580	And we shall denote the error vector b minus a times xk as rk, standing for the residual
148580	151820	vector at the kth step.
151820	158060	The main point in the OMP is to use the residual in each step in order to choose the next atom.
158060	163540	This will be done such that the chosen atom leads to a maximal reduction of the residual
163540	165060	energy.
165060	169980	Once we start with x0 being 0, the residual starts as the vector b.
169980	175940	We update x by adding one non-zero, becoming x1, the energy of r1 gets smaller.
175940	180700	We proceed this way, adding one non-zero at a time to the solution and reducing the energy
180700	185600	of the residual until it becomes 0 or sufficiently small.
185600	189540	And now to a detailed description of the OMP.
189540	197580	In initialization, we set k to be 0, x0 to be 0, the support s0 to be empty.
197580	199860	The residual is the vector b.
199860	203700	We increase k by 1 and perform the following steps.
203700	209980	Given the residual rk minus 1, we search for the best column to choose from a, such that
209980	215700	when multiplied by a scalar, it gives the smallest L2 difference from the residual.
215700	220860	Suppose that we did these M tests and got the error values Ei.
220860	225700	The best atom to choose is the one leading to the smallest error.
225700	228740	Let's assume that it is the atom I0.
228740	234980	Then this index joined the supports and now sk is updated to include it.
234980	240700	We proceed by updating the actual coefficients of x in the chosen support location that would
240700	245260	give the smallest L2 error between axk and b.
245260	251260	This is a simple L2 process and its result is an updated xk.
251260	259300	Our last step is to update the residual rk to be b minus a times xk.
259300	264660	If the obtained residual is small enough, we may choose to stop the algorithm, otherwise
264660	268940	we increase k by 1 and proceed.
268940	274300	Now let's zoom in on several of the steps described in order to better understand them.
274300	278500	We shall assume that the columns of a are L2 normalized, a fact that we'll prove useful
278500	280180	later on.
280180	285460	Looking closely at the computation of Ei, we are optimizing with respect to the scalar
285460	289420	z that multiplies the ith column taken from a.
289420	295020	The optimal value of z is given by a simple derivative of this L2 expression.
295020	301300	zopt equals the inner product between ai and the residual rk minus 1.
301300	307100	Notice how the denominator vanished since the atoms are normalized.
307100	312100	Plugging the expression of zopt back into the L2 error and applying few simplifying algebraic
312100	318380	steps, we get that ei equals the square norm of the residual minus the square of the inner
318380	321300	product between ai and the residual.
321300	326380	Therefore, instead of minimizing the error ei, we might as well maximize the absolute
326380	330540	value of this inner product.
330540	336340	That means that the choice of the next atom in the OMP can be done in this way.
336340	342060	Take a transpose and multiply by the current residual rk minus 1 and take the absolute
342060	343460	value.
343460	349380	The resulting vector is of length m and its maximal absolute entry points to the atom
349380	352420	to be chosen.
352420	357780	Focusing on the step of updating xk, this is a least squares computation over the portion
357780	360340	of the whole vector x.
360340	365700	Given the support as k, we are to extract only the green columns and solve for the green
365700	368060	entries in the vector x.
368060	373820	Thus, this amounts to a simple least squares with k unknowns and the solution is given
373820	378020	by the pseudo inverse of as times b.
378020	381740	Why is this algorithm called orthogonal matching pursuit?
381740	386660	The term matching refers to the correlations we apply between the residual and the atoms
386660	389780	in A in order to find the next atom.
389780	395020	By orthogonal, well, in the least squares we have just discussed, the optimal solution
395020	399700	can be found by the derivative of the L2 error with respect to x.
399700	405660	This leads to this expression, as transpose, multiplying this yellow term.
405660	409540	The yellow term is nothing but the new updated residual.
409540	414980	This means that after updating the solution xk, the inner product of the new residual
414980	420580	is orthogonal to the atoms in the support, being the bros of AS transpose.
420580	426140	This orthogonality is an asset, because it implies that once an atom has been chosen,
426140	433740	it will never be chosen again, since its inner product with the residual is zero.
433740	437980	Still on the matter of the least squares that updates xk, there is an effective numerical
437980	440460	shortcut worth mentioning.
440460	446100	The regular solution involves an inversion of a gram matrix of size k by k computed for
446100	447820	the matrix ASk.
447820	454700	However, one step before we inverted a similar matrix of size k minus 1 by k minus 1 that
454700	459060	referred to ASk minus 1 with one atom less.
459060	463020	Could we leverage the previous result in building the new one?
463020	465260	The answer is positive.
465260	470940	A new column has been added to create ASk, and along with it, a new scalar unknown has
470940	473220	been added to the vector x.
473220	477700	There is a recursive method for solving sequence of growing least squares problems of this
477700	484580	form exactly, which implies that we do not need to invert any matrix in the OMP.
484580	489060	We will not discuss this numerical shortcut further here.
489060	493820	To summarize, the OMP involves two main steps of computations.
493820	497940	The first is the sweep stage that searches for the next atom to add.
497940	503540	This requires the multiplication of A transpose by the residual vector, thus requiring mn
503540	505180	operations.
505180	509420	The second is the least square step that updates xk.
509420	515940	The main effort here is in computing AS transpose times AS, but there are various shortcuts
515940	518380	that can be applied here.
518380	524060	From line, the overall number of operations that OMP requires is on the order of k times
524060	528260	m times n, where k is the cardinality of the final solution.
