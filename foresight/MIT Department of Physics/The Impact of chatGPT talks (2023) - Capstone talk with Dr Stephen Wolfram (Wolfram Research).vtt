WEBVTT

00:00.000 --> 00:04.960
So our final speaker of the day is an external speaker.

00:04.960 --> 00:09.120
So this is Stephen Wolfram from Wolfram Research.

00:09.120 --> 00:15.240
So Stephen got his PhD in Caltech, PhD in physics from Caltech at the age of 20 working

00:15.240 --> 00:18.920
on high-energy physics quantum field theory and cosmology.

00:18.920 --> 00:23.440
He's the founder and president of Wolfram Research, developers of Mathematica and Wolfram

00:23.440 --> 00:26.640
Alpha, tools that I'm sure you've all used.

00:26.640 --> 00:30.520
And recently I think something interesting that Wolfram did was release a plug-in for

00:30.520 --> 00:36.040
chat GPT, giving access to the Wolfram Alpha computational intelligence engine, which I'm

00:36.040 --> 00:38.720
sure we will hear a little bit about.

00:38.720 --> 00:44.200
But yeah, if you're ready to go, I'll give you the floor.

00:44.200 --> 00:46.520
So I guess I want to talk about two things today.

00:46.520 --> 00:53.580
I want to talk about using LLMs for physics and how physics can help study LLMs.

00:53.580 --> 01:03.460
So to start off talking about how physics can use LLMs, the first thing is what do LLMs

01:03.460 --> 01:04.460
fundamentally do?

01:04.460 --> 01:10.740
LLMs have taken four billion pages from the web and a bunch of books, and they've kind

01:10.740 --> 01:15.580
of ground that up to find the statistics of everything that's said there.

01:15.580 --> 01:20.820
And when you ask an LLM something, its mission is to try and produce reasonable text based

01:20.820 --> 01:24.700
on kind of the statistics of what it saw on the web and so on.

01:24.700 --> 01:29.220
And as we'll talk about later, the things it extracts as its statistics are surprisingly

01:29.220 --> 01:34.660
sophisticated and include having sort of found a kind of semantic grammar of language which

01:34.660 --> 01:39.500
allows it to kind of say things that make sense, at least make some kind of sense.

01:39.500 --> 01:42.500
They may be fact, they may be fiction, but they kind of fit together in a way that makes

01:42.500 --> 01:43.500
sense.

01:43.500 --> 01:49.220
But so what the LLM is fundamentally doing is it's taking stuff we humans have put on

01:49.220 --> 01:53.620
the web, and it's feeding that back to us based on things that we ask it about.

01:53.620 --> 01:58.220
It's feeding us back sort of reasonable things that we could have said on the web even though

01:58.220 --> 02:00.500
we might not actually have done so.

02:00.500 --> 02:06.700
So it's a good way to generate our, I see LLMs actually as a practical matter as kind

02:06.700 --> 02:09.540
of an important layer of a linguistic user interface.

02:09.540 --> 02:13.420
We have graphical user interfaces, now we have a linguistic user interface where you

02:13.420 --> 02:18.860
can take like five points you wanted to make, you can puff those out with an LLM into a

02:18.860 --> 02:23.700
giant report, then maybe the person you're sending that report to really wants to know

02:23.700 --> 02:27.980
only two things, so they use an LLM again, and they grind it down and get the two things

02:27.980 --> 02:31.060
they actually wanted to know from that report.

02:31.060 --> 02:36.380
And that's a very sensible transport layer using kind of the big report as the transport

02:36.380 --> 02:41.340
layer for what's going on, and maybe that will happen with academic papers as well,

02:41.340 --> 02:46.340
that they will be just the linguistic transport layer for the actual content of what's going

02:46.340 --> 02:47.340
on.

02:47.340 --> 02:52.500
I would like to think that we can do better than that, in a sense, math has provided us

02:52.500 --> 02:56.620
a notation that's better than that, computational language, the kind of thing I've worked on

02:56.620 --> 03:00.740
for the last 40 years or so, is an attempt to kind of formalize statements about the

03:00.740 --> 03:06.420
world in a way that's kind of better than just giving it as natural language.

03:06.420 --> 03:11.180
But anyway, that's kind of, you know, what the LLM is doing is it's taking what's there

03:11.180 --> 03:15.580
on the web, it's reconstituting it and feeding it back to us, it's not going to be able to

03:15.580 --> 03:17.900
discover fundamentally new things.

03:17.900 --> 03:22.660
Well, with a couple of exceptions there, I think one thing it can do is, if there are

03:22.660 --> 03:26.580
analogies that might be found between this place and that place, it's really good at

03:26.580 --> 03:29.860
finding kind of statistical facts from language.

03:29.860 --> 03:34.180
Usually we're used to doing statistics from numbers, but LLMs manage to do statistics

03:34.180 --> 03:36.420
from text as well.

03:36.420 --> 03:42.620
And so if you say, well, what was the trend in fashion in 1955, there's a good chance

03:42.620 --> 03:47.260
that the LLM will be able to take sort of the stuff that ground up from the web and

03:47.260 --> 03:48.460
answer that.

03:48.460 --> 03:53.140
And similarly, if you say, well, could there be an analogy between, you know, metamathematics

03:53.140 --> 03:58.340
and general relativity, there's a chance that it could figure that out, because it can see

03:58.340 --> 04:03.660
that the kind of the structure of what's said about those two areas has a certain similarity.

04:03.660 --> 04:09.580
Something that seems like bizarrely magic to us humans, something that some of us humans

04:09.620 --> 04:13.540
kind of pride ourselves on being able to figure out such analogies, but I think we may be

04:13.540 --> 04:16.780
about to be outdone by the AIs.

04:16.780 --> 04:22.540
But okay, so there's sort of a question of the LLM is doing this kind of taking language

04:22.540 --> 04:27.300
from the web, giving us back some sort of reconstituted version of that.

04:27.300 --> 04:33.340
But there's more to figure out things, and for example, physics, as it has emerged since

04:33.340 --> 04:40.660
basically Newton and the Newton's big idea from 1687 was, as he called it, the mathematical

04:40.660 --> 04:42.220
principles of natural philosophy.

04:42.220 --> 04:48.140
In other words, there is a more formal method for dealing with natural philosophy, i.e. physics,

04:48.140 --> 04:51.980
than just talking about it as philosophy, so to speak.

04:51.980 --> 04:56.660
So this kind of notion of formalization that started in those days and has emerged into

04:56.660 --> 05:00.020
sort of modern mathematical methods in physics.

05:00.020 --> 05:06.500
Well, this kind of idea that you can do better than just pure thought about something.

05:06.500 --> 05:10.460
You can have a formalization that allows you to make further progress, which is most of

05:10.460 --> 05:12.980
the story of physics as we know it today.

05:12.980 --> 05:18.060
So if you're a pure LLM that's just dealing with language, that's just dealing with kind

05:18.060 --> 05:23.820
of pure common sense kinds of things, then you are stuck in the pre-Newtonian kind of

05:23.820 --> 05:26.580
paradigm for how you do physics.

05:26.580 --> 05:33.300
Well, so how do we kind of connect kind of this sort of linguistic layer of thinking

05:33.300 --> 05:39.460
about things with kind of the more formal, we might now say, computational layer of thinking

05:39.460 --> 05:40.540
about things.

05:40.540 --> 05:46.300
So I've spent most of my life kind of trying to figure out how you can sort of describe

05:46.300 --> 05:49.420
the world formally using computation.

05:49.420 --> 05:54.820
And so the question is, can you connect kind of the LLM world to this computational world?

05:54.820 --> 05:59.940
And actually, back in March, we did something with the folks at OpenAI of making a plug-in

05:59.940 --> 06:08.140
to chat GBT that allows it to kind of use our computational language from within the

06:08.140 --> 06:09.140
LLM.

06:09.140 --> 06:11.860
And I'll show you, I haven't actually used this interface for a while for reasons that

06:11.860 --> 06:13.420
I'm about to show you.

06:13.420 --> 06:23.220
But let's see, if we say make a picture of an airy function or something, let's see.

06:23.220 --> 06:26.740
Maybe it will probably, maybe, I don't know, you never know what it's going to do.

06:26.740 --> 06:31.700
It's some, okay, so it says using Wolfram, that's a good sign, maybe it's going to do

06:31.700 --> 06:36.980
the right thing, maybe not, who's to know, okay.

06:36.980 --> 06:39.660
So this is, I wonder how it did that, okay.

06:39.660 --> 06:41.900
So there it made a nice little plot of an airy function.

06:41.900 --> 06:45.340
Let's see how it did it, we're going to here, okay.

06:45.340 --> 06:48.620
So what it actually did there was it wrote a piece of Wolfram language code that just

06:48.620 --> 06:51.740
says plot the airy function, very straightforward.

06:51.740 --> 07:00.860
Let's say we say something like, I don't know, how far is it from, I don't know, Chicago

07:00.860 --> 07:01.940
to Tokyo.

07:01.940 --> 07:09.100
Wait a minute, what happens to that?

07:09.100 --> 07:10.700
It disappeared.

07:10.700 --> 07:11.700
What's going on?

07:11.700 --> 07:12.700
Scrolling down.

07:12.700 --> 07:13.700
Scrolling down.

07:13.700 --> 07:14.700
Oh, okay.

07:14.700 --> 07:15.700
Thanks.

07:15.700 --> 07:19.260
I thought I was scrolling down, it didn't seem to be showing up, okay.

07:19.260 --> 07:20.260
How lovely.

07:20.460 --> 07:25.820
So what it did there, again, was, in this case, let's see what it did here, okay.

07:25.820 --> 07:31.540
So in this case, it used Wolfram Alpha and just asked distance from Chicago to Tokyo,

07:31.540 --> 07:36.220
then it got back a bunch of results from Wolfram Alpha, which it then kind of interpreted

07:36.220 --> 07:39.100
and turned that into what it was saying.

07:39.100 --> 07:43.100
So it's sort of interesting what's happening here, because actually we have this plug-in,

07:43.100 --> 07:48.900
it's used a lot every day by people, and I think, at least when I last asked, which was

07:48.900 --> 07:53.380
a few weeks ago, there's still the case that about half of the queries go to Wolfram Alpha

07:53.380 --> 07:55.580
and half the queries go to Wolfram Language.

07:55.580 --> 07:59.580
And if you read the prompt, you know, the prompt engineering is this bizarre activity

07:59.580 --> 08:04.380
where you, whether you say please or not matters, whether things are in capital letters matters,

08:04.380 --> 08:08.300
whether you repeat things at the end of the prompt after you mentioned them at the beginning,

08:08.300 --> 08:09.300
that all matters.

08:09.300 --> 08:12.660
I will say, by the way, that if you ask, you know, what's the skill you need to do prompt

08:12.660 --> 08:17.500
engineering, so far as I can tell, expository writing is the number one skill needed for

08:17.500 --> 08:19.700
good prompt engineering.

08:19.700 --> 08:25.100
Maybe one day, and we'll talk about this later, when we talk about applying physics to LLMs,

08:25.100 --> 08:30.700
maybe there will be actual kind of AI psychology theory that can be used, but as of right now,

08:30.700 --> 08:35.580
I think it's expository writing, which kind of maps on to the kind of thing that the LLM

08:35.580 --> 08:38.100
has read from the web and so on.

08:38.100 --> 08:45.180
But in any case, the prompt here is saying, you know, if you have this kind of thing,

08:45.340 --> 08:51.860
try and send it to WolfMalpha, one of the things that's really convenient about WolfMalpha

08:51.860 --> 08:56.980
is that it is a thing that takes natural language's input, which is the same stuff that the LLM

08:56.980 --> 08:59.020
is used to dealing with.

08:59.020 --> 09:03.420
So it's kind of, it's using natural language as a transport layer, and what does WolfMalpha

09:03.420 --> 09:04.420
do?

09:04.420 --> 09:09.380
Well, what it's doing is to take whatever you type in, you know, if you type, I don't know,

09:09.380 --> 09:17.860
what is the integral of, I don't know, some random thing.

09:17.860 --> 09:24.500
What it's doing there is it's converting that question written in natural language into

09:24.500 --> 09:30.780
precise computational language internally, or if I say something like, I don't know,

09:30.780 --> 09:40.420
what earthquakes happened in Japan in August 1990 or something, I wonder if it can do that,

09:40.420 --> 09:44.940
I have no idea if it can do that, but that's always living dangerously, okay, we've managed

09:44.940 --> 09:45.940
to do that.

09:45.940 --> 09:54.380
Once again, what happened here was it converted that natural language question into its underlying

09:54.380 --> 09:58.660
computational language, which is our WolfMalph language system, to be able to resolve it.

09:58.660 --> 10:02.780
I mean, just to show you how that works, you know, if I were to say here something like,

10:02.780 --> 10:09.460
if I just said, you know, New York here, that this is a WolfMalph notebook, this thing New

10:09.460 --> 10:14.260
York, if I say what's the input form of that, it's the entity, city, New York, New York,

10:14.260 --> 10:17.300
United States, but it's also a thing that I can compute with.

10:17.300 --> 10:25.620
So if I say make a, I don't know, if I say, you know, geodistance from New York to, I

10:26.580 --> 10:32.260
don't know, London or something, it'll then just use those things as entities that it

10:32.260 --> 10:33.660
can compute with.

10:33.660 --> 10:40.180
So as I say, the sort of the mission of WolfMalph is convert natural language into this precise

10:40.180 --> 10:45.860
computational language from which we can do computations based on algorithms that we've

10:45.860 --> 10:51.700
spent the last three and a half decades, you know, setting up and based on curated knowledge

10:51.700 --> 10:55.420
that we've accumulated over the last couple of decades.

10:55.420 --> 11:02.140
So, you know, you can obviously mix things like, you can say things like, I don't know,

11:02.140 --> 11:09.340
capital cities in Europe or something, and you'll get something which again, that thing

11:09.340 --> 11:14.780
got converted into precise computational language, we can evaluate it, we can say something

11:14.780 --> 11:19.740
like, you know, I don't know, we could say make a plot of those, all those standard kinds

11:19.740 --> 11:23.580
of things that you can do in WolfMalph language, or we can find shortest tours, all those sorts

11:23.580 --> 11:24.580
of things.

11:24.780 --> 11:32.460
So, from within chat GBT, you can now access all of that functionality, so I don't know,

11:32.460 --> 11:37.140
we could, let's try, let's try doing something ambitious, which probably won't work.

11:37.140 --> 11:42.580
Find a shortest tour of the capital cities of Europe.

11:42.580 --> 11:52.580
Okay, let's watch this fail, grind, grind, grind, I have no idea, I hate to even open

11:52.580 --> 11:56.580
this to find out what horrifying thing it's actually doing in there.

11:56.580 --> 12:03.060
Maybe, maybe, let's see, okay, it's trying something again, either because it didn't

12:03.060 --> 12:07.460
get the answer it wanted, or for some other reason, oh, this is a bad sign, this is not

12:07.460 --> 12:13.460
good, this looks like it's, no.

12:13.460 --> 12:16.700
But what it's going to do, what it's doing is, every time, by the way, I mean, the way

12:16.700 --> 12:20.180
LLAM's work, we'll maybe talk about this a bit more later, they're always writing one

12:20.220 --> 12:24.980
token at a time, so they never have a plan for where they're going to go, they're always

12:24.980 --> 12:29.260
just looking at what was in the past and figuring out what to say next.

12:29.260 --> 12:32.820
So that means that it's quite often, it's kind of a hack you can use, if you get it

12:32.820 --> 12:35.900
to generate an output and you say, is that correct?

12:35.900 --> 12:40.740
And it will say, no, it's not correct, and how, why did you say it, well, because it

12:40.740 --> 12:49.740
didn't know what it was going to say, it just, well, let's see, let us see, okay, wow.

12:50.300 --> 12:59.300
Wow, wow, okay, let's see what happens, now, I have no idea if this is, okay, wait a minute,

12:59.300 --> 13:06.620
how many, how many, wait a second, okay, let's see, well, let's see, let's see what happens

13:06.620 --> 13:14.860
if we say plot that, and then I'm going to find out what it actually did there.

13:14.940 --> 13:18.940
This won't work, of course.

13:18.940 --> 13:26.940
Well, okay, this is slightly promising, I wonder if this is going to work, it's a little

13:26.940 --> 13:31.860
bit confused there, but we'll see if it can recover itself, I don't know, let's look at

13:31.860 --> 13:36.260
what it, let's look, to get some idea of whether this is actually right, let's look at what

13:36.260 --> 13:43.900
it actually asked here, okay, so it asked, okay, it did something sensible here, so what

13:43.940 --> 13:48.180
it was doing, it's a little bit confusing what it did here, and we'll see how this works

13:48.180 --> 13:53.700
a bit better in a moment, but what it did here was it was actually using results that

13:53.700 --> 13:58.700
it had got earlier in this whole sequence, because it actually knew the order of the cities

13:58.700 --> 14:02.860
by now, because it must have got that in one of these previous queries here, yeah, here

14:02.860 --> 14:08.460
we go, so it knew here, find shortest tour of those capitals, it found the shortest tour,

14:08.460 --> 14:12.060
it then used that in the next step to go and try and find something, let's see what it

14:12.140 --> 14:16.940
was doing down here, let's see what it got me where, no, it's still grinding away, oh

14:16.940 --> 14:24.460
well, alright, so, but this gives some sense perhaps of how you kind of connect sort of

14:24.460 --> 14:30.380
the LLM layer to the computational layer, but we built something recently that I think

14:30.380 --> 14:35.260
you might like to see, which is what we call, well let's see, there's different versions

14:35.260 --> 14:40.660
of this, what we call a chat enabled notebook, so this is using our notebook paradigm and

14:41.140 --> 14:47.060
let me see, let me make this a little bigger, and let me just get ready to save this,

14:49.380 --> 14:56.900
the, okay, let me tell it to use GPT-4 here, alright, so let's say we say here something like,

14:58.580 --> 15:01.620
again, I'm going to look very dangerously, because this never does the same thing twice,

15:02.580 --> 15:07.460
let's say solve a harmonic oscillator, and harmonic oscillator, whatever,

15:08.020 --> 15:22.500
uh, let's see what happens, oops, so, okay, okay, I mean it'd be not the right thing for it to do,

15:22.500 --> 15:32.580
but anyway, let's see, um, huh, okay, not terrible, let's say show me the equation,

15:38.260 --> 15:41.460
so we'll talk in a minute about what the heck it was actually doing here,

15:42.100 --> 15:45.380
that's not very useful, I want to know the differential equation,

15:46.980 --> 15:49.220
if you want to visualize it, okay, let's see what it does,

15:53.460 --> 15:59.060
let's see, you never know what this thing is going to do, so it's just kind of,

16:00.020 --> 16:07.380
um, okay, that's not terrible, I would give that a, you know, maybe a pass and grade, I don't know,

16:08.340 --> 16:15.140
let's see what it actually did, so here, it, okay, so it synthesized, well from language code here,

16:16.260 --> 16:21.540
this, what these boxes look like inside, probably by next week will look a bit better than what it

16:21.540 --> 16:28.180
does right now, but, you know, it synthesized some code here, actually, if I say here,

16:29.460 --> 16:38.660
you know, show me the ODE, let me see whether it can do that, um, okay, great,

16:41.060 --> 16:48.820
okay, very good, yes, yes, all good, is that right, no, yes, yes, that's right, that's okay,

16:49.780 --> 16:56.580
um, now I say solve that, okay, not bad,

16:59.860 --> 17:07.700
so, you know, this kind of thing I view as being a pretty useful, come on, I just want to see the

17:07.780 --> 17:14.980
equation, um, what I want to see is the, is the code here, okay, let's say show me the code,

17:18.260 --> 17:25.140
because this is, this is in a sense, okay, finally we got it, okay, and then what we can do here

17:25.140 --> 17:29.380
is given this piece of code, we can just say, for example, we can just say evaluate code,

17:29.380 --> 17:34.580
oh look, wait a minute, something is happening in the background here, it apologizes for the

17:34.580 --> 17:44.260
inconvenience, um, who knows what it's doing, we'll check back for that in a few moments,

17:45.620 --> 17:53.300
but back in this notebook, we're here, I can just say use that thing to copy that

17:53.860 --> 18:00.100
code down there to the next cell and then do the evaluation and get the result, so it's kind of

18:00.100 --> 18:04.500
interesting, you know, if I go back here, maybe I can try another example, let me show you how

18:04.500 --> 18:09.700
this works, I can put in what we call a chat block, that basically breaks the context of the LLM,

18:09.700 --> 18:15.780
so the LLM, whenever I'm saying, when I say show me the code, when I ask that, it's able to see the

18:15.780 --> 18:25.060
whole, the whole conversation that it's had above it, okay, so that's um, and so now here, I broke

18:25.060 --> 18:31.140
that by saying show me another, show me another thing here and I could say, well here, for example,

18:31.140 --> 18:36.980
I can do this pull down and this um, this allows me to make all kinds of changes, so I could, for

18:36.980 --> 18:44.740
example, we have this prompt repository that contains, there we go, so it contains various um,

18:44.740 --> 18:49.940
well many, okay, we can go to the prompt repository here, this is a prompt repository that has, in

18:50.020 --> 18:55.300
this case, it will allow us to pick personas for interacting with this, so I could pick um,

18:55.940 --> 18:59.700
I don't know, let's try this, I have no idea what this is going to be like, okay, so as I

18:59.700 --> 19:05.540
install the 19th century British novel persona, I've installed that, actually I kind of think we

19:05.540 --> 19:12.180
should use Bernardo, he's fun, um, but either one, okay, so I can now pull this down, okay, we can try

19:12.180 --> 19:28.580
19th century British novel, um, make a picture of a circle, uh, that is half red and half blue,

19:28.580 --> 19:42.900
let's say, now I think this will, uh, oh come now, oh great, well that's, that's okay, big mess, um,

19:45.140 --> 19:52.420
bad taste, okay, and this code snippet, blah blah blah, good luck, well let's try, all right,

19:52.420 --> 19:57.780
let's try, let's try doing this, actually I should just stop this yacking on like this,

19:58.420 --> 20:03.140
let's try, let's try a different persona, let's try, let's try the code assistant, but actually,

20:03.140 --> 20:09.540
you know what, I'm going to try Bernardo, Bernardo is fun, let's, let's try re-evaluating that,

20:13.540 --> 20:19.460
the, now what's it doing there, I don't know, this first creates a full red disk and it overlays

20:19.460 --> 20:25.780
a hard disk, okay, I wonder if this is actually right, dah, okay, it worked, nice, what's important

20:25.780 --> 20:30.420
about this, this maybe isn't the very best example, is you can actually read that code,

20:30.980 --> 20:36.580
unlike the, the thing that it happened to produce before, um, and the, the kind of the idea is,

20:36.580 --> 20:40.740
and this is by the way one big feature of, of kind of the whole computational language story

20:40.740 --> 20:45.620
that I've spent so long on, is that, you know, our language is intended as something that you can

20:45.620 --> 20:51.860
think in, as well as have your computer execute, so to speak, kind of like math notation would be,

20:51.860 --> 20:57.620
it's something that, where you can actually, you know, use it as your foundation for thinking about

20:57.620 --> 21:02.340
things, okay, anyway, that this is, you, you get the basic idea, I hope, of, of sort of this chat

21:02.340 --> 21:07.620
notebook notion, it's, it's pretty nice, I mean, I have to say, since the reason that I haven't used

21:07.620 --> 21:14.340
that, um, the chatGBT interface for months, is because this is really a lot nicer, you get to,

21:14.340 --> 21:18.500
not only, you know, you can also use all the standard features of notebooks, so you can say,

21:19.140 --> 21:25.300
this is a section about circles, and you can start putting in, maybe I could, well actually,

21:25.300 --> 21:32.740
let me just do this, hold on, let's say, do that, I'm not going to live dangerous, do that for a sphere,

21:32.740 --> 21:41.380
this is going to fail, of course, okay, let's see what happens, okay, interesting idea, interesting

21:41.380 --> 21:47.140
idea, I wonder whether that will work, that's definitely an interesting idea, I give that

21:47.140 --> 21:54.740
point, the spherical plot, that goes, wow, if this works, I'll be impressed, okay, let's run it,

21:56.020 --> 22:04.180
wow, that's cool, it's getting smarter, the, or how, or the fine tuning that we've done and so on

22:04.180 --> 22:09.300
is actually working, this is encouraging, um, the, because this is kind of interesting, I mean,

22:09.300 --> 22:15.940
it made a spherical plot over a certain, you know, latitude, sequence of latitude values,

22:15.940 --> 22:20.100
a different sequence of longitude values here, that's kind of interesting, you kind of learned

22:20.100 --> 22:24.980
something from that, maybe we could try, let's try one other thing, which might be fun, let's say,

22:25.860 --> 22:40.340
um, uh, show a star chart of the current position of Jupiter, now I'm probably going to have to say,

22:40.500 --> 22:44.980
use astrographics, let's see what will happen here,

22:48.820 --> 22:58.740
oh, come on, it just, well, I think it made that up, I'd be very surprised if these functions

22:58.740 --> 23:08.180
actually exist, no, they do not exist, um, well, that's a bad sign, okay, let's try saying use

23:08.260 --> 23:14.180
astro position, and what I'm expecting it's going to do, maybe,

23:19.300 --> 23:23.780
lovely, but that's also not relevant, okay, it's not doing what I thought it would do,

23:23.780 --> 23:29.700
which is to go read the documentation, we can, we could probably tell it to do that, let's say, um,

23:30.020 --> 23:41.380
blah, blah, blah, there we go, now maybe it'll get a little bit smarter,

23:47.060 --> 23:50.500
okay, this is much better, this is much, much better sign,

23:51.540 --> 23:57.060
so hopefully, if it read the documentation, it will be able to successfully do what it was,

23:58.020 --> 24:03.380
all right, I don't know whether it's blah, blah, blah, blah, blah, now probably if we now say,

24:03.380 --> 24:09.300
okay, great, it's talking about all kinds of, I don't know, it's telling us how to find the

24:09.300 --> 24:12.900
position of the large Magellanic cloud, et cetera, et cetera, et cetera, that's all fun,

24:12.900 --> 24:21.940
and we could ask it to run that, but I think use this for the picture of Jupiter,

24:22.020 --> 24:30.340
maybe this will work, maybe it won't, okay, this is much better, what,

24:32.100 --> 24:37.700
you see this is the problem, it just makes stuff up, well let's see, I wonder whether this will

24:37.700 --> 24:42.660
work, no, it made up the thing called planet marker, well we'd have to tell it not to do that,

24:43.380 --> 24:47.940
it's supposed to go back, and I'm a little bit surprised it did that here, because actually

24:48.020 --> 24:53.620
it has been told to go back and check the code it wrote to make sure that everything in it actually

24:53.620 --> 24:59.380
exists, so for some reason it didn't in this case, all right, well anyway, that's a little bit on

24:59.380 --> 25:05.700
kind of the sort of the interface between sort of LLMs, computational language, I thought another

25:05.700 --> 25:14.900
thing I would talk about, quite different subject, is using physics to think about LLMs, so let me

25:14.980 --> 25:20.260
pull up some things, so first question is what fundamentally is an LLM doing, as I said, what

25:20.260 --> 25:26.340
it's ultimately doing is it's saying, given a particular piece of text, let's see if this works,

25:26.340 --> 25:30.660
okay, so if you have something like this, you feed the prompt, the best thing about AI is its

25:30.660 --> 25:35.540
ability to, and then its mission is to give you what the next word should be, and there are

25:35.540 --> 25:42.900
some probabilities that it uses to do that, so if we kind of, we're interested in knowing, where's

25:42.900 --> 25:57.940
my mouse, come on, up, just a second, sigh, you know, maybe I should just, well, okay, let me just,

25:59.380 --> 26:12.180
that's very strange, fascinating, okay, the lost mouse, okay, the lost mouse has been found,

26:12.980 --> 26:20.340
maybe, all right, so just, I mean, let's talk a little bit about what,

26:23.300 --> 26:30.420
actually, let me show you something else here, so in our language, well, no, we can do it here,

26:31.300 --> 26:40.820
we can just say, let's use a plain chat, and let's set it so that one of the parameters is,

26:40.900 --> 26:45.060
we saw those probabilities that the LLM produced for what the next word should be,

26:45.700 --> 26:50.740
one of the things about LLMs is they have to decide, given those probabilities, which actual

26:50.740 --> 26:56.100
word should be picked, like one thing it could do is say, always pick the most probable word,

26:56.100 --> 27:02.660
another thing it could do is pick those words according to the probabilities as it generated them,

27:02.660 --> 27:06.740
there's this thing that's usually called the temperature parameter, which is an exponential

27:06.740 --> 27:12.100
distribution thing that basically is the thing that picks, zero temperature means always pick

27:12.100 --> 27:17.780
the most probable word, temperature one means pick the words in the probabilities that the LLM

27:17.780 --> 27:24.980
generated itself, as you increase the temperature, it's picking more and more bizarre words, so let's

27:24.980 --> 27:31.220
say we go here and let's say we increase the temperature to like 1.3, let's say, and we say

27:31.220 --> 27:40.580
something like, how are you today, and it will generate some, so this is now using, okay, right,

27:40.580 --> 27:46.340
great, okay, now let's try, let's change that temperature, let's go ahead here and just crank

27:46.340 --> 28:05.380
up that temperature, and let's try running this again, oh my, so I'm bonkers, oh no,

28:06.100 --> 28:10.580
okay, well at least it's stopped, often it never generates a stop token, it just keeps going forever,

28:11.300 --> 28:18.340
the, so okay, so here's an example of a physics question, is there a phase transition as a function

28:18.340 --> 28:24.500
of temperature in an LLM? The answer is almost certainly yes, probably around for something

28:24.500 --> 28:29.540
like GPT-4, it's almost certainly at a temperature around 1.3 or so, maybe there are actually two

28:29.540 --> 28:35.060
transitions that occur, actually there's a, we just had a summer school with people studying

28:35.060 --> 28:40.100
all kinds of things, and one person at our summer school studied this question, and I have to admit,

28:40.100 --> 28:45.060
I haven't read the thing they wrote about it, so, but I can show you, this is basically,

28:45.060 --> 28:51.140
as a function of temperature, this is essentially an order parameter changing, and in the LLM,

28:51.140 --> 28:55.300
and this is someplace here, this is an actual, you know, there's some innards of an LLM,

28:56.340 --> 29:02.420
and somewhere here, there should be, okay, that's some random pieces of language code,

29:02.500 --> 29:10.260
I think what was done here was to look at the extent to which it maintains kind of

29:12.020 --> 29:17.380
coherence in the structure of the sentences that it produces and so on, but anyway, the thing that

29:17.380 --> 29:23.620
I wanted to point out there is this is a very physics-like question, what, how does this work,

29:23.620 --> 29:28.580
and one of the things we don't have right now is a kind of good qualitative physics,

29:28.580 --> 29:34.100
overall physics-like model for an LLM, like you might say, oh, maybe it's like a spin glass,

29:34.100 --> 29:37.620
well, it's not really like a spin glass, maybe it's like some other statistical

29:37.620 --> 29:43.460
mechanics system, what is it really like? Well, there are a few things that we kind of know

29:43.460 --> 29:49.460
about LLM, so I can show you some pictures, let me just show you, just to get a sense of what's

29:49.460 --> 29:55.300
going on inside here, this is kind of a, like, let's say we're trying to learn this function,

29:55.300 --> 30:00.340
so we've got x and y are input parameters, and we're trying to learn that function,

30:00.340 --> 30:05.380
we're going to have a neural net, there's a neural net, and that neural net is taking those values,

30:05.380 --> 30:11.620
x and y, and at the top it has some weights, each of the connections has a certain weight,

30:11.620 --> 30:17.300
it indicated by the color of that, that connection, and then if we feed in particular values up at

30:17.300 --> 30:21.940
the top there, this neural net will have been trained, will have been set up with the correct

30:21.940 --> 30:27.620
weights, so that it will always produce a 0, 1, or minus 1 at the bottom, so for example we can,

30:28.340 --> 30:36.020
let's just, let's say, if we try and use a very, very trivial neural net, trying to learn that

30:36.740 --> 30:42.740
function, the totally trivial neural net will not succeed in producing that function, if we make

30:42.740 --> 30:47.540
the neural net more sophisticated, here are some slightly more sophisticated neural nets, as the

30:47.540 --> 30:51.460
neural net gets more sophisticated, it's going to be able to successfully learn that function,

30:51.940 --> 30:56.820
how big does a neural net have to be to learn what level of function, not really known, I mean

30:56.820 --> 31:00.740
there are theorems that say in principle you can do things with neural nets of certain sizes,

31:00.740 --> 31:08.260
but the practical question we don't know, that's another kind of thing, so now you know in terms of

31:08.260 --> 31:15.860
what, let's see, the, I mean you can do these experiments by the way, the things I've written

31:15.860 --> 31:20.820
about, I wrote some kind of whole explainer of chat GPT, which was one of the things that I've

31:21.140 --> 31:25.940
written fastest in my life, and it's the thing that seems to be read more, at least per unit of

31:25.940 --> 31:29.780
time spent on writing it, it seems to have been read more than anything else I've written, which

31:29.780 --> 31:35.060
to me is a little bit disappointing actually, but that's a different story, but anyway, so

31:36.340 --> 31:43.300
those are some things about the innards of chat GPT, and those are some, but we can start looking

31:43.300 --> 31:48.180
at kind of what's actually going on inside the system, and it's kind of complicated, and you

31:48.180 --> 31:54.820
start seeing, you know, this is a condensation of the kind of innards of the brain of actually this

31:54.820 --> 32:02.740
is GPT2, kind of a junior version of chat GPT, and this is kind of, in a sense this is taking

32:02.740 --> 32:08.340
human knowledge and human linguistics, and crushing it down to something that's represented

32:08.340 --> 32:12.820
in terms of arrays of numbers, and this is one of the pieces of what you see when that's done,

32:12.820 --> 32:19.620
I mean the full chat GPT has like 175 billion weights, this is just showing a little piece of

32:19.620 --> 32:28.420
that story. Now, okay, what can we say about what it actually does? Well, there's several

32:28.420 --> 32:33.540
different things, so one thing that's important is this concept of embeddings, we can take

32:34.260 --> 32:40.100
kind of, you know, words in a language, sentences, things like that, the big sort of idea of neural

32:40.100 --> 32:43.860
nets in some sense, and it's a very old idea, dates all the way back to when neural nets were

32:43.860 --> 32:50.980
invented in the 1940s, is don't just use digital information, use arrays of real numbers to represent

32:50.980 --> 32:55.620
things. It's not clear that you actually need to do that, you probably don't, I don't think you need

32:55.620 --> 33:01.380
to do it for physics, for example, but the way that neural nets are built, they are take everything,

33:01.380 --> 33:05.860
whether it's an image, whether it's text, whatever else, and grind it into arrays of real numbers,

33:05.940 --> 33:13.300
and then you can take those, then what you're doing is representing everything, you know,

33:13.300 --> 33:18.180
just as in standard digital computational stuff, you're representing things as bits in neural

33:18.180 --> 33:23.220
nets, you're representing everything in terms of arrays of real numbers, and so for example, any

33:23.220 --> 33:28.500
old sentence, any old piece of text is ultimately represented as an array of real numbers, and

33:28.500 --> 33:33.860
that array of real numbers we can think of as being some sort of feature vector that represents,

33:33.860 --> 33:40.020
in some sense, some digest of the meaning of the thing that we specified. So you can start

33:40.020 --> 33:46.500
asking in meaning space, in that space of embeddings, what can we see about what happens in that space,

33:46.500 --> 33:53.220
and for example, let's see, we can ask questions like, how linear is that space? You know, for

33:53.220 --> 33:57.940
example, if we do parallel transport in that space, if we look at the curvature of that space,

33:58.020 --> 34:04.340
we're looking at, you know, this is to that, as that is to that, that's kind of the analog for

34:04.340 --> 34:11.380
linguistics for sort of the structure of meaning of a question that you might ask in

34:12.500 --> 34:17.220
physics of space time or something, and you can ask about these questions about curvature in that

34:17.220 --> 34:24.020
space, I don't know all the answers to this, you can also ask things like, well, what is the trajectory

34:24.020 --> 34:31.220
that's carved out in that space? So is there, for example, a semantic law of motion? If you start

34:31.220 --> 34:36.820
in this particular way, is it the case that in this meaning space that you end up always tracing

34:36.820 --> 34:41.540
through in a particular way? And one thing that seems to be the case, the space to some experience

34:41.540 --> 34:47.700
we just did a couple weeks ago, is that the things are much more organized. So if you look at,

34:48.500 --> 34:50.980
oh, this is kind of, sorry, let me just show you,

34:52.900 --> 34:59.220
much of the time these trajectories aren't, in something like GPT2, the trajectories are

34:59.220 --> 35:03.940
quite disorganized. It seems that as you get to things like GPT4, the trajectories look a lot

35:03.940 --> 35:09.300
more organized. It's much more believable that there are semantic laws of motion, so to speak,

35:09.300 --> 35:14.980
laws of motion in meaning space in GPT4. By the way, it's worth realizing that there's sort of a

35:15.060 --> 35:21.940
quantum story to the whole thing because the whole thing is, it isn't just picking one trajectory,

35:21.940 --> 35:27.220
it's picking a whole bunch of different paths. One difference from, I mean, this is a quite

35:27.220 --> 35:31.540
different topic, but in the whole fundamental physics project that we've been doing for the

35:31.540 --> 35:36.100
last few years where it seems like we really actually do finally understand how quantum mechanics

35:36.100 --> 35:41.860
works, it becomes very important in that case that there is merging of different paths of history,

35:41.860 --> 35:49.220
as well as just branching the paths of history. In the current versions of these LLMs, there's

35:49.220 --> 35:53.700
pretty much just branching the paths of history, but you kind of get this quantum-like phenomenon

35:53.700 --> 35:58.820
going on of all these different possible things the LLM might say that aggregate up to different

35:58.820 --> 36:04.020
kinds of things. By the way, if you're, well, there's all kinds of interesting things to say

36:04.020 --> 36:14.020
about LLMs as observers in thinking about physics, but maybe one thing to talk about is just what is,

36:14.820 --> 36:22.500
this is sort of pictures of what meaning space looks like and so on, and questions like if you

36:22.500 --> 36:29.140
have a word and it has many different sort of partially, so this is the word crane, I think,

36:29.140 --> 36:35.620
and this is, in meaning space, this is where different sentences that mention cranes show up,

36:35.620 --> 36:39.460
and so I think the ones at the top are cranes as a bird and the ones at the bottom

36:39.460 --> 36:44.420
are cranes as construction equipment type thing, and you kind of see that separating, so you can

36:44.420 --> 36:49.220
kind of get, again, it's this kind of rather physics-like thing of kind of looking at this

36:49.220 --> 36:56.260
meaning space, and by the way, you can sort of ask things about the structure of that meaning space,

36:56.260 --> 37:00.900
and for instance, let me see if I can show you a picture, let me see here,

37:03.620 --> 37:10.660
maybe, okay, so in meaning space, you can ask something like, you can also do that with images,

37:10.660 --> 37:15.620
and so you can ask, for example, we can go in meaning space, we can go from a dog image

37:15.620 --> 37:22.180
to a cat image on the line in meaning space between a dog and a cat, and we could actually

37:22.260 --> 37:27.780
keep going from the cat out further, we can extend that line further out in meaning space,

37:27.780 --> 37:31.460
and we get all these kinds of weird things happening, or we can go from a plane to a cat,

37:31.460 --> 37:36.020
and we have something very strange in the middle of those two things, or we can just go out,

37:36.020 --> 37:41.860
this is what I was calling cat island, this is in the middle, so this was a generative AI,

37:42.580 --> 37:48.820
not specifically an LLM, this is an image generation AI, which uses somewhat similar,

37:48.820 --> 37:56.420
but not precisely the same technology inside, and I asked it in the middle to make a picture of a

37:56.420 --> 38:01.380
cat in a party hat, and then as you go outwards in meaning space, you see this kind of island

38:01.380 --> 38:06.100
of where you can see sort of identifiable cat things going on, and then further away,

38:06.100 --> 38:10.340
it becomes more and more bizarre, and by the way, you can ask questions like, well, what's actually

38:10.340 --> 38:16.180
out there in sort of arbitrary meaning space, and I think, well, you can look at other cat islands

38:16.260 --> 38:21.940
here, this thing is actually in 2000 dimensional space, and these are planes in 2000 dimensional

38:21.940 --> 38:27.460
space, different planes in 2000 dimensional space, and you see different cats live on different planes,

38:28.740 --> 38:35.220
but sometimes you can just, if you plop into this meaning space in some random place, you'll see

38:35.220 --> 38:41.220
things which kind of look, well, I don't know what those are, but sometimes you'll see things which

38:41.300 --> 38:46.900
kind of have a reminiscent of kind of human forms and so on, why does all this happen, same kind of

38:46.900 --> 38:52.580
reason as with LLMs, because this was trained from a five billion images, which were actual images

38:52.580 --> 38:59.860
people put on the web, and those actual images are of human relevant kinds of things, with images

38:59.860 --> 39:06.260
more so than with text, we're able to, as humans, we're able to look at things that weren't quite

39:06.260 --> 39:10.260
right, like we looked at that high temperature version of what the LLM produced, and it looked

39:10.260 --> 39:15.940
like garbage to us, it was incomprehensible, for images we do a little better at being able to

39:15.940 --> 39:20.900
not be just completely confused by what's going on, but if we kind of dive in and look, you know,

39:20.900 --> 39:26.580
what's out there in arbitrarily, let's see where do I have a picture of that, well, those are some

39:26.580 --> 39:33.620
pictures just randomly out there in kind of meaning space, and if you go in you can see,

39:33.620 --> 39:37.540
you know, there are weird things like this, these are, you know, people like pictures, or you can

39:37.540 --> 39:41.940
have, you know, pictures like these, which are kind of reminiscent of sort of landscape-like

39:41.940 --> 39:45.940
pictures, but aren't really landscape-like pictures, but this whole question about,

39:45.940 --> 39:53.300
you know, where in meaning space, where in this, I mean, there's this, if you try and imagine,

39:53.300 --> 39:58.980
where is the stuff that's meaningful, 10 to the minus 600 of all of meaning space is what we have

39:58.980 --> 40:04.740
so far explored as with sort of human language and so on, it's a very small fraction of it,

40:04.740 --> 40:10.340
with respect to images. Okay, so just to maybe finish off a bit, we could talk more about this

40:10.340 --> 40:15.940
kind of thing, but just to talk a little bit about sort of the physics of LLMs and so on,

40:16.580 --> 40:22.660
I think one of the things people, what one wants to do is, is there a kind of a narrative story of

40:22.660 --> 40:30.420
what LLMs are finding? Is there a way of saying, why do LLMs even work? It's not obvious that,

40:30.420 --> 40:36.900
you know, given that you, you know, you could say, take a sentence like, the cat sat on the,

40:37.540 --> 40:43.060
okay, based on just looking at pages on the web, you can reasonably guess the next word is going

40:43.060 --> 40:47.380
to be math, but by the time you've got a long prompt where you're asking it some physics question

40:47.380 --> 40:54.500
or something, there's no way that actual detailed text is going to be somewhere on the web, or

40:54.500 --> 40:59.380
probably not, unless it was some exercise or a book or something, but most of the time it won't

40:59.380 --> 41:04.180
be something that was on the web. So you have to have an actual model that allows you to extrapolate

41:04.180 --> 41:09.940
the model that's being used in chat GBT as a neural net. It is far from obvious. There's no

41:09.940 --> 41:15.380
fundamental reason to think it would be true that the way the neural net extrapolates will agree with

41:15.380 --> 41:21.860
the way we humans think it makes sense to extrapolate. The fact that it extrapolates to produce things

41:21.860 --> 41:27.300
that seem meaningful to us humans is a nontrivial scientific result. And, you know, I think what

41:27.300 --> 41:34.020
it's basically telling us is the way brains work is actually pretty well modeled by sort of neural

41:34.020 --> 41:39.780
net type things. And that's why the things that brains extrapolate with are pretty close to the

41:39.780 --> 41:45.460
things that these simple neural nets extrapolate with. So then the question is, well, okay, we've

41:45.460 --> 41:50.100
got this kind of extrapolation that's going on. We've got some, this thing is finding out some

41:50.100 --> 41:55.700
way to extrapolate. How is it doing that? Well, what regularities in language is it picking up to

41:55.780 --> 42:00.740
allow it to make meaningful sentences, meaningful text? Well, there's one big regularity that we

42:00.740 --> 42:06.340
know about in language, which is syntactic grammar. We know how you put parts of speech together,

42:06.340 --> 42:12.100
nouns and verbs and things like this. So in a sense, we can then construct sentences which

42:12.100 --> 42:18.100
are syntactically correct. But there are infinite number of sentences that are syntactically correct

42:18.100 --> 42:24.020
but complete nonsense. And that's, it's doing much better than just producing syntactically correct

42:24.020 --> 42:30.100
sentences. So what's it doing? Well, there's one good example of a place where we know a structure

42:30.100 --> 42:37.220
in sentences that exists that isn't sort of purely syntactic. And that's logic. And you can kind of

42:37.220 --> 42:41.860
think, you know, when Aristotle invented logic back a couple of thousand years ago, you know,

42:41.860 --> 42:46.100
what was he actually doing? Well, he was a bit like a machine learning system, because what he was

42:46.100 --> 42:51.140
effectively doing was saying, I've got all these examples of rhetoric. People make an argument

42:51.140 --> 42:56.420
that looks like this, but I can take something which instead of it being a discussion about, you

42:56.420 --> 43:02.580
know, Sparta and Athens, it can be a discussion about turtles and fishes. It doesn't matter. I can

43:02.580 --> 43:07.940
just replace those symbolically with P and Q and I can look at this sort of formal structure of these

43:07.940 --> 43:15.060
sentences. In a sense, you can lift logic out of the specifics of actual language, in his case,

43:15.060 --> 43:22.260
Greek. But in a sense, what LLMs have done is they've discovered the same thing. So people say,

43:22.260 --> 43:27.140
oh, my gosh, it's amazing, you know, LLMs have discovered logic. Well, they discovered logic,

43:27.140 --> 43:31.220
I think the same way Aristotle discovered logic, and you can find out they're basically doing

43:31.220 --> 43:36.500
so logistic logic. And if you try and feed them things which require sort of more formal, more

43:36.500 --> 43:41.300
formal kinds of things, even at the level of, you know, parenthesis matching and so on, they will

43:41.300 --> 43:46.340
fail after you get sort of too many parentheses to match. They don't do kind of the formal level

43:46.340 --> 43:52.260
of things. They don't do the computational thing. They do the kind of level of things that in a sense

43:52.260 --> 43:56.820
was the original way that logic was discovered. So that's a place where kind of one's able to lift

43:56.820 --> 44:03.140
something more semantic out of this kind of layer of pure language. But presumably, there is more

44:03.140 --> 44:08.660
that can be done along those lines. Presumably, there is kind of a semantic grammar of language,

44:08.660 --> 44:16.340
which in a sense, the LLMs have discovered something about language and common sense

44:16.340 --> 44:21.860
reasoning and so on. That is that there's this sort of thing you can lift out of language

44:21.860 --> 44:28.580
that allows you to kind of put together meaningful stuff beyond just the purely syntactic. And I

44:28.580 --> 44:32.580
think that's the thing where, well, I've been interested in this actually for a long time

44:32.580 --> 44:38.900
for different reasons, this kind of idea of sort of making a symbolic discourse language that allows

44:38.900 --> 44:47.300
you to sort of express things in a kind of, in a way that is sort of, is a symbolic way of expressing

44:47.300 --> 44:52.660
things that is not specific to the particulars of language. In a sense, the whole enterprise of

44:52.660 --> 44:58.020
making a computational language has got a certain distance with that, describing certain kinds of

44:58.020 --> 45:03.140
things in the world. But anyway, I think that there are many pieces of kind of what happens in

45:03.140 --> 45:09.380
LLMs. For example, why does few shot learning work? Why does it work to tell LLM and LLM to talk

45:09.380 --> 45:15.460
like a pirate? Why does it, how does that manage to place it somewhere in meaning space or something

45:15.460 --> 45:20.260
so that the kind of, you know, you placed it somewhere by giving that prompt, then somehow

45:20.260 --> 45:25.060
the semantic law of motion takes over and it successfully manages to produce semantically

45:25.060 --> 45:30.340
meaningful stuff. We don't know how any of this works. It's a great topic for physicists, I have

45:30.340 --> 45:36.660
to say. I think it's one of these places where it isn't particularly easy. It's something where,

45:36.660 --> 45:42.100
you know, this space of, you know, this sort of meaning space we're looking at with these images,

45:42.100 --> 45:46.580
we can sort of see things about what's out there in meaning space in a way it's a little bit easier

45:46.580 --> 45:51.380
than with text and words. But we're kind of, you know, this is sort of just the beginning of,

45:51.380 --> 45:55.220
in a sense, physicalizing using something like statistical mechanics

45:55.220 --> 46:00.980
to try and analyze what's happening inside an LLM. So I think kind of to sort of summarize,

46:00.980 --> 46:06.420
I mean, I've talked about two kinds of things. One is just the very practical aspects of using

46:06.420 --> 46:14.180
LLMs to, I think the most significant workflow there is this. You have a vague idea of what you

46:14.980 --> 46:21.860
want to do. Now I have to say to get that vague idea, you have to have an ability to sort of

46:21.860 --> 46:27.700
think computationally about things until you can express yourself in some kind of sort of

46:27.700 --> 46:34.340
with computational concepts. I mean, it's no good, you know, with some notion of how you think about

46:34.340 --> 46:38.980
the world computationally. Once you have that, you can kind of write a piece of natural language,

46:38.980 --> 46:45.140
you go sort of tell that to the LLM. The LLM will then write, you know, will write

46:45.140 --> 46:52.340
Wolfram language code or whatever, sometimes correctly, that will be an expression of what

46:52.340 --> 46:57.780
it thought you meant by the things that you said in natural language. Now sometimes when you look

46:57.780 --> 47:02.580
at that Wolfram language code, you'll say you misunderstood. It wasn't correct. You can fix

47:02.580 --> 47:08.180
that code or you can tell it to go fix the code or whatever else. But so the workflow is, you know,

47:08.180 --> 47:15.140
computationally imagine what you want to do, write it in natural language, have it kind of

47:15.140 --> 47:19.940
translated into computational language, then read the computational language. It's very important

47:19.940 --> 47:24.420
that something you can do with Wolfram language, no other, you know, that's the story of computational

47:24.420 --> 47:29.300
language, very different from programming languages which weren't intended for humans to read

47:29.300 --> 47:35.620
particularly. But so that's something where you read that computational language, you understand

47:35.620 --> 47:41.300
what it said, you fix it if you need to, then you say run that, then that becomes a sort of brick

47:41.300 --> 47:48.180
that you can use to build a whole tower of what you want on top of. And so that's, I think that's

47:48.180 --> 47:55.380
the workflow and, you know, I have to say, as we make these chat notebooks better, it's getting

47:55.380 --> 48:00.500
closer to the point where it actually makes sense, even if you know Wolfram language well,

48:00.500 --> 48:06.260
to try and use it as a way to get things started if you're not thinking very clearly, so to speak.

48:06.260 --> 48:10.980
Although as I say, to get the prompt right, you have to be kind of think expository writing because

48:10.980 --> 48:16.420
if you're totally confused, the LLM will be confused as well. But anyway, so the first thing I was

48:16.420 --> 48:24.020
talking about was this idea of how do we make use of LLMs mostly as a way to kind of get a leg up

48:24.020 --> 48:31.300
on creating kind of computational language to be able to actually do computations. I should say,

48:31.300 --> 48:39.380
by the way, I'm happy to talk about this, people interested if we have any time. But there's many

48:39.380 --> 48:45.700
use cases, like for example, we're working on a bunch of AI tutoring applications. Another use

48:45.700 --> 48:50.340
case I mentioned for physics, we've never been able to do, in Wolfram Alpha for example, we've

48:50.340 --> 48:56.420
never been able to do physics word problems. We can do that once you've turned the word problem

48:56.420 --> 49:02.660
into equations, for example, we can we can nail it. But turning going from the whole long textual

49:02.660 --> 49:09.140
description into the equations is not something we've been able to do. Now we can. Now, in fact,

49:09.140 --> 49:14.180
in practice, when you use LLMs, one of the things that's terrible, you know, you use the for example,

49:14.260 --> 49:20.660
a chat notebook or the Wolfram plugin for chat GBT, it'll sometimes, you know, correctly untangle

49:20.660 --> 49:25.940
the word problem, you know, solve the equations correctly. And then at the last minute, give the

49:25.940 --> 49:31.620
wrong answer, because it tried to inject something that it thought it knew, and it got very confused.

49:31.620 --> 49:37.540
But anyway, so lots of use cases for kind of the LLMs, their interaction with computational

49:37.540 --> 49:44.020
language. And then the second piece, really quite a disjoint piece is why did the LLMs work in the

49:44.020 --> 49:48.980
first place? This is a physics problem. And people should figure it out. And the results of

49:48.980 --> 49:54.260
figuring it out will be many important things. For example, probably most of what's inside a modern

49:54.260 --> 49:59.940
LLM doesn't need to be there. Most of what's it, you know, the actual structure you need to know

49:59.940 --> 50:06.980
enough to be able to do sort of linguistic interface, plus kind of enough common sense to

50:06.980 --> 50:11.860
support that linguistic interface is probably quite tiny compared to a current LLM. And probably

50:11.940 --> 50:16.900
you can delegate all the kind of computation and detailed computational knowledge outside of the

50:16.900 --> 50:22.100
LLM, which is an important thing in practice in terms of how much it costs to run an LLM,

50:22.100 --> 50:26.420
what kind of systems you need to run it on. But if we understand LLMs better and why they

50:26.420 --> 50:30.420
work in the first place, we have a better chance to be able to resolve those kinds of things.

50:30.420 --> 50:31.860
All right, I should stop there. Thanks.

50:32.820 --> 50:47.220
Very much. I think we have time for a couple of questions. I'd like to start with a quick one,

50:47.220 --> 50:53.060
slightly out of left field. I think you've made a good case here for physicists becoming linguists.

50:53.620 --> 50:58.580
Is there something that physicists should be learning from linguists or linguists should

50:58.660 --> 51:05.380
be transitioning to physics? Physics can give us, I don't know whether it's linguistics,

51:05.380 --> 51:09.780
I don't know whether you call it that. I don't know what you call it. But this whole idea about

51:09.780 --> 51:16.820
meaning and so on, what we're talking about, that's something that I think has now been exposed

51:16.820 --> 51:21.300
as something on which we can do experimental science on, on which we can apply physics.

51:21.300 --> 51:28.580
So I think that's the, I mean, in terms of, yeah, no, that's, I mean, it's, you know,

51:29.780 --> 51:35.060
if you look at the history of physics, right, physics has been a fantastic export field.

51:35.060 --> 51:39.780
That's, you know, populated molecular biology, it's populated, you know, quantitative finance,

51:39.780 --> 51:44.420
it's populated lots of kinds of things. It has every opportunity to populate this area

51:44.420 --> 51:50.660
and to populate and to really make some complete change to how one thinks about sort of meaning

51:50.660 --> 51:55.540
and language and so on, I believe. Well, thank you. All right, let's go to the right first.

51:56.420 --> 52:00.180
Hi, so I've seen some of your talks on the Wolfram physics project as well,

52:00.180 --> 52:06.100
and I see these n-dimensional graphs that you often use, and they often really look like neural

52:06.100 --> 52:10.820
networks. And so I wanted to ask if that was intentional or if there's some additional layers

52:10.820 --> 52:16.100
of physics going on there. They have nothing to do with neural nets. So far as I know,

52:16.100 --> 52:19.940
although there's at least one startup that believes they do, and we'll see how that works out.

52:21.060 --> 52:29.140
This is an utterly disjoint discussion about how kind of microscopic

52:29.140 --> 52:33.540
hypergraphs, you know, from them emerge space-time and quantum mechanics and so on.

52:34.900 --> 52:40.260
There is in fact a bizarre connection. Okay, this is to the deepest level of the rabbit hole

52:40.260 --> 52:47.060
immediately. There's this thing we call the rouliad, which is the entangled limit of all

52:47.060 --> 52:51.460
possible computations. Imagine you take all possible, let's say, Turing machines with all

52:51.460 --> 52:57.940
possible initial states. You run them, and they're all non-deterministic. They all have all possible

52:57.940 --> 53:03.860
rules. You run them, you get this big, messy thing. There's only one of it. It is the complete

53:03.860 --> 53:10.740
representation of all possible computations. And then that, I claim, is sort of the ultimate

53:10.740 --> 53:16.660
foundation of physics and mathematics, actually. And our physical universe ends up being,

53:17.940 --> 53:24.580
we have to exist within that. And so our physical universe ends up being our kind of, our sampling

53:24.580 --> 53:30.500
of that rouliad object. And here's the fascinating fact, at least I think it's interesting, is that

53:30.500 --> 53:37.220
if you assume that we as observers of the rouliad have two characteristics. One, we are computationally

53:37.220 --> 53:42.100
bounded. Two, we believe we are persistent in time. We believe we have a single thread of

53:42.100 --> 53:47.860
experience. Those two attributes alone are sufficient to give you, not just qualitatively,

53:47.860 --> 53:53.700
but exactly, general relativity and quantum mechanics. That's kind of exciting, because it

53:53.700 --> 53:59.540
tells you that it didn't need to be that way. The aliens who don't have those characteristics

53:59.540 --> 54:02.980
don't have to have general relativity and quantum mechanics. But it kind of gives you, I mean,

54:02.980 --> 54:08.180
this is a huge condensation of a very large amount of stuff. But that's, so okay, how does

54:08.180 --> 54:13.220
that relate to all of this? When I was showing you those weird cat pictures and things, the,

54:13.780 --> 54:19.220
this is a, one of the reasons I was studying weird cat pictures is because this is a way of

54:19.220 --> 54:24.820
understanding sort of different slices of this roulial space concept. There's much more to say

54:24.820 --> 54:30.420
about this. That's a way too, way too brief a description. Okay, let's take a question from

54:30.420 --> 54:36.420
the left now. Yeah, hi. So I've tried to use LLMs in research so far without great success.

54:36.420 --> 54:40.100
I'm a theoretical physicist. Something that would be, there's a weird echo here, I don't know.

54:40.100 --> 54:44.980
Anyway, sorry, something that would be really useful would be if I could have something where,

54:45.780 --> 54:52.340
you know, 300 page paper, I don't know, by Edward and Pierce. And I can ask it, can you give me a

54:52.340 --> 54:57.940
one page summary of that, you know, where it would be correct and where it would already kind of know

54:57.940 --> 55:02.100
from talking me to before, like what are the kind of things that I know and then I don't know.

55:02.100 --> 55:05.620
So I mean, how far are we from that? Well, you know, for example, in our company,

55:06.500 --> 55:12.340
you know, someone makes a daily digest of interesting papers about LLMs. Okay, and I got fed up

55:12.340 --> 55:15.620
trying to read the abstracts, because every abstract is written differently. They're very

55:15.620 --> 55:20.580
ponderous in many cases. I said, just get the frigging LLMs and make a two sentence summary

55:20.580 --> 55:25.940
of every paper. It works great. I mean, you can scan down this thing really quickly. The fact that

55:25.940 --> 55:31.940
the LLMs text is rather boring is actually good, because all the text is consistent, and you kind

55:31.940 --> 55:37.140
of can just see what's happening. Now, you know, do I get the essence of every paper correctly?

55:37.140 --> 55:42.260
Maybe not. But that's a statistical thing anyway, I might miss it from the abstract too. So that's

55:42.260 --> 55:50.580
a pretty good use case that I recommend, actually. In terms of the can you, if you want it to summarize

55:50.580 --> 55:56.260
for you, particularly, I think that's coming. And the, you know, kind of AI tutoring system that

55:56.260 --> 56:02.500
we're building, that's kind of one of the big ideas is know the student and be able to figure out,

56:03.140 --> 56:07.300
first of all, how is the student confused? Because one of the things that you typically can't do

56:07.300 --> 56:12.020
in sort of watching what a student does is watching the working that the student follows.

56:12.020 --> 56:17.700
But you can with an LLM, and you can kind of see, you know, how is the student confused as the

56:17.700 --> 56:22.980
student is doing their work? And then, so then the question is, will it come to the point where,

56:22.980 --> 56:28.820
you know, the LLM will know enough about me from having read, I mean, me personally, I've put 50

56:28.820 --> 56:36.100
million words out there. So it's, I'm pretty easy to learn about. And we're trying to get an LLM to

56:36.100 --> 56:43.860
be me, so to speak, which will save time, maybe, maybe not. But anyway, the point is,

56:44.580 --> 56:52.500
I'm, you know, given that the LLM knows about you, I think there is a very good chance that the LLM

56:52.500 --> 56:57.220
will be able to say the one thing you need to know, because you're confused about this or you don't

56:57.220 --> 57:02.020
know this, is this one fact. And you say, oh, that's the thing I want to know from that paper, all the

57:02.020 --> 57:07.140
other stuff is irrelevant. I think that's pretty realistic. And I think it's reasonably short-term.

57:07.140 --> 57:11.860
But you've got to understand, like everything with machine learning, it's kind of an 80% success,

57:11.860 --> 57:17.140
90% success story. And whenever you have a situation, like looking at these abstracts, where,

57:17.140 --> 57:21.940
you know, if I notice an abstract that looks really interesting, it's a win. If I miss one,

57:21.940 --> 57:27.460
it's not a disaster. That's a good use case. If it's a case where you're trying to do the next

57:27.460 --> 57:33.860
great, you know, precise physics calculation, it's probably a big lose to use an LLM where it

57:33.860 --> 57:40.820
might be wrong 10% of the time, you don't know which 10%. Okay, I understand that there are

57:40.900 --> 57:45.460
many, many questions, but at some point, everyone does have to go home, unfortunately.

57:45.460 --> 57:56.740
So I'm afraid we're going to have to cut off the questioning there. Let's thank our speaker again.

