WEBVTT

00:00.000 --> 00:05.440
This video is sponsored by Ground News, more from them in a bit.

00:05.440 --> 00:10.560
Miriam Webster defines AI as a three-toed sloth.

00:10.560 --> 00:16.700
According to Al Perkins, a sloth is a slow-moving arboreal mammal, and the name AI was given

00:16.700 --> 00:20.280
to this creature because of its high-pitched screech.

00:20.280 --> 00:21.280
Fascinating.

00:21.280 --> 00:26.040
Artificial intelligence, on the other hand, is the ability for computer systems and algorithms

00:26.040 --> 00:29.680
to imitate intelligent human behavior.

00:29.680 --> 00:31.920
This is not anything new.

00:31.920 --> 00:36.080
The technology dates back to nearly the beginning of computers.

00:36.080 --> 00:41.800
But obviously, the AI that is gaining all the hype today isn't quite the same as the

00:41.800 --> 00:47.600
enemies in your video games or the countless chatbots that have been around for decades.

00:47.600 --> 00:52.360
Clearly, chatGPT is not the same as Clippy.

00:52.360 --> 00:53.760
Probably?

00:53.760 --> 00:56.280
This whole AI thing is complicated.

00:56.280 --> 01:00.320
We don't know the ultimate potential of large language models and neural networks

01:00.320 --> 01:05.880
and blah, blah, blah, but at the same time, it doesn't take a genius to figure out that

01:05.880 --> 01:12.040
the letters A and I are being used as much as possible by corporations looking to increase

01:12.040 --> 01:13.720
their share values.

01:13.720 --> 01:20.560
If a company so much as utters AI, investors cannot help but invest.

01:20.560 --> 01:25.520
Even if they have no idea what it means, or what it does, or what it might do, they just

01:25.520 --> 01:28.640
assume it's going to make money.

01:28.640 --> 01:33.800
NVIDIA, which was well known for being the producer of GPUs for gaming PCs and other

01:33.800 --> 01:40.320
computing products, has gone from a successful company to, well, the third largest on the

01:40.320 --> 01:41.320
planet.

01:41.320 --> 01:48.960
It has seen an increase in value that is nothing short of obscene, all thanks to this AI.

01:48.960 --> 01:54.120
Microsoft is now the most valuable corporation on the planet, as the company is all aboard

01:54.240 --> 01:59.920
the AI hype train, pushing it into every corner of their operating system and having

01:59.920 --> 02:04.520
an extremely close relationship with open AI.

02:04.520 --> 02:09.920
All the while, nobody can seem to agree on whether this technology will change the very

02:09.920 --> 02:15.040
fabric of our society, or prove to be another flash in the pan.

02:15.040 --> 02:20.440
Tech fad, everyone, everyone has an opinion.

02:20.440 --> 02:26.360
I'm exhausted of seeing this back and forth argument that never seems to reach any conclusion.

02:26.360 --> 02:31.160
And speaking of, Ground News is a website and app that gathers related articles from

02:31.160 --> 02:36.760
more than 50,000 sources around the world in one place so you can compare how different

02:36.760 --> 02:39.240
outlets cover the same story.

02:39.240 --> 02:44.120
Each story comes with a clear breakdown of the political bias, ownership, and headlines

02:44.120 --> 02:50.080
of the sources reporting, all backed by ratings from three independent news monitoring organizations.

02:50.080 --> 02:54.080
Take a look at the story about how open AI is setting up a safety and security committee

02:54.080 --> 02:58.320
as it starts training for the next frontier model, something that has caused a lot of

02:58.320 --> 03:02.640
controversies as previous safety team leaders have recently left the company.

03:02.640 --> 03:09.320
This story has been covered by more than 73 sources, with 37% of them leaning left, while

03:09.320 --> 03:10.960
14% leans right.

03:10.960 --> 03:16.000
You can also see the ownership information, and for this story, 40% of the reporting outlets

03:16.000 --> 03:18.320
are owned by media conglomerates.

03:18.320 --> 03:22.060
You can even compare headlines to see how this bias can affect framing.

03:22.060 --> 03:26.320
We can compare headlines quickly and see how some organizations will stoke the public's

03:26.320 --> 03:31.440
existing fears about AI to get clicks, while others might capitalize on the distrust that

03:31.440 --> 03:34.960
Sam Altman has garnered over the past few months.

03:34.960 --> 03:38.720
Ground News has this feature called Blind Spot, which instantly shows you stories that the

03:38.720 --> 03:43.720
left-leaning or right-leaning news media conveniently won't report on.

03:43.720 --> 03:49.720
Now go to ground.news.usk or use the link in the video description to subscribe today.

03:49.720 --> 03:53.960
If you sign up through my link, you will get 40% off the vantage plan, which is what I

03:53.960 --> 03:57.600
use to get unlimited access to all of their features.

03:57.600 --> 04:03.400
I think Ground News is an exceptionally important website, and one you absolutely need to check

04:03.400 --> 04:04.400
out.

04:04.400 --> 04:05.800
Now, back to the video.

04:05.800 --> 04:10.840
Yes, AI has been around for a while, dating back to the earliest computers, but the hype

04:10.840 --> 04:14.640
right now surrounds progress on large language models.

04:14.640 --> 04:19.920
These are programs that take a lot of information in, require a user prompt, and through complex

04:19.920 --> 04:24.680
algorithms basically create probabilities of what the output should be.

04:24.680 --> 04:29.040
As lifelike as they might seem, these things are not actually alive.

04:29.040 --> 04:31.160
There's no thinking involved.

04:31.160 --> 04:34.080
They cannot create wholly original or novel ideas.

04:34.080 --> 04:37.320
They require training data to do anything.

04:37.400 --> 04:42.360
I've seen it suggested that one of the best ways to prove this is to ask a question with

04:42.360 --> 04:47.120
an answer that the AI model has not been provided with in its training data.

04:47.120 --> 04:53.120
For example, go to chatGPT and ask, what's the 21st letter in this sentence?

04:53.120 --> 04:58.840
You might get a different response, but I got the AI saying confidently, it's E. And

04:58.840 --> 05:03.840
if you say, I don't think that's right, it will try and count again and give you a

05:03.840 --> 05:05.000
different letter.

05:05.000 --> 05:06.920
This time, I.

05:06.920 --> 05:12.040
It will sometimes interpret two and one as letters, maybe the apostrophe.

05:12.040 --> 05:18.480
And the reason questions like this break the AI is because it doesn't actually understand

05:18.480 --> 05:20.680
what a letter is.

05:20.680 --> 05:26.400
It doesn't understand anything, but it searches the internet and its training data for the

05:26.400 --> 05:28.760
most likely answer.

05:28.760 --> 05:34.680
Even with these limitations, the technology is clearly capable of some impressive things.

05:34.680 --> 05:40.280
Some assisting you in writing computer programs to proofreading your short stories, to helping

05:40.280 --> 05:42.040
you cheat on your homework.

05:42.040 --> 05:48.520
But even still, a lot of what gets promoted as AI isn't really AI.

05:48.520 --> 05:54.120
A lot of the revolutionary abilities that AI has been reported to have is actually stuff

05:54.120 --> 05:58.840
that traditional software has been capable of doing for a long time.

05:58.840 --> 06:04.360
This creates a problem where the idea of this technology, it's often more valuable than

06:04.360 --> 06:06.960
what it can actually do.

06:06.960 --> 06:12.400
Because again, just saying AI makes stock number go up.

06:12.400 --> 06:17.280
So a while back, Amazon launched a real-life store, a brick-and-mortar shop where customers

06:17.280 --> 06:22.600
could walk in, grab items off the shelf, put them in their carts, and leave without ever

06:22.600 --> 06:24.280
checking out.

06:24.280 --> 06:28.360
These items were automatically charged to people's accounts without any need to speak

06:28.360 --> 06:32.000
to a cashier or even use a self-serve system.

06:32.000 --> 06:35.040
It was all done automatically.

06:35.040 --> 06:39.440
Many assume this was handled using an array of computers and sensors and scanners, but

06:39.440 --> 06:45.000
in reality, the company just probably hired a lot of Indian employees to watch people

06:45.000 --> 06:47.800
while they shopped on cameras.

06:47.800 --> 06:52.200
And then they would charge the user's Amazon account.

06:52.200 --> 06:57.280
Google was caught off guard by the immediate success of ChatGPT and has been trying its

06:57.280 --> 07:00.760
hardest to launch its own AI competitor.

07:00.760 --> 07:06.120
They paid millions of dollars to Reddit for access to the website's posts to train their

07:06.120 --> 07:10.920
AI with and it went about as well as you'd expect.

07:10.920 --> 07:15.840
When users asked questions like how to make your cheese stick on pizza, Google decided

07:15.840 --> 07:19.680
the best answer was to use non-toxic glue.

07:19.680 --> 07:26.160
This information, by the way, was provided by an 11-year-old Reddit post by user Fucksmith,

07:26.160 --> 07:31.520
which Google's model decided was the most reliable source for information.

07:31.520 --> 07:36.920
When asked about how many rocks you should eat a day, it did not give the correct answer

07:36.920 --> 07:38.840
of zero.

07:38.840 --> 07:41.800
And look, things just kept getting worse from here.

07:41.800 --> 07:47.480
As you can imagine, any technology that uses the internet to train itself is probably going

07:47.480 --> 07:49.080
to make a few mistakes.

07:49.080 --> 07:55.240
And those mistakes have made AI a very easy and fun punching bag right now.

07:55.320 --> 07:58.520
But yeah, not all AIs are created equally.

07:58.520 --> 08:04.320
You can't say that LLMs or machine learning or neural networks are completely useless

08:04.320 --> 08:08.400
because, well, a lot of people are using it.

08:08.400 --> 08:10.080
There's potential here.

08:10.080 --> 08:15.880
Natural language programming could allow people to write their own programs with no code required,

08:15.880 --> 08:22.120
just describing what kind of application they want to make and the AI would handle the rest.

08:22.120 --> 08:27.960
You could use this to learn to research information, but again, AI can be wrong.

08:27.960 --> 08:31.160
So I view it in the same way that I view Wikipedia.

08:31.160 --> 08:36.560
It's useful, it's a nice jumping off point, but you need to check your sources.

08:36.560 --> 08:41.600
It's not 100% accurate, or compiling lots of data really quickly to get back at your

08:41.600 --> 08:43.920
homeowner's association.

08:43.920 --> 08:45.640
This does have real value.

08:45.640 --> 08:50.680
Automatic translations, transcriptions, stuff that may have been possible with previous

08:50.720 --> 08:53.920
software is just more accessible than ever.

08:53.920 --> 08:56.480
But people are taking this too far.

08:56.480 --> 09:02.560
The end goal of open AI is to achieve artificial general intelligence.

09:02.560 --> 09:10.040
AGI is supposed to refer to a strong AI that can learn skills in tasks that it was never

09:10.040 --> 09:11.440
trained to learn.

09:11.440 --> 09:17.800
This could lead to machine sentience, consciousness, the singularity.

09:17.880 --> 09:22.360
And right now, everyone seems to believe that if you just keep throwing more computing

09:22.360 --> 09:31.200
power, more energy, more information into these algorithms, you can simply manifest AGI from

09:31.200 --> 09:34.520
the kinds of artificial intelligence we have today.

09:34.520 --> 09:39.440
Everybody has a different way of defining AGI because, well, nobody really knows what

09:39.440 --> 09:40.960
it's supposed to look like.

09:40.960 --> 09:46.440
We often divide AI into two categories, weak AI and strong AI.

09:46.480 --> 09:52.120
Weak AI is capable of doing very specific tasks, stuff it was programmed to do, and

09:52.120 --> 09:56.720
everything we've ever made so far has been a weak AI.

09:56.720 --> 10:02.120
AGI would be a strong AI, and it could do a lot of jobs.

10:02.120 --> 10:05.200
It could do a lot of stuff, would put you out of a job.

10:05.200 --> 10:08.200
But what might this look like exactly?

10:08.200 --> 10:14.960
There are a few different tests for AGI, but I've always found that the best would be

10:14.960 --> 10:18.920
something done with an actual robot in a Tamaton.

10:18.920 --> 10:23.520
Take a robot and ask it to repair the plumbing electrical systems and appliances of an early

10:23.520 --> 10:30.000
20th century home, especially if none of that information is available through documentation

10:30.000 --> 10:31.000
on the internet.

10:31.000 --> 10:34.520
Every home is going to be slightly different, so the robot will need to make assumptions

10:34.520 --> 10:40.760
to learn to understand why your custom 1950s toaster is not working and then try and figure

10:40.760 --> 10:46.440
out, possibly through trial and error, how to get it back into toast making condition.

10:46.440 --> 10:51.720
While today there are demos of robots completing simple tasks in the home, these are in controlled

10:51.720 --> 10:58.080
environments and are only possible because of training data created from previous experiences.

10:58.080 --> 11:04.200
This AGI robot would need to be capable of learning from unique situations, to ask questions

11:04.200 --> 11:08.200
based on its own volition, and solve them by itself.

11:08.200 --> 11:11.680
But there is no proof that this will happen.

11:11.680 --> 11:16.560
In fact, studies do seem to suggest that there are diminishing returns when it comes to this

11:16.560 --> 11:17.720
kind of stuff.

11:17.720 --> 11:23.800
We don't know if any of this is even possible with traditional silicon chips and programming,

11:23.800 --> 11:26.160
binary code, any of that.

11:26.160 --> 11:30.200
It could take entirely new forms of computing to achieve this.

11:30.200 --> 11:34.680
We don't fully understand how the human brain works, so attempting to replicate it

11:34.680 --> 11:40.520
with far more simplistic technology, far more rigid technology, it just seems more than

11:40.520 --> 11:42.400
a bit optimistic.

11:42.400 --> 11:47.240
People are acting like we're five years away from robots taking every job, becoming alive,

11:47.240 --> 11:51.240
enslaving humanity, changing life forever.

11:51.240 --> 11:55.560
And honestly, chatGPT could be a stepping stone to all of this.

11:55.560 --> 11:57.760
A stepping stone to AGI.

11:57.760 --> 12:04.440
In the same way that the discovery of gunpowder was a stepping stone to the nuke.

12:04.440 --> 12:09.800
Or the hot air balloon was a stepping stone to intergalactic spaceflight.

12:09.800 --> 12:12.520
That is to say, not much of a step at all.

12:12.520 --> 12:17.240
For all we know, LLMs and AGI might not even be related.

12:17.240 --> 12:19.640
We might not even be on the right track.

12:19.640 --> 12:22.000
We just don't know.

12:22.000 --> 12:29.720
So if we don't even know if this can manifest into some more powerful AI, if we have no substantial

12:29.720 --> 12:35.360
evidence to support that we're on the road to AGI, then why all the hype?

12:35.360 --> 12:39.920
Obviously, it is incorporation's best interest for people to believe that this technology

12:39.920 --> 12:46.520
is on the cusp of being something truly revolutionary, so good it's frightening.

12:46.520 --> 12:50.440
It makes it seem way more advanced than it actually is.

12:50.440 --> 12:55.280
It implies more potential for growth, which will make the stock number go up.

12:55.280 --> 12:58.560
And they have ways to market this technology.

12:58.560 --> 13:04.240
So many companies are just throwing around the words AI, even if it doesn't even apply

13:04.240 --> 13:06.720
to their products in any way.

13:06.720 --> 13:12.760
Gigabyte, which usually makes gaming-centric motherboards and memory thingies and whatnot.

13:12.760 --> 13:17.720
Well they decided they wanted to go all in on the AI thing and have rebranded their products

13:17.720 --> 13:21.160
with a big ole AI plastered on the side of them.

13:21.160 --> 13:25.680
Yeah, rebranded, because it's really just kind of the same stuff you could find anywhere

13:25.680 --> 13:26.680
else.

13:27.120 --> 13:30.600
It's got AI written on it, whatever that means.

13:30.600 --> 13:35.360
This exact same thing happened a few years back with the whole metaverse craze, where

13:35.360 --> 13:40.280
every company started proclaiming that their existing video games and online services were

13:40.280 --> 13:45.960
already in fact metaverses because investors wanted to hear that.

13:45.960 --> 13:50.120
And it diluted the term to such a point that the word metaverse started to mean nothing

13:50.120 --> 13:53.640
more than just a synonym for software.

13:53.640 --> 13:59.680
When an AI makes a mistake, the companies call it a hallucination, which is a very misleading

13:59.680 --> 14:00.680
term.

14:00.680 --> 14:06.280
This is applying a human quality to the machine, when in reality it's not hallucinating.

14:06.280 --> 14:11.360
It's just taking a set of probabilities and it hasn't received enough training data on

14:11.360 --> 14:15.800
the topic or the right algorithms to give you an accurate answer.

14:15.800 --> 14:17.360
It is not hallucinating.

14:17.360 --> 14:19.200
It simply made a mistake.

14:19.200 --> 14:22.480
The technology simply wasn't good enough.

14:22.480 --> 14:23.800
Will it improve?

14:23.800 --> 14:30.080
Yes, but we don't know how good it will get or how accurate it will become.

14:30.080 --> 14:37.960
For AI sentience, it could be 5 years away or 10 or 100 or 1000 or it might not be possible

14:37.960 --> 14:40.400
for us to build this at all.

14:40.400 --> 14:44.840
We don't know and everything else until it happens is just a guess.

14:44.840 --> 14:50.440
A lot of the AI safety you hear about actually does refer to more realistic concerns about

14:50.440 --> 14:52.720
how this technology might be used.

14:52.720 --> 14:58.600
If in the future, AI services become a replacement for traditional search engines like Google,

14:58.600 --> 15:03.840
if people rely on ChatGPT to get all their news, then those in charge of the service

15:03.840 --> 15:10.240
can lie, manipulate or alter information to benefit those who are in charge of the AI

15:10.240 --> 15:13.920
to push their own motives, their own agendas.

15:13.920 --> 15:19.640
This is where the concerns of safety often lie, not in the fantasy of robots taking over

15:19.640 --> 15:20.640
the world.

15:20.640 --> 15:24.080
Or at least that's where the fears should lie.

15:24.080 --> 15:29.600
And look, if fancy quantum computing or something entirely unprecedented allows for a robot

15:29.600 --> 15:36.840
revolution, allows for AGI, if today's technology and LLMs are on the right path to all of

15:36.840 --> 15:42.560
this, and all we need is just a few trillion dollars in the combined power consumption

15:42.560 --> 15:46.800
of a small nation, I'll be the first to admit I was wrong.

15:46.800 --> 15:53.080
Oopsie daisy, egg on my face, but right now I'm just a little bit skeptical.

15:53.080 --> 15:58.720
So for the purposes of this video, let's assume that the future of AI is not revolutionary,

15:58.720 --> 16:00.360
but evolutionary.

16:00.360 --> 16:04.120
And if that's the case, is it a bubble?

16:04.120 --> 16:08.840
Yes, yes it is, but that doesn't mean it's worthless.

16:08.840 --> 16:13.320
I kind of see AI right now like the dot com boom of the late 90s.

16:13.320 --> 16:17.240
This was a time where investors believed that every single website was going to make millions

16:17.240 --> 16:18.240
of dollars.

16:18.240 --> 16:22.800
And once they figured out that only certain websites would ever become popular, would

16:22.800 --> 16:26.800
ever become profitable, many of them took their money and ran.

16:26.800 --> 16:30.560
The resulting fallout led to the dot com bubble burst.

16:30.560 --> 16:35.300
But this wasn't the end of the worldwide web.

16:35.300 --> 16:41.240
Now I'm not saying that AI will be as important as the internet, but clearly this is more

16:41.240 --> 16:44.560
than just a simple fad that's going to fade away.

16:44.560 --> 16:49.400
I do think the bubble will burst, and then the industry will have to realistically look

16:49.400 --> 16:54.920
at its value rather than rely on unfounded promises and rampant speculation.

16:54.920 --> 17:00.720
But yeah, AI is here to stay, because it's been here for a long time.

17:00.720 --> 17:04.320
AI already has changed our world.

17:04.320 --> 17:08.840
Algorithms drive search engines, YouTube channel recommendations, most of the internet

17:08.840 --> 17:11.160
is driven off of this automation.

17:11.160 --> 17:16.680
We know that the technology has value because it's been around for a while.

17:16.680 --> 17:23.460
The question is whether this new form of AI, LLMs, will have a significant impact on how

17:23.460 --> 17:28.200
we live and work, or how significant of an impact that might be.

17:28.200 --> 17:31.920
And a lot of people seem to have some doubts about all of this.

17:31.920 --> 17:36.480
Rooters Institute for the Study of Journalism pulled 12,000 people from six different countries

17:36.480 --> 17:39.120
online about their opinions on AI.

17:39.240 --> 17:44.840
Granted, 12,000 people is not that many, doing polls online does not mean perfect results,

17:44.840 --> 17:47.880
but this is about as good as we're going to get if we're trying to figure out what

17:47.880 --> 17:52.080
the average person thinks about this technology.

17:52.080 --> 17:57.480
And most people have no idea what it is, or what it does, or what it could do.

17:57.480 --> 18:03.440
A lot of people have heard of AI in these new services, but they don't know what distinguishes

18:03.440 --> 18:07.800
a large language model from traditional computer software.

18:07.800 --> 18:13.520
You can tell that most people are not using AI that often, even if chat GPT has a huge

18:13.520 --> 18:15.160
install base.

18:15.160 --> 18:18.840
Younger people are more likely to try it out than older people, obviously.

18:18.840 --> 18:23.600
But most people view AI as a technology that will primarily be used in professional settings

18:23.600 --> 18:29.880
by scientists in social media companies, but less so by the average person and their daily

18:29.880 --> 18:30.880
lives.

18:30.880 --> 18:35.960
Again, if these people don't actually know what AI is, considering some of these poor

18:36.120 --> 18:42.520
results, none of this is super helpful, but there is some stuff we can take away from

18:42.520 --> 18:43.520
this.

18:43.520 --> 18:48.160
It seems like people aren't just confused by the technology, they seem to fundamentally

18:48.160 --> 18:49.240
dislike it.

18:49.240 --> 18:52.000
There are a lot of concerns about the damage it can do.

18:52.000 --> 18:56.600
People are scared it will take their jobs away, or just functions as tools to manipulate

18:56.600 --> 18:57.600
the public.

18:57.600 --> 19:02.920
And most don't seem interested in the positive aspects of this technology at all.

19:02.920 --> 19:05.920
Most can't even identify what that might be.

19:05.920 --> 19:11.600
Because a technology does need to be more than good enough, it needs to be perfect.

19:11.600 --> 19:15.960
When driving a school bus or doing taxes for a multi-trillion dollar corporation, you

19:15.960 --> 19:22.440
probably don't want to put this responsibility on a robot that can, or probably will, make

19:22.440 --> 19:23.440
a mistake.

19:23.440 --> 19:25.440
Yes, humans are not perfect.

19:25.440 --> 19:31.440
The AI might even be better than the human in many cases, but humans give people somebody

19:31.440 --> 19:34.240
to blame when things go wrong.

19:34.240 --> 19:40.880
They provide accountability, something that the AI just doesn't have for AI.

19:40.880 --> 19:46.840
Google spent all of Google I.O. 2024 talking about its AI initiatives, and people didn't

19:46.840 --> 19:48.480
really seem to care all that much.

19:48.480 --> 19:53.200
A lot of people just rolled their eyes because it's more AI slop.

19:53.200 --> 19:58.960
Microsoft hyped up its new line of AI PCs, which most saw as a concerning invasion of

19:58.960 --> 20:03.320
privacy rather than anything remotely worthwhile.

20:03.320 --> 20:08.520
The corporation is betting the future of its operating system, of the Windows operating

20:08.520 --> 20:13.840
system on AI, and it's a bet that doesn't seem to be panning out.

20:13.840 --> 20:19.160
In fact, I've seen a lot more people talk about moving to Linux now that Windows is

20:19.160 --> 20:22.560
infected with this AI garbage.

20:22.560 --> 20:28.720
I have no doubt going forward that LLMs and machine learning and AI will manifest into

20:28.720 --> 20:30.720
something valuable.

20:30.720 --> 20:36.400
It's possible this might even result in massive changes to everyday life, but right now this

20:36.400 --> 20:42.800
entire thing has been polluted by bad actors, false promises, and in my opinion, pretty

20:42.800 --> 20:48.080
misleading marketing tactics, and it's baffling to me that people have just forgotten the

20:48.080 --> 20:55.000
whole metaverse craze from a few years back, where the word itself began to mean nothing

20:55.000 --> 20:56.160
by the end.

20:56.160 --> 21:00.960
These analysts, who don't even understand the basic technology, are hyping up others

21:00.960 --> 21:06.840
about how much money we're all apparently about to make, claiming that Nvidia is going

21:06.840 --> 21:13.320
to be worth $10 trillion in just a few years, and as far as I can tell, there's just no

21:13.320 --> 21:16.280
reasonable basis for these claims.

21:16.280 --> 21:21.080
We've reached a point where Big Tech is so desperate to achieve growth that it just

21:21.080 --> 21:26.240
keeps taking these fairly predictable and standard advancements and software and then

21:26.240 --> 21:33.080
applying new buzzwords to the technology, and by the time the bubble should burst, they're

21:33.080 --> 21:36.080
already onto marketing their next buzzword.

21:36.080 --> 21:41.080
I don't want to dismiss the entire potential of AI by calling it the next metaverse, but

21:41.080 --> 21:43.800
look, there's a lot of problems here.

21:43.800 --> 21:48.680
And as of right now, for many people, this technology just kind of comes off as a slightly

21:48.680 --> 21:55.360
more invasive, less accurate version of all these digital personal assistants that have

21:55.360 --> 21:58.060
already become commonplace over the years.

21:58.060 --> 22:02.520
This whole industry right now just seems so flimsy to me.

22:02.520 --> 22:05.760
There's a good chance that everything I say here will age like milk.

22:05.760 --> 22:07.080
I get that.

22:07.080 --> 22:12.160
Maybe we will see a world where most jobs become significantly easier with the assistance

22:12.160 --> 22:17.320
of the machines, where this is a necessity, or maybe the tech is too good and we all lose

22:17.320 --> 22:18.320
our jobs.

22:18.480 --> 22:24.120
I think right now we're seeing a technology that is more style over substance.

22:24.120 --> 22:28.720
There is substance there, but there's just a lot of fluff here.

22:28.720 --> 22:32.440
Or maybe I'm completely wrong, and in five years we'll all have Rosie the Robot in our

22:32.440 --> 22:33.440
homes.

22:33.440 --> 22:35.840
I need to get my robot out of my swimming pool.

22:35.840 --> 22:37.800
I don't think she can breathe.

22:37.800 --> 22:42.240
Again, huge thanks to Ground News for sponsoring today's video.

22:42.240 --> 22:47.200
Go to ground.news slash husk or use the link in the video description to subscribe today.

22:47.200 --> 22:51.200
If you sign up through my link you will get 40% off the vantage plan.

23:17.200 --> 23:18.200
Thank you.

