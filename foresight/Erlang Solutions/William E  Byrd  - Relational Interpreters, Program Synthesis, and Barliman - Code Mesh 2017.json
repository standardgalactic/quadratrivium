{"text": " Thank you. This always happens to me at CodeMesh. I have an idea for a talk, and then after seeing a keynote or having a conversation with someone, I'm like, throw that out. Actually, Boodle last night tried to convince me to give a talk on StarCraft instead, which I'm sorely tempted to do, but maybe next year. Yes. But I saw Guy Steele's keynote last night, which I loved, and I have to say that I love Scheme. I agree with Alan Kay that Lisp is the most important programming language ever created, and for my money, Scheme is the most important Lisp. So I think Scheme is one of the great joys of my life. I love programming and Scheme, and when I went to Indiana University to get my PhD, I went there specifically to work with Dan Friedman and get my PhD in Scheme. On the first day of grad school, I walked up to Dan, and I said, I'm so excited to be here at Indiana University so that you could teach me Scheme, and he says, I don't do Scheme anymore. I do logic programming. It's like something you could have told me two weeks ago, and I would have gone Northeastern, but I didn't. Anyway, but Dan should have told me something else instead. He shouldn't have said, I don't do Scheme anymore. I do logic programming. He should have said something else, and so this talk is kind of about what Dan really should have told me, and sort of trying to explain what we've been doing the last 13 plus years. I've been doing it for the last 13 years. Dan's been doing it longer than that. What is it we're trying to do, and what is this weird mini-canon language we're working on, and why is it not prologue, and how does that fit into Guy's keynote, and all these other things? The original talk was relational interpreters, program census, and Barlaman strange, beautiful, and possibly useful. Maybe it'll be useful someday, but I don't really care about useful so much, as you might see. The language we're working on is called mini-canon, and I got to get my memes in, and my ponies for Boodle, but someone made this up. Fresh is one of the key operators. There are only three operators in the core language, but here's my second meme, and this is something I've heard a lot of. Mini-canon is the worst logic programming language I've ever heard of, but you have heard of it, right? People often say, well, this is terrible. Prologue has all these extra features, or prologue implementations are faster, so why use mini-canon? The point is, in my mind, isn't to build a logic language. That's not what I'm trying to do, at least. I don't care about logic programming. I don't care about mini-canon. That's not what I'm trying to do. Let me tell you a story, and I'll do my first live coding. I'm going to show you the first program I ever wrote. I was nine years old. My father bought this beautiful computer. Anyone know what this is? No one knows what that computer is, really. TRS-80 Coco, trash 80, color computer. Believe it or not, but one point in the time, this was the most popular computer in the world, and Radio Shack actually had summer camps. My first class in programming was taught by Radio Shack, the summer school in programming, in Logo. The TRS-80 Coco, that came out in 1980, hence the name. Let's see if I can show you the program. We got this new computer, and normally I used to think that I'd seen war games or whatever, and I knew how to program, but war games I don't think was out yet, so I must have seen Star Wars, but I thought I knew how to program, so we get this computer, and it's like, all right, I'm going to show off to my brother, my little brother, because I'd watched all these movies. Here is exactly the program that I wrote. Oh, I got to click on it. As I recall, the exact program I wrote 37 years ago, and that's the exact result I got. I basically flipped the table, and I said, this is not for me, and I didn't touch the computer or programming for several years after. In effect, I haven't really changed. This is really my philosophy of what programming should be like. The fact that I have become an expert and have a PhD in programming, to me, is offensive. It's not something joyful. It's like the same thing where writing books with Dan, or writing latex papers, or whatever. The fact that I've become a master in mangling latex files and post-processing latex files with Perl scripts is not something I'm proud of. It's something I'm ashamed of. The fact that I still, to this day, have to program at a much higher level, in a sense, I can't write that sort of program, really offends me. Let's see. I think you can sum up my attitude with this epigram in programming. If you haven't read Alan Perlis' epigrams in programming, you should read those. They're fantastic. The epigram 93. When someone says, I want a programming language in which I need only say what I wish done, give him a lollipop. I understand his philosophy or why he said that, but if someone wants to just type something in sort of naively, I think we should give him or her a lollipop, but we should also give them what they ask for. If you think of it that way, what I really want to do is lollipop-driven development. Rich Hickey has this idea of hammock-driven development, which is fine, but I prefer lollipop-driven development. I want to just be able to say what should happen and just have it happen. I think it's milkshake-driven. Milkshake-driven development, yes. Going back to Guy's keynote last night, he showed inference rules, typing judgments, context-free grammars, BNF, all these sorts of things. When I went to Indiana, really what Dan was trying to do at the time, which took a while for me to understand, was he wanted a way to write these sorts of rules down, make them executable, and be able to explore the resulting system. That's really what he was interested in. Anyway, we want some way to explore this. Going back to Guy's naming of the informal language use, computer science meta notation, basically we want to have an executable relational version of computer science meta notation. Just one other source of inspiration for the Commodore Amiga, which was my third computer, I think. There was a fantastic program for it called Doug's Math Aquarium. I love this program. You can see, this was on the September 87 issue of Info. You can see on the lower left the image again. You can do Manobrot, plus you can do wireframe. There are a whole bunch of ways you could visualize mathematics. The way it would work is like, hey, I want to zoom in on Manobrot's set. The computer was so slow, and the software was so slow, you would hit return, and you would see it draw each pixel. Then you would go away, and eight hours later, you would see a little bit of the Manobrot set. But it was still amazing. It was still incredibly inspiring to me. What I want is a computer science meta notation aquarium, just like the math aquarium. Even if it's slow, and even it's awkward to use, just being able to explore and play around with it to me would be far, far better than just writing interpreters the standard way. That's really what we're trying to do, I'd say. I'm going to not teach you the mini-canon language, and I'm not going to teach you how it's implemented. We actually have lots of resources and talks and things like that about this, about mini-canon, and how to use it, and how to write mini-canon programs. To really do it right would take far more time than I have, but I just want to show you maybe a couple of examples of what the rules look like. This is a type inferencer for the simply typed lambda calculus on the left, how we would write it with the computer science meta notation. Was that right, CSM? Computer science meta notation. That's how we might write it on the left. Then on the right is how you might write it in mini-canon using a macro called matchup, and then on the right is a little higher level syntax than what we normally use. You can see it's roughly the same. It's still awkward. It's not the greatest notation, but you can see it's not 100 times longer or 10 times longer or whatever. Here we have something similar for commentatory logic. We have another meta notation, and on the right is the mini-canon, and that's roughly the same length. Here is the program that we're going to play with today in Explorer. This is an environment passing interpreter for a subset of scheme or a subset of racket. If you know the rules, this is procedure application, this is abstraction or lambda, that's variable reference. Here we have lists. There we've got quote. We've actually added some other forms to various versions of the interpreter. I'll show you this version first. Then here on the right is the mini-canon code that corresponds to it. Then we also have to have some extra code for doing things like environment lookup and some side conditions where in the math when you write it down, you don't have to worry about it as much. Anyway, the point is we can write something that doesn't really look like the notation. It would be very nice to have something much closer to the notation, and it's roughly the same length or maybe twice as long or something like that. We're going to assume that we've already implemented an environment passing interpreter in mini-canon, and we've already implemented mini-canon. Mini-canon is a language that is sort of a combination of logic programming and constraint programming. This is basically a constraint logic programming language. It's a mixture of constraints and logic programming. I heard Peter Van Roy question last night to Guy, both logic programming and constraint programming came up. Basically, you can think of it as a language that's been optimized to write rules like this, not necessarily in terms of the syntax, like how you write them down, but more in terms of if you want to explore the resulting rules. The language is optimized for that, and the implementation is optimized for that. Okay. Now is the most fun part. This is always the part that scares me, loading a file. We haven't really solved the loading the file part, but let me make sure I can do this. Oh, okay. Great. Let me see if I can do this one. Good. All right. Okay. Can people see that? Is that big enough? Okay. Let me make sure we got, great. Okay. So, show of hands, please. Who here can read Scheme, Racket, Closure, or some other Lisp? At least a little bit. Emacs Lisp? Absolutely. Okay. So, most people, maybe not 100%. I think in the interest of time, I'm going to ask the people who aren't as familiar with parentheses to please try to bear with me and try to think at the high level what we're trying to do. Okay. Just from the standpoint of time, I can't also teach you all of Scheme, unfortunately. Although I gave a talk at Papers We Love recently where I actually do teach enough Scheme to do all the things we do, but I had an hour and a half then. So, if you look on YouTube, you can find papers we love to talk on called the most beautiful program ever written where I talk about some of these topics. Okay. So, what I've loaded is an interpreter for a subset of Scheme. And a language like Scheme, sort of like a language like Python, maybe, we have something called a vowel. So, a vowel is an evaluator. It can evaluate an expression, which we quote. So, I could do plus 3, 5. And this expression, a Scheme uses a prefix notation. We're adding 3 plus 5. That quote means that we're delaying evaluation. We're turning the plus 3, 5. We're treating that as a list of data instead of as a procedure call. So, you can see the difference. If I put the quote mark, we get back the list. If I don't put the quote mark, it evaluates immediately, we get back 8. Okay. So, a vowel sort of cancels out the quote mark, if you want to think of it that way. We're taking this list and we're going to evaluate it. So, we're going to look at the parts of the list and do some evaluation procedure. Okay. So, that's a vowel and Scheme. What we're going to do is use something called a vowel. So, a vowel is the relational version of the vowel function. So, the vowel function takes one argument, which is going to be a Scheme expression, as quoted, evaluates that and gives us back the value. The vowel, however, is going to take two arguments instead of one. It's going to take an expression as the first argument and it's going to take a value as the second argument. So, let's try using a vowel. Okay. Great. So, it's working. All right. How about I do something simple like I think this will work. Oh, yeah. Okay. So, for the people who don't know Scheme, Lisp stands for list processing. So, the list is a very common data structure we use. So, list 3, 4 creates a list containing 3 and 4. What I just did with this run expression is I called a vowel, which is my relational evaluator. And the quoted expression is list 3, 4, just like I typed directly in the Scheme. So, that's the expression. The first part of the first argument to a vowel is the expression I want to evaluate. Q is a query variable. You can say I introduce it right after the run one in parentheses. Q is my query variable. And I'm putting Q in the place of the value. I'm saying that whatever a list 3, 4 evaluates to, bind that to the variable Q. Okay. So, Q is a logic variable, query variable, whatever you want to call it, unification variable. Run one, the one means that I want one answer back. Sometimes we can get more than one answer back. Sometimes we can get infinitely many answers back. And in fact, we also might want to prove or show that there are only a finite number of answers, that there are only five answers that exist. Run is our interface operator between Scheme and Minikanron. So, Minikanron is embedded in a host language, most implementations. This implementation, Minikanron is embedded in Scheme. I'm running it in Shea Scheme. All right. So, that's the basic interface. The underlying language that we wrote a vowel in is quite simple. It basically extends Scheme with three operators, core operators. And then we've got a couple extensions for helping write interpreters and type in things like that. Okay. So, that's a vowel. And you can see that we can write things like list 3, 4. Now, what's interesting is that a vowel is written as a relation. And so, Guy talked about this a little bit yesterday. But, you know, the interesting thing about the rules, and in fact, I can show you the rules for interpreter, the interesting thing about these sorts of rules is that they don't really have a direction. So, here is a paper that was an ICFP in Oxford this year. And in this paper, you can see these rules written as inference rules. And the code on the right, which is Minikanron. This is kind of lower-level Minikanron, so it's a little longer. But the important thing is to realize that, you know, there's this bar here, right, that Guy was talking about. And normally, the way we read it is we have some antecedents, a consequence. So, we have some things that have to hold. And if these three things hold, then we can infer the thing on the bottom. And we also sort of read it as, okay, so this turnstile operator, we can read it as like an interpret or evaluate. So, in a certain environment, row, this particular expression, which is a procedure application, evaluates to the value v3. And the rules up top tell you what v3 is. So, if you're writing an interpreter in a standard way, you would read these rules as, okay, I'm going from left to right. Here's my expression. Here's my value. Notice there's an arrow instead of an equal sign. So, that's how you'd often think about it. But there's no reason that we have to go in any sort of direction. We could actually consider this more like an algebra problem, where we have variables that we want to place in the different parts. Maybe the row p. We replace that with some variable x. I don't know what x is. Or the expression or the value. Okay, so if we can put variables in and then have a system that can do a mixture of maybe things like search and constraint solving, then we can try putting variables in to get more flexibility. So, that's exactly what we've done. So, what that means is, if I go back to this valo call, I don't have to just put in an expression that's known in the first position and then put an unknown in the value position. I can do the opposite. So, what I could do is I say, okay, well, I know that the list is supposed to be three, four, right? And grab this list. The extra prens, by the way, and that answer up top have to do with, first of all, the fact that we can get more than one answer back and also that we can get some side conditions to help interpret the answer. Anyway, I'm going to replace that query variable with quote three, four. So, that's the expected value. And I'm going to replace the expression with my query variable Q. So, now what I'm asking is, give me an expression in scheme that evaluates the list three, four. So, what would be one such expression do you think? List three, four. Okay. So, list three, four is one. Quote three, four is another. So, I can ask for, you know, let me ask for two answers. Okay. So, list three, four was the second one I got. And I can ask for three answers. And we can see list three, quote, four. So, it turns out that if you quote three or four, it's the same as just writing three or four. And so, you can see that we have a number of answers, right? And so, some of those answers involve things like lambda and procedure application. So, as I say, hey, as function call can give you three, the list three, four. All right. Now, back to Lollipop land. So, Matt might, who's giving keynote tonight and whose lab I work in and work with for many years. He wrote a blog post for Valentine's Day a couple years ago called 99 ways to say I love you in racket. So, the idea of this was to teach students and beginning racket programmers a little bit of racket and a little bit of how they manipulate lists because racket's a list and list is list processing. So, the idea is to show 99 different expressions and there are various complicated ones and so forth that would evaluate to list I love you. And PD Aldous, who's one of the grad students said, hey, do you think you could use mini-canron to generate such programs? So, let's try doing that. We're going to generate 99 programs that evaluate to I love you. So, can you help me out with the query? What would that look like? Run 99? Sure. Okay. What else is going to change? Sure. Okay. How about I love you? Okay. All right. So, here are 99 programs that evaluate to I love you. So, I don't know. Let me, what's a fun one? How about, let's just start down here. Let me just grab that out and I'm running it in scheme now and you can see that evaluates I love you. So, we've got list quote I, quote love and then the last sub expression is a procedure call to a function which is variadic. It takes any number of arguments. The underscore dot zero represents a symbol representing, that's a symbol representing a variable. The name doesn't matter. That's why I picked underscore dot zero. That's our convention saying it doesn't matter. You could pick foo if you wanted there. And this quote underscore one thing. So, this is a quoted symbol also. If you look at the side conditions, you'll see these things. So, that could be any quoted symbol and this will hold. There might be some other side conditions like the symbol can't be called quote. Under score zero can't be called quote because you don't want to shadow quote, that kind of thing. Okay. So, that's a simple example. And after, after we started playing around with this a little bit, Dan Friedman and I gave a talk at closure conge and we, we showed this relational interpreter or variant of it and Stu Holloway at the end said, well, you know, you should be able to generate quines using this. Anyone know what a quine is? What's a quine? A program that outputs itself. That's right. Okay. In fact, if we go back to history, let's see if we can go back and, you know, I love the fact the guy went through so many papers, old papers. Well, this is a paper I really like by John McCarthy who is the creator of, of Lisp called a micromanual for Lisp, not the whole truth. And then this he gives rules for the Lisp language. So, you can see like what equal means, what cons means and so forth. Notice by the way he uses an equal sign. Right? Not narrow. But then he has this neat little problem. Difficult mathematical type exercise. Final list E such that value of E equals E. So, value is the name of his evaluator function, his eval. So, basically, what he's calling value is what we would call eval or evalo. And so, he's trying to find an expression E such that the value of E is E. So, that is also trying to find a quine. So, he was trying to find a quine or Gittis to find a quine in, I think, 1978. So, let's try to do that. So, given what you know, how would we find a quine? What would, how would we change our query so we could generate a quine? QQ, a value of QQ, that's right. Now, of course, there's nothing special about the name Q. So, why don't we, out of respect for John McCarthy, call it E instead. Valo EE. And let's do a run one. Okay. So, we're trying to find an expression E that evaluates to itself. This is pretty close to what John McCarthy wrote, right? I mean, we're calling it a valo instead of, instead of value. But, you know, this is exactly what you would want to be able to type into a system. So, let's see what Minicandron gives us back. Well, the first thing it says is that underscore zero is a number, which is true. Okay. So, in scheme five is a quine. So, five evaluates to itself. That's true. Okay. So, that's what Minicandron's telling us. Let's ask for a second one. It says hash t. Hash t is true in scheme. All right. So, those are all quines. Hash f is a quine. How about four? Now, it's thinking for a minute. Okay. Now, we've got something a little more interesting. I'm going to grab that expression and type it in. And sure enough, that's a quine. So, that's a self-evaluating expression. In fact, if you look at the quines page, you will see this quine. This is sort of the canonical quine. And we can generate all sorts of quines. We can generate twin quines and triple quines and that kind of thing. But what I love about this, and in some sense, this is probably my favorite Minicandron query using a relational interpreter, but I love it as the query is so simple. This is actually the shortest query you can write in terms of the number of distinct identifiers. This is like the shortest thing you can write. And it generates quines and it actually works. And I personally was shocked that like, oh, yeah, this actually, this actually, you can actually do something with this. You type it in. I figured it would take a million years or something. Okay. So, at that point, a grad student at Utah named Michael Ballantyne said, well, that's kind of fun. But what if you, now you have this interpreter, what if you were to take a scheme program and fill in the scheme program in the first expression, but leave some of the arguments to that program, to that function, you know, make those variables? Could you, could you get interesting behavior? And so he suggested append. So let's try doing that. So append in scheme takes two lists, like ABC and DE, and concatenates the list. So get ABCDE, in this case. So what we're going to do is we're going to write append. And the way I'll write append is using something called let rec. Let's me define a recursive relation or a function. Okay. So that's append. Did I get it right? And now we're going to call append. I'll use the same arguments as before, ABC to DE. Okay. So I just ran it forward. So, so what did I do? I took the scheme definition of append. This is not mini-canon code. This is not logic programming code or constraint logic program code. This is just scheme code. I ran it inside of a valo as the first argument. This is the expression argument. And I said we have an unknown value. So my query variable Q represents the unknown value. So what can we do? Okay. So now what we can do is we can say we know ABCDE is the output. And where else could I put a variable? Where could I put this Q variable? Well, how about I put it in a position of one of the arguments to append? How about I put it right here? I have to put a comma there because this whole thing is back-quoted if you know scheme. All right. So what do you think I'm going to get back in the place of the Q variable? ABC, right? So let's see if that works. Yeah. Quote ABC. Is there a second answer? What if I do a run two? Should there be a second answer or should it say no? No more answers. List ABC. All right. Well, let's see if we get something like that. It's not list ABC, but we get a procedure application. And if I evaluate that in scheme, I get back ABC. So what happens is we get an expression that evaluates to ABC. If I put a quote, I get back ABC itself. Okay. So that's a little subtle if you're not a schemer, but the point is we're making a distinction between expressions and values. So if I put a quote in front of the comma Q, that's going to say, well, I want the value, the list that's going to concatenate to give me ABCDE. If I don't put the quote, that means this could be an arbitrary expression in my subset of scheme that I'm handling. All right. Where else can I put Q? Inside the list, like here. Sure. Yep. In fact, I could have two variables. I could do like x and y. And I can do things like... In fact, I can ask for all the answers. So if you're familiar with logic programming and prologue or mini-canon or something like that, you've seen this before, things like a pen. That's a standard answer or a standard program. But we didn't write a pen in mini-canon or prologue. We wrote a pen in scheme. We'd get the relationality through the relational interpreter. All right. What else can we do? Where else can we put variable? How about if we put a variable inside the code? What if I put a variable where the s is? Okay. That used to be the symbol s. What should I get back? I get back the s, right? So I could also replace it here, like the car of L. Oh, I got two... I was doing a run two. Yeah. So I got car of L and another expression, which is the same as car of L, equivalent to it. All right. Now, I could show you much, much more. If you're interested in that sort of thing, I recommend you look at our paper in ICFP 2017. But I just want to show you what happens if you sort of put an interface on this. And you also speed up the naive version by about nine orders of magnitude, because that's what we've done. Michael Valentine and Greg Rosenblatt have been speeding up the system. So Greg gave us eight orders of magnitude in eight months or something. So now what we're going to do is we're going to do some program synthesis. So this... What's happening underneath the hood is we're just generating calls to our Valo. We're doing example-based program synthesis. So here I have a call to a pen. I've got a fragment of the append definition, the comma A, comma B, comma C. Those are logic variables representing holes in our program. And you can see at the bottom that Barleman's trying to figure out what we have. I can do this in various ways, but one way I might want to do it to try to keep the system from over-specializing is to use these G1, G2 things, which sort of represent universally quantified variables, if you want to think of that way, or sort of like Jenssen's skull invariables. So I don't quite have enough structure. So let me try one more example. Okay. Let that think for a minute. Okay. Now it's figured out the recursion. And it's a little hard to read it. So I'm going to just put in variable names, concrete variable names. And now you can see, you can read a little more. And if you know scheme, this is the correct definition of a pen. Okay. So what's happened? We've taken minicanron. We've implemented the semantics written in something similar to the CMS, computer science meta, or is it CMN? Whatever it's called. The computer science meta notation or whatever. Okay. Something like that. And through some cleverness on the back end, which we're hoping to generalize, so it's not just for our interpreter, but we'll work with a wider range of semantics and type systems and things like that. You would just type in. We can also do this for grammars, regular expressions, and so forth. We're able to get to the point where we can just type in input-output examples, and the system is able to do recursive, higher-order synthesis for our subset of scheme. We can also write type inferences in this way. So I'm hoping we can combine those. We'd write type inferences in the same way. We'd write the operational semantics for the evaluator. And we can also write grammars. There's also a grammar written in exactly the same style underneath this. So we can do grammars. We can generate expressions in exactly the same way. So I'm hoping as we improve this technology that we'll get closer and closer, I don't think we'll ever get there perfectly, but we'll get closer and closer to being able to be naive and just take a paper or some operational semantics or typing judgments or whatever, just type it in, hopefully with a nicer syntax, and then be able to start exploring this world and asking queries that maybe other people haven't thought of before or just being surprised. That's the best part for me. That's why I like Doug's math aquarium. It would surprise you. And that's why I like playing around with mini-canner. There's things like quines that surprise me. There are all sorts of programs that we're generating that surprise me. I didn't think it would be either possible or I had a different idea of which program would meet a certain specification, and mini-canner said, hey, this program meets it also, often sort of trolling me in the process. So anyway, this is lollipop driven development, if you will, where you just type the semantics, sort of like you'd read in the paper, write down examples, maybe write down types and things like that, get the system to fill in the unknowns for you in an exploratory way. So that's basically what Dan should have told me. He should have said, well, eight years from now, Guy Steele will give a keynote at CodeMesh, and at that point, we want to be able to type in those rules and just have it do things like and further program. So that's the idea. If you're interested in this, look at an ICFP 2017 paper, go to mini-canron.org, look at the paper on micro-canron, which shows an implementation of a simple version, and look for the second edition of the Reason Schemer, which is about to come out. Thank you. Well, we actually have two minutes left. I think this is the first for you, Will, so we can take a question if you want. So the second test didn't work. Could you just go back and do that again, but fill it in with kind of the readable symbols so we can see why. So you want this one? Yeah. Well, the second one did work in a sense. It depends what you mean by work. So the mini-canron or Barleman's idea is prove me wrong, right? So this program absolutely matches that specification, but you're right that it's not what we had in mind, and this is part of the problem, right? So even if you can imagine Barleman being 500 orders of magnitude faster, and in some sense it solves program census by example, in another sense you still have the problem of writing down a specification that is complete enough and correct enough that you're going to get the right output, even if we're much, much faster, right? So this shows that census really has at least two problems. One is the speed problem of dealing with this exponential space and dealing with, you know, synthesizing programs that could go in infant loops, but there's also the specification problem. So how did you know what to type in the box labeled test three? How do you know what to type in there? Well, so that's a good question. There are different ways to give a specification. So you could write types, right? We don't currently support that, but you could write types, you could write examples, you could write properties, high-level properties, right? The other thing you can do, which I didn't show you, is that this is an IDE, so you can edit the code. So you can be writing some of the code and writing some of the tests and writing some of the types, and it's going to fill in the rest for you. So you could also use it as sort of like an IDE. But at some point, if you don't know what the program should do and you don't know any of the code, it's not going to figure that out for you. So you're going to have to do a little work. You know, even with my example, my stupid box example, I still had to figure out that I wanted a box that was two inches by two inches, right? So yes. Thank you. So basically, this is automated TDD, isn't it? That's part of it, but the reason I gave that intro is the problem is every time I give a talk, and I've given many variants of this talk, every single time I give a talk, someone comes away thinking, oh, well, so your research is on program census, or your research is on test-driven development, or your research is on logic programming, or your research is like, no, no, that's not it. The research is on lollipops, okay? The research is on lollipops and being able to sort of do things like just write down the rules and explore it, okay? That's really what the dream is. Program census falls out of this. Now, if we can do, if we make the system much faster and we can get a useful program census tool, or a useful test-driven development tool, or a useful IDE, great. But that's only a very small part of really the overall goal. Thank you, Will.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 16.04, "text": " Thank you. This always happens to me at CodeMesh. I have an idea for a talk, and then after", "tokens": [50364, 1044, 291, 13, 639, 1009, 2314, 281, 385, 412, 15549, 44, 14935, 13, 286, 362, 364, 1558, 337, 257, 751, 11, 293, 550, 934, 51166], "temperature": 0.0, "avg_logprob": -0.25062548147665487, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.01997992768883705}, {"id": 1, "seek": 0, "start": 16.04, "end": 20.56, "text": " seeing a keynote or having a conversation with someone, I'm like, throw that out. Actually,", "tokens": [51166, 2577, 257, 33896, 420, 1419, 257, 3761, 365, 1580, 11, 286, 478, 411, 11, 3507, 300, 484, 13, 5135, 11, 51392], "temperature": 0.0, "avg_logprob": -0.25062548147665487, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.01997992768883705}, {"id": 2, "seek": 0, "start": 20.56, "end": 23.94, "text": " Boodle last night tried to convince me to give a talk on StarCraft instead, which I'm", "tokens": [51392, 363, 1816, 306, 1036, 1818, 3031, 281, 13447, 385, 281, 976, 257, 751, 322, 5705, 34, 4469, 2602, 11, 597, 286, 478, 51561], "temperature": 0.0, "avg_logprob": -0.25062548147665487, "compression_ratio": 1.4157894736842105, "no_speech_prob": 0.01997992768883705}, {"id": 3, "seek": 2394, "start": 23.94, "end": 32.620000000000005, "text": " sorely tempted to do, but maybe next year. Yes. But I saw Guy Steele's keynote last night,", "tokens": [50364, 22468, 356, 29941, 281, 360, 11, 457, 1310, 958, 1064, 13, 1079, 13, 583, 286, 1866, 14690, 745, 1653, 306, 311, 33896, 1036, 1818, 11, 50798], "temperature": 0.0, "avg_logprob": -0.17197240829467775, "compression_ratio": 1.6318181818181818, "no_speech_prob": 0.11273275315761566}, {"id": 4, "seek": 2394, "start": 32.620000000000005, "end": 38.260000000000005, "text": " which I loved, and I have to say that I love Scheme. I agree with Alan Kay that Lisp is", "tokens": [50798, 597, 286, 4333, 11, 293, 286, 362, 281, 584, 300, 286, 959, 2065, 5729, 13, 286, 3986, 365, 16442, 14179, 300, 441, 7631, 307, 51080], "temperature": 0.0, "avg_logprob": -0.17197240829467775, "compression_ratio": 1.6318181818181818, "no_speech_prob": 0.11273275315761566}, {"id": 5, "seek": 2394, "start": 38.260000000000005, "end": 42.96, "text": " the most important programming language ever created, and for my money, Scheme is the most", "tokens": [51080, 264, 881, 1021, 9410, 2856, 1562, 2942, 11, 293, 337, 452, 1460, 11, 2065, 5729, 307, 264, 881, 51315], "temperature": 0.0, "avg_logprob": -0.17197240829467775, "compression_ratio": 1.6318181818181818, "no_speech_prob": 0.11273275315761566}, {"id": 6, "seek": 2394, "start": 42.96, "end": 50.24, "text": " important Lisp. So I think Scheme is one of the great joys of my life. I love programming", "tokens": [51315, 1021, 441, 7631, 13, 407, 286, 519, 2065, 5729, 307, 472, 295, 264, 869, 1488, 749, 295, 452, 993, 13, 286, 959, 9410, 51679], "temperature": 0.0, "avg_logprob": -0.17197240829467775, "compression_ratio": 1.6318181818181818, "no_speech_prob": 0.11273275315761566}, {"id": 7, "seek": 5024, "start": 50.24, "end": 55.92, "text": " and Scheme, and when I went to Indiana University to get my PhD, I went there specifically to", "tokens": [50364, 293, 2065, 5729, 11, 293, 562, 286, 1437, 281, 21858, 3535, 281, 483, 452, 14476, 11, 286, 1437, 456, 4682, 281, 50648], "temperature": 0.0, "avg_logprob": -0.15210767296271596, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.07156623899936676}, {"id": 8, "seek": 5024, "start": 55.92, "end": 61.14, "text": " work with Dan Friedman and get my PhD in Scheme. On the first day of grad school, I walked", "tokens": [50648, 589, 365, 3394, 17605, 1601, 293, 483, 452, 14476, 294, 2065, 5729, 13, 1282, 264, 700, 786, 295, 2771, 1395, 11, 286, 7628, 50909], "temperature": 0.0, "avg_logprob": -0.15210767296271596, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.07156623899936676}, {"id": 9, "seek": 5024, "start": 61.14, "end": 67.82000000000001, "text": " up to Dan, and I said, I'm so excited to be here at Indiana University so that you could", "tokens": [50909, 493, 281, 3394, 11, 293, 286, 848, 11, 286, 478, 370, 2919, 281, 312, 510, 412, 21858, 3535, 370, 300, 291, 727, 51243], "temperature": 0.0, "avg_logprob": -0.15210767296271596, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.07156623899936676}, {"id": 10, "seek": 5024, "start": 67.82000000000001, "end": 73.64, "text": " teach me Scheme, and he says, I don't do Scheme anymore. I do logic programming. It's like", "tokens": [51243, 2924, 385, 2065, 5729, 11, 293, 415, 1619, 11, 286, 500, 380, 360, 2065, 5729, 3602, 13, 286, 360, 9952, 9410, 13, 467, 311, 411, 51534], "temperature": 0.0, "avg_logprob": -0.15210767296271596, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.07156623899936676}, {"id": 11, "seek": 5024, "start": 73.64, "end": 77.92, "text": " something you could have told me two weeks ago, and I would have gone Northeastern, but", "tokens": [51534, 746, 291, 727, 362, 1907, 385, 732, 3259, 2057, 11, 293, 286, 576, 362, 2780, 4067, 68, 32579, 11, 457, 51748], "temperature": 0.0, "avg_logprob": -0.15210767296271596, "compression_ratio": 1.7056603773584906, "no_speech_prob": 0.07156623899936676}, {"id": 12, "seek": 7792, "start": 77.92, "end": 83.36, "text": " I didn't. Anyway, but Dan should have told me something else instead. He shouldn't have", "tokens": [50364, 286, 994, 380, 13, 5684, 11, 457, 3394, 820, 362, 1907, 385, 746, 1646, 2602, 13, 634, 4659, 380, 362, 50636], "temperature": 0.0, "avg_logprob": -0.1285960920925798, "compression_ratio": 1.8403361344537814, "no_speech_prob": 0.0012841337593272328}, {"id": 13, "seek": 7792, "start": 83.36, "end": 86.9, "text": " said, I don't do Scheme anymore. I do logic programming. He should have said something", "tokens": [50636, 848, 11, 286, 500, 380, 360, 2065, 5729, 3602, 13, 286, 360, 9952, 9410, 13, 634, 820, 362, 848, 746, 50813], "temperature": 0.0, "avg_logprob": -0.1285960920925798, "compression_ratio": 1.8403361344537814, "no_speech_prob": 0.0012841337593272328}, {"id": 14, "seek": 7792, "start": 86.9, "end": 96.24000000000001, "text": " else, and so this talk is kind of about what Dan really should have told me, and sort of", "tokens": [50813, 1646, 11, 293, 370, 341, 751, 307, 733, 295, 466, 437, 3394, 534, 820, 362, 1907, 385, 11, 293, 1333, 295, 51280], "temperature": 0.0, "avg_logprob": -0.1285960920925798, "compression_ratio": 1.8403361344537814, "no_speech_prob": 0.0012841337593272328}, {"id": 15, "seek": 7792, "start": 96.24000000000001, "end": 100.76, "text": " trying to explain what we've been doing the last 13 plus years. I've been doing it for", "tokens": [51280, 1382, 281, 2903, 437, 321, 600, 668, 884, 264, 1036, 3705, 1804, 924, 13, 286, 600, 668, 884, 309, 337, 51506], "temperature": 0.0, "avg_logprob": -0.1285960920925798, "compression_ratio": 1.8403361344537814, "no_speech_prob": 0.0012841337593272328}, {"id": 16, "seek": 7792, "start": 100.76, "end": 105.66, "text": " the last 13 years. Dan's been doing it longer than that. What is it we're trying to do,", "tokens": [51506, 264, 1036, 3705, 924, 13, 3394, 311, 668, 884, 309, 2854, 813, 300, 13, 708, 307, 309, 321, 434, 1382, 281, 360, 11, 51751], "temperature": 0.0, "avg_logprob": -0.1285960920925798, "compression_ratio": 1.8403361344537814, "no_speech_prob": 0.0012841337593272328}, {"id": 17, "seek": 10566, "start": 105.66, "end": 110.24, "text": " and what is this weird mini-canon language we're working on, and why is it not prologue,", "tokens": [50364, 293, 437, 307, 341, 3657, 8382, 12, 7035, 266, 2856, 321, 434, 1364, 322, 11, 293, 983, 307, 309, 406, 447, 4987, 622, 11, 50593], "temperature": 0.0, "avg_logprob": -0.2265040134561473, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.003171124029904604}, {"id": 18, "seek": 10566, "start": 110.24, "end": 116.17999999999999, "text": " and how does that fit into Guy's keynote, and all these other things? The original talk", "tokens": [50593, 293, 577, 775, 300, 3318, 666, 14690, 311, 33896, 11, 293, 439, 613, 661, 721, 30, 440, 3380, 751, 50890], "temperature": 0.0, "avg_logprob": -0.2265040134561473, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.003171124029904604}, {"id": 19, "seek": 10566, "start": 116.17999999999999, "end": 121.69999999999999, "text": " was relational interpreters, program census, and Barlaman strange, beautiful, and possibly", "tokens": [50890, 390, 38444, 17489, 1559, 11, 1461, 23725, 11, 293, 4156, 4326, 282, 5861, 11, 2238, 11, 293, 6264, 51166], "temperature": 0.0, "avg_logprob": -0.2265040134561473, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.003171124029904604}, {"id": 20, "seek": 10566, "start": 121.69999999999999, "end": 127.78, "text": " useful. Maybe it'll be useful someday, but I don't really care about useful so much,", "tokens": [51166, 4420, 13, 2704, 309, 603, 312, 4420, 19412, 11, 457, 286, 500, 380, 534, 1127, 466, 4420, 370, 709, 11, 51470], "temperature": 0.0, "avg_logprob": -0.2265040134561473, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.003171124029904604}, {"id": 21, "seek": 10566, "start": 127.78, "end": 135.54, "text": " as you might see. The language we're working on is called mini-canon, and I got to get", "tokens": [51470, 382, 291, 1062, 536, 13, 440, 2856, 321, 434, 1364, 322, 307, 1219, 8382, 12, 7035, 266, 11, 293, 286, 658, 281, 483, 51858], "temperature": 0.0, "avg_logprob": -0.2265040134561473, "compression_ratio": 1.6692015209125475, "no_speech_prob": 0.003171124029904604}, {"id": 22, "seek": 13554, "start": 135.54, "end": 141.01999999999998, "text": " my memes in, and my ponies for Boodle, but someone made this up. Fresh is one of the", "tokens": [50364, 452, 29730, 294, 11, 293, 452, 9224, 530, 337, 363, 1816, 306, 11, 457, 1580, 1027, 341, 493, 13, 22843, 307, 472, 295, 264, 50638], "temperature": 0.0, "avg_logprob": -0.17773487170537314, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.004329219926148653}, {"id": 23, "seek": 13554, "start": 141.01999999999998, "end": 148.18, "text": " key operators. There are only three operators in the core language, but here's my second", "tokens": [50638, 2141, 19077, 13, 821, 366, 787, 1045, 19077, 294, 264, 4965, 2856, 11, 457, 510, 311, 452, 1150, 50996], "temperature": 0.0, "avg_logprob": -0.17773487170537314, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.004329219926148653}, {"id": 24, "seek": 13554, "start": 148.18, "end": 153.85999999999999, "text": " meme, and this is something I've heard a lot of. Mini-canon is the worst logic programming", "tokens": [50996, 21701, 11, 293, 341, 307, 746, 286, 600, 2198, 257, 688, 295, 13, 18239, 12, 7035, 266, 307, 264, 5855, 9952, 9410, 51280], "temperature": 0.0, "avg_logprob": -0.17773487170537314, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.004329219926148653}, {"id": 25, "seek": 13554, "start": 153.85999999999999, "end": 161.7, "text": " language I've ever heard of, but you have heard of it, right? People often say, well,", "tokens": [51280, 2856, 286, 600, 1562, 2198, 295, 11, 457, 291, 362, 2198, 295, 309, 11, 558, 30, 3432, 2049, 584, 11, 731, 11, 51672], "temperature": 0.0, "avg_logprob": -0.17773487170537314, "compression_ratio": 1.5695067264573992, "no_speech_prob": 0.004329219926148653}, {"id": 26, "seek": 16170, "start": 161.73999999999998, "end": 166.98, "text": " this is terrible. Prologue has all these extra features, or prologue implementations are", "tokens": [50366, 341, 307, 6237, 13, 1705, 4987, 622, 575, 439, 613, 2857, 4122, 11, 420, 447, 4987, 622, 4445, 763, 366, 50628], "temperature": 0.0, "avg_logprob": -0.15955510820661273, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.016396425664424896}, {"id": 27, "seek": 16170, "start": 166.98, "end": 173.98, "text": " faster, so why use mini-canon? The point is, in my mind, isn't to build a logic language.", "tokens": [50628, 4663, 11, 370, 983, 764, 8382, 12, 7035, 266, 30, 440, 935, 307, 11, 294, 452, 1575, 11, 1943, 380, 281, 1322, 257, 9952, 2856, 13, 50978], "temperature": 0.0, "avg_logprob": -0.15955510820661273, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.016396425664424896}, {"id": 28, "seek": 16170, "start": 174.89999999999998, "end": 179.04, "text": " That's not what I'm trying to do, at least. I don't care about logic programming. I don't", "tokens": [51024, 663, 311, 406, 437, 286, 478, 1382, 281, 360, 11, 412, 1935, 13, 286, 500, 380, 1127, 466, 9952, 9410, 13, 286, 500, 380, 51231], "temperature": 0.0, "avg_logprob": -0.15955510820661273, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.016396425664424896}, {"id": 29, "seek": 16170, "start": 179.04, "end": 186.04, "text": " care about mini-canon. That's not what I'm trying to do. Let me tell you a story, and", "tokens": [51231, 1127, 466, 8382, 12, 7035, 266, 13, 663, 311, 406, 437, 286, 478, 1382, 281, 360, 13, 961, 385, 980, 291, 257, 1657, 11, 293, 51581], "temperature": 0.0, "avg_logprob": -0.15955510820661273, "compression_ratio": 1.669811320754717, "no_speech_prob": 0.016396425664424896}, {"id": 30, "seek": 18604, "start": 186.88, "end": 192.88, "text": " I'll do my first live coding. I'm going to show you the first program I ever wrote. I", "tokens": [50406, 286, 603, 360, 452, 700, 1621, 17720, 13, 286, 478, 516, 281, 855, 291, 264, 700, 1461, 286, 1562, 4114, 13, 286, 50706], "temperature": 0.0, "avg_logprob": -0.23730519477357256, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.012051219120621681}, {"id": 31, "seek": 18604, "start": 192.88, "end": 197.0, "text": " was nine years old. My father bought this beautiful computer. Anyone know what this", "tokens": [50706, 390, 4949, 924, 1331, 13, 1222, 3086, 4243, 341, 2238, 3820, 13, 14643, 458, 437, 341, 50912], "temperature": 0.0, "avg_logprob": -0.23730519477357256, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.012051219120621681}, {"id": 32, "seek": 18604, "start": 197.0, "end": 204.0, "text": " is? No one knows what that computer is, really. TRS-80 Coco, trash 80, color computer. Believe", "tokens": [50912, 307, 30, 883, 472, 3255, 437, 300, 3820, 307, 11, 534, 13, 15176, 50, 12, 4702, 29787, 11, 11321, 4688, 11, 2017, 3820, 13, 21486, 51262], "temperature": 0.0, "avg_logprob": -0.23730519477357256, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.012051219120621681}, {"id": 33, "seek": 18604, "start": 209.39999999999998, "end": 214.6, "text": " it or not, but one point in the time, this was the most popular computer in the world,", "tokens": [51532, 309, 420, 406, 11, 457, 472, 935, 294, 264, 565, 11, 341, 390, 264, 881, 3743, 3820, 294, 264, 1002, 11, 51792], "temperature": 0.0, "avg_logprob": -0.23730519477357256, "compression_ratio": 1.5394736842105263, "no_speech_prob": 0.012051219120621681}, {"id": 34, "seek": 21460, "start": 215.0, "end": 220.4, "text": " and Radio Shack actually had summer camps. My first class in programming was taught by", "tokens": [50384, 293, 17296, 1160, 501, 767, 632, 4266, 16573, 13, 1222, 700, 1508, 294, 9410, 390, 5928, 538, 50654], "temperature": 0.0, "avg_logprob": -0.26649005142683835, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000731942243874073}, {"id": 35, "seek": 21460, "start": 220.4, "end": 227.4, "text": " Radio Shack, the summer school in programming, in Logo. The TRS-80 Coco, that came out in", "tokens": [50654, 17296, 1160, 501, 11, 264, 4266, 1395, 294, 9410, 11, 294, 10824, 78, 13, 440, 15176, 50, 12, 4702, 29787, 11, 300, 1361, 484, 294, 51004], "temperature": 0.0, "avg_logprob": -0.26649005142683835, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000731942243874073}, {"id": 36, "seek": 21460, "start": 227.92, "end": 234.92, "text": " 1980, hence the name. Let's see if I can show you the program. We got this new computer,", "tokens": [51030, 13626, 11, 16678, 264, 1315, 13, 961, 311, 536, 498, 286, 393, 855, 291, 264, 1461, 13, 492, 658, 341, 777, 3820, 11, 51380], "temperature": 0.0, "avg_logprob": -0.26649005142683835, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000731942243874073}, {"id": 37, "seek": 21460, "start": 237.44, "end": 243.4, "text": " and normally I used to think that I'd seen war games or whatever, and I knew how to program,", "tokens": [51506, 293, 5646, 286, 1143, 281, 519, 300, 286, 1116, 1612, 1516, 2813, 420, 2035, 11, 293, 286, 2586, 577, 281, 1461, 11, 51804], "temperature": 0.0, "avg_logprob": -0.26649005142683835, "compression_ratio": 1.5497835497835497, "no_speech_prob": 0.000731942243874073}, {"id": 38, "seek": 24340, "start": 243.4, "end": 247.24, "text": " but war games I don't think was out yet, so I must have seen Star Wars, but I thought", "tokens": [50364, 457, 1516, 2813, 286, 500, 380, 519, 390, 484, 1939, 11, 370, 286, 1633, 362, 1612, 5705, 9818, 11, 457, 286, 1194, 50556], "temperature": 0.0, "avg_logprob": -0.19349527883005666, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.003375596133992076}, {"id": 39, "seek": 24340, "start": 247.24, "end": 251.92000000000002, "text": " I knew how to program, so we get this computer, and it's like, all right, I'm going to show", "tokens": [50556, 286, 2586, 577, 281, 1461, 11, 370, 321, 483, 341, 3820, 11, 293, 309, 311, 411, 11, 439, 558, 11, 286, 478, 516, 281, 855, 50790], "temperature": 0.0, "avg_logprob": -0.19349527883005666, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.003375596133992076}, {"id": 40, "seek": 24340, "start": 251.92000000000002, "end": 256.48, "text": " off to my brother, my little brother, because I'd watched all these movies. Here is exactly", "tokens": [50790, 766, 281, 452, 3708, 11, 452, 707, 3708, 11, 570, 286, 1116, 6337, 439, 613, 6233, 13, 1692, 307, 2293, 51018], "temperature": 0.0, "avg_logprob": -0.19349527883005666, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.003375596133992076}, {"id": 41, "seek": 24340, "start": 256.48, "end": 263.48, "text": " the program that I wrote. Oh, I got to click on it.", "tokens": [51018, 264, 1461, 300, 286, 4114, 13, 876, 11, 286, 658, 281, 2052, 322, 309, 13, 51368], "temperature": 0.0, "avg_logprob": -0.19349527883005666, "compression_ratio": 1.5141509433962264, "no_speech_prob": 0.003375596133992076}, {"id": 42, "seek": 27340, "start": 274.4, "end": 281.4, "text": " As I recall, the exact program I wrote 37 years ago, and that's the exact result I got.", "tokens": [50414, 1018, 286, 9901, 11, 264, 1900, 1461, 286, 4114, 13435, 924, 2057, 11, 293, 300, 311, 264, 1900, 1874, 286, 658, 13, 50764], "temperature": 0.0, "avg_logprob": -0.2092515420222628, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0012064571492373943}, {"id": 43, "seek": 27340, "start": 284.4, "end": 289.32, "text": " I basically flipped the table, and I said, this is not for me, and I didn't touch the", "tokens": [50914, 286, 1936, 26273, 264, 3199, 11, 293, 286, 848, 11, 341, 307, 406, 337, 385, 11, 293, 286, 994, 380, 2557, 264, 51160], "temperature": 0.0, "avg_logprob": -0.2092515420222628, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0012064571492373943}, {"id": 44, "seek": 27340, "start": 289.32, "end": 296.32, "text": " computer or programming for several years after. In effect, I haven't really changed.", "tokens": [51160, 3820, 420, 9410, 337, 2940, 924, 934, 13, 682, 1802, 11, 286, 2378, 380, 534, 3105, 13, 51510], "temperature": 0.0, "avg_logprob": -0.2092515420222628, "compression_ratio": 1.505813953488372, "no_speech_prob": 0.0012064571492373943}, {"id": 45, "seek": 29632, "start": 297.32, "end": 304.32, "text": " This is really my philosophy of what programming should be like. The fact that I have become", "tokens": [50414, 639, 307, 534, 452, 10675, 295, 437, 9410, 820, 312, 411, 13, 440, 1186, 300, 286, 362, 1813, 50764], "temperature": 0.0, "avg_logprob": -0.21237140543320598, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.008313257247209549}, {"id": 46, "seek": 29632, "start": 305.71999999999997, "end": 311.71999999999997, "text": " an expert and have a PhD in programming, to me, is offensive. It's not something joyful.", "tokens": [50834, 364, 5844, 293, 362, 257, 14476, 294, 9410, 11, 281, 385, 11, 307, 15710, 13, 467, 311, 406, 746, 33090, 13, 51134], "temperature": 0.0, "avg_logprob": -0.21237140543320598, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.008313257247209549}, {"id": 47, "seek": 29632, "start": 311.71999999999997, "end": 318.71999999999997, "text": " It's like the same thing where writing books with Dan, or writing latex papers, or whatever.", "tokens": [51134, 467, 311, 411, 264, 912, 551, 689, 3579, 3642, 365, 3394, 11, 420, 3579, 3469, 87, 10577, 11, 420, 2035, 13, 51484], "temperature": 0.0, "avg_logprob": -0.21237140543320598, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.008313257247209549}, {"id": 48, "seek": 31872, "start": 319.12, "end": 324.12, "text": " The fact that I've become a master in mangling latex files and post-processing latex files", "tokens": [50384, 440, 1186, 300, 286, 600, 1813, 257, 4505, 294, 32432, 1688, 3469, 87, 7098, 293, 2183, 12, 41075, 278, 3469, 87, 7098, 50634], "temperature": 0.0, "avg_logprob": -0.20480132370852352, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.005057487171143293}, {"id": 49, "seek": 31872, "start": 324.12, "end": 329.12, "text": " with Perl scripts is not something I'm proud of. It's something I'm ashamed of.", "tokens": [50634, 365, 3026, 75, 23294, 307, 406, 746, 286, 478, 4570, 295, 13, 467, 311, 746, 286, 478, 19489, 295, 13, 50884], "temperature": 0.0, "avg_logprob": -0.20480132370852352, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.005057487171143293}, {"id": 50, "seek": 31872, "start": 329.12, "end": 336.12, "text": " The fact that I still, to this day, have to program at a much higher level, in a sense,", "tokens": [50884, 440, 1186, 300, 286, 920, 11, 281, 341, 786, 11, 362, 281, 1461, 412, 257, 709, 2946, 1496, 11, 294, 257, 2020, 11, 51234], "temperature": 0.0, "avg_logprob": -0.20480132370852352, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.005057487171143293}, {"id": 51, "seek": 31872, "start": 336.12, "end": 341.12, "text": " I can't write that sort of program, really offends me.", "tokens": [51234, 286, 393, 380, 2464, 300, 1333, 295, 1461, 11, 534, 766, 2581, 385, 13, 51484], "temperature": 0.0, "avg_logprob": -0.20480132370852352, "compression_ratio": 1.621761658031088, "no_speech_prob": 0.005057487171143293}, {"id": 52, "seek": 34112, "start": 341.52, "end": 348.52, "text": " Let's see. I think you can sum up my attitude with this epigram in programming.", "tokens": [50384, 961, 311, 536, 13, 286, 519, 291, 393, 2408, 493, 452, 10157, 365, 341, 2388, 33737, 294, 9410, 13, 50734], "temperature": 0.0, "avg_logprob": -0.20593579610188803, "compression_ratio": 1.5323383084577114, "no_speech_prob": 0.0028441522736102343}, {"id": 53, "seek": 34112, "start": 354.32, "end": 358.32, "text": " If you haven't read Alan Perlis' epigrams in programming, you should read those. They're", "tokens": [51024, 759, 291, 2378, 380, 1401, 16442, 3026, 75, 271, 6, 2388, 33737, 82, 294, 9410, 11, 291, 820, 1401, 729, 13, 814, 434, 51224], "temperature": 0.0, "avg_logprob": -0.20593579610188803, "compression_ratio": 1.5323383084577114, "no_speech_prob": 0.0028441522736102343}, {"id": 54, "seek": 34112, "start": 358.32, "end": 363.32, "text": " fantastic. The epigram 93. When someone says, I want a programming language in which I need", "tokens": [51224, 5456, 13, 440, 2388, 33737, 28876, 13, 1133, 1580, 1619, 11, 286, 528, 257, 9410, 2856, 294, 597, 286, 643, 51474], "temperature": 0.0, "avg_logprob": -0.20593579610188803, "compression_ratio": 1.5323383084577114, "no_speech_prob": 0.0028441522736102343}, {"id": 55, "seek": 34112, "start": 363.32, "end": 368.32, "text": " only say what I wish done, give him a lollipop.", "tokens": [51474, 787, 584, 437, 286, 3172, 1096, 11, 976, 796, 257, 450, 285, 647, 404, 13, 51724], "temperature": 0.0, "avg_logprob": -0.20593579610188803, "compression_ratio": 1.5323383084577114, "no_speech_prob": 0.0028441522736102343}, {"id": 56, "seek": 36832, "start": 368.52, "end": 375.52, "text": " I understand his philosophy or why he said that, but if someone wants to just type something", "tokens": [50374, 286, 1223, 702, 10675, 420, 983, 415, 848, 300, 11, 457, 498, 1580, 2738, 281, 445, 2010, 746, 50724], "temperature": 0.0, "avg_logprob": -0.12176283200581868, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.00030049867928028107}, {"id": 57, "seek": 36832, "start": 379.92, "end": 386.21999999999997, "text": " in sort of naively, I think we should give him or her a lollipop, but we should also", "tokens": [50944, 294, 1333, 295, 1667, 3413, 11, 286, 519, 321, 820, 976, 796, 420, 720, 257, 450, 285, 647, 404, 11, 457, 321, 820, 611, 51259], "temperature": 0.0, "avg_logprob": -0.12176283200581868, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.00030049867928028107}, {"id": 58, "seek": 36832, "start": 386.21999999999997, "end": 393.21999999999997, "text": " give them what they ask for. If you think of it that way, what I really want to do is", "tokens": [51259, 976, 552, 437, 436, 1029, 337, 13, 759, 291, 519, 295, 309, 300, 636, 11, 437, 286, 534, 528, 281, 360, 307, 51609], "temperature": 0.0, "avg_logprob": -0.12176283200581868, "compression_ratio": 1.5562130177514792, "no_speech_prob": 0.00030049867928028107}, {"id": 59, "seek": 39322, "start": 394.02000000000004, "end": 400.02000000000004, "text": " lollipop-driven development. Rich Hickey has this idea of hammock-driven development,", "tokens": [50404, 450, 285, 647, 404, 12, 25456, 3250, 13, 6781, 389, 299, 4119, 575, 341, 1558, 295, 36600, 1560, 12, 25456, 3250, 11, 50704], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 60, "seek": 39322, "start": 400.02000000000004, "end": 405.02000000000004, "text": " which is fine, but I prefer lollipop-driven development. I want to just be able to say", "tokens": [50704, 597, 307, 2489, 11, 457, 286, 4382, 450, 285, 647, 404, 12, 25456, 3250, 13, 286, 528, 281, 445, 312, 1075, 281, 584, 50954], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 61, "seek": 39322, "start": 405.02000000000004, "end": 408.02000000000004, "text": " what should happen and just have it happen.", "tokens": [50954, 437, 820, 1051, 293, 445, 362, 309, 1051, 13, 51104], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 62, "seek": 39322, "start": 408.02000000000004, "end": 410.02000000000004, "text": " I think it's milkshake-driven.", "tokens": [51104, 286, 519, 309, 311, 48773, 34593, 12, 25456, 13, 51204], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 63, "seek": 39322, "start": 410.02000000000004, "end": 415.58000000000004, "text": " Milkshake-driven development, yes. Going back to Guy's keynote last night, he showed", "tokens": [51204, 7036, 1694, 34593, 12, 25456, 3250, 11, 2086, 13, 10963, 646, 281, 14690, 311, 33896, 1036, 1818, 11, 415, 4712, 51482], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 64, "seek": 39322, "start": 415.58000000000004, "end": 422.58000000000004, "text": " inference rules, typing judgments, context-free grammars, BNF, all these sorts of things.", "tokens": [51482, 38253, 4474, 11, 18444, 40337, 11, 4319, 12, 10792, 17570, 685, 11, 363, 45, 37, 11, 439, 613, 7527, 295, 721, 13, 51832], "temperature": 0.0, "avg_logprob": -0.16101719161211434, "compression_ratio": 1.7016129032258065, "no_speech_prob": 0.006094058509916067}, {"id": 65, "seek": 42322, "start": 423.74, "end": 430.34000000000003, "text": " When I went to Indiana, really what Dan was trying to do at the time, which took a while", "tokens": [50390, 1133, 286, 1437, 281, 21858, 11, 534, 437, 3394, 390, 1382, 281, 360, 412, 264, 565, 11, 597, 1890, 257, 1339, 50720], "temperature": 0.0, "avg_logprob": -0.13071887758043077, "compression_ratio": 1.609865470852018, "no_speech_prob": 7.029997505014762e-05}, {"id": 66, "seek": 42322, "start": 430.34000000000003, "end": 436.3, "text": " for me to understand, was he wanted a way to write these sorts of rules down, make them", "tokens": [50720, 337, 385, 281, 1223, 11, 390, 415, 1415, 257, 636, 281, 2464, 613, 7527, 295, 4474, 760, 11, 652, 552, 51018], "temperature": 0.0, "avg_logprob": -0.13071887758043077, "compression_ratio": 1.609865470852018, "no_speech_prob": 7.029997505014762e-05}, {"id": 67, "seek": 42322, "start": 436.3, "end": 443.3, "text": " executable, and be able to explore the resulting system. That's really what he was interested", "tokens": [51018, 7568, 712, 11, 293, 312, 1075, 281, 6839, 264, 16505, 1185, 13, 663, 311, 534, 437, 415, 390, 3102, 51368], "temperature": 0.0, "avg_logprob": -0.13071887758043077, "compression_ratio": 1.609865470852018, "no_speech_prob": 7.029997505014762e-05}, {"id": 68, "seek": 42322, "start": 443.38000000000005, "end": 450.38000000000005, "text": " in. Anyway, we want some way to explore this. Going back to Guy's naming of the informal", "tokens": [51372, 294, 13, 5684, 11, 321, 528, 512, 636, 281, 6839, 341, 13, 10963, 646, 281, 14690, 311, 25290, 295, 264, 24342, 51722], "temperature": 0.0, "avg_logprob": -0.13071887758043077, "compression_ratio": 1.609865470852018, "no_speech_prob": 7.029997505014762e-05}, {"id": 69, "seek": 45322, "start": 453.26000000000005, "end": 459.86, "text": " language use, computer science meta notation, basically we want to have an executable relational", "tokens": [50366, 2856, 764, 11, 3820, 3497, 19616, 24657, 11, 1936, 321, 528, 281, 362, 364, 7568, 712, 38444, 50696], "temperature": 0.0, "avg_logprob": -0.18089359147208078, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00040441800956614316}, {"id": 70, "seek": 45322, "start": 459.86, "end": 466.86, "text": " version of computer science meta notation. Just one other source of inspiration for the", "tokens": [50696, 3037, 295, 3820, 3497, 19616, 24657, 13, 1449, 472, 661, 4009, 295, 10249, 337, 264, 51046], "temperature": 0.0, "avg_logprob": -0.18089359147208078, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00040441800956614316}, {"id": 71, "seek": 45322, "start": 468.22, "end": 474.42, "text": " Commodore Amiga, which was my third computer, I think. There was a fantastic program for", "tokens": [51114, 3046, 34239, 2012, 9900, 11, 597, 390, 452, 2636, 3820, 11, 286, 519, 13, 821, 390, 257, 5456, 1461, 337, 51424], "temperature": 0.0, "avg_logprob": -0.18089359147208078, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00040441800956614316}, {"id": 72, "seek": 45322, "start": 474.42, "end": 481.42, "text": " it called Doug's Math Aquarium. I love this program. You can see, this was on the September", "tokens": [51424, 309, 1219, 12742, 311, 15776, 8728, 19612, 13, 286, 959, 341, 1461, 13, 509, 393, 536, 11, 341, 390, 322, 264, 7216, 51774], "temperature": 0.0, "avg_logprob": -0.18089359147208078, "compression_ratio": 1.6008771929824561, "no_speech_prob": 0.00040441800956614316}, {"id": 73, "seek": 48142, "start": 482.42, "end": 489.42, "text": " 87 issue of Info. You can see on the lower left the image again. You can do Manobrot,", "tokens": [50414, 27990, 2734, 295, 11537, 78, 13, 509, 393, 536, 322, 264, 3126, 1411, 264, 3256, 797, 13, 509, 393, 360, 2458, 996, 10536, 11, 50764], "temperature": 0.0, "avg_logprob": -0.24274889628092447, "compression_ratio": 1.7370517928286853, "no_speech_prob": 0.0008294186554849148}, {"id": 74, "seek": 48142, "start": 490.02000000000004, "end": 494.86, "text": " plus you can do wireframe. There are a whole bunch of ways you could visualize mathematics.", "tokens": [50794, 1804, 291, 393, 360, 6234, 17265, 13, 821, 366, 257, 1379, 3840, 295, 2098, 291, 727, 23273, 18666, 13, 51036], "temperature": 0.0, "avg_logprob": -0.24274889628092447, "compression_ratio": 1.7370517928286853, "no_speech_prob": 0.0008294186554849148}, {"id": 75, "seek": 48142, "start": 494.86, "end": 498.54, "text": " The way it would work is like, hey, I want to zoom in on Manobrot's set. The computer", "tokens": [51036, 440, 636, 309, 576, 589, 307, 411, 11, 4177, 11, 286, 528, 281, 8863, 294, 322, 2458, 996, 10536, 311, 992, 13, 440, 3820, 51220], "temperature": 0.0, "avg_logprob": -0.24274889628092447, "compression_ratio": 1.7370517928286853, "no_speech_prob": 0.0008294186554849148}, {"id": 76, "seek": 48142, "start": 498.54, "end": 502.74, "text": " was so slow, and the software was so slow, you would hit return, and you would see it", "tokens": [51220, 390, 370, 2964, 11, 293, 264, 4722, 390, 370, 2964, 11, 291, 576, 2045, 2736, 11, 293, 291, 576, 536, 309, 51430], "temperature": 0.0, "avg_logprob": -0.24274889628092447, "compression_ratio": 1.7370517928286853, "no_speech_prob": 0.0008294186554849148}, {"id": 77, "seek": 48142, "start": 502.74, "end": 507.54, "text": " draw each pixel. Then you would go away, and eight hours later, you would see a little", "tokens": [51430, 2642, 1184, 19261, 13, 1396, 291, 576, 352, 1314, 11, 293, 3180, 2496, 1780, 11, 291, 576, 536, 257, 707, 51670], "temperature": 0.0, "avg_logprob": -0.24274889628092447, "compression_ratio": 1.7370517928286853, "no_speech_prob": 0.0008294186554849148}, {"id": 78, "seek": 50754, "start": 507.54, "end": 512.02, "text": " bit of the Manobrot set. But it was still amazing. It was still incredibly inspiring", "tokens": [50364, 857, 295, 264, 2458, 996, 10536, 992, 13, 583, 309, 390, 920, 2243, 13, 467, 390, 920, 6252, 15883, 50588], "temperature": 0.0, "avg_logprob": -0.1448948166587136, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0028887067455798388}, {"id": 79, "seek": 50754, "start": 512.02, "end": 519.02, "text": " to me. What I want is a computer science meta notation aquarium, just like the math aquarium.", "tokens": [50588, 281, 385, 13, 708, 286, 528, 307, 257, 3820, 3497, 19616, 24657, 30149, 11, 445, 411, 264, 5221, 30149, 13, 50938], "temperature": 0.0, "avg_logprob": -0.1448948166587136, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0028887067455798388}, {"id": 80, "seek": 50754, "start": 521.3000000000001, "end": 526.78, "text": " Even if it's slow, and even it's awkward to use, just being able to explore and play", "tokens": [51052, 2754, 498, 309, 311, 2964, 11, 293, 754, 309, 311, 11411, 281, 764, 11, 445, 885, 1075, 281, 6839, 293, 862, 51326], "temperature": 0.0, "avg_logprob": -0.1448948166587136, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0028887067455798388}, {"id": 81, "seek": 50754, "start": 526.78, "end": 532.02, "text": " around with it to me would be far, far better than just writing interpreters the standard", "tokens": [51326, 926, 365, 309, 281, 385, 576, 312, 1400, 11, 1400, 1101, 813, 445, 3579, 17489, 1559, 264, 3832, 51588], "temperature": 0.0, "avg_logprob": -0.1448948166587136, "compression_ratio": 1.5619469026548674, "no_speech_prob": 0.0028887067455798388}, {"id": 82, "seek": 53202, "start": 532.02, "end": 539.02, "text": " way. That's really what we're trying to do, I'd say. I'm going to not teach you the", "tokens": [50364, 636, 13, 663, 311, 534, 437, 321, 434, 1382, 281, 360, 11, 286, 1116, 584, 13, 286, 478, 516, 281, 406, 2924, 291, 264, 50714], "temperature": 0.0, "avg_logprob": -0.18522343193132854, "compression_ratio": 1.698019801980198, "no_speech_prob": 0.001699972664937377}, {"id": 83, "seek": 53202, "start": 542.9, "end": 546.9399999999999, "text": " mini-canon language, and I'm not going to teach you how it's implemented. We actually", "tokens": [50908, 8382, 12, 7035, 266, 2856, 11, 293, 286, 478, 406, 516, 281, 2924, 291, 577, 309, 311, 12270, 13, 492, 767, 51110], "temperature": 0.0, "avg_logprob": -0.18522343193132854, "compression_ratio": 1.698019801980198, "no_speech_prob": 0.001699972664937377}, {"id": 84, "seek": 53202, "start": 546.9399999999999, "end": 553.9399999999999, "text": " have lots of resources and talks and things like that about this, about mini-canon, and", "tokens": [51110, 362, 3195, 295, 3593, 293, 6686, 293, 721, 411, 300, 466, 341, 11, 466, 8382, 12, 7035, 266, 11, 293, 51460], "temperature": 0.0, "avg_logprob": -0.18522343193132854, "compression_ratio": 1.698019801980198, "no_speech_prob": 0.001699972664937377}, {"id": 85, "seek": 53202, "start": 555.1, "end": 560.38, "text": " how to use it, and how to write mini-canon programs. To really do it right would take", "tokens": [51518, 577, 281, 764, 309, 11, 293, 577, 281, 2464, 8382, 12, 7035, 266, 4268, 13, 1407, 534, 360, 309, 558, 576, 747, 51782], "temperature": 0.0, "avg_logprob": -0.18522343193132854, "compression_ratio": 1.698019801980198, "no_speech_prob": 0.001699972664937377}, {"id": 86, "seek": 56038, "start": 560.42, "end": 565.14, "text": " far more time than I have, but I just want to show you maybe a couple of examples of", "tokens": [50366, 1400, 544, 565, 813, 286, 362, 11, 457, 286, 445, 528, 281, 855, 291, 1310, 257, 1916, 295, 5110, 295, 50602], "temperature": 0.0, "avg_logprob": -0.2722090336314419, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.00043047507642768323}, {"id": 87, "seek": 56038, "start": 565.14, "end": 572.14, "text": " what the rules look like. This is a type inferencer for the simply typed lambda calculus on the", "tokens": [50602, 437, 264, 4474, 574, 411, 13, 639, 307, 257, 2010, 13596, 16542, 337, 264, 2935, 33941, 13607, 33400, 322, 264, 50952], "temperature": 0.0, "avg_logprob": -0.2722090336314419, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.00043047507642768323}, {"id": 88, "seek": 56038, "start": 572.66, "end": 579.66, "text": " left, how we would write it with the computer science meta notation. Was that right, CSM?", "tokens": [50978, 1411, 11, 577, 321, 576, 2464, 309, 365, 264, 3820, 3497, 19616, 24657, 13, 3027, 300, 558, 11, 9460, 44, 30, 51328], "temperature": 0.0, "avg_logprob": -0.2722090336314419, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.00043047507642768323}, {"id": 89, "seek": 56038, "start": 580.02, "end": 583.82, "text": " Computer science meta notation. That's how we might write it on the left. Then on the", "tokens": [51346, 22289, 3497, 19616, 24657, 13, 663, 311, 577, 321, 1062, 2464, 309, 322, 264, 1411, 13, 1396, 322, 264, 51536], "temperature": 0.0, "avg_logprob": -0.2722090336314419, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.00043047507642768323}, {"id": 90, "seek": 56038, "start": 583.82, "end": 590.32, "text": " right is how you might write it in mini-canon using a macro called matchup, and then on", "tokens": [51536, 558, 307, 577, 291, 1062, 2464, 309, 294, 8382, 12, 7035, 266, 1228, 257, 18887, 1219, 2995, 1010, 11, 293, 550, 322, 51861], "temperature": 0.0, "avg_logprob": -0.2722090336314419, "compression_ratio": 1.727626459143969, "no_speech_prob": 0.00043047507642768323}, {"id": 91, "seek": 59032, "start": 590.36, "end": 595.96, "text": " the right is a little higher level syntax than what we normally use. You can see it's", "tokens": [50366, 264, 558, 307, 257, 707, 2946, 1496, 28431, 813, 437, 321, 5646, 764, 13, 509, 393, 536, 309, 311, 50646], "temperature": 0.0, "avg_logprob": -0.26517921619200974, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037989692646078765}, {"id": 92, "seek": 59032, "start": 595.96, "end": 602.96, "text": " roughly the same. It's still awkward. It's not the greatest notation, but you can see", "tokens": [50646, 9810, 264, 912, 13, 467, 311, 920, 11411, 13, 467, 311, 406, 264, 6636, 24657, 11, 457, 291, 393, 536, 50996], "temperature": 0.0, "avg_logprob": -0.26517921619200974, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037989692646078765}, {"id": 93, "seek": 59032, "start": 603.72, "end": 610.5200000000001, "text": " it's not 100 times longer or 10 times longer or whatever. Here we have something similar", "tokens": [51034, 309, 311, 406, 2319, 1413, 2854, 420, 1266, 1413, 2854, 420, 2035, 13, 1692, 321, 362, 746, 2531, 51374], "temperature": 0.0, "avg_logprob": -0.26517921619200974, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037989692646078765}, {"id": 94, "seek": 59032, "start": 610.5200000000001, "end": 616.72, "text": " for commentatory logic. We have another meta notation, and on the right is the mini-canon,", "tokens": [51374, 337, 2871, 4745, 9952, 13, 492, 362, 1071, 19616, 24657, 11, 293, 322, 264, 558, 307, 264, 8382, 12, 7035, 266, 11, 51684], "temperature": 0.0, "avg_logprob": -0.26517921619200974, "compression_ratio": 1.6635071090047393, "no_speech_prob": 0.00037989692646078765}, {"id": 95, "seek": 61672, "start": 616.74, "end": 622.9200000000001, "text": " and that's roughly the same length. Here is the program that we're going to play with", "tokens": [50365, 293, 300, 311, 9810, 264, 912, 4641, 13, 1692, 307, 264, 1461, 300, 321, 434, 516, 281, 862, 365, 50674], "temperature": 0.0, "avg_logprob": -0.1466724617967328, "compression_ratio": 1.647940074906367, "no_speech_prob": 0.00013550781295634806}, {"id": 96, "seek": 61672, "start": 622.9200000000001, "end": 628.44, "text": " today in Explorer. This is an environment passing interpreter for a subset of scheme", "tokens": [50674, 965, 294, 31895, 13, 639, 307, 364, 2823, 8437, 34132, 337, 257, 25993, 295, 12232, 50950], "temperature": 0.0, "avg_logprob": -0.1466724617967328, "compression_ratio": 1.647940074906367, "no_speech_prob": 0.00013550781295634806}, {"id": 97, "seek": 61672, "start": 628.44, "end": 635.44, "text": " or a subset of racket. If you know the rules, this is procedure application, this is abstraction", "tokens": [50950, 420, 257, 25993, 295, 41130, 13, 759, 291, 458, 264, 4474, 11, 341, 307, 10747, 3861, 11, 341, 307, 37765, 51300], "temperature": 0.0, "avg_logprob": -0.1466724617967328, "compression_ratio": 1.647940074906367, "no_speech_prob": 0.00013550781295634806}, {"id": 98, "seek": 61672, "start": 635.8000000000001, "end": 641.0400000000001, "text": " or lambda, that's variable reference. Here we have lists. There we've got quote. We've", "tokens": [51318, 420, 13607, 11, 300, 311, 7006, 6408, 13, 1692, 321, 362, 14511, 13, 821, 321, 600, 658, 6513, 13, 492, 600, 51580], "temperature": 0.0, "avg_logprob": -0.1466724617967328, "compression_ratio": 1.647940074906367, "no_speech_prob": 0.00013550781295634806}, {"id": 99, "seek": 61672, "start": 641.0400000000001, "end": 644.6, "text": " actually added some other forms to various versions of the interpreter. I'll show you", "tokens": [51580, 767, 3869, 512, 661, 6422, 281, 3683, 9606, 295, 264, 34132, 13, 286, 603, 855, 291, 51758], "temperature": 0.0, "avg_logprob": -0.1466724617967328, "compression_ratio": 1.647940074906367, "no_speech_prob": 0.00013550781295634806}, {"id": 100, "seek": 64460, "start": 644.64, "end": 651.64, "text": " this version first. Then here on the right is the mini-canon code that corresponds to", "tokens": [50366, 341, 3037, 700, 13, 1396, 510, 322, 264, 558, 307, 264, 8382, 12, 7035, 266, 3089, 300, 23249, 281, 50716], "temperature": 0.0, "avg_logprob": -0.1566372997355911, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00036824916605837643}, {"id": 101, "seek": 64460, "start": 651.64, "end": 658.64, "text": " it. Then we also have to have some extra code for doing things like environment lookup", "tokens": [50716, 309, 13, 1396, 321, 611, 362, 281, 362, 512, 2857, 3089, 337, 884, 721, 411, 2823, 574, 1010, 51066], "temperature": 0.0, "avg_logprob": -0.1566372997355911, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00036824916605837643}, {"id": 102, "seek": 64460, "start": 658.84, "end": 662.44, "text": " and some side conditions where in the math when you write it down, you don't have to", "tokens": [51076, 293, 512, 1252, 4487, 689, 294, 264, 5221, 562, 291, 2464, 309, 760, 11, 291, 500, 380, 362, 281, 51256], "temperature": 0.0, "avg_logprob": -0.1566372997355911, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00036824916605837643}, {"id": 103, "seek": 64460, "start": 662.44, "end": 668.84, "text": " worry about it as much. Anyway, the point is we can write something that doesn't really", "tokens": [51256, 3292, 466, 309, 382, 709, 13, 5684, 11, 264, 935, 307, 321, 393, 2464, 746, 300, 1177, 380, 534, 51576], "temperature": 0.0, "avg_logprob": -0.1566372997355911, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00036824916605837643}, {"id": 104, "seek": 64460, "start": 668.84, "end": 674.0400000000001, "text": " look like the notation. It would be very nice to have something much closer to the notation,", "tokens": [51576, 574, 411, 264, 24657, 13, 467, 576, 312, 588, 1481, 281, 362, 746, 709, 4966, 281, 264, 24657, 11, 51836], "temperature": 0.0, "avg_logprob": -0.1566372997355911, "compression_ratio": 1.7380952380952381, "no_speech_prob": 0.00036824916605837643}, {"id": 105, "seek": 67404, "start": 674.0799999999999, "end": 680.28, "text": " and it's roughly the same length or maybe twice as long or something like that. We're", "tokens": [50366, 293, 309, 311, 9810, 264, 912, 4641, 420, 1310, 6091, 382, 938, 420, 746, 411, 300, 13, 492, 434, 50676], "temperature": 0.0, "avg_logprob": -0.17219921112060546, "compression_ratio": 1.8823529411764706, "no_speech_prob": 7.252966315718368e-05}, {"id": 106, "seek": 67404, "start": 680.28, "end": 687.04, "text": " going to assume that we've already implemented an environment passing interpreter in mini-canon,", "tokens": [50676, 516, 281, 6552, 300, 321, 600, 1217, 12270, 364, 2823, 8437, 34132, 294, 8382, 12, 7035, 266, 11, 51014], "temperature": 0.0, "avg_logprob": -0.17219921112060546, "compression_ratio": 1.8823529411764706, "no_speech_prob": 7.252966315718368e-05}, {"id": 107, "seek": 67404, "start": 687.04, "end": 693.4, "text": " and we've already implemented mini-canon. Mini-canon is a language that is sort of a", "tokens": [51014, 293, 321, 600, 1217, 12270, 8382, 12, 7035, 266, 13, 18239, 12, 7035, 266, 307, 257, 2856, 300, 307, 1333, 295, 257, 51332], "temperature": 0.0, "avg_logprob": -0.17219921112060546, "compression_ratio": 1.8823529411764706, "no_speech_prob": 7.252966315718368e-05}, {"id": 108, "seek": 67404, "start": 693.4, "end": 698.64, "text": " combination of logic programming and constraint programming. This is basically a constraint", "tokens": [51332, 6562, 295, 9952, 9410, 293, 25534, 9410, 13, 639, 307, 1936, 257, 25534, 51594], "temperature": 0.0, "avg_logprob": -0.17219921112060546, "compression_ratio": 1.8823529411764706, "no_speech_prob": 7.252966315718368e-05}, {"id": 109, "seek": 67404, "start": 698.64, "end": 703.24, "text": " logic programming language. It's a mixture of constraints and logic programming. I heard", "tokens": [51594, 9952, 9410, 2856, 13, 467, 311, 257, 9925, 295, 18491, 293, 9952, 9410, 13, 286, 2198, 51824], "temperature": 0.0, "avg_logprob": -0.17219921112060546, "compression_ratio": 1.8823529411764706, "no_speech_prob": 7.252966315718368e-05}, {"id": 110, "seek": 70324, "start": 703.32, "end": 708.92, "text": " Peter Van Roy question last night to Guy, both logic programming and constraint programming", "tokens": [50368, 6508, 8979, 8751, 1168, 1036, 1818, 281, 14690, 11, 1293, 9952, 9410, 293, 25534, 9410, 50648], "temperature": 0.0, "avg_logprob": -0.16571919712019556, "compression_ratio": 1.6090909090909091, "no_speech_prob": 8.885677380021662e-05}, {"id": 111, "seek": 70324, "start": 708.92, "end": 714.8, "text": " came up. Basically, you can think of it as a language that's been optimized to write", "tokens": [50648, 1361, 493, 13, 8537, 11, 291, 393, 519, 295, 309, 382, 257, 2856, 300, 311, 668, 26941, 281, 2464, 50942], "temperature": 0.0, "avg_logprob": -0.16571919712019556, "compression_ratio": 1.6090909090909091, "no_speech_prob": 8.885677380021662e-05}, {"id": 112, "seek": 70324, "start": 714.8, "end": 718.76, "text": " rules like this, not necessarily in terms of the syntax, like how you write them down,", "tokens": [50942, 4474, 411, 341, 11, 406, 4725, 294, 2115, 295, 264, 28431, 11, 411, 577, 291, 2464, 552, 760, 11, 51140], "temperature": 0.0, "avg_logprob": -0.16571919712019556, "compression_ratio": 1.6090909090909091, "no_speech_prob": 8.885677380021662e-05}, {"id": 113, "seek": 70324, "start": 718.76, "end": 724.24, "text": " but more in terms of if you want to explore the resulting rules. The language is optimized", "tokens": [51140, 457, 544, 294, 2115, 295, 498, 291, 528, 281, 6839, 264, 16505, 4474, 13, 440, 2856, 307, 26941, 51414], "temperature": 0.0, "avg_logprob": -0.16571919712019556, "compression_ratio": 1.6090909090909091, "no_speech_prob": 8.885677380021662e-05}, {"id": 114, "seek": 72424, "start": 724.24, "end": 733.32, "text": " for that, and the implementation is optimized for that. Okay. Now is the most fun part. This", "tokens": [50364, 337, 300, 11, 293, 264, 11420, 307, 26941, 337, 300, 13, 1033, 13, 823, 307, 264, 881, 1019, 644, 13, 639, 50818], "temperature": 0.0, "avg_logprob": -0.24608228517615277, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0675189197063446}, {"id": 115, "seek": 72424, "start": 733.32, "end": 738.96, "text": " is always the part that scares me, loading a file. We haven't really solved the loading", "tokens": [50818, 307, 1009, 264, 644, 300, 35721, 385, 11, 15114, 257, 3991, 13, 492, 2378, 380, 534, 13041, 264, 15114, 51100], "temperature": 0.0, "avg_logprob": -0.24608228517615277, "compression_ratio": 1.3636363636363635, "no_speech_prob": 0.0675189197063446}, {"id": 116, "seek": 73896, "start": 739.0400000000001, "end": 747.0400000000001, "text": " the file part, but let me make sure I can do this. Oh, okay. Great. Let me see if I can do this one.", "tokens": [50368, 264, 3991, 644, 11, 457, 718, 385, 652, 988, 286, 393, 360, 341, 13, 876, 11, 1392, 13, 3769, 13, 961, 385, 536, 498, 286, 393, 360, 341, 472, 13, 50768], "temperature": 0.0, "avg_logprob": -0.3610591273153982, "compression_ratio": 1.455223880597015, "no_speech_prob": 0.035668447613716125}, {"id": 117, "seek": 73896, "start": 757.0400000000001, "end": 768.0400000000001, "text": " Good. All right. Okay. Can people see that? Is that big enough? Okay. Let me make sure we got,", "tokens": [51268, 2205, 13, 1057, 558, 13, 1033, 13, 1664, 561, 536, 300, 30, 1119, 300, 955, 1547, 30, 1033, 13, 961, 385, 652, 988, 321, 658, 11, 51818], "temperature": 0.0, "avg_logprob": -0.3610591273153982, "compression_ratio": 1.455223880597015, "no_speech_prob": 0.035668447613716125}, {"id": 118, "seek": 76804, "start": 768.12, "end": 776.12, "text": " great. Okay. So, show of hands, please. Who here can read Scheme, Racket, Closure, or", "tokens": [50368, 869, 13, 1033, 13, 407, 11, 855, 295, 2377, 11, 1767, 13, 2102, 510, 393, 1401, 2065, 5729, 11, 497, 501, 302, 11, 2033, 7641, 11, 420, 50768], "temperature": 0.0, "avg_logprob": -0.23611661499621822, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0007791675161570311}, {"id": 119, "seek": 76804, "start": 776.12, "end": 784.12, "text": " some other Lisp? At least a little bit. Emacs Lisp? Absolutely. Okay. So, most people,", "tokens": [50768, 512, 661, 441, 7631, 30, 1711, 1935, 257, 707, 857, 13, 3968, 44937, 441, 7631, 30, 7021, 13, 1033, 13, 407, 11, 881, 561, 11, 51168], "temperature": 0.0, "avg_logprob": -0.23611661499621822, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0007791675161570311}, {"id": 120, "seek": 76804, "start": 784.12, "end": 790.12, "text": " maybe not 100%. I think in the interest of time, I'm going to ask the people who aren't", "tokens": [51168, 1310, 406, 2319, 6856, 286, 519, 294, 264, 1179, 295, 565, 11, 286, 478, 516, 281, 1029, 264, 561, 567, 3212, 380, 51468], "temperature": 0.0, "avg_logprob": -0.23611661499621822, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0007791675161570311}, {"id": 121, "seek": 76804, "start": 790.12, "end": 795.36, "text": " as familiar with parentheses to please try to bear with me and try to think at the high", "tokens": [51468, 382, 4963, 365, 34153, 281, 1767, 853, 281, 6155, 365, 385, 293, 853, 281, 519, 412, 264, 1090, 51730], "temperature": 0.0, "avg_logprob": -0.23611661499621822, "compression_ratio": 1.519650655021834, "no_speech_prob": 0.0007791675161570311}, {"id": 122, "seek": 79536, "start": 795.44, "end": 801.28, "text": " level what we're trying to do. Okay. Just from the standpoint of time, I can't also teach you all", "tokens": [50368, 1496, 437, 321, 434, 1382, 281, 360, 13, 1033, 13, 1449, 490, 264, 15827, 295, 565, 11, 286, 393, 380, 611, 2924, 291, 439, 50660], "temperature": 0.0, "avg_logprob": -0.1526729368394421, "compression_ratio": 1.605351170568562, "no_speech_prob": 0.003943826537579298}, {"id": 123, "seek": 79536, "start": 801.28, "end": 806.72, "text": " of Scheme, unfortunately. Although I gave a talk at Papers We Love recently where I actually do", "tokens": [50660, 295, 2065, 5729, 11, 7015, 13, 5780, 286, 2729, 257, 751, 412, 430, 14441, 492, 5956, 3938, 689, 286, 767, 360, 50932], "temperature": 0.0, "avg_logprob": -0.1526729368394421, "compression_ratio": 1.605351170568562, "no_speech_prob": 0.003943826537579298}, {"id": 124, "seek": 79536, "start": 806.72, "end": 810.96, "text": " teach enough Scheme to do all the things we do, but I had an hour and a half then. So, if you", "tokens": [50932, 2924, 1547, 2065, 5729, 281, 360, 439, 264, 721, 321, 360, 11, 457, 286, 632, 364, 1773, 293, 257, 1922, 550, 13, 407, 11, 498, 291, 51144], "temperature": 0.0, "avg_logprob": -0.1526729368394421, "compression_ratio": 1.605351170568562, "no_speech_prob": 0.003943826537579298}, {"id": 125, "seek": 79536, "start": 810.96, "end": 816.4, "text": " look on YouTube, you can find papers we love to talk on called the most beautiful program ever", "tokens": [51144, 574, 322, 3088, 11, 291, 393, 915, 10577, 321, 959, 281, 751, 322, 1219, 264, 881, 2238, 1461, 1562, 51416], "temperature": 0.0, "avg_logprob": -0.1526729368394421, "compression_ratio": 1.605351170568562, "no_speech_prob": 0.003943826537579298}, {"id": 126, "seek": 79536, "start": 816.4, "end": 822.08, "text": " written where I talk about some of these topics. Okay. So, what I've loaded is an interpreter for", "tokens": [51416, 3720, 689, 286, 751, 466, 512, 295, 613, 8378, 13, 1033, 13, 407, 11, 437, 286, 600, 13210, 307, 364, 34132, 337, 51700], "temperature": 0.0, "avg_logprob": -0.1526729368394421, "compression_ratio": 1.605351170568562, "no_speech_prob": 0.003943826537579298}, {"id": 127, "seek": 82208, "start": 822.08, "end": 829.0400000000001, "text": " a subset of Scheme. And a language like Scheme, sort of like a language like Python, maybe,", "tokens": [50364, 257, 25993, 295, 2065, 5729, 13, 400, 257, 2856, 411, 2065, 5729, 11, 1333, 295, 411, 257, 2856, 411, 15329, 11, 1310, 11, 50712], "temperature": 0.0, "avg_logprob": -0.18300686630548216, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0012062655296176672}, {"id": 128, "seek": 82208, "start": 829.0400000000001, "end": 834.5600000000001, "text": " we have something called a vowel. So, a vowel is an evaluator. It can evaluate an expression,", "tokens": [50712, 321, 362, 746, 1219, 257, 29410, 13, 407, 11, 257, 29410, 307, 364, 6133, 1639, 13, 467, 393, 13059, 364, 6114, 11, 50988], "temperature": 0.0, "avg_logprob": -0.18300686630548216, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0012062655296176672}, {"id": 129, "seek": 82208, "start": 834.5600000000001, "end": 844.5600000000001, "text": " which we quote. So, I could do plus 3, 5. And this expression, a Scheme uses a prefix notation.", "tokens": [50988, 597, 321, 6513, 13, 407, 11, 286, 727, 360, 1804, 805, 11, 1025, 13, 400, 341, 6114, 11, 257, 2065, 5729, 4960, 257, 46969, 24657, 13, 51488], "temperature": 0.0, "avg_logprob": -0.18300686630548216, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0012062655296176672}, {"id": 130, "seek": 82208, "start": 844.5600000000001, "end": 851.2800000000001, "text": " We're adding 3 plus 5. That quote means that we're delaying evaluation. We're turning the", "tokens": [51488, 492, 434, 5127, 805, 1804, 1025, 13, 663, 6513, 1355, 300, 321, 434, 8577, 278, 13344, 13, 492, 434, 6246, 264, 51824], "temperature": 0.0, "avg_logprob": -0.18300686630548216, "compression_ratio": 1.6863636363636363, "no_speech_prob": 0.0012062655296176672}, {"id": 131, "seek": 85128, "start": 851.28, "end": 859.6, "text": " plus 3, 5. We're treating that as a list of data instead of as a procedure call. So, you can see", "tokens": [50364, 1804, 805, 11, 1025, 13, 492, 434, 15083, 300, 382, 257, 1329, 295, 1412, 2602, 295, 382, 257, 10747, 818, 13, 407, 11, 291, 393, 536, 50780], "temperature": 0.0, "avg_logprob": -0.08039958926214688, "compression_ratio": 1.8932806324110671, "no_speech_prob": 3.120110704912804e-05}, {"id": 132, "seek": 85128, "start": 859.6, "end": 864.16, "text": " the difference. If I put the quote mark, we get back the list. If I don't put the quote mark,", "tokens": [50780, 264, 2649, 13, 759, 286, 829, 264, 6513, 1491, 11, 321, 483, 646, 264, 1329, 13, 759, 286, 500, 380, 829, 264, 6513, 1491, 11, 51008], "temperature": 0.0, "avg_logprob": -0.08039958926214688, "compression_ratio": 1.8932806324110671, "no_speech_prob": 3.120110704912804e-05}, {"id": 133, "seek": 85128, "start": 864.16, "end": 869.12, "text": " it evaluates immediately, we get back 8. Okay. So, a vowel sort of cancels out the quote mark,", "tokens": [51008, 309, 6133, 1024, 4258, 11, 321, 483, 646, 1649, 13, 1033, 13, 407, 11, 257, 29410, 1333, 295, 393, 66, 1625, 484, 264, 6513, 1491, 11, 51256], "temperature": 0.0, "avg_logprob": -0.08039958926214688, "compression_ratio": 1.8932806324110671, "no_speech_prob": 3.120110704912804e-05}, {"id": 134, "seek": 85128, "start": 869.12, "end": 873.12, "text": " if you want to think of it that way. We're taking this list and we're going to evaluate it. So,", "tokens": [51256, 498, 291, 528, 281, 519, 295, 309, 300, 636, 13, 492, 434, 1940, 341, 1329, 293, 321, 434, 516, 281, 13059, 309, 13, 407, 11, 51456], "temperature": 0.0, "avg_logprob": -0.08039958926214688, "compression_ratio": 1.8932806324110671, "no_speech_prob": 3.120110704912804e-05}, {"id": 135, "seek": 85128, "start": 873.12, "end": 879.04, "text": " we're going to look at the parts of the list and do some evaluation procedure. Okay. So, that's a", "tokens": [51456, 321, 434, 516, 281, 574, 412, 264, 3166, 295, 264, 1329, 293, 360, 512, 13344, 10747, 13, 1033, 13, 407, 11, 300, 311, 257, 51752], "temperature": 0.0, "avg_logprob": -0.08039958926214688, "compression_ratio": 1.8932806324110671, "no_speech_prob": 3.120110704912804e-05}, {"id": 136, "seek": 87904, "start": 879.04, "end": 885.92, "text": " vowel and Scheme. What we're going to do is use something called a vowel. So, a vowel is the", "tokens": [50364, 29410, 293, 2065, 5729, 13, 708, 321, 434, 516, 281, 360, 307, 764, 746, 1219, 257, 29410, 13, 407, 11, 257, 29410, 307, 264, 50708], "temperature": 0.0, "avg_logprob": -0.11399660031657574, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.00020341596973594278}, {"id": 137, "seek": 87904, "start": 885.92, "end": 892.4, "text": " relational version of the vowel function. So, the vowel function takes one argument, which is", "tokens": [50708, 38444, 3037, 295, 264, 29410, 2445, 13, 407, 11, 264, 29410, 2445, 2516, 472, 6770, 11, 597, 307, 51032], "temperature": 0.0, "avg_logprob": -0.11399660031657574, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.00020341596973594278}, {"id": 138, "seek": 87904, "start": 892.4, "end": 896.3199999999999, "text": " going to be a Scheme expression, as quoted, evaluates that and gives us back the value.", "tokens": [51032, 516, 281, 312, 257, 2065, 5729, 6114, 11, 382, 30047, 11, 6133, 1024, 300, 293, 2709, 505, 646, 264, 2158, 13, 51228], "temperature": 0.0, "avg_logprob": -0.11399660031657574, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.00020341596973594278}, {"id": 139, "seek": 87904, "start": 896.88, "end": 901.52, "text": " The vowel, however, is going to take two arguments instead of one. It's going to take an expression", "tokens": [51256, 440, 29410, 11, 4461, 11, 307, 516, 281, 747, 732, 12869, 2602, 295, 472, 13, 467, 311, 516, 281, 747, 364, 6114, 51488], "temperature": 0.0, "avg_logprob": -0.11399660031657574, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.00020341596973594278}, {"id": 140, "seek": 87904, "start": 901.52, "end": 906.9599999999999, "text": " as the first argument and it's going to take a value as the second argument. So, let's try using a", "tokens": [51488, 382, 264, 700, 6770, 293, 309, 311, 516, 281, 747, 257, 2158, 382, 264, 1150, 6770, 13, 407, 11, 718, 311, 853, 1228, 257, 51760], "temperature": 0.0, "avg_logprob": -0.11399660031657574, "compression_ratio": 1.962655601659751, "no_speech_prob": 0.00020341596973594278}, {"id": 141, "seek": 90696, "start": 906.96, "end": 930.48, "text": " vowel. Okay. Great. So, it's working. All right. How about I do something simple like", "tokens": [50364, 29410, 13, 1033, 13, 3769, 13, 407, 11, 309, 311, 1364, 13, 1057, 558, 13, 1012, 466, 286, 360, 746, 2199, 411, 51540], "temperature": 0.0, "avg_logprob": -0.21167844992417556, "compression_ratio": 0.9883720930232558, "no_speech_prob": 0.008441836573183537}, {"id": 142, "seek": 93048, "start": 931.04, "end": 940.96, "text": " I think this will work. Oh, yeah. Okay. So, for the people who don't know Scheme,", "tokens": [50392, 286, 519, 341, 486, 589, 13, 876, 11, 1338, 13, 1033, 13, 407, 11, 337, 264, 561, 567, 500, 380, 458, 2065, 5729, 11, 50888], "temperature": 0.0, "avg_logprob": -0.1502231798673931, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.0007320741424337029}, {"id": 143, "seek": 93048, "start": 942.72, "end": 949.76, "text": " Lisp stands for list processing. So, the list is a very common data structure we use. So,", "tokens": [50976, 441, 7631, 7382, 337, 1329, 9007, 13, 407, 11, 264, 1329, 307, 257, 588, 2689, 1412, 3877, 321, 764, 13, 407, 11, 51328], "temperature": 0.0, "avg_logprob": -0.1502231798673931, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.0007320741424337029}, {"id": 144, "seek": 93048, "start": 949.76, "end": 956.16, "text": " list 3, 4 creates a list containing 3 and 4. What I just did with this run expression is I", "tokens": [51328, 1329, 805, 11, 1017, 7829, 257, 1329, 19273, 805, 293, 1017, 13, 708, 286, 445, 630, 365, 341, 1190, 6114, 307, 286, 51648], "temperature": 0.0, "avg_logprob": -0.1502231798673931, "compression_ratio": 1.4162162162162162, "no_speech_prob": 0.0007320741424337029}, {"id": 145, "seek": 95616, "start": 956.16, "end": 963.36, "text": " called a vowel, which is my relational evaluator. And the quoted expression is list 3, 4, just like", "tokens": [50364, 1219, 257, 29410, 11, 597, 307, 452, 38444, 6133, 1639, 13, 400, 264, 30047, 6114, 307, 1329, 805, 11, 1017, 11, 445, 411, 50724], "temperature": 0.0, "avg_logprob": -0.09628477096557617, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.000626260123681277}, {"id": 146, "seek": 95616, "start": 963.36, "end": 969.04, "text": " I typed directly in the Scheme. So, that's the expression. The first part of the first argument", "tokens": [50724, 286, 33941, 3838, 294, 264, 2065, 5729, 13, 407, 11, 300, 311, 264, 6114, 13, 440, 700, 644, 295, 264, 700, 6770, 51008], "temperature": 0.0, "avg_logprob": -0.09628477096557617, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.000626260123681277}, {"id": 147, "seek": 95616, "start": 969.04, "end": 974.9599999999999, "text": " to a vowel is the expression I want to evaluate. Q is a query variable. You can say I introduce it", "tokens": [51008, 281, 257, 29410, 307, 264, 6114, 286, 528, 281, 13059, 13, 1249, 307, 257, 14581, 7006, 13, 509, 393, 584, 286, 5366, 309, 51304], "temperature": 0.0, "avg_logprob": -0.09628477096557617, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.000626260123681277}, {"id": 148, "seek": 95616, "start": 974.9599999999999, "end": 981.52, "text": " right after the run one in parentheses. Q is my query variable. And I'm putting Q in the place", "tokens": [51304, 558, 934, 264, 1190, 472, 294, 34153, 13, 1249, 307, 452, 14581, 7006, 13, 400, 286, 478, 3372, 1249, 294, 264, 1081, 51632], "temperature": 0.0, "avg_logprob": -0.09628477096557617, "compression_ratio": 1.641350210970464, "no_speech_prob": 0.000626260123681277}, {"id": 149, "seek": 98152, "start": 981.52, "end": 987.92, "text": " of the value. I'm saying that whatever a list 3, 4 evaluates to, bind that to the variable Q.", "tokens": [50364, 295, 264, 2158, 13, 286, 478, 1566, 300, 2035, 257, 1329, 805, 11, 1017, 6133, 1024, 281, 11, 14786, 300, 281, 264, 7006, 1249, 13, 50684], "temperature": 0.0, "avg_logprob": -0.10084195056204069, "compression_ratio": 1.8729508196721312, "no_speech_prob": 0.0030748797580599785}, {"id": 150, "seek": 98152, "start": 987.92, "end": 991.28, "text": " Okay. So, Q is a logic variable, query variable, whatever you want to call it,", "tokens": [50684, 1033, 13, 407, 11, 1249, 307, 257, 9952, 7006, 11, 14581, 7006, 11, 2035, 291, 528, 281, 818, 309, 11, 50852], "temperature": 0.0, "avg_logprob": -0.10084195056204069, "compression_ratio": 1.8729508196721312, "no_speech_prob": 0.0030748797580599785}, {"id": 151, "seek": 98152, "start": 991.92, "end": 998.4, "text": " unification variable. Run one, the one means that I want one answer back. Sometimes we can get", "tokens": [50884, 517, 3774, 7006, 13, 8950, 472, 11, 264, 472, 1355, 300, 286, 528, 472, 1867, 646, 13, 4803, 321, 393, 483, 51208], "temperature": 0.0, "avg_logprob": -0.10084195056204069, "compression_ratio": 1.8729508196721312, "no_speech_prob": 0.0030748797580599785}, {"id": 152, "seek": 98152, "start": 998.4, "end": 1002.48, "text": " more than one answer back. Sometimes we can get infinitely many answers back. And in fact, we", "tokens": [51208, 544, 813, 472, 1867, 646, 13, 4803, 321, 393, 483, 36227, 867, 6338, 646, 13, 400, 294, 1186, 11, 321, 51412], "temperature": 0.0, "avg_logprob": -0.10084195056204069, "compression_ratio": 1.8729508196721312, "no_speech_prob": 0.0030748797580599785}, {"id": 153, "seek": 98152, "start": 1002.48, "end": 1007.4399999999999, "text": " also might want to prove or show that there are only a finite number of answers, that there are", "tokens": [51412, 611, 1062, 528, 281, 7081, 420, 855, 300, 456, 366, 787, 257, 19362, 1230, 295, 6338, 11, 300, 456, 366, 51660], "temperature": 0.0, "avg_logprob": -0.10084195056204069, "compression_ratio": 1.8729508196721312, "no_speech_prob": 0.0030748797580599785}, {"id": 154, "seek": 100744, "start": 1007.44, "end": 1013.6, "text": " only five answers that exist. Run is our interface operator between Scheme and Minikanron. So,", "tokens": [50364, 787, 1732, 6338, 300, 2514, 13, 8950, 307, 527, 9226, 12973, 1296, 2065, 5729, 293, 2829, 16048, 2044, 13, 407, 11, 50672], "temperature": 0.0, "avg_logprob": -0.11583567680196559, "compression_ratio": 1.728110599078341, "no_speech_prob": 9.027704800246283e-05}, {"id": 155, "seek": 100744, "start": 1013.6, "end": 1018.5600000000001, "text": " Minikanron is embedded in a host language, most implementations. This implementation,", "tokens": [50672, 2829, 16048, 2044, 307, 16741, 294, 257, 3975, 2856, 11, 881, 4445, 763, 13, 639, 11420, 11, 50920], "temperature": 0.0, "avg_logprob": -0.11583567680196559, "compression_ratio": 1.728110599078341, "no_speech_prob": 9.027704800246283e-05}, {"id": 156, "seek": 100744, "start": 1018.5600000000001, "end": 1023.6, "text": " Minikanron is embedded in Scheme. I'm running it in Shea Scheme. All right. So, that's the basic", "tokens": [50920, 2829, 16048, 2044, 307, 16741, 294, 2065, 5729, 13, 286, 478, 2614, 309, 294, 1240, 64, 2065, 5729, 13, 1057, 558, 13, 407, 11, 300, 311, 264, 3875, 51172], "temperature": 0.0, "avg_logprob": -0.11583567680196559, "compression_ratio": 1.728110599078341, "no_speech_prob": 9.027704800246283e-05}, {"id": 157, "seek": 100744, "start": 1023.6, "end": 1030.3200000000002, "text": " interface. The underlying language that we wrote a vowel in is quite simple. It basically extends", "tokens": [51172, 9226, 13, 440, 14217, 2856, 300, 321, 4114, 257, 29410, 294, 307, 1596, 2199, 13, 467, 1936, 26448, 51508], "temperature": 0.0, "avg_logprob": -0.11583567680196559, "compression_ratio": 1.728110599078341, "no_speech_prob": 9.027704800246283e-05}, {"id": 158, "seek": 103032, "start": 1030.3999999999999, "end": 1037.9199999999998, "text": " Scheme with three operators, core operators. And then we've got a couple extensions for helping", "tokens": [50368, 2065, 5729, 365, 1045, 19077, 11, 4965, 19077, 13, 400, 550, 321, 600, 658, 257, 1916, 25129, 337, 4315, 50744], "temperature": 0.0, "avg_logprob": -0.14452444646776336, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.001098533975891769}, {"id": 159, "seek": 103032, "start": 1037.9199999999998, "end": 1043.6, "text": " write interpreters and type in things like that. Okay. So, that's a vowel. And you can see that", "tokens": [50744, 2464, 17489, 1559, 293, 2010, 294, 721, 411, 300, 13, 1033, 13, 407, 11, 300, 311, 257, 29410, 13, 400, 291, 393, 536, 300, 51028], "temperature": 0.0, "avg_logprob": -0.14452444646776336, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.001098533975891769}, {"id": 160, "seek": 103032, "start": 1043.6, "end": 1049.4399999999998, "text": " we can write things like list 3, 4. Now, what's interesting is that a vowel is written as a", "tokens": [51028, 321, 393, 2464, 721, 411, 1329, 805, 11, 1017, 13, 823, 11, 437, 311, 1880, 307, 300, 257, 29410, 307, 3720, 382, 257, 51320], "temperature": 0.0, "avg_logprob": -0.14452444646776336, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.001098533975891769}, {"id": 161, "seek": 103032, "start": 1049.4399999999998, "end": 1057.2, "text": " relation. And so, Guy talked about this a little bit yesterday. But, you know, the interesting", "tokens": [51320, 9721, 13, 400, 370, 11, 14690, 2825, 466, 341, 257, 707, 857, 5186, 13, 583, 11, 291, 458, 11, 264, 1880, 51708], "temperature": 0.0, "avg_logprob": -0.14452444646776336, "compression_ratio": 1.6578947368421053, "no_speech_prob": 0.001098533975891769}, {"id": 162, "seek": 105720, "start": 1057.68, "end": 1067.2, "text": " thing about the rules, and in fact, I can show you the rules for interpreter, the interesting", "tokens": [50388, 551, 466, 264, 4474, 11, 293, 294, 1186, 11, 286, 393, 855, 291, 264, 4474, 337, 34132, 11, 264, 1880, 50864], "temperature": 0.0, "avg_logprob": -0.10231537951363458, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.0002233918203273788}, {"id": 163, "seek": 105720, "start": 1067.2, "end": 1076.24, "text": " thing about these sorts of rules is that they don't really have a direction. So, here is a paper", "tokens": [50864, 551, 466, 613, 7527, 295, 4474, 307, 300, 436, 500, 380, 534, 362, 257, 3513, 13, 407, 11, 510, 307, 257, 3035, 51316], "temperature": 0.0, "avg_logprob": -0.10231537951363458, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.0002233918203273788}, {"id": 164, "seek": 105720, "start": 1077.2, "end": 1086.0800000000002, "text": " that was an ICFP in Oxford this year. And in this paper, you can see these rules written as", "tokens": [51364, 300, 390, 364, 14360, 45882, 294, 24786, 341, 1064, 13, 400, 294, 341, 3035, 11, 291, 393, 536, 613, 4474, 3720, 382, 51808], "temperature": 0.0, "avg_logprob": -0.10231537951363458, "compression_ratio": 1.6114285714285714, "no_speech_prob": 0.0002233918203273788}, {"id": 165, "seek": 108608, "start": 1086.08, "end": 1089.84, "text": " inference rules. And the code on the right, which is Minikanron. This is kind of lower-level", "tokens": [50364, 38253, 4474, 13, 400, 264, 3089, 322, 264, 558, 11, 597, 307, 2829, 16048, 2044, 13, 639, 307, 733, 295, 3126, 12, 12418, 50552], "temperature": 0.0, "avg_logprob": -0.10927581042051315, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.0008827617857605219}, {"id": 166, "seek": 108608, "start": 1089.84, "end": 1095.4399999999998, "text": " Minikanron, so it's a little longer. But the important thing is to realize that, you know,", "tokens": [50552, 2829, 16048, 2044, 11, 370, 309, 311, 257, 707, 2854, 13, 583, 264, 1021, 551, 307, 281, 4325, 300, 11, 291, 458, 11, 50832], "temperature": 0.0, "avg_logprob": -0.10927581042051315, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.0008827617857605219}, {"id": 167, "seek": 108608, "start": 1095.4399999999998, "end": 1103.04, "text": " there's this bar here, right, that Guy was talking about. And normally, the way we read it is we", "tokens": [50832, 456, 311, 341, 2159, 510, 11, 558, 11, 300, 14690, 390, 1417, 466, 13, 400, 5646, 11, 264, 636, 321, 1401, 309, 307, 321, 51212], "temperature": 0.0, "avg_logprob": -0.10927581042051315, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.0008827617857605219}, {"id": 168, "seek": 108608, "start": 1103.04, "end": 1108.8799999999999, "text": " have some antecedents, a consequence. So, we have some things that have to hold. And if these", "tokens": [51212, 362, 512, 23411, 1232, 791, 11, 257, 18326, 13, 407, 11, 321, 362, 512, 721, 300, 362, 281, 1797, 13, 400, 498, 613, 51504], "temperature": 0.0, "avg_logprob": -0.10927581042051315, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.0008827617857605219}, {"id": 169, "seek": 108608, "start": 1108.8799999999999, "end": 1115.36, "text": " three things hold, then we can infer the thing on the bottom. And we also sort of read it as,", "tokens": [51504, 1045, 721, 1797, 11, 550, 321, 393, 13596, 264, 551, 322, 264, 2767, 13, 400, 321, 611, 1333, 295, 1401, 309, 382, 11, 51828], "temperature": 0.0, "avg_logprob": -0.10927581042051315, "compression_ratio": 1.7205882352941178, "no_speech_prob": 0.0008827617857605219}, {"id": 170, "seek": 111536, "start": 1115.36, "end": 1121.12, "text": " okay, so this turnstile operator, we can read it as like an interpret or evaluate. So, in a", "tokens": [50364, 1392, 11, 370, 341, 1261, 372, 794, 12973, 11, 321, 393, 1401, 309, 382, 411, 364, 7302, 420, 13059, 13, 407, 11, 294, 257, 50652], "temperature": 0.0, "avg_logprob": -0.12216089617821478, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0001355019776383415}, {"id": 171, "seek": 111536, "start": 1121.12, "end": 1125.76, "text": " certain environment, row, this particular expression, which is a procedure application,", "tokens": [50652, 1629, 2823, 11, 5386, 11, 341, 1729, 6114, 11, 597, 307, 257, 10747, 3861, 11, 50884], "temperature": 0.0, "avg_logprob": -0.12216089617821478, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0001355019776383415}, {"id": 172, "seek": 111536, "start": 1125.76, "end": 1131.36, "text": " evaluates to the value v3. And the rules up top tell you what v3 is. So, if you're writing an", "tokens": [50884, 6133, 1024, 281, 264, 2158, 371, 18, 13, 400, 264, 4474, 493, 1192, 980, 291, 437, 371, 18, 307, 13, 407, 11, 498, 291, 434, 3579, 364, 51164], "temperature": 0.0, "avg_logprob": -0.12216089617821478, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0001355019776383415}, {"id": 173, "seek": 111536, "start": 1131.36, "end": 1137.6, "text": " interpreter in a standard way, you would read these rules as, okay, I'm going from left to right.", "tokens": [51164, 34132, 294, 257, 3832, 636, 11, 291, 576, 1401, 613, 4474, 382, 11, 1392, 11, 286, 478, 516, 490, 1411, 281, 558, 13, 51476], "temperature": 0.0, "avg_logprob": -0.12216089617821478, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0001355019776383415}, {"id": 174, "seek": 111536, "start": 1137.6, "end": 1142.3999999999999, "text": " Here's my expression. Here's my value. Notice there's an arrow instead of an equal sign. So,", "tokens": [51476, 1692, 311, 452, 6114, 13, 1692, 311, 452, 2158, 13, 13428, 456, 311, 364, 11610, 2602, 295, 364, 2681, 1465, 13, 407, 11, 51716], "temperature": 0.0, "avg_logprob": -0.12216089617821478, "compression_ratio": 1.7058823529411764, "no_speech_prob": 0.0001355019776383415}, {"id": 175, "seek": 114240, "start": 1142.4, "end": 1148.0800000000002, "text": " that's how you'd often think about it. But there's no reason that we have to go in any sort of", "tokens": [50364, 300, 311, 577, 291, 1116, 2049, 519, 466, 309, 13, 583, 456, 311, 572, 1778, 300, 321, 362, 281, 352, 294, 604, 1333, 295, 50648], "temperature": 0.0, "avg_logprob": -0.10246034029151212, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.00017399928765371442}, {"id": 176, "seek": 114240, "start": 1148.0800000000002, "end": 1153.3600000000001, "text": " direction. We could actually consider this more like an algebra problem, where we have variables", "tokens": [50648, 3513, 13, 492, 727, 767, 1949, 341, 544, 411, 364, 21989, 1154, 11, 689, 321, 362, 9102, 50912], "temperature": 0.0, "avg_logprob": -0.10246034029151212, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.00017399928765371442}, {"id": 177, "seek": 114240, "start": 1153.3600000000001, "end": 1158.64, "text": " that we want to place in the different parts. Maybe the row p. We replace that with some variable x.", "tokens": [50912, 300, 321, 528, 281, 1081, 294, 264, 819, 3166, 13, 2704, 264, 5386, 280, 13, 492, 7406, 300, 365, 512, 7006, 2031, 13, 51176], "temperature": 0.0, "avg_logprob": -0.10246034029151212, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.00017399928765371442}, {"id": 178, "seek": 114240, "start": 1158.64, "end": 1166.24, "text": " I don't know what x is. Or the expression or the value. Okay, so if we can put variables in", "tokens": [51176, 286, 500, 380, 458, 437, 2031, 307, 13, 1610, 264, 6114, 420, 264, 2158, 13, 1033, 11, 370, 498, 321, 393, 829, 9102, 294, 51556], "temperature": 0.0, "avg_logprob": -0.10246034029151212, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.00017399928765371442}, {"id": 179, "seek": 114240, "start": 1166.88, "end": 1172.16, "text": " and then have a system that can do a mixture of maybe things like search and constraint solving,", "tokens": [51588, 293, 550, 362, 257, 1185, 300, 393, 360, 257, 9925, 295, 1310, 721, 411, 3164, 293, 25534, 12606, 11, 51852], "temperature": 0.0, "avg_logprob": -0.10246034029151212, "compression_ratio": 1.6996466431095407, "no_speech_prob": 0.00017399928765371442}, {"id": 180, "seek": 117216, "start": 1172.16, "end": 1177.76, "text": " then we can try putting variables in to get more flexibility. So, that's exactly what we've done.", "tokens": [50364, 550, 321, 393, 853, 3372, 9102, 294, 281, 483, 544, 12635, 13, 407, 11, 300, 311, 2293, 437, 321, 600, 1096, 13, 50644], "temperature": 0.0, "avg_logprob": -0.09166921888078962, "compression_ratio": 1.6933333333333334, "no_speech_prob": 1.8342230760026723e-05}, {"id": 181, "seek": 117216, "start": 1178.72, "end": 1188.0800000000002, "text": " So, what that means is, if I go back to this valo call, I don't have to just put in an expression", "tokens": [50692, 407, 11, 437, 300, 1355, 307, 11, 498, 286, 352, 646, 281, 341, 1323, 78, 818, 11, 286, 500, 380, 362, 281, 445, 829, 294, 364, 6114, 51160], "temperature": 0.0, "avg_logprob": -0.09166921888078962, "compression_ratio": 1.6933333333333334, "no_speech_prob": 1.8342230760026723e-05}, {"id": 182, "seek": 117216, "start": 1188.64, "end": 1194.48, "text": " that's known in the first position and then put an unknown in the value position. I can do the", "tokens": [51188, 300, 311, 2570, 294, 264, 700, 2535, 293, 550, 829, 364, 9841, 294, 264, 2158, 2535, 13, 286, 393, 360, 264, 51480], "temperature": 0.0, "avg_logprob": -0.09166921888078962, "compression_ratio": 1.6933333333333334, "no_speech_prob": 1.8342230760026723e-05}, {"id": 183, "seek": 117216, "start": 1194.48, "end": 1199.6000000000001, "text": " opposite. So, what I could do is I say, okay, well, I know that the list is supposed to be", "tokens": [51480, 6182, 13, 407, 11, 437, 286, 727, 360, 307, 286, 584, 11, 1392, 11, 731, 11, 286, 458, 300, 264, 1329, 307, 3442, 281, 312, 51736], "temperature": 0.0, "avg_logprob": -0.09166921888078962, "compression_ratio": 1.6933333333333334, "no_speech_prob": 1.8342230760026723e-05}, {"id": 184, "seek": 119960, "start": 1199.6799999999998, "end": 1206.8799999999999, "text": " three, four, right? And grab this list. The extra prens, by the way, and that answer up top have to", "tokens": [50368, 1045, 11, 1451, 11, 558, 30, 400, 4444, 341, 1329, 13, 440, 2857, 659, 3695, 11, 538, 264, 636, 11, 293, 300, 1867, 493, 1192, 362, 281, 50728], "temperature": 0.0, "avg_logprob": -0.11808138267666686, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.00016864362987689674}, {"id": 185, "seek": 119960, "start": 1206.8799999999999, "end": 1211.6, "text": " do with, first of all, the fact that we can get more than one answer back and also that we can get", "tokens": [50728, 360, 365, 11, 700, 295, 439, 11, 264, 1186, 300, 321, 393, 483, 544, 813, 472, 1867, 646, 293, 611, 300, 321, 393, 483, 50964], "temperature": 0.0, "avg_logprob": -0.11808138267666686, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.00016864362987689674}, {"id": 186, "seek": 119960, "start": 1211.6, "end": 1217.04, "text": " some side conditions to help interpret the answer. Anyway, I'm going to replace that query variable", "tokens": [50964, 512, 1252, 4487, 281, 854, 7302, 264, 1867, 13, 5684, 11, 286, 478, 516, 281, 7406, 300, 14581, 7006, 51236], "temperature": 0.0, "avg_logprob": -0.11808138267666686, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.00016864362987689674}, {"id": 187, "seek": 119960, "start": 1217.04, "end": 1224.8, "text": " with quote three, four. So, that's the expected value. And I'm going to replace the expression", "tokens": [51236, 365, 6513, 1045, 11, 1451, 13, 407, 11, 300, 311, 264, 5176, 2158, 13, 400, 286, 478, 516, 281, 7406, 264, 6114, 51624], "temperature": 0.0, "avg_logprob": -0.11808138267666686, "compression_ratio": 1.708695652173913, "no_speech_prob": 0.00016864362987689674}, {"id": 188, "seek": 122480, "start": 1225.76, "end": 1232.32, "text": " with my query variable Q. So, now what I'm asking is, give me an expression in scheme", "tokens": [50412, 365, 452, 14581, 7006, 1249, 13, 407, 11, 586, 437, 286, 478, 3365, 307, 11, 976, 385, 364, 6114, 294, 12232, 50740], "temperature": 0.0, "avg_logprob": -0.13086708386739096, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.00031503106583841145}, {"id": 189, "seek": 122480, "start": 1232.32, "end": 1236.56, "text": " that evaluates the list three, four. So, what would be one such expression do you think?", "tokens": [50740, 300, 6133, 1024, 264, 1329, 1045, 11, 1451, 13, 407, 11, 437, 576, 312, 472, 1270, 6114, 360, 291, 519, 30, 50952], "temperature": 0.0, "avg_logprob": -0.13086708386739096, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.00031503106583841145}, {"id": 190, "seek": 122480, "start": 1241.12, "end": 1245.6, "text": " List three, four. Okay. So, list three, four is one. Quote three, four is another. So, I can ask", "tokens": [51180, 17668, 1045, 11, 1451, 13, 1033, 13, 407, 11, 1329, 1045, 11, 1451, 307, 472, 13, 2326, 1370, 1045, 11, 1451, 307, 1071, 13, 407, 11, 286, 393, 1029, 51404], "temperature": 0.0, "avg_logprob": -0.13086708386739096, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.00031503106583841145}, {"id": 191, "seek": 122480, "start": 1245.6, "end": 1250.72, "text": " for, you know, let me ask for two answers. Okay. So, list three, four was the second one I got.", "tokens": [51404, 337, 11, 291, 458, 11, 718, 385, 1029, 337, 732, 6338, 13, 1033, 13, 407, 11, 1329, 1045, 11, 1451, 390, 264, 1150, 472, 286, 658, 13, 51660], "temperature": 0.0, "avg_logprob": -0.13086708386739096, "compression_ratio": 1.7902439024390244, "no_speech_prob": 0.00031503106583841145}, {"id": 192, "seek": 125072, "start": 1251.6000000000001, "end": 1257.84, "text": " And I can ask for three answers. And we can see list three, quote, four. So, it turns out that", "tokens": [50408, 400, 286, 393, 1029, 337, 1045, 6338, 13, 400, 321, 393, 536, 1329, 1045, 11, 6513, 11, 1451, 13, 407, 11, 309, 4523, 484, 300, 50720], "temperature": 0.0, "avg_logprob": -0.10699041990133432, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003682791721075773}, {"id": 193, "seek": 125072, "start": 1257.84, "end": 1263.92, "text": " if you quote three or four, it's the same as just writing three or four. And so, you can see that", "tokens": [50720, 498, 291, 6513, 1045, 420, 1451, 11, 309, 311, 264, 912, 382, 445, 3579, 1045, 420, 1451, 13, 400, 370, 11, 291, 393, 536, 300, 51024], "temperature": 0.0, "avg_logprob": -0.10699041990133432, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003682791721075773}, {"id": 194, "seek": 125072, "start": 1263.92, "end": 1270.48, "text": " we have a number of answers, right? And so, some of those answers involve things like lambda and", "tokens": [51024, 321, 362, 257, 1230, 295, 6338, 11, 558, 30, 400, 370, 11, 512, 295, 729, 6338, 9494, 721, 411, 13607, 293, 51352], "temperature": 0.0, "avg_logprob": -0.10699041990133432, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003682791721075773}, {"id": 195, "seek": 125072, "start": 1270.48, "end": 1275.44, "text": " procedure application. So, as I say, hey, as function call can give you three, the list three,", "tokens": [51352, 10747, 3861, 13, 407, 11, 382, 286, 584, 11, 4177, 11, 382, 2445, 818, 393, 976, 291, 1045, 11, 264, 1329, 1045, 11, 51600], "temperature": 0.0, "avg_logprob": -0.10699041990133432, "compression_ratio": 1.7066666666666668, "no_speech_prob": 0.0003682791721075773}, {"id": 196, "seek": 127544, "start": 1275.44, "end": 1286.72, "text": " four. All right. Now, back to Lollipop land. So, Matt might, who's giving keynote tonight and", "tokens": [50364, 1451, 13, 1057, 558, 13, 823, 11, 646, 281, 441, 1833, 647, 404, 2117, 13, 407, 11, 7397, 1062, 11, 567, 311, 2902, 33896, 4440, 293, 50928], "temperature": 0.0, "avg_logprob": -0.199322277737647, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.0005032969056628644}, {"id": 197, "seek": 127544, "start": 1287.3600000000001, "end": 1293.2, "text": " whose lab I work in and work with for many years. He wrote a blog post for Valentine's Day", "tokens": [50960, 6104, 2715, 286, 589, 294, 293, 589, 365, 337, 867, 924, 13, 634, 4114, 257, 6968, 2183, 337, 24359, 311, 5226, 51252], "temperature": 0.0, "avg_logprob": -0.199322277737647, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.0005032969056628644}, {"id": 198, "seek": 127544, "start": 1294.16, "end": 1299.6000000000001, "text": " a couple years ago called 99 ways to say I love you in racket. So, the idea of this was to teach", "tokens": [51300, 257, 1916, 924, 2057, 1219, 11803, 2098, 281, 584, 286, 959, 291, 294, 41130, 13, 407, 11, 264, 1558, 295, 341, 390, 281, 2924, 51572], "temperature": 0.0, "avg_logprob": -0.199322277737647, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.0005032969056628644}, {"id": 199, "seek": 127544, "start": 1300.48, "end": 1304.4, "text": " students and beginning racket programmers a little bit of racket and a little bit of how", "tokens": [51616, 1731, 293, 2863, 41130, 41504, 257, 707, 857, 295, 41130, 293, 257, 707, 857, 295, 577, 51812], "temperature": 0.0, "avg_logprob": -0.199322277737647, "compression_ratio": 1.5677966101694916, "no_speech_prob": 0.0005032969056628644}, {"id": 200, "seek": 130440, "start": 1304.4, "end": 1312.0800000000002, "text": " they manipulate lists because racket's a list and list is list processing. So, the idea is to", "tokens": [50364, 436, 20459, 14511, 570, 41130, 311, 257, 1329, 293, 1329, 307, 1329, 9007, 13, 407, 11, 264, 1558, 307, 281, 50748], "temperature": 0.0, "avg_logprob": -0.23184197948824975, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00018521289166528732}, {"id": 201, "seek": 130440, "start": 1312.0800000000002, "end": 1318.4, "text": " show 99 different expressions and there are various complicated ones and so forth that", "tokens": [50748, 855, 11803, 819, 15277, 293, 456, 366, 3683, 6179, 2306, 293, 370, 5220, 300, 51064], "temperature": 0.0, "avg_logprob": -0.23184197948824975, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00018521289166528732}, {"id": 202, "seek": 130440, "start": 1319.44, "end": 1324.64, "text": " would evaluate to list I love you. And PD Aldous, who's one of the grad students said, hey,", "tokens": [51116, 576, 13059, 281, 1329, 286, 959, 291, 13, 400, 10464, 24031, 563, 11, 567, 311, 472, 295, 264, 2771, 1731, 848, 11, 4177, 11, 51376], "temperature": 0.0, "avg_logprob": -0.23184197948824975, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00018521289166528732}, {"id": 203, "seek": 130440, "start": 1325.44, "end": 1332.5600000000002, "text": " do you think you could use mini-canron to generate such programs? So, let's try doing that. We're", "tokens": [51416, 360, 291, 519, 291, 727, 764, 8382, 12, 7035, 2044, 281, 8460, 1270, 4268, 30, 407, 11, 718, 311, 853, 884, 300, 13, 492, 434, 51772], "temperature": 0.0, "avg_logprob": -0.23184197948824975, "compression_ratio": 1.5289256198347108, "no_speech_prob": 0.00018521289166528732}, {"id": 204, "seek": 133256, "start": 1332.56, "end": 1338.56, "text": " going to generate 99 programs that evaluate to I love you. So, can you help me out with the query?", "tokens": [50364, 516, 281, 8460, 11803, 4268, 300, 13059, 281, 286, 959, 291, 13, 407, 11, 393, 291, 854, 385, 484, 365, 264, 14581, 30, 50664], "temperature": 0.0, "avg_logprob": -0.12391533170427595, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.0001910906285047531}, {"id": 205, "seek": 133256, "start": 1338.56, "end": 1350.3999999999999, "text": " What would that look like? Run 99? Sure. Okay. What else is going to change?", "tokens": [50664, 708, 576, 300, 574, 411, 30, 8950, 11803, 30, 4894, 13, 1033, 13, 708, 1646, 307, 516, 281, 1319, 30, 51256], "temperature": 0.0, "avg_logprob": -0.12391533170427595, "compression_ratio": 1.2962962962962963, "no_speech_prob": 0.0001910906285047531}, {"id": 206, "seek": 135040, "start": 1351.2, "end": 1363.44, "text": " Sure. Okay. How about I love you? Okay. All right. So, here are 99 programs that evaluate to I love", "tokens": [50404, 4894, 13, 1033, 13, 1012, 466, 286, 959, 291, 30, 1033, 13, 1057, 558, 13, 407, 11, 510, 366, 11803, 4268, 300, 13059, 281, 286, 959, 51016], "temperature": 0.0, "avg_logprob": -0.22673824628194172, "compression_ratio": 1.3357142857142856, "no_speech_prob": 0.002472441177815199}, {"id": 207, "seek": 135040, "start": 1363.44, "end": 1375.8400000000001, "text": " you. So, I don't know. Let me, what's a fun one? How about, let's just start down here.", "tokens": [51016, 291, 13, 407, 11, 286, 500, 380, 458, 13, 961, 385, 11, 437, 311, 257, 1019, 472, 30, 1012, 466, 11, 718, 311, 445, 722, 760, 510, 13, 51636], "temperature": 0.0, "avg_logprob": -0.22673824628194172, "compression_ratio": 1.3357142857142856, "no_speech_prob": 0.002472441177815199}, {"id": 208, "seek": 137584, "start": 1376.6399999999999, "end": 1382.48, "text": " Let me just grab that out and I'm running it in scheme now and you can see that evaluates I love", "tokens": [50404, 961, 385, 445, 4444, 300, 484, 293, 286, 478, 2614, 309, 294, 12232, 586, 293, 291, 393, 536, 300, 6133, 1024, 286, 959, 50696], "temperature": 0.0, "avg_logprob": -0.153534669142503, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.001133483019657433}, {"id": 209, "seek": 137584, "start": 1382.48, "end": 1388.48, "text": " you. So, we've got list quote I, quote love and then the last sub expression is a procedure call", "tokens": [50696, 291, 13, 407, 11, 321, 600, 658, 1329, 6513, 286, 11, 6513, 959, 293, 550, 264, 1036, 1422, 6114, 307, 257, 10747, 818, 50996], "temperature": 0.0, "avg_logprob": -0.153534669142503, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.001133483019657433}, {"id": 210, "seek": 137584, "start": 1388.48, "end": 1392.9599999999998, "text": " to a function which is variadic. It takes any number of arguments. The underscore dot zero", "tokens": [50996, 281, 257, 2445, 597, 307, 3034, 43341, 13, 467, 2516, 604, 1230, 295, 12869, 13, 440, 37556, 5893, 4018, 51220], "temperature": 0.0, "avg_logprob": -0.153534669142503, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.001133483019657433}, {"id": 211, "seek": 137584, "start": 1392.9599999999998, "end": 1397.6, "text": " represents a symbol representing, that's a symbol representing a variable. The name doesn't matter.", "tokens": [51220, 8855, 257, 5986, 13460, 11, 300, 311, 257, 5986, 13460, 257, 7006, 13, 440, 1315, 1177, 380, 1871, 13, 51452], "temperature": 0.0, "avg_logprob": -0.153534669142503, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.001133483019657433}, {"id": 212, "seek": 137584, "start": 1397.6, "end": 1401.4399999999998, "text": " That's why I picked underscore dot zero. That's our convention saying it doesn't matter. You could", "tokens": [51452, 663, 311, 983, 286, 6183, 37556, 5893, 4018, 13, 663, 311, 527, 10286, 1566, 309, 1177, 380, 1871, 13, 509, 727, 51644], "temperature": 0.0, "avg_logprob": -0.153534669142503, "compression_ratio": 1.7563636363636363, "no_speech_prob": 0.001133483019657433}, {"id": 213, "seek": 140144, "start": 1401.44, "end": 1409.28, "text": " pick foo if you wanted there. And this quote underscore one thing. So, this is a quoted symbol", "tokens": [50364, 1888, 726, 78, 498, 291, 1415, 456, 13, 400, 341, 6513, 37556, 472, 551, 13, 407, 11, 341, 307, 257, 30047, 5986, 50756], "temperature": 0.0, "avg_logprob": -0.11752851130598682, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.0011694247368723154}, {"id": 214, "seek": 140144, "start": 1409.28, "end": 1412.96, "text": " also. If you look at the side conditions, you'll see these things. So, that could be any quoted", "tokens": [50756, 611, 13, 759, 291, 574, 412, 264, 1252, 4487, 11, 291, 603, 536, 613, 721, 13, 407, 11, 300, 727, 312, 604, 30047, 50940], "temperature": 0.0, "avg_logprob": -0.11752851130598682, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.0011694247368723154}, {"id": 215, "seek": 140144, "start": 1412.96, "end": 1418.8, "text": " symbol and this will hold. There might be some other side conditions like the symbol can't be", "tokens": [50940, 5986, 293, 341, 486, 1797, 13, 821, 1062, 312, 512, 661, 1252, 4487, 411, 264, 5986, 393, 380, 312, 51232], "temperature": 0.0, "avg_logprob": -0.11752851130598682, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.0011694247368723154}, {"id": 216, "seek": 140144, "start": 1418.8, "end": 1422.48, "text": " called quote. Under score zero can't be called quote because you don't want to shadow quote,", "tokens": [51232, 1219, 6513, 13, 6974, 6175, 4018, 393, 380, 312, 1219, 6513, 570, 291, 500, 380, 528, 281, 8576, 6513, 11, 51416], "temperature": 0.0, "avg_logprob": -0.11752851130598682, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.0011694247368723154}, {"id": 217, "seek": 140144, "start": 1422.48, "end": 1429.3600000000001, "text": " that kind of thing. Okay. So, that's a simple example. And after, after we started playing", "tokens": [51416, 300, 733, 295, 551, 13, 1033, 13, 407, 11, 300, 311, 257, 2199, 1365, 13, 400, 934, 11, 934, 321, 1409, 2433, 51760], "temperature": 0.0, "avg_logprob": -0.11752851130598682, "compression_ratio": 1.849802371541502, "no_speech_prob": 0.0011694247368723154}, {"id": 218, "seek": 142936, "start": 1429.36, "end": 1434.0, "text": " around with this a little bit, Dan Friedman and I gave a talk at closure conge and we,", "tokens": [50364, 926, 365, 341, 257, 707, 857, 11, 3394, 17605, 1601, 293, 286, 2729, 257, 751, 412, 24653, 416, 432, 293, 321, 11, 50596], "temperature": 0.0, "avg_logprob": -0.16110027537626379, "compression_ratio": 1.5060728744939271, "no_speech_prob": 0.0014102151617407799}, {"id": 219, "seek": 142936, "start": 1434.0, "end": 1439.4399999999998, "text": " we showed this relational interpreter or variant of it and Stu Holloway at the end said, well,", "tokens": [50596, 321, 4712, 341, 38444, 34132, 420, 17501, 295, 309, 293, 25203, 46731, 320, 412, 264, 917, 848, 11, 731, 11, 50868], "temperature": 0.0, "avg_logprob": -0.16110027537626379, "compression_ratio": 1.5060728744939271, "no_speech_prob": 0.0014102151617407799}, {"id": 220, "seek": 142936, "start": 1439.4399999999998, "end": 1447.04, "text": " you know, you should be able to generate quines using this. Anyone know what a quine is? What's a", "tokens": [50868, 291, 458, 11, 291, 820, 312, 1075, 281, 8460, 421, 1652, 1228, 341, 13, 14643, 458, 437, 257, 421, 533, 307, 30, 708, 311, 257, 51248], "temperature": 0.0, "avg_logprob": -0.16110027537626379, "compression_ratio": 1.5060728744939271, "no_speech_prob": 0.0014102151617407799}, {"id": 221, "seek": 142936, "start": 1447.04, "end": 1454.32, "text": " quine? A program that outputs itself. That's right. Okay. In fact, if we go back to history,", "tokens": [51248, 421, 533, 30, 316, 1461, 300, 23930, 2564, 13, 663, 311, 558, 13, 1033, 13, 682, 1186, 11, 498, 321, 352, 646, 281, 2503, 11, 51612], "temperature": 0.0, "avg_logprob": -0.16110027537626379, "compression_ratio": 1.5060728744939271, "no_speech_prob": 0.0014102151617407799}, {"id": 222, "seek": 145432, "start": 1454.32, "end": 1464.3999999999999, "text": " let's see if we can go back and, you know, I love the fact the guy went through so many papers,", "tokens": [50364, 718, 311, 536, 498, 321, 393, 352, 646, 293, 11, 291, 458, 11, 286, 959, 264, 1186, 264, 2146, 1437, 807, 370, 867, 10577, 11, 50868], "temperature": 0.0, "avg_logprob": -0.17998593524821754, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0010986580746248364}, {"id": 223, "seek": 145432, "start": 1464.3999999999999, "end": 1468.32, "text": " old papers. Well, this is a paper I really like by John McCarthy who is the creator of,", "tokens": [50868, 1331, 10577, 13, 1042, 11, 341, 307, 257, 3035, 286, 534, 411, 538, 2619, 44085, 567, 307, 264, 14181, 295, 11, 51064], "temperature": 0.0, "avg_logprob": -0.17998593524821754, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0010986580746248364}, {"id": 224, "seek": 145432, "start": 1468.8799999999999, "end": 1476.0, "text": " of Lisp called a micromanual for Lisp, not the whole truth. And then this he gives rules for", "tokens": [51092, 295, 441, 7631, 1219, 257, 3123, 81, 4277, 901, 337, 441, 7631, 11, 406, 264, 1379, 3494, 13, 400, 550, 341, 415, 2709, 4474, 337, 51448], "temperature": 0.0, "avg_logprob": -0.17998593524821754, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0010986580746248364}, {"id": 225, "seek": 145432, "start": 1476.8, "end": 1482.08, "text": " the Lisp language. So, you can see like what equal means, what cons means and so forth.", "tokens": [51488, 264, 441, 7631, 2856, 13, 407, 11, 291, 393, 536, 411, 437, 2681, 1355, 11, 437, 1014, 1355, 293, 370, 5220, 13, 51752], "temperature": 0.0, "avg_logprob": -0.17998593524821754, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.0010986580746248364}, {"id": 226, "seek": 148208, "start": 1483.04, "end": 1489.28, "text": " Notice by the way he uses an equal sign. Right? Not narrow. But then he has this neat little", "tokens": [50412, 13428, 538, 264, 636, 415, 4960, 364, 2681, 1465, 13, 1779, 30, 1726, 9432, 13, 583, 550, 415, 575, 341, 10654, 707, 50724], "temperature": 0.0, "avg_logprob": -0.16347501695770578, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.00023780515766702592}, {"id": 227, "seek": 148208, "start": 1489.28, "end": 1496.96, "text": " problem. Difficult mathematical type exercise. Final list E such that value of E equals E.", "tokens": [50724, 1154, 13, 35940, 1786, 723, 18894, 2010, 5380, 13, 13443, 1329, 462, 1270, 300, 2158, 295, 462, 6915, 462, 13, 51108], "temperature": 0.0, "avg_logprob": -0.16347501695770578, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.00023780515766702592}, {"id": 228, "seek": 148208, "start": 1497.84, "end": 1502.24, "text": " So, value is the name of his evaluator function, his eval. So, basically,", "tokens": [51152, 407, 11, 2158, 307, 264, 1315, 295, 702, 6133, 1639, 2445, 11, 702, 1073, 304, 13, 407, 11, 1936, 11, 51372], "temperature": 0.0, "avg_logprob": -0.16347501695770578, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.00023780515766702592}, {"id": 229, "seek": 148208, "start": 1504.0, "end": 1509.12, "text": " what he's calling value is what we would call eval or evalo. And so, he's trying to find an", "tokens": [51460, 437, 415, 311, 5141, 2158, 307, 437, 321, 576, 818, 1073, 304, 420, 1073, 10334, 13, 400, 370, 11, 415, 311, 1382, 281, 915, 364, 51716], "temperature": 0.0, "avg_logprob": -0.16347501695770578, "compression_ratio": 1.572072072072072, "no_speech_prob": 0.00023780515766702592}, {"id": 230, "seek": 150912, "start": 1509.12, "end": 1514.6399999999999, "text": " expression E such that the value of E is E. So, that is also trying to find a quine. So,", "tokens": [50364, 6114, 462, 1270, 300, 264, 2158, 295, 462, 307, 462, 13, 407, 11, 300, 307, 611, 1382, 281, 915, 257, 421, 533, 13, 407, 11, 50640], "temperature": 0.0, "avg_logprob": -0.12487586069915255, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00020341381605248898}, {"id": 231, "seek": 150912, "start": 1514.6399999999999, "end": 1520.8799999999999, "text": " he was trying to find a quine or Gittis to find a quine in, I think, 1978. So, let's try to do that.", "tokens": [50640, 415, 390, 1382, 281, 915, 257, 421, 533, 420, 460, 593, 271, 281, 915, 257, 421, 533, 294, 11, 286, 519, 11, 33191, 13, 407, 11, 718, 311, 853, 281, 360, 300, 13, 50952], "temperature": 0.0, "avg_logprob": -0.12487586069915255, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00020341381605248898}, {"id": 232, "seek": 150912, "start": 1522.32, "end": 1528.1599999999999, "text": " So, given what you know, how would we find a quine? What would, how would we change", "tokens": [51024, 407, 11, 2212, 437, 291, 458, 11, 577, 576, 321, 915, 257, 421, 533, 30, 708, 576, 11, 577, 576, 321, 1319, 51316], "temperature": 0.0, "avg_logprob": -0.12487586069915255, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00020341381605248898}, {"id": 233, "seek": 150912, "start": 1528.1599999999999, "end": 1537.76, "text": " our query so we could generate a quine? QQ, a value of QQ, that's right. Now, of course,", "tokens": [51316, 527, 14581, 370, 321, 727, 8460, 257, 421, 533, 30, 1249, 48, 11, 257, 2158, 295, 1249, 48, 11, 300, 311, 558, 13, 823, 11, 295, 1164, 11, 51796], "temperature": 0.0, "avg_logprob": -0.12487586069915255, "compression_ratio": 1.7320574162679425, "no_speech_prob": 0.00020341381605248898}, {"id": 234, "seek": 153776, "start": 1537.76, "end": 1542.16, "text": " there's nothing special about the name Q. So, why don't we, out of respect for John McCarthy,", "tokens": [50364, 456, 311, 1825, 2121, 466, 264, 1315, 1249, 13, 407, 11, 983, 500, 380, 321, 11, 484, 295, 3104, 337, 2619, 44085, 11, 50584], "temperature": 0.0, "avg_logprob": -0.1114507389959888, "compression_ratio": 1.551440329218107, "no_speech_prob": 8.480745600536466e-05}, {"id": 235, "seek": 153776, "start": 1542.16, "end": 1550.0, "text": " call it E instead. Valo EE. And let's do a run one. Okay. So, we're trying to find an expression E", "tokens": [50584, 818, 309, 462, 2602, 13, 7188, 78, 33685, 13, 400, 718, 311, 360, 257, 1190, 472, 13, 1033, 13, 407, 11, 321, 434, 1382, 281, 915, 364, 6114, 462, 50976], "temperature": 0.0, "avg_logprob": -0.1114507389959888, "compression_ratio": 1.551440329218107, "no_speech_prob": 8.480745600536466e-05}, {"id": 236, "seek": 153776, "start": 1550.0, "end": 1555.52, "text": " that evaluates to itself. This is pretty close to what John McCarthy wrote, right? I mean,", "tokens": [50976, 300, 6133, 1024, 281, 2564, 13, 639, 307, 1238, 1998, 281, 437, 2619, 44085, 4114, 11, 558, 30, 286, 914, 11, 51252], "temperature": 0.0, "avg_logprob": -0.1114507389959888, "compression_ratio": 1.551440329218107, "no_speech_prob": 8.480745600536466e-05}, {"id": 237, "seek": 153776, "start": 1555.52, "end": 1562.72, "text": " we're calling it a valo instead of, instead of value. But, you know, this is exactly what you", "tokens": [51252, 321, 434, 5141, 309, 257, 1323, 78, 2602, 295, 11, 2602, 295, 2158, 13, 583, 11, 291, 458, 11, 341, 307, 2293, 437, 291, 51612], "temperature": 0.0, "avg_logprob": -0.1114507389959888, "compression_ratio": 1.551440329218107, "no_speech_prob": 8.480745600536466e-05}, {"id": 238, "seek": 156272, "start": 1562.72, "end": 1567.92, "text": " would want to be able to type into a system. So, let's see what Minicandron gives us back.", "tokens": [50364, 576, 528, 281, 312, 1075, 281, 2010, 666, 257, 1185, 13, 407, 11, 718, 311, 536, 437, 2829, 299, 474, 2044, 2709, 505, 646, 13, 50624], "temperature": 0.0, "avg_logprob": -0.1615722622491617, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0012447662884369493}, {"id": 239, "seek": 156272, "start": 1569.44, "end": 1575.92, "text": " Well, the first thing it says is that underscore zero is a number, which is true. Okay. So,", "tokens": [50700, 1042, 11, 264, 700, 551, 309, 1619, 307, 300, 37556, 4018, 307, 257, 1230, 11, 597, 307, 2074, 13, 1033, 13, 407, 11, 51024], "temperature": 0.0, "avg_logprob": -0.1615722622491617, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0012447662884369493}, {"id": 240, "seek": 156272, "start": 1575.92, "end": 1581.04, "text": " in scheme five is a quine. So, five evaluates to itself. That's true. Okay. So, that's what", "tokens": [51024, 294, 12232, 1732, 307, 257, 421, 533, 13, 407, 11, 1732, 6133, 1024, 281, 2564, 13, 663, 311, 2074, 13, 1033, 13, 407, 11, 300, 311, 437, 51280], "temperature": 0.0, "avg_logprob": -0.1615722622491617, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0012447662884369493}, {"id": 241, "seek": 156272, "start": 1581.04, "end": 1586.48, "text": " Minicandron's telling us. Let's ask for a second one. It says hash t. Hash t is true in scheme.", "tokens": [51280, 2829, 299, 474, 2044, 311, 3585, 505, 13, 961, 311, 1029, 337, 257, 1150, 472, 13, 467, 1619, 22019, 256, 13, 30775, 256, 307, 2074, 294, 12232, 13, 51552], "temperature": 0.0, "avg_logprob": -0.1615722622491617, "compression_ratio": 1.6517857142857142, "no_speech_prob": 0.0012447662884369493}, {"id": 242, "seek": 158648, "start": 1587.04, "end": 1591.92, "text": " All right. So, those are all quines. Hash f is a quine. How about four?", "tokens": [50392, 1057, 558, 13, 407, 11, 729, 366, 439, 421, 1652, 13, 30775, 283, 307, 257, 421, 533, 13, 1012, 466, 1451, 30, 50636], "temperature": 0.0, "avg_logprob": -0.09759373848254864, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.0006878405692987144}, {"id": 243, "seek": 158648, "start": 1593.92, "end": 1597.04, "text": " Now, it's thinking for a minute. Okay. Now, we've got something a little more interesting.", "tokens": [50736, 823, 11, 309, 311, 1953, 337, 257, 3456, 13, 1033, 13, 823, 11, 321, 600, 658, 746, 257, 707, 544, 1880, 13, 50892], "temperature": 0.0, "avg_logprob": -0.09759373848254864, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.0006878405692987144}, {"id": 244, "seek": 158648, "start": 1598.16, "end": 1604.48, "text": " I'm going to grab that expression and type it in. And sure enough, that's a quine. So,", "tokens": [50948, 286, 478, 516, 281, 4444, 300, 6114, 293, 2010, 309, 294, 13, 400, 988, 1547, 11, 300, 311, 257, 421, 533, 13, 407, 11, 51264], "temperature": 0.0, "avg_logprob": -0.09759373848254864, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.0006878405692987144}, {"id": 245, "seek": 158648, "start": 1604.48, "end": 1610.48, "text": " that's a self-evaluating expression. In fact, if you look at the quines page, you will see this", "tokens": [51264, 300, 311, 257, 2698, 12, 68, 3337, 32438, 6114, 13, 682, 1186, 11, 498, 291, 574, 412, 264, 421, 1652, 3028, 11, 291, 486, 536, 341, 51564], "temperature": 0.0, "avg_logprob": -0.09759373848254864, "compression_ratio": 1.554054054054054, "no_speech_prob": 0.0006878405692987144}, {"id": 246, "seek": 161048, "start": 1610.48, "end": 1616.64, "text": " quine. This is sort of the canonical quine. And we can generate all sorts of quines. We can generate", "tokens": [50364, 421, 533, 13, 639, 307, 1333, 295, 264, 46491, 421, 533, 13, 400, 321, 393, 8460, 439, 7527, 295, 421, 1652, 13, 492, 393, 8460, 50672], "temperature": 0.0, "avg_logprob": -0.10342272122701009, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.0024723298847675323}, {"id": 247, "seek": 161048, "start": 1616.64, "end": 1623.28, "text": " twin quines and triple quines and that kind of thing. But what I love about this, and in some", "tokens": [50672, 18397, 421, 1652, 293, 15508, 421, 1652, 293, 300, 733, 295, 551, 13, 583, 437, 286, 959, 466, 341, 11, 293, 294, 512, 51004], "temperature": 0.0, "avg_logprob": -0.10342272122701009, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.0024723298847675323}, {"id": 248, "seek": 161048, "start": 1623.28, "end": 1628.4, "text": " sense, this is probably my favorite Minicandron query using a relational interpreter, but I love", "tokens": [51004, 2020, 11, 341, 307, 1391, 452, 2954, 2829, 299, 474, 2044, 14581, 1228, 257, 38444, 34132, 11, 457, 286, 959, 51260], "temperature": 0.0, "avg_logprob": -0.10342272122701009, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.0024723298847675323}, {"id": 249, "seek": 161048, "start": 1628.4, "end": 1632.48, "text": " it as the query is so simple. This is actually the shortest query you can write in terms of the", "tokens": [51260, 309, 382, 264, 14581, 307, 370, 2199, 13, 639, 307, 767, 264, 31875, 14581, 291, 393, 2464, 294, 2115, 295, 264, 51464], "temperature": 0.0, "avg_logprob": -0.10342272122701009, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.0024723298847675323}, {"id": 250, "seek": 161048, "start": 1632.48, "end": 1637.2, "text": " number of distinct identifiers. This is like the shortest thing you can write. And it generates", "tokens": [51464, 1230, 295, 10644, 2473, 23463, 13, 639, 307, 411, 264, 31875, 551, 291, 393, 2464, 13, 400, 309, 23815, 51700], "temperature": 0.0, "avg_logprob": -0.10342272122701009, "compression_ratio": 1.8576923076923078, "no_speech_prob": 0.0024723298847675323}, {"id": 251, "seek": 163720, "start": 1637.2, "end": 1642.88, "text": " quines and it actually works. And I personally was shocked that like, oh, yeah, this actually,", "tokens": [50364, 421, 1652, 293, 309, 767, 1985, 13, 400, 286, 5665, 390, 12763, 300, 411, 11, 1954, 11, 1338, 11, 341, 767, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1777900926994555, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.00016345364565495402}, {"id": 252, "seek": 163720, "start": 1642.88, "end": 1647.6000000000001, "text": " this actually, you can actually do something with this. You type it in. I figured it would take", "tokens": [50648, 341, 767, 11, 291, 393, 767, 360, 746, 365, 341, 13, 509, 2010, 309, 294, 13, 286, 8932, 309, 576, 747, 50884], "temperature": 0.0, "avg_logprob": -0.1777900926994555, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.00016345364565495402}, {"id": 253, "seek": 163720, "start": 1647.6000000000001, "end": 1656.24, "text": " a million years or something. Okay. So, at that point, a grad student at Utah named Michael", "tokens": [50884, 257, 2459, 924, 420, 746, 13, 1033, 13, 407, 11, 412, 300, 935, 11, 257, 2771, 3107, 412, 20226, 4926, 5116, 51316], "temperature": 0.0, "avg_logprob": -0.1777900926994555, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.00016345364565495402}, {"id": 254, "seek": 163720, "start": 1656.24, "end": 1663.6000000000001, "text": " Ballantyne said, well, that's kind of fun. But what if you, now you have this interpreter,", "tokens": [51316, 10744, 394, 88, 716, 848, 11, 731, 11, 300, 311, 733, 295, 1019, 13, 583, 437, 498, 291, 11, 586, 291, 362, 341, 34132, 11, 51684], "temperature": 0.0, "avg_logprob": -0.1777900926994555, "compression_ratio": 1.5940170940170941, "no_speech_prob": 0.00016345364565495402}, {"id": 255, "seek": 166360, "start": 1663.6, "end": 1671.28, "text": " what if you were to take a scheme program and fill in the scheme program in the first expression,", "tokens": [50364, 437, 498, 291, 645, 281, 747, 257, 12232, 1461, 293, 2836, 294, 264, 12232, 1461, 294, 264, 700, 6114, 11, 50748], "temperature": 0.0, "avg_logprob": -0.1503107401789451, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00010888942051678896}, {"id": 256, "seek": 166360, "start": 1671.28, "end": 1676.3999999999999, "text": " but leave some of the arguments to that program, to that function, you know, make those variables?", "tokens": [50748, 457, 1856, 512, 295, 264, 12869, 281, 300, 1461, 11, 281, 300, 2445, 11, 291, 458, 11, 652, 729, 9102, 30, 51004], "temperature": 0.0, "avg_logprob": -0.1503107401789451, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00010888942051678896}, {"id": 257, "seek": 166360, "start": 1676.3999999999999, "end": 1681.9199999999998, "text": " Could you, could you get interesting behavior? And so he suggested append. So let's try doing that.", "tokens": [51004, 7497, 291, 11, 727, 291, 483, 1880, 5223, 30, 400, 370, 415, 10945, 34116, 13, 407, 718, 311, 853, 884, 300, 13, 51280], "temperature": 0.0, "avg_logprob": -0.1503107401789451, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00010888942051678896}, {"id": 258, "seek": 166360, "start": 1682.56, "end": 1692.8, "text": " So append in scheme takes two lists, like ABC and DE, and concatenates the list. So get ABCDE,", "tokens": [51312, 407, 34116, 294, 12232, 2516, 732, 14511, 11, 411, 22342, 293, 10113, 11, 293, 1588, 7186, 1024, 264, 1329, 13, 407, 483, 22342, 22296, 11, 51824], "temperature": 0.0, "avg_logprob": -0.1503107401789451, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.00010888942051678896}, {"id": 259, "seek": 169280, "start": 1692.8, "end": 1695.2, "text": " in this case. So what we're going to do is we're going to write append.", "tokens": [50364, 294, 341, 1389, 13, 407, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 2464, 34116, 13, 50484], "temperature": 0.0, "avg_logprob": -0.2145395887658951, "compression_ratio": 1.4065040650406504, "no_speech_prob": 0.0005702906637452543}, {"id": 260, "seek": 169280, "start": 1702.96, "end": 1710.3999999999999, "text": " And the way I'll write append is using something called let rec. Let's me define a recursive relation", "tokens": [50872, 400, 264, 636, 286, 603, 2464, 34116, 307, 1228, 746, 1219, 718, 850, 13, 961, 311, 385, 6964, 257, 20560, 488, 9721, 51244], "temperature": 0.0, "avg_logprob": -0.2145395887658951, "compression_ratio": 1.4065040650406504, "no_speech_prob": 0.0005702906637452543}, {"id": 261, "seek": 171040, "start": 1711.3600000000001, "end": 1720.0, "text": " or a function.", "tokens": [50412, 420, 257, 2445, 13, 50844], "temperature": 0.0, "avg_logprob": -0.7545998096466064, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.3275777995586395}, {"id": 262, "seek": 172000, "start": 1720.0, "end": 1747.6, "text": " Okay. So that's append. Did I get it right?", "tokens": [50364, 1033, 13, 407, 300, 311, 34116, 13, 2589, 286, 483, 309, 558, 30, 51744], "temperature": 0.0, "avg_logprob": -0.37979546189308167, "compression_ratio": 0.8431372549019608, "no_speech_prob": 0.2908545136451721}, {"id": 263, "seek": 175000, "start": 1750.16, "end": 1756.88, "text": " And now we're going to call append. I'll use the same arguments as before, ABC to DE.", "tokens": [50372, 400, 586, 321, 434, 516, 281, 818, 34116, 13, 286, 603, 764, 264, 912, 12869, 382, 949, 11, 22342, 281, 10113, 13, 50708], "temperature": 0.0, "avg_logprob": -0.15794212341308594, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0017005206318572164}, {"id": 264, "seek": 175000, "start": 1759.6, "end": 1765.84, "text": " Okay. So I just ran it forward. So, so what did I do? I took the scheme definition of append.", "tokens": [50844, 1033, 13, 407, 286, 445, 5872, 309, 2128, 13, 407, 11, 370, 437, 630, 286, 360, 30, 286, 1890, 264, 12232, 7123, 295, 34116, 13, 51156], "temperature": 0.0, "avg_logprob": -0.15794212341308594, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0017005206318572164}, {"id": 265, "seek": 175000, "start": 1765.84, "end": 1769.44, "text": " This is not mini-canon code. This is not logic programming code or constraint logic program", "tokens": [51156, 639, 307, 406, 8382, 12, 7035, 266, 3089, 13, 639, 307, 406, 9952, 9410, 3089, 420, 25534, 9952, 1461, 51336], "temperature": 0.0, "avg_logprob": -0.15794212341308594, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0017005206318572164}, {"id": 266, "seek": 175000, "start": 1769.44, "end": 1775.12, "text": " code. This is just scheme code. I ran it inside of a valo as the first argument. This is the", "tokens": [51336, 3089, 13, 639, 307, 445, 12232, 3089, 13, 286, 5872, 309, 1854, 295, 257, 1323, 78, 382, 264, 700, 6770, 13, 639, 307, 264, 51620], "temperature": 0.0, "avg_logprob": -0.15794212341308594, "compression_ratio": 1.6545454545454545, "no_speech_prob": 0.0017005206318572164}, {"id": 267, "seek": 177512, "start": 1775.12, "end": 1780.8, "text": " expression argument. And I said we have an unknown value. So my query variable Q represents", "tokens": [50364, 6114, 6770, 13, 400, 286, 848, 321, 362, 364, 9841, 2158, 13, 407, 452, 14581, 7006, 1249, 8855, 50648], "temperature": 0.0, "avg_logprob": -0.07630412219321892, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.0008829903672449291}, {"id": 268, "seek": 177512, "start": 1780.8, "end": 1790.3999999999999, "text": " the unknown value. So what can we do? Okay. So now what we can do is we can say we know ABCDE", "tokens": [50648, 264, 9841, 2158, 13, 407, 437, 393, 321, 360, 30, 1033, 13, 407, 586, 437, 321, 393, 360, 307, 321, 393, 584, 321, 458, 22342, 22296, 51128], "temperature": 0.0, "avg_logprob": -0.07630412219321892, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.0008829903672449291}, {"id": 269, "seek": 177512, "start": 1791.1999999999998, "end": 1798.2399999999998, "text": " is the output. And where else could I put a variable? Where could I put this Q variable?", "tokens": [51168, 307, 264, 5598, 13, 400, 689, 1646, 727, 286, 829, 257, 7006, 30, 2305, 727, 286, 829, 341, 1249, 7006, 30, 51520], "temperature": 0.0, "avg_logprob": -0.07630412219321892, "compression_ratio": 1.621301775147929, "no_speech_prob": 0.0008829903672449291}, {"id": 270, "seek": 179824, "start": 1798.72, "end": 1806.48, "text": " Well, how about I put it in a position of one of the arguments to append? How about I put it", "tokens": [50388, 1042, 11, 577, 466, 286, 829, 309, 294, 257, 2535, 295, 472, 295, 264, 12869, 281, 34116, 30, 1012, 466, 286, 829, 309, 50776], "temperature": 0.0, "avg_logprob": -0.17351570835819952, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0001911000581458211}, {"id": 271, "seek": 179824, "start": 1806.48, "end": 1811.36, "text": " right here? I have to put a comma there because this whole thing is back-quoted if you know scheme.", "tokens": [50776, 558, 510, 30, 286, 362, 281, 829, 257, 22117, 456, 570, 341, 1379, 551, 307, 646, 12, 358, 23325, 498, 291, 458, 12232, 13, 51020], "temperature": 0.0, "avg_logprob": -0.17351570835819952, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0001911000581458211}, {"id": 272, "seek": 179824, "start": 1811.92, "end": 1816.4, "text": " All right. So what do you think I'm going to get back in the place of the Q variable?", "tokens": [51048, 1057, 558, 13, 407, 437, 360, 291, 519, 286, 478, 516, 281, 483, 646, 294, 264, 1081, 295, 264, 1249, 7006, 30, 51272], "temperature": 0.0, "avg_logprob": -0.17351570835819952, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0001911000581458211}, {"id": 273, "seek": 179824, "start": 1820.4, "end": 1827.84, "text": " ABC, right? So let's see if that works. Yeah. Quote ABC. Is there a second answer? What if I do a", "tokens": [51472, 22342, 11, 558, 30, 407, 718, 311, 536, 498, 300, 1985, 13, 865, 13, 2326, 1370, 22342, 13, 1119, 456, 257, 1150, 1867, 30, 708, 498, 286, 360, 257, 51844], "temperature": 0.0, "avg_logprob": -0.17351570835819952, "compression_ratio": 1.5666666666666667, "no_speech_prob": 0.0001911000581458211}, {"id": 274, "seek": 182784, "start": 1827.84, "end": 1837.76, "text": " run two? Should there be a second answer or should it say no? No more answers. List ABC. All right.", "tokens": [50364, 1190, 732, 30, 6454, 456, 312, 257, 1150, 1867, 420, 820, 309, 584, 572, 30, 883, 544, 6338, 13, 17668, 22342, 13, 1057, 558, 13, 50860], "temperature": 0.0, "avg_logprob": -0.09926053519560912, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0002868362935259938}, {"id": 275, "seek": 182784, "start": 1837.76, "end": 1844.72, "text": " Well, let's see if we get something like that. It's not list ABC, but we get a procedure application.", "tokens": [50860, 1042, 11, 718, 311, 536, 498, 321, 483, 746, 411, 300, 13, 467, 311, 406, 1329, 22342, 11, 457, 321, 483, 257, 10747, 3861, 13, 51208], "temperature": 0.0, "avg_logprob": -0.09926053519560912, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0002868362935259938}, {"id": 276, "seek": 182784, "start": 1844.72, "end": 1849.6, "text": " And if I evaluate that in scheme, I get back ABC. So what happens is we get an expression", "tokens": [51208, 400, 498, 286, 13059, 300, 294, 12232, 11, 286, 483, 646, 22342, 13, 407, 437, 2314, 307, 321, 483, 364, 6114, 51452], "temperature": 0.0, "avg_logprob": -0.09926053519560912, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0002868362935259938}, {"id": 277, "seek": 182784, "start": 1849.6, "end": 1857.4399999999998, "text": " that evaluates to ABC. If I put a quote, I get back ABC itself. Okay. So that's a little subtle", "tokens": [51452, 300, 6133, 1024, 281, 22342, 13, 759, 286, 829, 257, 6513, 11, 286, 483, 646, 22342, 2564, 13, 1033, 13, 407, 300, 311, 257, 707, 13743, 51844], "temperature": 0.0, "avg_logprob": -0.09926053519560912, "compression_ratio": 1.6192468619246863, "no_speech_prob": 0.0002868362935259938}, {"id": 278, "seek": 185744, "start": 1857.44, "end": 1864.72, "text": " if you're not a schemer, but the point is we're making a distinction between expressions and values.", "tokens": [50364, 498, 291, 434, 406, 257, 22627, 260, 11, 457, 264, 935, 307, 321, 434, 1455, 257, 16844, 1296, 15277, 293, 4190, 13, 50728], "temperature": 0.0, "avg_logprob": -0.07163738977341425, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.00015355416689999402}, {"id": 279, "seek": 185744, "start": 1864.72, "end": 1869.3600000000001, "text": " So if I put a quote in front of the comma Q, that's going to say, well, I want the value,", "tokens": [50728, 407, 498, 286, 829, 257, 6513, 294, 1868, 295, 264, 22117, 1249, 11, 300, 311, 516, 281, 584, 11, 731, 11, 286, 528, 264, 2158, 11, 50960], "temperature": 0.0, "avg_logprob": -0.07163738977341425, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.00015355416689999402}, {"id": 280, "seek": 185744, "start": 1869.3600000000001, "end": 1875.28, "text": " the list that's going to concatenate to give me ABCDE. If I don't put the quote, that means this", "tokens": [50960, 264, 1329, 300, 311, 516, 281, 1588, 7186, 473, 281, 976, 385, 22342, 22296, 13, 759, 286, 500, 380, 829, 264, 6513, 11, 300, 1355, 341, 51256], "temperature": 0.0, "avg_logprob": -0.07163738977341425, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.00015355416689999402}, {"id": 281, "seek": 185744, "start": 1875.28, "end": 1881.3600000000001, "text": " could be an arbitrary expression in my subset of scheme that I'm handling. All right. Where else can", "tokens": [51256, 727, 312, 364, 23211, 6114, 294, 452, 25993, 295, 12232, 300, 286, 478, 13175, 13, 1057, 558, 13, 2305, 1646, 393, 51560], "temperature": 0.0, "avg_logprob": -0.07163738977341425, "compression_ratio": 1.5708502024291497, "no_speech_prob": 0.00015355416689999402}, {"id": 282, "seek": 188136, "start": 1881.36, "end": 1894.32, "text": " I put Q? Inside the list, like here. Sure. Yep. In fact, I could have two variables. I could do", "tokens": [50364, 286, 829, 1249, 30, 15123, 264, 1329, 11, 411, 510, 13, 4894, 13, 7010, 13, 682, 1186, 11, 286, 727, 362, 732, 9102, 13, 286, 727, 360, 51012], "temperature": 0.0, "avg_logprob": -0.16675014183169506, "compression_ratio": 1.3819444444444444, "no_speech_prob": 0.0007793401600793004}, {"id": 283, "seek": 188136, "start": 1894.32, "end": 1906.7199999999998, "text": " like x and y. And I can do things like... In fact, I can ask for all the answers. So if you're familiar", "tokens": [51012, 411, 2031, 293, 288, 13, 400, 286, 393, 360, 721, 411, 485, 682, 1186, 11, 286, 393, 1029, 337, 439, 264, 6338, 13, 407, 498, 291, 434, 4963, 51632], "temperature": 0.0, "avg_logprob": -0.16675014183169506, "compression_ratio": 1.3819444444444444, "no_speech_prob": 0.0007793401600793004}, {"id": 284, "seek": 190672, "start": 1906.72, "end": 1911.68, "text": " with logic programming and prologue or mini-canon or something like that, you've seen this before,", "tokens": [50364, 365, 9952, 9410, 293, 447, 4987, 622, 420, 8382, 12, 7035, 266, 420, 746, 411, 300, 11, 291, 600, 1612, 341, 949, 11, 50612], "temperature": 0.0, "avg_logprob": -0.18478824124477877, "compression_ratio": 1.7162162162162162, "no_speech_prob": 0.002115543931722641}, {"id": 285, "seek": 190672, "start": 1911.68, "end": 1917.92, "text": " things like a pen. That's a standard answer or a standard program. But we didn't write a pen in", "tokens": [50612, 721, 411, 257, 3435, 13, 663, 311, 257, 3832, 1867, 420, 257, 3832, 1461, 13, 583, 321, 994, 380, 2464, 257, 3435, 294, 50924], "temperature": 0.0, "avg_logprob": -0.18478824124477877, "compression_ratio": 1.7162162162162162, "no_speech_prob": 0.002115543931722641}, {"id": 286, "seek": 190672, "start": 1919.3600000000001, "end": 1924.0, "text": " mini-canon or prologue. We wrote a pen in scheme. We'd get the relationality through the relational", "tokens": [50996, 8382, 12, 7035, 266, 420, 447, 4987, 622, 13, 492, 4114, 257, 3435, 294, 12232, 13, 492, 1116, 483, 264, 38444, 507, 807, 264, 38444, 51228], "temperature": 0.0, "avg_logprob": -0.18478824124477877, "compression_ratio": 1.7162162162162162, "no_speech_prob": 0.002115543931722641}, {"id": 287, "seek": 190672, "start": 1924.0, "end": 1929.44, "text": " interpreter. All right. What else can we do? Where else can we put variable? How about", "tokens": [51228, 34132, 13, 1057, 558, 13, 708, 1646, 393, 321, 360, 30, 2305, 1646, 393, 321, 829, 7006, 30, 1012, 466, 51500], "temperature": 0.0, "avg_logprob": -0.18478824124477877, "compression_ratio": 1.7162162162162162, "no_speech_prob": 0.002115543931722641}, {"id": 288, "seek": 192944, "start": 1930.16, "end": 1936.96, "text": " if we put a variable inside the code? What if I put a variable where the s is?", "tokens": [50400, 498, 321, 829, 257, 7006, 1854, 264, 3089, 30, 708, 498, 286, 829, 257, 7006, 689, 264, 262, 307, 30, 50740], "temperature": 0.0, "avg_logprob": -0.2411351264277591, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0029808394610881805}, {"id": 289, "seek": 192944, "start": 1939.28, "end": 1948.56, "text": " Okay. That used to be the symbol s. What should I get back? I get back the s, right? So I could", "tokens": [50856, 1033, 13, 663, 1143, 281, 312, 264, 5986, 262, 13, 708, 820, 286, 483, 646, 30, 286, 483, 646, 264, 262, 11, 558, 30, 407, 286, 727, 51320], "temperature": 0.0, "avg_logprob": -0.2411351264277591, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0029808394610881805}, {"id": 290, "seek": 192944, "start": 1948.56, "end": 1956.0, "text": " also replace it here, like the car of L. Oh, I got two... I was doing a run two.", "tokens": [51320, 611, 7406, 309, 510, 11, 411, 264, 1032, 295, 441, 13, 876, 11, 286, 658, 732, 485, 286, 390, 884, 257, 1190, 732, 13, 51692], "temperature": 0.0, "avg_logprob": -0.2411351264277591, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0029808394610881805}, {"id": 291, "seek": 195600, "start": 1956.96, "end": 1962.48, "text": " Yeah. So I got car of L and another expression, which is the same as car of L, equivalent to it.", "tokens": [50412, 865, 13, 407, 286, 658, 1032, 295, 441, 293, 1071, 6114, 11, 597, 307, 264, 912, 382, 1032, 295, 441, 11, 10344, 281, 309, 13, 50688], "temperature": 0.0, "avg_logprob": -0.13183271408081054, "compression_ratio": 1.506122448979592, "no_speech_prob": 0.00029593572253361344}, {"id": 292, "seek": 195600, "start": 1963.2, "end": 1969.92, "text": " All right. Now, I could show you much, much more. If you're interested in that sort of thing,", "tokens": [50724, 1057, 558, 13, 823, 11, 286, 727, 855, 291, 709, 11, 709, 544, 13, 759, 291, 434, 3102, 294, 300, 1333, 295, 551, 11, 51060], "temperature": 0.0, "avg_logprob": -0.13183271408081054, "compression_ratio": 1.506122448979592, "no_speech_prob": 0.00029593572253361344}, {"id": 293, "seek": 195600, "start": 1969.92, "end": 1978.0, "text": " I recommend you look at our paper in ICFP 2017. But I just want to show you what happens if you", "tokens": [51060, 286, 2748, 291, 574, 412, 527, 3035, 294, 14360, 45882, 6591, 13, 583, 286, 445, 528, 281, 855, 291, 437, 2314, 498, 291, 51464], "temperature": 0.0, "avg_logprob": -0.13183271408081054, "compression_ratio": 1.506122448979592, "no_speech_prob": 0.00029593572253361344}, {"id": 294, "seek": 195600, "start": 1979.36, "end": 1984.16, "text": " sort of put an interface on this. And you also speed up the naive version by about", "tokens": [51532, 1333, 295, 829, 364, 9226, 322, 341, 13, 400, 291, 611, 3073, 493, 264, 29052, 3037, 538, 466, 51772], "temperature": 0.0, "avg_logprob": -0.13183271408081054, "compression_ratio": 1.506122448979592, "no_speech_prob": 0.00029593572253361344}, {"id": 295, "seek": 198416, "start": 1984.16, "end": 1989.68, "text": " nine orders of magnitude, because that's what we've done. Michael Valentine and Greg Rosenblatt", "tokens": [50364, 4949, 9470, 295, 15668, 11, 570, 300, 311, 437, 321, 600, 1096, 13, 5116, 24359, 293, 11490, 33630, 5199, 1591, 50640], "temperature": 0.0, "avg_logprob": -0.09153984304060016, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.00036825588904321194}, {"id": 296, "seek": 198416, "start": 1989.68, "end": 1996.3200000000002, "text": " have been speeding up the system. So Greg gave us eight orders of magnitude in", "tokens": [50640, 362, 668, 35593, 493, 264, 1185, 13, 407, 11490, 2729, 505, 3180, 9470, 295, 15668, 294, 50972], "temperature": 0.0, "avg_logprob": -0.09153984304060016, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.00036825588904321194}, {"id": 297, "seek": 198416, "start": 1997.1200000000001, "end": 2001.6000000000001, "text": " eight months or something. So now what we're going to do is we're going to do some program", "tokens": [51012, 3180, 2493, 420, 746, 13, 407, 586, 437, 321, 434, 516, 281, 360, 307, 321, 434, 516, 281, 360, 512, 1461, 51236], "temperature": 0.0, "avg_logprob": -0.09153984304060016, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.00036825588904321194}, {"id": 298, "seek": 198416, "start": 2001.6000000000001, "end": 2007.44, "text": " synthesis. So this... What's happening underneath the hood is we're just generating calls to our", "tokens": [51236, 30252, 13, 407, 341, 485, 708, 311, 2737, 7223, 264, 13376, 307, 321, 434, 445, 17746, 5498, 281, 527, 51528], "temperature": 0.0, "avg_logprob": -0.09153984304060016, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.00036825588904321194}, {"id": 299, "seek": 198416, "start": 2007.44, "end": 2012.64, "text": " Valo. We're doing example-based program synthesis. So here I have a call to a pen. I've got a", "tokens": [51528, 7188, 78, 13, 492, 434, 884, 1365, 12, 6032, 1461, 30252, 13, 407, 510, 286, 362, 257, 818, 281, 257, 3435, 13, 286, 600, 658, 257, 51788], "temperature": 0.0, "avg_logprob": -0.09153984304060016, "compression_ratio": 1.8023715415019763, "no_speech_prob": 0.00036825588904321194}, {"id": 300, "seek": 201264, "start": 2012.64, "end": 2017.3600000000001, "text": " fragment of the append definition, the comma A, comma B, comma C. Those are logic variables", "tokens": [50364, 26424, 295, 264, 34116, 7123, 11, 264, 22117, 316, 11, 22117, 363, 11, 22117, 383, 13, 3950, 366, 9952, 9102, 50600], "temperature": 0.0, "avg_logprob": -0.15478595610587828, "compression_ratio": 1.6319444444444444, "no_speech_prob": 5.8288958825869486e-05}, {"id": 301, "seek": 201264, "start": 2017.3600000000001, "end": 2021.2800000000002, "text": " representing holes in our program. And you can see at the bottom that Barleman's trying to figure out", "tokens": [50600, 13460, 8118, 294, 527, 1461, 13, 400, 291, 393, 536, 412, 264, 2767, 300, 4156, 306, 1601, 311, 1382, 281, 2573, 484, 50796], "temperature": 0.0, "avg_logprob": -0.15478595610587828, "compression_ratio": 1.6319444444444444, "no_speech_prob": 5.8288958825869486e-05}, {"id": 302, "seek": 201264, "start": 2022.88, "end": 2030.72, "text": " what we have. I can do this in various ways, but one way I might want to do it to try to keep", "tokens": [50876, 437, 321, 362, 13, 286, 393, 360, 341, 294, 3683, 2098, 11, 457, 472, 636, 286, 1062, 528, 281, 360, 309, 281, 853, 281, 1066, 51268], "temperature": 0.0, "avg_logprob": -0.15478595610587828, "compression_ratio": 1.6319444444444444, "no_speech_prob": 5.8288958825869486e-05}, {"id": 303, "seek": 201264, "start": 2031.3600000000001, "end": 2036.5600000000002, "text": " the system from over-specializing is to use these G1, G2 things, which sort of represent", "tokens": [51300, 264, 1185, 490, 670, 12, 7053, 1013, 3319, 307, 281, 764, 613, 460, 16, 11, 460, 17, 721, 11, 597, 1333, 295, 2906, 51560], "temperature": 0.0, "avg_logprob": -0.15478595610587828, "compression_ratio": 1.6319444444444444, "no_speech_prob": 5.8288958825869486e-05}, {"id": 304, "seek": 201264, "start": 2036.5600000000002, "end": 2040.8000000000002, "text": " universally quantified variables, if you want to think of that way, or sort of like Jenssen's", "tokens": [51560, 43995, 4426, 2587, 9102, 11, 498, 291, 528, 281, 519, 295, 300, 636, 11, 420, 1333, 295, 411, 508, 694, 6748, 311, 51772], "temperature": 0.0, "avg_logprob": -0.15478595610587828, "compression_ratio": 1.6319444444444444, "no_speech_prob": 5.8288958825869486e-05}, {"id": 305, "seek": 204080, "start": 2041.2, "end": 2046.3999999999999, "text": " skull invariables. So I don't quite have enough structure. So let me try one more example.", "tokens": [50384, 11743, 33270, 2965, 13, 407, 286, 500, 380, 1596, 362, 1547, 3877, 13, 407, 718, 385, 853, 472, 544, 1365, 13, 50644], "temperature": 0.0, "avg_logprob": -0.2182240999661959, "compression_ratio": 1.3850931677018634, "no_speech_prob": 0.0007321499288082123}, {"id": 306, "seek": 204080, "start": 2057.6, "end": 2059.7599999999998, "text": " Okay. Let that think for a minute.", "tokens": [51204, 1033, 13, 961, 300, 519, 337, 257, 3456, 13, 51312], "temperature": 0.0, "avg_logprob": -0.2182240999661959, "compression_ratio": 1.3850931677018634, "no_speech_prob": 0.0007321499288082123}, {"id": 307, "seek": 204080, "start": 2065.2799999999997, "end": 2070.64, "text": " Okay. Now it's figured out the recursion. And it's a little hard to read it. So I'm going to just", "tokens": [51588, 1033, 13, 823, 309, 311, 8932, 484, 264, 20560, 313, 13, 400, 309, 311, 257, 707, 1152, 281, 1401, 309, 13, 407, 286, 478, 516, 281, 445, 51856], "temperature": 0.0, "avg_logprob": -0.2182240999661959, "compression_ratio": 1.3850931677018634, "no_speech_prob": 0.0007321499288082123}, {"id": 308, "seek": 207064, "start": 2070.64, "end": 2080.48, "text": " put in variable names, concrete variable names. And now you can see, you can read a little more.", "tokens": [50364, 829, 294, 7006, 5288, 11, 9859, 7006, 5288, 13, 400, 586, 291, 393, 536, 11, 291, 393, 1401, 257, 707, 544, 13, 50856], "temperature": 0.0, "avg_logprob": -0.15640817929620612, "compression_ratio": 1.4791666666666667, "no_speech_prob": 9.914710244629532e-05}, {"id": 309, "seek": 207064, "start": 2080.48, "end": 2085.44, "text": " And if you know scheme, this is the correct definition of a pen. Okay. So what's happened?", "tokens": [50856, 400, 498, 291, 458, 12232, 11, 341, 307, 264, 3006, 7123, 295, 257, 3435, 13, 1033, 13, 407, 437, 311, 2011, 30, 51104], "temperature": 0.0, "avg_logprob": -0.15640817929620612, "compression_ratio": 1.4791666666666667, "no_speech_prob": 9.914710244629532e-05}, {"id": 310, "seek": 207064, "start": 2085.44, "end": 2094.72, "text": " We've taken minicanron. We've implemented the semantics written in something similar to the CMS,", "tokens": [51104, 492, 600, 2726, 923, 8914, 2044, 13, 492, 600, 12270, 264, 4361, 45298, 3720, 294, 746, 2531, 281, 264, 33124, 11, 51568], "temperature": 0.0, "avg_logprob": -0.15640817929620612, "compression_ratio": 1.4791666666666667, "no_speech_prob": 9.914710244629532e-05}, {"id": 311, "seek": 209472, "start": 2095.68, "end": 2102.8799999999997, "text": " computer science meta, or is it CMN? Whatever it's called. The computer science meta notation or", "tokens": [50412, 3820, 3497, 19616, 11, 420, 307, 309, 20424, 45, 30, 8541, 309, 311, 1219, 13, 440, 3820, 3497, 19616, 24657, 420, 50772], "temperature": 0.0, "avg_logprob": -0.1438599395751953, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.0007321297889575362}, {"id": 312, "seek": 209472, "start": 2102.8799999999997, "end": 2113.9199999999996, "text": " whatever. Okay. Something like that. And through some cleverness on the back end, which we're hoping", "tokens": [50772, 2035, 13, 1033, 13, 6595, 411, 300, 13, 400, 807, 512, 13494, 1287, 322, 264, 646, 917, 11, 597, 321, 434, 7159, 51324], "temperature": 0.0, "avg_logprob": -0.1438599395751953, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.0007321297889575362}, {"id": 313, "seek": 209472, "start": 2113.9199999999996, "end": 2120.08, "text": " to generalize, so it's not just for our interpreter, but we'll work with a wider range of semantics", "tokens": [51324, 281, 2674, 1125, 11, 370, 309, 311, 406, 445, 337, 527, 34132, 11, 457, 321, 603, 589, 365, 257, 11842, 3613, 295, 4361, 45298, 51632], "temperature": 0.0, "avg_logprob": -0.1438599395751953, "compression_ratio": 1.4630541871921183, "no_speech_prob": 0.0007321297889575362}, {"id": 314, "seek": 212008, "start": 2120.7999999999997, "end": 2124.3199999999997, "text": " and type systems and things like that. You would just type in. We can also do this for", "tokens": [50400, 293, 2010, 3652, 293, 721, 411, 300, 13, 509, 576, 445, 2010, 294, 13, 492, 393, 611, 360, 341, 337, 50576], "temperature": 0.0, "avg_logprob": -0.09323323359254931, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.0026309909299016}, {"id": 315, "seek": 212008, "start": 2124.3199999999997, "end": 2129.6, "text": " grammars, regular expressions, and so forth. We're able to get to the point where we can just type", "tokens": [50576, 17570, 685, 11, 3890, 15277, 11, 293, 370, 5220, 13, 492, 434, 1075, 281, 483, 281, 264, 935, 689, 321, 393, 445, 2010, 50840], "temperature": 0.0, "avg_logprob": -0.09323323359254931, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.0026309909299016}, {"id": 316, "seek": 212008, "start": 2129.6, "end": 2136.72, "text": " in input-output examples, and the system is able to do recursive, higher-order synthesis for our", "tokens": [50840, 294, 4846, 12, 346, 2582, 5110, 11, 293, 264, 1185, 307, 1075, 281, 360, 20560, 488, 11, 2946, 12, 4687, 30252, 337, 527, 51196], "temperature": 0.0, "avg_logprob": -0.09323323359254931, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.0026309909299016}, {"id": 317, "seek": 212008, "start": 2136.72, "end": 2142.3199999999997, "text": " subset of scheme. We can also write type inferences in this way. So I'm hoping we can combine those.", "tokens": [51196, 25993, 295, 12232, 13, 492, 393, 611, 2464, 2010, 13596, 2667, 294, 341, 636, 13, 407, 286, 478, 7159, 321, 393, 10432, 729, 13, 51476], "temperature": 0.0, "avg_logprob": -0.09323323359254931, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.0026309909299016}, {"id": 318, "seek": 212008, "start": 2142.3199999999997, "end": 2146.24, "text": " We'd write type inferences in the same way. We'd write the operational semantics for the", "tokens": [51476, 492, 1116, 2464, 2010, 13596, 2667, 294, 264, 912, 636, 13, 492, 1116, 2464, 264, 16607, 4361, 45298, 337, 264, 51672], "temperature": 0.0, "avg_logprob": -0.09323323359254931, "compression_ratio": 1.8084291187739463, "no_speech_prob": 0.0026309909299016}, {"id": 319, "seek": 214624, "start": 2147.04, "end": 2151.52, "text": " evaluator. And we can also write grammars. There's also a grammar written in exactly the", "tokens": [50404, 6133, 1639, 13, 400, 321, 393, 611, 2464, 17570, 685, 13, 821, 311, 611, 257, 22317, 3720, 294, 2293, 264, 50628], "temperature": 0.0, "avg_logprob": -0.08996388035961705, "compression_ratio": 1.7933579335793357, "no_speech_prob": 9.314147609984502e-05}, {"id": 320, "seek": 214624, "start": 2151.52, "end": 2156.56, "text": " same style underneath this. So we can do grammars. We can generate expressions in exactly the same", "tokens": [50628, 912, 3758, 7223, 341, 13, 407, 321, 393, 360, 17570, 685, 13, 492, 393, 8460, 15277, 294, 2293, 264, 912, 50880], "temperature": 0.0, "avg_logprob": -0.08996388035961705, "compression_ratio": 1.7933579335793357, "no_speech_prob": 9.314147609984502e-05}, {"id": 321, "seek": 214624, "start": 2156.56, "end": 2164.72, "text": " way. So I'm hoping as we improve this technology that we'll get closer and closer, I don't think we'll", "tokens": [50880, 636, 13, 407, 286, 478, 7159, 382, 321, 3470, 341, 2899, 300, 321, 603, 483, 4966, 293, 4966, 11, 286, 500, 380, 519, 321, 603, 51288], "temperature": 0.0, "avg_logprob": -0.08996388035961705, "compression_ratio": 1.7933579335793357, "no_speech_prob": 9.314147609984502e-05}, {"id": 322, "seek": 214624, "start": 2164.72, "end": 2170.16, "text": " ever get there perfectly, but we'll get closer and closer to being able to be naive and just take", "tokens": [51288, 1562, 483, 456, 6239, 11, 457, 321, 603, 483, 4966, 293, 4966, 281, 885, 1075, 281, 312, 29052, 293, 445, 747, 51560], "temperature": 0.0, "avg_logprob": -0.08996388035961705, "compression_ratio": 1.7933579335793357, "no_speech_prob": 9.314147609984502e-05}, {"id": 323, "seek": 214624, "start": 2170.16, "end": 2175.68, "text": " a paper or some operational semantics or typing judgments or whatever, just type it in, hopefully", "tokens": [51560, 257, 3035, 420, 512, 16607, 4361, 45298, 420, 18444, 40337, 420, 2035, 11, 445, 2010, 309, 294, 11, 4696, 51836], "temperature": 0.0, "avg_logprob": -0.08996388035961705, "compression_ratio": 1.7933579335793357, "no_speech_prob": 9.314147609984502e-05}, {"id": 324, "seek": 217568, "start": 2175.68, "end": 2182.3999999999996, "text": " with a nicer syntax, and then be able to start exploring this world and asking queries that", "tokens": [50364, 365, 257, 22842, 28431, 11, 293, 550, 312, 1075, 281, 722, 12736, 341, 1002, 293, 3365, 24109, 300, 50700], "temperature": 0.0, "avg_logprob": -0.10749163870084083, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.0011689465027302504}, {"id": 325, "seek": 217568, "start": 2183.12, "end": 2189.6, "text": " maybe other people haven't thought of before or just being surprised. That's the best part for me.", "tokens": [50736, 1310, 661, 561, 2378, 380, 1194, 295, 949, 420, 445, 885, 6100, 13, 663, 311, 264, 1151, 644, 337, 385, 13, 51060], "temperature": 0.0, "avg_logprob": -0.10749163870084083, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.0011689465027302504}, {"id": 326, "seek": 217568, "start": 2189.6, "end": 2193.68, "text": " That's why I like Doug's math aquarium. It would surprise you. And that's why I like playing around", "tokens": [51060, 663, 311, 983, 286, 411, 12742, 311, 5221, 30149, 13, 467, 576, 6365, 291, 13, 400, 300, 311, 983, 286, 411, 2433, 926, 51264], "temperature": 0.0, "avg_logprob": -0.10749163870084083, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.0011689465027302504}, {"id": 327, "seek": 217568, "start": 2193.68, "end": 2197.7599999999998, "text": " with mini-canner. There's things like quines that surprise me. There are all sorts of programs that", "tokens": [51264, 365, 8382, 12, 66, 9805, 13, 821, 311, 721, 411, 421, 1652, 300, 6365, 385, 13, 821, 366, 439, 7527, 295, 4268, 300, 51468], "temperature": 0.0, "avg_logprob": -0.10749163870084083, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.0011689465027302504}, {"id": 328, "seek": 217568, "start": 2197.7599999999998, "end": 2203.04, "text": " we're generating that surprise me. I didn't think it would be either possible or I had a different", "tokens": [51468, 321, 434, 17746, 300, 6365, 385, 13, 286, 994, 380, 519, 309, 576, 312, 2139, 1944, 420, 286, 632, 257, 819, 51732], "temperature": 0.0, "avg_logprob": -0.10749163870084083, "compression_ratio": 1.7402135231316727, "no_speech_prob": 0.0011689465027302504}, {"id": 329, "seek": 220304, "start": 2203.04, "end": 2207.36, "text": " idea of which program would meet a certain specification, and mini-canner said, hey, this", "tokens": [50364, 1558, 295, 597, 1461, 576, 1677, 257, 1629, 31256, 11, 293, 8382, 12, 66, 9805, 848, 11, 4177, 11, 341, 50580], "temperature": 0.0, "avg_logprob": -0.12818527221679688, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.00037992207217030227}, {"id": 330, "seek": 220304, "start": 2207.36, "end": 2214.8, "text": " program meets it also, often sort of trolling me in the process. So anyway, this is lollipop", "tokens": [50580, 1461, 13961, 309, 611, 11, 2049, 1333, 295, 4495, 2669, 385, 294, 264, 1399, 13, 407, 4033, 11, 341, 307, 450, 285, 647, 404, 50952], "temperature": 0.0, "avg_logprob": -0.12818527221679688, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.00037992207217030227}, {"id": 331, "seek": 220304, "start": 2214.8, "end": 2220.4, "text": " driven development, if you will, where you just type the semantics, sort of like you'd read in the", "tokens": [50952, 9555, 3250, 11, 498, 291, 486, 11, 689, 291, 445, 2010, 264, 4361, 45298, 11, 1333, 295, 411, 291, 1116, 1401, 294, 264, 51232], "temperature": 0.0, "avg_logprob": -0.12818527221679688, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.00037992207217030227}, {"id": 332, "seek": 220304, "start": 2220.4, "end": 2225.84, "text": " paper, write down examples, maybe write down types and things like that, get the system to fill in", "tokens": [51232, 3035, 11, 2464, 760, 5110, 11, 1310, 2464, 760, 3467, 293, 721, 411, 300, 11, 483, 264, 1185, 281, 2836, 294, 51504], "temperature": 0.0, "avg_logprob": -0.12818527221679688, "compression_ratio": 1.6521739130434783, "no_speech_prob": 0.00037992207217030227}, {"id": 333, "seek": 222584, "start": 2225.84, "end": 2235.1200000000003, "text": " the unknowns for you in an exploratory way. So that's basically what Dan should have told me.", "tokens": [50364, 264, 46048, 337, 291, 294, 364, 24765, 4745, 636, 13, 407, 300, 311, 1936, 437, 3394, 820, 362, 1907, 385, 13, 50828], "temperature": 0.0, "avg_logprob": -0.10979848158986945, "compression_ratio": 1.453125, "no_speech_prob": 0.009706287644803524}, {"id": 334, "seek": 222584, "start": 2235.1200000000003, "end": 2241.76, "text": " He should have said, well, eight years from now, Guy Steele will give a keynote at CodeMesh,", "tokens": [50828, 634, 820, 362, 848, 11, 731, 11, 3180, 924, 490, 586, 11, 14690, 745, 1653, 306, 486, 976, 257, 33896, 412, 15549, 44, 14935, 11, 51160], "temperature": 0.0, "avg_logprob": -0.10979848158986945, "compression_ratio": 1.453125, "no_speech_prob": 0.009706287644803524}, {"id": 335, "seek": 222584, "start": 2242.6400000000003, "end": 2249.2000000000003, "text": " and at that point, we want to be able to type in those rules and just have it do things like", "tokens": [51204, 293, 412, 300, 935, 11, 321, 528, 281, 312, 1075, 281, 2010, 294, 729, 4474, 293, 445, 362, 309, 360, 721, 411, 51532], "temperature": 0.0, "avg_logprob": -0.10979848158986945, "compression_ratio": 1.453125, "no_speech_prob": 0.009706287644803524}, {"id": 336, "seek": 224920, "start": 2249.2, "end": 2256.08, "text": " and further program. So that's the idea. If you're interested in this, look at an ICFP 2017", "tokens": [50364, 293, 3052, 1461, 13, 407, 300, 311, 264, 1558, 13, 759, 291, 434, 3102, 294, 341, 11, 574, 412, 364, 14360, 45882, 6591, 50708], "temperature": 0.0, "avg_logprob": -0.17888238555506655, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.022825179621577263}, {"id": 337, "seek": 224920, "start": 2256.08, "end": 2262.24, "text": " paper, go to mini-canron.org, look at the paper on micro-canron, which shows an implementation", "tokens": [50708, 3035, 11, 352, 281, 8382, 12, 7035, 2044, 13, 4646, 11, 574, 412, 264, 3035, 322, 4532, 12, 7035, 2044, 11, 597, 3110, 364, 11420, 51016], "temperature": 0.0, "avg_logprob": -0.17888238555506655, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.022825179621577263}, {"id": 338, "seek": 224920, "start": 2262.24, "end": 2267.04, "text": " of a simple version, and look for the second edition of the Reason Schemer, which is about", "tokens": [51016, 295, 257, 2199, 3037, 11, 293, 574, 337, 264, 1150, 11377, 295, 264, 39693, 2065, 29660, 11, 597, 307, 466, 51256], "temperature": 0.0, "avg_logprob": -0.17888238555506655, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.022825179621577263}, {"id": 339, "seek": 226704, "start": 2267.04, "end": 2279.2799999999997, "text": " to come out. Thank you. Well, we actually have two minutes left. I think this is the first for", "tokens": [50364, 281, 808, 484, 13, 1044, 291, 13, 1042, 11, 321, 767, 362, 732, 2077, 1411, 13, 286, 519, 341, 307, 264, 700, 337, 50976], "temperature": 0.0, "avg_logprob": -0.15458961769386573, "compression_ratio": 1.0930232558139534, "no_speech_prob": 0.001829581568017602}, {"id": 340, "seek": 227928, "start": 2279.28, "end": 2299.44, "text": " you, Will, so we can take a question if you want. So the second test didn't work. Could you just go", "tokens": [50364, 291, 11, 3099, 11, 370, 321, 393, 747, 257, 1168, 498, 291, 528, 13, 407, 264, 1150, 1500, 994, 380, 589, 13, 7497, 291, 445, 352, 51372], "temperature": 0.0, "avg_logprob": -0.21600629602159774, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.008148728869855404}, {"id": 341, "seek": 227928, "start": 2299.44, "end": 2306.0, "text": " back and do that again, but fill it in with kind of the readable symbols so we can see why. So you", "tokens": [51372, 646, 293, 360, 300, 797, 11, 457, 2836, 309, 294, 365, 733, 295, 264, 49857, 16944, 370, 321, 393, 536, 983, 13, 407, 291, 51700], "temperature": 0.0, "avg_logprob": -0.21600629602159774, "compression_ratio": 1.3943661971830985, "no_speech_prob": 0.008148728869855404}, {"id": 342, "seek": 230600, "start": 2306.32, "end": 2311.6, "text": " want this one? Yeah. Well, the second one did work in a sense. It depends what you mean by work.", "tokens": [50380, 528, 341, 472, 30, 865, 13, 1042, 11, 264, 1150, 472, 630, 589, 294, 257, 2020, 13, 467, 5946, 437, 291, 914, 538, 589, 13, 50644], "temperature": 0.0, "avg_logprob": -0.15146608352661134, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.014949989505112171}, {"id": 343, "seek": 230600, "start": 2312.16, "end": 2319.52, "text": " So the mini-canron or Barleman's idea is prove me wrong, right? So this program", "tokens": [50672, 407, 264, 8382, 12, 7035, 2044, 420, 4156, 306, 1601, 311, 1558, 307, 7081, 385, 2085, 11, 558, 30, 407, 341, 1461, 51040], "temperature": 0.0, "avg_logprob": -0.15146608352661134, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.014949989505112171}, {"id": 344, "seek": 230600, "start": 2319.52, "end": 2324.4, "text": " absolutely matches that specification, but you're right that it's not what we had in mind, and this", "tokens": [51040, 3122, 10676, 300, 31256, 11, 457, 291, 434, 558, 300, 309, 311, 406, 437, 321, 632, 294, 1575, 11, 293, 341, 51284], "temperature": 0.0, "avg_logprob": -0.15146608352661134, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.014949989505112171}, {"id": 345, "seek": 230600, "start": 2324.4, "end": 2330.32, "text": " is part of the problem, right? So even if you can imagine Barleman being 500 orders of magnitude", "tokens": [51284, 307, 644, 295, 264, 1154, 11, 558, 30, 407, 754, 498, 291, 393, 3811, 4156, 306, 1601, 885, 5923, 9470, 295, 15668, 51580], "temperature": 0.0, "avg_logprob": -0.15146608352661134, "compression_ratio": 1.5672268907563025, "no_speech_prob": 0.014949989505112171}, {"id": 346, "seek": 233032, "start": 2330.32, "end": 2336.6400000000003, "text": " faster, and in some sense it solves program census by example, in another sense you still", "tokens": [50364, 4663, 11, 293, 294, 512, 2020, 309, 39890, 1461, 23725, 538, 1365, 11, 294, 1071, 2020, 291, 920, 50680], "temperature": 0.0, "avg_logprob": -0.10376912813920242, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.01280526164919138}, {"id": 347, "seek": 233032, "start": 2336.6400000000003, "end": 2342.32, "text": " have the problem of writing down a specification that is complete enough and correct enough", "tokens": [50680, 362, 264, 1154, 295, 3579, 760, 257, 31256, 300, 307, 3566, 1547, 293, 3006, 1547, 50964], "temperature": 0.0, "avg_logprob": -0.10376912813920242, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.01280526164919138}, {"id": 348, "seek": 233032, "start": 2342.32, "end": 2347.1200000000003, "text": " that you're going to get the right output, even if we're much, much faster, right? So this shows", "tokens": [50964, 300, 291, 434, 516, 281, 483, 264, 558, 5598, 11, 754, 498, 321, 434, 709, 11, 709, 4663, 11, 558, 30, 407, 341, 3110, 51204], "temperature": 0.0, "avg_logprob": -0.10376912813920242, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.01280526164919138}, {"id": 349, "seek": 233032, "start": 2347.1200000000003, "end": 2351.36, "text": " that census really has at least two problems. One is the speed problem of dealing with this", "tokens": [51204, 300, 23725, 534, 575, 412, 1935, 732, 2740, 13, 1485, 307, 264, 3073, 1154, 295, 6260, 365, 341, 51416], "temperature": 0.0, "avg_logprob": -0.10376912813920242, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.01280526164919138}, {"id": 350, "seek": 233032, "start": 2351.36, "end": 2355.44, "text": " exponential space and dealing with, you know, synthesizing programs that could go in infant", "tokens": [51416, 21510, 1901, 293, 6260, 365, 11, 291, 458, 11, 26617, 3319, 4268, 300, 727, 352, 294, 16757, 51620], "temperature": 0.0, "avg_logprob": -0.10376912813920242, "compression_ratio": 1.7303370786516854, "no_speech_prob": 0.01280526164919138}, {"id": 351, "seek": 235544, "start": 2355.44, "end": 2361.04, "text": " loops, but there's also the specification problem. So how did you know what to type in the box labeled", "tokens": [50364, 16121, 11, 457, 456, 311, 611, 264, 31256, 1154, 13, 407, 577, 630, 291, 458, 437, 281, 2010, 294, 264, 2424, 21335, 50644], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 352, "seek": 235544, "start": 2361.04, "end": 2367.12, "text": " test three? How do you know what to type in there? Well, so that's a good question. There are", "tokens": [50644, 1500, 1045, 30, 1012, 360, 291, 458, 437, 281, 2010, 294, 456, 30, 1042, 11, 370, 300, 311, 257, 665, 1168, 13, 821, 366, 50948], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 353, "seek": 235544, "start": 2367.12, "end": 2371.2000000000003, "text": " different ways to give a specification. So you could write types, right? We don't currently", "tokens": [50948, 819, 2098, 281, 976, 257, 31256, 13, 407, 291, 727, 2464, 3467, 11, 558, 30, 492, 500, 380, 4362, 51152], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 354, "seek": 235544, "start": 2371.2000000000003, "end": 2375.04, "text": " support that, but you could write types, you could write examples, you could write properties,", "tokens": [51152, 1406, 300, 11, 457, 291, 727, 2464, 3467, 11, 291, 727, 2464, 5110, 11, 291, 727, 2464, 7221, 11, 51344], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 355, "seek": 235544, "start": 2375.04, "end": 2379.44, "text": " high-level properties, right? The other thing you can do, which I didn't show you, is that this is", "tokens": [51344, 1090, 12, 12418, 7221, 11, 558, 30, 440, 661, 551, 291, 393, 360, 11, 597, 286, 994, 380, 855, 291, 11, 307, 300, 341, 307, 51564], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 356, "seek": 235544, "start": 2379.44, "end": 2384.4, "text": " an IDE, so you can edit the code. So you can be writing some of the code and writing some of the", "tokens": [51564, 364, 40930, 11, 370, 291, 393, 8129, 264, 3089, 13, 407, 291, 393, 312, 3579, 512, 295, 264, 3089, 293, 3579, 512, 295, 264, 51812], "temperature": 0.0, "avg_logprob": -0.08400148274947186, "compression_ratio": 1.9965517241379311, "no_speech_prob": 0.0038230777718126774}, {"id": 357, "seek": 238440, "start": 2384.4, "end": 2388.8, "text": " tests and writing some of the types, and it's going to fill in the rest for you. So you could also", "tokens": [50364, 6921, 293, 3579, 512, 295, 264, 3467, 11, 293, 309, 311, 516, 281, 2836, 294, 264, 1472, 337, 291, 13, 407, 291, 727, 611, 50584], "temperature": 0.0, "avg_logprob": -0.08426794611421742, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00013535592006519437}, {"id": 358, "seek": 238440, "start": 2388.8, "end": 2393.52, "text": " use it as sort of like an IDE. But at some point, if you don't know what the program should do", "tokens": [50584, 764, 309, 382, 1333, 295, 411, 364, 40930, 13, 583, 412, 512, 935, 11, 498, 291, 500, 380, 458, 437, 264, 1461, 820, 360, 50820], "temperature": 0.0, "avg_logprob": -0.08426794611421742, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00013535592006519437}, {"id": 359, "seek": 238440, "start": 2394.64, "end": 2398.4, "text": " and you don't know any of the code, it's not going to figure that out for you. So you're going to", "tokens": [50876, 293, 291, 500, 380, 458, 604, 295, 264, 3089, 11, 309, 311, 406, 516, 281, 2573, 300, 484, 337, 291, 13, 407, 291, 434, 516, 281, 51064], "temperature": 0.0, "avg_logprob": -0.08426794611421742, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00013535592006519437}, {"id": 360, "seek": 238440, "start": 2398.4, "end": 2404.8, "text": " have to do a little work. You know, even with my example, my stupid box example, I still had to", "tokens": [51064, 362, 281, 360, 257, 707, 589, 13, 509, 458, 11, 754, 365, 452, 1365, 11, 452, 6631, 2424, 1365, 11, 286, 920, 632, 281, 51384], "temperature": 0.0, "avg_logprob": -0.08426794611421742, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00013535592006519437}, {"id": 361, "seek": 238440, "start": 2404.8, "end": 2409.6800000000003, "text": " figure out that I wanted a box that was two inches by two inches, right? So yes. Thank you.", "tokens": [51384, 2573, 484, 300, 286, 1415, 257, 2424, 300, 390, 732, 8478, 538, 732, 8478, 11, 558, 30, 407, 2086, 13, 1044, 291, 13, 51628], "temperature": 0.0, "avg_logprob": -0.08426794611421742, "compression_ratio": 1.7806691449814127, "no_speech_prob": 0.00013535592006519437}, {"id": 362, "seek": 240968, "start": 2410.64, "end": 2414.7999999999997, "text": " So basically, this is automated TDD, isn't it?", "tokens": [50412, 407, 1936, 11, 341, 307, 18473, 314, 20818, 11, 1943, 380, 309, 30, 50620], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 363, "seek": 240968, "start": 2415.6, "end": 2421.8399999999997, "text": " That's part of it, but the reason I gave that intro is the problem is every time I give a talk,", "tokens": [50660, 663, 311, 644, 295, 309, 11, 457, 264, 1778, 286, 2729, 300, 12897, 307, 264, 1154, 307, 633, 565, 286, 976, 257, 751, 11, 50972], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 364, "seek": 240968, "start": 2421.8399999999997, "end": 2425.68, "text": " and I've given many variants of this talk, every single time I give a talk, someone comes away", "tokens": [50972, 293, 286, 600, 2212, 867, 21669, 295, 341, 751, 11, 633, 2167, 565, 286, 976, 257, 751, 11, 1580, 1487, 1314, 51164], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 365, "seek": 240968, "start": 2425.68, "end": 2430.0, "text": " thinking, oh, well, so your research is on program census, or your research is on test-driven", "tokens": [51164, 1953, 11, 1954, 11, 731, 11, 370, 428, 2132, 307, 322, 1461, 23725, 11, 420, 428, 2132, 307, 322, 1500, 12, 25456, 51380], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 366, "seek": 240968, "start": 2430.0, "end": 2433.44, "text": " development, or your research is on logic programming, or your research is like, no,", "tokens": [51380, 3250, 11, 420, 428, 2132, 307, 322, 9952, 9410, 11, 420, 428, 2132, 307, 411, 11, 572, 11, 51552], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 367, "seek": 240968, "start": 2433.44, "end": 2439.3599999999997, "text": " no, that's not it. The research is on lollipops, okay? The research is on lollipops and being able", "tokens": [51552, 572, 11, 300, 311, 406, 309, 13, 440, 2132, 307, 322, 450, 285, 647, 3370, 11, 1392, 30, 440, 2132, 307, 322, 450, 285, 647, 3370, 293, 885, 1075, 51848], "temperature": 0.0, "avg_logprob": -0.1477039283049022, "compression_ratio": 1.9731800766283525, "no_speech_prob": 0.0008494912181049585}, {"id": 368, "seek": 243936, "start": 2439.36, "end": 2444.2400000000002, "text": " to sort of do things like just write down the rules and explore it, okay? That's really what", "tokens": [50364, 281, 1333, 295, 360, 721, 411, 445, 2464, 760, 264, 4474, 293, 6839, 309, 11, 1392, 30, 663, 311, 534, 437, 50608], "temperature": 0.0, "avg_logprob": -0.1140516996383667, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.0002529658086132258}, {"id": 369, "seek": 243936, "start": 2444.2400000000002, "end": 2450.08, "text": " the dream is. Program census falls out of this. Now, if we can do, if we make the system much", "tokens": [50608, 264, 3055, 307, 13, 8338, 23725, 8804, 484, 295, 341, 13, 823, 11, 498, 321, 393, 360, 11, 498, 321, 652, 264, 1185, 709, 50900], "temperature": 0.0, "avg_logprob": -0.1140516996383667, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.0002529658086132258}, {"id": 370, "seek": 243936, "start": 2450.08, "end": 2455.04, "text": " faster and we can get a useful program census tool, or a useful test-driven development tool,", "tokens": [50900, 4663, 293, 321, 393, 483, 257, 4420, 1461, 23725, 2290, 11, 420, 257, 4420, 1500, 12, 25456, 3250, 2290, 11, 51148], "temperature": 0.0, "avg_logprob": -0.1140516996383667, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.0002529658086132258}, {"id": 371, "seek": 243936, "start": 2455.04, "end": 2461.52, "text": " or a useful IDE, great. But that's only a very small part of really the overall goal.", "tokens": [51148, 420, 257, 4420, 40930, 11, 869, 13, 583, 300, 311, 787, 257, 588, 1359, 644, 295, 534, 264, 4787, 3387, 13, 51472], "temperature": 0.0, "avg_logprob": -0.1140516996383667, "compression_ratio": 1.6266666666666667, "no_speech_prob": 0.0002529658086132258}, {"id": 372, "seek": 246152, "start": 2461.52, "end": 2463.68, "text": " Thank you, Will.", "tokens": [50388, 1044, 291, 11, 3099, 13, 50472], "temperature": 0.0, "avg_logprob": -0.7641070485115051, "compression_ratio": 0.6666666666666666, "no_speech_prob": 0.00965200550854206}], "language": "en"}