{"text": " Like buses, AI news can sometimes be slow and sometimes arrive all at once. In the last few days we have had dramatic new leaked insights into the sheer breadth of Google's Gemini. Just today we've had the release of Meta's Code Lama and earlier their impressive multilingual seamless M4T model. And last but definitely not least, this 88-page AI consciousness report. And yes, I read it all, it's juicy so I'm saving that for the end. But let's start with two major paywall articles, one from the information and one from the New York Times about Google's Gemini model. From both of them I counted a total of nine new revelations, so let's get straight to it. To give you a sense of timeline, by the way, Google's newly merged AI SWOT team, they call it, is preparing for a big fall or autumn launch. The takeaway for me from both articles is that Gemini is going to be the everything model. Did you know it's going to be the rival to mid-journey and stable diffusion? Mid-journey only has 11 full-time staff, so it is more than plausible that Google's Gemini could outperform mid-journey version 5. Next we may be able to create graphics with just text descriptions and control software using only text or voice commands. These next two are speculations, so I'm not even counting them in the list of leaks. I've already covered in a previous video that Gemini has been trained on YouTube video transcripts, and the speculation is that by integrating video and audio into Gemini, it could perhaps help a mechanic diagnose a problem with a car repair based on a video, or be a rival to Runway ML by generating advanced text to video based on descriptions of what a user wants to see. You can start to see why I'm beginning to think of it as the everything model. Another leak is that one of the co-founders of Google, Sergey Brin, is working on the front lines of Google Gemini. And lastly from this article, I found it really interesting that Google's lawyers have been closely evaluating the training, and they made researchers remove training data that had come from textbooks, even though those textbooks helped the model answer questions about subjects like astronomy or biology. And I do wonder if they privately benchmarked Gemini before removing that crucial textbook data. But if that's not enough, prepare to also receive life advice. My theory here is that Google wants to compete directly for market share with inflection's pie. What if you want scientific, creative, or professional writing? Yep, they're working on that too. In fact, we already know that Google has software named Genesis that they're pitching to the New York Times, which can generate news articles, rewrite them, suggest headlines, etc. But some people will be more interested in this feature that Google DeepMind is working on, the ability to draft critiques of an argument and generate quizzes, word, and number puzzles. It's almost easier at this point to ask what might Google Gemini not be able to do. And yes, this is not Gemini, but Google DeepMind is also using AI to design the next generation of semiconductors. But if the fall seems far away, how about today when we got CodeLama from Meta? I spent much of the last two hours reading most of the 47-page paper, and you can see CodeLama in action on screen. Some highlights include that the CodeLama models provide stable generations with up to 100,000 tokens of context. Obviously, that could be used for generating longer programs or providing the model with more context from your code base to make the generations more relevant. It comes in three versions, CodeLama, CodeLama Instruct, which can better understand natural language instructions, and CodeLama Python, better, of course, at Python. It's available for commercial use, and as you can see, some of the versions rival GPT 3.5 on human eval. That top score of 53.7% on Passat 1 puts it in the same ballpark as Phi 1. I've actually done a full video on Phi 1, so do check that out, but that got 50.6%. But it is about 25 times smaller at 1.3 billion parameters. Interestingly, the CodeLama paper, which also came out about two hours ago, mentions Phi 1 directly, saying that it follows in a similar spirit, but the difference is that Phi 1 is closed source. Anyway, a couple more interesting things before we move on from CodeLama, and the first one is the self-instruct method that they used. Let me know if you also find this fascinating, because step one was to generate 62,000 interview style programming questions by prompting Lama 2, the 70 billion parameter model. Then they removed duplicates in step two. But here's where it gets interesting. For each of those questions, they first generated a unit test by prompting CodeLama 7 billion parameters. Then they generated 10 Python solutions by prompting CodeLama. Finally, they ran unit tests on those 10 solutions, and they added the first solution that passes those tests, along with the corresponding question and test, to the self-instruct data set. If that sounded a bit complicated, let me try to distill it a bit. They asked the Big Brother Lama 2 model to generate questions, then got the Little Brother CodeLama to generate tests for those questions, then got the model to generate solutions to its own tests, found the good solutions that don't forget it produced, and then used those to further train the model. To be honest, synthetic data and self-instruct seem to be the future of feedback. One final interesting quote from the paper on safety, and that was an argument advanced by one of their red teamers. They made the point that various scripts and code is readily available on mainstream public websites, hacking forums, or the dark web. And the advanced malware development is beyond the current capabilities of available LLMs. And even an advanced LLM paired with an expert malware developer is not particularly useful at the moment, as the barrier is not typically writing the malware code itself. Let me know what you think in the comments. But we must move on to seamless M4T released a couple of days ago from Meta, which frankly seems amazing for multi-lingual translation. That's speech to text, speech to speech, text to text, and more. It has speech recognition for nearly 100 languages and can output in 36 languages. But there's one feature I find particularly cool. Now, let's talk about code switching. Code switching happens when a multilingual speaker switches between languages while they are speaking. Our model seamless M4T automatically recognizes and translates more than one language when mixed in the same sentence. As a multilingual speaker, this is a very exciting capability for me. I often switch from Hindi to Telugu when I speak with my dad. Notice in the following example when I change languages. I can speak Hindi, Telugu, and English. Sometimes I use all three languages in one conversation. Speaking of cool though, we had this epic story out yesterday. AI gave a paralyzed woman her voice back. In a moment, you're going to see her being plugged in to the model. There we go. And the short version is that this woman suffered a stroke that left her unable to speak. But now for the first time, her speech and facial expressions can be synthesized from her brain signals, decoding these signals into text at nearly 80 words per minute up from 14 words per minute. But let's now end on this, an 88 page report on consciousness in artificial intelligence, which counts as one of its co-authors, Yoshua Benjio, the Turing Award winner. It was dense and quite technical, but well worth the read. Look at this sentence in just the abstract. Our analysis suggests that no current AI systems are conscious, but also suggests that there are no obvious technical barriers to building AI systems which satisfy these indicators. These are the indicators and each one gets a few pages in the report. And the reason that they're split up is because each one rests on a certain theory of consciousness. Obviously, the key problem is that we don't have a consensus theory on what consciousness is or how it comes about. So in a way, to hedge their bets, they group in different theories and look at the kind of indicators that would satisfy each one. You might say that list seems so theoretical. Why not just test the model or even ask the model? For more on that approach, see my theory of mind video. But the problem is, as they say on page four, the main alternative to a theory heavy approach is to use behavioral tests for consciousness. But as I talked about in the other video, that method is unreliable because AI systems can be trained, of course they are, to mimic human behaviors, are working actually in very different ways. Essentially, LLMs have broken the traditional tests for consciousness, including of course the Turing test. The paper also rests on the assumption of computational functionalism, essentially that computations are essential for consciousness. As in, it's not what you're made of, it's what you do. If this is wrong, and the substrate in fact is key, say biological cells, then it stands to reason that AI would never be conscious. But one of their early conclusions is that if computational functionalism is true, and it is widely believed, conscious AI systems could realistically be built in the near term. Having digested the entire paper, they're strongly suggesting that we're not there yet. But if this theory is true, we could be there, especially if researchers deliberately designed systems to meet these criteria. In fact, here is a key quote from one of the authors in Science that came along with the piece. It would be trivial to design all of these features into an AI. The reason no one has done so is it is not clear that they would be useful for tasks. Now, to be honest, it is way beyond my pay grade to try to explain every aspect of the paper. But I'm going to try my best to convey the key bits. First, what is the definition of consciousness that they are working with? Well, skipping the jargon, they essentially say, if you are reading this report on a screen, you are having a conscious visual experience of the screen. That is separated from sentence, which is also sometimes used to mean being capable of pleasure or pain. And they say that it's possible for a system to be sentient without being conscious by sensing its body or environment. And it's possible for a system to be conscious without sensing its body or environment. It also might be possible to be slightly conscious or conscious to a greater degree than humans. Ilya Sutskova famously said, it may be that today's large neural networks are slightly conscious. And the Karl Schulman and Nick Bostrom wrote an entire chapter of a book on the possibility that models become more conscious than human beings. They say such beings could contribute immense value to the world and failing to respect their interests could produce a moral catastrophe. One of the theories of consciousness discussed is recurrent processing theory. And here is the key part of that theory. One initial feed forward sweep of activity through the hierarchy of visual areas is sufficient for some visual operations like extracting features from a scene, but not sufficient for conscious experience. However, when the stimulus is sufficiently strong or salient, we get this looped recurrent processing in which signals are sent back from higher areas to lower ones. It's only then that you get a conscious representation of an organized scene. The paper then draws indicators based on each theory. For example, if recurrent processing theory is accurate, then here are two indicators that something would be conscious. They then draw analogies for each theory to AI systems. For example, on recurrence, specifically algorithmic recurrence, they say that's a weak condition that many AI systems already meet. But don't forget when they say that it's an analogy. Not only does it require the theory to be correct, it requires the analogy to hold true. i.e. is the recurrence that we see in AI a good analogy for the recurrence of this theory. Or what about the next one, global workspace theory? If that theory is correct, here are four indicators of something being conscious according to that theory. To be honest, if you are at all interested in consciousness, the pages on each one of these taught me a lot about tests for consciousness and just theories of consciousness. But again, let's just say that theory is correct. Do AI systems demonstrate these indicators? Do they have modules that can work in parallel and a global workspace at the center? Is that workspace bandwidth limited, requiring the compression and selection of information from the modules? Well, here again, we can only rely on analogies, in this case, to the transformer architecture. They say, in a sense, they do have modules, they do have a limited capacity workspace introducing a bottleneck, but then the authors introduce plenty of points about how the analogy is not perfect, even here. Of course, you can pause and read the details if you like, or indeed read the entire paper. So that's the tone of the paper. If silicon can be a replacement to carbon, and if these analogies hold, then there is a strong case that most or all of the conditions for consciousness, suggested by current computational theories, can be met using existing techniques in AI. This is not to say that current AI systems are likely to be conscious. There is also the issue of whether they combine existing techniques in the right ways. But it does suggest that conscious AI is not merely a remote possibility in the distant future. And here is the key bit. If it is at all possible to build conscious AI systems without radically new hardware, it may be possible now. Of course, even if all of those conditions and analogies hold, it may not be the same type of consciousness as our consciousness. It seems possible, they say, to imagine a conscious being that had only a succession of brief static discrete experiences, perhaps just during pre-training. Or they might have experiences without feeling that they are a persisting subject. But my own summary is this. We clearly don't fully understand consciousness or what is required for consciousness. We don't know if consciousness in AI systems is theoretically impossible or imminent. The authors actually quote this open letter from the Association for Mathematical Consciousness Science. And in it, at the end, the letter says, we emphasize that the rapid development of AI is exposing the urgent need to accelerate research in the field of consciousness science, even if we develop a system that ticks all of these indicators. And trust me, someone is probably working on that right now. We still won't know for sure, and many people will deny forever that that system is conscious. I'm not claiming I have the answer, by the way. I have absolutely no idea if these systems are imminently conscious, already conscious, or will never be conscious. All I can say is that it's a bit less sci-fi than many people believe. And the authors also point out two risks, under attributing consciousness to AI, playing down the possibility. But they also point out the risk of over attributing consciousness to AI. On under attributing consciousness, they say this, given the uncertainties about consciousness mentioned above, we may create conscious AI systems long before we recognize that we have done so. And I see this sentence as a fateful prediction. This tendency is further amplified when AI systems exhibit human-like characteristics, such as natural language processing, which they already do, but also facial expressions or adaptive learning capabilities. So imagine what people are going to think when photo-realistic AI avatars are everywhere. And finally, there is the risk of experimentation itself. On balance, we believe that research to better understand the mechanisms which might underlie consciousness in AI is beneficial. However, of course, research on this topic runs the risk of building or enabling others to build a conscious AI system, which should not be done lightly, and that mitigating this kind of risk should be carefully weighed against the value of better understanding consciousness in AI. And to tie this back to the start of the video, Google's AI safety experts have added that some users who grew too dependent on this technology could think it was sentient. And I do wonder if that's an eventuality, Google's newly merged AI SWOT team is preparing for. As always, thank you so much for watching to the end and have a wonderful day. Oh, and just quickly before I end, I now have a discord, AI Explained Community. More info in the description.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.08, "text": " Like buses, AI news can sometimes be slow and sometimes arrive all at once.", "tokens": [50364, 1743, 20519, 11, 7318, 2583, 393, 2171, 312, 2964, 293, 2171, 8881, 439, 412, 1564, 13, 50668], "temperature": 0.0, "avg_logprob": -0.1430239899213924, "compression_ratio": 1.4786324786324787, "no_speech_prob": 0.0021145951468497515}, {"id": 1, "seek": 0, "start": 6.08, "end": 12.64, "text": " In the last few days we have had dramatic new leaked insights into the sheer breadth of Google's", "tokens": [50668, 682, 264, 1036, 1326, 1708, 321, 362, 632, 12023, 777, 31779, 14310, 666, 264, 23061, 35862, 295, 3329, 311, 50996], "temperature": 0.0, "avg_logprob": -0.1430239899213924, "compression_ratio": 1.4786324786324787, "no_speech_prob": 0.0021145951468497515}, {"id": 2, "seek": 0, "start": 12.64, "end": 18.96, "text": " Gemini. Just today we've had the release of Meta's Code Lama and earlier their impressive", "tokens": [50996, 22894, 3812, 13, 1449, 965, 321, 600, 632, 264, 4374, 295, 6377, 64, 311, 15549, 441, 2404, 293, 3071, 641, 8992, 51312], "temperature": 0.0, "avg_logprob": -0.1430239899213924, "compression_ratio": 1.4786324786324787, "no_speech_prob": 0.0021145951468497515}, {"id": 3, "seek": 0, "start": 18.96, "end": 26.8, "text": " multilingual seamless M4T model. And last but definitely not least, this 88-page AI", "tokens": [51312, 2120, 38219, 28677, 376, 19, 51, 2316, 13, 400, 1036, 457, 2138, 406, 1935, 11, 341, 24587, 12, 15161, 7318, 51704], "temperature": 0.0, "avg_logprob": -0.1430239899213924, "compression_ratio": 1.4786324786324787, "no_speech_prob": 0.0021145951468497515}, {"id": 4, "seek": 2680, "start": 26.88, "end": 32.64, "text": " consciousness report. And yes, I read it all, it's juicy so I'm saving that for the end.", "tokens": [50368, 10081, 2275, 13, 400, 2086, 11, 286, 1401, 309, 439, 11, 309, 311, 24696, 370, 286, 478, 6816, 300, 337, 264, 917, 13, 50656], "temperature": 0.0, "avg_logprob": -0.12088536033945635, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0900317057967186}, {"id": 5, "seek": 2680, "start": 32.64, "end": 38.72, "text": " But let's start with two major paywall articles, one from the information and one from the New York", "tokens": [50656, 583, 718, 311, 722, 365, 732, 2563, 1689, 16256, 11290, 11, 472, 490, 264, 1589, 293, 472, 490, 264, 1873, 3609, 50960], "temperature": 0.0, "avg_logprob": -0.12088536033945635, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0900317057967186}, {"id": 6, "seek": 2680, "start": 38.72, "end": 45.040000000000006, "text": " Times about Google's Gemini model. From both of them I counted a total of nine new revelations,", "tokens": [50960, 11366, 466, 3329, 311, 22894, 3812, 2316, 13, 3358, 1293, 295, 552, 286, 20150, 257, 3217, 295, 4949, 777, 15262, 763, 11, 51276], "temperature": 0.0, "avg_logprob": -0.12088536033945635, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0900317057967186}, {"id": 7, "seek": 2680, "start": 45.040000000000006, "end": 48.480000000000004, "text": " so let's get straight to it. To give you a sense of timeline, by the way,", "tokens": [51276, 370, 718, 311, 483, 2997, 281, 309, 13, 1407, 976, 291, 257, 2020, 295, 12933, 11, 538, 264, 636, 11, 51448], "temperature": 0.0, "avg_logprob": -0.12088536033945635, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0900317057967186}, {"id": 8, "seek": 2680, "start": 48.480000000000004, "end": 55.44, "text": " Google's newly merged AI SWOT team, they call it, is preparing for a big fall or autumn launch.", "tokens": [51448, 3329, 311, 15109, 36427, 7318, 20346, 5068, 1469, 11, 436, 818, 309, 11, 307, 10075, 337, 257, 955, 2100, 420, 24604, 4025, 13, 51796], "temperature": 0.0, "avg_logprob": -0.12088536033945635, "compression_ratio": 1.5547945205479452, "no_speech_prob": 0.0900317057967186}, {"id": 9, "seek": 5544, "start": 55.44, "end": 61.199999999999996, "text": " The takeaway for me from both articles is that Gemini is going to be the everything model. Did", "tokens": [50364, 440, 30681, 337, 385, 490, 1293, 11290, 307, 300, 22894, 3812, 307, 516, 281, 312, 264, 1203, 2316, 13, 2589, 50652], "temperature": 0.0, "avg_logprob": -0.08445257941881816, "compression_ratio": 1.5691056910569106, "no_speech_prob": 0.0033760052174329758}, {"id": 10, "seek": 5544, "start": 61.199999999999996, "end": 67.92, "text": " you know it's going to be the rival to mid-journey and stable diffusion? Mid-journey only has 11", "tokens": [50652, 291, 458, 309, 311, 516, 281, 312, 264, 16286, 281, 2062, 12, 8696, 2397, 293, 8351, 25242, 30, 7033, 12, 8696, 2397, 787, 575, 2975, 50988], "temperature": 0.0, "avg_logprob": -0.08445257941881816, "compression_ratio": 1.5691056910569106, "no_speech_prob": 0.0033760052174329758}, {"id": 11, "seek": 5544, "start": 67.92, "end": 74.0, "text": " full-time staff, so it is more than plausible that Google's Gemini could outperform mid-journey", "tokens": [50988, 1577, 12, 3766, 3525, 11, 370, 309, 307, 544, 813, 39925, 300, 3329, 311, 22894, 3812, 727, 484, 26765, 2062, 12, 8696, 2397, 51292], "temperature": 0.0, "avg_logprob": -0.08445257941881816, "compression_ratio": 1.5691056910569106, "no_speech_prob": 0.0033760052174329758}, {"id": 12, "seek": 5544, "start": 74.0, "end": 81.12, "text": " version 5. Next we may be able to create graphics with just text descriptions and control software", "tokens": [51292, 3037, 1025, 13, 3087, 321, 815, 312, 1075, 281, 1884, 11837, 365, 445, 2487, 24406, 293, 1969, 4722, 51648], "temperature": 0.0, "avg_logprob": -0.08445257941881816, "compression_ratio": 1.5691056910569106, "no_speech_prob": 0.0033760052174329758}, {"id": 13, "seek": 8112, "start": 81.12, "end": 86.64, "text": " using only text or voice commands. These next two are speculations, so I'm not even counting them", "tokens": [50364, 1228, 787, 2487, 420, 3177, 16901, 13, 1981, 958, 732, 366, 1608, 4136, 11, 370, 286, 478, 406, 754, 13251, 552, 50640], "temperature": 0.0, "avg_logprob": -0.07727475677217756, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.04602442681789398}, {"id": 14, "seek": 8112, "start": 86.64, "end": 92.16000000000001, "text": " in the list of leaks. I've already covered in a previous video that Gemini has been trained on", "tokens": [50640, 294, 264, 1329, 295, 28885, 13, 286, 600, 1217, 5343, 294, 257, 3894, 960, 300, 22894, 3812, 575, 668, 8895, 322, 50916], "temperature": 0.0, "avg_logprob": -0.07727475677217756, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.04602442681789398}, {"id": 15, "seek": 8112, "start": 92.16000000000001, "end": 98.80000000000001, "text": " YouTube video transcripts, and the speculation is that by integrating video and audio into Gemini,", "tokens": [50916, 3088, 960, 24444, 82, 11, 293, 264, 27696, 307, 300, 538, 26889, 960, 293, 6278, 666, 22894, 3812, 11, 51248], "temperature": 0.0, "avg_logprob": -0.07727475677217756, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.04602442681789398}, {"id": 16, "seek": 8112, "start": 98.80000000000001, "end": 104.16, "text": " it could perhaps help a mechanic diagnose a problem with a car repair based on a video,", "tokens": [51248, 309, 727, 4317, 854, 257, 23860, 36238, 257, 1154, 365, 257, 1032, 10535, 2361, 322, 257, 960, 11, 51516], "temperature": 0.0, "avg_logprob": -0.07727475677217756, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.04602442681789398}, {"id": 17, "seek": 8112, "start": 104.16, "end": 110.72, "text": " or be a rival to Runway ML by generating advanced text to video based on descriptions of what a user", "tokens": [51516, 420, 312, 257, 16286, 281, 8950, 676, 21601, 538, 17746, 7339, 2487, 281, 960, 2361, 322, 24406, 295, 437, 257, 4195, 51844], "temperature": 0.0, "avg_logprob": -0.07727475677217756, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.04602442681789398}, {"id": 18, "seek": 11072, "start": 110.72, "end": 115.44, "text": " wants to see. You can start to see why I'm beginning to think of it as the everything model.", "tokens": [50364, 2738, 281, 536, 13, 509, 393, 722, 281, 536, 983, 286, 478, 2863, 281, 519, 295, 309, 382, 264, 1203, 2316, 13, 50600], "temperature": 0.0, "avg_logprob": -0.08192784697921188, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.004330902360379696}, {"id": 19, "seek": 11072, "start": 115.44, "end": 121.12, "text": " Another leak is that one of the co-founders of Google, Sergey Brin, is working on the front lines", "tokens": [50600, 3996, 17143, 307, 300, 472, 295, 264, 598, 12, 17493, 433, 295, 3329, 11, 49238, 1603, 259, 11, 307, 1364, 322, 264, 1868, 3876, 50884], "temperature": 0.0, "avg_logprob": -0.08192784697921188, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.004330902360379696}, {"id": 20, "seek": 11072, "start": 121.12, "end": 126.32, "text": " of Google Gemini. And lastly from this article, I found it really interesting that Google's", "tokens": [50884, 295, 3329, 22894, 3812, 13, 400, 16386, 490, 341, 7222, 11, 286, 1352, 309, 534, 1880, 300, 3329, 311, 51144], "temperature": 0.0, "avg_logprob": -0.08192784697921188, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.004330902360379696}, {"id": 21, "seek": 11072, "start": 126.32, "end": 132.56, "text": " lawyers have been closely evaluating the training, and they made researchers remove training data", "tokens": [51144, 16219, 362, 668, 8185, 27479, 264, 3097, 11, 293, 436, 1027, 10309, 4159, 3097, 1412, 51456], "temperature": 0.0, "avg_logprob": -0.08192784697921188, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.004330902360379696}, {"id": 22, "seek": 11072, "start": 132.56, "end": 138.16, "text": " that had come from textbooks, even though those textbooks helped the model answer questions about", "tokens": [51456, 300, 632, 808, 490, 33587, 11, 754, 1673, 729, 33587, 4254, 264, 2316, 1867, 1651, 466, 51736], "temperature": 0.0, "avg_logprob": -0.08192784697921188, "compression_ratio": 1.707142857142857, "no_speech_prob": 0.004330902360379696}, {"id": 23, "seek": 13816, "start": 138.16, "end": 144.07999999999998, "text": " subjects like astronomy or biology. And I do wonder if they privately benchmarked Gemini before", "tokens": [50364, 13066, 411, 37844, 420, 14956, 13, 400, 286, 360, 2441, 498, 436, 31919, 18927, 292, 22894, 3812, 949, 50660], "temperature": 0.0, "avg_logprob": -0.07903505721182194, "compression_ratio": 1.588628762541806, "no_speech_prob": 0.010010940954089165}, {"id": 24, "seek": 13816, "start": 144.07999999999998, "end": 150.72, "text": " removing that crucial textbook data. But if that's not enough, prepare to also receive life advice.", "tokens": [50660, 12720, 300, 11462, 25591, 1412, 13, 583, 498, 300, 311, 406, 1547, 11, 5940, 281, 611, 4774, 993, 5192, 13, 50992], "temperature": 0.0, "avg_logprob": -0.07903505721182194, "compression_ratio": 1.588628762541806, "no_speech_prob": 0.010010940954089165}, {"id": 25, "seek": 13816, "start": 150.72, "end": 156.0, "text": " My theory here is that Google wants to compete directly for market share with inflection's", "tokens": [50992, 1222, 5261, 510, 307, 300, 3329, 2738, 281, 11831, 3838, 337, 2142, 2073, 365, 1536, 5450, 311, 51256], "temperature": 0.0, "avg_logprob": -0.07903505721182194, "compression_ratio": 1.588628762541806, "no_speech_prob": 0.010010940954089165}, {"id": 26, "seek": 13816, "start": 156.0, "end": 161.28, "text": " pie. What if you want scientific, creative, or professional writing? Yep, they're working on", "tokens": [51256, 1730, 13, 708, 498, 291, 528, 8134, 11, 5880, 11, 420, 4843, 3579, 30, 7010, 11, 436, 434, 1364, 322, 51520], "temperature": 0.0, "avg_logprob": -0.07903505721182194, "compression_ratio": 1.588628762541806, "no_speech_prob": 0.010010940954089165}, {"id": 27, "seek": 13816, "start": 161.28, "end": 166.48, "text": " that too. In fact, we already know that Google has software named Genesis that they're pitching", "tokens": [51520, 300, 886, 13, 682, 1186, 11, 321, 1217, 458, 300, 3329, 575, 4722, 4926, 20587, 300, 436, 434, 37499, 51780], "temperature": 0.0, "avg_logprob": -0.07903505721182194, "compression_ratio": 1.588628762541806, "no_speech_prob": 0.010010940954089165}, {"id": 28, "seek": 16648, "start": 166.48, "end": 171.92, "text": " to the New York Times, which can generate news articles, rewrite them, suggest headlines, etc.", "tokens": [50364, 281, 264, 1873, 3609, 11366, 11, 597, 393, 8460, 2583, 11290, 11, 28132, 552, 11, 3402, 23867, 11, 5183, 13, 50636], "temperature": 0.0, "avg_logprob": -0.054144280588524975, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.01911867968738079}, {"id": 29, "seek": 16648, "start": 171.92, "end": 176.72, "text": " But some people will be more interested in this feature that Google DeepMind is working on,", "tokens": [50636, 583, 512, 561, 486, 312, 544, 3102, 294, 341, 4111, 300, 3329, 14895, 44, 471, 307, 1364, 322, 11, 50876], "temperature": 0.0, "avg_logprob": -0.054144280588524975, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.01911867968738079}, {"id": 30, "seek": 16648, "start": 176.72, "end": 182.48, "text": " the ability to draft critiques of an argument and generate quizzes, word, and number puzzles.", "tokens": [50876, 264, 3485, 281, 11206, 3113, 4911, 295, 364, 6770, 293, 8460, 48955, 11, 1349, 11, 293, 1230, 24138, 13, 51164], "temperature": 0.0, "avg_logprob": -0.054144280588524975, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.01911867968738079}, {"id": 31, "seek": 16648, "start": 182.48, "end": 188.32, "text": " It's almost easier at this point to ask what might Google Gemini not be able to do. And yes,", "tokens": [51164, 467, 311, 1920, 3571, 412, 341, 935, 281, 1029, 437, 1062, 3329, 22894, 3812, 406, 312, 1075, 281, 360, 13, 400, 2086, 11, 51456], "temperature": 0.0, "avg_logprob": -0.054144280588524975, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.01911867968738079}, {"id": 32, "seek": 16648, "start": 188.32, "end": 195.44, "text": " this is not Gemini, but Google DeepMind is also using AI to design the next generation of semiconductors.", "tokens": [51456, 341, 307, 406, 22894, 3812, 11, 457, 3329, 14895, 44, 471, 307, 611, 1228, 7318, 281, 1715, 264, 958, 5125, 295, 36924, 5547, 13, 51812], "temperature": 0.0, "avg_logprob": -0.054144280588524975, "compression_ratio": 1.629251700680272, "no_speech_prob": 0.01911867968738079}, {"id": 33, "seek": 19544, "start": 195.44, "end": 201.12, "text": " But if the fall seems far away, how about today when we got CodeLama from Meta?", "tokens": [50364, 583, 498, 264, 2100, 2544, 1400, 1314, 11, 577, 466, 965, 562, 321, 658, 15549, 43, 2404, 490, 6377, 64, 30, 50648], "temperature": 0.0, "avg_logprob": -0.0956200190952846, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.006288745440542698}, {"id": 34, "seek": 19544, "start": 201.12, "end": 207.2, "text": " I spent much of the last two hours reading most of the 47-page paper, and you can see CodeLama", "tokens": [50648, 286, 4418, 709, 295, 264, 1036, 732, 2496, 3760, 881, 295, 264, 16953, 12, 15161, 3035, 11, 293, 291, 393, 536, 15549, 43, 2404, 50952], "temperature": 0.0, "avg_logprob": -0.0956200190952846, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.006288745440542698}, {"id": 35, "seek": 19544, "start": 207.2, "end": 213.44, "text": " in action on screen. Some highlights include that the CodeLama models provide stable generations with", "tokens": [50952, 294, 3069, 322, 2568, 13, 2188, 14254, 4090, 300, 264, 15549, 43, 2404, 5245, 2893, 8351, 10593, 365, 51264], "temperature": 0.0, "avg_logprob": -0.0956200190952846, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.006288745440542698}, {"id": 36, "seek": 19544, "start": 213.44, "end": 219.36, "text": " up to 100,000 tokens of context. Obviously, that could be used for generating longer programs or", "tokens": [51264, 493, 281, 2319, 11, 1360, 22667, 295, 4319, 13, 7580, 11, 300, 727, 312, 1143, 337, 17746, 2854, 4268, 420, 51560], "temperature": 0.0, "avg_logprob": -0.0956200190952846, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.006288745440542698}, {"id": 37, "seek": 19544, "start": 219.36, "end": 224.24, "text": " providing the model with more context from your code base to make the generations more relevant.", "tokens": [51560, 6530, 264, 2316, 365, 544, 4319, 490, 428, 3089, 3096, 281, 652, 264, 10593, 544, 7340, 13, 51804], "temperature": 0.0, "avg_logprob": -0.0956200190952846, "compression_ratio": 1.6319444444444444, "no_speech_prob": 0.006288745440542698}, {"id": 38, "seek": 22424, "start": 224.24, "end": 229.20000000000002, "text": " It comes in three versions, CodeLama, CodeLama Instruct, which can better understand natural", "tokens": [50364, 467, 1487, 294, 1045, 9606, 11, 15549, 43, 2404, 11, 15549, 43, 2404, 2730, 1757, 11, 597, 393, 1101, 1223, 3303, 50612], "temperature": 0.0, "avg_logprob": -0.1333312340153074, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.004754265770316124}, {"id": 39, "seek": 22424, "start": 229.20000000000002, "end": 234.08, "text": " language instructions, and CodeLama Python, better, of course, at Python. It's available", "tokens": [50612, 2856, 9415, 11, 293, 15549, 43, 2404, 15329, 11, 1101, 11, 295, 1164, 11, 412, 15329, 13, 467, 311, 2435, 50856], "temperature": 0.0, "avg_logprob": -0.1333312340153074, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.004754265770316124}, {"id": 40, "seek": 22424, "start": 234.08, "end": 240.8, "text": " for commercial use, and as you can see, some of the versions rival GPT 3.5 on human eval.", "tokens": [50856, 337, 6841, 764, 11, 293, 382, 291, 393, 536, 11, 512, 295, 264, 9606, 16286, 26039, 51, 805, 13, 20, 322, 1952, 1073, 304, 13, 51192], "temperature": 0.0, "avg_logprob": -0.1333312340153074, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.004754265770316124}, {"id": 41, "seek": 22424, "start": 240.8, "end": 247.84, "text": " That top score of 53.7% on Passat 1 puts it in the same ballpark as Phi 1. I've actually done", "tokens": [51192, 663, 1192, 6175, 295, 21860, 13, 22, 4, 322, 10319, 267, 502, 8137, 309, 294, 264, 912, 2594, 31239, 382, 41435, 502, 13, 286, 600, 767, 1096, 51544], "temperature": 0.0, "avg_logprob": -0.1333312340153074, "compression_ratio": 1.5466101694915255, "no_speech_prob": 0.004754265770316124}, {"id": 42, "seek": 24784, "start": 247.84, "end": 255.12, "text": " a full video on Phi 1, so do check that out, but that got 50.6%. But it is about 25 times smaller", "tokens": [50364, 257, 1577, 960, 322, 41435, 502, 11, 370, 360, 1520, 300, 484, 11, 457, 300, 658, 2625, 13, 21, 6856, 583, 309, 307, 466, 3552, 1413, 4356, 50728], "temperature": 0.0, "avg_logprob": -0.06813106244924116, "compression_ratio": 1.536, "no_speech_prob": 0.32062777876853943}, {"id": 43, "seek": 24784, "start": 255.12, "end": 260.48, "text": " at 1.3 billion parameters. Interestingly, the CodeLama paper, which also came out about two", "tokens": [50728, 412, 502, 13, 18, 5218, 9834, 13, 30564, 11, 264, 15549, 43, 2404, 3035, 11, 597, 611, 1361, 484, 466, 732, 50996], "temperature": 0.0, "avg_logprob": -0.06813106244924116, "compression_ratio": 1.536, "no_speech_prob": 0.32062777876853943}, {"id": 44, "seek": 24784, "start": 260.48, "end": 266.4, "text": " hours ago, mentions Phi 1 directly, saying that it follows in a similar spirit, but the difference", "tokens": [50996, 2496, 2057, 11, 23844, 41435, 502, 3838, 11, 1566, 300, 309, 10002, 294, 257, 2531, 3797, 11, 457, 264, 2649, 51292], "temperature": 0.0, "avg_logprob": -0.06813106244924116, "compression_ratio": 1.536, "no_speech_prob": 0.32062777876853943}, {"id": 45, "seek": 24784, "start": 266.4, "end": 272.24, "text": " is that Phi 1 is closed source. Anyway, a couple more interesting things before we move on from", "tokens": [51292, 307, 300, 41435, 502, 307, 5395, 4009, 13, 5684, 11, 257, 1916, 544, 1880, 721, 949, 321, 1286, 322, 490, 51584], "temperature": 0.0, "avg_logprob": -0.06813106244924116, "compression_ratio": 1.536, "no_speech_prob": 0.32062777876853943}, {"id": 46, "seek": 27224, "start": 272.32, "end": 278.08, "text": " CodeLama, and the first one is the self-instruct method that they used. Let me know if you also", "tokens": [50368, 15549, 43, 2404, 11, 293, 264, 700, 472, 307, 264, 2698, 12, 13911, 1757, 3170, 300, 436, 1143, 13, 961, 385, 458, 498, 291, 611, 50656], "temperature": 0.0, "avg_logprob": -0.10229649714061193, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.11593411862850189}, {"id": 47, "seek": 27224, "start": 278.08, "end": 284.24, "text": " find this fascinating, because step one was to generate 62,000 interview style programming", "tokens": [50656, 915, 341, 10343, 11, 570, 1823, 472, 390, 281, 8460, 24536, 11, 1360, 4049, 3758, 9410, 50964], "temperature": 0.0, "avg_logprob": -0.10229649714061193, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.11593411862850189}, {"id": 48, "seek": 27224, "start": 284.24, "end": 289.76, "text": " questions by prompting Lama 2, the 70 billion parameter model. Then they removed duplicates in", "tokens": [50964, 1651, 538, 12391, 278, 441, 2404, 568, 11, 264, 5285, 5218, 13075, 2316, 13, 1396, 436, 7261, 17154, 1024, 294, 51240], "temperature": 0.0, "avg_logprob": -0.10229649714061193, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.11593411862850189}, {"id": 49, "seek": 27224, "start": 289.76, "end": 293.92, "text": " step two. But here's where it gets interesting. For each of those questions, they first generated", "tokens": [51240, 1823, 732, 13, 583, 510, 311, 689, 309, 2170, 1880, 13, 1171, 1184, 295, 729, 1651, 11, 436, 700, 10833, 51448], "temperature": 0.0, "avg_logprob": -0.10229649714061193, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.11593411862850189}, {"id": 50, "seek": 27224, "start": 293.92, "end": 300.56, "text": " a unit test by prompting CodeLama 7 billion parameters. Then they generated 10 Python solutions", "tokens": [51448, 257, 4985, 1500, 538, 12391, 278, 15549, 43, 2404, 1614, 5218, 9834, 13, 1396, 436, 10833, 1266, 15329, 6547, 51780], "temperature": 0.0, "avg_logprob": -0.10229649714061193, "compression_ratio": 1.6964285714285714, "no_speech_prob": 0.11593411862850189}, {"id": 51, "seek": 30056, "start": 300.56, "end": 306.08, "text": " by prompting CodeLama. Finally, they ran unit tests on those 10 solutions, and they added the", "tokens": [50364, 538, 12391, 278, 15549, 43, 2404, 13, 6288, 11, 436, 5872, 4985, 6921, 322, 729, 1266, 6547, 11, 293, 436, 3869, 264, 50640], "temperature": 0.0, "avg_logprob": -0.07175207138061523, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.005384285934269428}, {"id": 52, "seek": 30056, "start": 306.08, "end": 310.88, "text": " first solution that passes those tests, along with the corresponding question and test, to the", "tokens": [50640, 700, 3827, 300, 11335, 729, 6921, 11, 2051, 365, 264, 11760, 1168, 293, 1500, 11, 281, 264, 50880], "temperature": 0.0, "avg_logprob": -0.07175207138061523, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.005384285934269428}, {"id": 53, "seek": 30056, "start": 310.88, "end": 315.28000000000003, "text": " self-instruct data set. If that sounded a bit complicated, let me try to distill it a bit.", "tokens": [50880, 2698, 12, 13911, 1757, 1412, 992, 13, 759, 300, 17714, 257, 857, 6179, 11, 718, 385, 853, 281, 42923, 309, 257, 857, 13, 51100], "temperature": 0.0, "avg_logprob": -0.07175207138061523, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.005384285934269428}, {"id": 54, "seek": 30056, "start": 315.28000000000003, "end": 322.08, "text": " They asked the Big Brother Lama 2 model to generate questions, then got the Little Brother CodeLama", "tokens": [51100, 814, 2351, 264, 5429, 8904, 441, 2404, 568, 2316, 281, 8460, 1651, 11, 550, 658, 264, 8022, 8904, 15549, 43, 2404, 51440], "temperature": 0.0, "avg_logprob": -0.07175207138061523, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.005384285934269428}, {"id": 55, "seek": 30056, "start": 322.08, "end": 328.4, "text": " to generate tests for those questions, then got the model to generate solutions to its own tests,", "tokens": [51440, 281, 8460, 6921, 337, 729, 1651, 11, 550, 658, 264, 2316, 281, 8460, 6547, 281, 1080, 1065, 6921, 11, 51756], "temperature": 0.0, "avg_logprob": -0.07175207138061523, "compression_ratio": 1.8779527559055118, "no_speech_prob": 0.005384285934269428}, {"id": 56, "seek": 32840, "start": 328.4, "end": 333.28, "text": " found the good solutions that don't forget it produced, and then used those to further train", "tokens": [50364, 1352, 264, 665, 6547, 300, 500, 380, 2870, 309, 7126, 11, 293, 550, 1143, 729, 281, 3052, 3847, 50608], "temperature": 0.0, "avg_logprob": -0.067025584994622, "compression_ratio": 1.6401384083044983, "no_speech_prob": 0.001987540628761053}, {"id": 57, "seek": 32840, "start": 333.28, "end": 339.52, "text": " the model. To be honest, synthetic data and self-instruct seem to be the future of feedback.", "tokens": [50608, 264, 2316, 13, 1407, 312, 3245, 11, 23420, 1412, 293, 2698, 12, 13911, 1757, 1643, 281, 312, 264, 2027, 295, 5824, 13, 50920], "temperature": 0.0, "avg_logprob": -0.067025584994622, "compression_ratio": 1.6401384083044983, "no_speech_prob": 0.001987540628761053}, {"id": 58, "seek": 32840, "start": 339.52, "end": 345.2, "text": " One final interesting quote from the paper on safety, and that was an argument advanced by one", "tokens": [50920, 1485, 2572, 1880, 6513, 490, 264, 3035, 322, 4514, 11, 293, 300, 390, 364, 6770, 7339, 538, 472, 51204], "temperature": 0.0, "avg_logprob": -0.067025584994622, "compression_ratio": 1.6401384083044983, "no_speech_prob": 0.001987540628761053}, {"id": 59, "seek": 32840, "start": 345.2, "end": 351.35999999999996, "text": " of their red teamers. They made the point that various scripts and code is readily available on", "tokens": [51204, 295, 641, 2182, 1469, 433, 13, 814, 1027, 264, 935, 300, 3683, 23294, 293, 3089, 307, 26336, 2435, 322, 51512], "temperature": 0.0, "avg_logprob": -0.067025584994622, "compression_ratio": 1.6401384083044983, "no_speech_prob": 0.001987540628761053}, {"id": 60, "seek": 32840, "start": 351.35999999999996, "end": 356.64, "text": " mainstream public websites, hacking forums, or the dark web. And the advanced malware development", "tokens": [51512, 15960, 1908, 12891, 11, 31422, 26998, 11, 420, 264, 2877, 3670, 13, 400, 264, 7339, 40747, 3250, 51776], "temperature": 0.0, "avg_logprob": -0.067025584994622, "compression_ratio": 1.6401384083044983, "no_speech_prob": 0.001987540628761053}, {"id": 61, "seek": 35664, "start": 356.64, "end": 362.56, "text": " is beyond the current capabilities of available LLMs. And even an advanced LLM paired with an", "tokens": [50364, 307, 4399, 264, 2190, 10862, 295, 2435, 441, 43, 26386, 13, 400, 754, 364, 7339, 441, 43, 44, 25699, 365, 364, 50660], "temperature": 0.0, "avg_logprob": -0.09332852722496114, "compression_ratio": 1.53125, "no_speech_prob": 0.0050596813671290874}, {"id": 62, "seek": 35664, "start": 362.56, "end": 368.24, "text": " expert malware developer is not particularly useful at the moment, as the barrier is not typically", "tokens": [50660, 5844, 40747, 10754, 307, 406, 4098, 4420, 412, 264, 1623, 11, 382, 264, 13357, 307, 406, 5850, 50944], "temperature": 0.0, "avg_logprob": -0.09332852722496114, "compression_ratio": 1.53125, "no_speech_prob": 0.0050596813671290874}, {"id": 63, "seek": 35664, "start": 368.24, "end": 374.56, "text": " writing the malware code itself. Let me know what you think in the comments. But we must move on to", "tokens": [50944, 3579, 264, 40747, 3089, 2564, 13, 961, 385, 458, 437, 291, 519, 294, 264, 3053, 13, 583, 321, 1633, 1286, 322, 281, 51260], "temperature": 0.0, "avg_logprob": -0.09332852722496114, "compression_ratio": 1.53125, "no_speech_prob": 0.0050596813671290874}, {"id": 64, "seek": 35664, "start": 374.56, "end": 382.08, "text": " seamless M4T released a couple of days ago from Meta, which frankly seems amazing for multi-lingual", "tokens": [51260, 28677, 376, 19, 51, 4736, 257, 1916, 295, 1708, 2057, 490, 6377, 64, 11, 597, 11939, 2544, 2243, 337, 4825, 12, 1688, 901, 51636], "temperature": 0.0, "avg_logprob": -0.09332852722496114, "compression_ratio": 1.53125, "no_speech_prob": 0.0050596813671290874}, {"id": 65, "seek": 38208, "start": 382.08, "end": 388.15999999999997, "text": " translation. That's speech to text, speech to speech, text to text, and more. It has speech", "tokens": [50364, 12853, 13, 663, 311, 6218, 281, 2487, 11, 6218, 281, 6218, 11, 2487, 281, 2487, 11, 293, 544, 13, 467, 575, 6218, 50668], "temperature": 0.0, "avg_logprob": -0.0771263699198878, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0021826105657964945}, {"id": 66, "seek": 38208, "start": 388.15999999999997, "end": 394.8, "text": " recognition for nearly 100 languages and can output in 36 languages. But there's one feature I find", "tokens": [50668, 11150, 337, 6217, 2319, 8650, 293, 393, 5598, 294, 8652, 8650, 13, 583, 456, 311, 472, 4111, 286, 915, 51000], "temperature": 0.0, "avg_logprob": -0.0771263699198878, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0021826105657964945}, {"id": 67, "seek": 38208, "start": 394.8, "end": 402.79999999999995, "text": " particularly cool. Now, let's talk about code switching. Code switching happens when a multilingual", "tokens": [51000, 4098, 1627, 13, 823, 11, 718, 311, 751, 466, 3089, 16493, 13, 15549, 16493, 2314, 562, 257, 2120, 38219, 51400], "temperature": 0.0, "avg_logprob": -0.0771263699198878, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0021826105657964945}, {"id": 68, "seek": 38208, "start": 402.79999999999995, "end": 408.79999999999995, "text": " speaker switches between languages while they are speaking. Our model seamless M4T automatically", "tokens": [51400, 8145, 19458, 1296, 8650, 1339, 436, 366, 4124, 13, 2621, 2316, 28677, 376, 19, 51, 6772, 51700], "temperature": 0.0, "avg_logprob": -0.0771263699198878, "compression_ratio": 1.6099585062240664, "no_speech_prob": 0.0021826105657964945}, {"id": 69, "seek": 40880, "start": 408.8, "end": 414.64, "text": " recognizes and translates more than one language when mixed in the same sentence. As a multilingual", "tokens": [50364, 26564, 293, 28468, 544, 813, 472, 2856, 562, 7467, 294, 264, 912, 8174, 13, 1018, 257, 2120, 38219, 50656], "temperature": 0.0, "avg_logprob": -0.10553106714467533, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.043444760143756866}, {"id": 70, "seek": 40880, "start": 414.64, "end": 420.0, "text": " speaker, this is a very exciting capability for me. I often switch from Hindi to Telugu", "tokens": [50656, 8145, 11, 341, 307, 257, 588, 4670, 13759, 337, 385, 13, 286, 2049, 3679, 490, 36225, 281, 27729, 13705, 50924], "temperature": 0.0, "avg_logprob": -0.10553106714467533, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.043444760143756866}, {"id": 71, "seek": 40880, "start": 420.0, "end": 424.96000000000004, "text": " when I speak with my dad. Notice in the following example when I change languages.", "tokens": [50924, 562, 286, 1710, 365, 452, 3546, 13, 13428, 294, 264, 3480, 1365, 562, 286, 1319, 8650, 13, 51172], "temperature": 0.0, "avg_logprob": -0.10553106714467533, "compression_ratio": 1.4594594594594594, "no_speech_prob": 0.043444760143756866}, {"id": 72, "seek": 43880, "start": 439.04, "end": 447.28000000000003, "text": " I can speak Hindi, Telugu, and English. Sometimes I use all three languages in one conversation.", "tokens": [50376, 286, 393, 1710, 36225, 11, 27729, 13705, 11, 293, 3669, 13, 4803, 286, 764, 439, 1045, 8650, 294, 472, 3761, 13, 50788], "temperature": 0.0, "avg_logprob": -0.12319770301740195, "compression_ratio": 1.5330739299610896, "no_speech_prob": 0.020327158272266388}, {"id": 73, "seek": 43880, "start": 447.84000000000003, "end": 454.8, "text": " Speaking of cool though, we had this epic story out yesterday. AI gave a paralyzed woman her voice", "tokens": [50816, 13069, 295, 1627, 1673, 11, 321, 632, 341, 13581, 1657, 484, 5186, 13, 7318, 2729, 257, 41919, 3059, 720, 3177, 51164], "temperature": 0.0, "avg_logprob": -0.12319770301740195, "compression_ratio": 1.5330739299610896, "no_speech_prob": 0.020327158272266388}, {"id": 74, "seek": 43880, "start": 454.8, "end": 461.36, "text": " back. In a moment, you're going to see her being plugged in to the model. There we go. And the short", "tokens": [51164, 646, 13, 682, 257, 1623, 11, 291, 434, 516, 281, 536, 720, 885, 25679, 294, 281, 264, 2316, 13, 821, 321, 352, 13, 400, 264, 2099, 51492], "temperature": 0.0, "avg_logprob": -0.12319770301740195, "compression_ratio": 1.5330739299610896, "no_speech_prob": 0.020327158272266388}, {"id": 75, "seek": 43880, "start": 461.36, "end": 467.76, "text": " version is that this woman suffered a stroke that left her unable to speak. But now for the first", "tokens": [51492, 3037, 307, 300, 341, 3059, 12770, 257, 12403, 300, 1411, 720, 11299, 281, 1710, 13, 583, 586, 337, 264, 700, 51812], "temperature": 0.0, "avg_logprob": -0.12319770301740195, "compression_ratio": 1.5330739299610896, "no_speech_prob": 0.020327158272266388}, {"id": 76, "seek": 46776, "start": 467.76, "end": 474.15999999999997, "text": " time, her speech and facial expressions can be synthesized from her brain signals, decoding", "tokens": [50364, 565, 11, 720, 6218, 293, 15642, 15277, 393, 312, 26617, 1602, 490, 720, 3567, 12354, 11, 979, 8616, 50684], "temperature": 0.0, "avg_logprob": -0.1019962885046518, "compression_ratio": 1.5140562248995983, "no_speech_prob": 0.0046087331138551235}, {"id": 77, "seek": 46776, "start": 474.15999999999997, "end": 480.08, "text": " these signals into text at nearly 80 words per minute up from 14 words per minute. But let's", "tokens": [50684, 613, 12354, 666, 2487, 412, 6217, 4688, 2283, 680, 3456, 493, 490, 3499, 2283, 680, 3456, 13, 583, 718, 311, 50980], "temperature": 0.0, "avg_logprob": -0.1019962885046518, "compression_ratio": 1.5140562248995983, "no_speech_prob": 0.0046087331138551235}, {"id": 78, "seek": 46776, "start": 480.08, "end": 486.4, "text": " now end on this, an 88 page report on consciousness in artificial intelligence, which counts as one", "tokens": [50980, 586, 917, 322, 341, 11, 364, 24587, 3028, 2275, 322, 10081, 294, 11677, 7599, 11, 597, 14893, 382, 472, 51296], "temperature": 0.0, "avg_logprob": -0.1019962885046518, "compression_ratio": 1.5140562248995983, "no_speech_prob": 0.0046087331138551235}, {"id": 79, "seek": 46776, "start": 486.4, "end": 492.24, "text": " of its co-authors, Yoshua Benjio, the Turing Award winner. It was dense and quite technical,", "tokens": [51296, 295, 1080, 598, 12, 40198, 830, 11, 38949, 4398, 3964, 73, 1004, 11, 264, 314, 1345, 13894, 8507, 13, 467, 390, 18011, 293, 1596, 6191, 11, 51588], "temperature": 0.0, "avg_logprob": -0.1019962885046518, "compression_ratio": 1.5140562248995983, "no_speech_prob": 0.0046087331138551235}, {"id": 80, "seek": 49224, "start": 492.24, "end": 498.64, "text": " but well worth the read. Look at this sentence in just the abstract. Our analysis suggests that no", "tokens": [50364, 457, 731, 3163, 264, 1401, 13, 2053, 412, 341, 8174, 294, 445, 264, 12649, 13, 2621, 5215, 13409, 300, 572, 50684], "temperature": 0.0, "avg_logprob": -0.05775767148927201, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.09003126621246338}, {"id": 81, "seek": 49224, "start": 498.64, "end": 504.24, "text": " current AI systems are conscious, but also suggests that there are no obvious technical barriers to", "tokens": [50684, 2190, 7318, 3652, 366, 6648, 11, 457, 611, 13409, 300, 456, 366, 572, 6322, 6191, 13565, 281, 50964], "temperature": 0.0, "avg_logprob": -0.05775767148927201, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.09003126621246338}, {"id": 82, "seek": 49224, "start": 504.24, "end": 511.6, "text": " building AI systems which satisfy these indicators. These are the indicators and each one gets a few", "tokens": [50964, 2390, 7318, 3652, 597, 19319, 613, 22176, 13, 1981, 366, 264, 22176, 293, 1184, 472, 2170, 257, 1326, 51332], "temperature": 0.0, "avg_logprob": -0.05775767148927201, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.09003126621246338}, {"id": 83, "seek": 49224, "start": 511.6, "end": 517.76, "text": " pages in the report. And the reason that they're split up is because each one rests on a certain", "tokens": [51332, 7183, 294, 264, 2275, 13, 400, 264, 1778, 300, 436, 434, 7472, 493, 307, 570, 1184, 472, 39755, 322, 257, 1629, 51640], "temperature": 0.0, "avg_logprob": -0.05775767148927201, "compression_ratio": 1.6708860759493671, "no_speech_prob": 0.09003126621246338}, {"id": 84, "seek": 51776, "start": 517.76, "end": 524.24, "text": " theory of consciousness. Obviously, the key problem is that we don't have a consensus theory on what", "tokens": [50364, 5261, 295, 10081, 13, 7580, 11, 264, 2141, 1154, 307, 300, 321, 500, 380, 362, 257, 19115, 5261, 322, 437, 50688], "temperature": 0.0, "avg_logprob": -0.06300552942419566, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.05031302571296692}, {"id": 85, "seek": 51776, "start": 524.24, "end": 530.0, "text": " consciousness is or how it comes about. So in a way, to hedge their bets, they group in different", "tokens": [50688, 10081, 307, 420, 577, 309, 1487, 466, 13, 407, 294, 257, 636, 11, 281, 25304, 641, 39922, 11, 436, 1594, 294, 819, 50976], "temperature": 0.0, "avg_logprob": -0.06300552942419566, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.05031302571296692}, {"id": 86, "seek": 51776, "start": 530.0, "end": 535.2, "text": " theories and look at the kind of indicators that would satisfy each one. You might say that list", "tokens": [50976, 13667, 293, 574, 412, 264, 733, 295, 22176, 300, 576, 19319, 1184, 472, 13, 509, 1062, 584, 300, 1329, 51236], "temperature": 0.0, "avg_logprob": -0.06300552942419566, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.05031302571296692}, {"id": 87, "seek": 51776, "start": 535.2, "end": 540.96, "text": " seems so theoretical. Why not just test the model or even ask the model? For more on that approach,", "tokens": [51236, 2544, 370, 20864, 13, 1545, 406, 445, 1500, 264, 2316, 420, 754, 1029, 264, 2316, 30, 1171, 544, 322, 300, 3109, 11, 51524], "temperature": 0.0, "avg_logprob": -0.06300552942419566, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.05031302571296692}, {"id": 88, "seek": 54096, "start": 541.0400000000001, "end": 545.76, "text": " see my theory of mind video. But the problem is, as they say on page four,", "tokens": [50368, 536, 452, 5261, 295, 1575, 960, 13, 583, 264, 1154, 307, 11, 382, 436, 584, 322, 3028, 1451, 11, 50604], "temperature": 0.0, "avg_logprob": -0.097652953011649, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.39961498975753784}, {"id": 89, "seek": 54096, "start": 545.76, "end": 552.32, "text": " the main alternative to a theory heavy approach is to use behavioral tests for consciousness.", "tokens": [50604, 264, 2135, 8535, 281, 257, 5261, 4676, 3109, 307, 281, 764, 19124, 6921, 337, 10081, 13, 50932], "temperature": 0.0, "avg_logprob": -0.097652953011649, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.39961498975753784}, {"id": 90, "seek": 54096, "start": 552.32, "end": 557.2800000000001, "text": " But as I talked about in the other video, that method is unreliable because AI systems can be", "tokens": [50932, 583, 382, 286, 2825, 466, 294, 264, 661, 960, 11, 300, 3170, 307, 20584, 2081, 712, 570, 7318, 3652, 393, 312, 51180], "temperature": 0.0, "avg_logprob": -0.097652953011649, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.39961498975753784}, {"id": 91, "seek": 54096, "start": 557.2800000000001, "end": 562.8000000000001, "text": " trained, of course they are, to mimic human behaviors, are working actually in very different", "tokens": [51180, 8895, 11, 295, 1164, 436, 366, 11, 281, 31075, 1952, 15501, 11, 366, 1364, 767, 294, 588, 819, 51456], "temperature": 0.0, "avg_logprob": -0.097652953011649, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.39961498975753784}, {"id": 92, "seek": 54096, "start": 562.8000000000001, "end": 568.64, "text": " ways. Essentially, LLMs have broken the traditional tests for consciousness, including of course the", "tokens": [51456, 2098, 13, 23596, 11, 441, 43, 26386, 362, 5463, 264, 5164, 6921, 337, 10081, 11, 3009, 295, 1164, 264, 51748], "temperature": 0.0, "avg_logprob": -0.097652953011649, "compression_ratio": 1.6925925925925926, "no_speech_prob": 0.39961498975753784}, {"id": 93, "seek": 56864, "start": 568.64, "end": 573.6, "text": " Turing test. The paper also rests on the assumption of computational functionalism,", "tokens": [50364, 314, 1345, 1500, 13, 440, 3035, 611, 39755, 322, 264, 15302, 295, 28270, 11745, 1434, 11, 50612], "temperature": 0.0, "avg_logprob": -0.07462414105733235, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.007344166748225689}, {"id": 94, "seek": 56864, "start": 573.6, "end": 578.96, "text": " essentially that computations are essential for consciousness. As in, it's not what you're made", "tokens": [50612, 4476, 300, 2807, 763, 366, 7115, 337, 10081, 13, 1018, 294, 11, 309, 311, 406, 437, 291, 434, 1027, 50880], "temperature": 0.0, "avg_logprob": -0.07462414105733235, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.007344166748225689}, {"id": 95, "seek": 56864, "start": 578.96, "end": 584.96, "text": " of, it's what you do. If this is wrong, and the substrate in fact is key, say biological cells,", "tokens": [50880, 295, 11, 309, 311, 437, 291, 360, 13, 759, 341, 307, 2085, 11, 293, 264, 27585, 294, 1186, 307, 2141, 11, 584, 13910, 5438, 11, 51180], "temperature": 0.0, "avg_logprob": -0.07462414105733235, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.007344166748225689}, {"id": 96, "seek": 56864, "start": 584.96, "end": 589.68, "text": " then it stands to reason that AI would never be conscious. But one of their early conclusions", "tokens": [51180, 550, 309, 7382, 281, 1778, 300, 7318, 576, 1128, 312, 6648, 13, 583, 472, 295, 641, 2440, 22865, 51416], "temperature": 0.0, "avg_logprob": -0.07462414105733235, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.007344166748225689}, {"id": 97, "seek": 56864, "start": 589.68, "end": 595.4399999999999, "text": " is that if computational functionalism is true, and it is widely believed, conscious AI systems", "tokens": [51416, 307, 300, 498, 28270, 11745, 1434, 307, 2074, 11, 293, 309, 307, 13371, 7847, 11, 6648, 7318, 3652, 51704], "temperature": 0.0, "avg_logprob": -0.07462414105733235, "compression_ratio": 1.7953667953667953, "no_speech_prob": 0.007344166748225689}, {"id": 98, "seek": 59544, "start": 595.44, "end": 600.6400000000001, "text": " could realistically be built in the near term. Having digested the entire paper, they're strongly", "tokens": [50364, 727, 40734, 312, 3094, 294, 264, 2651, 1433, 13, 10222, 13884, 292, 264, 2302, 3035, 11, 436, 434, 10613, 50624], "temperature": 0.0, "avg_logprob": -0.06880579824032991, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.012047946453094482}, {"id": 99, "seek": 59544, "start": 600.6400000000001, "end": 606.24, "text": " suggesting that we're not there yet. But if this theory is true, we could be there, especially if", "tokens": [50624, 18094, 300, 321, 434, 406, 456, 1939, 13, 583, 498, 341, 5261, 307, 2074, 11, 321, 727, 312, 456, 11, 2318, 498, 50904], "temperature": 0.0, "avg_logprob": -0.06880579824032991, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.012047946453094482}, {"id": 100, "seek": 59544, "start": 606.24, "end": 612.1600000000001, "text": " researchers deliberately designed systems to meet these criteria. In fact, here is a key quote from", "tokens": [50904, 10309, 23506, 4761, 3652, 281, 1677, 613, 11101, 13, 682, 1186, 11, 510, 307, 257, 2141, 6513, 490, 51200], "temperature": 0.0, "avg_logprob": -0.06880579824032991, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.012047946453094482}, {"id": 101, "seek": 59544, "start": 612.1600000000001, "end": 617.7600000000001, "text": " one of the authors in Science that came along with the piece. It would be trivial to design all of", "tokens": [51200, 472, 295, 264, 16552, 294, 8976, 300, 1361, 2051, 365, 264, 2522, 13, 467, 576, 312, 26703, 281, 1715, 439, 295, 51480], "temperature": 0.0, "avg_logprob": -0.06880579824032991, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.012047946453094482}, {"id": 102, "seek": 59544, "start": 617.7600000000001, "end": 623.6, "text": " these features into an AI. The reason no one has done so is it is not clear that they would be useful", "tokens": [51480, 613, 4122, 666, 364, 7318, 13, 440, 1778, 572, 472, 575, 1096, 370, 307, 309, 307, 406, 1850, 300, 436, 576, 312, 4420, 51772], "temperature": 0.0, "avg_logprob": -0.06880579824032991, "compression_ratio": 1.6756756756756757, "no_speech_prob": 0.012047946453094482}, {"id": 103, "seek": 62360, "start": 623.9200000000001, "end": 629.6, "text": " for tasks. Now, to be honest, it is way beyond my pay grade to try to explain every aspect of the", "tokens": [50380, 337, 9608, 13, 823, 11, 281, 312, 3245, 11, 309, 307, 636, 4399, 452, 1689, 7204, 281, 853, 281, 2903, 633, 4171, 295, 264, 50664], "temperature": 0.0, "avg_logprob": -0.07959571127164161, "compression_ratio": 1.6498316498316499, "no_speech_prob": 0.03020131029188633}, {"id": 104, "seek": 62360, "start": 629.6, "end": 635.44, "text": " paper. But I'm going to try my best to convey the key bits. First, what is the definition of", "tokens": [50664, 3035, 13, 583, 286, 478, 516, 281, 853, 452, 1151, 281, 16965, 264, 2141, 9239, 13, 2386, 11, 437, 307, 264, 7123, 295, 50956], "temperature": 0.0, "avg_logprob": -0.07959571127164161, "compression_ratio": 1.6498316498316499, "no_speech_prob": 0.03020131029188633}, {"id": 105, "seek": 62360, "start": 635.44, "end": 640.5600000000001, "text": " consciousness that they are working with? Well, skipping the jargon, they essentially say, if you", "tokens": [50956, 10081, 300, 436, 366, 1364, 365, 30, 1042, 11, 31533, 264, 15181, 10660, 11, 436, 4476, 584, 11, 498, 291, 51212], "temperature": 0.0, "avg_logprob": -0.07959571127164161, "compression_ratio": 1.6498316498316499, "no_speech_prob": 0.03020131029188633}, {"id": 106, "seek": 62360, "start": 640.5600000000001, "end": 646.16, "text": " are reading this report on a screen, you are having a conscious visual experience of the screen. That", "tokens": [51212, 366, 3760, 341, 2275, 322, 257, 2568, 11, 291, 366, 1419, 257, 6648, 5056, 1752, 295, 264, 2568, 13, 663, 51492], "temperature": 0.0, "avg_logprob": -0.07959571127164161, "compression_ratio": 1.6498316498316499, "no_speech_prob": 0.03020131029188633}, {"id": 107, "seek": 62360, "start": 646.16, "end": 652.0, "text": " is separated from sentence, which is also sometimes used to mean being capable of pleasure or pain.", "tokens": [51492, 307, 12005, 490, 8174, 11, 597, 307, 611, 2171, 1143, 281, 914, 885, 8189, 295, 6834, 420, 1822, 13, 51784], "temperature": 0.0, "avg_logprob": -0.07959571127164161, "compression_ratio": 1.6498316498316499, "no_speech_prob": 0.03020131029188633}, {"id": 108, "seek": 65200, "start": 652.0, "end": 656.64, "text": " And they say that it's possible for a system to be sentient without being conscious by sensing", "tokens": [50364, 400, 436, 584, 300, 309, 311, 1944, 337, 257, 1185, 281, 312, 2279, 1196, 1553, 885, 6648, 538, 30654, 50596], "temperature": 0.0, "avg_logprob": -0.09195268804376776, "compression_ratio": 1.9, "no_speech_prob": 0.011685071513056755}, {"id": 109, "seek": 65200, "start": 656.64, "end": 662.08, "text": " its body or environment. And it's possible for a system to be conscious without sensing its body", "tokens": [50596, 1080, 1772, 420, 2823, 13, 400, 309, 311, 1944, 337, 257, 1185, 281, 312, 6648, 1553, 30654, 1080, 1772, 50868], "temperature": 0.0, "avg_logprob": -0.09195268804376776, "compression_ratio": 1.9, "no_speech_prob": 0.011685071513056755}, {"id": 110, "seek": 65200, "start": 662.08, "end": 667.92, "text": " or environment. It also might be possible to be slightly conscious or conscious to a greater", "tokens": [50868, 420, 2823, 13, 467, 611, 1062, 312, 1944, 281, 312, 4748, 6648, 420, 6648, 281, 257, 5044, 51160], "temperature": 0.0, "avg_logprob": -0.09195268804376776, "compression_ratio": 1.9, "no_speech_prob": 0.011685071513056755}, {"id": 111, "seek": 65200, "start": 667.92, "end": 674.56, "text": " degree than humans. Ilya Sutskova famously said, it may be that today's large neural networks are", "tokens": [51160, 4314, 813, 6255, 13, 286, 45106, 318, 3648, 4093, 2757, 34360, 848, 11, 309, 815, 312, 300, 965, 311, 2416, 18161, 9590, 366, 51492], "temperature": 0.0, "avg_logprob": -0.09195268804376776, "compression_ratio": 1.9, "no_speech_prob": 0.011685071513056755}, {"id": 112, "seek": 65200, "start": 674.56, "end": 680.24, "text": " slightly conscious. And the Karl Schulman and Nick Bostrom wrote an entire chapter of a book", "tokens": [51492, 4748, 6648, 13, 400, 264, 20405, 21223, 1601, 293, 9449, 363, 555, 4397, 4114, 364, 2302, 7187, 295, 257, 1446, 51776], "temperature": 0.0, "avg_logprob": -0.09195268804376776, "compression_ratio": 1.9, "no_speech_prob": 0.011685071513056755}, {"id": 113, "seek": 68024, "start": 680.24, "end": 685.12, "text": " on the possibility that models become more conscious than human beings. They say such", "tokens": [50364, 322, 264, 7959, 300, 5245, 1813, 544, 6648, 813, 1952, 8958, 13, 814, 584, 1270, 50608], "temperature": 0.0, "avg_logprob": -0.06322906328284222, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00225163996219635}, {"id": 114, "seek": 68024, "start": 685.12, "end": 689.92, "text": " beings could contribute immense value to the world and failing to respect their interests could", "tokens": [50608, 8958, 727, 10586, 22920, 2158, 281, 264, 1002, 293, 18223, 281, 3104, 641, 8847, 727, 50848], "temperature": 0.0, "avg_logprob": -0.06322906328284222, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00225163996219635}, {"id": 115, "seek": 68024, "start": 689.92, "end": 695.76, "text": " produce a moral catastrophe. One of the theories of consciousness discussed is recurrent processing", "tokens": [50848, 5258, 257, 9723, 36043, 13, 1485, 295, 264, 13667, 295, 10081, 7152, 307, 18680, 1753, 9007, 51140], "temperature": 0.0, "avg_logprob": -0.06322906328284222, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00225163996219635}, {"id": 116, "seek": 68024, "start": 695.76, "end": 701.6800000000001, "text": " theory. And here is the key part of that theory. One initial feed forward sweep of activity through", "tokens": [51140, 5261, 13, 400, 510, 307, 264, 2141, 644, 295, 300, 5261, 13, 1485, 5883, 3154, 2128, 22169, 295, 5191, 807, 51436], "temperature": 0.0, "avg_logprob": -0.06322906328284222, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00225163996219635}, {"id": 117, "seek": 68024, "start": 701.6800000000001, "end": 707.12, "text": " the hierarchy of visual areas is sufficient for some visual operations like extracting features", "tokens": [51436, 264, 22333, 295, 5056, 3179, 307, 11563, 337, 512, 5056, 7705, 411, 49844, 4122, 51708], "temperature": 0.0, "avg_logprob": -0.06322906328284222, "compression_ratio": 1.7220216606498195, "no_speech_prob": 0.00225163996219635}, {"id": 118, "seek": 70712, "start": 707.12, "end": 713.04, "text": " from a scene, but not sufficient for conscious experience. However, when the stimulus is sufficiently", "tokens": [50364, 490, 257, 4145, 11, 457, 406, 11563, 337, 6648, 1752, 13, 2908, 11, 562, 264, 21366, 307, 31868, 50660], "temperature": 0.0, "avg_logprob": -0.055423193199689996, "compression_ratio": 1.6375, "no_speech_prob": 0.008846113458275795}, {"id": 119, "seek": 70712, "start": 713.04, "end": 718.32, "text": " strong or salient, we get this looped recurrent processing in which signals are sent back from", "tokens": [50660, 2068, 420, 1845, 1196, 11, 321, 483, 341, 6367, 292, 18680, 1753, 9007, 294, 597, 12354, 366, 2279, 646, 490, 50924], "temperature": 0.0, "avg_logprob": -0.055423193199689996, "compression_ratio": 1.6375, "no_speech_prob": 0.008846113458275795}, {"id": 120, "seek": 70712, "start": 718.32, "end": 725.28, "text": " higher areas to lower ones. It's only then that you get a conscious representation of an organized", "tokens": [50924, 2946, 3179, 281, 3126, 2306, 13, 467, 311, 787, 550, 300, 291, 483, 257, 6648, 10290, 295, 364, 9983, 51272], "temperature": 0.0, "avg_logprob": -0.055423193199689996, "compression_ratio": 1.6375, "no_speech_prob": 0.008846113458275795}, {"id": 121, "seek": 70712, "start": 725.28, "end": 731.2, "text": " scene. The paper then draws indicators based on each theory. For example, if recurrent processing", "tokens": [51272, 4145, 13, 440, 3035, 550, 20045, 22176, 2361, 322, 1184, 5261, 13, 1171, 1365, 11, 498, 18680, 1753, 9007, 51568], "temperature": 0.0, "avg_logprob": -0.055423193199689996, "compression_ratio": 1.6375, "no_speech_prob": 0.008846113458275795}, {"id": 122, "seek": 73120, "start": 731.2, "end": 737.84, "text": " theory is accurate, then here are two indicators that something would be conscious. They then draw", "tokens": [50364, 5261, 307, 8559, 11, 550, 510, 366, 732, 22176, 300, 746, 576, 312, 6648, 13, 814, 550, 2642, 50696], "temperature": 0.0, "avg_logprob": -0.06958884133232965, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.020325617864727974}, {"id": 123, "seek": 73120, "start": 737.84, "end": 744.32, "text": " analogies for each theory to AI systems. For example, on recurrence, specifically algorithmic", "tokens": [50696, 16660, 530, 337, 1184, 5261, 281, 7318, 3652, 13, 1171, 1365, 11, 322, 18680, 10760, 11, 4682, 9284, 299, 51020], "temperature": 0.0, "avg_logprob": -0.06958884133232965, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.020325617864727974}, {"id": 124, "seek": 73120, "start": 744.32, "end": 749.6, "text": " recurrence, they say that's a weak condition that many AI systems already meet. But don't forget", "tokens": [51020, 18680, 10760, 11, 436, 584, 300, 311, 257, 5336, 4188, 300, 867, 7318, 3652, 1217, 1677, 13, 583, 500, 380, 2870, 51284], "temperature": 0.0, "avg_logprob": -0.06958884133232965, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.020325617864727974}, {"id": 125, "seek": 73120, "start": 749.6, "end": 755.2, "text": " when they say that it's an analogy. Not only does it require the theory to be correct, it requires", "tokens": [51284, 562, 436, 584, 300, 309, 311, 364, 21663, 13, 1726, 787, 775, 309, 3651, 264, 5261, 281, 312, 3006, 11, 309, 7029, 51564], "temperature": 0.0, "avg_logprob": -0.06958884133232965, "compression_ratio": 1.6581196581196582, "no_speech_prob": 0.020325617864727974}, {"id": 126, "seek": 75520, "start": 755.2, "end": 761.2800000000001, "text": " the analogy to hold true. i.e. is the recurrence that we see in AI a good analogy for the recurrence", "tokens": [50364, 264, 21663, 281, 1797, 2074, 13, 741, 13, 68, 13, 307, 264, 18680, 10760, 300, 321, 536, 294, 7318, 257, 665, 21663, 337, 264, 18680, 10760, 50668], "temperature": 0.0, "avg_logprob": -0.07600939475883872, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.08752403408288956}, {"id": 127, "seek": 75520, "start": 761.2800000000001, "end": 767.36, "text": " of this theory. Or what about the next one, global workspace theory? If that theory is correct, here", "tokens": [50668, 295, 341, 5261, 13, 1610, 437, 466, 264, 958, 472, 11, 4338, 32706, 5261, 30, 759, 300, 5261, 307, 3006, 11, 510, 50972], "temperature": 0.0, "avg_logprob": -0.07600939475883872, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.08752403408288956}, {"id": 128, "seek": 75520, "start": 767.36, "end": 772.72, "text": " are four indicators of something being conscious according to that theory. To be honest, if you", "tokens": [50972, 366, 1451, 22176, 295, 746, 885, 6648, 4650, 281, 300, 5261, 13, 1407, 312, 3245, 11, 498, 291, 51240], "temperature": 0.0, "avg_logprob": -0.07600939475883872, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.08752403408288956}, {"id": 129, "seek": 75520, "start": 772.72, "end": 778.88, "text": " are at all interested in consciousness, the pages on each one of these taught me a lot about tests", "tokens": [51240, 366, 412, 439, 3102, 294, 10081, 11, 264, 7183, 322, 1184, 472, 295, 613, 5928, 385, 257, 688, 466, 6921, 51548], "temperature": 0.0, "avg_logprob": -0.07600939475883872, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.08752403408288956}, {"id": 130, "seek": 75520, "start": 778.88, "end": 784.24, "text": " for consciousness and just theories of consciousness. But again, let's just say that theory is correct.", "tokens": [51548, 337, 10081, 293, 445, 13667, 295, 10081, 13, 583, 797, 11, 718, 311, 445, 584, 300, 5261, 307, 3006, 13, 51816], "temperature": 0.0, "avg_logprob": -0.07600939475883872, "compression_ratio": 1.8518518518518519, "no_speech_prob": 0.08752403408288956}, {"id": 131, "seek": 78424, "start": 784.24, "end": 790.08, "text": " Do AI systems demonstrate these indicators? Do they have modules that can work in parallel", "tokens": [50364, 1144, 7318, 3652, 11698, 613, 22176, 30, 1144, 436, 362, 16679, 300, 393, 589, 294, 8952, 50656], "temperature": 0.0, "avg_logprob": -0.0807551041390132, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.0059098186902701855}, {"id": 132, "seek": 78424, "start": 790.08, "end": 796.64, "text": " and a global workspace at the center? Is that workspace bandwidth limited, requiring the compression", "tokens": [50656, 293, 257, 4338, 32706, 412, 264, 3056, 30, 1119, 300, 32706, 23647, 5567, 11, 24165, 264, 19355, 50984], "temperature": 0.0, "avg_logprob": -0.0807551041390132, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.0059098186902701855}, {"id": 133, "seek": 78424, "start": 796.64, "end": 803.2, "text": " and selection of information from the modules? Well, here again, we can only rely on analogies,", "tokens": [50984, 293, 9450, 295, 1589, 490, 264, 16679, 30, 1042, 11, 510, 797, 11, 321, 393, 787, 10687, 322, 16660, 530, 11, 51312], "temperature": 0.0, "avg_logprob": -0.0807551041390132, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.0059098186902701855}, {"id": 134, "seek": 78424, "start": 803.2, "end": 808.64, "text": " in this case, to the transformer architecture. They say, in a sense, they do have modules,", "tokens": [51312, 294, 341, 1389, 11, 281, 264, 31782, 9482, 13, 814, 584, 11, 294, 257, 2020, 11, 436, 360, 362, 16679, 11, 51584], "temperature": 0.0, "avg_logprob": -0.0807551041390132, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.0059098186902701855}, {"id": 135, "seek": 78424, "start": 808.64, "end": 813.52, "text": " they do have a limited capacity workspace introducing a bottleneck, but then the authors", "tokens": [51584, 436, 360, 362, 257, 5567, 6042, 32706, 15424, 257, 44641, 547, 11, 457, 550, 264, 16552, 51828], "temperature": 0.0, "avg_logprob": -0.0807551041390132, "compression_ratio": 1.7169117647058822, "no_speech_prob": 0.0059098186902701855}, {"id": 136, "seek": 81352, "start": 813.52, "end": 819.28, "text": " introduce plenty of points about how the analogy is not perfect, even here. Of course, you can pause", "tokens": [50364, 5366, 7140, 295, 2793, 466, 577, 264, 21663, 307, 406, 2176, 11, 754, 510, 13, 2720, 1164, 11, 291, 393, 10465, 50652], "temperature": 0.0, "avg_logprob": -0.05432791836493838, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0028891863767057657}, {"id": 137, "seek": 81352, "start": 819.28, "end": 824.72, "text": " and read the details if you like, or indeed read the entire paper. So that's the tone of the paper.", "tokens": [50652, 293, 1401, 264, 4365, 498, 291, 411, 11, 420, 6451, 1401, 264, 2302, 3035, 13, 407, 300, 311, 264, 8027, 295, 264, 3035, 13, 50924], "temperature": 0.0, "avg_logprob": -0.05432791836493838, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0028891863767057657}, {"id": 138, "seek": 81352, "start": 824.72, "end": 831.1999999999999, "text": " If silicon can be a replacement to carbon, and if these analogies hold, then there is a strong", "tokens": [50924, 759, 22848, 393, 312, 257, 14419, 281, 5954, 11, 293, 498, 613, 16660, 530, 1797, 11, 550, 456, 307, 257, 2068, 51248], "temperature": 0.0, "avg_logprob": -0.05432791836493838, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0028891863767057657}, {"id": 139, "seek": 81352, "start": 831.1999999999999, "end": 836.24, "text": " case that most or all of the conditions for consciousness, suggested by current computational", "tokens": [51248, 1389, 300, 881, 420, 439, 295, 264, 4487, 337, 10081, 11, 10945, 538, 2190, 28270, 51500], "temperature": 0.0, "avg_logprob": -0.05432791836493838, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0028891863767057657}, {"id": 140, "seek": 81352, "start": 836.24, "end": 841.6, "text": " theories, can be met using existing techniques in AI. This is not to say that current AI systems", "tokens": [51500, 13667, 11, 393, 312, 1131, 1228, 6741, 7512, 294, 7318, 13, 639, 307, 406, 281, 584, 300, 2190, 7318, 3652, 51768], "temperature": 0.0, "avg_logprob": -0.05432791836493838, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.0028891863767057657}, {"id": 141, "seek": 84160, "start": 841.6, "end": 845.9200000000001, "text": " are likely to be conscious. There is also the issue of whether they combine existing techniques", "tokens": [50364, 366, 3700, 281, 312, 6648, 13, 821, 307, 611, 264, 2734, 295, 1968, 436, 10432, 6741, 7512, 50580], "temperature": 0.0, "avg_logprob": -0.04428219361738725, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.008845837786793709}, {"id": 142, "seek": 84160, "start": 845.9200000000001, "end": 850.8000000000001, "text": " in the right ways. But it does suggest that conscious AI is not merely a remote possibility in the", "tokens": [50580, 294, 264, 558, 2098, 13, 583, 309, 775, 3402, 300, 6648, 7318, 307, 406, 17003, 257, 8607, 7959, 294, 264, 50824], "temperature": 0.0, "avg_logprob": -0.04428219361738725, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.008845837786793709}, {"id": 143, "seek": 84160, "start": 850.8000000000001, "end": 856.64, "text": " distant future. And here is the key bit. If it is at all possible to build conscious AI systems", "tokens": [50824, 17275, 2027, 13, 400, 510, 307, 264, 2141, 857, 13, 759, 309, 307, 412, 439, 1944, 281, 1322, 6648, 7318, 3652, 51116], "temperature": 0.0, "avg_logprob": -0.04428219361738725, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.008845837786793709}, {"id": 144, "seek": 84160, "start": 856.64, "end": 862.24, "text": " without radically new hardware, it may be possible now. Of course, even if all of those conditions", "tokens": [51116, 1553, 35508, 777, 8837, 11, 309, 815, 312, 1944, 586, 13, 2720, 1164, 11, 754, 498, 439, 295, 729, 4487, 51396], "temperature": 0.0, "avg_logprob": -0.04428219361738725, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.008845837786793709}, {"id": 145, "seek": 84160, "start": 862.24, "end": 868.1600000000001, "text": " and analogies hold, it may not be the same type of consciousness as our consciousness. It seems", "tokens": [51396, 293, 16660, 530, 1797, 11, 309, 815, 406, 312, 264, 912, 2010, 295, 10081, 382, 527, 10081, 13, 467, 2544, 51692], "temperature": 0.0, "avg_logprob": -0.04428219361738725, "compression_ratio": 1.7446043165467626, "no_speech_prob": 0.008845837786793709}, {"id": 146, "seek": 86816, "start": 868.16, "end": 873.8399999999999, "text": " possible, they say, to imagine a conscious being that had only a succession of brief static", "tokens": [50364, 1944, 11, 436, 584, 11, 281, 3811, 257, 6648, 885, 300, 632, 787, 257, 36624, 295, 5353, 13437, 50648], "temperature": 0.0, "avg_logprob": -0.07441476520739104, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.0016483357176184654}, {"id": 147, "seek": 86816, "start": 873.8399999999999, "end": 878.64, "text": " discrete experiences, perhaps just during pre-training. Or they might have experiences", "tokens": [50648, 27706, 5235, 11, 4317, 445, 1830, 659, 12, 17227, 1760, 13, 1610, 436, 1062, 362, 5235, 50888], "temperature": 0.0, "avg_logprob": -0.07441476520739104, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.0016483357176184654}, {"id": 148, "seek": 86816, "start": 878.64, "end": 884.3199999999999, "text": " without feeling that they are a persisting subject. But my own summary is this. We clearly", "tokens": [50888, 1553, 2633, 300, 436, 366, 257, 13233, 278, 3983, 13, 583, 452, 1065, 12691, 307, 341, 13, 492, 4448, 51172], "temperature": 0.0, "avg_logprob": -0.07441476520739104, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.0016483357176184654}, {"id": 149, "seek": 86816, "start": 884.3199999999999, "end": 889.76, "text": " don't fully understand consciousness or what is required for consciousness. We don't know if", "tokens": [51172, 500, 380, 4498, 1223, 10081, 420, 437, 307, 4739, 337, 10081, 13, 492, 500, 380, 458, 498, 51444], "temperature": 0.0, "avg_logprob": -0.07441476520739104, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.0016483357176184654}, {"id": 150, "seek": 86816, "start": 889.76, "end": 895.52, "text": " consciousness in AI systems is theoretically impossible or imminent. The authors actually", "tokens": [51444, 10081, 294, 7318, 3652, 307, 29400, 6243, 420, 44339, 13, 440, 16552, 767, 51732], "temperature": 0.0, "avg_logprob": -0.07441476520739104, "compression_ratio": 1.674074074074074, "no_speech_prob": 0.0016483357176184654}, {"id": 151, "seek": 89552, "start": 895.52, "end": 900.8, "text": " quote this open letter from the Association for Mathematical Consciousness Science. And in it,", "tokens": [50364, 6513, 341, 1269, 5063, 490, 264, 10734, 337, 15776, 8615, 804, 6923, 4139, 1287, 8976, 13, 400, 294, 309, 11, 50628], "temperature": 0.0, "avg_logprob": -0.08109441793189859, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.010010524652898312}, {"id": 152, "seek": 89552, "start": 900.8, "end": 906.24, "text": " at the end, the letter says, we emphasize that the rapid development of AI is exposing the urgent", "tokens": [50628, 412, 264, 917, 11, 264, 5063, 1619, 11, 321, 16078, 300, 264, 7558, 3250, 295, 7318, 307, 33178, 264, 19022, 50900], "temperature": 0.0, "avg_logprob": -0.08109441793189859, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.010010524652898312}, {"id": 153, "seek": 89552, "start": 906.24, "end": 911.1999999999999, "text": " need to accelerate research in the field of consciousness science, even if we develop a", "tokens": [50900, 643, 281, 21341, 2132, 294, 264, 2519, 295, 10081, 3497, 11, 754, 498, 321, 1499, 257, 51148], "temperature": 0.0, "avg_logprob": -0.08109441793189859, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.010010524652898312}, {"id": 154, "seek": 89552, "start": 911.1999999999999, "end": 916.16, "text": " system that ticks all of these indicators. And trust me, someone is probably working on that", "tokens": [51148, 1185, 300, 42475, 439, 295, 613, 22176, 13, 400, 3361, 385, 11, 1580, 307, 1391, 1364, 322, 300, 51396], "temperature": 0.0, "avg_logprob": -0.08109441793189859, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.010010524652898312}, {"id": 155, "seek": 89552, "start": 916.16, "end": 921.4399999999999, "text": " right now. We still won't know for sure, and many people will deny forever that that system", "tokens": [51396, 558, 586, 13, 492, 920, 1582, 380, 458, 337, 988, 11, 293, 867, 561, 486, 15744, 5680, 300, 300, 1185, 51660], "temperature": 0.0, "avg_logprob": -0.08109441793189859, "compression_ratio": 1.6607142857142858, "no_speech_prob": 0.010010524652898312}, {"id": 156, "seek": 92144, "start": 921.44, "end": 925.7600000000001, "text": " is conscious. I'm not claiming I have the answer, by the way. I have absolutely no idea", "tokens": [50364, 307, 6648, 13, 286, 478, 406, 19232, 286, 362, 264, 1867, 11, 538, 264, 636, 13, 286, 362, 3122, 572, 1558, 50580], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 157, "seek": 92144, "start": 925.7600000000001, "end": 930.08, "text": " if these systems are imminently conscious, already conscious, or will never be conscious.", "tokens": [50580, 498, 613, 3652, 366, 40728, 2276, 6648, 11, 1217, 6648, 11, 420, 486, 1128, 312, 6648, 13, 50796], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 158, "seek": 92144, "start": 930.08, "end": 935.12, "text": " All I can say is that it's a bit less sci-fi than many people believe. And the authors also point", "tokens": [50796, 1057, 286, 393, 584, 307, 300, 309, 311, 257, 857, 1570, 2180, 12, 13325, 813, 867, 561, 1697, 13, 400, 264, 16552, 611, 935, 51048], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 159, "seek": 92144, "start": 935.12, "end": 940.5600000000001, "text": " out two risks, under attributing consciousness to AI, playing down the possibility. But they also", "tokens": [51048, 484, 732, 10888, 11, 833, 9080, 10861, 10081, 281, 7318, 11, 2433, 760, 264, 7959, 13, 583, 436, 611, 51320], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 160, "seek": 92144, "start": 940.5600000000001, "end": 946.0, "text": " point out the risk of over attributing consciousness to AI. On under attributing consciousness,", "tokens": [51320, 935, 484, 264, 3148, 295, 670, 9080, 10861, 10081, 281, 7318, 13, 1282, 833, 9080, 10861, 10081, 11, 51592], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 161, "seek": 92144, "start": 946.0, "end": 951.2800000000001, "text": " they say this, given the uncertainties about consciousness mentioned above, we may create", "tokens": [51592, 436, 584, 341, 11, 2212, 264, 11308, 6097, 466, 10081, 2835, 3673, 11, 321, 815, 1884, 51856], "temperature": 0.0, "avg_logprob": -0.07584288693213648, "compression_ratio": 1.9409722222222223, "no_speech_prob": 0.0636836439371109}, {"id": 162, "seek": 95128, "start": 951.28, "end": 956.72, "text": " conscious AI systems long before we recognize that we have done so. And I see this sentence as a", "tokens": [50364, 6648, 7318, 3652, 938, 949, 321, 5521, 300, 321, 362, 1096, 370, 13, 400, 286, 536, 341, 8174, 382, 257, 50636], "temperature": 0.0, "avg_logprob": -0.06084522834190956, "compression_ratio": 1.577922077922078, "no_speech_prob": 0.0014100531116127968}, {"id": 163, "seek": 95128, "start": 956.72, "end": 962.48, "text": " fateful prediction. This tendency is further amplified when AI systems exhibit human-like", "tokens": [50636, 283, 7529, 17630, 13, 639, 18187, 307, 3052, 49237, 562, 7318, 3652, 20487, 1952, 12, 4092, 50924], "temperature": 0.0, "avg_logprob": -0.06084522834190956, "compression_ratio": 1.577922077922078, "no_speech_prob": 0.0014100531116127968}, {"id": 164, "seek": 95128, "start": 962.48, "end": 968.0, "text": " characteristics, such as natural language processing, which they already do, but also facial expressions", "tokens": [50924, 10891, 11, 1270, 382, 3303, 2856, 9007, 11, 597, 436, 1217, 360, 11, 457, 611, 15642, 15277, 51200], "temperature": 0.0, "avg_logprob": -0.06084522834190956, "compression_ratio": 1.577922077922078, "no_speech_prob": 0.0014100531116127968}, {"id": 165, "seek": 95128, "start": 968.0, "end": 972.8, "text": " or adaptive learning capabilities. So imagine what people are going to think when photo-realistic", "tokens": [51200, 420, 27912, 2539, 10862, 13, 407, 3811, 437, 561, 366, 516, 281, 519, 562, 5052, 12, 9342, 3142, 51440], "temperature": 0.0, "avg_logprob": -0.06084522834190956, "compression_ratio": 1.577922077922078, "no_speech_prob": 0.0014100531116127968}, {"id": 166, "seek": 95128, "start": 972.8, "end": 979.36, "text": " AI avatars are everywhere. And finally, there is the risk of experimentation itself. On balance,", "tokens": [51440, 7318, 1305, 267, 685, 366, 5315, 13, 400, 2721, 11, 456, 307, 264, 3148, 295, 37142, 2564, 13, 1282, 4772, 11, 51768], "temperature": 0.0, "avg_logprob": -0.06084522834190956, "compression_ratio": 1.577922077922078, "no_speech_prob": 0.0014100531116127968}, {"id": 167, "seek": 97936, "start": 979.36, "end": 984.64, "text": " we believe that research to better understand the mechanisms which might underlie consciousness in AI", "tokens": [50364, 321, 1697, 300, 2132, 281, 1101, 1223, 264, 15902, 597, 1062, 833, 6302, 10081, 294, 7318, 50628], "temperature": 0.0, "avg_logprob": -0.039624533606964406, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002550621749833226}, {"id": 168, "seek": 97936, "start": 984.64, "end": 989.84, "text": " is beneficial. However, of course, research on this topic runs the risk of building or enabling", "tokens": [50628, 307, 14072, 13, 2908, 11, 295, 1164, 11, 2132, 322, 341, 4829, 6676, 264, 3148, 295, 2390, 420, 23148, 50888], "temperature": 0.0, "avg_logprob": -0.039624533606964406, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002550621749833226}, {"id": 169, "seek": 97936, "start": 989.84, "end": 994.88, "text": " others to build a conscious AI system, which should not be done lightly, and that mitigating", "tokens": [50888, 2357, 281, 1322, 257, 6648, 7318, 1185, 11, 597, 820, 406, 312, 1096, 16695, 11, 293, 300, 15699, 990, 51140], "temperature": 0.0, "avg_logprob": -0.039624533606964406, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002550621749833226}, {"id": 170, "seek": 97936, "start": 994.88, "end": 1000.08, "text": " this kind of risk should be carefully weighed against the value of better understanding consciousness", "tokens": [51140, 341, 733, 295, 3148, 820, 312, 7500, 32844, 1970, 264, 2158, 295, 1101, 3701, 10081, 51400], "temperature": 0.0, "avg_logprob": -0.039624533606964406, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002550621749833226}, {"id": 171, "seek": 97936, "start": 1000.08, "end": 1005.6, "text": " in AI. And to tie this back to the start of the video, Google's AI safety experts have added", "tokens": [51400, 294, 7318, 13, 400, 281, 7582, 341, 646, 281, 264, 722, 295, 264, 960, 11, 3329, 311, 7318, 4514, 8572, 362, 3869, 51676], "temperature": 0.0, "avg_logprob": -0.039624533606964406, "compression_ratio": 1.7636363636363637, "no_speech_prob": 0.002550621749833226}, {"id": 172, "seek": 100560, "start": 1005.6800000000001, "end": 1010.16, "text": " that some users who grew too dependent on this technology could think it was sentient.", "tokens": [50368, 300, 512, 5022, 567, 6109, 886, 12334, 322, 341, 2899, 727, 519, 309, 390, 2279, 1196, 13, 50592], "temperature": 0.0, "avg_logprob": -0.15048349280106393, "compression_ratio": 1.4780876494023905, "no_speech_prob": 0.052558183670043945}, {"id": 173, "seek": 100560, "start": 1010.16, "end": 1016.16, "text": " And I do wonder if that's an eventuality, Google's newly merged AI SWOT team is preparing for.", "tokens": [50592, 400, 286, 360, 2441, 498, 300, 311, 364, 33160, 507, 11, 3329, 311, 15109, 36427, 7318, 20346, 5068, 1469, 307, 10075, 337, 13, 50892], "temperature": 0.0, "avg_logprob": -0.15048349280106393, "compression_ratio": 1.4780876494023905, "no_speech_prob": 0.052558183670043945}, {"id": 174, "seek": 100560, "start": 1016.16, "end": 1020.4, "text": " As always, thank you so much for watching to the end and have a wonderful day.", "tokens": [50892, 1018, 1009, 11, 1309, 291, 370, 709, 337, 1976, 281, 264, 917, 293, 362, 257, 3715, 786, 13, 51104], "temperature": 0.0, "avg_logprob": -0.15048349280106393, "compression_ratio": 1.4780876494023905, "no_speech_prob": 0.052558183670043945}, {"id": 175, "seek": 100560, "start": 1020.4, "end": 1026.08, "text": " Oh, and just quickly before I end, I now have a discord, AI Explained Community. More info in the", "tokens": [51104, 876, 11, 293, 445, 2661, 949, 286, 917, 11, 286, 586, 362, 257, 32989, 11, 7318, 12514, 3563, 10421, 13, 5048, 13614, 294, 264, 51388], "temperature": 0.0, "avg_logprob": -0.15048349280106393, "compression_ratio": 1.4780876494023905, "no_speech_prob": 0.052558183670043945}, {"id": 176, "seek": 100560, "start": 1026.08, "end": 1026.72, "text": " description.", "tokens": [51388, 3855, 13, 51420], "temperature": 0.0, "avg_logprob": -0.15048349280106393, "compression_ratio": 1.4780876494023905, "no_speech_prob": 0.052558183670043945}], "language": "en"}