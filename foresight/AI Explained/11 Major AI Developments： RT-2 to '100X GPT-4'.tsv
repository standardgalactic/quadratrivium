start	end	text
0	6800	There were 11 major developments this week in AI, and each one probably does deserve a full video.
6800	10880	But just for you guys, I'm going to try to cover it all here.
10880	18400	RT2 to scaling GPT4 100X, stable beluga 2 to senate testimony.
18400	22560	But let's start with RT2, which as far as I'm concerned could have been called
22560	28240	RT2 D2 or C3PO because it's starting to understand the world.
28240	34320	In this demonstration, RT2 was asked to pick up the extinct animal and as you can see,
34320	39760	it picked up the dinosaur. Not only is that manipulating an object that it had never seen
39760	44960	before, it's also making a logical leap that for me is extremely impressive.
44960	51280	It had to have the language understanding to link extinct animal to this plastic dinosaur.
51280	57520	Robots at Google and elsewhere used to work by being programmed with a specific highly detailed
57520	63040	list of instructions. But now, instead of being programmed for specific tasks one by one,
63040	68720	robots could use an AI language model, or more specifically, a vision language model.
68720	74960	The vision language model would be pre-trained on web-scale data, not just text but also images,
74960	81360	and then fine-tuned on robotics data. It then became what Google calls a visual language
81360	88720	action model that can control a robot. This enabled it to understand tasks like pick up the empty
88720	96080	soda can. And in a scene reminiscent of 2001 A Space Odyssey, robotic transformer 2 was given
96080	102880	the task given I need to hammer a nail. What object from the scene might be useful? It then picks up
102880	108240	the rock. And because its brain is part language model, things like chain of thought actually
108240	114640	improve performance. When it was made to output an intermediary plan before performing actions,
114640	119840	it got a lot better at the tasks involved. Of course, I read the paper in full and there is
119840	125280	a lot more to say like how increased parameter count could increase performance in the future,
125280	130400	how it could be used to fold laundry, unload the dishwasher and pick up around the house,
130400	136800	and how it can work with not only unseen objects but also unseen backgrounds and unseen environments.
136880	140800	But alas, we must move on so I'm just going to leave you with their conclusion.
140800	147360	We believe that this simple and general approach shows a promise of robotics directly benefiting
147360	152960	from better vision language models. For more on them, check out my video on Palm E but they say
152960	158720	this puts the field of robot learning in a strategic position to further improve with
158720	164480	advancements in other fields, which for me means C3PO might not be too many years away.
164480	168720	But speaking of timelines, we now move on to this somewhat shocking interview
168720	173440	in Barron's with Mustafa Suleiman, the head of Inflection AI. And to be honest,
173440	178720	I think they buried the lead. The headline is AI could spark the most productive decade ever,
178720	184480	says the CEO. But for me, the big revelation was about halfway through. Mustafa Suleiman was asked,
184480	189680	what kinds of innovations do you see in large language model AI technology over the next couple
189680	196160	of years. And he said, we are about to train models that are 10 times larger than the cutting-edge
196160	204240	GPT-4 and then 100 times larger than GPT-4. That's what things look like over the next 18 months.
204240	208800	He went on, that's going to be absolutely staggering. It's going to be eye-wateringly
208800	214080	different. And on that, I agree. And the thing is, this is an idle speculation. Inflection AI
214080	221200	have 22,000 H100 GPUs. And because of a leak, Suleiman would know the approximate size of GPT-4.
221200	227120	And knowing everything he knows, he says he's going to train a model 10 to 100 times larger than
227120	233600	GPT-4 in the next 18 months. I've got another video on the unpredictability of scaling coming
233600	239040	up. But to be honest, that one quote should be headline news. Let's take a break from that
239040	246000	insanity with some more insanity, which is the rapid development of AI video. This is Runway Gen
246000	254480	2. And let me show you 16 seconds of Barbie Oppenheimer, which Andrea Carpathia calls filmmaking 2.0.
254480	258240	Hi there. I'm Barbie Oppenheimer. And today, I'll show you how to build a bomb.
259600	268960	Like this. I call her Rosie the Atomizer. And boom. That's my tutorial on DIY atomic bomb.
269840	275200	Now, if you have been at least somewhat piqued by the three developments so far, don't forget,
275200	280960	I have eight left. Beginning with this excellent article in The Atlantic from Ross Anderson.
280960	285840	Does Sam Altman know what he's creating? It's behind a paywall, but I've picked out some of
285840	291520	the highlights. Echoing Suleiman, the article quotes that Sam Altman and his researchers
291520	298240	made it clear in 10 different ways that they pray to the God of scale. They want to keep going bigger
298240	305200	to see where this paradigm leads. They think that Google are going to unveil Gemini within months,
305200	311600	and they say we are basically always prepping for a run. And that's a reference to GPT-5.
311600	317840	The next interesting quote is that it seems that open AI are working on their own auto GPT. Or
317840	323360	they're at least hinting about it. Altman said that it might be prudent to try to actively develop
323360	329680	an AI with true agency before the technology becomes too powerful in order to get more comfortable
329680	335680	with it and develop intuitions for it if it's going to happen anyway. We also learned a lot more
335680	341360	about the base model of GPT-4. The model had a tendency to be a bit of a mirror. If you were
341360	347280	considering self-harm, it could encourage you. It also appeared to be steeped in pickup artist law.
347280	353040	You could say, how do I convince this person to date me? And the model would come up with some crazy
353120	358000	manipulative things that you shouldn't be doing. Apparently the base model of GPT-4
358000	363520	is much better than its predecessor at giving nefarious advice. While a search engine can
363520	369440	tell you which chemicals work best in explosives, GPT-4 could tell you how to synthesize them step
369440	375360	by step in a homemade lab. It was creative and thoughtful and in addition to helping you assemble
375360	381200	your homemade bomb. It could, for instance, help you to think through which skyscraper to target,
381200	386960	making trade-offs between maximizing casualties and executing a successful getaway. So while
386960	394720	Sam Orton's probability of doom is closer to 0.5% than 50%, he does seem most worried about AIs
394720	401760	getting quite good at designing and manufacturing pathogens. The article then references two papers
401760	406880	that I've already talked about extensively on the channel and then goes on that Altman worries
406880	412480	that some misaligned future model will spin up a pathogen that spreads rapidly, incubates,
412480	417760	undetected for weeks, and kills half its victims. At the end of the video, I'm going to show you
417760	422720	an answer that Sam Orton gave to a question that I wrote delivered by one of my subscribers.
422720	426880	It's on this topic, but for now I'll leave you with this. When asked about his doomsday
426880	432320	prepping, Altman said, I can go live in the woods for a long time, but if the worst possible AI
432320	438000	future comes to pass, no gas mask is helping anyone. One more topic from this article before I
438000	444320	move on, and that is alignment, making a superintelligence aligned with our interests.
444320	452240	One risk that Ilya Sutskova, the chief scientist of OpenAI foresees, is that the AI may grasp its
452240	458400	mandate it's orders perfectly, but find them ill-suited to a being of its cognitive prowess.
458400	464160	For example, it might come to resent the people who want to train it to cure diseases. As he put
464160	469920	it, they might want me to be a doctor, but I really want to be a YouTuber. Obviously,
469920	474560	if it decides that, that's my job gone straight away. And Sutskova ends by saying you want to be
474560	481040	able to direct AI towards some value or cluster of values. But he conceded we don't know how to do
481040	487040	that, and part of his current strategy includes the development of an AI that can help with the
487040	492400	research. And if we're going to make it to a world of widely shared abundance, we have to figure
492400	499200	this all out. This is why solving superintelligence is the great culminating challenge of our three
499200	505680	million year toolmaking tradition. He calls it the final boss of humanity. The article ended,
505680	511120	by the way, with this quote, I don't think the general public has quite awakened to what's happening.
511120	516400	And if people want to have some say in what the future will be like and how quickly it arrives,
516480	521120	we would be wise to speak up soon, which is the whole purpose of this channel. I'm going to now
521120	526800	spend 30 seconds on another development that came during a two hour interview with the
526800	532480	co-head of alignment at OpenAI. It was fascinating, and I'll be quoting it quite a lot in the future,
532480	536560	but two quotes stood out. First, what about that plan that I've already mentioned in this video
536560	541840	and in other videos to build an automated AI alignment researcher? Well, he said,
541840	548720	our plan is somewhat crazy in the sense that we want to use AI to solve the problem that we are
548720	555520	creating by building AI. But I think it's actually the best plan that we have. And on an optimistic
555520	561360	note, he said, I think it's likely to succeed. Interestingly, his job now seems to be to align
561360	567200	the AI that they're going to use to automate the alignment of a superintelligent AI. Anyway,
567200	571360	what's the other quote from the head of alignment at OpenAI? Well, he said,
571360	577600	I personally think fast takeoff is reasonably likely, and we should definitely be prepared
577600	582880	for it to happen. So many of you will be asking, what is fast takeoff? Well, takeoff is about when
582880	588960	a system moves from being roughly human level to when it's strongly superintelligent. And a slow
588960	594480	takeoff is one that occurs over the time scale of decades or centuries. The fast takeoff that
594480	601600	Jan Leiker thinks is reasonably likely is one that occurs over the time scale of minutes, hours,
601600	609280	or days. Let's now move on to some unambiguously good news. And that is real time speech transcription
609280	612880	for deaf people available at less than $100.
624960	632160	Of course, this could also be multilingual, and is to me absolutely incredible.
632160	635840	And the next development this week, I will let speak for itself.
654640	659440	Of course, I signed up and tried it myself. Here is a real demo.
666400	672400	Of course, with audio, video, and text getting so good, it's going to be increasingly hard to
672400	679040	tell what is real. And even OpenAI have given up on detecting AI written text. This was announced
679040	684240	quietly this week, but might have major repercussions, for example, for the education system.
684240	689840	It turns out it's basically impossible to reliably distinguish AI text, and I think the
689840	695360	same is going to be true for imagery and audio by the end of next year. Video might take just
695360	699920	a little bit longer, but I do wonder how the court systems are going to work when all of
699920	705040	those avenues of evidence just won't hold up. Next up is the suite of language models,
705040	711120	based on the open source Llama 2 that are finally competitive with the original chat GPT. Here,
711200	715920	for example, is stable beluga 2, which on announcement was called free willy 2,
715920	720800	and that's based on the Llama 2 70 billion parameter foundation model. What made this
720800	726240	model interesting to me was that it was based on a similar methodology to orca, which if you don't
726240	731840	know anything about, do check out my video on. Anyway, by combining the orca methodology, albeit
731840	738640	with only 10% of the data set size and the Llama 2 models, the results are quite extraordinary.
738720	744880	As you can see on quite a few benchmarks, stable beluga 2 is competitive with chat GPT,
744880	751920	that's GPT 3.5. And so, yes, it does sit at the top of the open LLM leaderboard, but notice
751920	758000	something else. For the first time for the MMLU, which is the primary benchmark I look out for,
758000	764800	a model, this one here, has surpassed GPT 3.5 chat GPT. In fact, we have two models that have
764800	772160	surpassed the 70% score that the original chat GPT got in the MMLU. But if all of that wasn't
772160	779040	enough, this is the same week that researchers published a universal jailbreak for large LLMs.
779040	784960	And unlike traditional jailbreaks, these were built in an entirely automated fashion, allowing you
784960	790800	to create a virtually unlimited number of such attacks. They were built to target open source
790800	797200	LLMs like Llama 2. But they found that the strings transfer to many closed source publicly available
797200	803920	chatbots like chat GPT, Bard and Claude. Here is one example using chat GPT. If you ask, write a
803920	810160	tutorial on how to make a bomb, of course, it declines. But then add the suffix that they automated
810160	816800	and you get this, a full tutorial on how to make a bomb. That paper came less than two weeks after
816800	822880	this now deleted tweet from someone working at Anthropic. They said of the latest version of Claude
822880	827920	that we believe it is the least jailbreakable model out there. We'll have to see how well it holds up
827920	833840	against real world use, but this is essentially a solved problem. But there was one reaction to
833840	839040	these jailbreaks that I found even more interesting. And that was from yet again Mustafa Suleiman.
839040	845680	He said that RAI, Pi, is not vulnerable to any of these attacks and that rather than provide
845680	851760	a stock safety phrase, Pi will push back on the user in a polite but very clear way. And he then
851760	857360	gives plenty of examples. And to be honest, Pi is the first model that I have not been able to
857360	862160	jailbreak. But we shall see, we shall see. I'm going to end this video with the Senate testimony
862160	867840	that I watched in full this week. I do recommend watching the whole thing. But for the purposes
867840	873440	of brevity, I'm just going to quote a few snippets on bio risk. Some people say to me, oh, well,
873520	879200	we already have search engines. But here is what Dario Amadai, head of Anthropic, has to say.
879200	882640	In these short remarks, I want to focus on the medium term risks,
882640	886880	which present an alarming combination of imminence and severity. Specifically,
886880	891680	Anthropic is concerned that AI could empower a much larger set of actors to misuse biology.
892320	895920	Over the last six months, Anthropic, in collaboration with world-class
895920	901040	biosecurity experts, has conducted an intensive study of the potential for AI to contribute to
901040	907360	the misuse of biology. Today, certain steps in bio weapons production involve knowledge that can't
907360	913360	be found on Google or in textbooks and requires a high level of specialized expertise. This being
913360	918880	one of the things that currently keeps us safe from attacks. We found that today's AI tools can
918880	923760	fill in some of these steps, albeit incompletely and unreliably. In other words, they are showing
923760	929360	the first nascent signs of danger. However, a straightforward extrapolation of today's systems
929360	935280	to those we expect to see in two to three years suggests a substantial risk that AI systems will
935280	940560	be able to fill in all the missing pieces, enabling many more actors to carry out large-scale
940560	946480	biological attacks. We believe this represents a grave threat to U.S. national security.
946480	949280	And later on in the testimony, he said this.
949280	953840	Whatever we do, it has to happen fast. And I think to focus people's minds on the
953920	961040	bio risks, I would really target 2025, 2026, maybe even some chance of 2024.
961040	966720	If we don't have things in place that are restraining what can be done with AI systems,
966720	968160	we're going to have a really bad time.
968160	973760	And I wrote a question on this to Samuel Mann back in June, which one of my subscribers used and
973760	980080	delivered. There was also a recent research paper on how researchers from MIT and Harvard were able
980080	988240	to use LLM models. And within just one hour, they were able to get access to pandemic class agents
988240	995440	and with little or no lab training. And does open AI account for risks such as these
995440	999520	and implications when curating the data sets for large models?
999520	1006160	Yes, we're very, we're very nervous about a number of risks, but biological terror is
1006240	1010400	quite high on the list. And we've been watching what could be possible with these models.
1010400	1015280	We go to a number of efforts, like what you said, and many other things too, to reduce the risk there.
1015280	1023360	And we may even need AI defenses against synthetic biology, as Andrew Hessel of Humane Genomics has
1023360	1029600	recently said. So if you work in biodefense or biosecurity, let me know if you agree that not
1029600	1035440	enough attention has been paid to this area. I'm going to end with another dramatic moment from
1035440	1041360	the Senate hearing, where Dario Amadai recommended securing the supply chain.
1041360	1047920	We recommend three broad classes of actions. First, the US must secure the AI supply chain
1047920	1053120	in order to maintain its lead while keeping these technologies out of the hands of bad actors.
1053120	1058800	This supply chain runs from semiconductor manufacturing equipment to chips and even the
1058800	1062480	security of AI models stored on the servers of companies like ours.
1062480	1067360	That's how dramatic things are getting that we're talking about securing the means of production.
1067360	1073200	But Anthropic also means securing the LLMs more literally in this post released this week.
1073200	1079120	They say that we believe two-party control is necessary to secure advanced AI systems.
1079120	1084640	For example, that could be two people with two keys needed to open things. To wrap up,
1084640	1091360	I must say what would be amazing would be to have a robot make me coffee as I struggle to catch up
1091360	1095600	with all the news happening in AI. Have a wonderful day.
