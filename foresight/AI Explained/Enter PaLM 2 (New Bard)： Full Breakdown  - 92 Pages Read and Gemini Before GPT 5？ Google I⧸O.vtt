WEBVTT

00:00.000 --> 00:06.960
Less than 24 hours ago, Google released the Palm 2 technical report. I have read all 92 pages,

00:06.960 --> 00:12.560
watched the Palm 2 presentation, read the release notes and have already tested the model in a dozen

00:12.560 --> 00:19.200
ways. But before getting into it all, my four main takeaways are these. First, Palm 2 is competitive

00:19.200 --> 00:25.520
with GPT-4 and while it is probably less smart overall, it's better in certain ways and that

00:26.400 --> 00:31.360
Second, Google is saying very little about the data it used to train the model or about

00:31.360 --> 00:36.720
parameters or about compute, although we can make educated guesses on each.

00:36.720 --> 00:43.280
Third, Gemini was announced to be in training and will likely rival GPT-5 while arriving earlier

00:43.280 --> 00:49.600
than GPT-5. As you probably know, Sam Orman said that GPT-5 isn't in training and won't be for a

00:49.600 --> 00:56.720
long time. Fourth, while dedicating 20 pages to bias, toxicity and misgendering, there wasn't a

00:56.720 --> 01:03.120
single page on AI impacts more broadly. Google boasted of giving Gemini planning abilities in a

01:03.120 --> 01:09.600
move that, surprise as I am to say it, makes open AI look like paragons of responsibility.

01:09.600 --> 01:16.080
So a lot to get to, but let's look at the first reason that Palm 2 is different from GPT-4. On

01:16.080 --> 01:21.680
page 3, they say we designed a more multilingual and diverse pre-training mixture, extending across

01:21.680 --> 01:26.960
hundreds of languages and domains like programming, mathematics, etc. So because the text that they

01:26.960 --> 01:32.800
train Palm 2 on is different to the text that open AI trained GPT-4 on, it means that those

01:32.800 --> 01:39.520
models have different abilities and I would say Palm 2 is better at translation and linguistics

01:39.520 --> 01:44.080
and in certain other areas which I'll get to shortly. If that's data, what about parameter

01:44.080 --> 01:50.160
count? Well, Google never actually say they only use words like it's significantly smaller than

01:50.160 --> 01:56.320
the largest Palm model, which was 540 billion parameters. Sometimes they say significantly,

01:56.320 --> 02:02.240
other times dramatically. Despite this, it significantly outperforms Palm on a variety

02:02.240 --> 02:07.440
of tasks. To all the references you may have seen to imminent 100 trillion parameter models

02:07.440 --> 02:14.240
were bogus. Skipping ahead to page 91 out of 92, in the model summary, they say further details of

02:14.240 --> 02:19.520
model size and architecture are withheld from external publication. But earlier on, they did

02:19.520 --> 02:25.040
seem to want to give hints about the parameter count inside Palm 2, which OpenAI never did. Here

02:25.040 --> 02:30.880
they present the optimal number of parameters given a certain amount of compute flops. Scaling

02:30.880 --> 02:36.560
this up to the estimated number of flops used to train Palm 2, that would give an optimal parameter

02:36.560 --> 02:43.840
count of between 100 and 200 billion. That is a comparable parameter count to GPT-3 while getting

02:43.840 --> 02:50.400
competitive performance with GPT-4. Bard is apparently now powered by Palm 2 and the inference

02:50.400 --> 02:56.560
speed is about 10 times faster than GPT-4 for the exact same prompt. And I know there are other

02:56.560 --> 03:02.160
factors that influence inference speed, but that would broadly fit with an order of magnitude

03:02.160 --> 03:07.520
fewer parameters. This has other implications, of course, and they say that Palm 2 is dramatically

03:07.520 --> 03:13.600
smaller, cheaper, and faster to serve. Not only that, Palm 2 itself comes in different sizes,

03:13.600 --> 03:19.760
as Sundar Pichai said. Palm 2 models deliver excellent foundational capabilities across a wide

03:19.760 --> 03:29.120
range of sizes. We have affectionately named them Gecko, Otter, Bison, and Unicon. Gecko is so

03:29.120 --> 03:35.360
lightweight that it can work on mobile devices fast enough for great interactive applications

03:35.360 --> 03:41.840
on-device, even when offline. I would expect Gecko to soon be inside the Google Pixel phones.

03:41.840 --> 03:47.760
Going back to data, Google cryptically said that their pre-training corpus is composed of a diverse

03:47.760 --> 03:54.480
set of sources, documents, books, code, mathematics, and conversational data. I've done a whole video

03:54.480 --> 03:59.600
on the data issues that these companies face, but suffice to say they're not saying anything about

03:59.600 --> 04:04.800
where the data comes from. Next, they don't go into detail, but they do say that Palm 2 was trained

04:04.800 --> 04:09.600
to increase the context length of a model significantly beyond that of Palm. As of today,

04:09.600 --> 04:14.720
you can input around 10,000 characters into BARD, but they end this paragraph with something a bit

04:14.720 --> 04:19.920
more interesting. They say, without demonstrating, our results show that it is possible to increase

04:20.000 --> 04:24.960
the context length of the model without hurting its performance on generic benchmarks.

04:24.960 --> 04:30.000
The bit about not hurting performance is interesting because in this experiment published a few weeks ago

04:30.000 --> 04:35.840
about extending the input size in tokens up to around 2 million tokens, the performance did drop

04:35.840 --> 04:41.840
off. If Google had found a way to increase the input size in tokens and not affect performance,

04:41.840 --> 04:47.200
that would be a breakthrough. On multilingual benchmarks, notice how the performance of Palm

04:47.200 --> 04:53.440
2 in English is not dramatically better than in other languages. In fact, in many other languages,

04:53.440 --> 04:58.800
it does better than in English. This is very different to GPT-4, which was noticeably better

04:58.800 --> 05:04.320
in English than in all other languages. As Google hinted earlier, this is likely due to the

05:04.320 --> 05:10.720
multilingual text data that Google trained Palm 2 with. In fact, on page 17, Google admit that the

05:10.720 --> 05:16.800
performance of Palm 2 exceeds Google Translate for certain languages, and they show on page 4 that

05:16.880 --> 05:23.040
it can pass the mastery exams across a range of languages like Chinese, Japanese, Italian,

05:23.040 --> 05:28.800
French, Spanish, German, etc. Look at the difference between Palm 2 and Palm in red.

05:28.800 --> 05:34.000
Now, before you rush off and try BARD in all of those languages, I tried that and apparently

05:34.000 --> 05:39.600
you can only use BARD at the moment in the following languages, English, US English, what a pity,

05:39.600 --> 05:47.440
and Japanese and Korean. But I was able to test BARD in Korean on a question translated via Google

05:47.440 --> 05:53.840
Translate from the MMLU dataset. It got the question right in each of its drafts. In contrast,

05:53.840 --> 06:00.480
GPT-4 not only got the question wrong in Korean, when I originally tested it for my smart GPT video,

06:00.480 --> 06:05.680
it got the question wrong in English. In case any of my regular viewers are wondering, I am working

06:05.680 --> 06:11.520
very hard on smart GPT to understand what it's capable of and getting it benchmarked officially,

06:11.520 --> 06:16.720
and thank you so much for all the kind offers of help in that regard. I must admit it was very

06:16.720 --> 06:24.160
interesting to see on page 14 a direct comparison between Palm 2 and GPT-4, and Google do admit

06:24.160 --> 06:30.000
for the Palm 2 results they use chain of thought prompting and self-consistency. Reading the

06:30.080 --> 06:35.520
self-consistency paper did remind me quite a lot actually of smart GPT, where it picks the

06:35.520 --> 06:41.760
most consistent answer of multiple outputs. So I do wonder if this comparison is totally fair

06:41.760 --> 06:46.800
if Palm 2 used this method and GPT-4 didn't. I'll have to talk about these benchmarks more

06:46.800 --> 06:52.160
in another video, otherwise this one would be too long, but a quick hint is that Wynogrand is

06:52.160 --> 06:58.320
about identifying what the pronoun in a sentence refers to. Google also weighed into the emerging

06:58.320 --> 07:04.160
abilities debate, saying that Palm 2 does indeed demonstrate new emerging abilities. They say it

07:04.160 --> 07:10.160
does so in things like multi-step arithmetic problems, temporal sequences, and hierarchical

07:10.160 --> 07:14.720
reasoning. Of course I'm going to test all of those and have begun to do so already, and in my

07:14.720 --> 07:20.000
early experiments I'm getting quite an interesting result. Palm 2 gets a lot of questions wrong that

07:20.000 --> 07:26.080
GPT-4 gets right, but it can also get questions right that GPT-4 gets wrong, and I must admit

07:26.080 --> 07:31.120
it's really weird to see Palm 2 getting really advanced college-level math questions right,

07:31.120 --> 07:36.960
that GPT-4 gets wrong. And yet also when I ask it a basic question about prime numbers, it gets

07:36.960 --> 07:41.920
it kind of hilariously wrong. Honestly I'm not certain what's going on there, but I do have my

07:41.920 --> 07:47.760
suspicions. Remember though that recent papers have claimed that emergent abilities are a mirage,

07:47.760 --> 07:54.320
so Google begs to differ. When Google put Palm 2 up against GPT-4 in high school mathematics problems,

07:54.320 --> 08:01.360
it did outperform GPT-4, but again it was using an advanced prompting strategy, not 100% different

08:01.360 --> 08:06.880
from smart GPT, so I wonder if the comparison is quite fair. What about coding? Well again it's

08:06.880 --> 08:12.880
really hard to find a direct comparison that's fair between the two models. Overall I would guess

08:12.880 --> 08:20.000
that the specialized coding model of Palm, what they call Palm 2S, is worse than GPT-4. It says

08:20.000 --> 08:27.840
it's pass at one accuracy, as in past first time, is 37.6%. Remember the Sparks of AGI paper? Well

08:27.840 --> 08:35.120
that gave GPT-4 as having an 82% zero shot pass at one accuracy level. However as I talked about in

08:35.120 --> 08:42.160
the Sparks of AGI video, the paper admits that it could be that GPT-4 has seen and memorized some

08:42.160 --> 08:47.840
or all of human eval. There is one thing I will give Google credit on, which is that their code

08:47.840 --> 08:53.280
now sometimes references where it came from. Here is a brief extract from the Google keynote

08:53.280 --> 08:59.760
presentation. How would I use Python to generate the Scholar's Mate move in chess? Okay here Bard

08:59.760 --> 09:05.600
created a script to recreate this chess move in Python, and notice how it also formatted the code

09:05.600 --> 09:11.200
nicely, making it easy to read. We've also heard great feedback from developers about how Bard

09:11.200 --> 09:17.280
provides code citations, and starting next week you'll notice something right here. We're making

09:17.280 --> 09:23.600
code citations even more precise. If Bard brings in a block of code, just click this annotation,

09:23.600 --> 09:28.960
and Bard will underline the block and link to the source. As always, it seems the appendix contained

09:28.960 --> 09:34.080
more interesting information sometimes than the main body of the technical report. For example,

09:34.080 --> 09:41.920
we get a direct and fair comparison between GPT-4 and palm 2, or I should say flan palm 2. That is

09:41.920 --> 09:47.440
the instruction fine tuned version of palm 2. Essentially that's the version where it's been

09:47.440 --> 09:52.560
fine tuned to get better at following a question and answer format. But anyway, the original palm

09:52.560 --> 10:02.480
2 scored 78.3%, and flan palm 2 scored 81.2%. That's below the 86.4% of GPT-4. And that's why my

10:02.480 --> 10:08.960
broad conclusion is that GPT-4 is a bit smarter than palm 2. But as I'll be showing over the

10:08.960 --> 10:15.840
coming days and weeks, there are genuinely quite a few areas in which palm 2 is better than GPT-4.

10:15.840 --> 10:20.400
What about the big bench, which was designed to be particularly tough for language models? I talked

10:20.400 --> 10:26.560
a lot about this in my earliest videos. Well, the graph is going to look pretty weird because palm 2

10:26.560 --> 10:33.200
has improved upon palm while reducing the number of parameters. So the graph kind of doubles back

10:33.280 --> 10:39.520
on itself back up here up to around 69% according to the technical report. I would say this is

10:39.520 --> 10:45.440
quite a major moment in human history. There is now virtually no language task that the average

10:45.440 --> 10:51.840
human can do better than palm 2. Of course, expert humans can do better in individual domains, but

10:51.840 --> 10:57.840
the average human is now worse in virtually every domain of language. Here you can see that confirmation

10:57.920 --> 11:04.640
of the big bench hard results for flan palm 2, 69.1%. Interestingly, in the original chart,

11:04.640 --> 11:11.440
palm 2 is even claimed to have higher performance than that at 78.1%. If you remember, the reason we

11:11.440 --> 11:17.440
can't compare that to GPT-4 is that in the technical report for GPT-4, they admit that during their

11:17.440 --> 11:23.040
contamination check, we discovered that portions of big bench were inadvertently mixed into the

11:23.040 --> 11:28.560
training set and we excluded it from our reported results. Before we get to Gemini, Google show off

11:28.560 --> 11:34.160
in the latter half of the technical report with examples of linguistic ability, like writing

11:34.160 --> 11:40.080
paragraphs in Tejiki and then translating them into Persian. They go on to show examples in

11:40.080 --> 11:45.840
Tamil and they are really making a big point of showing off its multilingual capabilities. At

11:45.840 --> 11:51.200
this point, and I'm going to admit this is my personal opinion, Google then strays into dozens

11:51.200 --> 11:58.000
of pages on bias, toxicity and gender. Interestingly, some of the people paid to assess these risks

11:58.000 --> 12:03.120
were paid only 1.5 cents per judgment. These things do need to be addressed, of course,

12:03.120 --> 12:08.480
but it was somewhat shocking to me to see 20 pages of that and not a single page on the

12:08.480 --> 12:14.000
broader AI impacts. As many of you may know, I have criticized open AI plenty of times on this

12:14.000 --> 12:19.440
channel, but compare their technical report, which goes into far more detail about what we need to

12:19.440 --> 12:25.360
monitor. The closest Google got was showing how their universal translator could be used for deep fakes.

12:25.360 --> 12:31.600
Universal Translate is an experimental AI video dubbing service that helps experts

12:31.600 --> 12:37.120
translate a speaker's voice while also matching their lip movements. Let me show you how it works

12:37.120 --> 12:42.560
with an online college course created in partnership with Arizona State University.

12:42.560 --> 12:47.440
What many college students don't realize is that knowing when to ask for help and then following

12:47.440 --> 12:51.280
through and using helpful resources is actually a hallmark of becoming a productive adult.

13:01.040 --> 13:05.440
It just seems a massive black hole when one of their recent former employees,

13:05.440 --> 13:08.640
Jeffrey Hinton, had this to say this week on CNN.

13:08.640 --> 13:15.200
You've spoken out saying that AI could manipulate or possibly figure out a way to kill humans?

13:15.440 --> 13:16.640
How could it kill humans?

13:16.640 --> 13:20.320
If it gets to be much smarter than us, it'll be very good at manipulation because it will

13:20.320 --> 13:25.200
have learned that from us. And a very few examples of a more intelligent thing being

13:25.200 --> 13:29.760
controlled by a less intelligent thing. And it knows how to program, so it'll figure out ways of

13:29.760 --> 13:34.800
getting around restrictions we put on it. It'll figure out ways of manipulating people to do

13:34.800 --> 13:40.720
what it wants. It's not clear to me that we can solve this problem. I believe we should put a big

13:40.720 --> 13:44.720
effort into thinking about ways to solve the problem. I don't have a solution at present.

13:44.720 --> 13:49.280
I just want people to be aware that this is a really serious problem and we need to be thinking

13:49.280 --> 13:53.680
about it very hard. This all seems particularly relevant when Google made this announcement

13:53.680 --> 14:00.560
about Gemini, their rival to GPT-5. All this helps set the stage for the inflection point we are at

14:00.560 --> 14:06.640
today. We recently brought these two teams together into a single unit, Google DeepMind.

14:07.360 --> 14:13.040
Using the computational resources of Google, they are focused on building more capable systems

14:13.760 --> 14:20.560
safely and responsibly. This includes our next generation foundation model, Gemini,

14:20.560 --> 14:26.400
which is still in training. Gemini was created from the ground up to be multi-modal,

14:27.280 --> 14:33.600
highly efficient at tool and API integrations, and built to enable future innovations

14:33.600 --> 14:39.280
like memory and planning. That ability to plan may ring a bell from the GPT-4

14:40.080 --> 14:44.400
which said this, novel capabilities often emerge in more powerful models.

14:44.400 --> 14:50.160
Some that are particularly concerning are the ability to create and act on long-term plans.

14:50.160 --> 14:55.760
Remember, Google didn't identify planning as a risk but as a selling point for Gemini.

14:55.760 --> 15:00.880
Next, Google talked about accelerating their progress, which was again directly mentioned

15:00.880 --> 15:05.920
in the GPT-4 technical report. It said, one concern of particular importance to open AI

15:05.920 --> 15:10.080
is the risk of racing dynamics leading to a decline in safety standards,

15:10.080 --> 15:15.840
the diffusion of bad norms and accelerated AI timelines, each of which heightens societal

15:15.840 --> 15:21.920
risks associated with AI. We refer to these here as acceleration risk and make no mistake,

15:21.920 --> 15:28.880
Gemini will be very accelerated from Palm II. It looks set to use the TPU V5 chip,

15:28.880 --> 15:34.800
which was announced back in January of last year. And on page 91 of the Palm II technical report,

15:34.800 --> 15:40.960
they say that that model used TPU V4. Now, it should be said that Palm II is leading to some

15:40.960 --> 15:46.240
impressive medical applications. As I actually first reported on seven weeks ago without quite

15:46.240 --> 15:51.440
realizing it, here's MedPalm II. We believe large language models have the potential to revolutionize

15:51.440 --> 15:56.240
healthcare and benefit society. MedPalm is a large language model that we've taken and tuned for the

15:56.240 --> 16:02.960
medical domain. Medical question answering has been a research grand challenge for several decades

16:02.960 --> 16:07.280
but till date the progress has been kind of slow. But then over the course of the last

16:08.000 --> 16:13.280
three to four months, first with MedPalm and MedPalm II, we have kind of like broken through that

16:13.280 --> 16:19.200
barrier. Unlike previous versions, MedPalm II was able to score 85% on the USMLA medical licensing

16:19.200 --> 16:24.000
exam. Yeah, this is immensely exciting because people have been working on medical question

16:24.000 --> 16:28.800
answering for over three decades. And finally, we are at a stage where we can say with confidence

16:28.800 --> 16:34.400
that AI systems can now at least answer USMLA questions as good as experts. As many of you

16:34.400 --> 16:40.400
may know, the CEO of Google as well as the CEO of Microsoft and Sam Altman and the CEO of Anthropic

16:40.400 --> 16:45.840
all went to the White House to discuss AI risk and opportunity. But given that the main outcome

16:45.840 --> 16:52.000
from that seems to be 140 million to establish seven new AI research institutes, that feels a

16:52.000 --> 16:56.800
little slow given all the acceleration that's occurring. Because as Google somewhat soberly

16:56.800 --> 17:01.680
conclude their report, we believe that further scaling of both model parameters and data set

17:01.680 --> 17:06.720
size and quality as well as improvements in the architecture and objective will continue to yield

17:06.720 --> 17:12.800
gains in language understanding and generation. They are not slowing down and the world hasn't

17:12.800 --> 17:26.640
yet caught up. Thank you so much for watching to the end and have a wonderful day.

