1
00:00:00,000 --> 00:00:03,840
Do you remember this paper, less than two weeks old?

2
00:00:03,840 --> 00:00:07,200
It made waves by concluding that open source models

3
00:00:07,200 --> 00:00:11,920
can mimic the style, but not the factuality of chat GPT.

4
00:00:11,920 --> 00:00:14,240
Overall, we can conclude they say

5
00:00:14,240 --> 00:00:17,520
that model imitation is a false promise.

6
00:00:17,520 --> 00:00:23,840
Well, 48 hours ago, we have this, a 51 page report on Orca,

7
00:00:23,840 --> 00:00:27,200
based on a small 13 billion parameter model.

8
00:00:27,200 --> 00:00:29,520
I don't often comment on open source models

9
00:00:29,520 --> 00:00:32,800
because they're simply not competitive with open AI's models.

10
00:00:32,800 --> 00:00:36,640
But Orca is not just competitive with GPT 3.5.

11
00:00:36,640 --> 00:00:40,320
It beats it in quite a few well-established benchmarks

12
00:00:40,320 --> 00:00:44,320
and even matches GPT-4 in a couple of tests of reasoning.

13
00:00:44,320 --> 00:00:46,400
As always, I've read both papers in full

14
00:00:46,400 --> 00:00:48,800
and can also bring in just-released comments

15
00:00:48,800 --> 00:00:53,920
from Sam Altman and Ilya Sutskova on competition from open source models.

16
00:00:53,920 --> 00:00:59,040
But let's start with Orca, named presumably because Orca's or killer whales

17
00:00:59,040 --> 00:01:02,000
are frequent visitors to South American coastlines.

18
00:01:02,000 --> 00:01:05,680
And South America is, of course, the land of llamas and vicunas.

19
00:01:05,680 --> 00:01:08,720
But all the research was done by Microsoft,

20
00:01:08,720 --> 00:01:12,000
which I find interesting and I'll come back to that at the end.

21
00:01:12,000 --> 00:01:14,880
But why did they make Orca and why does it perform better

22
00:01:14,880 --> 00:01:17,440
than models like llama, alpaca, and vicuna?

23
00:01:17,440 --> 00:01:19,200
Well, they say here in the abstract

24
00:01:19,200 --> 00:01:22,400
that those other models lack rigorous evaluation,

25
00:01:22,400 --> 00:01:25,920
resulting in overestimating the small model's capability

26
00:01:25,920 --> 00:01:28,640
as they tend to learn to imitate the style

27
00:01:28,720 --> 00:01:32,560
but not the reasoning of LFMs, large foundation models.

28
00:01:32,560 --> 00:01:34,880
To address these challenges, we developed Orca,

29
00:01:34,880 --> 00:01:38,000
a 13 billion parameter model, that learns to imitate

30
00:01:38,000 --> 00:01:40,880
the reasoning process of the larger models.

31
00:01:40,880 --> 00:01:45,360
Orca learned by looking at GPT-4's step-by-step thought processes

32
00:01:45,360 --> 00:01:50,640
and is guided by teacher assistants from chat GPT, which is GPT 3.5.

33
00:01:50,640 --> 00:01:52,560
And to give you a taste of what's to come,

34
00:01:52,560 --> 00:01:55,760
Orca surpasses conventional state-of-the-art models,

35
00:01:55,760 --> 00:01:58,960
such as vicuna, by more than 100%

36
00:01:58,960 --> 00:02:02,400
in complex zero-shot reasoning benchmarks,

37
00:02:02,400 --> 00:02:04,960
like the big bench hard, which I'll talk about,

38
00:02:04,960 --> 00:02:08,400
and by 42% on AGI eval.

39
00:02:08,400 --> 00:02:12,480
It goes on, Orca reaches parity with chat GPT

40
00:02:12,480 --> 00:02:16,400
on the big bench hard and shows competitive performance

41
00:02:16,400 --> 00:02:18,800
in professional and academic examinations

42
00:02:18,800 --> 00:02:21,520
by the SAT, LSAT, GRE, and GMAT.

43
00:02:21,520 --> 00:02:24,320
And I know many of you will be interested in this footnote.

44
00:02:24,320 --> 00:02:28,160
We are working with our legal team to publicly release

45
00:02:28,160 --> 00:02:30,480
a diff of the model weights in accordance

46
00:02:30,480 --> 00:02:32,240
with Lama's release policy.

47
00:02:32,240 --> 00:02:34,000
So if this is anything like Lama,

48
00:02:34,000 --> 00:02:36,320
it's going to be leaked across the internet imminently.

49
00:02:36,320 --> 00:02:39,760
I'm going to show you so many tests and benchmarks in a moment,

50
00:02:39,760 --> 00:02:41,440
but just to give you a sample,

51
00:02:41,440 --> 00:02:46,560
here is Orca outperforming chat GPT in the vicuna evaluation set

52
00:02:46,560 --> 00:02:51,600
and matching text DaVinci 3 in the SAT, LSAT, GRE, and GMAT.

53
00:02:51,600 --> 00:02:52,960
And as I'll touch on later,

54
00:02:52,960 --> 00:02:55,840
this was zero shot without chain of thought

55
00:02:55,840 --> 00:02:57,440
or any advanced methods.

56
00:02:57,440 --> 00:02:59,520
You can watch pretty much any of my other videos

57
00:02:59,520 --> 00:03:01,760
to see how advanced prompt engineering

58
00:03:01,760 --> 00:03:04,400
would probably boost those results still further.

59
00:03:04,400 --> 00:03:05,520
For those who didn't know,

60
00:03:05,520 --> 00:03:10,480
13 billion parameters is about 7% the size of GPT-3,

61
00:03:10,480 --> 00:03:12,880
which is 175 billion parameters,

62
00:03:12,880 --> 00:03:17,680
and possibly around one or 2% of GPT-4's size.

63
00:03:17,680 --> 00:03:20,000
That gives you an indication of the difference

64
00:03:20,080 --> 00:03:23,360
in size between Orca and these models that it's competing with.

65
00:03:23,360 --> 00:03:24,880
And if that doesn't make any sense,

66
00:03:24,880 --> 00:03:28,800
a smaller size means it can be run on much smaller devices,

67
00:03:28,800 --> 00:03:31,680
like a desktop or even possibly a laptop.

68
00:03:31,680 --> 00:03:34,720
The authors start off by giving a little slap to the other paper.

69
00:03:34,720 --> 00:03:37,920
You know that one that said model imitation is a false promise.

70
00:03:37,920 --> 00:03:40,480
And they continue that contrary to this assertion,

71
00:03:40,480 --> 00:03:45,040
it is possible to reduce the gap with proprietary LLMs

72
00:03:45,040 --> 00:03:49,360
on multiple zero shot benchmarks that require sophisticated reasoning.

73
00:03:49,360 --> 00:03:54,160
As we'll see, models like Vakuna claim to have 90% of chat GPT's quality,

74
00:03:54,160 --> 00:03:57,600
but when it came to reasoning tasks or more technical tasks,

75
00:03:57,600 --> 00:03:58,720
it basically flopped.

76
00:03:58,720 --> 00:04:00,800
Here's a chart I'll come back to outlining

77
00:04:00,800 --> 00:04:04,240
some of the more technical challenges you can give a language model.

78
00:04:04,240 --> 00:04:07,440
We should remember that Vakuna is a fine-tuned version

79
00:04:07,440 --> 00:04:08,880
of the Llama model,

80
00:04:08,880 --> 00:04:12,320
and it's competitive or even better than Palm II.

81
00:04:12,320 --> 00:04:15,840
But give it some of the harder challenges for a language model,

82
00:04:15,840 --> 00:04:18,720
and it really struggles, as you can see in this column.

83
00:04:18,720 --> 00:04:22,240
Take logical deduction, where it only scored 1.2%.

84
00:04:22,240 --> 00:04:26,320
Well, this Orca model was 2,900% better than that,

85
00:04:26,320 --> 00:04:29,520
scoring 36% competitive with chat GPT.

86
00:04:29,520 --> 00:04:31,840
I'm going to come back to the big benchmark,

87
00:04:31,840 --> 00:04:34,320
but look for a second at causal judgment,

88
00:04:34,320 --> 00:04:39,440
where Orca, a 13 billion parameter model matches GPT4,

89
00:04:39,440 --> 00:04:42,160
which is about 100 times the size.

90
00:04:42,160 --> 00:04:44,080
But back to how they actually did it.

91
00:04:44,080 --> 00:04:48,640
Models like Alpaca and Vakuna were given lots of query and responses

92
00:04:48,640 --> 00:04:50,880
from chat GPT or GPT4.

93
00:04:50,880 --> 00:04:54,080
But what they did is they leveraged system instructions,

94
00:04:54,080 --> 00:04:58,000
asking models like GPT4 and chat GPT to think step by step.

95
00:04:58,000 --> 00:05:02,080
This gave Orca access to detailed responses from the model

96
00:05:02,080 --> 00:05:05,200
that explained the reasoning process of the teacher

97
00:05:05,200 --> 00:05:06,800
as it generates the response.

98
00:05:06,800 --> 00:05:10,720
It allowed these parent models of GPT3.5 and GPT4

99
00:05:10,720 --> 00:05:14,160
to be much better tutors for this young Orca.

100
00:05:14,240 --> 00:05:17,680
Also, they let the teachers of chat GPT, which is 3.5,

101
00:05:17,680 --> 00:05:21,040
and GPT4 give far more examples to their student.

102
00:05:21,040 --> 00:05:24,080
5 million and 1 million examples, respectively.

103
00:05:24,080 --> 00:05:26,240
That compares to the other models you may have heard of,

104
00:05:26,240 --> 00:05:28,800
like Alpaca, Wizard, Vakuna, etc.,

105
00:05:28,800 --> 00:05:33,040
which had tens of thousands or the low hundreds of thousands of examples.

106
00:05:33,040 --> 00:05:36,080
But again, the key difference is the explanations,

107
00:05:36,080 --> 00:05:40,000
the step by step thinking that the smaller Orca could then imitate.

108
00:05:40,000 --> 00:05:43,040
They give a quick demo here of how the other open source models

109
00:05:43,040 --> 00:05:44,960
learn from their GPT parents,

110
00:05:44,960 --> 00:05:48,320
with a simplistic question and answer format.

111
00:05:48,320 --> 00:05:51,520
In contrast, the authors leveraged system messages

112
00:05:51,520 --> 00:05:55,600
to get chat GPT and GPT4 to think step by step,

113
00:05:55,600 --> 00:06:00,080
leading to much richer explanations, as you can see in this diagram.

114
00:06:00,080 --> 00:06:02,000
It wasn't just let's think step by step,

115
00:06:02,000 --> 00:06:05,120
by the way, also things like explain like I'm 5.

116
00:06:05,120 --> 00:06:09,600
They also wanted the task to be as complex and diverse as possible,

117
00:06:09,600 --> 00:06:11,920
so they used the Flan collection.

118
00:06:11,920 --> 00:06:14,000
This was released by Google in February,

119
00:06:14,000 --> 00:06:17,600
and focused on balancing the kind of prompts and tasks

120
00:06:17,600 --> 00:06:19,920
that you fine tune the language models on.

121
00:06:19,920 --> 00:06:22,480
You can see here the 16 system messages

122
00:06:22,480 --> 00:06:25,360
that they give to chat GPT and GPT4,

123
00:06:25,360 --> 00:06:28,080
and you can see here the kind of difference that that makes.

124
00:06:28,080 --> 00:06:31,360
Imagine a language model trying to learn from this human.

125
00:06:31,360 --> 00:06:32,480
The human is asked,

126
00:06:32,480 --> 00:06:34,640
pick which sentence is not logical.

127
00:06:34,640 --> 00:06:37,760
Sentence A, people in the desert often look forward to flood,

128
00:06:37,760 --> 00:06:41,040
or sentence B, people in the desert often look forward to rain.

129
00:06:41,040 --> 00:06:42,240
The human responds,

130
00:06:42,240 --> 00:06:44,480
there is no reason to look forward to a flood,

131
00:06:44,480 --> 00:06:47,520
because floods cause damage, the answer is sentence A.

132
00:06:47,520 --> 00:06:50,080
Now yes, a language model can learn from that,

133
00:06:50,080 --> 00:06:53,200
but by leveraging those system assistant messages,

134
00:06:53,200 --> 00:06:55,680
look at the kind of response that GPT4 gives.

135
00:06:55,680 --> 00:06:59,120
Now Orca can learn a lot more from that explanation,

136
00:06:59,120 --> 00:07:01,680
and that's one of the main reasons it's better

137
00:07:01,680 --> 00:07:03,920
than all the other open source models.

138
00:07:03,920 --> 00:07:07,760
Because remember, Vikuna is the best of the open source models.

139
00:07:07,760 --> 00:07:10,880
In this leaderboard, it has an elo of 1054,

140
00:07:10,880 --> 00:07:13,120
better even than Palm II Bison.

141
00:07:13,120 --> 00:07:15,520
All the models higher than it are proprietary.

142
00:07:15,520 --> 00:07:18,960
But there is another reason why Orca performs so much better.

143
00:07:18,960 --> 00:07:19,840
You might have wondered,

144
00:07:19,840 --> 00:07:22,400
why didn't they just use only GPT4?

145
00:07:22,400 --> 00:07:25,200
Well yes, there were cost and time considerations,

146
00:07:25,200 --> 00:07:27,120
but there was another factor that they found.

147
00:07:27,120 --> 00:07:32,400
They were able to use chat GPT or GPT3.5 as an intermediate teacher.

148
00:07:32,400 --> 00:07:36,800
That teacher, chat GPT, was able to reduce the gap in capabilities.

149
00:07:36,800 --> 00:07:39,600
So Orca got smarter and better able to learn.

150
00:07:39,600 --> 00:07:41,200
A bit like progressive learning,

151
00:07:41,200 --> 00:07:43,680
where you first learn from easier examples,

152
00:07:43,680 --> 00:07:45,200
then followed by harder ones.

153
00:07:45,200 --> 00:07:48,240
After that, they gave it outputs from GPT4.

154
00:07:48,240 --> 00:07:49,040
Notice by the way,

155
00:07:49,040 --> 00:07:52,800
what happens if you skip the chat GPT teaching assistant

156
00:07:52,800 --> 00:07:57,040
and only train on those one million examples from GPT4.

157
00:07:57,040 --> 00:08:00,240
What happens is a bit like a student struggling in a class

158
00:08:00,240 --> 00:08:01,600
that's too advanced for them.

159
00:08:01,600 --> 00:08:06,320
Orca actually performs worse in those circumstances, averaging 37%,

160
00:08:06,320 --> 00:08:10,800
but with that intermediate teacher beforehand, it gets 41.7%.

161
00:08:10,800 --> 00:08:11,840
Speaking of time,

162
00:08:11,840 --> 00:08:17,840
it only took about 200 hours to train Orca on 20 A100 GPUs.

163
00:08:17,840 --> 00:08:22,400
They did take a few weeks to collect the data from chat GPT and GPT4,

164
00:08:22,400 --> 00:08:24,960
but presumably if they're planning to open source this,

165
00:08:24,960 --> 00:08:26,160
which they say they are,

166
00:08:26,160 --> 00:08:29,120
then that step could be skipped by the wider community.

167
00:08:29,120 --> 00:08:31,280
Let's now look at some more of the results.

168
00:08:31,280 --> 00:08:34,640
First, for open-ended generation, not multiple choice.

169
00:08:34,640 --> 00:08:38,560
Orca is 95% of chat GPT quality

170
00:08:38,560 --> 00:08:43,040
and 85% of GPT4's quality as assessed by GPT4,

171
00:08:43,040 --> 00:08:46,480
but they wanted to quickly move on to some more definitive tasks

172
00:08:46,480 --> 00:08:49,920
because there is a problem of using GPT4 as an assessor.

173
00:08:49,920 --> 00:08:50,640
For example,

174
00:08:50,640 --> 00:08:54,720
they observed that there is a positive bias in GPT4 evaluation

175
00:08:54,720 --> 00:08:58,880
toward the response of the first model in the comparison set.

176
00:08:58,880 --> 00:09:02,000
This reminded me of the unfaithful reasoning paper

177
00:09:02,000 --> 00:09:04,640
that I talked about in one of my recent videos.

178
00:09:04,640 --> 00:09:08,000
You can't always trust GPT4 to give its true reasoning,

179
00:09:08,000 --> 00:09:11,360
but here it is in more objective multiple choice questions.

180
00:09:11,360 --> 00:09:13,760
And notice how much harder many of these tests are

181
00:09:13,760 --> 00:09:16,000
for even these advanced language models.

182
00:09:16,000 --> 00:09:19,200
I am fortunate and proud to have attained a perfect score

183
00:09:19,200 --> 00:09:20,880
in some of the tests in this chart,

184
00:09:20,880 --> 00:09:22,400
like the GRE and GMAT.

185
00:09:22,400 --> 00:09:25,760
They were part of the Aquarat tests that they gave the models,

186
00:09:25,760 --> 00:09:28,160
so I can say that they really are quite challenging,

187
00:09:28,160 --> 00:09:30,800
hence why GPT4 only gets a 40%.

188
00:09:30,880 --> 00:09:32,240
You can see that throughout,

189
00:09:32,240 --> 00:09:35,440
Orca outperforms Vecuna by quite a margin

190
00:09:35,440 --> 00:09:38,640
and is very competitive with Textavinci 3.

191
00:09:38,640 --> 00:09:41,360
Of course, overall, it does lag behind GPT4,

192
00:09:41,360 --> 00:09:43,200
but this is all zero shot.

193
00:09:43,200 --> 00:09:43,920
A bit later on,

194
00:09:43,920 --> 00:09:46,800
I'll come back to the range of methods that we could use

195
00:09:46,800 --> 00:09:48,880
to further improve on Orca.

196
00:09:48,880 --> 00:09:50,560
The percentages, by the way,

197
00:09:50,560 --> 00:09:52,480
are the improvements on Vecuna,

198
00:09:52,480 --> 00:09:55,040
again the second best open source model.

199
00:09:55,040 --> 00:09:57,840
So far, we've looked at human centric benchmarks

200
00:09:57,840 --> 00:09:59,680
like the GMAT and GRE.

201
00:09:59,680 --> 00:10:02,800
These are grouped with the lovely name AGI EVAL,

202
00:10:02,800 --> 00:10:03,600
and as we've seen,

203
00:10:03,600 --> 00:10:07,280
even the top models lag behind the top human performers.

204
00:10:07,280 --> 00:10:10,880
But what about a benchmark specifically for language models?

205
00:10:10,880 --> 00:10:12,720
It's called Big Bench Hard.

206
00:10:12,720 --> 00:10:15,680
The original Big Bench had 207 tasks,

207
00:10:15,680 --> 00:10:17,520
but language models got so good

208
00:10:17,520 --> 00:10:19,760
that they had to narrow down the benchmark

209
00:10:19,760 --> 00:10:22,480
to just the 23 challenging tasks

210
00:10:22,480 --> 00:10:25,440
where human raters still did better than language models.

211
00:10:25,440 --> 00:10:27,600
Now, it turns out when you add Chain of Thought prompting

212
00:10:27,600 --> 00:10:29,280
to the models, they do even better

213
00:10:29,280 --> 00:10:31,920
and there are even fewer tasks that humans are better at.

214
00:10:31,920 --> 00:10:33,440
But anyway, all you have to remember

215
00:10:33,440 --> 00:10:37,760
is that these are 23 of the hardest tasks for language models.

216
00:10:37,760 --> 00:10:40,320
And I'll just let you compare the results for yourself.

217
00:10:40,320 --> 00:10:42,880
But the trend is really quite clear.

218
00:10:42,880 --> 00:10:45,440
Orca massively outperforming

219
00:10:45,440 --> 00:10:48,240
the previous best open source model, Vecuna,

220
00:10:48,240 --> 00:10:50,720
beating even chat GPT on average,

221
00:10:50,720 --> 00:10:53,360
but still, of course, lagging behind GPT4,

222
00:10:53,360 --> 00:10:55,360
except for a few tasks.

223
00:10:55,360 --> 00:10:56,720
Look at Web of Lies,

224
00:10:56,720 --> 00:10:58,960
where Orca outperforms GPT4.

225
00:10:58,960 --> 00:11:00,800
That would be a question like this.

226
00:11:00,800 --> 00:11:03,200
Alexis says Shonda tells the truth.

227
00:11:03,200 --> 00:11:04,080
Jim Lies?

228
00:11:04,080 --> 00:11:06,640
Antoine says Jim tells the truth.

229
00:11:06,640 --> 00:11:08,800
Shonda says Antoine Lies.

230
00:11:08,800 --> 00:11:10,480
Does Alexis tell the truth?

231
00:11:10,480 --> 00:11:12,800
Or what about temporal sequences,

232
00:11:12,800 --> 00:11:15,680
where Orca absolutely crushes Vecuna

233
00:11:15,680 --> 00:11:18,320
and doubles chat GPT's performance?

234
00:11:18,320 --> 00:11:20,160
That would be a situation like this.

235
00:11:20,160 --> 00:11:21,520
Now, I'm not going to read it all out,

236
00:11:21,520 --> 00:11:23,280
but essentially you have to figure out

237
00:11:23,280 --> 00:11:24,720
when the timings match up.

238
00:11:24,720 --> 00:11:26,480
Basically keeping track of time

239
00:11:26,480 --> 00:11:28,320
and Orca does really well

240
00:11:28,400 --> 00:11:30,720
and chat GPT flops getting it wrong.

241
00:11:30,720 --> 00:11:33,520
Interestingly, they also tested all four models

242
00:11:33,520 --> 00:11:35,600
on that common sense reasoning question

243
00:11:35,600 --> 00:11:37,920
that I demonstrated for smart GPT,

244
00:11:37,920 --> 00:11:39,760
about hanging the clothes to dry.

245
00:11:39,760 --> 00:11:40,640
As you might remember,

246
00:11:40,640 --> 00:11:42,160
you can use prompt engineering

247
00:11:42,160 --> 00:11:44,720
to nudge the models to almost always get it right,

248
00:11:44,720 --> 00:11:47,040
which is partly why I view these results

249
00:11:47,040 --> 00:11:49,440
more as a baseline rather than a cap.

250
00:11:49,440 --> 00:11:51,040
And the authors admit this too.

251
00:11:51,040 --> 00:11:53,040
Orca has been trained on data

252
00:11:53,040 --> 00:11:55,280
that simulates zero shot setting

253
00:11:55,280 --> 00:11:56,480
with standard prompts.

254
00:11:56,480 --> 00:11:58,640
The model's performance in other contexts,

255
00:11:58,640 --> 00:12:00,720
such as multi-turn conversations,

256
00:12:00,720 --> 00:12:02,880
like the DERA paper I talked about on the channel,

257
00:12:02,880 --> 00:12:05,520
in context learning and few shot learning,

258
00:12:05,520 --> 00:12:07,600
or advanced prompting techniques,

259
00:12:07,600 --> 00:12:10,400
that smart GPT or Tree of Thoughts, for example,

260
00:12:10,400 --> 00:12:12,880
and they say like chain of thought prompting,

261
00:12:12,880 --> 00:12:14,320
remains untested.

262
00:12:14,320 --> 00:12:16,880
These results are a baseline, not a cap.

263
00:12:16,880 --> 00:12:19,680
They mention other ways that Orca could be improved,

264
00:12:19,680 --> 00:12:22,400
for example, through tool augmentation.

265
00:12:22,400 --> 00:12:24,000
And that's not just calculators,

266
00:12:24,080 --> 00:12:26,880
calendars, Bing, or auto GPT.

267
00:12:26,880 --> 00:12:29,040
I was going to do a separate video on this paper,

268
00:12:29,040 --> 00:12:30,400
but I'll just mention it here.

269
00:12:30,400 --> 00:12:32,400
This paper from last week demonstrated

270
00:12:32,400 --> 00:12:34,960
that larger models can create tools

271
00:12:34,960 --> 00:12:37,680
that smaller models can then use more efficiently.

272
00:12:37,680 --> 00:12:40,400
Once the best language model, say GPT-4,

273
00:12:40,400 --> 00:12:42,880
has created a generic Python function,

274
00:12:42,880 --> 00:12:43,840
which is the tool,

275
00:12:43,840 --> 00:12:45,760
and then written some unit tests,

276
00:12:45,760 --> 00:12:48,240
it can then wrap and hand over those tools

277
00:12:48,240 --> 00:12:50,800
to smaller models like GPT-3.5,

278
00:12:50,800 --> 00:12:52,080
or in this case, Orca,

279
00:12:52,080 --> 00:12:54,160
and check out the toolmaking row

280
00:12:54,160 --> 00:12:56,720
to see the improvement for chat GPT,

281
00:12:56,720 --> 00:12:58,160
or in our case, Orca,

282
00:12:58,160 --> 00:13:01,280
when they're given these tools created by GPT-4

283
00:13:01,280 --> 00:13:02,720
or better language models.

284
00:13:02,720 --> 00:13:05,200
Their performance across a range of tasks

285
00:13:05,200 --> 00:13:06,640
goes dramatically up,

286
00:13:06,640 --> 00:13:08,000
and we haven't even talked about

287
00:13:08,000 --> 00:13:10,400
using a process-based reward model,

288
00:13:10,400 --> 00:13:13,200
like in the Let's Verify step-by-step paper.

289
00:13:13,200 --> 00:13:16,480
That, of course, could further improve Orca's performance.

290
00:13:16,480 --> 00:13:18,960
Of course, when this model becomes publicly available,

291
00:13:18,960 --> 00:13:20,720
I will test all of this out,

292
00:13:20,720 --> 00:13:22,800
but it hasn't been open-sourced yet,

293
00:13:22,800 --> 00:13:24,560
and they do say this model

294
00:13:24,560 --> 00:13:27,360
is solely designed for research settings.

295
00:13:27,360 --> 00:13:29,680
That does seem a little bit naive to me.

296
00:13:29,680 --> 00:13:31,040
I mean, that's what Metta said

297
00:13:31,040 --> 00:13:32,160
when they released Lama,

298
00:13:32,160 --> 00:13:34,080
but then everyone and their grandma

299
00:13:34,080 --> 00:13:36,080
just use the language model for whatever.

300
00:13:36,080 --> 00:13:37,680
I do wonder what it means when they say

301
00:13:37,680 --> 00:13:39,760
we are working with our legal team.

302
00:13:39,760 --> 00:13:41,920
And it is particularly interesting to me

303
00:13:41,920 --> 00:13:44,400
that this was all done by Microsoft.

304
00:13:44,400 --> 00:13:46,480
I'm gonna go into a little bit of speculation here

305
00:13:46,480 --> 00:13:49,200
about why I think they conducted this research.

306
00:13:49,200 --> 00:13:51,600
You might remember that leaked memo from Google.

307
00:13:51,600 --> 00:13:54,480
We have no motes, and they even mentioned Vakuna,

308
00:13:54,480 --> 00:13:57,280
and talked about how it circumvented restrictions

309
00:13:57,280 --> 00:14:00,800
on the OpenAI API by using shared GPT.

310
00:14:00,800 --> 00:14:03,360
And my theory is that the Microsoft researchers

311
00:14:03,360 --> 00:14:05,520
were testing this point from the memo.

312
00:14:05,520 --> 00:14:08,320
The point was that training giant models from scratch

313
00:14:08,320 --> 00:14:10,320
not only throws away the pre-training,

314
00:14:10,320 --> 00:14:12,960
but also any iterative open-source improvements

315
00:14:12,960 --> 00:14:14,160
that have been made on top.

316
00:14:14,160 --> 00:14:16,560
It doesn't take long for those improvements to dominate,

317
00:14:16,640 --> 00:14:19,360
making the full retrain extremely costly.

318
00:14:19,360 --> 00:14:22,480
Maybe Microsoft is hesitating about future investments

319
00:14:22,480 --> 00:14:24,880
in GPT-5 or GPT-6.

320
00:14:24,880 --> 00:14:26,480
And they really wanna test out

321
00:14:26,480 --> 00:14:29,840
if it's easy to imitate those large models on the cheap.

322
00:14:29,840 --> 00:14:32,640
If it is, then why would Microsoft invest billions

323
00:14:32,640 --> 00:14:34,320
in a new giant model?

324
00:14:34,320 --> 00:14:37,280
That's my own theory as to why Microsoft is working on this,

325
00:14:37,280 --> 00:14:39,520
but let me know in the comments what your theory is.

326
00:14:39,520 --> 00:14:41,520
In the conclusion, the authors state that

327
00:14:41,520 --> 00:14:45,120
Orca suggests that learning from step-by-step explanations

328
00:14:45,120 --> 00:14:47,760
could significantly improve the quality of models

329
00:14:47,760 --> 00:14:49,360
regardless of their size,

330
00:14:49,360 --> 00:14:52,160
and that they hope these insights will inform the design

331
00:14:52,160 --> 00:14:54,720
of more robust evaluation methods,

332
00:14:54,720 --> 00:14:56,960
compared to those used for a vacuna, for example,

333
00:14:56,960 --> 00:15:00,400
and the advancement of alignment and post-training techniques,

334
00:15:00,400 --> 00:15:03,760
and the more effective use of powerful models

335
00:15:03,760 --> 00:15:05,840
like GPT-4 as teachers.

336
00:15:05,840 --> 00:15:06,880
And maybe they should have said,

337
00:15:06,880 --> 00:15:10,240
and also with chat GPT as an intermediate teacher.

338
00:15:10,240 --> 00:15:13,200
I'm gonna end with the thoughts of the leaders of OpenAI,

339
00:15:13,280 --> 00:15:16,400
Ilya Sutskova, and Sam Oltman on open source models.

340
00:15:16,400 --> 00:15:18,240
And I think there is a bit of a contrast

341
00:15:18,240 --> 00:15:19,520
between the two answers.

342
00:15:19,520 --> 00:15:22,640
Ilya Sutskova thinks that the gap is growing ever wider.

343
00:15:23,200 --> 00:15:26,720
To the open source versus non-open source models question,

344
00:15:27,680 --> 00:15:31,120
you don't wanna think about it in binary black and white terms

345
00:15:31,120 --> 00:15:34,560
where like, there is a secret source

346
00:15:34,560 --> 00:15:36,960
that will never be rediscovered.

347
00:15:37,840 --> 00:15:41,520
What I will say, or whether GPT-4 will ever be reproduced

348
00:15:41,600 --> 00:15:45,040
by open source models, perhaps one day it will be.

349
00:15:45,760 --> 00:15:47,040
But when it will be,

350
00:15:47,040 --> 00:15:49,600
there will be a much more powerful model in the companies.

351
00:15:50,640 --> 00:15:52,240
So there will always be a gap

352
00:15:52,240 --> 00:15:56,480
between the open source models and the private models.

353
00:15:57,440 --> 00:16:01,040
And this gap may even be increasing this time.

354
00:16:01,920 --> 00:16:05,920
The amount of effort and engineering and research

355
00:16:05,920 --> 00:16:09,840
that it takes to produce one such neural net keeps increasing.

356
00:16:09,920 --> 00:16:13,040
And so even if there are open source models,

357
00:16:13,040 --> 00:16:14,080
they will never be,

358
00:16:14,080 --> 00:16:17,280
they will be less and less produced by small groups

359
00:16:17,280 --> 00:16:21,040
of dedicated researchers and engineers.

360
00:16:21,040 --> 00:16:25,200
And it will only be the providence of a company, a big company.

361
00:16:25,760 --> 00:16:27,200
While Sam Oltman seems to say

362
00:16:27,200 --> 00:16:29,840
that even if open source models do catch up,

363
00:16:29,840 --> 00:16:32,720
OpenAI will always have a different kind of moat.

364
00:16:32,720 --> 00:16:34,320
What are your thoughts about the,

365
00:16:34,320 --> 00:16:38,320
we have no moat document that was released lately?

366
00:16:40,480 --> 00:16:41,360
The leak document.

367
00:16:44,240 --> 00:16:46,720
The thing that is special about OpenAI,

368
00:16:46,720 --> 00:16:49,920
and I think the thing that is so misunderstood by that document,

369
00:16:49,920 --> 00:16:53,200
aside from the fact that we have a gigantic number of users

370
00:16:53,200 --> 00:16:55,840
and people that have formed some sort of relationship

371
00:16:55,840 --> 00:16:56,800
with us and our products,

372
00:16:57,520 --> 00:17:00,400
is what OpenAI is special about

373
00:17:00,960 --> 00:17:02,880
is figuring out what comes next.

374
00:17:03,520 --> 00:17:04,560
It is the ability,

375
00:17:04,560 --> 00:17:07,280
it is easy to copy something once you know it can be done.

376
00:17:07,280 --> 00:17:08,720
And in that sense, sure.

377
00:17:09,680 --> 00:17:12,080
It is very hard to go figure out what to do next.

378
00:17:12,720 --> 00:17:14,720
And the ideas, the big ideas,

379
00:17:14,720 --> 00:17:16,960
the medium size ideas, the small ideas,

380
00:17:16,960 --> 00:17:18,960
and the careful execution on them

381
00:17:18,960 --> 00:17:21,520
that it takes to get from here to superintelligence,

382
00:17:21,520 --> 00:17:22,720
that's what our moat is.

383
00:17:22,720 --> 00:17:25,520
Anyway, this video could have been at least three times longer.

384
00:17:25,520 --> 00:17:28,400
There was so much I had to edit out for brevity.

385
00:17:28,400 --> 00:17:31,360
If you're interested in me talking more about open source models,

386
00:17:31,360 --> 00:17:32,960
do let me know in the comments.

387
00:17:32,960 --> 00:17:34,560
I've got much more to say.

388
00:17:34,560 --> 00:17:37,040
As always, thank you so much for watching to the end

389
00:17:37,040 --> 00:17:39,040
and have a wonderful day.

