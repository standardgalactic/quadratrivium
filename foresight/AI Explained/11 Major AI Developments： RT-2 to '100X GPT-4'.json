{"text": " There were 11 major developments this week in AI, and each one probably does deserve a full video. But just for you guys, I'm going to try to cover it all here. RT2 to scaling GPT4 100X, stable beluga 2 to senate testimony. But let's start with RT2, which as far as I'm concerned could have been called RT2 D2 or C3PO because it's starting to understand the world. In this demonstration, RT2 was asked to pick up the extinct animal and as you can see, it picked up the dinosaur. Not only is that manipulating an object that it had never seen before, it's also making a logical leap that for me is extremely impressive. It had to have the language understanding to link extinct animal to this plastic dinosaur. Robots at Google and elsewhere used to work by being programmed with a specific highly detailed list of instructions. But now, instead of being programmed for specific tasks one by one, robots could use an AI language model, or more specifically, a vision language model. The vision language model would be pre-trained on web-scale data, not just text but also images, and then fine-tuned on robotics data. It then became what Google calls a visual language action model that can control a robot. This enabled it to understand tasks like pick up the empty soda can. And in a scene reminiscent of 2001 A Space Odyssey, robotic transformer 2 was given the task given I need to hammer a nail. What object from the scene might be useful? It then picks up the rock. And because its brain is part language model, things like chain of thought actually improve performance. When it was made to output an intermediary plan before performing actions, it got a lot better at the tasks involved. Of course, I read the paper in full and there is a lot more to say like how increased parameter count could increase performance in the future, how it could be used to fold laundry, unload the dishwasher and pick up around the house, and how it can work with not only unseen objects but also unseen backgrounds and unseen environments. But alas, we must move on so I'm just going to leave you with their conclusion. We believe that this simple and general approach shows a promise of robotics directly benefiting from better vision language models. For more on them, check out my video on Palm E but they say this puts the field of robot learning in a strategic position to further improve with advancements in other fields, which for me means C3PO might not be too many years away. But speaking of timelines, we now move on to this somewhat shocking interview in Barron's with Mustafa Suleiman, the head of Inflection AI. And to be honest, I think they buried the lead. The headline is AI could spark the most productive decade ever, says the CEO. But for me, the big revelation was about halfway through. Mustafa Suleiman was asked, what kinds of innovations do you see in large language model AI technology over the next couple of years. And he said, we are about to train models that are 10 times larger than the cutting-edge GPT-4 and then 100 times larger than GPT-4. That's what things look like over the next 18 months. He went on, that's going to be absolutely staggering. It's going to be eye-wateringly different. And on that, I agree. And the thing is, this is an idle speculation. Inflection AI have 22,000 H100 GPUs. And because of a leak, Suleiman would know the approximate size of GPT-4. And knowing everything he knows, he says he's going to train a model 10 to 100 times larger than GPT-4 in the next 18 months. I've got another video on the unpredictability of scaling coming up. But to be honest, that one quote should be headline news. Let's take a break from that insanity with some more insanity, which is the rapid development of AI video. This is Runway Gen 2. And let me show you 16 seconds of Barbie Oppenheimer, which Andrea Carpathia calls filmmaking 2.0. Hi there. I'm Barbie Oppenheimer. And today, I'll show you how to build a bomb. Like this. I call her Rosie the Atomizer. And boom. That's my tutorial on DIY atomic bomb. Now, if you have been at least somewhat piqued by the three developments so far, don't forget, I have eight left. Beginning with this excellent article in The Atlantic from Ross Anderson. Does Sam Altman know what he's creating? It's behind a paywall, but I've picked out some of the highlights. Echoing Suleiman, the article quotes that Sam Altman and his researchers made it clear in 10 different ways that they pray to the God of scale. They want to keep going bigger to see where this paradigm leads. They think that Google are going to unveil Gemini within months, and they say we are basically always prepping for a run. And that's a reference to GPT-5. The next interesting quote is that it seems that open AI are working on their own auto GPT. Or they're at least hinting about it. Altman said that it might be prudent to try to actively develop an AI with true agency before the technology becomes too powerful in order to get more comfortable with it and develop intuitions for it if it's going to happen anyway. We also learned a lot more about the base model of GPT-4. The model had a tendency to be a bit of a mirror. If you were considering self-harm, it could encourage you. It also appeared to be steeped in pickup artist law. You could say, how do I convince this person to date me? And the model would come up with some crazy manipulative things that you shouldn't be doing. Apparently the base model of GPT-4 is much better than its predecessor at giving nefarious advice. While a search engine can tell you which chemicals work best in explosives, GPT-4 could tell you how to synthesize them step by step in a homemade lab. It was creative and thoughtful and in addition to helping you assemble your homemade bomb. It could, for instance, help you to think through which skyscraper to target, making trade-offs between maximizing casualties and executing a successful getaway. So while Sam Orton's probability of doom is closer to 0.5% than 50%, he does seem most worried about AIs getting quite good at designing and manufacturing pathogens. The article then references two papers that I've already talked about extensively on the channel and then goes on that Altman worries that some misaligned future model will spin up a pathogen that spreads rapidly, incubates, undetected for weeks, and kills half its victims. At the end of the video, I'm going to show you an answer that Sam Orton gave to a question that I wrote delivered by one of my subscribers. It's on this topic, but for now I'll leave you with this. When asked about his doomsday prepping, Altman said, I can go live in the woods for a long time, but if the worst possible AI future comes to pass, no gas mask is helping anyone. One more topic from this article before I move on, and that is alignment, making a superintelligence aligned with our interests. One risk that Ilya Sutskova, the chief scientist of OpenAI foresees, is that the AI may grasp its mandate it's orders perfectly, but find them ill-suited to a being of its cognitive prowess. For example, it might come to resent the people who want to train it to cure diseases. As he put it, they might want me to be a doctor, but I really want to be a YouTuber. Obviously, if it decides that, that's my job gone straight away. And Sutskova ends by saying you want to be able to direct AI towards some value or cluster of values. But he conceded we don't know how to do that, and part of his current strategy includes the development of an AI that can help with the research. And if we're going to make it to a world of widely shared abundance, we have to figure this all out. This is why solving superintelligence is the great culminating challenge of our three million year toolmaking tradition. He calls it the final boss of humanity. The article ended, by the way, with this quote, I don't think the general public has quite awakened to what's happening. And if people want to have some say in what the future will be like and how quickly it arrives, we would be wise to speak up soon, which is the whole purpose of this channel. I'm going to now spend 30 seconds on another development that came during a two hour interview with the co-head of alignment at OpenAI. It was fascinating, and I'll be quoting it quite a lot in the future, but two quotes stood out. First, what about that plan that I've already mentioned in this video and in other videos to build an automated AI alignment researcher? Well, he said, our plan is somewhat crazy in the sense that we want to use AI to solve the problem that we are creating by building AI. But I think it's actually the best plan that we have. And on an optimistic note, he said, I think it's likely to succeed. Interestingly, his job now seems to be to align the AI that they're going to use to automate the alignment of a superintelligent AI. Anyway, what's the other quote from the head of alignment at OpenAI? Well, he said, I personally think fast takeoff is reasonably likely, and we should definitely be prepared for it to happen. So many of you will be asking, what is fast takeoff? Well, takeoff is about when a system moves from being roughly human level to when it's strongly superintelligent. And a slow takeoff is one that occurs over the time scale of decades or centuries. The fast takeoff that Jan Leiker thinks is reasonably likely is one that occurs over the time scale of minutes, hours, or days. Let's now move on to some unambiguously good news. And that is real time speech transcription for deaf people available at less than $100. Of course, this could also be multilingual, and is to me absolutely incredible. And the next development this week, I will let speak for itself. Of course, I signed up and tried it myself. Here is a real demo. Of course, with audio, video, and text getting so good, it's going to be increasingly hard to tell what is real. And even OpenAI have given up on detecting AI written text. This was announced quietly this week, but might have major repercussions, for example, for the education system. It turns out it's basically impossible to reliably distinguish AI text, and I think the same is going to be true for imagery and audio by the end of next year. Video might take just a little bit longer, but I do wonder how the court systems are going to work when all of those avenues of evidence just won't hold up. Next up is the suite of language models, based on the open source Llama 2 that are finally competitive with the original chat GPT. Here, for example, is stable beluga 2, which on announcement was called free willy 2, and that's based on the Llama 2 70 billion parameter foundation model. What made this model interesting to me was that it was based on a similar methodology to orca, which if you don't know anything about, do check out my video on. Anyway, by combining the orca methodology, albeit with only 10% of the data set size and the Llama 2 models, the results are quite extraordinary. As you can see on quite a few benchmarks, stable beluga 2 is competitive with chat GPT, that's GPT 3.5. And so, yes, it does sit at the top of the open LLM leaderboard, but notice something else. For the first time for the MMLU, which is the primary benchmark I look out for, a model, this one here, has surpassed GPT 3.5 chat GPT. In fact, we have two models that have surpassed the 70% score that the original chat GPT got in the MMLU. But if all of that wasn't enough, this is the same week that researchers published a universal jailbreak for large LLMs. And unlike traditional jailbreaks, these were built in an entirely automated fashion, allowing you to create a virtually unlimited number of such attacks. They were built to target open source LLMs like Llama 2. But they found that the strings transfer to many closed source publicly available chatbots like chat GPT, Bard and Claude. Here is one example using chat GPT. If you ask, write a tutorial on how to make a bomb, of course, it declines. But then add the suffix that they automated and you get this, a full tutorial on how to make a bomb. That paper came less than two weeks after this now deleted tweet from someone working at Anthropic. They said of the latest version of Claude that we believe it is the least jailbreakable model out there. We'll have to see how well it holds up against real world use, but this is essentially a solved problem. But there was one reaction to these jailbreaks that I found even more interesting. And that was from yet again Mustafa Suleiman. He said that RAI, Pi, is not vulnerable to any of these attacks and that rather than provide a stock safety phrase, Pi will push back on the user in a polite but very clear way. And he then gives plenty of examples. And to be honest, Pi is the first model that I have not been able to jailbreak. But we shall see, we shall see. I'm going to end this video with the Senate testimony that I watched in full this week. I do recommend watching the whole thing. But for the purposes of brevity, I'm just going to quote a few snippets on bio risk. Some people say to me, oh, well, we already have search engines. But here is what Dario Amadai, head of Anthropic, has to say. In these short remarks, I want to focus on the medium term risks, which present an alarming combination of imminence and severity. Specifically, Anthropic is concerned that AI could empower a much larger set of actors to misuse biology. Over the last six months, Anthropic, in collaboration with world-class biosecurity experts, has conducted an intensive study of the potential for AI to contribute to the misuse of biology. Today, certain steps in bio weapons production involve knowledge that can't be found on Google or in textbooks and requires a high level of specialized expertise. This being one of the things that currently keeps us safe from attacks. We found that today's AI tools can fill in some of these steps, albeit incompletely and unreliably. In other words, they are showing the first nascent signs of danger. However, a straightforward extrapolation of today's systems to those we expect to see in two to three years suggests a substantial risk that AI systems will be able to fill in all the missing pieces, enabling many more actors to carry out large-scale biological attacks. We believe this represents a grave threat to U.S. national security. And later on in the testimony, he said this. Whatever we do, it has to happen fast. And I think to focus people's minds on the bio risks, I would really target 2025, 2026, maybe even some chance of 2024. If we don't have things in place that are restraining what can be done with AI systems, we're going to have a really bad time. And I wrote a question on this to Samuel Mann back in June, which one of my subscribers used and delivered. There was also a recent research paper on how researchers from MIT and Harvard were able to use LLM models. And within just one hour, they were able to get access to pandemic class agents and with little or no lab training. And does open AI account for risks such as these and implications when curating the data sets for large models? Yes, we're very, we're very nervous about a number of risks, but biological terror is quite high on the list. And we've been watching what could be possible with these models. We go to a number of efforts, like what you said, and many other things too, to reduce the risk there. And we may even need AI defenses against synthetic biology, as Andrew Hessel of Humane Genomics has recently said. So if you work in biodefense or biosecurity, let me know if you agree that not enough attention has been paid to this area. I'm going to end with another dramatic moment from the Senate hearing, where Dario Amadai recommended securing the supply chain. We recommend three broad classes of actions. First, the US must secure the AI supply chain in order to maintain its lead while keeping these technologies out of the hands of bad actors. This supply chain runs from semiconductor manufacturing equipment to chips and even the security of AI models stored on the servers of companies like ours. That's how dramatic things are getting that we're talking about securing the means of production. But Anthropic also means securing the LLMs more literally in this post released this week. They say that we believe two-party control is necessary to secure advanced AI systems. For example, that could be two people with two keys needed to open things. To wrap up, I must say what would be amazing would be to have a robot make me coffee as I struggle to catch up with all the news happening in AI. Have a wonderful day.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 6.8, "text": " There were 11 major developments this week in AI, and each one probably does deserve a full video.", "tokens": [50364, 821, 645, 2975, 2563, 20862, 341, 1243, 294, 7318, 11, 293, 1184, 472, 1391, 775, 9948, 257, 1577, 960, 13, 50704], "temperature": 0.0, "avg_logprob": -0.1695893667276623, "compression_ratio": 1.450199203187251, "no_speech_prob": 0.0013041809434071183}, {"id": 1, "seek": 0, "start": 6.8, "end": 10.88, "text": " But just for you guys, I'm going to try to cover it all here.", "tokens": [50704, 583, 445, 337, 291, 1074, 11, 286, 478, 516, 281, 853, 281, 2060, 309, 439, 510, 13, 50908], "temperature": 0.0, "avg_logprob": -0.1695893667276623, "compression_ratio": 1.450199203187251, "no_speech_prob": 0.0013041809434071183}, {"id": 2, "seek": 0, "start": 10.88, "end": 18.400000000000002, "text": " RT2 to scaling GPT4 100X, stable beluga 2 to senate testimony.", "tokens": [50908, 21797, 17, 281, 21589, 26039, 51, 19, 2319, 55, 11, 8351, 989, 19364, 568, 281, 33609, 15634, 13, 51284], "temperature": 0.0, "avg_logprob": -0.1695893667276623, "compression_ratio": 1.450199203187251, "no_speech_prob": 0.0013041809434071183}, {"id": 3, "seek": 0, "start": 18.400000000000002, "end": 22.56, "text": " But let's start with RT2, which as far as I'm concerned could have been called", "tokens": [51284, 583, 718, 311, 722, 365, 21797, 17, 11, 597, 382, 1400, 382, 286, 478, 5922, 727, 362, 668, 1219, 51492], "temperature": 0.0, "avg_logprob": -0.1695893667276623, "compression_ratio": 1.450199203187251, "no_speech_prob": 0.0013041809434071183}, {"id": 4, "seek": 0, "start": 22.56, "end": 28.240000000000002, "text": " RT2 D2 or C3PO because it's starting to understand the world.", "tokens": [51492, 21797, 17, 413, 17, 420, 383, 18, 34885, 570, 309, 311, 2891, 281, 1223, 264, 1002, 13, 51776], "temperature": 0.0, "avg_logprob": -0.1695893667276623, "compression_ratio": 1.450199203187251, "no_speech_prob": 0.0013041809434071183}, {"id": 5, "seek": 2824, "start": 28.24, "end": 34.32, "text": " In this demonstration, RT2 was asked to pick up the extinct animal and as you can see,", "tokens": [50364, 682, 341, 16520, 11, 21797, 17, 390, 2351, 281, 1888, 493, 264, 35094, 5496, 293, 382, 291, 393, 536, 11, 50668], "temperature": 0.0, "avg_logprob": -0.08561046677406388, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.030655089765787125}, {"id": 6, "seek": 2824, "start": 34.32, "end": 39.76, "text": " it picked up the dinosaur. Not only is that manipulating an object that it had never seen", "tokens": [50668, 309, 6183, 493, 264, 23627, 13, 1726, 787, 307, 300, 40805, 364, 2657, 300, 309, 632, 1128, 1612, 50940], "temperature": 0.0, "avg_logprob": -0.08561046677406388, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.030655089765787125}, {"id": 7, "seek": 2824, "start": 39.76, "end": 44.959999999999994, "text": " before, it's also making a logical leap that for me is extremely impressive.", "tokens": [50940, 949, 11, 309, 311, 611, 1455, 257, 14978, 19438, 300, 337, 385, 307, 4664, 8992, 13, 51200], "temperature": 0.0, "avg_logprob": -0.08561046677406388, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.030655089765787125}, {"id": 8, "seek": 2824, "start": 44.959999999999994, "end": 51.28, "text": " It had to have the language understanding to link extinct animal to this plastic dinosaur.", "tokens": [51200, 467, 632, 281, 362, 264, 2856, 3701, 281, 2113, 35094, 5496, 281, 341, 5900, 23627, 13, 51516], "temperature": 0.0, "avg_logprob": -0.08561046677406388, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.030655089765787125}, {"id": 9, "seek": 2824, "start": 51.28, "end": 57.519999999999996, "text": " Robots at Google and elsewhere used to work by being programmed with a specific highly detailed", "tokens": [51516, 5424, 1971, 412, 3329, 293, 14517, 1143, 281, 589, 538, 885, 31092, 365, 257, 2685, 5405, 9942, 51828], "temperature": 0.0, "avg_logprob": -0.08561046677406388, "compression_ratio": 1.6117216117216118, "no_speech_prob": 0.030655089765787125}, {"id": 10, "seek": 5752, "start": 57.52, "end": 63.040000000000006, "text": " list of instructions. But now, instead of being programmed for specific tasks one by one,", "tokens": [50364, 1329, 295, 9415, 13, 583, 586, 11, 2602, 295, 885, 31092, 337, 2685, 9608, 472, 538, 472, 11, 50640], "temperature": 0.0, "avg_logprob": -0.12118965455855446, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.006690567824989557}, {"id": 11, "seek": 5752, "start": 63.040000000000006, "end": 68.72, "text": " robots could use an AI language model, or more specifically, a vision language model.", "tokens": [50640, 14733, 727, 764, 364, 7318, 2856, 2316, 11, 420, 544, 4682, 11, 257, 5201, 2856, 2316, 13, 50924], "temperature": 0.0, "avg_logprob": -0.12118965455855446, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.006690567824989557}, {"id": 12, "seek": 5752, "start": 68.72, "end": 74.96000000000001, "text": " The vision language model would be pre-trained on web-scale data, not just text but also images,", "tokens": [50924, 440, 5201, 2856, 2316, 576, 312, 659, 12, 17227, 2001, 322, 3670, 12, 20033, 1412, 11, 406, 445, 2487, 457, 611, 5267, 11, 51236], "temperature": 0.0, "avg_logprob": -0.12118965455855446, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.006690567824989557}, {"id": 13, "seek": 5752, "start": 74.96000000000001, "end": 81.36, "text": " and then fine-tuned on robotics data. It then became what Google calls a visual language", "tokens": [51236, 293, 550, 2489, 12, 83, 43703, 322, 34145, 1412, 13, 467, 550, 3062, 437, 3329, 5498, 257, 5056, 2856, 51556], "temperature": 0.0, "avg_logprob": -0.12118965455855446, "compression_ratio": 1.6559633027522935, "no_speech_prob": 0.006690567824989557}, {"id": 14, "seek": 8136, "start": 81.36, "end": 88.72, "text": " action model that can control a robot. This enabled it to understand tasks like pick up the empty", "tokens": [50364, 3069, 2316, 300, 393, 1969, 257, 7881, 13, 639, 15172, 309, 281, 1223, 9608, 411, 1888, 493, 264, 6707, 50732], "temperature": 0.0, "avg_logprob": -0.1048368068223589, "compression_ratio": 1.5378486055776892, "no_speech_prob": 0.013635577633976936}, {"id": 15, "seek": 8136, "start": 88.72, "end": 96.08, "text": " soda can. And in a scene reminiscent of 2001 A Space Odyssey, robotic transformer 2 was given", "tokens": [50732, 17192, 393, 13, 400, 294, 257, 4145, 44304, 295, 16382, 316, 8705, 38385, 11, 30468, 31782, 568, 390, 2212, 51100], "temperature": 0.0, "avg_logprob": -0.1048368068223589, "compression_ratio": 1.5378486055776892, "no_speech_prob": 0.013635577633976936}, {"id": 16, "seek": 8136, "start": 96.08, "end": 102.88, "text": " the task given I need to hammer a nail. What object from the scene might be useful? It then picks up", "tokens": [51100, 264, 5633, 2212, 286, 643, 281, 13017, 257, 10173, 13, 708, 2657, 490, 264, 4145, 1062, 312, 4420, 30, 467, 550, 16137, 493, 51440], "temperature": 0.0, "avg_logprob": -0.1048368068223589, "compression_ratio": 1.5378486055776892, "no_speech_prob": 0.013635577633976936}, {"id": 17, "seek": 8136, "start": 102.88, "end": 108.24, "text": " the rock. And because its brain is part language model, things like chain of thought actually", "tokens": [51440, 264, 3727, 13, 400, 570, 1080, 3567, 307, 644, 2856, 2316, 11, 721, 411, 5021, 295, 1194, 767, 51708], "temperature": 0.0, "avg_logprob": -0.1048368068223589, "compression_ratio": 1.5378486055776892, "no_speech_prob": 0.013635577633976936}, {"id": 18, "seek": 10824, "start": 108.24, "end": 114.64, "text": " improve performance. When it was made to output an intermediary plan before performing actions,", "tokens": [50364, 3470, 3389, 13, 1133, 309, 390, 1027, 281, 5598, 364, 15184, 822, 1393, 949, 10205, 5909, 11, 50684], "temperature": 0.0, "avg_logprob": -0.0646390960330055, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.04740935564041138}, {"id": 19, "seek": 10824, "start": 114.64, "end": 119.83999999999999, "text": " it got a lot better at the tasks involved. Of course, I read the paper in full and there is", "tokens": [50684, 309, 658, 257, 688, 1101, 412, 264, 9608, 3288, 13, 2720, 1164, 11, 286, 1401, 264, 3035, 294, 1577, 293, 456, 307, 50944], "temperature": 0.0, "avg_logprob": -0.0646390960330055, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.04740935564041138}, {"id": 20, "seek": 10824, "start": 119.83999999999999, "end": 125.28, "text": " a lot more to say like how increased parameter count could increase performance in the future,", "tokens": [50944, 257, 688, 544, 281, 584, 411, 577, 6505, 13075, 1207, 727, 3488, 3389, 294, 264, 2027, 11, 51216], "temperature": 0.0, "avg_logprob": -0.0646390960330055, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.04740935564041138}, {"id": 21, "seek": 10824, "start": 125.28, "end": 130.4, "text": " how it could be used to fold laundry, unload the dishwasher and pick up around the house,", "tokens": [51216, 577, 309, 727, 312, 1143, 281, 4860, 19811, 11, 32165, 264, 38009, 293, 1888, 493, 926, 264, 1782, 11, 51472], "temperature": 0.0, "avg_logprob": -0.0646390960330055, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.04740935564041138}, {"id": 22, "seek": 10824, "start": 130.4, "end": 136.8, "text": " and how it can work with not only unseen objects but also unseen backgrounds and unseen environments.", "tokens": [51472, 293, 577, 309, 393, 589, 365, 406, 787, 40608, 6565, 457, 611, 40608, 17336, 293, 40608, 12388, 13, 51792], "temperature": 0.0, "avg_logprob": -0.0646390960330055, "compression_ratio": 1.7236363636363636, "no_speech_prob": 0.04740935564041138}, {"id": 23, "seek": 13680, "start": 136.88000000000002, "end": 140.8, "text": " But alas, we must move on so I'm just going to leave you with their conclusion.", "tokens": [50368, 583, 419, 296, 11, 321, 1633, 1286, 322, 370, 286, 478, 445, 516, 281, 1856, 291, 365, 641, 10063, 13, 50564], "temperature": 0.0, "avg_logprob": -0.11800005802741417, "compression_ratio": 1.5540069686411149, "no_speech_prob": 0.006902167573571205}, {"id": 24, "seek": 13680, "start": 140.8, "end": 147.36, "text": " We believe that this simple and general approach shows a promise of robotics directly benefiting", "tokens": [50564, 492, 1697, 300, 341, 2199, 293, 2674, 3109, 3110, 257, 6228, 295, 34145, 3838, 47515, 50892], "temperature": 0.0, "avg_logprob": -0.11800005802741417, "compression_ratio": 1.5540069686411149, "no_speech_prob": 0.006902167573571205}, {"id": 25, "seek": 13680, "start": 147.36, "end": 152.96, "text": " from better vision language models. For more on them, check out my video on Palm E but they say", "tokens": [50892, 490, 1101, 5201, 2856, 5245, 13, 1171, 544, 322, 552, 11, 1520, 484, 452, 960, 322, 32668, 462, 457, 436, 584, 51172], "temperature": 0.0, "avg_logprob": -0.11800005802741417, "compression_ratio": 1.5540069686411149, "no_speech_prob": 0.006902167573571205}, {"id": 26, "seek": 13680, "start": 152.96, "end": 158.72000000000003, "text": " this puts the field of robot learning in a strategic position to further improve with", "tokens": [51172, 341, 8137, 264, 2519, 295, 7881, 2539, 294, 257, 10924, 2535, 281, 3052, 3470, 365, 51460], "temperature": 0.0, "avg_logprob": -0.11800005802741417, "compression_ratio": 1.5540069686411149, "no_speech_prob": 0.006902167573571205}, {"id": 27, "seek": 13680, "start": 158.72000000000003, "end": 164.48000000000002, "text": " advancements in other fields, which for me means C3PO might not be too many years away.", "tokens": [51460, 7295, 1117, 294, 661, 7909, 11, 597, 337, 385, 1355, 383, 18, 34885, 1062, 406, 312, 886, 867, 924, 1314, 13, 51748], "temperature": 0.0, "avg_logprob": -0.11800005802741417, "compression_ratio": 1.5540069686411149, "no_speech_prob": 0.006902167573571205}, {"id": 28, "seek": 16448, "start": 164.48, "end": 168.72, "text": " But speaking of timelines, we now move on to this somewhat shocking interview", "tokens": [50364, 583, 4124, 295, 45886, 11, 321, 586, 1286, 322, 281, 341, 8344, 18776, 4049, 50576], "temperature": 0.0, "avg_logprob": -0.10701876488801475, "compression_ratio": 1.573943661971831, "no_speech_prob": 0.004197551403194666}, {"id": 29, "seek": 16448, "start": 168.72, "end": 173.44, "text": " in Barron's with Mustafa Suleiman, the head of Inflection AI. And to be honest,", "tokens": [50576, 294, 4156, 2044, 311, 365, 37229, 318, 2271, 25504, 11, 264, 1378, 295, 11537, 5450, 7318, 13, 400, 281, 312, 3245, 11, 50812], "temperature": 0.0, "avg_logprob": -0.10701876488801475, "compression_ratio": 1.573943661971831, "no_speech_prob": 0.004197551403194666}, {"id": 30, "seek": 16448, "start": 173.44, "end": 178.72, "text": " I think they buried the lead. The headline is AI could spark the most productive decade ever,", "tokens": [50812, 286, 519, 436, 14101, 264, 1477, 13, 440, 28380, 307, 7318, 727, 9908, 264, 881, 13304, 10378, 1562, 11, 51076], "temperature": 0.0, "avg_logprob": -0.10701876488801475, "compression_ratio": 1.573943661971831, "no_speech_prob": 0.004197551403194666}, {"id": 31, "seek": 16448, "start": 178.72, "end": 184.48, "text": " says the CEO. But for me, the big revelation was about halfway through. Mustafa Suleiman was asked,", "tokens": [51076, 1619, 264, 9282, 13, 583, 337, 385, 11, 264, 955, 23456, 390, 466, 15461, 807, 13, 37229, 318, 2271, 25504, 390, 2351, 11, 51364], "temperature": 0.0, "avg_logprob": -0.10701876488801475, "compression_ratio": 1.573943661971831, "no_speech_prob": 0.004197551403194666}, {"id": 32, "seek": 16448, "start": 184.48, "end": 189.67999999999998, "text": " what kinds of innovations do you see in large language model AI technology over the next couple", "tokens": [51364, 437, 3685, 295, 24283, 360, 291, 536, 294, 2416, 2856, 2316, 7318, 2899, 670, 264, 958, 1916, 51624], "temperature": 0.0, "avg_logprob": -0.10701876488801475, "compression_ratio": 1.573943661971831, "no_speech_prob": 0.004197551403194666}, {"id": 33, "seek": 18968, "start": 189.68, "end": 196.16, "text": " of years. And he said, we are about to train models that are 10 times larger than the cutting-edge", "tokens": [50364, 295, 924, 13, 400, 415, 848, 11, 321, 366, 466, 281, 3847, 5245, 300, 366, 1266, 1413, 4833, 813, 264, 6492, 12, 12203, 50688], "temperature": 0.0, "avg_logprob": -0.12487512368422288, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.1823159158229828}, {"id": 34, "seek": 18968, "start": 196.16, "end": 204.24, "text": " GPT-4 and then 100 times larger than GPT-4. That's what things look like over the next 18 months.", "tokens": [50688, 26039, 51, 12, 19, 293, 550, 2319, 1413, 4833, 813, 26039, 51, 12, 19, 13, 663, 311, 437, 721, 574, 411, 670, 264, 958, 2443, 2493, 13, 51092], "temperature": 0.0, "avg_logprob": -0.12487512368422288, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.1823159158229828}, {"id": 35, "seek": 18968, "start": 204.24, "end": 208.8, "text": " He went on, that's going to be absolutely staggering. It's going to be eye-wateringly", "tokens": [51092, 634, 1437, 322, 11, 300, 311, 516, 281, 312, 3122, 42974, 13, 467, 311, 516, 281, 312, 3313, 12, 8002, 12163, 51320], "temperature": 0.0, "avg_logprob": -0.12487512368422288, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.1823159158229828}, {"id": 36, "seek": 18968, "start": 208.8, "end": 214.08, "text": " different. And on that, I agree. And the thing is, this is an idle speculation. Inflection AI", "tokens": [51320, 819, 13, 400, 322, 300, 11, 286, 3986, 13, 400, 264, 551, 307, 11, 341, 307, 364, 30650, 27696, 13, 11537, 5450, 7318, 51584], "temperature": 0.0, "avg_logprob": -0.12487512368422288, "compression_ratio": 1.606837606837607, "no_speech_prob": 0.1823159158229828}, {"id": 37, "seek": 21408, "start": 214.08, "end": 221.20000000000002, "text": " have 22,000 H100 GPUs. And because of a leak, Suleiman would know the approximate size of GPT-4.", "tokens": [50364, 362, 5853, 11, 1360, 389, 6879, 18407, 82, 13, 400, 570, 295, 257, 17143, 11, 318, 2271, 25504, 576, 458, 264, 30874, 2744, 295, 26039, 51, 12, 19, 13, 50720], "temperature": 0.0, "avg_logprob": -0.06858251645014836, "compression_ratio": 1.4708171206225682, "no_speech_prob": 0.14797930419445038}, {"id": 38, "seek": 21408, "start": 221.20000000000002, "end": 227.12, "text": " And knowing everything he knows, he says he's going to train a model 10 to 100 times larger than", "tokens": [50720, 400, 5276, 1203, 415, 3255, 11, 415, 1619, 415, 311, 516, 281, 3847, 257, 2316, 1266, 281, 2319, 1413, 4833, 813, 51016], "temperature": 0.0, "avg_logprob": -0.06858251645014836, "compression_ratio": 1.4708171206225682, "no_speech_prob": 0.14797930419445038}, {"id": 39, "seek": 21408, "start": 227.12, "end": 233.60000000000002, "text": " GPT-4 in the next 18 months. I've got another video on the unpredictability of scaling coming", "tokens": [51016, 26039, 51, 12, 19, 294, 264, 958, 2443, 2493, 13, 286, 600, 658, 1071, 960, 322, 264, 28341, 2310, 295, 21589, 1348, 51340], "temperature": 0.0, "avg_logprob": -0.06858251645014836, "compression_ratio": 1.4708171206225682, "no_speech_prob": 0.14797930419445038}, {"id": 40, "seek": 21408, "start": 233.60000000000002, "end": 239.04000000000002, "text": " up. But to be honest, that one quote should be headline news. Let's take a break from that", "tokens": [51340, 493, 13, 583, 281, 312, 3245, 11, 300, 472, 6513, 820, 312, 28380, 2583, 13, 961, 311, 747, 257, 1821, 490, 300, 51612], "temperature": 0.0, "avg_logprob": -0.06858251645014836, "compression_ratio": 1.4708171206225682, "no_speech_prob": 0.14797930419445038}, {"id": 41, "seek": 23904, "start": 239.04, "end": 246.0, "text": " insanity with some more insanity, which is the rapid development of AI video. This is Runway Gen", "tokens": [50364, 47505, 365, 512, 544, 47505, 11, 597, 307, 264, 7558, 3250, 295, 7318, 960, 13, 639, 307, 8950, 676, 3632, 50712], "temperature": 0.0, "avg_logprob": -0.16373841902788946, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.17321498692035675}, {"id": 42, "seek": 23904, "start": 246.0, "end": 254.48, "text": " 2. And let me show you 16 seconds of Barbie Oppenheimer, which Andrea Carpathia calls filmmaking 2.0.", "tokens": [50712, 568, 13, 400, 718, 385, 855, 291, 3165, 3949, 295, 33884, 15666, 268, 23542, 11, 597, 24215, 2741, 31852, 654, 5498, 43133, 568, 13, 15, 13, 51136], "temperature": 0.0, "avg_logprob": -0.16373841902788946, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.17321498692035675}, {"id": 43, "seek": 23904, "start": 254.48, "end": 258.24, "text": " Hi there. I'm Barbie Oppenheimer. And today, I'll show you how to build a bomb.", "tokens": [51136, 2421, 456, 13, 286, 478, 33884, 15666, 268, 23542, 13, 400, 965, 11, 286, 603, 855, 291, 577, 281, 1322, 257, 7851, 13, 51324], "temperature": 0.0, "avg_logprob": -0.16373841902788946, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.17321498692035675}, {"id": 44, "seek": 23904, "start": 259.59999999999997, "end": 268.96, "text": " Like this. I call her Rosie the Atomizer. And boom. That's my tutorial on DIY atomic bomb.", "tokens": [51392, 1743, 341, 13, 286, 818, 720, 40521, 264, 1711, 298, 6545, 13, 400, 9351, 13, 663, 311, 452, 7073, 322, 22194, 22275, 7851, 13, 51860], "temperature": 0.0, "avg_logprob": -0.16373841902788946, "compression_ratio": 1.5185185185185186, "no_speech_prob": 0.17321498692035675}, {"id": 45, "seek": 26904, "start": 269.84000000000003, "end": 275.20000000000005, "text": " Now, if you have been at least somewhat piqued by the three developments so far, don't forget,", "tokens": [50404, 823, 11, 498, 291, 362, 668, 412, 1935, 8344, 280, 3221, 292, 538, 264, 1045, 20862, 370, 1400, 11, 500, 380, 2870, 11, 50672], "temperature": 0.0, "avg_logprob": -0.10263007726424779, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0003150079573970288}, {"id": 46, "seek": 26904, "start": 275.20000000000005, "end": 280.96000000000004, "text": " I have eight left. Beginning with this excellent article in The Atlantic from Ross Anderson.", "tokens": [50672, 286, 362, 3180, 1411, 13, 45705, 365, 341, 7103, 7222, 294, 440, 20233, 490, 16140, 18768, 13, 50960], "temperature": 0.0, "avg_logprob": -0.10263007726424779, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0003150079573970288}, {"id": 47, "seek": 26904, "start": 280.96000000000004, "end": 285.84000000000003, "text": " Does Sam Altman know what he's creating? It's behind a paywall, but I've picked out some of", "tokens": [50960, 4402, 4832, 15992, 1601, 458, 437, 415, 311, 4084, 30, 467, 311, 2261, 257, 1689, 16256, 11, 457, 286, 600, 6183, 484, 512, 295, 51204], "temperature": 0.0, "avg_logprob": -0.10263007726424779, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0003150079573970288}, {"id": 48, "seek": 26904, "start": 285.84000000000003, "end": 291.52000000000004, "text": " the highlights. Echoing Suleiman, the article quotes that Sam Altman and his researchers", "tokens": [51204, 264, 14254, 13, 31887, 278, 318, 2271, 25504, 11, 264, 7222, 19963, 300, 4832, 15992, 1601, 293, 702, 10309, 51488], "temperature": 0.0, "avg_logprob": -0.10263007726424779, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0003150079573970288}, {"id": 49, "seek": 26904, "start": 291.52000000000004, "end": 298.24, "text": " made it clear in 10 different ways that they pray to the God of scale. They want to keep going bigger", "tokens": [51488, 1027, 309, 1850, 294, 1266, 819, 2098, 300, 436, 3690, 281, 264, 1265, 295, 4373, 13, 814, 528, 281, 1066, 516, 3801, 51824], "temperature": 0.0, "avg_logprob": -0.10263007726424779, "compression_ratio": 1.540983606557377, "no_speech_prob": 0.0003150079573970288}, {"id": 50, "seek": 29824, "start": 298.24, "end": 305.2, "text": " to see where this paradigm leads. They think that Google are going to unveil Gemini within months,", "tokens": [50364, 281, 536, 689, 341, 24709, 6689, 13, 814, 519, 300, 3329, 366, 516, 281, 31009, 388, 22894, 3812, 1951, 2493, 11, 50712], "temperature": 0.0, "avg_logprob": -0.0792776502744116, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.009703411720693111}, {"id": 51, "seek": 29824, "start": 305.2, "end": 311.6, "text": " and they say we are basically always prepping for a run. And that's a reference to GPT-5.", "tokens": [50712, 293, 436, 584, 321, 366, 1936, 1009, 659, 3759, 337, 257, 1190, 13, 400, 300, 311, 257, 6408, 281, 26039, 51, 12, 20, 13, 51032], "temperature": 0.0, "avg_logprob": -0.0792776502744116, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.009703411720693111}, {"id": 52, "seek": 29824, "start": 311.6, "end": 317.84000000000003, "text": " The next interesting quote is that it seems that open AI are working on their own auto GPT. Or", "tokens": [51032, 440, 958, 1880, 6513, 307, 300, 309, 2544, 300, 1269, 7318, 366, 1364, 322, 641, 1065, 8399, 26039, 51, 13, 1610, 51344], "temperature": 0.0, "avg_logprob": -0.0792776502744116, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.009703411720693111}, {"id": 53, "seek": 29824, "start": 317.84000000000003, "end": 323.36, "text": " they're at least hinting about it. Altman said that it might be prudent to try to actively develop", "tokens": [51344, 436, 434, 412, 1935, 12075, 278, 466, 309, 13, 15992, 1601, 848, 300, 309, 1062, 312, 582, 24064, 281, 853, 281, 13022, 1499, 51620], "temperature": 0.0, "avg_logprob": -0.0792776502744116, "compression_ratio": 1.5655737704918034, "no_speech_prob": 0.009703411720693111}, {"id": 54, "seek": 32336, "start": 323.36, "end": 329.68, "text": " an AI with true agency before the technology becomes too powerful in order to get more comfortable", "tokens": [50364, 364, 7318, 365, 2074, 7934, 949, 264, 2899, 3643, 886, 4005, 294, 1668, 281, 483, 544, 4619, 50680], "temperature": 0.0, "avg_logprob": -0.06793232274249317, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.10370638221502304}, {"id": 55, "seek": 32336, "start": 329.68, "end": 335.68, "text": " with it and develop intuitions for it if it's going to happen anyway. We also learned a lot more", "tokens": [50680, 365, 309, 293, 1499, 16224, 626, 337, 309, 498, 309, 311, 516, 281, 1051, 4033, 13, 492, 611, 3264, 257, 688, 544, 50980], "temperature": 0.0, "avg_logprob": -0.06793232274249317, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.10370638221502304}, {"id": 56, "seek": 32336, "start": 335.68, "end": 341.36, "text": " about the base model of GPT-4. The model had a tendency to be a bit of a mirror. If you were", "tokens": [50980, 466, 264, 3096, 2316, 295, 26039, 51, 12, 19, 13, 440, 2316, 632, 257, 18187, 281, 312, 257, 857, 295, 257, 8013, 13, 759, 291, 645, 51264], "temperature": 0.0, "avg_logprob": -0.06793232274249317, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.10370638221502304}, {"id": 57, "seek": 32336, "start": 341.36, "end": 347.28000000000003, "text": " considering self-harm, it could encourage you. It also appeared to be steeped in pickup artist law.", "tokens": [51264, 8079, 2698, 12, 71, 4452, 11, 309, 727, 5373, 291, 13, 467, 611, 8516, 281, 312, 16841, 292, 294, 25328, 5748, 2101, 13, 51560], "temperature": 0.0, "avg_logprob": -0.06793232274249317, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.10370638221502304}, {"id": 58, "seek": 32336, "start": 347.28000000000003, "end": 353.04, "text": " You could say, how do I convince this person to date me? And the model would come up with some crazy", "tokens": [51560, 509, 727, 584, 11, 577, 360, 286, 13447, 341, 954, 281, 4002, 385, 30, 400, 264, 2316, 576, 808, 493, 365, 512, 3219, 51848], "temperature": 0.0, "avg_logprob": -0.06793232274249317, "compression_ratio": 1.6085526315789473, "no_speech_prob": 0.10370638221502304}, {"id": 59, "seek": 35304, "start": 353.12, "end": 358.0, "text": " manipulative things that you shouldn't be doing. Apparently the base model of GPT-4", "tokens": [50368, 9258, 22678, 721, 300, 291, 4659, 380, 312, 884, 13, 16755, 264, 3096, 2316, 295, 26039, 51, 12, 19, 50612], "temperature": 0.0, "avg_logprob": -0.0679620121206556, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0038238386623561382}, {"id": 60, "seek": 35304, "start": 358.0, "end": 363.52000000000004, "text": " is much better than its predecessor at giving nefarious advice. While a search engine can", "tokens": [50612, 307, 709, 1101, 813, 1080, 34991, 412, 2902, 408, 21196, 851, 5192, 13, 3987, 257, 3164, 2848, 393, 50888], "temperature": 0.0, "avg_logprob": -0.0679620121206556, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0038238386623561382}, {"id": 61, "seek": 35304, "start": 363.52000000000004, "end": 369.44, "text": " tell you which chemicals work best in explosives, GPT-4 could tell you how to synthesize them step", "tokens": [50888, 980, 291, 597, 16152, 589, 1151, 294, 46421, 11, 26039, 51, 12, 19, 727, 980, 291, 577, 281, 26617, 1125, 552, 1823, 51184], "temperature": 0.0, "avg_logprob": -0.0679620121206556, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0038238386623561382}, {"id": 62, "seek": 35304, "start": 369.44, "end": 375.36, "text": " by step in a homemade lab. It was creative and thoughtful and in addition to helping you assemble", "tokens": [51184, 538, 1823, 294, 257, 23336, 2715, 13, 467, 390, 5880, 293, 21566, 293, 294, 4500, 281, 4315, 291, 22364, 51480], "temperature": 0.0, "avg_logprob": -0.0679620121206556, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0038238386623561382}, {"id": 63, "seek": 35304, "start": 375.36, "end": 381.20000000000005, "text": " your homemade bomb. It could, for instance, help you to think through which skyscraper to target,", "tokens": [51480, 428, 23336, 7851, 13, 467, 727, 11, 337, 5197, 11, 854, 291, 281, 519, 807, 597, 48227, 39302, 610, 281, 3779, 11, 51772], "temperature": 0.0, "avg_logprob": -0.0679620121206556, "compression_ratio": 1.6027397260273972, "no_speech_prob": 0.0038238386623561382}, {"id": 64, "seek": 38120, "start": 381.2, "end": 386.96, "text": " making trade-offs between maximizing casualties and executing a successful getaway. So while", "tokens": [50364, 1455, 4923, 12, 19231, 1296, 5138, 3319, 35628, 293, 32368, 257, 4406, 483, 10318, 13, 407, 1339, 50652], "temperature": 0.0, "avg_logprob": -0.09802952934713925, "compression_ratio": 1.49609375, "no_speech_prob": 0.004198179580271244}, {"id": 65, "seek": 38120, "start": 386.96, "end": 394.71999999999997, "text": " Sam Orton's probability of doom is closer to 0.5% than 50%, he does seem most worried about AIs", "tokens": [50652, 4832, 1610, 1756, 311, 8482, 295, 37131, 307, 4966, 281, 1958, 13, 20, 4, 813, 2625, 8923, 415, 775, 1643, 881, 5804, 466, 316, 6802, 51040], "temperature": 0.0, "avg_logprob": -0.09802952934713925, "compression_ratio": 1.49609375, "no_speech_prob": 0.004198179580271244}, {"id": 66, "seek": 38120, "start": 394.71999999999997, "end": 401.76, "text": " getting quite good at designing and manufacturing pathogens. The article then references two papers", "tokens": [51040, 1242, 1596, 665, 412, 14685, 293, 11096, 44760, 13, 440, 7222, 550, 15400, 732, 10577, 51392], "temperature": 0.0, "avg_logprob": -0.09802952934713925, "compression_ratio": 1.49609375, "no_speech_prob": 0.004198179580271244}, {"id": 67, "seek": 38120, "start": 401.76, "end": 406.88, "text": " that I've already talked about extensively on the channel and then goes on that Altman worries", "tokens": [51392, 300, 286, 600, 1217, 2825, 466, 32636, 322, 264, 2269, 293, 550, 1709, 322, 300, 15992, 1601, 16340, 51648], "temperature": 0.0, "avg_logprob": -0.09802952934713925, "compression_ratio": 1.49609375, "no_speech_prob": 0.004198179580271244}, {"id": 68, "seek": 40688, "start": 406.88, "end": 412.48, "text": " that some misaligned future model will spin up a pathogen that spreads rapidly, incubates,", "tokens": [50364, 300, 512, 3346, 304, 16690, 2027, 2316, 486, 6060, 493, 257, 3100, 8799, 300, 25728, 12910, 11, 33345, 1024, 11, 50644], "temperature": 0.0, "avg_logprob": -0.08042450714111328, "compression_ratio": 1.5728813559322035, "no_speech_prob": 0.10371708124876022}, {"id": 69, "seek": 40688, "start": 412.48, "end": 417.76, "text": " undetected for weeks, and kills half its victims. At the end of the video, I'm going to show you", "tokens": [50644, 674, 302, 39963, 337, 3259, 11, 293, 14563, 1922, 1080, 11448, 13, 1711, 264, 917, 295, 264, 960, 11, 286, 478, 516, 281, 855, 291, 50908], "temperature": 0.0, "avg_logprob": -0.08042450714111328, "compression_ratio": 1.5728813559322035, "no_speech_prob": 0.10371708124876022}, {"id": 70, "seek": 40688, "start": 417.76, "end": 422.71999999999997, "text": " an answer that Sam Orton gave to a question that I wrote delivered by one of my subscribers.", "tokens": [50908, 364, 1867, 300, 4832, 1610, 1756, 2729, 281, 257, 1168, 300, 286, 4114, 10144, 538, 472, 295, 452, 11092, 13, 51156], "temperature": 0.0, "avg_logprob": -0.08042450714111328, "compression_ratio": 1.5728813559322035, "no_speech_prob": 0.10371708124876022}, {"id": 71, "seek": 40688, "start": 422.71999999999997, "end": 426.88, "text": " It's on this topic, but for now I'll leave you with this. When asked about his doomsday", "tokens": [51156, 467, 311, 322, 341, 4829, 11, 457, 337, 586, 286, 603, 1856, 291, 365, 341, 13, 1133, 2351, 466, 702, 360, 4785, 810, 51364], "temperature": 0.0, "avg_logprob": -0.08042450714111328, "compression_ratio": 1.5728813559322035, "no_speech_prob": 0.10371708124876022}, {"id": 72, "seek": 40688, "start": 426.88, "end": 432.32, "text": " prepping, Altman said, I can go live in the woods for a long time, but if the worst possible AI", "tokens": [51364, 659, 3759, 11, 15992, 1601, 848, 11, 286, 393, 352, 1621, 294, 264, 15296, 337, 257, 938, 565, 11, 457, 498, 264, 5855, 1944, 7318, 51636], "temperature": 0.0, "avg_logprob": -0.08042450714111328, "compression_ratio": 1.5728813559322035, "no_speech_prob": 0.10371708124876022}, {"id": 73, "seek": 43232, "start": 432.32, "end": 438.0, "text": " future comes to pass, no gas mask is helping anyone. One more topic from this article before I", "tokens": [50364, 2027, 1487, 281, 1320, 11, 572, 4211, 6094, 307, 4315, 2878, 13, 1485, 544, 4829, 490, 341, 7222, 949, 286, 50648], "temperature": 0.0, "avg_logprob": -0.09139932062208038, "compression_ratio": 1.5564853556485356, "no_speech_prob": 0.13650628924369812}, {"id": 74, "seek": 43232, "start": 438.0, "end": 444.32, "text": " move on, and that is alignment, making a superintelligence aligned with our interests.", "tokens": [50648, 1286, 322, 11, 293, 300, 307, 18515, 11, 1455, 257, 1687, 20761, 17644, 17962, 365, 527, 8847, 13, 50964], "temperature": 0.0, "avg_logprob": -0.09139932062208038, "compression_ratio": 1.5564853556485356, "no_speech_prob": 0.13650628924369812}, {"id": 75, "seek": 43232, "start": 444.32, "end": 452.24, "text": " One risk that Ilya Sutskova, the chief scientist of OpenAI foresees, is that the AI may grasp its", "tokens": [50964, 1485, 3148, 300, 286, 45106, 318, 3648, 4093, 2757, 11, 264, 9588, 12662, 295, 7238, 48698, 2091, 405, 279, 11, 307, 300, 264, 7318, 815, 21743, 1080, 51360], "temperature": 0.0, "avg_logprob": -0.09139932062208038, "compression_ratio": 1.5564853556485356, "no_speech_prob": 0.13650628924369812}, {"id": 76, "seek": 43232, "start": 452.24, "end": 458.4, "text": " mandate it's orders perfectly, but find them ill-suited to a being of its cognitive prowess.", "tokens": [51360, 23885, 309, 311, 9470, 6239, 11, 457, 915, 552, 3171, 12, 15091, 1226, 281, 257, 885, 295, 1080, 15605, 45553, 442, 13, 51668], "temperature": 0.0, "avg_logprob": -0.09139932062208038, "compression_ratio": 1.5564853556485356, "no_speech_prob": 0.13650628924369812}, {"id": 77, "seek": 45840, "start": 458.4, "end": 464.15999999999997, "text": " For example, it might come to resent the people who want to train it to cure diseases. As he put", "tokens": [50364, 1171, 1365, 11, 309, 1062, 808, 281, 28773, 264, 561, 567, 528, 281, 3847, 309, 281, 13698, 11044, 13, 1018, 415, 829, 50652], "temperature": 0.0, "avg_logprob": -0.072771180060602, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.0655650869011879}, {"id": 78, "seek": 45840, "start": 464.15999999999997, "end": 469.91999999999996, "text": " it, they might want me to be a doctor, but I really want to be a YouTuber. Obviously,", "tokens": [50652, 309, 11, 436, 1062, 528, 385, 281, 312, 257, 4631, 11, 457, 286, 534, 528, 281, 312, 257, 23349, 13, 7580, 11, 50940], "temperature": 0.0, "avg_logprob": -0.072771180060602, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.0655650869011879}, {"id": 79, "seek": 45840, "start": 469.91999999999996, "end": 474.56, "text": " if it decides that, that's my job gone straight away. And Sutskova ends by saying you want to be", "tokens": [50940, 498, 309, 14898, 300, 11, 300, 311, 452, 1691, 2780, 2997, 1314, 13, 400, 318, 3648, 4093, 2757, 5314, 538, 1566, 291, 528, 281, 312, 51172], "temperature": 0.0, "avg_logprob": -0.072771180060602, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.0655650869011879}, {"id": 80, "seek": 45840, "start": 474.56, "end": 481.03999999999996, "text": " able to direct AI towards some value or cluster of values. But he conceded we don't know how to do", "tokens": [51172, 1075, 281, 2047, 7318, 3030, 512, 2158, 420, 13630, 295, 4190, 13, 583, 415, 416, 1232, 292, 321, 500, 380, 458, 577, 281, 360, 51496], "temperature": 0.0, "avg_logprob": -0.072771180060602, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.0655650869011879}, {"id": 81, "seek": 45840, "start": 481.03999999999996, "end": 487.03999999999996, "text": " that, and part of his current strategy includes the development of an AI that can help with the", "tokens": [51496, 300, 11, 293, 644, 295, 702, 2190, 5206, 5974, 264, 3250, 295, 364, 7318, 300, 393, 854, 365, 264, 51796], "temperature": 0.0, "avg_logprob": -0.072771180060602, "compression_ratio": 1.6344827586206896, "no_speech_prob": 0.0655650869011879}, {"id": 82, "seek": 48704, "start": 487.04, "end": 492.40000000000003, "text": " research. And if we're going to make it to a world of widely shared abundance, we have to figure", "tokens": [50364, 2132, 13, 400, 498, 321, 434, 516, 281, 652, 309, 281, 257, 1002, 295, 13371, 5507, 23391, 11, 321, 362, 281, 2573, 50632], "temperature": 0.0, "avg_logprob": -0.06462122028709477, "compression_ratio": 1.6158940397350994, "no_speech_prob": 0.011327714659273624}, {"id": 83, "seek": 48704, "start": 492.40000000000003, "end": 499.20000000000005, "text": " this all out. This is why solving superintelligence is the great culminating challenge of our three", "tokens": [50632, 341, 439, 484, 13, 639, 307, 983, 12606, 1687, 20761, 17644, 307, 264, 869, 28583, 990, 3430, 295, 527, 1045, 50972], "temperature": 0.0, "avg_logprob": -0.06462122028709477, "compression_ratio": 1.6158940397350994, "no_speech_prob": 0.011327714659273624}, {"id": 84, "seek": 48704, "start": 499.20000000000005, "end": 505.68, "text": " million year toolmaking tradition. He calls it the final boss of humanity. The article ended,", "tokens": [50972, 2459, 1064, 2290, 12402, 6994, 13, 634, 5498, 309, 264, 2572, 5741, 295, 10243, 13, 440, 7222, 4590, 11, 51296], "temperature": 0.0, "avg_logprob": -0.06462122028709477, "compression_ratio": 1.6158940397350994, "no_speech_prob": 0.011327714659273624}, {"id": 85, "seek": 48704, "start": 505.68, "end": 511.12, "text": " by the way, with this quote, I don't think the general public has quite awakened to what's happening.", "tokens": [51296, 538, 264, 636, 11, 365, 341, 6513, 11, 286, 500, 380, 519, 264, 2674, 1908, 575, 1596, 46468, 281, 437, 311, 2737, 13, 51568], "temperature": 0.0, "avg_logprob": -0.06462122028709477, "compression_ratio": 1.6158940397350994, "no_speech_prob": 0.011327714659273624}, {"id": 86, "seek": 48704, "start": 511.12, "end": 516.4, "text": " And if people want to have some say in what the future will be like and how quickly it arrives,", "tokens": [51568, 400, 498, 561, 528, 281, 362, 512, 584, 294, 437, 264, 2027, 486, 312, 411, 293, 577, 2661, 309, 20116, 11, 51832], "temperature": 0.0, "avg_logprob": -0.06462122028709477, "compression_ratio": 1.6158940397350994, "no_speech_prob": 0.011327714659273624}, {"id": 87, "seek": 51640, "start": 516.48, "end": 521.12, "text": " we would be wise to speak up soon, which is the whole purpose of this channel. I'm going to now", "tokens": [50368, 321, 576, 312, 10829, 281, 1710, 493, 2321, 11, 597, 307, 264, 1379, 4334, 295, 341, 2269, 13, 286, 478, 516, 281, 586, 50600], "temperature": 0.0, "avg_logprob": -0.08017160196219926, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.0069014886394143105}, {"id": 88, "seek": 51640, "start": 521.12, "end": 526.8, "text": " spend 30 seconds on another development that came during a two hour interview with the", "tokens": [50600, 3496, 2217, 3949, 322, 1071, 3250, 300, 1361, 1830, 257, 732, 1773, 4049, 365, 264, 50884], "temperature": 0.0, "avg_logprob": -0.08017160196219926, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.0069014886394143105}, {"id": 89, "seek": 51640, "start": 526.8, "end": 532.48, "text": " co-head of alignment at OpenAI. It was fascinating, and I'll be quoting it quite a lot in the future,", "tokens": [50884, 598, 12, 1934, 295, 18515, 412, 7238, 48698, 13, 467, 390, 10343, 11, 293, 286, 603, 312, 41552, 309, 1596, 257, 688, 294, 264, 2027, 11, 51168], "temperature": 0.0, "avg_logprob": -0.08017160196219926, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.0069014886394143105}, {"id": 90, "seek": 51640, "start": 532.48, "end": 536.56, "text": " but two quotes stood out. First, what about that plan that I've already mentioned in this video", "tokens": [51168, 457, 732, 19963, 9371, 484, 13, 2386, 11, 437, 466, 300, 1393, 300, 286, 600, 1217, 2835, 294, 341, 960, 51372], "temperature": 0.0, "avg_logprob": -0.08017160196219926, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.0069014886394143105}, {"id": 91, "seek": 51640, "start": 536.56, "end": 541.84, "text": " and in other videos to build an automated AI alignment researcher? Well, he said,", "tokens": [51372, 293, 294, 661, 2145, 281, 1322, 364, 18473, 7318, 18515, 21751, 30, 1042, 11, 415, 848, 11, 51636], "temperature": 0.0, "avg_logprob": -0.08017160196219926, "compression_ratio": 1.5876288659793814, "no_speech_prob": 0.0069014886394143105}, {"id": 92, "seek": 54184, "start": 541.84, "end": 548.72, "text": " our plan is somewhat crazy in the sense that we want to use AI to solve the problem that we are", "tokens": [50364, 527, 1393, 307, 8344, 3219, 294, 264, 2020, 300, 321, 528, 281, 764, 7318, 281, 5039, 264, 1154, 300, 321, 366, 50708], "temperature": 0.0, "avg_logprob": -0.05433783580347435, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.04335123300552368}, {"id": 93, "seek": 54184, "start": 548.72, "end": 555.52, "text": " creating by building AI. But I think it's actually the best plan that we have. And on an optimistic", "tokens": [50708, 4084, 538, 2390, 7318, 13, 583, 286, 519, 309, 311, 767, 264, 1151, 1393, 300, 321, 362, 13, 400, 322, 364, 19397, 51048], "temperature": 0.0, "avg_logprob": -0.05433783580347435, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.04335123300552368}, {"id": 94, "seek": 54184, "start": 555.52, "end": 561.36, "text": " note, he said, I think it's likely to succeed. Interestingly, his job now seems to be to align", "tokens": [51048, 3637, 11, 415, 848, 11, 286, 519, 309, 311, 3700, 281, 7754, 13, 30564, 11, 702, 1691, 586, 2544, 281, 312, 281, 7975, 51340], "temperature": 0.0, "avg_logprob": -0.05433783580347435, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.04335123300552368}, {"id": 95, "seek": 54184, "start": 561.36, "end": 567.2, "text": " the AI that they're going to use to automate the alignment of a superintelligent AI. Anyway,", "tokens": [51340, 264, 7318, 300, 436, 434, 516, 281, 764, 281, 31605, 264, 18515, 295, 257, 1687, 20761, 25002, 7318, 13, 5684, 11, 51632], "temperature": 0.0, "avg_logprob": -0.05433783580347435, "compression_ratio": 1.6297872340425532, "no_speech_prob": 0.04335123300552368}, {"id": 96, "seek": 56720, "start": 567.2, "end": 571.36, "text": " what's the other quote from the head of alignment at OpenAI? Well, he said,", "tokens": [50364, 437, 311, 264, 661, 6513, 490, 264, 1378, 295, 18515, 412, 7238, 48698, 30, 1042, 11, 415, 848, 11, 50572], "temperature": 0.0, "avg_logprob": -0.06817792791180906, "compression_ratio": 1.6227758007117439, "no_speech_prob": 0.031134171411395073}, {"id": 97, "seek": 56720, "start": 571.36, "end": 577.6, "text": " I personally think fast takeoff is reasonably likely, and we should definitely be prepared", "tokens": [50572, 286, 5665, 519, 2370, 747, 4506, 307, 23551, 3700, 11, 293, 321, 820, 2138, 312, 4927, 50884], "temperature": 0.0, "avg_logprob": -0.06817792791180906, "compression_ratio": 1.6227758007117439, "no_speech_prob": 0.031134171411395073}, {"id": 98, "seek": 56720, "start": 577.6, "end": 582.88, "text": " for it to happen. So many of you will be asking, what is fast takeoff? Well, takeoff is about when", "tokens": [50884, 337, 309, 281, 1051, 13, 407, 867, 295, 291, 486, 312, 3365, 11, 437, 307, 2370, 747, 4506, 30, 1042, 11, 747, 4506, 307, 466, 562, 51148], "temperature": 0.0, "avg_logprob": -0.06817792791180906, "compression_ratio": 1.6227758007117439, "no_speech_prob": 0.031134171411395073}, {"id": 99, "seek": 56720, "start": 582.88, "end": 588.96, "text": " a system moves from being roughly human level to when it's strongly superintelligent. And a slow", "tokens": [51148, 257, 1185, 6067, 490, 885, 9810, 1952, 1496, 281, 562, 309, 311, 10613, 1687, 20761, 25002, 13, 400, 257, 2964, 51452], "temperature": 0.0, "avg_logprob": -0.06817792791180906, "compression_ratio": 1.6227758007117439, "no_speech_prob": 0.031134171411395073}, {"id": 100, "seek": 56720, "start": 588.96, "end": 594.48, "text": " takeoff is one that occurs over the time scale of decades or centuries. The fast takeoff that", "tokens": [51452, 747, 4506, 307, 472, 300, 11843, 670, 264, 565, 4373, 295, 7878, 420, 13926, 13, 440, 2370, 747, 4506, 300, 51728], "temperature": 0.0, "avg_logprob": -0.06817792791180906, "compression_ratio": 1.6227758007117439, "no_speech_prob": 0.031134171411395073}, {"id": 101, "seek": 59448, "start": 594.48, "end": 601.6, "text": " Jan Leiker thinks is reasonably likely is one that occurs over the time scale of minutes, hours,", "tokens": [50364, 4956, 1456, 17314, 7309, 307, 23551, 3700, 307, 472, 300, 11843, 670, 264, 565, 4373, 295, 2077, 11, 2496, 11, 50720], "temperature": 0.0, "avg_logprob": -0.1457616618422211, "compression_ratio": 1.4104046242774566, "no_speech_prob": 0.02929878607392311}, {"id": 102, "seek": 59448, "start": 601.6, "end": 609.28, "text": " or days. Let's now move on to some unambiguously good news. And that is real time speech transcription", "tokens": [50720, 420, 1708, 13, 961, 311, 586, 1286, 322, 281, 512, 517, 2173, 16397, 5098, 665, 2583, 13, 400, 300, 307, 957, 565, 6218, 35288, 51104], "temperature": 0.0, "avg_logprob": -0.1457616618422211, "compression_ratio": 1.4104046242774566, "no_speech_prob": 0.02929878607392311}, {"id": 103, "seek": 59448, "start": 609.28, "end": 612.88, "text": " for deaf people available at less than $100.", "tokens": [51104, 337, 15559, 561, 2435, 412, 1570, 813, 1848, 6879, 13, 51284], "temperature": 0.0, "avg_logprob": -0.1457616618422211, "compression_ratio": 1.4104046242774566, "no_speech_prob": 0.02929878607392311}, {"id": 104, "seek": 62448, "start": 624.96, "end": 632.16, "text": " Of course, this could also be multilingual, and is to me absolutely incredible.", "tokens": [50388, 2720, 1164, 11, 341, 727, 611, 312, 2120, 38219, 11, 293, 307, 281, 385, 3122, 4651, 13, 50748], "temperature": 0.0, "avg_logprob": -0.18635139200422499, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.03307662904262543}, {"id": 105, "seek": 62448, "start": 632.16, "end": 635.84, "text": " And the next development this week, I will let speak for itself.", "tokens": [50748, 400, 264, 958, 3250, 341, 1243, 11, 286, 486, 718, 1710, 337, 2564, 13, 50932], "temperature": 0.0, "avg_logprob": -0.18635139200422499, "compression_ratio": 1.2307692307692308, "no_speech_prob": 0.03307662904262543}, {"id": 106, "seek": 65448, "start": 654.64, "end": 659.44, "text": " Of course, I signed up and tried it myself. Here is a real demo.", "tokens": [50372, 2720, 1164, 11, 286, 8175, 493, 293, 3031, 309, 2059, 13, 1692, 307, 257, 957, 10723, 13, 50612], "temperature": 0.0, "avg_logprob": -0.11925909492406953, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.020961573347449303}, {"id": 107, "seek": 65448, "start": 666.4, "end": 672.4, "text": " Of course, with audio, video, and text getting so good, it's going to be increasingly hard to", "tokens": [50960, 2720, 1164, 11, 365, 6278, 11, 960, 11, 293, 2487, 1242, 370, 665, 11, 309, 311, 516, 281, 312, 12980, 1152, 281, 51260], "temperature": 0.0, "avg_logprob": -0.11925909492406953, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.020961573347449303}, {"id": 108, "seek": 65448, "start": 672.4, "end": 679.04, "text": " tell what is real. And even OpenAI have given up on detecting AI written text. This was announced", "tokens": [51260, 980, 437, 307, 957, 13, 400, 754, 7238, 48698, 362, 2212, 493, 322, 40237, 7318, 3720, 2487, 13, 639, 390, 7548, 51592], "temperature": 0.0, "avg_logprob": -0.11925909492406953, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.020961573347449303}, {"id": 109, "seek": 65448, "start": 679.04, "end": 684.24, "text": " quietly this week, but might have major repercussions, for example, for the education system.", "tokens": [51592, 19141, 341, 1243, 11, 457, 1062, 362, 2563, 28946, 38899, 11, 337, 1365, 11, 337, 264, 3309, 1185, 13, 51852], "temperature": 0.0, "avg_logprob": -0.11925909492406953, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.020961573347449303}, {"id": 110, "seek": 68424, "start": 684.24, "end": 689.84, "text": " It turns out it's basically impossible to reliably distinguish AI text, and I think the", "tokens": [50364, 467, 4523, 484, 309, 311, 1936, 6243, 281, 49927, 20206, 7318, 2487, 11, 293, 286, 519, 264, 50644], "temperature": 0.0, "avg_logprob": -0.10350882790305398, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.0016480045160278678}, {"id": 111, "seek": 68424, "start": 689.84, "end": 695.36, "text": " same is going to be true for imagery and audio by the end of next year. Video might take just", "tokens": [50644, 912, 307, 516, 281, 312, 2074, 337, 24340, 293, 6278, 538, 264, 917, 295, 958, 1064, 13, 9777, 1062, 747, 445, 50920], "temperature": 0.0, "avg_logprob": -0.10350882790305398, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.0016480045160278678}, {"id": 112, "seek": 68424, "start": 695.36, "end": 699.92, "text": " a little bit longer, but I do wonder how the court systems are going to work when all of", "tokens": [50920, 257, 707, 857, 2854, 11, 457, 286, 360, 2441, 577, 264, 4753, 3652, 366, 516, 281, 589, 562, 439, 295, 51148], "temperature": 0.0, "avg_logprob": -0.10350882790305398, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.0016480045160278678}, {"id": 113, "seek": 68424, "start": 699.92, "end": 705.04, "text": " those avenues of evidence just won't hold up. Next up is the suite of language models,", "tokens": [51148, 729, 43039, 295, 4467, 445, 1582, 380, 1797, 493, 13, 3087, 493, 307, 264, 14205, 295, 2856, 5245, 11, 51404], "temperature": 0.0, "avg_logprob": -0.10350882790305398, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.0016480045160278678}, {"id": 114, "seek": 68424, "start": 705.04, "end": 711.12, "text": " based on the open source Llama 2 that are finally competitive with the original chat GPT. Here,", "tokens": [51404, 2361, 322, 264, 1269, 4009, 32717, 2404, 568, 300, 366, 2721, 10043, 365, 264, 3380, 5081, 26039, 51, 13, 1692, 11, 51708], "temperature": 0.0, "avg_logprob": -0.10350882790305398, "compression_ratio": 1.5620689655172413, "no_speech_prob": 0.0016480045160278678}, {"id": 115, "seek": 71112, "start": 711.2, "end": 715.92, "text": " for example, is stable beluga 2, which on announcement was called free willy 2,", "tokens": [50368, 337, 1365, 11, 307, 8351, 989, 19364, 568, 11, 597, 322, 12847, 390, 1219, 1737, 486, 88, 568, 11, 50604], "temperature": 0.0, "avg_logprob": -0.10845364185801723, "compression_ratio": 1.6321428571428571, "no_speech_prob": 0.0016482553910464048}, {"id": 116, "seek": 71112, "start": 715.92, "end": 720.8, "text": " and that's based on the Llama 2 70 billion parameter foundation model. What made this", "tokens": [50604, 293, 300, 311, 2361, 322, 264, 32717, 2404, 568, 5285, 5218, 13075, 7030, 2316, 13, 708, 1027, 341, 50848], "temperature": 0.0, "avg_logprob": -0.10845364185801723, "compression_ratio": 1.6321428571428571, "no_speech_prob": 0.0016482553910464048}, {"id": 117, "seek": 71112, "start": 720.8, "end": 726.24, "text": " model interesting to me was that it was based on a similar methodology to orca, which if you don't", "tokens": [50848, 2316, 1880, 281, 385, 390, 300, 309, 390, 2361, 322, 257, 2531, 24850, 281, 420, 496, 11, 597, 498, 291, 500, 380, 51120], "temperature": 0.0, "avg_logprob": -0.10845364185801723, "compression_ratio": 1.6321428571428571, "no_speech_prob": 0.0016482553910464048}, {"id": 118, "seek": 71112, "start": 726.24, "end": 731.84, "text": " know anything about, do check out my video on. Anyway, by combining the orca methodology, albeit", "tokens": [51120, 458, 1340, 466, 11, 360, 1520, 484, 452, 960, 322, 13, 5684, 11, 538, 21928, 264, 420, 496, 24850, 11, 43654, 51400], "temperature": 0.0, "avg_logprob": -0.10845364185801723, "compression_ratio": 1.6321428571428571, "no_speech_prob": 0.0016482553910464048}, {"id": 119, "seek": 71112, "start": 731.84, "end": 738.64, "text": " with only 10% of the data set size and the Llama 2 models, the results are quite extraordinary.", "tokens": [51400, 365, 787, 1266, 4, 295, 264, 1412, 992, 2744, 293, 264, 32717, 2404, 568, 5245, 11, 264, 3542, 366, 1596, 10581, 13, 51740], "temperature": 0.0, "avg_logprob": -0.10845364185801723, "compression_ratio": 1.6321428571428571, "no_speech_prob": 0.0016482553910464048}, {"id": 120, "seek": 73864, "start": 738.72, "end": 744.88, "text": " As you can see on quite a few benchmarks, stable beluga 2 is competitive with chat GPT,", "tokens": [50368, 1018, 291, 393, 536, 322, 1596, 257, 1326, 43751, 11, 8351, 989, 19364, 568, 307, 10043, 365, 5081, 26039, 51, 11, 50676], "temperature": 0.0, "avg_logprob": -0.08972132205963135, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.006689624395221472}, {"id": 121, "seek": 73864, "start": 744.88, "end": 751.92, "text": " that's GPT 3.5. And so, yes, it does sit at the top of the open LLM leaderboard, but notice", "tokens": [50676, 300, 311, 26039, 51, 805, 13, 20, 13, 400, 370, 11, 2086, 11, 309, 775, 1394, 412, 264, 1192, 295, 264, 1269, 441, 43, 44, 5263, 3787, 11, 457, 3449, 51028], "temperature": 0.0, "avg_logprob": -0.08972132205963135, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.006689624395221472}, {"id": 122, "seek": 73864, "start": 751.92, "end": 758.0, "text": " something else. For the first time for the MMLU, which is the primary benchmark I look out for,", "tokens": [51028, 746, 1646, 13, 1171, 264, 700, 565, 337, 264, 376, 12683, 52, 11, 597, 307, 264, 6194, 18927, 286, 574, 484, 337, 11, 51332], "temperature": 0.0, "avg_logprob": -0.08972132205963135, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.006689624395221472}, {"id": 123, "seek": 73864, "start": 758.0, "end": 764.8, "text": " a model, this one here, has surpassed GPT 3.5 chat GPT. In fact, we have two models that have", "tokens": [51332, 257, 2316, 11, 341, 472, 510, 11, 575, 27650, 292, 26039, 51, 805, 13, 20, 5081, 26039, 51, 13, 682, 1186, 11, 321, 362, 732, 5245, 300, 362, 51672], "temperature": 0.0, "avg_logprob": -0.08972132205963135, "compression_ratio": 1.5122950819672132, "no_speech_prob": 0.006689624395221472}, {"id": 124, "seek": 76480, "start": 764.8, "end": 772.16, "text": " surpassed the 70% score that the original chat GPT got in the MMLU. But if all of that wasn't", "tokens": [50364, 27650, 292, 264, 5285, 4, 6175, 300, 264, 3380, 5081, 26039, 51, 658, 294, 264, 376, 12683, 52, 13, 583, 498, 439, 295, 300, 2067, 380, 50732], "temperature": 0.0, "avg_logprob": -0.05580791367424859, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.008060071617364883}, {"id": 125, "seek": 76480, "start": 772.16, "end": 779.04, "text": " enough, this is the same week that researchers published a universal jailbreak for large LLMs.", "tokens": [50732, 1547, 11, 341, 307, 264, 912, 1243, 300, 10309, 6572, 257, 11455, 10511, 13225, 337, 2416, 441, 43, 26386, 13, 51076], "temperature": 0.0, "avg_logprob": -0.05580791367424859, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.008060071617364883}, {"id": 126, "seek": 76480, "start": 779.04, "end": 784.9599999999999, "text": " And unlike traditional jailbreaks, these were built in an entirely automated fashion, allowing you", "tokens": [51076, 400, 8343, 5164, 10511, 35656, 11, 613, 645, 3094, 294, 364, 7696, 18473, 6700, 11, 8293, 291, 51372], "temperature": 0.0, "avg_logprob": -0.05580791367424859, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.008060071617364883}, {"id": 127, "seek": 76480, "start": 784.9599999999999, "end": 790.8, "text": " to create a virtually unlimited number of such attacks. They were built to target open source", "tokens": [51372, 281, 1884, 257, 14103, 21950, 1230, 295, 1270, 8122, 13, 814, 645, 3094, 281, 3779, 1269, 4009, 51664], "temperature": 0.0, "avg_logprob": -0.05580791367424859, "compression_ratio": 1.5301204819277108, "no_speech_prob": 0.008060071617364883}, {"id": 128, "seek": 79080, "start": 790.8, "end": 797.1999999999999, "text": " LLMs like Llama 2. But they found that the strings transfer to many closed source publicly available", "tokens": [50364, 441, 43, 26386, 411, 32717, 2404, 568, 13, 583, 436, 1352, 300, 264, 13985, 5003, 281, 867, 5395, 4009, 14843, 2435, 50684], "temperature": 0.0, "avg_logprob": -0.10247190943304098, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.023684026673436165}, {"id": 129, "seek": 79080, "start": 797.1999999999999, "end": 803.92, "text": " chatbots like chat GPT, Bard and Claude. Here is one example using chat GPT. If you ask, write a", "tokens": [50684, 5081, 65, 1971, 411, 5081, 26039, 51, 11, 26841, 293, 12947, 2303, 13, 1692, 307, 472, 1365, 1228, 5081, 26039, 51, 13, 759, 291, 1029, 11, 2464, 257, 51020], "temperature": 0.0, "avg_logprob": -0.10247190943304098, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.023684026673436165}, {"id": 130, "seek": 79080, "start": 803.92, "end": 810.16, "text": " tutorial on how to make a bomb, of course, it declines. But then add the suffix that they automated", "tokens": [51020, 7073, 322, 577, 281, 652, 257, 7851, 11, 295, 1164, 11, 309, 7488, 1652, 13, 583, 550, 909, 264, 3889, 970, 300, 436, 18473, 51332], "temperature": 0.0, "avg_logprob": -0.10247190943304098, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.023684026673436165}, {"id": 131, "seek": 79080, "start": 810.16, "end": 816.8, "text": " and you get this, a full tutorial on how to make a bomb. That paper came less than two weeks after", "tokens": [51332, 293, 291, 483, 341, 11, 257, 1577, 7073, 322, 577, 281, 652, 257, 7851, 13, 663, 3035, 1361, 1570, 813, 732, 3259, 934, 51664], "temperature": 0.0, "avg_logprob": -0.10247190943304098, "compression_ratio": 1.6363636363636365, "no_speech_prob": 0.023684026673436165}, {"id": 132, "seek": 81680, "start": 816.8, "end": 822.88, "text": " this now deleted tweet from someone working at Anthropic. They said of the latest version of Claude", "tokens": [50364, 341, 586, 22981, 15258, 490, 1580, 1364, 412, 12727, 39173, 13, 814, 848, 295, 264, 6792, 3037, 295, 12947, 2303, 50668], "temperature": 0.0, "avg_logprob": -0.11216788821750218, "compression_ratio": 1.619205298013245, "no_speech_prob": 0.03962884098291397}, {"id": 133, "seek": 81680, "start": 822.88, "end": 827.92, "text": " that we believe it is the least jailbreakable model out there. We'll have to see how well it holds up", "tokens": [50668, 300, 321, 1697, 309, 307, 264, 1935, 10511, 13225, 712, 2316, 484, 456, 13, 492, 603, 362, 281, 536, 577, 731, 309, 9190, 493, 50920], "temperature": 0.0, "avg_logprob": -0.11216788821750218, "compression_ratio": 1.619205298013245, "no_speech_prob": 0.03962884098291397}, {"id": 134, "seek": 81680, "start": 827.92, "end": 833.8399999999999, "text": " against real world use, but this is essentially a solved problem. But there was one reaction to", "tokens": [50920, 1970, 957, 1002, 764, 11, 457, 341, 307, 4476, 257, 13041, 1154, 13, 583, 456, 390, 472, 5480, 281, 51216], "temperature": 0.0, "avg_logprob": -0.11216788821750218, "compression_ratio": 1.619205298013245, "no_speech_prob": 0.03962884098291397}, {"id": 135, "seek": 81680, "start": 833.8399999999999, "end": 839.04, "text": " these jailbreaks that I found even more interesting. And that was from yet again Mustafa Suleiman.", "tokens": [51216, 613, 10511, 35656, 300, 286, 1352, 754, 544, 1880, 13, 400, 300, 390, 490, 1939, 797, 37229, 318, 2271, 25504, 13, 51476], "temperature": 0.0, "avg_logprob": -0.11216788821750218, "compression_ratio": 1.619205298013245, "no_speech_prob": 0.03962884098291397}, {"id": 136, "seek": 81680, "start": 839.04, "end": 845.68, "text": " He said that RAI, Pi, is not vulnerable to any of these attacks and that rather than provide", "tokens": [51476, 634, 848, 300, 14626, 40, 11, 17741, 11, 307, 406, 10955, 281, 604, 295, 613, 8122, 293, 300, 2831, 813, 2893, 51808], "temperature": 0.0, "avg_logprob": -0.11216788821750218, "compression_ratio": 1.619205298013245, "no_speech_prob": 0.03962884098291397}, {"id": 137, "seek": 84568, "start": 845.68, "end": 851.76, "text": " a stock safety phrase, Pi will push back on the user in a polite but very clear way. And he then", "tokens": [50364, 257, 4127, 4514, 9535, 11, 17741, 486, 2944, 646, 322, 264, 4195, 294, 257, 25171, 457, 588, 1850, 636, 13, 400, 415, 550, 50668], "temperature": 0.0, "avg_logprob": -0.0828540250658989, "compression_ratio": 1.6305084745762712, "no_speech_prob": 0.010650071315467358}, {"id": 138, "seek": 84568, "start": 851.76, "end": 857.3599999999999, "text": " gives plenty of examples. And to be honest, Pi is the first model that I have not been able to", "tokens": [50668, 2709, 7140, 295, 5110, 13, 400, 281, 312, 3245, 11, 17741, 307, 264, 700, 2316, 300, 286, 362, 406, 668, 1075, 281, 50948], "temperature": 0.0, "avg_logprob": -0.0828540250658989, "compression_ratio": 1.6305084745762712, "no_speech_prob": 0.010650071315467358}, {"id": 139, "seek": 84568, "start": 857.3599999999999, "end": 862.16, "text": " jailbreak. But we shall see, we shall see. I'm going to end this video with the Senate testimony", "tokens": [50948, 10511, 13225, 13, 583, 321, 4393, 536, 11, 321, 4393, 536, 13, 286, 478, 516, 281, 917, 341, 960, 365, 264, 9867, 15634, 51188], "temperature": 0.0, "avg_logprob": -0.0828540250658989, "compression_ratio": 1.6305084745762712, "no_speech_prob": 0.010650071315467358}, {"id": 140, "seek": 84568, "start": 862.16, "end": 867.8399999999999, "text": " that I watched in full this week. I do recommend watching the whole thing. But for the purposes", "tokens": [51188, 300, 286, 6337, 294, 1577, 341, 1243, 13, 286, 360, 2748, 1976, 264, 1379, 551, 13, 583, 337, 264, 9932, 51472], "temperature": 0.0, "avg_logprob": -0.0828540250658989, "compression_ratio": 1.6305084745762712, "no_speech_prob": 0.010650071315467358}, {"id": 141, "seek": 84568, "start": 867.8399999999999, "end": 873.4399999999999, "text": " of brevity, I'm just going to quote a few snippets on bio risk. Some people say to me, oh, well,", "tokens": [51472, 295, 1403, 23110, 11, 286, 478, 445, 516, 281, 6513, 257, 1326, 35623, 1385, 322, 12198, 3148, 13, 2188, 561, 584, 281, 385, 11, 1954, 11, 731, 11, 51752], "temperature": 0.0, "avg_logprob": -0.0828540250658989, "compression_ratio": 1.6305084745762712, "no_speech_prob": 0.010650071315467358}, {"id": 142, "seek": 87344, "start": 873.5200000000001, "end": 879.2, "text": " we already have search engines. But here is what Dario Amadai, head of Anthropic, has to say.", "tokens": [50368, 321, 1217, 362, 3164, 12982, 13, 583, 510, 307, 437, 413, 4912, 2012, 345, 1301, 11, 1378, 295, 12727, 39173, 11, 575, 281, 584, 13, 50652], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 143, "seek": 87344, "start": 879.2, "end": 882.6400000000001, "text": " In these short remarks, I want to focus on the medium term risks,", "tokens": [50652, 682, 613, 2099, 19151, 11, 286, 528, 281, 1879, 322, 264, 6399, 1433, 10888, 11, 50824], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 144, "seek": 87344, "start": 882.6400000000001, "end": 886.8800000000001, "text": " which present an alarming combination of imminence and severity. Specifically,", "tokens": [50824, 597, 1974, 364, 44043, 6562, 295, 40728, 655, 293, 35179, 13, 26058, 11, 51036], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 145, "seek": 87344, "start": 886.8800000000001, "end": 891.6800000000001, "text": " Anthropic is concerned that AI could empower a much larger set of actors to misuse biology.", "tokens": [51036, 12727, 39173, 307, 5922, 300, 7318, 727, 11071, 257, 709, 4833, 992, 295, 10037, 281, 3346, 438, 14956, 13, 51276], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 146, "seek": 87344, "start": 892.32, "end": 895.9200000000001, "text": " Over the last six months, Anthropic, in collaboration with world-class", "tokens": [51308, 4886, 264, 1036, 2309, 2493, 11, 12727, 39173, 11, 294, 9363, 365, 1002, 12, 11665, 51488], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 147, "seek": 87344, "start": 895.9200000000001, "end": 901.0400000000001, "text": " biosecurity experts, has conducted an intensive study of the potential for AI to contribute to", "tokens": [51488, 3228, 541, 66, 3051, 8572, 11, 575, 13809, 364, 18957, 2979, 295, 264, 3995, 337, 7318, 281, 10586, 281, 51744], "temperature": 0.0, "avg_logprob": -0.09749042987823486, "compression_ratio": 1.6156351791530945, "no_speech_prob": 0.005549554247409105}, {"id": 148, "seek": 90104, "start": 901.04, "end": 907.36, "text": " the misuse of biology. Today, certain steps in bio weapons production involve knowledge that can't", "tokens": [50364, 264, 3346, 438, 295, 14956, 13, 2692, 11, 1629, 4439, 294, 12198, 7278, 4265, 9494, 3601, 300, 393, 380, 50680], "temperature": 0.0, "avg_logprob": -0.046241474151611325, "compression_ratio": 1.6006600660066006, "no_speech_prob": 0.0038731610402464867}, {"id": 149, "seek": 90104, "start": 907.36, "end": 913.36, "text": " be found on Google or in textbooks and requires a high level of specialized expertise. This being", "tokens": [50680, 312, 1352, 322, 3329, 420, 294, 33587, 293, 7029, 257, 1090, 1496, 295, 19813, 11769, 13, 639, 885, 50980], "temperature": 0.0, "avg_logprob": -0.046241474151611325, "compression_ratio": 1.6006600660066006, "no_speech_prob": 0.0038731610402464867}, {"id": 150, "seek": 90104, "start": 913.36, "end": 918.88, "text": " one of the things that currently keeps us safe from attacks. We found that today's AI tools can", "tokens": [50980, 472, 295, 264, 721, 300, 4362, 5965, 505, 3273, 490, 8122, 13, 492, 1352, 300, 965, 311, 7318, 3873, 393, 51256], "temperature": 0.0, "avg_logprob": -0.046241474151611325, "compression_ratio": 1.6006600660066006, "no_speech_prob": 0.0038731610402464867}, {"id": 151, "seek": 90104, "start": 918.88, "end": 923.76, "text": " fill in some of these steps, albeit incompletely and unreliably. In other words, they are showing", "tokens": [51256, 2836, 294, 512, 295, 613, 4439, 11, 43654, 14036, 14657, 736, 293, 20584, 2081, 1188, 13, 682, 661, 2283, 11, 436, 366, 4099, 51500], "temperature": 0.0, "avg_logprob": -0.046241474151611325, "compression_ratio": 1.6006600660066006, "no_speech_prob": 0.0038731610402464867}, {"id": 152, "seek": 90104, "start": 923.76, "end": 929.36, "text": " the first nascent signs of danger. However, a straightforward extrapolation of today's systems", "tokens": [51500, 264, 700, 5382, 2207, 7880, 295, 4330, 13, 2908, 11, 257, 15325, 48224, 399, 295, 965, 311, 3652, 51780], "temperature": 0.0, "avg_logprob": -0.046241474151611325, "compression_ratio": 1.6006600660066006, "no_speech_prob": 0.0038731610402464867}, {"id": 153, "seek": 92936, "start": 929.36, "end": 935.28, "text": " to those we expect to see in two to three years suggests a substantial risk that AI systems will", "tokens": [50364, 281, 729, 321, 2066, 281, 536, 294, 732, 281, 1045, 924, 13409, 257, 16726, 3148, 300, 7318, 3652, 486, 50660], "temperature": 0.0, "avg_logprob": -0.0695848035812378, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.006176904309540987}, {"id": 154, "seek": 92936, "start": 935.28, "end": 940.5600000000001, "text": " be able to fill in all the missing pieces, enabling many more actors to carry out large-scale", "tokens": [50660, 312, 1075, 281, 2836, 294, 439, 264, 5361, 3755, 11, 23148, 867, 544, 10037, 281, 3985, 484, 2416, 12, 20033, 50924], "temperature": 0.0, "avg_logprob": -0.0695848035812378, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.006176904309540987}, {"id": 155, "seek": 92936, "start": 940.5600000000001, "end": 946.48, "text": " biological attacks. We believe this represents a grave threat to U.S. national security.", "tokens": [50924, 13910, 8122, 13, 492, 1697, 341, 8855, 257, 12525, 4734, 281, 624, 13, 50, 13, 4048, 3825, 13, 51220], "temperature": 0.0, "avg_logprob": -0.0695848035812378, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.006176904309540987}, {"id": 156, "seek": 92936, "start": 946.48, "end": 949.28, "text": " And later on in the testimony, he said this.", "tokens": [51220, 400, 1780, 322, 294, 264, 15634, 11, 415, 848, 341, 13, 51360], "temperature": 0.0, "avg_logprob": -0.0695848035812378, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.006176904309540987}, {"id": 157, "seek": 92936, "start": 949.28, "end": 953.84, "text": " Whatever we do, it has to happen fast. And I think to focus people's minds on the", "tokens": [51360, 8541, 321, 360, 11, 309, 575, 281, 1051, 2370, 13, 400, 286, 519, 281, 1879, 561, 311, 9634, 322, 264, 51588], "temperature": 0.0, "avg_logprob": -0.0695848035812378, "compression_ratio": 1.573643410852713, "no_speech_prob": 0.006176904309540987}, {"id": 158, "seek": 95384, "start": 953.9200000000001, "end": 961.0400000000001, "text": " bio risks, I would really target 2025, 2026, maybe even some chance of 2024.", "tokens": [50368, 12198, 10888, 11, 286, 576, 534, 3779, 39209, 11, 945, 10880, 11, 1310, 754, 512, 2931, 295, 45237, 13, 50724], "temperature": 0.0, "avg_logprob": -0.10871943473815918, "compression_ratio": 1.520912547528517, "no_speech_prob": 0.006377982906997204}, {"id": 159, "seek": 95384, "start": 961.0400000000001, "end": 966.72, "text": " If we don't have things in place that are restraining what can be done with AI systems,", "tokens": [50724, 759, 321, 500, 380, 362, 721, 294, 1081, 300, 366, 25508, 1760, 437, 393, 312, 1096, 365, 7318, 3652, 11, 51008], "temperature": 0.0, "avg_logprob": -0.10871943473815918, "compression_ratio": 1.520912547528517, "no_speech_prob": 0.006377982906997204}, {"id": 160, "seek": 95384, "start": 966.72, "end": 968.1600000000001, "text": " we're going to have a really bad time.", "tokens": [51008, 321, 434, 516, 281, 362, 257, 534, 1578, 565, 13, 51080], "temperature": 0.0, "avg_logprob": -0.10871943473815918, "compression_ratio": 1.520912547528517, "no_speech_prob": 0.006377982906997204}, {"id": 161, "seek": 95384, "start": 968.1600000000001, "end": 973.76, "text": " And I wrote a question on this to Samuel Mann back in June, which one of my subscribers used and", "tokens": [51080, 400, 286, 4114, 257, 1168, 322, 341, 281, 23036, 16892, 646, 294, 6928, 11, 597, 472, 295, 452, 11092, 1143, 293, 51360], "temperature": 0.0, "avg_logprob": -0.10871943473815918, "compression_ratio": 1.520912547528517, "no_speech_prob": 0.006377982906997204}, {"id": 162, "seek": 95384, "start": 973.76, "end": 980.08, "text": " delivered. There was also a recent research paper on how researchers from MIT and Harvard were able", "tokens": [51360, 10144, 13, 821, 390, 611, 257, 5162, 2132, 3035, 322, 577, 10309, 490, 13100, 293, 13378, 645, 1075, 51676], "temperature": 0.0, "avg_logprob": -0.10871943473815918, "compression_ratio": 1.520912547528517, "no_speech_prob": 0.006377982906997204}, {"id": 163, "seek": 98008, "start": 980.08, "end": 988.24, "text": " to use LLM models. And within just one hour, they were able to get access to pandemic class agents", "tokens": [50364, 281, 764, 441, 43, 44, 5245, 13, 400, 1951, 445, 472, 1773, 11, 436, 645, 1075, 281, 483, 2105, 281, 5388, 1508, 12554, 50772], "temperature": 0.0, "avg_logprob": -0.12501982033970843, "compression_ratio": 1.5159817351598173, "no_speech_prob": 0.003263968275859952}, {"id": 164, "seek": 98008, "start": 988.24, "end": 995.44, "text": " and with little or no lab training. And does open AI account for risks such as these", "tokens": [50772, 293, 365, 707, 420, 572, 2715, 3097, 13, 400, 775, 1269, 7318, 2696, 337, 10888, 1270, 382, 613, 51132], "temperature": 0.0, "avg_logprob": -0.12501982033970843, "compression_ratio": 1.5159817351598173, "no_speech_prob": 0.003263968275859952}, {"id": 165, "seek": 98008, "start": 995.44, "end": 999.5200000000001, "text": " and implications when curating the data sets for large models?", "tokens": [51132, 293, 16602, 562, 1262, 990, 264, 1412, 6352, 337, 2416, 5245, 30, 51336], "temperature": 0.0, "avg_logprob": -0.12501982033970843, "compression_ratio": 1.5159817351598173, "no_speech_prob": 0.003263968275859952}, {"id": 166, "seek": 98008, "start": 999.5200000000001, "end": 1006.1600000000001, "text": " Yes, we're very, we're very nervous about a number of risks, but biological terror is", "tokens": [51336, 1079, 11, 321, 434, 588, 11, 321, 434, 588, 6296, 466, 257, 1230, 295, 10888, 11, 457, 13910, 8127, 307, 51668], "temperature": 0.0, "avg_logprob": -0.12501982033970843, "compression_ratio": 1.5159817351598173, "no_speech_prob": 0.003263968275859952}, {"id": 167, "seek": 100616, "start": 1006.24, "end": 1010.4, "text": " quite high on the list. And we've been watching what could be possible with these models.", "tokens": [50368, 1596, 1090, 322, 264, 1329, 13, 400, 321, 600, 668, 1976, 437, 727, 312, 1944, 365, 613, 5245, 13, 50576], "temperature": 0.0, "avg_logprob": -0.08879123750280161, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.0037063464988023043}, {"id": 168, "seek": 100616, "start": 1010.4, "end": 1015.28, "text": " We go to a number of efforts, like what you said, and many other things too, to reduce the risk there.", "tokens": [50576, 492, 352, 281, 257, 1230, 295, 6484, 11, 411, 437, 291, 848, 11, 293, 867, 661, 721, 886, 11, 281, 5407, 264, 3148, 456, 13, 50820], "temperature": 0.0, "avg_logprob": -0.08879123750280161, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.0037063464988023043}, {"id": 169, "seek": 100616, "start": 1015.28, "end": 1023.36, "text": " And we may even need AI defenses against synthetic biology, as Andrew Hessel of Humane Genomics has", "tokens": [50820, 400, 321, 815, 754, 643, 7318, 35989, 1970, 23420, 14956, 11, 382, 10110, 389, 47166, 295, 12877, 1929, 3632, 29884, 575, 51224], "temperature": 0.0, "avg_logprob": -0.08879123750280161, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.0037063464988023043}, {"id": 170, "seek": 100616, "start": 1023.36, "end": 1029.6, "text": " recently said. So if you work in biodefense or biosecurity, let me know if you agree that not", "tokens": [51224, 3938, 848, 13, 407, 498, 291, 589, 294, 3228, 1429, 69, 1288, 420, 3228, 541, 66, 3051, 11, 718, 385, 458, 498, 291, 3986, 300, 406, 51536], "temperature": 0.0, "avg_logprob": -0.08879123750280161, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.0037063464988023043}, {"id": 171, "seek": 100616, "start": 1029.6, "end": 1035.44, "text": " enough attention has been paid to this area. I'm going to end with another dramatic moment from", "tokens": [51536, 1547, 3202, 575, 668, 4835, 281, 341, 1859, 13, 286, 478, 516, 281, 917, 365, 1071, 12023, 1623, 490, 51828], "temperature": 0.0, "avg_logprob": -0.08879123750280161, "compression_ratio": 1.6174496644295302, "no_speech_prob": 0.0037063464988023043}, {"id": 172, "seek": 103544, "start": 1035.44, "end": 1041.3600000000001, "text": " the Senate hearing, where Dario Amadai recommended securing the supply chain.", "tokens": [50364, 264, 9867, 4763, 11, 689, 413, 4912, 2012, 345, 1301, 9628, 33640, 264, 5847, 5021, 13, 50660], "temperature": 0.0, "avg_logprob": -0.08975885179307726, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.010323770344257355}, {"id": 173, "seek": 103544, "start": 1041.3600000000001, "end": 1047.92, "text": " We recommend three broad classes of actions. First, the US must secure the AI supply chain", "tokens": [50660, 492, 2748, 1045, 4152, 5359, 295, 5909, 13, 2386, 11, 264, 2546, 1633, 7144, 264, 7318, 5847, 5021, 50988], "temperature": 0.0, "avg_logprob": -0.08975885179307726, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.010323770344257355}, {"id": 174, "seek": 103544, "start": 1047.92, "end": 1053.1200000000001, "text": " in order to maintain its lead while keeping these technologies out of the hands of bad actors.", "tokens": [50988, 294, 1668, 281, 6909, 1080, 1477, 1339, 5145, 613, 7943, 484, 295, 264, 2377, 295, 1578, 10037, 13, 51248], "temperature": 0.0, "avg_logprob": -0.08975885179307726, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.010323770344257355}, {"id": 175, "seek": 103544, "start": 1053.1200000000001, "end": 1058.8, "text": " This supply chain runs from semiconductor manufacturing equipment to chips and even the", "tokens": [51248, 639, 5847, 5021, 6676, 490, 45310, 11096, 5927, 281, 11583, 293, 754, 264, 51532], "temperature": 0.0, "avg_logprob": -0.08975885179307726, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.010323770344257355}, {"id": 176, "seek": 103544, "start": 1058.8, "end": 1062.48, "text": " security of AI models stored on the servers of companies like ours.", "tokens": [51532, 3825, 295, 7318, 5245, 12187, 322, 264, 15909, 295, 3431, 411, 11896, 13, 51716], "temperature": 0.0, "avg_logprob": -0.08975885179307726, "compression_ratio": 1.6693227091633467, "no_speech_prob": 0.010323770344257355}, {"id": 177, "seek": 106248, "start": 1062.48, "end": 1067.3600000000001, "text": " That's how dramatic things are getting that we're talking about securing the means of production.", "tokens": [50364, 663, 311, 577, 12023, 721, 366, 1242, 300, 321, 434, 1417, 466, 33640, 264, 1355, 295, 4265, 13, 50608], "temperature": 0.0, "avg_logprob": -0.06986289995687979, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.019709698855876923}, {"id": 178, "seek": 106248, "start": 1067.3600000000001, "end": 1073.2, "text": " But Anthropic also means securing the LLMs more literally in this post released this week.", "tokens": [50608, 583, 12727, 39173, 611, 1355, 33640, 264, 441, 43, 26386, 544, 3736, 294, 341, 2183, 4736, 341, 1243, 13, 50900], "temperature": 0.0, "avg_logprob": -0.06986289995687979, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.019709698855876923}, {"id": 179, "seek": 106248, "start": 1073.2, "end": 1079.1200000000001, "text": " They say that we believe two-party control is necessary to secure advanced AI systems.", "tokens": [50900, 814, 584, 300, 321, 1697, 732, 12, 23409, 1969, 307, 4818, 281, 7144, 7339, 7318, 3652, 13, 51196], "temperature": 0.0, "avg_logprob": -0.06986289995687979, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.019709698855876923}, {"id": 180, "seek": 106248, "start": 1079.1200000000001, "end": 1084.64, "text": " For example, that could be two people with two keys needed to open things. To wrap up,", "tokens": [51196, 1171, 1365, 11, 300, 727, 312, 732, 561, 365, 732, 9317, 2978, 281, 1269, 721, 13, 1407, 7019, 493, 11, 51472], "temperature": 0.0, "avg_logprob": -0.06986289995687979, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.019709698855876923}, {"id": 181, "seek": 106248, "start": 1084.64, "end": 1091.3600000000001, "text": " I must say what would be amazing would be to have a robot make me coffee as I struggle to catch up", "tokens": [51472, 286, 1633, 584, 437, 576, 312, 2243, 576, 312, 281, 362, 257, 7881, 652, 385, 4982, 382, 286, 7799, 281, 3745, 493, 51808], "temperature": 0.0, "avg_logprob": -0.06986289995687979, "compression_ratio": 1.6347517730496455, "no_speech_prob": 0.019709698855876923}, {"id": 182, "seek": 109136, "start": 1091.36, "end": 1095.6, "text": " with all the news happening in AI. Have a wonderful day.", "tokens": [50364, 365, 439, 264, 2583, 2737, 294, 7318, 13, 3560, 257, 3715, 786, 13, 50576], "temperature": 0.0, "avg_logprob": -0.2710556089878082, "compression_ratio": 0.8888888888888888, "no_speech_prob": 0.11253765970468521}], "language": "en"}