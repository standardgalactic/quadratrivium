{"text": " I just got access to the code interpreter plugin about 48 hours ago and have been running experiments on it non-stop since then. I've come up with about 18 examples to show you guys its power. Most of them I reckon haven't been seen before. I predict many industries will have to update overnight when it's released more widely and at the end of the video please let me know what you think and what other experiments that we can try. First though, what about this one? A 3D surface plot. Just quickly, the way it works is you click this little button to the left of the text box and then you can upload many different file types like CSV files, word files, images and even short videos. Then it will automatically analyze the file type without you pressing anything and then of course you give it a prompt and as with all of chatbt it becomes a conversation. So the first 3d surface plot was decent but it was too small so I simply said in natural language can you make it four times bigger thank you and of course you have seen the amazing end result even with the lighting. Look at these shadows there. I believe this is based on a real contour map of a volcano in New Zealand and I could do a whole video just on this but I have 17 other examples to get to but this one was truly amazing. Did you know for example it can generate QR codes? I said create a QR code that I can scan with my phone to reach the following URL and lo and behold it creates it and yes it does work. Maybe I'm easily impressed but I think that's pretty amazing and what about a 3d scatter plot? This is truly remarkable. I uploaded the data from Gatminder and it created this chart based on the median age of over 100 countries from 1950 I think projected to 2100 and I asked highlight the UK that this is indeed the UK's median age through those years in red but I know what you might be thinking that is amazing that it's 3d and interactive but the blue kind of merges and it's hard to see what's going on. I engaged in a conversation and look what it created. It picked out the 30 most populous countries and separated them off with separate colors. Look at that that is gorgeous. Now you might have the critique that the median age is in descending order in the y-axis going from 20 down to 60 so in a sense the median age is actually rising not falling but nevertheless that's easily amendable and that is truly an incredible diagram and look just for fun I'm going to go into the data look at this I'm traveling into the data this is so wild I don't know how helpful it is but I think that's just beautiful and crazy. There are so many industries data analytics accounting consultancy that this will affect. By the way it got all of this done in about a minute. I see a lot of people online talking about five seconds later is no way done in five seconds you have to wait 30 seconds a minute sometimes much longer before I move on I want to give you a killer tip that it took me quite a while to work out so when you get access try to remember this say output the visualization as a downloadable file if you don't add that phrase as a downloadable file what will happen is it often gets stuck at this stage of the code it'll either say fig dot show or plot dot show and then just stop I found that I encountered this problem far less often if I said output a downloadable file next did you know that code interpreter can do optical character recognition I screenshotted this text from a New York Times article I think it was and I asked OCR the text in this image and write a poem in Danish about it now I don't want to exaggerate it often gets OCR wrong I don't want to get your hopes up it fails more often than it succeeds but when it works it can do it understood the text and then did a poem in Danish about the text now I'm going to need a Danish speaker to tell me if that was a good poem but either way it could do it how about this one it can do interactive time series with range sliders and selectors I uploaded a CSV file on life expectancy data from the entire world and I just said can you pick out the US UK and India and create a time series with range slider and selectors again that killer phrase output a downloadable file and here is what it came up with notice how the life expectancy for all three countries rises during the 20th century and look how I can select down here interactively a range of the data and even by clicking up here a 10-year interval or 50-year interval here's the crazy thing I did nothing I just uploaded the file there were hundreds of countries in there you can see here all the steps that it did and if you click on the arrow you get to see the actual code but then it goes through shows its explanation and eventually gives you a link that you can simply click and get the file downloaded and if you weren't that impressed already here's where it gets fairly game-changing you can get it to do the data analytics not just the visualizations for example I said find five unexpected non-obvious insights from this data and offer plausible explanations for them this was back to the median age data for the most interesting observation provide a compelling and clear visualization now ignore the first diagram which wasn't that good because of the x-axis but look at the insights this is data analytics you can see here that the original file was called median age years and it was just a table of data no analysis whatsoever but look what GPT-4 picked out insight one the global median age has been steadily increasing over time it calculated the global median age that wasn't included in the data it was just country data and it says it's gone from around 22 years to over 38 years in 2023 and it's projected to continue rising to approximately 44 years by 2100 and then it offers a cogent explanation this trend is likely due to a combination of increasing life expectancy and decreasing fertility rates worldwide as medical technology improves more people are living longer birth rates are declining particularly in developed regions it's picked this all out and then it moves on to the next insight the countries that have seen the most significant increases in median age are these ones and again it gives an explanation as to why their median age might have risen more than any other for example Albania has seen significant emigration of younger people which could also lead to an older median age is it me or is that kind of crazy that it crunched all the data visualized it but then also gave really interesting analyses of the data now you can read the other analyses but each of them are really interesting and the final visualization which I asked for is brilliant I think notice how the graph goes from green to red when you get to the future projection I didn't ask it to do that now obviously in this video I'm going to focus on the flashy visuals and the cool little tricks it can do but in terms of data analytics that is what is going to change jobs change industries and remember this is code interpreter alpha version one look at the difference between mid-journey version one and now mid-journey version five a year later how about basic video editing now there is a limit to what it can do but it can do some basic video editing if you ask it for example I uploaded a short file and asked it to rotate the file 180 degrees and it was able to do it now I'm not saying that is massively useful but it was able to do it here is a similar example I uploaded an image file and then said can you zoom out from the center of the image now initially it did zoom in but then I clarified that I wanted it to zoom out from the center just to be cheeky I also asked can you make it black and white oh and I also asked to add music but it couldn't add music anyway here is the end result by the way it gave it to me as an mp4 file and look it zooms out from the center and it's made the image black and white now because I got access so recently I honestly haven't explored the limits of what kind of video editing I can do with chat gpt code interpreter but I will let you know when I can now back to visualizations I gave it a hypothetical scenario that sounds kind of realistic I sent 231 cvs got 32 responses 12 phone interviews three follow-up face-to-face interviews and one job offer which I rejected output a downloadable sanki diagram of this data I did then get it to change the coloring slightly but I think that's a pretty cool sanki diagram look sent cvs 231 and then receive responses and you can go down 32 phone interviews 12 face-to-face interviews and three job offers and one rejected offer obviously I could have tweaked that for hours make it more visual make it more interactive maybe make a gif of it but for two minutes work I think that's a pretty interesting and incredible output next and here is one that you might say is a little bit concerning and it's about steganography now I will admit I am not at all an expert in fact I know virtually nothing about it essentially what it involves though is hiding a message inside an image or inside some code and gpt 4 was more than willing to play along and it encoded a secret message into an image there is the image by the way and if you looked at that you'd think that's totally normal that's just a silly little image right well apparently here's what it can do to a casual observer it looks like a simple image with some shapes but it actually contains the hidden message hello world then it provided a python function which can be used to decode the message from the image now obviously this is just a silly example that is totally harmless but I might be in crazy in thinking this is a somewhat concerning ability for future language models to possess especially when they reach the level of an agi often open ai talk about future versions of gpt doing scientific research and finding things that humans wouldn't have discovered but let me pose the scenario that it gets better than any human expert at steganography anyway enough from me I'll let the experts weigh in on that one next did you know that gpt 4 with code interpreter can do text to speech just before anyone comments though why did I write proceed without further question because gpt 4 with code interpreter has a tendency to always ask clarifying questions and if you have access to only 25 messages every three hours you don't want to use up half or more of them on clarifying what it wants to do or saying yes please do that but I found writing proceed without further question means it gets straight to it and essentially you get double the number of prompts for your money anyway as you can see I asked turn this entire prompt starting from the beginning into a text to speech file now quite a few times it denied it had the ability to do this but eventually I got it to work it was actually when I finally gave it this prompt and it worked I say worked but it didn't quite work as intended check it out here is the text to speech that it came up with you are at gpt a large language model trained by open ai when you send a message containing python code to python it will be executed in a stateful jupiter notebook environment python will respond with the output of the execution or timeout after 120.0 seconds internet access for this session is disabled do not make external web requests or API call must fail now thank you Stephen Hawking for that message the only thing is it had nothing to do with my original prompt now anyway when you get access to code interpreter play about with text to speech because it is able to do it even if it denies it time for a fun one I asked create a tree map of the letters in the following quote and I'm not going to read it out because I am not good at tongue twisters anyway I said give each part of the tree map a different color and output a downloadable file proceed without further question and here is the output and I checked it for the letter p and it was correct that there were 36 instances of the letter p in the output and look how it's proportional with the number of instances of the letter and the size of each rectangle I think that is pretty insane okay back to something more serious I uploaded this file which is an image of a math problem quite a hard one as well and you guessed I said solve the math problem in this image it then extracted the text from the image presumably using OCR and then proceeded to solve it and I'm going to get on to this in a second it is better at math than Wolfram Alpha I know that's a big claim but it's far less buggy I found Wolfram Alpha crashing very frequently anyway here are the two solutions and isn't that incredible from a photo essentially it then extracts out the math problem including the two square roots and then solves it this is all within the same window of chat tpt no need for any other apps or extensions next it can do radial bar plots which I think are really quite beautiful I'm not saying this is the best one ever and I'm sure you could tweak it to make it more clear and beautiful look at that the life expectancy in the US climbing from 1800 and then it goes clockwise reaching a projected almost 90 by 2100 again I'm sure you could do a far better job than me in extracting out a more beautiful diagram but aren't radial bar plots just beautiful to look at speaking of cool diagrams how about this I didn't even specify which visualization to do I uploaded this same life expectancy data and I just said what are the most advanced and technical visualizations you can do with this data proceed to do them now honestly it picks some visualizations that I don't think are the most advanced but nevertheless it was creative here is what it did it does frequently make the mistake of cluttering the axes and having far too many labels so that you can't see anything so scrub that one out not great but what about the next few remember it just did this on its own this is a heat map and you can see some really interesting things from this data like India starting with a much lower life expectancy than anyone else but gradually rising but still falling behind the others even in 2100 and look at China look how the life expectancy drops in the 60s and 70s I think we all know what happened there compare that to the US which is a gradual continual ascent actually aside from 2020 look how the shade gets a little darker in 2020 obviously you guys can probably work out what happened around then but then the projections are for it to go up toward 90 by 2100 that's a beautiful and clear heat map that I didn't even ask for it to do let's look at the next one box plot do you remember those from school you get the upper end of the data the highest one the lowest one the median the first quartile and third quartile and it's a great way of statistically representing a set of data and it's done it for every 50th year starting in 1900 obviously a slightly less beautiful diagram than some of the ones you've seen today but for the statisticians in the audience you will know that this is a very useful metric for a lot of data the individual points above and below are typically when there are outliers in the data I would estimate that all of these visualizations only took around two two and a half minutes so definitely not the 10 seconds as I said that you often see on Twitter I mean have you ever seen GPT-4 give an answer in less than 10 seconds speaking of useful I think many professionals will find the next thing that I'm about to showcase the most useful of all any insights that GPT-4 finds trends medians analyses whatever you can ask it to add to the original file and then download it do you remember that the original file was called median age years well notice this file name median age years with insights it has created a downloadable new file with the insights included and look at some of the insights that I mean you have the change from 1950 to 2100 and here is the average median age throughout the period and the change from 2023 to 2100 notice that the original file didn't have those columns they were added by GPT-4 with code interpreter and now how about data progression video files I was honestly shocked when I saw that it could do this but I asked can you make a 256 by 256 mp4 that gradually reveals the lines as they progress on the x-axis this was about the median age over time here is what it did and look at how the data and the chart progresses as time moves along I was really shocked to see this and the line in red which is going to be labeled at the end is the global median age and remember it calculated that that wasn't in the original file now I'm not sure why it picked out these four countries maybe because they represent extremes but either way I think the result is phenomenal and I'm genuinely impressed that it did this even though I know the final result could be improved dramatically for example far higher resolution and maybe the global median age labeled from the start and actually now that it's got to the end I can see why it did pick out these countries because Niger did have the lowest median age in 2100 and it looks like Puerto Rico had the highest and the fastest aging one was Albania next and this is going to shock quite a few people what about image editing I created this image in mid-journey version five and then here's what I asked I said use opencv to select the foreground of this image and look what it did it picked out the foreground no blue sky now I know it's not perfect but it's nevertheless impressive all within the window of chat bt this does actually make me wonder if open ai and chat bt is eventually not now but in a few years gonna swallow all other apps or maybe google's gemini but either way one interface one website one app doing the job of all others and by the way of course chat bt is now available on ios but imagine you have one app and it can do image editing text to speech video editing everything data analysis not at gpt4 levels but gpt6 or gpt7 levels if you can get every piece of information service and application in one interface a bit like now people being addicted to their smartphones won't people be addicted to this one interface again that's not going to happen now but i'm just posing it as a question to think over for the moment though before anyone gets too carried away it does still hallucinate quite a lot so I uploaded this image and I asked it questions about it and it answered and I was like wow it can do image recognition it said this image appears to be a digital painting of a humanoid figure at a desk with a rather complex background I was initially amazed until I realized that it probably got that from the file name because when I asked it questions it got it wrong so I said what is on the desk now look back there's this weird kind of microphone and a bit of paper and not much else a keyboard and look what it said there are multiple floating holographic displays okay a mouse not really a desk lamp I can't see that and then tools and devices now correct me if I'm wrong but I think most of those are incorrect now obviously I need to do far more experiments to see if it actually can recognize any particular images and maybe I'm putting it down too harshly but at the moment it does seem to hallucinate if you ask it about too much of the detail of an image next you remember how one of the key weaknesses of gt4 is that it can't really count things especially not characters words etc and even more so it can't do division and some of you might be thinking well with wolfram alpha it can do those things not quite here is an example of the code interpreter plugin essentially eating wolfram alpha obviating it making it not obvious what the utility of it is if you've got code interpreter I asked divide the number of the letter e's in this prompt by the number of the letter t's now you might think code interpreter can improve things by doing the character counting but it can also do the division notice how it counted the characters correctly compared to wolfram alpha and of course got the division correct as well so if it can do advanced quadratics and do division and character counting etc it does beg the question what would we use wolfram alpha for that we can't use code interpreter for I honestly might not know something that you guys know so do let me know in the comments it also got this math question correct and notice you get these beautiful math visuals that you don't get with the base version of gpt4 you get something more like this where the visuals aren't as clear and notice the base version of gpt4 gets the question wrong it can't do division but with code interpreter it gets the question right next one is a quick one pie charts nothing too special but I think it is a fairly beautiful visualization it doesn't seem to matter how big the csv file is that you upload this next example was really quite fascinating it was a word puzzle I have tried this particular word puzzle on gpt4 dozens of times the reason I picked this puzzle it's called a word ladder is because it really struggles with the puzzle if the number of steps required is more than a certain number usually about five or six steps it gave me a really interesting border of the limits of gpt4's planning abilities with language anyway it always gets it wrong here is a demonstration with the base model of gpt4 you might say why is this wrong but look at how it's changed from seas to sags which is more than one letter change and that's typical of the kind of errors it makes what about with code interpreter well you can probably guess the ending given that I featured it in the video but it gets it right I believe it draws upon a hard-coded word set and this does point towards the kind of puzzles that I think gpt4 with code interpreter will be able to solve things like crosswords and sedokus okay not exactly world-changing but nevertheless I think quite fascinating and how about Venn diagrams the reason I picked this example is that I had to go through about 10 steps to get it to create this rather basic three-way Venn diagram this represents the overlap between dogs AI and desks and apparently all of them are loyal companions well we will see about that but anyway it took quite a few steps to get it right which is pretty annoying but here's the really interesting thing once I got it set up in the way that I like all I had to do was say use the format above to create a new three-way Venn diagram this time for mangoes movie heroes and marmosets try to make each entry funny and use different colors proceed without further questions so it may have been a struggle to set up initially but once done it was so easy to iterate a new three-way Venn diagram and actually it was better than the original apparently all three are adored by fans worldwide apparently only marmosets and movie heroes can climb up trees really fast and mangoes and marmosets can hang upside down that's crazy one or two prompts iterating on a design already agreed upon this is honestly what is likely to happen in the future with people spending hours to find the perfect data visualization or piece of data analysis and then just hitting copy paste for all their other files perfect it once and then it does the rest for you a quick couple of bonus ones before I finish you can just ask it to come up with a visualization giving it no direction at all it came up with a distribution of prime numbers up to ten thousand thing is I believe there's a slight mistake at the beginning because I think there's only 25 in the first 100 and 21 in the next 100 so you probably do want to still check the outputs that code interpreter gives you and that's another reason it's not going to instantly replace all data analysis and data visualization it's not perfect and it's not fully reliable but you've got to look ahead to where things are going I'm going to end where I started with this insane 3d surface map of a volcano if this is what gpc4 can do now with the alpha version of code interpreter what will gpc5 or 6 do with version 7 or 20 of code interpreter I was about to speculate about that but then I got distracted with trying to get inside this volcano it is kind of fun and look I'm going above and into the volcano let me know what you will try when you get access I know they're rolling it out steadily and I know that some people have had access to it for about three weeks so hopefully if you want to experiment with it you will be able too soon in the meantime do let me know if you have any ideas that you want me to experiment with and thank you so much for watching all the way to the end have a wonderful day", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 4.8, "text": " I just got access to the code interpreter plugin about 48 hours ago and have been running", "tokens": [50364, 286, 445, 658, 2105, 281, 264, 3089, 34132, 23407, 466, 11174, 2496, 2057, 293, 362, 668, 2614, 50604], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 1, "seek": 0, "start": 4.8, "end": 10.0, "text": " experiments on it non-stop since then. I've come up with about 18 examples to show you guys its", "tokens": [50604, 12050, 322, 309, 2107, 12, 13559, 1670, 550, 13, 286, 600, 808, 493, 365, 466, 2443, 5110, 281, 855, 291, 1074, 1080, 50864], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 2, "seek": 0, "start": 10.0, "end": 15.280000000000001, "text": " power. Most of them I reckon haven't been seen before. I predict many industries will have to", "tokens": [50864, 1347, 13, 4534, 295, 552, 286, 29548, 2378, 380, 668, 1612, 949, 13, 286, 6069, 867, 13284, 486, 362, 281, 51128], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 3, "seek": 0, "start": 15.280000000000001, "end": 19.84, "text": " update overnight when it's released more widely and at the end of the video please let me know", "tokens": [51128, 5623, 13935, 562, 309, 311, 4736, 544, 13371, 293, 412, 264, 917, 295, 264, 960, 1767, 718, 385, 458, 51356], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 4, "seek": 0, "start": 19.84, "end": 24.64, "text": " what you think and what other experiments that we can try. First though, what about this one?", "tokens": [51356, 437, 291, 519, 293, 437, 661, 12050, 300, 321, 393, 853, 13, 2386, 1673, 11, 437, 466, 341, 472, 30, 51596], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 5, "seek": 0, "start": 24.64, "end": 29.36, "text": " A 3D surface plot. Just quickly, the way it works is you click this little button to the", "tokens": [51596, 316, 805, 35, 3753, 7542, 13, 1449, 2661, 11, 264, 636, 309, 1985, 307, 291, 2052, 341, 707, 2960, 281, 264, 51832], "temperature": 0.0, "avg_logprob": -0.09315155144024612, "compression_ratio": 1.6098265895953756, "no_speech_prob": 0.0021144829224795103}, {"id": 6, "seek": 2936, "start": 29.36, "end": 35.2, "text": " left of the text box and then you can upload many different file types like CSV files, word files,", "tokens": [50364, 1411, 295, 264, 2487, 2424, 293, 550, 291, 393, 6580, 867, 819, 3991, 3467, 411, 48814, 7098, 11, 1349, 7098, 11, 50656], "temperature": 0.0, "avg_logprob": -0.11641741665926847, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.011328773573040962}, {"id": 7, "seek": 2936, "start": 35.2, "end": 40.4, "text": " images and even short videos. Then it will automatically analyze the file type without", "tokens": [50656, 5267, 293, 754, 2099, 2145, 13, 1396, 309, 486, 6772, 12477, 264, 3991, 2010, 1553, 50916], "temperature": 0.0, "avg_logprob": -0.11641741665926847, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.011328773573040962}, {"id": 8, "seek": 2936, "start": 40.4, "end": 46.56, "text": " you pressing anything and then of course you give it a prompt and as with all of chatbt it becomes a", "tokens": [50916, 291, 12417, 1340, 293, 550, 295, 1164, 291, 976, 309, 257, 12391, 293, 382, 365, 439, 295, 5081, 65, 83, 309, 3643, 257, 51224], "temperature": 0.0, "avg_logprob": -0.11641741665926847, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.011328773573040962}, {"id": 9, "seek": 2936, "start": 46.56, "end": 52.4, "text": " conversation. So the first 3d surface plot was decent but it was too small so I simply said in", "tokens": [51224, 3761, 13, 407, 264, 700, 805, 67, 3753, 7542, 390, 8681, 457, 309, 390, 886, 1359, 370, 286, 2935, 848, 294, 51516], "temperature": 0.0, "avg_logprob": -0.11641741665926847, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.011328773573040962}, {"id": 10, "seek": 2936, "start": 52.4, "end": 56.879999999999995, "text": " natural language can you make it four times bigger thank you and of course you have seen the", "tokens": [51516, 3303, 2856, 393, 291, 652, 309, 1451, 1413, 3801, 1309, 291, 293, 295, 1164, 291, 362, 1612, 264, 51740], "temperature": 0.0, "avg_logprob": -0.11641741665926847, "compression_ratio": 1.674911660777385, "no_speech_prob": 0.011328773573040962}, {"id": 11, "seek": 5688, "start": 56.88, "end": 61.440000000000005, "text": " amazing end result even with the lighting. Look at these shadows there. I believe this is based", "tokens": [50364, 2243, 917, 1874, 754, 365, 264, 9577, 13, 2053, 412, 613, 14740, 456, 13, 286, 1697, 341, 307, 2361, 50592], "temperature": 0.0, "avg_logprob": -0.052159596297700526, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.022971520200371742}, {"id": 12, "seek": 5688, "start": 61.440000000000005, "end": 67.12, "text": " on a real contour map of a volcano in New Zealand and I could do a whole video just on this but I", "tokens": [50592, 322, 257, 957, 21234, 4471, 295, 257, 21979, 294, 1873, 13883, 293, 286, 727, 360, 257, 1379, 960, 445, 322, 341, 457, 286, 50876], "temperature": 0.0, "avg_logprob": -0.052159596297700526, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.022971520200371742}, {"id": 13, "seek": 5688, "start": 67.12, "end": 72.64, "text": " have 17 other examples to get to but this one was truly amazing. Did you know for example it can", "tokens": [50876, 362, 3282, 661, 5110, 281, 483, 281, 457, 341, 472, 390, 4908, 2243, 13, 2589, 291, 458, 337, 1365, 309, 393, 51152], "temperature": 0.0, "avg_logprob": -0.052159596297700526, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.022971520200371742}, {"id": 14, "seek": 5688, "start": 72.64, "end": 78.56, "text": " generate QR codes? I said create a QR code that I can scan with my phone to reach the following URL", "tokens": [51152, 8460, 32784, 14211, 30, 286, 848, 1884, 257, 32784, 3089, 300, 286, 393, 11049, 365, 452, 2593, 281, 2524, 264, 3480, 12905, 51448], "temperature": 0.0, "avg_logprob": -0.052159596297700526, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.022971520200371742}, {"id": 15, "seek": 5688, "start": 78.56, "end": 83.76, "text": " and lo and behold it creates it and yes it does work. Maybe I'm easily impressed but I think", "tokens": [51448, 293, 450, 293, 27234, 309, 7829, 309, 293, 2086, 309, 775, 589, 13, 2704, 286, 478, 3612, 11679, 457, 286, 519, 51708], "temperature": 0.0, "avg_logprob": -0.052159596297700526, "compression_ratio": 1.6153846153846154, "no_speech_prob": 0.022971520200371742}, {"id": 16, "seek": 8376, "start": 83.76, "end": 91.04, "text": " that's pretty amazing and what about a 3d scatter plot? This is truly remarkable. I uploaded the data", "tokens": [50364, 300, 311, 1238, 2243, 293, 437, 466, 257, 805, 67, 34951, 7542, 30, 639, 307, 4908, 12802, 13, 286, 17135, 264, 1412, 50728], "temperature": 0.0, "avg_logprob": -0.09500492497494346, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.04206284135580063}, {"id": 17, "seek": 8376, "start": 91.04, "end": 100.24000000000001, "text": " from Gatminder and it created this chart based on the median age of over 100 countries from 1950 I", "tokens": [50728, 490, 460, 267, 76, 5669, 293, 309, 2942, 341, 6927, 2361, 322, 264, 26779, 3205, 295, 670, 2319, 3517, 490, 18141, 286, 51188], "temperature": 0.0, "avg_logprob": -0.09500492497494346, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.04206284135580063}, {"id": 18, "seek": 8376, "start": 100.24000000000001, "end": 108.56, "text": " think projected to 2100 and I asked highlight the UK that this is indeed the UK's median age", "tokens": [51188, 519, 26231, 281, 5080, 628, 293, 286, 2351, 5078, 264, 7051, 300, 341, 307, 6451, 264, 7051, 311, 26779, 3205, 51604], "temperature": 0.0, "avg_logprob": -0.09500492497494346, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.04206284135580063}, {"id": 19, "seek": 8376, "start": 108.56, "end": 113.36000000000001, "text": " through those years in red but I know what you might be thinking that is amazing that it's 3d", "tokens": [51604, 807, 729, 924, 294, 2182, 457, 286, 458, 437, 291, 1062, 312, 1953, 300, 307, 2243, 300, 309, 311, 805, 67, 51844], "temperature": 0.0, "avg_logprob": -0.09500492497494346, "compression_ratio": 1.5731707317073171, "no_speech_prob": 0.04206284135580063}, {"id": 20, "seek": 11336, "start": 113.44, "end": 118.32, "text": " and interactive but the blue kind of merges and it's hard to see what's going on. I engaged in a", "tokens": [50368, 293, 15141, 457, 264, 3344, 733, 295, 3551, 2880, 293, 309, 311, 1152, 281, 536, 437, 311, 516, 322, 13, 286, 8237, 294, 257, 50612], "temperature": 0.0, "avg_logprob": -0.06380249559879303, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.003272024914622307}, {"id": 21, "seek": 11336, "start": 118.32, "end": 124.56, "text": " conversation and look what it created. It picked out the 30 most populous countries and separated", "tokens": [50612, 3761, 293, 574, 437, 309, 2942, 13, 467, 6183, 484, 264, 2217, 881, 1665, 6893, 3517, 293, 12005, 50924], "temperature": 0.0, "avg_logprob": -0.06380249559879303, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.003272024914622307}, {"id": 22, "seek": 11336, "start": 124.56, "end": 132.07999999999998, "text": " them off with separate colors. Look at that that is gorgeous. Now you might have the critique that the", "tokens": [50924, 552, 766, 365, 4994, 4577, 13, 2053, 412, 300, 300, 307, 12291, 13, 823, 291, 1062, 362, 264, 25673, 300, 264, 51300], "temperature": 0.0, "avg_logprob": -0.06380249559879303, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.003272024914622307}, {"id": 23, "seek": 11336, "start": 132.07999999999998, "end": 139.04, "text": " median age is in descending order in the y-axis going from 20 down to 60 so in a sense the median", "tokens": [51300, 26779, 3205, 307, 294, 40182, 1668, 294, 264, 288, 12, 24633, 516, 490, 945, 760, 281, 4060, 370, 294, 257, 2020, 264, 26779, 51648], "temperature": 0.0, "avg_logprob": -0.06380249559879303, "compression_ratio": 1.6390041493775933, "no_speech_prob": 0.003272024914622307}, {"id": 24, "seek": 13904, "start": 139.04, "end": 144.48, "text": " age is actually rising not falling but nevertheless that's easily amendable and that is truly an", "tokens": [50364, 3205, 307, 767, 11636, 406, 7440, 457, 26924, 300, 311, 3612, 11704, 712, 293, 300, 307, 4908, 364, 50636], "temperature": 0.0, "avg_logprob": -0.07516133785247803, "compression_ratio": 1.6713780918727916, "no_speech_prob": 0.013219905085861683}, {"id": 25, "seek": 13904, "start": 144.48, "end": 149.51999999999998, "text": " incredible diagram and look just for fun I'm going to go into the data look at this I'm traveling", "tokens": [50636, 4651, 10686, 293, 574, 445, 337, 1019, 286, 478, 516, 281, 352, 666, 264, 1412, 574, 412, 341, 286, 478, 9712, 50888], "temperature": 0.0, "avg_logprob": -0.07516133785247803, "compression_ratio": 1.6713780918727916, "no_speech_prob": 0.013219905085861683}, {"id": 26, "seek": 13904, "start": 149.51999999999998, "end": 155.28, "text": " into the data this is so wild I don't know how helpful it is but I think that's just beautiful", "tokens": [50888, 666, 264, 1412, 341, 307, 370, 4868, 286, 500, 380, 458, 577, 4961, 309, 307, 457, 286, 519, 300, 311, 445, 2238, 51176], "temperature": 0.0, "avg_logprob": -0.07516133785247803, "compression_ratio": 1.6713780918727916, "no_speech_prob": 0.013219905085861683}, {"id": 27, "seek": 13904, "start": 156.0, "end": 163.84, "text": " and crazy. There are so many industries data analytics accounting consultancy that this will", "tokens": [51212, 293, 3219, 13, 821, 366, 370, 867, 13284, 1412, 15370, 19163, 7189, 6717, 300, 341, 486, 51604], "temperature": 0.0, "avg_logprob": -0.07516133785247803, "compression_ratio": 1.6713780918727916, "no_speech_prob": 0.013219905085861683}, {"id": 28, "seek": 13904, "start": 163.84, "end": 168.48, "text": " affect. By the way it got all of this done in about a minute. I see a lot of people online", "tokens": [51604, 3345, 13, 3146, 264, 636, 309, 658, 439, 295, 341, 1096, 294, 466, 257, 3456, 13, 286, 536, 257, 688, 295, 561, 2950, 51836], "temperature": 0.0, "avg_logprob": -0.07516133785247803, "compression_ratio": 1.6713780918727916, "no_speech_prob": 0.013219905085861683}, {"id": 29, "seek": 16848, "start": 168.48, "end": 173.84, "text": " talking about five seconds later is no way done in five seconds you have to wait 30 seconds a", "tokens": [50364, 1417, 466, 1732, 3949, 1780, 307, 572, 636, 1096, 294, 1732, 3949, 291, 362, 281, 1699, 2217, 3949, 257, 50632], "temperature": 0.0, "avg_logprob": -0.06584349274635315, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.014950817450881004}, {"id": 30, "seek": 16848, "start": 173.84, "end": 179.12, "text": " minute sometimes much longer before I move on I want to give you a killer tip that it took me", "tokens": [50632, 3456, 2171, 709, 2854, 949, 286, 1286, 322, 286, 528, 281, 976, 291, 257, 13364, 4125, 300, 309, 1890, 385, 50896], "temperature": 0.0, "avg_logprob": -0.06584349274635315, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.014950817450881004}, {"id": 31, "seek": 16848, "start": 179.12, "end": 185.44, "text": " quite a while to work out so when you get access try to remember this say output the visualization", "tokens": [50896, 1596, 257, 1339, 281, 589, 484, 370, 562, 291, 483, 2105, 853, 281, 1604, 341, 584, 5598, 264, 25801, 51212], "temperature": 0.0, "avg_logprob": -0.06584349274635315, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.014950817450881004}, {"id": 32, "seek": 16848, "start": 185.44, "end": 191.51999999999998, "text": " as a downloadable file if you don't add that phrase as a downloadable file what will happen", "tokens": [51212, 382, 257, 5484, 712, 3991, 498, 291, 500, 380, 909, 300, 9535, 382, 257, 5484, 712, 3991, 437, 486, 1051, 51516], "temperature": 0.0, "avg_logprob": -0.06584349274635315, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.014950817450881004}, {"id": 33, "seek": 16848, "start": 191.51999999999998, "end": 197.28, "text": " is it often gets stuck at this stage of the code it'll either say fig dot show or plot dot show", "tokens": [51516, 307, 309, 2049, 2170, 5541, 412, 341, 3233, 295, 264, 3089, 309, 603, 2139, 584, 2147, 5893, 855, 420, 7542, 5893, 855, 51804], "temperature": 0.0, "avg_logprob": -0.06584349274635315, "compression_ratio": 1.7555555555555555, "no_speech_prob": 0.014950817450881004}, {"id": 34, "seek": 19728, "start": 197.28, "end": 202.08, "text": " and then just stop I found that I encountered this problem far less often if I said output a", "tokens": [50364, 293, 550, 445, 1590, 286, 1352, 300, 286, 20381, 341, 1154, 1400, 1570, 2049, 498, 286, 848, 5598, 257, 50604], "temperature": 0.0, "avg_logprob": -0.046588328846713954, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0037067332305014133}, {"id": 35, "seek": 19728, "start": 202.08, "end": 207.84, "text": " downloadable file next did you know that code interpreter can do optical character recognition", "tokens": [50604, 5484, 712, 3991, 958, 630, 291, 458, 300, 3089, 34132, 393, 360, 20674, 2517, 11150, 50892], "temperature": 0.0, "avg_logprob": -0.046588328846713954, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0037067332305014133}, {"id": 36, "seek": 19728, "start": 207.84, "end": 214.08, "text": " I screenshotted this text from a New York Times article I think it was and I asked OCR the text", "tokens": [50892, 286, 11171, 71, 11252, 341, 2487, 490, 257, 1873, 3609, 11366, 7222, 286, 519, 309, 390, 293, 286, 2351, 422, 18547, 264, 2487, 51204], "temperature": 0.0, "avg_logprob": -0.046588328846713954, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0037067332305014133}, {"id": 37, "seek": 19728, "start": 214.08, "end": 221.12, "text": " in this image and write a poem in Danish about it now I don't want to exaggerate it often gets OCR", "tokens": [51204, 294, 341, 3256, 293, 2464, 257, 13065, 294, 36944, 466, 309, 586, 286, 500, 380, 528, 281, 19123, 473, 309, 2049, 2170, 422, 18547, 51556], "temperature": 0.0, "avg_logprob": -0.046588328846713954, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0037067332305014133}, {"id": 38, "seek": 19728, "start": 221.12, "end": 226.4, "text": " wrong I don't want to get your hopes up it fails more often than it succeeds but when it works", "tokens": [51556, 2085, 286, 500, 380, 528, 281, 483, 428, 13681, 493, 309, 18199, 544, 2049, 813, 309, 49263, 457, 562, 309, 1985, 51820], "temperature": 0.0, "avg_logprob": -0.046588328846713954, "compression_ratio": 1.6736842105263159, "no_speech_prob": 0.0037067332305014133}, {"id": 39, "seek": 22640, "start": 226.4, "end": 232.24, "text": " it can do it understood the text and then did a poem in Danish about the text now I'm going to", "tokens": [50364, 309, 393, 360, 309, 7320, 264, 2487, 293, 550, 630, 257, 13065, 294, 36944, 466, 264, 2487, 586, 286, 478, 516, 281, 50656], "temperature": 0.0, "avg_logprob": -0.053875644156273376, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.004197637550532818}, {"id": 40, "seek": 22640, "start": 232.24, "end": 237.12, "text": " need a Danish speaker to tell me if that was a good poem but either way it could do it how about", "tokens": [50656, 643, 257, 36944, 8145, 281, 980, 385, 498, 300, 390, 257, 665, 13065, 457, 2139, 636, 309, 727, 360, 309, 577, 466, 50900], "temperature": 0.0, "avg_logprob": -0.053875644156273376, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.004197637550532818}, {"id": 41, "seek": 22640, "start": 237.12, "end": 244.88, "text": " this one it can do interactive time series with range sliders and selectors I uploaded a CSV file", "tokens": [50900, 341, 472, 309, 393, 360, 15141, 565, 2638, 365, 3613, 1061, 6936, 293, 3048, 830, 286, 17135, 257, 48814, 3991, 51288], "temperature": 0.0, "avg_logprob": -0.053875644156273376, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.004197637550532818}, {"id": 42, "seek": 22640, "start": 244.88, "end": 250.48000000000002, "text": " on life expectancy data from the entire world and I just said can you pick out the US UK and", "tokens": [51288, 322, 993, 42574, 1412, 490, 264, 2302, 1002, 293, 286, 445, 848, 393, 291, 1888, 484, 264, 2546, 7051, 293, 51568], "temperature": 0.0, "avg_logprob": -0.053875644156273376, "compression_ratio": 1.6394849785407726, "no_speech_prob": 0.004197637550532818}, {"id": 43, "seek": 25048, "start": 250.48, "end": 256.71999999999997, "text": " India and create a time series with range slider and selectors again that killer phrase output a", "tokens": [50364, 5282, 293, 1884, 257, 565, 2638, 365, 3613, 26046, 293, 3048, 830, 797, 300, 13364, 9535, 5598, 257, 50676], "temperature": 0.0, "avg_logprob": -0.06109716191011317, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.10370367765426636}, {"id": 44, "seek": 25048, "start": 256.71999999999997, "end": 262.08, "text": " downloadable file and here is what it came up with notice how the life expectancy for all three", "tokens": [50676, 5484, 712, 3991, 293, 510, 307, 437, 309, 1361, 493, 365, 3449, 577, 264, 993, 42574, 337, 439, 1045, 50944], "temperature": 0.0, "avg_logprob": -0.06109716191011317, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.10370367765426636}, {"id": 45, "seek": 25048, "start": 262.08, "end": 268.8, "text": " countries rises during the 20th century and look how I can select down here interactively", "tokens": [50944, 3517, 21373, 1830, 264, 945, 392, 4901, 293, 574, 577, 286, 393, 3048, 760, 510, 4648, 3413, 51280], "temperature": 0.0, "avg_logprob": -0.06109716191011317, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.10370367765426636}, {"id": 46, "seek": 25048, "start": 269.59999999999997, "end": 275.59999999999997, "text": " a range of the data and even by clicking up here a 10-year interval or 50-year interval", "tokens": [51320, 257, 3613, 295, 264, 1412, 293, 754, 538, 9697, 493, 510, 257, 1266, 12, 5294, 15035, 420, 2625, 12, 5294, 15035, 51620], "temperature": 0.0, "avg_logprob": -0.06109716191011317, "compression_ratio": 1.6591928251121075, "no_speech_prob": 0.10370367765426636}, {"id": 47, "seek": 27560, "start": 275.68, "end": 280.72, "text": " here's the crazy thing I did nothing I just uploaded the file there were hundreds of countries in", "tokens": [50368, 510, 311, 264, 3219, 551, 286, 630, 1825, 286, 445, 17135, 264, 3991, 456, 645, 6779, 295, 3517, 294, 50620], "temperature": 0.0, "avg_logprob": -0.04887401735460436, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.21454349160194397}, {"id": 48, "seek": 27560, "start": 280.72, "end": 285.84000000000003, "text": " there you can see here all the steps that it did and if you click on the arrow you get to see the", "tokens": [50620, 456, 291, 393, 536, 510, 439, 264, 4439, 300, 309, 630, 293, 498, 291, 2052, 322, 264, 11610, 291, 483, 281, 536, 264, 50876], "temperature": 0.0, "avg_logprob": -0.04887401735460436, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.21454349160194397}, {"id": 49, "seek": 27560, "start": 285.84000000000003, "end": 291.12, "text": " actual code but then it goes through shows its explanation and eventually gives you a link that", "tokens": [50876, 3539, 3089, 457, 550, 309, 1709, 807, 3110, 1080, 10835, 293, 4728, 2709, 291, 257, 2113, 300, 51140], "temperature": 0.0, "avg_logprob": -0.04887401735460436, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.21454349160194397}, {"id": 50, "seek": 27560, "start": 291.12, "end": 295.76000000000005, "text": " you can simply click and get the file downloaded and if you weren't that impressed already here's", "tokens": [51140, 291, 393, 2935, 2052, 293, 483, 264, 3991, 21748, 293, 498, 291, 4999, 380, 300, 11679, 1217, 510, 311, 51372], "temperature": 0.0, "avg_logprob": -0.04887401735460436, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.21454349160194397}, {"id": 51, "seek": 27560, "start": 295.76000000000005, "end": 301.68, "text": " where it gets fairly game-changing you can get it to do the data analytics not just the visualizations", "tokens": [51372, 689, 309, 2170, 6457, 1216, 12, 27123, 291, 393, 483, 309, 281, 360, 264, 1412, 15370, 406, 445, 264, 5056, 14455, 51668], "temperature": 0.0, "avg_logprob": -0.04887401735460436, "compression_ratio": 1.828996282527881, "no_speech_prob": 0.21454349160194397}, {"id": 52, "seek": 30168, "start": 301.68, "end": 307.68, "text": " for example I said find five unexpected non-obvious insights from this data and offer plausible", "tokens": [50364, 337, 1365, 286, 848, 915, 1732, 13106, 2107, 12, 996, 1502, 14310, 490, 341, 1412, 293, 2626, 39925, 50664], "temperature": 0.0, "avg_logprob": -0.04130984769009127, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02160683646798134}, {"id": 53, "seek": 30168, "start": 307.68, "end": 312.88, "text": " explanations for them this was back to the median age data for the most interesting observation", "tokens": [50664, 28708, 337, 552, 341, 390, 646, 281, 264, 26779, 3205, 1412, 337, 264, 881, 1880, 14816, 50924], "temperature": 0.0, "avg_logprob": -0.04130984769009127, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02160683646798134}, {"id": 54, "seek": 30168, "start": 312.88, "end": 318.64, "text": " provide a compelling and clear visualization now ignore the first diagram which wasn't that good", "tokens": [50924, 2893, 257, 20050, 293, 1850, 25801, 586, 11200, 264, 700, 10686, 597, 2067, 380, 300, 665, 51212], "temperature": 0.0, "avg_logprob": -0.04130984769009127, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02160683646798134}, {"id": 55, "seek": 30168, "start": 318.64, "end": 324.16, "text": " because of the x-axis but look at the insights this is data analytics you can see here that the", "tokens": [51212, 570, 295, 264, 2031, 12, 24633, 457, 574, 412, 264, 14310, 341, 307, 1412, 15370, 291, 393, 536, 510, 300, 264, 51488], "temperature": 0.0, "avg_logprob": -0.04130984769009127, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02160683646798134}, {"id": 56, "seek": 30168, "start": 324.16, "end": 330.64, "text": " original file was called median age years and it was just a table of data no analysis whatsoever", "tokens": [51488, 3380, 3991, 390, 1219, 26779, 3205, 924, 293, 309, 390, 445, 257, 3199, 295, 1412, 572, 5215, 17076, 51812], "temperature": 0.0, "avg_logprob": -0.04130984769009127, "compression_ratio": 1.7427536231884058, "no_speech_prob": 0.02160683646798134}, {"id": 57, "seek": 33064, "start": 330.64, "end": 336.4, "text": " but look what GPT-4 picked out insight one the global median age has been steadily increasing", "tokens": [50364, 457, 574, 437, 26039, 51, 12, 19, 6183, 484, 11269, 472, 264, 4338, 26779, 3205, 575, 668, 36129, 5662, 50652], "temperature": 0.0, "avg_logprob": -0.03930278426235162, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.0005883798003196716}, {"id": 58, "seek": 33064, "start": 336.4, "end": 341.44, "text": " over time it calculated the global median age that wasn't included in the data it was just", "tokens": [50652, 670, 565, 309, 15598, 264, 4338, 26779, 3205, 300, 2067, 380, 5556, 294, 264, 1412, 309, 390, 445, 50904], "temperature": 0.0, "avg_logprob": -0.03930278426235162, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.0005883798003196716}, {"id": 59, "seek": 33064, "start": 341.44, "end": 348.0, "text": " country data and it says it's gone from around 22 years to over 38 years in 2023 and it's projected", "tokens": [50904, 1941, 1412, 293, 309, 1619, 309, 311, 2780, 490, 926, 5853, 924, 281, 670, 12843, 924, 294, 44377, 293, 309, 311, 26231, 51232], "temperature": 0.0, "avg_logprob": -0.03930278426235162, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.0005883798003196716}, {"id": 60, "seek": 33064, "start": 348.0, "end": 354.64, "text": " to continue rising to approximately 44 years by 2100 and then it offers a cogent explanation", "tokens": [51232, 281, 2354, 11636, 281, 10447, 16408, 924, 538, 5080, 628, 293, 550, 309, 7736, 257, 598, 6930, 10835, 51564], "temperature": 0.0, "avg_logprob": -0.03930278426235162, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.0005883798003196716}, {"id": 61, "seek": 33064, "start": 354.64, "end": 359.91999999999996, "text": " this trend is likely due to a combination of increasing life expectancy and decreasing", "tokens": [51564, 341, 6028, 307, 3700, 3462, 281, 257, 6562, 295, 5662, 993, 42574, 293, 23223, 51828], "temperature": 0.0, "avg_logprob": -0.03930278426235162, "compression_ratio": 1.681159420289855, "no_speech_prob": 0.0005883798003196716}, {"id": 62, "seek": 35992, "start": 359.92, "end": 365.2, "text": " fertility rates worldwide as medical technology improves more people are living longer birth rates", "tokens": [50364, 31707, 6846, 13485, 382, 4625, 2899, 24771, 544, 561, 366, 2647, 2854, 3965, 6846, 50628], "temperature": 0.0, "avg_logprob": -0.04000117381413778, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.008576137013733387}, {"id": 63, "seek": 35992, "start": 365.2, "end": 369.28000000000003, "text": " are declining particularly in developed regions it's picked this all out and then it moves on to", "tokens": [50628, 366, 34298, 4098, 294, 4743, 10682, 309, 311, 6183, 341, 439, 484, 293, 550, 309, 6067, 322, 281, 50832], "temperature": 0.0, "avg_logprob": -0.04000117381413778, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.008576137013733387}, {"id": 64, "seek": 35992, "start": 369.28000000000003, "end": 374.32, "text": " the next insight the countries that have seen the most significant increases in median age are these", "tokens": [50832, 264, 958, 11269, 264, 3517, 300, 362, 1612, 264, 881, 4776, 8637, 294, 26779, 3205, 366, 613, 51084], "temperature": 0.0, "avg_logprob": -0.04000117381413778, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.008576137013733387}, {"id": 65, "seek": 35992, "start": 374.32, "end": 379.68, "text": " ones and again it gives an explanation as to why their median age might have risen more than any", "tokens": [51084, 2306, 293, 797, 309, 2709, 364, 10835, 382, 281, 983, 641, 26779, 3205, 1062, 362, 28614, 544, 813, 604, 51352], "temperature": 0.0, "avg_logprob": -0.04000117381413778, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.008576137013733387}, {"id": 66, "seek": 35992, "start": 379.68, "end": 384.8, "text": " other for example Albania has seen significant emigration of younger people which could also", "tokens": [51352, 661, 337, 1365, 41547, 654, 575, 1612, 4776, 846, 36045, 295, 7037, 561, 597, 727, 611, 51608], "temperature": 0.0, "avg_logprob": -0.04000117381413778, "compression_ratio": 1.7545126353790614, "no_speech_prob": 0.008576137013733387}, {"id": 67, "seek": 38480, "start": 384.8, "end": 390.48, "text": " lead to an older median age is it me or is that kind of crazy that it crunched all the data", "tokens": [50364, 1477, 281, 364, 4906, 26779, 3205, 307, 309, 385, 420, 307, 300, 733, 295, 3219, 300, 309, 13386, 292, 439, 264, 1412, 50648], "temperature": 0.0, "avg_logprob": -0.04304154569452459, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.23639240860939026}, {"id": 68, "seek": 38480, "start": 390.48, "end": 396.72, "text": " visualized it but then also gave really interesting analyses of the data now you can read the other", "tokens": [50648, 5056, 1602, 309, 457, 550, 611, 2729, 534, 1880, 37560, 295, 264, 1412, 586, 291, 393, 1401, 264, 661, 50960], "temperature": 0.0, "avg_logprob": -0.04304154569452459, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.23639240860939026}, {"id": 69, "seek": 38480, "start": 396.72, "end": 402.40000000000003, "text": " analyses but each of them are really interesting and the final visualization which I asked for", "tokens": [50960, 37560, 457, 1184, 295, 552, 366, 534, 1880, 293, 264, 2572, 25801, 597, 286, 2351, 337, 51244], "temperature": 0.0, "avg_logprob": -0.04304154569452459, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.23639240860939026}, {"id": 70, "seek": 38480, "start": 402.40000000000003, "end": 407.76, "text": " is brilliant I think notice how the graph goes from green to red when you get to the future", "tokens": [51244, 307, 10248, 286, 519, 3449, 577, 264, 4295, 1709, 490, 3092, 281, 2182, 562, 291, 483, 281, 264, 2027, 51512], "temperature": 0.0, "avg_logprob": -0.04304154569452459, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.23639240860939026}, {"id": 71, "seek": 38480, "start": 407.76, "end": 413.2, "text": " projection I didn't ask it to do that now obviously in this video I'm going to focus on the flashy", "tokens": [51512, 22743, 286, 994, 380, 1029, 309, 281, 360, 300, 586, 2745, 294, 341, 960, 286, 478, 516, 281, 1879, 322, 264, 47873, 51784], "temperature": 0.0, "avg_logprob": -0.04304154569452459, "compression_ratio": 1.7865168539325842, "no_speech_prob": 0.23639240860939026}, {"id": 72, "seek": 41320, "start": 413.2, "end": 418.15999999999997, "text": " visuals and the cool little tricks it can do but in terms of data analytics that is what is going", "tokens": [50364, 26035, 293, 264, 1627, 707, 11733, 309, 393, 360, 457, 294, 2115, 295, 1412, 15370, 300, 307, 437, 307, 516, 50612], "temperature": 0.0, "avg_logprob": -0.05303510459693703, "compression_ratio": 1.8044280442804428, "no_speech_prob": 0.030202703550457954}, {"id": 73, "seek": 41320, "start": 418.15999999999997, "end": 424.32, "text": " to change jobs change industries and remember this is code interpreter alpha version one look at the", "tokens": [50612, 281, 1319, 4782, 1319, 13284, 293, 1604, 341, 307, 3089, 34132, 8961, 3037, 472, 574, 412, 264, 50920], "temperature": 0.0, "avg_logprob": -0.05303510459693703, "compression_ratio": 1.8044280442804428, "no_speech_prob": 0.030202703550457954}, {"id": 74, "seek": 41320, "start": 424.32, "end": 429.59999999999997, "text": " difference between mid-journey version one and now mid-journey version five a year later how about", "tokens": [50920, 2649, 1296, 2062, 12, 8696, 2397, 3037, 472, 293, 586, 2062, 12, 8696, 2397, 3037, 1732, 257, 1064, 1780, 577, 466, 51184], "temperature": 0.0, "avg_logprob": -0.05303510459693703, "compression_ratio": 1.8044280442804428, "no_speech_prob": 0.030202703550457954}, {"id": 75, "seek": 41320, "start": 429.59999999999997, "end": 435.44, "text": " basic video editing now there is a limit to what it can do but it can do some basic video editing", "tokens": [51184, 3875, 960, 10000, 586, 456, 307, 257, 4948, 281, 437, 309, 393, 360, 457, 309, 393, 360, 512, 3875, 960, 10000, 51476], "temperature": 0.0, "avg_logprob": -0.05303510459693703, "compression_ratio": 1.8044280442804428, "no_speech_prob": 0.030202703550457954}, {"id": 76, "seek": 41320, "start": 435.44, "end": 442.24, "text": " if you ask it for example I uploaded a short file and asked it to rotate the file 180 degrees", "tokens": [51476, 498, 291, 1029, 309, 337, 1365, 286, 17135, 257, 2099, 3991, 293, 2351, 309, 281, 13121, 264, 3991, 11971, 5310, 51816], "temperature": 0.0, "avg_logprob": -0.05303510459693703, "compression_ratio": 1.8044280442804428, "no_speech_prob": 0.030202703550457954}, {"id": 77, "seek": 44224, "start": 442.24, "end": 448.32, "text": " and it was able to do it now I'm not saying that is massively useful but it was able to do it here", "tokens": [50364, 293, 309, 390, 1075, 281, 360, 309, 586, 286, 478, 406, 1566, 300, 307, 29379, 4420, 457, 309, 390, 1075, 281, 360, 309, 510, 50668], "temperature": 0.0, "avg_logprob": -0.029709644991942126, "compression_ratio": 1.811926605504587, "no_speech_prob": 0.0023962606210261583}, {"id": 78, "seek": 44224, "start": 448.32, "end": 454.56, "text": " is a similar example I uploaded an image file and then said can you zoom out from the center of the", "tokens": [50668, 307, 257, 2531, 1365, 286, 17135, 364, 3256, 3991, 293, 550, 848, 393, 291, 8863, 484, 490, 264, 3056, 295, 264, 50980], "temperature": 0.0, "avg_logprob": -0.029709644991942126, "compression_ratio": 1.811926605504587, "no_speech_prob": 0.0023962606210261583}, {"id": 79, "seek": 44224, "start": 454.56, "end": 460.0, "text": " image now initially it did zoom in but then I clarified that I wanted it to zoom out from the", "tokens": [50980, 3256, 586, 9105, 309, 630, 8863, 294, 457, 550, 286, 47605, 300, 286, 1415, 309, 281, 8863, 484, 490, 264, 51252], "temperature": 0.0, "avg_logprob": -0.029709644991942126, "compression_ratio": 1.811926605504587, "no_speech_prob": 0.0023962606210261583}, {"id": 80, "seek": 44224, "start": 460.0, "end": 466.32, "text": " center just to be cheeky I also asked can you make it black and white oh and I also asked to add music", "tokens": [51252, 3056, 445, 281, 312, 12839, 88, 286, 611, 2351, 393, 291, 652, 309, 2211, 293, 2418, 1954, 293, 286, 611, 2351, 281, 909, 1318, 51568], "temperature": 0.0, "avg_logprob": -0.029709644991942126, "compression_ratio": 1.811926605504587, "no_speech_prob": 0.0023962606210261583}, {"id": 81, "seek": 46632, "start": 466.32, "end": 473.68, "text": " but it couldn't add music anyway here is the end result by the way it gave it to me as an mp4 file", "tokens": [50364, 457, 309, 2809, 380, 909, 1318, 4033, 510, 307, 264, 917, 1874, 538, 264, 636, 309, 2729, 309, 281, 385, 382, 364, 275, 79, 19, 3991, 50732], "temperature": 0.0, "avg_logprob": -0.05877929263644748, "compression_ratio": 1.615702479338843, "no_speech_prob": 0.08265837281942368}, {"id": 82, "seek": 46632, "start": 473.68, "end": 478.96, "text": " and look it zooms out from the center and it's made the image black and white now because I got", "tokens": [50732, 293, 574, 309, 5721, 4785, 484, 490, 264, 3056, 293, 309, 311, 1027, 264, 3256, 2211, 293, 2418, 586, 570, 286, 658, 50996], "temperature": 0.0, "avg_logprob": -0.05877929263644748, "compression_ratio": 1.615702479338843, "no_speech_prob": 0.08265837281942368}, {"id": 83, "seek": 46632, "start": 478.96, "end": 484.08, "text": " access so recently I honestly haven't explored the limits of what kind of video editing I can do", "tokens": [50996, 2105, 370, 3938, 286, 6095, 2378, 380, 24016, 264, 10406, 295, 437, 733, 295, 960, 10000, 286, 393, 360, 51252], "temperature": 0.0, "avg_logprob": -0.05877929263644748, "compression_ratio": 1.615702479338843, "no_speech_prob": 0.08265837281942368}, {"id": 84, "seek": 46632, "start": 484.08, "end": 489.84, "text": " with chat gpt code interpreter but I will let you know when I can now back to visualizations I gave", "tokens": [51252, 365, 5081, 290, 662, 3089, 34132, 457, 286, 486, 718, 291, 458, 562, 286, 393, 586, 646, 281, 5056, 14455, 286, 2729, 51540], "temperature": 0.0, "avg_logprob": -0.05877929263644748, "compression_ratio": 1.615702479338843, "no_speech_prob": 0.08265837281942368}, {"id": 85, "seek": 48984, "start": 489.84, "end": 497.44, "text": " it a hypothetical scenario that sounds kind of realistic I sent 231 cvs got 32 responses 12 phone", "tokens": [50364, 309, 257, 33053, 9005, 300, 3263, 733, 295, 12465, 286, 2279, 6673, 16, 269, 36959, 658, 8858, 13019, 2272, 2593, 50744], "temperature": 0.0, "avg_logprob": -0.08696060992301778, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.5920114517211914}, {"id": 86, "seek": 48984, "start": 497.44, "end": 503.44, "text": " interviews three follow-up face-to-face interviews and one job offer which I rejected output a", "tokens": [50744, 12318, 1045, 1524, 12, 1010, 1851, 12, 1353, 12, 2868, 12318, 293, 472, 1691, 2626, 597, 286, 15749, 5598, 257, 51044], "temperature": 0.0, "avg_logprob": -0.08696060992301778, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.5920114517211914}, {"id": 87, "seek": 48984, "start": 503.44, "end": 510.32, "text": " downloadable sanki diagram of this data I did then get it to change the coloring slightly but I think", "tokens": [51044, 5484, 712, 262, 27203, 10686, 295, 341, 1412, 286, 630, 550, 483, 309, 281, 1319, 264, 23198, 4748, 457, 286, 519, 51388], "temperature": 0.0, "avg_logprob": -0.08696060992301778, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.5920114517211914}, {"id": 88, "seek": 48984, "start": 510.32, "end": 517.76, "text": " that's a pretty cool sanki diagram look sent cvs 231 and then receive responses and you can go down", "tokens": [51388, 300, 311, 257, 1238, 1627, 262, 27203, 10686, 574, 2279, 269, 36959, 6673, 16, 293, 550, 4774, 13019, 293, 291, 393, 352, 760, 51760], "temperature": 0.0, "avg_logprob": -0.08696060992301778, "compression_ratio": 1.628099173553719, "no_speech_prob": 0.5920114517211914}, {"id": 89, "seek": 51776, "start": 517.84, "end": 524.3199999999999, "text": " 32 phone interviews 12 face-to-face interviews and three job offers and one rejected offer", "tokens": [50368, 8858, 2593, 12318, 2272, 1851, 12, 1353, 12, 2868, 12318, 293, 1045, 1691, 7736, 293, 472, 15749, 2626, 50692], "temperature": 0.0, "avg_logprob": -0.056270912960842925, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.025948956608772278}, {"id": 90, "seek": 51776, "start": 524.3199999999999, "end": 529.28, "text": " obviously I could have tweaked that for hours make it more visual make it more interactive maybe", "tokens": [50692, 2745, 286, 727, 362, 6986, 7301, 300, 337, 2496, 652, 309, 544, 5056, 652, 309, 544, 15141, 1310, 50940], "temperature": 0.0, "avg_logprob": -0.056270912960842925, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.025948956608772278}, {"id": 91, "seek": 51776, "start": 529.28, "end": 534.96, "text": " make a gif of it but for two minutes work I think that's a pretty interesting and incredible output", "tokens": [50940, 652, 257, 290, 351, 295, 309, 457, 337, 732, 2077, 589, 286, 519, 300, 311, 257, 1238, 1880, 293, 4651, 5598, 51224], "temperature": 0.0, "avg_logprob": -0.056270912960842925, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.025948956608772278}, {"id": 92, "seek": 51776, "start": 534.96, "end": 540.8, "text": " next and here is one that you might say is a little bit concerning and it's about steganography", "tokens": [51224, 958, 293, 510, 307, 472, 300, 291, 1062, 584, 307, 257, 707, 857, 18087, 293, 309, 311, 466, 342, 43118, 5820, 51516], "temperature": 0.0, "avg_logprob": -0.056270912960842925, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.025948956608772278}, {"id": 93, "seek": 51776, "start": 540.8, "end": 545.6, "text": " now I will admit I am not at all an expert in fact I know virtually nothing about it essentially what", "tokens": [51516, 586, 286, 486, 9796, 286, 669, 406, 412, 439, 364, 5844, 294, 1186, 286, 458, 14103, 1825, 466, 309, 4476, 437, 51756], "temperature": 0.0, "avg_logprob": -0.056270912960842925, "compression_ratio": 1.7137809187279152, "no_speech_prob": 0.025948956608772278}, {"id": 94, "seek": 54560, "start": 545.6, "end": 551.52, "text": " it involves though is hiding a message inside an image or inside some code and gpt 4 was more", "tokens": [50364, 309, 11626, 1673, 307, 10596, 257, 3636, 1854, 364, 3256, 420, 1854, 512, 3089, 293, 290, 662, 1017, 390, 544, 50660], "temperature": 0.0, "avg_logprob": -0.036906463449651546, "compression_ratio": 1.8120300751879699, "no_speech_prob": 0.00857577845454216}, {"id": 95, "seek": 54560, "start": 551.52, "end": 557.9200000000001, "text": " than willing to play along and it encoded a secret message into an image there is the image by the way", "tokens": [50660, 813, 4950, 281, 862, 2051, 293, 309, 2058, 12340, 257, 4054, 3636, 666, 364, 3256, 456, 307, 264, 3256, 538, 264, 636, 50980], "temperature": 0.0, "avg_logprob": -0.036906463449651546, "compression_ratio": 1.8120300751879699, "no_speech_prob": 0.00857577845454216}, {"id": 96, "seek": 54560, "start": 557.9200000000001, "end": 562.08, "text": " and if you looked at that you'd think that's totally normal that's just a silly little image", "tokens": [50980, 293, 498, 291, 2956, 412, 300, 291, 1116, 519, 300, 311, 3879, 2710, 300, 311, 445, 257, 11774, 707, 3256, 51188], "temperature": 0.0, "avg_logprob": -0.036906463449651546, "compression_ratio": 1.8120300751879699, "no_speech_prob": 0.00857577845454216}, {"id": 97, "seek": 54560, "start": 562.08, "end": 566.32, "text": " right well apparently here's what it can do to a casual observer it looks like a simple image", "tokens": [51188, 558, 731, 7970, 510, 311, 437, 309, 393, 360, 281, 257, 13052, 27878, 309, 1542, 411, 257, 2199, 3256, 51400], "temperature": 0.0, "avg_logprob": -0.036906463449651546, "compression_ratio": 1.8120300751879699, "no_speech_prob": 0.00857577845454216}, {"id": 98, "seek": 54560, "start": 566.32, "end": 572.0, "text": " with some shapes but it actually contains the hidden message hello world then it provided a python", "tokens": [51400, 365, 512, 10854, 457, 309, 767, 8306, 264, 7633, 3636, 7751, 1002, 550, 309, 5649, 257, 38797, 51684], "temperature": 0.0, "avg_logprob": -0.036906463449651546, "compression_ratio": 1.8120300751879699, "no_speech_prob": 0.00857577845454216}, {"id": 99, "seek": 57200, "start": 572.0, "end": 577.92, "text": " function which can be used to decode the message from the image now obviously this is just a silly", "tokens": [50364, 2445, 597, 393, 312, 1143, 281, 979, 1429, 264, 3636, 490, 264, 3256, 586, 2745, 341, 307, 445, 257, 11774, 50660], "temperature": 0.0, "avg_logprob": -0.06780187129974365, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.03208312392234802}, {"id": 100, "seek": 57200, "start": 577.92, "end": 583.04, "text": " example that is totally harmless but I might be in crazy in thinking this is a somewhat concerning", "tokens": [50660, 1365, 300, 307, 3879, 40160, 457, 286, 1062, 312, 294, 3219, 294, 1953, 341, 307, 257, 8344, 18087, 50916], "temperature": 0.0, "avg_logprob": -0.06780187129974365, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.03208312392234802}, {"id": 101, "seek": 57200, "start": 583.04, "end": 588.56, "text": " ability for future language models to possess especially when they reach the level of an agi", "tokens": [50916, 3485, 337, 2027, 2856, 5245, 281, 17490, 2318, 562, 436, 2524, 264, 1496, 295, 364, 623, 72, 51192], "temperature": 0.0, "avg_logprob": -0.06780187129974365, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.03208312392234802}, {"id": 102, "seek": 57200, "start": 588.56, "end": 594.48, "text": " often open ai talk about future versions of gpt doing scientific research and finding things", "tokens": [51192, 2049, 1269, 9783, 751, 466, 2027, 9606, 295, 290, 662, 884, 8134, 2132, 293, 5006, 721, 51488], "temperature": 0.0, "avg_logprob": -0.06780187129974365, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.03208312392234802}, {"id": 103, "seek": 57200, "start": 594.48, "end": 598.96, "text": " that humans wouldn't have discovered but let me pose the scenario that it gets better than", "tokens": [51488, 300, 6255, 2759, 380, 362, 6941, 457, 718, 385, 10774, 264, 9005, 300, 309, 2170, 1101, 813, 51712], "temperature": 0.0, "avg_logprob": -0.06780187129974365, "compression_ratio": 1.686832740213523, "no_speech_prob": 0.03208312392234802}, {"id": 104, "seek": 59896, "start": 598.96, "end": 605.2, "text": " any human expert at steganography anyway enough from me I'll let the experts weigh in on that one", "tokens": [50364, 604, 1952, 5844, 412, 342, 43118, 5820, 4033, 1547, 490, 385, 286, 603, 718, 264, 8572, 13843, 294, 322, 300, 472, 50676], "temperature": 0.0, "avg_logprob": -0.062120651376658474, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.06951512396335602}, {"id": 105, "seek": 59896, "start": 605.2, "end": 611.6800000000001, "text": " next did you know that gpt 4 with code interpreter can do text to speech just before anyone comments", "tokens": [50676, 958, 630, 291, 458, 300, 290, 662, 1017, 365, 3089, 34132, 393, 360, 2487, 281, 6218, 445, 949, 2878, 3053, 51000], "temperature": 0.0, "avg_logprob": -0.062120651376658474, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.06951512396335602}, {"id": 106, "seek": 59896, "start": 611.6800000000001, "end": 617.6800000000001, "text": " though why did I write proceed without further question because gpt 4 with code interpreter has", "tokens": [51000, 1673, 983, 630, 286, 2464, 8991, 1553, 3052, 1168, 570, 290, 662, 1017, 365, 3089, 34132, 575, 51300], "temperature": 0.0, "avg_logprob": -0.062120651376658474, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.06951512396335602}, {"id": 107, "seek": 59896, "start": 617.6800000000001, "end": 623.84, "text": " a tendency to always ask clarifying questions and if you have access to only 25 messages every three", "tokens": [51300, 257, 18187, 281, 1009, 1029, 6093, 5489, 1651, 293, 498, 291, 362, 2105, 281, 787, 3552, 7897, 633, 1045, 51608], "temperature": 0.0, "avg_logprob": -0.062120651376658474, "compression_ratio": 1.6527196652719665, "no_speech_prob": 0.06951512396335602}, {"id": 108, "seek": 62384, "start": 623.84, "end": 629.0400000000001, "text": " hours you don't want to use up half or more of them on clarifying what it wants to do or saying", "tokens": [50364, 2496, 291, 500, 380, 528, 281, 764, 493, 1922, 420, 544, 295, 552, 322, 6093, 5489, 437, 309, 2738, 281, 360, 420, 1566, 50624], "temperature": 0.0, "avg_logprob": -0.040191546353426845, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.182338684797287}, {"id": 109, "seek": 62384, "start": 629.0400000000001, "end": 634.32, "text": " yes please do that but I found writing proceed without further question means it gets straight to", "tokens": [50624, 2086, 1767, 360, 300, 457, 286, 1352, 3579, 8991, 1553, 3052, 1168, 1355, 309, 2170, 2997, 281, 50888], "temperature": 0.0, "avg_logprob": -0.040191546353426845, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.182338684797287}, {"id": 110, "seek": 62384, "start": 634.32, "end": 639.44, "text": " it and essentially you get double the number of prompts for your money anyway as you can see I asked", "tokens": [50888, 309, 293, 4476, 291, 483, 3834, 264, 1230, 295, 41095, 337, 428, 1460, 4033, 382, 291, 393, 536, 286, 2351, 51144], "temperature": 0.0, "avg_logprob": -0.040191546353426845, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.182338684797287}, {"id": 111, "seek": 62384, "start": 639.44, "end": 645.36, "text": " turn this entire prompt starting from the beginning into a text to speech file now quite a few times", "tokens": [51144, 1261, 341, 2302, 12391, 2891, 490, 264, 2863, 666, 257, 2487, 281, 6218, 3991, 586, 1596, 257, 1326, 1413, 51440], "temperature": 0.0, "avg_logprob": -0.040191546353426845, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.182338684797287}, {"id": 112, "seek": 62384, "start": 645.36, "end": 650.48, "text": " it denied it had the ability to do this but eventually I got it to work it was actually", "tokens": [51440, 309, 17774, 309, 632, 264, 3485, 281, 360, 341, 457, 4728, 286, 658, 309, 281, 589, 309, 390, 767, 51696], "temperature": 0.0, "avg_logprob": -0.040191546353426845, "compression_ratio": 1.7374100719424461, "no_speech_prob": 0.182338684797287}, {"id": 113, "seek": 65048, "start": 650.48, "end": 656.72, "text": " when I finally gave it this prompt and it worked I say worked but it didn't quite work as intended", "tokens": [50364, 562, 286, 2721, 2729, 309, 341, 12391, 293, 309, 2732, 286, 584, 2732, 457, 309, 994, 380, 1596, 589, 382, 10226, 50676], "temperature": 0.0, "avg_logprob": -0.08806339470115868, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.12400990724563599}, {"id": 114, "seek": 65048, "start": 656.72, "end": 661.6800000000001, "text": " check it out here is the text to speech that it came up with you are at gpt a large language", "tokens": [50676, 1520, 309, 484, 510, 307, 264, 2487, 281, 6218, 300, 309, 1361, 493, 365, 291, 366, 412, 290, 662, 257, 2416, 2856, 50924], "temperature": 0.0, "avg_logprob": -0.08806339470115868, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.12400990724563599}, {"id": 115, "seek": 65048, "start": 661.6800000000001, "end": 667.04, "text": " model trained by open ai when you send a message containing python code to python it will be executed", "tokens": [50924, 2316, 8895, 538, 1269, 9783, 562, 291, 2845, 257, 3636, 19273, 38797, 3089, 281, 38797, 309, 486, 312, 17577, 51192], "temperature": 0.0, "avg_logprob": -0.08806339470115868, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.12400990724563599}, {"id": 116, "seek": 65048, "start": 667.04, "end": 671.52, "text": " in a stateful jupiter notebook environment python will respond with the output of the execution", "tokens": [51192, 294, 257, 1785, 906, 361, 1010, 1681, 21060, 2823, 38797, 486, 4196, 365, 264, 5598, 295, 264, 15058, 51416], "temperature": 0.0, "avg_logprob": -0.08806339470115868, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.12400990724563599}, {"id": 117, "seek": 65048, "start": 671.52, "end": 677.84, "text": " or timeout after 120.0 seconds internet access for this session is disabled do not make external", "tokens": [51416, 420, 565, 346, 934, 10411, 13, 15, 3949, 4705, 2105, 337, 341, 5481, 307, 15191, 360, 406, 652, 8320, 51732], "temperature": 0.0, "avg_logprob": -0.08806339470115868, "compression_ratio": 1.6816608996539792, "no_speech_prob": 0.12400990724563599}, {"id": 118, "seek": 67784, "start": 678.08, "end": 682.72, "text": " web requests or API call must fail now thank you Stephen Hawking for that message the only thing", "tokens": [50376, 3670, 12475, 420, 9362, 818, 1633, 3061, 586, 1309, 291, 13391, 9325, 5092, 337, 300, 3636, 264, 787, 551, 50608], "temperature": 0.0, "avg_logprob": -0.06921085944542518, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0043298015370965}, {"id": 119, "seek": 67784, "start": 682.72, "end": 687.36, "text": " is it had nothing to do with my original prompt now anyway when you get access to code interpreter", "tokens": [50608, 307, 309, 632, 1825, 281, 360, 365, 452, 3380, 12391, 586, 4033, 562, 291, 483, 2105, 281, 3089, 34132, 50840], "temperature": 0.0, "avg_logprob": -0.06921085944542518, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0043298015370965}, {"id": 120, "seek": 67784, "start": 687.36, "end": 692.8000000000001, "text": " play about with text to speech because it is able to do it even if it denies it time for a fun one", "tokens": [50840, 862, 466, 365, 2487, 281, 6218, 570, 309, 307, 1075, 281, 360, 309, 754, 498, 309, 1441, 530, 309, 565, 337, 257, 1019, 472, 51112], "temperature": 0.0, "avg_logprob": -0.06921085944542518, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0043298015370965}, {"id": 121, "seek": 67784, "start": 692.8000000000001, "end": 697.6, "text": " I asked create a tree map of the letters in the following quote and I'm not going to read it out", "tokens": [51112, 286, 2351, 1884, 257, 4230, 4471, 295, 264, 7825, 294, 264, 3480, 6513, 293, 286, 478, 406, 516, 281, 1401, 309, 484, 51352], "temperature": 0.0, "avg_logprob": -0.06921085944542518, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0043298015370965}, {"id": 122, "seek": 67784, "start": 697.6, "end": 702.5600000000001, "text": " because I am not good at tongue twisters anyway I said give each part of the tree map a different", "tokens": [51352, 570, 286, 669, 406, 665, 412, 10601, 683, 7423, 4033, 286, 848, 976, 1184, 644, 295, 264, 4230, 4471, 257, 819, 51600], "temperature": 0.0, "avg_logprob": -0.06921085944542518, "compression_ratio": 1.7038327526132404, "no_speech_prob": 0.0043298015370965}, {"id": 123, "seek": 70256, "start": 702.56, "end": 708.56, "text": " color and output a downloadable file proceed without further question and here is the output", "tokens": [50364, 2017, 293, 5598, 257, 5484, 712, 3991, 8991, 1553, 3052, 1168, 293, 510, 307, 264, 5598, 50664], "temperature": 0.0, "avg_logprob": -0.052406079428536555, "compression_ratio": 1.8053435114503817, "no_speech_prob": 0.11274953186511993}, {"id": 124, "seek": 70256, "start": 708.56, "end": 714.16, "text": " and I checked it for the letter p and it was correct that there were 36 instances of the letter p", "tokens": [50664, 293, 286, 10033, 309, 337, 264, 5063, 280, 293, 309, 390, 3006, 300, 456, 645, 8652, 14519, 295, 264, 5063, 280, 50944], "temperature": 0.0, "avg_logprob": -0.052406079428536555, "compression_ratio": 1.8053435114503817, "no_speech_prob": 0.11274953186511993}, {"id": 125, "seek": 70256, "start": 714.16, "end": 718.4, "text": " in the output and look how it's proportional with the number of instances of the letter", "tokens": [50944, 294, 264, 5598, 293, 574, 577, 309, 311, 24969, 365, 264, 1230, 295, 14519, 295, 264, 5063, 51156], "temperature": 0.0, "avg_logprob": -0.052406079428536555, "compression_ratio": 1.8053435114503817, "no_speech_prob": 0.11274953186511993}, {"id": 126, "seek": 70256, "start": 718.4, "end": 723.76, "text": " and the size of each rectangle I think that is pretty insane okay back to something more serious", "tokens": [51156, 293, 264, 2744, 295, 1184, 21930, 286, 519, 300, 307, 1238, 10838, 1392, 646, 281, 746, 544, 3156, 51424], "temperature": 0.0, "avg_logprob": -0.052406079428536555, "compression_ratio": 1.8053435114503817, "no_speech_prob": 0.11274953186511993}, {"id": 127, "seek": 70256, "start": 723.76, "end": 729.3599999999999, "text": " I uploaded this file which is an image of a math problem quite a hard one as well and you guessed", "tokens": [51424, 286, 17135, 341, 3991, 597, 307, 364, 3256, 295, 257, 5221, 1154, 1596, 257, 1152, 472, 382, 731, 293, 291, 21852, 51704], "temperature": 0.0, "avg_logprob": -0.052406079428536555, "compression_ratio": 1.8053435114503817, "no_speech_prob": 0.11274953186511993}, {"id": 128, "seek": 72936, "start": 729.84, "end": 734.64, "text": " I said solve the math problem in this image it then extracted the text from the image", "tokens": [50388, 286, 848, 5039, 264, 5221, 1154, 294, 341, 3256, 309, 550, 34086, 264, 2487, 490, 264, 3256, 50628], "temperature": 0.0, "avg_logprob": -0.06903418788203487, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.07582687586545944}, {"id": 129, "seek": 72936, "start": 734.64, "end": 739.92, "text": " presumably using OCR and then proceeded to solve it and I'm going to get on to this in a second", "tokens": [50628, 26742, 1228, 422, 18547, 293, 550, 39053, 281, 5039, 309, 293, 286, 478, 516, 281, 483, 322, 281, 341, 294, 257, 1150, 50892], "temperature": 0.0, "avg_logprob": -0.06903418788203487, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.07582687586545944}, {"id": 130, "seek": 72936, "start": 739.92, "end": 745.28, "text": " it is better at math than Wolfram Alpha I know that's a big claim but it's far less buggy I", "tokens": [50892, 309, 307, 1101, 412, 5221, 813, 16634, 2356, 20588, 286, 458, 300, 311, 257, 955, 3932, 457, 309, 311, 1400, 1570, 7426, 1480, 286, 51160], "temperature": 0.0, "avg_logprob": -0.06903418788203487, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.07582687586545944}, {"id": 131, "seek": 72936, "start": 745.28, "end": 751.04, "text": " found Wolfram Alpha crashing very frequently anyway here are the two solutions and isn't that", "tokens": [51160, 1352, 16634, 2356, 20588, 26900, 588, 10374, 4033, 510, 366, 264, 732, 6547, 293, 1943, 380, 300, 51448], "temperature": 0.0, "avg_logprob": -0.06903418788203487, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.07582687586545944}, {"id": 132, "seek": 72936, "start": 751.04, "end": 756.08, "text": " incredible from a photo essentially it then extracts out the math problem including the two", "tokens": [51448, 4651, 490, 257, 5052, 4476, 309, 550, 8947, 82, 484, 264, 5221, 1154, 3009, 264, 732, 51700], "temperature": 0.0, "avg_logprob": -0.06903418788203487, "compression_ratio": 1.751908396946565, "no_speech_prob": 0.07582687586545944}, {"id": 133, "seek": 75608, "start": 756.08, "end": 761.9200000000001, "text": " square roots and then solves it this is all within the same window of chat tpt no need for any other", "tokens": [50364, 3732, 10669, 293, 550, 39890, 309, 341, 307, 439, 1951, 264, 912, 4910, 295, 5081, 256, 662, 572, 643, 337, 604, 661, 50656], "temperature": 0.0, "avg_logprob": -0.07104327989661176, "compression_ratio": 1.6609589041095891, "no_speech_prob": 0.05498482659459114}, {"id": 134, "seek": 75608, "start": 761.9200000000001, "end": 767.84, "text": " apps or extensions next it can do radial bar plots which I think are really quite beautiful I'm not", "tokens": [50656, 7733, 420, 25129, 958, 309, 393, 360, 38783, 2159, 28609, 597, 286, 519, 366, 534, 1596, 2238, 286, 478, 406, 50952], "temperature": 0.0, "avg_logprob": -0.07104327989661176, "compression_ratio": 1.6609589041095891, "no_speech_prob": 0.05498482659459114}, {"id": 135, "seek": 75608, "start": 767.84, "end": 772.64, "text": " saying this is the best one ever and I'm sure you could tweak it to make it more clear and beautiful", "tokens": [50952, 1566, 341, 307, 264, 1151, 472, 1562, 293, 286, 478, 988, 291, 727, 29879, 309, 281, 652, 309, 544, 1850, 293, 2238, 51192], "temperature": 0.0, "avg_logprob": -0.07104327989661176, "compression_ratio": 1.6609589041095891, "no_speech_prob": 0.05498482659459114}, {"id": 136, "seek": 75608, "start": 772.64, "end": 778.72, "text": " look at that the life expectancy in the US climbing from 1800 and then it goes clockwise", "tokens": [51192, 574, 412, 300, 264, 993, 42574, 294, 264, 2546, 14780, 490, 24327, 293, 550, 309, 1709, 35790, 51496], "temperature": 0.0, "avg_logprob": -0.07104327989661176, "compression_ratio": 1.6609589041095891, "no_speech_prob": 0.05498482659459114}, {"id": 137, "seek": 75608, "start": 778.72, "end": 785.2800000000001, "text": " reaching a projected almost 90 by 2100 again I'm sure you could do a far better job than me in", "tokens": [51496, 9906, 257, 26231, 1920, 4289, 538, 5080, 628, 797, 286, 478, 988, 291, 727, 360, 257, 1400, 1101, 1691, 813, 385, 294, 51824], "temperature": 0.0, "avg_logprob": -0.07104327989661176, "compression_ratio": 1.6609589041095891, "no_speech_prob": 0.05498482659459114}, {"id": 138, "seek": 78528, "start": 785.28, "end": 790.48, "text": " extracting out a more beautiful diagram but aren't radial bar plots just beautiful to look at", "tokens": [50364, 49844, 484, 257, 544, 2238, 10686, 457, 3212, 380, 38783, 2159, 28609, 445, 2238, 281, 574, 412, 50624], "temperature": 0.0, "avg_logprob": -0.0352173218360314, "compression_ratio": 1.8168498168498168, "no_speech_prob": 0.0023229371290653944}, {"id": 139, "seek": 78528, "start": 790.48, "end": 796.0, "text": " speaking of cool diagrams how about this I didn't even specify which visualization to do I uploaded", "tokens": [50624, 4124, 295, 1627, 36709, 577, 466, 341, 286, 994, 380, 754, 16500, 597, 25801, 281, 360, 286, 17135, 50900], "temperature": 0.0, "avg_logprob": -0.0352173218360314, "compression_ratio": 1.8168498168498168, "no_speech_prob": 0.0023229371290653944}, {"id": 140, "seek": 78528, "start": 796.0, "end": 802.0, "text": " this same life expectancy data and I just said what are the most advanced and technical visualizations", "tokens": [50900, 341, 912, 993, 42574, 1412, 293, 286, 445, 848, 437, 366, 264, 881, 7339, 293, 6191, 5056, 14455, 51200], "temperature": 0.0, "avg_logprob": -0.0352173218360314, "compression_ratio": 1.8168498168498168, "no_speech_prob": 0.0023229371290653944}, {"id": 141, "seek": 78528, "start": 802.0, "end": 806.88, "text": " you can do with this data proceed to do them now honestly it picks some visualizations that I don't", "tokens": [51200, 291, 393, 360, 365, 341, 1412, 8991, 281, 360, 552, 586, 6095, 309, 16137, 512, 5056, 14455, 300, 286, 500, 380, 51444], "temperature": 0.0, "avg_logprob": -0.0352173218360314, "compression_ratio": 1.8168498168498168, "no_speech_prob": 0.0023229371290653944}, {"id": 142, "seek": 78528, "start": 806.88, "end": 812.8, "text": " think are the most advanced but nevertheless it was creative here is what it did it does frequently", "tokens": [51444, 519, 366, 264, 881, 7339, 457, 26924, 309, 390, 5880, 510, 307, 437, 309, 630, 309, 775, 10374, 51740], "temperature": 0.0, "avg_logprob": -0.0352173218360314, "compression_ratio": 1.8168498168498168, "no_speech_prob": 0.0023229371290653944}, {"id": 143, "seek": 81280, "start": 812.8, "end": 818.4799999999999, "text": " make the mistake of cluttering the axes and having far too many labels so that you can't see anything", "tokens": [50364, 652, 264, 6146, 295, 596, 32224, 264, 35387, 293, 1419, 1400, 886, 867, 16949, 370, 300, 291, 393, 380, 536, 1340, 50648], "temperature": 0.0, "avg_logprob": -0.040600247816606004, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.035134851932525635}, {"id": 144, "seek": 81280, "start": 818.4799999999999, "end": 823.52, "text": " so scrub that one out not great but what about the next few remember it just did this on its own", "tokens": [50648, 370, 24163, 300, 472, 484, 406, 869, 457, 437, 466, 264, 958, 1326, 1604, 309, 445, 630, 341, 322, 1080, 1065, 50900], "temperature": 0.0, "avg_logprob": -0.040600247816606004, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.035134851932525635}, {"id": 145, "seek": 81280, "start": 823.52, "end": 828.64, "text": " this is a heat map and you can see some really interesting things from this data like India", "tokens": [50900, 341, 307, 257, 3738, 4471, 293, 291, 393, 536, 512, 534, 1880, 721, 490, 341, 1412, 411, 5282, 51156], "temperature": 0.0, "avg_logprob": -0.040600247816606004, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.035134851932525635}, {"id": 146, "seek": 81280, "start": 828.64, "end": 833.8399999999999, "text": " starting with a much lower life expectancy than anyone else but gradually rising but still falling", "tokens": [51156, 2891, 365, 257, 709, 3126, 993, 42574, 813, 2878, 1646, 457, 13145, 11636, 457, 920, 7440, 51416], "temperature": 0.0, "avg_logprob": -0.040600247816606004, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.035134851932525635}, {"id": 147, "seek": 81280, "start": 833.8399999999999, "end": 841.1999999999999, "text": " behind the others even in 2100 and look at China look how the life expectancy drops in the 60s and", "tokens": [51416, 2261, 264, 2357, 754, 294, 5080, 628, 293, 574, 412, 3533, 574, 577, 264, 993, 42574, 11438, 294, 264, 4060, 82, 293, 51784], "temperature": 0.0, "avg_logprob": -0.040600247816606004, "compression_ratio": 1.7183098591549295, "no_speech_prob": 0.035134851932525635}, {"id": 148, "seek": 84120, "start": 841.2800000000001, "end": 846.24, "text": " 70s I think we all know what happened there compare that to the US which is a gradual", "tokens": [50368, 5285, 82, 286, 519, 321, 439, 458, 437, 2011, 456, 6794, 300, 281, 264, 2546, 597, 307, 257, 32890, 50616], "temperature": 0.0, "avg_logprob": -0.04993399199064787, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.029296983033418655}, {"id": 149, "seek": 84120, "start": 846.24, "end": 853.6800000000001, "text": " continual ascent actually aside from 2020 look how the shade gets a little darker in 2020 obviously", "tokens": [50616, 1421, 901, 382, 2207, 767, 7359, 490, 4808, 574, 577, 264, 11466, 2170, 257, 707, 12741, 294, 4808, 2745, 50988], "temperature": 0.0, "avg_logprob": -0.04993399199064787, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.029296983033418655}, {"id": 150, "seek": 84120, "start": 853.6800000000001, "end": 858.0, "text": " you guys can probably work out what happened around then but then the projections are for", "tokens": [50988, 291, 1074, 393, 1391, 589, 484, 437, 2011, 926, 550, 457, 550, 264, 32371, 366, 337, 51204], "temperature": 0.0, "avg_logprob": -0.04993399199064787, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.029296983033418655}, {"id": 151, "seek": 84120, "start": 858.0, "end": 864.24, "text": " it to go up toward 90 by 2100 that's a beautiful and clear heat map that I didn't even ask for", "tokens": [51204, 309, 281, 352, 493, 7361, 4289, 538, 5080, 628, 300, 311, 257, 2238, 293, 1850, 3738, 4471, 300, 286, 994, 380, 754, 1029, 337, 51516], "temperature": 0.0, "avg_logprob": -0.04993399199064787, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.029296983033418655}, {"id": 152, "seek": 84120, "start": 864.24, "end": 869.0400000000001, "text": " it to do let's look at the next one box plot do you remember those from school you get the", "tokens": [51516, 309, 281, 360, 718, 311, 574, 412, 264, 958, 472, 2424, 7542, 360, 291, 1604, 729, 490, 1395, 291, 483, 264, 51756], "temperature": 0.0, "avg_logprob": -0.04993399199064787, "compression_ratio": 1.6464285714285714, "no_speech_prob": 0.029296983033418655}, {"id": 153, "seek": 86904, "start": 869.04, "end": 874.88, "text": " upper end of the data the highest one the lowest one the median the first quartile and third quartile", "tokens": [50364, 6597, 917, 295, 264, 1412, 264, 6343, 472, 264, 12437, 472, 264, 26779, 264, 700, 20837, 794, 293, 2636, 20837, 794, 50656], "temperature": 0.0, "avg_logprob": -0.022661847096902353, "compression_ratio": 1.7740740740740741, "no_speech_prob": 0.02032831870019436}, {"id": 154, "seek": 86904, "start": 874.88, "end": 880.3199999999999, "text": " and it's a great way of statistically representing a set of data and it's done it for every 50th", "tokens": [50656, 293, 309, 311, 257, 869, 636, 295, 36478, 13460, 257, 992, 295, 1412, 293, 309, 311, 1096, 309, 337, 633, 2625, 392, 50928], "temperature": 0.0, "avg_logprob": -0.022661847096902353, "compression_ratio": 1.7740740740740741, "no_speech_prob": 0.02032831870019436}, {"id": 155, "seek": 86904, "start": 880.3199999999999, "end": 885.92, "text": " year starting in 1900 obviously a slightly less beautiful diagram than some of the ones you've", "tokens": [50928, 1064, 2891, 294, 28898, 2745, 257, 4748, 1570, 2238, 10686, 813, 512, 295, 264, 2306, 291, 600, 51208], "temperature": 0.0, "avg_logprob": -0.022661847096902353, "compression_ratio": 1.7740740740740741, "no_speech_prob": 0.02032831870019436}, {"id": 156, "seek": 86904, "start": 885.92, "end": 891.28, "text": " seen today but for the statisticians in the audience you will know that this is a very useful", "tokens": [51208, 1612, 965, 457, 337, 264, 29588, 2567, 294, 264, 4034, 291, 486, 458, 300, 341, 307, 257, 588, 4420, 51476], "temperature": 0.0, "avg_logprob": -0.022661847096902353, "compression_ratio": 1.7740740740740741, "no_speech_prob": 0.02032831870019436}, {"id": 157, "seek": 86904, "start": 891.28, "end": 896.7199999999999, "text": " metric for a lot of data the individual points above and below are typically when there are", "tokens": [51476, 20678, 337, 257, 688, 295, 1412, 264, 2609, 2793, 3673, 293, 2507, 366, 5850, 562, 456, 366, 51748], "temperature": 0.0, "avg_logprob": -0.022661847096902353, "compression_ratio": 1.7740740740740741, "no_speech_prob": 0.02032831870019436}, {"id": 158, "seek": 89672, "start": 896.72, "end": 902.4, "text": " outliers in the data I would estimate that all of these visualizations only took around", "tokens": [50364, 484, 23646, 294, 264, 1412, 286, 576, 12539, 300, 439, 295, 613, 5056, 14455, 787, 1890, 926, 50648], "temperature": 0.0, "avg_logprob": -0.06072446941274457, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.05832323059439659}, {"id": 159, "seek": 89672, "start": 902.4, "end": 907.9200000000001, "text": " two two and a half minutes so definitely not the 10 seconds as I said that you often see on Twitter", "tokens": [50648, 732, 732, 293, 257, 1922, 2077, 370, 2138, 406, 264, 1266, 3949, 382, 286, 848, 300, 291, 2049, 536, 322, 5794, 50924], "temperature": 0.0, "avg_logprob": -0.06072446941274457, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.05832323059439659}, {"id": 160, "seek": 89672, "start": 907.9200000000001, "end": 913.12, "text": " I mean have you ever seen GPT-4 give an answer in less than 10 seconds speaking of useful I think", "tokens": [50924, 286, 914, 362, 291, 1562, 1612, 26039, 51, 12, 19, 976, 364, 1867, 294, 1570, 813, 1266, 3949, 4124, 295, 4420, 286, 519, 51184], "temperature": 0.0, "avg_logprob": -0.06072446941274457, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.05832323059439659}, {"id": 161, "seek": 89672, "start": 913.12, "end": 918.5600000000001, "text": " many professionals will find the next thing that I'm about to showcase the most useful of all any", "tokens": [51184, 867, 11954, 486, 915, 264, 958, 551, 300, 286, 478, 466, 281, 20388, 264, 881, 4420, 295, 439, 604, 51456], "temperature": 0.0, "avg_logprob": -0.06072446941274457, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.05832323059439659}, {"id": 162, "seek": 89672, "start": 918.5600000000001, "end": 925.44, "text": " insights that GPT-4 finds trends medians analyses whatever you can ask it to add to the original", "tokens": [51456, 14310, 300, 26039, 51, 12, 19, 10704, 13892, 1205, 2567, 37560, 2035, 291, 393, 1029, 309, 281, 909, 281, 264, 3380, 51800], "temperature": 0.0, "avg_logprob": -0.06072446941274457, "compression_ratio": 1.6666666666666667, "no_speech_prob": 0.05832323059439659}, {"id": 163, "seek": 92544, "start": 925.44, "end": 931.2, "text": " file and then download it do you remember that the original file was called median age years well", "tokens": [50364, 3991, 293, 550, 5484, 309, 360, 291, 1604, 300, 264, 3380, 3991, 390, 1219, 26779, 3205, 924, 731, 50652], "temperature": 0.0, "avg_logprob": -0.04617276823664286, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.06006382033228874}, {"id": 164, "seek": 92544, "start": 931.2, "end": 938.0, "text": " notice this file name median age years with insights it has created a downloadable new file", "tokens": [50652, 3449, 341, 3991, 1315, 26779, 3205, 924, 365, 14310, 309, 575, 2942, 257, 5484, 712, 777, 3991, 50992], "temperature": 0.0, "avg_logprob": -0.04617276823664286, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.06006382033228874}, {"id": 165, "seek": 92544, "start": 938.0, "end": 944.08, "text": " with the insights included and look at some of the insights that I mean you have the change from", "tokens": [50992, 365, 264, 14310, 5556, 293, 574, 412, 512, 295, 264, 14310, 300, 286, 914, 291, 362, 264, 1319, 490, 51296], "temperature": 0.0, "avg_logprob": -0.04617276823664286, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.06006382033228874}, {"id": 166, "seek": 92544, "start": 944.08, "end": 952.1600000000001, "text": " 1950 to 2100 and here is the average median age throughout the period and the change from 2023", "tokens": [51296, 18141, 281, 5080, 628, 293, 510, 307, 264, 4274, 26779, 3205, 3710, 264, 2896, 293, 264, 1319, 490, 44377, 51700], "temperature": 0.0, "avg_logprob": -0.04617276823664286, "compression_ratio": 1.7887323943661972, "no_speech_prob": 0.06006382033228874}, {"id": 167, "seek": 95216, "start": 952.24, "end": 958.16, "text": " to 2100 notice that the original file didn't have those columns they were added by GPT-4", "tokens": [50368, 281, 5080, 628, 3449, 300, 264, 3380, 3991, 994, 380, 362, 729, 13766, 436, 645, 3869, 538, 26039, 51, 12, 19, 50664], "temperature": 0.0, "avg_logprob": -0.06486666074363134, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.04466579854488373}, {"id": 168, "seek": 95216, "start": 958.16, "end": 963.4399999999999, "text": " with code interpreter and now how about data progression video files I was honestly shocked", "tokens": [50664, 365, 3089, 34132, 293, 586, 577, 466, 1412, 18733, 960, 7098, 286, 390, 6095, 12763, 50928], "temperature": 0.0, "avg_logprob": -0.06486666074363134, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.04466579854488373}, {"id": 169, "seek": 95216, "start": 963.4399999999999, "end": 970.16, "text": " when I saw that it could do this but I asked can you make a 256 by 256 mp4 that gradually reveals", "tokens": [50928, 562, 286, 1866, 300, 309, 727, 360, 341, 457, 286, 2351, 393, 291, 652, 257, 38882, 538, 38882, 275, 79, 19, 300, 13145, 20893, 51264], "temperature": 0.0, "avg_logprob": -0.06486666074363134, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.04466579854488373}, {"id": 170, "seek": 95216, "start": 970.16, "end": 976.16, "text": " the lines as they progress on the x-axis this was about the median age over time here is what it did", "tokens": [51264, 264, 3876, 382, 436, 4205, 322, 264, 2031, 12, 24633, 341, 390, 466, 264, 26779, 3205, 670, 565, 510, 307, 437, 309, 630, 51564], "temperature": 0.0, "avg_logprob": -0.06486666074363134, "compression_ratio": 1.546938775510204, "no_speech_prob": 0.04466579854488373}, {"id": 171, "seek": 97616, "start": 976.16, "end": 983.68, "text": " and look at how the data and the chart progresses as time moves along I was really shocked to see this", "tokens": [50364, 293, 574, 412, 577, 264, 1412, 293, 264, 6927, 41929, 382, 565, 6067, 2051, 286, 390, 534, 12763, 281, 536, 341, 50740], "temperature": 0.0, "avg_logprob": -0.03766472231258045, "compression_ratio": 1.6348547717842323, "no_speech_prob": 0.002980816410854459}, {"id": 172, "seek": 97616, "start": 983.68, "end": 990.4, "text": " and the line in red which is going to be labeled at the end is the global median age and remember", "tokens": [50740, 293, 264, 1622, 294, 2182, 597, 307, 516, 281, 312, 21335, 412, 264, 917, 307, 264, 4338, 26779, 3205, 293, 1604, 51076], "temperature": 0.0, "avg_logprob": -0.03766472231258045, "compression_ratio": 1.6348547717842323, "no_speech_prob": 0.002980816410854459}, {"id": 173, "seek": 97616, "start": 990.4, "end": 995.52, "text": " it calculated that that wasn't in the original file now I'm not sure why it picked out these four", "tokens": [51076, 309, 15598, 300, 300, 2067, 380, 294, 264, 3380, 3991, 586, 286, 478, 406, 988, 983, 309, 6183, 484, 613, 1451, 51332], "temperature": 0.0, "avg_logprob": -0.03766472231258045, "compression_ratio": 1.6348547717842323, "no_speech_prob": 0.002980816410854459}, {"id": 174, "seek": 97616, "start": 995.52, "end": 1002.48, "text": " countries maybe because they represent extremes but either way I think the result is phenomenal", "tokens": [51332, 3517, 1310, 570, 436, 2906, 41119, 457, 2139, 636, 286, 519, 264, 1874, 307, 17778, 51680], "temperature": 0.0, "avg_logprob": -0.03766472231258045, "compression_ratio": 1.6348547717842323, "no_speech_prob": 0.002980816410854459}, {"id": 175, "seek": 100248, "start": 1002.48, "end": 1008.8000000000001, "text": " and I'm genuinely impressed that it did this even though I know the final result could be improved", "tokens": [50364, 293, 286, 478, 17839, 11679, 300, 309, 630, 341, 754, 1673, 286, 458, 264, 2572, 1874, 727, 312, 9689, 50680], "temperature": 0.0, "avg_logprob": -0.04910822634427053, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.0030751076992601156}, {"id": 176, "seek": 100248, "start": 1008.8000000000001, "end": 1015.04, "text": " dramatically for example far higher resolution and maybe the global median age labeled from the start", "tokens": [50680, 17548, 337, 1365, 1400, 2946, 8669, 293, 1310, 264, 4338, 26779, 3205, 21335, 490, 264, 722, 50992], "temperature": 0.0, "avg_logprob": -0.04910822634427053, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.0030751076992601156}, {"id": 177, "seek": 100248, "start": 1015.04, "end": 1018.96, "text": " and actually now that it's got to the end I can see why it did pick out these countries", "tokens": [50992, 293, 767, 586, 300, 309, 311, 658, 281, 264, 917, 286, 393, 536, 983, 309, 630, 1888, 484, 613, 3517, 51188], "temperature": 0.0, "avg_logprob": -0.04910822634427053, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.0030751076992601156}, {"id": 178, "seek": 100248, "start": 1018.96, "end": 1024.96, "text": " because Niger did have the lowest median age in 2100 and it looks like Puerto Rico had the", "tokens": [51188, 570, 21489, 630, 362, 264, 12437, 26779, 3205, 294, 5080, 628, 293, 309, 1542, 411, 21472, 22643, 632, 264, 51488], "temperature": 0.0, "avg_logprob": -0.04910822634427053, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.0030751076992601156}, {"id": 179, "seek": 100248, "start": 1024.96, "end": 1030.56, "text": " highest and the fastest aging one was Albania next and this is going to shock quite a few people", "tokens": [51488, 6343, 293, 264, 14573, 19090, 472, 390, 41547, 654, 958, 293, 341, 307, 516, 281, 5588, 1596, 257, 1326, 561, 51768], "temperature": 0.0, "avg_logprob": -0.04910822634427053, "compression_ratio": 1.6643356643356644, "no_speech_prob": 0.0030751076992601156}, {"id": 180, "seek": 103056, "start": 1030.56, "end": 1036.08, "text": " what about image editing I created this image in mid-journey version five and then here's what I", "tokens": [50364, 437, 466, 3256, 10000, 286, 2942, 341, 3256, 294, 2062, 12, 8696, 2397, 3037, 1732, 293, 550, 510, 311, 437, 286, 50640], "temperature": 0.0, "avg_logprob": -0.10634717633647303, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0037067090161144733}, {"id": 181, "seek": 103056, "start": 1036.08, "end": 1042.96, "text": " asked I said use opencv to select the foreground of this image and look what it did it picked out", "tokens": [50640, 2351, 286, 848, 764, 1269, 66, 85, 281, 3048, 264, 32058, 295, 341, 3256, 293, 574, 437, 309, 630, 309, 6183, 484, 50984], "temperature": 0.0, "avg_logprob": -0.10634717633647303, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0037067090161144733}, {"id": 182, "seek": 103056, "start": 1042.96, "end": 1048.6399999999999, "text": " the foreground no blue sky now I know it's not perfect but it's nevertheless impressive all", "tokens": [50984, 264, 32058, 572, 3344, 5443, 586, 286, 458, 309, 311, 406, 2176, 457, 309, 311, 26924, 8992, 439, 51268], "temperature": 0.0, "avg_logprob": -0.10634717633647303, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0037067090161144733}, {"id": 183, "seek": 103056, "start": 1048.6399999999999, "end": 1055.84, "text": " within the window of chat bt this does actually make me wonder if open ai and chat bt is eventually", "tokens": [51268, 1951, 264, 4910, 295, 5081, 272, 83, 341, 775, 767, 652, 385, 2441, 498, 1269, 9783, 293, 5081, 272, 83, 307, 4728, 51628], "temperature": 0.0, "avg_logprob": -0.10634717633647303, "compression_ratio": 1.7232142857142858, "no_speech_prob": 0.0037067090161144733}, {"id": 184, "seek": 105584, "start": 1055.84, "end": 1062.48, "text": " not now but in a few years gonna swallow all other apps or maybe google's gemini but either way one", "tokens": [50364, 406, 586, 457, 294, 257, 1326, 924, 799, 20099, 439, 661, 7733, 420, 1310, 20742, 311, 7173, 3812, 457, 2139, 636, 472, 50696], "temperature": 0.0, "avg_logprob": -0.0644592217036656, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.2448665052652359}, {"id": 185, "seek": 105584, "start": 1062.48, "end": 1068.3999999999999, "text": " interface one website one app doing the job of all others and by the way of course chat bt is now", "tokens": [50696, 9226, 472, 3144, 472, 724, 884, 264, 1691, 295, 439, 2357, 293, 538, 264, 636, 295, 1164, 5081, 272, 83, 307, 586, 50992], "temperature": 0.0, "avg_logprob": -0.0644592217036656, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.2448665052652359}, {"id": 186, "seek": 105584, "start": 1068.3999999999999, "end": 1074.48, "text": " available on ios but imagine you have one app and it can do image editing text to speech video", "tokens": [50992, 2435, 322, 741, 329, 457, 3811, 291, 362, 472, 724, 293, 309, 393, 360, 3256, 10000, 2487, 281, 6218, 960, 51296], "temperature": 0.0, "avg_logprob": -0.0644592217036656, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.2448665052652359}, {"id": 187, "seek": 105584, "start": 1074.48, "end": 1081.12, "text": " editing everything data analysis not at gpt4 levels but gpt6 or gpt7 levels if you can get every", "tokens": [51296, 10000, 1203, 1412, 5215, 406, 412, 290, 662, 19, 4358, 457, 290, 662, 21, 420, 290, 662, 22, 4358, 498, 291, 393, 483, 633, 51628], "temperature": 0.0, "avg_logprob": -0.0644592217036656, "compression_ratio": 1.7443946188340806, "no_speech_prob": 0.2448665052652359}, {"id": 188, "seek": 108112, "start": 1081.12, "end": 1086.8799999999999, "text": " piece of information service and application in one interface a bit like now people being addicted", "tokens": [50364, 2522, 295, 1589, 2643, 293, 3861, 294, 472, 9226, 257, 857, 411, 586, 561, 885, 24629, 50652], "temperature": 0.0, "avg_logprob": -0.05333792397735316, "compression_ratio": 1.818840579710145, "no_speech_prob": 0.08032168447971344}, {"id": 189, "seek": 108112, "start": 1086.8799999999999, "end": 1091.84, "text": " to their smartphones won't people be addicted to this one interface again that's not going to happen", "tokens": [50652, 281, 641, 26782, 1582, 380, 561, 312, 24629, 281, 341, 472, 9226, 797, 300, 311, 406, 516, 281, 1051, 50900], "temperature": 0.0, "avg_logprob": -0.05333792397735316, "compression_ratio": 1.818840579710145, "no_speech_prob": 0.08032168447971344}, {"id": 190, "seek": 108112, "start": 1091.84, "end": 1096.08, "text": " now but i'm just posing it as a question to think over for the moment though before anyone gets too", "tokens": [50900, 586, 457, 741, 478, 445, 40378, 309, 382, 257, 1168, 281, 519, 670, 337, 264, 1623, 1673, 949, 2878, 2170, 886, 51112], "temperature": 0.0, "avg_logprob": -0.05333792397735316, "compression_ratio": 1.818840579710145, "no_speech_prob": 0.08032168447971344}, {"id": 191, "seek": 108112, "start": 1096.08, "end": 1100.8799999999999, "text": " carried away it does still hallucinate quite a lot so I uploaded this image and I asked it questions", "tokens": [51112, 9094, 1314, 309, 775, 920, 35212, 13923, 1596, 257, 688, 370, 286, 17135, 341, 3256, 293, 286, 2351, 309, 1651, 51352], "temperature": 0.0, "avg_logprob": -0.05333792397735316, "compression_ratio": 1.818840579710145, "no_speech_prob": 0.08032168447971344}, {"id": 192, "seek": 108112, "start": 1100.8799999999999, "end": 1106.2399999999998, "text": " about it and it answered and I was like wow it can do image recognition it said this image appears to", "tokens": [51352, 466, 309, 293, 309, 10103, 293, 286, 390, 411, 6076, 309, 393, 360, 3256, 11150, 309, 848, 341, 3256, 7038, 281, 51620], "temperature": 0.0, "avg_logprob": -0.05333792397735316, "compression_ratio": 1.818840579710145, "no_speech_prob": 0.08032168447971344}, {"id": 193, "seek": 110624, "start": 1106.24, "end": 1112.0, "text": " be a digital painting of a humanoid figure at a desk with a rather complex background I was initially", "tokens": [50364, 312, 257, 4562, 5370, 295, 257, 1952, 17079, 2573, 412, 257, 10026, 365, 257, 2831, 3997, 3678, 286, 390, 9105, 50652], "temperature": 0.0, "avg_logprob": -0.05583550218950238, "compression_ratio": 1.7, "no_speech_prob": 0.07582367211580276}, {"id": 194, "seek": 110624, "start": 1112.0, "end": 1117.52, "text": " amazed until I realized that it probably got that from the file name because when I asked it questions", "tokens": [50652, 20507, 1826, 286, 5334, 300, 309, 1391, 658, 300, 490, 264, 3991, 1315, 570, 562, 286, 2351, 309, 1651, 50928], "temperature": 0.0, "avg_logprob": -0.05583550218950238, "compression_ratio": 1.7, "no_speech_prob": 0.07582367211580276}, {"id": 195, "seek": 110624, "start": 1117.52, "end": 1123.92, "text": " it got it wrong so I said what is on the desk now look back there's this weird kind of microphone and", "tokens": [50928, 309, 658, 309, 2085, 370, 286, 848, 437, 307, 322, 264, 10026, 586, 574, 646, 456, 311, 341, 3657, 733, 295, 10952, 293, 51248], "temperature": 0.0, "avg_logprob": -0.05583550218950238, "compression_ratio": 1.7, "no_speech_prob": 0.07582367211580276}, {"id": 196, "seek": 110624, "start": 1123.92, "end": 1129.36, "text": " a bit of paper and not much else a keyboard and look what it said there are multiple floating", "tokens": [51248, 257, 857, 295, 3035, 293, 406, 709, 1646, 257, 10186, 293, 574, 437, 309, 848, 456, 366, 3866, 12607, 51520], "temperature": 0.0, "avg_logprob": -0.05583550218950238, "compression_ratio": 1.7, "no_speech_prob": 0.07582367211580276}, {"id": 197, "seek": 110624, "start": 1129.36, "end": 1136.0, "text": " holographic displays okay a mouse not really a desk lamp I can't see that and then tools and", "tokens": [51520, 38541, 2662, 299, 20119, 1392, 257, 9719, 406, 534, 257, 10026, 12684, 286, 393, 380, 536, 300, 293, 550, 3873, 293, 51852], "temperature": 0.0, "avg_logprob": -0.05583550218950238, "compression_ratio": 1.7, "no_speech_prob": 0.07582367211580276}, {"id": 198, "seek": 113600, "start": 1136.08, "end": 1140.88, "text": " devices now correct me if I'm wrong but I think most of those are incorrect now obviously I need", "tokens": [50368, 5759, 586, 3006, 385, 498, 286, 478, 2085, 457, 286, 519, 881, 295, 729, 366, 18424, 586, 2745, 286, 643, 50608], "temperature": 0.0, "avg_logprob": -0.04478238147238026, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002472159219905734}, {"id": 199, "seek": 113600, "start": 1140.88, "end": 1145.84, "text": " to do far more experiments to see if it actually can recognize any particular images and maybe I'm", "tokens": [50608, 281, 360, 1400, 544, 12050, 281, 536, 498, 309, 767, 393, 5521, 604, 1729, 5267, 293, 1310, 286, 478, 50856], "temperature": 0.0, "avg_logprob": -0.04478238147238026, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002472159219905734}, {"id": 200, "seek": 113600, "start": 1145.84, "end": 1150.88, "text": " putting it down too harshly but at the moment it does seem to hallucinate if you ask it about too", "tokens": [50856, 3372, 309, 760, 886, 14897, 356, 457, 412, 264, 1623, 309, 775, 1643, 281, 35212, 13923, 498, 291, 1029, 309, 466, 886, 51108], "temperature": 0.0, "avg_logprob": -0.04478238147238026, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002472159219905734}, {"id": 201, "seek": 113600, "start": 1150.88, "end": 1156.16, "text": " much of the detail of an image next you remember how one of the key weaknesses of gt4 is that it", "tokens": [51108, 709, 295, 264, 2607, 295, 364, 3256, 958, 291, 1604, 577, 472, 295, 264, 2141, 24381, 295, 290, 83, 19, 307, 300, 309, 51372], "temperature": 0.0, "avg_logprob": -0.04478238147238026, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002472159219905734}, {"id": 202, "seek": 113600, "start": 1156.16, "end": 1161.84, "text": " can't really count things especially not characters words etc and even more so it can't do division", "tokens": [51372, 393, 380, 534, 1207, 721, 2318, 406, 4342, 2283, 5183, 293, 754, 544, 370, 309, 393, 380, 360, 10044, 51656], "temperature": 0.0, "avg_logprob": -0.04478238147238026, "compression_ratio": 1.7132867132867133, "no_speech_prob": 0.002472159219905734}, {"id": 203, "seek": 116184, "start": 1161.84, "end": 1166.9599999999998, "text": " and some of you might be thinking well with wolfram alpha it can do those things not quite here is", "tokens": [50364, 293, 512, 295, 291, 1062, 312, 1953, 731, 365, 19216, 2356, 8961, 309, 393, 360, 729, 721, 406, 1596, 510, 307, 50620], "temperature": 0.0, "avg_logprob": -0.059514123743230646, "compression_ratio": 1.9215686274509804, "no_speech_prob": 0.004198028706014156}, {"id": 204, "seek": 116184, "start": 1166.9599999999998, "end": 1173.12, "text": " an example of the code interpreter plugin essentially eating wolfram alpha obviating it making it not", "tokens": [50620, 364, 1365, 295, 264, 3089, 34132, 23407, 4476, 3936, 19216, 2356, 8961, 1111, 4917, 990, 309, 1455, 309, 406, 50928], "temperature": 0.0, "avg_logprob": -0.059514123743230646, "compression_ratio": 1.9215686274509804, "no_speech_prob": 0.004198028706014156}, {"id": 205, "seek": 116184, "start": 1173.12, "end": 1178.32, "text": " obvious what the utility of it is if you've got code interpreter I asked divide the number of the", "tokens": [50928, 6322, 437, 264, 14877, 295, 309, 307, 498, 291, 600, 658, 3089, 34132, 286, 2351, 9845, 264, 1230, 295, 264, 51188], "temperature": 0.0, "avg_logprob": -0.059514123743230646, "compression_ratio": 1.9215686274509804, "no_speech_prob": 0.004198028706014156}, {"id": 206, "seek": 116184, "start": 1178.32, "end": 1183.36, "text": " letter e's in this prompt by the number of the letter t's now you might think code interpreter", "tokens": [51188, 5063, 308, 311, 294, 341, 12391, 538, 264, 1230, 295, 264, 5063, 256, 311, 586, 291, 1062, 519, 3089, 34132, 51440], "temperature": 0.0, "avg_logprob": -0.059514123743230646, "compression_ratio": 1.9215686274509804, "no_speech_prob": 0.004198028706014156}, {"id": 207, "seek": 116184, "start": 1183.36, "end": 1188.0, "text": " can improve things by doing the character counting but it can also do the division notice how it", "tokens": [51440, 393, 3470, 721, 538, 884, 264, 2517, 13251, 457, 309, 393, 611, 360, 264, 10044, 3449, 577, 309, 51672], "temperature": 0.0, "avg_logprob": -0.059514123743230646, "compression_ratio": 1.9215686274509804, "no_speech_prob": 0.004198028706014156}, {"id": 208, "seek": 118800, "start": 1188.08, "end": 1193.12, "text": " counted the characters correctly compared to wolfram alpha and of course got the division", "tokens": [50368, 20150, 264, 4342, 8944, 5347, 281, 19216, 2356, 8961, 293, 295, 1164, 658, 264, 10044, 50620], "temperature": 0.0, "avg_logprob": -0.03872199285598028, "compression_ratio": 1.8423076923076922, "no_speech_prob": 0.010325982235372066}, {"id": 209, "seek": 118800, "start": 1193.12, "end": 1199.36, "text": " correct as well so if it can do advanced quadratics and do division and character counting etc it does", "tokens": [50620, 3006, 382, 731, 370, 498, 309, 393, 360, 7339, 10787, 4481, 1167, 293, 360, 10044, 293, 2517, 13251, 5183, 309, 775, 50932], "temperature": 0.0, "avg_logprob": -0.03872199285598028, "compression_ratio": 1.8423076923076922, "no_speech_prob": 0.010325982235372066}, {"id": 210, "seek": 118800, "start": 1199.36, "end": 1204.48, "text": " beg the question what would we use wolfram alpha for that we can't use code interpreter for I", "tokens": [50932, 4612, 264, 1168, 437, 576, 321, 764, 19216, 2356, 8961, 337, 300, 321, 393, 380, 764, 3089, 34132, 337, 286, 51188], "temperature": 0.0, "avg_logprob": -0.03872199285598028, "compression_ratio": 1.8423076923076922, "no_speech_prob": 0.010325982235372066}, {"id": 211, "seek": 118800, "start": 1204.48, "end": 1208.72, "text": " honestly might not know something that you guys know so do let me know in the comments it also", "tokens": [51188, 6095, 1062, 406, 458, 746, 300, 291, 1074, 458, 370, 360, 718, 385, 458, 294, 264, 3053, 309, 611, 51400], "temperature": 0.0, "avg_logprob": -0.03872199285598028, "compression_ratio": 1.8423076923076922, "no_speech_prob": 0.010325982235372066}, {"id": 212, "seek": 118800, "start": 1208.72, "end": 1213.52, "text": " got this math question correct and notice you get these beautiful math visuals that you don't get", "tokens": [51400, 658, 341, 5221, 1168, 3006, 293, 3449, 291, 483, 613, 2238, 5221, 26035, 300, 291, 500, 380, 483, 51640], "temperature": 0.0, "avg_logprob": -0.03872199285598028, "compression_ratio": 1.8423076923076922, "no_speech_prob": 0.010325982235372066}, {"id": 213, "seek": 121352, "start": 1213.52, "end": 1218.96, "text": " with the base version of gpt4 you get something more like this where the visuals aren't as clear", "tokens": [50364, 365, 264, 3096, 3037, 295, 290, 662, 19, 291, 483, 746, 544, 411, 341, 689, 264, 26035, 3212, 380, 382, 1850, 50636], "temperature": 0.0, "avg_logprob": -0.0508047494021329, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.11914284527301788}, {"id": 214, "seek": 121352, "start": 1218.96, "end": 1223.76, "text": " and notice the base version of gpt4 gets the question wrong it can't do division but with", "tokens": [50636, 293, 3449, 264, 3096, 3037, 295, 290, 662, 19, 2170, 264, 1168, 2085, 309, 393, 380, 360, 10044, 457, 365, 50876], "temperature": 0.0, "avg_logprob": -0.0508047494021329, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.11914284527301788}, {"id": 215, "seek": 121352, "start": 1223.76, "end": 1228.56, "text": " code interpreter it gets the question right next one is a quick one pie charts nothing too special", "tokens": [50876, 3089, 34132, 309, 2170, 264, 1168, 558, 958, 472, 307, 257, 1702, 472, 1730, 17767, 1825, 886, 2121, 51116], "temperature": 0.0, "avg_logprob": -0.0508047494021329, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.11914284527301788}, {"id": 216, "seek": 121352, "start": 1228.56, "end": 1233.92, "text": " but I think it is a fairly beautiful visualization it doesn't seem to matter how big the csv file", "tokens": [51116, 457, 286, 519, 309, 307, 257, 6457, 2238, 25801, 309, 1177, 380, 1643, 281, 1871, 577, 955, 264, 28277, 85, 3991, 51384], "temperature": 0.0, "avg_logprob": -0.0508047494021329, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.11914284527301788}, {"id": 217, "seek": 121352, "start": 1233.92, "end": 1239.76, "text": " is that you upload this next example was really quite fascinating it was a word puzzle I have", "tokens": [51384, 307, 300, 291, 6580, 341, 958, 1365, 390, 534, 1596, 10343, 309, 390, 257, 1349, 12805, 286, 362, 51676], "temperature": 0.0, "avg_logprob": -0.0508047494021329, "compression_ratio": 1.7732342007434945, "no_speech_prob": 0.11914284527301788}, {"id": 218, "seek": 123976, "start": 1239.76, "end": 1245.52, "text": " tried this particular word puzzle on gpt4 dozens of times the reason I picked this puzzle it's called", "tokens": [50364, 3031, 341, 1729, 1349, 12805, 322, 290, 662, 19, 18431, 295, 1413, 264, 1778, 286, 6183, 341, 12805, 309, 311, 1219, 50652], "temperature": 0.0, "avg_logprob": -0.04209718108177185, "compression_ratio": 1.7553956834532374, "no_speech_prob": 0.04670540988445282}, {"id": 219, "seek": 123976, "start": 1245.52, "end": 1251.36, "text": " a word ladder is because it really struggles with the puzzle if the number of steps required is more", "tokens": [50652, 257, 1349, 18325, 307, 570, 309, 534, 17592, 365, 264, 12805, 498, 264, 1230, 295, 4439, 4739, 307, 544, 50944], "temperature": 0.0, "avg_logprob": -0.04209718108177185, "compression_ratio": 1.7553956834532374, "no_speech_prob": 0.04670540988445282}, {"id": 220, "seek": 123976, "start": 1251.36, "end": 1256.8, "text": " than a certain number usually about five or six steps it gave me a really interesting border of", "tokens": [50944, 813, 257, 1629, 1230, 2673, 466, 1732, 420, 2309, 4439, 309, 2729, 385, 257, 534, 1880, 7838, 295, 51216], "temperature": 0.0, "avg_logprob": -0.04209718108177185, "compression_ratio": 1.7553956834532374, "no_speech_prob": 0.04670540988445282}, {"id": 221, "seek": 123976, "start": 1256.8, "end": 1262.32, "text": " the limits of gpt4's planning abilities with language anyway it always gets it wrong here is", "tokens": [51216, 264, 10406, 295, 290, 662, 19, 311, 5038, 11582, 365, 2856, 4033, 309, 1009, 2170, 309, 2085, 510, 307, 51492], "temperature": 0.0, "avg_logprob": -0.04209718108177185, "compression_ratio": 1.7553956834532374, "no_speech_prob": 0.04670540988445282}, {"id": 222, "seek": 123976, "start": 1262.32, "end": 1268.24, "text": " a demonstration with the base model of gpt4 you might say why is this wrong but look at how it's", "tokens": [51492, 257, 16520, 365, 264, 3096, 2316, 295, 290, 662, 19, 291, 1062, 584, 983, 307, 341, 2085, 457, 574, 412, 577, 309, 311, 51788], "temperature": 0.0, "avg_logprob": -0.04209718108177185, "compression_ratio": 1.7553956834532374, "no_speech_prob": 0.04670540988445282}, {"id": 223, "seek": 126824, "start": 1268.24, "end": 1273.92, "text": " changed from seas to sags which is more than one letter change and that's typical of the kind of", "tokens": [50364, 3105, 490, 22535, 281, 262, 12109, 597, 307, 544, 813, 472, 5063, 1319, 293, 300, 311, 7476, 295, 264, 733, 295, 50648], "temperature": 0.0, "avg_logprob": -0.09752191079629434, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.009707065299153328}, {"id": 224, "seek": 126824, "start": 1273.92, "end": 1279.04, "text": " errors it makes what about with code interpreter well you can probably guess the ending given that I", "tokens": [50648, 13603, 309, 1669, 437, 466, 365, 3089, 34132, 731, 291, 393, 1391, 2041, 264, 8121, 2212, 300, 286, 50904], "temperature": 0.0, "avg_logprob": -0.09752191079629434, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.009707065299153328}, {"id": 225, "seek": 126824, "start": 1279.04, "end": 1285.6, "text": " featured it in the video but it gets it right I believe it draws upon a hard-coded word set and", "tokens": [50904, 13822, 309, 294, 264, 960, 457, 309, 2170, 309, 558, 286, 1697, 309, 20045, 3564, 257, 1152, 12, 66, 12340, 1349, 992, 293, 51232], "temperature": 0.0, "avg_logprob": -0.09752191079629434, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.009707065299153328}, {"id": 226, "seek": 126824, "start": 1285.6, "end": 1290.64, "text": " this does point towards the kind of puzzles that I think gpt4 with code interpreter will be able to", "tokens": [51232, 341, 775, 935, 3030, 264, 733, 295, 24138, 300, 286, 519, 290, 662, 19, 365, 3089, 34132, 486, 312, 1075, 281, 51484], "temperature": 0.0, "avg_logprob": -0.09752191079629434, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.009707065299153328}, {"id": 227, "seek": 126824, "start": 1290.64, "end": 1296.24, "text": " solve things like crosswords and sedokus okay not exactly world-changing but nevertheless", "tokens": [51484, 5039, 721, 411, 3278, 13832, 293, 9643, 38480, 1392, 406, 2293, 1002, 12, 27123, 457, 26924, 51764], "temperature": 0.0, "avg_logprob": -0.09752191079629434, "compression_ratio": 1.7067137809187278, "no_speech_prob": 0.009707065299153328}, {"id": 228, "seek": 129624, "start": 1296.24, "end": 1301.36, "text": " I think quite fascinating and how about Venn diagrams the reason I picked this example is that", "tokens": [50364, 286, 519, 1596, 10343, 293, 577, 466, 691, 1857, 36709, 264, 1778, 286, 6183, 341, 1365, 307, 300, 50620], "temperature": 0.0, "avg_logprob": -0.05564266926533467, "compression_ratio": 1.7463768115942029, "no_speech_prob": 0.010325822979211807}, {"id": 229, "seek": 129624, "start": 1301.36, "end": 1307.1200000000001, "text": " I had to go through about 10 steps to get it to create this rather basic three-way Venn diagram", "tokens": [50620, 286, 632, 281, 352, 807, 466, 1266, 4439, 281, 483, 309, 281, 1884, 341, 2831, 3875, 1045, 12, 676, 691, 1857, 10686, 50908], "temperature": 0.0, "avg_logprob": -0.05564266926533467, "compression_ratio": 1.7463768115942029, "no_speech_prob": 0.010325822979211807}, {"id": 230, "seek": 129624, "start": 1307.1200000000001, "end": 1313.28, "text": " this represents the overlap between dogs AI and desks and apparently all of them are loyal companions", "tokens": [50908, 341, 8855, 264, 19959, 1296, 7197, 7318, 293, 730, 1694, 293, 7970, 439, 295, 552, 366, 12682, 28009, 51216], "temperature": 0.0, "avg_logprob": -0.05564266926533467, "compression_ratio": 1.7463768115942029, "no_speech_prob": 0.010325822979211807}, {"id": 231, "seek": 129624, "start": 1313.28, "end": 1317.44, "text": " well we will see about that but anyway it took quite a few steps to get it right which is pretty", "tokens": [51216, 731, 321, 486, 536, 466, 300, 457, 4033, 309, 1890, 1596, 257, 1326, 4439, 281, 483, 309, 558, 597, 307, 1238, 51424], "temperature": 0.0, "avg_logprob": -0.05564266926533467, "compression_ratio": 1.7463768115942029, "no_speech_prob": 0.010325822979211807}, {"id": 232, "seek": 129624, "start": 1317.44, "end": 1322.48, "text": " annoying but here's the really interesting thing once I got it set up in the way that I like", "tokens": [51424, 11304, 457, 510, 311, 264, 534, 1880, 551, 1564, 286, 658, 309, 992, 493, 294, 264, 636, 300, 286, 411, 51676], "temperature": 0.0, "avg_logprob": -0.05564266926533467, "compression_ratio": 1.7463768115942029, "no_speech_prob": 0.010325822979211807}, {"id": 233, "seek": 132248, "start": 1322.48, "end": 1329.04, "text": " all I had to do was say use the format above to create a new three-way Venn diagram this time", "tokens": [50364, 439, 286, 632, 281, 360, 390, 584, 764, 264, 7877, 3673, 281, 1884, 257, 777, 1045, 12, 676, 691, 1857, 10686, 341, 565, 50692], "temperature": 0.0, "avg_logprob": -0.0654147588289701, "compression_ratio": 1.7168949771689497, "no_speech_prob": 0.002115546725690365}, {"id": 234, "seek": 132248, "start": 1329.04, "end": 1335.6, "text": " for mangoes movie heroes and marmosets try to make each entry funny and use different colors", "tokens": [50692, 337, 23481, 279, 3169, 12332, 293, 1849, 3415, 1385, 853, 281, 652, 1184, 8729, 4074, 293, 764, 819, 4577, 51020], "temperature": 0.0, "avg_logprob": -0.0654147588289701, "compression_ratio": 1.7168949771689497, "no_speech_prob": 0.002115546725690365}, {"id": 235, "seek": 132248, "start": 1335.6, "end": 1341.6, "text": " proceed without further questions so it may have been a struggle to set up initially but once done", "tokens": [51020, 8991, 1553, 3052, 1651, 370, 309, 815, 362, 668, 257, 7799, 281, 992, 493, 9105, 457, 1564, 1096, 51320], "temperature": 0.0, "avg_logprob": -0.0654147588289701, "compression_ratio": 1.7168949771689497, "no_speech_prob": 0.002115546725690365}, {"id": 236, "seek": 132248, "start": 1341.6, "end": 1348.0, "text": " it was so easy to iterate a new three-way Venn diagram and actually it was better than the", "tokens": [51320, 309, 390, 370, 1858, 281, 44497, 257, 777, 1045, 12, 676, 691, 1857, 10686, 293, 767, 309, 390, 1101, 813, 264, 51640], "temperature": 0.0, "avg_logprob": -0.0654147588289701, "compression_ratio": 1.7168949771689497, "no_speech_prob": 0.002115546725690365}, {"id": 237, "seek": 134800, "start": 1348.0, "end": 1353.12, "text": " original apparently all three are adored by fans worldwide apparently only marmosets and", "tokens": [50364, 3380, 7970, 439, 1045, 366, 614, 2769, 538, 4499, 13485, 7970, 787, 1849, 3415, 1385, 293, 50620], "temperature": 0.0, "avg_logprob": -0.04518825357610529, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.17772652208805084}, {"id": 238, "seek": 134800, "start": 1353.12, "end": 1359.04, "text": " movie heroes can climb up trees really fast and mangoes and marmosets can hang upside down", "tokens": [50620, 3169, 12332, 393, 10724, 493, 5852, 534, 2370, 293, 23481, 279, 293, 1849, 3415, 1385, 393, 3967, 14119, 760, 50916], "temperature": 0.0, "avg_logprob": -0.04518825357610529, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.17772652208805084}, {"id": 239, "seek": 134800, "start": 1359.04, "end": 1364.8, "text": " that's crazy one or two prompts iterating on a design already agreed upon this is honestly", "tokens": [50916, 300, 311, 3219, 472, 420, 732, 41095, 17138, 990, 322, 257, 1715, 1217, 9166, 3564, 341, 307, 6095, 51204], "temperature": 0.0, "avg_logprob": -0.04518825357610529, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.17772652208805084}, {"id": 240, "seek": 134800, "start": 1364.8, "end": 1369.68, "text": " what is likely to happen in the future with people spending hours to find the perfect data", "tokens": [51204, 437, 307, 3700, 281, 1051, 294, 264, 2027, 365, 561, 6434, 2496, 281, 915, 264, 2176, 1412, 51448], "temperature": 0.0, "avg_logprob": -0.04518825357610529, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.17772652208805084}, {"id": 241, "seek": 134800, "start": 1369.68, "end": 1376.0, "text": " visualization or piece of data analysis and then just hitting copy paste for all their other files", "tokens": [51448, 25801, 420, 2522, 295, 1412, 5215, 293, 550, 445, 8850, 5055, 9163, 337, 439, 641, 661, 7098, 51764], "temperature": 0.0, "avg_logprob": -0.04518825357610529, "compression_ratio": 1.7228464419475655, "no_speech_prob": 0.17772652208805084}, {"id": 242, "seek": 137600, "start": 1376.0, "end": 1381.28, "text": " perfect it once and then it does the rest for you a quick couple of bonus ones before I finish", "tokens": [50364, 2176, 309, 1564, 293, 550, 309, 775, 264, 1472, 337, 291, 257, 1702, 1916, 295, 10882, 2306, 949, 286, 2413, 50628], "temperature": 0.0, "avg_logprob": -0.04487721554867856, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.008845428936183453}, {"id": 243, "seek": 137600, "start": 1381.28, "end": 1387.28, "text": " you can just ask it to come up with a visualization giving it no direction at all it came up with a", "tokens": [50628, 291, 393, 445, 1029, 309, 281, 808, 493, 365, 257, 25801, 2902, 309, 572, 3513, 412, 439, 309, 1361, 493, 365, 257, 50928], "temperature": 0.0, "avg_logprob": -0.04487721554867856, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.008845428936183453}, {"id": 244, "seek": 137600, "start": 1387.28, "end": 1392.56, "text": " distribution of prime numbers up to ten thousand thing is I believe there's a slight mistake at", "tokens": [50928, 7316, 295, 5835, 3547, 493, 281, 2064, 4714, 551, 307, 286, 1697, 456, 311, 257, 4036, 6146, 412, 51192], "temperature": 0.0, "avg_logprob": -0.04487721554867856, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.008845428936183453}, {"id": 245, "seek": 137600, "start": 1392.56, "end": 1398.08, "text": " the beginning because I think there's only 25 in the first 100 and 21 in the next 100 so you", "tokens": [51192, 264, 2863, 570, 286, 519, 456, 311, 787, 3552, 294, 264, 700, 2319, 293, 5080, 294, 264, 958, 2319, 370, 291, 51468], "temperature": 0.0, "avg_logprob": -0.04487721554867856, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.008845428936183453}, {"id": 246, "seek": 137600, "start": 1398.08, "end": 1403.04, "text": " probably do want to still check the outputs that code interpreter gives you and that's another reason", "tokens": [51468, 1391, 360, 528, 281, 920, 1520, 264, 23930, 300, 3089, 34132, 2709, 291, 293, 300, 311, 1071, 1778, 51716], "temperature": 0.0, "avg_logprob": -0.04487721554867856, "compression_ratio": 1.6958041958041958, "no_speech_prob": 0.008845428936183453}, {"id": 247, "seek": 140304, "start": 1403.12, "end": 1408.32, "text": " it's not going to instantly replace all data analysis and data visualization it's not perfect", "tokens": [50368, 309, 311, 406, 516, 281, 13518, 7406, 439, 1412, 5215, 293, 1412, 25801, 309, 311, 406, 2176, 50628], "temperature": 0.0, "avg_logprob": -0.06201656983823192, "compression_ratio": 1.7161572052401746, "no_speech_prob": 0.037317462265491486}, {"id": 248, "seek": 140304, "start": 1408.32, "end": 1413.04, "text": " and it's not fully reliable but you've got to look ahead to where things are going I'm going to end", "tokens": [50628, 293, 309, 311, 406, 4498, 12924, 457, 291, 600, 658, 281, 574, 2286, 281, 689, 721, 366, 516, 286, 478, 516, 281, 917, 50864], "temperature": 0.0, "avg_logprob": -0.06201656983823192, "compression_ratio": 1.7161572052401746, "no_speech_prob": 0.037317462265491486}, {"id": 249, "seek": 140304, "start": 1413.04, "end": 1422.3999999999999, "text": " where I started with this insane 3d surface map of a volcano if this is what gpc4 can do now with", "tokens": [50864, 689, 286, 1409, 365, 341, 10838, 805, 67, 3753, 4471, 295, 257, 21979, 498, 341, 307, 437, 290, 79, 66, 19, 393, 360, 586, 365, 51332], "temperature": 0.0, "avg_logprob": -0.06201656983823192, "compression_ratio": 1.7161572052401746, "no_speech_prob": 0.037317462265491486}, {"id": 250, "seek": 140304, "start": 1422.3999999999999, "end": 1432.08, "text": " the alpha version of code interpreter what will gpc5 or 6 do with version 7 or 20 of code interpreter", "tokens": [51332, 264, 8961, 3037, 295, 3089, 34132, 437, 486, 290, 79, 66, 20, 420, 1386, 360, 365, 3037, 1614, 420, 945, 295, 3089, 34132, 51816], "temperature": 0.0, "avg_logprob": -0.06201656983823192, "compression_ratio": 1.7161572052401746, "no_speech_prob": 0.037317462265491486}, {"id": 251, "seek": 143208, "start": 1432.08, "end": 1437.1999999999998, "text": " I was about to speculate about that but then I got distracted with trying to get inside this", "tokens": [50364, 286, 390, 466, 281, 40775, 466, 300, 457, 550, 286, 658, 21658, 365, 1382, 281, 483, 1854, 341, 50620], "temperature": 0.0, "avg_logprob": -0.03972686382762173, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.007574966177344322}, {"id": 252, "seek": 143208, "start": 1437.1999999999998, "end": 1444.32, "text": " volcano it is kind of fun and look I'm going above and into the volcano let me know what you", "tokens": [50620, 21979, 309, 307, 733, 295, 1019, 293, 574, 286, 478, 516, 3673, 293, 666, 264, 21979, 718, 385, 458, 437, 291, 50976], "temperature": 0.0, "avg_logprob": -0.03972686382762173, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.007574966177344322}, {"id": 253, "seek": 143208, "start": 1444.32, "end": 1448.72, "text": " will try when you get access I know they're rolling it out steadily and I know that some people have", "tokens": [50976, 486, 853, 562, 291, 483, 2105, 286, 458, 436, 434, 9439, 309, 484, 36129, 293, 286, 458, 300, 512, 561, 362, 51196], "temperature": 0.0, "avg_logprob": -0.03972686382762173, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.007574966177344322}, {"id": 254, "seek": 143208, "start": 1448.72, "end": 1453.76, "text": " had access to it for about three weeks so hopefully if you want to experiment with it you will be able", "tokens": [51196, 632, 2105, 281, 309, 337, 466, 1045, 3259, 370, 4696, 498, 291, 528, 281, 5120, 365, 309, 291, 486, 312, 1075, 51448], "temperature": 0.0, "avg_logprob": -0.03972686382762173, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.007574966177344322}, {"id": 255, "seek": 143208, "start": 1453.76, "end": 1458.72, "text": " too soon in the meantime do let me know if you have any ideas that you want me to experiment with", "tokens": [51448, 886, 2321, 294, 264, 14991, 360, 718, 385, 458, 498, 291, 362, 604, 3487, 300, 291, 528, 385, 281, 5120, 365, 51696], "temperature": 0.0, "avg_logprob": -0.03972686382762173, "compression_ratio": 1.873076923076923, "no_speech_prob": 0.007574966177344322}, {"id": 256, "seek": 145872, "start": 1458.72, "end": 1464.96, "text": " and thank you so much for watching all the way to the end have a wonderful day", "tokens": [50364, 293, 1309, 291, 370, 709, 337, 1976, 439, 264, 636, 281, 264, 917, 362, 257, 3715, 786, 50676], "temperature": 0.0, "avg_logprob": -0.2153641939163208, "compression_ratio": 1.0985915492957747, "no_speech_prob": 0.18674595654010773}], "language": "en"}