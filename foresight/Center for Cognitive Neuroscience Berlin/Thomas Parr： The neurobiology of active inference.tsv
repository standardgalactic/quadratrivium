start	end	text
0	14320	It's a great pleasure to introduce Thomas Paar today, we'll be about his background.
14320	25160	So he started medical school in 2012, I guess, at the UCL and did also like a bachelor there
25160	35080	with a focus in new science. In 2016, he started his PhD, I hope everything is correct, he started
35080	45400	his PhD working together with Carl Friston and Garen Rees. So I think Thomas is really like the
45400	53520	person who most frustrated me, when I was at the at the Philly, so a long time ago. I was fascinated
53520	61400	by like the idea of the free entry principle and Carl Friston and really started going, learning
61400	69480	about Boltzmann equations and some kind of like message passing and so on and over years and years.
69480	80600	And then in 2016-17, I realized that suddenly a number of papers were coming out, it became much
80680	88120	more accessible and on these papers there were always like one name, Thomas Paar. And so I looked
88120	95240	into that and I realized that there is one person out there who is so young and who plus
95240	106040	started his PhD, who was able to go all through this extremely complicated math and ideas so easily
106520	113000	that I thought I should really give up thinking about the free energy principle at all. And more
113000	119240	impressively, I think a couple of months ago, even like a book came out like about like Active
119240	127320	Influence, where he is like the first author on and I really can recommend this book. It's a
127320	133240	fantastic introduction to Active Influence, to the free energy principle. So it's a really,
133240	140680	really great pleasure to have you here tonight, Thomas, and I'm really looking forward to your
140680	149960	talk. Thanks for joining. Well, thank you very much for the very nice invitation and the very
149960	159320	nice introduction as well. First of all, can you hear me okay? Yes. And next thing is to see
159320	168120	whether I can successfully share my screen. Let's try this. So I'm assuming you can see the
168120	178120	PowerPoint and now hopefully in full screen. Perfect. Great. So today, I realized that you've
178120	185640	already had a talk from Ryan Smith previously, so I'm assuming he's given an excellent overview of
185640	191880	Active Influences as he always does. And I wanted to take the opportunity to focus in on something
191880	199800	a little bit more specific in this talk, which is thinking about how dealing with Active Influence
199800	205640	lets us think about neurobiology and how we can start to make connections and form neurobiological
205640	214360	theories from the principles. So I'll start just by giving an introduction that I think
214440	219160	will hopefully give everybody a little bit of a refresher on Active Influence and the basic
219160	224440	principles. And although there are some technical elements to it, I'll try to make it as intuitive
224440	228760	as possible. And it really doesn't matter if you get all the technical detail through this,
228760	236680	it's just to build some intuitions. So I tend to like to start talks with this slide, which just
236680	243320	shows two different sorts of system. The one on the left is one that just gradually diffuses over
243320	248920	time, sort of loses form becomes progressively less interesting. Whereas the one on the right,
248920	253800	despite having the same amount of randomness built into it, manages to maintain its form over time.
254520	259080	And a useful starting point in thinking about Active Influence is thinking about
259720	265800	what the difference between these two sorts of systems are and how the one on the right is able
265800	274120	to maintain its form and resist the effect of these random fluctuations that are forcing it
274120	280760	in all sorts of different directions. And it's often useful to reformulate this in terms of the
280760	286520	probability density or the change in the probability distribution of all of these little particles
286520	290120	over time. So again, you can see on the left, we've got something that's just diffusing out into
290120	295080	nothing. And on the right, we get something that behaves from a probabilistic level pretty much
295080	301080	statically. And it's really those on the right that we're interested in, those biological creatures
301080	305560	are able to maintain their form, are able to resist the effects of what the environment does to them.
306600	311080	Now, if we sort of write down the kinds of dynamics that we'd need for a single particle
311080	317080	or a single part of the system to try and maintain this form, what we get to is a system that I think
317080	323720	quite intuitively always moves when it can from regions of low probability to regions of high
323720	328440	probability. So if we interpret this final distribution it gets to as some steady state,
329240	334280	all we need to do to maintain that in a random environment is to always try and climb uphill
334280	338520	at the probability gradients. And then almost by definition, we end up spending more time in
338520	345480	highly probable states and less time in more improbable states. And this is sort of the starting
345480	350840	point really for active inference, because we now have this notion that we're climbing probability
350840	355240	gradients and we have some distribution that we're effectively trying to maximize.
356200	362600	And we can link that back to ideas like the Bayesian brain, the idea that the brain is using some
362600	370200	model of the world around it to generate predictions. And then is drawing inferences about
370200	375480	the data that it actually obtains, so sensory information coming in through our eyes, ears,
375480	380840	through our skin, that we can then use to draw inferences about the causes of those data.
382440	386920	So here we've got the idea that there's some states of the world X that are causing some
386920	394600	sensory data Y. We're then forming some posterior beliefs, so beliefs about the causes given with
394600	401480	the data. And we're doing this using a generative model that comprises a likelihood in a prior,
401480	405240	so prior being how plausible are the things out there in the world before we've
405240	411160	made any observations. The likelihood being how likely the observations we've made are given
411160	416040	the states of the world or given our hypotheses about what caused them. And together we refer
416040	421800	to these two things as a generative model. Now the posterior distribution is what happens when
421800	428120	we invert that model where we find the probability of some causes given the data.
429080	434120	And the final term we've got at the end here is referred to either as an evidence or a marginal
434120	439080	likelihood. And that's because in the context of Bayesian statistics we often use a marginal
439080	445400	likelihood as a measure of the fit of a model to the data that it's trying to explain. There's
445400	451080	how much evidence do those data afford some model of the world. And together we can think of these
451080	455960	as being an inversion of the generative model. Now the reason I've put this here is that we
455960	463880	can see that the dynamics that I'm showing in the upper left can be interpreted as the process of
463880	468840	maximising the evidence for some model, maximising the fit between the brain's model of how the world
468840	475400	works and how the world then engages with the model or engages with the brain by presenting it data.
476760	481320	And broadly there are two ways of doing that. The first is, as we've already spoken about,
481320	485880	it's changing your beliefs based upon new data such that you get a better fit to the world.
486680	491480	The other way, which I think is one of the key ideas in Active Inference, is that you
491480	496360	generate actions based upon your beliefs that change the world to make it more like your model.
497880	503160	And this is sort of the key idea that underwrites Active Inference, that all we're trying to do
503160	508680	is maximise the evidence for some model of our world. And we can either do that through
508680	514360	perception by changing our model or through action by changing the world. But together,
514360	520200	they come under one single objective, sometimes referred to, particularly by people like Kevin
520200	528120	the Acapoway, as self-evidencing. Now I want to go a little bit into the structure of generative
528120	533560	models and specifically the ways we can think about and the ways we can notate generative models,
534440	539240	because it often helps to move from the slightly more mathematical abstract description to a more
539240	544440	graphical notation that I think often gives a much better intuitive sense of what's going on.
545240	550280	So to do that, I'm going to start with this idea that model evidence is effectively what we get out
550280	556920	once we've integrated out all of the causes from our model, by which I mean if you take
556920	562440	account of all of the things our model predicts and then we take into account the prior probabilities
562440	569160	of all of the things that are causing those data, we can then work out what the probability of the
569160	575640	data are under that model. But the model itself takes account of the things that are being generated,
575640	579960	so our sensory data, and also the things that are causing them, simply a joint probability
579960	584840	distribution involving all of these things. So I'm now interpreting this graphic up on
584840	590520	the left as depending upon some generative model where we've effectively integrated out everything
590520	598760	that we don't need to determine explicitly. Now generative models will often have some
598760	602920	interesting structure, and in fact if they don't have interesting structures then they're not
602920	609000	interesting generative models. And normally that structure manifests as a factorization
609000	614440	of this joint distribution, but not everything depends upon everything else. And so we can
614440	619080	often factorize it, and here I'm just showing a completely arbitrary factorization of some
619080	625960	generative model where we have certain dependencies, so y depends directly upon x1 and x2, but not
625960	631640	directly upon x3 and so on. And the reason it's useful to think about this factorization is because
631640	637320	we can then express a graphical version of this model that provides a bit more intuition as to
637320	642840	what's going on. So the way we do that, or one way that we can do that, is using something known as a
642840	647720	factor graph. And the idea is that we take each of these factors in turn, we draw a square,
649160	655160	and then we draw an arrow to whatever's on the left of the probability factor we're interested in.
655160	660360	So here an arrow towards the y, because we're saying the probability of y conditioned upon or
660360	666360	depending upon the other two things, and then we attach those to the same square. We then move
666360	671800	on to the next factor, draw another square, and we then attach the relevant variables together
673000	678040	in exactly the same way. And we carry on doing that until we have a picture of what our model is
678040	682120	like. So now instead of having to look at this equation, you can look at this and say, okay,
682120	690440	well x3 causes x1, x4 causes x2, and together x1 and x2 relate to or together generate our data y.
693240	698360	This is just to demonstrate several models you may be familiar with generally, and the fact that we
698360	701960	we're often implicitly using these kinds of generative models without necessarily thinking
701960	706920	about it. So when we're performing a principal components analysis, we're often taking some
708840	713720	distribution of some variable x, we're then mapping that to a higher dimensional space y,
715000	720280	and that's our sort of model of how the data that we're working with are generated.
722120	725960	So what we can then do when we perform a principal components analysis is take our
725960	731720	high dimensional data y, work out how you go back from the y to the x, and that gives you all of your
731720	735880	specific principal components and the directions that have been stretched in various different ways.
737400	741160	Same principle applies for things like canonical variance analysis, where you've got some set of
741720	745320	variables then mapped to two different sorts of data by stretching them and
746120	750200	distorting them in various ways. And the challenge is how do you get back to the common
751560	757240	hidden variable common cause for both of those datasets. And we do the same sort of thing with
757240	762280	something like clustering analysis, where here the model says we're effectively sampling from
762280	766920	one of several different clusters with different probabilities. We're then generating some point
766920	773960	in space depending upon which cluster it falls in. And the process of inference is again undoing
773960	779000	this. It's finding the posterior by taking a point in a cluster and saying, well, which cluster is
779000	786120	that from? So going from the y to the s. So that's a sort of brief introduction to the idea of
786120	791560	generative models, the the role they play in active inference, some key examples and some of
791560	796600	the notation that I'm going to use as we go forward. What I've said so far has been relatively
796600	803080	abstract. And in the next section, I want to try and work from those sort of general principles
803080	807880	and these slightly abstract notions through to something more specific and more neurobiological.
809000	813160	Now, the first thing we're going to do to get there is to introduce one more abstract concept,
813160	818360	which is that of a Markov blanket. A Markov blanket comes up in all sorts of places in active
818360	823160	inference, but I'm going to use it in a very specific way here. And this is to talk about
823160	828840	conditional independence. And what I mean by conditional independence is that if you have
831400	835160	two different sets of variables, so here I've noted them as the mu and the eta,
836120	842760	the Markov blanket B is the set of set of variables that render the other two completely
842760	846680	independent to one another, that mean that if you know everything about the blanket,
846680	849880	knowing something about mu tells you nothing new about eta.
852040	856520	To give you an example of this, one of the examples that most people are familiar with
856520	862600	is the idea of a Markov chain, where you have a sequence of events in time. So something that
862600	867400	happens in the past then influences the present, which then influences the future with no direct
867400	872760	influence from the past to the future without going via the present. So if I know everything
872760	876680	there is to know about the present, knowing something about the past tells me nothing new
876680	881640	about the future and vice versa. So in that sense, the present is the Markov blanket that
881640	887880	separates the past from the future. Now, this is a very useful concept when we're dealing with
887880	892600	graphical models or generative models that have some interesting factorization structure,
892600	899560	and I'll try and explain why. The Markov blanket is often referred to as or can often be identified
899560	904440	by identifying variable we're interested in, so let's say we're interested in the variable x2,
905080	911480	then you find the parents of x2, so the things that caused it, the children of x2, so the things
911480	917240	it causes, and the parents of its children, and that gives you the Markov blanket of x2.
918600	925240	Now the significance of this is that knowing this means that if we know about the blanket,
925240	928600	it doesn't matter what else is going on in the generative model, you know, this might be some
928600	934200	tiny section of a huge generative model with many, many variables, but we don't need to know about
934200	938760	all those variables, all we need to know about are the blanket variables, so we can effectively
938760	946200	ignore everything else if what we're interested in is x2. Now, how does this then matter for
946200	952440	neurobiology? Well, I think the answer to that is that the brain is an extremely sparse structure,
952440	956840	that synaptic message passing does not involve connections between every different neuron in
956840	961240	the brain to every other neuron in the brain. There are a small number of, relatively speaking,
961240	968360	of synapses between any neuron and its neighbors or neurons elsewhere in the brain,
969160	973240	and so we can make an argument that if the brain is performing inference about lots of different
973240	979160	variables, all it needs is to know the structure of the generative model and the variables that
979160	983560	sit in that Markov blanket, or at least the neurons that are representing those other variables.
984600	988440	And that tells us that we can then, when we're inverting that model, when we're performing
988440	995080	inference, what I'm showing here is just one example of an inference scheme, we can, we can
995080	1003080	express the dynamics of that neuronal message passing in terms of connections from the other
1003080	1009960	neural populations that are representing the variables in that Markov blanket. The details
1009960	1015560	of this aren't that important, but this is one example of an inference scheme known as variational
1015560	1021640	message passing, here formulated as a gradient scheme in terms of some dynamics, which has
1021640	1027000	relevance for modeling neural populations, we're interested in how the dynamics of those
1027000	1033000	populations evolve over time. And we can sort of do this recursively, we can couple together
1033000	1039560	lots of different parts of this system, where the things that are being connected up are just the
1039560	1045560	Markov blankets of different populations. Here I've expressed it in terms of an error term,
1045640	1053000	this epsilon, which effectively represents the gradient of a free energy objective,
1053000	1057720	which is used as an approximation to that marginal likelihood or evidence that I spoke
1057720	1063800	about earlier. And then some beliefs about or expectations about that variable, so we can now
1063800	1069400	use our, the errors in our predictions to update those variables. And once we've written down the
1069400	1074440	dynamics of this sort of system, we can simulate things like firing rates, we can simulate the
1074440	1080920	dynamics and the behavior of these networks of neurons passing messages between one another
1081720	1087400	as a means of performing a form of inference and thus self evidencing.
1090280	1094520	I know that this is probably still seemingly relatively abstract, but I think what will
1094520	1098200	hopefully help is if we then go through some examples thinking about specific kinds of
1098200	1103720	generative model and how that might then affect the kind of message passing we would see in a
1103720	1108920	brain. And the first step to thinking about that I think is very important when we think about
1108920	1113720	really useful generative models is they will all typically have a temporal aspect to them that
1113720	1119320	as biological creatures we deal with things that evolve in time. And so it's worth thinking about
1119320	1123240	how do you formulate a generative model that has that kind of dynamic aspect to it.
1124760	1130280	And there are several different answers to that and one of them is we use something known as
1130360	1137320	as a Taylor series approximation. So we start by saying okay at the current time what is the
1138520	1143080	value of some variable x in the world and there's maybe some continuous variable it may be
1143080	1148760	where my arm is in space. If we then want to know how it's going to evolve in time we could then say
1148760	1152600	well let's take the next element of our Taylor series approximation that's taking out of its
1152600	1156440	velocity and that tells us a little bit more about the trajectory that my arm might be on.
1157400	1162920	We can then take another value which is the current acceleration of that position and we get
1162920	1169160	a slightly better approximation to the trajectory. And the more terms we add in the greater approximation
1169160	1173240	we have of the trajectory or the greater representation we have of the trajectory just as
1173240	1178360	a series of numbers where those numbers are my current position my current velocity acceleration
1178360	1183640	etc. So we could formulate a generative model by trying to predict each of these coefficients
1183720	1188920	of this Taylor series or each of these generalized coordinates of motion as they're sometimes referred
1188920	1195000	to. An alternative is we just say at time one where will I be at time two where will I be and
1195000	1202920	we simply represent it in terms of the sequence of points over time. Often when we're discretizing
1202920	1207720	time in this way we often we also discretize space so we might say okay where am I in some
1207800	1213320	discretized scheme am I in location one two three four or five at each different time point
1214120	1220680	and so we have two different ways of accounting for how things might evolve over time and each
1220680	1225400	of these can be useful in slightly different circumstances. So if I were dealing with a
1225400	1231160	sequential decision-making task it may be much more efficient for me to say okay at the first
1231160	1234760	move I'm going to make is this then the second one is this the third one is this and dealing
1234760	1240040	with something very sequential that might also be important in in sort of language processing
1240040	1243880	where you have to think which words you're going to put together in a sequence and we're dealing
1243880	1250040	with discrete variables over time because words are categorical instead of opposed to
1250040	1256760	continuing as opposed to lying on a continuum. However if I were dealing with movement or
1256760	1262120	the responses I'm getting from some photoreceptor in my retina it may be much more sensible for me
1262120	1267400	to be working in continuous time thinking about how things evolve at a continuous scale.
1268840	1273640	So what I'm showing here is an example of a generative model and the associated message
1273640	1279720	passing scheme when formulated in terms of this continuous time scheme. So what we've got here
1279720	1287400	is a factor graph at the top this blue element that uses exactly the same sort of formulation that
1287400	1295640	we've been discussing so far so we have some variable here which might represent our position
1295640	1301160	which then predicts our velocity at that time which then predicts the acceleration at that time.
1301160	1306920	So we have a series of predictions here about the coupling between different orders of motion
1307720	1312680	at each point those are predicting some sort of data here are wise which represents the
1313640	1318040	the current position of our sensory data the current velocity the current acceleration.
1318840	1324200	What I'm showing lower down here is the message passing scheme we get when we take account of
1324200	1330040	the Markov blankets of each of these variables so the Markov blanket here for the the velocity
1330040	1334440	would include the position and the acceleration but also the data I've got about those things
1335240	1341400	and some prior beliefs about about other variables in our model and so we'd end up connecting those
1341480	1346600	things up and although it looks like a bit of a mess of connections it's still fewer connections
1346600	1350840	than the total number connections you would get if you match everything to everything else.
1352360	1356760	What we've got here takes the form of effectively a predictive coding style scheme
1356760	1362040	which people may be familiar with and the idea that that you can you can hierarchically predict
1363640	1368200	predict some data and you can predict the thing that's predicting that data
1368200	1374680	those data and by observing the errors in your prediction of the data you update your prediction
1374680	1380680	which then cascades up a hierarchy allowing you to update subsequent predictions.
1382440	1387960	What I'm showing you here is the equivalent model formulated in terms of discrete time and in this
1387960	1394200	case discrete space as well so here we have a state at time t minus one which generates a
1394200	1399320	state at time t which generates a state at time t plus one at each of those time points we're
1399320	1405320	generating some observable outcomes which are represented as the o's with a variable pi here
1405320	1411000	that represents alternative trajectories I could I could pursue so alternative policies or plans
1411000	1419160	alternative ways I could change the sequence of events and again we have underneath the message
1419160	1425800	passing scheme that could perform inferences about this sort of model and you can see that the
1425800	1432600	message passing scheme to some extent looks like an inversion or or as loosely a sort of mirror
1432600	1437560	image of the generative model because all it's doing is taking each step that was performed
1437560	1442200	to generate some data and then inverting those steps one at a time so it's just going backwards
1442280	1450280	from the data to arrive at the causes of those data. Now what I've got shown here on the left
1451240	1459240	is just a sort of cartoon image of some of the key connections in in cortical micro circuits
1459240	1466280	so here we've got superficial pyramidal cells as spiny stellate cells as SS deep pyramidal
1466280	1474840	cells as DP and inhibitory engineer arms as the double eyes and this is clearly an oversimplification
1474840	1481640	of what is a very complex connectivity structure but the reason I'm showing this here is that
1482440	1487720	if we know something about this connectivity structure if we know about some of the key patterns
1487720	1492360	we can start to ask how can the the sorts of models that we've spoken about over the last
1492360	1498120	couple of slides then be interpreted in terms of the micro circuits that could help
1499800	1505640	could help implement these in a biological system. So what I'm going to show in the middle
1505640	1513240	is an example of a continuous states-based predictive coding style model that has all
1513240	1517400	the same elements as in the slide I showed you before but are now mapped so that some of the
1517400	1524280	connections coming in and out of it loosely map to those associated with a known cortical anatomy
1525880	1530600	and we can do exactly the same thing here with the discrete states-based model and think about how
1530600	1536440	we can assign those roles associated with the roles of different cortical layers
1537480	1543560	and then use that as a way of forming hypotheses. Now what I'm showing you on this slide is not
1543880	1548280	necessarily the last word on this and you could formulate several different hypotheses about how
1548280	1552840	these two things map together and that's where a lot of interesting science happens. This is just
1552840	1558680	one example of how we can associate what we know about cortical microcircuitry and anatomy
1558680	1563320	with what we know about the anatomy of message passing for some simple generic forms of generative
1563320	1568520	model. What I'm going to try and do over the rest of this presentation is to take the connections
1568600	1575480	coming out of this out of each of these points and to try and think about how those might or the
1575480	1580600	roles they might those might play when we take an active entrance approach and the sorts of structures
1580600	1587720	in the brain that might be involved in dealing with those dealing with those things. I'm going to
1587720	1593000	start by talking about movement and reflexes so here the kinds of things we're interested in
1593080	1599560	are the connections that leave the cortex and go to areas like the spinal cord in the motor
1599560	1608360	neurons, the predictions that we can then make about what we're seeing here in the central
1608360	1614280	plot and the G that's been circled in red is a prediction about the sort of data I might expect
1614280	1619240	to observe which may here be proprioceptive data consequent on particular sorts of action.
1619800	1625160	And we can think of this quite simply if we think about the structure of a reflex arc.
1626200	1631880	So what I've got here on the lower part is just the same marginal likelihood or model evidence
1631880	1637000	that we've dealt with before this idea of it being a measure of the fit of the model both in
1637000	1644280	terms of its accuracy, the accuracy with which it predicts some data and the simplest least complex
1644280	1649640	version of the model that will work for that. What do we do when we change the data? Well we try and
1649640	1656680	make the data more accurate in relation to our model by trying to align the data with our predictions.
1657400	1663320	So when we think of the structure of a reflex arc where we can interpret it as some descending
1663320	1667960	prediction coming from the motor cortex saying what is the proprioceptive data I expect to
1667960	1673800	observe. By comparing that with the proprioceptive data that's actually coming into the spinal cord
1673800	1679560	through the dorsal horn with that prediction we then get a potentially a mismatch between the two
1679560	1686120	that can be used to generate action via the ventral horn generating movements and contractions and
1686120	1693160	muscles that then try to fulfill these predictions. I'll show you just an example of a simulation of
1695000	1700280	an arm using active inference that has these sort of reflex arcs built in and all we're doing here
1700280	1706360	is we're just tapping on the biceps tendon where the red arrow is pointing and we're just seeing
1706360	1712360	the reflexive response that we're getting as a consequence of effectively inducing this additional
1712360	1718200	piece of sensory proprioceptive information by stretching that tendon. We induce the mismatch
1718200	1724600	between the prediction that's coming down and the data that's coming out and that
1725400	1731320	is corrected then by generating this additional movement. Interestingly we can do things by
1731320	1736360	manipulating the confidence of those predictions and sometimes get things like bigger reflexes
1736360	1740840	and hyperreflexia as the sort you might see in clinical populations with spinal cord injuries
1742360	1746440	and so here you can see the reflex is slightly larger than it was before and slightly brisker.
1748360	1754440	I'll show you another example of this same idea where now we've developed a mapping between
1754840	1761160	the microcircuit and the anatomy of the ocular motor brainstem so here starting from the superior
1761160	1768840	colliculus the the rostral interstitial nucleus of the medial longitudinal vesiculus and there is
1768840	1776280	other centers and the cranial nerves that are responsible for generating eye movements so cranial
1776280	1785560	nerve three and cranial nerve six here are seen here as resulting from these error terms so we're
1785560	1792280	predicting how I would expect my eyes to move and any error in the current position of the eyes is
1792280	1798280	corrected by generating eye movements so by inducing different priors on top of this model
1798280	1802360	of different predictions about where I'd expect the eyes to be we can actually then generate
1802360	1809480	different sorts of eye movements using predictive coding style active inference scheme where the key
1809480	1814360	thing is that the predictions can be fulfilled by actually changing the positions of our muscles
1814360	1822680	and positions of our eyes so that sort of provides a very brief overview and a couple of examples
1823640	1831400	dealing with the role of reflexes and predictions in generating movements but it doesn't really
1831400	1836280	tell us anything about how movements are chosen how movements are selected and you don't necessarily
1836280	1840840	get any intelligent behavior out of that and for that we need to start looking at different sorts
1840840	1847160	of structures and different parts of this generative model and here the key thing I want to focus on
1847160	1853000	is the role of the basal ganglia and which here we're going to associate with the computation
1853000	1857960	of something known as the expected free energy and I'll try and describe what that is a little bit
1857960	1865880	more in some of the subsequent slides so what I'm showing here is a mapping of some of the
1866680	1871880	subcortical but subcortical anatomy or more actually I should say that this is a mapping
1871880	1878440	between parts of our Bayesian message passing scheme parts of the model inversion when we're
1878440	1886680	dealing with the ability to plan and make decisions to some of the known subcortical anatomy of the
1886680	1894200	brain and the key thing I want to focus on is this G that is depicted as part of the as part of
1894200	1900760	the stride and so the things that are feeding into this are what we're getting from the cortex
1900760	1905080	here which is some prediction of the outcomes we'd expect if I were to pursue a particular
1905080	1912440	cause of action which is this subscript pi and the another sort of error term here which is how
1912440	1920920	far away are those predictions from my preferences about how the world should be my prior beliefs
1920920	1929960	about how the kind of data that I would actually actively seek out and act to get together those
1929960	1935640	are used to calculate our expected free energy which we can then use to formulate beliefs about
1935640	1941480	policies by saying that the policies we would select the plans we would engage in are those that
1941480	1948440	we would expect to be associated with the lowest expected free energy and to put that more formally
1949560	1955960	we're saying that we're going to give a prior belief that the policies the series of actions
1955960	1960440	we're going to choose are going to be those associated with the maximum information gain
1960440	1967800	tell us the most about the world around us that fulfill our preferences and then we're going to
1967800	1972440	add in an additional term here which deals with habitual type policies and things that we tend to
1972440	1977320	do because we've learned we behave in a particular way in those situations now the combination of
1977320	1982760	this information gain and preferences are often referred to as an expected free energy and I won't
1982760	1988360	go into the details here but that's simply because you can rearrange them mathematically to make them
1988360	1993160	look very much like the equation for a free energy or or marginal likelihood approximation
1994120	1999880	with an expectation around them to say that these are the what we would expect given
2000840	2005080	our predictions about the data we would obtain because here we're dealing with beliefs about
2005080	2010200	the future plans into the future where we haven't yet had those data and we need to deal with the
2010200	2014360	expectations of what those data would be under different plans that we could choose
2015960	2022040	and so here we're showing just an example of the direct pathway through the basal ganglia
2022040	2025560	which is normally thought to facilitate movement and depends upon this expected free energy
2026280	2031560	and an indirect pathway which here we've associated with these kinds of habitual drives and I'll
2031560	2035080	come back to those a little bit later on when we deal with hierarchical models
2036600	2040200	just to give you a little bit of intuition as to the information gain aspect of the expected
2040200	2045640	free energy because I think most people most people probably understand this idea of seeking
2046360	2051880	preferences and behaving to maximize some degree of reward but many people are less
2051880	2055880	familiar with the idea of seeking information into the way that that might manifest in these
2055880	2063880	kinds of models so as an example I'm going to show you just a simple simulation where we're
2063880	2068520	going to manipulate some of the different aspects of the uncertainty in the model so here
2068760	2075560	in the upper left I'm just showing a way of parameterizing the the uncertainty associated
2075560	2079720	with the data generating process so this is our likelihood precision on sensory precision
2080520	2086440	and it effectively says that when this precision is very high we can be very certain about the
2086440	2091560	outcome we'll observe given a particular state of the world whereas when it's very low we could
2091560	2097160	predict everything with very similar probability and we can do something very similar by manipulating
2097160	2101320	the uncertainty in the dynamics of the world so again when this is very high it means that
2101320	2105640	where I am now is very highly predictive of where I'll be at the next step in time
2107160	2111960	whereas when it's very low it means that pretty much anything at the next time point is is equally
2111960	2117960	probable and I'll show you a simple simulation where these two things are manipulated just to
2117960	2122600	try and give you an intuition for what it means to act to to maximize one's information about the
2122600	2131720	world so the upper simulation here top left shows four panels which can each change at some point
2131720	2140760	in time to a different color with some random probabilities and the blue line here is designed
2140760	2146840	to show effectively an eye tracking trace so it's a simulated agent who is allowed to choose which
2146840	2150920	of these panels it wants to look at at any one time and you can see it samples them with a
2150920	2158040	relatively even frequency in the middle panel what we've done is we've reduced the precision
2158040	2163480	or increased the uncertainty associated with the likelihood in the lower left that effectively is
2163480	2168760	like turning off the lights in that location it's effectively making that lower left location much more
2168760	2175480	much less informative much more noisy and so effectively what what we've got here is a system
2175480	2180680	that then ignores that it says that I can't get a good quality high quality information from there
2180680	2184600	so I'm going to look at all of the other locations rather than rather than this in the lower left
2189400	2193640	an analogy for this is if you're thinking about how you perform a scientific experiment you would
2193640	2198760	probably aim to use if you had a choice between two different measuring instruments you would
2198760	2202760	choose the one that gives you more precise measurements rather than the one that gives you
2202760	2210840	very noisy measurements in the lower left we've manipulated the uncertainty or the volatility
2210840	2216440	associated with the dynamics so here what's happened is the upper left location is associated
2216440	2221640	with much more uncertain dynamics so here what happens is that I end up sampling that upper left
2221640	2228200	location much more frequently and intuitively this makes a lot of sense because if you've looked
2228200	2232760	somewhere very recently normally you will you'll know a lot about what was there you don't need to
2232760	2239960	look back there anytime soon however if it's very volatile if it changes quite with some degree of
2239960	2245160	randomness and you have very little certainty about the state of it after you've looked away
2245160	2249240	you'll look back with a much greater frequency so we've effectively decreased the inhibition
2249240	2254920	of return in this location by increasing its volatility or decreasing the precision associated
2254920	2260840	with its with the dynamics in that location so the end of this was just to show you this sort
2260840	2266280	of emergent behavior just by having an information seeking objective by by having a prior belief
2266280	2271560	that we're going to act to minimize some expected free energy one component of which is to maximize
2271560	2279480	our information about the world now the next thing I want to come on to is the role of hierarchical
2279480	2285800	generative models and one of the key benefits of having a hierarchical model is that we can now deal
2285800	2290920	with things that evolve over a range of different timescales so you might have some things that
2290920	2296840	evolve very slowly and some things that evolve very quickly and to some extent we can separate
2296840	2306280	out two and use slowly evolving things to to to help us predict what's happening at the faster level
2306280	2313560	and here the key things to to note are all of these connections between higher cortical regions
2313560	2322120	and lower cortical regions which manifests both in the in the discrete and continuous state space
2322120	2327160	models and so it's worth them thinking about what the role of these are and how that manifests in
2327160	2331720	terms of the generative models we've been dealing with before and it's really this that links back
2331720	2338840	into the the idea of predictive coding as many people know it and you've probably seen graphics
2338840	2344280	of this sort in the past where we have a range of cortical regions that are each making predictions
2344280	2348920	about the others and so here going from going from the right to the left we've got a series of
2348920	2356520	predictions in as these dark black lines with prediction errors passed back up using these
2356520	2362520	these dashed lines that then allow us to correct at each level and all this this graphic shows
2362520	2368920	is a simplification of the graphic on on the previous slide so i want to give you an intuition
2368920	2373720	for why this is useful using a couple of examples so the first example i'm going to use is one from
2373720	2379960	the domain of active vision so imagine imagine you're doing a task now where you have to fixate
2379960	2387560	on this cross in the center and maintain that fixation and show you a stimulus but maintain
2387560	2392840	fixation on the cross. Stimulus is going to disappear and then your next task is to perform
2392840	2398120	an eye movement to the location where the stimulus appeared. It's a very simple task if the sort was
2398120	2404600	used frequently in monkey electrophysiology and all throughout neuroscience but it's an interesting
2404600	2409800	one because it has several different components to it that i think help in terms of thinking about
2409880	2416920	the utility of hierarchical models so one aspect of this is making decisions about
2416920	2420760	where you're looking at each of those time points and making inferences about which
2420760	2426360	of several alternative locations you're going to perform an eye movement to so simple form of
2426360	2435960	planning here so that calls into into action the sort of discrete state space model that we were
2435960	2441720	dealing with before this this partial observable decision process this set of discrete sequential
2441720	2449480	timing points and that's often very highly relevant structure of most simple tasks in cognitive
2449480	2456600	neuroscience. However we also need to actually move our eyes we need to we need to move our eyes
2456600	2460440	from one location to the next we need to know how to generate forces we need to know how to make
2460440	2465800	sure the eyes come to rest in the right location given those decisions and that calls into play
2466040	2471720	this sort of continuous state space predictive coding style model so how do we then how do we
2471720	2475800	then combine the two how do we deal with the situation where we want to predict a particular
2475800	2482840	location at a discrete level one of several alternatives but then also map that to a continuous
2482840	2489320	motor trajectory and this is where generative models get a little bit more complicated so
2489320	2495240	taking this a bit at a time what we've got at the top here is our mark-off decision process model
2495240	2500920	this is our discrete state space model in discrete time now at each of those time points we're no
2500920	2507560	longer predicting data specifically we're now predicting a short trajectory formulated in terms
2507560	2512680	of our continuous state space models so at time one we're now going to predict a short element of
2512680	2517320	our trajectory and this is very much like the sort of clustering model I showed you much earlier
2517320	2522200	that you take a discrete point and you map it to a point in continuous space with some probability
2522440	2528760	at the next time we then predict the next bit of that continuous trajectory so our priors for our
2528760	2534360	continuous model are now inheriting from the predictions from the discrete state space model
2534360	2539720	and then we can do the same thing again at the next time point and and so we can create a discrete
2539720	2545880	sequence from our our sequential model and at each point in that sequence associate that with a
2546840	2554120	short trajectory in continuous space that then predicts our continuous data allowing us to then
2554120	2557960	predict the proprioceptive information we would expect to get from the eyes when we're performing
2557960	2565080	a task at that sort and you can see that we now develop a hierarchical structure also in thinking
2565080	2569880	about the relationship between the bits of the message passing scheme so here we've got the
2569880	2575080	discrete bit of our message passing scheme our discrete microcircuit and a bit of the continuous
2575080	2579800	microcircuit here and the interactions between the two of those were making predictions from the
2579800	2585240	discrete one to the continuous one and then passing errors backwards to allow us to to update
2585880	2592280	the discrete element so interpreting this again neurobiologically you can imagine
2593160	2597400	that say we have some element of the cortex perhaps the frontal eye field that's making predictions
2597400	2603720	about one of several alternative locations I could direct my gaze we can then map that
2603720	2609720	via sort of output of the basal ganglia and the predictions about what policy I'm going to pursue
2611160	2616680	through to areas like the superior colliculus which then might make use of predictive coding
2616680	2622840	style networks of the sort depicted here to then generate eye movements as we've seen before
2623720	2628040	and just to show you that in action we imagine that these are population of neurons that at
2628040	2633080	each time point are trying to predict one of several in this case three different locations
2633080	2639480	at four different time points we can then map that through structures like the superior colliculus
2639480	2645480	and this is supposed to sort of cartoon the idea of a population code in the superior colliculus
2645480	2649880	but then results in the eye movement to each of those discrete locations
2651560	2656200	putting it all together we can then formulate exactly the task that I asked you to perform
2656200	2662120	earlier and see the result of an active infant scheme performing that task
2662920	2668760	and so here you can see it performs it very successfully by predicting sequences of eye
2668760	2676440	movements that are conditioned upon the discrete part of the model and the idea of maintaining
2676440	2682520	this belief about where the stimulus appeared and using that then to direct my policy selection
2682520	2690440	and eventually the movement I select I want to give you one more example of this sort of hierarchical
2690440	2696280	scheme in the domain of motor control and appeal to the same sort of simulations we were looking
2696280	2701800	at earlier in terms of the reflexes exhibited by that arm the generative model we're going to use
2701800	2707800	here is a slightly complicated one but here effectively involves transitions between different
2707800	2713880	locations that an arm could be in or a hand could be in which then predicts different locations in
2713880	2721720	some continuous space and different locations that a target might be in and that will then allow us
2721720	2729000	to make predictions about about given where some target is in some continuous space which decision
2729000	2734120	I'm going to make about the alternative points I could move my arm to and so here we have the
2734120	2739560	simulation where we have the target appearing as the black ball out of the out of the three balls
2739560	2745960	which is going to change at various points in time and our active infant scheme is now
2745960	2751080	selecting these locations translating those into predictions of continuous trajectories
2751080	2756440	and making the appropriate movements such that it reaches each of these target locations
2756440	2763480	and what's shown in terms of the the graphic here is also an interpretation of the message
2763480	2768760	passing in terms of the known anatomy of the motor system or part of it
2771000	2775240	we can perform various lesions to this and see whether they behave in the same way that we might
2775240	2781960	expect patient populations to so here we've induced a cerebellar lesion which effectively
2782760	2790280	involves a misestimation of certain precision terms certain confidence or variance parameters
2790840	2796280	and you see this sort of overshoot and this kind of oscillatory behavior in the way the arm behaves
2797160	2800360	that mimics what we might expect him as cerebellar attacks here
2802360	2805640	we can look at the higher levels of the model and actually have multiple
2806440	2810600	hierarchical levels of the discrete scheme and here what we've done is we've induced a
2811560	2818280	lesion in what might represent a frontal lobe lesion where now the model is able to perform
2818280	2823240	all the movements with perfect fluency but every time there's a change of context it takes quite
2823240	2828360	a while to adjust to that new context to deal with a new situation you'll see that instead of
2829160	2833720	moving straight there as it was before there's a lot more hesitancy and a lot more difficulty
2833800	2840120	constructing that long-term narrative because we've broken that slower hierarchical level
2842280	2847480	and here a final lesion that we can introduce is one that reduces my confidence in policy
2847480	2852520	selection so here this effectively makes me very uncertain about what I'm going to do next and
2852520	2858040	here we get a sort of a kinetic type picture and sort we might expect in a Parkinsonian type syndrome
2858120	2867960	so I realized that was quite a lot and I hope I'm not too far over time but I'll just try and
2867960	2874600	summarize briefly the key ideas that we've discussed so the first was thinking about this
2874600	2879080	idea of climbing probability gradients the idea that to maintain some form over time
2880040	2886520	and to persist we need to effectively be climbing these probability gradients all the time
2887480	2892440	we interpreted those probability gradients in terms of in terms of Bayes theorem and connected
2892440	2897240	that to the Bayes in brain and the sort of message passing that might be involved in
2898120	2903240	forming inferences about elements of some generative model and the role that might have
2903240	2911880	in cortical micro-circuitry we also discussed the role of action and the idea that that one way to
2911960	2917320	make our model better fit the world is to act upon it and one way to do that is to simply reduce
2917320	2923960	any discrepancy between the predictions from that model and the data that's coming in and the
2923960	2931160	structure of that is very similar to the idea of a reflex arc as is well known throughout
2931960	2939800	motor neuroscience and the final thing we thought about was how we can then construct hierarchical
2939800	2947640	models that allow us to produce simulations and theories that deal with much larger scale
2947640	2953800	networks in the brain and take a full sort of systems level view of how particular movements
2953800	2960920	and particular behaviors are generated through the inversion of particular forms of generative model
2962520	2968920	with that I'd like to thank many people who've been involved either directly or indirectly in
2968920	2974280	this work and I'll mention the book again which was mentioned at the beginning and a lot of this
2974280	2979320	talk was loosely following some of the structure in a couple of the chapters in the book so if
2979320	2986520	anybody's interested please do take a look I'm more than happy to answer any questions thank you for
2986520	2992120	your attention
