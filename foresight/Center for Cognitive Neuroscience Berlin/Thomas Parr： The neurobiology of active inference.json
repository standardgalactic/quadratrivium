{"text": " It's a great pleasure to introduce Thomas Paar today, we'll be about his background. So he started medical school in 2012, I guess, at the UCL and did also like a bachelor there with a focus in new science. In 2016, he started his PhD, I hope everything is correct, he started his PhD working together with Carl Friston and Garen Rees. So I think Thomas is really like the person who most frustrated me, when I was at the at the Philly, so a long time ago. I was fascinated by like the idea of the free entry principle and Carl Friston and really started going, learning about Boltzmann equations and some kind of like message passing and so on and over years and years. And then in 2016-17, I realized that suddenly a number of papers were coming out, it became much more accessible and on these papers there were always like one name, Thomas Paar. And so I looked into that and I realized that there is one person out there who is so young and who plus started his PhD, who was able to go all through this extremely complicated math and ideas so easily that I thought I should really give up thinking about the free energy principle at all. And more impressively, I think a couple of months ago, even like a book came out like about like Active Influence, where he is like the first author on and I really can recommend this book. It's a fantastic introduction to Active Influence, to the free energy principle. So it's a really, really great pleasure to have you here tonight, Thomas, and I'm really looking forward to your talk. Thanks for joining. Well, thank you very much for the very nice invitation and the very nice introduction as well. First of all, can you hear me okay? Yes. And next thing is to see whether I can successfully share my screen. Let's try this. So I'm assuming you can see the PowerPoint and now hopefully in full screen. Perfect. Great. So today, I realized that you've already had a talk from Ryan Smith previously, so I'm assuming he's given an excellent overview of Active Influences as he always does. And I wanted to take the opportunity to focus in on something a little bit more specific in this talk, which is thinking about how dealing with Active Influence lets us think about neurobiology and how we can start to make connections and form neurobiological theories from the principles. So I'll start just by giving an introduction that I think will hopefully give everybody a little bit of a refresher on Active Influence and the basic principles. And although there are some technical elements to it, I'll try to make it as intuitive as possible. And it really doesn't matter if you get all the technical detail through this, it's just to build some intuitions. So I tend to like to start talks with this slide, which just shows two different sorts of system. The one on the left is one that just gradually diffuses over time, sort of loses form becomes progressively less interesting. Whereas the one on the right, despite having the same amount of randomness built into it, manages to maintain its form over time. And a useful starting point in thinking about Active Influence is thinking about what the difference between these two sorts of systems are and how the one on the right is able to maintain its form and resist the effect of these random fluctuations that are forcing it in all sorts of different directions. And it's often useful to reformulate this in terms of the probability density or the change in the probability distribution of all of these little particles over time. So again, you can see on the left, we've got something that's just diffusing out into nothing. And on the right, we get something that behaves from a probabilistic level pretty much statically. And it's really those on the right that we're interested in, those biological creatures are able to maintain their form, are able to resist the effects of what the environment does to them. Now, if we sort of write down the kinds of dynamics that we'd need for a single particle or a single part of the system to try and maintain this form, what we get to is a system that I think quite intuitively always moves when it can from regions of low probability to regions of high probability. So if we interpret this final distribution it gets to as some steady state, all we need to do to maintain that in a random environment is to always try and climb uphill at the probability gradients. And then almost by definition, we end up spending more time in highly probable states and less time in more improbable states. And this is sort of the starting point really for active inference, because we now have this notion that we're climbing probability gradients and we have some distribution that we're effectively trying to maximize. And we can link that back to ideas like the Bayesian brain, the idea that the brain is using some model of the world around it to generate predictions. And then is drawing inferences about the data that it actually obtains, so sensory information coming in through our eyes, ears, through our skin, that we can then use to draw inferences about the causes of those data. So here we've got the idea that there's some states of the world X that are causing some sensory data Y. We're then forming some posterior beliefs, so beliefs about the causes given with the data. And we're doing this using a generative model that comprises a likelihood in a prior, so prior being how plausible are the things out there in the world before we've made any observations. The likelihood being how likely the observations we've made are given the states of the world or given our hypotheses about what caused them. And together we refer to these two things as a generative model. Now the posterior distribution is what happens when we invert that model where we find the probability of some causes given the data. And the final term we've got at the end here is referred to either as an evidence or a marginal likelihood. And that's because in the context of Bayesian statistics we often use a marginal likelihood as a measure of the fit of a model to the data that it's trying to explain. There's how much evidence do those data afford some model of the world. And together we can think of these as being an inversion of the generative model. Now the reason I've put this here is that we can see that the dynamics that I'm showing in the upper left can be interpreted as the process of maximising the evidence for some model, maximising the fit between the brain's model of how the world works and how the world then engages with the model or engages with the brain by presenting it data. And broadly there are two ways of doing that. The first is, as we've already spoken about, it's changing your beliefs based upon new data such that you get a better fit to the world. The other way, which I think is one of the key ideas in Active Inference, is that you generate actions based upon your beliefs that change the world to make it more like your model. And this is sort of the key idea that underwrites Active Inference, that all we're trying to do is maximise the evidence for some model of our world. And we can either do that through perception by changing our model or through action by changing the world. But together, they come under one single objective, sometimes referred to, particularly by people like Kevin the Acapoway, as self-evidencing. Now I want to go a little bit into the structure of generative models and specifically the ways we can think about and the ways we can notate generative models, because it often helps to move from the slightly more mathematical abstract description to a more graphical notation that I think often gives a much better intuitive sense of what's going on. So to do that, I'm going to start with this idea that model evidence is effectively what we get out once we've integrated out all of the causes from our model, by which I mean if you take account of all of the things our model predicts and then we take into account the prior probabilities of all of the things that are causing those data, we can then work out what the probability of the data are under that model. But the model itself takes account of the things that are being generated, so our sensory data, and also the things that are causing them, simply a joint probability distribution involving all of these things. So I'm now interpreting this graphic up on the left as depending upon some generative model where we've effectively integrated out everything that we don't need to determine explicitly. Now generative models will often have some interesting structure, and in fact if they don't have interesting structures then they're not interesting generative models. And normally that structure manifests as a factorization of this joint distribution, but not everything depends upon everything else. And so we can often factorize it, and here I'm just showing a completely arbitrary factorization of some generative model where we have certain dependencies, so y depends directly upon x1 and x2, but not directly upon x3 and so on. And the reason it's useful to think about this factorization is because we can then express a graphical version of this model that provides a bit more intuition as to what's going on. So the way we do that, or one way that we can do that, is using something known as a factor graph. And the idea is that we take each of these factors in turn, we draw a square, and then we draw an arrow to whatever's on the left of the probability factor we're interested in. So here an arrow towards the y, because we're saying the probability of y conditioned upon or depending upon the other two things, and then we attach those to the same square. We then move on to the next factor, draw another square, and we then attach the relevant variables together in exactly the same way. And we carry on doing that until we have a picture of what our model is like. So now instead of having to look at this equation, you can look at this and say, okay, well x3 causes x1, x4 causes x2, and together x1 and x2 relate to or together generate our data y. This is just to demonstrate several models you may be familiar with generally, and the fact that we we're often implicitly using these kinds of generative models without necessarily thinking about it. So when we're performing a principal components analysis, we're often taking some distribution of some variable x, we're then mapping that to a higher dimensional space y, and that's our sort of model of how the data that we're working with are generated. So what we can then do when we perform a principal components analysis is take our high dimensional data y, work out how you go back from the y to the x, and that gives you all of your specific principal components and the directions that have been stretched in various different ways. Same principle applies for things like canonical variance analysis, where you've got some set of variables then mapped to two different sorts of data by stretching them and distorting them in various ways. And the challenge is how do you get back to the common hidden variable common cause for both of those datasets. And we do the same sort of thing with something like clustering analysis, where here the model says we're effectively sampling from one of several different clusters with different probabilities. We're then generating some point in space depending upon which cluster it falls in. And the process of inference is again undoing this. It's finding the posterior by taking a point in a cluster and saying, well, which cluster is that from? So going from the y to the s. So that's a sort of brief introduction to the idea of generative models, the the role they play in active inference, some key examples and some of the notation that I'm going to use as we go forward. What I've said so far has been relatively abstract. And in the next section, I want to try and work from those sort of general principles and these slightly abstract notions through to something more specific and more neurobiological. Now, the first thing we're going to do to get there is to introduce one more abstract concept, which is that of a Markov blanket. A Markov blanket comes up in all sorts of places in active inference, but I'm going to use it in a very specific way here. And this is to talk about conditional independence. And what I mean by conditional independence is that if you have two different sets of variables, so here I've noted them as the mu and the eta, the Markov blanket B is the set of set of variables that render the other two completely independent to one another, that mean that if you know everything about the blanket, knowing something about mu tells you nothing new about eta. To give you an example of this, one of the examples that most people are familiar with is the idea of a Markov chain, where you have a sequence of events in time. So something that happens in the past then influences the present, which then influences the future with no direct influence from the past to the future without going via the present. So if I know everything there is to know about the present, knowing something about the past tells me nothing new about the future and vice versa. So in that sense, the present is the Markov blanket that separates the past from the future. Now, this is a very useful concept when we're dealing with graphical models or generative models that have some interesting factorization structure, and I'll try and explain why. The Markov blanket is often referred to as or can often be identified by identifying variable we're interested in, so let's say we're interested in the variable x2, then you find the parents of x2, so the things that caused it, the children of x2, so the things it causes, and the parents of its children, and that gives you the Markov blanket of x2. Now the significance of this is that knowing this means that if we know about the blanket, it doesn't matter what else is going on in the generative model, you know, this might be some tiny section of a huge generative model with many, many variables, but we don't need to know about all those variables, all we need to know about are the blanket variables, so we can effectively ignore everything else if what we're interested in is x2. Now, how does this then matter for neurobiology? Well, I think the answer to that is that the brain is an extremely sparse structure, that synaptic message passing does not involve connections between every different neuron in the brain to every other neuron in the brain. There are a small number of, relatively speaking, of synapses between any neuron and its neighbors or neurons elsewhere in the brain, and so we can make an argument that if the brain is performing inference about lots of different variables, all it needs is to know the structure of the generative model and the variables that sit in that Markov blanket, or at least the neurons that are representing those other variables. And that tells us that we can then, when we're inverting that model, when we're performing inference, what I'm showing here is just one example of an inference scheme, we can, we can express the dynamics of that neuronal message passing in terms of connections from the other neural populations that are representing the variables in that Markov blanket. The details of this aren't that important, but this is one example of an inference scheme known as variational message passing, here formulated as a gradient scheme in terms of some dynamics, which has relevance for modeling neural populations, we're interested in how the dynamics of those populations evolve over time. And we can sort of do this recursively, we can couple together lots of different parts of this system, where the things that are being connected up are just the Markov blankets of different populations. Here I've expressed it in terms of an error term, this epsilon, which effectively represents the gradient of a free energy objective, which is used as an approximation to that marginal likelihood or evidence that I spoke about earlier. And then some beliefs about or expectations about that variable, so we can now use our, the errors in our predictions to update those variables. And once we've written down the dynamics of this sort of system, we can simulate things like firing rates, we can simulate the dynamics and the behavior of these networks of neurons passing messages between one another as a means of performing a form of inference and thus self evidencing. I know that this is probably still seemingly relatively abstract, but I think what will hopefully help is if we then go through some examples thinking about specific kinds of generative model and how that might then affect the kind of message passing we would see in a brain. And the first step to thinking about that I think is very important when we think about really useful generative models is they will all typically have a temporal aspect to them that as biological creatures we deal with things that evolve in time. And so it's worth thinking about how do you formulate a generative model that has that kind of dynamic aspect to it. And there are several different answers to that and one of them is we use something known as as a Taylor series approximation. So we start by saying okay at the current time what is the value of some variable x in the world and there's maybe some continuous variable it may be where my arm is in space. If we then want to know how it's going to evolve in time we could then say well let's take the next element of our Taylor series approximation that's taking out of its velocity and that tells us a little bit more about the trajectory that my arm might be on. We can then take another value which is the current acceleration of that position and we get a slightly better approximation to the trajectory. And the more terms we add in the greater approximation we have of the trajectory or the greater representation we have of the trajectory just as a series of numbers where those numbers are my current position my current velocity acceleration etc. So we could formulate a generative model by trying to predict each of these coefficients of this Taylor series or each of these generalized coordinates of motion as they're sometimes referred to. An alternative is we just say at time one where will I be at time two where will I be and we simply represent it in terms of the sequence of points over time. Often when we're discretizing time in this way we often we also discretize space so we might say okay where am I in some discretized scheme am I in location one two three four or five at each different time point and so we have two different ways of accounting for how things might evolve over time and each of these can be useful in slightly different circumstances. So if I were dealing with a sequential decision-making task it may be much more efficient for me to say okay at the first move I'm going to make is this then the second one is this the third one is this and dealing with something very sequential that might also be important in in sort of language processing where you have to think which words you're going to put together in a sequence and we're dealing with discrete variables over time because words are categorical instead of opposed to continuing as opposed to lying on a continuum. However if I were dealing with movement or the responses I'm getting from some photoreceptor in my retina it may be much more sensible for me to be working in continuous time thinking about how things evolve at a continuous scale. So what I'm showing here is an example of a generative model and the associated message passing scheme when formulated in terms of this continuous time scheme. So what we've got here is a factor graph at the top this blue element that uses exactly the same sort of formulation that we've been discussing so far so we have some variable here which might represent our position which then predicts our velocity at that time which then predicts the acceleration at that time. So we have a series of predictions here about the coupling between different orders of motion at each point those are predicting some sort of data here are wise which represents the the current position of our sensory data the current velocity the current acceleration. What I'm showing lower down here is the message passing scheme we get when we take account of the Markov blankets of each of these variables so the Markov blanket here for the the velocity would include the position and the acceleration but also the data I've got about those things and some prior beliefs about about other variables in our model and so we'd end up connecting those things up and although it looks like a bit of a mess of connections it's still fewer connections than the total number connections you would get if you match everything to everything else. What we've got here takes the form of effectively a predictive coding style scheme which people may be familiar with and the idea that that you can you can hierarchically predict predict some data and you can predict the thing that's predicting that data those data and by observing the errors in your prediction of the data you update your prediction which then cascades up a hierarchy allowing you to update subsequent predictions. What I'm showing you here is the equivalent model formulated in terms of discrete time and in this case discrete space as well so here we have a state at time t minus one which generates a state at time t which generates a state at time t plus one at each of those time points we're generating some observable outcomes which are represented as the o's with a variable pi here that represents alternative trajectories I could I could pursue so alternative policies or plans alternative ways I could change the sequence of events and again we have underneath the message passing scheme that could perform inferences about this sort of model and you can see that the message passing scheme to some extent looks like an inversion or or as loosely a sort of mirror image of the generative model because all it's doing is taking each step that was performed to generate some data and then inverting those steps one at a time so it's just going backwards from the data to arrive at the causes of those data. Now what I've got shown here on the left is just a sort of cartoon image of some of the key connections in in cortical micro circuits so here we've got superficial pyramidal cells as spiny stellate cells as SS deep pyramidal cells as DP and inhibitory engineer arms as the double eyes and this is clearly an oversimplification of what is a very complex connectivity structure but the reason I'm showing this here is that if we know something about this connectivity structure if we know about some of the key patterns we can start to ask how can the the sorts of models that we've spoken about over the last couple of slides then be interpreted in terms of the micro circuits that could help could help implement these in a biological system. So what I'm going to show in the middle is an example of a continuous states-based predictive coding style model that has all the same elements as in the slide I showed you before but are now mapped so that some of the connections coming in and out of it loosely map to those associated with a known cortical anatomy and we can do exactly the same thing here with the discrete states-based model and think about how we can assign those roles associated with the roles of different cortical layers and then use that as a way of forming hypotheses. Now what I'm showing you on this slide is not necessarily the last word on this and you could formulate several different hypotheses about how these two things map together and that's where a lot of interesting science happens. This is just one example of how we can associate what we know about cortical microcircuitry and anatomy with what we know about the anatomy of message passing for some simple generic forms of generative model. What I'm going to try and do over the rest of this presentation is to take the connections coming out of this out of each of these points and to try and think about how those might or the roles they might those might play when we take an active entrance approach and the sorts of structures in the brain that might be involved in dealing with those dealing with those things. I'm going to start by talking about movement and reflexes so here the kinds of things we're interested in are the connections that leave the cortex and go to areas like the spinal cord in the motor neurons, the predictions that we can then make about what we're seeing here in the central plot and the G that's been circled in red is a prediction about the sort of data I might expect to observe which may here be proprioceptive data consequent on particular sorts of action. And we can think of this quite simply if we think about the structure of a reflex arc. So what I've got here on the lower part is just the same marginal likelihood or model evidence that we've dealt with before this idea of it being a measure of the fit of the model both in terms of its accuracy, the accuracy with which it predicts some data and the simplest least complex version of the model that will work for that. What do we do when we change the data? Well we try and make the data more accurate in relation to our model by trying to align the data with our predictions. So when we think of the structure of a reflex arc where we can interpret it as some descending prediction coming from the motor cortex saying what is the proprioceptive data I expect to observe. By comparing that with the proprioceptive data that's actually coming into the spinal cord through the dorsal horn with that prediction we then get a potentially a mismatch between the two that can be used to generate action via the ventral horn generating movements and contractions and muscles that then try to fulfill these predictions. I'll show you just an example of a simulation of an arm using active inference that has these sort of reflex arcs built in and all we're doing here is we're just tapping on the biceps tendon where the red arrow is pointing and we're just seeing the reflexive response that we're getting as a consequence of effectively inducing this additional piece of sensory proprioceptive information by stretching that tendon. We induce the mismatch between the prediction that's coming down and the data that's coming out and that is corrected then by generating this additional movement. Interestingly we can do things by manipulating the confidence of those predictions and sometimes get things like bigger reflexes and hyperreflexia as the sort you might see in clinical populations with spinal cord injuries and so here you can see the reflex is slightly larger than it was before and slightly brisker. I'll show you another example of this same idea where now we've developed a mapping between the microcircuit and the anatomy of the ocular motor brainstem so here starting from the superior colliculus the the rostral interstitial nucleus of the medial longitudinal vesiculus and there is other centers and the cranial nerves that are responsible for generating eye movements so cranial nerve three and cranial nerve six here are seen here as resulting from these error terms so we're predicting how I would expect my eyes to move and any error in the current position of the eyes is corrected by generating eye movements so by inducing different priors on top of this model of different predictions about where I'd expect the eyes to be we can actually then generate different sorts of eye movements using predictive coding style active inference scheme where the key thing is that the predictions can be fulfilled by actually changing the positions of our muscles and positions of our eyes so that sort of provides a very brief overview and a couple of examples dealing with the role of reflexes and predictions in generating movements but it doesn't really tell us anything about how movements are chosen how movements are selected and you don't necessarily get any intelligent behavior out of that and for that we need to start looking at different sorts of structures and different parts of this generative model and here the key thing I want to focus on is the role of the basal ganglia and which here we're going to associate with the computation of something known as the expected free energy and I'll try and describe what that is a little bit more in some of the subsequent slides so what I'm showing here is a mapping of some of the subcortical but subcortical anatomy or more actually I should say that this is a mapping between parts of our Bayesian message passing scheme parts of the model inversion when we're dealing with the ability to plan and make decisions to some of the known subcortical anatomy of the brain and the key thing I want to focus on is this G that is depicted as part of the as part of the stride and so the things that are feeding into this are what we're getting from the cortex here which is some prediction of the outcomes we'd expect if I were to pursue a particular cause of action which is this subscript pi and the another sort of error term here which is how far away are those predictions from my preferences about how the world should be my prior beliefs about how the kind of data that I would actually actively seek out and act to get together those are used to calculate our expected free energy which we can then use to formulate beliefs about policies by saying that the policies we would select the plans we would engage in are those that we would expect to be associated with the lowest expected free energy and to put that more formally we're saying that we're going to give a prior belief that the policies the series of actions we're going to choose are going to be those associated with the maximum information gain tell us the most about the world around us that fulfill our preferences and then we're going to add in an additional term here which deals with habitual type policies and things that we tend to do because we've learned we behave in a particular way in those situations now the combination of this information gain and preferences are often referred to as an expected free energy and I won't go into the details here but that's simply because you can rearrange them mathematically to make them look very much like the equation for a free energy or or marginal likelihood approximation with an expectation around them to say that these are the what we would expect given our predictions about the data we would obtain because here we're dealing with beliefs about the future plans into the future where we haven't yet had those data and we need to deal with the expectations of what those data would be under different plans that we could choose and so here we're showing just an example of the direct pathway through the basal ganglia which is normally thought to facilitate movement and depends upon this expected free energy and an indirect pathway which here we've associated with these kinds of habitual drives and I'll come back to those a little bit later on when we deal with hierarchical models just to give you a little bit of intuition as to the information gain aspect of the expected free energy because I think most people most people probably understand this idea of seeking preferences and behaving to maximize some degree of reward but many people are less familiar with the idea of seeking information into the way that that might manifest in these kinds of models so as an example I'm going to show you just a simple simulation where we're going to manipulate some of the different aspects of the uncertainty in the model so here in the upper left I'm just showing a way of parameterizing the the uncertainty associated with the data generating process so this is our likelihood precision on sensory precision and it effectively says that when this precision is very high we can be very certain about the outcome we'll observe given a particular state of the world whereas when it's very low we could predict everything with very similar probability and we can do something very similar by manipulating the uncertainty in the dynamics of the world so again when this is very high it means that where I am now is very highly predictive of where I'll be at the next step in time whereas when it's very low it means that pretty much anything at the next time point is is equally probable and I'll show you a simple simulation where these two things are manipulated just to try and give you an intuition for what it means to act to to maximize one's information about the world so the upper simulation here top left shows four panels which can each change at some point in time to a different color with some random probabilities and the blue line here is designed to show effectively an eye tracking trace so it's a simulated agent who is allowed to choose which of these panels it wants to look at at any one time and you can see it samples them with a relatively even frequency in the middle panel what we've done is we've reduced the precision or increased the uncertainty associated with the likelihood in the lower left that effectively is like turning off the lights in that location it's effectively making that lower left location much more much less informative much more noisy and so effectively what what we've got here is a system that then ignores that it says that I can't get a good quality high quality information from there so I'm going to look at all of the other locations rather than rather than this in the lower left an analogy for this is if you're thinking about how you perform a scientific experiment you would probably aim to use if you had a choice between two different measuring instruments you would choose the one that gives you more precise measurements rather than the one that gives you very noisy measurements in the lower left we've manipulated the uncertainty or the volatility associated with the dynamics so here what's happened is the upper left location is associated with much more uncertain dynamics so here what happens is that I end up sampling that upper left location much more frequently and intuitively this makes a lot of sense because if you've looked somewhere very recently normally you will you'll know a lot about what was there you don't need to look back there anytime soon however if it's very volatile if it changes quite with some degree of randomness and you have very little certainty about the state of it after you've looked away you'll look back with a much greater frequency so we've effectively decreased the inhibition of return in this location by increasing its volatility or decreasing the precision associated with its with the dynamics in that location so the end of this was just to show you this sort of emergent behavior just by having an information seeking objective by by having a prior belief that we're going to act to minimize some expected free energy one component of which is to maximize our information about the world now the next thing I want to come on to is the role of hierarchical generative models and one of the key benefits of having a hierarchical model is that we can now deal with things that evolve over a range of different timescales so you might have some things that evolve very slowly and some things that evolve very quickly and to some extent we can separate out two and use slowly evolving things to to to help us predict what's happening at the faster level and here the key things to to note are all of these connections between higher cortical regions and lower cortical regions which manifests both in the in the discrete and continuous state space models and so it's worth them thinking about what the role of these are and how that manifests in terms of the generative models we've been dealing with before and it's really this that links back into the the idea of predictive coding as many people know it and you've probably seen graphics of this sort in the past where we have a range of cortical regions that are each making predictions about the others and so here going from going from the right to the left we've got a series of predictions in as these dark black lines with prediction errors passed back up using these these dashed lines that then allow us to correct at each level and all this this graphic shows is a simplification of the graphic on on the previous slide so i want to give you an intuition for why this is useful using a couple of examples so the first example i'm going to use is one from the domain of active vision so imagine imagine you're doing a task now where you have to fixate on this cross in the center and maintain that fixation and show you a stimulus but maintain fixation on the cross. Stimulus is going to disappear and then your next task is to perform an eye movement to the location where the stimulus appeared. It's a very simple task if the sort was used frequently in monkey electrophysiology and all throughout neuroscience but it's an interesting one because it has several different components to it that i think help in terms of thinking about the utility of hierarchical models so one aspect of this is making decisions about where you're looking at each of those time points and making inferences about which of several alternative locations you're going to perform an eye movement to so simple form of planning here so that calls into into action the sort of discrete state space model that we were dealing with before this this partial observable decision process this set of discrete sequential timing points and that's often very highly relevant structure of most simple tasks in cognitive neuroscience. However we also need to actually move our eyes we need to we need to move our eyes from one location to the next we need to know how to generate forces we need to know how to make sure the eyes come to rest in the right location given those decisions and that calls into play this sort of continuous state space predictive coding style model so how do we then how do we then combine the two how do we deal with the situation where we want to predict a particular location at a discrete level one of several alternatives but then also map that to a continuous motor trajectory and this is where generative models get a little bit more complicated so taking this a bit at a time what we've got at the top here is our mark-off decision process model this is our discrete state space model in discrete time now at each of those time points we're no longer predicting data specifically we're now predicting a short trajectory formulated in terms of our continuous state space models so at time one we're now going to predict a short element of our trajectory and this is very much like the sort of clustering model I showed you much earlier that you take a discrete point and you map it to a point in continuous space with some probability at the next time we then predict the next bit of that continuous trajectory so our priors for our continuous model are now inheriting from the predictions from the discrete state space model and then we can do the same thing again at the next time point and and so we can create a discrete sequence from our our sequential model and at each point in that sequence associate that with a short trajectory in continuous space that then predicts our continuous data allowing us to then predict the proprioceptive information we would expect to get from the eyes when we're performing a task at that sort and you can see that we now develop a hierarchical structure also in thinking about the relationship between the bits of the message passing scheme so here we've got the discrete bit of our message passing scheme our discrete microcircuit and a bit of the continuous microcircuit here and the interactions between the two of those were making predictions from the discrete one to the continuous one and then passing errors backwards to allow us to to update the discrete element so interpreting this again neurobiologically you can imagine that say we have some element of the cortex perhaps the frontal eye field that's making predictions about one of several alternative locations I could direct my gaze we can then map that via sort of output of the basal ganglia and the predictions about what policy I'm going to pursue through to areas like the superior colliculus which then might make use of predictive coding style networks of the sort depicted here to then generate eye movements as we've seen before and just to show you that in action we imagine that these are population of neurons that at each time point are trying to predict one of several in this case three different locations at four different time points we can then map that through structures like the superior colliculus and this is supposed to sort of cartoon the idea of a population code in the superior colliculus but then results in the eye movement to each of those discrete locations putting it all together we can then formulate exactly the task that I asked you to perform earlier and see the result of an active infant scheme performing that task and so here you can see it performs it very successfully by predicting sequences of eye movements that are conditioned upon the discrete part of the model and the idea of maintaining this belief about where the stimulus appeared and using that then to direct my policy selection and eventually the movement I select I want to give you one more example of this sort of hierarchical scheme in the domain of motor control and appeal to the same sort of simulations we were looking at earlier in terms of the reflexes exhibited by that arm the generative model we're going to use here is a slightly complicated one but here effectively involves transitions between different locations that an arm could be in or a hand could be in which then predicts different locations in some continuous space and different locations that a target might be in and that will then allow us to make predictions about about given where some target is in some continuous space which decision I'm going to make about the alternative points I could move my arm to and so here we have the simulation where we have the target appearing as the black ball out of the out of the three balls which is going to change at various points in time and our active infant scheme is now selecting these locations translating those into predictions of continuous trajectories and making the appropriate movements such that it reaches each of these target locations and what's shown in terms of the the graphic here is also an interpretation of the message passing in terms of the known anatomy of the motor system or part of it we can perform various lesions to this and see whether they behave in the same way that we might expect patient populations to so here we've induced a cerebellar lesion which effectively involves a misestimation of certain precision terms certain confidence or variance parameters and you see this sort of overshoot and this kind of oscillatory behavior in the way the arm behaves that mimics what we might expect him as cerebellar attacks here we can look at the higher levels of the model and actually have multiple hierarchical levels of the discrete scheme and here what we've done is we've induced a lesion in what might represent a frontal lobe lesion where now the model is able to perform all the movements with perfect fluency but every time there's a change of context it takes quite a while to adjust to that new context to deal with a new situation you'll see that instead of moving straight there as it was before there's a lot more hesitancy and a lot more difficulty constructing that long-term narrative because we've broken that slower hierarchical level and here a final lesion that we can introduce is one that reduces my confidence in policy selection so here this effectively makes me very uncertain about what I'm going to do next and here we get a sort of a kinetic type picture and sort we might expect in a Parkinsonian type syndrome so I realized that was quite a lot and I hope I'm not too far over time but I'll just try and summarize briefly the key ideas that we've discussed so the first was thinking about this idea of climbing probability gradients the idea that to maintain some form over time and to persist we need to effectively be climbing these probability gradients all the time we interpreted those probability gradients in terms of in terms of Bayes theorem and connected that to the Bayes in brain and the sort of message passing that might be involved in forming inferences about elements of some generative model and the role that might have in cortical micro-circuitry we also discussed the role of action and the idea that that one way to make our model better fit the world is to act upon it and one way to do that is to simply reduce any discrepancy between the predictions from that model and the data that's coming in and the structure of that is very similar to the idea of a reflex arc as is well known throughout motor neuroscience and the final thing we thought about was how we can then construct hierarchical models that allow us to produce simulations and theories that deal with much larger scale networks in the brain and take a full sort of systems level view of how particular movements and particular behaviors are generated through the inversion of particular forms of generative model with that I'd like to thank many people who've been involved either directly or indirectly in this work and I'll mention the book again which was mentioned at the beginning and a lot of this talk was loosely following some of the structure in a couple of the chapters in the book so if anybody's interested please do take a look I'm more than happy to answer any questions thank you for your attention", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 14.32, "text": " It's a great pleasure to introduce Thomas Paar today, we'll be about his background.", "tokens": [50364, 467, 311, 257, 869, 6834, 281, 5366, 8500, 3426, 289, 965, 11, 321, 603, 312, 466, 702, 3678, 13, 51080], "temperature": 0.0, "avg_logprob": -0.3751451614055228, "compression_ratio": 1.2464788732394365, "no_speech_prob": 0.26150354743003845}, {"id": 1, "seek": 0, "start": 14.32, "end": 25.16, "text": " So he started medical school in 2012, I guess, at the UCL and did also like a bachelor there", "tokens": [51080, 407, 415, 1409, 4625, 1395, 294, 9125, 11, 286, 2041, 11, 412, 264, 14079, 43, 293, 630, 611, 411, 257, 25947, 456, 51622], "temperature": 0.0, "avg_logprob": -0.3751451614055228, "compression_ratio": 1.2464788732394365, "no_speech_prob": 0.26150354743003845}, {"id": 2, "seek": 2516, "start": 25.16, "end": 35.08, "text": " with a focus in new science. In 2016, he started his PhD, I hope everything is correct, he started", "tokens": [50364, 365, 257, 1879, 294, 777, 3497, 13, 682, 6549, 11, 415, 1409, 702, 14476, 11, 286, 1454, 1203, 307, 3006, 11, 415, 1409, 50860], "temperature": 0.0, "avg_logprob": -0.3851309556227464, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.0766948014497757}, {"id": 3, "seek": 2516, "start": 35.08, "end": 45.400000000000006, "text": " his PhD working together with Carl Friston and Garen Rees. So I think Thomas is really like the", "tokens": [50860, 702, 14476, 1364, 1214, 365, 14256, 1526, 47345, 293, 460, 4484, 1300, 279, 13, 407, 286, 519, 8500, 307, 534, 411, 264, 51376], "temperature": 0.0, "avg_logprob": -0.3851309556227464, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.0766948014497757}, {"id": 4, "seek": 2516, "start": 45.400000000000006, "end": 53.519999999999996, "text": " person who most frustrated me, when I was at the at the Philly, so a long time ago. I was fascinated", "tokens": [51376, 954, 567, 881, 15751, 385, 11, 562, 286, 390, 412, 264, 412, 264, 2623, 6917, 11, 370, 257, 938, 565, 2057, 13, 286, 390, 24597, 51782], "temperature": 0.0, "avg_logprob": -0.3851309556227464, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.0766948014497757}, {"id": 5, "seek": 5352, "start": 53.52, "end": 61.400000000000006, "text": " by like the idea of the free entry principle and Carl Friston and really started going, learning", "tokens": [50364, 538, 411, 264, 1558, 295, 264, 1737, 8729, 8665, 293, 14256, 1526, 47345, 293, 534, 1409, 516, 11, 2539, 50758], "temperature": 0.0, "avg_logprob": -0.25411507742745537, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.011362788267433643}, {"id": 6, "seek": 5352, "start": 61.400000000000006, "end": 69.48, "text": " about Boltzmann equations and some kind of like message passing and so on and over years and years.", "tokens": [50758, 466, 37884, 89, 14912, 11787, 293, 512, 733, 295, 411, 3636, 8437, 293, 370, 322, 293, 670, 924, 293, 924, 13, 51162], "temperature": 0.0, "avg_logprob": -0.25411507742745537, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.011362788267433643}, {"id": 7, "seek": 5352, "start": 69.48, "end": 80.60000000000001, "text": " And then in 2016-17, I realized that suddenly a number of papers were coming out, it became much", "tokens": [51162, 400, 550, 294, 6549, 12, 7773, 11, 286, 5334, 300, 5800, 257, 1230, 295, 10577, 645, 1348, 484, 11, 309, 3062, 709, 51718], "temperature": 0.0, "avg_logprob": -0.25411507742745537, "compression_ratio": 1.47979797979798, "no_speech_prob": 0.011362788267433643}, {"id": 8, "seek": 8060, "start": 80.67999999999999, "end": 88.11999999999999, "text": " more accessible and on these papers there were always like one name, Thomas Paar. And so I looked", "tokens": [50368, 544, 9515, 293, 322, 613, 10577, 456, 645, 1009, 411, 472, 1315, 11, 8500, 3426, 289, 13, 400, 370, 286, 2956, 50740], "temperature": 0.0, "avg_logprob": -0.23402457450752828, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.03208032622933388}, {"id": 9, "seek": 8060, "start": 88.11999999999999, "end": 95.24, "text": " into that and I realized that there is one person out there who is so young and who plus", "tokens": [50740, 666, 300, 293, 286, 5334, 300, 456, 307, 472, 954, 484, 456, 567, 307, 370, 2037, 293, 567, 1804, 51096], "temperature": 0.0, "avg_logprob": -0.23402457450752828, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.03208032622933388}, {"id": 10, "seek": 8060, "start": 95.24, "end": 106.03999999999999, "text": " started his PhD, who was able to go all through this extremely complicated math and ideas so easily", "tokens": [51096, 1409, 702, 14476, 11, 567, 390, 1075, 281, 352, 439, 807, 341, 4664, 6179, 5221, 293, 3487, 370, 3612, 51636], "temperature": 0.0, "avg_logprob": -0.23402457450752828, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.03208032622933388}, {"id": 11, "seek": 10604, "start": 106.52000000000001, "end": 113.0, "text": " that I thought I should really give up thinking about the free energy principle at all. And more", "tokens": [50388, 300, 286, 1194, 286, 820, 534, 976, 493, 1953, 466, 264, 1737, 2281, 8665, 412, 439, 13, 400, 544, 50712], "temperature": 0.0, "avg_logprob": -0.1614246578006954, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.018989035859704018}, {"id": 12, "seek": 10604, "start": 113.0, "end": 119.24000000000001, "text": " impressively, I think a couple of months ago, even like a book came out like about like Active", "tokens": [50712, 6729, 3413, 11, 286, 519, 257, 1916, 295, 2493, 2057, 11, 754, 411, 257, 1446, 1361, 484, 411, 466, 411, 26635, 51024], "temperature": 0.0, "avg_logprob": -0.1614246578006954, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.018989035859704018}, {"id": 13, "seek": 10604, "start": 119.24000000000001, "end": 127.32000000000001, "text": " Influence, where he is like the first author on and I really can recommend this book. It's a", "tokens": [51024, 11537, 40432, 11, 689, 415, 307, 411, 264, 700, 3793, 322, 293, 286, 534, 393, 2748, 341, 1446, 13, 467, 311, 257, 51428], "temperature": 0.0, "avg_logprob": -0.1614246578006954, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.018989035859704018}, {"id": 14, "seek": 10604, "start": 127.32000000000001, "end": 133.24, "text": " fantastic introduction to Active Influence, to the free energy principle. So it's a really,", "tokens": [51428, 5456, 9339, 281, 26635, 11537, 40432, 11, 281, 264, 1737, 2281, 8665, 13, 407, 309, 311, 257, 534, 11, 51724], "temperature": 0.0, "avg_logprob": -0.1614246578006954, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.018989035859704018}, {"id": 15, "seek": 13324, "start": 133.24, "end": 140.68, "text": " really great pleasure to have you here tonight, Thomas, and I'm really looking forward to your", "tokens": [50364, 534, 869, 6834, 281, 362, 291, 510, 4440, 11, 8500, 11, 293, 286, 478, 534, 1237, 2128, 281, 428, 50736], "temperature": 0.0, "avg_logprob": -0.17128148760114398, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.004243823233991861}, {"id": 16, "seek": 13324, "start": 140.68, "end": 149.96, "text": " talk. Thanks for joining. Well, thank you very much for the very nice invitation and the very", "tokens": [50736, 751, 13, 2561, 337, 5549, 13, 1042, 11, 1309, 291, 588, 709, 337, 264, 588, 1481, 17890, 293, 264, 588, 51200], "temperature": 0.0, "avg_logprob": -0.17128148760114398, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.004243823233991861}, {"id": 17, "seek": 13324, "start": 149.96, "end": 159.32000000000002, "text": " nice introduction as well. First of all, can you hear me okay? Yes. And next thing is to see", "tokens": [51200, 1481, 9339, 382, 731, 13, 2386, 295, 439, 11, 393, 291, 1568, 385, 1392, 30, 1079, 13, 400, 958, 551, 307, 281, 536, 51668], "temperature": 0.0, "avg_logprob": -0.17128148760114398, "compression_ratio": 1.518918918918919, "no_speech_prob": 0.004243823233991861}, {"id": 18, "seek": 15932, "start": 159.32, "end": 168.12, "text": " whether I can successfully share my screen. Let's try this. So I'm assuming you can see the", "tokens": [50364, 1968, 286, 393, 10727, 2073, 452, 2568, 13, 961, 311, 853, 341, 13, 407, 286, 478, 11926, 291, 393, 536, 264, 50804], "temperature": 0.0, "avg_logprob": -0.1051986044731693, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.0390281118452549}, {"id": 19, "seek": 15932, "start": 168.12, "end": 178.12, "text": " PowerPoint and now hopefully in full screen. Perfect. Great. So today, I realized that you've", "tokens": [50804, 25584, 293, 586, 4696, 294, 1577, 2568, 13, 10246, 13, 3769, 13, 407, 965, 11, 286, 5334, 300, 291, 600, 51304], "temperature": 0.0, "avg_logprob": -0.1051986044731693, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.0390281118452549}, {"id": 20, "seek": 15932, "start": 178.12, "end": 185.64, "text": " already had a talk from Ryan Smith previously, so I'm assuming he's given an excellent overview of", "tokens": [51304, 1217, 632, 257, 751, 490, 9116, 8538, 8046, 11, 370, 286, 478, 11926, 415, 311, 2212, 364, 7103, 12492, 295, 51680], "temperature": 0.0, "avg_logprob": -0.1051986044731693, "compression_ratio": 1.4564102564102563, "no_speech_prob": 0.0390281118452549}, {"id": 21, "seek": 18564, "start": 185.64, "end": 191.88, "text": " Active Influences as he always does. And I wanted to take the opportunity to focus in on something", "tokens": [50364, 26635, 11537, 2781, 2667, 382, 415, 1009, 775, 13, 400, 286, 1415, 281, 747, 264, 2650, 281, 1879, 294, 322, 746, 50676], "temperature": 0.0, "avg_logprob": -0.07828335926450532, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.02221532166004181}, {"id": 22, "seek": 18564, "start": 191.88, "end": 199.79999999999998, "text": " a little bit more specific in this talk, which is thinking about how dealing with Active Influence", "tokens": [50676, 257, 707, 857, 544, 2685, 294, 341, 751, 11, 597, 307, 1953, 466, 577, 6260, 365, 26635, 11537, 40432, 51072], "temperature": 0.0, "avg_logprob": -0.07828335926450532, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.02221532166004181}, {"id": 23, "seek": 18564, "start": 199.79999999999998, "end": 205.64, "text": " lets us think about neurobiology and how we can start to make connections and form neurobiological", "tokens": [51072, 6653, 505, 519, 466, 16499, 5614, 1793, 293, 577, 321, 393, 722, 281, 652, 9271, 293, 1254, 16499, 5614, 4383, 51364], "temperature": 0.0, "avg_logprob": -0.07828335926450532, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.02221532166004181}, {"id": 24, "seek": 18564, "start": 205.64, "end": 214.35999999999999, "text": " theories from the principles. So I'll start just by giving an introduction that I think", "tokens": [51364, 13667, 490, 264, 9156, 13, 407, 286, 603, 722, 445, 538, 2902, 364, 9339, 300, 286, 519, 51800], "temperature": 0.0, "avg_logprob": -0.07828335926450532, "compression_ratio": 1.641025641025641, "no_speech_prob": 0.02221532166004181}, {"id": 25, "seek": 21436, "start": 214.44000000000003, "end": 219.16000000000003, "text": " will hopefully give everybody a little bit of a refresher on Active Influence and the basic", "tokens": [50368, 486, 4696, 976, 2201, 257, 707, 857, 295, 257, 17368, 511, 322, 26635, 11537, 40432, 293, 264, 3875, 50604], "temperature": 0.0, "avg_logprob": -0.06602959973471505, "compression_ratio": 1.6505190311418685, "no_speech_prob": 0.028585221618413925}, {"id": 26, "seek": 21436, "start": 219.16000000000003, "end": 224.44000000000003, "text": " principles. And although there are some technical elements to it, I'll try to make it as intuitive", "tokens": [50604, 9156, 13, 400, 4878, 456, 366, 512, 6191, 4959, 281, 309, 11, 286, 603, 853, 281, 652, 309, 382, 21769, 50868], "temperature": 0.0, "avg_logprob": -0.06602959973471505, "compression_ratio": 1.6505190311418685, "no_speech_prob": 0.028585221618413925}, {"id": 27, "seek": 21436, "start": 224.44000000000003, "end": 228.76000000000002, "text": " as possible. And it really doesn't matter if you get all the technical detail through this,", "tokens": [50868, 382, 1944, 13, 400, 309, 534, 1177, 380, 1871, 498, 291, 483, 439, 264, 6191, 2607, 807, 341, 11, 51084], "temperature": 0.0, "avg_logprob": -0.06602959973471505, "compression_ratio": 1.6505190311418685, "no_speech_prob": 0.028585221618413925}, {"id": 28, "seek": 21436, "start": 228.76000000000002, "end": 236.68, "text": " it's just to build some intuitions. So I tend to like to start talks with this slide, which just", "tokens": [51084, 309, 311, 445, 281, 1322, 512, 16224, 626, 13, 407, 286, 3928, 281, 411, 281, 722, 6686, 365, 341, 4137, 11, 597, 445, 51480], "temperature": 0.0, "avg_logprob": -0.06602959973471505, "compression_ratio": 1.6505190311418685, "no_speech_prob": 0.028585221618413925}, {"id": 29, "seek": 21436, "start": 236.68, "end": 243.32000000000002, "text": " shows two different sorts of system. The one on the left is one that just gradually diffuses over", "tokens": [51480, 3110, 732, 819, 7527, 295, 1185, 13, 440, 472, 322, 264, 1411, 307, 472, 300, 445, 13145, 7593, 8355, 670, 51812], "temperature": 0.0, "avg_logprob": -0.06602959973471505, "compression_ratio": 1.6505190311418685, "no_speech_prob": 0.028585221618413925}, {"id": 30, "seek": 24332, "start": 243.32, "end": 248.92, "text": " time, sort of loses form becomes progressively less interesting. Whereas the one on the right,", "tokens": [50364, 565, 11, 1333, 295, 18293, 1254, 3643, 46667, 1570, 1880, 13, 13813, 264, 472, 322, 264, 558, 11, 50644], "temperature": 0.0, "avg_logprob": -0.07197918126612533, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0067947031930089}, {"id": 31, "seek": 24332, "start": 248.92, "end": 253.79999999999998, "text": " despite having the same amount of randomness built into it, manages to maintain its form over time.", "tokens": [50644, 7228, 1419, 264, 912, 2372, 295, 4974, 1287, 3094, 666, 309, 11, 22489, 281, 6909, 1080, 1254, 670, 565, 13, 50888], "temperature": 0.0, "avg_logprob": -0.07197918126612533, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0067947031930089}, {"id": 32, "seek": 24332, "start": 254.51999999999998, "end": 259.08, "text": " And a useful starting point in thinking about Active Influence is thinking about", "tokens": [50924, 400, 257, 4420, 2891, 935, 294, 1953, 466, 26635, 11537, 40432, 307, 1953, 466, 51152], "temperature": 0.0, "avg_logprob": -0.07197918126612533, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0067947031930089}, {"id": 33, "seek": 24332, "start": 259.71999999999997, "end": 265.8, "text": " what the difference between these two sorts of systems are and how the one on the right is able", "tokens": [51184, 437, 264, 2649, 1296, 613, 732, 7527, 295, 3652, 366, 293, 577, 264, 472, 322, 264, 558, 307, 1075, 51488], "temperature": 0.0, "avg_logprob": -0.07197918126612533, "compression_ratio": 1.6787330316742082, "no_speech_prob": 0.0067947031930089}, {"id": 34, "seek": 26580, "start": 265.8, "end": 274.12, "text": " to maintain its form and resist the effect of these random fluctuations that are forcing it", "tokens": [50364, 281, 6909, 1080, 1254, 293, 4597, 264, 1802, 295, 613, 4974, 45276, 300, 366, 19030, 309, 50780], "temperature": 0.0, "avg_logprob": -0.07924558531563237, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.10406651347875595}, {"id": 35, "seek": 26580, "start": 274.12, "end": 280.76, "text": " in all sorts of different directions. And it's often useful to reformulate this in terms of the", "tokens": [50780, 294, 439, 7527, 295, 819, 11095, 13, 400, 309, 311, 2049, 4420, 281, 8290, 5256, 341, 294, 2115, 295, 264, 51112], "temperature": 0.0, "avg_logprob": -0.07924558531563237, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.10406651347875595}, {"id": 36, "seek": 26580, "start": 280.76, "end": 286.52, "text": " probability density or the change in the probability distribution of all of these little particles", "tokens": [51112, 8482, 10305, 420, 264, 1319, 294, 264, 8482, 7316, 295, 439, 295, 613, 707, 10007, 51400], "temperature": 0.0, "avg_logprob": -0.07924558531563237, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.10406651347875595}, {"id": 37, "seek": 26580, "start": 286.52, "end": 290.12, "text": " over time. So again, you can see on the left, we've got something that's just diffusing out into", "tokens": [51400, 670, 565, 13, 407, 797, 11, 291, 393, 536, 322, 264, 1411, 11, 321, 600, 658, 746, 300, 311, 445, 7593, 7981, 484, 666, 51580], "temperature": 0.0, "avg_logprob": -0.07924558531563237, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.10406651347875595}, {"id": 38, "seek": 26580, "start": 290.12, "end": 295.08000000000004, "text": " nothing. And on the right, we get something that behaves from a probabilistic level pretty much", "tokens": [51580, 1825, 13, 400, 322, 264, 558, 11, 321, 483, 746, 300, 36896, 490, 257, 31959, 3142, 1496, 1238, 709, 51828], "temperature": 0.0, "avg_logprob": -0.07924558531563237, "compression_ratio": 1.7545787545787546, "no_speech_prob": 0.10406651347875595}, {"id": 39, "seek": 29508, "start": 295.08, "end": 301.08, "text": " statically. And it's really those on the right that we're interested in, those biological creatures", "tokens": [50364, 2219, 984, 13, 400, 309, 311, 534, 729, 322, 264, 558, 300, 321, 434, 3102, 294, 11, 729, 13910, 12281, 50664], "temperature": 0.0, "avg_logprob": -0.09288788685756447, "compression_ratio": 1.7802197802197801, "no_speech_prob": 0.0008918488747440279}, {"id": 40, "seek": 29508, "start": 301.08, "end": 305.56, "text": " are able to maintain their form, are able to resist the effects of what the environment does to them.", "tokens": [50664, 366, 1075, 281, 6909, 641, 1254, 11, 366, 1075, 281, 4597, 264, 5065, 295, 437, 264, 2823, 775, 281, 552, 13, 50888], "temperature": 0.0, "avg_logprob": -0.09288788685756447, "compression_ratio": 1.7802197802197801, "no_speech_prob": 0.0008918488747440279}, {"id": 41, "seek": 29508, "start": 306.59999999999997, "end": 311.08, "text": " Now, if we sort of write down the kinds of dynamics that we'd need for a single particle", "tokens": [50940, 823, 11, 498, 321, 1333, 295, 2464, 760, 264, 3685, 295, 15679, 300, 321, 1116, 643, 337, 257, 2167, 12359, 51164], "temperature": 0.0, "avg_logprob": -0.09288788685756447, "compression_ratio": 1.7802197802197801, "no_speech_prob": 0.0008918488747440279}, {"id": 42, "seek": 29508, "start": 311.08, "end": 317.08, "text": " or a single part of the system to try and maintain this form, what we get to is a system that I think", "tokens": [51164, 420, 257, 2167, 644, 295, 264, 1185, 281, 853, 293, 6909, 341, 1254, 11, 437, 321, 483, 281, 307, 257, 1185, 300, 286, 519, 51464], "temperature": 0.0, "avg_logprob": -0.09288788685756447, "compression_ratio": 1.7802197802197801, "no_speech_prob": 0.0008918488747440279}, {"id": 43, "seek": 29508, "start": 317.08, "end": 323.71999999999997, "text": " quite intuitively always moves when it can from regions of low probability to regions of high", "tokens": [51464, 1596, 46506, 1009, 6067, 562, 309, 393, 490, 10682, 295, 2295, 8482, 281, 10682, 295, 1090, 51796], "temperature": 0.0, "avg_logprob": -0.09288788685756447, "compression_ratio": 1.7802197802197801, "no_speech_prob": 0.0008918488747440279}, {"id": 44, "seek": 32372, "start": 323.72, "end": 328.44000000000005, "text": " probability. So if we interpret this final distribution it gets to as some steady state,", "tokens": [50364, 8482, 13, 407, 498, 321, 7302, 341, 2572, 7316, 309, 2170, 281, 382, 512, 13211, 1785, 11, 50600], "temperature": 0.0, "avg_logprob": -0.07862154337076041, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.006191295105963945}, {"id": 45, "seek": 32372, "start": 329.24, "end": 334.28000000000003, "text": " all we need to do to maintain that in a random environment is to always try and climb uphill", "tokens": [50640, 439, 321, 643, 281, 360, 281, 6909, 300, 294, 257, 4974, 2823, 307, 281, 1009, 853, 293, 10724, 39132, 50892], "temperature": 0.0, "avg_logprob": -0.07862154337076041, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.006191295105963945}, {"id": 46, "seek": 32372, "start": 334.28000000000003, "end": 338.52000000000004, "text": " at the probability gradients. And then almost by definition, we end up spending more time in", "tokens": [50892, 412, 264, 8482, 2771, 2448, 13, 400, 550, 1920, 538, 7123, 11, 321, 917, 493, 6434, 544, 565, 294, 51104], "temperature": 0.0, "avg_logprob": -0.07862154337076041, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.006191295105963945}, {"id": 47, "seek": 32372, "start": 338.52000000000004, "end": 345.48, "text": " highly probable states and less time in more improbable states. And this is sort of the starting", "tokens": [51104, 5405, 21759, 4368, 293, 1570, 565, 294, 544, 2530, 65, 712, 4368, 13, 400, 341, 307, 1333, 295, 264, 2891, 51452], "temperature": 0.0, "avg_logprob": -0.07862154337076041, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.006191295105963945}, {"id": 48, "seek": 32372, "start": 345.48, "end": 350.84000000000003, "text": " point really for active inference, because we now have this notion that we're climbing probability", "tokens": [51452, 935, 534, 337, 4967, 38253, 11, 570, 321, 586, 362, 341, 10710, 300, 321, 434, 14780, 8482, 51720], "temperature": 0.0, "avg_logprob": -0.07862154337076041, "compression_ratio": 1.7472118959107807, "no_speech_prob": 0.006191295105963945}, {"id": 49, "seek": 35084, "start": 350.84, "end": 355.23999999999995, "text": " gradients and we have some distribution that we're effectively trying to maximize.", "tokens": [50364, 2771, 2448, 293, 321, 362, 512, 7316, 300, 321, 434, 8659, 1382, 281, 19874, 13, 50584], "temperature": 0.0, "avg_logprob": -0.10381976667656956, "compression_ratio": 1.65, "no_speech_prob": 0.004161214921623468}, {"id": 50, "seek": 35084, "start": 356.2, "end": 362.59999999999997, "text": " And we can link that back to ideas like the Bayesian brain, the idea that the brain is using some", "tokens": [50632, 400, 321, 393, 2113, 300, 646, 281, 3487, 411, 264, 7840, 42434, 3567, 11, 264, 1558, 300, 264, 3567, 307, 1228, 512, 50952], "temperature": 0.0, "avg_logprob": -0.10381976667656956, "compression_ratio": 1.65, "no_speech_prob": 0.004161214921623468}, {"id": 51, "seek": 35084, "start": 362.59999999999997, "end": 370.2, "text": " model of the world around it to generate predictions. And then is drawing inferences about", "tokens": [50952, 2316, 295, 264, 1002, 926, 309, 281, 8460, 21264, 13, 400, 550, 307, 6316, 13596, 2667, 466, 51332], "temperature": 0.0, "avg_logprob": -0.10381976667656956, "compression_ratio": 1.65, "no_speech_prob": 0.004161214921623468}, {"id": 52, "seek": 35084, "start": 370.2, "end": 375.47999999999996, "text": " the data that it actually obtains, so sensory information coming in through our eyes, ears,", "tokens": [51332, 264, 1412, 300, 309, 767, 7464, 2315, 11, 370, 27233, 1589, 1348, 294, 807, 527, 2575, 11, 8798, 11, 51596], "temperature": 0.0, "avg_logprob": -0.10381976667656956, "compression_ratio": 1.65, "no_speech_prob": 0.004161214921623468}, {"id": 53, "seek": 37548, "start": 375.48, "end": 380.84000000000003, "text": " through our skin, that we can then use to draw inferences about the causes of those data.", "tokens": [50364, 807, 527, 3178, 11, 300, 321, 393, 550, 764, 281, 2642, 13596, 2667, 466, 264, 7700, 295, 729, 1412, 13, 50632], "temperature": 0.0, "avg_logprob": -0.0950515872829563, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.016780318692326546}, {"id": 54, "seek": 37548, "start": 382.44, "end": 386.92, "text": " So here we've got the idea that there's some states of the world X that are causing some", "tokens": [50712, 407, 510, 321, 600, 658, 264, 1558, 300, 456, 311, 512, 4368, 295, 264, 1002, 1783, 300, 366, 9853, 512, 50936], "temperature": 0.0, "avg_logprob": -0.0950515872829563, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.016780318692326546}, {"id": 55, "seek": 37548, "start": 386.92, "end": 394.6, "text": " sensory data Y. We're then forming some posterior beliefs, so beliefs about the causes given with", "tokens": [50936, 27233, 1412, 398, 13, 492, 434, 550, 15745, 512, 33529, 13585, 11, 370, 13585, 466, 264, 7700, 2212, 365, 51320], "temperature": 0.0, "avg_logprob": -0.0950515872829563, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.016780318692326546}, {"id": 56, "seek": 37548, "start": 394.6, "end": 401.48, "text": " the data. And we're doing this using a generative model that comprises a likelihood in a prior,", "tokens": [51320, 264, 1412, 13, 400, 321, 434, 884, 341, 1228, 257, 1337, 1166, 2316, 300, 16802, 3598, 257, 22119, 294, 257, 4059, 11, 51664], "temperature": 0.0, "avg_logprob": -0.0950515872829563, "compression_ratio": 1.7064220183486238, "no_speech_prob": 0.016780318692326546}, {"id": 57, "seek": 40148, "start": 401.48, "end": 405.24, "text": " so prior being how plausible are the things out there in the world before we've", "tokens": [50364, 370, 4059, 885, 577, 39925, 366, 264, 721, 484, 456, 294, 264, 1002, 949, 321, 600, 50552], "temperature": 0.0, "avg_logprob": -0.08483384052912395, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.0005354441818781197}, {"id": 58, "seek": 40148, "start": 405.24, "end": 411.16, "text": " made any observations. The likelihood being how likely the observations we've made are given", "tokens": [50552, 1027, 604, 18163, 13, 440, 22119, 885, 577, 3700, 264, 18163, 321, 600, 1027, 366, 2212, 50848], "temperature": 0.0, "avg_logprob": -0.08483384052912395, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.0005354441818781197}, {"id": 59, "seek": 40148, "start": 411.16, "end": 416.04, "text": " the states of the world or given our hypotheses about what caused them. And together we refer", "tokens": [50848, 264, 4368, 295, 264, 1002, 420, 2212, 527, 49969, 466, 437, 7008, 552, 13, 400, 1214, 321, 2864, 51092], "temperature": 0.0, "avg_logprob": -0.08483384052912395, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.0005354441818781197}, {"id": 60, "seek": 40148, "start": 416.04, "end": 421.8, "text": " to these two things as a generative model. Now the posterior distribution is what happens when", "tokens": [51092, 281, 613, 732, 721, 382, 257, 1337, 1166, 2316, 13, 823, 264, 33529, 7316, 307, 437, 2314, 562, 51380], "temperature": 0.0, "avg_logprob": -0.08483384052912395, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.0005354441818781197}, {"id": 61, "seek": 40148, "start": 421.8, "end": 428.12, "text": " we invert that model where we find the probability of some causes given the data.", "tokens": [51380, 321, 33966, 300, 2316, 689, 321, 915, 264, 8482, 295, 512, 7700, 2212, 264, 1412, 13, 51696], "temperature": 0.0, "avg_logprob": -0.08483384052912395, "compression_ratio": 1.8008130081300813, "no_speech_prob": 0.0005354441818781197}, {"id": 62, "seek": 42812, "start": 429.08, "end": 434.12, "text": " And the final term we've got at the end here is referred to either as an evidence or a marginal", "tokens": [50412, 400, 264, 2572, 1433, 321, 600, 658, 412, 264, 917, 510, 307, 10839, 281, 2139, 382, 364, 4467, 420, 257, 16885, 50664], "temperature": 0.0, "avg_logprob": -0.09470139888294957, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.0018808090826496482}, {"id": 63, "seek": 42812, "start": 434.12, "end": 439.08, "text": " likelihood. And that's because in the context of Bayesian statistics we often use a marginal", "tokens": [50664, 22119, 13, 400, 300, 311, 570, 294, 264, 4319, 295, 7840, 42434, 12523, 321, 2049, 764, 257, 16885, 50912], "temperature": 0.0, "avg_logprob": -0.09470139888294957, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.0018808090826496482}, {"id": 64, "seek": 42812, "start": 439.08, "end": 445.4, "text": " likelihood as a measure of the fit of a model to the data that it's trying to explain. There's", "tokens": [50912, 22119, 382, 257, 3481, 295, 264, 3318, 295, 257, 2316, 281, 264, 1412, 300, 309, 311, 1382, 281, 2903, 13, 821, 311, 51228], "temperature": 0.0, "avg_logprob": -0.09470139888294957, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.0018808090826496482}, {"id": 65, "seek": 42812, "start": 445.4, "end": 451.08, "text": " how much evidence do those data afford some model of the world. And together we can think of these", "tokens": [51228, 577, 709, 4467, 360, 729, 1412, 6157, 512, 2316, 295, 264, 1002, 13, 400, 1214, 321, 393, 519, 295, 613, 51512], "temperature": 0.0, "avg_logprob": -0.09470139888294957, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.0018808090826496482}, {"id": 66, "seek": 42812, "start": 451.08, "end": 455.96, "text": " as being an inversion of the generative model. Now the reason I've put this here is that we", "tokens": [51512, 382, 885, 364, 43576, 295, 264, 1337, 1166, 2316, 13, 823, 264, 1778, 286, 600, 829, 341, 510, 307, 300, 321, 51756], "temperature": 0.0, "avg_logprob": -0.09470139888294957, "compression_ratio": 1.8091603053435115, "no_speech_prob": 0.0018808090826496482}, {"id": 67, "seek": 45596, "start": 455.96, "end": 463.88, "text": " can see that the dynamics that I'm showing in the upper left can be interpreted as the process of", "tokens": [50364, 393, 536, 300, 264, 15679, 300, 286, 478, 4099, 294, 264, 6597, 1411, 393, 312, 26749, 382, 264, 1399, 295, 50760], "temperature": 0.0, "avg_logprob": -0.07063258730846902, "compression_ratio": 1.7455357142857142, "no_speech_prob": 0.0018573413835838437}, {"id": 68, "seek": 45596, "start": 463.88, "end": 468.84, "text": " maximising the evidence for some model, maximising the fit between the brain's model of how the world", "tokens": [50760, 5138, 3436, 264, 4467, 337, 512, 2316, 11, 5138, 3436, 264, 3318, 1296, 264, 3567, 311, 2316, 295, 577, 264, 1002, 51008], "temperature": 0.0, "avg_logprob": -0.07063258730846902, "compression_ratio": 1.7455357142857142, "no_speech_prob": 0.0018573413835838437}, {"id": 69, "seek": 45596, "start": 468.84, "end": 475.4, "text": " works and how the world then engages with the model or engages with the brain by presenting it data.", "tokens": [51008, 1985, 293, 577, 264, 1002, 550, 45576, 365, 264, 2316, 420, 45576, 365, 264, 3567, 538, 15578, 309, 1412, 13, 51336], "temperature": 0.0, "avg_logprob": -0.07063258730846902, "compression_ratio": 1.7455357142857142, "no_speech_prob": 0.0018573413835838437}, {"id": 70, "seek": 45596, "start": 476.76, "end": 481.32, "text": " And broadly there are two ways of doing that. The first is, as we've already spoken about,", "tokens": [51404, 400, 19511, 456, 366, 732, 2098, 295, 884, 300, 13, 440, 700, 307, 11, 382, 321, 600, 1217, 10759, 466, 11, 51632], "temperature": 0.0, "avg_logprob": -0.07063258730846902, "compression_ratio": 1.7455357142857142, "no_speech_prob": 0.0018573413835838437}, {"id": 71, "seek": 48132, "start": 481.32, "end": 485.88, "text": " it's changing your beliefs based upon new data such that you get a better fit to the world.", "tokens": [50364, 309, 311, 4473, 428, 13585, 2361, 3564, 777, 1412, 1270, 300, 291, 483, 257, 1101, 3318, 281, 264, 1002, 13, 50592], "temperature": 0.0, "avg_logprob": -0.06496642543151315, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.004640546161681414}, {"id": 72, "seek": 48132, "start": 486.68, "end": 491.48, "text": " The other way, which I think is one of the key ideas in Active Inference, is that you", "tokens": [50632, 440, 661, 636, 11, 597, 286, 519, 307, 472, 295, 264, 2141, 3487, 294, 26635, 682, 5158, 11, 307, 300, 291, 50872], "temperature": 0.0, "avg_logprob": -0.06496642543151315, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.004640546161681414}, {"id": 73, "seek": 48132, "start": 491.48, "end": 496.36, "text": " generate actions based upon your beliefs that change the world to make it more like your model.", "tokens": [50872, 8460, 5909, 2361, 3564, 428, 13585, 300, 1319, 264, 1002, 281, 652, 309, 544, 411, 428, 2316, 13, 51116], "temperature": 0.0, "avg_logprob": -0.06496642543151315, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.004640546161681414}, {"id": 74, "seek": 48132, "start": 497.88, "end": 503.15999999999997, "text": " And this is sort of the key idea that underwrites Active Inference, that all we're trying to do", "tokens": [51192, 400, 341, 307, 1333, 295, 264, 2141, 1558, 300, 833, 86, 30931, 26635, 682, 5158, 11, 300, 439, 321, 434, 1382, 281, 360, 51456], "temperature": 0.0, "avg_logprob": -0.06496642543151315, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.004640546161681414}, {"id": 75, "seek": 48132, "start": 503.15999999999997, "end": 508.68, "text": " is maximise the evidence for some model of our world. And we can either do that through", "tokens": [51456, 307, 5138, 908, 264, 4467, 337, 512, 2316, 295, 527, 1002, 13, 400, 321, 393, 2139, 360, 300, 807, 51732], "temperature": 0.0, "avg_logprob": -0.06496642543151315, "compression_ratio": 1.8207171314741035, "no_speech_prob": 0.004640546161681414}, {"id": 76, "seek": 50868, "start": 508.68, "end": 514.36, "text": " perception by changing our model or through action by changing the world. But together,", "tokens": [50364, 12860, 538, 4473, 527, 2316, 420, 807, 3069, 538, 4473, 264, 1002, 13, 583, 1214, 11, 50648], "temperature": 0.0, "avg_logprob": -0.1690261069308506, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0042285798117518425}, {"id": 77, "seek": 50868, "start": 514.36, "end": 520.2, "text": " they come under one single objective, sometimes referred to, particularly by people like Kevin", "tokens": [50648, 436, 808, 833, 472, 2167, 10024, 11, 2171, 10839, 281, 11, 4098, 538, 561, 411, 9954, 50940], "temperature": 0.0, "avg_logprob": -0.1690261069308506, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0042285798117518425}, {"id": 78, "seek": 50868, "start": 520.2, "end": 528.12, "text": " the Acapoway, as self-evidencing. Now I want to go a little bit into the structure of generative", "tokens": [50940, 264, 316, 9485, 305, 320, 11, 382, 2698, 12, 13379, 4380, 2175, 13, 823, 286, 528, 281, 352, 257, 707, 857, 666, 264, 3877, 295, 1337, 1166, 51336], "temperature": 0.0, "avg_logprob": -0.1690261069308506, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0042285798117518425}, {"id": 79, "seek": 50868, "start": 528.12, "end": 533.5600000000001, "text": " models and specifically the ways we can think about and the ways we can notate generative models,", "tokens": [51336, 5245, 293, 4682, 264, 2098, 321, 393, 519, 466, 293, 264, 2098, 321, 393, 406, 473, 1337, 1166, 5245, 11, 51608], "temperature": 0.0, "avg_logprob": -0.1690261069308506, "compression_ratio": 1.6830357142857142, "no_speech_prob": 0.0042285798117518425}, {"id": 80, "seek": 53356, "start": 534.4399999999999, "end": 539.2399999999999, "text": " because it often helps to move from the slightly more mathematical abstract description to a more", "tokens": [50408, 570, 309, 2049, 3665, 281, 1286, 490, 264, 4748, 544, 18894, 12649, 3855, 281, 257, 544, 50648], "temperature": 0.0, "avg_logprob": -0.08371919115013052, "compression_ratio": 1.7302158273381294, "no_speech_prob": 0.02799641527235508}, {"id": 81, "seek": 53356, "start": 539.2399999999999, "end": 544.4399999999999, "text": " graphical notation that I think often gives a much better intuitive sense of what's going on.", "tokens": [50648, 35942, 24657, 300, 286, 519, 2049, 2709, 257, 709, 1101, 21769, 2020, 295, 437, 311, 516, 322, 13, 50908], "temperature": 0.0, "avg_logprob": -0.08371919115013052, "compression_ratio": 1.7302158273381294, "no_speech_prob": 0.02799641527235508}, {"id": 82, "seek": 53356, "start": 545.2399999999999, "end": 550.28, "text": " So to do that, I'm going to start with this idea that model evidence is effectively what we get out", "tokens": [50948, 407, 281, 360, 300, 11, 286, 478, 516, 281, 722, 365, 341, 1558, 300, 2316, 4467, 307, 8659, 437, 321, 483, 484, 51200], "temperature": 0.0, "avg_logprob": -0.08371919115013052, "compression_ratio": 1.7302158273381294, "no_speech_prob": 0.02799641527235508}, {"id": 83, "seek": 53356, "start": 550.28, "end": 556.92, "text": " once we've integrated out all of the causes from our model, by which I mean if you take", "tokens": [51200, 1564, 321, 600, 10919, 484, 439, 295, 264, 7700, 490, 527, 2316, 11, 538, 597, 286, 914, 498, 291, 747, 51532], "temperature": 0.0, "avg_logprob": -0.08371919115013052, "compression_ratio": 1.7302158273381294, "no_speech_prob": 0.02799641527235508}, {"id": 84, "seek": 53356, "start": 556.92, "end": 562.4399999999999, "text": " account of all of the things our model predicts and then we take into account the prior probabilities", "tokens": [51532, 2696, 295, 439, 295, 264, 721, 527, 2316, 6069, 82, 293, 550, 321, 747, 666, 2696, 264, 4059, 33783, 51808], "temperature": 0.0, "avg_logprob": -0.08371919115013052, "compression_ratio": 1.7302158273381294, "no_speech_prob": 0.02799641527235508}, {"id": 85, "seek": 56244, "start": 562.44, "end": 569.1600000000001, "text": " of all of the things that are causing those data, we can then work out what the probability of the", "tokens": [50364, 295, 439, 295, 264, 721, 300, 366, 9853, 729, 1412, 11, 321, 393, 550, 589, 484, 437, 264, 8482, 295, 264, 50700], "temperature": 0.0, "avg_logprob": -0.09154454018305806, "compression_ratio": 1.86328125, "no_speech_prob": 0.003299866570159793}, {"id": 86, "seek": 56244, "start": 569.1600000000001, "end": 575.6400000000001, "text": " data are under that model. But the model itself takes account of the things that are being generated,", "tokens": [50700, 1412, 366, 833, 300, 2316, 13, 583, 264, 2316, 2564, 2516, 2696, 295, 264, 721, 300, 366, 885, 10833, 11, 51024], "temperature": 0.0, "avg_logprob": -0.09154454018305806, "compression_ratio": 1.86328125, "no_speech_prob": 0.003299866570159793}, {"id": 87, "seek": 56244, "start": 575.6400000000001, "end": 579.96, "text": " so our sensory data, and also the things that are causing them, simply a joint probability", "tokens": [51024, 370, 527, 27233, 1412, 11, 293, 611, 264, 721, 300, 366, 9853, 552, 11, 2935, 257, 7225, 8482, 51240], "temperature": 0.0, "avg_logprob": -0.09154454018305806, "compression_ratio": 1.86328125, "no_speech_prob": 0.003299866570159793}, {"id": 88, "seek": 56244, "start": 579.96, "end": 584.84, "text": " distribution involving all of these things. So I'm now interpreting this graphic up on", "tokens": [51240, 7316, 17030, 439, 295, 613, 721, 13, 407, 286, 478, 586, 37395, 341, 14089, 493, 322, 51484], "temperature": 0.0, "avg_logprob": -0.09154454018305806, "compression_ratio": 1.86328125, "no_speech_prob": 0.003299866570159793}, {"id": 89, "seek": 56244, "start": 584.84, "end": 590.5200000000001, "text": " the left as depending upon some generative model where we've effectively integrated out everything", "tokens": [51484, 264, 1411, 382, 5413, 3564, 512, 1337, 1166, 2316, 689, 321, 600, 8659, 10919, 484, 1203, 51768], "temperature": 0.0, "avg_logprob": -0.09154454018305806, "compression_ratio": 1.86328125, "no_speech_prob": 0.003299866570159793}, {"id": 90, "seek": 59052, "start": 590.52, "end": 598.76, "text": " that we don't need to determine explicitly. Now generative models will often have some", "tokens": [50364, 300, 321, 500, 380, 643, 281, 6997, 20803, 13, 823, 1337, 1166, 5245, 486, 2049, 362, 512, 50776], "temperature": 0.0, "avg_logprob": -0.09150472942151522, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.0013382482575252652}, {"id": 91, "seek": 59052, "start": 598.76, "end": 602.92, "text": " interesting structure, and in fact if they don't have interesting structures then they're not", "tokens": [50776, 1880, 3877, 11, 293, 294, 1186, 498, 436, 500, 380, 362, 1880, 9227, 550, 436, 434, 406, 50984], "temperature": 0.0, "avg_logprob": -0.09150472942151522, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.0013382482575252652}, {"id": 92, "seek": 59052, "start": 602.92, "end": 609.0, "text": " interesting generative models. And normally that structure manifests as a factorization", "tokens": [50984, 1880, 1337, 1166, 5245, 13, 400, 5646, 300, 3877, 50252, 382, 257, 5952, 2144, 51288], "temperature": 0.0, "avg_logprob": -0.09150472942151522, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.0013382482575252652}, {"id": 93, "seek": 59052, "start": 609.0, "end": 614.4399999999999, "text": " of this joint distribution, but not everything depends upon everything else. And so we can", "tokens": [51288, 295, 341, 7225, 7316, 11, 457, 406, 1203, 5946, 3564, 1203, 1646, 13, 400, 370, 321, 393, 51560], "temperature": 0.0, "avg_logprob": -0.09150472942151522, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.0013382482575252652}, {"id": 94, "seek": 59052, "start": 614.4399999999999, "end": 619.0799999999999, "text": " often factorize it, and here I'm just showing a completely arbitrary factorization of some", "tokens": [51560, 2049, 5952, 1125, 309, 11, 293, 510, 286, 478, 445, 4099, 257, 2584, 23211, 5952, 2144, 295, 512, 51792], "temperature": 0.0, "avg_logprob": -0.09150472942151522, "compression_ratio": 1.814516129032258, "no_speech_prob": 0.0013382482575252652}, {"id": 95, "seek": 61908, "start": 619.08, "end": 625.96, "text": " generative model where we have certain dependencies, so y depends directly upon x1 and x2, but not", "tokens": [50364, 1337, 1166, 2316, 689, 321, 362, 1629, 36606, 11, 370, 288, 5946, 3838, 3564, 2031, 16, 293, 2031, 17, 11, 457, 406, 50708], "temperature": 0.0, "avg_logprob": -0.07202845872050584, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004348202142864466}, {"id": 96, "seek": 61908, "start": 625.96, "end": 631.64, "text": " directly upon x3 and so on. And the reason it's useful to think about this factorization is because", "tokens": [50708, 3838, 3564, 2031, 18, 293, 370, 322, 13, 400, 264, 1778, 309, 311, 4420, 281, 519, 466, 341, 5952, 2144, 307, 570, 50992], "temperature": 0.0, "avg_logprob": -0.07202845872050584, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004348202142864466}, {"id": 97, "seek": 61908, "start": 631.64, "end": 637.32, "text": " we can then express a graphical version of this model that provides a bit more intuition as to", "tokens": [50992, 321, 393, 550, 5109, 257, 35942, 3037, 295, 341, 2316, 300, 6417, 257, 857, 544, 24002, 382, 281, 51276], "temperature": 0.0, "avg_logprob": -0.07202845872050584, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004348202142864466}, {"id": 98, "seek": 61908, "start": 637.32, "end": 642.84, "text": " what's going on. So the way we do that, or one way that we can do that, is using something known as a", "tokens": [51276, 437, 311, 516, 322, 13, 407, 264, 636, 321, 360, 300, 11, 420, 472, 636, 300, 321, 393, 360, 300, 11, 307, 1228, 746, 2570, 382, 257, 51552], "temperature": 0.0, "avg_logprob": -0.07202845872050584, "compression_ratio": 1.6596638655462186, "no_speech_prob": 0.004348202142864466}, {"id": 99, "seek": 64284, "start": 642.84, "end": 647.72, "text": " factor graph. And the idea is that we take each of these factors in turn, we draw a square,", "tokens": [50364, 5952, 4295, 13, 400, 264, 1558, 307, 300, 321, 747, 1184, 295, 613, 6771, 294, 1261, 11, 321, 2642, 257, 3732, 11, 50608], "temperature": 0.0, "avg_logprob": -0.11200800027933207, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.07175783067941666}, {"id": 100, "seek": 64284, "start": 649.1600000000001, "end": 655.1600000000001, "text": " and then we draw an arrow to whatever's on the left of the probability factor we're interested in.", "tokens": [50680, 293, 550, 321, 2642, 364, 11610, 281, 2035, 311, 322, 264, 1411, 295, 264, 8482, 5952, 321, 434, 3102, 294, 13, 50980], "temperature": 0.0, "avg_logprob": -0.11200800027933207, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.07175783067941666}, {"id": 101, "seek": 64284, "start": 655.1600000000001, "end": 660.36, "text": " So here an arrow towards the y, because we're saying the probability of y conditioned upon or", "tokens": [50980, 407, 510, 364, 11610, 3030, 264, 288, 11, 570, 321, 434, 1566, 264, 8482, 295, 288, 35833, 3564, 420, 51240], "temperature": 0.0, "avg_logprob": -0.11200800027933207, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.07175783067941666}, {"id": 102, "seek": 64284, "start": 660.36, "end": 666.36, "text": " depending upon the other two things, and then we attach those to the same square. We then move", "tokens": [51240, 5413, 3564, 264, 661, 732, 721, 11, 293, 550, 321, 5085, 729, 281, 264, 912, 3732, 13, 492, 550, 1286, 51540], "temperature": 0.0, "avg_logprob": -0.11200800027933207, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.07175783067941666}, {"id": 103, "seek": 64284, "start": 666.36, "end": 671.8000000000001, "text": " on to the next factor, draw another square, and we then attach the relevant variables together", "tokens": [51540, 322, 281, 264, 958, 5952, 11, 2642, 1071, 3732, 11, 293, 321, 550, 5085, 264, 7340, 9102, 1214, 51812], "temperature": 0.0, "avg_logprob": -0.11200800027933207, "compression_ratio": 1.880952380952381, "no_speech_prob": 0.07175783067941666}, {"id": 104, "seek": 67284, "start": 673.0, "end": 678.0400000000001, "text": " in exactly the same way. And we carry on doing that until we have a picture of what our model is", "tokens": [50372, 294, 2293, 264, 912, 636, 13, 400, 321, 3985, 322, 884, 300, 1826, 321, 362, 257, 3036, 295, 437, 527, 2316, 307, 50624], "temperature": 0.0, "avg_logprob": -0.0940889040629069, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0019618927035480738}, {"id": 105, "seek": 67284, "start": 678.0400000000001, "end": 682.12, "text": " like. So now instead of having to look at this equation, you can look at this and say, okay,", "tokens": [50624, 411, 13, 407, 586, 2602, 295, 1419, 281, 574, 412, 341, 5367, 11, 291, 393, 574, 412, 341, 293, 584, 11, 1392, 11, 50828], "temperature": 0.0, "avg_logprob": -0.0940889040629069, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0019618927035480738}, {"id": 106, "seek": 67284, "start": 682.12, "end": 690.44, "text": " well x3 causes x1, x4 causes x2, and together x1 and x2 relate to or together generate our data y.", "tokens": [50828, 731, 2031, 18, 7700, 2031, 16, 11, 2031, 19, 7700, 2031, 17, 11, 293, 1214, 2031, 16, 293, 2031, 17, 10961, 281, 420, 1214, 8460, 527, 1412, 288, 13, 51244], "temperature": 0.0, "avg_logprob": -0.0940889040629069, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0019618927035480738}, {"id": 107, "seek": 67284, "start": 693.24, "end": 698.36, "text": " This is just to demonstrate several models you may be familiar with generally, and the fact that we", "tokens": [51384, 639, 307, 445, 281, 11698, 2940, 5245, 291, 815, 312, 4963, 365, 5101, 11, 293, 264, 1186, 300, 321, 51640], "temperature": 0.0, "avg_logprob": -0.0940889040629069, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0019618927035480738}, {"id": 108, "seek": 67284, "start": 698.36, "end": 701.96, "text": " we're often implicitly using these kinds of generative models without necessarily thinking", "tokens": [51640, 321, 434, 2049, 26947, 356, 1228, 613, 3685, 295, 1337, 1166, 5245, 1553, 4725, 1953, 51820], "temperature": 0.0, "avg_logprob": -0.0940889040629069, "compression_ratio": 1.6925795053003534, "no_speech_prob": 0.0019618927035480738}, {"id": 109, "seek": 70196, "start": 701.96, "end": 706.9200000000001, "text": " about it. So when we're performing a principal components analysis, we're often taking some", "tokens": [50364, 466, 309, 13, 407, 562, 321, 434, 10205, 257, 9716, 6677, 5215, 11, 321, 434, 2049, 1940, 512, 50612], "temperature": 0.0, "avg_logprob": -0.09391744048507125, "compression_ratio": 1.875, "no_speech_prob": 0.0031495282892137766}, {"id": 110, "seek": 70196, "start": 708.84, "end": 713.72, "text": " distribution of some variable x, we're then mapping that to a higher dimensional space y,", "tokens": [50708, 7316, 295, 512, 7006, 2031, 11, 321, 434, 550, 18350, 300, 281, 257, 2946, 18795, 1901, 288, 11, 50952], "temperature": 0.0, "avg_logprob": -0.09391744048507125, "compression_ratio": 1.875, "no_speech_prob": 0.0031495282892137766}, {"id": 111, "seek": 70196, "start": 715.0, "end": 720.2800000000001, "text": " and that's our sort of model of how the data that we're working with are generated.", "tokens": [51016, 293, 300, 311, 527, 1333, 295, 2316, 295, 577, 264, 1412, 300, 321, 434, 1364, 365, 366, 10833, 13, 51280], "temperature": 0.0, "avg_logprob": -0.09391744048507125, "compression_ratio": 1.875, "no_speech_prob": 0.0031495282892137766}, {"id": 112, "seek": 70196, "start": 722.12, "end": 725.96, "text": " So what we can then do when we perform a principal components analysis is take our", "tokens": [51372, 407, 437, 321, 393, 550, 360, 562, 321, 2042, 257, 9716, 6677, 5215, 307, 747, 527, 51564], "temperature": 0.0, "avg_logprob": -0.09391744048507125, "compression_ratio": 1.875, "no_speech_prob": 0.0031495282892137766}, {"id": 113, "seek": 70196, "start": 725.96, "end": 731.72, "text": " high dimensional data y, work out how you go back from the y to the x, and that gives you all of your", "tokens": [51564, 1090, 18795, 1412, 288, 11, 589, 484, 577, 291, 352, 646, 490, 264, 288, 281, 264, 2031, 11, 293, 300, 2709, 291, 439, 295, 428, 51852], "temperature": 0.0, "avg_logprob": -0.09391744048507125, "compression_ratio": 1.875, "no_speech_prob": 0.0031495282892137766}, {"id": 114, "seek": 73172, "start": 731.72, "end": 735.88, "text": " specific principal components and the directions that have been stretched in various different ways.", "tokens": [50364, 2685, 9716, 6677, 293, 264, 11095, 300, 362, 668, 23563, 294, 3683, 819, 2098, 13, 50572], "temperature": 0.0, "avg_logprob": -0.12593873676500822, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0017878623912110925}, {"id": 115, "seek": 73172, "start": 737.4, "end": 741.1600000000001, "text": " Same principle applies for things like canonical variance analysis, where you've got some set of", "tokens": [50648, 10635, 8665, 13165, 337, 721, 411, 46491, 21977, 5215, 11, 689, 291, 600, 658, 512, 992, 295, 50836], "temperature": 0.0, "avg_logprob": -0.12593873676500822, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0017878623912110925}, {"id": 116, "seek": 73172, "start": 741.72, "end": 745.32, "text": " variables then mapped to two different sorts of data by stretching them and", "tokens": [50864, 9102, 550, 33318, 281, 732, 819, 7527, 295, 1412, 538, 19632, 552, 293, 51044], "temperature": 0.0, "avg_logprob": -0.12593873676500822, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0017878623912110925}, {"id": 117, "seek": 73172, "start": 746.12, "end": 750.2, "text": " distorting them in various ways. And the challenge is how do you get back to the common", "tokens": [51084, 37555, 278, 552, 294, 3683, 2098, 13, 400, 264, 3430, 307, 577, 360, 291, 483, 646, 281, 264, 2689, 51288], "temperature": 0.0, "avg_logprob": -0.12593873676500822, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0017878623912110925}, {"id": 118, "seek": 73172, "start": 751.5600000000001, "end": 757.24, "text": " hidden variable common cause for both of those datasets. And we do the same sort of thing with", "tokens": [51356, 7633, 7006, 2689, 3082, 337, 1293, 295, 729, 42856, 13, 400, 321, 360, 264, 912, 1333, 295, 551, 365, 51640], "temperature": 0.0, "avg_logprob": -0.12593873676500822, "compression_ratio": 1.7606177606177607, "no_speech_prob": 0.0017878623912110925}, {"id": 119, "seek": 75724, "start": 757.24, "end": 762.28, "text": " something like clustering analysis, where here the model says we're effectively sampling from", "tokens": [50364, 746, 411, 596, 48673, 5215, 11, 689, 510, 264, 2316, 1619, 321, 434, 8659, 21179, 490, 50616], "temperature": 0.0, "avg_logprob": -0.08511734891820837, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00739267049357295}, {"id": 120, "seek": 75724, "start": 762.28, "end": 766.92, "text": " one of several different clusters with different probabilities. We're then generating some point", "tokens": [50616, 472, 295, 2940, 819, 23313, 365, 819, 33783, 13, 492, 434, 550, 17746, 512, 935, 50848], "temperature": 0.0, "avg_logprob": -0.08511734891820837, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00739267049357295}, {"id": 121, "seek": 75724, "start": 766.92, "end": 773.96, "text": " in space depending upon which cluster it falls in. And the process of inference is again undoing", "tokens": [50848, 294, 1901, 5413, 3564, 597, 13630, 309, 8804, 294, 13, 400, 264, 1399, 295, 38253, 307, 797, 23779, 278, 51200], "temperature": 0.0, "avg_logprob": -0.08511734891820837, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00739267049357295}, {"id": 122, "seek": 75724, "start": 773.96, "end": 779.0, "text": " this. It's finding the posterior by taking a point in a cluster and saying, well, which cluster is", "tokens": [51200, 341, 13, 467, 311, 5006, 264, 33529, 538, 1940, 257, 935, 294, 257, 13630, 293, 1566, 11, 731, 11, 597, 13630, 307, 51452], "temperature": 0.0, "avg_logprob": -0.08511734891820837, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00739267049357295}, {"id": 123, "seek": 75724, "start": 779.0, "end": 786.12, "text": " that from? So going from the y to the s. So that's a sort of brief introduction to the idea of", "tokens": [51452, 300, 490, 30, 407, 516, 490, 264, 288, 281, 264, 262, 13, 407, 300, 311, 257, 1333, 295, 5353, 9339, 281, 264, 1558, 295, 51808], "temperature": 0.0, "avg_logprob": -0.08511734891820837, "compression_ratio": 1.749090909090909, "no_speech_prob": 0.00739267049357295}, {"id": 124, "seek": 78612, "start": 786.12, "end": 791.5600000000001, "text": " generative models, the the role they play in active inference, some key examples and some of", "tokens": [50364, 1337, 1166, 5245, 11, 264, 264, 3090, 436, 862, 294, 4967, 38253, 11, 512, 2141, 5110, 293, 512, 295, 50636], "temperature": 0.0, "avg_logprob": -0.07576397982510653, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0077662160620093346}, {"id": 125, "seek": 78612, "start": 791.5600000000001, "end": 796.6, "text": " the notation that I'm going to use as we go forward. What I've said so far has been relatively", "tokens": [50636, 264, 24657, 300, 286, 478, 516, 281, 764, 382, 321, 352, 2128, 13, 708, 286, 600, 848, 370, 1400, 575, 668, 7226, 50888], "temperature": 0.0, "avg_logprob": -0.07576397982510653, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0077662160620093346}, {"id": 126, "seek": 78612, "start": 796.6, "end": 803.08, "text": " abstract. And in the next section, I want to try and work from those sort of general principles", "tokens": [50888, 12649, 13, 400, 294, 264, 958, 3541, 11, 286, 528, 281, 853, 293, 589, 490, 729, 1333, 295, 2674, 9156, 51212], "temperature": 0.0, "avg_logprob": -0.07576397982510653, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0077662160620093346}, {"id": 127, "seek": 78612, "start": 803.08, "end": 807.88, "text": " and these slightly abstract notions through to something more specific and more neurobiological.", "tokens": [51212, 293, 613, 4748, 12649, 35799, 807, 281, 746, 544, 2685, 293, 544, 16499, 5614, 4383, 13, 51452], "temperature": 0.0, "avg_logprob": -0.07576397982510653, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0077662160620093346}, {"id": 128, "seek": 78612, "start": 809.0, "end": 813.16, "text": " Now, the first thing we're going to do to get there is to introduce one more abstract concept,", "tokens": [51508, 823, 11, 264, 700, 551, 321, 434, 516, 281, 360, 281, 483, 456, 307, 281, 5366, 472, 544, 12649, 3410, 11, 51716], "temperature": 0.0, "avg_logprob": -0.07576397982510653, "compression_ratio": 1.7148014440433212, "no_speech_prob": 0.0077662160620093346}, {"id": 129, "seek": 81316, "start": 813.16, "end": 818.36, "text": " which is that of a Markov blanket. A Markov blanket comes up in all sorts of places in active", "tokens": [50364, 597, 307, 300, 295, 257, 3934, 5179, 17907, 13, 316, 3934, 5179, 17907, 1487, 493, 294, 439, 7527, 295, 3190, 294, 4967, 50624], "temperature": 0.0, "avg_logprob": -0.11916105313734575, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.010217966511845589}, {"id": 130, "seek": 81316, "start": 818.36, "end": 823.16, "text": " inference, but I'm going to use it in a very specific way here. And this is to talk about", "tokens": [50624, 38253, 11, 457, 286, 478, 516, 281, 764, 309, 294, 257, 588, 2685, 636, 510, 13, 400, 341, 307, 281, 751, 466, 50864], "temperature": 0.0, "avg_logprob": -0.11916105313734575, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.010217966511845589}, {"id": 131, "seek": 81316, "start": 823.16, "end": 828.8399999999999, "text": " conditional independence. And what I mean by conditional independence is that if you have", "tokens": [50864, 27708, 14640, 13, 400, 437, 286, 914, 538, 27708, 14640, 307, 300, 498, 291, 362, 51148], "temperature": 0.0, "avg_logprob": -0.11916105313734575, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.010217966511845589}, {"id": 132, "seek": 81316, "start": 831.4, "end": 835.16, "text": " two different sets of variables, so here I've noted them as the mu and the eta,", "tokens": [51276, 732, 819, 6352, 295, 9102, 11, 370, 510, 286, 600, 12964, 552, 382, 264, 2992, 293, 264, 32415, 11, 51464], "temperature": 0.0, "avg_logprob": -0.11916105313734575, "compression_ratio": 1.6650943396226414, "no_speech_prob": 0.010217966511845589}, {"id": 133, "seek": 83516, "start": 836.12, "end": 842.76, "text": " the Markov blanket B is the set of set of variables that render the other two completely", "tokens": [50412, 264, 3934, 5179, 17907, 363, 307, 264, 992, 295, 992, 295, 9102, 300, 15529, 264, 661, 732, 2584, 50744], "temperature": 0.0, "avg_logprob": -0.09437514826194528, "compression_ratio": 1.8, "no_speech_prob": 0.03288416564464569}, {"id": 134, "seek": 83516, "start": 842.76, "end": 846.68, "text": " independent to one another, that mean that if you know everything about the blanket,", "tokens": [50744, 6695, 281, 472, 1071, 11, 300, 914, 300, 498, 291, 458, 1203, 466, 264, 17907, 11, 50940], "temperature": 0.0, "avg_logprob": -0.09437514826194528, "compression_ratio": 1.8, "no_speech_prob": 0.03288416564464569}, {"id": 135, "seek": 83516, "start": 846.68, "end": 849.88, "text": " knowing something about mu tells you nothing new about eta.", "tokens": [50940, 5276, 746, 466, 2992, 5112, 291, 1825, 777, 466, 32415, 13, 51100], "temperature": 0.0, "avg_logprob": -0.09437514826194528, "compression_ratio": 1.8, "no_speech_prob": 0.03288416564464569}, {"id": 136, "seek": 83516, "start": 852.04, "end": 856.52, "text": " To give you an example of this, one of the examples that most people are familiar with", "tokens": [51208, 1407, 976, 291, 364, 1365, 295, 341, 11, 472, 295, 264, 5110, 300, 881, 561, 366, 4963, 365, 51432], "temperature": 0.0, "avg_logprob": -0.09437514826194528, "compression_ratio": 1.8, "no_speech_prob": 0.03288416564464569}, {"id": 137, "seek": 83516, "start": 856.52, "end": 862.6, "text": " is the idea of a Markov chain, where you have a sequence of events in time. So something that", "tokens": [51432, 307, 264, 1558, 295, 257, 3934, 5179, 5021, 11, 689, 291, 362, 257, 8310, 295, 3931, 294, 565, 13, 407, 746, 300, 51736], "temperature": 0.0, "avg_logprob": -0.09437514826194528, "compression_ratio": 1.8, "no_speech_prob": 0.03288416564464569}, {"id": 138, "seek": 86260, "start": 862.6, "end": 867.4, "text": " happens in the past then influences the present, which then influences the future with no direct", "tokens": [50364, 2314, 294, 264, 1791, 550, 21222, 264, 1974, 11, 597, 550, 21222, 264, 2027, 365, 572, 2047, 50604], "temperature": 0.0, "avg_logprob": -0.06338903537163368, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.00286750216037035}, {"id": 139, "seek": 86260, "start": 867.4, "end": 872.76, "text": " influence from the past to the future without going via the present. So if I know everything", "tokens": [50604, 6503, 490, 264, 1791, 281, 264, 2027, 1553, 516, 5766, 264, 1974, 13, 407, 498, 286, 458, 1203, 50872], "temperature": 0.0, "avg_logprob": -0.06338903537163368, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.00286750216037035}, {"id": 140, "seek": 86260, "start": 872.76, "end": 876.6800000000001, "text": " there is to know about the present, knowing something about the past tells me nothing new", "tokens": [50872, 456, 307, 281, 458, 466, 264, 1974, 11, 5276, 746, 466, 264, 1791, 5112, 385, 1825, 777, 51068], "temperature": 0.0, "avg_logprob": -0.06338903537163368, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.00286750216037035}, {"id": 141, "seek": 86260, "start": 876.6800000000001, "end": 881.64, "text": " about the future and vice versa. So in that sense, the present is the Markov blanket that", "tokens": [51068, 466, 264, 2027, 293, 11964, 25650, 13, 407, 294, 300, 2020, 11, 264, 1974, 307, 264, 3934, 5179, 17907, 300, 51316], "temperature": 0.0, "avg_logprob": -0.06338903537163368, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.00286750216037035}, {"id": 142, "seek": 86260, "start": 881.64, "end": 887.88, "text": " separates the past from the future. Now, this is a very useful concept when we're dealing with", "tokens": [51316, 34149, 264, 1791, 490, 264, 2027, 13, 823, 11, 341, 307, 257, 588, 4420, 3410, 562, 321, 434, 6260, 365, 51628], "temperature": 0.0, "avg_logprob": -0.06338903537163368, "compression_ratio": 1.9661016949152543, "no_speech_prob": 0.00286750216037035}, {"id": 143, "seek": 88788, "start": 887.88, "end": 892.6, "text": " graphical models or generative models that have some interesting factorization structure,", "tokens": [50364, 35942, 5245, 420, 1337, 1166, 5245, 300, 362, 512, 1880, 5952, 2144, 3877, 11, 50600], "temperature": 0.0, "avg_logprob": -0.11398334503173828, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.035929229110479355}, {"id": 144, "seek": 88788, "start": 892.6, "end": 899.56, "text": " and I'll try and explain why. The Markov blanket is often referred to as or can often be identified", "tokens": [50600, 293, 286, 603, 853, 293, 2903, 983, 13, 440, 3934, 5179, 17907, 307, 2049, 10839, 281, 382, 420, 393, 2049, 312, 9234, 50948], "temperature": 0.0, "avg_logprob": -0.11398334503173828, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.035929229110479355}, {"id": 145, "seek": 88788, "start": 899.56, "end": 904.4399999999999, "text": " by identifying variable we're interested in, so let's say we're interested in the variable x2,", "tokens": [50948, 538, 16696, 7006, 321, 434, 3102, 294, 11, 370, 718, 311, 584, 321, 434, 3102, 294, 264, 7006, 2031, 17, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11398334503173828, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.035929229110479355}, {"id": 146, "seek": 88788, "start": 905.08, "end": 911.48, "text": " then you find the parents of x2, so the things that caused it, the children of x2, so the things", "tokens": [51224, 550, 291, 915, 264, 3152, 295, 2031, 17, 11, 370, 264, 721, 300, 7008, 309, 11, 264, 2227, 295, 2031, 17, 11, 370, 264, 721, 51544], "temperature": 0.0, "avg_logprob": -0.11398334503173828, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.035929229110479355}, {"id": 147, "seek": 88788, "start": 911.48, "end": 917.24, "text": " it causes, and the parents of its children, and that gives you the Markov blanket of x2.", "tokens": [51544, 309, 7700, 11, 293, 264, 3152, 295, 1080, 2227, 11, 293, 300, 2709, 291, 264, 3934, 5179, 17907, 295, 2031, 17, 13, 51832], "temperature": 0.0, "avg_logprob": -0.11398334503173828, "compression_ratio": 1.910569105691057, "no_speech_prob": 0.035929229110479355}, {"id": 148, "seek": 91788, "start": 918.6, "end": 925.24, "text": " Now the significance of this is that knowing this means that if we know about the blanket,", "tokens": [50400, 823, 264, 17687, 295, 341, 307, 300, 5276, 341, 1355, 300, 498, 321, 458, 466, 264, 17907, 11, 50732], "temperature": 0.0, "avg_logprob": -0.08509282061928197, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.00041788441012613475}, {"id": 149, "seek": 91788, "start": 925.24, "end": 928.6, "text": " it doesn't matter what else is going on in the generative model, you know, this might be some", "tokens": [50732, 309, 1177, 380, 1871, 437, 1646, 307, 516, 322, 294, 264, 1337, 1166, 2316, 11, 291, 458, 11, 341, 1062, 312, 512, 50900], "temperature": 0.0, "avg_logprob": -0.08509282061928197, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.00041788441012613475}, {"id": 150, "seek": 91788, "start": 928.6, "end": 934.2, "text": " tiny section of a huge generative model with many, many variables, but we don't need to know about", "tokens": [50900, 5870, 3541, 295, 257, 2603, 1337, 1166, 2316, 365, 867, 11, 867, 9102, 11, 457, 321, 500, 380, 643, 281, 458, 466, 51180], "temperature": 0.0, "avg_logprob": -0.08509282061928197, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.00041788441012613475}, {"id": 151, "seek": 91788, "start": 934.2, "end": 938.76, "text": " all those variables, all we need to know about are the blanket variables, so we can effectively", "tokens": [51180, 439, 729, 9102, 11, 439, 321, 643, 281, 458, 466, 366, 264, 17907, 9102, 11, 370, 321, 393, 8659, 51408], "temperature": 0.0, "avg_logprob": -0.08509282061928197, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.00041788441012613475}, {"id": 152, "seek": 91788, "start": 938.76, "end": 946.2, "text": " ignore everything else if what we're interested in is x2. Now, how does this then matter for", "tokens": [51408, 11200, 1203, 1646, 498, 437, 321, 434, 3102, 294, 307, 2031, 17, 13, 823, 11, 577, 775, 341, 550, 1871, 337, 51780], "temperature": 0.0, "avg_logprob": -0.08509282061928197, "compression_ratio": 1.865612648221344, "no_speech_prob": 0.00041788441012613475}, {"id": 153, "seek": 94620, "start": 946.2, "end": 952.44, "text": " neurobiology? Well, I think the answer to that is that the brain is an extremely sparse structure,", "tokens": [50364, 16499, 5614, 1793, 30, 1042, 11, 286, 519, 264, 1867, 281, 300, 307, 300, 264, 3567, 307, 364, 4664, 637, 11668, 3877, 11, 50676], "temperature": 0.0, "avg_logprob": -0.12100845518566314, "compression_ratio": 1.8, "no_speech_prob": 0.006416146643459797}, {"id": 154, "seek": 94620, "start": 952.44, "end": 956.84, "text": " that synaptic message passing does not involve connections between every different neuron in", "tokens": [50676, 300, 5451, 2796, 299, 3636, 8437, 775, 406, 9494, 9271, 1296, 633, 819, 34090, 294, 50896], "temperature": 0.0, "avg_logprob": -0.12100845518566314, "compression_ratio": 1.8, "no_speech_prob": 0.006416146643459797}, {"id": 155, "seek": 94620, "start": 956.84, "end": 961.24, "text": " the brain to every other neuron in the brain. There are a small number of, relatively speaking,", "tokens": [50896, 264, 3567, 281, 633, 661, 34090, 294, 264, 3567, 13, 821, 366, 257, 1359, 1230, 295, 11, 7226, 4124, 11, 51116], "temperature": 0.0, "avg_logprob": -0.12100845518566314, "compression_ratio": 1.8, "no_speech_prob": 0.006416146643459797}, {"id": 156, "seek": 94620, "start": 961.24, "end": 968.36, "text": " of synapses between any neuron and its neighbors or neurons elsewhere in the brain,", "tokens": [51116, 295, 5451, 2382, 279, 1296, 604, 34090, 293, 1080, 12512, 420, 22027, 14517, 294, 264, 3567, 11, 51472], "temperature": 0.0, "avg_logprob": -0.12100845518566314, "compression_ratio": 1.8, "no_speech_prob": 0.006416146643459797}, {"id": 157, "seek": 94620, "start": 969.1600000000001, "end": 973.24, "text": " and so we can make an argument that if the brain is performing inference about lots of different", "tokens": [51512, 293, 370, 321, 393, 652, 364, 6770, 300, 498, 264, 3567, 307, 10205, 38253, 466, 3195, 295, 819, 51716], "temperature": 0.0, "avg_logprob": -0.12100845518566314, "compression_ratio": 1.8, "no_speech_prob": 0.006416146643459797}, {"id": 158, "seek": 97324, "start": 973.24, "end": 979.16, "text": " variables, all it needs is to know the structure of the generative model and the variables that", "tokens": [50364, 9102, 11, 439, 309, 2203, 307, 281, 458, 264, 3877, 295, 264, 1337, 1166, 2316, 293, 264, 9102, 300, 50660], "temperature": 0.0, "avg_logprob": -0.08554412523905436, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.008311598561704159}, {"id": 159, "seek": 97324, "start": 979.16, "end": 983.5600000000001, "text": " sit in that Markov blanket, or at least the neurons that are representing those other variables.", "tokens": [50660, 1394, 294, 300, 3934, 5179, 17907, 11, 420, 412, 1935, 264, 22027, 300, 366, 13460, 729, 661, 9102, 13, 50880], "temperature": 0.0, "avg_logprob": -0.08554412523905436, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.008311598561704159}, {"id": 160, "seek": 97324, "start": 984.6, "end": 988.44, "text": " And that tells us that we can then, when we're inverting that model, when we're performing", "tokens": [50932, 400, 300, 5112, 505, 300, 321, 393, 550, 11, 562, 321, 434, 28653, 783, 300, 2316, 11, 562, 321, 434, 10205, 51124], "temperature": 0.0, "avg_logprob": -0.08554412523905436, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.008311598561704159}, {"id": 161, "seek": 97324, "start": 988.44, "end": 995.08, "text": " inference, what I'm showing here is just one example of an inference scheme, we can, we can", "tokens": [51124, 38253, 11, 437, 286, 478, 4099, 510, 307, 445, 472, 1365, 295, 364, 38253, 12232, 11, 321, 393, 11, 321, 393, 51456], "temperature": 0.0, "avg_logprob": -0.08554412523905436, "compression_ratio": 1.7361111111111112, "no_speech_prob": 0.008311598561704159}, {"id": 162, "seek": 99508, "start": 995.08, "end": 1003.08, "text": " express the dynamics of that neuronal message passing in terms of connections from the other", "tokens": [50364, 5109, 264, 15679, 295, 300, 12087, 21523, 3636, 8437, 294, 2115, 295, 9271, 490, 264, 661, 50764], "temperature": 0.0, "avg_logprob": -0.06876192948757073, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.03699943795800209}, {"id": 163, "seek": 99508, "start": 1003.08, "end": 1009.96, "text": " neural populations that are representing the variables in that Markov blanket. The details", "tokens": [50764, 18161, 12822, 300, 366, 13460, 264, 9102, 294, 300, 3934, 5179, 17907, 13, 440, 4365, 51108], "temperature": 0.0, "avg_logprob": -0.06876192948757073, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.03699943795800209}, {"id": 164, "seek": 99508, "start": 1009.96, "end": 1015.5600000000001, "text": " of this aren't that important, but this is one example of an inference scheme known as variational", "tokens": [51108, 295, 341, 3212, 380, 300, 1021, 11, 457, 341, 307, 472, 1365, 295, 364, 38253, 12232, 2570, 382, 3034, 1478, 51388], "temperature": 0.0, "avg_logprob": -0.06876192948757073, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.03699943795800209}, {"id": 165, "seek": 99508, "start": 1015.5600000000001, "end": 1021.6400000000001, "text": " message passing, here formulated as a gradient scheme in terms of some dynamics, which has", "tokens": [51388, 3636, 8437, 11, 510, 48936, 382, 257, 16235, 12232, 294, 2115, 295, 512, 15679, 11, 597, 575, 51692], "temperature": 0.0, "avg_logprob": -0.06876192948757073, "compression_ratio": 1.7110091743119267, "no_speech_prob": 0.03699943795800209}, {"id": 166, "seek": 102164, "start": 1021.64, "end": 1027.0, "text": " relevance for modeling neural populations, we're interested in how the dynamics of those", "tokens": [50364, 32684, 337, 15983, 18161, 12822, 11, 321, 434, 3102, 294, 577, 264, 15679, 295, 729, 50632], "temperature": 0.0, "avg_logprob": -0.10827835594735495, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.005716355517506599}, {"id": 167, "seek": 102164, "start": 1027.0, "end": 1033.0, "text": " populations evolve over time. And we can sort of do this recursively, we can couple together", "tokens": [50632, 12822, 16693, 670, 565, 13, 400, 321, 393, 1333, 295, 360, 341, 20560, 3413, 11, 321, 393, 1916, 1214, 50932], "temperature": 0.0, "avg_logprob": -0.10827835594735495, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.005716355517506599}, {"id": 168, "seek": 102164, "start": 1033.0, "end": 1039.56, "text": " lots of different parts of this system, where the things that are being connected up are just the", "tokens": [50932, 3195, 295, 819, 3166, 295, 341, 1185, 11, 689, 264, 721, 300, 366, 885, 4582, 493, 366, 445, 264, 51260], "temperature": 0.0, "avg_logprob": -0.10827835594735495, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.005716355517506599}, {"id": 169, "seek": 102164, "start": 1039.56, "end": 1045.56, "text": " Markov blankets of different populations. Here I've expressed it in terms of an error term,", "tokens": [51260, 3934, 5179, 38710, 295, 819, 12822, 13, 1692, 286, 600, 12675, 309, 294, 2115, 295, 364, 6713, 1433, 11, 51560], "temperature": 0.0, "avg_logprob": -0.10827835594735495, "compression_ratio": 1.6343612334801763, "no_speech_prob": 0.005716355517506599}, {"id": 170, "seek": 104556, "start": 1045.6399999999999, "end": 1053.0, "text": " this epsilon, which effectively represents the gradient of a free energy objective,", "tokens": [50368, 341, 17889, 11, 597, 8659, 8855, 264, 16235, 295, 257, 1737, 2281, 10024, 11, 50736], "temperature": 0.0, "avg_logprob": -0.09313744914774992, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.055901043117046356}, {"id": 171, "seek": 104556, "start": 1053.0, "end": 1057.72, "text": " which is used as an approximation to that marginal likelihood or evidence that I spoke", "tokens": [50736, 597, 307, 1143, 382, 364, 28023, 281, 300, 16885, 22119, 420, 4467, 300, 286, 7179, 50972], "temperature": 0.0, "avg_logprob": -0.09313744914774992, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.055901043117046356}, {"id": 172, "seek": 104556, "start": 1057.72, "end": 1063.8, "text": " about earlier. And then some beliefs about or expectations about that variable, so we can now", "tokens": [50972, 466, 3071, 13, 400, 550, 512, 13585, 466, 420, 9843, 466, 300, 7006, 11, 370, 321, 393, 586, 51276], "temperature": 0.0, "avg_logprob": -0.09313744914774992, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.055901043117046356}, {"id": 173, "seek": 104556, "start": 1063.8, "end": 1069.3999999999999, "text": " use our, the errors in our predictions to update those variables. And once we've written down the", "tokens": [51276, 764, 527, 11, 264, 13603, 294, 527, 21264, 281, 5623, 729, 9102, 13, 400, 1564, 321, 600, 3720, 760, 264, 51556], "temperature": 0.0, "avg_logprob": -0.09313744914774992, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.055901043117046356}, {"id": 174, "seek": 104556, "start": 1069.3999999999999, "end": 1074.44, "text": " dynamics of this sort of system, we can simulate things like firing rates, we can simulate the", "tokens": [51556, 15679, 295, 341, 1333, 295, 1185, 11, 321, 393, 27817, 721, 411, 16045, 6846, 11, 321, 393, 27817, 264, 51808], "temperature": 0.0, "avg_logprob": -0.09313744914774992, "compression_ratio": 1.7509578544061302, "no_speech_prob": 0.055901043117046356}, {"id": 175, "seek": 107444, "start": 1074.44, "end": 1080.92, "text": " dynamics and the behavior of these networks of neurons passing messages between one another", "tokens": [50364, 15679, 293, 264, 5223, 295, 613, 9590, 295, 22027, 8437, 7897, 1296, 472, 1071, 50688], "temperature": 0.0, "avg_logprob": -0.08418251393915532, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0030417004600167274}, {"id": 176, "seek": 107444, "start": 1081.72, "end": 1087.4, "text": " as a means of performing a form of inference and thus self evidencing.", "tokens": [50728, 382, 257, 1355, 295, 10205, 257, 1254, 295, 38253, 293, 8807, 2698, 43699, 2175, 13, 51012], "temperature": 0.0, "avg_logprob": -0.08418251393915532, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0030417004600167274}, {"id": 177, "seek": 107444, "start": 1090.28, "end": 1094.52, "text": " I know that this is probably still seemingly relatively abstract, but I think what will", "tokens": [51156, 286, 458, 300, 341, 307, 1391, 920, 18709, 7226, 12649, 11, 457, 286, 519, 437, 486, 51368], "temperature": 0.0, "avg_logprob": -0.08418251393915532, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0030417004600167274}, {"id": 178, "seek": 107444, "start": 1094.52, "end": 1098.2, "text": " hopefully help is if we then go through some examples thinking about specific kinds of", "tokens": [51368, 4696, 854, 307, 498, 321, 550, 352, 807, 512, 5110, 1953, 466, 2685, 3685, 295, 51552], "temperature": 0.0, "avg_logprob": -0.08418251393915532, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0030417004600167274}, {"id": 179, "seek": 107444, "start": 1098.2, "end": 1103.72, "text": " generative model and how that might then affect the kind of message passing we would see in a", "tokens": [51552, 1337, 1166, 2316, 293, 577, 300, 1062, 550, 3345, 264, 733, 295, 3636, 8437, 321, 576, 536, 294, 257, 51828], "temperature": 0.0, "avg_logprob": -0.08418251393915532, "compression_ratio": 1.7035573122529644, "no_speech_prob": 0.0030417004600167274}, {"id": 180, "seek": 110372, "start": 1103.72, "end": 1108.92, "text": " brain. And the first step to thinking about that I think is very important when we think about", "tokens": [50364, 3567, 13, 400, 264, 700, 1823, 281, 1953, 466, 300, 286, 519, 307, 588, 1021, 562, 321, 519, 466, 50624], "temperature": 0.0, "avg_logprob": -0.10594441126851202, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.004362845327705145}, {"id": 181, "seek": 110372, "start": 1108.92, "end": 1113.72, "text": " really useful generative models is they will all typically have a temporal aspect to them that", "tokens": [50624, 534, 4420, 1337, 1166, 5245, 307, 436, 486, 439, 5850, 362, 257, 30881, 4171, 281, 552, 300, 50864], "temperature": 0.0, "avg_logprob": -0.10594441126851202, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.004362845327705145}, {"id": 182, "seek": 110372, "start": 1113.72, "end": 1119.32, "text": " as biological creatures we deal with things that evolve in time. And so it's worth thinking about", "tokens": [50864, 382, 13910, 12281, 321, 2028, 365, 721, 300, 16693, 294, 565, 13, 400, 370, 309, 311, 3163, 1953, 466, 51144], "temperature": 0.0, "avg_logprob": -0.10594441126851202, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.004362845327705145}, {"id": 183, "seek": 110372, "start": 1119.32, "end": 1123.24, "text": " how do you formulate a generative model that has that kind of dynamic aspect to it.", "tokens": [51144, 577, 360, 291, 47881, 257, 1337, 1166, 2316, 300, 575, 300, 733, 295, 8546, 4171, 281, 309, 13, 51340], "temperature": 0.0, "avg_logprob": -0.10594441126851202, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.004362845327705145}, {"id": 184, "seek": 110372, "start": 1124.76, "end": 1130.28, "text": " And there are several different answers to that and one of them is we use something known as", "tokens": [51416, 400, 456, 366, 2940, 819, 6338, 281, 300, 293, 472, 295, 552, 307, 321, 764, 746, 2570, 382, 51692], "temperature": 0.0, "avg_logprob": -0.10594441126851202, "compression_ratio": 1.8054474708171206, "no_speech_prob": 0.004362845327705145}, {"id": 185, "seek": 113028, "start": 1130.36, "end": 1137.32, "text": " as a Taylor series approximation. So we start by saying okay at the current time what is the", "tokens": [50368, 382, 257, 12060, 2638, 28023, 13, 407, 321, 722, 538, 1566, 1392, 412, 264, 2190, 565, 437, 307, 264, 50716], "temperature": 0.0, "avg_logprob": -0.09205883472889394, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.019519668072462082}, {"id": 186, "seek": 113028, "start": 1138.52, "end": 1143.08, "text": " value of some variable x in the world and there's maybe some continuous variable it may be", "tokens": [50776, 2158, 295, 512, 7006, 2031, 294, 264, 1002, 293, 456, 311, 1310, 512, 10957, 7006, 309, 815, 312, 51004], "temperature": 0.0, "avg_logprob": -0.09205883472889394, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.019519668072462082}, {"id": 187, "seek": 113028, "start": 1143.08, "end": 1148.76, "text": " where my arm is in space. If we then want to know how it's going to evolve in time we could then say", "tokens": [51004, 689, 452, 3726, 307, 294, 1901, 13, 759, 321, 550, 528, 281, 458, 577, 309, 311, 516, 281, 16693, 294, 565, 321, 727, 550, 584, 51288], "temperature": 0.0, "avg_logprob": -0.09205883472889394, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.019519668072462082}, {"id": 188, "seek": 113028, "start": 1148.76, "end": 1152.6, "text": " well let's take the next element of our Taylor series approximation that's taking out of its", "tokens": [51288, 731, 718, 311, 747, 264, 958, 4478, 295, 527, 12060, 2638, 28023, 300, 311, 1940, 484, 295, 1080, 51480], "temperature": 0.0, "avg_logprob": -0.09205883472889394, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.019519668072462082}, {"id": 189, "seek": 113028, "start": 1152.6, "end": 1156.44, "text": " velocity and that tells us a little bit more about the trajectory that my arm might be on.", "tokens": [51480, 9269, 293, 300, 5112, 505, 257, 707, 857, 544, 466, 264, 21512, 300, 452, 3726, 1062, 312, 322, 13, 51672], "temperature": 0.0, "avg_logprob": -0.09205883472889394, "compression_ratio": 1.779467680608365, "no_speech_prob": 0.019519668072462082}, {"id": 190, "seek": 115644, "start": 1157.4, "end": 1162.92, "text": " We can then take another value which is the current acceleration of that position and we get", "tokens": [50412, 492, 393, 550, 747, 1071, 2158, 597, 307, 264, 2190, 17162, 295, 300, 2535, 293, 321, 483, 50688], "temperature": 0.0, "avg_logprob": -0.10484612981478374, "compression_ratio": 1.916, "no_speech_prob": 0.006683993153274059}, {"id": 191, "seek": 115644, "start": 1162.92, "end": 1169.16, "text": " a slightly better approximation to the trajectory. And the more terms we add in the greater approximation", "tokens": [50688, 257, 4748, 1101, 28023, 281, 264, 21512, 13, 400, 264, 544, 2115, 321, 909, 294, 264, 5044, 28023, 51000], "temperature": 0.0, "avg_logprob": -0.10484612981478374, "compression_ratio": 1.916, "no_speech_prob": 0.006683993153274059}, {"id": 192, "seek": 115644, "start": 1169.16, "end": 1173.24, "text": " we have of the trajectory or the greater representation we have of the trajectory just as", "tokens": [51000, 321, 362, 295, 264, 21512, 420, 264, 5044, 10290, 321, 362, 295, 264, 21512, 445, 382, 51204], "temperature": 0.0, "avg_logprob": -0.10484612981478374, "compression_ratio": 1.916, "no_speech_prob": 0.006683993153274059}, {"id": 193, "seek": 115644, "start": 1173.24, "end": 1178.3600000000001, "text": " a series of numbers where those numbers are my current position my current velocity acceleration", "tokens": [51204, 257, 2638, 295, 3547, 689, 729, 3547, 366, 452, 2190, 2535, 452, 2190, 9269, 17162, 51460], "temperature": 0.0, "avg_logprob": -0.10484612981478374, "compression_ratio": 1.916, "no_speech_prob": 0.006683993153274059}, {"id": 194, "seek": 115644, "start": 1178.3600000000001, "end": 1183.64, "text": " etc. So we could formulate a generative model by trying to predict each of these coefficients", "tokens": [51460, 5183, 13, 407, 321, 727, 47881, 257, 1337, 1166, 2316, 538, 1382, 281, 6069, 1184, 295, 613, 31994, 51724], "temperature": 0.0, "avg_logprob": -0.10484612981478374, "compression_ratio": 1.916, "no_speech_prob": 0.006683993153274059}, {"id": 195, "seek": 118364, "start": 1183.72, "end": 1188.92, "text": " of this Taylor series or each of these generalized coordinates of motion as they're sometimes referred", "tokens": [50368, 295, 341, 12060, 2638, 420, 1184, 295, 613, 44498, 21056, 295, 5394, 382, 436, 434, 2171, 10839, 50628], "temperature": 0.0, "avg_logprob": -0.0717568135523534, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.016123604029417038}, {"id": 196, "seek": 118364, "start": 1188.92, "end": 1195.0, "text": " to. An alternative is we just say at time one where will I be at time two where will I be and", "tokens": [50628, 281, 13, 1107, 8535, 307, 321, 445, 584, 412, 565, 472, 689, 486, 286, 312, 412, 565, 732, 689, 486, 286, 312, 293, 50932], "temperature": 0.0, "avg_logprob": -0.0717568135523534, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.016123604029417038}, {"id": 197, "seek": 118364, "start": 1195.0, "end": 1202.92, "text": " we simply represent it in terms of the sequence of points over time. Often when we're discretizing", "tokens": [50932, 321, 2935, 2906, 309, 294, 2115, 295, 264, 8310, 295, 2793, 670, 565, 13, 20043, 562, 321, 434, 25656, 3319, 51328], "temperature": 0.0, "avg_logprob": -0.0717568135523534, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.016123604029417038}, {"id": 198, "seek": 118364, "start": 1202.92, "end": 1207.72, "text": " time in this way we often we also discretize space so we might say okay where am I in some", "tokens": [51328, 565, 294, 341, 636, 321, 2049, 321, 611, 25656, 1125, 1901, 370, 321, 1062, 584, 1392, 689, 669, 286, 294, 512, 51568], "temperature": 0.0, "avg_logprob": -0.0717568135523534, "compression_ratio": 1.6782608695652175, "no_speech_prob": 0.016123604029417038}, {"id": 199, "seek": 120772, "start": 1207.8, "end": 1213.32, "text": " discretized scheme am I in location one two three four or five at each different time point", "tokens": [50368, 25656, 1602, 12232, 669, 286, 294, 4914, 472, 732, 1045, 1451, 420, 1732, 412, 1184, 819, 565, 935, 50644], "temperature": 0.0, "avg_logprob": -0.08754985446021671, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.08803386241197586}, {"id": 200, "seek": 120772, "start": 1214.1200000000001, "end": 1220.68, "text": " and so we have two different ways of accounting for how things might evolve over time and each", "tokens": [50684, 293, 370, 321, 362, 732, 819, 2098, 295, 19163, 337, 577, 721, 1062, 16693, 670, 565, 293, 1184, 51012], "temperature": 0.0, "avg_logprob": -0.08754985446021671, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.08803386241197586}, {"id": 201, "seek": 120772, "start": 1220.68, "end": 1225.4, "text": " of these can be useful in slightly different circumstances. So if I were dealing with a", "tokens": [51012, 295, 613, 393, 312, 4420, 294, 4748, 819, 9121, 13, 407, 498, 286, 645, 6260, 365, 257, 51248], "temperature": 0.0, "avg_logprob": -0.08754985446021671, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.08803386241197586}, {"id": 202, "seek": 120772, "start": 1225.4, "end": 1231.16, "text": " sequential decision-making task it may be much more efficient for me to say okay at the first", "tokens": [51248, 42881, 3537, 12, 12402, 5633, 309, 815, 312, 709, 544, 7148, 337, 385, 281, 584, 1392, 412, 264, 700, 51536], "temperature": 0.0, "avg_logprob": -0.08754985446021671, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.08803386241197586}, {"id": 203, "seek": 120772, "start": 1231.16, "end": 1234.76, "text": " move I'm going to make is this then the second one is this the third one is this and dealing", "tokens": [51536, 1286, 286, 478, 516, 281, 652, 307, 341, 550, 264, 1150, 472, 307, 341, 264, 2636, 472, 307, 341, 293, 6260, 51716], "temperature": 0.0, "avg_logprob": -0.08754985446021671, "compression_ratio": 1.7330827067669172, "no_speech_prob": 0.08803386241197586}, {"id": 204, "seek": 123476, "start": 1234.76, "end": 1240.04, "text": " with something very sequential that might also be important in in sort of language processing", "tokens": [50364, 365, 746, 588, 42881, 300, 1062, 611, 312, 1021, 294, 294, 1333, 295, 2856, 9007, 50628], "temperature": 0.0, "avg_logprob": -0.09437961389522741, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.032267674803733826}, {"id": 205, "seek": 123476, "start": 1240.04, "end": 1243.8799999999999, "text": " where you have to think which words you're going to put together in a sequence and we're dealing", "tokens": [50628, 689, 291, 362, 281, 519, 597, 2283, 291, 434, 516, 281, 829, 1214, 294, 257, 8310, 293, 321, 434, 6260, 50820], "temperature": 0.0, "avg_logprob": -0.09437961389522741, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.032267674803733826}, {"id": 206, "seek": 123476, "start": 1243.8799999999999, "end": 1250.04, "text": " with discrete variables over time because words are categorical instead of opposed to", "tokens": [50820, 365, 27706, 9102, 670, 565, 570, 2283, 366, 19250, 804, 2602, 295, 8851, 281, 51128], "temperature": 0.0, "avg_logprob": -0.09437961389522741, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.032267674803733826}, {"id": 207, "seek": 123476, "start": 1250.04, "end": 1256.76, "text": " continuing as opposed to lying on a continuum. However if I were dealing with movement or", "tokens": [51128, 9289, 382, 8851, 281, 8493, 322, 257, 36120, 13, 2908, 498, 286, 645, 6260, 365, 3963, 420, 51464], "temperature": 0.0, "avg_logprob": -0.09437961389522741, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.032267674803733826}, {"id": 208, "seek": 123476, "start": 1256.76, "end": 1262.12, "text": " the responses I'm getting from some photoreceptor in my retina it may be much more sensible for me", "tokens": [51464, 264, 13019, 286, 478, 1242, 490, 512, 2409, 418, 1336, 284, 294, 452, 1533, 1426, 309, 815, 312, 709, 544, 25380, 337, 385, 51732], "temperature": 0.0, "avg_logprob": -0.09437961389522741, "compression_ratio": 1.7032967032967032, "no_speech_prob": 0.032267674803733826}, {"id": 209, "seek": 126212, "start": 1262.12, "end": 1267.3999999999999, "text": " to be working in continuous time thinking about how things evolve at a continuous scale.", "tokens": [50364, 281, 312, 1364, 294, 10957, 565, 1953, 466, 577, 721, 16693, 412, 257, 10957, 4373, 13, 50628], "temperature": 0.0, "avg_logprob": -0.05262690414617091, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.01602686010301113}, {"id": 210, "seek": 126212, "start": 1268.84, "end": 1273.6399999999999, "text": " So what I'm showing here is an example of a generative model and the associated message", "tokens": [50700, 407, 437, 286, 478, 4099, 510, 307, 364, 1365, 295, 257, 1337, 1166, 2316, 293, 264, 6615, 3636, 50940], "temperature": 0.0, "avg_logprob": -0.05262690414617091, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.01602686010301113}, {"id": 211, "seek": 126212, "start": 1273.6399999999999, "end": 1279.7199999999998, "text": " passing scheme when formulated in terms of this continuous time scheme. So what we've got here", "tokens": [50940, 8437, 12232, 562, 48936, 294, 2115, 295, 341, 10957, 565, 12232, 13, 407, 437, 321, 600, 658, 510, 51244], "temperature": 0.0, "avg_logprob": -0.05262690414617091, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.01602686010301113}, {"id": 212, "seek": 126212, "start": 1279.7199999999998, "end": 1287.3999999999999, "text": " is a factor graph at the top this blue element that uses exactly the same sort of formulation that", "tokens": [51244, 307, 257, 5952, 4295, 412, 264, 1192, 341, 3344, 4478, 300, 4960, 2293, 264, 912, 1333, 295, 37642, 300, 51628], "temperature": 0.0, "avg_logprob": -0.05262690414617091, "compression_ratio": 1.7370892018779343, "no_speech_prob": 0.01602686010301113}, {"id": 213, "seek": 128740, "start": 1287.4, "end": 1295.64, "text": " we've been discussing so far so we have some variable here which might represent our position", "tokens": [50364, 321, 600, 668, 10850, 370, 1400, 370, 321, 362, 512, 7006, 510, 597, 1062, 2906, 527, 2535, 50776], "temperature": 0.0, "avg_logprob": -0.09280149753277118, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.0063987853936851025}, {"id": 214, "seek": 128740, "start": 1295.64, "end": 1301.16, "text": " which then predicts our velocity at that time which then predicts the acceleration at that time.", "tokens": [50776, 597, 550, 6069, 82, 527, 9269, 412, 300, 565, 597, 550, 6069, 82, 264, 17162, 412, 300, 565, 13, 51052], "temperature": 0.0, "avg_logprob": -0.09280149753277118, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.0063987853936851025}, {"id": 215, "seek": 128740, "start": 1301.16, "end": 1306.92, "text": " So we have a series of predictions here about the coupling between different orders of motion", "tokens": [51052, 407, 321, 362, 257, 2638, 295, 21264, 510, 466, 264, 37447, 1296, 819, 9470, 295, 5394, 51340], "temperature": 0.0, "avg_logprob": -0.09280149753277118, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.0063987853936851025}, {"id": 216, "seek": 128740, "start": 1307.72, "end": 1312.68, "text": " at each point those are predicting some sort of data here are wise which represents the", "tokens": [51380, 412, 1184, 935, 729, 366, 32884, 512, 1333, 295, 1412, 510, 366, 10829, 597, 8855, 264, 51628], "temperature": 0.0, "avg_logprob": -0.09280149753277118, "compression_ratio": 1.8507462686567164, "no_speech_prob": 0.0063987853936851025}, {"id": 217, "seek": 131268, "start": 1313.64, "end": 1318.04, "text": " the current position of our sensory data the current velocity the current acceleration.", "tokens": [50412, 264, 2190, 2535, 295, 527, 27233, 1412, 264, 2190, 9269, 264, 2190, 17162, 13, 50632], "temperature": 0.0, "avg_logprob": -0.10769861221313476, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.0034461566247045994}, {"id": 218, "seek": 131268, "start": 1318.8400000000001, "end": 1324.2, "text": " What I'm showing lower down here is the message passing scheme we get when we take account of", "tokens": [50672, 708, 286, 478, 4099, 3126, 760, 510, 307, 264, 3636, 8437, 12232, 321, 483, 562, 321, 747, 2696, 295, 50940], "temperature": 0.0, "avg_logprob": -0.10769861221313476, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.0034461566247045994}, {"id": 219, "seek": 131268, "start": 1324.2, "end": 1330.04, "text": " the Markov blankets of each of these variables so the Markov blanket here for the the velocity", "tokens": [50940, 264, 3934, 5179, 38710, 295, 1184, 295, 613, 9102, 370, 264, 3934, 5179, 17907, 510, 337, 264, 264, 9269, 51232], "temperature": 0.0, "avg_logprob": -0.10769861221313476, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.0034461566247045994}, {"id": 220, "seek": 131268, "start": 1330.04, "end": 1334.44, "text": " would include the position and the acceleration but also the data I've got about those things", "tokens": [51232, 576, 4090, 264, 2535, 293, 264, 17162, 457, 611, 264, 1412, 286, 600, 658, 466, 729, 721, 51452], "temperature": 0.0, "avg_logprob": -0.10769861221313476, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.0034461566247045994}, {"id": 221, "seek": 131268, "start": 1335.24, "end": 1341.4, "text": " and some prior beliefs about about other variables in our model and so we'd end up connecting those", "tokens": [51492, 293, 512, 4059, 13585, 466, 466, 661, 9102, 294, 527, 2316, 293, 370, 321, 1116, 917, 493, 11015, 729, 51800], "temperature": 0.0, "avg_logprob": -0.10769861221313476, "compression_ratio": 1.8577075098814229, "no_speech_prob": 0.0034461566247045994}, {"id": 222, "seek": 134140, "start": 1341.48, "end": 1346.6000000000001, "text": " things up and although it looks like a bit of a mess of connections it's still fewer connections", "tokens": [50368, 721, 493, 293, 4878, 309, 1542, 411, 257, 857, 295, 257, 2082, 295, 9271, 309, 311, 920, 13366, 9271, 50624], "temperature": 0.0, "avg_logprob": -0.08607262753425761, "compression_ratio": 1.8458333333333334, "no_speech_prob": 0.0034973332658410072}, {"id": 223, "seek": 134140, "start": 1346.6000000000001, "end": 1350.8400000000001, "text": " than the total number connections you would get if you match everything to everything else.", "tokens": [50624, 813, 264, 3217, 1230, 9271, 291, 576, 483, 498, 291, 2995, 1203, 281, 1203, 1646, 13, 50836], "temperature": 0.0, "avg_logprob": -0.08607262753425761, "compression_ratio": 1.8458333333333334, "no_speech_prob": 0.0034973332658410072}, {"id": 224, "seek": 134140, "start": 1352.3600000000001, "end": 1356.76, "text": " What we've got here takes the form of effectively a predictive coding style scheme", "tokens": [50912, 708, 321, 600, 658, 510, 2516, 264, 1254, 295, 8659, 257, 35521, 17720, 3758, 12232, 51132], "temperature": 0.0, "avg_logprob": -0.08607262753425761, "compression_ratio": 1.8458333333333334, "no_speech_prob": 0.0034973332658410072}, {"id": 225, "seek": 134140, "start": 1356.76, "end": 1362.0400000000002, "text": " which people may be familiar with and the idea that that you can you can hierarchically predict", "tokens": [51132, 597, 561, 815, 312, 4963, 365, 293, 264, 1558, 300, 300, 291, 393, 291, 393, 35250, 984, 6069, 51396], "temperature": 0.0, "avg_logprob": -0.08607262753425761, "compression_ratio": 1.8458333333333334, "no_speech_prob": 0.0034973332658410072}, {"id": 226, "seek": 134140, "start": 1363.64, "end": 1368.2, "text": " predict some data and you can predict the thing that's predicting that data", "tokens": [51476, 6069, 512, 1412, 293, 291, 393, 6069, 264, 551, 300, 311, 32884, 300, 1412, 51704], "temperature": 0.0, "avg_logprob": -0.08607262753425761, "compression_ratio": 1.8458333333333334, "no_speech_prob": 0.0034973332658410072}, {"id": 227, "seek": 136820, "start": 1368.2, "end": 1374.68, "text": " those data and by observing the errors in your prediction of the data you update your prediction", "tokens": [50364, 729, 1412, 293, 538, 22107, 264, 13603, 294, 428, 17630, 295, 264, 1412, 291, 5623, 428, 17630, 50688], "temperature": 0.0, "avg_logprob": -0.08677135705947876, "compression_ratio": 1.7230046948356808, "no_speech_prob": 0.00117524154484272}, {"id": 228, "seek": 136820, "start": 1374.68, "end": 1380.68, "text": " which then cascades up a hierarchy allowing you to update subsequent predictions.", "tokens": [50688, 597, 550, 3058, 66, 2977, 493, 257, 22333, 8293, 291, 281, 5623, 19962, 21264, 13, 50988], "temperature": 0.0, "avg_logprob": -0.08677135705947876, "compression_ratio": 1.7230046948356808, "no_speech_prob": 0.00117524154484272}, {"id": 229, "seek": 136820, "start": 1382.44, "end": 1387.96, "text": " What I'm showing you here is the equivalent model formulated in terms of discrete time and in this", "tokens": [51076, 708, 286, 478, 4099, 291, 510, 307, 264, 10344, 2316, 48936, 294, 2115, 295, 27706, 565, 293, 294, 341, 51352], "temperature": 0.0, "avg_logprob": -0.08677135705947876, "compression_ratio": 1.7230046948356808, "no_speech_prob": 0.00117524154484272}, {"id": 230, "seek": 136820, "start": 1387.96, "end": 1394.2, "text": " case discrete space as well so here we have a state at time t minus one which generates a", "tokens": [51352, 1389, 27706, 1901, 382, 731, 370, 510, 321, 362, 257, 1785, 412, 565, 256, 3175, 472, 597, 23815, 257, 51664], "temperature": 0.0, "avg_logprob": -0.08677135705947876, "compression_ratio": 1.7230046948356808, "no_speech_prob": 0.00117524154484272}, {"id": 231, "seek": 139420, "start": 1394.2, "end": 1399.32, "text": " state at time t which generates a state at time t plus one at each of those time points we're", "tokens": [50364, 1785, 412, 565, 256, 597, 23815, 257, 1785, 412, 565, 256, 1804, 472, 412, 1184, 295, 729, 565, 2793, 321, 434, 50620], "temperature": 0.0, "avg_logprob": -0.08623588537868065, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.003148401388898492}, {"id": 232, "seek": 139420, "start": 1399.32, "end": 1405.32, "text": " generating some observable outcomes which are represented as the o's with a variable pi here", "tokens": [50620, 17746, 512, 9951, 712, 10070, 597, 366, 10379, 382, 264, 277, 311, 365, 257, 7006, 3895, 510, 50920], "temperature": 0.0, "avg_logprob": -0.08623588537868065, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.003148401388898492}, {"id": 233, "seek": 139420, "start": 1405.32, "end": 1411.0, "text": " that represents alternative trajectories I could I could pursue so alternative policies or plans", "tokens": [50920, 300, 8855, 8535, 18257, 2083, 286, 727, 286, 727, 12392, 370, 8535, 7657, 420, 5482, 51204], "temperature": 0.0, "avg_logprob": -0.08623588537868065, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.003148401388898492}, {"id": 234, "seek": 139420, "start": 1411.0, "end": 1419.16, "text": " alternative ways I could change the sequence of events and again we have underneath the message", "tokens": [51204, 8535, 2098, 286, 727, 1319, 264, 8310, 295, 3931, 293, 797, 321, 362, 7223, 264, 3636, 51612], "temperature": 0.0, "avg_logprob": -0.08623588537868065, "compression_ratio": 1.813397129186603, "no_speech_prob": 0.003148401388898492}, {"id": 235, "seek": 141916, "start": 1419.16, "end": 1425.8000000000002, "text": " passing scheme that could perform inferences about this sort of model and you can see that the", "tokens": [50364, 8437, 12232, 300, 727, 2042, 13596, 2667, 466, 341, 1333, 295, 2316, 293, 291, 393, 536, 300, 264, 50696], "temperature": 0.0, "avg_logprob": -0.07645668869926817, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.07216357439756393}, {"id": 236, "seek": 141916, "start": 1425.8000000000002, "end": 1432.6000000000001, "text": " message passing scheme to some extent looks like an inversion or or as loosely a sort of mirror", "tokens": [50696, 3636, 8437, 12232, 281, 512, 8396, 1542, 411, 364, 43576, 420, 420, 382, 37966, 257, 1333, 295, 8013, 51036], "temperature": 0.0, "avg_logprob": -0.07645668869926817, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.07216357439756393}, {"id": 237, "seek": 141916, "start": 1432.6000000000001, "end": 1437.5600000000002, "text": " image of the generative model because all it's doing is taking each step that was performed", "tokens": [51036, 3256, 295, 264, 1337, 1166, 2316, 570, 439, 309, 311, 884, 307, 1940, 1184, 1823, 300, 390, 10332, 51284], "temperature": 0.0, "avg_logprob": -0.07645668869926817, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.07216357439756393}, {"id": 238, "seek": 141916, "start": 1437.5600000000002, "end": 1442.2, "text": " to generate some data and then inverting those steps one at a time so it's just going backwards", "tokens": [51284, 281, 8460, 512, 1412, 293, 550, 28653, 783, 729, 4439, 472, 412, 257, 565, 370, 309, 311, 445, 516, 12204, 51516], "temperature": 0.0, "avg_logprob": -0.07645668869926817, "compression_ratio": 1.766355140186916, "no_speech_prob": 0.07216357439756393}, {"id": 239, "seek": 144220, "start": 1442.28, "end": 1450.28, "text": " from the data to arrive at the causes of those data. Now what I've got shown here on the left", "tokens": [50368, 490, 264, 1412, 281, 8881, 412, 264, 7700, 295, 729, 1412, 13, 823, 437, 286, 600, 658, 4898, 510, 322, 264, 1411, 50768], "temperature": 0.0, "avg_logprob": -0.14677784408348193, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.037056367844343185}, {"id": 240, "seek": 144220, "start": 1451.24, "end": 1459.24, "text": " is just a sort of cartoon image of some of the key connections in in cortical micro circuits", "tokens": [50816, 307, 445, 257, 1333, 295, 18569, 3256, 295, 512, 295, 264, 2141, 9271, 294, 294, 11278, 804, 4532, 26354, 51216], "temperature": 0.0, "avg_logprob": -0.14677784408348193, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.037056367844343185}, {"id": 241, "seek": 144220, "start": 1459.24, "end": 1466.28, "text": " so here we've got superficial pyramidal cells as spiny stellate cells as SS deep pyramidal", "tokens": [51216, 370, 510, 321, 600, 658, 34622, 20543, 22151, 5438, 382, 637, 3519, 30787, 473, 5438, 382, 12238, 2452, 20543, 22151, 51568], "temperature": 0.0, "avg_logprob": -0.14677784408348193, "compression_ratio": 1.582857142857143, "no_speech_prob": 0.037056367844343185}, {"id": 242, "seek": 146628, "start": 1466.28, "end": 1474.84, "text": " cells as DP and inhibitory engineer arms as the double eyes and this is clearly an oversimplification", "tokens": [50364, 5438, 382, 42796, 293, 49858, 827, 11403, 5812, 382, 264, 3834, 2575, 293, 341, 307, 4448, 364, 15488, 332, 564, 3774, 50792], "temperature": 0.0, "avg_logprob": -0.10923777070156364, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.0063942414708435535}, {"id": 243, "seek": 146628, "start": 1474.84, "end": 1481.6399999999999, "text": " of what is a very complex connectivity structure but the reason I'm showing this here is that", "tokens": [50792, 295, 437, 307, 257, 588, 3997, 21095, 3877, 457, 264, 1778, 286, 478, 4099, 341, 510, 307, 300, 51132], "temperature": 0.0, "avg_logprob": -0.10923777070156364, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.0063942414708435535}, {"id": 244, "seek": 146628, "start": 1482.44, "end": 1487.72, "text": " if we know something about this connectivity structure if we know about some of the key patterns", "tokens": [51172, 498, 321, 458, 746, 466, 341, 21095, 3877, 498, 321, 458, 466, 512, 295, 264, 2141, 8294, 51436], "temperature": 0.0, "avg_logprob": -0.10923777070156364, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.0063942414708435535}, {"id": 245, "seek": 146628, "start": 1487.72, "end": 1492.36, "text": " we can start to ask how can the the sorts of models that we've spoken about over the last", "tokens": [51436, 321, 393, 722, 281, 1029, 577, 393, 264, 264, 7527, 295, 5245, 300, 321, 600, 10759, 466, 670, 264, 1036, 51668], "temperature": 0.0, "avg_logprob": -0.10923777070156364, "compression_ratio": 1.7207207207207207, "no_speech_prob": 0.0063942414708435535}, {"id": 246, "seek": 149236, "start": 1492.36, "end": 1498.12, "text": " couple of slides then be interpreted in terms of the micro circuits that could help", "tokens": [50364, 1916, 295, 9788, 550, 312, 26749, 294, 2115, 295, 264, 4532, 26354, 300, 727, 854, 50652], "temperature": 0.0, "avg_logprob": -0.12182176113128662, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.010126054286956787}, {"id": 247, "seek": 149236, "start": 1499.8, "end": 1505.6399999999999, "text": " could help implement these in a biological system. So what I'm going to show in the middle", "tokens": [50736, 727, 854, 4445, 613, 294, 257, 13910, 1185, 13, 407, 437, 286, 478, 516, 281, 855, 294, 264, 2808, 51028], "temperature": 0.0, "avg_logprob": -0.12182176113128662, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.010126054286956787}, {"id": 248, "seek": 149236, "start": 1505.6399999999999, "end": 1513.24, "text": " is an example of a continuous states-based predictive coding style model that has all", "tokens": [51028, 307, 364, 1365, 295, 257, 10957, 4368, 12, 6032, 35521, 17720, 3758, 2316, 300, 575, 439, 51408], "temperature": 0.0, "avg_logprob": -0.12182176113128662, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.010126054286956787}, {"id": 249, "seek": 149236, "start": 1513.24, "end": 1517.3999999999999, "text": " the same elements as in the slide I showed you before but are now mapped so that some of the", "tokens": [51408, 264, 912, 4959, 382, 294, 264, 4137, 286, 4712, 291, 949, 457, 366, 586, 33318, 370, 300, 512, 295, 264, 51616], "temperature": 0.0, "avg_logprob": -0.12182176113128662, "compression_ratio": 1.6418604651162791, "no_speech_prob": 0.010126054286956787}, {"id": 250, "seek": 151740, "start": 1517.4, "end": 1524.2800000000002, "text": " connections coming in and out of it loosely map to those associated with a known cortical anatomy", "tokens": [50364, 9271, 1348, 294, 293, 484, 295, 309, 37966, 4471, 281, 729, 6615, 365, 257, 2570, 11278, 804, 31566, 50708], "temperature": 0.0, "avg_logprob": -0.0795326346442813, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.009933894500136375}, {"id": 251, "seek": 151740, "start": 1525.88, "end": 1530.6000000000001, "text": " and we can do exactly the same thing here with the discrete states-based model and think about how", "tokens": [50788, 293, 321, 393, 360, 2293, 264, 912, 551, 510, 365, 264, 27706, 4368, 12, 6032, 2316, 293, 519, 466, 577, 51024], "temperature": 0.0, "avg_logprob": -0.0795326346442813, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.009933894500136375}, {"id": 252, "seek": 151740, "start": 1530.6000000000001, "end": 1536.44, "text": " we can assign those roles associated with the roles of different cortical layers", "tokens": [51024, 321, 393, 6269, 729, 9604, 6615, 365, 264, 9604, 295, 819, 11278, 804, 7914, 51316], "temperature": 0.0, "avg_logprob": -0.0795326346442813, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.009933894500136375}, {"id": 253, "seek": 151740, "start": 1537.48, "end": 1543.5600000000002, "text": " and then use that as a way of forming hypotheses. Now what I'm showing you on this slide is not", "tokens": [51368, 293, 550, 764, 300, 382, 257, 636, 295, 15745, 49969, 13, 823, 437, 286, 478, 4099, 291, 322, 341, 4137, 307, 406, 51672], "temperature": 0.0, "avg_logprob": -0.0795326346442813, "compression_ratio": 1.6954545454545455, "no_speech_prob": 0.009933894500136375}, {"id": 254, "seek": 154356, "start": 1543.8799999999999, "end": 1548.28, "text": " necessarily the last word on this and you could formulate several different hypotheses about how", "tokens": [50380, 4725, 264, 1036, 1349, 322, 341, 293, 291, 727, 47881, 2940, 819, 49969, 466, 577, 50600], "temperature": 0.0, "avg_logprob": -0.06361807414463588, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006672747898846865}, {"id": 255, "seek": 154356, "start": 1548.28, "end": 1552.84, "text": " these two things map together and that's where a lot of interesting science happens. This is just", "tokens": [50600, 613, 732, 721, 4471, 1214, 293, 300, 311, 689, 257, 688, 295, 1880, 3497, 2314, 13, 639, 307, 445, 50828], "temperature": 0.0, "avg_logprob": -0.06361807414463588, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006672747898846865}, {"id": 256, "seek": 154356, "start": 1552.84, "end": 1558.6799999999998, "text": " one example of how we can associate what we know about cortical microcircuitry and anatomy", "tokens": [50828, 472, 1365, 295, 577, 321, 393, 14644, 437, 321, 458, 466, 11278, 804, 4532, 23568, 66, 1983, 627, 293, 31566, 51120], "temperature": 0.0, "avg_logprob": -0.06361807414463588, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006672747898846865}, {"id": 257, "seek": 154356, "start": 1558.6799999999998, "end": 1563.32, "text": " with what we know about the anatomy of message passing for some simple generic forms of generative", "tokens": [51120, 365, 437, 321, 458, 466, 264, 31566, 295, 3636, 8437, 337, 512, 2199, 19577, 6422, 295, 1337, 1166, 51352], "temperature": 0.0, "avg_logprob": -0.06361807414463588, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006672747898846865}, {"id": 258, "seek": 154356, "start": 1563.32, "end": 1568.52, "text": " model. What I'm going to try and do over the rest of this presentation is to take the connections", "tokens": [51352, 2316, 13, 708, 286, 478, 516, 281, 853, 293, 360, 670, 264, 1472, 295, 341, 5860, 307, 281, 747, 264, 9271, 51612], "temperature": 0.0, "avg_logprob": -0.06361807414463588, "compression_ratio": 1.7275985663082438, "no_speech_prob": 0.006672747898846865}, {"id": 259, "seek": 156852, "start": 1568.6, "end": 1575.48, "text": " coming out of this out of each of these points and to try and think about how those might or the", "tokens": [50368, 1348, 484, 295, 341, 484, 295, 1184, 295, 613, 2793, 293, 281, 853, 293, 519, 466, 577, 729, 1062, 420, 264, 50712], "temperature": 0.0, "avg_logprob": -0.11254738117086477, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.14924663305282593}, {"id": 260, "seek": 156852, "start": 1575.48, "end": 1580.6, "text": " roles they might those might play when we take an active entrance approach and the sorts of structures", "tokens": [50712, 9604, 436, 1062, 729, 1062, 862, 562, 321, 747, 364, 4967, 12014, 3109, 293, 264, 7527, 295, 9227, 50968], "temperature": 0.0, "avg_logprob": -0.11254738117086477, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.14924663305282593}, {"id": 261, "seek": 156852, "start": 1580.6, "end": 1587.72, "text": " in the brain that might be involved in dealing with those dealing with those things. I'm going to", "tokens": [50968, 294, 264, 3567, 300, 1062, 312, 3288, 294, 6260, 365, 729, 6260, 365, 729, 721, 13, 286, 478, 516, 281, 51324], "temperature": 0.0, "avg_logprob": -0.11254738117086477, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.14924663305282593}, {"id": 262, "seek": 156852, "start": 1587.72, "end": 1593.0, "text": " start by talking about movement and reflexes so here the kinds of things we're interested in", "tokens": [51324, 722, 538, 1417, 466, 3963, 293, 23802, 279, 370, 510, 264, 3685, 295, 721, 321, 434, 3102, 294, 51588], "temperature": 0.0, "avg_logprob": -0.11254738117086477, "compression_ratio": 1.7889908256880733, "no_speech_prob": 0.14924663305282593}, {"id": 263, "seek": 159300, "start": 1593.08, "end": 1599.56, "text": " are the connections that leave the cortex and go to areas like the spinal cord in the motor", "tokens": [50368, 366, 264, 9271, 300, 1856, 264, 33312, 293, 352, 281, 3179, 411, 264, 28022, 12250, 294, 264, 5932, 50692], "temperature": 0.0, "avg_logprob": -0.10436579238536746, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.02102414146065712}, {"id": 264, "seek": 159300, "start": 1599.56, "end": 1608.36, "text": " neurons, the predictions that we can then make about what we're seeing here in the central", "tokens": [50692, 22027, 11, 264, 21264, 300, 321, 393, 550, 652, 466, 437, 321, 434, 2577, 510, 294, 264, 5777, 51132], "temperature": 0.0, "avg_logprob": -0.10436579238536746, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.02102414146065712}, {"id": 265, "seek": 159300, "start": 1608.36, "end": 1614.28, "text": " plot and the G that's been circled in red is a prediction about the sort of data I might expect", "tokens": [51132, 7542, 293, 264, 460, 300, 311, 668, 3510, 1493, 294, 2182, 307, 257, 17630, 466, 264, 1333, 295, 1412, 286, 1062, 2066, 51428], "temperature": 0.0, "avg_logprob": -0.10436579238536746, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.02102414146065712}, {"id": 266, "seek": 159300, "start": 1614.28, "end": 1619.24, "text": " to observe which may here be proprioceptive data consequent on particular sorts of action.", "tokens": [51428, 281, 11441, 597, 815, 510, 312, 28203, 1336, 488, 1412, 7242, 317, 322, 1729, 7527, 295, 3069, 13, 51676], "temperature": 0.0, "avg_logprob": -0.10436579238536746, "compression_ratio": 1.716279069767442, "no_speech_prob": 0.02102414146065712}, {"id": 267, "seek": 161924, "start": 1619.8, "end": 1625.16, "text": " And we can think of this quite simply if we think about the structure of a reflex arc.", "tokens": [50392, 400, 321, 393, 519, 295, 341, 1596, 2935, 498, 321, 519, 466, 264, 3877, 295, 257, 23802, 10346, 13, 50660], "temperature": 0.0, "avg_logprob": -0.13360734419389206, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.0030977418646216393}, {"id": 268, "seek": 161924, "start": 1626.2, "end": 1631.88, "text": " So what I've got here on the lower part is just the same marginal likelihood or model evidence", "tokens": [50712, 407, 437, 286, 600, 658, 510, 322, 264, 3126, 644, 307, 445, 264, 912, 16885, 22119, 420, 2316, 4467, 50996], "temperature": 0.0, "avg_logprob": -0.13360734419389206, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.0030977418646216393}, {"id": 269, "seek": 161924, "start": 1631.88, "end": 1637.0, "text": " that we've dealt with before this idea of it being a measure of the fit of the model both in", "tokens": [50996, 300, 321, 600, 15991, 365, 949, 341, 1558, 295, 309, 885, 257, 3481, 295, 264, 3318, 295, 264, 2316, 1293, 294, 51252], "temperature": 0.0, "avg_logprob": -0.13360734419389206, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.0030977418646216393}, {"id": 270, "seek": 161924, "start": 1637.0, "end": 1644.28, "text": " terms of its accuracy, the accuracy with which it predicts some data and the simplest least complex", "tokens": [51252, 2115, 295, 1080, 14170, 11, 264, 14170, 365, 597, 309, 6069, 82, 512, 1412, 293, 264, 22811, 1935, 3997, 51616], "temperature": 0.0, "avg_logprob": -0.13360734419389206, "compression_ratio": 1.6475770925110131, "no_speech_prob": 0.0030977418646216393}, {"id": 271, "seek": 164428, "start": 1644.28, "end": 1649.6399999999999, "text": " version of the model that will work for that. What do we do when we change the data? Well we try and", "tokens": [50364, 3037, 295, 264, 2316, 300, 486, 589, 337, 300, 13, 708, 360, 321, 360, 562, 321, 1319, 264, 1412, 30, 1042, 321, 853, 293, 50632], "temperature": 0.0, "avg_logprob": -0.07061702711088164, "compression_ratio": 1.8314606741573034, "no_speech_prob": 0.008315046317875385}, {"id": 272, "seek": 164428, "start": 1649.6399999999999, "end": 1656.68, "text": " make the data more accurate in relation to our model by trying to align the data with our predictions.", "tokens": [50632, 652, 264, 1412, 544, 8559, 294, 9721, 281, 527, 2316, 538, 1382, 281, 7975, 264, 1412, 365, 527, 21264, 13, 50984], "temperature": 0.0, "avg_logprob": -0.07061702711088164, "compression_ratio": 1.8314606741573034, "no_speech_prob": 0.008315046317875385}, {"id": 273, "seek": 164428, "start": 1657.3999999999999, "end": 1663.32, "text": " So when we think of the structure of a reflex arc where we can interpret it as some descending", "tokens": [51020, 407, 562, 321, 519, 295, 264, 3877, 295, 257, 23802, 10346, 689, 321, 393, 7302, 309, 382, 512, 40182, 51316], "temperature": 0.0, "avg_logprob": -0.07061702711088164, "compression_ratio": 1.8314606741573034, "no_speech_prob": 0.008315046317875385}, {"id": 274, "seek": 164428, "start": 1663.32, "end": 1667.96, "text": " prediction coming from the motor cortex saying what is the proprioceptive data I expect to", "tokens": [51316, 17630, 1348, 490, 264, 5932, 33312, 1566, 437, 307, 264, 28203, 1336, 488, 1412, 286, 2066, 281, 51548], "temperature": 0.0, "avg_logprob": -0.07061702711088164, "compression_ratio": 1.8314606741573034, "no_speech_prob": 0.008315046317875385}, {"id": 275, "seek": 164428, "start": 1667.96, "end": 1673.8, "text": " observe. By comparing that with the proprioceptive data that's actually coming into the spinal cord", "tokens": [51548, 11441, 13, 3146, 15763, 300, 365, 264, 28203, 1336, 488, 1412, 300, 311, 767, 1348, 666, 264, 28022, 12250, 51840], "temperature": 0.0, "avg_logprob": -0.07061702711088164, "compression_ratio": 1.8314606741573034, "no_speech_prob": 0.008315046317875385}, {"id": 276, "seek": 167380, "start": 1673.8, "end": 1679.56, "text": " through the dorsal horn with that prediction we then get a potentially a mismatch between the two", "tokens": [50364, 807, 264, 274, 830, 304, 13482, 365, 300, 17630, 321, 550, 483, 257, 7263, 257, 23220, 852, 1296, 264, 732, 50652], "temperature": 0.0, "avg_logprob": -0.08160856868443864, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0025960132479667664}, {"id": 277, "seek": 167380, "start": 1679.56, "end": 1686.12, "text": " that can be used to generate action via the ventral horn generating movements and contractions and", "tokens": [50652, 300, 393, 312, 1143, 281, 8460, 3069, 5766, 264, 6931, 2155, 13482, 17746, 9981, 293, 4364, 626, 293, 50980], "temperature": 0.0, "avg_logprob": -0.08160856868443864, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0025960132479667664}, {"id": 278, "seek": 167380, "start": 1686.12, "end": 1693.1599999999999, "text": " muscles that then try to fulfill these predictions. I'll show you just an example of a simulation of", "tokens": [50980, 9530, 300, 550, 853, 281, 13875, 613, 21264, 13, 286, 603, 855, 291, 445, 364, 1365, 295, 257, 16575, 295, 51332], "temperature": 0.0, "avg_logprob": -0.08160856868443864, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0025960132479667664}, {"id": 279, "seek": 167380, "start": 1695.0, "end": 1700.28, "text": " an arm using active inference that has these sort of reflex arcs built in and all we're doing here", "tokens": [51424, 364, 3726, 1228, 4967, 38253, 300, 575, 613, 1333, 295, 23802, 10346, 82, 3094, 294, 293, 439, 321, 434, 884, 510, 51688], "temperature": 0.0, "avg_logprob": -0.08160856868443864, "compression_ratio": 1.7142857142857142, "no_speech_prob": 0.0025960132479667664}, {"id": 280, "seek": 170028, "start": 1700.28, "end": 1706.36, "text": " is we're just tapping on the biceps tendon where the red arrow is pointing and we're just seeing", "tokens": [50364, 307, 321, 434, 445, 21444, 322, 264, 272, 35552, 46479, 689, 264, 2182, 11610, 307, 12166, 293, 321, 434, 445, 2577, 50668], "temperature": 0.0, "avg_logprob": -0.07770757910646038, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.015386459417641163}, {"id": 281, "seek": 170028, "start": 1706.36, "end": 1712.36, "text": " the reflexive response that we're getting as a consequence of effectively inducing this additional", "tokens": [50668, 264, 23802, 488, 4134, 300, 321, 434, 1242, 382, 257, 18326, 295, 8659, 13716, 2175, 341, 4497, 50968], "temperature": 0.0, "avg_logprob": -0.07770757910646038, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.015386459417641163}, {"id": 282, "seek": 170028, "start": 1712.36, "end": 1718.2, "text": " piece of sensory proprioceptive information by stretching that tendon. We induce the mismatch", "tokens": [50968, 2522, 295, 27233, 28203, 1336, 488, 1589, 538, 19632, 300, 46479, 13, 492, 41263, 264, 23220, 852, 51260], "temperature": 0.0, "avg_logprob": -0.07770757910646038, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.015386459417641163}, {"id": 283, "seek": 170028, "start": 1718.2, "end": 1724.6, "text": " between the prediction that's coming down and the data that's coming out and that", "tokens": [51260, 1296, 264, 17630, 300, 311, 1348, 760, 293, 264, 1412, 300, 311, 1348, 484, 293, 300, 51580], "temperature": 0.0, "avg_logprob": -0.07770757910646038, "compression_ratio": 1.7666666666666666, "no_speech_prob": 0.015386459417641163}, {"id": 284, "seek": 172460, "start": 1725.3999999999999, "end": 1731.32, "text": " is corrected then by generating this additional movement. Interestingly we can do things by", "tokens": [50404, 307, 31687, 550, 538, 17746, 341, 4497, 3963, 13, 30564, 321, 393, 360, 721, 538, 50700], "temperature": 0.0, "avg_logprob": -0.12364783578989458, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.014471643604338169}, {"id": 285, "seek": 172460, "start": 1731.32, "end": 1736.36, "text": " manipulating the confidence of those predictions and sometimes get things like bigger reflexes", "tokens": [50700, 40805, 264, 6687, 295, 729, 21264, 293, 2171, 483, 721, 411, 3801, 23802, 279, 50952], "temperature": 0.0, "avg_logprob": -0.12364783578989458, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.014471643604338169}, {"id": 286, "seek": 172460, "start": 1736.36, "end": 1740.84, "text": " and hyperreflexia as the sort you might see in clinical populations with spinal cord injuries", "tokens": [50952, 293, 9848, 33115, 2021, 654, 382, 264, 1333, 291, 1062, 536, 294, 9115, 12822, 365, 28022, 12250, 14799, 51176], "temperature": 0.0, "avg_logprob": -0.12364783578989458, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.014471643604338169}, {"id": 287, "seek": 172460, "start": 1742.36, "end": 1746.4399999999998, "text": " and so here you can see the reflex is slightly larger than it was before and slightly brisker.", "tokens": [51252, 293, 370, 510, 291, 393, 536, 264, 23802, 307, 4748, 4833, 813, 309, 390, 949, 293, 4748, 738, 271, 5767, 13, 51456], "temperature": 0.0, "avg_logprob": -0.12364783578989458, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.014471643604338169}, {"id": 288, "seek": 172460, "start": 1748.36, "end": 1754.4399999999998, "text": " I'll show you another example of this same idea where now we've developed a mapping between", "tokens": [51552, 286, 603, 855, 291, 1071, 1365, 295, 341, 912, 1558, 689, 586, 321, 600, 4743, 257, 18350, 1296, 51856], "temperature": 0.0, "avg_logprob": -0.12364783578989458, "compression_ratio": 1.7232472324723247, "no_speech_prob": 0.014471643604338169}, {"id": 289, "seek": 175444, "start": 1754.8400000000001, "end": 1761.16, "text": " the microcircuit and the anatomy of the ocular motor brainstem so here starting from the superior", "tokens": [50384, 264, 4532, 23568, 66, 1983, 293, 264, 31566, 295, 264, 10409, 1040, 5932, 3567, 1099, 370, 510, 2891, 490, 264, 13028, 50700], "temperature": 0.0, "avg_logprob": -0.26043995448521207, "compression_ratio": 1.7337278106508875, "no_speech_prob": 0.0031974741723388433}, {"id": 290, "seek": 175444, "start": 1761.16, "end": 1768.8400000000001, "text": " colliculus the the rostral interstitial nucleus of the medial longitudinal vesiculus and there is", "tokens": [50700, 1263, 299, 26107, 264, 264, 367, 555, 2155, 728, 372, 270, 831, 28055, 295, 264, 1205, 831, 48250, 28274, 299, 26107, 293, 456, 307, 51084], "temperature": 0.0, "avg_logprob": -0.26043995448521207, "compression_ratio": 1.7337278106508875, "no_speech_prob": 0.0031974741723388433}, {"id": 291, "seek": 175444, "start": 1768.8400000000001, "end": 1776.28, "text": " other centers and the cranial nerves that are responsible for generating eye movements so cranial", "tokens": [51084, 661, 10898, 293, 264, 39685, 831, 23078, 300, 366, 6250, 337, 17746, 3313, 9981, 370, 39685, 831, 51456], "temperature": 0.0, "avg_logprob": -0.26043995448521207, "compression_ratio": 1.7337278106508875, "no_speech_prob": 0.0031974741723388433}, {"id": 292, "seek": 177628, "start": 1776.28, "end": 1785.56, "text": " nerve three and cranial nerve six here are seen here as resulting from these error terms so we're", "tokens": [50364, 16355, 1045, 293, 39685, 831, 16355, 2309, 510, 366, 1612, 510, 382, 16505, 490, 613, 6713, 2115, 370, 321, 434, 50828], "temperature": 0.0, "avg_logprob": -0.0790955282392956, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.08497403562068939}, {"id": 293, "seek": 177628, "start": 1785.56, "end": 1792.28, "text": " predicting how I would expect my eyes to move and any error in the current position of the eyes is", "tokens": [50828, 32884, 577, 286, 576, 2066, 452, 2575, 281, 1286, 293, 604, 6713, 294, 264, 2190, 2535, 295, 264, 2575, 307, 51164], "temperature": 0.0, "avg_logprob": -0.0790955282392956, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.08497403562068939}, {"id": 294, "seek": 177628, "start": 1792.28, "end": 1798.28, "text": " corrected by generating eye movements so by inducing different priors on top of this model", "tokens": [51164, 31687, 538, 17746, 3313, 9981, 370, 538, 13716, 2175, 819, 1790, 830, 322, 1192, 295, 341, 2316, 51464], "temperature": 0.0, "avg_logprob": -0.0790955282392956, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.08497403562068939}, {"id": 295, "seek": 177628, "start": 1798.28, "end": 1802.36, "text": " of different predictions about where I'd expect the eyes to be we can actually then generate", "tokens": [51464, 295, 819, 21264, 466, 689, 286, 1116, 2066, 264, 2575, 281, 312, 321, 393, 767, 550, 8460, 51668], "temperature": 0.0, "avg_logprob": -0.0790955282392956, "compression_ratio": 1.7674418604651163, "no_speech_prob": 0.08497403562068939}, {"id": 296, "seek": 180236, "start": 1802.36, "end": 1809.4799999999998, "text": " different sorts of eye movements using predictive coding style active inference scheme where the key", "tokens": [50364, 819, 7527, 295, 3313, 9981, 1228, 35521, 17720, 3758, 4967, 38253, 12232, 689, 264, 2141, 50720], "temperature": 0.0, "avg_logprob": -0.09040659124200995, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004099942743778229}, {"id": 297, "seek": 180236, "start": 1809.4799999999998, "end": 1814.36, "text": " thing is that the predictions can be fulfilled by actually changing the positions of our muscles", "tokens": [50720, 551, 307, 300, 264, 21264, 393, 312, 21380, 538, 767, 4473, 264, 8432, 295, 527, 9530, 50964], "temperature": 0.0, "avg_logprob": -0.09040659124200995, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004099942743778229}, {"id": 298, "seek": 180236, "start": 1814.36, "end": 1822.6799999999998, "text": " and positions of our eyes so that sort of provides a very brief overview and a couple of examples", "tokens": [50964, 293, 8432, 295, 527, 2575, 370, 300, 1333, 295, 6417, 257, 588, 5353, 12492, 293, 257, 1916, 295, 5110, 51380], "temperature": 0.0, "avg_logprob": -0.09040659124200995, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004099942743778229}, {"id": 299, "seek": 180236, "start": 1823.6399999999999, "end": 1831.3999999999999, "text": " dealing with the role of reflexes and predictions in generating movements but it doesn't really", "tokens": [51428, 6260, 365, 264, 3090, 295, 23802, 279, 293, 21264, 294, 17746, 9981, 457, 309, 1177, 380, 534, 51816], "temperature": 0.0, "avg_logprob": -0.09040659124200995, "compression_ratio": 1.7935779816513762, "no_speech_prob": 0.004099942743778229}, {"id": 300, "seek": 183140, "start": 1831.4, "end": 1836.2800000000002, "text": " tell us anything about how movements are chosen how movements are selected and you don't necessarily", "tokens": [50364, 980, 505, 1340, 466, 577, 9981, 366, 8614, 577, 9981, 366, 8209, 293, 291, 500, 380, 4725, 50608], "temperature": 0.0, "avg_logprob": -0.04755619084723642, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.005974817089736462}, {"id": 301, "seek": 183140, "start": 1836.2800000000002, "end": 1840.8400000000001, "text": " get any intelligent behavior out of that and for that we need to start looking at different sorts", "tokens": [50608, 483, 604, 13232, 5223, 484, 295, 300, 293, 337, 300, 321, 643, 281, 722, 1237, 412, 819, 7527, 50836], "temperature": 0.0, "avg_logprob": -0.04755619084723642, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.005974817089736462}, {"id": 302, "seek": 183140, "start": 1840.8400000000001, "end": 1847.16, "text": " of structures and different parts of this generative model and here the key thing I want to focus on", "tokens": [50836, 295, 9227, 293, 819, 3166, 295, 341, 1337, 1166, 2316, 293, 510, 264, 2141, 551, 286, 528, 281, 1879, 322, 51152], "temperature": 0.0, "avg_logprob": -0.04755619084723642, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.005974817089736462}, {"id": 303, "seek": 183140, "start": 1847.16, "end": 1853.0, "text": " is the role of the basal ganglia and which here we're going to associate with the computation", "tokens": [51152, 307, 264, 3090, 295, 264, 987, 304, 10145, 14218, 293, 597, 510, 321, 434, 516, 281, 14644, 365, 264, 24903, 51444], "temperature": 0.0, "avg_logprob": -0.04755619084723642, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.005974817089736462}, {"id": 304, "seek": 183140, "start": 1853.0, "end": 1857.96, "text": " of something known as the expected free energy and I'll try and describe what that is a little bit", "tokens": [51444, 295, 746, 2570, 382, 264, 5176, 1737, 2281, 293, 286, 603, 853, 293, 6786, 437, 300, 307, 257, 707, 857, 51692], "temperature": 0.0, "avg_logprob": -0.04755619084723642, "compression_ratio": 1.7697841726618706, "no_speech_prob": 0.005974817089736462}, {"id": 305, "seek": 185796, "start": 1857.96, "end": 1865.88, "text": " more in some of the subsequent slides so what I'm showing here is a mapping of some of the", "tokens": [50364, 544, 294, 512, 295, 264, 19962, 9788, 370, 437, 286, 478, 4099, 510, 307, 257, 18350, 295, 512, 295, 264, 50760], "temperature": 0.0, "avg_logprob": -0.12492570984229613, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.005929730366915464}, {"id": 306, "seek": 185796, "start": 1866.68, "end": 1871.88, "text": " subcortical but subcortical anatomy or more actually I should say that this is a mapping", "tokens": [50800, 1422, 66, 477, 804, 457, 1422, 66, 477, 804, 31566, 420, 544, 767, 286, 820, 584, 300, 341, 307, 257, 18350, 51060], "temperature": 0.0, "avg_logprob": -0.12492570984229613, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.005929730366915464}, {"id": 307, "seek": 185796, "start": 1871.88, "end": 1878.44, "text": " between parts of our Bayesian message passing scheme parts of the model inversion when we're", "tokens": [51060, 1296, 3166, 295, 527, 7840, 42434, 3636, 8437, 12232, 3166, 295, 264, 2316, 43576, 562, 321, 434, 51388], "temperature": 0.0, "avg_logprob": -0.12492570984229613, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.005929730366915464}, {"id": 308, "seek": 185796, "start": 1878.44, "end": 1886.68, "text": " dealing with the ability to plan and make decisions to some of the known subcortical anatomy of the", "tokens": [51388, 6260, 365, 264, 3485, 281, 1393, 293, 652, 5327, 281, 512, 295, 264, 2570, 1422, 66, 477, 804, 31566, 295, 264, 51800], "temperature": 0.0, "avg_logprob": -0.12492570984229613, "compression_ratio": 1.832512315270936, "no_speech_prob": 0.005929730366915464}, {"id": 309, "seek": 188668, "start": 1886.68, "end": 1894.2, "text": " brain and the key thing I want to focus on is this G that is depicted as part of the as part of", "tokens": [50364, 3567, 293, 264, 2141, 551, 286, 528, 281, 1879, 322, 307, 341, 460, 300, 307, 30207, 382, 644, 295, 264, 382, 644, 295, 50740], "temperature": 0.0, "avg_logprob": -0.11326855879563552, "compression_ratio": 1.8300970873786409, "no_speech_prob": 0.00820563081651926}, {"id": 310, "seek": 188668, "start": 1894.2, "end": 1900.76, "text": " the stride and so the things that are feeding into this are what we're getting from the cortex", "tokens": [50740, 264, 1056, 482, 293, 370, 264, 721, 300, 366, 12919, 666, 341, 366, 437, 321, 434, 1242, 490, 264, 33312, 51068], "temperature": 0.0, "avg_logprob": -0.11326855879563552, "compression_ratio": 1.8300970873786409, "no_speech_prob": 0.00820563081651926}, {"id": 311, "seek": 188668, "start": 1900.76, "end": 1905.0800000000002, "text": " here which is some prediction of the outcomes we'd expect if I were to pursue a particular", "tokens": [51068, 510, 597, 307, 512, 17630, 295, 264, 10070, 321, 1116, 2066, 498, 286, 645, 281, 12392, 257, 1729, 51284], "temperature": 0.0, "avg_logprob": -0.11326855879563552, "compression_ratio": 1.8300970873786409, "no_speech_prob": 0.00820563081651926}, {"id": 312, "seek": 188668, "start": 1905.0800000000002, "end": 1912.44, "text": " cause of action which is this subscript pi and the another sort of error term here which is how", "tokens": [51284, 3082, 295, 3069, 597, 307, 341, 2325, 662, 3895, 293, 264, 1071, 1333, 295, 6713, 1433, 510, 597, 307, 577, 51652], "temperature": 0.0, "avg_logprob": -0.11326855879563552, "compression_ratio": 1.8300970873786409, "no_speech_prob": 0.00820563081651926}, {"id": 313, "seek": 191244, "start": 1912.44, "end": 1920.92, "text": " far away are those predictions from my preferences about how the world should be my prior beliefs", "tokens": [50364, 1400, 1314, 366, 729, 21264, 490, 452, 21910, 466, 577, 264, 1002, 820, 312, 452, 4059, 13585, 50788], "temperature": 0.0, "avg_logprob": -0.0620672908830054, "compression_ratio": 1.8516746411483254, "no_speech_prob": 0.005917510949075222}, {"id": 314, "seek": 191244, "start": 1920.92, "end": 1929.96, "text": " about how the kind of data that I would actually actively seek out and act to get together those", "tokens": [50788, 466, 577, 264, 733, 295, 1412, 300, 286, 576, 767, 13022, 8075, 484, 293, 605, 281, 483, 1214, 729, 51240], "temperature": 0.0, "avg_logprob": -0.0620672908830054, "compression_ratio": 1.8516746411483254, "no_speech_prob": 0.005917510949075222}, {"id": 315, "seek": 191244, "start": 1929.96, "end": 1935.64, "text": " are used to calculate our expected free energy which we can then use to formulate beliefs about", "tokens": [51240, 366, 1143, 281, 8873, 527, 5176, 1737, 2281, 597, 321, 393, 550, 764, 281, 47881, 13585, 466, 51524], "temperature": 0.0, "avg_logprob": -0.0620672908830054, "compression_ratio": 1.8516746411483254, "no_speech_prob": 0.005917510949075222}, {"id": 316, "seek": 191244, "start": 1935.64, "end": 1941.48, "text": " policies by saying that the policies we would select the plans we would engage in are those that", "tokens": [51524, 7657, 538, 1566, 300, 264, 7657, 321, 576, 3048, 264, 5482, 321, 576, 4683, 294, 366, 729, 300, 51816], "temperature": 0.0, "avg_logprob": -0.0620672908830054, "compression_ratio": 1.8516746411483254, "no_speech_prob": 0.005917510949075222}, {"id": 317, "seek": 194148, "start": 1941.48, "end": 1948.44, "text": " we would expect to be associated with the lowest expected free energy and to put that more formally", "tokens": [50364, 321, 576, 2066, 281, 312, 6615, 365, 264, 12437, 5176, 1737, 2281, 293, 281, 829, 300, 544, 25983, 50712], "temperature": 0.0, "avg_logprob": -0.08853720455634885, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.006700757425278425}, {"id": 318, "seek": 194148, "start": 1949.56, "end": 1955.96, "text": " we're saying that we're going to give a prior belief that the policies the series of actions", "tokens": [50768, 321, 434, 1566, 300, 321, 434, 516, 281, 976, 257, 4059, 7107, 300, 264, 7657, 264, 2638, 295, 5909, 51088], "temperature": 0.0, "avg_logprob": -0.08853720455634885, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.006700757425278425}, {"id": 319, "seek": 194148, "start": 1955.96, "end": 1960.44, "text": " we're going to choose are going to be those associated with the maximum information gain", "tokens": [51088, 321, 434, 516, 281, 2826, 366, 516, 281, 312, 729, 6615, 365, 264, 6674, 1589, 6052, 51312], "temperature": 0.0, "avg_logprob": -0.08853720455634885, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.006700757425278425}, {"id": 320, "seek": 194148, "start": 1960.44, "end": 1967.8, "text": " tell us the most about the world around us that fulfill our preferences and then we're going to", "tokens": [51312, 980, 505, 264, 881, 466, 264, 1002, 926, 505, 300, 13875, 527, 21910, 293, 550, 321, 434, 516, 281, 51680], "temperature": 0.0, "avg_logprob": -0.08853720455634885, "compression_ratio": 1.8571428571428572, "no_speech_prob": 0.006700757425278425}, {"id": 321, "seek": 196780, "start": 1967.8, "end": 1972.44, "text": " add in an additional term here which deals with habitual type policies and things that we tend to", "tokens": [50364, 909, 294, 364, 4497, 1433, 510, 597, 11215, 365, 46883, 2010, 7657, 293, 721, 300, 321, 3928, 281, 50596], "temperature": 0.0, "avg_logprob": -0.06908469248299647, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.00981764867901802}, {"id": 322, "seek": 196780, "start": 1972.44, "end": 1977.32, "text": " do because we've learned we behave in a particular way in those situations now the combination of", "tokens": [50596, 360, 570, 321, 600, 3264, 321, 15158, 294, 257, 1729, 636, 294, 729, 6851, 586, 264, 6562, 295, 50840], "temperature": 0.0, "avg_logprob": -0.06908469248299647, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.00981764867901802}, {"id": 323, "seek": 196780, "start": 1977.32, "end": 1982.76, "text": " this information gain and preferences are often referred to as an expected free energy and I won't", "tokens": [50840, 341, 1589, 6052, 293, 21910, 366, 2049, 10839, 281, 382, 364, 5176, 1737, 2281, 293, 286, 1582, 380, 51112], "temperature": 0.0, "avg_logprob": -0.06908469248299647, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.00981764867901802}, {"id": 324, "seek": 196780, "start": 1982.76, "end": 1988.36, "text": " go into the details here but that's simply because you can rearrange them mathematically to make them", "tokens": [51112, 352, 666, 264, 4365, 510, 457, 300, 311, 2935, 570, 291, 393, 39568, 552, 44003, 281, 652, 552, 51392], "temperature": 0.0, "avg_logprob": -0.06908469248299647, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.00981764867901802}, {"id": 325, "seek": 196780, "start": 1988.36, "end": 1993.1599999999999, "text": " look very much like the equation for a free energy or or marginal likelihood approximation", "tokens": [51392, 574, 588, 709, 411, 264, 5367, 337, 257, 1737, 2281, 420, 420, 16885, 22119, 28023, 51632], "temperature": 0.0, "avg_logprob": -0.06908469248299647, "compression_ratio": 1.7392857142857143, "no_speech_prob": 0.00981764867901802}, {"id": 326, "seek": 199316, "start": 1994.1200000000001, "end": 1999.88, "text": " with an expectation around them to say that these are the what we would expect given", "tokens": [50412, 365, 364, 14334, 926, 552, 281, 584, 300, 613, 366, 264, 437, 321, 576, 2066, 2212, 50700], "temperature": 0.0, "avg_logprob": -0.11220894054490693, "compression_ratio": 1.9270386266094421, "no_speech_prob": 0.031779494136571884}, {"id": 327, "seek": 199316, "start": 2000.8400000000001, "end": 2005.0800000000002, "text": " our predictions about the data we would obtain because here we're dealing with beliefs about", "tokens": [50748, 527, 21264, 466, 264, 1412, 321, 576, 12701, 570, 510, 321, 434, 6260, 365, 13585, 466, 50960], "temperature": 0.0, "avg_logprob": -0.11220894054490693, "compression_ratio": 1.9270386266094421, "no_speech_prob": 0.031779494136571884}, {"id": 328, "seek": 199316, "start": 2005.0800000000002, "end": 2010.2, "text": " the future plans into the future where we haven't yet had those data and we need to deal with the", "tokens": [50960, 264, 2027, 5482, 666, 264, 2027, 689, 321, 2378, 380, 1939, 632, 729, 1412, 293, 321, 643, 281, 2028, 365, 264, 51216], "temperature": 0.0, "avg_logprob": -0.11220894054490693, "compression_ratio": 1.9270386266094421, "no_speech_prob": 0.031779494136571884}, {"id": 329, "seek": 199316, "start": 2010.2, "end": 2014.3600000000001, "text": " expectations of what those data would be under different plans that we could choose", "tokens": [51216, 9843, 295, 437, 729, 1412, 576, 312, 833, 819, 5482, 300, 321, 727, 2826, 51424], "temperature": 0.0, "avg_logprob": -0.11220894054490693, "compression_ratio": 1.9270386266094421, "no_speech_prob": 0.031779494136571884}, {"id": 330, "seek": 199316, "start": 2015.96, "end": 2022.0400000000002, "text": " and so here we're showing just an example of the direct pathway through the basal ganglia", "tokens": [51504, 293, 370, 510, 321, 434, 4099, 445, 364, 1365, 295, 264, 2047, 18590, 807, 264, 987, 304, 10145, 14218, 51808], "temperature": 0.0, "avg_logprob": -0.11220894054490693, "compression_ratio": 1.9270386266094421, "no_speech_prob": 0.031779494136571884}, {"id": 331, "seek": 202204, "start": 2022.04, "end": 2025.56, "text": " which is normally thought to facilitate movement and depends upon this expected free energy", "tokens": [50364, 597, 307, 5646, 1194, 281, 20207, 3963, 293, 5946, 3564, 341, 5176, 1737, 2281, 50540], "temperature": 0.0, "avg_logprob": -0.055367828697286625, "compression_ratio": 1.7423076923076923, "no_speech_prob": 0.005465597379952669}, {"id": 332, "seek": 202204, "start": 2026.28, "end": 2031.56, "text": " and an indirect pathway which here we've associated with these kinds of habitual drives and I'll", "tokens": [50576, 293, 364, 19523, 18590, 597, 510, 321, 600, 6615, 365, 613, 3685, 295, 46883, 11754, 293, 286, 603, 50840], "temperature": 0.0, "avg_logprob": -0.055367828697286625, "compression_ratio": 1.7423076923076923, "no_speech_prob": 0.005465597379952669}, {"id": 333, "seek": 202204, "start": 2031.56, "end": 2035.08, "text": " come back to those a little bit later on when we deal with hierarchical models", "tokens": [50840, 808, 646, 281, 729, 257, 707, 857, 1780, 322, 562, 321, 2028, 365, 35250, 804, 5245, 51016], "temperature": 0.0, "avg_logprob": -0.055367828697286625, "compression_ratio": 1.7423076923076923, "no_speech_prob": 0.005465597379952669}, {"id": 334, "seek": 202204, "start": 2036.6, "end": 2040.2, "text": " just to give you a little bit of intuition as to the information gain aspect of the expected", "tokens": [51092, 445, 281, 976, 291, 257, 707, 857, 295, 24002, 382, 281, 264, 1589, 6052, 4171, 295, 264, 5176, 51272], "temperature": 0.0, "avg_logprob": -0.055367828697286625, "compression_ratio": 1.7423076923076923, "no_speech_prob": 0.005465597379952669}, {"id": 335, "seek": 202204, "start": 2040.2, "end": 2045.6399999999999, "text": " free energy because I think most people most people probably understand this idea of seeking", "tokens": [51272, 1737, 2281, 570, 286, 519, 881, 561, 881, 561, 1391, 1223, 341, 1558, 295, 11670, 51544], "temperature": 0.0, "avg_logprob": -0.055367828697286625, "compression_ratio": 1.7423076923076923, "no_speech_prob": 0.005465597379952669}, {"id": 336, "seek": 204564, "start": 2046.3600000000001, "end": 2051.88, "text": " preferences and behaving to maximize some degree of reward but many people are less", "tokens": [50400, 21910, 293, 35263, 281, 19874, 512, 4314, 295, 7782, 457, 867, 561, 366, 1570, 50676], "temperature": 0.0, "avg_logprob": -0.07498152632462352, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.05085717514157295}, {"id": 337, "seek": 204564, "start": 2051.88, "end": 2055.88, "text": " familiar with the idea of seeking information into the way that that might manifest in these", "tokens": [50676, 4963, 365, 264, 1558, 295, 11670, 1589, 666, 264, 636, 300, 300, 1062, 10067, 294, 613, 50876], "temperature": 0.0, "avg_logprob": -0.07498152632462352, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.05085717514157295}, {"id": 338, "seek": 204564, "start": 2055.88, "end": 2063.88, "text": " kinds of models so as an example I'm going to show you just a simple simulation where we're", "tokens": [50876, 3685, 295, 5245, 370, 382, 364, 1365, 286, 478, 516, 281, 855, 291, 445, 257, 2199, 16575, 689, 321, 434, 51276], "temperature": 0.0, "avg_logprob": -0.07498152632462352, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.05085717514157295}, {"id": 339, "seek": 204564, "start": 2063.88, "end": 2068.52, "text": " going to manipulate some of the different aspects of the uncertainty in the model so here", "tokens": [51276, 516, 281, 20459, 512, 295, 264, 819, 7270, 295, 264, 15697, 294, 264, 2316, 370, 510, 51508], "temperature": 0.0, "avg_logprob": -0.07498152632462352, "compression_ratio": 1.6966824644549763, "no_speech_prob": 0.05085717514157295}, {"id": 340, "seek": 206852, "start": 2068.7599999999998, "end": 2075.56, "text": " in the upper left I'm just showing a way of parameterizing the the uncertainty associated", "tokens": [50376, 294, 264, 6597, 1411, 286, 478, 445, 4099, 257, 636, 295, 13075, 3319, 264, 264, 15697, 6615, 50716], "temperature": 0.0, "avg_logprob": -0.09663712350945723, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.04223143309354782}, {"id": 341, "seek": 206852, "start": 2075.56, "end": 2079.72, "text": " with the data generating process so this is our likelihood precision on sensory precision", "tokens": [50716, 365, 264, 1412, 17746, 1399, 370, 341, 307, 527, 22119, 18356, 322, 27233, 18356, 50924], "temperature": 0.0, "avg_logprob": -0.09663712350945723, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.04223143309354782}, {"id": 342, "seek": 206852, "start": 2080.52, "end": 2086.44, "text": " and it effectively says that when this precision is very high we can be very certain about the", "tokens": [50964, 293, 309, 8659, 1619, 300, 562, 341, 18356, 307, 588, 1090, 321, 393, 312, 588, 1629, 466, 264, 51260], "temperature": 0.0, "avg_logprob": -0.09663712350945723, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.04223143309354782}, {"id": 343, "seek": 206852, "start": 2086.44, "end": 2091.56, "text": " outcome we'll observe given a particular state of the world whereas when it's very low we could", "tokens": [51260, 9700, 321, 603, 11441, 2212, 257, 1729, 1785, 295, 264, 1002, 9735, 562, 309, 311, 588, 2295, 321, 727, 51516], "temperature": 0.0, "avg_logprob": -0.09663712350945723, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.04223143309354782}, {"id": 344, "seek": 206852, "start": 2091.56, "end": 2097.16, "text": " predict everything with very similar probability and we can do something very similar by manipulating", "tokens": [51516, 6069, 1203, 365, 588, 2531, 8482, 293, 321, 393, 360, 746, 588, 2531, 538, 40805, 51796], "temperature": 0.0, "avg_logprob": -0.09663712350945723, "compression_ratio": 1.7611940298507462, "no_speech_prob": 0.04223143309354782}, {"id": 345, "seek": 209716, "start": 2097.16, "end": 2101.3199999999997, "text": " the uncertainty in the dynamics of the world so again when this is very high it means that", "tokens": [50364, 264, 15697, 294, 264, 15679, 295, 264, 1002, 370, 797, 562, 341, 307, 588, 1090, 309, 1355, 300, 50572], "temperature": 0.0, "avg_logprob": -0.050978269217149264, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.003249604254961014}, {"id": 346, "seek": 209716, "start": 2101.3199999999997, "end": 2105.64, "text": " where I am now is very highly predictive of where I'll be at the next step in time", "tokens": [50572, 689, 286, 669, 586, 307, 588, 5405, 35521, 295, 689, 286, 603, 312, 412, 264, 958, 1823, 294, 565, 50788], "temperature": 0.0, "avg_logprob": -0.050978269217149264, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.003249604254961014}, {"id": 347, "seek": 209716, "start": 2107.16, "end": 2111.96, "text": " whereas when it's very low it means that pretty much anything at the next time point is is equally", "tokens": [50864, 9735, 562, 309, 311, 588, 2295, 309, 1355, 300, 1238, 709, 1340, 412, 264, 958, 565, 935, 307, 307, 12309, 51104], "temperature": 0.0, "avg_logprob": -0.050978269217149264, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.003249604254961014}, {"id": 348, "seek": 209716, "start": 2111.96, "end": 2117.96, "text": " probable and I'll show you a simple simulation where these two things are manipulated just to", "tokens": [51104, 21759, 293, 286, 603, 855, 291, 257, 2199, 16575, 689, 613, 732, 721, 366, 37161, 445, 281, 51404], "temperature": 0.0, "avg_logprob": -0.050978269217149264, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.003249604254961014}, {"id": 349, "seek": 209716, "start": 2117.96, "end": 2122.6, "text": " try and give you an intuition for what it means to act to to maximize one's information about the", "tokens": [51404, 853, 293, 976, 291, 364, 24002, 337, 437, 309, 1355, 281, 605, 281, 281, 19874, 472, 311, 1589, 466, 264, 51636], "temperature": 0.0, "avg_logprob": -0.050978269217149264, "compression_ratio": 1.8412698412698412, "no_speech_prob": 0.003249604254961014}, {"id": 350, "seek": 212260, "start": 2122.6, "end": 2131.72, "text": " world so the upper simulation here top left shows four panels which can each change at some point", "tokens": [50364, 1002, 370, 264, 6597, 16575, 510, 1192, 1411, 3110, 1451, 13419, 597, 393, 1184, 1319, 412, 512, 935, 50820], "temperature": 0.0, "avg_logprob": -0.05127727284150965, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.011921487748622894}, {"id": 351, "seek": 212260, "start": 2131.72, "end": 2140.7599999999998, "text": " in time to a different color with some random probabilities and the blue line here is designed", "tokens": [50820, 294, 565, 281, 257, 819, 2017, 365, 512, 4974, 33783, 293, 264, 3344, 1622, 510, 307, 4761, 51272], "temperature": 0.0, "avg_logprob": -0.05127727284150965, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.011921487748622894}, {"id": 352, "seek": 212260, "start": 2140.7599999999998, "end": 2146.8399999999997, "text": " to show effectively an eye tracking trace so it's a simulated agent who is allowed to choose which", "tokens": [51272, 281, 855, 8659, 364, 3313, 11603, 13508, 370, 309, 311, 257, 41713, 9461, 567, 307, 4350, 281, 2826, 597, 51576], "temperature": 0.0, "avg_logprob": -0.05127727284150965, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.011921487748622894}, {"id": 353, "seek": 212260, "start": 2146.8399999999997, "end": 2150.92, "text": " of these panels it wants to look at at any one time and you can see it samples them with a", "tokens": [51576, 295, 613, 13419, 309, 2738, 281, 574, 412, 412, 604, 472, 565, 293, 291, 393, 536, 309, 10938, 552, 365, 257, 51780], "temperature": 0.0, "avg_logprob": -0.05127727284150965, "compression_ratio": 1.7130044843049328, "no_speech_prob": 0.011921487748622894}, {"id": 354, "seek": 215092, "start": 2150.92, "end": 2158.04, "text": " relatively even frequency in the middle panel what we've done is we've reduced the precision", "tokens": [50364, 7226, 754, 7893, 294, 264, 2808, 4831, 437, 321, 600, 1096, 307, 321, 600, 9212, 264, 18356, 50720], "temperature": 0.0, "avg_logprob": -0.06941520690917968, "compression_ratio": 1.9325396825396826, "no_speech_prob": 0.007448050193488598}, {"id": 355, "seek": 215092, "start": 2158.04, "end": 2163.48, "text": " or increased the uncertainty associated with the likelihood in the lower left that effectively is", "tokens": [50720, 420, 6505, 264, 15697, 6615, 365, 264, 22119, 294, 264, 3126, 1411, 300, 8659, 307, 50992], "temperature": 0.0, "avg_logprob": -0.06941520690917968, "compression_ratio": 1.9325396825396826, "no_speech_prob": 0.007448050193488598}, {"id": 356, "seek": 215092, "start": 2163.48, "end": 2168.76, "text": " like turning off the lights in that location it's effectively making that lower left location much more", "tokens": [50992, 411, 6246, 766, 264, 5811, 294, 300, 4914, 309, 311, 8659, 1455, 300, 3126, 1411, 4914, 709, 544, 51256], "temperature": 0.0, "avg_logprob": -0.06941520690917968, "compression_ratio": 1.9325396825396826, "no_speech_prob": 0.007448050193488598}, {"id": 357, "seek": 215092, "start": 2168.76, "end": 2175.48, "text": " much less informative much more noisy and so effectively what what we've got here is a system", "tokens": [51256, 709, 1570, 27759, 709, 544, 24518, 293, 370, 8659, 437, 437, 321, 600, 658, 510, 307, 257, 1185, 51592], "temperature": 0.0, "avg_logprob": -0.06941520690917968, "compression_ratio": 1.9325396825396826, "no_speech_prob": 0.007448050193488598}, {"id": 358, "seek": 215092, "start": 2175.48, "end": 2180.6800000000003, "text": " that then ignores that it says that I can't get a good quality high quality information from there", "tokens": [51592, 300, 550, 5335, 2706, 300, 309, 1619, 300, 286, 393, 380, 483, 257, 665, 3125, 1090, 3125, 1589, 490, 456, 51852], "temperature": 0.0, "avg_logprob": -0.06941520690917968, "compression_ratio": 1.9325396825396826, "no_speech_prob": 0.007448050193488598}, {"id": 359, "seek": 218068, "start": 2180.68, "end": 2184.6, "text": " so I'm going to look at all of the other locations rather than rather than this in the lower left", "tokens": [50364, 370, 286, 478, 516, 281, 574, 412, 439, 295, 264, 661, 9253, 2831, 813, 2831, 813, 341, 294, 264, 3126, 1411, 50560], "temperature": 0.0, "avg_logprob": -0.08136475527728046, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0009142115595750511}, {"id": 360, "seek": 218068, "start": 2189.3999999999996, "end": 2193.64, "text": " an analogy for this is if you're thinking about how you perform a scientific experiment you would", "tokens": [50800, 364, 21663, 337, 341, 307, 498, 291, 434, 1953, 466, 577, 291, 2042, 257, 8134, 5120, 291, 576, 51012], "temperature": 0.0, "avg_logprob": -0.08136475527728046, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0009142115595750511}, {"id": 361, "seek": 218068, "start": 2193.64, "end": 2198.7599999999998, "text": " probably aim to use if you had a choice between two different measuring instruments you would", "tokens": [51012, 1391, 5939, 281, 764, 498, 291, 632, 257, 3922, 1296, 732, 819, 13389, 12190, 291, 576, 51268], "temperature": 0.0, "avg_logprob": -0.08136475527728046, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0009142115595750511}, {"id": 362, "seek": 218068, "start": 2198.7599999999998, "end": 2202.7599999999998, "text": " choose the one that gives you more precise measurements rather than the one that gives you", "tokens": [51268, 2826, 264, 472, 300, 2709, 291, 544, 13600, 15383, 2831, 813, 264, 472, 300, 2709, 291, 51468], "temperature": 0.0, "avg_logprob": -0.08136475527728046, "compression_ratio": 1.8009478672985781, "no_speech_prob": 0.0009142115595750511}, {"id": 363, "seek": 220276, "start": 2202.76, "end": 2210.84, "text": " very noisy measurements in the lower left we've manipulated the uncertainty or the volatility", "tokens": [50364, 588, 24518, 15383, 294, 264, 3126, 1411, 321, 600, 37161, 264, 15697, 420, 264, 25877, 50768], "temperature": 0.0, "avg_logprob": -0.06859638189014636, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03487718105316162}, {"id": 364, "seek": 220276, "start": 2210.84, "end": 2216.44, "text": " associated with the dynamics so here what's happened is the upper left location is associated", "tokens": [50768, 6615, 365, 264, 15679, 370, 510, 437, 311, 2011, 307, 264, 6597, 1411, 4914, 307, 6615, 51048], "temperature": 0.0, "avg_logprob": -0.06859638189014636, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03487718105316162}, {"id": 365, "seek": 220276, "start": 2216.44, "end": 2221.6400000000003, "text": " with much more uncertain dynamics so here what happens is that I end up sampling that upper left", "tokens": [51048, 365, 709, 544, 11308, 15679, 370, 510, 437, 2314, 307, 300, 286, 917, 493, 21179, 300, 6597, 1411, 51308], "temperature": 0.0, "avg_logprob": -0.06859638189014636, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03487718105316162}, {"id": 366, "seek": 220276, "start": 2221.6400000000003, "end": 2228.2000000000003, "text": " location much more frequently and intuitively this makes a lot of sense because if you've looked", "tokens": [51308, 4914, 709, 544, 10374, 293, 46506, 341, 1669, 257, 688, 295, 2020, 570, 498, 291, 600, 2956, 51636], "temperature": 0.0, "avg_logprob": -0.06859638189014636, "compression_ratio": 1.8495145631067962, "no_speech_prob": 0.03487718105316162}, {"id": 367, "seek": 222820, "start": 2228.2, "end": 2232.7599999999998, "text": " somewhere very recently normally you will you'll know a lot about what was there you don't need to", "tokens": [50364, 4079, 588, 3938, 5646, 291, 486, 291, 603, 458, 257, 688, 466, 437, 390, 456, 291, 500, 380, 643, 281, 50592], "temperature": 0.0, "avg_logprob": -0.0646311378479004, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.03266199305653572}, {"id": 368, "seek": 222820, "start": 2232.7599999999998, "end": 2239.96, "text": " look back there anytime soon however if it's very volatile if it changes quite with some degree of", "tokens": [50592, 574, 646, 456, 13038, 2321, 4461, 498, 309, 311, 588, 34377, 498, 309, 2962, 1596, 365, 512, 4314, 295, 50952], "temperature": 0.0, "avg_logprob": -0.0646311378479004, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.03266199305653572}, {"id": 369, "seek": 222820, "start": 2239.96, "end": 2245.16, "text": " randomness and you have very little certainty about the state of it after you've looked away", "tokens": [50952, 4974, 1287, 293, 291, 362, 588, 707, 27022, 466, 264, 1785, 295, 309, 934, 291, 600, 2956, 1314, 51212], "temperature": 0.0, "avg_logprob": -0.0646311378479004, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.03266199305653572}, {"id": 370, "seek": 222820, "start": 2245.16, "end": 2249.24, "text": " you'll look back with a much greater frequency so we've effectively decreased the inhibition", "tokens": [51212, 291, 603, 574, 646, 365, 257, 709, 5044, 7893, 370, 321, 600, 8659, 24436, 264, 20406, 849, 51416], "temperature": 0.0, "avg_logprob": -0.0646311378479004, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.03266199305653572}, {"id": 371, "seek": 222820, "start": 2249.24, "end": 2254.9199999999996, "text": " of return in this location by increasing its volatility or decreasing the precision associated", "tokens": [51416, 295, 2736, 294, 341, 4914, 538, 5662, 1080, 25877, 420, 23223, 264, 18356, 6615, 51700], "temperature": 0.0, "avg_logprob": -0.0646311378479004, "compression_ratio": 1.7573529411764706, "no_speech_prob": 0.03266199305653572}, {"id": 372, "seek": 225492, "start": 2254.92, "end": 2260.84, "text": " with its with the dynamics in that location so the end of this was just to show you this sort", "tokens": [50364, 365, 1080, 365, 264, 15679, 294, 300, 4914, 370, 264, 917, 295, 341, 390, 445, 281, 855, 291, 341, 1333, 50660], "temperature": 0.0, "avg_logprob": -0.0673042220630865, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.003255767747759819}, {"id": 373, "seek": 225492, "start": 2260.84, "end": 2266.28, "text": " of emergent behavior just by having an information seeking objective by by having a prior belief", "tokens": [50660, 295, 4345, 6930, 5223, 445, 538, 1419, 364, 1589, 11670, 10024, 538, 538, 1419, 257, 4059, 7107, 50932], "temperature": 0.0, "avg_logprob": -0.0673042220630865, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.003255767747759819}, {"id": 374, "seek": 225492, "start": 2266.28, "end": 2271.56, "text": " that we're going to act to minimize some expected free energy one component of which is to maximize", "tokens": [50932, 300, 321, 434, 516, 281, 605, 281, 17522, 512, 5176, 1737, 2281, 472, 6542, 295, 597, 307, 281, 19874, 51196], "temperature": 0.0, "avg_logprob": -0.0673042220630865, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.003255767747759819}, {"id": 375, "seek": 225492, "start": 2271.56, "end": 2279.48, "text": " our information about the world now the next thing I want to come on to is the role of hierarchical", "tokens": [51196, 527, 1589, 466, 264, 1002, 586, 264, 958, 551, 286, 528, 281, 808, 322, 281, 307, 264, 3090, 295, 35250, 804, 51592], "temperature": 0.0, "avg_logprob": -0.0673042220630865, "compression_ratio": 1.7333333333333334, "no_speech_prob": 0.003255767747759819}, {"id": 376, "seek": 227948, "start": 2279.48, "end": 2285.8, "text": " generative models and one of the key benefits of having a hierarchical model is that we can now deal", "tokens": [50364, 1337, 1166, 5245, 293, 472, 295, 264, 2141, 5311, 295, 1419, 257, 35250, 804, 2316, 307, 300, 321, 393, 586, 2028, 50680], "temperature": 0.0, "avg_logprob": -0.08493078166040881, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.14362306892871857}, {"id": 377, "seek": 227948, "start": 2285.8, "end": 2290.92, "text": " with things that evolve over a range of different timescales so you might have some things that", "tokens": [50680, 365, 721, 300, 16693, 670, 257, 3613, 295, 819, 1413, 66, 4229, 370, 291, 1062, 362, 512, 721, 300, 50936], "temperature": 0.0, "avg_logprob": -0.08493078166040881, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.14362306892871857}, {"id": 378, "seek": 227948, "start": 2290.92, "end": 2296.84, "text": " evolve very slowly and some things that evolve very quickly and to some extent we can separate", "tokens": [50936, 16693, 588, 5692, 293, 512, 721, 300, 16693, 588, 2661, 293, 281, 512, 8396, 321, 393, 4994, 51232], "temperature": 0.0, "avg_logprob": -0.08493078166040881, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.14362306892871857}, {"id": 379, "seek": 227948, "start": 2296.84, "end": 2306.28, "text": " out two and use slowly evolving things to to to help us predict what's happening at the faster level", "tokens": [51232, 484, 732, 293, 764, 5692, 21085, 721, 281, 281, 281, 854, 505, 6069, 437, 311, 2737, 412, 264, 4663, 1496, 51704], "temperature": 0.0, "avg_logprob": -0.08493078166040881, "compression_ratio": 1.8666666666666667, "no_speech_prob": 0.14362306892871857}, {"id": 380, "seek": 230628, "start": 2306.28, "end": 2313.5600000000004, "text": " and here the key things to to note are all of these connections between higher cortical regions", "tokens": [50364, 293, 510, 264, 2141, 721, 281, 281, 3637, 366, 439, 295, 613, 9271, 1296, 2946, 11278, 804, 10682, 50728], "temperature": 0.0, "avg_logprob": -0.08105759340174058, "compression_ratio": 1.8309859154929577, "no_speech_prob": 0.004043114371597767}, {"id": 381, "seek": 230628, "start": 2313.5600000000004, "end": 2322.1200000000003, "text": " and lower cortical regions which manifests both in the in the discrete and continuous state space", "tokens": [50728, 293, 3126, 11278, 804, 10682, 597, 50252, 1293, 294, 264, 294, 264, 27706, 293, 10957, 1785, 1901, 51156], "temperature": 0.0, "avg_logprob": -0.08105759340174058, "compression_ratio": 1.8309859154929577, "no_speech_prob": 0.004043114371597767}, {"id": 382, "seek": 230628, "start": 2322.1200000000003, "end": 2327.1600000000003, "text": " models and so it's worth them thinking about what the role of these are and how that manifests in", "tokens": [51156, 5245, 293, 370, 309, 311, 3163, 552, 1953, 466, 437, 264, 3090, 295, 613, 366, 293, 577, 300, 50252, 294, 51408], "temperature": 0.0, "avg_logprob": -0.08105759340174058, "compression_ratio": 1.8309859154929577, "no_speech_prob": 0.004043114371597767}, {"id": 383, "seek": 230628, "start": 2327.1600000000003, "end": 2331.7200000000003, "text": " terms of the generative models we've been dealing with before and it's really this that links back", "tokens": [51408, 2115, 295, 264, 1337, 1166, 5245, 321, 600, 668, 6260, 365, 949, 293, 309, 311, 534, 341, 300, 6123, 646, 51636], "temperature": 0.0, "avg_logprob": -0.08105759340174058, "compression_ratio": 1.8309859154929577, "no_speech_prob": 0.004043114371597767}, {"id": 384, "seek": 233172, "start": 2331.72, "end": 2338.8399999999997, "text": " into the the idea of predictive coding as many people know it and you've probably seen graphics", "tokens": [50364, 666, 264, 264, 1558, 295, 35521, 17720, 382, 867, 561, 458, 309, 293, 291, 600, 1391, 1612, 11837, 50720], "temperature": 0.0, "avg_logprob": -0.06207327047983805, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0900253877043724}, {"id": 385, "seek": 233172, "start": 2338.8399999999997, "end": 2344.2799999999997, "text": " of this sort in the past where we have a range of cortical regions that are each making predictions", "tokens": [50720, 295, 341, 1333, 294, 264, 1791, 689, 321, 362, 257, 3613, 295, 11278, 804, 10682, 300, 366, 1184, 1455, 21264, 50992], "temperature": 0.0, "avg_logprob": -0.06207327047983805, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0900253877043724}, {"id": 386, "seek": 233172, "start": 2344.2799999999997, "end": 2348.9199999999996, "text": " about the others and so here going from going from the right to the left we've got a series of", "tokens": [50992, 466, 264, 2357, 293, 370, 510, 516, 490, 516, 490, 264, 558, 281, 264, 1411, 321, 600, 658, 257, 2638, 295, 51224], "temperature": 0.0, "avg_logprob": -0.06207327047983805, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0900253877043724}, {"id": 387, "seek": 233172, "start": 2348.9199999999996, "end": 2356.52, "text": " predictions in as these dark black lines with prediction errors passed back up using these", "tokens": [51224, 21264, 294, 382, 613, 2877, 2211, 3876, 365, 17630, 13603, 4678, 646, 493, 1228, 613, 51604], "temperature": 0.0, "avg_logprob": -0.06207327047983805, "compression_ratio": 1.7557603686635945, "no_speech_prob": 0.0900253877043724}, {"id": 388, "seek": 235652, "start": 2356.52, "end": 2362.52, "text": " these dashed lines that then allow us to correct at each level and all this this graphic shows", "tokens": [50364, 613, 8240, 292, 3876, 300, 550, 2089, 505, 281, 3006, 412, 1184, 1496, 293, 439, 341, 341, 14089, 3110, 50664], "temperature": 0.0, "avg_logprob": -0.06097361805674794, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.017079593613743782}, {"id": 389, "seek": 235652, "start": 2362.52, "end": 2368.92, "text": " is a simplification of the graphic on on the previous slide so i want to give you an intuition", "tokens": [50664, 307, 257, 6883, 3774, 295, 264, 14089, 322, 322, 264, 3894, 4137, 370, 741, 528, 281, 976, 291, 364, 24002, 50984], "temperature": 0.0, "avg_logprob": -0.06097361805674794, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.017079593613743782}, {"id": 390, "seek": 235652, "start": 2368.92, "end": 2373.72, "text": " for why this is useful using a couple of examples so the first example i'm going to use is one from", "tokens": [50984, 337, 983, 341, 307, 4420, 1228, 257, 1916, 295, 5110, 370, 264, 700, 1365, 741, 478, 516, 281, 764, 307, 472, 490, 51224], "temperature": 0.0, "avg_logprob": -0.06097361805674794, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.017079593613743782}, {"id": 391, "seek": 235652, "start": 2373.72, "end": 2379.96, "text": " the domain of active vision so imagine imagine you're doing a task now where you have to fixate", "tokens": [51224, 264, 9274, 295, 4967, 5201, 370, 3811, 3811, 291, 434, 884, 257, 5633, 586, 689, 291, 362, 281, 3191, 473, 51536], "temperature": 0.0, "avg_logprob": -0.06097361805674794, "compression_ratio": 1.7264573991031391, "no_speech_prob": 0.017079593613743782}, {"id": 392, "seek": 237996, "start": 2379.96, "end": 2387.56, "text": " on this cross in the center and maintain that fixation and show you a stimulus but maintain", "tokens": [50364, 322, 341, 3278, 294, 264, 3056, 293, 6909, 300, 3191, 399, 293, 855, 291, 257, 21366, 457, 6909, 50744], "temperature": 0.0, "avg_logprob": -0.08820974046938887, "compression_ratio": 1.7627737226277371, "no_speech_prob": 0.07646206021308899}, {"id": 393, "seek": 237996, "start": 2387.56, "end": 2392.84, "text": " fixation on the cross. Stimulus is going to disappear and then your next task is to perform", "tokens": [50744, 3191, 399, 322, 264, 3278, 13, 745, 332, 26107, 307, 516, 281, 11596, 293, 550, 428, 958, 5633, 307, 281, 2042, 51008], "temperature": 0.0, "avg_logprob": -0.08820974046938887, "compression_ratio": 1.7627737226277371, "no_speech_prob": 0.07646206021308899}, {"id": 394, "seek": 237996, "start": 2392.84, "end": 2398.12, "text": " an eye movement to the location where the stimulus appeared. It's a very simple task if the sort was", "tokens": [51008, 364, 3313, 3963, 281, 264, 4914, 689, 264, 21366, 8516, 13, 467, 311, 257, 588, 2199, 5633, 498, 264, 1333, 390, 51272], "temperature": 0.0, "avg_logprob": -0.08820974046938887, "compression_ratio": 1.7627737226277371, "no_speech_prob": 0.07646206021308899}, {"id": 395, "seek": 237996, "start": 2398.12, "end": 2404.6, "text": " used frequently in monkey electrophysiology and all throughout neuroscience but it's an interesting", "tokens": [51272, 1143, 10374, 294, 17847, 2185, 11741, 749, 46457, 293, 439, 3710, 42762, 457, 309, 311, 364, 1880, 51596], "temperature": 0.0, "avg_logprob": -0.08820974046938887, "compression_ratio": 1.7627737226277371, "no_speech_prob": 0.07646206021308899}, {"id": 396, "seek": 237996, "start": 2404.6, "end": 2409.8, "text": " one because it has several different components to it that i think help in terms of thinking about", "tokens": [51596, 472, 570, 309, 575, 2940, 819, 6677, 281, 309, 300, 741, 519, 854, 294, 2115, 295, 1953, 466, 51856], "temperature": 0.0, "avg_logprob": -0.08820974046938887, "compression_ratio": 1.7627737226277371, "no_speech_prob": 0.07646206021308899}, {"id": 397, "seek": 240980, "start": 2409.88, "end": 2416.92, "text": " the utility of hierarchical models so one aspect of this is making decisions about", "tokens": [50368, 264, 14877, 295, 35250, 804, 5245, 370, 472, 4171, 295, 341, 307, 1455, 5327, 466, 50720], "temperature": 0.0, "avg_logprob": -0.09618033233441804, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.002767044585198164}, {"id": 398, "seek": 240980, "start": 2416.92, "end": 2420.76, "text": " where you're looking at each of those time points and making inferences about which", "tokens": [50720, 689, 291, 434, 1237, 412, 1184, 295, 729, 565, 2793, 293, 1455, 13596, 2667, 466, 597, 50912], "temperature": 0.0, "avg_logprob": -0.09618033233441804, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.002767044585198164}, {"id": 399, "seek": 240980, "start": 2420.76, "end": 2426.36, "text": " of several alternative locations you're going to perform an eye movement to so simple form of", "tokens": [50912, 295, 2940, 8535, 9253, 291, 434, 516, 281, 2042, 364, 3313, 3963, 281, 370, 2199, 1254, 295, 51192], "temperature": 0.0, "avg_logprob": -0.09618033233441804, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.002767044585198164}, {"id": 400, "seek": 240980, "start": 2426.36, "end": 2435.96, "text": " planning here so that calls into into action the sort of discrete state space model that we were", "tokens": [51192, 5038, 510, 370, 300, 5498, 666, 666, 3069, 264, 1333, 295, 27706, 1785, 1901, 2316, 300, 321, 645, 51672], "temperature": 0.0, "avg_logprob": -0.09618033233441804, "compression_ratio": 1.7246376811594204, "no_speech_prob": 0.002767044585198164}, {"id": 401, "seek": 243596, "start": 2435.96, "end": 2441.7200000000003, "text": " dealing with before this this partial observable decision process this set of discrete sequential", "tokens": [50364, 6260, 365, 949, 341, 341, 14641, 9951, 712, 3537, 1399, 341, 992, 295, 27706, 42881, 50652], "temperature": 0.0, "avg_logprob": -0.07459967679316455, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.03511998802423477}, {"id": 402, "seek": 243596, "start": 2441.7200000000003, "end": 2449.48, "text": " timing points and that's often very highly relevant structure of most simple tasks in cognitive", "tokens": [50652, 10822, 2793, 293, 300, 311, 2049, 588, 5405, 7340, 3877, 295, 881, 2199, 9608, 294, 15605, 51040], "temperature": 0.0, "avg_logprob": -0.07459967679316455, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.03511998802423477}, {"id": 403, "seek": 243596, "start": 2449.48, "end": 2456.6, "text": " neuroscience. However we also need to actually move our eyes we need to we need to move our eyes", "tokens": [51040, 42762, 13, 2908, 321, 611, 643, 281, 767, 1286, 527, 2575, 321, 643, 281, 321, 643, 281, 1286, 527, 2575, 51396], "temperature": 0.0, "avg_logprob": -0.07459967679316455, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.03511998802423477}, {"id": 404, "seek": 243596, "start": 2456.6, "end": 2460.44, "text": " from one location to the next we need to know how to generate forces we need to know how to make", "tokens": [51396, 490, 472, 4914, 281, 264, 958, 321, 643, 281, 458, 577, 281, 8460, 5874, 321, 643, 281, 458, 577, 281, 652, 51588], "temperature": 0.0, "avg_logprob": -0.07459967679316455, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.03511998802423477}, {"id": 405, "seek": 243596, "start": 2460.44, "end": 2465.8, "text": " sure the eyes come to rest in the right location given those decisions and that calls into play", "tokens": [51588, 988, 264, 2575, 808, 281, 1472, 294, 264, 558, 4914, 2212, 729, 5327, 293, 300, 5498, 666, 862, 51856], "temperature": 0.0, "avg_logprob": -0.07459967679316455, "compression_ratio": 1.8505747126436782, "no_speech_prob": 0.03511998802423477}, {"id": 406, "seek": 246596, "start": 2466.04, "end": 2471.7200000000003, "text": " this sort of continuous state space predictive coding style model so how do we then how do we", "tokens": [50368, 341, 1333, 295, 10957, 1785, 1901, 35521, 17720, 3758, 2316, 370, 577, 360, 321, 550, 577, 360, 321, 50652], "temperature": 0.0, "avg_logprob": -0.08736005196204552, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.00400723610073328}, {"id": 407, "seek": 246596, "start": 2471.7200000000003, "end": 2475.8, "text": " then combine the two how do we deal with the situation where we want to predict a particular", "tokens": [50652, 550, 10432, 264, 732, 577, 360, 321, 2028, 365, 264, 2590, 689, 321, 528, 281, 6069, 257, 1729, 50856], "temperature": 0.0, "avg_logprob": -0.08736005196204552, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.00400723610073328}, {"id": 408, "seek": 246596, "start": 2475.8, "end": 2482.84, "text": " location at a discrete level one of several alternatives but then also map that to a continuous", "tokens": [50856, 4914, 412, 257, 27706, 1496, 472, 295, 2940, 20478, 457, 550, 611, 4471, 300, 281, 257, 10957, 51208], "temperature": 0.0, "avg_logprob": -0.08736005196204552, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.00400723610073328}, {"id": 409, "seek": 246596, "start": 2482.84, "end": 2489.32, "text": " motor trajectory and this is where generative models get a little bit more complicated so", "tokens": [51208, 5932, 21512, 293, 341, 307, 689, 1337, 1166, 5245, 483, 257, 707, 857, 544, 6179, 370, 51532], "temperature": 0.0, "avg_logprob": -0.08736005196204552, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.00400723610073328}, {"id": 410, "seek": 246596, "start": 2489.32, "end": 2495.2400000000002, "text": " taking this a bit at a time what we've got at the top here is our mark-off decision process model", "tokens": [51532, 1940, 341, 257, 857, 412, 257, 565, 437, 321, 600, 658, 412, 264, 1192, 510, 307, 527, 1491, 12, 4506, 3537, 1399, 2316, 51828], "temperature": 0.0, "avg_logprob": -0.08736005196204552, "compression_ratio": 1.8076923076923077, "no_speech_prob": 0.00400723610073328}, {"id": 411, "seek": 249524, "start": 2495.24, "end": 2500.9199999999996, "text": " this is our discrete state space model in discrete time now at each of those time points we're no", "tokens": [50364, 341, 307, 527, 27706, 1785, 1901, 2316, 294, 27706, 565, 586, 412, 1184, 295, 729, 565, 2793, 321, 434, 572, 50648], "temperature": 0.0, "avg_logprob": -0.04385076119349553, "compression_ratio": 1.9558232931726907, "no_speech_prob": 0.0021337484940886497}, {"id": 412, "seek": 249524, "start": 2500.9199999999996, "end": 2507.56, "text": " longer predicting data specifically we're now predicting a short trajectory formulated in terms", "tokens": [50648, 2854, 32884, 1412, 4682, 321, 434, 586, 32884, 257, 2099, 21512, 48936, 294, 2115, 50980], "temperature": 0.0, "avg_logprob": -0.04385076119349553, "compression_ratio": 1.9558232931726907, "no_speech_prob": 0.0021337484940886497}, {"id": 413, "seek": 249524, "start": 2507.56, "end": 2512.68, "text": " of our continuous state space models so at time one we're now going to predict a short element of", "tokens": [50980, 295, 527, 10957, 1785, 1901, 5245, 370, 412, 565, 472, 321, 434, 586, 516, 281, 6069, 257, 2099, 4478, 295, 51236], "temperature": 0.0, "avg_logprob": -0.04385076119349553, "compression_ratio": 1.9558232931726907, "no_speech_prob": 0.0021337484940886497}, {"id": 414, "seek": 249524, "start": 2512.68, "end": 2517.3199999999997, "text": " our trajectory and this is very much like the sort of clustering model I showed you much earlier", "tokens": [51236, 527, 21512, 293, 341, 307, 588, 709, 411, 264, 1333, 295, 596, 48673, 2316, 286, 4712, 291, 709, 3071, 51468], "temperature": 0.0, "avg_logprob": -0.04385076119349553, "compression_ratio": 1.9558232931726907, "no_speech_prob": 0.0021337484940886497}, {"id": 415, "seek": 249524, "start": 2517.3199999999997, "end": 2522.2, "text": " that you take a discrete point and you map it to a point in continuous space with some probability", "tokens": [51468, 300, 291, 747, 257, 27706, 935, 293, 291, 4471, 309, 281, 257, 935, 294, 10957, 1901, 365, 512, 8482, 51712], "temperature": 0.0, "avg_logprob": -0.04385076119349553, "compression_ratio": 1.9558232931726907, "no_speech_prob": 0.0021337484940886497}, {"id": 416, "seek": 252220, "start": 2522.4399999999996, "end": 2528.7599999999998, "text": " at the next time we then predict the next bit of that continuous trajectory so our priors for our", "tokens": [50376, 412, 264, 958, 565, 321, 550, 6069, 264, 958, 857, 295, 300, 10957, 21512, 370, 527, 1790, 830, 337, 527, 50692], "temperature": 0.0, "avg_logprob": -0.16992545127868652, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.006142096593976021}, {"id": 417, "seek": 252220, "start": 2528.7599999999998, "end": 2534.3599999999997, "text": " continuous model are now inheriting from the predictions from the discrete state space model", "tokens": [50692, 10957, 2316, 366, 586, 9484, 1748, 490, 264, 21264, 490, 264, 27706, 1785, 1901, 2316, 50972], "temperature": 0.0, "avg_logprob": -0.16992545127868652, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.006142096593976021}, {"id": 418, "seek": 252220, "start": 2534.3599999999997, "end": 2539.72, "text": " and then we can do the same thing again at the next time point and and so we can create a discrete", "tokens": [50972, 293, 550, 321, 393, 360, 264, 912, 551, 797, 412, 264, 958, 565, 935, 293, 293, 370, 321, 393, 1884, 257, 27706, 51240], "temperature": 0.0, "avg_logprob": -0.16992545127868652, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.006142096593976021}, {"id": 419, "seek": 252220, "start": 2539.72, "end": 2545.8799999999997, "text": " sequence from our our sequential model and at each point in that sequence associate that with a", "tokens": [51240, 8310, 490, 527, 527, 42881, 2316, 293, 412, 1184, 935, 294, 300, 8310, 14644, 300, 365, 257, 51548], "temperature": 0.0, "avg_logprob": -0.16992545127868652, "compression_ratio": 1.9845360824742269, "no_speech_prob": 0.006142096593976021}, {"id": 420, "seek": 254588, "start": 2546.84, "end": 2554.12, "text": " short trajectory in continuous space that then predicts our continuous data allowing us to then", "tokens": [50412, 2099, 21512, 294, 10957, 1901, 300, 550, 6069, 82, 527, 10957, 1412, 8293, 505, 281, 550, 50776], "temperature": 0.0, "avg_logprob": -0.08781935186947093, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.17942380905151367}, {"id": 421, "seek": 254588, "start": 2554.12, "end": 2557.96, "text": " predict the proprioceptive information we would expect to get from the eyes when we're performing", "tokens": [50776, 6069, 264, 28203, 1336, 488, 1589, 321, 576, 2066, 281, 483, 490, 264, 2575, 562, 321, 434, 10205, 50968], "temperature": 0.0, "avg_logprob": -0.08781935186947093, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.17942380905151367}, {"id": 422, "seek": 254588, "start": 2557.96, "end": 2565.08, "text": " a task at that sort and you can see that we now develop a hierarchical structure also in thinking", "tokens": [50968, 257, 5633, 412, 300, 1333, 293, 291, 393, 536, 300, 321, 586, 1499, 257, 35250, 804, 3877, 611, 294, 1953, 51324], "temperature": 0.0, "avg_logprob": -0.08781935186947093, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.17942380905151367}, {"id": 423, "seek": 254588, "start": 2565.08, "end": 2569.88, "text": " about the relationship between the bits of the message passing scheme so here we've got the", "tokens": [51324, 466, 264, 2480, 1296, 264, 9239, 295, 264, 3636, 8437, 12232, 370, 510, 321, 600, 658, 264, 51564], "temperature": 0.0, "avg_logprob": -0.08781935186947093, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.17942380905151367}, {"id": 424, "seek": 254588, "start": 2569.88, "end": 2575.08, "text": " discrete bit of our message passing scheme our discrete microcircuit and a bit of the continuous", "tokens": [51564, 27706, 857, 295, 527, 3636, 8437, 12232, 527, 27706, 4532, 23568, 66, 1983, 293, 257, 857, 295, 264, 10957, 51824], "temperature": 0.0, "avg_logprob": -0.08781935186947093, "compression_ratio": 1.8604651162790697, "no_speech_prob": 0.17942380905151367}, {"id": 425, "seek": 257508, "start": 2575.08, "end": 2579.7999999999997, "text": " microcircuit here and the interactions between the two of those were making predictions from the", "tokens": [50364, 4532, 23568, 66, 1983, 510, 293, 264, 13280, 1296, 264, 732, 295, 729, 645, 1455, 21264, 490, 264, 50600], "temperature": 0.0, "avg_logprob": -0.07816312160897762, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.010264190845191479}, {"id": 426, "seek": 257508, "start": 2579.7999999999997, "end": 2585.24, "text": " discrete one to the continuous one and then passing errors backwards to allow us to to update", "tokens": [50600, 27706, 472, 281, 264, 10957, 472, 293, 550, 8437, 13603, 12204, 281, 2089, 505, 281, 281, 5623, 50872], "temperature": 0.0, "avg_logprob": -0.07816312160897762, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.010264190845191479}, {"id": 427, "seek": 257508, "start": 2585.88, "end": 2592.2799999999997, "text": " the discrete element so interpreting this again neurobiologically you can imagine", "tokens": [50904, 264, 27706, 4478, 370, 37395, 341, 797, 16499, 5614, 17157, 291, 393, 3811, 51224], "temperature": 0.0, "avg_logprob": -0.07816312160897762, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.010264190845191479}, {"id": 428, "seek": 257508, "start": 2593.16, "end": 2597.4, "text": " that say we have some element of the cortex perhaps the frontal eye field that's making predictions", "tokens": [51268, 300, 584, 321, 362, 512, 4478, 295, 264, 33312, 4317, 264, 34647, 3313, 2519, 300, 311, 1455, 21264, 51480], "temperature": 0.0, "avg_logprob": -0.07816312160897762, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.010264190845191479}, {"id": 429, "seek": 257508, "start": 2597.4, "end": 2603.72, "text": " about one of several alternative locations I could direct my gaze we can then map that", "tokens": [51480, 466, 472, 295, 2940, 8535, 9253, 286, 727, 2047, 452, 24294, 321, 393, 550, 4471, 300, 51796], "temperature": 0.0, "avg_logprob": -0.07816312160897762, "compression_ratio": 1.7859922178988328, "no_speech_prob": 0.010264190845191479}, {"id": 430, "seek": 260372, "start": 2603.72, "end": 2609.72, "text": " via sort of output of the basal ganglia and the predictions about what policy I'm going to pursue", "tokens": [50364, 5766, 1333, 295, 5598, 295, 264, 987, 304, 10145, 14218, 293, 264, 21264, 466, 437, 3897, 286, 478, 516, 281, 12392, 50664], "temperature": 0.0, "avg_logprob": -0.08237097522999981, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.004404688253998756}, {"id": 431, "seek": 260372, "start": 2611.16, "end": 2616.68, "text": " through to areas like the superior colliculus which then might make use of predictive coding", "tokens": [50736, 807, 281, 3179, 411, 264, 13028, 1263, 299, 26107, 597, 550, 1062, 652, 764, 295, 35521, 17720, 51012], "temperature": 0.0, "avg_logprob": -0.08237097522999981, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.004404688253998756}, {"id": 432, "seek": 260372, "start": 2616.68, "end": 2622.8399999999997, "text": " style networks of the sort depicted here to then generate eye movements as we've seen before", "tokens": [51012, 3758, 9590, 295, 264, 1333, 30207, 510, 281, 550, 8460, 3313, 9981, 382, 321, 600, 1612, 949, 51320], "temperature": 0.0, "avg_logprob": -0.08237097522999981, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.004404688253998756}, {"id": 433, "seek": 260372, "start": 2623.72, "end": 2628.04, "text": " and just to show you that in action we imagine that these are population of neurons that at", "tokens": [51364, 293, 445, 281, 855, 291, 300, 294, 3069, 321, 3811, 300, 613, 366, 4415, 295, 22027, 300, 412, 51580], "temperature": 0.0, "avg_logprob": -0.08237097522999981, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.004404688253998756}, {"id": 434, "seek": 260372, "start": 2628.04, "end": 2633.08, "text": " each time point are trying to predict one of several in this case three different locations", "tokens": [51580, 1184, 565, 935, 366, 1382, 281, 6069, 472, 295, 2940, 294, 341, 1389, 1045, 819, 9253, 51832], "temperature": 0.0, "avg_logprob": -0.08237097522999981, "compression_ratio": 1.749063670411985, "no_speech_prob": 0.004404688253998756}, {"id": 435, "seek": 263308, "start": 2633.08, "end": 2639.48, "text": " at four different time points we can then map that through structures like the superior colliculus", "tokens": [50364, 412, 1451, 819, 565, 2793, 321, 393, 550, 4471, 300, 807, 9227, 411, 264, 13028, 1263, 299, 26107, 50684], "temperature": 0.0, "avg_logprob": -0.06390162003345978, "compression_ratio": 1.7259615384615385, "no_speech_prob": 0.003544565988704562}, {"id": 436, "seek": 263308, "start": 2639.48, "end": 2645.48, "text": " and this is supposed to sort of cartoon the idea of a population code in the superior colliculus", "tokens": [50684, 293, 341, 307, 3442, 281, 1333, 295, 18569, 264, 1558, 295, 257, 4415, 3089, 294, 264, 13028, 1263, 299, 26107, 50984], "temperature": 0.0, "avg_logprob": -0.06390162003345978, "compression_ratio": 1.7259615384615385, "no_speech_prob": 0.003544565988704562}, {"id": 437, "seek": 263308, "start": 2645.48, "end": 2649.88, "text": " but then results in the eye movement to each of those discrete locations", "tokens": [50984, 457, 550, 3542, 294, 264, 3313, 3963, 281, 1184, 295, 729, 27706, 9253, 51204], "temperature": 0.0, "avg_logprob": -0.06390162003345978, "compression_ratio": 1.7259615384615385, "no_speech_prob": 0.003544565988704562}, {"id": 438, "seek": 263308, "start": 2651.56, "end": 2656.2, "text": " putting it all together we can then formulate exactly the task that I asked you to perform", "tokens": [51288, 3372, 309, 439, 1214, 321, 393, 550, 47881, 2293, 264, 5633, 300, 286, 2351, 291, 281, 2042, 51520], "temperature": 0.0, "avg_logprob": -0.06390162003345978, "compression_ratio": 1.7259615384615385, "no_speech_prob": 0.003544565988704562}, {"id": 439, "seek": 265620, "start": 2656.2, "end": 2662.12, "text": " earlier and see the result of an active infant scheme performing that task", "tokens": [50364, 3071, 293, 536, 264, 1874, 295, 364, 4967, 16757, 12232, 10205, 300, 5633, 50660], "temperature": 0.0, "avg_logprob": -0.0702811362038196, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.028846386820077896}, {"id": 440, "seek": 265620, "start": 2662.9199999999996, "end": 2668.7599999999998, "text": " and so here you can see it performs it very successfully by predicting sequences of eye", "tokens": [50700, 293, 370, 510, 291, 393, 536, 309, 26213, 309, 588, 10727, 538, 32884, 22978, 295, 3313, 50992], "temperature": 0.0, "avg_logprob": -0.0702811362038196, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.028846386820077896}, {"id": 441, "seek": 265620, "start": 2668.7599999999998, "end": 2676.4399999999996, "text": " movements that are conditioned upon the discrete part of the model and the idea of maintaining", "tokens": [50992, 9981, 300, 366, 35833, 3564, 264, 27706, 644, 295, 264, 2316, 293, 264, 1558, 295, 14916, 51376], "temperature": 0.0, "avg_logprob": -0.0702811362038196, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.028846386820077896}, {"id": 442, "seek": 265620, "start": 2676.4399999999996, "end": 2682.52, "text": " this belief about where the stimulus appeared and using that then to direct my policy selection", "tokens": [51376, 341, 7107, 466, 689, 264, 21366, 8516, 293, 1228, 300, 550, 281, 2047, 452, 3897, 9450, 51680], "temperature": 0.0, "avg_logprob": -0.0702811362038196, "compression_ratio": 1.6729857819905214, "no_speech_prob": 0.028846386820077896}, {"id": 443, "seek": 268252, "start": 2682.52, "end": 2690.44, "text": " and eventually the movement I select I want to give you one more example of this sort of hierarchical", "tokens": [50364, 293, 4728, 264, 3963, 286, 3048, 286, 528, 281, 976, 291, 472, 544, 1365, 295, 341, 1333, 295, 35250, 804, 50760], "temperature": 0.0, "avg_logprob": -0.07297805460487924, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.004037491045892239}, {"id": 444, "seek": 268252, "start": 2690.44, "end": 2696.28, "text": " scheme in the domain of motor control and appeal to the same sort of simulations we were looking", "tokens": [50760, 12232, 294, 264, 9274, 295, 5932, 1969, 293, 13668, 281, 264, 912, 1333, 295, 35138, 321, 645, 1237, 51052], "temperature": 0.0, "avg_logprob": -0.07297805460487924, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.004037491045892239}, {"id": 445, "seek": 268252, "start": 2696.28, "end": 2701.8, "text": " at earlier in terms of the reflexes exhibited by that arm the generative model we're going to use", "tokens": [51052, 412, 3071, 294, 2115, 295, 264, 23802, 279, 49446, 538, 300, 3726, 264, 1337, 1166, 2316, 321, 434, 516, 281, 764, 51328], "temperature": 0.0, "avg_logprob": -0.07297805460487924, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.004037491045892239}, {"id": 446, "seek": 268252, "start": 2701.8, "end": 2707.8, "text": " here is a slightly complicated one but here effectively involves transitions between different", "tokens": [51328, 510, 307, 257, 4748, 6179, 472, 457, 510, 8659, 11626, 23767, 1296, 819, 51628], "temperature": 0.0, "avg_logprob": -0.07297805460487924, "compression_ratio": 1.649789029535865, "no_speech_prob": 0.004037491045892239}, {"id": 447, "seek": 270780, "start": 2707.8, "end": 2713.88, "text": " locations that an arm could be in or a hand could be in which then predicts different locations in", "tokens": [50364, 9253, 300, 364, 3726, 727, 312, 294, 420, 257, 1011, 727, 312, 294, 597, 550, 6069, 82, 819, 9253, 294, 50668], "temperature": 0.0, "avg_logprob": -0.05967527838314281, "compression_ratio": 1.9261083743842364, "no_speech_prob": 0.08089115470647812}, {"id": 448, "seek": 270780, "start": 2713.88, "end": 2721.7200000000003, "text": " some continuous space and different locations that a target might be in and that will then allow us", "tokens": [50668, 512, 10957, 1901, 293, 819, 9253, 300, 257, 3779, 1062, 312, 294, 293, 300, 486, 550, 2089, 505, 51060], "temperature": 0.0, "avg_logprob": -0.05967527838314281, "compression_ratio": 1.9261083743842364, "no_speech_prob": 0.08089115470647812}, {"id": 449, "seek": 270780, "start": 2721.7200000000003, "end": 2729.0, "text": " to make predictions about about given where some target is in some continuous space which decision", "tokens": [51060, 281, 652, 21264, 466, 466, 2212, 689, 512, 3779, 307, 294, 512, 10957, 1901, 597, 3537, 51424], "temperature": 0.0, "avg_logprob": -0.05967527838314281, "compression_ratio": 1.9261083743842364, "no_speech_prob": 0.08089115470647812}, {"id": 450, "seek": 270780, "start": 2729.0, "end": 2734.1200000000003, "text": " I'm going to make about the alternative points I could move my arm to and so here we have the", "tokens": [51424, 286, 478, 516, 281, 652, 466, 264, 8535, 2793, 286, 727, 1286, 452, 3726, 281, 293, 370, 510, 321, 362, 264, 51680], "temperature": 0.0, "avg_logprob": -0.05967527838314281, "compression_ratio": 1.9261083743842364, "no_speech_prob": 0.08089115470647812}, {"id": 451, "seek": 273412, "start": 2734.12, "end": 2739.56, "text": " simulation where we have the target appearing as the black ball out of the out of the three balls", "tokens": [50364, 16575, 689, 321, 362, 264, 3779, 19870, 382, 264, 2211, 2594, 484, 295, 264, 484, 295, 264, 1045, 9803, 50636], "temperature": 0.0, "avg_logprob": -0.07419566705193319, "compression_ratio": 1.7524271844660195, "no_speech_prob": 0.0032135711517184973}, {"id": 452, "seek": 273412, "start": 2739.56, "end": 2745.96, "text": " which is going to change at various points in time and our active infant scheme is now", "tokens": [50636, 597, 307, 516, 281, 1319, 412, 3683, 2793, 294, 565, 293, 527, 4967, 16757, 12232, 307, 586, 50956], "temperature": 0.0, "avg_logprob": -0.07419566705193319, "compression_ratio": 1.7524271844660195, "no_speech_prob": 0.0032135711517184973}, {"id": 453, "seek": 273412, "start": 2745.96, "end": 2751.08, "text": " selecting these locations translating those into predictions of continuous trajectories", "tokens": [50956, 18182, 613, 9253, 35030, 729, 666, 21264, 295, 10957, 18257, 2083, 51212], "temperature": 0.0, "avg_logprob": -0.07419566705193319, "compression_ratio": 1.7524271844660195, "no_speech_prob": 0.0032135711517184973}, {"id": 454, "seek": 273412, "start": 2751.08, "end": 2756.44, "text": " and making the appropriate movements such that it reaches each of these target locations", "tokens": [51212, 293, 1455, 264, 6854, 9981, 1270, 300, 309, 14235, 1184, 295, 613, 3779, 9253, 51480], "temperature": 0.0, "avg_logprob": -0.07419566705193319, "compression_ratio": 1.7524271844660195, "no_speech_prob": 0.0032135711517184973}, {"id": 455, "seek": 275644, "start": 2756.44, "end": 2763.48, "text": " and what's shown in terms of the the graphic here is also an interpretation of the message", "tokens": [50364, 293, 437, 311, 4898, 294, 2115, 295, 264, 264, 14089, 510, 307, 611, 364, 14174, 295, 264, 3636, 50716], "temperature": 0.0, "avg_logprob": -0.11492438316345215, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.012650392949581146}, {"id": 456, "seek": 275644, "start": 2763.48, "end": 2768.76, "text": " passing in terms of the known anatomy of the motor system or part of it", "tokens": [50716, 8437, 294, 2115, 295, 264, 2570, 31566, 295, 264, 5932, 1185, 420, 644, 295, 309, 50980], "temperature": 0.0, "avg_logprob": -0.11492438316345215, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.012650392949581146}, {"id": 457, "seek": 275644, "start": 2771.0, "end": 2775.2400000000002, "text": " we can perform various lesions to this and see whether they behave in the same way that we might", "tokens": [51092, 321, 393, 2042, 3683, 1512, 626, 281, 341, 293, 536, 1968, 436, 15158, 294, 264, 912, 636, 300, 321, 1062, 51304], "temperature": 0.0, "avg_logprob": -0.11492438316345215, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.012650392949581146}, {"id": 458, "seek": 275644, "start": 2775.2400000000002, "end": 2781.96, "text": " expect patient populations to so here we've induced a cerebellar lesion which effectively", "tokens": [51304, 2066, 4537, 12822, 281, 370, 510, 321, 600, 33991, 257, 11643, 7100, 289, 1512, 313, 597, 8659, 51640], "temperature": 0.0, "avg_logprob": -0.11492438316345215, "compression_ratio": 1.6941747572815533, "no_speech_prob": 0.012650392949581146}, {"id": 459, "seek": 278196, "start": 2782.76, "end": 2790.28, "text": " involves a misestimation of certain precision terms certain confidence or variance parameters", "tokens": [50404, 11626, 257, 3346, 377, 332, 399, 295, 1629, 18356, 2115, 1629, 6687, 420, 21977, 9834, 50780], "temperature": 0.0, "avg_logprob": -0.1448140854531146, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028224990237504244}, {"id": 460, "seek": 278196, "start": 2790.84, "end": 2796.28, "text": " and you see this sort of overshoot and this kind of oscillatory behavior in the way the arm behaves", "tokens": [50808, 293, 291, 536, 341, 1333, 295, 15488, 24467, 293, 341, 733, 295, 18225, 4745, 5223, 294, 264, 636, 264, 3726, 36896, 51080], "temperature": 0.0, "avg_logprob": -0.1448140854531146, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028224990237504244}, {"id": 461, "seek": 278196, "start": 2797.16, "end": 2800.36, "text": " that mimics what we might expect him as cerebellar attacks here", "tokens": [51124, 300, 12247, 1167, 437, 321, 1062, 2066, 796, 382, 11643, 7100, 289, 8122, 510, 51284], "temperature": 0.0, "avg_logprob": -0.1448140854531146, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028224990237504244}, {"id": 462, "seek": 278196, "start": 2802.36, "end": 2805.64, "text": " we can look at the higher levels of the model and actually have multiple", "tokens": [51384, 321, 393, 574, 412, 264, 2946, 4358, 295, 264, 2316, 293, 767, 362, 3866, 51548], "temperature": 0.0, "avg_logprob": -0.1448140854531146, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028224990237504244}, {"id": 463, "seek": 278196, "start": 2806.44, "end": 2810.6, "text": " hierarchical levels of the discrete scheme and here what we've done is we've induced a", "tokens": [51588, 35250, 804, 4358, 295, 264, 27706, 12232, 293, 510, 437, 321, 600, 1096, 307, 321, 600, 33991, 257, 51796], "temperature": 0.0, "avg_logprob": -0.1448140854531146, "compression_ratio": 1.7521008403361344, "no_speech_prob": 0.0028224990237504244}, {"id": 464, "seek": 281060, "start": 2811.56, "end": 2818.2799999999997, "text": " lesion in what might represent a frontal lobe lesion where now the model is able to perform", "tokens": [50412, 1512, 313, 294, 437, 1062, 2906, 257, 34647, 450, 650, 1512, 313, 689, 586, 264, 2316, 307, 1075, 281, 2042, 50748], "temperature": 0.0, "avg_logprob": -0.1251749342138117, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0034328787587583065}, {"id": 465, "seek": 281060, "start": 2818.2799999999997, "end": 2823.24, "text": " all the movements with perfect fluency but every time there's a change of context it takes quite", "tokens": [50748, 439, 264, 9981, 365, 2176, 5029, 3020, 457, 633, 565, 456, 311, 257, 1319, 295, 4319, 309, 2516, 1596, 50996], "temperature": 0.0, "avg_logprob": -0.1251749342138117, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0034328787587583065}, {"id": 466, "seek": 281060, "start": 2823.24, "end": 2828.36, "text": " a while to adjust to that new context to deal with a new situation you'll see that instead of", "tokens": [50996, 257, 1339, 281, 4369, 281, 300, 777, 4319, 281, 2028, 365, 257, 777, 2590, 291, 603, 536, 300, 2602, 295, 51252], "temperature": 0.0, "avg_logprob": -0.1251749342138117, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0034328787587583065}, {"id": 467, "seek": 281060, "start": 2829.16, "end": 2833.72, "text": " moving straight there as it was before there's a lot more hesitancy and a lot more difficulty", "tokens": [51292, 2684, 2997, 456, 382, 309, 390, 949, 456, 311, 257, 688, 544, 28336, 6717, 293, 257, 688, 544, 10360, 51520], "temperature": 0.0, "avg_logprob": -0.1251749342138117, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0034328787587583065}, {"id": 468, "seek": 283372, "start": 2833.7999999999997, "end": 2840.12, "text": " constructing that long-term narrative because we've broken that slower hierarchical level", "tokens": [50368, 39969, 300, 938, 12, 7039, 9977, 570, 321, 600, 5463, 300, 14009, 35250, 804, 1496, 50684], "temperature": 0.0, "avg_logprob": -0.08729686969664038, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.26582399010658264}, {"id": 469, "seek": 283372, "start": 2842.2799999999997, "end": 2847.48, "text": " and here a final lesion that we can introduce is one that reduces my confidence in policy", "tokens": [50792, 293, 510, 257, 2572, 1512, 313, 300, 321, 393, 5366, 307, 472, 300, 18081, 452, 6687, 294, 3897, 51052], "temperature": 0.0, "avg_logprob": -0.08729686969664038, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.26582399010658264}, {"id": 470, "seek": 283372, "start": 2847.48, "end": 2852.52, "text": " selection so here this effectively makes me very uncertain about what I'm going to do next and", "tokens": [51052, 9450, 370, 510, 341, 8659, 1669, 385, 588, 11308, 466, 437, 286, 478, 516, 281, 360, 958, 293, 51304], "temperature": 0.0, "avg_logprob": -0.08729686969664038, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.26582399010658264}, {"id": 471, "seek": 283372, "start": 2852.52, "end": 2858.04, "text": " here we get a sort of a kinetic type picture and sort we might expect in a Parkinsonian type syndrome", "tokens": [51304, 510, 321, 483, 257, 1333, 295, 257, 27135, 2010, 3036, 293, 1333, 321, 1062, 2066, 294, 257, 35823, 952, 2010, 19371, 51580], "temperature": 0.0, "avg_logprob": -0.08729686969664038, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.26582399010658264}, {"id": 472, "seek": 285804, "start": 2858.12, "end": 2867.96, "text": " so I realized that was quite a lot and I hope I'm not too far over time but I'll just try and", "tokens": [50368, 370, 286, 5334, 300, 390, 1596, 257, 688, 293, 286, 1454, 286, 478, 406, 886, 1400, 670, 565, 457, 286, 603, 445, 853, 293, 50860], "temperature": 0.0, "avg_logprob": -0.11372420228557822, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.009700698778033257}, {"id": 473, "seek": 285804, "start": 2867.96, "end": 2874.6, "text": " summarize briefly the key ideas that we've discussed so the first was thinking about this", "tokens": [50860, 20858, 10515, 264, 2141, 3487, 300, 321, 600, 7152, 370, 264, 700, 390, 1953, 466, 341, 51192], "temperature": 0.0, "avg_logprob": -0.11372420228557822, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.009700698778033257}, {"id": 474, "seek": 285804, "start": 2874.6, "end": 2879.08, "text": " idea of climbing probability gradients the idea that to maintain some form over time", "tokens": [51192, 1558, 295, 14780, 8482, 2771, 2448, 264, 1558, 300, 281, 6909, 512, 1254, 670, 565, 51416], "temperature": 0.0, "avg_logprob": -0.11372420228557822, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.009700698778033257}, {"id": 475, "seek": 285804, "start": 2880.04, "end": 2886.52, "text": " and to persist we need to effectively be climbing these probability gradients all the time", "tokens": [51464, 293, 281, 13233, 321, 643, 281, 8659, 312, 14780, 613, 8482, 2771, 2448, 439, 264, 565, 51788], "temperature": 0.0, "avg_logprob": -0.11372420228557822, "compression_ratio": 1.7177033492822966, "no_speech_prob": 0.009700698778033257}, {"id": 476, "seek": 288652, "start": 2887.48, "end": 2892.44, "text": " we interpreted those probability gradients in terms of in terms of Bayes theorem and connected", "tokens": [50412, 321, 26749, 729, 8482, 2771, 2448, 294, 2115, 295, 294, 2115, 295, 7840, 279, 20904, 293, 4582, 50660], "temperature": 0.0, "avg_logprob": -0.16067133510813994, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.002361810766160488}, {"id": 477, "seek": 288652, "start": 2892.44, "end": 2897.24, "text": " that to the Bayes in brain and the sort of message passing that might be involved in", "tokens": [50660, 300, 281, 264, 7840, 279, 294, 3567, 293, 264, 1333, 295, 3636, 8437, 300, 1062, 312, 3288, 294, 50900], "temperature": 0.0, "avg_logprob": -0.16067133510813994, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.002361810766160488}, {"id": 478, "seek": 288652, "start": 2898.12, "end": 2903.24, "text": " forming inferences about elements of some generative model and the role that might have", "tokens": [50944, 15745, 13596, 2667, 466, 4959, 295, 512, 1337, 1166, 2316, 293, 264, 3090, 300, 1062, 362, 51200], "temperature": 0.0, "avg_logprob": -0.16067133510813994, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.002361810766160488}, {"id": 479, "seek": 288652, "start": 2903.24, "end": 2911.88, "text": " in cortical micro-circuitry we also discussed the role of action and the idea that that one way to", "tokens": [51200, 294, 11278, 804, 4532, 12, 23568, 66, 1983, 627, 321, 611, 7152, 264, 3090, 295, 3069, 293, 264, 1558, 300, 300, 472, 636, 281, 51632], "temperature": 0.0, "avg_logprob": -0.16067133510813994, "compression_ratio": 1.7511961722488039, "no_speech_prob": 0.002361810766160488}, {"id": 480, "seek": 291188, "start": 2911.96, "end": 2917.32, "text": " make our model better fit the world is to act upon it and one way to do that is to simply reduce", "tokens": [50368, 652, 527, 2316, 1101, 3318, 264, 1002, 307, 281, 605, 3564, 309, 293, 472, 636, 281, 360, 300, 307, 281, 2935, 5407, 50636], "temperature": 0.0, "avg_logprob": -0.07164571477078843, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.03723709657788277}, {"id": 481, "seek": 291188, "start": 2917.32, "end": 2923.96, "text": " any discrepancy between the predictions from that model and the data that's coming in and the", "tokens": [50636, 604, 2983, 265, 6040, 1344, 1296, 264, 21264, 490, 300, 2316, 293, 264, 1412, 300, 311, 1348, 294, 293, 264, 50968], "temperature": 0.0, "avg_logprob": -0.07164571477078843, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.03723709657788277}, {"id": 482, "seek": 291188, "start": 2923.96, "end": 2931.1600000000003, "text": " structure of that is very similar to the idea of a reflex arc as is well known throughout", "tokens": [50968, 3877, 295, 300, 307, 588, 2531, 281, 264, 1558, 295, 257, 23802, 10346, 382, 307, 731, 2570, 3710, 51328], "temperature": 0.0, "avg_logprob": -0.07164571477078843, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.03723709657788277}, {"id": 483, "seek": 291188, "start": 2931.96, "end": 2939.8, "text": " motor neuroscience and the final thing we thought about was how we can then construct hierarchical", "tokens": [51368, 5932, 42762, 293, 264, 2572, 551, 321, 1194, 466, 390, 577, 321, 393, 550, 7690, 35250, 804, 51760], "temperature": 0.0, "avg_logprob": -0.07164571477078843, "compression_ratio": 1.738532110091743, "no_speech_prob": 0.03723709657788277}, {"id": 484, "seek": 293980, "start": 2939.8, "end": 2947.6400000000003, "text": " models that allow us to produce simulations and theories that deal with much larger scale", "tokens": [50364, 5245, 300, 2089, 505, 281, 5258, 35138, 293, 13667, 300, 2028, 365, 709, 4833, 4373, 50756], "temperature": 0.0, "avg_logprob": -0.07848448435465495, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.001158235128968954}, {"id": 485, "seek": 293980, "start": 2947.6400000000003, "end": 2953.8, "text": " networks in the brain and take a full sort of systems level view of how particular movements", "tokens": [50756, 9590, 294, 264, 3567, 293, 747, 257, 1577, 1333, 295, 3652, 1496, 1910, 295, 577, 1729, 9981, 51064], "temperature": 0.0, "avg_logprob": -0.07848448435465495, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.001158235128968954}, {"id": 486, "seek": 293980, "start": 2953.8, "end": 2960.92, "text": " and particular behaviors are generated through the inversion of particular forms of generative model", "tokens": [51064, 293, 1729, 15501, 366, 10833, 807, 264, 43576, 295, 1729, 6422, 295, 1337, 1166, 2316, 51420], "temperature": 0.0, "avg_logprob": -0.07848448435465495, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.001158235128968954}, {"id": 487, "seek": 293980, "start": 2962.52, "end": 2968.92, "text": " with that I'd like to thank many people who've been involved either directly or indirectly in", "tokens": [51500, 365, 300, 286, 1116, 411, 281, 1309, 867, 561, 567, 600, 668, 3288, 2139, 3838, 420, 37779, 294, 51820], "temperature": 0.0, "avg_logprob": -0.07848448435465495, "compression_ratio": 1.6905829596412556, "no_speech_prob": 0.001158235128968954}, {"id": 488, "seek": 296892, "start": 2968.92, "end": 2974.28, "text": " this work and I'll mention the book again which was mentioned at the beginning and a lot of this", "tokens": [50364, 341, 589, 293, 286, 603, 2152, 264, 1446, 797, 597, 390, 2835, 412, 264, 2863, 293, 257, 688, 295, 341, 50632], "temperature": 0.0, "avg_logprob": -0.13225179643773322, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.021731294691562653}, {"id": 489, "seek": 296892, "start": 2974.28, "end": 2979.32, "text": " talk was loosely following some of the structure in a couple of the chapters in the book so if", "tokens": [50632, 751, 390, 37966, 3480, 512, 295, 264, 3877, 294, 257, 1916, 295, 264, 20013, 294, 264, 1446, 370, 498, 50884], "temperature": 0.0, "avg_logprob": -0.13225179643773322, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.021731294691562653}, {"id": 490, "seek": 296892, "start": 2979.32, "end": 2986.52, "text": " anybody's interested please do take a look I'm more than happy to answer any questions thank you for", "tokens": [50884, 4472, 311, 3102, 1767, 360, 747, 257, 574, 286, 478, 544, 813, 2055, 281, 1867, 604, 1651, 1309, 291, 337, 51244], "temperature": 0.0, "avg_logprob": -0.13225179643773322, "compression_ratio": 1.6404494382022472, "no_speech_prob": 0.021731294691562653}, {"id": 491, "seek": 298652, "start": 2986.52, "end": 2992.12, "text": " your attention", "tokens": [50364, 428, 3202, 50644], "temperature": 0.0, "avg_logprob": -0.652293348312378, "compression_ratio": 0.6363636363636364, "no_speech_prob": 0.40794721245765686}], "language": "en"}