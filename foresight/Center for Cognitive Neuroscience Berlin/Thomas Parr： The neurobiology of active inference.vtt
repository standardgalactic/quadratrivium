WEBVTT

00:00.000 --> 00:14.320
It's a great pleasure to introduce Thomas Paar today, we'll be about his background.

00:14.320 --> 00:25.160
So he started medical school in 2012, I guess, at the UCL and did also like a bachelor there

00:25.160 --> 00:35.080
with a focus in new science. In 2016, he started his PhD, I hope everything is correct, he started

00:35.080 --> 00:45.400
his PhD working together with Carl Friston and Garen Rees. So I think Thomas is really like the

00:45.400 --> 00:53.520
person who most frustrated me, when I was at the at the Philly, so a long time ago. I was fascinated

00:53.520 --> 01:01.400
by like the idea of the free entry principle and Carl Friston and really started going, learning

01:01.400 --> 01:09.480
about Boltzmann equations and some kind of like message passing and so on and over years and years.

01:09.480 --> 01:20.600
And then in 2016-17, I realized that suddenly a number of papers were coming out, it became much

01:20.680 --> 01:28.120
more accessible and on these papers there were always like one name, Thomas Paar. And so I looked

01:28.120 --> 01:35.240
into that and I realized that there is one person out there who is so young and who plus

01:35.240 --> 01:46.040
started his PhD, who was able to go all through this extremely complicated math and ideas so easily

01:46.520 --> 01:53.000
that I thought I should really give up thinking about the free energy principle at all. And more

01:53.000 --> 01:59.240
impressively, I think a couple of months ago, even like a book came out like about like Active

01:59.240 --> 02:07.320
Influence, where he is like the first author on and I really can recommend this book. It's a

02:07.320 --> 02:13.240
fantastic introduction to Active Influence, to the free energy principle. So it's a really,

02:13.240 --> 02:20.680
really great pleasure to have you here tonight, Thomas, and I'm really looking forward to your

02:20.680 --> 02:29.960
talk. Thanks for joining. Well, thank you very much for the very nice invitation and the very

02:29.960 --> 02:39.320
nice introduction as well. First of all, can you hear me okay? Yes. And next thing is to see

02:39.320 --> 02:48.120
whether I can successfully share my screen. Let's try this. So I'm assuming you can see the

02:48.120 --> 02:58.120
PowerPoint and now hopefully in full screen. Perfect. Great. So today, I realized that you've

02:58.120 --> 03:05.640
already had a talk from Ryan Smith previously, so I'm assuming he's given an excellent overview of

03:05.640 --> 03:11.880
Active Influences as he always does. And I wanted to take the opportunity to focus in on something

03:11.880 --> 03:19.800
a little bit more specific in this talk, which is thinking about how dealing with Active Influence

03:19.800 --> 03:25.640
lets us think about neurobiology and how we can start to make connections and form neurobiological

03:25.640 --> 03:34.360
theories from the principles. So I'll start just by giving an introduction that I think

03:34.440 --> 03:39.160
will hopefully give everybody a little bit of a refresher on Active Influence and the basic

03:39.160 --> 03:44.440
principles. And although there are some technical elements to it, I'll try to make it as intuitive

03:44.440 --> 03:48.760
as possible. And it really doesn't matter if you get all the technical detail through this,

03:48.760 --> 03:56.680
it's just to build some intuitions. So I tend to like to start talks with this slide, which just

03:56.680 --> 04:03.320
shows two different sorts of system. The one on the left is one that just gradually diffuses over

04:03.320 --> 04:08.920
time, sort of loses form becomes progressively less interesting. Whereas the one on the right,

04:08.920 --> 04:13.800
despite having the same amount of randomness built into it, manages to maintain its form over time.

04:14.520 --> 04:19.080
And a useful starting point in thinking about Active Influence is thinking about

04:19.720 --> 04:25.800
what the difference between these two sorts of systems are and how the one on the right is able

04:25.800 --> 04:34.120
to maintain its form and resist the effect of these random fluctuations that are forcing it

04:34.120 --> 04:40.760
in all sorts of different directions. And it's often useful to reformulate this in terms of the

04:40.760 --> 04:46.520
probability density or the change in the probability distribution of all of these little particles

04:46.520 --> 04:50.120
over time. So again, you can see on the left, we've got something that's just diffusing out into

04:50.120 --> 04:55.080
nothing. And on the right, we get something that behaves from a probabilistic level pretty much

04:55.080 --> 05:01.080
statically. And it's really those on the right that we're interested in, those biological creatures

05:01.080 --> 05:05.560
are able to maintain their form, are able to resist the effects of what the environment does to them.

05:06.600 --> 05:11.080
Now, if we sort of write down the kinds of dynamics that we'd need for a single particle

05:11.080 --> 05:17.080
or a single part of the system to try and maintain this form, what we get to is a system that I think

05:17.080 --> 05:23.720
quite intuitively always moves when it can from regions of low probability to regions of high

05:23.720 --> 05:28.440
probability. So if we interpret this final distribution it gets to as some steady state,

05:29.240 --> 05:34.280
all we need to do to maintain that in a random environment is to always try and climb uphill

05:34.280 --> 05:38.520
at the probability gradients. And then almost by definition, we end up spending more time in

05:38.520 --> 05:45.480
highly probable states and less time in more improbable states. And this is sort of the starting

05:45.480 --> 05:50.840
point really for active inference, because we now have this notion that we're climbing probability

05:50.840 --> 05:55.240
gradients and we have some distribution that we're effectively trying to maximize.

05:56.200 --> 06:02.600
And we can link that back to ideas like the Bayesian brain, the idea that the brain is using some

06:02.600 --> 06:10.200
model of the world around it to generate predictions. And then is drawing inferences about

06:10.200 --> 06:15.480
the data that it actually obtains, so sensory information coming in through our eyes, ears,

06:15.480 --> 06:20.840
through our skin, that we can then use to draw inferences about the causes of those data.

06:22.440 --> 06:26.920
So here we've got the idea that there's some states of the world X that are causing some

06:26.920 --> 06:34.600
sensory data Y. We're then forming some posterior beliefs, so beliefs about the causes given with

06:34.600 --> 06:41.480
the data. And we're doing this using a generative model that comprises a likelihood in a prior,

06:41.480 --> 06:45.240
so prior being how plausible are the things out there in the world before we've

06:45.240 --> 06:51.160
made any observations. The likelihood being how likely the observations we've made are given

06:51.160 --> 06:56.040
the states of the world or given our hypotheses about what caused them. And together we refer

06:56.040 --> 07:01.800
to these two things as a generative model. Now the posterior distribution is what happens when

07:01.800 --> 07:08.120
we invert that model where we find the probability of some causes given the data.

07:09.080 --> 07:14.120
And the final term we've got at the end here is referred to either as an evidence or a marginal

07:14.120 --> 07:19.080
likelihood. And that's because in the context of Bayesian statistics we often use a marginal

07:19.080 --> 07:25.400
likelihood as a measure of the fit of a model to the data that it's trying to explain. There's

07:25.400 --> 07:31.080
how much evidence do those data afford some model of the world. And together we can think of these

07:31.080 --> 07:35.960
as being an inversion of the generative model. Now the reason I've put this here is that we

07:35.960 --> 07:43.880
can see that the dynamics that I'm showing in the upper left can be interpreted as the process of

07:43.880 --> 07:48.840
maximising the evidence for some model, maximising the fit between the brain's model of how the world

07:48.840 --> 07:55.400
works and how the world then engages with the model or engages with the brain by presenting it data.

07:56.760 --> 08:01.320
And broadly there are two ways of doing that. The first is, as we've already spoken about,

08:01.320 --> 08:05.880
it's changing your beliefs based upon new data such that you get a better fit to the world.

08:06.680 --> 08:11.480
The other way, which I think is one of the key ideas in Active Inference, is that you

08:11.480 --> 08:16.360
generate actions based upon your beliefs that change the world to make it more like your model.

08:17.880 --> 08:23.160
And this is sort of the key idea that underwrites Active Inference, that all we're trying to do

08:23.160 --> 08:28.680
is maximise the evidence for some model of our world. And we can either do that through

08:28.680 --> 08:34.360
perception by changing our model or through action by changing the world. But together,

08:34.360 --> 08:40.200
they come under one single objective, sometimes referred to, particularly by people like Kevin

08:40.200 --> 08:48.120
the Acapoway, as self-evidencing. Now I want to go a little bit into the structure of generative

08:48.120 --> 08:53.560
models and specifically the ways we can think about and the ways we can notate generative models,

08:54.440 --> 08:59.240
because it often helps to move from the slightly more mathematical abstract description to a more

08:59.240 --> 09:04.440
graphical notation that I think often gives a much better intuitive sense of what's going on.

09:05.240 --> 09:10.280
So to do that, I'm going to start with this idea that model evidence is effectively what we get out

09:10.280 --> 09:16.920
once we've integrated out all of the causes from our model, by which I mean if you take

09:16.920 --> 09:22.440
account of all of the things our model predicts and then we take into account the prior probabilities

09:22.440 --> 09:29.160
of all of the things that are causing those data, we can then work out what the probability of the

09:29.160 --> 09:35.640
data are under that model. But the model itself takes account of the things that are being generated,

09:35.640 --> 09:39.960
so our sensory data, and also the things that are causing them, simply a joint probability

09:39.960 --> 09:44.840
distribution involving all of these things. So I'm now interpreting this graphic up on

09:44.840 --> 09:50.520
the left as depending upon some generative model where we've effectively integrated out everything

09:50.520 --> 09:58.760
that we don't need to determine explicitly. Now generative models will often have some

09:58.760 --> 10:02.920
interesting structure, and in fact if they don't have interesting structures then they're not

10:02.920 --> 10:09.000
interesting generative models. And normally that structure manifests as a factorization

10:09.000 --> 10:14.440
of this joint distribution, but not everything depends upon everything else. And so we can

10:14.440 --> 10:19.080
often factorize it, and here I'm just showing a completely arbitrary factorization of some

10:19.080 --> 10:25.960
generative model where we have certain dependencies, so y depends directly upon x1 and x2, but not

10:25.960 --> 10:31.640
directly upon x3 and so on. And the reason it's useful to think about this factorization is because

10:31.640 --> 10:37.320
we can then express a graphical version of this model that provides a bit more intuition as to

10:37.320 --> 10:42.840
what's going on. So the way we do that, or one way that we can do that, is using something known as a

10:42.840 --> 10:47.720
factor graph. And the idea is that we take each of these factors in turn, we draw a square,

10:49.160 --> 10:55.160
and then we draw an arrow to whatever's on the left of the probability factor we're interested in.

10:55.160 --> 11:00.360
So here an arrow towards the y, because we're saying the probability of y conditioned upon or

11:00.360 --> 11:06.360
depending upon the other two things, and then we attach those to the same square. We then move

11:06.360 --> 11:11.800
on to the next factor, draw another square, and we then attach the relevant variables together

11:13.000 --> 11:18.040
in exactly the same way. And we carry on doing that until we have a picture of what our model is

11:18.040 --> 11:22.120
like. So now instead of having to look at this equation, you can look at this and say, okay,

11:22.120 --> 11:30.440
well x3 causes x1, x4 causes x2, and together x1 and x2 relate to or together generate our data y.

11:33.240 --> 11:38.360
This is just to demonstrate several models you may be familiar with generally, and the fact that we

11:38.360 --> 11:41.960
we're often implicitly using these kinds of generative models without necessarily thinking

11:41.960 --> 11:46.920
about it. So when we're performing a principal components analysis, we're often taking some

11:48.840 --> 11:53.720
distribution of some variable x, we're then mapping that to a higher dimensional space y,

11:55.000 --> 12:00.280
and that's our sort of model of how the data that we're working with are generated.

12:02.120 --> 12:05.960
So what we can then do when we perform a principal components analysis is take our

12:05.960 --> 12:11.720
high dimensional data y, work out how you go back from the y to the x, and that gives you all of your

12:11.720 --> 12:15.880
specific principal components and the directions that have been stretched in various different ways.

12:17.400 --> 12:21.160
Same principle applies for things like canonical variance analysis, where you've got some set of

12:21.720 --> 12:25.320
variables then mapped to two different sorts of data by stretching them and

12:26.120 --> 12:30.200
distorting them in various ways. And the challenge is how do you get back to the common

12:31.560 --> 12:37.240
hidden variable common cause for both of those datasets. And we do the same sort of thing with

12:37.240 --> 12:42.280
something like clustering analysis, where here the model says we're effectively sampling from

12:42.280 --> 12:46.920
one of several different clusters with different probabilities. We're then generating some point

12:46.920 --> 12:53.960
in space depending upon which cluster it falls in. And the process of inference is again undoing

12:53.960 --> 12:59.000
this. It's finding the posterior by taking a point in a cluster and saying, well, which cluster is

12:59.000 --> 13:06.120
that from? So going from the y to the s. So that's a sort of brief introduction to the idea of

13:06.120 --> 13:11.560
generative models, the the role they play in active inference, some key examples and some of

13:11.560 --> 13:16.600
the notation that I'm going to use as we go forward. What I've said so far has been relatively

13:16.600 --> 13:23.080
abstract. And in the next section, I want to try and work from those sort of general principles

13:23.080 --> 13:27.880
and these slightly abstract notions through to something more specific and more neurobiological.

13:29.000 --> 13:33.160
Now, the first thing we're going to do to get there is to introduce one more abstract concept,

13:33.160 --> 13:38.360
which is that of a Markov blanket. A Markov blanket comes up in all sorts of places in active

13:38.360 --> 13:43.160
inference, but I'm going to use it in a very specific way here. And this is to talk about

13:43.160 --> 13:48.840
conditional independence. And what I mean by conditional independence is that if you have

13:51.400 --> 13:55.160
two different sets of variables, so here I've noted them as the mu and the eta,

13:56.120 --> 14:02.760
the Markov blanket B is the set of set of variables that render the other two completely

14:02.760 --> 14:06.680
independent to one another, that mean that if you know everything about the blanket,

14:06.680 --> 14:09.880
knowing something about mu tells you nothing new about eta.

14:12.040 --> 14:16.520
To give you an example of this, one of the examples that most people are familiar with

14:16.520 --> 14:22.600
is the idea of a Markov chain, where you have a sequence of events in time. So something that

14:22.600 --> 14:27.400
happens in the past then influences the present, which then influences the future with no direct

14:27.400 --> 14:32.760
influence from the past to the future without going via the present. So if I know everything

14:32.760 --> 14:36.680
there is to know about the present, knowing something about the past tells me nothing new

14:36.680 --> 14:41.640
about the future and vice versa. So in that sense, the present is the Markov blanket that

14:41.640 --> 14:47.880
separates the past from the future. Now, this is a very useful concept when we're dealing with

14:47.880 --> 14:52.600
graphical models or generative models that have some interesting factorization structure,

14:52.600 --> 14:59.560
and I'll try and explain why. The Markov blanket is often referred to as or can often be identified

14:59.560 --> 15:04.440
by identifying variable we're interested in, so let's say we're interested in the variable x2,

15:05.080 --> 15:11.480
then you find the parents of x2, so the things that caused it, the children of x2, so the things

15:11.480 --> 15:17.240
it causes, and the parents of its children, and that gives you the Markov blanket of x2.

15:18.600 --> 15:25.240
Now the significance of this is that knowing this means that if we know about the blanket,

15:25.240 --> 15:28.600
it doesn't matter what else is going on in the generative model, you know, this might be some

15:28.600 --> 15:34.200
tiny section of a huge generative model with many, many variables, but we don't need to know about

15:34.200 --> 15:38.760
all those variables, all we need to know about are the blanket variables, so we can effectively

15:38.760 --> 15:46.200
ignore everything else if what we're interested in is x2. Now, how does this then matter for

15:46.200 --> 15:52.440
neurobiology? Well, I think the answer to that is that the brain is an extremely sparse structure,

15:52.440 --> 15:56.840
that synaptic message passing does not involve connections between every different neuron in

15:56.840 --> 16:01.240
the brain to every other neuron in the brain. There are a small number of, relatively speaking,

16:01.240 --> 16:08.360
of synapses between any neuron and its neighbors or neurons elsewhere in the brain,

16:09.160 --> 16:13.240
and so we can make an argument that if the brain is performing inference about lots of different

16:13.240 --> 16:19.160
variables, all it needs is to know the structure of the generative model and the variables that

16:19.160 --> 16:23.560
sit in that Markov blanket, or at least the neurons that are representing those other variables.

16:24.600 --> 16:28.440
And that tells us that we can then, when we're inverting that model, when we're performing

16:28.440 --> 16:35.080
inference, what I'm showing here is just one example of an inference scheme, we can, we can

16:35.080 --> 16:43.080
express the dynamics of that neuronal message passing in terms of connections from the other

16:43.080 --> 16:49.960
neural populations that are representing the variables in that Markov blanket. The details

16:49.960 --> 16:55.560
of this aren't that important, but this is one example of an inference scheme known as variational

16:55.560 --> 17:01.640
message passing, here formulated as a gradient scheme in terms of some dynamics, which has

17:01.640 --> 17:07.000
relevance for modeling neural populations, we're interested in how the dynamics of those

17:07.000 --> 17:13.000
populations evolve over time. And we can sort of do this recursively, we can couple together

17:13.000 --> 17:19.560
lots of different parts of this system, where the things that are being connected up are just the

17:19.560 --> 17:25.560
Markov blankets of different populations. Here I've expressed it in terms of an error term,

17:25.640 --> 17:33.000
this epsilon, which effectively represents the gradient of a free energy objective,

17:33.000 --> 17:37.720
which is used as an approximation to that marginal likelihood or evidence that I spoke

17:37.720 --> 17:43.800
about earlier. And then some beliefs about or expectations about that variable, so we can now

17:43.800 --> 17:49.400
use our, the errors in our predictions to update those variables. And once we've written down the

17:49.400 --> 17:54.440
dynamics of this sort of system, we can simulate things like firing rates, we can simulate the

17:54.440 --> 18:00.920
dynamics and the behavior of these networks of neurons passing messages between one another

18:01.720 --> 18:07.400
as a means of performing a form of inference and thus self evidencing.

18:10.280 --> 18:14.520
I know that this is probably still seemingly relatively abstract, but I think what will

18:14.520 --> 18:18.200
hopefully help is if we then go through some examples thinking about specific kinds of

18:18.200 --> 18:23.720
generative model and how that might then affect the kind of message passing we would see in a

18:23.720 --> 18:28.920
brain. And the first step to thinking about that I think is very important when we think about

18:28.920 --> 18:33.720
really useful generative models is they will all typically have a temporal aspect to them that

18:33.720 --> 18:39.320
as biological creatures we deal with things that evolve in time. And so it's worth thinking about

18:39.320 --> 18:43.240
how do you formulate a generative model that has that kind of dynamic aspect to it.

18:44.760 --> 18:50.280
And there are several different answers to that and one of them is we use something known as

18:50.360 --> 18:57.320
as a Taylor series approximation. So we start by saying okay at the current time what is the

18:58.520 --> 19:03.080
value of some variable x in the world and there's maybe some continuous variable it may be

19:03.080 --> 19:08.760
where my arm is in space. If we then want to know how it's going to evolve in time we could then say

19:08.760 --> 19:12.600
well let's take the next element of our Taylor series approximation that's taking out of its

19:12.600 --> 19:16.440
velocity and that tells us a little bit more about the trajectory that my arm might be on.

19:17.400 --> 19:22.920
We can then take another value which is the current acceleration of that position and we get

19:22.920 --> 19:29.160
a slightly better approximation to the trajectory. And the more terms we add in the greater approximation

19:29.160 --> 19:33.240
we have of the trajectory or the greater representation we have of the trajectory just as

19:33.240 --> 19:38.360
a series of numbers where those numbers are my current position my current velocity acceleration

19:38.360 --> 19:43.640
etc. So we could formulate a generative model by trying to predict each of these coefficients

19:43.720 --> 19:48.920
of this Taylor series or each of these generalized coordinates of motion as they're sometimes referred

19:48.920 --> 19:55.000
to. An alternative is we just say at time one where will I be at time two where will I be and

19:55.000 --> 20:02.920
we simply represent it in terms of the sequence of points over time. Often when we're discretizing

20:02.920 --> 20:07.720
time in this way we often we also discretize space so we might say okay where am I in some

20:07.800 --> 20:13.320
discretized scheme am I in location one two three four or five at each different time point

20:14.120 --> 20:20.680
and so we have two different ways of accounting for how things might evolve over time and each

20:20.680 --> 20:25.400
of these can be useful in slightly different circumstances. So if I were dealing with a

20:25.400 --> 20:31.160
sequential decision-making task it may be much more efficient for me to say okay at the first

20:31.160 --> 20:34.760
move I'm going to make is this then the second one is this the third one is this and dealing

20:34.760 --> 20:40.040
with something very sequential that might also be important in in sort of language processing

20:40.040 --> 20:43.880
where you have to think which words you're going to put together in a sequence and we're dealing

20:43.880 --> 20:50.040
with discrete variables over time because words are categorical instead of opposed to

20:50.040 --> 20:56.760
continuing as opposed to lying on a continuum. However if I were dealing with movement or

20:56.760 --> 21:02.120
the responses I'm getting from some photoreceptor in my retina it may be much more sensible for me

21:02.120 --> 21:07.400
to be working in continuous time thinking about how things evolve at a continuous scale.

21:08.840 --> 21:13.640
So what I'm showing here is an example of a generative model and the associated message

21:13.640 --> 21:19.720
passing scheme when formulated in terms of this continuous time scheme. So what we've got here

21:19.720 --> 21:27.400
is a factor graph at the top this blue element that uses exactly the same sort of formulation that

21:27.400 --> 21:35.640
we've been discussing so far so we have some variable here which might represent our position

21:35.640 --> 21:41.160
which then predicts our velocity at that time which then predicts the acceleration at that time.

21:41.160 --> 21:46.920
So we have a series of predictions here about the coupling between different orders of motion

21:47.720 --> 21:52.680
at each point those are predicting some sort of data here are wise which represents the

21:53.640 --> 21:58.040
the current position of our sensory data the current velocity the current acceleration.

21:58.840 --> 22:04.200
What I'm showing lower down here is the message passing scheme we get when we take account of

22:04.200 --> 22:10.040
the Markov blankets of each of these variables so the Markov blanket here for the the velocity

22:10.040 --> 22:14.440
would include the position and the acceleration but also the data I've got about those things

22:15.240 --> 22:21.400
and some prior beliefs about about other variables in our model and so we'd end up connecting those

22:21.480 --> 22:26.600
things up and although it looks like a bit of a mess of connections it's still fewer connections

22:26.600 --> 22:30.840
than the total number connections you would get if you match everything to everything else.

22:32.360 --> 22:36.760
What we've got here takes the form of effectively a predictive coding style scheme

22:36.760 --> 22:42.040
which people may be familiar with and the idea that that you can you can hierarchically predict

22:43.640 --> 22:48.200
predict some data and you can predict the thing that's predicting that data

22:48.200 --> 22:54.680
those data and by observing the errors in your prediction of the data you update your prediction

22:54.680 --> 23:00.680
which then cascades up a hierarchy allowing you to update subsequent predictions.

23:02.440 --> 23:07.960
What I'm showing you here is the equivalent model formulated in terms of discrete time and in this

23:07.960 --> 23:14.200
case discrete space as well so here we have a state at time t minus one which generates a

23:14.200 --> 23:19.320
state at time t which generates a state at time t plus one at each of those time points we're

23:19.320 --> 23:25.320
generating some observable outcomes which are represented as the o's with a variable pi here

23:25.320 --> 23:31.000
that represents alternative trajectories I could I could pursue so alternative policies or plans

23:31.000 --> 23:39.160
alternative ways I could change the sequence of events and again we have underneath the message

23:39.160 --> 23:45.800
passing scheme that could perform inferences about this sort of model and you can see that the

23:45.800 --> 23:52.600
message passing scheme to some extent looks like an inversion or or as loosely a sort of mirror

23:52.600 --> 23:57.560
image of the generative model because all it's doing is taking each step that was performed

23:57.560 --> 24:02.200
to generate some data and then inverting those steps one at a time so it's just going backwards

24:02.280 --> 24:10.280
from the data to arrive at the causes of those data. Now what I've got shown here on the left

24:11.240 --> 24:19.240
is just a sort of cartoon image of some of the key connections in in cortical micro circuits

24:19.240 --> 24:26.280
so here we've got superficial pyramidal cells as spiny stellate cells as SS deep pyramidal

24:26.280 --> 24:34.840
cells as DP and inhibitory engineer arms as the double eyes and this is clearly an oversimplification

24:34.840 --> 24:41.640
of what is a very complex connectivity structure but the reason I'm showing this here is that

24:42.440 --> 24:47.720
if we know something about this connectivity structure if we know about some of the key patterns

24:47.720 --> 24:52.360
we can start to ask how can the the sorts of models that we've spoken about over the last

24:52.360 --> 24:58.120
couple of slides then be interpreted in terms of the micro circuits that could help

24:59.800 --> 25:05.640
could help implement these in a biological system. So what I'm going to show in the middle

25:05.640 --> 25:13.240
is an example of a continuous states-based predictive coding style model that has all

25:13.240 --> 25:17.400
the same elements as in the slide I showed you before but are now mapped so that some of the

25:17.400 --> 25:24.280
connections coming in and out of it loosely map to those associated with a known cortical anatomy

25:25.880 --> 25:30.600
and we can do exactly the same thing here with the discrete states-based model and think about how

25:30.600 --> 25:36.440
we can assign those roles associated with the roles of different cortical layers

25:37.480 --> 25:43.560
and then use that as a way of forming hypotheses. Now what I'm showing you on this slide is not

25:43.880 --> 25:48.280
necessarily the last word on this and you could formulate several different hypotheses about how

25:48.280 --> 25:52.840
these two things map together and that's where a lot of interesting science happens. This is just

25:52.840 --> 25:58.680
one example of how we can associate what we know about cortical microcircuitry and anatomy

25:58.680 --> 26:03.320
with what we know about the anatomy of message passing for some simple generic forms of generative

26:03.320 --> 26:08.520
model. What I'm going to try and do over the rest of this presentation is to take the connections

26:08.600 --> 26:15.480
coming out of this out of each of these points and to try and think about how those might or the

26:15.480 --> 26:20.600
roles they might those might play when we take an active entrance approach and the sorts of structures

26:20.600 --> 26:27.720
in the brain that might be involved in dealing with those dealing with those things. I'm going to

26:27.720 --> 26:33.000
start by talking about movement and reflexes so here the kinds of things we're interested in

26:33.080 --> 26:39.560
are the connections that leave the cortex and go to areas like the spinal cord in the motor

26:39.560 --> 26:48.360
neurons, the predictions that we can then make about what we're seeing here in the central

26:48.360 --> 26:54.280
plot and the G that's been circled in red is a prediction about the sort of data I might expect

26:54.280 --> 26:59.240
to observe which may here be proprioceptive data consequent on particular sorts of action.

26:59.800 --> 27:05.160
And we can think of this quite simply if we think about the structure of a reflex arc.

27:06.200 --> 27:11.880
So what I've got here on the lower part is just the same marginal likelihood or model evidence

27:11.880 --> 27:17.000
that we've dealt with before this idea of it being a measure of the fit of the model both in

27:17.000 --> 27:24.280
terms of its accuracy, the accuracy with which it predicts some data and the simplest least complex

27:24.280 --> 27:29.640
version of the model that will work for that. What do we do when we change the data? Well we try and

27:29.640 --> 27:36.680
make the data more accurate in relation to our model by trying to align the data with our predictions.

27:37.400 --> 27:43.320
So when we think of the structure of a reflex arc where we can interpret it as some descending

27:43.320 --> 27:47.960
prediction coming from the motor cortex saying what is the proprioceptive data I expect to

27:47.960 --> 27:53.800
observe. By comparing that with the proprioceptive data that's actually coming into the spinal cord

27:53.800 --> 27:59.560
through the dorsal horn with that prediction we then get a potentially a mismatch between the two

27:59.560 --> 28:06.120
that can be used to generate action via the ventral horn generating movements and contractions and

28:06.120 --> 28:13.160
muscles that then try to fulfill these predictions. I'll show you just an example of a simulation of

28:15.000 --> 28:20.280
an arm using active inference that has these sort of reflex arcs built in and all we're doing here

28:20.280 --> 28:26.360
is we're just tapping on the biceps tendon where the red arrow is pointing and we're just seeing

28:26.360 --> 28:32.360
the reflexive response that we're getting as a consequence of effectively inducing this additional

28:32.360 --> 28:38.200
piece of sensory proprioceptive information by stretching that tendon. We induce the mismatch

28:38.200 --> 28:44.600
between the prediction that's coming down and the data that's coming out and that

28:45.400 --> 28:51.320
is corrected then by generating this additional movement. Interestingly we can do things by

28:51.320 --> 28:56.360
manipulating the confidence of those predictions and sometimes get things like bigger reflexes

28:56.360 --> 29:00.840
and hyperreflexia as the sort you might see in clinical populations with spinal cord injuries

29:02.360 --> 29:06.440
and so here you can see the reflex is slightly larger than it was before and slightly brisker.

29:08.360 --> 29:14.440
I'll show you another example of this same idea where now we've developed a mapping between

29:14.840 --> 29:21.160
the microcircuit and the anatomy of the ocular motor brainstem so here starting from the superior

29:21.160 --> 29:28.840
colliculus the the rostral interstitial nucleus of the medial longitudinal vesiculus and there is

29:28.840 --> 29:36.280
other centers and the cranial nerves that are responsible for generating eye movements so cranial

29:36.280 --> 29:45.560
nerve three and cranial nerve six here are seen here as resulting from these error terms so we're

29:45.560 --> 29:52.280
predicting how I would expect my eyes to move and any error in the current position of the eyes is

29:52.280 --> 29:58.280
corrected by generating eye movements so by inducing different priors on top of this model

29:58.280 --> 30:02.360
of different predictions about where I'd expect the eyes to be we can actually then generate

30:02.360 --> 30:09.480
different sorts of eye movements using predictive coding style active inference scheme where the key

30:09.480 --> 30:14.360
thing is that the predictions can be fulfilled by actually changing the positions of our muscles

30:14.360 --> 30:22.680
and positions of our eyes so that sort of provides a very brief overview and a couple of examples

30:23.640 --> 30:31.400
dealing with the role of reflexes and predictions in generating movements but it doesn't really

30:31.400 --> 30:36.280
tell us anything about how movements are chosen how movements are selected and you don't necessarily

30:36.280 --> 30:40.840
get any intelligent behavior out of that and for that we need to start looking at different sorts

30:40.840 --> 30:47.160
of structures and different parts of this generative model and here the key thing I want to focus on

30:47.160 --> 30:53.000
is the role of the basal ganglia and which here we're going to associate with the computation

30:53.000 --> 30:57.960
of something known as the expected free energy and I'll try and describe what that is a little bit

30:57.960 --> 31:05.880
more in some of the subsequent slides so what I'm showing here is a mapping of some of the

31:06.680 --> 31:11.880
subcortical but subcortical anatomy or more actually I should say that this is a mapping

31:11.880 --> 31:18.440
between parts of our Bayesian message passing scheme parts of the model inversion when we're

31:18.440 --> 31:26.680
dealing with the ability to plan and make decisions to some of the known subcortical anatomy of the

31:26.680 --> 31:34.200
brain and the key thing I want to focus on is this G that is depicted as part of the as part of

31:34.200 --> 31:40.760
the stride and so the things that are feeding into this are what we're getting from the cortex

31:40.760 --> 31:45.080
here which is some prediction of the outcomes we'd expect if I were to pursue a particular

31:45.080 --> 31:52.440
cause of action which is this subscript pi and the another sort of error term here which is how

31:52.440 --> 32:00.920
far away are those predictions from my preferences about how the world should be my prior beliefs

32:00.920 --> 32:09.960
about how the kind of data that I would actually actively seek out and act to get together those

32:09.960 --> 32:15.640
are used to calculate our expected free energy which we can then use to formulate beliefs about

32:15.640 --> 32:21.480
policies by saying that the policies we would select the plans we would engage in are those that

32:21.480 --> 32:28.440
we would expect to be associated with the lowest expected free energy and to put that more formally

32:29.560 --> 32:35.960
we're saying that we're going to give a prior belief that the policies the series of actions

32:35.960 --> 32:40.440
we're going to choose are going to be those associated with the maximum information gain

32:40.440 --> 32:47.800
tell us the most about the world around us that fulfill our preferences and then we're going to

32:47.800 --> 32:52.440
add in an additional term here which deals with habitual type policies and things that we tend to

32:52.440 --> 32:57.320
do because we've learned we behave in a particular way in those situations now the combination of

32:57.320 --> 33:02.760
this information gain and preferences are often referred to as an expected free energy and I won't

33:02.760 --> 33:08.360
go into the details here but that's simply because you can rearrange them mathematically to make them

33:08.360 --> 33:13.160
look very much like the equation for a free energy or or marginal likelihood approximation

33:14.120 --> 33:19.880
with an expectation around them to say that these are the what we would expect given

33:20.840 --> 33:25.080
our predictions about the data we would obtain because here we're dealing with beliefs about

33:25.080 --> 33:30.200
the future plans into the future where we haven't yet had those data and we need to deal with the

33:30.200 --> 33:34.360
expectations of what those data would be under different plans that we could choose

33:35.960 --> 33:42.040
and so here we're showing just an example of the direct pathway through the basal ganglia

33:42.040 --> 33:45.560
which is normally thought to facilitate movement and depends upon this expected free energy

33:46.280 --> 33:51.560
and an indirect pathway which here we've associated with these kinds of habitual drives and I'll

33:51.560 --> 33:55.080
come back to those a little bit later on when we deal with hierarchical models

33:56.600 --> 34:00.200
just to give you a little bit of intuition as to the information gain aspect of the expected

34:00.200 --> 34:05.640
free energy because I think most people most people probably understand this idea of seeking

34:06.360 --> 34:11.880
preferences and behaving to maximize some degree of reward but many people are less

34:11.880 --> 34:15.880
familiar with the idea of seeking information into the way that that might manifest in these

34:15.880 --> 34:23.880
kinds of models so as an example I'm going to show you just a simple simulation where we're

34:23.880 --> 34:28.520
going to manipulate some of the different aspects of the uncertainty in the model so here

34:28.760 --> 34:35.560
in the upper left I'm just showing a way of parameterizing the the uncertainty associated

34:35.560 --> 34:39.720
with the data generating process so this is our likelihood precision on sensory precision

34:40.520 --> 34:46.440
and it effectively says that when this precision is very high we can be very certain about the

34:46.440 --> 34:51.560
outcome we'll observe given a particular state of the world whereas when it's very low we could

34:51.560 --> 34:57.160
predict everything with very similar probability and we can do something very similar by manipulating

34:57.160 --> 35:01.320
the uncertainty in the dynamics of the world so again when this is very high it means that

35:01.320 --> 35:05.640
where I am now is very highly predictive of where I'll be at the next step in time

35:07.160 --> 35:11.960
whereas when it's very low it means that pretty much anything at the next time point is is equally

35:11.960 --> 35:17.960
probable and I'll show you a simple simulation where these two things are manipulated just to

35:17.960 --> 35:22.600
try and give you an intuition for what it means to act to to maximize one's information about the

35:22.600 --> 35:31.720
world so the upper simulation here top left shows four panels which can each change at some point

35:31.720 --> 35:40.760
in time to a different color with some random probabilities and the blue line here is designed

35:40.760 --> 35:46.840
to show effectively an eye tracking trace so it's a simulated agent who is allowed to choose which

35:46.840 --> 35:50.920
of these panels it wants to look at at any one time and you can see it samples them with a

35:50.920 --> 35:58.040
relatively even frequency in the middle panel what we've done is we've reduced the precision

35:58.040 --> 36:03.480
or increased the uncertainty associated with the likelihood in the lower left that effectively is

36:03.480 --> 36:08.760
like turning off the lights in that location it's effectively making that lower left location much more

36:08.760 --> 36:15.480
much less informative much more noisy and so effectively what what we've got here is a system

36:15.480 --> 36:20.680
that then ignores that it says that I can't get a good quality high quality information from there

36:20.680 --> 36:24.600
so I'm going to look at all of the other locations rather than rather than this in the lower left

36:29.400 --> 36:33.640
an analogy for this is if you're thinking about how you perform a scientific experiment you would

36:33.640 --> 36:38.760
probably aim to use if you had a choice between two different measuring instruments you would

36:38.760 --> 36:42.760
choose the one that gives you more precise measurements rather than the one that gives you

36:42.760 --> 36:50.840
very noisy measurements in the lower left we've manipulated the uncertainty or the volatility

36:50.840 --> 36:56.440
associated with the dynamics so here what's happened is the upper left location is associated

36:56.440 --> 37:01.640
with much more uncertain dynamics so here what happens is that I end up sampling that upper left

37:01.640 --> 37:08.200
location much more frequently and intuitively this makes a lot of sense because if you've looked

37:08.200 --> 37:12.760
somewhere very recently normally you will you'll know a lot about what was there you don't need to

37:12.760 --> 37:19.960
look back there anytime soon however if it's very volatile if it changes quite with some degree of

37:19.960 --> 37:25.160
randomness and you have very little certainty about the state of it after you've looked away

37:25.160 --> 37:29.240
you'll look back with a much greater frequency so we've effectively decreased the inhibition

37:29.240 --> 37:34.920
of return in this location by increasing its volatility or decreasing the precision associated

37:34.920 --> 37:40.840
with its with the dynamics in that location so the end of this was just to show you this sort

37:40.840 --> 37:46.280
of emergent behavior just by having an information seeking objective by by having a prior belief

37:46.280 --> 37:51.560
that we're going to act to minimize some expected free energy one component of which is to maximize

37:51.560 --> 37:59.480
our information about the world now the next thing I want to come on to is the role of hierarchical

37:59.480 --> 38:05.800
generative models and one of the key benefits of having a hierarchical model is that we can now deal

38:05.800 --> 38:10.920
with things that evolve over a range of different timescales so you might have some things that

38:10.920 --> 38:16.840
evolve very slowly and some things that evolve very quickly and to some extent we can separate

38:16.840 --> 38:26.280
out two and use slowly evolving things to to to help us predict what's happening at the faster level

38:26.280 --> 38:33.560
and here the key things to to note are all of these connections between higher cortical regions

38:33.560 --> 38:42.120
and lower cortical regions which manifests both in the in the discrete and continuous state space

38:42.120 --> 38:47.160
models and so it's worth them thinking about what the role of these are and how that manifests in

38:47.160 --> 38:51.720
terms of the generative models we've been dealing with before and it's really this that links back

38:51.720 --> 38:58.840
into the the idea of predictive coding as many people know it and you've probably seen graphics

38:58.840 --> 39:04.280
of this sort in the past where we have a range of cortical regions that are each making predictions

39:04.280 --> 39:08.920
about the others and so here going from going from the right to the left we've got a series of

39:08.920 --> 39:16.520
predictions in as these dark black lines with prediction errors passed back up using these

39:16.520 --> 39:22.520
these dashed lines that then allow us to correct at each level and all this this graphic shows

39:22.520 --> 39:28.920
is a simplification of the graphic on on the previous slide so i want to give you an intuition

39:28.920 --> 39:33.720
for why this is useful using a couple of examples so the first example i'm going to use is one from

39:33.720 --> 39:39.960
the domain of active vision so imagine imagine you're doing a task now where you have to fixate

39:39.960 --> 39:47.560
on this cross in the center and maintain that fixation and show you a stimulus but maintain

39:47.560 --> 39:52.840
fixation on the cross. Stimulus is going to disappear and then your next task is to perform

39:52.840 --> 39:58.120
an eye movement to the location where the stimulus appeared. It's a very simple task if the sort was

39:58.120 --> 40:04.600
used frequently in monkey electrophysiology and all throughout neuroscience but it's an interesting

40:04.600 --> 40:09.800
one because it has several different components to it that i think help in terms of thinking about

40:09.880 --> 40:16.920
the utility of hierarchical models so one aspect of this is making decisions about

40:16.920 --> 40:20.760
where you're looking at each of those time points and making inferences about which

40:20.760 --> 40:26.360
of several alternative locations you're going to perform an eye movement to so simple form of

40:26.360 --> 40:35.960
planning here so that calls into into action the sort of discrete state space model that we were

40:35.960 --> 40:41.720
dealing with before this this partial observable decision process this set of discrete sequential

40:41.720 --> 40:49.480
timing points and that's often very highly relevant structure of most simple tasks in cognitive

40:49.480 --> 40:56.600
neuroscience. However we also need to actually move our eyes we need to we need to move our eyes

40:56.600 --> 41:00.440
from one location to the next we need to know how to generate forces we need to know how to make

41:00.440 --> 41:05.800
sure the eyes come to rest in the right location given those decisions and that calls into play

41:06.040 --> 41:11.720
this sort of continuous state space predictive coding style model so how do we then how do we

41:11.720 --> 41:15.800
then combine the two how do we deal with the situation where we want to predict a particular

41:15.800 --> 41:22.840
location at a discrete level one of several alternatives but then also map that to a continuous

41:22.840 --> 41:29.320
motor trajectory and this is where generative models get a little bit more complicated so

41:29.320 --> 41:35.240
taking this a bit at a time what we've got at the top here is our mark-off decision process model

41:35.240 --> 41:40.920
this is our discrete state space model in discrete time now at each of those time points we're no

41:40.920 --> 41:47.560
longer predicting data specifically we're now predicting a short trajectory formulated in terms

41:47.560 --> 41:52.680
of our continuous state space models so at time one we're now going to predict a short element of

41:52.680 --> 41:57.320
our trajectory and this is very much like the sort of clustering model I showed you much earlier

41:57.320 --> 42:02.200
that you take a discrete point and you map it to a point in continuous space with some probability

42:02.440 --> 42:08.760
at the next time we then predict the next bit of that continuous trajectory so our priors for our

42:08.760 --> 42:14.360
continuous model are now inheriting from the predictions from the discrete state space model

42:14.360 --> 42:19.720
and then we can do the same thing again at the next time point and and so we can create a discrete

42:19.720 --> 42:25.880
sequence from our our sequential model and at each point in that sequence associate that with a

42:26.840 --> 42:34.120
short trajectory in continuous space that then predicts our continuous data allowing us to then

42:34.120 --> 42:37.960
predict the proprioceptive information we would expect to get from the eyes when we're performing

42:37.960 --> 42:45.080
a task at that sort and you can see that we now develop a hierarchical structure also in thinking

42:45.080 --> 42:49.880
about the relationship between the bits of the message passing scheme so here we've got the

42:49.880 --> 42:55.080
discrete bit of our message passing scheme our discrete microcircuit and a bit of the continuous

42:55.080 --> 42:59.800
microcircuit here and the interactions between the two of those were making predictions from the

42:59.800 --> 43:05.240
discrete one to the continuous one and then passing errors backwards to allow us to to update

43:05.880 --> 43:12.280
the discrete element so interpreting this again neurobiologically you can imagine

43:13.160 --> 43:17.400
that say we have some element of the cortex perhaps the frontal eye field that's making predictions

43:17.400 --> 43:23.720
about one of several alternative locations I could direct my gaze we can then map that

43:23.720 --> 43:29.720
via sort of output of the basal ganglia and the predictions about what policy I'm going to pursue

43:31.160 --> 43:36.680
through to areas like the superior colliculus which then might make use of predictive coding

43:36.680 --> 43:42.840
style networks of the sort depicted here to then generate eye movements as we've seen before

43:43.720 --> 43:48.040
and just to show you that in action we imagine that these are population of neurons that at

43:48.040 --> 43:53.080
each time point are trying to predict one of several in this case three different locations

43:53.080 --> 43:59.480
at four different time points we can then map that through structures like the superior colliculus

43:59.480 --> 44:05.480
and this is supposed to sort of cartoon the idea of a population code in the superior colliculus

44:05.480 --> 44:09.880
but then results in the eye movement to each of those discrete locations

44:11.560 --> 44:16.200
putting it all together we can then formulate exactly the task that I asked you to perform

44:16.200 --> 44:22.120
earlier and see the result of an active infant scheme performing that task

44:22.920 --> 44:28.760
and so here you can see it performs it very successfully by predicting sequences of eye

44:28.760 --> 44:36.440
movements that are conditioned upon the discrete part of the model and the idea of maintaining

44:36.440 --> 44:42.520
this belief about where the stimulus appeared and using that then to direct my policy selection

44:42.520 --> 44:50.440
and eventually the movement I select I want to give you one more example of this sort of hierarchical

44:50.440 --> 44:56.280
scheme in the domain of motor control and appeal to the same sort of simulations we were looking

44:56.280 --> 45:01.800
at earlier in terms of the reflexes exhibited by that arm the generative model we're going to use

45:01.800 --> 45:07.800
here is a slightly complicated one but here effectively involves transitions between different

45:07.800 --> 45:13.880
locations that an arm could be in or a hand could be in which then predicts different locations in

45:13.880 --> 45:21.720
some continuous space and different locations that a target might be in and that will then allow us

45:21.720 --> 45:29.000
to make predictions about about given where some target is in some continuous space which decision

45:29.000 --> 45:34.120
I'm going to make about the alternative points I could move my arm to and so here we have the

45:34.120 --> 45:39.560
simulation where we have the target appearing as the black ball out of the out of the three balls

45:39.560 --> 45:45.960
which is going to change at various points in time and our active infant scheme is now

45:45.960 --> 45:51.080
selecting these locations translating those into predictions of continuous trajectories

45:51.080 --> 45:56.440
and making the appropriate movements such that it reaches each of these target locations

45:56.440 --> 46:03.480
and what's shown in terms of the the graphic here is also an interpretation of the message

46:03.480 --> 46:08.760
passing in terms of the known anatomy of the motor system or part of it

46:11.000 --> 46:15.240
we can perform various lesions to this and see whether they behave in the same way that we might

46:15.240 --> 46:21.960
expect patient populations to so here we've induced a cerebellar lesion which effectively

46:22.760 --> 46:30.280
involves a misestimation of certain precision terms certain confidence or variance parameters

46:30.840 --> 46:36.280
and you see this sort of overshoot and this kind of oscillatory behavior in the way the arm behaves

46:37.160 --> 46:40.360
that mimics what we might expect him as cerebellar attacks here

46:42.360 --> 46:45.640
we can look at the higher levels of the model and actually have multiple

46:46.440 --> 46:50.600
hierarchical levels of the discrete scheme and here what we've done is we've induced a

46:51.560 --> 46:58.280
lesion in what might represent a frontal lobe lesion where now the model is able to perform

46:58.280 --> 47:03.240
all the movements with perfect fluency but every time there's a change of context it takes quite

47:03.240 --> 47:08.360
a while to adjust to that new context to deal with a new situation you'll see that instead of

47:09.160 --> 47:13.720
moving straight there as it was before there's a lot more hesitancy and a lot more difficulty

47:13.800 --> 47:20.120
constructing that long-term narrative because we've broken that slower hierarchical level

47:22.280 --> 47:27.480
and here a final lesion that we can introduce is one that reduces my confidence in policy

47:27.480 --> 47:32.520
selection so here this effectively makes me very uncertain about what I'm going to do next and

47:32.520 --> 47:38.040
here we get a sort of a kinetic type picture and sort we might expect in a Parkinsonian type syndrome

47:38.120 --> 47:47.960
so I realized that was quite a lot and I hope I'm not too far over time but I'll just try and

47:47.960 --> 47:54.600
summarize briefly the key ideas that we've discussed so the first was thinking about this

47:54.600 --> 47:59.080
idea of climbing probability gradients the idea that to maintain some form over time

48:00.040 --> 48:06.520
and to persist we need to effectively be climbing these probability gradients all the time

48:07.480 --> 48:12.440
we interpreted those probability gradients in terms of in terms of Bayes theorem and connected

48:12.440 --> 48:17.240
that to the Bayes in brain and the sort of message passing that might be involved in

48:18.120 --> 48:23.240
forming inferences about elements of some generative model and the role that might have

48:23.240 --> 48:31.880
in cortical micro-circuitry we also discussed the role of action and the idea that that one way to

48:31.960 --> 48:37.320
make our model better fit the world is to act upon it and one way to do that is to simply reduce

48:37.320 --> 48:43.960
any discrepancy between the predictions from that model and the data that's coming in and the

48:43.960 --> 48:51.160
structure of that is very similar to the idea of a reflex arc as is well known throughout

48:51.960 --> 48:59.800
motor neuroscience and the final thing we thought about was how we can then construct hierarchical

48:59.800 --> 49:07.640
models that allow us to produce simulations and theories that deal with much larger scale

49:07.640 --> 49:13.800
networks in the brain and take a full sort of systems level view of how particular movements

49:13.800 --> 49:20.920
and particular behaviors are generated through the inversion of particular forms of generative model

49:22.520 --> 49:28.920
with that I'd like to thank many people who've been involved either directly or indirectly in

49:28.920 --> 49:34.280
this work and I'll mention the book again which was mentioned at the beginning and a lot of this

49:34.280 --> 49:39.320
talk was loosely following some of the structure in a couple of the chapters in the book so if

49:39.320 --> 49:46.520
anybody's interested please do take a look I'm more than happy to answer any questions thank you for

49:46.520 --> 49:52.120
your attention

