Now, so I'm going to talk about EGI.
I've got long, I've got lots of slides, so I'll move very quickly.
Here's a report I wrote for Riley.
There's a company I started as an AI consulting company.
And so what are we going to talk about?
So the first question we have to ask, and I apologize if you've seen this talk before,
I had given it a few times, hopefully there's none in the room who has.
What is intelligence and then what physical systems are available for us to get inspiration from
and how far have we come in building the hardware.
And then I'm going to look at very briefly deep learning as, you know,
just ask very quickly the question, are we on the right track?
And then with deep learning, is that going to get us all the way to EGI?
The answer is no, spoiler.
And so what do we need, what's missing?
I'll do a very quick overview at the end.
And we'll look at one particular, one theory in particular called active inference.
And amongst a whole, you know, zoo of theories, really, EGI theories.
We'll pick that one out, I'll explain why.
And then I'll wrap it up with conclusions.
So, you know, why do we want to build it?
Well, it's kind of obvious, right?
We want to build it to solve the problem of the century, probably,
of the human race, maybe, arguably, so I might argue.
And then, you know, to make lots of money doing it, but really it's just to solve it.
And see, and then once we solve it, as DeepMind said, we can use it to solve everything else.
That includes all science or medicine, how to live longer, how to be alive,
new materials, you name it, you know, spacecraft, explore the galaxies, use your imagination.
So that really is the aim, right?
To build general level intelligence and quite quickly, you know,
move beyond that to superintelligence.
So, you know, a quick question I always ask the audience.
Are any of these general intelligence?
So we've got Watson there, Super Impressive, you know,
we've got the chess playing Deep Blue, IBM, Alpha Star, just very recently,
you know, DeepMind built that system that could beat some of the best players at Starcraft.
And online game and AlphaGo.
So, no, no matter how impressive all of these are, and they certainly were,
you know, years into making 10, 20, 30 years since the birth of AI, maybe,
they're not, they're nothing to do with AI.
So, and here's why, because intelligence is much broader than that.
Remember, we asked the question, what is intelligence?
Well, a guy called Howard Gardner at Harvard, I think in the 90s,
wrote down quite a nice way of categorizing it.
So you put it into nine categories.
So we've got naturalist understanding nature, the external world, can go do that, no.
You know, and I want to keep going, can go do that, can go do that.
The answer is no, no, no.
The spatial visualization.
So we have AI, you know, that can do maybe one of these really well,
but never more than two, right?
So we're nowhere near AI.
Intrapersonal introspection, you know, there's a TPU sitting in a Google Data Center.
No matter what algorithm you run on it, it doesn't go, why am I here?
Right, why am I a TPU who made me?
Right, no.
This is all part of intelligence.
Introspection, even though I make light of it, is, you know,
a very important aspect of intelligence.
Language, linguistics, we have NLP.
We can have things that read and classify sentences.
And, you know, are they created?
It's mostly based on statistical analysis of words and images and pixels and whatnot.
It's not quite how the brain does it, or the biological brain.
We have movement.
You know, the best assets in the world get paid, you know,
all players getting transferred for 100, 200 million pounds, right?
I mean, there's some of the highest-paid people in the world,
because they use their body so well.
The basketball players in America, the football players in Europe.
So that's a part of intelligence.
And, you know, we have robotics, right?
So there's nowhere, we haven't got any robots that can play football like Nestle,
or, you know, the Beth, Michael Jordan, and muscle balls.
They work very close.
Although, you know, impressive progress has been made with that.
You see it being backflips and whatnot.
Super impressive, right?
It's quite general, even that one small limit of sense.
Interpersonal, how we communicate with each other in the world.
Animals, ourselves.
Interpersonal, communications, modeling what the other person is thinking, right?
And then predicting what their next move will be.
Now, we know that.
It's essential.
That's the way we hear it.
And the logical mathematical path that we've kind of got.
I would argue, you know, fight with it, chess, and go,
and numerical stuff and calculate it.
It's a very simple calculator.
So we probably were okay in that quadrant.
And then musical and other creative art music, writing poems, just, you know,
but mostly musical, you know, writing would be linguistic.
So art, the creative fine arts.
Yeah, you know, AI, narrow AI has written some songs,
but, you know, use the word written very loosely.
You know, one could argue again, it's statistical, not creative.
So what are we missing?
So, you know, how far have we come?
Well, like, the highest is probably logical mathematical at 50%.
So calculation is great, but not creativity.
You know, they can't really invent new games of go or new types of math yet.
Okay.
You know, there's mathematicians in the world, the guys who gets the field there that we haven't,
they can't, you know, do math at the level of the field there,
that's sort of a Nobel Prize winner.
And linguistic is good as they are.
It's in creating stuff and complete sentence,
completion and, you know, sentiment analysis.
It's a statistical analysis.
It's not what we're doing.
It's not a creative thing.
And then I don't know how to read the list, right?
Spatial, we've got the span and body, you've got atlas.
You know, in understanding the environment, I thought 10%, that's a generous 10% music,
you know, Google, the Gentile, 50%.
These are all pretty generous numbers, I would say.
So basically, you know, we know we need a general intelligence.
We're not at 100%, but we can do all of these really well.
You know, we specialize in what we pick, what we put out and specialize,
but we can do them all.
So it takes a village to, you know, raise a child,
and it's going to take a village to create AGI.
So we're going to need computer science.
That's the one that everybody's got right now,
but also going to need physics, we're going to need neuroscience,
and we're going to need psychology.
We're going to need people from all walks of life,
because that word general means general, right?
It's everything.
And so let's move on now to the hardware.
You know, how far we've got with the hardware.
Then we'll look at the algorithms and we'll put it all together at the end.
So we basically look at, you know, we have an existence proof.
That's us.
You know, that's a three pound of wet flesh in ourselves.
That's what's creating this general intelligence,
unless you believe in something else.
But, you know, neuroscience, physics tells us that it's all we have.
So we need to get, we are getting inspiration.
Maybe not enough, actually, but this is where it's the first place.
You know, I would probably start looking at how nature builds intelligence,
or how nature hits built intelligence,
even though it's had a little bit of a hit start on us,
like four billion years.
You could argue the big bang, 13 billion years.
We've only been doing it for about 50.
But it's come up with this thing up here in our skulls,
that can come up with a general theory of relativity,
play chess, play go, drive a car, go shopping, raise children,
create mathematics, do this,
pay, you know, everything that civilization has done,
you know, there's a little three pound thing up here.
Given there's a lot of us, and, you know, we think we're on our own,
we don't collectively, we know we're near there, are we?
We're honest with ourselves.
So how does nature do it?
Well, you know, you start off with a single cell organism.
This is where the definition of intelligence gets a little bit tricky.
It's like, is that thing intelligent?
It's alive, it's living, it responds to its environment.
I would argue, yes, it stays alive, manages to stay alive
over billions of years even.
Maybe it's more intelligent than us in that respect, the way you see.
And it reproduces.
It doesn't come out, it can't come up with a general theory of relativity.
So in some sense, it has limited intelligence,
but it's still intelligent.
So, you know, what's that doing?
Can we reproduce that?
Let's start there.
That's the C. elegans worm.
It has 100, 302 neurons.
It has a central nervous system.
It's an organism with the simplest nervous system,
CNS, central nervous system, 302 neurons.
We can build that today.
We've got models of that.
So that's sort of where we are.
You know, we have 80 billion, 100 billion neurons.
We're at 300.
So we've got a little road to travel,
but if we can kind of understand how that thing works,
you know, maybe we can extrapolate and scale a little bit.
We can't give ourselves too hard of time.
In the last 10 years, we can model a C. elegans worm.
We have a bumblebee.
That's about a million neurons.
And they can navigate and do little dances
and tell the rest of the bee colony where the hunt,
where the polliners and come back and mate and stay alive.
They're super intelligent.
I would argue they're super intelligent, right?
They cannot come up with the general theory of relativity,
but they're still super smart.
We haven't got that far.
And then there's these things,
the wick mushy bit in our head,
three pounds in our skull.
And we know any of that, even though, you know, it's small, right?
I mean, we're trying to understand the universe,
the cosmos, the galaxy.
We're kind of, you know, doing a better job.
We can't even understand the tiny little thing.
I mean, just, it's not just.
It's very, very clever.
It's had billions of years to evolve.
So, you know, what are we missing?
What's the math?
What's the mathematical model to build something
that can model or come up with math
and model its environment into personal introspection?
How does that happen, right?
That's what we've got to figure out.
It's not it.
It's no small problem.
So, the first thing we notice from biology is it's hierarchical.
It starts off with molecules and neurons cells
and then networks of cells
and then sort of subsections of the brain
or integrated connected together wonderfully
to create a whole brain.
That's a connectome.
And, you know, there's a part doing math.
There's a part doing language.
There's a part doing emotion.
There's a part.
Is there a part that creates music?
Is there another part that drives a car?
Another part that, you know,
or is it all sort of integrated?
You know, so that's the kind of inspiration
we need to take from biology
and kind of use that to build mathematical models
and then actually build it in physical hardware.
Because Simon said,
we don't understand anything in this.
We can build it.
And I quite agree, right?
We can write down any mathematical stuff we like.
There's lots of models,
the public kits, all sorts of different models.
But until we build it,
we don't really understand.
We don't know if it tries.
It's just a few.
Okay.
And then, yeah,
certainly we have societies
which are kind of hierarchical.
We organize ourselves hierarchical in cities
and countries and nations, et cetera.
Right?
Okay.
So this is biology.
Super complicated, super complex, right?
You know, do we have to go down to that level of complexity?
Well, that's a good question.
Or can we just start at the cell in Europe?
That's a bit of an open question right now.
It's good to have open questions
about science.
That's what science is about, okay?
But then it sort of organized itself
into about two million of these cortical columns.
So the brain has some sort of sort of substructure there.
And it's quite common over the whole brain
in the neocortex.
Yeah, the math part, the seeing, the hearing.
So one part of our brain,
if we go blind or whatever through accident,
those cortical columns are used to analyze the sound.
So there's something very fundamental
going on there.
These are all clues.
From biology, there's a connectome,
and there's a central nervous system
that helps all connect together.
Maybe we don't need to build bodies.
You know, if you want robots, we do.
But if we just want something that thinks really well,
create series like Stephen Hawking.
I mean, you can parallelize it to get around.
But I'm just saying that we only need the rest of that
if we want to build a robot, okay?
We're really focused on the neocortex
a bit in the skull.
Okay, and then there's the societal limits.
So what have we built with hardware?
Okay, well, we've come a long way.
We're up to about 10 billion transistors,
and there's different types,
CPU, GPU, the Graphcore, IQ.
And there's different types of,
due to different data sets, basically.
So if you want to understand environmental data,
that's where we probably need something beyond the GPU.
The GPU is really good at matrix modification,
and the brain doesn't do matrix modification
to understand and create, right?
But deep learning does.
So we do need GPUs to that and CPUs.
But if we really need to go beyond
in a different sort of hardware architecture,
if we do want to have general intelligence.
Okay, so there's a little nostalgia here.
That's a cray, over 40 years ago,
160 megaflops, how quaint, you know,
we have teraflops in our pocket now.
So this is where we are today.
We have, you know, with Moore's Law,
we've had a factor of a million or so since then.
So we've got the i9 Intel CPU,
we've got the NVIDIA V100 Volta GPU,
we've got the Google TPU version 3,
which are absolutely pedaflops,
but just beyond the TPU,
coming online is the Graphcore IQ.
But really, these are all matrix multipliers.
So super impressive, you know,
we've got 100 pedaflops in a thing that, you know,
we've put on this stage,
which is somewhat what the brain does.
I think the brain does about a pedaflop or so.
So it's not about raw computation, right?
If it was, we would be there.
This thing would be coming up with theories
of relativity and all sorts of stuff.
We're trying to find physics and creating symphonies,
but it can't.
It's done as a brick, right?
Instead of that, that's exaflops, right?
That's a thousand times a pedaflop.
So we're going to need something more.
What are we missing in the hardware, right?
So it's not just about hardware.
It's actually about the hardware,
which is pretty obvious when you think about it,
because what's up here is a little different
than the hardware we've just seen.
What about neuromorphic computing?
So this is where things get interesting,
because now we're using analog circuits,
which is what the brain is.
The brain uses spiking neural networks,
which is almost a combination of analog and digital.
So there's a guy called Steve Berber,
one of the co-founders of ARM.
After 20 years, he left ARM
in the University of Manchester 20 years ago.
He set up a project called Spinnacle,
which is now being folded into the human brain project.
There's IBM True North.
There's brain scales at the human brain project.
There's various projects throughout the world
building this analog hardware.
So to me, I think this is a big part of it.
Albums are certainly important,
but I think the hardware is important as well.
So Spinnacle, we've got a billion neurons.
So a hundred times that, we've got the human brain.
So we've built a mouse brain already,
and it can do stuff like navigate through mazes
and play Sudoku and do crossword puzzles.
It does intelligent stuff,
and you know, some people have heard of that,
but it does not get depressed, does it?
Deep mind does.
Now, for go, everything else, it doesn't.
I argue that this is part of my thesis
that this is what will take us to general intelligence.
And there it is.
Five racks are up to 10 now.
There it is, sitting in a data center in Manchester,
part of the human brain project,
and that is neuromorphic computing.
There's a billion neurons here.
There's a mouse brain right there.
It's a little bigger than a mouse brain,
but we've seen with Moore's Law,
we're quite good at scaling, right?
So the point is, we've built some stuff here
which might be useful for us.
And that's how you scale up.
You put 1,000 neurons on a core.
You put 18 cores on a chip.
You send it away.
You get it built.
It comes back.
You put them together.
You put the chips on the board,
put boards in a rack,
and then you get 10 cabinets,
and you put quite racks in each cabinet.
You've got 50 servers, neuromorphic servers,
and you have a mouse brain.
That's how you do it, and it's been done.
That is the brain scale approach that I mentioned
at the human brain project.
That's about the same size as the spinnaker
and the same power,
got a mouse brain,
uses a slightly different architecture.
I won't go into the details.
True North IBM uses a slightly different architecture,
but the point is, you're all neuromorphic,
and you're all analog based on spiking your networks.
And that's sort of general intelligent mouse level
compared to the Google TPUs,
which are super impressive at different types of things.
I'd argue they won't get us a general intelligence
with the thing on the left side.
What about quantum?
I don't think the brain is quantum.
It's too warm and wet.
Quantum needs super cold temperatures.
It's decoherence very quickly.
I don't think there's qubits in the brain,
but they look nice.
I put a picture of one on there.
That's what a quantum circuit looks like.
Suddenly, we're not just about the CPUs anymore.
We've got these four different types of architectures.
One's biological.
One's quantum.
Or three are not biological.
We've got quantum.
We've got neuromorphic.
And we've got the digital.
And I'm arguing that the thing on the top right
will be needed.
The general intelligence is what they look like.
We've built them all.
The quantum bits are 7 bit IBM qubits.
They're 7 bit IBM processor.
Quantum processor.
There's a neuromorphic.
That's what they look like microscopically.
There's a digital.
I mentioned 10 billion on a chip.
And a processor with a CPU-PPU.
And that's how biology looks like.
So, you know, I think the neuromorphic in the biology,
the neuromorphic will map onto the biological
the best out of all of those options there.
Not to say the others aren't clear.
So, the data centers of the future.
They'll look like this.
We might just have them fill up with CPU-PPUs.
We'll have neuromorphics.
We'll have quantum.
And we'll have a little bit of classical as well.
Interesting time to head.
Deep learning.
Just going to have a couple of slides here.
There's this plethora of neural networks.
It won't get us there.
They've got very good classification and regression.
And pattern matching.
Very good.
This is all statistical analysis.
Very clever.
But nothing to do with what the brain is doing at all.
And so, this is a TensorFlow meetup.
So, I had to mention TensorFlow.
Here's how popular TensorFlow is.
So, if you're going to start on the deep learning,
you know, you need a quick pie talk to TensorFlow.
Okay.
So, that's that.
There we go.
So, what do we need?
How do we build AGI?
So, well, I would start as a physicist.
I would start with the laws of physics.
And we've come up with physics as an old subject,
about 400 years old.
Computer science is quite new, about 70 years old.
So, I will just go back and start with the laws of physics.
You know, what are the laws of physics?
Because the brain, I would argue, is a physical system.
So, probably that's the best place to start.
Don't just start writing a JavaScript.
No, start, you know, go back to basics.
This is what physics is.
And basically all the physics,
and maybe not too many people in the room know this,
can be written as a principle of least action.
S is the action, L is the function, blah, blah, blah.
You know, it's a great level of physics.
So, I know this stuff really well.
Build into me hundreds of exams and assignments, blah, blah, blah.
And there's been a book just recently called
Principles of Least Action, which surprised me.
So, it sort of has checked us on each section of physics
and how you can derive it from delta S equals zero.
So, I would start there if I was going to build
an intelligent system.
So, that's physics.
What else do we need?
So, intelligence isn't just about pattern action.
I've hope, you know, I've conveyed that already
in nine different types.
And one or two types is about pattern action, really.
It's about modeling the world, really.
That's what intelligence is.
It's how well we can model the world
and then make predictions and predict the next step.
That's how we make money.
That's how we stay alive.
You know, that's how we do everything.
That's what intelligence is, like, definition, really.
We can play chess and do all sorts of things,
but really chess is about understanding our environment,
modeling our environment,
the ability to model our environment,
then to make predictions and then to take action
from those predictions.
We need to understand, explain and understand what we see.
This is what we need to build.
We need to imagine things,
and we need to problem-solve and plan actions.
We need to build new models as we learn about the world.
Nothing to do with AlphaGo.
Nothing to do with AlphaStuff at all.
Okay.
I would argue they're super clever,
but they're statistical.
They're not really intelligent.
Okay.
So, what is intelligence?
Well, there's loads of theories.
I'm going to pick out actually,
but there's a ton of work,
and all of these people have been doing this work
for 30 years now.
There's Schmidt-Rieber,
Rooker,
Bialectic,
Princeton, Tishvie,
and Friston at UCL here.
Yeah, this is their life's work.
They're mad scientists twining away,
but sort of it's starting to happen for them.
So, they'll probably get to see a little bit of,
you know, the fruits of their labor.
Okay.
So, what is that,
the built-proofs that, when I picked up,
you're more than welcome to go home and Google all of these.
They're all got papers on archives.
They've all got wonderful websites,
loads and loads of beautiful,
really reading,
and interested in intelligence,
essentially,
and how we might get there.
And they all have useful input,
and we don't quite know which one is right,
maybe the combination is a few.
But this is what Friston's saying.
It's called active inference.
It's based on physics and information theory.
So, it's a very fundamental theory.
It uses something called the free energy principle,
and it does encompass all space and all time scales.
So, yeah, it works from the very small to the very large,
and it works from nanoseconds to the age of the universe.
It's completely general.
Yeah.
Now, I don't expect you, there is Sarah,
I don't expect you, you know,
to go, ah, I get it now,
because this is hard stuff,
and it takes a lot of reading.
It certainly took me an awful lot of time, actually,
to read through all of these different theories,
and just start at the basics of computer science.
You know, I said it took a village,
neuroscience, physics, psychology.
You know, I just learned a lot about a lot of things, right?
And we do.
This is why it's a hard problem,
unless it was so quick.
So, this is how he sort of puts it down, models it,
I guess, so the free energy principle.
You just divide the world into internal states,
which is our brain and outside the environment,
agent environment.
Anybody who's ever done reinforcement learning,
it's a similar sort of thing, right?
You have the agent and the environment,
but this kind of explains how the agent works itself.
What's going on inside the brain,
what's going on outside the brain,
it's separated by something called a Markov banquet,
which is kind of a cool-sounding name.
The guy called Julia Pulitzer,
University of Southern California,
came up with 18.
So, you know, there's this contribution from everywhere
into this theory.
And so it works from, like I say,
small to large, it works from cells to brains,
external states, internal states,
whether that's a cell, microscopic,
we saw the cell, I think that was intelligent to a brain.
The difference is the brain is much more complicated
than the cell.
So it's got none.
But that's a similar setup.
And so you can kind of, you know,
it all different scales, mice, people, bacteria.
Okay, there's the math.
The math gets ugly.
That's what it looks like.
But if you've ever read a reinforcement learning paper,
that's what that looks like as well.
So, you know, if you're a deep learning researcher,
the only difference is the physical one
that needs my entropy and things like that.
And the reinforcement learning needs to be
much more statistical.
But it's kind of similar looking,
probability distributions,
but this one's based on
fundamental physics and information theory.
Okay, don't expect you to take any of that.
And I just wanted to show off the math.
Yeah.
So, how to provide, look at that math,
but I didn't do it.
It's not mine.
Okay, so can we build it?
Well, yes, we can.
We have the theories, theories, theories, theories.
We have a few candidates.
We have the algorithm.
We even have software.
All of the professor has a big software base
that has been developed over the years.
We have the hardware.
I'm going to argue,
the neuromorphic hardware is there.
So, we run this on Spinnaker.
We should be good.
And we have data sets.
It's a thing called the internet.
We have all the data we need.
And so, I would say,
to some extent, we're kind of there.
We have the mouse screen.
And we have, you know,
the active inference running on it.
And I'd say we're kind of there.
We're kind of in the very early stages.
We're not millions of miles away,
many years away down the road.
We're sort of there.
We're on the road.
It's the neutral road.
I don't think there's anything missing.
There's no theory of missing.
There's no hardware missing.
There's no data missing.
And there's no, we have a theory.
That's a big statement, right?
So, I think we're there.
Okay.
So, what do we need?
We need hardware.
We've got a hardware.
We need a piece of clothing,
a general intelligence.
So, we need software engineers here in the room
who want to get started.
About building,
you'll be completely missed.
And, yeah,
it's the color project of our time.
I mean, you know, it's the one, right?
We've got a sort of intelligence.
We need sort of everything else.
There's many.
There's a huge,
there's a deep,
deep mind,
the brain,
the human brain project,
China,
just with this 10 million dollars,
sitting up a city,
the whole city,
EGI.
And should we build it?
I mean,
if ethics is safety,
but I'll leave that to another discussion.
Finishing off,
here's some EGI projects that are real.
They exist.
They have venture funding.
They have people.
They're working on it 24 seven every day.
That's their life.
That's what they do.
You know, I didn't put the mind up there.
Some of them are well known,
some not so well known.
Some are smaller,
some are bigger.
And so,
in conclusion,
it's obvious to most,
that deep learning is lacking the foundation,
to the general theory of intelligence.
It's based on statistics,
not physics.
Some groups are starting to look at
viable models.
And it frustrates me that they weren't starting
looking at them all along somewhere,
but a lot of this deep learning stuff
is just, you know,
it wasn't ever going to get us there.
And people, you know,
hopefully realize that now,
but I'm not that optimistic.
But I'm saying right now,
it's not going to get us there at all.
And is it?
Yeah.
I've already said,
we've sort of,
we've already,
we've already got it.
Not human level,
but mouse level.
And normal,
it might be a platform to get us there.
And I'll leave you with this,
parting words from Jeff Hinton
a bit.
Okay.
So what he was saying there
is basically what I think
the Godfather of AI
of deep learning from the 80s
and his whole life,
used to work with Princeton at UCL,
by the way,
went to Toronto in the end.
What he is saying is that deep learning
won't get us there.
It was never meant to.
I didn't make a mistake.
It's just,
I was working on something else.
What we do need,
what will get us there
is understanding the brain.
And he said,
this was in 2016.
He's saying,
I think that
we are very close to that moment.
And I've,
I've,
I've put up a few theories there,
which maybe he wasn't even aware of.
Maybe he was,
he was a smart guy,
but I believe we do understand the brain.
I believe we're there.
Thanks.
Great stuff,
round of applause.
Okay, good stuff.
So we're a little bit tight for time,
but I'm curious.
So you've done,
you've been a research fellow.
You've obviously been running
deep learning partnerships
for quite a while now.
Yeah.
What is your interest?
How come so much focus
we're interested in this?
And where do we find you online?
And what are your next,
what's your next project?
Yeah.
So I have started a company called
TuringAI.co.
Which was up there, right?
Yeah.
Yeah.
Maybe it would have been interesting.
It was one of the boxes up there.
Yeah, it was, actually.
One of the boxes.
Tell us about that.
Yeah.
Turing,
like it is now,
TuringAI.co.
Now,
I've actually started that company
with Professor Frisson
and a couple of very clever post-docs.
So we're working on this.
Schmidt Hooper's working on it.
Weilich at Princeton's working on it.
DeepMind are working on it.
So I'm not saying that
we're going to crack it first,
but yeah,
we're very involved in solving the problem.
Big respect.
Well, with you all the way,
we'll have you back on TensorFlow
once you solve that problem.
Yeah.
Okay, cool.
Next,
we've got time for two quick questions.
Anyone in the crowd?
Okay, gentlemen.
Introduce yourself.
Hi.
My name is Erdogan.
Yeah.
I help you.
The one you mentioned,
which is less publicity.
Given that 3.0
could be deep blue
within nine hours of learning,
why isn't there something similar
being done to promote it?
Yeah.
So, I mean,
I don't know,
really,
they're using reinforcement voting
and lack of,
you know,
Monte Carlo's
tree certifications.
Right.
So,
you know,
I don't know,
I don't know,
I don't know,
I don't know,
I don't know,
everything's been right.
So,
I'm not going to take anything
away from any of that work,
it's brilliant, right.
Remember,
calculator can out
calculators that modify two
large numbers together.
You know
there's no way
we're ever going to be
going against or go over again.
It's super clear.
But remember,
my nine types of intelligent
but can't do anything
as it may be.
I can't write a symphony.
We need a differential reversal
for that.
So,
you know,
how do we integrate them all
together?
Yeah, that's a pretty big problem actually, yeah, that's clear.
Any other questions?
Hi, my name is Nuki, I'm just wondering, what's the
number of neurons in the system?
Yeah, nothing like it, so that's a great point, so there's two
neurons, there's a number of neurons, but there's also the connectivity between the
neurons, so the biology seems to like to connect about a thousand to ten
thousand synapses per neuron, so if Spinnaker is nowhere near that, it might
have a few dozen, so that's a very important mention.
Connectivity is super important to you.
Can I start talking a little more? There's one over here.
Hi, my name is Marco, I work at the real startup called
Erypadet. My question is, you focus a lot on the CPU architecture, but obviously the charge
tool in the thesis says that any function that is computable can be executed by any
machine, whether it's a biologist, whether it's a CPU, whether it's a GPU, is it just the
execution speed that you care about, or do you see anything wrong with the charge
tool?
No, I do believe that's a great question, and there's been a lot of debate, even for
the last philosophical debate, about whether the brain is Turing complete, and I
think it is, and most people do as well, so it's a very fringe people who say there's
something else in the brain that's not Turing complete, so I don't believe there's
any bottleneck there at all, I just think it's a different type of computational system.
We're going to follow you, generally connect with any type of CPU.
Yeah, I still think we need the synaptic connections, like a thousand to ten thousand, so it really
is a deeply embedded hardware problem, but that hardware is Turing complete, so the general
theory of computation applies, but it's just a different hardware, that's a good question.
Okay, thank you.
