start	end	text
0	9360	Okay, so welcome everybody for tonight's talk. Today we have Ilaria and she was going to talk
9360	16640	about explainability with knowledge graphs. What have we learned? This is the talk series of the
16640	23680	cost action on distributed knowledge graphs. We've had a few talks already. You can watch them in our
23680	31040	YouTube channel and we also have a few talks coming up on January the 31st. We will have a
31040	38720	talk by Mayankerival on March the 4th. We will have a talk by Marc Neusen and on April the 17th
38720	48720	we have a talk by Peter Patelschneider. What is this cost action? It is a European research network
49520	54640	where more than 30 countries are represented. We run workshops, hackathons and short term
54640	63440	scientific missions for which also you can apply. This overall runs from 2020 to 2024.
64160	73920	So we have a few months still on the project and we are now in our final year. This is chaired by
73920	79520	myself. This cost action with Axel Polares as the vice chair. We have Michel Dumontier and
79520	88480	Renzi as working group leads next to Andreas Antoine Olaf. Then there is John as a scientific
88480	94000	representative of the grant holder Anastasia Dimou as the science communication manager
94000	102320	and Stefan Gostowicz as the grant coordinator. So much on the cost action. Today we have Ilaria
102400	111840	and I would like to hand over to Olaf to announce the speaker. Yes, hello and welcome from my side
111840	122160	as well. I'm very happy to have Ilaria as a speaker. She got her PhD from the Open University in the
122160	129680	UK and the title of the PhD was explaining data patterns using knowledge from the web of data
130560	136720	and for the PhD she received this distinguished dissertation award of the Semantic Web Science
136720	148720	Association of Swizzers. She got this award in 2017 and as you maybe know we run this talk series
148720	154080	with speakers who received either this dissertation award or they received the 10 years award of
154080	160400	Swizzers. So now Ilaria received this award in 2017. One year later she went to Amsterdam
160960	168640	to the Free University in Amsterdam where she became an assistant professor there that she still is.
170400	179040	She has been involved in several conferences. She is the editor-in-chief for the CEWS
179840	186000	workshop proceedings where many of us probably publish their proceedings of their workshops.
186000	190400	She's also in the steering committee at the moment of the Hybrid Human AI Conference
191200	197840	and her research, the focus of her research is on systems that combine semantic technologies,
197840	205120	open data, machine learning in order to generate complex narratives with applications mostly in
205120	211440	scientific scenarios and in robotics and if you look at kind of her most cited papers many of them
211440	219040	have the word explain or explaining explanation in their title. So I'm very happy to have her here
219040	225040	and kind of reflect on the work that she did in the PhD and what has happened since then with this
225040	234400	work. The floor is yours Ilaria. Thank you so much. Thank you for all of Tobias for the introduction.
235600	241520	Yeah I'm going to share my screen so my question was whether you are keeping the rights.
242240	249120	Can you just give me a sign that you can see that I think okay. Yeah great. So
252000	257760	good evening or good morning everybody. My name is Ilaria and I work at the Free University in
257760	266640	Amsterdam. I'm an assistant professor. I'm very very happy of giving this talk today. There was
266640	274640	really a nice opportunity for me to reflect on the overall research that I've been doing in
276640	283920	the past since I was a PhD student and of course it's about explanations which is a very hot topic
283920	290720	in these days and really my work and my background is on knowledge graphs so I've been working most
290720	295440	of my life on how to use knowledge graphs in the context of generating explanations
296080	306960	and that's what we are going to see a bit. So I just to all I've gave her a very good introduction
306960	312080	of myself as I said I'm an assistant professor and have read intelligence. My background is on
312080	318720	knowledge representation, knowledge graphs, knowledge graphs for explainable AI. These
318720	325360	days I'm mostly focusing on my use cases around hybrid intelligence. You will hear a bit more
325360	332400	later on knowledge representation driven robotics and also scientific assistance and scientific
332400	341360	discovery. There's more about me you can check on the on my website. This slide is actually wrong
341360	348240	so it's IWC 2017 that I missed the one when I was about to receive supposed to come on stage and
348240	356960	receive the SWSA dissertation award. I was actually driving to a very far plate so I had to miss the
356960	366560	conference but I was very happy of receiving the news nevertheless. So to give you an overview
366560	376720	of what this talk is going to be about I will be describing a bit what's the work during my PhD was
376720	385120	so as as you heard from all of the title of my thesis was on explaining data patterns using
385120	392400	knowledge from the web of data and then I also want to discuss a bit what has going on since
392400	400640	then so since 2017 2016-17 what how explanations have developed how our knowledge graphs have
400640	407280	developed and the overall area and also some and concluding with some future consideration
407280	417280	of where do we want to go and and and how can we go from here. Starting with about 10 years ago
417280	426960	a bit more it's always hard to realize it over 10 years now. I like to show these pictures
426960	432400	or map a bit the audience I am not sure I can actually see the chat but maybe somebody wants to
432400	438880	I like to ask the question on whether somebody knows this picture which it's quite famous used to
438880	442080	be quite famous I don't know whether somebody is familiar with that
446560	456800	and this might be how I don't really see the chat but that's okay. So this is a typical
458160	464640	knowledge discovery process as was firstly introduced around in the middle of the 90s
465120	473040	when knowledge discovery was one of the main scientific processes that
475600	484400	scientists were using computer science method 4 and the process was actually was
484400	491760	firstly introduced by Fayyad so you can look up the reference and it used to be described as
491760	499120	all the steps that scientists need to produce in order to go from data into knowledge
499120	505520	and these steps were mostly selection of the data processing of the data transformation
505520	515040	data mining that was what came before the current machine learning and deep learning method
515280	522720	and then interpretation of an evaluation of the patterns so every step in every step you do
522720	529920	you transform your data little by little first you identify the relevant information then you
529920	536320	preprocess your data you transform them into something that you give to a data mining algorithm
536320	542240	and then you come up with patterns that then need an interpretation and an evaluation in order to
542240	556080	become knowledge. Now what we focused on is mostly this interpretation process so the last step
556800	563280	the interpretation of the patterns was somehow the core of the scientific process was what would
563280	571840	allow to transform patterns into into knowledge so to give a meaning to these patterns this is
571920	579520	actually how interpretation is being defined somehow in the dictionary so it's really the
579520	588320	action of capturing the meaning and communicating conveying the meaning of something usually the
588320	597360	way you interpret patterns so the way you try to give a meaning to that to capture this meaning
597360	602960	is by using your own background knowledge so you come up with patterns you might have
603680	608640	your own background knowledge or maybe human experts in a topic that explain the patterns
608640	616480	that the data mining algorithm has come up with and that helps evaluating and interpreting this
616480	624800	knowledge the problem is this background knowledge might be missing so you might require maybe the
624800	632240	expert doesn't know the actual explanation or you might need in certain use cases you might need
632240	638560	different experts from different domains so gathering this background knowledge might be
638560	648720	quite a time consuming process in this case when this information is missing the kind of
648800	659040	hypothesis that we put forward was that symbolic AI so symbols or knowledge graphs or linked open
659040	666480	data as we used to call them at that time are another source of background knowledge so the
666480	677280	kind of idea that we had is okay if we have plenty of multiple of knowledge graph of data sources
677280	683600	that are multi-domain that are connected between each other so at that time we had the link data
683600	689440	cloud I think this is this picture is slightly later than 2013 but the idea is to have all these
689440	698000	connected data sets that point to each other and then you can continuously discover knowledge simply
698000	704320	by crawling data set one after the other this information is most of the time it's connected
704320	712320	it's centralized in hubs and observatories it's standardized according to certain vocabularies
712320	723040	that allow modeling data sharing data so the the vocabularies would allow to to to have inter
723040	730160	operability across application then the kind of idea was okay maybe we can use this all this
730160	738800	information which is available online to help us explaining the patterns that an algorithm gives us
739600	743760	whenever we don't have an expert in the picture or whenever we are missing the background knowledge
743760	754560	to explain that and and it is very similar to the idea that Newell and Simon already in the 70s had
755520	765280	so among the the faders in AI that symbols were one additional layer to to use when somebody
765280	772240	wants to capture and and and convey the meaning so you don't only need the data or the experience
772240	777920	but you need to put a structure and you need symbols on top of it in order to really get into
778880	787360	into an intelligent system that can understand and capture meaning so based on these hypotheses
787360	795680	we set up a number of research questions so the very first one we we looked into was okay if we
795680	801920	want to use uh if if we want to use knowledge graph large-scale knowledge graphs to to to
801920	807600	generate explanations um we kind of need to understand what do we mean by an explanation
807600	813040	so we need a definition even if it's a working definition we still need one and then we kind
813040	818560	of said okay we need a method that will allow us to to to generate explanations from knowledge
818560	828480	graphs so how how are we going to do that um then then assuming we come up with one such a method
828480	833280	we need to try to cope with all the problems that come with knowledge graph including
834000	843520	incompleteness, bias, noise um so so the the later research questions obviously some of the
843520	847840	research questions came out little by little throughout the process right so you look at your
847840	855440	phd from a different perspective but somehow the the later research questions were on improving
855440	859600	the methods that we had in order to cope with the limitations of knowledge graphs including
859600	868160	incompleteness and bias and basically uh looking now i'm going to go through the the research
868160	874240	questions but i don't want to dive too much into it i mean we have papers for that i'm just the next
874240	881360	slides are mostly to give you an idea of what the overall approach was uh starting with the the
881360	887840	definition of explanation we defined we first defined an ontology design pattern for explanation
887840	893360	so what we did was we looked into different disciplines we looked into philosophy we looked
893360	901600	into linguistics into social science and we looked into their definition of explanations and we
901600	907520	noticed that even though there were different approaches and methods explanations were always
907520	913200	seen according to the similar characteristics so there was always the generation of some
913200	918800	coherence between old knowledge and new knowledge uh the elements in the explanation were always the
918800	925520	same there was a theory there were an anterior and a posterior event there were sequences that
925520	933440	would make this event happening at the same time and there were always processes um
934400	940000	uh that would be one internal process where you come up with an explanation for yourself and then
940000	944640	one that is more an external process where you communicated the explanation to the rest of the
944640	953040	world and based on this we then defined our own uh ontology design ontology for an explanation so
953040	959120	our own definition that we could then feed into a system that would try to generate explanation
959200	964880	according to these patterns so we we then just it's a pattern in the sense that it can be
964880	972400	instantiated in multiple um in multiple contexts but the overall idea was that you always have an
972400	978160	event uh that happens before an event that happens after I'm not sure you see my pointer but I hope
978160	986240	so uh there are certain uh conditions that make this uh this event happening in a specific setting
986240	994080	and then there's some sort of uh theory behind and a sort and an agent that that that outputs the
994080	1004480	that creates the conceptualizes the uh the explanation uh based on um based on this pattern
1004480	1011040	we then try to to design a system that would try to use knowledge graph to generate explanation for
1011040	1017040	a given pattern of data and then the the kind of question we try to answer is really okay if we
1017040	1022560	want to use a knowledge graph a very large knowledge graph uh as background knowledge
1022560	1028880	which kind of process do I need to uh generate explanation and then we try to work with some
1028880	1036480	with some examples of patterns of data of things that people might want to to explain uh we had this
1036960	1043280	very good example that would work with uh google trends and then you try to explain why a certain
1043280	1050720	website uh is uh regularly happening at specific points in time so in these cases why people are
1050720	1056240	searching for the term a song in ice and fire only in certain periods so you see that there are very
1056240	1063760	regular peaks or maybe we try to explain data like statistical data for example from the UNESCO
1064320	1070080	uh in this case we have uh countries that are grouped according to the
1071040	1077600	female literacy rate and then you try to explain okay why is is it oops oops sorry uh why is it
1077600	1084960	happening that um that that certain countries have in common like a certain characteristic
1085600	1091840	and the very good thing is that uh we try to come up with a method that had us uh working
1091920	1098400	out these examples and it was basically it was based on three main steps one was an inductive
1098400	1103920	logic programming step where you try to compare positive and negative examples and you have some
1103920	1110320	background knowledge expressed in uh as as tripos as facts about these examples and then the goal
1110320	1115680	is to induce the hypothesis that mostly represents your positive examples which are the examples
1115680	1125600	you want to explain uh we used a knowledge graph search so we we try to uh uh search the the link
1125600	1132640	data graph uh in order to find a common path which would be expressed in terms of predicates
1133200	1139520	relationships uh leading to a specific entity in the graph so we call this path and then we
1139520	1146480	would consider any path that is uh common uh to all the positive examples as an explanation for the
1146480	1154080	group of positive example uh and then in order to to to improve the the the graph search we we
1154080	1163040	implemented a greedy uh links reversal strategy uh so we try to aim for uh the uh longer and longer
1163040	1170160	path you know um and explore the graph using simple http d referencing in order to avoid
1170160	1177440	computational costs it was 2013 we still had issues of computational costs and uh based on this
1177440	1182960	method we try to answer mostly two questions so first we said okay which kind of your uh
1182960	1189600	risks do we need to to drive a greedy search and identify the best explanation so we try
1189600	1195920	different strategies and then one of the main finding for us was that a measure so a strategy
1196480	1205920	based on entropy um would lead to a higher explanation in in in in less time so we simply
1205920	1214960	measured on what is the best accuracy of an explanation over time so this is um uh iteration
1214960	1221280	in searching the graph and we always ended up having the best uh an entropy based measure
1221280	1228560	as the one that would perform best and give us the best explanation uh these allowed us to to to
1228560	1235680	come up with uh explanation for the use cases i was showing before so uh why are women less
1235680	1240160	educated than men in certain countries and that's mostly when countries are least developed for
1240160	1248400	example uh so they have a quite a high human development index rank and uh or they are expressed
1248400	1256000	they are defined in dbpb as least developed countries um or we we had explanations like okay
1256000	1263840	people search for a song in ice and fire whenever there is an event that is somehow linked to a
1263840	1271120	game of thrones tv series so that's this is we consider these explanations but of course if you
1271120	1278320	look at the results you might notice things that are quite not right and uh in particular you look
1278320	1284480	at these kind of examples so uh it's true that if you have enough background knowledge about a song
1284480	1290960	in ice and fire which is actually a book uh and you know that there is a certain tv series related
1291600	1296560	that is based on this book you know that the explanation for people being particularly
1296560	1302720	interested in these uh is whenever the tv series is coming out so there is a new season coming out
1302720	1310320	but there's nothing that relates the tonga tonga uh to to to the book or basketball
1310320	1317360	competition to the book so the kind of questions we had to ask answer afterwards was really okay is
1317360	1324160	there something in linked data that can tell us that game of thrones is strongly related to a song
1324160	1329920	in ice and fire much more than basketball competitions or anything related to tonga so the
1329920	1336000	second part of the method was really focused on strengthening this knowledge based explanation
1336000	1343280	and we focused we used a genetic programming algorithm to try to learn um a function that
1343280	1350000	could detect the strong relationships between two graph entities that are quite distant in the graph
1350000	1355680	so we are not talking about two entities in in in the same graph but you have one entity that is
1355680	1362320	connected to another entity through hops in multiple graphs in multiple data sets and then we really
1362320	1368000	want to try to understand what is the the strongest relationship and what we did is that with a genetic
1368000	1376080	programming algorithm we try to learn a function that could study the topological and semantic
1376080	1382720	characteristics of the knowledge graph so we really looked into how many hubs and how many
1385520	1390320	how strongly connected was the graph for example which kind of vocabulary the graph was was using
1391600	1396400	all these we gave all these to our genetic programming algorithm and then we tried to
1396400	1403040	come up with a with a function that would tell us okay this is a strong relationship and we evaluated
1403040	1410800	that with against a human evaluated relationship path and um actually what what came out from
1410800	1418160	from this study was that the best thing for us would have been to try to follow uh notes that
1418160	1423840	would have quite rich descriptions so here you have different examples of different functions
1423840	1430960	that we tried and then here you have the say the best performing ones um and the the the best
1430960	1438240	functions that we could find were really the ones were focusing on uh following notes with
1438240	1445040	rich descriptions that they would have quite a good number of namespaces uh it was best to follow
1445040	1450880	more specific entities so really not not not hubs with many incoming links but rather something
1450880	1458320	that is more specific and also we look into scores the scores vocabulary and uh it was best to have
1458320	1464160	fewer topical categories so not something quite generic in some in terms of topic but but rather
1466080	1475760	again a bit more specificity uh of course we had to look into into into into into into the bias
1475760	1482960	in the data as well so the the results were not optimal and as I said we needed to deal both with
1482960	1490800	incompleteness of the data but also when inner bias of the data and what we tried to do was to um
1491680	1497440	use identity links so remember that we are still we were still we are still talking about link data
1497440	1504080	where data sets are connected to each other through identity links including same as and what we uh
1504720	1514720	tried to do was to um measure the bias in a given data set uh by uh comparing the projection on one
1514720	1520000	data set into another one so the overall idea was really that you have a data set which could be
1520000	1525840	I don't know the link movie database and you have a certain amount of entities that are connected
1525920	1535600	through the dbpdia uh using identity links and the projection of the the movie database is mostly
1535600	1542080	the set of entities that's in dbpdia that are connected to to to the movie database and then
1542080	1550560	we we would basically compare all the entities in the larger data set with the subset and using
1550560	1558400	some correlation uh tests or some t-test and by comparing the distribution of uh property value
1558400	1566320	pairs uh between the subset of the entities and the large set uh we try to identify with uh which
1566320	1575360	were the the the the the bias in a given data set uh so for example we uh and yeah I would
1575920	1583120	uh send uh I would recommend you to refer to the paper but what we what we discovered was
1583120	1589680	for example that the link movie database was particularly focused on black and white movies and
1591600	1598560	that certain digital humanities data sets were focused on uh uh poets and novelists from the
1598560	1606720	18th and 19th century so it was a way to try to measure the bias in the in the in the data
1606720	1613840	set that we were using to generate explanations and to once we learned these bias we could also try to
1617440	1624000	somehow input this information in our system and generate better explanations
1624880	1633680	now this was uh uh quite a long a long journey that uh ended up in 2016 and there's a number of
1633680	1642240	things that happened uh since then what I what I'm I call the the present um so I don't have
1642240	1648080	enough time to focus on everything but I choose three particular uh aspects that I'm going to to
1648080	1657280	show which help us also thinking a bit further uh into the steps that we want to uh to take afterwards
1658000	1664480	the very first thing of course is the rise of deep learning so when uh when uh we started the
1664480	1668640	the work on explanations and knowledge graphs actually on knowledge graphs for explanations
1669600	1675200	deep learning was just was probably just booming and I wasn't even aware of that so what we were
1675200	1682240	talking about was uh using knowledge graphs to um generate explanation for outputs of any
1682240	1688640	machine learning algorithm uh but we've never heard of deep learning I think that yeah maybe the the
1689360	1697040	the the first papers are around 2012 but if I'm not mistaken but um of course the the hype came
1697040	1707520	much later and um uh the the the DARPA uh so so deep learning and all the methods behind we
1707520	1712960	that came with deep learning showed uh impressive results that could achieve uh
1715120	1720960	the same results as human would and uh but but also showed a number of limitations so the
1721600	1728640	uh the the the facts like the Cambridge Analytica scandals or the the loan accreditation scandals
1729680	1736400	show that these systems were uh were not able to to show a clear reasoning so the reasoning was
1736400	1742160	quite opaque uh these systems were data hungry so you needed a lot of data to train them they were
1742160	1748880	too brittle in this sense and then DARPA came out with this explainable AI program that was 2017
1749280	1757840	if not if I'm not mistaken um on okay let's try to implement create systems where the user is
1757840	1764800	that are transparent that can explain the machine learning model and then where uh an explanation
1764800	1770880	can be given on why a certain output is being given uh so this need of explaining the models
1770880	1776880	and the results really came out and you start we started seeing methods like SHOP and LIME which
1776880	1782320	are probably the most basic ones and then there's there's a number of other systems that came out
1782320	1788640	afterwards uh that could tell you okay the the most important features to come up with an explanation
1789680	1799440	and more in your data set are uh like maybe the race or the occupation of of of of your data
1800160	1806320	or we started seeing saliency maps okay with with imagery recognition uh what are the most
1806400	1816080	important parts that that system focuses on when generating explanations uh this especially the
1816080	1822880	explanations in in in the explainable AI area and if you look into the major AI conference you
1822880	1829920	start seeing a boom of uh I think explainable AI became an actual topic or a subfield in in AI
1830560	1836800	uh one of the questions that people asked was okay uh are these explanations that SHOP and LIME
1836800	1843840	come up with are they really working especially in a real-world context so they do work in in a
1843840	1850560	small use case but what if I applied into into a real-world context uh and somehow the narrow
1850560	1857840	symbolic field uh which was already in in the meantime in developing on on his own came up a
1857840	1865600	bit in the rescue of this problem so somehow we started seeing methods that try to combine
1866160	1873360	a symbolic approach so symbolic reasoning uh with neural network either to uh maybe improve
1873360	1880560	the explainability and trust of a system using a symbolic description uh or by creating a sort
1880560	1885840	of hybrid interaction between the the neural network and and the reasoning system uh so these
1885840	1891600	are just two of the many examples that you could could see when uh where the knowledge graph would
1891600	1897440	try to jump in into the explainable AI word and say okay hey look we should be maybe using
1897440	1905520	knowledge graphs and ontologies to help uh we also did a part of this uh so what what we try to do um
1905520	1913040	and um uh this this I completely forgot the the uh this the reference to this work but
1913040	1920400	if we published in 2021 uh we really try to say okay if everybody if many people are looking into
1920400	1929440	using knowledge graphs as a as a tool to explain um machine learning methods let's try to look at
1929440	1936160	what's the state of the art so uh how are people in machine learning using knowledge graphs what are
1936160	1942720	the the most important characteristics so we try to look into different uh tasks and different areas
1943200	1947680	and uh we try to look into the characteristics of the knowledge graphs the characteristics of
1947680	1952960	the model and the characteristics of the explanations that we were being generating uh
1952960	1958000	in order to come up with really with a with a picture of the field uh and this this is more
1958000	1965120	or less what we came up with so uh we we learned certain things like if you are dealing with tasks
1965120	1970560	for recognition and recommendation uh most of the explanation you will get are really about the
1970560	1976960	model and how it behaves and most of the information that is being used uh from the knowledge graph is
1976960	1985520	the is the a is the aversion box uh and whenever uh we deal with tasks that involve the interaction
1985520	1991200	of the user like conversational agents or recommender systems the knowledge graph information is
1991200	1997680	used to is used more into the training of the model uh to generate a certain explanation
1997760	2004720	rather than as a postdoc stack uh we looked into the different types of knowledge graphs whether
2004720	2010800	they were factual or common sense or domain knowledge graphs domain specific and it turns
2010800	2015760	out that common sense knowledge graphs they're not that many but they were being used for image
2015760	2021440	recognition and question answering uh we also look into the reuse of knowledge graphs so we've been
2021520	2027920	uh talking so much in our field about reusing knowledge graph reusing ontology ontologies and
2027920	2032640	we kind of ask okay is this being applied in this field and it actually turned out it was
2032640	2037920	quite an established practice so very few were coming up with their own knowledge graph uh most
2037920	2046320	of the the methods were were using uh dbpdia uh wikidata um consonants or a combination of them
2046880	2053680	um actually we looked into uh whether these methods were using only one knowledge graph
2053680	2060160	or multiple ones and we we were hoping to to see a bit more but it does happen sometimes in
2060160	2066960	nlp tasks and really the kind of this is the kind of picture that came out so if you if certain
2066960	2072240	areas are more focused on on model embedded knowledge so explaining the model rather than
2072240	2079760	explaining the outputs certain others are more focused on using the ontologies of the
2079760	2086640	knowledge graph rather than the facts um and um and so on and so forth so I think the analysis we
2086640	2093920	did it's around 60 60 papers more or less um and we kind of try to identify also the challenges
2093920	2100480	for the field right so there are things that were we were hoping to see but that didn't happen
2100560	2105040	including the what we call the co-creation of explanations so really having a sort
2107440	2112560	the human having a role into the generation of the explanation there are there were there are
2112560	2118400	issues related to the maintenance of the knowledge graph so how to deal with uh
2118960	2125760	missing information or bias when coming up when generating explanations and of course this is a
2125760	2131760	problem that we also saw during in the in the phd and also there are issues related to the
2131760	2137520	automated extraction of relevant knowledge when using a knowledge graph that generates explanations
2137520	2144560	so most of the methods that we analyzed when coming up with an explanation end up manually
2144560	2150480	selecting uh the relevant relevant relevant information to generate an explanation and
2150480	2154640	this is quite something it means that there's still a lot to do in the in the field in order to
2155520	2166000	um uh to move forward um there's uh so this was one part of the story so what happened
2166000	2171440	ever since deep learning uh there's also the field of hybrid intelligence that came up so
2171440	2177280	I don't know if many of you heard about uh hybrid intelligence maybe you had about human
2177280	2183600	centric ai this is another way of addressing this this problem uh the overall idea was that
2184960	2190320	this there is an emerging field in ai which uh and it's emerging because you start seeing
2190320	2196720	different conferences and workshops uh around the topic there's a number of uh national and
2196720	2205360	international um collaboration networks uh that uh that are really focusing on uh on this concept
2205360	2211040	of hybrid intelligence and and the overall idea because we don't really have a proper definition
2211040	2218960	but we do have a working definition of hybrid intelligence is to have uh to to aim for ai systems
2218960	2226400	that try to enhance human capabilities as other scientific tools would do think of the telescope
2226400	2235760	that allows a scientist to um to look uh where his own eyes cannot see or the machine the the
2235760	2241440	the sorry the the card that or the the airplane would allow people to to to reach places that
2241440	2248400	they couldn't reach easily with their with their feet um so it's really about seeing ai system as
2248400	2255840	an extension of the human intelligence rather than seeing ai as a tool that replaces us so in
2255840	2264320	this sense hybrid intelligence really look into uh systems that collaborate uh with humans uh aiming
2264320	2271200	for a complementarity so weak weaknesses and strengths of both ai and humans are complemented
2271200	2280000	by each other uh and really about this synergetic idea so the the the mixed team the hybrid team
2280000	2290800	is is aiming for the same has a shared goal um this is um the so so we have a research agenda
2290800	2295360	I'm part of the Dutch hybrid intelligence consortium and I've been part of the hybrid
2295360	2302400	intelligence conference of the past uh in the past years um and it's a really vibrant uh field
2302960	2310720	um and and explainability explaining um it's also a part of the research agenda so
2310720	2315520	it's not only about trying to collaborate but how in in this in this collaboration
2315520	2322640	the goal is is also to try to communicate our own intention and explain our own actions and
2322640	2332720	our own reasoning uh so the one of the the core topics that we established when when
2332720	2337840	hybrid intelligence came into the picture was really on on on how to create systems that are
2337840	2346640	able to deliberate and and explain to to their collaborators um I'm more than happy to to discuss
2346640	2353840	this a bit further uh and somehow in as part of the hybrid intelligence picture we also uh
2353840	2359120	and as part of the the the contribution that we could give with ontologies and knowledge
2359120	2366960	across with respect to explainability we also try to um work on on on on a number of what we
2366960	2372400	call boxologies or terminologies for hybrid intelligence where so to establish mostly to
2372400	2379760	establish a shared language between uh agents in a different team um sorry agents in the same
2379760	2386800	team that would collaborate between each other um and uh what what we did in one of the the the
2388000	2392880	the newest work was really on comparing different hybrid intelligence scenarios
2393920	2399920	and first trying to identify what are the common uh knowledge roles so we came up with a high level
2400000	2408000	ontologies of agents interaction types uh and and and specific scenarios and and we try to also
2408000	2415360	identify um uh using these high level ontologies what were the the most specific hybrid intelligent
2415360	2425120	tasks uh including ones that would uh relate to creativity and and explainability uh and then
2425120	2431440	on the side of it we would have uh tasks like team awareness and multimodality uh that's the
2431440	2437600	second part of the picture so we talk about uh deep learning we talk about uh hybrid intelligence
2438800	2446320	and what also came into play with respect to to explanation and uh we didn't have that much
2446320	2452080	time to to dive into it but hybrid intelligence is strongly related to that as well is really on
2452080	2458640	especially with a with a european perspective is really on the gdpr and uh so um and an eu
2459600	2467360	ai act which recently came up uh but really the idea is to try to monitor the systems that we are
2467360	2475600	developing uh to make sure that that that uh users are are protected both in terms in terms of the
2475600	2481520	data that are being generated and the methods that are being generated uh and these also
2481520	2490960	means to be able to to to explain um uh the reasoning and to trace back the the the information
2490960	2500800	that is being output uh so so explainability and transparency became um started uh appearing
2500800	2506080	together in the in the picture so if you want transparency you need to be explainable therefore
2506080	2514960	showing your reasoning um and now with this eu ai act the the idea is really that that there are
2514960	2522000	certain obligations there are certain systems that need to show um uh some transparent they have
2522000	2528800	transparency obligations so they need to uh be able to explain why certain things are are happening
2528880	2540080	um otherwise they are considered uh unacceptable uh this is a very uh so i have a few minutes left
2540080	2548160	i think this is a very uh quick overview of what has happened ever since uh which leads us back to
2548160	2554240	okay what is going to happen now and how can we kind of think of everything that has happened so far
2554880	2561680	and and where are we going to to go uh of course i couldn't get away without mentioning language
2561680	2570160	models at least once so somehow one of the questions and one might ask and we also kind of wondered uh
2570160	2576640	was uh okay but everything we've done could this be now done so the the overall knowledge
2576800	2582560	process could just be replaced by language models and by large language models by LLMs
2583280	2588640	could we just not replace all the steps or the explainability steps do we actually need
2588640	2596720	knowledge grasp for that and it's true that um LLMs language and language models are very good
2596720	2602160	in dealing with noise and inconsistency and like methods that the methods that we had before were
2602160	2607920	not that much able they allow us to extract information very quickly from large structure
2607920	2615360	data so that goes towards the dream of doing a web-scale learning um or one could argue that
2615360	2621840	you already achieved that uh they're actually quite good in capturing some complex semantics so
2621840	2629360	somehow it has been demonstrated that defining a class can can be uh uh with specific boundaries
2629360	2633040	so the boundaries of the definition of a class is quite difficult are quite hard
2634880	2644560	so there is no universal class description and and it the especially with the embeddings method
2644560	2651600	based methods are able to capture this this this complexity quite a bit better and of course
2651600	2656800	are very good in generating natural language so instead of generating explanation in a
2656880	2663840	mechanic mechanical mechanistic way from from from the triples uh they are able to generate a much
2663840	2670880	more human friendly um explanation the problem is that there are still limited in a number of things
2670880	2677120	so learning from rare and unique events especially like the ones that that that you can find in the
2677120	2686480	web is still quite difficult um if this these methods are not yet able to show proper reasoning
2686480	2694160	and argumenting behind thoroughly creating a thorough argumentation uh behind what has happened
2694160	2700640	and also they don't really deal with with with fairness and interoperability acceptability all
2700640	2709920	these this fair aspects that we've been looking into as as knowledge graph community are not yet
2709920	2714880	part of the picture in a language model so somehow there are limitations in using that
2714880	2720000	but it doesn't mean that we need to discard them completely but we can just join the the
2720000	2725760	both words and and work out something to for to generate better better explanations
2726720	2735040	so i want to conclude in the last few minutes to really think okay if we now look at knowledge
2735040	2743280	graphs and whether they're useful uh to to generate explanation and do they actually work
2744000	2750240	what is it that we launch so uh somehow both based on the phc and everything that happens
2750240	2756640	afterwards uh yes we can use knowledge graphs but they are mostly an intermediate representation
2756640	2762320	so knowledge graphs are really for the machine consumption uh they shouldn't be for human consumption
2762960	2771920	and the rdf is just a language that that for machines to perform an exchange of information
2772000	2777920	which is unambiguous so uh we should really not look into knowledge graph as something that we human
2777920	2785600	should understand but but more as something a machine can can quickly exchange um we can use
2785600	2792880	knowledge graphs to as to get together content to generate explanation but really the graph
2792880	2799440	structure is just a backbone so we don't really want to use the knowledge graph to create an output
2799440	2807360	we can use language models for that uh but but we can use knowledge graph as to to to gather the
2807360	2813520	backbone of the explanation which can then be output according to different users in a different
2813520	2821520	dimension so we think okay an expert user might need a longer explanation uh which with more
2821520	2829040	arguments and an expert a non-expert and layman might need a much shorter and simpler explanation
2830080	2835280	in terms and llms are great in doing that you can ask them to rephrase a certain concept in
2835280	2841760	different uh in different according to different dimensions um also knowledge graphs allow allow
2841760	2849040	to check the to trace back information so you can really walk down the graph and and and check
2849040	2855440	whether the information is truth and this is quite uh this is much better than looking into
2855440	2861360	the propagation of an error the activation of a neural network and try to decode what does it mean
2861360	2867040	um in order to come up with an explanation that you might not be able to to to explain
2868800	2876000	that clearly yourself and finally scalability which was part of the picture at that time okay
2876000	2882240	how can we deal with very large knowledge graphs and uh uh we want to to to integrate as much
2882240	2887920	knowledge as possible well actually this is not that relevant anymore and what people are really
2887920	2895440	aiming for and we also saw this when collaborating with industry is more it's much better to have
2896160	2902480	a high quality knowledge graph which is curated by the expert uh to generate explanations rather
2902480	2909680	than having a very large knowledge graph um so this is one part of the story and then the other part
2909680	2915200	is more of the big picture uh what we learned is really explainability is not only about machine
2915200	2920800	learning uh so in hybrid intelligence we deal with explainability we deal with experts from
2920800	2927280	all kind of fields from social science to computer science and um people look into
2927360	2934240	explainability from from this in different ways so it's a bit of a jungle of terminology we cannot
2934240	2941200	really agree what uh what we mean by something being explainable and then we need to try to find
2941200	2949680	a way to harmonize that um we we learned that explanations are really task dependent so yes
2949680	2954720	we have an ontology design patterns for the explanation but we need to adapt this according
2954720	2961680	to the context and again we can use language models for that but it's um the the target audience or the
2962480	2967360	the language or the the type of explanation really need to change according to the situation
2968000	2974480	and more importantly we need to look for the human so knowledge graphs are only one part in the
2974480	2980560	explanation process so in order to generate explanation you need a knowledge graph you need
2980560	2985520	a sub symbolic method but you also need a human that interacts with the with the system
2986560	2990640	because in the end as we said at the beginning explanation is a social process it's a dual
2990640	2997760	process so it has to happen in a in a in a co-creation setting where the user is really
2997760	3003360	interacting with the system to come up with an explanation is satisfied with and in this sense
3003360	3010240	we also need interdisciplinarity in the picture to try to measure whether an explanation is is
3010320	3015680	interesting or not so we kind of we don't only need a computer science perspective but we also
3015680	3021760	need to try to integrate the talks that we have with social scientists and cognitive uh scientists
3021760	3028880	to make sure that the explanations that are being generated are actually useful uh so to give some
3028880	3035680	ideas on what and uh then i'm i'm just done i know i'm over a bit um uh what we suggest is that
3035680	3041120	really we should look into the kind of knowledge in artificial intelligence so some people have called
3041120	3046000	this knowledge science some people have called it empirical semantics we call it knowledge in AI
3047120	3052720	so we really need to go back to the empirical analysis of the knowledge graphs that we create
3052720	3058400	and we deal with we need to understand their modeling style and the kind of semantics they're
3058400	3063840	communicating and whether the semantics is enough or too much to generate explanations
3063840	3067600	we need to check for the usefulness and limitation of the knowledge graph that
3067600	3074160	and the knowledge that that we create and somehow we need to try to move from the step of okay how
3074160	3081200	can we fit knowledge into the learning process these we know how to do it uh or at least we have
3081200	3087520	good methods but we really need to focus on what is which kind of knowledge uh we need to fit
3087520	3091680	in order to be able to learn something and to generate explanation for example
3091680	3098400	so somehow this is a call for the community to to start so where do we start and uh i have
3098400	3104160	tried to revisit a bit the research questions that that i had in the beginning thinking okay
3104160	3110720	based on on this idea of knowledge in AI then maybe we need to try to fit the explanation pattern
3110720	3119520	into the existing uh systems uh we need to try to to to to come up with explanations that like
3119520	3128240	uh using deep learning and uh at a web scale uh we need to try to augment explanations and turn
3128240	3134240	them into complex narratives we mentioned these uh complex argumentations so and for these we
3134240	3140400	can really combine knowledge graphs and language models and we really need to compensate whatever
3140400	3148880	information is missing uh by uh performing a co-creation of explanation with with the humans
3150000	3154720	this is the end of my talk uh i thank you so much i don't know how many people are there i
3154720	3160800	thank you so much for taking the time to listen into me i thank uh tobya santua and olav for
3160800	3168720	inviting me there was an amazing opportunity i invite you to to reach me out for exchanges
3168720	3175040	and i really hope to see you in uh at the next hybrid intelligence conference in in sweden in in
3175040	3185680	june uh this is the end of my talk thank you all right uh thank you ilaria um i should buy one of
3185680	3193360	the sitcom applause machines and give you a round of applause that reflects the size of the audience
3193360	3202160	that we had um there were a few questions already in the youtube chat um so please keep them come in
3203360	3210960	and um in the meantime i will post some of them to you and uh if there are no more questions
3210960	3221600	i may ask the people have to deal with mine um good so let's start there is um there is a question
3221600	3229760	by mevish on the chat um and she's asking uh what is your vision on using your explanation
3229760	3235920	techniques for a large language model so you do you think the same techniques are useful for them
3235920	3242000	as well or do you need a different kind or is there a way of adapting maybe um the methods
3244320	3249920	yeah thanks so this is a very cool question of course i mean that that's the kind of question we
3250000	3257280	i i i'm expecting in these days because we do have language models are able to achieve so much
3259280	3265360	that it's it's hard to think okay if i done everything wrong can they just do better than me
3265360	3272480	and i mean i would be very curious to to just do a um a simple comparison i like this question a lot
3272480	3280720	so the the the question is really can we use these techniques um um with large language models
3280720	3285520	because i i now have a number of PhD students working on these and we were discussing this just
3285520	3293920	this morning um the you you certainly have the advantage that you might not need to crawl
3294880	3299120	the knowledge graph anymore to generate explanation so all the problems of
3299840	3307360	um heretics to search the graph um to to reduce the computational complexity
3309120	3318480	might not be needed anymore uh uh with that said i still think that using you you need to combine
3318480	3324640	language models and knowledge graphs um in order to be able to to trace back the information and
3324640	3331520	especially if we are talking about uh truthfulness of an explanation i can ask my knowledge graph to
3333280	3338320	the language model to to come up with an explanation for a given pattern of data but i
3338320	3344960	i also want to make sure that i can trace the provenance back and this is something that i
3345840	3350480	i want to know i mean probably a knowledge graph is much better to do than than a language model
3351200	3357200	uh so i still think that as i said the backbone of the information should come from a knowledge
3357200	3365600	graph in a way that you can uh you can reconstruct the subgraph somehow that generates your explanation
3365600	3374960	and then the output for the form it can be uh can be generated or or situated according to the
3374960	3384960	users by the language model that will be my answer okay um so thanks for that there's another
3384960	3391200	question by peter jones he's asking to what extent do you think ai and explainable ai may
3391200	3399440	reduce or undermine the use or development of domain specific languages uh sorry i
3399440	3407920	lost the second part of the question so do i think the ai and explainable ai reduced the use
3407920	3420000	of domain specific languages um well i don't think they actually i i'm not quite sure uh
3420000	3428320	whether by domain specific language uh yeah we mean the domain specific representation
3428320	3437200	or so the main ontologies but i don't think they actually uh reduce it or at least i don't think
3437200	3446160	they should reduce it somehow um i see more an integration of the two in the sense that uh
3446160	3454160	the the the same way uh there are these methods that use so you i've seen methods using domain
3454160	3461520	specific ontologies to um come up with maybe decision trees about the an explanation that is
3461520	3469920	being generated so they um uh the advantage of domain specific language is still that they are
3470880	3476960	highly they're curated by by the experts and so they are still more reliable so the two methods
3476960	3485440	should kind of uh i don't i don't want to think of uh of explainable ai methods as taking over
3485440	3492080	but rather to try to uh complement to to to combine the two or in a in a neuro symbolic fashion
3493840	3504400	i hope this answer the questions uh hi yeah i hope so too um speaking of maybe maybe this
3504400	3510960	this goes one into the direction of one of the questions that uh that i uh noted um so if we
3510960	3515520	have if you have a domain specific language or a domain specific may of modeling things
3515520	3524800	then this allows to very uh concisely write down things for a specific domain um previously one
3524800	3534160	of your explanation methods you use something that like was looking at graph uh the distance in the
3534160	3539600	graph right and if you change like if you have something very good for one domain then that
3539600	3547440	obviously changes the the the distance in the graph so maybe you can reflect a little bit on how
3548080	3554800	the graph structure or the role of how model how things are modeled or how much entailment is
3554800	3563840	applied on on the graph changes the the the distance or the results of your approach
3564800	3571600	yeah so i think um in general this is the kind of problem we try to to to approach
3574800	3580960	both so with uh say with a with a follow-up method so when we looked into
3581840	3586880	uh trying to identify strong relationships but also trying to cope with the with the
3586880	3592160	the inner bias of the information uh the assumption so we we've never dealt with
3592800	3598480	knowledge graphs we created right so we always dealt with knowledge graphs that were created by
3598480	3604320	others so the assumption was you might not find the information that that you might need and you
3604320	3610320	need to so sometimes the the information is very well curated and sometimes this is not
3610320	3617600	and somehow we need to find um a way to to to cope with this problem in order to be as general
3617600	3628160	as possible so the my view is really that there is not a a universal way of so there is not a
3628160	3636640	method that can can deal with both the most important thing is being able to um to cope
3636640	3640560	with the problem and integrate it in the methods that you develop so you need to be aware that
3640560	3647600	information might be missing and and you need to make sure that your method compensates for that
3647600	3653440	this can happen inside the development of your method or as a postdoc it's like a posteriori
3653440	3661840	step and and it can be as simple as i mean in the same view of the co-creation with the user it can
3661840	3667840	be as simple as okay let's interact and see whether i'm missing some part of the information
3670640	3676800	so so somehow one of the reasons why we had to look into the strength of the relationship was
3676800	3684400	also because we were missing these and we had to find a strategy to to survive in the in this
3684960	3695680	case okay um there's another question from ask kim star and uh they are asking what
3695680	3702160	adaptions do you see for knowledge for for this whole set of approaches to deal with multimodality
3704320	3712960	um sorry so the so you had so you had like there was this with the cat picture where there
3712960	3722080	was some computer vision aspects in it um and maybe you reflect a bit on on multimodality when
3722080	3730240	it comes so it's uh it's through that we've never uh it's the kind of knowledge graph we've been
3730240	3738880	dealing with and and multi multi-modal knowledge graphs were not really um uh um that common at
3738960	3745760	that time i think uh so so it's through that one aspect that would be interesting and maybe
3746640	3753440	we kind of we didn't discuss this as as in the future step but it is in these days we are now
3753440	3761680	talking about we hear much more about multimodal knowledge graphs we hear um also about knowledge
3761680	3767120	graph that somehow try to integrate the physical words so like we deal with robots in some scenarios
3767120	3772240	and we also have this problem of okay i have a knowledge graph that has to integrate both
3772240	3781040	abstract concepts but also the physical word um so um uh i think it would be quite interesting to
3781040	3787360	think on how to generate explanations that are multimodal in this sense uh this is one part of
3787360	3792800	the answer in the sense that yes we didn't look into multimodal knowledge graphs and this it could
3792880	3800800	change uh the other part of the answer is uh uh the explanation that we could generate
3801440	3807680	so the kind of patterns that were coming out could also be patterns coming from from multimodal
3807680	3816320	data so like the uh i dealt a lot with clusters of of of data points but these data points could as
3816320	3824080	well be um uh paths of an image for example that will represent that will represent i don't know
3824080	3829920	the ear or the the tail of the cut of this kind of thing so i didn't deal with that concretely but
3829920	3841600	it could uh i i don't see why the method shouldn't work on um image uh labels uh with yeah with specific
3841600	3847600	information that we might want to explain uh so that say with respect to multimodality there are
3847600	3853040	these two parts so the the the original method would probably work also on data points coming up
3853040	3859680	from multimodal data and then the multimodal knowledge graph we didn't look that much into it
3859680	3865200	and it could be quite interesting to to look into multimodal explanation in this sense so that's
3865280	3875360	okay thanks um so maybe as a as a last question jumping back to your history um and because this
3875360	3882640	is the cost action on distributed knowledge graph where we uh care about distributed decentralized
3882640	3889440	things so you you had this one approach that was based on dereferencing of your eyes and looking at
3889440	3897920	things from from that perspective now um you kind of gave me the impression that you say okay now the
3897920	3903440	person who developed the large language model did the web crawling for you but maybe you can say
3903440	3910000	something like all the methods that you have developed in the meantime after you were done
3910000	3917200	with dereferencing your eyes are they based on a global kind of view uh to i don't know generate
3917200	3922880	embeddings and things um or would they still work in a distributed and decentralized setting
3924080	3933200	i i guess as long as uh so the the embeddings are convenient because they can embed a lot of
3933200	3939200	information in in a very small space and that's something that we didn't have so we had to come
3939200	3946400	up with a different dereferencing opportunity but also we didn't want to deal with uh storing the
3946400	3950960	graph because if you store the graph and you query it then you then you you need to know the
3950960	3956640	data model and we didn't care about it so what we really cared about was this kind of serendipitous
3956640	3964800	hope um i remember one of the first papers i i saw was um something all of also did on on on
3964800	3973200	navigation query languages so that was quite quite quite related um so i think the the most
3973200	3981280	important the the part that would still work is even in a distributed context is as long as you
3981280	3989040	have connections or pointers to to from data to data then it's fine it doesn't really matter and uh
3989040	3996000	and we we didn't care whether it was the web of data or it could have been the load and load
3996960	4004160	stored in a in an hdt file um that was really not the the problem the main problem was uh
4004960	4010720	what where is the irrelevant information uh how do i identify the the links between the
4010720	4016480	between that and this is valid in any context do i whether i have the information centralized or
4016480	4022240	decentralized i would say then i have really experimented with that so i can't tell but
4022400	4032400	so good um yeah thanks for the answer um i don't have more questions from the youtube chat um
4033760	4040640	with that i just want you to thank you again for the very nice talk and the very nice tna session
4042000	4048480	before we close the stream i can only advertise the next talk on january the 31st at the same
4048480	4057520	time as today by mayank um you can check out our website and find uh follow us on this thing
4057520	4064400	formerly called twitter and of course you find all the recordings of our talk on our youtube channel
