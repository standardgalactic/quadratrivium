WEBVTT

00:00.000 --> 00:09.360
Okay, so welcome everybody for tonight's talk. Today we have Ilaria and she was going to talk

00:09.360 --> 00:16.640
about explainability with knowledge graphs. What have we learned? This is the talk series of the

00:16.640 --> 00:23.680
cost action on distributed knowledge graphs. We've had a few talks already. You can watch them in our

00:23.680 --> 00:31.040
YouTube channel and we also have a few talks coming up on January the 31st. We will have a

00:31.040 --> 00:38.720
talk by Mayankerival on March the 4th. We will have a talk by Marc Neusen and on April the 17th

00:38.720 --> 00:48.720
we have a talk by Peter Patelschneider. What is this cost action? It is a European research network

00:49.520 --> 00:54.640
where more than 30 countries are represented. We run workshops, hackathons and short term

00:54.640 --> 01:03.440
scientific missions for which also you can apply. This overall runs from 2020 to 2024.

01:04.160 --> 01:13.920
So we have a few months still on the project and we are now in our final year. This is chaired by

01:13.920 --> 01:19.520
myself. This cost action with Axel Polares as the vice chair. We have Michel Dumontier and

01:19.520 --> 01:28.480
Renzi as working group leads next to Andreas Antoine Olaf. Then there is John as a scientific

01:28.480 --> 01:34.000
representative of the grant holder Anastasia Dimou as the science communication manager

01:34.000 --> 01:42.320
and Stefan Gostowicz as the grant coordinator. So much on the cost action. Today we have Ilaria

01:42.400 --> 01:51.840
and I would like to hand over to Olaf to announce the speaker. Yes, hello and welcome from my side

01:51.840 --> 02:02.160
as well. I'm very happy to have Ilaria as a speaker. She got her PhD from the Open University in the

02:02.160 --> 02:09.680
UK and the title of the PhD was explaining data patterns using knowledge from the web of data

02:10.560 --> 02:16.720
and for the PhD she received this distinguished dissertation award of the Semantic Web Science

02:16.720 --> 02:28.720
Association of Swizzers. She got this award in 2017 and as you maybe know we run this talk series

02:28.720 --> 02:34.080
with speakers who received either this dissertation award or they received the 10 years award of

02:34.080 --> 02:40.400
Swizzers. So now Ilaria received this award in 2017. One year later she went to Amsterdam

02:40.960 --> 02:48.640
to the Free University in Amsterdam where she became an assistant professor there that she still is.

02:50.400 --> 02:59.040
She has been involved in several conferences. She is the editor-in-chief for the CEWS

02:59.840 --> 03:06.000
workshop proceedings where many of us probably publish their proceedings of their workshops.

03:06.000 --> 03:10.400
She's also in the steering committee at the moment of the Hybrid Human AI Conference

03:11.200 --> 03:17.840
and her research, the focus of her research is on systems that combine semantic technologies,

03:17.840 --> 03:25.120
open data, machine learning in order to generate complex narratives with applications mostly in

03:25.120 --> 03:31.440
scientific scenarios and in robotics and if you look at kind of her most cited papers many of them

03:31.440 --> 03:39.040
have the word explain or explaining explanation in their title. So I'm very happy to have her here

03:39.040 --> 03:45.040
and kind of reflect on the work that she did in the PhD and what has happened since then with this

03:45.040 --> 03:54.400
work. The floor is yours Ilaria. Thank you so much. Thank you for all of Tobias for the introduction.

03:55.600 --> 04:01.520
Yeah I'm going to share my screen so my question was whether you are keeping the rights.

04:02.240 --> 04:09.120
Can you just give me a sign that you can see that I think okay. Yeah great. So

04:12.000 --> 04:17.760
good evening or good morning everybody. My name is Ilaria and I work at the Free University in

04:17.760 --> 04:26.640
Amsterdam. I'm an assistant professor. I'm very very happy of giving this talk today. There was

04:26.640 --> 04:34.640
really a nice opportunity for me to reflect on the overall research that I've been doing in

04:36.640 --> 04:43.920
the past since I was a PhD student and of course it's about explanations which is a very hot topic

04:43.920 --> 04:50.720
in these days and really my work and my background is on knowledge graphs so I've been working most

04:50.720 --> 04:55.440
of my life on how to use knowledge graphs in the context of generating explanations

04:56.080 --> 05:06.960
and that's what we are going to see a bit. So I just to all I've gave her a very good introduction

05:06.960 --> 05:12.080
of myself as I said I'm an assistant professor and have read intelligence. My background is on

05:12.080 --> 05:18.720
knowledge representation, knowledge graphs, knowledge graphs for explainable AI. These

05:18.720 --> 05:25.360
days I'm mostly focusing on my use cases around hybrid intelligence. You will hear a bit more

05:25.360 --> 05:32.400
later on knowledge representation driven robotics and also scientific assistance and scientific

05:32.400 --> 05:41.360
discovery. There's more about me you can check on the on my website. This slide is actually wrong

05:41.360 --> 05:48.240
so it's IWC 2017 that I missed the one when I was about to receive supposed to come on stage and

05:48.240 --> 05:56.960
receive the SWSA dissertation award. I was actually driving to a very far plate so I had to miss the

05:56.960 --> 06:06.560
conference but I was very happy of receiving the news nevertheless. So to give you an overview

06:06.560 --> 06:16.720
of what this talk is going to be about I will be describing a bit what's the work during my PhD was

06:16.720 --> 06:25.120
so as as you heard from all of the title of my thesis was on explaining data patterns using

06:25.120 --> 06:32.400
knowledge from the web of data and then I also want to discuss a bit what has going on since

06:32.400 --> 06:40.640
then so since 2017 2016-17 what how explanations have developed how our knowledge graphs have

06:40.640 --> 06:47.280
developed and the overall area and also some and concluding with some future consideration

06:47.280 --> 06:57.280
of where do we want to go and and and how can we go from here. Starting with about 10 years ago

06:57.280 --> 07:06.960
a bit more it's always hard to realize it over 10 years now. I like to show these pictures

07:06.960 --> 07:12.400
or map a bit the audience I am not sure I can actually see the chat but maybe somebody wants to

07:12.400 --> 07:18.880
I like to ask the question on whether somebody knows this picture which it's quite famous used to

07:18.880 --> 07:22.080
be quite famous I don't know whether somebody is familiar with that

07:26.560 --> 07:36.800
and this might be how I don't really see the chat but that's okay. So this is a typical

07:38.160 --> 07:44.640
knowledge discovery process as was firstly introduced around in the middle of the 90s

07:45.120 --> 07:53.040
when knowledge discovery was one of the main scientific processes that

07:55.600 --> 08:04.400
scientists were using computer science method 4 and the process was actually was

08:04.400 --> 08:11.760
firstly introduced by Fayyad so you can look up the reference and it used to be described as

08:11.760 --> 08:19.120
all the steps that scientists need to produce in order to go from data into knowledge

08:19.120 --> 08:25.520
and these steps were mostly selection of the data processing of the data transformation

08:25.520 --> 08:35.040
data mining that was what came before the current machine learning and deep learning method

08:35.280 --> 08:42.720
and then interpretation of an evaluation of the patterns so every step in every step you do

08:42.720 --> 08:49.920
you transform your data little by little first you identify the relevant information then you

08:49.920 --> 08:56.320
preprocess your data you transform them into something that you give to a data mining algorithm

08:56.320 --> 09:02.240
and then you come up with patterns that then need an interpretation and an evaluation in order to

09:02.240 --> 09:16.080
become knowledge. Now what we focused on is mostly this interpretation process so the last step

09:16.800 --> 09:23.280
the interpretation of the patterns was somehow the core of the scientific process was what would

09:23.280 --> 09:31.840
allow to transform patterns into into knowledge so to give a meaning to these patterns this is

09:31.920 --> 09:39.520
actually how interpretation is being defined somehow in the dictionary so it's really the

09:39.520 --> 09:48.320
action of capturing the meaning and communicating conveying the meaning of something usually the

09:48.320 --> 09:57.360
way you interpret patterns so the way you try to give a meaning to that to capture this meaning

09:57.360 --> 10:02.960
is by using your own background knowledge so you come up with patterns you might have

10:03.680 --> 10:08.640
your own background knowledge or maybe human experts in a topic that explain the patterns

10:08.640 --> 10:16.480
that the data mining algorithm has come up with and that helps evaluating and interpreting this

10:16.480 --> 10:24.800
knowledge the problem is this background knowledge might be missing so you might require maybe the

10:24.800 --> 10:32.240
expert doesn't know the actual explanation or you might need in certain use cases you might need

10:32.240 --> 10:38.560
different experts from different domains so gathering this background knowledge might be

10:38.560 --> 10:48.720
quite a time consuming process in this case when this information is missing the kind of

10:48.800 --> 10:59.040
hypothesis that we put forward was that symbolic AI so symbols or knowledge graphs or linked open

10:59.040 --> 11:06.480
data as we used to call them at that time are another source of background knowledge so the

11:06.480 --> 11:17.280
kind of idea that we had is okay if we have plenty of multiple of knowledge graph of data sources

11:17.280 --> 11:23.600
that are multi-domain that are connected between each other so at that time we had the link data

11:23.600 --> 11:29.440
cloud I think this is this picture is slightly later than 2013 but the idea is to have all these

11:29.440 --> 11:38.000
connected data sets that point to each other and then you can continuously discover knowledge simply

11:38.000 --> 11:44.320
by crawling data set one after the other this information is most of the time it's connected

11:44.320 --> 11:52.320
it's centralized in hubs and observatories it's standardized according to certain vocabularies

11:52.320 --> 12:03.040
that allow modeling data sharing data so the the vocabularies would allow to to to have inter

12:03.040 --> 12:10.160
operability across application then the kind of idea was okay maybe we can use this all this

12:10.160 --> 12:18.800
information which is available online to help us explaining the patterns that an algorithm gives us

12:19.600 --> 12:23.760
whenever we don't have an expert in the picture or whenever we are missing the background knowledge

12:23.760 --> 12:34.560
to explain that and and it is very similar to the idea that Newell and Simon already in the 70s had

12:35.520 --> 12:45.280
so among the the faders in AI that symbols were one additional layer to to use when somebody

12:45.280 --> 12:52.240
wants to capture and and and convey the meaning so you don't only need the data or the experience

12:52.240 --> 12:57.920
but you need to put a structure and you need symbols on top of it in order to really get into

12:58.880 --> 13:07.360
into an intelligent system that can understand and capture meaning so based on these hypotheses

13:07.360 --> 13:15.680
we set up a number of research questions so the very first one we we looked into was okay if we

13:15.680 --> 13:21.920
want to use uh if if we want to use knowledge graph large-scale knowledge graphs to to to

13:21.920 --> 13:27.600
generate explanations um we kind of need to understand what do we mean by an explanation

13:27.600 --> 13:33.040
so we need a definition even if it's a working definition we still need one and then we kind

13:33.040 --> 13:38.560
of said okay we need a method that will allow us to to to generate explanations from knowledge

13:38.560 --> 13:48.480
graphs so how how are we going to do that um then then assuming we come up with one such a method

13:48.480 --> 13:53.280
we need to try to cope with all the problems that come with knowledge graph including

13:54.000 --> 14:03.520
incompleteness, bias, noise um so so the the later research questions obviously some of the

14:03.520 --> 14:07.840
research questions came out little by little throughout the process right so you look at your

14:07.840 --> 14:15.440
phd from a different perspective but somehow the the later research questions were on improving

14:15.440 --> 14:19.600
the methods that we had in order to cope with the limitations of knowledge graphs including

14:19.600 --> 14:28.160
incompleteness and bias and basically uh looking now i'm going to go through the the research

14:28.160 --> 14:34.240
questions but i don't want to dive too much into it i mean we have papers for that i'm just the next

14:34.240 --> 14:41.360
slides are mostly to give you an idea of what the overall approach was uh starting with the the

14:41.360 --> 14:47.840
definition of explanation we defined we first defined an ontology design pattern for explanation

14:47.840 --> 14:53.360
so what we did was we looked into different disciplines we looked into philosophy we looked

14:53.360 --> 15:01.600
into linguistics into social science and we looked into their definition of explanations and we

15:01.600 --> 15:07.520
noticed that even though there were different approaches and methods explanations were always

15:07.520 --> 15:13.200
seen according to the similar characteristics so there was always the generation of some

15:13.200 --> 15:18.800
coherence between old knowledge and new knowledge uh the elements in the explanation were always the

15:18.800 --> 15:25.520
same there was a theory there were an anterior and a posterior event there were sequences that

15:25.520 --> 15:33.440
would make this event happening at the same time and there were always processes um

15:34.400 --> 15:40.000
uh that would be one internal process where you come up with an explanation for yourself and then

15:40.000 --> 15:44.640
one that is more an external process where you communicated the explanation to the rest of the

15:44.640 --> 15:53.040
world and based on this we then defined our own uh ontology design ontology for an explanation so

15:53.040 --> 15:59.120
our own definition that we could then feed into a system that would try to generate explanation

15:59.200 --> 16:04.880
according to these patterns so we we then just it's a pattern in the sense that it can be

16:04.880 --> 16:12.400
instantiated in multiple um in multiple contexts but the overall idea was that you always have an

16:12.400 --> 16:18.160
event uh that happens before an event that happens after I'm not sure you see my pointer but I hope

16:18.160 --> 16:26.240
so uh there are certain uh conditions that make this uh this event happening in a specific setting

16:26.240 --> 16:34.080
and then there's some sort of uh theory behind and a sort and an agent that that that outputs the

16:34.080 --> 16:44.480
that creates the conceptualizes the uh the explanation uh based on um based on this pattern

16:44.480 --> 16:51.040
we then try to to design a system that would try to use knowledge graph to generate explanation for

16:51.040 --> 16:57.040
a given pattern of data and then the the kind of question we try to answer is really okay if we

16:57.040 --> 17:02.560
want to use a knowledge graph a very large knowledge graph uh as background knowledge

17:02.560 --> 17:08.880
which kind of process do I need to uh generate explanation and then we try to work with some

17:08.880 --> 17:16.480
with some examples of patterns of data of things that people might want to to explain uh we had this

17:16.960 --> 17:23.280
very good example that would work with uh google trends and then you try to explain why a certain

17:23.280 --> 17:30.720
website uh is uh regularly happening at specific points in time so in these cases why people are

17:30.720 --> 17:36.240
searching for the term a song in ice and fire only in certain periods so you see that there are very

17:36.240 --> 17:43.760
regular peaks or maybe we try to explain data like statistical data for example from the UNESCO

17:44.320 --> 17:50.080
uh in this case we have uh countries that are grouped according to the

17:51.040 --> 17:57.600
female literacy rate and then you try to explain okay why is is it oops oops sorry uh why is it

17:57.600 --> 18:04.960
happening that um that that certain countries have in common like a certain characteristic

18:05.600 --> 18:11.840
and the very good thing is that uh we try to come up with a method that had us uh working

18:11.920 --> 18:18.400
out these examples and it was basically it was based on three main steps one was an inductive

18:18.400 --> 18:23.920
logic programming step where you try to compare positive and negative examples and you have some

18:23.920 --> 18:30.320
background knowledge expressed in uh as as tripos as facts about these examples and then the goal

18:30.320 --> 18:35.680
is to induce the hypothesis that mostly represents your positive examples which are the examples

18:35.680 --> 18:45.600
you want to explain uh we used a knowledge graph search so we we try to uh uh search the the link

18:45.600 --> 18:52.640
data graph uh in order to find a common path which would be expressed in terms of predicates

18:53.200 --> 18:59.520
relationships uh leading to a specific entity in the graph so we call this path and then we

18:59.520 --> 19:06.480
would consider any path that is uh common uh to all the positive examples as an explanation for the

19:06.480 --> 19:14.080
group of positive example uh and then in order to to to improve the the the graph search we we

19:14.080 --> 19:23.040
implemented a greedy uh links reversal strategy uh so we try to aim for uh the uh longer and longer

19:23.040 --> 19:30.160
path you know um and explore the graph using simple http d referencing in order to avoid

19:30.160 --> 19:37.440
computational costs it was 2013 we still had issues of computational costs and uh based on this

19:37.440 --> 19:42.960
method we try to answer mostly two questions so first we said okay which kind of your uh

19:42.960 --> 19:49.600
risks do we need to to drive a greedy search and identify the best explanation so we try

19:49.600 --> 19:55.920
different strategies and then one of the main finding for us was that a measure so a strategy

19:56.480 --> 20:05.920
based on entropy um would lead to a higher explanation in in in in less time so we simply

20:05.920 --> 20:14.960
measured on what is the best accuracy of an explanation over time so this is um uh iteration

20:14.960 --> 20:21.280
in searching the graph and we always ended up having the best uh an entropy based measure

20:21.280 --> 20:28.560
as the one that would perform best and give us the best explanation uh these allowed us to to to

20:28.560 --> 20:35.680
come up with uh explanation for the use cases i was showing before so uh why are women less

20:35.680 --> 20:40.160
educated than men in certain countries and that's mostly when countries are least developed for

20:40.160 --> 20:48.400
example uh so they have a quite a high human development index rank and uh or they are expressed

20:48.400 --> 20:56.000
they are defined in dbpb as least developed countries um or we we had explanations like okay

20:56.000 --> 21:03.840
people search for a song in ice and fire whenever there is an event that is somehow linked to a

21:03.840 --> 21:11.120
game of thrones tv series so that's this is we consider these explanations but of course if you

21:11.120 --> 21:18.320
look at the results you might notice things that are quite not right and uh in particular you look

21:18.320 --> 21:24.480
at these kind of examples so uh it's true that if you have enough background knowledge about a song

21:24.480 --> 21:30.960
in ice and fire which is actually a book uh and you know that there is a certain tv series related

21:31.600 --> 21:36.560
that is based on this book you know that the explanation for people being particularly

21:36.560 --> 21:42.720
interested in these uh is whenever the tv series is coming out so there is a new season coming out

21:42.720 --> 21:50.320
but there's nothing that relates the tonga tonga uh to to to the book or basketball

21:50.320 --> 21:57.360
competition to the book so the kind of questions we had to ask answer afterwards was really okay is

21:57.360 --> 22:04.160
there something in linked data that can tell us that game of thrones is strongly related to a song

22:04.160 --> 22:09.920
in ice and fire much more than basketball competitions or anything related to tonga so the

22:09.920 --> 22:16.000
second part of the method was really focused on strengthening this knowledge based explanation

22:16.000 --> 22:23.280
and we focused we used a genetic programming algorithm to try to learn um a function that

22:23.280 --> 22:30.000
could detect the strong relationships between two graph entities that are quite distant in the graph

22:30.000 --> 22:35.680
so we are not talking about two entities in in in the same graph but you have one entity that is

22:35.680 --> 22:42.320
connected to another entity through hops in multiple graphs in multiple data sets and then we really

22:42.320 --> 22:48.000
want to try to understand what is the the strongest relationship and what we did is that with a genetic

22:48.000 --> 22:56.080
programming algorithm we try to learn a function that could study the topological and semantic

22:56.080 --> 23:02.720
characteristics of the knowledge graph so we really looked into how many hubs and how many

23:05.520 --> 23:10.320
how strongly connected was the graph for example which kind of vocabulary the graph was was using

23:11.600 --> 23:16.400
all these we gave all these to our genetic programming algorithm and then we tried to

23:16.400 --> 23:23.040
come up with a with a function that would tell us okay this is a strong relationship and we evaluated

23:23.040 --> 23:30.800
that with against a human evaluated relationship path and um actually what what came out from

23:30.800 --> 23:38.160
from this study was that the best thing for us would have been to try to follow uh notes that

23:38.160 --> 23:43.840
would have quite rich descriptions so here you have different examples of different functions

23:43.840 --> 23:50.960
that we tried and then here you have the say the best performing ones um and the the the best

23:50.960 --> 23:58.240
functions that we could find were really the ones were focusing on uh following notes with

23:58.240 --> 24:05.040
rich descriptions that they would have quite a good number of namespaces uh it was best to follow

24:05.040 --> 24:10.880
more specific entities so really not not not hubs with many incoming links but rather something

24:10.880 --> 24:18.320
that is more specific and also we look into scores the scores vocabulary and uh it was best to have

24:18.320 --> 24:24.160
fewer topical categories so not something quite generic in some in terms of topic but but rather

24:26.080 --> 24:35.760
again a bit more specificity uh of course we had to look into into into into into into the bias

24:35.760 --> 24:42.960
in the data as well so the the results were not optimal and as I said we needed to deal both with

24:42.960 --> 24:50.800
incompleteness of the data but also when inner bias of the data and what we tried to do was to um

24:51.680 --> 24:57.440
use identity links so remember that we are still we were still we are still talking about link data

24:57.440 --> 25:04.080
where data sets are connected to each other through identity links including same as and what we uh

25:04.720 --> 25:14.720
tried to do was to um measure the bias in a given data set uh by uh comparing the projection on one

25:14.720 --> 25:20.000
data set into another one so the overall idea was really that you have a data set which could be

25:20.000 --> 25:25.840
I don't know the link movie database and you have a certain amount of entities that are connected

25:25.920 --> 25:35.600
through the dbpdia uh using identity links and the projection of the the movie database is mostly

25:35.600 --> 25:42.080
the set of entities that's in dbpdia that are connected to to to the movie database and then

25:42.080 --> 25:50.560
we we would basically compare all the entities in the larger data set with the subset and using

25:50.560 --> 25:58.400
some correlation uh tests or some t-test and by comparing the distribution of uh property value

25:58.400 --> 26:06.320
pairs uh between the subset of the entities and the large set uh we try to identify with uh which

26:06.320 --> 26:15.360
were the the the the the bias in a given data set uh so for example we uh and yeah I would

26:15.920 --> 26:23.120
uh send uh I would recommend you to refer to the paper but what we what we discovered was

26:23.120 --> 26:29.680
for example that the link movie database was particularly focused on black and white movies and

26:31.600 --> 26:38.560
that certain digital humanities data sets were focused on uh uh poets and novelists from the

26:38.560 --> 26:46.720
18th and 19th century so it was a way to try to measure the bias in the in the in the data

26:46.720 --> 26:53.840
set that we were using to generate explanations and to once we learned these bias we could also try to

26:57.440 --> 27:04.000
somehow input this information in our system and generate better explanations

27:04.880 --> 27:13.680
now this was uh uh quite a long a long journey that uh ended up in 2016 and there's a number of

27:13.680 --> 27:22.240
things that happened uh since then what I what I'm I call the the present um so I don't have

27:22.240 --> 27:28.080
enough time to focus on everything but I choose three particular uh aspects that I'm going to to

27:28.080 --> 27:37.280
show which help us also thinking a bit further uh into the steps that we want to uh to take afterwards

27:38.000 --> 27:44.480
the very first thing of course is the rise of deep learning so when uh when uh we started the

27:44.480 --> 27:48.640
the work on explanations and knowledge graphs actually on knowledge graphs for explanations

27:49.600 --> 27:55.200
deep learning was just was probably just booming and I wasn't even aware of that so what we were

27:55.200 --> 28:02.240
talking about was uh using knowledge graphs to um generate explanation for outputs of any

28:02.240 --> 28:08.640
machine learning algorithm uh but we've never heard of deep learning I think that yeah maybe the the

28:09.360 --> 28:17.040
the the first papers are around 2012 but if I'm not mistaken but um of course the the hype came

28:17.040 --> 28:27.520
much later and um uh the the the DARPA uh so so deep learning and all the methods behind we

28:27.520 --> 28:32.960
that came with deep learning showed uh impressive results that could achieve uh

28:35.120 --> 28:40.960
the same results as human would and uh but but also showed a number of limitations so the

28:41.600 --> 28:48.640
uh the the the facts like the Cambridge Analytica scandals or the the loan accreditation scandals

28:49.680 --> 28:56.400
show that these systems were uh were not able to to show a clear reasoning so the reasoning was

28:56.400 --> 29:02.160
quite opaque uh these systems were data hungry so you needed a lot of data to train them they were

29:02.160 --> 29:08.880
too brittle in this sense and then DARPA came out with this explainable AI program that was 2017

29:09.280 --> 29:17.840
if not if I'm not mistaken um on okay let's try to implement create systems where the user is

29:17.840 --> 29:24.800
that are transparent that can explain the machine learning model and then where uh an explanation

29:24.800 --> 29:30.880
can be given on why a certain output is being given uh so this need of explaining the models

29:30.880 --> 29:36.880
and the results really came out and you start we started seeing methods like SHOP and LIME which

29:36.880 --> 29:42.320
are probably the most basic ones and then there's there's a number of other systems that came out

29:42.320 --> 29:48.640
afterwards uh that could tell you okay the the most important features to come up with an explanation

29:49.680 --> 29:59.440
and more in your data set are uh like maybe the race or the occupation of of of of your data

30:00.160 --> 30:06.320
or we started seeing saliency maps okay with with imagery recognition uh what are the most

30:06.400 --> 30:16.080
important parts that that system focuses on when generating explanations uh this especially the

30:16.080 --> 30:22.880
explanations in in in the explainable AI area and if you look into the major AI conference you

30:22.880 --> 30:29.920
start seeing a boom of uh I think explainable AI became an actual topic or a subfield in in AI

30:30.560 --> 30:36.800
uh one of the questions that people asked was okay uh are these explanations that SHOP and LIME

30:36.800 --> 30:43.840
come up with are they really working especially in a real-world context so they do work in in a

30:43.840 --> 30:50.560
small use case but what if I applied into into a real-world context uh and somehow the narrow

30:50.560 --> 30:57.840
symbolic field uh which was already in in the meantime in developing on on his own came up a

30:57.840 --> 31:05.600
bit in the rescue of this problem so somehow we started seeing methods that try to combine

31:06.160 --> 31:13.360
a symbolic approach so symbolic reasoning uh with neural network either to uh maybe improve

31:13.360 --> 31:20.560
the explainability and trust of a system using a symbolic description uh or by creating a sort

31:20.560 --> 31:25.840
of hybrid interaction between the the neural network and and the reasoning system uh so these

31:25.840 --> 31:31.600
are just two of the many examples that you could could see when uh where the knowledge graph would

31:31.600 --> 31:37.440
try to jump in into the explainable AI word and say okay hey look we should be maybe using

31:37.440 --> 31:45.520
knowledge graphs and ontologies to help uh we also did a part of this uh so what what we try to do um

31:45.520 --> 31:53.040
and um uh this this I completely forgot the the uh this the reference to this work but

31:53.040 --> 32:00.400
if we published in 2021 uh we really try to say okay if everybody if many people are looking into

32:00.400 --> 32:09.440
using knowledge graphs as a as a tool to explain um machine learning methods let's try to look at

32:09.440 --> 32:16.160
what's the state of the art so uh how are people in machine learning using knowledge graphs what are

32:16.160 --> 32:22.720
the the most important characteristics so we try to look into different uh tasks and different areas

32:23.200 --> 32:27.680
and uh we try to look into the characteristics of the knowledge graphs the characteristics of

32:27.680 --> 32:32.960
the model and the characteristics of the explanations that we were being generating uh

32:32.960 --> 32:38.000
in order to come up with really with a with a picture of the field uh and this this is more

32:38.000 --> 32:45.120
or less what we came up with so uh we we learned certain things like if you are dealing with tasks

32:45.120 --> 32:50.560
for recognition and recommendation uh most of the explanation you will get are really about the

32:50.560 --> 32:56.960
model and how it behaves and most of the information that is being used uh from the knowledge graph is

32:56.960 --> 33:05.520
the is the a is the aversion box uh and whenever uh we deal with tasks that involve the interaction

33:05.520 --> 33:11.200
of the user like conversational agents or recommender systems the knowledge graph information is

33:11.200 --> 33:17.680
used to is used more into the training of the model uh to generate a certain explanation

33:17.760 --> 33:24.720
rather than as a postdoc stack uh we looked into the different types of knowledge graphs whether

33:24.720 --> 33:30.800
they were factual or common sense or domain knowledge graphs domain specific and it turns

33:30.800 --> 33:35.760
out that common sense knowledge graphs they're not that many but they were being used for image

33:35.760 --> 33:41.440
recognition and question answering uh we also look into the reuse of knowledge graphs so we've been

33:41.520 --> 33:47.920
uh talking so much in our field about reusing knowledge graph reusing ontology ontologies and

33:47.920 --> 33:52.640
we kind of ask okay is this being applied in this field and it actually turned out it was

33:52.640 --> 33:57.920
quite an established practice so very few were coming up with their own knowledge graph uh most

33:57.920 --> 34:06.320
of the the methods were were using uh dbpdia uh wikidata um consonants or a combination of them

34:06.880 --> 34:13.680
um actually we looked into uh whether these methods were using only one knowledge graph

34:13.680 --> 34:20.160
or multiple ones and we we were hoping to to see a bit more but it does happen sometimes in

34:20.160 --> 34:26.960
nlp tasks and really the kind of this is the kind of picture that came out so if you if certain

34:26.960 --> 34:32.240
areas are more focused on on model embedded knowledge so explaining the model rather than

34:32.240 --> 34:39.760
explaining the outputs certain others are more focused on using the ontologies of the

34:39.760 --> 34:46.640
knowledge graph rather than the facts um and um and so on and so forth so I think the analysis we

34:46.640 --> 34:53.920
did it's around 60 60 papers more or less um and we kind of try to identify also the challenges

34:53.920 --> 35:00.480
for the field right so there are things that were we were hoping to see but that didn't happen

35:00.560 --> 35:05.040
including the what we call the co-creation of explanations so really having a sort

35:07.440 --> 35:12.560
the human having a role into the generation of the explanation there are there were there are

35:12.560 --> 35:18.400
issues related to the maintenance of the knowledge graph so how to deal with uh

35:18.960 --> 35:25.760
missing information or bias when coming up when generating explanations and of course this is a

35:25.760 --> 35:31.760
problem that we also saw during in the in the phd and also there are issues related to the

35:31.760 --> 35:37.520
automated extraction of relevant knowledge when using a knowledge graph that generates explanations

35:37.520 --> 35:44.560
so most of the methods that we analyzed when coming up with an explanation end up manually

35:44.560 --> 35:50.480
selecting uh the relevant relevant relevant information to generate an explanation and

35:50.480 --> 35:54.640
this is quite something it means that there's still a lot to do in the in the field in order to

35:55.520 --> 36:06.000
um uh to move forward um there's uh so this was one part of the story so what happened

36:06.000 --> 36:11.440
ever since deep learning uh there's also the field of hybrid intelligence that came up so

36:11.440 --> 36:17.280
I don't know if many of you heard about uh hybrid intelligence maybe you had about human

36:17.280 --> 36:23.600
centric ai this is another way of addressing this this problem uh the overall idea was that

36:24.960 --> 36:30.320
this there is an emerging field in ai which uh and it's emerging because you start seeing

36:30.320 --> 36:36.720
different conferences and workshops uh around the topic there's a number of uh national and

36:36.720 --> 36:45.360
international um collaboration networks uh that uh that are really focusing on uh on this concept

36:45.360 --> 36:51.040
of hybrid intelligence and and the overall idea because we don't really have a proper definition

36:51.040 --> 36:58.960
but we do have a working definition of hybrid intelligence is to have uh to to aim for ai systems

36:58.960 --> 37:06.400
that try to enhance human capabilities as other scientific tools would do think of the telescope

37:06.400 --> 37:15.760
that allows a scientist to um to look uh where his own eyes cannot see or the machine the the

37:15.760 --> 37:21.440
the sorry the the card that or the the airplane would allow people to to to reach places that

37:21.440 --> 37:28.400
they couldn't reach easily with their with their feet um so it's really about seeing ai system as

37:28.400 --> 37:35.840
an extension of the human intelligence rather than seeing ai as a tool that replaces us so in

37:35.840 --> 37:44.320
this sense hybrid intelligence really look into uh systems that collaborate uh with humans uh aiming

37:44.320 --> 37:51.200
for a complementarity so weak weaknesses and strengths of both ai and humans are complemented

37:51.200 --> 38:00.000
by each other uh and really about this synergetic idea so the the the mixed team the hybrid team

38:00.000 --> 38:10.800
is is aiming for the same has a shared goal um this is um the so so we have a research agenda

38:10.800 --> 38:15.360
I'm part of the Dutch hybrid intelligence consortium and I've been part of the hybrid

38:15.360 --> 38:22.400
intelligence conference of the past uh in the past years um and it's a really vibrant uh field

38:22.960 --> 38:30.720
um and and explainability explaining um it's also a part of the research agenda so

38:30.720 --> 38:35.520
it's not only about trying to collaborate but how in in this in this collaboration

38:35.520 --> 38:42.640
the goal is is also to try to communicate our own intention and explain our own actions and

38:42.640 --> 38:52.720
our own reasoning uh so the one of the the core topics that we established when when

38:52.720 --> 38:57.840
hybrid intelligence came into the picture was really on on on how to create systems that are

38:57.840 --> 39:06.640
able to deliberate and and explain to to their collaborators um I'm more than happy to to discuss

39:06.640 --> 39:13.840
this a bit further uh and somehow in as part of the hybrid intelligence picture we also uh

39:13.840 --> 39:19.120
and as part of the the the contribution that we could give with ontologies and knowledge

39:19.120 --> 39:26.960
across with respect to explainability we also try to um work on on on on a number of what we

39:26.960 --> 39:32.400
call boxologies or terminologies for hybrid intelligence where so to establish mostly to

39:32.400 --> 39:39.760
establish a shared language between uh agents in a different team um sorry agents in the same

39:39.760 --> 39:46.800
team that would collaborate between each other um and uh what what we did in one of the the the

39:48.000 --> 39:52.880
the newest work was really on comparing different hybrid intelligence scenarios

39:53.920 --> 39:59.920
and first trying to identify what are the common uh knowledge roles so we came up with a high level

40:00.000 --> 40:08.000
ontologies of agents interaction types uh and and and specific scenarios and and we try to also

40:08.000 --> 40:15.360
identify um uh using these high level ontologies what were the the most specific hybrid intelligent

40:15.360 --> 40:25.120
tasks uh including ones that would uh relate to creativity and and explainability uh and then

40:25.120 --> 40:31.440
on the side of it we would have uh tasks like team awareness and multimodality uh that's the

40:31.440 --> 40:37.600
second part of the picture so we talk about uh deep learning we talk about uh hybrid intelligence

40:38.800 --> 40:46.320
and what also came into play with respect to to explanation and uh we didn't have that much

40:46.320 --> 40:52.080
time to to dive into it but hybrid intelligence is strongly related to that as well is really on

40:52.080 --> 40:58.640
especially with a with a european perspective is really on the gdpr and uh so um and an eu

40:59.600 --> 41:07.360
ai act which recently came up uh but really the idea is to try to monitor the systems that we are

41:07.360 --> 41:15.600
developing uh to make sure that that that uh users are are protected both in terms in terms of the

41:15.600 --> 41:21.520
data that are being generated and the methods that are being generated uh and these also

41:21.520 --> 41:30.960
means to be able to to to explain um uh the reasoning and to trace back the the the information

41:30.960 --> 41:40.800
that is being output uh so so explainability and transparency became um started uh appearing

41:40.800 --> 41:46.080
together in the in the picture so if you want transparency you need to be explainable therefore

41:46.080 --> 41:54.960
showing your reasoning um and now with this eu ai act the the idea is really that that there are

41:54.960 --> 42:02.000
certain obligations there are certain systems that need to show um uh some transparent they have

42:02.000 --> 42:08.800
transparency obligations so they need to uh be able to explain why certain things are are happening

42:08.880 --> 42:20.080
um otherwise they are considered uh unacceptable uh this is a very uh so i have a few minutes left

42:20.080 --> 42:28.160
i think this is a very uh quick overview of what has happened ever since uh which leads us back to

42:28.160 --> 42:34.240
okay what is going to happen now and how can we kind of think of everything that has happened so far

42:34.880 --> 42:41.680
and and where are we going to to go uh of course i couldn't get away without mentioning language

42:41.680 --> 42:50.160
models at least once so somehow one of the questions and one might ask and we also kind of wondered uh

42:50.160 --> 42:56.640
was uh okay but everything we've done could this be now done so the the overall knowledge

42:56.800 --> 43:02.560
process could just be replaced by language models and by large language models by LLMs

43:03.280 --> 43:08.640
could we just not replace all the steps or the explainability steps do we actually need

43:08.640 --> 43:16.720
knowledge grasp for that and it's true that um LLMs language and language models are very good

43:16.720 --> 43:22.160
in dealing with noise and inconsistency and like methods that the methods that we had before were

43:22.160 --> 43:27.920
not that much able they allow us to extract information very quickly from large structure

43:27.920 --> 43:35.360
data so that goes towards the dream of doing a web-scale learning um or one could argue that

43:35.360 --> 43:41.840
you already achieved that uh they're actually quite good in capturing some complex semantics so

43:41.840 --> 43:49.360
somehow it has been demonstrated that defining a class can can be uh uh with specific boundaries

43:49.360 --> 43:53.040
so the boundaries of the definition of a class is quite difficult are quite hard

43:54.880 --> 44:04.560
so there is no universal class description and and it the especially with the embeddings method

44:04.560 --> 44:11.600
based methods are able to capture this this this complexity quite a bit better and of course

44:11.600 --> 44:16.800
are very good in generating natural language so instead of generating explanation in a

44:16.880 --> 44:23.840
mechanic mechanical mechanistic way from from from the triples uh they are able to generate a much

44:23.840 --> 44:30.880
more human friendly um explanation the problem is that there are still limited in a number of things

44:30.880 --> 44:37.120
so learning from rare and unique events especially like the ones that that that you can find in the

44:37.120 --> 44:46.480
web is still quite difficult um if this these methods are not yet able to show proper reasoning

44:46.480 --> 44:54.160
and argumenting behind thoroughly creating a thorough argumentation uh behind what has happened

44:54.160 --> 45:00.640
and also they don't really deal with with with fairness and interoperability acceptability all

45:00.640 --> 45:09.920
these this fair aspects that we've been looking into as as knowledge graph community are not yet

45:09.920 --> 45:14.880
part of the picture in a language model so somehow there are limitations in using that

45:14.880 --> 45:20.000
but it doesn't mean that we need to discard them completely but we can just join the the

45:20.000 --> 45:25.760
both words and and work out something to for to generate better better explanations

45:26.720 --> 45:35.040
so i want to conclude in the last few minutes to really think okay if we now look at knowledge

45:35.040 --> 45:43.280
graphs and whether they're useful uh to to generate explanation and do they actually work

45:44.000 --> 45:50.240
what is it that we launch so uh somehow both based on the phc and everything that happens

45:50.240 --> 45:56.640
afterwards uh yes we can use knowledge graphs but they are mostly an intermediate representation

45:56.640 --> 46:02.320
so knowledge graphs are really for the machine consumption uh they shouldn't be for human consumption

46:02.960 --> 46:11.920
and the rdf is just a language that that for machines to perform an exchange of information

46:12.000 --> 46:17.920
which is unambiguous so uh we should really not look into knowledge graph as something that we human

46:17.920 --> 46:25.600
should understand but but more as something a machine can can quickly exchange um we can use

46:25.600 --> 46:32.880
knowledge graphs to as to get together content to generate explanation but really the graph

46:32.880 --> 46:39.440
structure is just a backbone so we don't really want to use the knowledge graph to create an output

46:39.440 --> 46:47.360
we can use language models for that uh but but we can use knowledge graph as to to to gather the

46:47.360 --> 46:53.520
backbone of the explanation which can then be output according to different users in a different

46:53.520 --> 47:01.520
dimension so we think okay an expert user might need a longer explanation uh which with more

47:01.520 --> 47:09.040
arguments and an expert a non-expert and layman might need a much shorter and simpler explanation

47:10.080 --> 47:15.280
in terms and llms are great in doing that you can ask them to rephrase a certain concept in

47:15.280 --> 47:21.760
different uh in different according to different dimensions um also knowledge graphs allow allow

47:21.760 --> 47:29.040
to check the to trace back information so you can really walk down the graph and and and check

47:29.040 --> 47:35.440
whether the information is truth and this is quite uh this is much better than looking into

47:35.440 --> 47:41.360
the propagation of an error the activation of a neural network and try to decode what does it mean

47:41.360 --> 47:47.040
um in order to come up with an explanation that you might not be able to to to explain

47:48.800 --> 47:56.000
that clearly yourself and finally scalability which was part of the picture at that time okay

47:56.000 --> 48:02.240
how can we deal with very large knowledge graphs and uh uh we want to to to integrate as much

48:02.240 --> 48:07.920
knowledge as possible well actually this is not that relevant anymore and what people are really

48:07.920 --> 48:15.440
aiming for and we also saw this when collaborating with industry is more it's much better to have

48:16.160 --> 48:22.480
a high quality knowledge graph which is curated by the expert uh to generate explanations rather

48:22.480 --> 48:29.680
than having a very large knowledge graph um so this is one part of the story and then the other part

48:29.680 --> 48:35.200
is more of the big picture uh what we learned is really explainability is not only about machine

48:35.200 --> 48:40.800
learning uh so in hybrid intelligence we deal with explainability we deal with experts from

48:40.800 --> 48:47.280
all kind of fields from social science to computer science and um people look into

48:47.360 --> 48:54.240
explainability from from this in different ways so it's a bit of a jungle of terminology we cannot

48:54.240 --> 49:01.200
really agree what uh what we mean by something being explainable and then we need to try to find

49:01.200 --> 49:09.680
a way to harmonize that um we we learned that explanations are really task dependent so yes

49:09.680 --> 49:14.720
we have an ontology design patterns for the explanation but we need to adapt this according

49:14.720 --> 49:21.680
to the context and again we can use language models for that but it's um the the target audience or the

49:22.480 --> 49:27.360
the language or the the type of explanation really need to change according to the situation

49:28.000 --> 49:34.480
and more importantly we need to look for the human so knowledge graphs are only one part in the

49:34.480 --> 49:40.560
explanation process so in order to generate explanation you need a knowledge graph you need

49:40.560 --> 49:45.520
a sub symbolic method but you also need a human that interacts with the with the system

49:46.560 --> 49:50.640
because in the end as we said at the beginning explanation is a social process it's a dual

49:50.640 --> 49:57.760
process so it has to happen in a in a in a co-creation setting where the user is really

49:57.760 --> 50:03.360
interacting with the system to come up with an explanation is satisfied with and in this sense

50:03.360 --> 50:10.240
we also need interdisciplinarity in the picture to try to measure whether an explanation is is

50:10.320 --> 50:15.680
interesting or not so we kind of we don't only need a computer science perspective but we also

50:15.680 --> 50:21.760
need to try to integrate the talks that we have with social scientists and cognitive uh scientists

50:21.760 --> 50:28.880
to make sure that the explanations that are being generated are actually useful uh so to give some

50:28.880 --> 50:35.680
ideas on what and uh then i'm i'm just done i know i'm over a bit um uh what we suggest is that

50:35.680 --> 50:41.120
really we should look into the kind of knowledge in artificial intelligence so some people have called

50:41.120 --> 50:46.000
this knowledge science some people have called it empirical semantics we call it knowledge in AI

50:47.120 --> 50:52.720
so we really need to go back to the empirical analysis of the knowledge graphs that we create

50:52.720 --> 50:58.400
and we deal with we need to understand their modeling style and the kind of semantics they're

50:58.400 --> 51:03.840
communicating and whether the semantics is enough or too much to generate explanations

51:03.840 --> 51:07.600
we need to check for the usefulness and limitation of the knowledge graph that

51:07.600 --> 51:14.160
and the knowledge that that we create and somehow we need to try to move from the step of okay how

51:14.160 --> 51:21.200
can we fit knowledge into the learning process these we know how to do it uh or at least we have

51:21.200 --> 51:27.520
good methods but we really need to focus on what is which kind of knowledge uh we need to fit

51:27.520 --> 51:31.680
in order to be able to learn something and to generate explanation for example

51:31.680 --> 51:38.400
so somehow this is a call for the community to to start so where do we start and uh i have

51:38.400 --> 51:44.160
tried to revisit a bit the research questions that that i had in the beginning thinking okay

51:44.160 --> 51:50.720
based on on this idea of knowledge in AI then maybe we need to try to fit the explanation pattern

51:50.720 --> 51:59.520
into the existing uh systems uh we need to try to to to to come up with explanations that like

51:59.520 --> 52:08.240
uh using deep learning and uh at a web scale uh we need to try to augment explanations and turn

52:08.240 --> 52:14.240
them into complex narratives we mentioned these uh complex argumentations so and for these we

52:14.240 --> 52:20.400
can really combine knowledge graphs and language models and we really need to compensate whatever

52:20.400 --> 52:28.880
information is missing uh by uh performing a co-creation of explanation with with the humans

52:30.000 --> 52:34.720
this is the end of my talk uh i thank you so much i don't know how many people are there i

52:34.720 --> 52:40.800
thank you so much for taking the time to listen into me i thank uh tobya santua and olav for

52:40.800 --> 52:48.720
inviting me there was an amazing opportunity i invite you to to reach me out for exchanges

52:48.720 --> 52:55.040
and i really hope to see you in uh at the next hybrid intelligence conference in in sweden in in

52:55.040 --> 53:05.680
june uh this is the end of my talk thank you all right uh thank you ilaria um i should buy one of

53:05.680 --> 53:13.360
the sitcom applause machines and give you a round of applause that reflects the size of the audience

53:13.360 --> 53:22.160
that we had um there were a few questions already in the youtube chat um so please keep them come in

53:23.360 --> 53:30.960
and um in the meantime i will post some of them to you and uh if there are no more questions

53:30.960 --> 53:41.600
i may ask the people have to deal with mine um good so let's start there is um there is a question

53:41.600 --> 53:49.760
by mevish on the chat um and she's asking uh what is your vision on using your explanation

53:49.760 --> 53:55.920
techniques for a large language model so you do you think the same techniques are useful for them

53:55.920 --> 54:02.000
as well or do you need a different kind or is there a way of adapting maybe um the methods

54:04.320 --> 54:09.920
yeah thanks so this is a very cool question of course i mean that that's the kind of question we

54:10.000 --> 54:17.280
i i i'm expecting in these days because we do have language models are able to achieve so much

54:19.280 --> 54:25.360
that it's it's hard to think okay if i done everything wrong can they just do better than me

54:25.360 --> 54:32.480
and i mean i would be very curious to to just do a um a simple comparison i like this question a lot

54:32.480 --> 54:40.720
so the the the question is really can we use these techniques um um with large language models

54:40.720 --> 54:45.520
because i i now have a number of PhD students working on these and we were discussing this just

54:45.520 --> 54:53.920
this morning um the you you certainly have the advantage that you might not need to crawl

54:54.880 --> 54:59.120
the knowledge graph anymore to generate explanation so all the problems of

54:59.840 --> 55:07.360
um heretics to search the graph um to to reduce the computational complexity

55:09.120 --> 55:18.480
might not be needed anymore uh uh with that said i still think that using you you need to combine

55:18.480 --> 55:24.640
language models and knowledge graphs um in order to be able to to trace back the information and

55:24.640 --> 55:31.520
especially if we are talking about uh truthfulness of an explanation i can ask my knowledge graph to

55:33.280 --> 55:38.320
the language model to to come up with an explanation for a given pattern of data but i

55:38.320 --> 55:44.960
i also want to make sure that i can trace the provenance back and this is something that i

55:45.840 --> 55:50.480
i want to know i mean probably a knowledge graph is much better to do than than a language model

55:51.200 --> 55:57.200
uh so i still think that as i said the backbone of the information should come from a knowledge

55:57.200 --> 56:05.600
graph in a way that you can uh you can reconstruct the subgraph somehow that generates your explanation

56:05.600 --> 56:14.960
and then the output for the form it can be uh can be generated or or situated according to the

56:14.960 --> 56:24.960
users by the language model that will be my answer okay um so thanks for that there's another

56:24.960 --> 56:31.200
question by peter jones he's asking to what extent do you think ai and explainable ai may

56:31.200 --> 56:39.440
reduce or undermine the use or development of domain specific languages uh sorry i

56:39.440 --> 56:47.920
lost the second part of the question so do i think the ai and explainable ai reduced the use

56:47.920 --> 57:00.000
of domain specific languages um well i don't think they actually i i'm not quite sure uh

57:00.000 --> 57:08.320
whether by domain specific language uh yeah we mean the domain specific representation

57:08.320 --> 57:17.200
or so the main ontologies but i don't think they actually uh reduce it or at least i don't think

57:17.200 --> 57:26.160
they should reduce it somehow um i see more an integration of the two in the sense that uh

57:26.160 --> 57:34.160
the the the same way uh there are these methods that use so you i've seen methods using domain

57:34.160 --> 57:41.520
specific ontologies to um come up with maybe decision trees about the an explanation that is

57:41.520 --> 57:49.920
being generated so they um uh the advantage of domain specific language is still that they are

57:50.880 --> 57:56.960
highly they're curated by by the experts and so they are still more reliable so the two methods

57:56.960 --> 58:05.440
should kind of uh i don't i don't want to think of uh of explainable ai methods as taking over

58:05.440 --> 58:12.080
but rather to try to uh complement to to to combine the two or in a in a neuro symbolic fashion

58:13.840 --> 58:24.400
i hope this answer the questions uh hi yeah i hope so too um speaking of maybe maybe this

58:24.400 --> 58:30.960
this goes one into the direction of one of the questions that uh that i uh noted um so if we

58:30.960 --> 58:35.520
have if you have a domain specific language or a domain specific may of modeling things

58:35.520 --> 58:44.800
then this allows to very uh concisely write down things for a specific domain um previously one

58:44.800 --> 58:54.160
of your explanation methods you use something that like was looking at graph uh the distance in the

58:54.160 --> 58:59.600
graph right and if you change like if you have something very good for one domain then that

58:59.600 --> 59:07.440
obviously changes the the the distance in the graph so maybe you can reflect a little bit on how

59:08.080 --> 59:14.800
the graph structure or the role of how model how things are modeled or how much entailment is

59:14.800 --> 59:23.840
applied on on the graph changes the the the distance or the results of your approach

59:24.800 --> 59:31.600
yeah so i think um in general this is the kind of problem we try to to to approach

59:34.800 --> 59:40.960
both so with uh say with a with a follow-up method so when we looked into

59:41.840 --> 59:46.880
uh trying to identify strong relationships but also trying to cope with the with the

59:46.880 --> 59:52.160
the inner bias of the information uh the assumption so we we've never dealt with

59:52.800 --> 59:58.480
knowledge graphs we created right so we always dealt with knowledge graphs that were created by

59:58.480 --> 01:00:04.320
others so the assumption was you might not find the information that that you might need and you

01:00:04.320 --> 01:00:10.320
need to so sometimes the the information is very well curated and sometimes this is not

01:00:10.320 --> 01:00:17.600
and somehow we need to find um a way to to to cope with this problem in order to be as general

01:00:17.600 --> 01:00:28.160
as possible so the my view is really that there is not a a universal way of so there is not a

01:00:28.160 --> 01:00:36.640
method that can can deal with both the most important thing is being able to um to cope

01:00:36.640 --> 01:00:40.560
with the problem and integrate it in the methods that you develop so you need to be aware that

01:00:40.560 --> 01:00:47.600
information might be missing and and you need to make sure that your method compensates for that

01:00:47.600 --> 01:00:53.440
this can happen inside the development of your method or as a postdoc it's like a posteriori

01:00:53.440 --> 01:01:01.840
step and and it can be as simple as i mean in the same view of the co-creation with the user it can

01:01:01.840 --> 01:01:07.840
be as simple as okay let's interact and see whether i'm missing some part of the information

01:01:10.640 --> 01:01:16.800
so so somehow one of the reasons why we had to look into the strength of the relationship was

01:01:16.800 --> 01:01:24.400
also because we were missing these and we had to find a strategy to to survive in the in this

01:01:24.960 --> 01:01:35.680
case okay um there's another question from ask kim star and uh they are asking what

01:01:35.680 --> 01:01:42.160
adaptions do you see for knowledge for for this whole set of approaches to deal with multimodality

01:01:44.320 --> 01:01:52.960
um sorry so the so you had so you had like there was this with the cat picture where there

01:01:52.960 --> 01:02:02.080
was some computer vision aspects in it um and maybe you reflect a bit on on multimodality when

01:02:02.080 --> 01:02:10.240
it comes so it's uh it's through that we've never uh it's the kind of knowledge graph we've been

01:02:10.240 --> 01:02:18.880
dealing with and and multi multi-modal knowledge graphs were not really um uh um that common at

01:02:18.960 --> 01:02:25.760
that time i think uh so so it's through that one aspect that would be interesting and maybe

01:02:26.640 --> 01:02:33.440
we kind of we didn't discuss this as as in the future step but it is in these days we are now

01:02:33.440 --> 01:02:41.680
talking about we hear much more about multimodal knowledge graphs we hear um also about knowledge

01:02:41.680 --> 01:02:47.120
graph that somehow try to integrate the physical words so like we deal with robots in some scenarios

01:02:47.120 --> 01:02:52.240
and we also have this problem of okay i have a knowledge graph that has to integrate both

01:02:52.240 --> 01:03:01.040
abstract concepts but also the physical word um so um uh i think it would be quite interesting to

01:03:01.040 --> 01:03:07.360
think on how to generate explanations that are multimodal in this sense uh this is one part of

01:03:07.360 --> 01:03:12.800
the answer in the sense that yes we didn't look into multimodal knowledge graphs and this it could

01:03:12.880 --> 01:03:20.800
change uh the other part of the answer is uh uh the explanation that we could generate

01:03:21.440 --> 01:03:27.680
so the kind of patterns that were coming out could also be patterns coming from from multimodal

01:03:27.680 --> 01:03:36.320
data so like the uh i dealt a lot with clusters of of of data points but these data points could as

01:03:36.320 --> 01:03:44.080
well be um uh paths of an image for example that will represent that will represent i don't know

01:03:44.080 --> 01:03:49.920
the ear or the the tail of the cut of this kind of thing so i didn't deal with that concretely but

01:03:49.920 --> 01:04:01.600
it could uh i i don't see why the method shouldn't work on um image uh labels uh with yeah with specific

01:04:01.600 --> 01:04:07.600
information that we might want to explain uh so that say with respect to multimodality there are

01:04:07.600 --> 01:04:13.040
these two parts so the the the original method would probably work also on data points coming up

01:04:13.040 --> 01:04:19.680
from multimodal data and then the multimodal knowledge graph we didn't look that much into it

01:04:19.680 --> 01:04:25.200
and it could be quite interesting to to look into multimodal explanation in this sense so that's

01:04:25.280 --> 01:04:35.360
okay thanks um so maybe as a as a last question jumping back to your history um and because this

01:04:35.360 --> 01:04:42.640
is the cost action on distributed knowledge graph where we uh care about distributed decentralized

01:04:42.640 --> 01:04:49.440
things so you you had this one approach that was based on dereferencing of your eyes and looking at

01:04:49.440 --> 01:04:57.920
things from from that perspective now um you kind of gave me the impression that you say okay now the

01:04:57.920 --> 01:05:03.440
person who developed the large language model did the web crawling for you but maybe you can say

01:05:03.440 --> 01:05:10.000
something like all the methods that you have developed in the meantime after you were done

01:05:10.000 --> 01:05:17.200
with dereferencing your eyes are they based on a global kind of view uh to i don't know generate

01:05:17.200 --> 01:05:22.880
embeddings and things um or would they still work in a distributed and decentralized setting

01:05:24.080 --> 01:05:33.200
i i guess as long as uh so the the embeddings are convenient because they can embed a lot of

01:05:33.200 --> 01:05:39.200
information in in a very small space and that's something that we didn't have so we had to come

01:05:39.200 --> 01:05:46.400
up with a different dereferencing opportunity but also we didn't want to deal with uh storing the

01:05:46.400 --> 01:05:50.960
graph because if you store the graph and you query it then you then you you need to know the

01:05:50.960 --> 01:05:56.640
data model and we didn't care about it so what we really cared about was this kind of serendipitous

01:05:56.640 --> 01:06:04.800
hope um i remember one of the first papers i i saw was um something all of also did on on on

01:06:04.800 --> 01:06:13.200
navigation query languages so that was quite quite quite related um so i think the the most

01:06:13.200 --> 01:06:21.280
important the the part that would still work is even in a distributed context is as long as you

01:06:21.280 --> 01:06:29.040
have connections or pointers to to from data to data then it's fine it doesn't really matter and uh

01:06:29.040 --> 01:06:36.000
and we we didn't care whether it was the web of data or it could have been the load and load

01:06:36.960 --> 01:06:44.160
stored in a in an hdt file um that was really not the the problem the main problem was uh

01:06:44.960 --> 01:06:50.720
what where is the irrelevant information uh how do i identify the the links between the

01:06:50.720 --> 01:06:56.480
between that and this is valid in any context do i whether i have the information centralized or

01:06:56.480 --> 01:07:02.240
decentralized i would say then i have really experimented with that so i can't tell but

01:07:02.400 --> 01:07:12.400
so good um yeah thanks for the answer um i don't have more questions from the youtube chat um

01:07:13.760 --> 01:07:20.640
with that i just want you to thank you again for the very nice talk and the very nice tna session

01:07:22.000 --> 01:07:28.480
before we close the stream i can only advertise the next talk on january the 31st at the same

01:07:28.480 --> 01:07:37.520
time as today by mayank um you can check out our website and find uh follow us on this thing

01:07:37.520 --> 01:07:44.400
formerly called twitter and of course you find all the recordings of our talk on our youtube channel

