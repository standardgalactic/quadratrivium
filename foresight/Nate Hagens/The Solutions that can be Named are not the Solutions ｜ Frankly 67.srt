1
00:00:00,000 --> 00:00:07,000
That's a very polite way to say greetings in Chinese.

2
00:00:07,000 --> 00:00:17,000
You know, it would be great as an aside to have someone from China on the show to discuss

3
00:00:17,000 --> 00:00:23,000
the metacrisis and how China is thinking about and facing some of these things.

4
00:00:23,000 --> 00:00:29,000
So last week I had a frankly called the reality party.

5
00:00:29,000 --> 00:00:34,000
It was really my frustration looking at both parties in the United States,

6
00:00:34,000 --> 00:00:38,000
and I'm sure it's similar elsewhere in the world,

7
00:00:38,000 --> 00:00:45,000
not really talking about the core issues that we're going to be facing in the coming decade.

8
00:00:45,000 --> 00:00:50,000
And some of the feedback I got is what would a reality party stand for?

9
00:00:50,000 --> 00:00:54,000
What would be the solutions to the human predicament?

10
00:00:54,000 --> 00:00:58,000
What would be the policies that we would put forward?

11
00:00:58,000 --> 00:01:05,000
And today I want to talk about that and talk about specifically why I am not

12
00:01:05,000 --> 00:01:12,000
promoting certain solutions to what we face, at least not yet.

13
00:01:12,000 --> 00:01:16,000
And that is going to be the subject of today's frankly.

14
00:01:29,000 --> 00:01:33,000
Okay, so brief recap, the human predicament.

15
00:01:33,000 --> 00:01:41,000
We are supported by ancient sunlight and treating it as if it were interest.

16
00:01:41,000 --> 00:01:48,000
We currently have a 19-some terawatt global human metabolism,

17
00:01:48,000 --> 00:01:56,000
which is around 190 billion light bulbs worth of energy turned on 24-7.

18
00:01:56,000 --> 00:02:02,000
That is impacting the biosphere and its waste absorption capacity.

19
00:02:02,000 --> 00:02:08,000
We're overlaying this with monetary claims that continue to grow.

20
00:02:08,000 --> 00:02:10,000
We're in ecological overshoot.

21
00:02:10,000 --> 00:02:14,000
Climate change is just one of many risks to the environment,

22
00:02:14,000 --> 00:02:20,000
including novel entities and plastic and PFAS and species loss, et cetera.

23
00:02:20,000 --> 00:02:25,000
It's my belief and my 20 years of research has led me to believe that

24
00:02:25,000 --> 00:02:32,000
from 19 terawatts, we will hit 15 terawatts before we hit 25 terawatts.

25
00:02:32,000 --> 00:02:40,000
And we have a lot of things to do between now and then to make the future

26
00:02:40,000 --> 00:02:43,000
better than the default.

27
00:02:43,000 --> 00:02:47,000
On top of all that is the evolved human behavioral constraints

28
00:02:47,000 --> 00:02:52,000
and predilections of modern Homo sapiens.

29
00:02:52,000 --> 00:02:56,000
So with that as the general problem statement,

30
00:02:56,000 --> 00:03:02,000
and there's 200 hours of content on this site that unpacks the statements I just made,

31
00:03:02,000 --> 00:03:06,000
with that as a general problem statement, what are the solutions?

32
00:03:06,000 --> 00:03:08,000
What are the policies?

33
00:03:08,000 --> 00:03:10,000
What should we do?

34
00:03:14,000 --> 00:03:19,000
So first I would, as I said last week, there are no solutions, right?

35
00:03:19,000 --> 00:03:22,000
There are solutions to a problem.

36
00:03:22,000 --> 00:03:25,000
What we face is a predicament.

37
00:03:25,000 --> 00:03:31,000
And predicament, there are responses and things that would make it better than the default.

38
00:03:31,000 --> 00:03:38,000
So I really don't like talking about solutions, but it's quite a common word.

39
00:03:38,000 --> 00:03:44,000
How do we think about solutions mitigation to what I call the human predicament

40
00:03:44,000 --> 00:03:46,000
or the great simplification?

41
00:03:46,000 --> 00:03:54,000
Okay, so first of all, the responses to the great simplification are not simple.

42
00:03:54,000 --> 00:03:55,000
They are complex.

43
00:03:55,000 --> 00:04:03,000
So first of all, the categories of the interventions would fall into three broad areas.

44
00:04:03,000 --> 00:04:08,000
One would be using Marvin Harris's framework, the superstructure,

45
00:04:08,000 --> 00:04:15,000
which is the ideas and the values and the beliefs and the memes and the stories and the narratives.

46
00:04:15,000 --> 00:04:24,000
Another category would be the structure or what Daniel Schmackenberger and I have started to refer to as the social structure,

47
00:04:24,000 --> 00:04:32,000
which is our laws and our rules and our economic ways of transacting goals, etc.

48
00:04:32,000 --> 00:04:39,000
And underneath that is, of course, the infrastructure, which is our energy, our systems, our buildings,

49
00:04:39,000 --> 00:04:45,000
our environmental waste capacity, and all those things.

50
00:04:45,000 --> 00:04:50,000
So if we talk about solutions, which of those categories are we referring to?

51
00:04:50,000 --> 00:05:02,000
And then to put this in a two-dimensional space, those of you listening, those paying attention to the future,

52
00:05:02,000 --> 00:05:05,000
care about different scales.

53
00:05:05,000 --> 00:05:07,000
There's the individual scale.

54
00:05:07,000 --> 00:05:10,000
There's the local and regional scale.

55
00:05:10,000 --> 00:05:13,000
There's the national and global scale.

56
00:05:13,000 --> 00:05:18,000
And then to make it three-dimensional, there's the time aspect,

57
00:05:18,000 --> 00:05:26,000
which is the pre-crisis time, which is now to whenever there is a financial or geopolitical cascade,

58
00:05:26,000 --> 00:05:31,000
which could be very soon or we could have a decade before that happens.

59
00:05:31,000 --> 00:05:44,000
That moment I call the bend versus break moment is how do we stabilize the system and keep it going at a less complex, smaller scale.

60
00:05:44,000 --> 00:05:50,000
And then the third timeline is 20 years from now, 30 years from now, 40 years from now, what are the technologies,

61
00:05:50,000 --> 00:05:58,000
ways of living with each other and with nature, governance models, etc., for the longer term.

62
00:05:58,000 --> 00:06:06,000
So that's kind of a three-dimensional view of how we might think about the solution space.

63
00:06:06,000 --> 00:06:11,000
But then if we even took one of those cubes, we could extrapolate it even wider.

64
00:06:11,000 --> 00:06:13,000
There are different sorts of people.

65
00:06:13,000 --> 00:06:18,000
Of course, the world has 8 billion people in wildly different circumstances.

66
00:06:18,000 --> 00:06:25,000
But even the people watching this show, they might have a lot of resources or no resources.

67
00:06:25,000 --> 00:06:38,000
They might have a lot of social capital and friends and networks or just be by themselves in their off-the-grid home in British Columbia or something.

68
00:06:38,000 --> 00:06:43,000
So people's circumstances, high to low.

69
00:06:43,000 --> 00:06:52,000
Also, people might be living in a different culture that is not fully complexified.

70
00:06:52,000 --> 00:06:55,000
There's the global north where I live near Minneapolis.

71
00:06:55,000 --> 00:06:57,000
Things are incredibly complex.

72
00:06:57,000 --> 00:07:02,000
But also, I gave a presentation last week to a bunch of NGO leaders in India.

73
00:07:02,000 --> 00:07:07,000
India has not yet fully complexified, which is an advantage to them.

74
00:07:07,000 --> 00:07:16,000
The options available to someone living in India is to kind of resist the siren song of conspicuous consumption in the global north.

75
00:07:16,000 --> 00:07:24,000
And they have actually less degrees of freedom on the climate standpoint, but more degrees of freedom on how they organize things.

76
00:07:24,000 --> 00:07:31,000
And lastly, in this second Rubik's Cube, is what you care about.

77
00:07:31,000 --> 00:07:39,000
A lot of listeners to this show care about other species and Earth's ecosystems and future generations.

78
00:07:39,000 --> 00:07:45,000
Others just care about social justice and inequality.

79
00:07:45,000 --> 00:07:53,000
Others care about local resilience and the economy where they live.

80
00:07:53,000 --> 00:08:09,000
So all of these things make it clear that there isn't a one-size-fits-all recommendation to people in the world or viewers of this program.

81
00:08:09,000 --> 00:08:17,000
So one of the things that I feel strongly about and the purpose that I'm, the reason I'm doing this, this work,

82
00:08:17,000 --> 00:08:25,000
is I think we have to avoid, have more people avoid being captured by wrong narratives that are dead ends.

83
00:08:25,000 --> 00:08:37,000
So in the sequence of being ecology, systems and energy blind, the very first step, and it is the most important step, is to understand what's going on.

84
00:08:37,000 --> 00:08:46,000
To understand how energy, money, technology and economic growth fit together, how we do these things to get the same neurotransmitters of our successful ancestors,

85
00:08:46,000 --> 00:08:50,000
and how this whole system has an environmental impact.

86
00:08:50,000 --> 00:08:54,000
That takes a lot of time, but it's very important to understand.

87
00:08:54,000 --> 00:08:56,000
And this is politically neutral.

88
00:08:56,000 --> 00:09:02,000
It doesn't matter who you vote for or what your value system is at this point.

89
00:09:02,000 --> 00:09:06,000
Just to understand it is integration of science.

90
00:09:06,000 --> 00:09:14,000
And no one including me knows all this stuff, but we're all learning and headed in that direction to understand the present.

91
00:09:14,000 --> 00:09:21,000
Because as my former guest at Conway said, we have to understand the present to understand the future and we don't.

92
00:09:21,000 --> 00:09:26,000
Beyond that, once we understand that's when your values come in.

93
00:09:26,000 --> 00:09:27,000
What do you care about?

94
00:09:27,000 --> 00:09:28,000
What do you feel?

95
00:09:28,000 --> 00:09:30,000
What is important to you?

96
00:09:30,000 --> 00:09:46,000
People that have followed me for 20 years or the last couple of years in this podcast know I deeply care about the natural world and the one and a half to two million known species and the up to 10 million unidentified species that have no say in our economic system.

97
00:09:46,000 --> 00:09:52,000
And I want to chaperone them as best as possible through the bottlenecks of the 21st century.

98
00:09:52,000 --> 00:09:59,000
I've concluded that we have to also help human systems navigate this bender break in order for that to happen.

99
00:09:59,000 --> 00:10:01,000
So that's my value system.

100
00:10:01,000 --> 00:10:11,000
I that comes across, I think in my podcast, but it's secondary for the work to have people understand what's going on.

101
00:10:11,000 --> 00:10:23,000
Then downstream from understanding and caring about something is the plans and the responses and the solution set and to figure out what your strategy is.

102
00:10:23,000 --> 00:10:30,000
And then downstream from that is engaging and executing your strategies.

103
00:10:30,000 --> 00:10:35,000
By far the most important thing on this podcast is the understanding.

104
00:10:35,000 --> 00:10:48,000
And I'm going to continue to say why I'm not going whole hog into the solutions, but this is one reason why.

105
00:10:48,000 --> 00:10:57,000
Another reason why is as soon as you have a specific solution, you have narrowed your audience dramatically.

106
00:10:57,000 --> 00:11:06,000
For instance, I've come up with and I will be articulating this later this summer, many categories of intervention interventions.

107
00:11:06,000 --> 00:11:09,000
There's regenerative agriculture and technology.

108
00:11:09,000 --> 00:11:15,000
There's what I call the real energy transition, which isn't transitioning to a type of energy.

109
00:11:15,000 --> 00:11:21,000
It's a transition on how we use energy and interact with others and with with our local ecosystems.

110
00:11:21,000 --> 00:11:28,000
There's Goldilocks technology, not too hot, not too cold, just right for a lower throughput future.

111
00:11:28,000 --> 00:11:30,000
There's advanced policy.

112
00:11:30,000 --> 00:11:37,000
There's a new framework for philanthropy, which I may call capital in the service of life.

113
00:11:37,000 --> 00:11:39,000
There's different governance models.

114
00:11:39,000 --> 00:11:41,000
There's libraries of healing.

115
00:11:41,000 --> 00:11:44,000
These are all general categories.

116
00:11:44,000 --> 00:11:57,000
But once you get more specific than that, what if your audience is an engineer or a teacher or a celebrity or a college student or a college professor or a philanthropist or a farmer?

117
00:11:57,000 --> 00:12:03,000
There's different answers for each of those categories.

118
00:12:07,000 --> 00:12:15,000
Okay, another reason I don't talk about solutions is a delicate one.

119
00:12:15,000 --> 00:12:23,000
And I probably could say a lot more about this and I probably will already say too much.

120
00:12:23,000 --> 00:12:34,000
Human systems, the way we have a shared mind space around the world with the 8 billion humans or at least the billions that are connected to the Internet.

121
00:12:34,000 --> 00:12:37,000
Technology has accentuated this.

122
00:12:37,000 --> 00:12:44,000
This mind space functions very similar to systems in nature.

123
00:12:44,000 --> 00:12:48,000
And there are adaptive systems, adaptive processes.

124
00:12:48,000 --> 00:12:54,000
There's a predator-prey-like relationship and things move very fast.

125
00:12:54,000 --> 00:13:00,000
To give a natural system analog, there are bivalves, which are like mollusks and clams.

126
00:13:00,000 --> 00:13:07,000
And the thickness of their shell is based on the predators around them that would be able to crush the shell.

127
00:13:07,000 --> 00:13:13,000
And if there are no predators that have strong jaws in their environment, they don't need to grow thick shells.

128
00:13:13,000 --> 00:13:16,000
Growing the thick shells is a waste of energy and resources.

129
00:13:16,000 --> 00:13:19,000
They only do that in response to things.

130
00:13:19,000 --> 00:13:22,000
And it's the same thing in human systems.

131
00:13:23,000 --> 00:13:30,000
You know, Bucky Fuller famously said, you can't change the existing system by fighting it.

132
00:13:30,000 --> 00:13:33,000
You have to create a new system that makes the old system obsolete.

133
00:13:33,000 --> 00:13:35,000
He didn't believe that.

134
00:13:35,000 --> 00:13:45,000
He was a military contractor that did the due lines and the Arctic for the domes to protect the ICBM nuclear missiles.

135
00:13:45,000 --> 00:13:47,000
He was the contractor for those domes.

136
00:13:47,000 --> 00:13:56,000
He couldn't come out and say, you know, fight the existing system because then there would have been an immediate adaptive response to that.

137
00:13:56,000 --> 00:14:02,000
And he would have, you know, lost status and the voice that he had.

138
00:14:02,000 --> 00:14:05,000
Countless examples like that.

139
00:14:05,000 --> 00:14:10,000
9-11, no one knew that you could hijack planes.

140
00:14:10,000 --> 00:14:14,000
Osama bin Laden figured it out and it was adaptive response.

141
00:14:14,000 --> 00:14:23,000
But the response in counter to it happened really fast because I think it was the third plane on their cell phones.

142
00:14:23,000 --> 00:14:26,000
People knew that you were, they were doing this.

143
00:14:26,000 --> 00:14:28,000
So they no longer allowed that to happen.

144
00:14:28,000 --> 00:14:32,000
And the passengers attacked the pilots.

145
00:14:32,000 --> 00:14:35,000
And that's why the plane didn't hit the White House.

146
00:14:35,000 --> 00:14:44,000
So all of the information out there is very quickly adapted to and responded to.

147
00:14:44,000 --> 00:14:52,000
And so the real solutions to the Meta crisis will not be televised and they will not be popular either.

148
00:14:52,000 --> 00:15:00,000
So it's, it's good to talk about the framework that we face.

149
00:15:00,000 --> 00:15:13,000
And so people don't buy dumb narratives like net zero by 2050 with continued economic growth, but it will never be a thing that the solution set to the Meta crisis is outlined publicly.

150
00:15:13,000 --> 00:15:24,000
You know, in a subset of that, that's not the adaptive nature of it is the universe of socially acceptable solutions.

151
00:15:24,000 --> 00:15:33,000
And then there's a universe of effective solutions and how much that overlap is is probably not huge.

152
00:15:33,000 --> 00:15:44,000
So and then on top of that, we've got climate change and economic growth and poverty and inequality and biodiversity and all these concentric circles.

153
00:15:44,000 --> 00:15:49,000
There's some overlap with some of them, but there's no overlap of all of them.

154
00:15:49,000 --> 00:15:53,000
And how do we manage for that?

155
00:15:55,000 --> 00:16:05,000
A deeper, more tangible example of this adaptive ceiling that I mentioned.

156
00:16:05,000 --> 00:16:13,000
I've been blessed with this podcast to come across a lot of humans who are working on fantastic things.

157
00:16:13,000 --> 00:16:31,000
I met someone recently who is working on existing language that when a wetland gets bulldozed over for a new Walmart or something, that community has to procure a new wetland somewhere in the world.

158
00:16:31,000 --> 00:16:40,000
And this person is is working on the language to make that scalable in all communities in Canada and the United States.

159
00:16:40,000 --> 00:16:51,000
Another person I know has individually conserved millions of acres in South America of biologically sensitive land.

160
00:16:51,000 --> 00:17:06,000
These people, I want to highlight them on the podcast, not to say, hey, go do this, but to say, hey, wow, look at all these things that can be done, but they don't want to come on the podcast because if they explain what they're doing,

161
00:17:06,000 --> 00:17:13,000
that creates an adaptive counter response from people that don't share their values and don't want those things to happen.

162
00:17:13,000 --> 00:17:17,000
So it actually causes their special sauce to dissipate.

163
00:17:17,000 --> 00:17:27,000
The one example that I have had on the show is my colleague and friend, DJ White, one of the early Green Peacers and the founder of Earth Trust.

164
00:17:27,000 --> 00:17:33,000
He successfully stopped the only drive kill of dolphins in history.

165
00:17:33,000 --> 00:17:35,000
It's over 30 years ago.

166
00:17:35,000 --> 00:17:51,000
And I think the reason he shared why he did it and how he did it is because all the people in the Taiwanese government that were involved in that, which he wasn't allowed to tell anyone that was part of the agreement are no longer alive.

167
00:17:51,000 --> 00:17:59,000
The point is that there will be an in service of life underground movement.

168
00:17:59,000 --> 00:18:07,000
There will be things going on that are responses and mitigations to the problems we face that no one knows about.

169
00:18:07,000 --> 00:18:12,000
And hopefully some of you listening to this will do that.

170
00:18:16,000 --> 00:18:18,000
That leads me to policy.

171
00:18:18,000 --> 00:18:25,000
One of the policies that knowing about the human predicament and the great simplification we could do.

172
00:18:25,000 --> 00:18:38,000
Well, on the surface level, there are some generic policies that would just generally be good ideas like term limits or age limits or getting the money out of politics.

173
00:18:38,000 --> 00:18:48,000
Most of the things that I'm talking about are not only in the future, but to avoid these things from happening, the policies that we're voting for exactly the opposite direction.

174
00:18:48,000 --> 00:19:04,000
So one of the things that I started a couple of years ago, and I've spoken to around 25 senators, governors, congressmen is the concept of advanced policy, which is those things that we will have to do in the coming decade,

175
00:19:04,000 --> 00:19:17,000
but that are socially and politically too advanced to be accepted by the current political zeitgeist.

176
00:19:17,000 --> 00:19:28,000
But we still need to do them to build research to do scenario planning to build constituency to create break gas glass plans.

177
00:19:28,000 --> 00:19:43,000
I did some of that with some agencies of the US government back in 2014, but those aren't online, obviously, because talking about them makes them become self fulfilling prophecies or removes their potential effectiveness.

178
00:19:43,000 --> 00:20:00,000
This is a long way of saying that solutions aren't going to just be listed 123 and followed linearly.

179
00:20:00,000 --> 00:20:10,000
I think the last reason that I don't talk about solutions is probably the most salient one, which is truly I don't know.

180
00:20:11,000 --> 00:20:14,000
I think it's clear to you all what I care about.

181
00:20:14,000 --> 00:20:16,000
I am learning along with you.

182
00:20:16,000 --> 00:20:29,000
It's one of the blessings of unexpected blessings of this podcast is I've come across so many really smart caring people who share my value systems and I'm learning along with you.

183
00:20:29,000 --> 00:20:39,000
And so, you know, if you go to a doctor and you're sick, the doctor will diagnose you and give you a pill or do a surgery.

184
00:20:39,000 --> 00:20:46,000
If you go to an auto mechanic and he or she will tell you what's wrong with your car and then they'll fix it.

185
00:20:46,000 --> 00:20:53,000
Describing the great simplification doesn't qualify me or anyone to then know what to do.

186
00:20:53,000 --> 00:20:55,000
I'm trying to describe it.

187
00:20:55,000 --> 00:21:10,000
And it's my hope that there is a collective learning and a change in the conversation that creates emergent ideas, emergent responses.

188
00:21:10,000 --> 00:21:21,000
So my main goal now is to paint the picture as clearly as I can myself and then get different aspects, different angles of it from my guests.

189
00:21:21,000 --> 00:21:25,000
To further complicate things is we don't know what future is going to arrive.

190
00:21:25,000 --> 00:21:33,000
There could be the AI, more boost in productivity, more door economy where we have more growth and more environmental impact.

191
00:21:33,000 --> 00:21:35,000
There could be the great simplification.

192
00:21:35,000 --> 00:21:39,000
This financial Wiley Coyote moment I've been talking about or there could be a collapse.

193
00:21:39,000 --> 00:21:43,000
So how do we plan for those scenarios?

194
00:21:44,000 --> 00:21:53,000
I at this point don't think that I'm trying, I mean, although pro-social prepping is one of the categories I think is important.

195
00:21:53,000 --> 00:21:56,000
This isn't just a prepping channel.

196
00:21:56,000 --> 00:22:05,000
There are other ones that exist and based on how my farm looks, you don't want to use me as an example on how to prep.

197
00:22:05,000 --> 00:22:24,000
I'm still trying to save the whole, you know, social system in a way that we can go to a kinder, gentler, more sapient economy that includes the other species and the value of ecosystem services into our value system.

198
00:22:24,000 --> 00:22:31,000
So I'm still trying to breathe life into that vision.

199
00:22:31,000 --> 00:22:36,000
I hope this answers questions that none of you even had.

200
00:22:36,000 --> 00:22:50,000
Actually, this feels important to me to describe what I'm trying to do and why a solution for the Metacrisis is kind of a unicorn or a carrot.

201
00:22:50,000 --> 00:22:54,000
And the reality is that's not how the world works.

202
00:22:54,000 --> 00:23:04,000
I have a very intense personal, frankly, hopefully on deck for next week about my family.

203
00:23:04,000 --> 00:23:10,000
So until then, Womansajianba. Talk to you next week. Bye-bye.

