WEBVTT

00:00.000 --> 00:28.000
So, let me start a little bit with the introduction of who Melanie Mitchell is.

00:28.000 --> 00:36.520
She is a Davis Professor of Complexity at Santa Fe Institute, and her research focuses

00:36.520 --> 00:42.360
on conceptual abstraction, analogy making, and visual recognition.

00:42.360 --> 00:48.440
She's done a couple of very popular and well-received books.

00:48.440 --> 00:54.860
The first one was Oxford University Press in 2009, Complexity, a guided tour.

00:54.860 --> 01:01.460
Her most recent book is Artificial Intelligence, a Guide for Thinking Humans, and I have to

01:01.460 --> 01:08.020
say that people who've talked about the Artificial Intelligence book have said some very, very

01:08.020 --> 01:09.980
good things.

01:09.980 --> 01:18.220
For example, we have Allison Gopnik, who says it's very intelligent, clear and sensible

01:18.220 --> 01:19.220
book.

01:19.220 --> 01:26.460
Jeffrey West at Santa Fe has said it's remarkably lucid, comprehensive overview.

01:26.460 --> 01:33.140
Sean Carroll, an astonishing intelligence, and John Paulus, who's been on the show,

01:33.140 --> 01:39.620
says that Mitchell sketches enough details and clever illustrations that one gets a good

01:39.620 --> 01:42.860
intuitive understanding of AI.

01:42.860 --> 01:51.140
So you have high praise from some of the titans of a number of different disciplines,

01:51.140 --> 01:54.740
and I think that's a good way to take the next step.

01:54.740 --> 02:04.600
The next step is I'm in conversation with someone who is familiar with at least three

02:04.600 --> 02:15.500
important domains, mathematics, physics, and computer science, as well as artificial

02:15.500 --> 02:22.920
intelligence, which I would put in as part of the computer science part of this.

02:22.920 --> 02:32.120
So I see from my research of your background is you really have excelled as an interpreter,

02:32.120 --> 02:38.880
as someone who's been able to translate between these domains.

02:38.880 --> 02:44.200
And as a result, we'll be looking a little later in the show about how your childhood

02:44.200 --> 02:53.640
reading and those books help you create this kind of ability to map and track other thought

02:53.640 --> 03:00.200
processes in other domains and make them accessible to ordinary people.

03:01.200 --> 03:10.400
Yeah, so we humans are all masters of analogy, even when we don't know it.

03:10.400 --> 03:16.200
So let's think about a kind of unconscious analogy.

03:16.200 --> 03:19.480
One example that I use is the notion of a bridge.

03:19.480 --> 03:21.280
We all know what a bridge is.

03:21.280 --> 03:25.800
We all drive across bridges or we walk across bridges, whatever, but we also talk about

03:25.800 --> 03:32.960
bridges like the bridging the gender gap, or the bridge of a song, or the bridge of

03:32.960 --> 03:41.960
my nose, or there's all kinds of ways in which these terms are used metaphorically or by

03:41.960 --> 03:46.800
analogy throughout language, even unconsciously.

03:46.800 --> 03:54.520
But this kind of ability we have to extend concepts in this metaphorical way, and it's

03:54.520 --> 04:01.920
not just bridge, you could do it with almost any concept we want to talk about, is, I claim,

04:01.920 --> 04:05.720
what gives us our unique kind of intelligence.

04:05.720 --> 04:15.240
It allows us to understand more and more abstract notions in terms of very physical notions.

04:15.240 --> 04:21.120
Like you just said, you know, she has sunny face, so we all instantly know what that means.

04:21.120 --> 04:26.480
And we know, we don't even think of it necessarily as a metaphor.

04:26.480 --> 04:31.560
It's just so, you know, I might say, oh, you gave me such a warm introduction, you know,

04:31.560 --> 04:35.800
and it was, it wasn't literally warm, right?

04:35.800 --> 04:41.040
The temperature in this room didn't literally go up, I don't think, but it's something

04:41.040 --> 04:45.480
that we all couch all of our abstract thinking in.

04:45.480 --> 04:50.520
And this is exactly what AI systems today are lacking.

04:50.520 --> 04:58.720
They can learn to recognize photos of bridges, but they can't make that extension and talk

04:58.720 --> 05:08.840
about, you know, a bridge between two people, you know, you and I, or you may be your bridgingness,

05:08.840 --> 05:13.280
the culture of science with the culture of humanities, or things like that.

05:13.280 --> 05:18.240
So that's fascinating to me, and that's what my research is on, is trying to understand

05:18.280 --> 05:26.120
how human concepts are formed, what kind of structure they have, and how we might give

05:26.120 --> 05:28.360
such a concept to a machine.

05:28.360 --> 05:37.800
Yeah, presumably we're some ways away from AI understanding it's raining cats and dogs.

05:37.800 --> 05:45.200
Or, or she has a heart of gold.

05:45.200 --> 05:51.360
I mean, yeah, we don't, we, one problem with talking about AI is that we, when we talk

05:51.360 --> 05:54.720
about understanding, we don't really know exactly what we mean.

05:54.720 --> 05:57.760
What is it to understand something?

05:57.760 --> 06:03.160
That's actually been debated quite a bit by philosophers for millennia.

06:03.160 --> 06:06.320
And it's really an unanswered question.

06:06.320 --> 06:11.760
It's one of those words we use to describe our mental state that we don't quite understand

06:11.760 --> 06:13.920
scientifically what it means.

06:14.000 --> 06:21.720
I think in terms of kind of the sort of intuitive understanding we have of that notion, you're

06:21.720 --> 06:26.280
absolutely right, machines don't have the same kind of understanding of language that

06:26.280 --> 06:28.080
we humans have.

06:28.080 --> 06:37.240
I'm wondering as well if part of that issue has to do with, you've written about GPT-3

06:37.240 --> 06:40.440
making a knowledges in medium.

06:40.440 --> 06:46.680
And you've said that with metaphors there isn't a right answer.

06:46.680 --> 06:51.400
There's an effective explanation or description that convey information.

06:51.400 --> 06:55.760
It's really a conveyor from the abstract to the concrete.

06:55.760 --> 07:02.200
But it's not, you can't really say it's 100% right.

07:02.200 --> 07:04.400
It can be close to right.

07:04.400 --> 07:12.440
What goes back to what you were talking about a moment ago is how we understand that transition

07:12.440 --> 07:17.360
from the abstract into something that's concrete.

07:17.360 --> 07:24.560
Is it giving us with that similarity a true representation from what the abstract really

07:24.560 --> 07:25.560
means?

07:25.920 --> 07:36.520
Yeah, it's machines, they've been shown to be what people in AI call very brittle, meaning

07:36.520 --> 07:43.680
that they have this kind of appearance of being intelligent until suddenly something

07:43.680 --> 07:45.200
shows you very clearly.

07:45.200 --> 07:50.280
It's like it's a breaking point and that's why it's brittleness that they didn't understand

07:50.280 --> 07:55.320
at all what the language they were using meant.

07:56.080 --> 08:06.160
What of my favorite things I saw on social media some time ago was someone had taken

08:06.160 --> 08:12.400
an apple and written the word iPad on a piece of paper and put that on the apple with a

08:12.400 --> 08:20.920
rubber band and then ask an AI for questions or for answers to what this is and it said

08:20.960 --> 08:24.040
with 90% probability it's an iPod.

08:27.640 --> 08:38.920
So that kind of literalism, you can see it's part of that inability to deal with analogies

08:38.920 --> 08:39.920
and metaphors.

08:39.920 --> 08:47.640
And again, you've talked about in how analogies shape our thoughts, what happens if you strip

08:47.720 --> 08:54.480
away metaphors, simile, and analogies from language, what is left?

08:55.960 --> 08:58.040
Are we left just with abstractions?

08:58.040 --> 09:05.280
Is that the part of the problem that we have with storytelling AIs is that they lack the

09:05.280 --> 09:14.120
essential building blocks of how you tell a story, which basically is the bricks of that

09:14.200 --> 09:17.920
building of that story really are metaphorical, a lot of them.

09:19.120 --> 09:21.200
That's one of the problems for sure.

09:21.880 --> 09:25.880
Another problem is that AI systems don't understand how the world works.

09:26.680 --> 09:36.840
You know, they don't know that they don't know that, you know, if a child is holding

09:36.840 --> 09:42.520
an ice cream cone and then the ice cream cone falls on the ground, that that would be upsetting

09:43.320 --> 09:45.000
because how are they going to know that?

09:45.000 --> 09:47.960
They haven't experienced the world the way that we have.

09:48.840 --> 09:54.600
They don't even know that, you know, when an ice cream cone hits the ground that it's going,

09:54.600 --> 09:57.640
it's not edible anymore, and you wouldn't want to eat it.

09:58.440 --> 09:59.320
How would they know that?

10:01.000 --> 10:05.480
It goes back to what you've written about as well of saying that the problem with AIs,

10:05.480 --> 10:06.760
that lacks common sense.

10:07.720 --> 10:13.960
And common sense is if you drop the ice cream cone, even a four-year-old knows it's no longer

10:13.960 --> 10:22.600
something you want to eat or an AI system would not have that particular response because it's

10:22.600 --> 10:29.080
not an embodied biological entity that learns certain things about food from a very early age.

10:29.720 --> 10:30.760
That's exactly right.

10:31.720 --> 10:36.520
So that's the, you know, that's one of the big problems is how do you get a system like

10:37.560 --> 10:44.120
GPT-3 or any other AI system to get that kind of knowledge about the world that we all have,

10:44.120 --> 10:50.200
you know, as children, we all learn so much by just living and existing in the world.

10:50.920 --> 10:55.960
You know, part of what you've written that strikes me as very interesting as well is

10:56.920 --> 11:02.840
that a lot of the analogy making we have comes from an unconscious part of our brains.

11:03.400 --> 11:09.880
There was, when you start to think of analogies, they will come to you and if I ask, well,

11:09.880 --> 11:10.840
where did that come from?

11:11.800 --> 11:12.760
Probably don't really know.

11:13.400 --> 11:19.640
It's just, it's been triggered by some, some gesture, some thought, something that you're not

11:19.720 --> 11:21.080
really connected to.

11:21.080 --> 11:25.880
You can make up a story of why you access that, but it's just that.

11:25.880 --> 11:27.240
It's just a story.

11:27.240 --> 11:28.200
You don't really know.

11:28.840 --> 11:38.200
So AI does not have an unconscious matrix in which to draw upon to pull those analogies

11:38.200 --> 11:43.320
and metaphors from a huge reservoir.

11:43.960 --> 11:50.920
I mean, presumably that material for analogy making is as close to infinite as a human can

11:50.920 --> 11:51.400
get to.

11:52.200 --> 12:00.600
And as a result, it's very hard, I would think, to program into a computer intelligence

12:00.600 --> 12:07.160
an analogy making function because it goes much deeper than just being able to calculate

12:07.240 --> 12:14.440
precisely what the next best move is in chess or goal or Atari.

12:15.800 --> 12:16.040
Right.

12:18.120 --> 12:26.040
Our analogy making comes in part from the fact that we have this huge store of memories.

12:27.720 --> 12:32.520
And, you know, if you might, you probably have the experience where somebody tells you a story

12:32.520 --> 12:35.160
and you say something like, oh, the same thing happened to me.

12:35.880 --> 12:36.200
Yes.

12:36.200 --> 12:36.760
Right.

12:36.840 --> 12:41.320
And of course, the same thing literally didn't happen to you because you're not that other person.

12:42.120 --> 12:50.920
But you, something about their story triggers a memory that you somehow mapped on to the story

12:50.920 --> 12:55.000
that they just told you happens to us all the time every day.

12:55.000 --> 12:58.360
You know, someone says something about their life and you say, oh, yeah, me too.

12:59.160 --> 12:59.560
Right.

12:59.560 --> 13:03.240
And that's like, you know, you're making an analogy between their life and your life.

13:03.240 --> 13:05.080
And it's just constant.

13:05.080 --> 13:13.480
But it has to do with an interaction between our perceptual abilities, our memories, our pattern

13:13.480 --> 13:17.160
recognition facilities and so on.

13:17.160 --> 13:20.200
And this is something we haven't yet figured out how to give to machines.

13:20.920 --> 13:28.520
I'm wondering as well whether that exchange also falls under the heading of empathy,

13:29.080 --> 13:31.240
which is something a machine doesn't have.

13:31.240 --> 13:36.840
Is that you will say, oh, that's similar because you have a theory of mind about that person.

13:36.840 --> 13:43.720
You can put yourself in that position and see that as happening to you and that you would have

13:43.720 --> 13:49.400
had a similar response to a particular event or an object or a gesture.

13:50.440 --> 13:51.960
Yeah, that's absolutely right.

13:51.960 --> 13:57.880
And, you know, one of the things about humans is they're incredibly socially oriented,

13:58.600 --> 14:05.880
meaning that they're always trying to understand other people that they encounter from the earliest

14:05.880 --> 14:10.360
infancy and they're able to put themselves in the position of other people.

14:11.080 --> 14:20.680
So that's something that, again, is very human and so perhaps essential for intelligence.

14:21.400 --> 14:22.680
You know, we don't know.

14:22.680 --> 14:27.640
Usually AI people often think of intelligence as something kind of separable from

14:28.520 --> 14:33.080
things like empathy and emotions and it's pure rationality.

14:33.080 --> 14:39.240
But I think a lot of people are now trying to make sense of how the centrality of these

14:40.040 --> 14:44.360
or emotional aspects of our intelligence.

14:45.000 --> 14:51.320
Right. Well, what I'd like now to do with this background in terms of metaphors,

14:51.320 --> 14:59.640
analogies to move on to your reading list, which I hope that we'll be able to get into how

15:00.440 --> 15:08.440
this may have been a training set and education for you into the world of metaphor,

15:08.440 --> 15:10.840
simile and analogy making.

15:11.480 --> 15:16.440
So let's start with really your background, your first books.

15:17.080 --> 15:19.160
You're at home.

15:20.040 --> 15:24.920
Was the first books from your mother or your father or a sibling?

15:25.560 --> 15:30.920
I mean, how did you come to first have that book, that first book in your hand?

15:32.120 --> 15:33.160
The first book?

15:33.800 --> 15:41.640
Yeah. In other words, we look at the first book on the list, which is The Phantom Tooth Toe Book,

15:41.640 --> 15:43.800
which is an absolutely wonderful book.

15:43.800 --> 15:48.920
I'm so glad you chose that. I can't wait to get into it, but let's just start for a moment.

15:48.920 --> 15:54.440
And how did you come to have that book in your possession and how old were you?

15:56.440 --> 16:02.840
Wow. I was, I'm guessing I was about eight or nine, something like that.

16:03.960 --> 16:11.560
And I really don't remember at all how I got that book, who gave it to me or anything.

16:11.640 --> 16:19.400
Somehow it appeared, sort of like The Phantom Toe Booth in the book just suddenly appeared.

16:19.400 --> 16:20.600
No one knew where it came from.

16:23.400 --> 16:29.400
Did you grow up in a reading environment where your parents were reading or siblings were reading?

16:29.400 --> 16:33.880
And then that kind of storytelling from reading was kind of a natural

16:35.240 --> 16:39.000
bridge from one to the other. You're reading books, you're telling stories, you're reading books.

16:39.880 --> 16:52.360
Yeah. My parents both were avid readers and read to us from earliest childhood.

16:58.280 --> 17:03.640
I just, I can't remember any time when I couldn't read or didn't spend most of my time reading.

17:03.640 --> 17:09.080
So I loved reading as a child. I did too. That's why I'm doing this show.

17:09.640 --> 17:17.400
And I think that the people who have that experience or fortunate for a lot of reasons,

17:17.400 --> 17:27.080
because it does ground, I think, a person in the ability to be curious about stories,

17:27.080 --> 17:32.680
about other people's stories, and to learn from them and to apply that learning to new

17:32.760 --> 17:40.520
and novel situations. Which is, you know, basically that's so much of what you're doing as well is

17:42.200 --> 17:48.920
how do you deal with surprise? And how you deal with surprise is something that you can learn

17:49.560 --> 17:56.520
through the experiences of characters in books. You can see that experience is something,

17:56.520 --> 18:03.080
oh, that person was surprised. They reacted in this way. And that has the profound implication

18:03.080 --> 18:14.440
for your own feeling about security in the world, how I would react. So the phantom toll booth by

18:15.240 --> 18:24.120
Norton Justin, you know, he, he just recently died in March of this year at age 92.

18:24.360 --> 18:33.800
But he left behind this absolutely wonderful book. You know, there's the little bored boy named Milo,

18:34.920 --> 18:42.040
who's, you know, has this kit, which he has to assemble, which is toll booth. Comes with two toll booths.

18:42.040 --> 18:44.520
It just appears also. That was very, it's

18:45.320 --> 18:49.480
Magically, it's striking to me that this thing just appeared in his bedroom.

18:49.480 --> 18:50.040
Right.

18:50.040 --> 18:51.560
Where did it come from?

18:52.520 --> 18:57.720
Exactly. So that's the first question you're asking at eight or nine, right? It is,

18:58.440 --> 19:07.160
how did Milo end up with this kit in his room? So what does he do with that?

19:08.360 --> 19:14.600
He puts it together. He assembles it, right? So there's an immediately kind of an engineering

19:14.600 --> 19:21.640
puzzle making aspect to the book, which I almost, all the scientists I've talked to,

19:21.640 --> 19:30.040
there's some book like that. Here is a puzzle. If I put it together, what representation do I see?

19:31.560 --> 19:39.640
And so for Milo, he also has a little electric car. So once he's assembled the toll booth,

19:40.200 --> 19:49.000
he's got the map, the rules, two tokens, drops one in, takes off and starts driving. And

19:51.000 --> 19:57.720
I could see where your love and passion for metaphor and analogy would have started at eight

19:57.720 --> 20:05.560
or nine with this book. I mean, a dog's body shape like a cock, a watchdog.

20:06.280 --> 20:15.160
Right. That was another thing. It was all the word play and Hans was just so enchanting.

20:17.160 --> 20:23.880
So yeah, I mean, there you go. You're certainly starting to see that word play,

20:24.840 --> 20:34.680
a clock body for a dog, a watchdog, and then a bug that just brags and brags about its own

20:35.480 --> 20:44.840
abilities and claims, which aren't true, which is a humbug. And so Milo basically teams up with

20:44.840 --> 20:55.960
these two, doesn't he? The humbug and the watchdog to go on an adventure and they end up in the empire

20:55.960 --> 21:03.800
of wisdom. But the problem is there's no rhyme or reason. Right. The princesses.

21:04.760 --> 21:15.080
Exactly. The two sisters. Yes. So they set out for a quest to rescue them, right,

21:15.880 --> 21:25.240
and to bring the two sisters rhyme and reason back into the empire of wisdom.

21:25.400 --> 21:32.760
And again, part of the word play here, it's quite wonderful, is on their journey,

21:33.320 --> 21:40.120
you know, running into the mountain of ignorance where there's the ever present word snatcher,

21:41.560 --> 21:45.160
which is quite the person who's constantly interrupting them.

21:45.480 --> 21:56.200
The terrible triumphant, waste time doing unimportant and trivial tasks. The sense

21:56.200 --> 22:02.440
taker, the person who wastes time filling out countless wasteful forms to no particular end.

22:04.040 --> 22:12.920
So ultimately, they, they succeed, right? Milo. Oh, yes. The humbug, the watchdog. Yes.

22:13.320 --> 22:26.440
By rescuing the two sisters rhyme and reason. Now, what out of that, the phantom of toll booth,

22:27.080 --> 22:34.760
if you can kind of recreate what it was that in your mind as you read it as a child,

22:35.320 --> 22:40.440
how you process that. I mean, you're processing some things which were a kid could be a little bit

22:40.440 --> 22:48.680
maybe frightening, like demons. And some of the demons are described in quite vivid detail,

22:48.680 --> 22:55.080
long nose, green eyed, curly haired, wide mouth, thick neck, broad shoulder, round body,

22:55.080 --> 23:01.960
short arm, bow legged, big footed monster. That's the demon of insecurity or insincerity.

23:02.600 --> 23:10.760
Mm-hmm. Yeah. That, I mean, part of the book, I remember, were some wonderful illustrations

23:11.480 --> 23:17.480
by Jules Pfeiffer. Right. I mean, I didn't know who he was when I was, you know, that child, but I

23:17.480 --> 23:26.040
certainly knew him later on. And they were fantastically evocative and terrifying, some of

23:26.040 --> 23:34.280
them. I still remember that there was a man who had no face. I don't know if you saw that one,

23:34.280 --> 23:42.760
but that was a really terrifying thing. Right. Right. So it introduced a wordplay

23:42.760 --> 23:51.160
world and a visual world in between the covers of the same book. Yes. Yes. And there were, you know,

23:51.800 --> 23:58.920
I, there were two kind of two different cities. One was concerned with words and the other was

23:58.920 --> 24:06.360
concerned with numbers. Right. So that this kind of separation between sort of the world of numbers

24:06.360 --> 24:11.560
and the world of words was one that I think I already was starting to resonate with because

24:11.560 --> 24:20.040
I felt like I had sort of interests in both, in both of those worlds. That's, that's interesting. So

24:21.560 --> 24:28.280
here's a child book, The Phantom Toe Booth, which actually opens up

24:30.840 --> 24:39.560
a window to two different kinds of cultures. Mm-hmm. There's the culture of language and words,

24:39.560 --> 24:47.080
and then there's the culture of mathematics and numbers. And there's a, there are border lines

24:47.080 --> 24:54.360
between those, but here's an author who's able to cross those borders at will, going from numbers

24:54.360 --> 25:00.360
to representations, representations to numbers. That had to be a thrilling thing for you as a child.

25:01.720 --> 25:06.920
Yeah. I remember really, really being struck by that idea that these things were, you know,

25:07.640 --> 25:12.760
they were very separate and that, and there was this, you know, I, I'm sort of only vaguely

25:12.760 --> 25:18.120
remembering a lot of this book I have to admit, but that's one of the things that was striking to me.

25:19.320 --> 25:26.920
That's interesting. So this is a book that I presume you would recommend for, for parents and

25:26.920 --> 25:36.200
teachers and others, if you want to inspire a young person in the world of metaphor and

25:36.200 --> 25:44.840
analogies and mathematical objects, this is, this is a place to start because it, it is accessible.

25:46.200 --> 25:50.920
It's very accessible and kids, children love it. I, I read it to my own two children,

25:51.880 --> 25:59.240
many years ago. And they, I, I don't know if they loved it as much as I did, but I remember them

25:59.240 --> 26:05.880
that they, they, they found it quite amusing, all the word play and puns and everything.

26:06.760 --> 26:12.920
That's interesting. So the tradition of the first book on your list that you had as a child,

26:13.640 --> 26:18.680
you made a point of sharing that experience with your own two children

26:19.480 --> 26:25.320
in order to pass along, which you hope would be a similar kind of experience.

26:26.280 --> 26:30.840
Yeah. And I haven't asked them if they remember that book. I should ask them someday.

26:31.320 --> 26:40.200
No. I think it would be interesting to go back for parents to go back to children, particularly

26:40.200 --> 26:48.360
if they're late teens or early adults and say, do you remember when I, when we read this book

26:48.360 --> 26:54.200
together? Do you, do you have any memories of this? Did it have any impact on your life?

26:54.200 --> 27:02.680
Because it had an impact on mine. I was on a conversation with someone on a talk show

27:03.720 --> 27:07.160
where I talked about this book and I talked about you. Right.

27:07.560 --> 27:12.200
Full circle. Right. Y'all, I'll ask them.

27:14.520 --> 27:22.520
The next book, another wonderful selection is A Wrinkle in Time by Madeleine Naingal.

27:24.440 --> 27:29.560
Again, I'll give just a little bit of an introduction because I don't expect you to

27:29.560 --> 27:34.840
remember all the details of this. You've read a long time ago, but before I get to that,

27:34.840 --> 27:40.920
about what age were you when you read this? That one I remember because I, we read it in

27:40.920 --> 27:49.320
my fourth grade class, which is nine years old. Okay. So at nine years old, you're reading about a

27:49.320 --> 27:57.480
high school student named Meg Murray and her younger brother Charles Wallace and their friend

27:57.560 --> 28:04.200
Calvin O'Keefe. And basically it's a quest, right? Where the father who's a scientist

28:04.760 --> 28:13.480
has gone missing. He's disappeared. No one knows where he is for a year. And suddenly out of kind

28:13.480 --> 28:21.800
of nowhere, this is the magic of children's literature, someone arrives called Mrs. Wetzit.

28:22.680 --> 28:29.160
And Mrs. Wetzit is one of these creatures from another dimension

28:30.040 --> 28:37.480
who comes with information about the father. And she also has two friends,

28:37.480 --> 28:48.520
Mrs. Who and Mrs. Witch. So Mrs. Wetzit, Mrs. Who and Mrs. Witch become the guides

28:49.240 --> 28:55.320
for these three youngsters who are able to find a wrinkle in time, a pteroset,

28:56.680 --> 29:03.240
to be able to go into another dimension to follow the trail of the missing father.

29:04.920 --> 29:15.080
Now, so what we have then is this notion of searching for a parent, which is something I think

29:15.080 --> 29:20.680
all children can probably relate to. The father's missing. What can I do to find my dad?

29:21.320 --> 29:26.520
What help can I find? It goes back to your earlier point where social creatures,

29:27.240 --> 29:35.480
we seek other people around us that we trust to help us on our quest. This goes from the Lord of

29:35.480 --> 29:44.600
the Rings to a wrinkle in time. It's the same kind of dynamic. As you find your allies, those people

29:44.600 --> 29:49.960
that you've bonded with who see the world pretty much like you do, that will watch your back when

29:49.960 --> 30:02.680
you're going into the unknown. So what I like about the story is the secret weapon that Meg

30:02.680 --> 30:11.800
discovers through Mary's trials and tribulations of trying to find the father. And ultimately,

30:11.800 --> 30:20.840
she goes back to confront this dark AI kind of force, which is taken over and made everything

30:20.840 --> 30:35.080
the same and controls the mind of everyone within this AI's domain. Except Mrs. Wetzit says there is

30:35.160 --> 30:43.480
a secret weapon. You'll have to look deep in yourself and you'll find it. If you can find that

30:43.480 --> 30:52.760
weapon and you go back to this place and use it, you will be able to find and retrieve your father.

30:53.320 --> 30:54.680
Do you remember what the weapon was?

30:59.640 --> 31:06.360
Love. Yes, that's what I was going to say. Right. Yeah, it was a little corny there.

31:10.040 --> 31:19.080
But yes. Corny in a way, but on the other hand, very humanizing because it is, again, with that

31:19.080 --> 31:28.040
notion of self-sacrifice. And maybe that's something that we do well as humans, and maybe we should

31:28.040 --> 31:37.400
do better. But the real notion of love is that ability to sacrifice yourself for another. It's

31:37.400 --> 31:42.840
not necessarily just the romantic part of it. It's a self-sacrifice. And here's a daughter

31:42.920 --> 31:53.640
who is willing to self-sacrifice for her father that disabled the AI. AI was defeated at that point.

31:55.880 --> 32:04.920
Gosh, I don't even remember that it was an AI. Was it a machine? Well, I'm saying an AI. It's called

32:05.480 --> 32:13.800
it. Okay, I do remember that. Yeah. And it's, my notes here, all objects and places appear exactly

32:13.800 --> 32:23.480
alike because the whole planet must conform to the terrifying rhythm pulsation of it. A giant

32:24.040 --> 32:32.600
disembodied brain. Now, that seems to me to be a reasonably good description of for a child of

32:32.600 --> 32:42.840
what an AI is. This big disembodied brain, in this case, having a kind of super level of intelligence

32:42.840 --> 32:50.840
as opposed to the kind of AI intelligence that confuses a writing of iPod for an apple.

32:51.240 --> 33:04.360
Right. Yeah. I mean, the thing that for me that stands out in my memory about this book is,

33:05.560 --> 33:13.240
first of all, the female scientists, like both Meg and her mother. Her mother was a brilliant

33:13.240 --> 33:19.560
scientist. And I really, you know, I think this was one of the first books I had read or

33:21.320 --> 33:27.800
encountered that had such characters that had female scientists, people who are interested in

33:27.800 --> 33:35.720
science. And also this notion of multiple dimensions. That was sort of my first introduction to that

33:35.720 --> 33:41.640
idea of like the fourth dimension and this notion of a tesseract. And I remember that very clearly,

33:41.640 --> 33:48.520
that that, you know, explaining that this is a four dimensional cube. And it was just fascinating

33:48.520 --> 33:58.680
to me. I think that's exactly the kind of thing I was hoping to hear is that here's a book that

33:58.680 --> 34:09.480
opened up the role of genders. And that you could see for the first time as a child that women are

34:09.480 --> 34:19.000
as capable as men, and that women can be scientists, that they can also head up a quest and an

34:19.000 --> 34:29.800
adventure. It doesn't have to be a boy. It can be a girl who actually does all the hard work of

34:30.760 --> 34:38.200
putting together the team, charting the journey, assessing the risks, and ultimately finding the

34:38.200 --> 34:48.520
solution. So that must have made a bit of a change in terms of how you thought about your own

34:48.520 --> 34:55.720
potential as a young girl. It probably did. You know, I don't remember that explicitly, but I do

34:55.720 --> 35:03.400
remember, you know, very much identifying with the Meg character. And also just being very intrigued

35:03.400 --> 35:11.080
by her mother. Right. Because at that time, my own mother at that time was a housewife.

35:13.160 --> 35:20.600
My father was an engineer. I hadn't really encountered women doing being scientists.

35:21.400 --> 35:29.880
But maybe that's part of the real beauty of early reading is it provides multiple role models for

35:29.880 --> 35:36.600
children. Because when you grow up, your role models are your mom, your dad. Okay, I have a model of

35:36.600 --> 35:43.960
a man as an engineer, a model of a woman as a housemaker. And suddenly you're reading a book where,

35:44.600 --> 35:52.200
you know, there are other models out there. There are other kinds of things that people do, other

35:52.200 --> 36:03.560
kinds of identities that they're able to shape and create a life with. So that so that that book,

36:03.560 --> 36:10.920
I could see would be a quite important foundational one for your own kind of psychological development

36:10.920 --> 36:17.960
and perhaps confidence that yeah, there are some other roles out there for women other than which

36:17.960 --> 36:30.440
just what I'm saying around me. Yeah, definitely. Okay, so to leave the world of fiction for a moment,

36:30.440 --> 36:39.320
to look at the next book on your list, which is The Universe and Dr. Einstein by Lincoln Barnett.

36:39.320 --> 36:46.440
Now, I've heard you say on another webcast that you read this in high school, and it was responsible

36:46.520 --> 36:54.280
for you to pursue a degree in physics. Right, so that I absolutely I read that in high school.

36:54.840 --> 37:01.800
I think it was suggested by my physics teacher. And I absolutely loved it. You know, it was a

37:01.800 --> 37:10.520
popular exposition of Einstein's theory of relativity. It was fairly short, extremely

37:11.240 --> 37:20.920
clear and well written. And it just, you know, astounded me, these ideas. And the fact that you

37:20.920 --> 37:30.280
could just, you know, Einstein relied quite a bit on thought experiments, you know, what she

37:30.280 --> 37:38.280
called gedonkin experiments, where he didn't actually have a lab or, you know, be doing,

37:38.280 --> 37:42.600
you know, writing down lots of equations. But he was just kind of thinking about how things might

37:42.600 --> 37:49.320
work. And thinking, you know, well, what happens if the speed of light is constant?

37:50.040 --> 37:55.400
But what would that imply? And all of that was just very eye opening for me. And I decided I

37:55.400 --> 38:02.680
wanted to study physics in college. It's interesting. Again, I can see a little bit of a link here

38:02.680 --> 38:09.000
between the wrinkle of time, because he's dealing with other dimensions. And also, he's dealing with

38:10.680 --> 38:18.440
reasoning, not in a lab, but by way of analogy, by way of visualization. So he's using

38:18.440 --> 38:28.280
metaphors, and he's using concrete examples of trains moving in order for that thought experiment

38:28.280 --> 38:35.560
to allow, in which he's doing a reversal, he's using analogies as a reversal process

38:36.600 --> 38:48.040
to come up with an abstraction about an aspect of time, space, velocity, momentum, and

38:49.880 --> 38:57.160
to come up with the mathematics of the metaphors that he thought at his desk.

38:58.360 --> 39:04.200
Exactly. Yeah. So that was, that was quite, quite fascinating for me.

39:05.240 --> 39:11.240
So again, I think, you know, I can see this a little bit in your own work that you,

39:11.240 --> 39:17.880
you're able to see the metaphor making isn't just a translation of the hard mathematics.

39:18.600 --> 39:27.160
Einstein in this book, the universe, and Dr. Einstein, shows that it can go the other way as

39:27.160 --> 39:37.320
well. You can go from the childlike storytelling of multidimensions to creation of mathematical

39:37.320 --> 39:47.000
models that try to come up with a more abstract general way of explaining what a phenomenon is.

39:47.000 --> 39:57.640
Is that? Yes. Yeah. I mean, much later, I read another book, you know, now as an adult about

39:57.640 --> 40:06.600
Einstein, and it hypothesized that, you know, Einstein was a patent officer in Switzerland.

40:07.240 --> 40:10.680
And one of the things that people in Switzerland were trying to do at the time

40:11.640 --> 40:17.400
was, how do you synchronize clocks between train stations? Because this was an important

40:17.400 --> 40:22.120
thing to make trains, you know, be able to follow their schedule. So, so he was thinking about this

40:22.120 --> 40:29.320
extremely practical problem. But thinking about the implications of what does it mean to synchronize?

40:29.320 --> 40:37.720
What does it mean for time to be synchronized? And blowing that up into this incredibly profound

40:38.440 --> 40:47.640
truth about the universe and about time itself. So, you know, that's like, as you say,

40:47.640 --> 40:54.680
it's kind of the reverse metaphor. It's like he sees the very concrete thing of trains and

40:54.680 --> 41:03.720
synchronization and so on. And then he is able to expand that idea into something much more general

41:03.720 --> 41:10.680
and much more profound. You wonder if he had that kind of aha moment because, you know, the

41:10.680 --> 41:18.360
history of our species, you know, for 200,000 years would have been, we think of time as absolute,

41:19.160 --> 41:26.360
of spaces unchanging and absolute. And suddenly to have a thought, it's not absolute,

41:27.160 --> 41:34.280
it's relative. And to take that on the implications of that on, and I think we're,

41:34.280 --> 41:41.480
we're still trying to come to terms with the implications of what that means with time being

41:41.480 --> 41:51.240
relative. Because all of our earthly experiences prepare us for kind of an absolute, absolutist

41:51.320 --> 41:58.920
notion of time. And you're someone who challenged what is probably one of the bedrock notions

42:00.040 --> 42:06.840
that most people have. And I can see you're in high school now, and you're thinking,

42:07.800 --> 42:15.080
if time can, is not absolute and can be challenged, what else is there in physics

42:15.080 --> 42:22.920
that will allow me to do similar kinds of challenges to what are basic understandings of

42:22.920 --> 42:27.960
the world, which work on one level, but are fundamentally incorrect?

42:31.480 --> 42:40.120
Yeah, I don't know if I was thinking all that, but yeah, I didn't, yeah, I was trying to just get

42:40.120 --> 42:49.960
my mind around that, that whole very counterintuitive ideas. Yes, yes. So by the time you're in high

42:49.960 --> 43:01.960
school, you've decided that physics is the career path that you wanted to take. And you've, you've

43:01.960 --> 43:08.760
said that this, this particular book is one of the books that probably was influential in setting

43:08.760 --> 43:18.680
you on that path. Yes. So again, I think it shows childhood reading has enormous implications,

43:19.880 --> 43:25.880
because what it does is it starts a train of thought, and that train of thought leads people

43:25.880 --> 43:32.520
into a direction which they may not have otherwise taken, but for having come across to read that

43:32.520 --> 43:35.480
book. Absolutely. Yes.

43:39.400 --> 43:49.320
The next book, Fads Balaces in the Name of Science by Martin Gardner. I hadn't been familiar with

43:49.320 --> 43:57.000
this book, but it's an absolutely timely book to, to discuss. I mean, this is pre-internet,

43:57.000 --> 44:08.200
pre-fake news, you know, pre silos on Twitter and Facebook and the rest of it. He's taking on

44:08.920 --> 44:18.760
the whole kind of area of quack remedies, of cranks, and how cranks have, you know, historically been

44:18.760 --> 44:24.520
able to get quite a good audience. They didn't need social media to come along to give them an

44:24.840 --> 44:32.280
audience. I mean, now that has been quite effective, but before they had publishers

44:33.320 --> 44:40.280
that were quite willing to publish their books because there was an audience for what cranks

44:41.480 --> 44:45.160
had to say, even though it was clearly wrong.

44:45.560 --> 44:56.040
So, tell me a little bit about what age you were and the circumstances of coming across this book.

44:58.840 --> 45:06.360
So, I think I was in college. I don't quite remember, but I loved Martin Gardner. You know,

45:06.360 --> 45:14.200
he was a long time columnist for Scientific American. He was an incredible communicator

45:15.240 --> 45:25.480
of math. He was a math puzzle fanatic and a math puzzle creator and a wonderful writer,

45:27.320 --> 45:34.440
just super playful person interested in all kinds of things. So, I had been reading, you know,

45:34.440 --> 45:42.120
I read his column and I picked up, I guess I picked up this book and found it really just,

45:42.120 --> 45:49.560
you know, thinking about what drives people to believe things and sort of, and as you say,

45:49.560 --> 45:57.880
it's very relevant now is sort of, what is science? Why do we believe science? What is

45:57.880 --> 46:04.840
different between science and all these kind of quack beliefs? And that's something, you know,

46:04.840 --> 46:10.680
I think we all still struggle with. I think it's probably right. I mean, one of the things that

46:10.680 --> 46:19.640
seemed to me from my reading of the book is the central role that Gardner thought that the

46:19.640 --> 46:26.120
scientific community played. And again, it goes back to that kind of social role that we are

46:26.920 --> 46:36.520
social people and that we learn from each other. And usually, he says the crank is someone who's

46:36.520 --> 46:43.800
almost always outside the scientific community. They don't have colleagues to bounce the ideas off

46:43.800 --> 46:48.680
and not going to conferences, listening to other people's papers. They're not presenting their

46:48.680 --> 46:58.440
papers for peer review or for comment by other people. And as a result, it's easy to get off

46:58.440 --> 47:05.800
the rails because there's no one to say you're off the rails. Right. And they get these cult

47:05.880 --> 47:18.120
followings where they get reinforced, you know, people people are believing them. And he said that

47:18.120 --> 47:28.840
there are really a couple of signifiers for a crank is one of them is that person stands entirely

47:28.840 --> 47:35.080
outside the closely integrated channels through which new ideas are introduced and evaluated.

47:35.800 --> 47:44.120
And secondly, as a tendency to paranoia. But I think one of the things that people may say

47:44.120 --> 47:52.280
is, well, the scientific community is not that perfect. That maybe some of the grants and the

47:52.280 --> 47:59.880
money that comes from them are twisting the dogma in ways that favor the people who are funding

47:59.880 --> 48:06.600
studies and so forth. And therefore, can we really trust dogma that's coming out of a scientific

48:06.600 --> 48:21.560
community that is not as pure science as we would wish it to be. Sure. And science is done by humans,

48:21.560 --> 48:27.000
right. And humans have their own prejudices and biases and

48:29.000 --> 48:34.680
influences. And it's just a human endeavor. But what we do have in science is we have

48:35.800 --> 48:43.160
replication, we have, you know, community sort of think things are wrong all the time. But

48:43.160 --> 48:51.480
eventually, people discover that they're wrong. We have kind of this notion of consensus.

48:52.200 --> 48:57.320
There's certain things that are consensus, eventually, in the scientific community. And

48:58.280 --> 49:05.560
that those consensus, the consensus believe can eventually be overturned. But it's,

49:06.280 --> 49:18.280
it's, it is a community. And I think, you know, it has, I don't know how to say this,

49:20.920 --> 49:26.600
why should we trust scientists as opposed to anyone else? It's because I think scientists

49:28.120 --> 49:34.280
are, I mean, part of the deal of being a scientist is that you're always trying to disprove your own

49:34.280 --> 49:41.880
work. And you try as hard as you can. And that's the fundamental thing. You always are trying to be

49:41.880 --> 49:48.760
skeptical of everything in your own work. And if you pound on it and pound on it and people

49:48.760 --> 49:54.280
replicate it and replicate it, finally you come to as close as you can to what you might call

49:54.280 --> 50:02.360
verification. So yeah, I mean, it's perfect for sure. That's a very good description. I mean,

50:03.320 --> 50:10.360
I think in terms of sciences, also it creates a cultural, cultural aspect of thinking,

50:11.080 --> 50:17.480
where scientists tend to be comfortable with uncertainty, at least more comfortable than

50:17.480 --> 50:24.520
most people, because they understand that even the existing dogma is a tentative position.

50:24.520 --> 50:31.320
It's not yet disproved. There will be flaws in it, in that every time someone thinks they've come

50:31.320 --> 50:39.000
up with an absolute answer, they've usually found out that that's not the case. And so there is more

50:39.000 --> 50:47.480
of a humility. I mean, you have some big eagles in science, as you would expect. But the idea is

50:47.480 --> 50:56.920
to be humble in the face of new changing information that requires constant revaluation

50:57.080 --> 51:05.240
and updating, where the people who are the cranks have the absolute truth. There is no updating

51:05.240 --> 51:12.600
that is needed. It's all defense of the existing structure. The structure is perfect,

51:13.240 --> 51:21.480
it can't be improved upon, and you either believe this or you don't. You're either part of our

51:21.480 --> 51:27.240
belief system or you're not. That, it seems to me, is very anti-scientific.

51:30.600 --> 51:37.400
So the book by Gardner, and his books have appeared on the list of other guests as well.

51:37.400 --> 51:44.040
He's someone who's had, I think, a profound influence in terms of educating a whole

51:45.000 --> 51:51.720
couple of generations of thinkers and mathematicians and physicists and artists and others who

51:52.760 --> 51:59.400
want to look deeply at those kinds of ways of thinking and processing reality.

52:00.120 --> 52:06.360
And science is just a different way of processing reality through investigation,

52:06.360 --> 52:14.680
observation, testing, reevaluation, and understanding that no matter what the result

52:14.680 --> 52:20.440
appears to show today, it may be overturned in the next week.

52:22.440 --> 52:29.000
I think one other thing you can say about Martin Gardner is that he was an incredible

52:29.560 --> 52:40.600
expositor of science and math, and kind of was a model for me, myself, of trying to write

52:40.600 --> 52:46.600
for the general public about science. How do you make things clear? How do you make things

52:46.600 --> 52:54.280
entertaining? How do you make things accessible? I'm glad you mentioned that, because the reviews

52:54.280 --> 53:02.680
of your books, all point to the fact that you've done this with enormous success, is to be able to

53:02.680 --> 53:11.400
use those metaphors and analogies to go from the very hard mathematical world of pure science

53:11.960 --> 53:18.760
into another language that most people can understand and relate to. That's a very

53:18.760 --> 53:25.720
particular skill. It's a little bit like translation. Where I live, translation is a very

53:25.720 --> 53:34.920
important aspect of life, and you get people who are, say, bilingual, but as I say, there's a

53:34.920 --> 53:42.120
difference between being bilingual and bicultural. To know another language is not necessarily to

53:42.120 --> 53:50.200
know that culture. You are bilingual and bicultural, and that's a real advantage, and I think someone

53:50.200 --> 53:58.600
like Martin Gardner was like that as well, who understood both cultures and understood the

53:58.600 --> 54:02.920
language and the barriers of communication between those cultures.

54:11.400 --> 54:20.920
Just for the people watching, some of the chapters in this book by Martin Gardner

54:20.920 --> 54:28.760
on fads and fallacies, he takes on the flat earth people, the hollow earth, I hadn't heard that one

54:28.760 --> 54:41.640
before, monsters of doom, flying saucers, down with Einstein, dousing rods and doodle bugs, geology

54:41.640 --> 54:52.520
versus Genesis, Atlantis, the Great Pyramids, medical cults, from homeopathy to natural

54:52.520 --> 55:04.760
apathy, and food fattice, so dynetics. He covers a fair range of the traditional kind of cult-like

55:05.480 --> 55:11.720
absolutists, fad friends that a lot of people were attracted to.

55:13.480 --> 55:21.400
Still are, in some cases. It still are, and as a result, maybe this is a book that has to be

55:22.200 --> 55:32.440
updated for modern times, because social media now is the main vehicle through the internet

55:33.160 --> 55:42.200
of being able to create these kinds of pseudoscientific communities which they talk to each other and

55:42.200 --> 55:49.080
reinforce each other, but they're reinforcing basically a highly flawed, mistaken view of

55:49.080 --> 55:57.080
reality. So the question is, how do you reach them? Martin Gardner's book reached you and probably

55:57.080 --> 56:02.840
reached a lot of people of your generation, but the question is, for the new generation,

56:04.040 --> 56:12.760
it will this book be one that will allow them to have a different window on social media once

56:12.760 --> 56:20.200
they've read it? Yeah, I don't know, I don't know if books are even relevant anymore for a lot of

56:20.200 --> 56:28.040
people. Well, this is becoming an issue, and it's part of the reason for the show,

56:28.920 --> 56:37.560
is to show the relevance of books. They've been very relevant in your life. I mean, so far when

56:37.560 --> 56:46.760
the books that we've gone through, we've seen the Professor Mitchell emerge as a mathematician,

56:47.720 --> 56:54.040
as a physicist, and as a computer science, artificial intelligence person,

56:55.160 --> 57:01.240
that part of that process, I'm certain it's far more complex, and of course complexity is another

57:01.240 --> 57:09.480
one of your areas, more complex than just childhood reading, but childhood reading is part of that

57:09.560 --> 57:18.840
nonlinear interplay of factors that have made you construct a model of reality that has served you

57:18.840 --> 57:27.880
very well. So the idea is, when people say books are not relevant, I think they're missing a very

57:27.880 --> 57:34.200
key important role in how they're relevant and why they're relevant at a particular age.

57:35.080 --> 57:41.080
Right. I mean, I was saying that facetiously, of course, but the young people I know today

57:41.080 --> 57:49.720
are tend to read a lot less or fewer books than I did as a child. They're reading things on the

57:49.720 --> 57:58.040
internet, as you say. We didn't have a choice. We only had books. Correct. So you're probably

57:58.040 --> 58:04.440
finding this then in your students? My students, oh yeah, my students, my own children,

58:06.520 --> 58:18.280
they just have so many different options for media that books are not number one on their list,

58:18.280 --> 58:28.440
I think, the way they were for me. Which is too bad. Yeah. Well, let's hope that this interview,

58:28.440 --> 58:37.560
this conversation, will inspire young people to say, I want to be like Melanie. I would love

58:37.560 --> 58:45.480
to be able to follow that career path. And here, if it worked for her, maybe this will be the kind

58:45.560 --> 58:54.520
of fine tuning that will help sculpt my own mind in a similar direction. That's the goal. We'll see.

58:57.800 --> 59:10.680
The next book is One, Two, Three, Infinity by George Gamov, which came out in 1947

59:11.560 --> 59:17.080
and explores the fundamental concepts of mathematics and science.

59:20.680 --> 59:24.200
Tell us a little bit about your initial reading of the book.

59:26.200 --> 59:34.600
Yeah, so this one I read in college. Okay. And I was thinking about all these

59:35.560 --> 59:42.280
fundamental ideas, you know, fascinated to read all of this stuff. I remember

59:43.240 --> 59:51.080
being very impressed and influenced by it, although I don't totally remember all the content of the

59:51.080 --> 01:00:00.840
book. But I do remember it was very fundamental ideas, especially in mathematics. There are two

01:00:00.920 --> 01:00:09.720
points in my research of the book that now make me think it had an influence on you is one,

01:00:09.720 --> 01:00:16.600
it's noted for its quirky sense of humor. That seems to be something that's a thread through

01:00:16.600 --> 01:00:23.240
all the books that we've looked at so far. And secondly, it's noted for its memorable metaphors.

01:00:24.200 --> 01:00:30.200
Again, again, something that is a thread through all the books that you've chosen

01:00:30.920 --> 01:00:36.600
that influenced you as a child. So you were growing up probably without realizing it,

01:00:36.600 --> 01:00:42.920
that you were having a master class with some of the best mentors on the planet,

01:00:43.880 --> 01:00:52.200
teaching metaphorical thinking, and teaching humor and ways of entertaining to get people's

01:00:52.200 --> 01:00:59.720
attention and to explain sometimes very hard, difficult, abstract concepts like number theory,

01:01:01.640 --> 01:01:04.440
which is done in this book.

01:01:07.000 --> 01:01:14.520
Yes, absolutely. So I think a lot of these books, I kind of read them and almost,

01:01:15.160 --> 01:01:21.640
you know, the way that like a film student will analyze a film at a much more kind of

01:01:22.440 --> 01:01:28.200
like trying to figure out how did the director pull that off? How did they set up that scene?

01:01:29.080 --> 01:01:34.680
I was quite interested in how do you explain things to people? How do you explain these hard

01:01:34.680 --> 01:01:40.200
concepts? So I was looking at how are they doing this? How is George Gamoff actually

01:01:40.760 --> 01:01:50.440
pulling this off? It's true because I think it's a very insightful observation you've made,

01:01:50.440 --> 01:01:57.320
because in a sense, books like this are a kind of performance art.

01:01:59.240 --> 01:02:05.560
And if I look at the other people who have cited this book as foundational,

01:02:06.200 --> 01:02:13.480
they are some of the great science communicators. For example, theoretical physicist Sean Carroll

01:02:14.440 --> 01:02:21.800
mentions this one, two, three, infinity as setting the trajectory of his professional life.

01:02:24.120 --> 01:02:29.560
Cognitive scientist Stephen Pinker read the book as a child and cited as contributing to his

01:02:29.560 --> 01:02:38.600
interest in popular science. And astrophysicist Neil deGrasse Tyson has also cited this as one

01:02:38.600 --> 01:02:47.320
of the greatest of two books that impact on his development, the other one being James Newman's

01:02:47.320 --> 01:02:56.280
Mathematics and Imagination. So here you have three other great scientific translators,

01:02:56.280 --> 01:03:06.280
communicators, masters of the metaphor who have had this book come into their life at the right time

01:03:07.160 --> 01:03:15.800
to say beyond just metaphor and simile and analogy, you have to find ways to entertain people

01:03:16.920 --> 01:03:25.640
and the entertainment is the way that most people learn. And if you're asking them to go back and do

01:03:25.640 --> 01:03:31.160
all the foundational for the original abstracts and say of number theory, they're not going to follow

01:03:31.240 --> 01:03:37.720
you there, they're not going to go down that path. But if you can give them a watchdog,

01:03:37.720 --> 01:03:45.640
a dog with a clock-like body, they're going to stay with you and follow you down the path

01:03:45.640 --> 01:03:55.160
because it is fun. Right. And I think George Gamoff also, he was Russian and he had that

01:03:55.160 --> 01:04:01.960
kind of very dry wit that the Russian writers often have. I think that was something I really

01:04:01.960 --> 01:04:12.600
appreciated. So humor and metaphor from George Gamoff, one, two, three and infinity, a book

01:04:13.320 --> 01:04:20.920
which clearly has inspired you and some of the other very important scientific communicators

01:04:20.920 --> 01:04:30.520
out there cite this book as well, which takes us to your next book, which is a book of essays by

01:04:30.520 --> 01:04:37.320
one of the world's foremost astronomers, Beyond the Observatory by Harlow Shapley,

01:04:39.880 --> 01:04:48.040
which is essays on scientific achievements of the 20th century. And one of the things which I

01:04:48.040 --> 01:04:55.400
thought was kind of an interesting presentation, Breathing the Future in the Past. I don't know

01:04:55.400 --> 01:05:01.800
if you recall that essay or not, but it was showing how your breath contains more than

01:05:02.440 --> 01:05:07.960
400,000 Aragon atoms that Gandhi breathed in his long life.

01:05:08.680 --> 01:05:21.720
Yeah, I do remember that. Bringing science again alive with an illustration here that makes it very vivid.

01:05:24.440 --> 01:05:30.680
Yes. When did you come? Was this a high school college you came across? That was in college.

01:05:31.400 --> 01:05:38.760
During college, I became very interested in astronomy and started to actually do some research

01:05:38.760 --> 01:05:45.320
in astronomy. We had a small observatory that I got involved in sort of a group of students

01:05:45.960 --> 01:05:54.040
who were doing independent research in astronomy. So I picked up this book and one essay that I

01:05:54.040 --> 01:06:04.440
remember really clearly was a discussion about how much you can infer from a sort of a single

01:06:04.440 --> 01:06:10.440
pinpoint of light. You know, you're looking at a star. All you're getting is very, you know,

01:06:11.160 --> 01:06:17.480
pinpoint of light. And then you can infer, like, what is the chemical makeup of the star? How old

01:06:17.480 --> 01:06:26.440
is it? Where it fits on the sort of spectrum of different kinds of stars? Is it you can infer? Is

01:06:26.440 --> 01:06:32.760
it orbiting another star? Is it going to explode? You know, all of these different things. It's just

01:06:32.760 --> 01:06:44.360
astounding what astronomy can achieve with just this incredibly kind of, you know, seemingly very

01:06:44.920 --> 01:06:48.760
limited amount of data. So I was very struck by that essay.

01:06:50.680 --> 01:06:58.600
Did you think of a career in astronomy? Yeah, I did think for a long time that I was going to

01:06:59.880 --> 01:07:07.080
have a career in astronomy and I did several internships in astronomy labs

01:07:08.360 --> 01:07:13.240
and thought about going to graduate school in astronomy, but ended up not doing that.

01:07:14.520 --> 01:07:22.760
Okay. So I guess maybe one of the lessons is that you can be intrigued and enthralled by a

01:07:22.760 --> 01:07:29.960
particular book that leads you in a direction, but ultimately you decide that's not exactly

01:07:29.960 --> 01:07:34.280
the full direction of where you want to go. You learn from it and you learn something about

01:07:34.280 --> 01:07:42.280
yourself from it and take on that knowledge, but get on with another career path.

01:07:44.280 --> 01:07:50.120
Yes, life is full of twists and turns, of course, that you can't predict.

01:07:53.320 --> 01:07:59.800
The other essay, which kind of fits into some of the other books that we've discussed,

01:08:00.440 --> 01:08:08.520
is the Science Outside the Lab, which was one of the essays there, again, which is back to the

01:08:08.520 --> 01:08:20.280
Einstein book that we discussed earlier, and that there is this kind of notion that science isn't

01:08:20.280 --> 01:08:31.880
just something that happens in the laboratory. Yeah, I mean, I don't remember that particular essay,

01:08:33.480 --> 01:08:39.720
but I assume he was talking about sort of what you see out in real life, I mean, what the kind

01:08:39.720 --> 01:08:45.880
of science takes place by observations that are outside of the lab, just like Einstein.

01:08:46.600 --> 01:08:54.360
Right, and again, what Shapley's book, from my understanding of these essays,

01:08:54.360 --> 01:09:01.160
is it's looking at science in a broad way. It's looking at science, sociology, and philosophy as

01:09:01.160 --> 01:09:08.760
well. In other words, the broader context in which science exists. It's a culture within a larger

01:09:08.760 --> 01:09:17.960
culture, and you are one of the bridge builders that are crossing that moat where the scientists

01:09:17.960 --> 01:09:25.000
are inside, talking to each other in a language which would be incomprehensible for most of us

01:09:25.000 --> 01:09:33.640
listening to ancient Greek. But you've mastered that language and can go over and say, this is what

01:09:33.640 --> 01:09:39.960
they're really talking about. This is what it really means. Here are some examples. Visualize this,

01:09:39.960 --> 01:09:50.840
visualize that. Which talking and visualization takes us to Hind's Teeth, Horses Tolls by Stephen

01:09:50.840 --> 01:10:00.120
Gould, which, oh, wonderful writer, I'm getting waiting for my Smithsonian Institute magazine

01:10:00.120 --> 01:10:07.400
to arrive here in Bangkok back in the early 90s. And sometimes it wouldn't arrive because I must

01:10:07.400 --> 01:10:12.120
have been a postman who shared my interest, decided to keep it himself. But in any event,

01:10:13.240 --> 01:10:18.920
he had a wonderful mind. And tell us how this book came into your life.

01:10:23.400 --> 01:10:29.560
So when I was in college, one of my housemates was an evolutionary biology major.

01:10:30.840 --> 01:10:36.680
And he was telling me how I should learn something about this field because I knew nothing about it.

01:10:36.680 --> 01:10:46.280
I'd never taken a biology class. So I tried to get into, there was a very popular course on

01:10:46.280 --> 01:10:51.800
evolutionary biology in my college, which I was unable to get into because it was so popular.

01:10:53.000 --> 01:10:59.640
So this housemate gave me this book, said, read this, this will teach you everything you need to

01:10:59.640 --> 01:11:06.120
know about. And I had never heard of Stephen J. Gould. I didn't know anything about evolution.

01:11:08.440 --> 01:11:14.760
So it was a real eye-opener. He's a fantastic writer, just like all of these books are

01:11:16.520 --> 01:11:23.720
these master science expositors. And talking about some of these

01:11:24.680 --> 01:11:32.040
sort of really interesting questions that you would never have thought to ask about evolution.

01:11:32.920 --> 01:11:37.800
So this was my first introduction to a lot of these ideas.

01:11:40.200 --> 01:11:46.840
What would you think would have been the influence of the book on your own thinking and your own

01:11:46.920 --> 01:11:59.240
choices and career? Well, it sparked my interest in ideas of evolution, which then

01:12:01.800 --> 01:12:11.880
went a lot further, especially when I was in graduate school and encountered an

01:12:11.880 --> 01:12:19.080
entire field called biologically inspired computation, an evolutionary computation,

01:12:19.720 --> 01:12:28.040
which merged ideas from evolution into computer science. And it's something that I got very deeply

01:12:28.040 --> 01:12:37.800
involved with later on. So that's an interesting point because in some ways you're drawing an

01:12:37.880 --> 01:12:46.440
analogy from the evolutionary biology world of Stephen Gould into a quite different realm

01:12:47.000 --> 01:12:55.080
and seeing that that perspective is transferable. Yes, exactly. That you can use,

01:12:55.960 --> 01:13:03.720
you could be inspired in a metaphorical way by ideas in one field and apply them into other

01:13:03.720 --> 01:13:12.520
fields. And interestingly, that's exactly what happened with Darwin, who sort of came up with

01:13:12.520 --> 01:13:19.960
a lot of these ideas. He was inspired by ideas from economics, from geology, and other fields,

01:13:19.960 --> 01:13:26.120
and he brought that into his own ideas about biology. So there's a lot of these cross-scientific

01:13:26.120 --> 01:13:33.960
analogies going on. It's an excellent point because certainly with Darwin's generation,

01:13:34.600 --> 01:13:42.680
there would have been a far broader education. And maybe that's part of the problem we have with AI,

01:13:42.680 --> 01:13:52.360
is that people are brilliant, but narrowly brilliant in very specific subdomains of subdomains. And so

01:13:52.440 --> 01:14:00.840
as a result, there isn't the same kind of cross-fertilization of ideas. Like for example,

01:14:00.840 --> 01:14:10.440
talking with someone who's coding an algorithm about empathy, there may not be an easy bridge

01:14:11.320 --> 01:14:17.320
with that coder and with those kinds of concepts simply because the background isn't there. They

01:14:17.320 --> 01:14:26.520
haven't come across the Steven Gould model that what you do is you find someone who is able to

01:14:26.520 --> 01:14:32.840
explain something brilliantly and see, again, you drew the metaphor of what he's talking about

01:14:32.840 --> 01:14:39.480
into another realm. You transported that infrastructure, that framework of thinking,

01:14:40.200 --> 01:14:46.200
and allowed you to see something quite different about computers that other people were not seeing.

01:14:48.120 --> 01:14:54.120
Well, yeah, I mean, I think I would say I was the one who came up with some of those analogies,

01:14:54.120 --> 01:15:05.560
but some of my mentors did. Talking about mentors, let's move on to Goethe Escher and Bach by

01:15:05.560 --> 01:15:13.640
Douglas Hofstadter, who I know was your mentor and an important intellectual force in your life.

01:15:14.440 --> 01:15:23.480
This book in 1973 was a monumental work. I want to pull a surprise. It is still read and discussed

01:15:23.480 --> 01:15:32.600
in the shape thinking of a couple generations since it was first published. So you must have

01:15:32.600 --> 01:15:43.640
read this book before you decided to, this was going to be your thing. You were at university

01:15:43.640 --> 01:15:55.880
somewhere, you got the book, what happened next? So I read it the year after I graduated from college.

01:15:56.520 --> 01:16:03.240
Okay. I actually read about it, I read a review of it in Martin Gardner's column in Scientific

01:16:03.240 --> 01:16:09.400
American, which is how I had heard about it in the first place. So I went out and bought it and

01:16:11.320 --> 01:16:19.720
it's a very long book. It's not like a beach read, if you will. It takes a lot of thinking.

01:16:20.680 --> 01:16:27.400
So I read it over the course of many months and decided that this is what I want to work on.

01:16:27.960 --> 01:16:35.720
And it's really a book about, it's about intelligence and how something like intelligence,

01:16:35.720 --> 01:16:43.320
as complex as intelligence, can emerge from a non-intelligent substrate, how consciousness

01:16:43.320 --> 01:16:49.320
might come about. And it uses ideas from mathematics, from music, from art,

01:16:50.040 --> 01:17:03.160
to kind of eliminate these core ideas. What was the connecting thread that Hofstadter

01:17:03.160 --> 01:17:09.720
discovered that links together Goethe and Bach and Escher?

01:17:13.000 --> 01:17:17.560
I say there are several connecting threads, but maybe one of them is this idea of self-reference

01:17:18.680 --> 01:17:27.080
that is fundamental in Goethe's theorem, his mathematical theorem, because you can get mathematical

01:17:27.880 --> 01:17:37.320
systems to be talking about themselves, to be referring to themselves. And that shows up in

01:17:37.320 --> 01:17:44.280
Escher. You see all these kinds of strange kind of loopy references.

01:17:44.920 --> 01:17:52.440
The hand drawing the hand. Yeah, the hand drawing the hand and so on. And in Bach's music, too,

01:17:52.440 --> 01:18:03.400
there's some examples that Hofstadter goes into in detail. And this is really the idea of

01:18:03.400 --> 01:18:09.480
intelligence is a self-rential, what he calls a strange loop, the strange loop of consciousness,

01:18:09.480 --> 01:18:16.680
where we're able to reflect on our own thinking. A kind of recursion. A kind of recursion, exactly.

01:18:17.080 --> 01:18:27.880
That goes on. And kind of a meta-thinking as well. So that at each stage recursive part, I mean,

01:18:27.880 --> 01:18:38.680
Bach's fugues, for example, there is a thing that reoccurs in them. From Nietzsche's eternal

01:18:38.680 --> 01:18:46.920
return. There are things that are patterns that show up against slightly altered, but recognizable.

01:18:48.360 --> 01:18:55.480
And that that that is the nature of intelligence, as we understand it.

01:18:56.920 --> 01:19:04.440
Something like that. Yeah, I mean, it's a... Hofstadter's ideas are not

01:19:05.400 --> 01:19:12.200
easily expressible in a short period of time. So, but that's kind of getting at the idea

01:19:12.200 --> 01:19:21.000
of this, what he calls this strange loop. Would you say that this, I mean, this is

01:19:21.000 --> 01:19:30.200
absolutely foundational book, that maybe it's at the outer edge of where you can use metaphor and

01:19:30.200 --> 01:19:38.200
summary with these abstractions to convey accurately what is being talked about.

01:19:40.760 --> 01:19:46.760
Because a lot of people find this book very, very difficult. Yeah, it is difficult. But what's really

01:19:46.760 --> 01:19:54.200
striking is how much Hofstadter comes up with amazing analogies and metaphors to talk about these

01:19:54.200 --> 01:20:05.160
things. And that's really, turns out to be what he's most fascinated by is how we think in analogies

01:20:05.160 --> 01:20:17.160
and metaphors. And he is a master of using these, you know, language and everyday examples

01:20:17.800 --> 01:20:22.760
to try and illustrate what's going on in these incredibly abstract ideas.

01:20:25.320 --> 01:20:36.040
So, he's a master cultural translator from these various realms. And again, using what,

01:20:36.040 --> 01:20:42.120
I mean, I can see the influence because you've done a number of articles on metaphor and

01:20:42.120 --> 01:20:50.200
analogy, particularly in the context of AI. So that understanding by way of metaphor and

01:20:50.200 --> 01:20:56.840
analogy has obviously been very central to your own development as a scientist and as an interpreter

01:20:56.840 --> 01:21:04.120
of science to a larger community. Yeah, and in fact, you know, Hofstadter was the one who

01:21:05.000 --> 01:21:12.840
introduced me to the idea of building AI systems that can make analogies. That was the

01:21:12.840 --> 01:21:21.160
topic of my PhD dissertation for which he was the advisor. Right. So this notion of analogy and

01:21:21.160 --> 01:21:29.560
metaphor kind of circles through all of my research. And it certainly circles through all of your

01:21:29.720 --> 01:21:39.160
readings as well. Evidently. You're starting to discover a certain kind of pattern that started

01:21:39.160 --> 01:21:47.720
at age eight. Yeah, I never had made that connection. It's kind of like psychotherapy, right?

01:21:49.640 --> 01:21:56.440
It's all started in your childhood. Are you still in contact with Professor Hofstadter?

01:21:56.440 --> 01:22:06.440
Yeah. Yeah. Talk to him from time to time. Okay. So the next book, unless there's something else

01:22:06.440 --> 01:22:12.680
you'd like to say about that, I think we've kind of established the fact that it's been

01:22:12.680 --> 01:22:19.960
transformational. I mean, your PhD thesis was about analogies, about the man who had written a book

01:22:20.520 --> 01:22:29.320
filled full of analogies and metaphors. And that was a watershed book and a watershed period of

01:22:29.320 --> 01:22:40.280
your life. Absolutely. Yep. The Recursive Universe by William Poundstone, which is really kind of the

01:22:40.280 --> 01:22:47.160
origin of complexity, which I know is another one of the fields that you've done a fair amount of

01:22:47.160 --> 01:22:57.400
research and study and writing. And explain a little bit about how this book came to you

01:22:57.400 --> 01:23:05.320
and what it said to you about complexity that still is important to you.

01:23:05.320 --> 01:23:18.760
Yes. So this book, I believe I read it in graduate school. I don't remember how I came across it.

01:23:20.440 --> 01:23:31.400
But what it is, it takes John Conway's Game of Life, which is

01:23:31.880 --> 01:23:43.880
what's called a cellular automaton. It's not exactly a game. It's more like a very idealized model,

01:23:46.280 --> 01:23:55.160
very simplified model of complex systems. And it uses this Game of Life and Game of Life is full

01:23:55.160 --> 01:24:04.280
of little patterns that people have discovered in things that are gliders and other kinds of

01:24:05.000 --> 01:24:17.800
structures that can do all kinds of computations. And Poundstone uses this as a way to talk about

01:24:17.800 --> 01:24:25.480
bigger ideas in cosmology and physics. And it's just a fascinating kind of approach to talking

01:24:25.480 --> 01:24:31.400
about those ideas. And it was one of my introductions to the Game of Life,

01:24:33.240 --> 01:24:38.920
and I think you've seen sort of how complex that all is and how complexity can emerge from these

01:24:38.920 --> 01:24:44.200
very simple rules, and then tying it to these much bigger ideas.

01:24:46.600 --> 01:24:50.760
So I just loved that book. I thought it was beautiful, and it's not that well known. I mean,

01:24:50.760 --> 01:25:01.560
it's surprisingly, I think, underappreciated. I think from what I've read, I haven't read the book,

01:25:01.560 --> 01:25:06.040
but I've read about it, and it seems absolutely fascinating in terms of

01:25:07.000 --> 01:25:13.560
of this notion of self-assembly, of how you can get very complex systems out of something that is

01:25:14.280 --> 01:25:23.000
in itself very simple. And for example, he gives the example of Pi, where, you know, basically

01:25:23.800 --> 01:25:30.840
you can encode it using only two terms and end up with this unbelievably complex

01:25:31.640 --> 01:25:41.400
number from just the initial to write the components to begin with. So I thought it was a

01:25:41.400 --> 01:25:47.080
quite interesting aspect of it. And the other thing is the initial information input and the

01:25:47.080 --> 01:25:57.960
relationship of information with entropy. You know, Claude Shannon with Bolson of looking at

01:25:57.960 --> 01:26:07.640
those two aspects of the universe, from an informational model to a model of

01:26:08.280 --> 01:26:14.200
the second law of thermodynamics or entropy, where things will go into greater disorder.

01:26:15.000 --> 01:26:21.720
Yes, exactly. So this book brought together a lot of ideas of complex systems that I had been

01:26:22.600 --> 01:26:27.320
thinking a little bit about, but never really found them brought all together,

01:26:28.040 --> 01:26:35.400
including entropy, information, computation, you know, he shows, he talks about Conway's proof that

01:26:36.280 --> 01:26:43.640
the game of life, which is just, it's just a two-dimensional grid of black and white,

01:26:45.160 --> 01:26:51.480
what they call cells, that influence each other in simple ways. But this actually you can

01:26:51.480 --> 01:27:01.240
embed an entire computer in this incredibly simple system. And it's just, it's full of very profound

01:27:01.240 --> 01:27:10.280
ideas. I know it's kind of fair you teach an online course on complexity, which is highly popular.

01:27:10.280 --> 01:27:18.360
I read somewhere like 25,000 students have more now, where I read is probably outdated.

01:27:18.440 --> 01:27:21.720
But it seems to be a very popular, is this one of the books that's

01:27:22.680 --> 01:27:29.080
in the course? So I don't use the book in that course, but I do talk about a lot of these ideas.

01:27:29.720 --> 01:27:39.640
I see. Yeah. So we cover that kind of thing. Yeah. Right. Okay. The last book on the list is

01:27:39.640 --> 01:27:45.960
Adaptations in Natural and Artificial Systems by John Holland. Last but not least,

01:27:46.920 --> 01:27:53.480
here we have adaptation is a biological process, rearranging genetic material, goes back to what

01:27:53.480 --> 01:28:01.640
you're talking earlier about Darwin's and in the evolutionary biology that you found an attractive

01:28:01.640 --> 01:28:10.680
way to take into another domain. So adaptation in Natural and Artificial Systems by John Holland,

01:28:11.480 --> 01:28:15.560
was this something from your university days or earlier?

01:28:15.640 --> 01:28:21.000
This was from graduate school. So John Holland was one of my professors at the University of Michigan.

01:28:22.040 --> 01:28:29.160
And he taught a course by, he was a computer science professor, yet he taught a course

01:28:29.160 --> 01:28:32.760
in computer science called Adaptation in Natural and Artificial Systems.

01:28:34.040 --> 01:28:39.880
It's a very technical book. So it's the only technical book on my list, really.

01:28:40.040 --> 01:28:49.080
But it was, John Holland was the founder of this field called Genetic Algorithms,

01:28:49.080 --> 01:28:55.720
which brought ideas from evolutionary biology into computer science.

01:28:57.400 --> 01:29:07.720
And this book was his theory of adaptation. So when you think about adaptation, maybe you think

01:29:07.720 --> 01:29:22.760
about some kind of species adapting to a particular niche. For instance, you have things like butterflies

01:29:22.760 --> 01:29:32.840
that the color of their wings change in response to their environment. And so this notion of adaptation

01:29:32.840 --> 01:29:40.520
is fundamental to biology. And yet Holland brought that into that field of computer science by saying

01:29:40.520 --> 01:29:49.720
what we want in computer science and AI is to have computers that adapt. So we don't want just

01:29:49.720 --> 01:29:56.360
living systems that adapt. We want machines that adapt, that are able to adapt to different

01:29:56.360 --> 01:30:06.520
environments and to be able to be flexible and learn the way that living systems do.

01:30:07.720 --> 01:30:17.480
So Holland became my co-advisor, along with Douglas Hofstetter. And this book was sort of set

01:30:17.480 --> 01:30:25.000
the path of a lot of my future research for up until now, really.

01:30:25.960 --> 01:30:34.200
Yeah. What seemed to me interesting about this book is the part that plays

01:30:34.920 --> 01:30:45.480
just conceptually of kind of perpetual novelty. That there is no kind of in-point that it's aimed

01:30:45.480 --> 01:30:52.760
for a particular in-point, that it's always open. And you can't quite predict where it will go,

01:30:52.760 --> 01:31:00.600
how that co-evolution or that adaptation will go next. I guess that's part of the non-linearity

01:31:00.600 --> 01:31:08.920
that he discusses in the book, is that we have trouble with things like exponential numbers,

01:31:08.920 --> 01:31:16.280
non-linearity. These are things that are outside our realm of experiences, like absolute time as

01:31:16.280 --> 01:31:24.360
opposed to relative time. And this is where you as a communicator of science try to come in and say,

01:31:24.360 --> 01:31:31.480
well, people are looking to take you to an in-point, but you have to be careful. Because the way

01:31:31.480 --> 01:31:36.440
in-points work in reality are quite different from the way that they're portrayed.

01:31:38.200 --> 01:31:44.840
Right. So one interesting thing about this idea of perpetual novelty that Holland

01:31:45.400 --> 01:31:52.600
talks about, you can imagine that in biology where you're having species continually evolving

01:31:52.600 --> 01:32:00.440
and changing and the environment's changing. But Holland also brought these ideas into economics.

01:32:01.480 --> 01:32:06.920
So interestingly, economics, the theory of economics that people,

01:32:08.440 --> 01:32:14.040
the sort of classical economic theory has to do with equilibrium. You want sort of this economic

01:32:14.040 --> 01:32:19.080
system to be in equilibrium or markets to be in equilibrium. But this idea of perpetual

01:32:19.080 --> 01:32:27.800
novelty says such systems are never in equilibrium. And therefore, the classical theories don't describe

01:32:27.800 --> 01:32:35.240
reality where we actually have this continually changing co-adaptive system of all these economic

01:32:35.240 --> 01:32:41.160
agents. So that's really been revolutionizing a lot of thinking in economics as well as in

01:32:41.160 --> 01:32:53.640
biology and computer science. Again, I guess things like global optimum and equilibrium

01:32:53.640 --> 01:33:00.520
are in a way metaphorical, trying to create the notion that there's an in-point where everything

01:33:00.520 --> 01:33:09.720
is absolutely balanced as opposed to the fact that in reality, nothing is ever balanced for long.

01:33:09.720 --> 01:33:18.200
There may be moments in time where it appears that birds and rabbits and dinosaurs had a

01:33:18.200 --> 01:33:26.120
particular adaptation, but then it doesn't last. It's overtaken by something else. And as a result,

01:33:26.680 --> 01:33:38.120
you have to live with the uncertainty of a perpetual changing environment and adaptation

01:33:38.120 --> 01:33:46.840
to those changes. Yes. I think one of your previous guests, John Allen Palos, has a great

01:33:46.840 --> 01:33:51.720
quote where he says, you know, living with uncertainty is the only certainty.

01:33:54.360 --> 01:34:02.520
That's something that I could just hear John saying. John's a friend I've known for years.

01:34:02.520 --> 01:34:09.800
Yeah, very, very brilliant mathematician and, again, a communicator of a high level

01:34:10.680 --> 01:34:16.600
as you are as well. So I want to thank you for this been a delightful conversation.

01:34:16.600 --> 01:34:19.880
Let me know, what do you think about the experience of being on the show?

01:34:22.760 --> 01:34:29.080
It's been a lot of fun. I mean, it's intimidating to try and have to think back on books that I've

01:34:29.080 --> 01:34:35.960
read years and years and years ago. But you reminded me of a lot of things that I'd forgotten,

01:34:36.520 --> 01:34:42.680
which has been great. And you also pointed out so many connections that I had never made about,

01:34:43.240 --> 01:34:47.400
you know, different the books, these books that I've read and the things that I've been

01:34:47.400 --> 01:34:54.600
thinking about for a long time. So I thank you for that. And thank you. This has been a wonderful

01:34:54.600 --> 01:35:04.200
conversation. And I will continue to follow your writings and learn from them. You're a master of

01:35:04.840 --> 01:35:12.760
communication between the arts and the science. And you contribute to both. And I think you have

01:35:13.560 --> 01:35:20.920
done a great job in that communication. Please keep up this wonderful work.

01:35:20.920 --> 01:35:33.240
Thank you so much. Bye for now. Okay, bye bye.

