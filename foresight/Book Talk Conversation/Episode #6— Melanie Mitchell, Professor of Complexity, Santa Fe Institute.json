{"text": " So, let me start a little bit with the introduction of who Melanie Mitchell is. She is a Davis Professor of Complexity at Santa Fe Institute, and her research focuses on conceptual abstraction, analogy making, and visual recognition. She's done a couple of very popular and well-received books. The first one was Oxford University Press in 2009, Complexity, a guided tour. Her most recent book is Artificial Intelligence, a Guide for Thinking Humans, and I have to say that people who've talked about the Artificial Intelligence book have said some very, very good things. For example, we have Allison Gopnik, who says it's very intelligent, clear and sensible book. Jeffrey West at Santa Fe has said it's remarkably lucid, comprehensive overview. Sean Carroll, an astonishing intelligence, and John Paulus, who's been on the show, says that Mitchell sketches enough details and clever illustrations that one gets a good intuitive understanding of AI. So you have high praise from some of the titans of a number of different disciplines, and I think that's a good way to take the next step. The next step is I'm in conversation with someone who is familiar with at least three important domains, mathematics, physics, and computer science, as well as artificial intelligence, which I would put in as part of the computer science part of this. So I see from my research of your background is you really have excelled as an interpreter, as someone who's been able to translate between these domains. And as a result, we'll be looking a little later in the show about how your childhood reading and those books help you create this kind of ability to map and track other thought processes in other domains and make them accessible to ordinary people. Yeah, so we humans are all masters of analogy, even when we don't know it. So let's think about a kind of unconscious analogy. One example that I use is the notion of a bridge. We all know what a bridge is. We all drive across bridges or we walk across bridges, whatever, but we also talk about bridges like the bridging the gender gap, or the bridge of a song, or the bridge of my nose, or there's all kinds of ways in which these terms are used metaphorically or by analogy throughout language, even unconsciously. But this kind of ability we have to extend concepts in this metaphorical way, and it's not just bridge, you could do it with almost any concept we want to talk about, is, I claim, what gives us our unique kind of intelligence. It allows us to understand more and more abstract notions in terms of very physical notions. Like you just said, you know, she has sunny face, so we all instantly know what that means. And we know, we don't even think of it necessarily as a metaphor. It's just so, you know, I might say, oh, you gave me such a warm introduction, you know, and it was, it wasn't literally warm, right? The temperature in this room didn't literally go up, I don't think, but it's something that we all couch all of our abstract thinking in. And this is exactly what AI systems today are lacking. They can learn to recognize photos of bridges, but they can't make that extension and talk about, you know, a bridge between two people, you know, you and I, or you may be your bridgingness, the culture of science with the culture of humanities, or things like that. So that's fascinating to me, and that's what my research is on, is trying to understand how human concepts are formed, what kind of structure they have, and how we might give such a concept to a machine. Yeah, presumably we're some ways away from AI understanding it's raining cats and dogs. Or, or she has a heart of gold. I mean, yeah, we don't, we, one problem with talking about AI is that we, when we talk about understanding, we don't really know exactly what we mean. What is it to understand something? That's actually been debated quite a bit by philosophers for millennia. And it's really an unanswered question. It's one of those words we use to describe our mental state that we don't quite understand scientifically what it means. I think in terms of kind of the sort of intuitive understanding we have of that notion, you're absolutely right, machines don't have the same kind of understanding of language that we humans have. I'm wondering as well if part of that issue has to do with, you've written about GPT-3 making a knowledges in medium. And you've said that with metaphors there isn't a right answer. There's an effective explanation or description that convey information. It's really a conveyor from the abstract to the concrete. But it's not, you can't really say it's 100% right. It can be close to right. What goes back to what you were talking about a moment ago is how we understand that transition from the abstract into something that's concrete. Is it giving us with that similarity a true representation from what the abstract really means? Yeah, it's machines, they've been shown to be what people in AI call very brittle, meaning that they have this kind of appearance of being intelligent until suddenly something shows you very clearly. It's like it's a breaking point and that's why it's brittleness that they didn't understand at all what the language they were using meant. What of my favorite things I saw on social media some time ago was someone had taken an apple and written the word iPad on a piece of paper and put that on the apple with a rubber band and then ask an AI for questions or for answers to what this is and it said with 90% probability it's an iPod. So that kind of literalism, you can see it's part of that inability to deal with analogies and metaphors. And again, you've talked about in how analogies shape our thoughts, what happens if you strip away metaphors, simile, and analogies from language, what is left? Are we left just with abstractions? Is that the part of the problem that we have with storytelling AIs is that they lack the essential building blocks of how you tell a story, which basically is the bricks of that building of that story really are metaphorical, a lot of them. That's one of the problems for sure. Another problem is that AI systems don't understand how the world works. You know, they don't know that they don't know that, you know, if a child is holding an ice cream cone and then the ice cream cone falls on the ground, that that would be upsetting because how are they going to know that? They haven't experienced the world the way that we have. They don't even know that, you know, when an ice cream cone hits the ground that it's going, it's not edible anymore, and you wouldn't want to eat it. How would they know that? It goes back to what you've written about as well of saying that the problem with AIs, that lacks common sense. And common sense is if you drop the ice cream cone, even a four-year-old knows it's no longer something you want to eat or an AI system would not have that particular response because it's not an embodied biological entity that learns certain things about food from a very early age. That's exactly right. So that's the, you know, that's one of the big problems is how do you get a system like GPT-3 or any other AI system to get that kind of knowledge about the world that we all have, you know, as children, we all learn so much by just living and existing in the world. You know, part of what you've written that strikes me as very interesting as well is that a lot of the analogy making we have comes from an unconscious part of our brains. There was, when you start to think of analogies, they will come to you and if I ask, well, where did that come from? Probably don't really know. It's just, it's been triggered by some, some gesture, some thought, something that you're not really connected to. You can make up a story of why you access that, but it's just that. It's just a story. You don't really know. So AI does not have an unconscious matrix in which to draw upon to pull those analogies and metaphors from a huge reservoir. I mean, presumably that material for analogy making is as close to infinite as a human can get to. And as a result, it's very hard, I would think, to program into a computer intelligence an analogy making function because it goes much deeper than just being able to calculate precisely what the next best move is in chess or goal or Atari. Right. Our analogy making comes in part from the fact that we have this huge store of memories. And, you know, if you might, you probably have the experience where somebody tells you a story and you say something like, oh, the same thing happened to me. Yes. Right. And of course, the same thing literally didn't happen to you because you're not that other person. But you, something about their story triggers a memory that you somehow mapped on to the story that they just told you happens to us all the time every day. You know, someone says something about their life and you say, oh, yeah, me too. Right. And that's like, you know, you're making an analogy between their life and your life. And it's just constant. But it has to do with an interaction between our perceptual abilities, our memories, our pattern recognition facilities and so on. And this is something we haven't yet figured out how to give to machines. I'm wondering as well whether that exchange also falls under the heading of empathy, which is something a machine doesn't have. Is that you will say, oh, that's similar because you have a theory of mind about that person. You can put yourself in that position and see that as happening to you and that you would have had a similar response to a particular event or an object or a gesture. Yeah, that's absolutely right. And, you know, one of the things about humans is they're incredibly socially oriented, meaning that they're always trying to understand other people that they encounter from the earliest infancy and they're able to put themselves in the position of other people. So that's something that, again, is very human and so perhaps essential for intelligence. You know, we don't know. Usually AI people often think of intelligence as something kind of separable from things like empathy and emotions and it's pure rationality. But I think a lot of people are now trying to make sense of how the centrality of these or emotional aspects of our intelligence. Right. Well, what I'd like now to do with this background in terms of metaphors, analogies to move on to your reading list, which I hope that we'll be able to get into how this may have been a training set and education for you into the world of metaphor, simile and analogy making. So let's start with really your background, your first books. You're at home. Was the first books from your mother or your father or a sibling? I mean, how did you come to first have that book, that first book in your hand? The first book? Yeah. In other words, we look at the first book on the list, which is The Phantom Tooth Toe Book, which is an absolutely wonderful book. I'm so glad you chose that. I can't wait to get into it, but let's just start for a moment. And how did you come to have that book in your possession and how old were you? Wow. I was, I'm guessing I was about eight or nine, something like that. And I really don't remember at all how I got that book, who gave it to me or anything. Somehow it appeared, sort of like The Phantom Toe Booth in the book just suddenly appeared. No one knew where it came from. Did you grow up in a reading environment where your parents were reading or siblings were reading? And then that kind of storytelling from reading was kind of a natural bridge from one to the other. You're reading books, you're telling stories, you're reading books. Yeah. My parents both were avid readers and read to us from earliest childhood. I just, I can't remember any time when I couldn't read or didn't spend most of my time reading. So I loved reading as a child. I did too. That's why I'm doing this show. And I think that the people who have that experience or fortunate for a lot of reasons, because it does ground, I think, a person in the ability to be curious about stories, about other people's stories, and to learn from them and to apply that learning to new and novel situations. Which is, you know, basically that's so much of what you're doing as well is how do you deal with surprise? And how you deal with surprise is something that you can learn through the experiences of characters in books. You can see that experience is something, oh, that person was surprised. They reacted in this way. And that has the profound implication for your own feeling about security in the world, how I would react. So the phantom toll booth by Norton Justin, you know, he, he just recently died in March of this year at age 92. But he left behind this absolutely wonderful book. You know, there's the little bored boy named Milo, who's, you know, has this kit, which he has to assemble, which is toll booth. Comes with two toll booths. It just appears also. That was very, it's Magically, it's striking to me that this thing just appeared in his bedroom. Right. Where did it come from? Exactly. So that's the first question you're asking at eight or nine, right? It is, how did Milo end up with this kit in his room? So what does he do with that? He puts it together. He assembles it, right? So there's an immediately kind of an engineering puzzle making aspect to the book, which I almost, all the scientists I've talked to, there's some book like that. Here is a puzzle. If I put it together, what representation do I see? And so for Milo, he also has a little electric car. So once he's assembled the toll booth, he's got the map, the rules, two tokens, drops one in, takes off and starts driving. And I could see where your love and passion for metaphor and analogy would have started at eight or nine with this book. I mean, a dog's body shape like a cock, a watchdog. Right. That was another thing. It was all the word play and Hans was just so enchanting. So yeah, I mean, there you go. You're certainly starting to see that word play, a clock body for a dog, a watchdog, and then a bug that just brags and brags about its own abilities and claims, which aren't true, which is a humbug. And so Milo basically teams up with these two, doesn't he? The humbug and the watchdog to go on an adventure and they end up in the empire of wisdom. But the problem is there's no rhyme or reason. Right. The princesses. Exactly. The two sisters. Yes. So they set out for a quest to rescue them, right, and to bring the two sisters rhyme and reason back into the empire of wisdom. And again, part of the word play here, it's quite wonderful, is on their journey, you know, running into the mountain of ignorance where there's the ever present word snatcher, which is quite the person who's constantly interrupting them. The terrible triumphant, waste time doing unimportant and trivial tasks. The sense taker, the person who wastes time filling out countless wasteful forms to no particular end. So ultimately, they, they succeed, right? Milo. Oh, yes. The humbug, the watchdog. Yes. By rescuing the two sisters rhyme and reason. Now, what out of that, the phantom of toll booth, if you can kind of recreate what it was that in your mind as you read it as a child, how you process that. I mean, you're processing some things which were a kid could be a little bit maybe frightening, like demons. And some of the demons are described in quite vivid detail, long nose, green eyed, curly haired, wide mouth, thick neck, broad shoulder, round body, short arm, bow legged, big footed monster. That's the demon of insecurity or insincerity. Mm-hmm. Yeah. That, I mean, part of the book, I remember, were some wonderful illustrations by Jules Pfeiffer. Right. I mean, I didn't know who he was when I was, you know, that child, but I certainly knew him later on. And they were fantastically evocative and terrifying, some of them. I still remember that there was a man who had no face. I don't know if you saw that one, but that was a really terrifying thing. Right. Right. So it introduced a wordplay world and a visual world in between the covers of the same book. Yes. Yes. And there were, you know, I, there were two kind of two different cities. One was concerned with words and the other was concerned with numbers. Right. So that this kind of separation between sort of the world of numbers and the world of words was one that I think I already was starting to resonate with because I felt like I had sort of interests in both, in both of those worlds. That's, that's interesting. So here's a child book, The Phantom Toe Booth, which actually opens up a window to two different kinds of cultures. Mm-hmm. There's the culture of language and words, and then there's the culture of mathematics and numbers. And there's a, there are border lines between those, but here's an author who's able to cross those borders at will, going from numbers to representations, representations to numbers. That had to be a thrilling thing for you as a child. Yeah. I remember really, really being struck by that idea that these things were, you know, they were very separate and that, and there was this, you know, I, I'm sort of only vaguely remembering a lot of this book I have to admit, but that's one of the things that was striking to me. That's interesting. So this is a book that I presume you would recommend for, for parents and teachers and others, if you want to inspire a young person in the world of metaphor and analogies and mathematical objects, this is, this is a place to start because it, it is accessible. It's very accessible and kids, children love it. I, I read it to my own two children, many years ago. And they, I, I don't know if they loved it as much as I did, but I remember them that they, they, they found it quite amusing, all the word play and puns and everything. That's interesting. So the tradition of the first book on your list that you had as a child, you made a point of sharing that experience with your own two children in order to pass along, which you hope would be a similar kind of experience. Yeah. And I haven't asked them if they remember that book. I should ask them someday. No. I think it would be interesting to go back for parents to go back to children, particularly if they're late teens or early adults and say, do you remember when I, when we read this book together? Do you, do you have any memories of this? Did it have any impact on your life? Because it had an impact on mine. I was on a conversation with someone on a talk show where I talked about this book and I talked about you. Right. Full circle. Right. Y'all, I'll ask them. The next book, another wonderful selection is A Wrinkle in Time by Madeleine Naingal. Again, I'll give just a little bit of an introduction because I don't expect you to remember all the details of this. You've read a long time ago, but before I get to that, about what age were you when you read this? That one I remember because I, we read it in my fourth grade class, which is nine years old. Okay. So at nine years old, you're reading about a high school student named Meg Murray and her younger brother Charles Wallace and their friend Calvin O'Keefe. And basically it's a quest, right? Where the father who's a scientist has gone missing. He's disappeared. No one knows where he is for a year. And suddenly out of kind of nowhere, this is the magic of children's literature, someone arrives called Mrs. Wetzit. And Mrs. Wetzit is one of these creatures from another dimension who comes with information about the father. And she also has two friends, Mrs. Who and Mrs. Witch. So Mrs. Wetzit, Mrs. Who and Mrs. Witch become the guides for these three youngsters who are able to find a wrinkle in time, a pteroset, to be able to go into another dimension to follow the trail of the missing father. Now, so what we have then is this notion of searching for a parent, which is something I think all children can probably relate to. The father's missing. What can I do to find my dad? What help can I find? It goes back to your earlier point where social creatures, we seek other people around us that we trust to help us on our quest. This goes from the Lord of the Rings to a wrinkle in time. It's the same kind of dynamic. As you find your allies, those people that you've bonded with who see the world pretty much like you do, that will watch your back when you're going into the unknown. So what I like about the story is the secret weapon that Meg discovers through Mary's trials and tribulations of trying to find the father. And ultimately, she goes back to confront this dark AI kind of force, which is taken over and made everything the same and controls the mind of everyone within this AI's domain. Except Mrs. Wetzit says there is a secret weapon. You'll have to look deep in yourself and you'll find it. If you can find that weapon and you go back to this place and use it, you will be able to find and retrieve your father. Do you remember what the weapon was? Love. Yes, that's what I was going to say. Right. Yeah, it was a little corny there. But yes. Corny in a way, but on the other hand, very humanizing because it is, again, with that notion of self-sacrifice. And maybe that's something that we do well as humans, and maybe we should do better. But the real notion of love is that ability to sacrifice yourself for another. It's not necessarily just the romantic part of it. It's a self-sacrifice. And here's a daughter who is willing to self-sacrifice for her father that disabled the AI. AI was defeated at that point. Gosh, I don't even remember that it was an AI. Was it a machine? Well, I'm saying an AI. It's called it. Okay, I do remember that. Yeah. And it's, my notes here, all objects and places appear exactly alike because the whole planet must conform to the terrifying rhythm pulsation of it. A giant disembodied brain. Now, that seems to me to be a reasonably good description of for a child of what an AI is. This big disembodied brain, in this case, having a kind of super level of intelligence as opposed to the kind of AI intelligence that confuses a writing of iPod for an apple. Right. Yeah. I mean, the thing that for me that stands out in my memory about this book is, first of all, the female scientists, like both Meg and her mother. Her mother was a brilliant scientist. And I really, you know, I think this was one of the first books I had read or encountered that had such characters that had female scientists, people who are interested in science. And also this notion of multiple dimensions. That was sort of my first introduction to that idea of like the fourth dimension and this notion of a tesseract. And I remember that very clearly, that that, you know, explaining that this is a four dimensional cube. And it was just fascinating to me. I think that's exactly the kind of thing I was hoping to hear is that here's a book that opened up the role of genders. And that you could see for the first time as a child that women are as capable as men, and that women can be scientists, that they can also head up a quest and an adventure. It doesn't have to be a boy. It can be a girl who actually does all the hard work of putting together the team, charting the journey, assessing the risks, and ultimately finding the solution. So that must have made a bit of a change in terms of how you thought about your own potential as a young girl. It probably did. You know, I don't remember that explicitly, but I do remember, you know, very much identifying with the Meg character. And also just being very intrigued by her mother. Right. Because at that time, my own mother at that time was a housewife. My father was an engineer. I hadn't really encountered women doing being scientists. But maybe that's part of the real beauty of early reading is it provides multiple role models for children. Because when you grow up, your role models are your mom, your dad. Okay, I have a model of a man as an engineer, a model of a woman as a housemaker. And suddenly you're reading a book where, you know, there are other models out there. There are other kinds of things that people do, other kinds of identities that they're able to shape and create a life with. So that so that that book, I could see would be a quite important foundational one for your own kind of psychological development and perhaps confidence that yeah, there are some other roles out there for women other than which just what I'm saying around me. Yeah, definitely. Okay, so to leave the world of fiction for a moment, to look at the next book on your list, which is The Universe and Dr. Einstein by Lincoln Barnett. Now, I've heard you say on another webcast that you read this in high school, and it was responsible for you to pursue a degree in physics. Right, so that I absolutely I read that in high school. I think it was suggested by my physics teacher. And I absolutely loved it. You know, it was a popular exposition of Einstein's theory of relativity. It was fairly short, extremely clear and well written. And it just, you know, astounded me, these ideas. And the fact that you could just, you know, Einstein relied quite a bit on thought experiments, you know, what she called gedonkin experiments, where he didn't actually have a lab or, you know, be doing, you know, writing down lots of equations. But he was just kind of thinking about how things might work. And thinking, you know, well, what happens if the speed of light is constant? But what would that imply? And all of that was just very eye opening for me. And I decided I wanted to study physics in college. It's interesting. Again, I can see a little bit of a link here between the wrinkle of time, because he's dealing with other dimensions. And also, he's dealing with reasoning, not in a lab, but by way of analogy, by way of visualization. So he's using metaphors, and he's using concrete examples of trains moving in order for that thought experiment to allow, in which he's doing a reversal, he's using analogies as a reversal process to come up with an abstraction about an aspect of time, space, velocity, momentum, and to come up with the mathematics of the metaphors that he thought at his desk. Exactly. Yeah. So that was, that was quite, quite fascinating for me. So again, I think, you know, I can see this a little bit in your own work that you, you're able to see the metaphor making isn't just a translation of the hard mathematics. Einstein in this book, the universe, and Dr. Einstein, shows that it can go the other way as well. You can go from the childlike storytelling of multidimensions to creation of mathematical models that try to come up with a more abstract general way of explaining what a phenomenon is. Is that? Yes. Yeah. I mean, much later, I read another book, you know, now as an adult about Einstein, and it hypothesized that, you know, Einstein was a patent officer in Switzerland. And one of the things that people in Switzerland were trying to do at the time was, how do you synchronize clocks between train stations? Because this was an important thing to make trains, you know, be able to follow their schedule. So, so he was thinking about this extremely practical problem. But thinking about the implications of what does it mean to synchronize? What does it mean for time to be synchronized? And blowing that up into this incredibly profound truth about the universe and about time itself. So, you know, that's like, as you say, it's kind of the reverse metaphor. It's like he sees the very concrete thing of trains and synchronization and so on. And then he is able to expand that idea into something much more general and much more profound. You wonder if he had that kind of aha moment because, you know, the history of our species, you know, for 200,000 years would have been, we think of time as absolute, of spaces unchanging and absolute. And suddenly to have a thought, it's not absolute, it's relative. And to take that on the implications of that on, and I think we're, we're still trying to come to terms with the implications of what that means with time being relative. Because all of our earthly experiences prepare us for kind of an absolute, absolutist notion of time. And you're someone who challenged what is probably one of the bedrock notions that most people have. And I can see you're in high school now, and you're thinking, if time can, is not absolute and can be challenged, what else is there in physics that will allow me to do similar kinds of challenges to what are basic understandings of the world, which work on one level, but are fundamentally incorrect? Yeah, I don't know if I was thinking all that, but yeah, I didn't, yeah, I was trying to just get my mind around that, that whole very counterintuitive ideas. Yes, yes. So by the time you're in high school, you've decided that physics is the career path that you wanted to take. And you've, you've said that this, this particular book is one of the books that probably was influential in setting you on that path. Yes. So again, I think it shows childhood reading has enormous implications, because what it does is it starts a train of thought, and that train of thought leads people into a direction which they may not have otherwise taken, but for having come across to read that book. Absolutely. Yes. The next book, Fads Balaces in the Name of Science by Martin Gardner. I hadn't been familiar with this book, but it's an absolutely timely book to, to discuss. I mean, this is pre-internet, pre-fake news, you know, pre silos on Twitter and Facebook and the rest of it. He's taking on the whole kind of area of quack remedies, of cranks, and how cranks have, you know, historically been able to get quite a good audience. They didn't need social media to come along to give them an audience. I mean, now that has been quite effective, but before they had publishers that were quite willing to publish their books because there was an audience for what cranks had to say, even though it was clearly wrong. So, tell me a little bit about what age you were and the circumstances of coming across this book. So, I think I was in college. I don't quite remember, but I loved Martin Gardner. You know, he was a long time columnist for Scientific American. He was an incredible communicator of math. He was a math puzzle fanatic and a math puzzle creator and a wonderful writer, just super playful person interested in all kinds of things. So, I had been reading, you know, I read his column and I picked up, I guess I picked up this book and found it really just, you know, thinking about what drives people to believe things and sort of, and as you say, it's very relevant now is sort of, what is science? Why do we believe science? What is different between science and all these kind of quack beliefs? And that's something, you know, I think we all still struggle with. I think it's probably right. I mean, one of the things that seemed to me from my reading of the book is the central role that Gardner thought that the scientific community played. And again, it goes back to that kind of social role that we are social people and that we learn from each other. And usually, he says the crank is someone who's almost always outside the scientific community. They don't have colleagues to bounce the ideas off and not going to conferences, listening to other people's papers. They're not presenting their papers for peer review or for comment by other people. And as a result, it's easy to get off the rails because there's no one to say you're off the rails. Right. And they get these cult followings where they get reinforced, you know, people people are believing them. And he said that there are really a couple of signifiers for a crank is one of them is that person stands entirely outside the closely integrated channels through which new ideas are introduced and evaluated. And secondly, as a tendency to paranoia. But I think one of the things that people may say is, well, the scientific community is not that perfect. That maybe some of the grants and the money that comes from them are twisting the dogma in ways that favor the people who are funding studies and so forth. And therefore, can we really trust dogma that's coming out of a scientific community that is not as pure science as we would wish it to be. Sure. And science is done by humans, right. And humans have their own prejudices and biases and influences. And it's just a human endeavor. But what we do have in science is we have replication, we have, you know, community sort of think things are wrong all the time. But eventually, people discover that they're wrong. We have kind of this notion of consensus. There's certain things that are consensus, eventually, in the scientific community. And that those consensus, the consensus believe can eventually be overturned. But it's, it's, it is a community. And I think, you know, it has, I don't know how to say this, why should we trust scientists as opposed to anyone else? It's because I think scientists are, I mean, part of the deal of being a scientist is that you're always trying to disprove your own work. And you try as hard as you can. And that's the fundamental thing. You always are trying to be skeptical of everything in your own work. And if you pound on it and pound on it and people replicate it and replicate it, finally you come to as close as you can to what you might call verification. So yeah, I mean, it's perfect for sure. That's a very good description. I mean, I think in terms of sciences, also it creates a cultural, cultural aspect of thinking, where scientists tend to be comfortable with uncertainty, at least more comfortable than most people, because they understand that even the existing dogma is a tentative position. It's not yet disproved. There will be flaws in it, in that every time someone thinks they've come up with an absolute answer, they've usually found out that that's not the case. And so there is more of a humility. I mean, you have some big eagles in science, as you would expect. But the idea is to be humble in the face of new changing information that requires constant revaluation and updating, where the people who are the cranks have the absolute truth. There is no updating that is needed. It's all defense of the existing structure. The structure is perfect, it can't be improved upon, and you either believe this or you don't. You're either part of our belief system or you're not. That, it seems to me, is very anti-scientific. So the book by Gardner, and his books have appeared on the list of other guests as well. He's someone who's had, I think, a profound influence in terms of educating a whole couple of generations of thinkers and mathematicians and physicists and artists and others who want to look deeply at those kinds of ways of thinking and processing reality. And science is just a different way of processing reality through investigation, observation, testing, reevaluation, and understanding that no matter what the result appears to show today, it may be overturned in the next week. I think one other thing you can say about Martin Gardner is that he was an incredible expositor of science and math, and kind of was a model for me, myself, of trying to write for the general public about science. How do you make things clear? How do you make things entertaining? How do you make things accessible? I'm glad you mentioned that, because the reviews of your books, all point to the fact that you've done this with enormous success, is to be able to use those metaphors and analogies to go from the very hard mathematical world of pure science into another language that most people can understand and relate to. That's a very particular skill. It's a little bit like translation. Where I live, translation is a very important aspect of life, and you get people who are, say, bilingual, but as I say, there's a difference between being bilingual and bicultural. To know another language is not necessarily to know that culture. You are bilingual and bicultural, and that's a real advantage, and I think someone like Martin Gardner was like that as well, who understood both cultures and understood the language and the barriers of communication between those cultures. Just for the people watching, some of the chapters in this book by Martin Gardner on fads and fallacies, he takes on the flat earth people, the hollow earth, I hadn't heard that one before, monsters of doom, flying saucers, down with Einstein, dousing rods and doodle bugs, geology versus Genesis, Atlantis, the Great Pyramids, medical cults, from homeopathy to natural apathy, and food fattice, so dynetics. He covers a fair range of the traditional kind of cult-like absolutists, fad friends that a lot of people were attracted to. Still are, in some cases. It still are, and as a result, maybe this is a book that has to be updated for modern times, because social media now is the main vehicle through the internet of being able to create these kinds of pseudoscientific communities which they talk to each other and reinforce each other, but they're reinforcing basically a highly flawed, mistaken view of reality. So the question is, how do you reach them? Martin Gardner's book reached you and probably reached a lot of people of your generation, but the question is, for the new generation, it will this book be one that will allow them to have a different window on social media once they've read it? Yeah, I don't know, I don't know if books are even relevant anymore for a lot of people. Well, this is becoming an issue, and it's part of the reason for the show, is to show the relevance of books. They've been very relevant in your life. I mean, so far when the books that we've gone through, we've seen the Professor Mitchell emerge as a mathematician, as a physicist, and as a computer science, artificial intelligence person, that part of that process, I'm certain it's far more complex, and of course complexity is another one of your areas, more complex than just childhood reading, but childhood reading is part of that nonlinear interplay of factors that have made you construct a model of reality that has served you very well. So the idea is, when people say books are not relevant, I think they're missing a very key important role in how they're relevant and why they're relevant at a particular age. Right. I mean, I was saying that facetiously, of course, but the young people I know today are tend to read a lot less or fewer books than I did as a child. They're reading things on the internet, as you say. We didn't have a choice. We only had books. Correct. So you're probably finding this then in your students? My students, oh yeah, my students, my own children, they just have so many different options for media that books are not number one on their list, I think, the way they were for me. Which is too bad. Yeah. Well, let's hope that this interview, this conversation, will inspire young people to say, I want to be like Melanie. I would love to be able to follow that career path. And here, if it worked for her, maybe this will be the kind of fine tuning that will help sculpt my own mind in a similar direction. That's the goal. We'll see. The next book is One, Two, Three, Infinity by George Gamov, which came out in 1947 and explores the fundamental concepts of mathematics and science. Tell us a little bit about your initial reading of the book. Yeah, so this one I read in college. Okay. And I was thinking about all these fundamental ideas, you know, fascinated to read all of this stuff. I remember being very impressed and influenced by it, although I don't totally remember all the content of the book. But I do remember it was very fundamental ideas, especially in mathematics. There are two points in my research of the book that now make me think it had an influence on you is one, it's noted for its quirky sense of humor. That seems to be something that's a thread through all the books that we've looked at so far. And secondly, it's noted for its memorable metaphors. Again, again, something that is a thread through all the books that you've chosen that influenced you as a child. So you were growing up probably without realizing it, that you were having a master class with some of the best mentors on the planet, teaching metaphorical thinking, and teaching humor and ways of entertaining to get people's attention and to explain sometimes very hard, difficult, abstract concepts like number theory, which is done in this book. Yes, absolutely. So I think a lot of these books, I kind of read them and almost, you know, the way that like a film student will analyze a film at a much more kind of like trying to figure out how did the director pull that off? How did they set up that scene? I was quite interested in how do you explain things to people? How do you explain these hard concepts? So I was looking at how are they doing this? How is George Gamoff actually pulling this off? It's true because I think it's a very insightful observation you've made, because in a sense, books like this are a kind of performance art. And if I look at the other people who have cited this book as foundational, they are some of the great science communicators. For example, theoretical physicist Sean Carroll mentions this one, two, three, infinity as setting the trajectory of his professional life. Cognitive scientist Stephen Pinker read the book as a child and cited as contributing to his interest in popular science. And astrophysicist Neil deGrasse Tyson has also cited this as one of the greatest of two books that impact on his development, the other one being James Newman's Mathematics and Imagination. So here you have three other great scientific translators, communicators, masters of the metaphor who have had this book come into their life at the right time to say beyond just metaphor and simile and analogy, you have to find ways to entertain people and the entertainment is the way that most people learn. And if you're asking them to go back and do all the foundational for the original abstracts and say of number theory, they're not going to follow you there, they're not going to go down that path. But if you can give them a watchdog, a dog with a clock-like body, they're going to stay with you and follow you down the path because it is fun. Right. And I think George Gamoff also, he was Russian and he had that kind of very dry wit that the Russian writers often have. I think that was something I really appreciated. So humor and metaphor from George Gamoff, one, two, three and infinity, a book which clearly has inspired you and some of the other very important scientific communicators out there cite this book as well, which takes us to your next book, which is a book of essays by one of the world's foremost astronomers, Beyond the Observatory by Harlow Shapley, which is essays on scientific achievements of the 20th century. And one of the things which I thought was kind of an interesting presentation, Breathing the Future in the Past. I don't know if you recall that essay or not, but it was showing how your breath contains more than 400,000 Aragon atoms that Gandhi breathed in his long life. Yeah, I do remember that. Bringing science again alive with an illustration here that makes it very vivid. Yes. When did you come? Was this a high school college you came across? That was in college. During college, I became very interested in astronomy and started to actually do some research in astronomy. We had a small observatory that I got involved in sort of a group of students who were doing independent research in astronomy. So I picked up this book and one essay that I remember really clearly was a discussion about how much you can infer from a sort of a single pinpoint of light. You know, you're looking at a star. All you're getting is very, you know, pinpoint of light. And then you can infer, like, what is the chemical makeup of the star? How old is it? Where it fits on the sort of spectrum of different kinds of stars? Is it you can infer? Is it orbiting another star? Is it going to explode? You know, all of these different things. It's just astounding what astronomy can achieve with just this incredibly kind of, you know, seemingly very limited amount of data. So I was very struck by that essay. Did you think of a career in astronomy? Yeah, I did think for a long time that I was going to have a career in astronomy and I did several internships in astronomy labs and thought about going to graduate school in astronomy, but ended up not doing that. Okay. So I guess maybe one of the lessons is that you can be intrigued and enthralled by a particular book that leads you in a direction, but ultimately you decide that's not exactly the full direction of where you want to go. You learn from it and you learn something about yourself from it and take on that knowledge, but get on with another career path. Yes, life is full of twists and turns, of course, that you can't predict. The other essay, which kind of fits into some of the other books that we've discussed, is the Science Outside the Lab, which was one of the essays there, again, which is back to the Einstein book that we discussed earlier, and that there is this kind of notion that science isn't just something that happens in the laboratory. Yeah, I mean, I don't remember that particular essay, but I assume he was talking about sort of what you see out in real life, I mean, what the kind of science takes place by observations that are outside of the lab, just like Einstein. Right, and again, what Shapley's book, from my understanding of these essays, is it's looking at science in a broad way. It's looking at science, sociology, and philosophy as well. In other words, the broader context in which science exists. It's a culture within a larger culture, and you are one of the bridge builders that are crossing that moat where the scientists are inside, talking to each other in a language which would be incomprehensible for most of us listening to ancient Greek. But you've mastered that language and can go over and say, this is what they're really talking about. This is what it really means. Here are some examples. Visualize this, visualize that. Which talking and visualization takes us to Hind's Teeth, Horses Tolls by Stephen Gould, which, oh, wonderful writer, I'm getting waiting for my Smithsonian Institute magazine to arrive here in Bangkok back in the early 90s. And sometimes it wouldn't arrive because I must have been a postman who shared my interest, decided to keep it himself. But in any event, he had a wonderful mind. And tell us how this book came into your life. So when I was in college, one of my housemates was an evolutionary biology major. And he was telling me how I should learn something about this field because I knew nothing about it. I'd never taken a biology class. So I tried to get into, there was a very popular course on evolutionary biology in my college, which I was unable to get into because it was so popular. So this housemate gave me this book, said, read this, this will teach you everything you need to know about. And I had never heard of Stephen J. Gould. I didn't know anything about evolution. So it was a real eye-opener. He's a fantastic writer, just like all of these books are these master science expositors. And talking about some of these sort of really interesting questions that you would never have thought to ask about evolution. So this was my first introduction to a lot of these ideas. What would you think would have been the influence of the book on your own thinking and your own choices and career? Well, it sparked my interest in ideas of evolution, which then went a lot further, especially when I was in graduate school and encountered an entire field called biologically inspired computation, an evolutionary computation, which merged ideas from evolution into computer science. And it's something that I got very deeply involved with later on. So that's an interesting point because in some ways you're drawing an analogy from the evolutionary biology world of Stephen Gould into a quite different realm and seeing that that perspective is transferable. Yes, exactly. That you can use, you could be inspired in a metaphorical way by ideas in one field and apply them into other fields. And interestingly, that's exactly what happened with Darwin, who sort of came up with a lot of these ideas. He was inspired by ideas from economics, from geology, and other fields, and he brought that into his own ideas about biology. So there's a lot of these cross-scientific analogies going on. It's an excellent point because certainly with Darwin's generation, there would have been a far broader education. And maybe that's part of the problem we have with AI, is that people are brilliant, but narrowly brilliant in very specific subdomains of subdomains. And so as a result, there isn't the same kind of cross-fertilization of ideas. Like for example, talking with someone who's coding an algorithm about empathy, there may not be an easy bridge with that coder and with those kinds of concepts simply because the background isn't there. They haven't come across the Steven Gould model that what you do is you find someone who is able to explain something brilliantly and see, again, you drew the metaphor of what he's talking about into another realm. You transported that infrastructure, that framework of thinking, and allowed you to see something quite different about computers that other people were not seeing. Well, yeah, I mean, I think I would say I was the one who came up with some of those analogies, but some of my mentors did. Talking about mentors, let's move on to Goethe Escher and Bach by Douglas Hofstadter, who I know was your mentor and an important intellectual force in your life. This book in 1973 was a monumental work. I want to pull a surprise. It is still read and discussed in the shape thinking of a couple generations since it was first published. So you must have read this book before you decided to, this was going to be your thing. You were at university somewhere, you got the book, what happened next? So I read it the year after I graduated from college. Okay. I actually read about it, I read a review of it in Martin Gardner's column in Scientific American, which is how I had heard about it in the first place. So I went out and bought it and it's a very long book. It's not like a beach read, if you will. It takes a lot of thinking. So I read it over the course of many months and decided that this is what I want to work on. And it's really a book about, it's about intelligence and how something like intelligence, as complex as intelligence, can emerge from a non-intelligent substrate, how consciousness might come about. And it uses ideas from mathematics, from music, from art, to kind of eliminate these core ideas. What was the connecting thread that Hofstadter discovered that links together Goethe and Bach and Escher? I say there are several connecting threads, but maybe one of them is this idea of self-reference that is fundamental in Goethe's theorem, his mathematical theorem, because you can get mathematical systems to be talking about themselves, to be referring to themselves. And that shows up in Escher. You see all these kinds of strange kind of loopy references. The hand drawing the hand. Yeah, the hand drawing the hand and so on. And in Bach's music, too, there's some examples that Hofstadter goes into in detail. And this is really the idea of intelligence is a self-rential, what he calls a strange loop, the strange loop of consciousness, where we're able to reflect on our own thinking. A kind of recursion. A kind of recursion, exactly. That goes on. And kind of a meta-thinking as well. So that at each stage recursive part, I mean, Bach's fugues, for example, there is a thing that reoccurs in them. From Nietzsche's eternal return. There are things that are patterns that show up against slightly altered, but recognizable. And that that that is the nature of intelligence, as we understand it. Something like that. Yeah, I mean, it's a... Hofstadter's ideas are not easily expressible in a short period of time. So, but that's kind of getting at the idea of this, what he calls this strange loop. Would you say that this, I mean, this is absolutely foundational book, that maybe it's at the outer edge of where you can use metaphor and summary with these abstractions to convey accurately what is being talked about. Because a lot of people find this book very, very difficult. Yeah, it is difficult. But what's really striking is how much Hofstadter comes up with amazing analogies and metaphors to talk about these things. And that's really, turns out to be what he's most fascinated by is how we think in analogies and metaphors. And he is a master of using these, you know, language and everyday examples to try and illustrate what's going on in these incredibly abstract ideas. So, he's a master cultural translator from these various realms. And again, using what, I mean, I can see the influence because you've done a number of articles on metaphor and analogy, particularly in the context of AI. So that understanding by way of metaphor and analogy has obviously been very central to your own development as a scientist and as an interpreter of science to a larger community. Yeah, and in fact, you know, Hofstadter was the one who introduced me to the idea of building AI systems that can make analogies. That was the topic of my PhD dissertation for which he was the advisor. Right. So this notion of analogy and metaphor kind of circles through all of my research. And it certainly circles through all of your readings as well. Evidently. You're starting to discover a certain kind of pattern that started at age eight. Yeah, I never had made that connection. It's kind of like psychotherapy, right? It's all started in your childhood. Are you still in contact with Professor Hofstadter? Yeah. Yeah. Talk to him from time to time. Okay. So the next book, unless there's something else you'd like to say about that, I think we've kind of established the fact that it's been transformational. I mean, your PhD thesis was about analogies, about the man who had written a book filled full of analogies and metaphors. And that was a watershed book and a watershed period of your life. Absolutely. Yep. The Recursive Universe by William Poundstone, which is really kind of the origin of complexity, which I know is another one of the fields that you've done a fair amount of research and study and writing. And explain a little bit about how this book came to you and what it said to you about complexity that still is important to you. Yes. So this book, I believe I read it in graduate school. I don't remember how I came across it. But what it is, it takes John Conway's Game of Life, which is what's called a cellular automaton. It's not exactly a game. It's more like a very idealized model, very simplified model of complex systems. And it uses this Game of Life and Game of Life is full of little patterns that people have discovered in things that are gliders and other kinds of structures that can do all kinds of computations. And Poundstone uses this as a way to talk about bigger ideas in cosmology and physics. And it's just a fascinating kind of approach to talking about those ideas. And it was one of my introductions to the Game of Life, and I think you've seen sort of how complex that all is and how complexity can emerge from these very simple rules, and then tying it to these much bigger ideas. So I just loved that book. I thought it was beautiful, and it's not that well known. I mean, it's surprisingly, I think, underappreciated. I think from what I've read, I haven't read the book, but I've read about it, and it seems absolutely fascinating in terms of of this notion of self-assembly, of how you can get very complex systems out of something that is in itself very simple. And for example, he gives the example of Pi, where, you know, basically you can encode it using only two terms and end up with this unbelievably complex number from just the initial to write the components to begin with. So I thought it was a quite interesting aspect of it. And the other thing is the initial information input and the relationship of information with entropy. You know, Claude Shannon with Bolson of looking at those two aspects of the universe, from an informational model to a model of the second law of thermodynamics or entropy, where things will go into greater disorder. Yes, exactly. So this book brought together a lot of ideas of complex systems that I had been thinking a little bit about, but never really found them brought all together, including entropy, information, computation, you know, he shows, he talks about Conway's proof that the game of life, which is just, it's just a two-dimensional grid of black and white, what they call cells, that influence each other in simple ways. But this actually you can embed an entire computer in this incredibly simple system. And it's just, it's full of very profound ideas. I know it's kind of fair you teach an online course on complexity, which is highly popular. I read somewhere like 25,000 students have more now, where I read is probably outdated. But it seems to be a very popular, is this one of the books that's in the course? So I don't use the book in that course, but I do talk about a lot of these ideas. I see. Yeah. So we cover that kind of thing. Yeah. Right. Okay. The last book on the list is Adaptations in Natural and Artificial Systems by John Holland. Last but not least, here we have adaptation is a biological process, rearranging genetic material, goes back to what you're talking earlier about Darwin's and in the evolutionary biology that you found an attractive way to take into another domain. So adaptation in Natural and Artificial Systems by John Holland, was this something from your university days or earlier? This was from graduate school. So John Holland was one of my professors at the University of Michigan. And he taught a course by, he was a computer science professor, yet he taught a course in computer science called Adaptation in Natural and Artificial Systems. It's a very technical book. So it's the only technical book on my list, really. But it was, John Holland was the founder of this field called Genetic Algorithms, which brought ideas from evolutionary biology into computer science. And this book was his theory of adaptation. So when you think about adaptation, maybe you think about some kind of species adapting to a particular niche. For instance, you have things like butterflies that the color of their wings change in response to their environment. And so this notion of adaptation is fundamental to biology. And yet Holland brought that into that field of computer science by saying what we want in computer science and AI is to have computers that adapt. So we don't want just living systems that adapt. We want machines that adapt, that are able to adapt to different environments and to be able to be flexible and learn the way that living systems do. So Holland became my co-advisor, along with Douglas Hofstetter. And this book was sort of set the path of a lot of my future research for up until now, really. Yeah. What seemed to me interesting about this book is the part that plays just conceptually of kind of perpetual novelty. That there is no kind of in-point that it's aimed for a particular in-point, that it's always open. And you can't quite predict where it will go, how that co-evolution or that adaptation will go next. I guess that's part of the non-linearity that he discusses in the book, is that we have trouble with things like exponential numbers, non-linearity. These are things that are outside our realm of experiences, like absolute time as opposed to relative time. And this is where you as a communicator of science try to come in and say, well, people are looking to take you to an in-point, but you have to be careful. Because the way in-points work in reality are quite different from the way that they're portrayed. Right. So one interesting thing about this idea of perpetual novelty that Holland talks about, you can imagine that in biology where you're having species continually evolving and changing and the environment's changing. But Holland also brought these ideas into economics. So interestingly, economics, the theory of economics that people, the sort of classical economic theory has to do with equilibrium. You want sort of this economic system to be in equilibrium or markets to be in equilibrium. But this idea of perpetual novelty says such systems are never in equilibrium. And therefore, the classical theories don't describe reality where we actually have this continually changing co-adaptive system of all these economic agents. So that's really been revolutionizing a lot of thinking in economics as well as in biology and computer science. Again, I guess things like global optimum and equilibrium are in a way metaphorical, trying to create the notion that there's an in-point where everything is absolutely balanced as opposed to the fact that in reality, nothing is ever balanced for long. There may be moments in time where it appears that birds and rabbits and dinosaurs had a particular adaptation, but then it doesn't last. It's overtaken by something else. And as a result, you have to live with the uncertainty of a perpetual changing environment and adaptation to those changes. Yes. I think one of your previous guests, John Allen Palos, has a great quote where he says, you know, living with uncertainty is the only certainty. That's something that I could just hear John saying. John's a friend I've known for years. Yeah, very, very brilliant mathematician and, again, a communicator of a high level as you are as well. So I want to thank you for this been a delightful conversation. Let me know, what do you think about the experience of being on the show? It's been a lot of fun. I mean, it's intimidating to try and have to think back on books that I've read years and years and years ago. But you reminded me of a lot of things that I'd forgotten, which has been great. And you also pointed out so many connections that I had never made about, you know, different the books, these books that I've read and the things that I've been thinking about for a long time. So I thank you for that. And thank you. This has been a wonderful conversation. And I will continue to follow your writings and learn from them. You're a master of communication between the arts and the science. And you contribute to both. And I think you have done a great job in that communication. Please keep up this wonderful work. Thank you so much. Bye for now. Okay, bye bye.", "segments": [{"id": 0, "seek": 0, "start": 0.0, "end": 28.0, "text": " So, let me start a little bit with the introduction of who Melanie Mitchell is.", "tokens": [50364, 407, 11, 718, 385, 722, 257, 707, 857, 365, 264, 9339, 295, 567, 42798, 27582, 307, 13, 51764], "temperature": 0.0, "avg_logprob": -0.2992351395743234, "compression_ratio": 1.082191780821918, "no_speech_prob": 0.02628546766936779}, {"id": 1, "seek": 2800, "start": 28.0, "end": 36.519999999999996, "text": " She is a Davis Professor of Complexity at Santa Fe Institute, and her research focuses", "tokens": [50364, 1240, 307, 257, 15658, 8419, 295, 41184, 507, 412, 9933, 3697, 9446, 11, 293, 720, 2132, 16109, 50790], "temperature": 0.0, "avg_logprob": -0.18605526515415738, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.5565208792686462}, {"id": 2, "seek": 2800, "start": 36.519999999999996, "end": 42.36, "text": " on conceptual abstraction, analogy making, and visual recognition.", "tokens": [50790, 322, 24106, 37765, 11, 21663, 1455, 11, 293, 5056, 11150, 13, 51082], "temperature": 0.0, "avg_logprob": -0.18605526515415738, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.5565208792686462}, {"id": 3, "seek": 2800, "start": 42.36, "end": 48.44, "text": " She's done a couple of very popular and well-received books.", "tokens": [51082, 1240, 311, 1096, 257, 1916, 295, 588, 3743, 293, 731, 12, 44209, 3194, 3642, 13, 51386], "temperature": 0.0, "avg_logprob": -0.18605526515415738, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.5565208792686462}, {"id": 4, "seek": 2800, "start": 48.44, "end": 54.86, "text": " The first one was Oxford University Press in 2009, Complexity, a guided tour.", "tokens": [51386, 440, 700, 472, 390, 24786, 3535, 6776, 294, 11453, 11, 41184, 507, 11, 257, 19663, 3512, 13, 51707], "temperature": 0.0, "avg_logprob": -0.18605526515415738, "compression_ratio": 1.3904761904761904, "no_speech_prob": 0.5565208792686462}, {"id": 5, "seek": 5486, "start": 54.86, "end": 61.46, "text": " Her most recent book is Artificial Intelligence, a Guide for Thinking Humans, and I have to", "tokens": [50364, 3204, 881, 5162, 1446, 307, 5735, 10371, 27274, 11, 257, 18727, 337, 24460, 35809, 11, 293, 286, 362, 281, 50694], "temperature": 0.0, "avg_logprob": -0.22412758904534416, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.41796281933784485}, {"id": 6, "seek": 5486, "start": 61.46, "end": 68.02, "text": " say that people who've talked about the Artificial Intelligence book have said some very, very", "tokens": [50694, 584, 300, 561, 567, 600, 2825, 466, 264, 5735, 10371, 27274, 1446, 362, 848, 512, 588, 11, 588, 51022], "temperature": 0.0, "avg_logprob": -0.22412758904534416, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.41796281933784485}, {"id": 7, "seek": 5486, "start": 68.02, "end": 69.98, "text": " good things.", "tokens": [51022, 665, 721, 13, 51120], "temperature": 0.0, "avg_logprob": -0.22412758904534416, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.41796281933784485}, {"id": 8, "seek": 5486, "start": 69.98, "end": 78.22, "text": " For example, we have Allison Gopnik, who says it's very intelligent, clear and sensible", "tokens": [51120, 1171, 1365, 11, 321, 362, 32638, 460, 404, 13123, 11, 567, 1619, 309, 311, 588, 13232, 11, 1850, 293, 25380, 51532], "temperature": 0.0, "avg_logprob": -0.22412758904534416, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.41796281933784485}, {"id": 9, "seek": 5486, "start": 78.22, "end": 79.22, "text": " book.", "tokens": [51532, 1446, 13, 51582], "temperature": 0.0, "avg_logprob": -0.22412758904534416, "compression_ratio": 1.5585106382978724, "no_speech_prob": 0.41796281933784485}, {"id": 10, "seek": 7922, "start": 79.22, "end": 86.46, "text": " Jeffrey West at Santa Fe has said it's remarkably lucid, comprehensive overview.", "tokens": [50364, 28721, 4055, 412, 9933, 3697, 575, 848, 309, 311, 37381, 21296, 327, 11, 13914, 12492, 13, 50726], "temperature": 0.0, "avg_logprob": -0.22532981634140015, "compression_ratio": 1.3990147783251232, "no_speech_prob": 0.02632426843047142}, {"id": 11, "seek": 7922, "start": 86.46, "end": 93.14, "text": " Sean Carroll, an astonishing intelligence, and John Paulus, who's been on the show,", "tokens": [50726, 14839, 48456, 11, 364, 35264, 7599, 11, 293, 2619, 4552, 301, 11, 567, 311, 668, 322, 264, 855, 11, 51060], "temperature": 0.0, "avg_logprob": -0.22532981634140015, "compression_ratio": 1.3990147783251232, "no_speech_prob": 0.02632426843047142}, {"id": 12, "seek": 7922, "start": 93.14, "end": 99.62, "text": " says that Mitchell sketches enough details and clever illustrations that one gets a good", "tokens": [51060, 1619, 300, 27582, 34547, 1547, 4365, 293, 13494, 34540, 300, 472, 2170, 257, 665, 51384], "temperature": 0.0, "avg_logprob": -0.22532981634140015, "compression_ratio": 1.3990147783251232, "no_speech_prob": 0.02632426843047142}, {"id": 13, "seek": 7922, "start": 99.62, "end": 102.86, "text": " intuitive understanding of AI.", "tokens": [51384, 21769, 3701, 295, 7318, 13, 51546], "temperature": 0.0, "avg_logprob": -0.22532981634140015, "compression_ratio": 1.3990147783251232, "no_speech_prob": 0.02632426843047142}, {"id": 14, "seek": 10286, "start": 102.86, "end": 111.14, "text": " So you have high praise from some of the titans of a number of different disciplines,", "tokens": [50364, 407, 291, 362, 1090, 13286, 490, 512, 295, 264, 3459, 599, 295, 257, 1230, 295, 819, 21919, 11, 50778], "temperature": 0.0, "avg_logprob": -0.12630941156755415, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.12409839779138565}, {"id": 15, "seek": 10286, "start": 111.14, "end": 114.74, "text": " and I think that's a good way to take the next step.", "tokens": [50778, 293, 286, 519, 300, 311, 257, 665, 636, 281, 747, 264, 958, 1823, 13, 50958], "temperature": 0.0, "avg_logprob": -0.12630941156755415, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.12409839779138565}, {"id": 16, "seek": 10286, "start": 114.74, "end": 124.6, "text": " The next step is I'm in conversation with someone who is familiar with at least three", "tokens": [50958, 440, 958, 1823, 307, 286, 478, 294, 3761, 365, 1580, 567, 307, 4963, 365, 412, 1935, 1045, 51451], "temperature": 0.0, "avg_logprob": -0.12630941156755415, "compression_ratio": 1.4545454545454546, "no_speech_prob": 0.12409839779138565}, {"id": 17, "seek": 12460, "start": 124.6, "end": 135.5, "text": " important domains, mathematics, physics, and computer science, as well as artificial", "tokens": [50364, 1021, 25514, 11, 18666, 11, 10649, 11, 293, 3820, 3497, 11, 382, 731, 382, 11677, 50909], "temperature": 0.0, "avg_logprob": -0.13237777806944767, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.6751567125320435}, {"id": 18, "seek": 12460, "start": 135.5, "end": 142.92, "text": " intelligence, which I would put in as part of the computer science part of this.", "tokens": [50909, 7599, 11, 597, 286, 576, 829, 294, 382, 644, 295, 264, 3820, 3497, 644, 295, 341, 13, 51280], "temperature": 0.0, "avg_logprob": -0.13237777806944767, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.6751567125320435}, {"id": 19, "seek": 12460, "start": 142.92, "end": 152.12, "text": " So I see from my research of your background is you really have excelled as an interpreter,", "tokens": [51280, 407, 286, 536, 490, 452, 2132, 295, 428, 3678, 307, 291, 534, 362, 45817, 292, 382, 364, 34132, 11, 51740], "temperature": 0.0, "avg_logprob": -0.13237777806944767, "compression_ratio": 1.5575757575757576, "no_speech_prob": 0.6751567125320435}, {"id": 20, "seek": 15212, "start": 152.12, "end": 158.88, "text": " as someone who's been able to translate between these domains.", "tokens": [50364, 382, 1580, 567, 311, 668, 1075, 281, 13799, 1296, 613, 25514, 13, 50702], "temperature": 0.0, "avg_logprob": -0.1540431158883231, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.1478366106748581}, {"id": 21, "seek": 15212, "start": 158.88, "end": 164.20000000000002, "text": " And as a result, we'll be looking a little later in the show about how your childhood", "tokens": [50702, 400, 382, 257, 1874, 11, 321, 603, 312, 1237, 257, 707, 1780, 294, 264, 855, 466, 577, 428, 9278, 50968], "temperature": 0.0, "avg_logprob": -0.1540431158883231, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.1478366106748581}, {"id": 22, "seek": 15212, "start": 164.20000000000002, "end": 173.64000000000001, "text": " reading and those books help you create this kind of ability to map and track other thought", "tokens": [50968, 3760, 293, 729, 3642, 854, 291, 1884, 341, 733, 295, 3485, 281, 4471, 293, 2837, 661, 1194, 51440], "temperature": 0.0, "avg_logprob": -0.1540431158883231, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.1478366106748581}, {"id": 23, "seek": 15212, "start": 173.64000000000001, "end": 180.20000000000002, "text": " processes in other domains and make them accessible to ordinary people.", "tokens": [51440, 7555, 294, 661, 25514, 293, 652, 552, 9515, 281, 10547, 561, 13, 51768], "temperature": 0.0, "avg_logprob": -0.1540431158883231, "compression_ratio": 1.5918367346938775, "no_speech_prob": 0.1478366106748581}, {"id": 24, "seek": 18020, "start": 181.2, "end": 190.39999999999998, "text": " Yeah, so we humans are all masters of analogy, even when we don't know it.", "tokens": [50414, 865, 11, 370, 321, 6255, 366, 439, 19294, 295, 21663, 11, 754, 562, 321, 500, 380, 458, 309, 13, 50874], "temperature": 0.0, "avg_logprob": -0.15224846601486205, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.025154396891593933}, {"id": 25, "seek": 18020, "start": 190.39999999999998, "end": 196.2, "text": " So let's think about a kind of unconscious analogy.", "tokens": [50874, 407, 718, 311, 519, 466, 257, 733, 295, 18900, 21663, 13, 51164], "temperature": 0.0, "avg_logprob": -0.15224846601486205, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.025154396891593933}, {"id": 26, "seek": 18020, "start": 196.2, "end": 199.48, "text": " One example that I use is the notion of a bridge.", "tokens": [51164, 1485, 1365, 300, 286, 764, 307, 264, 10710, 295, 257, 7283, 13, 51328], "temperature": 0.0, "avg_logprob": -0.15224846601486205, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.025154396891593933}, {"id": 27, "seek": 18020, "start": 199.48, "end": 201.28, "text": " We all know what a bridge is.", "tokens": [51328, 492, 439, 458, 437, 257, 7283, 307, 13, 51418], "temperature": 0.0, "avg_logprob": -0.15224846601486205, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.025154396891593933}, {"id": 28, "seek": 18020, "start": 201.28, "end": 205.79999999999998, "text": " We all drive across bridges or we walk across bridges, whatever, but we also talk about", "tokens": [51418, 492, 439, 3332, 2108, 21114, 420, 321, 1792, 2108, 21114, 11, 2035, 11, 457, 321, 611, 751, 466, 51644], "temperature": 0.0, "avg_logprob": -0.15224846601486205, "compression_ratio": 1.5806451612903225, "no_speech_prob": 0.025154396891593933}, {"id": 29, "seek": 20580, "start": 205.8, "end": 212.96, "text": " bridges like the bridging the gender gap, or the bridge of a song, or the bridge of", "tokens": [50364, 21114, 411, 264, 16362, 3249, 264, 7898, 7417, 11, 420, 264, 7283, 295, 257, 2153, 11, 420, 264, 7283, 295, 50722], "temperature": 0.0, "avg_logprob": -0.1574907179002638, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.006483746692538261}, {"id": 30, "seek": 20580, "start": 212.96, "end": 221.96, "text": " my nose, or there's all kinds of ways in which these terms are used metaphorically or by", "tokens": [50722, 452, 6690, 11, 420, 456, 311, 439, 3685, 295, 2098, 294, 597, 613, 2115, 366, 1143, 19157, 984, 420, 538, 51172], "temperature": 0.0, "avg_logprob": -0.1574907179002638, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.006483746692538261}, {"id": 31, "seek": 20580, "start": 221.96, "end": 226.8, "text": " analogy throughout language, even unconsciously.", "tokens": [51172, 21663, 3710, 2856, 11, 754, 18900, 356, 13, 51414], "temperature": 0.0, "avg_logprob": -0.1574907179002638, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.006483746692538261}, {"id": 32, "seek": 20580, "start": 226.8, "end": 234.52, "text": " But this kind of ability we have to extend concepts in this metaphorical way, and it's", "tokens": [51414, 583, 341, 733, 295, 3485, 321, 362, 281, 10101, 10392, 294, 341, 19157, 804, 636, 11, 293, 309, 311, 51800], "temperature": 0.0, "avg_logprob": -0.1574907179002638, "compression_ratio": 1.6296296296296295, "no_speech_prob": 0.006483746692538261}, {"id": 33, "seek": 23452, "start": 234.52, "end": 241.92000000000002, "text": " not just bridge, you could do it with almost any concept we want to talk about, is, I claim,", "tokens": [50364, 406, 445, 7283, 11, 291, 727, 360, 309, 365, 1920, 604, 3410, 321, 528, 281, 751, 466, 11, 307, 11, 286, 3932, 11, 50734], "temperature": 0.0, "avg_logprob": -0.19244133984601056, "compression_ratio": 1.5502392344497609, "no_speech_prob": 0.0016479818150401115}, {"id": 34, "seek": 23452, "start": 241.92000000000002, "end": 245.72, "text": " what gives us our unique kind of intelligence.", "tokens": [50734, 437, 2709, 505, 527, 3845, 733, 295, 7599, 13, 50924], "temperature": 0.0, "avg_logprob": -0.19244133984601056, "compression_ratio": 1.5502392344497609, "no_speech_prob": 0.0016479818150401115}, {"id": 35, "seek": 23452, "start": 245.72, "end": 255.24, "text": " It allows us to understand more and more abstract notions in terms of very physical notions.", "tokens": [50924, 467, 4045, 505, 281, 1223, 544, 293, 544, 12649, 35799, 294, 2115, 295, 588, 4001, 35799, 13, 51400], "temperature": 0.0, "avg_logprob": -0.19244133984601056, "compression_ratio": 1.5502392344497609, "no_speech_prob": 0.0016479818150401115}, {"id": 36, "seek": 23452, "start": 255.24, "end": 261.12, "text": " Like you just said, you know, she has sunny face, so we all instantly know what that means.", "tokens": [51400, 1743, 291, 445, 848, 11, 291, 458, 11, 750, 575, 20412, 1851, 11, 370, 321, 439, 13518, 458, 437, 300, 1355, 13, 51694], "temperature": 0.0, "avg_logprob": -0.19244133984601056, "compression_ratio": 1.5502392344497609, "no_speech_prob": 0.0016479818150401115}, {"id": 37, "seek": 26112, "start": 261.12, "end": 266.48, "text": " And we know, we don't even think of it necessarily as a metaphor.", "tokens": [50364, 400, 321, 458, 11, 321, 500, 380, 754, 519, 295, 309, 4725, 382, 257, 19157, 13, 50632], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 38, "seek": 26112, "start": 266.48, "end": 271.56, "text": " It's just so, you know, I might say, oh, you gave me such a warm introduction, you know,", "tokens": [50632, 467, 311, 445, 370, 11, 291, 458, 11, 286, 1062, 584, 11, 1954, 11, 291, 2729, 385, 1270, 257, 4561, 9339, 11, 291, 458, 11, 50886], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 39, "seek": 26112, "start": 271.56, "end": 275.8, "text": " and it was, it wasn't literally warm, right?", "tokens": [50886, 293, 309, 390, 11, 309, 2067, 380, 3736, 4561, 11, 558, 30, 51098], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 40, "seek": 26112, "start": 275.8, "end": 281.04, "text": " The temperature in this room didn't literally go up, I don't think, but it's something", "tokens": [51098, 440, 4292, 294, 341, 1808, 994, 380, 3736, 352, 493, 11, 286, 500, 380, 519, 11, 457, 309, 311, 746, 51360], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 41, "seek": 26112, "start": 281.04, "end": 285.48, "text": " that we all couch all of our abstract thinking in.", "tokens": [51360, 300, 321, 439, 16511, 439, 295, 527, 12649, 1953, 294, 13, 51582], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 42, "seek": 26112, "start": 285.48, "end": 290.52, "text": " And this is exactly what AI systems today are lacking.", "tokens": [51582, 400, 341, 307, 2293, 437, 7318, 3652, 965, 366, 20889, 13, 51834], "temperature": 0.0, "avg_logprob": -0.16765081773110485, "compression_ratio": 1.6333333333333333, "no_speech_prob": 0.003823194419965148}, {"id": 43, "seek": 29052, "start": 290.52, "end": 298.71999999999997, "text": " They can learn to recognize photos of bridges, but they can't make that extension and talk", "tokens": [50364, 814, 393, 1466, 281, 5521, 5787, 295, 21114, 11, 457, 436, 393, 380, 652, 300, 10320, 293, 751, 50774], "temperature": 0.0, "avg_logprob": -0.1759807268778483, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012800770811736584}, {"id": 44, "seek": 29052, "start": 298.71999999999997, "end": 308.84, "text": " about, you know, a bridge between two people, you know, you and I, or you may be your bridgingness,", "tokens": [50774, 466, 11, 291, 458, 11, 257, 7283, 1296, 732, 561, 11, 291, 458, 11, 291, 293, 286, 11, 420, 291, 815, 312, 428, 16362, 3249, 1287, 11, 51280], "temperature": 0.0, "avg_logprob": -0.1759807268778483, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012800770811736584}, {"id": 45, "seek": 29052, "start": 308.84, "end": 313.28, "text": " the culture of science with the culture of humanities, or things like that.", "tokens": [51280, 264, 3713, 295, 3497, 365, 264, 3713, 295, 36140, 11, 420, 721, 411, 300, 13, 51502], "temperature": 0.0, "avg_logprob": -0.1759807268778483, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012800770811736584}, {"id": 46, "seek": 29052, "start": 313.28, "end": 318.24, "text": " So that's fascinating to me, and that's what my research is on, is trying to understand", "tokens": [51502, 407, 300, 311, 10343, 281, 385, 11, 293, 300, 311, 437, 452, 2132, 307, 322, 11, 307, 1382, 281, 1223, 51750], "temperature": 0.0, "avg_logprob": -0.1759807268778483, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.012800770811736584}, {"id": 47, "seek": 31824, "start": 318.28000000000003, "end": 326.12, "text": " how human concepts are formed, what kind of structure they have, and how we might give", "tokens": [50366, 577, 1952, 10392, 366, 8693, 11, 437, 733, 295, 3877, 436, 362, 11, 293, 577, 321, 1062, 976, 50758], "temperature": 0.0, "avg_logprob": -0.21565785483708458, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0064847334288060665}, {"id": 48, "seek": 31824, "start": 326.12, "end": 328.36, "text": " such a concept to a machine.", "tokens": [50758, 1270, 257, 3410, 281, 257, 3479, 13, 50870], "temperature": 0.0, "avg_logprob": -0.21565785483708458, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0064847334288060665}, {"id": 49, "seek": 31824, "start": 328.36, "end": 337.8, "text": " Yeah, presumably we're some ways away from AI understanding it's raining cats and dogs.", "tokens": [50870, 865, 11, 26742, 321, 434, 512, 2098, 1314, 490, 7318, 3701, 309, 311, 18441, 11111, 293, 7197, 13, 51342], "temperature": 0.0, "avg_logprob": -0.21565785483708458, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0064847334288060665}, {"id": 50, "seek": 31824, "start": 337.8, "end": 345.2, "text": " Or, or she has a heart of gold.", "tokens": [51342, 1610, 11, 420, 750, 575, 257, 1917, 295, 3821, 13, 51712], "temperature": 0.0, "avg_logprob": -0.21565785483708458, "compression_ratio": 1.3823529411764706, "no_speech_prob": 0.0064847334288060665}, {"id": 51, "seek": 34520, "start": 345.2, "end": 351.36, "text": " I mean, yeah, we don't, we, one problem with talking about AI is that we, when we talk", "tokens": [50364, 286, 914, 11, 1338, 11, 321, 500, 380, 11, 321, 11, 472, 1154, 365, 1417, 466, 7318, 307, 300, 321, 11, 562, 321, 751, 50672], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 52, "seek": 34520, "start": 351.36, "end": 354.71999999999997, "text": " about understanding, we don't really know exactly what we mean.", "tokens": [50672, 466, 3701, 11, 321, 500, 380, 534, 458, 2293, 437, 321, 914, 13, 50840], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 53, "seek": 34520, "start": 354.71999999999997, "end": 357.76, "text": " What is it to understand something?", "tokens": [50840, 708, 307, 309, 281, 1223, 746, 30, 50992], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 54, "seek": 34520, "start": 357.76, "end": 363.15999999999997, "text": " That's actually been debated quite a bit by philosophers for millennia.", "tokens": [50992, 663, 311, 767, 668, 42212, 1596, 257, 857, 538, 36839, 337, 21362, 654, 13, 51262], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 55, "seek": 34520, "start": 363.15999999999997, "end": 366.32, "text": " And it's really an unanswered question.", "tokens": [51262, 400, 309, 311, 534, 364, 517, 43904, 292, 1168, 13, 51420], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 56, "seek": 34520, "start": 366.32, "end": 371.76, "text": " It's one of those words we use to describe our mental state that we don't quite understand", "tokens": [51420, 467, 311, 472, 295, 729, 2283, 321, 764, 281, 6786, 527, 4973, 1785, 300, 321, 500, 380, 1596, 1223, 51692], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 57, "seek": 34520, "start": 371.76, "end": 373.91999999999996, "text": " scientifically what it means.", "tokens": [51692, 39719, 437, 309, 1355, 13, 51800], "temperature": 0.0, "avg_logprob": -0.13900175801029913, "compression_ratio": 1.689516129032258, "no_speech_prob": 0.006686783395707607}, {"id": 58, "seek": 37392, "start": 374.0, "end": 381.72, "text": " I think in terms of kind of the sort of intuitive understanding we have of that notion, you're", "tokens": [50368, 286, 519, 294, 2115, 295, 733, 295, 264, 1333, 295, 21769, 3701, 321, 362, 295, 300, 10710, 11, 291, 434, 50754], "temperature": 0.0, "avg_logprob": -0.20855259895324707, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.0021819332614541054}, {"id": 59, "seek": 37392, "start": 381.72, "end": 386.28000000000003, "text": " absolutely right, machines don't have the same kind of understanding of language that", "tokens": [50754, 3122, 558, 11, 8379, 500, 380, 362, 264, 912, 733, 295, 3701, 295, 2856, 300, 50982], "temperature": 0.0, "avg_logprob": -0.20855259895324707, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.0021819332614541054}, {"id": 60, "seek": 37392, "start": 386.28000000000003, "end": 388.08000000000004, "text": " we humans have.", "tokens": [50982, 321, 6255, 362, 13, 51072], "temperature": 0.0, "avg_logprob": -0.20855259895324707, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.0021819332614541054}, {"id": 61, "seek": 37392, "start": 388.08000000000004, "end": 397.24, "text": " I'm wondering as well if part of that issue has to do with, you've written about GPT-3", "tokens": [51072, 286, 478, 6359, 382, 731, 498, 644, 295, 300, 2734, 575, 281, 360, 365, 11, 291, 600, 3720, 466, 26039, 51, 12, 18, 51530], "temperature": 0.0, "avg_logprob": -0.20855259895324707, "compression_ratio": 1.546448087431694, "no_speech_prob": 0.0021819332614541054}, {"id": 62, "seek": 39724, "start": 397.24, "end": 400.44, "text": " making a knowledges in medium.", "tokens": [50364, 1455, 257, 458, 1493, 2880, 294, 6399, 13, 50524], "temperature": 0.0, "avg_logprob": -0.18036182403564452, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.30042392015457153}, {"id": 63, "seek": 39724, "start": 400.44, "end": 406.68, "text": " And you've said that with metaphors there isn't a right answer.", "tokens": [50524, 400, 291, 600, 848, 300, 365, 30946, 830, 456, 1943, 380, 257, 558, 1867, 13, 50836], "temperature": 0.0, "avg_logprob": -0.18036182403564452, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.30042392015457153}, {"id": 64, "seek": 39724, "start": 406.68, "end": 411.40000000000003, "text": " There's an effective explanation or description that convey information.", "tokens": [50836, 821, 311, 364, 4942, 10835, 420, 3855, 300, 16965, 1589, 13, 51072], "temperature": 0.0, "avg_logprob": -0.18036182403564452, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.30042392015457153}, {"id": 65, "seek": 39724, "start": 411.40000000000003, "end": 415.76, "text": " It's really a conveyor from the abstract to the concrete.", "tokens": [51072, 467, 311, 534, 257, 18053, 2454, 490, 264, 12649, 281, 264, 9859, 13, 51290], "temperature": 0.0, "avg_logprob": -0.18036182403564452, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.30042392015457153}, {"id": 66, "seek": 39724, "start": 415.76, "end": 422.2, "text": " But it's not, you can't really say it's 100% right.", "tokens": [51290, 583, 309, 311, 406, 11, 291, 393, 380, 534, 584, 309, 311, 2319, 4, 558, 13, 51612], "temperature": 0.0, "avg_logprob": -0.18036182403564452, "compression_ratio": 1.4578947368421054, "no_speech_prob": 0.30042392015457153}, {"id": 67, "seek": 42220, "start": 422.2, "end": 424.4, "text": " It can be close to right.", "tokens": [50364, 467, 393, 312, 1998, 281, 558, 13, 50474], "temperature": 0.0, "avg_logprob": -0.14626957121349515, "compression_ratio": 1.5257142857142858, "no_speech_prob": 0.053366128355264664}, {"id": 68, "seek": 42220, "start": 424.4, "end": 432.44, "text": " What goes back to what you were talking about a moment ago is how we understand that transition", "tokens": [50474, 708, 1709, 646, 281, 437, 291, 645, 1417, 466, 257, 1623, 2057, 307, 577, 321, 1223, 300, 6034, 50876], "temperature": 0.0, "avg_logprob": -0.14626957121349515, "compression_ratio": 1.5257142857142858, "no_speech_prob": 0.053366128355264664}, {"id": 69, "seek": 42220, "start": 432.44, "end": 437.36, "text": " from the abstract into something that's concrete.", "tokens": [50876, 490, 264, 12649, 666, 746, 300, 311, 9859, 13, 51122], "temperature": 0.0, "avg_logprob": -0.14626957121349515, "compression_ratio": 1.5257142857142858, "no_speech_prob": 0.053366128355264664}, {"id": 70, "seek": 42220, "start": 437.36, "end": 444.56, "text": " Is it giving us with that similarity a true representation from what the abstract really", "tokens": [51122, 1119, 309, 2902, 505, 365, 300, 32194, 257, 2074, 10290, 490, 437, 264, 12649, 534, 51482], "temperature": 0.0, "avg_logprob": -0.14626957121349515, "compression_ratio": 1.5257142857142858, "no_speech_prob": 0.053366128355264664}, {"id": 71, "seek": 42220, "start": 444.56, "end": 445.56, "text": " means?", "tokens": [51482, 1355, 30, 51532], "temperature": 0.0, "avg_logprob": -0.14626957121349515, "compression_ratio": 1.5257142857142858, "no_speech_prob": 0.053366128355264664}, {"id": 72, "seek": 44556, "start": 445.92, "end": 456.52, "text": " Yeah, it's machines, they've been shown to be what people in AI call very brittle, meaning", "tokens": [50382, 865, 11, 309, 311, 8379, 11, 436, 600, 668, 4898, 281, 312, 437, 561, 294, 7318, 818, 588, 49325, 11, 3620, 50912], "temperature": 0.0, "avg_logprob": -0.2047773843788239, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.008571057580411434}, {"id": 73, "seek": 44556, "start": 456.52, "end": 463.68, "text": " that they have this kind of appearance of being intelligent until suddenly something", "tokens": [50912, 300, 436, 362, 341, 733, 295, 8967, 295, 885, 13232, 1826, 5800, 746, 51270], "temperature": 0.0, "avg_logprob": -0.2047773843788239, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.008571057580411434}, {"id": 74, "seek": 44556, "start": 463.68, "end": 465.2, "text": " shows you very clearly.", "tokens": [51270, 3110, 291, 588, 4448, 13, 51346], "temperature": 0.0, "avg_logprob": -0.2047773843788239, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.008571057580411434}, {"id": 75, "seek": 44556, "start": 465.2, "end": 470.28, "text": " It's like it's a breaking point and that's why it's brittleness that they didn't understand", "tokens": [51346, 467, 311, 411, 309, 311, 257, 7697, 935, 293, 300, 311, 983, 309, 311, 738, 593, 45887, 300, 436, 994, 380, 1223, 51600], "temperature": 0.0, "avg_logprob": -0.2047773843788239, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.008571057580411434}, {"id": 76, "seek": 44556, "start": 470.28, "end": 475.32, "text": " at all what the language they were using meant.", "tokens": [51600, 412, 439, 437, 264, 2856, 436, 645, 1228, 4140, 13, 51852], "temperature": 0.0, "avg_logprob": -0.2047773843788239, "compression_ratio": 1.599056603773585, "no_speech_prob": 0.008571057580411434}, {"id": 77, "seek": 47532, "start": 476.08, "end": 486.15999999999997, "text": " What of my favorite things I saw on social media some time ago was someone had taken", "tokens": [50402, 708, 295, 452, 2954, 721, 286, 1866, 322, 2093, 3021, 512, 565, 2057, 390, 1580, 632, 2726, 50906], "temperature": 0.0, "avg_logprob": -0.1929130107164383, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.054112426936626434}, {"id": 78, "seek": 47532, "start": 486.15999999999997, "end": 492.4, "text": " an apple and written the word iPad on a piece of paper and put that on the apple with a", "tokens": [50906, 364, 10606, 293, 3720, 264, 1349, 12945, 322, 257, 2522, 295, 3035, 293, 829, 300, 322, 264, 10606, 365, 257, 51218], "temperature": 0.0, "avg_logprob": -0.1929130107164383, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.054112426936626434}, {"id": 79, "seek": 47532, "start": 492.4, "end": 500.92, "text": " rubber band and then ask an AI for questions or for answers to what this is and it said", "tokens": [51218, 11593, 4116, 293, 550, 1029, 364, 7318, 337, 1651, 420, 337, 6338, 281, 437, 341, 307, 293, 309, 848, 51644], "temperature": 0.0, "avg_logprob": -0.1929130107164383, "compression_ratio": 1.5294117647058822, "no_speech_prob": 0.054112426936626434}, {"id": 80, "seek": 50092, "start": 500.96000000000004, "end": 504.04, "text": " with 90% probability it's an iPod.", "tokens": [50366, 365, 4289, 4, 8482, 309, 311, 364, 5180, 378, 13, 50520], "temperature": 0.0, "avg_logprob": -0.270098143357497, "compression_ratio": 1.4268292682926829, "no_speech_prob": 0.027978379279375076}, {"id": 81, "seek": 50092, "start": 507.64000000000004, "end": 518.9200000000001, "text": " So that kind of literalism, you can see it's part of that inability to deal with analogies", "tokens": [50700, 407, 300, 733, 295, 20411, 1434, 11, 291, 393, 536, 309, 311, 644, 295, 300, 33162, 281, 2028, 365, 16660, 530, 51264], "temperature": 0.0, "avg_logprob": -0.270098143357497, "compression_ratio": 1.4268292682926829, "no_speech_prob": 0.027978379279375076}, {"id": 82, "seek": 50092, "start": 518.9200000000001, "end": 519.9200000000001, "text": " and metaphors.", "tokens": [51264, 293, 30946, 830, 13, 51314], "temperature": 0.0, "avg_logprob": -0.270098143357497, "compression_ratio": 1.4268292682926829, "no_speech_prob": 0.027978379279375076}, {"id": 83, "seek": 50092, "start": 519.9200000000001, "end": 527.64, "text": " And again, you've talked about in how analogies shape our thoughts, what happens if you strip", "tokens": [51314, 400, 797, 11, 291, 600, 2825, 466, 294, 577, 16660, 530, 3909, 527, 4598, 11, 437, 2314, 498, 291, 12828, 51700], "temperature": 0.0, "avg_logprob": -0.270098143357497, "compression_ratio": 1.4268292682926829, "no_speech_prob": 0.027978379279375076}, {"id": 84, "seek": 52764, "start": 527.72, "end": 534.48, "text": " away metaphors, simile, and analogies from language, what is left?", "tokens": [50368, 1314, 30946, 830, 11, 1034, 794, 11, 293, 16660, 530, 490, 2856, 11, 437, 307, 1411, 30, 50706], "temperature": 0.0, "avg_logprob": -0.23824780423876266, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00400572782382369}, {"id": 85, "seek": 52764, "start": 535.96, "end": 538.04, "text": " Are we left just with abstractions?", "tokens": [50780, 2014, 321, 1411, 445, 365, 12649, 626, 30, 50884], "temperature": 0.0, "avg_logprob": -0.23824780423876266, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00400572782382369}, {"id": 86, "seek": 52764, "start": 538.04, "end": 545.28, "text": " Is that the part of the problem that we have with storytelling AIs is that they lack the", "tokens": [50884, 1119, 300, 264, 644, 295, 264, 1154, 300, 321, 362, 365, 21479, 316, 6802, 307, 300, 436, 5011, 264, 51246], "temperature": 0.0, "avg_logprob": -0.23824780423876266, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00400572782382369}, {"id": 87, "seek": 52764, "start": 545.28, "end": 554.12, "text": " essential building blocks of how you tell a story, which basically is the bricks of that", "tokens": [51246, 7115, 2390, 8474, 295, 577, 291, 980, 257, 1657, 11, 597, 1936, 307, 264, 25497, 295, 300, 51688], "temperature": 0.0, "avg_logprob": -0.23824780423876266, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.00400572782382369}, {"id": 88, "seek": 55412, "start": 554.2, "end": 557.92, "text": " building of that story really are metaphorical, a lot of them.", "tokens": [50368, 2390, 295, 300, 1657, 534, 366, 19157, 804, 11, 257, 688, 295, 552, 13, 50554], "temperature": 0.0, "avg_logprob": -0.1657911866575807, "compression_ratio": 1.721951219512195, "no_speech_prob": 0.002980303717777133}, {"id": 89, "seek": 55412, "start": 559.12, "end": 561.2, "text": " That's one of the problems for sure.", "tokens": [50614, 663, 311, 472, 295, 264, 2740, 337, 988, 13, 50718], "temperature": 0.0, "avg_logprob": -0.1657911866575807, "compression_ratio": 1.721951219512195, "no_speech_prob": 0.002980303717777133}, {"id": 90, "seek": 55412, "start": 561.88, "end": 565.88, "text": " Another problem is that AI systems don't understand how the world works.", "tokens": [50752, 3996, 1154, 307, 300, 7318, 3652, 500, 380, 1223, 577, 264, 1002, 1985, 13, 50952], "temperature": 0.0, "avg_logprob": -0.1657911866575807, "compression_ratio": 1.721951219512195, "no_speech_prob": 0.002980303717777133}, {"id": 91, "seek": 55412, "start": 566.68, "end": 576.84, "text": " You know, they don't know that they don't know that, you know, if a child is holding", "tokens": [50992, 509, 458, 11, 436, 500, 380, 458, 300, 436, 500, 380, 458, 300, 11, 291, 458, 11, 498, 257, 1440, 307, 5061, 51500], "temperature": 0.0, "avg_logprob": -0.1657911866575807, "compression_ratio": 1.721951219512195, "no_speech_prob": 0.002980303717777133}, {"id": 92, "seek": 55412, "start": 576.84, "end": 582.52, "text": " an ice cream cone and then the ice cream cone falls on the ground, that that would be upsetting", "tokens": [51500, 364, 4435, 4689, 19749, 293, 550, 264, 4435, 4689, 19749, 8804, 322, 264, 2727, 11, 300, 300, 576, 312, 44109, 51784], "temperature": 0.0, "avg_logprob": -0.1657911866575807, "compression_ratio": 1.721951219512195, "no_speech_prob": 0.002980303717777133}, {"id": 93, "seek": 58252, "start": 583.3199999999999, "end": 585.0, "text": " because how are they going to know that?", "tokens": [50404, 570, 577, 366, 436, 516, 281, 458, 300, 30, 50488], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 94, "seek": 58252, "start": 585.0, "end": 587.96, "text": " They haven't experienced the world the way that we have.", "tokens": [50488, 814, 2378, 380, 6751, 264, 1002, 264, 636, 300, 321, 362, 13, 50636], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 95, "seek": 58252, "start": 588.84, "end": 594.6, "text": " They don't even know that, you know, when an ice cream cone hits the ground that it's going,", "tokens": [50680, 814, 500, 380, 754, 458, 300, 11, 291, 458, 11, 562, 364, 4435, 4689, 19749, 8664, 264, 2727, 300, 309, 311, 516, 11, 50968], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 96, "seek": 58252, "start": 594.6, "end": 597.64, "text": " it's not edible anymore, and you wouldn't want to eat it.", "tokens": [50968, 309, 311, 406, 30666, 3602, 11, 293, 291, 2759, 380, 528, 281, 1862, 309, 13, 51120], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 97, "seek": 58252, "start": 598.4399999999999, "end": 599.3199999999999, "text": " How would they know that?", "tokens": [51160, 1012, 576, 436, 458, 300, 30, 51204], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 98, "seek": 58252, "start": 601.0, "end": 605.48, "text": " It goes back to what you've written about as well of saying that the problem with AIs,", "tokens": [51288, 467, 1709, 646, 281, 437, 291, 600, 3720, 466, 382, 731, 295, 1566, 300, 264, 1154, 365, 316, 6802, 11, 51512], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 99, "seek": 58252, "start": 605.48, "end": 606.76, "text": " that lacks common sense.", "tokens": [51512, 300, 31132, 2689, 2020, 13, 51576], "temperature": 0.0, "avg_logprob": -0.17367884797869987, "compression_ratio": 1.670995670995671, "no_speech_prob": 0.001366752083413303}, {"id": 100, "seek": 60676, "start": 607.72, "end": 613.96, "text": " And common sense is if you drop the ice cream cone, even a four-year-old knows it's no longer", "tokens": [50412, 400, 2689, 2020, 307, 498, 291, 3270, 264, 4435, 4689, 19749, 11, 754, 257, 1451, 12, 5294, 12, 2641, 3255, 309, 311, 572, 2854, 50724], "temperature": 0.0, "avg_logprob": -0.1000125859234784, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.0059096016921103}, {"id": 101, "seek": 60676, "start": 613.96, "end": 622.6, "text": " something you want to eat or an AI system would not have that particular response because it's", "tokens": [50724, 746, 291, 528, 281, 1862, 420, 364, 7318, 1185, 576, 406, 362, 300, 1729, 4134, 570, 309, 311, 51156], "temperature": 0.0, "avg_logprob": -0.1000125859234784, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.0059096016921103}, {"id": 102, "seek": 60676, "start": 622.6, "end": 629.08, "text": " not an embodied biological entity that learns certain things about food from a very early age.", "tokens": [51156, 406, 364, 42046, 13910, 13977, 300, 27152, 1629, 721, 466, 1755, 490, 257, 588, 2440, 3205, 13, 51480], "temperature": 0.0, "avg_logprob": -0.1000125859234784, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.0059096016921103}, {"id": 103, "seek": 60676, "start": 629.72, "end": 630.76, "text": " That's exactly right.", "tokens": [51512, 663, 311, 2293, 558, 13, 51564], "temperature": 0.0, "avg_logprob": -0.1000125859234784, "compression_ratio": 1.4805825242718447, "no_speech_prob": 0.0059096016921103}, {"id": 104, "seek": 63076, "start": 631.72, "end": 636.52, "text": " So that's the, you know, that's one of the big problems is how do you get a system like", "tokens": [50412, 407, 300, 311, 264, 11, 291, 458, 11, 300, 311, 472, 295, 264, 955, 2740, 307, 577, 360, 291, 483, 257, 1185, 411, 50652], "temperature": 0.0, "avg_logprob": -0.11912035434804064, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00337609788402915}, {"id": 105, "seek": 63076, "start": 637.56, "end": 644.12, "text": " GPT-3 or any other AI system to get that kind of knowledge about the world that we all have,", "tokens": [50704, 26039, 51, 12, 18, 420, 604, 661, 7318, 1185, 281, 483, 300, 733, 295, 3601, 466, 264, 1002, 300, 321, 439, 362, 11, 51032], "temperature": 0.0, "avg_logprob": -0.11912035434804064, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00337609788402915}, {"id": 106, "seek": 63076, "start": 644.12, "end": 650.2, "text": " you know, as children, we all learn so much by just living and existing in the world.", "tokens": [51032, 291, 458, 11, 382, 2227, 11, 321, 439, 1466, 370, 709, 538, 445, 2647, 293, 6741, 294, 264, 1002, 13, 51336], "temperature": 0.0, "avg_logprob": -0.11912035434804064, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00337609788402915}, {"id": 107, "seek": 63076, "start": 650.92, "end": 655.96, "text": " You know, part of what you've written that strikes me as very interesting as well is", "tokens": [51372, 509, 458, 11, 644, 295, 437, 291, 600, 3720, 300, 16750, 385, 382, 588, 1880, 382, 731, 307, 51624], "temperature": 0.0, "avg_logprob": -0.11912035434804064, "compression_ratio": 1.610091743119266, "no_speech_prob": 0.00337609788402915}, {"id": 108, "seek": 65596, "start": 656.9200000000001, "end": 662.84, "text": " that a lot of the analogy making we have comes from an unconscious part of our brains.", "tokens": [50412, 300, 257, 688, 295, 264, 21663, 1455, 321, 362, 1487, 490, 364, 18900, 644, 295, 527, 15442, 13, 50708], "temperature": 0.0, "avg_logprob": -0.12244286320426247, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.007694515865296125}, {"id": 109, "seek": 65596, "start": 663.4000000000001, "end": 669.88, "text": " There was, when you start to think of analogies, they will come to you and if I ask, well,", "tokens": [50736, 821, 390, 11, 562, 291, 722, 281, 519, 295, 16660, 530, 11, 436, 486, 808, 281, 291, 293, 498, 286, 1029, 11, 731, 11, 51060], "temperature": 0.0, "avg_logprob": -0.12244286320426247, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.007694515865296125}, {"id": 110, "seek": 65596, "start": 669.88, "end": 670.84, "text": " where did that come from?", "tokens": [51060, 689, 630, 300, 808, 490, 30, 51108], "temperature": 0.0, "avg_logprob": -0.12244286320426247, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.007694515865296125}, {"id": 111, "seek": 65596, "start": 671.8000000000001, "end": 672.76, "text": " Probably don't really know.", "tokens": [51156, 9210, 500, 380, 534, 458, 13, 51204], "temperature": 0.0, "avg_logprob": -0.12244286320426247, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.007694515865296125}, {"id": 112, "seek": 65596, "start": 673.4000000000001, "end": 679.64, "text": " It's just, it's been triggered by some, some gesture, some thought, something that you're not", "tokens": [51236, 467, 311, 445, 11, 309, 311, 668, 21710, 538, 512, 11, 512, 22252, 11, 512, 1194, 11, 746, 300, 291, 434, 406, 51548], "temperature": 0.0, "avg_logprob": -0.12244286320426247, "compression_ratio": 1.5476190476190477, "no_speech_prob": 0.007694515865296125}, {"id": 113, "seek": 67964, "start": 679.72, "end": 681.08, "text": " really connected to.", "tokens": [50368, 534, 4582, 281, 13, 50436], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 114, "seek": 67964, "start": 681.08, "end": 685.88, "text": " You can make up a story of why you access that, but it's just that.", "tokens": [50436, 509, 393, 652, 493, 257, 1657, 295, 983, 291, 2105, 300, 11, 457, 309, 311, 445, 300, 13, 50676], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 115, "seek": 67964, "start": 685.88, "end": 687.24, "text": " It's just a story.", "tokens": [50676, 467, 311, 445, 257, 1657, 13, 50744], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 116, "seek": 67964, "start": 687.24, "end": 688.1999999999999, "text": " You don't really know.", "tokens": [50744, 509, 500, 380, 534, 458, 13, 50792], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 117, "seek": 67964, "start": 688.84, "end": 698.1999999999999, "text": " So AI does not have an unconscious matrix in which to draw upon to pull those analogies", "tokens": [50824, 407, 7318, 775, 406, 362, 364, 18900, 8141, 294, 597, 281, 2642, 3564, 281, 2235, 729, 16660, 530, 51292], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 118, "seek": 67964, "start": 698.1999999999999, "end": 703.3199999999999, "text": " and metaphors from a huge reservoir.", "tokens": [51292, 293, 30946, 830, 490, 257, 2603, 26316, 13, 51548], "temperature": 0.0, "avg_logprob": -0.10044215176556562, "compression_ratio": 1.4406779661016949, "no_speech_prob": 0.010815824382007122}, {"id": 119, "seek": 70332, "start": 703.96, "end": 710.9200000000001, "text": " I mean, presumably that material for analogy making is as close to infinite as a human can", "tokens": [50396, 286, 914, 11, 26742, 300, 2527, 337, 21663, 1455, 307, 382, 1998, 281, 13785, 382, 257, 1952, 393, 50744], "temperature": 0.0, "avg_logprob": -0.13933450525457208, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.04955535754561424}, {"id": 120, "seek": 70332, "start": 710.9200000000001, "end": 711.4000000000001, "text": " get to.", "tokens": [50744, 483, 281, 13, 50768], "temperature": 0.0, "avg_logprob": -0.13933450525457208, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.04955535754561424}, {"id": 121, "seek": 70332, "start": 712.2, "end": 720.6, "text": " And as a result, it's very hard, I would think, to program into a computer intelligence", "tokens": [50808, 400, 382, 257, 1874, 11, 309, 311, 588, 1152, 11, 286, 576, 519, 11, 281, 1461, 666, 257, 3820, 7599, 51228], "temperature": 0.0, "avg_logprob": -0.13933450525457208, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.04955535754561424}, {"id": 122, "seek": 70332, "start": 720.6, "end": 727.1600000000001, "text": " an analogy making function because it goes much deeper than just being able to calculate", "tokens": [51228, 364, 21663, 1455, 2445, 570, 309, 1709, 709, 7731, 813, 445, 885, 1075, 281, 8873, 51556], "temperature": 0.0, "avg_logprob": -0.13933450525457208, "compression_ratio": 1.5027322404371584, "no_speech_prob": 0.04955535754561424}, {"id": 123, "seek": 72716, "start": 727.24, "end": 734.4399999999999, "text": " precisely what the next best move is in chess or goal or Atari.", "tokens": [50368, 13402, 437, 264, 958, 1151, 1286, 307, 294, 24122, 420, 3387, 420, 41381, 13, 50728], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 124, "seek": 72716, "start": 735.8, "end": 736.04, "text": " Right.", "tokens": [50796, 1779, 13, 50808], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 125, "seek": 72716, "start": 738.12, "end": 746.04, "text": " Our analogy making comes in part from the fact that we have this huge store of memories.", "tokens": [50912, 2621, 21663, 1455, 1487, 294, 644, 490, 264, 1186, 300, 321, 362, 341, 2603, 3531, 295, 8495, 13, 51308], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 126, "seek": 72716, "start": 747.7199999999999, "end": 752.52, "text": " And, you know, if you might, you probably have the experience where somebody tells you a story", "tokens": [51392, 400, 11, 291, 458, 11, 498, 291, 1062, 11, 291, 1391, 362, 264, 1752, 689, 2618, 5112, 291, 257, 1657, 51632], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 127, "seek": 72716, "start": 752.52, "end": 755.16, "text": " and you say something like, oh, the same thing happened to me.", "tokens": [51632, 293, 291, 584, 746, 411, 11, 1954, 11, 264, 912, 551, 2011, 281, 385, 13, 51764], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 128, "seek": 72716, "start": 755.88, "end": 756.1999999999999, "text": " Yes.", "tokens": [51800, 1079, 13, 51816], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 129, "seek": 72716, "start": 756.1999999999999, "end": 756.76, "text": " Right.", "tokens": [51816, 1779, 13, 51844], "temperature": 0.0, "avg_logprob": -0.10932194784785924, "compression_ratio": 1.5446009389671362, "no_speech_prob": 0.0019262071000412107}, {"id": 130, "seek": 75676, "start": 756.84, "end": 761.3199999999999, "text": " And of course, the same thing literally didn't happen to you because you're not that other person.", "tokens": [50368, 400, 295, 1164, 11, 264, 912, 551, 3736, 994, 380, 1051, 281, 291, 570, 291, 434, 406, 300, 661, 954, 13, 50592], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 131, "seek": 75676, "start": 762.12, "end": 770.92, "text": " But you, something about their story triggers a memory that you somehow mapped on to the story", "tokens": [50632, 583, 291, 11, 746, 466, 641, 1657, 22827, 257, 4675, 300, 291, 6063, 33318, 322, 281, 264, 1657, 51072], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 132, "seek": 75676, "start": 770.92, "end": 775.0, "text": " that they just told you happens to us all the time every day.", "tokens": [51072, 300, 436, 445, 1907, 291, 2314, 281, 505, 439, 264, 565, 633, 786, 13, 51276], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 133, "seek": 75676, "start": 775.0, "end": 778.36, "text": " You know, someone says something about their life and you say, oh, yeah, me too.", "tokens": [51276, 509, 458, 11, 1580, 1619, 746, 466, 641, 993, 293, 291, 584, 11, 1954, 11, 1338, 11, 385, 886, 13, 51444], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 134, "seek": 75676, "start": 779.16, "end": 779.56, "text": " Right.", "tokens": [51484, 1779, 13, 51504], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 135, "seek": 75676, "start": 779.56, "end": 783.24, "text": " And that's like, you know, you're making an analogy between their life and your life.", "tokens": [51504, 400, 300, 311, 411, 11, 291, 458, 11, 291, 434, 1455, 364, 21663, 1296, 641, 993, 293, 428, 993, 13, 51688], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 136, "seek": 75676, "start": 783.24, "end": 785.08, "text": " And it's just constant.", "tokens": [51688, 400, 309, 311, 445, 5754, 13, 51780], "temperature": 0.0, "avg_logprob": -0.1408853938436916, "compression_ratio": 1.7976190476190477, "no_speech_prob": 0.00040435546543449163}, {"id": 137, "seek": 78508, "start": 785.08, "end": 793.48, "text": " But it has to do with an interaction between our perceptual abilities, our memories, our pattern", "tokens": [50364, 583, 309, 575, 281, 360, 365, 364, 9285, 1296, 527, 43276, 901, 11582, 11, 527, 8495, 11, 527, 5102, 50784], "temperature": 0.0, "avg_logprob": -0.09970436952052972, "compression_ratio": 1.5734597156398105, "no_speech_prob": 0.0005032462649978697}, {"id": 138, "seek": 78508, "start": 793.48, "end": 797.1600000000001, "text": " recognition facilities and so on.", "tokens": [50784, 11150, 9406, 293, 370, 322, 13, 50968], "temperature": 0.0, "avg_logprob": -0.09970436952052972, "compression_ratio": 1.5734597156398105, "no_speech_prob": 0.0005032462649978697}, {"id": 139, "seek": 78508, "start": 797.1600000000001, "end": 800.2, "text": " And this is something we haven't yet figured out how to give to machines.", "tokens": [50968, 400, 341, 307, 746, 321, 2378, 380, 1939, 8932, 484, 577, 281, 976, 281, 8379, 13, 51120], "temperature": 0.0, "avg_logprob": -0.09970436952052972, "compression_ratio": 1.5734597156398105, "no_speech_prob": 0.0005032462649978697}, {"id": 140, "seek": 78508, "start": 800.9200000000001, "end": 808.5200000000001, "text": " I'm wondering as well whether that exchange also falls under the heading of empathy,", "tokens": [51156, 286, 478, 6359, 382, 731, 1968, 300, 7742, 611, 8804, 833, 264, 9864, 295, 18701, 11, 51536], "temperature": 0.0, "avg_logprob": -0.09970436952052972, "compression_ratio": 1.5734597156398105, "no_speech_prob": 0.0005032462649978697}, {"id": 141, "seek": 78508, "start": 809.08, "end": 811.24, "text": " which is something a machine doesn't have.", "tokens": [51564, 597, 307, 746, 257, 3479, 1177, 380, 362, 13, 51672], "temperature": 0.0, "avg_logprob": -0.09970436952052972, "compression_ratio": 1.5734597156398105, "no_speech_prob": 0.0005032462649978697}, {"id": 142, "seek": 81124, "start": 811.24, "end": 816.84, "text": " Is that you will say, oh, that's similar because you have a theory of mind about that person.", "tokens": [50364, 1119, 300, 291, 486, 584, 11, 1954, 11, 300, 311, 2531, 570, 291, 362, 257, 5261, 295, 1575, 466, 300, 954, 13, 50644], "temperature": 0.0, "avg_logprob": -0.08284549302952264, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.001648054108954966}, {"id": 143, "seek": 81124, "start": 816.84, "end": 823.72, "text": " You can put yourself in that position and see that as happening to you and that you would have", "tokens": [50644, 509, 393, 829, 1803, 294, 300, 2535, 293, 536, 300, 382, 2737, 281, 291, 293, 300, 291, 576, 362, 50988], "temperature": 0.0, "avg_logprob": -0.08284549302952264, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.001648054108954966}, {"id": 144, "seek": 81124, "start": 823.72, "end": 829.4, "text": " had a similar response to a particular event or an object or a gesture.", "tokens": [50988, 632, 257, 2531, 4134, 281, 257, 1729, 2280, 420, 364, 2657, 420, 257, 22252, 13, 51272], "temperature": 0.0, "avg_logprob": -0.08284549302952264, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.001648054108954966}, {"id": 145, "seek": 81124, "start": 830.44, "end": 831.96, "text": " Yeah, that's absolutely right.", "tokens": [51324, 865, 11, 300, 311, 3122, 558, 13, 51400], "temperature": 0.0, "avg_logprob": -0.08284549302952264, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.001648054108954966}, {"id": 146, "seek": 81124, "start": 831.96, "end": 837.88, "text": " And, you know, one of the things about humans is they're incredibly socially oriented,", "tokens": [51400, 400, 11, 291, 458, 11, 472, 295, 264, 721, 466, 6255, 307, 436, 434, 6252, 21397, 21841, 11, 51696], "temperature": 0.0, "avg_logprob": -0.08284549302952264, "compression_ratio": 1.6293103448275863, "no_speech_prob": 0.001648054108954966}, {"id": 147, "seek": 83788, "start": 838.6, "end": 845.88, "text": " meaning that they're always trying to understand other people that they encounter from the earliest", "tokens": [50400, 3620, 300, 436, 434, 1009, 1382, 281, 1223, 661, 561, 300, 436, 8593, 490, 264, 20573, 50764], "temperature": 0.0, "avg_logprob": -0.10356530021218692, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0010984777472913265}, {"id": 148, "seek": 83788, "start": 845.88, "end": 850.36, "text": " infancy and they're able to put themselves in the position of other people.", "tokens": [50764, 1536, 6717, 293, 436, 434, 1075, 281, 829, 2969, 294, 264, 2535, 295, 661, 561, 13, 50988], "temperature": 0.0, "avg_logprob": -0.10356530021218692, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0010984777472913265}, {"id": 149, "seek": 83788, "start": 851.08, "end": 860.68, "text": " So that's something that, again, is very human and so perhaps essential for intelligence.", "tokens": [51024, 407, 300, 311, 746, 300, 11, 797, 11, 307, 588, 1952, 293, 370, 4317, 7115, 337, 7599, 13, 51504], "temperature": 0.0, "avg_logprob": -0.10356530021218692, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0010984777472913265}, {"id": 150, "seek": 83788, "start": 861.4, "end": 862.68, "text": " You know, we don't know.", "tokens": [51540, 509, 458, 11, 321, 500, 380, 458, 13, 51604], "temperature": 0.0, "avg_logprob": -0.10356530021218692, "compression_ratio": 1.5934065934065933, "no_speech_prob": 0.0010984777472913265}, {"id": 151, "seek": 86268, "start": 862.68, "end": 867.64, "text": " Usually AI people often think of intelligence as something kind of separable from", "tokens": [50364, 11419, 7318, 561, 2049, 519, 295, 7599, 382, 746, 733, 295, 3128, 712, 490, 50612], "temperature": 0.0, "avg_logprob": -0.10344884535845589, "compression_ratio": 1.6, "no_speech_prob": 0.0007914275047369301}, {"id": 152, "seek": 86268, "start": 868.52, "end": 873.0799999999999, "text": " things like empathy and emotions and it's pure rationality.", "tokens": [50656, 721, 411, 18701, 293, 8462, 293, 309, 311, 6075, 15090, 507, 13, 50884], "temperature": 0.0, "avg_logprob": -0.10344884535845589, "compression_ratio": 1.6, "no_speech_prob": 0.0007914275047369301}, {"id": 153, "seek": 86268, "start": 873.0799999999999, "end": 879.2399999999999, "text": " But I think a lot of people are now trying to make sense of how the centrality of these", "tokens": [50884, 583, 286, 519, 257, 688, 295, 561, 366, 586, 1382, 281, 652, 2020, 295, 577, 264, 32199, 1860, 295, 613, 51192], "temperature": 0.0, "avg_logprob": -0.10344884535845589, "compression_ratio": 1.6, "no_speech_prob": 0.0007914275047369301}, {"id": 154, "seek": 86268, "start": 880.04, "end": 884.3599999999999, "text": " or emotional aspects of our intelligence.", "tokens": [51232, 420, 6863, 7270, 295, 527, 7599, 13, 51448], "temperature": 0.0, "avg_logprob": -0.10344884535845589, "compression_ratio": 1.6, "no_speech_prob": 0.0007914275047369301}, {"id": 155, "seek": 86268, "start": 885.0, "end": 891.3199999999999, "text": " Right. Well, what I'd like now to do with this background in terms of metaphors,", "tokens": [51480, 1779, 13, 1042, 11, 437, 286, 1116, 411, 586, 281, 360, 365, 341, 3678, 294, 2115, 295, 30946, 830, 11, 51796], "temperature": 0.0, "avg_logprob": -0.10344884535845589, "compression_ratio": 1.6, "no_speech_prob": 0.0007914275047369301}, {"id": 156, "seek": 89132, "start": 891.32, "end": 899.6400000000001, "text": " analogies to move on to your reading list, which I hope that we'll be able to get into how", "tokens": [50364, 16660, 530, 281, 1286, 322, 281, 428, 3760, 1329, 11, 597, 286, 1454, 300, 321, 603, 312, 1075, 281, 483, 666, 577, 50780], "temperature": 0.0, "avg_logprob": -0.1589507495655733, "compression_ratio": 1.4692737430167597, "no_speech_prob": 0.0018963671755045652}, {"id": 157, "seek": 89132, "start": 900.44, "end": 908.44, "text": " this may have been a training set and education for you into the world of metaphor,", "tokens": [50820, 341, 815, 362, 668, 257, 3097, 992, 293, 3309, 337, 291, 666, 264, 1002, 295, 19157, 11, 51220], "temperature": 0.0, "avg_logprob": -0.1589507495655733, "compression_ratio": 1.4692737430167597, "no_speech_prob": 0.0018963671755045652}, {"id": 158, "seek": 89132, "start": 908.44, "end": 910.84, "text": " simile and analogy making.", "tokens": [51220, 1034, 794, 293, 21663, 1455, 13, 51340], "temperature": 0.0, "avg_logprob": -0.1589507495655733, "compression_ratio": 1.4692737430167597, "no_speech_prob": 0.0018963671755045652}, {"id": 159, "seek": 89132, "start": 911.48, "end": 916.44, "text": " So let's start with really your background, your first books.", "tokens": [51372, 407, 718, 311, 722, 365, 534, 428, 3678, 11, 428, 700, 3642, 13, 51620], "temperature": 0.0, "avg_logprob": -0.1589507495655733, "compression_ratio": 1.4692737430167597, "no_speech_prob": 0.0018963671755045652}, {"id": 160, "seek": 91644, "start": 917.08, "end": 919.1600000000001, "text": " You're at home.", "tokens": [50396, 509, 434, 412, 1280, 13, 50500], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 161, "seek": 91644, "start": 920.0400000000001, "end": 924.9200000000001, "text": " Was the first books from your mother or your father or a sibling?", "tokens": [50544, 3027, 264, 700, 3642, 490, 428, 2895, 420, 428, 3086, 420, 257, 39409, 30, 50788], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 162, "seek": 91644, "start": 925.5600000000001, "end": 930.9200000000001, "text": " I mean, how did you come to first have that book, that first book in your hand?", "tokens": [50820, 286, 914, 11, 577, 630, 291, 808, 281, 700, 362, 300, 1446, 11, 300, 700, 1446, 294, 428, 1011, 30, 51088], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 163, "seek": 91644, "start": 932.12, "end": 933.1600000000001, "text": " The first book?", "tokens": [51148, 440, 700, 1446, 30, 51200], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 164, "seek": 91644, "start": 933.8000000000001, "end": 941.6400000000001, "text": " Yeah. In other words, we look at the first book on the list, which is The Phantom Tooth Toe Book,", "tokens": [51232, 865, 13, 682, 661, 2283, 11, 321, 574, 412, 264, 700, 1446, 322, 264, 1329, 11, 597, 307, 440, 34689, 1407, 900, 1407, 68, 9476, 11, 51624], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 165, "seek": 91644, "start": 941.6400000000001, "end": 943.8000000000001, "text": " which is an absolutely wonderful book.", "tokens": [51624, 597, 307, 364, 3122, 3715, 1446, 13, 51732], "temperature": 0.0, "avg_logprob": -0.19134720696343316, "compression_ratio": 1.6613756613756614, "no_speech_prob": 0.008186192251741886}, {"id": 166, "seek": 94380, "start": 943.8, "end": 948.92, "text": " I'm so glad you chose that. I can't wait to get into it, but let's just start for a moment.", "tokens": [50364, 286, 478, 370, 5404, 291, 5111, 300, 13, 286, 393, 380, 1699, 281, 483, 666, 309, 11, 457, 718, 311, 445, 722, 337, 257, 1623, 13, 50620], "temperature": 0.0, "avg_logprob": -0.1306577481721577, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.0005702594062313437}, {"id": 167, "seek": 94380, "start": 948.92, "end": 954.4399999999999, "text": " And how did you come to have that book in your possession and how old were you?", "tokens": [50620, 400, 577, 630, 291, 808, 281, 362, 300, 1446, 294, 428, 20935, 293, 577, 1331, 645, 291, 30, 50896], "temperature": 0.0, "avg_logprob": -0.1306577481721577, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.0005702594062313437}, {"id": 168, "seek": 94380, "start": 956.4399999999999, "end": 962.8399999999999, "text": " Wow. I was, I'm guessing I was about eight or nine, something like that.", "tokens": [50996, 3153, 13, 286, 390, 11, 286, 478, 17939, 286, 390, 466, 3180, 420, 4949, 11, 746, 411, 300, 13, 51316], "temperature": 0.0, "avg_logprob": -0.1306577481721577, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.0005702594062313437}, {"id": 169, "seek": 94380, "start": 963.9599999999999, "end": 971.56, "text": " And I really don't remember at all how I got that book, who gave it to me or anything.", "tokens": [51372, 400, 286, 534, 500, 380, 1604, 412, 439, 577, 286, 658, 300, 1446, 11, 567, 2729, 309, 281, 385, 420, 1340, 13, 51752], "temperature": 0.0, "avg_logprob": -0.1306577481721577, "compression_ratio": 1.5761904761904761, "no_speech_prob": 0.0005702594062313437}, {"id": 170, "seek": 97156, "start": 971.64, "end": 979.4, "text": " Somehow it appeared, sort of like The Phantom Toe Booth in the book just suddenly appeared.", "tokens": [50368, 28357, 309, 8516, 11, 1333, 295, 411, 440, 34689, 1407, 68, 3286, 900, 294, 264, 1446, 445, 5800, 8516, 13, 50756], "temperature": 0.0, "avg_logprob": -0.1873574000532909, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.00017399028001818806}, {"id": 171, "seek": 97156, "start": 979.4, "end": 980.5999999999999, "text": " No one knew where it came from.", "tokens": [50756, 883, 472, 2586, 689, 309, 1361, 490, 13, 50816], "temperature": 0.0, "avg_logprob": -0.1873574000532909, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.00017399028001818806}, {"id": 172, "seek": 97156, "start": 983.4, "end": 989.4, "text": " Did you grow up in a reading environment where your parents were reading or siblings were reading?", "tokens": [50956, 2589, 291, 1852, 493, 294, 257, 3760, 2823, 689, 428, 3152, 645, 3760, 420, 20571, 645, 3760, 30, 51256], "temperature": 0.0, "avg_logprob": -0.1873574000532909, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.00017399028001818806}, {"id": 173, "seek": 97156, "start": 989.4, "end": 993.88, "text": " And then that kind of storytelling from reading was kind of a natural", "tokens": [51256, 400, 550, 300, 733, 295, 21479, 490, 3760, 390, 733, 295, 257, 3303, 51480], "temperature": 0.0, "avg_logprob": -0.1873574000532909, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.00017399028001818806}, {"id": 174, "seek": 97156, "start": 995.2399999999999, "end": 999.0, "text": " bridge from one to the other. You're reading books, you're telling stories, you're reading books.", "tokens": [51548, 7283, 490, 472, 281, 264, 661, 13, 509, 434, 3760, 3642, 11, 291, 434, 3585, 3676, 11, 291, 434, 3760, 3642, 13, 51736], "temperature": 0.0, "avg_logprob": -0.1873574000532909, "compression_ratio": 1.7180616740088106, "no_speech_prob": 0.00017399028001818806}, {"id": 175, "seek": 99900, "start": 999.88, "end": 1012.36, "text": " Yeah. My parents both were avid readers and read to us from earliest childhood.", "tokens": [50408, 865, 13, 1222, 3152, 1293, 645, 1305, 327, 17147, 293, 1401, 281, 505, 490, 20573, 9278, 13, 51032], "temperature": 0.0, "avg_logprob": -0.1438365286969124, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.0004878313047811389}, {"id": 176, "seek": 99900, "start": 1018.28, "end": 1023.64, "text": " I just, I can't remember any time when I couldn't read or didn't spend most of my time reading.", "tokens": [51328, 286, 445, 11, 286, 393, 380, 1604, 604, 565, 562, 286, 2809, 380, 1401, 420, 994, 380, 3496, 881, 295, 452, 565, 3760, 13, 51596], "temperature": 0.0, "avg_logprob": -0.1438365286969124, "compression_ratio": 1.3257575757575757, "no_speech_prob": 0.0004878313047811389}, {"id": 177, "seek": 102364, "start": 1023.64, "end": 1029.08, "text": " So I loved reading as a child. I did too. That's why I'm doing this show.", "tokens": [50364, 407, 286, 4333, 3760, 382, 257, 1440, 13, 286, 630, 886, 13, 663, 311, 983, 286, 478, 884, 341, 855, 13, 50636], "temperature": 0.0, "avg_logprob": -0.13178390680357469, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.002472333377227187}, {"id": 178, "seek": 102364, "start": 1029.6399999999999, "end": 1037.4, "text": " And I think that the people who have that experience or fortunate for a lot of reasons,", "tokens": [50664, 400, 286, 519, 300, 264, 561, 567, 362, 300, 1752, 420, 14096, 337, 257, 688, 295, 4112, 11, 51052], "temperature": 0.0, "avg_logprob": -0.13178390680357469, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.002472333377227187}, {"id": 179, "seek": 102364, "start": 1037.4, "end": 1047.08, "text": " because it does ground, I think, a person in the ability to be curious about stories,", "tokens": [51052, 570, 309, 775, 2727, 11, 286, 519, 11, 257, 954, 294, 264, 3485, 281, 312, 6369, 466, 3676, 11, 51536], "temperature": 0.0, "avg_logprob": -0.13178390680357469, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.002472333377227187}, {"id": 180, "seek": 102364, "start": 1047.08, "end": 1052.68, "text": " about other people's stories, and to learn from them and to apply that learning to new", "tokens": [51536, 466, 661, 561, 311, 3676, 11, 293, 281, 1466, 490, 552, 293, 281, 3079, 300, 2539, 281, 777, 51816], "temperature": 0.0, "avg_logprob": -0.13178390680357469, "compression_ratio": 1.5829383886255923, "no_speech_prob": 0.002472333377227187}, {"id": 181, "seek": 105268, "start": 1052.76, "end": 1060.52, "text": " and novel situations. Which is, you know, basically that's so much of what you're doing as well is", "tokens": [50368, 293, 7613, 6851, 13, 3013, 307, 11, 291, 458, 11, 1936, 300, 311, 370, 709, 295, 437, 291, 434, 884, 382, 731, 307, 50756], "temperature": 0.0, "avg_logprob": -0.15231076153841885, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0019868386443704367}, {"id": 182, "seek": 105268, "start": 1062.2, "end": 1068.92, "text": " how do you deal with surprise? And how you deal with surprise is something that you can learn", "tokens": [50840, 577, 360, 291, 2028, 365, 6365, 30, 400, 577, 291, 2028, 365, 6365, 307, 746, 300, 291, 393, 1466, 51176], "temperature": 0.0, "avg_logprob": -0.15231076153841885, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0019868386443704367}, {"id": 183, "seek": 105268, "start": 1069.5600000000002, "end": 1076.52, "text": " through the experiences of characters in books. You can see that experience is something,", "tokens": [51208, 807, 264, 5235, 295, 4342, 294, 3642, 13, 509, 393, 536, 300, 1752, 307, 746, 11, 51556], "temperature": 0.0, "avg_logprob": -0.15231076153841885, "compression_ratio": 1.6206896551724137, "no_speech_prob": 0.0019868386443704367}, {"id": 184, "seek": 107652, "start": 1076.52, "end": 1083.08, "text": " oh, that person was surprised. They reacted in this way. And that has the profound implication", "tokens": [50364, 1954, 11, 300, 954, 390, 6100, 13, 814, 34037, 294, 341, 636, 13, 400, 300, 575, 264, 14382, 37814, 50692], "temperature": 0.0, "avg_logprob": -0.1331094956733811, "compression_ratio": 1.4375, "no_speech_prob": 0.004608564544469118}, {"id": 185, "seek": 107652, "start": 1083.08, "end": 1094.44, "text": " for your own feeling about security in the world, how I would react. So the phantom toll booth by", "tokens": [50692, 337, 428, 1065, 2633, 466, 3825, 294, 264, 1002, 11, 577, 286, 576, 4515, 13, 407, 264, 903, 25796, 16629, 20912, 538, 51260], "temperature": 0.0, "avg_logprob": -0.1331094956733811, "compression_ratio": 1.4375, "no_speech_prob": 0.004608564544469118}, {"id": 186, "seek": 107652, "start": 1095.24, "end": 1104.12, "text": " Norton Justin, you know, he, he just recently died in March of this year at age 92.", "tokens": [51300, 426, 36184, 11320, 11, 291, 458, 11, 415, 11, 415, 445, 3938, 4539, 294, 6129, 295, 341, 1064, 412, 3205, 28225, 13, 51744], "temperature": 0.0, "avg_logprob": -0.1331094956733811, "compression_ratio": 1.4375, "no_speech_prob": 0.004608564544469118}, {"id": 187, "seek": 110412, "start": 1104.36, "end": 1113.8, "text": " But he left behind this absolutely wonderful book. You know, there's the little bored boy named Milo,", "tokens": [50376, 583, 415, 1411, 2261, 341, 3122, 3715, 1446, 13, 509, 458, 11, 456, 311, 264, 707, 13521, 3237, 4926, 7036, 78, 11, 50848], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 188, "seek": 110412, "start": 1114.9199999999998, "end": 1122.04, "text": " who's, you know, has this kit, which he has to assemble, which is toll booth. Comes with two toll booths.", "tokens": [50904, 567, 311, 11, 291, 458, 11, 575, 341, 8260, 11, 597, 415, 575, 281, 22364, 11, 597, 307, 16629, 20912, 13, 47290, 365, 732, 16629, 20912, 82, 13, 51260], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 189, "seek": 110412, "start": 1122.04, "end": 1124.52, "text": " It just appears also. That was very, it's", "tokens": [51260, 467, 445, 7038, 611, 13, 663, 390, 588, 11, 309, 311, 51384], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 190, "seek": 110412, "start": 1125.32, "end": 1129.4799999999998, "text": " Magically, it's striking to me that this thing just appeared in his bedroom.", "tokens": [51424, 6395, 984, 11, 309, 311, 18559, 281, 385, 300, 341, 551, 445, 8516, 294, 702, 11211, 13, 51632], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 191, "seek": 110412, "start": 1129.4799999999998, "end": 1130.04, "text": " Right.", "tokens": [51632, 1779, 13, 51660], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 192, "seek": 110412, "start": 1130.04, "end": 1131.56, "text": " Where did it come from?", "tokens": [51660, 2305, 630, 309, 808, 490, 30, 51736], "temperature": 0.0, "avg_logprob": -0.421390495300293, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.0008693099371157587}, {"id": 193, "seek": 113156, "start": 1132.52, "end": 1137.72, "text": " Exactly. So that's the first question you're asking at eight or nine, right? It is,", "tokens": [50412, 7587, 13, 407, 300, 311, 264, 700, 1168, 291, 434, 3365, 412, 3180, 420, 4949, 11, 558, 30, 467, 307, 11, 50672], "temperature": 0.0, "avg_logprob": -0.15333972178714375, "compression_ratio": 1.4431818181818181, "no_speech_prob": 0.00029593450017273426}, {"id": 194, "seek": 113156, "start": 1138.44, "end": 1147.1599999999999, "text": " how did Milo end up with this kit in his room? So what does he do with that?", "tokens": [50708, 577, 630, 7036, 78, 917, 493, 365, 341, 8260, 294, 702, 1808, 30, 407, 437, 775, 415, 360, 365, 300, 30, 51144], "temperature": 0.0, "avg_logprob": -0.15333972178714375, "compression_ratio": 1.4431818181818181, "no_speech_prob": 0.00029593450017273426}, {"id": 195, "seek": 113156, "start": 1148.36, "end": 1154.6, "text": " He puts it together. He assembles it, right? So there's an immediately kind of an engineering", "tokens": [51204, 634, 8137, 309, 1214, 13, 634, 8438, 904, 309, 11, 558, 30, 407, 456, 311, 364, 4258, 733, 295, 364, 7043, 51516], "temperature": 0.0, "avg_logprob": -0.15333972178714375, "compression_ratio": 1.4431818181818181, "no_speech_prob": 0.00029593450017273426}, {"id": 196, "seek": 115460, "start": 1154.6, "end": 1161.6399999999999, "text": " puzzle making aspect to the book, which I almost, all the scientists I've talked to,", "tokens": [50364, 12805, 1455, 4171, 281, 264, 1446, 11, 597, 286, 1920, 11, 439, 264, 7708, 286, 600, 2825, 281, 11, 50716], "temperature": 0.0, "avg_logprob": -0.08237810392637511, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.015660954639315605}, {"id": 197, "seek": 115460, "start": 1161.6399999999999, "end": 1170.04, "text": " there's some book like that. Here is a puzzle. If I put it together, what representation do I see?", "tokens": [50716, 456, 311, 512, 1446, 411, 300, 13, 1692, 307, 257, 12805, 13, 759, 286, 829, 309, 1214, 11, 437, 10290, 360, 286, 536, 30, 51136], "temperature": 0.0, "avg_logprob": -0.08237810392637511, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.015660954639315605}, {"id": 198, "seek": 115460, "start": 1171.56, "end": 1179.6399999999999, "text": " And so for Milo, he also has a little electric car. So once he's assembled the toll booth,", "tokens": [51212, 400, 370, 337, 7036, 78, 11, 415, 611, 575, 257, 707, 5210, 1032, 13, 407, 1564, 415, 311, 24204, 264, 16629, 20912, 11, 51616], "temperature": 0.0, "avg_logprob": -0.08237810392637511, "compression_ratio": 1.4497354497354498, "no_speech_prob": 0.015660954639315605}, {"id": 199, "seek": 117964, "start": 1180.2, "end": 1189.0, "text": " he's got the map, the rules, two tokens, drops one in, takes off and starts driving. And", "tokens": [50392, 415, 311, 658, 264, 4471, 11, 264, 4474, 11, 732, 22667, 11, 11438, 472, 294, 11, 2516, 766, 293, 3719, 4840, 13, 400, 50832], "temperature": 0.0, "avg_logprob": -0.16962763922555105, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.002550790086388588}, {"id": 200, "seek": 117964, "start": 1191.0, "end": 1197.72, "text": " I could see where your love and passion for metaphor and analogy would have started at eight", "tokens": [50932, 286, 727, 536, 689, 428, 959, 293, 5418, 337, 19157, 293, 21663, 576, 362, 1409, 412, 3180, 51268], "temperature": 0.0, "avg_logprob": -0.16962763922555105, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.002550790086388588}, {"id": 201, "seek": 117964, "start": 1197.72, "end": 1205.5600000000002, "text": " or nine with this book. I mean, a dog's body shape like a cock, a watchdog.", "tokens": [51268, 420, 4949, 365, 341, 1446, 13, 286, 914, 11, 257, 3000, 311, 1772, 3909, 411, 257, 11241, 11, 257, 1159, 14833, 13, 51660], "temperature": 0.0, "avg_logprob": -0.16962763922555105, "compression_ratio": 1.4770114942528736, "no_speech_prob": 0.002550790086388588}, {"id": 202, "seek": 120556, "start": 1206.28, "end": 1215.1599999999999, "text": " Right. That was another thing. It was all the word play and Hans was just so enchanting.", "tokens": [50400, 1779, 13, 663, 390, 1071, 551, 13, 467, 390, 439, 264, 1349, 862, 293, 17926, 390, 445, 370, 35213, 18571, 13, 50844], "temperature": 0.0, "avg_logprob": -0.27986189659605637, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.0007793267723172903}, {"id": 203, "seek": 120556, "start": 1217.1599999999999, "end": 1223.8799999999999, "text": " So yeah, I mean, there you go. You're certainly starting to see that word play,", "tokens": [50944, 407, 1338, 11, 286, 914, 11, 456, 291, 352, 13, 509, 434, 3297, 2891, 281, 536, 300, 1349, 862, 11, 51280], "temperature": 0.0, "avg_logprob": -0.27986189659605637, "compression_ratio": 1.3228346456692914, "no_speech_prob": 0.0007793267723172903}, {"id": 204, "seek": 122388, "start": 1224.8400000000001, "end": 1234.68, "text": " a clock body for a dog, a watchdog, and then a bug that just brags and brags about its own", "tokens": [50412, 257, 7830, 1772, 337, 257, 3000, 11, 257, 1159, 14833, 11, 293, 550, 257, 7426, 300, 445, 1548, 21559, 293, 1548, 21559, 466, 1080, 1065, 50904], "temperature": 0.0, "avg_logprob": -0.09417817327711317, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.02297399938106537}, {"id": 205, "seek": 122388, "start": 1235.48, "end": 1244.8400000000001, "text": " abilities and claims, which aren't true, which is a humbug. And so Milo basically teams up with", "tokens": [50944, 11582, 293, 9441, 11, 597, 3212, 380, 2074, 11, 597, 307, 257, 1484, 44455, 13, 400, 370, 7036, 78, 1936, 5491, 493, 365, 51412], "temperature": 0.0, "avg_logprob": -0.09417817327711317, "compression_ratio": 1.3880597014925373, "no_speech_prob": 0.02297399938106537}, {"id": 206, "seek": 124484, "start": 1244.84, "end": 1255.9599999999998, "text": " these two, doesn't he? The humbug and the watchdog to go on an adventure and they end up in the empire", "tokens": [50364, 613, 732, 11, 1177, 380, 415, 30, 440, 1484, 44455, 293, 264, 1159, 14833, 281, 352, 322, 364, 9868, 293, 436, 917, 493, 294, 264, 17506, 50920], "temperature": 0.0, "avg_logprob": -0.16227094943706805, "compression_ratio": 1.326086956521739, "no_speech_prob": 0.02128170244395733}, {"id": 207, "seek": 124484, "start": 1255.9599999999998, "end": 1263.8, "text": " of wisdom. But the problem is there's no rhyme or reason. Right. The princesses.", "tokens": [50920, 295, 10712, 13, 583, 264, 1154, 307, 456, 311, 572, 34753, 420, 1778, 13, 1779, 13, 440, 14742, 279, 13, 51312], "temperature": 0.0, "avg_logprob": -0.16227094943706805, "compression_ratio": 1.326086956521739, "no_speech_prob": 0.02128170244395733}, {"id": 208, "seek": 126380, "start": 1264.76, "end": 1275.08, "text": " Exactly. The two sisters. Yes. So they set out for a quest to rescue them, right,", "tokens": [50412, 7587, 13, 440, 732, 11589, 13, 1079, 13, 407, 436, 992, 484, 337, 257, 866, 281, 13283, 552, 11, 558, 11, 50928], "temperature": 0.0, "avg_logprob": -0.18677432038063227, "compression_ratio": 1.3140495867768596, "no_speech_prob": 0.004069608636200428}, {"id": 209, "seek": 126380, "start": 1275.8799999999999, "end": 1285.24, "text": " and to bring the two sisters rhyme and reason back into the empire of wisdom.", "tokens": [50968, 293, 281, 1565, 264, 732, 11589, 34753, 293, 1778, 646, 666, 264, 17506, 295, 10712, 13, 51436], "temperature": 0.0, "avg_logprob": -0.18677432038063227, "compression_ratio": 1.3140495867768596, "no_speech_prob": 0.004069608636200428}, {"id": 210, "seek": 128524, "start": 1285.4, "end": 1292.76, "text": " And again, part of the word play here, it's quite wonderful, is on their journey,", "tokens": [50372, 400, 797, 11, 644, 295, 264, 1349, 862, 510, 11, 309, 311, 1596, 3715, 11, 307, 322, 641, 4671, 11, 50740], "temperature": 0.0, "avg_logprob": -0.17872101685096478, "compression_ratio": 1.4968553459119496, "no_speech_prob": 0.002631252631545067}, {"id": 211, "seek": 128524, "start": 1293.32, "end": 1300.1200000000001, "text": " you know, running into the mountain of ignorance where there's the ever present word snatcher,", "tokens": [50768, 291, 458, 11, 2614, 666, 264, 6937, 295, 25390, 689, 456, 311, 264, 1562, 1974, 1349, 46328, 260, 11, 51108], "temperature": 0.0, "avg_logprob": -0.17872101685096478, "compression_ratio": 1.4968553459119496, "no_speech_prob": 0.002631252631545067}, {"id": 212, "seek": 128524, "start": 1301.56, "end": 1305.16, "text": " which is quite the person who's constantly interrupting them.", "tokens": [51180, 597, 307, 1596, 264, 954, 567, 311, 6460, 49455, 552, 13, 51360], "temperature": 0.0, "avg_logprob": -0.17872101685096478, "compression_ratio": 1.4968553459119496, "no_speech_prob": 0.002631252631545067}, {"id": 213, "seek": 130516, "start": 1305.48, "end": 1316.2, "text": " The terrible triumphant, waste time doing unimportant and trivial tasks. The sense", "tokens": [50380, 440, 6237, 1376, 449, 15071, 11, 5964, 565, 884, 517, 41654, 293, 26703, 9608, 13, 440, 2020, 50916], "temperature": 0.0, "avg_logprob": -0.268636597527398, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.00658853305503726}, {"id": 214, "seek": 130516, "start": 1316.2, "end": 1322.44, "text": " taker, the person who wastes time filling out countless wasteful forms to no particular end.", "tokens": [50916, 991, 260, 11, 264, 954, 567, 390, 7269, 565, 10623, 484, 19223, 5964, 906, 6422, 281, 572, 1729, 917, 13, 51228], "temperature": 0.0, "avg_logprob": -0.268636597527398, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.00658853305503726}, {"id": 215, "seek": 130516, "start": 1324.0400000000002, "end": 1332.92, "text": " So ultimately, they, they succeed, right? Milo. Oh, yes. The humbug, the watchdog. Yes.", "tokens": [51308, 407, 6284, 11, 436, 11, 436, 7754, 11, 558, 30, 7036, 78, 13, 876, 11, 2086, 13, 440, 1484, 44455, 11, 264, 1159, 14833, 13, 1079, 13, 51752], "temperature": 0.0, "avg_logprob": -0.268636597527398, "compression_ratio": 1.4371584699453552, "no_speech_prob": 0.00658853305503726}, {"id": 216, "seek": 133292, "start": 1333.3200000000002, "end": 1346.44, "text": " By rescuing the two sisters rhyme and reason. Now, what out of that, the phantom of toll booth,", "tokens": [50384, 3146, 9610, 9635, 264, 732, 11589, 34753, 293, 1778, 13, 823, 11, 437, 484, 295, 300, 11, 264, 903, 25796, 295, 16629, 20912, 11, 51040], "temperature": 0.0, "avg_logprob": -0.19959359486897787, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.0007095864275470376}, {"id": 217, "seek": 133292, "start": 1347.0800000000002, "end": 1354.76, "text": " if you can kind of recreate what it was that in your mind as you read it as a child,", "tokens": [51072, 498, 291, 393, 733, 295, 25833, 437, 309, 390, 300, 294, 428, 1575, 382, 291, 1401, 309, 382, 257, 1440, 11, 51456], "temperature": 0.0, "avg_logprob": -0.19959359486897787, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.0007095864275470376}, {"id": 218, "seek": 133292, "start": 1355.3200000000002, "end": 1360.44, "text": " how you process that. I mean, you're processing some things which were a kid could be a little bit", "tokens": [51484, 577, 291, 1399, 300, 13, 286, 914, 11, 291, 434, 9007, 512, 721, 597, 645, 257, 1636, 727, 312, 257, 707, 857, 51740], "temperature": 0.0, "avg_logprob": -0.19959359486897787, "compression_ratio": 1.5245901639344261, "no_speech_prob": 0.0007095864275470376}, {"id": 219, "seek": 136044, "start": 1360.44, "end": 1368.68, "text": " maybe frightening, like demons. And some of the demons are described in quite vivid detail,", "tokens": [50364, 1310, 31043, 11, 411, 19733, 13, 400, 512, 295, 264, 19733, 366, 7619, 294, 1596, 23603, 2607, 11, 50776], "temperature": 0.0, "avg_logprob": -0.1581171897992696, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.002631151583045721}, {"id": 220, "seek": 136044, "start": 1368.68, "end": 1375.0800000000002, "text": " long nose, green eyed, curly haired, wide mouth, thick neck, broad shoulder, round body,", "tokens": [50776, 938, 6690, 11, 3092, 9817, 292, 11, 32066, 324, 1824, 11, 4874, 4525, 11, 5060, 6189, 11, 4152, 7948, 11, 3098, 1772, 11, 51096], "temperature": 0.0, "avg_logprob": -0.1581171897992696, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.002631151583045721}, {"id": 221, "seek": 136044, "start": 1375.0800000000002, "end": 1381.96, "text": " short arm, bow legged, big footed monster. That's the demon of insecurity or insincerity.", "tokens": [51096, 2099, 3726, 11, 4503, 476, 12244, 11, 955, 2671, 292, 10090, 13, 663, 311, 264, 14283, 295, 35058, 420, 1028, 259, 1776, 507, 13, 51440], "temperature": 0.0, "avg_logprob": -0.1581171897992696, "compression_ratio": 1.4754098360655739, "no_speech_prob": 0.002631151583045721}, {"id": 222, "seek": 138196, "start": 1382.6000000000001, "end": 1390.76, "text": " Mm-hmm. Yeah. That, I mean, part of the book, I remember, were some wonderful illustrations", "tokens": [50396, 8266, 12, 10250, 13, 865, 13, 663, 11, 286, 914, 11, 644, 295, 264, 1446, 11, 286, 1604, 11, 645, 512, 3715, 34540, 50804], "temperature": 0.0, "avg_logprob": -0.16236335848584588, "compression_ratio": 1.405, "no_speech_prob": 0.00781378336250782}, {"id": 223, "seek": 138196, "start": 1391.48, "end": 1397.48, "text": " by Jules Pfeiffer. Right. I mean, I didn't know who he was when I was, you know, that child, but I", "tokens": [50840, 538, 508, 3473, 430, 2106, 12612, 13, 1779, 13, 286, 914, 11, 286, 994, 380, 458, 567, 415, 390, 562, 286, 390, 11, 291, 458, 11, 300, 1440, 11, 457, 286, 51140], "temperature": 0.0, "avg_logprob": -0.16236335848584588, "compression_ratio": 1.405, "no_speech_prob": 0.00781378336250782}, {"id": 224, "seek": 138196, "start": 1397.48, "end": 1406.04, "text": " certainly knew him later on. And they were fantastically evocative and terrifying, some of", "tokens": [51140, 3297, 2586, 796, 1780, 322, 13, 400, 436, 645, 4115, 22808, 1073, 905, 1166, 293, 18106, 11, 512, 295, 51568], "temperature": 0.0, "avg_logprob": -0.16236335848584588, "compression_ratio": 1.405, "no_speech_prob": 0.00781378336250782}, {"id": 225, "seek": 140604, "start": 1406.04, "end": 1414.28, "text": " them. I still remember that there was a man who had no face. I don't know if you saw that one,", "tokens": [50364, 552, 13, 286, 920, 1604, 300, 456, 390, 257, 587, 567, 632, 572, 1851, 13, 286, 500, 380, 458, 498, 291, 1866, 300, 472, 11, 50776], "temperature": 0.0, "avg_logprob": -0.09898472459692705, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.0013248855248093605}, {"id": 226, "seek": 140604, "start": 1414.28, "end": 1422.76, "text": " but that was a really terrifying thing. Right. Right. So it introduced a wordplay", "tokens": [50776, 457, 300, 390, 257, 534, 18106, 551, 13, 1779, 13, 1779, 13, 407, 309, 7268, 257, 1349, 2858, 51200], "temperature": 0.0, "avg_logprob": -0.09898472459692705, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.0013248855248093605}, {"id": 227, "seek": 140604, "start": 1422.76, "end": 1431.1599999999999, "text": " world and a visual world in between the covers of the same book. Yes. Yes. And there were, you know,", "tokens": [51200, 1002, 293, 257, 5056, 1002, 294, 1296, 264, 10538, 295, 264, 912, 1446, 13, 1079, 13, 1079, 13, 400, 456, 645, 11, 291, 458, 11, 51620], "temperature": 0.0, "avg_logprob": -0.09898472459692705, "compression_ratio": 1.538888888888889, "no_speech_prob": 0.0013248855248093605}, {"id": 228, "seek": 143116, "start": 1431.8000000000002, "end": 1438.92, "text": " I, there were two kind of two different cities. One was concerned with words and the other was", "tokens": [50396, 286, 11, 456, 645, 732, 733, 295, 732, 819, 6486, 13, 1485, 390, 5922, 365, 2283, 293, 264, 661, 390, 50752], "temperature": 0.0, "avg_logprob": -0.13584898435152493, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0005882597179152071}, {"id": 229, "seek": 143116, "start": 1438.92, "end": 1446.3600000000001, "text": " concerned with numbers. Right. So that this kind of separation between sort of the world of numbers", "tokens": [50752, 5922, 365, 3547, 13, 1779, 13, 407, 300, 341, 733, 295, 14634, 1296, 1333, 295, 264, 1002, 295, 3547, 51124], "temperature": 0.0, "avg_logprob": -0.13584898435152493, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0005882597179152071}, {"id": 230, "seek": 143116, "start": 1446.3600000000001, "end": 1451.5600000000002, "text": " and the world of words was one that I think I already was starting to resonate with because", "tokens": [51124, 293, 264, 1002, 295, 2283, 390, 472, 300, 286, 519, 286, 1217, 390, 2891, 281, 34285, 365, 570, 51384], "temperature": 0.0, "avg_logprob": -0.13584898435152493, "compression_ratio": 1.6923076923076923, "no_speech_prob": 0.0005882597179152071}, {"id": 231, "seek": 145156, "start": 1451.56, "end": 1460.04, "text": " I felt like I had sort of interests in both, in both of those worlds. That's, that's interesting. So", "tokens": [50364, 286, 2762, 411, 286, 632, 1333, 295, 8847, 294, 1293, 11, 294, 1293, 295, 729, 13401, 13, 663, 311, 11, 300, 311, 1880, 13, 407, 50788], "temperature": 0.0, "avg_logprob": -0.10613704389995998, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.004827873315662146}, {"id": 232, "seek": 145156, "start": 1461.56, "end": 1468.28, "text": " here's a child book, The Phantom Toe Booth, which actually opens up", "tokens": [50864, 510, 311, 257, 1440, 1446, 11, 440, 34689, 1407, 68, 3286, 900, 11, 597, 767, 9870, 493, 51200], "temperature": 0.0, "avg_logprob": -0.10613704389995998, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.004827873315662146}, {"id": 233, "seek": 145156, "start": 1470.84, "end": 1479.56, "text": " a window to two different kinds of cultures. Mm-hmm. There's the culture of language and words,", "tokens": [51328, 257, 4910, 281, 732, 819, 3685, 295, 12951, 13, 8266, 12, 10250, 13, 821, 311, 264, 3713, 295, 2856, 293, 2283, 11, 51764], "temperature": 0.0, "avg_logprob": -0.10613704389995998, "compression_ratio": 1.4505494505494505, "no_speech_prob": 0.004827873315662146}, {"id": 234, "seek": 147956, "start": 1479.56, "end": 1487.08, "text": " and then there's the culture of mathematics and numbers. And there's a, there are border lines", "tokens": [50364, 293, 550, 456, 311, 264, 3713, 295, 18666, 293, 3547, 13, 400, 456, 311, 257, 11, 456, 366, 7838, 3876, 50740], "temperature": 0.0, "avg_logprob": -0.07666786424406283, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0002694143040571362}, {"id": 235, "seek": 147956, "start": 1487.08, "end": 1494.36, "text": " between those, but here's an author who's able to cross those borders at will, going from numbers", "tokens": [50740, 1296, 729, 11, 457, 510, 311, 364, 3793, 567, 311, 1075, 281, 3278, 729, 16287, 412, 486, 11, 516, 490, 3547, 51104], "temperature": 0.0, "avg_logprob": -0.07666786424406283, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0002694143040571362}, {"id": 236, "seek": 147956, "start": 1494.36, "end": 1500.36, "text": " to representations, representations to numbers. That had to be a thrilling thing for you as a child.", "tokens": [51104, 281, 33358, 11, 33358, 281, 3547, 13, 663, 632, 281, 312, 257, 39347, 551, 337, 291, 382, 257, 1440, 13, 51404], "temperature": 0.0, "avg_logprob": -0.07666786424406283, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0002694143040571362}, {"id": 237, "seek": 147956, "start": 1501.72, "end": 1506.9199999999998, "text": " Yeah. I remember really, really being struck by that idea that these things were, you know,", "tokens": [51472, 865, 13, 286, 1604, 534, 11, 534, 885, 13159, 538, 300, 1558, 300, 613, 721, 645, 11, 291, 458, 11, 51732], "temperature": 0.0, "avg_logprob": -0.07666786424406283, "compression_ratio": 1.711111111111111, "no_speech_prob": 0.0002694143040571362}, {"id": 238, "seek": 150692, "start": 1507.64, "end": 1512.76, "text": " they were very separate and that, and there was this, you know, I, I'm sort of only vaguely", "tokens": [50400, 436, 645, 588, 4994, 293, 300, 11, 293, 456, 390, 341, 11, 291, 458, 11, 286, 11, 286, 478, 1333, 295, 787, 13501, 48863, 50656], "temperature": 0.0, "avg_logprob": -0.10748452889291864, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.00024532846873626113}, {"id": 239, "seek": 150692, "start": 1512.76, "end": 1518.1200000000001, "text": " remembering a lot of this book I have to admit, but that's one of the things that was striking to me.", "tokens": [50656, 20719, 257, 688, 295, 341, 1446, 286, 362, 281, 9796, 11, 457, 300, 311, 472, 295, 264, 721, 300, 390, 18559, 281, 385, 13, 50924], "temperature": 0.0, "avg_logprob": -0.10748452889291864, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.00024532846873626113}, {"id": 240, "seek": 150692, "start": 1519.3200000000002, "end": 1526.92, "text": " That's interesting. So this is a book that I presume you would recommend for, for parents and", "tokens": [50984, 663, 311, 1880, 13, 407, 341, 307, 257, 1446, 300, 286, 43283, 291, 576, 2748, 337, 11, 337, 3152, 293, 51364], "temperature": 0.0, "avg_logprob": -0.10748452889291864, "compression_ratio": 1.5769230769230769, "no_speech_prob": 0.00024532846873626113}, {"id": 241, "seek": 152692, "start": 1526.92, "end": 1536.2, "text": " teachers and others, if you want to inspire a young person in the world of metaphor and", "tokens": [50364, 6023, 293, 2357, 11, 498, 291, 528, 281, 15638, 257, 2037, 954, 294, 264, 1002, 295, 19157, 293, 50828], "temperature": 0.0, "avg_logprob": -0.09367801802498954, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.03408864140510559}, {"id": 242, "seek": 152692, "start": 1536.2, "end": 1544.8400000000001, "text": " analogies and mathematical objects, this is, this is a place to start because it, it is accessible.", "tokens": [50828, 16660, 530, 293, 18894, 6565, 11, 341, 307, 11, 341, 307, 257, 1081, 281, 722, 570, 309, 11, 309, 307, 9515, 13, 51260], "temperature": 0.0, "avg_logprob": -0.09367801802498954, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.03408864140510559}, {"id": 243, "seek": 152692, "start": 1546.2, "end": 1550.92, "text": " It's very accessible and kids, children love it. I, I read it to my own two children,", "tokens": [51328, 467, 311, 588, 9515, 293, 2301, 11, 2227, 959, 309, 13, 286, 11, 286, 1401, 309, 281, 452, 1065, 732, 2227, 11, 51564], "temperature": 0.0, "avg_logprob": -0.09367801802498954, "compression_ratio": 1.5689655172413792, "no_speech_prob": 0.03408864140510559}, {"id": 244, "seek": 155092, "start": 1551.88, "end": 1559.24, "text": " many years ago. And they, I, I don't know if they loved it as much as I did, but I remember them", "tokens": [50412, 867, 924, 2057, 13, 400, 436, 11, 286, 11, 286, 500, 380, 458, 498, 436, 4333, 309, 382, 709, 382, 286, 630, 11, 457, 286, 1604, 552, 50780], "temperature": 0.0, "avg_logprob": -0.1630994004088563, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.0009109099046327174}, {"id": 245, "seek": 155092, "start": 1559.24, "end": 1565.88, "text": " that they, they, they found it quite amusing, all the word play and puns and everything.", "tokens": [50780, 300, 436, 11, 436, 11, 436, 1352, 309, 1596, 47809, 11, 439, 264, 1349, 862, 293, 4468, 82, 293, 1203, 13, 51112], "temperature": 0.0, "avg_logprob": -0.1630994004088563, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.0009109099046327174}, {"id": 246, "seek": 155092, "start": 1566.76, "end": 1572.92, "text": " That's interesting. So the tradition of the first book on your list that you had as a child,", "tokens": [51156, 663, 311, 1880, 13, 407, 264, 6994, 295, 264, 700, 1446, 322, 428, 1329, 300, 291, 632, 382, 257, 1440, 11, 51464], "temperature": 0.0, "avg_logprob": -0.1630994004088563, "compression_ratio": 1.5108695652173914, "no_speech_prob": 0.0009109099046327174}, {"id": 247, "seek": 157292, "start": 1573.64, "end": 1578.68, "text": " you made a point of sharing that experience with your own two children", "tokens": [50400, 291, 1027, 257, 935, 295, 5414, 300, 1752, 365, 428, 1065, 732, 2227, 50652], "temperature": 0.0, "avg_logprob": -0.13718796968460084, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.03788148611783981}, {"id": 248, "seek": 157292, "start": 1579.48, "end": 1585.3200000000002, "text": " in order to pass along, which you hope would be a similar kind of experience.", "tokens": [50692, 294, 1668, 281, 1320, 2051, 11, 597, 291, 1454, 576, 312, 257, 2531, 733, 295, 1752, 13, 50984], "temperature": 0.0, "avg_logprob": -0.13718796968460084, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.03788148611783981}, {"id": 249, "seek": 157292, "start": 1586.28, "end": 1590.8400000000001, "text": " Yeah. And I haven't asked them if they remember that book. I should ask them someday.", "tokens": [51032, 865, 13, 400, 286, 2378, 380, 2351, 552, 498, 436, 1604, 300, 1446, 13, 286, 820, 1029, 552, 19412, 13, 51260], "temperature": 0.0, "avg_logprob": -0.13718796968460084, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.03788148611783981}, {"id": 250, "seek": 157292, "start": 1591.3200000000002, "end": 1600.2, "text": " No. I think it would be interesting to go back for parents to go back to children, particularly", "tokens": [51284, 883, 13, 286, 519, 309, 576, 312, 1880, 281, 352, 646, 337, 3152, 281, 352, 646, 281, 2227, 11, 4098, 51728], "temperature": 0.0, "avg_logprob": -0.13718796968460084, "compression_ratio": 1.5942028985507246, "no_speech_prob": 0.03788148611783981}, {"id": 251, "seek": 160020, "start": 1600.2, "end": 1608.3600000000001, "text": " if they're late teens or early adults and say, do you remember when I, when we read this book", "tokens": [50364, 498, 436, 434, 3469, 24849, 420, 2440, 8865, 293, 584, 11, 360, 291, 1604, 562, 286, 11, 562, 321, 1401, 341, 1446, 50772], "temperature": 0.0, "avg_logprob": -0.10531001255430024, "compression_ratio": 1.625615763546798, "no_speech_prob": 0.002980299759656191}, {"id": 252, "seek": 160020, "start": 1608.3600000000001, "end": 1614.2, "text": " together? Do you, do you have any memories of this? Did it have any impact on your life?", "tokens": [50772, 1214, 30, 1144, 291, 11, 360, 291, 362, 604, 8495, 295, 341, 30, 2589, 309, 362, 604, 2712, 322, 428, 993, 30, 51064], "temperature": 0.0, "avg_logprob": -0.10531001255430024, "compression_ratio": 1.625615763546798, "no_speech_prob": 0.002980299759656191}, {"id": 253, "seek": 160020, "start": 1614.2, "end": 1622.68, "text": " Because it had an impact on mine. I was on a conversation with someone on a talk show", "tokens": [51064, 1436, 309, 632, 364, 2712, 322, 3892, 13, 286, 390, 322, 257, 3761, 365, 1580, 322, 257, 751, 855, 51488], "temperature": 0.0, "avg_logprob": -0.10531001255430024, "compression_ratio": 1.625615763546798, "no_speech_prob": 0.002980299759656191}, {"id": 254, "seek": 160020, "start": 1623.72, "end": 1627.16, "text": " where I talked about this book and I talked about you. Right.", "tokens": [51540, 689, 286, 2825, 466, 341, 1446, 293, 286, 2825, 466, 291, 13, 1779, 13, 51712], "temperature": 0.0, "avg_logprob": -0.10531001255430024, "compression_ratio": 1.625615763546798, "no_speech_prob": 0.002980299759656191}, {"id": 255, "seek": 162716, "start": 1627.5600000000002, "end": 1632.2, "text": " Full circle. Right. Y'all, I'll ask them.", "tokens": [50384, 13841, 6329, 13, 1779, 13, 398, 6, 336, 11, 286, 603, 1029, 552, 13, 50616], "temperature": 0.0, "avg_logprob": -0.18698013660519622, "compression_ratio": 1.4018691588785046, "no_speech_prob": 0.00036827477742917836}, {"id": 256, "seek": 162716, "start": 1634.52, "end": 1642.52, "text": " The next book, another wonderful selection is A Wrinkle in Time by Madeleine Naingal.", "tokens": [50732, 440, 958, 1446, 11, 1071, 3715, 9450, 307, 316, 10159, 14095, 294, 6161, 538, 18330, 306, 533, 6056, 278, 304, 13, 51132], "temperature": 0.0, "avg_logprob": -0.18698013660519622, "compression_ratio": 1.4018691588785046, "no_speech_prob": 0.00036827477742917836}, {"id": 257, "seek": 162716, "start": 1644.44, "end": 1649.5600000000002, "text": " Again, I'll give just a little bit of an introduction because I don't expect you to", "tokens": [51228, 3764, 11, 286, 603, 976, 445, 257, 707, 857, 295, 364, 9339, 570, 286, 500, 380, 2066, 291, 281, 51484], "temperature": 0.0, "avg_logprob": -0.18698013660519622, "compression_ratio": 1.4018691588785046, "no_speech_prob": 0.00036827477742917836}, {"id": 258, "seek": 162716, "start": 1649.5600000000002, "end": 1654.8400000000001, "text": " remember all the details of this. You've read a long time ago, but before I get to that,", "tokens": [51484, 1604, 439, 264, 4365, 295, 341, 13, 509, 600, 1401, 257, 938, 565, 2057, 11, 457, 949, 286, 483, 281, 300, 11, 51748], "temperature": 0.0, "avg_logprob": -0.18698013660519622, "compression_ratio": 1.4018691588785046, "no_speech_prob": 0.00036827477742917836}, {"id": 259, "seek": 165484, "start": 1654.84, "end": 1660.9199999999998, "text": " about what age were you when you read this? That one I remember because I, we read it in", "tokens": [50364, 466, 437, 3205, 645, 291, 562, 291, 1401, 341, 30, 663, 472, 286, 1604, 570, 286, 11, 321, 1401, 309, 294, 50668], "temperature": 0.0, "avg_logprob": -0.11346268653869629, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0008691740222275257}, {"id": 260, "seek": 165484, "start": 1660.9199999999998, "end": 1669.32, "text": " my fourth grade class, which is nine years old. Okay. So at nine years old, you're reading about a", "tokens": [50668, 452, 6409, 7204, 1508, 11, 597, 307, 4949, 924, 1331, 13, 1033, 13, 407, 412, 4949, 924, 1331, 11, 291, 434, 3760, 466, 257, 51088], "temperature": 0.0, "avg_logprob": -0.11346268653869629, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0008691740222275257}, {"id": 261, "seek": 165484, "start": 1669.32, "end": 1677.48, "text": " high school student named Meg Murray and her younger brother Charles Wallace and their friend", "tokens": [51088, 1090, 1395, 3107, 4926, 9986, 27291, 293, 720, 7037, 3708, 10523, 32626, 293, 641, 1277, 51496], "temperature": 0.0, "avg_logprob": -0.11346268653869629, "compression_ratio": 1.4789473684210526, "no_speech_prob": 0.0008691740222275257}, {"id": 262, "seek": 167748, "start": 1677.56, "end": 1684.2, "text": " Calvin O'Keefe. And basically it's a quest, right? Where the father who's a scientist", "tokens": [50368, 28025, 422, 6, 42, 1653, 2106, 13, 400, 1936, 309, 311, 257, 866, 11, 558, 30, 2305, 264, 3086, 567, 311, 257, 12662, 50700], "temperature": 0.0, "avg_logprob": -0.16343907674153646, "compression_ratio": 1.3959390862944163, "no_speech_prob": 0.02095630206167698}, {"id": 263, "seek": 167748, "start": 1684.76, "end": 1693.48, "text": " has gone missing. He's disappeared. No one knows where he is for a year. And suddenly out of kind", "tokens": [50728, 575, 2780, 5361, 13, 634, 311, 13954, 13, 883, 472, 3255, 689, 415, 307, 337, 257, 1064, 13, 400, 5800, 484, 295, 733, 51164], "temperature": 0.0, "avg_logprob": -0.16343907674153646, "compression_ratio": 1.3959390862944163, "no_speech_prob": 0.02095630206167698}, {"id": 264, "seek": 167748, "start": 1693.48, "end": 1701.8, "text": " of nowhere, this is the magic of children's literature, someone arrives called Mrs. Wetzit.", "tokens": [51164, 295, 11159, 11, 341, 307, 264, 5585, 295, 2227, 311, 10394, 11, 1580, 20116, 1219, 9814, 13, 343, 10074, 270, 13, 51580], "temperature": 0.0, "avg_logprob": -0.16343907674153646, "compression_ratio": 1.3959390862944163, "no_speech_prob": 0.02095630206167698}, {"id": 265, "seek": 170180, "start": 1702.68, "end": 1709.1599999999999, "text": " And Mrs. Wetzit is one of these creatures from another dimension", "tokens": [50408, 400, 9814, 13, 343, 10074, 270, 307, 472, 295, 613, 12281, 490, 1071, 10139, 50732], "temperature": 0.0, "avg_logprob": -0.09288888592873851, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.004828992299735546}, {"id": 266, "seek": 170180, "start": 1710.04, "end": 1717.48, "text": " who comes with information about the father. And she also has two friends,", "tokens": [50776, 567, 1487, 365, 1589, 466, 264, 3086, 13, 400, 750, 611, 575, 732, 1855, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09288888592873851, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.004828992299735546}, {"id": 267, "seek": 170180, "start": 1717.48, "end": 1728.52, "text": " Mrs. Who and Mrs. Witch. So Mrs. Wetzit, Mrs. Who and Mrs. Witch become the guides", "tokens": [51148, 9814, 13, 2102, 293, 9814, 13, 23522, 13, 407, 9814, 13, 343, 10074, 270, 11, 9814, 13, 2102, 293, 9814, 13, 23522, 1813, 264, 17007, 51700], "temperature": 0.0, "avg_logprob": -0.09288888592873851, "compression_ratio": 1.5633802816901408, "no_speech_prob": 0.004828992299735546}, {"id": 268, "seek": 172852, "start": 1729.24, "end": 1735.32, "text": " for these three youngsters who are able to find a wrinkle in time, a pteroset,", "tokens": [50400, 337, 613, 1045, 49068, 567, 366, 1075, 281, 915, 257, 928, 14095, 294, 565, 11, 257, 280, 391, 329, 302, 11, 50704], "temperature": 0.0, "avg_logprob": -0.12964846482917444, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.001115813385695219}, {"id": 269, "seek": 172852, "start": 1736.68, "end": 1743.24, "text": " to be able to go into another dimension to follow the trail of the missing father.", "tokens": [50772, 281, 312, 1075, 281, 352, 666, 1071, 10139, 281, 1524, 264, 9924, 295, 264, 5361, 3086, 13, 51100], "temperature": 0.0, "avg_logprob": -0.12964846482917444, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.001115813385695219}, {"id": 270, "seek": 172852, "start": 1744.92, "end": 1755.08, "text": " Now, so what we have then is this notion of searching for a parent, which is something I think", "tokens": [51184, 823, 11, 370, 437, 321, 362, 550, 307, 341, 10710, 295, 10808, 337, 257, 2596, 11, 597, 307, 746, 286, 519, 51692], "temperature": 0.0, "avg_logprob": -0.12964846482917444, "compression_ratio": 1.532934131736527, "no_speech_prob": 0.001115813385695219}, {"id": 271, "seek": 175508, "start": 1755.08, "end": 1760.6799999999998, "text": " all children can probably relate to. The father's missing. What can I do to find my dad?", "tokens": [50364, 439, 2227, 393, 1391, 10961, 281, 13, 440, 3086, 311, 5361, 13, 708, 393, 286, 360, 281, 915, 452, 3546, 30, 50644], "temperature": 0.0, "avg_logprob": -0.13565882632606907, "compression_ratio": 1.555084745762712, "no_speech_prob": 0.0057287802919745445}, {"id": 272, "seek": 175508, "start": 1761.32, "end": 1766.52, "text": " What help can I find? It goes back to your earlier point where social creatures,", "tokens": [50676, 708, 854, 393, 286, 915, 30, 467, 1709, 646, 281, 428, 3071, 935, 689, 2093, 12281, 11, 50936], "temperature": 0.0, "avg_logprob": -0.13565882632606907, "compression_ratio": 1.555084745762712, "no_speech_prob": 0.0057287802919745445}, {"id": 273, "seek": 175508, "start": 1767.24, "end": 1775.48, "text": " we seek other people around us that we trust to help us on our quest. This goes from the Lord of", "tokens": [50972, 321, 8075, 661, 561, 926, 505, 300, 321, 3361, 281, 854, 505, 322, 527, 866, 13, 639, 1709, 490, 264, 3257, 295, 51384], "temperature": 0.0, "avg_logprob": -0.13565882632606907, "compression_ratio": 1.555084745762712, "no_speech_prob": 0.0057287802919745445}, {"id": 274, "seek": 175508, "start": 1775.48, "end": 1784.6, "text": " the Rings to a wrinkle in time. It's the same kind of dynamic. As you find your allies, those people", "tokens": [51384, 264, 38543, 281, 257, 928, 14095, 294, 565, 13, 467, 311, 264, 912, 733, 295, 8546, 13, 1018, 291, 915, 428, 14719, 11, 729, 561, 51840], "temperature": 0.0, "avg_logprob": -0.13565882632606907, "compression_ratio": 1.555084745762712, "no_speech_prob": 0.0057287802919745445}, {"id": 275, "seek": 178460, "start": 1784.6, "end": 1789.9599999999998, "text": " that you've bonded with who see the world pretty much like you do, that will watch your back when", "tokens": [50364, 300, 291, 600, 41194, 365, 567, 536, 264, 1002, 1238, 709, 411, 291, 360, 11, 300, 486, 1159, 428, 646, 562, 50632], "temperature": 0.0, "avg_logprob": -0.0923348683029858, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0010000483598560095}, {"id": 276, "seek": 178460, "start": 1789.9599999999998, "end": 1802.6799999999998, "text": " you're going into the unknown. So what I like about the story is the secret weapon that Meg", "tokens": [50632, 291, 434, 516, 666, 264, 9841, 13, 407, 437, 286, 411, 466, 264, 1657, 307, 264, 4054, 7463, 300, 9986, 51268], "temperature": 0.0, "avg_logprob": -0.0923348683029858, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0010000483598560095}, {"id": 277, "seek": 178460, "start": 1802.6799999999998, "end": 1811.8, "text": " discovers through Mary's trials and tribulations of trying to find the father. And ultimately,", "tokens": [51268, 44522, 807, 6059, 311, 12450, 293, 15039, 4136, 295, 1382, 281, 915, 264, 3086, 13, 400, 6284, 11, 51724], "temperature": 0.0, "avg_logprob": -0.0923348683029858, "compression_ratio": 1.4791666666666667, "no_speech_prob": 0.0010000483598560095}, {"id": 278, "seek": 181180, "start": 1811.8, "end": 1820.84, "text": " she goes back to confront this dark AI kind of force, which is taken over and made everything", "tokens": [50364, 750, 1709, 646, 281, 12422, 341, 2877, 7318, 733, 295, 3464, 11, 597, 307, 2726, 670, 293, 1027, 1203, 50816], "temperature": 0.0, "avg_logprob": -0.1742515762646993, "compression_ratio": 1.3566433566433567, "no_speech_prob": 0.0009398593683727086}, {"id": 279, "seek": 181180, "start": 1820.84, "end": 1835.08, "text": " the same and controls the mind of everyone within this AI's domain. Except Mrs. Wetzit says there is", "tokens": [50816, 264, 912, 293, 9003, 264, 1575, 295, 1518, 1951, 341, 7318, 311, 9274, 13, 16192, 9814, 13, 343, 10074, 270, 1619, 456, 307, 51528], "temperature": 0.0, "avg_logprob": -0.1742515762646993, "compression_ratio": 1.3566433566433567, "no_speech_prob": 0.0009398593683727086}, {"id": 280, "seek": 183508, "start": 1835.1599999999999, "end": 1843.48, "text": " a secret weapon. You'll have to look deep in yourself and you'll find it. If you can find that", "tokens": [50368, 257, 4054, 7463, 13, 509, 603, 362, 281, 574, 2452, 294, 1803, 293, 291, 603, 915, 309, 13, 759, 291, 393, 915, 300, 50784], "temperature": 0.0, "avg_logprob": -0.08824715247521034, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.06554938107728958}, {"id": 281, "seek": 183508, "start": 1843.48, "end": 1852.76, "text": " weapon and you go back to this place and use it, you will be able to find and retrieve your father.", "tokens": [50784, 7463, 293, 291, 352, 646, 281, 341, 1081, 293, 764, 309, 11, 291, 486, 312, 1075, 281, 915, 293, 30254, 428, 3086, 13, 51248], "temperature": 0.0, "avg_logprob": -0.08824715247521034, "compression_ratio": 1.4696969696969697, "no_speech_prob": 0.06554938107728958}, {"id": 282, "seek": 185276, "start": 1853.32, "end": 1854.68, "text": " Do you remember what the weapon was?", "tokens": [50392, 1144, 291, 1604, 437, 264, 7463, 390, 30, 50460], "temperature": 0.0, "avg_logprob": -0.17637154593396542, "compression_ratio": 1.3734177215189873, "no_speech_prob": 0.03208587318658829}, {"id": 283, "seek": 185276, "start": 1859.64, "end": 1866.36, "text": " Love. Yes, that's what I was going to say. Right. Yeah, it was a little corny there.", "tokens": [50708, 5956, 13, 1079, 11, 300, 311, 437, 286, 390, 516, 281, 584, 13, 1779, 13, 865, 11, 309, 390, 257, 707, 1181, 1634, 456, 13, 51044], "temperature": 0.0, "avg_logprob": -0.17637154593396542, "compression_ratio": 1.3734177215189873, "no_speech_prob": 0.03208587318658829}, {"id": 284, "seek": 185276, "start": 1870.04, "end": 1879.08, "text": " But yes. Corny in a way, but on the other hand, very humanizing because it is, again, with that", "tokens": [51228, 583, 2086, 13, 3925, 1634, 294, 257, 636, 11, 457, 322, 264, 661, 1011, 11, 588, 1952, 3319, 570, 309, 307, 11, 797, 11, 365, 300, 51680], "temperature": 0.0, "avg_logprob": -0.17637154593396542, "compression_ratio": 1.3734177215189873, "no_speech_prob": 0.03208587318658829}, {"id": 285, "seek": 187908, "start": 1879.08, "end": 1888.04, "text": " notion of self-sacrifice. And maybe that's something that we do well as humans, and maybe we should", "tokens": [50364, 10710, 295, 2698, 12, 82, 326, 81, 10505, 13, 400, 1310, 300, 311, 746, 300, 321, 360, 731, 382, 6255, 11, 293, 1310, 321, 820, 50812], "temperature": 0.0, "avg_logprob": -0.0932948620288403, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0012253198074176908}, {"id": 286, "seek": 187908, "start": 1888.04, "end": 1897.3999999999999, "text": " do better. But the real notion of love is that ability to sacrifice yourself for another. It's", "tokens": [50812, 360, 1101, 13, 583, 264, 957, 10710, 295, 959, 307, 300, 3485, 281, 11521, 1803, 337, 1071, 13, 467, 311, 51280], "temperature": 0.0, "avg_logprob": -0.0932948620288403, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0012253198074176908}, {"id": 287, "seek": 187908, "start": 1897.3999999999999, "end": 1902.84, "text": " not necessarily just the romantic part of it. It's a self-sacrifice. And here's a daughter", "tokens": [51280, 406, 4725, 445, 264, 13590, 644, 295, 309, 13, 467, 311, 257, 2698, 12, 82, 326, 81, 10505, 13, 400, 510, 311, 257, 4653, 51552], "temperature": 0.0, "avg_logprob": -0.0932948620288403, "compression_ratio": 1.6379310344827587, "no_speech_prob": 0.0012253198074176908}, {"id": 288, "seek": 190284, "start": 1902.9199999999998, "end": 1913.6399999999999, "text": " who is willing to self-sacrifice for her father that disabled the AI. AI was defeated at that point.", "tokens": [50368, 567, 307, 4950, 281, 2698, 12, 82, 326, 81, 10505, 337, 720, 3086, 300, 15191, 264, 7318, 13, 7318, 390, 15563, 412, 300, 935, 13, 50904], "temperature": 0.0, "avg_logprob": -0.11478291352589926, "compression_ratio": 1.3673469387755102, "no_speech_prob": 0.003883445868268609}, {"id": 289, "seek": 190284, "start": 1915.8799999999999, "end": 1924.9199999999998, "text": " Gosh, I don't even remember that it was an AI. Was it a machine? Well, I'm saying an AI. It's called", "tokens": [51016, 19185, 11, 286, 500, 380, 754, 1604, 300, 309, 390, 364, 7318, 13, 3027, 309, 257, 3479, 30, 1042, 11, 286, 478, 1566, 364, 7318, 13, 467, 311, 1219, 51468], "temperature": 0.0, "avg_logprob": -0.11478291352589926, "compression_ratio": 1.3673469387755102, "no_speech_prob": 0.003883445868268609}, {"id": 290, "seek": 192492, "start": 1925.48, "end": 1933.8000000000002, "text": " it. Okay, I do remember that. Yeah. And it's, my notes here, all objects and places appear exactly", "tokens": [50392, 309, 13, 1033, 11, 286, 360, 1604, 300, 13, 865, 13, 400, 309, 311, 11, 452, 5570, 510, 11, 439, 6565, 293, 3190, 4204, 2293, 50808], "temperature": 0.0, "avg_logprob": -0.2004157272545067, "compression_ratio": 1.435, "no_speech_prob": 0.023318029940128326}, {"id": 291, "seek": 192492, "start": 1933.8000000000002, "end": 1943.48, "text": " alike because the whole planet must conform to the terrifying rhythm pulsation of it. A giant", "tokens": [50808, 20025, 570, 264, 1379, 5054, 1633, 18975, 281, 264, 18106, 11801, 32295, 399, 295, 309, 13, 316, 7410, 51292], "temperature": 0.0, "avg_logprob": -0.2004157272545067, "compression_ratio": 1.435, "no_speech_prob": 0.023318029940128326}, {"id": 292, "seek": 192492, "start": 1944.04, "end": 1952.6000000000001, "text": " disembodied brain. Now, that seems to me to be a reasonably good description of for a child of", "tokens": [51320, 717, 33748, 378, 1091, 3567, 13, 823, 11, 300, 2544, 281, 385, 281, 312, 257, 23551, 665, 3855, 295, 337, 257, 1440, 295, 51748], "temperature": 0.0, "avg_logprob": -0.2004157272545067, "compression_ratio": 1.435, "no_speech_prob": 0.023318029940128326}, {"id": 293, "seek": 195260, "start": 1952.6, "end": 1962.84, "text": " what an AI is. This big disembodied brain, in this case, having a kind of super level of intelligence", "tokens": [50364, 437, 364, 7318, 307, 13, 639, 955, 717, 33748, 378, 1091, 3567, 11, 294, 341, 1389, 11, 1419, 257, 733, 295, 1687, 1496, 295, 7599, 50876], "temperature": 0.0, "avg_logprob": -0.13324990927004346, "compression_ratio": 1.3897058823529411, "no_speech_prob": 0.0029795069713145494}, {"id": 294, "seek": 195260, "start": 1962.84, "end": 1970.84, "text": " as opposed to the kind of AI intelligence that confuses a writing of iPod for an apple.", "tokens": [50876, 382, 8851, 281, 264, 733, 295, 7318, 7599, 300, 1497, 8355, 257, 3579, 295, 5180, 378, 337, 364, 10606, 13, 51276], "temperature": 0.0, "avg_logprob": -0.13324990927004346, "compression_ratio": 1.3897058823529411, "no_speech_prob": 0.0029795069713145494}, {"id": 295, "seek": 197084, "start": 1971.24, "end": 1984.36, "text": " Right. Yeah. I mean, the thing that for me that stands out in my memory about this book is,", "tokens": [50384, 1779, 13, 865, 13, 286, 914, 11, 264, 551, 300, 337, 385, 300, 7382, 484, 294, 452, 4675, 466, 341, 1446, 307, 11, 51040], "temperature": 0.0, "avg_logprob": -0.25999464307512554, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.09002945572137833}, {"id": 296, "seek": 197084, "start": 1985.56, "end": 1993.24, "text": " first of all, the female scientists, like both Meg and her mother. Her mother was a brilliant", "tokens": [51100, 700, 295, 439, 11, 264, 6556, 7708, 11, 411, 1293, 9986, 293, 720, 2895, 13, 3204, 2895, 390, 257, 10248, 51484], "temperature": 0.0, "avg_logprob": -0.25999464307512554, "compression_ratio": 1.3805970149253732, "no_speech_prob": 0.09002945572137833}, {"id": 297, "seek": 199324, "start": 1993.24, "end": 1999.56, "text": " scientist. And I really, you know, I think this was one of the first books I had read or", "tokens": [50364, 12662, 13, 400, 286, 534, 11, 291, 458, 11, 286, 519, 341, 390, 472, 295, 264, 700, 3642, 286, 632, 1401, 420, 50680], "temperature": 0.0, "avg_logprob": -0.11562863263216885, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.03513161092996597}, {"id": 298, "seek": 199324, "start": 2001.32, "end": 2007.8, "text": " encountered that had such characters that had female scientists, people who are interested in", "tokens": [50768, 20381, 300, 632, 1270, 4342, 300, 632, 6556, 7708, 11, 561, 567, 366, 3102, 294, 51092], "temperature": 0.0, "avg_logprob": -0.11562863263216885, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.03513161092996597}, {"id": 299, "seek": 199324, "start": 2007.8, "end": 2015.72, "text": " science. And also this notion of multiple dimensions. That was sort of my first introduction to that", "tokens": [51092, 3497, 13, 400, 611, 341, 10710, 295, 3866, 12819, 13, 663, 390, 1333, 295, 452, 700, 9339, 281, 300, 51488], "temperature": 0.0, "avg_logprob": -0.11562863263216885, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.03513161092996597}, {"id": 300, "seek": 199324, "start": 2015.72, "end": 2021.64, "text": " idea of like the fourth dimension and this notion of a tesseract. And I remember that very clearly,", "tokens": [51488, 1558, 295, 411, 264, 6409, 10139, 293, 341, 10710, 295, 257, 256, 14239, 578, 13, 400, 286, 1604, 300, 588, 4448, 11, 51784], "temperature": 0.0, "avg_logprob": -0.11562863263216885, "compression_ratio": 1.7568807339449541, "no_speech_prob": 0.03513161092996597}, {"id": 301, "seek": 202164, "start": 2021.64, "end": 2028.5200000000002, "text": " that that, you know, explaining that this is a four dimensional cube. And it was just fascinating", "tokens": [50364, 300, 300, 11, 291, 458, 11, 13468, 300, 341, 307, 257, 1451, 18795, 13728, 13, 400, 309, 390, 445, 10343, 50708], "temperature": 0.0, "avg_logprob": -0.12943626403808595, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00024533714167773724}, {"id": 302, "seek": 202164, "start": 2028.5200000000002, "end": 2038.68, "text": " to me. I think that's exactly the kind of thing I was hoping to hear is that here's a book that", "tokens": [50708, 281, 385, 13, 286, 519, 300, 311, 2293, 264, 733, 295, 551, 286, 390, 7159, 281, 1568, 307, 300, 510, 311, 257, 1446, 300, 51216], "temperature": 0.0, "avg_logprob": -0.12943626403808595, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00024533714167773724}, {"id": 303, "seek": 202164, "start": 2038.68, "end": 2049.48, "text": " opened up the role of genders. And that you could see for the first time as a child that women are", "tokens": [51216, 5625, 493, 264, 3090, 295, 290, 16292, 13, 400, 300, 291, 727, 536, 337, 264, 700, 565, 382, 257, 1440, 300, 2266, 366, 51756], "temperature": 0.0, "avg_logprob": -0.12943626403808595, "compression_ratio": 1.5783783783783785, "no_speech_prob": 0.00024533714167773724}, {"id": 304, "seek": 204948, "start": 2049.48, "end": 2059.0, "text": " as capable as men, and that women can be scientists, that they can also head up a quest and an", "tokens": [50364, 382, 8189, 382, 1706, 11, 293, 300, 2266, 393, 312, 7708, 11, 300, 436, 393, 611, 1378, 493, 257, 866, 293, 364, 50840], "temperature": 0.0, "avg_logprob": -0.10155832767486572, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.012817704118788242}, {"id": 305, "seek": 204948, "start": 2059.0, "end": 2069.8, "text": " adventure. It doesn't have to be a boy. It can be a girl who actually does all the hard work of", "tokens": [50840, 9868, 13, 467, 1177, 380, 362, 281, 312, 257, 3237, 13, 467, 393, 312, 257, 2013, 567, 767, 775, 439, 264, 1152, 589, 295, 51380], "temperature": 0.0, "avg_logprob": -0.10155832767486572, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.012817704118788242}, {"id": 306, "seek": 204948, "start": 2070.76, "end": 2078.2, "text": " putting together the team, charting the journey, assessing the risks, and ultimately finding the", "tokens": [51428, 3372, 1214, 264, 1469, 11, 6927, 278, 264, 4671, 11, 34348, 264, 10888, 11, 293, 6284, 5006, 264, 51800], "temperature": 0.0, "avg_logprob": -0.10155832767486572, "compression_ratio": 1.6033519553072626, "no_speech_prob": 0.012817704118788242}, {"id": 307, "seek": 207820, "start": 2078.2, "end": 2088.52, "text": " solution. So that must have made a bit of a change in terms of how you thought about your own", "tokens": [50364, 3827, 13, 407, 300, 1633, 362, 1027, 257, 857, 295, 257, 1319, 294, 2115, 295, 577, 291, 1194, 466, 428, 1065, 50880], "temperature": 0.0, "avg_logprob": -0.1037034786922831, "compression_ratio": 1.455, "no_speech_prob": 0.0008828858262859285}, {"id": 308, "seek": 207820, "start": 2088.52, "end": 2095.72, "text": " potential as a young girl. It probably did. You know, I don't remember that explicitly, but I do", "tokens": [50880, 3995, 382, 257, 2037, 2013, 13, 467, 1391, 630, 13, 509, 458, 11, 286, 500, 380, 1604, 300, 20803, 11, 457, 286, 360, 51240], "temperature": 0.0, "avg_logprob": -0.1037034786922831, "compression_ratio": 1.455, "no_speech_prob": 0.0008828858262859285}, {"id": 309, "seek": 207820, "start": 2095.72, "end": 2103.3999999999996, "text": " remember, you know, very much identifying with the Meg character. And also just being very intrigued", "tokens": [51240, 1604, 11, 291, 458, 11, 588, 709, 16696, 365, 264, 9986, 2517, 13, 400, 611, 445, 885, 588, 35140, 51624], "temperature": 0.0, "avg_logprob": -0.1037034786922831, "compression_ratio": 1.455, "no_speech_prob": 0.0008828858262859285}, {"id": 310, "seek": 210340, "start": 2103.4, "end": 2111.08, "text": " by her mother. Right. Because at that time, my own mother at that time was a housewife.", "tokens": [50364, 538, 720, 2895, 13, 1779, 13, 1436, 412, 300, 565, 11, 452, 1065, 2895, 412, 300, 565, 390, 257, 1782, 32779, 13, 50748], "temperature": 0.0, "avg_logprob": -0.20390200981727014, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.01639558933675289}, {"id": 311, "seek": 210340, "start": 2113.1600000000003, "end": 2120.6, "text": " My father was an engineer. I hadn't really encountered women doing being scientists.", "tokens": [50852, 1222, 3086, 390, 364, 11403, 13, 286, 8782, 380, 534, 20381, 2266, 884, 885, 7708, 13, 51224], "temperature": 0.0, "avg_logprob": -0.20390200981727014, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.01639558933675289}, {"id": 312, "seek": 210340, "start": 2121.4, "end": 2129.88, "text": " But maybe that's part of the real beauty of early reading is it provides multiple role models for", "tokens": [51264, 583, 1310, 300, 311, 644, 295, 264, 957, 6643, 295, 2440, 3760, 307, 309, 6417, 3866, 3090, 5245, 337, 51688], "temperature": 0.0, "avg_logprob": -0.20390200981727014, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.01639558933675289}, {"id": 313, "seek": 212988, "start": 2129.88, "end": 2136.6, "text": " children. Because when you grow up, your role models are your mom, your dad. Okay, I have a model of", "tokens": [50364, 2227, 13, 1436, 562, 291, 1852, 493, 11, 428, 3090, 5245, 366, 428, 1225, 11, 428, 3546, 13, 1033, 11, 286, 362, 257, 2316, 295, 50700], "temperature": 0.0, "avg_logprob": -0.10342420505571968, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.003123147413134575}, {"id": 314, "seek": 212988, "start": 2136.6, "end": 2143.96, "text": " a man as an engineer, a model of a woman as a housemaker. And suddenly you're reading a book where,", "tokens": [50700, 257, 587, 382, 364, 11403, 11, 257, 2316, 295, 257, 3059, 382, 257, 1782, 18821, 13, 400, 5800, 291, 434, 3760, 257, 1446, 689, 11, 51068], "temperature": 0.0, "avg_logprob": -0.10342420505571968, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.003123147413134575}, {"id": 315, "seek": 212988, "start": 2144.6, "end": 2152.2000000000003, "text": " you know, there are other models out there. There are other kinds of things that people do, other", "tokens": [51100, 291, 458, 11, 456, 366, 661, 5245, 484, 456, 13, 821, 366, 661, 3685, 295, 721, 300, 561, 360, 11, 661, 51480], "temperature": 0.0, "avg_logprob": -0.10342420505571968, "compression_ratio": 1.6555555555555554, "no_speech_prob": 0.003123147413134575}, {"id": 316, "seek": 215220, "start": 2152.2, "end": 2163.56, "text": " kinds of identities that they're able to shape and create a life with. So that so that that book,", "tokens": [50364, 3685, 295, 24239, 300, 436, 434, 1075, 281, 3909, 293, 1884, 257, 993, 365, 13, 407, 300, 370, 300, 300, 1446, 11, 50932], "temperature": 0.0, "avg_logprob": -0.1160645264845628, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.008313543163239956}, {"id": 317, "seek": 215220, "start": 2163.56, "end": 2170.9199999999996, "text": " I could see would be a quite important foundational one for your own kind of psychological development", "tokens": [50932, 286, 727, 536, 576, 312, 257, 1596, 1021, 32195, 472, 337, 428, 1065, 733, 295, 14346, 3250, 51300], "temperature": 0.0, "avg_logprob": -0.1160645264845628, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.008313543163239956}, {"id": 318, "seek": 215220, "start": 2170.9199999999996, "end": 2177.96, "text": " and perhaps confidence that yeah, there are some other roles out there for women other than which", "tokens": [51300, 293, 4317, 6687, 300, 1338, 11, 456, 366, 512, 661, 9604, 484, 456, 337, 2266, 661, 813, 597, 51652], "temperature": 0.0, "avg_logprob": -0.1160645264845628, "compression_ratio": 1.544041450777202, "no_speech_prob": 0.008313543163239956}, {"id": 319, "seek": 217796, "start": 2177.96, "end": 2190.44, "text": " just what I'm saying around me. Yeah, definitely. Okay, so to leave the world of fiction for a moment,", "tokens": [50364, 445, 437, 286, 478, 1566, 926, 385, 13, 865, 11, 2138, 13, 1033, 11, 370, 281, 1856, 264, 1002, 295, 13266, 337, 257, 1623, 11, 50988], "temperature": 0.0, "avg_logprob": -0.11093691330921801, "compression_ratio": 1.419811320754717, "no_speech_prob": 0.002433609217405319}, {"id": 320, "seek": 217796, "start": 2190.44, "end": 2199.32, "text": " to look at the next book on your list, which is The Universe and Dr. Einstein by Lincoln Barnett.", "tokens": [50988, 281, 574, 412, 264, 958, 1446, 322, 428, 1329, 11, 597, 307, 440, 18307, 293, 2491, 13, 23486, 538, 15993, 21605, 3093, 13, 51432], "temperature": 0.0, "avg_logprob": -0.11093691330921801, "compression_ratio": 1.419811320754717, "no_speech_prob": 0.002433609217405319}, {"id": 321, "seek": 217796, "start": 2199.32, "end": 2206.44, "text": " Now, I've heard you say on another webcast that you read this in high school, and it was responsible", "tokens": [51432, 823, 11, 286, 600, 2198, 291, 584, 322, 1071, 3670, 3734, 300, 291, 1401, 341, 294, 1090, 1395, 11, 293, 309, 390, 6250, 51788], "temperature": 0.0, "avg_logprob": -0.11093691330921801, "compression_ratio": 1.419811320754717, "no_speech_prob": 0.002433609217405319}, {"id": 322, "seek": 220644, "start": 2206.52, "end": 2214.28, "text": " for you to pursue a degree in physics. Right, so that I absolutely I read that in high school.", "tokens": [50368, 337, 291, 281, 12392, 257, 4314, 294, 10649, 13, 1779, 11, 370, 300, 286, 3122, 286, 1401, 300, 294, 1090, 1395, 13, 50756], "temperature": 0.0, "avg_logprob": -0.11417002537671257, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.002842182060703635}, {"id": 323, "seek": 220644, "start": 2214.84, "end": 2221.8, "text": " I think it was suggested by my physics teacher. And I absolutely loved it. You know, it was a", "tokens": [50784, 286, 519, 309, 390, 10945, 538, 452, 10649, 5027, 13, 400, 286, 3122, 4333, 309, 13, 509, 458, 11, 309, 390, 257, 51132], "temperature": 0.0, "avg_logprob": -0.11417002537671257, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.002842182060703635}, {"id": 324, "seek": 220644, "start": 2221.8, "end": 2230.52, "text": " popular exposition of Einstein's theory of relativity. It was fairly short, extremely", "tokens": [51132, 3743, 1278, 5830, 295, 23486, 311, 5261, 295, 45675, 13, 467, 390, 6457, 2099, 11, 4664, 51568], "temperature": 0.0, "avg_logprob": -0.11417002537671257, "compression_ratio": 1.4731182795698925, "no_speech_prob": 0.002842182060703635}, {"id": 325, "seek": 223052, "start": 2231.24, "end": 2240.92, "text": " clear and well written. And it just, you know, astounded me, these ideas. And the fact that you", "tokens": [50400, 1850, 293, 731, 3720, 13, 400, 309, 445, 11, 291, 458, 11, 5357, 37706, 385, 11, 613, 3487, 13, 400, 264, 1186, 300, 291, 50884], "temperature": 0.0, "avg_logprob": -0.16353788891354124, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.03512424975633621}, {"id": 326, "seek": 223052, "start": 2240.92, "end": 2250.28, "text": " could just, you know, Einstein relied quite a bit on thought experiments, you know, what she", "tokens": [50884, 727, 445, 11, 291, 458, 11, 23486, 35463, 1596, 257, 857, 322, 1194, 12050, 11, 291, 458, 11, 437, 750, 51352], "temperature": 0.0, "avg_logprob": -0.16353788891354124, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.03512424975633621}, {"id": 327, "seek": 223052, "start": 2250.28, "end": 2258.28, "text": " called gedonkin experiments, where he didn't actually have a lab or, you know, be doing,", "tokens": [51352, 1219, 19238, 266, 5843, 12050, 11, 689, 415, 994, 380, 767, 362, 257, 2715, 420, 11, 291, 458, 11, 312, 884, 11, 51752], "temperature": 0.0, "avg_logprob": -0.16353788891354124, "compression_ratio": 1.6104651162790697, "no_speech_prob": 0.03512424975633621}, {"id": 328, "seek": 225828, "start": 2258.28, "end": 2262.6000000000004, "text": " you know, writing down lots of equations. But he was just kind of thinking about how things might", "tokens": [50364, 291, 458, 11, 3579, 760, 3195, 295, 11787, 13, 583, 415, 390, 445, 733, 295, 1953, 466, 577, 721, 1062, 50580], "temperature": 0.0, "avg_logprob": -0.09279239052220395, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.0010985786793753505}, {"id": 329, "seek": 225828, "start": 2262.6000000000004, "end": 2269.32, "text": " work. And thinking, you know, well, what happens if the speed of light is constant?", "tokens": [50580, 589, 13, 400, 1953, 11, 291, 458, 11, 731, 11, 437, 2314, 498, 264, 3073, 295, 1442, 307, 5754, 30, 50916], "temperature": 0.0, "avg_logprob": -0.09279239052220395, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.0010985786793753505}, {"id": 330, "seek": 225828, "start": 2270.0400000000004, "end": 2275.4, "text": " But what would that imply? And all of that was just very eye opening for me. And I decided I", "tokens": [50952, 583, 437, 576, 300, 33616, 30, 400, 439, 295, 300, 390, 445, 588, 3313, 5193, 337, 385, 13, 400, 286, 3047, 286, 51220], "temperature": 0.0, "avg_logprob": -0.09279239052220395, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.0010985786793753505}, {"id": 331, "seek": 225828, "start": 2275.4, "end": 2282.6800000000003, "text": " wanted to study physics in college. It's interesting. Again, I can see a little bit of a link here", "tokens": [51220, 1415, 281, 2979, 10649, 294, 3859, 13, 467, 311, 1880, 13, 3764, 11, 286, 393, 536, 257, 707, 857, 295, 257, 2113, 510, 51584], "temperature": 0.0, "avg_logprob": -0.09279239052220395, "compression_ratio": 1.6147186147186148, "no_speech_prob": 0.0010985786793753505}, {"id": 332, "seek": 228268, "start": 2282.68, "end": 2289.0, "text": " between the wrinkle of time, because he's dealing with other dimensions. And also, he's dealing with", "tokens": [50364, 1296, 264, 928, 14095, 295, 565, 11, 570, 415, 311, 6260, 365, 661, 12819, 13, 400, 611, 11, 415, 311, 6260, 365, 50680], "temperature": 0.0, "avg_logprob": -0.09511379514421736, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.025949211791157722}, {"id": 333, "seek": 228268, "start": 2290.68, "end": 2298.44, "text": " reasoning, not in a lab, but by way of analogy, by way of visualization. So he's using", "tokens": [50764, 21577, 11, 406, 294, 257, 2715, 11, 457, 538, 636, 295, 21663, 11, 538, 636, 295, 25801, 13, 407, 415, 311, 1228, 51152], "temperature": 0.0, "avg_logprob": -0.09511379514421736, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.025949211791157722}, {"id": 334, "seek": 228268, "start": 2298.44, "end": 2308.2799999999997, "text": " metaphors, and he's using concrete examples of trains moving in order for that thought experiment", "tokens": [51152, 30946, 830, 11, 293, 415, 311, 1228, 9859, 5110, 295, 16329, 2684, 294, 1668, 337, 300, 1194, 5120, 51644], "temperature": 0.0, "avg_logprob": -0.09511379514421736, "compression_ratio": 1.548913043478261, "no_speech_prob": 0.025949211791157722}, {"id": 335, "seek": 230828, "start": 2308.28, "end": 2315.5600000000004, "text": " to allow, in which he's doing a reversal, he's using analogies as a reversal process", "tokens": [50364, 281, 2089, 11, 294, 597, 415, 311, 884, 257, 42778, 11, 415, 311, 1228, 16660, 530, 382, 257, 42778, 1399, 50728], "temperature": 0.0, "avg_logprob": -0.09427698074825226, "compression_ratio": 1.585987261146497, "no_speech_prob": 0.0008692669798620045}, {"id": 336, "seek": 230828, "start": 2316.6000000000004, "end": 2328.0400000000004, "text": " to come up with an abstraction about an aspect of time, space, velocity, momentum, and", "tokens": [50780, 281, 808, 493, 365, 364, 37765, 466, 364, 4171, 295, 565, 11, 1901, 11, 9269, 11, 11244, 11, 293, 51352], "temperature": 0.0, "avg_logprob": -0.09427698074825226, "compression_ratio": 1.585987261146497, "no_speech_prob": 0.0008692669798620045}, {"id": 337, "seek": 230828, "start": 2329.88, "end": 2337.1600000000003, "text": " to come up with the mathematics of the metaphors that he thought at his desk.", "tokens": [51444, 281, 808, 493, 365, 264, 18666, 295, 264, 30946, 830, 300, 415, 1194, 412, 702, 10026, 13, 51808], "temperature": 0.0, "avg_logprob": -0.09427698074825226, "compression_ratio": 1.585987261146497, "no_speech_prob": 0.0008692669798620045}, {"id": 338, "seek": 233828, "start": 2338.36, "end": 2344.2000000000003, "text": " Exactly. Yeah. So that was, that was quite, quite fascinating for me.", "tokens": [50368, 7587, 13, 865, 13, 407, 300, 390, 11, 300, 390, 1596, 11, 1596, 10343, 337, 385, 13, 50660], "temperature": 0.0, "avg_logprob": -0.17533161375257705, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.0002065822045551613}, {"id": 339, "seek": 233828, "start": 2345.2400000000002, "end": 2351.2400000000002, "text": " So again, I think, you know, I can see this a little bit in your own work that you,", "tokens": [50712, 407, 797, 11, 286, 519, 11, 291, 458, 11, 286, 393, 536, 341, 257, 707, 857, 294, 428, 1065, 589, 300, 291, 11, 51012], "temperature": 0.0, "avg_logprob": -0.17533161375257705, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.0002065822045551613}, {"id": 340, "seek": 233828, "start": 2351.2400000000002, "end": 2357.88, "text": " you're able to see the metaphor making isn't just a translation of the hard mathematics.", "tokens": [51012, 291, 434, 1075, 281, 536, 264, 19157, 1455, 1943, 380, 445, 257, 12853, 295, 264, 1152, 18666, 13, 51344], "temperature": 0.0, "avg_logprob": -0.17533161375257705, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.0002065822045551613}, {"id": 341, "seek": 233828, "start": 2358.6000000000004, "end": 2367.1600000000003, "text": " Einstein in this book, the universe, and Dr. Einstein, shows that it can go the other way as", "tokens": [51380, 23486, 294, 341, 1446, 11, 264, 6445, 11, 293, 2491, 13, 23486, 11, 3110, 300, 309, 393, 352, 264, 661, 636, 382, 51808], "temperature": 0.0, "avg_logprob": -0.17533161375257705, "compression_ratio": 1.5876777251184835, "no_speech_prob": 0.0002065822045551613}, {"id": 342, "seek": 236716, "start": 2367.16, "end": 2377.3199999999997, "text": " well. You can go from the childlike storytelling of multidimensions to creation of mathematical", "tokens": [50364, 731, 13, 509, 393, 352, 490, 264, 1440, 4092, 21479, 295, 2120, 327, 332, 8302, 281, 8016, 295, 18894, 50872], "temperature": 0.0, "avg_logprob": -0.08175575733184814, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0005701971822418272}, {"id": 343, "seek": 236716, "start": 2377.3199999999997, "end": 2387.0, "text": " models that try to come up with a more abstract general way of explaining what a phenomenon is.", "tokens": [50872, 5245, 300, 853, 281, 808, 493, 365, 257, 544, 12649, 2674, 636, 295, 13468, 437, 257, 14029, 307, 13, 51356], "temperature": 0.0, "avg_logprob": -0.08175575733184814, "compression_ratio": 1.4044117647058822, "no_speech_prob": 0.0005701971822418272}, {"id": 344, "seek": 238700, "start": 2387.0, "end": 2397.64, "text": " Is that? Yes. Yeah. I mean, much later, I read another book, you know, now as an adult about", "tokens": [50364, 1119, 300, 30, 1079, 13, 865, 13, 286, 914, 11, 709, 1780, 11, 286, 1401, 1071, 1446, 11, 291, 458, 11, 586, 382, 364, 5075, 466, 50896], "temperature": 0.0, "avg_logprob": -0.13729850105617358, "compression_ratio": 1.5114942528735633, "no_speech_prob": 0.008175565861165524}, {"id": 345, "seek": 238700, "start": 2397.64, "end": 2406.6, "text": " Einstein, and it hypothesized that, you know, Einstein was a patent officer in Switzerland.", "tokens": [50896, 23486, 11, 293, 309, 14276, 1602, 300, 11, 291, 458, 11, 23486, 390, 257, 20495, 8456, 294, 23312, 13, 51344], "temperature": 0.0, "avg_logprob": -0.13729850105617358, "compression_ratio": 1.5114942528735633, "no_speech_prob": 0.008175565861165524}, {"id": 346, "seek": 238700, "start": 2407.24, "end": 2410.68, "text": " And one of the things that people in Switzerland were trying to do at the time", "tokens": [51376, 400, 472, 295, 264, 721, 300, 561, 294, 23312, 645, 1382, 281, 360, 412, 264, 565, 51548], "temperature": 0.0, "avg_logprob": -0.13729850105617358, "compression_ratio": 1.5114942528735633, "no_speech_prob": 0.008175565861165524}, {"id": 347, "seek": 241068, "start": 2411.64, "end": 2417.3999999999996, "text": " was, how do you synchronize clocks between train stations? Because this was an important", "tokens": [50412, 390, 11, 577, 360, 291, 19331, 1125, 41528, 1296, 3847, 13390, 30, 1436, 341, 390, 364, 1021, 50700], "temperature": 0.0, "avg_logprob": -0.11809856590183301, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.005057079717516899}, {"id": 348, "seek": 241068, "start": 2417.3999999999996, "end": 2422.12, "text": " thing to make trains, you know, be able to follow their schedule. So, so he was thinking about this", "tokens": [50700, 551, 281, 652, 16329, 11, 291, 458, 11, 312, 1075, 281, 1524, 641, 7567, 13, 407, 11, 370, 415, 390, 1953, 466, 341, 50936], "temperature": 0.0, "avg_logprob": -0.11809856590183301, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.005057079717516899}, {"id": 349, "seek": 241068, "start": 2422.12, "end": 2429.3199999999997, "text": " extremely practical problem. But thinking about the implications of what does it mean to synchronize?", "tokens": [50936, 4664, 8496, 1154, 13, 583, 1953, 466, 264, 16602, 295, 437, 775, 309, 914, 281, 19331, 1125, 30, 51296], "temperature": 0.0, "avg_logprob": -0.11809856590183301, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.005057079717516899}, {"id": 350, "seek": 241068, "start": 2429.3199999999997, "end": 2437.72, "text": " What does it mean for time to be synchronized? And blowing that up into this incredibly profound", "tokens": [51296, 708, 775, 309, 914, 337, 565, 281, 312, 19331, 1602, 30, 400, 15068, 300, 493, 666, 341, 6252, 14382, 51716], "temperature": 0.0, "avg_logprob": -0.11809856590183301, "compression_ratio": 1.6899563318777293, "no_speech_prob": 0.005057079717516899}, {"id": 351, "seek": 243772, "start": 2438.4399999999996, "end": 2447.64, "text": " truth about the universe and about time itself. So, you know, that's like, as you say,", "tokens": [50400, 3494, 466, 264, 6445, 293, 466, 565, 2564, 13, 407, 11, 291, 458, 11, 300, 311, 411, 11, 382, 291, 584, 11, 50860], "temperature": 0.0, "avg_logprob": -0.09237857546125139, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.005728586111217737}, {"id": 352, "seek": 243772, "start": 2447.64, "end": 2454.68, "text": " it's kind of the reverse metaphor. It's like he sees the very concrete thing of trains and", "tokens": [50860, 309, 311, 733, 295, 264, 9943, 19157, 13, 467, 311, 411, 415, 8194, 264, 588, 9859, 551, 295, 16329, 293, 51212], "temperature": 0.0, "avg_logprob": -0.09237857546125139, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.005728586111217737}, {"id": 353, "seek": 243772, "start": 2454.68, "end": 2463.72, "text": " synchronization and so on. And then he is able to expand that idea into something much more general", "tokens": [51212, 19331, 2144, 293, 370, 322, 13, 400, 550, 415, 307, 1075, 281, 5268, 300, 1558, 666, 746, 709, 544, 2674, 51664], "temperature": 0.0, "avg_logprob": -0.09237857546125139, "compression_ratio": 1.547486033519553, "no_speech_prob": 0.005728586111217737}, {"id": 354, "seek": 246372, "start": 2463.72, "end": 2470.68, "text": " and much more profound. You wonder if he had that kind of aha moment because, you know, the", "tokens": [50364, 293, 709, 544, 14382, 13, 509, 2441, 498, 415, 632, 300, 733, 295, 47340, 1623, 570, 11, 291, 458, 11, 264, 50712], "temperature": 0.0, "avg_logprob": -0.12479179435306126, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010814007837325335}, {"id": 355, "seek": 246372, "start": 2470.68, "end": 2478.3599999999997, "text": " history of our species, you know, for 200,000 years would have been, we think of time as absolute,", "tokens": [50712, 2503, 295, 527, 6172, 11, 291, 458, 11, 337, 2331, 11, 1360, 924, 576, 362, 668, 11, 321, 519, 295, 565, 382, 8236, 11, 51096], "temperature": 0.0, "avg_logprob": -0.12479179435306126, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010814007837325335}, {"id": 356, "seek": 246372, "start": 2479.16, "end": 2486.3599999999997, "text": " of spaces unchanging and absolute. And suddenly to have a thought, it's not absolute,", "tokens": [51136, 295, 7673, 517, 27123, 293, 8236, 13, 400, 5800, 281, 362, 257, 1194, 11, 309, 311, 406, 8236, 11, 51496], "temperature": 0.0, "avg_logprob": -0.12479179435306126, "compression_ratio": 1.491891891891892, "no_speech_prob": 0.0010814007837325335}, {"id": 357, "seek": 248636, "start": 2487.1600000000003, "end": 2494.28, "text": " it's relative. And to take that on the implications of that on, and I think we're,", "tokens": [50404, 309, 311, 4972, 13, 400, 281, 747, 300, 322, 264, 16602, 295, 300, 322, 11, 293, 286, 519, 321, 434, 11, 50760], "temperature": 0.0, "avg_logprob": -0.08470618908221905, "compression_ratio": 1.622754491017964, "no_speech_prob": 0.01321936585009098}, {"id": 358, "seek": 248636, "start": 2494.28, "end": 2501.48, "text": " we're still trying to come to terms with the implications of what that means with time being", "tokens": [50760, 321, 434, 920, 1382, 281, 808, 281, 2115, 365, 264, 16602, 295, 437, 300, 1355, 365, 565, 885, 51120], "temperature": 0.0, "avg_logprob": -0.08470618908221905, "compression_ratio": 1.622754491017964, "no_speech_prob": 0.01321936585009098}, {"id": 359, "seek": 248636, "start": 2501.48, "end": 2511.2400000000002, "text": " relative. Because all of our earthly experiences prepare us for kind of an absolute, absolutist", "tokens": [51120, 4972, 13, 1436, 439, 295, 527, 46262, 5235, 5940, 505, 337, 733, 295, 364, 8236, 11, 18757, 468, 51608], "temperature": 0.0, "avg_logprob": -0.08470618908221905, "compression_ratio": 1.622754491017964, "no_speech_prob": 0.01321936585009098}, {"id": 360, "seek": 251124, "start": 2511.3199999999997, "end": 2518.9199999999996, "text": " notion of time. And you're someone who challenged what is probably one of the bedrock notions", "tokens": [50368, 10710, 295, 565, 13, 400, 291, 434, 1580, 567, 17737, 437, 307, 1391, 472, 295, 264, 2901, 17799, 35799, 50748], "temperature": 0.0, "avg_logprob": -0.11541970570882161, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.012051289901137352}, {"id": 361, "seek": 251124, "start": 2520.04, "end": 2526.8399999999997, "text": " that most people have. And I can see you're in high school now, and you're thinking,", "tokens": [50804, 300, 881, 561, 362, 13, 400, 286, 393, 536, 291, 434, 294, 1090, 1395, 586, 11, 293, 291, 434, 1953, 11, 51144], "temperature": 0.0, "avg_logprob": -0.11541970570882161, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.012051289901137352}, {"id": 362, "seek": 251124, "start": 2527.7999999999997, "end": 2535.08, "text": " if time can, is not absolute and can be challenged, what else is there in physics", "tokens": [51192, 498, 565, 393, 11, 307, 406, 8236, 293, 393, 312, 17737, 11, 437, 1646, 307, 456, 294, 10649, 51556], "temperature": 0.0, "avg_logprob": -0.11541970570882161, "compression_ratio": 1.5853658536585367, "no_speech_prob": 0.012051289901137352}, {"id": 363, "seek": 253508, "start": 2535.08, "end": 2542.92, "text": " that will allow me to do similar kinds of challenges to what are basic understandings of", "tokens": [50364, 300, 486, 2089, 385, 281, 360, 2531, 3685, 295, 4759, 281, 437, 366, 3875, 1223, 1109, 295, 50756], "temperature": 0.0, "avg_logprob": -0.14088872653334888, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0018671653233468533}, {"id": 364, "seek": 253508, "start": 2542.92, "end": 2547.96, "text": " the world, which work on one level, but are fundamentally incorrect?", "tokens": [50756, 264, 1002, 11, 597, 589, 322, 472, 1496, 11, 457, 366, 17879, 18424, 30, 51008], "temperature": 0.0, "avg_logprob": -0.14088872653334888, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0018671653233468533}, {"id": 365, "seek": 253508, "start": 2551.48, "end": 2560.12, "text": " Yeah, I don't know if I was thinking all that, but yeah, I didn't, yeah, I was trying to just get", "tokens": [51184, 865, 11, 286, 500, 380, 458, 498, 286, 390, 1953, 439, 300, 11, 457, 1338, 11, 286, 994, 380, 11, 1338, 11, 286, 390, 1382, 281, 445, 483, 51616], "temperature": 0.0, "avg_logprob": -0.14088872653334888, "compression_ratio": 1.5088757396449703, "no_speech_prob": 0.0018671653233468533}, {"id": 366, "seek": 256012, "start": 2560.12, "end": 2569.96, "text": " my mind around that, that whole very counterintuitive ideas. Yes, yes. So by the time you're in high", "tokens": [50364, 452, 1575, 926, 300, 11, 300, 1379, 588, 5682, 686, 48314, 3487, 13, 1079, 11, 2086, 13, 407, 538, 264, 565, 291, 434, 294, 1090, 50856], "temperature": 0.0, "avg_logprob": -0.11045696928694441, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00062600988894701}, {"id": 367, "seek": 256012, "start": 2569.96, "end": 2581.96, "text": " school, you've decided that physics is the career path that you wanted to take. And you've, you've", "tokens": [50856, 1395, 11, 291, 600, 3047, 300, 10649, 307, 264, 3988, 3100, 300, 291, 1415, 281, 747, 13, 400, 291, 600, 11, 291, 600, 51456], "temperature": 0.0, "avg_logprob": -0.11045696928694441, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00062600988894701}, {"id": 368, "seek": 256012, "start": 2581.96, "end": 2588.7599999999998, "text": " said that this, this particular book is one of the books that probably was influential in setting", "tokens": [51456, 848, 300, 341, 11, 341, 1729, 1446, 307, 472, 295, 264, 3642, 300, 1391, 390, 22215, 294, 3287, 51796], "temperature": 0.0, "avg_logprob": -0.11045696928694441, "compression_ratio": 1.5549738219895288, "no_speech_prob": 0.00062600988894701}, {"id": 369, "seek": 258876, "start": 2588.76, "end": 2598.6800000000003, "text": " you on that path. Yes. So again, I think it shows childhood reading has enormous implications,", "tokens": [50364, 291, 322, 300, 3100, 13, 1079, 13, 407, 797, 11, 286, 519, 309, 3110, 9278, 3760, 575, 11322, 16602, 11, 50860], "temperature": 0.0, "avg_logprob": -0.08267489346590909, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.001366821234114468}, {"id": 370, "seek": 258876, "start": 2599.88, "end": 2605.88, "text": " because what it does is it starts a train of thought, and that train of thought leads people", "tokens": [50920, 570, 437, 309, 775, 307, 309, 3719, 257, 3847, 295, 1194, 11, 293, 300, 3847, 295, 1194, 6689, 561, 51220], "temperature": 0.0, "avg_logprob": -0.08267489346590909, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.001366821234114468}, {"id": 371, "seek": 258876, "start": 2605.88, "end": 2612.5200000000004, "text": " into a direction which they may not have otherwise taken, but for having come across to read that", "tokens": [51220, 666, 257, 3513, 597, 436, 815, 406, 362, 5911, 2726, 11, 457, 337, 1419, 808, 2108, 281, 1401, 300, 51552], "temperature": 0.0, "avg_logprob": -0.08267489346590909, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.001366821234114468}, {"id": 372, "seek": 261252, "start": 2612.52, "end": 2615.48, "text": " book. Absolutely. Yes.", "tokens": [50364, 1446, 13, 7021, 13, 1079, 13, 50512], "temperature": 0.0, "avg_logprob": -0.18397819995880127, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.0022863629274070263}, {"id": 373, "seek": 261252, "start": 2619.4, "end": 2629.32, "text": " The next book, Fads Balaces in the Name of Science by Martin Gardner. I hadn't been familiar with", "tokens": [50708, 440, 958, 1446, 11, 479, 5834, 13140, 2116, 294, 264, 13866, 295, 8976, 538, 9184, 12882, 1193, 13, 286, 8782, 380, 668, 4963, 365, 51204], "temperature": 0.0, "avg_logprob": -0.18397819995880127, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.0022863629274070263}, {"id": 374, "seek": 261252, "start": 2629.32, "end": 2637.0, "text": " this book, but it's an absolutely timely book to, to discuss. I mean, this is pre-internet,", "tokens": [51204, 341, 1446, 11, 457, 309, 311, 364, 3122, 25150, 1446, 281, 11, 281, 2248, 13, 286, 914, 11, 341, 307, 659, 12, 259, 2231, 302, 11, 51588], "temperature": 0.0, "avg_logprob": -0.18397819995880127, "compression_ratio": 1.3503184713375795, "no_speech_prob": 0.0022863629274070263}, {"id": 375, "seek": 263700, "start": 2637.0, "end": 2648.2, "text": " pre-fake news, you know, pre silos on Twitter and Facebook and the rest of it. He's taking on", "tokens": [50364, 659, 12, 69, 619, 2583, 11, 291, 458, 11, 659, 48893, 322, 5794, 293, 4384, 293, 264, 1472, 295, 309, 13, 634, 311, 1940, 322, 50924], "temperature": 0.0, "avg_logprob": -0.1193281608291819, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.003272696863859892}, {"id": 376, "seek": 263700, "start": 2648.92, "end": 2658.76, "text": " the whole kind of area of quack remedies, of cranks, and how cranks have, you know, historically been", "tokens": [50960, 264, 1379, 733, 295, 1859, 295, 421, 501, 47133, 11, 295, 941, 14592, 11, 293, 577, 941, 14592, 362, 11, 291, 458, 11, 16180, 668, 51452], "temperature": 0.0, "avg_logprob": -0.1193281608291819, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.003272696863859892}, {"id": 377, "seek": 263700, "start": 2658.76, "end": 2664.52, "text": " able to get quite a good audience. They didn't need social media to come along to give them an", "tokens": [51452, 1075, 281, 483, 1596, 257, 665, 4034, 13, 814, 994, 380, 643, 2093, 3021, 281, 808, 2051, 281, 976, 552, 364, 51740], "temperature": 0.0, "avg_logprob": -0.1193281608291819, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.003272696863859892}, {"id": 378, "seek": 266452, "start": 2664.84, "end": 2672.28, "text": " audience. I mean, now that has been quite effective, but before they had publishers", "tokens": [50380, 4034, 13, 286, 914, 11, 586, 300, 575, 668, 1596, 4942, 11, 457, 949, 436, 632, 30421, 50752], "temperature": 0.0, "avg_logprob": -0.10809733732691351, "compression_ratio": 1.5, "no_speech_prob": 0.0006262861425057054}, {"id": 379, "seek": 266452, "start": 2673.32, "end": 2680.28, "text": " that were quite willing to publish their books because there was an audience for what cranks", "tokens": [50804, 300, 645, 1596, 4950, 281, 11374, 641, 3642, 570, 456, 390, 364, 4034, 337, 437, 941, 14592, 51152], "temperature": 0.0, "avg_logprob": -0.10809733732691351, "compression_ratio": 1.5, "no_speech_prob": 0.0006262861425057054}, {"id": 380, "seek": 266452, "start": 2681.48, "end": 2685.16, "text": " had to say, even though it was clearly wrong.", "tokens": [51212, 632, 281, 584, 11, 754, 1673, 309, 390, 4448, 2085, 13, 51396], "temperature": 0.0, "avg_logprob": -0.10809733732691351, "compression_ratio": 1.5, "no_speech_prob": 0.0006262861425057054}, {"id": 381, "seek": 268516, "start": 2685.56, "end": 2696.04, "text": " So, tell me a little bit about what age you were and the circumstances of coming across this book.", "tokens": [50384, 407, 11, 980, 385, 257, 707, 857, 466, 437, 3205, 291, 645, 293, 264, 9121, 295, 1348, 2108, 341, 1446, 13, 50908], "temperature": 0.0, "avg_logprob": -0.12591340908637413, "compression_ratio": 1.2925170068027212, "no_speech_prob": 0.0021822904236614704}, {"id": 382, "seek": 268516, "start": 2698.8399999999997, "end": 2706.3599999999997, "text": " So, I think I was in college. I don't quite remember, but I loved Martin Gardner. You know,", "tokens": [51048, 407, 11, 286, 519, 286, 390, 294, 3859, 13, 286, 500, 380, 1596, 1604, 11, 457, 286, 4333, 9184, 12882, 1193, 13, 509, 458, 11, 51424], "temperature": 0.0, "avg_logprob": -0.12591340908637413, "compression_ratio": 1.2925170068027212, "no_speech_prob": 0.0021822904236614704}, {"id": 383, "seek": 270636, "start": 2706.36, "end": 2714.2000000000003, "text": " he was a long time columnist for Scientific American. He was an incredible communicator", "tokens": [50364, 415, 390, 257, 938, 565, 7738, 468, 337, 47437, 2665, 13, 634, 390, 364, 4651, 3363, 1639, 50756], "temperature": 0.0, "avg_logprob": -0.11347405115763347, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.09262494742870331}, {"id": 384, "seek": 270636, "start": 2715.2400000000002, "end": 2725.48, "text": " of math. He was a math puzzle fanatic and a math puzzle creator and a wonderful writer,", "tokens": [50808, 295, 5221, 13, 634, 390, 257, 5221, 12805, 3429, 2399, 293, 257, 5221, 12805, 14181, 293, 257, 3715, 9936, 11, 51320], "temperature": 0.0, "avg_logprob": -0.11347405115763347, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.09262494742870331}, {"id": 385, "seek": 270636, "start": 2727.32, "end": 2734.44, "text": " just super playful person interested in all kinds of things. So, I had been reading, you know,", "tokens": [51412, 445, 1687, 30730, 954, 3102, 294, 439, 3685, 295, 721, 13, 407, 11, 286, 632, 668, 3760, 11, 291, 458, 11, 51768], "temperature": 0.0, "avg_logprob": -0.11347405115763347, "compression_ratio": 1.5083798882681565, "no_speech_prob": 0.09262494742870331}, {"id": 386, "seek": 273444, "start": 2734.44, "end": 2742.12, "text": " I read his column and I picked up, I guess I picked up this book and found it really just,", "tokens": [50364, 286, 1401, 702, 7738, 293, 286, 6183, 493, 11, 286, 2041, 286, 6183, 493, 341, 1446, 293, 1352, 309, 534, 445, 11, 50748], "temperature": 0.0, "avg_logprob": -0.14026686171410788, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0010984636610373855}, {"id": 387, "seek": 273444, "start": 2742.12, "end": 2749.56, "text": " you know, thinking about what drives people to believe things and sort of, and as you say,", "tokens": [50748, 291, 458, 11, 1953, 466, 437, 11754, 561, 281, 1697, 721, 293, 1333, 295, 11, 293, 382, 291, 584, 11, 51120], "temperature": 0.0, "avg_logprob": -0.14026686171410788, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0010984636610373855}, {"id": 388, "seek": 273444, "start": 2749.56, "end": 2757.88, "text": " it's very relevant now is sort of, what is science? Why do we believe science? What is", "tokens": [51120, 309, 311, 588, 7340, 586, 307, 1333, 295, 11, 437, 307, 3497, 30, 1545, 360, 321, 1697, 3497, 30, 708, 307, 51536], "temperature": 0.0, "avg_logprob": -0.14026686171410788, "compression_ratio": 1.6047904191616766, "no_speech_prob": 0.0010984636610373855}, {"id": 389, "seek": 275788, "start": 2757.88, "end": 2764.84, "text": " different between science and all these kind of quack beliefs? And that's something, you know,", "tokens": [50364, 819, 1296, 3497, 293, 439, 613, 733, 295, 421, 501, 13585, 30, 400, 300, 311, 746, 11, 291, 458, 11, 50712], "temperature": 0.0, "avg_logprob": -0.08177504172691932, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002115558134391904}, {"id": 390, "seek": 275788, "start": 2764.84, "end": 2770.6800000000003, "text": " I think we all still struggle with. I think it's probably right. I mean, one of the things that", "tokens": [50712, 286, 519, 321, 439, 920, 7799, 365, 13, 286, 519, 309, 311, 1391, 558, 13, 286, 914, 11, 472, 295, 264, 721, 300, 51004], "temperature": 0.0, "avg_logprob": -0.08177504172691932, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002115558134391904}, {"id": 391, "seek": 275788, "start": 2770.6800000000003, "end": 2779.6400000000003, "text": " seemed to me from my reading of the book is the central role that Gardner thought that the", "tokens": [51004, 6576, 281, 385, 490, 452, 3760, 295, 264, 1446, 307, 264, 5777, 3090, 300, 12882, 1193, 1194, 300, 264, 51452], "temperature": 0.0, "avg_logprob": -0.08177504172691932, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002115558134391904}, {"id": 392, "seek": 275788, "start": 2779.6400000000003, "end": 2786.12, "text": " scientific community played. And again, it goes back to that kind of social role that we are", "tokens": [51452, 8134, 1768, 3737, 13, 400, 797, 11, 309, 1709, 646, 281, 300, 733, 295, 2093, 3090, 300, 321, 366, 51776], "temperature": 0.0, "avg_logprob": -0.08177504172691932, "compression_ratio": 1.6403508771929824, "no_speech_prob": 0.002115558134391904}, {"id": 393, "seek": 278612, "start": 2786.92, "end": 2796.52, "text": " social people and that we learn from each other. And usually, he says the crank is someone who's", "tokens": [50404, 2093, 561, 293, 300, 321, 1466, 490, 1184, 661, 13, 400, 2673, 11, 415, 1619, 264, 21263, 307, 1580, 567, 311, 50884], "temperature": 0.0, "avg_logprob": -0.10631639510393143, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0015244839014485478}, {"id": 394, "seek": 278612, "start": 2796.52, "end": 2803.7999999999997, "text": " almost always outside the scientific community. They don't have colleagues to bounce the ideas off", "tokens": [50884, 1920, 1009, 2380, 264, 8134, 1768, 13, 814, 500, 380, 362, 7734, 281, 15894, 264, 3487, 766, 51248], "temperature": 0.0, "avg_logprob": -0.10631639510393143, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0015244839014485478}, {"id": 395, "seek": 278612, "start": 2803.7999999999997, "end": 2808.68, "text": " and not going to conferences, listening to other people's papers. They're not presenting their", "tokens": [51248, 293, 406, 516, 281, 22032, 11, 4764, 281, 661, 561, 311, 10577, 13, 814, 434, 406, 15578, 641, 51492], "temperature": 0.0, "avg_logprob": -0.10631639510393143, "compression_ratio": 1.5183246073298429, "no_speech_prob": 0.0015244839014485478}, {"id": 396, "seek": 280868, "start": 2808.68, "end": 2818.44, "text": " papers for peer review or for comment by other people. And as a result, it's easy to get off", "tokens": [50364, 10577, 337, 15108, 3131, 420, 337, 2871, 538, 661, 561, 13, 400, 382, 257, 1874, 11, 309, 311, 1858, 281, 483, 766, 50852], "temperature": 0.0, "avg_logprob": -0.08631843566894531, "compression_ratio": 1.4122137404580153, "no_speech_prob": 0.012816332280635834}, {"id": 397, "seek": 280868, "start": 2818.44, "end": 2825.7999999999997, "text": " the rails because there's no one to say you're off the rails. Right. And they get these cult", "tokens": [50852, 264, 27649, 570, 456, 311, 572, 472, 281, 584, 291, 434, 766, 264, 27649, 13, 1779, 13, 400, 436, 483, 613, 2376, 51220], "temperature": 0.0, "avg_logprob": -0.08631843566894531, "compression_ratio": 1.4122137404580153, "no_speech_prob": 0.012816332280635834}, {"id": 398, "seek": 282580, "start": 2825.88, "end": 2838.1200000000003, "text": " followings where they get reinforced, you know, people people are believing them. And he said that", "tokens": [50368, 1524, 1109, 689, 436, 483, 31365, 11, 291, 458, 11, 561, 561, 366, 16594, 552, 13, 400, 415, 848, 300, 50980], "temperature": 0.0, "avg_logprob": -0.17022264199178727, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.018259724602103233}, {"id": 399, "seek": 282580, "start": 2838.1200000000003, "end": 2848.84, "text": " there are really a couple of signifiers for a crank is one of them is that person stands entirely", "tokens": [50980, 456, 366, 534, 257, 1916, 295, 1465, 23463, 337, 257, 21263, 307, 472, 295, 552, 307, 300, 954, 7382, 7696, 51516], "temperature": 0.0, "avg_logprob": -0.17022264199178727, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.018259724602103233}, {"id": 400, "seek": 282580, "start": 2848.84, "end": 2855.0800000000004, "text": " outside the closely integrated channels through which new ideas are introduced and evaluated.", "tokens": [51516, 2380, 264, 8185, 10919, 9235, 807, 597, 777, 3487, 366, 7268, 293, 25509, 13, 51828], "temperature": 0.0, "avg_logprob": -0.17022264199178727, "compression_ratio": 1.5591397849462365, "no_speech_prob": 0.018259724602103233}, {"id": 401, "seek": 285580, "start": 2855.8, "end": 2864.1200000000003, "text": " And secondly, as a tendency to paranoia. But I think one of the things that people may say", "tokens": [50364, 400, 26246, 11, 382, 257, 18187, 281, 31416, 654, 13, 583, 286, 519, 472, 295, 264, 721, 300, 561, 815, 584, 50780], "temperature": 0.0, "avg_logprob": -0.10927879810333252, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0005975290550850332}, {"id": 402, "seek": 285580, "start": 2864.1200000000003, "end": 2872.28, "text": " is, well, the scientific community is not that perfect. That maybe some of the grants and the", "tokens": [50780, 307, 11, 731, 11, 264, 8134, 1768, 307, 406, 300, 2176, 13, 663, 1310, 512, 295, 264, 16101, 293, 264, 51188], "temperature": 0.0, "avg_logprob": -0.10927879810333252, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0005975290550850332}, {"id": 403, "seek": 285580, "start": 2872.28, "end": 2879.88, "text": " money that comes from them are twisting the dogma in ways that favor the people who are funding", "tokens": [51188, 1460, 300, 1487, 490, 552, 366, 34491, 264, 3000, 1696, 294, 2098, 300, 2294, 264, 561, 567, 366, 6137, 51568], "temperature": 0.0, "avg_logprob": -0.10927879810333252, "compression_ratio": 1.5555555555555556, "no_speech_prob": 0.0005975290550850332}, {"id": 404, "seek": 287988, "start": 2879.88, "end": 2886.6, "text": " studies and so forth. And therefore, can we really trust dogma that's coming out of a scientific", "tokens": [50364, 5313, 293, 370, 5220, 13, 400, 4412, 11, 393, 321, 534, 3361, 3000, 1696, 300, 311, 1348, 484, 295, 257, 8134, 50700], "temperature": 0.0, "avg_logprob": -0.11645910786647423, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.004133023787289858}, {"id": 405, "seek": 287988, "start": 2886.6, "end": 2901.56, "text": " community that is not as pure science as we would wish it to be. Sure. And science is done by humans,", "tokens": [50700, 1768, 300, 307, 406, 382, 6075, 3497, 382, 321, 576, 3172, 309, 281, 312, 13, 4894, 13, 400, 3497, 307, 1096, 538, 6255, 11, 51448], "temperature": 0.0, "avg_logprob": -0.11645910786647423, "compression_ratio": 1.4142857142857144, "no_speech_prob": 0.004133023787289858}, {"id": 406, "seek": 290156, "start": 2901.56, "end": 2907.0, "text": " right. And humans have their own prejudices and biases and", "tokens": [50364, 558, 13, 400, 6255, 362, 641, 1065, 23121, 1473, 293, 32152, 293, 50636], "temperature": 0.0, "avg_logprob": -0.14067492485046387, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.05416153743863106}, {"id": 407, "seek": 290156, "start": 2909.0, "end": 2914.68, "text": " influences. And it's just a human endeavor. But what we do have in science is we have", "tokens": [50736, 21222, 13, 400, 309, 311, 445, 257, 1952, 34975, 13, 583, 437, 321, 360, 362, 294, 3497, 307, 321, 362, 51020], "temperature": 0.0, "avg_logprob": -0.14067492485046387, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.05416153743863106}, {"id": 408, "seek": 290156, "start": 2915.7999999999997, "end": 2923.16, "text": " replication, we have, you know, community sort of think things are wrong all the time. But", "tokens": [51076, 39911, 11, 321, 362, 11, 291, 458, 11, 1768, 1333, 295, 519, 721, 366, 2085, 439, 264, 565, 13, 583, 51444], "temperature": 0.0, "avg_logprob": -0.14067492485046387, "compression_ratio": 1.4873417721518987, "no_speech_prob": 0.05416153743863106}, {"id": 409, "seek": 292316, "start": 2923.16, "end": 2931.48, "text": " eventually, people discover that they're wrong. We have kind of this notion of consensus.", "tokens": [50364, 4728, 11, 561, 4411, 300, 436, 434, 2085, 13, 492, 362, 733, 295, 341, 10710, 295, 19115, 13, 50780], "temperature": 0.0, "avg_logprob": -0.18151871632721464, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.016909299418330193}, {"id": 410, "seek": 292316, "start": 2932.2, "end": 2937.3199999999997, "text": " There's certain things that are consensus, eventually, in the scientific community. And", "tokens": [50816, 821, 311, 1629, 721, 300, 366, 19115, 11, 4728, 11, 294, 264, 8134, 1768, 13, 400, 51072], "temperature": 0.0, "avg_logprob": -0.18151871632721464, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.016909299418330193}, {"id": 411, "seek": 292316, "start": 2938.2799999999997, "end": 2945.56, "text": " that those consensus, the consensus believe can eventually be overturned. But it's,", "tokens": [51120, 300, 729, 19115, 11, 264, 19115, 1697, 393, 4728, 312, 42865, 292, 13, 583, 309, 311, 11, 51484], "temperature": 0.0, "avg_logprob": -0.18151871632721464, "compression_ratio": 1.5914634146341464, "no_speech_prob": 0.016909299418330193}, {"id": 412, "seek": 294556, "start": 2946.2799999999997, "end": 2958.2799999999997, "text": " it's, it is a community. And I think, you know, it has, I don't know how to say this,", "tokens": [50400, 309, 311, 11, 309, 307, 257, 1768, 13, 400, 286, 519, 11, 291, 458, 11, 309, 575, 11, 286, 500, 380, 458, 577, 281, 584, 341, 11, 51000], "temperature": 0.0, "avg_logprob": -0.1736094826146176, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0028889707755297422}, {"id": 413, "seek": 294556, "start": 2960.92, "end": 2966.6, "text": " why should we trust scientists as opposed to anyone else? It's because I think scientists", "tokens": [51132, 983, 820, 321, 3361, 7708, 382, 8851, 281, 2878, 1646, 30, 467, 311, 570, 286, 519, 7708, 51416], "temperature": 0.0, "avg_logprob": -0.1736094826146176, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0028889707755297422}, {"id": 414, "seek": 294556, "start": 2968.12, "end": 2974.2799999999997, "text": " are, I mean, part of the deal of being a scientist is that you're always trying to disprove your own", "tokens": [51492, 366, 11, 286, 914, 11, 644, 295, 264, 2028, 295, 885, 257, 12662, 307, 300, 291, 434, 1009, 1382, 281, 717, 46955, 428, 1065, 51800], "temperature": 0.0, "avg_logprob": -0.1736094826146176, "compression_ratio": 1.5248618784530388, "no_speech_prob": 0.0028889707755297422}, {"id": 415, "seek": 297428, "start": 2974.28, "end": 2981.88, "text": " work. And you try as hard as you can. And that's the fundamental thing. You always are trying to be", "tokens": [50364, 589, 13, 400, 291, 853, 382, 1152, 382, 291, 393, 13, 400, 300, 311, 264, 8088, 551, 13, 509, 1009, 366, 1382, 281, 312, 50744], "temperature": 0.0, "avg_logprob": -0.11926205304204202, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.007575050462037325}, {"id": 416, "seek": 297428, "start": 2981.88, "end": 2988.76, "text": " skeptical of everything in your own work. And if you pound on it and pound on it and people", "tokens": [50744, 28601, 295, 1203, 294, 428, 1065, 589, 13, 400, 498, 291, 12013, 322, 309, 293, 12013, 322, 309, 293, 561, 51088], "temperature": 0.0, "avg_logprob": -0.11926205304204202, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.007575050462037325}, {"id": 417, "seek": 297428, "start": 2988.76, "end": 2994.28, "text": " replicate it and replicate it, finally you come to as close as you can to what you might call", "tokens": [51088, 25356, 309, 293, 25356, 309, 11, 2721, 291, 808, 281, 382, 1998, 382, 291, 393, 281, 437, 291, 1062, 818, 51364], "temperature": 0.0, "avg_logprob": -0.11926205304204202, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.007575050462037325}, {"id": 418, "seek": 297428, "start": 2994.28, "end": 3002.36, "text": " verification. So yeah, I mean, it's perfect for sure. That's a very good description. I mean,", "tokens": [51364, 30206, 13, 407, 1338, 11, 286, 914, 11, 309, 311, 2176, 337, 988, 13, 663, 311, 257, 588, 665, 3855, 13, 286, 914, 11, 51768], "temperature": 0.0, "avg_logprob": -0.11926205304204202, "compression_ratio": 1.7072072072072073, "no_speech_prob": 0.007575050462037325}, {"id": 419, "seek": 300236, "start": 3003.32, "end": 3010.36, "text": " I think in terms of sciences, also it creates a cultural, cultural aspect of thinking,", "tokens": [50412, 286, 519, 294, 2115, 295, 17677, 11, 611, 309, 7829, 257, 6988, 11, 6988, 4171, 295, 1953, 11, 50764], "temperature": 0.0, "avg_logprob": -0.10172194526309059, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0013456116430461407}, {"id": 420, "seek": 300236, "start": 3011.08, "end": 3017.48, "text": " where scientists tend to be comfortable with uncertainty, at least more comfortable than", "tokens": [50800, 689, 7708, 3928, 281, 312, 4619, 365, 15697, 11, 412, 1935, 544, 4619, 813, 51120], "temperature": 0.0, "avg_logprob": -0.10172194526309059, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0013456116430461407}, {"id": 421, "seek": 300236, "start": 3017.48, "end": 3024.52, "text": " most people, because they understand that even the existing dogma is a tentative position.", "tokens": [51120, 881, 561, 11, 570, 436, 1223, 300, 754, 264, 6741, 3000, 1696, 307, 257, 7054, 1166, 2535, 13, 51472], "temperature": 0.0, "avg_logprob": -0.10172194526309059, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0013456116430461407}, {"id": 422, "seek": 300236, "start": 3024.52, "end": 3031.32, "text": " It's not yet disproved. There will be flaws in it, in that every time someone thinks they've come", "tokens": [51472, 467, 311, 406, 1939, 717, 4318, 937, 13, 821, 486, 312, 27108, 294, 309, 11, 294, 300, 633, 565, 1580, 7309, 436, 600, 808, 51812], "temperature": 0.0, "avg_logprob": -0.10172194526309059, "compression_ratio": 1.60352422907489, "no_speech_prob": 0.0013456116430461407}, {"id": 423, "seek": 303132, "start": 3031.32, "end": 3039.0, "text": " up with an absolute answer, they've usually found out that that's not the case. And so there is more", "tokens": [50364, 493, 365, 364, 8236, 1867, 11, 436, 600, 2673, 1352, 484, 300, 300, 311, 406, 264, 1389, 13, 400, 370, 456, 307, 544, 50748], "temperature": 0.0, "avg_logprob": -0.10377668998610805, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.0014100694097578526}, {"id": 424, "seek": 303132, "start": 3039.0, "end": 3047.48, "text": " of a humility. I mean, you have some big eagles in science, as you would expect. But the idea is", "tokens": [50748, 295, 257, 27106, 13, 286, 914, 11, 291, 362, 512, 955, 308, 33300, 294, 3497, 11, 382, 291, 576, 2066, 13, 583, 264, 1558, 307, 51172], "temperature": 0.0, "avg_logprob": -0.10377668998610805, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.0014100694097578526}, {"id": 425, "seek": 303132, "start": 3047.48, "end": 3056.92, "text": " to be humble in the face of new changing information that requires constant revaluation", "tokens": [51172, 281, 312, 16735, 294, 264, 1851, 295, 777, 4473, 1589, 300, 7029, 5754, 319, 46504, 51644], "temperature": 0.0, "avg_logprob": -0.10377668998610805, "compression_ratio": 1.507936507936508, "no_speech_prob": 0.0014100694097578526}, {"id": 426, "seek": 305692, "start": 3057.08, "end": 3065.2400000000002, "text": " and updating, where the people who are the cranks have the absolute truth. There is no updating", "tokens": [50372, 293, 25113, 11, 689, 264, 561, 567, 366, 264, 941, 14592, 362, 264, 8236, 3494, 13, 821, 307, 572, 25113, 50780], "temperature": 0.0, "avg_logprob": -0.09416433693706125, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06460875272750854}, {"id": 427, "seek": 305692, "start": 3065.2400000000002, "end": 3072.6, "text": " that is needed. It's all defense of the existing structure. The structure is perfect,", "tokens": [50780, 300, 307, 2978, 13, 467, 311, 439, 7654, 295, 264, 6741, 3877, 13, 440, 3877, 307, 2176, 11, 51148], "temperature": 0.0, "avg_logprob": -0.09416433693706125, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06460875272750854}, {"id": 428, "seek": 305692, "start": 3073.2400000000002, "end": 3081.48, "text": " it can't be improved upon, and you either believe this or you don't. You're either part of our", "tokens": [51180, 309, 393, 380, 312, 9689, 3564, 11, 293, 291, 2139, 1697, 341, 420, 291, 500, 380, 13, 509, 434, 2139, 644, 295, 527, 51592], "temperature": 0.0, "avg_logprob": -0.09416433693706125, "compression_ratio": 1.5862068965517242, "no_speech_prob": 0.06460875272750854}, {"id": 429, "seek": 308148, "start": 3081.48, "end": 3087.2400000000002, "text": " belief system or you're not. That, it seems to me, is very anti-scientific.", "tokens": [50364, 7107, 1185, 420, 291, 434, 406, 13, 663, 11, 309, 2544, 281, 385, 11, 307, 588, 6061, 12, 82, 5412, 1089, 13, 50652], "temperature": 0.0, "avg_logprob": -0.10979398999895368, "compression_ratio": 1.4011299435028248, "no_speech_prob": 0.0004877153842244297}, {"id": 430, "seek": 308148, "start": 3090.6, "end": 3097.4, "text": " So the book by Gardner, and his books have appeared on the list of other guests as well.", "tokens": [50820, 407, 264, 1446, 538, 12882, 1193, 11, 293, 702, 3642, 362, 8516, 322, 264, 1329, 295, 661, 9804, 382, 731, 13, 51160], "temperature": 0.0, "avg_logprob": -0.10979398999895368, "compression_ratio": 1.4011299435028248, "no_speech_prob": 0.0004877153842244297}, {"id": 431, "seek": 308148, "start": 3097.4, "end": 3104.04, "text": " He's someone who's had, I think, a profound influence in terms of educating a whole", "tokens": [51160, 634, 311, 1580, 567, 311, 632, 11, 286, 519, 11, 257, 14382, 6503, 294, 2115, 295, 28835, 257, 1379, 51492], "temperature": 0.0, "avg_logprob": -0.10979398999895368, "compression_ratio": 1.4011299435028248, "no_speech_prob": 0.0004877153842244297}, {"id": 432, "seek": 310404, "start": 3105.0, "end": 3111.72, "text": " couple of generations of thinkers and mathematicians and physicists and artists and others who", "tokens": [50412, 1916, 295, 10593, 295, 37895, 293, 32811, 2567, 293, 48716, 293, 6910, 293, 2357, 567, 50748], "temperature": 0.0, "avg_logprob": -0.10104265400007659, "compression_ratio": 1.6178343949044587, "no_speech_prob": 0.006190858315676451}, {"id": 433, "seek": 310404, "start": 3112.7599999999998, "end": 3119.4, "text": " want to look deeply at those kinds of ways of thinking and processing reality.", "tokens": [50800, 528, 281, 574, 8760, 412, 729, 3685, 295, 2098, 295, 1953, 293, 9007, 4103, 13, 51132], "temperature": 0.0, "avg_logprob": -0.10104265400007659, "compression_ratio": 1.6178343949044587, "no_speech_prob": 0.006190858315676451}, {"id": 434, "seek": 310404, "start": 3120.12, "end": 3126.36, "text": " And science is just a different way of processing reality through investigation,", "tokens": [51168, 400, 3497, 307, 445, 257, 819, 636, 295, 9007, 4103, 807, 9627, 11, 51480], "temperature": 0.0, "avg_logprob": -0.10104265400007659, "compression_ratio": 1.6178343949044587, "no_speech_prob": 0.006190858315676451}, {"id": 435, "seek": 312636, "start": 3126.36, "end": 3134.6800000000003, "text": " observation, testing, reevaluation, and understanding that no matter what the result", "tokens": [50364, 14816, 11, 4997, 11, 43060, 46504, 11, 293, 3701, 300, 572, 1871, 437, 264, 1874, 50780], "temperature": 0.0, "avg_logprob": -0.08585241862705775, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024720309302210808}, {"id": 436, "seek": 312636, "start": 3134.6800000000003, "end": 3140.44, "text": " appears to show today, it may be overturned in the next week.", "tokens": [50780, 7038, 281, 855, 965, 11, 309, 815, 312, 42865, 292, 294, 264, 958, 1243, 13, 51068], "temperature": 0.0, "avg_logprob": -0.08585241862705775, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024720309302210808}, {"id": 437, "seek": 312636, "start": 3142.44, "end": 3149.0, "text": " I think one other thing you can say about Martin Gardner is that he was an incredible", "tokens": [51168, 286, 519, 472, 661, 551, 291, 393, 584, 466, 9184, 12882, 1193, 307, 300, 415, 390, 364, 4651, 51496], "temperature": 0.0, "avg_logprob": -0.08585241862705775, "compression_ratio": 1.4777070063694266, "no_speech_prob": 0.0024720309302210808}, {"id": 438, "seek": 314900, "start": 3149.56, "end": 3160.6, "text": " expositor of science and math, and kind of was a model for me, myself, of trying to write", "tokens": [50392, 1278, 9598, 284, 295, 3497, 293, 5221, 11, 293, 733, 295, 390, 257, 2316, 337, 385, 11, 2059, 11, 295, 1382, 281, 2464, 50944], "temperature": 0.0, "avg_logprob": -0.1861522370490475, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.010646548122167587}, {"id": 439, "seek": 314900, "start": 3160.6, "end": 3166.6, "text": " for the general public about science. How do you make things clear? How do you make things", "tokens": [50944, 337, 264, 2674, 1908, 466, 3497, 13, 1012, 360, 291, 652, 721, 1850, 30, 1012, 360, 291, 652, 721, 51244], "temperature": 0.0, "avg_logprob": -0.1861522370490475, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.010646548122167587}, {"id": 440, "seek": 314900, "start": 3166.6, "end": 3174.28, "text": " entertaining? How do you make things accessible? I'm glad you mentioned that, because the reviews", "tokens": [51244, 20402, 30, 1012, 360, 291, 652, 721, 9515, 30, 286, 478, 5404, 291, 2835, 300, 11, 570, 264, 10229, 51628], "temperature": 0.0, "avg_logprob": -0.1861522370490475, "compression_ratio": 1.6449704142011834, "no_speech_prob": 0.010646548122167587}, {"id": 441, "seek": 317428, "start": 3174.28, "end": 3182.6800000000003, "text": " of your books, all point to the fact that you've done this with enormous success, is to be able to", "tokens": [50364, 295, 428, 3642, 11, 439, 935, 281, 264, 1186, 300, 291, 600, 1096, 341, 365, 11322, 2245, 11, 307, 281, 312, 1075, 281, 50784], "temperature": 0.0, "avg_logprob": -0.10014470907358022, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0014776216121390462}, {"id": 442, "seek": 317428, "start": 3182.6800000000003, "end": 3191.4, "text": " use those metaphors and analogies to go from the very hard mathematical world of pure science", "tokens": [50784, 764, 729, 30946, 830, 293, 16660, 530, 281, 352, 490, 264, 588, 1152, 18894, 1002, 295, 6075, 3497, 51220], "temperature": 0.0, "avg_logprob": -0.10014470907358022, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0014776216121390462}, {"id": 443, "seek": 317428, "start": 3191.96, "end": 3198.76, "text": " into another language that most people can understand and relate to. That's a very", "tokens": [51248, 666, 1071, 2856, 300, 881, 561, 393, 1223, 293, 10961, 281, 13, 663, 311, 257, 588, 51588], "temperature": 0.0, "avg_logprob": -0.10014470907358022, "compression_ratio": 1.510989010989011, "no_speech_prob": 0.0014776216121390462}, {"id": 444, "seek": 319876, "start": 3198.76, "end": 3205.7200000000003, "text": " particular skill. It's a little bit like translation. Where I live, translation is a very", "tokens": [50364, 1729, 5389, 13, 467, 311, 257, 707, 857, 411, 12853, 13, 2305, 286, 1621, 11, 12853, 307, 257, 588, 50712], "temperature": 0.0, "avg_logprob": -0.1088936364472802, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.02515643835067749}, {"id": 445, "seek": 319876, "start": 3205.7200000000003, "end": 3214.92, "text": " important aspect of life, and you get people who are, say, bilingual, but as I say, there's a", "tokens": [50712, 1021, 4171, 295, 993, 11, 293, 291, 483, 561, 567, 366, 11, 584, 11, 48757, 11, 457, 382, 286, 584, 11, 456, 311, 257, 51172], "temperature": 0.0, "avg_logprob": -0.1088936364472802, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.02515643835067749}, {"id": 446, "seek": 319876, "start": 3214.92, "end": 3222.1200000000003, "text": " difference between being bilingual and bicultural. To know another language is not necessarily to", "tokens": [51172, 2649, 1296, 885, 48757, 293, 34472, 11056, 13, 1407, 458, 1071, 2856, 307, 406, 4725, 281, 51532], "temperature": 0.0, "avg_logprob": -0.1088936364472802, "compression_ratio": 1.5611111111111111, "no_speech_prob": 0.02515643835067749}, {"id": 447, "seek": 322212, "start": 3222.12, "end": 3230.2, "text": " know that culture. You are bilingual and bicultural, and that's a real advantage, and I think someone", "tokens": [50364, 458, 300, 3713, 13, 509, 366, 48757, 293, 34472, 11056, 11, 293, 300, 311, 257, 957, 5002, 11, 293, 286, 519, 1580, 50768], "temperature": 0.0, "avg_logprob": -0.10027123557196724, "compression_ratio": 1.465648854961832, "no_speech_prob": 0.01048376876860857}, {"id": 448, "seek": 322212, "start": 3230.2, "end": 3238.6, "text": " like Martin Gardner was like that as well, who understood both cultures and understood the", "tokens": [50768, 411, 9184, 12882, 1193, 390, 411, 300, 382, 731, 11, 567, 7320, 1293, 12951, 293, 7320, 264, 51188], "temperature": 0.0, "avg_logprob": -0.10027123557196724, "compression_ratio": 1.465648854961832, "no_speech_prob": 0.01048376876860857}, {"id": 449, "seek": 323860, "start": 3238.6, "end": 3242.92, "text": " language and the barriers of communication between those cultures.", "tokens": [50364, 2856, 293, 264, 13565, 295, 6101, 1296, 729, 12951, 13, 50580], "temperature": 0.0, "avg_logprob": -0.18673107840798117, "compression_ratio": 1.2542372881355932, "no_speech_prob": 0.014055862091481686}, {"id": 450, "seek": 323860, "start": 3251.4, "end": 3260.92, "text": " Just for the people watching, some of the chapters in this book by Martin Gardner", "tokens": [51004, 1449, 337, 264, 561, 1976, 11, 512, 295, 264, 20013, 294, 341, 1446, 538, 9184, 12882, 1193, 51480], "temperature": 0.0, "avg_logprob": -0.18673107840798117, "compression_ratio": 1.2542372881355932, "no_speech_prob": 0.014055862091481686}, {"id": 451, "seek": 326092, "start": 3260.92, "end": 3268.76, "text": " on fads and fallacies, he takes on the flat earth people, the hollow earth, I hadn't heard that one", "tokens": [50364, 322, 283, 5834, 293, 2100, 20330, 11, 415, 2516, 322, 264, 4962, 4120, 561, 11, 264, 23972, 4120, 11, 286, 8782, 380, 2198, 300, 472, 50756], "temperature": 0.0, "avg_logprob": -0.14446609108536332, "compression_ratio": 1.4113475177304964, "no_speech_prob": 0.22781755030155182}, {"id": 452, "seek": 326092, "start": 3268.76, "end": 3281.64, "text": " before, monsters of doom, flying saucers, down with Einstein, dousing rods and doodle bugs, geology", "tokens": [50756, 949, 11, 15785, 295, 37131, 11, 7137, 49181, 433, 11, 760, 365, 23486, 11, 274, 24220, 32761, 293, 360, 30013, 15120, 11, 48788, 51400], "temperature": 0.0, "avg_logprob": -0.14446609108536332, "compression_ratio": 1.4113475177304964, "no_speech_prob": 0.22781755030155182}, {"id": 453, "seek": 328164, "start": 3281.64, "end": 3292.52, "text": " versus Genesis, Atlantis, the Great Pyramids, medical cults, from homeopathy to natural", "tokens": [50364, 5717, 20587, 11, 11000, 37952, 11, 264, 3769, 9953, 2356, 3742, 11, 4625, 2376, 82, 11, 490, 1280, 404, 9527, 281, 3303, 50908], "temperature": 0.0, "avg_logprob": -0.2442677064375444, "compression_ratio": 1.3381294964028776, "no_speech_prob": 0.03459145128726959}, {"id": 454, "seek": 328164, "start": 3292.52, "end": 3304.7599999999998, "text": " apathy, and food fattice, so dynetics. He covers a fair range of the traditional kind of cult-like", "tokens": [50908, 1882, 9527, 11, 293, 1755, 283, 1591, 573, 11, 370, 274, 2534, 15793, 13, 634, 10538, 257, 3143, 3613, 295, 264, 5164, 733, 295, 2376, 12, 4092, 51520], "temperature": 0.0, "avg_logprob": -0.2442677064375444, "compression_ratio": 1.3381294964028776, "no_speech_prob": 0.03459145128726959}, {"id": 455, "seek": 330476, "start": 3305.48, "end": 3311.7200000000003, "text": " absolutists, fad friends that a lot of people were attracted to.", "tokens": [50400, 18757, 1751, 11, 283, 345, 1855, 300, 257, 688, 295, 561, 645, 15912, 281, 13, 50712], "temperature": 0.0, "avg_logprob": -0.2014838457107544, "compression_ratio": 1.4821428571428572, "no_speech_prob": 0.016144976019859314}, {"id": 456, "seek": 330476, "start": 3313.48, "end": 3321.4, "text": " Still are, in some cases. It still are, and as a result, maybe this is a book that has to be", "tokens": [50800, 8291, 366, 11, 294, 512, 3331, 13, 467, 920, 366, 11, 293, 382, 257, 1874, 11, 1310, 341, 307, 257, 1446, 300, 575, 281, 312, 51196], "temperature": 0.0, "avg_logprob": -0.2014838457107544, "compression_ratio": 1.4821428571428572, "no_speech_prob": 0.016144976019859314}, {"id": 457, "seek": 330476, "start": 3322.2000000000003, "end": 3332.44, "text": " updated for modern times, because social media now is the main vehicle through the internet", "tokens": [51236, 10588, 337, 4363, 1413, 11, 570, 2093, 3021, 586, 307, 264, 2135, 5864, 807, 264, 4705, 51748], "temperature": 0.0, "avg_logprob": -0.2014838457107544, "compression_ratio": 1.4821428571428572, "no_speech_prob": 0.016144976019859314}, {"id": 458, "seek": 333244, "start": 3333.16, "end": 3342.2000000000003, "text": " of being able to create these kinds of pseudoscientific communities which they talk to each other and", "tokens": [50400, 295, 885, 1075, 281, 1884, 613, 3685, 295, 25505, 35063, 5412, 1089, 4456, 597, 436, 751, 281, 1184, 661, 293, 50852], "temperature": 0.0, "avg_logprob": -0.10970278942223752, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.0017539572436362505}, {"id": 459, "seek": 333244, "start": 3342.2000000000003, "end": 3349.08, "text": " reinforce each other, but they're reinforcing basically a highly flawed, mistaken view of", "tokens": [50852, 22634, 1184, 661, 11, 457, 436, 434, 48262, 1936, 257, 5405, 38823, 11, 21333, 1910, 295, 51196], "temperature": 0.0, "avg_logprob": -0.10970278942223752, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.0017539572436362505}, {"id": 460, "seek": 333244, "start": 3349.08, "end": 3357.08, "text": " reality. So the question is, how do you reach them? Martin Gardner's book reached you and probably", "tokens": [51196, 4103, 13, 407, 264, 1168, 307, 11, 577, 360, 291, 2524, 552, 30, 9184, 12882, 1193, 311, 1446, 6488, 291, 293, 1391, 51596], "temperature": 0.0, "avg_logprob": -0.10970278942223752, "compression_ratio": 1.4871794871794872, "no_speech_prob": 0.0017539572436362505}, {"id": 461, "seek": 335708, "start": 3357.08, "end": 3362.84, "text": " reached a lot of people of your generation, but the question is, for the new generation,", "tokens": [50364, 6488, 257, 688, 295, 561, 295, 428, 5125, 11, 457, 264, 1168, 307, 11, 337, 264, 777, 5125, 11, 50652], "temperature": 0.0, "avg_logprob": -0.08833742803997463, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.00490271532908082}, {"id": 462, "seek": 335708, "start": 3364.04, "end": 3372.7599999999998, "text": " it will this book be one that will allow them to have a different window on social media once", "tokens": [50712, 309, 486, 341, 1446, 312, 472, 300, 486, 2089, 552, 281, 362, 257, 819, 4910, 322, 2093, 3021, 1564, 51148], "temperature": 0.0, "avg_logprob": -0.08833742803997463, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.00490271532908082}, {"id": 463, "seek": 335708, "start": 3372.7599999999998, "end": 3380.2, "text": " they've read it? Yeah, I don't know, I don't know if books are even relevant anymore for a lot of", "tokens": [51148, 436, 600, 1401, 309, 30, 865, 11, 286, 500, 380, 458, 11, 286, 500, 380, 458, 498, 3642, 366, 754, 7340, 3602, 337, 257, 688, 295, 51520], "temperature": 0.0, "avg_logprob": -0.08833742803997463, "compression_ratio": 1.5819209039548023, "no_speech_prob": 0.00490271532908082}, {"id": 464, "seek": 338020, "start": 3380.2, "end": 3388.04, "text": " people. Well, this is becoming an issue, and it's part of the reason for the show,", "tokens": [50364, 561, 13, 1042, 11, 341, 307, 5617, 364, 2734, 11, 293, 309, 311, 644, 295, 264, 1778, 337, 264, 855, 11, 50756], "temperature": 0.0, "avg_logprob": -0.11843137338127889, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.011323116719722748}, {"id": 465, "seek": 338020, "start": 3388.9199999999996, "end": 3397.56, "text": " is to show the relevance of books. They've been very relevant in your life. I mean, so far when", "tokens": [50800, 307, 281, 855, 264, 32684, 295, 3642, 13, 814, 600, 668, 588, 7340, 294, 428, 993, 13, 286, 914, 11, 370, 1400, 562, 51232], "temperature": 0.0, "avg_logprob": -0.11843137338127889, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.011323116719722748}, {"id": 466, "seek": 338020, "start": 3397.56, "end": 3406.7599999999998, "text": " the books that we've gone through, we've seen the Professor Mitchell emerge as a mathematician,", "tokens": [51232, 264, 3642, 300, 321, 600, 2780, 807, 11, 321, 600, 1612, 264, 8419, 27582, 21511, 382, 257, 48281, 11, 51692], "temperature": 0.0, "avg_logprob": -0.11843137338127889, "compression_ratio": 1.4972677595628416, "no_speech_prob": 0.011323116719722748}, {"id": 467, "seek": 340676, "start": 3407.7200000000003, "end": 3414.0400000000004, "text": " as a physicist, and as a computer science, artificial intelligence person,", "tokens": [50412, 382, 257, 42466, 11, 293, 382, 257, 3820, 3497, 11, 11677, 7599, 954, 11, 50728], "temperature": 0.0, "avg_logprob": -0.1456885645466466, "compression_ratio": 1.6832298136645962, "no_speech_prob": 0.003271718742325902}, {"id": 468, "seek": 340676, "start": 3415.1600000000003, "end": 3421.2400000000002, "text": " that part of that process, I'm certain it's far more complex, and of course complexity is another", "tokens": [50784, 300, 644, 295, 300, 1399, 11, 286, 478, 1629, 309, 311, 1400, 544, 3997, 11, 293, 295, 1164, 14024, 307, 1071, 51088], "temperature": 0.0, "avg_logprob": -0.1456885645466466, "compression_ratio": 1.6832298136645962, "no_speech_prob": 0.003271718742325902}, {"id": 469, "seek": 340676, "start": 3421.2400000000002, "end": 3429.48, "text": " one of your areas, more complex than just childhood reading, but childhood reading is part of that", "tokens": [51088, 472, 295, 428, 3179, 11, 544, 3997, 813, 445, 9278, 3760, 11, 457, 9278, 3760, 307, 644, 295, 300, 51500], "temperature": 0.0, "avg_logprob": -0.1456885645466466, "compression_ratio": 1.6832298136645962, "no_speech_prob": 0.003271718742325902}, {"id": 470, "seek": 342948, "start": 3429.56, "end": 3438.84, "text": " nonlinear interplay of factors that have made you construct a model of reality that has served you", "tokens": [50368, 2107, 28263, 728, 2858, 295, 6771, 300, 362, 1027, 291, 7690, 257, 2316, 295, 4103, 300, 575, 7584, 291, 50832], "temperature": 0.0, "avg_logprob": -0.08526868679944206, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.003883132478222251}, {"id": 471, "seek": 342948, "start": 3438.84, "end": 3447.88, "text": " very well. So the idea is, when people say books are not relevant, I think they're missing a very", "tokens": [50832, 588, 731, 13, 407, 264, 1558, 307, 11, 562, 561, 584, 3642, 366, 406, 7340, 11, 286, 519, 436, 434, 5361, 257, 588, 51284], "temperature": 0.0, "avg_logprob": -0.08526868679944206, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.003883132478222251}, {"id": 472, "seek": 342948, "start": 3447.88, "end": 3454.2, "text": " key important role in how they're relevant and why they're relevant at a particular age.", "tokens": [51284, 2141, 1021, 3090, 294, 577, 436, 434, 7340, 293, 983, 436, 434, 7340, 412, 257, 1729, 3205, 13, 51600], "temperature": 0.0, "avg_logprob": -0.08526868679944206, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.003883132478222251}, {"id": 473, "seek": 345420, "start": 3455.08, "end": 3461.08, "text": " Right. I mean, I was saying that facetiously, of course, but the young people I know today", "tokens": [50408, 1779, 13, 286, 914, 11, 286, 390, 1566, 300, 1915, 302, 8994, 11, 295, 1164, 11, 457, 264, 2037, 561, 286, 458, 965, 50708], "temperature": 0.0, "avg_logprob": -0.12142403920491536, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00940859317779541}, {"id": 474, "seek": 345420, "start": 3461.08, "end": 3469.72, "text": " are tend to read a lot less or fewer books than I did as a child. They're reading things on the", "tokens": [50708, 366, 3928, 281, 1401, 257, 688, 1570, 420, 13366, 3642, 813, 286, 630, 382, 257, 1440, 13, 814, 434, 3760, 721, 322, 264, 51140], "temperature": 0.0, "avg_logprob": -0.12142403920491536, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00940859317779541}, {"id": 475, "seek": 345420, "start": 3469.72, "end": 3478.04, "text": " internet, as you say. We didn't have a choice. We only had books. Correct. So you're probably", "tokens": [51140, 4705, 11, 382, 291, 584, 13, 492, 994, 380, 362, 257, 3922, 13, 492, 787, 632, 3642, 13, 12753, 13, 407, 291, 434, 1391, 51556], "temperature": 0.0, "avg_logprob": -0.12142403920491536, "compression_ratio": 1.4583333333333333, "no_speech_prob": 0.00940859317779541}, {"id": 476, "seek": 347804, "start": 3478.04, "end": 3484.44, "text": " finding this then in your students? My students, oh yeah, my students, my own children,", "tokens": [50364, 5006, 341, 550, 294, 428, 1731, 30, 1222, 1731, 11, 1954, 1338, 11, 452, 1731, 11, 452, 1065, 2227, 11, 50684], "temperature": 0.0, "avg_logprob": -0.16511830223931206, "compression_ratio": 1.4076923076923078, "no_speech_prob": 0.03306304290890694}, {"id": 477, "seek": 347804, "start": 3486.52, "end": 3498.2799999999997, "text": " they just have so many different options for media that books are not number one on their list,", "tokens": [50788, 436, 445, 362, 370, 867, 819, 3956, 337, 3021, 300, 3642, 366, 406, 1230, 472, 322, 641, 1329, 11, 51376], "temperature": 0.0, "avg_logprob": -0.16511830223931206, "compression_ratio": 1.4076923076923078, "no_speech_prob": 0.03306304290890694}, {"id": 478, "seek": 349828, "start": 3498.28, "end": 3508.44, "text": " I think, the way they were for me. Which is too bad. Yeah. Well, let's hope that this interview,", "tokens": [50364, 286, 519, 11, 264, 636, 436, 645, 337, 385, 13, 3013, 307, 886, 1578, 13, 865, 13, 1042, 11, 718, 311, 1454, 300, 341, 4049, 11, 50872], "temperature": 0.0, "avg_logprob": -0.15392222771277794, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.06274987012147903}, {"id": 479, "seek": 349828, "start": 3508.44, "end": 3517.5600000000004, "text": " this conversation, will inspire young people to say, I want to be like Melanie. I would love", "tokens": [50872, 341, 3761, 11, 486, 15638, 2037, 561, 281, 584, 11, 286, 528, 281, 312, 411, 42798, 13, 286, 576, 959, 51328], "temperature": 0.0, "avg_logprob": -0.15392222771277794, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.06274987012147903}, {"id": 480, "seek": 349828, "start": 3517.5600000000004, "end": 3525.48, "text": " to be able to follow that career path. And here, if it worked for her, maybe this will be the kind", "tokens": [51328, 281, 312, 1075, 281, 1524, 300, 3988, 3100, 13, 400, 510, 11, 498, 309, 2732, 337, 720, 11, 1310, 341, 486, 312, 264, 733, 51724], "temperature": 0.0, "avg_logprob": -0.15392222771277794, "compression_ratio": 1.4922279792746114, "no_speech_prob": 0.06274987012147903}, {"id": 481, "seek": 352548, "start": 3525.56, "end": 3534.52, "text": " of fine tuning that will help sculpt my own mind in a similar direction. That's the goal. We'll see.", "tokens": [50368, 295, 2489, 15164, 300, 486, 854, 12613, 452, 1065, 1575, 294, 257, 2531, 3513, 13, 663, 311, 264, 3387, 13, 492, 603, 536, 13, 50816], "temperature": 0.0, "avg_logprob": -0.14448143454159007, "compression_ratio": 1.2281879194630871, "no_speech_prob": 0.005217852536588907}, {"id": 482, "seek": 352548, "start": 3537.8, "end": 3550.68, "text": " The next book is One, Two, Three, Infinity by George Gamov, which came out in 1947", "tokens": [50980, 440, 958, 1446, 307, 1485, 11, 4453, 11, 6244, 11, 34762, 538, 7136, 24723, 5179, 11, 597, 1361, 484, 294, 40417, 51624], "temperature": 0.0, "avg_logprob": -0.14448143454159007, "compression_ratio": 1.2281879194630871, "no_speech_prob": 0.005217852536588907}, {"id": 483, "seek": 355068, "start": 3551.56, "end": 3557.08, "text": " and explores the fundamental concepts of mathematics and science.", "tokens": [50408, 293, 45473, 264, 8088, 10392, 295, 18666, 293, 3497, 13, 50684], "temperature": 0.0, "avg_logprob": -0.17554088592529296, "compression_ratio": 1.3691275167785235, "no_speech_prob": 0.0021152268163859844}, {"id": 484, "seek": 355068, "start": 3560.68, "end": 3564.2, "text": " Tell us a little bit about your initial reading of the book.", "tokens": [50864, 5115, 505, 257, 707, 857, 466, 428, 5883, 3760, 295, 264, 1446, 13, 51040], "temperature": 0.0, "avg_logprob": -0.17554088592529296, "compression_ratio": 1.3691275167785235, "no_speech_prob": 0.0021152268163859844}, {"id": 485, "seek": 355068, "start": 3566.2, "end": 3574.6, "text": " Yeah, so this one I read in college. Okay. And I was thinking about all these", "tokens": [51140, 865, 11, 370, 341, 472, 286, 1401, 294, 3859, 13, 1033, 13, 400, 286, 390, 1953, 466, 439, 613, 51560], "temperature": 0.0, "avg_logprob": -0.17554088592529296, "compression_ratio": 1.3691275167785235, "no_speech_prob": 0.0021152268163859844}, {"id": 486, "seek": 357460, "start": 3575.56, "end": 3582.2799999999997, "text": " fundamental ideas, you know, fascinated to read all of this stuff. I remember", "tokens": [50412, 8088, 3487, 11, 291, 458, 11, 24597, 281, 1401, 439, 295, 341, 1507, 13, 286, 1604, 50748], "temperature": 0.0, "avg_logprob": -0.1579089472370763, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.0021155329886823893}, {"id": 487, "seek": 357460, "start": 3583.24, "end": 3591.08, "text": " being very impressed and influenced by it, although I don't totally remember all the content of the", "tokens": [50796, 885, 588, 11679, 293, 15269, 538, 309, 11, 4878, 286, 500, 380, 3879, 1604, 439, 264, 2701, 295, 264, 51188], "temperature": 0.0, "avg_logprob": -0.1579089472370763, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.0021155329886823893}, {"id": 488, "seek": 357460, "start": 3591.08, "end": 3600.8399999999997, "text": " book. But I do remember it was very fundamental ideas, especially in mathematics. There are two", "tokens": [51188, 1446, 13, 583, 286, 360, 1604, 309, 390, 588, 8088, 3487, 11, 2318, 294, 18666, 13, 821, 366, 732, 51676], "temperature": 0.0, "avg_logprob": -0.1579089472370763, "compression_ratio": 1.5337078651685394, "no_speech_prob": 0.0021155329886823893}, {"id": 489, "seek": 360084, "start": 3600.92, "end": 3609.7200000000003, "text": " points in my research of the book that now make me think it had an influence on you is one,", "tokens": [50368, 2793, 294, 452, 2132, 295, 264, 1446, 300, 586, 652, 385, 519, 309, 632, 364, 6503, 322, 291, 307, 472, 11, 50808], "temperature": 0.0, "avg_logprob": -0.09303373098373413, "compression_ratio": 1.543956043956044, "no_speech_prob": 0.003375560976564884}, {"id": 490, "seek": 360084, "start": 3609.7200000000003, "end": 3616.6000000000004, "text": " it's noted for its quirky sense of humor. That seems to be something that's a thread through", "tokens": [50808, 309, 311, 12964, 337, 1080, 49515, 2020, 295, 14318, 13, 663, 2544, 281, 312, 746, 300, 311, 257, 7207, 807, 51152], "temperature": 0.0, "avg_logprob": -0.09303373098373413, "compression_ratio": 1.543956043956044, "no_speech_prob": 0.003375560976564884}, {"id": 491, "seek": 360084, "start": 3616.6000000000004, "end": 3623.2400000000002, "text": " all the books that we've looked at so far. And secondly, it's noted for its memorable metaphors.", "tokens": [51152, 439, 264, 3642, 300, 321, 600, 2956, 412, 370, 1400, 13, 400, 26246, 11, 309, 311, 12964, 337, 1080, 20723, 30946, 830, 13, 51484], "temperature": 0.0, "avg_logprob": -0.09303373098373413, "compression_ratio": 1.543956043956044, "no_speech_prob": 0.003375560976564884}, {"id": 492, "seek": 362324, "start": 3624.2, "end": 3630.2, "text": " Again, again, something that is a thread through all the books that you've chosen", "tokens": [50412, 3764, 11, 797, 11, 746, 300, 307, 257, 7207, 807, 439, 264, 3642, 300, 291, 600, 8614, 50712], "temperature": 0.0, "avg_logprob": -0.12727935592849532, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.005818069446831942}, {"id": 493, "seek": 362324, "start": 3630.9199999999996, "end": 3636.6, "text": " that influenced you as a child. So you were growing up probably without realizing it,", "tokens": [50748, 300, 15269, 291, 382, 257, 1440, 13, 407, 291, 645, 4194, 493, 1391, 1553, 16734, 309, 11, 51032], "temperature": 0.0, "avg_logprob": -0.12727935592849532, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.005818069446831942}, {"id": 494, "seek": 362324, "start": 3636.6, "end": 3642.9199999999996, "text": " that you were having a master class with some of the best mentors on the planet,", "tokens": [51032, 300, 291, 645, 1419, 257, 4505, 1508, 365, 512, 295, 264, 1151, 21798, 322, 264, 5054, 11, 51348], "temperature": 0.0, "avg_logprob": -0.12727935592849532, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.005818069446831942}, {"id": 495, "seek": 362324, "start": 3643.8799999999997, "end": 3652.2, "text": " teaching metaphorical thinking, and teaching humor and ways of entertaining to get people's", "tokens": [51396, 4571, 19157, 804, 1953, 11, 293, 4571, 14318, 293, 2098, 295, 20402, 281, 483, 561, 311, 51812], "temperature": 0.0, "avg_logprob": -0.12727935592849532, "compression_ratio": 1.6346153846153846, "no_speech_prob": 0.005818069446831942}, {"id": 496, "seek": 365220, "start": 3652.2, "end": 3659.72, "text": " attention and to explain sometimes very hard, difficult, abstract concepts like number theory,", "tokens": [50364, 3202, 293, 281, 2903, 2171, 588, 1152, 11, 2252, 11, 12649, 10392, 411, 1230, 5261, 11, 50740], "temperature": 0.0, "avg_logprob": -0.12038698588332085, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.0006770635372959077}, {"id": 497, "seek": 365220, "start": 3661.64, "end": 3664.4399999999996, "text": " which is done in this book.", "tokens": [50836, 597, 307, 1096, 294, 341, 1446, 13, 50976], "temperature": 0.0, "avg_logprob": -0.12038698588332085, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.0006770635372959077}, {"id": 498, "seek": 365220, "start": 3667.0, "end": 3674.52, "text": " Yes, absolutely. So I think a lot of these books, I kind of read them and almost,", "tokens": [51104, 1079, 11, 3122, 13, 407, 286, 519, 257, 688, 295, 613, 3642, 11, 286, 733, 295, 1401, 552, 293, 1920, 11, 51480], "temperature": 0.0, "avg_logprob": -0.12038698588332085, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.0006770635372959077}, {"id": 499, "seek": 365220, "start": 3675.16, "end": 3681.64, "text": " you know, the way that like a film student will analyze a film at a much more kind of", "tokens": [51512, 291, 458, 11, 264, 636, 300, 411, 257, 2007, 3107, 486, 12477, 257, 2007, 412, 257, 709, 544, 733, 295, 51836], "temperature": 0.0, "avg_logprob": -0.12038698588332085, "compression_ratio": 1.5025906735751295, "no_speech_prob": 0.0006770635372959077}, {"id": 500, "seek": 368220, "start": 3682.4399999999996, "end": 3688.2, "text": " like trying to figure out how did the director pull that off? How did they set up that scene?", "tokens": [50376, 411, 1382, 281, 2573, 484, 577, 630, 264, 5391, 2235, 300, 766, 30, 1012, 630, 436, 992, 493, 300, 4145, 30, 50664], "temperature": 0.0, "avg_logprob": -0.14411693744445114, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0010000114561989903}, {"id": 501, "seek": 368220, "start": 3689.08, "end": 3694.68, "text": " I was quite interested in how do you explain things to people? How do you explain these hard", "tokens": [50708, 286, 390, 1596, 3102, 294, 577, 360, 291, 2903, 721, 281, 561, 30, 1012, 360, 291, 2903, 613, 1152, 50988], "temperature": 0.0, "avg_logprob": -0.14411693744445114, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0010000114561989903}, {"id": 502, "seek": 368220, "start": 3694.68, "end": 3700.2, "text": " concepts? So I was looking at how are they doing this? How is George Gamoff actually", "tokens": [50988, 10392, 30, 407, 286, 390, 1237, 412, 577, 366, 436, 884, 341, 30, 1012, 307, 7136, 24723, 4506, 767, 51264], "temperature": 0.0, "avg_logprob": -0.14411693744445114, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0010000114561989903}, {"id": 503, "seek": 368220, "start": 3700.7599999999998, "end": 3710.4399999999996, "text": " pulling this off? It's true because I think it's a very insightful observation you've made,", "tokens": [51292, 8407, 341, 766, 30, 467, 311, 2074, 570, 286, 519, 309, 311, 257, 588, 46401, 14816, 291, 600, 1027, 11, 51776], "temperature": 0.0, "avg_logprob": -0.14411693744445114, "compression_ratio": 1.6425339366515836, "no_speech_prob": 0.0010000114561989903}, {"id": 504, "seek": 371044, "start": 3710.44, "end": 3717.32, "text": " because in a sense, books like this are a kind of performance art.", "tokens": [50364, 570, 294, 257, 2020, 11, 3642, 411, 341, 366, 257, 733, 295, 3389, 1523, 13, 50708], "temperature": 0.0, "avg_logprob": -0.1119457653590611, "compression_ratio": 1.4201183431952662, "no_speech_prob": 0.0005525742308236659}, {"id": 505, "seek": 371044, "start": 3719.2400000000002, "end": 3725.56, "text": " And if I look at the other people who have cited this book as foundational,", "tokens": [50804, 400, 498, 286, 574, 412, 264, 661, 561, 567, 362, 30134, 341, 1446, 382, 32195, 11, 51120], "temperature": 0.0, "avg_logprob": -0.1119457653590611, "compression_ratio": 1.4201183431952662, "no_speech_prob": 0.0005525742308236659}, {"id": 506, "seek": 371044, "start": 3726.2000000000003, "end": 3733.48, "text": " they are some of the great science communicators. For example, theoretical physicist Sean Carroll", "tokens": [51152, 436, 366, 512, 295, 264, 869, 3497, 3363, 3391, 13, 1171, 1365, 11, 20864, 42466, 14839, 48456, 51516], "temperature": 0.0, "avg_logprob": -0.1119457653590611, "compression_ratio": 1.4201183431952662, "no_speech_prob": 0.0005525742308236659}, {"id": 507, "seek": 373348, "start": 3734.44, "end": 3741.8, "text": " mentions this one, two, three, infinity as setting the trajectory of his professional life.", "tokens": [50412, 23844, 341, 472, 11, 732, 11, 1045, 11, 13202, 382, 3287, 264, 21512, 295, 702, 4843, 993, 13, 50780], "temperature": 0.0, "avg_logprob": -0.16797048905316522, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.009856652468442917}, {"id": 508, "seek": 373348, "start": 3744.12, "end": 3749.56, "text": " Cognitive scientist Stephen Pinker read the book as a child and cited as contributing to his", "tokens": [50896, 383, 2912, 2187, 12662, 13391, 17118, 260, 1401, 264, 1446, 382, 257, 1440, 293, 30134, 382, 19270, 281, 702, 51168], "temperature": 0.0, "avg_logprob": -0.16797048905316522, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.009856652468442917}, {"id": 509, "seek": 373348, "start": 3749.56, "end": 3758.6, "text": " interest in popular science. And astrophysicist Neil deGrasse Tyson has also cited this as one", "tokens": [51168, 1179, 294, 3743, 3497, 13, 400, 5357, 11741, 749, 299, 468, 18615, 368, 38, 3906, 405, 43382, 575, 611, 30134, 341, 382, 472, 51620], "temperature": 0.0, "avg_logprob": -0.16797048905316522, "compression_ratio": 1.4840425531914894, "no_speech_prob": 0.009856652468442917}, {"id": 510, "seek": 375860, "start": 3758.6, "end": 3767.3199999999997, "text": " of the greatest of two books that impact on his development, the other one being James Newman's", "tokens": [50364, 295, 264, 6636, 295, 732, 3642, 300, 2712, 322, 702, 3250, 11, 264, 661, 472, 885, 5678, 49377, 311, 50800], "temperature": 0.0, "avg_logprob": -0.08897238969802856, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0005883343401364982}, {"id": 511, "seek": 375860, "start": 3767.3199999999997, "end": 3776.2799999999997, "text": " Mathematics and Imagination. So here you have three other great scientific translators,", "tokens": [50800, 15776, 37541, 293, 34223, 2486, 13, 407, 510, 291, 362, 1045, 661, 869, 8134, 5105, 3391, 11, 51248], "temperature": 0.0, "avg_logprob": -0.08897238969802856, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0005883343401364982}, {"id": 512, "seek": 375860, "start": 3776.2799999999997, "end": 3786.2799999999997, "text": " communicators, masters of the metaphor who have had this book come into their life at the right time", "tokens": [51248, 3363, 3391, 11, 19294, 295, 264, 19157, 567, 362, 632, 341, 1446, 808, 666, 641, 993, 412, 264, 558, 565, 51748], "temperature": 0.0, "avg_logprob": -0.08897238969802856, "compression_ratio": 1.5026455026455026, "no_speech_prob": 0.0005883343401364982}, {"id": 513, "seek": 378628, "start": 3787.1600000000003, "end": 3795.8, "text": " to say beyond just metaphor and simile and analogy, you have to find ways to entertain people", "tokens": [50408, 281, 584, 4399, 445, 19157, 293, 1034, 794, 293, 21663, 11, 291, 362, 281, 915, 2098, 281, 7655, 561, 50840], "temperature": 0.0, "avg_logprob": -0.09404628864233044, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.0031231255270540714}, {"id": 514, "seek": 378628, "start": 3796.92, "end": 3805.6400000000003, "text": " and the entertainment is the way that most people learn. And if you're asking them to go back and do", "tokens": [50896, 293, 264, 12393, 307, 264, 636, 300, 881, 561, 1466, 13, 400, 498, 291, 434, 3365, 552, 281, 352, 646, 293, 360, 51332], "temperature": 0.0, "avg_logprob": -0.09404628864233044, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.0031231255270540714}, {"id": 515, "seek": 378628, "start": 3805.6400000000003, "end": 3811.1600000000003, "text": " all the foundational for the original abstracts and say of number theory, they're not going to follow", "tokens": [51332, 439, 264, 32195, 337, 264, 3380, 12649, 82, 293, 584, 295, 1230, 5261, 11, 436, 434, 406, 516, 281, 1524, 51608], "temperature": 0.0, "avg_logprob": -0.09404628864233044, "compression_ratio": 1.6174863387978142, "no_speech_prob": 0.0031231255270540714}, {"id": 516, "seek": 381116, "start": 3811.24, "end": 3817.72, "text": " you there, they're not going to go down that path. But if you can give them a watchdog,", "tokens": [50368, 291, 456, 11, 436, 434, 406, 516, 281, 352, 760, 300, 3100, 13, 583, 498, 291, 393, 976, 552, 257, 1159, 14833, 11, 50692], "temperature": 0.0, "avg_logprob": -0.10368143717447917, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.01081511564552784}, {"id": 517, "seek": 381116, "start": 3817.72, "end": 3825.64, "text": " a dog with a clock-like body, they're going to stay with you and follow you down the path", "tokens": [50692, 257, 3000, 365, 257, 7830, 12, 4092, 1772, 11, 436, 434, 516, 281, 1754, 365, 291, 293, 1524, 291, 760, 264, 3100, 51088], "temperature": 0.0, "avg_logprob": -0.10368143717447917, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.01081511564552784}, {"id": 518, "seek": 381116, "start": 3825.64, "end": 3835.16, "text": " because it is fun. Right. And I think George Gamoff also, he was Russian and he had that", "tokens": [51088, 570, 309, 307, 1019, 13, 1779, 13, 400, 286, 519, 7136, 24723, 4506, 611, 11, 415, 390, 7220, 293, 415, 632, 300, 51564], "temperature": 0.0, "avg_logprob": -0.10368143717447917, "compression_ratio": 1.4860335195530727, "no_speech_prob": 0.01081511564552784}, {"id": 519, "seek": 383516, "start": 3835.16, "end": 3841.96, "text": " kind of very dry wit that the Russian writers often have. I think that was something I really", "tokens": [50364, 733, 295, 588, 4016, 32161, 300, 264, 7220, 13491, 2049, 362, 13, 286, 519, 300, 390, 746, 286, 534, 50704], "temperature": 0.0, "avg_logprob": -0.14263077387734066, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.0003513757837936282}, {"id": 520, "seek": 383516, "start": 3841.96, "end": 3852.6, "text": " appreciated. So humor and metaphor from George Gamoff, one, two, three and infinity, a book", "tokens": [50704, 17169, 13, 407, 14318, 293, 19157, 490, 7136, 24723, 4506, 11, 472, 11, 732, 11, 1045, 293, 13202, 11, 257, 1446, 51236], "temperature": 0.0, "avg_logprob": -0.14263077387734066, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.0003513757837936282}, {"id": 521, "seek": 383516, "start": 3853.3199999999997, "end": 3860.92, "text": " which clearly has inspired you and some of the other very important scientific communicators", "tokens": [51272, 597, 4448, 575, 7547, 291, 293, 512, 295, 264, 661, 588, 1021, 8134, 3363, 3391, 51652], "temperature": 0.0, "avg_logprob": -0.14263077387734066, "compression_ratio": 1.4787234042553192, "no_speech_prob": 0.0003513757837936282}, {"id": 522, "seek": 386092, "start": 3860.92, "end": 3870.52, "text": " out there cite this book as well, which takes us to your next book, which is a book of essays by", "tokens": [50364, 484, 456, 37771, 341, 1446, 382, 731, 11, 597, 2516, 505, 281, 428, 958, 1446, 11, 597, 307, 257, 1446, 295, 35123, 538, 50844], "temperature": 0.0, "avg_logprob": -0.13481740390553193, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0018959848675876856}, {"id": 523, "seek": 386092, "start": 3870.52, "end": 3877.32, "text": " one of the world's foremost astronomers, Beyond the Observatory by Harlow Shapley,", "tokens": [50844, 472, 295, 264, 1002, 311, 18864, 43151, 11, 19707, 264, 42547, 4745, 538, 3653, 14107, 44160, 3420, 11, 51184], "temperature": 0.0, "avg_logprob": -0.13481740390553193, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0018959848675876856}, {"id": 524, "seek": 386092, "start": 3879.88, "end": 3888.04, "text": " which is essays on scientific achievements of the 20th century. And one of the things which I", "tokens": [51312, 597, 307, 35123, 322, 8134, 21420, 295, 264, 945, 392, 4901, 13, 400, 472, 295, 264, 721, 597, 286, 51720], "temperature": 0.0, "avg_logprob": -0.13481740390553193, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0018959848675876856}, {"id": 525, "seek": 388804, "start": 3888.04, "end": 3895.4, "text": " thought was kind of an interesting presentation, Breathing the Future in the Past. I don't know", "tokens": [50364, 1194, 390, 733, 295, 364, 1880, 5860, 11, 20093, 571, 264, 20805, 294, 264, 18408, 13, 286, 500, 380, 458, 50732], "temperature": 0.0, "avg_logprob": -0.11547304372318455, "compression_ratio": 1.4152046783625731, "no_speech_prob": 0.0026308740489184856}, {"id": 526, "seek": 388804, "start": 3895.4, "end": 3901.8, "text": " if you recall that essay or not, but it was showing how your breath contains more than", "tokens": [50732, 498, 291, 9901, 300, 16238, 420, 406, 11, 457, 309, 390, 4099, 577, 428, 6045, 8306, 544, 813, 51052], "temperature": 0.0, "avg_logprob": -0.11547304372318455, "compression_ratio": 1.4152046783625731, "no_speech_prob": 0.0026308740489184856}, {"id": 527, "seek": 388804, "start": 3902.44, "end": 3907.96, "text": " 400,000 Aragon atoms that Gandhi breathed in his long life.", "tokens": [51084, 8423, 11, 1360, 316, 25997, 16871, 300, 34717, 6045, 292, 294, 702, 938, 993, 13, 51360], "temperature": 0.0, "avg_logprob": -0.11547304372318455, "compression_ratio": 1.4152046783625731, "no_speech_prob": 0.0026308740489184856}, {"id": 528, "seek": 390796, "start": 3908.68, "end": 3921.7200000000003, "text": " Yeah, I do remember that. Bringing science again alive with an illustration here that makes it very vivid.", "tokens": [50400, 865, 11, 286, 360, 1604, 300, 13, 45241, 3497, 797, 5465, 365, 364, 22645, 510, 300, 1669, 309, 588, 23603, 13, 51052], "temperature": 0.0, "avg_logprob": -0.31611794841532803, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.04144133999943733}, {"id": 529, "seek": 390796, "start": 3924.44, "end": 3930.68, "text": " Yes. When did you come? Was this a high school college you came across? That was in college.", "tokens": [51188, 1079, 13, 1133, 630, 291, 808, 30, 3027, 341, 257, 1090, 1395, 3859, 291, 1361, 2108, 30, 663, 390, 294, 3859, 13, 51500], "temperature": 0.0, "avg_logprob": -0.31611794841532803, "compression_ratio": 1.3537414965986394, "no_speech_prob": 0.04144133999943733}, {"id": 530, "seek": 393068, "start": 3931.3999999999996, "end": 3938.7599999999998, "text": " During college, I became very interested in astronomy and started to actually do some research", "tokens": [50400, 6842, 3859, 11, 286, 3062, 588, 3102, 294, 37844, 293, 1409, 281, 767, 360, 512, 2132, 50768], "temperature": 0.0, "avg_logprob": -0.09339090377565414, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.014721313491463661}, {"id": 531, "seek": 393068, "start": 3938.7599999999998, "end": 3945.3199999999997, "text": " in astronomy. We had a small observatory that I got involved in sort of a group of students", "tokens": [50768, 294, 37844, 13, 492, 632, 257, 1359, 9951, 4745, 300, 286, 658, 3288, 294, 1333, 295, 257, 1594, 295, 1731, 51096], "temperature": 0.0, "avg_logprob": -0.09339090377565414, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.014721313491463661}, {"id": 532, "seek": 393068, "start": 3945.96, "end": 3954.04, "text": " who were doing independent research in astronomy. So I picked up this book and one essay that I", "tokens": [51128, 567, 645, 884, 6695, 2132, 294, 37844, 13, 407, 286, 6183, 493, 341, 1446, 293, 472, 16238, 300, 286, 51532], "temperature": 0.0, "avg_logprob": -0.09339090377565414, "compression_ratio": 1.5842696629213484, "no_speech_prob": 0.014721313491463661}, {"id": 533, "seek": 395404, "start": 3954.04, "end": 3964.44, "text": " remember really clearly was a discussion about how much you can infer from a sort of a single", "tokens": [50364, 1604, 534, 4448, 390, 257, 5017, 466, 577, 709, 291, 393, 13596, 490, 257, 1333, 295, 257, 2167, 50884], "temperature": 0.0, "avg_logprob": -0.1280030420381729, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.06365858763456345}, {"id": 534, "seek": 395404, "start": 3964.44, "end": 3970.44, "text": " pinpoint of light. You know, you're looking at a star. All you're getting is very, you know,", "tokens": [50884, 40837, 295, 1442, 13, 509, 458, 11, 291, 434, 1237, 412, 257, 3543, 13, 1057, 291, 434, 1242, 307, 588, 11, 291, 458, 11, 51184], "temperature": 0.0, "avg_logprob": -0.1280030420381729, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.06365858763456345}, {"id": 535, "seek": 395404, "start": 3971.16, "end": 3977.48, "text": " pinpoint of light. And then you can infer, like, what is the chemical makeup of the star? How old", "tokens": [51220, 40837, 295, 1442, 13, 400, 550, 291, 393, 13596, 11, 411, 11, 437, 307, 264, 7313, 6567, 295, 264, 3543, 30, 1012, 1331, 51536], "temperature": 0.0, "avg_logprob": -0.1280030420381729, "compression_ratio": 1.5519125683060109, "no_speech_prob": 0.06365858763456345}, {"id": 536, "seek": 397748, "start": 3977.48, "end": 3986.44, "text": " is it? Where it fits on the sort of spectrum of different kinds of stars? Is it you can infer? Is", "tokens": [50364, 307, 309, 30, 2305, 309, 9001, 322, 264, 1333, 295, 11143, 295, 819, 3685, 295, 6105, 30, 1119, 309, 291, 393, 13596, 30, 1119, 50812], "temperature": 0.0, "avg_logprob": -0.12281536729368445, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0044675725512206554}, {"id": 537, "seek": 397748, "start": 3986.44, "end": 3992.76, "text": " it orbiting another star? Is it going to explode? You know, all of these different things. It's just", "tokens": [50812, 309, 48985, 1071, 3543, 30, 1119, 309, 516, 281, 21411, 30, 509, 458, 11, 439, 295, 613, 819, 721, 13, 467, 311, 445, 51128], "temperature": 0.0, "avg_logprob": -0.12281536729368445, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0044675725512206554}, {"id": 538, "seek": 397748, "start": 3992.76, "end": 4004.36, "text": " astounding what astronomy can achieve with just this incredibly kind of, you know, seemingly very", "tokens": [51128, 5357, 24625, 437, 37844, 393, 4584, 365, 445, 341, 6252, 733, 295, 11, 291, 458, 11, 18709, 588, 51708], "temperature": 0.0, "avg_logprob": -0.12281536729368445, "compression_ratio": 1.549738219895288, "no_speech_prob": 0.0044675725512206554}, {"id": 539, "seek": 400436, "start": 4004.92, "end": 4008.76, "text": " limited amount of data. So I was very struck by that essay.", "tokens": [50392, 5567, 2372, 295, 1412, 13, 407, 286, 390, 588, 13159, 538, 300, 16238, 13, 50584], "temperature": 0.0, "avg_logprob": -0.09125678790243048, "compression_ratio": 1.679144385026738, "no_speech_prob": 0.0010646894806995988}, {"id": 540, "seek": 400436, "start": 4010.6800000000003, "end": 4018.6, "text": " Did you think of a career in astronomy? Yeah, I did think for a long time that I was going to", "tokens": [50680, 2589, 291, 519, 295, 257, 3988, 294, 37844, 30, 865, 11, 286, 630, 519, 337, 257, 938, 565, 300, 286, 390, 516, 281, 51076], "temperature": 0.0, "avg_logprob": -0.09125678790243048, "compression_ratio": 1.679144385026738, "no_speech_prob": 0.0010646894806995988}, {"id": 541, "seek": 400436, "start": 4019.88, "end": 4027.08, "text": " have a career in astronomy and I did several internships in astronomy labs", "tokens": [51140, 362, 257, 3988, 294, 37844, 293, 286, 630, 2940, 35712, 294, 37844, 20339, 51500], "temperature": 0.0, "avg_logprob": -0.09125678790243048, "compression_ratio": 1.679144385026738, "no_speech_prob": 0.0010646894806995988}, {"id": 542, "seek": 400436, "start": 4028.36, "end": 4033.2400000000002, "text": " and thought about going to graduate school in astronomy, but ended up not doing that.", "tokens": [51564, 293, 1194, 466, 516, 281, 8080, 1395, 294, 37844, 11, 457, 4590, 493, 406, 884, 300, 13, 51808], "temperature": 0.0, "avg_logprob": -0.09125678790243048, "compression_ratio": 1.679144385026738, "no_speech_prob": 0.0010646894806995988}, {"id": 543, "seek": 403436, "start": 4034.52, "end": 4042.76, "text": " Okay. So I guess maybe one of the lessons is that you can be intrigued and enthralled by a", "tokens": [50372, 1033, 13, 407, 286, 2041, 1310, 472, 295, 264, 8820, 307, 300, 291, 393, 312, 35140, 293, 948, 1703, 8907, 538, 257, 50784], "temperature": 0.0, "avg_logprob": -0.09591919725591486, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.00026526188594289124}, {"id": 544, "seek": 403436, "start": 4042.76, "end": 4049.96, "text": " particular book that leads you in a direction, but ultimately you decide that's not exactly", "tokens": [50784, 1729, 1446, 300, 6689, 291, 294, 257, 3513, 11, 457, 6284, 291, 4536, 300, 311, 406, 2293, 51144], "temperature": 0.0, "avg_logprob": -0.09591919725591486, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.00026526188594289124}, {"id": 545, "seek": 403436, "start": 4049.96, "end": 4054.28, "text": " the full direction of where you want to go. You learn from it and you learn something about", "tokens": [51144, 264, 1577, 3513, 295, 689, 291, 528, 281, 352, 13, 509, 1466, 490, 309, 293, 291, 1466, 746, 466, 51360], "temperature": 0.0, "avg_logprob": -0.09591919725591486, "compression_ratio": 1.5054945054945055, "no_speech_prob": 0.00026526188594289124}, {"id": 546, "seek": 405428, "start": 4054.28, "end": 4062.28, "text": " yourself from it and take on that knowledge, but get on with another career path.", "tokens": [50364, 1803, 490, 309, 293, 747, 322, 300, 3601, 11, 457, 483, 322, 365, 1071, 3988, 3100, 13, 50764], "temperature": 0.0, "avg_logprob": -0.1247965797545418, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.014061542227864265}, {"id": 547, "seek": 405428, "start": 4064.28, "end": 4070.1200000000003, "text": " Yes, life is full of twists and turns, of course, that you can't predict.", "tokens": [50864, 1079, 11, 993, 307, 1577, 295, 35290, 293, 4523, 11, 295, 1164, 11, 300, 291, 393, 380, 6069, 13, 51156], "temperature": 0.0, "avg_logprob": -0.1247965797545418, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.014061542227864265}, {"id": 548, "seek": 405428, "start": 4073.32, "end": 4079.8, "text": " The other essay, which kind of fits into some of the other books that we've discussed,", "tokens": [51316, 440, 661, 16238, 11, 597, 733, 295, 9001, 666, 512, 295, 264, 661, 3642, 300, 321, 600, 7152, 11, 51640], "temperature": 0.0, "avg_logprob": -0.1247965797545418, "compression_ratio": 1.475609756097561, "no_speech_prob": 0.014061542227864265}, {"id": 549, "seek": 407980, "start": 4080.44, "end": 4088.52, "text": " is the Science Outside the Lab, which was one of the essays there, again, which is back to the", "tokens": [50396, 307, 264, 8976, 28218, 264, 10137, 11, 597, 390, 472, 295, 264, 35123, 456, 11, 797, 11, 597, 307, 646, 281, 264, 50800], "temperature": 0.0, "avg_logprob": -0.14129667079195063, "compression_ratio": 1.443609022556391, "no_speech_prob": 0.001186974230222404}, {"id": 550, "seek": 407980, "start": 4088.52, "end": 4100.28, "text": " Einstein book that we discussed earlier, and that there is this kind of notion that science isn't", "tokens": [50800, 23486, 1446, 300, 321, 7152, 3071, 11, 293, 300, 456, 307, 341, 733, 295, 10710, 300, 3497, 1943, 380, 51388], "temperature": 0.0, "avg_logprob": -0.14129667079195063, "compression_ratio": 1.443609022556391, "no_speech_prob": 0.001186974230222404}, {"id": 551, "seek": 410028, "start": 4100.28, "end": 4111.88, "text": " just something that happens in the laboratory. Yeah, I mean, I don't remember that particular essay,", "tokens": [50364, 445, 746, 300, 2314, 294, 264, 16523, 13, 865, 11, 286, 914, 11, 286, 500, 380, 1604, 300, 1729, 16238, 11, 50944], "temperature": 0.0, "avg_logprob": -0.16514981311300528, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0072292727418243885}, {"id": 552, "seek": 410028, "start": 4113.48, "end": 4119.719999999999, "text": " but I assume he was talking about sort of what you see out in real life, I mean, what the kind", "tokens": [51024, 457, 286, 6552, 415, 390, 1417, 466, 1333, 295, 437, 291, 536, 484, 294, 957, 993, 11, 286, 914, 11, 437, 264, 733, 51336], "temperature": 0.0, "avg_logprob": -0.16514981311300528, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0072292727418243885}, {"id": 553, "seek": 410028, "start": 4119.719999999999, "end": 4125.88, "text": " of science takes place by observations that are outside of the lab, just like Einstein.", "tokens": [51336, 295, 3497, 2516, 1081, 538, 18163, 300, 366, 2380, 295, 264, 2715, 11, 445, 411, 23486, 13, 51644], "temperature": 0.0, "avg_logprob": -0.16514981311300528, "compression_ratio": 1.4973544973544974, "no_speech_prob": 0.0072292727418243885}, {"id": 554, "seek": 412588, "start": 4126.6, "end": 4134.36, "text": " Right, and again, what Shapley's book, from my understanding of these essays,", "tokens": [50400, 1779, 11, 293, 797, 11, 437, 44160, 3420, 311, 1446, 11, 490, 452, 3701, 295, 613, 35123, 11, 50788], "temperature": 0.0, "avg_logprob": -0.14677111307779947, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.000882754975464195}, {"id": 555, "seek": 412588, "start": 4134.36, "end": 4141.16, "text": " is it's looking at science in a broad way. It's looking at science, sociology, and philosophy as", "tokens": [50788, 307, 309, 311, 1237, 412, 3497, 294, 257, 4152, 636, 13, 467, 311, 1237, 412, 3497, 11, 41744, 11, 293, 10675, 382, 51128], "temperature": 0.0, "avg_logprob": -0.14677111307779947, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.000882754975464195}, {"id": 556, "seek": 412588, "start": 4141.16, "end": 4148.76, "text": " well. In other words, the broader context in which science exists. It's a culture within a larger", "tokens": [51128, 731, 13, 682, 661, 2283, 11, 264, 13227, 4319, 294, 597, 3497, 8198, 13, 467, 311, 257, 3713, 1951, 257, 4833, 51508], "temperature": 0.0, "avg_logprob": -0.14677111307779947, "compression_ratio": 1.5454545454545454, "no_speech_prob": 0.000882754975464195}, {"id": 557, "seek": 414876, "start": 4148.76, "end": 4157.96, "text": " culture, and you are one of the bridge builders that are crossing that moat where the scientists", "tokens": [50364, 3713, 11, 293, 291, 366, 472, 295, 264, 7283, 36281, 300, 366, 14712, 300, 705, 267, 689, 264, 7708, 50824], "temperature": 0.0, "avg_logprob": -0.14231075960047104, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.017700454220175743}, {"id": 558, "seek": 414876, "start": 4157.96, "end": 4165.0, "text": " are inside, talking to each other in a language which would be incomprehensible for most of us", "tokens": [50824, 366, 1854, 11, 1417, 281, 1184, 661, 294, 257, 2856, 597, 576, 312, 14036, 40128, 30633, 337, 881, 295, 505, 51176], "temperature": 0.0, "avg_logprob": -0.14231075960047104, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.017700454220175743}, {"id": 559, "seek": 414876, "start": 4165.0, "end": 4173.64, "text": " listening to ancient Greek. But you've mastered that language and can go over and say, this is what", "tokens": [51176, 4764, 281, 7832, 10281, 13, 583, 291, 600, 38686, 300, 2856, 293, 393, 352, 670, 293, 584, 11, 341, 307, 437, 51608], "temperature": 0.0, "avg_logprob": -0.14231075960047104, "compression_ratio": 1.547872340425532, "no_speech_prob": 0.017700454220175743}, {"id": 560, "seek": 417364, "start": 4173.64, "end": 4179.96, "text": " they're really talking about. This is what it really means. Here are some examples. Visualize this,", "tokens": [50364, 436, 434, 534, 1417, 466, 13, 639, 307, 437, 309, 534, 1355, 13, 1692, 366, 512, 5110, 13, 23187, 1125, 341, 11, 50680], "temperature": 0.0, "avg_logprob": -0.2118817450295032, "compression_ratio": 1.5, "no_speech_prob": 0.0025905671063810587}, {"id": 561, "seek": 417364, "start": 4179.96, "end": 4190.84, "text": " visualize that. Which talking and visualization takes us to Hind's Teeth, Horses Tolls by Stephen", "tokens": [50680, 23273, 300, 13, 3013, 1417, 293, 25801, 2516, 505, 281, 15307, 311, 1989, 3293, 11, 389, 830, 279, 1407, 43909, 538, 13391, 51224], "temperature": 0.0, "avg_logprob": -0.2118817450295032, "compression_ratio": 1.5, "no_speech_prob": 0.0025905671063810587}, {"id": 562, "seek": 417364, "start": 4190.84, "end": 4200.12, "text": " Gould, which, oh, wonderful writer, I'm getting waiting for my Smithsonian Institute magazine", "tokens": [51224, 460, 429, 11, 597, 11, 1954, 11, 3715, 9936, 11, 286, 478, 1242, 3806, 337, 452, 46013, 9446, 11332, 51688], "temperature": 0.0, "avg_logprob": -0.2118817450295032, "compression_ratio": 1.5, "no_speech_prob": 0.0025905671063810587}, {"id": 563, "seek": 420012, "start": 4200.12, "end": 4207.4, "text": " to arrive here in Bangkok back in the early 90s. And sometimes it wouldn't arrive because I must", "tokens": [50364, 281, 8881, 510, 294, 43055, 646, 294, 264, 2440, 4289, 82, 13, 400, 2171, 309, 2759, 380, 8881, 570, 286, 1633, 50728], "temperature": 0.0, "avg_logprob": -0.14374294946360033, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0007670812192372978}, {"id": 564, "seek": 420012, "start": 4207.4, "end": 4212.12, "text": " have been a postman who shared my interest, decided to keep it himself. But in any event,", "tokens": [50728, 362, 668, 257, 2183, 1601, 567, 5507, 452, 1179, 11, 3047, 281, 1066, 309, 3647, 13, 583, 294, 604, 2280, 11, 50964], "temperature": 0.0, "avg_logprob": -0.14374294946360033, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0007670812192372978}, {"id": 565, "seek": 420012, "start": 4213.24, "end": 4218.92, "text": " he had a wonderful mind. And tell us how this book came into your life.", "tokens": [51020, 415, 632, 257, 3715, 1575, 13, 400, 980, 505, 577, 341, 1446, 1361, 666, 428, 993, 13, 51304], "temperature": 0.0, "avg_logprob": -0.14374294946360033, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0007670812192372978}, {"id": 566, "seek": 420012, "start": 4223.4, "end": 4229.5599999999995, "text": " So when I was in college, one of my housemates was an evolutionary biology major.", "tokens": [51528, 407, 562, 286, 390, 294, 3859, 11, 472, 295, 452, 1782, 10977, 390, 364, 27567, 14956, 2563, 13, 51836], "temperature": 0.0, "avg_logprob": -0.14374294946360033, "compression_ratio": 1.4782608695652173, "no_speech_prob": 0.0007670812192372978}, {"id": 567, "seek": 423012, "start": 4230.84, "end": 4236.68, "text": " And he was telling me how I should learn something about this field because I knew nothing about it.", "tokens": [50400, 400, 415, 390, 3585, 385, 577, 286, 820, 1466, 746, 466, 341, 2519, 570, 286, 2586, 1825, 466, 309, 13, 50692], "temperature": 0.0, "avg_logprob": -0.09241287682646064, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.00043713804916478693}, {"id": 568, "seek": 423012, "start": 4236.68, "end": 4246.28, "text": " I'd never taken a biology class. So I tried to get into, there was a very popular course on", "tokens": [50692, 286, 1116, 1128, 2726, 257, 14956, 1508, 13, 407, 286, 3031, 281, 483, 666, 11, 456, 390, 257, 588, 3743, 1164, 322, 51172], "temperature": 0.0, "avg_logprob": -0.09241287682646064, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.00043713804916478693}, {"id": 569, "seek": 423012, "start": 4246.28, "end": 4251.8, "text": " evolutionary biology in my college, which I was unable to get into because it was so popular.", "tokens": [51172, 27567, 14956, 294, 452, 3859, 11, 597, 286, 390, 11299, 281, 483, 666, 570, 309, 390, 370, 3743, 13, 51448], "temperature": 0.0, "avg_logprob": -0.09241287682646064, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.00043713804916478693}, {"id": 570, "seek": 423012, "start": 4253.0, "end": 4259.64, "text": " So this housemate gave me this book, said, read this, this will teach you everything you need to", "tokens": [51508, 407, 341, 1782, 13963, 2729, 385, 341, 1446, 11, 848, 11, 1401, 341, 11, 341, 486, 2924, 291, 1203, 291, 643, 281, 51840], "temperature": 0.0, "avg_logprob": -0.09241287682646064, "compression_ratio": 1.6798245614035088, "no_speech_prob": 0.00043713804916478693}, {"id": 571, "seek": 425964, "start": 4259.64, "end": 4266.12, "text": " know about. And I had never heard of Stephen J. Gould. I didn't know anything about evolution.", "tokens": [50364, 458, 466, 13, 400, 286, 632, 1128, 2198, 295, 13391, 508, 13, 460, 429, 13, 286, 994, 380, 458, 1340, 466, 9303, 13, 50688], "temperature": 0.0, "avg_logprob": -0.17614647836396188, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0012837088434025645}, {"id": 572, "seek": 425964, "start": 4268.4400000000005, "end": 4274.76, "text": " So it was a real eye-opener. He's a fantastic writer, just like all of these books are", "tokens": [50804, 407, 309, 390, 257, 957, 3313, 12, 404, 7971, 13, 634, 311, 257, 5456, 9936, 11, 445, 411, 439, 295, 613, 3642, 366, 51120], "temperature": 0.0, "avg_logprob": -0.17614647836396188, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0012837088434025645}, {"id": 573, "seek": 425964, "start": 4276.52, "end": 4283.72, "text": " these master science expositors. And talking about some of these", "tokens": [51208, 613, 4505, 3497, 30076, 9862, 13, 400, 1417, 466, 512, 295, 613, 51568], "temperature": 0.0, "avg_logprob": -0.17614647836396188, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0012837088434025645}, {"id": 574, "seek": 428372, "start": 4284.68, "end": 4292.04, "text": " sort of really interesting questions that you would never have thought to ask about evolution.", "tokens": [50412, 1333, 295, 534, 1880, 1651, 300, 291, 576, 1128, 362, 1194, 281, 1029, 466, 9303, 13, 50780], "temperature": 0.0, "avg_logprob": -0.1799185105732509, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0010479845805093646}, {"id": 575, "seek": 428372, "start": 4292.92, "end": 4297.8, "text": " So this was my first introduction to a lot of these ideas.", "tokens": [50824, 407, 341, 390, 452, 700, 9339, 281, 257, 688, 295, 613, 3487, 13, 51068], "temperature": 0.0, "avg_logprob": -0.1799185105732509, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0010479845805093646}, {"id": 576, "seek": 428372, "start": 4300.2, "end": 4306.84, "text": " What would you think would have been the influence of the book on your own thinking and your own", "tokens": [51188, 708, 576, 291, 519, 576, 362, 668, 264, 6503, 295, 264, 1446, 322, 428, 1065, 1953, 293, 428, 1065, 51520], "temperature": 0.0, "avg_logprob": -0.1799185105732509, "compression_ratio": 1.5822784810126582, "no_speech_prob": 0.0010479845805093646}, {"id": 577, "seek": 430684, "start": 4306.92, "end": 4319.24, "text": " choices and career? Well, it sparked my interest in ideas of evolution, which then", "tokens": [50368, 7994, 293, 3988, 30, 1042, 11, 309, 39653, 452, 1179, 294, 3487, 295, 9303, 11, 597, 550, 50984], "temperature": 0.0, "avg_logprob": -0.11755105068809107, "compression_ratio": 1.296, "no_speech_prob": 0.008183133788406849}, {"id": 578, "seek": 430684, "start": 4321.8, "end": 4331.88, "text": " went a lot further, especially when I was in graduate school and encountered an", "tokens": [51112, 1437, 257, 688, 3052, 11, 2318, 562, 286, 390, 294, 8080, 1395, 293, 20381, 364, 51616], "temperature": 0.0, "avg_logprob": -0.11755105068809107, "compression_ratio": 1.296, "no_speech_prob": 0.008183133788406849}, {"id": 579, "seek": 433188, "start": 4331.88, "end": 4339.08, "text": " entire field called biologically inspired computation, an evolutionary computation,", "tokens": [50364, 2302, 2519, 1219, 3228, 17157, 7547, 24903, 11, 364, 27567, 24903, 11, 50724], "temperature": 0.0, "avg_logprob": -0.17114368237947164, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0004877914907410741}, {"id": 580, "seek": 433188, "start": 4339.72, "end": 4348.04, "text": " which merged ideas from evolution into computer science. And it's something that I got very deeply", "tokens": [50756, 597, 36427, 3487, 490, 9303, 666, 3820, 3497, 13, 400, 309, 311, 746, 300, 286, 658, 588, 8760, 51172], "temperature": 0.0, "avg_logprob": -0.17114368237947164, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0004877914907410741}, {"id": 581, "seek": 433188, "start": 4348.04, "end": 4357.8, "text": " involved with later on. So that's an interesting point because in some ways you're drawing an", "tokens": [51172, 3288, 365, 1780, 322, 13, 407, 300, 311, 364, 1880, 935, 570, 294, 512, 2098, 291, 434, 6316, 364, 51660], "temperature": 0.0, "avg_logprob": -0.17114368237947164, "compression_ratio": 1.5333333333333334, "no_speech_prob": 0.0004877914907410741}, {"id": 582, "seek": 435780, "start": 4357.88, "end": 4366.4400000000005, "text": " analogy from the evolutionary biology world of Stephen Gould into a quite different realm", "tokens": [50368, 21663, 490, 264, 27567, 14956, 1002, 295, 13391, 460, 429, 666, 257, 1596, 819, 15355, 50796], "temperature": 0.0, "avg_logprob": -0.11877780755360921, "compression_ratio": 1.461111111111111, "no_speech_prob": 0.0001465095701860264}, {"id": 583, "seek": 435780, "start": 4367.0, "end": 4375.08, "text": " and seeing that that perspective is transferable. Yes, exactly. That you can use,", "tokens": [50824, 293, 2577, 300, 300, 4585, 307, 5003, 712, 13, 1079, 11, 2293, 13, 663, 291, 393, 764, 11, 51228], "temperature": 0.0, "avg_logprob": -0.11877780755360921, "compression_ratio": 1.461111111111111, "no_speech_prob": 0.0001465095701860264}, {"id": 584, "seek": 435780, "start": 4375.96, "end": 4383.72, "text": " you could be inspired in a metaphorical way by ideas in one field and apply them into other", "tokens": [51272, 291, 727, 312, 7547, 294, 257, 19157, 804, 636, 538, 3487, 294, 472, 2519, 293, 3079, 552, 666, 661, 51660], "temperature": 0.0, "avg_logprob": -0.11877780755360921, "compression_ratio": 1.461111111111111, "no_speech_prob": 0.0001465095701860264}, {"id": 585, "seek": 438372, "start": 4383.72, "end": 4392.52, "text": " fields. And interestingly, that's exactly what happened with Darwin, who sort of came up with", "tokens": [50364, 7909, 13, 400, 25873, 11, 300, 311, 2293, 437, 2011, 365, 30233, 11, 567, 1333, 295, 1361, 493, 365, 50804], "temperature": 0.0, "avg_logprob": -0.09732034844411931, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0032711795065551996}, {"id": 586, "seek": 438372, "start": 4392.52, "end": 4399.96, "text": " a lot of these ideas. He was inspired by ideas from economics, from geology, and other fields,", "tokens": [50804, 257, 688, 295, 613, 3487, 13, 634, 390, 7547, 538, 3487, 490, 14564, 11, 490, 48788, 11, 293, 661, 7909, 11, 51176], "temperature": 0.0, "avg_logprob": -0.09732034844411931, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0032711795065551996}, {"id": 587, "seek": 438372, "start": 4399.96, "end": 4406.12, "text": " and he brought that into his own ideas about biology. So there's a lot of these cross-scientific", "tokens": [51176, 293, 415, 3038, 300, 666, 702, 1065, 3487, 466, 14956, 13, 407, 456, 311, 257, 688, 295, 613, 3278, 12, 82, 5412, 1089, 51484], "temperature": 0.0, "avg_logprob": -0.09732034844411931, "compression_ratio": 1.532258064516129, "no_speech_prob": 0.0032711795065551996}, {"id": 588, "seek": 440612, "start": 4406.12, "end": 4413.96, "text": " analogies going on. It's an excellent point because certainly with Darwin's generation,", "tokens": [50364, 16660, 530, 516, 322, 13, 467, 311, 364, 7103, 935, 570, 3297, 365, 30233, 311, 5125, 11, 50756], "temperature": 0.0, "avg_logprob": -0.11070023945399693, "compression_ratio": 1.515625, "no_speech_prob": 0.03113354928791523}, {"id": 589, "seek": 440612, "start": 4414.599999999999, "end": 4422.68, "text": " there would have been a far broader education. And maybe that's part of the problem we have with AI,", "tokens": [50788, 456, 576, 362, 668, 257, 1400, 13227, 3309, 13, 400, 1310, 300, 311, 644, 295, 264, 1154, 321, 362, 365, 7318, 11, 51192], "temperature": 0.0, "avg_logprob": -0.11070023945399693, "compression_ratio": 1.515625, "no_speech_prob": 0.03113354928791523}, {"id": 590, "seek": 440612, "start": 4422.68, "end": 4432.36, "text": " is that people are brilliant, but narrowly brilliant in very specific subdomains of subdomains. And so", "tokens": [51192, 307, 300, 561, 366, 10248, 11, 457, 9432, 356, 10248, 294, 588, 2685, 1422, 4121, 2315, 295, 1422, 4121, 2315, 13, 400, 370, 51676], "temperature": 0.0, "avg_logprob": -0.11070023945399693, "compression_ratio": 1.515625, "no_speech_prob": 0.03113354928791523}, {"id": 591, "seek": 443236, "start": 4432.44, "end": 4440.839999999999, "text": " as a result, there isn't the same kind of cross-fertilization of ideas. Like for example,", "tokens": [50368, 382, 257, 1874, 11, 456, 1943, 380, 264, 912, 733, 295, 3278, 12, 612, 20007, 2144, 295, 3487, 13, 1743, 337, 1365, 11, 50788], "temperature": 0.0, "avg_logprob": -0.08913206352907069, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00022689047909807414}, {"id": 592, "seek": 443236, "start": 4440.839999999999, "end": 4450.44, "text": " talking with someone who's coding an algorithm about empathy, there may not be an easy bridge", "tokens": [50788, 1417, 365, 1580, 567, 311, 17720, 364, 9284, 466, 18701, 11, 456, 815, 406, 312, 364, 1858, 7283, 51268], "temperature": 0.0, "avg_logprob": -0.08913206352907069, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00022689047909807414}, {"id": 593, "seek": 443236, "start": 4451.32, "end": 4457.32, "text": " with that coder and with those kinds of concepts simply because the background isn't there. They", "tokens": [51312, 365, 300, 17656, 260, 293, 365, 729, 3685, 295, 10392, 2935, 570, 264, 3678, 1943, 380, 456, 13, 814, 51612], "temperature": 0.0, "avg_logprob": -0.08913206352907069, "compression_ratio": 1.5217391304347827, "no_speech_prob": 0.00022689047909807414}, {"id": 594, "seek": 445732, "start": 4457.32, "end": 4466.5199999999995, "text": " haven't come across the Steven Gould model that what you do is you find someone who is able to", "tokens": [50364, 2378, 380, 808, 2108, 264, 12754, 460, 429, 2316, 300, 437, 291, 360, 307, 291, 915, 1580, 567, 307, 1075, 281, 50824], "temperature": 0.0, "avg_logprob": -0.11323868036270142, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0006262499373406172}, {"id": 595, "seek": 445732, "start": 4466.5199999999995, "end": 4472.84, "text": " explain something brilliantly and see, again, you drew the metaphor of what he's talking about", "tokens": [50824, 2903, 746, 8695, 42580, 293, 536, 11, 797, 11, 291, 12804, 264, 19157, 295, 437, 415, 311, 1417, 466, 51140], "temperature": 0.0, "avg_logprob": -0.11323868036270142, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0006262499373406172}, {"id": 596, "seek": 445732, "start": 4472.84, "end": 4479.48, "text": " into another realm. You transported that infrastructure, that framework of thinking,", "tokens": [51140, 666, 1071, 15355, 13, 509, 29373, 300, 6896, 11, 300, 8388, 295, 1953, 11, 51472], "temperature": 0.0, "avg_logprob": -0.11323868036270142, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0006262499373406172}, {"id": 597, "seek": 445732, "start": 4480.2, "end": 4486.2, "text": " and allowed you to see something quite different about computers that other people were not seeing.", "tokens": [51508, 293, 4350, 291, 281, 536, 746, 1596, 819, 466, 10807, 300, 661, 561, 645, 406, 2577, 13, 51808], "temperature": 0.0, "avg_logprob": -0.11323868036270142, "compression_ratio": 1.619047619047619, "no_speech_prob": 0.0006262499373406172}, {"id": 598, "seek": 448732, "start": 4488.12, "end": 4494.12, "text": " Well, yeah, I mean, I think I would say I was the one who came up with some of those analogies,", "tokens": [50404, 1042, 11, 1338, 11, 286, 914, 11, 286, 519, 286, 576, 584, 286, 390, 264, 472, 567, 1361, 493, 365, 512, 295, 729, 16660, 530, 11, 50704], "temperature": 0.0, "avg_logprob": -0.13764826456705728, "compression_ratio": 1.4818652849740932, "no_speech_prob": 0.000625994463916868}, {"id": 599, "seek": 448732, "start": 4494.12, "end": 4505.5599999999995, "text": " but some of my mentors did. Talking about mentors, let's move on to Goethe Escher and Bach by", "tokens": [50704, 457, 512, 295, 452, 21798, 630, 13, 22445, 466, 21798, 11, 718, 311, 1286, 322, 281, 1037, 302, 675, 2313, 6759, 293, 30920, 538, 51276], "temperature": 0.0, "avg_logprob": -0.13764826456705728, "compression_ratio": 1.4818652849740932, "no_speech_prob": 0.000625994463916868}, {"id": 600, "seek": 448732, "start": 4505.5599999999995, "end": 4513.639999999999, "text": " Douglas Hofstadter, who I know was your mentor and an important intellectual force in your life.", "tokens": [51276, 23010, 37379, 48299, 391, 11, 567, 286, 458, 390, 428, 14478, 293, 364, 1021, 12576, 3464, 294, 428, 993, 13, 51680], "temperature": 0.0, "avg_logprob": -0.13764826456705728, "compression_ratio": 1.4818652849740932, "no_speech_prob": 0.000625994463916868}, {"id": 601, "seek": 451364, "start": 4514.4400000000005, "end": 4523.4800000000005, "text": " This book in 1973 was a monumental work. I want to pull a surprise. It is still read and discussed", "tokens": [50404, 639, 1446, 294, 33530, 390, 257, 43105, 589, 13, 286, 528, 281, 2235, 257, 6365, 13, 467, 307, 920, 1401, 293, 7152, 50856], "temperature": 0.0, "avg_logprob": -0.12771594006082285, "compression_ratio": 1.2993197278911566, "no_speech_prob": 0.0015480974689126015}, {"id": 602, "seek": 451364, "start": 4523.4800000000005, "end": 4532.6, "text": " in the shape thinking of a couple generations since it was first published. So you must have", "tokens": [50856, 294, 264, 3909, 1953, 295, 257, 1916, 10593, 1670, 309, 390, 700, 6572, 13, 407, 291, 1633, 362, 51312], "temperature": 0.0, "avg_logprob": -0.12771594006082285, "compression_ratio": 1.2993197278911566, "no_speech_prob": 0.0015480974689126015}, {"id": 603, "seek": 453260, "start": 4532.6, "end": 4543.64, "text": " read this book before you decided to, this was going to be your thing. You were at university", "tokens": [50364, 1401, 341, 1446, 949, 291, 3047, 281, 11, 341, 390, 516, 281, 312, 428, 551, 13, 509, 645, 412, 5454, 50916], "temperature": 0.0, "avg_logprob": -0.13497412934595224, "compression_ratio": 1.380281690140845, "no_speech_prob": 0.012621637433767319}, {"id": 604, "seek": 453260, "start": 4543.64, "end": 4555.88, "text": " somewhere, you got the book, what happened next? So I read it the year after I graduated from college.", "tokens": [50916, 4079, 11, 291, 658, 264, 1446, 11, 437, 2011, 958, 30, 407, 286, 1401, 309, 264, 1064, 934, 286, 13693, 490, 3859, 13, 51528], "temperature": 0.0, "avg_logprob": -0.13497412934595224, "compression_ratio": 1.380281690140845, "no_speech_prob": 0.012621637433767319}, {"id": 605, "seek": 455588, "start": 4556.52, "end": 4563.24, "text": " Okay. I actually read about it, I read a review of it in Martin Gardner's column in Scientific", "tokens": [50396, 1033, 13, 286, 767, 1401, 466, 309, 11, 286, 1401, 257, 3131, 295, 309, 294, 9184, 12882, 1193, 311, 7738, 294, 47437, 50732], "temperature": 0.0, "avg_logprob": -0.12997238545478146, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.02368159405887127}, {"id": 606, "seek": 455588, "start": 4563.24, "end": 4569.400000000001, "text": " American, which is how I had heard about it in the first place. So I went out and bought it and", "tokens": [50732, 2665, 11, 597, 307, 577, 286, 632, 2198, 466, 309, 294, 264, 700, 1081, 13, 407, 286, 1437, 484, 293, 4243, 309, 293, 51040], "temperature": 0.0, "avg_logprob": -0.12997238545478146, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.02368159405887127}, {"id": 607, "seek": 455588, "start": 4571.32, "end": 4579.72, "text": " it's a very long book. It's not like a beach read, if you will. It takes a lot of thinking.", "tokens": [51136, 309, 311, 257, 588, 938, 1446, 13, 467, 311, 406, 411, 257, 7534, 1401, 11, 498, 291, 486, 13, 467, 2516, 257, 688, 295, 1953, 13, 51556], "temperature": 0.0, "avg_logprob": -0.12997238545478146, "compression_ratio": 1.461139896373057, "no_speech_prob": 0.02368159405887127}, {"id": 608, "seek": 457972, "start": 4580.68, "end": 4587.400000000001, "text": " So I read it over the course of many months and decided that this is what I want to work on.", "tokens": [50412, 407, 286, 1401, 309, 670, 264, 1164, 295, 867, 2493, 293, 3047, 300, 341, 307, 437, 286, 528, 281, 589, 322, 13, 50748], "temperature": 0.0, "avg_logprob": -0.12141577647282527, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0019870884716510773}, {"id": 609, "seek": 457972, "start": 4587.96, "end": 4595.72, "text": " And it's really a book about, it's about intelligence and how something like intelligence,", "tokens": [50776, 400, 309, 311, 534, 257, 1446, 466, 11, 309, 311, 466, 7599, 293, 577, 746, 411, 7599, 11, 51164], "temperature": 0.0, "avg_logprob": -0.12141577647282527, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0019870884716510773}, {"id": 610, "seek": 457972, "start": 4595.72, "end": 4603.320000000001, "text": " as complex as intelligence, can emerge from a non-intelligent substrate, how consciousness", "tokens": [51164, 382, 3997, 382, 7599, 11, 393, 21511, 490, 257, 2107, 12, 20761, 25002, 27585, 11, 577, 10081, 51544], "temperature": 0.0, "avg_logprob": -0.12141577647282527, "compression_ratio": 1.5568181818181819, "no_speech_prob": 0.0019870884716510773}, {"id": 611, "seek": 460332, "start": 4603.32, "end": 4609.32, "text": " might come about. And it uses ideas from mathematics, from music, from art,", "tokens": [50364, 1062, 808, 466, 13, 400, 309, 4960, 3487, 490, 18666, 11, 490, 1318, 11, 490, 1523, 11, 50664], "temperature": 0.0, "avg_logprob": -0.22166247367858888, "compression_ratio": 1.3416666666666666, "no_speech_prob": 0.00955325085669756}, {"id": 612, "seek": 460332, "start": 4610.04, "end": 4623.16, "text": " to kind of eliminate these core ideas. What was the connecting thread that Hofstadter", "tokens": [50700, 281, 733, 295, 13819, 613, 4965, 3487, 13, 708, 390, 264, 11015, 7207, 300, 37379, 48299, 391, 51356], "temperature": 0.0, "avg_logprob": -0.22166247367858888, "compression_ratio": 1.3416666666666666, "no_speech_prob": 0.00955325085669756}, {"id": 613, "seek": 462316, "start": 4623.16, "end": 4629.72, "text": " discovered that links together Goethe and Bach and Escher?", "tokens": [50364, 6941, 300, 6123, 1214, 1037, 302, 675, 293, 30920, 293, 2313, 6759, 30, 50692], "temperature": 0.0, "avg_logprob": -0.16936062984779232, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.005814112722873688}, {"id": 614, "seek": 462316, "start": 4633.0, "end": 4637.5599999999995, "text": " I say there are several connecting threads, but maybe one of them is this idea of self-reference", "tokens": [50856, 286, 584, 456, 366, 2940, 11015, 19314, 11, 457, 1310, 472, 295, 552, 307, 341, 1558, 295, 2698, 12, 265, 5158, 51084], "temperature": 0.0, "avg_logprob": -0.16936062984779232, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.005814112722873688}, {"id": 615, "seek": 462316, "start": 4638.68, "end": 4647.08, "text": " that is fundamental in Goethe's theorem, his mathematical theorem, because you can get mathematical", "tokens": [51140, 300, 307, 8088, 294, 1037, 302, 675, 311, 20904, 11, 702, 18894, 20904, 11, 570, 291, 393, 483, 18894, 51560], "temperature": 0.0, "avg_logprob": -0.16936062984779232, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.005814112722873688}, {"id": 616, "seek": 464708, "start": 4647.88, "end": 4657.32, "text": " systems to be talking about themselves, to be referring to themselves. And that shows up in", "tokens": [50404, 3652, 281, 312, 1417, 466, 2969, 11, 281, 312, 13761, 281, 2969, 13, 400, 300, 3110, 493, 294, 50876], "temperature": 0.0, "avg_logprob": -0.16393391054068038, "compression_ratio": 1.6, "no_speech_prob": 0.008692693896591663}, {"id": 617, "seek": 464708, "start": 4657.32, "end": 4664.28, "text": " Escher. You see all these kinds of strange kind of loopy references.", "tokens": [50876, 2313, 6759, 13, 509, 536, 439, 613, 3685, 295, 5861, 733, 295, 6367, 88, 15400, 13, 51224], "temperature": 0.0, "avg_logprob": -0.16393391054068038, "compression_ratio": 1.6, "no_speech_prob": 0.008692693896591663}, {"id": 618, "seek": 464708, "start": 4664.92, "end": 4672.44, "text": " The hand drawing the hand. Yeah, the hand drawing the hand and so on. And in Bach's music, too,", "tokens": [51256, 440, 1011, 6316, 264, 1011, 13, 865, 11, 264, 1011, 6316, 264, 1011, 293, 370, 322, 13, 400, 294, 30920, 311, 1318, 11, 886, 11, 51632], "temperature": 0.0, "avg_logprob": -0.16393391054068038, "compression_ratio": 1.6, "no_speech_prob": 0.008692693896591663}, {"id": 619, "seek": 467244, "start": 4672.44, "end": 4683.4, "text": " there's some examples that Hofstadter goes into in detail. And this is really the idea of", "tokens": [50364, 456, 311, 512, 5110, 300, 37379, 48299, 391, 1709, 666, 294, 2607, 13, 400, 341, 307, 534, 264, 1558, 295, 50912], "temperature": 0.0, "avg_logprob": -0.1685719747801085, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0007313914247788489}, {"id": 620, "seek": 467244, "start": 4683.4, "end": 4689.48, "text": " intelligence is a self-rential, what he calls a strange loop, the strange loop of consciousness,", "tokens": [50912, 7599, 307, 257, 2698, 12, 1753, 831, 11, 437, 415, 5498, 257, 5861, 6367, 11, 264, 5861, 6367, 295, 10081, 11, 51216], "temperature": 0.0, "avg_logprob": -0.1685719747801085, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0007313914247788489}, {"id": 621, "seek": 467244, "start": 4689.48, "end": 4696.679999999999, "text": " where we're able to reflect on our own thinking. A kind of recursion. A kind of recursion, exactly.", "tokens": [51216, 689, 321, 434, 1075, 281, 5031, 322, 527, 1065, 1953, 13, 316, 733, 295, 20560, 313, 13, 316, 733, 295, 20560, 313, 11, 2293, 13, 51576], "temperature": 0.0, "avg_logprob": -0.1685719747801085, "compression_ratio": 1.5888888888888888, "no_speech_prob": 0.0007313914247788489}, {"id": 622, "seek": 469668, "start": 4697.08, "end": 4707.88, "text": " That goes on. And kind of a meta-thinking as well. So that at each stage recursive part, I mean,", "tokens": [50384, 663, 1709, 322, 13, 400, 733, 295, 257, 19616, 12, 39873, 382, 731, 13, 407, 300, 412, 1184, 3233, 20560, 488, 644, 11, 286, 914, 11, 50924], "temperature": 0.0, "avg_logprob": -0.2375391909950658, "compression_ratio": 1.2945205479452055, "no_speech_prob": 0.003322529373690486}, {"id": 623, "seek": 469668, "start": 4707.88, "end": 4718.68, "text": " Bach's fugues, for example, there is a thing that reoccurs in them. From Nietzsche's eternal", "tokens": [50924, 30920, 311, 31838, 1247, 11, 337, 1365, 11, 456, 307, 257, 551, 300, 319, 43280, 2156, 294, 552, 13, 3358, 36583, 89, 12287, 311, 14503, 51464], "temperature": 0.0, "avg_logprob": -0.2375391909950658, "compression_ratio": 1.2945205479452055, "no_speech_prob": 0.003322529373690486}, {"id": 624, "seek": 471868, "start": 4718.68, "end": 4726.92, "text": " return. There are things that are patterns that show up against slightly altered, but recognizable.", "tokens": [50364, 2736, 13, 821, 366, 721, 300, 366, 8294, 300, 855, 493, 1970, 4748, 28783, 11, 457, 40757, 13, 50776], "temperature": 0.0, "avg_logprob": -0.19370691893530673, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.01081352774053812}, {"id": 625, "seek": 471868, "start": 4728.360000000001, "end": 4735.4800000000005, "text": " And that that that is the nature of intelligence, as we understand it.", "tokens": [50848, 400, 300, 300, 300, 307, 264, 3687, 295, 7599, 11, 382, 321, 1223, 309, 13, 51204], "temperature": 0.0, "avg_logprob": -0.19370691893530673, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.01081352774053812}, {"id": 626, "seek": 471868, "start": 4736.92, "end": 4744.4400000000005, "text": " Something like that. Yeah, I mean, it's a... Hofstadter's ideas are not", "tokens": [51276, 6595, 411, 300, 13, 865, 11, 286, 914, 11, 309, 311, 257, 485, 37379, 48299, 391, 311, 3487, 366, 406, 51652], "temperature": 0.0, "avg_logprob": -0.19370691893530673, "compression_ratio": 1.4319526627218935, "no_speech_prob": 0.01081352774053812}, {"id": 627, "seek": 474444, "start": 4745.4, "end": 4752.2, "text": " easily expressible in a short period of time. So, but that's kind of getting at the idea", "tokens": [50412, 3612, 5109, 964, 294, 257, 2099, 2896, 295, 565, 13, 407, 11, 457, 300, 311, 733, 295, 1242, 412, 264, 1558, 50752], "temperature": 0.0, "avg_logprob": -0.16027905284494592, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0005271636764518917}, {"id": 628, "seek": 474444, "start": 4752.2, "end": 4761.0, "text": " of this, what he calls this strange loop. Would you say that this, I mean, this is", "tokens": [50752, 295, 341, 11, 437, 415, 5498, 341, 5861, 6367, 13, 6068, 291, 584, 300, 341, 11, 286, 914, 11, 341, 307, 51192], "temperature": 0.0, "avg_logprob": -0.16027905284494592, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0005271636764518917}, {"id": 629, "seek": 474444, "start": 4761.0, "end": 4770.2, "text": " absolutely foundational book, that maybe it's at the outer edge of where you can use metaphor and", "tokens": [51192, 3122, 32195, 1446, 11, 300, 1310, 309, 311, 412, 264, 10847, 4691, 295, 689, 291, 393, 764, 19157, 293, 51652], "temperature": 0.0, "avg_logprob": -0.16027905284494592, "compression_ratio": 1.5112359550561798, "no_speech_prob": 0.0005271636764518917}, {"id": 630, "seek": 477020, "start": 4770.2, "end": 4778.2, "text": " summary with these abstractions to convey accurately what is being talked about.", "tokens": [50364, 12691, 365, 613, 12649, 626, 281, 16965, 20095, 437, 307, 885, 2825, 466, 13, 50764], "temperature": 0.0, "avg_logprob": -0.13247451782226563, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.0007434136350639164}, {"id": 631, "seek": 477020, "start": 4780.76, "end": 4786.76, "text": " Because a lot of people find this book very, very difficult. Yeah, it is difficult. But what's really", "tokens": [50892, 1436, 257, 688, 295, 561, 915, 341, 1446, 588, 11, 588, 2252, 13, 865, 11, 309, 307, 2252, 13, 583, 437, 311, 534, 51192], "temperature": 0.0, "avg_logprob": -0.13247451782226563, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.0007434136350639164}, {"id": 632, "seek": 477020, "start": 4786.76, "end": 4794.2, "text": " striking is how much Hofstadter comes up with amazing analogies and metaphors to talk about these", "tokens": [51192, 18559, 307, 577, 709, 37379, 48299, 391, 1487, 493, 365, 2243, 16660, 530, 293, 30946, 830, 281, 751, 466, 613, 51564], "temperature": 0.0, "avg_logprob": -0.13247451782226563, "compression_ratio": 1.5053763440860215, "no_speech_prob": 0.0007434136350639164}, {"id": 633, "seek": 479420, "start": 4794.2, "end": 4805.16, "text": " things. And that's really, turns out to be what he's most fascinated by is how we think in analogies", "tokens": [50364, 721, 13, 400, 300, 311, 534, 11, 4523, 484, 281, 312, 437, 415, 311, 881, 24597, 538, 307, 577, 321, 519, 294, 16660, 530, 50912], "temperature": 0.0, "avg_logprob": -0.11761371612548828, "compression_ratio": 1.3546099290780143, "no_speech_prob": 0.007341480348259211}, {"id": 634, "seek": 479420, "start": 4805.16, "end": 4817.16, "text": " and metaphors. And he is a master of using these, you know, language and everyday examples", "tokens": [50912, 293, 30946, 830, 13, 400, 415, 307, 257, 4505, 295, 1228, 613, 11, 291, 458, 11, 2856, 293, 7429, 5110, 51512], "temperature": 0.0, "avg_logprob": -0.11761371612548828, "compression_ratio": 1.3546099290780143, "no_speech_prob": 0.007341480348259211}, {"id": 635, "seek": 481716, "start": 4817.8, "end": 4822.76, "text": " to try and illustrate what's going on in these incredibly abstract ideas.", "tokens": [50396, 281, 853, 293, 23221, 437, 311, 516, 322, 294, 613, 6252, 12649, 3487, 13, 50644], "temperature": 0.0, "avg_logprob": -0.10675029754638672, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.0038239157292991877}, {"id": 636, "seek": 481716, "start": 4825.32, "end": 4836.04, "text": " So, he's a master cultural translator from these various realms. And again, using what,", "tokens": [50772, 407, 11, 415, 311, 257, 4505, 6988, 35223, 490, 613, 3683, 42824, 13, 400, 797, 11, 1228, 437, 11, 51308], "temperature": 0.0, "avg_logprob": -0.10675029754638672, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.0038239157292991877}, {"id": 637, "seek": 481716, "start": 4836.04, "end": 4842.12, "text": " I mean, I can see the influence because you've done a number of articles on metaphor and", "tokens": [51308, 286, 914, 11, 286, 393, 536, 264, 6503, 570, 291, 600, 1096, 257, 1230, 295, 11290, 322, 19157, 293, 51612], "temperature": 0.0, "avg_logprob": -0.10675029754638672, "compression_ratio": 1.4204545454545454, "no_speech_prob": 0.0038239157292991877}, {"id": 638, "seek": 484212, "start": 4842.12, "end": 4850.2, "text": " analogy, particularly in the context of AI. So that understanding by way of metaphor and", "tokens": [50364, 21663, 11, 4098, 294, 264, 4319, 295, 7318, 13, 407, 300, 3701, 538, 636, 295, 19157, 293, 50768], "temperature": 0.0, "avg_logprob": -0.12738202901986928, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0015969370724633336}, {"id": 639, "seek": 484212, "start": 4850.2, "end": 4856.84, "text": " analogy has obviously been very central to your own development as a scientist and as an interpreter", "tokens": [50768, 21663, 575, 2745, 668, 588, 5777, 281, 428, 1065, 3250, 382, 257, 12662, 293, 382, 364, 34132, 51100], "temperature": 0.0, "avg_logprob": -0.12738202901986928, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0015969370724633336}, {"id": 640, "seek": 484212, "start": 4856.84, "end": 4864.12, "text": " of science to a larger community. Yeah, and in fact, you know, Hofstadter was the one who", "tokens": [51100, 295, 3497, 281, 257, 4833, 1768, 13, 865, 11, 293, 294, 1186, 11, 291, 458, 11, 37379, 48299, 391, 390, 264, 472, 567, 51464], "temperature": 0.0, "avg_logprob": -0.12738202901986928, "compression_ratio": 1.4607329842931938, "no_speech_prob": 0.0015969370724633336}, {"id": 641, "seek": 486412, "start": 4865.0, "end": 4872.84, "text": " introduced me to the idea of building AI systems that can make analogies. That was the", "tokens": [50408, 7268, 385, 281, 264, 1558, 295, 2390, 7318, 3652, 300, 393, 652, 16660, 530, 13, 663, 390, 264, 50800], "temperature": 0.0, "avg_logprob": -0.11859243363142014, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.015412688255310059}, {"id": 642, "seek": 486412, "start": 4872.84, "end": 4881.16, "text": " topic of my PhD dissertation for which he was the advisor. Right. So this notion of analogy and", "tokens": [50800, 4829, 295, 452, 14476, 39555, 337, 597, 415, 390, 264, 19161, 13, 1779, 13, 407, 341, 10710, 295, 21663, 293, 51216], "temperature": 0.0, "avg_logprob": -0.11859243363142014, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.015412688255310059}, {"id": 643, "seek": 486412, "start": 4881.16, "end": 4889.5599999999995, "text": " metaphor kind of circles through all of my research. And it certainly circles through all of your", "tokens": [51216, 19157, 733, 295, 13040, 807, 439, 295, 452, 2132, 13, 400, 309, 3297, 13040, 807, 439, 295, 428, 51636], "temperature": 0.0, "avg_logprob": -0.11859243363142014, "compression_ratio": 1.5469613259668509, "no_speech_prob": 0.015412688255310059}, {"id": 644, "seek": 488956, "start": 4889.72, "end": 4899.160000000001, "text": " readings as well. Evidently. You're starting to discover a certain kind of pattern that started", "tokens": [50372, 27319, 382, 731, 13, 5689, 1078, 356, 13, 509, 434, 2891, 281, 4411, 257, 1629, 733, 295, 5102, 300, 1409, 50844], "temperature": 0.0, "avg_logprob": -0.11078177860804966, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.02756851352751255}, {"id": 645, "seek": 488956, "start": 4899.160000000001, "end": 4907.72, "text": " at age eight. Yeah, I never had made that connection. It's kind of like psychotherapy, right?", "tokens": [50844, 412, 3205, 3180, 13, 865, 11, 286, 1128, 632, 1027, 300, 4984, 13, 467, 311, 733, 295, 411, 4681, 23208, 11, 558, 30, 51272], "temperature": 0.0, "avg_logprob": -0.11078177860804966, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.02756851352751255}, {"id": 646, "seek": 488956, "start": 4909.64, "end": 4916.4400000000005, "text": " It's all started in your childhood. Are you still in contact with Professor Hofstadter?", "tokens": [51368, 467, 311, 439, 1409, 294, 428, 9278, 13, 2014, 291, 920, 294, 3385, 365, 8419, 37379, 48299, 391, 30, 51708], "temperature": 0.0, "avg_logprob": -0.11078177860804966, "compression_ratio": 1.4656084656084656, "no_speech_prob": 0.02756851352751255}, {"id": 647, "seek": 491644, "start": 4916.44, "end": 4926.44, "text": " Yeah. Yeah. Talk to him from time to time. Okay. So the next book, unless there's something else", "tokens": [50364, 865, 13, 865, 13, 8780, 281, 796, 490, 565, 281, 565, 13, 1033, 13, 407, 264, 958, 1446, 11, 5969, 456, 311, 746, 1646, 50864], "temperature": 0.0, "avg_logprob": -0.14140246073404947, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.0009252011077478528}, {"id": 648, "seek": 491644, "start": 4926.44, "end": 4932.679999999999, "text": " you'd like to say about that, I think we've kind of established the fact that it's been", "tokens": [50864, 291, 1116, 411, 281, 584, 466, 300, 11, 286, 519, 321, 600, 733, 295, 7545, 264, 1186, 300, 309, 311, 668, 51176], "temperature": 0.0, "avg_logprob": -0.14140246073404947, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.0009252011077478528}, {"id": 649, "seek": 491644, "start": 4932.679999999999, "end": 4939.96, "text": " transformational. I mean, your PhD thesis was about analogies, about the man who had written a book", "tokens": [51176, 4088, 1478, 13, 286, 914, 11, 428, 14476, 22288, 390, 466, 16660, 530, 11, 466, 264, 587, 567, 632, 3720, 257, 1446, 51540], "temperature": 0.0, "avg_logprob": -0.14140246073404947, "compression_ratio": 1.471502590673575, "no_speech_prob": 0.0009252011077478528}, {"id": 650, "seek": 493996, "start": 4940.52, "end": 4949.32, "text": " filled full of analogies and metaphors. And that was a watershed book and a watershed period of", "tokens": [50392, 6412, 1577, 295, 16660, 530, 293, 30946, 830, 13, 400, 300, 390, 257, 49728, 1446, 293, 257, 49728, 2896, 295, 50832], "temperature": 0.0, "avg_logprob": -0.1001939250998301, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.004397798329591751}, {"id": 651, "seek": 493996, "start": 4949.32, "end": 4960.28, "text": " your life. Absolutely. Yep. The Recursive Universe by William Poundstone, which is really kind of the", "tokens": [50832, 428, 993, 13, 7021, 13, 7010, 13, 440, 9647, 2156, 488, 18307, 538, 6740, 430, 554, 11243, 11, 597, 307, 534, 733, 295, 264, 51380], "temperature": 0.0, "avg_logprob": -0.1001939250998301, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.004397798329591751}, {"id": 652, "seek": 493996, "start": 4960.28, "end": 4967.16, "text": " origin of complexity, which I know is another one of the fields that you've done a fair amount of", "tokens": [51380, 4957, 295, 14024, 11, 597, 286, 458, 307, 1071, 472, 295, 264, 7909, 300, 291, 600, 1096, 257, 3143, 2372, 295, 51724], "temperature": 0.0, "avg_logprob": -0.1001939250998301, "compression_ratio": 1.4824120603015076, "no_speech_prob": 0.004397798329591751}, {"id": 653, "seek": 496716, "start": 4967.16, "end": 4977.4, "text": " research and study and writing. And explain a little bit about how this book came to you", "tokens": [50364, 2132, 293, 2979, 293, 3579, 13, 400, 2903, 257, 707, 857, 466, 577, 341, 1446, 1361, 281, 291, 50876], "temperature": 0.0, "avg_logprob": -0.11184892898950821, "compression_ratio": 1.3879310344827587, "no_speech_prob": 0.00023778920876793563}, {"id": 654, "seek": 496716, "start": 4977.4, "end": 4985.32, "text": " and what it said to you about complexity that still is important to you.", "tokens": [50876, 293, 437, 309, 848, 281, 291, 466, 14024, 300, 920, 307, 1021, 281, 291, 13, 51272], "temperature": 0.0, "avg_logprob": -0.11184892898950821, "compression_ratio": 1.3879310344827587, "no_speech_prob": 0.00023778920876793563}, {"id": 655, "seek": 498532, "start": 4985.32, "end": 4998.759999999999, "text": " Yes. So this book, I believe I read it in graduate school. I don't remember how I came across it.", "tokens": [50364, 1079, 13, 407, 341, 1446, 11, 286, 1697, 286, 1401, 309, 294, 8080, 1395, 13, 286, 500, 380, 1604, 577, 286, 1361, 2108, 309, 13, 51036], "temperature": 0.0, "avg_logprob": -0.22475075721740723, "compression_ratio": 1.213740458015267, "no_speech_prob": 0.008186357095837593}, {"id": 656, "seek": 498532, "start": 5000.44, "end": 5011.4, "text": " But what it is, it takes John Conway's Game of Life, which is", "tokens": [51120, 583, 437, 309, 307, 11, 309, 2516, 2619, 2656, 676, 311, 7522, 295, 7720, 11, 597, 307, 51668], "temperature": 0.0, "avg_logprob": -0.22475075721740723, "compression_ratio": 1.213740458015267, "no_speech_prob": 0.008186357095837593}, {"id": 657, "seek": 501140, "start": 5011.879999999999, "end": 5023.879999999999, "text": " what's called a cellular automaton. It's not exactly a game. It's more like a very idealized model,", "tokens": [50388, 437, 311, 1219, 257, 29267, 3553, 25781, 13, 467, 311, 406, 2293, 257, 1216, 13, 467, 311, 544, 411, 257, 588, 7157, 1602, 2316, 11, 50988], "temperature": 0.0, "avg_logprob": -0.19489572562423407, "compression_ratio": 1.4202898550724639, "no_speech_prob": 0.0022509268019348383}, {"id": 658, "seek": 501140, "start": 5026.28, "end": 5035.16, "text": " very simplified model of complex systems. And it uses this Game of Life and Game of Life is full", "tokens": [51108, 588, 26335, 2316, 295, 3997, 3652, 13, 400, 309, 4960, 341, 7522, 295, 7720, 293, 7522, 295, 7720, 307, 1577, 51552], "temperature": 0.0, "avg_logprob": -0.19489572562423407, "compression_ratio": 1.4202898550724639, "no_speech_prob": 0.0022509268019348383}, {"id": 659, "seek": 503516, "start": 5035.16, "end": 5044.28, "text": " of little patterns that people have discovered in things that are gliders and other kinds of", "tokens": [50364, 295, 707, 8294, 300, 561, 362, 6941, 294, 721, 300, 366, 1563, 6936, 293, 661, 3685, 295, 50820], "temperature": 0.0, "avg_logprob": -0.11704443825615776, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0025500475894659758}, {"id": 660, "seek": 503516, "start": 5045.0, "end": 5057.8, "text": " structures that can do all kinds of computations. And Poundstone uses this as a way to talk about", "tokens": [50856, 9227, 300, 393, 360, 439, 3685, 295, 2807, 763, 13, 400, 430, 554, 11243, 4960, 341, 382, 257, 636, 281, 751, 466, 51496], "temperature": 0.0, "avg_logprob": -0.11704443825615776, "compression_ratio": 1.4285714285714286, "no_speech_prob": 0.0025500475894659758}, {"id": 661, "seek": 505780, "start": 5057.8, "end": 5065.4800000000005, "text": " bigger ideas in cosmology and physics. And it's just a fascinating kind of approach to talking", "tokens": [50364, 3801, 3487, 294, 22207, 1793, 293, 10649, 13, 400, 309, 311, 445, 257, 10343, 733, 295, 3109, 281, 1417, 50748], "temperature": 0.0, "avg_logprob": -0.1333821415901184, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.040208641439676285}, {"id": 662, "seek": 505780, "start": 5065.4800000000005, "end": 5071.400000000001, "text": " about those ideas. And it was one of my introductions to the Game of Life,", "tokens": [50748, 466, 729, 3487, 13, 400, 309, 390, 472, 295, 452, 48032, 281, 264, 7522, 295, 7720, 11, 51044], "temperature": 0.0, "avg_logprob": -0.1333821415901184, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.040208641439676285}, {"id": 663, "seek": 505780, "start": 5073.24, "end": 5078.92, "text": " and I think you've seen sort of how complex that all is and how complexity can emerge from these", "tokens": [51136, 293, 286, 519, 291, 600, 1612, 1333, 295, 577, 3997, 300, 439, 307, 293, 577, 14024, 393, 21511, 490, 613, 51420], "temperature": 0.0, "avg_logprob": -0.1333821415901184, "compression_ratio": 1.4777777777777779, "no_speech_prob": 0.040208641439676285}, {"id": 664, "seek": 507892, "start": 5078.92, "end": 5084.2, "text": " very simple rules, and then tying it to these much bigger ideas.", "tokens": [50364, 588, 2199, 4474, 11, 293, 550, 32405, 309, 281, 613, 709, 3801, 3487, 13, 50628], "temperature": 0.0, "avg_logprob": -0.1470361391703288, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.009410873986780643}, {"id": 665, "seek": 507892, "start": 5086.6, "end": 5090.76, "text": " So I just loved that book. I thought it was beautiful, and it's not that well known. I mean,", "tokens": [50748, 407, 286, 445, 4333, 300, 1446, 13, 286, 1194, 309, 390, 2238, 11, 293, 309, 311, 406, 300, 731, 2570, 13, 286, 914, 11, 50956], "temperature": 0.0, "avg_logprob": -0.1470361391703288, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.009410873986780643}, {"id": 666, "seek": 507892, "start": 5090.76, "end": 5101.56, "text": " it's surprisingly, I think, underappreciated. I think from what I've read, I haven't read the book,", "tokens": [50956, 309, 311, 17600, 11, 286, 519, 11, 833, 1746, 3326, 770, 13, 286, 519, 490, 437, 286, 600, 1401, 11, 286, 2378, 380, 1401, 264, 1446, 11, 51496], "temperature": 0.0, "avg_logprob": -0.1470361391703288, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.009410873986780643}, {"id": 667, "seek": 507892, "start": 5101.56, "end": 5106.04, "text": " but I've read about it, and it seems absolutely fascinating in terms of", "tokens": [51496, 457, 286, 600, 1401, 466, 309, 11, 293, 309, 2544, 3122, 10343, 294, 2115, 295, 51720], "temperature": 0.0, "avg_logprob": -0.1470361391703288, "compression_ratio": 1.5817307692307692, "no_speech_prob": 0.009410873986780643}, {"id": 668, "seek": 510604, "start": 5107.0, "end": 5113.56, "text": " of this notion of self-assembly, of how you can get very complex systems out of something that is", "tokens": [50412, 295, 341, 10710, 295, 2698, 12, 29386, 356, 11, 295, 577, 291, 393, 483, 588, 3997, 3652, 484, 295, 746, 300, 307, 50740], "temperature": 0.0, "avg_logprob": -0.13165856810177073, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0047534918412566185}, {"id": 669, "seek": 510604, "start": 5114.28, "end": 5123.0, "text": " in itself very simple. And for example, he gives the example of Pi, where, you know, basically", "tokens": [50776, 294, 2564, 588, 2199, 13, 400, 337, 1365, 11, 415, 2709, 264, 1365, 295, 17741, 11, 689, 11, 291, 458, 11, 1936, 51212], "temperature": 0.0, "avg_logprob": -0.13165856810177073, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0047534918412566185}, {"id": 670, "seek": 510604, "start": 5123.8, "end": 5130.84, "text": " you can encode it using only two terms and end up with this unbelievably complex", "tokens": [51252, 291, 393, 2058, 1429, 309, 1228, 787, 732, 2115, 293, 917, 493, 365, 341, 43593, 3997, 51604], "temperature": 0.0, "avg_logprob": -0.13165856810177073, "compression_ratio": 1.5251396648044693, "no_speech_prob": 0.0047534918412566185}, {"id": 671, "seek": 513084, "start": 5131.64, "end": 5141.400000000001, "text": " number from just the initial to write the components to begin with. So I thought it was a", "tokens": [50404, 1230, 490, 445, 264, 5883, 281, 2464, 264, 6677, 281, 1841, 365, 13, 407, 286, 1194, 309, 390, 257, 50892], "temperature": 0.0, "avg_logprob": -0.23209234975999402, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.006385160610079765}, {"id": 672, "seek": 513084, "start": 5141.400000000001, "end": 5147.08, "text": " quite interesting aspect of it. And the other thing is the initial information input and the", "tokens": [50892, 1596, 1880, 4171, 295, 309, 13, 400, 264, 661, 551, 307, 264, 5883, 1589, 4846, 293, 264, 51176], "temperature": 0.0, "avg_logprob": -0.23209234975999402, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.006385160610079765}, {"id": 673, "seek": 513084, "start": 5147.08, "end": 5157.96, "text": " relationship of information with entropy. You know, Claude Shannon with Bolson of looking at", "tokens": [51176, 2480, 295, 1589, 365, 30867, 13, 509, 458, 11, 12947, 2303, 28974, 365, 14331, 3015, 295, 1237, 412, 51720], "temperature": 0.0, "avg_logprob": -0.23209234975999402, "compression_ratio": 1.5536723163841808, "no_speech_prob": 0.006385160610079765}, {"id": 674, "seek": 515796, "start": 5157.96, "end": 5167.64, "text": " those two aspects of the universe, from an informational model to a model of", "tokens": [50364, 729, 732, 7270, 295, 264, 6445, 11, 490, 364, 49391, 2316, 281, 257, 2316, 295, 50848], "temperature": 0.0, "avg_logprob": -0.09643089771270752, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.0005882493569515646}, {"id": 675, "seek": 515796, "start": 5168.28, "end": 5174.2, "text": " the second law of thermodynamics or entropy, where things will go into greater disorder.", "tokens": [50880, 264, 1150, 2101, 295, 8810, 35483, 420, 30867, 11, 689, 721, 486, 352, 666, 5044, 13399, 13, 51176], "temperature": 0.0, "avg_logprob": -0.09643089771270752, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.0005882493569515646}, {"id": 676, "seek": 515796, "start": 5175.0, "end": 5181.72, "text": " Yes, exactly. So this book brought together a lot of ideas of complex systems that I had been", "tokens": [51216, 1079, 11, 2293, 13, 407, 341, 1446, 3038, 1214, 257, 688, 295, 3487, 295, 3997, 3652, 300, 286, 632, 668, 51552], "temperature": 0.0, "avg_logprob": -0.09643089771270752, "compression_ratio": 1.463276836158192, "no_speech_prob": 0.0005882493569515646}, {"id": 677, "seek": 518172, "start": 5182.6, "end": 5187.320000000001, "text": " thinking a little bit about, but never really found them brought all together,", "tokens": [50408, 1953, 257, 707, 857, 466, 11, 457, 1128, 534, 1352, 552, 3038, 439, 1214, 11, 50644], "temperature": 0.0, "avg_logprob": -0.1458773502083712, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.006287591997534037}, {"id": 678, "seek": 518172, "start": 5188.04, "end": 5195.400000000001, "text": " including entropy, information, computation, you know, he shows, he talks about Conway's proof that", "tokens": [50680, 3009, 30867, 11, 1589, 11, 24903, 11, 291, 458, 11, 415, 3110, 11, 415, 6686, 466, 2656, 676, 311, 8177, 300, 51048], "temperature": 0.0, "avg_logprob": -0.1458773502083712, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.006287591997534037}, {"id": 679, "seek": 518172, "start": 5196.280000000001, "end": 5203.64, "text": " the game of life, which is just, it's just a two-dimensional grid of black and white,", "tokens": [51092, 264, 1216, 295, 993, 11, 597, 307, 445, 11, 309, 311, 445, 257, 732, 12, 18759, 10748, 295, 2211, 293, 2418, 11, 51460], "temperature": 0.0, "avg_logprob": -0.1458773502083712, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.006287591997534037}, {"id": 680, "seek": 518172, "start": 5205.16, "end": 5211.4800000000005, "text": " what they call cells, that influence each other in simple ways. But this actually you can", "tokens": [51536, 437, 436, 818, 5438, 11, 300, 6503, 1184, 661, 294, 2199, 2098, 13, 583, 341, 767, 291, 393, 51852], "temperature": 0.0, "avg_logprob": -0.1458773502083712, "compression_ratio": 1.5594713656387664, "no_speech_prob": 0.006287591997534037}, {"id": 681, "seek": 521148, "start": 5211.48, "end": 5221.24, "text": " embed an entire computer in this incredibly simple system. And it's just, it's full of very profound", "tokens": [50364, 12240, 364, 2302, 3820, 294, 341, 6252, 2199, 1185, 13, 400, 309, 311, 445, 11, 309, 311, 1577, 295, 588, 14382, 50852], "temperature": 0.0, "avg_logprob": -0.19603590284075056, "compression_ratio": 1.4422110552763818, "no_speech_prob": 0.0005272937123663723}, {"id": 682, "seek": 521148, "start": 5221.24, "end": 5230.28, "text": " ideas. I know it's kind of fair you teach an online course on complexity, which is highly popular.", "tokens": [50852, 3487, 13, 286, 458, 309, 311, 733, 295, 3143, 291, 2924, 364, 2950, 1164, 322, 14024, 11, 597, 307, 5405, 3743, 13, 51304], "temperature": 0.0, "avg_logprob": -0.19603590284075056, "compression_ratio": 1.4422110552763818, "no_speech_prob": 0.0005272937123663723}, {"id": 683, "seek": 521148, "start": 5230.28, "end": 5238.36, "text": " I read somewhere like 25,000 students have more now, where I read is probably outdated.", "tokens": [51304, 286, 1401, 4079, 411, 3552, 11, 1360, 1731, 362, 544, 586, 11, 689, 286, 1401, 307, 1391, 36313, 13, 51708], "temperature": 0.0, "avg_logprob": -0.19603590284075056, "compression_ratio": 1.4422110552763818, "no_speech_prob": 0.0005272937123663723}, {"id": 684, "seek": 523836, "start": 5238.44, "end": 5241.719999999999, "text": " But it seems to be a very popular, is this one of the books that's", "tokens": [50368, 583, 309, 2544, 281, 312, 257, 588, 3743, 11, 307, 341, 472, 295, 264, 3642, 300, 311, 50532], "temperature": 0.0, "avg_logprob": -0.14665645360946655, "compression_ratio": 1.5339366515837105, "no_speech_prob": 0.0011157204862684011}, {"id": 685, "seek": 523836, "start": 5242.679999999999, "end": 5249.08, "text": " in the course? So I don't use the book in that course, but I do talk about a lot of these ideas.", "tokens": [50580, 294, 264, 1164, 30, 407, 286, 500, 380, 764, 264, 1446, 294, 300, 1164, 11, 457, 286, 360, 751, 466, 257, 688, 295, 613, 3487, 13, 50900], "temperature": 0.0, "avg_logprob": -0.14665645360946655, "compression_ratio": 1.5339366515837105, "no_speech_prob": 0.0011157204862684011}, {"id": 686, "seek": 523836, "start": 5249.719999999999, "end": 5259.639999999999, "text": " I see. Yeah. So we cover that kind of thing. Yeah. Right. Okay. The last book on the list is", "tokens": [50932, 286, 536, 13, 865, 13, 407, 321, 2060, 300, 733, 295, 551, 13, 865, 13, 1779, 13, 1033, 13, 440, 1036, 1446, 322, 264, 1329, 307, 51428], "temperature": 0.0, "avg_logprob": -0.14665645360946655, "compression_ratio": 1.5339366515837105, "no_speech_prob": 0.0011157204862684011}, {"id": 687, "seek": 523836, "start": 5259.639999999999, "end": 5265.96, "text": " Adaptations in Natural and Artificial Systems by John Holland. Last but not least,", "tokens": [51428, 49643, 763, 294, 20137, 293, 5735, 10371, 27059, 538, 2619, 27201, 13, 5264, 457, 406, 1935, 11, 51744], "temperature": 0.0, "avg_logprob": -0.14665645360946655, "compression_ratio": 1.5339366515837105, "no_speech_prob": 0.0011157204862684011}, {"id": 688, "seek": 526596, "start": 5266.92, "end": 5273.4800000000005, "text": " here we have adaptation is a biological process, rearranging genetic material, goes back to what", "tokens": [50412, 510, 321, 362, 21549, 307, 257, 13910, 1399, 11, 29875, 9741, 12462, 2527, 11, 1709, 646, 281, 437, 50740], "temperature": 0.0, "avg_logprob": -0.18039065438347893, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0014322572387754917}, {"id": 689, "seek": 526596, "start": 5273.4800000000005, "end": 5281.64, "text": " you're talking earlier about Darwin's and in the evolutionary biology that you found an attractive", "tokens": [50740, 291, 434, 1417, 3071, 466, 30233, 311, 293, 294, 264, 27567, 14956, 300, 291, 1352, 364, 12609, 51148], "temperature": 0.0, "avg_logprob": -0.18039065438347893, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0014322572387754917}, {"id": 690, "seek": 526596, "start": 5281.64, "end": 5290.68, "text": " way to take into another domain. So adaptation in Natural and Artificial Systems by John Holland,", "tokens": [51148, 636, 281, 747, 666, 1071, 9274, 13, 407, 21549, 294, 20137, 293, 5735, 10371, 27059, 538, 2619, 27201, 11, 51600], "temperature": 0.0, "avg_logprob": -0.18039065438347893, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0014322572387754917}, {"id": 691, "seek": 526596, "start": 5291.4800000000005, "end": 5295.56, "text": " was this something from your university days or earlier?", "tokens": [51640, 390, 341, 746, 490, 428, 5454, 1708, 420, 3071, 30, 51844], "temperature": 0.0, "avg_logprob": -0.18039065438347893, "compression_ratio": 1.5151515151515151, "no_speech_prob": 0.0014322572387754917}, {"id": 692, "seek": 529556, "start": 5295.64, "end": 5301.0, "text": " This was from graduate school. So John Holland was one of my professors at the University of Michigan.", "tokens": [50368, 639, 390, 490, 8080, 1395, 13, 407, 2619, 27201, 390, 472, 295, 452, 15924, 412, 264, 3535, 295, 11925, 13, 50636], "temperature": 0.0, "avg_logprob": -0.1144590726712855, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.000148811872350052}, {"id": 693, "seek": 529556, "start": 5302.04, "end": 5309.160000000001, "text": " And he taught a course by, he was a computer science professor, yet he taught a course", "tokens": [50688, 400, 415, 5928, 257, 1164, 538, 11, 415, 390, 257, 3820, 3497, 8304, 11, 1939, 415, 5928, 257, 1164, 51044], "temperature": 0.0, "avg_logprob": -0.1144590726712855, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.000148811872350052}, {"id": 694, "seek": 529556, "start": 5309.160000000001, "end": 5312.76, "text": " in computer science called Adaptation in Natural and Artificial Systems.", "tokens": [51044, 294, 3820, 3497, 1219, 49643, 399, 294, 20137, 293, 5735, 10371, 27059, 13, 51224], "temperature": 0.0, "avg_logprob": -0.1144590726712855, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.000148811872350052}, {"id": 695, "seek": 529556, "start": 5314.04, "end": 5319.88, "text": " It's a very technical book. So it's the only technical book on my list, really.", "tokens": [51288, 467, 311, 257, 588, 6191, 1446, 13, 407, 309, 311, 264, 787, 6191, 1446, 322, 452, 1329, 11, 534, 13, 51580], "temperature": 0.0, "avg_logprob": -0.1144590726712855, "compression_ratio": 1.6442307692307692, "no_speech_prob": 0.000148811872350052}, {"id": 696, "seek": 531988, "start": 5320.04, "end": 5329.08, "text": " But it was, John Holland was the founder of this field called Genetic Algorithms,", "tokens": [50372, 583, 309, 390, 11, 2619, 27201, 390, 264, 14917, 295, 341, 2519, 1219, 3632, 3532, 35014, 6819, 2592, 11, 50824], "temperature": 0.0, "avg_logprob": -0.16091169629778182, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0009397672838531435}, {"id": 697, "seek": 531988, "start": 5329.08, "end": 5335.72, "text": " which brought ideas from evolutionary biology into computer science.", "tokens": [50824, 597, 3038, 3487, 490, 27567, 14956, 666, 3820, 3497, 13, 51156], "temperature": 0.0, "avg_logprob": -0.16091169629778182, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0009397672838531435}, {"id": 698, "seek": 531988, "start": 5337.400000000001, "end": 5347.72, "text": " And this book was his theory of adaptation. So when you think about adaptation, maybe you think", "tokens": [51240, 400, 341, 1446, 390, 702, 5261, 295, 21549, 13, 407, 562, 291, 519, 466, 21549, 11, 1310, 291, 519, 51756], "temperature": 0.0, "avg_logprob": -0.16091169629778182, "compression_ratio": 1.430232558139535, "no_speech_prob": 0.0009397672838531435}, {"id": 699, "seek": 534772, "start": 5347.72, "end": 5362.76, "text": " about some kind of species adapting to a particular niche. For instance, you have things like butterflies", "tokens": [50364, 466, 512, 733, 295, 6172, 34942, 281, 257, 1729, 19956, 13, 1171, 5197, 11, 291, 362, 721, 411, 31987, 51116], "temperature": 0.0, "avg_logprob": -0.1177749742161144, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0006067818612791598}, {"id": 700, "seek": 534772, "start": 5362.76, "end": 5372.84, "text": " that the color of their wings change in response to their environment. And so this notion of adaptation", "tokens": [51116, 300, 264, 2017, 295, 641, 11405, 1319, 294, 4134, 281, 641, 2823, 13, 400, 370, 341, 10710, 295, 21549, 51620], "temperature": 0.0, "avg_logprob": -0.1177749742161144, "compression_ratio": 1.4217687074829932, "no_speech_prob": 0.0006067818612791598}, {"id": 701, "seek": 537284, "start": 5372.84, "end": 5380.52, "text": " is fundamental to biology. And yet Holland brought that into that field of computer science by saying", "tokens": [50364, 307, 8088, 281, 14956, 13, 400, 1939, 27201, 3038, 300, 666, 300, 2519, 295, 3820, 3497, 538, 1566, 50748], "temperature": 0.0, "avg_logprob": -0.0963421234717736, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004608413204550743}, {"id": 702, "seek": 537284, "start": 5380.52, "end": 5389.72, "text": " what we want in computer science and AI is to have computers that adapt. So we don't want just", "tokens": [50748, 437, 321, 528, 294, 3820, 3497, 293, 7318, 307, 281, 362, 10807, 300, 6231, 13, 407, 321, 500, 380, 528, 445, 51208], "temperature": 0.0, "avg_logprob": -0.0963421234717736, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004608413204550743}, {"id": 703, "seek": 537284, "start": 5389.72, "end": 5396.360000000001, "text": " living systems that adapt. We want machines that adapt, that are able to adapt to different", "tokens": [51208, 2647, 3652, 300, 6231, 13, 492, 528, 8379, 300, 6231, 11, 300, 366, 1075, 281, 6231, 281, 819, 51540], "temperature": 0.0, "avg_logprob": -0.0963421234717736, "compression_ratio": 1.6551724137931034, "no_speech_prob": 0.004608413204550743}, {"id": 704, "seek": 539636, "start": 5396.36, "end": 5406.5199999999995, "text": " environments and to be able to be flexible and learn the way that living systems do.", "tokens": [50364, 12388, 293, 281, 312, 1075, 281, 312, 11358, 293, 1466, 264, 636, 300, 2647, 3652, 360, 13, 50872], "temperature": 0.0, "avg_logprob": -0.14441829919815063, "compression_ratio": 1.4269005847953216, "no_speech_prob": 0.0010647515300661325}, {"id": 705, "seek": 539636, "start": 5407.719999999999, "end": 5417.48, "text": " So Holland became my co-advisor, along with Douglas Hofstetter. And this book was sort of set", "tokens": [50932, 407, 27201, 3062, 452, 598, 12, 345, 16457, 11, 2051, 365, 23010, 37379, 372, 27296, 13, 400, 341, 1446, 390, 1333, 295, 992, 51420], "temperature": 0.0, "avg_logprob": -0.14441829919815063, "compression_ratio": 1.4269005847953216, "no_speech_prob": 0.0010647515300661325}, {"id": 706, "seek": 539636, "start": 5417.48, "end": 5425.0, "text": " the path of a lot of my future research for up until now, really.", "tokens": [51420, 264, 3100, 295, 257, 688, 295, 452, 2027, 2132, 337, 493, 1826, 586, 11, 534, 13, 51796], "temperature": 0.0, "avg_logprob": -0.14441829919815063, "compression_ratio": 1.4269005847953216, "no_speech_prob": 0.0010647515300661325}, {"id": 707, "seek": 542500, "start": 5425.96, "end": 5434.2, "text": " Yeah. What seemed to me interesting about this book is the part that plays", "tokens": [50412, 865, 13, 708, 6576, 281, 385, 1880, 466, 341, 1446, 307, 264, 644, 300, 5749, 50824], "temperature": 0.0, "avg_logprob": -0.17402689007745273, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.000687630265019834}, {"id": 708, "seek": 542500, "start": 5434.92, "end": 5445.48, "text": " just conceptually of kind of perpetual novelty. That there is no kind of in-point that it's aimed", "tokens": [50860, 445, 3410, 671, 295, 733, 295, 48216, 44805, 13, 663, 456, 307, 572, 733, 295, 294, 12, 6053, 300, 309, 311, 20540, 51388], "temperature": 0.0, "avg_logprob": -0.17402689007745273, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.000687630265019834}, {"id": 709, "seek": 542500, "start": 5445.48, "end": 5452.76, "text": " for a particular in-point, that it's always open. And you can't quite predict where it will go,", "tokens": [51388, 337, 257, 1729, 294, 12, 6053, 11, 300, 309, 311, 1009, 1269, 13, 400, 291, 393, 380, 1596, 6069, 689, 309, 486, 352, 11, 51752], "temperature": 0.0, "avg_logprob": -0.17402689007745273, "compression_ratio": 1.5227272727272727, "no_speech_prob": 0.000687630265019834}, {"id": 710, "seek": 545276, "start": 5452.76, "end": 5460.6, "text": " how that co-evolution or that adaptation will go next. I guess that's part of the non-linearity", "tokens": [50364, 577, 300, 598, 12, 13379, 3386, 420, 300, 21549, 486, 352, 958, 13, 286, 2041, 300, 311, 644, 295, 264, 2107, 12, 1889, 17409, 50756], "temperature": 0.0, "avg_logprob": -0.10562763751392633, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0007791802636347711}, {"id": 711, "seek": 545276, "start": 5460.6, "end": 5468.92, "text": " that he discusses in the book, is that we have trouble with things like exponential numbers,", "tokens": [50756, 300, 415, 2248, 279, 294, 264, 1446, 11, 307, 300, 321, 362, 5253, 365, 721, 411, 21510, 3547, 11, 51172], "temperature": 0.0, "avg_logprob": -0.10562763751392633, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0007791802636347711}, {"id": 712, "seek": 545276, "start": 5468.92, "end": 5476.280000000001, "text": " non-linearity. These are things that are outside our realm of experiences, like absolute time as", "tokens": [51172, 2107, 12, 1889, 17409, 13, 1981, 366, 721, 300, 366, 2380, 527, 15355, 295, 5235, 11, 411, 8236, 565, 382, 51540], "temperature": 0.0, "avg_logprob": -0.10562763751392633, "compression_ratio": 1.574585635359116, "no_speech_prob": 0.0007791802636347711}, {"id": 713, "seek": 547628, "start": 5476.28, "end": 5484.36, "text": " opposed to relative time. And this is where you as a communicator of science try to come in and say,", "tokens": [50364, 8851, 281, 4972, 565, 13, 400, 341, 307, 689, 291, 382, 257, 3363, 1639, 295, 3497, 853, 281, 808, 294, 293, 584, 11, 50768], "temperature": 0.0, "avg_logprob": -0.07719367742538452, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.0013246898306533694}, {"id": 714, "seek": 547628, "start": 5484.36, "end": 5491.48, "text": " well, people are looking to take you to an in-point, but you have to be careful. Because the way", "tokens": [50768, 731, 11, 561, 366, 1237, 281, 747, 291, 281, 364, 294, 12, 6053, 11, 457, 291, 362, 281, 312, 5026, 13, 1436, 264, 636, 51124], "temperature": 0.0, "avg_logprob": -0.07719367742538452, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.0013246898306533694}, {"id": 715, "seek": 547628, "start": 5491.48, "end": 5496.44, "text": " in-points work in reality are quite different from the way that they're portrayed.", "tokens": [51124, 294, 12, 20552, 589, 294, 4103, 366, 1596, 819, 490, 264, 636, 300, 436, 434, 29845, 13, 51372], "temperature": 0.0, "avg_logprob": -0.07719367742538452, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.0013246898306533694}, {"id": 716, "seek": 547628, "start": 5498.2, "end": 5504.84, "text": " Right. So one interesting thing about this idea of perpetual novelty that Holland", "tokens": [51460, 1779, 13, 407, 472, 1880, 551, 466, 341, 1558, 295, 48216, 44805, 300, 27201, 51792], "temperature": 0.0, "avg_logprob": -0.07719367742538452, "compression_ratio": 1.567099567099567, "no_speech_prob": 0.0013246898306533694}, {"id": 717, "seek": 550484, "start": 5505.400000000001, "end": 5512.6, "text": " talks about, you can imagine that in biology where you're having species continually evolving", "tokens": [50392, 6686, 466, 11, 291, 393, 3811, 300, 294, 14956, 689, 291, 434, 1419, 6172, 22277, 21085, 50752], "temperature": 0.0, "avg_logprob": -0.14382003104850039, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0024704481475055218}, {"id": 718, "seek": 550484, "start": 5512.6, "end": 5520.4400000000005, "text": " and changing and the environment's changing. But Holland also brought these ideas into economics.", "tokens": [50752, 293, 4473, 293, 264, 2823, 311, 4473, 13, 583, 27201, 611, 3038, 613, 3487, 666, 14564, 13, 51144], "temperature": 0.0, "avg_logprob": -0.14382003104850039, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0024704481475055218}, {"id": 719, "seek": 550484, "start": 5521.4800000000005, "end": 5526.92, "text": " So interestingly, economics, the theory of economics that people,", "tokens": [51196, 407, 25873, 11, 14564, 11, 264, 5261, 295, 14564, 300, 561, 11, 51468], "temperature": 0.0, "avg_logprob": -0.14382003104850039, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0024704481475055218}, {"id": 720, "seek": 550484, "start": 5528.4400000000005, "end": 5534.04, "text": " the sort of classical economic theory has to do with equilibrium. You want sort of this economic", "tokens": [51544, 264, 1333, 295, 13735, 4836, 5261, 575, 281, 360, 365, 15625, 13, 509, 528, 1333, 295, 341, 4836, 51824], "temperature": 0.0, "avg_logprob": -0.14382003104850039, "compression_ratio": 1.6619718309859155, "no_speech_prob": 0.0024704481475055218}, {"id": 721, "seek": 553404, "start": 5534.04, "end": 5539.08, "text": " system to be in equilibrium or markets to be in equilibrium. But this idea of perpetual", "tokens": [50364, 1185, 281, 312, 294, 15625, 420, 8383, 281, 312, 294, 15625, 13, 583, 341, 1558, 295, 48216, 50616], "temperature": 0.0, "avg_logprob": -0.09983560515613091, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007431076373904943}, {"id": 722, "seek": 553404, "start": 5539.08, "end": 5547.8, "text": " novelty says such systems are never in equilibrium. And therefore, the classical theories don't describe", "tokens": [50616, 44805, 1619, 1270, 3652, 366, 1128, 294, 15625, 13, 400, 4412, 11, 264, 13735, 13667, 500, 380, 6786, 51052], "temperature": 0.0, "avg_logprob": -0.09983560515613091, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007431076373904943}, {"id": 723, "seek": 553404, "start": 5547.8, "end": 5555.24, "text": " reality where we actually have this continually changing co-adaptive system of all these economic", "tokens": [51052, 4103, 689, 321, 767, 362, 341, 22277, 4473, 598, 12, 345, 2796, 488, 1185, 295, 439, 613, 4836, 51424], "temperature": 0.0, "avg_logprob": -0.09983560515613091, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007431076373904943}, {"id": 724, "seek": 553404, "start": 5555.24, "end": 5561.16, "text": " agents. So that's really been revolutionizing a lot of thinking in economics as well as in", "tokens": [51424, 12554, 13, 407, 300, 311, 534, 668, 8894, 3319, 257, 688, 295, 1953, 294, 14564, 382, 731, 382, 294, 51720], "temperature": 0.0, "avg_logprob": -0.09983560515613091, "compression_ratio": 1.6858407079646018, "no_speech_prob": 0.0007431076373904943}, {"id": 725, "seek": 556116, "start": 5561.16, "end": 5573.639999999999, "text": " biology and computer science. Again, I guess things like global optimum and equilibrium", "tokens": [50364, 14956, 293, 3820, 3497, 13, 3764, 11, 286, 2041, 721, 411, 4338, 39326, 293, 15625, 50988], "temperature": 0.0, "avg_logprob": -0.11758002780732654, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0006770717445760965}, {"id": 726, "seek": 556116, "start": 5573.639999999999, "end": 5580.5199999999995, "text": " are in a way metaphorical, trying to create the notion that there's an in-point where everything", "tokens": [50988, 366, 294, 257, 636, 19157, 804, 11, 1382, 281, 1884, 264, 10710, 300, 456, 311, 364, 294, 12, 6053, 689, 1203, 51332], "temperature": 0.0, "avg_logprob": -0.11758002780732654, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0006770717445760965}, {"id": 727, "seek": 556116, "start": 5580.5199999999995, "end": 5589.72, "text": " is absolutely balanced as opposed to the fact that in reality, nothing is ever balanced for long.", "tokens": [51332, 307, 3122, 13902, 382, 8851, 281, 264, 1186, 300, 294, 4103, 11, 1825, 307, 1562, 13902, 337, 938, 13, 51792], "temperature": 0.0, "avg_logprob": -0.11758002780732654, "compression_ratio": 1.5243243243243243, "no_speech_prob": 0.0006770717445760965}, {"id": 728, "seek": 558972, "start": 5589.72, "end": 5598.2, "text": " There may be moments in time where it appears that birds and rabbits and dinosaurs had a", "tokens": [50364, 821, 815, 312, 6065, 294, 565, 689, 309, 7038, 300, 9009, 293, 38752, 293, 25851, 632, 257, 50788], "temperature": 0.0, "avg_logprob": -0.06940119497237666, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0013666520826518536}, {"id": 729, "seek": 558972, "start": 5598.2, "end": 5606.12, "text": " particular adaptation, but then it doesn't last. It's overtaken by something else. And as a result,", "tokens": [50788, 1729, 21549, 11, 457, 550, 309, 1177, 380, 1036, 13, 467, 311, 17038, 9846, 538, 746, 1646, 13, 400, 382, 257, 1874, 11, 51184], "temperature": 0.0, "avg_logprob": -0.06940119497237666, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0013666520826518536}, {"id": 730, "seek": 558972, "start": 5606.68, "end": 5618.12, "text": " you have to live with the uncertainty of a perpetual changing environment and adaptation", "tokens": [51212, 291, 362, 281, 1621, 365, 264, 15697, 295, 257, 48216, 4473, 2823, 293, 21549, 51784], "temperature": 0.0, "avg_logprob": -0.06940119497237666, "compression_ratio": 1.481283422459893, "no_speech_prob": 0.0013666520826518536}, {"id": 731, "seek": 561812, "start": 5618.12, "end": 5626.84, "text": " to those changes. Yes. I think one of your previous guests, John Allen Palos, has a great", "tokens": [50364, 281, 729, 2962, 13, 1079, 13, 286, 519, 472, 295, 428, 3894, 9804, 11, 2619, 17160, 6116, 329, 11, 575, 257, 869, 50800], "temperature": 0.0, "avg_logprob": -0.19406476661340513, "compression_ratio": 1.4098360655737705, "no_speech_prob": 0.0038216374814510345}, {"id": 732, "seek": 561812, "start": 5626.84, "end": 5631.72, "text": " quote where he says, you know, living with uncertainty is the only certainty.", "tokens": [50800, 6513, 689, 415, 1619, 11, 291, 458, 11, 2647, 365, 15697, 307, 264, 787, 27022, 13, 51044], "temperature": 0.0, "avg_logprob": -0.19406476661340513, "compression_ratio": 1.4098360655737705, "no_speech_prob": 0.0038216374814510345}, {"id": 733, "seek": 561812, "start": 5634.36, "end": 5642.5199999999995, "text": " That's something that I could just hear John saying. John's a friend I've known for years.", "tokens": [51176, 663, 311, 746, 300, 286, 727, 445, 1568, 2619, 1566, 13, 2619, 311, 257, 1277, 286, 600, 2570, 337, 924, 13, 51584], "temperature": 0.0, "avg_logprob": -0.19406476661340513, "compression_ratio": 1.4098360655737705, "no_speech_prob": 0.0038216374814510345}, {"id": 734, "seek": 564252, "start": 5642.52, "end": 5649.8, "text": " Yeah, very, very brilliant mathematician and, again, a communicator of a high level", "tokens": [50364, 865, 11, 588, 11, 588, 10248, 48281, 293, 11, 797, 11, 257, 3363, 1639, 295, 257, 1090, 1496, 50728], "temperature": 0.0, "avg_logprob": -0.11779482099745009, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007692586164921522}, {"id": 735, "seek": 564252, "start": 5650.68, "end": 5656.6, "text": " as you are as well. So I want to thank you for this been a delightful conversation.", "tokens": [50772, 382, 291, 366, 382, 731, 13, 407, 286, 528, 281, 1309, 291, 337, 341, 668, 257, 35194, 3761, 13, 51068], "temperature": 0.0, "avg_logprob": -0.11779482099745009, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007692586164921522}, {"id": 736, "seek": 564252, "start": 5656.6, "end": 5659.88, "text": " Let me know, what do you think about the experience of being on the show?", "tokens": [51068, 961, 385, 458, 11, 437, 360, 291, 519, 466, 264, 1752, 295, 885, 322, 264, 855, 30, 51232], "temperature": 0.0, "avg_logprob": -0.11779482099745009, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007692586164921522}, {"id": 737, "seek": 564252, "start": 5662.76, "end": 5669.080000000001, "text": " It's been a lot of fun. I mean, it's intimidating to try and have to think back on books that I've", "tokens": [51376, 467, 311, 668, 257, 688, 295, 1019, 13, 286, 914, 11, 309, 311, 29714, 281, 853, 293, 362, 281, 519, 646, 322, 3642, 300, 286, 600, 51692], "temperature": 0.0, "avg_logprob": -0.11779482099745009, "compression_ratio": 1.5178571428571428, "no_speech_prob": 0.007692586164921522}, {"id": 738, "seek": 566908, "start": 5669.08, "end": 5675.96, "text": " read years and years and years ago. But you reminded me of a lot of things that I'd forgotten,", "tokens": [50364, 1401, 924, 293, 924, 293, 924, 2057, 13, 583, 291, 15920, 385, 295, 257, 688, 295, 721, 300, 286, 1116, 11832, 11, 50708], "temperature": 0.0, "avg_logprob": -0.07353769101594623, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0024718623608350754}, {"id": 739, "seek": 566908, "start": 5676.5199999999995, "end": 5682.68, "text": " which has been great. And you also pointed out so many connections that I had never made about,", "tokens": [50736, 597, 575, 668, 869, 13, 400, 291, 611, 10932, 484, 370, 867, 9271, 300, 286, 632, 1128, 1027, 466, 11, 51044], "temperature": 0.0, "avg_logprob": -0.07353769101594623, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0024718623608350754}, {"id": 740, "seek": 566908, "start": 5683.24, "end": 5687.4, "text": " you know, different the books, these books that I've read and the things that I've been", "tokens": [51072, 291, 458, 11, 819, 264, 3642, 11, 613, 3642, 300, 286, 600, 1401, 293, 264, 721, 300, 286, 600, 668, 51280], "temperature": 0.0, "avg_logprob": -0.07353769101594623, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0024718623608350754}, {"id": 741, "seek": 566908, "start": 5687.4, "end": 5694.6, "text": " thinking about for a long time. So I thank you for that. And thank you. This has been a wonderful", "tokens": [51280, 1953, 466, 337, 257, 938, 565, 13, 407, 286, 1309, 291, 337, 300, 13, 400, 1309, 291, 13, 639, 575, 668, 257, 3715, 51640], "temperature": 0.0, "avg_logprob": -0.07353769101594623, "compression_ratio": 1.724770642201835, "no_speech_prob": 0.0024718623608350754}, {"id": 742, "seek": 569460, "start": 5694.6, "end": 5704.200000000001, "text": " conversation. And I will continue to follow your writings and learn from them. You're a master of", "tokens": [50364, 3761, 13, 400, 286, 486, 2354, 281, 1524, 428, 30083, 293, 1466, 490, 552, 13, 509, 434, 257, 4505, 295, 50844], "temperature": 0.0, "avg_logprob": -0.10506484585423623, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002017931081354618}, {"id": 743, "seek": 569460, "start": 5704.84, "end": 5712.76, "text": " communication between the arts and the science. And you contribute to both. And I think you have", "tokens": [50876, 6101, 1296, 264, 8609, 293, 264, 3497, 13, 400, 291, 10586, 281, 1293, 13, 400, 286, 519, 291, 362, 51272], "temperature": 0.0, "avg_logprob": -0.10506484585423623, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002017931081354618}, {"id": 744, "seek": 569460, "start": 5713.56, "end": 5720.92, "text": " done a great job in that communication. Please keep up this wonderful work.", "tokens": [51312, 1096, 257, 869, 1691, 294, 300, 6101, 13, 2555, 1066, 493, 341, 3715, 589, 13, 51680], "temperature": 0.0, "avg_logprob": -0.10506484585423623, "compression_ratio": 1.5340909090909092, "no_speech_prob": 0.002017931081354618}, {"id": 745, "seek": 572092, "start": 5720.92, "end": 5733.24, "text": " Thank you so much. Bye for now. Okay, bye bye.", "tokens": [50388, 1044, 291, 370, 709, 13, 4621, 337, 586, 13, 1033, 11, 6543, 6543, 13, 50980], "temperature": 0.0, "avg_logprob": -0.37418003643260284, "compression_ratio": 0.9019607843137255, "no_speech_prob": 0.06178099662065506}], "language": "en"}