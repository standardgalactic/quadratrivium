start	end	text
0	3840	Even Wolfram is a mathematician, computer scientist,
3840	9200	physicist, and businessman. Have I lied so far, Steve?
9200	13680	I don't know. So some people would not put mathematician first, but that's okay.
13680	17680	He's known for his work in computer science, mathematics, and theoretical
17680	19920	physics. The fellow of the American Mathematical
19920	23920	Society, founder and CEO of the software company
23920	27840	Wolfram Research, where he works as chief designer of Mathematica,
27840	34560	at the Wolfram Alpha NSERP engine. Now I'm going to move that away,
34560	39920	and I'm going to give it, you have also, besides the people in the
39920	45600	the attendees, there's also one, two, three, four, five
45600	48320	panelists that are here so far, and there might be some more.
48320	54080	Carl Friston, Ronnie Katzier, Sammy Benjiro. I can see the names, yeah.
54080	57840	Hi, Carl. The rest of you, I don't know, so nice to meet you.
57840	62080	Sammy, it's the other Benjiro. We'll find out more about that. He's the
62080	67920	brother of Yoshua, who is the co-sponsor of this event.
67920	74320	Okay, it's all yours. Wing it. Okay, so, well, let's see.
74320	78960	So I think you guys want to talk about language,
78960	83120	and computation, and AI, and all those good kinds of things, and I was
83120	87600	thinking I could talk about things about LLMs and so on.
87600	91920	You know, I wrote this little book last February about
91920	95920	ChatGBT. You can find a version of it online. I can put it in the
95920	99200	chat. It's, let me not talk about that, but if
99200	102000	people want to ask about it, I'm happy to chat about it.
102000	105440	I thought what I would try to do in 45 minutes give you
105440	110560	kind of the, a very rough tour of my last four and a half decades of
110560	114800	development of a worldview, and see how that relates to
114800	118800	things about AI, and language, and so on.
118800	128000	So to begin, you know, I think a thing that,
128000	131920	sort of the, there's kind of this progression of paradigms
131920	136000	to do with how we formalize the world. So there's sort of this
136080	141920	question of what, what can we do? We start, when we, when we see the
141920	146080	world, we're interested in finding ways to have sort of formal
146080	149840	descriptions of it that we can build on. So historically, kind of the
149840	153280	first of those, the big one for our species, was the invention of
153280	156720	human language, and the idea that you didn't have to just point at
156720	159840	each individual rock, but you could have this kind of symbolic
159840	165040	name, rock, wasn't rock originally, obviously, for that concept, and
165120	170000	you could communicate abstractly about that thing using human language.
170000	173040	Now then, we've had sort of a stack of other ideas,
173040	178000	another big idea is logic, being able to, as a way of sort of
178000	182400	abstracting things about the world, formalizing things about the world.
182400	186640	Another big direction is mathematics, being able to,
186640	189760	something that sort of became big in the late 1600s,
189840	194480	of being able to describe our world by mathematical concepts and constructs.
195520	200640	In this century, and the end of the last one, the big new thing has been
200640	204240	using computation as a way to formalize and describe the world.
204880	210320	Being able to specify kind of if you, the way I think about computation,
210320	216480	it's a way of setting up rules, and then saying, let these rules run.
216480	221040	And the question is, can we set up rules that describe the way the world is,
221040	224160	is, or the aspects of the world at least that we care about?
224800	229760	And my kind of day job for the last four decades has been building our
229760	232560	computational language, Wolfram Language, Mathematica, and so on,
233120	237360	as a way to kind of take the things that we humans care about,
237360	242480	whether they're molecules or cities or algorithms or whatever,
242480	249040	and create a systematic computational language to let one describe those things,
249040	252720	and not only describe them in a way that humans can read,
253440	259520	but also something where computers can help humans to execute those things.
260080	263040	So that's been kind of the way I see sort of that effort,
263040	268080	is take the things that we humans care about, and find a way to formalize them
268160	272960	computationally, so that we can provide sort of the raw material that we need
272960	276080	to work with the world computationally. It's kind of the effort,
276080	279120	is a bit like the effort that happened maybe 500 years ago,
279120	283920	with the development of mathematical notation, where people went from kind of talking about
283920	288320	math in terms of words, to having sort of a streamlined notation with plus signs and equal
288320	293680	signs and things like that. And that idea of notation, that sort of streamlined notation
293680	298320	for mathematics, is what ended up launching algebra and then calculus, and basically the
298320	305120	modern mathematical sciences. Kind of my day job mission has been to create a computational
305120	314080	language that lets one kind of launch computational x for all fields x. So okay, that's, so kind of
314080	320320	this idea is computational language as a way to sort of formalize things that happen in the world,
320320	326080	things that we care about in the world. Now the next question is what is the intrinsic description
326080	333280	of the world, so to speak? How should we describe the world in general? And the thing that sort of
333280	338320	had been the tradition of exact science for about 300 years, was use mathematical equations,
338320	343600	write down an equation that describes this or that aspect of the world. The thing that I got
343600	349760	interested in in the early 1980s is how does one generalize that idea? How does one, how does one,
349760	355600	what kinds of raw material can you find to talk about the world? And the thing that I started
355600	360640	studying a lot was using computation as kind of the raw material for describing the world.
361360	367280	And so the question, the first question is, well okay, what kinds of, how do you set up kind of
367280	372480	computational systems to do that? And for example, let's see, let's actually do something here.
374560	386640	Okay, let's say we are just kind of, we want to see what do
387600	394160	programs that might be computational descriptions of the world, what, let's just look at some
394160	402960	program that, just say what do the typical programs out there do? So this is a very simple example,
403040	408080	it's just you imagine a line of black and white cells and you have some simple rule that says,
408080	412960	given the colors of cells on one row, these are the, this is the color, this is how you determine
412960	422080	the color of the cells on the next row. So if you run this and just run this starting,
422080	428480	let's say, from one black cell, let's run it for like 40 steps. According to that rule,
429040	433680	you start off from, you end up with something where you have this very simple rule, very
433680	438240	simple computational rule, you run it, you get this very simple pattern. Now the question is,
438240	442560	what happens if we look at other kinds of rules? What happens if we kind of turn our
442560	447200	computational telescope out into the computational universe and just look at what's out there?
447840	453840	So we can do that, let's do this, let's just make a, let's just make a table of
453920	465360	all possible rules, let's say the first 63 of these rules, 64 of these rules.
466160	469920	Okay, so each one of these rules corresponds, each one of these pictures
470640	476320	corresponds to a different rule for how the colors of cells are determined by colors of
476320	482480	cells above them. What we see is many of these patterns are very simple, sometimes we'll get
482480	487120	slightly more complicated patterns, we might get a nested pattern, for example, here,
487760	491680	but the thing that is kind of my all-time favorite science discovery that I made almost
491680	497840	exactly 40 years ago, it was 40 years ago on June 1st, is this thing that I call rule 30.
498480	506160	It's specified by this set of cases here, and if we just run,
506480	517600	just run this, started off from single black cell, let's run it for let's say 200 steps,
519920	526240	this is what we get. And to me, this is something very surprising and kind of intuition breaking.
526240	533200	We have a very simple rule, and yet when we run that rule, we're generating something that looks
533200	538640	at least to us very complicated. And actually, you can go and you can sort of work out what's the
538640	543760	center column of cells here, and for all practical purposes, it seems completely random. But so what
543760	549600	this is telling us is out in the computational universe, even very simple rules can easily give
549600	555040	one very complicated behavior. And there are a lot of consequences of this. One thing that this led
555040	560560	me to is this thing I call the principle of computational equivalence. So the thing that is
560560	566000	sort of a big question is, how do you characterize what's going on in a system like this? Well,
566000	572000	you can think about the system as performing a computation. It starts from its initial conditions
572000	578320	at the top, and then it's going crunch, crunch, crunch, and and executing a computation. The
578320	583200	question then is sort of how sophisticated is that computation? And we might have thought, well,
583200	587600	it's just a simple rule, it's doing what it does. If we think about the kinds of computations that,
587680	591760	for example, we do in our brains, well, those are going to be much more sophisticated than this.
592560	597680	But what the principle of computational equivalence says is that actually that's not true.
597680	603920	Above some very low threshold, essentially, all of these kinds of systems, regardless of how simple
603920	609920	their rules are, are equivalent in the sophistication of the computations that they can do. So that
609920	615120	means that in a sense, this little rule 30 thing is doing a computation that's just as sophisticated
615200	620720	as the computations that go on, for example, in our brains. Well, what consequences does that have?
621600	627120	One consequence that has is this phenomenon I call computational irreducibility. So let's say
627120	632400	you want to know what this, well, how this pattern is going to work out a billion steps
632400	637600	later from now. Well, how do you how do you figure that out? One way you can figure that out is just
637600	642320	to follow those billion steps and see what happens. Another thing you can do is to say, wait a minute,
642400	646080	I'm much smarter than this system. I'm just going to jump ahead and I'm going to say,
646080	651040	I know what the answer is after a billion steps. That's the thing we've become used to
651040	657760	in doing, for example, mathematical science. You imagine an idealized planet orbiting a star.
657760	662160	You say, do you have to work out where it's going to be a million years from now? Do you have to
662160	667600	follow those million orbits? Or can you just use a formula and kind of fill in the number of million
667600	672000	and jump ahead and see what the answer is? That kind of what we can call computational
672000	677120	reducibility is what we've become used to from kind of what happens in mathematical science.
677840	682560	But the principle of computational equivalence tells us that will not generally be what one
682560	688320	can do. In general, the systems that we're studying will be just as computationally sophisticated
688320	692960	as anything that we can muster in studying them. And so that means we won't be able to do that kind
692960	697680	of jumping ahead. We won't be able to do that kind of computational outrunning of the system
697680	701520	and will be reduced to something where to work out what the system does,
701520	707040	we basically have to follow every step and see what the outcome is. So this is something which
707600	713200	or kind of in a sense for science, it's telling when there's a major limitation on science. And
713200	718640	by the way, this idea is something, things like girl's theorem, a sort of a special case of this
718640	723600	idea and lots of other kinds of things that one knows about universal computation and so on
723600	730240	is also related to this. But this is kind of a tighter version of those kinds of ideas
731200	736800	and one which I think sort of shows one kind of the relationship of these things to science.
736800	742320	And sort of the big consequences, there's lots of stuff that you won't be able to
742320	747600	have a theory for, work out, jump ahead, know what's going to happen. You'll have to just follow
747600	754320	every step and see what happens. And so in a sense, that's a limitation on science. From within
754320	759680	science, one is seeing kind of a fundamental limitation of science. It's actually something
759680	764480	which for many purposes might, one might not think of being a such bad thing, because in a sense,
764480	770240	it's the thing that makes, for example, the passage of time meaningful. If it wasn't for
770240	778160	computational irreducibility, then if you live for 50 years, then in a sense, that would not be,
778160	782720	nothing would be achieved by that. One would be able to say, oh, I know what's going to happen in
782720	787200	the end. I can jump ahead and say what the outcome is going to be. But because of computational
787200	792720	irreducibility, there is something sort of really happening in the passage of time. It is a sort of
792720	797200	an irreducible computation that's going on. There are many other consequences of computational
797280	803040	irreducibility. For example, when it comes to things like AI, we can ask the question,
804160	809840	what in so far as AI is doing computation? And we'll talk about the sense maybe later
809840	815440	in which typical modern neural nets are doing only very weak levels of computation.
815440	821040	But let's imagine that we have a system that is doing computation as computation can be done.
821680	827760	Well, we sort of have a choice. Either we can say that system is we're going to make that system
827760	832800	computationally reducible. So we know what the outcome is going to be. And so, for example,
832800	838000	we can say we're absolutely sure this system will never do the wrong thing because we know its outcomes
838000	843360	and we can constrain it to say that, to set it up so we can sort of prove that we'll never do the
843360	847680	wrong thing. It's reducible enough that we can know enough about what it's going to do that we
847680	854080	can know it isn't going to do the wrong thing. So that's plan A. But the problem with plan A
854080	859840	is that means that the system can't do irreducible computations. The system can only do computations
859840	864720	where we can jump ahead and foresee the outcome. So in a sense, that means we're crippling the
864720	869520	system. We're preventing it from doing what it could do as a computational system. We're saying
869520	874640	it's only going to do those things which are kind of reducible. So in a sense, I think it's going
874720	881360	to end up being sort of a big societal choice is, do we want the AIs, computational systems,
881360	885200	to be able to do all the powerful things that computational systems can do,
885200	889280	or do we want to insist that they'll only do things where we can foresee what they'll do?
889920	902000	And in a sense, it's kind of like we have a, you could say, well, I'm going to set up all these
902000	908240	rules for the AIs that make sure they only do the right things. Well, to make that work,
908240	913440	you have to have the AIs be sort of computationally reducible. If they're computationally
913440	918080	irreducible, well, maybe you can constrain it in all sorts of ways, but there'll always be surprises.
918080	922160	There'll always be things where you can't foresee that particular outcome. By the way,
922160	927360	computational irreducibility has many, many consequences. But another consequence it has
927360	933280	is that sort of science will never be finished. There will always be, if we think about kind of,
933280	938000	there'll always be things where we can't foresee the next thing that will happen.
938000	942560	There will always be surprises in mathematics. There will always be new theorems that can be
942560	947600	proved and so on. The thing that is an issue there in terms of things like will science be
947600	954960	finished and so on is, well, okay, there might be things that were surprises, but are they surprises
954960	959440	we care about? If we were exploring all of mathematics, we would prove more and more and more
959440	964240	theorems. But it could be that we get to the point where we know all the theorems we care about,
964240	968000	and anything else is something we're not going to care about. So in a sense, it's a,
968000	975120	there's sort of this, this connection to sort of human issues in what, but the point is that
975120	981120	there is ultimately an infinite and unlimited frontier of what's possible to discover in science
981200	985760	and so on. By the way, that also relates, maybe we can talk about, to things like,
987440	993920	well, okay, let's, let's maybe talk about, so, so kind of this, this idea of computational
993920	999840	irreducibility, that you can't know the outcome of a computational process in general, except by
999840	1005040	running it and seeing what happens. Limitation on science, thing that makes the passage of time
1005040	1020720	meaningful, kind of dichotomy for thinking about AI and so on. It's the, so that, so let's see,
1021680	1028320	one of the things that's sort of interesting about this is we can just sort of, in this
1028320	1035040	computational universe, we'll find all sorts of, of things that go on. The question becomes,
1035040	1040480	sort of, are those things that we find out there, things that we care about or not? In other words,
1040480	1046320	we can go and we can, oh, I don't know, we can, you know, that's a, an example of just a simple
1046320	1051120	rule and what it does and we can get the lots of other, lots of other examples we can, we can,
1051840	1061040	we can go and do this ourselves if we want to, let's see, and just go find very simple rules
1061040	1065280	that do very complicated things. It's easy to kind of launch out into the computational
1065280	1073360	universe and find these things. The question ends up being, so how, what do we humans care about
1073360	1079280	these things? Well, it could be that this particular thing, we will be able to use it for
1079280	1083840	technology in some way. It could be that we'll think this is something very important for art,
1084400	1088080	but it's something where out there in the computational universe, there's kind of an
1088080	1095440	infinite supply of original things. The question is, which ones do we humans choose to care about?
1096240	1103600	And, and for example, if we imagine kind of the, the, the future of AIs, you can say, okay AI,
1103600	1108240	go out into the computational universe, you can go and create things that have never been seen
1108240	1113760	before, all kinds of things. The question is, are those things that are of, of kind of human
1113760	1120080	relevance to us now? Well, one thing you might do, you can actually do a little experiment here,
1120080	1128640	let me show you something. Where is it? So for example, we could say we could take some image
1128640	1138880	generation AI, and this is just a diffusion image generator. And we could say, let's, let's look,
1138880	1145440	let's ask the thing to make a picture of a cat in a party hat. Okay, but inside the AI,
1146080	1151920	it's got some, you know, embedding vector, it's got some, some set of numbers that describe
1151920	1157280	that is its version of what that concept is. But one thing we could do is something very simple
1158080	1163520	to sort of explore the universe of possibilities. We could say we're going to take this AI that's
1163520	1168080	very aligned with human interest because it's been trained on billions of human images.
1168080	1173840	But nevertheless, we could say, let's take this AI and let's sort of move around in this space of
1173840	1179440	possibilities. And so for some set of numbers, we've got the cat and the party hat. But as we
1179440	1184240	change those numbers, we're moving out from that. And we have this kind of in the middle,
1184240	1189920	we have this thing we might sort of describe as kind of cat island, that is things that to us kind
1189920	1196080	of look like cats. But then we go further away, and we'll get into things which aren't like cats.
1196080	1200720	If we go far enough, you know, we'll, we'll be able to go, I don't know, as an example, we'd be
1200720	1206080	able to go from, what is that going to? That's, well, okay, here's one that goes from a cat to
1206080	1213600	a dog, we're going through through this kind of meaning space from a cat to a dog. But in general,
1213600	1221280	what we'll find is that we in this sort of space of possibilities, there's this region that corresponds
1221280	1227360	to this concept that we have of a cat and a party hat. But as we go away from that, eventually,
1227360	1232000	we move far enough, we'll get to a picture of a, you know, a dog wearing a sweater or something.
1232960	1239360	But we go through a large volume of inter concept space of things which are images,
1239360	1245120	which were generated by this AI using, you know, computationally generated out there in the
1245120	1250880	computational universe, even set up to be quite aligned with kind of the pictures that we humans
1250880	1255120	have put on the web. But nevertheless, they're not things which are normally described by a
1255120	1260000	word like a cat or a dog or whatever else. So you might ask the question, you know, in an image
1260000	1266560	generation AI, what volume of the space of possibilities is covered by concepts that we
1266560	1273680	have already defined? The answer is maybe one part and 10 to the 600. So in other words, there's
1273680	1281600	this vast kind of inter concept space of possible images, only tiny corners of which are described
1281600	1288720	by words that we have in human languages. So in a sense, as we look at this kind of inter concept
1288720	1294320	space, we could say, you know, we don't necessarily have a word to describe some of these patterns,
1294400	1299280	but we might say, oh, that's kind of a cool pattern. And maybe we decide at some point that
1299280	1303600	that's a particular style of art. And eventually we get a word for it. And then we develop this
1303600	1309120	whole kind of human interest in that particular piece of what was inter concept space. And now
1309120	1318320	that becomes a concept in our languages and so on. So this idea is sort of this core idea that
1318320	1322720	there's this huge space, this huge kind of computational universe of possibilities,
1322720	1328240	even reduced here by ones that are sort of images aligned with images that we put on the web.
1328240	1333680	Even if you reduce it in that way, the part of that space that we have so far explored,
1333680	1340240	that we have so far come up with words for and described with concepts, is a tiny part of the
1340240	1346320	space. And there's vastly more that is kind of be found in the sort of inter concept space.
1346400	1351920	Now, what, you know, can we describe kind of the way that kind of we, we think about
1351920	1358960	sort of our progression in kind of the progression of human civilization and so on.
1358960	1364640	In some sense, you can think about us as progressively colonizing inter concept space.
1364640	1369280	We're progressively coming up with things coming up with, we're coming up with sort of this
1369280	1375840	social construct of language that that different ones of us sort of collectively understand,
1375840	1380720	that corresponds to the, these different points in the space of possibilities.
1381280	1386160	And sort of the progression of civilization, we can think of as being this progressive kind of
1387120	1392880	progressive exploration of inter concept space. And, you know, as we invent new paradigms for
1392880	1396720	things, we get to kind of, or new ways of describing things, we get to kind of move
1396720	1403440	outwards in the space. Now, for example, in my day job of creating computational language to
1403440	1411760	describe things, my, my mission in a sense is to find those, those places in the space of
1411760	1417760	possibilities that we humans care about, and that we can use as kind of building blocks
1417760	1424880	to construct kind of in a computational way, a description of what we want. But there's kind
1424880	1430800	of a broader science of what's in principle out there, which is broader than the things that we
1430800	1435600	humans have so far chosen to, to come up with words for and so on and have languages for.
1436480	1441760	Well, just to kind of fill out a little bit, kind of the, a little bit more of kind of the,
1442320	1449520	the world view that develops from all of this, we can ask questions about, okay, what about
1449520	1454640	our physical world? How is that constructed? What is the, what's kind of the, the underlying
1454640	1458640	structure there? And one of the things that's been very exciting to me in the last few years,
1458720	1465920	something I really did not expect sort of to, to, to happen is that it's, it's turned out that we've
1465920	1473120	been able to work out that how this kind of computational ideas provide sort of an ultimate
1474240	1480000	infrastructure, an ultimate kind of machine code for the physical universe. And what, what,
1480000	1484560	let me describe that a little bit because we're going to come back to this question of concepts
1484560	1489440	and into concept space and so on, but we're going to come at it now from a different direction
1489440	1497120	from understanding the structure of the physical world. So, sort of big picture, back in antiquity,
1497680	1501120	people were arguing, you know, is the world discreet or is it continuous? Is it made of
1501120	1507440	atoms or is it just things that are sort of flowing? And one didn't know. End of the 19th
1507440	1514240	century, it became clear, yes, there are molecules, matter is discreet. A little bit later, became
1514240	1519440	clear, there are photons like can be thought of as being discreet. At that time, people mostly
1519440	1524480	assumed that space would turn out to be discreet as well. But for various reasons, nobody technically
1524480	1529920	managed to make that work. And so physics kind of went on with the space is continuous, you can
1529920	1535680	kind of put things anywhere you want in space. Well, if you're thinking about things in kind
1535680	1540800	of computational terms, you're immediately led to say, wait a minute, you know, perhaps space is
1540800	1545680	actually fundamentally a computational construct, fundamentally a discreet kind of thing. And the
1545680	1550960	big surprise of four years ago now was that, yes, we actually managed to figure out how to make that
1550960	1558080	work and managed to figure out how that connects to the big theories of current 20th century physics.
1558080	1561840	And actually, the really remarkable thing that maybe I'll have a chance to describe
1561840	1566480	is that the big theories of 20th century physics, essentially general relativity, the theory of
1566480	1571600	gravity and spacetime, quantum mechanics, and statistical mechanics for the second law of
1571600	1577360	thermodynamics, those are sort of three big theories of 20th century physics. It turns out that all
1577360	1583040	three of those theories are not just things that we can kind of say, oh, that's what's true.
1583040	1588800	There are actually things that we can in some sense derive from fundamental considerations.
1588800	1594000	I had not expected any such thing to be the case that we could derive the laws of physics, so to
1594000	1599440	speak. But we can and I'll explain how that works. And that's kind of loop back to questions about
1599440	1607360	language and concepts and so on. But okay, so what's the universe made of? Well, in our models,
1607360	1612560	the universe consists of a bunch of sort of discrete atoms of space, we tend to call them
1612560	1618320	eames, kind of atoms of existence. They're things where the only thing you can say about them is
1618320	1622000	they exist, and they have an identity, and they're distinct from each other.
1622960	1628160	And then there's one more thing, which is you can say how these eames, how these atoms of space
1628160	1632800	are related to each other. You can say this one is related to these two other ones. It's kind of
1632800	1638080	like what atom of space is friends with what other atoms of space? And you define this whole
1638080	1642800	collection of relations between atoms of space, and you can represent that by a graph, a network,
1642800	1649200	or actually more formally in our models, a hypergraph. But the essentially one's just dealing
1649200	1655440	with this big network of relations between the atoms of space. And so everything in the universe
1655440	1660640	in our models is just made of the relations between atoms of space. So for example, if
1661360	1670160	something like a black hole, for example, is just a structure in the, I might even be able to show
1670160	1687120	you a picture of one, let me see if I can pull this up. This is actually in kind of the fabric
1687120	1694000	of space. This is two little tiny black holes. And we'll see in this video kind of space, most of
1694000	1698080	the activity of the universe actually is knitting together the structure of space. But there are
1698080	1702400	two black holes there, and you can kind of see they eventually merge. They produce gravitational
1702400	1708560	radiation. Actually, what we get from this model, where we're looking at kind of the
1708560	1713600	discrete structure of space, we can successfully reproduce the actual things that are observed
1713600	1720000	in black hole mergers and so on. But in any case, the basic point is what the universe is made of,
1720000	1725520	everything in the universe is just a feature of the structure of space. And when it comes to time,
1726160	1732400	time is the progressive rewriting of the structure of that network that represents space.
1732400	1736240	So time is actually a very different kind of thing in these models from space.
1736240	1741920	Things like relativity emerge as a feature of the model. They're not things that are put in
1741920	1747680	from the underlying structure of the model. Okay, so we've got sort of the notion of space,
1747680	1755200	notion of time. It turns out quantum mechanics is a thing that inevitably emerges from the fact that
1755280	1759680	when we are updating this network, there isn't just one possible path of history. There isn't
1759680	1764800	just one possible way that the network can be updated. There are many possible paths of history
1764800	1770000	that branch and merge. And essentially, the structure of those things is what leads to
1770000	1775920	quantum mechanics. Well, one of the issues is when we're looking at the system, and we're
1775920	1781920	seeing all these rewrites and the structure of space and so on, the question is, how do we experience
1781920	1788480	that? There are all these things microscopically happening, but we have a certain experience of
1788480	1794240	that. And it turns out that sort of a critical feature of what's going on is that we are observers
1794240	1802640	of a certain kind. So let's take the case of, let's look at, for example, let's see,
1806880	1810640	let's look at something like statistical mechanics. We've got a bunch of molecules
1810640	1815920	bouncing around in a box. And one of the kind of big principles is the second law of thermodynamics
1815920	1820960	that says when you start those molecules off in an orderly way, their motion will tend to
1820960	1826240	eventually look disordered and random. It will look as if it has higher entropy. And the question
1826240	1833040	is sort of what's really going on there? And it turns out that what's actually happening,
1833040	1838960	something I finally understood, I've been thinking about this for like 50 years, actually, is that
1839760	1844160	what's ultimately going on, you can look at different kinds of versions of this, what's
1844160	1850160	ultimately going on is that these molecules are bouncing around in a certain determined way
1850160	1855040	according to some rule. And in fact, that rule can be reversed. So you can take this pattern of
1855040	1859280	molecules you get at the end and you can say, I can figure out, oh, yes, that pattern of molecules
1859280	1865120	came from the simple initial state. Well, in principle, you can do that, but it's a computationally
1865680	1870960	irreducible process. And the difficulty is that we human observers of things
1871680	1878080	computationally bounded, we can't do that, that, that all the computation that's needed to reverse
1878080	1883600	what happens in the molecules, we're just stuck saying that we can, we can get this
1883600	1888000	impression of what's going on. And with that impression of what's going on with that computationally
1888000	1893280	bounded impression of what's going on, all we can say is, oh, it looks random to us. And that's
1893280	1897680	kind of the ultimate origin of the second law of thermodynamics is something which is to do with
1897680	1903440	the relationship between underlying computational irreducibility and our computational boundedness
1903440	1910880	as observers. Well, it turns out that both general relativity and quantum mechanics
1910880	1917440	come from the exact same thing. They both come from this idea that there is computational
1917440	1922320	irreducibility underneath. But we are, well, actually, there are two attributes that we have
1922320	1927680	to have as observers, that we are computationally bounded, and that we believe we are persistent
1927680	1933280	in time. So in this model, for example, we are at every moment in time, we're made of different
1933280	1940240	atoms of space, yet we all have the impression that we are experiencing things through that it's
1940240	1946160	still us a second later, so to speak, and that we experience things we are persistent, we have a
1946160	1952560	continuous thread of experience through time. Well, okay, so the really ultimately big concept
1952560	1959200	here is this thing we call the Ruliad. And so here's how this works. When we look at
1960800	1964960	these, this underlying hypergraph and its rewrite rules and all those kinds of things,
1965760	1973760	we can, we say, okay, there are these underlying rules. And if we run those enough times,
1973760	1978560	we'll eventually get something that seems like our universe that satisfies Einstein's equations
1978560	1983040	of general relativity, that shows the Feynman path integral for quantum mechanics, all those kinds of
1983040	1989760	good things. But we still might be asking the question, well, why did our universe get one
1989760	1996480	particular rule and not another? And that had me very confused for quite a while, until I realized
1996480	2003440	that actually we can think of the universe as running all possible rules. So what we imagine is
2003440	2008080	that there are these possible computational rules that can be used to update this hypergraph and so
2008080	2013920	on. But let's just imagine that we use all possible rules. What we get are all these different parts
2013920	2018800	of history that branched and merge and so on, corresponding to the application of all these
2018800	2025120	different rules. And this whole object that is the entangled limit of all possible computational
2025120	2032000	processes, we call the Ruliad. And the Ruliad is a completely unique thing. It is, it is you take
2032000	2037360	every possible Turing machine, every possible computational system, you run all of them, and
2037360	2042480	you run them in such a way that they are producing kind of, that they don't just have one possible
2042480	2047200	outcome, they have all possible outcomes. You might say, what an incredible mess, how could you ever
2047200	2051920	conclude anything from this Ruliad object? It is the case that this Ruliad object is a unique thing,
2051920	2056880	there's not, it's not like there's seven different Ruliad's, there's just this thing that is the
2056880	2061440	entangled limit of all possible computations. And so then the question is, well, how can you conclude
2061440	2066560	anything about, about this Ruliad object? Well, what you have to realize is the Ruliad object
2066560	2074160	represents everything that's possible, everything. And so, for example, we, as observers of what's
2074160	2081120	going on, we must be embedded within this Ruliad. And so what we can think of is that this, this
2081680	2093680	was I sharing the screen or did I stop sharing? Well, anyway, the, this, so the issue is we are
2093680	2099680	observers embedded within this Ruliad, observing the Ruliad. And the question is, what do we
2099680	2104720	conclude about the Ruliad? And the Ruliad is a necessary thing, there's no choice about it.
2105280	2112000	But the nature of us as observers is contingent, so to speak. And so what turns out to be the case
2112000	2119680	is that observers like us, observers that have certain attributes necessarily conclude that
2119680	2126160	necessarily describe the Ruliad in certain ways. So in a sense, by being an observer who is
2126160	2131680	computationally bounded, who believes they're persistent in time, those two attributes alone
2131760	2136320	are sufficient to tell us that the slice of the Ruliad, the way that we parse the Ruliad
2136880	2140080	is exactly the way that corresponds to the laws of physics that we know.
2140800	2145840	So in other words, what we're saying is you can derive the laws of physics, the laws of physics
2145840	2151440	are derived by starting with this Ruliad, which is a necessary unique object, and then saying what,
2152240	2156960	for observers like us, which happen to have the properties that we have of being computationally
2156960	2162720	bounded and believing we're persistent in time, any observer with those very coarse properties
2162720	2168000	will necessarily conclude that the universe operates according to Einstein's equations and
2168000	2172640	the path integral and so on. So that's a rather interesting philosophical conclusion.
2173200	2177600	Now you can ask, well, what would observers not like us conclude? Well, we don't know.
2178400	2185680	You can kind of, and that's sort of a question of how do we think about observers not like us?
2186560	2192400	Well, one thing to realize is we can think of in the Ruliad, we can think of different possible
2192400	2198080	observers as being sort of at different points in the Ruliad. There are different places in Rulial
2198080	2203600	space. Just like in physical space, we could be here on this planet, we could be on a galaxy on
2203600	2208000	the other side of the universe, we can be at different places in physical space, and each
2208000	2212160	different place in physical space will give us a different point of view about how the universe
2212160	2218240	works. Well, so it is in Rulial space, each different place in Rulial space will give us
2218240	2225280	a different point of view about how the universe works, how things work. So here's a way to think
2225280	2231280	about that. We can think of essentially different minds as being at different places in Rulial
2231280	2240800	space. It's as if, and these different minds are kind of experiencing possibilities in a
2240800	2246000	different way. So if we think about that in terms of, you know, the LLMs and so on, it's kind of
2246000	2251520	like we could imagine just having a differently trained LLM and that differently trained LLM
2251520	2258800	basically exists at a different place in Rulial space. So for example, minds that are sort of
2258800	2263600	similar and sort of similarly trained will be fairly close in Rulial space. Minds that are
2263600	2268000	different, like, you know, let's say cats and dogs, further away in Rulial space.
2268800	2273520	Minds, I tend to, I think that one of the consequences of the principle of computational
2273520	2278240	equivalence that I mentioned earlier is that one could sort of attribute mind like things
2278240	2283040	to lots of systems in the world and lots of abstract systems. And so for example,
2283040	2288720	when one says the weather has a mind of its own, in the principle of computational equivalence says,
2288720	2293440	yes, that's a meaningful thing to say. But in a sense, the mind that corresponds to the
2293440	2299280	weather is pretty far away from us in Rulial space. Also now there's a question, how do you
2299280	2304320	communicate across Rulial space? How do you, what is it what's involved in doing that? Well,
2304320	2309520	at some computational level, one point in Rulial space corresponds to sort of computing,
2309520	2313440	according to let's say one Turing machine, another point in Rulial space computing,
2313440	2317520	according to another Turing machine, another computer. We know that in principle, we can
2317520	2321440	make a translation from one place in Rulial space to another place in Rulial space takes
2321440	2325360	effort. We have to actually create that interpreter that's going to interpret the
2325360	2329760	instructions of one machine as the instructions of another machine. It takes effort in the same
2329760	2335280	way as it takes effort to move in physical space. In a sense, when we move in physical space in our
2335280	2340560	models, we're reconstructing ourselves at a different point in physical space. And by the way,
2340560	2344720	you can understand things like time dilation and relativity. There's a nice kind of mechanical
2344720	2349520	explanation of that. If you're always in one place, you're spending your kind of computation
2349520	2355520	budget figuring out what the next behave what the what the next stage you'll be in is. But if
2355520	2360720	you're moving, then you're using some of your computation budget to kind of recreate yourself
2360720	2366560	at a different place in space. And so that's used up having used up some of your computation budget,
2366560	2372960	you necessarily sort of moves go through time more slowly time time goes more slowly because
2372960	2378960	you used up some of your computation budget in moving in space. But in any case, you can you
2378960	2385200	can think of so so by the way, in our models, the possibility of motion is non trivial. It's not
2385200	2390240	obvious that you can you know pick up a glass and move it somewhere, and it'll still be the same
2390240	2395200	glass. That's something that we generally assume about the world that pure motion is possible.
2395200	2399520	But it's something in our models that you have to prove that pure motion is possible. And even
2399520	2405040	in traditional physics, if you're sufficiently near a space time singularity, for example,
2405040	2411280	no no material object will maintain its identity as you move it around that that singularity.
2411280	2416560	But in our models, the the possibility that that thing can just move, and that it's still the same
2416560	2423200	thing is non trivial. And actually, in a sense, the the particles of motion are exactly the kinds
2423200	2427600	of particles that we know about like electrons and quarks and so on. What is an electron an
2427600	2433840	electron in some sense in an abstract level is a lump that is capable of pure motion. It's something
2433840	2439440	where you can have an electron in one place, and you can move it and it'll still just be that electron.
2439440	2443440	So it's it's a particles are kind of the carriers of pure motion and physical space.
2444320	2450400	So here's a here's a thing in rural space, we can ask sort of what is motion in rural space about.
2451120	2456000	Well, in a sense, what what it means to have motion in rural space is you're effectively
2456000	2461200	transporting something from one mind to another if different points in rural space
2461280	2465840	correspond to the positions of different minds, you're asking the question, what does it take
2465840	2471600	to kind of transport things around rural space. And I think this is one of the very bizarre
2471600	2477040	kinds of things that one realizes is it seems to be the case that concepts are the analog of
2477040	2482000	particles. So what in physical space and an electron that doesn't change as you move it from
2482000	2489200	here to there, in rural space, it's the concept of a cat, for example, that can be moved from one
2489200	2494560	mind to another without change. I mean, the particular details of the neural firings that
2494560	2500320	exist in my brain, when I think of the concept of cat, in any of your brains, the particular
2500320	2506800	neural firings will be different. But yet, we can package up the concept of a cat, and I can say
2506800	2514000	the word cat, I can transport it to you, and then you can unpack it. And in your place in rural space,
2514080	2519520	you can end up with the same thing, so to speak. So it's kind of a way of understanding that that's
2519520	2525920	sort of the fundamental thing that's going on. And we can think of kind of concepts as being
2525920	2532960	the particles of rural space. Well, there are lots of lots of things I see I'm running out of time
2532960	2540320	here. But there are lots of things we can talk about about what, well, let me just say a couple
2540320	2549280	of other things about, I'll talk a little bit about AI. And I mean, the AI has had many different
2549280	2553680	meanings over the course of time. And many things where people have said, if we can only have that,
2553680	2559280	then we have AI are things that I've built as kind of pure computational systems. And then
2559280	2563280	people say, well, it's just a computational system, it's not really AI. And in more than seconds,
2563840	2569040	just one second, I want to, you do have more time, because for some reason, I can't explain,
2570160	2575840	Caillou, who has been extremely conscientious in everything, is not here, which may mean that he
2575840	2580960	had misunderstood being a discussant for being a member of the panel, which means he won't be here
2580960	2588320	until the panel starts, in which case you have more time, if you wish. I just compressed four
2588400	2592240	and a half decades into a remarkably short time, I hope people could follow it.
2592800	2596160	Nothing, you could have taken place at this time.
2599280	2602720	Well, okay, so let me let me finish what I was saying here, and then maybe we can
2602720	2609840	turn this over to discussion, which is more fun for me. So talking about kind of modern
2609840	2619520	AIs, and you know, to many people, modern AI is neural networks. And the, there's sort of a
2619520	2630240	question of, well, what can, how do neural networks relate to all of the things I've been talking
2630240	2636080	about? And one of the questions we can ask is, okay, we have, we have our friendly neural net
2636160	2639120	here, let's see, oops, share the screen and then,
2646240	2650240	okay, we have some typical trained neural net, let's say we're trying to train it,
2650240	2655680	let's say we're trying to train it to reproduce the sine wave. So what we're doing is we're going
2655680	2662400	to feed in the x value at the top there, and we're going to have set up these neural net weights,
2662400	2667360	and it's going to compute the y value down here. And actually, we'll do a pretty crummy job of that
2667360	2673040	typically. And you can, you can change the neural net, you'll get different kinds of behavior,
2673040	2677520	it's usually not particularly good at computing something like this. Well, so one thing you can
2677520	2683440	ask is, you know, neural nets, let's say if we have a big enough neural net, maybe we can break
2683440	2687440	computational irreducibility, maybe we can just predict what's going to happen in any kind of system.
2688400	2696320	That is not going to work. I mean, the way that a neural net of this type works, it's just having
2696320	2701600	kind of numbers ripple through the sequence of layers. And we're ending up with something where
2701600	2710320	you can, this is something trained, I used a modern transformer architecture and trained it
2710320	2714960	to try and recognize what was going to happen in a cellular automaton. And it has certain,
2714960	2718960	it says, well, there's certain probability of what's going to happen. But when the behavior is
2718960	2724320	pretty simple, it'll nail it. When the behavior is more complicated, it's like, I'm sorry, I can't,
2725680	2730080	you know, I can't figure that out. This is, this is different levels of training of one of those
2730080	2736720	neural nets. So in a sense, it's not surprisingly, the kind of very finite computation of these layers
2736720	2743360	of a neural net can't do the unboundedly large computation required to kind of solve a computationally
2743440	2749440	irreducible problem. And you can see that again. See, where do I have an example here? This is,
2749440	2756960	these are examples of the three body problem in celestial mechanics, Earth, Moon, Sun, all idealized,
2756960	2762080	all with interacting through gravity. You can ask the question, if you train a neural net,
2762080	2767200	can it correctly reproduce the behavior? The answer is the neural net is the kind of solid
2767200	2771760	line here, that's its prediction. When the behavior is fairly simple, yes, it can do it.
2771760	2774960	When the behavior is kind of computationally irreducible, no, it can't do it.
2775520	2782160	None of this is really very surprising. But there's kind of the question, for example,
2782160	2786880	when we look at something like chat GPT, and we say, oh my gosh, it actually worked, it produced
2786880	2792800	something that is like human language. How did that work? What I think is the main thing going on
2792800	2796720	is something which tells us a lot more about human language, probably, than it does about
2796720	2805360	neural nets. Because what it's telling us is, if we think about how does chat GPT work,
2805920	2812400	it's basically just saying, I'm going to predict the next word by figuring out certain probabilities.
2812400	2817680	And it's going to do that by, at the very simplest level, it might just do it, let's see if we've got
2817680	2823040	one here, might just do it by knowing the frequencies of different letters. And then,
2823040	2826320	if you just use the frequencies of different letters, you get pretty much nonsense.
2826320	2830080	If you use blocks of letters, you'll start getting more sensible kinds of things.
2830080	2836880	If you use kind of whole words occurring with the probability that they occur in English,
2836880	2843360	you'll get things that don't make much sense, but they're kind of things that can construct.
2843360	2849440	Now, the big thing that's interesting and surprising is that when you kind of train
2849440	2856800	a neural net from kind of all of the text, you know, a trillion words of text or something,
2857440	2863760	that the extrapolations it makes about what make meaningful sentences tend to agree with
2863760	2868720	the extrapolations that we humans would make about that. It's very similar to the fact that if we
2868720	2874720	train a neural net to recognize cats from dogs and images, that the distinctions it will make
2874720	2879280	seem to be similar to the distinctions we will make. At a theoretical level, if we say,
2879280	2884800	where's the dividing line between cat pictures and dog pictures? There isn't a good mathematical
2884800	2890240	characterization of where that dividing line is. It's really a question of where do we humans say
2890240	2894720	is a dividing line between cats and dogs? And the thing that's interesting about neural nets
2894720	2899040	is they tend to make the same kinds of decisions about that that we tend to make.
2899600	2903600	Probably the reason is that ultimately their architecture is similar to the architecture
2903600	2908320	of our brains. But the main point is that those kinds of distinctions, there's not a theorem,
2908400	2913280	there's no theorem that says the neural net will reproduce the distinction between cats and dogs,
2913280	2917440	because you don't know what the target is. The target is what do humans think is going on there,
2917440	2922640	and it does a pretty good job at that. So now the question is, in the case of language, what's
2922640	2932720	going on? And I think what's happened is that the thing that allows an LLM to produce reasonable
2932720	2937920	language is something that is a regularity of language that we could have recognized a long
2937920	2944000	time ago, but we didn't. And so we know certain regularities in language. We know that, for example,
2944000	2950720	in English, you tend to have sentences that go noun verb noun. But there are plenty of sentences
2950720	2956640	of the form noun verb noun that are total nonsense. So the question is, you have this kind of
2956640	2961760	syntactic grammar of language that says that you go things like noun verb noun. But now you have
2961760	2967600	the question of, well, what noun verb nouns actually make sense? And so what I think chat,
2967600	2972720	you know, chat GBT and LLMs and so on are kind of showing us is that there is also a semantic
2972720	2979440	grammar of language. There's also a construction kit, not only of what the parts of speech might be,
2979440	2984640	but also what kinds of words they might be to have them make sense. And that's something that
2984640	2989760	eventually kind of sort of expands up to write a whole essay and have these puzzle pieces fit
2989760	2995120	together in a way so that the whole thing makes sense. So, you know, in a sense, what one's
2995120	3002560	seeing and one can kind of look at, let's see if I have some pictures here. Maybe I have some pictures.
3004960	3009920	Yeah, these are from, these are very ancient, actually, there's better ones now for GBT-4.
3012240	3018240	What extent can you kind of imagine semantic laws of motion where you're kind of moving around in
3018240	3024480	meaning space, and where, just like Newton's laws tell you in physical space, how you move
3024480	3030240	from one, you know, how motion happens when in the absence of a force you just keep moving in
3030240	3035120	the same direction and so on. So you can ask questions about rural space, and you can ask
3035120	3042000	questions about kind of the structure of rural space and how that works. And I think we're kind
3042000	3046560	of learning some scientific things from the operation of LLMs about how that works.
3047280	3054800	Now, another question would be, so in other words, I think the reason LLMs work as well as they do
3054800	3058560	is because there are a bunch of regularities in human language that we kind of didn't know were
3058560	3064320	there and that we've never really codified. People started codifying these things back in the 1600s,
3064320	3069280	for example, people tried to invent these so-called philosophical languages that would be kind of
3069920	3073840	not specific to any particular language, but they would be things that sort of represent the
3073840	3079600	meaning of things without the specificity of particular languages. Well, actually,
3079600	3085120	I've had a project for a while now much more energetic to make what I call a symbolic discourse
3085120	3091120	language, a language where just like in Wolfman language, we have this computational language
3091120	3098160	that describes many aspects of the world. I mean, we might have all sorts of different
3099120	3108880	sort of categories of thing that we describe in our language. And the question is, can we kind
3108880	3120000	of describe all, can we describe sort of things that come up in everyday language? Can we describe
3120000	3125200	those kinds of things in a sort of precise symbolic way? And I have to say that I can't say I've got
3125200	3129120	the full answer to that, but it's going really well. And it's become clear, and by the way,
3129120	3136160	LLMs are quite helpful in this, to having a way to take something not the level of language where
3136160	3140640	we're actually putting words together, but the representation of the core meaning of what's
3140640	3146720	going on. Just like in our computational language, we have that representation of sort of the core
3146720	3151520	meaning of what's going on in a way that can be read by humans, but also executed by a computer.
3152320	3157600	So in any case, that's sort of one direction about things with LLMs and so on. Another question
3157600	3164400	that I was curious about is, okay, why does machine learning work at all? Why is it the case that you
3164400	3171360	can train one of these neural nets to do something like, I don't know, recognize digits or recognize
3171360	3177680	cats and dogs or generate language or whatever else? Why does that work? When I played around
3177680	3183440	with neural nets back in 1981, and I couldn't get them to do anything interesting. And I kind of
3183440	3186960	thought at the time, oh, if I've got a simple enough problem, I'll be able to get a simple neural
3186960	3193200	net to do things, didn't really work very well, wasn't very interesting. The big thing that got
3193200	3199600	sort of accidentally discovered basically in 2011 was that if you have a big neural net and you
3199600	3205200	bash it really hard, you show it enough training examples, it'll learn, well, lots of different
3205280	3210320	kinds of things, it'll learn almost anything. And the kind of the big meta discovery of modern
3210320	3215280	machine learning is that if you bash a neural net hard enough, it'll learn almost anything. We don't
3215280	3219920	know quite what the almost is. We can't really characterize what kind of thing it can learn.
3219920	3225280	For example, as I said, it can't break out of computational irreducibility. So there's limitations
3225280	3229680	to what it can learn, what it can do. But nevertheless, there's a broad class of things that seem to
3229680	3234480	correspond a lot to kinds of things that we humans can do easily that the neural net can
3234480	3243520	successfully do. And so that's sort of the meta discovery. The question is, why does that work?
3244240	3249600	Why is it the case that this neural net can be successfully sort of bashed into learning
3249600	3254880	things? Why doesn't it get stuck? Why doesn't it get to the point where you just can't get there
3254880	3260080	from here? You can't arrange it. Why is it the case that it's possible to do it and then why is it
3260080	3267280	the case that you can iteratively do it by sort of adaptively training it? I got interested in
3267280	3272400	this very recently, actually. And I don't know whether I can show you pictures. Let me see. I can
3272400	3276560	show you some things that I did recently. And then maybe I'll be able to pull up some pictures
3276560	3286560	just from the last few days that let me see here. Right. So actually, I decided to look at a simpler
3286560	3292000	problem, which is the problem of biological evolution, which is sort of another case of adaptation
3292800	3297920	that is a little simpler than neural nets. But let me explain what I figured out about
3297920	3302080	biological evolution. For a long time, I wondered what sort of the minimal model of biological
3302080	3306800	evolution was always very unsatisfied because models, you know, natural selection seems like a
3306800	3311120	simple principle. But when you actually try and make explicit models for it, you end up with all
3311120	3316720	kinds of hair about, you know, how many sub, you know, suboptimal organisms do you keep and all
3316720	3320800	this kind of thing. So I was interested in sort of a minimal version of that. So here's a version
3320800	3325440	of that. This is actually one of these cellular automata. It's got these rules here, starts off
3325440	3331040	from one red cell here. And with these particular rules, you get a pattern that lives for this amount
3331040	3339520	of time and then dies out. Okay, so let's imagine that you're interested in doing something where
3339600	3344960	you just keep on tweaking the rules, you keep on resetting the rules, you keep on making
3344960	3350880	single point mutations in the rules to try and get it to live longer and longer. This is what
3350880	3356560	happens. You start off from something that that is just a blank rule. For example, it dies immediately,
3356560	3360720	you keep tweaking the rule, you have to go through many different tweaks and so on. But
3360720	3364160	eventually you'll get to the point where it lives there for 50 something steps.
3364720	3368960	Well, and you can see that the sequence of mutations that got made there. And if you look at how the
3368960	3374800	fitness of this organism, the length of time it lived, varies as you go through all these
3374800	3380720	different sort of steps of adaptive evolution, you'll see there are, you know, it's going along
3380720	3386400	and there are many things that don't work out. But, you know, it'll kind of cruise along here at a
3386400	3391600	certain fitness, and then it makes a discovery. And then it can go to higher fitness. And actually,
3392560	3396480	you can end up with all kinds of discoveries that it makes. These are different sort of
3396480	3401200	paths of evolution. And you'll see that, for example, here, it's kind of going along and
3401200	3405920	eventually it manages to discover a lot. It manages to live a long time. You could sort of imagine
3405920	3411760	in the fossil record, you might find, you know, a critter from the Cambrian period that looks
3411760	3417280	like this. And then it uses that idea to extend further. And by the time it's in the Silurian
3417360	3422560	period, it's looking like this. And maybe it makes it to this in the Triassic period or something.
3422560	3427840	But what's happening here is that there are sort of, it's having progressively more ideas,
3427840	3433760	in a sense, about how to live longer in this particular case. And actually, you can even
3433760	3438960	go ahead, this is a simple enough system, that you can actually work out. Let's see, that's an
3438960	3444960	example of a better example. There we go. This is, this is the path of all possible paths of
3444960	3451760	evolution for a simple system like this. So every different picture here is a possible organism.
3451760	3456480	And the arrows show the possible adaptation paths. And what you see is something that's very much
3456480	3461120	like what happens in biological evolution. There are different branches in the tree of life.
3461120	3466320	There are, you know, one set of ideas leads to long life over here. In this way, a different
3466320	3471440	set of ideas leads to kind of long life over here in a different way. Okay, what does this have to
3471520	3478000	do with machine learning? Well, you can, you can ask the question, let me see if I can pull this up.
3478720	3484160	I am going to have to pull up something that I just made. So I'm not sure whether I can find it here.
3485040	3490640	Hold on, you can get hot off the press or not really off the press at all. Where is it?
3493520	3495520	Let me see. Maybe.
3502400	3506080	Maybe this will have it. Oh yeah, this is, this might be it.
3509840	3512560	This is a very minimal model for,
3516240	3524240	let's see if I can get this bigger. It's a very minimal model for a neural net where
3524240	3530480	it's actually a cellular automaton as well. But instead of having a fixed rule that it keeps on
3530480	3535600	applying kind of like a recurrent neural network, it has something more like a feed forward neural
3535600	3541360	network where you have a discrete choice of one of let's say two different possible rules. And at
3541360	3546240	every point in space time, so to speak, you're picking a different rule. And so then the learning
3546240	3550720	consists of, well, what's the pattern of rules you should pick to get a particular outcome. In
3550720	3555680	this particular case, we're trying to learn to live as long as possible. And what's interesting
3555760	3563760	here, and again, this is just raw off the literally raw material that from a couple of days ago,
3564960	3571840	this is kind of showing in a sense how the thing does what it does. So in a standard neural net,
3571840	3576080	it's just much more complicated to display what's going on. You've got these neurons with
3576080	3581440	continuous weights and you've got connectivity all over the place and so on. This is a much simpler
3581440	3585680	case. So you can kind of see more about what's going on. What's non trivial is that training
3585680	3591120	actually works in this case. And it does, you can find this arrangement of bits that will cause
3591120	3596160	the thing to do, I don't know whether I have it in this example here, but that will cause it to
3596160	3604320	learn, see if I have one here. Now those activation levels, well, it doesn't matter, but that will
3604320	3610880	basically cause it to learn something like, you know, to tell whether the number of bits at the
3610880	3615040	beginning is even or odd or something like this. And we actually even tried training this on the
3615040	3623200	MNIST training set, and it doesn't do too badly. So the point here, the thing that's interesting
3623200	3629840	here, these are all different solutions that this kind of very idealized neural net found
3630400	3637120	to living for this exact number of steps. What's interesting about these is they're very bizarre.
3637120	3642080	They're not sort of engineered solutions. They're not solutions where we can say, oh, yeah, let me
3642080	3646800	look inside and see how this works. Let me show you another example of that. And this is more back
3646800	3653040	to the biological evolution case. This is kind of all the different ways that a certain class of
3653040	3658240	systems manages to live a long time. And some of them, it's kind of pretty structured. You can imagine
3658240	3662640	sort of this was an engineered thing, but some of them, it's like it just seems to sort of happen
3662640	3669120	to live that long, and then it dies out. So in other words, there's a lot. And by doing this
3669120	3674880	sort of adaptive evolution, you're ending up finding these things which are very not,
3674880	3680000	they're not mechanical, they're not engineered kind of ways that things work. They're things
3680000	3688640	where kind of this is sort of what's happening inside. This is the thing that's going on,
3688640	3693440	but it's not something where you can say, oh, I've got a mechanism. By the way, if you're interested
3693440	3698720	in neuroscience, this is something you should pay attention to, because in a sense, if you're
3698720	3703120	trying to explain what's happening in the brain, and you say, oh, I'm going to figure out how this
3703120	3709280	works. Well, how this works is an attempt to have kind of a human understandable narrative
3709280	3714400	for what's going on. But if I were to look at these pictures in the background here,
3714400	3718320	if this was something going on in a brain, I might be able to say, okay,
3718400	3722160	I can have some human narrative about what's happening here. If this is what's going on in a
3722160	3726720	brain, it's just, well, it happens to work that way, and it happens to give this result. It's
3726720	3732640	kind of a computational irreducible story. It's something where there's no sort of narrative
3732640	3738080	mechanistic explanation. It's something which just works that way, and it's computationally
3738080	3742640	irreducible, but it just comes out in that fashion. And I think there's sort of an interesting question
3743200	3750720	for in machine learning. Why does machine learning work? Okay, so let's look at,
3752800	3760000	was a nice picture of that. By the way, this is in biological evolution. People often talk
3760000	3764800	about fitness landscapes. This is an actual fitness landscape correctly drawn, so to speak.
3764800	3769920	And you can start seeing all kinds of things about things evolving on fitness landscapes.
3769920	3776880	But the thing I really wanted to show you, here it is. This is kind of the local behavior
3776880	3784320	at a particular point in rule space at various steps in the adaptive evolution.
3784320	3789280	So what's happening here is at this step, for example, in the adaptive evolution,
3789280	3794960	here are different possible directions in rule space that you might go. And the ones inside
3794960	3798800	the circle are ones that are losers relative to where you've already got. They're ones that would be
3798880	3803440	live less long than what we have here, but there are some that would make progress.
3804240	3808320	And in fact, this is the one we happened to choose in this particular random
3808320	3812800	sequence of adaptive evolution steps. And that was the thing that made progress. So
3812800	3818160	the thing that is not obvious is in this sort of high dimensional space of possible ways you could
3818160	3822720	go, the question is, will you always be able to make progress? Will there be a direction that
3822720	3828160	makes progress? Or will you get stuck? Well, I think that this is again a computational
3828160	3834320	irreducibility story that basically what would make you get stuck? Well, if the structure of
3834320	3841200	this rule space was very orderly, very reducible and easy to predict, you might end up in a box
3841200	3847040	with very precisely defined walls and you just can't escape from that. But the presence of
3847040	3851920	computational irreducibility kind of implies a certain degree of unpredictability, a certain
3851920	3857680	degree of intrinsic randomness effectively in the structure of rule space. And that's what
3857680	3862720	means that in these high dimensional spaces, there's always a kind of a path to success.
3862720	3870320	So in a sense, I think computational irreducibility, which is a limitation on what one can do with,
3870320	3874480	for example, a neural net, what kinds of things computations one can expect to do,
3874480	3881440	is also the reason that training of neural nets, for example, can work. And so I think that's a,
3881520	3889920	anyway, this is still an in progress kind of investigation. But I sort of think it's
3889920	3893520	an interesting connection between a lot of different things I've talked about.
3893520	3901200	All right, I've gone on longer than I intended to. So let me wrap up there and I'm happy to
3901200	3906960	have a discussion, questions, whatever else. I just fed you an awful lot of material.
3907440	3911760	Yes, good. Let's first applaud this president.
3916640	3924160	The problem was that Kaiyou had an emergency during your talk, so he couldn't hear it.
3924160	3928880	Kaiyou, do you think that you have, from the background material you might have looked at,
3928880	3935520	you have a basis for saying something? Sorry, I missed most part of the time, so probably.
3936240	3943120	If you haven't seen, this is a large amount of material. I would be surprised if we could
3943120	3948960	have a useful conversation without having some anchor to this. Could you please explain to Kaiyou
3948960	3957280	and to me and to us how computational irreducibility differs from ABC,
3957600	3966080	the commagor of complexity, the church-touring thesis, and NP completeness.
3967120	3977200	Okay. All right, let's start off with Chetan Komogorov complexity. So when we look at a picture
3977520	3987520	like this, the algorithmic complexity of this picture is tiny. That's the program that's needed
3987520	3994320	to produce it, just a few bits. The thing that is remarkable is that even things with very low
3994320	4000880	algorithmic complexity are very complicated. In fact, they're complicated enough that to us humans,
4000880	4005840	we wouldn't even be able to distinguish them from things that have high algorithmic complexity.
4005840	4009920	One of the things I've had a long-running discussion with my friend Greg Chetan,
4009920	4016480	where the question is, is the universe like Pi or like Omega? Omega is this thing that Greg
4016480	4022480	invented 50 years ago, actually, that is the halting probability for a universal Turing machine.
4022480	4029600	It's a fundamentally non-computable object. It's an object with infinite algorithmic complexity.
4029680	4037520	It is a thing where there is no small program that you can't specify it by a small program.
4037520	4044560	Pi, on the other hand, is a thing that is specified by a quite a small program.
4046400	4050080	Once you generate its digits, it looks for all practical purposes random.
4050080	4055680	So the question that one can ask is, in our universe, is there anything of high algorithmic
4055680	4062400	complexity? Or is the whole universe actually a thing that is like Pi generated from something
4062400	4069440	which is a very simple underlying sort of program? And in our model of physics, the answer is the
4069440	4076400	universe is like Pi. The universe is something that is generated from a thing of very tiny
4076400	4082080	algorithmic complexity. So that's kind of the distinction between everything I'm talking about
4082160	4087120	is things of incredibly low algorithmic complexity. The remarkable fact that is not obvious,
4087120	4091760	it kind of breaks one's intuition, is that things, very simple programs, things of very
4091760	4097600	low algorithmic complexity can produce what seems to us like great complexity. And the
4097600	4104320	seems to us becomes much harder when we start talking about our computational boundedness.
4104320	4109680	It's not the case that it's just, oh, it seems complicated. It's that for a computationally
4109680	4117600	bounded observer like us, there is no way to compress it. So in algorithmic complexity,
4117600	4122560	algorithmic information, when saying this is the program and there is no shorter program,
4122560	4128000	one can say for a computationally bounded observer, this is the set of bits and there is no way to
4128000	4135040	make it shorter. So that was algorithmic information theory, algorithmic complexity.
4135040	4144480	I think the second one you had was, what was it? Church Turing. Okay. So, okay. The thing that,
4148240	4152960	if you go back to the beginning of the 20th century, and you'd wanted to get an adding
4152960	4157920	machine, you might go to a store, you buy an adding machine. You want to get a square root
4157920	4162240	machine. Okay, you go to a different store, perhaps, and you buy a different machine that
4162240	4167120	is the square root machine. The big discovery that actually originally got made by Moses
4167120	4172320	Schoenfinkel with combinators in 1920, but nobody understood it then or since, basically,
4172320	4180640	but then kind of got clarified by Turing in 1936 is that there exist kind of,
4182560	4187520	there exist systems that are universal in the sense that you can have a single piece of hardware
4187520	4191440	that by feeding it different initial conditions, by feeding it different inputs,
4191520	4196640	you can make it compute different kinds of things. So, for example, you can have a Turing machine
4196640	4202960	that has some, where just by feeding it different initial conditions, it will emulate any other
4202960	4210400	Turing machine. So, for example, if we go to, in terms of Turing machines, there's some, I'm going
4210480	4222880	to show you something. There we go. Well, so, the big point is there exist machines that are
4222880	4227680	universal in the sense that they can at least emulate all other machines of their type. The thing
4227680	4232880	that then became clear, starting in the 1930s, is that Turing machines, you can have a Turing machine
4232880	4237280	that emulates every other Turing machine. It also, by the way, can emulate every register machine,
4237280	4244480	every piece of lambda calculus, every combinator and so on. So, there's this notion that in the
4244480	4250320	class of computational devices, there's a certain degree of universality. People had not thought
4250320	4257680	that that extended to physics. That was the thing that basically was my effort in the 1980s was to
4257680	4265040	kind of imagine that this notion that what is computationally computable would also be what
4265040	4270160	is what can happen in physics. People had sort of assumed that physics kind of breaks out of
4270160	4274480	kind of this computational paradigm. It has real numbers, precise real numbers, has other kinds
4274480	4280000	of things like that. So, the first thing is the realization in the principle of computational
4280000	4285840	equivalence. The first thing is kind of the claim that, well, first part of it is sort of the
4285840	4291440	physics part that, yes, actually, in the physical universe, this is all we've got. We can't say,
4291520	4299200	oh, we're going to make an analog computer that jumps beyond kind of the church Turing level.
4299200	4305840	Second point is this. People imagined that to make a universal machine was a complicated
4305840	4311680	matter. It was something that would be kind of, you have to build this whole microprocessor. It
4311680	4316400	might have a billion gates in it. It has all these instructions. It's got if statements. It's got all
4316400	4321120	this kind of structure. And the question is, well, what's, you know, is that really necessary?
4321120	4326240	Or is universal computation actually something much more naturally occurring? Is universal
4326240	4330320	computation a special thing? Have to go to a lot of trouble to get? Or is it something that's just
4330320	4334560	sort of lying around the computational universe? One of the big points to the principle of
4334560	4339120	computational equivalence is, yes, it's just lying around the computational universe. So,
4339120	4345360	for example, if we look at these different possible rules here, some of them behave in
4345440	4348480	such simple ways that we can readily see what they're going to do. They're computationally
4348480	4354080	reducible. There's nothing more to say. But some of them behave in a complicated enough way
4354080	4358400	that we're kind of not really sure what they do. Let me show you an example of one of those. So,
4358400	4367600	this is, let me show you rule 110. This thing actually only grows on one side here, but
4368880	4373280	just show that. I shall make it, just show just the part where it's growing. So that's,
4373760	4379040	after 200 steps, let's run it for 1,000 steps. Okay, there it is. It's a little bit unclear what
4379040	4383600	it's going to do. This is kind of computational irreducibility in action or undecidability,
4383600	4387760	ultimately in action. What's it going to do? Is it going to have all those little things,
4387760	4390480	structures? Are they going to survive or are they eventually going to die out?
4391120	4397200	After, I think it's about 4,500 steps, they do eventually all die out and they just get left
4397200	4401680	with this one single structure here. But this kind of computational irreducibility in action,
4401680	4407040	you can't tell what's going on. This particular rule turns out, if you just look at it, let's
4407040	4415600	start it off from random initial conditions. Let's say 600 across. No, let's say 1,000 across.
4416800	4425280	And let's say 800 down. Okay, oh boy. It's a little bit on the screen here. Let me
4426240	4433040	make it a bit bigger. Okay, there we go. So what you see there is that's the initial condition.
4433680	4438640	This is what happens. What you see is a bunch of little structures here. And you might imagine as
4438640	4442320	you look at these structures, oh, they're kind of interacting and maybe that's like a logic gate
4442320	4446960	and maybe we can make an OR gate out of this and so on. But it turns out with considerable
4446960	4452400	effort, you can do that. And you can show that rule 110, which is kind of just the 110th rule
4452400	4457120	in this very simple enumeration of possible rules. It's universal. The first one that you
4457120	4462240	might imagine could be universal is actually universal. So in a sense, you know, the church
4462240	4466640	touring thesis is saying it is possible to have a universal machine, at least universal within the
4466640	4470400	class of computational devices that we're talking about. The principle of computational
4470400	4475360	equivalence says not only is it possible, it's also generically the case it is ubiquitous.
4475920	4480800	And in fact, it goes on to talk more about individual computations rather than
4480800	4485920	programmability, but that's kind of a bonus. By the way, in terms of touring machines,
4485920	4490080	I was very curious what is, you know, if you just look out in the space of possible touring
4490080	4495280	machines, just start enumerating touring machines. The first one whose behavior is not
4495280	4499920	obviously simple as this one here that I found sometime in the 1990s. And so then I was really
4499920	4507200	curious, is this in fact a universal machine in 2007? I put up this little prize and a chap called
4507200	4513920	Alex Smith managed to show that yes, this particular touring machine, the first conceivably
4513920	4518560	universal touring machine actually is universal, which is a nice piece of evidence for the principle
4518560	4524160	of computational equivalence. So that's kind of the relationship between church touring and
4525280	4530400	principle of computational equivalence. And computational irreducibility is something that
4531040	4538720	is sort of, it's made tougher by the fact that this property of universality
4538720	4544160	is ubiquitous in the computational universe. Okay, thank you. MP completeness. What's that?
4544720	4551600	We have a question here already, so. Wait a second. You get me. My software is not empty yet.
4552000	4558640	So you asked about NP completeness. So let me try and address that. So
4560880	4567760	normally, in a touring machine, for example, you have this touring machine, it has a rule,
4567760	4574240	you started off from some initial condition, it just evolves in some specific way. It has a specific
4574240	4578880	history. But you can also have, let's see if I have a picture of this.
4595440	4598800	I have a bunch of these multiway systems. Well, here, let me show you
4605200	4607200	a tag.
4618400	4624880	Find some multiway touring machines. There we go. Multiway touring machines. Okay. So
4627520	4631520	that's a typical touring machine. It has a rule, it evolves in a particular way.
4632240	4636960	But you can also have a multiway touring machine in which there isn't just a single
4636960	4640640	possible path of evolution, but there are many paths. So you can end up with this
4640640	4644800	kind of branching structure. This turns out to be closely related to what happens in quantum
4644800	4652080	mechanics. That's a separate issue. But so this idea of NP completeness, NP problems versus
4652080	4658000	P problems and so on, it's this question. If we have a touring machine and it computes something
4658080	4662560	and it takes a certain amount of number of steps to compute it, an ordinary touring machine
4662560	4668160	might take n squared steps to compute a size n version of some problem. But we can also have
4668160	4673200	a non-deterministic touring machine. We can have a multiway touring machine that follows many
4673200	4679040	different possible paths. And we say, if we have a path that gets to the answer, then it's a winner,
4679040	4684320	so to speak. And that's the story of NP problems, non-deterministic polynomial time problems,
4684480	4690720	ones where there exists a path in this multiway touring machine, which gets you to that answer.
4691520	4700480	So in a sense, this question of NP, sort of the big question, is P equal to NP? Is the class of
4700480	4708640	problems that you can solve with in polynomial time with an ordinary touring machine, the same
4708640	4713440	class or different class, than the ones that you can solve with a non-deterministic
4714080	4722240	with a multiway touring machine? And actually, that question, so, well, let's see. I mean,
4722240	4726080	we can talk about computational irreducibility and its relationship to computational complexity
4726080	4731520	theory in general. But NP completeness in particular, there's perhaps a more interesting
4731520	4748160	thing to say, which is, if I can find this one. Okay, so we can look at all possible touring machines.
4748160	4756800	This is in a sense in rural space. Where is this? Nice picture somewhere here. Do I? Yes, here we go.
4757360	4761680	Okay, so this is a picture of kind of the behavior of all possible multiway touring
4761680	4768320	machines. So in a sense, all possible programs. And this is showing sort of all possible
4768320	4775600	non-deterministic programs. The red part is the part that's showing deterministic programs only.
4775600	4780240	It's not allowing the possibility of the rules changing, so to speak, as you go through the system.
4781040	4785280	So the P equals NP problem, one of the things that's pretty interesting that comes out of
4785280	4791680	our physics project is essentially a geometrization of the P equals NP problem. That is a question
4791680	4800000	of the structure of these objects in rural space, that P equals NP becomes the question of
4800000	4805280	whether essentially the red bit here eventually fills out the gray part of this picture. So you
4805280	4810800	can kind of have a geometrical version of this ball in rural space that corresponds to the
4811760	4817200	P problems and the NP problems. So that's a little bit of an indication of that. But you can,
4817200	4824880	I mean, this whole question about non-determinism and so on, it's a, oh gosh, there's much to
4824880	4834400	say about that. I've studied this a lot because it ends up being sort of a proxy for quantum
4834400	4840000	mechanics. What happens in quantum mechanics is that you are following many paths of history
4840000	4845360	and the observer in quantum mechanics is effectively a sort of an interesting situation.
4845360	4850000	The observer is branching in the same way that these actual paths of history in the universe
4850000	4854720	are branching. So quantum mechanics becomes this question of how does a branching mind
4854720	4859920	perceive a branching universe? And so it's interesting to kind of see a bunch of different
4859920	4864640	examples of multi-way systems as a way to get sort of more intuition about that.
4865440	4867120	Okay, another question, apparently.
4868560	4875040	Well, let's bring it back to our universe just for now. I want to, if possible, in a few minutes
4875040	4880560	left, because I don't want to say anything. I want to make a connection between what you said
4880560	4890800	and what Kyle, what Kai you said before. His program was related to computer aided proof
4891520	4900160	and transformation of verbally stated truths and conjectures into
4901200	4908000	formal form called auto formalization. And my question to you is what does the irreducibility
4908000	4914320	principle say about all the possible theorems and all the possible paths to their solution?
4914320	4920960	And Kyle, you can say a couple of words in response, but you have to say it in your own
4920960	4926400	words first because you missed your talk. Well, let's see, I wrote a book recently about the
4926400	4934080	physicalization of metamathematics, which I think is pretty relevant to this. And so, you know,
4934080	4940400	we can imagine some, let's see, where's a good example? This is that might be some axiom in a
4940400	4945520	mathematical system. And we can ask the question, what are the consequences of that axiom? That
4945520	4952160	axiom is saying x dot y is equivalent to y dot x dot y. And now we can say, well, what things are
4952160	4958640	also equivalent based on that axiom, we can start figuring out. So every path here is a theorem,
4958640	4964240	that that's equivalent to that. We can start just following, we can start making this network
4964320	4974480	of all possible equivalent things. And actually, and so a proof becomes a path in this whole network.
4974480	4977600	And actually, it's a little bit trickier than that when you start looking at,
4979280	4987040	there's a good example here. The way one actually does, let's see where I've got a good example.
4987040	4993280	Okay, so this is an example of what more is actually what's happening in mathematics. You have
4993280	4999840	basically, let's say two axioms here, and you are combining them to get a new theorem. And so you
4999840	5005520	can kind of build up this kind of this structure you get with those two green axioms, you're,
5005520	5011200	you're deriving all those theorems, you get this big network that represents all possible
5011200	5016560	theorems derived from a particular set of axioms. So you can go on, you can get pretty complicated
5016560	5022000	versions of this, you can derive all sorts of theorems that are true based on certain axioms.
5022000	5028960	And what's happening is in this, in this graph, the every blue dot is a theorem. Okay. So then you
5028960	5038080	can ask the question, if you look at, do I have an example of this? If you look at actual axiom
5038080	5043360	systems in present day mathematics, so for example, you can look at, there's the axiom for semi-groups.
5044080	5048400	You can start proving theorems about semi-groups. Okay, so we've got this whole network of theorems
5048400	5054800	about semi-groups. And so one big question is, if you do that, well, okay, so here's, here's an
5054800	5060720	example based on the axioms of Boolean algebra. So this is proving theorems based on axioms in
5060720	5065920	Boolean algebra. And you can go and you can build up this giant network of theorems of Boolean
5065920	5071600	algebra. And this is, this is kind of the, the enumeration of all possibilities. Okay. So now
5071600	5076160	the question is, is we enumerate all those possibilities? Where are the theorems we care
5076160	5081440	about? We've got gazillions of theorems that we can just build out eventually. And this is kind
5081440	5086480	of spoiled. If you didn't know, you don't haven't followed this, but this really odd object that
5086480	5092320	I talked about in the talk I gave, that is the ultimate limit of all possible mathematics is
5092320	5099760	this really odd object. And the question of what theorems are, so all these theorems here are true.
5099760	5104160	All these theorems can be constructed from the axioms. But these are the only two theorems that
5104160	5110720	people give names to in textbooks of logic out of this collection. We can keep going. We can find,
5110720	5115280	we can go to, to lots of other theorems. If we, if we use a theorem proving system,
5115280	5120080	we can, in that big giant explosion of possible theorems, we can go and say, this is the theorem
5120080	5125280	we're searching for, and we can find a path to it using, using theorem proving. And those are the
5125280	5133920	paths in that, in that structure of, of, of possible theorems. Okay, so one question then is,
5134800	5140800	well, out of all these possible, this, this complicated network of all possible theorems,
5140800	5146720	where are the ones that we humans care about? And so I looked a little bit at that. And so,
5146720	5152400	for example, you can, you can look, well, that's, that's, for example, that's Euclid. So Euclid
5152400	5158160	has 465 theorems. And you can start off from the axioms at the top. And you can see what are the
5158160	5163600	connections between those theorems, according to the proofs in Euclid. Perhaps more interestingly,
5163600	5171040	you can take a proof of existence system. I looked at lean. I looked a little bit simpler
5171040	5177360	to look at the system called metamath, which is a formalized math system. And you can ask questions
5177360	5183920	like, well, that's the Pythagorean theorem, proved from the axioms in metamath. And you can see
5183920	5188080	they're a different, it's a pretty complicated thing. This somewhere, I think at the bottom here
5188080	5192400	is the Pythagorean theorem. And you start from the axioms there, and you can kind of count up
5193120	5197840	of the various axioms, you know, how many times did you use the axiom of equality?
5197840	5204080	Five times 10 to the 31 times. This is a, you know, this, this is kind of a, a, this is what
5204080	5209200	happens if you start from sort of the axiomatic foundation, and you build up to something like
5209200	5216000	the Pythagorean theorem. So, okay. So one interesting point here is this is the axiomatic
5216000	5220640	sort of structure of the Pythagorean theorem. The question is, do mathematicians care about this?
5221360	5225600	So, you know, a decade ago, I was very interested in formalization of mathematics. I organized
5225600	5230720	this conference. We invited all these formalization of mathematics people, all these people interested
5230720	5235600	in mathematics itself. The formalizers all showed up. The mathematicians didn't show up.
5237600	5241440	And so the question is, what does a working mathematician actually do? You know, working
5241440	5247680	mathematician who's, who's thinking about the, you know, the Pythagorean theorem, are they
5247680	5252240	thinking about it in this kind of axiomatic way? Are they drilling down to kind of this, this low
5252240	5256160	level axiomatic structure? Or are they just saying it's the Pythagorean theorem and I'm going to do
5256160	5259840	things at that level? The thing that's pretty interesting and relates to a lot of what I was
5259840	5266000	talking about is at this kind of axiomatic level of mathematics, it's kind of like molecular
5266000	5270560	dynamics in a, in a fluid. You've got all these molecules bouncing around. They're doing all these
5270560	5275920	complicated things. But then at the higher level, at the more human level, what we get to see is
5275920	5281760	fluid dynamics. And we can ask the question, can we make conclusions at the fluid dynamics level?
5281760	5286640	Or do we get dragged down to the molecular dynamics level and have to address things at that level?
5286640	5290800	So in the question of, you know, using the Pythagorean theorem, for example, do you need
5290800	5295520	to go down to the level of these axioms and worry about how you define the real numbers and so on?
5295520	5300160	Or are you actually operating in practical mathematics at a higher level, at this level,
5300160	5309760	where you're, you're just operating in terms of, of, of these kind of sort of fluid dynamics
5310000	5316240	concepts? So I have to say, I was curious in, you know, in the, in sort of the world of LLMs and
5316240	5322880	so on. So I will say that the mission of taking kind of a piece of informal mathematics and
5322880	5328480	formalizing it seems like a fairly, fairly promising use case for things like LLMs.
5329600	5334960	I don't know whether the formalization in terms of, you know, existing proof assistance and so on,
5334960	5340400	I don't know how useful that will really end up being. I was curious whether you could use
5340400	5355920	LLMs as a way to, as a way to, to kind of guide theorem proving. So I looked here at, here we go.
5356480	5361520	May I make another suggestion instead of looking at, let Kai answer, just a second,
5361520	5363920	because there's so little time now we can continue in the back.
5363920	5368720	Please. Am I, let me just ask a very practical question. I have another thing in 30 minutes.
5368720	5372800	Am I, I could push it back, but am I going to make that or not?
5372800	5378320	Yes. The other thing in 30 minutes is the plan, is the panel where you, where you plan,
5378320	5378800	Oh really?
5378800	5380400	The panel, are you going to do something else?
5381760	5384640	Well, I don't know. It really depends, but go ahead.
5384640	5387120	Danielle, Danielle said that you were going to do both.
5387680	5388480	Okay. All right.
5388480	5393040	I think she, if you got the other thing from Danielle, it is in fact the panel.
5393120	5398000	No, no, no. It's a completely different thing, but that's okay. We'll, we'll, we'll tell you a panel.
5398000	5398480	That's great.
5399200	5399680	Say this.
5400400	5406240	Yeah. I think the short answer is yes. Yes. People are using informal mathematics and
5406800	5411280	auto formalization, which means translating informal to formal to guide theorem proving.
5411280	5415680	For example, given a proof, you can use language model like GPT-4 to,
5415680	5420000	you just ask it to generate informal proof or even a sketch, some ideas of,
5420960	5423600	could be high level idea of how this proof might go.
5423600	5426320	And then conditioned on this informal sketch,
5427040	5430640	you, there will be a second step to generate the formal proof.
5430640	5436400	And, but I think a caveat is if you rely on auto formalization to give you the proof,
5437360	5440640	it only works if human already discovered this proof.
5442320	5447440	Because then there's no, if not, if it's completely alien to mathematics,
5447440	5449200	then there's nothing for you to auto formalize.
5450240	5454720	I think another direction related to what Stephen mentioned is,
5455680	5461040	how can we even take one step further? Can we use language models to generate conjecture?
5461040	5464560	Like generate the huge graph Stephen was mentioning.
5465200	5470880	But of course the graph, I think it might be infinite or it may be simply too big.
5470880	5476000	So a really interesting question I want to maybe learn from Stephen is
5476720	5483040	say we want to generate this graph, but how do we tell if a node is worthy?
5483040	5488880	Like if a math statement is interesting, because I imagine in this infinite graph,
5488880	5493520	most of the nodes will be just garbage, like two greater than one, three greater than two.
5493520	5496400	But we really want to focus on this interesting nodes.
5497040	5502080	Yes, it's an interesting question. So I've looked at this a bit and I can tell you that in the case
5502080	5507440	of Boolean algebra, there is a criterion. So maybe I can pull up a picture of that.
5508640	5524640	If you order, here we go. Hold on. Let's see. If you order the theorems of Boolean algebra
5525360	5533520	in lexicographic order, then you can ask which are the theorems of all possible theorems? Which
5533520	5539920	ones are given names in logic textbooks? And sort of a surprise to me is the theorems that
5539920	5544400	are given names in logic textbooks are the theorems that have, in this case, no back links.
5544400	5548720	So there's a backlink from this result here, which might be one of your boring results.
5549440	5554240	This result is derivable from something earlier in this lexicographic list.
5555120	5560160	So in a sense, it gives you no new information. It turns out the ones that get given names
5560160	5564640	are precisely the ones that do not have back links. They are not derivable
5564640	5570800	from lexicographically simpler theorems. So in other words, I was surprised that I discovered
5570800	5575360	this sometime in the 90s. I was surprised by this, that there was actually a criterion
5575440	5580080	for what would be given a name in a logic textbook. Now, the general case of is this
5580080	5585280	theorem interesting? Can we learn enough about the humans to know what they'll think is interesting?
5585280	5589440	It's a good question. I mean, by the way, in this connection between formal and informal,
5589440	5595200	obviously, Wolfram language gets connected to LLMs. And we've done lots of work in kind of
5595200	5600800	tool calling from LLMs to Wolfram language. And there's this whole question of, can you take,
5600960	5605840	to what extent can you get the LLM to crisp things up to the point where you can, I don't know,
5605840	5614160	I mean, if I say something like draw a pentagon and a hexagon, for example,
5615200	5620160	let's see what it does. I don't know if it'll figure it out or not. It might be able to,
5621120	5632080	we could, the question is, can we generate a, can we turn that informal statement into a piece
5632080	5640000	of formal Wolfram language code? Okay, not bad to manage to do that one. And if we look here,
5640000	5646640	I'm sure we can get it to, there we go. So that showed us the actual code that did that,
5646640	5651440	wouldn't have been the way I would have done it, but it's okay. That's a reasonable way to do it.
5651440	5655760	But so this is a case where we're going from an informal description to this computational
5655760	5659920	language, which we can then compute from. And that's a very powerful thing to do. And in fact,
5659920	5664160	we even have a product that's coming out soon that is based precisely on that idea.
5665280	5671920	But so I think this question of whether you can sort of, can you guide the proof this way?
5671920	5677840	I suspect you can. Now this question of what is a human proof, what's, okay, this is an example.
5677840	5683200	So in automated theorem proving, one of the shocking things about automated theorem proving,
5683200	5688000	I believe you might correct me and tell me, one day somebody is going to tell me I'm wrong about
5688000	5694560	this. But so far as I know, essentially all the theorems that have been proved by automated
5694560	5699280	theorem proving were theorems that somebody already believed were true. In other words,
5699280	5705200	there is no newly discovered thing that came from automated theorem proving with one counter
5705200	5710400	example. The one counter example is something I found 24 years ago now, which is this is the
5710400	5717120	simplest axiom system for Boolean algebra. So you can think of that as a NAND operator.
5717120	5723760	This is of all possible from that one axiom, you can derive all the true statements of Boolean
5723760	5732400	algebra. The proof of that is this long 100 step automated proof. Let's see if I have a picture
5732400	5736800	of it. Yeah, I mean, that's sort of some kind of visual representation of that proof. It has
5736800	5742560	various popular lemmas in it and so on. In the last 24 years, despite quite a bit of effort,
5742560	5747840	actually, nobody has ever understood this proof. But it is interesting because it is a proof of
5747840	5753600	something surprising, potentially interesting, depending on whether you care about simplest
5753600	5760480	axiom systems for things. But it was found by automated theorem proving without already knowing
5760480	5767280	what you were searching for, so to speak. And that's a case where now you ask the question,
5767280	5774560	if you're out in the wilds of, I mean, we can look, I have a nice picture of this,
5774560	5785120	we can look at, oh, here, is that one? Yeah, this is, these are axiom systems down the left.
5785840	5793120	Those are theorems across the top. And there's a dot, a blue square, whenever that theorem
5793120	5799280	is true in that axiom system. So we can ask the question, given an axiom system that we decide
5799280	5804240	is exciting, and how we decide that is an interesting question, it's unright. But given an axiom system,
5804640	5810240	we can say, here are the theorems that are true. Now, which are the theorems here that we care about?
5810880	5816240	And that's essentially a model for humans. And I think it's an interesting question. We've done
5816240	5821600	some experiments kind of grinding up archive and so on, and trying to figure out, can we deduce
5822240	5828160	what, in a space of possible theorems, what theorems are likely to be interesting? I don't
5828160	5833040	know if you've looked at that. Is that, I think that's an interesting thing to look at. Have you
5833040	5845600	looked at that? Yeah, I think the way I'm looking at it is more, so I kind of am not considering
5845600	5853360	its relationship with other theorems. I'm taking the theorem statement itself and try to have some,
5854080	5858240	for example, have the language model telling me whether it's interesting. I believe the language
5858240	5865760	model can look at some kind of superficial cues, like how long the theorem is and what are the
5865760	5872000	variables, how they are arranged, how messy it is, and which can already give us some way of
5873360	5879200	judging how interesting it is. But I agree, like maybe ultimately what an interesting theorem is,
5880480	5886400	it can help you prove a lot of other theorems. Is that your definition of an interesting theorem?
5886400	5893920	I'm not sure that's right. I mean, in other words, that is one possible way, I guess.
5895280	5899600	There are many different criteria you can imagine for interestingness. That particular one
5899600	5905120	would be saying that if that was the correct criterion, then what you could do,
5906240	5910080	like I was just showing that picture, actually, in the Boolean algebra case,
5910640	5919840	wherever it is, then I would deduce from your statement that the theorems that are big here are
5919840	5926320	the ones that have many, those are the high-out-degree theorems. In other words, those theorems,
5926320	5931520	that theorem there should be the one I should care about. I don't understand these theorems,
5931520	5938960	honestly. What's that? I mean, in that sense, yes, because they are special in this graph.
5939680	5947200	That's right. But the question of whether those are human useful is, I think, a different question.
5947200	5953680	I mean, in other words, what is, you know, there's this question. It could be the case that two,
5953680	5959280	okay, first question is, if you look at many different possible things you might prove,
5959280	5965200	you can ask the question, are there repeated theorems that often, are there repeated lemmas
5965200	5971680	that often come up in those proofs? Okay. So I looked at that. And the answer is there are.
5972320	5979920	And so, for example, that axiom system of mine for Boolean algebra, if you use it to prove
5979920	5985200	theorems in Boolean algebra, you can just look at what intermediate lemmas does a theorem prove
5985200	5990080	are typically proved to make progress. And the answer is, for example, it takes it 100 steps
5990080	5995040	to prove the commutativity of NAND, and it often does that and then goes on and does other things.
5995680	6000240	So in that sense, you know, you can, I mean, it is an interesting experimental question.
6000240	6004720	To what extent are there repeated lemmas that show up? And that might be a criterion,
6004720	6008800	but that's a criterion that has nothing to do with LLMs and so on. That's a criterion that just
6008800	6017280	has to do with the mathematical graph. I think this question of, you know, if we look at images,
6017280	6022960	for example, you didn't see what I was showing earlier, but here I'll pull up a,
6024720	6030880	I was just showing something like this. This is in, you know, embedding space of a
6030880	6036640	generative AI system with in the middle is the cat in the party hat, then there's sort of a cat
6036640	6041920	island of cat-like things, and then you're out in sort of inter-concept space that we have not yet
6041920	6047600	explored. And so you can imagine the same kind of thing for mathematics. You say, here's a theorem
6047600	6053920	that somebody wrote down. Let's sort of change the embedding in some sense and say here are nearby
6053920	6061440	theorems that weren't necessarily, you know, where is the island? How far out does the island of
6061440	6067600	interestingness go? What happens in this kind of inter-concept space between this theorem
6067600	6071360	that we thought was interesting and this other one we thought was interesting? So I mean, I think
6072160	6080880	it's a, I mean, let's take an example. Let's say, I don't know, let's take, well here, we've got,
6080880	6085760	you know, these are random pictures generated in inter-concept space that maybe are of things
6085760	6090160	that we care about. I don't know. I mean, that one on the right, we might kind of think it's,
6090160	6094640	I don't know what it is, but you know, it was just generated by a generative AI.
6094640	6099200	And similarly, imagine that was a theorem. The question is, is this a theorem that we care about?
6100160	6102720	You know, it's just like, is this a picture we somehow
6103840	6110640	seems relevant to us? And I think, you know, this question of whether, I mean, if we look,
6111280	6115760	one of the things that's sort of interesting that one can do is to kind of look at this whole space
6116640	6124240	of, let's see, we can kind of look at metamathematical space and we can kind of ask,
6125200	6131120	let's take a look here. I think I had a nice picture and find it. I mean, we can ask all sorts
6131120	6138400	of questions about different possible proof structures, which are, that's a meta mathematical
6138400	6144720	thing, but let's see if I can find a picture here. Yeah, that's a picture of, I think this is
6144720	6153440	from metamath. This is empirical metamathematics. It's asking, in the space of all 200,000 theorems,
6153520	6160800	discussed in, you know, presented in the metamath corpus, where do these famous theorems of mathematics
6160800	6166480	lie in that space? So it's kind of asking this question that this isn't all possible theorems.
6166480	6174160	This one is reduced to just the ones that are in the, I think it's set dot mm corpus for metamath.
6176560	6180240	But, you know, this is again related to this question of where are the ones,
6180240	6184560	where are the ones one cares about, so to speak. And you can kind of, well, you can kind of see,
6184560	6188560	this is kind of how the different theorems and different areas of mathematics kind of
6189360	6192560	get related to each other. But I think it's a really interesting question. What,
6193840	6200560	you know, and you mentioned that, I mean, I suspect LLM is a really good at picking up on
6200560	6206960	cues from humans. And so I'm sure there's ways that people will write their master theorem.
6206960	6211200	You know, they'll make, there'll be more trumpets blaring when they present the master theorem in
6211200	6216320	their paper than when they present a little lemma. But here's a good question. Here's a question.
6216320	6223680	If you try and make this, this is an easy thing to test. Okay. Can an LLM classify,
6223680	6229120	given a statement, can it decide whether the, whether the author of the paper will have called
6229200	6237520	it a theorem or a lemma? Well, I would guess yes, because there are different subtle cues,
6237520	6245680	but I didn't try. What I tried, what I did try is I gave LLM some inequalities, like very simple
6245680	6250880	elementary inequalities. Some were written by humans from the problem sets, from MO problem
6250880	6256160	sets, for example. And others are just generated randomly by machines, which typically look very
6256160	6263120	messy. And LLMs can do a reasonably good job at that task. Although I would say that task may not
6263120	6267520	be very difficult. Well, okay, so we've tried to do things like this, because we've been interested
6267520	6272320	in automated testing of Mathematica and Moulton language. So we're interested in generating
6272320	6278240	tests that are plausible input, so to speak. So we've indeed tried doing things like that.
6279200	6283680	Not been particularly successful. I mean, in other words, you can, you can generate an
6283680	6288800	expression at random just by some Markov process, for example, and you can generate an expression
6288800	6295520	by using some LLM like device. And you can ask the question, you know, given, given that you've seen,
6296240	6301920	I don't know, we've got billions of sort of human related Wolfram language expressions.
6301920	6307520	And then the question is, can we generate others that are like those? That's one question. Another
6307520	6313120	question of great practical interest for us is, can we guess whether something that somebody entered
6313200	6319440	is likely to be what they meant? Or is it something, in other words, it's like asking the question,
6319440	6323920	is this a, a plausible sentence, or is this a sentence nobody would ever write,
6324640	6328320	which is something which LLMs in a sense implicitly are capable of doing?
6329360	6334720	I must make an executive decision now. And it's a calculated risk. We may lose
6335440	6340880	Steven Wolfram, if it turns out he has something else of higher priority. We may use lose other
6340880	6347040	people for the panel, in which case I will have called closure on this needlessly. And there may
6347040	6351600	be nothing in the panel, but I have to call closure because we have to stop this session
6351600	6357600	and then restart for the next session. I want to thank you very much, Steven, for your, for
6357600	6363440	your talk. And I hope we'll be seeing you again in 10 minutes, but we'll see. Okay.
6364000	6366720	Are we using the same link for the panel?
6368720	6371040	Are we using the same Zoom link for the panel?
6371040	6375200	I will redo it on, I'll restart it for the panel and I hope you'll be there.
6376240	6379440	Steven's there too, but I have to break it now.
